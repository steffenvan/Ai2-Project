<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004134">
<title confidence="0.986798">
Automated planning for situated natural language generation
</title>
<author confidence="0.975417">
Konstantina Garoufi and Alexander Koller
</author>
<affiliation confidence="0.9349865">
Cluster of Excellence “Multimodal Computing and Interaction”
Saarland University, Saarbr¨ucken, Germany
</affiliation>
<email confidence="0.991563">
{garoufi,koller}@mmci.uni-saarland.de
</email>
<sectionHeader confidence="0.997289" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999001875">
We present a natural language genera-
tion approach which models, exploits, and
manipulates the non-linguistic context in
situated communication, using techniques
from AI planning. We show how to gen-
erate instructions which deliberately guide
the hearer to a location that is convenient
for the generation of simple referring ex-
pressions, and how to generate referring
expressions with context-dependent adjec-
tives. We implement and evaluate our
approach in the framework of the Chal-
lenge on Generating Instructions in Vir-
tual Environments, finding that it performs
well even under the constraints of real-
time generation.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.988884541666667">
The problem of situated natural language gen-
eration (NLG)—i.e., of generating natural lan-
guage in the context of a physical (or virtual)
environment—has received increasing attention in
the past few years. On the one hand, this is be-
cause it is the foundation of various emerging ap-
plications, including human-robot interaction and
mobile navigation systems, and is the focus of a
current evaluation effort, the Challenges on Gener-
ating Instructions in Virtual Environments (GIVE;
(Koller et al., 2010b)). On the other hand, situated
generation comes with interesting theoretical chal-
lenges: Compared to the generation of pure text,
the interpretation of expressions in situated com-
munication is sensitive to the non-linguistic con-
text, and this context can change as easily as the
user can move around in the environment.
One interesting aspect of situated communica-
tion from an NLG perspective is that this non-
linguistic context can be manipulated by the
speaker. Consider the following segment of dis-
course between an instruction giver (IG) and an
instruction follower (IF), which is adapted from
the SCARE corpus (Stoia et al., 2008):
</bodyText>
<listItem confidence="0.804449666666667">
(1) IG: Walk forward and then turn right.
IF: (walks and turns)
IG: OK. Now hit the button in the middle.
</listItem>
<bodyText confidence="0.999888342857143">
In this example, the IG plans to refer to an ob-
ject (here, a button); and in order to do so, gives a
navigation instruction to guide the IF to a conve-
nient location at which she can then use a simple
referring expression (RE). That is, there is an inter-
action between navigation instructions (intended
to manipulate the non-linguistic context in a cer-
tain way) and referring expressions (which exploit
the non-linguistic context). Although such subdi-
alogues are common in SCARE, we are not aware
of any previous research that can generate them in
a computationally feasible manner.
This paper presents an approach to generation
which is able to model the effect of an utter-
ance on the non-linguistic context, and to inten-
tionally generate utterances such as the above as
part of a process of referring to objects. Our ap-
proach builds upon the CRISP generation system
(Koller and Stone, 2007), which translates gener-
ation problems into planning problems and solves
these with an AI planner. We extend the CRISP
planning operators with the perlocutionary effects
that uttering a particular word has on the physi-
cal environment if it is understood correctly; more
specifically, on the position and orientation of the
hearer. This allows the planner to predict the non-
linguistic context in which a later part of the ut-
terance will be interpreted, and therefore to search
for contexts that allow the use of simple REs. As a
result, the work of referring to an object gets dis-
tributed over multiple utterances of low cognitive
load rather than a single complex noun phrase.
A second contribution of our paper is the gen-
eration of REs involving context-dependent adjec-
tives: A button can be described as “the left blue
</bodyText>
<page confidence="0.891522">
1573
</page>
<note confidence="0.9423075">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1573–1582,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999962514285714">
button” even if there is a red button to its left. We
model adjectives whose interpretation depends on
the nominal phrases they modify, as well as on the
non-linguistic context, by keeping track of the dis-
tractors that remain after uttering a series of mod-
ifiers. Thus, unlike most other RE generation ap-
proaches, we are not restricted to building an RE
by simply intersecting lexically specified sets rep-
resenting the extensions of different attributes, but
can correctly generate expressions whose mean-
ing depends on the context in a number of ways.
In this way we are able to refer to objects earlier
and more flexibly.
We implement and evaluate our approach in
the context of a GIVE NLG system, by using
the GIVE-1 software infrastructure and a GIVE-1
evaluation world. This shows that our system gen-
erates an instruction-giving discourse as in (1) in
about a second. It outperforms a mostly non-
situated baseline significantly, and compares well
against a second baseline based on one of the
top-performing systems of the GIVE-1 Challenge.
Next to the practical usefulness this evaluation es-
tablishes, we argue that our approach to jointly
modeling the grammatical and physical effects of
a communicative action can also inform new mod-
els of the pragmatics of speech acts.
Plan of the paper. We discuss related work in
Section 2, and review the CRISP system, on which
our work is based, in Section 3. We then show
in Section 4 how we extend CRISP to generate
navigation-and-reference discourses as in (1), and
add context-dependent adjectives in Section 5. We
evaluate our system in Section 6; Section 7 con-
cludes and points to future work.
</bodyText>
<sectionHeader confidence="0.999931" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999318815384616">
The research reported here can be seen in the
wider context of approaches to generating refer-
ring expressions. Since the foundational work of
Dale and Reiter (1995), there has been a consider-
able amount of literature on this topic. Our work
departs from the mainstream in two ways. First, it
exploits the situated communicative setting to de-
liberately modify the context in which an RE is
generated. Second, unlike most other RE genera-
tion systems, we allow the contribution of a modi-
fier to an RE to depend both on the context and on
the rest of the RE.
We are aware of only one earlier study on gen-
eration of REs with focus on interleaving naviga-
tion and referring (Stoia et al., 2006). In this ma-
chine learning approach, Stoia et al. train classi-
fiers that signal when the context conditions (e.g.
visibility of target and distractors) are appropriate
for the generation of an RE. This method can be
then used as part of a content selection component
of an NLG system. Such a component, however,
can only inform a system on whether to choose
navigation over RE generation at a given point of
the discourse, and is not able to help it decide
what kind of navigational instructions to generate
so that subsequent REs become simple.
To our knowledge, the only previous research
on generating REs with context-dependent modi-
fiers is van Deemter’s (2006) algorithm for gener-
ating vague adjectives. Unlike van Deemter, we
integrate the RE generation process tightly with
the syntactic realization, which allows us to gen-
erate REs with more than one context-dependent
modifier and model the effect of their linear or-
der on the meaning of the phrase. In modeling
the context, we focus on the non-linguistic con-
text and the influence of each of the RE’s words;
this is in contrast to previous research on context-
sensitive generation of REs, which mainly focused
on the discourse context (Krahmer and Theune,
2002). Our interpretation of context-dependent
modifiers picks up ideas by Kamp and Partee
(1995) and implements them in a practical system,
while our method of ordering modifiers is linguis-
tically informed by the class-based paradigm (e.g.,
Mitchell (2009)).
On the other hand, our work also stands in a tra-
dition of NLG research that is based on AI plan-
ning. Early approaches (Perrault and Allen, 1980;
Appelt, 1985) provided compelling intuitions for
this connection, but were not computationally vi-
able. The research we report here can be seen
as combining Appelt’s idea of using planning for
sentence-level NLG with a computationally be-
nign variant of Perrault et al.’s approach of model-
ing the intended perlocutionary effects of a speech
act as the effects of a planning operator. Our work
is linked to a growing body of very recent work
that applies modern planning research to various
problems in NLG (Steedman and Petrick, 2007;
Brenner and Kruijff-Korbayov´a, 2008; Benotti,
2009). It is directly based on Koller and Stone’s
(2007) reimplementation of the SPUD generator
(Stone et al., 2003) with planning. As far as we
know, ours is the first system in the SPUD tradi-
</bodyText>
<page confidence="0.997381">
1574
</page>
<figureCaption confidence="0.999606">
Figure 1: (a) An example grammar; (b) a derivation of “John pushes the red button” using (a).
</figureCaption>
<figure confidence="0.997046931034483">
John
N:b1
red N *
semcontent: {John(self)}
semcontent: {button(self)}
semcontent: {push(self,subj,obj)}
the
NP:self
(a) S:self (b) S:e
NP:self
NP:subj 1 VP:self
the
V:e
pushes
V:self
pushes
NP:obj 1
NP:j
John
NP:b1 1
NP:b1
NP:j 1 VP:e
N:self
button
N:b1
button
N:self
red N *
semcontent: {red(self)}
</figure>
<bodyText confidence="0.998891">
tion that explicitly models the context change ef-
fects of an utterance.
While nothing in our work directly hinges on
this, we implemented our approach in the context
of an NLG system for the GIVE Challenge (Koller
et al., 2010b), that is, as an instruction giving sys-
tem for virtual worlds. This makes our system
comparable with other approaches to instruction
giving implemented in the GIVE framework.
</bodyText>
<sectionHeader confidence="0.928103" genericHeader="method">
3 Sentence generation as planning
</sectionHeader>
<bodyText confidence="0.9999596">
Our work is based on the CRISP system (Koller
and Stone, 2007), which encodes sentence gener-
ation with tree-adjoining grammars (TAG; (Joshi
and Schabes, 1997)) as an AI planning problem
and solves that using efficient planners. It then
decodes the resulting plan into a TAG derivation,
from which it can read off a sentence. In this sec-
tion, we briefly recall how this works. For space
reasons, we will present primarily examples in-
stead of definitions.
</bodyText>
<subsectionHeader confidence="0.999361">
3.1 TAG sentence generation
</subsectionHeader>
<bodyText confidence="0.999973052631579">
The CRISP generation problem (like that of SPUD
(Stone et al., 2003)) assumes a lexicon of entries
consisting of a TAG elementary tree annotated
with semantic and pragmatic information. An ex-
ample is shown in Fig. 1a. In addition to the el-
ementary tree, each lexicon entry specifies its se-
mantic content and possibly a semantic require-
ment, which can express certain presuppositions
triggered by this entry. The nodes in the tree may
be labeled with argument names such as semantic
roles, which specify the participants in the rela-
tion expressed by the lexicon entry; in the exam-
ple, every entry uses the semantic role self repre-
senting the event or individual itself, and the en-
try for “pushes” furthermore uses subj and obj for
the subject and object argument, respectively. We
combine here for simplicity the entries for “the”
and “button” into “the button”.
For generation, we assume as input a knowl-
edge base and a communicative goal in addition to
the grammar. The goal is to compute a derivation
that expresses the communicative goal in a sen-
tence that is grammatically correct and complete;
whose meaning is justified by the knowledge base;
and in which all REs can be resolved to unique
individuals in the world by the hearer. Let’s say,
for example, that we have a knowledge base
{push(e, j, b1), John(j), button(b1), button(b2),
red(b1)j. Then we can combine instances of the
trees for “John”, “pushes”, and “the button” into
a grammatically complete derivation. However,
because both b1 and b2 satisfy the semantic
content of “the button”, we must adjoin “red” into
the derivation to make the RE refer uniquely to
b1. The complete derivation is shown in Fig. 1b;
we can read off the output sentence “John pushes
the red button” from the leaves of the derived tree
we build in this way.
</bodyText>
<subsectionHeader confidence="0.997192">
3.2 TAG generation as planning
</subsectionHeader>
<bodyText confidence="0.999982666666667">
In the CRISP system, Koller and Stone (2007)
show how this generation problem can be solved
by converting it into a planning problem (Nau et
al., 2004). The basic idea is to encode the partial
derivation in the planning state, and to encode the
action of adding each elementary tree in the plan-
ning operators. The encoding of our example as a
planning problem is shown in Fig. 2.
In the example, we start with an initial state
which contains the entire knowledge base, plus
atoms subst(S, root) and ref(root, e) expressing
that we want to generate a sentence about the event
e. We can then apply the (instantiated) action
pushes(root, n1, n2, n3, e, j, b1), which models the
act of substituting the elementary tree for “pushes”
</bodyText>
<page confidence="0.537284">
1575
</page>
<equation confidence="0.99474225">
pushes(u, u1, u2, un, x, x1, x2):
Precond: subst(S, u), ref(u, x), push(x, x1, x2),
current(u1), next(u1, u2), next(u2, un)
Effect: -subst(S, u), subst(NP, u1), subst(NP, u2),
ref(u1, x1), ref(u2, x2), `dy.distractor(u1, y),
`dy.distractor(u2, y)
John(u, x):
Precond: subst(NP, u), ref(u, x), John(x)
Effect: -subst(NP, u), `dy.-John(y) --+ -distractor(u, y)
the-button(u, x):
Precond: subst(NP, u), ref(u, x), button(x)
Effect: -subst(NP, u), canadjoin(N, u),
`dy.-button(y) --+ -distractor(u, y)
red(u, x):
Precond: canadjoin(N, u), ref(u, x), red(x)
Effect: `dy.-red(y) --+ -distractor(u, y)
</equation>
<figureCaption confidence="0.9936405">
Figure 2: CRISP planning operators for the ele-
mentary trees in Fig. 1.
</figureCaption>
<bodyText confidence="0.985497066666667">
into the substitution node root: It can only be
applied because root is an unfilled substitution
node (precondition subst(S, root)), and its effect
is to remove subst(S, root) from the planning state
while adding two new atoms subst(NP, n1) and
subst(NP, n2) for the substitution nodes of the
“pushes” tree. The planning state maintains in-
formation about which individual each node refers
to in the ref atoms. The current and next atoms
are needed to select unused names for newly in-
troduced syntax nodes.1 Finally, the action in-
troduces a number of distractor atoms including
distractor(n2, e) and distractor(n2, b2), express-
ing that the RE at n2 can still be misunderstood
by the hearer as e or b2.
In this new state, all subst and distractor
atoms for n1 can be eliminated with the ac-
tion John(n1, j). We can also apply the action
the-button(n2, b1) to eliminate subst(NP, n2)
and distractor(n2, e), since e is not a button.
However distractor(n2, b2) remains. Now be-
cause the action the-button also introduced the
atom canadjoin(N, n2), we can remove the fi-
nal distractor atom by applying red(n2, b1).
This brings us into a goal state, and we
are done. Goal states in CRISP planning
problems are characterized by axioms such as
bAbu.-,subst(A, u) (encoding grammatical com-
pleteness) and bubx.-,distractor(u, x) (requiring
unique reference).
</bodyText>
<footnote confidence="0.907714666666667">
1This is a different solution to the name-selection problem
than in Koller and Stone (2007). It is simpler and improves
computational efficiency.
</footnote>
<figureCaption confidence="0.997366">
Figure 3: An example map for instruction giving.
</figureCaption>
<subsectionHeader confidence="0.998745">
3.3 Decoding the plan
</subsectionHeader>
<bodyText confidence="0.999985857142857">
An AI planner such as FF (Hoffmann and Nebel,
2001) can compute a plan for a planning problem
that consists of the planning operators in Fig. 2
and a specification of the initial state and the goal.
We can then decode this plan into the TAG deriva-
tion shown in Fig. 1b. The basic idea of this
decoding step is that an action with a precondi-
tion subst(A, u) fills the substitution node u, while
an action with a precondition canadjoin(A, u) ad-
joins into a node of category A in the elementary
tree that was substituted into u. CRISP allows
multiple trees to adjoin into the same node. In this
case, the decoder executes the adjunctions in the
order in which they occur in the plan.
</bodyText>
<sectionHeader confidence="0.989106" genericHeader="method">
4 Context manipulation
</sectionHeader>
<bodyText confidence="0.999815">
We are now ready to describe our NLG ap-
proach, SCRISP (“Situated CRISP”), which ex-
tends CRISP to take the non-linguistic context of
the generated utterance into account, and deliber-
ately manipulate it to simplify RE generation.
As a simplified version of our introductory in-
struction giving example (1), consider the map in
Fig. 3. The instruction follower (IF), who is lo-
cated on the map at position pos3�2 facing north,
sees the scene from the first-person perspective as
in Fig. 7. Now an instruction giver (IG) could in-
struct the IF to press the button b1 in this scene by
saying “push the button on the wall to your left”.
Interpreting this instruction is difficult for the IF
because it requires her to either memorize the RE
until she has turned to see the button, or to per-
form a mental rotation task to visualize b1 inter-
nally. Alternatively, the IG can first instruct the
IF to “turn left”; once the IF has done this, the IG
can then simply say “now push the button in front
</bodyText>
<figure confidence="0.980314833333333">
3
2
1
4
b1
1 2 3 4
f1
b2 b3
north
1576
semreq: visible(p, o, obj)
nonlingcon: player–pos(p),
player–ori(o)
impeff: push(obj)
nonlingcon: player–ori(o1),
next–ori–left(o1, o2)
nonlingeff: -player–ori(o1),
player–ori(o2)
impeff: turnleft
S:self * and S:other ↓
S:self
Adv
left
V:self
turn
S:self
V:self
push
NP:obj ↓
S:self
</figure>
<equation confidence="0.830258857142857">
turnleft(u, x, o1, o2):
Precond: subst(S, u), ref(u, x), player–ori(o1),
next–ori–left(o1, o2), .. .
Effect: -subst(S, u), -player–ori(o1), player–ori(o2),
to–do(turnleft), ...
push(u, u1, un, x, x1, p, o):
Precond: subst(S, u), ref(u, x), player–pos(p),
player–ori(o), visible(p, o, x1), .. .
Effect: -subst(S, u), subst(NP, u1), ref(u1, x1),
Vy.(y # x1 ∧ visible(p, o, y) --+ distractor(u1, y)),
to–do(push(x1)), canadjoin(S, u), .. .
and(u, u1, un, e1, e2):
Precond: canadjoin(S, u), ref(u, e1), ...
Effect: subst(S, u1), ref(u1, e2), .. .
</equation>
<figureCaption confidence="0.996692">
Figure 4: An example SCRISP lexicon.
</figureCaption>
<bodyText confidence="0.9980478125">
of you”. This lowers the cognitive load on the IF,
and presumably improves the rate of correctly in-
terpreted REs.
SCRISP is capable of deliberately generat-
ing such context-changing navigation instructions.
The key idea of our approach is to extend the
CRISP planning operators with preconditions and
effects that describe the (simulated) physical envi-
ronment: A “turn left” action, for example, mod-
ifies the IF’s orientation in space and changes the
set of visible objects; a “push” operator can then
pick up this changed set and restrict the distractors
of the forthcoming RE it introduces (i.e. “the but-
ton”) to only objects that are visible in the changed
context. We also extend CRISP to generate imper-
ative rather than declarative sentences.
</bodyText>
<subsectionHeader confidence="0.883969">
4.1 Situated CRISP
</subsectionHeader>
<bodyText confidence="0.856930210526316">
We define a lexicon for SCRISP to be a CRISP
lexicon in which every lexicon entry may also de-
scribe non-linguistic conditions, non-linguistic ef-
fects and imperative effects. Each of these is a
set of atoms over constants, semantic roles, and
possibly some free variables. Non-linguistic con-
ditions specify what must be true in the world
so a particular instance of a lexicon entry can be
uttered felicitously; non-linguistic effects specify
what changes uttering the word brings about in the
world; and imperative effects contribute to the IF’s
“to-do list” (Portner, 2007) by adding the proper-
ties they denote.
A small lexicon for our example is shown in
Fig. 4. This lexicon specifies that saying “push
X” puts pushing X on the IF’s to-do list, and car-
ries the presupposition that X must be visible from
the location where “push X” is uttered; this re-
flects our simplifying assumption that the IG can
</bodyText>
<figureCaption confidence="0.904362">
Figure 5: SCRISP planning operators for the lexi-
con in Fig. 4.
</figureCaption>
<bodyText confidence="0.999904296296296">
only refer to objects that are currently visible.
Similarly, “turn left” puts turning left on the IF’s
agenda. In addition, the lexicon entry for “turn
left” specifies that, under the assumption that the
IF understands and follows the instruction, they
will turn 90 degrees to the left after hearing it. The
planning operators are written in a way that as-
sumes that the intended (perlocutionary) effects of
an utterance actually come true. This assumption
is crucial in connecting the non-linguistic effects
of one SCRISP action to the non-linguistic pre-
conditions of another, and generalizes to a scalable
model of planning perlocutionary acts. We discuss
this in more detail in Koller et al. (2010a).
We then translate a SCRISP generation prob-
lem into a planning problem. In addition to what
CRISP does, we translate all non-linguistic condi-
tions into preconditions and all non-linguistic ef-
fects into effects of the planning operator, adding
any free variables to the operator’s parameters.
An imperative effect P is translated into an ef-
fect to–do(P). The operators for the example lex-
icon of Fig. 4 are shown in Fig. 5. Finally, we
add information about the situated environment to
the initial state, and specify the planning goal by
adding to–do(P) atoms for each atom P that is to
be placed on the IF’s agenda.
</bodyText>
<subsectionHeader confidence="0.996057">
4.2 An example
</subsectionHeader>
<bodyText confidence="0.954917333333333">
Now let’s look at how this generates the appropri-
ate instructions for our example scene of Fig. 3.
We encode the state of the world as depicted
in the map in an initial state which contains,
among others, the atoms player–pos(pos3,2),
player–ori(north), next–ori–left(north,west),
</bodyText>
<page confidence="0.982915">
1577
</page>
<bodyText confidence="0.999769586206897">
visible(pos3�2, west, b1), etc.2 We want the IF to
press b1, so we add to–do(push(b1)) to the goal.
We can start by applying the action
turnleft(root, e, north, west) to the initial
state. Next to the ordinary grammatical effects
from CRISP, this action makes player–ori(west)
true. The new state does not contain any subst
atoms, but we can continue the sentence by
adjoining “and”, i.e. by applying the action
and(root, n1, n2, e, e1). This produces a new
atom subst(S, e1), which satisfies one precon-
dition of push(n1, n2, n3, e1, b1, pos3�2, west).
Because turnleft changed the player orientation,
the visible precondition of push is now satisfied
too (unlike in the initial state, in which b1 was not
visible). Applying the action push now introduces
the need to substitute a noun phrase for the object,
which we can eliminate with an application of
the-button(n2, b1) as in Subsection 3.2.
Since there are no other visible buttons from
pos3�2 facing west, there are no remaining
distractor atoms at this point, and a goal state
has been reached. Together, this four-step plan
decodes into the sentence “turn left and push
the button”. The final state contains the atoms
to–do(push(b1)) and to–do(turnleft), indicating
that an IF that understands and accepts this in-
struction also accepts these two commitments into
their to-do list.
</bodyText>
<sectionHeader confidence="0.983166" genericHeader="method">
5 Generating context-dependent
adjectives
</sectionHeader>
<bodyText confidence="0.9999678125">
Now consider if we wanted to instruct the IF to
press b2 in Fig. 3 instead of b1, say with the
instruction “push the left button”. This is still
challenging, because (like most other approaches
to RE generation) CRISP interprets adjectives by
simply intersecting all their extensions. In the case
of “left”, the most reasonable way to do this would
be to interpret it as “leftmost among all visible ob-
jects”; but this is f1 in the example, and so there is
no distinguishing RE for b2.
In truth, spatial adjectives like “left” and “up-
per” depend on the context in two different ways.
On the one hand, they are interpreted with respect
to the current spatio-visual context, in that what is
on the left depends on the current position and ori-
entation of the hearer. On the other hand, they also
</bodyText>
<footnote confidence="0.99242125">
2In a more complex situation, it may be infeasible to ex-
haustively model visibility in this way. This could be fixed by
connecting the planner to an external spatial reasoner (Dorn-
hege et al., 2009).
</footnote>
<equation confidence="0.9906402">
left(u, x):
Precond: `dy.-(distractor(u, y) n left–of(y, x)),
canadjoin(N, u), ref(u, x)
Effect: `dy.(left–of(x, y) --+ -distractor(u, y)),
premod–index(u, 2), .. .
red(u, x):
Precond: red(x), canadjoin(N, u), ref(u, x),
-premod–index(u, 2)
Effect: `dy.(-red(y) --+ -distractor(u, y)),
premod–index(u, 1), .. .
</equation>
<figureCaption confidence="0.985652">
Figure 6: SCRISP operators for context-
dependent and context-independent adjectives.
</figureCaption>
<bodyText confidence="0.998181714285714">
depend on the meaning of the phrase they modify:
“the left button” is not necessarily both a button
and further to the left than all other objects, it is
only the leftmost object among the buttons.
We will now show how to extend SCRISP so it
can generate REs that use such context-dependent
adjectives.
</bodyText>
<subsectionHeader confidence="0.957585">
5.1 Context-dependence of adjectives in
SCRISP
</subsectionHeader>
<bodyText confidence="0.999969344827586">
As a planning-based approach to NLG, SCRISP
is not limited to simply intersecting sets of po-
tential referents that only depend on the attributes
that contribute to an RE: Distractors are removed
by applying operators which may have context-
sensitive conditions depending on the referent and
the distractors that are still left.
Our encoding of context-dependent adjectives
as planning operators is shown in Fig. 6. We only
show the operators here for lack of space; they can
of course be computed automatically from lexicon
entries. In addition to the ordinary CRISP precon-
ditions, the left operator has a precondition requir-
ing that no current distractor for the RE u is to the
left of x, capturing a presupposition of the adjec-
tive. Its effect is that everything that is to the right
of x is no longer a distractor for u. Notice that we
allow that there may still be distractors after left
has been applied (above or below x); we only re-
quire unique reference in the goal state. (Ignore
the premod–index part of the effect for now; we
will get to that in a moment.)
Let’s say that we are computing a plan for re-
ferring to b2 in the example map of Fig. 3, starting
with push(root, n1, n2, e, b2, pos31, north) and
the-button(n1, b2). The state after these two ac-
tions is not a goal state, because it still contains
the atom distractor(n1, b3) (the plant f1 was re-
moved as a distractor by the action the-button).
</bodyText>
<page confidence="0.984809">
1578
</page>
<bodyText confidence="0.999976108108108">
Now assume that we have modeled the spatial
relations between all objects in the initial state
in left–of and above atoms; in particular, we
have left–of(b2, b3). Then the action instance
left(n1, b2) is applicable in this state, as there is
no other object that is still a distractor in this state
and that is to the left of b2. Applying left removes
distractor(n1, b3) from the state. Thus we have
reached a goal state; the complete plan decodes to
the sentence “push the left button”.
This system is sensitive to the order in which
operators for context-dependent adjectives are ap-
plied. To generate the RE “the upper left but-
ton”, for instance, we first apply the left action and
then the upper action, and therefore upper only
needs to remove distractors in the leftmost posi-
tion. On the other hand, the RE “the left upper
button” corresponds to first applying upper and
then left. These action sequences succeed in re-
moving all distractors for different context states,
which is consistent with the difference in meaning
between the two REs.
Furthermore, notice that the adjective operators
themselves do not interact directly with the en-
coding of the context in atoms like visible and
player–pos, just like the noun operators in Sec-
tion 4 didn’t. The REs to which the adjectives and
nouns contribute are introduced by verb operators;
it is these verb operators that inspect the current
context and initialize the distractor set for the new
RE appropriately. This makes the correctness of
the generated sentence independent of the order in
which noun and adjective operators occur in the
plan. We only need to ensure that the verbs are
ordered correctly, and the workload of modeling
interactions with the non-linguistic context is lim-
ited to a single place in the encoding.
</bodyText>
<subsectionHeader confidence="0.998916">
5.2 Adjective word order
</subsectionHeader>
<bodyText confidence="0.999908166666667">
One final challenge that arises in our system is to
generate the adjectives in the correct order, which
on top of semantically valid must be linguisti-
cally acceptable. In particular, it is known that
some types of adjectives are limited with respect
to the word order in which they can occur in a
noun phrase. For instance, “large foreign finan-
cial firms” sounds perfectly acceptable, but “? for-
eign large financial firms” sounds odd (Shaw and
Hatzivassiloglou, 1999). In our setting, some ad-
jective orders are forbidden because only one or-
der produces a correct and distinguishing descrip-
</bodyText>
<figureCaption confidence="0.911866">
Figure 7: The IF’s view of the scene in Fig. 3, as
rendered by the GIVE client.
</figureCaption>
<bodyText confidence="0.999890777777778">
tion of the target referent (cf. “upper left” vs. “left
upper” example above). However, there are also
other constraints at work: “? the red left button” is
rather odd even when it is a semantically correct
description, whereas “the left red button” is fine.
To ensure that SCRISP chooses to generate
these adjectives correctly, we follow a class-based
approach to the premodifier ordering problem
(Mitchell, 2009). In our lexicon we assign adjec-
tives denoting spatial relations (“left”) to one class
and adjectives denoting color (“red”) to another;
then we require that spatial adjectives must always
precede color adjectives. We enforce this by keep-
ing track of the current premodifier index of the RE
in atoms of the form premod–index. Any newly
generated RE node starts off with a premodifier
index of zero; adjoining an adjective of a certain
class then raises this number to the index for that
class. As the operators in Fig. 6 illustrate, color
adjectives such as “red” have index one and can
only be used while the index is not higher; once
an adjective from a higher class (such as “left”, of
a class with index two) is used, the premod–index
precondition of the “red” operator will fail. For
this reason, we can generate a plan for “the left
red button”, but not for “? the red left button”, as
desired.
</bodyText>
<sectionHeader confidence="0.997881" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.999681666666667">
To establish the quality of the generated instruc-
tions, we implemented SCRISP as part of a gener-
ation system in the GIVE-1 framework, and eval-
uated it against two baselines. GIVE-1 was the
First Challenge on Generating Instructions in Vir-
tual Environments, which was completed in 2009
</bodyText>
<page confidence="0.99878">
1579
</page>
<tableCaption confidence="0.995459">
Table 1: Example system instructions generated in
</tableCaption>
<bodyText confidence="0.989893944444444">
the same scene. REs for the target are typeset in
boldface.
(Koller et al., 2010b). In this challenge, sys-
tems must generate real-time instructions that help
users perform a task in a treasure-hunt virtual en-
vironment such as the one shown in Fig. 7.
We conducted our evaluation in World 2 from
GIVE-1, which was deliberately designed to be
challenging for RE generation. The world con-
sists of one room filled with several objects and
buttons, most of which cannot be distinguished by
simple descriptions. Moreover, some of those may
activate an alarm and cause the player to lose the
game. The player’s moves and turns are discrete
and the NLG system has complete and accurate
real-time information about the state of the world.
Instructions that each of the three systems under
comparison generated in an example scene of the
evaluation world are presented in Table 1.
The evaluation took place online via the Ama-
zon Mechanical Turk, where we collected 25
games for each system. We focus on four mea-
sures of evaluation: success rates for solving the
task and resolving the generated REs, average
task completion time (in seconds) for successful
games, and average distance (in steps) between the
IF and the referent at the time when the RE was
generated. As in the challenge, the task is consid-
ered as solved if the player has correctly been led
through manipulating all target objects required to
discover and collect the treasure; in World 2, the
minimum number of such targets is eight. An RE
is successfully resolved if it results in the manipu-
lation of the referent, whereas manipulation of an
alarm-triggering distractor ends the game unsuc-
cessfully.
</bodyText>
<subsectionHeader confidence="0.998699">
6.1 The SCRISP system
</subsectionHeader>
<bodyText confidence="0.997066">
Our system receives as input a plan for what the
IF should do to solve the task, and successively
takes object-manipulating actions as the commu-
</bodyText>
<table confidence="0.9990382">
success success RE
rate time distance
SCRISP 69% 306 71% 2.49
Baseline A 16%** 230 49%** 1.97*
Baseline B 84% 288 81%* 2.00*
</table>
<tableCaption confidence="0.99482">
Table 2: Evaluation results. Differences to
</tableCaption>
<bodyText confidence="0.984787736842105">
SCRISP are significant at *p &lt; .05, **p &lt; .005
(Pearson’s chi-square test for system success rates;
unpaired two-sample t-test for the rest).
nicative goals for SCRISP. Then, for each of the
communicative goals, it generates instructions us-
ing SCRISP, segments them into navigation and
action parts, and presents these to the user as sep-
arate instructions sequentially (see Table 1).
For each instruction, SCRISP thus draws from
a knowledge base of about 1500 facts and a gram-
mar of about 30 lexicon entries. We use the
FF planner (Hoffmann and Nebel, 2001; Koller
and Hoffmann, 2010) to solve the planning prob-
lems. The maximum planning time for any in-
struction is 1.03 seconds on a 3.06 GHz Intel Core
2 Duo CPU. So although our planning-based sys-
tem tackles a very difficult search problem, FF is
very good at solving it—fast enough to generate
instructions in real time.
</bodyText>
<subsectionHeader confidence="0.999879">
6.2 Comparison with Baseline A
</subsectionHeader>
<bodyText confidence="0.999857421052632">
Baseline A is a very basic system designed to sim-
ulate the performance of a classical RE genera-
tion module which does not attempt to manipu-
late the visual context. We hand-coded a correct
distinguishing RE for each target button in the
world; the only way in which Baseline A reacts
to changes of the context is to describe on which
wall the button is with respect to the user’s current
orientation (e.g. “Press the right red button on the
wall to your right”).
As Table 2 shows, our system guided 69% of
users to complete the task successfully, compared
to only 16% for Baseline A (difference is statis-
tically significant at p &lt; .005; Pearson’s chi-
square test). This is primarily because only 49%
of the REs generated by Baseline A were success-
ful. This comparison illustrates the importance of
REs that minimize the cognitive load on the IF to
avoid misunderstandings.
</bodyText>
<subsectionHeader confidence="0.999073">
6.3 Comparison with Baseline B
</subsectionHeader>
<bodyText confidence="0.994459">
Baseline B is a corrected and improved version
of the “Austin” system (Chen and Karpov, 2009),
</bodyText>
<figure confidence="0.991907923076923">
1. Turn right and move one step.
2. Push the right red button.
SCRISP
1. Press the right red button on the
wall to your right.
Baseline A
1. Turn right.
2. Walk forward 3 steps.
3. Turn right.
4. Walk forward 1 step.
5. Turn left.
6. Good! Now press the left button.
Baseline B
</figure>
<page confidence="0.966069">
1580
</page>
<bodyText confidence="0.999942567567568">
one of the best-performing systems of the GIVE-1
Challenge. Baseline B, like the original “Austin”
system, issues navigation instructions by precom-
puting the shortest path from the IF’s current lo-
cation to the target, and generates REs using the
description logic based algorithm of Areces et al.
(2008). Unlike the original system, which inflex-
ibly navigates the user all the way to the target,
Baseline B starts off with navigation, and oppor-
tunistically instructs the IF to push a button once it
has become visible and can be described by a dis-
tinguishing RE. We fixed bugs in the original im-
plementation of the RE generation module, so that
Baseline B generates only unambiguous REs. The
module nonetheless naively treats all adjectives as
intersective and is not sensitive to the context of
their comparison set. Specifically, a button can-
not be referred to as “the right red button” if it is
not the rightmost of all visible objects—which ex-
plains the long chain of navigational instructions
the system produced in Table 1.
We did not find any significant differences in
the success rates or task completion times between
this system and SCRISP, but the former achieved
a higher RE success rate (see Table 2). However,
a closer analysis shows that SCRISP was able to
generate REs from significantly further away. This
means that SCRISP’s RE generator solves a harder
problem, as it typically has to deal with more vis-
ible distractors. Furthermore, because of the in-
creased distance, the system’s execution monitor-
ing strategies (e.g. for detection and repair of mis-
understandings) become increasingly important,
and this was not a focus of this work. In summary,
then, we take the results to mean that SCRISP per-
forms quite capably in comparison to a top-ranked
GIVE-1 system.
</bodyText>
<sectionHeader confidence="0.998913" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999979844444444">
In this paper, we have shown how situated instruc-
tions can be generated using AI planning. We ex-
ploited the planner’s ability to model the perlocu-
tionary effects of communicative actions for effi-
cient generation. We showed how this made it pos-
sible to generate instructions that manipulate the
non-linguistic context in convenient ways, and to
generate correct REs with context-dependent ad-
jectives.
We believe that this illustrates the power of
a planning-based approach to NLG to flexibly
model very different phenomena. An interesting
topic for future work, for instance, is to expand our
notion of context by taking visual and discourse
salience into account when generating REs. In ad-
dition, we plan to experiment with assigning costs
to planning operators in a metric planning problem
(Hoffmann, 2002) in order to model the cognitive
cost of an RE (Krahmer et al., 2003) and compute
minimal-cost instruction sequences.
On a more theoretical level, the SCRISP actions
model the physical effects of a correctly under-
stood and grounded instruction directly as effects
of the planning operator. This is computationally
much less complex than classical speech act plan-
ning (Perrault and Allen, 1980), in which the in-
tended physical effect comes at the end of a long
chain of inferences. But our approach is also very
optimistic in estimating the perlocutionary effects
of an instruction, and must be complemented by an
appropriate model of execution monitoring. What
this means for a novel scalable approach to the
pragmatics of speech acts (Koller et al., 2010a)
is, we believe, an interesting avenue for future re-
search.
Acknowledgments. We are grateful to J¨org
Hoffmann for improving the efficiency of FF in the
SCRISP domain at a crucial time, and to Margaret
Mitchell, Matthew Stone and Kees van Deemter
for helping us expand our view of the context-
dependent adjective generation problem. We also
thank Ines Rehbein and Josef Ruppenhofer for
testing early implementations of our system, and
Andrew Gargett as well as the reviewers for their
helpful comments.
</bodyText>
<sectionHeader confidence="0.999476" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999435266666666">
Douglas E. Appelt. 1985. Planning English sentences.
Cambridge University Press, Cambridge, England.
Carlos Areces, Alexander Koller, and Kristina Strieg-
nitz. 2008. Referring expressions as formulas of
description logic. In Proceedings of the 5th Inter-
national Natural Language Generation Conference,
pages 42–49, Salt Fork, Ohio, USA.
Luciana Benotti. 2009. Clarification potential of in-
structions. In Proceedings of the SIGDIAL 2009
Conference, pages 196–205, London, UK.
Michael Brenner and Ivana Kruijff-Korbayov´a. 2008.
A continual multiagent planning approach to situ-
ated dialogue. In Proceedings of the 12th Workshop
on the Semantics and Pragmatics of Dialogue, Lon-
don, UK.
</reference>
<page confidence="0.807666">
1581
</page>
<reference confidence="0.999830078431372">
David Chen and Igor Karpov. 2009. The
GIVE-1 Austin system. In The First
GIVE Challenge: System descriptions.
http://www.give-challenge.org/
research/files/GIVE-09-Austin.pdf.
Robert Dale and Ehud Reiter. 1995. Computational
interpretations of the Gricean maxims in the genera-
tion of referring expressions. Cognitive Science, 19.
Christian Dornhege, Patrick Eyerich, Thomas Keller,
Sebastian Trig, Michael Brenner, and Bernhard
Nebel. 2009. Semantic attachments for domain-
independent planning systems. In Proceedings of
the 19th International Conference on Automated
Planning and Scheduling, pages 114–121.
J¨org Hoffmann and Bernhard Nebel. 2001. The
FF planning system: Fast plan generation through
heuristic search. Journal of Artificial Intelligence
Research, 14:253–302.
J¨org Hoffmann. 2002. Extending FF to numerical state
variables. In Proceedings of the 15th European Con-
ference on Artificial Intelligence, Lyon, France.
Aravind K. Joshi and Yves Schabes. 1997. Tree-
Adjoining Grammars. In G. Rozenberg and A. Salo-
maa, editors, Handbook of Formal Languages, vol-
ume 3, pages 69–123. Springer-Verlag, Berlin, Ger-
many.
Hans Kamp and Barbara Partee. 1995. Prototype the-
ory and compositionality. Cognition, 57(2):129 –
191.
Alexander Koller and J¨org Hoffmann. 2010. Waking
up a sleeping rabbit: On natural-language sentence
generation with FF. In Proceedings of the 20th In-
ternational Conference on Automated Planning and
Scheduling, Toronto, Canada.
Alexander Koller and Matthew Stone. 2007. Sentence
generation as planning. In Proceedings of the 45th
Annual Meeting of the Association of Computational
Linguistics, Prague, Czech Republic.
Alexander Koller, Andrew Gargett, and Konstantina
Garoufi. 2010a. A scalable model of planning per-
locutionary acts. In Proceedings of the 14th Work-
shop on the Semantics and Pragmatics of Dialogue,
Poznan, Poland.
Alexander Koller, Kristina Striegnitz, Donna Byron,
Justine Cassell, Robert Dale, Johanna Moore, and
Jon Oberlander. 2010b. The First Challenge on
Generating Instructions in Virtual Environments.
In M. Theune and E. Krahmer, editors, Empir-
ical Methods in Natural Language Generation,
volume 5790 of LNCS, pages 337–361. Springer,
Berlin/Heidelberg. To appear.
Emiel Krahmer and Mariet Theune. 2002. Effi-
cient context-sensitive generation of referring ex-
pressions. In Kees van Deemter and Rodger Kibble,
editors, Information Sharing: Reference and Pre-
supposition in Language Generation and Interpre-
tation, pages 223–264. CSLI Publications.
Emiel Krahmer, Sebastiaan van Erk, and Andr´e Verleg.
2003. Graph-based generation of referring expres-
sions. Computational Linguistics, 29(1):53–72.
Margaret Mitchell. 2009. Class-based ordering of
prenominal modifiers. In Proceedings of the 12th
European Workshop on Natural Language Genera-
tion, pages 50–57, Athens, Greece.
Dana Nau, Malik Ghallab, and Paolo Traverso. 2004.
Automated Planning: Theory and Practice. Morgan
Kaufmann.
C. Raymond Perrault and James F. Allen. 1980. A
plan-based analysis of indirect speech acts. Amer-
ican Journal of Computational Linguistics, 6(3–
4):167–182.
Paul Portner. 2007. Imperatives and modals. Natural
Language Semantics, 15(4):351–383.
James Shaw and Vasileios Hatzivassiloglou. 1999. Or-
dering among premodifiers. In Proceedings of the
37th Annual Meeting of the Association for Compu-
tational Linguistics, pages 135–143, College Park,
Maryland, USA.
Mark Steedman and Ronald P. A. Petrick. 2007. Plan-
ning dialog actions. In Proceedings of the 8th SIG-
dial Workshop on Discourse and Dialogue, pages
265–272, Antwerp, Belgium.
Laura Stoia, Donna K. Byron, Darla Magdalene Shock-
ley, and Eric Fosler-Lussier. 2006. Sentence
planning for realtime navigational instructions. In
NAACL ’06: Proceedings of the Human Language
Technology Conference of the NAACL, pages 157–
160, Morristown, NJ, USA.
Laura Stoia, Darla M. Shockley, Donna K. Byron,
and Eric Fosler-Lussier. 2008. SCARE: A sit-
uated corpus with annotated referring expressions.
In Proceedings of the 6th International Conference
on Language Resources and Evaluation, Marrakech,
Morocco.
Matthew Stone, Christine Doran, Bonnie Webber, To-
nia Bleam, and Martha Palmer. 2003. Microplan-
ning with communicative intentions: The SPUD
system. Computational Intelligence, 19(4):311–
381.
Kees van Deemter. 2006. Generating referring ex-
pressions that involve gradable properties. Compu-
tational Linguistics, 32(2).
</reference>
<page confidence="0.994331">
1582
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.786003">
<title confidence="0.999481">Automated planning for situated natural language generation</title>
<author confidence="0.997219">Garoufi Koller</author>
<affiliation confidence="0.9279385">Cluster of Excellence “Multimodal Computing and Interaction” Saarland University, Saarbr¨ucken, Germany</affiliation>
<abstract confidence="0.995197588235294">We present a natural language generation approach which models, exploits, and manipulates the non-linguistic context in situated communication, using techniques from AI planning. We show how to generate instructions which deliberately guide the hearer to a location that is convenient for the generation of simple referring expressions, and how to generate referring expressions with context-dependent adjectives. We implement and evaluate our approach in the framework of the Challenge on Generating Instructions in Virtual Environments, finding that it performs well even under the constraints of realtime generation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas E Appelt</author>
</authors>
<title>Planning English sentences.</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England.</location>
<contexts>
<context position="8018" citStr="Appelt, 1985" startWordPosition="1309" endWordPosition="1310">xt and the influence of each of the RE’s words; this is in contrast to previous research on contextsensitive generation of REs, which mainly focused on the discourse context (Krahmer and Theune, 2002). Our interpretation of context-dependent modifiers picks up ideas by Kamp and Partee (1995) and implements them in a practical system, while our method of ordering modifiers is linguistically informed by the class-based paradigm (e.g., Mitchell (2009)). On the other hand, our work also stands in a tradition of NLG research that is based on AI planning. Early approaches (Perrault and Allen, 1980; Appelt, 1985) provided compelling intuitions for this connection, but were not computationally viable. The research we report here can be seen as combining Appelt’s idea of using planning for sentence-level NLG with a computationally benign variant of Perrault et al.’s approach of modeling the intended perlocutionary effects of a speech act as the effects of a planning operator. Our work is linked to a growing body of very recent work that applies modern planning research to various problems in NLG (Steedman and Petrick, 2007; Brenner and Kruijff-Korbayov´a, 2008; Benotti, 2009). It is directly based on Ko</context>
</contexts>
<marker>Appelt, 1985</marker>
<rawString>Douglas E. Appelt. 1985. Planning English sentences. Cambridge University Press, Cambridge, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Areces</author>
<author>Alexander Koller</author>
<author>Kristina Striegnitz</author>
</authors>
<title>Referring expressions as formulas of description logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 5th International Natural Language Generation Conference,</booktitle>
<pages>42--49</pages>
<location>Salt Fork, Ohio, USA.</location>
<contexts>
<context position="33989" citStr="Areces et al. (2008)" startWordPosition="5672" endWordPosition="5675">” system (Chen and Karpov, 2009), 1. Turn right and move one step. 2. Push the right red button. SCRISP 1. Press the right red button on the wall to your right. Baseline A 1. Turn right. 2. Walk forward 3 steps. 3. Turn right. 4. Walk forward 1 step. 5. Turn left. 6. Good! Now press the left button. Baseline B 1580 one of the best-performing systems of the GIVE-1 Challenge. Baseline B, like the original “Austin” system, issues navigation instructions by precomputing the shortest path from the IF’s current location to the target, and generates REs using the description logic based algorithm of Areces et al. (2008). Unlike the original system, which inflexibly navigates the user all the way to the target, Baseline B starts off with navigation, and opportunistically instructs the IF to push a button once it has become visible and can be described by a distinguishing RE. We fixed bugs in the original implementation of the RE generation module, so that Baseline B generates only unambiguous REs. The module nonetheless naively treats all adjectives as intersective and is not sensitive to the context of their comparison set. Specifically, a button cannot be referred to as “the right red button” if it is not t</context>
</contexts>
<marker>Areces, Koller, Striegnitz, 2008</marker>
<rawString>Carlos Areces, Alexander Koller, and Kristina Striegnitz. 2008. Referring expressions as formulas of description logic. In Proceedings of the 5th International Natural Language Generation Conference, pages 42–49, Salt Fork, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luciana Benotti</author>
</authors>
<title>Clarification potential of instructions.</title>
<date>2009</date>
<booktitle>In Proceedings of the SIGDIAL 2009 Conference,</booktitle>
<pages>196--205</pages>
<location>London, UK.</location>
<contexts>
<context position="8590" citStr="Benotti, 2009" startWordPosition="1400" endWordPosition="1401">s (Perrault and Allen, 1980; Appelt, 1985) provided compelling intuitions for this connection, but were not computationally viable. The research we report here can be seen as combining Appelt’s idea of using planning for sentence-level NLG with a computationally benign variant of Perrault et al.’s approach of modeling the intended perlocutionary effects of a speech act as the effects of a planning operator. Our work is linked to a growing body of very recent work that applies modern planning research to various problems in NLG (Steedman and Petrick, 2007; Brenner and Kruijff-Korbayov´a, 2008; Benotti, 2009). It is directly based on Koller and Stone’s (2007) reimplementation of the SPUD generator (Stone et al., 2003) with planning. As far as we know, ours is the first system in the SPUD tradi1574 Figure 1: (a) An example grammar; (b) a derivation of “John pushes the red button” using (a). John N:b1 red N * semcontent: {John(self)} semcontent: {button(self)} semcontent: {push(self,subj,obj)} the NP:self (a) S:self (b) S:e NP:self NP:subj 1 VP:self the V:e pushes V:self pushes NP:obj 1 NP:j John NP:b1 1 NP:b1 NP:j 1 VP:e N:self button N:b1 button N:self red N * semcontent: {red(self)} tion that exp</context>
</contexts>
<marker>Benotti, 2009</marker>
<rawString>Luciana Benotti. 2009. Clarification potential of instructions. In Proceedings of the SIGDIAL 2009 Conference, pages 196–205, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Brenner</author>
<author>Ivana Kruijff-Korbayov´a</author>
</authors>
<title>A continual multiagent planning approach to situated dialogue.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Workshop on the Semantics and Pragmatics of Dialogue,</booktitle>
<location>London, UK.</location>
<marker>Brenner, Kruijff-Korbayov´a, 2008</marker>
<rawString>Michael Brenner and Ivana Kruijff-Korbayov´a. 2008. A continual multiagent planning approach to situated dialogue. In Proceedings of the 12th Workshop on the Semantics and Pragmatics of Dialogue, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chen</author>
<author>Igor Karpov</author>
</authors>
<title>The GIVE-1 Austin system.</title>
<date>2009</date>
<booktitle>In The First GIVE Challenge: System descriptions. http://www.give-challenge.org/</booktitle>
<pages>09</pages>
<contexts>
<context position="33401" citStr="Chen and Karpov, 2009" startWordPosition="5567" endWordPosition="5570">ser’s current orientation (e.g. “Press the right red button on the wall to your right”). As Table 2 shows, our system guided 69% of users to complete the task successfully, compared to only 16% for Baseline A (difference is statistically significant at p &lt; .005; Pearson’s chisquare test). This is primarily because only 49% of the REs generated by Baseline A were successful. This comparison illustrates the importance of REs that minimize the cognitive load on the IF to avoid misunderstandings. 6.3 Comparison with Baseline B Baseline B is a corrected and improved version of the “Austin” system (Chen and Karpov, 2009), 1. Turn right and move one step. 2. Push the right red button. SCRISP 1. Press the right red button on the wall to your right. Baseline A 1. Turn right. 2. Walk forward 3 steps. 3. Turn right. 4. Walk forward 1 step. 5. Turn left. 6. Good! Now press the left button. Baseline B 1580 one of the best-performing systems of the GIVE-1 Challenge. Baseline B, like the original “Austin” system, issues navigation instructions by precomputing the shortest path from the IF’s current location to the target, and generates REs using the description logic based algorithm of Areces et al. (2008). Unlike the</context>
</contexts>
<marker>Chen, Karpov, 2009</marker>
<rawString>David Chen and Igor Karpov. 2009. The GIVE-1 Austin system. In The First GIVE Challenge: System descriptions. http://www.give-challenge.org/ research/files/GIVE-09-Austin.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
<author>Ehud Reiter</author>
</authors>
<title>Computational interpretations of the Gricean maxims in the generation of referring expressions.</title>
<date>1995</date>
<journal>Cognitive Science,</journal>
<volume>19</volume>
<contexts>
<context position="5862" citStr="Dale and Reiter (1995)" startWordPosition="939" endWordPosition="942">cative action can also inform new models of the pragmatics of speech acts. Plan of the paper. We discuss related work in Section 2, and review the CRISP system, on which our work is based, in Section 3. We then show in Section 4 how we extend CRISP to generate navigation-and-reference discourses as in (1), and add context-dependent adjectives in Section 5. We evaluate our system in Section 6; Section 7 concludes and points to future work. 2 Related work The research reported here can be seen in the wider context of approaches to generating referring expressions. Since the foundational work of Dale and Reiter (1995), there has been a considerable amount of literature on this topic. Our work departs from the mainstream in two ways. First, it exploits the situated communicative setting to deliberately modify the context in which an RE is generated. Second, unlike most other RE generation systems, we allow the contribution of a modifier to an RE to depend both on the context and on the rest of the RE. We are aware of only one earlier study on generation of REs with focus on interleaving navigation and referring (Stoia et al., 2006). In this machine learning approach, Stoia et al. train classifiers that sign</context>
</contexts>
<marker>Dale, Reiter, 1995</marker>
<rawString>Robert Dale and Ehud Reiter. 1995. Computational interpretations of the Gricean maxims in the generation of referring expressions. Cognitive Science, 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Dornhege</author>
<author>Patrick Eyerich</author>
<author>Thomas Keller</author>
<author>Sebastian Trig</author>
<author>Michael Brenner</author>
<author>Bernhard Nebel</author>
</authors>
<title>Semantic attachments for domainindependent planning systems.</title>
<date>2009</date>
<booktitle>In Proceedings of the 19th International Conference on Automated Planning and Scheduling,</booktitle>
<pages>114--121</pages>
<contexts>
<context position="23199" citStr="Dornhege et al., 2009" startWordPosition="3834" endWordPosition="3838">as “leftmost among all visible objects”; but this is f1 in the example, and so there is no distinguishing RE for b2. In truth, spatial adjectives like “left” and “upper” depend on the context in two different ways. On the one hand, they are interpreted with respect to the current spatio-visual context, in that what is on the left depends on the current position and orientation of the hearer. On the other hand, they also 2In a more complex situation, it may be infeasible to exhaustively model visibility in this way. This could be fixed by connecting the planner to an external spatial reasoner (Dornhege et al., 2009). left(u, x): Precond: `dy.-(distractor(u, y) n left–of(y, x)), canadjoin(N, u), ref(u, x) Effect: `dy.(left–of(x, y) --+ -distractor(u, y)), premod–index(u, 2), .. . red(u, x): Precond: red(x), canadjoin(N, u), ref(u, x), -premod–index(u, 2) Effect: `dy.(-red(y) --+ -distractor(u, y)), premod–index(u, 1), .. . Figure 6: SCRISP operators for contextdependent and context-independent adjectives. depend on the meaning of the phrase they modify: “the left button” is not necessarily both a button and further to the left than all other objects, it is only the leftmost object among the buttons. We wi</context>
</contexts>
<marker>Dornhege, Eyerich, Keller, Trig, Brenner, Nebel, 2009</marker>
<rawString>Christian Dornhege, Patrick Eyerich, Thomas Keller, Sebastian Trig, Michael Brenner, and Bernhard Nebel. 2009. Semantic attachments for domainindependent planning systems. In Proceedings of the 19th International Conference on Automated Planning and Scheduling, pages 114–121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Hoffmann</author>
<author>Bernhard Nebel</author>
</authors>
<title>The FF planning system: Fast plan generation through heuristic search.</title>
<date>2001</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>14--253</pages>
<contexts>
<context position="14937" citStr="Hoffmann and Nebel, 2001" startWordPosition="2448" endWordPosition="2451">he-button also introduced the atom canadjoin(N, n2), we can remove the final distractor atom by applying red(n2, b1). This brings us into a goal state, and we are done. Goal states in CRISP planning problems are characterized by axioms such as bAbu.-,subst(A, u) (encoding grammatical completeness) and bubx.-,distractor(u, x) (requiring unique reference). 1This is a different solution to the name-selection problem than in Koller and Stone (2007). It is simpler and improves computational efficiency. Figure 3: An example map for instruction giving. 3.3 Decoding the plan An AI planner such as FF (Hoffmann and Nebel, 2001) can compute a plan for a planning problem that consists of the planning operators in Fig. 2 and a specification of the initial state and the goal. We can then decode this plan into the TAG derivation shown in Fig. 1b. The basic idea of this decoding step is that an action with a precondition subst(A, u) fills the substitution node u, while an action with a precondition canadjoin(A, u) adjoins into a node of category A in the elementary tree that was substituted into u. CRISP allows multiple trees to adjoin into the same node. In this case, the decoder executes the adjunctions in the order in </context>
<context position="32056" citStr="Hoffmann and Nebel, 2001" startWordPosition="5332" endWordPosition="5335">ne B 84% 288 81%* 2.00* Table 2: Evaluation results. Differences to SCRISP are significant at *p &lt; .05, **p &lt; .005 (Pearson’s chi-square test for system success rates; unpaired two-sample t-test for the rest). nicative goals for SCRISP. Then, for each of the communicative goals, it generates instructions using SCRISP, segments them into navigation and action parts, and presents these to the user as separate instructions sequentially (see Table 1). For each instruction, SCRISP thus draws from a knowledge base of about 1500 facts and a grammar of about 30 lexicon entries. We use the FF planner (Hoffmann and Nebel, 2001; Koller and Hoffmann, 2010) to solve the planning problems. The maximum planning time for any instruction is 1.03 seconds on a 3.06 GHz Intel Core 2 Duo CPU. So although our planning-based system tackles a very difficult search problem, FF is very good at solving it—fast enough to generate instructions in real time. 6.2 Comparison with Baseline A Baseline A is a very basic system designed to simulate the performance of a classical RE generation module which does not attempt to manipulate the visual context. We hand-coded a correct distinguishing RE for each target button in the world; the onl</context>
</contexts>
<marker>Hoffmann, Nebel, 2001</marker>
<rawString>J¨org Hoffmann and Bernhard Nebel. 2001. The FF planning system: Fast plan generation through heuristic search. Journal of Artificial Intelligence Research, 14:253–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Hoffmann</author>
</authors>
<title>Extending FF to numerical state variables.</title>
<date>2002</date>
<booktitle>In Proceedings of the 15th European Conference on Artificial Intelligence,</booktitle>
<location>Lyon, France.</location>
<contexts>
<context position="36289" citStr="Hoffmann, 2002" startWordPosition="6052" endWordPosition="6053">fficient generation. We showed how this made it possible to generate instructions that manipulate the non-linguistic context in convenient ways, and to generate correct REs with context-dependent adjectives. We believe that this illustrates the power of a planning-based approach to NLG to flexibly model very different phenomena. An interesting topic for future work, for instance, is to expand our notion of context by taking visual and discourse salience into account when generating REs. In addition, we plan to experiment with assigning costs to planning operators in a metric planning problem (Hoffmann, 2002) in order to model the cognitive cost of an RE (Krahmer et al., 2003) and compute minimal-cost instruction sequences. On a more theoretical level, the SCRISP actions model the physical effects of a correctly understood and grounded instruction directly as effects of the planning operator. This is computationally much less complex than classical speech act planning (Perrault and Allen, 1980), in which the intended physical effect comes at the end of a long chain of inferences. But our approach is also very optimistic in estimating the perlocutionary effects of an instruction, and must be comple</context>
</contexts>
<marker>Hoffmann, 2002</marker>
<rawString>J¨org Hoffmann. 2002. Extending FF to numerical state variables. In Proceedings of the 15th European Conference on Artificial Intelligence, Lyon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>Yves Schabes</author>
</authors>
<title>TreeAdjoining Grammars.</title>
<date>1997</date>
<booktitle>Handbook of Formal Languages,</booktitle>
<volume>3</volume>
<pages>69--123</pages>
<editor>In G. Rozenberg and A. Salomaa, editors,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin, Germany.</location>
<contexts>
<context position="9772" citStr="Joshi and Schabes, 1997" startWordPosition="1593" endWordPosition="1596"> N * semcontent: {red(self)} tion that explicitly models the context change effects of an utterance. While nothing in our work directly hinges on this, we implemented our approach in the context of an NLG system for the GIVE Challenge (Koller et al., 2010b), that is, as an instruction giving system for virtual worlds. This makes our system comparable with other approaches to instruction giving implemented in the GIVE framework. 3 Sentence generation as planning Our work is based on the CRISP system (Koller and Stone, 2007), which encodes sentence generation with tree-adjoining grammars (TAG; (Joshi and Schabes, 1997)) as an AI planning problem and solves that using efficient planners. It then decodes the resulting plan into a TAG derivation, from which it can read off a sentence. In this section, we briefly recall how this works. For space reasons, we will present primarily examples instead of definitions. 3.1 TAG sentence generation The CRISP generation problem (like that of SPUD (Stone et al., 2003)) assumes a lexicon of entries consisting of a TAG elementary tree annotated with semantic and pragmatic information. An example is shown in Fig. 1a. In addition to the elementary tree, each lexicon entry spe</context>
</contexts>
<marker>Joshi, Schabes, 1997</marker>
<rawString>Aravind K. Joshi and Yves Schabes. 1997. TreeAdjoining Grammars. In G. Rozenberg and A. Salomaa, editors, Handbook of Formal Languages, volume 3, pages 69–123. Springer-Verlag, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Barbara Partee</author>
</authors>
<title>Prototype theory and compositionality.</title>
<date>1995</date>
<journal>Cognition,</journal>
<volume>57</volume>
<issue>2</issue>
<pages>191</pages>
<contexts>
<context position="7697" citStr="Kamp and Partee (1995)" startWordPosition="1253" endWordPosition="1256"> vague adjectives. Unlike van Deemter, we integrate the RE generation process tightly with the syntactic realization, which allows us to generate REs with more than one context-dependent modifier and model the effect of their linear order on the meaning of the phrase. In modeling the context, we focus on the non-linguistic context and the influence of each of the RE’s words; this is in contrast to previous research on contextsensitive generation of REs, which mainly focused on the discourse context (Krahmer and Theune, 2002). Our interpretation of context-dependent modifiers picks up ideas by Kamp and Partee (1995) and implements them in a practical system, while our method of ordering modifiers is linguistically informed by the class-based paradigm (e.g., Mitchell (2009)). On the other hand, our work also stands in a tradition of NLG research that is based on AI planning. Early approaches (Perrault and Allen, 1980; Appelt, 1985) provided compelling intuitions for this connection, but were not computationally viable. The research we report here can be seen as combining Appelt’s idea of using planning for sentence-level NLG with a computationally benign variant of Perrault et al.’s approach of modeling t</context>
</contexts>
<marker>Kamp, Partee, 1995</marker>
<rawString>Hans Kamp and Barbara Partee. 1995. Prototype theory and compositionality. Cognition, 57(2):129 – 191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Koller</author>
<author>J¨org Hoffmann</author>
</authors>
<title>Waking up a sleeping rabbit: On natural-language sentence generation with FF.</title>
<date>2010</date>
<booktitle>In Proceedings of the 20th International Conference on Automated Planning and Scheduling,</booktitle>
<location>Toronto, Canada.</location>
<contexts>
<context position="32084" citStr="Koller and Hoffmann, 2010" startWordPosition="5336" endWordPosition="5339">ble 2: Evaluation results. Differences to SCRISP are significant at *p &lt; .05, **p &lt; .005 (Pearson’s chi-square test for system success rates; unpaired two-sample t-test for the rest). nicative goals for SCRISP. Then, for each of the communicative goals, it generates instructions using SCRISP, segments them into navigation and action parts, and presents these to the user as separate instructions sequentially (see Table 1). For each instruction, SCRISP thus draws from a knowledge base of about 1500 facts and a grammar of about 30 lexicon entries. We use the FF planner (Hoffmann and Nebel, 2001; Koller and Hoffmann, 2010) to solve the planning problems. The maximum planning time for any instruction is 1.03 seconds on a 3.06 GHz Intel Core 2 Duo CPU. So although our planning-based system tackles a very difficult search problem, FF is very good at solving it—fast enough to generate instructions in real time. 6.2 Comparison with Baseline A Baseline A is a very basic system designed to simulate the performance of a classical RE generation module which does not attempt to manipulate the visual context. We hand-coded a correct distinguishing RE for each target button in the world; the only way in which Baseline A re</context>
</contexts>
<marker>Koller, Hoffmann, 2010</marker>
<rawString>Alexander Koller and J¨org Hoffmann. 2010. Waking up a sleeping rabbit: On natural-language sentence generation with FF. In Proceedings of the 20th International Conference on Automated Planning and Scheduling, Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Koller</author>
<author>Matthew Stone</author>
</authors>
<title>Sentence generation as planning.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3023" citStr="Koller and Stone, 2007" startWordPosition="469" endWordPosition="472">navigation instructions (intended to manipulate the non-linguistic context in a certain way) and referring expressions (which exploit the non-linguistic context). Although such subdialogues are common in SCARE, we are not aware of any previous research that can generate them in a computationally feasible manner. This paper presents an approach to generation which is able to model the effect of an utterance on the non-linguistic context, and to intentionally generate utterances such as the above as part of a process of referring to objects. Our approach builds upon the CRISP generation system (Koller and Stone, 2007), which translates generation problems into planning problems and solves these with an AI planner. We extend the CRISP planning operators with the perlocutionary effects that uttering a particular word has on the physical environment if it is understood correctly; more specifically, on the position and orientation of the hearer. This allows the planner to predict the nonlinguistic context in which a later part of the utterance will be interpreted, and therefore to search for contexts that allow the use of simple REs. As a result, the work of referring to an object gets distributed over multipl</context>
<context position="9676" citStr="Koller and Stone, 2007" startWordPosition="1580" endWordPosition="1583">V:self pushes NP:obj 1 NP:j John NP:b1 1 NP:b1 NP:j 1 VP:e N:self button N:b1 button N:self red N * semcontent: {red(self)} tion that explicitly models the context change effects of an utterance. While nothing in our work directly hinges on this, we implemented our approach in the context of an NLG system for the GIVE Challenge (Koller et al., 2010b), that is, as an instruction giving system for virtual worlds. This makes our system comparable with other approaches to instruction giving implemented in the GIVE framework. 3 Sentence generation as planning Our work is based on the CRISP system (Koller and Stone, 2007), which encodes sentence generation with tree-adjoining grammars (TAG; (Joshi and Schabes, 1997)) as an AI planning problem and solves that using efficient planners. It then decodes the resulting plan into a TAG derivation, from which it can read off a sentence. In this section, we briefly recall how this works. For space reasons, we will present primarily examples instead of definitions. 3.1 TAG sentence generation The CRISP generation problem (like that of SPUD (Stone et al., 2003)) assumes a lexicon of entries consisting of a TAG elementary tree annotated with semantic and pragmatic informa</context>
<context position="11969" citStr="Koller and Stone (2007)" startWordPosition="1968" endWordPosition="1971"> example, that we have a knowledge base {push(e, j, b1), John(j), button(b1), button(b2), red(b1)j. Then we can combine instances of the trees for “John”, “pushes”, and “the button” into a grammatically complete derivation. However, because both b1 and b2 satisfy the semantic content of “the button”, we must adjoin “red” into the derivation to make the RE refer uniquely to b1. The complete derivation is shown in Fig. 1b; we can read off the output sentence “John pushes the red button” from the leaves of the derived tree we build in this way. 3.2 TAG generation as planning In the CRISP system, Koller and Stone (2007) show how this generation problem can be solved by converting it into a planning problem (Nau et al., 2004). The basic idea is to encode the partial derivation in the planning state, and to encode the action of adding each elementary tree in the planning operators. The encoding of our example as a planning problem is shown in Fig. 2. In the example, we start with an initial state which contains the entire knowledge base, plus atoms subst(S, root) and ref(root, e) expressing that we want to generate a sentence about the event e. We can then apply the (instantiated) action pushes(root, n1, n2, n</context>
<context position="14760" citStr="Koller and Stone (2007)" startWordPosition="2419" endWordPosition="2422">lso apply the action the-button(n2, b1) to eliminate subst(NP, n2) and distractor(n2, e), since e is not a button. However distractor(n2, b2) remains. Now because the action the-button also introduced the atom canadjoin(N, n2), we can remove the final distractor atom by applying red(n2, b1). This brings us into a goal state, and we are done. Goal states in CRISP planning problems are characterized by axioms such as bAbu.-,subst(A, u) (encoding grammatical completeness) and bubx.-,distractor(u, x) (requiring unique reference). 1This is a different solution to the name-selection problem than in Koller and Stone (2007). It is simpler and improves computational efficiency. Figure 3: An example map for instruction giving. 3.3 Decoding the plan An AI planner such as FF (Hoffmann and Nebel, 2001) can compute a plan for a planning problem that consists of the planning operators in Fig. 2 and a specification of the initial state and the goal. We can then decode this plan into the TAG derivation shown in Fig. 1b. The basic idea of this decoding step is that an action with a precondition subst(A, u) fills the substitution node u, while an action with a precondition canadjoin(A, u) adjoins into a node of category A </context>
</contexts>
<marker>Koller, Stone, 2007</marker>
<rawString>Alexander Koller and Matthew Stone. 2007. Sentence generation as planning. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Koller</author>
<author>Andrew Gargett</author>
<author>Konstantina Garoufi</author>
</authors>
<title>A scalable model of planning perlocutionary acts.</title>
<date>2010</date>
<booktitle>In Proceedings of the 14th Workshop on the Semantics and Pragmatics of Dialogue,</booktitle>
<location>Poznan, Poland.</location>
<contexts>
<context position="1388" citStr="Koller et al., 2010" startWordPosition="194" endWordPosition="197">Virtual Environments, finding that it performs well even under the constraints of realtime generation. 1 Introduction The problem of situated natural language generation (NLG)—i.e., of generating natural language in the context of a physical (or virtual) environment—has received increasing attention in the past few years. On the one hand, this is because it is the foundation of various emerging applications, including human-robot interaction and mobile navigation systems, and is the focus of a current evaluation effort, the Challenges on Generating Instructions in Virtual Environments (GIVE; (Koller et al., 2010b)). On the other hand, situated generation comes with interesting theoretical challenges: Compared to the generation of pure text, the interpretation of expressions in situated communication is sensitive to the non-linguistic context, and this context can change as easily as the user can move around in the environment. One interesting aspect of situated communication from an NLG perspective is that this nonlinguistic context can be manipulated by the speaker. Consider the following segment of discourse between an instruction giver (IG) and an instruction follower (IF), which is adapted from t</context>
<context position="9403" citStr="Koller et al., 2010" startWordPosition="1536" endWordPosition="1539">igure 1: (a) An example grammar; (b) a derivation of “John pushes the red button” using (a). John N:b1 red N * semcontent: {John(self)} semcontent: {button(self)} semcontent: {push(self,subj,obj)} the NP:self (a) S:self (b) S:e NP:self NP:subj 1 VP:self the V:e pushes V:self pushes NP:obj 1 NP:j John NP:b1 1 NP:b1 NP:j 1 VP:e N:self button N:b1 button N:self red N * semcontent: {red(self)} tion that explicitly models the context change effects of an utterance. While nothing in our work directly hinges on this, we implemented our approach in the context of an NLG system for the GIVE Challenge (Koller et al., 2010b), that is, as an instruction giving system for virtual worlds. This makes our system comparable with other approaches to instruction giving implemented in the GIVE framework. 3 Sentence generation as planning Our work is based on the CRISP system (Koller and Stone, 2007), which encodes sentence generation with tree-adjoining grammars (TAG; (Joshi and Schabes, 1997)) as an AI planning problem and solves that using efficient planners. It then decodes the resulting plan into a TAG derivation, from which it can read off a sentence. In this section, we briefly recall how this works. For space rea</context>
<context position="19908" citStr="Koller et al. (2010" startWordPosition="3282" endWordPosition="3285">rning left on the IF’s agenda. In addition, the lexicon entry for “turn left” specifies that, under the assumption that the IF understands and follows the instruction, they will turn 90 degrees to the left after hearing it. The planning operators are written in a way that assumes that the intended (perlocutionary) effects of an utterance actually come true. This assumption is crucial in connecting the non-linguistic effects of one SCRISP action to the non-linguistic preconditions of another, and generalizes to a scalable model of planning perlocutionary acts. We discuss this in more detail in Koller et al. (2010a). We then translate a SCRISP generation problem into a planning problem. In addition to what CRISP does, we translate all non-linguistic conditions into preconditions and all non-linguistic effects into effects of the planning operator, adding any free variables to the operator’s parameters. An imperative effect P is translated into an effect to–do(P). The operators for the example lexicon of Fig. 4 are shown in Fig. 5. Finally, we add information about the situated environment to the initial state, and specify the planning goal by adding to–do(P) atoms for each atom P that is to be placed o</context>
<context position="29586" citStr="Koller et al., 2010" startWordPosition="4916" endWordPosition="4919"> used, the premod–index precondition of the “red” operator will fail. For this reason, we can generate a plan for “the left red button”, but not for “? the red left button”, as desired. 6 Evaluation To establish the quality of the generated instructions, we implemented SCRISP as part of a generation system in the GIVE-1 framework, and evaluated it against two baselines. GIVE-1 was the First Challenge on Generating Instructions in Virtual Environments, which was completed in 2009 1579 Table 1: Example system instructions generated in the same scene. REs for the target are typeset in boldface. (Koller et al., 2010b). In this challenge, systems must generate real-time instructions that help users perform a task in a treasure-hunt virtual environment such as the one shown in Fig. 7. We conducted our evaluation in World 2 from GIVE-1, which was deliberately designed to be challenging for RE generation. The world consists of one room filled with several objects and buttons, most of which cannot be distinguished by simple descriptions. Moreover, some of those may activate an alarm and cause the player to lose the game. The player’s moves and turns are discrete and the NLG system has complete and accurate re</context>
</contexts>
<marker>Koller, Gargett, Garoufi, 2010</marker>
<rawString>Alexander Koller, Andrew Gargett, and Konstantina Garoufi. 2010a. A scalable model of planning perlocutionary acts. In Proceedings of the 14th Workshop on the Semantics and Pragmatics of Dialogue, Poznan, Poland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Koller</author>
<author>Kristina Striegnitz</author>
<author>Donna Byron</author>
<author>Justine Cassell</author>
<author>Robert Dale</author>
<author>Johanna Moore</author>
<author>Jon Oberlander</author>
</authors>
<title>The First Challenge on Generating Instructions in Virtual Environments.</title>
<date>2010</date>
<booktitle>Empirical Methods in Natural Language Generation,</booktitle>
<volume>5790</volume>
<pages>337--361</pages>
<editor>In M. Theune and E. Krahmer, editors,</editor>
<publisher>Springer, Berlin/Heidelberg.</publisher>
<note>To appear.</note>
<contexts>
<context position="1388" citStr="Koller et al., 2010" startWordPosition="194" endWordPosition="197">Virtual Environments, finding that it performs well even under the constraints of realtime generation. 1 Introduction The problem of situated natural language generation (NLG)—i.e., of generating natural language in the context of a physical (or virtual) environment—has received increasing attention in the past few years. On the one hand, this is because it is the foundation of various emerging applications, including human-robot interaction and mobile navigation systems, and is the focus of a current evaluation effort, the Challenges on Generating Instructions in Virtual Environments (GIVE; (Koller et al., 2010b)). On the other hand, situated generation comes with interesting theoretical challenges: Compared to the generation of pure text, the interpretation of expressions in situated communication is sensitive to the non-linguistic context, and this context can change as easily as the user can move around in the environment. One interesting aspect of situated communication from an NLG perspective is that this nonlinguistic context can be manipulated by the speaker. Consider the following segment of discourse between an instruction giver (IG) and an instruction follower (IF), which is adapted from t</context>
<context position="9403" citStr="Koller et al., 2010" startWordPosition="1536" endWordPosition="1539">igure 1: (a) An example grammar; (b) a derivation of “John pushes the red button” using (a). John N:b1 red N * semcontent: {John(self)} semcontent: {button(self)} semcontent: {push(self,subj,obj)} the NP:self (a) S:self (b) S:e NP:self NP:subj 1 VP:self the V:e pushes V:self pushes NP:obj 1 NP:j John NP:b1 1 NP:b1 NP:j 1 VP:e N:self button N:b1 button N:self red N * semcontent: {red(self)} tion that explicitly models the context change effects of an utterance. While nothing in our work directly hinges on this, we implemented our approach in the context of an NLG system for the GIVE Challenge (Koller et al., 2010b), that is, as an instruction giving system for virtual worlds. This makes our system comparable with other approaches to instruction giving implemented in the GIVE framework. 3 Sentence generation as planning Our work is based on the CRISP system (Koller and Stone, 2007), which encodes sentence generation with tree-adjoining grammars (TAG; (Joshi and Schabes, 1997)) as an AI planning problem and solves that using efficient planners. It then decodes the resulting plan into a TAG derivation, from which it can read off a sentence. In this section, we briefly recall how this works. For space rea</context>
<context position="19908" citStr="Koller et al. (2010" startWordPosition="3282" endWordPosition="3285">rning left on the IF’s agenda. In addition, the lexicon entry for “turn left” specifies that, under the assumption that the IF understands and follows the instruction, they will turn 90 degrees to the left after hearing it. The planning operators are written in a way that assumes that the intended (perlocutionary) effects of an utterance actually come true. This assumption is crucial in connecting the non-linguistic effects of one SCRISP action to the non-linguistic preconditions of another, and generalizes to a scalable model of planning perlocutionary acts. We discuss this in more detail in Koller et al. (2010a). We then translate a SCRISP generation problem into a planning problem. In addition to what CRISP does, we translate all non-linguistic conditions into preconditions and all non-linguistic effects into effects of the planning operator, adding any free variables to the operator’s parameters. An imperative effect P is translated into an effect to–do(P). The operators for the example lexicon of Fig. 4 are shown in Fig. 5. Finally, we add information about the situated environment to the initial state, and specify the planning goal by adding to–do(P) atoms for each atom P that is to be placed o</context>
<context position="29586" citStr="Koller et al., 2010" startWordPosition="4916" endWordPosition="4919"> used, the premod–index precondition of the “red” operator will fail. For this reason, we can generate a plan for “the left red button”, but not for “? the red left button”, as desired. 6 Evaluation To establish the quality of the generated instructions, we implemented SCRISP as part of a generation system in the GIVE-1 framework, and evaluated it against two baselines. GIVE-1 was the First Challenge on Generating Instructions in Virtual Environments, which was completed in 2009 1579 Table 1: Example system instructions generated in the same scene. REs for the target are typeset in boldface. (Koller et al., 2010b). In this challenge, systems must generate real-time instructions that help users perform a task in a treasure-hunt virtual environment such as the one shown in Fig. 7. We conducted our evaluation in World 2 from GIVE-1, which was deliberately designed to be challenging for RE generation. The world consists of one room filled with several objects and buttons, most of which cannot be distinguished by simple descriptions. Moreover, some of those may activate an alarm and cause the player to lose the game. The player’s moves and turns are discrete and the NLG system has complete and accurate re</context>
</contexts>
<marker>Koller, Striegnitz, Byron, Cassell, Dale, Moore, Oberlander, 2010</marker>
<rawString>Alexander Koller, Kristina Striegnitz, Donna Byron, Justine Cassell, Robert Dale, Johanna Moore, and Jon Oberlander. 2010b. The First Challenge on Generating Instructions in Virtual Environments. In M. Theune and E. Krahmer, editors, Empirical Methods in Natural Language Generation, volume 5790 of LNCS, pages 337–361. Springer, Berlin/Heidelberg. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiel Krahmer</author>
<author>Mariet Theune</author>
</authors>
<title>Efficient context-sensitive generation of referring expressions.</title>
<date>2002</date>
<booktitle>Information Sharing: Reference and Presupposition in Language Generation and Interpretation,</booktitle>
<pages>223--264</pages>
<editor>In Kees van Deemter and Rodger Kibble, editors,</editor>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="7605" citStr="Krahmer and Theune, 2002" startWordPosition="1240" endWordPosition="1243">enerating REs with context-dependent modifiers is van Deemter’s (2006) algorithm for generating vague adjectives. Unlike van Deemter, we integrate the RE generation process tightly with the syntactic realization, which allows us to generate REs with more than one context-dependent modifier and model the effect of their linear order on the meaning of the phrase. In modeling the context, we focus on the non-linguistic context and the influence of each of the RE’s words; this is in contrast to previous research on contextsensitive generation of REs, which mainly focused on the discourse context (Krahmer and Theune, 2002). Our interpretation of context-dependent modifiers picks up ideas by Kamp and Partee (1995) and implements them in a practical system, while our method of ordering modifiers is linguistically informed by the class-based paradigm (e.g., Mitchell (2009)). On the other hand, our work also stands in a tradition of NLG research that is based on AI planning. Early approaches (Perrault and Allen, 1980; Appelt, 1985) provided compelling intuitions for this connection, but were not computationally viable. The research we report here can be seen as combining Appelt’s idea of using planning for sentence</context>
</contexts>
<marker>Krahmer, Theune, 2002</marker>
<rawString>Emiel Krahmer and Mariet Theune. 2002. Efficient context-sensitive generation of referring expressions. In Kees van Deemter and Rodger Kibble, editors, Information Sharing: Reference and Presupposition in Language Generation and Interpretation, pages 223–264. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emiel Krahmer</author>
<author>Sebastiaan van Erk</author>
<author>Andr´e Verleg</author>
</authors>
<title>Graph-based generation of referring expressions.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<marker>Krahmer, van Erk, Verleg, 2003</marker>
<rawString>Emiel Krahmer, Sebastiaan van Erk, and Andr´e Verleg. 2003. Graph-based generation of referring expressions. Computational Linguistics, 29(1):53–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret Mitchell</author>
</authors>
<title>Class-based ordering of prenominal modifiers.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th European Workshop on Natural Language Generation,</booktitle>
<pages>50--57</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="7857" citStr="Mitchell (2009)" startWordPosition="1279" endWordPosition="1280">e context-dependent modifier and model the effect of their linear order on the meaning of the phrase. In modeling the context, we focus on the non-linguistic context and the influence of each of the RE’s words; this is in contrast to previous research on contextsensitive generation of REs, which mainly focused on the discourse context (Krahmer and Theune, 2002). Our interpretation of context-dependent modifiers picks up ideas by Kamp and Partee (1995) and implements them in a practical system, while our method of ordering modifiers is linguistically informed by the class-based paradigm (e.g., Mitchell (2009)). On the other hand, our work also stands in a tradition of NLG research that is based on AI planning. Early approaches (Perrault and Allen, 1980; Appelt, 1985) provided compelling intuitions for this connection, but were not computationally viable. The research we report here can be seen as combining Appelt’s idea of using planning for sentence-level NLG with a computationally benign variant of Perrault et al.’s approach of modeling the intended perlocutionary effects of a speech act as the effects of a planning operator. Our work is linked to a growing body of very recent work that applies </context>
<context position="28252" citStr="Mitchell, 2009" startWordPosition="4687" endWordPosition="4688"> In our setting, some adjective orders are forbidden because only one order produces a correct and distinguishing descripFigure 7: The IF’s view of the scene in Fig. 3, as rendered by the GIVE client. tion of the target referent (cf. “upper left” vs. “left upper” example above). However, there are also other constraints at work: “? the red left button” is rather odd even when it is a semantically correct description, whereas “the left red button” is fine. To ensure that SCRISP chooses to generate these adjectives correctly, we follow a class-based approach to the premodifier ordering problem (Mitchell, 2009). In our lexicon we assign adjectives denoting spatial relations (“left”) to one class and adjectives denoting color (“red”) to another; then we require that spatial adjectives must always precede color adjectives. We enforce this by keeping track of the current premodifier index of the RE in atoms of the form premod–index. Any newly generated RE node starts off with a premodifier index of zero; adjoining an adjective of a certain class then raises this number to the index for that class. As the operators in Fig. 6 illustrate, color adjectives such as “red” have index one and can only be used </context>
</contexts>
<marker>Mitchell, 2009</marker>
<rawString>Margaret Mitchell. 2009. Class-based ordering of prenominal modifiers. In Proceedings of the 12th European Workshop on Natural Language Generation, pages 50–57, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dana Nau</author>
<author>Malik Ghallab</author>
<author>Paolo Traverso</author>
</authors>
<title>Automated Planning: Theory and Practice.</title>
<date>2004</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="12076" citStr="Nau et al., 2004" startWordPosition="1987" endWordPosition="1990">ombine instances of the trees for “John”, “pushes”, and “the button” into a grammatically complete derivation. However, because both b1 and b2 satisfy the semantic content of “the button”, we must adjoin “red” into the derivation to make the RE refer uniquely to b1. The complete derivation is shown in Fig. 1b; we can read off the output sentence “John pushes the red button” from the leaves of the derived tree we build in this way. 3.2 TAG generation as planning In the CRISP system, Koller and Stone (2007) show how this generation problem can be solved by converting it into a planning problem (Nau et al., 2004). The basic idea is to encode the partial derivation in the planning state, and to encode the action of adding each elementary tree in the planning operators. The encoding of our example as a planning problem is shown in Fig. 2. In the example, we start with an initial state which contains the entire knowledge base, plus atoms subst(S, root) and ref(root, e) expressing that we want to generate a sentence about the event e. We can then apply the (instantiated) action pushes(root, n1, n2, n3, e, j, b1), which models the act of substituting the elementary tree for “pushes” 1575 pushes(u, u1, u2, </context>
</contexts>
<marker>Nau, Ghallab, Traverso, 2004</marker>
<rawString>Dana Nau, Malik Ghallab, and Paolo Traverso. 2004. Automated Planning: Theory and Practice. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Raymond Perrault</author>
<author>James F Allen</author>
</authors>
<title>A plan-based analysis of indirect speech acts.</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>6</volume>
<issue>3</issue>
<pages>4--167</pages>
<contexts>
<context position="8003" citStr="Perrault and Allen, 1980" startWordPosition="1305" endWordPosition="1308">n the non-linguistic context and the influence of each of the RE’s words; this is in contrast to previous research on contextsensitive generation of REs, which mainly focused on the discourse context (Krahmer and Theune, 2002). Our interpretation of context-dependent modifiers picks up ideas by Kamp and Partee (1995) and implements them in a practical system, while our method of ordering modifiers is linguistically informed by the class-based paradigm (e.g., Mitchell (2009)). On the other hand, our work also stands in a tradition of NLG research that is based on AI planning. Early approaches (Perrault and Allen, 1980; Appelt, 1985) provided compelling intuitions for this connection, but were not computationally viable. The research we report here can be seen as combining Appelt’s idea of using planning for sentence-level NLG with a computationally benign variant of Perrault et al.’s approach of modeling the intended perlocutionary effects of a speech act as the effects of a planning operator. Our work is linked to a growing body of very recent work that applies modern planning research to various problems in NLG (Steedman and Petrick, 2007; Brenner and Kruijff-Korbayov´a, 2008; Benotti, 2009). It is direc</context>
<context position="36682" citStr="Perrault and Allen, 1980" startWordPosition="6112" endWordPosition="6115">is to expand our notion of context by taking visual and discourse salience into account when generating REs. In addition, we plan to experiment with assigning costs to planning operators in a metric planning problem (Hoffmann, 2002) in order to model the cognitive cost of an RE (Krahmer et al., 2003) and compute minimal-cost instruction sequences. On a more theoretical level, the SCRISP actions model the physical effects of a correctly understood and grounded instruction directly as effects of the planning operator. This is computationally much less complex than classical speech act planning (Perrault and Allen, 1980), in which the intended physical effect comes at the end of a long chain of inferences. But our approach is also very optimistic in estimating the perlocutionary effects of an instruction, and must be complemented by an appropriate model of execution monitoring. What this means for a novel scalable approach to the pragmatics of speech acts (Koller et al., 2010a) is, we believe, an interesting avenue for future research. Acknowledgments. We are grateful to J¨org Hoffmann for improving the efficiency of FF in the SCRISP domain at a crucial time, and to Margaret Mitchell, Matthew Stone and Kees v</context>
</contexts>
<marker>Perrault, Allen, 1980</marker>
<rawString>C. Raymond Perrault and James F. Allen. 1980. A plan-based analysis of indirect speech acts. American Journal of Computational Linguistics, 6(3– 4):167–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Portner</author>
</authors>
<title>Imperatives and modals.</title>
<date>2007</date>
<journal>Natural Language Semantics,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="18816" citStr="Portner, 2007" startWordPosition="3098" endWordPosition="3099">eclarative sentences. 4.1 Situated CRISP We define a lexicon for SCRISP to be a CRISP lexicon in which every lexicon entry may also describe non-linguistic conditions, non-linguistic effects and imperative effects. Each of these is a set of atoms over constants, semantic roles, and possibly some free variables. Non-linguistic conditions specify what must be true in the world so a particular instance of a lexicon entry can be uttered felicitously; non-linguistic effects specify what changes uttering the word brings about in the world; and imperative effects contribute to the IF’s “to-do list” (Portner, 2007) by adding the properties they denote. A small lexicon for our example is shown in Fig. 4. This lexicon specifies that saying “push X” puts pushing X on the IF’s to-do list, and carries the presupposition that X must be visible from the location where “push X” is uttered; this reflects our simplifying assumption that the IG can Figure 5: SCRISP planning operators for the lexicon in Fig. 4. only refer to objects that are currently visible. Similarly, “turn left” puts turning left on the IF’s agenda. In addition, the lexicon entry for “turn left” specifies that, under the assumption that the IF </context>
</contexts>
<marker>Portner, 2007</marker>
<rawString>Paul Portner. 2007. Imperatives and modals. Natural Language Semantics, 15(4):351–383.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shaw</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Ordering among premodifiers.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>135--143</pages>
<location>College Park, Maryland, USA.</location>
<contexts>
<context position="27636" citStr="Shaw and Hatzivassiloglou, 1999" startWordPosition="4582" endWordPosition="4585"> ordered correctly, and the workload of modeling interactions with the non-linguistic context is limited to a single place in the encoding. 5.2 Adjective word order One final challenge that arises in our system is to generate the adjectives in the correct order, which on top of semantically valid must be linguistically acceptable. In particular, it is known that some types of adjectives are limited with respect to the word order in which they can occur in a noun phrase. For instance, “large foreign financial firms” sounds perfectly acceptable, but “? foreign large financial firms” sounds odd (Shaw and Hatzivassiloglou, 1999). In our setting, some adjective orders are forbidden because only one order produces a correct and distinguishing descripFigure 7: The IF’s view of the scene in Fig. 3, as rendered by the GIVE client. tion of the target referent (cf. “upper left” vs. “left upper” example above). However, there are also other constraints at work: “? the red left button” is rather odd even when it is a semantically correct description, whereas “the left red button” is fine. To ensure that SCRISP chooses to generate these adjectives correctly, we follow a class-based approach to the premodifier ordering problem </context>
</contexts>
<marker>Shaw, Hatzivassiloglou, 1999</marker>
<rawString>James Shaw and Vasileios Hatzivassiloglou. 1999. Ordering among premodifiers. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 135–143, College Park, Maryland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
<author>Ronald P A Petrick</author>
</authors>
<title>Planning dialog actions.</title>
<date>2007</date>
<booktitle>In Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>265--272</pages>
<location>Antwerp, Belgium.</location>
<contexts>
<context position="8536" citStr="Steedman and Petrick, 2007" startWordPosition="1392" endWordPosition="1395">tion of NLG research that is based on AI planning. Early approaches (Perrault and Allen, 1980; Appelt, 1985) provided compelling intuitions for this connection, but were not computationally viable. The research we report here can be seen as combining Appelt’s idea of using planning for sentence-level NLG with a computationally benign variant of Perrault et al.’s approach of modeling the intended perlocutionary effects of a speech act as the effects of a planning operator. Our work is linked to a growing body of very recent work that applies modern planning research to various problems in NLG (Steedman and Petrick, 2007; Brenner and Kruijff-Korbayov´a, 2008; Benotti, 2009). It is directly based on Koller and Stone’s (2007) reimplementation of the SPUD generator (Stone et al., 2003) with planning. As far as we know, ours is the first system in the SPUD tradi1574 Figure 1: (a) An example grammar; (b) a derivation of “John pushes the red button” using (a). John N:b1 red N * semcontent: {John(self)} semcontent: {button(self)} semcontent: {push(self,subj,obj)} the NP:self (a) S:self (b) S:e NP:self NP:subj 1 VP:self the V:e pushes V:self pushes NP:obj 1 NP:j John NP:b1 1 NP:b1 NP:j 1 VP:e N:self button N:b1 butto</context>
</contexts>
<marker>Steedman, Petrick, 2007</marker>
<rawString>Mark Steedman and Ronald P. A. Petrick. 2007. Planning dialog actions. In Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue, pages 265–272, Antwerp, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Stoia</author>
<author>Donna K Byron</author>
<author>Darla Magdalene Shockley</author>
<author>Eric Fosler-Lussier</author>
</authors>
<title>Sentence planning for realtime navigational instructions.</title>
<date>2006</date>
<booktitle>In NAACL ’06: Proceedings of the Human Language Technology Conference of the NAACL,</booktitle>
<pages>157--160</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6385" citStr="Stoia et al., 2006" startWordPosition="1036" endWordPosition="1039">aches to generating referring expressions. Since the foundational work of Dale and Reiter (1995), there has been a considerable amount of literature on this topic. Our work departs from the mainstream in two ways. First, it exploits the situated communicative setting to deliberately modify the context in which an RE is generated. Second, unlike most other RE generation systems, we allow the contribution of a modifier to an RE to depend both on the context and on the rest of the RE. We are aware of only one earlier study on generation of REs with focus on interleaving navigation and referring (Stoia et al., 2006). In this machine learning approach, Stoia et al. train classifiers that signal when the context conditions (e.g. visibility of target and distractors) are appropriate for the generation of an RE. This method can be then used as part of a content selection component of an NLG system. Such a component, however, can only inform a system on whether to choose navigation over RE generation at a given point of the discourse, and is not able to help it decide what kind of navigational instructions to generate so that subsequent REs become simple. To our knowledge, the only previous research on genera</context>
</contexts>
<marker>Stoia, Byron, Shockley, Fosler-Lussier, 2006</marker>
<rawString>Laura Stoia, Donna K. Byron, Darla Magdalene Shockley, and Eric Fosler-Lussier. 2006. Sentence planning for realtime navigational instructions. In NAACL ’06: Proceedings of the Human Language Technology Conference of the NAACL, pages 157– 160, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Stoia</author>
<author>Darla M Shockley</author>
<author>Donna K Byron</author>
<author>Eric Fosler-Lussier</author>
</authors>
<title>SCARE: A situated corpus with annotated referring expressions.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation,</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="2024" citStr="Stoia et al., 2008" startWordPosition="295" endWordPosition="298"> hand, situated generation comes with interesting theoretical challenges: Compared to the generation of pure text, the interpretation of expressions in situated communication is sensitive to the non-linguistic context, and this context can change as easily as the user can move around in the environment. One interesting aspect of situated communication from an NLG perspective is that this nonlinguistic context can be manipulated by the speaker. Consider the following segment of discourse between an instruction giver (IG) and an instruction follower (IF), which is adapted from the SCARE corpus (Stoia et al., 2008): (1) IG: Walk forward and then turn right. IF: (walks and turns) IG: OK. Now hit the button in the middle. In this example, the IG plans to refer to an object (here, a button); and in order to do so, gives a navigation instruction to guide the IF to a convenient location at which she can then use a simple referring expression (RE). That is, there is an interaction between navigation instructions (intended to manipulate the non-linguistic context in a certain way) and referring expressions (which exploit the non-linguistic context). Although such subdialogues are common in SCARE, we are not aw</context>
</contexts>
<marker>Stoia, Shockley, Byron, Fosler-Lussier, 2008</marker>
<rawString>Laura Stoia, Darla M. Shockley, Donna K. Byron, and Eric Fosler-Lussier. 2008. SCARE: A situated corpus with annotated referring expressions. In Proceedings of the 6th International Conference on Language Resources and Evaluation, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Stone</author>
<author>Christine Doran</author>
<author>Bonnie Webber</author>
<author>Tonia Bleam</author>
<author>Martha Palmer</author>
</authors>
<title>Microplanning with communicative intentions: The SPUD system.</title>
<date>2003</date>
<journal>Computational Intelligence,</journal>
<volume>19</volume>
<issue>4</issue>
<pages>381</pages>
<contexts>
<context position="8701" citStr="Stone et al., 2003" startWordPosition="1416" endWordPosition="1419">t computationally viable. The research we report here can be seen as combining Appelt’s idea of using planning for sentence-level NLG with a computationally benign variant of Perrault et al.’s approach of modeling the intended perlocutionary effects of a speech act as the effects of a planning operator. Our work is linked to a growing body of very recent work that applies modern planning research to various problems in NLG (Steedman and Petrick, 2007; Brenner and Kruijff-Korbayov´a, 2008; Benotti, 2009). It is directly based on Koller and Stone’s (2007) reimplementation of the SPUD generator (Stone et al., 2003) with planning. As far as we know, ours is the first system in the SPUD tradi1574 Figure 1: (a) An example grammar; (b) a derivation of “John pushes the red button” using (a). John N:b1 red N * semcontent: {John(self)} semcontent: {button(self)} semcontent: {push(self,subj,obj)} the NP:self (a) S:self (b) S:e NP:self NP:subj 1 VP:self the V:e pushes V:self pushes NP:obj 1 NP:j John NP:b1 1 NP:b1 NP:j 1 VP:e N:self button N:b1 button N:self red N * semcontent: {red(self)} tion that explicitly models the context change effects of an utterance. While nothing in our work directly hinges on this, w</context>
<context position="10164" citStr="Stone et al., 2003" startWordPosition="1660" endWordPosition="1663">implemented in the GIVE framework. 3 Sentence generation as planning Our work is based on the CRISP system (Koller and Stone, 2007), which encodes sentence generation with tree-adjoining grammars (TAG; (Joshi and Schabes, 1997)) as an AI planning problem and solves that using efficient planners. It then decodes the resulting plan into a TAG derivation, from which it can read off a sentence. In this section, we briefly recall how this works. For space reasons, we will present primarily examples instead of definitions. 3.1 TAG sentence generation The CRISP generation problem (like that of SPUD (Stone et al., 2003)) assumes a lexicon of entries consisting of a TAG elementary tree annotated with semantic and pragmatic information. An example is shown in Fig. 1a. In addition to the elementary tree, each lexicon entry specifies its semantic content and possibly a semantic requirement, which can express certain presuppositions triggered by this entry. The nodes in the tree may be labeled with argument names such as semantic roles, which specify the participants in the relation expressed by the lexicon entry; in the example, every entry uses the semantic role self representing the event or individual itself,</context>
</contexts>
<marker>Stone, Doran, Webber, Bleam, Palmer, 2003</marker>
<rawString>Matthew Stone, Christine Doran, Bonnie Webber, Tonia Bleam, and Martha Palmer. 2003. Microplanning with communicative intentions: The SPUD system. Computational Intelligence, 19(4):311– 381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
</authors>
<title>Generating referring expressions that involve gradable properties.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>2</issue>
<marker>van Deemter, 2006</marker>
<rawString>Kees van Deemter. 2006. Generating referring expressions that involve gradable properties. Computational Linguistics, 32(2).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>