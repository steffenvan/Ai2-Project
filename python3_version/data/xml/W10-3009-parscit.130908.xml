<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000969">
<title confidence="0.940686">
Hedge Detection Using the RelHunter Approach∗
</title>
<note confidence="0.649755333333333">
Eraldo R. Fernandes† and Carlos E. M. Crestana‡ and Ruy L. Milidi´u§
Departamento de Inform´atica, PUC-Rio
Rio de Janeiro, Brazil
</note>
<email confidence="0.87357">
{efernandes, ccrestana, milidiu}@inf.puc-rio.br
</email>
<sectionHeader confidence="0.9933" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.929777461538461">
RelHunter is a Machine Learning based
method for the extraction of structured in-
formation from text. Here, we apply Rel-
Hunter to the Hedge Detection task, pro-
posed as the CoNLL-2010 Shared Task1.
RelHunter’s key design idea is to model
the target structures as a relation over enti-
ties. The method decomposes the original
task into three subtasks: (i) Entity Iden-
tification; (ii) Candidate Relation Gener-
ation; and (iii) Relation Recognition. In
the Hedge Detection task, we define three
types of entities: cue chunk, start scope
token and end scope token. Hence, the
Entity Identification subtask is further de-
composed into three token classification
subtasks, one for each entity type. In
the Candidate Relation Generation sub-
task, we apply a simple procedure to gen-
erate a ternary candidate relation. Each in-
stance in this relation represents a hedge
candidate composed by a cue chunk, a
start scope token and an end scope to-
ken. For the Relation Recognition sub-
task, we use a binary classifier to discrim-
inate between true and false candidates.
The four classifiers are trained with the
Entropy Guided Transformation Learning
algorithm. When compared to the other
hedge detection systems of the CoNLL
shared task, our scheme shows a competi-
tive performance. The F-score of our sys-
tem is 54.05 on the evaluation corpus.
∗ This work is partially funded by CNPq and FAPERJ
grants 557.128/2009-9 and E-26/170028/2008.
† Holds a CNPq doctoral fellowship and has financial
support from IFG, Brazil.
‡Holds a CAPES doctoral fellowship.
§Holds a CNPq research fellowship.
</bodyText>
<footnote confidence="0.840591">
1Closed Task 2: detection of hedge cues and their scopes.
</footnote>
<sectionHeader confidence="0.994757" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998609">
Hedges are linguistic devices that indicate un-
certain or unreliable information within a text.
The detection of hedge structures is important for
many applications that extract facts from textual
data. The CoNLL-2010 Shared Task (Farkas et
al., 2010) is dedicated to hedge detection.
A hedge structure consists of a cue and a scope.
In Figure 1, we present a sentence with two hedge
instances. The hedge cues are highlighted and
their scopes are delimited by brackets. The hedge
cue comprises one or more keywords that indi-
cate uncertainty. The hedge scope is the uncertain
statement which is hedged by the cue. The scope
always includes the corresponding cue.
[ They indicate that [ the demonstration
is possible in this context ] and there is a
correlation ]
</bodyText>
<figureCaption confidence="0.997411">
Figure 1: Sentence with two hedge instances.
</figureCaption>
<bodyText confidence="0.999559315789474">
Over the last two decades, several Computa-
tional Linguistic problems have been successfully
modeled as local token classification tasks (Brill,
1995; Milidi´u et al., 2009). Nevertheless, the
harder problems consist in identifying complex
structures within a text. These structures comprise
many tokens and show non local token dependen-
cies.
Phrase chunking (Sang and Buchholz, 2000) is
a task that involves structure recognition. Pun-
yakanok and Roth decompose this task into
four subtasks, that are sequentially solved (Pun-
yakanok and Roth, 2001). They use Hidden
Markov Models for the first three subtasks. They
find out that task decomposition improves the
overall token classification modeling.
Clause identification (Sang and D´ejean, 2001)
is another task that requires structure recognition.
As clauses may embed other clauses, these struc-
</bodyText>
<page confidence="0.992413">
64
</page>
<bodyText confidence="0.972428111111111">
Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 64–69,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
tures involve stronger dependencies than phrase
chunks. Carreras et al. propose an approach that
extends Punyakanok and Roth’s previous work
(Carreras et al., 2002). Their system comprises
complex methods for training and extraction, in
order to exploit the specific dependency aspects of
clause structures.
Phrase Recognition is a general type of task that
includes both phrase chunking and clause iden-
tification. Carreras et al. propose the Filtering-
Ranking Perceptron (FRP) system for this general
task (Carreras et al., 2005). The FRP task model-
ing is strongly related to previous proposals (Pun-
yakanok and Roth, 2001; Carreras et al., 2002).
However, it simultaneously learns to solve three
subtasks. FRP is very effective, although compu-
tationally expensive at both training and prediction
time. Currently, FRP provides the best performing
clause identification system.
In Morante and Daelemans (2009), the hedge
detection task is solved as two consecutive classi-
fication tasks. The first one consists of classify-
ing the tokens of a sentence as hedge cues using
the IOB tagging style. The second task consists of
classifying tokens of a sentence as being the start
of a hedge scope, the end of one, or neither. The
result of those two tasks is combined using a set of
six rules to solve the hedge detection task.
Here, we describe RelHunter, a new method
for the extraction of structured information from
text. Additionally, we apply it to the Hedge Detec-
tion task. RelHunter extends the modeling strat-
egy used both in Carreras et al. (2005) and Pun-
yakanok et al. (2001). Other applications of this
method are presented in Fernandes at al. (2009b;
2010).
The remainder of this text is organized as fol-
lows. In Section 2, we present an overview of the
RelHunter method. The modeling approach for
the Hedge Detection task is presented in Sections
3 and 4. The experimental findings are depicted
and discussed in Section 5. Finally, in Section 6,
we present our final remarks.
</bodyText>
<sectionHeader confidence="0.991331" genericHeader="method">
2 RelHunter Overview
</sectionHeader>
<bodyText confidence="0.9997564">
The central idea of RelHunter is to model the tar-
get structures as a relation over entities. To learn
how to extract this relation from text, RelHunter
uses two additional schemes: task decomposition
and interdependent classification.
We decompose the original task into three sub-
tasks: (i) Entity Identification; (ii) Candidate Re-
lation Generation; and (iii) Relation Recognition.
In Figure 2, we illustrate the application of Rel-
Hunter to hedge detection. We use the sentence
introduced by Figure 1.
Entity Identification is a local subtask, in which
simple entities are detected without any concern
about the structures they belong to. The outcome
of this subtask is the entity set. For instance, for
hedge detection, we identify three types of enti-
ties: hedge cues, tokens that start a scope and to-
kens that end a scope.
The second subtask is performed by a simple
procedure that generates the candidate relation
over the entity set. This relation includes true and
false candidates. This procedure considers do-
main specific knowledge to avoid the generation
of all possible candidates. In the hedge detection
task, we define the candidate relation as the set
of entity triples that comprise a hedge cue, a start
scope token and an end scope token, such that the
start token does not occur after the end token and
the hedge cue occurs between the start and the end
tokens.
The Relation Recognition subtask is a binary
classification problem. In this subtask, we dis-
criminate between true and false candidates. The
output relation produced in this subtask contains
the identified hedge instances.
</bodyText>
<sectionHeader confidence="0.976112" genericHeader="method">
3 Hedge Detection using RelHunter
</sectionHeader>
<bodyText confidence="0.999926">
In this section, we detail the RelHunter method
and describe its application to hedge detection.
</bodyText>
<subsectionHeader confidence="0.994126">
3.1 Entity Identification
</subsectionHeader>
<bodyText confidence="0.999940625">
We consider three specific entity types: cue chunk,
start scope token, and end scope token. We divide
entity identification into three token classification
tasks, one for each entity type. Thus, we use the
original corpus to train three classifiers.
The cue chunk subtask is approached as a to-
ken classification problem by using the IOB tag-
ging style. The token tag is defined as follows: I,
when it is inside a hedge cue; O, when it is outside
a hedge cue; and B, when it begins a hedge cue
immediately after a distinct cue. As the baseline
classifier, we use the Cue Dictionary proposed in
Morante and Daelemans (2009), classifying each
occurrence of those words as a cue.
The start scope and end scope subtasks are
modeled as binary token classification problems.
</bodyText>
<page confidence="0.999237">
65
</page>
<figureCaption confidence="0.999855">
Figure 2: Diagram of the RelHunter method.
</figureCaption>
<bodyText confidence="0.999995846153846">
As the baseline classifier for the start scope sub-
task, we assign the first token of each hedge cue as
the start of a scope.
We have two baseline classifiers for the end
scope subtask: END and END-X. The END sys-
tem classifies as an end token the second to the
last token of each sentence that contains a cue.
Due to the frequent occurrence of parenthesized
clauses at the end of sentences in full articles, the
END-X system extends the END system with an
additional operation. It reassigns an end scope tag,
from a close parentheses token, to the token before
its corresponding open parentheses.
</bodyText>
<subsectionHeader confidence="0.999367">
3.2 Candidate Relation Generation
</subsectionHeader>
<bodyText confidence="0.999831666666667">
We define as the candidate hedge relation the set
of entity triples that comprise a hedge cue, a start
scope token and an end scope token, such that the
start token does not occur after the end token and
the hedge cue occurs between the start and the end
tokens.
</bodyText>
<subsectionHeader confidence="0.995744">
3.3 Relation Recognition
</subsectionHeader>
<bodyText confidence="0.999980549019608">
We train a binary classifier to discriminate be-
tween positive and negative candidates within the
candidate relation. This classifier is trained on the
relation dataset, which is built by a general pro-
cedure. This dataset contains an entry for each
candidate. For each candidate, we generate two
feature sets: local features and global features.
The local features include local information
about each candidate entity, namely: cue chunk,
start scope token and end scope token. These fea-
tures are retrieved from the original corpus. For
the start and end tokens, we use all their features in
the original corpus. For the cue chunk, we use the
features of the rightmost token within the chunk.
The global features follow Carreras et al.
(2002). These features are generated by consid-
ering the whole sentence where the candidate lies
in. They inform about the occurrence of relevant
elements within sentence fragments. We consider
as relevant elements the three entity types and ver-
bal chunks.
For each candidate entity, we consider three
fragments. The first one contains all the tokens be-
fore the entity. The second, all the entity tokens,
and the third all the tokens after the entity. Simi-
larly, for the whole candidate, we have three more
fragments: one containing all the tokens before the
candidate, another containing all the candidate to-
kens, and the third one containing all the tokens
after the candidate. Thus, there are 12 fragments
for each candidate, three for each entity plus three
for the whole candidate.
For each relevant element and fragment, we
generate two global features in the relation dataset:
a flag indicating the occurrence of the element
within the fragment and a counter showing its fre-
quency.
The relation dataset has km local features and
6r(k + 1) global features, where k is the relation
cardinality (number of entities), m is the number
of features in the original corpus, and r is the num-
ber of relevant elements.
Our current RelHunter implementation uses the
Entropy Guided Transformation Learning (ETL)
as its learning engine (Milidi´u et al., 2008; dos
Santos and Milidi´u, 2009). For instance, we train
four ETL based classifiers: one for each Entity
Identification subtask and one for the Relation
Recognition subtask. In the next section, we de-
scribe an important issue explored by the ETL al-
gorithm.
</bodyText>
<page confidence="0.981599">
66
</page>
<sectionHeader confidence="0.997941" genericHeader="method">
4 Interdependent Classification
</sectionHeader>
<bodyText confidence="0.998204441860465">
The input to the Relation Recognition subtask is
the candidate relation, i.e., a set of hedge candi-
dates. The corresponding classifier must discrim-
inate positive from negative candidates. However,
identifying one candidate as positive implies that
some other candidates must be negatives. This in-
volves a special modeling issue: interdependent
classification. The learning engine may explore
these dependencies, when building the classifier
for this subtask.
Interdependent classification is usually assumed
for neighboring examples. When the learning
model adopts a Markovian Property, then the
neighborhood is given by a context window. This
is the case for Markovian Fields such as Hidden
Markov Models. Another model that also explores
interdependent examples is ETL.
ETL is a very attractive modeling tool and has
been applied to several classification tasks (Mi-
lidi´u et al., 2008; dos Santos and Milidi´u, 2009;
Fernandes et al., 2009a; Fernandes et al., 2010).
ETL uses an annotated corpus, where the corre-
sponding class is attached to each example. The
corpus is partitioned into segments. Each segment
is a sequence of examples. Examples within the
same segment are considered dependent. Con-
versely, examples within different segments are
considered independent. Moreover, an example
classification depends only on the features of the
examples from its corresponding context window.
Hence, to apply ETL we need to provide three
modeling ingredients: segment definition, exam-
ple ordering within a segment and the context win-
dow size. Given that, classification dependencies
are explored by the ETL classifier. Hence, Rel-
Hunter uses ETL as its learning engine.
We include in the same segment the hedge can-
didates that have the same cue and start scope to-
kens. Within a segment, we order the candidates
by the order of the end token in the original cor-
pus. We use a context window of 7 candidates,
i.e., three candidates before the current, the current
candidate and three candidates after the current.
</bodyText>
<sectionHeader confidence="0.997644" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.986866192307692">
We use the corpus provided in the CoNLL-2010
Shared Task to train and evaluate our hedge de-
tection system. We add the following annota-
tion to the corpus: word stems, part-of-speech
tags, phrase chunks, and clause annotations. Word
stems have been generated by the Porter stemmer
(Porter, 1980). The additional annotation has been
generated by ETL based systems (dos Santos and
Milidi´u, 2009; Fernandes et al., 2009b; Milidi´u et
al., 2008).
The CoNLL corpus is based on the BioScope
corpus (Vincze et al., 2008). Since it contains doc-
uments of two different kinds – paper abstracts and
full papers – we split it into two subcorpora. The
first subcorpus is called ABST and contains all the
paper abstracts. The second is called FULL and
contains all the full papers.
We have two experimental setups: Development
and Evaluation. In the Development Setup, we use
ABST as the training corpus and FULL as the de-
velopment corpus. This is a conservative decision
since the CoNLL Evaluation Corpus is comprised
only of full articles. In the Evaluation Setup, we
use the union of ABST and FULL as the train-
ing corpus and report the performance over the
CoNLL Evaluation Corpus.
</bodyText>
<subsectionHeader confidence="0.978902">
5.1 Development
</subsectionHeader>
<bodyText confidence="0.997848166666667">
Here, we report the development setup experimen-
tal findings. In Table 1, we show the performance
of the three baseline classifiers. The start and end
classifiers are evaluated with golden standard cue
chunks. All results are obtained with the END-X
baseline system, except when explicitly stated.
</bodyText>
<table confidence="0.9883875">
Task Precision Recall F-score
Cue 51.96 51.65 51.80
Start scope 72.01 72.22 72.11
End scope 65.90 58.97 62.24
</table>
<tableCaption confidence="0.9703265">
Table 1: Development performance of the three
Baseline Classifiers.
</tableCaption>
<bodyText confidence="0.999764">
In Table 2, we report the performance of the
three entity identification ETL classifiers. Again,
the start and end classifiers are evaluated with
golden standard cue chunks. These results indi-
cate that the end scope subtask is the hardest one.
Indeed, our ETL classifier is not able to improve
the baseline classifier performance. The last ta-
ble line shows the performance of the RelHunter
method on the target task – hedge detection.
</bodyText>
<subsectionHeader confidence="0.993816">
5.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.9962825">
Here, we report the evaluation setup findings. In
Table 3, we show the performance of the three
</bodyText>
<page confidence="0.99897">
67
</page>
<table confidence="0.9998206">
Task Precision Recall F-score
Cue 81.23 73.20 77.01
Start scope 91.81 72.37 80.94
End scope 65.90 58.97 62.24
Hedge 53.49 34.43 41.89
</table>
<tableCaption confidence="0.9322074">
Table 2: Development performance of the three
entity identification ETL classifiers and the Rel-
Hunter method to hedge detection.
baseline classifiers. The start and end classifiers
are evaluated with golden standard cue chunks.
</tableCaption>
<table confidence="0.999771">
Task Precision Recall F-score
Cue 45.12 60.02 51.52
Start scope 75.51 75.73 75.62
End scope 81.01 72.56 76.55
</table>
<tableCaption confidence="0.969089">
Table 3: Evaluation performance of the three
Baseline Classifiers.
</tableCaption>
<bodyText confidence="0.999715">
In Table 4, we report the performance of the
three entity identification ETL classifiers. Again,
the start and end classifiers are evaluated with
golden standard cue chunks. The last table line
shows the performance of the RelHunter method
on the target task – hedge detection.
</bodyText>
<table confidence="0.9979994">
Task Precision Recall F-score
Cue 78.73 77.05 77.88
Start scope 89.21 77.86 83.15
End scope 81.01 72.56 76.55
Hedge 57.84 50.73 54.05
</table>
<tableCaption confidence="0.758422333333333">
Table 4: Evaluation performance of the three
entity identification ETL classifiers and the Rel-
Hunter method to hedge detection.
</tableCaption>
<bodyText confidence="0.9998099">
In Table 5, we report the Hedge Detection per-
formances when using END and END-X, as the
baseline classifier for the end scope subtask. The
use of END-X improves the overall system F-
score by more than ten twelve.
In Table 6, we report the Final Results of the
CoNLL-2010 Shared Task – Closed Task 2. For
the sake of comparison, we also include the per-
formance of the RelHunter system with END-X,
that has been developed and tested after the com-
</bodyText>
<table confidence="0.983738666666667">
End scope Precision Recall F-score
END 45.96 38.04 41.63
END-X 57.84 50.73 54.05
</table>
<tableCaption confidence="0.784432">
Table 5: Evaluation performance of the RelHunter
system when using END and END-X.
petition end. The version with the END baseline
holds rank 7 at the competition.
</tableCaption>
<table confidence="0.999305133333333">
Official System P R F
Rank
1 Morante 59.62 55.18 57.32
2 Rei 56.74 54.60 55.65
3 Velldal 56.71 54.02 55.33
- RelHunter 57.84 50.73 54.05
4 Li 57.42 47.92 52.24
5 Zhou 45.32 43.56 44.42
6 Zhang 45.94 42.69 44.25
7 Fernandes 45.96 38.04 41.63
8 Vlachos 41.18 35.91 38.37
9 Zhao 34.78 41.05 37.66
10 Tang 34.49 31.85 33.12
11 Ji 21.87 17.23 19.27
12 T¨ackstr¨om 02.27 02.03 02.15
</table>
<tableCaption confidence="0.759091">
Table 6: Evaluation performance of the CoNLL-
2010 systems and the RelHunter method with the
END-X end scope classifier.
</tableCaption>
<sectionHeader confidence="0.99821" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999976882352941">
We propose RelHunter, a new machine learning
based method for the extraction of structured in-
formation from text. RelHunter consists in model-
ing the target structures as a relation over entities.
To learn how to extract this relation from text, Rel-
Hunter uses two main schemes: task decomposi-
tion and interdependent classification.
RelHunter decomposes the identification of en-
tities into several but simple token classification
subtasks. Additionally, the method generates a
candidate relation over the identified entities and
discriminates between true and false candidates
within this relation.
RelHunter uses the Entropy Guided Transfor-
mation Learning algorithm as its learning engine.
As Hidden Markov Models, ETL is able to con-
sider interdependent examples. RelHunter ex-
</bodyText>
<page confidence="0.997924">
68
</page>
<bodyText confidence="0.99996805">
ploits this powerful feature in order to tackle de-
pendencies among the hedge candidates.
RelHunter is easily applied to many complex
Computational Linguistic problems. We show its
effectiveness by applying it to hedge detection.
Other successful applications of this method are
presented in Fernandes et al. (2009b; 2010).
RelHunter explores the dependency among lin-
guistic structures by using a powerful feature of
the ETL algorithm. Nevertheless, this feature
is restricted to sequentially organized examples,
since ETL has been initially proposed for token
classification problems. Linguistic structures in-
volve topologies that are frequently more complex
than that. The ETL algorithm may be extended to
consider more complex topologies. We conjecture
that it is possible to consider quite general topolo-
gies. This would contribute to the construction of
better solutions to many Computational Linguistic
tasks.
</bodyText>
<sectionHeader confidence="0.997474" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999729333333333">
The authors thank Evelin Amorim and Eduardo
Motta for coding dataset normalization procedures
that are very handy for Hedge Detection.
</bodyText>
<sectionHeader confidence="0.985834" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.976587292682927">
Eric Brill. 1995. Transformation-based error-driven
learning and natural language processing: a case
study in part-of-speech tagging. Computational Lin-
guistics, 21(4):543–565.
Xavier Carreras, Llu´ıs M`arquez, Vasin Punyakanok,
and Dan Roth. 2002. Learning and inference for
clause identification. In Proceedings of the Thir-
teenth European Conference on Machine Learning,
pages 35–47.
Xavier Carreras, Llu´ıs M`arquez, and Jorge Castro.
2005. Filtering-ranking perceptron learning for par-
tial parsing. Machine Learning, 60(1–3):41–71.
C´ıcero N. dos Santos and Ruy L. Milidi´u, 2009. Foun-
dations of Computational Intelligence, Volume 1:
Learning and Approximation, volume 201 of Stud-
ies in Computational Intelligence, chapter Entropy
Guided Transformation Learning, pages 159–184.
Springer.
Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos
Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL-
2010 Shared Task: Learning to Detect Hedges and
their Scope in Natural Language Text. In Proceed-
ings of the Fourteenth Conference on Computational
Natural Language Learning (CoNLL-2010): Shared
Task, pages 1–12, Uppsala, Sweden, July. Associa-
tion for Computational Linguistics.
Eraldo R. Fernandes, C´ıcero N. dos Santos, and Ruy L.
Milidi´u. 2009a. Portuguese language processing
service. In Proceedings of the Web in Ibero-America
Alternate Track of the 18th World Wide Web Confer-
ence (WWW’2009), Madrid.
Eraldo R. Fernandes, Bernardo A. Pires, C´ıcero N. dos
Santos, and Ruy L. Milidi´u. 2009b. Clause identifi-
cation using entropy guided transformation learning.
In Proceedings of the 7th Brazilian Symposium in In-
formation and Human Language Technology (STIL),
S˜ao Carlos, Brazil.
Eraldo R. Fernandes, Bernardo A. Pires, C´ıcero N.
dos Santos, and Ruy L. Milidi´u. 2010. A ma-
chine learning approach to Portuguese clause iden-
tification. In Proceedings of the Nineth Interna-
tional Conference on Computational Processing of
the Portuguese Language (PROPOR), volume 6001
of Lecture Notes in Artificial Intelligence, pages 55–
64, Porto Alegre, Brazil. Springer.
Ruy L. Milidi´u, C´ıcero N. dos Santos, and Julio C.
Duarte. 2008. Phrase chunking using entropy
guided transformation learning. In Proceedings of
ACL-08: HLT, pages 647–655, Columbus, USA.
Association for Computational Linguistics.
Ruy L. Milidi´u, C´ıcero N. dos Santos, and Carlos
E. M. Crestana. 2009. A token classification ap-
proach to dependency parsing. In Proceedings of
the 7th Brazilian Symposium in Information and Hu-
man Language Technology (STIL’2009), S˜ao Carlos,
Brazil.
Roser Morante and Walter Daelemans. 2009. Learn-
ing the scope of hedge cues in biomedical texts. In
Proceedings of the BioNLP 2009 Workshop, pages
28–36, Boulder, USA, June. Association for Com-
putational Linguistics.
Martin F. Porter. 1980. An algorithm for suffix strip-
ping. Program, 14(3):130–137.
Vasin Punyakanok and Dan Roth. 2001. The use of
classifiers in sequential inference. In Proceedings of
the Conference on Advances in Neural Information
Processing Systems (NIPS), pages 995–1001. MIT
Press.
Erik F. Tjong Kim Sang and Sabine Buchholz.
2000. Introduction to the CoNLL-2000 shared task:
Chunking. In Proceedings of CoNLL-2000 and
LLL-2000, Lisbon, Portugal.
Erik F. T. K. Sang and Herv´e D´ejean. 2001. Introduc-
tion to the CoNLL-2001 shared task: Clause identifi-
cation. In Proceedings of Fifth Conference on Com-
putational Natural Language Learning, Toulouse,
France.
Veronika Vincze, Gy¨orgy Szarvas, Rich´ard Farkas,
Gy¨orgy M´ora, and J´anos Csirik. 2008. The Bio-
Scope corpus: biomedical texts annotated for uncer-
tainty, negation and their scopes. BMC Bioinformat-
ics, 9 (Suppl 11):S9.
</reference>
<page confidence="0.999313">
69
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.501291">
<title confidence="0.999617">Detection Using the</title>
<author confidence="0.988521">R E M L</author>
<affiliation confidence="0.848048">Departamento de Inform´atica, Rio de Janeiro,</affiliation>
<email confidence="0.952971">ccrestana,</email>
<abstract confidence="0.993167804878049">a Machine Learning based method for the extraction of structured infrom text. Here, we apply Relthe Hedge Detection task, proas the CoNLL-2010 Shared key design idea is to model the target structures as a relation over entities. The method decomposes the original task into three subtasks: (i) Entity Identification; (ii) Candidate Relation Generation; and (iii) Relation Recognition. In the Hedge Detection task, we define three of entities: scope scope Hence, the Entity Identification subtask is further decomposed into three token classification subtasks, one for each entity type. In the Candidate Relation Generation subtask, we apply a simple procedure to gena relation. Each instance in this relation represents a hedge candidate composed by a cue chunk, a start scope token and an end scope token. For the Relation Recognition subtask, we use a binary classifier to discriminate between true and false candidates. The four classifiers are trained with the Entropy Guided Transformation Learning algorithm. When compared to the other hedge detection systems of the CoNLL shared task, our scheme shows a competiperformance. The of our sysis the evaluation corpus. work is partially funded by CNPq and FAPERJ grants 557.128/2009-9 and E-26/170028/2008. a CNPq doctoral fellowship and has financial support from IFG, Brazil. a CAPES doctoral fellowship. a CNPq research fellowship. Task detection of hedge cues and their scopes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: a case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="2828" citStr="Brill, 1995" startWordPosition="449" endWordPosition="450">1, we present a sentence with two hedge instances. The hedge cues are highlighted and their scopes are delimited by brackets. The hedge cue comprises one or more keywords that indicate uncertainty. The hedge scope is the uncertain statement which is hedged by the cue. The scope always includes the corresponding cue. [ They indicate that [ the demonstration is possible in this context ] and there is a correlation ] Figure 1: Sentence with two hedge instances. Over the last two decades, several Computational Linguistic problems have been successfully modeled as local token classification tasks (Brill, 1995; Milidi´u et al., 2009). Nevertheless, the harder problems consist in identifying complex structures within a text. These structures comprise many tokens and show non local token dependencies. Phrase chunking (Sang and Buchholz, 2000) is a task that involves structure recognition. Punyakanok and Roth decompose this task into four subtasks, that are sequentially solved (Punyakanok and Roth, 2001). They use Hidden Markov Models for the first three subtasks. They find out that task decomposition improves the overall token classification modeling. Clause identification (Sang and D´ejean, 2001) is</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based error-driven learning and natural language processing: a case study in part-of-speech tagging. Computational Linguistics, 21(4):543–565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Llu´ıs M`arquez</author>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
</authors>
<title>Learning and inference for clause identification.</title>
<date>2002</date>
<booktitle>In Proceedings of the Thirteenth European Conference on Machine Learning,</booktitle>
<pages>35--47</pages>
<marker>Carreras, M`arquez, Punyakanok, Roth, 2002</marker>
<rawString>Xavier Carreras, Llu´ıs M`arquez, Vasin Punyakanok, and Dan Roth. 2002. Learning and inference for clause identification. In Proceedings of the Thirteenth European Conference on Machine Learning, pages 35–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Llu´ıs M`arquez</author>
<author>Jorge Castro</author>
</authors>
<title>Filtering-ranking perceptron learning for partial parsing.</title>
<date>2005</date>
<booktitle>Machine Learning,</booktitle>
<pages>60--1</pages>
<marker>Carreras, M`arquez, Castro, 2005</marker>
<rawString>Xavier Carreras, Llu´ıs M`arquez, and Jorge Castro. 2005. Filtering-ranking perceptron learning for partial parsing. Machine Learning, 60(1–3):41–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C´ıcero N dos Santos</author>
<author>Ruy L Milidi´u</author>
</authors>
<date>2009</date>
<booktitle>Foundations of Computational Intelligence, Volume 1: Learning and Approximation,</booktitle>
<volume>201</volume>
<pages>159--184</pages>
<publisher>Springer.</publisher>
<marker>Santos, Milidi´u, 2009</marker>
<rawString>C´ıcero N. dos Santos and Ruy L. Milidi´u, 2009. Foundations of Computational Intelligence, Volume 1: Learning and Approximation, volume 201 of Studies in Computational Intelligence, chapter Entropy Guided Transformation Learning, pages 159–184. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich´ard Farkas</author>
<author>Veronika Vincze</author>
<author>Gy¨orgy M´ora</author>
<author>J´anos Csirik</author>
<author>Gy¨orgy Szarvas</author>
</authors>
<title>The CoNLL2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task,</booktitle>
<pages>1--12</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<marker>Farkas, Vincze, M´ora, Csirik, Szarvas, 2010</marker>
<rawString>Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task, pages 1–12, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eraldo R Fernandes</author>
<author>C´ıcero N dos Santos</author>
<author>Ruy L Milidi´u</author>
</authors>
<title>Portuguese language processing service.</title>
<date>2009</date>
<booktitle>In Proceedings of the Web in Ibero-America Alternate Track of the 18th World Wide Web Conference (WWW’2009),</booktitle>
<location>Madrid.</location>
<marker>Fernandes, Santos, Milidi´u, 2009</marker>
<rawString>Eraldo R. Fernandes, C´ıcero N. dos Santos, and Ruy L. Milidi´u. 2009a. Portuguese language processing service. In Proceedings of the Web in Ibero-America Alternate Track of the 18th World Wide Web Conference (WWW’2009), Madrid.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eraldo R Fernandes</author>
<author>Bernardo A Pires</author>
<author>C´ıcero N dos Santos</author>
<author>Ruy L Milidi´u</author>
</authors>
<title>Clause identification using entropy guided transformation learning.</title>
<date>2009</date>
<booktitle>In Proceedings of the 7th Brazilian Symposium in Information and Human Language Technology (STIL),</booktitle>
<location>S˜ao Carlos, Brazil.</location>
<marker>Fernandes, Pires, Santos, Milidi´u, 2009</marker>
<rawString>Eraldo R. Fernandes, Bernardo A. Pires, C´ıcero N. dos Santos, and Ruy L. Milidi´u. 2009b. Clause identification using entropy guided transformation learning. In Proceedings of the 7th Brazilian Symposium in Information and Human Language Technology (STIL), S˜ao Carlos, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eraldo R Fernandes</author>
<author>Bernardo A Pires</author>
<author>C´ıcero N dos Santos</author>
<author>Ruy L Milidi´u</author>
</authors>
<title>A machine learning approach to Portuguese clause identification.</title>
<date>2010</date>
<booktitle>In Proceedings of the Nineth International Conference on Computational Processing of the Portuguese Language (PROPOR),</booktitle>
<volume>6001</volume>
<pages>55--64</pages>
<publisher>Springer.</publisher>
<location>Porto Alegre, Brazil.</location>
<marker>Fernandes, Pires, Santos, Milidi´u, 2010</marker>
<rawString>Eraldo R. Fernandes, Bernardo A. Pires, C´ıcero N. dos Santos, and Ruy L. Milidi´u. 2010. A machine learning approach to Portuguese clause identification. In Proceedings of the Nineth International Conference on Computational Processing of the Portuguese Language (PROPOR), volume 6001 of Lecture Notes in Artificial Intelligence, pages 55– 64, Porto Alegre, Brazil. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruy L Milidi´u</author>
<author>C´ıcero N dos Santos</author>
<author>Julio C Duarte</author>
</authors>
<title>Phrase chunking using entropy guided transformation learning.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>647--655</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, USA.</location>
<marker>Milidi´u, Santos, Duarte, 2008</marker>
<rawString>Ruy L. Milidi´u, C´ıcero N. dos Santos, and Julio C. Duarte. 2008. Phrase chunking using entropy guided transformation learning. In Proceedings of ACL-08: HLT, pages 647–655, Columbus, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruy L Milidi´u</author>
<author>C´ıcero N dos Santos</author>
<author>Carlos E M Crestana</author>
</authors>
<title>A token classification approach to dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 7th Brazilian Symposium in Information and Human Language Technology (STIL’2009),</booktitle>
<location>S˜ao Carlos, Brazil.</location>
<marker>Milidi´u, Santos, Crestana, 2009</marker>
<rawString>Ruy L. Milidi´u, C´ıcero N. dos Santos, and Carlos E. M. Crestana. 2009. A token classification approach to dependency parsing. In Proceedings of the 7th Brazilian Symposium in Information and Human Language Technology (STIL’2009), S˜ao Carlos, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the scope of hedge cues in biomedical texts.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop,</booktitle>
<pages>28--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, USA,</location>
<contexts>
<context position="4630" citStr="Morante and Daelemans (2009)" startWordPosition="710" endWordPosition="713">spects of clause structures. Phrase Recognition is a general type of task that includes both phrase chunking and clause identification. Carreras et al. propose the FilteringRanking Perceptron (FRP) system for this general task (Carreras et al., 2005). The FRP task modeling is strongly related to previous proposals (Punyakanok and Roth, 2001; Carreras et al., 2002). However, it simultaneously learns to solve three subtasks. FRP is very effective, although computationally expensive at both training and prediction time. Currently, FRP provides the best performing clause identification system. In Morante and Daelemans (2009), the hedge detection task is solved as two consecutive classification tasks. The first one consists of classifying the tokens of a sentence as hedge cues using the IOB tagging style. The second task consists of classifying tokens of a sentence as being the start of a hedge scope, the end of one, or neither. The result of those two tasks is combined using a set of six rules to solve the hedge detection task. Here, we describe RelHunter, a new method for the extraction of structured information from text. Additionally, we apply it to the Hedge Detection task. RelHunter extends the modeling stra</context>
<context position="8101" citStr="Morante and Daelemans (2009)" startWordPosition="1293" endWordPosition="1296">ication We consider three specific entity types: cue chunk, start scope token, and end scope token. We divide entity identification into three token classification tasks, one for each entity type. Thus, we use the original corpus to train three classifiers. The cue chunk subtask is approached as a token classification problem by using the IOB tagging style. The token tag is defined as follows: I, when it is inside a hedge cue; O, when it is outside a hedge cue; and B, when it begins a hedge cue immediately after a distinct cue. As the baseline classifier, we use the Cue Dictionary proposed in Morante and Daelemans (2009), classifying each occurrence of those words as a cue. The start scope and end scope subtasks are modeled as binary token classification problems. 65 Figure 2: Diagram of the RelHunter method. As the baseline classifier for the start scope subtask, we assign the first token of each hedge cue as the start of a scope. We have two baseline classifiers for the end scope subtask: END and END-X. The END system classifies as an end token the second to the last token of each sentence that contains a cue. Due to the frequent occurrence of parenthesized clauses at the end of sentences in full articles, </context>
</contexts>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante and Walter Daelemans. 2009. Learning the scope of hedge cues in biomedical texts. In Proceedings of the BioNLP 2009 Workshop, pages 28–36, Boulder, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="13915" citStr="Porter, 1980" startWordPosition="2240" endWordPosition="2241">didates that have the same cue and start scope tokens. Within a segment, we order the candidates by the order of the end token in the original corpus. We use a context window of 7 candidates, i.e., three candidates before the current, the current candidate and three candidates after the current. 5 Experimental Results We use the corpus provided in the CoNLL-2010 Shared Task to train and evaluate our hedge detection system. We add the following annotation to the corpus: word stems, part-of-speech tags, phrase chunks, and clause annotations. Word stems have been generated by the Porter stemmer (Porter, 1980). The additional annotation has been generated by ETL based systems (dos Santos and Milidi´u, 2009; Fernandes et al., 2009b; Milidi´u et al., 2008). The CoNLL corpus is based on the BioScope corpus (Vincze et al., 2008). Since it contains documents of two different kinds – paper abstracts and full papers – we split it into two subcorpora. The first subcorpus is called ABST and contains all the paper abstracts. The second is called FULL and contains all the full papers. We have two experimental setups: Development and Evaluation. In the Development Setup, we use ABST as the training corpus and </context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Martin F. Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
</authors>
<title>The use of classifiers in sequential inference.</title>
<date>2001</date>
<booktitle>In Proceedings of the Conference on Advances in Neural Information Processing Systems (NIPS),</booktitle>
<pages>995--1001</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3227" citStr="Punyakanok and Roth, 2001" startWordPosition="506" endWordPosition="510">xt ] and there is a correlation ] Figure 1: Sentence with two hedge instances. Over the last two decades, several Computational Linguistic problems have been successfully modeled as local token classification tasks (Brill, 1995; Milidi´u et al., 2009). Nevertheless, the harder problems consist in identifying complex structures within a text. These structures comprise many tokens and show non local token dependencies. Phrase chunking (Sang and Buchholz, 2000) is a task that involves structure recognition. Punyakanok and Roth decompose this task into four subtasks, that are sequentially solved (Punyakanok and Roth, 2001). They use Hidden Markov Models for the first three subtasks. They find out that task decomposition improves the overall token classification modeling. Clause identification (Sang and D´ejean, 2001) is another task that requires structure recognition. As clauses may embed other clauses, these struc64 Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 64–69, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics tures involve stronger dependencies than phrase chunks. Carreras et al. propose an approach that extends</context>
</contexts>
<marker>Punyakanok, Roth, 2001</marker>
<rawString>Vasin Punyakanok and Dan Roth. 2001. The use of classifiers in sequential inference. In Proceedings of the Conference on Advances in Neural Information Processing Systems (NIPS), pages 995–1001. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Sabine Buchholz</author>
</authors>
<title>Introduction to the CoNLL-2000 shared task: Chunking.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="3063" citStr="Sang and Buchholz, 2000" startWordPosition="481" endWordPosition="484">ncertain statement which is hedged by the cue. The scope always includes the corresponding cue. [ They indicate that [ the demonstration is possible in this context ] and there is a correlation ] Figure 1: Sentence with two hedge instances. Over the last two decades, several Computational Linguistic problems have been successfully modeled as local token classification tasks (Brill, 1995; Milidi´u et al., 2009). Nevertheless, the harder problems consist in identifying complex structures within a text. These structures comprise many tokens and show non local token dependencies. Phrase chunking (Sang and Buchholz, 2000) is a task that involves structure recognition. Punyakanok and Roth decompose this task into four subtasks, that are sequentially solved (Punyakanok and Roth, 2001). They use Hidden Markov Models for the first three subtasks. They find out that task decomposition improves the overall token classification modeling. Clause identification (Sang and D´ejean, 2001) is another task that requires structure recognition. As clauses may embed other clauses, these struc64 Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 64–69, Uppsala, Sweden, 15-16 </context>
</contexts>
<marker>Sang, Buchholz, 2000</marker>
<rawString>Erik F. Tjong Kim Sang and Sabine Buchholz. 2000. Introduction to the CoNLL-2000 shared task: Chunking. In Proceedings of CoNLL-2000 and LLL-2000, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F T K Sang</author>
<author>Herv´e D´ejean</author>
</authors>
<title>Introduction to the CoNLL-2001 shared task: Clause identification.</title>
<date>2001</date>
<booktitle>In Proceedings of Fifth Conference on Computational Natural Language Learning,</booktitle>
<location>Toulouse, France.</location>
<marker>Sang, D´ejean, 2001</marker>
<rawString>Erik F. T. K. Sang and Herv´e D´ejean. 2001. Introduction to the CoNLL-2001 shared task: Clause identification. In Proceedings of Fifth Conference on Computational Natural Language Learning, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Gy¨orgy Szarvas</author>
<author>Rich´ard Farkas</author>
<author>Gy¨orgy M´ora</author>
<author>J´anos Csirik</author>
</authors>
<title>The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<marker>Vincze, Szarvas, Farkas, M´ora, Csirik, 2008</marker>
<rawString>Veronika Vincze, Gy¨orgy Szarvas, Rich´ard Farkas, Gy¨orgy M´ora, and J´anos Csirik. 2008. The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9 (Suppl 11):S9.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>