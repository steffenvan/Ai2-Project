<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.9995095">
A Non-negative Matrix Tri-factorization Approach to
Sentiment Classification with Lexical Prior Knowledge
</title>
<author confidence="0.999149">
Tao Li Yi Zhang
</author>
<affiliation confidence="0.993775">
School of Computer Science
Florida International University
</affiliation>
<email confidence="0.998404">
{taoli,yzhan004}@cs.fiu.edu
</email>
<sectionHeader confidence="0.994785" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999916821428571">
Sentiment classification refers to the task
of automatically identifying whether a
given piece of text expresses positive or
negative opinion towards a subject at hand.
The proliferation of user-generated web
content such as blogs, discussion forums
and online review sites has made it possi-
ble to perform large-scale mining of pub-
lic opinion. Sentiment modeling is thus
becoming a critical component of market
intelligence and social media technologies
that aim to tap into the collective wis-
dom of crowds. In this paper, we consider
the problem of learning high-quality senti-
ment models with minimal manual super-
vision. We propose a novel approach to
learn from lexical prior knowledge in the
form of domain-independent sentiment-
laden terms, in conjunction with domain-
dependent unlabeled data and a few la-
beled documents. Our model is based on a
constrained non-negative tri-factorization
of the term-document matrix which can
be implemented using simple update rules.
Extensive experimental studies demon-
strate the effectiveness of our approach on
a variety of real-world sentiment predic-
tion tasks.
</bodyText>
<sectionHeader confidence="0.998879" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9996649">
Web 2.0 platforms such as blogs, discussion fo-
rums and other such social media have now given
a public voice to every consumer. Recent sur-
veys have estimated that a massive number of in-
ternet users turn to such forums to collect rec-
ommendations for products and services, guid-
ing their own choices and decisions by the opin-
ions that other consumers have publically ex-
pressed. Gleaning insights by monitoring and an-
alyzing large amounts of such user-generated data
</bodyText>
<note confidence="0.848001666666667">
Vikas Sindhwani
Mathematical Sciences
IBM T.J. Watson Research Center
</note>
<email confidence="0.956851">
vsindhw@us.ibm.com
</email>
<bodyText confidence="0.999851365853659">
is thus becoming a key competitive differentia-
tor for many companies. While tracking brand
perceptions in traditional media is hardly a new
challenge, handling the unprecedented scale of
unstructured user-generated web content requires
new methodologies. These methodologies are
likely to be rooted in natural language processing
and machine learning techniques.
Automatically classifying the sentiment ex-
pressed in a blog around selected topics of interest
is a canonical machine learning task in this dis-
cussion. A standard approach would be to manu-
ally label documents with their sentiment orienta-
tion and then apply off-the-shelf text classification
techniques. However, sentiment is often conveyed
with subtle linguistic mechanisms such as the use
of sarcasm and highly domain-specific contextual
cues. This makes manual annotation of sentiment
time consuming and error-prone, presenting a bot-
tleneck in learning high quality models. Moreover,
products and services of current focus, and asso-
ciated community of bloggers with their idiosyn-
cratic expressions, may rapidly evolve over time
causing models to potentially lose performance
and become stale. This motivates the problem of
learning robust sentiment models from minimal
supervision.
In their seminal work, (Pang et al., 2002)
demonstrated that supervised learning signifi-
cantly outperformed a competing body of work
where hand-crafted dictionaries are used to assign
sentiment labels based on relative frequencies of
positive and negative terms. As observed by (Ng et
al., 2006), most semi-automated dictionary-based
approaches yield unsatisfactory lexicons, with ei-
ther high coverage and low precision or vice versa.
However, the treatment of such dictionaries as
forms of prior knowledge that can be incorporated
in machine learning models is a relatively less ex-
plored topic; even lesser so in conjunction with
semi-supervised models that attempt to utilize un-
</bodyText>
<page confidence="0.96869">
244
</page>
<note confidence="0.9996165">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 244–252,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.9979580625">
labeled data. This is the focus of the current paper.
Our models are based on a constrained non-
negative tri-factorization of the term-document
matrix, which can be implemented using simple
update rules. Treated as a set of labeled features,
the sentiment lexicon is incorporated as one set of
constraints that enforce domain-independent prior
knowledge. A second set of constraints introduce
domain-specific supervision via a few document
labels. Together these constraints enable learning
from partial supervision along both dimensions of
the term-document matrix, in what may be viewed
more broadly as a framework for incorporating
dual-supervision in matrix factorization models.
We provide empirical comparisons with several
competing methodologies on four, very different
domains – blogs discussing enterprise software
products, political blogs discussing US presiden-
tial candidates, amazon.com product reviews and
IMDB movie reviews. Results demonstrate the ef-
fectiveness and generality of our approach.
The rest of the paper is organized as follows.
We begin by discussing related work in Section 2.
Section 3 gives a quick background on Non-
negative Matrix Tri-factorization models. In Sec-
tion 4, we present a constrained model and compu-
tational algorithm for incorporating lexical knowl-
edge in sentiment analysis. In Section 5, we en-
hance this model by introducing document labels
as additional constraints. Section 6 presents an
empirical study on four datasets. Finally, Section 7
concludes this paper.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999076544117648">
We point the reader to a recent book (Pang and
Lee, 2008) for an in-depth survey of literature on
sentiment analysis. In this section, we briskly
cover related work to position our contributions
appropriately in the sentiment analysis and ma-
chine learning literature.
Methods focussing on the use and generation of
dictionaries capturing the sentiment of words have
ranged from manual approaches of developing
domain-dependent lexicons (Das and Chen, 2001)
to semi-automated approaches (Hu and Liu, 2004;
Zhuang et al., 2006; Kim and Hovy, 2004), and
even an almost fully automated approach (Turney,
2002). Most semi-automated approaches have met
with limited success (Ng et al., 2006) and super-
vised learning models have tended to outperform
dictionary-based classification schemes (Pang et
al., 2002). A two-tier scheme (Pang and Lee,
2004) where sentences are first classified as sub-
jective versus objective, and then applying the sen-
timent classifier on only the subjective sentences
further improves performance. Results in these
papers also suggest that using more sophisticated
linguistic models, incorporating parts-of-speech
and n-gram language models, do not improve over
the simple unigram bag-of-words representation.
In keeping with these findings, we also adopt a
unigram text model. A subjectivity classification
phase before our models are applied may further
improve the results reported in this paper, but our
focus is on driving the polarity prediction stage
with minimal manual effort.
In this regard, our model brings two inter-
related but distinct themes from machine learning
to bear on this problem: semi-supervised learn-
ing and learning from labeled features. The goal
of the former theme is to learn from few labeled
examples by making use of unlabeled data, while
the goal of the latter theme is to utilize weak
prior knowledge about term-class affinities (e.g.,
the term “awful” indicates negative sentiment and
therefore may be considered as a negatively la-
beled feature). Empirical results in this paper
demonstrate that simultaneously attempting both
these goals in a single model leads to improve-
ments over models that focus on a single goal.
(Goldberg and Zhu, 2006) adapt semi-supervised
graph-based methods for sentiment analysis but
do not incorporate lexical prior knowledge in the
form of labeled features. Most work in machine
learning literature on utilizing labeled features has
focused on using them to generate weakly labeled
examples that are then used for standard super-
vised learning: (Schapire et al., 2002) propose one
such framework for boosting logistic regression;
(Wu and Srihari, 2004) build a modified SVM
and (Liu et al., 2004) use a combination of clus-
tering and EM based methods to instantiate simi-
lar frameworks. By contrast, we incorporate lex-
ical knowledge directly as constraints on our ma-
trix factorization model. In recent work, Druck et
al. (Druck et al., 2008) constrain the predictions of
a multinomial logistic regression model on unla-
beled instances in a Generalized Expectation for-
mulation for learning from labeled features. Un-
like their approach which uses only unlabeled in-
stances, our method uses both labeled and unla-
beled documents in conjunction with labeled and
</bodyText>
<page confidence="0.997277">
245
</page>
<bodyText confidence="0.999582351351351">
unlabeled words.
The matrix tri-factorization models explored in
this paper are closely related to the models pro-
posed recently in (Li et al., 2008; Sindhwani et al.,
2008). Though, their techniques for proving algo-
rithm convergence and correctness can be readily
adapted for our models, (Li et al., 2008) do not
incorporate dual supervision as we do. On the
other hand, while (Sindhwani et al., 2008) do in-
corporate dual supervision in a non-linear kernel-
based setting, they do not enforce non-negativity
or orthogonality – aspects of matrix factorization
models that have shown benefits in prior empirical
studies, see e.g., (Ding et al., 2006).
We also note the very recent work of (Sind-
hwani and Melville, 2008) which proposes a dual-
supervision model for semi-supervised sentiment
analysis. In this model, bipartite graph regulariza-
tion is used to diffuse label information along both
sides of the term-document matrix. Conceptually,
their model implements a co-clustering assump-
tion closely related to Singular Value Decomposi-
tion (see also (Dhillon, 2001; Zha et al., 2001) for
more on this perspective) while our model is based
on Non-negative Matrix Factorization. In another
recent paper (Sandler et al., 2008), standard regu-
larization models are constrained using graphs of
word co-occurences. These are very recently pro-
posed competing methodologies, and we have not
been able to address empirical comparisons with
them in this paper.
Finally, recent efforts have also looked at trans-
fer learning mechanisms for sentiment analysis,
e.g., see (Blitzer et al., 2007). While our focus
is on single-domain learning in this paper, we note
that cross-domain variants of our model can also
be orthogonally developed.
</bodyText>
<sectionHeader confidence="0.99901" genericHeader="method">
3 Background
</sectionHeader>
<subsectionHeader confidence="0.99997">
3.1 Basic Matrix Factorization Model
</subsectionHeader>
<bodyText confidence="0.9997915">
Our proposed models are based on non-negative
matrix Tri-factorization (Ding et al., 2006). In
these models, an m x n term-document matrix X
is approximated by three factors that specify soft
membership of terms and documents in one of k-
classes:
</bodyText>
<equation confidence="0.9659">
X Pz� FSGT . (1)
</equation>
<bodyText confidence="0.999729733333333">
where F is an m x k non-negative matrix repre-
senting knowledge in the word space, i.e., i-th row
of F represents the posterior probability of word
i belonging to the k classes, G is an n x k non-
negative matrix representing knowledge in docu-
ment space, i.e., the i-th row of G represents the
posterior probability of document i belonging to
the k classes, and S is an k x k nonnegative matrix
providing a condensed view of X.
The matrix factorization model is similar to
the probabilistic latent semantic indexing (PLSI)
model (Hofmann, 1999). In PLSI, X is treated
as the joint distribution between words and doc-
uments by the scaling X —* X¯ = X/∑ij Xij thus
∑ij ¯Xij = 1). X¯ is factorized as
</bodyText>
<equation confidence="0.896337">
X¯�WSDT,∑ Wik = 1,∑ Djk = 1,∑ Skk = 1.
k k k
</equation>
<bodyText confidence="0.950580592592593">
(2)
where X is the m x n word-document seman-
tic matrix, X = WSD, W is the word class-
conditional probability, and D is the document
class-conditional probability and S is the class
probability distribution.
PLSI provides a simultaneous solution for the
word and document class conditional distribu-
tion. Our model provides simultaneous solution
for clustering the rows and the columns of X. To
avoid ambiguity, the orthogonality conditions
FTF=I, GTG=I. (3)
can be imposed to enforce each row of F and G
to possess only one nonzero entry. Approximating
the term-document matrix with a tri-factorization
while imposing non-negativity and orthogonal-
ity constraints gives a principled framework for
simultaneously clustering the rows (words) and
columns (documents) of X. In the context of co-
clustering, these models return excellent empiri-
cal performance, see e.g., (Ding et al., 2006). Our
goal now is to bias these models with constraints
incorporating (a) labels of features (coming from
a domain-independent sentiment lexicon), and (b)
labels of documents for the purposes of domain-
specific adaptation. These enhancements are ad-
dressed in Sections 4 and 5 respectively.
</bodyText>
<sectionHeader confidence="0.980961" genericHeader="method">
4 Incorporating Lexical Knowledge
</sectionHeader>
<bodyText confidence="0.999848857142857">
We used a sentiment lexicon generated by the
IBM India Research Labs that was developed for
other text mining applications (Ramakrishnan et
al., 2003). It contains 2,968 words that have been
human-labeled as expressing positive or negative
sentiment. In total, there are 1,267 positive (e.g.
“great”) and 1,701 negative (e.g., “bad”) unique
</bodyText>
<page confidence="0.990163">
246
</page>
<bodyText confidence="0.999886333333333">
terms after stemming. We eliminated terms that
were ambiguous and dependent on context, such
as “dear” and “fine”. It should be noted, that this
list was constructed without a specific domain in
mind; which is further motivation for using train-
ing examples and unlabeled data to learn domain
specific connotations.
Lexical knowledge in the form of the polarity
of terms in this lexicon can be introduced in the
matrix factorization model. By partially specify-
ing term polarities via F, the lexicon influences
the sentiment predictions G over documents.
</bodyText>
<subsectionHeader confidence="0.999899">
4.1 Representing Knowledge in Word Space
</subsectionHeader>
<bodyText confidence="0.999912125">
Let F0 represent prior knowledge about sentiment-
laden words in the lexicon, i.e., if word i is a
positive word (F0)i1 = 1 while if it is negative
(F0)i2 = 1. Note that one may also use soft sen-
timent polarities though our experiments are con-
ducted with hard assignments. This information
is incorporated in the tri-factorization model via a
squared loss term,
</bodyText>
<equation confidence="0.9553515">
min X −FSGT2 +aTr�(F −F0)TC1(F −F0)]
F,G,S
</equation>
<bodyText confidence="0.987500461538462">
(4)
where the notation Tr(A) means trace of the matrix
A. Here, a &gt; 0 is a parameter which determines
the extent to which we enforce F  F0, C1 is a m×
m diagonal matrix whose entry (C1)ii = 1 if the
category of the i-th word is known (i.e., specified
by the i-th row of F0) and (C1)ii = 0 otherwise.
The squared loss terms ensure that the solution for
F in the otherwise unsupervised learning problem
be close to the prior knowledge F0. Note that if
C1 = I, then we know the class orientation of all
the words and thus have a full specification of F0,
Eq.(4) is then reduced to
</bodyText>
<equation confidence="0.980464">
min X −FSGT2 +aF −F02 (5)
F,G,S
</equation>
<bodyText confidence="0.999990125">
The above model is generic and it allows certain
flexibility. For example, in some cases, our prior
knowledge on F0 is not very accurate and we use
smaller a so that the final results are not depen-
dent on F0 very much, i.e., the results are mostly
unsupervised learning results. In addition, the in-
troduction of C1 allows us to incorporate partial
knowledge on word polarity information.
</bodyText>
<subsectionHeader confidence="0.996286">
4.2 Computational Algorithm
</subsectionHeader>
<bodyText confidence="0.9998855">
The optimization problem in Eq.( 4) can be solved
using the following update rules
</bodyText>
<equation confidence="0.989355777777778">
(XTFS)jk
Gjk  Gjk , (6)
(GGTXTFS)jk
(FTXG)ik
Sik  Sik . (7)
(FTFSGTG)ik
(XGST +aC1F0)ik
.
(FFTXGST +aC1F)ik
</equation>
<bodyText confidence="0.9997302">
The algorithm consists of an iterative procedure
using the above three rules until convergence. We
call this approach Matrix Factorization with Lex-
ical Knowledge (MFLK) and outline the precise
steps in the table below.
</bodyText>
<figure confidence="0.931366">
Algorithm 1 Matrix Factorization with Lexical
Knowledge (MFLK)
begin
1. Initialization:
Initialize F = F0
G to K-means clustering results,
S = (FTF)−1FTXG(GTG)−1.
</figure>
<listItem confidence="0.8993882">
2. Iteration:
Update G: fixing F,S, updating G
Update F: fixing S,G, updating F
Update S: fixing F,G, updating S
end
</listItem>
<subsectionHeader confidence="0.999286">
4.3 Algorithm Correctness and Convergence
</subsectionHeader>
<bodyText confidence="0.997133">
Updating F,G,S using the rules above leads to an
asymptotic convergence to a local minima. This
can be proved using arguments similar to (Ding
et al., 2006). We outline the proof of correctness
for updating F since the squared loss term that in-
volves F is a new component in our models.
</bodyText>
<construct confidence="0.994577166666667">
Theorem 1 The above iterative algorithm con-
verges.
Theorem 2 At convergence, the solution satisfies
the Karuch, Kuhn, Tucker optimality condition,
i.e., the algorithm converges correctly to a local
optima.
</construct>
<bodyText confidence="0.9621504">
Theorem 1 can be proved using the standard
auxiliary function approach used in (Lee and Se-
ung, 2001).
Proof of Theorem 2. Following the theory of con-
strained optimization (Nocedal and Wright, 1999),
</bodyText>
<figure confidence="0.9027145">
Fik  Fik
(8)
</figure>
<page confidence="0.947877">
247
</page>
<bodyText confidence="0.740037833333333">
we minimize the following function
L(F) = ||X −FSGT ||2+αTr[(F −F0)TC1(F −F0)]
Note that the gradient of L is,
= −2XGST + 2FSGT GST + 2αC1(F − F0).
The KKT complementarity condition for the non-
negativity of Fik gives
</bodyText>
<equation confidence="0.499491">
[−2XGST +FSGT GST + 2αC1(F − F0)]ikFik = 0.
</equation>
<bodyText confidence="0.999658">
This is the fixed point relation that local minima
for F must satisfy. Given an initial guess of F, the
successive update of F using Eq.(8) will converge
to a local minima. At convergence, we have
</bodyText>
<equation confidence="0.985424">
Fik = Fik .
(FFTXGST +αC1F)ik
</equation>
<bodyText confidence="0.999498571428571">
which is equivalent to the KKT condition of
Eq.(10). The correctness of updating rules for G in
Eq.(6) and S in Eq.(7) have been proved in (Ding
et al., 2006). –
Note that we do not enforce exact orthogonality
in our updating rules since this often implies softer
class assignments.
</bodyText>
<sectionHeader confidence="0.8208895" genericHeader="method">
5 Semi-Supervised Learning With
Lexical Knowledge
</sectionHeader>
<bodyText confidence="0.9999544375">
So far our models have made no demands on hu-
man effort, other than unsupervised collection of
the term-document matrix and a one-time effort in
compiling a domain-independent sentiment lexi-
con. We now assume that a few documents are
manually labeled for the purposes of capturing
some domain-specific connotations leading to a
more domain-adapted model. The partial labels
on documents can be described using G0 where
(G0)i1 = 1 if the document expresses positive sen-
timent, and (G0)i2 = 1 for negative sentiment. As
with F0, one can also use soft sentiment labeling
for documents, though our experiments are con-
ducted with hard assignments.
Therefore, the semi-supervised learning with
lexical knowledge can be described as
</bodyText>
<equation confidence="0.99086">
min X −FSGT2 +αTr[(F −F0)TC1(F −F0)] +
F,G,S
βTr[(G− G0)TC2(G− G0)]
</equation>
<bodyText confidence="0.999554875">
Where α &gt; 0,β &gt; 0 are parameters which deter-
mine the extent to which we enforce F  F0 and
G  G0 respectively, C1 and C2 are diagonal ma-
trices indicating the entries of F0 and G0 that cor-
respond to labeled entities. The squared loss terms
ensure that the solution for F,G, in the otherwise
unsupervised learning problem, be close to the
prior knowledge F0 and G0.
</bodyText>
<subsectionHeader confidence="0.987847">
5.1 Computational Algorithm
</subsectionHeader>
<bodyText confidence="0.999359">
The optimization problem in Eq.( 4) can be solved
using the following update rules
</bodyText>
<equation confidence="0.989219625">
(XTFS+βC2G0)jk
Gjk  Gjk (11)
(GGTXTFS + βGGTC2G0)jk
Sik  Sik (FTXG)ik .
(12)
(FTFSGTG)ik
Fik  Fik (XGST +αC1F0)ik . (13)
(FFTXGST +αC1F)ik
</equation>
<bodyText confidence="0.999734260869565">
Thus the algorithm for semi-supervised learning
with lexical knowledge based on our matrix fac-
torization framework, referred as SSMFLK, con-
sists of an iterative procedure using the above three
rules until convergence. The correctness and con-
vergence of the algorithm can also be proved using
similar arguments as what we outlined earlier for
MFLK in Section 4.3.
A quick word about computational complexity.
The term-document matrix is typically very sparse
with z  nm non-zero entries while k is typically
also much smaller than n,m. By using sparse ma-
trix multiplications and avoiding dense intermedi-
ate matrices, the updates can be very efficiently
and easily implemented. In particular, updating
F,S,G each takes O(k2(m + n) + kz) time per it-
eration which scales linearly with the dimensions
and density of the data matrix. Empirically, the
number of iterations before practical convergence
is usually very small (less than 100). Thus, com-
putationally our approach scales to large datasets
even though our experiments are run on relatively
small-sized datasets.
</bodyText>
<sectionHeader confidence="0.999912" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<subsectionHeader confidence="0.998315">
6.1 Datasets Description
</subsectionHeader>
<bodyText confidence="0.999493428571429">
Four different datasets are used in our experi-
ments.
Movies Reviews: This is a popular dataset in
sentiment analysis literature (Pang et al., 2002).
It consists of 1000 positive and 1000 negative
movie reviews drawn from the IMDB archive of
the rec.arts.movies.reviews newsgroups.
</bodyText>
<equation confidence="0.686442">
∂L
∂F
(XGST +αC1F0)ik
</equation>
<page confidence="0.992052">
248
</page>
<bodyText confidence="0.999476130434783">
Lotus blogs: The data set is targeted at detect-
ing sentiment around enterprise software, specif-
ically pertaining to the IBM Lotus brand (Sind-
hwani and Melville, 2008). An unlabeled set
of blog posts was created by randomly sampling
2000 posts from a universe of 14,258 blogs that
discuss issues relevant to Lotus software. In ad-
dition to this unlabeled set, 145 posts were cho-
sen for manual labeling. These posts came from
14 individual blogs, 4 of which are actively post-
ing negative content on the brand, with the rest
tending to write more positive or neutral posts.
The data was collected by downloading the lat-
est posts from each blogger’s RSS feeds, or ac-
cessing the blog’s archives. Manual labeling re-
sulted in 34 positive and 111 negative examples.
Political candidate blogs: For our second blog
domain, we used data gathered from 16,742 polit-
ical blogs, which contain over 500,000 posts. As
with the Lotus dataset, an unlabeled set was cre-
ated by randomly sampling 2000 posts. 107 posts
were chosen for labeling. A post was labeled as
having positive or negative sentiment about a spe-
cific candidate (Barack Obama or Hillary Clinton)
if it explicitly mentioned the candidate in posi-
tive or negative terms. This resulted in 49 posi-
tively and 58 negatively labeled posts. Amazon
Reviews: The dataset contains product reviews
taken from Amazon.com from 4 product types:
Kitchen, Books, DVDs, and Electronics (Blitzer
et al., 2007). The dataset contains about 4000 pos-
itive reviews and 4000 negative reviews and can
be obtained from http://www.cis.upenn.
edu/˜mdredze/datasets/sentiment/.
For all datasets, we picked 5000 words with
highest document-frequency to generate the vo-
cabulary. Stopwords were removed and a nor-
malized term-frequency representation was used.
Genuinely unlabeled posts for Political and Lo-
tus were used for semi-supervised learning experi-
ments in section 6.3; they were not used in section
6.2 on the effect of lexical prior knowledge. In the
experiments, we set α, the parameter determining
the extent to which to enforce the feature labels,
to be 1/2, and b, the corresponding parameter for
enforcing document labels, to be 1.
</bodyText>
<subsectionHeader confidence="0.9844925">
6.2 Sentiment Analysis with Lexical
Knowledge
</subsectionHeader>
<bodyText confidence="0.999943923076923">
Of course, one can remove all burden on hu-
man effort by simply using unsupervised tech-
niques. Our interest in the first set of experi-
ments is to explore the benefits of incorporating a
sentiment lexicon over unsupervised approaches.
Does a one-time effort in compiling a domain-
independent dictionary and using it for different
sentiment tasks pay off in comparison to simply
using unsupervised methods? In our case, matrix
tri-factorization and other co-clustering methods
form the obvious unsupervised baseline for com-
parison and so we start by comparing our method
(MFLK) with the following methods:
</bodyText>
<listItem confidence="0.909876933333334">
• Four document clustering methods: K-
means, Tri-Factor Nonnegative Ma-
trix Factorization (TNMF) (Ding et al.,
2006), Information-Theoretic Co-clustering
(ITCC) (Dhillon et al., 2003), and Euclidean
Co-clustering algorithm (ECC) (Cho et al.,
2004). These methods do not make use of
the sentiment lexicon.
• Feature Centroid (FC): This is a simple
dictionary-based baseline method. Recall
that each word can be expressed as a “bag-
of-documents” vector. In this approach, we
compute the centroids of these vectors, one
corresponding to positive words and another
corresponding to negative words. This yields
</listItem>
<bodyText confidence="0.9487466">
a two-dimensional representation for docu-
ments, on which we then perform K-means
clustering.
Performance Comparison Figure 1 shows the
experimental results on four datasets using accu-
racy as the performance measure. The results are
obtained by averaging 20 runs. It can be observed
that our MFLK method can effectively utilize the
lexical knowledge to improve the quality of senti-
ment prediction.
</bodyText>
<figureCaption confidence="0.999629">
Figure 1: Accuracy results on four datasets
</figureCaption>
<figure confidence="0.999300736842105">
Accuracy
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
Movies Lotus Political Amazon
MFLK
FC
TNMF
ECC
ITCC
K−Means
</figure>
<page confidence="0.992342">
249
</page>
<bodyText confidence="0.903410375">
Size of Sentiment Lexicon We also investigate
the effects of the size of the sentiment lexicon on
the performance of our model. Figure 2 shows
results with random subsets of the lexicon of in-
creasing size. We observe that generally the per-
formance increases as more and more lexical su-
pervision is provided.
Fraction of sentiment words labeled
</bodyText>
<figureCaption confidence="0.961368333333333">
Figure 2: MFLK accuracy as size of sentiment
lexicon (i.e., number of words in the lexicon) in-
creases on the four datasets
</figureCaption>
<subsectionHeader confidence="0.706111">
Robustness to Vocabulary Size High dimen-
</subsectionHeader>
<bodyText confidence="0.9998608125">
sionality and noise can have profound impact on
the comparative performance of clustering and
semi-supervised learning algorithms. We simu-
late scenarios with different vocabulary sizes by
selecting words based on information gain. It
should, however, be kept in mind that in a tru-
ely unsupervised setting document labels are un-
available and therefore information gain cannot
be practically computed. Figure 3 and Figure 4
show results for Lotus and Amazon datasets re-
spectively and are representative of performance
on other datasets. MLFK tends to retain its po-
sition as the best performing method even at dif-
ferent vocabulary sizes. ITCC performance is also
noteworthy given that it is a completely unsuper-
vised method.
</bodyText>
<subsectionHeader confidence="0.504935">
Fraction of Original Vocabulary
</subsectionHeader>
<figureCaption confidence="0.990206">
Figure 3: Accuracy results on Lotus dataset with
increasing vocabulary size
</figureCaption>
<figure confidence="0.394926">
Fraction of Original Vocabulary
</figure>
<figureCaption confidence="0.9818515">
Figure 4: Accuracy results on Amazon dataset
with increasing vocabulary size
</figureCaption>
<subsectionHeader confidence="0.9937615">
6.3 Sentiment Analysis with Dual
Supervision
</subsectionHeader>
<bodyText confidence="0.999601903225806">
We now assume that together with labeled features
from the sentiment lexicon, we also have access to
a few labeled documents. The natural question is
whether the presence of lexical constraints leads
to better semi-supervised models. In this section,
we compare our method (SSMFLK) with the fol-
lowing three semi-supervised approaches: (1) The
algorithm proposed in (Zhou et al., 2003) which
conducts semi-supervised learning with local and
global consistency (Consistency Method); (2) Zhu
et al.’s harmonic Gaussian field method coupled
with the Class Mass Normalization (Harmonic-
CMN) (Zhu et al., 2003); and (3) Green’s function
learning algorithm (Green’s Function) proposed
in (Ding et al., 2007).
We also compare the results of SSMFLK with
those of two supervised classification methods:
Support Vector Machine (SVM) and Naive Bayes.
Both of these methods have been widely used in
sentiment analysis. In particular, the use of SVMs
in (Pang et al., 2002) initially sparked interest
in using machine learning methods for sentiment
classification. Note that none of these competing
methods utilizes lexical knowledge.
The results are presented in Figure 5, Figure 6,
Figure 7, and Figure 8. We note that our SSMFLK
method either outperforms all other methods over
the entire range of number of labeled documents
(Movies, Political), or ultimately outpaces other
methods (Lotus, Amazon) as a few document la-
bels come in.
</bodyText>
<subsectionHeader confidence="0.954234">
Learning Domain-Specific Connotations In
</subsectionHeader>
<bodyText confidence="0.99629">
our first set of experiments, we incorporated the
sentiment lexicon in our models and learnt the
sentiment orientation of words and documents via
F,G factors respectively. In the second set of
</bodyText>
<figure confidence="0.993708962264151">
0.85
0.8
0.75
Movies
Lotus
Political
Amazon
0.6
0.55
0.5
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
Accuracy
0.7
0.65
0.85
0.8
0.75
MFLK
FC
TNMF
K−Means
ITCC
ECC
0.6
0.55
0.5
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
Accuracy
0.7
0.65
1
0.5
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
0.68
0.66
0.64
0.62
0.6
0.58
0.56
0.54
0.52
MFLK
FC
TNMF
K−Means
ITCC
ECC
Accuracy
250
Number of documents labeled as a fraction of the original set of labeled documents
</figure>
<figureCaption confidence="0.9923335">
Figure 5: Accuracy results with increasing number
of labeled documents on Movies dataset
</figureCaption>
<figure confidence="0.643383">
Number of documents labeled as a fraction of the original set of labeled documents
</figure>
<figureCaption confidence="0.99645">
Figure 7: Accuracy results with increasing number
of labeled documents on Political dataset
</figureCaption>
<figure confidence="0.999933485714286">
0.8
0.75
0.7
0.65
0.6
0.55
0.45
0.5
SSMFLK
Consistency Method
Homonic−CMN
Green Function
SVM
Naive Bays
0.4
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
0.8
0.75
0.7
0.65
0.6
0.55
0.5
SSMFLK
Consistency Method
Homonic−CMN
Green Function
SVM
Naive Bays
0.3
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
0.45
0.4
0.35
Accuracy
Accuracy
Number of documents labeled as a fraction of the original set of labeled documents
0.8
0.9
0.8
0.7
0.6
SSMFLK
Consistency Method
Homonic−CMN
Green Function
SVM
Naive Bayes
0.3
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
0.5
0.4
0.75
Accuracy
0.7
0.65
Accuracy
0.6
0.55
0.45
0.5
SSMFLK
Consistency Method
Homonic−CMN
Green Function
SVM
Naive Bays
0.4
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
Number of documents labeled as a fraction of the original set of labeled documents
</figure>
<figureCaption confidence="0.8863365">
Figure 6: Accuracy results with increasing number
of labeled documents on Lotus dataset
</figureCaption>
<bodyText confidence="0.93665856">
experiments, we additionally introduced labeled
documents for domain-specific adjustments. Be-
tween these experiments, we can now look for
words that switch sentiment polarity. These words
are interesting because their domain-specific con-
notation differs from their lexical orientation. For
amazon reviews, the following words switched
polarity from positive to negative: fan, impor-
tant, learning, cons, fast, feature, happy, memory,
portable, simple, small, work while the following
words switched polarity from negative to positive:
address, finish, lack, mean, budget, rent, throw.
Note that words like fan, memory probably refer
to product or product components (i.e., computer
fan and memory) in the amazon review context
but have a very different connotation say in the
context of movie reviews where they probably re-
fer to movie fanfare and memorable performances.
We were surprised to see happy switch polarity!
Two examples of its negative-sentiment usage are:
I ended up buying a Samsung and I couldn’t be
more happy and BORING, not one single exciting
thing about this book. I was happy when my lunch
break ended so I could go back to work and stop
reading.
</bodyText>
<figureCaption confidence="0.8760655">
Figure 8: Accuracy results with increasing number
of labeled documents on Amazon dataset
</figureCaption>
<sectionHeader confidence="0.996693" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.982749583333333">
The primary contribution of this paper is to pro-
pose and benchmark new methodologies for sen-
timent analysis. Non-negative Matrix Factoriza-
tions constitute a rich body of algorithms that have
found applicability in a variety of machine learn-
ing applications: from recommender systems to
document clustering. We have shown how to build
effective sentiment models by appropriately con-
straining the factors using lexical prior knowledge
and document annotations. To more effectively
utilize unlabeled data and induce domain-specific
adaptation of our models, several extensions are
possible: facilitating learning from related do-
mains, incorporating hyperlinks between docu-
ments, incorporating synonyms or co-occurences
between words etc. As a topic of vigorous current
activity, there are several very recently proposed
competing methodologies for sentiment analysis
that we would like to benchmark against. These
are topics for future work.
Acknowledgement: The work of T. Li is par-
tially supported by NSF grants DMS-0844513 and
CCF-0830659. We would also like to thank Prem
Melville and Richard Lawrence for their support.
</bodyText>
<page confidence="0.99633">
251
</page>
<sectionHeader confidence="0.993888" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999867049504951">
J. Blitzer, M. Dredze, and F. Pereira. 2007. Biogra-
phies, bollywood, boom-boxes and blenders: Do-
main adaptation for sentiment classification. In Pro-
ceedings ofACL, pages 440–447.
H. Cho, I. Dhillon, Y. Guan, and S. Sra. 2004. Mini-
mum sum squared residue co-clustering of gene ex-
pression data. In Proceedings of The 4th SIAMData
Mining Conference, pages 22–24, April.
S. Das and M. Chen. 2001. Yahoo! for amazon:
Extracting market sentiment from stock message
boards. In Proceedings of the 8th Asia Pacific Fi-
nance Association (APFA).
I. S. Dhillon, S. Mallela, and D. S. Modha. 2003.
Information-theoretical co-clustering. In Proceed-
ings ofACM SIGKDD, pages 89–98.
I. S. Dhillon. 2001. Co-clustering documents and
words using bipartite spectral graph partitioning. In
Proceedings ofACMSIGKDD.
C. Ding, T. Li, W. Peng, and H. Park. 2006. Orthogo-
nal nonnegative matrix tri-factorizations for cluster-
ing. In Proceedings of ACM SIGKDD, pages 126–
135.
C. Ding, R. Jin, T. Li, and H.D. Simon. 2007. A
learning framework using green’s function and ker-
nel regularization with application to recommender
system. In Proceedings of ACM SIGKDD, pages
260–269.
G. Druck, G. Mann, and A. McCallum. 2008. Learn-
ing from labeled features using generalized expecta-
tion criteria. In SIGIR.
A. Goldberg and X. Zhu. 2006. Seeing stars
when there aren’t many stars: Graph-based semi-
supervised learning for sentiment categorization. In
HLT-NAACL 2006: Workshop on Textgraphs.
T. Hofmann. 1999. Probabilistic latent semantic in-
dexing. Proceeding of SIGIR, pages 50–57.
M. Hu and B. Liu. 2004. Mining and summarizing
customer reviews. In KDD, pages 168–177.
S.-M. Kim and E. Hovy. 2004. Determining the sen-
timent of opinions. In Proceedings of International
Conference on Computational Linguistics.
D.D. Lee and H.S. Seung. 2001. Algorithms for non-
negative matrix factorization. In Advances in Neural
Information Processing Systems 13.
T. Li, C. Ding, Y. Zhang, and B. Shao. 2008. Knowl-
edge transformation from word space to document
space. In Proceedings of SIGIR, pages 187–194.
B. Liu, X. Li, W.S. Lee, and P. Yu. 2004. Text classifi-
cation by labeling words. In AAAI.
V. Ng, S. Dasgupta, and S. M. Niaz Arifin. 2006. Ex-
amining the role of linguistic knowledge sources in
the automatic identification and classification of re-
views. In COLING &amp; ACL.
J. Nocedal and S.J. Wright. 1999. Numerical Opti-
mization. Springer-Verlag.
B. Pang and L. Lee. 2004. A sentimental education:
sentiment analysis using subjectivity summarization
based on minimum cuts. In ACL.
B. Pang and L. Lee. 2008. Opinion mining
and sentiment analysis. Foundations and Trends
in Information Retrieval: Vol. 2: No 12, pp
1-135 http://www.cs.cornell.edu/home/llee/opinion-
mining-sentiment-analysis-survey.html.
B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs
up? sentiment classification using machine learning
techniques. In EMNLP.
G. Ramakrishnan, A. Jadhav, A. Joshi, S. Chakrabarti,
and P. Bhattacharyya. 2003. Question answering
via bayesian inference on lexical relations. In ACL,
pages 1–10.
T. Sandler, J. Blitzer, P. Talukdar, and L. Ungar. 2008.
Regularized learning with networks of features. In
NIPS.
R.E. Schapire, M. Rochery, M.G. Rahim, and
N. Gupta. 2002. Incorporating prior knowledge into
boosting. In ICML.
V. Sindhwani and P. Melville. 2008. Document-
word co-regularization for semi-supervised senti-
ment analysis. In Proceedings ofIEEE ICDM.
V. Sindhwani, J. Hu, and A. Mojsilovic. 2008. Regu-
larized co-clustering with dual supervision. In Pro-
ceedings ofNIPS.
P. Turney. 2002. Thumbs up or thumbs down? Se-
mantic orientation applied to unsupervised classifi-
cation of reviews. Proceedings of the 40th Annual
Meeting of the Association for Computational Lin-
guistics, pages 417–424.
X. Wu and R. Srihari. 2004. Incorporating prior
knowledge with weighted margin support vector ma-
chines. In KDD.
H. Zha, X. He, C. Ding, M. Gu, and H.D. Simon.
2001. Bipartite graph partitioning and data cluster-
ing. Proceedings ofACM CIKM.
D. Zhou, O. Bousquet, T.N. Lal, J. Weston, and
B. Scholkopf. 2003. Learning with local and global
consistency. In Proceedings ofNIPS.
X. Zhu, Z. Ghahramani, and J. Lafferty. 2003. Semi-
supervised learning using gaussian fields and har-
monic functions. In Proceedings ofICML.
L. Zhuang, F. Jing, and X. Zhu. 2006. Movie review
mining and summarization. In CIKM, pages 43–50.
</reference>
<page confidence="0.997434">
252
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.964469">
<title confidence="0.9944025">A Non-negative Matrix Tri-factorization Approach to Sentiment Classification with Lexical Prior Knowledge</title>
<author confidence="0.999968">Tao Li Yi Zhang</author>
<affiliation confidence="0.9998115">School of Computer Science Florida International University</affiliation>
<abstract confidence="0.999162172413793">Sentiment classification refers to the task of automatically identifying whether a given piece of text expresses positive or negative opinion towards a subject at hand. The proliferation of user-generated web content such as blogs, discussion forums and online review sites has made it possible to perform large-scale mining of public opinion. Sentiment modeling is thus becoming a critical component of market intelligence and social media technologies that aim to tap into the collective wisdom of crowds. In this paper, we consider the problem of learning high-quality sentiment models with minimal manual supervision. We propose a novel approach to learn from lexical prior knowledge in the form of domain-independent sentimentladen terms, in conjunction with domaindependent unlabeled data and a few labeled documents. Our model is based on a constrained non-negative tri-factorization of the term-document matrix which can be implemented using simple update rules. Extensive experimental studies demonstrate the effectiveness of our approach on a variety of real-world sentiment prediction tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>M Dredze</author>
<author>F Pereira</author>
</authors>
<title>Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="10321" citStr="Blitzer et al., 2007" startWordPosition="1564" endWordPosition="1567">ements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective) while our model is based on Non-negative Matrix Factorization. In another recent paper (Sandler et al., 2008), standard regularization models are constrained using graphs of word co-occurences. These are very recently proposed competing methodologies, and we have not been able to address empirical comparisons with them in this paper. Finally, recent efforts have also looked at transfer learning mechanisms for sentiment analysis, e.g., see (Blitzer et al., 2007). While our focus is on single-domain learning in this paper, we note that cross-domain variants of our model can also be orthogonally developed. 3 Background 3.1 Basic Matrix Factorization Model Our proposed models are based on non-negative matrix Tri-factorization (Ding et al., 2006). In these models, an m x n term-document matrix X is approximated by three factors that specify soft membership of terms and documents in one of kclasses: X Pz� FSGT . (1) where F is an m x k non-negative matrix representing knowledge in the word space, i.e., i-th row of F represents the posterior probability of</context>
<context position="21626" citStr="Blitzer et al., 2007" startWordPosition="3456" endWordPosition="3459">used data gathered from 16,742 political blogs, which contain over 500,000 posts. As with the Lotus dataset, an unlabeled set was created by randomly sampling 2000 posts. 107 posts were chosen for labeling. A post was labeled as having positive or negative sentiment about a specific candidate (Barack Obama or Hillary Clinton) if it explicitly mentioned the candidate in positive or negative terms. This resulted in 49 positively and 58 negatively labeled posts. Amazon Reviews: The dataset contains product reviews taken from Amazon.com from 4 product types: Kitchen, Books, DVDs, and Electronics (Blitzer et al., 2007). The dataset contains about 4000 positive reviews and 4000 negative reviews and can be obtained from http://www.cis.upenn. edu/˜mdredze/datasets/sentiment/. For all datasets, we picked 5000 words with highest document-frequency to generate the vocabulary. Stopwords were removed and a normalized term-frequency representation was used. Genuinely unlabeled posts for Political and Lotus were used for semi-supervised learning experiments in section 6.3; they were not used in section 6.2 on the effect of lexical prior knowledge. In the experiments, we set α, the parameter determining the extent to </context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>J. Blitzer, M. Dredze, and F. Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In Proceedings ofACL, pages 440–447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cho</author>
<author>I Dhillon</author>
<author>Y Guan</author>
<author>S Sra</author>
</authors>
<title>Minimum sum squared residue co-clustering of gene expression data.</title>
<date>2004</date>
<booktitle>In Proceedings of The 4th SIAMData Mining Conference,</booktitle>
<pages>22--24</pages>
<contexts>
<context position="23242" citStr="Cho et al., 2004" startWordPosition="3700" endWordPosition="3703">s. Does a one-time effort in compiling a domainindependent dictionary and using it for different sentiment tasks pay off in comparison to simply using unsupervised methods? In our case, matrix tri-factorization and other co-clustering methods form the obvious unsupervised baseline for comparison and so we start by comparing our method (MFLK) with the following methods: • Four document clustering methods: Kmeans, Tri-Factor Nonnegative Matrix Factorization (TNMF) (Ding et al., 2006), Information-Theoretic Co-clustering (ITCC) (Dhillon et al., 2003), and Euclidean Co-clustering algorithm (ECC) (Cho et al., 2004). These methods do not make use of the sentiment lexicon. • Feature Centroid (FC): This is a simple dictionary-based baseline method. Recall that each word can be expressed as a “bagof-documents” vector. In this approach, we compute the centroids of these vectors, one corresponding to positive words and another corresponding to negative words. This yields a two-dimensional representation for documents, on which we then perform K-means clustering. Performance Comparison Figure 1 shows the experimental results on four datasets using accuracy as the performance measure. The results are obtained b</context>
</contexts>
<marker>Cho, Dhillon, Guan, Sra, 2004</marker>
<rawString>H. Cho, I. Dhillon, Y. Guan, and S. Sra. 2004. Minimum sum squared residue co-clustering of gene expression data. In Proceedings of The 4th SIAMData Mining Conference, pages 22–24, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Das</author>
<author>M Chen</author>
</authors>
<title>Yahoo! for amazon: Extracting market sentiment from stock message boards.</title>
<date>2001</date>
<booktitle>In Proceedings of the 8th Asia Pacific Finance Association (APFA).</booktitle>
<contexts>
<context position="5960" citStr="Das and Chen, 2001" startWordPosition="886" endWordPosition="889">oducing document labels as additional constraints. Section 6 presents an empirical study on four datasets. Finally, Section 7 concludes this paper. 2 Related Work We point the reader to a recent book (Pang and Lee, 2008) for an in-depth survey of literature on sentiment analysis. In this section, we briskly cover related work to position our contributions appropriately in the sentiment analysis and machine learning literature. Methods focussing on the use and generation of dictionaries capturing the sentiment of words have ranged from manual approaches of developing domain-dependent lexicons (Das and Chen, 2001) to semi-automated approaches (Hu and Liu, 2004; Zhuang et al., 2006; Kim and Hovy, 2004), and even an almost fully automated approach (Turney, 2002). Most semi-automated approaches have met with limited success (Ng et al., 2006) and supervised learning models have tended to outperform dictionary-based classification schemes (Pang et al., 2002). A two-tier scheme (Pang and Lee, 2004) where sentences are first classified as subjective versus objective, and then applying the sentiment classifier on only the subjective sentences further improves performance. Results in these papers also suggest t</context>
</contexts>
<marker>Das, Chen, 2001</marker>
<rawString>S. Das and M. Chen. 2001. Yahoo! for amazon: Extracting market sentiment from stock message boards. In Proceedings of the 8th Asia Pacific Finance Association (APFA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I S Dhillon</author>
<author>S Mallela</author>
<author>D S Modha</author>
</authors>
<title>Information-theoretical co-clustering.</title>
<date>2003</date>
<booktitle>In Proceedings ofACM SIGKDD,</booktitle>
<pages>89--98</pages>
<contexts>
<context position="23178" citStr="Dhillon et al., 2003" startWordPosition="3691" endWordPosition="3694">its of incorporating a sentiment lexicon over unsupervised approaches. Does a one-time effort in compiling a domainindependent dictionary and using it for different sentiment tasks pay off in comparison to simply using unsupervised methods? In our case, matrix tri-factorization and other co-clustering methods form the obvious unsupervised baseline for comparison and so we start by comparing our method (MFLK) with the following methods: • Four document clustering methods: Kmeans, Tri-Factor Nonnegative Matrix Factorization (TNMF) (Ding et al., 2006), Information-Theoretic Co-clustering (ITCC) (Dhillon et al., 2003), and Euclidean Co-clustering algorithm (ECC) (Cho et al., 2004). These methods do not make use of the sentiment lexicon. • Feature Centroid (FC): This is a simple dictionary-based baseline method. Recall that each word can be expressed as a “bagof-documents” vector. In this approach, we compute the centroids of these vectors, one corresponding to positive words and another corresponding to negative words. This yields a two-dimensional representation for documents, on which we then perform K-means clustering. Performance Comparison Figure 1 shows the experimental results on four datasets using</context>
</contexts>
<marker>Dhillon, Mallela, Modha, 2003</marker>
<rawString>I. S. Dhillon, S. Mallela, and D. S. Modha. 2003. Information-theoretical co-clustering. In Proceedings ofACM SIGKDD, pages 89–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I S Dhillon</author>
</authors>
<title>Co-clustering documents and words using bipartite spectral graph partitioning.</title>
<date>2001</date>
<booktitle>In Proceedings ofACMSIGKDD.</booktitle>
<contexts>
<context position="9806" citStr="Dhillon, 2001" startWordPosition="1486" endWordPosition="1487">ar kernelbased setting, they do not enforce non-negativity or orthogonality – aspects of matrix factorization models that have shown benefits in prior empirical studies, see e.g., (Ding et al., 2006). We also note the very recent work of (Sindhwani and Melville, 2008) which proposes a dualsupervision model for semi-supervised sentiment analysis. In this model, bipartite graph regularization is used to diffuse label information along both sides of the term-document matrix. Conceptually, their model implements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective) while our model is based on Non-negative Matrix Factorization. In another recent paper (Sandler et al., 2008), standard regularization models are constrained using graphs of word co-occurences. These are very recently proposed competing methodologies, and we have not been able to address empirical comparisons with them in this paper. Finally, recent efforts have also looked at transfer learning mechanisms for sentiment analysis, e.g., see (Blitzer et al., 2007). While our focus is on single-domain learning in this paper, we note that cross-doma</context>
</contexts>
<marker>Dhillon, 2001</marker>
<rawString>I. S. Dhillon. 2001. Co-clustering documents and words using bipartite spectral graph partitioning. In Proceedings ofACMSIGKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Ding</author>
<author>T Li</author>
<author>W Peng</author>
<author>H Park</author>
</authors>
<title>Orthogonal nonnegative matrix tri-factorizations for clustering.</title>
<date>2006</date>
<booktitle>In Proceedings of ACM SIGKDD,</booktitle>
<pages>126--135</pages>
<contexts>
<context position="9392" citStr="Ding et al., 2006" startWordPosition="1422" endWordPosition="1425">tri-factorization models explored in this paper are closely related to the models proposed recently in (Li et al., 2008; Sindhwani et al., 2008). Though, their techniques for proving algorithm convergence and correctness can be readily adapted for our models, (Li et al., 2008) do not incorporate dual supervision as we do. On the other hand, while (Sindhwani et al., 2008) do incorporate dual supervision in a non-linear kernelbased setting, they do not enforce non-negativity or orthogonality – aspects of matrix factorization models that have shown benefits in prior empirical studies, see e.g., (Ding et al., 2006). We also note the very recent work of (Sindhwani and Melville, 2008) which proposes a dualsupervision model for semi-supervised sentiment analysis. In this model, bipartite graph regularization is used to diffuse label information along both sides of the term-document matrix. Conceptually, their model implements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective) while our model is based on Non-negative Matrix Factorization. In another recent paper (Sandler et al., 2008), standard regularization m</context>
<context position="12400" citStr="Ding et al., 2006" startWordPosition="1920" endWordPosition="1923">cument class conditional distribution. Our model provides simultaneous solution for clustering the rows and the columns of X. To avoid ambiguity, the orthogonality conditions FTF=I, GTG=I. (3) can be imposed to enforce each row of F and G to possess only one nonzero entry. Approximating the term-document matrix with a tri-factorization while imposing non-negativity and orthogonality constraints gives a principled framework for simultaneously clustering the rows (words) and columns (documents) of X. In the context of coclustering, these models return excellent empirical performance, see e.g., (Ding et al., 2006). Our goal now is to bias these models with constraints incorporating (a) labels of features (coming from a domain-independent sentiment lexicon), and (b) labels of documents for the purposes of domainspecific adaptation. These enhancements are addressed in Sections 4 and 5 respectively. 4 Incorporating Lexical Knowledge We used a sentiment lexicon generated by the IBM India Research Labs that was developed for other text mining applications (Ramakrishnan et al., 2003). It contains 2,968 words that have been human-labeled as expressing positive or negative sentiment. In total, there are 1,267 </context>
<context position="15988" citStr="Ding et al., 2006" startWordPosition="2520" endWordPosition="2523">til convergence. We call this approach Matrix Factorization with Lexical Knowledge (MFLK) and outline the precise steps in the table below. Algorithm 1 Matrix Factorization with Lexical Knowledge (MFLK) begin 1. Initialization: Initialize F = F0 G to K-means clustering results, S = (FTF)−1FTXG(GTG)−1. 2. Iteration: Update G: fixing F,S, updating G Update F: fixing S,G, updating F Update S: fixing F,G, updating S end 4.3 Algorithm Correctness and Convergence Updating F,G,S using the rules above leads to an asymptotic convergence to a local minima. This can be proved using arguments similar to (Ding et al., 2006). We outline the proof of correctness for updating F since the squared loss term that involves F is a new component in our models. Theorem 1 The above iterative algorithm converges. Theorem 2 At convergence, the solution satisfies the Karuch, Kuhn, Tucker optimality condition, i.e., the algorithm converges correctly to a local optima. Theorem 1 can be proved using the standard auxiliary function approach used in (Lee and Seung, 2001). Proof of Theorem 2. Following the theory of constrained optimization (Nocedal and Wright, 1999), Fik  Fik (8) 247 we minimize the following function L(F) = ||X </context>
<context position="23111" citStr="Ding et al., 2006" startWordPosition="3684" endWordPosition="3687">interest in the first set of experiments is to explore the benefits of incorporating a sentiment lexicon over unsupervised approaches. Does a one-time effort in compiling a domainindependent dictionary and using it for different sentiment tasks pay off in comparison to simply using unsupervised methods? In our case, matrix tri-factorization and other co-clustering methods form the obvious unsupervised baseline for comparison and so we start by comparing our method (MFLK) with the following methods: • Four document clustering methods: Kmeans, Tri-Factor Nonnegative Matrix Factorization (TNMF) (Ding et al., 2006), Information-Theoretic Co-clustering (ITCC) (Dhillon et al., 2003), and Euclidean Co-clustering algorithm (ECC) (Cho et al., 2004). These methods do not make use of the sentiment lexicon. • Feature Centroid (FC): This is a simple dictionary-based baseline method. Recall that each word can be expressed as a “bagof-documents” vector. In this approach, we compute the centroids of these vectors, one corresponding to positive words and another corresponding to negative words. This yields a two-dimensional representation for documents, on which we then perform K-means clustering. Performance Compar</context>
</contexts>
<marker>Ding, Li, Peng, Park, 2006</marker>
<rawString>C. Ding, T. Li, W. Peng, and H. Park. 2006. Orthogonal nonnegative matrix tri-factorizations for clustering. In Proceedings of ACM SIGKDD, pages 126– 135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Ding</author>
<author>R Jin</author>
<author>T Li</author>
<author>H D Simon</author>
</authors>
<title>A learning framework using green’s function and kernel regularization with application to recommender system.</title>
<date>2007</date>
<booktitle>In Proceedings of ACM SIGKDD,</booktitle>
<pages>260--269</pages>
<contexts>
<context position="26344" citStr="Ding et al., 2007" startWordPosition="4187" endWordPosition="4190">also have access to a few labeled documents. The natural question is whether the presence of lexical constraints leads to better semi-supervised models. In this section, we compare our method (SSMFLK) with the following three semi-supervised approaches: (1) The algorithm proposed in (Zhou et al., 2003) which conducts semi-supervised learning with local and global consistency (Consistency Method); (2) Zhu et al.’s harmonic Gaussian field method coupled with the Class Mass Normalization (HarmonicCMN) (Zhu et al., 2003); and (3) Green’s function learning algorithm (Green’s Function) proposed in (Ding et al., 2007). We also compare the results of SSMFLK with those of two supervised classification methods: Support Vector Machine (SVM) and Naive Bayes. Both of these methods have been widely used in sentiment analysis. In particular, the use of SVMs in (Pang et al., 2002) initially sparked interest in using machine learning methods for sentiment classification. Note that none of these competing methods utilizes lexical knowledge. The results are presented in Figure 5, Figure 6, Figure 7, and Figure 8. We note that our SSMFLK method either outperforms all other methods over the entire range of number of lab</context>
</contexts>
<marker>Ding, Jin, Li, Simon, 2007</marker>
<rawString>C. Ding, R. Jin, T. Li, and H.D. Simon. 2007. A learning framework using green’s function and kernel regularization with application to recommender system. In Proceedings of ACM SIGKDD, pages 260–269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Druck</author>
<author>G Mann</author>
<author>A McCallum</author>
</authors>
<title>Learning from labeled features using generalized expectation criteria.</title>
<date>2008</date>
<booktitle>In SIGIR.</booktitle>
<contexts>
<context position="8428" citStr="Druck et al., 2008" startWordPosition="1269" endWordPosition="1272">ledge in the form of labeled features. Most work in machine learning literature on utilizing labeled features has focused on using them to generate weakly labeled examples that are then used for standard supervised learning: (Schapire et al., 2002) propose one such framework for boosting logistic regression; (Wu and Srihari, 2004) build a modified SVM and (Liu et al., 2004) use a combination of clustering and EM based methods to instantiate similar frameworks. By contrast, we incorporate lexical knowledge directly as constraints on our matrix factorization model. In recent work, Druck et al. (Druck et al., 2008) constrain the predictions of a multinomial logistic regression model on unlabeled instances in a Generalized Expectation formulation for learning from labeled features. Unlike their approach which uses only unlabeled instances, our method uses both labeled and unlabeled documents in conjunction with labeled and 245 unlabeled words. The matrix tri-factorization models explored in this paper are closely related to the models proposed recently in (Li et al., 2008; Sindhwani et al., 2008). Though, their techniques for proving algorithm convergence and correctness can be readily adapted for our mo</context>
</contexts>
<marker>Druck, Mann, McCallum, 2008</marker>
<rawString>G. Druck, G. Mann, and A. McCallum. 2008. Learning from labeled features using generalized expectation criteria. In SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Goldberg</author>
<author>X Zhu</author>
</authors>
<title>Seeing stars when there aren’t many stars: Graph-based semisupervised learning for sentiment categorization.</title>
<date>2006</date>
<booktitle>In HLT-NAACL 2006: Workshop on Textgraphs.</booktitle>
<contexts>
<context position="7702" citStr="Goldberg and Zhu, 2006" startWordPosition="1154" endWordPosition="1157"> from machine learning to bear on this problem: semi-supervised learning and learning from labeled features. The goal of the former theme is to learn from few labeled examples by making use of unlabeled data, while the goal of the latter theme is to utilize weak prior knowledge about term-class affinities (e.g., the term “awful” indicates negative sentiment and therefore may be considered as a negatively labeled feature). Empirical results in this paper demonstrate that simultaneously attempting both these goals in a single model leads to improvements over models that focus on a single goal. (Goldberg and Zhu, 2006) adapt semi-supervised graph-based methods for sentiment analysis but do not incorporate lexical prior knowledge in the form of labeled features. Most work in machine learning literature on utilizing labeled features has focused on using them to generate weakly labeled examples that are then used for standard supervised learning: (Schapire et al., 2002) propose one such framework for boosting logistic regression; (Wu and Srihari, 2004) build a modified SVM and (Liu et al., 2004) use a combination of clustering and EM based methods to instantiate similar frameworks. By contrast, we incorporate </context>
</contexts>
<marker>Goldberg, Zhu, 2006</marker>
<rawString>A. Goldberg and X. Zhu. 2006. Seeing stars when there aren’t many stars: Graph-based semisupervised learning for sentiment categorization. In HLT-NAACL 2006: Workshop on Textgraphs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing. Proceeding of SIGIR,</title>
<date>1999</date>
<pages>50--57</pages>
<contexts>
<context position="11321" citStr="Hofmann, 1999" startWordPosition="1739" endWordPosition="1740">t membership of terms and documents in one of kclasses: X Pz� FSGT . (1) where F is an m x k non-negative matrix representing knowledge in the word space, i.e., i-th row of F represents the posterior probability of word i belonging to the k classes, G is an n x k nonnegative matrix representing knowledge in document space, i.e., the i-th row of G represents the posterior probability of document i belonging to the k classes, and S is an k x k nonnegative matrix providing a condensed view of X. The matrix factorization model is similar to the probabilistic latent semantic indexing (PLSI) model (Hofmann, 1999). In PLSI, X is treated as the joint distribution between words and documents by the scaling X —* X¯ = X/∑ij Xij thus ∑ij ¯Xij = 1). X¯ is factorized as X¯�WSDT,∑ Wik = 1,∑ Djk = 1,∑ Skk = 1. k k k (2) where X is the m x n word-document semantic matrix, X = WSD, W is the word classconditional probability, and D is the document class-conditional probability and S is the class probability distribution. PLSI provides a simultaneous solution for the word and document class conditional distribution. Our model provides simultaneous solution for clustering the rows and the columns of X. To avoid ambi</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>T. Hofmann. 1999. Probabilistic latent semantic indexing. Proceeding of SIGIR, pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In KDD,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="6007" citStr="Hu and Liu, 2004" startWordPosition="893" endWordPosition="896"> Section 6 presents an empirical study on four datasets. Finally, Section 7 concludes this paper. 2 Related Work We point the reader to a recent book (Pang and Lee, 2008) for an in-depth survey of literature on sentiment analysis. In this section, we briskly cover related work to position our contributions appropriately in the sentiment analysis and machine learning literature. Methods focussing on the use and generation of dictionaries capturing the sentiment of words have ranged from manual approaches of developing domain-dependent lexicons (Das and Chen, 2001) to semi-automated approaches (Hu and Liu, 2004; Zhuang et al., 2006; Kim and Hovy, 2004), and even an almost fully automated approach (Turney, 2002). Most semi-automated approaches have met with limited success (Ng et al., 2006) and supervised learning models have tended to outperform dictionary-based classification schemes (Pang et al., 2002). A two-tier scheme (Pang and Lee, 2004) where sentences are first classified as subjective versus objective, and then applying the sentiment classifier on only the subjective sentences further improves performance. Results in these papers also suggest that using more sophisticated linguistic models,</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>M. Hu and B. Liu. 2004. Mining and summarizing customer reviews. In KDD, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-M Kim</author>
<author>E Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="6049" citStr="Kim and Hovy, 2004" startWordPosition="901" endWordPosition="904">on four datasets. Finally, Section 7 concludes this paper. 2 Related Work We point the reader to a recent book (Pang and Lee, 2008) for an in-depth survey of literature on sentiment analysis. In this section, we briskly cover related work to position our contributions appropriately in the sentiment analysis and machine learning literature. Methods focussing on the use and generation of dictionaries capturing the sentiment of words have ranged from manual approaches of developing domain-dependent lexicons (Das and Chen, 2001) to semi-automated approaches (Hu and Liu, 2004; Zhuang et al., 2006; Kim and Hovy, 2004), and even an almost fully automated approach (Turney, 2002). Most semi-automated approaches have met with limited success (Ng et al., 2006) and supervised learning models have tended to outperform dictionary-based classification schemes (Pang et al., 2002). A two-tier scheme (Pang and Lee, 2004) where sentences are first classified as subjective versus objective, and then applying the sentiment classifier on only the subjective sentences further improves performance. Results in these papers also suggest that using more sophisticated linguistic models, incorporating parts-of-speech and n-gram </context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>S.-M. Kim and E. Hovy. 2004. Determining the sentiment of opinions. In Proceedings of International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Lee</author>
<author>H S Seung</author>
</authors>
<title>Algorithms for nonnegative matrix factorization.</title>
<date>2001</date>
<booktitle>In Advances in Neural Information Processing Systems 13.</booktitle>
<contexts>
<context position="16425" citStr="Lee and Seung, 2001" startWordPosition="2592" endWordPosition="2596">orrectness and Convergence Updating F,G,S using the rules above leads to an asymptotic convergence to a local minima. This can be proved using arguments similar to (Ding et al., 2006). We outline the proof of correctness for updating F since the squared loss term that involves F is a new component in our models. Theorem 1 The above iterative algorithm converges. Theorem 2 At convergence, the solution satisfies the Karuch, Kuhn, Tucker optimality condition, i.e., the algorithm converges correctly to a local optima. Theorem 1 can be proved using the standard auxiliary function approach used in (Lee and Seung, 2001). Proof of Theorem 2. Following the theory of constrained optimization (Nocedal and Wright, 1999), Fik  Fik (8) 247 we minimize the following function L(F) = ||X −FSGT ||2+αTr[(F −F0)TC1(F −F0)] Note that the gradient of L is, = −2XGST + 2FSGT GST + 2αC1(F − F0). The KKT complementarity condition for the nonnegativity of Fik gives [−2XGST +FSGT GST + 2αC1(F − F0)]ikFik = 0. This is the fixed point relation that local minima for F must satisfy. Given an initial guess of F, the successive update of F using Eq.(8) will converge to a local minima. At convergence, we have Fik = Fik . (FFTXGST +αC1</context>
</contexts>
<marker>Lee, Seung, 2001</marker>
<rawString>D.D. Lee and H.S. Seung. 2001. Algorithms for nonnegative matrix factorization. In Advances in Neural Information Processing Systems 13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Li</author>
<author>C Ding</author>
<author>Y Zhang</author>
<author>B Shao</author>
</authors>
<title>Knowledge transformation from word space to document space.</title>
<date>2008</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>187--194</pages>
<contexts>
<context position="8893" citStr="Li et al., 2008" startWordPosition="1342" endWordPosition="1345">ontrast, we incorporate lexical knowledge directly as constraints on our matrix factorization model. In recent work, Druck et al. (Druck et al., 2008) constrain the predictions of a multinomial logistic regression model on unlabeled instances in a Generalized Expectation formulation for learning from labeled features. Unlike their approach which uses only unlabeled instances, our method uses both labeled and unlabeled documents in conjunction with labeled and 245 unlabeled words. The matrix tri-factorization models explored in this paper are closely related to the models proposed recently in (Li et al., 2008; Sindhwani et al., 2008). Though, their techniques for proving algorithm convergence and correctness can be readily adapted for our models, (Li et al., 2008) do not incorporate dual supervision as we do. On the other hand, while (Sindhwani et al., 2008) do incorporate dual supervision in a non-linear kernelbased setting, they do not enforce non-negativity or orthogonality – aspects of matrix factorization models that have shown benefits in prior empirical studies, see e.g., (Ding et al., 2006). We also note the very recent work of (Sindhwani and Melville, 2008) which proposes a dualsupervisio</context>
</contexts>
<marker>Li, Ding, Zhang, Shao, 2008</marker>
<rawString>T. Li, C. Ding, Y. Zhang, and B. Shao. 2008. Knowledge transformation from word space to document space. In Proceedings of SIGIR, pages 187–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
<author>X Li</author>
<author>W S Lee</author>
<author>P Yu</author>
</authors>
<title>Text classification by labeling words.</title>
<date>2004</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="8185" citStr="Liu et al., 2004" startWordPosition="1228" endWordPosition="1231"> attempting both these goals in a single model leads to improvements over models that focus on a single goal. (Goldberg and Zhu, 2006) adapt semi-supervised graph-based methods for sentiment analysis but do not incorporate lexical prior knowledge in the form of labeled features. Most work in machine learning literature on utilizing labeled features has focused on using them to generate weakly labeled examples that are then used for standard supervised learning: (Schapire et al., 2002) propose one such framework for boosting logistic regression; (Wu and Srihari, 2004) build a modified SVM and (Liu et al., 2004) use a combination of clustering and EM based methods to instantiate similar frameworks. By contrast, we incorporate lexical knowledge directly as constraints on our matrix factorization model. In recent work, Druck et al. (Druck et al., 2008) constrain the predictions of a multinomial logistic regression model on unlabeled instances in a Generalized Expectation formulation for learning from labeled features. Unlike their approach which uses only unlabeled instances, our method uses both labeled and unlabeled documents in conjunction with labeled and 245 unlabeled words. The matrix tri-factori</context>
</contexts>
<marker>Liu, Li, Lee, Yu, 2004</marker>
<rawString>B. Liu, X. Li, W.S. Lee, and P. Yu. 2004. Text classification by labeling words. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
<author>S Dasgupta</author>
<author>S M Niaz Arifin</author>
</authors>
<title>Examining the role of linguistic knowledge sources in the automatic identification and classification of reviews.</title>
<date>2006</date>
<booktitle>In COLING &amp; ACL.</booktitle>
<contexts>
<context position="3432" citStr="Ng et al., 2006" startWordPosition="505" endWordPosition="508">lity models. Moreover, products and services of current focus, and associated community of bloggers with their idiosyncratic expressions, may rapidly evolve over time causing models to potentially lose performance and become stale. This motivates the problem of learning robust sentiment models from minimal supervision. In their seminal work, (Pang et al., 2002) demonstrated that supervised learning significantly outperformed a competing body of work where hand-crafted dictionaries are used to assign sentiment labels based on relative frequencies of positive and negative terms. As observed by (Ng et al., 2006), most semi-automated dictionary-based approaches yield unsatisfactory lexicons, with either high coverage and low precision or vice versa. However, the treatment of such dictionaries as forms of prior knowledge that can be incorporated in machine learning models is a relatively less explored topic; even lesser so in conjunction with semi-supervised models that attempt to utilize un244 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 244–252, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP labeled data. This is the focus of the current paper. Ou</context>
<context position="6189" citStr="Ng et al., 2006" startWordPosition="922" endWordPosition="925">epth survey of literature on sentiment analysis. In this section, we briskly cover related work to position our contributions appropriately in the sentiment analysis and machine learning literature. Methods focussing on the use and generation of dictionaries capturing the sentiment of words have ranged from manual approaches of developing domain-dependent lexicons (Das and Chen, 2001) to semi-automated approaches (Hu and Liu, 2004; Zhuang et al., 2006; Kim and Hovy, 2004), and even an almost fully automated approach (Turney, 2002). Most semi-automated approaches have met with limited success (Ng et al., 2006) and supervised learning models have tended to outperform dictionary-based classification schemes (Pang et al., 2002). A two-tier scheme (Pang and Lee, 2004) where sentences are first classified as subjective versus objective, and then applying the sentiment classifier on only the subjective sentences further improves performance. Results in these papers also suggest that using more sophisticated linguistic models, incorporating parts-of-speech and n-gram language models, do not improve over the simple unigram bag-of-words representation. In keeping with these findings, we also adopt a unigram</context>
</contexts>
<marker>Ng, Dasgupta, Arifin, 2006</marker>
<rawString>V. Ng, S. Dasgupta, and S. M. Niaz Arifin. 2006. Examining the role of linguistic knowledge sources in the automatic identification and classification of reviews. In COLING &amp; ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nocedal</author>
<author>S J Wright</author>
</authors>
<title>Numerical Optimization.</title>
<date>1999</date>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="16522" citStr="Nocedal and Wright, 1999" startWordPosition="2608" endWordPosition="2611">rgence to a local minima. This can be proved using arguments similar to (Ding et al., 2006). We outline the proof of correctness for updating F since the squared loss term that involves F is a new component in our models. Theorem 1 The above iterative algorithm converges. Theorem 2 At convergence, the solution satisfies the Karuch, Kuhn, Tucker optimality condition, i.e., the algorithm converges correctly to a local optima. Theorem 1 can be proved using the standard auxiliary function approach used in (Lee and Seung, 2001). Proof of Theorem 2. Following the theory of constrained optimization (Nocedal and Wright, 1999), Fik  Fik (8) 247 we minimize the following function L(F) = ||X −FSGT ||2+αTr[(F −F0)TC1(F −F0)] Note that the gradient of L is, = −2XGST + 2FSGT GST + 2αC1(F − F0). The KKT complementarity condition for the nonnegativity of Fik gives [−2XGST +FSGT GST + 2αC1(F − F0)]ikFik = 0. This is the fixed point relation that local minima for F must satisfy. Given an initial guess of F, the successive update of F using Eq.(8) will converge to a local minima. At convergence, we have Fik = Fik . (FFTXGST +αC1F)ik which is equivalent to the KKT condition of Eq.(10). The correctness of updating rules for G</context>
</contexts>
<marker>Nocedal, Wright, 1999</marker>
<rawString>J. Nocedal and S.J. Wright. 1999. Numerical Optimization. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="6346" citStr="Pang and Lee, 2004" startWordPosition="945" endWordPosition="948">nt analysis and machine learning literature. Methods focussing on the use and generation of dictionaries capturing the sentiment of words have ranged from manual approaches of developing domain-dependent lexicons (Das and Chen, 2001) to semi-automated approaches (Hu and Liu, 2004; Zhuang et al., 2006; Kim and Hovy, 2004), and even an almost fully automated approach (Turney, 2002). Most semi-automated approaches have met with limited success (Ng et al., 2006) and supervised learning models have tended to outperform dictionary-based classification schemes (Pang et al., 2002). A two-tier scheme (Pang and Lee, 2004) where sentences are first classified as subjective versus objective, and then applying the sentiment classifier on only the subjective sentences further improves performance. Results in these papers also suggest that using more sophisticated linguistic models, incorporating parts-of-speech and n-gram language models, do not improve over the simple unigram bag-of-words representation. In keeping with these findings, we also adopt a unigram text model. A subjectivity classification phase before our models are applied may further improve the results reported in this paper, but our focus is on dr</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>B. Pang and L. Lee. 2004. A sentimental education: sentiment analysis using subjectivity summarization based on minimum cuts. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval:</booktitle>
<volume>2</volume>
<pages>1--135</pages>
<contexts>
<context position="5561" citStr="Pang and Lee, 2008" startWordPosition="828" endWordPosition="831">fectiveness and generality of our approach. The rest of the paper is organized as follows. We begin by discussing related work in Section 2. Section 3 gives a quick background on Nonnegative Matrix Tri-factorization models. In Section 4, we present a constrained model and computational algorithm for incorporating lexical knowledge in sentiment analysis. In Section 5, we enhance this model by introducing document labels as additional constraints. Section 6 presents an empirical study on four datasets. Finally, Section 7 concludes this paper. 2 Related Work We point the reader to a recent book (Pang and Lee, 2008) for an in-depth survey of literature on sentiment analysis. In this section, we briskly cover related work to position our contributions appropriately in the sentiment analysis and machine learning literature. Methods focussing on the use and generation of dictionaries capturing the sentiment of words have ranged from manual approaches of developing domain-dependent lexicons (Das and Chen, 2001) to semi-automated approaches (Hu and Liu, 2004; Zhuang et al., 2006; Kim and Hovy, 2004), and even an almost fully automated approach (Turney, 2002). Most semi-automated approaches have met with limit</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>B. Pang and L. Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval: Vol. 2: No 12, pp 1-135 http://www.cs.cornell.edu/home/llee/opinionmining-sentiment-analysis-survey.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up? sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="3179" citStr="Pang et al., 2002" startWordPosition="468" endWordPosition="471">er, sentiment is often conveyed with subtle linguistic mechanisms such as the use of sarcasm and highly domain-specific contextual cues. This makes manual annotation of sentiment time consuming and error-prone, presenting a bottleneck in learning high quality models. Moreover, products and services of current focus, and associated community of bloggers with their idiosyncratic expressions, may rapidly evolve over time causing models to potentially lose performance and become stale. This motivates the problem of learning robust sentiment models from minimal supervision. In their seminal work, (Pang et al., 2002) demonstrated that supervised learning significantly outperformed a competing body of work where hand-crafted dictionaries are used to assign sentiment labels based on relative frequencies of positive and negative terms. As observed by (Ng et al., 2006), most semi-automated dictionary-based approaches yield unsatisfactory lexicons, with either high coverage and low precision or vice versa. However, the treatment of such dictionaries as forms of prior knowledge that can be incorporated in machine learning models is a relatively less explored topic; even lesser so in conjunction with semi-superv</context>
<context position="6306" citStr="Pang et al., 2002" startWordPosition="938" endWordPosition="941">tributions appropriately in the sentiment analysis and machine learning literature. Methods focussing on the use and generation of dictionaries capturing the sentiment of words have ranged from manual approaches of developing domain-dependent lexicons (Das and Chen, 2001) to semi-automated approaches (Hu and Liu, 2004; Zhuang et al., 2006; Kim and Hovy, 2004), and even an almost fully automated approach (Turney, 2002). Most semi-automated approaches have met with limited success (Ng et al., 2006) and supervised learning models have tended to outperform dictionary-based classification schemes (Pang et al., 2002). A two-tier scheme (Pang and Lee, 2004) where sentences are first classified as subjective versus objective, and then applying the sentiment classifier on only the subjective sentences further improves performance. Results in these papers also suggest that using more sophisticated linguistic models, incorporating parts-of-speech and n-gram language models, do not improve over the simple unigram bag-of-words representation. In keeping with these findings, we also adopt a unigram text model. A subjectivity classification phase before our models are applied may further improve the results report</context>
<context position="20030" citStr="Pang et al., 2002" startWordPosition="3192" endWordPosition="3195"> very efficiently and easily implemented. In particular, updating F,S,G each takes O(k2(m + n) + kz) time per iteration which scales linearly with the dimensions and density of the data matrix. Empirically, the number of iterations before practical convergence is usually very small (less than 100). Thus, computationally our approach scales to large datasets even though our experiments are run on relatively small-sized datasets. 6 Experiments 6.1 Datasets Description Four different datasets are used in our experiments. Movies Reviews: This is a popular dataset in sentiment analysis literature (Pang et al., 2002). It consists of 1000 positive and 1000 negative movie reviews drawn from the IMDB archive of the rec.arts.movies.reviews newsgroups. ∂L ∂F (XGST +αC1F0)ik 248 Lotus blogs: The data set is targeted at detecting sentiment around enterprise software, specifically pertaining to the IBM Lotus brand (Sindhwani and Melville, 2008). An unlabeled set of blog posts was created by randomly sampling 2000 posts from a universe of 14,258 blogs that discuss issues relevant to Lotus software. In addition to this unlabeled set, 145 posts were chosen for manual labeling. These posts came from 14 individual blo</context>
<context position="26603" citStr="Pang et al., 2002" startWordPosition="4230" endWordPosition="4233">he algorithm proposed in (Zhou et al., 2003) which conducts semi-supervised learning with local and global consistency (Consistency Method); (2) Zhu et al.’s harmonic Gaussian field method coupled with the Class Mass Normalization (HarmonicCMN) (Zhu et al., 2003); and (3) Green’s function learning algorithm (Green’s Function) proposed in (Ding et al., 2007). We also compare the results of SSMFLK with those of two supervised classification methods: Support Vector Machine (SVM) and Naive Bayes. Both of these methods have been widely used in sentiment analysis. In particular, the use of SVMs in (Pang et al., 2002) initially sparked interest in using machine learning methods for sentiment classification. Note that none of these competing methods utilizes lexical knowledge. The results are presented in Figure 5, Figure 6, Figure 7, and Figure 8. We note that our SSMFLK method either outperforms all other methods over the entire range of number of labeled documents (Movies, Political), or ultimately outpaces other methods (Lotus, Amazon) as a few document labels come in. Learning Domain-Specific Connotations In our first set of experiments, we incorporated the sentiment lexicon in our models and learnt th</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up? sentiment classification using machine learning techniques. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ramakrishnan</author>
<author>A Jadhav</author>
<author>A Joshi</author>
<author>S Chakrabarti</author>
<author>P Bhattacharyya</author>
</authors>
<title>Question answering via bayesian inference on lexical relations.</title>
<date>2003</date>
<booktitle>In ACL,</booktitle>
<pages>1--10</pages>
<contexts>
<context position="12873" citStr="Ramakrishnan et al., 2003" startWordPosition="1992" endWordPosition="1995"> (words) and columns (documents) of X. In the context of coclustering, these models return excellent empirical performance, see e.g., (Ding et al., 2006). Our goal now is to bias these models with constraints incorporating (a) labels of features (coming from a domain-independent sentiment lexicon), and (b) labels of documents for the purposes of domainspecific adaptation. These enhancements are addressed in Sections 4 and 5 respectively. 4 Incorporating Lexical Knowledge We used a sentiment lexicon generated by the IBM India Research Labs that was developed for other text mining applications (Ramakrishnan et al., 2003). It contains 2,968 words that have been human-labeled as expressing positive or negative sentiment. In total, there are 1,267 positive (e.g. “great”) and 1,701 negative (e.g., “bad”) unique 246 terms after stemming. We eliminated terms that were ambiguous and dependent on context, such as “dear” and “fine”. It should be noted, that this list was constructed without a specific domain in mind; which is further motivation for using training examples and unlabeled data to learn domain specific connotations. Lexical knowledge in the form of the polarity of terms in this lexicon can be introduced i</context>
</contexts>
<marker>Ramakrishnan, Jadhav, Joshi, Chakrabarti, Bhattacharyya, 2003</marker>
<rawString>G. Ramakrishnan, A. Jadhav, A. Joshi, S. Chakrabarti, and P. Bhattacharyya. 2003. Question answering via bayesian inference on lexical relations. In ACL, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sandler</author>
<author>J Blitzer</author>
<author>P Talukdar</author>
<author>L Ungar</author>
</authors>
<title>Regularized learning with networks of features.</title>
<date>2008</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="9965" citStr="Sandler et al., 2008" startWordPosition="1510" endWordPosition="1513">empirical studies, see e.g., (Ding et al., 2006). We also note the very recent work of (Sindhwani and Melville, 2008) which proposes a dualsupervision model for semi-supervised sentiment analysis. In this model, bipartite graph regularization is used to diffuse label information along both sides of the term-document matrix. Conceptually, their model implements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective) while our model is based on Non-negative Matrix Factorization. In another recent paper (Sandler et al., 2008), standard regularization models are constrained using graphs of word co-occurences. These are very recently proposed competing methodologies, and we have not been able to address empirical comparisons with them in this paper. Finally, recent efforts have also looked at transfer learning mechanisms for sentiment analysis, e.g., see (Blitzer et al., 2007). While our focus is on single-domain learning in this paper, we note that cross-domain variants of our model can also be orthogonally developed. 3 Background 3.1 Basic Matrix Factorization Model Our proposed models are based on non-negative ma</context>
</contexts>
<marker>Sandler, Blitzer, Talukdar, Ungar, 2008</marker>
<rawString>T. Sandler, J. Blitzer, P. Talukdar, and L. Ungar. 2008. Regularized learning with networks of features. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Schapire</author>
<author>M Rochery</author>
<author>M G Rahim</author>
<author>N Gupta</author>
</authors>
<title>Incorporating prior knowledge into boosting.</title>
<date>2002</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="8057" citStr="Schapire et al., 2002" startWordPosition="1207" endWordPosition="1210">ent and therefore may be considered as a negatively labeled feature). Empirical results in this paper demonstrate that simultaneously attempting both these goals in a single model leads to improvements over models that focus on a single goal. (Goldberg and Zhu, 2006) adapt semi-supervised graph-based methods for sentiment analysis but do not incorporate lexical prior knowledge in the form of labeled features. Most work in machine learning literature on utilizing labeled features has focused on using them to generate weakly labeled examples that are then used for standard supervised learning: (Schapire et al., 2002) propose one such framework for boosting logistic regression; (Wu and Srihari, 2004) build a modified SVM and (Liu et al., 2004) use a combination of clustering and EM based methods to instantiate similar frameworks. By contrast, we incorporate lexical knowledge directly as constraints on our matrix factorization model. In recent work, Druck et al. (Druck et al., 2008) constrain the predictions of a multinomial logistic regression model on unlabeled instances in a Generalized Expectation formulation for learning from labeled features. Unlike their approach which uses only unlabeled instances, </context>
</contexts>
<marker>Schapire, Rochery, Rahim, Gupta, 2002</marker>
<rawString>R.E. Schapire, M. Rochery, M.G. Rahim, and N. Gupta. 2002. Incorporating prior knowledge into boosting. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Sindhwani</author>
<author>P Melville</author>
</authors>
<title>Documentword co-regularization for semi-supervised sentiment analysis.</title>
<date>2008</date>
<booktitle>In Proceedings ofIEEE ICDM.</booktitle>
<contexts>
<context position="9461" citStr="Sindhwani and Melville, 2008" startWordPosition="1434" endWordPosition="1438">y related to the models proposed recently in (Li et al., 2008; Sindhwani et al., 2008). Though, their techniques for proving algorithm convergence and correctness can be readily adapted for our models, (Li et al., 2008) do not incorporate dual supervision as we do. On the other hand, while (Sindhwani et al., 2008) do incorporate dual supervision in a non-linear kernelbased setting, they do not enforce non-negativity or orthogonality – aspects of matrix factorization models that have shown benefits in prior empirical studies, see e.g., (Ding et al., 2006). We also note the very recent work of (Sindhwani and Melville, 2008) which proposes a dualsupervision model for semi-supervised sentiment analysis. In this model, bipartite graph regularization is used to diffuse label information along both sides of the term-document matrix. Conceptually, their model implements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective) while our model is based on Non-negative Matrix Factorization. In another recent paper (Sandler et al., 2008), standard regularization models are constrained using graphs of word co-occurences. These are v</context>
<context position="20356" citStr="Sindhwani and Melville, 2008" startWordPosition="3242" endWordPosition="3246">onally our approach scales to large datasets even though our experiments are run on relatively small-sized datasets. 6 Experiments 6.1 Datasets Description Four different datasets are used in our experiments. Movies Reviews: This is a popular dataset in sentiment analysis literature (Pang et al., 2002). It consists of 1000 positive and 1000 negative movie reviews drawn from the IMDB archive of the rec.arts.movies.reviews newsgroups. ∂L ∂F (XGST +αC1F0)ik 248 Lotus blogs: The data set is targeted at detecting sentiment around enterprise software, specifically pertaining to the IBM Lotus brand (Sindhwani and Melville, 2008). An unlabeled set of blog posts was created by randomly sampling 2000 posts from a universe of 14,258 blogs that discuss issues relevant to Lotus software. In addition to this unlabeled set, 145 posts were chosen for manual labeling. These posts came from 14 individual blogs, 4 of which are actively posting negative content on the brand, with the rest tending to write more positive or neutral posts. The data was collected by downloading the latest posts from each blogger’s RSS feeds, or accessing the blog’s archives. Manual labeling resulted in 34 positive and 111 negative examples. Political</context>
</contexts>
<marker>Sindhwani, Melville, 2008</marker>
<rawString>V. Sindhwani and P. Melville. 2008. Documentword co-regularization for semi-supervised sentiment analysis. In Proceedings ofIEEE ICDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Sindhwani</author>
<author>J Hu</author>
<author>A Mojsilovic</author>
</authors>
<title>Regularized co-clustering with dual supervision.</title>
<date>2008</date>
<booktitle>In Proceedings ofNIPS.</booktitle>
<contexts>
<context position="8918" citStr="Sindhwani et al., 2008" startWordPosition="1346" endWordPosition="1349">porate lexical knowledge directly as constraints on our matrix factorization model. In recent work, Druck et al. (Druck et al., 2008) constrain the predictions of a multinomial logistic regression model on unlabeled instances in a Generalized Expectation formulation for learning from labeled features. Unlike their approach which uses only unlabeled instances, our method uses both labeled and unlabeled documents in conjunction with labeled and 245 unlabeled words. The matrix tri-factorization models explored in this paper are closely related to the models proposed recently in (Li et al., 2008; Sindhwani et al., 2008). Though, their techniques for proving algorithm convergence and correctness can be readily adapted for our models, (Li et al., 2008) do not incorporate dual supervision as we do. On the other hand, while (Sindhwani et al., 2008) do incorporate dual supervision in a non-linear kernelbased setting, they do not enforce non-negativity or orthogonality – aspects of matrix factorization models that have shown benefits in prior empirical studies, see e.g., (Ding et al., 2006). We also note the very recent work of (Sindhwani and Melville, 2008) which proposes a dualsupervision model for semi-supervis</context>
</contexts>
<marker>Sindhwani, Hu, Mojsilovic, 2008</marker>
<rawString>V. Sindhwani, J. Hu, and A. Mojsilovic. 2008. Regularized co-clustering with dual supervision. In Proceedings ofNIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>417--424</pages>
<contexts>
<context position="6109" citStr="Turney, 2002" startWordPosition="912" endWordPosition="913">ed Work We point the reader to a recent book (Pang and Lee, 2008) for an in-depth survey of literature on sentiment analysis. In this section, we briskly cover related work to position our contributions appropriately in the sentiment analysis and machine learning literature. Methods focussing on the use and generation of dictionaries capturing the sentiment of words have ranged from manual approaches of developing domain-dependent lexicons (Das and Chen, 2001) to semi-automated approaches (Hu and Liu, 2004; Zhuang et al., 2006; Kim and Hovy, 2004), and even an almost fully automated approach (Turney, 2002). Most semi-automated approaches have met with limited success (Ng et al., 2006) and supervised learning models have tended to outperform dictionary-based classification schemes (Pang et al., 2002). A two-tier scheme (Pang and Lee, 2004) where sentences are first classified as subjective versus objective, and then applying the sentiment classifier on only the subjective sentences further improves performance. Results in these papers also suggest that using more sophisticated linguistic models, incorporating parts-of-speech and n-gram language models, do not improve over the simple unigram bag-</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>P. Turney. 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews. Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 417–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wu</author>
<author>R Srihari</author>
</authors>
<title>Incorporating prior knowledge with weighted margin support vector machines.</title>
<date>2004</date>
<booktitle>In KDD.</booktitle>
<contexts>
<context position="8141" citStr="Wu and Srihari, 2004" startWordPosition="1219" endWordPosition="1222">ts in this paper demonstrate that simultaneously attempting both these goals in a single model leads to improvements over models that focus on a single goal. (Goldberg and Zhu, 2006) adapt semi-supervised graph-based methods for sentiment analysis but do not incorporate lexical prior knowledge in the form of labeled features. Most work in machine learning literature on utilizing labeled features has focused on using them to generate weakly labeled examples that are then used for standard supervised learning: (Schapire et al., 2002) propose one such framework for boosting logistic regression; (Wu and Srihari, 2004) build a modified SVM and (Liu et al., 2004) use a combination of clustering and EM based methods to instantiate similar frameworks. By contrast, we incorporate lexical knowledge directly as constraints on our matrix factorization model. In recent work, Druck et al. (Druck et al., 2008) constrain the predictions of a multinomial logistic regression model on unlabeled instances in a Generalized Expectation formulation for learning from labeled features. Unlike their approach which uses only unlabeled instances, our method uses both labeled and unlabeled documents in conjunction with labeled and</context>
</contexts>
<marker>Wu, Srihari, 2004</marker>
<rawString>X. Wu and R. Srihari. 2004. Incorporating prior knowledge with weighted margin support vector machines. In KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zha</author>
<author>X He</author>
<author>C Ding</author>
<author>M Gu</author>
<author>H D Simon</author>
</authors>
<title>Bipartite graph partitioning and data clustering.</title>
<date>2001</date>
<booktitle>Proceedings ofACM CIKM.</booktitle>
<contexts>
<context position="9825" citStr="Zha et al., 2001" startWordPosition="1488" endWordPosition="1491">setting, they do not enforce non-negativity or orthogonality – aspects of matrix factorization models that have shown benefits in prior empirical studies, see e.g., (Ding et al., 2006). We also note the very recent work of (Sindhwani and Melville, 2008) which proposes a dualsupervision model for semi-supervised sentiment analysis. In this model, bipartite graph regularization is used to diffuse label information along both sides of the term-document matrix. Conceptually, their model implements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective) while our model is based on Non-negative Matrix Factorization. In another recent paper (Sandler et al., 2008), standard regularization models are constrained using graphs of word co-occurences. These are very recently proposed competing methodologies, and we have not been able to address empirical comparisons with them in this paper. Finally, recent efforts have also looked at transfer learning mechanisms for sentiment analysis, e.g., see (Blitzer et al., 2007). While our focus is on single-domain learning in this paper, we note that cross-domain variants of our </context>
</contexts>
<marker>Zha, He, Ding, Gu, Simon, 2001</marker>
<rawString>H. Zha, X. He, C. Ding, M. Gu, and H.D. Simon. 2001. Bipartite graph partitioning and data clustering. Proceedings ofACM CIKM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Zhou</author>
<author>O Bousquet</author>
<author>T N Lal</author>
<author>J Weston</author>
<author>B Scholkopf</author>
</authors>
<title>Learning with local and global consistency.</title>
<date>2003</date>
<booktitle>In Proceedings ofNIPS.</booktitle>
<contexts>
<context position="26029" citStr="Zhou et al., 2003" startWordPosition="4142" endWordPosition="4145">ary Figure 3: Accuracy results on Lotus dataset with increasing vocabulary size Fraction of Original Vocabulary Figure 4: Accuracy results on Amazon dataset with increasing vocabulary size 6.3 Sentiment Analysis with Dual Supervision We now assume that together with labeled features from the sentiment lexicon, we also have access to a few labeled documents. The natural question is whether the presence of lexical constraints leads to better semi-supervised models. In this section, we compare our method (SSMFLK) with the following three semi-supervised approaches: (1) The algorithm proposed in (Zhou et al., 2003) which conducts semi-supervised learning with local and global consistency (Consistency Method); (2) Zhu et al.’s harmonic Gaussian field method coupled with the Class Mass Normalization (HarmonicCMN) (Zhu et al., 2003); and (3) Green’s function learning algorithm (Green’s Function) proposed in (Ding et al., 2007). We also compare the results of SSMFLK with those of two supervised classification methods: Support Vector Machine (SVM) and Naive Bayes. Both of these methods have been widely used in sentiment analysis. In particular, the use of SVMs in (Pang et al., 2002) initially sparked interes</context>
</contexts>
<marker>Zhou, Bousquet, Lal, Weston, Scholkopf, 2003</marker>
<rawString>D. Zhou, O. Bousquet, T.N. Lal, J. Weston, and B. Scholkopf. 2003. Learning with local and global consistency. In Proceedings ofNIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>Z Ghahramani</author>
<author>J Lafferty</author>
</authors>
<title>Semisupervised learning using gaussian fields and harmonic functions.</title>
<date>2003</date>
<booktitle>In Proceedings ofICML.</booktitle>
<contexts>
<context position="26248" citStr="Zhu et al., 2003" startWordPosition="4173" endWordPosition="4176">l Supervision We now assume that together with labeled features from the sentiment lexicon, we also have access to a few labeled documents. The natural question is whether the presence of lexical constraints leads to better semi-supervised models. In this section, we compare our method (SSMFLK) with the following three semi-supervised approaches: (1) The algorithm proposed in (Zhou et al., 2003) which conducts semi-supervised learning with local and global consistency (Consistency Method); (2) Zhu et al.’s harmonic Gaussian field method coupled with the Class Mass Normalization (HarmonicCMN) (Zhu et al., 2003); and (3) Green’s function learning algorithm (Green’s Function) proposed in (Ding et al., 2007). We also compare the results of SSMFLK with those of two supervised classification methods: Support Vector Machine (SVM) and Naive Bayes. Both of these methods have been widely used in sentiment analysis. In particular, the use of SVMs in (Pang et al., 2002) initially sparked interest in using machine learning methods for sentiment classification. Note that none of these competing methods utilizes lexical knowledge. The results are presented in Figure 5, Figure 6, Figure 7, and Figure 8. We note th</context>
</contexts>
<marker>Zhu, Ghahramani, Lafferty, 2003</marker>
<rawString>X. Zhu, Z. Ghahramani, and J. Lafferty. 2003. Semisupervised learning using gaussian fields and harmonic functions. In Proceedings ofICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Zhuang</author>
<author>F Jing</author>
<author>X Zhu</author>
</authors>
<title>Movie review mining and summarization.</title>
<date>2006</date>
<booktitle>In CIKM,</booktitle>
<pages>43--50</pages>
<contexts>
<context position="6028" citStr="Zhuang et al., 2006" startWordPosition="897" endWordPosition="900">s an empirical study on four datasets. Finally, Section 7 concludes this paper. 2 Related Work We point the reader to a recent book (Pang and Lee, 2008) for an in-depth survey of literature on sentiment analysis. In this section, we briskly cover related work to position our contributions appropriately in the sentiment analysis and machine learning literature. Methods focussing on the use and generation of dictionaries capturing the sentiment of words have ranged from manual approaches of developing domain-dependent lexicons (Das and Chen, 2001) to semi-automated approaches (Hu and Liu, 2004; Zhuang et al., 2006; Kim and Hovy, 2004), and even an almost fully automated approach (Turney, 2002). Most semi-automated approaches have met with limited success (Ng et al., 2006) and supervised learning models have tended to outperform dictionary-based classification schemes (Pang et al., 2002). A two-tier scheme (Pang and Lee, 2004) where sentences are first classified as subjective versus objective, and then applying the sentiment classifier on only the subjective sentences further improves performance. Results in these papers also suggest that using more sophisticated linguistic models, incorporating parts-</context>
</contexts>
<marker>Zhuang, Jing, Zhu, 2006</marker>
<rawString>L. Zhuang, F. Jing, and X. Zhu. 2006. Movie review mining and summarization. In CIKM, pages 43–50.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>