<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.996214">
Aid is Out There:
Looking for Help from Tweets during a Large Scale Disaster
</title>
<author confidence="0.8659475">
Istv´an Varga† Motoki Sano† Kentaro Torisawa† Chikara Hashimoto†
Kiyonori Ohtake† Takao Kawai§ Jong-Hoon Oh† Stijn De Saeger††Information Analysis Laboratory,
</author>
<affiliation confidence="0.989257">
National Institute of Information and Communications Technology (NICT), Japan
</affiliation>
<email confidence="0.933736">
{istvan, msano, torisawa, ch, kiyonori.ohtake, rovellia, stijn}@nict.go.jp
</email>
<affiliation confidence="0.467374">
§Knowledge Discovery Research Laboratories, NEC Corporation, Japan
</affiliation>
<email confidence="0.982333">
t-kawai@bx.jp.nec.com
</email>
<sectionHeader confidence="0.993572" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99980585">
The 2011 Great East Japan Earthquake
caused a wide range of problems, and as
countermeasures, many aid activities were
carried out. Many of these problems and
aid activities were reported via Twitter.
However, most problem reports and corre-
sponding aid messages were not success-
fully exchanged between victims and lo-
cal governments or humanitarian organi-
zations, overwhelmed by the vast amount
of information. As a result, victims could
not receive necessary aid and humanitar-
ian organizations wasted resources on re-
dundant efforts. In this paper, we propose
a method for discovering matches between
problem reports and aid messages. Our
system contributes to problem-solving in
a large scale disaster situation by facilitat-
ing communication between victims and
humanitarian organizations.
</bodyText>
<sectionHeader confidence="0.998985" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.970010433962264">
The 2011 Great East Japan Earthquake in March
11, 2011 killed 15,883 people and destroyed over
260,000 households (National Police Agency of
Japan, 2013). Accustomed way of living suddenly
became unmanageable and people found them-
selves in extreme conditions for months.
Just after the disaster, many people used Twitter
for posting problem reports and aid messages as
it functioned while most communication channels
suffered disruptions (Winn, 2011; Acar and Mu-
raki, 2011; Sano et al., 2012). Examples of such
problem reports and aid messages, translated from
Japanese tweets, are given below (P1, A1).
P1 My friend said infant formula is sold out. If
somebody knows shops in Sendai-city where
they still have it in stock, please let us know.
A1 At Jusco supermarket in Sendai, you can still
buy water and infant formula.
If A1 would have been forwarded to the sender
of P1, it could have helped since it would help
the “friend” to obtain infant formula. But in re-
ality, the majority of such reports/messages, es-
pecially unforeseen ones went unnoticed amongst
the mass of information (Ohtake et al., 2013). In
addition, there were cases where many humani-
tarian organizations responded to the same prob-
lems and wasted precious resources. For instance,
many volunteers responded to problems which
were heavily reported by public media, leading
to oversupply (Saijo, 2012). Such waste of re-
sources could have been avoided if the organiza-
tions would have successfully shared the aid mes-
sages for the same problems.
Such observations motivated this work. We de-
veloped methods for recognizing problem reports
and aid messages in tweets and finding proper
matches between them. By browsing the discov-
ered matches, victims can be assisted to over-
come their problems, and humanitarian organiza-
tions can avoid redundant relief efforts. We define
problem reports, aid messages and their successful
matches as follows.
Problem report: A tweet that informs about the
possibility or emergence of a problem that re-
quires a treatment or countermeasure.
Aid message: A tweet that (1) informs about sit-
uations or actions that can be a remedy or so-
lution for a problem, or (2) informs that the
problem is solved or is about to be solved.
Problem-aid tweet match: A tweet pair is a
problem-aid tweet match (1) if the aid mes-
sage informs how to overcome the problem,
(2) if the aid message informs about the set-
</bodyText>
<page confidence="0.961905">
1619
</page>
<note confidence="0.913527">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1619–1629,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.949636816901408">
tlement of the problem, or (3) if the aid mes-
sage provides information which contributes
to the settlement of the problem.
In this work we excluded direct requests, such as
“Send us food!”, from problem reports. This is be-
cause it is relatively easy to recognize such direct
requests by checking mood types (i.e., imperative)
and their behavior is quite different from prob-
lem reports like “People in Sendai are starving”.
Problem reports in this work do not directly state
which actions are required, only implying the ne-
cessity of a countermeasure through claiming the
existence of problems.
An underlying assumption of our method is that
we can find a noun-predicate dependency relation
that works as an indicator of problems and aids in
problem reports and aid messages, which we refer
to as problem nucleus and aid nucleus.&apos; An exam-
ple of problem nucleus is “infant formula is sold
out” in P1, and that of aid nucleus is “(can) buy
infant formula” in A1. Many problem-aid tweet
matches can be recognized through problem and
aid nuclei pairs.
We also assume that if the problem and aid nu-
clei match, they share the same noun. Then, the
semantics of predicates in the nuclei is the main
factor that decides whether the nuclei constitute
a match. We introduce a semantic classification
of predicates according to the framework of ex-
citation polarities proposed in Hashimoto et al.
(2012). Our hypothesis is that excitation polarities
along with trouble expressions can characterize
problem reports, aid messages and their matches.
We developed a supervised method encoding such
information into its features.
An evident alternative to this approach is to use
sentiment analysis (Mandel et al., 2012; Tsagkali-
dou et al., 2011) assuming that problem reports
should include something ‘bad’ while aid mes-
sages describe something ‘good’. However, we
will show that this does not work well in our exper-
iments. We think this is due to mismatch between
the concepts of problem/aid and sentiment polar-
ity. Note that previous work on ‘demand’ recogni-
tion also found similar tendencies (Kanayama and
Nasukawa, 2008).
Another issue in this task is, of course, the
context surrounding problem/aid nuclei. The fol-
&apos;We found that out of 500 random tweets only 4.5% of
problem reports and 9.1% of aid messages did not contain
any problem report/aid message nuclei.
lowing (imaginary) tweets exemplify the problems
caused by contexts.
FP1 I do not believe infant formula is sold out
in Sendai.
FA1 At Jusco supermarket in Iwaki, you can still
buy infant formula.
The problem nuclei of FP1 and P1 are the same
but FP1 is not a problem report because of the ex-
pression “I do not believe”. The aid nuclei of FA1
and A1 are the same but FA1 does not constitute
a proper match with P1 because FA1 and P1 re-
fer to different cities, “Iwaki” and “Sendai”. In
this work, the problems concerning the modality
and other semantic modifications to problem/aid
nuclei by context are dealt with by the introduc-
tion of features representing the text surrounding
the nuclei in machine learning. As for the loca-
tion problem, we apply a location recognizer to all
tweets and restrict the matching candidates to the
tweet pairs referring to the same location.
</bodyText>
<sectionHeader confidence="0.986977" genericHeader="introduction">
2 Approach
</sectionHeader>
<figureCaption confidence="0.999112">
Figure 1: Problem-aid matching system overview.
</figureCaption>
<bodyText confidence="0.9998106">
We developed machine learning based systems
to recognize problem reports, aid messages and
problem-aid tweet matches. Figure 1 illustrates
the whole system. First, location names in tweets
are identified by matching tweets against our loca-
tion dictionary, described in Section 3. Then, each
tweet is paired with each dependency relation in
the tweet, which is a candidate of problem/aid nu-
clei and given to the problem report and aid mes-
sage recognizers. A tweet-nucleus-candidate pair
judged as problem report is combined with another
tweet-nucleus-candidate pair recognized as an aid
message if the two nuclei share the same noun and
the tweets share the same location name, and given
to the problem-aid match recognizer.
</bodyText>
<figure confidence="0.997863826086957">
!&amp;quot;#$%&amp;&apos; &amp;quot;&amp;!#&amp;quot;) &amp;quot;&amp;*#+,-.&amp;&amp;quot;
tweets
problem nucleus
problem report
morphological
analysis and
dependency
parsing
location
recogniaer
/-0 &apos;&amp;11/+&amp; &amp;quot;&amp;*#+,-.&amp;&amp;quot;
aid message
aid nucleus
dependency
relation
tweet
!&amp;quot;#$%&amp;&apos;2/-0 &apos;/)*4 &amp;quot;&amp;*#+,-.&amp;&amp;quot;
problem and aid noun are the same; same geographical location
problem nucleus
problem report
!&amp;quot;#$%&amp;&apos;2/-0 )3&amp;&amp;) &apos;/)*4
aid message
aid nucleus
</figure>
<page confidence="0.981138">
1620
</page>
<bodyText confidence="0.998985">
In the following, problem and aid nuclei are
denoted by a noun-template pair. A template is
composed of a predicate and its argument posi-
tion. For instance, “water supply stopped” in P2
is a problem nucleus, “water supply recovered” in
A2 is an aid nucleus and they are denoted by the
noun-template pairs (water supply, X stopped) and
(water supply, X recovered).
</bodyText>
<footnote confidence="0.8745405">
P2 In Sendai city, water supply stopped.
A2 In Sendai city, water supply recovered.
</footnote>
<bodyText confidence="0.9997652">
Roughly speaking, we regard the tasks of prob-
lem report recognition and aid message recogni-
tion as the tasks of finding proper problem/aid
nuclei in tweets and our method performs these
tasks based on the semantic properties of nouns
and templates in problem/aid nucleus candidates
and their surrounding contexts.
The basic intuition behind this approach can
be explained using excitation polarity proposed in
Hashimoto et al. (2012). Excitation polarity differ-
entiates templates into ‘excitatory’ or ‘inhibitory’
with regard to the main function or effect of en-
tities referred to by their argument noun. While
excitatory templates (e.g., cause X, buy X, suf-
fer from X) entail that the main function or ef-
fect is activated or enhanced, inhibitory templates
(e.g., ruin X, prevent X, X runs out) entail that
the main function or effect is deactivated or sup-
pressed. The templates that do not fit into the
above categorization are classified as ‘neutral’.
We observed that problem reports in general
included either of (A) a dependency relation be-
tween a noun referring to some trouble and an
excitatory template or (B) a dependency rela-
tion between a noun not referring to any trouble
and an inhibitory template. Examples of (A) in-
clude (carbon monoxide poisoning, suffer from
X), (false rumor, spread X). They refer to events
that activate troubles. On the other hand, (B) is
exemplified by (school, X is collapsed), (battery,
X runs out), which imply that some non-trouble
objects such as resources, appliances and facilities
are dysfunctional. We assume that if we can find
such dependency relations in tweets, the tweets are
likely to be problem reports.
Contrary, a tweet is more likely to be an aid
message when it includes either (C) a dependency
relation between a noun referring to some trouble
and an inhibitory template or (D) a dependency re-
lation between a noun not referring to any trou-
</bodyText>
<table confidence="0.402383666666667">
trouble non-trouble
excitatory (A) problem nucleus (D) aid nucleus
inhibitory (C) aid nucleus (B) problem nucleus
</table>
<tableCaption confidence="0.993432">
Table 1: Problem/aid-excitation matrix.
</tableCaption>
<bodyText confidence="0.942278511111111">
ble and an excitatory template. Examples of (C)
are (flu, X was eradicated (in some shelter)) and
(debris, remove X). They represent the dysfunc-
tion of troubles and can mean the solution or the
settlement of troubles. On the other hand, exam-
ples of (D) include (school, X re-build) and (baby
formula, buy X). They entail that some resources
function properly or become available. These for-
mulations are summarized in Table 1.
As an interesting consequence of such a view
on problem/aid nucleus, we can say the following
regarding problem-aid tweet matchings: when a
problem nucleus and an aid nucleus are an ade-
quate match, the excitation polarities of their tem-
plates are opposite. Consider the following tweets.
P3 Some people were going back to Iwaki, but the
water system has not come back yet. It’s ter-
rible that bath is unusable.
A3 We open the bath for the public, located on
the 2F of Iwaki Kuhon temple. If you’re stay-
ing at a relief shelter and would like to take a
bath, you can use it.
“Bath is unusable” in P3 is a problem nucleus
while “open the bath” in A3 is an aid nucleus.
Since the problem reported in P3 can be solved
with A3, they are a successful match. The in-
hibitory template “X is unusable” indicates that
the function of “bath”, a non-trouble expression,
is suppressed. The excitatory template “open X”
indicates that the function of “bath” is activated.
The same holds when we consider the noun re-
ferring to troubles like “flu”. The polarity of the
template in a problem nucleus should be excita-
tory like “flu is raging” while that of an aid nucleus
should be inhibitory like (flu, X was eradicated).
These examples keep the constraint that the prob-
lem and aid nucleus should have opposite polari-
ties when they constitute a match.
Note that the formulations of problem report,
aid message and their matches or the excitation
matrix (Table 1) were not presented to our anno-
tators and our test/training data may contain data
that contradict with the formulations. These for-
mulations constitute the hypothesis to be validated
in this work.
</bodyText>
<page confidence="0.950341">
1621
</page>
<bodyText confidence="0.999986761904762">
An important point to be stressed here is that
there are problem-aid tweet matches that do not
fit into our formulations. For instance, we as-
sume that the problem nucleus and aid nucleus in
a proper match share the same noun. However,
tweet pairs such as “There are many injured people
in Sendai city” and “We are sending ambulances
to Sendai” can constitute a proper match, but there
is no proper problem-aid nuclei pair that share the
same noun in these tweets. (We can find the de-
pendency relations sharing “Sendai” but they do
not express anything about the contents of prob-
lem and aid.) The point is that the tweet pairs can
be judged because people know ambulances can
be a countermeasure to injured people as world
knowledge. Introducing such world knowledge is
beyond the scope of this current study.
Also, we exclude direct requests from problem
reports. As mentioned in the introduction, identi-
fying direct requests is relatively easy, hence we
excluded them from our target.
</bodyText>
<sectionHeader confidence="0.930953" genericHeader="method">
3 Problem Report and Aid Message
Recognizers
</sectionHeader>
<bodyText confidence="0.634529325">
We recognize problem reports and aid messages in
given tweets using a supervised classifier, SVMs
with linear kernel, which worked best in our pre-
liminary experiments. The feature set given to
the SVMs are summarized in the top part of Ta-
ble 2. Note that we used a common feature
set for both the problem report recognizer and
aid message recognizer and that it is categorized
into several types: features concerning trouble
expressions (TR), excitation polarity (EX), their
combination (TREX1) and word sentiment polar-
ity (WSP), features expressing morphological and
syntactic structures of nuclei and their context sur-
rounding problem/aid nuclei (MSA), features con-
cerning semantic word classes (SWC) appearing
in nuclei and their context, request phrases, such
as “Please help us”, appearing in tweets (REQ),
and geographical locations in tweets recognized
by our location recognizer (GL). MSA is used to
express the modality of nuclei and other contex-
tual information surrounding nuclei. REQ was in-
troduced based on our observation that if there are
some requests in tweets, problem nuclei tend to
appear as justification for the requests.
We also attempted to represent nucleus template
IDs, noun IDs and their combinations directly in
our feature set to capture typical templates fre-
TR Whether the nucleus noun is a trouble/non-trouble expression.
EX1 The excitation polarity and the value of the excitation score of the
nucleus template.
TREX1 All possible combinations of trouble/non-trouble of TR and exci-
tation polarities of EX1.
WSP1 Whether the nucleus noun is positive/negative/not in the Word Sen-
timent Polarity (WSP) dictionary.
WSP2 Whether the nucleus template is positive/negative/not in the WSP
dictionary.
WSP3 Whether the nucleus template is followed by a positive/negative
word within the tweet.
MSA1 Morpheme n-grams, syntactic dependency n-grams in the tweet
and morpheme n-grams before and after the nucleus template.
(1 &lt; n &lt; 3)
MSA2 Character n-grams of the nucleus template to capture conjugation
and modality variations. (1 &lt; n &lt; 3)
MSA3 Morpheme and part-of-speech n-grams within the bunsetsu con-
taining the nucleus template to capture conjugation and modality
variations. (1 &lt; n &lt; 3) (A bunsetsu is a syntactic constituent
composed of a content word and several function words, the small-
est unit of syntactic analysis in Japanese.)
MSA4 The part-of-speech of the nucleus template’s head to capture
modality variations outside the nucleus template’s bunsetsu.
MSA5 The number of bunsetsu between the nucleus noun and the nucleus
template. We found that a long distance between the noun and the
template suggests parsing errors.
MSA6 Re-occurrence of the nucleus noun’s postpositional particle be-
tween the nucleus noun and the nucleus template. We found
that the re-occurrence of the same postpositional particle within
a clause suggests parsing errors.
SWC1 The semantic class n-grams in the tweet.
SWC2 The semantic class(es) of the nucleus noun.
REQ Presence of a request phrase in the tweet, identified from within
426 manually collected request phrases.
GL Geographical locations in the tweet identified using our location
recognizer. Existence/non-existence of locations in tweets are also
encoded.
EX2 Whether the problem and aid nucleus templates have the same or
opposite excitation polarities.
EX3 Product of the values of the excitation scores for the problem and
the aid nucleus template.
TREX2 All possible combinations of trouble/non-trouble of TR, excitation
polarity EX1 of the problem nucleus template and excitation po-
larity EX1 of the aid nucleus template.
SIM1 Common semantic word classes of the problem report and aid mes-
sage.
SIM2 Whether there are common nouns modifying the common nucleus
noun or not in the problem report and aid message.
SIM3 Whether the words in the same word class modify the common
nucleus noun or not in the problem report and aid message.
SIM4 The semantic similarity score between the problem nucleus tem-
plate and the aid nucleus template.
CTP Whether the problem nucleus template and the aid nucleus tem-
</bodyText>
<table confidence="0.879133714285714">
plate are in contradiction relation dictionary or not.
SSR1 Problem report recognizer’s SVM score of problem nucleus tem-
plate.
SSR2 Problem report recognizer’s SVM score of aid nucleus template.
SSR3 Aid message recognizer’s SVM score of the problem nucleus tem-
plate.
SSR4 Aid message recognizer’s SVM score of the aid nucleus template.
</table>
<tableCaption confidence="0.926577">
Table 2: Features used with the problem re-
</tableCaption>
<bodyText confidence="0.998346357142857">
port recognizer and the aid message recognizer
(above); additional features used in training the
problem-aid match recognizer (below).
quently appearing in problem and aid nuclei, but
since there was no improvement we omit them.
The other feature types need some non-trivial
dictionaries. In the following, we explain how we
created the dictionaries for each feature type along
with the motivation behind their introduction.
Trouble Expressions (TR) As mentioned previ-
ously, trouble expressions work as good evidence
for recognizing problem reports and aid messages.
The TR feature indicates whether the noun in the
problem/aid nucleus candidate is a trouble ex-
</bodyText>
<page confidence="0.966959">
1622
</page>
<bodyText confidence="0.998911428571429">
pression or not. For this purpose, we created
a list of trouble expressions following the semi-
supervised procedure presented in De Saeger et al.
(2008). After manual validation of the list, we ob-
tained 20,249 expressions referring to some trou-
bles, such as “tsunami” and “flu”. The value of the
TR feature is determined by checking whether the
nucleus noun is contained in the list.
Excitation Polarities (EX) The excitation po-
larities are also important in recognizing problem
reports and aid messages as mentioned before. For
constructing the dictionary for excitation polarities
of templates, we applied the bootstrapping proce-
dure in Hashimoto et al. (2012) to 600 million Web
pages. Hashimoto’s method provides the value of
the excitation score in [−1, 1] for each template
indicating the polarities and their strength. Posi-
tive value indicates excitatory, negative value in-
hibitory and small absolute value neutral. After
manual checking of the results by the majority
vote of three human annotators (other than the au-
thors), we limited the templates to the ones that
have score values consistent with the majority vote
of the annotators, obtaining a dictionary consisting
of 7,848 excitatory, 836 inhibitory and 7,230 neu-
tral templates. The Fleiss’ (1971) kappa-score was
0.48 (moderate agreement). We used the excita-
tion score values as feature values. Excitation has
already been used in many works, such as causal-
ity and contradiction extraction (Hashimoto et al.,
2012) or Why-QA (Oh et al., 2013).
Word Sentiment Polarity (WSP) As we sug-
gested before, full-fledged sentiment analysis to
recognize the expressions, including clauses and
phrases, that refer to something good or bad was
not effective in our task. However, the sentiment
polarity, assigned to single words turned out to
be effective. To identify the sentiment polarity
of words, we employed the word sentiment polar-
ity dictionary used with a sentiment analysis tool
for Japanese, the Opinion Extraction Tool soft-
ware2, which is an implementation of Nakagawa
et al. (2010). The dictionary includes 9,030 posi-
tive and 27,951 negative words. Note that we used
the Opinion Extraction Tool in the experiments to
check the effectiveness of the full-fledged senti-
ment analysis in this task.
Semantic Word Class (SWC) We assume that
nouns in the same semantic class behave simi-
</bodyText>
<footnote confidence="0.966415">
2Provided at the ALAGIN Forum (http://www.alagin.jp/).
</footnote>
<bodyText confidence="0.999855043478261">
larly in crisis situations. For example, if “infec-
tion” appears in a problem report, the tweets in-
cluding “pulmonary embolism” are also likely to
be problem reports. Semantic word class features
are used to capture such tendencies. We applied
an EM-style word clustering algorithm in Kazama
and Torisawa (2008) to 600 million Web pages and
clustered 1 million nouns into 500 classes. This
algorithm has been used in many works, such as
relation extraction (De Saeger et al., 2011) and
Why-QA (Oh et al., 2012), and can generate vari-
ous kinds of semantically clean word classes, such
as foods, disease names, and natural disasters. We
used the word classes in tweets as features.3
Geographical Locations (GL) Our location
recognizer matches tweets against our loca-
tion dictionary. Location names and their
existence/non-existence in tweets constitute evi-
dence, thus we encoded such information into our
features. The location dictionary was created from
the Japan Post code data4 and Wikipedia, contain-
ing 2.7 million location names including cities,
schools and other facilities (Kazama et al., 2013).
</bodyText>
<sectionHeader confidence="0.983193" genericHeader="method">
4 Problem-Aid Match Recognizer
</sectionHeader>
<bodyText confidence="0.999803333333333">
After problem report and aid message recogni-
tion, the positive outputs of the respective classi-
fiers are used as input in this step. The problem-
aid match recognizer classifies an aid message-
nucleus pair together with the problem report-
nucleus pair employing SVMs with linear ker-
nel, which performed best in this task again. The
problem-aid match recognizer uses all the features
used in the problem report recognizer and the aid
message recognizer along with additional features
regarding: excitation polarity (EX) and trouble
expressions (TR), distributional similarity (SIM),
contradiction (CTP) and SVM-scores of the prob-
lem report and aid message recognizers (SSR).
Here also we attempted to capture typical or fre-
quent matches of nuclei using template and noun
IDs and their combinations, but we did not observe
any improvement so we omit them from the fea-
ture set. The bottom part of Table 2 summarizes
the additional feature set, some of which are de-
scribed below in more detail.
</bodyText>
<footnote confidence="0.9882695">
3There is a slight complication here. For each noun n, EM
clustering estimates a probability distribution P(nlc*) for n
and semantic class c*. From this distribution we obtained
discrete semantic word classes by assigning each noun n to
semantic class c = argmax.* p(c*|n).
4http://www.post.japanpost.jp/zipcode/download.html
</footnote>
<page confidence="0.941844">
1623
</page>
<bodyText confidence="0.999928222222222">
As for TR and EX, our intuition is that if a prob-
lem nucleus and an aid nucleus are an adequate
match, their excitation polarities are opposite, as
described in Section 2. We encode whether the ex-
citation polarities of nuclei templates are the same
or not in our features. Also, the excitation polar-
ities of problem and aid nuclei and TR are com-
bined (TREX1, TREX2) so that the classifier can
know whether the nuclei follow the constraint for
adequate matches described in Section 2.
As for SIM, if an aid message matches a prob-
lem report, besides the common nucleus noun, it is
reasonable to assume that certain contexts are se-
mantically similar. We capture this characteristic
in three ways. SIM1 looks for common semantic
word classes in the problem report and aid mes-
sage. SIM2 and SIM3 target the modifiers of the
common nucleus noun if they exist.
We also observed that if an aid message matches
a problem report, the problem nucleus template
and aid nucleus template are often distributionally
similar. A typical example is “X is sold out” and
“buy X”. SIM4 captures this tendency. As the dis-
tributional similarity between templates, we used
a Bayesian distributional similarity measure pro-
posed by Kazama et al. (2010).5
CTP indicates whether the problem and aid nu-
clei are in contradiction relation or not. This fea-
ture was implemented based on the observation
that when problem and aid nuclei are in contradic-
tion relation, they are often proper matches (e.g.,
(blackout, “X starts”) and (blackout, “X ends”)).
CTP indicates whether nucleus pairs are in the
one million contradiction phrase pairs6 automat-
ically obtained by applying a method proposed by
Hashimoto et al. (2012) to 600 million Web pages.
</bodyText>
<sectionHeader confidence="0.999611" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999850125">
We evaluated our problem report recognizer and
problem-aid match recognizer. For the sake of
space, we give only the performance figures of the
aid message recognizer at the end of Section 5.1.
We collected tweets posted during and after
the 2011 Great East Japan Earthquake, between
March 10 and April 4, 2011. After applying
keyword-based filtering with a list of over 300
</bodyText>
<footnote confidence="0.997459166666667">
5The original similarity was defined over noun pairs and it
was estimated from dependency relations. Obtaining similar-
ity between template pairs, not noun pairs, is straightforward
given the same dependency relations. We used 600 million
Web pages for this similarity estimation.
6The precision of the pairs was reported as around 70%.
</footnote>
<bodyText confidence="0.993446333333333">
disaster related keywords, we obtained 55 million
tweets. After dependency parsing7, we used them
in our evaluation.
</bodyText>
<subsectionHeader confidence="0.993902">
5.1 Problem Report Recognition
</subsectionHeader>
<bodyText confidence="0.99994328125">
Firstly, we evaluated our problem report recog-
nizer. Particularly, we assessed the effect of ex-
citation polarities and trouble expressions in two
settings. The first is against a naturally distributed
gold standard data. The second targets problem
reports with problem nuclei unseen in the training
data.
In both experiments we observed that the per-
formance drops when excitation polarities and
trouble expressions are removed from the feature
set. The performance drop was larger in the sec-
ond experiment which suggests that the excitation
polarities and trouble expressions are more effec-
tive against unseen problem reports.
Training and test data for problem report recog-
nition consist of tweet-nucleus candidate pairs
randomly sampled from our 55 million tweet data.
The training data (R) and test data (T) consist of
13,000 and 1,000 pairs, respectively, manually la-
beled by three annotators (other than the authors)
as problem or other. Final judgment was made by
majority vote. The Fleiss’ kappa score for train-
ing and test data for annotation judgement is 0.74
(substantial agreement).
Our problem report recognizer and its variants
are listed in Table 3. Table 4 shows the evalua-
tion results. The proposed method achieved about
44% recall and nearly 80% precision, outperform-
ing all other systems in terms of precision, F-score
and average precision8. The improvement in pre-
cision when using TR&amp;EX is statistically signif-
icant (p &lt; 0.05).9 Note that F-measure dropped
</bodyText>
<tableCaption confidence="0.893045272727273">
PROPOSED: Our proposed method with all features used.
PROPOSED-*: The proposed method without the feature set de-
noted by “*”. Here EX and TR denote all excitation po-
larity and trouble expression related features, respectively,
including their combinations (TREX1).
PROPOSED+OET: The proposed method incorporating the
classification results of problem nucleus candidates by the
Opinion Extraction Tool as additional binary features.
RULE-BASED: The method that regards only nuclei satisfying
the constraint in Table 1 as problem nuclei.
Table 3: Evaluated problem report recognizers.
</tableCaption>
<footnote confidence="0.798091285714286">
7http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?KNP
8We calculate average precision using the formula: aP =
, where Prec(k) is the precision at
�
cut-off k and rel(k) is an indicator function equaling 1 if
the item at rank k is relevant, zero otherwise.
9Throughout this paper we performed two-tailed test of
</footnote>
<equation confidence="0.4209915">
∑�
k=1(Prec(k)Xrel(k))
</equation>
<page confidence="0.601295">
1624
</page>
<figure confidence="0.9872517">
1
0.9
0.8
Precision
0.7
0.6
0.5
0.4
0.3
0.2
</figure>
<table confidence="0.984464071428571">
Recognition system R (%) P (%) F (%) aP (%)
PROPOSED 44.26 79.41 56.83 71.82
PROPOSED-TR&amp;EX 45.08 74.83 56.26 69.67
PROPOSED-EX 44.67 74.66 55.89 69.90
PROPOSED-TR 43.85 74.31 55.15 69.44
PROPOSED-MSA 28.69 70.71 40.81 57.74
PROPOSED-SWC 43.42 75.97 55.25 70.61
PROPOSED-WSP 43.14 77.83 55.50 70.45
PROPOSED-REQ 42.64 76.16 55.50 54.67
PROPOSED-GL 44.14 78.34 55.50 56.46
PROPOSED+OET 44.24 79.41 56.82 71.81
RULE-BASED 30.32 67.96 41.93 n/a
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
</table>
<tableCaption confidence="0.766187333333333">
Table 4: Recall (R), precision (P), F-score (F) and
average precision (aP) of the problem report rec-
ognizers.
</tableCaption>
<bodyText confidence="0.995309205128205">
whenever each type of feature was removed, im-
plying that each type of feature is effective in this
task. Especially note the performance drop if we
remove excitation polarities (EX), trouble expres-
sion (TR) and both excitation and trouble expres-
sion features (TR&amp;EX), confirming that they are
crucial in recognizing problem reports with high
accuracy. Also note that the performance of PRO-
POSED+OET was actually slightly worse than that
of the proposed method. This suggests that full-
fledged sentiment analysis is not effective at least
in this setting. The rule-based method achieved
relatively high precision despite of the low recall,
demonstrating the importance of problem and aid
nuclei formulations described in Section 1.
The second experiment assessed the efficiency
of our problem report recognizer against unseen
problem nuclei under the condition that every tem-
plate in nuclei has excitation polarity. We sampled
the training and test data so that the problem nu-
cleus nouns and templates in the training and test
data are disjoint. First we created a subset of the
test data by selecting the samples which had nu-
clei with excitation templates. We call this sub-
set T′. Next, we removed samples from training
data R if either of their problem nouns or tem-
plates appeared in the nuclei of T′. The result-
ing new training data (called R′) and test data (T′)
consist of 6,484 and 407 tweet-nucleus candidate
pairs, respectively. We trained our problem report
recognizer using R′ and tested its performance us-
ing T′. Figure 2 shows the precision-recall curves
obtained by changing the threshold on the SVM
scores. The effectiveness of excitation polarities
and trouble expressions was more evident in this
setting. The PROPOSED’s performance was ac-
tually better in this setting (almost 50% recall at
population proportion (Ott and Longnecker, 2010) using
SVM-threshold=0.
</bodyText>
<figure confidence="0.798967">
PROPOSED-TR&amp;EX
PROPOSED
</figure>
<figureCaption confidence="0.9901715">
Figure 2: Precision-recall curves of problem re-
port recognizers against unseen problem nuclei.
</figureCaption>
<bodyText confidence="0.999923222222222">
more that 80% precision), than the previous set-
ting, showing that excitation templates and trouble
expressions are crucial in achieving high perfor-
mance especially for unseen problem nuclei. The
same was confirmed when we removed excitation
polarity and trouble expression related features,
with performance dropping by 7.43 points in terms
of average precision. The improvement in pre-
cision when using TR&amp;EX is statistically signif-
icant (p &lt; 0.01). This implies, assuming that we
have a wide-coverage dictionary of templates with
excitation polarities, that excitation polarities are
important in dealing with unexpected problems in
disaster situations.
We also evaluated the aid-message recognizer,
using tweet-nucleus pairs in R and T as train-
ing and test data and the annotation scheme was
also the same. The average Fleiss’ kappa score
was 0.55 (moderate agreement). Our recognizer
achieved 53.82% recall and 65.67% precision and
showed similar tendencies with the problem report
recognizer, with the excitation polarities and trou-
ble expressions contributing to higher accuracy.
We can conclude that excitation polarities and
trouble expressions are important in identifying
problem reports and aid messages during disaster
situations.
</bodyText>
<subsectionHeader confidence="0.998523">
5.2 Problem-Aid Matching
</subsectionHeader>
<bodyText confidence="0.9999516">
Next, we evaluated the performance of the
problem-aid match recognizer. We applied our
problem report recognizer and aid message recog-
nizer to all 55 million tweets and combined the
tweet-nucleus pairs judged as problem reports and
aid messages, respectively, to create the training
and test data.
The training data consists of two parts (M1 and
M2). M1 includes many variations of the aid
messages for each problem report, while M2 en-
</bodyText>
<figure confidence="0.5008515">
PROPOSED-TR
PROPOSED-EX
</figure>
<page confidence="0.965175">
1625
</page>
<bodyText confidence="0.999922441860465">
sures diversity in nouns and templates in problem
nuclei. For M1, we randomly picked up problem
reports from the output of the problem report rec-
ognizer and to each we attached up to 30 randomly
picked, distinct aid messages that have the same
nucleus noun. Building M2 follows the construc-
tion method of M1, except that: (1) we used up
to 30 distinct problem nuclei for each noun; (2)
for each problem report we attached only one ran-
domly picked aid message.
In creating the test data T2, we followed the
construction method used for M2 to assess the
performance of our proposal with a large variety
of problems. M1, M2 and T2 consist of 3,000,
6,000 and 1,000 samples, respectively. The an-
notation was done by majority vote of three hu-
man annotators (other than the authors), the aver-
age Fleiss’ kappa-score for training and test data
was 0.63 (substantial agreement).
We trained the problem-aid match recognizers
of Table 5 with M1 and M2. The evaluation
results performed on T2 are shown in Table 6.
We can observe that, among the nuclei related
features, the trouble expression (TR) and excita-
tion polarity (EX) features and their combination
(TR&amp;EX) contribute most to the performance, al-
though the contribution of nuclei related features
is less in comparison to the problem report and aid
message recognition. The improvement in preci-
sion when using TR&amp;EX is marginally significant
(p = 0.056). Instead, morphological and syntactic
analysis (MSA) and semantic word class (SWC)
features greatly improved performance.
As the final experiments, we evaluated top-
ranking matches of our problem-aid match recog-
nizer, where the recognizer classified all the possi-
ble combinations of tweet-nuclei pairs taken from
55 million tweets. In addition, we assessed the ef-
fectiveness of excitation polarities and trouble ex-
pressions by comparing all positive matches pro-
duced by our full problem-aid match recognizer
(PROPOSED) and those produced by the problem-
aid match recognizer (PROPOSED-TR&amp;EX) that
</bodyText>
<tableCaption confidence="0.9823771">
PROPOSED: Our proposed method with all features used.
PROPOSED-*: The proposed method without the feature set de-
noted by “*”. Here also EX and TR denote all excitation
polarity and trouble expression related features, respec-
tively, including their combinations (TREX1 and TREX2).
RULE-BASED: The method that judges only problem-aid nuclei
combinations with opposite excitation polarities as proper
matches.
Table 5: Evaluated problem-aid match recogniz-
ers.
</tableCaption>
<table confidence="0.999979142857143">
Matching system R (%) P (%) F (%) aP (%)
PROPOSED 30.67 70.42 42.92 55.16
PROPOSED-TR&amp;EX 28.83 67.14 40.33 53.99
PROPOSED-EX 31.29 67.11 42.68 54.19
PROPOSED-TR 30.56 69.33 42.42 54.85
PROPOSED-MSA 13.50 53.66 21.57 44.52
PROPOSED-SWC 26.99 67.69 38.59 52.23
PROPOSED-WSP 30.61 69.51 42.50 54.81
PROPOSED-CTP 30.06 70.00 42.05 54.94
PROPOSED-SIM 29.95 70.11 41.97 54.98
PROPOSED-REQ 30.58 70.25 42.61 54.67
PROPOSED-GL 30.61 70.31 42.65 55.02
PROPOSED-SSR 30.67 69.44 42.72 54.91
RULE-BASED 15.33 17.36 16.28 n/a
</table>
<tableCaption confidence="0.679506">
Table 6: Recall (R), precision (P), F-score (F) and
average precision (aP) of the problem-aid match
recognizers.
</tableCaption>
<bodyText confidence="0.9998844">
did not use excitation polarities and trouble ex-
pressions in its feature set. Note that PROPOSED-
TR&amp;EX was fed by the problem report and aid
message recognizers that didn’t use excitation po-
larities and trouble expressions. For both systems’
training data we used R for the problem report
and aid message recognizers; M1 and M2 for the
problem-aid matching recognizers.
PROPOSED and PROPOSED-TR&amp;EX output 15.2
million and 13.4 million positive matches, cover-
ing 1,691 and 1,442 nucleus nouns, respectively.
Table 7 shows match samples identified with PRO-
POSED. We observed that the output of each sys-
tem was dominated by just a handful of frequent
nucleus nouns, such as “water” or “gasoline”. We
preferred to assess the performance of our system
against a large variation of problem-aid nuclei,
thus we restricted the number of matches to 10
for each nounlo. After this restriction the number
of matches found by PROPOSED and PROPOSED-
</bodyText>
<figure confidence="0.994899666666667">
1
0.8
0.6
0.4
0.2
0
0 1000 2000 3000 4000 5000 6000 7000 8000 9000
Rank
PROPOSED (unseen)
PROPOSED-TR&amp;EX (unseen)
PROPOSED (all)
PROPOSED-TR&amp;EX (all)
</figure>
<figureCaption confidence="0.938443">
Figure 3: Problem-aid match recognition perfor-
mance for ‘all’ and ‘unseen’ problem reports.
</figureCaption>
<footnote confidence="0.6833">
10Note that this setting is a pessimistic estimation of our
system’s overall performance, since according to our obser-
vations problem reports with very frequent nucleus nouns had
proper matches with a higher accuracy than problem reports
with less frequent nucleus nouns.
</footnote>
<table confidence="0.99309768">
Precision
1626
Problem report: いわきの常磐病院、いわき泌尿器科病院、
竹林貞吉記念クリニック、泉中央クリニックは、17日か
ら透析を中止します。患者の方は至急連絡してください。
(Starting from the 17th, the Iwaki Joban Hospital, the Iwaki
Urology Clinique, the Takebayashi Sadakichi Memorial Clin-
ique and the Izumi Central Clinique have all suspended dial-
ysis sessions. Patients are advised to urgently make contact.)
Aid message: いわき泌尿器科病院で短時間透析が可能で
す。受付時間は9時から16時までです。(透析の再開)
(Restart of dialysis sessions: short dialysis sessions are
available at the Iwaki Urology Clinique between 9 AM and
4 PM.)
Problem report:ごめんなさい拡散をお願いしてもいいで
すか。仙台の父親の話ですと携帯の充電がもうない人が
続出しているそうです。携帯充電器の支援が必要かと思
われます。
(Please spread this message. According to my father in
Sendai, there are more and more people whose phones ran
out of battery. We need phone chargers!)
Aid message: 【拡散希望】仙台若林区役所で携帯電話の
充電ができるそうです。
([Please spread] At the City Hall of Wakabayashi-ku, Sendai,
you can recharge your phone battery.)
</table>
<tableCaption confidence="0.99248">
Table 7: Examples from the output of the proposed
</tableCaption>
<bodyText confidence="0.995323411764706">
method in the ‘all’ setting. Problem report and aid
message nuclei are boldfaced in the English trans-
lations.
TR&amp;EX was 8,484 and 7,363, respectively.
The performance of PROPOSED and
PROPOSED-TR&amp;EX were assessed in two
settings: ‘all’ and ‘unseen’. For ‘all’, we selected
400 problem-aid matches from the outputs of the
respective systems after applying the 10-match
restriction. For ‘unseen’, first we removed the
samples from the systems’ outputs if either the
nucleus noun or template pair appear in the nuclei
of the problem-aid match recognizers’ training
data. Next we applied the same sampling process
as with ‘all’. Three annotators (other than the
authors) manually labeled the sample sets, final
judgment being made by majority vote. The
Fleiss’ kappa score for all test data was 0.73
(substantial agreement).
Figure 3 shows the systems’ precision curves,
drawn from the samples whose X-axis positions
represent the ranks according to SVM scores. In
both scenarios we can confirm that excitation po-
larity and trouble expression related features con-
tribute to this task. In the ‘all’ setting in terms
of average precision calculated over the top 7,200
matches, PROPOSED’s 62.36% is 10.48 points
higher than that of PROPOSED-TR&amp;EX. For un-
seen problem/aid nuclei PROPOSED method’s av-
erage precision of 58.57% calculated at the top
3,800 matches is 5.47 points higher than that of
PROPOSED-TR&amp;EX at the same data point. The
improvement in precision when using TR&amp;EX is
statistically significant in both settings (p &lt; 0.01).
</bodyText>
<sectionHeader confidence="0.999924" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999989757575758">
Twitter has been observed as a platform for situ-
ational awareness during various crisis situations
(Starbird et al., 2010; Vieweg et al., 2010), as sen-
sors for an earthquake reporting system (Sakaki et
al., 2010; Okazaki and Matsuo, 2010) or to de-
tect epidemics (Aramaki et al., 2011). Besides
Twitter, blogs or forums have also been the tar-
get of community response analysis (Qu et al.,
2009; Torrey et al., 2007). Similar to our work
are the ones of Neubig et al. (2011) and Ishino et
al. (2012), who tackle specific problems that occur
during disasters (i.e., safety information and trans-
portation information, respectively); and Munro
(2011), who extracted “actionable messages” (re-
quests and aids, indiscriminately), matching being
performed manually. Our work differs from (Neu-
big et al., 2011) and (Ishino et al., 2012) in that we
do not restrict the range of problem reports, and as
opposed to (Munro, 2011), matching is automatic.
Systems such as that of Seki (2011)11 or Munro
(2013)12 are successful examples of crisis crowd-
sourcing, but these require extensive human inter-
vention to coordinate useful information.
Another category of related work relevant to our
task is troubleshooting. Baldwin et al. (2007) and
Raghavan et al. (2010) use discussion forums to
solve technical problems using supervised learn-
ing methods, but these approaches presume that
the solution of a specific problem is within the
same thread. In our work we do not employ struc-
tural characteristics of tweets as restrictions (e.g.,
a problem report and its aid message need to be in
the same tweet chain).
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999927">
In this paper, we proposed a method to dis-
cover matches between problem reports and aid
messages from tweets in large-scale disasters.
Through a series of experiments, we demonstrated
that the performance of the problem-aid match-
ing can be improved with the usage of seman-
tic orientation of excitation polarities, proposed in
(Hashimoto et al., 2012), and trouble expressions.
We are planning to deploy our system and re-
lease model files of the classifiers to assist relief
efforts in future crisis scenarios.
</bodyText>
<footnote confidence="0.9965405">
11http://www.sinsai.info/
12http://www.mission4636.org/
</footnote>
<page confidence="0.994141">
1627
</page>
<sectionHeader confidence="0.989231" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999723846846847">
Adam Acar and Yuya Muraki. 2011. Twitter for cri-
sis communication: Lessons learned from Japan’s
tsunami disaster. International Journal of Web
Based Communities, 7(3):392–402.
Eiji Aramaki, Sachiko Maskawa, and Mizuki Morita.
2011. Twitter catches the flu: Detecting influenza
epidemics using Twitter. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP 2011), pages 1568–1576.
Timothy Baldwin, David Martinez, and Richard B.
Penman. 2007. Automatic thread classification for
Linux user forum information access. In Proceed-
ings of the 12th Australasian Document Computing
Symposium (ADCS 2007), pages 72–79.
Stijn De Saeger, Kentaro Torisawa, and Jun’ichi
Kazama. 2008. Looking for trouble. In Proceed-
ings of the 22nd International Conference on Com-
putational Linguistics (COLING 2008), pages 185–
192.
Stijn De Saeger, Kentaro Torisawa, Masaaki Tsuchida,
Jun’ichi Kazama, Chikara Hashimoto, Ichiro Ya-
mada, Jong-Hoon Oh, Istv´an Varga, and Yulan Yan.
2011. Relation acquisition using word classes and
partial patterns. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP 2011), pages 825–835.
Joseph L. Fleiss. 1971. Measuring nominal scale
agreement among many raters. Psychological Bul-
letin, 5:378–382.
Chikara Hashimoto, Kentaro Torisawa, Stijn
De Saeger, Jong-Hoon Oh, and Jun’ichi Kazama.
2012. Excitatory or inhibitory: A new semantic
orientation extracts contradiction and causality from
the web. In Proceedings of the 2012 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP-CoNLL 2012), pages 619–630.
Aya Ishino, Shuhei Odawara, Hidetsugu Nanba, and
Toshiyuki Takezawa. 2012. Extracting transporta-
tion information and traffic problems from tweets
during a disaster: Where do you evacuate to? In
Proceedings of the Second International Conference
on Advances in Information Mining and Manage-
ment (IMMM 2012), pages 91–96.
Hiroshi Kanayama and Tetsuya Nasukawa. 2008. Tex-
tual demand analysis: Detection of users’ wants and
needs from opinions. In Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics (COLING 2008), pages 409–416.
Jun’ichi Kazama and Kentaro Torisawa. 2008. Induc-
ing gazetteers for named entity recognition by large-
scale clustering of dependency relations. In Pro-
ceedings of the 46th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies (ACL-08: HLT), pages 407–
415.
Jun’ichi Kazama, Stijn De Saeger, Kow Kuroda,
Masaki Murata, and Kentaro Torisawa. 2010. A
Bayesian method for robust estimation of distribu-
tional similarities. In Proceedings of the 48th An-
nual Meeting of the Association for Computational
Linguistics (ACL 2010), pages 247–256.
Jun’ichi Kazama, Stijn De Saeger, Kentaro Torisawa,
Jun Goto, and Istv´an Varga. 2013. Saigaiji jouhou
e no shitsumon outo shisutemu no tekiyou no koko-
romi. (An attempt for applying question-answering
system on disaster related information). In Pro-
ceeding of the Nineteenth Annual Meeting of The
Association for Natural Language Processing. (in
Japanese).
Benjamin Mandel, Aron Culotta, John Boulahanis,
Danielle Stark, Bonnie Lewis, and Jeremy Rodrigue.
2012. A demographic analysis of online sentiment
during Hurricane Irene. In Proceedings of the Sec-
ond Workshop on Language Analysis in Social Me-
dia (LASM 2012), pages 27–36.
Robert Munro. 2011. Subword and spatiotempo-
ral models for identifying actionable information in
Haitian Kreyol. In Proceedings of the Fifteenth
Conference on Computational Natural Language
Learning (CoNLL-2011), pages 68–77.
Robert Munro. 2013. Crowdsourcing and the
crisis-affected community. Information Retrieval,
16(2):210–266.
Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.
2010. Dependency tree-based sentiment classifica-
tion using CRFs with hidden variables. In Human
Language Technologies: The 2010 Annual Confer-
ence of the North American Chapter of the Associ-
ation for Computational Linguistics (NAACL HLT
2010), pages 786–794.
National Police Agency of Japan. 2013. Damage sit-
uation and public countermeasures associated with
2011 Tohoku district – off the Pacific Ocean Earth-
quake. http://www.npa.go.jp/archive/
keibi/biki/higaijokyo_e.pdf. (accessed
on 30 April, 2013).
Graham Neubig, Yuichiroh Matsubayashi, Masato
Hagiwara, and Koji Murakami. 2011. Safety infor-
mation mining ― what can NLP do in a disaster ―.
In Proceedings of the 5th International Joint Con-
ference on Natural Language Processing (IJCNLP
2011), pages 965–973.
Jong-Hoon Oh, Kentaro Torisawa, Chikara Hashimoto,
Takuya Kawada, Stijn De Saeger, Jun’ichi Kazama,
and Yiou Wang. 2012. Why question answering
using sentiment analysis and word classes. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL 2012), pages 368–378.
</reference>
<page confidence="0.815014">
1628
</page>
<reference confidence="0.999911839506173">
Jong-Hoon Oh, Kentaro Torisawa, Chikara Hashimoto,
Motoki Sano, Stijn De Saeger, and Kiyonori Ohtake.
2013. Why-question answering using intra- and
inter-sentential causal relations. In Proceedings of
the 51st Annual Meeting of the Association for Com-
putational Linguistics (ACL 2013).
Kiyonori Ohtake, Kentaro Torisawa, Jun Goto, and
Stijn De Saeger. 2013. Saigaiji ni okeru hi-
saisha to kyuuen kyuujosha kan no souhoko komyu-
nikeeshon. (Bi-directional communication between
victims and rescures during a crisis). In Proceeding
of the Nineteenth Annual Meeting of The Association
for Natural Language Processing. (in Japanese).
Makoto Okazaki and Yutaka Matsuo. 2010. Seman-
tic Twitter: Analyzing tweets for real-time event
notification. In Proceedings of the 2008/2009 in-
ternational conference on Social software: Re-
cent trends and developments in social software
(BlogTalk 2008), pages 63–74.
R. Lyman Ott and Michael T. Longnecker, 2010. An
Introduction to Statistical Methods and Data Analy-
sis, chapter 10.2. Brooks Cole, 6th edition.
Yan Qu, Philip Fei Wu, and Xiaoqing Wang. 2009.
Online community response to major disaster: A
study of Tianya forum in the 2008 Sichuan Earth-
quake. In 42st Hawaii International International
Conference on Systems Science (HICSS-42), pages
1–11.
Preethi Raghavan, Rose Catherine, Shajith Ikbal,
Nanda Kambhatla, and Debapriyo Majumdar. 2010.
Extracting problem and resolution information from
online discussion forums. In Proceedings of the
16th International Conference on Management of
Data (COMAD 2010).
Takeo Saijo. 2012. Hito-o tasukeru sungoi shikumi. (A
stunning system that saves people). Diamond Inc.
(in Japanese).
Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.
2010. Earthquake shakes Twitter users: Real-time
event detection by social sensors. In Proceedings
of the 19th International Conference on World Wide
Web (WWW 2010), pages 851–860.
Motoki Sano, Istv´an Varga, Jun’ichi Kazama, and Ken-
taro Torisawa. 2012. Requests in tweets dur-
ing a crisis: A systemic functional analysis of
tweets on the Great East Japan Earthquake and
the Fukushima Daiichi nuclear disaster. In Pa-
pers from the 39th International Systemic Func-
tional Congress (ISFC39), pages 135–140.
Haruyuki Seki. 2011. Higashi-nihon daishinsai fukkou
shien platform sinsai.info no naritachi to kongo no
kadai. (The organizational structure of sinsai.info
restoration support platform for the 2011 Great East
Japan Earthquake and future challenges). Journal of
digital practices, 2(4):237–241. (in Japanese).
Kate Starbird, Leysia Palen, Amanda L. Hughes, and
Sarah Vieweg. 2010. Chatter on the red: What
hazards threat reveals about the social life of mi-
croblogged information. In Proceedings of The
2010 ACM Conference on Computer Supported Co-
operative Work (CSCW 2010), pages 241–250.
Cristen Torrey, Moira Burke, Matthew L. Lee,
Anind K. Dey, Susan R. Fussell, and Sara B. Kiesler.
2007. Connected giving: Ordinary people coordi-
nating disaster relief on the Internet. In Proceedings
of the 40th Annual Hawaii International Conference
on System Sciences (HICSS-40), pages 179–188.
Katerina Tsagkalidou, Vassiliki Koutsonikola, Athena
Vakali, and Konstantinos Kafetsios. 2011. Emo-
tional aware clustering on micro-blogging sources.
In Proceedings of the 4th international conference
on Affective computing and intelligent interaction
(ACII2011), pages 387–396.
Sarah Vieweg, Amanda L. Hughes, Kate Starbird, and
Leysia Palen. 2010. Microblogging during two nat-
ural hazards events: What Twitter may contribute
to situational awareness. In Proceedings of the
SIGCHI Conference on Human Factors in Comput-
ing Systems (CHI 2010), pages 1079–1088.
Patrick Winn. 2011. Japan tsunami disaster: As Japan
scrambles, Twitter reigns. GlobalPost, 18 March.
</reference>
<page confidence="0.995775">
1629
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.206079">
<title confidence="0.846264333333333">Aid is Out There: Looking for Help from Tweets during a Large Scale Disaster De Analysis</title>
<affiliation confidence="0.942999">National Institute of Information and Communications Technology (NICT), Japan</affiliation>
<email confidence="0.924469">msano,torisawa,ch,kiyonori.ohtake,rovellia,</email>
<affiliation confidence="0.412531">Discovery Research Laboratories, NEC Corporation, Japan</affiliation>
<email confidence="0.998346">t-kawai@bx.jp.nec.com</email>
<abstract confidence="0.999151904761905">The 2011 Great East Japan Earthquake caused a wide range of problems, and as countermeasures, many aid activities were carried out. Many of these problems and aid activities were reported via Twitter. However, most problem reports and corresponding aid messages were not successfully exchanged between victims and local governments or humanitarian organizations, overwhelmed by the vast amount of information. As a result, victims could not receive necessary aid and humanitarian organizations wasted resources on redundant efforts. In this paper, we propose a method for discovering matches between problem reports and aid messages. Our system contributes to problem-solving in a large scale disaster situation by facilitating communication between victims and humanitarian organizations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adam Acar</author>
<author>Yuya Muraki</author>
</authors>
<title>Twitter for crisis communication: Lessons learned from Japan’s tsunami disaster.</title>
<date>2011</date>
<journal>International Journal of Web Based Communities,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="1764" citStr="Acar and Muraki, 2011" startWordPosition="245" endWordPosition="249"> to problem-solving in a large scale disaster situation by facilitating communication between victims and humanitarian organizations. 1 Introduction The 2011 Great East Japan Earthquake in March 11, 2011 killed 15,883 people and destroyed over 260,000 households (National Police Agency of Japan, 2013). Accustomed way of living suddenly became unmanageable and people found themselves in extreme conditions for months. Just after the disaster, many people used Twitter for posting problem reports and aid messages as it functioned while most communication channels suffered disruptions (Winn, 2011; Acar and Muraki, 2011; Sano et al., 2012). Examples of such problem reports and aid messages, translated from Japanese tweets, are given below (P1, A1). P1 My friend said infant formula is sold out. If somebody knows shops in Sendai-city where they still have it in stock, please let us know. A1 At Jusco supermarket in Sendai, you can still buy water and infant formula. If A1 would have been forwarded to the sender of P1, it could have helped since it would help the “friend” to obtain infant formula. But in reality, the majority of such reports/messages, especially unforeseen ones went unnoticed amongst the mass of</context>
</contexts>
<marker>Acar, Muraki, 2011</marker>
<rawString>Adam Acar and Yuya Muraki. 2011. Twitter for crisis communication: Lessons learned from Japan’s tsunami disaster. International Journal of Web Based Communities, 7(3):392–402.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eiji Aramaki</author>
<author>Sachiko Maskawa</author>
<author>Mizuki Morita</author>
</authors>
<title>Twitter catches the flu: Detecting influenza epidemics using Twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>1568--1576</pages>
<contexts>
<context position="40515" citStr="Aramaki et al., 2011" startWordPosition="6409" endWordPosition="6412">er than that of PROPOSED-TR&amp;EX. For unseen problem/aid nuclei PROPOSED method’s average precision of 58.57% calculated at the top 3,800 matches is 5.47 points higher than that of PROPOSED-TR&amp;EX at the same data point. The improvement in precision when using TR&amp;EX is statistically significant in both settings (p &lt; 0.01). 6 Related Work Twitter has been observed as a platform for situational awareness during various crisis situations (Starbird et al., 2010; Vieweg et al., 2010), as sensors for an earthquake reporting system (Sakaki et al., 2010; Okazaki and Matsuo, 2010) or to detect epidemics (Aramaki et al., 2011). Besides Twitter, blogs or forums have also been the target of community response analysis (Qu et al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we do not restrict the range of problem reports, </context>
</contexts>
<marker>Aramaki, Maskawa, Morita, 2011</marker>
<rawString>Eiji Aramaki, Sachiko Maskawa, and Mizuki Morita. 2011. Twitter catches the flu: Detecting influenza epidemics using Twitter. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2011), pages 1568–1576.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>David Martinez</author>
<author>Richard B Penman</author>
</authors>
<title>Automatic thread classification for Linux user forum information access.</title>
<date>2007</date>
<booktitle>In Proceedings of the 12th Australasian Document Computing Symposium (ADCS</booktitle>
<pages>72--79</pages>
<contexts>
<context position="41452" citStr="Baldwin et al. (2007)" startWordPosition="6558" endWordPosition="6561"> information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we do not restrict the range of problem reports, and as opposed to (Munro, 2011), matching is automatic. Systems such as that of Seki (2011)11 or Munro (2013)12 are successful examples of crisis crowdsourcing, but these require extensive human intervention to coordinate useful information. Another category of related work relevant to our task is troubleshooting. Baldwin et al. (2007) and Raghavan et al. (2010) use discussion forums to solve technical problems using supervised learning methods, but these approaches presume that the solution of a specific problem is within the same thread. In our work we do not employ structural characteristics of tweets as restrictions (e.g., a problem report and its aid message need to be in the same tweet chain). 7 Conclusions In this paper, we proposed a method to discover matches between problem reports and aid messages from tweets in large-scale disasters. Through a series of experiments, we demonstrated that the performance of the pr</context>
</contexts>
<marker>Baldwin, Martinez, Penman, 2007</marker>
<rawString>Timothy Baldwin, David Martinez, and Richard B. Penman. 2007. Automatic thread classification for Linux user forum information access. In Proceedings of the 12th Australasian Document Computing Symposium (ADCS 2007), pages 72–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stijn De Saeger</author>
<author>Kentaro Torisawa</author>
<author>Jun’ichi Kazama</author>
</authors>
<title>Looking for trouble.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING</booktitle>
<pages>185--192</pages>
<marker>De Saeger, Torisawa, Kazama, 2008</marker>
<rawString>Stijn De Saeger, Kentaro Torisawa, and Jun’ichi Kazama. 2008. Looking for trouble. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008), pages 185– 192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stijn De Saeger</author>
<author>Kentaro Torisawa</author>
<author>Masaaki Tsuchida</author>
<author>Jun’ichi Kazama</author>
<author>Chikara Hashimoto</author>
<author>Ichiro Yamada</author>
<author>Jong-Hoon Oh</author>
<author>Istv´an Varga</author>
<author>Yulan Yan</author>
</authors>
<title>Relation acquisition using word classes and partial patterns.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>825--835</pages>
<marker>De Saeger, Torisawa, Tsuchida, Kazama, Hashimoto, Yamada, Oh, Varga, Yan, 2011</marker>
<rawString>Stijn De Saeger, Kentaro Torisawa, Masaaki Tsuchida, Jun’ichi Kazama, Chikara Hashimoto, Ichiro Yamada, Jong-Hoon Oh, Istv´an Varga, and Yulan Yan. 2011. Relation acquisition using word classes and partial patterns. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2011), pages 825–835.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph L Fleiss</author>
</authors>
<title>Measuring nominal scale agreement among many raters.</title>
<date>1971</date>
<journal>Psychological Bulletin,</journal>
<pages>5--378</pages>
<marker>Fleiss, 1971</marker>
<rawString>Joseph L. Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin, 5:378–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikara Hashimoto</author>
<author>Kentaro Torisawa</author>
<author>Stijn De Saeger</author>
<author>Jong-Hoon Oh</author>
<author>Jun’ichi Kazama</author>
</authors>
<title>Excitatory or inhibitory: A new semantic orientation extracts contradiction and causality from the web.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>619--630</pages>
<marker>Hashimoto, Torisawa, De Saeger, Oh, Kazama, 2012</marker>
<rawString>Chikara Hashimoto, Kentaro Torisawa, Stijn De Saeger, Jong-Hoon Oh, and Jun’ichi Kazama. 2012. Excitatory or inhibitory: A new semantic orientation extracts contradiction and causality from the web. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2012), pages 619–630.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aya Ishino</author>
<author>Shuhei Odawara</author>
<author>Hidetsugu Nanba</author>
<author>Toshiyuki Takezawa</author>
</authors>
<title>Extracting transportation information and traffic problems from tweets during a disaster: Where do you evacuate to?</title>
<date>2012</date>
<booktitle>In Proceedings of the Second International Conference on Advances in Information Mining and Management (IMMM</booktitle>
<pages>91--96</pages>
<contexts>
<context position="40728" citStr="Ishino et al. (2012)" startWordPosition="6449" endWordPosition="6452">nt. The improvement in precision when using TR&amp;EX is statistically significant in both settings (p &lt; 0.01). 6 Related Work Twitter has been observed as a platform for situational awareness during various crisis situations (Starbird et al., 2010; Vieweg et al., 2010), as sensors for an earthquake reporting system (Sakaki et al., 2010; Okazaki and Matsuo, 2010) or to detect epidemics (Aramaki et al., 2011). Besides Twitter, blogs or forums have also been the target of community response analysis (Qu et al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we do not restrict the range of problem reports, and as opposed to (Munro, 2011), matching is automatic. Systems such as that of Seki (2011)11 or Munro (2013)12 are successful examples of crisis crowdsourcing, but these require extensive human intervention to co</context>
</contexts>
<marker>Ishino, Odawara, Nanba, Takezawa, 2012</marker>
<rawString>Aya Ishino, Shuhei Odawara, Hidetsugu Nanba, and Toshiyuki Takezawa. 2012. Extracting transportation information and traffic problems from tweets during a disaster: Where do you evacuate to? In Proceedings of the Second International Conference on Advances in Information Mining and Management (IMMM 2012), pages 91–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Kanayama</author>
<author>Tetsuya Nasukawa</author>
</authors>
<title>Textual demand analysis: Detection of users’ wants and needs from opinions.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING</booktitle>
<pages>409--416</pages>
<contexts>
<context position="5983" citStr="Kanayama and Nasukawa, 2008" startWordPosition="941" endWordPosition="944">erize problem reports, aid messages and their matches. We developed a supervised method encoding such information into its features. An evident alternative to this approach is to use sentiment analysis (Mandel et al., 2012; Tsagkalidou et al., 2011) assuming that problem reports should include something ‘bad’ while aid messages describe something ‘good’. However, we will show that this does not work well in our experiments. We think this is due to mismatch between the concepts of problem/aid and sentiment polarity. Note that previous work on ‘demand’ recognition also found similar tendencies (Kanayama and Nasukawa, 2008). Another issue in this task is, of course, the context surrounding problem/aid nuclei. The fol&apos;We found that out of 500 random tweets only 4.5% of problem reports and 9.1% of aid messages did not contain any problem report/aid message nuclei. lowing (imaginary) tweets exemplify the problems caused by contexts. FP1 I do not believe infant formula is sold out in Sendai. FA1 At Jusco supermarket in Iwaki, you can still buy infant formula. The problem nuclei of FP1 and P1 are the same but FP1 is not a problem report because of the expression “I do not believe”. The aid nuclei of FA1 and A1 are th</context>
</contexts>
<marker>Kanayama, Nasukawa, 2008</marker>
<rawString>Hiroshi Kanayama and Tetsuya Nasukawa. 2008. Textual demand analysis: Detection of users’ wants and needs from opinions. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008), pages 409–416.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun’ichi Kazama</author>
<author>Kentaro Torisawa</author>
</authors>
<title>Inducing gazetteers for named entity recognition by largescale clustering of dependency relations.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-08: HLT),</booktitle>
<pages>407--415</pages>
<contexts>
<context position="21701" citStr="Kazama and Torisawa (2008)" startWordPosition="3479" endWordPosition="3482">ive and 27,951 negative words. Note that we used the Opinion Extraction Tool in the experiments to check the effectiveness of the full-fledged sentiment analysis in this task. Semantic Word Class (SWC) We assume that nouns in the same semantic class behave simi2Provided at the ALAGIN Forum (http://www.alagin.jp/). larly in crisis situations. For example, if “infection” appears in a problem report, the tweets including “pulmonary embolism” are also likely to be problem reports. Semantic word class features are used to capture such tendencies. We applied an EM-style word clustering algorithm in Kazama and Torisawa (2008) to 600 million Web pages and clustered 1 million nouns into 500 classes. This algorithm has been used in many works, such as relation extraction (De Saeger et al., 2011) and Why-QA (Oh et al., 2012), and can generate various kinds of semantically clean word classes, such as foods, disease names, and natural disasters. We used the word classes in tweets as features.3 Geographical Locations (GL) Our location recognizer matches tweets against our location dictionary. Location names and their existence/non-existence in tweets constitute evidence, thus we encoded such information into our features</context>
</contexts>
<marker>Kazama, Torisawa, 2008</marker>
<rawString>Jun’ichi Kazama and Kentaro Torisawa. 2008. Inducing gazetteers for named entity recognition by largescale clustering of dependency relations. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-08: HLT), pages 407– 415.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun’ichi Kazama</author>
<author>Stijn De Saeger</author>
<author>Kow Kuroda</author>
<author>Masaki Murata</author>
<author>Kentaro Torisawa</author>
</authors>
<title>A Bayesian method for robust estimation of distributional similarities.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>247--256</pages>
<marker>Kazama, De Saeger, Kuroda, Murata, Torisawa, 2010</marker>
<rawString>Jun’ichi Kazama, Stijn De Saeger, Kow Kuroda, Masaki Murata, and Kentaro Torisawa. 2010. A Bayesian method for robust estimation of distributional similarities. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL 2010), pages 247–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun’ichi Kazama</author>
<author>Stijn De Saeger</author>
<author>Kentaro Torisawa</author>
<author>Jun Goto</author>
<author>Istv´an Varga</author>
</authors>
<title>Saigaiji jouhou e no shitsumon outo shisutemu no tekiyou no kokoromi. (An attempt for applying question-answering system on disaster related information).</title>
<date>2013</date>
<booktitle>In Proceeding of the Nineteenth Annual Meeting of The</booktitle>
<note>(in Japanese).</note>
<marker>Kazama, De Saeger, Torisawa, Goto, Varga, 2013</marker>
<rawString>Jun’ichi Kazama, Stijn De Saeger, Kentaro Torisawa, Jun Goto, and Istv´an Varga. 2013. Saigaiji jouhou e no shitsumon outo shisutemu no tekiyou no kokoromi. (An attempt for applying question-answering system on disaster related information). In Proceeding of the Nineteenth Annual Meeting of The Association for Natural Language Processing. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Mandel</author>
<author>Aron Culotta</author>
<author>John Boulahanis</author>
<author>Danielle Stark</author>
<author>Bonnie Lewis</author>
<author>Jeremy Rodrigue</author>
</authors>
<title>A demographic analysis of online sentiment during Hurricane Irene.</title>
<date>2012</date>
<booktitle>In Proceedings of the Second Workshop on Language Analysis in Social Media (LASM</booktitle>
<pages>27--36</pages>
<contexts>
<context position="5577" citStr="Mandel et al., 2012" startWordPosition="875" endWordPosition="878"> and aid nuclei match, they share the same noun. Then, the semantics of predicates in the nuclei is the main factor that decides whether the nuclei constitute a match. We introduce a semantic classification of predicates according to the framework of excitation polarities proposed in Hashimoto et al. (2012). Our hypothesis is that excitation polarities along with trouble expressions can characterize problem reports, aid messages and their matches. We developed a supervised method encoding such information into its features. An evident alternative to this approach is to use sentiment analysis (Mandel et al., 2012; Tsagkalidou et al., 2011) assuming that problem reports should include something ‘bad’ while aid messages describe something ‘good’. However, we will show that this does not work well in our experiments. We think this is due to mismatch between the concepts of problem/aid and sentiment polarity. Note that previous work on ‘demand’ recognition also found similar tendencies (Kanayama and Nasukawa, 2008). Another issue in this task is, of course, the context surrounding problem/aid nuclei. The fol&apos;We found that out of 500 random tweets only 4.5% of problem reports and 9.1% of aid messages did n</context>
</contexts>
<marker>Mandel, Culotta, Boulahanis, Stark, Lewis, Rodrigue, 2012</marker>
<rawString>Benjamin Mandel, Aron Culotta, John Boulahanis, Danielle Stark, Bonnie Lewis, and Jeremy Rodrigue. 2012. A demographic analysis of online sentiment during Hurricane Irene. In Proceedings of the Second Workshop on Language Analysis in Social Media (LASM 2012), pages 27–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Munro</author>
</authors>
<title>Subword and spatiotemporal models for identifying actionable information in Haitian Kreyol.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning (CoNLL-2011),</booktitle>
<pages>68--77</pages>
<contexts>
<context position="40876" citStr="Munro (2011)" startWordPosition="6470" endWordPosition="6471">atform for situational awareness during various crisis situations (Starbird et al., 2010; Vieweg et al., 2010), as sensors for an earthquake reporting system (Sakaki et al., 2010; Okazaki and Matsuo, 2010) or to detect epidemics (Aramaki et al., 2011). Besides Twitter, blogs or forums have also been the target of community response analysis (Qu et al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we do not restrict the range of problem reports, and as opposed to (Munro, 2011), matching is automatic. Systems such as that of Seki (2011)11 or Munro (2013)12 are successful examples of crisis crowdsourcing, but these require extensive human intervention to coordinate useful information. Another category of related work relevant to our task is troubleshooting. Baldwin et al. (2007) and Raghavan et al. (20</context>
</contexts>
<marker>Munro, 2011</marker>
<rawString>Robert Munro. 2011. Subword and spatiotemporal models for identifying actionable information in Haitian Kreyol. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning (CoNLL-2011), pages 68–77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Munro</author>
</authors>
<title>Crowdsourcing and the crisis-affected community.</title>
<date>2013</date>
<journal>Information Retrieval,</journal>
<volume>16</volume>
<issue>2</issue>
<contexts>
<context position="41224" citStr="Munro (2013)" startWordPosition="6527" endWordPosition="6528">t al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we do not restrict the range of problem reports, and as opposed to (Munro, 2011), matching is automatic. Systems such as that of Seki (2011)11 or Munro (2013)12 are successful examples of crisis crowdsourcing, but these require extensive human intervention to coordinate useful information. Another category of related work relevant to our task is troubleshooting. Baldwin et al. (2007) and Raghavan et al. (2010) use discussion forums to solve technical problems using supervised learning methods, but these approaches presume that the solution of a specific problem is within the same thread. In our work we do not employ structural characteristics of tweets as restrictions (e.g., a problem report and its aid message need to be in the same tweet chain). </context>
</contexts>
<marker>Munro, 2013</marker>
<rawString>Robert Munro. 2013. Crowdsourcing and the crisis-affected community. Information Retrieval, 16(2):210–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakagawa</author>
<author>Kentaro Inui</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Dependency tree-based sentiment classification using CRFs with hidden variables.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT</booktitle>
<pages>786--794</pages>
<contexts>
<context position="21038" citStr="Nakagawa et al. (2010)" startWordPosition="3375" endWordPosition="3378">y and contradiction extraction (Hashimoto et al., 2012) or Why-QA (Oh et al., 2013). Word Sentiment Polarity (WSP) As we suggested before, full-fledged sentiment analysis to recognize the expressions, including clauses and phrases, that refer to something good or bad was not effective in our task. However, the sentiment polarity, assigned to single words turned out to be effective. To identify the sentiment polarity of words, we employed the word sentiment polarity dictionary used with a sentiment analysis tool for Japanese, the Opinion Extraction Tool software2, which is an implementation of Nakagawa et al. (2010). The dictionary includes 9,030 positive and 27,951 negative words. Note that we used the Opinion Extraction Tool in the experiments to check the effectiveness of the full-fledged sentiment analysis in this task. Semantic Word Class (SWC) We assume that nouns in the same semantic class behave simi2Provided at the ALAGIN Forum (http://www.alagin.jp/). larly in crisis situations. For example, if “infection” appears in a problem report, the tweets including “pulmonary embolism” are also likely to be problem reports. Semantic word class features are used to capture such tendencies. We applied an E</context>
</contexts>
<marker>Nakagawa, Inui, Kurohashi, 2010</marker>
<rawString>Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi. 2010. Dependency tree-based sentiment classification using CRFs with hidden variables. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010), pages 786–794.</rawString>
</citation>
<citation valid="true">
<title>Damage situation and public countermeasures associated with 2011 Tohoku district – off the Pacific Ocean Earthquake. http://www.npa.go.jp/archive/ keibi/biki/higaijokyo_e.pdf. (accessed on 30</title>
<date>2013</date>
<institution>National Police Agency of</institution>
<contexts>
<context position="41224" citStr="(2013)" startWordPosition="6528" endWordPosition="6528"> 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we do not restrict the range of problem reports, and as opposed to (Munro, 2011), matching is automatic. Systems such as that of Seki (2011)11 or Munro (2013)12 are successful examples of crisis crowdsourcing, but these require extensive human intervention to coordinate useful information. Another category of related work relevant to our task is troubleshooting. Baldwin et al. (2007) and Raghavan et al. (2010) use discussion forums to solve technical problems using supervised learning methods, but these approaches presume that the solution of a specific problem is within the same thread. In our work we do not employ structural characteristics of tweets as restrictions (e.g., a problem report and its aid message need to be in the same tweet chain). </context>
</contexts>
<marker>2013</marker>
<rawString>National Police Agency of Japan. 2013. Damage situation and public countermeasures associated with 2011 Tohoku district – off the Pacific Ocean Earthquake. http://www.npa.go.jp/archive/ keibi/biki/higaijokyo_e.pdf. (accessed on 30 April, 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Neubig</author>
<author>Yuichiroh Matsubayashi</author>
<author>Masato Hagiwara</author>
<author>Koji Murakami</author>
</authors>
<title>Safety information mining ― what can NLP do in a disaster ―.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP</booktitle>
<pages>965--973</pages>
<contexts>
<context position="40703" citStr="Neubig et al. (2011)" startWordPosition="6444" endWordPosition="6447">R&amp;EX at the same data point. The improvement in precision when using TR&amp;EX is statistically significant in both settings (p &lt; 0.01). 6 Related Work Twitter has been observed as a platform for situational awareness during various crisis situations (Starbird et al., 2010; Vieweg et al., 2010), as sensors for an earthquake reporting system (Sakaki et al., 2010; Okazaki and Matsuo, 2010) or to detect epidemics (Aramaki et al., 2011). Besides Twitter, blogs or forums have also been the target of community response analysis (Qu et al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we do not restrict the range of problem reports, and as opposed to (Munro, 2011), matching is automatic. Systems such as that of Seki (2011)11 or Munro (2013)12 are successful examples of crisis crowdsourcing, but these require extensive</context>
</contexts>
<marker>Neubig, Matsubayashi, Hagiwara, Murakami, 2011</marker>
<rawString>Graham Neubig, Yuichiroh Matsubayashi, Masato Hagiwara, and Koji Murakami. 2011. Safety information mining ― what can NLP do in a disaster ―. In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP 2011), pages 965–973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong-Hoon Oh</author>
<author>Kentaro Torisawa</author>
<author>Chikara Hashimoto</author>
<author>Takuya Kawada</author>
<author>Stijn De Saeger</author>
<author>Jun’ichi Kazama</author>
<author>Yiou Wang</author>
</authors>
<title>Why question answering using sentiment analysis and word classes.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>368--378</pages>
<marker>Oh, Torisawa, Hashimoto, Kawada, De Saeger, Kazama, Wang, 2012</marker>
<rawString>Jong-Hoon Oh, Kentaro Torisawa, Chikara Hashimoto, Takuya Kawada, Stijn De Saeger, Jun’ichi Kazama, and Yiou Wang. 2012. Why question answering using sentiment analysis and word classes. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL 2012), pages 368–378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong-Hoon Oh</author>
<author>Kentaro Torisawa</author>
<author>Chikara Hashimoto</author>
<author>Motoki Sano</author>
<author>Stijn De Saeger</author>
<author>Kiyonori Ohtake</author>
</authors>
<title>Why-question answering using intra- and inter-sentential causal relations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<marker>Oh, Torisawa, Hashimoto, Sano, De Saeger, Ohtake, 2013</marker>
<rawString>Jong-Hoon Oh, Kentaro Torisawa, Chikara Hashimoto, Motoki Sano, Stijn De Saeger, and Kiyonori Ohtake. 2013. Why-question answering using intra- and inter-sentential causal relations. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyonori Ohtake</author>
<author>Kentaro Torisawa</author>
<author>Jun Goto</author>
<author>Stijn De Saeger</author>
</authors>
<title>Saigaiji ni okeru hisaisha to kyuuen kyuujosha kan no souhoko komyunikeeshon. (Bi-directional communication between victims and rescures during a crisis). In Proceeding of the Nineteenth Annual Meeting of The Association for Natural Language Processing.</title>
<date>2013</date>
<note>(in Japanese).</note>
<marker>Ohtake, Torisawa, Goto, De Saeger, 2013</marker>
<rawString>Kiyonori Ohtake, Kentaro Torisawa, Jun Goto, and Stijn De Saeger. 2013. Saigaiji ni okeru hisaisha to kyuuen kyuujosha kan no souhoko komyunikeeshon. (Bi-directional communication between victims and rescures during a crisis). In Proceeding of the Nineteenth Annual Meeting of The Association for Natural Language Processing. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Okazaki</author>
<author>Yutaka Matsuo</author>
</authors>
<title>Semantic Twitter: Analyzing tweets for real-time event notification.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2008/2009 international conference on Social software: Recent trends and developments in social software (BlogTalk</booktitle>
<pages>63--74</pages>
<contexts>
<context position="40469" citStr="Okazaki and Matsuo, 2010" startWordPosition="6400" endWordPosition="6403">00 matches, PROPOSED’s 62.36% is 10.48 points higher than that of PROPOSED-TR&amp;EX. For unseen problem/aid nuclei PROPOSED method’s average precision of 58.57% calculated at the top 3,800 matches is 5.47 points higher than that of PROPOSED-TR&amp;EX at the same data point. The improvement in precision when using TR&amp;EX is statistically significant in both settings (p &lt; 0.01). 6 Related Work Twitter has been observed as a platform for situational awareness during various crisis situations (Starbird et al., 2010; Vieweg et al., 2010), as sensors for an earthquake reporting system (Sakaki et al., 2010; Okazaki and Matsuo, 2010) or to detect epidemics (Aramaki et al., 2011). Besides Twitter, blogs or forums have also been the target of community response analysis (Qu et al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we </context>
</contexts>
<marker>Okazaki, Matsuo, 2010</marker>
<rawString>Makoto Okazaki and Yutaka Matsuo. 2010. Semantic Twitter: Analyzing tweets for real-time event notification. In Proceedings of the 2008/2009 international conference on Social software: Recent trends and developments in social software (BlogTalk 2008), pages 63–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Lyman Ott</author>
<author>Michael T Longnecker</author>
</authors>
<title>An Introduction to Statistical Methods and Data Analysis, chapter 10.2. Brooks Cole, 6th edition.</title>
<date>2010</date>
<contexts>
<context position="31319" citStr="Ott and Longnecker, 2010" startWordPosition="5005" endWordPosition="5008"> either of their problem nouns or templates appeared in the nuclei of T′. The resulting new training data (called R′) and test data (T′) consist of 6,484 and 407 tweet-nucleus candidate pairs, respectively. We trained our problem report recognizer using R′ and tested its performance using T′. Figure 2 shows the precision-recall curves obtained by changing the threshold on the SVM scores. The effectiveness of excitation polarities and trouble expressions was more evident in this setting. The PROPOSED’s performance was actually better in this setting (almost 50% recall at population proportion (Ott and Longnecker, 2010) using SVM-threshold=0. PROPOSED-TR&amp;EX PROPOSED Figure 2: Precision-recall curves of problem report recognizers against unseen problem nuclei. more that 80% precision), than the previous setting, showing that excitation templates and trouble expressions are crucial in achieving high performance especially for unseen problem nuclei. The same was confirmed when we removed excitation polarity and trouble expression related features, with performance dropping by 7.43 points in terms of average precision. The improvement in precision when using TR&amp;EX is statistically significant (p &lt; 0.01). This im</context>
</contexts>
<marker>Ott, Longnecker, 2010</marker>
<rawString>R. Lyman Ott and Michael T. Longnecker, 2010. An Introduction to Statistical Methods and Data Analysis, chapter 10.2. Brooks Cole, 6th edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yan Qu</author>
<author>Philip Fei Wu</author>
<author>Xiaoqing Wang</author>
</authors>
<title>Online community response to major disaster: A study of Tianya forum in the 2008 Sichuan Earthquake.</title>
<date>2009</date>
<booktitle>In 42st Hawaii International International Conference on Systems Science (HICSS-42),</booktitle>
<pages>1--11</pages>
<contexts>
<context position="40623" citStr="Qu et al., 2009" startWordPosition="6428" endWordPosition="6431">ated at the top 3,800 matches is 5.47 points higher than that of PROPOSED-TR&amp;EX at the same data point. The improvement in precision when using TR&amp;EX is statistically significant in both settings (p &lt; 0.01). 6 Related Work Twitter has been observed as a platform for situational awareness during various crisis situations (Starbird et al., 2010; Vieweg et al., 2010), as sensors for an earthquake reporting system (Sakaki et al., 2010; Okazaki and Matsuo, 2010) or to detect epidemics (Aramaki et al., 2011). Besides Twitter, blogs or forums have also been the target of community response analysis (Qu et al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we do not restrict the range of problem reports, and as opposed to (Munro, 2011), matching is automatic. Systems such as that of Seki (2011)11 or Munro (2013</context>
</contexts>
<marker>Qu, Wu, Wang, 2009</marker>
<rawString>Yan Qu, Philip Fei Wu, and Xiaoqing Wang. 2009. Online community response to major disaster: A study of Tianya forum in the 2008 Sichuan Earthquake. In 42st Hawaii International International Conference on Systems Science (HICSS-42), pages 1–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preethi Raghavan</author>
<author>Rose Catherine</author>
<author>Shajith Ikbal</author>
<author>Nanda Kambhatla</author>
<author>Debapriyo Majumdar</author>
</authors>
<title>Extracting problem and resolution information from online discussion forums.</title>
<date>2010</date>
<booktitle>In Proceedings of the 16th International Conference on Management of Data (COMAD</booktitle>
<contexts>
<context position="41479" citStr="Raghavan et al. (2010)" startWordPosition="6563" endWordPosition="6566">); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we do not restrict the range of problem reports, and as opposed to (Munro, 2011), matching is automatic. Systems such as that of Seki (2011)11 or Munro (2013)12 are successful examples of crisis crowdsourcing, but these require extensive human intervention to coordinate useful information. Another category of related work relevant to our task is troubleshooting. Baldwin et al. (2007) and Raghavan et al. (2010) use discussion forums to solve technical problems using supervised learning methods, but these approaches presume that the solution of a specific problem is within the same thread. In our work we do not employ structural characteristics of tweets as restrictions (e.g., a problem report and its aid message need to be in the same tweet chain). 7 Conclusions In this paper, we proposed a method to discover matches between problem reports and aid messages from tweets in large-scale disasters. Through a series of experiments, we demonstrated that the performance of the problem-aid matching can be i</context>
</contexts>
<marker>Raghavan, Catherine, Ikbal, Kambhatla, Majumdar, 2010</marker>
<rawString>Preethi Raghavan, Rose Catherine, Shajith Ikbal, Nanda Kambhatla, and Debapriyo Majumdar. 2010. Extracting problem and resolution information from online discussion forums. In Proceedings of the 16th International Conference on Management of Data (COMAD 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeo Saijo</author>
</authors>
<title>Hito-o tasukeru sungoi shikumi. (A stunning system that saves people). Diamond Inc.</title>
<date>2012</date>
<note>(in Japanese).</note>
<contexts>
<context position="2662" citStr="Saijo, 2012" startWordPosition="397" endWordPosition="398">permarket in Sendai, you can still buy water and infant formula. If A1 would have been forwarded to the sender of P1, it could have helped since it would help the “friend” to obtain infant formula. But in reality, the majority of such reports/messages, especially unforeseen ones went unnoticed amongst the mass of information (Ohtake et al., 2013). In addition, there were cases where many humanitarian organizations responded to the same problems and wasted precious resources. For instance, many volunteers responded to problems which were heavily reported by public media, leading to oversupply (Saijo, 2012). Such waste of resources could have been avoided if the organizations would have successfully shared the aid messages for the same problems. Such observations motivated this work. We developed methods for recognizing problem reports and aid messages in tweets and finding proper matches between them. By browsing the discovered matches, victims can be assisted to overcome their problems, and humanitarian organizations can avoid redundant relief efforts. We define problem reports, aid messages and their successful matches as follows. Problem report: A tweet that informs about the possibility or </context>
</contexts>
<marker>Saijo, 2012</marker>
<rawString>Takeo Saijo. 2012. Hito-o tasukeru sungoi shikumi. (A stunning system that saves people). Diamond Inc. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeshi Sakaki</author>
<author>Makoto Okazaki</author>
<author>Yutaka Matsuo</author>
</authors>
<title>Earthquake shakes Twitter users: Real-time event detection by social sensors.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th International Conference on World Wide Web (WWW</booktitle>
<pages>851--860</pages>
<contexts>
<context position="40442" citStr="Sakaki et al., 2010" startWordPosition="6396" endWordPosition="6399">ated over the top 7,200 matches, PROPOSED’s 62.36% is 10.48 points higher than that of PROPOSED-TR&amp;EX. For unseen problem/aid nuclei PROPOSED method’s average precision of 58.57% calculated at the top 3,800 matches is 5.47 points higher than that of PROPOSED-TR&amp;EX at the same data point. The improvement in precision when using TR&amp;EX is statistically significant in both settings (p &lt; 0.01). 6 Related Work Twitter has been observed as a platform for situational awareness during various crisis situations (Starbird et al., 2010; Vieweg et al., 2010), as sensors for an earthquake reporting system (Sakaki et al., 2010; Okazaki and Matsuo, 2010) or to detect epidemics (Aramaki et al., 2011). Besides Twitter, blogs or forums have also been the target of community response analysis (Qu et al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishin</context>
</contexts>
<marker>Sakaki, Okazaki, Matsuo, 2010</marker>
<rawString>Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo. 2010. Earthquake shakes Twitter users: Real-time event detection by social sensors. In Proceedings of the 19th International Conference on World Wide Web (WWW 2010), pages 851–860.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Motoki Sano</author>
<author>Istv´an Varga</author>
<author>Jun’ichi Kazama</author>
<author>Kentaro Torisawa</author>
</authors>
<title>Requests in tweets during a crisis: A systemic functional analysis of tweets on the Great East Japan Earthquake and the Fukushima Daiichi nuclear disaster.</title>
<date>2012</date>
<booktitle>In Papers from the 39th International Systemic Functional Congress (ISFC39),</booktitle>
<pages>135--140</pages>
<contexts>
<context position="1784" citStr="Sano et al., 2012" startWordPosition="250" endWordPosition="253">a large scale disaster situation by facilitating communication between victims and humanitarian organizations. 1 Introduction The 2011 Great East Japan Earthquake in March 11, 2011 killed 15,883 people and destroyed over 260,000 households (National Police Agency of Japan, 2013). Accustomed way of living suddenly became unmanageable and people found themselves in extreme conditions for months. Just after the disaster, many people used Twitter for posting problem reports and aid messages as it functioned while most communication channels suffered disruptions (Winn, 2011; Acar and Muraki, 2011; Sano et al., 2012). Examples of such problem reports and aid messages, translated from Japanese tweets, are given below (P1, A1). P1 My friend said infant formula is sold out. If somebody knows shops in Sendai-city where they still have it in stock, please let us know. A1 At Jusco supermarket in Sendai, you can still buy water and infant formula. If A1 would have been forwarded to the sender of P1, it could have helped since it would help the “friend” to obtain infant formula. But in reality, the majority of such reports/messages, especially unforeseen ones went unnoticed amongst the mass of information (Ohtake</context>
</contexts>
<marker>Sano, Varga, Kazama, Torisawa, 2012</marker>
<rawString>Motoki Sano, Istv´an Varga, Jun’ichi Kazama, and Kentaro Torisawa. 2012. Requests in tweets during a crisis: A systemic functional analysis of tweets on the Great East Japan Earthquake and the Fukushima Daiichi nuclear disaster. In Papers from the 39th International Systemic Functional Congress (ISFC39), pages 135–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haruyuki Seki</author>
</authors>
<title>Higashi-nihon daishinsai fukkou shien platform sinsai.info no naritachi to kongo no kadai. (The organizational structure of sinsai.info restoration support platform for the 2011 Great East Japan Earthquake and future challenges).</title>
<date>2011</date>
<journal>Journal of digital practices,</journal>
<volume>2</volume>
<issue>4</issue>
<note>(in Japanese).</note>
<contexts>
<context position="41206" citStr="Seki (2011)" startWordPosition="6524" endWordPosition="6525">se analysis (Qu et al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we do not restrict the range of problem reports, and as opposed to (Munro, 2011), matching is automatic. Systems such as that of Seki (2011)11 or Munro (2013)12 are successful examples of crisis crowdsourcing, but these require extensive human intervention to coordinate useful information. Another category of related work relevant to our task is troubleshooting. Baldwin et al. (2007) and Raghavan et al. (2010) use discussion forums to solve technical problems using supervised learning methods, but these approaches presume that the solution of a specific problem is within the same thread. In our work we do not employ structural characteristics of tweets as restrictions (e.g., a problem report and its aid message need to be in the s</context>
</contexts>
<marker>Seki, 2011</marker>
<rawString>Haruyuki Seki. 2011. Higashi-nihon daishinsai fukkou shien platform sinsai.info no naritachi to kongo no kadai. (The organizational structure of sinsai.info restoration support platform for the 2011 Great East Japan Earthquake and future challenges). Journal of digital practices, 2(4):237–241. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kate Starbird</author>
<author>Leysia Palen</author>
<author>Amanda L Hughes</author>
<author>Sarah Vieweg</author>
</authors>
<title>Chatter on the red: What hazards threat reveals about the social life of microblogged information.</title>
<date>2010</date>
<booktitle>In Proceedings of The 2010 ACM Conference on Computer Supported Cooperative Work (CSCW</booktitle>
<pages>241--250</pages>
<contexts>
<context position="40352" citStr="Starbird et al., 2010" startWordPosition="6380" endWordPosition="6383"> features contribute to this task. In the ‘all’ setting in terms of average precision calculated over the top 7,200 matches, PROPOSED’s 62.36% is 10.48 points higher than that of PROPOSED-TR&amp;EX. For unseen problem/aid nuclei PROPOSED method’s average precision of 58.57% calculated at the top 3,800 matches is 5.47 points higher than that of PROPOSED-TR&amp;EX at the same data point. The improvement in precision when using TR&amp;EX is statistically significant in both settings (p &lt; 0.01). 6 Related Work Twitter has been observed as a platform for situational awareness during various crisis situations (Starbird et al., 2010; Vieweg et al., 2010), as sensors for an earthquake reporting system (Sakaki et al., 2010; Okazaki and Matsuo, 2010) or to detect epidemics (Aramaki et al., 2011). Besides Twitter, blogs or forums have also been the target of community response analysis (Qu et al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately),</context>
</contexts>
<marker>Starbird, Palen, Hughes, Vieweg, 2010</marker>
<rawString>Kate Starbird, Leysia Palen, Amanda L. Hughes, and Sarah Vieweg. 2010. Chatter on the red: What hazards threat reveals about the social life of microblogged information. In Proceedings of The 2010 ACM Conference on Computer Supported Cooperative Work (CSCW 2010), pages 241–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristen Torrey</author>
<author>Moira Burke</author>
<author>Matthew L Lee</author>
<author>Anind K Dey</author>
<author>Susan R Fussell</author>
<author>Sara B Kiesler</author>
</authors>
<title>Connected giving: Ordinary people coordinating disaster relief on the Internet.</title>
<date>2007</date>
<booktitle>In Proceedings of the 40th Annual Hawaii International Conference on System Sciences (HICSS-40),</booktitle>
<pages>179--188</pages>
<contexts>
<context position="40645" citStr="Torrey et al., 2007" startWordPosition="6432" endWordPosition="6435">,800 matches is 5.47 points higher than that of PROPOSED-TR&amp;EX at the same data point. The improvement in precision when using TR&amp;EX is statistically significant in both settings (p &lt; 0.01). 6 Related Work Twitter has been observed as a platform for situational awareness during various crisis situations (Starbird et al., 2010; Vieweg et al., 2010), as sensors for an earthquake reporting system (Sakaki et al., 2010; Okazaki and Matsuo, 2010) or to detect epidemics (Aramaki et al., 2011). Besides Twitter, blogs or forums have also been the target of community response analysis (Qu et al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being performed manually. Our work differs from (Neubig et al., 2011) and (Ishino et al., 2012) in that we do not restrict the range of problem reports, and as opposed to (Munro, 2011), matching is automatic. Systems such as that of Seki (2011)11 or Munro (2013)12 are successful exa</context>
</contexts>
<marker>Torrey, Burke, Lee, Dey, Fussell, Kiesler, 2007</marker>
<rawString>Cristen Torrey, Moira Burke, Matthew L. Lee, Anind K. Dey, Susan R. Fussell, and Sara B. Kiesler. 2007. Connected giving: Ordinary people coordinating disaster relief on the Internet. In Proceedings of the 40th Annual Hawaii International Conference on System Sciences (HICSS-40), pages 179–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katerina Tsagkalidou</author>
<author>Vassiliki Koutsonikola</author>
<author>Athena Vakali</author>
<author>Konstantinos Kafetsios</author>
</authors>
<title>Emotional aware clustering on micro-blogging sources.</title>
<date>2011</date>
<booktitle>In Proceedings of the 4th international conference on Affective computing and intelligent interaction (ACII2011),</booktitle>
<pages>387--396</pages>
<contexts>
<context position="5604" citStr="Tsagkalidou et al., 2011" startWordPosition="879" endWordPosition="883">, they share the same noun. Then, the semantics of predicates in the nuclei is the main factor that decides whether the nuclei constitute a match. We introduce a semantic classification of predicates according to the framework of excitation polarities proposed in Hashimoto et al. (2012). Our hypothesis is that excitation polarities along with trouble expressions can characterize problem reports, aid messages and their matches. We developed a supervised method encoding such information into its features. An evident alternative to this approach is to use sentiment analysis (Mandel et al., 2012; Tsagkalidou et al., 2011) assuming that problem reports should include something ‘bad’ while aid messages describe something ‘good’. However, we will show that this does not work well in our experiments. We think this is due to mismatch between the concepts of problem/aid and sentiment polarity. Note that previous work on ‘demand’ recognition also found similar tendencies (Kanayama and Nasukawa, 2008). Another issue in this task is, of course, the context surrounding problem/aid nuclei. The fol&apos;We found that out of 500 random tweets only 4.5% of problem reports and 9.1% of aid messages did not contain any problem repo</context>
</contexts>
<marker>Tsagkalidou, Koutsonikola, Vakali, Kafetsios, 2011</marker>
<rawString>Katerina Tsagkalidou, Vassiliki Koutsonikola, Athena Vakali, and Konstantinos Kafetsios. 2011. Emotional aware clustering on micro-blogging sources. In Proceedings of the 4th international conference on Affective computing and intelligent interaction (ACII2011), pages 387–396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarah Vieweg</author>
<author>Amanda L Hughes</author>
<author>Kate Starbird</author>
<author>Leysia Palen</author>
</authors>
<title>Microblogging during two natural hazards events: What Twitter may contribute to situational awareness.</title>
<date>2010</date>
<booktitle>In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI</booktitle>
<pages>1079--1088</pages>
<contexts>
<context position="40374" citStr="Vieweg et al., 2010" startWordPosition="6384" endWordPosition="6387"> this task. In the ‘all’ setting in terms of average precision calculated over the top 7,200 matches, PROPOSED’s 62.36% is 10.48 points higher than that of PROPOSED-TR&amp;EX. For unseen problem/aid nuclei PROPOSED method’s average precision of 58.57% calculated at the top 3,800 matches is 5.47 points higher than that of PROPOSED-TR&amp;EX at the same data point. The improvement in precision when using TR&amp;EX is statistically significant in both settings (p &lt; 0.01). 6 Related Work Twitter has been observed as a platform for situational awareness during various crisis situations (Starbird et al., 2010; Vieweg et al., 2010), as sensors for an earthquake reporting system (Sakaki et al., 2010; Okazaki and Matsuo, 2010) or to detect epidemics (Aramaki et al., 2011). Besides Twitter, blogs or forums have also been the target of community response analysis (Qu et al., 2009; Torrey et al., 2007). Similar to our work are the ones of Neubig et al. (2011) and Ishino et al. (2012), who tackle specific problems that occur during disasters (i.e., safety information and transportation information, respectively); and Munro (2011), who extracted “actionable messages” (requests and aids, indiscriminately), matching being perfor</context>
</contexts>
<marker>Vieweg, Hughes, Starbird, Palen, 2010</marker>
<rawString>Sarah Vieweg, Amanda L. Hughes, Kate Starbird, and Leysia Palen. 2010. Microblogging during two natural hazards events: What Twitter may contribute to situational awareness. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2010), pages 1079–1088.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Winn</author>
</authors>
<title>Japan tsunami disaster: As Japan scrambles, Twitter reigns.</title>
<date>2011</date>
<journal>GlobalPost,</journal>
<volume>18</volume>
<contexts>
<context position="1741" citStr="Winn, 2011" startWordPosition="243" endWordPosition="244"> contributes to problem-solving in a large scale disaster situation by facilitating communication between victims and humanitarian organizations. 1 Introduction The 2011 Great East Japan Earthquake in March 11, 2011 killed 15,883 people and destroyed over 260,000 households (National Police Agency of Japan, 2013). Accustomed way of living suddenly became unmanageable and people found themselves in extreme conditions for months. Just after the disaster, many people used Twitter for posting problem reports and aid messages as it functioned while most communication channels suffered disruptions (Winn, 2011; Acar and Muraki, 2011; Sano et al., 2012). Examples of such problem reports and aid messages, translated from Japanese tweets, are given below (P1, A1). P1 My friend said infant formula is sold out. If somebody knows shops in Sendai-city where they still have it in stock, please let us know. A1 At Jusco supermarket in Sendai, you can still buy water and infant formula. If A1 would have been forwarded to the sender of P1, it could have helped since it would help the “friend” to obtain infant formula. But in reality, the majority of such reports/messages, especially unforeseen ones went unnoti</context>
</contexts>
<marker>Winn, 2011</marker>
<rawString>Patrick Winn. 2011. Japan tsunami disaster: As Japan scrambles, Twitter reigns. GlobalPost, 18 March.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>