<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.089632">
<note confidence="0.948221">
Proceedings of HLT-NAACL 2003
Demonstrations , pp. 33-34
Edmonton, May-June 2003
</note>
<title confidence="0.997191">
Identifying Opinionated Sentences
</title>
<author confidence="0.990319">
Theresa Wilson
</author>
<affiliation confidence="0.985202">
Intelligent Systems Program
University of Pittsburgh
</affiliation>
<email confidence="0.990927">
twilson@cs.pitt.edu
</email>
<author confidence="0.999143">
David R. Pierce
</author>
<affiliation confidence="0.989653">
Department of Computer Science
and Engineering
University of Buffalo
The State University of New York
</affiliation>
<email confidence="0.990967">
drpierce@cse.buffalo.edu
</email>
<author confidence="0.992371">
Janyce Wiebe
</author>
<affiliation confidence="0.9992715">
Department of Computer Science
University of Pittsburgh
</affiliation>
<email confidence="0.993688">
wiebe@cs.pitt.edu
</email>
<sectionHeader confidence="0.999723" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999847153846154">
Natural language processing applications that summa-
rize or answer questions about news and other discourse
need to process information about opinions, emotions,
and evaluations. For example, a question answering sys-
tem that could identify opinions in the news could answer
questions such as the following:
Was the 2002 presidential election in Zim-
babwe regarded as fair?
What was the world-wide reaction to the
2001 annual U.S. report on human rights?
In the news, editorials, reviews, and letters to the editor
are sources for finding opinions, but even in news reports,
segments presenting objective facts are often mixed with
segments presenting opinions and verbal reactions. This
is especially true for articles that report on controversial
or “lightning rod” topics. Thus, there is a need to be able
to identify which sentences in a text actually contain ex-
pressions of opinions and emotions.
We demonstrate a system that identifies opinionated
sentences. In general, an opinionated sentence is a sen-
tence that contains a significant expression of an opin-
ion, belief, emotion, evaluation, speculation, or senti-
ment. The system was built using data and other re-
sources from a summer workshop on multi-perspective
question answering (Wiebe et al., 2003) funded under
ARDA NRRC.1
</bodyText>
<footnote confidence="0.580869714285714">
&apos;This work was performed in support of the Northeast Re-
gional Research Center (NRRC) which is sponsored by the
Advanced Research and Development Activity in Information
Technology (ARDA), a U.S. Government entity which sponsors
and promotes research of import to the Intelligence Community
which includes but is not limited to the CIA, DIA, NSA, NIMA,
and NRO.
</footnote>
<sectionHeader confidence="0.963336" genericHeader="categories and subject descriptors">
2 Opinion Recognition System
</sectionHeader>
<subsectionHeader confidence="0.955717">
2.1 System Architecture
</subsectionHeader>
<bodyText confidence="0.999973916666667">
The opinion recognition system takes as input a URL
or raw text document and produces as output an HTML
version of the document with the opinionated sentences
found by the system highlighted in bold. Figure 2.1
shows a news article that was processed by the system.
When the opinion recognition system receives a docu-
ment, it first uses GATE (Cunningham et al., 2002) (mod-
ified to run in batch mode) to tokenize, sentence split,
and part-of-speech tag the document. Then the document
is stemmed and searched for features of opinionated lan-
guage. Finally, opinionated sentences are identified using
the features found, and they are highlighted in the output.
</bodyText>
<subsectionHeader confidence="0.923855">
2.2 Features
</subsectionHeader>
<bodyText confidence="0.999826">
The system uses a combination of manually and auto-
matically identified features. The manually identified
features were culled from a variety of sources, includ-
ing (Levin, 1993) and (Framenet, 2002). In addition to
features learned in previous work (Wiebe et al., 1999;
Wiebe et al., 2001), the automatically identified features
include new features that were learned using information
extraction techniques (Riloffand Jones, 1999; Thelen and
Riloff, 2002) applied to an unannotated corpus of world
news documents.
</bodyText>
<subsectionHeader confidence="0.981453">
2.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999621777777778">
We evaluated the system component that identifies opin-
ionated sentences on a corpus of 109 documents (2200
sentences) from the world news. These articles were an-
notated for expressions of opinions as part of the summer
workshop on multi-perspective question answering. In
this test corpus, 59% of sentences are opinionated sen-
tences. By varying system settings, the opinionated sen-
tence recognizer may be tuned to be very precise (91%
precision), identifying only those sentences it is very sure
</bodyText>
<figureCaption confidence="0.989208">
Figure 1: Example of an article processed by the opinionated sentence recognition system. Sentences identified by the
system are highlighted in bold.
</figureCaption>
<bodyText confidence="0.998014666666667">
are opinionated (33% recall), or less precise (82% preci-
sion), identifing many more opinionated sentences (77%
recall), but also making more errors.
</bodyText>
<sectionHeader confidence="0.813755" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.911526166666667">
Hamish Cunningham, Diana Maynard, Kalina
Bontcheva, and Valentin Tablan. 2002. GATE:
A framework and graphical development environment
for robust nlp tools and applications. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics.
</bodyText>
<reference confidence="0.989792148148148">
Framenet. 2002. http://www.icsi.berkeley.edu/ framenet/.
Beth Levin. 1993. English Verb Classes and Alter-
nations: A Preliminary Investigation. University of
Chicago Press, Chicago.
E. Riloff and R. Jones. 1999. Learning Dictionaries for
Information Extraction by Multi-Level Bootstrapping.
In Proceedings of the Sixteenth National Conference
on Artificial Intelligence.
M. Thelen and E. Riloff. 2002. A bootstrapping method
for learning semantic lexicons using extraction pattern
contexts. In Proceedings of the 2002 Conference on
Empirical Methods in Natural Language Processing.
J. Wiebe, R. Bruce, and T. O’Hara. 1999. Development
and use of a gold standard data set for subjectivity clas-
sifications. In Proc. 37th Annual Meeting of the Assoc.
for Computational Linguistics (ACL-99), pages 246–
253, University of Maryland, June. ACL.
J. Wiebe, T. Wilson, and M. Bell. 2001. Identifying col-
locations for recognizing opinions. In Proc. ACL-01
Workshop on Collocation: Computational Extraction,
Analysis, and Exploitation, July.
J. Wiebe, E. Breck, C. Buckley, C. Cardie, P. Davis,
B. Fraser, D. Litman, D. Pierce, E. Riloff, T. Wilson,
D. Day, and M. Maybury. 2003. Recognizing and
organizing opinions expressed in the world press. In
Working Notes - New Directions in Question Answer-
ing (AAAI Spring Symposium Series).
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.685886">
<note confidence="0.984363">Proceedings of HLT-NAACL 2003 Demonstrations , pp. 33-34 Edmonton, May-June 2003</note>
<title confidence="0.99854">Identifying Opinionated Sentences</title>
<author confidence="0.990127">Theresa</author>
<affiliation confidence="0.997401">Intelligent Systems University of</affiliation>
<email confidence="0.995497">twilson@cs.pitt.edu</email>
<author confidence="0.999481">R David</author>
<affiliation confidence="0.997582">Department of Computer and University of The State University of New</affiliation>
<email confidence="0.999319">drpierce@cse.buffalo.edu</email>
<author confidence="0.772284">Janyce</author>
<affiliation confidence="0.9997625">Department of Computer University of</affiliation>
<email confidence="0.957954">wiebe@cs.pitt.edu</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Framenet</author>
</authors>
<date>2002</date>
<note>http://www.icsi.berkeley.edu/ framenet/.</note>
<contexts>
<context position="3013" citStr="Framenet, 2002" startWordPosition="456" endWordPosition="457"> the system. When the opinion recognition system receives a document, it first uses GATE (Cunningham et al., 2002) (modified to run in batch mode) to tokenize, sentence split, and part-of-speech tag the document. Then the document is stemmed and searched for features of opinionated language. Finally, opinionated sentences are identified using the features found, and they are highlighted in the output. 2.2 Features The system uses a combination of manually and automatically identified features. The manually identified features were culled from a variety of sources, including (Levin, 1993) and (Framenet, 2002). In addition to features learned in previous work (Wiebe et al., 1999; Wiebe et al., 2001), the automatically identified features include new features that were learned using information extraction techniques (Riloffand Jones, 1999; Thelen and Riloff, 2002) applied to an unannotated corpus of world news documents. 2.3 Evaluation We evaluated the system component that identifies opinionated sentences on a corpus of 109 documents (2200 sentences) from the world news. These articles were annotated for expressions of opinions as part of the summer workshop on multi-perspective question answering.</context>
</contexts>
<marker>Framenet, 2002</marker>
<rawString>Framenet. 2002. http://www.icsi.berkeley.edu/ framenet/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations: A Preliminary Investigation.</title>
<date>1993</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="2992" citStr="Levin, 1993" startWordPosition="453" endWordPosition="454">t was processed by the system. When the opinion recognition system receives a document, it first uses GATE (Cunningham et al., 2002) (modified to run in batch mode) to tokenize, sentence split, and part-of-speech tag the document. Then the document is stemmed and searched for features of opinionated language. Finally, opinionated sentences are identified using the features found, and they are highlighted in the output. 2.2 Features The system uses a combination of manually and automatically identified features. The manually identified features were culled from a variety of sources, including (Levin, 1993) and (Framenet, 2002). In addition to features learned in previous work (Wiebe et al., 1999; Wiebe et al., 2001), the automatically identified features include new features that were learned using information extraction techniques (Riloffand Jones, 1999; Thelen and Riloff, 2002) applied to an unannotated corpus of world news documents. 2.3 Evaluation We evaluated the system component that identifies opinionated sentences on a corpus of 109 documents (2200 sentences) from the world news. These articles were annotated for expressions of opinions as part of the summer workshop on multi-perspectiv</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes and Alternations: A Preliminary Investigation. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>R Jones</author>
</authors>
<title>Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping.</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth National Conference on Artificial Intelligence.</booktitle>
<marker>Riloff, Jones, 1999</marker>
<rawString>E. Riloff and R. Jones. 1999. Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping. In Proceedings of the Sixteenth National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Thelen</author>
<author>E Riloff</author>
</authors>
<title>A bootstrapping method for learning semantic lexicons using extraction pattern contexts.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="3271" citStr="Thelen and Riloff, 2002" startWordPosition="491" endWordPosition="494">rched for features of opinionated language. Finally, opinionated sentences are identified using the features found, and they are highlighted in the output. 2.2 Features The system uses a combination of manually and automatically identified features. The manually identified features were culled from a variety of sources, including (Levin, 1993) and (Framenet, 2002). In addition to features learned in previous work (Wiebe et al., 1999; Wiebe et al., 2001), the automatically identified features include new features that were learned using information extraction techniques (Riloffand Jones, 1999; Thelen and Riloff, 2002) applied to an unannotated corpus of world news documents. 2.3 Evaluation We evaluated the system component that identifies opinionated sentences on a corpus of 109 documents (2200 sentences) from the world news. These articles were annotated for expressions of opinions as part of the summer workshop on multi-perspective question answering. In this test corpus, 59% of sentences are opinionated sentences. By varying system settings, the opinionated sentence recognizer may be tuned to be very precise (91% precision), identifying only those sentences it is very sure Figure 1: Example of an articl</context>
</contexts>
<marker>Thelen, Riloff, 2002</marker>
<rawString>M. Thelen and E. Riloff. 2002. A bootstrapping method for learning semantic lexicons using extraction pattern contexts. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>R Bruce</author>
<author>T O’Hara</author>
</authors>
<title>Development and use of a gold standard data set for subjectivity classifications.</title>
<date>1999</date>
<booktitle>In Proc. 37th Annual Meeting of the Assoc. for Computational Linguistics (ACL-99),</booktitle>
<pages>246--253</pages>
<publisher>ACL.</publisher>
<institution>University of Maryland,</institution>
<marker>Wiebe, Bruce, O’Hara, 1999</marker>
<rawString>J. Wiebe, R. Bruce, and T. O’Hara. 1999. Development and use of a gold standard data set for subjectivity classifications. In Proc. 37th Annual Meeting of the Assoc. for Computational Linguistics (ACL-99), pages 246– 253, University of Maryland, June. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>T Wilson</author>
<author>M Bell</author>
</authors>
<title>Identifying collocations for recognizing opinions.</title>
<date>2001</date>
<booktitle>In Proc. ACL-01 Workshop on Collocation: Computational Extraction, Analysis, and Exploitation,</booktitle>
<contexts>
<context position="3104" citStr="Wiebe et al., 2001" startWordPosition="470" endWordPosition="473">E (Cunningham et al., 2002) (modified to run in batch mode) to tokenize, sentence split, and part-of-speech tag the document. Then the document is stemmed and searched for features of opinionated language. Finally, opinionated sentences are identified using the features found, and they are highlighted in the output. 2.2 Features The system uses a combination of manually and automatically identified features. The manually identified features were culled from a variety of sources, including (Levin, 1993) and (Framenet, 2002). In addition to features learned in previous work (Wiebe et al., 1999; Wiebe et al., 2001), the automatically identified features include new features that were learned using information extraction techniques (Riloffand Jones, 1999; Thelen and Riloff, 2002) applied to an unannotated corpus of world news documents. 2.3 Evaluation We evaluated the system component that identifies opinionated sentences on a corpus of 109 documents (2200 sentences) from the world news. These articles were annotated for expressions of opinions as part of the summer workshop on multi-perspective question answering. In this test corpus, 59% of sentences are opinionated sentences. By varying system setting</context>
</contexts>
<marker>Wiebe, Wilson, Bell, 2001</marker>
<rawString>J. Wiebe, T. Wilson, and M. Bell. 2001. Identifying collocations for recognizing opinions. In Proc. ACL-01 Workshop on Collocation: Computational Extraction, Analysis, and Exploitation, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>E Breck</author>
<author>C Buckley</author>
<author>C Cardie</author>
<author>P Davis</author>
<author>B Fraser</author>
<author>D Litman</author>
<author>D Pierce</author>
<author>E Riloff</author>
<author>T Wilson</author>
<author>D Day</author>
<author>M Maybury</author>
</authors>
<title>Recognizing and organizing opinions expressed in the world press.</title>
<date>2003</date>
<booktitle>In Working Notes - New Directions in Question Answering (AAAI Spring Symposium Series).</booktitle>
<contexts>
<context position="1705" citStr="Wiebe et al., 2003" startWordPosition="246" endWordPosition="249">presenting opinions and verbal reactions. This is especially true for articles that report on controversial or “lightning rod” topics. Thus, there is a need to be able to identify which sentences in a text actually contain expressions of opinions and emotions. We demonstrate a system that identifies opinionated sentences. In general, an opinionated sentence is a sentence that contains a significant expression of an opinion, belief, emotion, evaluation, speculation, or sentiment. The system was built using data and other resources from a summer workshop on multi-perspective question answering (Wiebe et al., 2003) funded under ARDA NRRC.1 &apos;This work was performed in support of the Northeast Regional Research Center (NRRC) which is sponsored by the Advanced Research and Development Activity in Information Technology (ARDA), a U.S. Government entity which sponsors and promotes research of import to the Intelligence Community which includes but is not limited to the CIA, DIA, NSA, NIMA, and NRO. 2 Opinion Recognition System 2.1 System Architecture The opinion recognition system takes as input a URL or raw text document and produces as output an HTML version of the document with the opinionated sentences f</context>
</contexts>
<marker>Wiebe, Breck, Buckley, Cardie, Davis, Fraser, Litman, Pierce, Riloff, Wilson, Day, Maybury, 2003</marker>
<rawString>J. Wiebe, E. Breck, C. Buckley, C. Cardie, P. Davis, B. Fraser, D. Litman, D. Pierce, E. Riloff, T. Wilson, D. Day, and M. Maybury. 2003. Recognizing and organizing opinions expressed in the world press. In Working Notes - New Directions in Question Answering (AAAI Spring Symposium Series).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>