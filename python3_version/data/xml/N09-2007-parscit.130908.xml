<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.062939">
<title confidence="0.988143">
Translation Corpus Source and Size in Bilingual Retrieval
</title>
<author confidence="0.993181">
Paul McNamee and James Mayfield Charles Nicholas
</author>
<affiliation confidence="0.8352195">
Human Language Technology Center of Excellence Dept. of Computer Science and Electrical Engineering
Johns Hopkins University UMBC
</affiliation>
<address confidence="0.655855">
Baltimore, MD 21218, USA Baltimore, MD 21250, USA
</address>
<email confidence="0.998155">
1paul.mcnamee,james.mayfieldl@jhuapl.edu nicholas@umbc.edu
</email>
<sectionHeader confidence="0.993861" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999635">
This paper explores corpus-based bilingual re-
trieval where the translation corpora used vary
by source and size. We find that the quality of
translation alignments and the domain of the
bitext are important. In some settings these
factors are more critical than corpus size. We
also show that judicious choice of tokeniza-
tion can reduce the amount of bitext required
to obtain good bilingual retrieval performance.
</bodyText>
<sectionHeader confidence="0.998792" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999821958333333">
Large parallel corpora are an increasingly available
commodity. Such texts are the fuel of statistical
machine translation systems and are used in appli-
cations such as cross-language information retrieval
(CLIR). Several beliefs are commonly held regard-
ing the relationship between parallel text quality and
size for CLIR. It is thought that larger texts should
be better, because the problems of data sparseness
and untranslatable terms are reduced. Similarly, par-
allel text from a domain more closely related to a
document collection should lead to better bilingual
retrieval performance, again because better lexical
translations are available.
We compared four sources of parallel text us-
ing CLEF document collections in eight languages
(Braschler and Peters, 2004). English topic sets
from 2000 to 2007 were used. Corpus-based trans-
lation of query terms was performed and documents
were ranked using a statistical language model ap-
proach to retrieval (Ponte and Croft, 1998). Exper-
iments were conducted using unlemmatized words
and character 5-grams. No use was made of pre-
translation query expansion or automated relevance
feedback.
</bodyText>
<page confidence="0.988223">
25
</page>
<sectionHeader confidence="0.983304" genericHeader="method">
2 Translation Corpora
</sectionHeader>
<bodyText confidence="0.999869666666667">
Information about the four parallel texts used in our
experiments is provided in Table 1. We restricted
our focus to Dutch (NL), English (EN), Finnish (FI),
French (FR), German (DE), Italian (IT), Portuguese
(PT), Spanish (ES), and Swedish (SV). These lan-
guages are covered by each parallel corpus.
</bodyText>
<subsectionHeader confidence="0.992972">
2.1 Bible
</subsectionHeader>
<bodyText confidence="0.997410666666667">
The bible corpus is based on the 66 books in the Old
and New Testaments. Alignments at the verse level
were used; there are 31103 verses in the English text.
</bodyText>
<subsectionHeader confidence="0.999716">
2.2 JRC-Acquis v3
</subsectionHeader>
<bodyText confidence="0.9999797">
This parallel text is based on EU laws comprising the
Acquis Communautaire and translations are avail-
able in 22 languages. The English portion of the
acquis data includes 1.2 million aligned passages
containing over 32 million words, which is approxi-
mately 40 times larger than the Biblical text. Align-
ments were provided with the corpus and were pro-
duced by the Vanilla algorithm.1 The alignments are
at roughly the sentence level, but only 85% corre-
spond to a single sentence in both languages.
</bodyText>
<subsectionHeader confidence="0.996908">
2.3 Europarl v3
</subsectionHeader>
<bodyText confidence="0.9999805">
The Europarl corpus was assembled to support ex-
periments in statistical machine translation (Koehn,
2005). The documents consist of transcribed dia-
logue from the official proceedings of the European
Parliament. We used the precomputed alignments
that are provided with the corpus, and which are
based on the algorithm by Gale and Church (1991).
The alignments are believed to be of high quality.
</bodyText>
<footnote confidence="0.6993555">
1Available from http://nl.ijs.si/telri/vanilla/
Proceedings of NAACL HLT 2009: Short Papers, pages 25–28,
</footnote>
<note confidence="0.582914">
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<table confidence="0.988676857142857">
Name Words Wrds/doc Alignments Genre Source
bible 785k 25.3 Near Perfect Religious http://unbound.biola.edu/
acquis 32M 26.3 Good EU law (1958 to 2006) http://wt.jrc.it/lt/acquis/
europarl 33M 25.5 Very Good Parliamentary oration http://www.statmt.org/europarl/
(1996 to 2006)
ojeu 84M 34.5 Fair Governmental affairs Derived from documents at
(1998 to 2004) http://europea.eu.int/
</table>
<tableCaption confidence="0.99983">
Table 1: Parallel texts used in experiments.
</tableCaption>
<subsectionHeader confidence="0.994779">
2.4 Official Journal of the EU
</subsectionHeader>
<bodyText confidence="0.999961526315789">
The Official Journal of the European Union covers a
wide range of topics such as agriculture, trade, and
foreign relations. We constructed this parallel cor-
pus by downloading documents dating from January
1998 through April 2004 and converting the texts
from Adobe’s Portable Document Format (PDF) to
ISO-8859-1 encoded text using pdftotext. The doc-
uments were segmented into pages and into para-
graphs consisting of a small number of sentences
(typically 1 to 3); however this process was compli-
cated by the fact that many documents have outline
or tabular formatting. Alignments were produced
using Church’s char align software (1993).
Due to complexities of decoding the PDF, some of
the accented characters were not extracted properly,
but this is a problem mostly for the earlier material
in the collection. In total about 85 million words of
text per language was obtained, which is over twice
the size of either the acquis or europarl collections.
</bodyText>
<sectionHeader confidence="0.996109" genericHeader="method">
3 Translation
</sectionHeader>
<bodyText confidence="0.999805111111111">
Using the pairwise-aligned corpora described above,
parallel indexes for each corpus were created using
words and 5-grams. Query translation was accom-
plished as follows. For each query term s, source
language documents from the aligned collection that
contain s are identified. If no document contains this
term, then it is left untranslated. Each target lan-
guage term t appearing in the corresponding docu-
ments is scored:
</bodyText>
<equation confidence="0.994845">
Score(t) = (Fl(t) − Fc(t)) × IDF(t)1.25 (1)
</equation>
<bodyText confidence="0.996811045454546">
where Fl and Fc are relative document frequencies
based on local subset of documents and the whole
corpus. IDF(t) is the inverse document frequency,
or log2( N
df(t)). The candidate translation with the
highest score replaced the original query term and
the transformed query vector is used for retrieval
against the target language collection.
This is a straightforward approach to query trans-
lation. More sophisticated methods have been pro-
posed, including bidirectional translation (Wang and
Oard, 2006) and use of more than one translation
candidate per query term (Pirkola et al., 2003).
Subword translation, the direct translation of
character n-grams, offers several advantages over
translating words (McNamee and Mayfield, 2005).
N-grams provide morphological normalization,
translations of multiword expressions are suggested
by translation of word-spanning n-grams, and out-
of-vocabulary (OOV) words can be be partly trans-
lated with n-gram fragments. Additionally, there are
few OOV n-grams, at least for n = 4 and n = 5.
</bodyText>
<sectionHeader confidence="0.998662" genericHeader="evaluation">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.9999236">
We describe two experiments. The first examines
the efficacy of the different translation resources and
the second measures the relationship between cor-
pus size and retrieval effectiveness. English was the
sole source language.
</bodyText>
<subsectionHeader confidence="0.992725">
4.1 Translation Resources
</subsectionHeader>
<bodyText confidence="0.999967142857143">
First the relationship between translation source and
bilingual retrieval effectiveness is studied. Table 2
reports mean average precision when word-based to-
kenization and translation was performed for each
of the target collections. For comparison the cor-
responding performance using topics in the target
language (mono) is also given. As expected, the
smallest bitext, bible, performs the worst. Averaged
across the eight languages only 39% relative effec-
tiveness is seen compared to monolingual perfor-
mance. Reports advocating the use of religious texts
for general purpose CLIR may have been overly op-
timistic (Chew et al., 2006). Both acquis and eu-
roparl are roughly 40 times larger in size than bible
</bodyText>
<page confidence="0.973495">
26
</page>
<table confidence="0.999663909090909">
Target mono bible acquis europarl ojeu
DE 0.3303 0.1338 0.1802 0.2427 0.1937
ES 0.4396 0.1454 0.2583 0.3509 0.2786
FI 0.3406 0.1288 0.1286 0.2135 0.1636
FR 0.3638 0.1651 0.2508 0.2942 0.2600
IT 0.3749 0.1080 0.2365 0.2913 0.2405
NL 0.3813 0.1502 0.2474 0.2974 0.2484
PT 0.3162 0.1432 0.2009 0.2365 0.2157
SV 0.3387 0.1509 0.2111 0.2447 0.1861
Average 0.3607 0.1407 0.2142 0.2714 0.2233
39.0% 59.4% 75.3% 61.9%
</table>
<tableCaption confidence="0.9330795">
Table 2: Mean average precision for word-based transla-
tion of English topics using different corpora.
</tableCaption>
<table confidence="0.998695181818182">
Target mono bible acquis europarl ojeu
DE 0.4201 0.1921 0.2952 0.3519 0.3169
ES 0.4609 0.2295 0.3661 0.4294 0.3837
FI 0.5078 0.1886 0.3552 0.3744 0.3743
FR 0.3930 0.2203 0.3013 0.3523 0.3334
IT 0.3997 0.2110 0.2920 0.3395 0.3160
NL 0.4243 0.2132 0.3060 0.3603 0.3276
PT 0.3524 0.1892 0.2544 0.2931 0.2769
SV 0.4271 0.1653 0.3016 0.3203 0.2998
Average 0.4232 0.2012 0.3090 0.3527 0.3286
47.5% 73.0% 83.3% 77.6%
</table>
<tableCaption confidence="0.9924065">
Table 3: Mean average precision using 5-gram transla-
tions of English topics using different corpora.
</tableCaption>
<bodyText confidence="0.999909631578947">
and both do significantly better; however europarl is
clearly superior and achieves 75% of monolingual
effectiveness. Though nearly twice the size, ojeu
fails to outperform europarl and just barely beats
acquis. Likely reasons for this include difficulties
properly converting the ojeu data to text, problem-
atic alignments, and the substantially greater length
of the aligned passages.
The same observations can be seen from Table 3
where 5-grams were used for tokenization and trans-
lation instead of words. The level of performance
with 5-grams is higher and these improvements are
statistically significant with p &lt; 0.01 (t-test).2 Av-
eraged across the eight languages gains from 30% to
47% were seen using 5-grams, depending on the re-
source. As a translation resource europarl still out-
performs the other sources in each of the eight lan-
guages and the relative ordering of {europarl, ojeu,
acquis, bible} is the same in both cases.
</bodyText>
<footnote confidence="0.958463">
2Except in four cases: mono: In ES &amp; IT p &lt; 0.05; bible:
5-grams were not significantly different than words in FI &amp; SV
</footnote>
<subsectionHeader confidence="0.981539">
4.2 Size of Parallel Text
</subsectionHeader>
<bodyText confidence="0.999991083333333">
To investigate how corpus size effects bilingual
retrieval we subsampled europarl and used these
smaller subcorpora for translation. The entire cor-
pus is 33 million words in size, and samples of 1%,
2%, 5%, 10%, 20%, 40%, 60%, and 80% were made
based on counting documents, which for europarl
is equivalent to counting sentences. Samples were
taken by processing the data in chronological order.
In Figure 1 (a-d) the effect of using larger parallel
corpora is plotted for four languages. Mean average
precision is on the vertical axes, and for visual effect
the chart for each language pair uses the same scale.
The general shape of the curves is to rise quickly as
increasing subsets from 1% to 10% are used and to
flatten as size increases further. Curves for the other
four languages (not shown) are quite similar. The
deceleration of improvement with increasing cor-
pus size can be explained by Heap’s Law. Similar
results have been obtained in the few studies that
have sought to quantify bilingual retrieval perfor-
mance as a function of translation resource size (Xu
and Weischedel, 2000; Demner-Fushman and Oard,
2003). In the higher complexity languages such as
German and Finnish, n-grams appear to be gaining
a slight improvement even when the entire corpus is
used; vocabulary size is greater in those languages.
The data for the 0% condition were based on
cognate matches for words and ‘cognate n-grams’
that require no translation. The figure reveals that
even very small amounts of parallel text quickly im-
prove performance. The 2% condition is roughly the
size of bible, but is higher performing, likely due
to a better domain match.3 Using a subsample of
only 5% of available data from the highest perform-
ing translation resource, europarl, 5-grams outper-
formed plain words using any amount of bitext.
</bodyText>
<sectionHeader confidence="0.995847" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9997806">
We examined issues in corpus-based bilingual re-
trieval, including the importance of parallel corpus
selection and size, and the relative effectiveness of
alternative tokenization methods. Size is not the
only important factor in corpus-based bilingual re-
</bodyText>
<footnote confidence="0.994423">
3For example, the Biblical text does not contain the words
nuclear or energy and thus is greatly disadvantaged for a topic
about nuclear power.
</footnote>
<page confidence="0.994489">
27
</page>
<figure confidence="0.999848178571428">
0.50 0.50
0.45 0.45
0.40 0.40
0.35 0.35
0.30 0.30
0.25 0.25
0.20 0.20
0.15 0.15
0.10 0.10
0% 20% 40% 60% 80% 100%
0% 20% 40% 60% 80% 100%
DE words DE 5-grams DE mono-5
ES words ES 5-grams ES mono-5
(a) German (b) Spanish
0.50 0.50
0.45 0.45
0.40 0.40
0.35 0.35
0.30 0.30
0.25 0.25
0.20 0.20
0.15 0.15
0.10 0.10
0% 20% 40% 60% 80% 100%
0% 20% 40% 60% 80% 100%
FI words FI 5-grams FI mono-5
FR words FR 5-grams FR mono-5
(c) Finnish (d) French
</figure>
<figureCaption confidence="0.99998">
Figure 1: Performance improvement with corpus growth.
</figureCaption>
<bodyText confidence="0.997902923076923">
trieval, the quality of alignments, compatibility in
genre, and choice of tokenization are also important.
We found that character 5-gram tokenization out-
performs words when used both for translation and
document indexing. Large relative improvements
(over 30%) were observed with 5-grams, and when
only limited parallel data is available for translation,
n-grams are markedly more effective than words.
Future work could address some limitations of the
present study by using bidirectional translation mod-
els, considering other language families and source
languages other than English, and applying query
expansion techniques.
</bodyText>
<sectionHeader confidence="0.999476" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999830571428571">
Martin Braschler and Carol Peters. 2004. Cross-
language evaluation forum: Objectives, results,
achievements. Inf. Retr., 7(1-2):7–31.
P. A. Chew, S. J. Verzi, T. L. Bauer, and J. T. Mc-
Clain. 2006. Evaluation of the Bible as a resource for
cross-language information retrieval. In Workshop on
Multilingual Language Resources and Interoperabil-
ity, pages 68–74.
Kenneth Ward Church. 1993. Char align: A program for
aligning parallel texts at the character level. In Pro-
ceedings ACL, pages 1–8.
Dina Demner-Fushman and Douglas W. Oard. 2003.
The effect of bilingual term list size on dictionary-
based cross-language information retrieval. In HICSS,
pages 108–117.
William A. Gale and Kenneth W. Church. 1991. A pro-
gram for aligning sentences in bilingual corpora. In
Proceedings ACL, pages 177–184.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In MT Summit.
Paul McNamee and James Mayfield. 2005. Translating
pieces of words. In ACM SIGIR, pages 643–644.
Ari Pirkola, Deniz Puolam¨aki, and Kalervo J¨arvelin.
2003. Applying query structuring in cross-language
retrieval. Inf. Process. Manage, 39(3):391–402.
Jay M. Ponte and W. Bruce Croft. 1998. A language
modeling approach to information retrieval. In ACM
SIGIR, pages 275–281.
Jianqiang Wang and Douglas W. Oard. 2006. Combin-
ing bidirectional translation and synonymy for cross-
language information retrieval. In ACM SIGIR, pages
202–209.
Jinxi Xu and Ralph Weischedel. 2000. Cross-lingual in-
formation retrieval using hidden Markov models. In
EMNLP, pages 85–103.
</reference>
<page confidence="0.999071">
28
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.749657">
<title confidence="0.996061">Translation Corpus Source and Size in Bilingual Retrieval</title>
<author confidence="0.862278">McNamee Mayfield Charles Nicholas</author>
<affiliation confidence="0.912782">Human Language Technology Center of Excellence Dept. of Computer Science and Electrical Engineering Johns Hopkins University UMBC</affiliation>
<address confidence="0.997623">Baltimore, MD 21218, USA Baltimore, MD 21250, USA</address>
<email confidence="0.995695">1paul.mcnamee,james.mayfieldl@jhuapl.edunicholas@umbc.edu</email>
<abstract confidence="0.9950805">This paper explores corpus-based bilingual retrieval where the translation corpora used vary by source and size. We find that the quality of translation alignments and the domain of the bitext are important. In some settings these factors are more critical than corpus size. We also show that judicious choice of tokenization can reduce the amount of bitext required to obtain good bilingual retrieval performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Martin Braschler</author>
<author>Carol Peters</author>
</authors>
<title>Crosslanguage evaluation forum: Objectives, results, achievements.</title>
<date>2004</date>
<journal>Inf. Retr.,</journal>
<pages>7--1</pages>
<contexts>
<context position="1554" citStr="Braschler and Peters, 2004" startWordPosition="221" endWordPosition="224">d in applications such as cross-language information retrieval (CLIR). Several beliefs are commonly held regarding the relationship between parallel text quality and size for CLIR. It is thought that larger texts should be better, because the problems of data sparseness and untranslatable terms are reduced. Similarly, parallel text from a domain more closely related to a document collection should lead to better bilingual retrieval performance, again because better lexical translations are available. We compared four sources of parallel text using CLEF document collections in eight languages (Braschler and Peters, 2004). English topic sets from 2000 to 2007 were used. Corpus-based translation of query terms was performed and documents were ranked using a statistical language model approach to retrieval (Ponte and Croft, 1998). Experiments were conducted using unlemmatized words and character 5-grams. No use was made of pretranslation query expansion or automated relevance feedback. 25 2 Translation Corpora Information about the four parallel texts used in our experiments is provided in Table 1. We restricted our focus to Dutch (NL), English (EN), Finnish (FI), French (FR), German (DE), Italian (IT), Portugue</context>
</contexts>
<marker>Braschler, Peters, 2004</marker>
<rawString>Martin Braschler and Carol Peters. 2004. Crosslanguage evaluation forum: Objectives, results, achievements. Inf. Retr., 7(1-2):7–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P A Chew</author>
<author>S J Verzi</author>
<author>T L Bauer</author>
<author>J T McClain</author>
</authors>
<title>Evaluation of the Bible as a resource for cross-language information retrieval.</title>
<date>2006</date>
<booktitle>In Workshop on Multilingual Language Resources and Interoperability,</booktitle>
<pages>68--74</pages>
<contexts>
<context position="7361" citStr="Chew et al., 2006" startWordPosition="1114" endWordPosition="1117">ionship between translation source and bilingual retrieval effectiveness is studied. Table 2 reports mean average precision when word-based tokenization and translation was performed for each of the target collections. For comparison the corresponding performance using topics in the target language (mono) is also given. As expected, the smallest bitext, bible, performs the worst. Averaged across the eight languages only 39% relative effectiveness is seen compared to monolingual performance. Reports advocating the use of religious texts for general purpose CLIR may have been overly optimistic (Chew et al., 2006). Both acquis and europarl are roughly 40 times larger in size than bible 26 Target mono bible acquis europarl ojeu DE 0.3303 0.1338 0.1802 0.2427 0.1937 ES 0.4396 0.1454 0.2583 0.3509 0.2786 FI 0.3406 0.1288 0.1286 0.2135 0.1636 FR 0.3638 0.1651 0.2508 0.2942 0.2600 IT 0.3749 0.1080 0.2365 0.2913 0.2405 NL 0.3813 0.1502 0.2474 0.2974 0.2484 PT 0.3162 0.1432 0.2009 0.2365 0.2157 SV 0.3387 0.1509 0.2111 0.2447 0.1861 Average 0.3607 0.1407 0.2142 0.2714 0.2233 39.0% 59.4% 75.3% 61.9% Table 2: Mean average precision for word-based translation of English topics using different corpora. Target mono</context>
</contexts>
<marker>Chew, Verzi, Bauer, McClain, 2006</marker>
<rawString>P. A. Chew, S. J. Verzi, T. L. Bauer, and J. T. McClain. 2006. Evaluation of the Bible as a resource for cross-language information retrieval. In Workshop on Multilingual Language Resources and Interoperability, pages 68–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
</authors>
<title>Char align: A program for aligning parallel texts at the character level.</title>
<date>1993</date>
<booktitle>In Proceedings ACL,</booktitle>
<pages>1--8</pages>
<marker>Church, 1993</marker>
<rawString>Kenneth Ward Church. 1993. Char align: A program for aligning parallel texts at the character level. In Proceedings ACL, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dina Demner-Fushman</author>
<author>Douglas W Oard</author>
</authors>
<title>The effect of bilingual term list size on dictionarybased cross-language information retrieval.</title>
<date>2003</date>
<booktitle>In HICSS,</booktitle>
<pages>108--117</pages>
<contexts>
<context position="10666" citStr="Demner-Fushman and Oard, 2003" startWordPosition="1652" endWordPosition="1655">verage precision is on the vertical axes, and for visual effect the chart for each language pair uses the same scale. The general shape of the curves is to rise quickly as increasing subsets from 1% to 10% are used and to flatten as size increases further. Curves for the other four languages (not shown) are quite similar. The deceleration of improvement with increasing corpus size can be explained by Heap’s Law. Similar results have been obtained in the few studies that have sought to quantify bilingual retrieval performance as a function of translation resource size (Xu and Weischedel, 2000; Demner-Fushman and Oard, 2003). In the higher complexity languages such as German and Finnish, n-grams appear to be gaining a slight improvement even when the entire corpus is used; vocabulary size is greater in those languages. The data for the 0% condition were based on cognate matches for words and ‘cognate n-grams’ that require no translation. The figure reveals that even very small amounts of parallel text quickly improve performance. The 2% condition is roughly the size of bible, but is higher performing, likely due to a better domain match.3 Using a subsample of only 5% of available data from the highest performing </context>
</contexts>
<marker>Demner-Fushman, Oard, 2003</marker>
<rawString>Dina Demner-Fushman and Douglas W. Oard. 2003. The effect of bilingual term list size on dictionarybased cross-language information retrieval. In HICSS, pages 108–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.</title>
<date>1991</date>
<booktitle>In Proceedings ACL,</booktitle>
<pages>177--184</pages>
<contexts>
<context position="3290" citStr="Gale and Church (1991)" startWordPosition="504" endWordPosition="507">which is approximately 40 times larger than the Biblical text. Alignments were provided with the corpus and were produced by the Vanilla algorithm.1 The alignments are at roughly the sentence level, but only 85% correspond to a single sentence in both languages. 2.3 Europarl v3 The Europarl corpus was assembled to support experiments in statistical machine translation (Koehn, 2005). The documents consist of transcribed dialogue from the official proceedings of the European Parliament. We used the precomputed alignments that are provided with the corpus, and which are based on the algorithm by Gale and Church (1991). The alignments are believed to be of high quality. 1Available from http://nl.ijs.si/telri/vanilla/ Proceedings of NAACL HLT 2009: Short Papers, pages 25–28, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Name Words Wrds/doc Alignments Genre Source bible 785k 25.3 Near Perfect Religious http://unbound.biola.edu/ acquis 32M 26.3 Good EU law (1958 to 2006) http://wt.jrc.it/lt/acquis/ europarl 33M 25.5 Very Good Parliamentary oration http://www.statmt.org/europarl/ (1996 to 2006) ojeu 84M 34.5 Fair Governmental affairs Derived from documents at (1998 to 2004) http</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>William A. Gale and Kenneth W. Church. 1991. A program for aligning sentences in bilingual corpora. In Proceedings ACL, pages 177–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT Summit.</booktitle>
<contexts>
<context position="3052" citStr="Koehn, 2005" startWordPosition="468" endWordPosition="469">arallel text is based on EU laws comprising the Acquis Communautaire and translations are available in 22 languages. The English portion of the acquis data includes 1.2 million aligned passages containing over 32 million words, which is approximately 40 times larger than the Biblical text. Alignments were provided with the corpus and were produced by the Vanilla algorithm.1 The alignments are at roughly the sentence level, but only 85% correspond to a single sentence in both languages. 2.3 Europarl v3 The Europarl corpus was assembled to support experiments in statistical machine translation (Koehn, 2005). The documents consist of transcribed dialogue from the official proceedings of the European Parliament. We used the precomputed alignments that are provided with the corpus, and which are based on the algorithm by Gale and Church (1991). The alignments are believed to be of high quality. 1Available from http://nl.ijs.si/telri/vanilla/ Proceedings of NAACL HLT 2009: Short Papers, pages 25–28, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Name Words Wrds/doc Alignments Genre Source bible 785k 25.3 Near Perfect Religious http://unbound.biola.edu/ acquis 32M 26.3</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>James Mayfield</author>
</authors>
<title>Translating pieces of words.</title>
<date>2005</date>
<booktitle>In ACM SIGIR,</booktitle>
<pages>643--644</pages>
<contexts>
<context position="6156" citStr="McNamee and Mayfield, 2005" startWordPosition="935" endWordPosition="938">F(t) is the inverse document frequency, or log2( N df(t)). The candidate translation with the highest score replaced the original query term and the transformed query vector is used for retrieval against the target language collection. This is a straightforward approach to query translation. More sophisticated methods have been proposed, including bidirectional translation (Wang and Oard, 2006) and use of more than one translation candidate per query term (Pirkola et al., 2003). Subword translation, the direct translation of character n-grams, offers several advantages over translating words (McNamee and Mayfield, 2005). N-grams provide morphological normalization, translations of multiword expressions are suggested by translation of word-spanning n-grams, and outof-vocabulary (OOV) words can be be partly translated with n-gram fragments. Additionally, there are few OOV n-grams, at least for n = 4 and n = 5. 4 Experimental Results We describe two experiments. The first examines the efficacy of the different translation resources and the second measures the relationship between corpus size and retrieval effectiveness. English was the sole source language. 4.1 Translation Resources First the relationship betwe</context>
</contexts>
<marker>McNamee, Mayfield, 2005</marker>
<rawString>Paul McNamee and James Mayfield. 2005. Translating pieces of words. In ACM SIGIR, pages 643–644.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ari Pirkola</author>
<author>Deniz Puolam¨aki</author>
<author>Kalervo J¨arvelin</author>
</authors>
<title>Applying query structuring in cross-language retrieval.</title>
<date>2003</date>
<journal>Inf. Process. Manage,</journal>
<volume>39</volume>
<issue>3</issue>
<marker>Pirkola, Puolam¨aki, J¨arvelin, 2003</marker>
<rawString>Ari Pirkola, Deniz Puolam¨aki, and Kalervo J¨arvelin. 2003. Applying query structuring in cross-language retrieval. Inf. Process. Manage, 39(3):391–402.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay M Ponte</author>
<author>W Bruce Croft</author>
</authors>
<title>A language modeling approach to information retrieval.</title>
<date>1998</date>
<booktitle>In ACM SIGIR,</booktitle>
<pages>275--281</pages>
<contexts>
<context position="1764" citStr="Ponte and Croft, 1998" startWordPosition="255" endWordPosition="258">ould be better, because the problems of data sparseness and untranslatable terms are reduced. Similarly, parallel text from a domain more closely related to a document collection should lead to better bilingual retrieval performance, again because better lexical translations are available. We compared four sources of parallel text using CLEF document collections in eight languages (Braschler and Peters, 2004). English topic sets from 2000 to 2007 were used. Corpus-based translation of query terms was performed and documents were ranked using a statistical language model approach to retrieval (Ponte and Croft, 1998). Experiments were conducted using unlemmatized words and character 5-grams. No use was made of pretranslation query expansion or automated relevance feedback. 25 2 Translation Corpora Information about the four parallel texts used in our experiments is provided in Table 1. We restricted our focus to Dutch (NL), English (EN), Finnish (FI), French (FR), German (DE), Italian (IT), Portuguese (PT), Spanish (ES), and Swedish (SV). These languages are covered by each parallel corpus. 2.1 Bible The bible corpus is based on the 66 books in the Old and New Testaments. Alignments at the verse level wer</context>
</contexts>
<marker>Ponte, Croft, 1998</marker>
<rawString>Jay M. Ponte and W. Bruce Croft. 1998. A language modeling approach to information retrieval. In ACM SIGIR, pages 275–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianqiang Wang</author>
<author>Douglas W Oard</author>
</authors>
<title>Combining bidirectional translation and synonymy for crosslanguage information retrieval.</title>
<date>2006</date>
<booktitle>In ACM SIGIR,</booktitle>
<pages>202--209</pages>
<contexts>
<context position="5926" citStr="Wang and Oard, 2006" startWordPosition="902" endWordPosition="905">t language term t appearing in the corresponding documents is scored: Score(t) = (Fl(t) − Fc(t)) × IDF(t)1.25 (1) where Fl and Fc are relative document frequencies based on local subset of documents and the whole corpus. IDF(t) is the inverse document frequency, or log2( N df(t)). The candidate translation with the highest score replaced the original query term and the transformed query vector is used for retrieval against the target language collection. This is a straightforward approach to query translation. More sophisticated methods have been proposed, including bidirectional translation (Wang and Oard, 2006) and use of more than one translation candidate per query term (Pirkola et al., 2003). Subword translation, the direct translation of character n-grams, offers several advantages over translating words (McNamee and Mayfield, 2005). N-grams provide morphological normalization, translations of multiword expressions are suggested by translation of word-spanning n-grams, and outof-vocabulary (OOV) words can be be partly translated with n-gram fragments. Additionally, there are few OOV n-grams, at least for n = 4 and n = 5. 4 Experimental Results We describe two experiments. The first examines the </context>
</contexts>
<marker>Wang, Oard, 2006</marker>
<rawString>Jianqiang Wang and Douglas W. Oard. 2006. Combining bidirectional translation and synonymy for crosslanguage information retrieval. In ACM SIGIR, pages 202–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinxi Xu</author>
<author>Ralph Weischedel</author>
</authors>
<title>Cross-lingual information retrieval using hidden Markov models.</title>
<date>2000</date>
<booktitle>In EMNLP,</booktitle>
<pages>85--103</pages>
<contexts>
<context position="10634" citStr="Xu and Weischedel, 2000" startWordPosition="1648" endWordPosition="1651">or four languages. Mean average precision is on the vertical axes, and for visual effect the chart for each language pair uses the same scale. The general shape of the curves is to rise quickly as increasing subsets from 1% to 10% are used and to flatten as size increases further. Curves for the other four languages (not shown) are quite similar. The deceleration of improvement with increasing corpus size can be explained by Heap’s Law. Similar results have been obtained in the few studies that have sought to quantify bilingual retrieval performance as a function of translation resource size (Xu and Weischedel, 2000; Demner-Fushman and Oard, 2003). In the higher complexity languages such as German and Finnish, n-grams appear to be gaining a slight improvement even when the entire corpus is used; vocabulary size is greater in those languages. The data for the 0% condition were based on cognate matches for words and ‘cognate n-grams’ that require no translation. The figure reveals that even very small amounts of parallel text quickly improve performance. The 2% condition is roughly the size of bible, but is higher performing, likely due to a better domain match.3 Using a subsample of only 5% of available d</context>
</contexts>
<marker>Xu, Weischedel, 2000</marker>
<rawString>Jinxi Xu and Ralph Weischedel. 2000. Cross-lingual information retrieval using hidden Markov models. In EMNLP, pages 85–103.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>