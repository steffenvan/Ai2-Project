<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000030">
<title confidence="0.995391">
Discourse Generation Using Utility-Trained Coherence Models
</title>
<author confidence="0.988873">
Radu Soricut
</author>
<affiliation confidence="0.906091666666667">
Information Sciences Institute
University of Southern California
4676 Admiralty Way, Suite 1001
</affiliation>
<address confidence="0.611338">
Marina del Rey, CA 90292
</address>
<email confidence="0.998444">
radu@isi.edu
</email>
<author confidence="0.996258">
Daniel Marcu
</author>
<affiliation confidence="0.907881">
Information Sciences Institute
University of Southern California
4676 Admiralty Way, Suite 1001
</affiliation>
<address confidence="0.611796">
Marina del Rey, CA 90292
</address>
<email confidence="0.999293">
marcu@isi.edu
</email>
<sectionHeader confidence="0.99391" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999900583333333">
We describe a generic framework for inte-
grating various stochastic models of dis-
course coherence in a manner that takes
advantage of their individual strengths. An
integral part of this framework are algo-
rithms for searching and training these
stochastic coherence models. We evaluate
the performance of our models and algo-
rithms and show empirically that utility-
trained log-linear coherence models out-
perform each of the individual coherence
models considered.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999925016666667">
Various theories of discourse coherence (Mann
and Thompson, 1988; Grosz et al., 1995) have
been applied successfully in discourse analy-
sis (Marcu, 2000; Forbes et al., 2001) and dis-
course generation (Scott and de Souza, 1990; Kib-
ble and Power, 2004). Most of these efforts, how-
ever, have limited applicability. Those that use
manually written rules model only the most visi-
ble discourse constraints (e.g., the discourse con-
nective “although” marks a CONCESSION relation),
while being oblivious to fine-grained lexical indi-
cators. And the methods that utilize manually an-
notated corpora (Carlson et al., 2003; Karamanis
et al., 2004) and supervised learning algorithms
have high costs associated with the annotation pro-
cedure, and cannot be easily adapted to different
domains and genres.
In contrast, more recent research has focused on
stochastic approaches that model discourse coher-
ence at the local lexical (Lapata, 2003) and global
levels (Barzilay and Lee, 2004), while preserving
regularities recognized by classic discourse theo-
ries (Barzilay and Lapata, 2005). These stochas-
tic coherence models use simple, non-hierarchical
representations of discourse, and can be trained
with minimal human intervention, using large col-
lections of existing human-authored documents.
These models are attractive due to their increased
scalability and portability. As each of these
stochastic models captures different aspects of co-
herence, an important question is whether we can
combine them in a model capable of exploiting all
coherence indicators.
A frequently used testbed for coherence models
is the discourse ordering problem, which occurs
often in text generation, complex question answer-
ing, and multi-document summarization: given
discourse units, what is the most coherent order-
ing of them (Marcu, 1996; Lapata, 2003; Barzilay
and Lee, 2004; Barzilay and Lapata, 2005)? Be-
cause the problem is NP-complete (Althaus et al.,
2005), it is critical how coherence model evalua-
tion is intertwined with search: if the search for the
best ordering is greedy and has many errors, one
is not able to properly evaluate whether a model is
better than another. If the search is exhaustive, the
ordering procedure may take too long to be useful.
In this paper, we propose an A search al-
gorithm for the discourse ordering problem that
comes with strong theoretical guarantees. For a
wide range of practical problems (discourse order-
ing of up to 15 units), the algorithm finds an op-
timal solution in reasonable time (on the order of
seconds). A beam search version of the algorithm
enables one to find good, approximate solutions
for very large reordering tasks. These algorithms
enable us not only to compare head-to-head, for
the first time, a set of coherence models, but also
to combine these models so as to benefit from
their complementary strengths. The model com-
</bodyText>
<page confidence="0.984735">
803
</page>
<note confidence="0.7236735">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 803–810,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999759583333333">
bination is accomplished using statistically well-
founded utility training procedures which auto-
matically optimize the contributions of the indi-
vidual models on a development corpus. We em-
pirically show that utility-based models of dis-
course coherence outperform each of the individ-
ual coherence models considered.
In the following section, we describe
previously-proposed and new coherence models.
Then, we present our search algorithms and the
input representation they use. Finally, we show
evaluation results and discuss their implications.
</bodyText>
<sectionHeader confidence="0.9979595" genericHeader="method">
2 Stochastic Models of Discourse
Coherence
</sectionHeader>
<subsectionHeader confidence="0.994966">
2.1 Local Models of Discourse Coherence
</subsectionHeader>
<bodyText confidence="0.9991586">
Stochastic local models of coherence work under
the assumption that well-formed discourse can be
characterized in terms of specific distributions of
local recurring patterns. These distributions can be
defined at the lexical level or entity-based levels.
</bodyText>
<subsectionHeader confidence="0.407275">
Word-Coocurrence Coherence Models. We
</subsectionHeader>
<bodyText confidence="0.99098152173913">
propose a new coherence model, inspired
by (Knight, 2003), that models the intuition that
the usage of certain words in a discourse unit
(sentence) tends to trigger the usage of other
words in subsequent discourse units. (A similar
intuition holds for the Machine Translation mod-
els generically known as the IBM models (Brown
et al., 1993), which assume that certain words in a
source language sentence tend to trigger the usage
of certain words in a target language translation
of that sentence.)
We train models able to recognize local recur-
ring patterns of word usage across sentences in an
unsupervised manner, by running an Expectation-
Maximization (EM) procedure over pairs of con-
secutive sentences extracted from a large collec-
tion of training documents&apos;. We expect EM to
detect and assign higher probabilities to recur-
ring word patterns compared to casually occurring
word patterns.
A local coherence model based on IBM Model
1 assigns the following probability to a text con-
sisting of sentences :
</bodyText>
<footnote confidence="0.789672">
&apos;We use for training the publicly-available GIZA++
toolkit, http://www.fjoch.com/GIZA++.html
</footnote>
<bodyText confidence="0.992893511627907">
We call the above equation the direct IBM
Model 1, as this model considers the words in sen-
tence (the events) as being generated by
the words in sentence (the events, which in-
clude the special event called the NULL word),
with probability . We also define a local
coherence inverse IBM Model 1:
This model considers the words in sentence (the
events) as being generated by the words in sen-
tence (the events, which include the spe-
cial event called the NULL word), with prob-
ability .
Entity-based Coherence Models. Barzilay and
Lapata (2005) recently proposed an entity-based
coherence model that aims to learn abstract coher-
ence properties, similar to those stipulated by Cen-
tering Theory (Grosz et al., 1995). Their model
learns distribution patterns for transitions between
discourse entities that are abstracted into their syn-
tactic roles – subject (S), object (O), other (X),
missing (-). The feature values are computed us-
ing an entity-grid representation for the discourse
that records the syntactic role of each entity as it
appears in each sentence. Also, salient entities
are differentiated from casually occurring entities,
based on the widely used assumption that occur-
rence frequency correlates with discourse promi-
nence (Morris and Hirst, 1991; Grosz et al., 1995).
We exclude the coreference information from this
model, as the discourse ordering problem can-
not accommodate current coreference solutions,
which assume a pre-specified order (Ng, 2005).
In the jargon of (Barzilay and Lapata, 2005), the
model we implemented is called Syntax+Salience.
The probability assigned to a text
by this Entity-Based model (henceforth called EB)
can be locally computed (i.e., at sentence transi-
tion level) using feature functions, as follows:
Here, are feature values, and are
weights trained to discriminate between coher-
ent, human-authored documents and examples as-
sumed to have lost some degree of coherence
(scrambled versions of the original documents).
</bodyText>
<subsectionHeader confidence="0.984364">
2.2 Global Models of Discourse Coherence
</subsectionHeader>
<bodyText confidence="0.9346105">
Barzilay and Lee (2004) propose a document con-
tent model that uses a Hidden Markov Model
</bodyText>
<page confidence="0.997239">
804
</page>
<bodyText confidence="0.991801125">
(HMM) to capture more global aspects of coher-
ence. Each state in their HMM corresponds to a
distinct “topic”. Topics are determined by an un-
supervised algorithm via complete-link clustering,
and are written as , with .
The probability assigned to a text
by this Content Model (henceforth called CM) can
be written as follows:
</bodyText>
<figure confidence="0.964851882352941">
A: It said no information had been received about injuries or damage from the mag−
nitude 6.1 quake which struck the sparsely inhabited area at 2 43 AM (1843 GMT)
B: BC−China−Earthquake|Urgent Earthquake rocks northwestern Xinjiang Mountains
(a)
C: Beijing (AP) A strong earthquake hit the Altai Mountains in northwestern
Xinjiang early Wednesday the official Xinhua News Agency reported
S S X X X X O X - - - - - - - - - - - −
(b) − −− − − − − − S S O O O − − - - - - −
−−− ---- − S X X O S X O X S S S
&amp;quot;it said no information had been received about injuries or damage from the
magnitude +.+ quake which struck the sparsely inhabited area at + ++ am
( ++++ gmt ) ## SSXXXXOX &amp;quot;
&amp;quot;−Name− earthquake rocks northwestern −Name− −Name− ## −−−−−−−−SSOOO
&amp;quot; &amp;quot;
α:
b:
(1)
</figure>
<bodyText confidence="0.9973505">
The first term, , models the probability of
changing from topic to topic . The second
term, , models the probability of generating
sentences from topic .
</bodyText>
<subsectionHeader confidence="0.997288">
2.3 Combining Local and Global Models of
Discourse Coherence
</subsectionHeader>
<bodyText confidence="0.999920173913043">
We can model the probability of a text us-
ing a log-linear model that combines the discourse
coherence models presented above. In this frame-
work, we have a set of feature functions ,
. For each feature function, there ex-
ists a model parameter ,
Under this model, finding the most probable text
is equivalent with solving Equation 1, and there-
fore we do not need to be concerned about com-
puting expensive normalization factors.
In this framework, we distinguish between the
modeling problem, which amounts to finding ap-
propriate feature functions for the discourse co-
herence task, and the training problem, which
amounts to finding appropriate values for ,
. We address the modeling problem by
using as feature functions the discourse coherence
models presented in the previous sections. In Sec-
tion 3, we address the training problem by per-
forming a discriminative training procedure of the
parameters, using as utility functions a metric
that measures how different a training instance is
from a given reference.
</bodyText>
<figure confidence="0.560483666666667">
&amp;quot;−Name− ( −Name− ) a strong earthquake hit the −Name− −Name− in
g: northwestern −Name− early −Name− the official −Name− −Name−
−Name− reported ## −−−−−−−−−SXXOSXOXSSS−&amp;quot;
</figure>
<figureCaption confidence="0.986119">
Figure 1: Example consisting of discourse units
</figureCaption>
<bodyText confidence="0.7489506">
A, B, and C (a). In (b), their entities are detected
(underlined) and assigned syntactic roles: S (sub-
ject), O (object), X (other), - (missing). In (c),
terms , and encode these discourse units for
model scoring purposes.
</bodyText>
<sectionHeader confidence="0.9769955" genericHeader="method">
3 Search Algorithms for Coherent
Discourses and Utility-Based Training
</sectionHeader>
<bodyText confidence="0.999998444444444">
The algorithms we propose use as input repre-
sentation the IDL-expressions formalism (Neder-
hof and Satta, 2004; Soricut and Marcu, 2005).
We use here the IDL formalism (which stands for
Interleave, Disjunction, Lock, after the names of
its operators) to define finite sets of possible dis-
courses over given discourse units. Without losing
generality, we will consider sentences as discourse
units in our examples and experiments.
</bodyText>
<subsectionHeader confidence="0.995449">
3.1 Input Representation
</subsectionHeader>
<bodyText confidence="0.962045368421053">
Consider the discourse units A-C presented in Fig-
ure 1(a). Each of these units undergoes various
processing stages in order to provide the infor-
mation needed by our coherence models. The
entity-based model (EB) (Section 2), for instance,
makes use of a syntactic parser to determine the
syntactic role played by each detected entity (Fig-
ure 1(b)). For example, the string SSXXXXOX- - - - - - - - - - - (first row of the grid in Figure 1(b),
corresponding to discourse unit A) encodes that
and have subject (S) role, , etc.
have other (X) roles, has object (O) role, and
the rest of the entities do not appear (-) in this unit.
In order to be able to solve Equation 1, the
input representation needs to provide the neces-
sary information to compute all terms, that is,
all individual model scores. Textual units A, B,
. The
probability can be written under the log-
linear model as follows:
</bodyText>
<page confidence="0.969988">
805
</page>
<figureCaption confidence="0.999111">
Figure 2: The IDL-graph corresponding to the
</figureCaption>
<bodyText confidence="0.986792947368421">
IDL-expression .
and C in our example are therefore represented
as terms , and , respectively2 (Figure 1(c)).
These terms act like building blocks for IDL-
expressions, as in the following example:
uses the (Interleave) operator to create a bag-
of-units representation. That is, E stands for the
set of all possible order permutations of , and
, with the additional information that any of these
orders are to appear between the beginning and
end of document . An equivalent represen-
tation, called IDL-graphs, captures the same in-
formation using vertices and edges, which stand
in a direct correspondence with the operators and
atomic symbols of IDL-expressions. For instance,
each and –labeled edge -pair, and their source
and target vertices, respectively, correspond to a
-argument operator. In Figure 2, we show the
IDL-graph corresponding to IDL-expression .
</bodyText>
<subsectionHeader confidence="0.999394">
3.2 Search Algorithms
</subsectionHeader>
<bodyText confidence="0.983392596491228">
Algorithms that operate on IDL-graphs have been
recently proposed by Soricut and Marcu (2005).
We extend these algorithms to take as input IDL-
graphs over non-atomic symbols (such that the co-
herence models can operate inside terms like ,
and from Figure 1), and also to work under
models with hidden variables such as CM (Sec-
tion 2.2).
These algorithm, called IDL-CH-A (A search
for IDL-expressions under Coherence models) and
IDL-CH-HB (Histogram-Based beam search for
IDL-expressions under Coherence models, with
histogram beam ), assume an alphabet of non-
atomic (visible) variables (over which the input
IDL-expressions are defined), and an alphabet
of hidden variables. They unfold an input IDL-
graph on-the-fly, as follows: starting from the
initial vertex , the input graph is traversed in
an IDL-specific manner, by creating states which
2Following Barzilay and Lee (2004), proper names, dates,
and numbers are replaced with generic tokens.
keep track of positions in any subgraph cor-
responding to a -argument operator, as well
as the last edge traversed and the last hidden
variable considered. For instance, state
(see the blackened vertices in Fig-
ure 2) records that expressions and have al-
ready been considered (while is still in the fu-
ture of state ), and was the last one considered,
evaluated under the hidden variable . The infor-
mation recorded in each state allows for the com-
putation of a current coherence cost under any of
the models described in Section 2. In what fol-
lows, we assume this model to be the model from
Equation 1, since each of the individual models
can be obtained by setting the other s to 0.
We also define an admissible heuristic func-
tion (Russell and Norvig, 1995), which is used to
compute an admissible future cost for state ,
using the following equation:
is the set of future (visible) events for state
, which can be computed directly from an input
IDL-graph, as the set of all –edge-labels between
the vertices of state and final vertex . For
example, for state , we have
. is the set of future (visible)
conditions for state , which can be obtained from
(any non-final future event may become a fu-
ture conditioning event), by eliminating and
adding the current conditioning event of . For the
considered example state , we have .
The value is admissible because, for each fu-
ture event
and Norvig, 1995).
The IDL-CH-HB algorithm uses a histogram
beam to control the unfolding of an input IDL-
graph, by processing, at each unfolding step, the
</bodyText>
<figure confidence="0.910657333333333">
v5
v6
vs v v ve
3 4
d s p s /d
v1
a
Y
v2
, its cost
is computed using the most inexpensive condition-
ing event .
</figure>
<bodyText confidence="0.9424952">
The IDL-CH-A algorithm uses a priority
queue (sorted according to total cost, computed
as current admissible) to control the unfolding
of an input IDL-graph, by processing, at each un-
folding step, the most inexpensive state (extracted
from the top of ). The admissibility of the fu-
ture costs and the monotonicity property enforced
by the priority queue guarantees that IDL-CH-A
finds an optimal solution to Equation 1 (Russell
, with and
</bodyText>
<page confidence="0.967587">
806
</page>
<bodyText confidence="0.999773833333333">
top most inexpensive states (according to to-
tal cost). This algorithm can be tuned (via ) to
achieve good trade-off between speed and accu-
racy. We refer the reader to (Soricut, 2006) for
additional details regarding the optimality and the
theoretical run-time behavior of these algorithms.
</bodyText>
<subsectionHeader confidence="0.996428">
3.3 Utility-based Training
</subsectionHeader>
<bodyText confidence="0.999896346938775">
In addition to the modeling problem, we must also
address the training problem, which amounts to
finding appropriate values for the parameters
from Equation 1.
The solution we employ here is the discrimina-
tive training procedure of Och (2003). This proce-
dure learns an optimal setting of the parame-
ters using as optimality criterion the utility of the
proposed solution. There are two necessary ingre-
dients to implement Och’s (2003) training proce-
dure. First, it needs a search algorithm that is able
to produce ranked -best lists of the most promis-
ing candidates in a reasonably fast manner (Huang
and Chiang, 2005). We accommodate -best
computation within the IDL-CH-HB algorithm,
which decodes bag-of-units IDL-expressions at an
average speed of 75.4 sec./exp. on a 3.0 GHz CPU
Linux machine, for an average input of 11.5 units
per expression.
Second, it needs a criterion which can automati-
cally assess the quality of the proposed candidates.
To this end, we employ two different metrics, such
that we can measure the impact of using different
utility functions on performance.
TAU (Kendall’s ). One of the most frequently
used metrics for the automatic evaluation of doc-
ument coherence is Kendall’s (Lapata, 2003;
Barzilay and Lee, 2004). TAU measures the mini-
mum number of adjacent transpositions needed to
transform a proposed order into a reference order.
The range of the TAU metric is between -1 (the
worst) to 1 (the best).
BLEU. One of the most successful metrics for
judging machine-generated text is BLEU (Pap-
ineni et al., 2002). It counts the number of un-
igram, bigram, trigram, and four-gram matches
between hypothesis and reference, and combines
them using geometric mean. For the discourse or-
dering problem, we represent hypotheses and ref-
erences by index sequences (e.g., “4 2 3 1” is a hy-
pothesis order over four discourse units, in which
the first and last units have been swapped with re-
spect to the reference order). The range of BLEU
scores is between 0 (the worst) and 1 (the best).
We run different discriminative training ses-
sions using TAU and BLEU, and train two differ-
ent sets of the parameters for Equation 1. The
log-linear models thus obtained are called Log-
linear and Log-linear , respectively.
</bodyText>
<sectionHeader confidence="0.999579" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999993222222222">
We evaluate empirically two different aspects of
our work. First, we measure the performance
of our search algorithms across different models.
Second, we compare the performance of each indi-
vidual coherence model, and also the performance
of the discriminatively trained log-linear models.
We also compare the overall performance (model
&amp; decoding strategy) obtained in our framework
with previously reported results.
</bodyText>
<subsectionHeader confidence="0.989498">
4.1 Evaluation setting
</subsectionHeader>
<bodyText confidence="0.9998761">
The task on which we conduct our evaluation
is information ordering (Lapata, 2003; Barzilay
and Lee, 2004; Barzilay and Lapata, 2005). In
this task, a pre-selected set of information-bearing
document units (in our case, sentences) needs to
be arranged in a sequence which maximizes some
specific information quality (in our case, docu-
ment coherence). We use the information-ordering
task as a means to measure the performance of our
algorithms and models in a well-controlled setting.
As described in Section 3, our framework can be
used in applications such as multi-document sum-
marization. In fact, Barzilay et al. (2002) formu-
late the multi-document summarization problem
as an information ordering problem, and show that
naive ordering algorithms such as majority order-
ing (select most frequent orders across input docu-
ments) and chronological ordering (order facts ac-
cording to publication date) do not always yield
coherent summaries.
Data. For training and testing, we use docu-
ments from two different genres: newspaper arti-
cles and accident reports written by government
officials (Barzilay and Lapata, 2005). The first
collection (henceforth called EARTHQUAKES)
consists of Associated Press articles from the
North American News Corpus on the topic of nat-
ural disasters. The second collection (henceforth
called ACCIDENTS) consists of aviation accident
reports from the National Transportation Safety
</bodyText>
<page confidence="0.99628">
807
</page>
<table confidence="0.99964675">
Search Algorithm IBM IBM CM EB
ESE TAU BLEU ESE TAU BLEU ESE TAU BLEU ESE TAU BLEU
EARTHQUAKES
IDL-CH-A 0% .39 .12 0% .33 .13 0% .39 .12 0% .19 .05
IDL-CH-HB 0% .38 .12 0% .32 .13 0% .39 .12 0% .19 .06
IDL-CH-HB 4% .37 .13 13% .34 .14 36% .32 .11 16% .18 .05
Lapata, 2003 90% .01 .04 58% .02 .06 97% .05 .04 46% -.05 .00
ACCIDENTS
IDL-CH-A 0% .41 .21 0% .40 .21 0% .37 .15 0% .13 .10
IDL-CH-HB 0% .41 .20 0% .40 .21 2% .36 .15 0% .12 .10
IDL-CH-HB 0% .38 .19 12% .32 .20 13% .34 .13 33% -.04 .06
Lapata, 2003 86% .11 .03 67% .12 .05 85% .18 .00 24% -.05 .06
</table>
<tableCaption confidence="0.9580845">
Table 1: Evaluation of search algorithms for document coherence, for both EARTHQUAKES and
ACCIDENTS genres, across the IBM , IBM , CM, and EB models. Performance is measured in terms
of percentage of Estimated Search Errors (ESE), as well as quality of found realizations (average TAU
and BLEU).
</tableCaption>
<table confidence="0.999902777777778">
Model TAU BLEU TAU BLEU
EARTHQUAKES ACCIDENTS
IBM .38 .12 .41 .20
IBM .32 .13 .40 .21
CM .39 .12 .36 .15
EB .19 .06 .12 .10
Log-linear .34 .14 .48 .23
Log-linear .47 .15 .50 .23
Log-linear .46 .16 .49 .24
</table>
<tableCaption confidence="0.966817">
Table 2: Evaluation of stochastic models for doc-
ument coherence, for both EARTHQUAKES and
ACCIDENTS genre, using IDL-CH-HB .
</tableCaption>
<bodyText confidence="0.959402142857143">
Board’s database.
For both collections, we used 100 documents
for training and 100 documents for testing. A frac-
tion of 40% of the training documents was tem-
porarily removed and used as a development set,
on which we performed the discriminative train-
ing procedure.
</bodyText>
<subsectionHeader confidence="0.999774">
4.2 Evaluation of Search Algorithms
</subsectionHeader>
<bodyText confidence="0.9988018">
We evaluated the performance of several search
algorithms across four stochastic models of doc-
ument coherence: the IBM and IBM coher-
ence models, the content model of Barzilay and
Lee (2004) (CM), and the entity-based model of
Barzilay and Lapata (2005) (EB) (Section 2). We
measure search performance using an Estimated
Search Error (ESE) figure, which reports the per-
centage of times when the search algorithm pro-
poses a sentence order which scores lower than
</bodyText>
<table confidence="0.999623625">
Overall performance TAU
QUAKES ACCID.
Lapata (2003) 0.48 0.07
Barzilay &amp; Lee (2004) 0.81 0.44
Barzilay &amp; Lee (reproduced) 0.39 0.36
Barzilay &amp; Lapata (2005) 0.19 0.12
IBM , IDL-CH-HB 0.38 0.41
Log-lin , IDL-CH-HB 0.47 0.50
</table>
<tableCaption confidence="0.999508">
Table 3: Comparison of overall performance (af-
</tableCaption>
<bodyText confidence="0.954661666666667">
fected by both model &amp; search procedure) of our
framework with previous results.
the original sentence order (OSO). We also mea-
sure the quality of the proposed documents using
TAU and BLEU, using as reference the OSO.
In Table 1, we report the performance of four
search algorithms. The first three, IDL-CH-A ,
IDL-CH-HB , and IDL-CH-HB are the IDL-
based search algorithms of Section 3, implement-
ing A search, histogram beam search with a
beam of 100, and histogram beam search with a
beam of 1, respectively. We compare our algo-
rithms against the greedy algorithm used by La-
pata (2003). We note here that the comparison
is rendered meaningful by the observation that
this algorithm performs search identically with al-
gorithm IDL-CH-HB (histogram beam 1), when
setting the heuristic function for future costs to
constant 0.
The results in Table 1 clearly show the superi-
ority of the IDL-CH-A and IDL-CH-HB algo-
</bodyText>
<page confidence="0.995268">
808
</page>
<bodyText confidence="0.999809166666667">
rithms. Across all models considered, they consis-
tently propose documents with scores at least as
good as OSO (0% Estimated Search Error). As
the original documents were coherent, it follows
that the proposed document realizations also ex-
hibit coherence. In contrast, the greedy algorithm
of Lapata (2003) makes grave search errors. As
the comparison between IDL-CH-HB and IDL-
CH-HB shows, the superiority of the IDL-CH al-
gorithms depends more on the admissible heuristic
function than in the ability to maintain multiple
hypotheses while searching.
</bodyText>
<subsectionHeader confidence="0.999967">
4.3 Evaluation of Log-linear Models
</subsectionHeader>
<bodyText confidence="0.999976458333333">
For this round of experiments, we held con-
stant the search procedure (IDL-CH-HB ), and
varied the parameters of Equation 1. The
utility-trained log-linear models are compared
here against a baseline log-linear model log-
linear , for which all parameters are set
to 1, and also against the individual models. The
results are presented in Table 2.
If not properly weighted, the log-linear com-
bination may yield poorer results than those of
individual models (average TAU of .34 for log-
linear , versus .38 for IBM and .39 for
CM, on the EARTHQUAKES domain). The highest
TAU accuracy is obtained when using TAU to per-
form utility-based training of the parameters
(.47 for EARTHQUAKES, .50 for ACCIDENTS).
The highest BLEU accuracy is obtained when us-
ing BLEU to perform utility-based training of the
parameters (.16 for EARTHQUAKES, .24 for
the ACCIDENTS). For both genres, the differences
between the highest accuracy figures (in bold) and
the accuracy of the individual models are statis-
tically significant at 95% confidence (using boot-
strap resampling).
</bodyText>
<subsectionHeader confidence="0.995235">
4.4 Overall Performance Evaluation
</subsectionHeader>
<bodyText confidence="0.999954625">
The last comparison we provide is between the
performance provided by our framework and
previously-reported performance results (Table 3).
We are able to provide this comparison based on
the TAU figures reported in (Barzilay and Lee,
2004). The training and test data for both genres
is the same, and therefore the figures can be di-
rectly compared. These figures account for com-
bined model and search performance.
We first note that, unfortunately, we failed to
accurately reproduce the model of Barzilay and
Lee (2004). Our reproduction has an average
TAU figure of only .39 versus the original fig-
ure of .81 for EARTHQUAKES, and .36 versus .44
for ACCIDENTS. On the other hand, we repro-
duced successfully the model of Barzilay and La-
pata (2005), and the average TAU figure is .19 for
EARTHQUAKES, and .12 for ACCIDENTS&apos;. The
large difference on the EARTHQUAKES corpus be-
tween the performance of Barzilay and Lee (2004)
and our reproduction of their model is responsi-
ble for the overall lower performance (0.47) of
our log-linear model and IDL-CH-HB
search algorithm, which is nevertheless higher
than that of its component model CM (0.39). On
the other hand, we achieve the highest accuracy
figure (0.50) on the ACCIDENTS corpus, out-
performing the previous-highest figure (0.44) of
Barzilay and Lee (2004). These result empirically
show that utility-trained log-linear models of dis-
course coherence outperform each of the individ-
ual coherence models considered.
</bodyText>
<sectionHeader confidence="0.995906" genericHeader="conclusions">
5 Discussion and Conclusions
</sectionHeader>
<bodyText confidence="0.99999224">
We presented a generic framework that is capa-
ble of integrating various stochastic models of dis-
course coherence into a more powerful model that
combines the strengths of the individual models.
An important ingredient of this framework are
the search algorithms based on IDL-expressions,
which provide a flexible way of solving discourse
generation problems using stochastic models. Our
generation algorithms are fundamentally differ-
ent from previously-proposed algorithms for dis-
course generation. The genetic algorithms of
Mellish et al. (1998) and Karamanis and Man-
arung (2002), as well as the greedy algorithm of
Lapata (2003), provide no theoretical guarantees
on the optimality of the solutions they propose.
At the other end of the spectrum, the exhaus-
tive search of Barzilay and Lee (2004), while en-
suring optimal solutions, is prohibitively expen-
sive, and cannot be used to perform utility-based
training. The linear programming algorithm of
Althaus et al. (2005) is the only proposal that
achieves both good speed and accuracy. Their al-
gorithm, however, cannot handle models with hid-
den states, cannot compute -best lists, and does
not have the representation flexibility provided by
</bodyText>
<footnote confidence="0.8931398">
3Note that these figures cannot be compared directly with
the figures reported in (Barzilay and Lapata, 2005), as they
use a different type of evaluation. Our EB model achieves the
same performance as the original Syntax+Salience model, in
their evaluation setting.
</footnote>
<page confidence="0.997398">
809
</page>
<bodyText confidence="0.995835470588235">
IDL-expressions, which is crucial for coherence
decoding in realistic applications such as multi-
document summarization.
For each of the coherence model combinations
that we have utility trained, we obtained improved
results on the discourse ordering problem com-
pared to the individual models. This is important
for two reasons. Our improvements can have an
immediate impact on multi-document summariza-
tion applications (Barzilay et al., 2002). Also, our
framework provides a solid foundation for subse-
quent research on discourse coherence models and
related applications.
Acknowledgments This work was partially sup-
ported under the GALE program of the Defense
Advanced Research Projects Agency, Contract
No. HR0011-06-C-0022.
</bodyText>
<sectionHeader confidence="0.999195" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997841">
Ernst Althaus, Nikiforos Karamanis, and Alexander Koller.
2005. Computing locally coherent discourse. In Proceed-
ings of the ACL, pages 399–406.
Regina Barzilay and Mirella Lapata. 2005. Modeling local
coherence: An entity-based approach. In Proceedings of
the ACL, pages 141–148.
Regina Barzilay and Lillian Lee. 2004. Catching the drift:
Probabilistic content models, with applications to gener-
ation and summarization. In Proceedings of the HLT-
NAACL, pages 113–120.
Regina Barzilay, Noemie Elhadad, and Kathleen R. McKe-
own. 2002. Inferring strategies for sentence ordering in
multidocument news summarization. Journal ofArtificial
Intelligence Research, 17:35–55.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The mathematics
of statistical machine translation: Parameter estimation.
Computational Linguistics, 19(2):263–311.
L. Carlson, D. Marcu, and M. E. Okurowski. 2003. Building
a discourse-tagged corpus in the framework of Rhetorical
Structure Theory. In J. van Kuppevelt and R. Smith, eds.,
Current Directions in Discourse and Dialogue. Kluwer
Academic Publishers.
K. Forbes, E. Miltsakaki, R. Prasad, A. Sarkar, A. Joshi, and
B. Webber. 2001. D-LTAG System: Discourse parsing
with a lexicalized tree-adjoining grammar. In Workshop
on Information Structure, Discourse Structure and Dis-
course Semantics.
Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein.
1995. Centering: A framework for modeling the lo-
cal coherence of discourse. Computational Linguistics,
21(2):203–226.
Liang Huang and David Chiang. 2005. Better k-best parsing.
In Proceedings of the International Workshop on Parsing
Technologies (IWPT 2005).
Nikiforos Karamanis and Hisar M. Manurung. 2002.
Stochastic text structuring using the principle of continu-
ity. In Proceedings ofINLG, pages 81–88.
Nikiforos Karamanis, Massimo Poesio, Chris Mellish, and
Jon Oberlander. 2004. Evaluating centering-based met-
rics of coherence for text structuring using a reliably an-
notated corpus. In Proc. of the ACL.
Rodger Kibble and Richard Power. 2004. Optimising refer-
ential coherence in text generation. Computational Lin-
guistics, 30(4):410–416.
Kevin Knight. 2003. Personal Communication.
Mirella Lapata. 2003. Probabilistic text structuring: Exper-
iments with text ordering. In Proceedings of the ACL,
pages 545–552.
William C. Mann and Sandra A. Thompson. 1988. Rhetor-
ical Structure Theory: Toward a functional theory of text
organization. Text, 8(3):243–281.
Daniel Marcu. 1996. In Proceedings of the Student Confer-
ence on Computational Linguistics, pages 136-143.
Daniel Marcu. 2000. The Theory and Practice of Discourse
Parsing and Summarization. The MIT Press.
Chris Mellish, Alistair Knott, Jon Oberlander, and Mick
O’Donnell. 1998. Experiments using stochastic search
for text planning. In Proceedings of the INLG, pages 98–
107.
Jane Morris and Graeme Hirst. 1991. Lexical cohesion com-
puted by thesaural relations as an indicator of the structure
of text. Computational Linguistics, 17(1):21–48.
Mark-Jan Nederhof and Giorgio Satta. 2004. IDL-
expressions: a formalism for representing and parsing fi-
nite languages in natural language processing. Journal of
Artificial Intelligence Research, pages 287–317.
Vincent Ng. 2005. Machine learning for coreference res-
olution: from local clasiffication to global reranking. In
Procedings of the ACL, pages 157–164.
Franz Josef Och. 2003. Minimum error rate training in sta-
tistical machine translation. In Proceedings of the ACL,
pages 160–167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
Zhu. 2002. BLEU: a method for automatic evaluation
of machine translation. In Proceedings of the ACL, pages
311–318.
Stuart Russell and Peter Norvig. 1995. Artificial Intelli-
gence. A Modern Approach. Prentice Hall.
Donia R. Scott and Clarisse S. de Souza. 1990. Getting the
message across in RST-based text generation. In Robert
Dale, Chris Mellish, and Michael Zock, eds., Current Re-
search in Natural Language Generation, pages 47–73.
Academic Press.
Radu Soricut and Daniel Marcu. 2005. Towards develop-
ing generation algorithms for text-to-text applications. In
Proceedings of the ACL, pages 66–74.
Radu Soricut. 2006. Natural Language Generation for Text-
to-Text Applications Using an Information-SlimRepresen-
tation. Ph.D. thesis, University of Southern California.
</reference>
<page confidence="0.997558">
810
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.921868">
<title confidence="0.997049">Discourse Generation Using Utility-Trained Coherence Models</title>
<author confidence="0.978814">Radu Soricut</author>
<affiliation confidence="0.9986285">Information Sciences Institute University of Southern California</affiliation>
<address confidence="0.9979195">4676 Admiralty Way, Suite 1001 Marina del Rey, CA 90292</address>
<email confidence="0.999735">radu@isi.edu</email>
<author confidence="0.99937">Daniel Marcu</author>
<affiliation confidence="0.998635">Information Sciences Institute University of Southern California</affiliation>
<address confidence="0.994875">4676 Admiralty Way, Suite 1001 Marina del Rey, CA 90292</address>
<email confidence="0.997971">marcu@isi.edu</email>
<abstract confidence="0.997145461538462">We describe a generic framework for integrating various stochastic models of discourse coherence in a manner that takes advantage of their individual strengths. An integral part of this framework are algorithms for searching and training these stochastic coherence models. We evaluate the performance of our models and algorithms and show empirically that utilitytrained log-linear coherence models outperform each of the individual coherence models considered.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ernst Althaus</author>
<author>Nikiforos Karamanis</author>
<author>Alexander Koller</author>
</authors>
<title>Computing locally coherent discourse.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>399--406</pages>
<contexts>
<context position="2772" citStr="Althaus et al., 2005" startWordPosition="405" endWordPosition="408">o their increased scalability and portability. As each of these stochastic models captures different aspects of coherence, an important question is whether we can combine them in a model capable of exploiting all coherence indicators. A frequently used testbed for coherence models is the discourse ordering problem, which occurs often in text generation, complex question answering, and multi-document summarization: given discourse units, what is the most coherent ordering of them (Marcu, 1996; Lapata, 2003; Barzilay and Lee, 2004; Barzilay and Lapata, 2005)? Because the problem is NP-complete (Althaus et al., 2005), it is critical how coherence model evaluation is intertwined with search: if the search for the best ordering is greedy and has many errors, one is not able to properly evaluate whether a model is better than another. If the search is exhaustive, the ordering procedure may take too long to be useful. In this paper, we propose an A search algorithm for the discourse ordering problem that comes with strong theoretical guarantees. For a wide range of practical problems (discourse ordering of up to 15 units), the algorithm finds an optimal solution in reasonable time (on the order of seconds). A</context>
<context position="27784" citStr="Althaus et al. (2005)" startWordPosition="4523" endWordPosition="4526">oblems using stochastic models. Our generation algorithms are fundamentally different from previously-proposed algorithms for discourse generation. The genetic algorithms of Mellish et al. (1998) and Karamanis and Manarung (2002), as well as the greedy algorithm of Lapata (2003), provide no theoretical guarantees on the optimality of the solutions they propose. At the other end of the spectrum, the exhaustive search of Barzilay and Lee (2004), while ensuring optimal solutions, is prohibitively expensive, and cannot be used to perform utility-based training. The linear programming algorithm of Althaus et al. (2005) is the only proposal that achieves both good speed and accuracy. Their algorithm, however, cannot handle models with hidden states, cannot compute -best lists, and does not have the representation flexibility provided by 3Note that these figures cannot be compared directly with the figures reported in (Barzilay and Lapata, 2005), as they use a different type of evaluation. Our EB model achieves the same performance as the original Syntax+Salience model, in their evaluation setting. 809 IDL-expressions, which is crucial for coherence decoding in realistic applications such as multidocument sum</context>
</contexts>
<marker>Althaus, Karamanis, Koller, 2005</marker>
<rawString>Ernst Althaus, Nikiforos Karamanis, and Alexander Koller. 2005. Computing locally coherent discourse. In Proceedings of the ACL, pages 399–406.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Mirella Lapata</author>
</authors>
<title>Modeling local coherence: An entity-based approach.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>141--148</pages>
<contexts>
<context position="1909" citStr="Barzilay and Lapata, 2005" startWordPosition="278" endWordPosition="281">marks a CONCESSION relation), while being oblivious to fine-grained lexical indicators. And the methods that utilize manually annotated corpora (Carlson et al., 2003; Karamanis et al., 2004) and supervised learning algorithms have high costs associated with the annotation procedure, and cannot be easily adapted to different domains and genres. In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical (Lapata, 2003) and global levels (Barzilay and Lee, 2004), while preserving regularities recognized by classic discourse theories (Barzilay and Lapata, 2005). These stochastic coherence models use simple, non-hierarchical representations of discourse, and can be trained with minimal human intervention, using large collections of existing human-authored documents. These models are attractive due to their increased scalability and portability. As each of these stochastic models captures different aspects of coherence, an important question is whether we can combine them in a model capable of exploiting all coherence indicators. A frequently used testbed for coherence models is the discourse ordering problem, which occurs often in text generation, co</context>
<context position="6410" citStr="Barzilay and Lapata (2005)" startWordPosition="981" endWordPosition="984">e for training the publicly-available GIZA++ toolkit, http://www.fjoch.com/GIZA++.html We call the above equation the direct IBM Model 1, as this model considers the words in sentence (the events) as being generated by the words in sentence (the events, which include the special event called the NULL word), with probability . We also define a local coherence inverse IBM Model 1: This model considers the words in sentence (the events) as being generated by the words in sentence (the events, which include the special event called the NULL word), with probability . Entity-based Coherence Models. Barzilay and Lapata (2005) recently proposed an entity-based coherence model that aims to learn abstract coherence properties, similar to those stipulated by Centering Theory (Grosz et al., 1995). Their model learns distribution patterns for transitions between discourse entities that are abstracted into their syntactic roles – subject (S), object (O), other (X), missing (-). The feature values are computed using an entity-grid representation for the discourse that records the syntactic role of each entity as it appears in each sentence. Also, salient entities are differentiated from casually occurring entities, based </context>
<context position="19237" citStr="Barzilay and Lapata, 2005" startWordPosition="3122" endWordPosition="3125">linear and Log-linear , respectively. 4 Experiments We evaluate empirically two different aspects of our work. First, we measure the performance of our search algorithms across different models. Second, we compare the performance of each individual coherence model, and also the performance of the discriminatively trained log-linear models. We also compare the overall performance (model &amp; decoding strategy) obtained in our framework with previously reported results. 4.1 Evaluation setting The task on which we conduct our evaluation is information ordering (Lapata, 2003; Barzilay and Lee, 2004; Barzilay and Lapata, 2005). In this task, a pre-selected set of information-bearing document units (in our case, sentences) needs to be arranged in a sequence which maximizes some specific information quality (in our case, document coherence). We use the information-ordering task as a means to measure the performance of our algorithms and models in a well-controlled setting. As described in Section 3, our framework can be used in applications such as multi-document summarization. In fact, Barzilay et al. (2002) formulate the multi-document summarization problem as an information ordering problem, and show that naive or</context>
<context position="22256" citStr="Barzilay and Lapata (2005)" startWordPosition="3638" endWordPosition="3641"> coherence, for both EARTHQUAKES and ACCIDENTS genre, using IDL-CH-HB . Board’s database. For both collections, we used 100 documents for training and 100 documents for testing. A fraction of 40% of the training documents was temporarily removed and used as a development set, on which we performed the discriminative training procedure. 4.2 Evaluation of Search Algorithms We evaluated the performance of several search algorithms across four stochastic models of document coherence: the IBM and IBM coherence models, the content model of Barzilay and Lee (2004) (CM), and the entity-based model of Barzilay and Lapata (2005) (EB) (Section 2). We measure search performance using an Estimated Search Error (ESE) figure, which reports the percentage of times when the search algorithm proposes a sentence order which scores lower than Overall performance TAU QUAKES ACCID. Lapata (2003) 0.48 0.07 Barzilay &amp; Lee (2004) 0.81 0.44 Barzilay &amp; Lee (reproduced) 0.39 0.36 Barzilay &amp; Lapata (2005) 0.19 0.12 IBM , IDL-CH-HB 0.38 0.41 Log-lin , IDL-CH-HB 0.47 0.50 Table 3: Comparison of overall performance (affected by both model &amp; search procedure) of our framework with previous results. the original sentence order (OSO). We als</context>
<context position="26065" citStr="Barzilay and Lapata (2005)" startWordPosition="4259" endWordPosition="4263">results (Table 3). We are able to provide this comparison based on the TAU figures reported in (Barzilay and Lee, 2004). The training and test data for both genres is the same, and therefore the figures can be directly compared. These figures account for combined model and search performance. We first note that, unfortunately, we failed to accurately reproduce the model of Barzilay and Lee (2004). Our reproduction has an average TAU figure of only .39 versus the original figure of .81 for EARTHQUAKES, and .36 versus .44 for ACCIDENTS. On the other hand, we reproduced successfully the model of Barzilay and Lapata (2005), and the average TAU figure is .19 for EARTHQUAKES, and .12 for ACCIDENTS&apos;. The large difference on the EARTHQUAKES corpus between the performance of Barzilay and Lee (2004) and our reproduction of their model is responsible for the overall lower performance (0.47) of our log-linear model and IDL-CH-HB search algorithm, which is nevertheless higher than that of its component model CM (0.39). On the other hand, we achieve the highest accuracy figure (0.50) on the ACCIDENTS corpus, outperforming the previous-highest figure (0.44) of Barzilay and Lee (2004). These result empirically show that ut</context>
<context position="28115" citStr="Barzilay and Lapata, 2005" startWordPosition="4575" endWordPosition="4578">mality of the solutions they propose. At the other end of the spectrum, the exhaustive search of Barzilay and Lee (2004), while ensuring optimal solutions, is prohibitively expensive, and cannot be used to perform utility-based training. The linear programming algorithm of Althaus et al. (2005) is the only proposal that achieves both good speed and accuracy. Their algorithm, however, cannot handle models with hidden states, cannot compute -best lists, and does not have the representation flexibility provided by 3Note that these figures cannot be compared directly with the figures reported in (Barzilay and Lapata, 2005), as they use a different type of evaluation. Our EB model achieves the same performance as the original Syntax+Salience model, in their evaluation setting. 809 IDL-expressions, which is crucial for coherence decoding in realistic applications such as multidocument summarization. For each of the coherence model combinations that we have utility trained, we obtained improved results on the discourse ordering problem compared to the individual models. This is important for two reasons. Our improvements can have an immediate impact on multi-document summarization applications (Barzilay et al., 20</context>
<context position="22621" citStr="Barzilay &amp; Lapata (2005)" startWordPosition="3697" endWordPosition="3700">rithms We evaluated the performance of several search algorithms across four stochastic models of document coherence: the IBM and IBM coherence models, the content model of Barzilay and Lee (2004) (CM), and the entity-based model of Barzilay and Lapata (2005) (EB) (Section 2). We measure search performance using an Estimated Search Error (ESE) figure, which reports the percentage of times when the search algorithm proposes a sentence order which scores lower than Overall performance TAU QUAKES ACCID. Lapata (2003) 0.48 0.07 Barzilay &amp; Lee (2004) 0.81 0.44 Barzilay &amp; Lee (reproduced) 0.39 0.36 Barzilay &amp; Lapata (2005) 0.19 0.12 IBM , IDL-CH-HB 0.38 0.41 Log-lin , IDL-CH-HB 0.47 0.50 Table 3: Comparison of overall performance (affected by both model &amp; search procedure) of our framework with previous results. the original sentence order (OSO). We also measure the quality of the proposed documents using TAU and BLEU, using as reference the OSO. In Table 1, we report the performance of four search algorithms. The first three, IDL-CH-A , IDL-CH-HB , and IDL-CH-HB are the IDLbased search algorithms of Section 3, implementing A search, histogram beam search with a beam of 100, and histogram beam search with a bea</context>
</contexts>
<marker>Barzilay, Lapata, 2005</marker>
<rawString>Regina Barzilay and Mirella Lapata. 2005. Modeling local coherence: An entity-based approach. In Proceedings of the ACL, pages 141–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Catching the drift: Probabilistic content models, with applications to generation and summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of the HLTNAACL,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="1809" citStr="Barzilay and Lee, 2004" startWordPosition="265" endWordPosition="268">les model only the most visible discourse constraints (e.g., the discourse connective “although” marks a CONCESSION relation), while being oblivious to fine-grained lexical indicators. And the methods that utilize manually annotated corpora (Carlson et al., 2003; Karamanis et al., 2004) and supervised learning algorithms have high costs associated with the annotation procedure, and cannot be easily adapted to different domains and genres. In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical (Lapata, 2003) and global levels (Barzilay and Lee, 2004), while preserving regularities recognized by classic discourse theories (Barzilay and Lapata, 2005). These stochastic coherence models use simple, non-hierarchical representations of discourse, and can be trained with minimal human intervention, using large collections of existing human-authored documents. These models are attractive due to their increased scalability and portability. As each of these stochastic models captures different aspects of coherence, an important question is whether we can combine them in a model capable of exploiting all coherence indicators. A frequently used testb</context>
<context position="7897" citStr="Barzilay and Lee (2004)" startWordPosition="1204" endWordPosition="1207">nce solutions, which assume a pre-specified order (Ng, 2005). In the jargon of (Barzilay and Lapata, 2005), the model we implemented is called Syntax+Salience. The probability assigned to a text by this Entity-Based model (henceforth called EB) can be locally computed (i.e., at sentence transition level) using feature functions, as follows: Here, are feature values, and are weights trained to discriminate between coherent, human-authored documents and examples assumed to have lost some degree of coherence (scrambled versions of the original documents). 2.2 Global Models of Discourse Coherence Barzilay and Lee (2004) propose a document content model that uses a Hidden Markov Model 804 (HMM) to capture more global aspects of coherence. Each state in their HMM corresponds to a distinct “topic”. Topics are determined by an unsupervised algorithm via complete-link clustering, and are written as , with . The probability assigned to a text by this Content Model (henceforth called CM) can be written as follows: A: It said no information had been received about injuries or damage from the mag− nitude 6.1 quake which struck the sparsely inhabited area at 2 43 AM (1843 GMT) B: BC−China−Earthquake|Urgent Earthquake </context>
<context position="13942" citStr="Barzilay and Lee (2004)" startWordPosition="2228" endWordPosition="2231">), and also to work under models with hidden variables such as CM (Section 2.2). These algorithm, called IDL-CH-A (A search for IDL-expressions under Coherence models) and IDL-CH-HB (Histogram-Based beam search for IDL-expressions under Coherence models, with histogram beam ), assume an alphabet of nonatomic (visible) variables (over which the input IDL-expressions are defined), and an alphabet of hidden variables. They unfold an input IDLgraph on-the-fly, as follows: starting from the initial vertex , the input graph is traversed in an IDL-specific manner, by creating states which 2Following Barzilay and Lee (2004), proper names, dates, and numbers are replaced with generic tokens. keep track of positions in any subgraph corresponding to a -argument operator, as well as the last edge traversed and the last hidden variable considered. For instance, state (see the blackened vertices in Figure 2) records that expressions and have already been considered (while is still in the future of state ), and was the last one considered, evaluated under the hidden variable . The information recorded in each state allows for the computation of a current coherence cost under any of the models described in Section 2. In</context>
<context position="17662" citStr="Barzilay and Lee, 2004" startWordPosition="2866" endWordPosition="2869">e accommodate -best computation within the IDL-CH-HB algorithm, which decodes bag-of-units IDL-expressions at an average speed of 75.4 sec./exp. on a 3.0 GHz CPU Linux machine, for an average input of 11.5 units per expression. Second, it needs a criterion which can automatically assess the quality of the proposed candidates. To this end, we employ two different metrics, such that we can measure the impact of using different utility functions on performance. TAU (Kendall’s ). One of the most frequently used metrics for the automatic evaluation of document coherence is Kendall’s (Lapata, 2003; Barzilay and Lee, 2004). TAU measures the minimum number of adjacent transpositions needed to transform a proposed order into a reference order. The range of the TAU metric is between -1 (the worst) to 1 (the best). BLEU. One of the most successful metrics for judging machine-generated text is BLEU (Papineni et al., 2002). It counts the number of unigram, bigram, trigram, and four-gram matches between hypothesis and reference, and combines them using geometric mean. For the discourse ordering problem, we represent hypotheses and references by index sequences (e.g., “4 2 3 1” is a hypothesis order over four discourse</context>
<context position="19209" citStr="Barzilay and Lee, 2004" startWordPosition="3118" endWordPosition="3121"> obtained are called Loglinear and Log-linear , respectively. 4 Experiments We evaluate empirically two different aspects of our work. First, we measure the performance of our search algorithms across different models. Second, we compare the performance of each individual coherence model, and also the performance of the discriminatively trained log-linear models. We also compare the overall performance (model &amp; decoding strategy) obtained in our framework with previously reported results. 4.1 Evaluation setting The task on which we conduct our evaluation is information ordering (Lapata, 2003; Barzilay and Lee, 2004; Barzilay and Lapata, 2005). In this task, a pre-selected set of information-bearing document units (in our case, sentences) needs to be arranged in a sequence which maximizes some specific information quality (in our case, document coherence). We use the information-ordering task as a means to measure the performance of our algorithms and models in a well-controlled setting. As described in Section 3, our framework can be used in applications such as multi-document summarization. In fact, Barzilay et al. (2002) formulate the multi-document summarization problem as an information ordering pro</context>
<context position="22193" citStr="Barzilay and Lee (2004)" startWordPosition="3628" endWordPosition="3631">49 .24 Table 2: Evaluation of stochastic models for document coherence, for both EARTHQUAKES and ACCIDENTS genre, using IDL-CH-HB . Board’s database. For both collections, we used 100 documents for training and 100 documents for testing. A fraction of 40% of the training documents was temporarily removed and used as a development set, on which we performed the discriminative training procedure. 4.2 Evaluation of Search Algorithms We evaluated the performance of several search algorithms across four stochastic models of document coherence: the IBM and IBM coherence models, the content model of Barzilay and Lee (2004) (CM), and the entity-based model of Barzilay and Lapata (2005) (EB) (Section 2). We measure search performance using an Estimated Search Error (ESE) figure, which reports the percentage of times when the search algorithm proposes a sentence order which scores lower than Overall performance TAU QUAKES ACCID. Lapata (2003) 0.48 0.07 Barzilay &amp; Lee (2004) 0.81 0.44 Barzilay &amp; Lee (reproduced) 0.39 0.36 Barzilay &amp; Lapata (2005) 0.19 0.12 IBM , IDL-CH-HB 0.38 0.41 Log-lin , IDL-CH-HB 0.47 0.50 Table 3: Comparison of overall performance (affected by both model &amp; search procedure) of our framework w</context>
<context position="25558" citStr="Barzilay and Lee, 2004" startWordPosition="4172" endWordPosition="4175"> highest BLEU accuracy is obtained when using BLEU to perform utility-based training of the parameters (.16 for EARTHQUAKES, .24 for the ACCIDENTS). For both genres, the differences between the highest accuracy figures (in bold) and the accuracy of the individual models are statistically significant at 95% confidence (using bootstrap resampling). 4.4 Overall Performance Evaluation The last comparison we provide is between the performance provided by our framework and previously-reported performance results (Table 3). We are able to provide this comparison based on the TAU figures reported in (Barzilay and Lee, 2004). The training and test data for both genres is the same, and therefore the figures can be directly compared. These figures account for combined model and search performance. We first note that, unfortunately, we failed to accurately reproduce the model of Barzilay and Lee (2004). Our reproduction has an average TAU figure of only .39 versus the original figure of .81 for EARTHQUAKES, and .36 versus .44 for ACCIDENTS. On the other hand, we reproduced successfully the model of Barzilay and Lapata (2005), and the average TAU figure is .19 for EARTHQUAKES, and .12 for ACCIDENTS&apos;. The large differ</context>
<context position="27609" citStr="Barzilay and Lee (2004)" startWordPosition="4497" endWordPosition="4500"> individual models. An important ingredient of this framework are the search algorithms based on IDL-expressions, which provide a flexible way of solving discourse generation problems using stochastic models. Our generation algorithms are fundamentally different from previously-proposed algorithms for discourse generation. The genetic algorithms of Mellish et al. (1998) and Karamanis and Manarung (2002), as well as the greedy algorithm of Lapata (2003), provide no theoretical guarantees on the optimality of the solutions they propose. At the other end of the spectrum, the exhaustive search of Barzilay and Lee (2004), while ensuring optimal solutions, is prohibitively expensive, and cannot be used to perform utility-based training. The linear programming algorithm of Althaus et al. (2005) is the only proposal that achieves both good speed and accuracy. Their algorithm, however, cannot handle models with hidden states, cannot compute -best lists, and does not have the representation flexibility provided by 3Note that these figures cannot be compared directly with the figures reported in (Barzilay and Lapata, 2005), as they use a different type of evaluation. Our EB model achieves the same performance as th</context>
<context position="22548" citStr="Barzilay &amp; Lee (2004)" startWordPosition="3685" endWordPosition="3688">d the discriminative training procedure. 4.2 Evaluation of Search Algorithms We evaluated the performance of several search algorithms across four stochastic models of document coherence: the IBM and IBM coherence models, the content model of Barzilay and Lee (2004) (CM), and the entity-based model of Barzilay and Lapata (2005) (EB) (Section 2). We measure search performance using an Estimated Search Error (ESE) figure, which reports the percentage of times when the search algorithm proposes a sentence order which scores lower than Overall performance TAU QUAKES ACCID. Lapata (2003) 0.48 0.07 Barzilay &amp; Lee (2004) 0.81 0.44 Barzilay &amp; Lee (reproduced) 0.39 0.36 Barzilay &amp; Lapata (2005) 0.19 0.12 IBM , IDL-CH-HB 0.38 0.41 Log-lin , IDL-CH-HB 0.47 0.50 Table 3: Comparison of overall performance (affected by both model &amp; search procedure) of our framework with previous results. the original sentence order (OSO). We also measure the quality of the proposed documents using TAU and BLEU, using as reference the OSO. In Table 1, we report the performance of four search algorithms. The first three, IDL-CH-A , IDL-CH-HB , and IDL-CH-HB are the IDLbased search algorithms of Section 3, implementing A search, histo</context>
</contexts>
<marker>Barzilay, Lee, 2004</marker>
<rawString>Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of the HLTNAACL, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Noemie Elhadad</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Inferring strategies for sentence ordering in multidocument news summarization.</title>
<date>2002</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<pages>17--35</pages>
<contexts>
<context position="19727" citStr="Barzilay et al. (2002)" startWordPosition="3199" endWordPosition="3202">he task on which we conduct our evaluation is information ordering (Lapata, 2003; Barzilay and Lee, 2004; Barzilay and Lapata, 2005). In this task, a pre-selected set of information-bearing document units (in our case, sentences) needs to be arranged in a sequence which maximizes some specific information quality (in our case, document coherence). We use the information-ordering task as a means to measure the performance of our algorithms and models in a well-controlled setting. As described in Section 3, our framework can be used in applications such as multi-document summarization. In fact, Barzilay et al. (2002) formulate the multi-document summarization problem as an information ordering problem, and show that naive ordering algorithms such as majority ordering (select most frequent orders across input documents) and chronological ordering (order facts according to publication date) do not always yield coherent summaries. Data. For training and testing, we use documents from two different genres: newspaper articles and accident reports written by government officials (Barzilay and Lapata, 2005). The first collection (henceforth called EARTHQUAKES) consists of Associated Press articles from the North</context>
</contexts>
<marker>Barzilay, Elhadad, McKeown, 2002</marker>
<rawString>Regina Barzilay, Noemie Elhadad, and Kathleen R. McKeown. 2002. Inferring strategies for sentence ordering in multidocument news summarization. Journal ofArtificial Intelligence Research, 17:35–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="5112" citStr="Brown et al., 1993" startWordPosition="769" endWordPosition="772">cal models of coherence work under the assumption that well-formed discourse can be characterized in terms of specific distributions of local recurring patterns. These distributions can be defined at the lexical level or entity-based levels. Word-Coocurrence Coherence Models. We propose a new coherence model, inspired by (Knight, 2003), that models the intuition that the usage of certain words in a discourse unit (sentence) tends to trigger the usage of other words in subsequent discourse units. (A similar intuition holds for the Machine Translation models generically known as the IBM models (Brown et al., 1993), which assume that certain words in a source language sentence tend to trigger the usage of certain words in a target language translation of that sentence.) We train models able to recognize local recurring patterns of word usage across sentences in an unsupervised manner, by running an ExpectationMaximization (EM) procedure over pairs of consecutive sentences extracted from a large collection of training documents&apos;. We expect EM to detect and assign higher probabilities to recurring word patterns compared to casually occurring word patterns. A local coherence model based on IBM Model 1 assi</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Carlson</author>
<author>D Marcu</author>
<author>M E Okurowski</author>
</authors>
<title>Building a discourse-tagged corpus in the framework of Rhetorical Structure Theory.</title>
<date>2003</date>
<booktitle>Current Directions in Discourse and Dialogue.</booktitle>
<editor>In J. van Kuppevelt and R. Smith, eds.,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1448" citStr="Carlson et al., 2003" startWordPosition="210" endWordPosition="213">Introduction Various theories of discourse coherence (Mann and Thompson, 1988; Grosz et al., 1995) have been applied successfully in discourse analysis (Marcu, 2000; Forbes et al., 2001) and discourse generation (Scott and de Souza, 1990; Kibble and Power, 2004). Most of these efforts, however, have limited applicability. Those that use manually written rules model only the most visible discourse constraints (e.g., the discourse connective “although” marks a CONCESSION relation), while being oblivious to fine-grained lexical indicators. And the methods that utilize manually annotated corpora (Carlson et al., 2003; Karamanis et al., 2004) and supervised learning algorithms have high costs associated with the annotation procedure, and cannot be easily adapted to different domains and genres. In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical (Lapata, 2003) and global levels (Barzilay and Lee, 2004), while preserving regularities recognized by classic discourse theories (Barzilay and Lapata, 2005). These stochastic coherence models use simple, non-hierarchical representations of discourse, and can be trained with minimal human interv</context>
</contexts>
<marker>Carlson, Marcu, Okurowski, 2003</marker>
<rawString>L. Carlson, D. Marcu, and M. E. Okurowski. 2003. Building a discourse-tagged corpus in the framework of Rhetorical Structure Theory. In J. van Kuppevelt and R. Smith, eds., Current Directions in Discourse and Dialogue. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Forbes</author>
<author>E Miltsakaki</author>
<author>R Prasad</author>
<author>A Sarkar</author>
<author>A Joshi</author>
<author>B Webber</author>
</authors>
<title>D-LTAG System: Discourse parsing with a lexicalized tree-adjoining grammar.</title>
<date>2001</date>
<booktitle>In Workshop on Information Structure, Discourse Structure and Discourse Semantics.</booktitle>
<contexts>
<context position="1014" citStr="Forbes et al., 2001" startWordPosition="142" endWordPosition="145">k for integrating various stochastic models of discourse coherence in a manner that takes advantage of their individual strengths. An integral part of this framework are algorithms for searching and training these stochastic coherence models. We evaluate the performance of our models and algorithms and show empirically that utilitytrained log-linear coherence models outperform each of the individual coherence models considered. 1 Introduction Various theories of discourse coherence (Mann and Thompson, 1988; Grosz et al., 1995) have been applied successfully in discourse analysis (Marcu, 2000; Forbes et al., 2001) and discourse generation (Scott and de Souza, 1990; Kibble and Power, 2004). Most of these efforts, however, have limited applicability. Those that use manually written rules model only the most visible discourse constraints (e.g., the discourse connective “although” marks a CONCESSION relation), while being oblivious to fine-grained lexical indicators. And the methods that utilize manually annotated corpora (Carlson et al., 2003; Karamanis et al., 2004) and supervised learning algorithms have high costs associated with the annotation procedure, and cannot be easily adapted to different domai</context>
</contexts>
<marker>Forbes, Miltsakaki, Prasad, Sarkar, Joshi, Webber, 2001</marker>
<rawString>K. Forbes, E. Miltsakaki, R. Prasad, A. Sarkar, A. Joshi, and B. Webber. 2001. D-LTAG System: Discourse parsing with a lexicalized tree-adjoining grammar. In Workshop on Information Structure, Discourse Structure and Discourse Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="926" citStr="Grosz et al., 1995" startWordPosition="128" endWordPosition="131">ite 1001 Marina del Rey, CA 90292 marcu@isi.edu Abstract We describe a generic framework for integrating various stochastic models of discourse coherence in a manner that takes advantage of their individual strengths. An integral part of this framework are algorithms for searching and training these stochastic coherence models. We evaluate the performance of our models and algorithms and show empirically that utilitytrained log-linear coherence models outperform each of the individual coherence models considered. 1 Introduction Various theories of discourse coherence (Mann and Thompson, 1988; Grosz et al., 1995) have been applied successfully in discourse analysis (Marcu, 2000; Forbes et al., 2001) and discourse generation (Scott and de Souza, 1990; Kibble and Power, 2004). Most of these efforts, however, have limited applicability. Those that use manually written rules model only the most visible discourse constraints (e.g., the discourse connective “although” marks a CONCESSION relation), while being oblivious to fine-grained lexical indicators. And the methods that utilize manually annotated corpora (Carlson et al., 2003; Karamanis et al., 2004) and supervised learning algorithms have high costs a</context>
<context position="6579" citStr="Grosz et al., 1995" startWordPosition="1007" endWordPosition="1010">entence (the events) as being generated by the words in sentence (the events, which include the special event called the NULL word), with probability . We also define a local coherence inverse IBM Model 1: This model considers the words in sentence (the events) as being generated by the words in sentence (the events, which include the special event called the NULL word), with probability . Entity-based Coherence Models. Barzilay and Lapata (2005) recently proposed an entity-based coherence model that aims to learn abstract coherence properties, similar to those stipulated by Centering Theory (Grosz et al., 1995). Their model learns distribution patterns for transitions between discourse entities that are abstracted into their syntactic roles – subject (S), object (O), other (X), missing (-). The feature values are computed using an entity-grid representation for the discourse that records the syntactic role of each entity as it appears in each sentence. Also, salient entities are differentiated from casually occurring entities, based on the widely used assumption that occurrence frequency correlates with discourse prominence (Morris and Hirst, 1991; Grosz et al., 1995). We exclude the coreference inf</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Better k-best parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Workshop on Parsing Technologies (IWPT</booktitle>
<contexts>
<context position="17036" citStr="Huang and Chiang, 2005" startWordPosition="2767" endWordPosition="2770">aining In addition to the modeling problem, we must also address the training problem, which amounts to finding appropriate values for the parameters from Equation 1. The solution we employ here is the discriminative training procedure of Och (2003). This procedure learns an optimal setting of the parameters using as optimality criterion the utility of the proposed solution. There are two necessary ingredients to implement Och’s (2003) training procedure. First, it needs a search algorithm that is able to produce ranked -best lists of the most promising candidates in a reasonably fast manner (Huang and Chiang, 2005). We accommodate -best computation within the IDL-CH-HB algorithm, which decodes bag-of-units IDL-expressions at an average speed of 75.4 sec./exp. on a 3.0 GHz CPU Linux machine, for an average input of 11.5 units per expression. Second, it needs a criterion which can automatically assess the quality of the proposed candidates. To this end, we employ two different metrics, such that we can measure the impact of using different utility functions on performance. TAU (Kendall’s ). One of the most frequently used metrics for the automatic evaluation of document coherence is Kendall’s (Lapata, 200</context>
</contexts>
<marker>Huang, Chiang, 2005</marker>
<rawString>Liang Huang and David Chiang. 2005. Better k-best parsing. In Proceedings of the International Workshop on Parsing Technologies (IWPT 2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikiforos Karamanis</author>
<author>Hisar M Manurung</author>
</authors>
<title>Stochastic text structuring using the principle of continuity.</title>
<date>2002</date>
<booktitle>In Proceedings ofINLG,</booktitle>
<pages>81--88</pages>
<marker>Karamanis, Manurung, 2002</marker>
<rawString>Nikiforos Karamanis and Hisar M. Manurung. 2002. Stochastic text structuring using the principle of continuity. In Proceedings ofINLG, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikiforos Karamanis</author>
<author>Massimo Poesio</author>
<author>Chris Mellish</author>
<author>Jon Oberlander</author>
</authors>
<title>Evaluating centering-based metrics of coherence for text structuring using a reliably annotated corpus.</title>
<date>2004</date>
<booktitle>In Proc. of the ACL.</booktitle>
<contexts>
<context position="1473" citStr="Karamanis et al., 2004" startWordPosition="214" endWordPosition="217">heories of discourse coherence (Mann and Thompson, 1988; Grosz et al., 1995) have been applied successfully in discourse analysis (Marcu, 2000; Forbes et al., 2001) and discourse generation (Scott and de Souza, 1990; Kibble and Power, 2004). Most of these efforts, however, have limited applicability. Those that use manually written rules model only the most visible discourse constraints (e.g., the discourse connective “although” marks a CONCESSION relation), while being oblivious to fine-grained lexical indicators. And the methods that utilize manually annotated corpora (Carlson et al., 2003; Karamanis et al., 2004) and supervised learning algorithms have high costs associated with the annotation procedure, and cannot be easily adapted to different domains and genres. In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical (Lapata, 2003) and global levels (Barzilay and Lee, 2004), while preserving regularities recognized by classic discourse theories (Barzilay and Lapata, 2005). These stochastic coherence models use simple, non-hierarchical representations of discourse, and can be trained with minimal human intervention, using large colle</context>
</contexts>
<marker>Karamanis, Poesio, Mellish, Oberlander, 2004</marker>
<rawString>Nikiforos Karamanis, Massimo Poesio, Chris Mellish, and Jon Oberlander. 2004. Evaluating centering-based metrics of coherence for text structuring using a reliably annotated corpus. In Proc. of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodger Kibble</author>
<author>Richard Power</author>
</authors>
<title>Optimising referential coherence in text generation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="1090" citStr="Kibble and Power, 2004" startWordPosition="155" endWordPosition="159">anner that takes advantage of their individual strengths. An integral part of this framework are algorithms for searching and training these stochastic coherence models. We evaluate the performance of our models and algorithms and show empirically that utilitytrained log-linear coherence models outperform each of the individual coherence models considered. 1 Introduction Various theories of discourse coherence (Mann and Thompson, 1988; Grosz et al., 1995) have been applied successfully in discourse analysis (Marcu, 2000; Forbes et al., 2001) and discourse generation (Scott and de Souza, 1990; Kibble and Power, 2004). Most of these efforts, however, have limited applicability. Those that use manually written rules model only the most visible discourse constraints (e.g., the discourse connective “although” marks a CONCESSION relation), while being oblivious to fine-grained lexical indicators. And the methods that utilize manually annotated corpora (Carlson et al., 2003; Karamanis et al., 2004) and supervised learning algorithms have high costs associated with the annotation procedure, and cannot be easily adapted to different domains and genres. In contrast, more recent research has focused on stochastic a</context>
</contexts>
<marker>Kibble, Power, 2004</marker>
<rawString>Rodger Kibble and Richard Power. 2004. Optimising referential coherence in text generation. Computational Linguistics, 30(4):410–416.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
</authors>
<date>2003</date>
<tech>Personal Communication.</tech>
<contexts>
<context position="4830" citStr="Knight, 2003" startWordPosition="724" endWordPosition="725">roposed and new coherence models. Then, we present our search algorithms and the input representation they use. Finally, we show evaluation results and discuss their implications. 2 Stochastic Models of Discourse Coherence 2.1 Local Models of Discourse Coherence Stochastic local models of coherence work under the assumption that well-formed discourse can be characterized in terms of specific distributions of local recurring patterns. These distributions can be defined at the lexical level or entity-based levels. Word-Coocurrence Coherence Models. We propose a new coherence model, inspired by (Knight, 2003), that models the intuition that the usage of certain words in a discourse unit (sentence) tends to trigger the usage of other words in subsequent discourse units. (A similar intuition holds for the Machine Translation models generically known as the IBM models (Brown et al., 1993), which assume that certain words in a source language sentence tend to trigger the usage of certain words in a target language translation of that sentence.) We train models able to recognize local recurring patterns of word usage across sentences in an unsupervised manner, by running an ExpectationMaximization (EM)</context>
</contexts>
<marker>Knight, 2003</marker>
<rawString>Kevin Knight. 2003. Personal Communication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>Probabilistic text structuring: Experiments with text ordering.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>545--552</pages>
<contexts>
<context position="1766" citStr="Lapata, 2003" startWordPosition="260" endWordPosition="261">hose that use manually written rules model only the most visible discourse constraints (e.g., the discourse connective “although” marks a CONCESSION relation), while being oblivious to fine-grained lexical indicators. And the methods that utilize manually annotated corpora (Carlson et al., 2003; Karamanis et al., 2004) and supervised learning algorithms have high costs associated with the annotation procedure, and cannot be easily adapted to different domains and genres. In contrast, more recent research has focused on stochastic approaches that model discourse coherence at the local lexical (Lapata, 2003) and global levels (Barzilay and Lee, 2004), while preserving regularities recognized by classic discourse theories (Barzilay and Lapata, 2005). These stochastic coherence models use simple, non-hierarchical representations of discourse, and can be trained with minimal human intervention, using large collections of existing human-authored documents. These models are attractive due to their increased scalability and portability. As each of these stochastic models captures different aspects of coherence, an important question is whether we can combine them in a model capable of exploiting all co</context>
<context position="17637" citStr="Lapata, 2003" startWordPosition="2864" endWordPosition="2865">iang, 2005). We accommodate -best computation within the IDL-CH-HB algorithm, which decodes bag-of-units IDL-expressions at an average speed of 75.4 sec./exp. on a 3.0 GHz CPU Linux machine, for an average input of 11.5 units per expression. Second, it needs a criterion which can automatically assess the quality of the proposed candidates. To this end, we employ two different metrics, such that we can measure the impact of using different utility functions on performance. TAU (Kendall’s ). One of the most frequently used metrics for the automatic evaluation of document coherence is Kendall’s (Lapata, 2003; Barzilay and Lee, 2004). TAU measures the minimum number of adjacent transpositions needed to transform a proposed order into a reference order. The range of the TAU metric is between -1 (the worst) to 1 (the best). BLEU. One of the most successful metrics for judging machine-generated text is BLEU (Papineni et al., 2002). It counts the number of unigram, bigram, trigram, and four-gram matches between hypothesis and reference, and combines them using geometric mean. For the discourse ordering problem, we represent hypotheses and references by index sequences (e.g., “4 2 3 1” is a hypothesis </context>
<context position="19185" citStr="Lapata, 2003" startWordPosition="3116" endWordPosition="3117">ar models thus obtained are called Loglinear and Log-linear , respectively. 4 Experiments We evaluate empirically two different aspects of our work. First, we measure the performance of our search algorithms across different models. Second, we compare the performance of each individual coherence model, and also the performance of the discriminatively trained log-linear models. We also compare the overall performance (model &amp; decoding strategy) obtained in our framework with previously reported results. 4.1 Evaluation setting The task on which we conduct our evaluation is information ordering (Lapata, 2003; Barzilay and Lee, 2004; Barzilay and Lapata, 2005). In this task, a pre-selected set of information-bearing document units (in our case, sentences) needs to be arranged in a sequence which maximizes some specific information quality (in our case, document coherence). We use the information-ordering task as a means to measure the performance of our algorithms and models in a well-controlled setting. As described in Section 3, our framework can be used in applications such as multi-document summarization. In fact, Barzilay et al. (2002) formulate the multi-document summarization problem as an </context>
<context position="20789" citStr="Lapata, 2003" startWordPosition="3375" endWordPosition="3376">nment officials (Barzilay and Lapata, 2005). The first collection (henceforth called EARTHQUAKES) consists of Associated Press articles from the North American News Corpus on the topic of natural disasters. The second collection (henceforth called ACCIDENTS) consists of aviation accident reports from the National Transportation Safety 807 Search Algorithm IBM IBM CM EB ESE TAU BLEU ESE TAU BLEU ESE TAU BLEU ESE TAU BLEU EARTHQUAKES IDL-CH-A 0% .39 .12 0% .33 .13 0% .39 .12 0% .19 .05 IDL-CH-HB 0% .38 .12 0% .32 .13 0% .39 .12 0% .19 .06 IDL-CH-HB 4% .37 .13 13% .34 .14 36% .32 .11 16% .18 .05 Lapata, 2003 90% .01 .04 58% .02 .06 97% .05 .04 46% -.05 .00 ACCIDENTS IDL-CH-A 0% .41 .21 0% .40 .21 0% .37 .15 0% .13 .10 IDL-CH-HB 0% .41 .20 0% .40 .21 2% .36 .15 0% .12 .10 IDL-CH-HB 0% .38 .19 12% .32 .20 13% .34 .13 33% -.04 .06 Lapata, 2003 86% .11 .03 67% .12 .05 85% .18 .00 24% -.05 .06 Table 1: Evaluation of search algorithms for document coherence, for both EARTHQUAKES and ACCIDENTS genres, across the IBM , IBM , CM, and EB models. Performance is measured in terms of percentage of Estimated Search Errors (ESE), as well as quality of found realizations (average TAU and BLEU). Model TAU BLEU TA</context>
<context position="22516" citStr="Lapata (2003)" startWordPosition="3681" endWordPosition="3682">et, on which we performed the discriminative training procedure. 4.2 Evaluation of Search Algorithms We evaluated the performance of several search algorithms across four stochastic models of document coherence: the IBM and IBM coherence models, the content model of Barzilay and Lee (2004) (CM), and the entity-based model of Barzilay and Lapata (2005) (EB) (Section 2). We measure search performance using an Estimated Search Error (ESE) figure, which reports the percentage of times when the search algorithm proposes a sentence order which scores lower than Overall performance TAU QUAKES ACCID. Lapata (2003) 0.48 0.07 Barzilay &amp; Lee (2004) 0.81 0.44 Barzilay &amp; Lee (reproduced) 0.39 0.36 Barzilay &amp; Lapata (2005) 0.19 0.12 IBM , IDL-CH-HB 0.38 0.41 Log-lin , IDL-CH-HB 0.47 0.50 Table 3: Comparison of overall performance (affected by both model &amp; search procedure) of our framework with previous results. the original sentence order (OSO). We also measure the quality of the proposed documents using TAU and BLEU, using as reference the OSO. In Table 1, we report the performance of four search algorithms. The first three, IDL-CH-A , IDL-CH-HB , and IDL-CH-HB are the IDLbased search algorithms of Section</context>
<context position="23952" citStr="Lapata (2003)" startWordPosition="3920" endWordPosition="3921">the comparison is rendered meaningful by the observation that this algorithm performs search identically with algorithm IDL-CH-HB (histogram beam 1), when setting the heuristic function for future costs to constant 0. The results in Table 1 clearly show the superiority of the IDL-CH-A and IDL-CH-HB algo808 rithms. Across all models considered, they consistently propose documents with scores at least as good as OSO (0% Estimated Search Error). As the original documents were coherent, it follows that the proposed document realizations also exhibit coherence. In contrast, the greedy algorithm of Lapata (2003) makes grave search errors. As the comparison between IDL-CH-HB and IDLCH-HB shows, the superiority of the IDL-CH algorithms depends more on the admissible heuristic function than in the ability to maintain multiple hypotheses while searching. 4.3 Evaluation of Log-linear Models For this round of experiments, we held constant the search procedure (IDL-CH-HB ), and varied the parameters of Equation 1. The utility-trained log-linear models are compared here against a baseline log-linear model loglinear , for which all parameters are set to 1, and also against the individual models. The results a</context>
<context position="27442" citStr="Lapata (2003)" startWordPosition="4471" endWordPosition="4472">neric framework that is capable of integrating various stochastic models of discourse coherence into a more powerful model that combines the strengths of the individual models. An important ingredient of this framework are the search algorithms based on IDL-expressions, which provide a flexible way of solving discourse generation problems using stochastic models. Our generation algorithms are fundamentally different from previously-proposed algorithms for discourse generation. The genetic algorithms of Mellish et al. (1998) and Karamanis and Manarung (2002), as well as the greedy algorithm of Lapata (2003), provide no theoretical guarantees on the optimality of the solutions they propose. At the other end of the spectrum, the exhaustive search of Barzilay and Lee (2004), while ensuring optimal solutions, is prohibitively expensive, and cannot be used to perform utility-based training. The linear programming algorithm of Althaus et al. (2005) is the only proposal that achieves both good speed and accuracy. Their algorithm, however, cannot handle models with hidden states, cannot compute -best lists, and does not have the representation flexibility provided by 3Note that these figures cannot be c</context>
</contexts>
<marker>Lapata, 2003</marker>
<rawString>Mirella Lapata. 2003. Probabilistic text structuring: Experiments with text ordering. In Proceedings of the ACL, pages 545–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<contexts>
<context position="905" citStr="Mann and Thompson, 1988" startWordPosition="124" endWordPosition="127">ia 4676 Admiralty Way, Suite 1001 Marina del Rey, CA 90292 marcu@isi.edu Abstract We describe a generic framework for integrating various stochastic models of discourse coherence in a manner that takes advantage of their individual strengths. An integral part of this framework are algorithms for searching and training these stochastic coherence models. We evaluate the performance of our models and algorithms and show empirically that utilitytrained log-linear coherence models outperform each of the individual coherence models considered. 1 Introduction Various theories of discourse coherence (Mann and Thompson, 1988; Grosz et al., 1995) have been applied successfully in discourse analysis (Marcu, 2000; Forbes et al., 2001) and discourse generation (Scott and de Souza, 1990; Kibble and Power, 2004). Most of these efforts, however, have limited applicability. Those that use manually written rules model only the most visible discourse constraints (e.g., the discourse connective “although” marks a CONCESSION relation), while being oblivious to fine-grained lexical indicators. And the methods that utilize manually annotated corpora (Carlson et al., 2003; Karamanis et al., 2004) and supervised learning algorit</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1988. Rhetorical Structure Theory: Toward a functional theory of text organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<date>1996</date>
<booktitle>In Proceedings of the Student Conference on Computational Linguistics,</booktitle>
<pages>136--143</pages>
<contexts>
<context position="2647" citStr="Marcu, 1996" startWordPosition="387" endWordPosition="388">human intervention, using large collections of existing human-authored documents. These models are attractive due to their increased scalability and portability. As each of these stochastic models captures different aspects of coherence, an important question is whether we can combine them in a model capable of exploiting all coherence indicators. A frequently used testbed for coherence models is the discourse ordering problem, which occurs often in text generation, complex question answering, and multi-document summarization: given discourse units, what is the most coherent ordering of them (Marcu, 1996; Lapata, 2003; Barzilay and Lee, 2004; Barzilay and Lapata, 2005)? Because the problem is NP-complete (Althaus et al., 2005), it is critical how coherence model evaluation is intertwined with search: if the search for the best ordering is greedy and has many errors, one is not able to properly evaluate whether a model is better than another. If the search is exhaustive, the ordering procedure may take too long to be useful. In this paper, we propose an A search algorithm for the discourse ordering problem that comes with strong theoretical guarantees. For a wide range of practical problems (d</context>
</contexts>
<marker>Marcu, 1996</marker>
<rawString>Daniel Marcu. 1996. In Proceedings of the Student Conference on Computational Linguistics, pages 136-143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The Theory and Practice of Discourse Parsing and Summarization.</title>
<date>2000</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="992" citStr="Marcu, 2000" startWordPosition="140" endWordPosition="141">eric framework for integrating various stochastic models of discourse coherence in a manner that takes advantage of their individual strengths. An integral part of this framework are algorithms for searching and training these stochastic coherence models. We evaluate the performance of our models and algorithms and show empirically that utilitytrained log-linear coherence models outperform each of the individual coherence models considered. 1 Introduction Various theories of discourse coherence (Mann and Thompson, 1988; Grosz et al., 1995) have been applied successfully in discourse analysis (Marcu, 2000; Forbes et al., 2001) and discourse generation (Scott and de Souza, 1990; Kibble and Power, 2004). Most of these efforts, however, have limited applicability. Those that use manually written rules model only the most visible discourse constraints (e.g., the discourse connective “although” marks a CONCESSION relation), while being oblivious to fine-grained lexical indicators. And the methods that utilize manually annotated corpora (Carlson et al., 2003; Karamanis et al., 2004) and supervised learning algorithms have high costs associated with the annotation procedure, and cannot be easily adap</context>
</contexts>
<marker>Marcu, 2000</marker>
<rawString>Daniel Marcu. 2000. The Theory and Practice of Discourse Parsing and Summarization. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Mellish</author>
<author>Alistair Knott</author>
<author>Jon Oberlander</author>
<author>Mick O’Donnell</author>
</authors>
<title>Experiments using stochastic search for text planning.</title>
<date>1998</date>
<booktitle>In Proceedings of the INLG,</booktitle>
<pages>98--107</pages>
<marker>Mellish, Knott, Oberlander, O’Donnell, 1998</marker>
<rawString>Chris Mellish, Alistair Knott, Jon Oberlander, and Mick O’Donnell. 1998. Experiments using stochastic search for text planning. In Proceedings of the INLG, pages 98– 107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Morris</author>
<author>Graeme Hirst</author>
</authors>
<title>Lexical cohesion computed by thesaural relations as an indicator of the structure of text.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="7126" citStr="Morris and Hirst, 1991" startWordPosition="1089" endWordPosition="1092">rties, similar to those stipulated by Centering Theory (Grosz et al., 1995). Their model learns distribution patterns for transitions between discourse entities that are abstracted into their syntactic roles – subject (S), object (O), other (X), missing (-). The feature values are computed using an entity-grid representation for the discourse that records the syntactic role of each entity as it appears in each sentence. Also, salient entities are differentiated from casually occurring entities, based on the widely used assumption that occurrence frequency correlates with discourse prominence (Morris and Hirst, 1991; Grosz et al., 1995). We exclude the coreference information from this model, as the discourse ordering problem cannot accommodate current coreference solutions, which assume a pre-specified order (Ng, 2005). In the jargon of (Barzilay and Lapata, 2005), the model we implemented is called Syntax+Salience. The probability assigned to a text by this Entity-Based model (henceforth called EB) can be locally computed (i.e., at sentence transition level) using feature functions, as follows: Here, are feature values, and are weights trained to discriminate between coherent, human-authored documents </context>
</contexts>
<marker>Morris, Hirst, 1991</marker>
<rawString>Jane Morris and Graeme Hirst. 1991. Lexical cohesion computed by thesaural relations as an indicator of the structure of text. Computational Linguistics, 17(1):21–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark-Jan Nederhof</author>
<author>Giorgio Satta</author>
</authors>
<title>IDLexpressions: a formalism for representing and parsing finite languages in natural language processing.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>287--317</pages>
<contexts>
<context position="10901" citStr="Nederhof and Satta, 2004" startWordPosition="1729" endWordPosition="1733">nce. &amp;quot;−Name− ( −Name− ) a strong earthquake hit the −Name− −Name− in g: northwestern −Name− early −Name− the official −Name− −Name− −Name− reported ## −−−−−−−−−SXXOSXOXSSS−&amp;quot; Figure 1: Example consisting of discourse units A, B, and C (a). In (b), their entities are detected (underlined) and assigned syntactic roles: S (subject), O (object), X (other), - (missing). In (c), terms , and encode these discourse units for model scoring purposes. 3 Search Algorithms for Coherent Discourses and Utility-Based Training The algorithms we propose use as input representation the IDL-expressions formalism (Nederhof and Satta, 2004; Soricut and Marcu, 2005). We use here the IDL formalism (which stands for Interleave, Disjunction, Lock, after the names of its operators) to define finite sets of possible discourses over given discourse units. Without losing generality, we will consider sentences as discourse units in our examples and experiments. 3.1 Input Representation Consider the discourse units A-C presented in Figure 1(a). Each of these units undergoes various processing stages in order to provide the information needed by our coherence models. The entity-based model (EB) (Section 2), for instance, makes use of a sy</context>
</contexts>
<marker>Nederhof, Satta, 2004</marker>
<rawString>Mark-Jan Nederhof and Giorgio Satta. 2004. IDLexpressions: a formalism for representing and parsing finite languages in natural language processing. Journal of Artificial Intelligence Research, pages 287–317.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Machine learning for coreference resolution: from local clasiffication to global reranking.</title>
<date>2005</date>
<booktitle>In Procedings of the ACL,</booktitle>
<pages>157--164</pages>
<contexts>
<context position="7334" citStr="Ng, 2005" startWordPosition="1121" endWordPosition="1122">, object (O), other (X), missing (-). The feature values are computed using an entity-grid representation for the discourse that records the syntactic role of each entity as it appears in each sentence. Also, salient entities are differentiated from casually occurring entities, based on the widely used assumption that occurrence frequency correlates with discourse prominence (Morris and Hirst, 1991; Grosz et al., 1995). We exclude the coreference information from this model, as the discourse ordering problem cannot accommodate current coreference solutions, which assume a pre-specified order (Ng, 2005). In the jargon of (Barzilay and Lapata, 2005), the model we implemented is called Syntax+Salience. The probability assigned to a text by this Entity-Based model (henceforth called EB) can be locally computed (i.e., at sentence transition level) using feature functions, as follows: Here, are feature values, and are weights trained to discriminate between coherent, human-authored documents and examples assumed to have lost some degree of coherence (scrambled versions of the original documents). 2.2 Global Models of Discourse Coherence Barzilay and Lee (2004) propose a document content model tha</context>
</contexts>
<marker>Ng, 2005</marker>
<rawString>Vincent Ng. 2005. Machine learning for coreference resolution: from local clasiffication to global reranking. In Procedings of the ACL, pages 157–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="16662" citStr="Och (2003)" startWordPosition="2706" endWordPosition="2707">mal solution to Equation 1 (Russell , with and 806 top most inexpensive states (according to total cost). This algorithm can be tuned (via ) to achieve good trade-off between speed and accuracy. We refer the reader to (Soricut, 2006) for additional details regarding the optimality and the theoretical run-time behavior of these algorithms. 3.3 Utility-based Training In addition to the modeling problem, we must also address the training problem, which amounts to finding appropriate values for the parameters from Equation 1. The solution we employ here is the discriminative training procedure of Och (2003). This procedure learns an optimal setting of the parameters using as optimality criterion the utility of the proposed solution. There are two necessary ingredients to implement Och’s (2003) training procedure. First, it needs a search algorithm that is able to produce ranked -best lists of the most promising candidates in a reasonably fast manner (Huang and Chiang, 2005). We accommodate -best computation within the IDL-CH-HB algorithm, which decodes bag-of-units IDL-expressions at an average speed of 75.4 sec./exp. on a 3.0 GHz CPU Linux machine, for an average input of 11.5 units per express</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the ACL, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="17962" citStr="Papineni et al., 2002" startWordPosition="2917" endWordPosition="2921">f the proposed candidates. To this end, we employ two different metrics, such that we can measure the impact of using different utility functions on performance. TAU (Kendall’s ). One of the most frequently used metrics for the automatic evaluation of document coherence is Kendall’s (Lapata, 2003; Barzilay and Lee, 2004). TAU measures the minimum number of adjacent transpositions needed to transform a proposed order into a reference order. The range of the TAU metric is between -1 (the worst) to 1 (the best). BLEU. One of the most successful metrics for judging machine-generated text is BLEU (Papineni et al., 2002). It counts the number of unigram, bigram, trigram, and four-gram matches between hypothesis and reference, and combines them using geometric mean. For the discourse ordering problem, we represent hypotheses and references by index sequences (e.g., “4 2 3 1” is a hypothesis order over four discourse units, in which the first and last units have been swapped with respect to the reference order). The range of BLEU scores is between 0 (the worst) and 1 (the best). We run different discriminative training sessions using TAU and BLEU, and train two different sets of the parameters for Equation 1. T</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the ACL, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Russell</author>
<author>Peter Norvig</author>
</authors>
<title>Artificial Intelligence. A Modern Approach.</title>
<date>1995</date>
<publisher>Prentice Hall.</publisher>
<contexts>
<context position="14766" citStr="Russell and Norvig, 1995" startWordPosition="2375" endWordPosition="2378">den variable considered. For instance, state (see the blackened vertices in Figure 2) records that expressions and have already been considered (while is still in the future of state ), and was the last one considered, evaluated under the hidden variable . The information recorded in each state allows for the computation of a current coherence cost under any of the models described in Section 2. In what follows, we assume this model to be the model from Equation 1, since each of the individual models can be obtained by setting the other s to 0. We also define an admissible heuristic function (Russell and Norvig, 1995), which is used to compute an admissible future cost for state , using the following equation: is the set of future (visible) events for state , which can be computed directly from an input IDL-graph, as the set of all –edge-labels between the vertices of state and final vertex . For example, for state , we have . is the set of future (visible) conditions for state , which can be obtained from (any non-final future event may become a future conditioning event), by eliminating and adding the current conditioning event of . For the considered example state , we have . The value is admissible bec</context>
</contexts>
<marker>Russell, Norvig, 1995</marker>
<rawString>Stuart Russell and Peter Norvig. 1995. Artificial Intelligence. A Modern Approach. Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donia R Scott</author>
<author>Clarisse S de Souza</author>
</authors>
<title>Getting the message across in RST-based text generation.</title>
<date>1990</date>
<booktitle>Current Research in Natural Language Generation,</booktitle>
<pages>47--73</pages>
<editor>In Robert Dale, Chris Mellish, and Michael Zock, eds.,</editor>
<publisher>Academic Press.</publisher>
<marker>Scott, de Souza, 1990</marker>
<rawString>Donia R. Scott and Clarisse S. de Souza. 1990. Getting the message across in RST-based text generation. In Robert Dale, Chris Mellish, and Michael Zock, eds., Current Research in Natural Language Generation, pages 47–73. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
<author>Daniel Marcu</author>
</authors>
<title>Towards developing generation algorithms for text-to-text applications.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>66--74</pages>
<contexts>
<context position="10927" citStr="Soricut and Marcu, 2005" startWordPosition="1734" endWordPosition="1737">strong earthquake hit the −Name− −Name− in g: northwestern −Name− early −Name− the official −Name− −Name− −Name− reported ## −−−−−−−−−SXXOSXOXSSS−&amp;quot; Figure 1: Example consisting of discourse units A, B, and C (a). In (b), their entities are detected (underlined) and assigned syntactic roles: S (subject), O (object), X (other), - (missing). In (c), terms , and encode these discourse units for model scoring purposes. 3 Search Algorithms for Coherent Discourses and Utility-Based Training The algorithms we propose use as input representation the IDL-expressions formalism (Nederhof and Satta, 2004; Soricut and Marcu, 2005). We use here the IDL formalism (which stands for Interleave, Disjunction, Lock, after the names of its operators) to define finite sets of possible discourses over given discourse units. Without losing generality, we will consider sentences as discourse units in our examples and experiments. 3.1 Input Representation Consider the discourse units A-C presented in Figure 1(a). Each of these units undergoes various processing stages in order to provide the information needed by our coherence models. The entity-based model (EB) (Section 2), for instance, makes use of a syntactic parser to determin</context>
<context position="13158" citStr="Soricut and Marcu (2005)" startWordPosition="2105" endWordPosition="2108">additional information that any of these orders are to appear between the beginning and end of document . An equivalent representation, called IDL-graphs, captures the same information using vertices and edges, which stand in a direct correspondence with the operators and atomic symbols of IDL-expressions. For instance, each and –labeled edge -pair, and their source and target vertices, respectively, correspond to a -argument operator. In Figure 2, we show the IDL-graph corresponding to IDL-expression . 3.2 Search Algorithms Algorithms that operate on IDL-graphs have been recently proposed by Soricut and Marcu (2005). We extend these algorithms to take as input IDLgraphs over non-atomic symbols (such that the coherence models can operate inside terms like , and from Figure 1), and also to work under models with hidden variables such as CM (Section 2.2). These algorithm, called IDL-CH-A (A search for IDL-expressions under Coherence models) and IDL-CH-HB (Histogram-Based beam search for IDL-expressions under Coherence models, with histogram beam ), assume an alphabet of nonatomic (visible) variables (over which the input IDL-expressions are defined), and an alphabet of hidden variables. They unfold an input</context>
</contexts>
<marker>Soricut, Marcu, 2005</marker>
<rawString>Radu Soricut and Daniel Marcu. 2005. Towards developing generation algorithms for text-to-text applications. In Proceedings of the ACL, pages 66–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
</authors>
<title>Natural Language Generation for Textto-Text Applications Using an Information-SlimRepresentation.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Southern California.</institution>
<contexts>
<context position="16285" citStr="Soricut, 2006" startWordPosition="2650" endWordPosition="2651">-A algorithm uses a priority queue (sorted according to total cost, computed as current admissible) to control the unfolding of an input IDL-graph, by processing, at each unfolding step, the most inexpensive state (extracted from the top of ). The admissibility of the future costs and the monotonicity property enforced by the priority queue guarantees that IDL-CH-A finds an optimal solution to Equation 1 (Russell , with and 806 top most inexpensive states (according to total cost). This algorithm can be tuned (via ) to achieve good trade-off between speed and accuracy. We refer the reader to (Soricut, 2006) for additional details regarding the optimality and the theoretical run-time behavior of these algorithms. 3.3 Utility-based Training In addition to the modeling problem, we must also address the training problem, which amounts to finding appropriate values for the parameters from Equation 1. The solution we employ here is the discriminative training procedure of Och (2003). This procedure learns an optimal setting of the parameters using as optimality criterion the utility of the proposed solution. There are two necessary ingredients to implement Och’s (2003) training procedure. First, it ne</context>
</contexts>
<marker>Soricut, 2006</marker>
<rawString>Radu Soricut. 2006. Natural Language Generation for Textto-Text Applications Using an Information-SlimRepresentation. Ph.D. thesis, University of Southern California.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>