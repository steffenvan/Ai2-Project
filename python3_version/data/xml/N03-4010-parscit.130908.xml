<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.440805">
<note confidence="0.968264333333333">
Proceedings of HLT-NAACL 2003
Demonstrations , pp. 19-20
Edmonton, May-June 2003
</note>
<title confidence="0.918645">
JAVELIN: A Flexible, Planner-Based Architecture for Question Answering
</title>
<author confidence="0.998611">
Eric Nyberg
</author>
<affiliation confidence="0.9875695">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<email confidence="0.997591">
ehn@cs.cmu.edu
</email>
<author confidence="0.99554">
Robert Frederking
</author>
<affiliation confidence="0.98734">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<email confidence="0.998527">
ref@cs.cmu.edu
</email>
<sectionHeader confidence="0.995644" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999930181818182">
The JAVELIN system integrates a flexible,
planning-based architecture with a variety of
language processing modules to provide an
open-domain question answering capability on
free text. The demonstration will focus on how
JAVELIN processes questions and retrieves the
most likely answer candidates from the given
text corpus. The operation of the system will be
explained in depth through browsing the repos-
itory of data objects created by the system dur-
ing each question answering session.
</bodyText>
<sectionHeader confidence="0.998037" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992182481481481">
Simple factoid questions can now be answered reason-
ably well using pattern matching. Some systems (Soub-
botin and Soubbotin, 2002) use surface patterns enhanced
with semantic categories and question types in order to
model the likelihood of answers given the question. Fur-
thermore, Hovy et al. (Hovy et al., 2002) have obtained
good results using only surface patterns pre-extracted
from the web. However, pattern-based approaches don’t
represent the meaning of the patterns they use, and it is
not clear whether they can be generalized for more diffi-
cult, non-factoid questions.
Open domain question answering is a complex, multi-
faceted task, where question type, information availabil-
ity, user needs, and a combination of text processing tech-
niques (statistical, NLP, etc.) must be combined dynami-
cally to determine the optimal answer. For more complex
questions, a more flexible and powerful control mech-
anism is required. For example, LCC (D. Moldovan
and Surdeanu, 2002) has implemented feedback loops
which ensure that processing constraints are met by re-
trieving more documents or expanding question terms.
The LCC system includes a passage retrieval loop, a
lexico-semantic loop and a logic proving loop. The
IBM PIQUANT system (Carroll et al., 2002) combines
knowledge-based agents using predictive annotation with
a statistical approach based on a maximum entropy model
(Ittycheriah et al., 2001).
</bodyText>
<figureCaption confidence="0.985567666666667">
Figure 1: The JAVELIN architecture. The Planner con-
trols execution of the individual components via the Ex-
ecution Manager.
</figureCaption>
<bodyText confidence="0.999645192307692">
Both the LCC and IBM systems represent a depar-
ture from the standard pipelined approach to QA archi-
tecture, and both work well for straightforward factoid
questions. Nevertheless, both approaches incorporate a
pre-determined set of processing steps or strategies, and
have limited ability to reason about new types of ques-
tions not previously encountered. Practically useful ques-
tion answering in non-factoid domains (e.g., intelligence
analysis) requires more sophisticated question decom-
position, reasoning, and answer synthesis. For these
hard questions, QA architectures must define relation-
ships among entities, gather information from multiple
sources, and reason over the data to produce an effec-
tive answer. As QA functionality becomes more sophis-
ticated, the set of decisions made by a system will not
be captured by pipelined architectures or multi-pass con-
straint relaxation, but must be modeled as a step-by-step
decision flow, where the set of processing steps is deter-
mined at run time for each question.
This demonstration illustrates the JAVELIN QA archi-
tecture (Nyberg et al., 2002), which includes a general,
modular infrastructure controlled by a step-by-step plan-
ning component. JAVELIN combines analysis modules,
information sources, user discourse and answer synthe-
sis as required for each question-answering interaction.
JAVELIN also incorporates a global memory, or repos-
</bodyText>
<figure confidence="0.998376891891892">
Web
Browser
JAVELIN
GUI
Planner
...
exe
results
exe
results
exe
results
Execution
Manager
Question
Analyzer
Retrieval
Strategist
Information
Extractor
Answer
Generator
question
ack
dialog
response
answer
JAVELIN operator
(action) models
Domain
Model
Data
Repository
process history
and data
Answer
Justification
</figure>
<bodyText confidence="0.999799">
itory, which maintains a linked set of object dependen-
cies for each question answering session. The repository
can be used to provide a processing summary or answer
justification for the user. The repository also provides a
straightforward way to compare the results of different
versions of individual processing modules running on the
same question. The modularity and flexibility of the ar-
chitecture provide a good platform for component-based
(glass box) evaluation (Nyberg and Mitamura, 2002).
</bodyText>
<sectionHeader confidence="0.899332" genericHeader="introduction">
2 Demonstration Outline
</sectionHeader>
<bodyText confidence="0.999957333333333">
The demonstration will be conducted on a laptop con-
nected to the Internet. The demonstration will feature
the JAVELIN graphical user interface (a Java application
running on the laptop) and the JAVELIN Repository (the
central database of JAVELIN result objects, accessed via
a web browser). A variety of questions will be asked of
the system, and the audience will be able to view the sys-
tem’s answers along with a detailed trace of the steps that
were taken to retrieve the answers.
</bodyText>
<figureCaption confidence="0.992129">
Figure 2: An Answer Justification.
</figureCaption>
<bodyText confidence="0.994885909090909">
Figure 2 shows the top-level result returned by
JAVELIN. The preliminary answer justification includes
the selected answer along with a variety of hyperlinks
that can be clicked to provide additional detail regarding
the system’s analysis of the question, the documents re-
trieved, the passages extracted, and the full set of answer
candidates. The justification also provides drill-down ac-
cess to the steps taken by the Planner module in reason-
ing about how to best answer the given question. Figure 3
shows additional detail that is exposed when the “Docu-
ments Returned” and “Request Fills” links are activated.
</bodyText>
<sectionHeader confidence="0.997035" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9986068">
The research described in this paper was supported in part
by a grant from ARDA under the AQUAINT Program
Phase I. The current version of the JAVELIN system was
conceived, designed and constructed with past and cur-
rent members of the JAVELIN team at CMU, including:
</bodyText>
<figureCaption confidence="0.983083">
Figure 3: Partial Answer Detail.
</figureCaption>
<reference confidence="0.9935435">
Jamie Callan, Jaime Carbonell, Teruko Mitamura, Kevyn
Collins-Thompson, Krzysztof Czuba, Michael Duggan,
Laurie Hiyakumoto, Ning Hu, Yifen Huang, Curtis Hut-
tenhower, Scott Judy, Jeongwoo Ko, Anna Kup´s´c, Lucian
Lita, Stephen Murtagh, Vasco Pedro, David Svoboda, and
Benjamin Van Durme.
</reference>
<sectionHeader confidence="0.912974" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99957665">
J. Carroll, J. Prager, C. Welty, K. Czuba, and D. Ferrucci.
2002. A multi-strategy and multi-source approach to
question answering.
S. Harabagiu D. Moldovan, M. Pasca and M. Surdeanu.
2002.
E. Hovy, U. Hermjakob, and D. Ravichandran. 2002. A
question/answer typology with surface text patterns.
A. Ittycheriah, M. Franz, W. Zhu, and A. Ratnaparkhi.
2001. Question answering using maximum-entropy
components.
E. Nyberg and T. Mitamura. 2002. Evaluating qa sys-
tems on multiple dimensions.
E. Nyberg, T. Mitamura, J. Carbonell, J. Callan,
K. Collins-Thompson, K. Czuba, M. Duggan,
L. Hiyakumoto, N. Hu, Y. Huang, J. Ko, L. Lita,
S. Murtagh, V. Pedro, and D. Svoboda. 2002. The
javelin question-answering system at trec 2002.
M. Soubbotin and S. Soubbotin. 2002. Use of patterns
for detection of likely answer strings: A systematic ap-
proach.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.475712">
<note confidence="0.965209666666667">Proceedings of HLT-NAACL 2003 Demonstrations , pp. 19-20 Edmonton, May-June 2003</note>
<title confidence="0.993463">JAVELIN: A Flexible, Planner-Based Architecture for Question Answering</title>
<author confidence="0.8048">Eric</author>
<affiliation confidence="0.7028375">Language Technologies Carnegie Mellon</affiliation>
<email confidence="0.999449">ehn@cs.cmu.edu</email>
<author confidence="0.93434">Robert</author>
<affiliation confidence="0.9118745">Language Technologies Carnegie Mellon</affiliation>
<email confidence="0.999341">ref@cs.cmu.edu</email>
<abstract confidence="0.998629833333333">The JAVELIN system integrates a flexible, planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text. The demonstration will focus on how JAVELIN processes questions and retrieves the most likely answer candidates from the given text corpus. The operation of the system will be explained in depth through browsing the repository of data objects created by the system during each question answering session.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Jamie Callan</author>
<author>Jaime Carbonell</author>
<author>Teruko Mitamura</author>
<author>Kevyn Collins-Thompson</author>
<author>Krzysztof Czuba</author>
<author>Michael Duggan</author>
</authors>
<title>Laurie Hiyakumoto, Ning Hu, Yifen Huang, Curtis Huttenhower,</title>
<location>Scott Judy, Jeongwoo Ko, Anna Kup´s´c, Lucian Lita, Stephen Murtagh, Vasco</location>
<marker>Callan, Carbonell, Mitamura, Collins-Thompson, Czuba, Duggan, </marker>
<rawString>Jamie Callan, Jaime Carbonell, Teruko Mitamura, Kevyn Collins-Thompson, Krzysztof Czuba, Michael Duggan, Laurie Hiyakumoto, Ning Hu, Yifen Huang, Curtis Huttenhower, Scott Judy, Jeongwoo Ko, Anna Kup´s´c, Lucian Lita, Stephen Murtagh, Vasco Pedro, David Svoboda, and Benjamin Van Durme.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>J Prager</author>
<author>C Welty</author>
<author>K Czuba</author>
<author>D Ferrucci</author>
</authors>
<title>A multi-strategy and multi-source approach to question answering.</title>
<date>2002</date>
<contexts>
<context position="2102" citStr="Carroll et al., 2002" startWordPosition="305" endWordPosition="308"> task, where question type, information availability, user needs, and a combination of text processing techniques (statistical, NLP, etc.) must be combined dynamically to determine the optimal answer. For more complex questions, a more flexible and powerful control mechanism is required. For example, LCC (D. Moldovan and Surdeanu, 2002) has implemented feedback loops which ensure that processing constraints are met by retrieving more documents or expanding question terms. The LCC system includes a passage retrieval loop, a lexico-semantic loop and a logic proving loop. The IBM PIQUANT system (Carroll et al., 2002) combines knowledge-based agents using predictive annotation with a statistical approach based on a maximum entropy model (Ittycheriah et al., 2001). Figure 1: The JAVELIN architecture. The Planner controls execution of the individual components via the Execution Manager. Both the LCC and IBM systems represent a departure from the standard pipelined approach to QA architecture, and both work well for straightforward factoid questions. Nevertheless, both approaches incorporate a pre-determined set of processing steps or strategies, and have limited ability to reason about new types of questions</context>
</contexts>
<marker>Carroll, Prager, Welty, Czuba, Ferrucci, 2002</marker>
<rawString>J. Carroll, J. Prager, C. Welty, K. Czuba, and D. Ferrucci. 2002. A multi-strategy and multi-source approach to question answering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Harabagiu D Moldovan</author>
<author>M Pasca</author>
<author>M Surdeanu</author>
</authors>
<date>2002</date>
<marker>Moldovan, Pasca, Surdeanu, 2002</marker>
<rawString>S. Harabagiu D. Moldovan, M. Pasca and M. Surdeanu. 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy</author>
<author>U Hermjakob</author>
<author>D Ravichandran</author>
</authors>
<title>A question/answer typology with surface text patterns.</title>
<date>2002</date>
<contexts>
<context position="1157" citStr="Hovy et al., 2002" startWordPosition="160" endWordPosition="163">ion will focus on how JAVELIN processes questions and retrieves the most likely answer candidates from the given text corpus. The operation of the system will be explained in depth through browsing the repository of data objects created by the system during each question answering session. 1 Introduction Simple factoid questions can now be answered reasonably well using pattern matching. Some systems (Soubbotin and Soubbotin, 2002) use surface patterns enhanced with semantic categories and question types in order to model the likelihood of answers given the question. Furthermore, Hovy et al. (Hovy et al., 2002) have obtained good results using only surface patterns pre-extracted from the web. However, pattern-based approaches don’t represent the meaning of the patterns they use, and it is not clear whether they can be generalized for more difficult, non-factoid questions. Open domain question answering is a complex, multifaceted task, where question type, information availability, user needs, and a combination of text processing techniques (statistical, NLP, etc.) must be combined dynamically to determine the optimal answer. For more complex questions, a more flexible and powerful control mechanism </context>
</contexts>
<marker>Hovy, Hermjakob, Ravichandran, 2002</marker>
<rawString>E. Hovy, U. Hermjakob, and D. Ravichandran. 2002. A question/answer typology with surface text patterns.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ittycheriah</author>
<author>M Franz</author>
<author>W Zhu</author>
<author>A Ratnaparkhi</author>
</authors>
<title>Question answering using maximum-entropy components.</title>
<date>2001</date>
<contexts>
<context position="2250" citStr="Ittycheriah et al., 2001" startWordPosition="325" endWordPosition="328">be combined dynamically to determine the optimal answer. For more complex questions, a more flexible and powerful control mechanism is required. For example, LCC (D. Moldovan and Surdeanu, 2002) has implemented feedback loops which ensure that processing constraints are met by retrieving more documents or expanding question terms. The LCC system includes a passage retrieval loop, a lexico-semantic loop and a logic proving loop. The IBM PIQUANT system (Carroll et al., 2002) combines knowledge-based agents using predictive annotation with a statistical approach based on a maximum entropy model (Ittycheriah et al., 2001). Figure 1: The JAVELIN architecture. The Planner controls execution of the individual components via the Execution Manager. Both the LCC and IBM systems represent a departure from the standard pipelined approach to QA architecture, and both work well for straightforward factoid questions. Nevertheless, both approaches incorporate a pre-determined set of processing steps or strategies, and have limited ability to reason about new types of questions not previously encountered. Practically useful question answering in non-factoid domains (e.g., intelligence analysis) requires more sophisticated </context>
</contexts>
<marker>Ittycheriah, Franz, Zhu, Ratnaparkhi, 2001</marker>
<rawString>A. Ittycheriah, M. Franz, W. Zhu, and A. Ratnaparkhi. 2001. Question answering using maximum-entropy components.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Nyberg</author>
<author>T Mitamura</author>
</authors>
<title>Evaluating qa systems on multiple dimensions.</title>
<date>2002</date>
<contexts>
<context position="4579" citStr="Nyberg and Mitamura, 2002" startWordPosition="665" endWordPosition="668">alog response answer JAVELIN operator (action) models Domain Model Data Repository process history and data Answer Justification itory, which maintains a linked set of object dependencies for each question answering session. The repository can be used to provide a processing summary or answer justification for the user. The repository also provides a straightforward way to compare the results of different versions of individual processing modules running on the same question. The modularity and flexibility of the architecture provide a good platform for component-based (glass box) evaluation (Nyberg and Mitamura, 2002). 2 Demonstration Outline The demonstration will be conducted on a laptop connected to the Internet. The demonstration will feature the JAVELIN graphical user interface (a Java application running on the laptop) and the JAVELIN Repository (the central database of JAVELIN result objects, accessed via a web browser). A variety of questions will be asked of the system, and the audience will be able to view the system’s answers along with a detailed trace of the steps that were taken to retrieve the answers. Figure 2: An Answer Justification. Figure 2 shows the top-level result returned by JAVELIN</context>
</contexts>
<marker>Nyberg, Mitamura, 2002</marker>
<rawString>E. Nyberg and T. Mitamura. 2002. Evaluating qa systems on multiple dimensions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Nyberg</author>
<author>T Mitamura</author>
<author>J Carbonell</author>
<author>J Callan</author>
<author>K Collins-Thompson</author>
<author>K Czuba</author>
<author>M Duggan</author>
<author>L Hiyakumoto</author>
<author>N Hu</author>
<author>Y Huang</author>
<author>J Ko</author>
<author>L Lita</author>
<author>S Murtagh</author>
<author>V Pedro</author>
<author>D Svoboda</author>
</authors>
<title>The javelin question-answering system at trec</title>
<date>2002</date>
<contexts>
<context position="3474" citStr="Nyberg et al., 2002" startWordPosition="510" endWordPosition="513">tion decomposition, reasoning, and answer synthesis. For these hard questions, QA architectures must define relationships among entities, gather information from multiple sources, and reason over the data to produce an effective answer. As QA functionality becomes more sophisticated, the set of decisions made by a system will not be captured by pipelined architectures or multi-pass constraint relaxation, but must be modeled as a step-by-step decision flow, where the set of processing steps is determined at run time for each question. This demonstration illustrates the JAVELIN QA architecture (Nyberg et al., 2002), which includes a general, modular infrastructure controlled by a step-by-step planning component. JAVELIN combines analysis modules, information sources, user discourse and answer synthesis as required for each question-answering interaction. JAVELIN also incorporates a global memory, or reposWeb Browser JAVELIN GUI Planner ... exe results exe results exe results Execution Manager Question Analyzer Retrieval Strategist Information Extractor Answer Generator question ack dialog response answer JAVELIN operator (action) models Domain Model Data Repository process history and data Answer Justif</context>
</contexts>
<marker>Nyberg, Mitamura, Carbonell, Callan, Collins-Thompson, Czuba, Duggan, Hiyakumoto, Hu, Huang, Ko, Lita, Murtagh, Pedro, Svoboda, 2002</marker>
<rawString>E. Nyberg, T. Mitamura, J. Carbonell, J. Callan, K. Collins-Thompson, K. Czuba, M. Duggan, L. Hiyakumoto, N. Hu, Y. Huang, J. Ko, L. Lita, S. Murtagh, V. Pedro, and D. Svoboda. 2002. The javelin question-answering system at trec 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Soubbotin</author>
<author>S Soubbotin</author>
</authors>
<title>Use of patterns for detection of likely answer strings: A systematic approach.</title>
<date>2002</date>
<contexts>
<context position="974" citStr="Soubbotin and Soubbotin, 2002" startWordPosition="129" endWordPosition="133">AVELIN system integrates a flexible, planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text. The demonstration will focus on how JAVELIN processes questions and retrieves the most likely answer candidates from the given text corpus. The operation of the system will be explained in depth through browsing the repository of data objects created by the system during each question answering session. 1 Introduction Simple factoid questions can now be answered reasonably well using pattern matching. Some systems (Soubbotin and Soubbotin, 2002) use surface patterns enhanced with semantic categories and question types in order to model the likelihood of answers given the question. Furthermore, Hovy et al. (Hovy et al., 2002) have obtained good results using only surface patterns pre-extracted from the web. However, pattern-based approaches don’t represent the meaning of the patterns they use, and it is not clear whether they can be generalized for more difficult, non-factoid questions. Open domain question answering is a complex, multifaceted task, where question type, information availability, user needs, and a combination of text p</context>
</contexts>
<marker>Soubbotin, Soubbotin, 2002</marker>
<rawString>M. Soubbotin and S. Soubbotin. 2002. Use of patterns for detection of likely answer strings: A systematic approach.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>