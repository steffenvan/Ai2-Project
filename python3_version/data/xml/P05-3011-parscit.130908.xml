<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004994">
<title confidence="0.848482">
SPEECH OGLE: Indexing Uncertainty for Spoken Document Search
</title>
<author confidence="0.931068">
Ciprian Chelba and Alex Acero
</author>
<affiliation confidence="0.9341975">
Microsoft Research
Microsoft Corporation
</affiliation>
<address confidence="0.911835">
One Microsoft Way
Redmond, WA 98052
</address>
<email confidence="0.994706">
{chelba, alexac}@microsoft.com
</email>
<sectionHeader confidence="0.982851" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999988272727273">
The paper presents the Position Specific
Posterior Lattice (PSPL), a novel lossy
representation of automatic speech recog-
nition lattices that naturally lends itself
to efficient indexing and subsequent rele-
vance ranking of spoken documents.
In experiments performed on a collec-
tion of lecture recordings — MIT iCam-
pus data — the spoken document rank-
ing accuracy was improved by 20% rela-
tive over the commonly used baseline of
indexing the 1-best output from an auto-
matic speech recognizer.
The inverted index built from PSPL lat-
tices is compact — about 20% of the size
of 3-gram ASR lattices and 3% of the size
of the uncompressed speech — and it al-
lows for extremely fast retrieval. Further-
more, little degradation in performance is
observed when pruning PSPL lattices, re-
sulting in even smaller indexes — 5% of
the size of 3-gram ASR lattices.
</bodyText>
<sectionHeader confidence="0.995171" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999949818181818">
Ever increasing computing power and connectivity
bandwidth together with falling storage costs result
in an overwhelming amount of data of various types
being produced, exchanged, and stored. Conse-
quently, search has emerged as a key application as
more and more data is being saved (Church, 2003).
Text search in particular is the most active area, with
applications that range from web and private net-
work search to searching for private information re-
siding on one’s hard-drive.
Speech search has not received much attention
due to the fact that large collections of untranscribed
spoken material have not been available, mostly
due to storage constraints. As storage is becoming
cheaper, the availability and usefulness of large col-
lections of spoken documents is limited strictly by
the lack of adequate technology to exploit them.
Manually transcribing speech is expensive and
sometimes outright impossible due to privacy con-
cerns. This leads us to exploring an automatic ap-
proach to searching and navigating spoken docu-
ment collections (Chelba and Acero, 2005).
</bodyText>
<sectionHeader confidence="0.941603" genericHeader="method">
2 Text Document Retrieval in the Early
</sectionHeader>
<subsectionHeader confidence="0.737814">
Google Approach
</subsectionHeader>
<bodyText confidence="0.99988725">
Aside from the use of PageRank for relevance rank-
ing, the early Google also uses both proximity and
context information heavily when assigning a rel-
evance score to a given document (Brin and Page,
1998), Section 4.5.1.
For each given query term qi one retrieves the list
of hits corresponding to qi in document D. Hits
can be of various types depending on the context in
which the hit occurred: title, anchor text, etc. Each
type of hit has its own type-weight and the type-
weights are indexed by type.
For a single word query, their ranking algorithm
takes the inner-product between the type-weight
vector and a vector consisting of count-weights (ta-
pered counts such that the effect of large counts is
discounted) and combines the resulting score with
</bodyText>
<page confidence="0.783684">
41
</page>
<note confidence="0.622769">
Proceedings of the ACL Interactive Poster and Demonstration Sessions,
pages 41–44, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.987140777777778">
PageRank in a final relevance score.
For multiple word queries, terms co-occurring in a
given document are considered as forming different
proximity-types based on their proximity, from adja-
cent to “not even close”. Each proximity type comes
with a proximity-weight and the relevance score in-
cludes the contribution of proximity information by
taking the inner product over all types, including the
proximity ones.
</bodyText>
<sectionHeader confidence="0.841282" genericHeader="method">
3 Position Specific Posterior Lattices
</sectionHeader>
<bodyText confidence="0.998366">
the start node of the lattice and end at node n:
</bodyText>
<equation confidence="0.979287166666667">
�αn[l] = P(7r)
7r:end(7r)=n,length(7r)=l
The posterior probability that a given node n occurs
at position l is thus calculated using:
P(n,l|LAT) = norm(LAT)
αn[l] · �n
</equation>
<bodyText confidence="0.996148333333333">
The posterior probability of a given word w occur-
ring at a given position l can be easily calculated
using:
</bodyText>
<equation confidence="0.821887">
P(w, l|LAT) =
</equation>
<bodyText confidence="0.994625153846154">
As highlighted in the previous section, position in-
formation is crucial for being able to evaluate prox-
imity information when assigning a relevance score
to a given document.
In the spoken document case however, we are
faced with a dilemma. On one hand, using 1-best
ASR output as the transcription to be indexed is sub-
optimal due to the high WER, which is likely to lead
to low recall — query terms that were in fact spo-
ken are wrongly recognized and thus not retrieved.
On the other hand, ASR lattices do have a much bet-
ter WER — in our case the 1-best WER was 55%
whereas the lattice WER was 30% — but the posi-
tion information is not readily available.
The occurrence of a given word in a lattice ob-
tained from a given spoken document is uncertain
and so is the position at which the word occurs in the
document. However, the ASR lattices do contain the
information needed to evaluate proximity informa-
tion, since on a given path through the lattice we can
easily assign a position index to each link/word in
the normal way. Each path occurs with a given pos-
terior probability, easily computable from the lattice,
so in principle one could index soft-hits which spec-
ify (document id, position, posterior probability) for
each word in the lattice.
A simple dynamic programming algorithm which
is a variation on the standard forward-backward al-
gorithm can be employed for performing this com-
putation. The computation for the backward proba-
bility On stays unchanged (Rabiner, 1989) whereas
during the forward pass one needs to split the for-
ward probability arriving at a given node n, αn, ac-
cording to the length of the partial paths that start at
En s.t. P(n,l)&gt;0 P(n, l|LAT) · S(w, word(n))
The Position Specific Posterior Lattice (PSPL) is
nothing but a representation of the P(w,l|LAT)
distribution. For details on the algorithm and prop-
erties of PSPL please see (Chelba and Acero, 2005).
</bodyText>
<sectionHeader confidence="0.9354705" genericHeader="method">
4 Spoken Document Indexing and Search
Using PSPL
</sectionHeader>
<bodyText confidence="0.9999903">
Speech content can be very long. In our case the
speech content of a typical spoken document was
approximately 1 hr long. It is customary to segment
a given speech file in shorter segments. A spoken
document thus consists of an ordered list of seg-
ments. For each segment we generate a correspond-
ing PSPL lattice. Each document and each segment
in a given collection are mapped to an integer value
using a collection descriptor file which lists all doc-
uments and segments.
The soft hits for a given word are
stored as a vector of entries sorted by
(document id, segment id). Document
and segment boundaries in this array, respectively,
are stored separately in a map for convenience of
use and memory efficiency. The soft index simply
lists all hits for every word in the ASR vocabulary;
each word entry can be stored in a separate file if we
wish to augment the index easily as new documents
are added to the collection.
</bodyText>
<subsectionHeader confidence="0.808311">
4.1 Speech Content Relevance Ranking Using
PSPL Representation
</subsectionHeader>
<bodyText confidence="0.999092333333333">
Consider a given query Q = q1 ... qz ... qQ and
a spoken document D represented as a PSPL. Our
ranking scheme follows the description in Section 2.
</bodyText>
<page confidence="0.763935">
42
</page>
<bodyText confidence="0.96545125">
For all query terms, a 1-gram score is calculated
by summing the PSPL posterior probability across
all segments s and positions k. This is equivalent
to calculating the expected count of a given query
term qi according to the PSPL probability distribu-
tion P(wk(s)|D) for each segment s of document
D. The results are aggregated in a common value
S1−gram(D, Q):
</bodyText>
<equation confidence="0.99389975">
S(D, qi) = log L1 + E E P(wk(s) = qi|D)J
s k
S1−gram(D, Q) = � Q S(D, qi) (1)
i=1
</equation>
<bodyText confidence="0.9895326">
Similar to (Brin and Page, 1998), the logarithmic ta-
pering off is used for discounting the effect of large
counts in a given document.
Our current ranking scheme takes into account
proximity in the form of matching N-grams present
in the query. Similar to the 1-gram case, we cal-
culate an expected tapered-count for each N-gram
qi ... qi+N−1 in the query and then aggregate the re-
sults in a common value SN−gram(D, Q) for each
order N:
</bodyText>
<equation confidence="0.969045">
S(D, qi ... qi+N−1) =
log [1 + Es Ek �1 01 P(wk+l (s) = qi+l  |D)Jll
SN−gram(D, Q) = Q−N+1 S(D, qi ... qi+N−1) (2)
�
i=1
</equation>
<bodyText confidence="0.997662">
The different proximity types, one for each N-
gram order allowed by the query length, are com-
bined by taking the inner product with a vector of
weights.
</bodyText>
<equation confidence="0.997055333333333">
Q
S(D, Q) = L wN · SN−gram(D, Q)
N=1
</equation>
<bodyText confidence="0.999842833333333">
It is worth noting that the transcription for any given
segment can also be represented as a PSPL with ex-
actly one word per position bin. It is easy to see that
in this case the relevance scores calculated accord-
ing to Eq. (1-2) are the ones specified by 2.
Only documents containing all the terms in the
query are returned. We have also enriched the query
language with the “quoted functionality” that al-
lows us to retrieve only documents that contain exact
PSPL matches for the quoted phrases, e.g. the query
‘‘L M’’ tools will return only documents con-
taining occurrences of L M and of tools.
</bodyText>
<sectionHeader confidence="0.99873" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9999918">
We have carried all our experiments on the iCam-
pus corpus (Glass et al., 2004) prepared by MIT
CSAIL. The main advantages of the corpus are: re-
alistic speech recording conditions — all lectures are
recorded using a lapel microphone — and the avail-
ability of accurate manual transcriptions — which
enables the evaluation of a SDR system against its
text counterpart.
The corpus consists of about 169 hours of lec-
ture materials. Each lecture comes with a word-level
manual transcription that segments the text into se-
mantic units that could be thought of as sentences;
word-level time-alignments between the transcrip-
tion and the speech are also provided. The speech
was segmented at the sentence level based on the
time alignments; each lecture is considered to be a
spoken document consisting of a set of one-sentence
long segments determined this way. The final col-
lection consists of 169 documents, 66,102 segments
and an average document length of 391 segments.
</bodyText>
<subsectionHeader confidence="0.992631">
5.1 Spoken Document Retrieval
</subsectionHeader>
<bodyText confidence="0.999811476190476">
Our aim is to narrow the gap between speech and
text document retrieval. We have thus taken as our
reference the output of a standard retrieval engine
working according to one of the TF-IDF flavors. The
engine indexes the manual transcription using an un-
limited vocabulary. All retrieval results presented
in this section have used the standard trec eval
_
package used by the TREC evaluations.
The PSPL lattices for each segment in the spoken
document collection were indexed. In terms of rel-
ative size on disk, the uncompressed speech for the
first 20 lectures uses 2.5GB, the ASR 3-gram lat-
tices use 322MB, and the corresponding index de-
rived from the PSPL lattices uses 61MB.
In addition, we generated the PSPL representa-
tion of the manual transcript and of the 1-best ASR
output and indexed those as well. This allows us to
compare our retrieval results against the results ob-
tained using the reference engine when working on
the same text document collection.
</bodyText>
<page confidence="0.962106">
43
</page>
<subsubsectionHeader confidence="0.533407">
5.1.1 Query Collection and Retrieval Setup
</subsubsectionHeader>
<bodyText confidence="0.9999769">
We have asked a few colleagues to issue queries
against a demo shell using the index built from the
manual transcription.We have collected 116 queries
in this manner. The query out-of-vocabulary rate (Q-
OOV) was 5.2% and the average query length was
1.97 words. Since our approach so far does not in-
dex sub-word units, we cannot deal with OOV query
words. We have thus removed the queries which
contained OOV words — resulting in a set of 96
queries.
</bodyText>
<subsubsectionHeader confidence="0.894116">
5.1.2 Retrieval Experiments
</subsubsectionHeader>
<bodyText confidence="0.9996882">
We have carried out retrieval experiments in the
above setup. Indexes have been built from: trans,
manual transcription filtered through ASR vocabu-
lary; 1-best, ASR 1-best output; lat, PSPL lat-
tices. Table 1 presents the results. As a sanity check,
</bodyText>
<table confidence="0.998949333333333">
trans 1-best lat
# docs retrieved 1411 3206 4971
# relevant docs 1416 1416 1416
# rel retrieved 1411 1088 1301
MAP 0.99 0.53 0.62
R-precision 0.99 0.53 0.58
</table>
<tableCaption confidence="0.9081605">
Table 1: Retrieval performance on indexes built
from transcript, ASR 1-best and PSPL lattices
</tableCaption>
<bodyText confidence="0.9998842">
the retrieval results on transcription — trans —
match almost perfectly the reference. The small dif-
ference comes from stemming rules that the baseline
engine is using for query enhancement which are not
replicated in our retrieval engine.
The results on lattices (lat) improve signifi-
cantly on (1-best) — 20% relative improvement
in mean average precision (MAP). Table 2 shows the
retrieval accuracy results as well as the index size for
various pruning thresholds applied to the lat PSPL.
MAP performance increases with PSPL depth, as
expected. A good compromise between accuracy
and index size is obtained for a pruning threshold
of 2.0: at very little loss in MAP one could use an
index that is only 20% of the full index.
</bodyText>
<sectionHeader confidence="0.996138" genericHeader="conclusions">
6 Conclusions and Future work
</sectionHeader>
<bodyText confidence="0.997325">
We have developed a new representation for ASR
lattices — the Position Specific Posterior Lattice —
</bodyText>
<table confidence="0.999791090909091">
pruning MAP R-precision Index Size
threshold (MB)
0.0 0.53 0.54 16
0.1 0.54 0.55 21
0.2 0.55 0.56 26
0.5 0.56 0.57 40
1.0 0.58 0.58 62
2.0 0.61 0.59 110
5.0 0.62 0.57 300
10.0 0.62 0.57 460
1000000 0.62 0.57 540
</table>
<tableCaption confidence="0.833564">
Table 2: Retrieval performance on indexes built
from pruned PSPL lattices, along with index size
</tableCaption>
<bodyText confidence="0.999494571428571">
that lends itself to indexing speech content. The
retrieval results obtained by indexing the PSPL are
20% better than when using the ASR 1-best output.
The techniques presented can be applied to in-
dexing contents of documents when uncertainty is
present: optical character recognition, handwriting
recognition are examples of such situations.
</bodyText>
<sectionHeader confidence="0.998599" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.99997925">
We would like to thank Jim Glass and T J Hazen
at MIT for providing the iCampus data. We would
also like to thank Frank Seide for offering valuable
suggestions on our work.
</bodyText>
<sectionHeader confidence="0.996431" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998958777777778">
Sergey Brin and Lawrence Page. 1998. The anatomy of
a large-scale hypertextual Web search engine. Com-
puter Networks andISDNSystems, 30(1–7):107–117.
Ciprian Chelba and Alex Acero. 2005. Position specific
posterior lattices for indexing speech. In Proceedings
ofACL, Ann Arbor, Michigan, June.
Kenneth Ward Church. 2003. Speech and language pro-
cessing: Where have we been and where are we going?
In Proceedings of Eurospeech, Geneva, Switzerland.
James Glass, Timothy J. Hazen, Lee Hetherington, and
Chao Wang. 2004. Analysis and processing of lec-
ture audio data: Preliminary investigations. In HLT-
NAACL 2004 Workshop: Interdisciplinary Approaches
to Speech Indexing and Retrieval, pages 9–12, Boston,
Massachusetts, USA, May 6.
L. R. Rabiner. 1989. A tutorial on hidden markov mod-
els and selected applications in speech recognition. In
Proceedings IEEE, volume 77(2), pages 257–285.
</reference>
<page confidence="0.961389">
44
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.943217">
<title confidence="0.992993">SPEECH OGLE: Indexing Uncertainty for Spoken Document Search</title>
<author confidence="0.992215">Chelba Acero</author>
<affiliation confidence="0.9997465">Microsoft Research Microsoft Corporation</affiliation>
<address confidence="0.9969105">One Microsoft Way Redmond, WA 98052</address>
<abstract confidence="0.997753173913044">The paper presents the Position Specific Posterior Lattice (PSPL), a novel lossy representation of automatic speech recognition lattices that naturally lends itself to efficient indexing and subsequent relevance ranking of spoken documents. In experiments performed on a collection of lecture recordings — MIT iCampus data — the spoken document ranking accuracy was improved by 20% relative over the commonly used baseline of indexing the 1-best output from an automatic speech recognizer. The inverted index built from PSPL lattices is compact — about 20% of the size of 3-gram ASR lattices and 3% of the size of the uncompressed speech — and it allows for extremely fast retrieval. Furthermore, little degradation in performance is observed when pruning PSPL lattices, resulting in even smaller indexes — 5% of the size of 3-gram ASR lattices.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The anatomy of a large-scale hypertextual Web search engine.</title>
<date>1998</date>
<journal>Computer Networks andISDNSystems,</journal>
<pages>30--1</pages>
<contexts>
<context position="2395" citStr="Brin and Page, 1998" startWordPosition="377" endWordPosition="380">ty and usefulness of large collections of spoken documents is limited strictly by the lack of adequate technology to exploit them. Manually transcribing speech is expensive and sometimes outright impossible due to privacy concerns. This leads us to exploring an automatic approach to searching and navigating spoken document collections (Chelba and Acero, 2005). 2 Text Document Retrieval in the Early Google Approach Aside from the use of PageRank for relevance ranking, the early Google also uses both proximity and context information heavily when assigning a relevance score to a given document (Brin and Page, 1998), Section 4.5.1. For each given query term qi one retrieves the list of hits corresponding to qi in document D. Hits can be of various types depending on the context in which the hit occurred: title, anchor text, etc. Each type of hit has its own type-weight and the typeweights are indexed by type. For a single word query, their ranking algorithm takes the inner-product between the type-weight vector and a vector consisting of count-weights (tapered counts such that the effect of large counts is discounted) and combines the resulting score with 41 Proceedings of the ACL Interactive Poster and </context>
<context position="7448" citStr="Brin and Page, 1998" startWordPosition="1250" endWordPosition="1253">er a given query Q = q1 ... qz ... qQ and a spoken document D represented as a PSPL. Our ranking scheme follows the description in Section 2. 42 For all query terms, a 1-gram score is calculated by summing the PSPL posterior probability across all segments s and positions k. This is equivalent to calculating the expected count of a given query term qi according to the PSPL probability distribution P(wk(s)|D) for each segment s of document D. The results are aggregated in a common value S1−gram(D, Q): S(D, qi) = log L1 + E E P(wk(s) = qi|D)J s k S1−gram(D, Q) = � Q S(D, qi) (1) i=1 Similar to (Brin and Page, 1998), the logarithmic tapering off is used for discounting the effect of large counts in a given document. Our current ranking scheme takes into account proximity in the form of matching N-grams present in the query. Similar to the 1-gram case, we calculate an expected tapered-count for each N-gram qi ... qi+N−1 in the query and then aggregate the results in a common value SN−gram(D, Q) for each order N: S(D, qi ... qi+N−1) = log [1 + Es Ek �1 01 P(wk+l (s) = qi+l |D)Jll SN−gram(D, Q) = Q−N+1 S(D, qi ... qi+N−1) (2) � i=1 The different proximity types, one for each Ngram order allowed by the query</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Lawrence Page. 1998. The anatomy of a large-scale hypertextual Web search engine. Computer Networks andISDNSystems, 30(1–7):107–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ciprian Chelba</author>
<author>Alex Acero</author>
</authors>
<title>Position specific posterior lattices for indexing speech.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL,</booktitle>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="2136" citStr="Chelba and Acero, 2005" startWordPosition="333" endWordPosition="336">rmation residing on one’s hard-drive. Speech search has not received much attention due to the fact that large collections of untranscribed spoken material have not been available, mostly due to storage constraints. As storage is becoming cheaper, the availability and usefulness of large collections of spoken documents is limited strictly by the lack of adequate technology to exploit them. Manually transcribing speech is expensive and sometimes outright impossible due to privacy concerns. This leads us to exploring an automatic approach to searching and navigating spoken document collections (Chelba and Acero, 2005). 2 Text Document Retrieval in the Early Google Approach Aside from the use of PageRank for relevance ranking, the early Google also uses both proximity and context information heavily when assigning a relevance score to a given document (Brin and Page, 1998), Section 4.5.1. For each given query term qi one retrieves the list of hits corresponding to qi in document D. Hits can be of various types depending on the context in which the hit occurred: title, anchor text, etc. Each type of hit has its own type-weight and the typeweights are indexed by type. For a single word query, their ranking al</context>
<context position="5787" citStr="Chelba and Acero, 2005" startWordPosition="951" endWordPosition="954">rogramming algorithm which is a variation on the standard forward-backward algorithm can be employed for performing this computation. The computation for the backward probability On stays unchanged (Rabiner, 1989) whereas during the forward pass one needs to split the forward probability arriving at a given node n, αn, according to the length of the partial paths that start at En s.t. P(n,l)&gt;0 P(n, l|LAT) · S(w, word(n)) The Position Specific Posterior Lattice (PSPL) is nothing but a representation of the P(w,l|LAT) distribution. For details on the algorithm and properties of PSPL please see (Chelba and Acero, 2005). 4 Spoken Document Indexing and Search Using PSPL Speech content can be very long. In our case the speech content of a typical spoken document was approximately 1 hr long. It is customary to segment a given speech file in shorter segments. A spoken document thus consists of an ordered list of segments. For each segment we generate a corresponding PSPL lattice. Each document and each segment in a given collection are mapped to an integer value using a collection descriptor file which lists all documents and segments. The soft hits for a given word are stored as a vector of entries sorted by (d</context>
</contexts>
<marker>Chelba, Acero, 2005</marker>
<rawString>Ciprian Chelba and Alex Acero. 2005. Position specific posterior lattices for indexing speech. In Proceedings ofACL, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
</authors>
<title>Speech and language processing: Where have we been and where are we going?</title>
<date>2003</date>
<booktitle>In Proceedings of Eurospeech,</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="1366" citStr="Church, 2003" startWordPosition="215" endWordPosition="216">— about 20% of the size of 3-gram ASR lattices and 3% of the size of the uncompressed speech — and it allows for extremely fast retrieval. Furthermore, little degradation in performance is observed when pruning PSPL lattices, resulting in even smaller indexes — 5% of the size of 3-gram ASR lattices. 1 Introduction Ever increasing computing power and connectivity bandwidth together with falling storage costs result in an overwhelming amount of data of various types being produced, exchanged, and stored. Consequently, search has emerged as a key application as more and more data is being saved (Church, 2003). Text search in particular is the most active area, with applications that range from web and private network search to searching for private information residing on one’s hard-drive. Speech search has not received much attention due to the fact that large collections of untranscribed spoken material have not been available, mostly due to storage constraints. As storage is becoming cheaper, the availability and usefulness of large collections of spoken documents is limited strictly by the lack of adequate technology to exploit them. Manually transcribing speech is expensive and sometimes outr</context>
</contexts>
<marker>Church, 2003</marker>
<rawString>Kenneth Ward Church. 2003. Speech and language processing: Where have we been and where are we going? In Proceedings of Eurospeech, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Glass</author>
<author>Timothy J Hazen</author>
<author>Lee Hetherington</author>
<author>Chao Wang</author>
</authors>
<title>Analysis and processing of lecture audio data: Preliminary investigations.</title>
<date>2004</date>
<booktitle>In HLTNAACL</booktitle>
<pages>9--12</pages>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="8849" citStr="Glass et al., 2004" startWordPosition="1513" endWordPosition="1516">lso be represented as a PSPL with exactly one word per position bin. It is easy to see that in this case the relevance scores calculated according to Eq. (1-2) are the ones specified by 2. Only documents containing all the terms in the query are returned. We have also enriched the query language with the “quoted functionality” that allows us to retrieve only documents that contain exact PSPL matches for the quoted phrases, e.g. the query ‘‘L M’’ tools will return only documents containing occurrences of L M and of tools. 5 Experiments We have carried all our experiments on the iCampus corpus (Glass et al., 2004) prepared by MIT CSAIL. The main advantages of the corpus are: realistic speech recording conditions — all lectures are recorded using a lapel microphone — and the availability of accurate manual transcriptions — which enables the evaluation of a SDR system against its text counterpart. The corpus consists of about 169 hours of lecture materials. Each lecture comes with a word-level manual transcription that segments the text into semantic units that could be thought of as sentences; word-level time-alignments between the transcription and the speech are also provided. The speech was segmented</context>
</contexts>
<marker>Glass, Hazen, Hetherington, Wang, 2004</marker>
<rawString>James Glass, Timothy J. Hazen, Lee Hetherington, and Chao Wang. 2004. Analysis and processing of lecture audio data: Preliminary investigations. In HLTNAACL 2004 Workshop: Interdisciplinary Approaches to Speech Indexing and Retrieval, pages 9–12, Boston, Massachusetts, USA, May 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Rabiner</author>
</authors>
<title>A tutorial on hidden markov models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>In Proceedings IEEE,</booktitle>
<volume>77</volume>
<issue>2</issue>
<pages>257--285</pages>
<contexts>
<context position="5377" citStr="Rabiner, 1989" startWordPosition="882" endWordPosition="883">n needed to evaluate proximity information, since on a given path through the lattice we can easily assign a position index to each link/word in the normal way. Each path occurs with a given posterior probability, easily computable from the lattice, so in principle one could index soft-hits which specify (document id, position, posterior probability) for each word in the lattice. A simple dynamic programming algorithm which is a variation on the standard forward-backward algorithm can be employed for performing this computation. The computation for the backward probability On stays unchanged (Rabiner, 1989) whereas during the forward pass one needs to split the forward probability arriving at a given node n, αn, according to the length of the partial paths that start at En s.t. P(n,l)&gt;0 P(n, l|LAT) · S(w, word(n)) The Position Specific Posterior Lattice (PSPL) is nothing but a representation of the P(w,l|LAT) distribution. For details on the algorithm and properties of PSPL please see (Chelba and Acero, 2005). 4 Spoken Document Indexing and Search Using PSPL Speech content can be very long. In our case the speech content of a typical spoken document was approximately 1 hr long. It is customary t</context>
</contexts>
<marker>Rabiner, 1989</marker>
<rawString>L. R. Rabiner. 1989. A tutorial on hidden markov models and selected applications in speech recognition. In Proceedings IEEE, volume 77(2), pages 257–285.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>