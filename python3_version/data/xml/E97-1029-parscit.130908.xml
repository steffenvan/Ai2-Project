<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.986839">
Morphological Disambiguation by Voting Constraints
</title>
<author confidence="0.931544">
Kemal Oflazer and GOkhan Tiir
</author>
<affiliation confidence="0.971779">
Department of Computer Engineering and Information Science
Bilkent University, Bilkent, TR-06533, Turkey
</affiliation>
<email confidence="0.625794">
fko,turlOcs.bilkent.edu.tr
</email>
<sectionHeader confidence="0.99377" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999874714285714">
We present a constraint-based morpholog-
ical disambiguation system in which indi-
vidual constraints vote on matching mor-
phological parses, and disambiguation of
all the tokens in a sentence is performed
at the end by selecting parses that receive
the highest votes. This constraint applica-
tion paradigm makes the outcome of the
disambiguation independent of the rule se-
quence, and hence relieves the rule devel-
oper from worrying about potentially con-
flicting rule sequencing. Our results for
disambiguating Turkish indicate that using
about 500 constraint rules and some addi-
tional simple statistics, we can attain a re-
call of 95-96% and a precision of 94-95%
with about 1.01 parses per token. Our sys-
tem is implemented in Prolog and we are
currently investigating an efficient imple-
mentation based on finite state transduc-
ers.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994945945946">
Automatic morphological disambiguation is an im-
portant component in higher level analysis of natural
language text corpora. There has been a large num-
ber of studies in tagging and morphological disam-
biguation using various techniques such as statisti-
cal techniques, e.g., (Church, 1988; Cutting et al.,
1992; DeRose, 1988), constraint-based techniques
(Karlsson et al., 1995; Voutilainen, 1995b; Vouti-
lainen, Heikkila, and Anttila, 1992; Voutilainen
and Tapanainen, 1993; Oflazer and Kurth:5z, 1994;
Oflazer and Tiir, 1996) and transformation-based
techniques (Brill, 1992; Brill, 1994; Brill, 1995).
This paper presents a novel approach to constraint
based morphological disambiguation which relieves
the rule developer from worrying about conflicting
rule ordering requirements. The approach depends
on assigning votes to constraints according to their
complexity and specificity, and then letting con-
straints cast votes on matching parses of a given
lexical item. This approach does not reflect the out-
come of matching constraints to the set of morpho-
logical parses immediately. Only after all applicable
rules are applied to a sentence, all tokens are dis-
ambiguated in parallel. Thus, the outcome of the
rule applications is independent of the order of rule
applications. Rule ordering issue has been discussed
by Voutilainen(1994), but he has recently indicated&apos;
that insensitivity to rule ordering is not a property
of their system (although Voutilainen(1995a) states
that it is a very desirable property) but rather is
achieved by extensively testing and tuning the rules.
In the following sections, we present an overview
of the morphological disambiguation problem, high-
lighted with examples from Turkish. We then
present our approach and results. We finally con-
clude with a very brief outline of our investigation
into efficient implementations of our approach.
</bodyText>
<sectionHeader confidence="0.995208" genericHeader="introduction">
2 Morphological Disambiguation
</sectionHeader>
<bodyText confidence="0.968246130434783">
In all languages, words are usually ambiguous in
their parts-of-speech or other morphological fea-
tures, and may represent lexical items of different
syntactic categories, or morphological structures de-
pending on the syntactic and semantic context. In
languages like English, there are a very small number
of possible word forms that can be generated from
a given root word, and a small number of part-of-
speech tags associated with a given lexical form. On
the other hand, in languages like Turkish or Finnish
with very productive agglutinative morphology, it
is possible to produce thousands of forms (or even
millions (Hankamer, 1989)) from a given root word
and the kinds of ambiguities one observes are quite
different than what is observed in languages like En-
glish.
In Turkish, there are ambiguities of the sort
typically found in languages like English (e.g.,
book/noun vs book/verb type). However, the ag-
glutinative nature of the language usually helps res-
olution of such ambiguities due to the restrictions
on morphotactics of subsequent morphemes. On the
&apos;Voutilainen, Private communication.
</bodyText>
<page confidence="0.995966">
222
</page>
<bodyText confidence="0.996310090909091">
other hand, this very nature introduces another kind
of ambiguity, where a lexical form can be morpho-
logically interpreted in many ways not usually pre-
dictable in advance. Furthermore, Turkish allows
very productive derivational processes and the infor-
mation about the derivational structure of a word
form is usually crucial for disambiguation (Oflazer
and Tiir, 1996).
Most kinds of morphological ambiguities that we
have observed in Turkish typically fall into one the
following classes:2
</bodyText>
<listItem confidence="0.971550457142857">
1. the form is uninflected and assumes the default
inflectional features, e.g.,
1. taS (made of stone)
[CAT=ADJ] [ROOT=taS]]
2. taS (stone)
[ [CAT=NOUN] [ROOT=taS]
[AGR=3SG] [POSS=NONE] [CASE=NOM] ]
3. taS (overflow!)
[[CAT=VERB] [ROOT=t aS] [SENSE=POS]
[TAM1=IMP] [AGR=2SG]]
2. Lexically different affixes (conveying different
morphological features) surface the same due to
the morphographemic context, e.g.,
1. ev+ [n] in (of the house)
[ [CAT=NOUN] [ROOT=ev]
[AGR=3SG] [POSS=NONE] [CASE=GEN] ]
2. ev+in (your house)
[ [CAT=NOUN] [ROOT=ev]
[AGR=3SG] [P0SS=2SG] [CASE=NOM]]
3. The root of one of the parses is a prefix string of
the root of the other parse, and the parse with
the shorter root word has a suffix which surfaces
as the rest of the longer root word, e.g.,
1. koyu+ [u]n (your dark (thing) )
[CAT=ADJ] [ROOT=koyu] [CONV=NOUN=NONE]
[AGR=3SG] [POSS=2SG] [CASE=NOM]]
2. koyun (sheep)
[ [CAT=NOUN] [ROOT=koyun]
[AGR=3SG] [POSS=NONE] [CASE=NOM] ]
3. koy+ [n] un (of the bay)
[ [CAT=NOUN] [ROO T=koy]
[AGR=3SG] [POSS=NONE] [CASE=GEN] ]
4. koy+un (your bay)
[ [CAT=NOUN] [ROOT=koy]
[AGR=3SG] [POSS=2SG] ECASE=NOME
</listItem>
<bodyText confidence="0.622146">
2Output of the morphological analyzer is edited for
clarity, and English glosses have been given. We have
also provided the morpheme structure, where [...]s, in-
dicate elision. Glosses are given as linear feature value
sequences corresponding to the morphemes (which are
not shown). The feature names are as follows: CAT-major
category, TYPE-minor category, ROOT-main root form, AGR
-number and person agreement, PUSS - possessive agree-
ment, CASE - surface case, CONV - conversion to the cat-
egory following with a certain suffix indicated by the
argument after that, TAM1-tense, aspect, mood marker
1, SENSE-verbal polarity. Upper cases in morphological
output indicates one of the non-ASCII special Turkish
characters: e.g., G denotes g, U denotes 5, etc.
</bodyText>
<equation confidence="0.494319">
5. koy+ [y]un (put!)
C[CAT=VER13] [ROOT=koy] [SENSE=POS]
[TAM1=IMP] [AGR=2PL] ]
</equation>
<listItem confidence="0.883266296296296">
4. The roots take different numbers of unrelated
inflectional and/or derivational suffixes which
when concatenated turn out to have the same
surface form, e.g.,
1. yap+madan (without having done (it ) )
HCAT=VERB] [ROOT=yap] [SENSE=POS]
[CONV=ADVERB=MADAN] ]
2. yap+ma+dan (from doing ( it ) )
[ [CAT=VERB] [ROOT=yap] [SENSE=POS]
[CONV=NOUN=MA] [TYPE=INFINITIVE]
[AGR=3SG] [POSS=NONE] [CASE=ABL]]
5. One of the ambiguous parses is a lexicalized
form while another is form derived by a pro-
ductive derivation as in 1 and 2 below.
6. The same suffix appears in different positions in
the morphotactic paradigm conveying different
information as in 2 and 3 below.
1. uygulama / (application)
[ [CAT=NOUN] [ROOT=uygulama]
[AGR=35G] [POSS=NONE] [CASE=NOM]]
2. uygula+ma / ( (the act of) applying)
HCAT=VERB] [ROOT=uygula] [SENSE=POS]
[CONV=NOUN=MA] [TYPE=INFINITIVE]
[AGR=3SG] [POSS=NONE] [CASE=NOM] ]
3. uygula+ma / (do not apply ! )
[ [CAT=VERB] [ROOT=uygula] [SENSE=NEG]
[TAM1=IMP] [AGR=2SG]]
</listItem>
<bodyText confidence="0.999937133333333">
The main intent of our system is to achieve mor-
phological disambiguation by choosing for a given
ambiguous token, the correct parse in a given con-
text. It is certainly possible that a given token may
have multiple correct parses, usually with the same
inflectional features, or with inflectional features not
ruled out by the syntactic context, but one will be
the &amp;quot;correct&amp;quot; parse usually on semantic grounds.
We consider a token fully disambiguated if it has
only one morphological parse remaining after auto-
matic disambiguation. We consider a token as cor-
rectly disambiguated, if one of the parses remaining
for that token is the correct intended parse. We eval-
uate the resulting disambiguated text by a number
of metrics defined as follows (Voutilainen, 1995a):
</bodyText>
<subsubsectionHeader confidence="0.477105">
#Parses
#Tokens Correctly Disambiguated
</subsubsectionHeader>
<equation confidence="0.87110675">
Recall =
#Tokens
Precision â€”
#Parses
</equation>
<bodyText confidence="0.993863333333333">
In the ideal case where each token is uniquely and
correctly disambiguated with the correct parse, both
recall and precision will be 1.0. On the other hand, a
</bodyText>
<figure confidence="0.724969">
Aznbiguity =
#Tokens
#Tokens Correctly Disambiguated
</figure>
<page confidence="0.996015">
223
</page>
<bodyText confidence="0.999989">
text where each token is annotated with all possible
parses,3 the recall will be 1.0, but the precision will
be low. The goal is to have both recall and precision
as high as possible.
</bodyText>
<sectionHeader confidence="0.9850275" genericHeader="method">
3 Constraint-based Morphological
Disambiguation
</sectionHeader>
<bodyText confidence="0.999909">
This section outlines our approach to constraint-
based morphological disambiguation where con-
straints vote on matching parses of sequential to-
kens.
</bodyText>
<subsectionHeader confidence="0.998812">
3.1 Constraints on morphological parses
</subsectionHeader>
<bodyText confidence="0.9999335">
We describe constraints on the morphological parses
of tokens using rules with two components
</bodyText>
<equation confidence="0.908136">
R =(Ci,C2, â€¢ â€¢ â€¢ Cn; V)
</equation>
<bodyText confidence="0.8852361875">
where the Ci are (possibly hierarchical) feature con-
straints on a sequence of the morphological parses,
and V is an integer denoting the vote of the rule.
To illustrate the flavor of our rules we can give the
following examples:
1. The following rule with two constraints matches
parses with case feature ablative, preceding a
parse matching a postposition subcategorizing
for an ablative nominal form.
[[case : abl] , [cat :postp,subcat : abl]]
2. The rule
[[agr: &apos;2SG&apos; ,case :gen] , [cat :noun,poss: &apos;2SG&apos;]]
matches a nominal form with a possessive
marker 2SG, following a pronoun with 2SG
agreement and genitive case, enforcing the sim-
plest form of noun phrase constraints.
</bodyText>
<listItem confidence="0.8818928">
3. In general constraints can make references to
the derivational structure of the lexical form
and hence be hierarchical. For instance, the fol-
lowing rule is an example of a rule employing a
hierarchical constraint:
</listItem>
<equation confidence="0.376727">
Hcat:adj,stem: [taml:narr]]
[cat:noun,stem:no]]
</equation>
<bodyText confidence="0.999166666666667">
which matches the derived participle reading of
a verb with narrative past tense, if it is followed
by an underived noun parse.
</bodyText>
<subsectionHeader confidence="0.999812">
3.2 Determining the vote of a rule
</subsectionHeader>
<bodyText confidence="0.999893375">
There are a number of ways votes can be assigned
to rules. For the purposes of this work the vote of
a rule is determined by its static properties, but it
is certainly conceivable that votes can be assigned
or learned by using statistics from disambiguated
corpora.4 For static vote assignment, intuitively, we
would like to give high votes to rules that are more
specific: i.e., to rules that have
</bodyText>
<footnote confidence="0.933985">
3Assuming no unknown words.
4We have left this for future work.
</footnote>
<listItem confidence="0.992636166666667">
â€¢ higher number of constraints,
â€¢ higher number of features in the constraints,
â€¢ constraints that make reference to nested stems
(from which the current form is derived),
â€¢ constraints that make reference to very specific
features or values.
</listItem>
<bodyText confidence="0.9797295">
Let R = (C1, C2, â€¢ â€¢ â€¢ , Cn; V) be a constraint rule.
The vote V is determined as
</bodyText>
<equation confidence="0.996912">
V = EV(C2)
</equation>
<bodyText confidence="0.999664666666667">
where V(Ci) is the contribution of constraint Ci to
the vote of the rule R. A (generic) constraint has
the following form:
</bodyText>
<equation confidence="0.953367">
C = [(Ii : vi)Sz(f2 : v2)&amp; â€¢ â€¢ â€¢ (fm : vâ€ž,)]
</equation>
<bodyText confidence="0.9993335">
where fi is the name of a morphological feature, and
vz is one of the possible values for that feature. The
contribution of fi : vi in the vote of a constraint
depends on a number of factors:
</bodyText>
<listItem confidence="0.869202647058823">
1. The value vi may be a distinguished value that
has a more important function in disambigua-
tion.3 In this case, the weight of the feature
constraint is w(vi)(&gt; 1).
2. The feature itself may be a distinguished feature
which has more important function in disam-
biguation. In this case the weight of the feature
is w(fi)(&gt; 1).
3. If the feature fi refers to the stem of a de-
rived form and the value part of the feature con-
straint is a full fledged constraint C&apos; on the stem
structure, the weight of the feature constraint is
found by recursively computing the vote of C&apos;
and scaling the resulting value by a factor (2 in
our current system) to improve its specificity.
4. Otherwise, the weight of the feature constraint
is 1.
</listItem>
<bodyText confidence="0.833905142857143">
For example suppose we have the following con-
straint:
[cat:noun, case:gen,
stem: [cat : adj , stem: [cat :v] suffix=mis]]
Assuming the value gen is a distinguished value
with weight 4 (cf., factor 1 above), the vote of this
constraint is computed as follows:
</bodyText>
<listItem confidence="0.9387802">
1. cat :noun contributes 1,
2. case:gen contributes 4,
3. stem: [cat : adj , stem: [cat : v] , suff ix=mis]
contributes 8 computed as follows:
(a) cat :adj contributes 1,
</listItem>
<footnote confidence="0.996702">
5For instance, for Turkish we have noted that
the genitive case marker is usually very helpful in
disambiguation.
</footnote>
<page confidence="0.991169">
224
</page>
<listItem confidence="0.928707">
(b) suffix=mis contributes 1,
(c) stem: [cat :v] contributes 2 = 2 * 1, the 1
being from cat :v,
(d) the sum 4 is scaled by 2 to give 8.
4. Votes from steps 1, 2 and 3(d) are added up to
give 13 as the constraint vote.
</listItem>
<bodyText confidence="0.999957307692308">
We also employ a set of rules which express pref-
erences among the parses of single lexical form in-
dependent of the context in which the form occurs.
The weights for these rules are currently manually
determined. These rules give negative votes to the
parses which are not preferred or high votes to cer-
tain parses which are always preferred. Our experi-
ence is that such preference rules depend on the kind
of the text one is disambiguating. For instance if one
is disambiguating a manual of some sort, imperative
readings of verbs are certainly possible, whereas in
normal plain text with no discourse, such readings
are discouraged.
</bodyText>
<subsectionHeader confidence="0.990521">
3.3 Voting and selecting parses
</subsectionHeader>
<bodyText confidence="0.999927117647059">
A rule R = (C1, C2, â€¢ â€¢ , Cn; V) will match a se-
quence of tokens wi, tvi+1, â€¢ â€¢ â€¢ , w_1 within a sen-
tence w1 through ws if some morphological parse of
every token wi i&lt; &lt; i n â€” 1 is subsumed by
the corresponding constraint Ci_i+1. When all con-
straints match, the votes of all the matching parses
are incremented by V. If a given constraint matches
more than one parse of a token, then the votes of all
such matching parses are incremented.
After all rules have been applied to all token po-
sitions in a sentence and votes are tallied, morpho-
logical parses are selected in the following manner.
Let vi and vh be the votes of the lowest and high-
est scoring parses for a given token. All parses with
votes equal to or higher than vi m * (vh â€” v1) are
selected with in (0 &lt; in &lt; 1) being a parameter.
in = 1 selects the highest scoring parse(s).
</bodyText>
<sectionHeader confidence="0.949521" genericHeader="method">
4 Results from Disambiguating
Turkish Text
</sectionHeader>
<bodyText confidence="0.999948306451613">
We have applied our approach to disambiguating
Turkish text. Raw text is processed by a prepro-
cessor which segments the text into sentences using
various heuristics about punctuation, and then to-
kenizes and runs it through a wide-coverage high-
performance morphological analyzer developed us-
ing two-level morphology tools by Xerox (Kart-
tunen, 1993). The preprocessor module also per-
forms a number of additional functions such as
grouping of lexicalized and non-lexicalized colloca-
tions, compound verbs, etc., (Oflazer and Kurth:3z,
1994; Oflazer and Tar, 1996). The preprocessor also
uses a second morphological processor for dealing
with unknown words which recovers any derivational
and inflectional information from a word even if the
root word is not known. This unknown word pro-
cessor has a (nominal) root lexicon which recognizes
S+, where S is the Turkish surface alphabet (in the
two-level morphology sense), but then tries to in-
terpret an arbitrary postfix string of the unknown
word, as a sequence of Turkish suffixes subject to
all morphographemic constraints (Oflazer and Tiir,
1996).
We have applied our approach to four texts la-
beled ARK, HIST, MAN, EMB, with statistics
given in Table 1. The tokens considered are those
that are generated after morphological analysis, un-
known word processing and any lexical coalescing is
done. The words that are counted as unknown are
those that could not even be processed by the un-
known noun processor as they violate Turkish mor-
phographemic constraints. Whenever an unknown
word has more than one parse it is counted under the
appropriate group.&apos; The fourth and fifth columns in
this table give the average parses per token and the
initial precision assuming initial recall is 100%.
We have disambiguated these texts using a rule
base of about 500 hand-crafted rules. Most of the
rule crafting was done using the general linguistic
constraints and constraints that we derived from the
first text, ARK. In this sense, this text is our &amp;quot;train-
ing data&amp;quot;, while the other three texts were not con-
sidered in rule crafting.
Our results are summarized in Table 2. The last
four columns in this table present results for differ-
ent values for the parameter 771 mentioned above,
ni = 1 denoting the case when only the highest
scoring parse(s) is (are) selected. The columns for
in &lt; 1 are presented in order to emphasize that dras-
tic loss of precision for those cases. Even at m = 0.95
there is considerable loss of precision and going up
to m = 1 causes a dramatic increase in precision
without a significant loss in recall. It can be seen
that we can attain very good recall and quite ac-
ceptable precision with just voting constraint rules.
Our experience is that we can in principle add highly
specialized rules by covering a larger text base to
improve our recall and precision for the m = 1. A
post-mortem analysis has shown that cases that have
been missed are mostly due to morphosyntactic de-
pendencies that span a context much wider that 5
tokens that we currently employ.
</bodyText>
<subsectionHeader confidence="0.99907">
4.1 Using root and contextual statistics
</subsectionHeader>
<bodyText confidence="0.9998844">
We have employed two additional sources of infor-
mation: root word usage statistics, and contextual
statistics. We have statistics compiled from previ-
ously disambiguated text, on root frequencies. After
the application of constraints as described above, for
</bodyText>
<footnote confidence="0.56482375">
6The reason for the (comparatively) high number of
unknown words in MAN, is that tokens found in such
texts, like 110, denoting a function key in the computer
can not be parsed as a Turkish root word!
</footnote>
<page confidence="0.994964">
225
</page>
<table confidence="0.999171555555556">
Text Sent. Tokens Parses/ Init. Distribution
Token Prec. of
Morphological Parse
0 1 2 3 4 &gt; 4
ARK 492 7928 1.823 0.55 0.15% 49.34% 30.93% 9.19% 8.46% 1.93%
1.69%
HIST 270 5212 1.797 0.56 0.02% 50.63% 30.68% 8.62% 8.36%
MAN 204 2756 1.840 0.54 0.65% 49.01% 31.70% 6.37% 8.91% 3.36%
EMB 198 5177 1.914 0.52 0.09% 43.94% 34.58% 9.60% 9.46% 2.33%
</table>
<tableCaption confidence="0.996022">
Table 1: Statistics on Texts
</tableCaption>
<table confidence="0.999941357142857">
Vote Range Selected(m)
TEXT 1.0 0.95 0.8 0.6
ARK Rec. 98.05 98.47 98.69 98.77
Prec. 94.13 87.65 84.41 82.43
Amb. 1.042 1.123 1.169 1.200
HIST Rec. 97.03 97.65 98.81 97.01
Prec. 94.13 87.10 84.41 82.29
Amb. 1.058 1.121 1.169 1.189
MAN Rec. 97.03 97.92 97.81 98.77
Prec. 91.05 83.51 79.85 77.34
Amb. 1.068 1.172 1.237 1.277
EMB Rec. 96.51 97.48 97.76 97.94
Prec. 91.28 84.36 77.87 75.79
Amb. 1.057 1.150 1.255 1.292
</table>
<tableCaption confidence="0.995196">
Table 2: Results with voting constraints
</tableCaption>
<table confidence="0.999947230769231">
TEXT V V+R V+R+C
ARK Rec. 98.05 97.60 96.98
Prec. 94.13 95.28 96.19
Amb. 1.042 1.024 1.008
HIST Rec. 97.03 96.52 95.62
Prec. 94.13 92.59 94.33
Amb. 1.058 1.042 1.013
MAN Rec. 97.03 96.47 95.84
Prec. 91.05 93.08 94.47
Amb. 1.058 1.042 1.014
EMB Rec. 96.51 96.47 95.37
Prec. 91.28 93.08 94.45
Amb. 1.057 1.036 1.009
</table>
<tableCaption confidence="0.9462615">
Table 3: Results with voting constraints and root
statistics, context statistics
</tableCaption>
<bodyText confidence="0.998298142857143">
tokens which are still ambiguous with ambiguity re-
sulting from different root words, we discard parses
if the frequencies of the root words for those parses
are considerably lower than the frequency of the root
of the highest scoring parse. The results after apply-
ing this step on top of voting, with m = 1, are shown
in the fourth column of Table 3 (labeled V+R).
On top of this, we use the following heuristic us-
ing context statistics to eliminate any further ambi-
guities. For every remaining ambiguous token with
unambiguous immediate left and right contexts (i.e.,
the tokens in the immediate left and right are unam-
biguous), we perform the following, by ignoring the
root/stem feature of the parses:
</bodyText>
<listItem confidence="0.831383166666667">
1. For every ambiguous parse in such an unam-
biguous context, we count how many times, this
parse occurs unambiguously in exactly the same
unambiguous context, in the rest of the text.
2. We then choose the parse whose count is sub-
stantially higher than the others.
</listItem>
<bodyText confidence="0.9997655">
The results after applying this step on of the previ-
ous two steps are shown in the last column of Table
3 (labeled V+R+C). One can see from the last three
columns of this table, the impact of each of the steps.
By ignoring root/stem features during this pro-
cess, we essentially are considering just the top level
inflectional information of the parses. This is very
similar to Brill&apos;s use of contexts to induce transfor-
mation rules for his tagger (Brill, 1992; Brill, 1995),
but instead of generating transformation rules from
a training text, we gather statistics and apply them
to parses in the text being disambiguated.
</bodyText>
<sectionHeader confidence="0.9140475" genericHeader="method">
5 Efficient Implementation
Techniques and Extensions
</sectionHeader>
<bodyText confidence="0.999969764705883">
The current implementation of the voting approach
is meant to be a proof of concept implementation
and is rather inefficient. However, the use of regular
relations and finite state transducers (Kaplan and
Kay, 1994) provide a very efficient implementation
method. For this, we view the parses of the tokens
making up a sentence as making up a acyclic a fi-
nite state recognizer with the states marking word
boundaries and the ambiguous interpretations of the
tokens as the state transitions between states, the
rightmost node denoting the final state, as depicted
in Figure 1 for a sentence with 5 tokens. In Figure 1,
the transition labels are triples of the sort (wi , pj , 0)
for the it h parse of token i, with the 0 indicating
the initial vote of the parse. The rules imposing
constraints can also be represented as transducers
which increment the votes of the matching transi-
</bodyText>
<page confidence="0.972895">
226
</page>
<equation confidence="0.996387">
(wl,p1,0) (w2,p1,0) (w3,p1,0) (w4,p1,0) (w5,p1,0)
(wl,p3,0) (w2,p5, 0) (w3,p4,0) (w4,p3,0) (w5,p4,0)
</equation>
<figureCaption confidence="0.998763">
Figure 1: Sentence as a finite state recognizer.
</figureCaption>
<bodyText confidence="0.999317942857143">
tion labels by an appropriate amount.7 Such trans-
ducers ignore and pass through unchanged, parses
that they are not sensitive to.
When a finite state recognizer corresponding to
the input sentence (which actually may be consid-
ered as an identity transducer) is composed with a
constraint transducer, one gets a slightly modified
version of the sentence transducer with possibly ad-
ditional transitions and states, where the votes of
some of the labels have been appropriately incre-
mented. When the sentence transducer is composed
with all the constraint transducers in sequence, all
possible votes are cast and the final sentence trans-
ducer reflects all the votes. The parse corresponding
to each token with the highest vote can then be se-
lected. The key point here is that due to the nature
of the composition operator, the constraint transduc-
ers can be composed off-line first, giving a single con-
straint transducer and then this one is composed with
every sentence transducer once (See Figure 2).
The idea of voting can further be extended to a
path voting framework where rules vote on paths
containing sequences of matching parses and the
path from the start state to the final stated with
the highest votes received, is then selected. This can
be implemented again using finite state transducers
as described above (except that path vote is appor-
tioned equally to relevant parse votes), but instead
of selecting highest scoring parses, one selects the
path from the start state to one of the final states
where the sum of the parse votes is maximum. We
have recently completed a prototype implementation
of this approach (in C) for English (Brown Corpus)
and have obtained quite similar results (Tiir, Of-
lazer, and oz-kan, 1997).
</bodyText>
<sectionHeader confidence="0.999492" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99045045">
We have presented an approach to constraint-based
morphological disambiguation which uses constraint
voting as its primary mechanism for parse selec-
tion and alleviates the rule developer from worrying
about rule ordering issues. Our approach is quite
general and is applicable to any language. Rules de-
scribing language specific linguistic constraints vote
on matching parses of tokens, and at the end, parses
&apos;Suggested by Lauri Karttunen (private communica-
tion).
for every token receiving the highest tokens are se-
lected. We have applied this approach to Turkish,
a language with complex agglutinative word forms
exhibiting morphological ambiguity phenomena not
usually found in languages like English and have ob-
tained quite promising results. The convenience of
adding new rules in without worrying about where
exactly it goes in terms of rule ordering (some-
thing that hampered our progress in our earlier work
on disambiguating Turkish morphology (Oflazer and
Kuru6z, 1994; Oflazer and Tiir, 1996)), has also been
a key positive point. Furthermore, it is also possible
to use rules with negative votes to disallow impos-
sible cases. This has been quite useful for our work
on tagging English (Tiir, Oflazer, and Oz-kan, 1997)
where such rules with negative weights were used to
fine tune the behavior of the tagger in various prob-
lematic cases.
The proposed approach is also amenable to an
efficient implementation by finite state transducers
(Kaplan and Kay, 1994). By using finite state trans-
ducers, it is furthermore possible to use a bit more
expressive rule formalism including for instance the
Kleene * operator so that one can use a much smaller
set of rules to cover the same set of local linguistic
phenomena.
Our current and future work in this framework
involves the learning of constraints and their votes
from corpora, and combining learned and hand-
crafted rules.
</bodyText>
<sectionHeader confidence="0.998168" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999235166666667">
This research has been supported in part by a NATO
Science for Stability Grant TUâ€”LANGUAGE. We
thank Lauri Karttunen of Rank Xerox Research
Centre in Grenoble for providing the Xerox two-level
morphology tools on which the Turkish morpholog-
ical analyzer was built.
</bodyText>
<sectionHeader confidence="0.994748" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.679720833333333">
Brill, Eric. 1992. A simple-rule based part-of-speech
tagger. In Proceedings of the Third Conference
on Applied Natural Language Processing, Trento,
Italy.
Brill, Eric. 1994. Some advances in rule-based
part of speech tagging. In Proceedings of the
</reference>
<page confidence="0.987765">
227
</page>
<figure confidence="0.998732666666666">
(wl,p1,0) (w2,p1,0) (w3,p1,0) (w4,p1,0) (w5,p1,0)
(w4,p3,0)
(w2,p5,0)
(wl,p3,0)
0
(w3 ,p4,0)
Jr
Constraint
Transducer 1 (+V1)
(w5,p4,0)
Composition of the
sentence transducer
with the constraint
transducer
I
Single transducer
Icomposed from all
!constraint
!transducers
Constraint
Transducer n (+Vn)
</figure>
<figureCaption confidence="0.993751">
Figure 2: Sentence and Constraint Transducers
</figureCaption>
<figure confidence="0.996746">
Resulting sentence
transducer after
composition
Jr
</figure>
<page confidence="0.973505">
228
</page>
<reference confidence="0.998983123287671">
Twelfth National Conference on Artificial Intel-
ligence (AAAI-94), Seattle, Washington.
Brill, Eric. 1995. Transformation-based error-driven
learning and natural language processing: A case
study in part-of-speech tagging. Computational
Linguistics, 21(4):543-566, December.
Church, Kenneth W. 1988. A stochastic parts pro-
gram and a noun phrase parser for unrestricted
text. In Proceedings of the Second Conference
on Applied Natural Language Processing, Austin,
Texas.
Cutting, Doug, Julian Kupiec, Jan Pedersen, and
Penelope Sibun. 1992. A practical part-of-speech
tagger. In Proceedings of the Third Conference
on. Applied Natural Language Processing, Trento,
Italy.
DeRose, Steven J. 1988. Grammatical category dis-
ambiguation by statistical optimization. Compu-
tational Linguistics, 14(1):31-39.
Hankamer, Jorge. 1989. Morphological parsing and
the lexicon. In W. Marslen-Wilson, editor, Lexical
Representation and Process. MIT Press.
Kaplan, Ronald M. and Martin Kay. 1994. Regular
models of phonological rule systems. Computa-
tional Linguistics, 20(3):331-378, September.
Karlsson, Fred, Atro Voutilainen, Julia Heikkila,
and Arto Anttila. 1995. Constraint Grammar-A
Language-Independent System for Parsing Unre-
stricted Text. Mouton de Gruyter.
Karttunen, Lauri. 1993. Finite-state lexicon com-
piler. XEROX, Palo Alto Research Center- Tech-
nical Report, April.
Oflazer, Kemal and ilker KuruOz. 1994. Tag-
ging and morphological disambiguation of Turk-
ish text. In Proceedings of the 4th Applied Natural
Language Processing Conference, pages 144-149.
ACL, October.
Oflazer, Kemal and Giikhan Tiir. 1996. Combin-
ing hand-crafted rules and unsupervised learn-
ing in constraint-based morphological disambigua-
tion. In Eric Brill and Kenneth Church, editors,
Proceedings of the ACL-SIGDAT Conference on
Empirical Methods in Natural Language Process-
ing.
Tiir, Gokhan, Kemal Oflazer, and Nihat Oz-
kan. 1997. Tagging English by path
voting constraints. Technical Report BU-
CEIS-9704, Bilkent University, Department of
Computer Engineering and Information Sci-
ence, Ankara, Turkey, March. Available as
ftp://ftp.cs.bilkent.edu.tr/pub/tech-rep-
orts/1997/BU-CEIS-9704.ps.z.
Voutilainen, Atro. 1994. Three studies of grammar-
based surface-syntactic parsing of unrestricted En-
glish text. Ph.D. thesis, Research Unit for Com-
putational Linguistics, University of Helsinki.
Voutilainen, Atro. 1995a. Morphological disam-
biguation. In Fred Karlsson, Atro Voutilainen,
Juha Heikkila, and Arto Anttila, editors, Con-
straint Grammar-A Language-Independent Sys-
tem. for Parsing Unrestricted Text. Mouton de
Gruyter, chapter 5.
Voutilainen, Atro. 1995b. A syntax-based part-of-
speech analyzer. In Proceedings of the Seventh
Conference of the European Chapter of the Asso-
ciation of Computational Linguistics, Dublin, Ire-
land.
Voutilainen, Atro, Juha Heikkila, and Arto Anttila.
1992. Constraint Grammar of English. University
of Helsinki.
Voutilainen, Atro and Pasi Tapanainen. 1993. Am-
biguity resolution in a reductionistic parser. In
Proceedings of EACL &apos;93, Utrecht, Holland.
</reference>
<page confidence="0.998916">
229
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.690005">
<title confidence="0.999841">Morphological Disambiguation by Voting Constraints</title>
<author confidence="0.96886">Oflazer Tiir</author>
<affiliation confidence="0.999628">Department of Computer Engineering and Information Science</affiliation>
<address confidence="0.869782">Bilkent University, Bilkent, TR-06533, Turkey</address>
<email confidence="0.996474">fko,turlOcs.bilkent.edu.tr</email>
<abstract confidence="0.991786409090909">We present a constraint-based morphological disambiguation system in which individual constraints vote on matching morphological parses, and disambiguation of all the tokens in a sentence is performed at the end by selecting parses that receive the highest votes. This constraint application paradigm makes the outcome of the the rule sequence, and hence relieves the rule developer from worrying about potentially conflicting rule sequencing. Our results for disambiguating Turkish indicate that using about 500 constraint rules and some addisimple statistics, we can attain a reof 95-96% a of 94-95% about 1.01 parses per token. system is implemented in Prolog and we are currently investigating an efficient implementation based on finite state transducers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>A simple-rule based part-of-speech tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the Third Conference on Applied Natural Language Processing,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="1635" citStr="Brill, 1992" startWordPosition="236" endWordPosition="237">nite state transducers. 1 Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item. This approach does not reflect the outcome of matching constraints to the set of morphological parses immediately. Only after all applicable rules are applied to a sentence, all tokens are disambiguated in</context>
<context position="20589" citStr="Brill, 1992" startWordPosition="3388" endWordPosition="3389">usly in exactly the same unambiguous context, in the rest of the text. 2. We then choose the parse whose count is substantially higher than the others. The results after applying this step on of the previous two steps are shown in the last column of Table 3 (labeled V+R+C). One can see from the last three columns of this table, the impact of each of the steps. By ignoring root/stem features during this process, we essentially are considering just the top level inflectional information of the parses. This is very similar to Brill&apos;s use of contexts to induce transformation rules for his tagger (Brill, 1992; Brill, 1995), but instead of generating transformation rules from a training text, we gather statistics and apply them to parses in the text being disambiguated. 5 Efficient Implementation Techniques and Extensions The current implementation of the voting approach is meant to be a proof of concept implementation and is rather inefficient. However, the use of regular relations and finite state transducers (Kaplan and Kay, 1994) provide a very efficient implementation method. For this, we view the parses of the tokens making up a sentence as making up a acyclic a finite state recognizer with t</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Brill, Eric. 1992. A simple-rule based part-of-speech tagger. In Proceedings of the Third Conference on Applied Natural Language Processing, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Some advances in rule-based part of speech tagging.</title>
<date>1994</date>
<booktitle>In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94),</booktitle>
<location>Seattle, Washington.</location>
<contexts>
<context position="1648" citStr="Brill, 1994" startWordPosition="238" endWordPosition="239">ansducers. 1 Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item. This approach does not reflect the outcome of matching constraints to the set of morphological parses immediately. Only after all applicable rules are applied to a sentence, all tokens are disambiguated in parallel. Th</context>
</contexts>
<marker>Brill, 1994</marker>
<rawString>Brill, Eric. 1994. Some advances in rule-based part of speech tagging. In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--4</pages>
<contexts>
<context position="1662" citStr="Brill, 1995" startWordPosition="240" endWordPosition="241">Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item. This approach does not reflect the outcome of matching constraints to the set of morphological parses immediately. Only after all applicable rules are applied to a sentence, all tokens are disambiguated in parallel. Thus, the outcom</context>
<context position="20603" citStr="Brill, 1995" startWordPosition="3390" endWordPosition="3391">ly the same unambiguous context, in the rest of the text. 2. We then choose the parse whose count is substantially higher than the others. The results after applying this step on of the previous two steps are shown in the last column of Table 3 (labeled V+R+C). One can see from the last three columns of this table, the impact of each of the steps. By ignoring root/stem features during this process, we essentially are considering just the top level inflectional information of the parses. This is very similar to Brill&apos;s use of contexts to induce transformation rules for his tagger (Brill, 1992; Brill, 1995), but instead of generating transformation rules from a training text, we gather statistics and apply them to parses in the text being disambiguated. 5 Efficient Implementation Techniques and Extensions The current implementation of the voting approach is meant to be a proof of concept implementation and is rather inefficient. However, the use of regular relations and finite state transducers (Kaplan and Kay, 1994) provide a very efficient implementation method. For this, we view the parses of the tokens making up a sentence as making up a acyclic a finite state recognizer with the states mark</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Brill, Eric. 1995. Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging. Computational Linguistics, 21(4):543-566, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
</authors>
<title>A stochastic parts program and a noun phrase parser for unrestricted text.</title>
<date>1988</date>
<booktitle>In Proceedings of the Second Conference on Applied Natural Language Processing,</booktitle>
<location>Austin, Texas.</location>
<contexts>
<context position="1348" citStr="Church, 1988" startWordPosition="199" endWordPosition="200">ndicate that using about 500 constraint rules and some additional simple statistics, we can attain a recall of 95-96% and a precision of 94-95% with about 1.01 parses per token. Our system is implemented in Prolog and we are currently investigating an efficient implementation based on finite state transducers. 1 Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, an</context>
</contexts>
<marker>Church, 1988</marker>
<rawString>Church, Kenneth W. 1988. A stochastic parts program and a noun phrase parser for unrestricted text. In Proceedings of the Second Conference on Applied Natural Language Processing, Austin, Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Cutting</author>
<author>Julian Kupiec</author>
<author>Jan Pedersen</author>
<author>Penelope Sibun</author>
</authors>
<title>A practical part-of-speech tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the Third Conference on. Applied Natural Language Processing,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="1370" citStr="Cutting et al., 1992" startWordPosition="201" endWordPosition="204">sing about 500 constraint rules and some additional simple statistics, we can attain a recall of 95-96% and a precision of 94-95% with about 1.01 parses per token. Our system is implemented in Prolog and we are currently investigating an efficient implementation based on finite state transducers. 1 Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constra</context>
</contexts>
<marker>Cutting, Kupiec, Pedersen, Sibun, 1992</marker>
<rawString>Cutting, Doug, Julian Kupiec, Jan Pedersen, and Penelope Sibun. 1992. A practical part-of-speech tagger. In Proceedings of the Third Conference on. Applied Natural Language Processing, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven J DeRose</author>
</authors>
<title>Grammatical category disambiguation by statistical optimization.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<pages>14--1</pages>
<contexts>
<context position="1385" citStr="DeRose, 1988" startWordPosition="205" endWordPosition="206">int rules and some additional simple statistics, we can attain a recall of 95-96% and a precision of 94-95% with about 1.01 parses per token. Our system is implemented in Prolog and we are currently investigating an efficient implementation based on finite state transducers. 1 Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes</context>
</contexts>
<marker>DeRose, 1988</marker>
<rawString>DeRose, Steven J. 1988. Grammatical category disambiguation by statistical optimization. Computational Linguistics, 14(1):31-39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Hankamer</author>
</authors>
<title>Morphological parsing and the lexicon.</title>
<date>1989</date>
<booktitle>Lexical Representation and Process.</booktitle>
<editor>In W. Marslen-Wilson, editor,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3601" citStr="Hankamer, 1989" startWordPosition="536" endWordPosition="537">rds are usually ambiguous in their parts-of-speech or other morphological features, and may represent lexical items of different syntactic categories, or morphological structures depending on the syntactic and semantic context. In languages like English, there are a very small number of possible word forms that can be generated from a given root word, and a small number of part-ofspeech tags associated with a given lexical form. On the other hand, in languages like Turkish or Finnish with very productive agglutinative morphology, it is possible to produce thousands of forms (or even millions (Hankamer, 1989)) from a given root word and the kinds of ambiguities one observes are quite different than what is observed in languages like English. In Turkish, there are ambiguities of the sort typically found in languages like English (e.g., book/noun vs book/verb type). However, the agglutinative nature of the language usually helps resolution of such ambiguities due to the restrictions on morphotactics of subsequent morphemes. On the &apos;Voutilainen, Private communication. 222 other hand, this very nature introduces another kind of ambiguity, where a lexical form can be morphologically interpreted in many</context>
</contexts>
<marker>Hankamer, 1989</marker>
<rawString>Hankamer, Jorge. 1989. Morphological parsing and the lexicon. In W. Marslen-Wilson, editor, Lexical Representation and Process. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Martin Kay</author>
</authors>
<title>Regular models of phonological rule systems.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--3</pages>
<contexts>
<context position="21021" citStr="Kaplan and Kay, 1994" startWordPosition="3451" endWordPosition="3454">ntially are considering just the top level inflectional information of the parses. This is very similar to Brill&apos;s use of contexts to induce transformation rules for his tagger (Brill, 1992; Brill, 1995), but instead of generating transformation rules from a training text, we gather statistics and apply them to parses in the text being disambiguated. 5 Efficient Implementation Techniques and Extensions The current implementation of the voting approach is meant to be a proof of concept implementation and is rather inefficient. However, the use of regular relations and finite state transducers (Kaplan and Kay, 1994) provide a very efficient implementation method. For this, we view the parses of the tokens making up a sentence as making up a acyclic a finite state recognizer with the states marking word boundaries and the ambiguous interpretations of the tokens as the state transitions between states, the rightmost node denoting the final state, as depicted in Figure 1 for a sentence with 5 tokens. In Figure 1, the transition labels are triples of the sort (wi , pj , 0) for the it h parse of token i, with the 0 indicating the initial vote of the parse. The rules imposing constraints can also be represente</context>
<context position="25058" citStr="Kaplan and Kay, 1994" startWordPosition="4107" endWordPosition="4110">ordering (something that hampered our progress in our earlier work on disambiguating Turkish morphology (Oflazer and Kuru6z, 1994; Oflazer and Tiir, 1996)), has also been a key positive point. Furthermore, it is also possible to use rules with negative votes to disallow impossible cases. This has been quite useful for our work on tagging English (Tiir, Oflazer, and Oz-kan, 1997) where such rules with negative weights were used to fine tune the behavior of the tagger in various problematic cases. The proposed approach is also amenable to an efficient implementation by finite state transducers (Kaplan and Kay, 1994). By using finite state transducers, it is furthermore possible to use a bit more expressive rule formalism including for instance the Kleene * operator so that one can use a much smaller set of rules to cover the same set of local linguistic phenomena. Our current and future work in this framework involves the learning of constraints and their votes from corpora, and combining learned and handcrafted rules. 7 Acknowledgments This research has been supported in part by a NATO Science for Stability Grant TUâ€”LANGUAGE. We thank Lauri Karttunen of Rank Xerox Research Centre in Grenoble for providi</context>
</contexts>
<marker>Kaplan, Kay, 1994</marker>
<rawString>Kaplan, Ronald M. and Martin Kay. 1994. Regular models of phonological rule systems. Computational Linguistics, 20(3):331-378, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred Karlsson</author>
<author>Atro Voutilainen</author>
<author>Julia Heikkila</author>
<author>Arto Anttila</author>
</authors>
<title>Constraint Grammar-A Language-Independent System for Parsing Unrestricted Text. Mouton de Gruyter.</title>
<date>1995</date>
<contexts>
<context position="1437" citStr="Karlsson et al., 1995" startWordPosition="209" endWordPosition="212">ics, we can attain a recall of 95-96% and a precision of 94-95% with about 1.01 parses per token. Our system is implemented in Prolog and we are currently investigating an efficient implementation based on finite state transducers. 1 Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item. This ap</context>
</contexts>
<marker>Karlsson, Voutilainen, Heikkila, Anttila, 1995</marker>
<rawString>Karlsson, Fred, Atro Voutilainen, Julia Heikkila, and Arto Anttila. 1995. Constraint Grammar-A Language-Independent System for Parsing Unrestricted Text. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>Finite-state lexicon compiler. XEROX, Palo Alto Research Center-</title>
<date>1993</date>
<tech>Technical Report,</tech>
<contexts>
<context position="14759" citStr="Karttunen, 1993" startWordPosition="2389" endWordPosition="2391">otes of the lowest and highest scoring parses for a given token. All parses with votes equal to or higher than vi m * (vh â€” v1) are selected with in (0 &lt; in &lt; 1) being a parameter. in = 1 selects the highest scoring parse(s). 4 Results from Disambiguating Turkish Text We have applied our approach to disambiguating Turkish text. Raw text is processed by a preprocessor which segments the text into sentences using various heuristics about punctuation, and then tokenizes and runs it through a wide-coverage highperformance morphological analyzer developed using two-level morphology tools by Xerox (Karttunen, 1993). The preprocessor module also performs a number of additional functions such as grouping of lexicalized and non-lexicalized collocations, compound verbs, etc., (Oflazer and Kurth:3z, 1994; Oflazer and Tar, 1996). The preprocessor also uses a second morphological processor for dealing with unknown words which recovers any derivational and inflectional information from a word even if the root word is not known. This unknown word processor has a (nominal) root lexicon which recognizes S+, where S is the Turkish surface alphabet (in the two-level morphology sense), but then tries to interpret an </context>
</contexts>
<marker>Karttunen, 1993</marker>
<rawString>Karttunen, Lauri. 1993. Finite-state lexicon compiler. XEROX, Palo Alto Research Center- Technical Report, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
<author>ilker KuruOz</author>
</authors>
<title>Tagging and morphological disambiguation of Turkish text.</title>
<date>1994</date>
<booktitle>In Proceedings of the 4th Applied Natural Language Processing Conference,</booktitle>
<pages>144--149</pages>
<publisher>ACL,</publisher>
<marker>Oflazer, KuruOz, 1994</marker>
<rawString>Oflazer, Kemal and ilker KuruOz. 1994. Tagging and morphological disambiguation of Turkish text. In Proceedings of the 4th Applied Natural Language Processing Conference, pages 144-149. ACL, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
<author>Giikhan Tiir</author>
</authors>
<title>Combining hand-crafted rules and unsupervised learning in constraint-based morphological disambiguation.</title>
<date>1996</date>
<booktitle>In Eric Brill and Kenneth Church, editors, Proceedings of the ACL-SIGDAT Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="1586" citStr="Oflazer and Tiir, 1996" startWordPosition="229" endWordPosition="232">rrently investigating an efficient implementation based on finite state transducers. 1 Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item. This approach does not reflect the outcome of matching constraints to the set of morphological parses immediately. Only after all applicable rules are appli</context>
<context position="4440" citStr="Oflazer and Tiir, 1996" startWordPosition="663" endWordPosition="666">English (e.g., book/noun vs book/verb type). However, the agglutinative nature of the language usually helps resolution of such ambiguities due to the restrictions on morphotactics of subsequent morphemes. On the &apos;Voutilainen, Private communication. 222 other hand, this very nature introduces another kind of ambiguity, where a lexical form can be morphologically interpreted in many ways not usually predictable in advance. Furthermore, Turkish allows very productive derivational processes and the information about the derivational structure of a word form is usually crucial for disambiguation (Oflazer and Tiir, 1996). Most kinds of morphological ambiguities that we have observed in Turkish typically fall into one the following classes:2 1. the form is uninflected and assumes the default inflectional features, e.g., 1. taS (made of stone) [CAT=ADJ] [ROOT=taS]] 2. taS (stone) [ [CAT=NOUN] [ROOT=taS] [AGR=3SG] [POSS=NONE] [CASE=NOM] ] 3. taS (overflow!) [[CAT=VERB] [ROOT=t aS] [SENSE=POS] [TAM1=IMP] [AGR=2SG]] 2. Lexically different affixes (conveying different morphological features) surface the same due to the morphographemic context, e.g., 1. ev+ [n] in (of the house) [ [CAT=NOUN] [ROOT=ev] [AGR=3SG] [POS</context>
<context position="15506" citStr="Oflazer and Tiir, 1996" startWordPosition="2504" endWordPosition="2507"> collocations, compound verbs, etc., (Oflazer and Kurth:3z, 1994; Oflazer and Tar, 1996). The preprocessor also uses a second morphological processor for dealing with unknown words which recovers any derivational and inflectional information from a word even if the root word is not known. This unknown word processor has a (nominal) root lexicon which recognizes S+, where S is the Turkish surface alphabet (in the two-level morphology sense), but then tries to interpret an arbitrary postfix string of the unknown word, as a sequence of Turkish suffixes subject to all morphographemic constraints (Oflazer and Tiir, 1996). We have applied our approach to four texts labeled ARK, HIST, MAN, EMB, with statistics given in Table 1. The tokens considered are those that are generated after morphological analysis, unknown word processing and any lexical coalescing is done. The words that are counted as unknown are those that could not even be processed by the unknown noun processor as they violate Turkish morphographemic constraints. Whenever an unknown word has more than one parse it is counted under the appropriate group.&apos; The fourth and fifth columns in this table give the average parses per token and the initial p</context>
<context position="24591" citStr="Oflazer and Tiir, 1996" startWordPosition="4029" endWordPosition="4032">tokens, and at the end, parses &apos;Suggested by Lauri Karttunen (private communication). for every token receiving the highest tokens are selected. We have applied this approach to Turkish, a language with complex agglutinative word forms exhibiting morphological ambiguity phenomena not usually found in languages like English and have obtained quite promising results. The convenience of adding new rules in without worrying about where exactly it goes in terms of rule ordering (something that hampered our progress in our earlier work on disambiguating Turkish morphology (Oflazer and Kuru6z, 1994; Oflazer and Tiir, 1996)), has also been a key positive point. Furthermore, it is also possible to use rules with negative votes to disallow impossible cases. This has been quite useful for our work on tagging English (Tiir, Oflazer, and Oz-kan, 1997) where such rules with negative weights were used to fine tune the behavior of the tagger in various problematic cases. The proposed approach is also amenable to an efficient implementation by finite state transducers (Kaplan and Kay, 1994). By using finite state transducers, it is furthermore possible to use a bit more expressive rule formalism including for instance th</context>
</contexts>
<marker>Oflazer, Tiir, 1996</marker>
<rawString>Oflazer, Kemal and Giikhan Tiir. 1996. Combining hand-crafted rules and unsupervised learning in constraint-based morphological disambiguation. In Eric Brill and Kenneth Church, editors, Proceedings of the ACL-SIGDAT Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gokhan Tiir</author>
<author>Kemal Oflazer</author>
<author>Nihat Ozkan</author>
</authors>
<title>Tagging English by path voting constraints.</title>
<date>1997</date>
<tech>Technical Report BUCEIS-9704,</tech>
<institution>Bilkent University, Department of Computer Engineering and Information Science,</institution>
<location>Ankara, Turkey,</location>
<note>Available as ftp://ftp.cs.bilkent.edu.tr/pub/tech-reports/1997/BU-CEIS-9704.ps.z.</note>
<marker>Tiir, Oflazer, Ozkan, 1997</marker>
<rawString>Tiir, Gokhan, Kemal Oflazer, and Nihat Ozkan. 1997. Tagging English by path voting constraints. Technical Report BUCEIS-9704, Bilkent University, Department of Computer Engineering and Information Science, Ankara, Turkey, March. Available as ftp://ftp.cs.bilkent.edu.tr/pub/tech-reports/1997/BU-CEIS-9704.ps.z.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atro Voutilainen</author>
</authors>
<title>Three studies of grammarbased surface-syntactic parsing of unrestricted English text.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Research Unit for Computational Linguistics, University of Helsinki.</institution>
<marker>Voutilainen, 1994</marker>
<rawString>Voutilainen, Atro. 1994. Three studies of grammarbased surface-syntactic parsing of unrestricted English text. Ph.D. thesis, Research Unit for Computational Linguistics, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atro Voutilainen</author>
</authors>
<title>Morphological disambiguation.</title>
<date>1995</date>
<booktitle>Constraint Grammar-A Language-Independent System. for Parsing Unrestricted Text. Mouton de Gruyter, chapter 5.</booktitle>
<editor>In Fred Karlsson, Atro Voutilainen, Juha Heikkila, and Arto Anttila, editors,</editor>
<contexts>
<context position="1456" citStr="Voutilainen, 1995" startWordPosition="213" endWordPosition="214">call of 95-96% and a precision of 94-95% with about 1.01 parses per token. Our system is implemented in Prolog and we are currently investigating an efficient implementation based on finite state transducers. 1 Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item. This approach does not ref</context>
<context position="8272" citStr="Voutilainen, 1995" startWordPosition="1244" endWordPosition="1245">ontext. It is certainly possible that a given token may have multiple correct parses, usually with the same inflectional features, or with inflectional features not ruled out by the syntactic context, but one will be the &amp;quot;correct&amp;quot; parse usually on semantic grounds. We consider a token fully disambiguated if it has only one morphological parse remaining after automatic disambiguation. We consider a token as correctly disambiguated, if one of the parses remaining for that token is the correct intended parse. We evaluate the resulting disambiguated text by a number of metrics defined as follows (Voutilainen, 1995a): #Parses #Tokens Correctly Disambiguated Recall = #Tokens Precision â€” #Parses In the ideal case where each token is uniquely and correctly disambiguated with the correct parse, both recall and precision will be 1.0. On the other hand, a Aznbiguity = #Tokens #Tokens Correctly Disambiguated 223 text where each token is annotated with all possible parses,3 the recall will be 1.0, but the precision will be low. The goal is to have both recall and precision as high as possible. 3 Constraint-based Morphological Disambiguation This section outlines our approach to constraintbased morphological dis</context>
</contexts>
<marker>Voutilainen, 1995</marker>
<rawString>Voutilainen, Atro. 1995a. Morphological disambiguation. In Fred Karlsson, Atro Voutilainen, Juha Heikkila, and Arto Anttila, editors, Constraint Grammar-A Language-Independent System. for Parsing Unrestricted Text. Mouton de Gruyter, chapter 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atro Voutilainen</author>
</authors>
<title>A syntax-based part-ofspeech analyzer.</title>
<date>1995</date>
<booktitle>In Proceedings of the Seventh Conference of the European Chapter of the Association of Computational Linguistics,</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="1456" citStr="Voutilainen, 1995" startWordPosition="213" endWordPosition="214">call of 95-96% and a precision of 94-95% with about 1.01 parses per token. Our system is implemented in Prolog and we are currently investigating an efficient implementation based on finite state transducers. 1 Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item. This approach does not ref</context>
<context position="8272" citStr="Voutilainen, 1995" startWordPosition="1244" endWordPosition="1245">ontext. It is certainly possible that a given token may have multiple correct parses, usually with the same inflectional features, or with inflectional features not ruled out by the syntactic context, but one will be the &amp;quot;correct&amp;quot; parse usually on semantic grounds. We consider a token fully disambiguated if it has only one morphological parse remaining after automatic disambiguation. We consider a token as correctly disambiguated, if one of the parses remaining for that token is the correct intended parse. We evaluate the resulting disambiguated text by a number of metrics defined as follows (Voutilainen, 1995a): #Parses #Tokens Correctly Disambiguated Recall = #Tokens Precision â€” #Parses In the ideal case where each token is uniquely and correctly disambiguated with the correct parse, both recall and precision will be 1.0. On the other hand, a Aznbiguity = #Tokens #Tokens Correctly Disambiguated 223 text where each token is annotated with all possible parses,3 the recall will be 1.0, but the precision will be low. The goal is to have both recall and precision as high as possible. 3 Constraint-based Morphological Disambiguation This section outlines our approach to constraintbased morphological dis</context>
</contexts>
<marker>Voutilainen, 1995</marker>
<rawString>Voutilainen, Atro. 1995b. A syntax-based part-ofspeech analyzer. In Proceedings of the Seventh Conference of the European Chapter of the Association of Computational Linguistics, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atro Voutilainen</author>
<author>Juha Heikkila</author>
<author>Arto Anttila</author>
</authors>
<date>1992</date>
<institution>Constraint Grammar of English. University of Helsinki.</institution>
<contexts>
<context position="1499" citStr="Voutilainen, Heikkila, and Anttila, 1992" startWordPosition="215" endWordPosition="220"> precision of 94-95% with about 1.01 parses per token. Our system is implemented in Prolog and we are currently investigating an efficient implementation based on finite state transducers. 1 Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item. This approach does not reflect the outcome of matching constraints to</context>
</contexts>
<marker>Voutilainen, Heikkila, Anttila, 1992</marker>
<rawString>Voutilainen, Atro, Juha Heikkila, and Arto Anttila. 1992. Constraint Grammar of English. University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atro Voutilainen</author>
<author>Pasi Tapanainen</author>
</authors>
<title>Ambiguity resolution in a reductionistic parser.</title>
<date>1993</date>
<booktitle>In Proceedings of EACL &apos;93,</booktitle>
<location>Utrecht, Holland.</location>
<contexts>
<context position="1533" citStr="Voutilainen and Tapanainen, 1993" startWordPosition="221" endWordPosition="224">s per token. Our system is implemented in Prolog and we are currently investigating an efficient implementation based on finite state transducers. 1 Introduction Automatic morphological disambiguation is an important component in higher level analysis of natural language text corpora. There has been a large number of studies in tagging and morphological disambiguation using various techniques such as statistical techniques, e.g., (Church, 1988; Cutting et al., 1992; DeRose, 1988), constraint-based techniques (Karlsson et al., 1995; Voutilainen, 1995b; Voutilainen, Heikkila, and Anttila, 1992; Voutilainen and Tapanainen, 1993; Oflazer and Kurth:5z, 1994; Oflazer and Tiir, 1996) and transformation-based techniques (Brill, 1992; Brill, 1994; Brill, 1995). This paper presents a novel approach to constraint based morphological disambiguation which relieves the rule developer from worrying about conflicting rule ordering requirements. The approach depends on assigning votes to constraints according to their complexity and specificity, and then letting constraints cast votes on matching parses of a given lexical item. This approach does not reflect the outcome of matching constraints to the set of morphological parses i</context>
</contexts>
<marker>Voutilainen, Tapanainen, 1993</marker>
<rawString>Voutilainen, Atro and Pasi Tapanainen. 1993. Ambiguity resolution in a reductionistic parser. In Proceedings of EACL &apos;93, Utrecht, Holland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>