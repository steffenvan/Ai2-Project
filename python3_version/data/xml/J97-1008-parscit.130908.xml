<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.030552">
<title confidence="0.904697">
Book Review
Corpus Processing for Lexical Acquisition
</title>
<author confidence="0.537877">
Branimir Boguraev and James Pustejovsky (editors)
(Apple Computer and Brandeis University)
</author>
<figureCaption confidence="0.570847">
Cambridge, MA: The MIT Press
(Language, speech, and communication
series), 1996, xvii+245 pp; hardbound,
ISBN 0-262-02392-X, $32.50
</figureCaption>
<figure confidence="0.893365666666667">
Reviewed by
Brian Ulicny
Inso Corporation
</figure>
<bodyText confidence="0.995460294117647">
As the editors of this collection point out, NLP systems are generally only as good
as the lexical resources that they employ. But acquiring these resources is costly. To
what extent can the acquisition, extension, or improvement of computational lexical re-
sources be automated? Corpus Processing for Lexical Acquisition contains revised versions
of 10 papers originally presented at the ACL/SIGLEX Workshop on the Acquisition of
Lexical Knowledge from Text, held at The Ohio State University in 1993, which focused
on just these issues. The editors state that the contributions represent the &amp;quot;beginning
of a new research programme combining linguistically inspired language analysis and
statistically based corpus research&amp;quot; (p. 17). In addition to an introductory chapter by
the editors providing a short review of the problems and previous approaches to lexical
acquisition, the contributions are grouped into five sections: &amp;quot;Coping with unknown
lexicalizations&amp;quot; (3 papers), &amp;quot;Task-driven lexicon induction&amp;quot; (2 papers), &amp;quot;Categorization
of lexical units&amp;quot; (2 papers), &amp;quot;Lexical semantics from corpus analysis&amp;quot; (2 papers), and
&amp;quot;Measuring lexical acquisition&amp;quot; (1 paper).
The first section, &amp;quot;Coping with unknown lexicalizations,&amp;quot; deals primarily with
identifying and reidentifying the names of individuals and organizations in journal-
istic text, particularly the Wall Street Journal. Largely due to the complications of their
internal punctuation and irregular capitalization, naive approaches to name identifi-
cation will not produce acceptable results. David D. McDonald&apos;s contribution &amp;quot;Inter-
nal and external evidence in the identification and semantic categorization of proper
names&amp;quot; stands out as a state-of-the-art presentation of a context-sensitive grammar
for proper-name identification. Here, internal evidence refers to the properties of the
words of a sequence to be evaluated as a proper name, and external evidence refers to
the properties of the context of that sequence. McDonald&apos;s system is especially inter-
esting in that it does not rely on lists of open-class name elements, such as common
first names and surnames. Inderjeet Mani and T. Richard MacMillan address simi-
lar issues in their contribution. Their paper, &amp;quot;Identifying unknown proper names in
newswire text,&amp;quot; outlines a sophisticated algorithm for identifying coreferential long
names (e.g., U.S. President Bill Clinton) and short names (e.g., Clinton) within and across
texts, drawing on discourse theory.
The general utility of this name recognition section is somewhat limited by its
focus on the Wall Street Journal corpus. While McDonald reports impressive results for
his system, it is fine-tuned to the particularities of the Journal&apos;s domain. For exam-
Computational Linguistics Volume 23, Number 1
pie, McDonald&apos;s system takes proper names not to extend across possessives (p. 35),
thereby excluding Bram Stoker&apos;s Dracula and Babette&apos;s Feast (two recent film titles) as
single names, not to mention sex, lies, and videotape (all lowercase). For comparison, it
would be helpful to see some discussion of name recognition and resolution in very
poorly edited text, such as Usenet newsgroup corpora.
The second section, &amp;quot;Task-driven lexicon induction,&amp;quot; reports work on the appli-
cation of machine learning techniques to the problem of word-sense discrimination.
Marti Hearst and Hinrich Schritze describe a variety of techniques for modifying the
WordNet lexicon by means of lexical co-occurrence statistics from a specialized cor-
pus in order to better identify the subject matter of documents. Similar techniques are
proposed and evaluated in the contribution by Claudia Leacock and her colleagues
Geoffrey Towell and Ellen Voorhees.
The third and fourth sections deal largely with the acquisition of argument struc-
ture from corpora and verb categorization. Roberto Basili and his colleagues report on
their CIAULA system for inducing verb classifications within specialized text domains
and provide an interesting discussion of the methodological considerations that went
into its design. The system seems to require sophisticated manual markup of subcat-
egorization patterns as input to the system. Basili et al. report that the verb clusters
discovered may be &amp;quot;unintuitive&amp;quot; (p. 127), but it was unclear how the resulting clusters
of verbs with varying adicities and subcategorization frames constituted a reasonable
grouping of verbs. Here, perhaps, Beth Levin&apos;s work on English verb classes (Levin
1993) might serve as a better point of departure for future work in both English and
other languages (cf. Jones et al. 1994).
Scott Waterman&apos;s contribution makes interesting use of the notion of &amp;quot;edit dis-
tance&amp;quot; in pattern matching, which has been successfully applied to problems in ge-
netics, handwriting analysis, and other fields, in the problem of extracting the subcat-
egorization patterns of various prepositions.
Victor Poznariski and Antonio Sanfilippo give a crisp overview of their CorPSE sys-
tem (Corpus-based Predicate Structure Extractor), which combines information from
the Longman Lexicon of Contemporary English with corpus data in order to automatically
assign thematic roles and verb senses in parsing. Somewhat less clear is Chinatsu
Aone and Douglas McKee&apos;s contribution. They seek to automatically assign all verbs
in English, Spanish, and Japanese to four situation types: caused process, process-or-state,
agentive-action, and inverse-state. No linguistic motivation is provided for this very un-
intuitive set of classifications, so it is nearly impossible to evaluate their work. Aone
and McKee, for example, inexplicably assert that suffice is correctly classified as a tran-
sitive inverse-state verb with a Goal subject and Theme direct object. As with the Basili
contribution, if thematic roles are to be invoked, some account of how many there are
and what they contribute to the sentence should be given.
The sole contribution to the section on evaluation is Gregory Grefenstette&apos;s pa-
per proposing and comparing some methods for evaluating automatic assessments of
word similarity. The automatic techniques are evaluated in comparison with machine-
readable dictionaries and thesauri. The dictionaries and thesauri are proposed as &amp;quot;gold
standards,&amp;quot; but readers may make their own judgments as to which resource, the cor-
pora or the lexicographic resources, get word similarities right.
In general, the editors&apos; promise that this book represents a new marriage of lin-
guistic and empirical techniques is somewhat overstated on the linguistic side. Little
use is made of such notions as head of a phrase, scope, movement, inflection, domi-
nance, and other basic concepts of linguistic analysis. While some attention is paid to
passivization in the discussion of subcategorization frames, for example, there is no
attempt to control for the effects of wh-movement in questions or relative clauses in
</bodyText>
<page confidence="0.994511">
192
</page>
<subsectionHeader confidence="0.573811">
Book Review
</subsectionHeader>
<bodyText confidence="0.999932222222222">
gathering a verb&apos;s syntactic frames. Also, as mentioned above, little attention is paid
to how recent discussions of thematical roles and linking theory (most recently as
in Dowty [19911, Hale and Keyser [1993], and Pesetsky [1995]) inform computational
techniques, or how computational techniques could put them to the test.
Nevertheless, this collection is a valuable resource for those who need to address
problems associated with the automatic acquisition of lexical resources, particularly
with regard to proper-name identification and argument-structure assignment. It con-
tains a thorough bibliography, and separate author and subject indices. No significant
typos were found, although grammatical repairs were needed in some papers.
</bodyText>
<sectionHeader confidence="0.971971" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.994216571428571">
Dowty, David. 1991. Thematic proto-roles
and argument selection. Language
67:547-619.
Hale, Kenneth and Samuel Jay Keyser. 1993.
On argument structure and the lexical
expression of syntactic relations. In
Kenneth Hale and Samuel Jay Keyser,
editors, The View from Building 20: Essays in
Linguistics in Honor of Sylvain Bromberger,
The MIT Press, Cambridge, MA.
Jones, Douglas A., Robert C. Berwick,
Franklin Cho, Zeeshan R. Khan, Naoyuki
Nomura, Anand Radhakrishrian, Ulrich
Sauerland, and Brian Ulicny. 1994. Verb
classes and alternations in Bangla,
German, English, and Korean. Memo
1517, Artificial Intelligence Laboratory,
Massachusetts Institute of Technology,
Levin, Beth. 1993. English Verb Classes and
Alternations: A Preliminary Investigation.
University of Chicago Press, Chicago, IL.
Pesetsky, David. 1995. Zero Syntax:
Experiencers and Cascades. The MIT Press,
Cambridge, MA.
Brian Ulicny completed his doctorate at MIT in 1993 and is a Senior Member of the Technical Staff
at Quarterdeck Corporation. His research interests include the application of lexical semantics to
information retrieval tasks. Ulicny&apos;s address is: Inso Corporation, 31 St. James Avenue, Boston,
MA 02116; e-mail: bulicny@inso.com
</reference>
<page confidence="0.99924">
193
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000525">
<title confidence="0.992965">Book Review Corpus Processing for Lexical Acquisition</title>
<author confidence="0.978043">Branimir Boguraev</author>
<author confidence="0.978043">James Pustejovsky</author>
<affiliation confidence="0.995605">(Apple Computer and Brandeis University)</affiliation>
<address confidence="0.975111">Cambridge, MA: The MIT Press</address>
<keyword confidence="0.495416">(Language, speech, and communication series), 1996, xvii+245 pp; hardbound,</keyword>
<note confidence="0.947056">ISBN 0-262-02392-X, $32.50 Reviewed by</note>
<author confidence="0.998401">Brian Ulicny</author>
<affiliation confidence="0.997855">Inso Corporation</affiliation>
<abstract confidence="0.992179939393939">As the editors of this collection point out, NLP systems are generally only as good as the lexical resources that they employ. But acquiring these resources is costly. To what extent can the acquisition, extension, or improvement of computational lexical rebe automated? Processing for Lexical Acquisition revised versions of 10 papers originally presented at the ACL/SIGLEX Workshop on the Acquisition of Lexical Knowledge from Text, held at The Ohio State University in 1993, which focused on just these issues. The editors state that the contributions represent the &amp;quot;beginning of a new research programme combining linguistically inspired language analysis and statistically based corpus research&amp;quot; (p. 17). In addition to an introductory chapter by the editors providing a short review of the problems and previous approaches to lexical acquisition, the contributions are grouped into five sections: &amp;quot;Coping with unknown lexicalizations&amp;quot; (3 papers), &amp;quot;Task-driven lexicon induction&amp;quot; (2 papers), &amp;quot;Categorization of lexical units&amp;quot; (2 papers), &amp;quot;Lexical semantics from corpus analysis&amp;quot; (2 papers), and &amp;quot;Measuring lexical acquisition&amp;quot; (1 paper). The first section, &amp;quot;Coping with unknown lexicalizations,&amp;quot; deals primarily with identifying and reidentifying the names of individuals and organizations in journaltext, particularly the Street Journal. due to the complications of their internal punctuation and irregular capitalization, naive approaches to name identification will not produce acceptable results. David D. McDonald&apos;s contribution &amp;quot;Internal and external evidence in the identification and semantic categorization of proper names&amp;quot; stands out as a state-of-the-art presentation of a context-sensitive grammar for proper-name identification. Here, internal evidence refers to the properties of the words of a sequence to be evaluated as a proper name, and external evidence refers to the properties of the context of that sequence. McDonald&apos;s system is especially interesting in that it does not rely on lists of open-class name elements, such as common names and surnames. Inderjeet Mani and MacMillan address similar issues in their contribution. Their paper, &amp;quot;Identifying unknown proper names in newswire text,&amp;quot; outlines a sophisticated algorithm for identifying coreferential long U.S. President Bill Clinton) short names Clinton) and across texts, drawing on discourse theory. The general utility of this name recognition section is somewhat limited by its on the Street Journal While McDonald reports impressive results for system, it is fine-tuned to the particularities of the For exam- Computational Linguistics Volume 23, Number 1 pie, McDonald&apos;s system takes proper names not to extend across possessives (p. 35), excluding Stoker&apos;s Dracula Feast recent film titles) as names, not to mention lies, and videotape lowercase). For comparison, it would be helpful to see some discussion of name recognition and resolution in very poorly edited text, such as Usenet newsgroup corpora. The second section, &amp;quot;Task-driven lexicon induction,&amp;quot; reports work on the application of machine learning techniques to the problem of word-sense discrimination. Marti Hearst and Hinrich Schritze describe a variety of techniques for modifying the WordNet lexicon by means of lexical co-occurrence statistics from a specialized corpus in order to better identify the subject matter of documents. Similar techniques are proposed and evaluated in the contribution by Claudia Leacock and her colleagues Geoffrey Towell and Ellen Voorhees. The third and fourth sections deal largely with the acquisition of argument structure from corpora and verb categorization. Roberto Basili and his colleagues report on their CIAULA system for inducing verb classifications within specialized text domains and provide an interesting discussion of the methodological considerations that went into its design. The system seems to require sophisticated manual markup of subcategorization patterns as input to the system. Basili et al. report that the verb clusters discovered may be &amp;quot;unintuitive&amp;quot; (p. 127), but it was unclear how the resulting clusters of verbs with varying adicities and subcategorization frames constituted a reasonable grouping of verbs. Here, perhaps, Beth Levin&apos;s work on English verb classes (Levin 1993) might serve as a better point of departure for future work in both English and other languages (cf. Jones et al. 1994). Scott Waterman&apos;s contribution makes interesting use of the notion of &amp;quot;edit distance&amp;quot; in pattern matching, which has been successfully applied to problems in genetics, handwriting analysis, and other fields, in the problem of extracting the subcategorization patterns of various prepositions. Poznariski and Antonio Sanfilippo give a crisp overview of their CorPSE sys- Predicate Structure Extractor), which combines information from Lexicon of Contemporary English corpus data in order to automatically assign thematic roles and verb senses in parsing. Somewhat less clear is Chinatsu Aone and Douglas McKee&apos;s contribution. They seek to automatically assign all verbs English, Spanish, and Japanese to four types: process, process-or-state, linguistic motivation is provided for this very unintuitive set of classifications, so it is nearly impossible to evaluate their work. Aone McKee, for example, inexplicably assert that correctly classified as a tranwith a Goal subject and Theme direct object. As with the Basili contribution, if thematic roles are to be invoked, some account of how many there are and what they contribute to the sentence should be given. The sole contribution to the section on evaluation is Gregory Grefenstette&apos;s paper proposing and comparing some methods for evaluating automatic assessments of word similarity. The automatic techniques are evaluated in comparison with machinereadable dictionaries and thesauri. The dictionaries and thesauri are proposed as &amp;quot;gold standards,&amp;quot; but readers may make their own judgments as to which resource, the corpora or the lexicographic resources, get word similarities right. In general, the editors&apos; promise that this book represents a new marriage of linguistic and empirical techniques is somewhat overstated on the linguistic side. Little use is made of such notions as head of a phrase, scope, movement, inflection, dominance, and other basic concepts of linguistic analysis. While some attention is paid to passivization in the discussion of subcategorization frames, for example, there is no attempt to control for the effects of wh-movement in questions or relative clauses in 192 Book Review gathering a verb&apos;s syntactic frames. Also, as mentioned above, little attention is paid to how recent discussions of thematical roles and linking theory (most recently as in Dowty [19911, Hale and Keyser [1993], and Pesetsky [1995]) inform computational techniques, or how computational techniques could put them to the test. Nevertheless, this collection is a valuable resource for those who need to address problems associated with the automatic acquisition of lexical resources, particularly with regard to proper-name identification and argument-structure assignment. It contains a thorough bibliography, and separate author and subject indices. No significant typos were found, although grammatical repairs were needed in some papers. References Dowty, David. 1991. Thematic proto-roles argument selection.</abstract>
<note confidence="0.8543995">67:547-619. Hale, Kenneth and Samuel Jay Keyser. 1993.</note>
<title confidence="0.7392995">On argument structure and the lexical expression of syntactic relations. In</title>
<author confidence="0.790840666666667">Kenneth Hale</author>
<author confidence="0.790840666666667">Samuel Jay Keyser</author>
<author confidence="0.790840666666667">View from Building Essays in Linguistics in Honor of Sylvain Bromberger</author>
<affiliation confidence="0.891515">The MIT Press, Cambridge, MA. Jones, Douglas A., Robert C. Berwick,</affiliation>
<address confidence="0.667904666666667">Franklin Cho, Zeeshan R. Khan, Naoyuki Nomura, Anand Radhakrishrian, Ulrich Sauerland, and Brian Ulicny. 1994. Verb</address>
<affiliation confidence="0.718731">classes and alternations in Bangla,</affiliation>
<address confidence="0.650519">German, English, and Korean. Memo</address>
<affiliation confidence="0.9411685">1517, Artificial Intelligence Laboratory, Massachusetts Institute of Technology,</affiliation>
<address confidence="0.992622">Beth. 1993. Verb Classes and</address>
<note confidence="0.53534">Alternations: A Preliminary Investigation. University of Chicago Press, Chicago, IL. David. 1995. Syntax:</note>
<affiliation confidence="0.980694">and Cascades. MIT Press,</affiliation>
<address confidence="0.985186">Cambridge, MA.</address>
<note confidence="0.443063666666667">Ulicny his doctorate at MIT in 1993 and is a Senior Member of the Technical Staff at Quarterdeck Corporation. His research interests include the application of lexical semantics to information retrieval tasks. Ulicny&apos;s address is: Inso Corporation, 31 St. James Avenue, Boston,</note>
<email confidence="0.810049">MA02116;e-mail:bulicny@inso.com</email>
<intro confidence="0.323476">193</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>Thematic proto-roles and argument selection.</title>
<date>1991</date>
<journal>Language</journal>
<pages>67--547</pages>
<marker>Dowty, 1991</marker>
<rawString>Dowty, David. 1991. Thematic proto-roles and argument selection. Language 67:547-619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Hale</author>
<author>Samuel Jay Keyser</author>
</authors>
<title>On argument structure and the lexical expression of syntactic relations.</title>
<date>1993</date>
<booktitle>The View from Building 20: Essays in Linguistics in Honor of Sylvain Bromberger, The</booktitle>
<editor>In Kenneth Hale and Samuel Jay Keyser, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Hale, Keyser, 1993</marker>
<rawString>Hale, Kenneth and Samuel Jay Keyser. 1993. On argument structure and the lexical expression of syntactic relations. In Kenneth Hale and Samuel Jay Keyser, editors, The View from Building 20: Essays in Linguistics in Honor of Sylvain Bromberger, The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Douglas A Jones</author>
<author>Robert C Berwick</author>
<author>Franklin Cho</author>
<author>Zeeshan R Khan</author>
</authors>
<location>Naoyuki</location>
<marker>Jones, Berwick, Cho, Khan, </marker>
<rawString>Jones, Douglas A., Robert C. Berwick, Franklin Cho, Zeeshan R. Khan, Naoyuki</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anand Radhakrishrian Nomura</author>
<author>Ulrich Sauerland</author>
<author>Brian Ulicny</author>
</authors>
<title>Verb classes and alternations in</title>
<date>1994</date>
<booktitle>Korean. Memo 1517, Artificial</booktitle>
<institution>Intelligence Laboratory, Massachusetts Institute of Technology,</institution>
<location>Bangla, German, English, and</location>
<marker>Nomura, Sauerland, Ulicny, 1994</marker>
<rawString>Nomura, Anand Radhakrishrian, Ulrich Sauerland, and Brian Ulicny. 1994. Verb classes and alternations in Bangla, German, English, and Korean. Memo 1517, Artificial Intelligence Laboratory, Massachusetts Institute of Technology,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations: A Preliminary Investigation.</title>
<date>1993</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, IL.</location>
<contexts>
<context position="4800" citStr="Levin 1993" startWordPosition="697" endWordPosition="698">ort on their CIAULA system for inducing verb classifications within specialized text domains and provide an interesting discussion of the methodological considerations that went into its design. The system seems to require sophisticated manual markup of subcategorization patterns as input to the system. Basili et al. report that the verb clusters discovered may be &amp;quot;unintuitive&amp;quot; (p. 127), but it was unclear how the resulting clusters of verbs with varying adicities and subcategorization frames constituted a reasonable grouping of verbs. Here, perhaps, Beth Levin&apos;s work on English verb classes (Levin 1993) might serve as a better point of departure for future work in both English and other languages (cf. Jones et al. 1994). Scott Waterman&apos;s contribution makes interesting use of the notion of &amp;quot;edit distance&amp;quot; in pattern matching, which has been successfully applied to problems in genetics, handwriting analysis, and other fields, in the problem of extracting the subcategorization patterns of various prepositions. Victor Poznariski and Antonio Sanfilippo give a crisp overview of their CorPSE system (Corpus-based Predicate Structure Extractor), which combines information from the Longman Lexicon of </context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Levin, Beth. 1993. English Verb Classes and Alternations: A Preliminary Investigation. University of Chicago Press, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Pesetsky</author>
</authors>
<title>Zero Syntax: Experiencers and Cascades.</title>
<date>1995</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Pesetsky, 1995</marker>
<rawString>Pesetsky, David. 1995. Zero Syntax: Experiencers and Cascades. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Brian</author>
</authors>
<title>Ulicny completed his doctorate at MIT in 1993 and is a Senior Member of the Technical Staff at Quarterdeck Corporation. His research interests include the application of lexical semantics to information retrieval tasks. Ulicny&apos;s address is: Inso Corporation, 31 St. James Avenue,</title>
<location>Boston, MA</location>
<note>02116; e-mail: bulicny@inso.com</note>
<marker>Brian, </marker>
<rawString>Brian Ulicny completed his doctorate at MIT in 1993 and is a Senior Member of the Technical Staff at Quarterdeck Corporation. His research interests include the application of lexical semantics to information retrieval tasks. Ulicny&apos;s address is: Inso Corporation, 31 St. James Avenue, Boston, MA 02116; e-mail: bulicny@inso.com</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>