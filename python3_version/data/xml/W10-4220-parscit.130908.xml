<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.013628">
<title confidence="0.9963275">
‘If you’ve heard it, you can say it’ -
Towards an Account of Expressibility
</title>
<author confidence="0.997322">
David D. McDonald Charles F. Greenbacker
</author>
<affiliation confidence="0.991821">
Raytheon BBN Technologies University of Delaware
</affiliation>
<address confidence="0.757001">
Cambridge, MA USA Newark, DE, USA
</address>
<email confidence="0.998935">
dmcdonald@bbn.com charlieg@cis.udel.edu
</email>
<sectionHeader confidence="0.997385" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999876571428571">
We have begun a project to automatically cre-
ate the lexico-syntactic resources for a mi-
croplanner as a side-effect of running a do-
main-specific language understanding system.
The resources are parameterized synchronous
TAG Derivation Trees. Since the KB is as-
sembled from the information in the texts that
these resources are abstracted from, it will de-
compose along those same lines when used for
generation. As all possible ways of expressing
each concept are pre-organized into general
patterns known to be linguistically-valid (they
were observed in natural text), we obtain an
architectural account for expressibility.
</bodyText>
<sectionHeader confidence="0.995399" genericHeader="keywords">
1. Expressibility
</sectionHeader>
<bodyText confidence="0.998909875">
People speak grammatically. They may stutter,
restart, or make the occasional speech error, but
all in all they are faithful to the grammar of the
language dialects they use. One of the ways that
a language generation system can account for
this is through the use of grammar that defines
all of the possible lexico-syntactic elements from
which a text can be constructed and defines all
their rules of composition, such as lexicalized
Tree Adjoining Grammar (TAG). Without the
ability to even formulate an ungrammatical text,
such a generator provides an account for human
grammaticality based on its architecture rather
than its programmer.
We propose a similar kind of accounting for
the problem of expressibility: one based on
architecture rather than accident. Expressibility,
as defined by Meteer (1992), is an issue for
microplanners as they decide on which lexical
and syntactic resources to employ. Not all of the
options they might want to use are available in
the language – they are not expressible. Consider
the examples in Figure 1, adapted from Meteer
1992 pg. 50.
</bodyText>
<figure confidence="0.9915084">
Expression Construction (‘decide’)
“quick decision” &lt;result&gt; + &lt;quick&gt;
“decide quickly” &lt;action&gt; + &lt;quick&gt;
“important decision” &lt;result&gt; + &lt;important&gt;
* “decide importantly” &lt;action&gt; + &lt;important&gt;
</figure>
<figureCaption confidence="0.9288025">
Figure 1: Constraints on expressibility: To say
that there was a decision and it was important,
</figureCaption>
<bodyText confidence="0.967080555555555">
you are forced to use the noun form because
there is no adverbial form for important as
there is for quick
In this short paper, we discuss our approach to
expressibility. We describe in detail our novel
method centered on how to use parser observa-
tions to guide generator decisions, and we pro-
vide a snapshot of the current status of our
system implementation.
</bodyText>
<sectionHeader confidence="0.999914" genericHeader="introduction">
2. Related Work
</sectionHeader>
<bodyText confidence="0.99990535">
Natural language generation (NLG) systems
must have some way of making sure that the
messages they build are actually expressible.
Template-based generators avoid problems with
expressibility largely by anticipating all of the
wording that will be needed and packaging it in
chunks that are guaranteed to compose correctly.
Becker (2006), for example, does this via fully
lexicalized TAG trees.
Among more general-purpose generators, one
approach to expressibility is to look ahead into
the lexicon, avoiding constructions that are
lexically incompatible. Look-ahead is expensive,
however, and is only practical at small abstrac-
tion distances such as Shaw’s re-writing sentence
planner (1998).
Meteer’s own approach to expressibility
started by interposing another level of represen-
tation between the microplanner and the surface
realizer, an ‘abstract syntactic representation’ in
the sense of RAGS (Cahill et al. 1999), that
employed functional relationships (head, argu-
ment, matrix, adjunct) over semantically typed,
lexicalized constituents. This blocks *decide
importantly because ‘important’ only has a
realization as a property and her composition
rules prohibit using a property to modify an
action (‘decide’). Shifting the perspective from
the action to its result allows the composition to
go through.
We are in sympathy with this approach – a
microplanner needs its own representational
level to serve as a scratch pad (if using a revi-
sion-based approach) or just as a scaffold to hold
intermediate results. However, Meteer’s seman-
tic and lexical constraints do require operating
with fine-grain details. We believe that we can
work with larger chunks that have already been
vetted for expressibility because we’ve observed
someone use them, either in writing or speech.
</bodyText>
<sectionHeader confidence="0.963232" genericHeader="method">
3. Method
</sectionHeader>
<bodyText confidence="0.9999071">
Our approach is similar to that of Zhong &amp; Stent
(2005) in that we use the analysis of a corpus as
the basis for creating the resources for the reali-
zation component. Several differences stand out.
For one, we are working in specific domains
rather than generic corpora like the WSJ. This
enables the biggest difference: our analysis is
performed by a completely accurate,1 domain-
specific NLU system (‘parser’)2 based on a
semantic grammar (McDonald 1993). It is read-
ing for the benefit of a knowledge base, adding
specific facts within instances of a highly struc-
tured, predefined prototypes. Such instances are
used as the starting point for the generation
process.
On the KB side, our present focus happens to
be on hurricanes and the process they go through
as they evolve. We have developed a semantic
grammar for this domain, and it lets us analyze
texts like these:3
</bodyText>
<listItem confidence="0.803302071428571">
(1) “Later that day it made landfall near
the Haitian town of Jacmel.”
1 Parse accuracy and correct word sense interpretation is
only possible if the semantic domain under analysis is
restricted by topic and sublanguage.
2 Most systems referred to as “parsers” stop at a structural
description. Ours stops at the level of a disambiguated
conceptual model and is more integrated than most.
3 #1 and 2 are from the Wikipedia article on Hurricane
Gustav. #3 is from a New York Times article.
(2) “É and remained at that intensity until
landfall on the morning of September 1
near Cocodrie, Louisiana.”
(3) “By landfall on Monday morning É”
</listItem>
<bodyText confidence="0.9999646">
Such texts tell us how people talk about hurri-
canes, specifically here about landfall events.
They tell us what combinations of entities are
reasonable to include within single clauses
(intensity, time, location), and they tell us which
particular realizations of the landfall concept
have been used in which larger linguistic con-
texts. They also indicate what information can be
left out under the discourse conditions defined by
the larger texts they appear in.4
As different texts are read, we accumulate dif-
ferent realization forms for the same content. In
example #1, landfall is expressed via the idiom
make landfall, the time is given in an initial
adverbial, and the location as a trailing adjunct.
In #2, the landfall stands by itself as the head of a
time-adverbial and the time and location are
adjuncts off of it. This set of alternative phras-
ings provides the raw material for the microplan-
ner to work with – a natural set of paraphrases.
</bodyText>
<subsectionHeader confidence="0.99871">
3.1 Derivation Trees as templates
</subsectionHeader>
<bodyText confidence="0.998046454545454">
As shown in Figure 3, to create resources for the
microplanner, we start with the semantic analysis
that the parser anchors to its referent when it
instantiates the appropriate event type within the
prototypical model of what hurricanes do, here a
‘landfall event’, noting the specific time and
location. Following Bateman (e.g. 2007) and
Meteer (1992), we work with typed, structured
objects organized under a foundational ontol-
ogy.5 Figure 2 shows the current definition of the
landfall class in a local notation for OWL Full.
</bodyText>
<table confidence="0.9346664">
(Class HurricaneLandfall
(restrict hurricane - Hurricane)
(restrict intensity Ð Saffir-Simpson)
(restrict location Ð PhysEndurant)
(restrict time Ð Date&amp;Time))
</table>
<figureCaption confidence="0.988907">
Figure 2. The Landfall class
</figureCaption>
<figure confidence="0.531327">
4 For example, in #1 and #3 the precise date had been given
already in earlier sentences.
5 An extension of Dolce (Gangemi et al. 2002).
</figure>
<figureCaption confidence="0.996822">
Figure 3. Overview
</figureCaption>
<bodyText confidence="0.999982095238095">
The semantic analysis recursively maps con-
stituents’ referents to properties of a class in-
stance. Accompanying it is a syntactic analysis in
the form of a TAG Derivation Tree6 (DT) where
each of its nodes (initial trees, insertions or
adjunctions) points both to its lexical anchor and
its specific correspondence in the domain model.
To create a reusable resource, we abstract
away from the lexicalization in these DT/model-
anchored pairs, and replace it with the corre-
sponding model classes as determined by the
restrictions on the properties. For example, the
day of the week in #3, lexically given as Monday
morning and then dereferenced to an object with
the meaning ‘9/1/2008 before noon’ is replaced
in the resource with that object’s type.
The result is a set of templates associated with
the combination of types that corresponds to the
participants in its source text – the more com-
posed the type, the more insertions / adjunctions
in the template derivation tree.
</bodyText>
<subsectionHeader confidence="0.997068">
3.2 Synchronous TAGS
</subsectionHeader>
<bodyText confidence="0.99825325">
This combination of derived trees and model-
levels classes and properties where the nodes of
the two structures are linked is a synchronous
TAG (ST). As observed by Shieber and Schabes
(1991) who introduced this notion, “[STs] make
the fine-grained correspondences between ex-
pressions of natural language and their meanings
explicit by É node linking”.
</bodyText>
<footnote confidence="0.8206235">
6 The primary analysis is phrase structure in a chart, but
since every rule in the grammar corresponds to either a
lexicalized insertion or adjunction, the pattern of rule
application is read out as a TAG derivation tree.
</footnote>
<figureCaption confidence="0.998299">
Figure 4. Synchronous TAG
</figureCaption>
<bodyText confidence="0.999980695652174">
In particular, they observe that STs solve an
otherwise arbitrary problem of ‘where does one
start’ when faced with a bag of content to be
realized as a text. Our STs identify natural
‘slices’ of the content – those parts that have
already been observed to have been realized
together in a naturally occurring text.
Because we have the luxury to be creating the
knowledge base of our hurricane model by the
accretion of relationships among individually
small chunks of information (a triple store), we
can take synchronous TAGS a step further and
allow them to dictate the permitted ways that
information can be delimited within the KB for
purposes of generation following the ideas in
(Stone 2002).
If we can surmount the issues described be-
low, this stricture – that one can only select for
generation units of content of the types that have
been observed to be used together (the model
side of the STs) – is a clean architectural expla-
nation of how it is that the generator’s messages
are always expressible.
</bodyText>
<sectionHeader confidence="0.946859" genericHeader="method">
4. State of Development
</sectionHeader>
<bodyText confidence="0.9996525">
We are at an early stage in our work. Everything
we have described is implemented, but only on a
</bodyText>
<figure confidence="0.961049444444444">
pp(&amp;quot;by&amp;quot;)
insert: prep-comp(&amp;quot;landfall&amp;quot;)
adjoin: pp (&amp;quot;on&amp;quot;)
insert: prep-comp(&amp;quot;Monday&amp;quot;)
(Individual HurricaneLandfall new-instance
(hurricane #&lt;&gt;)
(intensity #&lt;&gt;)
(location #&lt;&gt;)
(time #&lt;DayOfWeek Monday&gt;))
</figure>
<bodyText confidence="0.999735163265306">
‘thin slice’ to establish that our ideas were credi-
ble. There are many issues to work out as we
‘bulk up’ the system and begin to actually inte-
grate it in a in ‘tactical’ microplanner and begin
to actually do the style of macro-planning (de-
termining the relevant portions of the domain
model to use as content given the intent and
affect) that our use of synchronous TAGS should
allow. The most salient issues are how broadly
we should generalize when we substitute domain
types for lexicalizations in the templates, and
what contextual information must be kept with
the templates.
The type generalizations need to be broad
enough to encompass as many substitutions as
possible, while being strict enough to ensure that
when the template is applied to those objects the
realizations available to them permit them to be
expressed in that linguistic context.7
The examples all have specific contexts in the
sentences and recent discourse. Two of them (#2,
#3) are using the landfall event as a time phrase.
Can we move them and still retain the natural-
ness of the original (e.g. from sentence initial to
sentence final), or does this sort of information
need to be encoded?
Another issue is how to evaluate a system like
this. Given the accuracy of the analysis, recreat-
ing the source text is trivial, so comparison to the
source of the resources as a gold standard is
meaningless. Some alternative must be found.
While we work out these issues, we are ex-
tending the NLU domain model and grammar to
cover more cases and thence create more syn-
chronized TAG templates. We then manually
identify alternative domain content to app hly to
them to in order to explore the space of realiza-
tions and identify unforeseen interactions.
Our short-term goals are to vastly increase the
grammar coverage for our motivating examples
and to hand over all microplanning decisions to
the system itself. Long-term goals include broad-
ening the coverage further still, to as open a
domain as is feasible, as well as testing different
macroplanners and applications with which to
drive the entire process. Among several possi-
bilities are automatic merged-and-modified
summarization and a query-based discourse
system.
</bodyText>
<footnote confidence="0.751737833333333">
7 In our example, substituting different days and times is
obvious (by landfall on the afternoon of August 22), but as
we move away from that precise set of types (general-time-
of-day + date) we see that what had been lexically fixed in
the derivation tree (by landfall on) has to shift: É at 2:00 on
August 22.
</footnote>
<sectionHeader confidence="0.991499" genericHeader="conclusions">
5. Discussion
</sectionHeader>
<bodyText confidence="0.999874285714286">
Because the phrasal patterns observed in the
corpus act as templates guiding the generation
process, and as the underlying NLU system and
generator (McDonald 1993, Meteer et al. 1987)
are mature and grounded in linguistic principles,
our system combines template-based and theory-
based approaches.
</bodyText>
<listItem confidence="0.9222336">
Van Deemter et al. (2005) outlined three crite-
ria for judging template-driven applications
against &amp;quot;standard&amp;quot; (non-template) NLG systems.
(1) Maintainability is addressed by the fact that
our templates aren&apos;t hand-made. To extend the
set of available realization forms we expose the
NLU system to more text. The subject domain
has to be one that has already been modeled, but
we are operating from the premise that a NLG
component would only bother to speak about
things that the system as a whole understands.
(2) Output quality and variability are determined
by the corpus; using corpora containing high
quality and varied constructions will enable
similar output from the generator. (3) Most
</listItem>
<bodyText confidence="0.988622192307693">
crucially, our parser and generator components
are linguistically well-founded. Composition into
our ‘templates’ is smoothly accommodated
(extra modifiers, shifts in tense or aspect, appli-
cation of transformations over the DT to form
questions, relative clauses, dropped constituents
under conjunction). The fully-articulated syntac-
tic structure can be automatically annotated to
facilitate prosody or to take information structure
markup on the DT.
The closest system to ours may be Marciniak
&amp; Strube (2005) who also use an annotated
corpus as a knowledge source for generation,
getting their annotations via “a simple rule-based
system tuned to the given types of text”. As far
as we can tell, they are more concerned with
discourse while we focus on the integration with
the underlying knowledge base and how that KB
is extended over time.
Like them, we believe that one of the most
promising aspects of this work going forward is
that the use of a parser provides us with “self-
labeling data” to draw on for statistical analysis.
Such training material would reduce the effort
required to adapt a generator to a new domain,
while simultaneously improving its output.
</bodyText>
<sectionHeader confidence="0.998362" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.978664666666667">
This work was supported in part by the BBN
POIROT project: DARPA IPTO contract FA865
0-06-C-7606.
</bodyText>
<sectionHeader confidence="0.995681" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999559333333334">
John Bateman, Thora Tenbrink, and Scott Farrar.
2007. The Role of Conceptual and Linguistic On-
tologies in Interpreting Spatial Discourse. Dis-
course Processes, 44(3):175–213.
Tilman Becker. 2006. Natural Language Generation
with Fully Specified Templates. In W. Wahlster
(Ed.), SmartKom: Foundations of Multimodal Dia-
log Systems, 401–410. Springer, Berlin Heidelberg.
Lynne Cahill, Christy Doran, Roger Evans, Chris
Mellish, Daniel Paiva, Mike Reape, Donia Scott, &amp;
Neil Tipper. 1999. Towards a Reference Architec-
ture for Natural Language Generation Systems,
The RAGS project. ITRI technical report number
ITRI-99-14, University of Brighton, March.
Aldo Gangemi, Nicola Guarino, Claudio Masolo,
Alessandro Oltramari, &amp; Luc Schneider. 2002.
Sweetening Ontologies with DOLCE. In Proceed-
ings of the 13th International Conference on
Knowledge Acquisition, Modeling and Manage-
ment (EKAW), pages 166–181, SigŸenza, Spain,
October 1–4.
Tomasz Marciniak &amp; Michael Strube. 2005. Using an
Annotated Corpus As a Knowledge Source For
Language Generation. In Proceedings of the Cor-
pus Linguistics 2005 Workshop on Using Corpora
for Natural Language Generation (UCNLG), pages
19–24, Birmingham, UK, July 14.
David McDonald. 2003. The Interplay of Syntactic
and Semantic Node Labels in Partial Parsing, in the
proceedings of the Third International Workshop
on Parsing Technologies, August 10-13, 1993 Til-
burg, The Netherlands, pp. 171-186; revised ver-
sion in Bunt and Tomita (eds), Recent Advances in
Parsing Technology, Kluwer Academic Publishers,
pgs. 295-323.
Marie W. Meteer. 1992. Expressibility and the Prob-
lem of Efficient Text Planning. Pinter, London.
Marie Meteer, David McDonald, Scott Anderson,
David Forster, Linda Gay, Alison Huettner &amp;
Penelope Sibun. 1987. Mumble-86: Design and
Implementation, TR #87-87 Dept. Computer &amp;
Information Science, UMass., September 1987,
174 pgs.
James Shaw. 1998. Clause Aggregation Using Lin-
guistic Knowledge. In Proceedings of the 9th In-
ternational Workshop on Natural Language Gen-
eration, pages 138–147, Niagara-on-the-Lake, On-
tario, August 5–7.
Stuart Shieber &amp; Yves Schabes. 1991. Generation and
synchronous tree-adjoining grammar. Computa-
tional Intelligence, 7(4):220–228.
Matthew Stone. 2003. Specifying Generation of
Referring Expressions by Example. In Proceedings
of the AAAI Spring Symposium on Natural Lan-
guage Generation in Spoken and Written Dialogue,
pages 133–140, Stanford, March.
Kees van Deemter, Emiel Krahmer, &amp; Mari‘t Theune.
2005. Real versus Template-Based Natural Lan-
guage Generation: A False Opposition? Computa-
tional Linguistics, 31(1):15–24.
Huvava Zhong &amp; Amada Stent. 2005. Building
Surface Realizers Automatically From Corpora. In
Proceedings of the Corpus Linguistics 2005 Work-
shop on Using Corpora for Natural Language
Generation (UCNLG), pages 49–54, Birmingham,
UK, July 14.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.106628">
<title confidence="0.999013">If you’ve heard it, you can say it’ - Towards an Account of Expressibility</title>
<author confidence="0.999994">David D McDonald Charles F Greenbacker</author>
<affiliation confidence="0.995396">Raytheon BBN Technologies University of Delaware</affiliation>
<address confidence="0.999474">Cambridge, MA USA Newark, DE, USA</address>
<email confidence="0.999663">dmcdonald@bbn.comcharlieg@cis.udel.edu</email>
<abstract confidence="0.999291435158502">We have begun a project to automatically create the lexico-syntactic resources for a microplanner as a side-effect of running a domain-specific language understanding system. The resources are parameterized synchronous TAG Derivation Trees. Since the KB is assembled from the information in the texts that these resources are abstracted from, it will decompose along those same lines when used for generation. As all possible ways of expressing each concept are pre-organized into general patterns known to be linguistically-valid (they were observed in natural text), we obtain an architectural account for expressibility. 1. Expressibility People speak grammatically. They may stutter, restart, or make the occasional speech error, but all in all they are faithful to the grammar of the language dialects they use. One of the ways that a language generation system can account for this is through the use of grammar that defines all of the possible lexico-syntactic elements from which a text can be constructed and defines all their rules of composition, such as lexicalized Tree Adjoining Grammar (TAG). Without the ability to even formulate an ungrammatical text, such a generator provides an account for human grammaticality based on its architecture rather than its programmer. We propose a similar kind of accounting for the problem of expressibility: one based on rather than accident. as defined by Meteer (1992), is an issue for microplanners as they decide on which lexical and syntactic resources to employ. Not all of the options they might want to use are available in the language – they are not expressible. Consider the examples in Figure 1, adapted from Meteer 1992 pg. 50. Expression Construction (‘decide’) &lt;result&gt; + &lt;quick&gt; &lt;action&gt; + &lt;quick&gt; &lt;result&gt; + &lt;action&gt; + &lt;important&gt; Figure 1: Constraints on expressibility: To say that there was a decision and it was important, you are forced to use the noun form because is no adverbial form for is for In this short paper, we discuss our approach to expressibility. We describe in detail our novel method centered on how to use parser observations to guide generator decisions, and we provide a snapshot of the current status of our system implementation. 2. Related Work Natural language generation (NLG) systems must have some way of making sure that the messages they build are actually expressible. Template-based generators avoid problems with expressibility largely by anticipating all of the wording that will be needed and packaging it in chunks that are guaranteed to compose correctly. Becker (2006), for example, does this via fully lexicalized TAG trees. Among more general-purpose generators, one approach to expressibility is to look ahead into the lexicon, avoiding constructions that are lexically incompatible. Look-ahead is expensive, however, and is only practical at small abstraction distances such as Shaw’s re-writing sentence planner (1998). Meteer’s own approach to expressibility started by interposing another level of representation between the microplanner and the surface realizer, an ‘abstract syntactic representation’ in the sense of RAGS (Cahill et al. 1999), that employed functional relationships (head, argument, matrix, adjunct) over semantically typed, constituents. This blocks ‘important’ only has a realization as a property and her composition rules prohibit using a property to modify an action (‘decide’). Shifting the perspective from the action to its result allows the composition to go through. We are in sympathy with this approach – a microplanner needs its own representational level to serve as a scratch pad (if using a revision-based approach) or just as a scaffold to hold intermediate results. However, Meteer’s semantic and lexical constraints do require operating with fine-grain details. We believe that we can work with larger chunks that have already been vetted for expressibility because we’ve observed someone use them, either in writing or speech. 3. Method Our approach is similar to that of Zhong &amp; Stent (2005) in that we use the analysis of a corpus as the basis for creating the resources for the realization component. Several differences stand out. For one, we are working in specific domains rather than generic corpora like the WSJ. This enables the biggest difference: our analysis is by a completely domain- NLU system based on a semantic grammar (McDonald 1993). It is reading for the benefit of a knowledge base, adding specific facts within instances of a highly structured, predefined prototypes. Such instances are used as the starting point for the generation process. On the KB side, our present focus happens to be on hurricanes and the process they go through as they evolve. We have developed a semantic grammar for this domain, and it lets us analyze like that day it made landfall near Haitian town of accuracy and correct word sense interpretation is only possible if the semantic domain under analysis is restricted by topic and sublanguage. systems referred to as “parsers” stop at a structural description. Ours stops at the level of a disambiguated conceptual model and is more integrated than most. and 2 are from the Wikipedia article on Hurricane Gustav. #3 is from a New York Times article. (2) and remained at that intensity until landfall on the morning of September 1 Cocodrie, (3) landfall on Monday morning Such texts tell us how people talk about hurricanes, specifically here about landfall events. They tell us what combinations of entities are reasonable to include within single clauses (intensity, time, location), and they tell us which particular realizations of the landfall concept have been used in which larger linguistic contexts. They also indicate what information can be left out under the discourse conditions defined by larger texts they appear As different texts are read, we accumulate different realization forms for the same content. In example #1, landfall is expressed via the idiom the time is given in an initial adverbial, and the location as a trailing adjunct. In #2, the landfall stands by itself as the head of a time-adverbial and the time and location are adjuncts off of it. This set of alternative phrasings provides the raw material for the microplanner to work with – a natural set of paraphrases. 3.1 Derivation Trees as templates As shown in Figure 3, to create resources for the microplanner, we start with the semantic analysis that the parser anchors to its referent when it instantiates the appropriate event type within the prototypical model of what hurricanes do, here a ‘landfall event’, noting the specific time and location. Following Bateman (e.g. 2007) and Meteer (1992), we work with typed, structured objects organized under a foundational ontol- Figure 2 shows the current definition of the landfall class in a local notation for OWL Full. (Class HurricaneLandfall (restrict hurricane - Hurricane) (restrict intensity Ð Saffir-Simpson) (restrict location Ð PhysEndurant) (restrict time Ð Date&amp;Time)) Figure 2. The Landfall class example, in #1 and #3 the precise date had been given already in earlier sentences. extension of Dolce (Gangemi et al. 2002). Figure 3. Overview The semantic analysis recursively maps constituents’ referents to properties of a class instance. Accompanying it is a syntactic analysis in form of a TAG Derivation (DT) where each of its nodes (initial trees, insertions or adjunctions) points both to its lexical anchor and its specific correspondence in the domain model. To create a reusable resource, we abstract away from the lexicalization in these DT/modelanchored pairs, and replace it with the corresponding model classes as determined by the restrictions on the properties. For example, the of the week in #3, lexically given as then dereferenced to an object with the meaning ‘9/1/2008 before noon’ is replaced in the resource with that object’s type. The result is a set of templates associated with the combination of types that corresponds to the participants in its source text – the more composed the type, the more insertions / adjunctions in the template derivation tree. 3.2 Synchronous TAGS This combination of derived trees and modellevels classes and properties where the nodes of two structures are linked is a As observed by Shieber and Schabes (1991) who introduced this notion, “[STs] make the fine-grained correspondences between expressions of natural language and their meanings explicit by É node linking”. primary analysis is phrase structure in a chart, but since every rule in the grammar corresponds to either a lexicalized insertion or adjunction, the pattern of rule application is read out as a TAG derivation tree. Figure 4. Synchronous TAG In particular, they observe that STs solve an otherwise arbitrary problem of ‘where does one start’ when faced with a bag of content to be realized as a text. Our STs identify natural ‘slices’ of the content – those parts that have already been observed to have been realized together in a naturally occurring text. Because we have the luxury to be creating the knowledge base of our hurricane model by the accretion of relationships among individually small chunks of information (a triple store), we can take synchronous TAGS a step further and allow them to dictate the permitted ways that information can be delimited within the KB for purposes of generation following the ideas in (Stone 2002). If we can surmount the issues described below, this stricture – that one can only select for generation units of content of the types that have been observed to be used together (the model side of the STs) – is a clean architectural explanation of how it is that the generator’s messages are always expressible. 4. State of Development We are at an early stage in our work. Everything we have described is implemented, but only on a pp(&amp;quot;by&amp;quot;) insert: prep-comp(&amp;quot;landfall&amp;quot;) adjoin: pp (&amp;quot;on&amp;quot;) insert: prep-comp(&amp;quot;Monday&amp;quot;) (Individual HurricaneLandfall new-instance (hurricane #&lt;&gt;) (intensity #&lt;&gt;) (location #&lt;&gt;) (time #&lt;DayOfWeek Monday&gt;)) ‘thin slice’ to establish that our ideas were credible. There are many issues to work out as we ‘bulk up’ the system and begin to actually integrate it in a in ‘tactical’ microplanner and begin to actually do the style of macro-planning (determining the relevant portions of the domain model to use as content given the intent and affect) that our use of synchronous TAGS should allow. The most salient issues are how broadly we should generalize when we substitute domain types for lexicalizations in the templates, and what contextual information must be kept with the templates. The type generalizations need to be broad enough to encompass as many substitutions as possible, while being strict enough to ensure that when the template is applied to those objects the realizations available to them permit them to be in that linguistic The examples all have specific contexts in the sentences and recent discourse. Two of them (#2, Can we move them and still retain the naturalness of the original (e.g. from sentence initial to sentence final), or does this sort of information need to be encoded? Another issue is how to evaluate a system like this. Given the accuracy of the analysis, recreating the source text is trivial, so comparison to the source of the resources as a gold standard is meaningless. Some alternative must be found. While we work out these issues, we are extending the NLU domain model and grammar to cover more cases and thence create more synchronized TAG templates. We then manually identify alternative domain content to app hly to them to in order to explore the space of realizations and identify unforeseen interactions. Our short-term goals are to vastly increase the grammar coverage for our motivating examples and to hand over all microplanning decisions to the system itself. Long-term goals include broadening the coverage further still, to as open a domain as is feasible, as well as testing different macroplanners and applications with which to drive the entire process. Among several possibilities are automatic merged-and-modified summarization and a query-based discourse system. our example, substituting different days and times is landfall on the afternoon of August but as we move away from that precise set of types (general-timeof-day + date) we see that what had been lexically fixed in derivation tree landfall has to shift: on August 22. 5. Discussion Because the phrasal patterns observed in the corpus act as templates guiding the generation process, and as the underlying NLU system and generator (McDonald 1993, Meteer et al. 1987) are mature and grounded in linguistic principles, our system combines template-based and theorybased approaches. Van Deemter et al. (2005) outlined three criteria for judging template-driven applications against &amp;quot;standard&amp;quot; (non-template) NLG systems. Maintainability addressed by the fact that our templates aren&apos;t hand-made. To extend the set of available realization forms we expose the NLU system to more text. The subject domain has to be one that has already been modeled, but we are operating from the premise that a NLG component would only bother to speak about things that the system as a whole understands. Output quality and are determined by the corpus; using corpora containing high quality and varied constructions will enable similar output from the generator. (3) Most crucially, our parser and generator components linguistically Composition into our ‘templates’ is smoothly accommodated (extra modifiers, shifts in tense or aspect, application of transformations over the DT to form questions, relative clauses, dropped constituents under conjunction). The fully-articulated syntactic structure can be automatically annotated to facilitate prosody or to take information structure markup on the DT. The closest system to ours may be Marciniak &amp; Strube (2005) who also use an annotated corpus as a knowledge source for generation, getting their annotations via “a simple rule-based system tuned to the given types of text”. As far as we can tell, they are more concerned with discourse while we focus on the integration with the underlying knowledge base and how that KB is extended over time. Like them, we believe that one of the most promising aspects of this work going forward is that the use of a parser provides us with “selflabeling data” to draw on for statistical analysis. Such training material would reduce the effort required to adapt a generator to a new domain, while simultaneously improving its output.</abstract>
<note confidence="0.941004785714285">Acknowledgments This work was supported in part by the BBN POIROT project: DARPA IPTO contract FA865 References John Bateman, Thora Tenbrink, and Scott Farrar. 2007. The Role of Conceptual and Linguistic Onin Interpreting Spatial Discourse. Dis- 44(3):175–213. Tilman Becker. 2006. Natural Language Generation with Fully Specified Templates. In W. Wahlster Foundations of Multimodal Dia- 401–410. Springer, Berlin Heidelberg. Lynne Cahill, Christy Doran, Roger Evans, Chris Mellish, Daniel Paiva, Mike Reape, Donia Scott, &amp; Tipper. 1999. a Reference Architecture for Natural Language Generation Systems, RAGS ITRI technical report number ITRI-99-14, University of Brighton, March. Aldo Gangemi, Nicola Guarino, Claudio Masolo, Alessandro Oltramari, &amp; Luc Schneider. 2002. Ontologies with DOLCE. In Proceedings of the 13th International Conference on Knowledge Acquisition, Modeling and Managepages 166–181, SigŸenza, Spain, October 1–4. Tomasz Marciniak &amp; Michael Strube. 2005. Using an Annotated Corpus As a Knowledge Source For Generation. In of the Corpus Linguistics 2005 Workshop on Using Corpora Natural Language Generation pages 19–24, Birmingham, UK, July 14. David McDonald. 2003. The Interplay of Syntactic and Semantic Node Labels in Partial Parsing, in the proceedings of the Third International Workshop on Parsing Technologies, August 10-13, 1993 Tilburg, The Netherlands, pp. 171-186; revised version in Bunt and Tomita (eds), Recent Advances in Parsing Technology, Kluwer Academic Publishers, pgs. 295-323. W. Meteer. 1992. and the Probof Efficient Text Pinter, London. Marie Meteer, David McDonald, Scott Anderson, David Forster, Linda Gay, Alison Huettner &amp; Penelope Sibun. 1987. Mumble-86: Design and Implementation, TR #87-87 Dept. Computer &amp; Information Science, UMass., September 1987, 174 pgs. James Shaw. 1998. Clause Aggregation Using Lin- Knowledge. In of the 9th International Workshop on Natural Language Genpages 138–147, Niagara-on-the-Lake, Ontario, August 5–7. Stuart Shieber &amp; Yves Schabes. 1991. Generation and tree-adjoining grammar. Computa- 7(4):220–228. Matthew Stone. 2003. Specifying Generation of Expressions by Example. In of the AAAI Spring Symposium on Natural Lan- Generation in Spoken and Written pages 133–140, Stanford, March. Kees van Deemter, Emiel Krahmer, &amp; Mari‘t Theune. 2005. Real versus Template-Based Natural Lan- Generation: A False Opposition? Computa- 31(1):15–24. Huvava Zhong &amp; Amada Stent. 2005. Building Surface Realizers Automatically From Corpora. In Proceedings of the Corpus Linguistics 2005 Workshop on Using Corpora for Natural Language pages 49–54, Birmingham, UK, July 14.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Bateman</author>
<author>Thora Tenbrink</author>
<author>Scott Farrar</author>
</authors>
<date>2007</date>
<booktitle>The Role of Conceptual and Linguistic Ontologies in Interpreting Spatial Discourse. Discourse Processes,</booktitle>
<volume>44</volume>
<issue>3</issue>
<marker>Bateman, Tenbrink, Farrar, 2007</marker>
<rawString>John Bateman, Thora Tenbrink, and Scott Farrar. 2007. The Role of Conceptual and Linguistic Ontologies in Interpreting Spatial Discourse. Discourse Processes, 44(3):175–213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tilman Becker</author>
</authors>
<title>Natural Language Generation with Fully Specified Templates.</title>
<date>2006</date>
<booktitle>In W. Wahlster (Ed.), SmartKom: Foundations of Multimodal Dialog Systems,</booktitle>
<pages>401--410</pages>
<publisher>Springer,</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="2978" citStr="Becker (2006)" startWordPosition="463" endWordPosition="464">quick In this short paper, we discuss our approach to expressibility. We describe in detail our novel method centered on how to use parser observations to guide generator decisions, and we provide a snapshot of the current status of our system implementation. 2. Related Work Natural language generation (NLG) systems must have some way of making sure that the messages they build are actually expressible. Template-based generators avoid problems with expressibility largely by anticipating all of the wording that will be needed and packaging it in chunks that are guaranteed to compose correctly. Becker (2006), for example, does this via fully lexicalized TAG trees. Among more general-purpose generators, one approach to expressibility is to look ahead into the lexicon, avoiding constructions that are lexically incompatible. Look-ahead is expensive, however, and is only practical at small abstraction distances such as Shaw’s re-writing sentence planner (1998). Meteer’s own approach to expressibility started by interposing another level of representation between the microplanner and the surface realizer, an ‘abstract syntactic representation’ in the sense of RAGS (Cahill et al. 1999), that employed f</context>
</contexts>
<marker>Becker, 2006</marker>
<rawString>Tilman Becker. 2006. Natural Language Generation with Fully Specified Templates. In W. Wahlster (Ed.), SmartKom: Foundations of Multimodal Dialog Systems, 401–410. Springer, Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynne Cahill</author>
<author>Christy Doran</author>
<author>Roger Evans</author>
<author>Chris Mellish</author>
<author>Daniel Paiva</author>
<author>Mike Reape</author>
<author>Donia Scott</author>
<author>Neil Tipper</author>
</authors>
<title>Towards a Reference Architecture for Natural Language Generation Systems, The RAGS project. ITRI technical report number ITRI-99-14,</title>
<date>1999</date>
<institution>University of Brighton,</institution>
<contexts>
<context position="3561" citStr="Cahill et al. 1999" startWordPosition="544" endWordPosition="547"> to compose correctly. Becker (2006), for example, does this via fully lexicalized TAG trees. Among more general-purpose generators, one approach to expressibility is to look ahead into the lexicon, avoiding constructions that are lexically incompatible. Look-ahead is expensive, however, and is only practical at small abstraction distances such as Shaw’s re-writing sentence planner (1998). Meteer’s own approach to expressibility started by interposing another level of representation between the microplanner and the surface realizer, an ‘abstract syntactic representation’ in the sense of RAGS (Cahill et al. 1999), that employed functional relationships (head, argument, matrix, adjunct) over semantically typed, lexicalized constituents. This blocks *decide importantly because ‘important’ only has a realization as a property and her composition rules prohibit using a property to modify an action (‘decide’). Shifting the perspective from the action to its result allows the composition to go through. We are in sympathy with this approach – a microplanner needs its own representational level to serve as a scratch pad (if using a revision-based approach) or just as a scaffold to hold intermediate results. H</context>
</contexts>
<marker>Cahill, Doran, Evans, Mellish, Paiva, Reape, Scott, Tipper, 1999</marker>
<rawString>Lynne Cahill, Christy Doran, Roger Evans, Chris Mellish, Daniel Paiva, Mike Reape, Donia Scott, &amp; Neil Tipper. 1999. Towards a Reference Architecture for Natural Language Generation Systems, The RAGS project. ITRI technical report number ITRI-99-14, University of Brighton, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aldo Gangemi</author>
<author>Nicola Guarino</author>
<author>Claudio Masolo</author>
<author>Alessandro Oltramari</author>
<author>Luc Schneider</author>
</authors>
<title>Sweetening Ontologies with DOLCE.</title>
<date>2002</date>
<booktitle>In Proceedings of the 13th International Conference on Knowledge Acquisition, Modeling and Management (EKAW),</booktitle>
<pages>166--181</pages>
<location>SigŸenza, Spain,</location>
<contexts>
<context position="7783" citStr="Gangemi et al. 2002" startWordPosition="1234" endWordPosition="1237">nes do, here a ‘landfall event’, noting the specific time and location. Following Bateman (e.g. 2007) and Meteer (1992), we work with typed, structured objects organized under a foundational ontology.5 Figure 2 shows the current definition of the landfall class in a local notation for OWL Full. (Class HurricaneLandfall (restrict hurricane - Hurricane) (restrict intensity Ð Saffir-Simpson) (restrict location Ð PhysEndurant) (restrict time Ð Date&amp;Time)) Figure 2. The Landfall class 4 For example, in #1 and #3 the precise date had been given already in earlier sentences. 5 An extension of Dolce (Gangemi et al. 2002). Figure 3. Overview The semantic analysis recursively maps constituents’ referents to properties of a class instance. Accompanying it is a syntactic analysis in the form of a TAG Derivation Tree6 (DT) where each of its nodes (initial trees, insertions or adjunctions) points both to its lexical anchor and its specific correspondence in the domain model. To create a reusable resource, we abstract away from the lexicalization in these DT/modelanchored pairs, and replace it with the corresponding model classes as determined by the restrictions on the properties. For example, the day of the week i</context>
</contexts>
<marker>Gangemi, Guarino, Masolo, Oltramari, Schneider, 2002</marker>
<rawString>Aldo Gangemi, Nicola Guarino, Claudio Masolo, Alessandro Oltramari, &amp; Luc Schneider. 2002. Sweetening Ontologies with DOLCE. In Proceedings of the 13th International Conference on Knowledge Acquisition, Modeling and Management (EKAW), pages 166–181, SigŸenza, Spain, October 1–4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomasz Marciniak</author>
<author>Michael Strube</author>
</authors>
<title>Using an Annotated Corpus As a Knowledge Source For Language Generation.</title>
<date>2005</date>
<booktitle>In Proceedings of the Corpus Linguistics 2005 Workshop on Using Corpora for Natural Language Generation (UCNLG),</booktitle>
<pages>pages</pages>
<location>Birmingham, UK,</location>
<contexts>
<context position="14756" citStr="Marciniak &amp; Strube (2005)" startWordPosition="2367" endWordPosition="2370">ng corpora containing high quality and varied constructions will enable similar output from the generator. (3) Most crucially, our parser and generator components are linguistically well-founded. Composition into our ‘templates’ is smoothly accommodated (extra modifiers, shifts in tense or aspect, application of transformations over the DT to form questions, relative clauses, dropped constituents under conjunction). The fully-articulated syntactic structure can be automatically annotated to facilitate prosody or to take information structure markup on the DT. The closest system to ours may be Marciniak &amp; Strube (2005) who also use an annotated corpus as a knowledge source for generation, getting their annotations via “a simple rule-based system tuned to the given types of text”. As far as we can tell, they are more concerned with discourse while we focus on the integration with the underlying knowledge base and how that KB is extended over time. Like them, we believe that one of the most promising aspects of this work going forward is that the use of a parser provides us with “selflabeling data” to draw on for statistical analysis. Such training material would reduce the effort required to adapt a generato</context>
</contexts>
<marker>Marciniak, Strube, 2005</marker>
<rawString>Tomasz Marciniak &amp; Michael Strube. 2005. Using an Annotated Corpus As a Knowledge Source For Language Generation. In Proceedings of the Corpus Linguistics 2005 Workshop on Using Corpora for Natural Language Generation (UCNLG), pages 19–24, Birmingham, UK, July 14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McDonald</author>
</authors>
<title>The Interplay of Syntactic and Semantic Node Labels in Partial Parsing,</title>
<date>2003</date>
<booktitle>in the proceedings of the Third International Workshop on Parsing Technologies,</booktitle>
<pages>171--186</pages>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Tilburg, The</location>
<marker>McDonald, 2003</marker>
<rawString>David McDonald. 2003. The Interplay of Syntactic and Semantic Node Labels in Partial Parsing, in the proceedings of the Third International Workshop on Parsing Technologies, August 10-13, 1993 Tilburg, The Netherlands, pp. 171-186; revised version in Bunt and Tomita (eds), Recent Advances in Parsing Technology, Kluwer Academic Publishers, pgs. 295-323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie W Meteer</author>
</authors>
<title>Expressibility and the Problem of Efficient Text Planning.</title>
<date>1992</date>
<location>Pinter, London.</location>
<contexts>
<context position="1700" citStr="Meteer (1992)" startWordPosition="258" endWordPosition="259">a language generation system can account for this is through the use of grammar that defines all of the possible lexico-syntactic elements from which a text can be constructed and defines all their rules of composition, such as lexicalized Tree Adjoining Grammar (TAG). Without the ability to even formulate an ungrammatical text, such a generator provides an account for human grammaticality based on its architecture rather than its programmer. We propose a similar kind of accounting for the problem of expressibility: one based on architecture rather than accident. Expressibility, as defined by Meteer (1992), is an issue for microplanners as they decide on which lexical and syntactic resources to employ. Not all of the options they might want to use are available in the language – they are not expressible. Consider the examples in Figure 1, adapted from Meteer 1992 pg. 50. Expression Construction (‘decide’) “quick decision” &lt;result&gt; + &lt;quick&gt; “decide quickly” &lt;action&gt; + &lt;quick&gt; “important decision” &lt;result&gt; + &lt;important&gt; * “decide importantly” &lt;action&gt; + &lt;important&gt; Figure 1: Constraints on expressibility: To say that there was a decision and it was important, you are forced to use the noun form </context>
<context position="7282" citStr="Meteer (1992)" startWordPosition="1158" endWordPosition="1159">l stands by itself as the head of a time-adverbial and the time and location are adjuncts off of it. This set of alternative phrasings provides the raw material for the microplanner to work with – a natural set of paraphrases. 3.1 Derivation Trees as templates As shown in Figure 3, to create resources for the microplanner, we start with the semantic analysis that the parser anchors to its referent when it instantiates the appropriate event type within the prototypical model of what hurricanes do, here a ‘landfall event’, noting the specific time and location. Following Bateman (e.g. 2007) and Meteer (1992), we work with typed, structured objects organized under a foundational ontology.5 Figure 2 shows the current definition of the landfall class in a local notation for OWL Full. (Class HurricaneLandfall (restrict hurricane - Hurricane) (restrict intensity Ð Saffir-Simpson) (restrict location Ð PhysEndurant) (restrict time Ð Date&amp;Time)) Figure 2. The Landfall class 4 For example, in #1 and #3 the precise date had been given already in earlier sentences. 5 An extension of Dolce (Gangemi et al. 2002). Figure 3. Overview The semantic analysis recursively maps constituents’ referents to properties o</context>
</contexts>
<marker>Meteer, 1992</marker>
<rawString>Marie W. Meteer. 1992. Expressibility and the Problem of Efficient Text Planning. Pinter, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Meteer</author>
<author>David McDonald</author>
<author>Scott Anderson</author>
<author>David Forster</author>
<author>Linda Gay</author>
</authors>
<title>Alison Huettner &amp; Penelope Sibun.</title>
<date>1987</date>
<booktitle>Mumble-86: Design and Implementation, TR #87-87 Dept. Computer &amp; Information Science,</booktitle>
<pages>174</pages>
<location>UMass.,</location>
<contexts>
<context position="13438" citStr="Meteer et al. 1987" startWordPosition="2171" endWordPosition="2174">mong several possibilities are automatic merged-and-modified summarization and a query-based discourse system. 7 In our example, substituting different days and times is obvious (by landfall on the afternoon of August 22), but as we move away from that precise set of types (general-timeof-day + date) we see that what had been lexically fixed in the derivation tree (by landfall on) has to shift: É at 2:00 on August 22. 5. Discussion Because the phrasal patterns observed in the corpus act as templates guiding the generation process, and as the underlying NLU system and generator (McDonald 1993, Meteer et al. 1987) are mature and grounded in linguistic principles, our system combines template-based and theorybased approaches. Van Deemter et al. (2005) outlined three criteria for judging template-driven applications against &amp;quot;standard&amp;quot; (non-template) NLG systems. (1) Maintainability is addressed by the fact that our templates aren&apos;t hand-made. To extend the set of available realization forms we expose the NLU system to more text. The subject domain has to be one that has already been modeled, but we are operating from the premise that a NLG component would only bother to speak about things that the system</context>
</contexts>
<marker>Meteer, McDonald, Anderson, Forster, Gay, 1987</marker>
<rawString>Marie Meteer, David McDonald, Scott Anderson, David Forster, Linda Gay, Alison Huettner &amp; Penelope Sibun. 1987. Mumble-86: Design and Implementation, TR #87-87 Dept. Computer &amp; Information Science, UMass., September 1987, 174 pgs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shaw</author>
</authors>
<title>Clause Aggregation Using Linguistic Knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 9th International Workshop on Natural Language Generation,</booktitle>
<pages>138--147</pages>
<location>Niagara-on-the-Lake, Ontario,</location>
<marker>Shaw, 1998</marker>
<rawString>James Shaw. 1998. Clause Aggregation Using Linguistic Knowledge. In Proceedings of the 9th International Workshop on Natural Language Generation, pages 138–147, Niagara-on-the-Lake, Ontario, August 5–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
<author>Yves Schabes</author>
</authors>
<title>Generation and synchronous tree-adjoining grammar.</title>
<date>1991</date>
<journal>Computational Intelligence,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="8989" citStr="Shieber and Schabes (1991)" startWordPosition="1433" endWordPosition="1436">he day of the week in #3, lexically given as Monday morning and then dereferenced to an object with the meaning ‘9/1/2008 before noon’ is replaced in the resource with that object’s type. The result is a set of templates associated with the combination of types that corresponds to the participants in its source text – the more composed the type, the more insertions / adjunctions in the template derivation tree. 3.2 Synchronous TAGS This combination of derived trees and modellevels classes and properties where the nodes of the two structures are linked is a synchronous TAG (ST). As observed by Shieber and Schabes (1991) who introduced this notion, “[STs] make the fine-grained correspondences between expressions of natural language and their meanings explicit by É node linking”. 6 The primary analysis is phrase structure in a chart, but since every rule in the grammar corresponds to either a lexicalized insertion or adjunction, the pattern of rule application is read out as a TAG derivation tree. Figure 4. Synchronous TAG In particular, they observe that STs solve an otherwise arbitrary problem of ‘where does one start’ when faced with a bag of content to be realized as a text. Our STs identify natural ‘slice</context>
</contexts>
<marker>Shieber, Schabes, 1991</marker>
<rawString>Stuart Shieber &amp; Yves Schabes. 1991. Generation and synchronous tree-adjoining grammar. Computational Intelligence, 7(4):220–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Stone</author>
</authors>
<title>Specifying Generation of Referring Expressions by Example.</title>
<date>2003</date>
<booktitle>In Proceedings of the AAAI Spring Symposium on Natural Language Generation in Spoken and Written Dialogue,</booktitle>
<pages>133--140</pages>
<location>Stanford,</location>
<marker>Stone, 2003</marker>
<rawString>Matthew Stone. 2003. Specifying Generation of Referring Expressions by Example. In Proceedings of the AAAI Spring Symposium on Natural Language Generation in Spoken and Written Dialogue, pages 133–140, Stanford, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
<author>Emiel Krahmer</author>
<author>Mari‘t Theune</author>
</authors>
<title>Real versus Template-Based Natural Language Generation: A False Opposition?</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<marker>van Deemter, Krahmer, Theune, 2005</marker>
<rawString>Kees van Deemter, Emiel Krahmer, &amp; Mari‘t Theune. 2005. Real versus Template-Based Natural Language Generation: A False Opposition? Computational Linguistics, 31(1):15–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huvava Zhong</author>
<author>Amada Stent</author>
</authors>
<title>Building Surface Realizers Automatically From Corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of the Corpus Linguistics 2005 Workshop on Using Corpora for Natural Language Generation (UCNLG),</booktitle>
<pages>49--54</pages>
<location>Birmingham, UK,</location>
<contexts>
<context position="4488" citStr="Zhong &amp; Stent (2005)" startWordPosition="688" endWordPosition="691"> the perspective from the action to its result allows the composition to go through. We are in sympathy with this approach – a microplanner needs its own representational level to serve as a scratch pad (if using a revision-based approach) or just as a scaffold to hold intermediate results. However, Meteer’s semantic and lexical constraints do require operating with fine-grain details. We believe that we can work with larger chunks that have already been vetted for expressibility because we’ve observed someone use them, either in writing or speech. 3. Method Our approach is similar to that of Zhong &amp; Stent (2005) in that we use the analysis of a corpus as the basis for creating the resources for the realization component. Several differences stand out. For one, we are working in specific domains rather than generic corpora like the WSJ. This enables the biggest difference: our analysis is performed by a completely accurate,1 domainspecific NLU system (‘parser’)2 based on a semantic grammar (McDonald 1993). It is reading for the benefit of a knowledge base, adding specific facts within instances of a highly structured, predefined prototypes. Such instances are used as the starting point for the generat</context>
</contexts>
<marker>Zhong, Stent, 2005</marker>
<rawString>Huvava Zhong &amp; Amada Stent. 2005. Building Surface Realizers Automatically From Corpora. In Proceedings of the Corpus Linguistics 2005 Workshop on Using Corpora for Natural Language Generation (UCNLG), pages 49–54, Birmingham, UK, July 14.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>