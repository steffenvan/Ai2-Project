<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.031508">
<title confidence="0.997067">
Predicting Overt Display of Power in Written Dialogs
</title>
<author confidence="0.993653">
Vinodkumar Prabhakaran
</author>
<affiliation confidence="0.9940765">
Computer Science Dept.
Columbia University
</affiliation>
<address confidence="0.988512">
New York, NY 10027, USA
</address>
<email confidence="0.999312">
vinod@cs.columbia.edu
</email>
<author confidence="0.981255">
Owen Rambow
</author>
<affiliation confidence="0.971447">
CCLS
Columbia University
</affiliation>
<address confidence="0.987704">
New York, NY 10027, USA
</address>
<email confidence="0.99934">
rambow@ccls.columbia.edu
</email>
<author confidence="0.958228">
Mona Diab
</author>
<affiliation confidence="0.957557">
CCLS
Columbia University
</affiliation>
<address confidence="0.987168">
New York, NY 10027, USA
</address>
<email confidence="0.99955">
mdiab@ccls.columbia.edu
</email>
<sectionHeader confidence="0.995654" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998945714285714">
We analyze overt displays of power (ODPs)
in written dialogs. We present an email cor-
pus with utterances annotated for ODP and
present a supervised learning system to predict
it. We obtain a best cross validation F-measure
of 65.8 using gold dialog act features and 55.6
without using them.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956827586207">
Analyzing written dialogs (such as email exchanges)
to extract social power relations has generated great
interest recently. This paper introduces a new task
within the general field of finding power relations
in written dialogs. In written dialog, an utterance
can represent an overt display of power (ODP) on
the part of the utterer if it constrains the addressee’s
actions beyond the constraints that the underlying
dialog act on its own imposes. For example, a re-
quest for action is the first part of an adjacency pair
and thus requires a response from the addressee, but
declining the request is a valid response. However,
the utterer may formulate her request for action in a
way that attempts to remove the option of declining
it (“Come to my office now!”). In so doing, she re-
stricts her addressee’s options for responding more
severely than a simple request for action would. Our
new task is to classify utterances in written dialog
as to whether they are ODPs or not. Such a classifi-
cation can be interesting in and of itself, and it can
also be used to study social relations among dialog
participants.
After reviewing related work (Section 2), we de-
fine “overt display of power” (Section 3) and then
present manual annotations for ODP in a small sub-
set of Enron email corpus. In Section 5, we present a
supervised learning system using word and part-of-
speech features along with features indicating dialog
acts.
</bodyText>
<sectionHeader confidence="0.999691" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99991192">
Many studies in sociolinguistics have shown that
power relations are manifested in language use
(e.g., (O’Barr, 1982)). Locher (2004) recognizes
“restriction of an interactant’s action-environment”
(Wartenberg, 1990) as a key element by which ex-
ercise of power in interactions can be identified.
Through ODP we capture this action-restriction at
an utterance level. In the computational field, sev-
eral studies have used Social Network Analysis
(e.g., (Diesner and Carley, 2005)) for extracting so-
cial relations from online communication. Only re-
cently have researchers started using NLP to analyze
the content of messages to deduce social relations
(e.g., (Diehl et al., 2007)). Bramsen et al. (2011) use
knowledge of the actual organizational structure to
create two sets of messages: messages sent from a
superior to a subordinate, and vice versa. Their task
is to determine the direction of power (since all their
data, by construction of the corpus, has a power re-
lationship). Their reported results cannot be directly
compared with ours since their results are on classi-
fying aggregations of messages as being to a supe-
rior or to a subordinate, whereas our results are on
predicting whether a single utterance has an ODP or
not.
</bodyText>
<page confidence="0.927101">
518
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 518–522,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</page>
<sectionHeader confidence="0.987999" genericHeader="method">
3 Overt Display of Power (ODP)
</sectionHeader>
<bodyText confidence="0.968335754716981">
Dialog is successful when all discourse participants
show cooperative dialog behavior. Certain types of
dialog acts, notably requests for actions and requests
for information (questions), “set constraints on what
should be done in a next turn” (Sacks et al., 1974).
Suppose a boss sends an email to her subordinate:
“It would be great if you could come to my of-
fice right now”. He responds by politely declining
(“Would love to, but unfortunately I need to pick up
my kids”). He has met the expectation to respond
in one of the constrained ways that the request for
action allows (other acceptable responses include a
commitment to performing the action, or actually
performing the action, while unacceptable responses
include silence, or changing the topic). However, di-
alog acts only provide an initial description of these
constraints. Other sources of constraints include
the social relations between the utterer and the ad-
dressee, and the linguistic form of the utterance. As-
sume our email example had come, say, from the
CEO of the company. In this case, the addressee’s
response would not meet the constraints set by the
utterance, even though it is still analyzed as the same
dialog act (a request for action). Detecting such
power relations and determining their effect on di-
alog is a hard problem, and it is the ultimate goal of
our research. Therefore, we do not use knowledge
of power relations as features in performing a finer-
grained analysis of dialog acts. Instead, we turn to
the linguistic form of an utterance. Specifically, the
utterer can choose linguistic forms in her utterance
to signal that she is imposing further constraints on
the addressee’s choice of how to respond, constraints
which go beyond those defined by the standard set
of dialog acts. For example, if the boss’s email is
“Please come to my office right now”, and the ad-
dressee declines, he is clearly not adhering to the
constraints the boss has signaled, though he is ad-
hering to the general constraints of cooperative dia-
log by responding to the request for action. We are
interested in these additional constraints imposed on
utterances through choices in linguistic form. We
define an utterance to have Overt Display of Power
(ODP) if it is interpreted as creating additional con-
straints on the response beyond those imposed by
the general dialog act. Note that use of polite lan-
ID Sample utterance
s1 If there is any movement of these people between
groups can you please keep me in the loop.
s2 I need the answer ASAP, as ....
s3 Please give me your views ASAP.
s4* Enjoy the rest of your week!
s5 Would you work on that?
</bodyText>
<tableCaption confidence="0.691898166666667">
s6* ... would you agree that the same law firm advise on
that issue as well?
s7* can you BELIEVE this bloody election?
s8 ok call me on my cell later.
Table 1: Sample utterances from the corpus; * next to ID
denotes an utterance without an ODP
</tableCaption>
<bodyText confidence="0.999928842105263">
guage does not, on its own, determine the presence
or absence of an ODP. Furthermore, the presence of
an ODP does not presuppose that the utterer actually
possess social power: the utterer could be attempt-
ing to gain power.
Table 1 presents some sample utterances cho-
sen from our corpus (the * indicates those without
ODP). An utterance with ODP can be an explicit or-
der or command (s3, s8) or an implicit one (s2, s5).
It can be a simple sentence (s3) or a complex one
(s1). It can be an imperative (s3), an interrogative
(s5) or even a declarative (s2) sentence. But not all
imperatives (s4) or interrogatives (s6, s7) are ODPs.
s5, s6 and s7 are all syntactically questions. How-
ever, s5’s discourse function within an email is to
request/order to work on “that” which makes it an
instance of ODP, while s6 is merely an inquiry and
s7 is a rhetorical question. This makes the problem
of finding ODP in utterances a non-trivial one.
</bodyText>
<sectionHeader confidence="0.989186" genericHeader="method">
4 Data and Annotations
</sectionHeader>
<bodyText confidence="0.994026444444445">
For our study, we use a small corpus of Enron email
threads which has been previously annotated with
dialog acts (Hu et al., 2009). The corpus contains
122 email threads with 360 messages, 1734 utter-
ances and 20,740 word tokens. We trained an anno-
tator using the definition for ODP given in Section
3. She was given full email threads whose messages
were already segmented into utterances. She iden-
tified 86 utterances (about 5%) to have an ODP.1 In
</bodyText>
<footnote confidence="0.998604666666667">
1These annotations were done as part of a larger annotation
effort (Prabhakaran et al., 2012). The annotated corpus can be
obtained at http://www.cs.columbia.edu/∼vinod/powerann/.
</footnote>
<page confidence="0.995737">
519
</page>
<bodyText confidence="0.9999925">
order to validate the annotations, we trained another
annotator using the same definitions and examples
and had him annotate 46 randomly selected threads
from the corpus, which contained a total of 595 ut-
terances (34.3% of whole corpus). We obtained a
reasonable inter annotator agreement, n value, of
0.669, which validates the annotations while con-
firming that the task is not a trivial one.
</bodyText>
<sectionHeader confidence="0.995813" genericHeader="method">
5 Automatic ODP Tagging
</sectionHeader>
<bodyText confidence="0.999915111111111">
In this section, we present a supervised learning
method to tag unseen utterances that contain an ODP
using a binary SVM classifier. We use the tokenizer,
POS tagger, lemmatizer and SVMLight (Joachims,
1999) wrapper that come with ClearTK (Ogren et
al., 2008). We use a linear kernel with C = 1 for
all experiments and present (P)recision, (R)ecall and
(F)-measure obtained on 5-fold cross validation on
the data. Our folds do not cross thread boundaries.
</bodyText>
<subsectionHeader confidence="0.992623">
5.1 Handling Class Imbalance
</subsectionHeader>
<bodyText confidence="0.999850653846154">
In its basic formulation, SVMs learn a decision func-
tion f from a set of positive and negative training in-
stances such that an unlabeled instance x is labeled
as positive if f(x) &gt; 0. Since SVMs optimize on
training set accuracy to learn f, it performs better
on balanced training sets. However, our dataset is
highly imbalanced (- 5% positive instances). We
explore two ways of handling this class imbalance
problem: an instance weighting method, InstWeight,
where training errors on negative instances are out-
weighed by errors on positive instances, and SigTh-
resh, a threshold adjusting method to find a better
threshold for f(x). For InstWeight, we used the j
option in SVMlight to set the outweighing factor
to be the ratio of negative to positive instances in
the training set for each cross validation fold. Inst-
Weight is roughly equivalent to oversampling by re-
peating positive instances. For SigThresh, we used
a threshold based on a posterior probabilistic score,
p = Pr(y = 1Jx), calculated using the ClearTK im-
plementation of Lin et al. (2007)’s algorithm. It uses
Platt (1999)’s approximation of p to a sigmoid func-
tion PA,B(f) = (1 + exp(Af + B))−1, where A
and B are estimated from the training set. Then, we
predict x as positive if p &gt; 0.5 which in effect shifts
the threshold for f(x) to a value based on its distri-
</bodyText>
<table confidence="0.998950875">
Experiment P InstWeight F P SigThresh F
R R
ALL-TRUE 5.0 100.0 9.5 5.0 100.0 9.5
RANDOM 5.7 58.1 10.4 5.7 58.1 10.4
WORD-UNG 43.1 29.1 34.7 63.0 39.5 48.6
PN,MN,FV,DA 66.7 48.8 56.4 72.3 54.7 62.3
PN,MN,DA 64.5 46.5 54.1 75.8 58.1 65.8
LN,PN,MN,FV 64.4 44.2 52.4 65.2 50.0 56.6
</table>
<tableCaption confidence="0.987795">
Table 2: Results
</tableCaption>
<table confidence="0.6511406">
Class Imbalance Handling: InstWeight: Instance weighting and
SigThresh: Sigmoid thresholding
Features: WORD-UNG: Word unigrams, LN: Lemma ngrams, PN:
POS ngrams, MN: Mixed ngrams, FV: First verb, DA: Dialog acts
bution on positive and negative training instances.
</table>
<subsectionHeader confidence="0.826357">
5.2 Features
</subsectionHeader>
<bodyText confidence="0.9999748">
We present experiments using counts of three types
of ngrams: lemma ngrams (LN), POS ngrams (PN)
and mixed ngrams (MN).2 Mixed ngram is a re-
stricted formulation of lemma ngram where open-
class lemmas (nouns, verbs, adjectives and adverbs)
are replaced by POS tags. E.g., for the utterance
s2, LN would capture patterns {i, need, i need, ... },
while PN would capture {PRP, VBP, PRP VBP, ... }
and MN would capture {i VBP the NN, ... }. We
also used a feature (FV) to denote the first verb
lemma in the utterance. Since ODPs, like dialog
acts, constrain how the addressee should react, we
also include Dialog Acts as features (DA). We use
the manual gold dialog act annotations present in
our corpus, which use a very small dialog act tag
set. An utterance has one of 5 dialog acts: Reques-
tAction, RequestInformation, Inform, Commit and
Conventional (see (Hu et al., 2009) for details). For
example, for utterance s2, FV would be ‘need’ and
DA would be ‘Inform’.3
</bodyText>
<subsectionHeader confidence="0.92553">
5.3 Results and Analysis
</subsectionHeader>
<bodyText confidence="0.9999952">
We present two simple baselines — ALL-TRUE,
where an utterance is always predicted to have an
ODP, and RANDOM, where an utterance is pre-
dicted at random, with 50% chance to have an ODP.
We also present a strong baseline WORD-UNG,
</bodyText>
<footnote confidence="0.9798348">
2LN performed consistently better than word ngrams.
3We also explored other features including the number of
tokens, the previous or following dialect act, none of which im-
proved the results and. We omit a detailed discussion for rea-
sons of space.
</footnote>
<page confidence="0.994732">
520
</page>
<bodyText confidence="0.999955731707317">
which is trained using surface-form word unigrams
as features. ALL-TRUE and RANDOM obtained F
scores of 9.5 and 10.4 respectively, while WORD-
UNG obtained an F score of 34.7 under InstWeight,
and improved it to 48.6 under SigThresh.
For LN, PN and MN, we first found the best value
for n to be 1, 2 and 4, respectively. We then did
an exhaustive search in all combinations of LN, PN,
MN, FV and DA under both InstWeight and SigTh-
resh. Results obtained for best feature subset under
both configurations are presented in Table 2 in rows
3 and 4. SigThresh outweighed InstWeight in all our
experiments. (Combining these two techniques for
dealing with class imbalance performed worse than
using either one.) In both settings, we surpassed the
WORD-UNG baseline by a high margin. We found
MN and DA to be most useful: removing either from
the feature set dropped the F significantly in both
settings. We obtained a best F score of 65.8 using
PN, MN and DA under the SigThresh.
Following (Guyon et al., 2002), we inspected fea-
ture weights of the model created for the last fold of
our best performing feature configuration as a post-
hoc analysis. The binary feature DA:RequestAction
got the highest positive weight of 2.5. The top
ten positive weighted features included patterns
like you VB, * VB, MD PRP, VB VB and * MD,
where * denotes the utterance boundary. DA:Inform
got the most negative weight of -1.4, followed by
DA:Conventional with -1.0. The top ten negative
weighted features included patterns like MD VB,
VB you, what, VB VB me VB and WP. In both
cases, DA features got almost 2.5 times higher
weight than the highest weighted ngram pattern,
which reaffirms their importance in this task. Also,
mixed ngrams helped to capture long patterns like
”please let me know” by VB VB me VB without in-
creasing dimensionality as much as word ngrams;
they also distinguish VB you with a negative weight
of -0.51 from VB me with a positive weight of 0.32,
which pure POS ngrams couldn’t have captured.
</bodyText>
<subsectionHeader confidence="0.988874">
5.4 Not Using Gold Dialog Acts
</subsectionHeader>
<bodyText confidence="0.999990357142857">
We also evaluate the performance of our ODP tagger
without using gold DA tags. We instead use the DA
tagger of Hu et al. (2009), which we re-trained us-
ing the training sets for each of our cross validation
folds, applying it to the test set of that fold. We then
did cross validation for the ODP tagger using gold
dialog acts for training and automatically tagged di-
alog acts for testing. However, for our best perform-
ing feature set so far, this reduced the F score from
65.8 to 52.7. Our best result for ODP tagging with-
out using gold DAs is shown in row 5 in Table 2,
56.9 F score under SigThresh. The features used are
all of our features other than the DA tags. On fur-
ther analysis, we find that even though the dialog
act tagger has a high accuracy (85.8% in our cross
validation), it obtained a very low recall of 28.6%
and precision of 47.6% for the RequestAction dia-
log act. Since RequestAction is the most important
feature (weighted 1.7 times more than the next fea-
ture), the DA-tagger’s poor performance on Reques-
tAction hurt ODP tagging badly. The performance
reduction in this setting is probably partly due to us-
ing gold DAs in training and automatically tagged
DAs in testing; however, we feel that improving the
detection of minority classes in dialog act tagging
(RequestAction constitutes only 2.5% in the corpus)
is a necessary first step towards successfully using
automatically tagged DAs in ODP tagging.
</bodyText>
<sectionHeader confidence="0.999234" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999984272727273">
We have introduced a new binary classification task
on utterances in dialogs, namely predicting Overt
Display of Power. An ODP adds constraints on the
possible responses by the addressee. We have in-
troduced a corpus annotated for ODP and we have
shown that using supervised machine learning with
gold dialog acts we can achieve an F-measure of
66% despite the fact that ODPs are very rare in the
corpus. We intend to develop a better dialog act tag-
ger which we can use to automatically obtain dialog
act labels for ODP classification.
</bodyText>
<sectionHeader confidence="0.998742" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999927285714286">
This work is supported, in part, by the Johns Hop-
kins Human Language Technology Center of Ex-
cellence. Any opinions, findings, and conclusions
or recommendations expressed in this material are
those of the authors and do not necessarily reflect
the views of the sponsor. We thank several anony-
mous reviewers for their constructive feedback.
</bodyText>
<page confidence="0.996594">
521
</page>
<sectionHeader confidence="0.989829" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999812120689655">
Philip Bramsen, Martha Escobar-Molano, Ami Patel, and
Rafael Alonso. 2011. Extracting social power rela-
tionships from natural language. In ACL, pages 773–
782. The Association for Computer Linguistics.
Christopher P. Diehl, Galileo Namata, and Lise Getoor.
2007. Relationship identification for social network
discovery. In AAAI, pages 546–552. AAAI Press.
Jana Diesner and Kathleen M. Carley. 2005. Exploration
of communication networks from the enron email cor-
pus. In In Proc. of Workshop on Link Analysis, Coun-
terterrorism and Security, SIAM International Confer-
ence on Data Mining 2005, pages 21–23.
Isabelle Guyon, Jason Weston, Stephen Barnhill, and
Vladimir Vapnik. 2002. Gene selection for cancer
classification using support vector machines. Mach.
Learn., 46:389–422, March.
Jun Hu, Rebecca Passonneau, and Owen Rambow. 2009.
Contrasting the interaction structure of an email and a
telephone corpus: A machine learning approach to an-
notation of dialogue function units. In Proceedings of
the SIGDIAL 2009 Conference, London, UK, Septem-
ber. Association for Computational Linguistics.
Thorsten Joachims. 1999. Making Large-Scale SVM
Learning Practical. In Bernhard Sch¨olkopf, Christo-
pher J.C. Burges, and A. Smola, editors, Advances
in Kernel Methods - Support Vector Learning, Cam-
bridge, MA, USA. MIT Press.
Hsuan-Tien Lin, Chih-Jen Lin, and Ruby C. Weng. 2007.
A note on platt’s probabilistic outputs for support vec-
tor machines. Mach. Learn., 68:267–276, October.
Miriam A. Locher. 2004. Power and politeness in ac-
tion: disagreements in oral communication. Lan-
guage, power, and social process. M. de Gruyter.
William M. O’Barr. 1982. Linguistic evidence: lan-
guage, power, and strategy in the courtroom. Studies
on law and social control. Academic Press.
Philip V. Ogren, Philipp G. Wetzler, and Steven Bethard.
2008. ClearTK: A UIMA toolkit for statistical natural
language processing. In Towards Enhanced Interoper-
ability for Large HLT Systems: UIMA for NLP work-
shop at Language Resources and Evaluation Confer-
ence (LREC).
John C. Platt. 1999. Probabilistic outputs for support
vector machines and comparisons to regularized like-
lihood methods. In ADVANCES IN LARGE MARGIN
CLASSIFIERS, pages 61–74. MIT Press.
Vinodkumar Prabhakaran, Owen Rambow, and Mona
Diab. 2012. Annotations for power relations on
email threads. In Proceedings of the Eighth confer-
ence on International Language Resources and Eval-
uation (LREC’12), Istanbul, Turkey, May. European
Language Resources Association (ELRA).
Sacks, E Schegloff, and G Jefferson. 1974. A simplest
systematics for the organization of turn-taking for con-
versation. Language, 50:696–735.
Thomas E. Wartenberg. 1990. The forms of power:
from domination to transformation. Temple Univer-
sity Press.
</reference>
<page confidence="0.997411">
522
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.241137">
<title confidence="0.999841">Predicting Overt Display of Power in Written Dialogs</title>
<author confidence="0.904864">Vinodkumar</author>
<affiliation confidence="0.999343">Computer Science</affiliation>
<address confidence="0.8606935">Columbia New York, NY 10027, USA</address>
<email confidence="0.999534">vinod@cs.columbia.edu</email>
<author confidence="0.868353">Owen</author>
<affiliation confidence="0.788747">Columbia</affiliation>
<address confidence="0.99913">New York, NY 10027, USA</address>
<email confidence="0.99927">rambow@ccls.columbia.edu</email>
<author confidence="0.809887">Mona</author>
<affiliation confidence="0.548031">Columbia</affiliation>
<address confidence="0.997059">New York, NY 10027, USA</address>
<email confidence="0.999803">mdiab@ccls.columbia.edu</email>
<abstract confidence="0.998912625">We analyze overt displays of power (ODPs) in written dialogs. We present an email corpus with utterances annotated for ODP and present a supervised learning system to predict it. We obtain a best cross validation F-measure of 65.8 using gold dialog act features and 55.6 without using them.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Philip Bramsen</author>
<author>Martha Escobar-Molano</author>
<author>Ami Patel</author>
<author>Rafael Alonso</author>
</authors>
<title>Extracting social power relationships from natural language. In</title>
<date>2011</date>
<booktitle>ACL,</booktitle>
<pages>773--782</pages>
<institution>The Association for Computer Linguistics.</institution>
<contexts>
<context position="2788" citStr="Bramsen et al. (2011)" startWordPosition="440" endWordPosition="443"> in language use (e.g., (O’Barr, 1982)). Locher (2004) recognizes “restriction of an interactant’s action-environment” (Wartenberg, 1990) as a key element by which exercise of power in interactions can be identified. Through ODP we capture this action-restriction at an utterance level. In the computational field, several studies have used Social Network Analysis (e.g., (Diesner and Carley, 2005)) for extracting social relations from online communication. Only recently have researchers started using NLP to analyze the content of messages to deduce social relations (e.g., (Diehl et al., 2007)). Bramsen et al. (2011) use knowledge of the actual organizational structure to create two sets of messages: messages sent from a superior to a subordinate, and vice versa. Their task is to determine the direction of power (since all their data, by construction of the corpus, has a power relationship). Their reported results cannot be directly compared with ours since their results are on classifying aggregations of messages as being to a superior or to a subordinate, whereas our results are on predicting whether a single utterance has an ODP or not. 518 2012 Conference of the North American Chapter of the Associati</context>
</contexts>
<marker>Bramsen, Escobar-Molano, Patel, Alonso, 2011</marker>
<rawString>Philip Bramsen, Martha Escobar-Molano, Ami Patel, and Rafael Alonso. 2011. Extracting social power relationships from natural language. In ACL, pages 773– 782. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher P Diehl</author>
<author>Galileo Namata</author>
<author>Lise Getoor</author>
</authors>
<title>Relationship identification for social network discovery.</title>
<date>2007</date>
<booktitle>In AAAI,</booktitle>
<pages>546--552</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="2764" citStr="Diehl et al., 2007" startWordPosition="436" endWordPosition="439">lations are manifested in language use (e.g., (O’Barr, 1982)). Locher (2004) recognizes “restriction of an interactant’s action-environment” (Wartenberg, 1990) as a key element by which exercise of power in interactions can be identified. Through ODP we capture this action-restriction at an utterance level. In the computational field, several studies have used Social Network Analysis (e.g., (Diesner and Carley, 2005)) for extracting social relations from online communication. Only recently have researchers started using NLP to analyze the content of messages to deduce social relations (e.g., (Diehl et al., 2007)). Bramsen et al. (2011) use knowledge of the actual organizational structure to create two sets of messages: messages sent from a superior to a subordinate, and vice versa. Their task is to determine the direction of power (since all their data, by construction of the corpus, has a power relationship). Their reported results cannot be directly compared with ours since their results are on classifying aggregations of messages as being to a superior or to a subordinate, whereas our results are on predicting whether a single utterance has an ODP or not. 518 2012 Conference of the North American </context>
</contexts>
<marker>Diehl, Namata, Getoor, 2007</marker>
<rawString>Christopher P. Diehl, Galileo Namata, and Lise Getoor. 2007. Relationship identification for social network discovery. In AAAI, pages 546–552. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jana Diesner</author>
<author>Kathleen M Carley</author>
</authors>
<title>Exploration of communication networks from the enron email corpus. In</title>
<date>2005</date>
<booktitle>In Proc. of Workshop on Link Analysis, Counterterrorism and Security, SIAM International Conference on Data Mining</booktitle>
<pages>21--23</pages>
<contexts>
<context position="2565" citStr="Diesner and Carley, 2005" startWordPosition="405" endWordPosition="408">Section 5, we present a supervised learning system using word and part-ofspeech features along with features indicating dialog acts. 2 Related Work Many studies in sociolinguistics have shown that power relations are manifested in language use (e.g., (O’Barr, 1982)). Locher (2004) recognizes “restriction of an interactant’s action-environment” (Wartenberg, 1990) as a key element by which exercise of power in interactions can be identified. Through ODP we capture this action-restriction at an utterance level. In the computational field, several studies have used Social Network Analysis (e.g., (Diesner and Carley, 2005)) for extracting social relations from online communication. Only recently have researchers started using NLP to analyze the content of messages to deduce social relations (e.g., (Diehl et al., 2007)). Bramsen et al. (2011) use knowledge of the actual organizational structure to create two sets of messages: messages sent from a superior to a subordinate, and vice versa. Their task is to determine the direction of power (since all their data, by construction of the corpus, has a power relationship). Their reported results cannot be directly compared with ours since their results are on classify</context>
</contexts>
<marker>Diesner, Carley, 2005</marker>
<rawString>Jana Diesner and Kathleen M. Carley. 2005. Exploration of communication networks from the enron email corpus. In In Proc. of Workshop on Link Analysis, Counterterrorism and Security, SIAM International Conference on Data Mining 2005, pages 21–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabelle Guyon</author>
<author>Jason Weston</author>
<author>Stephen Barnhill</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Gene selection for cancer classification using support vector machines.</title>
<date>2002</date>
<location>Mach. Learn., 46:389–422,</location>
<contexts>
<context position="13312" citStr="Guyon et al., 2002" startWordPosition="2240" endWordPosition="2243">MN, FV and DA under both InstWeight and SigThresh. Results obtained for best feature subset under both configurations are presented in Table 2 in rows 3 and 4. SigThresh outweighed InstWeight in all our experiments. (Combining these two techniques for dealing with class imbalance performed worse than using either one.) In both settings, we surpassed the WORD-UNG baseline by a high margin. We found MN and DA to be most useful: removing either from the feature set dropped the F significantly in both settings. We obtained a best F score of 65.8 using PN, MN and DA under the SigThresh. Following (Guyon et al., 2002), we inspected feature weights of the model created for the last fold of our best performing feature configuration as a posthoc analysis. The binary feature DA:RequestAction got the highest positive weight of 2.5. The top ten positive weighted features included patterns like you VB, * VB, MD PRP, VB VB and * MD, where * denotes the utterance boundary. DA:Inform got the most negative weight of -1.4, followed by DA:Conventional with -1.0. The top ten negative weighted features included patterns like MD VB, VB you, what, VB VB me VB and WP. In both cases, DA features got almost 2.5 times higher w</context>
</contexts>
<marker>Guyon, Weston, Barnhill, Vapnik, 2002</marker>
<rawString>Isabelle Guyon, Jason Weston, Stephen Barnhill, and Vladimir Vapnik. 2002. Gene selection for cancer classification using support vector machines. Mach. Learn., 46:389–422, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Hu</author>
<author>Rebecca Passonneau</author>
<author>Owen Rambow</author>
</authors>
<title>Contrasting the interaction structure of an email and a telephone corpus: A machine learning approach to annotation of dialogue function units.</title>
<date>2009</date>
<booktitle>In Proceedings of the SIGDIAL 2009 Conference,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>London, UK,</location>
<contexts>
<context position="7530" citStr="Hu et al., 2009" startWordPosition="1257" endWordPosition="1260">s1). It can be an imperative (s3), an interrogative (s5) or even a declarative (s2) sentence. But not all imperatives (s4) or interrogatives (s6, s7) are ODPs. s5, s6 and s7 are all syntactically questions. However, s5’s discourse function within an email is to request/order to work on “that” which makes it an instance of ODP, while s6 is merely an inquiry and s7 is a rhetorical question. This makes the problem of finding ODP in utterances a non-trivial one. 4 Data and Annotations For our study, we use a small corpus of Enron email threads which has been previously annotated with dialog acts (Hu et al., 2009). The corpus contains 122 email threads with 360 messages, 1734 utterances and 20,740 word tokens. We trained an annotator using the definition for ODP given in Section 3. She was given full email threads whose messages were already segmented into utterances. She identified 86 utterances (about 5%) to have an ODP.1 In 1These annotations were done as part of a larger annotation effort (Prabhakaran et al., 2012). The annotated corpus can be obtained at http://www.cs.columbia.edu/∼vinod/powerann/. 519 order to validate the annotations, we trained another annotator using the same definitions and e</context>
<context position="11711" citStr="Hu et al., 2009" startWordPosition="1961" endWordPosition="1964">POS tags. E.g., for the utterance s2, LN would capture patterns {i, need, i need, ... }, while PN would capture {PRP, VBP, PRP VBP, ... } and MN would capture {i VBP the NN, ... }. We also used a feature (FV) to denote the first verb lemma in the utterance. Since ODPs, like dialog acts, constrain how the addressee should react, we also include Dialog Acts as features (DA). We use the manual gold dialog act annotations present in our corpus, which use a very small dialog act tag set. An utterance has one of 5 dialog acts: RequestAction, RequestInformation, Inform, Commit and Conventional (see (Hu et al., 2009) for details). For example, for utterance s2, FV would be ‘need’ and DA would be ‘Inform’.3 5.3 Results and Analysis We present two simple baselines — ALL-TRUE, where an utterance is always predicted to have an ODP, and RANDOM, where an utterance is predicted at random, with 50% chance to have an ODP. We also present a strong baseline WORD-UNG, 2LN performed consistently better than word ngrams. 3We also explored other features including the number of tokens, the previous or following dialect act, none of which improved the results and. We omit a detailed discussion for reasons of space. 520 w</context>
<context position="14464" citStr="Hu et al. (2009)" startWordPosition="2443" endWordPosition="2446">and WP. In both cases, DA features got almost 2.5 times higher weight than the highest weighted ngram pattern, which reaffirms their importance in this task. Also, mixed ngrams helped to capture long patterns like ”please let me know” by VB VB me VB without increasing dimensionality as much as word ngrams; they also distinguish VB you with a negative weight of -0.51 from VB me with a positive weight of 0.32, which pure POS ngrams couldn’t have captured. 5.4 Not Using Gold Dialog Acts We also evaluate the performance of our ODP tagger without using gold DA tags. We instead use the DA tagger of Hu et al. (2009), which we re-trained using the training sets for each of our cross validation folds, applying it to the test set of that fold. We then did cross validation for the ODP tagger using gold dialog acts for training and automatically tagged dialog acts for testing. However, for our best performing feature set so far, this reduced the F score from 65.8 to 52.7. Our best result for ODP tagging without using gold DAs is shown in row 5 in Table 2, 56.9 F score under SigThresh. The features used are all of our features other than the DA tags. On further analysis, we find that even though the dialog act</context>
</contexts>
<marker>Hu, Passonneau, Rambow, 2009</marker>
<rawString>Jun Hu, Rebecca Passonneau, and Owen Rambow. 2009. Contrasting the interaction structure of an email and a telephone corpus: A machine learning approach to annotation of dialogue function units. In Proceedings of the SIGDIAL 2009 Conference, London, UK, September. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making Large-Scale SVM Learning Practical.</title>
<date>1999</date>
<booktitle>Advances in Kernel Methods - Support Vector Learning,</booktitle>
<editor>In Bernhard Sch¨olkopf, Christopher J.C. Burges, and A. Smola, editors,</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="8659" citStr="Joachims, 1999" startWordPosition="1439" endWordPosition="1440">alidate the annotations, we trained another annotator using the same definitions and examples and had him annotate 46 randomly selected threads from the corpus, which contained a total of 595 utterances (34.3% of whole corpus). We obtained a reasonable inter annotator agreement, n value, of 0.669, which validates the annotations while confirming that the task is not a trivial one. 5 Automatic ODP Tagging In this section, we present a supervised learning method to tag unseen utterances that contain an ODP using a binary SVM classifier. We use the tokenizer, POS tagger, lemmatizer and SVMLight (Joachims, 1999) wrapper that come with ClearTK (Ogren et al., 2008). We use a linear kernel with C = 1 for all experiments and present (P)recision, (R)ecall and (F)-measure obtained on 5-fold cross validation on the data. Our folds do not cross thread boundaries. 5.1 Handling Class Imbalance In its basic formulation, SVMs learn a decision function f from a set of positive and negative training instances such that an unlabeled instance x is labeled as positive if f(x) &gt; 0. Since SVMs optimize on training set accuracy to learn f, it performs better on balanced training sets. However, our dataset is highly imba</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making Large-Scale SVM Learning Practical. In Bernhard Sch¨olkopf, Christopher J.C. Burges, and A. Smola, editors, Advances in Kernel Methods - Support Vector Learning, Cambridge, MA, USA. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hsuan-Tien Lin</author>
<author>Chih-Jen Lin</author>
<author>Ruby C Weng</author>
</authors>
<title>A note on platt’s probabilistic outputs for support vector machines.</title>
<date>2007</date>
<location>Mach. Learn., 68:267–276,</location>
<contexts>
<context position="9991" citStr="Lin et al. (2007)" startWordPosition="1660" endWordPosition="1663">ng method, InstWeight, where training errors on negative instances are outweighed by errors on positive instances, and SigThresh, a threshold adjusting method to find a better threshold for f(x). For InstWeight, we used the j option in SVMlight to set the outweighing factor to be the ratio of negative to positive instances in the training set for each cross validation fold. InstWeight is roughly equivalent to oversampling by repeating positive instances. For SigThresh, we used a threshold based on a posterior probabilistic score, p = Pr(y = 1Jx), calculated using the ClearTK implementation of Lin et al. (2007)’s algorithm. It uses Platt (1999)’s approximation of p to a sigmoid function PA,B(f) = (1 + exp(Af + B))−1, where A and B are estimated from the training set. Then, we predict x as positive if p &gt; 0.5 which in effect shifts the threshold for f(x) to a value based on its distriExperiment P InstWeight F P SigThresh F R R ALL-TRUE 5.0 100.0 9.5 5.0 100.0 9.5 RANDOM 5.7 58.1 10.4 5.7 58.1 10.4 WORD-UNG 43.1 29.1 34.7 63.0 39.5 48.6 PN,MN,FV,DA 66.7 48.8 56.4 72.3 54.7 62.3 PN,MN,DA 64.5 46.5 54.1 75.8 58.1 65.8 LN,PN,MN,FV 64.4 44.2 52.4 65.2 50.0 56.6 Table 2: Results Class Imbalance Handling: I</context>
</contexts>
<marker>Lin, Lin, Weng, 2007</marker>
<rawString>Hsuan-Tien Lin, Chih-Jen Lin, and Ruby C. Weng. 2007. A note on platt’s probabilistic outputs for support vector machines. Mach. Learn., 68:267–276, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam A Locher</author>
</authors>
<title>Power and politeness in action: disagreements in oral communication.</title>
<date>2004</date>
<journal>Language, power, and social</journal>
<contexts>
<context position="2221" citStr="Locher (2004)" startWordPosition="357" endWordPosition="358">y are ODPs or not. Such a classification can be interesting in and of itself, and it can also be used to study social relations among dialog participants. After reviewing related work (Section 2), we define “overt display of power” (Section 3) and then present manual annotations for ODP in a small subset of Enron email corpus. In Section 5, we present a supervised learning system using word and part-ofspeech features along with features indicating dialog acts. 2 Related Work Many studies in sociolinguistics have shown that power relations are manifested in language use (e.g., (O’Barr, 1982)). Locher (2004) recognizes “restriction of an interactant’s action-environment” (Wartenberg, 1990) as a key element by which exercise of power in interactions can be identified. Through ODP we capture this action-restriction at an utterance level. In the computational field, several studies have used Social Network Analysis (e.g., (Diesner and Carley, 2005)) for extracting social relations from online communication. Only recently have researchers started using NLP to analyze the content of messages to deduce social relations (e.g., (Diehl et al., 2007)). Bramsen et al. (2011) use knowledge of the actual orga</context>
</contexts>
<marker>Locher, 2004</marker>
<rawString>Miriam A. Locher. 2004. Power and politeness in action: disagreements in oral communication. Language, power, and social process. M. de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William M O’Barr</author>
</authors>
<title>Linguistic evidence: language, power, and strategy in the courtroom. Studies on law and social control.</title>
<date>1982</date>
<publisher>Academic Press.</publisher>
<marker>O’Barr, 1982</marker>
<rawString>William M. O’Barr. 1982. Linguistic evidence: language, power, and strategy in the courtroom. Studies on law and social control. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip V Ogren</author>
<author>Philipp G Wetzler</author>
<author>Steven Bethard</author>
</authors>
<title>ClearTK: A UIMA toolkit for statistical natural language processing.</title>
<date>2008</date>
<booktitle>In Towards Enhanced Interoperability for Large HLT Systems: UIMA for NLP workshop at Language Resources and Evaluation Conference (LREC).</booktitle>
<contexts>
<context position="8711" citStr="Ogren et al., 2008" startWordPosition="1446" endWordPosition="1449">tator using the same definitions and examples and had him annotate 46 randomly selected threads from the corpus, which contained a total of 595 utterances (34.3% of whole corpus). We obtained a reasonable inter annotator agreement, n value, of 0.669, which validates the annotations while confirming that the task is not a trivial one. 5 Automatic ODP Tagging In this section, we present a supervised learning method to tag unseen utterances that contain an ODP using a binary SVM classifier. We use the tokenizer, POS tagger, lemmatizer and SVMLight (Joachims, 1999) wrapper that come with ClearTK (Ogren et al., 2008). We use a linear kernel with C = 1 for all experiments and present (P)recision, (R)ecall and (F)-measure obtained on 5-fold cross validation on the data. Our folds do not cross thread boundaries. 5.1 Handling Class Imbalance In its basic formulation, SVMs learn a decision function f from a set of positive and negative training instances such that an unlabeled instance x is labeled as positive if f(x) &gt; 0. Since SVMs optimize on training set accuracy to learn f, it performs better on balanced training sets. However, our dataset is highly imbalanced (- 5% positive instances). We explore two way</context>
</contexts>
<marker>Ogren, Wetzler, Bethard, 2008</marker>
<rawString>Philip V. Ogren, Philipp G. Wetzler, and Steven Bethard. 2008. ClearTK: A UIMA toolkit for statistical natural language processing. In Towards Enhanced Interoperability for Large HLT Systems: UIMA for NLP workshop at Language Resources and Evaluation Conference (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Platt</author>
</authors>
<title>Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods.</title>
<date>1999</date>
<booktitle>In ADVANCES IN LARGE MARGIN CLASSIFIERS,</booktitle>
<pages>61--74</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="10025" citStr="Platt (1999)" startWordPosition="1667" endWordPosition="1668">rrors on negative instances are outweighed by errors on positive instances, and SigThresh, a threshold adjusting method to find a better threshold for f(x). For InstWeight, we used the j option in SVMlight to set the outweighing factor to be the ratio of negative to positive instances in the training set for each cross validation fold. InstWeight is roughly equivalent to oversampling by repeating positive instances. For SigThresh, we used a threshold based on a posterior probabilistic score, p = Pr(y = 1Jx), calculated using the ClearTK implementation of Lin et al. (2007)’s algorithm. It uses Platt (1999)’s approximation of p to a sigmoid function PA,B(f) = (1 + exp(Af + B))−1, where A and B are estimated from the training set. Then, we predict x as positive if p &gt; 0.5 which in effect shifts the threshold for f(x) to a value based on its distriExperiment P InstWeight F P SigThresh F R R ALL-TRUE 5.0 100.0 9.5 5.0 100.0 9.5 RANDOM 5.7 58.1 10.4 5.7 58.1 10.4 WORD-UNG 43.1 29.1 34.7 63.0 39.5 48.6 PN,MN,FV,DA 66.7 48.8 56.4 72.3 54.7 62.3 PN,MN,DA 64.5 46.5 54.1 75.8 58.1 65.8 LN,PN,MN,FV 64.4 44.2 52.4 65.2 50.0 56.6 Table 2: Results Class Imbalance Handling: InstWeight: Instance weighting and </context>
</contexts>
<marker>Platt, 1999</marker>
<rawString>John C. Platt. 1999. Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. In ADVANCES IN LARGE MARGIN CLASSIFIERS, pages 61–74. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vinodkumar Prabhakaran</author>
<author>Owen Rambow</author>
<author>Mona Diab</author>
</authors>
<title>Annotations for power relations on email threads.</title>
<date>2012</date>
<journal>European Language Resources Association (ELRA).</journal>
<booktitle>In Proceedings of the Eighth conference on International Language Resources and Evaluation (LREC’12),</booktitle>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="7943" citStr="Prabhakaran et al., 2012" startWordPosition="1327" endWordPosition="1330">he problem of finding ODP in utterances a non-trivial one. 4 Data and Annotations For our study, we use a small corpus of Enron email threads which has been previously annotated with dialog acts (Hu et al., 2009). The corpus contains 122 email threads with 360 messages, 1734 utterances and 20,740 word tokens. We trained an annotator using the definition for ODP given in Section 3. She was given full email threads whose messages were already segmented into utterances. She identified 86 utterances (about 5%) to have an ODP.1 In 1These annotations were done as part of a larger annotation effort (Prabhakaran et al., 2012). The annotated corpus can be obtained at http://www.cs.columbia.edu/∼vinod/powerann/. 519 order to validate the annotations, we trained another annotator using the same definitions and examples and had him annotate 46 randomly selected threads from the corpus, which contained a total of 595 utterances (34.3% of whole corpus). We obtained a reasonable inter annotator agreement, n value, of 0.669, which validates the annotations while confirming that the task is not a trivial one. 5 Automatic ODP Tagging In this section, we present a supervised learning method to tag unseen utterances that cont</context>
</contexts>
<marker>Prabhakaran, Rambow, Diab, 2012</marker>
<rawString>Vinodkumar Prabhakaran, Owen Rambow, and Mona Diab. 2012. Annotations for power relations on email threads. In Proceedings of the Eighth conference on International Language Resources and Evaluation (LREC’12), Istanbul, Turkey, May. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Schegloff Sacks</author>
<author>G Jefferson</author>
</authors>
<title>A simplest systematics for the organization of turn-taking for conversation.</title>
<date>1974</date>
<journal>Language,</journal>
<pages>50--696</pages>
<marker>Sacks, Jefferson, 1974</marker>
<rawString>Sacks, E Schegloff, and G Jefferson. 1974. A simplest systematics for the organization of turn-taking for conversation. Language, 50:696–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas E Wartenberg</author>
</authors>
<title>The forms of power: from domination to transformation.</title>
<date>1990</date>
<publisher>Temple University Press.</publisher>
<contexts>
<context position="2304" citStr="Wartenberg, 1990" startWordPosition="365" endWordPosition="366">nd it can also be used to study social relations among dialog participants. After reviewing related work (Section 2), we define “overt display of power” (Section 3) and then present manual annotations for ODP in a small subset of Enron email corpus. In Section 5, we present a supervised learning system using word and part-ofspeech features along with features indicating dialog acts. 2 Related Work Many studies in sociolinguistics have shown that power relations are manifested in language use (e.g., (O’Barr, 1982)). Locher (2004) recognizes “restriction of an interactant’s action-environment” (Wartenberg, 1990) as a key element by which exercise of power in interactions can be identified. Through ODP we capture this action-restriction at an utterance level. In the computational field, several studies have used Social Network Analysis (e.g., (Diesner and Carley, 2005)) for extracting social relations from online communication. Only recently have researchers started using NLP to analyze the content of messages to deduce social relations (e.g., (Diehl et al., 2007)). Bramsen et al. (2011) use knowledge of the actual organizational structure to create two sets of messages: messages sent from a superior </context>
</contexts>
<marker>Wartenberg, 1990</marker>
<rawString>Thomas E. Wartenberg. 1990. The forms of power: from domination to transformation. Temple University Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>