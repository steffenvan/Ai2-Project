<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.265393">
<title confidence="0.9646">
Bootstrapping for Named Entity Tagging Using Concept-based Seeds
</title>
<author confidence="0.983612">
Cheng Niu, Wei Li, Jihong Ding, Rohini K. Srihari
</author>
<affiliation confidence="0.954076">
Cymfony Inc.
</affiliation>
<address confidence="0.960523">
600 Essjay Road, Williamsville, NY 14221. USA.
</address>
<email confidence="0.980554">
{cniu, wei, jding, rohini}@cymfony.com
</email>
<sectionHeader confidence="0.997068" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997478125">
A novel bootstrapping approach to
Named Entity (NE)tagging using con-
cept-based seeds and successive learners
is presented. This approach only requires
a few common noun or pronoun seeds
that correspond to the concept for the tar-
geted NE, e.g. he/she/man/woman for
PERSON NE. The bootstrapping proce-
dure is implemented as training two suc-
cessive learners. First, decision list is used
to learn the parsing-based NE rules. Then,
a Hidden Markov Model is trained on a
corpus automatically tagged by the first
learner. The resulting NE system ap-
proaches supervised NE performance for
some NE types.
</bodyText>
<sectionHeader confidence="0.997543" genericHeader="keywords">
1 Overview
</sectionHeader>
<bodyText confidence="0.999869672727273">
Recognizing and classifying proper names is a
fundamental task for information extraction. Three
types of proper names are defined in the Message
Understanding Conference (MUC) Named Entity
(NE) standards, namely, PERSON (PER),
ORGANIZATION (ORG), and LOCATION
(LOC). [MUC-7 1998]
There is considerable research on NE tagging
using supervised machine learning [e.g. Bikel et al.
1997; Borthwick 1998]. To overcome the knowl-
edge bottleneck of supervised learning, unsuper-
vised machine learning has been applied to NE.
[Cucchiarelli &amp; Velardi 2001] discussed boosting
the performance of an existing NE tagger by unsu-
pervised learning based on parsing structures.
[Cucerzan &amp; Yarowsky 1999], [Collins &amp; Singer
1999] and [Kim et al. 2002] presented various
techniques using co-training schemes for NE ex-
traction seeded by a small list of proper names or
hand-crafted NE rules. NE tagging has two tasks:
(i) NE chunking; (ii) NE classification. Parsing-
supported unsupervised NE learning systems in-
cluding ours only need to focus on NE classifica-
tion, assuming the NE chunks have been
constructed by the parser.
This paper presents a new bootstrapping ap-
proach using successive learning and concept-
based seeds. The successive learning is as follows.
First, parsing-based NE rules are learned with high
precision but limited recall. Then, these rules are
applied to a large raw corpus to automatically gen-
erate a tagged corpus. Finally, a high-performance
HMM-based NE tagger is trained using this cor-
pus.
Unlike co-training, our bootstrapping does not
involve iterative learning between the two learners,
hence it suffers little from error propagation which
is commonly associated with iterative learning.
To derive the parsing-based learner, the system
only requires a few common noun or pronoun
seeds that correspond to the concept for the tar-
geted NE, e.g. he/she/man/woman for PERSON
NE. Such concept-based seeds share grammatical
structures with the corresponding NEs, hence a
parser is utilized to support bootstrapping. Since
pronouns and common nouns occur more often
than NE instances, the parsing-based NE rules can
be learned in one iteration to avoid iterative learn-
ing.
The benchmarking shows that this system ap-
proaches the performance of supervised NE tag-
gers for two of the three proper name NE types in
MUC, namely, PER NE and LOC NE. This ap-
proach also supports tagging user-defined NE
types.
</bodyText>
<sectionHeader confidence="0.993908" genericHeader="introduction">
2 Implementation
</sectionHeader>
<bodyText confidence="0.99683525">
Figure 1 shows the overall system architecture.
Before the bootstrapping is started, a large raw
training corpus is parsed. The bootstrapping ex-
periment reported in this paper is based on a cor-
pus containing ~100,000 news articles and totally
~88,000,000 words. The parsed corpus is saved
into a repository, which supports fast retrieval by
keyword based indexing scheme.
</bodyText>
<figureCaption confidence="0.999063">
Figure 1. Bootstrapping System Architecture
</figureCaption>
<bodyText confidence="0.9993735">
The unsupervised bootstrapping is performed as
follows:
</bodyText>
<listItem confidence="0.995206909090909">
1. User provides concept-based seeds;
2. Retrieve parsing structures involving con-
cept-based seeds from the repository to train
a decision list for NE classification;
3. Apply the learned rules to the NE candidates
retrieved from the repository;
4. Construct an NE annotated corpus using the
tagged proper names and their neighboring
words;
5. Train an HMM based on the annotated cor-
pus.
</listItem>
<bodyText confidence="0.999632842105263">
A parser is necessary for concept-based NE
bootstrapping. This is due to the fact that concept-
based seeds only share pattern similarity with the
corresponding NEs at structural level, not at string
sequence level. In fact, the anaphoric function of
pronouns and common nouns to represent antece-
dent NEs indicates the substitutability of proper
names by the noun phrases headed by the corre-
sponding common nouns or pronouns. For exam-
ple, this man can substitute the proper name John
Smith in almost all structural patterns.
Five binary dependency relationships decoded
by our parser are used for parsing-based NE rule
learning: (i) a Has_Predicate(b): from logical sub-
ject a to verb b; (ii) a Object_Of(b): from logical
object a to verb b; (iii) a Has_Amod(b): from noun
a to its adjective modifier b; (iv) a Possess(b):
from the possessive noun-modifier a to head noun
b; (v) a IsA(b): equivalence relation (including
appositions) from one NP a to another NP b.
The concept-based seeds used in the experi-
ments are: (i) he, she, his, her, him, man, woman
for PER; (ii) city, province, town, village for LOC;
(iii) company, firm, organization, bank, airline,
army, committee, government, school, university
for ORG.
From the parsed corpus in the repository, all in-
stances (821,267) of the concept-based seeds in-
volved in the five dependency relations are
retrieved. Each seed instance was assigned a con-
cept tag corresponding to NE. For example, each
instance of he is marked as PER. The instances
with concept tagging plus their associated parsing
relationships are equivalent to an annotated NE
corpus. Based on this training corpus, the Decision
List Learning algorithm [Segal &amp; Etzioni 1994] is
used. The accuracy of each rule was evaluated us-
ing Laplace smoothing as follows,
</bodyText>
<equation confidence="0.9448028">
accuracy
positive 1
+
positive negative NE category No.
+ +
</equation>
<bodyText confidence="0.999973444444445">
As the PER tag dominates the corpus due to the
high occurrence frequency of he and she, learning
is biased towards PER as the answer. To correct
this bias, we employ the following modification
scheme for instance count. Suppose there are a to-
tal of NPER PER instances, NLOC LOC instances,
NORG ORG instances, then in the process of rule
accuracy evaluation, the involved instance count
for any NE type will be adjusted by the coefficient
</bodyText>
<equation confidence="0.951319333333333">
min (N , N , N
PER LOC ORG
NNE
</equation>
<bodyText confidence="0.999948333333333">
A total of 1,290 parsing-based NE rules, shown
in samples below, are learned, with accuracy
higher than 0.9.
</bodyText>
<equation confidence="0.961883333333333">
Possess(wife) 4 PER
Has_Predicate(divorce) 4 PER
Object_Of(deport) 4 PER
Possess(mayor) 4 LOC
Has_AMod(coastal) 4 LOC
Possess(ceo) 4 ORG
Has_AMod(non-profit) 4 ORG
Has_AMod(non-governmental) 4 ORG
............
</equation>
<bodyText confidence="0.99832725">
Due to the unique equivalence nature of the IsA
relation, we add the following IsA-based rules to
the top of the decision list: IsA(seed)4 tag of the
seed, e.g. IsA(man) 4 PER
</bodyText>
<figure confidence="0.967370705882353">
Repository
(parsed corpus)
NE tagging using parsing-based rules
parsing-based NE rules
training corpus
based on tagged NEs
Concept-based Seeds
Decision List
NE Learning
HMM
NE Learning
Bootstrapping Procedure
NE
Tagger
=
)
.
</figure>
<bodyText confidence="0.999920148148148">
The parsing-based first learner is used to tag a
raw corpus. First, we retrieve all the named entity
candidates associated with at least one of the five
parsing relationships from the repository. After
applying the decision list to the retrieved 1,607,709
NE candidates, 33,104 PER names, 16,426 LOC
names, and 11,908 ORG names are tagged. In or-
der to improve the bootstrapping performance, we
use the heuristic one tag per domain for multi-
word NE in addition to the one sense per discourse
principle [Gale et al 1992]. These heuristics are
found to be very helpful in both increasing positive
instances (i.e. tag propagation) and decreasing the
spurious instances (i.e. tag elimination). The tag
propagation/elimination scheme is adopted from
[Yarowsky 1995]. After this step, a total of
367,441 proper names are classified, including
134,722 PER names, 186,488 LOC names, and
46,231 ORG names.
The classified proper name instances lead to the
construction of an automatically tagged training
corpus, consisting of the NE instances and their
two (left and right) neighboring words within the
same sentence.
In the final stage, a bi-gram HMM is trained
based on the above training corpus. The HMM
training process follows [Bikel 1997].
</bodyText>
<sectionHeader confidence="0.996676" genericHeader="acknowledgments">
3 Benchmarking
</sectionHeader>
<bodyText confidence="0.9997535">
We used the same blind testing corpus of 300,000
words containing 20,000 PER, LOC and ORG in-
stances to measure performance degradation of
unsupervised learning from the existing supervised
NE tagger (Table 1, P for Precision, R for Recall, F
for F-measure and F/D for F-measure degradation).
</bodyText>
<tableCaption confidence="0.998655">
Table 1: Supervised-to-Unsupervised NE Degradation
</tableCaption>
<table confidence="0.999132">
Supervised NE Unsupervised NE
TYPE P R F P R F F/D
PER 92.3% 93.1% 92.7% 86.6% 88.9% 87.7% 5.0%
LOC 89.0% 87.7% 88.3% 82.9% 81.7% 82.3% 6.0%
ORG 85.7% 87.8% 86.7% 57.1% 48.9% 52.7% 34.0%
</table>
<bodyText confidence="0.9964514">
The performance for PER and LOC are above
80%, and approaching the performance of super-
vised learning. The reason of the unsatisfactory
performance of ORG (52.7%) is not difficult to
understand. There are numerous sub-types of ORG
that cannot be represented by the less than a dozen
concept-based seeds used for this experiment.
In addition to the key NE types in MUC, we
also tested this method for recognizing user-
defined NE types. We use the following concept-
based seeds for PRODUCT (PRO) NE: car, truck,
vehicle, product, plane, aircraft, computer, soft-
ware, operating system, database, book, platform,
network. Table 2 shows the benchmarks for
PRODUCT tagging.
</bodyText>
<tableCaption confidence="0.9276">
Table 2: Performance for PRODUCT NE
</tableCaption>
<table confidence="0.9960385">
TYPE PRECISION RECALL F-MEASURE
PRODUCT 67.27% 72.52% 69.80%
</table>
<sectionHeader confidence="0.9969" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999833705882353">
Bikel, D. M. 1997. Nymble: a high-performance learn-
ing name-finder. Proceedings of ANLP’97, 194-201,
Morgan Kaufmann Publishers.
Borthwick, A. et al. 1998. Description of the MENE
named Entity System. Proceedings of MUC-7.
Collins, M. and Y. Singer. 1999. Unsupervised Models
for Named Entity Classification. Proceedings of the
Joint SIGAT Conference on EMNLP and
VLC. ???Association for Computational Linguis-
tics, 1999.
Cucchiarelli, A. and P. Velardi. 2001. Unsupervised
Named Entity Recognition Using Syntactic and Se-
mantic Contextual Evidence. Computational Linguis-
tics, Volume 27, Number 1, 123-131.
Cucerzan, S. and D. Yarowsky. 1999. Language Inde-
pendent Named Entity Recognition Combining
Morphological and Contextual Evidence. Proceed-
ings of the Joint SIGDAT Conference on EMNLP
and VLC, 90-99.
Gale, W., K. Church, and D. Yarowsky. 1992. One
Sense Per Discourse. Proceedings of the 4th DARPA
Speech and Natural Language Workshop. 233-237.
Kim, J., I. Kang, and K. Choi. 2002. Unsupervised
Named Entity Classification Models and their En-
sembles. Proceedings of COLING 2002.
MUC-7, 1998. Proceedings of the Seventh Message
Understanding Conference (MUC-7), published on
the website http://www.muc.saic.com/
Segal, R. and O. Etzioni. 1994. Learning decision lists
using homogeneous rules. Proceedings of the 12th
National Conference on Artificial Intelligence.
Yarowsky, David. 1995. Unsupervised Word Sense
Disambiguation Rivaling Supervised Method. Pro-
ceedings of ACL 1995.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.004460">
<title confidence="0.998718">Bootstrapping for Named Entity Tagging Using Concept-based Seeds</title>
<author confidence="0.978722">Cheng Niu</author>
<author confidence="0.978722">Wei Li</author>
<author confidence="0.978722">Jihong Ding</author>
<author confidence="0.978722">K Rohini</author>
<affiliation confidence="0.999756">Cymfony Inc.</affiliation>
<address confidence="0.999935">600 Essjay Road, Williamsville, NY 14221. USA.</address>
<email confidence="0.999721">wei,jding,rohini}@cymfony.com</email>
<abstract confidence="0.996745323170732">A novel bootstrapping approach to Entity using concept-based seeds and successive learners is presented. This approach only requires a few common noun or pronoun seeds that correspond to the concept for the tar- NE, e.g. PERSON NE. The bootstrapping procedure is implemented as training two successive learners. First, decision list is used to learn the parsing-based NE rules. Then, a Hidden Markov Model is trained on a corpus automatically tagged by the first learner. The resulting NE system approaches supervised NE performance for some NE types. 1 Overview Recognizing and classifying proper names is a fundamental task for information extraction. Three types of proper names are defined in the Message Understanding Conference (MUC) Named Entity (NE) standards, namely, PERSON (PER), ORGANIZATION (ORG), and LOCATION (LOC). [MUC-7 1998] There is considerable research on NE tagging supervised machine learning [e.g. Bikel al. 1997; Borthwick 1998]. To overcome the knowledge bottleneck of supervised learning, unsupervised machine learning has been applied to NE. [Cucchiarelli &amp; Velardi 2001] discussed boosting the performance of an existing NE tagger by unsupervised learning based on parsing structures. [Cucerzan &amp; Yarowsky 1999], [Collins &amp; Singer and [Kim al. presented various techniques using co-training schemes for NE extraction seeded by a small list of proper names or hand-crafted NE rules. NE tagging has two tasks: (i) NE chunking; (ii) NE classification. Parsingsupported unsupervised NE learning systems including ours only need to focus on NE classification, assuming the NE chunks have been constructed by the parser. This paper presents a new bootstrapping approach using successive learning and conceptbased seeds. The successive learning is as follows. First, parsing-based NE rules are learned with high precision but limited recall. Then, these rules are applied to a large raw corpus to automatically generate a tagged corpus. Finally, a high-performance HMM-based NE tagger is trained using this corpus. Unlike co-training, our bootstrapping does not involve iterative learning between the two learners, hence it suffers little from error propagation which is commonly associated with iterative learning. To derive the parsing-based learner, the system only requires a few common noun or pronoun seeds that correspond to the concept for the tar- NE, e.g. PERSON NE. Such concept-based seeds share grammatical structures with the corresponding NEs, hence a parser is utilized to support bootstrapping. Since pronouns and common nouns occur more often than NE instances, the parsing-based NE rules can be learned in one iteration to avoid iterative learning. The benchmarking shows that this system approaches the performance of supervised NE taggers for two of the three proper name NE types in MUC, namely, PER NE and LOC NE. This approach also supports tagging user-defined NE types. 2 Implementation Figure 1 shows the overall system architecture. Before the bootstrapping is started, a large raw training corpus is parsed. The bootstrapping experiment reported in this paper is based on a corpus containing ~100,000 news articles and totally ~88,000,000 words. The parsed corpus is saved into a repository, which supports fast retrieval by keyword based indexing scheme. Figure 1. Bootstrapping System Architecture The unsupervised bootstrapping is performed as follows: 1. User provides concept-based seeds; 2. Retrieve parsing structures involving concept-based seeds from the repository to train a decision list for NE classification; 3. Apply the learned rules to the NE candidates retrieved from the repository; 4. Construct an NE annotated corpus using the tagged proper names and their neighboring words; 5. Train an HMM based on the annotated corpus. A parser is necessary for concept-based NE bootstrapping. This is due to the fact that conceptbased seeds only share pattern similarity with the corresponding NEs at structural level, not at string sequence level. In fact, the anaphoric function of pronouns and common nouns to represent antecedent NEs indicates the substitutability of proper names by the noun phrases headed by the corresponding common nouns or pronouns. For examman substitute the proper name almost all structural patterns. Five binary dependency relationships decoded by our parser are used for parsing-based NE rule learning: (i) a Has_Predicate(b): from logical subverb (ii) a Object_Of(b): from logical object a to verb b; (iii) a Has_Amod(b): from noun its adjective modifier (iv) a Possess(b): the possessive noun-modifier head noun (v) a IsA(b): equivalence relation (including from one NP another NP The concept-based seeds used in the experiare: (i) she, his, her, him, man, woman PER; (ii) province, town, village LOC; firm, organization, bank, airline, army, committee, government, school, university for ORG. From the parsed corpus in the repository, all instances (821,267) of the concept-based seeds involved in the five dependency relations are retrieved. Each seed instance was assigned a concept tag corresponding to NE. For example, each of marked as PER. The instances with concept tagging plus their associated parsing relationships are equivalent to an annotated NE corpus. Based on this training corpus, the Decision List Learning algorithm [Segal &amp; Etzioni 1994] is used. The accuracy of each rule was evaluated using Laplace smoothing as follows, accuracy positive 1 + positive negative NE category No. + + As the PER tag dominates the corpus due to the occurrence frequency of is biased towards PER as the answer. To correct this bias, we employ the following modification scheme for instance count. Suppose there are a toof PER instances, LOC instances, instances, then in the process of rule accuracy evaluation, the involved instance count for any NE type will be adjusted by the coefficient , N , N PER LOC ORG A total of 1,290 parsing-based NE rules, shown in samples below, are learned, with accuracy higher than 0.9. ............ Due to the unique equivalence nature of the IsA we add the following rules to top of the decision list: of the e.g. Repository (parsed corpus) NE tagging using parsing-based rules parsing-based NE rules training corpus based on tagged NEs</abstract>
<title confidence="0.844523">Concept-based Seeds Decision List NE Learning NE Learning Bootstrapping Procedure NE Tagger</title>
<abstract confidence="0.957086327586207">The parsing-based first learner is used to tag a raw corpus. First, we retrieve all the named entity candidates associated with at least one of the five parsing relationships from the repository. After applying the decision list to the retrieved 1,607,709 NE candidates, 33,104 PER names, 16,426 LOC names, and 11,908 ORG names are tagged. In order to improve the bootstrapping performance, we the heuristic tag per domain for multi- NE addition to the sense per discourse [Gale al These heuristics are found to be very helpful in both increasing positive instances (i.e. tag propagation) and decreasing the spurious instances (i.e. tag elimination). The tag propagation/elimination scheme is adopted from [Yarowsky 1995]. After this step, a total of 367,441 proper names are classified, including 134,722 PER names, 186,488 LOC names, and 46,231 ORG names. The classified proper name instances lead to the construction of an automatically tagged training corpus, consisting of the NE instances and their two (left and right) neighboring words within the same sentence. In the final stage, a bi-gram HMM is trained based on the above training corpus. The HMM training process follows [Bikel 1997]. 3 Benchmarking We used the same blind testing corpus of 300,000 words containing 20,000 PER, LOC and ORG instances to measure performance degradation of unsupervised learning from the existing supervised NE tagger (Table 1, P for Precision, R for Recall, F for F-measure and F/D for F-measure degradation). Table 1: Supervised-to-Unsupervised NE Degradation Supervised NE Unsupervised NE TYPE P R F P R F F/D PER 92.3% 93.1% 92.7% 86.6% 88.9% 87.7% 5.0% LOC 89.0% 87.7% 88.3% 82.9% 81.7% 82.3% 6.0% ORG 85.7% 87.8% 86.7% 57.1% 48.9% 52.7% 34.0% The performance for PER and LOC are above 80%, and approaching the performance of supervised learning. The reason of the unsatisfactory performance of ORG (52.7%) is not difficult to understand. There are numerous sub-types of ORG that cannot be represented by the less than a dozen concept-based seeds used for this experiment. In addition to the key NE types in MUC, we also tested this method for recognizing userdefined NE types. We use the following conceptseeds for PRODUCT (PRO) NE: truck, vehicle, product, plane, aircraft, computer, software, operating system, database, book, platform, Table 2 shows the benchmarks for PRODUCT tagging.</abstract>
<note confidence="0.907387970588236">Table 2: Performance for PRODUCT NE TYPE PRECISION RECALL F-MEASURE PRODUCT 67.27% 72.52% 69.80% References Bikel, D. M. 1997. Nymble: a high-performance learnname-finder. of 194-201, Morgan Kaufmann Publishers. A. 1998. Description of the MENE Entity System. of Collins, M. and Y. Singer. 1999. Unsupervised Models Named Entity Classification. of the Joint SIGAT Conference on EMNLP and for Computational tics, 1999. Cucchiarelli, A. and P. Velardi. 2001. Unsupervised Named Entity Recognition Using Syntactic and Se- Contextual Evidence. Linguis- Volume 27, Number 1, 123-131. Cucerzan, S. and D. Yarowsky. 1999. Language Independent Named Entity Recognition Combining and Contextual Evidence. Proceedings of the Joint SIGDAT Conference on EMNLP 90-99. Gale, W., K. Church, and D. Yarowsky. 1992. One Per Discourse. of the 4th DARPA and Natural Language 233-237. Kim, J., I. Kang, and K. Choi. 2002. Unsupervised Named Entity Classification Models and their Enof COLING 2002. MUC-7, 1998. Proceedings of the Seventh Message Understanding Conference (MUC-7), published on the website http://www.muc.saic.com/ Segal, R. and O. Etzioni. 1994. Learning decision lists homogeneous rules. of the 12th</note>
<title confidence="0.689618">Conference on Artificial</title>
<author confidence="0.677397">Unsupervised Word Sense Rivaling Supervised Method Pro-</author>
<intro confidence="0.693475">of ACL</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D M Bikel</author>
</authors>
<title>Nymble: a high-performance learning name-finder.</title>
<date>1997</date>
<booktitle>Proceedings of ANLP’97,</booktitle>
<pages>194--201</pages>
<publisher>Morgan Kaufmann Publishers.</publisher>
<contexts>
<context position="8372" citStr="Bikel 1997" startWordPosition="1326" endWordPosition="1327">on) and decreasing the spurious instances (i.e. tag elimination). The tag propagation/elimination scheme is adopted from [Yarowsky 1995]. After this step, a total of 367,441 proper names are classified, including 134,722 PER names, 186,488 LOC names, and 46,231 ORG names. The classified proper name instances lead to the construction of an automatically tagged training corpus, consisting of the NE instances and their two (left and right) neighboring words within the same sentence. In the final stage, a bi-gram HMM is trained based on the above training corpus. The HMM training process follows [Bikel 1997]. 3 Benchmarking We used the same blind testing corpus of 300,000 words containing 20,000 PER, LOC and ORG instances to measure performance degradation of unsupervised learning from the existing supervised NE tagger (Table 1, P for Precision, R for Recall, F for F-measure and F/D for F-measure degradation). Table 1: Supervised-to-Unsupervised NE Degradation Supervised NE Unsupervised NE TYPE P R F P R F F/D PER 92.3% 93.1% 92.7% 86.6% 88.9% 87.7% 5.0% LOC 89.0% 87.7% 88.3% 82.9% 81.7% 82.3% 6.0% ORG 85.7% 87.8% 86.7% 57.1% 48.9% 52.7% 34.0% The performance for PER and LOC are above 80%, and a</context>
</contexts>
<marker>Bikel, 1997</marker>
<rawString>Bikel, D. M. 1997. Nymble: a high-performance learning name-finder. Proceedings of ANLP’97, 194-201, Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Borthwick</author>
</authors>
<title>Description of the MENE named Entity System.</title>
<date>1998</date>
<booktitle>Proceedings of MUC-7.</booktitle>
<contexts>
<context position="1228" citStr="Borthwick 1998" startWordPosition="183" endWordPosition="184">n the parsing-based NE rules. Then, a Hidden Markov Model is trained on a corpus automatically tagged by the first learner. The resulting NE system approaches supervised NE performance for some NE types. 1 Overview Recognizing and classifying proper names is a fundamental task for information extraction. Three types of proper names are defined in the Message Understanding Conference (MUC) Named Entity (NE) standards, namely, PERSON (PER), ORGANIZATION (ORG), and LOCATION (LOC). [MUC-7 1998] There is considerable research on NE tagging using supervised machine learning [e.g. Bikel et al. 1997; Borthwick 1998]. To overcome the knowledge bottleneck of supervised learning, unsupervised machine learning has been applied to NE. [Cucchiarelli &amp; Velardi 2001] discussed boosting the performance of an existing NE tagger by unsupervised learning based on parsing structures. [Cucerzan &amp; Yarowsky 1999], [Collins &amp; Singer 1999] and [Kim et al. 2002] presented various techniques using co-training schemes for NE extraction seeded by a small list of proper names or hand-crafted NE rules. NE tagging has two tasks: (i) NE chunking; (ii) NE classification. Parsingsupported unsupervised NE learning systems including</context>
</contexts>
<marker>Borthwick, 1998</marker>
<rawString>Borthwick, A. et al. 1998. Description of the MENE named Entity System. Proceedings of MUC-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>Y Singer</author>
</authors>
<title>Unsupervised Models for Named Entity Classification.</title>
<date>1999</date>
<booktitle>Proceedings of the Joint SIGAT Conference on EMNLP and VLC. ???Association for Computational Linguistics,</booktitle>
<contexts>
<context position="1540" citStr="Collins &amp; Singer 1999" startWordPosition="228" endWordPosition="231"> Three types of proper names are defined in the Message Understanding Conference (MUC) Named Entity (NE) standards, namely, PERSON (PER), ORGANIZATION (ORG), and LOCATION (LOC). [MUC-7 1998] There is considerable research on NE tagging using supervised machine learning [e.g. Bikel et al. 1997; Borthwick 1998]. To overcome the knowledge bottleneck of supervised learning, unsupervised machine learning has been applied to NE. [Cucchiarelli &amp; Velardi 2001] discussed boosting the performance of an existing NE tagger by unsupervised learning based on parsing structures. [Cucerzan &amp; Yarowsky 1999], [Collins &amp; Singer 1999] and [Kim et al. 2002] presented various techniques using co-training schemes for NE extraction seeded by a small list of proper names or hand-crafted NE rules. NE tagging has two tasks: (i) NE chunking; (ii) NE classification. Parsingsupported unsupervised NE learning systems including ours only need to focus on NE classification, assuming the NE chunks have been constructed by the parser. This paper presents a new bootstrapping approach using successive learning and conceptbased seeds. The successive learning is as follows. First, parsing-based NE rules are learned with high precision but l</context>
</contexts>
<marker>Collins, Singer, 1999</marker>
<rawString>Collins, M. and Y. Singer. 1999. Unsupervised Models for Named Entity Classification. Proceedings of the Joint SIGAT Conference on EMNLP and VLC. ???Association for Computational Linguistics, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Cucchiarelli</author>
<author>P Velardi</author>
</authors>
<title>Unsupervised Named Entity Recognition Using Syntactic and Semantic Contextual Evidence.</title>
<date>2001</date>
<journal>Computational Linguistics, Volume</journal>
<volume>27</volume>
<pages>123--131</pages>
<contexts>
<context position="1374" citStr="Cucchiarelli &amp; Velardi 2001" startWordPosition="203" endWordPosition="206">ting NE system approaches supervised NE performance for some NE types. 1 Overview Recognizing and classifying proper names is a fundamental task for information extraction. Three types of proper names are defined in the Message Understanding Conference (MUC) Named Entity (NE) standards, namely, PERSON (PER), ORGANIZATION (ORG), and LOCATION (LOC). [MUC-7 1998] There is considerable research on NE tagging using supervised machine learning [e.g. Bikel et al. 1997; Borthwick 1998]. To overcome the knowledge bottleneck of supervised learning, unsupervised machine learning has been applied to NE. [Cucchiarelli &amp; Velardi 2001] discussed boosting the performance of an existing NE tagger by unsupervised learning based on parsing structures. [Cucerzan &amp; Yarowsky 1999], [Collins &amp; Singer 1999] and [Kim et al. 2002] presented various techniques using co-training schemes for NE extraction seeded by a small list of proper names or hand-crafted NE rules. NE tagging has two tasks: (i) NE chunking; (ii) NE classification. Parsingsupported unsupervised NE learning systems including ours only need to focus on NE classification, assuming the NE chunks have been constructed by the parser. This paper presents a new bootstrapping</context>
</contexts>
<marker>Cucchiarelli, Velardi, 2001</marker>
<rawString>Cucchiarelli, A. and P. Velardi. 2001. Unsupervised Named Entity Recognition Using Syntactic and Semantic Contextual Evidence. Computational Linguistics, Volume 27, Number 1, 123-131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cucerzan</author>
<author>D Yarowsky</author>
</authors>
<title>Language Independent Named Entity Recognition Combining Morphological and Contextual Evidence.</title>
<date>1999</date>
<booktitle>Proceedings of the Joint SIGDAT Conference on EMNLP and VLC,</booktitle>
<pages>90--99</pages>
<contexts>
<context position="1515" citStr="Cucerzan &amp; Yarowsky 1999" startWordPosition="224" endWordPosition="227"> for information extraction. Three types of proper names are defined in the Message Understanding Conference (MUC) Named Entity (NE) standards, namely, PERSON (PER), ORGANIZATION (ORG), and LOCATION (LOC). [MUC-7 1998] There is considerable research on NE tagging using supervised machine learning [e.g. Bikel et al. 1997; Borthwick 1998]. To overcome the knowledge bottleneck of supervised learning, unsupervised machine learning has been applied to NE. [Cucchiarelli &amp; Velardi 2001] discussed boosting the performance of an existing NE tagger by unsupervised learning based on parsing structures. [Cucerzan &amp; Yarowsky 1999], [Collins &amp; Singer 1999] and [Kim et al. 2002] presented various techniques using co-training schemes for NE extraction seeded by a small list of proper names or hand-crafted NE rules. NE tagging has two tasks: (i) NE chunking; (ii) NE classification. Parsingsupported unsupervised NE learning systems including ours only need to focus on NE classification, assuming the NE chunks have been constructed by the parser. This paper presents a new bootstrapping approach using successive learning and conceptbased seeds. The successive learning is as follows. First, parsing-based NE rules are learned </context>
</contexts>
<marker>Cucerzan, Yarowsky, 1999</marker>
<rawString>Cucerzan, S. and D. Yarowsky. 1999. Language Independent Named Entity Recognition Combining Morphological and Contextual Evidence. Proceedings of the Joint SIGDAT Conference on EMNLP and VLC, 90-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K Church</author>
<author>D Yarowsky</author>
</authors>
<title>One Sense Per Discourse.</title>
<date>1992</date>
<booktitle>Proceedings of the 4th DARPA Speech and Natural Language Workshop.</booktitle>
<pages>233--237</pages>
<contexts>
<context position="7656" citStr="Gale et al 1992" startWordPosition="1215" endWordPosition="1218">ept-based Seeds Decision List NE Learning HMM NE Learning Bootstrapping Procedure NE Tagger = ) . The parsing-based first learner is used to tag a raw corpus. First, we retrieve all the named entity candidates associated with at least one of the five parsing relationships from the repository. After applying the decision list to the retrieved 1,607,709 NE candidates, 33,104 PER names, 16,426 LOC names, and 11,908 ORG names are tagged. In order to improve the bootstrapping performance, we use the heuristic one tag per domain for multiword NE in addition to the one sense per discourse principle [Gale et al 1992]. These heuristics are found to be very helpful in both increasing positive instances (i.e. tag propagation) and decreasing the spurious instances (i.e. tag elimination). The tag propagation/elimination scheme is adopted from [Yarowsky 1995]. After this step, a total of 367,441 proper names are classified, including 134,722 PER names, 186,488 LOC names, and 46,231 ORG names. The classified proper name instances lead to the construction of an automatically tagged training corpus, consisting of the NE instances and their two (left and right) neighboring words within the same sentence. In the fi</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>Gale, W., K. Church, and D. Yarowsky. 1992. One Sense Per Discourse. Proceedings of the 4th DARPA Speech and Natural Language Workshop. 233-237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kim</author>
<author>I Kang</author>
<author>K Choi</author>
</authors>
<title>Unsupervised Named Entity Classification Models and their Ensembles.</title>
<date>2002</date>
<booktitle>Proceedings of COLING</booktitle>
<contexts>
<context position="1562" citStr="Kim et al. 2002" startWordPosition="233" endWordPosition="236"> are defined in the Message Understanding Conference (MUC) Named Entity (NE) standards, namely, PERSON (PER), ORGANIZATION (ORG), and LOCATION (LOC). [MUC-7 1998] There is considerable research on NE tagging using supervised machine learning [e.g. Bikel et al. 1997; Borthwick 1998]. To overcome the knowledge bottleneck of supervised learning, unsupervised machine learning has been applied to NE. [Cucchiarelli &amp; Velardi 2001] discussed boosting the performance of an existing NE tagger by unsupervised learning based on parsing structures. [Cucerzan &amp; Yarowsky 1999], [Collins &amp; Singer 1999] and [Kim et al. 2002] presented various techniques using co-training schemes for NE extraction seeded by a small list of proper names or hand-crafted NE rules. NE tagging has two tasks: (i) NE chunking; (ii) NE classification. Parsingsupported unsupervised NE learning systems including ours only need to focus on NE classification, assuming the NE chunks have been constructed by the parser. This paper presents a new bootstrapping approach using successive learning and conceptbased seeds. The successive learning is as follows. First, parsing-based NE rules are learned with high precision but limited recall. Then, t</context>
</contexts>
<marker>Kim, Kang, Choi, 2002</marker>
<rawString>Kim, J., I. Kang, and K. Choi. 2002. Unsupervised Named Entity Classification Models and their Ensembles. Proceedings of COLING 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MUC-7</author>
</authors>
<date>1998</date>
<booktitle>Proceedings of the Seventh Message Understanding Conference (MUC-7),</booktitle>
<note>published on the website http://www.muc.saic.com/</note>
<marker>MUC-7, 1998</marker>
<rawString>MUC-7, 1998. Proceedings of the Seventh Message Understanding Conference (MUC-7), published on the website http://www.muc.saic.com/</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Segal</author>
<author>O Etzioni</author>
</authors>
<title>Learning decision lists using homogeneous rules.</title>
<date>1994</date>
<booktitle>Proceedings of the 12th National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="5803" citStr="Segal &amp; Etzioni 1994" startWordPosition="907" endWordPosition="910">, province, town, village for LOC; (iii) company, firm, organization, bank, airline, army, committee, government, school, university for ORG. From the parsed corpus in the repository, all instances (821,267) of the concept-based seeds involved in the five dependency relations are retrieved. Each seed instance was assigned a concept tag corresponding to NE. For example, each instance of he is marked as PER. The instances with concept tagging plus their associated parsing relationships are equivalent to an annotated NE corpus. Based on this training corpus, the Decision List Learning algorithm [Segal &amp; Etzioni 1994] is used. The accuracy of each rule was evaluated using Laplace smoothing as follows, accuracy positive 1 + positive negative NE category No. + + As the PER tag dominates the corpus due to the high occurrence frequency of he and she, learning is biased towards PER as the answer. To correct this bias, we employ the following modification scheme for instance count. Suppose there are a total of NPER PER instances, NLOC LOC instances, NORG ORG instances, then in the process of rule accuracy evaluation, the involved instance count for any NE type will be adjusted by the coefficient min (N , N , N </context>
</contexts>
<marker>Segal, Etzioni, 1994</marker>
<rawString>Segal, R. and O. Etzioni. 1994. Learning decision lists using homogeneous rules. Proceedings of the 12th National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised Word Sense Disambiguation Rivaling Supervised Method.</title>
<date>1995</date>
<booktitle>Proceedings of ACL</booktitle>
<contexts>
<context position="7897" citStr="Yarowsky 1995" startWordPosition="1250" endWordPosition="1251">he five parsing relationships from the repository. After applying the decision list to the retrieved 1,607,709 NE candidates, 33,104 PER names, 16,426 LOC names, and 11,908 ORG names are tagged. In order to improve the bootstrapping performance, we use the heuristic one tag per domain for multiword NE in addition to the one sense per discourse principle [Gale et al 1992]. These heuristics are found to be very helpful in both increasing positive instances (i.e. tag propagation) and decreasing the spurious instances (i.e. tag elimination). The tag propagation/elimination scheme is adopted from [Yarowsky 1995]. After this step, a total of 367,441 proper names are classified, including 134,722 PER names, 186,488 LOC names, and 46,231 ORG names. The classified proper name instances lead to the construction of an automatically tagged training corpus, consisting of the NE instances and their two (left and right) neighboring words within the same sentence. In the final stage, a bi-gram HMM is trained based on the above training corpus. The HMM training process follows [Bikel 1997]. 3 Benchmarking We used the same blind testing corpus of 300,000 words containing 20,000 PER, LOC and ORG instances to meas</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>Yarowsky, David. 1995. Unsupervised Word Sense Disambiguation Rivaling Supervised Method. Proceedings of ACL 1995.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>