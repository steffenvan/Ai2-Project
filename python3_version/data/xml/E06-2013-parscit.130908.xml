<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004425">
<title confidence="0.993315">
Automatic Annotation for All Semantic Layers in FrameNet
</title>
<author confidence="0.961479">
Richard Johansson and Pierre Nugues
</author>
<affiliation confidence="0.967674">
Department of Computer Science, Lund University
</affiliation>
<address confidence="0.9411625">
Box 118
SE-221 00 Lund, Sweden
</address>
<email confidence="0.998575">
{richard, pierre}@cs.lth.se
</email>
<sectionHeader confidence="0.995635" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999857545454546">
We describe a system for automatic an-
notation of English text in the FrameNet
standard. In addition to the conventional
annotation of frame elements and their se-
mantic roles, we annotate additional se-
mantic information such as support verbs
and prepositions, aspectual markers, cop-
ular verbs, null arguments, and slot fillers.
As far as we are aware, this is the first sys-
tem that finds this information automati-
cally.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999946433333333">
Shallow semantic parsing has been an active area
of research during the last few years. Seman-
tic parsers, which are typically based on the
FrameNet (Baker et al., 1998) or PropBank for-
malisms, have proven useful in a number of NLP
projects, such as information extraction and ques-
tion answering. The main reason for their popular-
ity is that they can produce a flat layer of semantic
structure with a fair degree of robustness.
Building English semantic parsers for the
FrameNet standard has been studied widely
(Gildea and Jurafsky, 2002; Litkowski, 2004).
These systems typically address the task of identi-
fying and classifying Frame Elements (FEs), that
is semantic arguments of predicates, for a given
target word (predicate).
Although the FE layer is arguably the most cen-
tral, the FrameNet annotation standard defines a
number of additional semantic layers, which con-
tain information about support expressions (verbs
and prepositions), copulas, null arguments, slot-
fillers, and aspectual particles. This information
can for example be used in a semantic parser to
refine the meaning of a predicate, to link predi-
cates in a sentence together, or possibly to improve
detection and classification of FEs. The task of
automatic reconstruction of the additional seman-
tic layers has not been addressed by any previous
system. In this work, we describe a system that au-
tomatically identifies the entities in those layers.
</bodyText>
<sectionHeader confidence="0.958893" genericHeader="introduction">
2 Introduction to FrameNet
</sectionHeader>
<bodyText confidence="0.999018730769231">
FrameNet (Baker et al., 1998; Johnson et al.,
2003) is a comprehensive lexical database that
lists descriptions of words in the frame-semantic
paradigm (Fillmore, 1976). The core concept is
the frame, which is conceptual structure that rep-
resents a type of situation, object, or event, cou-
pled with a semantic valence description that de-
scribes what kinds of semantic arguments (frame
elements) are allowed or required for that partic-
ular frame. The frames are arranged in an ontol-
ogy using relations such as inheritance (such as the
relation between COMMUNICATION and COM-
MUNICATION_NOISE) and causative-of (such as
KILLING and DEATH).
For each frame, FrameNet lists a set of lemmas
or lexical units (mostly nouns, verbs, and adjec-
tives, but also a few prepositions and adverbs).
When such a word occurs in a sentence, it is called
a target word that evokes the frame. FrameNet
comes with a large set of manually annotated ex-
ample sentences, which is typically used by sta-
tistical systems for training and testing. Figure 1
shows an example of such a sentence. Here,
the target word eat evokes the INGESTION frame.
Three FEs are present: INGESTOR, INGESTIBLES,
and PLACE.
</bodyText>
<page confidence="0.99819">
135
</page>
<bodyText confidence="0.9981185">
Often [an informal group]INGESTOR will eat
[lunch]INGESTIBLES [near a machine or other
work station]PLACE, even though a canteen is
available.
</bodyText>
<figureCaption confidence="0.928032">
Figure 1: A sentence from the FrameNet example
</figureCaption>
<bodyText confidence="0.530797">
corpus, with FEs bracketed and the target word in
italics.
</bodyText>
<sectionHeader confidence="0.893761" genericHeader="method">
3 Semantic Entities in FrameNet
</sectionHeader>
<bodyText confidence="0.9993076">
The semantic annotation in FrameNet consists of
a set of layers. One of the layers defines the tar-
get, and the other layers provide additional infor-
mation with respect to the target. The following
layers are used:
</bodyText>
<listItem confidence="0.9293135">
• The FE layer, which defines the spans and se-
mantic roles of the arguments of the predi-
cate.
• A part-of-speech-specific layer, which con-
</listItem>
<bodyText confidence="0.946323875">
tains aspectual information for verbs; and
copulas, support expressions, and slot filling
information for nouns and adjectives.
• The “Other” layer, containing special cases
such as null arguments.
The semantic entities that we consider in this
article are defined in the second and third of these
layers.
</bodyText>
<subsectionHeader confidence="0.99914">
3.1 Support Expressions
</subsectionHeader>
<bodyText confidence="0.9999812">
Some noun targets, typically denoting events, are
often constructed using support verbs. In this case,
the noun carries most of the semantics (that is, it
evokes the frame), while the verb allows the slots
of the frame to be filled. Thus, the dependents
of a support verb are annotated as FEs, just like
for a verb target. Support verbs are annotated us-
ing the SUPP label on the Noun or Adjective layer.
In the following sentence, there is a support verb
(underwent) for the noun target (operation).
</bodyText>
<subsectionHeader confidence="0.674415333333333">
[Frances Patterson]PATIENT underwent an op-
eration at RMH today and is expected to be hos-
pitalized for a week or more.
</subsectionHeader>
<bodyText confidence="0.9964214375">
The support verbs do not change the core se-
mantics of the noun target (that is, they bear no re-
lation to the frame). However, they may determine
the relation between the FEs and the target (“point-
of-view supports”, such as “undergo an operation”
or “perform an operation”) or provide aspectual
information (such as “start an operation”).
The following sentence shows an example
where a governing verb is not a support verb of the
noun target. An automatic system must be able to
distinguish support verbs from other verbs.
A senior nurse observed the operation.
Although a large majority of the support expres-
sions are verbs, there are additionally some cases
of support prepositions, such as the following ex-
ample:
</bodyText>
<subsectionHeader confidence="0.9628165">
Secret agents of this ilk are at work all the time.
3.2 Copulas
</subsectionHeader>
<bodyText confidence="0.9995355">
Copular verbs, typically be, may be seen as a spe-
cial kind of support verb. They are marked us-
ing the COP label on the Noun or Adjective layer.
There are several uses of copulas:
</bodyText>
<listItem confidence="0.991042">
• Class membership: John is a sailor.
• Qualities: Your literary masterpiece was delicious.
• Location: This was inside a desk drawer.
• Identity: Smithers is the vice-president of the arm-
chair division.
</listItem>
<bodyText confidence="0.837801">
In FrameNet annotation, these uses of the cop-
ular verb are not distinguished.
</bodyText>
<subsectionHeader confidence="0.995029">
3.3 Null Arguments
</subsectionHeader>
<bodyText confidence="0.9651777">
There are constructions that require special argu-
ments to be syntactically valid, but where these ar-
guments have no relation to the semantics of the
sentence. In the example below, it is an example
of this phenomenon.
I hate it when you do that.
Other common cases include existential con-
stuctions (“there are”) and subject requirement of
zero-place predicates (“it rains”). These null argu-
ments are tagged as NULL on the Other layer.
</bodyText>
<subsectionHeader confidence="0.956854">
3.4 Aspectual Particles
</subsectionHeader>
<bodyText confidence="0.851556166666667">
Verb particles that indicate aspectual information
are marked using the ASPECT label. These parti-
cles must be distinguished from particles that are
parts of multiword units, such as carry out.
They just moan on and on about Fergie this and
Fergie that and I ’ve simply had enough.
</bodyText>
<page confidence="0.997459">
136
</page>
<subsectionHeader confidence="0.753292">
3.5 Slot Fillers: GOV and X
</subsectionHeader>
<bodyText confidence="0.999878533333333">
FrameNet annotation contains some information
about the relation of predicates in the same sen-
tence when one predicate is a slot filler (that is,
an argument) of the other. This is most common
for noun target words, typically referring to natu-
ral kinds or artifacts.
In the following example, the target word
fingertips evokes the OBSERVABLE_BODYPARTS
frame, involving two FEs: POSSESSOR (“his”)
and BODY_PART (“fingertips”). This noun phrase
is also a slot filler (that is, an argument) of another
predicate in the sentence: cling on. In FrameNet,
such predicates are annotated using the GOV la-
bel. The constituent that contains the slot filler in
question is called (for lack of a better name) X.
</bodyText>
<subsectionHeader confidence="0.678446">
Shares will boom and John Major will
</subsectionHeader>
<bodyText confidence="0.878003666666667">
[cling on]GOV [by [his]POSSESSOR
[fingertips]BODY_PART ]X.
If GOV and X are present, all FEs must be
contained in the span of the X node, such as
BODY_PART and POSSESSOR above. This may
be of use for automatic FE identifiers.
</bodyText>
<sectionHeader confidence="0.986363" genericHeader="method">
4 Identifying Semantic Entities
</sectionHeader>
<bodyText confidence="0.9995558">
To find the semantic entities in the text, we used
the method that has previously been used for
FE detection: classification of nodes in a parse
tree. We divide the identification process into two
stages:
</bodyText>
<listItem confidence="0.936622">
• The first stage finds SUPP, COP, and GOV.
• The second stage finds NULL, ASP, and X.
</listItem>
<bodyText confidence="0.9995921875">
The reason for this division is that we expect
that the knowledge of the presence of SUPP, COP,
and GOV, which are almost always verbs, is use-
ful when detecting the other entities. The second
stage makes use of the information found in the
first stage. Above all, it is necessary to have infor-
mation about GOV to be able to detect X.
To train the classifiers, we selected the 150 most
common frames and divided the annotated exam-
ple sentences for those frames into a training set
of 100,000 sentences and a test set of 8,000 sen-
tences.
The classifiers used the Support Vector learning
method using the LIBSVM package (Chang and
Lin, 2001). The features used by the classifiers are
listed in Table 1. Apart from the features used by
</bodyText>
<table confidence="0.9550554375">
Features for first and second stage
Target lemma
Target POS
Voice
Available semantic role labels
Position (before or after target)
Head word and POS
Phrase type
Parse tree path from target to node
Features for second stage only
Has SUPP
Has COP
Has GOV
Parse tree path from SUPP to node
Parse tree path from COP to node
Parse tree path from GOV to node
</table>
<tableCaption confidence="0.999755">
Table 1: Features used by the classifiers.
</tableCaption>
<bodyText confidence="0.999843">
Stage 2, most of them are well-known from pre-
vious literature on FE identification and labeling
(Gildea and Jurafsky, 2002; Litkowski, 2004). For
all path features, we used both the traditional con-
stituent parse tree path (as by Gildea and Jurafsky
(2002)) and a dependency tree path (as by Ahn et
al. (2004)). We produced the parse trees using the
parser of Collins (1999).
</bodyText>
<sectionHeader confidence="0.99536" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.99645525">
We applied the system to a test set consisting of
approximately 8,000 sentences.
Because of inconsistent annotation, we did not
evaluate the performance of detection of the EX-
IST tag used in existential constructions. Prelim-
inary experiments indicated that the performance
was very poor.
The results, with confidence intervals at the
95% level, are shown in Table 2. They demon-
strate that the classical approach for FE identifica-
tion, that is classification of nodes in the parse tree,
is as well a viable method for detection of other
kinds of semantic information. The detection of
X shows the poorest performance. This is to be
expected, since it is very dependent on a GOV to
have been detected in the first stage.
The results for detection of aspectual particles
is not very reliable (the confidence interval was
±0.17 for precision and ±0.19 for recall), since
test corpus contained just 25 of these particles.
</bodyText>
<page confidence="0.989473">
137
</page>
<table confidence="0.999918571428571">
P R Fβ=1
SUPP 0.85 ± 0.046 0.64 ± 0.054 0.73
COP 0.90 ± 0.027 0.87 ± 0.030 0.88
NULL 0.76 ± 0.082 0.80 ± 0.080 0.78
ASP 0.83 ± 0.17 0.6 ± 0.19 0.70
GOV 0.79 ± 0.029 0.64 ± 0.030 0.71
X 0.59 ± 0.035 0.49 ± 0.032 0.54
</table>
<tableCaption confidence="0.966398">
Table 2: Results with 95% confidence intervals on
the test set.
</tableCaption>
<sectionHeader confidence="0.990966" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999992904761905">
We have described a system that reconstructs all
semantic layers in FrameNet: in addition to the
traditional task of building the FE layer, it marks
up support expressions, aspectual particles, cop-
ulas, null arguments, and slot filling information
(GOV/X). As far as we know, no previous system
has addressed these tasks.
In the future, we would like to study how the
information provided by the additional layers in-
fluence the performance of the traditional task for
a semantic parser. FE identification, especially
for noun and adjective target words, may be made
easier by knowledge of the additional layers. As
mentioned above, if a support verb is present, its
dependents are arguments of the predicate. The
same holds for copular verbs. GOV/X nodes also
restrict where FEs may occur. In addition, support
verbs (such as “perform” or “undergo” an opera-
tion) may be beneficial when determining the re-
lationship between the FE and the predicate, that
is when assigning semantic roles.
</bodyText>
<sectionHeader confidence="0.999281" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9996039">
David Ahn, Sisay Fissaha, Valentin Jijkoun, and
Maarten de Rijke. 2004. The university of Amster-
dam at Senseval-3: Semantic roles and logic forms.
In Proceedings of SENSEVAL-3.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet Project. In Proceed-
ings of COLING-ACL’98, pages 86–90, Montréal,
Canada.
Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM:
a library for support vector machines.
Michael J. Collins. 1999. Head-driven statistical mod-
els for natural language parsing. Ph.D. thesis, Uni-
versity of Pennsylvania, Philadelphia.
Charles J. Fillmore. 1976. Frame semantics and
the nature of language. Annals of the New York
Academy of Sciences: Conference on the Origin and
Development of Language, 280:20–32.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28(3):245–288.
Christopher Johnson, Miriam Petruck, Collin Baker,
Michael Ellsworth, Josef Ruppenhofer, and Charles
Fillmore. 2003. FrameNet: Theory and Practice.
Ken Litkowski. 2004. Senseval-3 task: Automatic
labeling of semantic roles. In Rada Mihalcea and
Phil Edmonds, editors, Senseval-3: Third Interna-
tional Workshop on the Evaluation of Systems for the
Semantic Analysis of Text, pages 9–12, Barcelona,
Spain, July. Association for Computational Linguis-
tics.
</reference>
<page confidence="0.997337">
138
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.738274">
<title confidence="0.999925">Automatic Annotation for All Semantic Layers in FrameNet</title>
<author confidence="0.999676">Richard Johansson</author>
<author confidence="0.999676">Pierre Nugues</author>
<affiliation confidence="0.999999">Department of Computer Science, Lund University</affiliation>
<address confidence="0.983354">Box 118 SE-221 00 Lund, Sweden</address>
<email confidence="0.926682">richard@cs.lth.se</email>
<email confidence="0.926682">pierre@cs.lth.se</email>
<abstract confidence="0.9839795">We describe a system for automatic annotation of English text in the FrameNet standard. In addition to the conventional annotation of frame elements and their semantic roles, we annotate additional semantic information such as support verbs and prepositions, aspectual markers, copular verbs, null arguments, and slot fillers. As far as we are aware, this is the first system that finds this information automatically.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Ahn</author>
<author>Sisay Fissaha</author>
<author>Valentin Jijkoun</author>
<author>Maarten de Rijke</author>
</authors>
<title>The university of Amsterdam at Senseval-3: Semantic roles and logic forms.</title>
<date>2004</date>
<booktitle>In Proceedings of SENSEVAL-3.</booktitle>
<marker>Ahn, Fissaha, Jijkoun, de Rijke, 2004</marker>
<rawString>David Ahn, Sisay Fissaha, Valentin Jijkoun, and Maarten de Rijke. 2004. The university of Amsterdam at Senseval-3: Semantic roles and logic forms. In Proceedings of SENSEVAL-3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL’98,</booktitle>
<pages>86--90</pages>
<location>Montréal, Canada.</location>
<contexts>
<context position="811" citStr="Baker et al., 1998" startWordPosition="124" endWordPosition="127">.lth.se Abstract We describe a system for automatic annotation of English text in the FrameNet standard. In addition to the conventional annotation of frame elements and their semantic roles, we annotate additional semantic information such as support verbs and prepositions, aspectual markers, copular verbs, null arguments, and slot fillers. As far as we are aware, this is the first system that finds this information automatically. 1 Introduction Shallow semantic parsing has been an active area of research during the last few years. Semantic parsers, which are typically based on the FrameNet (Baker et al., 1998) or PropBank formalisms, have proven useful in a number of NLP projects, such as information extraction and question answering. The main reason for their popularity is that they can produce a flat layer of semantic structure with a fair degree of robustness. Building English semantic parsers for the FrameNet standard has been studied widely (Gildea and Jurafsky, 2002; Litkowski, 2004). These systems typically address the task of identifying and classifying Frame Elements (FEs), that is semantic arguments of predicates, for a given target word (predicate). Although the FE layer is arguably the </context>
<context position="2118" citStr="Baker et al., 1998" startWordPosition="331" endWordPosition="334">yers, which contain information about support expressions (verbs and prepositions), copulas, null arguments, slotfillers, and aspectual particles. This information can for example be used in a semantic parser to refine the meaning of a predicate, to link predicates in a sentence together, or possibly to improve detection and classification of FEs. The task of automatic reconstruction of the additional semantic layers has not been addressed by any previous system. In this work, we describe a system that automatically identifies the entities in those layers. 2 Introduction to FrameNet FrameNet (Baker et al., 1998; Johnson et al., 2003) is a comprehensive lexical database that lists descriptions of words in the frame-semantic paradigm (Fillmore, 1976). The core concept is the frame, which is conceptual structure that represents a type of situation, object, or event, coupled with a semantic valence description that describes what kinds of semantic arguments (frame elements) are allowed or required for that particular frame. The frames are arranged in an ontology using relations such as inheritance (such as the relation between COMMUNICATION and COMMUNICATION_NOISE) and causative-of (such as KILLING and </context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of COLING-ACL’98, pages 86–90, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines.</title>
<date>2001</date>
<contexts>
<context position="8803" citStr="Chang and Lin, 2001" startWordPosition="1463" endWordPosition="1466">s division is that we expect that the knowledge of the presence of SUPP, COP, and GOV, which are almost always verbs, is useful when detecting the other entities. The second stage makes use of the information found in the first stage. Above all, it is necessary to have information about GOV to be able to detect X. To train the classifiers, we selected the 150 most common frames and divided the annotated example sentences for those frames into a training set of 100,000 sentences and a test set of 8,000 sentences. The classifiers used the Support Vector learning method using the LIBSVM package (Chang and Lin, 2001). The features used by the classifiers are listed in Table 1. Apart from the features used by Features for first and second stage Target lemma Target POS Voice Available semantic role labels Position (before or after target) Head word and POS Phrase type Parse tree path from target to node Features for second stage only Has SUPP Has COP Has GOV Parse tree path from SUPP to node Parse tree path from COP to node Parse tree path from GOV to node Table 1: Features used by the classifiers. Stage 2, most of them are well-known from previous literature on FE identification and labeling (Gildea and Ju</context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: a library for support vector machines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia.</location>
<contexts>
<context position="9666" citStr="Collins (1999)" startWordPosition="1618" endWordPosition="1619"> type Parse tree path from target to node Features for second stage only Has SUPP Has COP Has GOV Parse tree path from SUPP to node Parse tree path from COP to node Parse tree path from GOV to node Table 1: Features used by the classifiers. Stage 2, most of them are well-known from previous literature on FE identification and labeling (Gildea and Jurafsky, 2002; Litkowski, 2004). For all path features, we used both the traditional constituent parse tree path (as by Gildea and Jurafsky (2002)) and a dependency tree path (as by Ahn et al. (2004)). We produced the parse trees using the parser of Collins (1999). 5 Evaluation We applied the system to a test set consisting of approximately 8,000 sentences. Because of inconsistent annotation, we did not evaluate the performance of detection of the EXIST tag used in existential constructions. Preliminary experiments indicated that the performance was very poor. The results, with confidence intervals at the 95% level, are shown in Table 2. They demonstrate that the classical approach for FE identification, that is classification of nodes in the parse tree, is as well a viable method for detection of other kinds of semantic information. The detection of X</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael J. Collins. 1999. Head-driven statistical models for natural language parsing. Ph.D. thesis, University of Pennsylvania, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>Frame semantics and the nature of language. Annals of the New York Academy</title>
<date>1976</date>
<booktitle>of Sciences: Conference on the Origin and Development of Language,</booktitle>
<pages>280--20</pages>
<contexts>
<context position="2258" citStr="Fillmore, 1976" startWordPosition="353" endWordPosition="354">es. This information can for example be used in a semantic parser to refine the meaning of a predicate, to link predicates in a sentence together, or possibly to improve detection and classification of FEs. The task of automatic reconstruction of the additional semantic layers has not been addressed by any previous system. In this work, we describe a system that automatically identifies the entities in those layers. 2 Introduction to FrameNet FrameNet (Baker et al., 1998; Johnson et al., 2003) is a comprehensive lexical database that lists descriptions of words in the frame-semantic paradigm (Fillmore, 1976). The core concept is the frame, which is conceptual structure that represents a type of situation, object, or event, coupled with a semantic valence description that describes what kinds of semantic arguments (frame elements) are allowed or required for that particular frame. The frames are arranged in an ontology using relations such as inheritance (such as the relation between COMMUNICATION and COMMUNICATION_NOISE) and causative-of (such as KILLING and DEATH). For each frame, FrameNet lists a set of lemmas or lexical units (mostly nouns, verbs, and adjectives, but also a few prepositions an</context>
</contexts>
<marker>Fillmore, 1976</marker>
<rawString>Charles J. Fillmore. 1976. Frame semantics and the nature of language. Annals of the New York Academy of Sciences: Conference on the Origin and Development of Language, 280:20–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="1180" citStr="Gildea and Jurafsky, 2002" startWordPosition="185" endWordPosition="188">are, this is the first system that finds this information automatically. 1 Introduction Shallow semantic parsing has been an active area of research during the last few years. Semantic parsers, which are typically based on the FrameNet (Baker et al., 1998) or PropBank formalisms, have proven useful in a number of NLP projects, such as information extraction and question answering. The main reason for their popularity is that they can produce a flat layer of semantic structure with a fair degree of robustness. Building English semantic parsers for the FrameNet standard has been studied widely (Gildea and Jurafsky, 2002; Litkowski, 2004). These systems typically address the task of identifying and classifying Frame Elements (FEs), that is semantic arguments of predicates, for a given target word (predicate). Although the FE layer is arguably the most central, the FrameNet annotation standard defines a number of additional semantic layers, which contain information about support expressions (verbs and prepositions), copulas, null arguments, slotfillers, and aspectual particles. This information can for example be used in a semantic parser to refine the meaning of a predicate, to link predicates in a sentence </context>
<context position="9415" citStr="Gildea and Jurafsky, 2002" startWordPosition="1572" endWordPosition="1575">nd Lin, 2001). The features used by the classifiers are listed in Table 1. Apart from the features used by Features for first and second stage Target lemma Target POS Voice Available semantic role labels Position (before or after target) Head word and POS Phrase type Parse tree path from target to node Features for second stage only Has SUPP Has COP Has GOV Parse tree path from SUPP to node Parse tree path from COP to node Parse tree path from GOV to node Table 1: Features used by the classifiers. Stage 2, most of them are well-known from previous literature on FE identification and labeling (Gildea and Jurafsky, 2002; Litkowski, 2004). For all path features, we used both the traditional constituent parse tree path (as by Gildea and Jurafsky (2002)) and a dependency tree path (as by Ahn et al. (2004)). We produced the parse trees using the parser of Collins (1999). 5 Evaluation We applied the system to a test set consisting of approximately 8,000 sentences. Because of inconsistent annotation, we did not evaluate the performance of detection of the EXIST tag used in existential constructions. Preliminary experiments indicated that the performance was very poor. The results, with confidence intervals at the </context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Johnson</author>
<author>Miriam Petruck</author>
<author>Collin Baker</author>
<author>Michael Ellsworth</author>
<author>Josef Ruppenhofer</author>
<author>Charles Fillmore</author>
</authors>
<title>FrameNet: Theory and Practice.</title>
<date>2003</date>
<contexts>
<context position="2141" citStr="Johnson et al., 2003" startWordPosition="335" endWordPosition="338">information about support expressions (verbs and prepositions), copulas, null arguments, slotfillers, and aspectual particles. This information can for example be used in a semantic parser to refine the meaning of a predicate, to link predicates in a sentence together, or possibly to improve detection and classification of FEs. The task of automatic reconstruction of the additional semantic layers has not been addressed by any previous system. In this work, we describe a system that automatically identifies the entities in those layers. 2 Introduction to FrameNet FrameNet (Baker et al., 1998; Johnson et al., 2003) is a comprehensive lexical database that lists descriptions of words in the frame-semantic paradigm (Fillmore, 1976). The core concept is the frame, which is conceptual structure that represents a type of situation, object, or event, coupled with a semantic valence description that describes what kinds of semantic arguments (frame elements) are allowed or required for that particular frame. The frames are arranged in an ontology using relations such as inheritance (such as the relation between COMMUNICATION and COMMUNICATION_NOISE) and causative-of (such as KILLING and DEATH). For each frame,</context>
</contexts>
<marker>Johnson, Petruck, Baker, Ellsworth, Ruppenhofer, Fillmore, 2003</marker>
<rawString>Christopher Johnson, Miriam Petruck, Collin Baker, Michael Ellsworth, Josef Ruppenhofer, and Charles Fillmore. 2003. FrameNet: Theory and Practice.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Litkowski</author>
</authors>
<title>Senseval-3 task: Automatic labeling of semantic roles.</title>
<date>2004</date>
<booktitle>Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<pages>9--12</pages>
<editor>In Rada Mihalcea and Phil Edmonds, editors,</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<contexts>
<context position="1198" citStr="Litkowski, 2004" startWordPosition="189" endWordPosition="190">em that finds this information automatically. 1 Introduction Shallow semantic parsing has been an active area of research during the last few years. Semantic parsers, which are typically based on the FrameNet (Baker et al., 1998) or PropBank formalisms, have proven useful in a number of NLP projects, such as information extraction and question answering. The main reason for their popularity is that they can produce a flat layer of semantic structure with a fair degree of robustness. Building English semantic parsers for the FrameNet standard has been studied widely (Gildea and Jurafsky, 2002; Litkowski, 2004). These systems typically address the task of identifying and classifying Frame Elements (FEs), that is semantic arguments of predicates, for a given target word (predicate). Although the FE layer is arguably the most central, the FrameNet annotation standard defines a number of additional semantic layers, which contain information about support expressions (verbs and prepositions), copulas, null arguments, slotfillers, and aspectual particles. This information can for example be used in a semantic parser to refine the meaning of a predicate, to link predicates in a sentence together, or possi</context>
<context position="9433" citStr="Litkowski, 2004" startWordPosition="1576" endWordPosition="1577"> used by the classifiers are listed in Table 1. Apart from the features used by Features for first and second stage Target lemma Target POS Voice Available semantic role labels Position (before or after target) Head word and POS Phrase type Parse tree path from target to node Features for second stage only Has SUPP Has COP Has GOV Parse tree path from SUPP to node Parse tree path from COP to node Parse tree path from GOV to node Table 1: Features used by the classifiers. Stage 2, most of them are well-known from previous literature on FE identification and labeling (Gildea and Jurafsky, 2002; Litkowski, 2004). For all path features, we used both the traditional constituent parse tree path (as by Gildea and Jurafsky (2002)) and a dependency tree path (as by Ahn et al. (2004)). We produced the parse trees using the parser of Collins (1999). 5 Evaluation We applied the system to a test set consisting of approximately 8,000 sentences. Because of inconsistent annotation, we did not evaluate the performance of detection of the EXIST tag used in existential constructions. Preliminary experiments indicated that the performance was very poor. The results, with confidence intervals at the 95% level, are sho</context>
</contexts>
<marker>Litkowski, 2004</marker>
<rawString>Ken Litkowski. 2004. Senseval-3 task: Automatic labeling of semantic roles. In Rada Mihalcea and Phil Edmonds, editors, Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, pages 9–12, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>