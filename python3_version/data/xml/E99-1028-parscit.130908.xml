<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000045">
<note confidence="0.704508">
Proceedings of EACL &apos;99
</note>
<title confidence="0.887968">
Word Sense Disambiguation in Untagged Text based on Term
Weight Learning
</title>
<author confidence="0.825783">
Fumiyo Fukumoto and Yoshimi Suzukit
</author>
<affiliation confidence="0.997732">
Department of Computer Science and Media Engineering,
Yamanashi University
</affiliation>
<address confidence="0.985362">
4-3-11 Takeda, Kofu 400-8511 Japan
</address>
<email confidence="0.981113">
{ fukumo to @ sky e.esb , ysuzuki@windermere.alpsl.esithyamanashi.ac.jp
</email>
<sectionHeader confidence="0.981721" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999979076923077">
This paper describes unsupervised learn-
ing algorithm for disambiguating verbal
word senses using term weight learning.
In our method, collocations which char-
acterise every sense are extracted using
similarity-based estimation. For the re-
sults, term weight learning is performed.
Parameters of term weighting are then
estimated so as to maximise the colloca-
tions which characterise every sense and
minimise the other collocations. The re-
sults of experiment demonstrate the ef-
fectiveness of the method.
</bodyText>
<sectionHeader confidence="0.995511" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999989926829268">
One of the major approaches to disambiguate
word senses is supervised learning (Gale et al.,
1992), (Yarowsky, 1992), (Bruce and Janyce,
1994), (Miller et al., 1994), (Niwa and Nitta,
1994), (Luk, 1995), (Ng and Lee, 1996), (Wilks
and Stevenson, 1998). However, a major obstacle
impedes the acquisition of lexical knowledge from
corpora, i.e. the difficulties of manually sense-
tagging a training corpus, since this limits the ap-
plicability of many approaches to domains where
this hard to acquire knowledge is already avail-
able.
This paper describes unsupervised learning al-
gorithm for disambiguating verbal word senses us-
ing term weight learning. In our approach, an
overlapping clustering algorithm based on Mutual
information-based (Mu) term weight learning be-
tween a verb and a noun is applied to a set of
verbs. It is preferable that Mu is not low (Mu(x,y)
&gt; 3) for a reliable statistical analysis (Church et
al., 1991). However, this suffers from the problem
of data sparseness, i.e. the co-occurrences which
are used to represent every distinct senses does
not appear in the test data. To attack this prob-
lem, for a low Mu value, we distinguish between
unobserved co-occurrences that are likely to oc-
cur in a new corpus and those that are not, by
using similarity-based estimation between two co-
occurrences of words. For the results, term weight
learning is performed. Parameters of term weight-
ing are then estimated so as to maximise the col-
locations which characterise every sense and min-
imise the other collocations.
In the following sections, we first define a pol-
ysemy from the viewpoint of clustering, then de-
scribe how to extract collocations using similarity-
based estimation. Next, we present a clustering
method and a method for verbal word sense dis-
ambiguation using the result of clustering. Fi-
nally, we report on an experiment in order to show
the effect of the method.
</bodyText>
<sectionHeader confidence="0.807011" genericHeader="introduction">
2 Polysemy in Context
</sectionHeader>
<bodyText confidence="0.9994735">
Most previous corpus-based WSD algorithms are
based on the fact that semantically similar words
appear in a similar context. Semantically sim-
ilar verbs, for example, co-occur with the same
nouns. The following sentences from the Wall
Street Journal show polysemous usages of take.
</bodyText>
<listItem confidence="0.7174195">
(sl) Coke has typically taken a minority
stake in such ventures.
(s1&apos;) Guber and pepers tried to buy a stake
in mgm in 1988.
(s2) That process of sorting out specifies is
likely to take time.
</listItem>
<bodyText confidence="0.98718">
(s2&apos;) We spent a lot of time and money in
building our group of stations.
Let us consider a two-dimensional Euclidean space
spanned by the two axes, each associated with
stake and time, and in which take is assigned a
vector whose value of the i-th dimension is the
value of Mu between the verb and the noun as-
signed to the i-th axis. Take co-occurs with the
two nouns, while buy and spend co-occur only
with one of the two nouns. Therefore, the dis-
tances between take and these two verbs are large
</bodyText>
<page confidence="0.997253">
209
</page>
<bodyText confidence="0.9306236">
Proceedings of EACL &apos;99
and the synonymy of take with them disappears.
stake
summarises the sample result from the set {close,
open, end}.
</bodyText>
<figureCaption confidence="0.99974">
Figure 1: The decomposition of the verb take
</figureCaption>
<bodyText confidence="0.999978962962963">
In order to capture the synonymy of take with
the two verbs correctly, one has to decompose the
vector assigned to take into two component vec-
tors, takel and take2, each of which corresponds
to one of the two distinct usages of take (in Figure
1). (we call them hypothetical verbs in the follow-
ing). The decomposition of a vector into a set of
its component vectors requires a proper decom-
position of the context in which the word occurs.
Furthermore, in a general situation, a polysemous
verb co-occurs with a large group of nouns and
one has to divide the group of nouns into a set of
subgroups, each of which correctly characterises
the context for a specific sense of the polysemous
word. Therefore, the algorithm has to be able to
determine when the context of a word should be
divided and how.
The approach proposed in this paper explic-
itly introduces new entities, i.e. hypothetical verbs
when an entity is judged polysemous and asso-
ciates them with contexts which are sub-contexts
of the context of the original entity. Our algorithm
has two basic operations, splitting and lumping.
Splitting means to divide a polysemous verb into
two hypothetical verbs and lumping means to com-
bine two hypothetical verbs to make one verb out
of them (Fukumoto and Tsujii, 1994).
</bodyText>
<sectionHeader confidence="0.88073" genericHeader="method">
3 Extraction of Collocations
</sectionHeader>
<bodyText confidence="0.99960425">
Given a set of verbs, v1, 1)2, • • •, vm, the algorithm
produces a set of semantic clusters, which are or-
dered in the ascending order of their semantic de-
viation values. Semantic deviation is a measure
of the deviation of the set in an n-dimensional
Euclidean space, where n is the number of nouns
which co-occur with the verbs.
In our algorithm, if vi is non-polysemous, it be-
longs to at least one of the resultant semantic clus-
ters. If it is polysemous, the algorithm splits it
into several hypothetical verbs and each of them
belongs to at least one of the clusters. Table 1
</bodyText>
<tableCaption confidence="0.9823">
Table 1: Distinct senses of the verb &apos;close&apos;
</tableCaption>
<figure confidence="0.910116083333333">
vi Mu(vi,n)
closel account 2.116
(open) banking 2.026
acquisition 1.072
book 4.427
bottle 3.650
close2 announcement 1.692
(end) connection 2.745
conversation 4.890
period 1.876
practice 2.564
•
</figure>
<bodyText confidence="0.979986815789474">
In Table 1, subsets &apos;open&apos; and &apos;end&apos; correspond to
the distinct senses of &apos;close&apos;. Mu(vi,n) is the value
of mutual information between a verb and a noun.
If a polysemous verb is followed by a noun which
belongs to a set of the nouns, the meaning of the
verb within the sentence can be determined ac-
cordingly, because a set of the nouns characterises
one of the possible senses of the verb.
The basic assumption of our approach is that
a polysemous verb could not be recognised cor-
rectly if collocations which represent every dis-
tinct senses of a polysemous verb were not
weighted correctly. In particular, for a low Mu
value, we have to distinguish between those unob-
served co-occurrences that are likely to occur in a
new corpus and those that are not. We extracted
these collocations which represent every distinct
senses of a polysemous verb using similarity-based
estimation. Let (wp, nq) and (wp&apos;,:, nq) be two dif-
ferent co-occurrence pairs. We say that wp and
nq are semantically related if wipi and nq are se-
mantically related and (wp, nq) and (wipi, nq) are
semantically similar (Dagan et al., 1993). Us-
ing the estimation, collocations are extracted and
term weight learning is performed. Parameters
of term weighting are then estimated so as to
maximise the collocations which characterise ev-
ery sense and minimise the other collocations.
Let v be two senses, wp and wi, but not be
judged correctly. Let N _Seti be a set of nouns
which co-occur with both v and wp, but do not co-
occur with wi. Let also N _Set2 be a set of nouns
which co-occur with both v and w1, but do not
co-occur with wp, and N _Set3 be a set of nouns
which co-occur with v, wp and WI. Extraction
of collocations using similarity-based estimation
takel &amp;buy take
take2 espend time
</bodyText>
<page confidence="0.897337">
210
</page>
<figure confidence="0.977898045454545">
Proceedings of EACL &apos;99
begin
(a) for all nq E N _Seti - N_Set3 such that Mu(wpmq) &lt; 3
Extract wipa: (1 &lt; i &lt; s) such that Mu(wp&apos; nq) &gt; 3. Here, s is the number of verbs which
co-occur with nq
for all wpii
if wipi exists such that Sim(wp,w; i) &gt; 0
(a-1) then parameters of Mu of (wp,nq) and (v,nq) are set to a (1 &lt; a)
(a-2) else parameters of Mu of (wp,nq) and (v,nq) are set to [3 (0 &lt; &lt; 1)
end_if
end_for
end_for
(b) for all n E N_Set3 such that Mu(wp,a,.) &gt; 3 and Mu(tvi,74) &gt; 3
Extract wpii (1 _&lt; i &lt; t) such that Mu(wp&apos; &gt; 3. Here, t is the number of verbs which
co-occur with
for all wp&apos;i
if wici exists such that Sim(wp,wp&apos; i) &gt; 0 and Sim(wi,wpii) &gt; 0
then parameters of Mu of (v,n,.), (wp,n,.) and (tvi,n,.) are set to 3 (0 &lt; &lt; 1)
end_if
end_for
end_for
end
</figure>
<figureCaption confidence="0.999964">
Figure 2: Extraction of collocations
</figureCaption>
<bodyText confidence="0.997085411764706">
is shown in Figure 2 1 .
In Figure 2, (a-1) is the procedure to extract
collocations which were not weighted correctly
and (a-2) and (b) are the procedures to extract
other words which were not weighted correctly.
Sim(vi,v1i) in Figure 2 is the similarity value of vi
and v: which is measured by the inner product of
their normalised vectors, and is shown in formula
Sim(wp, wipi) &gt; 0. In (a) of Figure 2, for example,
when (wp,nq) is judged to be a collocation which
represents every distinct senses, we set Mu values
of (wp,nq) and (v,nq) to a x Mu(wp,mq) and a x
Mu(v,r4), 1 &lt; a. On the other hand, when nq
is judged not to be a collocation which represents
every distinct senses, we set Mu values of these
co-occurrence pairs to f3 x Mu(wp,r1q) and /3 x
Mu(v,nq), 0 &lt; &lt; 1 2 .
</bodyText>
<sectionHeader confidence="0.44544" genericHeader="method">
4 Clustering a Set of Verbs
</sectionHeader>
<bodyText confidence="0.99646">
Given a set of verbs, VG = {vi, vm}, the algo-
rithm produces a set of semantic clusters, which
are sorted in ascending order of their semantic de-
viation. The deviation value of VG, Dev(VG) is
shown in formula (3).
</bodyText>
<equation confidence="0.994034375">
Sirn(v,v3=
I vi II
Vi
vi = (Vil, • • •
vi X V:
(1)
vii = { M u(vi, if Mu(vi,nj) 23 (2)
0 otherwise
</equation>
<bodyText confidence="0.9513455">
In formula (1), k is the number of nouns which
co-occur with vi. vii is the Mu value between vi
and ni.
We recall that wp and nq are semantically re-
lated if w2; i and nq are semantically related and
(wp,nq) and (wpi i,nq) are semantically similar. (a)
in Figure 2, we represent wpii and nq are se-
mantically related when Mu(w; i,nq) &gt; 3. Also,
(wp,nq) and (wp&apos; i,nq) are semantically similar if
1 For w1, we can replace tv,, with w1, nq E N-Sett -
N _Set3 with n, E N_Seti - N _Set2, and Sim(wp, wpi .)
&gt; 0 with Sim(wi, wp&apos;,) &gt; 0.
</bodyText>
<figure confidence="0.3704594">
Dev(VG)
1
and 7 are
tamed by least square estimation3 .
Mu value between vi and ni. =
</figure>
<footnote confidence="0.7461545">
2 In the experiment, we set increment value of a
and decrease value of 0 to 0.001.
3 Using Wall Street Journal, we obtained 0 = 0.964
and -y = -0.495.
</footnote>
<figure confidence="0.830986142857143">
m n
EDvii
i=1 j=1
(3)
ob-
is the
77.ii vii
</figure>
<page confidence="0.931441">
211
</page>
<bodyText confidence="0.97697725">
Proceedings of EACL &apos;99
is the j-th value of the centre of gravity. I I =
vi1,2 is the length of the centre of
gravity. In formula (3), a set with a smaller value
is considered semantically less deviant.
Figure 3 shows the flow of the clustering algo-
rithm. As shown in `(&apos; in Figure 3, the func-
tion Make-Initial-Cluster-Set applies to VG
and produces all possible pairs of verbs with
their semantic deviation values. The result is a
list of pairs called the ICS (Initial Cluster Set).
The CCS (Created Cluster Set) shows the clus-
ters which have been created so far. The func-
tion Make-Temporary-Cluster-Set retrieves
the clusters from the CCS which contain one of
the verbs of Set. The results (S et p) are passed to
the function Recognition-of-Polysemy, which
determines whether or not a verb is polysemous.
Let v be an element included in both Set i and
Seto. To determine whether v has two senses wp,
where wp is an element of Sets, and wi, where wi
is an element of Seto, we make two clusters, as
shown in (4) and their merged cluster, as shown
in (5).
</bodyText>
<listItem confidence="0.909999">
• • • and Eit Mu(vm, ni). Here, t is the number of
nouns which co-occur with v within the five-word
distance.
</listItem>
<sectionHeader confidence="0.99084" genericHeader="method">
6 Experiment
</sectionHeader>
<bodyText confidence="0.9998785">
This section describes an experiment conducted
to evaluate the performance of our method.
</bodyText>
<subsectionHeader confidence="0.992233">
6.1 Data
</subsectionHeader>
<bodyText confidence="0.994977444444444">
The data we have used is 1989 Wall Street Jour-
nal (WSJ) in ACL/DCI CD-ROM which consists
of 2,878,688 occurrences of part-of-speech tagged
words (Brill, 1992). The inflected forms of the
same nouns and verbs are treated as single units.
For example, &apos;book&apos; and &apos;books&apos; are treated as sin-
gle units. We obtained 5,940,193 word pairs in a
window size of 5 words, 2,743,974 different word
pairs. From these, we selected collocations of a
verb and a noun.
As a test data, we used 40 sets of verbs. We
selected at most four senses for each verb, the best
sense, from among the set of the Collins dictionary
and thesaurus (McLeod, 1987), is determined by
a human judge.
v wr v , w , • • • Wn} 6.2 Results
{V, W1 &amp;quot; • , Wp, &amp;quot; • Wn}
Here, v and wp are verbs and WI., • tar, are verbs
or hypothetical verbs. wi, • •, wp, • wn, in (5)
satisfy D ev (v , wi) &lt; Dev(v , wi) (1 &lt; i &lt; j &lt; n).
vi and v2 in (4) are new hypothetical verbs which
correspond to two distinct senses of v.
If v is a polysemy, but is not recognised cor-
rectly, then Extraction-of-Collocations shown
in Figure 2 is applied. In Extraction-of-
Collocations, for (4) and (5), a and /3 are es-
timated so as to satisfy (6) and (7).
</bodyText>
<equation confidence="0.995017">
Dev(vi,wp) &lt; Dev(v,w1,- • ,wp, • (6)
Dev(v2, , • , &lt; Dev(v, , • • • , wp, • • , tun) (7)
</equation>
<bodyText confidence="0.999788333333333">
The whole process is repeated until the newly ob-
tained cluster, Set.y, contains all the verbs in the
input or the ICS is exhausted.
</bodyText>
<sectionHeader confidence="0.989743" genericHeader="method">
5 Word Sense Disambiguation
</sectionHeader>
<bodyText confidence="0.986863705882353">
We used the result of our clustering analysis,
which consists of pairs of collocations of a distinct
sense of a polysemous verb and a noun.
Let v has senses v1, v2, vm. The sense
of a polysemous verb v is vi (1 &lt; i &lt; m) if
Ejt Mu(vi, n3) is largest among E3 Mu(vi, n3),
The results of the experiment are shown in Table
2, Table 3 and Table 4.
In Table 2, 3 and 4, every polysemous verb has
two, three and four senses, respectively. Column
1 in Table 2, 3 and 4 shows the test data. The
verb v is a polysemous verb and the remains show
these senses. For example, &apos;cause&apos; of (1) in Table
2 has two senses, &apos;effect&apos; and &apos;produce&apos;. &apos;Sentence&apos;
shows the number of sentences of occurrences of
a polysemous verb, and column 4 shows their dis-
tributions. &apos;v&apos; shows the number of polysemous
verbs in the data. W in Table 2 shows the num-
ber of nouns which co-occur with wp and w1. v
fl W shows the number of nouns which co-occur
with both v and W. In a similar way, W in Table
3 and 4 shows the number of nouns which co-occur
with wp w2 and wp w3, respectively. &apos;Correct&apos;
shows the performance of our method. &apos;Total&apos; in
the bottom of Table 4 shows the performance of
40 sets of verbs.
Table 2 shows when polysemous verbs have two
senses, the percentage attained at 80.0%. When
polysemous verbs have three and four senses, the
percentage was 77.7% and 76.4%, respectively.
This shows that there is no striking difference
among them. Column 8 and 9 in Table 2, 3 and
4 show the results of collocations which were ex-
tracted by our method.
</bodyText>
<page confidence="0.995583">
212
</page>
<figure confidence="0.993184714285715">
Proceedings of EACL &apos;99
begin
ICS := Make-Initial-Cluster-Set(VG)
(VG = {vi I i = 1, - . - , m} ICS = {Seti,- - - , Set ,,,(7i)}
where Setp = {v, v1} and Setq = {14,, vi } E ICS (1 &lt; p &lt; q &lt; m) satisfy Dev(vi, vi) &lt; Dev(vk,vi)
for i := 1 to
if CCS = (1)
then Set-f := Set, i.e. Set, is stored in CCS as a newly obtained cluster
else if Seta E CCS exists such that Set, C Seta
then Set, is removed from ICS and Set7 :=
else if
for all Seta E CCS do
if Set, n Seta =
then Set-, := Seti i.e. Set, is stored in CCS as a newly obtained cluster
end_if
end_for
else Seto := Make-Temporary-Cluster-Set(Seti,CCS)
( Seto := Seta E CCS such that Set, n Seta 0 0
Set7 := Recognition-of-Polysemy(Seti,Seto)
if Set7 was not recognised correctly
then for v, wp and w, do
Extraction-of-Collocations.
end_for
1
end_if
endif
end_if
end_if
if Set.). = VG
then exit from the for_loop ;
end_if
end_for
end
m(m-1)
2 do
</figure>
<figureCaption confidence="0.999982">
Figure 3: Flow of the algorithm
</figureCaption>
<bodyText confidence="0.999422875">
Mu &lt; 3 shows the number of nouns which satisfy
Mu(wp,n) &lt; 3 or Mu(wl,n) &lt;3. &apos;Correct&apos; shows
the total number of collocations which could be
estimated correctly. Table 2 — 4 show that the
frequency of v is proportional to that of v 11 W.
As a result, the larger the number of v fl W is,
the higher the percentage of correctness of collo-
cations is.
</bodyText>
<sectionHeader confidence="0.999959" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.997404318181818">
Unsupervised learning approaches, i.e. to de-
termine the class membership of each object to
be classified in a sample without using sense-
tagged training examples of correct classifications,
is considered to have an advantage over supervised
learning algorithms, as it does not require costly
hand-tagged training data.
Schiitze and Zernik&apos;s methods avoid tagging
each occurrence in the training corpus. Their
methods associate each sense of a polysemous
word with a set of its co-occurring words (Schutze,
1992), (Zernik, 1991). If a word has several senses,
then the word is associated with several different
sets of co-occurring words, each of which corre-
sponds to one of the senses of the word. The
weakness of Schiitze and Zernik&apos;s method, how-
ever, is that it solely relies on human intuition for
identifying different senses of a word, i.e. the hu-
man editor has to determine, by her/his intuition,
how many senses a word has, and then identify
the sets of co-occurring words that correspond to
the different senses.
</bodyText>
<page confidence="0.999439">
213
</page>
<tableCaption confidence="0.9232915">
Proceedings of EACL &apos;99
Table 2: The result of disambiguation experiment(two senses)
</tableCaption>
<table confidence="0.999754069767442">
Num {v, top, wi} Sentence wr(%) v v 11 ig Correct(%) Mu &lt; 3 Correct(%)
wi(%)
(1) {cause, effect, produce} 232 89(38.3) 464 254 158(68.1) 118 85(72.0)
143(61.7)
(2) {claim, require affirm} 202 158(78.2) 545 328 160(79.2) 89 71(80.0)
44(21.8)
(3) {close, open, end} 206 92(44.6) 2,025 1,498 162(78.6) 136 120(88.2)
114(55.4)
(4) {fall, decline, win} 278 182(65.5) 697 393 215(77.3) 395 325(82.5)
96(34.5)
(5) {feel, think, sense} 280 178(63.5) 210 53 156(55.7) 39 20(53.1)
102(36.5)
(6) {hit, attack, strike} 250 156(62.4) 452 122 181(72.4) 83 63(77.0)
94(37.6)
(7) {leave, remain, go} 183 41(22.4) 1,409 942 160(87.4) 132 113(86.2)
142(77.6)
(8) {lose,win, get} 301 70(23.3) 2,244 1,920 242(80.3) 329 282(86.0)
231(76.7)
(9) {manage, accomplish, operate} 216 23(10.6) 648 306 165(76.3) 89 71(80.6)
193(89.4)
(10) {occur, happen, exist} 199 137(68.9) 324 180 175(87.9) 136 95(70.3)
62(31.1)
(11) (order, request, arrange) 240 206(85.8) 1,256 831 202(84.1) 138 121(87.7)
34(14.2)
(12) (pass, adopt, succeed} 301 175(58.1) 378 247 259(86.0) 52 41(80.5)
126(41.9)
(13) {post, mail, inform} 274 63(22.9) 91 68 231(84.3) 44 32(72.9)
211(77.1)
(14) {produce, create, grow} 231 129(55.8) 640 370 184(79.6) 296 258(87.1)
102(44.2)
(15) {push, attack, pull} 223 93(41.8) 202 153 189(84.7) 126 97(77.7)
130(58.2)
(16) {save, keep, rescue} 216 149(68-9) 396 354 168(77.7) 115 93(81.6)
a 7(31.1)
(17) {ship, put, send} 218 92(42.2) 361 241 176(80.7) 92 74(80.4)
126(57.8)
(18) {stop, end, move} 244 52(21.4) 993 886 210(86.0) 193 169(87.5)
192(78.6)
(19) {add, append, total} 184 35(19.0) 1,164 778 147(79.8) 164 129(78-6)
149(81.0)
(20) {keep, maintain, protect} 378 231(61.1) 1,266 905 349(92.3) 267 234(87.7)
147(38.9)
Total (2 senses) 4,856 _ 3,332(68.6) 3,889(80.0)
</table>
<bodyText confidence="0.999467821428571">
Yarowsky used an unsupervised learning pro-
cedure to perform noun WSD (Yarowsky, 1995).
This algorithm requires a small number of training
examples to serve as a seed. The result shows that
the average percentage attained was 96.1% for 12
nouns when the training data was a 460 million
word corpus, although Yarowsky uses only nouns
and does not discuss distinguishing more than two
senses of a word.
A more recent unsupervised approach is de-
scribed in (Pedersen and Bruce, 1997). They
presented three unsupervised learning algorithms
that distinguish the sense of an ambiguous word in
untagged text, i.e. McQuitty&apos;s similarity analysis,
Ward&apos;s minimum-variance method and the EM al-
gorithm. These algorithms assign each instance
of an ambiguous word to a known sense definition
based solely on the values of automatically iden-
tifiable features in text. Their methods are per-
haps the most similar to our present work. They
reported that disambiguating nouns is more suc-
cessful rather than adjectives or verbs and the best
result of verbs was McQuitty&apos;s method (71.8%),
although they only tested 13 ambiguous words
(of these, there are only 4 verbs). Furthermore,
each has at most three senses. In future, we will
compare our method with their methods using the
data we used in our experiment.
</bodyText>
<sectionHeader confidence="0.9871" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.9999568">
In this study, we proposed a method for disam-
biguating verbal word senses using term weight
learning based on similarity-based estimation.
The results showed that when polysemous verbs
have two, three and four senses, the average per-
centage attained at 80.0%, 77.7% and 76.4%, re-
spectively. Our method assumes that nouns which
co-occur with a polysemous verb is disambiguated
in advance. In future, we will extend our method
to cope with this problem and also apply our
</bodyText>
<page confidence="0.998656">
214
</page>
<tableCaption confidence="0.925087">
Proceedings of EACL &apos;99
Table 3: The result of disambiguation experiment(three senses)
</tableCaption>
<table confidence="0.99959703030303">
Num (v, w„, wi v)21 Sentence tv(%) v v n W Correct(%) Mu &lt; 3 Correct(%)
11)1(70
{catch, acquire, grab, watch} 240 120(50.0) 447 432 180(75.0) 124 99(79.9)
21(9.0)
199(41.0)
{complete, end, develop, fill} 365 107(29.3) 727 450 280(76.7) 240 193(80.4)
242(66.3)
16(4.4)
{gain, win, get, increase} 334 47(14.0) 527 467 270(80.8) 187 152(81.4)
228(68.2)
59(17.8)
{grow, increase, develop become} 310 68(21.9) 903 651 241(77.7) 372 305(82.0)
132(42.5)
110(35.6)
{operate, run, act, control} 232 76(32.7) 812 651 187(80.6) 311 255(82.3)
83(35.7-)
73(31.6)
{rise, increase, appear, grow} 276 51(18.4) 711 414 198(71.7) 372 294(79.1)
137(49.6)
88(32.0)
{see, look, know, feel} 318 128(40.2) 1,785 934 263(82.7) 497 414(83.4)
162(50.9)
28(8.9)
{want, desire, search, lack} 267 66(24.7) 590 470 208(77.9) 198 159(80.8)
53(19.8)
148(55.5)
{lead, cause, guide, precede} 183 139(75.9) 548 456 138(75.4) 274 221(80.9)
38(20.7)
6(3.4)
{carry, bring, capture, behave} 186 142(76.3) 474 440 142(76.3) 207 167(80.7)
39(20.9)
5(2.8)
Total (3 senses) 2,711 1,573(56.5) 2,107(77.7)
</table>
<bodyText confidence="0.968297">
method to not only a verb but also a noun and
an adjective sense disambiguation to evaluate our
method.
</bodyText>
<sectionHeader confidence="0.994079" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99973075">
The authors would like to thank the reviewers
for their valuable comments. This work was sup-
ported by the Grant-in-aid for the Japan Society
for the Promotion of Science(JSPS).
</bodyText>
<sectionHeader confidence="0.998089" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.946256184210526">
E. Brill. 1992. A simple rule-based part of speech
tagger. In Proc. of the 3rd Conference on Ap-
plied Natural Language Processing, pages 152-
155.
R. Bruce and W. Janyce. 1994. Word-sense dis-
ambiguation using decomposable models. In
Proc. of the 32nd Annual Meeting, pages 139-
145.
K. W. Church, W. Gale, P. Hanks, and D. Hindle.
1991. Using statistics in lexical analysis. In
Lexical acquisition: Exploiting on-line resources
to build a lexicon, pages 115-164. (Zernik Uri
(ed.)), London, Lawrence Erlbaum Associates.
I. Dagan, P. Fernando, and L. Lilian. 1993. Con-
textual word similarity and estimation from
sparse data. In Proc. of the 31th Annual Meet-
ing of the ACL, pages 164-171.
F. Fukumoto and J. Tsujii. 1994. Automatic
recognition of verbal polysemy. In Proc. of the
15th COLING, Kyoto, Japan, pages 762-768.
W. K. Gale, K. W. Church, and D. Yarowsky.
1992. A method for disambiguating word senses
in a large corpus. In Computers and the Hu-
manities, volume 26, pages 415-439.
A. K. Luk. 1995. Statistical sense disambiguation
with relatively small corpora using dictionary
definitions. In Proc. of the 33st Annual Meeting
of ACL, pages 181-188.
W. T. McLeod. 1987. The new collins dictionary
and thesaurus in one volume. London, Harper-
Collins Publishers.
G. Miller, C. Martin, L. Shari, L. Claudia, and
R. G. Thomas. 1994. Using a semantic concor-
dance for sense identification. In Proc. of the
ARPA Workshop on Human Language Technol-
ogy, pages 240-243.
H. T. Ng and H. B. Lee. 1996. Integrating mul-
tiple knowledge sources to disambiguate word
</reference>
<page confidence="0.999098">
215
</page>
<tableCaption confidence="0.887587">
Proceedings of EACL &apos;99
Table 4: The result of disambiguation experiment(four senses)
</tableCaption>
<figure confidence="0.97193464">
Num {v, wp, wi, w2, w3} Sentence wp(%) v v il W Correct(%) Mu &lt; 3 Correct(%)
wi(%)
w2(%)
W3(%)
(31) {develop, create, grow, improve, 187 117(62.5) 922 597 155(82.8) 253 218(86.1)
expand}
34(181
4(2.1
32(17.3
(32) {face, confront, cover, lie, turn} 222 54(24.3) 859 567 184(82.8) 178 154(86.5)
103(46.3)
12(5.4)
53(24.0)
(33) {get, become, lose, understand, 302 88(29.1) 762 513 229(75.8) 424 365(86.2)
catch} 98
34 32.1
11.2
82 27.3
(34) {go, come, become, run, fit} 217 101(46.5) 732 435 145(66.8) 374 302(80.9)
66(30.4)
36(16.5)
14(6.6)
(35) {make, create, do, get, behave} 227 123(54.1) 783 555 178(78.4) 435 370(85.2)
28(12.3i
58(25.5
18(8.1
(36) {show, appear, inform, prove, 227 121(53.3) 996 560 181(79.7) 258 214(83.2)
express} 16(7.0)
40(17.6)
50(22.1)
(37) {take, buy, obtain, spend, bring} 246 20(8.1) 2,742 1,244 179(72.7) 829 677(81.6)
123150
42 17.0
1
61 24.9
(38) {hold, keep, carry, reserve, 145 7(4.8) 727 459 111(76.5) 394 300(76.2)
accept} 53(36.5)
2(1.5)
83(57.2)
(39) {raise, lift, increase, create, 204 2(1.1) 746 491 151(74.0) 341 272(79.7)
collect}
8139.7i
86 42.1
35 17.1
(40) {draw, attract, pull, close, 162 78(48.1) 798 533 123(75.9) 143 119(83.2)
write} 13(8.0)
43(26.5)
28(17.4)
Total (4 senses) 2,139 1,636(76.4)
Total 9,706 1 7,572(78.6) II
</figure>
<reference confidence="0.9974803">
sense: An examplar-based approach. In Proc.
of the 34th Annual Meeting of A CL, pages 40-
47.
Y. Niwa and Y. Nitta. 1994. Co-occurrence vec-
tors from corpora vs. distance vectors from dic-
tionaries. In Proc. of 15th COLING, Kyoto,
Japan, pages 304-309.
T. Pedersen and R. Bruce. 1997. Distinguishing
word senses in untagged text. In Proc. of the
2nd Conference on Empirical Methods in Natu-
ral Language Processing, pages 197-207.
H. Schutze. 1992. Dimensions of meaning. In
Proc. of Supercomputing, pages 787-796.
Y. Wilks and M. Stevenson. 1998. Word sense dis-
ambiguation using optimised combinations of
knowledge sources. In Proc. of the COLING-
A C L &apos;98, pages 1398-1402.
D. Yarowsky. 1992. Word sense disambiguation
using statistical models of roget&apos;s categories
trained on large corpora. In Proc. of the 14th
COLING, pages 454-460.
D. Yarowsky. 1995. Unsupervised word sense dis-
ambiguation rivaling supervised methods. In
Proc. of the 33rd Annual Meeting of the ACL,
pages 189-196.
U. Zernik. 1991. Trainl vs. train2: Tagging
word senses in corpus. In Lexical acquisi-
tion: Exploiting on-line resources to build a lex-
icon, pages 91-112. Uri Zernik(Ed.), London,
Lawrence Erlbaum Associates.
</reference>
<page confidence="0.999145">
216
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.625805">
<note confidence="0.707914">Proceedings of EACL &apos;99</note>
<title confidence="0.975726">Word Sense Disambiguation in Untagged Text based on Term Weight Learning</title>
<author confidence="0.994115">Fumiyo Fukumoto</author>
<author confidence="0.994115">Yoshimi Suzukit</author>
<affiliation confidence="0.9995085">Department of Computer Science and Media Engineering, Yamanashi University</affiliation>
<address confidence="0.991617">4-3-11 Takeda, Kofu 400-8511 Japan</address>
<email confidence="0.978277">fukumo@e.esb,ysuzuki@windermere.alpsl.esithyamanashi.ac.jp</email>
<abstract confidence="0.997309357142857">This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. our method, characterise every sense are extracted using similarity-based estimation. For the results, term weight learning is performed. Parameters of term weighting are then estimated so as to maximise the collocations which characterise every sense and minimise the other collocations. The results of experiment demonstrate the effectiveness of the method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<booktitle>In Proc. of the 3rd Conference on Applied Natural Language Processing,</booktitle>
<pages>152--155</pages>
<contexts>
<context position="11965" citStr="Brill, 1992" startWordPosition="2135" endWordPosition="2136">ent included in both Set i and Seto. To determine whether v has two senses wp, where wp is an element of Sets, and wi, where wi is an element of Seto, we make two clusters, as shown in (4) and their merged cluster, as shown in (5). • • • and Eit Mu(vm, ni). Here, t is the number of nouns which co-occur with v within the five-word distance. 6 Experiment This section describes an experiment conducted to evaluate the performance of our method. 6.1 Data The data we have used is 1989 Wall Street Journal (WSJ) in ACL/DCI CD-ROM which consists of 2,878,688 occurrences of part-of-speech tagged words (Brill, 1992). The inflected forms of the same nouns and verbs are treated as single units. For example, &apos;book&apos; and &apos;books&apos; are treated as single units. We obtained 5,940,193 word pairs in a window size of 5 words, 2,743,974 different word pairs. From these, we selected collocations of a verb and a noun. As a test data, we used 40 sets of verbs. We selected at most four senses for each verb, the best sense, from among the set of the Collins dictionary and thesaurus (McLeod, 1987), is determined by a human judge. v wr v , w , • • • Wn} 6.2 Results {V, W1 &amp;quot; • , Wp, &amp;quot; • Wn} Here, v and wp are verbs and WI., •</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>E. Brill. 1992. A simple rule-based part of speech tagger. In Proc. of the 3rd Conference on Applied Natural Language Processing, pages 152-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bruce</author>
<author>W Janyce</author>
</authors>
<title>Word-sense disambiguation using decomposable models.</title>
<date>1994</date>
<booktitle>In Proc. of the 32nd Annual Meeting,</booktitle>
<pages>139--145</pages>
<contexts>
<context position="982" citStr="Bruce and Janyce, 1994" startWordPosition="137" endWordPosition="140">earning algorithm for disambiguating verbal word senses using term weight learning. In our method, collocations which characterise every sense are extracted using similarity-based estimation. For the results, term weight learning is performed. Parameters of term weighting are then estimated so as to maximise the collocations which characterise every sense and minimise the other collocations. The results of experiment demonstrate the effectiveness of the method. 1 Introduction One of the major approaches to disambiguate word senses is supervised learning (Gale et al., 1992), (Yarowsky, 1992), (Bruce and Janyce, 1994), (Miller et al., 1994), (Niwa and Nitta, 1994), (Luk, 1995), (Ng and Lee, 1996), (Wilks and Stevenson, 1998). However, a major obstacle impedes the acquisition of lexical knowledge from corpora, i.e. the difficulties of manually sensetagging a training corpus, since this limits the applicability of many approaches to domains where this hard to acquire knowledge is already available. This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. In our approach, an overlapping clustering algorithm based on Mutual information-based (Mu) te</context>
</contexts>
<marker>Bruce, Janyce, 1994</marker>
<rawString>R. Bruce and W. Janyce. 1994. Word-sense disambiguation using decomposable models. In Proc. of the 32nd Annual Meeting, pages 139-145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>W Gale</author>
<author>P Hanks</author>
<author>D Hindle</author>
</authors>
<title>Using statistics in lexical analysis.</title>
<date>1991</date>
<booktitle>In Lexical acquisition: Exploiting on-line resources to build a lexicon,</booktitle>
<pages>115--164</pages>
<editor>Zernik Uri (ed.)),</editor>
<location>London, Lawrence Erlbaum Associates.</location>
<contexts>
<context position="1764" citStr="Church et al., 1991" startWordPosition="264" endWordPosition="267">f lexical knowledge from corpora, i.e. the difficulties of manually sensetagging a training corpus, since this limits the applicability of many approaches to domains where this hard to acquire knowledge is already available. This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. In our approach, an overlapping clustering algorithm based on Mutual information-based (Mu) term weight learning between a verb and a noun is applied to a set of verbs. It is preferable that Mu is not low (Mu(x,y) &gt; 3) for a reliable statistical analysis (Church et al., 1991). However, this suffers from the problem of data sparseness, i.e. the co-occurrences which are used to represent every distinct senses does not appear in the test data. To attack this problem, for a low Mu value, we distinguish between unobserved co-occurrences that are likely to occur in a new corpus and those that are not, by using similarity-based estimation between two cooccurrences of words. For the results, term weight learning is performed. Parameters of term weighting are then estimated so as to maximise the collocations which characterise every sense and minimise the other collocation</context>
</contexts>
<marker>Church, Gale, Hanks, Hindle, 1991</marker>
<rawString>K. W. Church, W. Gale, P. Hanks, and D. Hindle. 1991. Using statistics in lexical analysis. In Lexical acquisition: Exploiting on-line resources to build a lexicon, pages 115-164. (Zernik Uri (ed.)), London, Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>P Fernando</author>
<author>L Lilian</author>
</authors>
<title>Contextual word similarity and estimation from sparse data.</title>
<date>1993</date>
<booktitle>In Proc. of the 31th Annual Meeting of the ACL,</booktitle>
<pages>164--171</pages>
<contexts>
<context position="7137" citStr="Dagan et al., 1993" startWordPosition="1194" endWordPosition="1197">f collocations which represent every distinct senses of a polysemous verb were not weighted correctly. In particular, for a low Mu value, we have to distinguish between those unobserved co-occurrences that are likely to occur in a new corpus and those that are not. We extracted these collocations which represent every distinct senses of a polysemous verb using similarity-based estimation. Let (wp, nq) and (wp&apos;,:, nq) be two different co-occurrence pairs. We say that wp and nq are semantically related if wipi and nq are semantically related and (wp, nq) and (wipi, nq) are semantically similar (Dagan et al., 1993). Using the estimation, collocations are extracted and term weight learning is performed. Parameters of term weighting are then estimated so as to maximise the collocations which characterise every sense and minimise the other collocations. Let v be two senses, wp and wi, but not be judged correctly. Let N _Seti be a set of nouns which co-occur with both v and wp, but do not cooccur with wi. Let also N _Set2 be a set of nouns which co-occur with both v and w1, but do not co-occur with wp, and N _Set3 be a set of nouns which co-occur with v, wp and WI. Extraction of collocations using similarit</context>
</contexts>
<marker>Dagan, Fernando, Lilian, 1993</marker>
<rawString>I. Dagan, P. Fernando, and L. Lilian. 1993. Contextual word similarity and estimation from sparse data. In Proc. of the 31th Annual Meeting of the ACL, pages 164-171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Fukumoto</author>
<author>J Tsujii</author>
</authors>
<title>Automatic recognition of verbal polysemy.</title>
<date>1994</date>
<booktitle>In Proc. of the 15th COLING, Kyoto, Japan,</booktitle>
<pages>762--768</pages>
<contexts>
<context position="5182" citStr="Fukumoto and Tsujii, 1994" startWordPosition="855" endWordPosition="858">xt for a specific sense of the polysemous word. Therefore, the algorithm has to be able to determine when the context of a word should be divided and how. The approach proposed in this paper explicitly introduces new entities, i.e. hypothetical verbs when an entity is judged polysemous and associates them with contexts which are sub-contexts of the context of the original entity. Our algorithm has two basic operations, splitting and lumping. Splitting means to divide a polysemous verb into two hypothetical verbs and lumping means to combine two hypothetical verbs to make one verb out of them (Fukumoto and Tsujii, 1994). 3 Extraction of Collocations Given a set of verbs, v1, 1)2, • • •, vm, the algorithm produces a set of semantic clusters, which are ordered in the ascending order of their semantic deviation values. Semantic deviation is a measure of the deviation of the set in an n-dimensional Euclidean space, where n is the number of nouns which co-occur with the verbs. In our algorithm, if vi is non-polysemous, it belongs to at least one of the resultant semantic clusters. If it is polysemous, the algorithm splits it into several hypothetical verbs and each of them belongs to at least one of the clusters.</context>
</contexts>
<marker>Fukumoto, Tsujii, 1994</marker>
<rawString>F. Fukumoto and J. Tsujii. 1994. Automatic recognition of verbal polysemy. In Proc. of the 15th COLING, Kyoto, Japan, pages 762-768.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W K Gale</author>
<author>K W Church</author>
<author>D Yarowsky</author>
</authors>
<title>A method for disambiguating word senses in a large corpus.</title>
<date>1992</date>
<booktitle>In Computers and the Humanities,</booktitle>
<volume>26</volume>
<pages>415--439</pages>
<contexts>
<context position="938" citStr="Gale et al., 1992" startWordPosition="131" endWordPosition="134">act This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. In our method, collocations which characterise every sense are extracted using similarity-based estimation. For the results, term weight learning is performed. Parameters of term weighting are then estimated so as to maximise the collocations which characterise every sense and minimise the other collocations. The results of experiment demonstrate the effectiveness of the method. 1 Introduction One of the major approaches to disambiguate word senses is supervised learning (Gale et al., 1992), (Yarowsky, 1992), (Bruce and Janyce, 1994), (Miller et al., 1994), (Niwa and Nitta, 1994), (Luk, 1995), (Ng and Lee, 1996), (Wilks and Stevenson, 1998). However, a major obstacle impedes the acquisition of lexical knowledge from corpora, i.e. the difficulties of manually sensetagging a training corpus, since this limits the applicability of many approaches to domains where this hard to acquire knowledge is already available. This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. In our approach, an overlapping clustering algorit</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>W. K. Gale, K. W. Church, and D. Yarowsky. 1992. A method for disambiguating word senses in a large corpus. In Computers and the Humanities, volume 26, pages 415-439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Luk</author>
</authors>
<title>Statistical sense disambiguation with relatively small corpora using dictionary definitions.</title>
<date>1995</date>
<booktitle>In Proc. of the 33st Annual Meeting of ACL,</booktitle>
<pages>181--188</pages>
<contexts>
<context position="1042" citStr="Luk, 1995" startWordPosition="149" endWordPosition="150"> learning. In our method, collocations which characterise every sense are extracted using similarity-based estimation. For the results, term weight learning is performed. Parameters of term weighting are then estimated so as to maximise the collocations which characterise every sense and minimise the other collocations. The results of experiment demonstrate the effectiveness of the method. 1 Introduction One of the major approaches to disambiguate word senses is supervised learning (Gale et al., 1992), (Yarowsky, 1992), (Bruce and Janyce, 1994), (Miller et al., 1994), (Niwa and Nitta, 1994), (Luk, 1995), (Ng and Lee, 1996), (Wilks and Stevenson, 1998). However, a major obstacle impedes the acquisition of lexical knowledge from corpora, i.e. the difficulties of manually sensetagging a training corpus, since this limits the applicability of many approaches to domains where this hard to acquire knowledge is already available. This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. In our approach, an overlapping clustering algorithm based on Mutual information-based (Mu) term weight learning between a verb and a noun is applied to a</context>
</contexts>
<marker>Luk, 1995</marker>
<rawString>A. K. Luk. 1995. Statistical sense disambiguation with relatively small corpora using dictionary definitions. In Proc. of the 33st Annual Meeting of ACL, pages 181-188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W T McLeod</author>
</authors>
<title>The new collins dictionary and thesaurus in one volume.</title>
<date>1987</date>
<publisher>Publishers.</publisher>
<location>London, HarperCollins</location>
<contexts>
<context position="12436" citStr="McLeod, 1987" startWordPosition="2221" endWordPosition="2222"> used is 1989 Wall Street Journal (WSJ) in ACL/DCI CD-ROM which consists of 2,878,688 occurrences of part-of-speech tagged words (Brill, 1992). The inflected forms of the same nouns and verbs are treated as single units. For example, &apos;book&apos; and &apos;books&apos; are treated as single units. We obtained 5,940,193 word pairs in a window size of 5 words, 2,743,974 different word pairs. From these, we selected collocations of a verb and a noun. As a test data, we used 40 sets of verbs. We selected at most four senses for each verb, the best sense, from among the set of the Collins dictionary and thesaurus (McLeod, 1987), is determined by a human judge. v wr v , w , • • • Wn} 6.2 Results {V, W1 &amp;quot; • , Wp, &amp;quot; • Wn} Here, v and wp are verbs and WI., • tar, are verbs or hypothetical verbs. wi, • •, wp, • wn, in (5) satisfy D ev (v , wi) &lt; Dev(v , wi) (1 &lt; i &lt; j &lt; n). vi and v2 in (4) are new hypothetical verbs which correspond to two distinct senses of v. If v is a polysemy, but is not recognised correctly, then Extraction-of-Collocations shown in Figure 2 is applied. In Extraction-ofCollocations, for (4) and (5), a and /3 are estimated so as to satisfy (6) and (7). Dev(vi,wp) &lt; Dev(v,w1,- • ,wp, • (6) Dev(v2, , •</context>
</contexts>
<marker>McLeod, 1987</marker>
<rawString>W. T. McLeod. 1987. The new collins dictionary and thesaurus in one volume. London, HarperCollins Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>C Martin</author>
<author>L Shari</author>
<author>L Claudia</author>
<author>R G Thomas</author>
</authors>
<title>Using a semantic concordance for sense identification.</title>
<date>1994</date>
<booktitle>In Proc. of the ARPA Workshop on Human Language Technology,</booktitle>
<pages>240--243</pages>
<contexts>
<context position="1005" citStr="Miller et al., 1994" startWordPosition="141" endWordPosition="144">mbiguating verbal word senses using term weight learning. In our method, collocations which characterise every sense are extracted using similarity-based estimation. For the results, term weight learning is performed. Parameters of term weighting are then estimated so as to maximise the collocations which characterise every sense and minimise the other collocations. The results of experiment demonstrate the effectiveness of the method. 1 Introduction One of the major approaches to disambiguate word senses is supervised learning (Gale et al., 1992), (Yarowsky, 1992), (Bruce and Janyce, 1994), (Miller et al., 1994), (Niwa and Nitta, 1994), (Luk, 1995), (Ng and Lee, 1996), (Wilks and Stevenson, 1998). However, a major obstacle impedes the acquisition of lexical knowledge from corpora, i.e. the difficulties of manually sensetagging a training corpus, since this limits the applicability of many approaches to domains where this hard to acquire knowledge is already available. This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. In our approach, an overlapping clustering algorithm based on Mutual information-based (Mu) term weight learning betw</context>
</contexts>
<marker>Miller, Martin, Shari, Claudia, Thomas, 1994</marker>
<rawString>G. Miller, C. Martin, L. Shari, L. Claudia, and R. G. Thomas. 1994. Using a semantic concordance for sense identification. In Proc. of the ARPA Workshop on Human Language Technology, pages 240-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H T Ng</author>
<author>H B Lee</author>
</authors>
<title>Integrating multiple knowledge sources to disambiguate word sense: An examplar-based approach.</title>
<date>1996</date>
<booktitle>In Proc. of the 34th Annual Meeting of A CL,</booktitle>
<pages>40--47</pages>
<contexts>
<context position="1062" citStr="Ng and Lee, 1996" startWordPosition="151" endWordPosition="154"> our method, collocations which characterise every sense are extracted using similarity-based estimation. For the results, term weight learning is performed. Parameters of term weighting are then estimated so as to maximise the collocations which characterise every sense and minimise the other collocations. The results of experiment demonstrate the effectiveness of the method. 1 Introduction One of the major approaches to disambiguate word senses is supervised learning (Gale et al., 1992), (Yarowsky, 1992), (Bruce and Janyce, 1994), (Miller et al., 1994), (Niwa and Nitta, 1994), (Luk, 1995), (Ng and Lee, 1996), (Wilks and Stevenson, 1998). However, a major obstacle impedes the acquisition of lexical knowledge from corpora, i.e. the difficulties of manually sensetagging a training corpus, since this limits the applicability of many approaches to domains where this hard to acquire knowledge is already available. This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. In our approach, an overlapping clustering algorithm based on Mutual information-based (Mu) term weight learning between a verb and a noun is applied to a set of verbs. It is</context>
</contexts>
<marker>Ng, Lee, 1996</marker>
<rawString>H. T. Ng and H. B. Lee. 1996. Integrating multiple knowledge sources to disambiguate word sense: An examplar-based approach. In Proc. of the 34th Annual Meeting of A CL, pages 40-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Niwa</author>
<author>Y Nitta</author>
</authors>
<title>Co-occurrence vectors from corpora vs. distance vectors from dictionaries.</title>
<date>1994</date>
<booktitle>In Proc. of 15th COLING, Kyoto, Japan,</booktitle>
<pages>304--309</pages>
<contexts>
<context position="1029" citStr="Niwa and Nitta, 1994" startWordPosition="145" endWordPosition="148">senses using term weight learning. In our method, collocations which characterise every sense are extracted using similarity-based estimation. For the results, term weight learning is performed. Parameters of term weighting are then estimated so as to maximise the collocations which characterise every sense and minimise the other collocations. The results of experiment demonstrate the effectiveness of the method. 1 Introduction One of the major approaches to disambiguate word senses is supervised learning (Gale et al., 1992), (Yarowsky, 1992), (Bruce and Janyce, 1994), (Miller et al., 1994), (Niwa and Nitta, 1994), (Luk, 1995), (Ng and Lee, 1996), (Wilks and Stevenson, 1998). However, a major obstacle impedes the acquisition of lexical knowledge from corpora, i.e. the difficulties of manually sensetagging a training corpus, since this limits the applicability of many approaches to domains where this hard to acquire knowledge is already available. This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. In our approach, an overlapping clustering algorithm based on Mutual information-based (Mu) term weight learning between a verb and a noun is</context>
</contexts>
<marker>Niwa, Nitta, 1994</marker>
<rawString>Y. Niwa and Y. Nitta. 1994. Co-occurrence vectors from corpora vs. distance vectors from dictionaries. In Proc. of 15th COLING, Kyoto, Japan, pages 304-309.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>R Bruce</author>
</authors>
<title>Distinguishing word senses in untagged text.</title>
<date>1997</date>
<booktitle>In Proc. of the 2nd Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>197--207</pages>
<contexts>
<context position="19401" citStr="Pedersen and Bruce, 1997" startWordPosition="3469" endWordPosition="3472">49(81.0) (20) {keep, maintain, protect} 378 231(61.1) 1,266 905 349(92.3) 267 234(87.7) 147(38.9) Total (2 senses) 4,856 _ 3,332(68.6) 3,889(80.0) Yarowsky used an unsupervised learning procedure to perform noun WSD (Yarowsky, 1995). This algorithm requires a small number of training examples to serve as a seed. The result shows that the average percentage attained was 96.1% for 12 nouns when the training data was a 460 million word corpus, although Yarowsky uses only nouns and does not discuss distinguishing more than two senses of a word. A more recent unsupervised approach is described in (Pedersen and Bruce, 1997). They presented three unsupervised learning algorithms that distinguish the sense of an ambiguous word in untagged text, i.e. McQuitty&apos;s similarity analysis, Ward&apos;s minimum-variance method and the EM algorithm. These algorithms assign each instance of an ambiguous word to a known sense definition based solely on the values of automatically identifiable features in text. Their methods are perhaps the most similar to our present work. They reported that disambiguating nouns is more successful rather than adjectives or verbs and the best result of verbs was McQuitty&apos;s method (71.8%), although th</context>
</contexts>
<marker>Pedersen, Bruce, 1997</marker>
<rawString>T. Pedersen and R. Bruce. 1997. Distinguishing word senses in untagged text. In Proc. of the 2nd Conference on Empirical Methods in Natural Language Processing, pages 197-207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schutze</author>
</authors>
<title>Dimensions of meaning.</title>
<date>1992</date>
<booktitle>In Proc. of Supercomputing,</booktitle>
<pages>787--796</pages>
<contexts>
<context position="16567" citStr="Schutze, 1992" startWordPosition="3027" endWordPosition="3028">er the number of v fl W is, the higher the percentage of correctness of collocations is. 7 Related Work Unsupervised learning approaches, i.e. to determine the class membership of each object to be classified in a sample without using sensetagged training examples of correct classifications, is considered to have an advantage over supervised learning algorithms, as it does not require costly hand-tagged training data. Schiitze and Zernik&apos;s methods avoid tagging each occurrence in the training corpus. Their methods associate each sense of a polysemous word with a set of its co-occurring words (Schutze, 1992), (Zernik, 1991). If a word has several senses, then the word is associated with several different sets of co-occurring words, each of which corresponds to one of the senses of the word. The weakness of Schiitze and Zernik&apos;s method, however, is that it solely relies on human intuition for identifying different senses of a word, i.e. the human editor has to determine, by her/his intuition, how many senses a word has, and then identify the sets of co-occurring words that correspond to the different senses. 213 Proceedings of EACL &apos;99 Table 2: The result of disambiguation experiment(two senses) N</context>
</contexts>
<marker>Schutze, 1992</marker>
<rawString>H. Schutze. 1992. Dimensions of meaning. In Proc. of Supercomputing, pages 787-796.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
<author>M Stevenson</author>
</authors>
<title>Word sense disambiguation using optimised combinations of knowledge sources.</title>
<date>1998</date>
<booktitle>In Proc. of the COLINGA C L &apos;98,</booktitle>
<pages>1398--1402</pages>
<contexts>
<context position="1091" citStr="Wilks and Stevenson, 1998" startWordPosition="155" endWordPosition="158">tions which characterise every sense are extracted using similarity-based estimation. For the results, term weight learning is performed. Parameters of term weighting are then estimated so as to maximise the collocations which characterise every sense and minimise the other collocations. The results of experiment demonstrate the effectiveness of the method. 1 Introduction One of the major approaches to disambiguate word senses is supervised learning (Gale et al., 1992), (Yarowsky, 1992), (Bruce and Janyce, 1994), (Miller et al., 1994), (Niwa and Nitta, 1994), (Luk, 1995), (Ng and Lee, 1996), (Wilks and Stevenson, 1998). However, a major obstacle impedes the acquisition of lexical knowledge from corpora, i.e. the difficulties of manually sensetagging a training corpus, since this limits the applicability of many approaches to domains where this hard to acquire knowledge is already available. This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. In our approach, an overlapping clustering algorithm based on Mutual information-based (Mu) term weight learning between a verb and a noun is applied to a set of verbs. It is preferable that Mu is not lo</context>
</contexts>
<marker>Wilks, Stevenson, 1998</marker>
<rawString>Y. Wilks and M. Stevenson. 1998. Word sense disambiguation using optimised combinations of knowledge sources. In Proc. of the COLINGA C L &apos;98, pages 1398-1402.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Word sense disambiguation using statistical models of roget&apos;s categories trained on large corpora.</title>
<date>1992</date>
<booktitle>In Proc. of the 14th COLING,</booktitle>
<pages>454--460</pages>
<contexts>
<context position="956" citStr="Yarowsky, 1992" startWordPosition="135" endWordPosition="136">bes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. In our method, collocations which characterise every sense are extracted using similarity-based estimation. For the results, term weight learning is performed. Parameters of term weighting are then estimated so as to maximise the collocations which characterise every sense and minimise the other collocations. The results of experiment demonstrate the effectiveness of the method. 1 Introduction One of the major approaches to disambiguate word senses is supervised learning (Gale et al., 1992), (Yarowsky, 1992), (Bruce and Janyce, 1994), (Miller et al., 1994), (Niwa and Nitta, 1994), (Luk, 1995), (Ng and Lee, 1996), (Wilks and Stevenson, 1998). However, a major obstacle impedes the acquisition of lexical knowledge from corpora, i.e. the difficulties of manually sensetagging a training corpus, since this limits the applicability of many approaches to domains where this hard to acquire knowledge is already available. This paper describes unsupervised learning algorithm for disambiguating verbal word senses using term weight learning. In our approach, an overlapping clustering algorithm based on Mutual</context>
</contexts>
<marker>Yarowsky, 1992</marker>
<rawString>D. Yarowsky. 1992. Word sense disambiguation using statistical models of roget&apos;s categories trained on large corpora. In Proc. of the 14th COLING, pages 454-460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proc. of the 33rd Annual Meeting of the ACL,</booktitle>
<pages>189--196</pages>
<contexts>
<context position="19008" citStr="Yarowsky, 1995" startWordPosition="3404" endWordPosition="3405">push, attack, pull} 223 93(41.8) 202 153 189(84.7) 126 97(77.7) 130(58.2) (16) {save, keep, rescue} 216 149(68-9) 396 354 168(77.7) 115 93(81.6) a 7(31.1) (17) {ship, put, send} 218 92(42.2) 361 241 176(80.7) 92 74(80.4) 126(57.8) (18) {stop, end, move} 244 52(21.4) 993 886 210(86.0) 193 169(87.5) 192(78.6) (19) {add, append, total} 184 35(19.0) 1,164 778 147(79.8) 164 129(78-6) 149(81.0) (20) {keep, maintain, protect} 378 231(61.1) 1,266 905 349(92.3) 267 234(87.7) 147(38.9) Total (2 senses) 4,856 _ 3,332(68.6) 3,889(80.0) Yarowsky used an unsupervised learning procedure to perform noun WSD (Yarowsky, 1995). This algorithm requires a small number of training examples to serve as a seed. The result shows that the average percentage attained was 96.1% for 12 nouns when the training data was a 460 million word corpus, although Yarowsky uses only nouns and does not discuss distinguishing more than two senses of a word. A more recent unsupervised approach is described in (Pedersen and Bruce, 1997). They presented three unsupervised learning algorithms that distinguish the sense of an ambiguous word in untagged text, i.e. McQuitty&apos;s similarity analysis, Ward&apos;s minimum-variance method and the EM algori</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>D. Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proc. of the 33rd Annual Meeting of the ACL, pages 189-196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Zernik</author>
</authors>
<title>Trainl vs. train2: Tagging word senses in corpus. In Lexical acquisition: Exploiting on-line resources to build a lexicon,</title>
<date>1991</date>
<pages>91--112</pages>
<location>Uri Zernik(Ed.), London, Lawrence Erlbaum Associates.</location>
<contexts>
<context position="16583" citStr="Zernik, 1991" startWordPosition="3029" endWordPosition="3030">v fl W is, the higher the percentage of correctness of collocations is. 7 Related Work Unsupervised learning approaches, i.e. to determine the class membership of each object to be classified in a sample without using sensetagged training examples of correct classifications, is considered to have an advantage over supervised learning algorithms, as it does not require costly hand-tagged training data. Schiitze and Zernik&apos;s methods avoid tagging each occurrence in the training corpus. Their methods associate each sense of a polysemous word with a set of its co-occurring words (Schutze, 1992), (Zernik, 1991). If a word has several senses, then the word is associated with several different sets of co-occurring words, each of which corresponds to one of the senses of the word. The weakness of Schiitze and Zernik&apos;s method, however, is that it solely relies on human intuition for identifying different senses of a word, i.e. the human editor has to determine, by her/his intuition, how many senses a word has, and then identify the sets of co-occurring words that correspond to the different senses. 213 Proceedings of EACL &apos;99 Table 2: The result of disambiguation experiment(two senses) Num {v, top, wi} </context>
</contexts>
<marker>Zernik, 1991</marker>
<rawString>U. Zernik. 1991. Trainl vs. train2: Tagging word senses in corpus. In Lexical acquisition: Exploiting on-line resources to build a lexicon, pages 91-112. Uri Zernik(Ed.), London, Lawrence Erlbaum Associates.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>