<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.987476">
Unsupervised Discovery of Rhyme Schemes
</title>
<author confidence="0.994546">
Sravana Reddy
</author>
<affiliation confidence="0.998924">
Department of Computer Science
The University of Chicago
</affiliation>
<address confidence="0.664559">
Chicago, IL 60637
</address>
<email confidence="0.99844">
sravana@cs.uchicago.edu
</email>
<author confidence="0.997969">
Kevin Knight
</author>
<affiliation confidence="0.9972555">
Information Sciences Institute
University of Southern California
</affiliation>
<address confidence="0.49082">
Marina del Rey, CA 90292
</address>
<email confidence="0.998948">
knight@isi.edu
</email>
<sectionHeader confidence="0.995645" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99962475">
This paper describes an unsupervised,
language-independent model for finding
rhyme schemes in poetry, using no prior
knowledge about rhyme or pronunciation.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996587285714286">
Rhyming stanzas of poetry are characterized by
rhyme schemes, patterns that specify how the lines
in the stanza rhyme with one another. The question
we raise in this paper is: can we infer the rhyme
scheme of a stanza given no information about pro-
nunciations or rhyming relations among words?
Background A rhyme scheme is represented as a
string corresponding to the sequence of lines that
comprise the stanza, in which rhyming lines are de-
noted by the same letter. For example, the limerick’s
rhyme scheme is aabba, indicating that the 1&amp;quot;, 2nd,
and 5th lines rhyme, as do the the 3rd and 4th.
Motivation Automatic rhyme scheme annotation
would benefit several research areas, including:
</bodyText>
<listItem confidence="0.993361666666666">
• Machine Translation of Poetry There has been
a growing interest in translation under con-
straints of rhyme and meter, which requires
training on a large amount of annotated poetry
data in various languages.
• ‘Culturomics’ The field of digital humanities
is growing, with a focus on statistics to track
cultural and literary trends (partially spurred
by projects like the Google Books Ngrams1).
</listItem>
<footnote confidence="0.979961">
1http://ngrams.googlelabs.com/
</footnote>
<page confidence="0.994238">
77
</page>
<bodyText confidence="0.9265455">
Rhyming corpora could be extremely useful for
large-scale statistical analyses of poetic texts.
</bodyText>
<listItem confidence="0.693485857142857">
• Historical Linguistics/Study of Dialects
Rhymes of a word in poetry of a given time
period or dialect region provide clues about its
pronunciation in that time or dialect, a fact that
is often taken advantage of by linguists (Wyld,
1923). One could automate this task given
enough annotated data.
</listItem>
<bodyText confidence="0.999845">
An obvious approach to finding rhyme schemes
is to use word pronunciations and a definition of
rhyme, in which case the problem is fairly easy.
However, we favor an unsupervised solution that uti-
lizes no external knowledge for several reasons.
</bodyText>
<listItem confidence="0.887087846153846">
• Pronunciation dictionaries are simply not avail-
able for many languages. When dictionaries
are available, they do not include all possible
words, or account for different dialects.
• The definition of rhyme varies across poetic
traditions and languages, and may include
slant rhymes like gate/mat, ‘sight rhymes’ like
word/sword, assonance/consonance like shore/
alone, leaves/lance, etc.
• Pronunciations and spelling conventions
change over time. Words that rhymed histori-
cally may not anymore, like prove and love –
or proued and beloued.
</listItem>
<sectionHeader confidence="0.999154" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.953698727272727">
There have been a number of recent papers on the
automated annotation, analysis, or translation of po-
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 77–82,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
etry. Greene et al. (2010) use a finite state trans-
ducer to infer the syllable-stress assignments in lines
of poetry under metrical constraints. Genzel et al.
(2010) incorporate constraints on meter and rhyme
(where the stress and rhyming information is derived
from a pronunciation dictionary) into a machine
translation system. Jiang and Zhou (2008) develop a
system to generate the second line of a Chinese cou-
plet given the first. A few researchers have also ex-
plored the problem of poetry generation under some
constraints (Manurung et al., 2000; Netzer et al.,
2009; Ramakrishnan et al., 2009). There has also
been some work on computational approaches to
characterizing rhymes (Byrd and Chodorow, 1985)
and global properties of the rhyme network (Son-
deregger, 2011) in English. To the best of our knowl-
edge, there has been no language-independent com-
putational work on finding rhyme schemes.
</bodyText>
<sectionHeader confidence="0.954973" genericHeader="method">
3 Finding Stanza Rhyme Schemes
</sectionHeader>
<bodyText confidence="0.999964636363636">
A collection of rhyming poetry inevitably contains
repetition of rhyming pairs. For example, the word
trees will often rhyme with breeze across different
stanzas, even those with different rhyme schemes
and written by different authors. This is partly due
to sparsity of rhymes – many words that have no
rhymes at all, and many others have only a handful,
forcing poets to reuse rhyming pairs.
In this section, we describe an unsupervised al-
gorithm to infer rhyme schemes that harnesses this
repetition, based on a model of stanza generation.
</bodyText>
<subsectionHeader confidence="0.46864">
3.1 Generative Model of a Stanza
</subsectionHeader>
<listItem confidence="0.957437857142857">
1. Pick a rhyme scheme r of length n with proba-
bility P(r).
2. For each i E [1, n], pick a word sequence,
choosing the last2 word xi as follows:
(a) If, according to r, the ith line does not
rhyme with any previous line in the stanza, pick
a word xi from a vocabulary of line-end words
with probability P(xi).
(b) If the ith line rhymes with some previous
line(s) j according to r, choose a word xi that
2A rhyme may span more than one word in a line – for ex-
ample, laureate... /Tory at... /are ye at (Byron, 1824), but this
is uncommon. An extension of our model could include a latent
variable that selects the entire rhyming portion of a line.
</listItem>
<bodyText confidence="0.996446">
rhymes with the last words of all such lines
with probability Qj&lt;i:ri=r, P(xi|xj).
The probability of a stanza x of length n is given
by Eq. 1. Ii,r is the indicator variable for whether
line i rhymes with at least one previous line under r.
</bodyText>
<equation confidence="0.94884425">
P(x) = X P(r)P(x|r) =
rER
(1 − Ii,r)P(xi) + Ii,r Y P(xi|xj) (1)
j&lt;i:ri=rj
</equation>
<subsectionHeader confidence="0.998064">
3.2 Learning
</subsectionHeader>
<bodyText confidence="0.999176636363637">
We denote our data by X, a set of stanzas. Each
stanza x is represented as a sequence of its line-end
words, xi, .. . xlen(x). We are also given a large set
R of all possible rhyme schemes.3
If each stanza in the data is generated indepen-
dently (an assumption we relax in §4), the log-
likelihood of the data is PxcX log P(x). We would
like to maximize this over all possible rhyme scheme
assignments, under the latent variables θ, which rep-
resents pairwise rhyme strength, and ρ, the distribu-
tion of rhyme schemes. θ,,,,,, is defined for all words
v and w as a non-negative real value indicating how
strongly the words v and w rhyme, and ρr is P(r).
The expectation maximization (EM) learning al-
gorithm for this formulation is described below. The
intuition behind the algorithm is this: after one iter-
ation, θ,,,,,, = 0 for all v and w that never occur to-
gether in a stanza. If v and w co-occur in more than
one stanza, θ,,,,,, has a high pseudo-count, reflecting
the fact that they are likely to be rhymes.
Initialize: ρ and θ uniformly (giving θ the same
positive value for all word pairs).
</bodyText>
<equation confidence="0.934505833333333">
Expectation Step: Compute P(r|x) =
P(x|r)ρr/ PQER P(x|q)ρQ, where
P(x|r) = Yn (1 − Ii,r)P(xi) +
i=1
YIi,r Xθxi,xj/ θw,xi (2)
j&lt;i:ri=rj w
</equation>
<bodyText confidence="0.964505333333333">
3While the number of rhyme schemes of length n is tech-
nically the number of partitions of an n- element set (the Bell
number), only a subset of these are typically used.
</bodyText>
<equation confidence="0.979533461538461">
Yn
i=1
P(r)
X
rER
78
P(xi) is simply the relative frequency of the
word xi in the data.
Maximization Step: Update θ and ρ:
P(r|x) (3)
r,x:v rhymes with w
�ρr = P(r|x)/ � P(q|x) (4)
xEX qER,xEX
</equation>
<bodyText confidence="0.754481">
After Convergence: Label each stanza x with the
best rhyme scheme, arg maxrER P(r|x).
</bodyText>
<subsectionHeader confidence="0.974939">
3.3 Data
</subsectionHeader>
<bodyText confidence="0.999993">
We test the algorithm on rhyming poetry in En-
glish and French. The English data is an edited ver-
sion of the public-domain portion of the corpus used
by Sonderegger (2011), and consists of just under
12000 stanzas spanning a range of poets and dates
from the 15th to 20th centuries. The French data
is from the ARTFL project (Morrissey, 2011), and
contains about 3000 stanzas. All poems in the data
are manually annotated with rhyme schemes.
The set R is taken to be all the rhyme schemes
from the gold standard annotations of both corpora,
numbering 462 schemes in total, with an average of
6.5 schemes per stanza length. There are 27.12 can-
didate rhyme schemes on an average for each En-
glish stanza, and 33.81 for each French stanza.
</bodyText>
<sectionHeader confidence="0.88382" genericHeader="method">
3.4 Results
</sectionHeader>
<bodyText confidence="0.999919">
We measure the accuracy of the discovered rhyme
schemes relative to the gold standard. We also eval-
uate for each word token xi, the set of words in
{xi+1, xi+2, . . .} that are found to rhyme with xi by
measuring precision and recall. This is to account
for partial correctness – if abcb is found instead of
abab, for example, we would like to credit the algo-
rithm for knowing that the 2nd and 4th lines rhyme.
Table 1 shows the results of the algorithm for the
entire corpus in each language, as well as for a few
sub-corpora from different time periods.
</bodyText>
<subsectionHeader confidence="0.934846">
3.5 Orthographic Similarity Bias
</subsectionHeader>
<bodyText confidence="0.999970681818182">
So far, we have relied on the repetition of rhymes,
and have made no assumptions about word pronun-
ciations. Therefore, the algorithm’s performance
is strongly correlated4 with the predictability of
rhyming words. For writing systems where the
written form of a word approximates its pronunci-
ation, we have some additional information about
rhyming: for example, English words ending with
similar characters are most probably rhymes. We
do not want to assume too much in the interest of
language-independence – following from our earlier
point in §1 about the nebulous definition of rhyme
– but it is safe to say that rhyming words involve
some orthographic similarity (though this does not
hold for writing systems like Chinese). We therefore
initialize θ at the start of EM with a simple similarity
measure: (Eq. 5). The addition of E = 0.001 ensures
that words with no letters in common, like new and
you, are not eliminated as rhymes.
This simple modification produces results that
outperform the naive baselines for most of the data
by a considerable margin, as detailed in Table 2.
</bodyText>
<subsectionHeader confidence="0.98382">
3.6 Using Pronunciation, Rhyming Definition
</subsectionHeader>
<bodyText confidence="0.999618571428572">
How does our algorithm compare to a standard sys-
tem where rhyme schemes are determined by pre-
defined rules of rhyming and dictionary pronunci-
ations? We use the accepted definition of rhyme
in English: two words rhyme if their final stressed
vowels and all following phonemes are identical.
For every pair of English words v, w, we let θ,,,w =
1 + E if the CELEX (Baayen et al., 1995) pronun-
ciations of v and w rhyme, and θ,,,w = 0 + E if not
(with E = 0.001). If either v or w is not present
in CELEX, we set θ,,,w to a random value in [0, 1].
We then find the best rhyme scheme for each stanza,
using Eq. 2 with uniformly initialized ρ.
Figure 1 shows that the accuracy of this system
is generally much lower than that of our model for
the sub-corpora from before 1750. Performance is
comparable for the 1750-1850 data, after which we
get better accuracies using the rhyming definition
than with our model. This is clearly a reflection of
language change; older poetry differs more signifi-
cantly in pronunciation and lexical usage from con-
</bodyText>
<footnote confidence="0.8281675">
4For the five English sub-corpora, R2 = 0.946 for the nega-
tive correlation of accuracy with entropy of rhyming word pairs.
</footnote>
<equation confidence="0.855218333333334">
θv,w =
θv,w = min(len(v), len(w)) + e (5)
# letters common to v &amp; w
</equation>
<page confidence="0.998501">
79
</page>
<tableCaption confidence="0.980918">
Table 1: Rhyme scheme accuracy and F-Score (computed from average precision and recall over all lines) using our algorithm
for independent stanzas, with uniform initialization of 0. Rows labeled ‘All’ refer to training and evaluation on all the data in the
language. Other rows refer to training and evaluating on a particular sub-corpus only. Bold indicates that we outperform the naive
baseline, where most common scheme of the appropriate length from the gold standard of the entire corpus is assigned to every
stanza, and italics that we outperform the ‘less naive’ baseline, where we assign the most common scheme of the appropriate length
from the gold standard of the given sub-corpus.
</tableCaption>
<table confidence="0.999158071428571">
Sub-corpus Sub-corpus overview Accuracy (%) F-Score
(time-
period)
# of Total # # of line- EM Naive Less naive EM Naive Less
stanzas of lines end words induction baseline baseline induction baseline naive
All 11613 93030 13807 62.15 56.76 60.24 0.79 0.74 0.77
1450-1550 197 1250 782 17.77 53.30 97.46 0.41 0.73 0.98
1550-1650 3786 35485 7826 67.17 62.28 74.72 0.82 0.78 0.85
En 1650-1750 2198 20110 4447 87.58 58.42 82.98 0.94 0.68 0.91
1750-1850 2555 20598 5188 31.00 69.16 74.52 0.65 0.83 0.87
1850-1950 2877 15587 4382 50.92 37.43 49.70 0.81 0.55 0.68
All 2814 26543 10781 40.29 39.66 64.46 0.58 0.57 0.80
Fr 1450-1550 1478 14126 7122 28.21 58.66 77.67 0.59 0.83 0.89
1550-1650 1336 12417 5724 52.84 18.64 61.23 0.70 0.28 0.75
</table>
<bodyText confidence="0.999774">
temporary dictionaries, and therefore, benefits more
from a model that assumes no pronunciation knowl-
edge. (While we may get better results on older
data using dictionaries that are historically accurate,
these are not easily available, and require a great
deal of effort and linguistic knowledge to create.)
Initializing 0 as specified above and then running
EM produces some improvement compared to or-
thographic similarity (Table 2).
</bodyText>
<sectionHeader confidence="0.99821" genericHeader="method">
4 Accounting for Stanza Dependencies
</sectionHeader>
<bodyText confidence="0.999936428571429">
So far, we have treated stanzas as being indepen-
dent of each other. In reality, stanzas in a poem are
usually generated using the same or similar rhyme
schemes. Furthermore, some rhyme schemes span
multiple stanzas – for example, the Italian form terza
rima has the scheme aba bcb cdc... (the 1�t and Yd
lines rhyme with the 2nd line of the previous stanza).
</bodyText>
<subsectionHeader confidence="0.793999">
4.1 Generative Model
</subsectionHeader>
<bodyText confidence="0.996399875">
We model stanza generation within a poem as a
Markov process, where each stanza is conditioned
on the previous one. To generate a poem y consist-
ing of m stanzas, for each k E [1, m], generate a
stanza xk of length nk as described below:
1. If k = 1, pick a rhyme scheme rk of length nk
with probability P(rk), and generate the stanza
as in the previous section.
</bodyText>
<figureCaption confidence="0.846547428571429">
Figure 1: Comparison of EM with a definition-based system
(a) Accuracy and F-Score ratios of the rhyming-definition-
based system over that of our model with orthographic sim-
ilarity. The former is more accurate than EM for post-1850
data (ratio &gt; 1), but is outperformed by our model for older
poetry (ratio &lt; 1), largely due to pronunciation changes like
the Great Vowel Shift that alter rhyming relations.
</figureCaption>
<table confidence="0.970654727272727">
Found by EM Found by definitions
1450-1550 left/craft, shone/done edify/lie, adieu/hue
1550-1650 appeareth/weareth, obtain/vain, amend/
speaking/breaking, depend, breed/heed,
proue/moue, doe/two prefers/hers
1650-1750 most/cost, presage/ see/family, blade/
rage, join’d/mind shade, noted/quoted
1750-1850 desponds/wounds, gore/shore, ice/vice,
o’er/shore, it/basket head/tread, too/blew
1850-1950 of/love, lover/ old/enfold, within/
half-over, again/rain win, be/immortality
</table>
<footnote confidence="0.46818775">
(b) Some examples of rhymes in English found by EM but not
the definition-based system (due to divergence from the contem-
porary dictionary or rhyming definition), and vice-versa (due to
inadequate repetition).
</footnote>
<figure confidence="0.997843928571429">
Ratio of rhyming rules to
EM performance
0.6
0.4
0.2
1.6
1.4
1.2
0.8
0
1
1450-1550 1550-1650 1650-1750 1750-1850 1850-1950
Accuracy
F-Score
</figure>
<page confidence="0.982297">
80
</page>
<tableCaption confidence="0.761303">
Table 2: Performance of EM with 0 initialized by orthographic similarity (§3.5), pronunciation-based rhyming definitions (§3.6),
and the HMM for stanza dependencies (§4). Bold and italics indicate that we outperform the naive baselines shown in Table 1.
</tableCaption>
<table confidence="0.999501214285714">
Sub-corpus Accuracy (%) F-Score
(time-
period)
HMM Rhyming Orthographic Uniform HMM Rhyming Ortho. Uniform
stanzas definition init. initialization initialization stanzas defn. init. init. init.
All 72.48 64.18 63.08 62.15 0.88 0.84 0.83 0.79
1450-1550 74.31 75.63 69.04 17.77 0.86 0.86 0.82 0.41
1550-1650 79.17 69.76 71.98 67.17 0.90 0.86 0.88 0.82
En 1650-1750 91.23 91.95 89.54 87.58 0.97 0.97 0.96 0.94
1750-1850 49.11 42.74 33.62 31.00 0.82 0.77 0.70 0.65
1850-1950 58.95 57.18 54.05 50.92 0.90 0.89 0.84 0.81
All 56.47 - 48.90 40.29 0.81 - 0.75 0.58
Fr 1450-1550 61.28 - 35.25 28.21 0.86 - 0.71 0.59
1550-1650 67.96 - 63.40 52.84 0.79 - 0.77 0.70
</table>
<bodyText confidence="0.938401111111111">
2. If k &gt; 1, pick a scheme rk of length nk with
probability P(rk|rk−1). If no rhymes in rk
are shared with the previous stanza’s rhyme
scheme, rk−1, generate the stanza as before.
If rk shares rhymes with rk−1, generate the
stanza as a continuation of xk−1. For exam-
ple, if xk−1 = [dreams, lay, streams], and rk−1
and rk = aba and bcb, the stanza xk should be
generated so that xk1 and xk3 rhyme with lay.
</bodyText>
<subsectionHeader confidence="0.963687">
4.2 Learning
</subsectionHeader>
<bodyText confidence="0.999846666666667">
This model for a poem can be formalized as an au-
toregressive HMM, an hidden Markov model where
each observation is conditioned on the previous ob-
servation as well as the latent state. An observation
at a time step k is the stanza xk, and the latent state at
that time step is the rhyme scheme rk. This model is
parametrized by 0 and p, where pr,Q = P(r|q) for all
schemes r and q. 0 is initialized with orthographic
similarity. The learning algorithm follows from EM
for HMMs and our earlier algorithm.
Expectation Step: Estimate P(r|x) for each
stanza in the poem using the forward-backward
algorithm. The ‘emission probability’ P(x|r)
for the first stanza is same as in §3, and for
subsequent stanzas xk, k &gt; 1 is given by:
</bodyText>
<equation confidence="0.695821">
P(xk|xk−1, rk) = 11 nk (1 − Ii,rk)P(xki ) +
i=1
</equation>
<table confidence="0.558086">
11 Ii,rk 11 P(xk i |xk j ) P(xk i |xk−1
j&lt;i4 =rkj j4 =rk−1 j ) (6)
j
Maximization Step: Update p and 0 analogously
to HMM transition and emission probabilities.
</table>
<subsectionHeader confidence="0.543151">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.999977">
As Table 2 shows, there is considerable improve-
ment over models that assume independent stanzas.
The most gains are found in French, which contains
many instances of ‘linked’ stanzas like the terza
rima, as well as English data containing long poems
made of several stanzas with the same scheme.
</bodyText>
<sectionHeader confidence="0.999654" genericHeader="discussions">
5 Future Work
</sectionHeader>
<bodyText confidence="0.999965230769231">
Some possible extensions of our work include au-
tomatically generating the set of possible rhyme
schemes R, and incorporating partial supervision
into our algorithm as well as better ways of using
and adapting pronunciation information when avail-
able. We would also like to test our method on a
range of languages and texts.
To return to the motivations, one could use
the discovered annotations for machine translation
of poetry, or to computationally reconstruct pro-
nunciations, which is useful for historical linguis-
tics as well as other applications involving out-of-
vocabulary words.
</bodyText>
<sectionHeader confidence="0.998665" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999325">
We would like to thank Morgan Sonderegger for
providing most of the annotated English data in the
rhyming corpus and for helpful discussion, and the
anonymous reviewers for their suggestions.
</bodyText>
<page confidence="0.99805">
81
</page>
<sectionHeader confidence="0.995887" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9994723">
R. H. Baayen, R. Piepenbrock, and L. Gulikers. 1995.
The CELEX Lexical Database (CD-ROM). Linguistic
Data Consortium.
Roy J. Byrd and Martin S. Chodorow. 1985. Using an
online dictionary to find rhyming words and pronunci-
ations for unknown words. In Proceedings of ACL.
Lord Byron. 1824. Don Juan.
Dmitriy Genzel, Jakob Uszkoreit, and Franz Och. 2010.
“Poetic” statistical machine translation: Rhyme and
meter. In Proceedings of EMNLP.
Erica Greene, Tugba Bodrumlu, and Kevin Knight. 2010.
Automatic analysis of rhythmic poetry with applica-
tions to generation and translation. In Proceedings of
EMNLP.
Long Jiang and Ming Zhou. 2008. Generating Chinese
couplets using a statistical MT approach. In Proceed-
ings of COLING.
Hisar Maruli Manurung, Graeme Ritchie, and Henry
Thompson. 2000. Towards a computational model of
poetry generation. In Proceedings ofAISB Symposium
on Creative and Cultural Aspects and Applications of
AI and Cognitive Science.
Robert Morrissey. 2011. ARTFL : American research
on the treasury of the French language. http://artfl-
project.uchicago.edu/content/artfl-frantext.
Yael Netzer, David Gabay, Yoav Goldberg, and Michael
Elhadad. 2009. Gaiku : Generating Haiku with word
associations norms. In Proceedings of the NAACL
workshop on Computational Approaches to Linguistic
Creativity.
Ananth Ramakrishnan, Sankar Kuppan, and
Sobha Lalitha Devi. 2009. Automatic genera-
tion of Tamil lyrics for melodies. In Proceedings of
the NAACL workshop on Computational Approaches
to Linguistic Creativity.
Morgan Sonderegger. 2011. Applications of graph the-
ory to an English rhyming corpus. Computer Speech
and Language, 25:655–678.
Henry Wyld. 1923. Studies in English rhymes from Sur-
rey to Pope. J Murray, London.
</reference>
<page confidence="0.999125">
82
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.306503">
<title confidence="0.999381">Unsupervised Discovery of Rhyme Schemes</title>
<author confidence="0.949239">Sravana</author>
<affiliation confidence="0.9991555">Department of Computer The University of</affiliation>
<address confidence="0.494748">Chicago, IL</address>
<email confidence="0.998421">sravana@cs.uchicago.edu</email>
<author confidence="0.957793">Kevin</author>
<affiliation confidence="0.999579">Information Sciences University of Southern</affiliation>
<author confidence="0.687948">Marina del Rey</author>
<author confidence="0.687948">CA</author>
<email confidence="0.999246">knight@isi.edu</email>
<abstract confidence="0.9987124">This paper describes an unsupervised, language-independent model for finding rhyme schemes in poetry, using no prior knowledge about rhyme or pronunciation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R H Baayen</author>
<author>R Piepenbrock</author>
<author>L Gulikers</author>
</authors>
<date>1995</date>
<booktitle>The CELEX Lexical Database (CD-ROM). Linguistic Data Consortium.</booktitle>
<contexts>
<context position="10088" citStr="Baayen et al., 1995" startWordPosition="1703" endWordPosition="1706"> new and you, are not eliminated as rhymes. This simple modification produces results that outperform the naive baselines for most of the data by a considerable margin, as detailed in Table 2. 3.6 Using Pronunciation, Rhyming Definition How does our algorithm compare to a standard system where rhyme schemes are determined by predefined rules of rhyming and dictionary pronunciations? We use the accepted definition of rhyme in English: two words rhyme if their final stressed vowels and all following phonemes are identical. For every pair of English words v, w, we let θ,,,w = 1 + E if the CELEX (Baayen et al., 1995) pronunciations of v and w rhyme, and θ,,,w = 0 + E if not (with E = 0.001). If either v or w is not present in CELEX, we set θ,,,w to a random value in [0, 1]. We then find the best rhyme scheme for each stanza, using Eq. 2 with uniformly initialized ρ. Figure 1 shows that the accuracy of this system is generally much lower than that of our model for the sub-corpora from before 1750. Performance is comparable for the 1750-1850 data, after which we get better accuracies using the rhyming definition than with our model. This is clearly a reflection of language change; older poetry differs more </context>
</contexts>
<marker>Baayen, Piepenbrock, Gulikers, 1995</marker>
<rawString>R. H. Baayen, R. Piepenbrock, and L. Gulikers. 1995. The CELEX Lexical Database (CD-ROM). Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy J Byrd</author>
<author>Martin S Chodorow</author>
</authors>
<title>Using an online dictionary to find rhyming words and pronunciations for unknown words.</title>
<date>1985</date>
<booktitle>In Proceedings of</booktitle>
<contexts>
<context position="3777" citStr="Byrd and Chodorow, 1985" startWordPosition="574" endWordPosition="577"> assignments in lines of poetry under metrical constraints. Genzel et al. (2010) incorporate constraints on meter and rhyme (where the stress and rhyming information is derived from a pronunciation dictionary) into a machine translation system. Jiang and Zhou (2008) develop a system to generate the second line of a Chinese couplet given the first. A few researchers have also explored the problem of poetry generation under some constraints (Manurung et al., 2000; Netzer et al., 2009; Ramakrishnan et al., 2009). There has also been some work on computational approaches to characterizing rhymes (Byrd and Chodorow, 1985) and global properties of the rhyme network (Sonderegger, 2011) in English. To the best of our knowledge, there has been no language-independent computational work on finding rhyme schemes. 3 Finding Stanza Rhyme Schemes A collection of rhyming poetry inevitably contains repetition of rhyming pairs. For example, the word trees will often rhyme with breeze across different stanzas, even those with different rhyme schemes and written by different authors. This is partly due to sparsity of rhymes – many words that have no rhymes at all, and many others have only a handful, forcing poets to reuse </context>
</contexts>
<marker>Byrd, Chodorow, 1985</marker>
<rawString>Roy J. Byrd and Martin S. Chodorow. 1985. Using an online dictionary to find rhyming words and pronunciations for unknown words. In Proceedings of ACL. Lord Byron. 1824. Don Juan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitriy Genzel</author>
<author>Jakob Uszkoreit</author>
<author>Franz Och</author>
</authors>
<title>Poetic” statistical machine translation: Rhyme and meter.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="3233" citStr="Genzel et al. (2010)" startWordPosition="488" endWordPosition="491">ons and spelling conventions change over time. Words that rhymed historically may not anymore, like prove and love – or proued and beloued. 2 Related Work There have been a number of recent papers on the automated annotation, analysis, or translation of poProceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 77–82, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics etry. Greene et al. (2010) use a finite state transducer to infer the syllable-stress assignments in lines of poetry under metrical constraints. Genzel et al. (2010) incorporate constraints on meter and rhyme (where the stress and rhyming information is derived from a pronunciation dictionary) into a machine translation system. Jiang and Zhou (2008) develop a system to generate the second line of a Chinese couplet given the first. A few researchers have also explored the problem of poetry generation under some constraints (Manurung et al., 2000; Netzer et al., 2009; Ramakrishnan et al., 2009). There has also been some work on computational approaches to characterizing rhymes (Byrd and Chodorow, 1985) and global properties of the rhyme network (Sonderegger</context>
</contexts>
<marker>Genzel, Uszkoreit, Och, 2010</marker>
<rawString>Dmitriy Genzel, Jakob Uszkoreit, and Franz Och. 2010. “Poetic” statistical machine translation: Rhyme and meter. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erica Greene</author>
<author>Tugba Bodrumlu</author>
<author>Kevin Knight</author>
</authors>
<title>Automatic analysis of rhythmic poetry with applications to generation and translation.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="3094" citStr="Greene et al. (2010)" startWordPosition="466" endWordPosition="469">nclude slant rhymes like gate/mat, ‘sight rhymes’ like word/sword, assonance/consonance like shore/ alone, leaves/lance, etc. • Pronunciations and spelling conventions change over time. Words that rhymed historically may not anymore, like prove and love – or proued and beloued. 2 Related Work There have been a number of recent papers on the automated annotation, analysis, or translation of poProceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 77–82, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics etry. Greene et al. (2010) use a finite state transducer to infer the syllable-stress assignments in lines of poetry under metrical constraints. Genzel et al. (2010) incorporate constraints on meter and rhyme (where the stress and rhyming information is derived from a pronunciation dictionary) into a machine translation system. Jiang and Zhou (2008) develop a system to generate the second line of a Chinese couplet given the first. A few researchers have also explored the problem of poetry generation under some constraints (Manurung et al., 2000; Netzer et al., 2009; Ramakrishnan et al., 2009). There has also been some </context>
</contexts>
<marker>Greene, Bodrumlu, Knight, 2010</marker>
<rawString>Erica Greene, Tugba Bodrumlu, and Kevin Knight. 2010. Automatic analysis of rhythmic poetry with applications to generation and translation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Ming Zhou</author>
</authors>
<title>Generating Chinese couplets using a statistical MT approach.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="3419" citStr="Jiang and Zhou (2008)" startWordPosition="515" endWordPosition="518">cent papers on the automated annotation, analysis, or translation of poProceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 77–82, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics etry. Greene et al. (2010) use a finite state transducer to infer the syllable-stress assignments in lines of poetry under metrical constraints. Genzel et al. (2010) incorporate constraints on meter and rhyme (where the stress and rhyming information is derived from a pronunciation dictionary) into a machine translation system. Jiang and Zhou (2008) develop a system to generate the second line of a Chinese couplet given the first. A few researchers have also explored the problem of poetry generation under some constraints (Manurung et al., 2000; Netzer et al., 2009; Ramakrishnan et al., 2009). There has also been some work on computational approaches to characterizing rhymes (Byrd and Chodorow, 1985) and global properties of the rhyme network (Sonderegger, 2011) in English. To the best of our knowledge, there has been no language-independent computational work on finding rhyme schemes. 3 Finding Stanza Rhyme Schemes A collection of rhymi</context>
</contexts>
<marker>Jiang, Zhou, 2008</marker>
<rawString>Long Jiang and Ming Zhou. 2008. Generating Chinese couplets using a statistical MT approach. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hisar Maruli Manurung</author>
<author>Graeme Ritchie</author>
<author>Henry Thompson</author>
</authors>
<title>Towards a computational model of poetry generation.</title>
<date>2000</date>
<booktitle>In Proceedings ofAISB Symposium on Creative and Cultural Aspects and Applications of AI and Cognitive Science.</booktitle>
<contexts>
<context position="3618" citStr="Manurung et al., 2000" startWordPosition="550" endWordPosition="553">on, June 19-24, 2011. c�2011 Association for Computational Linguistics etry. Greene et al. (2010) use a finite state transducer to infer the syllable-stress assignments in lines of poetry under metrical constraints. Genzel et al. (2010) incorporate constraints on meter and rhyme (where the stress and rhyming information is derived from a pronunciation dictionary) into a machine translation system. Jiang and Zhou (2008) develop a system to generate the second line of a Chinese couplet given the first. A few researchers have also explored the problem of poetry generation under some constraints (Manurung et al., 2000; Netzer et al., 2009; Ramakrishnan et al., 2009). There has also been some work on computational approaches to characterizing rhymes (Byrd and Chodorow, 1985) and global properties of the rhyme network (Sonderegger, 2011) in English. To the best of our knowledge, there has been no language-independent computational work on finding rhyme schemes. 3 Finding Stanza Rhyme Schemes A collection of rhyming poetry inevitably contains repetition of rhyming pairs. For example, the word trees will often rhyme with breeze across different stanzas, even those with different rhyme schemes and written by di</context>
</contexts>
<marker>Manurung, Ritchie, Thompson, 2000</marker>
<rawString>Hisar Maruli Manurung, Graeme Ritchie, and Henry Thompson. 2000. Towards a computational model of poetry generation. In Proceedings ofAISB Symposium on Creative and Cultural Aspects and Applications of AI and Cognitive Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Morrissey</author>
</authors>
<title>ARTFL : American research on the treasury of the French language.</title>
<date>2011</date>
<note>http://artflproject.uchicago.edu/content/artfl-frantext.</note>
<contexts>
<context position="7579" citStr="Morrissey, 2011" startWordPosition="1270" endWordPosition="1271"> rER 78 P(xi) is simply the relative frequency of the word xi in the data. Maximization Step: Update θ and ρ: P(r|x) (3) r,x:v rhymes with w �ρr = P(r|x)/ � P(q|x) (4) xEX qER,xEX After Convergence: Label each stanza x with the best rhyme scheme, arg maxrER P(r|x). 3.3 Data We test the algorithm on rhyming poetry in English and French. The English data is an edited version of the public-domain portion of the corpus used by Sonderegger (2011), and consists of just under 12000 stanzas spanning a range of poets and dates from the 15th to 20th centuries. The French data is from the ARTFL project (Morrissey, 2011), and contains about 3000 stanzas. All poems in the data are manually annotated with rhyme schemes. The set R is taken to be all the rhyme schemes from the gold standard annotations of both corpora, numbering 462 schemes in total, with an average of 6.5 schemes per stanza length. There are 27.12 candidate rhyme schemes on an average for each English stanza, and 33.81 for each French stanza. 3.4 Results We measure the accuracy of the discovered rhyme schemes relative to the gold standard. We also evaluate for each word token xi, the set of words in {xi+1, xi+2, . . .} that are found to rhyme wi</context>
</contexts>
<marker>Morrissey, 2011</marker>
<rawString>Robert Morrissey. 2011. ARTFL : American research on the treasury of the French language. http://artflproject.uchicago.edu/content/artfl-frantext.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yael Netzer</author>
<author>David Gabay</author>
<author>Yoav Goldberg</author>
<author>Michael Elhadad</author>
</authors>
<title>Gaiku : Generating Haiku with word associations norms.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL workshop on Computational Approaches to Linguistic Creativity.</booktitle>
<contexts>
<context position="3639" citStr="Netzer et al., 2009" startWordPosition="554" endWordPosition="557">�2011 Association for Computational Linguistics etry. Greene et al. (2010) use a finite state transducer to infer the syllable-stress assignments in lines of poetry under metrical constraints. Genzel et al. (2010) incorporate constraints on meter and rhyme (where the stress and rhyming information is derived from a pronunciation dictionary) into a machine translation system. Jiang and Zhou (2008) develop a system to generate the second line of a Chinese couplet given the first. A few researchers have also explored the problem of poetry generation under some constraints (Manurung et al., 2000; Netzer et al., 2009; Ramakrishnan et al., 2009). There has also been some work on computational approaches to characterizing rhymes (Byrd and Chodorow, 1985) and global properties of the rhyme network (Sonderegger, 2011) in English. To the best of our knowledge, there has been no language-independent computational work on finding rhyme schemes. 3 Finding Stanza Rhyme Schemes A collection of rhyming poetry inevitably contains repetition of rhyming pairs. For example, the word trees will often rhyme with breeze across different stanzas, even those with different rhyme schemes and written by different authors. This</context>
</contexts>
<marker>Netzer, Gabay, Goldberg, Elhadad, 2009</marker>
<rawString>Yael Netzer, David Gabay, Yoav Goldberg, and Michael Elhadad. 2009. Gaiku : Generating Haiku with word associations norms. In Proceedings of the NAACL workshop on Computational Approaches to Linguistic Creativity.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ananth Ramakrishnan</author>
<author>Sankar Kuppan</author>
<author>Sobha Lalitha Devi</author>
</authors>
<title>Automatic generation of Tamil lyrics for melodies.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL workshop on Computational Approaches to Linguistic Creativity.</booktitle>
<contexts>
<context position="3667" citStr="Ramakrishnan et al., 2009" startWordPosition="558" endWordPosition="561"> Computational Linguistics etry. Greene et al. (2010) use a finite state transducer to infer the syllable-stress assignments in lines of poetry under metrical constraints. Genzel et al. (2010) incorporate constraints on meter and rhyme (where the stress and rhyming information is derived from a pronunciation dictionary) into a machine translation system. Jiang and Zhou (2008) develop a system to generate the second line of a Chinese couplet given the first. A few researchers have also explored the problem of poetry generation under some constraints (Manurung et al., 2000; Netzer et al., 2009; Ramakrishnan et al., 2009). There has also been some work on computational approaches to characterizing rhymes (Byrd and Chodorow, 1985) and global properties of the rhyme network (Sonderegger, 2011) in English. To the best of our knowledge, there has been no language-independent computational work on finding rhyme schemes. 3 Finding Stanza Rhyme Schemes A collection of rhyming poetry inevitably contains repetition of rhyming pairs. For example, the word trees will often rhyme with breeze across different stanzas, even those with different rhyme schemes and written by different authors. This is partly due to sparsity o</context>
</contexts>
<marker>Ramakrishnan, Kuppan, Devi, 2009</marker>
<rawString>Ananth Ramakrishnan, Sankar Kuppan, and Sobha Lalitha Devi. 2009. Automatic generation of Tamil lyrics for melodies. In Proceedings of the NAACL workshop on Computational Approaches to Linguistic Creativity.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morgan Sonderegger</author>
</authors>
<title>Applications of graph theory to an English rhyming corpus. Computer Speech and Language,</title>
<date>2011</date>
<pages>25--655</pages>
<contexts>
<context position="3840" citStr="Sonderegger, 2011" startWordPosition="585" endWordPosition="587"> al. (2010) incorporate constraints on meter and rhyme (where the stress and rhyming information is derived from a pronunciation dictionary) into a machine translation system. Jiang and Zhou (2008) develop a system to generate the second line of a Chinese couplet given the first. A few researchers have also explored the problem of poetry generation under some constraints (Manurung et al., 2000; Netzer et al., 2009; Ramakrishnan et al., 2009). There has also been some work on computational approaches to characterizing rhymes (Byrd and Chodorow, 1985) and global properties of the rhyme network (Sonderegger, 2011) in English. To the best of our knowledge, there has been no language-independent computational work on finding rhyme schemes. 3 Finding Stanza Rhyme Schemes A collection of rhyming poetry inevitably contains repetition of rhyming pairs. For example, the word trees will often rhyme with breeze across different stanzas, even those with different rhyme schemes and written by different authors. This is partly due to sparsity of rhymes – many words that have no rhymes at all, and many others have only a handful, forcing poets to reuse rhyming pairs. In this section, we describe an unsupervised alg</context>
<context position="7408" citStr="Sonderegger (2011)" startWordPosition="1240" endWordPosition="1241"> number of rhyme schemes of length n is technically the number of partitions of an n- element set (the Bell number), only a subset of these are typically used. Yn i=1 P(r) X rER 78 P(xi) is simply the relative frequency of the word xi in the data. Maximization Step: Update θ and ρ: P(r|x) (3) r,x:v rhymes with w �ρr = P(r|x)/ � P(q|x) (4) xEX qER,xEX After Convergence: Label each stanza x with the best rhyme scheme, arg maxrER P(r|x). 3.3 Data We test the algorithm on rhyming poetry in English and French. The English data is an edited version of the public-domain portion of the corpus used by Sonderegger (2011), and consists of just under 12000 stanzas spanning a range of poets and dates from the 15th to 20th centuries. The French data is from the ARTFL project (Morrissey, 2011), and contains about 3000 stanzas. All poems in the data are manually annotated with rhyme schemes. The set R is taken to be all the rhyme schemes from the gold standard annotations of both corpora, numbering 462 schemes in total, with an average of 6.5 schemes per stanza length. There are 27.12 candidate rhyme schemes on an average for each English stanza, and 33.81 for each French stanza. 3.4 Results We measure the accuracy</context>
</contexts>
<marker>Sonderegger, 2011</marker>
<rawString>Morgan Sonderegger. 2011. Applications of graph theory to an English rhyming corpus. Computer Speech and Language, 25:655–678.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henry Wyld</author>
</authors>
<title>Studies in English rhymes from Surrey to Pope.</title>
<date>1923</date>
<publisher>J Murray,</publisher>
<location>London.</location>
<contexts>
<context position="1906" citStr="Wyld, 1923" startWordPosition="290" endWordPosition="291">amount of annotated poetry data in various languages. • ‘Culturomics’ The field of digital humanities is growing, with a focus on statistics to track cultural and literary trends (partially spurred by projects like the Google Books Ngrams1). 1http://ngrams.googlelabs.com/ 77 Rhyming corpora could be extremely useful for large-scale statistical analyses of poetic texts. • Historical Linguistics/Study of Dialects Rhymes of a word in poetry of a given time period or dialect region provide clues about its pronunciation in that time or dialect, a fact that is often taken advantage of by linguists (Wyld, 1923). One could automate this task given enough annotated data. An obvious approach to finding rhyme schemes is to use word pronunciations and a definition of rhyme, in which case the problem is fairly easy. However, we favor an unsupervised solution that utilizes no external knowledge for several reasons. • Pronunciation dictionaries are simply not available for many languages. When dictionaries are available, they do not include all possible words, or account for different dialects. • The definition of rhyme varies across poetic traditions and languages, and may include slant rhymes like gate/ma</context>
</contexts>
<marker>Wyld, 1923</marker>
<rawString>Henry Wyld. 1923. Studies in English rhymes from Surrey to Pope. J Murray, London.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>