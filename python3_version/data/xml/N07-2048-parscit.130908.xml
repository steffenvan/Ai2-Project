<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002620">
<title confidence="0.9983575">
Modifying SO-PMI for Japanese Weblog Opinion Mining by Using a
Balancing Factor and Detecting Neutral Expressions
</title>
<author confidence="0.996668">
Guangwei Wang
</author>
<affiliation confidence="0.91480725">
Graduate School of Information
Science and Technology
Hokkaido University
Sapporo, Japan 060-0814
</affiliation>
<email confidence="0.990255">
wgw@media.eng.hokudai.ac.jp
</email>
<sectionHeader confidence="0.993673" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999912368421053">
We propose a variation of the SO-PMI al-
gorithm for Japanese, for use in Weblog
Opinion Mining. SO-PMI is an unsuper-
vised approach proposed by Turney that
has been shown to work well for English.
We first used the SO-PMI algorithm on
Japanese in a way very similar to Turney’s
original idea. The result of this trial leaned
heavily toward positive opinions. We then
expanded the reference words to be sets of
words, tried to introduce a balancing fac-
tor and to detect neutral expressions. After
these modifications, we achieved a well-
balanced result: both positive and negative
accuracy exceeded 70%. This shows that
our proposed approach not only adapted
the SO-PMI for Japanese, but also modi-
fied it to analyze Japanese opinions more
effectively.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999200307692308">
Recently, more and more websites add information
in the form of personal opinions to the Web, e.g.
customer reviews of products, forums, discussion
groups, and blogs. Here, we use the term Weblog for
these sites. This type of information is often useful.
However, we have to deal with an enormous amount
of unstructured and/or semi-structured data. These
data are subjective, in free format and mostly tex-
tual, thus using them is difficult and time consum-
ing. Therefore, how to mine the Weblog opinions
automatically more effectively has attracted more
and more attention (Gamon, 2005; Popescu, 2005;
Chaovalit, 2005).
</bodyText>
<subsectionHeader confidence="0.640091">
Kenji Araki
</subsectionHeader>
<bodyText confidence="0.99131275">
Graduate School of Information
Science and Technology
Hokkaido University
Sapporo, Japan 060-0814
araki@media.eng.hokudai.ac.jp
Turney (2002) has presented an unsupervised
opinion classification algorithm called SO-PMI (Se-
mantic Orientation Using Pointwise Mutual Infor-
mation). The main use of SO-PMI is to estimate
the semantic orientation (i.e. positive or negative)
of a phrase by measuring the hits returned from a
search engine of pairs of words or phrases, based on
the mutual information theory. This approach has
previously been successfully used on English. The
average accuracy was 74% when evaluated on 410
reviews from Epinions1.
However, according to our preliminary experi-
ment, directly translating Turney’s original idea into
Japanese gave a very slanted result, with a positive
accuracy of 95% and a negative accuracy of only
8%. We found that the balance between the posi-
tive and negative sides is influenced greatly by the
page hits of reference words/sets, since a search en-
gine is used. Therefore, we introduced a balancing
factor according for the difference in occurrence be-
tween positive and negative words. And then we
added several threshold rules to detect neutral ex-
pressions. The proposed approach is evaluated on
200 positive and 200 negative Japanese opinion sen-
tences and yielded a well-balanced result.
In the remainder of this paper, we review the SO-
PMI Algorithm in Section 2, then adapt the SO-PMI
for Japanese and present the modifications in Sec-
tion 3. In section 4, we evaluate and discuss the
experimental results. Section 5 gives concluding re-
marks.
</bodyText>
<sectionHeader confidence="0.677344" genericHeader="method">
2 Details of the SO-PMI Algorithm
</sectionHeader>
<bodyText confidence="0.962517">
The SO-PMI algorithm (Turney, 2002) is used to es-
timate the semantic orientation (SO) of a phrase by
</bodyText>
<footnote confidence="0.996659">
1http://www.epinions.com
</footnote>
<page confidence="0.961311">
189
</page>
<note confidence="0.371693">
Proceedings of NAACL HLT 2007, Companion Volume, pages 189–192,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.997061">
measuring the similarity of pairs of words or phrases
using the following formula:
</bodyText>
<equation confidence="0.999685333333333">
PMI(word1,word2)=lo92Ip(w ord1)p(word2))J (1)
SO(phrase) = PMI(phrase,“excellent&amp;quot;)
−PMI(phrase,“poor&amp;quot;) (2)
</equation>
<bodyText confidence="0.997801125">
The reference words “excellent” and “poor” are
used, thus SO is positive when a phrase is more
strongly associated with “excellent” and negative
when a phrase is more strongly associated with
“poor”. Let hits(query) be the number of hits re-
turned when using a search engine, the following
estimate of SO can be derived from Formula (2) and
(1) with some minor algebraic manipulation.
</bodyText>
<equation confidence="0.890234666666667">
SO(phrase) = log2 [A]
A = hits(phrase NEAR“excellent&amp;quot;)*hits(“poor&amp;quot;) (3)
hits(phrase NEAR “poor&amp;quot;)*hits( “excellent&amp;quot; )
</equation>
<bodyText confidence="0.998507857142857">
Turney used AltaVista2 search engine because it
has a NEAR operator. This operator constrains the
search to documents that contain the words within
ten words of one another, in either order. Turney’s
previous work has shown that NEAR performs bet-
ter than AND when measuring the strength of se-
mantic association between words.
</bodyText>
<sectionHeader confidence="0.992606" genericHeader="method">
3 Our Proposed Approach
</sectionHeader>
<bodyText confidence="0.999966571428571">
The first step of our approach is to extract opin-
ion phrases using word POS (part of speech) tem-
plates based on our analysis of opinions in Japanese
Weblog and the results of related work (Kobayashi,
2003; Taku, 2002; Wang, 2006). The second step is
to estimate the semantic orientation of the extracted
phrases, using the SO-PMI algorithm.
</bodyText>
<subsectionHeader confidence="0.999735">
3.1 Adapting SO-PMI for Japanese
</subsectionHeader>
<bodyText confidence="0.997254333333333">
Following Turney’s original idea, we first translated
the SO formula to the one shown in Formula (4) for
Japanese.
</bodyText>
<equation confidence="0.995082">
SO(phrase) = log2 [B] (4)
</equation>
<bodyText confidence="0.999882">
We used the Google search engine3 to get the
hits(query) even though Google does not have a
NEAR operator. The AltaVista NEAR operator does
not work well for Japanese and Google indexes more
</bodyText>
<footnote confidence="0.999724">
2http://www.altavista.com/sites/search/adv
3http://www.google.co.jp/
</footnote>
<bodyText confidence="0.997636">
pages than AltaVista, thus we used Google and re-
placed the NEAR operator with the AND operator in
the SO formula. “ ” and “ ” were se-
lected because they correspond to the English words
“excellent” and “poor”.
For testing the performance of this trial, we used
200 positive and 200 negative Japanese opinion sen-
tences which have been labeled by hand. The re-
sults were very slanted. Many phrases, whether pos-
itive or negative in meaning, still received a posi-
tive SO. Some possible causes could be that “
(poor)” has more hits than “ (excellent)”,
as shown in Table 1, and that the AND operator is
less useful than the NEAR operator.
</bodyText>
<subsectionHeader confidence="0.998866">
3.2 Modifying SO-PMI for Japanese
</subsectionHeader>
<bodyText confidence="0.98405875">
In Japanese, there are many expressions when
people evaluate something. For example, “
(good)”, “ (good)”, “ (satisfaction)” , “
(excellent)” are usually used when some-
one wants to convey a positive opinion. Hence
we tried to replace the reference words “excellent”
and “poor” with two reference sets: “p−basic” and
“n−basic”:
</bodyText>
<equation confidence="0.969503">
SO(phrase) = log2 [C]
C = hits(phrase ANDp_basic)*hits(n_basic) (5)
hits(phrase ANDn_ basic) *hits(p_ basic)
</equation>
<bodyText confidence="0.9990102">
“p−basic” is a set of common strong positive
words in Japanese. “n−basic” is a set of common
weak negative words. The hit counts of these words
from Google is shown in Table 1 (All data from
2007/01/12). The hits(query) was calculated by
</bodyText>
<equation confidence="0.3711255">
hits(phrase AND (“ (good)” OR “ (like)”)
OR “ (good)” OR ...).
</equation>
<tableCaption confidence="0.993972">
Table 1: Frequency of p_basic/n_basic words on the Web
</tableCaption>
<bodyText confidence="0.954746">
We evaluated this modification using the same
</bodyText>
<page confidence="0.99411">
190
</page>
<bodyText confidence="0.999960846153846">
data as in Section 3.1. We obtained a slightly bet-
ter result. However the SO values were still slanted.
This time many phrases, whether positive or nega-
tive in meaning, still received a negative SO. All of
these test results are shown in detail in Section 4.2.
In the experiments above, we obtained heavily
slanted results. We consider that the large differ-
ence in page hits between the positive and negative
reference words/sets are the main cause for this phe-
nomenon. To mitigate this problem, we decided to
introduce a balancing factor to adjust the balance be-
tween the positive and negative sides. The SO for-
mula was modified from (5) to (6).
</bodyText>
<equation confidence="0.9332835">
SO(phrase) = log2 [C] + f (α) (6)
The balancing factor f(α) was calculated by For-
mula (7).
f (α) = α * log2 hits(p−basic)[hits(n−basic)] (7)
</equation>
<bodyText confidence="0.999690473684211">
The log2 of “p−basic” and “n−basic” is a fac-
tor that adjusts the balance of the similarity of
“p−basic”/“n−basic” and phrases automatically by
the hits of “p−basic”/“n−basic” itself. α is a weight
value. We evaluated different values of α from “0.0”
to “1.0” on the benchmark dataset, which is shown
in detail in Section 4.2.
From these preliminary trials, we also found that
many neutral phrases often receive positive or neg-
ative SO. Therefore we added detection of neu-
tral expressions. The idea is that if the phrase is
strongly or faintly associated with both “p−basic”
and “n−basic”, it is considered a neutral phrase. Be-
cause this means that this phrase has an ambiguous
connection with both “p−basic” and “n−basic”. We
use the following rules (Figure 1) to separate neutral
phrases from positive/negative phrases. The thresh-
old values ta, tb and tc are obtained from a small,
hand-labeled corpus.
</bodyText>
<figureCaption confidence="0.984889">
Figure 1: Rules for Detecting Neutral Expressions
</figureCaption>
<sectionHeader confidence="0.987442" genericHeader="method">
4 Experimental Performance Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999463">
4.1 Gold Standard and Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.99997904">
As a gold standard, we collected a benchmark
dataset which has 200 positive opinion sentences
and 200 negative opinion sentences from the reviews
about Electronic Dictionary and MP3 Player prod-
ucts that have been labeled as either positive or neg-
ative reviews in “Kakaku.com”4. “Kakaku.com” is
the largest Japanese Weblog specializing in product
comparison of consumer goods, including price and
user opinions, etc. Lots of people exchange mis-
cellaneous product information and reviews. These
reviews are classified as questions, positive re-
views, negative reviews, rumors, sale information or
“other” category.
To classify a sentence as positive (P) or negative
(N), the average SO of the phrases in the sentence is
used. If the average SO is P, the sentence is a posi-
tive sentence; otherwise it is a negative sentence. As
evaluation metrics, we measured our proposed ap-
proach’s performance by accuracy. accuracy was
measured as the number of sentences correctly clas-
sified as P/N sentences to the total number of P/N
sentences in the benchmark dataset (200). PA means
positive accuracy, NA means negative accuracy, i.e.
the accuracy on only positive or negative sentences
respectively.
</bodyText>
<subsectionHeader confidence="0.98499">
4.2 Experiments and Results
</subsectionHeader>
<bodyText confidence="0.9999725">
First we did the balancing factor experiment to
determine the value of “α”, using the benchmark
dataset. The results are shown in Figure 2. (a)
and (b) show the dashed line indicates average ac-
curacy (74%) on English Data from Turney’s Study
(2002). Turney didn’t evaluate positive and nega-
tive accuracy respectively. The full drawn line indi-
cates the result after translating the original SO-PMI
to Japanese (PA:95%, NA: 8%). PA series (the line
with triangle mark)/NA series (the line with circle
mark) when values of “α” from “0.0” to “1.0” were
used.
Changing the α tends to be a tradeoff, lowering
PA when NA is improved and vice versa. There-
fore, we used Harmonic−Mean by the following
formula to find a proper value of “α”.
</bodyText>
<equation confidence="0.789069">
2*PA*NA
Harmonic−Mean = PA + NA (8)
</equation>
<bodyText confidence="0.467215">
Figure 2, (c) shows PA, NA and
Harmonic−Mean curves for different values
</bodyText>
<footnote confidence="0.975311">
4http://www.kakaku.com/
</footnote>
<page confidence="0.99138">
191
</page>
<figure confidence="0.968551">
(a) Positive Accuracy (PA) (b) Negative Accuracy (NA) (c) Harmonic-Mean of PA/NA
</figure>
<figureCaption confidence="0.999753">
Figure 2: Experiment for α in Balance Factor
</figureCaption>
<bodyText confidence="0.993413833333333">
of “α”. We selected the “α=0.9” giving the highest
Harmonic−Mean value, thus giving a good
balance between PA (75%) and NA (70%).
The comparative experiment results between the
SO-PMI for Japanese (Test 1), and our modifications
(Test 2, 3, 4) are shown in Table 2.
</bodyText>
<tableCaption confidence="0.973371">
Table 2: Comparative Experiment Results
</tableCaption>
<bodyText confidence="0.999103818181818">
In Test 1 and 2, we obtained extreme results, lean-
ing to the positive or negative end, whether using the
Turney’s original approach or expanding the refer-
ence word as “p−basic” and “n−basic”. In Test 3,
we added a balancing factor as described in section
3.2, and obtained a comparatively well-balanced re-
sult. Finally, after adding the neutral expressions de-
tection, we achieved a PA of 78% and NA of 72%
(Test 4). The balance between positive and negative
sides was quite improved by contrast with Test 1 and
2.
</bodyText>
<sectionHeader confidence="0.99942" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999977904761905">
This study first proposed a modified unsupervised
approach (SO-PMI) for Japanese Weblog Opinion
Mining. Some parts of Turney’s approach, such as
the NEAR operator, does not work for Japanese,
thus some modifications must be done. In a prelim-
inary experiment, the negative accuracy (8%) was
very poor while the positive accuracy (95%) was
high. To deal with this phenomenon, we presented
three modifications based on the characteristics of
Japanese and the results of related work. The ex-
periment results (positive accuracy: 78%, negative
accuracy: 72%) show that our proposal achieved
a considerably improved performance, comparing
with directly translating the SO-PMI. Hence it
would be expected that the balancing factor and neu-
tral expressions detection would work effectively
also for other reference words or languages. In the
future, we will evaluate different choices of words
for the sets of positive and negative reference words.
We also plan to appraise our proposal on other lan-
guages.
</bodyText>
<sectionHeader confidence="0.999097" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99981408">
Peter D. Turney. 2002. Thumbs up or thumbs down? Semantic
orientation applied to unsupervised classification of reviews.
Proceedings 40th Annual Meeting of the ACL, pp. 417-424.
Popescu, Ana-Maria, and Oren Etzioni. 2005. Extracting Prod-
uct Features and Opinions from Reviews. Proceedings of
HLT-EMNLP.
Michael Gamon, Anthony Aue, Simon Corston-Oliver and Eric
K. Ringger. 2005. Pulse: Mining Customer Opinions from
Free Text. Proceedings of the 2005 Conference on Intelligent
Data Analysis (IDA), pp.121-132.
Pimwadee Chaovalit and Lina Zhou. 2005. Movie Review Min-
ing: a Comparison between Supervised and Unsupervised
Classification Approaches. Proceedings of the 38th Annual
HICSS.
Nozomi Kobayashi, Kentaro Inui, Yuji Matsumoto, Kenji
Tateishi and Toshikazu Fukushima. 2003. Collecting eval-
uative expressions by a text mining technique. IPSJ SIG
NOTE, Vol.154, No.12, In Japanese.
Taku Kudoh and Yuji Matsumoto. 2002. Applying Cascaded
Chunking to Japanese Dependency Structure Analysis. In-
formation Processing Society of Japan (IPSJ)Academic
Journals, Vol 43, No 6, pp. 1834-1842, In Japanese.
Guangwei Wang and Kenji Araki. 2006. A Decision Support
System Using Text Mining Technology. IEICE SIG Notes
WI2-2006-6, pp. 55-56.
</reference>
<page confidence="0.998194">
192
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.538786">
<title confidence="0.9971335">Modifying SO-PMI for Japanese Weblog Opinion Mining by Using Balancing Factor and Detecting Neutral Expressions</title>
<author confidence="0.929497">Guangwei</author>
<affiliation confidence="0.88151">Graduate School of Science and Hokkaido</affiliation>
<address confidence="0.94535">Sapporo, Japan</address>
<email confidence="0.988777">wgw@media.eng.hokudai.ac.jp</email>
<abstract confidence="0.99511955">We propose a variation of the SO-PMI algorithm for Japanese, for use in Weblog Opinion Mining. SO-PMI is an unsupervised approach proposed by Turney that has been shown to work well for English. We first used the SO-PMI algorithm on Japanese in a way very similar to Turney’s original idea. The result of this trial leaned heavily toward positive opinions. We then expanded the reference words to be sets of words, tried to introduce a balancing factor and to detect neutral expressions. After these modifications, we achieved a wellbalanced result: both positive and negative accuracy exceeded 70%. This shows that our proposed approach not only adapted the SO-PMI for Japanese, but also modified it to analyze Japanese opinions more effectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>Proceedings 40th Annual Meeting of the ACL,</booktitle>
<pages>417--424</pages>
<contexts>
<context position="1798" citStr="Turney (2002)" startWordPosition="272" endWordPosition="273"> blogs. Here, we use the term Weblog for these sites. This type of information is often useful. However, we have to deal with an enormous amount of unstructured and/or semi-structured data. These data are subjective, in free format and mostly textual, thus using them is difficult and time consuming. Therefore, how to mine the Weblog opinions automatically more effectively has attracted more and more attention (Gamon, 2005; Popescu, 2005; Chaovalit, 2005). Kenji Araki Graduate School of Information Science and Technology Hokkaido University Sapporo, Japan 060-0814 araki@media.eng.hokudai.ac.jp Turney (2002) has presented an unsupervised opinion classification algorithm called SO-PMI (Semantic Orientation Using Pointwise Mutual Information). The main use of SO-PMI is to estimate the semantic orientation (i.e. positive or negative) of a phrase by measuring the hits returned from a search engine of pairs of words or phrases, based on the mutual information theory. This approach has previously been successfully used on English. The average accuracy was 74% when evaluated on 410 reviews from Epinions1. However, according to our preliminary experiment, directly translating Turney’s original idea into </context>
<context position="3316" citStr="Turney, 2002" startWordPosition="516" endWordPosition="517">ctor according for the difference in occurrence between positive and negative words. And then we added several threshold rules to detect neutral expressions. The proposed approach is evaluated on 200 positive and 200 negative Japanese opinion sentences and yielded a well-balanced result. In the remainder of this paper, we review the SOPMI Algorithm in Section 2, then adapt the SO-PMI for Japanese and present the modifications in Section 3. In section 4, we evaluate and discuss the experimental results. Section 5 gives concluding remarks. 2 Details of the SO-PMI Algorithm The SO-PMI algorithm (Turney, 2002) is used to estimate the semantic orientation (SO) of a phrase by 1http://www.epinions.com 189 Proceedings of NAACL HLT 2007, Companion Volume, pages 189–192, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics measuring the similarity of pairs of words or phrases using the following formula: PMI(word1,word2)=lo92Ip(w ord1)p(word2))J (1) SO(phrase) = PMI(phrase,“excellent&amp;quot;) −PMI(phrase,“poor&amp;quot;) (2) The reference words “excellent” and “poor” are used, thus SO is positive when a phrase is more strongly associated with “excellent” and negative when a phrase is more strongly</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews. Proceedings 40th Annual Meeting of the ACL, pp. 417-424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting Product Features and Opinions from Reviews.</title>
<date>2005</date>
<booktitle>Proceedings of HLT-EMNLP.</booktitle>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Popescu, Ana-Maria, and Oren Etzioni. 2005. Extracting Product Features and Opinions from Reviews. Proceedings of HLT-EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
<author>Anthony Aue</author>
<author>Simon Corston-Oliver</author>
<author>Eric K Ringger</author>
</authors>
<title>Pulse: Mining Customer Opinions from Free Text.</title>
<date>2005</date>
<booktitle>Proceedings of the 2005 Conference on Intelligent Data Analysis (IDA),</booktitle>
<pages>121--132</pages>
<marker>Gamon, Aue, Corston-Oliver, Ringger, 2005</marker>
<rawString>Michael Gamon, Anthony Aue, Simon Corston-Oliver and Eric K. Ringger. 2005. Pulse: Mining Customer Opinions from Free Text. Proceedings of the 2005 Conference on Intelligent Data Analysis (IDA), pp.121-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pimwadee Chaovalit</author>
<author>Lina Zhou</author>
</authors>
<title>Movie Review Mining: a Comparison between Supervised and Unsupervised Classification Approaches.</title>
<date>2005</date>
<booktitle>Proceedings of the 38th Annual HICSS.</booktitle>
<marker>Chaovalit, Zhou, 2005</marker>
<rawString>Pimwadee Chaovalit and Lina Zhou. 2005. Movie Review Mining: a Comparison between Supervised and Unsupervised Classification Approaches. Proceedings of the 38th Annual HICSS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nozomi Kobayashi</author>
</authors>
<title>Kentaro Inui, Yuji Matsumoto, Kenji Tateishi and Toshikazu Fukushima.</title>
<date>2003</date>
<booktitle>IPSJ SIG NOTE, Vol.154, No.12, In Japanese.</booktitle>
<contexts>
<context position="4796" citStr="Kobayashi, 2003" startWordPosition="742" endWordPosition="743">its(“poor&amp;quot;) (3) hits(phrase NEAR “poor&amp;quot;)*hits( “excellent&amp;quot; ) Turney used AltaVista2 search engine because it has a NEAR operator. This operator constrains the search to documents that contain the words within ten words of one another, in either order. Turney’s previous work has shown that NEAR performs better than AND when measuring the strength of semantic association between words. 3 Our Proposed Approach The first step of our approach is to extract opinion phrases using word POS (part of speech) templates based on our analysis of opinions in Japanese Weblog and the results of related work (Kobayashi, 2003; Taku, 2002; Wang, 2006). The second step is to estimate the semantic orientation of the extracted phrases, using the SO-PMI algorithm. 3.1 Adapting SO-PMI for Japanese Following Turney’s original idea, we first translated the SO formula to the one shown in Formula (4) for Japanese. SO(phrase) = log2 [B] (4) We used the Google search engine3 to get the hits(query) even though Google does not have a NEAR operator. The AltaVista NEAR operator does not work well for Japanese and Google indexes more 2http://www.altavista.com/sites/search/adv 3http://www.google.co.jp/ pages than AltaVista, thus we</context>
</contexts>
<marker>Kobayashi, 2003</marker>
<rawString>Nozomi Kobayashi, Kentaro Inui, Yuji Matsumoto, Kenji Tateishi and Toshikazu Fukushima. 2003. Collecting evaluative expressions by a text mining technique. IPSJ SIG NOTE, Vol.154, No.12, In Japanese.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudoh</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Applying Cascaded Chunking to Japanese Dependency Structure Analysis.</title>
<date>2002</date>
<journal>Information Processing Society of Japan (IPSJ)Academic Journals, Vol</journal>
<volume>43</volume>
<pages>1834--1842</pages>
<location>In Japanese.</location>
<marker>Kudoh, Matsumoto, 2002</marker>
<rawString>Taku Kudoh and Yuji Matsumoto. 2002. Applying Cascaded Chunking to Japanese Dependency Structure Analysis. Information Processing Society of Japan (IPSJ)Academic Journals, Vol 43, No 6, pp. 1834-1842, In Japanese.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guangwei Wang</author>
<author>Kenji Araki</author>
</authors>
<title>A Decision Support System Using Text Mining Technology.</title>
<date>2006</date>
<journal>IEICE SIG Notes</journal>
<pages>2--2006</pages>
<marker>Wang, Araki, 2006</marker>
<rawString>Guangwei Wang and Kenji Araki. 2006. A Decision Support System Using Text Mining Technology. IEICE SIG Notes WI2-2006-6, pp. 55-56.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>