<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.051261">
<title confidence="0.940324">
SemEval-2012 Task 4: Evaluating Chinese Word Similarity
</title>
<author confidence="0.998869">
Peng Jin Yunfang Wu
</author>
<affiliation confidence="0.920118">
School of Computer Science Institute of Computational Linguistics
Leshan Normal University Peking University
Leshan, 614000, China Beijing, 100871, China
</affiliation>
<email confidence="0.990777">
jandp@pku.edu.cn wuyf@pku.edu.cn
</email>
<sectionHeader confidence="0.995494" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99979375">
This task focuses on evaluating word similari-
ty computation in Chinese. We follow the way
of Finkelstein et al. (2002) to select word
pairs. Then we organize twenty under-
graduates who are major in Chinese linguis-
tics to annotate the data. Each pair is assigned
a similarity score by each annotator. We rank
the word pairs by the average value of similar
scores among the twenty annotators. This data
is used as gold standard. Four systems partici-
pating in this task return their results. We
evaluate their results on gold standard data in
term of Kendall&apos;s tau value, and the results
show three of them have a positive correlation
with the rank manually created while the taus&apos;
value is very small.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999948585365854">
The goal of word similarity is to compute the simi-
larity degree between words. It is widely used in
natural language processing to alleviate data
sparseness which is an open problem in this field.
Many research have focus on English language
(Lin, 1998; Curran and Moens, 2003; Dinu and
Lapata, 2010), some of which rely on the manual
created thesaurus such as WordNet (Budanitsky
and Hirst, 2006), some of which obtain the similar-
ity of the words via large scale corpus (Lee, 1999),
and some research integrate both thesaurus and
corpus (Fujii et al., 1997). This task tries to evalu-
ate the approach on word similarity for Chinese
language. To the best of our knowledge, this is first
release of benchmark data for this study.
In English language, there are two data sets: Ru-
benstein and Goodenough (1965) and Finkelstein
et al. (2002) created a ranking of word pairs as the
benchmark data. Both of them are manually anno-
tated. In this task, we follow the way to create the
data and annotate the similarity score between
word pairs by twenty Chinese native speakers.
Finkelstein et al. (2002) carried out a psycholin-
guistic experiment: they selected out 353 word
pairs, then ask the annotators assign a numerical
similarity score between 0 and 10 (0 denotes that
words are totally unrelated, 10 denotes that words
are VERY closely related) to each pair. By defini-
tion, the similarity of the word to itself should be
10. A fractional score is allowed.
It should be noted that besides the rank of word
pairs, the thesaurus such as Roget&apos;s thesaurus are
often used for word similarity study (Gorman and
Curran, 2006).
The paper is organized as follows. In section 2
we describe in detail the process of the data prepa-
ration. Section 3 introduces the four participating
systems. Section 4 reports their results and gives a
brief discussion.. And finally in section 5 we bring
forward some suggestions for the next campaign
and conclude the paper.
</bodyText>
<page confidence="0.986555">
374
</page>
<note confidence="0.7241895">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 374–377,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.916359" genericHeader="method">
2 Data Preparation
</sectionHeader>
<subsectionHeader confidence="0.992829">
2.1 Data Set
</subsectionHeader>
<bodyText confidence="0.999552857142857">
We use wordsim 353 (Finkelstein et al., 2002) as
the original data set. First, each word pair is trans-
lated into Chinese by two undergraduates who are
fluent in English. 169 word pairs are the same in
their translation results. To the rest 184 word pairs,
the third undergraduate student check them fol-
lowing the rules:
</bodyText>
<listItem confidence="0.935152176470588">
(i) Single character vs. two characters. If one
translator translate one English word into the Chi-
nese word which consists only one Chinese charac-
ter and the other use two characters to convey the
translation, we will prefer to the later provided that
these two translations are semantically same. For
example, &amp;quot;tiger&amp;quot; is translated into &amp;quot;*&amp;quot; and &amp;quot;Z*&amp;quot;,
we will treat them as same and use &amp;quot;Z*&amp;quot; as the
final translation. This was the same case in &amp;quot;drug&amp;quot;
(&amp;quot;3A&amp;quot; and &amp;quot;3AVA&amp;quot; are same translations).
(ii) Alias. The typical instance is &amp;quot;potato&amp;quot;, both &amp;quot;
�:LR&amp;quot; and &amp;quot;�` &amp;quot; are the correct translations. So
we will treat them as same and prefer &amp;quot;�:LR&amp;quot; as the
final translation because it is more general used
than the latter one.
(iii) There are five distinct word pairs in the
translations and are removed.
</listItem>
<bodyText confidence="0.9997705">
At last, 348 word pairs are used in this task.
Among these 348 word pairs, 50 ones are used as
the trial data and the rest ones are used as the test
data1.
</bodyText>
<subsectionHeader confidence="0.998401">
2.2 Manual Annotation
</subsectionHeader>
<bodyText confidence="0.99998975">
Each word pair is assigned the similarity score by
twenty Chinese native speakers. The score ranges
from 0 to 5 and 0 means two words have nothing
to do with each other and 5 means they are identi-
cally in semantic meaning. The higher score means
the more similar between two words. Not only in-
teger but also real is acceptable as the annotated
score. We get the average of all the scores given by
the annotators for each word pair and then sort
them according to the similarity scores. The distri-
bution of word pairs on the similar score is illus-
trated as table 1.
</bodyText>
<footnote confidence="0.9731155">
1 In fact there are 297 word pairs are evaluated because one
pair is missed during the annotation.
</footnote>
<table confidence="0.973958368421052">
Score 0.0-1.0 1.0-2.0 2.0-3.0 3.0-4.0 4.0-5.0
# Word pairs 39 90 132 72 13
Table1: The distribution of similarity score
Ra- Word in Chi- Word 2 in Simi- Std. RSD
nk nese/English Chinese/ Eng- larity dev (%)
lish score
1 Xf*/football Xf*/soccer 4.98 0.1 2.0
2 Z*/tiger Z*/tiger 4.89 0.320 6.55
3 MY/planet MY/star 4.72 0.984 20.8
4 k 4 f 7-r. /ticket 4.60 0.516 11.2
/admission
5 VC/money All�/cash 4.58 0.584 12.7
6 Wf7/bank VC/cash 4.29 0.708 16.5
7 -T-#L/cell Ct/phone 4.28 0.751 17.5
8 �,i/gem Act/jewel 4.24 0.767 18.1
9 �Mtype #/kind 4.24 1.000 23.6
10 LA / calcu- #&apos;A / compu- 4.14 0.780 19.0
lation tation
Avg - - 4.496 0.651 14.80
</table>
<tableCaption confidence="0.999742">
Table 2: Top ten similar word pairs
</tableCaption>
<bodyText confidence="0.849964166666667">
Table 2 and table 3 list top ten similar word
pairs and top ten un-similar word pairs individual-
ly. Standard deviation (Std. dev) and relative standard
deviation (RSD) are also computed. Obviously, the rela-
tive standard deviation of top ten similar word pairs is
far less than the un-similar pairs.
</bodyText>
<subsectionHeader confidence="0.999587">
2.3 Annotation Analysis
</subsectionHeader>
<bodyText confidence="0.999540666666667">
Figure 1 illustrates the relationship between the
similarity score and relative standard deviation.
The digits in &amp;quot;x&amp;quot; axes are the average similarity
score of every integer interval, for an instance,
1.506 is the average of all word pairs&apos; similarity
score between 1.0 and 2.0.
</bodyText>
<sectionHeader confidence="0.974642" genericHeader="method">
3 Participating Systems
</sectionHeader>
<bodyText confidence="0.9964415">
Four systems coming from two teams participated
in this task.
</bodyText>
<page confidence="0.997315">
375
</page>
<figureCaption confidence="0.969797">
Figure 1. The relationship between RSD and simi-
lar score
</figureCaption>
<table confidence="0.996445176470588">
Ra- Word1 in Chi- Word2 in Chi- Simi- Std. RSD(
nk nese/in English nese/in English larity dev %)
score
1 ��/noon *4/string 0.06 .213 338.7
2 [AT_/king 41bi 0.16 .382 245.3
/cabbage
3 j p &apos;,( /hike 0.17 .432 247.5
/production
4 giLL/delay # *X 0.26 .502 191.1
/racism
5 A /professor RX/cucumber 0.30 .62 211.1
6 ]RM/stock XVQ/jaguar 0.30 .815 268.2
7 �t/sign Vflk/recess 0.30 .655 215.4
8 RM/stock CD/CD 0.31 .540 173.6
9 Wv/drink _4,e&apos;�,:/ear 0.31 .833 264.8
10 �A/rooster )L&amp;/voyage 0.33 .771 236.7
Avg - - 0.25 .576 239.2
</table>
<tableCaption confidence="0.999958">
Table 3: Top ten un-similar word pairs
</tableCaption>
<bodyText confidence="0.995016625">
MIXCC: This system used two machine reada-
ble dictionary (MRD), HIT IR-Lab Tongyici Cilin
(Extended) (Cilin) and the other is Chinese Con-
cept Dictionary (CCD). The extended CiLin con-
sists of 12 large classes, 97 medium classes, 1,400
small classes (topics), and 17,817 small synonym
sets which cover 77,343 head terms. All the items
are constructed as a tree with five levels. With the
increasing of levels, word senses are more fine-
grained. The Chinese Concept Dictionary is a Chi-
nese WordNet produced by Peking University.
Word concepts are presented as synsets corre-
sponding to WordNet 1.6. Besides synonym, anto-
nym, hypernym/hyponym, holonym/meronym,
there is another semantic relation type named as
attribute which happens between two words with
different part-of-speeches.
They first divide all word pairs into five parts
and rank them according to their levels in Cilin in
descending order. For each part, they computed
word similarity by Jiang and Conrath (1997) meth-
od2.
MIXCD: Different form MIXCC, this system
used the trial data to learn a multiple linear regres-
sion functions. The CCD was considered as a di-
rected graph. The nodes were synsets and edges
were the semantic relations between two synsets.
The features for this system were derived from
CCD and a corpus and listed as follows:
 the shortest path between two synsets
which contain the words
 the rates of 5 semantic relation types
 mutual information of a word pair in the
corpus
They used the result of multiple linear regres-
sions to forecast the similarity of other word pairs
and get the rank.
GUO-ngram: This system used the method
proposed by (Gabrilovich and Markovitch, 2007).
They downloaded the Wikipedia on 25th Novem-
ber, 2011 as the knowledge source. In order to by-
pass the Chinese segmentation, they extract one
character (uni-gram) and two sequential characters
(bi-gram) as the features.
GUO-words: This system is very similar to
GUO-ngram except that the features consist of
words rather than n-grams. They implemented a
simple index method which searches all continuous
character strings appearing in a dictionary. For ex-
ample, given a text string ABCDEFG in which
ABC, BC, and EF appear in the dictionary. The
output of the tokenization algorithm is the three
words ABC, BC, EF and the two characters E and
G.
2 Because there is no sense-tagged corpus for CCD, the fre-
quency of each concept was set to 1 in this system.
</bodyText>
<page confidence="0.997781">
376
</page>
<bodyText confidence="0.99984">
Generally the tau&apos;s value is very small, it indi-
cates that obtaining a good rank is still difficult.
We will provide more word pairs and distinct them
relatedness from similar, and attract more teams to
participate in the interesting task.
</bodyText>
<sectionHeader confidence="0.993599" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.99601475">
Each system is required to rank these 500 word
pairs according to their similarity scores. Table 4
gives the overall results obtained by each of the
systems.
</bodyText>
<table confidence="0.999449571428571">
Rank Team ID System ID Tau&apos;s
value
1 lib MIXCC 0.050
2 MIXCD 0.040
3 Guo-ngram 0.007
Gfp1987
4 Guo-words -0.011
</table>
<tableCaption confidence="0.999732">
Table 4: The results of four systmes
</tableCaption>
<bodyText confidence="0.999836142857143">
The ranks returned by these four systems will be
compared with the rank from human annotation by
the Kendall Rank Correlation Coefficient:
Where is the number of objects. and are
two distinct orderings of a object in two ranks.
S(ir,6) is the minimum number of adjacent
transpositions needing to bring and (Lapata,
2006). In this metric, tau&apos;s value ranges from -1 to
+1 and -1 means that the two ranks are inverse to
each other and +1 means the identical rank.
From table 4, we can see that except the final
system, three of them got the positive tau&apos;s value. It
is regret that the tau&apos;s is very small even if the
MIXCC system is the best one.
</bodyText>
<sectionHeader confidence="0.998954" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999921166666666">
We organize an evaluation task focuses on word
similarity in Chinese language. Totally 347 word
pairs are annotated similarity scores by twenty na-
tive speakers. These word pairs are ordered by the
similarity scores and this rank is used as bench-
mark data for evaluation.
Four systems participated in this task. Except
the system MIXCD, three ones got their own rank
only via the corpus. Kendall&apos;s tau is used as the
evaluation metric. Three of them got the positive
correlation rank compared with the gold standard
data
</bodyText>
<sectionHeader confidence="0.997894" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.779011666666667">
This research is supported by National Natural
Science Foundation of China (NSFC) under Grant
No. 61003206, 60703063.
</bodyText>
<sectionHeader confidence="0.996226" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99988915">
A. Budanitsky and G. Hirst. Evaluating WordNet-based
Measures of Lexical Semantic Relatedness. Compu-
tational Linguistics, 2006, 32(1):13-47.
J. Curran and M. Moens. Scaling Context Space. Pro-
ceedings of ACL, 2002, pp. 231-238.
G. Dinu and M. Lapata. Measuring Distributional Simi-
larity in Context. Proceedings of EMNLP, 2010, pp.
1162-1172.
L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z.
Solan, G. Wolfman, and E. Ruppin. 2002. Placing
Search in Context: The Concept Revisited. ACM
Transactions on Information Systems, 20(1):116-131.
A. Fujii, T. Hasegawa, T. Tokunaga and H. Tanaka.
Integration of Hand-Crafted and Statistical Resources
in Measuring Word Similarity. 1997. Proceedings of
Workshop of Automatic Information Extraction and
Building of Lexical Semantic Resources for NLP Ap-
plications. pp. 45-51.
E. Gabrilovich and S. Markovitch, Computing Semantic
Relatedness using Wikipedia-based Explicit Seman-
tic Analysis, Proceedings of IJCAI, Hyderabad, 2007,
pp. 1606—1611.
J. Gorman and J. Curran. Scaling Distributional Similar-
ity to Large Corpora. Proceedings of ACL, 2006, pp.
361-368.
J. Jiang and D. Conrath. 1997. Semantic similarity
based on corpus statistics and lexical taxonomy. Pro-
ceedings of International Conference on Research in
Computational Linguistics, Taiwan.
M. Lapata. Automatic Evaluation of Information Order-
ing: Kendall&apos;s Tau. Computational Linguistics, 2006,
32(4):471-484.
D. Lin. Automatic Retrieval and Clustering of Similar
Words. Proceedings of ACL / COLING, 1998, pp.
768-774.
L. Lee. Measures of Distributional Similarity. Proceed-
ings of ACL, 1999, pp. 25-32.
H. Rubenstein and J.B. Goodenough. 1965. Contextual
correlates of synonymy. Communications of the ACM,
8(10):627-633.
</reference>
<page confidence="0.998401">
377
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.833670">
<title confidence="0.992251">SemEval-2012 Task 4: Evaluating Chinese Word Similarity</title>
<author confidence="0.999729">Peng Jin Yunfang Wu</author>
<affiliation confidence="0.999715">School of Computer Science Institute of Computational Linguistics Leshan Normal University Peking University</affiliation>
<address confidence="0.99981">Leshan, 614000, China Beijing, 100871, China</address>
<email confidence="0.847787">jandp@pku.edu.cnwuyf@pku.edu.cn</email>
<abstract confidence="0.999515058823529">This task focuses on evaluating word similarity computation in Chinese. We follow the way of Finkelstein et al. (2002) to select word pairs. Then we organize twenty undergraduates who are major in Chinese linguistics to annotate the data. Each pair is assigned a similarity score by each annotator. We rank the word pairs by the average value of similar scores among the twenty annotators. This data is used as gold standard. Four systems participating in this task return their results. We evaluate their results on gold standard data in term of Kendall&apos;s tau value, and the results show three of them have a positive correlation with the rank manually created while the taus&apos; value is very small.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Budanitsky</author>
<author>G Hirst</author>
</authors>
<title>Evaluating WordNet-based Measures of Lexical Semantic Relatedness. Computational Linguistics,</title>
<date>2006</date>
<pages>32--1</pages>
<contexts>
<context position="1383" citStr="Budanitsky and Hirst, 2006" startWordPosition="219" endWordPosition="222">ts. We evaluate their results on gold standard data in term of Kendall&apos;s tau value, and the results show three of them have a positive correlation with the rank manually created while the taus&apos; value is very small. 1 Introduction The goal of word similarity is to compute the similarity degree between words. It is widely used in natural language processing to alleviate data sparseness which is an open problem in this field. Many research have focus on English language (Lin, 1998; Curran and Moens, 2003; Dinu and Lapata, 2010), some of which rely on the manual created thesaurus such as WordNet (Budanitsky and Hirst, 2006), some of which obtain the similarity of the words via large scale corpus (Lee, 1999), and some research integrate both thesaurus and corpus (Fujii et al., 1997). This task tries to evaluate the approach on word similarity for Chinese language. To the best of our knowledge, this is first release of benchmark data for this study. In English language, there are two data sets: Rubenstein and Goodenough (1965) and Finkelstein et al. (2002) created a ranking of word pairs as the benchmark data. Both of them are manually annotated. In this task, we follow the way to create the data and annotate the </context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>A. Budanitsky and G. Hirst. Evaluating WordNet-based Measures of Lexical Semantic Relatedness. Computational Linguistics, 2006, 32(1):13-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Curran</author>
<author>M Moens</author>
</authors>
<title>Scaling Context Space.</title>
<date>2002</date>
<booktitle>Proceedings of ACL,</booktitle>
<pages>231--238</pages>
<marker>Curran, Moens, 2002</marker>
<rawString>J. Curran and M. Moens. Scaling Context Space. Proceedings of ACL, 2002, pp. 231-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Dinu</author>
<author>M Lapata</author>
</authors>
<title>Measuring Distributional Similarity in Context.</title>
<date>2010</date>
<booktitle>Proceedings of EMNLP,</booktitle>
<pages>1162--1172</pages>
<contexts>
<context position="1286" citStr="Dinu and Lapata, 2010" startWordPosition="203" endWordPosition="206">is data is used as gold standard. Four systems participating in this task return their results. We evaluate their results on gold standard data in term of Kendall&apos;s tau value, and the results show three of them have a positive correlation with the rank manually created while the taus&apos; value is very small. 1 Introduction The goal of word similarity is to compute the similarity degree between words. It is widely used in natural language processing to alleviate data sparseness which is an open problem in this field. Many research have focus on English language (Lin, 1998; Curran and Moens, 2003; Dinu and Lapata, 2010), some of which rely on the manual created thesaurus such as WordNet (Budanitsky and Hirst, 2006), some of which obtain the similarity of the words via large scale corpus (Lee, 1999), and some research integrate both thesaurus and corpus (Fujii et al., 1997). This task tries to evaluate the approach on word similarity for Chinese language. To the best of our knowledge, this is first release of benchmark data for this study. In English language, there are two data sets: Rubenstein and Goodenough (1965) and Finkelstein et al. (2002) created a ranking of word pairs as the benchmark data. Both of </context>
</contexts>
<marker>Dinu, Lapata, 2010</marker>
<rawString>G. Dinu and M. Lapata. Measuring Distributional Similarity in Context. Proceedings of EMNLP, 2010, pp. 1162-1172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Finkelstein</author>
<author>E Gabrilovich</author>
<author>Y Matias</author>
<author>E Rivlin</author>
<author>Z Solan</author>
<author>G Wolfman</author>
<author>E Ruppin</author>
</authors>
<title>Placing Search in Context: The Concept Revisited.</title>
<date>2002</date>
<journal>ACM Transactions on Information Systems,</journal>
<pages>20--1</pages>
<contexts>
<context position="1822" citStr="Finkelstein et al. (2002)" startWordPosition="295" endWordPosition="298">have focus on English language (Lin, 1998; Curran and Moens, 2003; Dinu and Lapata, 2010), some of which rely on the manual created thesaurus such as WordNet (Budanitsky and Hirst, 2006), some of which obtain the similarity of the words via large scale corpus (Lee, 1999), and some research integrate both thesaurus and corpus (Fujii et al., 1997). This task tries to evaluate the approach on word similarity for Chinese language. To the best of our knowledge, this is first release of benchmark data for this study. In English language, there are two data sets: Rubenstein and Goodenough (1965) and Finkelstein et al. (2002) created a ranking of word pairs as the benchmark data. Both of them are manually annotated. In this task, we follow the way to create the data and annotate the similarity score between word pairs by twenty Chinese native speakers. Finkelstein et al. (2002) carried out a psycholinguistic experiment: they selected out 353 word pairs, then ask the annotators assign a numerical similarity score between 0 and 10 (0 denotes that words are totally unrelated, 10 denotes that words are VERY closely related) to each pair. By definition, the similarity of the word to itself should be 10. A fractional sc</context>
<context position="3180" citStr="Finkelstein et al., 2002" startWordPosition="520" endWordPosition="523">rd similarity study (Gorman and Curran, 2006). The paper is organized as follows. In section 2 we describe in detail the process of the data preparation. Section 3 introduces the four participating systems. Section 4 reports their results and gives a brief discussion.. And finally in section 5 we bring forward some suggestions for the next campaign and conclude the paper. 374 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 374–377, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics 2 Data Preparation 2.1 Data Set We use wordsim 353 (Finkelstein et al., 2002) as the original data set. First, each word pair is translated into Chinese by two undergraduates who are fluent in English. 169 word pairs are the same in their translation results. To the rest 184 word pairs, the third undergraduate student check them following the rules: (i) Single character vs. two characters. If one translator translate one English word into the Chinese word which consists only one Chinese character and the other use two characters to convey the translation, we will prefer to the later provided that these two translations are semantically same. For example, &amp;quot;tiger&amp;quot; is tra</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2002</marker>
<rawString>L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan, G. Wolfman, and E. Ruppin. 2002. Placing Search in Context: The Concept Revisited. ACM Transactions on Information Systems, 20(1):116-131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Fujii</author>
<author>T Hasegawa</author>
<author>T Tokunaga</author>
<author>H Tanaka</author>
</authors>
<title>Integration of Hand-Crafted and Statistical Resources in Measuring Word Similarity.</title>
<date>1997</date>
<booktitle>Proceedings of Workshop of Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications.</booktitle>
<pages>45--51</pages>
<contexts>
<context position="1544" citStr="Fujii et al., 1997" startWordPosition="247" endWordPosition="250"> created while the taus&apos; value is very small. 1 Introduction The goal of word similarity is to compute the similarity degree between words. It is widely used in natural language processing to alleviate data sparseness which is an open problem in this field. Many research have focus on English language (Lin, 1998; Curran and Moens, 2003; Dinu and Lapata, 2010), some of which rely on the manual created thesaurus such as WordNet (Budanitsky and Hirst, 2006), some of which obtain the similarity of the words via large scale corpus (Lee, 1999), and some research integrate both thesaurus and corpus (Fujii et al., 1997). This task tries to evaluate the approach on word similarity for Chinese language. To the best of our knowledge, this is first release of benchmark data for this study. In English language, there are two data sets: Rubenstein and Goodenough (1965) and Finkelstein et al. (2002) created a ranking of word pairs as the benchmark data. Both of them are manually annotated. In this task, we follow the way to create the data and annotate the similarity score between word pairs by twenty Chinese native speakers. Finkelstein et al. (2002) carried out a psycholinguistic experiment: they selected out 353</context>
</contexts>
<marker>Fujii, Hasegawa, Tokunaga, Tanaka, 1997</marker>
<rawString>A. Fujii, T. Hasegawa, T. Tokunaga and H. Tanaka. Integration of Hand-Crafted and Statistical Resources in Measuring Word Similarity. 1997. Proceedings of Workshop of Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications. pp. 45-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis,</title>
<date>2007</date>
<booktitle>Proceedings of IJCAI,</booktitle>
<pages>1606--1611</pages>
<location>Hyderabad,</location>
<contexts>
<context position="8737" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="1481" endWordPosition="1484">he trial data to learn a multiple linear regression functions. The CCD was considered as a directed graph. The nodes were synsets and edges were the semantic relations between two synsets. The features for this system were derived from CCD and a corpus and listed as follows:  the shortest path between two synsets which contain the words  the rates of 5 semantic relation types  mutual information of a word pair in the corpus They used the result of multiple linear regressions to forecast the similarity of other word pairs and get the rank. GUO-ngram: This system used the method proposed by (Gabrilovich and Markovitch, 2007). They downloaded the Wikipedia on 25th November, 2011 as the knowledge source. In order to bypass the Chinese segmentation, they extract one character (uni-gram) and two sequential characters (bi-gram) as the features. GUO-words: This system is very similar to GUO-ngram except that the features consist of words rather than n-grams. They implemented a simple index method which searches all continuous character strings appearing in a dictionary. For example, given a text string ABCDEFG in which ABC, BC, and EF appear in the dictionary. The output of the tokenization algorithm is the three words</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>E. Gabrilovich and S. Markovitch, Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis, Proceedings of IJCAI, Hyderabad, 2007, pp. 1606—1611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gorman</author>
<author>J Curran</author>
</authors>
<title>Scaling Distributional Similarity to Large Corpora.</title>
<date>2006</date>
<booktitle>Proceedings of ACL,</booktitle>
<pages>361--368</pages>
<contexts>
<context position="2600" citStr="Gorman and Curran, 2006" startWordPosition="429" endWordPosition="432">te the similarity score between word pairs by twenty Chinese native speakers. Finkelstein et al. (2002) carried out a psycholinguistic experiment: they selected out 353 word pairs, then ask the annotators assign a numerical similarity score between 0 and 10 (0 denotes that words are totally unrelated, 10 denotes that words are VERY closely related) to each pair. By definition, the similarity of the word to itself should be 10. A fractional score is allowed. It should be noted that besides the rank of word pairs, the thesaurus such as Roget&apos;s thesaurus are often used for word similarity study (Gorman and Curran, 2006). The paper is organized as follows. In section 2 we describe in detail the process of the data preparation. Section 3 introduces the four participating systems. Section 4 reports their results and gives a brief discussion.. And finally in section 5 we bring forward some suggestions for the next campaign and conclude the paper. 374 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 374–377, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics 2 Data Preparation 2.1 Data Set We use wordsim 353 (Finkelstein et al., 2002) as the original dat</context>
</contexts>
<marker>Gorman, Curran, 2006</marker>
<rawString>J. Gorman and J. Curran. Scaling Distributional Similarity to Large Corpora. Proceedings of ACL, 2006, pp. 361-368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jiang</author>
<author>D Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>Proceedings of International Conference on Research in Computational Linguistics,</booktitle>
<contexts>
<context position="8047" citStr="Jiang and Conrath (1997)" startWordPosition="1361" endWordPosition="1364">ed as a tree with five levels. With the increasing of levels, word senses are more finegrained. The Chinese Concept Dictionary is a Chinese WordNet produced by Peking University. Word concepts are presented as synsets corresponding to WordNet 1.6. Besides synonym, antonym, hypernym/hyponym, holonym/meronym, there is another semantic relation type named as attribute which happens between two words with different part-of-speeches. They first divide all word pairs into five parts and rank them according to their levels in Cilin in descending order. For each part, they computed word similarity by Jiang and Conrath (1997) method2. MIXCD: Different form MIXCC, this system used the trial data to learn a multiple linear regression functions. The CCD was considered as a directed graph. The nodes were synsets and edges were the semantic relations between two synsets. The features for this system were derived from CCD and a corpus and listed as follows:  the shortest path between two synsets which contain the words  the rates of 5 semantic relation types  mutual information of a word pair in the corpus They used the result of multiple linear regressions to forecast the similarity of other word pairs and get the r</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>J. Jiang and D. Conrath. 1997. Semantic similarity based on corpus statistics and lexical taxonomy. Proceedings of International Conference on Research in Computational Linguistics, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lapata</author>
</authors>
<title>Automatic Evaluation of Information Ordering: Kendall&apos;s Tau. Computational Linguistics,</title>
<date>2006</date>
<pages>32--4</pages>
<contexts>
<context position="10373" citStr="Lapata, 2006" startWordPosition="1762" endWordPosition="1763"> required to rank these 500 word pairs according to their similarity scores. Table 4 gives the overall results obtained by each of the systems. Rank Team ID System ID Tau&apos;s value 1 lib MIXCC 0.050 2 MIXCD 0.040 3 Guo-ngram 0.007 Gfp1987 4 Guo-words -0.011 Table 4: The results of four systmes The ranks returned by these four systems will be compared with the rank from human annotation by the Kendall Rank Correlation Coefficient: Where is the number of objects. and are two distinct orderings of a object in two ranks. S(ir,6) is the minimum number of adjacent transpositions needing to bring and (Lapata, 2006). In this metric, tau&apos;s value ranges from -1 to +1 and -1 means that the two ranks are inverse to each other and +1 means the identical rank. From table 4, we can see that except the final system, three of them got the positive tau&apos;s value. It is regret that the tau&apos;s is very small even if the MIXCC system is the best one. 5 Conclusion We organize an evaluation task focuses on word similarity in Chinese language. Totally 347 word pairs are annotated similarity scores by twenty native speakers. These word pairs are ordered by the similarity scores and this rank is used as benchmark data for eva</context>
</contexts>
<marker>Lapata, 2006</marker>
<rawString>M. Lapata. Automatic Evaluation of Information Ordering: Kendall&apos;s Tau. Computational Linguistics, 2006, 32(4):471-484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Automatic Retrieval and Clustering of Similar Words.</title>
<date>1998</date>
<booktitle>Proceedings of ACL / COLING,</booktitle>
<pages>768--774</pages>
<contexts>
<context position="1238" citStr="Lin, 1998" startWordPosition="197" endWordPosition="198">res among the twenty annotators. This data is used as gold standard. Four systems participating in this task return their results. We evaluate their results on gold standard data in term of Kendall&apos;s tau value, and the results show three of them have a positive correlation with the rank manually created while the taus&apos; value is very small. 1 Introduction The goal of word similarity is to compute the similarity degree between words. It is widely used in natural language processing to alleviate data sparseness which is an open problem in this field. Many research have focus on English language (Lin, 1998; Curran and Moens, 2003; Dinu and Lapata, 2010), some of which rely on the manual created thesaurus such as WordNet (Budanitsky and Hirst, 2006), some of which obtain the similarity of the words via large scale corpus (Lee, 1999), and some research integrate both thesaurus and corpus (Fujii et al., 1997). This task tries to evaluate the approach on word similarity for Chinese language. To the best of our knowledge, this is first release of benchmark data for this study. In English language, there are two data sets: Rubenstein and Goodenough (1965) and Finkelstein et al. (2002) created a ranki</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. Automatic Retrieval and Clustering of Similar Words. Proceedings of ACL / COLING, 1998, pp. 768-774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lee</author>
</authors>
<title>Measures of Distributional Similarity.</title>
<date>1999</date>
<booktitle>Proceedings of ACL,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="1468" citStr="Lee, 1999" startWordPosition="237" endWordPosition="238">ow three of them have a positive correlation with the rank manually created while the taus&apos; value is very small. 1 Introduction The goal of word similarity is to compute the similarity degree between words. It is widely used in natural language processing to alleviate data sparseness which is an open problem in this field. Many research have focus on English language (Lin, 1998; Curran and Moens, 2003; Dinu and Lapata, 2010), some of which rely on the manual created thesaurus such as WordNet (Budanitsky and Hirst, 2006), some of which obtain the similarity of the words via large scale corpus (Lee, 1999), and some research integrate both thesaurus and corpus (Fujii et al., 1997). This task tries to evaluate the approach on word similarity for Chinese language. To the best of our knowledge, this is first release of benchmark data for this study. In English language, there are two data sets: Rubenstein and Goodenough (1965) and Finkelstein et al. (2002) created a ranking of word pairs as the benchmark data. Both of them are manually annotated. In this task, we follow the way to create the data and annotate the similarity score between word pairs by twenty Chinese native speakers. Finkelstein et</context>
</contexts>
<marker>Lee, 1999</marker>
<rawString>L. Lee. Measures of Distributional Similarity. Proceedings of ACL, 1999, pp. 25-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Rubenstein</author>
<author>J B Goodenough</author>
</authors>
<title>Contextual correlates of synonymy.</title>
<date>1965</date>
<journal>Communications of the ACM,</journal>
<pages>8--10</pages>
<contexts>
<context position="1792" citStr="Rubenstein and Goodenough (1965)" startWordPosition="289" endWordPosition="293">problem in this field. Many research have focus on English language (Lin, 1998; Curran and Moens, 2003; Dinu and Lapata, 2010), some of which rely on the manual created thesaurus such as WordNet (Budanitsky and Hirst, 2006), some of which obtain the similarity of the words via large scale corpus (Lee, 1999), and some research integrate both thesaurus and corpus (Fujii et al., 1997). This task tries to evaluate the approach on word similarity for Chinese language. To the best of our knowledge, this is first release of benchmark data for this study. In English language, there are two data sets: Rubenstein and Goodenough (1965) and Finkelstein et al. (2002) created a ranking of word pairs as the benchmark data. Both of them are manually annotated. In this task, we follow the way to create the data and annotate the similarity score between word pairs by twenty Chinese native speakers. Finkelstein et al. (2002) carried out a psycholinguistic experiment: they selected out 353 word pairs, then ask the annotators assign a numerical similarity score between 0 and 10 (0 denotes that words are totally unrelated, 10 denotes that words are VERY closely related) to each pair. By definition, the similarity of the word to itself</context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>H. Rubenstein and J.B. Goodenough. 1965. Contextual correlates of synonymy. Communications of the ACM, 8(10):627-633.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>