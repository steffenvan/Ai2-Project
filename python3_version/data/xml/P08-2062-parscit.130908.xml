<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000074">
<title confidence="0.963866">
Efficient Processing of Underspecified Discourse Representations
</title>
<author confidence="0.923384">
Michaela Regneri† * Markus Egg† Alexander Koller§
</author>
<email confidence="0.824851">
regneri@coli.uni-sb.de egg@let.rug.nl a.koller@ed.ac.uk
</email>
<note confidence="0.776184">
* Saarland University † University of Groningen § University of Edinburgh
</note>
<sectionHeader confidence="0.987903" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998281">
Underspecification-based algorithms for pro-
cessing partially disambiguated discourse
structure must cope with extremely high num-
bers of readings. Based on previous work on
dominance graphs and weighted tree gram-
mars, we provide the first possibility for com-
puting an underspecified discourse description
and a best discourse representation efficiently
enough to process even the longest discourses
in the RST Discourse Treebank.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999958405405405">
Discourse processing has emerged as a highly rele-
vant source of information for applications such as
information extraction and automatic summarisation
(Taboada and Mann (2006) outline this and further
applications). But discourse structures cannot al-
ways be described completely, either due to genuine
ambiguity (Stede, 2004) or to the limitations of a
discourse parser. In either case, only partial infor-
mation on discourse structure is available. To han-
dle such information, underspecification formalisms
can be used. Underspecification was originally in-
troduced in computational semantics to model struc-
tural ambiguity without disjunctively enumerating
the readings, and later applied to discourse parsing
(Gardent and Webber, 1998; Schilder, 2002).
However, while the existing algorithms for un-
derspecification processing work well for seman-
tic structures, they were not designed for discourse
structures, which can be much larger. Indeed, it
has never been shown that underspecified discourse
reprentations (UDRs) can be processed efficiently,
since the general-purpose implementations are too
slow for that task.
In this paper, we present a new way to imple-
ment and process discourse underspecification in
terms of regular tree grammars (RTGs). RTGs are
used as an underspecification formalism in seman-
tics (Koller et al., 2008). We show how to compute
RTGs for discourse from dominance-based under-
specified representations more efficiently (by a typ-
ical factor of 100) than before. Furthermore, we
show how weighted RTGs can be used to represent
constraints and preferences on the discourse struc-
ture. Taking all these results together, we show for
the first time how the globally optimal discourse rep-
resentation based on some preference model can be
computed efficiently from an UDR.
</bodyText>
<sectionHeader confidence="0.991846" genericHeader="method">
2 Underspecified Discourse Representation
</sectionHeader>
<bodyText confidence="0.9989818">
Following annotation schemes like the one of Stede
(2004), we model discourse structures by binary
trees. Fig. (1b-f) represent the potential structures of
(1). We write each elementary discourse unit (EDU)
in square brackets.
</bodyText>
<equation confidence="0.458707">
(1) [C1 I try to read a novel] [C2 if I feel bored]
[C3 because the TV programs disappoint me]
[C4 but I can’t concentrate on anything.]
</equation>
<bodyText confidence="0.999649611111111">
Underspecification formalisms such as domi-
nance graphs (Althaus et al., 2003) can model par-
tial information about such trees; see Fig. (1a) for
the underspecified discourse representation (UDR)
of (1). These graphs consist of labelled roots and
unlabelled holes; the solid edges indicate that a
node must be the parent of another, and the dashed
edges indicate (transitive) dominance requirements.
A configuration of a dominance graph is an arrange-
ment of the (labelled) graph nodes into a tree that
satisfies all (immediate and transitive) dominance
requirements. Subgraphs that are connected by solid
edges are called fragments and must be tree-shaped.
Using UDRs, discourse parsing can be modu-
larised into three separate steps. First, a discourse
parser segments the text and generates an UDR from
it. The node labels in the UDR aren’t necessarily
fully specified (Egg and Redeker, 2007; Schilder,
</bodyText>
<page confidence="0.986504">
245
</page>
<reference confidence="0.3379115">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 245–248,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</reference>
<equation confidence="0.996081">
(a) (�) (c) (�) (�)
Condition(1) Cause(2) Contrast Contrast Contrast
Condition(1) (�) Condition(1)
2 4
6
Condition(1)
Cause(2)
Cause(2)
C4 Condition(1) Contrast
C4 C1
C3
Condition(1) Contrast
C1
Cause(2)
Cause(2)
C4
C1
C2
Cause(2)
Contrast
7
C1 1 C2 3 C3 5 C4
C1
C2
C2 C3
C1 C2 C3 C4
C2 C3
C3 C4
</equation>
<figureCaption confidence="0.530304">
Figure
</figureCaption>
<figure confidence="0.687206333333333">
An underspecified discourse structure an
1:
d its five configurations
→Contr({3;5},{7}) [1]
{1;7} → Contr({1;5},{7}) [1]
{1;7} → Cause({1;3},{5;7}) [1]
{1;5} → Cause({1;3},{5}) [1]
{1} → C1 [1] {3} → C2 [1]
→Cond({1},{3}) [5]
{1;5} → Cond({1},{3;5}) [3]
{3;7} → Cause({3},{5;7}) [1]
{5} → C3 [1] {7} → C4 [1]
</figure>
<figureCaption confidence="0.997615">
Figure 2: A wRTG modelling Fig. 1
</figureCaption>
<bodyText confidence="0.979911947368421">
holes. There must also be a numbering
+ 1
of the fragments such that for every 1
i
n, frag-
ment 2i is an upper fragment, fragments 2i
1 and
are lower fragments, and there are dominance
edges from the left hole of 2i to the root of
and
from the right hole of 2i to the root of 2i + 1 (and
possibly further dominance edges). These numbers
are shown in circles in Fig.
In discourse dom-
inance graphs, upper fragments correspond to dis-
course relations, and lower fragments correspond to
EDUs; the EDUs are ordered according to their ap-
pearance in the text, and the upper fragments con-
nect the two text span
</bodyText>
<figure confidence="0.44265425">
1,...,2n
≤
≤
−
2i + 1
2i−1
(1a).
s to which they are adjacent.
</figure>
<page confidence="0.514196">
an
{1;7},
</page>
<bodyText confidence="0.999425388888889">
d it describes exactly the five trees in
2002); here we pretend that they are to simplify the
presentation, as nothing in this paper hinges on it.
Then weights are added to the UDR that incorporate
preferences for discourse structures based on lin-
guistic cues. Finally, the weighted UDR can either
be processed directly by other applications, or, if a
tree structure is required, we can compute the best
configuration. In this paper, we show how an UDR
dominance graph can be converted into a regular tree
grammar efficiently. This simplifies the specifica-
tion of weights in Step 2; we also show how to ef-
ficiently compute a best tree from a weighted RTG
(Step 3). We do not discuss Step 1 in this paper.
The dominance graphs used in discourse under-
specification are constrained chains. A constrained
chain of length n consists of n upper fragments with
two holes each and n + 1 lower fragments with no
</bodyText>
<sectionHeader confidence="0.937591" genericHeader="method">
3 Underspecified Processing for Discourses
</sectionHeader>
<bodyText confidence="0.997436636363636">
Recently, Koller et al. (2008) showed how to pro-
cess dominance graphs with regular tree grammars
(Comon et al., 2007, RTGs). RTGs are a grammar
formalism that describes sets of trees using produc-
tion rules which rewrite non-terminal symbols (NTs)
into terms consisting of tree constructors and possi-
bly further NTs. A tree (without NTs) is accepted
by the grammar if it can be derived by a sequence
of rule applications from a given start symbol. An
example RTG is shown in Fig. 2; its start symbol
is
</bodyText>
<figure confidence="0.997553833333333">
{1;7} → Cond({1},{3;7})[1]
{3;7}
{5;7} → Contr({5},{7}) [1]
{3;5}
→Cause({3},{5}) [1]
{1;3}
</figure>
<figureCaption confidence="0.591759">
Fig.
For example, Fig.
</figureCaption>
<bodyText confidence="0.953763333333333">
is derived by ex-
panding the start symbol with the first rule in Fig. 2.
This determines that the tree root is labelled with
Condition; we then derive the left subtree from the
NT
and the right subtree from the NT
The NTs in the grammar correspond to subgraphs
in the dominance graph: The NT
repre-
sents the subgraph
(i.e. the whole
graph); the NT
the subgraph contain-
ing only the fragment 1; and so forth. The trees that
can be derived from each nonterminal correspond
exactly to the configurations of the subgraph.
Koller and Thater (2005b) presented an algorithm
for generating, from a very general class of dom-
inance graphs, an RTG that describes exactly the
same trees. For each subgraph S that is to be the
LHS of a rule, the algorithm determines the free
fragments of S, i.e. the fragments that may serve
as the root of one of its configurations, by a certain
graph algorithm. For every free fragment in S with
n holes and a root label f, the algorithm generates a
new rule of the form S
f
where each
Si corresponds to the remaining subgraph under the
i-th hole. The procedure calls itself recursively on
the subgraphs until it reaches singleton subgraphs.
While this algorithm works well with underspec-
ified semantic representations in semantics, it is too
slow for the larger discourse graphs, as we will see in
Section 5. However, we will now optimise it for the
special case of constrained chains. First, we observe
that all subgraphs ever visited by the algorithm are
connected subchains. A subchain is uniquely identi-
fiable by the positions of the first and last fragment
in the left-to-right order of the chain; we can thus
read the nonterminal {i; j} simply as a pair of inte-
gers that identifies the subchain fr
</bodyText>
<figure confidence="0.973297444444444">
(1b-f).
(1e)
{1}
{3;7}.
{1;7}
{1,2,3,4,5,6,7}
{1} represents
→
(S1,...,Sn),
</figure>
<footnote confidence="0.613479">
om the i-th to the
</footnote>
<page confidence="0.953891">
246
</page>
<figure confidence="0.855010727272727">
Algorithm 1: GenerateRules({i; j},G,C)
1 if G contains rules for {i; j} then return
2 if i=j then G.add({ {i; j} → Label(i) } ) else
/* Loop over upper fragments */
3 for k = i+1 to j-1 step 2 do
4 if-]edge=(s,t)ECs.t.(i&lt;s&lt;k&lt;t&lt;j)V(i&lt;t
&lt; k &lt; s &lt; j) then
5 lSub +-- {i;k-1}, rSub +-- {k+1; j}
6 G.add({i; j} → Label(i)(lSub, rSub))
7 GenerateRules(lSub, G, C)
8 GenerateRules(rSub, G, C)
</figure>
<bodyText confidence="0.99548852173913">
j-th fragment (rather than an abbreviation for a set
of fragments). i and j will generally represent lower
fragments. In the grammar in Fig. 2, {i} is an abbre-
viation of {i;i}.
We can now rephrase the Koller &amp; Thater algo-
rithm in our terms (Algorithm 1). The most impor-
tant change is that we can now test whether an up-
per fragment k in a subgraph {i; j} is free simply by
checking whether there is no dominance edge from
some upper fragment l to some upper fragment r
such that i &lt; l &lt; k &lt; r &lt; j, and no dominance edge
from r to l such that i &lt; l &lt; k &lt; r &lt; j. For instance,
if there was a dominance edge from the right hole of
2 to the root of 6 in Fig. (1a), then 4 and 6 would
not be free, but 2 would be; and indeed, all config-
urations of this graph would have to have 2 as their
roots. Hence we can replace the graph algorithm for
freeness by a simple comparison of integers. The
general structure of the algorithm remains the same
as in (Koller and Thater, 2005b): It takes a domi-
nance graph C as its input, and recursively calls itself
on pairs {i; j} representing subgraphs while adding
rules and NTs to an RTG G.
</bodyText>
<sectionHeader confidence="0.970593" genericHeader="method">
4 Soft Discourse Constraints
</sectionHeader>
<bodyText confidence="0.999525">
RTGs can be extended to weighted regular tree
grammars (Knight and Graehl, 2005, wRTGs) by
adding numeric weights to the rules. WRTG deriva-
tions assign weights to each tree: The weight of a
tree is the product of the weights of all rules that
were used in its derivation.
Egg and Regneri (2008) motivate the use of
wRTGs in discourse processing. They assign rule
weights based on corpus-extracted constraints which
express the interdependencies between discourse re-
lations and their surrounding tree structure. One
such constraint states that the right subtree of a Con-
</bodyText>
<figure confidence="0.813012">
0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230
</figure>
<figureCaption confidence="0.999684">
Figure 3: Runtime Comparison
</figureCaption>
<bodyText confidence="0.999490111111111">
dition node should be of minimal size, which ranks
the readings of Fig. 1 (a): (b), (d) &gt; (c) &gt; (e), (f).
In order to state this constraint in a wRTG, we
annotate the grammar in Fig. 2 with the weights
shown in brackets. The Condition rules get higher
weights if the second NT on the RHS represents a
smaller subgraph. The grammar assigns the maxi-
mum weight of 5 to (b) and (d) (fragment 2 has a
leaf as right child), the medium weight 3 to (c) (the
right subgraph of fragment 2 contains two EDUs),
and the minimum weight 1 to (e) and (f). i.e. it ranks
the readings as intended.
Based on our implementation of nonterminals as
integer pairs, we can efficiently compute a con-
figuration with maximal weight using a version of
Knight and Graehl’s (2005) algorithm for comput-
ing the best derivation of a wRTG that is specialised
to the grammars we use.
</bodyText>
<sectionHeader confidence="0.997275" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.9999358125">
We compare our runtimes with those of Utool
(Koller and Thater, 2005a), the fasted known solver
for general dominance graphs; it implements the
Koller &amp; Thater algorithm. Utool runs very fast for
underspecified representations in semantics, but the
representations for discourse parsing are consider-
ably larger: The largest underspecified semantic rep-
resentation found in the Rondane treebank analysed
with the English Resource Grammar (Copestake and
Flickinger, 2000, ERG) has 4.5 x 1012 structural
scope readings, but for 59% of the discourses in the
RST Discourse Treebank (Carlson et al., 2002, RST-
DT), there are more ways of configuring all EDUs
into a binary tree than that.
We evaluate the efficiency of our algorithm on 364
texts from the RST-DT, by converting each discourse
</bodyText>
<figure confidence="0.988807166666667">
60000.00
3833.66
244.95
new total utool total
15.65
1.00
</figure>
<page confidence="0.988597">
247
</page>
<bodyText confidence="0.999987708333333">
into a chain with one lower fragment for each EDU
and one upper fragment labelled with each anno-
tated discourse relation. We use our algorithm and
Utool to generate the RTG from the chain, assign
all soft constraints of Egg and Regneri (2008) to the
grammar, and finally compute the best configuration
according to this model. The evaluation results are
shown in Fig. 3. The horizontal axis shows the chain
length (= number of EDUs minus 1), rounded down
to multiples of ten; the (logarithmic) vertical axis
shows the average runtime in milliseconds for dis-
courses of that length. Both algorithms spend a bit
over half the runtime on computing the RTGs.
As the diagram shows, our algorithm is up to 100
times faster than Utool for the same discourses. It
is capable of computing the best configuration for
every tested discourse – in less than one second for
86% of the texts. Utool exceeded the OS memory
limit on 77 discourses, and generally couldn’t pro-
cess any text with more than 100 EDUs. The longest
text in the RST-DT has 304 EDUs, so the UDR has
about 2.8×10178 different configurations. Our algo-
rithm computes the best configuration for this UDR
in about three minutes.
</bodyText>
<sectionHeader confidence="0.999431" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999996392857143">
We presented the first solver for underspecified dis-
course representations that is efficient enough to
compute the globally best configurations of every
discourse in the RST discourse treebank, by exploit-
ing the fact that UDRs are very large but obey very
strong structural restrictions. Our solver converts
a dominance graph into an RTG, adds weights to
the RTG to represent discourse constraints, and then
computes the globally optimal configuration.
It takes about three minutes to compute a best
configuration with a given probability model for the
longest discourse in the treebank, out of 10178 pos-
sible configurations. For comparison, an algorithm
that enumerates a billion configurations per second
to find the best one could have inspected only about
1026 within the estimated age of the universe. So our
algorithm is useful and necessary to process real-
world underspecified discourse representations.
We have thus demonstrated that discourse pro-
cessing based on underspecification is computation-
ally feasible. Nothing in our algorithm hinges on
using RST in particular; it is compatible with any
approach that uses binary trees. In future research,
it would be interesting to complete our system into
a full-blown discourse parser by adding a module
that computes an UDR for a given text, and evaluate
whether its ability to delay decisions about discourse
structure would improve accuracy.
</bodyText>
<sectionHeader confidence="0.998479" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999889022727273">
E. Althaus, D. Duchier, A. Koller, K. Mehlhorn,
J. Niehren, and S. Thiel. 2003. An efficient graph
algorithm for dominance constraints. Journal of Algo-
rithms, 48:194–219.
L. Carlson, D. Marcu, and M. E. Okurowski. 2002. RST
Discourse Treebank. LDC.
H. Comon, M. Dauchet, R. Gilleron, C. L¨oding,
F. Jacquemard, D. Lugiez, S. Tison, and M. Tom-
masi. 2007. Tree Automata Techniques and Ap-
plications. Available on: http://www.grappa.
univ-lille3.fr/tata. Release 12-10-2007.
A. Copestake and D. Flickinger. 2000. An open-
source grammar development environment and broad-
coverage English grammar using HPSG. In Confer-
ence on Language Resources and Evaluation.
M. Egg and G. Redeker. 2007. Underspecified discourse
representation. In A. Benz and P. K¨uhnlein, editors,
Constraints in Discourse, Amsterdam. Benjamins.
M. Egg and M. Regneri. 2008. Underspecified Mod-
elling of Complex Discourse Constraints. Submitted.
C. Gardent and B. Webber. 1998. Describing Discourse
Semantics. In Proceedings of the 4th TAG+ Workshop,
University of Pennsylvania, Philadelphia.
K. Knight and J. Graehl. 2005. An overview of proba-
bilistic tree transducers for natural language process-
ing. In Computational linguistics and intelligent text
processing, pages 1–24. Springer.
A. Koller and S. Thater. 2005a. Efficient solving and
exploration of scope ambiguities. Proceedings of the
ACL-05 Demo Session.
A. Koller and S. Thater. 2005b. The evolution of dom-
inance constraint solvers. In Proceedings of the ACL-
05 Workshop on Software, Ann Arbor.
A. Koller, M. Regneri, and S. Thater. 2008. Regular tree
grammars as a formalism for scope underspecification.
In Proceedings of ACL-08: HLT.
F. Schilder. 2002. Robust discourse parsing via discourse
markers, topicality and position. Natural Language
Engineering, 8:235–255.
M. Stede. 2004. The Potsdam Commentary Corpus. In
B. Webber and D. Byron, editors, ACL-04 Workshop
on Discourse Annotation.
M. Taboada and W. Mann. 2006. Applications of Rhetor-
ical Structure Theory. Discourse Studies, 8:567–588.
</reference>
<page confidence="0.997006">
248
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.737370">
<title confidence="0.989849">Efficient Processing of Underspecified Discourse Representations</title>
<author confidence="0.796964">regnericoli uni-sb de_egglet rug nl a kollered ac uk</author>
<affiliation confidence="0.995384">University of Groningen of Edinburgh</affiliation>
<abstract confidence="0.992847818181818">Underspecification-based algorithms for processing partially disambiguated discourse structure must cope with extremely high numbers of readings. Based on previous work on dominance graphs and weighted tree grammars, we provide the first possibility for computing an underspecified discourse description and a best discourse representation efficiently enough to process even the longest discourses in the RST Discourse Treebank.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Proceedings of ACL-08: HLT, Short Papers (Companion Volume),</booktitle>
<pages>245--248</pages>
<marker></marker>
<rawString>Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 245–248,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Columbus</author>
</authors>
<date>2008</date>
<booktitle>c�2008 Association for Computational Linguistics</booktitle>
<location>Ohio, USA,</location>
<marker>Columbus, 2008</marker>
<rawString>Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Althaus</author>
<author>D Duchier</author>
<author>A Koller</author>
<author>K Mehlhorn</author>
<author>J Niehren</author>
<author>S Thiel</author>
</authors>
<title>An efficient graph algorithm for dominance constraints.</title>
<date>2003</date>
<journal>Journal of Algorithms,</journal>
<pages>48--194</pages>
<contexts>
<context position="2975" citStr="Althaus et al., 2003" startWordPosition="429" endWordPosition="432"> the first time how the globally optimal discourse representation based on some preference model can be computed efficiently from an UDR. 2 Underspecified Discourse Representation Following annotation schemes like the one of Stede (2004), we model discourse structures by binary trees. Fig. (1b-f) represent the potential structures of (1). We write each elementary discourse unit (EDU) in square brackets. (1) [C1 I try to read a novel] [C2 if I feel bored] [C3 because the TV programs disappoint me] [C4 but I can’t concentrate on anything.] Underspecification formalisms such as dominance graphs (Althaus et al., 2003) can model partial information about such trees; see Fig. (1a) for the underspecified discourse representation (UDR) of (1). These graphs consist of labelled roots and unlabelled holes; the solid edges indicate that a node must be the parent of another, and the dashed edges indicate (transitive) dominance requirements. A configuration of a dominance graph is an arrangement of the (labelled) graph nodes into a tree that satisfies all (immediate and transitive) dominance requirements. Subgraphs that are connected by solid edges are called fragments and must be tree-shaped. Using UDRs, discourse </context>
</contexts>
<marker>Althaus, Duchier, Koller, Mehlhorn, Niehren, Thiel, 2003</marker>
<rawString>E. Althaus, D. Duchier, A. Koller, K. Mehlhorn, J. Niehren, and S. Thiel. 2003. An efficient graph algorithm for dominance constraints. Journal of Algorithms, 48:194–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Carlson</author>
<author>D Marcu</author>
<author>M E Okurowski</author>
</authors>
<date>2002</date>
<booktitle>RST Discourse Treebank. LDC.</booktitle>
<marker>Carlson, Marcu, Okurowski, 2002</marker>
<rawString>L. Carlson, D. Marcu, and M. E. Okurowski. 2002. RST Discourse Treebank. LDC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Comon</author>
<author>M Dauchet</author>
<author>R Gilleron</author>
<author>C L¨oding</author>
<author>F Jacquemard</author>
<author>D Lugiez</author>
<author>S Tison</author>
<author>M Tommasi</author>
</authors>
<date>2007</date>
<booktitle>Tree Automata Techniques and Applications. Available on: http://www.grappa. univ-lille3.fr/tata. Release</booktitle>
<pages>12--10</pages>
<marker>Comon, Dauchet, Gilleron, L¨oding, Jacquemard, Lugiez, Tison, Tommasi, 2007</marker>
<rawString>H. Comon, M. Dauchet, R. Gilleron, C. L¨oding, F. Jacquemard, D. Lugiez, S. Tison, and M. Tommasi. 2007. Tree Automata Techniques and Applications. Available on: http://www.grappa. univ-lille3.fr/tata. Release 12-10-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>D Flickinger</author>
</authors>
<title>An opensource grammar development environment and broadcoverage English grammar using HPSG.</title>
<date>2000</date>
<booktitle>In Conference on Language Resources and Evaluation.</booktitle>
<marker>Copestake, Flickinger, 2000</marker>
<rawString>A. Copestake and D. Flickinger. 2000. An opensource grammar development environment and broadcoverage English grammar using HPSG. In Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Egg</author>
<author>G Redeker</author>
</authors>
<title>Underspecified discourse representation.</title>
<date>2007</date>
<journal>Benjamins. M. Egg</journal>
<booktitle>Constraints in Discourse,</booktitle>
<editor>In A. Benz and P. K¨uhnlein, editors,</editor>
<publisher>Submitted.</publisher>
<location>Amsterdam.</location>
<marker>Egg, Redeker, 2007</marker>
<rawString>M. Egg and G. Redeker. 2007. Underspecified discourse representation. In A. Benz and P. K¨uhnlein, editors, Constraints in Discourse, Amsterdam. Benjamins. M. Egg and M. Regneri. 2008. Underspecified Modelling of Complex Discourse Constraints. Submitted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gardent</author>
<author>B Webber</author>
</authors>
<title>Describing Discourse Semantics.</title>
<date>1998</date>
<booktitle>In Proceedings of the 4th TAG+ Workshop,</booktitle>
<location>University of Pennsylvania, Philadelphia.</location>
<contexts>
<context position="1433" citStr="Gardent and Webber, 1998" startWordPosition="190" endWordPosition="193">n extraction and automatic summarisation (Taboada and Mann (2006) outline this and further applications). But discourse structures cannot always be described completely, either due to genuine ambiguity (Stede, 2004) or to the limitations of a discourse parser. In either case, only partial information on discourse structure is available. To handle such information, underspecification formalisms can be used. Underspecification was originally introduced in computational semantics to model structural ambiguity without disjunctively enumerating the readings, and later applied to discourse parsing (Gardent and Webber, 1998; Schilder, 2002). However, while the existing algorithms for underspecification processing work well for semantic structures, they were not designed for discourse structures, which can be much larger. Indeed, it has never been shown that underspecified discourse reprentations (UDRs) can be processed efficiently, since the general-purpose implementations are too slow for that task. In this paper, we present a new way to implement and process discourse underspecification in terms of regular tree grammars (RTGs). RTGs are used as an underspecification formalism in semantics (Koller et al., 2008)</context>
</contexts>
<marker>Gardent, Webber, 1998</marker>
<rawString>C. Gardent and B. Webber. 1998. Describing Discourse Semantics. In Proceedings of the 4th TAG+ Workshop, University of Pennsylvania, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<title>An overview of probabilistic tree transducers for natural language processing.</title>
<date>2005</date>
<booktitle>In Computational linguistics and intelligent text processing,</booktitle>
<pages>1--24</pages>
<publisher>Springer.</publisher>
<marker>Knight, Graehl, 2005</marker>
<rawString>K. Knight and J. Graehl. 2005. An overview of probabilistic tree transducers for natural language processing. In Computational linguistics and intelligent text processing, pages 1–24. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Koller</author>
<author>S Thater</author>
</authors>
<title>Efficient solving and exploration of scope ambiguities.</title>
<date>2005</date>
<booktitle>Proceedings of the ACL-05 Demo Session.</booktitle>
<marker>Koller, Thater, 2005</marker>
<rawString>A. Koller and S. Thater. 2005a. Efficient solving and exploration of scope ambiguities. Proceedings of the ACL-05 Demo Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Koller</author>
<author>S Thater</author>
</authors>
<title>The evolution of dominance constraint solvers.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL05 Workshop on Software,</booktitle>
<location>Ann Arbor.</location>
<marker>Koller, Thater, 2005</marker>
<rawString>A. Koller and S. Thater. 2005b. The evolution of dominance constraint solvers. In Proceedings of the ACL05 Workshop on Software, Ann Arbor.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Koller</author>
<author>M Regneri</author>
<author>S Thater</author>
</authors>
<title>Regular tree grammars as a formalism for scope underspecification.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT.</booktitle>
<contexts>
<context position="2033" citStr="Koller et al., 2008" startWordPosition="280" endWordPosition="283">ent and Webber, 1998; Schilder, 2002). However, while the existing algorithms for underspecification processing work well for semantic structures, they were not designed for discourse structures, which can be much larger. Indeed, it has never been shown that underspecified discourse reprentations (UDRs) can be processed efficiently, since the general-purpose implementations are too slow for that task. In this paper, we present a new way to implement and process discourse underspecification in terms of regular tree grammars (RTGs). RTGs are used as an underspecification formalism in semantics (Koller et al., 2008). We show how to compute RTGs for discourse from dominance-based underspecified representations more efficiently (by a typical factor of 100) than before. Furthermore, we show how weighted RTGs can be used to represent constraints and preferences on the discourse structure. Taking all these results together, we show for the first time how the globally optimal discourse representation based on some preference model can be computed efficiently from an UDR. 2 Underspecified Discourse Representation Following annotation schemes like the one of Stede (2004), we model discourse structures by binary </context>
</contexts>
<marker>Koller, Regneri, Thater, 2008</marker>
<rawString>A. Koller, M. Regneri, and S. Thater. 2008. Regular tree grammars as a formalism for scope underspecification. In Proceedings of ACL-08: HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Schilder</author>
</authors>
<title>Robust discourse parsing via discourse markers, topicality and position.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<pages>8--235</pages>
<contexts>
<context position="1450" citStr="Schilder, 2002" startWordPosition="194" endWordPosition="195"> summarisation (Taboada and Mann (2006) outline this and further applications). But discourse structures cannot always be described completely, either due to genuine ambiguity (Stede, 2004) or to the limitations of a discourse parser. In either case, only partial information on discourse structure is available. To handle such information, underspecification formalisms can be used. Underspecification was originally introduced in computational semantics to model structural ambiguity without disjunctively enumerating the readings, and later applied to discourse parsing (Gardent and Webber, 1998; Schilder, 2002). However, while the existing algorithms for underspecification processing work well for semantic structures, they were not designed for discourse structures, which can be much larger. Indeed, it has never been shown that underspecified discourse reprentations (UDRs) can be processed efficiently, since the general-purpose implementations are too slow for that task. In this paper, we present a new way to implement and process discourse underspecification in terms of regular tree grammars (RTGs). RTGs are used as an underspecification formalism in semantics (Koller et al., 2008). We show how to </context>
</contexts>
<marker>Schilder, 2002</marker>
<rawString>F. Schilder. 2002. Robust discourse parsing via discourse markers, topicality and position. Natural Language Engineering, 8:235–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stede</author>
</authors>
<title>The Potsdam Commentary Corpus.</title>
<date>2004</date>
<booktitle>ACL-04 Workshop on Discourse Annotation.</booktitle>
<editor>In B. Webber and D. Byron, editors,</editor>
<contexts>
<context position="1024" citStr="Stede, 2004" startWordPosition="134" endWordPosition="135">vious work on dominance graphs and weighted tree grammars, we provide the first possibility for computing an underspecified discourse description and a best discourse representation efficiently enough to process even the longest discourses in the RST Discourse Treebank. 1 Introduction Discourse processing has emerged as a highly relevant source of information for applications such as information extraction and automatic summarisation (Taboada and Mann (2006) outline this and further applications). But discourse structures cannot always be described completely, either due to genuine ambiguity (Stede, 2004) or to the limitations of a discourse parser. In either case, only partial information on discourse structure is available. To handle such information, underspecification formalisms can be used. Underspecification was originally introduced in computational semantics to model structural ambiguity without disjunctively enumerating the readings, and later applied to discourse parsing (Gardent and Webber, 1998; Schilder, 2002). However, while the existing algorithms for underspecification processing work well for semantic structures, they were not designed for discourse structures, which can be mu</context>
<context position="2591" citStr="Stede (2004)" startWordPosition="368" endWordPosition="369">ification formalism in semantics (Koller et al., 2008). We show how to compute RTGs for discourse from dominance-based underspecified representations more efficiently (by a typical factor of 100) than before. Furthermore, we show how weighted RTGs can be used to represent constraints and preferences on the discourse structure. Taking all these results together, we show for the first time how the globally optimal discourse representation based on some preference model can be computed efficiently from an UDR. 2 Underspecified Discourse Representation Following annotation schemes like the one of Stede (2004), we model discourse structures by binary trees. Fig. (1b-f) represent the potential structures of (1). We write each elementary discourse unit (EDU) in square brackets. (1) [C1 I try to read a novel] [C2 if I feel bored] [C3 because the TV programs disappoint me] [C4 but I can’t concentrate on anything.] Underspecification formalisms such as dominance graphs (Althaus et al., 2003) can model partial information about such trees; see Fig. (1a) for the underspecified discourse representation (UDR) of (1). These graphs consist of labelled roots and unlabelled holes; the solid edges indicate that </context>
</contexts>
<marker>Stede, 2004</marker>
<rawString>M. Stede. 2004. The Potsdam Commentary Corpus. In B. Webber and D. Byron, editors, ACL-04 Workshop on Discourse Annotation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Taboada</author>
<author>W Mann</author>
</authors>
<date>2006</date>
<booktitle>Applications of Rhetorical Structure Theory. Discourse Studies,</booktitle>
<pages>8--567</pages>
<contexts>
<context position="874" citStr="Taboada and Mann (2006)" startWordPosition="111" endWordPosition="114">ct Underspecification-based algorithms for processing partially disambiguated discourse structure must cope with extremely high numbers of readings. Based on previous work on dominance graphs and weighted tree grammars, we provide the first possibility for computing an underspecified discourse description and a best discourse representation efficiently enough to process even the longest discourses in the RST Discourse Treebank. 1 Introduction Discourse processing has emerged as a highly relevant source of information for applications such as information extraction and automatic summarisation (Taboada and Mann (2006) outline this and further applications). But discourse structures cannot always be described completely, either due to genuine ambiguity (Stede, 2004) or to the limitations of a discourse parser. In either case, only partial information on discourse structure is available. To handle such information, underspecification formalisms can be used. Underspecification was originally introduced in computational semantics to model structural ambiguity without disjunctively enumerating the readings, and later applied to discourse parsing (Gardent and Webber, 1998; Schilder, 2002). However, while the exi</context>
</contexts>
<marker>Taboada, Mann, 2006</marker>
<rawString>M. Taboada and W. Mann. 2006. Applications of Rhetorical Structure Theory. Discourse Studies, 8:567–588.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>