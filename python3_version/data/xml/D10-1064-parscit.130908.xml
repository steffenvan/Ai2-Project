<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.957204">
Example-based Paraphrasing for Improved Phrase-Based
Statistical Machine Translation
</title>
<author confidence="0.881555">
Aur´elien Max
</author>
<affiliation confidence="0.7010575">
LIMSI-CNRS &amp; Univ. Paris Sud
Orsay, France
</affiliation>
<email confidence="0.993021">
aurelien.max@limsi.fr
</email>
<sectionHeader confidence="0.998566" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998711727272727">
In this article, an original view on how to
improve phrase translation estimates is pro-
posed. This proposal is grounded on two main
ideas: first, that appropriate examples of a
given phrase should participate more in build-
ing its translation distribution; second, that
paraphrases can be used to better estimate this
distribution. Initial experiments provide ev-
idence of the potential of our approach and
its implementation for effectively improving
translation performance.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992380872727273">
Phrase translation estimation in Statistical Phrase-
based Translation (Koehn et al., 2003) is hampered
by the availability of both too many and too few
training instances. Recent results on tera-scale SMT
(Lopez, 2008) show that access to many training
examples1 can lead to significant improvements in
translation quality. Also, providing indirect train-
ing instances via synonyms or paraphrases for pre-
viously unseen phrases can result in gains in trans-
lation quality, which are more apparent when little
training data is originally available (Callison-Burch
et al., 2006; Marton et al., 2009; Mirkin et al., 2009;
Aziz et al., 2010). Although there is a consensus on
the importance of using more parallel data in SMT,
it has never been formally shown that all additional
training instances are actually useful in predicting
contextually appropriate translation hypotheses.
1To be more accurate, works such as that of (Lopez, 2008)
have recourse to random sampling to build models of a manage-
able size in a reasonable amount of time.
Attempts at limiting training parallel sentences to
those resembling test data through thematic adapta-
tion (Hildebrand et al., 2005) indeed confirm that
large quantities of training data cannot compen-
sate for the requirement for contextually appropriate
training instances. In fact, it is important that phrase
translation models adequatly reflect contextual pref-
erences for each phrase occurrence in a text. A vari-
ety of recent works have used dynamically adapted
translation models, where each phrase occurrence
has its own translation distribution (Carpuat and Wu,
2007; Stroppa et al., 2007; Max et al., 2008; Gim-
pel and Smith, 2008; Haque et al., 2009) derived
from local contextual information in the training ex-
amples.2 These approaches are supported by the
study of (Wisniewski et al., 2010) which shows that
phrase-based SMT systems are expressive enough to
achieve very high translation performance and there-
fore suggests a better scoring of phrases.
The apparent tradeoff between the number of
training examples and their appropriateness in each
indivual context naturally asks for means of increas-
ing the number of appropriate examples. Exploiting
comparable corpora for acquiring translation equiva-
lents (Munteanu and Marcu, 2005; Abdul-Rauf and
Schwenk, 2009) offers interesting prospects to this
issue, but so far focus has not been so much on con-
text appropriateness as on globally increasing the
number of biphrase examples.
2The study of (Carpuat, 2009) shows that the one transla-
tion per discourse hypothesis holds in some cases, but to our
knowledge no SMT systems have attempted to exploit it yet.
However, in our view, this finding does not contradict the need
for estimating translation distributions at the individual phrase
level, but they should be integrated as additional information.
</bodyText>
<page confidence="0.98322">
656
</page>
<note confidence="0.817801">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 656–666,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999937822222222">
The approach we take in this article is motivated
by the fact that natural language allows for multiple
text views on a given content, and that if two phrases
are good paraphrases in context, then considering
appropriate training examples of one of the phrases
could provide larger quantities of training data for
translating the other. In other words, we hypothe-
size that there may be more training data to learn a
phrase’s translations in a bilingual corpus than what
SMT approaches typically use.
In contrast to previous attempts at using para-
phrases to improve Statistical Machine Translation,
which require external data in the form of additional
parallel bilingual corpora (Callison-Burch et al.,
2006), monolingual corpora (Marton et al., 2009),
lexico-semantic resources (Mirkin et al., 2009; Aziz
et al., 2010), or sub-sentential (Resnik et al., 2010)
or sentential paraphrases of the input (Schroeder et
al., 2009), the approach we take here can be endoge-
nous with respect to the original training data. It
also significantly departs from previous work in that
paraphrasing is not simply considered as a way of
finding alternative wordings that can be translated
given the original training data for out-of-vocabulary
phrases only (Callison-Burch et al., 2006; Marton
et al., 2009; Mirkin et al., 2009; Aziz et al., 2010),
but as a means to better estimate translations for any
possible phrase. Also, as opposed to the work by
(Schroeder et al., 2009; Onishi et al., 2010; Du et
al., 2010), we do not encode paraphrases into input
lattices to have them compete against each other to
belong to the source sentential paraphrase that will
lead to the highest scoring output sentence3. Instead,
we make use of all contextually appropriate para-
phrases of a source phrase, which collectively eval-
uate the quality of each translation for that phrase.
This work can thus be seen as a contribution to-
wards shifting from global phrase translation dis-
tributions to contextual translation distributions for
contextually equivalent source units. The remainder
of this paper is organized as followed. In section 2
we review relevant previous works and discuss how
they differ from our approach. Section 3 provides a
description of the details of our approach. We de-
scribe an experimental setup in section 4 and com-
</bodyText>
<footnote confidence="0.667966">
3This highly depends on how well estimated translations for
each independent paraphrase are.
</footnote>
<bodyText confidence="0.999256">
ment on our results. Finally, we discuss our future
work in section 5.
</bodyText>
<sectionHeader confidence="0.98507" genericHeader="method">
2 Relation to previous work
</sectionHeader>
<subsectionHeader confidence="0.9935935">
2.1 Contextual estimation of phrase
translations
</subsectionHeader>
<bodyText confidence="0.999870682926829">
In standard approaches to phrase-based SMT, evi-
dence of a translation is accumulated uniformely ev-
ery time it is found associated with a source phrase
in the training corpus. In addition to the fact that
errors in automatic word alignment and non literal
translations often produce useless biphrases, this re-
sults in rare but appropriate translations being very
unlikely to be considered during decoding. Some
approaches on source context modelling (Carpuat
and Wu, 2007; Stroppa et al., 2007; Max et al., 2008;
Haque et al., 2009) build classifiers offline for the
phrases in a test set, so that context similarity can
for example reinforce scores associated with rare
but appropriate translations. However, heavy offline
computation makes scaling to larger corpora an is-
sue. Other approaches (Callison-Burch et al., 2005;
Lopez, 2008) instead focus on accessing very large
corpora. Indexing by suffix arrays is used to allow
fast access to phrase instances in the corpus, and ran-
dom sampling to avoid collecting the full set of ex-
amples has been shown to perform well. However,
these approaches consider all instances of a phrase
as equivalent for the estimation of its translations.
These works converge on the need for accessing
a sufficient number of examples that are relevant for
any source phrase in context, fast enough to permit
on-the-fly phrase table building. This paper pro-
poses an intermediate step: the full set of phrase
examples is found efficiently, and a measure of the
adequacy of each example with a phrase in context
provides evidence for its translation that depends on
this value of adequacy. In this way, the translation
associated with an example for a different sense of
a polysemous word would in the best scenario only
be considered marginally when computing the trans-
lation distribution. As in most previous works, ad-
equacy can be approximated by context similarity
between phrase occurrences and training examples.
Ideally, one would stop extracting examples when
enough appropriate examples have been found to es-
timate a reliable translation distribution. (Callison-
</bodyText>
<page confidence="0.995717">
657
</page>
<table confidence="0.820728">
sample size 100 500 1K 5K 10k 50k unlim.
BLEU score 28.8 28.8 28.8 28.9 29.1 28.9 29.0
</table>
<figureCaption confidence="0.855836">
Figure 1: Effect of number of samples on translation
quality (measured on German to English translation on
Europarl data) reported by (Callison-Burch et al., 2005)
</figureCaption>
<bodyText confidence="0.999416652173913">
Burch et al., 2005) measured the impact on transla-
tion quality of the sample size in random sampling
of source phrase examples in the training corpus to
estimate a phrase’s translation probabilities. As Ta-
ble 1 shows, quality (in terms of BLEU scores) al-
most remains constant for samples of size 100 or
more. This apparent confirmation of the efficiency
of random sampling is backed up by the authors
with the following possible explanations: 1) the
most probable translations remain the same for dif-
ferent sample sizes; 2) misestimated probabilities
are ruled out by the target language model; and
3) longer or less frequent phrases, which are not
affected by sampling, are preferred. However, as
said previously, random sampling cannot guarantee
that contextually-appropriate examples are selected.
In fact, (Lopez, 2008) points out to using discrimi-
natively trained models with contextual features of
source phrases in conjunction with phrase sampling
as an open problem. This work does not attempt to
directly address it, but instead resorts to complete
analysis of the training data to guarantee that all
contextually-appropriate examples are considered.
</bodyText>
<subsectionHeader confidence="0.999787">
2.2 Using paraphrases for translating
</subsectionHeader>
<bodyText confidence="0.999836866666667">
For some phrases, not enough examples can be
found in the training corpus to estimate reliable
translation probabilities in context. In such cases,
one might be interested in finding more appropri-
ate examples, which seems at first impossible us-
ing the sole original bilingual corpus. We can in
fact consider the set of source phrases that have
similar translations in context. This set is roughly
made up of a subset of what can be referred to as
paraphrases. One possible approach to extract lo-
cal (i.e. phrasal) paraphrases precisely exploits sim-
ilarity on the target side in another language by ex-
tracting source phrases that share common transla-
tions (Bannard and Callison-Burch, 2005), but re-
cent approaches have combined this approach with
</bodyText>
<table confidence="0.97563875">
Source phrase Paraphrases
Balkan War Balkan war (0.25) Balkans War
(0.125) Balkans (0.125) Balkans
war (0.125) war in the Balkans
(0.125) Balkan conflict (0.125)
British forces British troops (0.29) British
armed forces (0.19)
Czech president President of the Czech Republic
</table>
<figure confidence="0.69733225">
(0.5)
Dalai Lama’s of the Dalai Lama (0.27)
I don’t see I do not believe (0.18) I do not think
(0.18) I do not see (0.15)
</figure>
<figureCaption confidence="0.999097">
Figure 2: Examples of paraphrases obtained by pivoting
via French; values indicate paraphrase probability as de-
fined in (Bannard and Callison-Burch, 2005).
</figureCaption>
<bodyText confidence="0.999285107142857">
similarity computation in the “source” (i.e. original)
language (Callison-Burch, 2008; Max, 2008; Kok
and Brockett, 2010). Figure 2 provides examples of
English paraphrases obtained by automatically piv-
oting via French. As can be seen, some examples
would be clearly useful to better estimate transla-
tions of the original source phrase: (Balkan War
H war in the Balkans) are syntactic variants that
can generally substitute with each other, (Balkan
War H Balkans war) are character-level variants4.
Other examples, however, clearly illustrate the need
for validation in context: (Dalai Lama’s H of the
Dalai Lama) require different syntactic contexts,
and (I don’t see H I do not believe) are only inter-
changeable in specific semantic contexts.
Previous attempts at exploiting paraphrases in
SMT have first concentrated on obtaining transla-
tions for phrases absent from the training corpus
(Callison-Burch et al., 2006; Marton et al., 2009;
Mirkin et al., 2009)5, with modest gains in trans-
lation performance as measured by automatic met-
rics. (Callison-Burch et al., 2006) obtain para-
phrases by pivoting via additional bilingual corpora
and use the translations of known paraphrases to
translate unseen phrases, which requires that the ad-
ditional bilingual corpora contain the unseen source
phrases and that some of the extracted paraphrases
be present in the original corpus. (Marton et al.,
</bodyText>
<footnote confidence="0.9242424">
4To our knowledge, most implementations of SMT decoders
do not integrate flexible matching of phrases.
5The work by (Mirkin et al., 2009) in fact considers both
paraphrases and entailed texts to increase the number of prop-
erly translated texts.
</footnote>
<page confidence="0.995323">
658
</page>
<bodyText confidence="0.999990931818182">
2009) proceed similarly but obtain their paraphrases
from comparatively much larger monolingual cor-
pora by following the distributionality hypothesis.
In both cases, gains are only obtained in very spe-
cific conditions where very few training data are
available and where useful additional knowledge can
be brought in from external resources. Furthermore,
the described implementations do not consider ac-
ceptability of the paraphrases in context, as their un-
derlying hypothesis is that it might be more desir-
able to translate some paraphrase than not to trans-
late a given phrase.6 In contrast, the work by (Mirkin
et al., 2009) attempts to model context when using
replacements for words (synonyms or hypernyms).
The natural next step that we take here is to
exploit the complementarity of the original bilin-
gual training corpus for finding paraphrases and the
monolingual (source) side of the same corpus for
validating them in context. Furthermore, our fo-
cus here is not on paraphrasing unseen phrases7, but
possibly any phrase, or any phrase seen less than a
given number of times, or any types of difficult-to-
translate phrases (Mohit and Hwa, 2007).
The recent work of (Resnik et al., 2010)
uses crowdsourcing to obtain paraphrases for
source phrases corresponding to mistranslated target
phrases. The spotting of the incorrect target phrases
and the paraphrasing of the source phrases can be
automated. Promising oracle figures are obtained,
validating the claim that some variations of the input
sentence might be more easily translated than oth-
ers by a given system. Paraphrases have also been
used to represent alternative inputs encoded in lat-
tices using existing (Schroeder et al., 2009) or au-
tomatically built paraphrases (Onishi et al., 2010;
Du et al., 2010). In this scenario, paraphrases are in
fact competing with each other, whereas in our pro-
posal paraphrases collectively participate in evalu-
ating the quality of each translation for a source
phrase. We believe that if two phrases are indeed
paraphrases in context, then their respective set of
translations are both relevant to translate the two
phrases. The target language model nevertheless
still has an important role to play to select appro-
</bodyText>
<footnote confidence="0.9265505">
6The default strategy for most decoders is to copy out-of-
vocabulary tokens into the final text.
7Doing it in conjunction with our approach for improving
the translation of known phrases is part of our future work.
</footnote>
<bodyText confidence="0.997901125">
priate translations among semantically-compatible
translations (i.e., target side paraphrases) in the spe-
cific context of a generated target hypothesis.
Lastly, automatic sentential paraphrasing has also
been used in SMT to build alternative reference
translations for parameter optimization (Madnani
et al., 2008) and to build alternative training cor-
pora (Bond et al., 2008).
</bodyText>
<sectionHeader confidence="0.667875" genericHeader="method">
3 Towards better exploitation of training
</sectionHeader>
<subsectionHeader confidence="0.612305">
corpora in phrase-based SMT
</subsectionHeader>
<bodyText confidence="0.999859846153846">
In typical phrase-based SMT settings (Koehn et al.,
2003), words from the source side of the corpus
are first aligned to words on the target side and
biphrases are extracted from each training sentence
using some heuristics on the word alignments. A
source phrase f in a sentence being translated may
therefore be aligned to a variety of target phrases.
In the example on Figure 3, f is aligned some num-
ber of times in the training corpus to target phrases
e1, e2, e3 and e5. Using the number of times f is
paired with some target phrase ei, count(f, ei), rela-
tive frequency estimation can be used to compute the
probability of translation ei given source phrase f:
</bodyText>
<equation confidence="0.991992">
prel(ei |f) = coun,
Ej cout�t(f, �j) (1)
</equation>
<bodyText confidence="0.868595952380952">
This value, together with other estimates of how
appropriate a translation pair (f, ei) is, are recorded
in a phrase table, which typically discards all con-
textual information.8 Therefore, the translation dis-
tribution of some phrase is globally estimated from
a training corpus independently of the actual context
of that phrase.9 On Figure 3, phrase f has at least
two distinct senses: one represented by set £, which
in our example corresponds to the appropriate sense
for a particular occurrence of f in a test sentence;
and one which corresponds to translation e5. A typ-
ical problem, due to the lack of context modeling,
8See (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et
al., 2008; Gimpel and Smith, 2008; Haque et al., 2009) for no-
table exceptions.
9Context is in fact taken into account to some extent by the
target language model, which should score higher translations
that are more appropriate given a target translation hypothesis
being built. In fact, in this work we consider the target language
model as the main source of information for selecting among
acceptable target phrases (target language paraphrases).
</bodyText>
<page confidence="0.99806">
659
</page>
<figureCaption confidence="0.856854555555555">
Figure 3: Example of possible source equivalents and
translations for phrase occurrence f “un bon avocat” in
the sentence “L’embauche d’un bon avocat est cruciale
quelle que soit l’activit6” (“Hiring a good lawyer is cru-
cial to any business”). Set £ represents target phrase
types that are acceptable translations given the particu-
lar context of f, and set J7 represents source phrase types
that can be in a paraphrasing relation to f depending on
the context they appear in.
</figureCaption>
<bodyText confidence="0.999751933333334">
is that in situations such as bei E £, count(f, e5) »
count(f, ei), it is very unlikely that a correct trans-
lation will be selected during decoding against the
incorrect but much more frequent one. Taking an
extreme view on this issue, it is in fact desirable that
when estimating phrase translation probabilities for
a phrase f, translations of incompatible senses be
not considered.10 Of course, this raises the diffi-
cult issue of sense clustering of phrases. We propose
here an intermediary solution, which consists in con-
sidering each occurrence in the training corpus as
counting a number of times that depends on its con-
textual similarity with the occurrence of f from the
test file, through the following additional translation
model:
</bodyText>
<equation confidence="0.906009">
C (fk))
E( fk ei) simcont(C (f ),
pcont(ei|f) = (fk,ej) simcont(C(f), C(fk))
(2)
</equation>
<bodyText confidence="0.957790666666667">
where f is some source phrase to translate and fk
an example of f in the training corpus, (fk, ei) is a
10Put differently, is it more acceptable to copy a source word
in the target hypothesis or to incorrectly translate it when the
confidence about its being incorrect is high?
biphrase from the training corpus, C(f) the context
of some source phrase, C(fk) the context of a par-
ticular example of f in the training corpus, simphr
a function indicating the contextual similarity be-
tween two phrase contexts, and ej is any possible
translation of f.
The problem of modeling phrase translation is
however not limited to inappropriate training exam-
ples. For various reasons, legitimate occurrences of
source phrases may not be considered when building
a phrase’s translation distribution. We describe those
cases by considering the possible source phrases pi
from Figure 3:
</bodyText>
<listItem confidence="0.989122166666667">
• p1’s only translation, e1, is a common transla-
tion with f; each contextually-appropriate ex-
ample of p1 should reinforce the probability of
e1 being a translation for f.
• Contextually-appropriate examples of p2 can
reinforce e3. Translation e6 should correspond
to contextually-inappropriate examples of p2,
so e6 should not be considered as a new po-
tential translation for f.
• Contrarily to the examples of p2 translating as
e6, examples of p3 translating as e4 are much
more likely of being contextually-appropriate
with f, meaning that f could be substituted
with most p3 examples. Therefore, e4, which
was not initially considered as a possible trans-
lation of f, could now be considered as such.
• p4 shares a translation with f, e2, but this is
due to the polysemous nature of this transla-
tion. Again, all examples of p4 should be found
contextually-inappropriate with f, and their
translations should not be considered when es-
timating the translations of f.
• Lastly, the case of the common translation e5
between f and p5 illustrates a consequence of
the polysemous nature of the source phrase cor-
responding to word sequence f: translations
corresponding to other senses of f should not
get reinforced by paraphrase examples such as
those of p5 as these examples should be found
contextually-inappropriate with f.
</listItem>
<page confidence="0.989025">
660
</page>
<bodyText confidence="0.998409">
We build a separate translation model for transla-
tions estimated through paraphrases, defined as fol-
lows:
</bodyText>
<equation confidence="0.9655248">
E
(pk,ez) simpara(C(f), C(pk))
E
(pk,ej) simpara(C(f),C(pk))
(3)
</equation>
<bodyText confidence="0.943019545454545">
where pk is a paraphrase of f, (pk, ei) is a biphrase
from the training corpus such that ei is also a transla-
tion of f, C(f) the context of a given source phrase
for which we are estimating the translation distribu-
tion, C(pk) the context of a particular example of pk
in the training corpus, simpara a function indicat-
ing the contextual similarity between a phrase con-
text and a paraphrase context, and ej is any possible
translation of f.
Several requirements can be drawn from the pre-
vious description:
</bodyText>
<listItem confidence="0.996280115384615">
1. List of potential paraphrases: some mech-
anism for finding potential paraphrases for
source phrases is required, and several such
mechanisms could be combined. Pivoting via
bilingual corpora, a natural strategy given the
issue at hand, is just one among many different
proposed strategies (Madnani and Dorr, 2010).
2. Contextual similarity measure: a similarity
measure between the contexts of two phrases
or two potential local paraphrases is required.
This automatic measure should ideally be able
to model not only syntactic but also semantic
and pragmatic information.
3. Robust translation evaluation: our ap-
proach is designed to reinforce estimates for
any contextually-appropriate translations of a
phrase, as shown by set £ on Figure 3. It is
therefore important to have some means of ac-
cepting them as subparts of valid translations.
Robustness in Machine Translation evaluation
is an active domain, and potential candidates
include using BLEU-like metrics with multiple
references, Human-targeted Translation Error
Rate (Snover et al., 2006) and the use of para-
phrases for reference translations (Kauchak and
Barzilay, 2006).
</listItem>
<table confidence="0.99229775">
train dev. test
# sent. # tok. # sent. # tok. # sent. # tok.
en 318K 9.1M 500 14,0K 500 13,6K
fr 318K 10.3M 500 16,1K 500 15,7k
</table>
<figureCaption confidence="0.997374">
Figure 4: Statistics of the corpora used.
</figureCaption>
<bodyText confidence="0.999953352941176">
In this paper, we want to evaluate whether an en-
dogenous approach for finding paraphrases can lead
to some improvement in translation performance.
Note that we will not consider in this initial work
the possibility of adding new translations to phrases
(such as e4 for f on Figure 3) as it adds complexity
and should be investigated when the other simpler
cases can be handled successfully.
In the following section, we describe experiments
in which the original bilingual corpus is the only re-
source used to find potential paraphrases and to esti-
mate phrase translations in context. We chose a very
simple measure of similarity, and let to our future
work the task of improving context modeling. As
regards evaluation, we will resort to various ways to
measure the impact of our implementation on trans-
lation performance.
</bodyText>
<sectionHeader confidence="0.999236" genericHeader="evaluation">
4 Experiments and results
</sectionHeader>
<subsectionHeader confidence="0.998935">
4.1 Data and baseline SMT systems
</subsectionHeader>
<bodyText confidence="0.999933166666667">
We have conducted our experiments using the
MOSES11 package to build state-of-the-art phrase-
based SMT systems for phrases of up to 5 tokens,
using standard parameters and MERT for optimizing
model weights. We used a subpart of the Europarl
corpus12 in French and English as our training cor-
pus and built baseline MOSES systems (bsl) in both
directions. The target side of the training corpus
was used to train 3-gram target language model with
modified Kneser-Ney smoothing. Held-out datasets
were used for development and testing. The charac-
teristics of all corpora are described in Figure 4.
</bodyText>
<subsectionHeader confidence="0.970483">
4.2 Example-based Paraphrasing SMT systems
</subsectionHeader>
<bodyText confidence="0.999509">
We also built systems that exploit phrase and para-
phrase context under the form of two additional
models pcont and ppara described in section 3. These
</bodyText>
<footnote confidence="0.975228">
11http://www.statmt.org/moses
12http://www.statmt.org/europarl
</footnote>
<equation confidence="0.921187">
ppara(ei|f) =
</equation>
<page confidence="0.933729">
661
</page>
<figure confidence="0.999439307692308">
(4)
length =
phrase table size num. entries
en—*fr
baseline 240Mb 2.4M
our systems 5.0Gb 37.5M
fr—*en
baseline 193Mb 1.9M
our systems 4.0Gb 30.2M
{ lengthleft + lengthright
if lengthleft &gt; 0
and lengthright &gt; 0
0 otherwise
</figure>
<figureCaption confidence="0.9961035">
Figure 5: Statistics on the size and the number of entries
of the phrase tables filtered on the development set.
</figureCaption>
<bodyText confidence="0.999886304347826">
models are added to the list of models used to eval-
uate the various translations of a phrase in the ap-
propriate phrase tables, and are optimized with the
other models by standard MERT.
In order to model context, we modified the source
texts so that each phrase becomes unique in the
phrase table, i.e. it has its own translation distribu-
tion. This is done (as in other works (Carpuat and
Wu, 2007; Stroppa et al., 2007)) by transforming
each token into a unique token, e.g. token —* to-
ken@337. This therefore leads to a significant in-
crease in the size of the phrase table, as illustrated
on Figure 5, as all occurrences for the same phrase
are not factored anymore.13
We chose a very simple initial definition of con-
text similarity based on the presence of common
n-grams in the immediate vicinity of two phrases.
Let lengthleft (resp. lengthright) be the length of
the longest common n-gram in the immediate vicin-
ity on the left (resp. right) of two phrases in context
(C(f) and C(fi)). For instance, given the two fol-
lowing contexts (phrases under focus are in bold and
common n-grams are underlined):
</bodyText>
<listItem confidence="0.840802">
1. the commission accepts the substance of the
</listItem>
<equation confidence="0.7457545">
amendments@11257 proposed@11258
by@11259 the committee on fisheries ...
</equation>
<bodyText confidence="0.89786125">
2. this is why we shall support all of the amend-
ments put forward by the committee on agri-
culture and rural development ...
lengthleft = 2 and lengthright = 3. We further
define length as:
13These volumes of data and our available hardware facilities
for these experiments led us to initially limit the size of our data
sets. We will discuss in section 5 how we intend to address this
limitation in our future work.
We can now define the two similarity functions
used in Equations 2 and 3 that we used for our ex-
periments:
</bodyText>
<equation confidence="0.998873">
simcont(C(f), C(fi)) = (1 + length)&apos; (5)
simpara(C(f), C(pi)) = (length),3 (6)
</equation>
<bodyText confidence="0.999802555555556">
The rationale for these functions is the follow-
ing. Exact phrase examples add at least a transla-
tion count of 1, i.e. their translation is always taken
into account to estimate pcont. Paraphrase exam-
ples add a translation count of 0 if length = 0,
i.e. their translation is not taken into account at all
if surrounding n-gram similarity is too low. We used
α = Q = 1.5. Algorithm 1 describes how the two
models are estimated from the training data.
</bodyText>
<figure confidence="0.391637125">
foreach phrase f in training file do
extract C(f);
/* phrase count */
foreach unique phrase fi in test(f)) do
extract C(fi);
compute simcont(C(f), C(fi));
end
/* paraphrase count */
foreach phrase pi in para(f) do
foreach unique phrase fj in test(pi) do
extract C(fj);
compute simpara(C(f), C(fj));
end
end
end
estimate pcont and para;
</figure>
<figureCaption confidence="0.365084">
Algorithm 1: Model estimation for pcont and
</figureCaption>
<bodyText confidence="0.9767215">
ppara. Function test(f) returns all unique
phrases corresponding to phrase f from the test
file. Function para(f) return all phrases for
which f is a known paraphrase.
We implemented the following strategy to find
paraphrases for phrases in the test file. We extract all
</bodyText>
<page confidence="0.993082">
662
</page>
<table confidence="0.935875769230769">
Left context phrase/paraphrase Right context
IS#1 at the moment it is up to each member state to decide, and practice dif-
fers considerably from country to country
PE#1 ... as regards the terminal portion in the the responsability of each member state to define its own policy.
cycle of nuclear fuel, it is
PT#1 la responsabilit´e de chaque
IS#2 that is why i find it extremely regrettable that the amendment on harmonising the re-
registration of cars that have been involved
in accidents ...
PE#2 for all these reasons and given your most a pity that the new legal base for the daphne pro-
excellent statement, i find it
gramme is so restrictive ...
PT#2 dommage que
</table>
<figureCaption confidence="0.990463333333333">
Figure 6: Examples of paraphrases in context from the development file. The input sentence (IS) contains a source
phrase of interest (in bold), the paraphrase example (PE) contains a paraphrase of that source phrase (in bold) for
which a paraphrase translation (PT) is known.
</figureCaption>
<bodyText confidence="0.9998946">
paraphrases p for a phrase f by pivot: all target lan-
guage phrases e aligned to f are first extracted, and
all source language phrases p aligned to e are ex-
tracted. The following constraints are then applied
to define which paraphrases are kept:
</bodyText>
<listItem confidence="0.983306181818182">
• string p is not included in string f and vice
versa (in order to minimize the impact of align-
ment errors in the training corpus);
• the paraphrasing probability is greater than a
fixed threshold: para(f, p) &gt; 10−2, where
para(f, p) = Ee p(e|f)p(p|e) (Bannard and
Callison-Burch, 2005);
• the number of occurrences of phrase f and
paraphrase p are equal or less than indepen-
dent thresholds: numOccs(f) &lt; 100 and
numOccs(p) &lt; 1000.14
</listItem>
<bodyText confidence="0.98823425">
Figure 6 shows examples of paraphrases in con-
text with high similarity with some original phrase,
and Figure 7 provides various statistics on the para-
phrases extracted on the test file.
</bodyText>
<subsectionHeader confidence="0.988997">
4.3 Results and analysis
</subsectionHeader>
<bodyText confidence="0.995458">
Automatic evaluation results are reported in Table 8
for various configurations. We also wanted to focus
our measures on content words, which are known
</bodyText>
<footnote confidence="0.92281725">
14The first threshold value was chosen as (Callison-Burch et
al., 2005) report it to be an optimal sample size for estimating
phrase translation probabilities. The relatively low value for the
second threshold was selected to reduce computation time.
</footnote>
<table confidence="0.879186875">
phrase # phrases # paraphrased # paraphrases
length
en fr en fr en fr
1 13,620 15,707 458 725 1,824 2,684
2 13,120 15,207 4,127 4,481 18,871 19,700
3 12,620 14,707 4,782 5,715 24,111 27,377
4 12,120 14,208 2,859 4,078 15,071 20,345
5 11,623 13,711 1,171 2,275 6,077 12,132
</table>
<figureCaption confidence="0.996145666666667">
Figure 7: Statistics on numbers of phrases, numbers
of paraphrased phrases and numbers of paraphrases per
phrase length.
</figureCaption>
<bodyText confidence="0.992991318181818">
to be important as regards information content in
translation. We applied the contrastive lexical eval-
uation (CLE) methodology described in (Max et
al., 2010), which indicates how many times source
words grouped into user-defined classes were cor-
rectly translated or not across systems. These addi-
tional results are reported on Figure 9.
On English to French translation, both additional
features lead to improvements over the baseline
with all metrics, including CLE, and their combi-
nation shows a strong improvement in TER (-1.55).
CLE on content words reveals that the para feature
seems particularly effective in reducing the number
of words in all categories that only the baseline sys-
tem translated correctly.
Results on French to English translation are less
positive: neither cont nor para alone improve over
the baseline with any metrics. However, their com-
bination improves over the baseline with all met-
rics except BLEU, including a reduction of -1.07
in TER. Detailed analysis of CLE results shows
that the translation of adjectives and nouns benefited
</bodyText>
<page confidence="0.997886">
663
</page>
<bodyText confidence="0.999982022222223">
more from using our two additional models. Verbs,
whose translation improved slightly, are strongly in-
flected in French, so finding examples for a given
form is more difficult than for less inflected word
categories, as is finding paraphrases with the appro-
priate inflection. Also, pivoting via English is one
reason why paraphrases obtained via a low-inflected
language can be of varying quality. Furthermore, the
simplicity of our context modeling may have been
ineffective in filtering out some bad examples. Over-
all, para was more effective with the low-inflected
English as the source language, improving over the
baseline with all metrics.
These results confirm that translation perfor-
mance can be improved by exploiting context and
paraphrases in the original training corpus only. We
next attempted to measure whether some improve-
ment in the quality of the paraphrases used would
have some measurable impact on translation perfor-
mance. To this end, we devised a semi-oracle ex-
periment in the following way: the source and target
test files were automatically aligned, and for each
source phrase possible target phrases (i.e., reference
translations) were extracted, and used as pivots to
extract potential paraphrases, which were then fil-
tered with the same constraints as previously. In
this way, we exploit the information that paraphrases
can at least produce the desired translation, but they
may also propose other incorrect translations and/or
be present in very few examples. Results appear
in the inf rows of Tables 8 and 9. We obtain the
most important improvement over the baseline in
BLEU for the two language pairs (resp. +0.99 and
+0.44), though the results for the other metrics for
French to English translation are more difficult to
interpret. For this language pair, possible reasons
include again that the pivot language may not be
appropriate, and also that the limitation to a sin-
gle pivot15 may not have produced more monolin-
gual variation that might have proved useful. CLE
on English to French, however, reveals significant
gains with a relative improvement over the baseline
of +116 content words. Under this condition, this
result shows that the higher the quality of the para-
phrases used, the more translation quality can be im-
</bodyText>
<footnote confidence="0.642160333333333">
15Several pivot phrases may in fact have been automatically
extracted for a given phrase, some of which being possible bad
candidates.
</footnote>
<table confidence="0.999022461538461">
BLEU NIST TER METEOR
en→fr
bsl 30.28 - 6.66 - 57.86 - 54.79 -
+cont 31.11 +0.83 6.77 +0.11 57.24 -0.62 55.22 +0.43
+para 30.97 +0.69 6.74 +0.08 57.38 -0.48 55.39 +0.60
all 30.93 +0.65 6.84 +0.18 56.31 -1.55 55.28 +0.49
inf 31.27 +0.99 6.78 +0.12 57.22 -0.64 55.80 +1.01
fr→en
bsl 29.90 - 6.90 - 54.64 - 61.36 -
+cont 29.56 -0.34 6.89 -0.01 54.95 +0.31 60.98 -0.38
+para 29.70 -0.20 6.92 +0.02 54.64 +0.00 61.10 -0.26
all 29.75 -0.15 7.03 +0.13 53.57 -1.07 61.63 +0.27
inf 30.34 +0.44 6.93 +0.03 54.90 +0.26 60.99 -0.37
</table>
<figureCaption confidence="0.9916008">
Figure 8: Automatic scores for the MOSES baseline sys-
tems (bsl), systems additionnally using the contextual
feature (+cont), systems additionnally using the para-
phrasing feature (+para), systems using both features
(all), and pivot-informed systems (inf).
</figureCaption>
<table confidence="0.999895952380953">
Adj Adv Noun Verb
en→fr
+cont - 74 28 113 60 275
+ 55 35 114 85 289 +14
- 62 12 82 46 202
+para
+ 58 32 111 78 279 +77
all - 72 25 91 72 260
+ 50 37 118 97 302 +42
inf - 58 20 108 56 242
+ 65 43 147 103 358 +116
fr→en
+cont - 30 16 80 69 195
+ 15 21 69 46 151 -44
- 32 19 72 60 183
+para
+ 12 18 65 43 138 -45
all - 21 18 67 61 167
+ 30 18 94 48 190 +23
inf - 38 21 83 66 208
+ 31 23 106 57 217 +9
</table>
<figureCaption confidence="0.96932575">
Figure 9: Contrastive lexical evaluation results per part-
of-speech measured on the test file. ’-’ (resp. ’+’) rows
indicate the number of source words that only bsl (resp.
the compared system) correctly translated.
</figureCaption>
<bodyText confidence="0.999935222222222">
proved, which is in line with works that make use
of human-made paraphrases to improve translation
quality (Schroeder et al., 2009; Resnik et al., 2010).
Table 10 presents a typology of paraphrases found
in our development set and classifies the impact of
using them for phrase translation estimation. As can
be seen, more work is needed to better understand
the characteristics of the phrases that should be para-
phrased and of their paraphrases.
</bodyText>
<page confidence="0.994871">
664
</page>
<table confidence="0.954799714285714">
Type Impact Examples
Morphological variants +/- (yugoslav republic ↔ yugoslavian republic), (go far ↔ goes far)
Synonymy + (duties ↔ obligations), (to look into ↔ to study)
Grammatical word substitution ?/- (states in the ↔ the states of the), (amendments by ↔ amendments to)
Word deletion or insertion ?/- (first reading, the → first reading the), (amendments by ↔ amendments
proposed by)
Syntactic rewritings + (approval of the majority ↔ majority support), (capacity of the euro-
pean union ↔ european union’s ability)
Phrasal idiomatic substitutions + (must be said that the ↔ goes without saying that the), (is fully in line
↔ is totally coherent), (is amazing ↔ strikes me)
Context-dependent substitu- +/- (is not right ↔ is unacceptable), (offer my ↔ express my)
tions
Alignment and translation prob- - (unnecessary if ↔ vital if), (the crime ↔ organized), (ill-advised ↔
lems wise), (to begin by thanking ↔ to begin by congratulating)
</table>
<figureCaption confidence="0.575282">
Figure 10: Main types of paraphrase pairs found in our dev. and training corpora. Pairs shown have length &gt; 0.
</figureCaption>
<sectionHeader confidence="0.988196" genericHeader="conclusions">
5 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999982948717949">
We have introduced an original way of exploiting
both context and paraphrasing for the estimation
of phrase translations in phrase-based SMT. To our
knowledge, this is the first time that paraphrases ac-
quired in an endogenous manner have been shown
to improve translation performance, which shows
that bilingual corpora can be better exploited than
they typically are. Our experiments further showed
the promises of our approach when paraphrases of
higher quality are available.
In the light of our results and our initial typology
of paraphrases presented on Figure 10, as well as
previous work on paraphrasing for SMT, the diffi-
cult question of what units should be paraphrased
for what success should be addressed, taking into ac-
count parameters such as language pairs, quantity of
training data and availability of external resources.
Our future work includes three main areas: first,
we want to improve the modeling of context, by no-
tably working on techniques inspired from Informa-
tion Retrieval to quickly access contextually-similar
examples of source phrases in bilingual corpora.
Such contextual sampling on large bilingual corpora
for phrases and their paraphrases, which could inte-
grate more complex linguistic information, will al-
low us to assess our approach on more challenging
conditions. This would also allow us to build con-
textual models on-the-fly, and experiment with us-
ing lattices to encode contextually estimated para-
phrases. Second, we will combine paraphrases ob-
tained via different techniques and resources, which
will allow us to also learn translation distributions
for phrases absent from the original corpus. Lastly,
we want to also exploit paraphrases for the addi-
tional translations that they propose (such as e4 on
Figure 3) and that would be contextually similar in
the target language to other existing translations of
a given phrase or that could even represent a new
sense of the original phrase.
</bodyText>
<sectionHeader confidence="0.993969" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99922875">
This work was partly supported by ANR project
Trace (ANR-09-CORD-023). The author would like
to thank the anonymous reviewers for their helpful
questions and comments.
</bodyText>
<sectionHeader confidence="0.999119" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999034333333333">
Sadaf Abdul-Rauf and Holger Schwenk. 2009. On the
Use of Comparable Corpora to Improve SMT perfor-
mance. In Proceedings of EACL, Athens, Greece.
Wilker Aziz, Marc Dymetman, Shachar Mirkin, Lucia
Specia, Nicola Cancedda, and Ido Dagan. 2010.
Learning an Expert from Human Annotations in Sta-
tistical Machine Translation: the Case of Out-of-
Vocabulary Words. In Proceedings of EAMT, Saint-
Raphael, France.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with Bilingual Parallel Corpora. In Proceed-
ings of ACL, Ann Arbor, USA.
Francis Bond, Eric Nichols, Darren Scott Appling, and
Michael Paul. 2008. Improving statistical machine
translation by paraphrasing the training data. In Pro-
ceedings of IWSLT, Hawai, USA.
Chris Callison-Burch, Colin Bannard, and Josh
Schroeder. 2005. Scaling Phrase-Based Statis-
</reference>
<page confidence="0.980454">
665
</page>
<reference confidence="0.99988">
tical Machine Translation to Larger Corpora and
Longer Phrases. In Proceedings of ACL, Ann Arbor,
USA.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved Statistical Machine Transla-
tion Using Paraphrases. In Proceedings of NAACL,
New York, USA.
Chris Callison-Burch. 2008. Syntactic Constraints on
Paraphrases Extracted from Parallel Corpora. In Pro-
ceedings of EMNLP, Hawai, USA.
Marine Carpuat and Dekai Wu. 2007. Context-
Dependent Phrasal Translation Lexicons for Statisti-
cal Machine Translation. In Proceedings of Machine
Translation Summit XI, Copenhagen, Denmark.
Marine Carpuat. 2009. One Translation Per Discourse.
In Proceedings of the NAACL-HLT Workshop on Se-
mantic Evaluations, Boulder, USA.
Jinhua Du, Jie Jiang, and Andy Way. 2010. Facilitating
Translation Using Source Language Paraphrase Lat-
tices. In Proceedings of EMNLP, Cambridge, USA.
Kevin Gimpel and Noah A. Smith. 2008. Rich Source-
Side Context for Statistical Machine Translation. In
Proceedings of the ACL Workshop on Statistical Ma-
chine Translation, Columbus, USA.
Rejwanul Haque, Sudip Kumar Naskar, Yanjun Ma, and
Andy Way. 2009. Using Supertags as Source Lan-
guage Context in SMT. In Proceedings of EAMT,
Barcelona, Spain.
Almut Silja Hildebrand, Matthias Eck, Stephan Vogel,
and Alex Waibel. 2005. Adaptation of the Transla-
tion Model for Statistical Machine Translation Based
on Information Retrieval. In Proceedings of EAMT,
Budapest, Hungary.
David Kauchak and Regina Barzilay. 2006. Paraphras-
ing for Automatic Evaluation. In Proceedings of
NAACL HLT, New York, USA.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Pro-
ceedings of NAACL HLT, Edmonton, Canada.
Stanley Kok and Chris Brockett. 2010. Hitting the Right
Paraphrases in Good Time. In Proceedings of NAACL,
Los Angeles, USA.
Adam Lopez. 2008. Tera-Scale Translation Models
via Pattern Matching. In Proceedings of COLING,
Manchester, UK.
Nitin Madnani and Bonnie J. Dorr. 2010. Generating
Phrasal &amp; Sentential Paraphrases: A Survey of Data-
Driven Methods. Computational Linguistics, 36(3).
Nitin Madnani, Philip Resnik, Bonnie J. Dorr, and
Richard Schwartz. 2008. Are Multiple Reference
Translations Necessary? Investigating the Value of
Paraphrased Reference Translations in Parameter Op-
timization. In Proceedings of AMTA, Waikiki, USA.
Yuval Marton, Chris Callison-Burch, and Philip Resnik.
2009. Improved Statistical Machine Translation Using
Monolingually-derived Paraphrases. In Proceedings
of EMNLP, Singapore.
Aur´elien Max, Rafik Makhloufi, and Philippe Langlais.
2008. Explorations in using grammatical dependen-
cies for contextual phrase translation disambiguation.
In Proceedings of EAMT, Hamburg, Germany.
Aur´elien Max, Josep M. Crego, and Franc¸ois Yvon.
2010. Contrastive Lexical Evaluation of Machine
Translation. In Proceedings of LREC, Valletta, Malta.
Aur´elien Max. 2008. Local rephrasing suggestions for
supporting the work of writers. In Proceedings of Go-
TAL, Gothenburg, Sweden.
Shachar Mirkin, Lucia Specia, Nicola Cancedda, Ido
Dagan, Marc Dymetman, and Idan Szpektor. 2009.
Source-Language Entailment Modeling for Translat-
ing Unknown Terms. In Proceedings of ACL, Singa-
pore.
Behrang Mohit and Rebecca Hwa. 2007. Localization
of Difficult-to-Translate Phrases. In Proceedings of
the ACL Workshop on Statistical Machine Translation,
Prague, Czech Republic.
Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving Machine Translation Performance by Exploit-
ing Non-parallel Corpora. Computational Linguistics,
31(4).
Takashi Onishi, Masao Utiyama, and Eiichiro Sumita.
2010. Paraphrase Lattice for Statistical Machine
Translation. In Proceedings of ACL, short paper ses-
sion, Uppsala, Sweden.
Philip Resnik, Olivia Buzek, Chang Hu, Yakov Kron-
rod, Alex Quinn, and Benjamin B. Bederson. 2010.
Improving Translation via Targeted Paraphrasing. In
Proceedings of EMNLP, Cambridge, USA.
Josh Schroeder, Trevor Cohn, and Philipp Koehn. 2009.
Word Lattices for Multi-Source Translation. In Pro-
ceedings of EACL, Athens, Greece.
Matthew Snover, Bonnie J. Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study of
Translation Edit Rate with Targeted Human Annota-
tion. In Proceedings of AMTA, Boston, USA.
Nicolas Stroppa, Antal van den Bosch, and Andy Way.
2007. Exploiting Source Similarity for SMT using
Context-Informed Features. In Proceedings of TMI,
Skovde, Sweden.
Guillaume Wisniewski, Alexandre Allauzen, and
Franc¸ois Yvon. 2010. Assessing Phrase-based Trans-
lation Models with Oracle Decoding. In Proceedings
of EMNLP, Cambridge, USA.
</reference>
<page confidence="0.998445">
666
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.793864">
<title confidence="0.998347">Example-based Paraphrasing for Improved Statistical Machine Translation</title>
<author confidence="0.872663">Aur´elien</author>
<affiliation confidence="0.991456">LIMSI-CNRS &amp; Univ. Paris</affiliation>
<address confidence="0.921251">Orsay,</address>
<email confidence="0.997801">aurelien.max@limsi.fr</email>
<abstract confidence="0.999289583333333">In this article, an original view on how to improve phrase translation estimates is proposed. This proposal is grounded on two main ideas: first, that appropriate examples of a given phrase should participate more in building its translation distribution; second, that paraphrases can be used to better estimate this distribution. Initial experiments provide evidence of the potential of our approach and its implementation for effectively improving translation performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sadaf Abdul-Rauf</author>
<author>Holger Schwenk</author>
</authors>
<title>On the Use of Comparable Corpora to Improve SMT performance.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL,</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="2970" citStr="Abdul-Rauf and Schwenk, 2009" startWordPosition="442" endWordPosition="445">et al., 2009) derived from local contextual information in the training examples.2 These approaches are supported by the study of (Wisniewski et al., 2010) which shows that phrase-based SMT systems are expressive enough to achieve very high translation performance and therefore suggests a better scoring of phrases. The apparent tradeoff between the number of training examples and their appropriateness in each indivual context naturally asks for means of increasing the number of appropriate examples. Exploiting comparable corpora for acquiring translation equivalents (Munteanu and Marcu, 2005; Abdul-Rauf and Schwenk, 2009) offers interesting prospects to this issue, but so far focus has not been so much on context appropriateness as on globally increasing the number of biphrase examples. 2The study of (Carpuat, 2009) shows that the one translation per discourse hypothesis holds in some cases, but to our knowledge no SMT systems have attempted to exploit it yet. However, in our view, this finding does not contradict the need for estimating translation distributions at the individual phrase level, but they should be integrated as additional information. 656 Proceedings of the 2010 Conference on Empirical Methods </context>
</contexts>
<marker>Abdul-Rauf, Schwenk, 2009</marker>
<rawString>Sadaf Abdul-Rauf and Holger Schwenk. 2009. On the Use of Comparable Corpora to Improve SMT performance. In Proceedings of EACL, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wilker Aziz</author>
<author>Marc Dymetman</author>
<author>Shachar Mirkin</author>
<author>Lucia Specia</author>
<author>Nicola Cancedda</author>
<author>Ido Dagan</author>
</authors>
<title>Learning an Expert from Human Annotations in Statistical Machine Translation: the Case of Out-ofVocabulary Words.</title>
<date>2010</date>
<booktitle>In Proceedings of EAMT, SaintRaphael,</booktitle>
<contexts>
<context position="1296" citStr="Aziz et al., 2010" startWordPosition="186" endWordPosition="189">ion estimation in Statistical Phrasebased Translation (Koehn et al., 2003) is hampered by the availability of both too many and too few training instances. Recent results on tera-scale SMT (Lopez, 2008) show that access to many training examples1 can lead to significant improvements in translation quality. Also, providing indirect training instances via synonyms or paraphrases for previously unseen phrases can result in gains in translation quality, which are more apparent when little training data is originally available (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010). Although there is a consensus on the importance of using more parallel data in SMT, it has never been formally shown that all additional training instances are actually useful in predicting contextually appropriate translation hypotheses. 1To be more accurate, works such as that of (Lopez, 2008) have recourse to random sampling to build models of a manageable size in a reasonable amount of time. Attempts at limiting training parallel sentences to those resembling test data through thematic adaptation (Hildebrand et al., 2005) indeed confirm that large quantities of training data cannot compe</context>
<context position="4529" citStr="Aziz et al., 2010" startWordPosition="684" endWordPosition="687">idering appropriate training examples of one of the phrases could provide larger quantities of training data for translating the other. In other words, we hypothesize that there may be more training data to learn a phrase’s translations in a bilingual corpus than what SMT approaches typically use. In contrast to previous attempts at using paraphrases to improve Statistical Machine Translation, which require external data in the form of additional parallel bilingual corpora (Callison-Burch et al., 2006), monolingual corpora (Marton et al., 2009), lexico-semantic resources (Mirkin et al., 2009; Aziz et al., 2010), or sub-sentential (Resnik et al., 2010) or sentential paraphrases of the input (Schroeder et al., 2009), the approach we take here can be endogenous with respect to the original training data. It also significantly departs from previous work in that paraphrasing is not simply considered as a way of finding alternative wordings that can be translated given the original training data for out-of-vocabulary phrases only (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010), but as a means to better estimate translations for any possible phrase. Also, as oppos</context>
</contexts>
<marker>Aziz, Dymetman, Mirkin, Specia, Cancedda, Dagan, 2010</marker>
<rawString>Wilker Aziz, Marc Dymetman, Shachar Mirkin, Lucia Specia, Nicola Cancedda, and Ido Dagan. 2010. Learning an Expert from Human Annotations in Statistical Machine Translation: the Case of Out-ofVocabulary Words. In Proceedings of EAMT, SaintRaphael, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with Bilingual Parallel Corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Ann Arbor, USA.</location>
<contexts>
<context position="10501" citStr="Bannard and Callison-Burch, 2005" startWordPosition="1641" endWordPosition="1644">e training corpus to estimate reliable translation probabilities in context. In such cases, one might be interested in finding more appropriate examples, which seems at first impossible using the sole original bilingual corpus. We can in fact consider the set of source phrases that have similar translations in context. This set is roughly made up of a subset of what can be referred to as paraphrases. One possible approach to extract local (i.e. phrasal) paraphrases precisely exploits similarity on the target side in another language by extracting source phrases that share common translations (Bannard and Callison-Burch, 2005), but recent approaches have combined this approach with Source phrase Paraphrases Balkan War Balkan war (0.25) Balkans War (0.125) Balkans (0.125) Balkans war (0.125) war in the Balkans (0.125) Balkan conflict (0.125) British forces British troops (0.29) British armed forces (0.19) Czech president President of the Czech Republic (0.5) Dalai Lama’s of the Dalai Lama (0.27) I don’t see I do not believe (0.18) I do not think (0.18) I do not see (0.15) Figure 2: Examples of paraphrases obtained by pivoting via French; values indicate paraphrase probability as defined in (Bannard and Callison-Burc</context>
<context position="29445" citStr="Bannard and Callison-Burch, 2005" startWordPosition="4756" endWordPosition="4759">tains a paraphrase of that source phrase (in bold) for which a paraphrase translation (PT) is known. paraphrases p for a phrase f by pivot: all target language phrases e aligned to f are first extracted, and all source language phrases p aligned to e are extracted. The following constraints are then applied to define which paraphrases are kept: • string p is not included in string f and vice versa (in order to minimize the impact of alignment errors in the training corpus); • the paraphrasing probability is greater than a fixed threshold: para(f, p) &gt; 10−2, where para(f, p) = Ee p(e|f)p(p|e) (Bannard and Callison-Burch, 2005); • the number of occurrences of phrase f and paraphrase p are equal or less than independent thresholds: numOccs(f) &lt; 100 and numOccs(p) &lt; 1000.14 Figure 6 shows examples of paraphrases in context with high similarity with some original phrase, and Figure 7 provides various statistics on the paraphrases extracted on the test file. 4.3 Results and analysis Automatic evaluation results are reported in Table 8 for various configurations. We also wanted to focus our measures on content words, which are known 14The first threshold value was chosen as (Callison-Burch et al., 2005) report it to be a</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with Bilingual Parallel Corpora. In Proceedings of ACL, Ann Arbor, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francis Bond</author>
<author>Eric Nichols</author>
<author>Darren Scott Appling</author>
<author>Michael Paul</author>
</authors>
<title>Improving statistical machine translation by paraphrasing the training data.</title>
<date>2008</date>
<booktitle>In Proceedings of IWSLT,</booktitle>
<location>Hawai, USA.</location>
<contexts>
<context position="15558" citStr="Bond et al., 2008" startWordPosition="2431" endWordPosition="2434">role to play to select appro6The default strategy for most decoders is to copy out-ofvocabulary tokens into the final text. 7Doing it in conjunction with our approach for improving the translation of known phrases is part of our future work. priate translations among semantically-compatible translations (i.e., target side paraphrases) in the specific context of a generated target hypothesis. Lastly, automatic sentential paraphrasing has also been used in SMT to build alternative reference translations for parameter optimization (Madnani et al., 2008) and to build alternative training corpora (Bond et al., 2008). 3 Towards better exploitation of training corpora in phrase-based SMT In typical phrase-based SMT settings (Koehn et al., 2003), words from the source side of the corpus are first aligned to words on the target side and biphrases are extracted from each training sentence using some heuristics on the word alignments. A source phrase f in a sentence being translated may therefore be aligned to a variety of target phrases. In the example on Figure 3, f is aligned some number of times in the training corpus to target phrases e1, e2, e3 and e5. Using the number of times f is paired with some targ</context>
</contexts>
<marker>Bond, Nichols, Appling, Paul, 2008</marker>
<rawString>Francis Bond, Eric Nichols, Darren Scott Appling, and Michael Paul. 2008. Improving statistical machine translation by paraphrasing the training data. In Proceedings of IWSLT, Hawai, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Colin Bannard</author>
<author>Josh Schroeder</author>
</authors>
<title>Scaling Phrase-Based Statistical Machine Translation to Larger Corpora and Longer Phrases.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Ann Arbor, USA.</location>
<contexts>
<context position="7083" citStr="Callison-Burch et al., 2005" startWordPosition="1094" endWordPosition="1097">act that errors in automatic word alignment and non literal translations often produce useless biphrases, this results in rare but appropriate translations being very unlikely to be considered during decoding. Some approaches on source context modelling (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Haque et al., 2009) build classifiers offline for the phrases in a test set, so that context similarity can for example reinforce scores associated with rare but appropriate translations. However, heavy offline computation makes scaling to larger corpora an issue. Other approaches (Callison-Burch et al., 2005; Lopez, 2008) instead focus on accessing very large corpora. Indexing by suffix arrays is used to allow fast access to phrase instances in the corpus, and random sampling to avoid collecting the full set of examples has been shown to perform well. However, these approaches consider all instances of a phrase as equivalent for the estimation of its translations. These works converge on the need for accessing a sufficient number of examples that are relevant for any source phrase in context, fast enough to permit on-the-fly phrase table building. This paper proposes an intermediate step: the ful</context>
<context position="8613" citStr="Callison-Burch et al., 2005" startWordPosition="1343" endWordPosition="1346">n the best scenario only be considered marginally when computing the translation distribution. As in most previous works, adequacy can be approximated by context similarity between phrase occurrences and training examples. Ideally, one would stop extracting examples when enough appropriate examples have been found to estimate a reliable translation distribution. (Callison657 sample size 100 500 1K 5K 10k 50k unlim. BLEU score 28.8 28.8 28.8 28.9 29.1 28.9 29.0 Figure 1: Effect of number of samples on translation quality (measured on German to English translation on Europarl data) reported by (Callison-Burch et al., 2005) Burch et al., 2005) measured the impact on translation quality of the sample size in random sampling of source phrase examples in the training corpus to estimate a phrase’s translation probabilities. As Table 1 shows, quality (in terms of BLEU scores) almost remains constant for samples of size 100 or more. This apparent confirmation of the efficiency of random sampling is backed up by the authors with the following possible explanations: 1) the most probable translations remain the same for different sample sizes; 2) misestimated probabilities are ruled out by the target language model; and </context>
<context position="30027" citStr="Callison-Burch et al., 2005" startWordPosition="4852" endWordPosition="4855">(e|f)p(p|e) (Bannard and Callison-Burch, 2005); • the number of occurrences of phrase f and paraphrase p are equal or less than independent thresholds: numOccs(f) &lt; 100 and numOccs(p) &lt; 1000.14 Figure 6 shows examples of paraphrases in context with high similarity with some original phrase, and Figure 7 provides various statistics on the paraphrases extracted on the test file. 4.3 Results and analysis Automatic evaluation results are reported in Table 8 for various configurations. We also wanted to focus our measures on content words, which are known 14The first threshold value was chosen as (Callison-Burch et al., 2005) report it to be an optimal sample size for estimating phrase translation probabilities. The relatively low value for the second threshold was selected to reduce computation time. phrase # phrases # paraphrased # paraphrases length en fr en fr en fr 1 13,620 15,707 458 725 1,824 2,684 2 13,120 15,207 4,127 4,481 18,871 19,700 3 12,620 14,707 4,782 5,715 24,111 27,377 4 12,120 14,208 2,859 4,078 15,071 20,345 5 11,623 13,711 1,171 2,275 6,077 12,132 Figure 7: Statistics on numbers of phrases, numbers of paraphrased phrases and numbers of paraphrases per phrase length. to be important as regards</context>
</contexts>
<marker>Callison-Burch, Bannard, Schroeder, 2005</marker>
<rawString>Chris Callison-Burch, Colin Bannard, and Josh Schroeder. 2005. Scaling Phrase-Based Statistical Machine Translation to Larger Corpora and Longer Phrases. In Proceedings of ACL, Ann Arbor, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved Statistical Machine Translation Using Paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<location>New York, USA.</location>
<contexts>
<context position="1234" citStr="Callison-Burch et al., 2006" startWordPosition="174" endWordPosition="177">ively improving translation performance. 1 Introduction Phrase translation estimation in Statistical Phrasebased Translation (Koehn et al., 2003) is hampered by the availability of both too many and too few training instances. Recent results on tera-scale SMT (Lopez, 2008) show that access to many training examples1 can lead to significant improvements in translation quality. Also, providing indirect training instances via synonyms or paraphrases for previously unseen phrases can result in gains in translation quality, which are more apparent when little training data is originally available (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010). Although there is a consensus on the importance of using more parallel data in SMT, it has never been formally shown that all additional training instances are actually useful in predicting contextually appropriate translation hypotheses. 1To be more accurate, works such as that of (Lopez, 2008) have recourse to random sampling to build models of a manageable size in a reasonable amount of time. Attempts at limiting training parallel sentences to those resembling test data through thematic adaptation (Hildebrand et al., 2005) inde</context>
<context position="4418" citStr="Callison-Burch et al., 2006" startWordPosition="668" endWordPosition="671">age allows for multiple text views on a given content, and that if two phrases are good paraphrases in context, then considering appropriate training examples of one of the phrases could provide larger quantities of training data for translating the other. In other words, we hypothesize that there may be more training data to learn a phrase’s translations in a bilingual corpus than what SMT approaches typically use. In contrast to previous attempts at using paraphrases to improve Statistical Machine Translation, which require external data in the form of additional parallel bilingual corpora (Callison-Burch et al., 2006), monolingual corpora (Marton et al., 2009), lexico-semantic resources (Mirkin et al., 2009; Aziz et al., 2010), or sub-sentential (Resnik et al., 2010) or sentential paraphrases of the input (Schroeder et al., 2009), the approach we take here can be endogenous with respect to the original training data. It also significantly departs from previous work in that paraphrasing is not simply considered as a way of finding alternative wordings that can be translated given the original training data for out-of-vocabulary phrases only (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2</context>
<context position="12029" citStr="Callison-Burch et al., 2006" startWordPosition="1877" endWordPosition="1880">e translations of the original source phrase: (Balkan War H war in the Balkans) are syntactic variants that can generally substitute with each other, (Balkan War H Balkans war) are character-level variants4. Other examples, however, clearly illustrate the need for validation in context: (Dalai Lama’s H of the Dalai Lama) require different syntactic contexts, and (I don’t see H I do not believe) are only interchangeable in specific semantic contexts. Previous attempts at exploiting paraphrases in SMT have first concentrated on obtaining translations for phrases absent from the training corpus (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009)5, with modest gains in translation performance as measured by automatic metrics. (Callison-Burch et al., 2006) obtain paraphrases by pivoting via additional bilingual corpora and use the translations of known paraphrases to translate unseen phrases, which requires that the additional bilingual corpora contain the unseen source phrases and that some of the extracted paraphrases be present in the original corpus. (Marton et al., 4To our knowledge, most implementations of SMT decoders do not integrate flexible matching of phrases. 5The work by (Mirkin e</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved Statistical Machine Translation Using Paraphrases. In Proceedings of NAACL, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Syntactic Constraints on Paraphrases Extracted from Parallel Corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Hawai, USA.</location>
<contexts>
<context position="11196" citStr="Callison-Burch, 2008" startWordPosition="1750" endWordPosition="1751">phrases Balkan War Balkan war (0.25) Balkans War (0.125) Balkans (0.125) Balkans war (0.125) war in the Balkans (0.125) Balkan conflict (0.125) British forces British troops (0.29) British armed forces (0.19) Czech president President of the Czech Republic (0.5) Dalai Lama’s of the Dalai Lama (0.27) I don’t see I do not believe (0.18) I do not think (0.18) I do not see (0.15) Figure 2: Examples of paraphrases obtained by pivoting via French; values indicate paraphrase probability as defined in (Bannard and Callison-Burch, 2005). similarity computation in the “source” (i.e. original) language (Callison-Burch, 2008; Max, 2008; Kok and Brockett, 2010). Figure 2 provides examples of English paraphrases obtained by automatically pivoting via French. As can be seen, some examples would be clearly useful to better estimate translations of the original source phrase: (Balkan War H war in the Balkans) are syntactic variants that can generally substitute with each other, (Balkan War H Balkans war) are character-level variants4. Other examples, however, clearly illustrate the need for validation in context: (Dalai Lama’s H of the Dalai Lama) require different syntactic contexts, and (I don’t see H I do not belie</context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>Chris Callison-Burch. 2008. Syntactic Constraints on Paraphrases Extracted from Parallel Corpora. In Proceedings of EMNLP, Hawai, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>ContextDependent Phrasal Translation Lexicons for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of Machine Translation</booktitle>
<location>Summit XI, Copenhagen, Denmark.</location>
<contexts>
<context position="2269" citStr="Carpuat and Wu, 2007" startWordPosition="335" endWordPosition="338">manageable size in a reasonable amount of time. Attempts at limiting training parallel sentences to those resembling test data through thematic adaptation (Hildebrand et al., 2005) indeed confirm that large quantities of training data cannot compensate for the requirement for contextually appropriate training instances. In fact, it is important that phrase translation models adequatly reflect contextual preferences for each phrase occurrence in a text. A variety of recent works have used dynamically adapted translation models, where each phrase occurrence has its own translation distribution (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Gimpel and Smith, 2008; Haque et al., 2009) derived from local contextual information in the training examples.2 These approaches are supported by the study of (Wisniewski et al., 2010) which shows that phrase-based SMT systems are expressive enough to achieve very high translation performance and therefore suggests a better scoring of phrases. The apparent tradeoff between the number of training examples and their appropriateness in each indivual context naturally asks for means of increasing the number of appropriate examples. Exploiting comparable c</context>
<context position="6731" citStr="Carpuat and Wu, 2007" startWordPosition="1039" endWordPosition="1042">. ment on our results. Finally, we discuss our future work in section 5. 2 Relation to previous work 2.1 Contextual estimation of phrase translations In standard approaches to phrase-based SMT, evidence of a translation is accumulated uniformely every time it is found associated with a source phrase in the training corpus. In addition to the fact that errors in automatic word alignment and non literal translations often produce useless biphrases, this results in rare but appropriate translations being very unlikely to be considered during decoding. Some approaches on source context modelling (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Haque et al., 2009) build classifiers offline for the phrases in a test set, so that context similarity can for example reinforce scores associated with rare but appropriate translations. However, heavy offline computation makes scaling to larger corpora an issue. Other approaches (Callison-Burch et al., 2005; Lopez, 2008) instead focus on accessing very large corpora. Indexing by suffix arrays is used to allow fast access to phrase instances in the corpus, and random sampling to avoid collecting the full set of examples has been shown to perform well.</context>
<context position="16988" citStr="Carpuat and Wu, 2007" startWordPosition="2677" endWordPosition="2680"> estimates of how appropriate a translation pair (f, ei) is, are recorded in a phrase table, which typically discards all contextual information.8 Therefore, the translation distribution of some phrase is globally estimated from a training corpus independently of the actual context of that phrase.9 On Figure 3, phrase f has at least two distinct senses: one represented by set £, which in our example corresponds to the appropriate sense for a particular occurrence of f in a test sentence; and one which corresponds to translation e5. A typical problem, due to the lack of context modeling, 8See (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Gimpel and Smith, 2008; Haque et al., 2009) for notable exceptions. 9Context is in fact taken into account to some extent by the target language model, which should score higher translations that are more appropriate given a target translation hypothesis being built. In fact, in this work we consider the target language model as the main source of information for selecting among acceptable target phrases (target language paraphrases). 659 Figure 3: Example of possible source equivalents and translations for phrase occurrence f “un bon avocat” in the se</context>
<context position="25439" citStr="Carpuat and Wu, 2007" startWordPosition="4065" endWordPosition="4068">93Mb 1.9M our systems 4.0Gb 30.2M { lengthleft + lengthright if lengthleft &gt; 0 and lengthright &gt; 0 0 otherwise Figure 5: Statistics on the size and the number of entries of the phrase tables filtered on the development set. models are added to the list of models used to evaluate the various translations of a phrase in the appropriate phrase tables, and are optimized with the other models by standard MERT. In order to model context, we modified the source texts so that each phrase becomes unique in the phrase table, i.e. it has its own translation distribution. This is done (as in other works (Carpuat and Wu, 2007; Stroppa et al., 2007)) by transforming each token into a unique token, e.g. token —* token@337. This therefore leads to a significant increase in the size of the phrase table, as illustrated on Figure 5, as all occurrences for the same phrase are not factored anymore.13 We chose a very simple initial definition of context similarity based on the presence of common n-grams in the immediate vicinity of two phrases. Let lengthleft (resp. lengthright) be the length of the longest common n-gram in the immediate vicinity on the left (resp. right) of two phrases in context (C(f) and C(fi)). For ins</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007. ContextDependent Phrasal Translation Lexicons for Statistical Machine Translation. In Proceedings of Machine Translation Summit XI, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
</authors>
<title>One Translation Per Discourse.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL-HLT Workshop on Semantic Evaluations,</booktitle>
<location>Boulder, USA.</location>
<contexts>
<context position="3168" citStr="Carpuat, 2009" startWordPosition="477" endWordPosition="478">enough to achieve very high translation performance and therefore suggests a better scoring of phrases. The apparent tradeoff between the number of training examples and their appropriateness in each indivual context naturally asks for means of increasing the number of appropriate examples. Exploiting comparable corpora for acquiring translation equivalents (Munteanu and Marcu, 2005; Abdul-Rauf and Schwenk, 2009) offers interesting prospects to this issue, but so far focus has not been so much on context appropriateness as on globally increasing the number of biphrase examples. 2The study of (Carpuat, 2009) shows that the one translation per discourse hypothesis holds in some cases, but to our knowledge no SMT systems have attempted to exploit it yet. However, in our view, this finding does not contradict the need for estimating translation distributions at the individual phrase level, but they should be integrated as additional information. 656 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 656–666, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics The approach we take in this article is motivated by the f</context>
</contexts>
<marker>Carpuat, 2009</marker>
<rawString>Marine Carpuat. 2009. One Translation Per Discourse. In Proceedings of the NAACL-HLT Workshop on Semantic Evaluations, Boulder, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinhua Du</author>
<author>Jie Jiang</author>
<author>Andy Way</author>
</authors>
<title>Facilitating Translation Using Source Language Paraphrase Lattices.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Cambridge, USA.</location>
<contexts>
<context position="5209" citStr="Du et al., 2010" startWordPosition="797" endWordPosition="800">ses of the input (Schroeder et al., 2009), the approach we take here can be endogenous with respect to the original training data. It also significantly departs from previous work in that paraphrasing is not simply considered as a way of finding alternative wordings that can be translated given the original training data for out-of-vocabulary phrases only (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010), but as a means to better estimate translations for any possible phrase. Also, as opposed to the work by (Schroeder et al., 2009; Onishi et al., 2010; Du et al., 2010), we do not encode paraphrases into input lattices to have them compete against each other to belong to the source sentential paraphrase that will lead to the highest scoring output sentence3. Instead, we make use of all contextually appropriate paraphrases of a source phrase, which collectively evaluate the quality of each translation for that phrase. This work can thus be seen as a contribution towards shifting from global phrase translation distributions to contextual translation distributions for contextually equivalent source units. The remainder of this paper is organized as followed. In</context>
<context position="14523" citStr="Du et al., 2010" startWordPosition="2272" endWordPosition="2275">he recent work of (Resnik et al., 2010) uses crowdsourcing to obtain paraphrases for source phrases corresponding to mistranslated target phrases. The spotting of the incorrect target phrases and the paraphrasing of the source phrases can be automated. Promising oracle figures are obtained, validating the claim that some variations of the input sentence might be more easily translated than others by a given system. Paraphrases have also been used to represent alternative inputs encoded in lattices using existing (Schroeder et al., 2009) or automatically built paraphrases (Onishi et al., 2010; Du et al., 2010). In this scenario, paraphrases are in fact competing with each other, whereas in our proposal paraphrases collectively participate in evaluating the quality of each translation for a source phrase. We believe that if two phrases are indeed paraphrases in context, then their respective set of translations are both relevant to translate the two phrases. The target language model nevertheless still has an important role to play to select appro6The default strategy for most decoders is to copy out-ofvocabulary tokens into the final text. 7Doing it in conjunction with our approach for improving th</context>
</contexts>
<marker>Du, Jiang, Way, 2010</marker>
<rawString>Jinhua Du, Jie Jiang, and Andy Way. 2010. Facilitating Translation Using Source Language Paraphrase Lattices. In Proceedings of EMNLP, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Noah A Smith</author>
</authors>
<title>Rich SourceSide Context for Statistical Machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL Workshop on Statistical Machine Translation,</booktitle>
<location>Columbus, USA.</location>
<contexts>
<context position="2333" citStr="Gimpel and Smith, 2008" startWordPosition="347" endWordPosition="351">miting training parallel sentences to those resembling test data through thematic adaptation (Hildebrand et al., 2005) indeed confirm that large quantities of training data cannot compensate for the requirement for contextually appropriate training instances. In fact, it is important that phrase translation models adequatly reflect contextual preferences for each phrase occurrence in a text. A variety of recent works have used dynamically adapted translation models, where each phrase occurrence has its own translation distribution (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Gimpel and Smith, 2008; Haque et al., 2009) derived from local contextual information in the training examples.2 These approaches are supported by the study of (Wisniewski et al., 2010) which shows that phrase-based SMT systems are expressive enough to achieve very high translation performance and therefore suggests a better scoring of phrases. The apparent tradeoff between the number of training examples and their appropriateness in each indivual context naturally asks for means of increasing the number of appropriate examples. Exploiting comparable corpora for acquiring translation equivalents (Munteanu and Marcu</context>
<context position="17052" citStr="Gimpel and Smith, 2008" startWordPosition="2689" endWordPosition="2692">re recorded in a phrase table, which typically discards all contextual information.8 Therefore, the translation distribution of some phrase is globally estimated from a training corpus independently of the actual context of that phrase.9 On Figure 3, phrase f has at least two distinct senses: one represented by set £, which in our example corresponds to the appropriate sense for a particular occurrence of f in a test sentence; and one which corresponds to translation e5. A typical problem, due to the lack of context modeling, 8See (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Gimpel and Smith, 2008; Haque et al., 2009) for notable exceptions. 9Context is in fact taken into account to some extent by the target language model, which should score higher translations that are more appropriate given a target translation hypothesis being built. In fact, in this work we consider the target language model as the main source of information for selecting among acceptable target phrases (target language paraphrases). 659 Figure 3: Example of possible source equivalents and translations for phrase occurrence f “un bon avocat” in the sentence “L’embauche d’un bon avocat est cruciale quelle que soit </context>
</contexts>
<marker>Gimpel, Smith, 2008</marker>
<rawString>Kevin Gimpel and Noah A. Smith. 2008. Rich SourceSide Context for Statistical Machine Translation. In Proceedings of the ACL Workshop on Statistical Machine Translation, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rejwanul Haque</author>
<author>Sudip Kumar Naskar</author>
<author>Yanjun Ma</author>
<author>Andy Way</author>
</authors>
<title>Using Supertags as Source Language Context in SMT.</title>
<date>2009</date>
<booktitle>In Proceedings of EAMT,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="2354" citStr="Haque et al., 2009" startWordPosition="352" endWordPosition="355"> sentences to those resembling test data through thematic adaptation (Hildebrand et al., 2005) indeed confirm that large quantities of training data cannot compensate for the requirement for contextually appropriate training instances. In fact, it is important that phrase translation models adequatly reflect contextual preferences for each phrase occurrence in a text. A variety of recent works have used dynamically adapted translation models, where each phrase occurrence has its own translation distribution (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Gimpel and Smith, 2008; Haque et al., 2009) derived from local contextual information in the training examples.2 These approaches are supported by the study of (Wisniewski et al., 2010) which shows that phrase-based SMT systems are expressive enough to achieve very high translation performance and therefore suggests a better scoring of phrases. The apparent tradeoff between the number of training examples and their appropriateness in each indivual context naturally asks for means of increasing the number of appropriate examples. Exploiting comparable corpora for acquiring translation equivalents (Munteanu and Marcu, 2005; Abdul-Rauf an</context>
<context position="6792" citStr="Haque et al., 2009" startWordPosition="1051" endWordPosition="1054">section 5. 2 Relation to previous work 2.1 Contextual estimation of phrase translations In standard approaches to phrase-based SMT, evidence of a translation is accumulated uniformely every time it is found associated with a source phrase in the training corpus. In addition to the fact that errors in automatic word alignment and non literal translations often produce useless biphrases, this results in rare but appropriate translations being very unlikely to be considered during decoding. Some approaches on source context modelling (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Haque et al., 2009) build classifiers offline for the phrases in a test set, so that context similarity can for example reinforce scores associated with rare but appropriate translations. However, heavy offline computation makes scaling to larger corpora an issue. Other approaches (Callison-Burch et al., 2005; Lopez, 2008) instead focus on accessing very large corpora. Indexing by suffix arrays is used to allow fast access to phrase instances in the corpus, and random sampling to avoid collecting the full set of examples has been shown to perform well. However, these approaches consider all instances of a phrase</context>
<context position="17073" citStr="Haque et al., 2009" startWordPosition="2693" endWordPosition="2696">table, which typically discards all contextual information.8 Therefore, the translation distribution of some phrase is globally estimated from a training corpus independently of the actual context of that phrase.9 On Figure 3, phrase f has at least two distinct senses: one represented by set £, which in our example corresponds to the appropriate sense for a particular occurrence of f in a test sentence; and one which corresponds to translation e5. A typical problem, due to the lack of context modeling, 8See (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Gimpel and Smith, 2008; Haque et al., 2009) for notable exceptions. 9Context is in fact taken into account to some extent by the target language model, which should score higher translations that are more appropriate given a target translation hypothesis being built. In fact, in this work we consider the target language model as the main source of information for selecting among acceptable target phrases (target language paraphrases). 659 Figure 3: Example of possible source equivalents and translations for phrase occurrence f “un bon avocat” in the sentence “L’embauche d’un bon avocat est cruciale quelle que soit l’activit6” (“Hiring </context>
</contexts>
<marker>Haque, Naskar, Ma, Way, 2009</marker>
<rawString>Rejwanul Haque, Sudip Kumar Naskar, Yanjun Ma, and Andy Way. 2009. Using Supertags as Source Language Context in SMT. In Proceedings of EAMT, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Almut Silja Hildebrand</author>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Adaptation of the Translation Model for Statistical Machine Translation Based on Information Retrieval.</title>
<date>2005</date>
<booktitle>In Proceedings of EAMT,</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="1829" citStr="Hildebrand et al., 2005" startWordPosition="270" endWordPosition="273"> (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010). Although there is a consensus on the importance of using more parallel data in SMT, it has never been formally shown that all additional training instances are actually useful in predicting contextually appropriate translation hypotheses. 1To be more accurate, works such as that of (Lopez, 2008) have recourse to random sampling to build models of a manageable size in a reasonable amount of time. Attempts at limiting training parallel sentences to those resembling test data through thematic adaptation (Hildebrand et al., 2005) indeed confirm that large quantities of training data cannot compensate for the requirement for contextually appropriate training instances. In fact, it is important that phrase translation models adequatly reflect contextual preferences for each phrase occurrence in a text. A variety of recent works have used dynamically adapted translation models, where each phrase occurrence has its own translation distribution (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Gimpel and Smith, 2008; Haque et al., 2009) derived from local contextual information in the training examples.2 These</context>
</contexts>
<marker>Hildebrand, Eck, Vogel, Waibel, 2005</marker>
<rawString>Almut Silja Hildebrand, Matthias Eck, Stephan Vogel, and Alex Waibel. 2005. Adaptation of the Translation Model for Statistical Machine Translation Based on Information Retrieval. In Proceedings of EAMT, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Kauchak</author>
<author>Regina Barzilay</author>
</authors>
<title>Paraphrasing for Automatic Evaluation.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL HLT,</booktitle>
<location>New York, USA.</location>
<contexts>
<context position="22783" citStr="Kauchak and Barzilay, 2006" startWordPosition="3619" endWordPosition="3622">l not only syntactic but also semantic and pragmatic information. 3. Robust translation evaluation: our approach is designed to reinforce estimates for any contextually-appropriate translations of a phrase, as shown by set £ on Figure 3. It is therefore important to have some means of accepting them as subparts of valid translations. Robustness in Machine Translation evaluation is an active domain, and potential candidates include using BLEU-like metrics with multiple references, Human-targeted Translation Error Rate (Snover et al., 2006) and the use of paraphrases for reference translations (Kauchak and Barzilay, 2006). train dev. test # sent. # tok. # sent. # tok. # sent. # tok. en 318K 9.1M 500 14,0K 500 13,6K fr 318K 10.3M 500 16,1K 500 15,7k Figure 4: Statistics of the corpora used. In this paper, we want to evaluate whether an endogenous approach for finding paraphrases can lead to some improvement in translation performance. Note that we will not consider in this initial work the possibility of adding new translations to phrases (such as e4 for f on Figure 3) as it adds complexity and should be investigated when the other simpler cases can be handled successfully. In the following section, we describe</context>
</contexts>
<marker>Kauchak, Barzilay, 2006</marker>
<rawString>David Kauchak and Regina Barzilay. 2006. Paraphrasing for Automatic Evaluation. In Proceedings of NAACL HLT, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL HLT,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="752" citStr="Koehn et al., 2003" startWordPosition="100" endWordPosition="103">, France aurelien.max@limsi.fr Abstract In this article, an original view on how to improve phrase translation estimates is proposed. This proposal is grounded on two main ideas: first, that appropriate examples of a given phrase should participate more in building its translation distribution; second, that paraphrases can be used to better estimate this distribution. Initial experiments provide evidence of the potential of our approach and its implementation for effectively improving translation performance. 1 Introduction Phrase translation estimation in Statistical Phrasebased Translation (Koehn et al., 2003) is hampered by the availability of both too many and too few training instances. Recent results on tera-scale SMT (Lopez, 2008) show that access to many training examples1 can lead to significant improvements in translation quality. Also, providing indirect training instances via synonyms or paraphrases for previously unseen phrases can result in gains in translation quality, which are more apparent when little training data is originally available (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010). Although there is a consensus on the importance of usi</context>
<context position="15687" citStr="Koehn et al., 2003" startWordPosition="2450" endWordPosition="2453">ng it in conjunction with our approach for improving the translation of known phrases is part of our future work. priate translations among semantically-compatible translations (i.e., target side paraphrases) in the specific context of a generated target hypothesis. Lastly, automatic sentential paraphrasing has also been used in SMT to build alternative reference translations for parameter optimization (Madnani et al., 2008) and to build alternative training corpora (Bond et al., 2008). 3 Towards better exploitation of training corpora in phrase-based SMT In typical phrase-based SMT settings (Koehn et al., 2003), words from the source side of the corpus are first aligned to words on the target side and biphrases are extracted from each training sentence using some heuristics on the word alignments. A source phrase f in a sentence being translated may therefore be aligned to a variety of target phrases. In the example on Figure 3, f is aligned some number of times in the training corpus to target phrases e1, e2, e3 and e5. Using the number of times f is paired with some target phrase ei, count(f, ei), relative frequency estimation can be used to compute the probability of translation ei given source p</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Proceedings of NAACL HLT, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Kok</author>
<author>Chris Brockett</author>
</authors>
<title>Hitting the Right Paraphrases in Good Time.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<location>Los Angeles, USA.</location>
<contexts>
<context position="11232" citStr="Kok and Brockett, 2010" startWordPosition="1754" endWordPosition="1757">25) Balkans War (0.125) Balkans (0.125) Balkans war (0.125) war in the Balkans (0.125) Balkan conflict (0.125) British forces British troops (0.29) British armed forces (0.19) Czech president President of the Czech Republic (0.5) Dalai Lama’s of the Dalai Lama (0.27) I don’t see I do not believe (0.18) I do not think (0.18) I do not see (0.15) Figure 2: Examples of paraphrases obtained by pivoting via French; values indicate paraphrase probability as defined in (Bannard and Callison-Burch, 2005). similarity computation in the “source” (i.e. original) language (Callison-Burch, 2008; Max, 2008; Kok and Brockett, 2010). Figure 2 provides examples of English paraphrases obtained by automatically pivoting via French. As can be seen, some examples would be clearly useful to better estimate translations of the original source phrase: (Balkan War H war in the Balkans) are syntactic variants that can generally substitute with each other, (Balkan War H Balkans war) are character-level variants4. Other examples, however, clearly illustrate the need for validation in context: (Dalai Lama’s H of the Dalai Lama) require different syntactic contexts, and (I don’t see H I do not believe) are only interchangeable in spec</context>
</contexts>
<marker>Kok, Brockett, 2010</marker>
<rawString>Stanley Kok and Chris Brockett. 2010. Hitting the Right Paraphrases in Good Time. In Proceedings of NAACL, Los Angeles, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
</authors>
<title>Tera-Scale Translation Models via Pattern Matching.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING,</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="880" citStr="Lopez, 2008" startWordPosition="123" endWordPosition="124">his proposal is grounded on two main ideas: first, that appropriate examples of a given phrase should participate more in building its translation distribution; second, that paraphrases can be used to better estimate this distribution. Initial experiments provide evidence of the potential of our approach and its implementation for effectively improving translation performance. 1 Introduction Phrase translation estimation in Statistical Phrasebased Translation (Koehn et al., 2003) is hampered by the availability of both too many and too few training instances. Recent results on tera-scale SMT (Lopez, 2008) show that access to many training examples1 can lead to significant improvements in translation quality. Also, providing indirect training instances via synonyms or paraphrases for previously unseen phrases can result in gains in translation quality, which are more apparent when little training data is originally available (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010). Although there is a consensus on the importance of using more parallel data in SMT, it has never been formally shown that all additional training instances are actually useful in pre</context>
<context position="7097" citStr="Lopez, 2008" startWordPosition="1098" endWordPosition="1099">word alignment and non literal translations often produce useless biphrases, this results in rare but appropriate translations being very unlikely to be considered during decoding. Some approaches on source context modelling (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Haque et al., 2009) build classifiers offline for the phrases in a test set, so that context similarity can for example reinforce scores associated with rare but appropriate translations. However, heavy offline computation makes scaling to larger corpora an issue. Other approaches (Callison-Burch et al., 2005; Lopez, 2008) instead focus on accessing very large corpora. Indexing by suffix arrays is used to allow fast access to phrase instances in the corpus, and random sampling to avoid collecting the full set of examples has been shown to perform well. However, these approaches consider all instances of a phrase as equivalent for the estimation of its translations. These works converge on the need for accessing a sufficient number of examples that are relevant for any source phrase in context, fast enough to permit on-the-fly phrase table building. This paper proposes an intermediate step: the full set of phras</context>
<context position="9437" citStr="Lopez, 2008" startWordPosition="1475" endWordPosition="1476">shows, quality (in terms of BLEU scores) almost remains constant for samples of size 100 or more. This apparent confirmation of the efficiency of random sampling is backed up by the authors with the following possible explanations: 1) the most probable translations remain the same for different sample sizes; 2) misestimated probabilities are ruled out by the target language model; and 3) longer or less frequent phrases, which are not affected by sampling, are preferred. However, as said previously, random sampling cannot guarantee that contextually-appropriate examples are selected. In fact, (Lopez, 2008) points out to using discriminatively trained models with contextual features of source phrases in conjunction with phrase sampling as an open problem. This work does not attempt to directly address it, but instead resorts to complete analysis of the training data to guarantee that all contextually-appropriate examples are considered. 2.2 Using paraphrases for translating For some phrases, not enough examples can be found in the training corpus to estimate reliable translation probabilities in context. In such cases, one might be interested in finding more appropriate examples, which seems at </context>
</contexts>
<marker>Lopez, 2008</marker>
<rawString>Adam Lopez. 2008. Tera-Scale Translation Models via Pattern Matching. In Proceedings of COLING, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Generating Phrasal &amp; Sentential Paraphrases: A Survey of DataDriven Methods.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>3</issue>
<contexts>
<context position="21962" citStr="Madnani and Dorr, 2010" startWordPosition="3497" endWordPosition="3500">nslation distribution, C(pk) the context of a particular example of pk in the training corpus, simpara a function indicating the contextual similarity between a phrase context and a paraphrase context, and ej is any possible translation of f. Several requirements can be drawn from the previous description: 1. List of potential paraphrases: some mechanism for finding potential paraphrases for source phrases is required, and several such mechanisms could be combined. Pivoting via bilingual corpora, a natural strategy given the issue at hand, is just one among many different proposed strategies (Madnani and Dorr, 2010). 2. Contextual similarity measure: a similarity measure between the contexts of two phrases or two potential local paraphrases is required. This automatic measure should ideally be able to model not only syntactic but also semantic and pragmatic information. 3. Robust translation evaluation: our approach is designed to reinforce estimates for any contextually-appropriate translations of a phrase, as shown by set £ on Figure 3. It is therefore important to have some means of accepting them as subparts of valid translations. Robustness in Machine Translation evaluation is an active domain, and </context>
</contexts>
<marker>Madnani, Dorr, 2010</marker>
<rawString>Nitin Madnani and Bonnie J. Dorr. 2010. Generating Phrasal &amp; Sentential Paraphrases: A Survey of DataDriven Methods. Computational Linguistics, 36(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Philip Resnik</author>
<author>Bonnie J Dorr</author>
<author>Richard Schwartz</author>
</authors>
<title>Are Multiple Reference Translations Necessary? Investigating the Value of Paraphrased Reference Translations in Parameter Optimization.</title>
<date>2008</date>
<booktitle>In Proceedings of AMTA,</booktitle>
<location>Waikiki, USA.</location>
<contexts>
<context position="15496" citStr="Madnani et al., 2008" startWordPosition="2420" endWordPosition="2423">s. The target language model nevertheless still has an important role to play to select appro6The default strategy for most decoders is to copy out-ofvocabulary tokens into the final text. 7Doing it in conjunction with our approach for improving the translation of known phrases is part of our future work. priate translations among semantically-compatible translations (i.e., target side paraphrases) in the specific context of a generated target hypothesis. Lastly, automatic sentential paraphrasing has also been used in SMT to build alternative reference translations for parameter optimization (Madnani et al., 2008) and to build alternative training corpora (Bond et al., 2008). 3 Towards better exploitation of training corpora in phrase-based SMT In typical phrase-based SMT settings (Koehn et al., 2003), words from the source side of the corpus are first aligned to words on the target side and biphrases are extracted from each training sentence using some heuristics on the word alignments. A source phrase f in a sentence being translated may therefore be aligned to a variety of target phrases. In the example on Figure 3, f is aligned some number of times in the training corpus to target phrases e1, e2, e</context>
</contexts>
<marker>Madnani, Resnik, Dorr, Schwartz, 2008</marker>
<rawString>Nitin Madnani, Philip Resnik, Bonnie J. Dorr, and Richard Schwartz. 2008. Are Multiple Reference Translations Necessary? Investigating the Value of Paraphrased Reference Translations in Parameter Optimization. In Proceedings of AMTA, Waikiki, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Chris Callison-Burch</author>
<author>Philip Resnik</author>
</authors>
<title>Improved Statistical Machine Translation Using Monolingually-derived Paraphrases.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<contexts>
<context position="1255" citStr="Marton et al., 2009" startWordPosition="178" endWordPosition="181">erformance. 1 Introduction Phrase translation estimation in Statistical Phrasebased Translation (Koehn et al., 2003) is hampered by the availability of both too many and too few training instances. Recent results on tera-scale SMT (Lopez, 2008) show that access to many training examples1 can lead to significant improvements in translation quality. Also, providing indirect training instances via synonyms or paraphrases for previously unseen phrases can result in gains in translation quality, which are more apparent when little training data is originally available (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010). Although there is a consensus on the importance of using more parallel data in SMT, it has never been formally shown that all additional training instances are actually useful in predicting contextually appropriate translation hypotheses. 1To be more accurate, works such as that of (Lopez, 2008) have recourse to random sampling to build models of a manageable size in a reasonable amount of time. Attempts at limiting training parallel sentences to those resembling test data through thematic adaptation (Hildebrand et al., 2005) indeed confirm that large</context>
<context position="4461" citStr="Marton et al., 2009" startWordPosition="674" endWordPosition="677">nt, and that if two phrases are good paraphrases in context, then considering appropriate training examples of one of the phrases could provide larger quantities of training data for translating the other. In other words, we hypothesize that there may be more training data to learn a phrase’s translations in a bilingual corpus than what SMT approaches typically use. In contrast to previous attempts at using paraphrases to improve Statistical Machine Translation, which require external data in the form of additional parallel bilingual corpora (Callison-Burch et al., 2006), monolingual corpora (Marton et al., 2009), lexico-semantic resources (Mirkin et al., 2009; Aziz et al., 2010), or sub-sentential (Resnik et al., 2010) or sentential paraphrases of the input (Schroeder et al., 2009), the approach we take here can be endogenous with respect to the original training data. It also significantly departs from previous work in that paraphrasing is not simply considered as a way of finding alternative wordings that can be translated given the original training data for out-of-vocabulary phrases only (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010), but as a means to </context>
<context position="12050" citStr="Marton et al., 2009" startWordPosition="1881" endWordPosition="1884">l source phrase: (Balkan War H war in the Balkans) are syntactic variants that can generally substitute with each other, (Balkan War H Balkans war) are character-level variants4. Other examples, however, clearly illustrate the need for validation in context: (Dalai Lama’s H of the Dalai Lama) require different syntactic contexts, and (I don’t see H I do not believe) are only interchangeable in specific semantic contexts. Previous attempts at exploiting paraphrases in SMT have first concentrated on obtaining translations for phrases absent from the training corpus (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009)5, with modest gains in translation performance as measured by automatic metrics. (Callison-Burch et al., 2006) obtain paraphrases by pivoting via additional bilingual corpora and use the translations of known paraphrases to translate unseen phrases, which requires that the additional bilingual corpora contain the unseen source phrases and that some of the extracted paraphrases be present in the original corpus. (Marton et al., 4To our knowledge, most implementations of SMT decoders do not integrate flexible matching of phrases. 5The work by (Mirkin et al., 2009) in fact </context>
</contexts>
<marker>Marton, Callison-Burch, Resnik, 2009</marker>
<rawString>Yuval Marton, Chris Callison-Burch, and Philip Resnik. 2009. Improved Statistical Machine Translation Using Monolingually-derived Paraphrases. In Proceedings of EMNLP, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aur´elien Max</author>
<author>Rafik Makhloufi</author>
<author>Philippe Langlais</author>
</authors>
<title>Explorations in using grammatical dependencies for contextual phrase translation disambiguation.</title>
<date>2008</date>
<booktitle>In Proceedings of EAMT,</booktitle>
<location>Hamburg, Germany.</location>
<contexts>
<context position="2309" citStr="Max et al., 2008" startWordPosition="343" endWordPosition="346">me. Attempts at limiting training parallel sentences to those resembling test data through thematic adaptation (Hildebrand et al., 2005) indeed confirm that large quantities of training data cannot compensate for the requirement for contextually appropriate training instances. In fact, it is important that phrase translation models adequatly reflect contextual preferences for each phrase occurrence in a text. A variety of recent works have used dynamically adapted translation models, where each phrase occurrence has its own translation distribution (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Gimpel and Smith, 2008; Haque et al., 2009) derived from local contextual information in the training examples.2 These approaches are supported by the study of (Wisniewski et al., 2010) which shows that phrase-based SMT systems are expressive enough to achieve very high translation performance and therefore suggests a better scoring of phrases. The apparent tradeoff between the number of training examples and their appropriateness in each indivual context naturally asks for means of increasing the number of appropriate examples. Exploiting comparable corpora for acquiring translation equival</context>
<context position="6771" citStr="Max et al., 2008" startWordPosition="1047" endWordPosition="1050">ur future work in section 5. 2 Relation to previous work 2.1 Contextual estimation of phrase translations In standard approaches to phrase-based SMT, evidence of a translation is accumulated uniformely every time it is found associated with a source phrase in the training corpus. In addition to the fact that errors in automatic word alignment and non literal translations often produce useless biphrases, this results in rare but appropriate translations being very unlikely to be considered during decoding. Some approaches on source context modelling (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Haque et al., 2009) build classifiers offline for the phrases in a test set, so that context similarity can for example reinforce scores associated with rare but appropriate translations. However, heavy offline computation makes scaling to larger corpora an issue. Other approaches (Callison-Burch et al., 2005; Lopez, 2008) instead focus on accessing very large corpora. Indexing by suffix arrays is used to allow fast access to phrase instances in the corpus, and random sampling to avoid collecting the full set of examples has been shown to perform well. However, these approaches consider all </context>
<context position="17028" citStr="Max et al., 2008" startWordPosition="2685" endWordPosition="2688">pair (f, ei) is, are recorded in a phrase table, which typically discards all contextual information.8 Therefore, the translation distribution of some phrase is globally estimated from a training corpus independently of the actual context of that phrase.9 On Figure 3, phrase f has at least two distinct senses: one represented by set £, which in our example corresponds to the appropriate sense for a particular occurrence of f in a test sentence; and one which corresponds to translation e5. A typical problem, due to the lack of context modeling, 8See (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Gimpel and Smith, 2008; Haque et al., 2009) for notable exceptions. 9Context is in fact taken into account to some extent by the target language model, which should score higher translations that are more appropriate given a target translation hypothesis being built. In fact, in this work we consider the target language model as the main source of information for selecting among acceptable target phrases (target language paraphrases). 659 Figure 3: Example of possible source equivalents and translations for phrase occurrence f “un bon avocat” in the sentence “L’embauche d’un bon avocat est c</context>
</contexts>
<marker>Max, Makhloufi, Langlais, 2008</marker>
<rawString>Aur´elien Max, Rafik Makhloufi, and Philippe Langlais. 2008. Explorations in using grammatical dependencies for contextual phrase translation disambiguation. In Proceedings of EAMT, Hamburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aur´elien Max</author>
<author>Josep M Crego</author>
<author>Franc¸ois Yvon</author>
</authors>
<title>Contrastive Lexical Evaluation of Machine Translation.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Valletta,</location>
<contexts>
<context position="30759" citStr="Max et al., 2010" startWordPosition="4970" endWordPosition="4973">or the second threshold was selected to reduce computation time. phrase # phrases # paraphrased # paraphrases length en fr en fr en fr 1 13,620 15,707 458 725 1,824 2,684 2 13,120 15,207 4,127 4,481 18,871 19,700 3 12,620 14,707 4,782 5,715 24,111 27,377 4 12,120 14,208 2,859 4,078 15,071 20,345 5 11,623 13,711 1,171 2,275 6,077 12,132 Figure 7: Statistics on numbers of phrases, numbers of paraphrased phrases and numbers of paraphrases per phrase length. to be important as regards information content in translation. We applied the contrastive lexical evaluation (CLE) methodology described in (Max et al., 2010), which indicates how many times source words grouped into user-defined classes were correctly translated or not across systems. These additional results are reported on Figure 9. On English to French translation, both additional features lead to improvements over the baseline with all metrics, including CLE, and their combination shows a strong improvement in TER (-1.55). CLE on content words reveals that the para feature seems particularly effective in reducing the number of words in all categories that only the baseline system translated correctly. Results on French to English translation a</context>
</contexts>
<marker>Max, Crego, Yvon, 2010</marker>
<rawString>Aur´elien Max, Josep M. Crego, and Franc¸ois Yvon. 2010. Contrastive Lexical Evaluation of Machine Translation. In Proceedings of LREC, Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aur´elien Max</author>
</authors>
<title>Local rephrasing suggestions for supporting the work of writers.</title>
<date>2008</date>
<booktitle>In Proceedings of GoTAL,</booktitle>
<location>Gothenburg,</location>
<contexts>
<context position="11207" citStr="Max, 2008" startWordPosition="1752" endWordPosition="1753">kan war (0.25) Balkans War (0.125) Balkans (0.125) Balkans war (0.125) war in the Balkans (0.125) Balkan conflict (0.125) British forces British troops (0.29) British armed forces (0.19) Czech president President of the Czech Republic (0.5) Dalai Lama’s of the Dalai Lama (0.27) I don’t see I do not believe (0.18) I do not think (0.18) I do not see (0.15) Figure 2: Examples of paraphrases obtained by pivoting via French; values indicate paraphrase probability as defined in (Bannard and Callison-Burch, 2005). similarity computation in the “source” (i.e. original) language (Callison-Burch, 2008; Max, 2008; Kok and Brockett, 2010). Figure 2 provides examples of English paraphrases obtained by automatically pivoting via French. As can be seen, some examples would be clearly useful to better estimate translations of the original source phrase: (Balkan War H war in the Balkans) are syntactic variants that can generally substitute with each other, (Balkan War H Balkans war) are character-level variants4. Other examples, however, clearly illustrate the need for validation in context: (Dalai Lama’s H of the Dalai Lama) require different syntactic contexts, and (I don’t see H I do not believe) are onl</context>
</contexts>
<marker>Max, 2008</marker>
<rawString>Aur´elien Max. 2008. Local rephrasing suggestions for supporting the work of writers. In Proceedings of GoTAL, Gothenburg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shachar Mirkin</author>
<author>Lucia Specia</author>
<author>Nicola Cancedda</author>
<author>Ido Dagan</author>
<author>Marc Dymetman</author>
<author>Idan Szpektor</author>
</authors>
<title>Source-Language Entailment Modeling for Translating Unknown Terms.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL,</booktitle>
<contexts>
<context position="1276" citStr="Mirkin et al., 2009" startWordPosition="182" endWordPosition="185">ction Phrase translation estimation in Statistical Phrasebased Translation (Koehn et al., 2003) is hampered by the availability of both too many and too few training instances. Recent results on tera-scale SMT (Lopez, 2008) show that access to many training examples1 can lead to significant improvements in translation quality. Also, providing indirect training instances via synonyms or paraphrases for previously unseen phrases can result in gains in translation quality, which are more apparent when little training data is originally available (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010). Although there is a consensus on the importance of using more parallel data in SMT, it has never been formally shown that all additional training instances are actually useful in predicting contextually appropriate translation hypotheses. 1To be more accurate, works such as that of (Lopez, 2008) have recourse to random sampling to build models of a manageable size in a reasonable amount of time. Attempts at limiting training parallel sentences to those resembling test data through thematic adaptation (Hildebrand et al., 2005) indeed confirm that large quantities of traini</context>
<context position="4509" citStr="Mirkin et al., 2009" startWordPosition="680" endWordPosition="683">in context, then considering appropriate training examples of one of the phrases could provide larger quantities of training data for translating the other. In other words, we hypothesize that there may be more training data to learn a phrase’s translations in a bilingual corpus than what SMT approaches typically use. In contrast to previous attempts at using paraphrases to improve Statistical Machine Translation, which require external data in the form of additional parallel bilingual corpora (Callison-Burch et al., 2006), monolingual corpora (Marton et al., 2009), lexico-semantic resources (Mirkin et al., 2009; Aziz et al., 2010), or sub-sentential (Resnik et al., 2010) or sentential paraphrases of the input (Schroeder et al., 2009), the approach we take here can be endogenous with respect to the original training data. It also significantly departs from previous work in that paraphrasing is not simply considered as a way of finding alternative wordings that can be translated given the original training data for out-of-vocabulary phrases only (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010), but as a means to better estimate translations for any possible ph</context>
<context position="12072" citStr="Mirkin et al., 2009" startWordPosition="1885" endWordPosition="1888">kan War H war in the Balkans) are syntactic variants that can generally substitute with each other, (Balkan War H Balkans war) are character-level variants4. Other examples, however, clearly illustrate the need for validation in context: (Dalai Lama’s H of the Dalai Lama) require different syntactic contexts, and (I don’t see H I do not believe) are only interchangeable in specific semantic contexts. Previous attempts at exploiting paraphrases in SMT have first concentrated on obtaining translations for phrases absent from the training corpus (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009)5, with modest gains in translation performance as measured by automatic metrics. (Callison-Burch et al., 2006) obtain paraphrases by pivoting via additional bilingual corpora and use the translations of known paraphrases to translate unseen phrases, which requires that the additional bilingual corpora contain the unseen source phrases and that some of the extracted paraphrases be present in the original corpus. (Marton et al., 4To our knowledge, most implementations of SMT decoders do not integrate flexible matching of phrases. 5The work by (Mirkin et al., 2009) in fact considers both paraphr</context>
<context position="13379" citStr="Mirkin et al., 2009" startWordPosition="2089" endWordPosition="2092">proceed similarly but obtain their paraphrases from comparatively much larger monolingual corpora by following the distributionality hypothesis. In both cases, gains are only obtained in very specific conditions where very few training data are available and where useful additional knowledge can be brought in from external resources. Furthermore, the described implementations do not consider acceptability of the paraphrases in context, as their underlying hypothesis is that it might be more desirable to translate some paraphrase than not to translate a given phrase.6 In contrast, the work by (Mirkin et al., 2009) attempts to model context when using replacements for words (synonyms or hypernyms). The natural next step that we take here is to exploit the complementarity of the original bilingual training corpus for finding paraphrases and the monolingual (source) side of the same corpus for validating them in context. Furthermore, our focus here is not on paraphrasing unseen phrases7, but possibly any phrase, or any phrase seen less than a given number of times, or any types of difficult-totranslate phrases (Mohit and Hwa, 2007). The recent work of (Resnik et al., 2010) uses crowdsourcing to obtain par</context>
</contexts>
<marker>Mirkin, Specia, Cancedda, Dagan, Dymetman, Szpektor, 2009</marker>
<rawString>Shachar Mirkin, Lucia Specia, Nicola Cancedda, Ido Dagan, Marc Dymetman, and Idan Szpektor. 2009. Source-Language Entailment Modeling for Translating Unknown Terms. In Proceedings of ACL, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Behrang Mohit</author>
<author>Rebecca Hwa</author>
</authors>
<title>Localization of Difficult-to-Translate Phrases.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL Workshop on Statistical Machine Translation,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="13904" citStr="Mohit and Hwa, 2007" startWordPosition="2175" endWordPosition="2178">araphrase than not to translate a given phrase.6 In contrast, the work by (Mirkin et al., 2009) attempts to model context when using replacements for words (synonyms or hypernyms). The natural next step that we take here is to exploit the complementarity of the original bilingual training corpus for finding paraphrases and the monolingual (source) side of the same corpus for validating them in context. Furthermore, our focus here is not on paraphrasing unseen phrases7, but possibly any phrase, or any phrase seen less than a given number of times, or any types of difficult-totranslate phrases (Mohit and Hwa, 2007). The recent work of (Resnik et al., 2010) uses crowdsourcing to obtain paraphrases for source phrases corresponding to mistranslated target phrases. The spotting of the incorrect target phrases and the paraphrasing of the source phrases can be automated. Promising oracle figures are obtained, validating the claim that some variations of the input sentence might be more easily translated than others by a given system. Paraphrases have also been used to represent alternative inputs encoded in lattices using existing (Schroeder et al., 2009) or automatically built paraphrases (Onishi et al., 201</context>
</contexts>
<marker>Mohit, Hwa, 2007</marker>
<rawString>Behrang Mohit and Rebecca Hwa. 2007. Localization of Difficult-to-Translate Phrases. In Proceedings of the ACL Workshop on Statistical Machine Translation, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Stefan Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Improving Machine Translation Performance by Exploiting Non-parallel Corpora.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>4</issue>
<contexts>
<context position="2939" citStr="Munteanu and Marcu, 2005" startWordPosition="438" endWordPosition="441">el and Smith, 2008; Haque et al., 2009) derived from local contextual information in the training examples.2 These approaches are supported by the study of (Wisniewski et al., 2010) which shows that phrase-based SMT systems are expressive enough to achieve very high translation performance and therefore suggests a better scoring of phrases. The apparent tradeoff between the number of training examples and their appropriateness in each indivual context naturally asks for means of increasing the number of appropriate examples. Exploiting comparable corpora for acquiring translation equivalents (Munteanu and Marcu, 2005; Abdul-Rauf and Schwenk, 2009) offers interesting prospects to this issue, but so far focus has not been so much on context appropriateness as on globally increasing the number of biphrase examples. 2The study of (Carpuat, 2009) shows that the one translation per discourse hypothesis holds in some cases, but to our knowledge no SMT systems have attempted to exploit it yet. However, in our view, this finding does not contradict the need for estimating translation distributions at the individual phrase level, but they should be integrated as additional information. 656 Proceedings of the 2010 C</context>
</contexts>
<marker>Munteanu, Marcu, 2005</marker>
<rawString>Dragos Stefan Munteanu and Daniel Marcu. 2005. Improving Machine Translation Performance by Exploiting Non-parallel Corpora. Computational Linguistics, 31(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takashi Onishi</author>
<author>Masao Utiyama</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Paraphrase Lattice for Statistical Machine Translation.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL, short paper session,</booktitle>
<location>Uppsala,</location>
<contexts>
<context position="5191" citStr="Onishi et al., 2010" startWordPosition="793" endWordPosition="796">r sentential paraphrases of the input (Schroeder et al., 2009), the approach we take here can be endogenous with respect to the original training data. It also significantly departs from previous work in that paraphrasing is not simply considered as a way of finding alternative wordings that can be translated given the original training data for out-of-vocabulary phrases only (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010), but as a means to better estimate translations for any possible phrase. Also, as opposed to the work by (Schroeder et al., 2009; Onishi et al., 2010; Du et al., 2010), we do not encode paraphrases into input lattices to have them compete against each other to belong to the source sentential paraphrase that will lead to the highest scoring output sentence3. Instead, we make use of all contextually appropriate paraphrases of a source phrase, which collectively evaluate the quality of each translation for that phrase. This work can thus be seen as a contribution towards shifting from global phrase translation distributions to contextual translation distributions for contextually equivalent source units. The remainder of this paper is organiz</context>
<context position="14505" citStr="Onishi et al., 2010" startWordPosition="2268" endWordPosition="2271">hit and Hwa, 2007). The recent work of (Resnik et al., 2010) uses crowdsourcing to obtain paraphrases for source phrases corresponding to mistranslated target phrases. The spotting of the incorrect target phrases and the paraphrasing of the source phrases can be automated. Promising oracle figures are obtained, validating the claim that some variations of the input sentence might be more easily translated than others by a given system. Paraphrases have also been used to represent alternative inputs encoded in lattices using existing (Schroeder et al., 2009) or automatically built paraphrases (Onishi et al., 2010; Du et al., 2010). In this scenario, paraphrases are in fact competing with each other, whereas in our proposal paraphrases collectively participate in evaluating the quality of each translation for a source phrase. We believe that if two phrases are indeed paraphrases in context, then their respective set of translations are both relevant to translate the two phrases. The target language model nevertheless still has an important role to play to select appro6The default strategy for most decoders is to copy out-ofvocabulary tokens into the final text. 7Doing it in conjunction with our approac</context>
</contexts>
<marker>Onishi, Utiyama, Sumita, 2010</marker>
<rawString>Takashi Onishi, Masao Utiyama, and Eiichiro Sumita. 2010. Paraphrase Lattice for Statistical Machine Translation. In Proceedings of ACL, short paper session, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Olivia Buzek</author>
<author>Chang Hu</author>
<author>Yakov Kronrod</author>
<author>Alex Quinn</author>
<author>Benjamin B Bederson</author>
</authors>
<title>Improving Translation via Targeted Paraphrasing.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Cambridge, USA.</location>
<contexts>
<context position="4570" citStr="Resnik et al., 2010" startWordPosition="690" endWordPosition="693">f one of the phrases could provide larger quantities of training data for translating the other. In other words, we hypothesize that there may be more training data to learn a phrase’s translations in a bilingual corpus than what SMT approaches typically use. In contrast to previous attempts at using paraphrases to improve Statistical Machine Translation, which require external data in the form of additional parallel bilingual corpora (Callison-Burch et al., 2006), monolingual corpora (Marton et al., 2009), lexico-semantic resources (Mirkin et al., 2009; Aziz et al., 2010), or sub-sentential (Resnik et al., 2010) or sentential paraphrases of the input (Schroeder et al., 2009), the approach we take here can be endogenous with respect to the original training data. It also significantly departs from previous work in that paraphrasing is not simply considered as a way of finding alternative wordings that can be translated given the original training data for out-of-vocabulary phrases only (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010), but as a means to better estimate translations for any possible phrase. Also, as opposed to the work by (Schroeder et al., 2009</context>
<context position="13946" citStr="Resnik et al., 2010" startWordPosition="2183" endWordPosition="2186">rase.6 In contrast, the work by (Mirkin et al., 2009) attempts to model context when using replacements for words (synonyms or hypernyms). The natural next step that we take here is to exploit the complementarity of the original bilingual training corpus for finding paraphrases and the monolingual (source) side of the same corpus for validating them in context. Furthermore, our focus here is not on paraphrasing unseen phrases7, but possibly any phrase, or any phrase seen less than a given number of times, or any types of difficult-totranslate phrases (Mohit and Hwa, 2007). The recent work of (Resnik et al., 2010) uses crowdsourcing to obtain paraphrases for source phrases corresponding to mistranslated target phrases. The spotting of the incorrect target phrases and the paraphrasing of the source phrases can be automated. Promising oracle figures are obtained, validating the claim that some variations of the input sentence might be more easily translated than others by a given system. Paraphrases have also been used to represent alternative inputs encoded in lattices using existing (Schroeder et al., 2009) or automatically built paraphrases (Onishi et al., 2010; Du et al., 2010). In this scenario, par</context>
<context position="35606" citStr="Resnik et al., 2010" startWordPosition="5803" endWordPosition="5806"> 37 118 97 302 +42 inf - 58 20 108 56 242 + 65 43 147 103 358 +116 fr→en +cont - 30 16 80 69 195 + 15 21 69 46 151 -44 - 32 19 72 60 183 +para + 12 18 65 43 138 -45 all - 21 18 67 61 167 + 30 18 94 48 190 +23 inf - 38 21 83 66 208 + 31 23 106 57 217 +9 Figure 9: Contrastive lexical evaluation results per partof-speech measured on the test file. ’-’ (resp. ’+’) rows indicate the number of source words that only bsl (resp. the compared system) correctly translated. proved, which is in line with works that make use of human-made paraphrases to improve translation quality (Schroeder et al., 2009; Resnik et al., 2010). Table 10 presents a typology of paraphrases found in our development set and classifies the impact of using them for phrase translation estimation. As can be seen, more work is needed to better understand the characteristics of the phrases that should be paraphrased and of their paraphrases. 664 Type Impact Examples Morphological variants +/- (yugoslav republic ↔ yugoslavian republic), (go far ↔ goes far) Synonymy + (duties ↔ obligations), (to look into ↔ to study) Grammatical word substitution ?/- (states in the ↔ the states of the), (amendments by ↔ amendments to) Word deletion or insertio</context>
</contexts>
<marker>Resnik, Buzek, Hu, Kronrod, Quinn, Bederson, 2010</marker>
<rawString>Philip Resnik, Olivia Buzek, Chang Hu, Yakov Kronrod, Alex Quinn, and Benjamin B. Bederson. 2010. Improving Translation via Targeted Paraphrasing. In Proceedings of EMNLP, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josh Schroeder</author>
<author>Trevor Cohn</author>
<author>Philipp Koehn</author>
</authors>
<title>Word Lattices for Multi-Source Translation.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL,</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="4634" citStr="Schroeder et al., 2009" startWordPosition="700" endWordPosition="703">ing data for translating the other. In other words, we hypothesize that there may be more training data to learn a phrase’s translations in a bilingual corpus than what SMT approaches typically use. In contrast to previous attempts at using paraphrases to improve Statistical Machine Translation, which require external data in the form of additional parallel bilingual corpora (Callison-Burch et al., 2006), monolingual corpora (Marton et al., 2009), lexico-semantic resources (Mirkin et al., 2009; Aziz et al., 2010), or sub-sentential (Resnik et al., 2010) or sentential paraphrases of the input (Schroeder et al., 2009), the approach we take here can be endogenous with respect to the original training data. It also significantly departs from previous work in that paraphrasing is not simply considered as a way of finding alternative wordings that can be translated given the original training data for out-of-vocabulary phrases only (Callison-Burch et al., 2006; Marton et al., 2009; Mirkin et al., 2009; Aziz et al., 2010), but as a means to better estimate translations for any possible phrase. Also, as opposed to the work by (Schroeder et al., 2009; Onishi et al., 2010; Du et al., 2010), we do not encode paraph</context>
<context position="14449" citStr="Schroeder et al., 2009" startWordPosition="2259" endWordPosition="2262"> of times, or any types of difficult-totranslate phrases (Mohit and Hwa, 2007). The recent work of (Resnik et al., 2010) uses crowdsourcing to obtain paraphrases for source phrases corresponding to mistranslated target phrases. The spotting of the incorrect target phrases and the paraphrasing of the source phrases can be automated. Promising oracle figures are obtained, validating the claim that some variations of the input sentence might be more easily translated than others by a given system. Paraphrases have also been used to represent alternative inputs encoded in lattices using existing (Schroeder et al., 2009) or automatically built paraphrases (Onishi et al., 2010; Du et al., 2010). In this scenario, paraphrases are in fact competing with each other, whereas in our proposal paraphrases collectively participate in evaluating the quality of each translation for a source phrase. We believe that if two phrases are indeed paraphrases in context, then their respective set of translations are both relevant to translate the two phrases. The target language model nevertheless still has an important role to play to select appro6The default strategy for most decoders is to copy out-ofvocabulary tokens into t</context>
<context position="35584" citStr="Schroeder et al., 2009" startWordPosition="5799" endWordPosition="5802">l - 72 25 91 72 260 + 50 37 118 97 302 +42 inf - 58 20 108 56 242 + 65 43 147 103 358 +116 fr→en +cont - 30 16 80 69 195 + 15 21 69 46 151 -44 - 32 19 72 60 183 +para + 12 18 65 43 138 -45 all - 21 18 67 61 167 + 30 18 94 48 190 +23 inf - 38 21 83 66 208 + 31 23 106 57 217 +9 Figure 9: Contrastive lexical evaluation results per partof-speech measured on the test file. ’-’ (resp. ’+’) rows indicate the number of source words that only bsl (resp. the compared system) correctly translated. proved, which is in line with works that make use of human-made paraphrases to improve translation quality (Schroeder et al., 2009; Resnik et al., 2010). Table 10 presents a typology of paraphrases found in our development set and classifies the impact of using them for phrase translation estimation. As can be seen, more work is needed to better understand the characteristics of the phrases that should be paraphrased and of their paraphrases. 664 Type Impact Examples Morphological variants +/- (yugoslav republic ↔ yugoslavian republic), (go far ↔ goes far) Synonymy + (duties ↔ obligations), (to look into ↔ to study) Grammatical word substitution ?/- (states in the ↔ the states of the), (amendments by ↔ amendments to) Wor</context>
</contexts>
<marker>Schroeder, Cohn, Koehn, 2009</marker>
<rawString>Josh Schroeder, Trevor Cohn, and Philipp Koehn. 2009. Word Lattices for Multi-Source Translation. In Proceedings of EACL, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie J Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A Study of Translation Edit Rate with Targeted Human Annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of AMTA,</booktitle>
<location>Boston, USA.</location>
<contexts>
<context position="22700" citStr="Snover et al., 2006" startWordPosition="3606" endWordPosition="3609">raphrases is required. This automatic measure should ideally be able to model not only syntactic but also semantic and pragmatic information. 3. Robust translation evaluation: our approach is designed to reinforce estimates for any contextually-appropriate translations of a phrase, as shown by set £ on Figure 3. It is therefore important to have some means of accepting them as subparts of valid translations. Robustness in Machine Translation evaluation is an active domain, and potential candidates include using BLEU-like metrics with multiple references, Human-targeted Translation Error Rate (Snover et al., 2006) and the use of paraphrases for reference translations (Kauchak and Barzilay, 2006). train dev. test # sent. # tok. # sent. # tok. # sent. # tok. en 318K 9.1M 500 14,0K 500 13,6K fr 318K 10.3M 500 16,1K 500 15,7k Figure 4: Statistics of the corpora used. In this paper, we want to evaluate whether an endogenous approach for finding paraphrases can lead to some improvement in translation performance. Note that we will not consider in this initial work the possibility of adding new translations to phrases (such as e4 for f on Figure 3) as it adds complexity and should be investigated when the oth</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie J. Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of AMTA, Boston, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolas Stroppa</author>
<author>Antal van den Bosch</author>
<author>Andy Way</author>
</authors>
<title>Exploiting Source Similarity for SMT using Context-Informed Features.</title>
<date>2007</date>
<booktitle>In Proceedings of TMI, Skovde,</booktitle>
<marker>Stroppa, van den Bosch, Way, 2007</marker>
<rawString>Nicolas Stroppa, Antal van den Bosch, and Andy Way. 2007. Exploiting Source Similarity for SMT using Context-Informed Features. In Proceedings of TMI, Skovde, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guillaume Wisniewski</author>
<author>Alexandre Allauzen</author>
<author>Franc¸ois Yvon</author>
</authors>
<title>Assessing Phrase-based Translation Models with Oracle Decoding.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Cambridge, USA.</location>
<contexts>
<context position="2496" citStr="Wisniewski et al., 2010" startWordPosition="374" endWordPosition="377">aining data cannot compensate for the requirement for contextually appropriate training instances. In fact, it is important that phrase translation models adequatly reflect contextual preferences for each phrase occurrence in a text. A variety of recent works have used dynamically adapted translation models, where each phrase occurrence has its own translation distribution (Carpuat and Wu, 2007; Stroppa et al., 2007; Max et al., 2008; Gimpel and Smith, 2008; Haque et al., 2009) derived from local contextual information in the training examples.2 These approaches are supported by the study of (Wisniewski et al., 2010) which shows that phrase-based SMT systems are expressive enough to achieve very high translation performance and therefore suggests a better scoring of phrases. The apparent tradeoff between the number of training examples and their appropriateness in each indivual context naturally asks for means of increasing the number of appropriate examples. Exploiting comparable corpora for acquiring translation equivalents (Munteanu and Marcu, 2005; Abdul-Rauf and Schwenk, 2009) offers interesting prospects to this issue, but so far focus has not been so much on context appropriateness as on globally i</context>
</contexts>
<marker>Wisniewski, Allauzen, Yvon, 2010</marker>
<rawString>Guillaume Wisniewski, Alexandre Allauzen, and Franc¸ois Yvon. 2010. Assessing Phrase-based Translation Models with Oracle Decoding. In Proceedings of EMNLP, Cambridge, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>