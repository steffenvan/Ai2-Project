<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002524">
<title confidence="0.990279">
EdIt: A Broad-Coverage Grammar Checker Using Pattern Grammar
</title>
<author confidence="0.998208">
Chung-Chi Huang Mei-Hua Chen Shih-Ting Huang Jason S. Chang
</author>
<affiliation confidence="0.998711">
Institute of Information Systems and Department of Computer Science,
</affiliation>
<address confidence="0.740303">
Applications, National Tsing Hua University, National Tsing Hua University,
HsinChu, Taiwan, R.O.C. 300 HsinChu, Taiwan, R.O.C. 300
</address>
<email confidence="0.99947">
{u901571,chen.meihua,koromiko1104,Jason.jschang}@gmail.com
</email>
<sectionHeader confidence="0.995646" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999525">
We introduce a new method for learning to
detect grammatical errors in learner’s writ-
ing and provide suggestions. The method
involves parsing a reference corpus and
inferring grammar patterns in the form of a
sequence of content words, function words,
and parts-of-speech (e.g., “play ~ role in
Ving” and “look forward to Ving”). At run-
time, the given passage submitted by the
learner is matched using an extended
Levenshtein algorithm against the set of
pattern rules in order to detect errors and
provide suggestions. We present a proto-
type implementation of the proposed
method, EdIt, that can handle a broad range
of errors. Promising results are illustrated
with three common types of errors in non-
native writing.
</bodyText>
<sectionHeader confidence="0.999335" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999949813953488">
Recently, an increasing number of research has
targeted language learners’ need in editorial assis-
tance including detecting and correcting grammar
and usage errors in texts written in a second lan-
guage. For example, Microsoft Research has de-
veloped the ESL Assistant, which provides such a
service to ESL and EFL learners.
Much of the research in this area depends on
hand-crafted rules and focuses on certain error
types. Very little research provides a general
framework for detecting and correcting all types of
errors. However, in the sentences of ESL writing,
there may be more than one errors and one error
may affect the performance of handling other er-
rors. Erroneous sentences could be more efficiently
identified and corrected if a grammar checker han-
dles all errors at once, using a set of pattern rules
that reflect the predominant usage of the English
language.
Consider the sentences, “He play an important
roles to close this deals.” and “He looks forward to
hear you.” The first sentence contains inaccurate
word forms (i.e., play, roles, and deals), and rare
usage (i.e., “role to close”), while the second sen-
tence use the incorrect verb form of “hear”. Good
responses to these writing errors might be (a) Use
“played” instead of “play.” (b) Use “role” instead
of “roles”, (c) Use “in closing” instead of “to
close” (d) Use “to hearing” instead of “to hear”,
and (e) insert “from” between “hear” and “you.”
These suggestions can be offered by learning the
patterns rules related to “play — role” and “look
forward” based on analysis of ngrams and collo-
cations in a very large-scale reference corpus. With
corpus statistics, we could learn the needed phra-
seological tendency in the form of pattern rules
such as “play — role in V-ing) and “look forward
to V-ing.” The use of such pattern rules is in line
with the recent theory of Pattern Grammar put
forward by Hunston and Francis (2000).
We present a system, EdIt, that automatically
learns to provide suggestions for rare/wrong usages
in non-native writing. Example EdIt responses to a
</bodyText>
<page confidence="0.992247">
26
</page>
<bodyText confidence="0.9981562">
text are shown in Figure 1. EdIt has retrieved the
related pattern grammar of some ngram and collo-
cation sequences given the input (e.g., “play — role
in V-ing1”, and “look forward to V-ing”). EdIt
learns these patterns during pattern extraction
process by syntactically analyzing a collection of
well-formed, published texts.
At run-time, EdIt first processes the input pas-
sages in the article (e.g., “He play an important
roles to close ”) submitted by the L2 learner. And
EdIt tag the passage with part of speech informa-
tion, and compares the tagged sentence against the
pattern rules anchored at certain collocations (e.g.,
“play — role” and “look forward”). Finally, EdIt
finds the minimum-edit-cost patterns matching the
passages using an extended Levenshtein’s algo-
rithm (Levenshtein, 1966). The system then high-
lights the edits and displays the pattern rules as
suggestions for correction. In our prototype, EdIt
returns the preferred word form and preposition
usages to the user directly (see Figure 1); alterna-
tively, the actual surface words (e.g., “closing” and
“deal”) could be provided.
Input: He play an important roles to close this
deals. He looks forward to hear you.
</bodyText>
<subsectionHeader confidence="0.853527">
Suggestion:
</subsectionHeader>
<bodyText confidence="0.9876815">
He played an important role in closing this deal. He looks
forward to hearing from you.
</bodyText>
<figureCaption confidence="0.974447">
Figure 1. Example responses to the non-native writing.
</figureCaption>
<sectionHeader confidence="0.999529" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999913653846154">
Grammar checking has been an area of active re-
search. Many methods, rule-oriented or data-
driven, have been proposed to tackle the problem
of detecting and correcting incorrect grammatical
and usage errors in learner texts. It is at times no
easy to distinguish these errors. But Fraser and
Hodson (1978) shows the distinction between these
two kinds of errors.
For some specific error types (e.g., article and
preposition error), a number of interesting rule-
based systems have been proposed. For example,
Uria et al. (2009) and Lee et al. (2009) leverage
heuristic rules for detecting Basque determiner and
Korean particle errors, respectively. Gamon et al.
(2009) bases some of the modules in ESL Assistant
on rules derived from manually inspecting learner
data. Our pattern rules, however, are automatically
derived from readily available well-formed data,
but nevertheless very helpful for correcting errors
in non-native writing.
More recently, statistical approaches to develop-
ing grammar checkers have prevailed. Among un-
supervised checkers, Chodorow and Leacock
(2000) exploits negative evidence from edited tex-
tual corpora achieving high precision but low re-
call, while Tsao and Wible (2009) uses general
corpus only. Additionally, Hermet et al. (2008) and
Gamon and Leacock (2010) both use Web as a
corpus to detect errors in non-native writing. On
the other hand, supervised models, typically treat-
ing error detection/correction as a classification
problem, may train on well-formed texts as in the
methods by De Felice and Pulman (2008) and Te-
treault et al. (2010), or with additional learner texts
as in the method proposed by Brockett et al.
(2006). Sun et al. (2007) describes a method for
constructing a supervised detection system trained
on raw well-formed and learner texts without error
annotation.
Recent work has been done on incorporating
word class information into grammar checkers. For
example, Chodorow and Leacock (2000) exploit
bigrams and trigrams of function words and part-
of-speech (PoS) tags, while Sun et al. (2007) use
labeled sequential patterns of function, time ex-
pression, and part-of-speech tags. In an approach
similar to our work, Tsao and Wible (2009) use a
combined ngrams of words forms, lemmas, and
part-of-speech tags for research into constructional
phenomena. The main differences are that we an-
chored each pattern rule in lexical collocation so
as to avoid deriving rules that is may have two
</bodyText>
<figureCaption confidence="0.667617857142857">
Related pattern rules
play — role in Noun
play — role in V-ing
he plays DET
he played DET
look forward to V-ing
hear from PRON ...
</figureCaption>
<bodyText confidence="0.710589">
1 In the pattern rules, we translate the part-of-speech tag to labels that are commonly used in learner dictionaries. For
instance, we use V-ing for the tag VBG denoting the progressive verb form, and Pron and Pron$ denotes a pronoun
and a possessive pronoun respectively.
</bodyText>
<page confidence="0.990684">
27
</page>
<bodyText confidence="0.999903909090909">
consecutive part-of-speech tags (e.g, “V Pron$
socks offÓ). The pattern rules we have derived are
more specific and can be effectively used in detect-
ing and correcting errors.
In contrast to the previous research, we intro-
duce a broad-coverage grammar checker that ac-
commodates edits such as substitution, insertion
and deletion, as well as replacing word forms or
prepositions using pattern rules automatically de-
rived from very large-scale corpora of well-formed
texts.
</bodyText>
<sectionHeader confidence="0.956192" genericHeader="method">
3 The EdIt System
</sectionHeader>
<bodyText confidence="0.999913545454545">
Using supervised training on a learner corpus is not
very feasible due to the limited availability of
large-scale annotated non-native writing. Existing
systems trained on learner data tend to offer high
precision but low recall. Broad coverage grammar
checkers may be developed using readily available
large-scale corpora. To detect and correct errors in
non-native writing, a promising approach is to
automatically extract lexico-syntactical pattern
rules that are expected to distinguish correct and in
correct sentences.
</bodyText>
<subsectionHeader confidence="0.999592">
3.1 Problem Statement
</subsectionHeader>
<bodyText confidence="0.804946214285714">
We focus on correcting grammatical and usage
errors by exploiting pattern rules of specific collo-
cation (elastic or rigid such as “play — rule” or
“look forward”). For simplification, we assume
that there is no spelling errors. EdIt provides sug-
gestions to common writing errors2 of the follow-
ing correlated with essay scores3.
(1) wrong word form
(A) singular determiner preceding plural noun
(B) wrong verb form: concerning modal verbs (e.g.,
“would said”), subject-verb agreement, auxiliary
(e.g., “should have tell the truth”), gerund and in-
finitive usage (e.g., “look forward to see you” and
“in an attempt to helping you”)
</bodyText>
<listItem confidence="0.980594875">
(2) wrong preposition (or infinitive-to)
(A) wrong preposition (e.g., “to depends of it”)
(B) wrong preposition and verb form (e.g., “to play
an important role to close this deal”)
(3) transitivity errors
(A) transitive verb (e.g., “to discuss about the mat-
ter” and “to affect to his decision”)
(B) intransitive verb (e.g., “to listens the music”)
</listItem>
<bodyText confidence="0.997457944444445">
The system is designed to find pattern rules related
to the errors and return suggestionst. We now for-
mally state the problem that we are addressing.
Problem Statement: We are given a reference
corpus C and a non-native passage T. Our goal is
to detect grammatical and usage errors in T and
provide suggestions for correction. For this, we
extract a set of pattern rules, u1,É, um from C
such that the rules reflect the predominant usage
and are likely to distinguish most errors in non-
native writing.
In the rest of this section, we describe our solu-
tion to this problem. First, we define a strategy for
identifying predominant phraseology of frequent
ngrams and collocations in Section 3.2. Afer that,
we show how EdIt proposes grammar correc-
tionsedits to non-native writing at run-time in Sec-
tion 3.3.
</bodyText>
<subsectionHeader confidence="0.999084">
3.2 Deriving Pattern Rules
</subsectionHeader>
<bodyText confidence="0.997967961538462">
We attempt to derive patterns (e.g., “play — role in
V-ing”) from C expected to represent the immedi-
ate context of collocations (e.g., “play — role” or
“look forward”). Our derivation process consists of
the following four-stage:
Stage 1. Lemmatizing, POS Tagging and Phrase
chunking. In the first stage, we lemmatize and tag
sentences in C. Lemmatization and POS tagging
both help to produce more general pattern rules
from ngrams or collocations. The based phrases are
used to extract collocations.
Stage 2. Ngrams and Collocations. In the second
stage of the training process, we calculate ngrams
and collocations in C, and pass the frequent
ngrams and collocations to Stage 4.
We employ a number of steps to acquire statisti-
cally significant collocations--determining the pair
of head words in adjacent base phrases, calculating
their pair-wise mutual information values, and fil-
tering out candidates with low MI values.
Stage 3. onstructing Inverted Files. In the third
stage in the training procedure, we build up in-
verted files for the lemmas in C for quick access in
Stage 4. For each word lemma we store surface
words, POS tags, pointers to sentences with base
phrases marked.
</bodyText>
<footnote confidence="0.360738">
2 See (Nicholls, 1999) for common errors.
3 See (Leacock and Chodorow, 2003) and (Burstein et al., 2004) for correlation.
</footnote>
<page confidence="0.987534">
28
</page>
<figure confidence="0.530197875">
procedure GrammarChecking(T,PatternGrammarBank)
(1) Suggestions=“”//candidate suggestions
(2) sentences=sentenceSplitting(T)
for each sentence in sentences
(3) userProposedUsages=extractUsage(sentence)
for each userUsage in userProposedUsages
(4) patGram=findPatternGrammar(userUsage.lexemes,
PatternGrammarBank)
(5) minEditedCost=SystemMax; minEditedSug=“”
for each pattern in patGram
(6) cost=extendedLevenshtein(userUsage,pattern)
if cost&lt;minEditedCost
(7) minEditedCost=cost; minEditedSug=pattern
if minEditedCost&gt;0
(8) append (userUsage,minEditedSug) to Suggestions
(9) Return Suggestions
</figure>
<figureCaption confidence="0.995757">
Figure 2. Grammar suggestion/correction at run-time
</figureCaption>
<figure confidence="0.953755470588235">
procedure extendedLevenshtein(userUsage,pattern)
(1) allocate and initialize costArray
for i in range(len(userUsage))
for j in range(len(pattern))
if equal(userUsage[i],pattern[j]) //substitution
(2a) substiCost=costArray[i-1,j-1]+0
elseif sameWordGroup(userUsage[i],pattern[j])
(2b) substiCost=costArray[i-1,j-1]+0.5
(2c) else substiCost=costArray[i-1,j-1]+1
if equal(userUsage[i+1],pattern[j+1]) //deletion
(3a) delCost=costArray[i-1,j]+smallCost
(3b) else delCost=costArray[i-1,j]+1
if equal(userUsage[i+1],pattern[j+1]) //insertion
(4a) insCost=costArray[i,j-1]+smallCost
(4b) else insCost=costArray[i,j-1]+1
(5) costArray[i,j]=min(substiCost,delCost,insCost)
(6) Return costArray[len(userUsage),len(pattern)]
</figure>
<figureCaption confidence="0.999936">
Figure 3. Algorithm for identifying errors
</figureCaption>
<bodyText confidence="0.9999373">
Stage 4. Deriving pattern rules. In the fourth and
final stage, we use the method described in a pre-
vious work (Chen et al., 2011) and use the inverted
files to find all sentences containing a give word
and collocation. Words surrounding a collocation
are identified and generalized based on their corre-
sponding POS tags. These sentences are then trans-
formed into a set of n-gram of words and POS
tags, which are subsequently counted and ranked to
produce pattern rules with high frequencies.
</bodyText>
<subsectionHeader confidence="0.999379">
3.3 Run-Time Error Correction
</subsectionHeader>
<bodyText confidence="0.999869576271186">
Once the patterns rules are derived from a corpus
of well-formed texts, EdIt utilizes them to check
grammaticality and provide suggestions for a given
text via the procedure in Figure 2.
In Step (1) of the procedure, we initiate a set
Suggestions to collect grammar suggestions to the
user text T according to the bank of pattern gram-
mar PatternGrammarBank. Since EdIt system fo-
cuses on grammar checking at sentence level, T is
heuristically split (Step (2)).
For each sentence, we extract ngram and POS
tag sequences userUsage in T. For the example of
“He play an important roles. He looks forword to
hear you”, we extract ngram such as he V DET,
play an JJ NNS, play — roles to V, this NNS, look
forward to VB, and hear Pron.
For each userUsage, we first access the pattern
rules related to the word and collocation within
(e.g., play-role patterns for “play — role to close”)
Step (4). And then we compare userUsage against
these rules (from Step (5) to (7)). We use the ex-
tended Levenshtein’s algorithm shown in Figure 3
to compare userUsage and pattern rules.
If only partial matches are found for userUsage,
that could mean we have found a potential errors.
We use minEditedCost and minEditedSug to con-
train the patterns rules found for error suggestions
(Step (5)). In the following, we describe how to
find minimal-distance edits.
In Step (1) of the algorithm in Figure 3 we allo-
cate and initialize costArray to gather the dynamic
programming based cost to transform userUsage
into a specific contextual rule pattern. Afterwards,
the algorithm defines the cost of performing substi-
tution (Step (2)), deletion (Step (3)) and insertion
(Step (4)) at i-indexed userUsage and j-indexed
pattern. If the entries userUsage[i] and pattern[j]
are equal literally (e.g., “VB” and “VB”) or gram-
matically (e.g., “DT” and “Pron$”), no edit is
needed, hence, no cost (Step (2a)). On the other
hand, since learners tend to select wrong word
form and preposition, we set a lower cost for sub-
stitution among different word forms of the same
lemma or lemmas with the same POS tag (e.g.,
replacing V with V-ing or replacing to with in”. In
addition to the conventional deletion and insertion
(Step (3b) and (4b) respectively), we look ahead to
the elements userUsage[i+1] and pattern[j+1] con-
sidering the fact that “with or without preposition”
and “transitive or intransitive verb” often puzzles
EFL learners (Step (3a) and (4a)). Only a small
edit cost is counted if the next elements in use-
rUsage and Pattern are “equal”. In Step (6) the
extended Levenshtein’s algorithm returns the
minimum edit cost of revising userUsage using
pattern.
Once we obtain the costs to transform the use-
rUsage into a similar, frequent pattern rules, we
propose the minimum-cost rules as suggestions for
</bodyText>
<page confidence="0.996764">
29
</page>
<bodyText confidence="0.99993359375">
correction (e.g., “play — role in V-ing” for revising
“play — role to V”) (Step (8) in Figure 2), if its
minimum edit cost is greater than zero. Otherwise,
the usage is considered valid. Finally, the Sugges-
tions accumulated for T are returned to users (Step
(9)). Example input and editorial suggestions re-
turned to the user are shown in Figure 1. Note that
pattern rules involved flexible collocations are de-
signed to take care of long distance dependencies
that might be always possible to cover with limited
ngram (for n less than 6). In addition, the long pat-
ter rules can be useful even when it is not clear
whether there is an error when looking at a very
narrow context. For example, “hear” can be either
be transitive or intransitive depending on context.
In the context of “look forward to” and person
noun object, it is should be intransitive and require
the preposition “from” as suggested in the results
provided by EdIt (see Figure 1).
In existing grammar checkers, there are typically
many modules examining different types of errors
and different module may have different priority
and conflict with one another. Let us note that this
general framework for error detection and correc-
tion is an original contribution of our work. In ad-
dition, we incorporate probabilities conditioned on
word positions in order to weigh edit costs. For
example, the conditional probability of V to imme-
diately follow “look forward to” is virtually 0,
while the probability of V-ing to do so is approxi-
mates 0.3. Those probabilistic values are used to
weigh different edits.
</bodyText>
<sectionHeader confidence="0.993485" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999941285714286">
In this section, we first present the experimental
setting in EdIt (Section 4.1). Since our goal is to
provide to learners a means to efficient broad-
coverage grammar checking, EdIt is web-based
and the acquisition of the pattern grammar in use is
offline. Then, we illustrate three common types of
errors, scores correlated, EdIt4 capable of handling.
</bodyText>
<subsectionHeader confidence="0.964642">
4.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.999945611111111">
We used British National Corpus (BNC) as our
underlying general corpus C. It is a 100 million
British English word collection from a wide range
of sources. We exploited GENIA tagger to obtain
the lemmas, PoS tags and shallow parsing results
of C’s sentences, which were all used in construct-
ing inverted files and used as examples for GRASP
to infer lexicalized pattern grammar.
Inspired by (Chen et al., 2011) indicating EFL
learners tend to choose incorrect prepositions and
following word forms following a VN collocation,
and (Gamon and Leacock, 2010) showing fixed-
length and fixed-window lexical items are the best
evidence for correction, we equipped EdIt with
pattern grammar rules consisting of fixed-length
(from one- to five-gram) lexical sequences or VN
collocations and their fixed-window usages (e.g.,
“IN(in) VBG” after “play ~ role”, for window 2).
</bodyText>
<sectionHeader confidence="0.681893" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.999874">
We examined three types of errors and the mixture
of them for our correction system (see Table 1). In
this table, results of ESL Assistant are shown for
comparison, and grammatical suggestions are un-
derscored. As suggested, lexical and PoS informa-
tion in learner texts is useful for a grammar
checker, pattern grammar EdIt uses is easily acces-
sible and effective in both grammaticality and us-
age check, and a weighted extension to Leven-
shtein’s algorithm in EdIt accommodates substitu-
tion, deletion and insertion edits to learners’ fre-
quent mistakes in writing.
</bodyText>
<sectionHeader confidence="0.996953" genericHeader="conclusions">
5 Future Work and Summary
</sectionHeader>
<bodyText confidence="0.999927571428571">
Many avenues exist for future research and im-
provement. For example, we could augment pat-
tern grammar with lexemes’ PoS information in
that the contexts of a word of different PoS tags
vary. Take discuss for instance. The present tense
verb discuss is often followed by determiners and
nouns while the passive is by the preposition in as
in “É is discussed in Chapter one.” Additionally,
an interesting direction to explore is enriching pat-
tern grammar with semantic role labels (Chen et
al., 2011) for simple semantic check.
In summary, we have introduced a method for
correcting errors in learner text based on its lexical
and PoS evidence. We have implemented the
method and shown that the pattern grammar and
extended Levenshtein algorithm in this method are
promising in grammar checking. Concerning EdIt’s
broad coverage over different error types, simplic-
ity in design, and short response time, we plan to
evaluate it more fully: with or without conditional
probability using majority voting or not.
</bodyText>
<footnote confidence="0.886879">
4 At http://140.114.214.80/theSite/EdIt_demo2/
</footnote>
<page confidence="0.984105">
30
</page>
<table confidence="0.720519">
Erroneous sentence EdIt suggestion ESL Assistant suggestion
Incorrect word form
... a sunny days ... a sunny N a sunny day
every days, I ... every N every day
</table>
<bodyText confidence="0.981259619047619">
I would said to ... would V would say
he play a ... he V-ed none
... should have tell the truth should have V-en should have to tell
... look forward to see you look forward to V-ing none
... in an attempt to seeing you an attempt to V none
... be able to solved this problem able to V none
Incorrect preposition
he plays an important role to close ... play — role in none
he has a vital effect at her. have — effect on effect on her
it has an effect on reducing ... have — effect of V-ing none
... depend of the scholarship depend on depend on
Confusion between intransitive and transitive verb
he listens the music. missing “to” after “listens” missing “to” after “listens”
it affects to his decision. unnecessary “to” unnecessary “to”
I understand about the situation. unnecessary “about” unnecessary “about”
we would like to discuss about this matter. unnecessary “about” unnecessary “about”
Mixed
she play an important roles to close this deals. she V-ed; an Adj N; play an important role;
play — role in V-ing; this N close this deal
I look forward to hear you. look forward to V-ing; none
missing “from” after “hear”
</bodyText>
<tableCaption confidence="0.993322">
Table 1. Three common score-related error types and their examples with suggestions from EdIt and ESL Assistant.
</tableCaption>
<sectionHeader confidence="0.997133" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997311875">
C. Brockett, W. Dolan, and M. Gamon. 2006. Correcting ESL
errors using phrasal SMT techniques. In Proceedings of the
ACL.
J. Burstein, M. Chodorow, and C. Leacock. 2004. Automated
essay evaluation: the criterion online writing service. AI
Magazine, 25(3):27-36.
M. H. Chen, C. C. Huang, S. T. Huang, H. C. Liou, and J. S.
Chang. 2011. A cross-lingual pattern retrieval framework.
In Proceedings of the CICLing.
M. Chodorow and C. Leacock. 2000. An unsupervised method
for detecting grammatical errors. In Proceedings of the
NAACL, pages 140-147.
R. De Felice and S. Pulman. 2008. A classifer-based approach
to preposition and determiner error correction in L2 Eng-
lish. In COLING.
I. S. Fraser and L. M. Hodson. 1978. Twenty-one kicks at the
grammar horse. English Journal.
M. Gamon, C. Leacock, C. Brockett, W. B. Bolan, J. F. Gao,
D. Belenko, and A. Klementiev. Using statistical tech-
niques and web search to correct ESL errors. CALICO,
26(3): 491-511.
M. Gamon and C. Leacock. 2010. Search right and thou shalt
find É using web queries for learner error detection. In
Proceedings of the NAACL.
M. Hermet, A. Desilets, S. Szpakowicz. 2008. Using the web
as a linguistic resource to automatically correct lexico-
syntatic errors. In LREC, pages 874-878.
S. Hunston and G. Francis. 2000. Pattern grammar: a corpus-
driven approach to the lexical grammar of English.
C. M. Lee, S. J. Eom, and M. Dickinson. 2009. Toward ana-
lyzing Korean learner particles. In CALICO.
V. I. Levenshtein. 1966. Binary codes capable of correcting
deletions, insertions and reversals. Soviet Physics Doklady,
10:707-710.
C. Leacock and M. Chodorow. 2003. Automated grammatical
error detection.
D. Nicholls. 1999. The Cambridge Learner Corpus – error
coding and analysis for writing dictionaries and other
books for English Learners.
G. H. Sun, X. H. Liu, G. Cong, M. Zhou, Z. Y. Xiong, J. Lee,
and C. Y. Lin. 2007. Detecting erroneous sentences using
automatically mined sequential patterns. In ACL.
J. Tetreault, J. Foster, and M. Chodorow. 2010. Using parse
features for prepositions selection and error detection. In
Proceedings of the ACL, pages 353-358.
N. L. Tsao and D. Wible. 2009. A method for unsupervised
broad-coverage lexical error detection and correction. In
NAACL Workshop, pages 51-54.
</reference>
<page confidence="0.999913">
31
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.893471">
<title confidence="0.998737">EdIt: A Broad-Coverage Grammar Checker Using Pattern Grammar</title>
<author confidence="0.999869">Chung-Chi Huang Mei-Hua Chen Shih-Ting Huang Jason S Chang</author>
<affiliation confidence="0.9962065">Institute of Information Systems and Department of Computer Science, Applications, National Tsing Hua University, National Tsing Hua University,</affiliation>
<address confidence="0.969328">HsinChu, Taiwan, R.O.C. 300 HsinChu, Taiwan, R.O.C. 300</address>
<email confidence="0.998201">u901571@gmail.com</email>
<email confidence="0.998201">chen.meihua@gmail.com</email>
<email confidence="0.998201">koromiko1104@gmail.com</email>
<email confidence="0.998201">Jason.jschang@gmail.com</email>
<abstract confidence="0.996384">We introduce a new method for learning to detect grammatical errors in learner’s writing and provide suggestions. The method involves parsing a reference corpus and inferring grammar patterns in the form of a sequence of content words, function words, parts-of-speech (e.g., in and forward to At runtime, the given passage submitted by the learner is matched using an extended Levenshtein algorithm against the set of pattern rules in order to detect errors and provide suggestions. We present a prototype implementation of the proposed method, EdIt, that can handle a broad range of errors. Promising results are illustrated with three common types of errors in nonnative writing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Brockett</author>
<author>W Dolan</author>
<author>M Gamon</author>
</authors>
<title>Correcting ESL errors using phrasal SMT techniques.</title>
<date>2006</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<contexts>
<context position="6200" citStr="Brockett et al. (2006)" startWordPosition="981" endWordPosition="984">heckers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without error annotation. Recent work has been done on incorporating word class information into grammar checkers. For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and partof-speech (PoS) tags, while Sun et al. (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. In an approach similar to our work, Tsao and Wible (2009) use a combined ngrams of words forms, lemmas, and part-of-speech ta</context>
</contexts>
<marker>Brockett, Dolan, Gamon, 2006</marker>
<rawString>C. Brockett, W. Dolan, and M. Gamon. 2006. Correcting ESL errors using phrasal SMT techniques. In Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Burstein</author>
<author>M Chodorow</author>
<author>C Leacock</author>
</authors>
<title>Automated essay evaluation: the criterion online writing service.</title>
<date>2004</date>
<journal>AI Magazine,</journal>
<pages>25--3</pages>
<contexts>
<context position="11524" citStr="Burstein et al., 2004" startWordPosition="1840" endWordPosition="1843"> to Stage 4. We employ a number of steps to acquire statistically significant collocations--determining the pair of head words in adjacent base phrases, calculating their pair-wise mutual information values, and filtering out candidates with low MI values. Stage 3. onstructing Inverted Files. In the third stage in the training procedure, we build up inverted files for the lemmas in C for quick access in Stage 4. For each word lemma we store surface words, POS tags, pointers to sentences with base phrases marked. 2 See (Nicholls, 1999) for common errors. 3 See (Leacock and Chodorow, 2003) and (Burstein et al., 2004) for correlation. 28 procedure GrammarChecking(T,PatternGrammarBank) (1) Suggestions=“”//candidate suggestions (2) sentences=sentenceSplitting(T) for each sentence in sentences (3) userProposedUsages=extractUsage(sentence) for each userUsage in userProposedUsages (4) patGram=findPatternGrammar(userUsage.lexemes, PatternGrammarBank) (5) minEditedCost=SystemMax; minEditedSug=“” for each pattern in patGram (6) cost=extendedLevenshtein(userUsage,pattern) if cost&lt;minEditedCost (7) minEditedCost=cost; minEditedSug=pattern if minEditedCost&gt;0 (8) append (userUsage,minEditedSug) to Suggestions (9) Retu</context>
</contexts>
<marker>Burstein, Chodorow, Leacock, 2004</marker>
<rawString>J. Burstein, M. Chodorow, and C. Leacock. 2004. Automated essay evaluation: the criterion online writing service. AI Magazine, 25(3):27-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M H Chen</author>
<author>C C Huang</author>
<author>S T Huang</author>
<author>H C Liou</author>
<author>J S Chang</author>
</authors>
<title>A cross-lingual pattern retrieval framework.</title>
<date>2011</date>
<booktitle>In Proceedings of the CICLing.</booktitle>
<contexts>
<context position="13078" citStr="Chen et al., 2011" startWordPosition="1975" endWordPosition="1978">ttern[j]) (2b) substiCost=costArray[i-1,j-1]+0.5 (2c) else substiCost=costArray[i-1,j-1]+1 if equal(userUsage[i+1],pattern[j+1]) //deletion (3a) delCost=costArray[i-1,j]+smallCost (3b) else delCost=costArray[i-1,j]+1 if equal(userUsage[i+1],pattern[j+1]) //insertion (4a) insCost=costArray[i,j-1]+smallCost (4b) else insCost=costArray[i,j-1]+1 (5) costArray[i,j]=min(substiCost,delCost,insCost) (6) Return costArray[len(userUsage),len(pattern)] Figure 3. Algorithm for identifying errors Stage 4. Deriving pattern rules. In the fourth and final stage, we use the method described in a previous work (Chen et al., 2011) and use the inverted files to find all sentences containing a give word and collocation. Words surrounding a collocation are identified and generalized based on their corresponding POS tags. These sentences are then transformed into a set of n-gram of words and POS tags, which are subsequently counted and ranked to produce pattern rules with high frequencies. 3.3 Run-Time Error Correction Once the patterns rules are derived from a corpus of well-formed texts, EdIt utilizes them to check grammaticality and provide suggestions for a given text via the procedure in Figure 2. In Step (1) of the p</context>
<context position="18630" citStr="Chen et al., 2011" startWordPosition="2906" endWordPosition="2909">cking, EdIt is web-based and the acquisition of the pattern grammar in use is offline. Then, we illustrate three common types of errors, scores correlated, EdIt4 capable of handling. 4.1 Experimental Setting We used British National Corpus (BNC) as our underlying general corpus C. It is a 100 million British English word collection from a wide range of sources. We exploited GENIA tagger to obtain the lemmas, PoS tags and shallow parsing results of C’s sentences, which were all used in constructing inverted files and used as examples for GRASP to infer lexicalized pattern grammar. Inspired by (Chen et al., 2011) indicating EFL learners tend to choose incorrect prepositions and following word forms following a VN collocation, and (Gamon and Leacock, 2010) showing fixedlength and fixed-window lexical items are the best evidence for correction, we equipped EdIt with pattern grammar rules consisting of fixed-length (from one- to five-gram) lexical sequences or VN collocations and their fixed-window usages (e.g., “IN(in) VBG” after “play ~ role”, for window 2). 4.2 Results We examined three types of errors and the mixture of them for our correction system (see Table 1). In this table, results of ESL Assis</context>
<context position="20182" citStr="Chen et al., 2011" startWordPosition="3156" endWordPosition="3159">modates substitution, deletion and insertion edits to learners’ frequent mistakes in writing. 5 Future Work and Summary Many avenues exist for future research and improvement. For example, we could augment pattern grammar with lexemes’ PoS information in that the contexts of a word of different PoS tags vary. Take discuss for instance. The present tense verb discuss is often followed by determiners and nouns while the passive is by the preposition in as in “É is discussed in Chapter one.” Additionally, an interesting direction to explore is enriching pattern grammar with semantic role labels (Chen et al., 2011) for simple semantic check. In summary, we have introduced a method for correcting errors in learner text based on its lexical and PoS evidence. We have implemented the method and shown that the pattern grammar and extended Levenshtein algorithm in this method are promising in grammar checking. Concerning EdIt’s broad coverage over different error types, simplicity in design, and short response time, we plan to evaluate it more fully: with or without conditional probability using majority voting or not. 4 At http://140.114.214.80/theSite/EdIt_demo2/ 30 Erroneous sentence EdIt suggestion ESL As</context>
</contexts>
<marker>Chen, Huang, Huang, Liou, Chang, 2011</marker>
<rawString>M. H. Chen, C. C. Huang, S. T. Huang, H. C. Liou, and J. S. Chang. 2011. A cross-lingual pattern retrieval framework. In Proceedings of the CICLing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chodorow</author>
<author>C Leacock</author>
</authors>
<title>An unsupervised method for detecting grammatical errors.</title>
<date>2000</date>
<booktitle>In Proceedings of the NAACL,</booktitle>
<pages>140--147</pages>
<contexts>
<context position="5614" citStr="Chodorow and Leacock (2000)" startWordPosition="884" endWordPosition="887">sting rulebased systems have been proposed. For example, Uria et al. (2009) and Lee et al. (2009) leverage heuristic rules for detecting Basque determiner and Korean particle errors, respectively. Gamon et al. (2009) bases some of the modules in ESL Assistant on rules derived from manually inspecting learner data. Our pattern rules, however, are automatically derived from readily available well-formed data, but nevertheless very helpful for correcting errors in non-native writing. More recently, statistical approaches to developing grammar checkers have prevailed. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (</context>
</contexts>
<marker>Chodorow, Leacock, 2000</marker>
<rawString>M. Chodorow and C. Leacock. 2000. An unsupervised method for detecting grammatical errors. In Proceedings of the NAACL, pages 140-147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R De Felice</author>
<author>S Pulman</author>
</authors>
<title>A classifer-based approach to preposition and determiner error correction in L2 English.</title>
<date>2008</date>
<booktitle>In COLING.</booktitle>
<marker>De Felice, Pulman, 2008</marker>
<rawString>R. De Felice and S. Pulman. 2008. A classifer-based approach to preposition and determiner error correction in L2 English. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I S Fraser</author>
<author>L M Hodson</author>
</authors>
<title>Twenty-one kicks at the grammar horse.</title>
<date>1978</date>
<journal>English Journal.</journal>
<contexts>
<context position="4842" citStr="Fraser and Hodson (1978)" startWordPosition="771" endWordPosition="774">ual surface words (e.g., “closing” and “deal”) could be provided. Input: He play an important roles to close this deals. He looks forward to hear you. Suggestion: He played an important role in closing this deal. He looks forward to hearing from you. Figure 1. Example responses to the non-native writing. 2 Related Work Grammar checking has been an area of active research. Many methods, rule-oriented or datadriven, have been proposed to tackle the problem of detecting and correcting incorrect grammatical and usage errors in learner texts. It is at times no easy to distinguish these errors. But Fraser and Hodson (1978) shows the distinction between these two kinds of errors. For some specific error types (e.g., article and preposition error), a number of interesting rulebased systems have been proposed. For example, Uria et al. (2009) and Lee et al. (2009) leverage heuristic rules for detecting Basque determiner and Korean particle errors, respectively. Gamon et al. (2009) bases some of the modules in ESL Assistant on rules derived from manually inspecting learner data. Our pattern rules, however, are automatically derived from readily available well-formed data, but nevertheless very helpful for correcting</context>
</contexts>
<marker>Fraser, Hodson, 1978</marker>
<rawString>I. S. Fraser and L. M. Hodson. 1978. Twenty-one kicks at the grammar horse. English Journal.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Gamon</author>
<author>C Leacock</author>
<author>C Brockett</author>
<author>W B Bolan</author>
<author>J F Gao</author>
<author>D Belenko</author>
<author>A Klementiev</author>
</authors>
<title>Using statistical techniques and web search to correct ESL errors.</title>
<journal>CALICO,</journal>
<volume>26</volume>
<issue>3</issue>
<pages>491--511</pages>
<marker>Gamon, Leacock, Brockett, Bolan, Gao, Belenko, Klementiev, </marker>
<rawString>M. Gamon, C. Leacock, C. Brockett, W. B. Bolan, J. F. Gao, D. Belenko, and A. Klementiev. Using statistical techniques and web search to correct ESL errors. CALICO, 26(3): 491-511.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gamon</author>
<author>C Leacock</author>
</authors>
<title>Search right and thou shalt find É using web queries for learner error detection.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL.</booktitle>
<contexts>
<context position="5828" citStr="Gamon and Leacock (2010)" startWordPosition="918" endWordPosition="921">bases some of the modules in ESL Assistant on rules derived from manually inspecting learner data. Our pattern rules, however, are automatically derived from readily available well-formed data, but nevertheless very helpful for correcting errors in non-native writing. More recently, statistical approaches to developing grammar checkers have prevailed. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without error annotation. Recent work has been done on incorporating word class information into </context>
<context position="18775" citStr="Gamon and Leacock, 2010" startWordPosition="2927" endWordPosition="2930">ores correlated, EdIt4 capable of handling. 4.1 Experimental Setting We used British National Corpus (BNC) as our underlying general corpus C. It is a 100 million British English word collection from a wide range of sources. We exploited GENIA tagger to obtain the lemmas, PoS tags and shallow parsing results of C’s sentences, which were all used in constructing inverted files and used as examples for GRASP to infer lexicalized pattern grammar. Inspired by (Chen et al., 2011) indicating EFL learners tend to choose incorrect prepositions and following word forms following a VN collocation, and (Gamon and Leacock, 2010) showing fixedlength and fixed-window lexical items are the best evidence for correction, we equipped EdIt with pattern grammar rules consisting of fixed-length (from one- to five-gram) lexical sequences or VN collocations and their fixed-window usages (e.g., “IN(in) VBG” after “play ~ role”, for window 2). 4.2 Results We examined three types of errors and the mixture of them for our correction system (see Table 1). In this table, results of ESL Assistant are shown for comparison, and grammatical suggestions are underscored. As suggested, lexical and PoS information in learner texts is useful </context>
</contexts>
<marker>Gamon, Leacock, 2010</marker>
<rawString>M. Gamon and C. Leacock. 2010. Search right and thou shalt find É using web queries for learner error detection. In Proceedings of the NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hermet</author>
<author>A Desilets</author>
<author>S Szpakowicz</author>
</authors>
<title>Using the web as a linguistic resource to automatically correct lexicosyntatic errors.</title>
<date>2008</date>
<booktitle>In LREC,</booktitle>
<pages>874--878</pages>
<contexts>
<context position="5799" citStr="Hermet et al. (2008)" startWordPosition="913" endWordPosition="916">ely. Gamon et al. (2009) bases some of the modules in ESL Assistant on rules derived from manually inspecting learner data. Our pattern rules, however, are automatically derived from readily available well-formed data, but nevertheless very helpful for correcting errors in non-native writing. More recently, statistical approaches to developing grammar checkers have prevailed. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without error annotation. Recent work has been done on incorporating</context>
</contexts>
<marker>Hermet, Desilets, Szpakowicz, 2008</marker>
<rawString>M. Hermet, A. Desilets, S. Szpakowicz. 2008. Using the web as a linguistic resource to automatically correct lexicosyntatic errors. In LREC, pages 874-878.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hunston</author>
<author>G Francis</author>
</authors>
<title>Pattern grammar: a corpusdriven approach to the lexical grammar of English.</title>
<date>2000</date>
<contexts>
<context position="3029" citStr="Hunston and Francis (2000)" startWordPosition="481" endWordPosition="484">of “roles”, (c) Use “in closing” instead of “to close” (d) Use “to hearing” instead of “to hear”, and (e) insert “from” between “hear” and “you.” These suggestions can be offered by learning the patterns rules related to “play — role” and “look forward” based on analysis of ngrams and collocations in a very large-scale reference corpus. With corpus statistics, we could learn the needed phraseological tendency in the form of pattern rules such as “play — role in V-ing) and “look forward to V-ing.” The use of such pattern rules is in line with the recent theory of Pattern Grammar put forward by Hunston and Francis (2000). We present a system, EdIt, that automatically learns to provide suggestions for rare/wrong usages in non-native writing. Example EdIt responses to a 26 text are shown in Figure 1. EdIt has retrieved the related pattern grammar of some ngram and collocation sequences given the input (e.g., “play — role in V-ing1”, and “look forward to V-ing”). EdIt learns these patterns during pattern extraction process by syntactically analyzing a collection of well-formed, published texts. At run-time, EdIt first processes the input passages in the article (e.g., “He play an important roles to close ”) subm</context>
</contexts>
<marker>Hunston, Francis, 2000</marker>
<rawString>S. Hunston and G. Francis. 2000. Pattern grammar: a corpusdriven approach to the lexical grammar of English.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C M Lee</author>
<author>S J Eom</author>
<author>M Dickinson</author>
</authors>
<title>Toward analyzing Korean learner particles.</title>
<date>2009</date>
<booktitle>In CALICO.</booktitle>
<contexts>
<context position="5084" citStr="Lee et al. (2009)" startWordPosition="811" endWordPosition="814">. Figure 1. Example responses to the non-native writing. 2 Related Work Grammar checking has been an area of active research. Many methods, rule-oriented or datadriven, have been proposed to tackle the problem of detecting and correcting incorrect grammatical and usage errors in learner texts. It is at times no easy to distinguish these errors. But Fraser and Hodson (1978) shows the distinction between these two kinds of errors. For some specific error types (e.g., article and preposition error), a number of interesting rulebased systems have been proposed. For example, Uria et al. (2009) and Lee et al. (2009) leverage heuristic rules for detecting Basque determiner and Korean particle errors, respectively. Gamon et al. (2009) bases some of the modules in ESL Assistant on rules derived from manually inspecting learner data. Our pattern rules, however, are automatically derived from readily available well-formed data, but nevertheless very helpful for correcting errors in non-native writing. More recently, statistical approaches to developing grammar checkers have prevailed. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high</context>
</contexts>
<marker>Lee, Eom, Dickinson, 2009</marker>
<rawString>C. M. Lee, S. J. Eom, and M. Dickinson. 2009. Toward analyzing Korean learner particles. In CALICO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions and reversals.</title>
<date>1966</date>
<journal>Soviet Physics Doklady,</journal>
<pages>10--707</pages>
<contexts>
<context position="3980" citStr="Levenshtein, 1966" startWordPosition="631" endWordPosition="632">d to V-ing”). EdIt learns these patterns during pattern extraction process by syntactically analyzing a collection of well-formed, published texts. At run-time, EdIt first processes the input passages in the article (e.g., “He play an important roles to close ”) submitted by the L2 learner. And EdIt tag the passage with part of speech information, and compares the tagged sentence against the pattern rules anchored at certain collocations (e.g., “play — role” and “look forward”). Finally, EdIt finds the minimum-edit-cost patterns matching the passages using an extended Levenshtein’s algorithm (Levenshtein, 1966). The system then highlights the edits and displays the pattern rules as suggestions for correction. In our prototype, EdIt returns the preferred word form and preposition usages to the user directly (see Figure 1); alternatively, the actual surface words (e.g., “closing” and “deal”) could be provided. Input: He play an important roles to close this deals. He looks forward to hear you. Suggestion: He played an important role in closing this deal. He looks forward to hearing from you. Figure 1. Example responses to the non-native writing. 2 Related Work Grammar checking has been an area of acti</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>V. I. Levenshtein. 1966. Binary codes capable of correcting deletions, insertions and reversals. Soviet Physics Doklady, 10:707-710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
</authors>
<title>Automated grammatical error detection.</title>
<date>2003</date>
<contexts>
<context position="11496" citStr="Leacock and Chodorow, 2003" startWordPosition="1835" endWordPosition="1838"> frequent ngrams and collocations to Stage 4. We employ a number of steps to acquire statistically significant collocations--determining the pair of head words in adjacent base phrases, calculating their pair-wise mutual information values, and filtering out candidates with low MI values. Stage 3. onstructing Inverted Files. In the third stage in the training procedure, we build up inverted files for the lemmas in C for quick access in Stage 4. For each word lemma we store surface words, POS tags, pointers to sentences with base phrases marked. 2 See (Nicholls, 1999) for common errors. 3 See (Leacock and Chodorow, 2003) and (Burstein et al., 2004) for correlation. 28 procedure GrammarChecking(T,PatternGrammarBank) (1) Suggestions=“”//candidate suggestions (2) sentences=sentenceSplitting(T) for each sentence in sentences (3) userProposedUsages=extractUsage(sentence) for each userUsage in userProposedUsages (4) patGram=findPatternGrammar(userUsage.lexemes, PatternGrammarBank) (5) minEditedCost=SystemMax; minEditedSug=“” for each pattern in patGram (6) cost=extendedLevenshtein(userUsage,pattern) if cost&lt;minEditedCost (7) minEditedCost=cost; minEditedSug=pattern if minEditedCost&gt;0 (8) append (userUsage,minEdited</context>
</contexts>
<marker>Leacock, Chodorow, 2003</marker>
<rawString>C. Leacock and M. Chodorow. 2003. Automated grammatical error detection.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Nicholls</author>
</authors>
<title>The Cambridge Learner Corpus – error coding and analysis for writing dictionaries and other books for English Learners.</title>
<date>1999</date>
<contexts>
<context position="11442" citStr="Nicholls, 1999" startWordPosition="1828" endWordPosition="1829">ngrams and collocations in C, and pass the frequent ngrams and collocations to Stage 4. We employ a number of steps to acquire statistically significant collocations--determining the pair of head words in adjacent base phrases, calculating their pair-wise mutual information values, and filtering out candidates with low MI values. Stage 3. onstructing Inverted Files. In the third stage in the training procedure, we build up inverted files for the lemmas in C for quick access in Stage 4. For each word lemma we store surface words, POS tags, pointers to sentences with base phrases marked. 2 See (Nicholls, 1999) for common errors. 3 See (Leacock and Chodorow, 2003) and (Burstein et al., 2004) for correlation. 28 procedure GrammarChecking(T,PatternGrammarBank) (1) Suggestions=“”//candidate suggestions (2) sentences=sentenceSplitting(T) for each sentence in sentences (3) userProposedUsages=extractUsage(sentence) for each userUsage in userProposedUsages (4) patGram=findPatternGrammar(userUsage.lexemes, PatternGrammarBank) (5) minEditedCost=SystemMax; minEditedSug=“” for each pattern in patGram (6) cost=extendedLevenshtein(userUsage,pattern) if cost&lt;minEditedCost (7) minEditedCost=cost; minEditedSug=patt</context>
</contexts>
<marker>Nicholls, 1999</marker>
<rawString>D. Nicholls. 1999. The Cambridge Learner Corpus – error coding and analysis for writing dictionaries and other books for English Learners.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G H Sun</author>
<author>X H Liu</author>
<author>G Cong</author>
<author>M Zhou</author>
<author>Z Y Xiong</author>
<author>J Lee</author>
<author>C Y Lin</author>
</authors>
<title>Detecting erroneous sentences using automatically mined sequential patterns.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="6219" citStr="Sun et al. (2007)" startWordPosition="985" endWordPosition="988">acock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without error annotation. Recent work has been done on incorporating word class information into grammar checkers. For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and partof-speech (PoS) tags, while Sun et al. (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. In an approach similar to our work, Tsao and Wible (2009) use a combined ngrams of words forms, lemmas, and part-of-speech tags for research int</context>
</contexts>
<marker>Sun, Liu, Cong, Zhou, Xiong, Lee, Lin, 2007</marker>
<rawString>G. H. Sun, X. H. Liu, G. Cong, M. Zhou, Z. Y. Xiong, J. Lee, and C. Y. Lin. 2007. Detecting erroneous sentences using automatically mined sequential patterns. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Tetreault</author>
<author>J Foster</author>
<author>M Chodorow</author>
</authors>
<title>Using parse features for prepositions selection and error detection.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>353--358</pages>
<contexts>
<context position="6114" citStr="Tetreault et al. (2010)" startWordPosition="965" endWordPosition="969">tistical approaches to developing grammar checkers have prevailed. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without error annotation. Recent work has been done on incorporating word class information into grammar checkers. For example, Chodorow and Leacock (2000) exploit bigrams and trigrams of function words and partof-speech (PoS) tags, while Sun et al. (2007) use labeled sequential patterns of function, time expression, and part-of-speech tags. In an approach similar to our work, Tsa</context>
</contexts>
<marker>Tetreault, Foster, Chodorow, 2010</marker>
<rawString>J. Tetreault, J. Foster, and M. Chodorow. 2010. Using parse features for prepositions selection and error detection. In Proceedings of the ACL, pages 353-358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N L Tsao</author>
<author>D Wible</author>
</authors>
<title>A method for unsupervised broad-coverage lexical error detection and correction.</title>
<date>2009</date>
<booktitle>In NAACL Workshop,</booktitle>
<pages>51--54</pages>
<contexts>
<context position="5738" citStr="Tsao and Wible (2009)" startWordPosition="904" endWordPosition="907">ecting Basque determiner and Korean particle errors, respectively. Gamon et al. (2009) bases some of the modules in ESL Assistant on rules derived from manually inspecting learner data. Our pattern rules, however, are automatically derived from readily available well-formed data, but nevertheless very helpful for correcting errors in non-native writing. More recently, statistical approaches to developing grammar checkers have prevailed. Among unsupervised checkers, Chodorow and Leacock (2000) exploits negative evidence from edited textual corpora achieving high precision but low recall, while Tsao and Wible (2009) uses general corpus only. Additionally, Hermet et al. (2008) and Gamon and Leacock (2010) both use Web as a corpus to detect errors in non-native writing. On the other hand, supervised models, typically treating error detection/correction as a classification problem, may train on well-formed texts as in the methods by De Felice and Pulman (2008) and Tetreault et al. (2010), or with additional learner texts as in the method proposed by Brockett et al. (2006). Sun et al. (2007) describes a method for constructing a supervised detection system trained on raw well-formed and learner texts without</context>
</contexts>
<marker>Tsao, Wible, 2009</marker>
<rawString>N. L. Tsao and D. Wible. 2009. A method for unsupervised broad-coverage lexical error detection and correction. In NAACL Workshop, pages 51-54.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>