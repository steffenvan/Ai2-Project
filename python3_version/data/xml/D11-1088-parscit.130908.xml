<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.99954">
A Non-negative Matrix Factorization Based Approach for Active Dual
Supervision from Document and Word Labels
</title>
<author confidence="0.993363">
Chao Shen and Tao Li
</author>
<affiliation confidence="0.9965125">
School of Computing and Information Sciences
Florida International University
</affiliation>
<address confidence="0.536672">
Miami, FL 33199 USA
</address>
<email confidence="0.999486">
{cshen001,taoli}@cs.fiu.edu
</email>
<sectionHeader confidence="0.99667" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999966705882353">
In active dual supervision, not only informa-
tive examples but also features are selected for
labeling to build a high quality classifier with
low cost. However, how to measure the infor-
mativeness for both examples and feature on
the same scale has not been well solved. In
this paper, we propose a non-negative matrix
factorization based approach to address this is-
sue. We first extend the matrix factorization
framework to explicitly model the correspond-
ing relationships between feature classes and
examples classes. Then by making use of
the reconstruction error, we propose a unified
scheme to determine which feature or exam-
ple a classifier is most likely to benefit from
having labeled. Empirical results demonstrate
the effectiveness of our proposed methods.
</bodyText>
<sectionHeader confidence="0.998881" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999795">
Active learning, as an effective paradigm to optimize
the learning benefit from domain experts’ feedback
and to reduce the cost of acquiring labeled examples
for supervised learning, has been intensively stud-
ied in recent years (McCallum and Nigam, 1998;
Tong and Koller, 2002; Settles, 2009). Traditional
approaches for active learning query the human ex-
perts to obtain the labels for intelligently chosen
data samples. However, in text classification where
the input data is generally represented as document-
word matrices, human supervision can be obtained
on both documents and words. For example, in sen-
timent analysis of product reviews, human labelers
can label reviews as positive or negative, they can
also label the words that elicit positive sentiment
(such as “sensational” and “electrifying”) as posi-
tive and words that evoke negative sentiment (such
as “depressed” and “unfulfilling”) as negative. Re-
cent work has demonstrated that labeled words (or
feature supervision) can greatly reduce the number
of labeled samples for building high-quality classi-
fiers (Druck et al., 2008; Zaidan and Eisner, 2008).
In fact, different kinds of supervision generally have
different acquisition costs, different degrees of util-
ity and are not mutually redundant (Sindhwani et
al., 2009). Ideally, effective active learning schemes
should be able to utilize different forms of supervi-
sion.
To incorporate the supervision on words and doc-
uments at same time into the active learning scheme,
recently an active dual supervision (or dual active
learning) has been proposed (Melville and Sind-
hwani, 2009; Sindhwani et al., 2009). Comparing
with traditional active learning which aims to select
the most “informative” examples (e.g., documents)
for domain experts to label, active dual supervi-
sion selects both the “informative” examples (e.g.,
documents) and features (e.g., words) for labeling.
For active dual supervision to be effective, there
are three important components: a) an underlying
learning mechanism that is able to learn from both
the labeled examples and features (i.e., incorporat-
ing supervision on both examples and features); b)
methods for estimating the value of information for
example and feature labels; and c) a scheme that
should be able to trade-off the costs and benefits of
the different forms of supervision since they have
different labeling costs and different benefits.
</bodyText>
<page confidence="0.98105">
949
</page>
<note confidence="0.958348">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 949–958,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.997540333333334">
In Sindhwani et al.’s initial work on active dual
supervision (Sindhwani et al., 2009), a transductive
bipartite graph regularization approach is used for
learning from both labeled examples and features.
In addition, uncertainty sampling and experimental
design are used for selecting informative examples
and features for labeling. To trade-off between dif-
ferent types of supervision, a simple probabilistic
interleaving scheme where the active learner prob-
abilistically queries the example oracle and the fea-
ture oracle is used. One problem in their method is
that the values of acquiring the feature labels and
the example labels are not on the same scale.
Recently, Li et al. (Li et al., 2009) proposed a
dual supervision method based on constrained non-
negative tri-factorization of the document-term ma-
trix where the labeled features and examples are
naturally incorporated as sets of constraints. Hav-
ing a framework for incorporating dual-supervision
based on matrix factorization, gives rise to the nat-
ural question of how to perform active dual super-
vision in this setting. Since rows and columns are
treated equally in estimating the errors of matrix fac-
torization, another question is can we address the
scaling issue in comparing the value of feature la-
bels and example labels.
In this paper, we study the problem of ac-
tive dual supervision using non-negative matrix tri-
factorization. Our work is based on the dual supervi-
sion framework using constrained non-negative tri-
factorization proposed in (Li et al., 2009). We first
extend the framework to explicitly model the corre-
sponding relationships between feature classes and
example classes. Then by making use of the recon-
struction error criterion in matrix factorization, we
propose a unified scheme to evaluate the value of
feature and example labels. Instead of comparing
the estimated performance increase of new feature
labels or example labels, our proposed scheme as-
sumes that a better supervision (a feature label or a
example label) should lead to a more accurate re-
construction of the original data matrix. In our pro-
posed scheme, the value of feature labels and ex-
ample labels is computed on the same scale. The
experiments show that our proposed unified scheme
to query selection (i.e., feature/example selection for
labeling) outperforms the interleaving schemes and
the scheme based on expected log gain.
The rest of this paper is organized as follows: the
related work is discussed in Section 2, and the dual
supervision framework based on non-negative ma-
trix tri-factorization is introduced in Section 3. We
extend non-negative matrix tri-factorization to active
learning settings in Section 4, and propose a unified
scheme for query selection in Section 5. Experi-
ments are presented in Section 6, and finally Section
7 concludes the paper.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9998735">
We point the reader to a recent report (Settles, 2009)
for an in-depth survey on active learning. In this
section, we briefly cover related work to position our
contributions appropriately.
</bodyText>
<sectionHeader confidence="0.408651" genericHeader="method">
Active Learning/Active Dual Supervision Most
</sectionHeader>
<bodyText confidence="0.999956">
prior work in active learning has focused on pooled-
based techniques, where examples from an unla-
beled pool are selected for labeling (Cohn et al.,
1994). With the study of learning from labeled fea-
tures, many research efforts on active learning with
feature supervision are also reported (Melville et al.,
2005; Raghavan et al., 2006). (Godbole et al., 2004)
proposed the notion of feature uncertainty and in-
corporated the acquired feature labels into learning
by creating one-term mini-documents. (Druck et al.,
2009) performed active learning via feature labeling
using several uncertainty reduction heuristics using
the learning model developed in (Druck et al., 2008).
(Sindhwani et al., 2009) studied the problem of ac-
tive dual supervision from examples and features
using a graph-based dual supervision method with
a simple probabilistic method for interleaving fea-
ture labels and example labels. In our work, we de-
velop our active dual supervision framework using
constrained non-negative tri-factorization and also
propose a unified scheme to evaluate the value of
feature and example labels. We note the very re-
cent work of (Attenberg et al., 2010), which pro-
poses a unified approach for the dual active learn-
ing problem using expected utility where the utility
is defined as the log gain of the classification model
with a new labeled document or word. Conceptu-
ally, our proposed unified scheme is a special case
of the expected utility framework where the utility
is computed using the matrix reconstruction error.
The utility based on the log gain of the classification
</bodyText>
<page confidence="0.993853">
950
</page>
<bodyText confidence="0.999914032258065">
model may not be reliable as small model changes
resulted from a single additional example label or
feature label may not be reflected in the classifica-
tion performance (Attenberg et al., 2010). The em-
pirical comparisons show that our proposed unified
scheme based on reconstruction error outperforms
the expected log gain.
Dual Supervision Note that a learning method
that is capable of performing dual supervision (i.e.,
learning from both labeled examples and features)
is the basis for active dual supervision. Dual su-
pervision is a relatively new area of research and
few methods have been developed for dual super-
vision. In (Sindhwani and Melville, 2008; Sind-
hwani et al., 2008), a bipartite graph regularization
model (GRADS) is used to diffuse label informa-
tion along both sides of the document-term matrix
and to perform dual supervision for semi-supervised
sentiment analysis. Conceptually, their model im-
plements a co-clustering assumption closely related
to Singular Value Decomposition (see also (Dhillon,
2001; Zha et al., 2001) for more on this perspec-
tive). In (Sandler et al., 2008), standard regulariza-
tion models are constrained using graphs of word co-
occurrences. In (Melville et al., 2009), Naive Bayes
classifier is extended, where the parameters, the con-
ditional word distributions given the classes, are es-
timated by combining multiple sources, e.g. docu-
ment labels and word labels. Our work is based on
the dual supervision framework using constrained
non-negative tri-factorization.
</bodyText>
<sectionHeader confidence="0.5811675" genericHeader="method">
3 Learning with Dual Supervision via
Tri-NMF
</sectionHeader>
<bodyText confidence="0.999237117647059">
Our dual supervision model is based on non-
negative matrix tri-factorization (Tri-NMF), where
the non-negative input document-word matrix is ap-
proximated by 3 factor matrices as X Pz GSFT, in
which, X is an nxm document-term matrix, G is an
n x k non-negative orthogonal matrix representing
the probability of generating a document from a doc-
ument cluster, F is an m x k non-negative orthogo-
nal matrix representing the probability of generating
a word from a word cluster, and S is a k x k non-
negative matrix providing the relationship between
document cluster space and word cluster space.
While Tri-NMF is first applied in co-clustering, Li
et al. (Li et al., 2009) extended it to incorporate la-
beled words and documents as dual supervision via
two loss terms in the objective function of Tri-NMF
as following:
</bodyText>
<equation confidence="0.994663333333333">
minF,G,S IIX − GSFT II2
+αtrace[(F − F0)TC1(F − F0)]
+Otrace[(G − G0)TC2(G − G0)].
</equation>
<bodyText confidence="0.9642101875">
Here, α &gt; 0 is a parameter which determines the
extent to which we enforce F Pz F0 to its labeled
rows. C1 is a m x m diagonal matrix whose en-
try (C1)ii = 1 if the row of F0 is labeled, that is,
the class of the i-th word is known and (C1)ii = 0
otherwise. 0 &gt; 0 is a parameter which determines
the extent to which we enforce G Pz G0 to its la-
beled rows. C2 is a n x n diagonal matrix whose
entry (C2)ii = 1 if the row of G0 is labeled, that
is, the category of the i-th document is known and
(C2)ii = 0 otherwise. The squared loss terms ensure
that the solution for G, F in the otherwise unsuper-
vised learning problem be close to the prior knowl-
edge G0, F0. So the partial labels on documents and
words can be described using G0 and F0, respec-
tively.
</bodyText>
<sectionHeader confidence="0.9912815" genericHeader="method">
4 Dual Supervision with Explicit Class
Alignment
</sectionHeader>
<subsectionHeader confidence="0.99952">
4.1 Modeling the Relationships between Word
Classes and Document Classes
</subsectionHeader>
<bodyText confidence="0.994686642857143">
In the solution to Equation 1, we have S = GT XF,
or
iERl jECk
where |Rl |is the size of the l-th document class, and
|Ck |is the size of the k-th word class (Ding et al.,
2006). Note that Slk represents properly normalized
within-class sum of weights (l = k) and between-
class sum of weights (l =� k). So, S represents the
relationship between the classes over documents and
the classes over words. Under the assumption that
the i-th document class should correspond to the i-
th word class, S should be an approximate diago-
nal matrix, since the documents of i-th class is more
likely to contain the words of the i-th class. Note
</bodyText>
<equation confidence="0.9890545">
/1 /
Slk = 9&apos;Tl Xfk = |Rl|1 2|CkI1 2 Xij,
</equation>
<page confidence="0.955249">
951
</page>
<bodyText confidence="0.998124117647059">
that S is not an exact diagonal matrix, since a doc-
ument of one class apparently can use words from
other classes (especially G and F are required to be
approximately orthogonal, which means the classi-
fication is rigorous). However, in Equation 1, there
are no explicit constraints on the relationship be-
tween word classes and document classes. Instead,
the relationship is established and enforced implic-
itly using existing labeled documents and words.
In active learning, the set of starting labeled doc-
uments or words is small, and this may generate an
ill-formed S, leading to an incorrect alignment of
word classes and document classes. To explicitly
model the relationships between word classes and
document classes, we constrain the shape of S via
an extra loss term in the objective function as fol-
lows:
</bodyText>
<equation confidence="0.97009">
minF,G,S kX − GSFT k2
+α trace[(F − F0)T C1(F − F0)]
+β trace[(G − G0)TC2(G − G0)]
+γ trace[(S − S0)T (S − S0)]
(3)
</equation>
<bodyText confidence="0.958814833333333">
where S0 is a diagonal matrix.
How to Choose S0 If there is no orthogonal con-
straint on F, G and I-divergence is used as the ob-
jective function, it can been shown that the factors
of Tri-NMF have probabilistic interpretation (Ding
et al., 2008; Shen et al., 2011):
</bodyText>
<equation confidence="0.996179333333333">
Fil = P(w = wi|zw = l),
Gjk = P(d = dj|zd = k), (4)
Skl = P(zd = k,zw = l),
</equation>
<bodyText confidence="0.999980666666667">
where w is word variable, d is document variable,
and zw, zd are random variables indicating word
class and document class respectively. F and G
represent posterior distributions for words and docu-
ments, and S represents the joint distribution of doc-
ument class and word class. With such an interpre-
tation, S0 can be easily decided in balanced classifi-
cation problems with each diagonal entry equals to
one over the number of classes.
However, in our setting of Tri-NMF, orthogonal
constraints are enforced on F, G and Euclidean dis-
tance is used as the objective function. To pre-
compute S0, one way is to first solve the optimiza-
tion problem Equation 1 with another constraint that
S should be diagonal. Alternatively, to keep it sim-
ple, we ignore the known label information and just
assume there exists a diagonal matrix S0 and two
orthogonal matrices G, F, that
</bodyText>
<equation confidence="0.924281454545454">
GS0FT ≈ X.
Then
trace[XXT] ≈ trace[GS0FTFST0 GT],
� trace[S0ST0 FTFGTG],
� trace[S0ST0 ],
� �k(S0)2kk.
So if a classification problem is balanced with K
classes, S0 can be estimated as following:
� S - / traceK XT ] l = k,
( 0)kl = �/ (6)
0 otherwise.
</equation>
<subsectionHeader confidence="0.991642">
4.2 Computing Algorithm
</subsectionHeader>
<bodyText confidence="0.9997345">
This optimization problem can be solved using the
following update rules
</bodyText>
<equation confidence="0.693782">
Gjk ← Gjk (GGT XFS+βGGT C2G)jk ,
XFS+βC2G0
Sjk ← Sjk (FT FSGT G+γS)jk,
FT XT G+γS0
Fjk ← Fjk XT GST +αC1F0 (FFT XT GST +αC1F)jk .
</equation>
<bodyText confidence="0.9895565">
The algorithm consists of an iterative procedure us-
ing the above three rules until convergence.
</bodyText>
<construct confidence="0.893342333333333">
Theorem 4.1 The above iterative algorithm con-
verges.
Theorem 4.2 At convergence, the solution satisfies
the Karuch-Kuhn-Tucker (KKT) optimality condi-
tion, i.e., the algorithm converges correctly to a lo-
cal optima.
</construct>
<bodyText confidence="0.9933446">
Theorem 4.1 can be proved using the standard aux-
iliary function approach (Lee and Seung, 2001).
Proof of Theorem 4.2: Proof for the update rules
of G, F is the same as in (Li et al., 2009). Here we
focus on the update rule of S. We want to minimize
</bodyText>
<equation confidence="0.987146">
L(S) = kX − GSFTk2
+αtrace[(F − F0)TC1(F − F0)]
+β trace[(G − G0)TC2(G − G0)]
+γ trace[(S − S0)T (S − S0)].
(5)
</equation>
<page confidence="0.958209">
952
</page>
<bodyText confidence="0.84860125">
The gradient of L is
= 2FT FSGT G − 2FT XT G + 2γ(S − S0)
The KKT complementarity condition for the non-
negativity of Sjk gives
</bodyText>
<equation confidence="0.725531">
[2FT FSGTG−2F TXT G+2γ(S−S0)]jkSjk = 0.
</equation>
<bodyText confidence="0.997815">
This is the fixed point relation that local minima for
S must satisfy, which is equivalent with the update
rule of S in Equation 7.
</bodyText>
<sectionHeader confidence="0.9476745" genericHeader="method">
5 A Unified Scheme for Query Selection
Using the Reconstruction Error
</sectionHeader>
<subsectionHeader confidence="0.977566">
5.1 Introduction
</subsectionHeader>
<bodyText confidence="0.999294">
An ideal active dual supervision scheme should be
able to evaluate the value of acquiring labels for doc-
uments and words on the same scale. In the initial
study of dual active supervision, different scores are
used for documents and words (e.g. uncertainty for
documents and certainty for words), and thus they
are not on the same scale (Sindhwani et al., 2009).
Recently, the framework of Expected Utility (Esti-
mated Risk Minimization) is proposed in (Attenberg
et al., 2010). At each step of the framework, the next
word or document selected for labeling is the one
that will result in the highest estimated improvement
in classifier performance as defined as:
that a good supervision should lead to a good con-
strained factorization for the document-term matrix,
X Pz GSFT . If the new query qj is a word and its
label is k, then the new factorization is
</bodyText>
<equation confidence="0.9090916">
G∗ j=k, S∗j=k, F∗j=k
= arg minG,S,F IIX − GSFT II2
+ α trace[(G − G0)TC2(G − G0)]
+ β trace[(F − F0,j=k)TC1(F − F0,j=k)]
+ γ trace[(S − S0)T (S − S0)],
</equation>
<bodyText confidence="0.9991032">
where F0,j=k is same as F0 except that
F0,j=k(j, k) = 1. In other words, we obtained
a new factorization using the labeled words. Sim-
ilarly, if the new query qj is a document, then the
new factorization is
</bodyText>
<equation confidence="0.9307418">
G∗ j=k, S∗j=k, F∗j=k
= arg minG,S,F IIX − GSFT II2
+ α trace[(G − G0,j=k)TC2(G − G0,j=k)]
+ β trace[(F − F0)TC1(F − F0)]
+ γ trace[(S − S0)T (S − S0)],
</equation>
<bodyText confidence="0.9999575">
where G0,j=k is same as G0 except that
G0,j=k(j, k) = 1. In other words, we obtained
a new factorization using the labeled documents.
Then the new reconstruction error is
</bodyText>
<equation confidence="0.994829">
RE(qj = k) = IIX − G∗ j=kS∗ j=kF ∗ j=kII2. (12)
</equation>
<bodyText confidence="0.948773">
So the expected utility of a document or word label
query, qj, can be computed as
</bodyText>
<equation confidence="0.998619">
∂L
∂S
EU(qj) = XK P(qj = ck)U(qj = ck), (9) EU(qj) = XK P(qj = k) * (−RE(qj = k)). (13)
k=1 k=1
</equation>
<bodyText confidence="0.9998355">
where K is the class number, P(qj = ck) indicates
the probability that qj, j-th query (a word or docu-
ment), belongs to the k-th class, and the U(qj = ck)
indicates the utility that qj belongs to the k-th class.
However, the choice of the utility measure is still a
challenge.
</bodyText>
<subsectionHeader confidence="0.999744">
5.2 Reconstruction Error
</subsectionHeader>
<bodyText confidence="0.999931">
In our matrix factorization framework, rows and
columns are treated equally in estimating the errors
of matrix factorization, and the reconstruction error
is thus a natural measure of utility. Let the current
supervision knowledge be G0, F0. To select a new
unlabeled document/word for labeling, we assume
To calculate the P(qj = k), which is the posterior
distribution for words or documents, probabilistic
interpretation of Tri-NMF is abused. When a query
qj is a word, P(qj = k) is
</bodyText>
<equation confidence="0.8178968">
P(zw = k|w = wi)
a P(w = wi|zw = k) PKj=1 P(zw = k, zd = j)
= Fik * PK j=1 Skj,
otherwise,
P(zd = k|d = di)
</equation>
<bodyText confidence="0.830334">
a P(d = di|zd = k) PKj=1 P(zw = j, zd = k)
= Gik * PK j=1 Sjk.
</bodyText>
<page confidence="0.993965">
953
</page>
<subsectionHeader confidence="0.975601">
5.3 Algorithm Description
</subsectionHeader>
<bodyText confidence="0.993082352941176">
Computational Improvement: It can be computa-
tionally intensive if the reconstruction error is com-
puted for all unknown documents and words. In-
spired by (Attenberg et al., 2010), we first select the
top 100 unknown words that the current model is
most certain about, and the top 100 unknown docu-
ments that the current model is most uncertain about.
Then we identify the words or documents in this
pool with the highest expected utility (reconstruc-
tion error). Equations 14 and 15 are used to perform
the initial selection of top 100 unknown words and
top 100 unknown documents.
Algorithm 1 Active Dual Supervision Algorithm
Based on Matrix Factorization
INPUT: X, document-word matrix; F0, current la-
beled words; G0, current labeled documents; O, the
oracle
</bodyText>
<listItem confidence="0.852852">
OUTPUT: G, classification result for all documents
in X
1. Get base factorization of X: G, 5, F.
2. Active dual supervision
</listItem>
<bodyText confidence="0.82035775">
repeat
D is the set of top 100 unlabeled documents
with most uncertainty;
W is the set of top 100 unlabeled words with
</bodyText>
<equation confidence="0.797501">
most certainty;
Q=DUW;
for all q E Q do
fork= 1toKdo
Get G∗q=k, F∗q=k, 5∗q=k by Equation 10 or
Equation 11 according to whether the
query q is a document or a word;
Calculate EU(q) by Equation 13;
q* = arg maxq EU(q);
Acquire new label of q∗, l from O;
G, F, 5 = G∗q*=l, F∗q*=l, 5∗q*=l;
</equation>
<bodyText confidence="0.989769227272727">
until stop criterion is met.
The overall algorithm procedure is described in
Algorithm 1. First we iteratively use the updat-
ing rules of Equation 7 to obtain the factoriza-
tion G, F, 5 based on initial labeled documents and
words. Then to select a new query, for each unla-
beled document or word in the pool and for each
possible class, we compute the reconstruction error
with new supervision (using the current factoriza-
tion results as initialization values). It is efficient to
compute a new factorization due to the sparsity of
the matrices. The document-term matrix is typically
very sparse with z « nm non-zero entries while k is
typically also much smaller than document number
n, and word number m. By using sparse matrix mul-
tiplications and avoiding dense intermediate matri-
ces, updating F, 5, G each takes O(k2(m+n)+kz)
time per iteration which scales linearly with the di-
mensions and density of the data matrix (Li et al.,
2009). Empirically, the number of iterations that is
needed to compute the new factorization is usually
very small (less than 10).
</bodyText>
<sectionHeader confidence="0.999872" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<subsectionHeader confidence="0.995197">
6.1 Experiments Settings
</subsectionHeader>
<bodyText confidence="0.999938321428571">
Three popular binary text classification datasets are
used in the experiments: ibm-mac (1937 examples),
baseball-hockey (1988 examples) and med-space
(1972 examples) datasets. All of them are drawn
from the 20-newsgroups text collection) where the
task is to assign messages into the newsgroup in
which they appeared. Top 1500 frequent words in
each dataset are used as features in the binary vec-
tor representation. These datasets have labels for all
the documents. For a document query, the oracle re-
turns its label. We construct the word oracle in the
same manner as in (Sindhwani et al., 2009): first
compute the information gain of words with respect
to the known true class labels in the training splits of
a dataset, and then the top 100 words as ranked by
information gain are assigned the label which is the
class in which the word appears more frequently. To
those words with labels, the word oracle returns its
label; otherwise, the oracle returns a “don’t know”
response (no word label is obtained for learning, but
the word is excluded from the following query se-
lection).
Results are averaged over 10 random training-
test splits. For each split, 30% examples are used
for testing. All methods are initialized by a ran-
dom choice of 10 document labels and 10 word la-
bels. For simplicity, we follow the widely used cost
model (Raghavan and Allan, 2007; Druck et al.,
</bodyText>
<footnote confidence="0.89052">
lhttp://www.ai.mit.edu/people/jrennie/
20_newsgroups/
</footnote>
<page confidence="0.998079">
954
</page>
<bodyText confidence="0.994362">
2008; Sindhwani et al., 2009) where features are
roughly 5 times cheaper to label than examples, so
we assume the cost is 1 for a word query and is 5 for
a document query. We set α = 6 = 5, -y = 1 for all
the following experiments2.
</bodyText>
<figure confidence="0.9866315">
#labeled documents-#labeled words
(b) ibm-mac
#labeled documents-#labeled words
(c) med-space
</figure>
<figureCaption confidence="0.997258">
Figure 1: Comparing the performance of dual supervision
via Tri-NMF w/ and w/o the constraint on S.
</figureCaption>
<bodyText confidence="0.483236">
2We do not perform fine tuning on the parameters since the
main objective of the paper is to demonstrate the effectiveness
of matrix factorization based methods for dual active supervi-
sion. A vigorous investigation on the parameter choices is our
further work.
</bodyText>
<subsectionHeader confidence="0.995507">
6.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.969267488888889">
Effect of Constraints on S in Constrained Tri-
NMF Figure 1 demonstrates the effectiveness of
dual supervision with explicit class alignment via
Tri-NMF as described in Section 4. When there
are enough labeled documents and words, the con-
straints on S have a relative small impact on the per-
formance of dual supervision. However, in the be-
ginning phase of active learning, the labeled dataset
can be small (such as 10 labeled documents and 10
labeled words). In this case, without the constraint
of S, the matrix factorization may generate incorrect
class alignment, thus lead to almost random classi-
fication results (around 50% accuracy), as shown in
Figure 1, and further make unreasonable the follow-
ing evaluation of queries.
Comparing Query Selection Approaches Figure
2 compares our proposed unified scheme (denoted as
Expected-reconstruction-error) with the following
baselines using Tri-NMF as the classifier for dual
supervision: (1). Interleaved-uncertainty which
first selects feature query by certainty and sample
query by uncertainty and then combines the two
types of queries using an interleaving scheme. The
interleaving probability (probability to select the
query as a document) is set as 0.2, 0.4, 0.6 and
0.8. (2). Expected-log-gain which selects feature
and sample query by maximizing the expected log
gain. Expected-reconstruction-error outperforms
interleaving schemes with all the different interleav-
ing probability values with which we experimented.
It also has a better performance than Expected-log-
gain. Although log gain is a finer-grained utility
measure of classifier performance than accuracy and
has a good performance in the setting with a large set
of starting labeled documents (e.g., 100 documents),
it is not reliable especially in the setting with a small
set of labeled data. Different from the Expected-log-
gain, Expected-reconstruction-error estimates the
utility using the matrix reconstruction error, making
use of information of all documents and words, in-
cluding those unlabeled.
Comparing Interleaving Scheme vs. the Uni-
fied Scheme To further demonstrate the benefit
of the proposed unified scheme , we compare it
with its interleaved version: Interleaved-expected-
</bodyText>
<figure confidence="0.994450952941177">
Accuracy
Accuracy
0.75
0.65
0.55
0.45
0.85
0.75
0.65
0.55
0.8
0.7
0.6
0.5
0.8
0.7
0.6
0.5
w/o. constraint on S
w/. constraint on S
w/o. constraint on S
w/. constraint on S
(a) baseball-hockey
#labeled documents-#labeled words
Accuracy
0.75
0.65
0.55
0.7
0.6
0.5
w/o. constraint on S
w/. constraint on S
955
Accuracy
0.84
0.82
0.8
0.78
0.76
0.74
0.72
0.7
0 100 200 300 400 500 600 700 800
Labeling Cost
(a) baseball-hockey
0 100 200 300 400 500 600 700 800
Labeling Cost
(b) ibm-mac
0 100 200 300 400 500 600 700 800
Labeling Cost
(c) med-space
Expected-log-gain
Interleaved-uncertainty-0.2
Interleaved-uncertainty-0.4
Interleaved-uncertainty-0.6
Interleaved-uncertainty-0.8
Expected-reconstruction-error
Expected-log-gain
Interleaved-uncertainty-0.2
Interleaved-uncertainty-0.4
Interleaved-uncertainty-0.6
Interleaved-uncertainty-0.8
Expected-reconstruction-error
Accuracy 0.82
0.8
0.78
0.76
0.74
0.72
0.7
Accuracy 0.7
0.68
0.66
0.64
0.62
0.6
0.58
0.56
Expected-log-gain
Interleaved-uncertainty-0.2
Interleaved-uncertainty-0.4
Interleaved-uncertainty-0.6
Interleaved-uncertainty-0.8
Expected-reconstruction-error
</figure>
<figureCaption confidence="0.97589">
Figure 2: Comparing the different query selection approaches in active learning via Tri-NMF with dual supervision.
</figureCaption>
<figure confidence="0.999926081632653">
Accuracy
0.84
0.82
0.8
0.78
0.76
0.74
0.72
0.7
0 100 200 300 400 500 600 700 800
Labeling Cost
(a) baseball-hockey
0 100 200 300 400 500 600 700 800
Labeling Cost
(b) ibm-mac
0 100 200 300 400 500 600 700 800
Labeling Cost
(c) med-space
Interleaved-expected-reconstruction-error-0.2
Interleaved-expected-reconstruction-error-0.4
Interleaved-expected-reconstruction-error-0.6
Interleaved-expected-reconstruction-error-0.8
Expected-reconstruction-error
Accuracy 0.82
0.8
0.78
0.76
0.74
0.72
0.7
0.68
Accuracy 0.7
0.68
0.66
0.64
0.62
0.6
0.58
0.56
Interleaved-expected-reconstruction-error-0.2
Interleaved-expected-reconstruction-error-0.4
Interleaved-expected-reconstruction-error-0.6
Interleaved-expected-reconstruction-error-0.8
Expected-reconstruction-error
Interleaved-expected-reconstruction-error-0.2
Interleaved-expected-reconstruction-error-0.4
Interleaved-expected-reconstruction-error-0.6
Interleaved-expected-reconstruction-error-0.8
Expected-reconstruction-error
</figure>
<figureCaption confidence="0.999966">
Figure 3: Comparing the unified and interleaving scheme based on reconstruction error.
</figureCaption>
<bodyText confidence="0.99996684">
construction-error which computes the utility of a
query using the reconstruction error, but uses inter-
leaving scheme to decide which type of query to
select. We experiment with different interleaving
probability values ranging from 0.2 to 0.8, which
lead to quite different performance results. From
Figure 3, the optimal interleaving probability value
varies on different datasets. For example, the proba-
bility value of 0.8 is among the optimal interleaving
probability values on baseball-hockey dataset but
performs poorly on ibm-mac dataset. This obser-
vation also illustrates the need for a unified scheme,
because of the difficulty in choosing the optimal in-
terleaving probability value. Although the proposed
unified scheme is not significantly better than its in-
terleaving counterparts for all interleaving probabil-
ity values on all datasets, it avoids the bad choices.
Figure 5 presents the sequence of different query
types selected by our unified scheme and it clearly
demonstrates the distribution patterns of different
query types. At the beginning phase of active learn-
ing, word queries have much higher probabilities to
be selected, which is consistent with the result of
previous work: feature labels can be more effec-
tive than examples in text classification (Druck et
</bodyText>
<figure confidence="0.975739833333333">
50 100 150 200 250 300
Query Sequence
(a) baseball-hockey
50 100 150 200 250 300
Query Sequence
(b) ibm-mac
</figure>
<figureCaption confidence="0.99999">
Figure 5: Example of query sequence.
</figureCaption>
<bodyText confidence="0.9801636">
al., 2008). And in the later learning phase, docu-
ments are more likely to be selected, since the num-
ber of words that can benefit the classification is
much smaller than the effective documents.
Reconstruction Error vs. Interleaving uncer-
tainty using GRADS It should be pointed out that
our unified scheme for query selection based on re-
construction error does not rely on the estimation
of model performance on training data and can be
easily integrated with other dual supervision mod-
</bodyText>
<figure confidence="0.994916296296296">
Query Type
Document
Word
Query Type
Document
Word
956
0.84
0.82
0.8
0.78
0.76
Accuracy
0.74
0.72
0.7
0.68
0.66
0.64
0.62
0.93
0.92
0.91
Accuracy
0.9
0.89
0.88
0.87
0.86
GRADS-Interleaving-0.5
GRADS-Reconstruction-Error
GRADS-Interleaving-0.5
GRADS-Reconstruction-Error
Accuracy
0.94
0.91
0.93
0.92
0.9
0.89
0.88
0.87
0.86
GRADS-Interleaving-0.5
GRADS-Reconstruction-Error
0 100 200 300 400 500 600 700 800
Labeling Cost
(a) baseball-hockey
0 100 200 300 400 500 600 700 800
Labeling Cost
(b) ibm-mac
0 100 200 300 400 500 600 700 800
Labeling Cost
(c) med-space
</figure>
<figureCaption confidence="0.999944">
Figure 4: GRADS with reconstruction error and interleaving uncertainty.
</figureCaption>
<bodyText confidence="0.999843666666667">
els such as GRADS (Sindhwani et al., 2008). Fig-
ure 4 shows the comparison of GRADS using the
interleaved scheme with an interleaving probability
of 0.5, and using our unified scheme based on recon-
struction error. Among the 3 datasets we used, the
reconstruction error based approach outperforms the
interleaving scheme on baseball-hockey and ibm-
mac, and has similar performance with the interleav-
ing scheme on med-space.
</bodyText>
<figure confidence="0.9558075">
0 100 200 300 400 500 600 700 800
Labeling Cost
</figure>
<figureCaption confidence="0.997446">
Figure 6: Comparing active dual supervision using ma-
trix factorization with GRADS on sentiment analysis.
</figureCaption>
<bodyText confidence="0.987113111111111">
Comparing Active Dual Supervision Using Ma-
trix Factorization with GRADS on Sentiment
Analysis The sentiment analysis experiment is
conducted on the movies review dataset (Pang et al.,
2002), containing 1000 positive and 1000 negative
movie reviews. The results are shown in Figure 6.
The experimental results clearly demonstrate the ef-
fectiveness of our approach, denoted as Tri-NMF-
Reconstruction-Error.
</bodyText>
<sectionHeader confidence="0.998759" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.9999761">
In this paper, we study the problem of active dual
supervision, and propose a matrix tri-factorization
based approach to address the issue, how to evaluate
labeling benifit of different types of queries (exam-
ples or features) in the same scale. Following ex-
tending the nonnegative matrix tri-factorization to
the active dual supervision setting, we use the recon-
struction error to evaluate the value of feature and
example labels. Experimental results show that our
proposed approach outperforms existing methods.
</bodyText>
<sectionHeader confidence="0.946046" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9996634">
The work is partially supported by NSF grants
DMS-0915110, CCF-0830659, and HRD-0833093.
We would like to thank Dr. Vikas Sindhwani for
his insightful discussions and for sharing us with his
GRADS code.
</bodyText>
<sectionHeader confidence="0.997831" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995590066666666">
J. Attenberg, P. Melville, and F. Provost. 2010. A Uni-
fied Approach to Active Dual Supervision for Label-
ing Features and Examples. Machine Learning and
Knowledge Discovery in Databases, pages 40–55.
D. Cohn, L. Atlas, and R. Ladner. 1994. Improving gen-
eralization with active learning. Machine Learning,
15(2):201–221.
I.S. Dhillon. 2001. Co-clustering documents and words
using bipartite spectral graph partitioning. In Pro-
ceedings of the seventh ACM SIGKDD international
conference on Knowledge discovery and data mining,
pages 269–274. ACM.
C. Ding, T. Li, W. Peng, and H. Park. 2006. Orthogonal
nonnegative matrix t-factorizations for clustering. In
Proceedings of the 12th ACM SIGKDD international
</reference>
<figure confidence="0.998018083333333">
Accuracy
0.75
0.65
0.55
0.7
0.6
0.5
GRADS-Interleaving-0.2
GRADS-Interleaving-0.4
GRADS-Interleaving-0.6
GRADS-Interleaving-0.8
Tri-NMF-Reconstruction-Error
</figure>
<page confidence="0.943132">
957
</page>
<reference confidence="0.996600776699029">
conference on Knowledge discovery and data mining,
pages 126–135. ACM.
C. Ding, T. Li, and W. Peng. 2008. On the equiva-
lence between non-negative matrix factorization and
probabilistic latent semantic indexing. Computational
Statistics &amp; Data Analysis, 52(8):3913–3927.
G. Druck, G. Mann, and A. McCallum. 2008. Learn-
ing from labeled features using generalized expecta-
tion criteria. In Proceedings of the 31st annual in-
ternational ACM SIGIR conference on Research and
development in information retrieval, pages 595–602.
ACM.
G. Druck, B. Settles, and A. McCallum. 2009. Active
learning by labeling features. In Proceedings of the
2009 conference on Empirical methods in natural lan-
guage processing, pages 81–90. Association for Com-
putational Linguistics.
S. Godbole, A. Harpale, S. Sarawagi, and S. Chakrabarti.
2004. Document classification through interactive su-
pervision of document and term labels. Knowledge
Discovery in Databases: PKDD 2004, pages 185–196.
D.D. Lee and H.S. Seung. 2001. Algorithms for non-
negative matrix factorization. Advances in neural in-
formation processing systems, 13.
T. Li, Y. Zhang, and V. Sindhwani. 2009. A non-negative
matrix tri-factorization approach to sentiment classifi-
cation with lexical prior knowledge. In Proceedings of
the Joint Conference of the 47th Annual Meeting of the
ACL, pages 244–252. Association for Computational
Linguistics.
A.K. McCallum and K. Nigam. 1998. Employing EM
and pool-based active learning for text classification.
In Proceedings of the Fifteenth International Confer-
ence on Machine Learning. Citeseer.
P. Melville and V. Sindhwani. 2009. Active dual su-
pervision: Reducing the cost of annotating examples
and features. In Proceedings of the NAACL HLT 2009
Workshop on Active Learning for Natural Language
Processing, pages 49–57. Association for Computa-
tional Linguistics.
P. Melville, M. Saar-Tsechansky, F. Provost, and
R. Mooney. 2005. An expected utility approach to
active feature-value acquisition. In Proceedings of
Fifth IEEE International Conference on Data Mining.
IEEE.
P. Melville, W. Gryc, and R.D. Lawrence. 2009. Senti-
ment analysis of blogs by combining lexical knowl-
edge with text classification. In Proceedings of
the 15th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 1275–
1284. ACM.
B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs
up?: sentiment classification using machine learning
techniques. In Proceedings of the 2002 conference
on Empirical methods in natural language processing,
pages 79–86. Association for Computational Linguis-
tics.
H. Raghavan and J. Allan. 2007. An interactive algo-
rithm for asking and incorporating feature feedback
into support vector machines. In Proceedings of the
30th annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 79–86. ACM.
H. Raghavan, O. Madani, and R. Jones. 2006. Active
learning with feedback on features and instances. The
Journal of Machine Learning Research, 7:1655–1686.
T. Sandler, P.P. Talukdar, L.H. Ungar, and J. Blitzer.
2008. Regularized learning with networks of features.
Advances in Neural Information Processing Systems,
pages 1401–1408.
B. Settles. 2009. Active Learning Literature Survey.
Technical Report 1648.
C. Shen, T. Li, and C. Ding. 2011. Integrating Clustering
and Multi-Document Summarization by Bi-mixture
Probabilistic Latent Semantic Analysis (PLSA) with
Sentence Bases. In Proceedings of the national con-
ference on Artificial intelligence. AAAI Press.
V. Sindhwani and P. Melville. 2008. Document-word
co-regularization for semi-supervised sentiment anal-
ysis. In Data Mining, Eighth IEEE International Con-
ference on, pages 1025–1030. IEEE.
V. Sindhwani, J. Hu, and A. Mojsilovic. 2008. Regular-
ized co-clustering with dual supervision. Advances in
Neural Information Processing Systems, 21.
V. Sindhwani, P. Melville, and R.D. Lawrence. 2009.
Uncertainty sampling and transductive experimental
design for active dual supervision. In Proceedings of
the 26th Annual International Conference on Machine
Learning, pages 953–960. ACM.
S. Tong and D. Koller. 2002. Support vector machine
active learning with applications to text classification.
The Journal of Machine Learning Research, 2:45–66.
Omar F. Zaidan and Jason Eisner. 2008. Modeling anno-
tators: A generative approach to learning from annota-
tor rationales. In Proceedings of the 2008 conference
on Empirical methods in natural language processing,
pages 31–40. Association for Computational Linguis-
tics, October.
H. Zha, X. He, C. Ding, H. Simon, and M. Gu. 2001. Bi-
partite graph partitioning and data clustering. In Pro-
ceedings of the tenth international conference on In-
formation and knowledge management, pages 25–32.
ACM.
</reference>
<page confidence="0.997078">
958
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.968665">
<title confidence="0.997648">A Non-negative Matrix Factorization Based Approach for Active Supervision from Document and Word Labels</title>
<author confidence="0.997602">Shen</author>
<affiliation confidence="0.998724">School of Computing and Information Florida International</affiliation>
<address confidence="0.998742">Miami, FL 33199</address>
<abstract confidence="0.998818611111111">In active dual supervision, not only informative examples but also features are selected for labeling to build a high quality classifier with low cost. However, how to measure the informativeness for both examples and feature on the same scale has not been well solved. In this paper, we propose a non-negative matrix factorization based approach to address this issue. We first extend the matrix factorization framework to explicitly model the corresponding relationships between feature classes and examples classes. Then by making use of the reconstruction error, we propose a unified scheme to determine which feature or example a classifier is most likely to benefit from having labeled. Empirical results demonstrate the effectiveness of our proposed methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Attenberg</author>
<author>P Melville</author>
<author>F Provost</author>
</authors>
<title>A Unified Approach to Active Dual Supervision for Labeling Features and Examples. Machine Learning and Knowledge Discovery in Databases,</title>
<date>2010</date>
<pages>40--55</pages>
<contexts>
<context position="7872" citStr="Attenberg et al., 2010" startWordPosition="1209" endWordPosition="1212">e learning via feature labeling using several uncertainty reduction heuristics using the learning model developed in (Druck et al., 2008). (Sindhwani et al., 2009) studied the problem of active dual supervision from examples and features using a graph-based dual supervision method with a simple probabilistic method for interleaving feature labels and example labels. In our work, we develop our active dual supervision framework using constrained non-negative tri-factorization and also propose a unified scheme to evaluate the value of feature and example labels. We note the very recent work of (Attenberg et al., 2010), which proposes a unified approach for the dual active learning problem using expected utility where the utility is defined as the log gain of the classification model with a new labeled document or word. Conceptually, our proposed unified scheme is a special case of the expected utility framework where the utility is computed using the matrix reconstruction error. The utility based on the log gain of the classification 950 model may not be reliable as small model changes resulted from a single additional example label or feature label may not be reflected in the classification performance (A</context>
<context position="16448" citStr="Attenberg et al., 2010" startWordPosition="2721" endWordPosition="2724">hich is equivalent with the update rule of S in Equation 7. 5 A Unified Scheme for Query Selection Using the Reconstruction Error 5.1 Introduction An ideal active dual supervision scheme should be able to evaluate the value of acquiring labels for documents and words on the same scale. In the initial study of dual active supervision, different scores are used for documents and words (e.g. uncertainty for documents and certainty for words), and thus they are not on the same scale (Sindhwani et al., 2009). Recently, the framework of Expected Utility (Estimated Risk Minimization) is proposed in (Attenberg et al., 2010). At each step of the framework, the next word or document selected for labeling is the one that will result in the highest estimated improvement in classifier performance as defined as: that a good supervision should lead to a good constrained factorization for the document-term matrix, X Pz GSFT . If the new query qj is a word and its label is k, then the new factorization is G∗ j=k, S∗j=k, F∗j=k = arg minG,S,F IIX − GSFT II2 + α trace[(G − G0)TC2(G − G0)] + β trace[(F − F0,j=k)TC1(F − F0,j=k)] + γ trace[(S − S0)T (S − S0)], where F0,j=k is same as F0 except that F0,j=k(j, k) = 1. In other w</context>
<context position="18899" citStr="Attenberg et al., 2010" startWordPosition="3192" endWordPosition="3195">0. To select a new unlabeled document/word for labeling, we assume To calculate the P(qj = k), which is the posterior distribution for words or documents, probabilistic interpretation of Tri-NMF is abused. When a query qj is a word, P(qj = k) is P(zw = k|w = wi) a P(w = wi|zw = k) PKj=1 P(zw = k, zd = j) = Fik * PK j=1 Skj, otherwise, P(zd = k|d = di) a P(d = di|zd = k) PKj=1 P(zw = j, zd = k) = Gik * PK j=1 Sjk. 953 5.3 Algorithm Description Computational Improvement: It can be computationally intensive if the reconstruction error is computed for all unknown documents and words. Inspired by (Attenberg et al., 2010), we first select the top 100 unknown words that the current model is most certain about, and the top 100 unknown documents that the current model is most uncertain about. Then we identify the words or documents in this pool with the highest expected utility (reconstruction error). Equations 14 and 15 are used to perform the initial selection of top 100 unknown words and top 100 unknown documents. Algorithm 1 Active Dual Supervision Algorithm Based on Matrix Factorization INPUT: X, document-word matrix; F0, current labeled words; G0, current labeled documents; O, the oracle OUTPUT: G, classifi</context>
</contexts>
<marker>Attenberg, Melville, Provost, 2010</marker>
<rawString>J. Attenberg, P. Melville, and F. Provost. 2010. A Unified Approach to Active Dual Supervision for Labeling Features and Examples. Machine Learning and Knowledge Discovery in Databases, pages 40–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cohn</author>
<author>L Atlas</author>
<author>R Ladner</author>
</authors>
<title>Improving generalization with active learning.</title>
<date>1994</date>
<booktitle>Machine Learning,</booktitle>
<volume>15</volume>
<issue>2</issue>
<contexts>
<context position="6867" citStr="Cohn et al., 1994" startWordPosition="1055" endWordPosition="1058">ve matrix tri-factorization to active learning settings in Section 4, and propose a unified scheme for query selection in Section 5. Experiments are presented in Section 6, and finally Section 7 concludes the paper. 2 Related Work We point the reader to a recent report (Settles, 2009) for an in-depth survey on active learning. In this section, we briefly cover related work to position our contributions appropriately. Active Learning/Active Dual Supervision Most prior work in active learning has focused on pooledbased techniques, where examples from an unlabeled pool are selected for labeling (Cohn et al., 1994). With the study of learning from labeled features, many research efforts on active learning with feature supervision are also reported (Melville et al., 2005; Raghavan et al., 2006). (Godbole et al., 2004) proposed the notion of feature uncertainty and incorporated the acquired feature labels into learning by creating one-term mini-documents. (Druck et al., 2009) performed active learning via feature labeling using several uncertainty reduction heuristics using the learning model developed in (Druck et al., 2008). (Sindhwani et al., 2009) studied the problem of active dual supervision from ex</context>
</contexts>
<marker>Cohn, Atlas, Ladner, 1994</marker>
<rawString>D. Cohn, L. Atlas, and R. Ladner. 1994. Improving generalization with active learning. Machine Learning, 15(2):201–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I S Dhillon</author>
</authors>
<title>Co-clustering documents and words using bipartite spectral graph partitioning.</title>
<date>2001</date>
<booktitle>In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>269--274</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9324" citStr="Dhillon, 2001" startWordPosition="1440" endWordPosition="1441">ision (i.e., learning from both labeled examples and features) is the basis for active dual supervision. Dual supervision is a relatively new area of research and few methods have been developed for dual supervision. In (Sindhwani and Melville, 2008; Sindhwani et al., 2008), a bipartite graph regularization model (GRADS) is used to diffuse label information along both sides of the document-term matrix and to perform dual supervision for semi-supervised sentiment analysis. Conceptually, their model implements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective). In (Sandler et al., 2008), standard regularization models are constrained using graphs of word cooccurrences. In (Melville et al., 2009), Naive Bayes classifier is extended, where the parameters, the conditional word distributions given the classes, are estimated by combining multiple sources, e.g. document labels and word labels. Our work is based on the dual supervision framework using constrained non-negative tri-factorization. 3 Learning with Dual Supervision via Tri-NMF Our dual supervision model is based on nonnegative matrix tri-factori</context>
</contexts>
<marker>Dhillon, 2001</marker>
<rawString>I.S. Dhillon. 2001. Co-clustering documents and words using bipartite spectral graph partitioning. In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, pages 269–274. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Ding</author>
<author>T Li</author>
<author>W Peng</author>
<author>H Park</author>
</authors>
<title>Orthogonal nonnegative matrix t-factorizations for clustering.</title>
<date>2006</date>
<booktitle>In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>126--135</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="11801" citStr="Ding et al., 2006" startWordPosition="1888" endWordPosition="1891">ed, that is, the category of the i-th document is known and (C2)ii = 0 otherwise. The squared loss terms ensure that the solution for G, F in the otherwise unsupervised learning problem be close to the prior knowledge G0, F0. So the partial labels on documents and words can be described using G0 and F0, respectively. 4 Dual Supervision with Explicit Class Alignment 4.1 Modeling the Relationships between Word Classes and Document Classes In the solution to Equation 1, we have S = GT XF, or iERl jECk where |Rl |is the size of the l-th document class, and |Ck |is the size of the k-th word class (Ding et al., 2006). Note that Slk represents properly normalized within-class sum of weights (l = k) and betweenclass sum of weights (l =� k). So, S represents the relationship between the classes over documents and the classes over words. Under the assumption that the i-th document class should correspond to the ith word class, S should be an approximate diagonal matrix, since the documents of i-th class is more likely to contain the words of the i-th class. Note /1 / Slk = 9&apos;Tl Xfk = |Rl|1 2|CkI1 2 Xij, 951 that S is not an exact diagonal matrix, since a document of one class apparently can use words from oth</context>
</contexts>
<marker>Ding, Li, Peng, Park, 2006</marker>
<rawString>C. Ding, T. Li, W. Peng, and H. Park. 2006. Orthogonal nonnegative matrix t-factorizations for clustering. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 126–135. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Ding</author>
<author>T Li</author>
<author>W Peng</author>
</authors>
<title>On the equivalence between non-negative matrix factorization and probabilistic latent semantic indexing.</title>
<date>2008</date>
<journal>Computational Statistics &amp; Data Analysis,</journal>
<volume>52</volume>
<issue>8</issue>
<contexts>
<context position="13469" citStr="Ding et al., 2008" startWordPosition="2184" endWordPosition="2187">n ill-formed S, leading to an incorrect alignment of word classes and document classes. To explicitly model the relationships between word classes and document classes, we constrain the shape of S via an extra loss term in the objective function as follows: minF,G,S kX − GSFT k2 +α trace[(F − F0)T C1(F − F0)] +β trace[(G − G0)TC2(G − G0)] +γ trace[(S − S0)T (S − S0)] (3) where S0 is a diagonal matrix. How to Choose S0 If there is no orthogonal constraint on F, G and I-divergence is used as the objective function, it can been shown that the factors of Tri-NMF have probabilistic interpretation (Ding et al., 2008; Shen et al., 2011): Fil = P(w = wi|zw = l), Gjk = P(d = dj|zd = k), (4) Skl = P(zd = k,zw = l), where w is word variable, d is document variable, and zw, zd are random variables indicating word class and document class respectively. F and G represent posterior distributions for words and documents, and S represents the joint distribution of document class and word class. With such an interpretation, S0 can be easily decided in balanced classification problems with each diagonal entry equals to one over the number of classes. However, in our setting of Tri-NMF, orthogonal constraints are enfo</context>
</contexts>
<marker>Ding, Li, Peng, 2008</marker>
<rawString>C. Ding, T. Li, and W. Peng. 2008. On the equivalence between non-negative matrix factorization and probabilistic latent semantic indexing. Computational Statistics &amp; Data Analysis, 52(8):3913–3927.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Druck</author>
<author>G Mann</author>
<author>A McCallum</author>
</authors>
<title>Learning from labeled features using generalized expectation criteria.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>595--602</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2136" citStr="Druck et al., 2008" startWordPosition="320" endWordPosition="323">a is generally represented as documentword matrices, human supervision can be obtained on both documents and words. For example, in sentiment analysis of product reviews, human labelers can label reviews as positive or negative, they can also label the words that elicit positive sentiment (such as “sensational” and “electrifying”) as positive and words that evoke negative sentiment (such as “depressed” and “unfulfilling”) as negative. Recent work has demonstrated that labeled words (or feature supervision) can greatly reduce the number of labeled samples for building high-quality classifiers (Druck et al., 2008; Zaidan and Eisner, 2008). In fact, different kinds of supervision generally have different acquisition costs, different degrees of utility and are not mutually redundant (Sindhwani et al., 2009). Ideally, effective active learning schemes should be able to utilize different forms of supervision. To incorporate the supervision on words and documents at same time into the active learning scheme, recently an active dual supervision (or dual active learning) has been proposed (Melville and Sindhwani, 2009; Sindhwani et al., 2009). Comparing with traditional active learning which aims to select t</context>
<context position="7386" citStr="Druck et al., 2008" startWordPosition="1132" endWordPosition="1135">ased techniques, where examples from an unlabeled pool are selected for labeling (Cohn et al., 1994). With the study of learning from labeled features, many research efforts on active learning with feature supervision are also reported (Melville et al., 2005; Raghavan et al., 2006). (Godbole et al., 2004) proposed the notion of feature uncertainty and incorporated the acquired feature labels into learning by creating one-term mini-documents. (Druck et al., 2009) performed active learning via feature labeling using several uncertainty reduction heuristics using the learning model developed in (Druck et al., 2008). (Sindhwani et al., 2009) studied the problem of active dual supervision from examples and features using a graph-based dual supervision method with a simple probabilistic method for interleaving feature labels and example labels. In our work, we develop our active dual supervision framework using constrained non-negative tri-factorization and also propose a unified scheme to evaluate the value of feature and example labels. We note the very recent work of (Attenberg et al., 2010), which proposes a unified approach for the dual active learning problem using expected utility where the utility </context>
</contexts>
<marker>Druck, Mann, McCallum, 2008</marker>
<rawString>G. Druck, G. Mann, and A. McCallum. 2008. Learning from labeled features using generalized expectation criteria. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pages 595–602. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Druck</author>
<author>B Settles</author>
<author>A McCallum</author>
</authors>
<title>Active learning by labeling features.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 conference on Empirical methods in natural language processing,</booktitle>
<pages>81--90</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7233" citStr="Druck et al., 2009" startWordPosition="1111" endWordPosition="1114">lated work to position our contributions appropriately. Active Learning/Active Dual Supervision Most prior work in active learning has focused on pooledbased techniques, where examples from an unlabeled pool are selected for labeling (Cohn et al., 1994). With the study of learning from labeled features, many research efforts on active learning with feature supervision are also reported (Melville et al., 2005; Raghavan et al., 2006). (Godbole et al., 2004) proposed the notion of feature uncertainty and incorporated the acquired feature labels into learning by creating one-term mini-documents. (Druck et al., 2009) performed active learning via feature labeling using several uncertainty reduction heuristics using the learning model developed in (Druck et al., 2008). (Sindhwani et al., 2009) studied the problem of active dual supervision from examples and features using a graph-based dual supervision method with a simple probabilistic method for interleaving feature labels and example labels. In our work, we develop our active dual supervision framework using constrained non-negative tri-factorization and also propose a unified scheme to evaluate the value of feature and example labels. We note the very </context>
</contexts>
<marker>Druck, Settles, McCallum, 2009</marker>
<rawString>G. Druck, B. Settles, and A. McCallum. 2009. Active learning by labeling features. In Proceedings of the 2009 conference on Empirical methods in natural language processing, pages 81–90. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Godbole</author>
<author>A Harpale</author>
<author>S Sarawagi</author>
<author>S Chakrabarti</author>
</authors>
<title>Document classification through interactive supervision of document and term labels. Knowledge Discovery in Databases: PKDD</title>
<date>2004</date>
<pages>185--196</pages>
<contexts>
<context position="7073" citStr="Godbole et al., 2004" startWordPosition="1088" endWordPosition="1091">s the paper. 2 Related Work We point the reader to a recent report (Settles, 2009) for an in-depth survey on active learning. In this section, we briefly cover related work to position our contributions appropriately. Active Learning/Active Dual Supervision Most prior work in active learning has focused on pooledbased techniques, where examples from an unlabeled pool are selected for labeling (Cohn et al., 1994). With the study of learning from labeled features, many research efforts on active learning with feature supervision are also reported (Melville et al., 2005; Raghavan et al., 2006). (Godbole et al., 2004) proposed the notion of feature uncertainty and incorporated the acquired feature labels into learning by creating one-term mini-documents. (Druck et al., 2009) performed active learning via feature labeling using several uncertainty reduction heuristics using the learning model developed in (Druck et al., 2008). (Sindhwani et al., 2009) studied the problem of active dual supervision from examples and features using a graph-based dual supervision method with a simple probabilistic method for interleaving feature labels and example labels. In our work, we develop our active dual supervision fra</context>
</contexts>
<marker>Godbole, Harpale, Sarawagi, Chakrabarti, 2004</marker>
<rawString>S. Godbole, A. Harpale, S. Sarawagi, and S. Chakrabarti. 2004. Document classification through interactive supervision of document and term labels. Knowledge Discovery in Databases: PKDD 2004, pages 185–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Lee</author>
<author>H S Seung</author>
</authors>
<title>Algorithms for nonnegative matrix factorization. Advances in neural information processing systems,</title>
<date>2001</date>
<pages>13</pages>
<contexts>
<context position="15315" citStr="Lee and Seung, 2001" startWordPosition="2511" endWordPosition="2514">ng Algorithm This optimization problem can be solved using the following update rules Gjk ← Gjk (GGT XFS+βGGT C2G)jk , XFS+βC2G0 Sjk ← Sjk (FT FSGT G+γS)jk, FT XT G+γS0 Fjk ← Fjk XT GST +αC1F0 (FFT XT GST +αC1F)jk . The algorithm consists of an iterative procedure using the above three rules until convergence. Theorem 4.1 The above iterative algorithm converges. Theorem 4.2 At convergence, the solution satisfies the Karuch-Kuhn-Tucker (KKT) optimality condition, i.e., the algorithm converges correctly to a local optima. Theorem 4.1 can be proved using the standard auxiliary function approach (Lee and Seung, 2001). Proof of Theorem 4.2: Proof for the update rules of G, F is the same as in (Li et al., 2009). Here we focus on the update rule of S. We want to minimize L(S) = kX − GSFTk2 +αtrace[(F − F0)TC1(F − F0)] +β trace[(G − G0)TC2(G − G0)] +γ trace[(S − S0)T (S − S0)]. (5) 952 The gradient of L is = 2FT FSGT G − 2FT XT G + 2γ(S − S0) The KKT complementarity condition for the nonnegativity of Sjk gives [2FT FSGTG−2F TXT G+2γ(S−S0)]jkSjk = 0. This is the fixed point relation that local minima for S must satisfy, which is equivalent with the update rule of S in Equation 7. 5 A Unified Scheme for Query S</context>
</contexts>
<marker>Lee, Seung, 2001</marker>
<rawString>D.D. Lee and H.S. Seung. 2001. Algorithms for nonnegative matrix factorization. Advances in neural information processing systems, 13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Li</author>
<author>Y Zhang</author>
<author>V Sindhwani</author>
</authors>
<title>A non-negative matrix tri-factorization approach to sentiment classification with lexical prior knowledge.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL,</booktitle>
<pages>244--252</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4342" citStr="Li et al., 2009" startWordPosition="654" endWordPosition="657">009), a transductive bipartite graph regularization approach is used for learning from both labeled examples and features. In addition, uncertainty sampling and experimental design are used for selecting informative examples and features for labeling. To trade-off between different types of supervision, a simple probabilistic interleaving scheme where the active learner probabilistically queries the example oracle and the feature oracle is used. One problem in their method is that the values of acquiring the feature labels and the example labels are not on the same scale. Recently, Li et al. (Li et al., 2009) proposed a dual supervision method based on constrained nonnegative tri-factorization of the document-term matrix where the labeled features and examples are naturally incorporated as sets of constraints. Having a framework for incorporating dual-supervision based on matrix factorization, gives rise to the natural question of how to perform active dual supervision in this setting. Since rows and columns are treated equally in estimating the errors of matrix factorization, another question is can we address the scaling issue in comparing the value of feature labels and example labels. In this </context>
<context position="10521" citStr="Li et al., 2009" startWordPosition="1634" endWordPosition="1637"> matrix tri-factorization (Tri-NMF), where the non-negative input document-word matrix is approximated by 3 factor matrices as X Pz GSFT, in which, X is an nxm document-term matrix, G is an n x k non-negative orthogonal matrix representing the probability of generating a document from a document cluster, F is an m x k non-negative orthogonal matrix representing the probability of generating a word from a word cluster, and S is a k x k nonnegative matrix providing the relationship between document cluster space and word cluster space. While Tri-NMF is first applied in co-clustering, Li et al. (Li et al., 2009) extended it to incorporate labeled words and documents as dual supervision via two loss terms in the objective function of Tri-NMF as following: minF,G,S IIX − GSFT II2 +αtrace[(F − F0)TC1(F − F0)] +Otrace[(G − G0)TC2(G − G0)]. Here, α &gt; 0 is a parameter which determines the extent to which we enforce F Pz F0 to its labeled rows. C1 is a m x m diagonal matrix whose entry (C1)ii = 1 if the row of F0 is labeled, that is, the class of the i-th word is known and (C1)ii = 0 otherwise. 0 &gt; 0 is a parameter which determines the extent to which we enforce G Pz G0 to its labeled rows. C2 is a n x n di</context>
<context position="15409" citStr="Li et al., 2009" startWordPosition="2532" endWordPosition="2535">GT XFS+βGGT C2G)jk , XFS+βC2G0 Sjk ← Sjk (FT FSGT G+γS)jk, FT XT G+γS0 Fjk ← Fjk XT GST +αC1F0 (FFT XT GST +αC1F)jk . The algorithm consists of an iterative procedure using the above three rules until convergence. Theorem 4.1 The above iterative algorithm converges. Theorem 4.2 At convergence, the solution satisfies the Karuch-Kuhn-Tucker (KKT) optimality condition, i.e., the algorithm converges correctly to a local optima. Theorem 4.1 can be proved using the standard auxiliary function approach (Lee and Seung, 2001). Proof of Theorem 4.2: Proof for the update rules of G, F is the same as in (Li et al., 2009). Here we focus on the update rule of S. We want to minimize L(S) = kX − GSFTk2 +αtrace[(F − F0)TC1(F − F0)] +β trace[(G − G0)TC2(G − G0)] +γ trace[(S − S0)T (S − S0)]. (5) 952 The gradient of L is = 2FT FSGT G − 2FT XT G + 2γ(S − S0) The KKT complementarity condition for the nonnegativity of Sjk gives [2FT FSGTG−2F TXT G+2γ(S−S0)]jkSjk = 0. This is the fixed point relation that local minima for S must satisfy, which is equivalent with the update rule of S in Equation 7. 5 A Unified Scheme for Query Selection Using the Reconstruction Error 5.1 Introduction An ideal active dual supervision sche</context>
<context position="20947" citStr="Li et al., 2009" startWordPosition="3551" endWordPosition="3554">ssible class, we compute the reconstruction error with new supervision (using the current factorization results as initialization values). It is efficient to compute a new factorization due to the sparsity of the matrices. The document-term matrix is typically very sparse with z « nm non-zero entries while k is typically also much smaller than document number n, and word number m. By using sparse matrix multiplications and avoiding dense intermediate matrices, updating F, 5, G each takes O(k2(m+n)+kz) time per iteration which scales linearly with the dimensions and density of the data matrix (Li et al., 2009). Empirically, the number of iterations that is needed to compute the new factorization is usually very small (less than 10). 6 Experiments 6.1 Experiments Settings Three popular binary text classification datasets are used in the experiments: ibm-mac (1937 examples), baseball-hockey (1988 examples) and med-space (1972 examples) datasets. All of them are drawn from the 20-newsgroups text collection) where the task is to assign messages into the newsgroup in which they appeared. Top 1500 frequent words in each dataset are used as features in the binary vector representation. These datasets have</context>
</contexts>
<marker>Li, Zhang, Sindhwani, 2009</marker>
<rawString>T. Li, Y. Zhang, and V. Sindhwani. 2009. A non-negative matrix tri-factorization approach to sentiment classification with lexical prior knowledge. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL, pages 244–252. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K McCallum</author>
<author>K Nigam</author>
</authors>
<title>Employing EM and pool-based active learning for text classification.</title>
<date>1998</date>
<booktitle>In Proceedings of the Fifteenth International Conference on Machine Learning. Citeseer.</booktitle>
<contexts>
<context position="1299" citStr="McCallum and Nigam, 1998" startWordPosition="193" endWordPosition="196"> framework to explicitly model the corresponding relationships between feature classes and examples classes. Then by making use of the reconstruction error, we propose a unified scheme to determine which feature or example a classifier is most likely to benefit from having labeled. Empirical results demonstrate the effectiveness of our proposed methods. 1 Introduction Active learning, as an effective paradigm to optimize the learning benefit from domain experts’ feedback and to reduce the cost of acquiring labeled examples for supervised learning, has been intensively studied in recent years (McCallum and Nigam, 1998; Tong and Koller, 2002; Settles, 2009). Traditional approaches for active learning query the human experts to obtain the labels for intelligently chosen data samples. However, in text classification where the input data is generally represented as documentword matrices, human supervision can be obtained on both documents and words. For example, in sentiment analysis of product reviews, human labelers can label reviews as positive or negative, they can also label the words that elicit positive sentiment (such as “sensational” and “electrifying”) as positive and words that evoke negative sentim</context>
</contexts>
<marker>McCallum, Nigam, 1998</marker>
<rawString>A.K. McCallum and K. Nigam. 1998. Employing EM and pool-based active learning for text classification. In Proceedings of the Fifteenth International Conference on Machine Learning. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Melville</author>
<author>V Sindhwani</author>
</authors>
<title>Active dual supervision: Reducing the cost of annotating examples and features.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing,</booktitle>
<pages>49--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2644" citStr="Melville and Sindhwani, 2009" startWordPosition="397" endWordPosition="401"> supervision) can greatly reduce the number of labeled samples for building high-quality classifiers (Druck et al., 2008; Zaidan and Eisner, 2008). In fact, different kinds of supervision generally have different acquisition costs, different degrees of utility and are not mutually redundant (Sindhwani et al., 2009). Ideally, effective active learning schemes should be able to utilize different forms of supervision. To incorporate the supervision on words and documents at same time into the active learning scheme, recently an active dual supervision (or dual active learning) has been proposed (Melville and Sindhwani, 2009; Sindhwani et al., 2009). Comparing with traditional active learning which aims to select the most “informative” examples (e.g., documents) for domain experts to label, active dual supervision selects both the “informative” examples (e.g., documents) and features (e.g., words) for labeling. For active dual supervision to be effective, there are three important components: a) an underlying learning mechanism that is able to learn from both the labeled examples and features (i.e., incorporating supervision on both examples and features); b) methods for estimating the value of information for ex</context>
</contexts>
<marker>Melville, Sindhwani, 2009</marker>
<rawString>P. Melville and V. Sindhwani. 2009. Active dual supervision: Reducing the cost of annotating examples and features. In Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing, pages 49–57. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Melville</author>
<author>M Saar-Tsechansky</author>
<author>F Provost</author>
<author>R Mooney</author>
</authors>
<title>An expected utility approach to active feature-value acquisition.</title>
<date>2005</date>
<booktitle>In Proceedings of Fifth IEEE International Conference on Data Mining. IEEE.</booktitle>
<contexts>
<context position="7025" citStr="Melville et al., 2005" startWordPosition="1080" endWordPosition="1083">ted in Section 6, and finally Section 7 concludes the paper. 2 Related Work We point the reader to a recent report (Settles, 2009) for an in-depth survey on active learning. In this section, we briefly cover related work to position our contributions appropriately. Active Learning/Active Dual Supervision Most prior work in active learning has focused on pooledbased techniques, where examples from an unlabeled pool are selected for labeling (Cohn et al., 1994). With the study of learning from labeled features, many research efforts on active learning with feature supervision are also reported (Melville et al., 2005; Raghavan et al., 2006). (Godbole et al., 2004) proposed the notion of feature uncertainty and incorporated the acquired feature labels into learning by creating one-term mini-documents. (Druck et al., 2009) performed active learning via feature labeling using several uncertainty reduction heuristics using the learning model developed in (Druck et al., 2008). (Sindhwani et al., 2009) studied the problem of active dual supervision from examples and features using a graph-based dual supervision method with a simple probabilistic method for interleaving feature labels and example labels. In our </context>
</contexts>
<marker>Melville, Saar-Tsechansky, Provost, Mooney, 2005</marker>
<rawString>P. Melville, M. Saar-Tsechansky, F. Provost, and R. Mooney. 2005. An expected utility approach to active feature-value acquisition. In Proceedings of Fifth IEEE International Conference on Data Mining. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Melville</author>
<author>W Gryc</author>
<author>R D Lawrence</author>
</authors>
<title>Sentiment analysis of blogs by combining lexical knowledge with text classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>1275--1284</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9511" citStr="Melville et al., 2009" startWordPosition="1470" endWordPosition="1473">e been developed for dual supervision. In (Sindhwani and Melville, 2008; Sindhwani et al., 2008), a bipartite graph regularization model (GRADS) is used to diffuse label information along both sides of the document-term matrix and to perform dual supervision for semi-supervised sentiment analysis. Conceptually, their model implements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective). In (Sandler et al., 2008), standard regularization models are constrained using graphs of word cooccurrences. In (Melville et al., 2009), Naive Bayes classifier is extended, where the parameters, the conditional word distributions given the classes, are estimated by combining multiple sources, e.g. document labels and word labels. Our work is based on the dual supervision framework using constrained non-negative tri-factorization. 3 Learning with Dual Supervision via Tri-NMF Our dual supervision model is based on nonnegative matrix tri-factorization (Tri-NMF), where the non-negative input document-word matrix is approximated by 3 factor matrices as X Pz GSFT, in which, X is an nxm document-term matrix, G is an n x k non-negati</context>
</contexts>
<marker>Melville, Gryc, Lawrence, 2009</marker>
<rawString>P. Melville, W. Gryc, and R.D. Lawrence. 2009. Sentiment analysis of blogs by combining lexical knowledge with text classification. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1275– 1284. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 conference on Empirical methods in natural language processing,</booktitle>
<pages>79--86</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="31066" citStr="Pang et al., 2002" startWordPosition="5029" endWordPosition="5032">of 0.5, and using our unified scheme based on reconstruction error. Among the 3 datasets we used, the reconstruction error based approach outperforms the interleaving scheme on baseball-hockey and ibmmac, and has similar performance with the interleaving scheme on med-space. 0 100 200 300 400 500 600 700 800 Labeling Cost Figure 6: Comparing active dual supervision using matrix factorization with GRADS on sentiment analysis. Comparing Active Dual Supervision Using Matrix Factorization with GRADS on Sentiment Analysis The sentiment analysis experiment is conducted on the movies review dataset (Pang et al., 2002), containing 1000 positive and 1000 negative movie reviews. The results are shown in Figure 6. The experimental results clearly demonstrate the effectiveness of our approach, denoted as Tri-NMFReconstruction-Error. 7 Conclusions In this paper, we study the problem of active dual supervision, and propose a matrix tri-factorization based approach to address the issue, how to evaluate labeling benifit of different types of queries (examples or features) in the same scale. Following extending the nonnegative matrix tri-factorization to the active dual supervision setting, we use the reconstruction</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In Proceedings of the 2002 conference on Empirical methods in natural language processing, pages 79–86. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Raghavan</author>
<author>J Allan</author>
</authors>
<title>An interactive algorithm for asking and incorporating feature feedback into support vector machines.</title>
<date>2007</date>
<booktitle>In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>79--86</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="22472" citStr="Raghavan and Allan, 2007" startWordPosition="3806" endWordPosition="3809">top 100 words as ranked by information gain are assigned the label which is the class in which the word appears more frequently. To those words with labels, the word oracle returns its label; otherwise, the oracle returns a “don’t know” response (no word label is obtained for learning, but the word is excluded from the following query selection). Results are averaged over 10 random trainingtest splits. For each split, 30% examples are used for testing. All methods are initialized by a random choice of 10 document labels and 10 word labels. For simplicity, we follow the widely used cost model (Raghavan and Allan, 2007; Druck et al., lhttp://www.ai.mit.edu/people/jrennie/ 20_newsgroups/ 954 2008; Sindhwani et al., 2009) where features are roughly 5 times cheaper to label than examples, so we assume the cost is 1 for a word query and is 5 for a document query. We set α = 6 = 5, -y = 1 for all the following experiments2. #labeled documents-#labeled words (b) ibm-mac #labeled documents-#labeled words (c) med-space Figure 1: Comparing the performance of dual supervision via Tri-NMF w/ and w/o the constraint on S. 2We do not perform fine tuning on the parameters since the main objective of the paper is to demons</context>
</contexts>
<marker>Raghavan, Allan, 2007</marker>
<rawString>H. Raghavan and J. Allan. 2007. An interactive algorithm for asking and incorporating feature feedback into support vector machines. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, pages 79–86. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Raghavan</author>
<author>O Madani</author>
<author>R Jones</author>
</authors>
<title>Active learning with feedback on features and instances.</title>
<date>2006</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>7--1655</pages>
<contexts>
<context position="7049" citStr="Raghavan et al., 2006" startWordPosition="1084" endWordPosition="1087">inally Section 7 concludes the paper. 2 Related Work We point the reader to a recent report (Settles, 2009) for an in-depth survey on active learning. In this section, we briefly cover related work to position our contributions appropriately. Active Learning/Active Dual Supervision Most prior work in active learning has focused on pooledbased techniques, where examples from an unlabeled pool are selected for labeling (Cohn et al., 1994). With the study of learning from labeled features, many research efforts on active learning with feature supervision are also reported (Melville et al., 2005; Raghavan et al., 2006). (Godbole et al., 2004) proposed the notion of feature uncertainty and incorporated the acquired feature labels into learning by creating one-term mini-documents. (Druck et al., 2009) performed active learning via feature labeling using several uncertainty reduction heuristics using the learning model developed in (Druck et al., 2008). (Sindhwani et al., 2009) studied the problem of active dual supervision from examples and features using a graph-based dual supervision method with a simple probabilistic method for interleaving feature labels and example labels. In our work, we develop our act</context>
</contexts>
<marker>Raghavan, Madani, Jones, 2006</marker>
<rawString>H. Raghavan, O. Madani, and R. Jones. 2006. Active learning with feedback on features and instances. The Journal of Machine Learning Research, 7:1655–1686.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sandler</author>
<author>P P Talukdar</author>
<author>L H Ungar</author>
<author>J Blitzer</author>
</authors>
<title>Regularized learning with networks of features.</title>
<date>2008</date>
<booktitle>Advances in Neural Information Processing Systems,</booktitle>
<pages>1401--1408</pages>
<contexts>
<context position="9400" citStr="Sandler et al., 2008" startWordPosition="1453" endWordPosition="1456">e basis for active dual supervision. Dual supervision is a relatively new area of research and few methods have been developed for dual supervision. In (Sindhwani and Melville, 2008; Sindhwani et al., 2008), a bipartite graph regularization model (GRADS) is used to diffuse label information along both sides of the document-term matrix and to perform dual supervision for semi-supervised sentiment analysis. Conceptually, their model implements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective). In (Sandler et al., 2008), standard regularization models are constrained using graphs of word cooccurrences. In (Melville et al., 2009), Naive Bayes classifier is extended, where the parameters, the conditional word distributions given the classes, are estimated by combining multiple sources, e.g. document labels and word labels. Our work is based on the dual supervision framework using constrained non-negative tri-factorization. 3 Learning with Dual Supervision via Tri-NMF Our dual supervision model is based on nonnegative matrix tri-factorization (Tri-NMF), where the non-negative input document-word matrix is appro</context>
</contexts>
<marker>Sandler, Talukdar, Ungar, Blitzer, 2008</marker>
<rawString>T. Sandler, P.P. Talukdar, L.H. Ungar, and J. Blitzer. 2008. Regularized learning with networks of features. Advances in Neural Information Processing Systems, pages 1401–1408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Settles</author>
</authors>
<title>Active Learning Literature Survey.</title>
<date>2009</date>
<tech>Technical Report 1648.</tech>
<contexts>
<context position="1338" citStr="Settles, 2009" startWordPosition="201" endWordPosition="202">relationships between feature classes and examples classes. Then by making use of the reconstruction error, we propose a unified scheme to determine which feature or example a classifier is most likely to benefit from having labeled. Empirical results demonstrate the effectiveness of our proposed methods. 1 Introduction Active learning, as an effective paradigm to optimize the learning benefit from domain experts’ feedback and to reduce the cost of acquiring labeled examples for supervised learning, has been intensively studied in recent years (McCallum and Nigam, 1998; Tong and Koller, 2002; Settles, 2009). Traditional approaches for active learning query the human experts to obtain the labels for intelligently chosen data samples. However, in text classification where the input data is generally represented as documentword matrices, human supervision can be obtained on both documents and words. For example, in sentiment analysis of product reviews, human labelers can label reviews as positive or negative, they can also label the words that elicit positive sentiment (such as “sensational” and “electrifying”) as positive and words that evoke negative sentiment (such as “depressed” and “unfulfill</context>
<context position="6534" citStr="Settles, 2009" startWordPosition="1006" endWordPosition="1007">le selection for labeling) outperforms the interleaving schemes and the scheme based on expected log gain. The rest of this paper is organized as follows: the related work is discussed in Section 2, and the dual supervision framework based on non-negative matrix tri-factorization is introduced in Section 3. We extend non-negative matrix tri-factorization to active learning settings in Section 4, and propose a unified scheme for query selection in Section 5. Experiments are presented in Section 6, and finally Section 7 concludes the paper. 2 Related Work We point the reader to a recent report (Settles, 2009) for an in-depth survey on active learning. In this section, we briefly cover related work to position our contributions appropriately. Active Learning/Active Dual Supervision Most prior work in active learning has focused on pooledbased techniques, where examples from an unlabeled pool are selected for labeling (Cohn et al., 1994). With the study of learning from labeled features, many research efforts on active learning with feature supervision are also reported (Melville et al., 2005; Raghavan et al., 2006). (Godbole et al., 2004) proposed the notion of feature uncertainty and incorporated </context>
</contexts>
<marker>Settles, 2009</marker>
<rawString>B. Settles. 2009. Active Learning Literature Survey. Technical Report 1648.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Shen</author>
<author>T Li</author>
<author>C Ding</author>
</authors>
<title>Integrating Clustering and Multi-Document Summarization by Bi-mixture Probabilistic Latent Semantic Analysis (PLSA) with Sentence Bases.</title>
<date>2011</date>
<booktitle>In Proceedings of the national conference on Artificial intelligence.</booktitle>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="13489" citStr="Shen et al., 2011" startWordPosition="2188" endWordPosition="2191">ding to an incorrect alignment of word classes and document classes. To explicitly model the relationships between word classes and document classes, we constrain the shape of S via an extra loss term in the objective function as follows: minF,G,S kX − GSFT k2 +α trace[(F − F0)T C1(F − F0)] +β trace[(G − G0)TC2(G − G0)] +γ trace[(S − S0)T (S − S0)] (3) where S0 is a diagonal matrix. How to Choose S0 If there is no orthogonal constraint on F, G and I-divergence is used as the objective function, it can been shown that the factors of Tri-NMF have probabilistic interpretation (Ding et al., 2008; Shen et al., 2011): Fil = P(w = wi|zw = l), Gjk = P(d = dj|zd = k), (4) Skl = P(zd = k,zw = l), where w is word variable, d is document variable, and zw, zd are random variables indicating word class and document class respectively. F and G represent posterior distributions for words and documents, and S represents the joint distribution of document class and word class. With such an interpretation, S0 can be easily decided in balanced classification problems with each diagonal entry equals to one over the number of classes. However, in our setting of Tri-NMF, orthogonal constraints are enforced on F, G and Euc</context>
</contexts>
<marker>Shen, Li, Ding, 2011</marker>
<rawString>C. Shen, T. Li, and C. Ding. 2011. Integrating Clustering and Multi-Document Summarization by Bi-mixture Probabilistic Latent Semantic Analysis (PLSA) with Sentence Bases. In Proceedings of the national conference on Artificial intelligence. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Sindhwani</author>
<author>P Melville</author>
</authors>
<title>Document-word co-regularization for semi-supervised sentiment analysis.</title>
<date>2008</date>
<booktitle>In Data Mining, Eighth IEEE International Conference on,</booktitle>
<pages>1025--1030</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="8960" citStr="Sindhwani and Melville, 2008" startWordPosition="1386" endWordPosition="1389">all model changes resulted from a single additional example label or feature label may not be reflected in the classification performance (Attenberg et al., 2010). The empirical comparisons show that our proposed unified scheme based on reconstruction error outperforms the expected log gain. Dual Supervision Note that a learning method that is capable of performing dual supervision (i.e., learning from both labeled examples and features) is the basis for active dual supervision. Dual supervision is a relatively new area of research and few methods have been developed for dual supervision. In (Sindhwani and Melville, 2008; Sindhwani et al., 2008), a bipartite graph regularization model (GRADS) is used to diffuse label information along both sides of the document-term matrix and to perform dual supervision for semi-supervised sentiment analysis. Conceptually, their model implements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective). In (Sandler et al., 2008), standard regularization models are constrained using graphs of word cooccurrences. In (Melville et al., 2009), Naive Bayes classifier is extended, where the p</context>
</contexts>
<marker>Sindhwani, Melville, 2008</marker>
<rawString>V. Sindhwani and P. Melville. 2008. Document-word co-regularization for semi-supervised sentiment analysis. In Data Mining, Eighth IEEE International Conference on, pages 1025–1030. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Sindhwani</author>
<author>J Hu</author>
<author>A Mojsilovic</author>
</authors>
<title>Regularized co-clustering with dual supervision.</title>
<date>2008</date>
<booktitle>Advances in Neural Information Processing Systems,</booktitle>
<pages>21</pages>
<contexts>
<context position="8985" citStr="Sindhwani et al., 2008" startWordPosition="1390" endWordPosition="1394">m a single additional example label or feature label may not be reflected in the classification performance (Attenberg et al., 2010). The empirical comparisons show that our proposed unified scheme based on reconstruction error outperforms the expected log gain. Dual Supervision Note that a learning method that is capable of performing dual supervision (i.e., learning from both labeled examples and features) is the basis for active dual supervision. Dual supervision is a relatively new area of research and few methods have been developed for dual supervision. In (Sindhwani and Melville, 2008; Sindhwani et al., 2008), a bipartite graph regularization model (GRADS) is used to diffuse label information along both sides of the document-term matrix and to perform dual supervision for semi-supervised sentiment analysis. Conceptually, their model implements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective). In (Sandler et al., 2008), standard regularization models are constrained using graphs of word cooccurrences. In (Melville et al., 2009), Naive Bayes classifier is extended, where the parameters, the conditiona</context>
<context position="30345" citStr="Sindhwani et al., 2008" startWordPosition="4916" endWordPosition="4919"> 0.84 0.82 0.8 0.78 0.76 Accuracy 0.74 0.72 0.7 0.68 0.66 0.64 0.62 0.93 0.92 0.91 Accuracy 0.9 0.89 0.88 0.87 0.86 GRADS-Interleaving-0.5 GRADS-Reconstruction-Error GRADS-Interleaving-0.5 GRADS-Reconstruction-Error Accuracy 0.94 0.91 0.93 0.92 0.9 0.89 0.88 0.87 0.86 GRADS-Interleaving-0.5 GRADS-Reconstruction-Error 0 100 200 300 400 500 600 700 800 Labeling Cost (a) baseball-hockey 0 100 200 300 400 500 600 700 800 Labeling Cost (b) ibm-mac 0 100 200 300 400 500 600 700 800 Labeling Cost (c) med-space Figure 4: GRADS with reconstruction error and interleaving uncertainty. els such as GRADS (Sindhwani et al., 2008). Figure 4 shows the comparison of GRADS using the interleaved scheme with an interleaving probability of 0.5, and using our unified scheme based on reconstruction error. Among the 3 datasets we used, the reconstruction error based approach outperforms the interleaving scheme on baseball-hockey and ibmmac, and has similar performance with the interleaving scheme on med-space. 0 100 200 300 400 500 600 700 800 Labeling Cost Figure 6: Comparing active dual supervision using matrix factorization with GRADS on sentiment analysis. Comparing Active Dual Supervision Using Matrix Factorization with GR</context>
</contexts>
<marker>Sindhwani, Hu, Mojsilovic, 2008</marker>
<rawString>V. Sindhwani, J. Hu, and A. Mojsilovic. 2008. Regularized co-clustering with dual supervision. Advances in Neural Information Processing Systems, 21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Sindhwani</author>
<author>P Melville</author>
<author>R D Lawrence</author>
</authors>
<title>Uncertainty sampling and transductive experimental design for active dual supervision.</title>
<date>2009</date>
<booktitle>In Proceedings of the 26th Annual International Conference on Machine Learning,</booktitle>
<pages>953--960</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2332" citStr="Sindhwani et al., 2009" startWordPosition="349" endWordPosition="352">abel reviews as positive or negative, they can also label the words that elicit positive sentiment (such as “sensational” and “electrifying”) as positive and words that evoke negative sentiment (such as “depressed” and “unfulfilling”) as negative. Recent work has demonstrated that labeled words (or feature supervision) can greatly reduce the number of labeled samples for building high-quality classifiers (Druck et al., 2008; Zaidan and Eisner, 2008). In fact, different kinds of supervision generally have different acquisition costs, different degrees of utility and are not mutually redundant (Sindhwani et al., 2009). Ideally, effective active learning schemes should be able to utilize different forms of supervision. To incorporate the supervision on words and documents at same time into the active learning scheme, recently an active dual supervision (or dual active learning) has been proposed (Melville and Sindhwani, 2009; Sindhwani et al., 2009). Comparing with traditional active learning which aims to select the most “informative” examples (e.g., documents) for domain experts to label, active dual supervision selects both the “informative” examples (e.g., documents) and features (e.g., words) for label</context>
<context position="3730" citStr="Sindhwani et al., 2009" startWordPosition="559" endWordPosition="562">s and features (i.e., incorporating supervision on both examples and features); b) methods for estimating the value of information for example and feature labels; and c) a scheme that should be able to trade-off the costs and benefits of the different forms of supervision since they have different labeling costs and different benefits. 949 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 949–958, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics In Sindhwani et al.’s initial work on active dual supervision (Sindhwani et al., 2009), a transductive bipartite graph regularization approach is used for learning from both labeled examples and features. In addition, uncertainty sampling and experimental design are used for selecting informative examples and features for labeling. To trade-off between different types of supervision, a simple probabilistic interleaving scheme where the active learner probabilistically queries the example oracle and the feature oracle is used. One problem in their method is that the values of acquiring the feature labels and the example labels are not on the same scale. Recently, Li et al. (Li e</context>
<context position="7412" citStr="Sindhwani et al., 2009" startWordPosition="1136" endWordPosition="1139"> examples from an unlabeled pool are selected for labeling (Cohn et al., 1994). With the study of learning from labeled features, many research efforts on active learning with feature supervision are also reported (Melville et al., 2005; Raghavan et al., 2006). (Godbole et al., 2004) proposed the notion of feature uncertainty and incorporated the acquired feature labels into learning by creating one-term mini-documents. (Druck et al., 2009) performed active learning via feature labeling using several uncertainty reduction heuristics using the learning model developed in (Druck et al., 2008). (Sindhwani et al., 2009) studied the problem of active dual supervision from examples and features using a graph-based dual supervision method with a simple probabilistic method for interleaving feature labels and example labels. In our work, we develop our active dual supervision framework using constrained non-negative tri-factorization and also propose a unified scheme to evaluate the value of feature and example labels. We note the very recent work of (Attenberg et al., 2010), which proposes a unified approach for the dual active learning problem using expected utility where the utility is defined as the log gain</context>
<context position="16333" citStr="Sindhwani et al., 2009" startWordPosition="2704" endWordPosition="2707">es [2FT FSGTG−2F TXT G+2γ(S−S0)]jkSjk = 0. This is the fixed point relation that local minima for S must satisfy, which is equivalent with the update rule of S in Equation 7. 5 A Unified Scheme for Query Selection Using the Reconstruction Error 5.1 Introduction An ideal active dual supervision scheme should be able to evaluate the value of acquiring labels for documents and words on the same scale. In the initial study of dual active supervision, different scores are used for documents and words (e.g. uncertainty for documents and certainty for words), and thus they are not on the same scale (Sindhwani et al., 2009). Recently, the framework of Expected Utility (Estimated Risk Minimization) is proposed in (Attenberg et al., 2010). At each step of the framework, the next word or document selected for labeling is the one that will result in the highest estimated improvement in classifier performance as defined as: that a good supervision should lead to a good constrained factorization for the document-term matrix, X Pz GSFT . If the new query qj is a word and its label is k, then the new factorization is G∗ j=k, S∗j=k, F∗j=k = arg minG,S,F IIX − GSFT II2 + α trace[(G − G0)TC2(G − G0)] + β trace[(F − F0,j=k)</context>
<context position="21708" citStr="Sindhwani et al., 2009" startWordPosition="3672" endWordPosition="3675">s 6.1 Experiments Settings Three popular binary text classification datasets are used in the experiments: ibm-mac (1937 examples), baseball-hockey (1988 examples) and med-space (1972 examples) datasets. All of them are drawn from the 20-newsgroups text collection) where the task is to assign messages into the newsgroup in which they appeared. Top 1500 frequent words in each dataset are used as features in the binary vector representation. These datasets have labels for all the documents. For a document query, the oracle returns its label. We construct the word oracle in the same manner as in (Sindhwani et al., 2009): first compute the information gain of words with respect to the known true class labels in the training splits of a dataset, and then the top 100 words as ranked by information gain are assigned the label which is the class in which the word appears more frequently. To those words with labels, the word oracle returns its label; otherwise, the oracle returns a “don’t know” response (no word label is obtained for learning, but the word is excluded from the following query selection). Results are averaged over 10 random trainingtest splits. For each split, 30% examples are used for testing. All</context>
</contexts>
<marker>Sindhwani, Melville, Lawrence, 2009</marker>
<rawString>V. Sindhwani, P. Melville, and R.D. Lawrence. 2009. Uncertainty sampling and transductive experimental design for active dual supervision. In Proceedings of the 26th Annual International Conference on Machine Learning, pages 953–960. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Tong</author>
<author>D Koller</author>
</authors>
<title>Support vector machine active learning with applications to text classification.</title>
<date>2002</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>2--45</pages>
<contexts>
<context position="1322" citStr="Tong and Koller, 2002" startWordPosition="197" endWordPosition="200">odel the corresponding relationships between feature classes and examples classes. Then by making use of the reconstruction error, we propose a unified scheme to determine which feature or example a classifier is most likely to benefit from having labeled. Empirical results demonstrate the effectiveness of our proposed methods. 1 Introduction Active learning, as an effective paradigm to optimize the learning benefit from domain experts’ feedback and to reduce the cost of acquiring labeled examples for supervised learning, has been intensively studied in recent years (McCallum and Nigam, 1998; Tong and Koller, 2002; Settles, 2009). Traditional approaches for active learning query the human experts to obtain the labels for intelligently chosen data samples. However, in text classification where the input data is generally represented as documentword matrices, human supervision can be obtained on both documents and words. For example, in sentiment analysis of product reviews, human labelers can label reviews as positive or negative, they can also label the words that elicit positive sentiment (such as “sensational” and “electrifying”) as positive and words that evoke negative sentiment (such as “depressed</context>
</contexts>
<marker>Tong, Koller, 2002</marker>
<rawString>S. Tong and D. Koller. 2002. Support vector machine active learning with applications to text classification. The Journal of Machine Learning Research, 2:45–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omar F Zaidan</author>
<author>Jason Eisner</author>
</authors>
<title>Modeling annotators: A generative approach to learning from annotator rationales.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 conference on Empirical methods in natural language processing,</booktitle>
<pages>31--40</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics,</institution>
<contexts>
<context position="2162" citStr="Zaidan and Eisner, 2008" startWordPosition="324" endWordPosition="327">sented as documentword matrices, human supervision can be obtained on both documents and words. For example, in sentiment analysis of product reviews, human labelers can label reviews as positive or negative, they can also label the words that elicit positive sentiment (such as “sensational” and “electrifying”) as positive and words that evoke negative sentiment (such as “depressed” and “unfulfilling”) as negative. Recent work has demonstrated that labeled words (or feature supervision) can greatly reduce the number of labeled samples for building high-quality classifiers (Druck et al., 2008; Zaidan and Eisner, 2008). In fact, different kinds of supervision generally have different acquisition costs, different degrees of utility and are not mutually redundant (Sindhwani et al., 2009). Ideally, effective active learning schemes should be able to utilize different forms of supervision. To incorporate the supervision on words and documents at same time into the active learning scheme, recently an active dual supervision (or dual active learning) has been proposed (Melville and Sindhwani, 2009; Sindhwani et al., 2009). Comparing with traditional active learning which aims to select the most “informative” exam</context>
</contexts>
<marker>Zaidan, Eisner, 2008</marker>
<rawString>Omar F. Zaidan and Jason Eisner. 2008. Modeling annotators: A generative approach to learning from annotator rationales. In Proceedings of the 2008 conference on Empirical methods in natural language processing, pages 31–40. Association for Computational Linguistics, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zha</author>
<author>X He</author>
<author>C Ding</author>
<author>H Simon</author>
<author>M Gu</author>
</authors>
<title>Bipartite graph partitioning and data clustering.</title>
<date>2001</date>
<booktitle>In Proceedings of the tenth international conference on Information and knowledge management,</booktitle>
<pages>25--32</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9343" citStr="Zha et al., 2001" startWordPosition="1442" endWordPosition="1445">arning from both labeled examples and features) is the basis for active dual supervision. Dual supervision is a relatively new area of research and few methods have been developed for dual supervision. In (Sindhwani and Melville, 2008; Sindhwani et al., 2008), a bipartite graph regularization model (GRADS) is used to diffuse label information along both sides of the document-term matrix and to perform dual supervision for semi-supervised sentiment analysis. Conceptually, their model implements a co-clustering assumption closely related to Singular Value Decomposition (see also (Dhillon, 2001; Zha et al., 2001) for more on this perspective). In (Sandler et al., 2008), standard regularization models are constrained using graphs of word cooccurrences. In (Melville et al., 2009), Naive Bayes classifier is extended, where the parameters, the conditional word distributions given the classes, are estimated by combining multiple sources, e.g. document labels and word labels. Our work is based on the dual supervision framework using constrained non-negative tri-factorization. 3 Learning with Dual Supervision via Tri-NMF Our dual supervision model is based on nonnegative matrix tri-factorization (Tri-NMF), w</context>
</contexts>
<marker>Zha, He, Ding, Simon, Gu, 2001</marker>
<rawString>H. Zha, X. He, C. Ding, H. Simon, and M. Gu. 2001. Bipartite graph partitioning and data clustering. In Proceedings of the tenth international conference on Information and knowledge management, pages 25–32. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>