<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006200">
<title confidence="0.989071">
Mining Transliterations from Wikipedia using Pair HMMs
</title>
<author confidence="0.993283">
Peter Nabende
</author>
<affiliation confidence="0.7900915">
Alfa-Informatica, University of Groningen
The Netherlands
</affiliation>
<email confidence="0.979557">
p.nabende@rug.nl
</email>
<sectionHeader confidence="0.993447" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999971076923077">
This paper describes the use of a pair
Hidden Markov Model (pair HMM) sys-
tem in mining transliteration pairs from
noisy Wikipedia data. A pair HMM vari-
ant that uses nine transition parameters,
and emission parameters associated with
single character mappings between source
and target language alphabets is identified
and used in estimating transliteration sim-
ilarity. The system resulted in a precision
of 78% and recall of 83% when evaluated
on a random selection of English-Russian
Wikipedia topics.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999973894736842">
The transliteration mining task as defined in the
NEWS 2010 White paper (Kumaran et al., 2010)
required identifying single word transliteration
pairs from a set of candidate transliteration pairs.
In the case of Wikipedia data, we have a collection
of corresponding source and target language topics
that can be used for extracting candidate translit-
erations. We apply a pair HMM edit-distance
based method to obtain transliteration similarity
estimates. The similarity estimates for a given set
of source and target language words are then com-
pared with the aim of identifying potential translit-
eration pairs. Generally, the pair HMM method
uses the notion of transforming a source string
to a target string through a series of edit opera-
tions. The three edit operations that we consider
for use in transliteration similarity estimation in-
clude: substitution, insertion, and deletion. These
edit operations are represented as hidden states of
a pair HMM. Depending on the source and target
language alphabets, it is possible to design or use a
specific pair HMM algorithm for estimating paired
character emission parameters in the edit opera-
tion states, and transition parameters for a given
design of transitions between the pair HMM’s
states. Before applying the pair HMM method, we
use external datasets to identify a pair HMM vari-
ant that we consider as suitable for application to
transliteration similarity estimation. We then use
the shared task datasets to train the selected pair
HMM variant, and finally apply an algorithm that
is specific to the trained pair HMM for comput-
ing transliteration similarity estimates. In section
2, we discuss transliteration similarity estimation
with regard to applying the pair HMM method;
section 3 describes the experimental setup and re-
sults; section 4 concludes the paper with pointers
to future work.
</bodyText>
<sectionHeader confidence="0.8381095" genericHeader="method">
2 Transliteration Similarity Estimation
using Pair HMMs
</sectionHeader>
<bodyText confidence="0.886263090909091">
To describe the transliteration similarity estima-
tion process, consider examples of corresponding
English (as source language) and Russian (as tar-
get language) Wikipedia topics as shown in Table
1. Across languages, Wikipedia topics are written
in different ways and all words in a topic could be
important for mining transliterations. One main
step in the transliteration mining task is to identify
a set of words in each topic for consideration as
candidate transliterations. As seen in Table 1, it is
very likely that some words will not be selected as
</bodyText>
<table confidence="0.976874125">
id English topic Russian topic
1 Johnston Atoll j}KOHCTOH (aTO.TI.TI)
2 Oleksandr 11a.TIHH11ga A.TIeKCaHqp
Palyanytya B11Ta.TIbeB11t1
3 Ministers for KaTerOpIIH:M14H14CTpbI
Foreign Affairs of HHOCTpaHHbIX qe.TI
Luxembourg T11OKCeM6ypra
... ...
</table>
<tableCaption confidence="0.973781">
Table 1: Example of corresponding English Rus-
sian Wikipedia topics
</tableCaption>
<page confidence="0.913402">
76
</page>
<note confidence="0.6293565">
Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 76–80,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999905647058824">
candidate transliterations depending on the criteria
for selection. For example, if a criterion is such
that we consider only words starting with upper-
case characters for English and Russian datasets,
then the Russian word ‘aTOJIJI’ in the topic pair 1
in Table 1 will not be used as a candidate translit-
eration and that in turn makes the system loose
the likely pair of ‘Atoll, aTOJIJI’. After extracting
candidate transliterations, the approach we use in
this paper takes each candidate word on the source
language side and determines a transliteration es-
timate with each candidate word on the target lan-
guage side. Consider the example for topic id 1 in
Table 1 where we expect to have ‘Johnston’ and
‘Atoll’ as candidate source language translitera-
tions, and ‘J KOxcTOx’ and ‘aTOJIJI’ as candidate
target language transliterations. The method used
is expected to compare ‘Johnston’ against ‘J KOx-
cTOx’ and ‘aTOJIJI’, and then compare ‘Atoll’ to
the Russian candidate transliterations. We expect
the output to be ‘Johston, J KOxcTOx’ and ‘Atoll,
aTOJIJI’ as the most likely single word transliter-
ations from topic pair 1 after sorting out all the
four transliteration similarity estimates in this par-
ticular case. We employ the pair HMM approach
to estimate transliteration similarity for candidate
source-target language words.
A pair HMM has an emission state or states that
generate two observation sequences instead of one
observation sequence as is the case in standard
HMMs. Pair HMMs originate from work in Bi-
ological sequence analysis (Durbin et al., 1998;
Rivas and Eddy, 2001) from which variants were
created and successfully applied in cognate identi-
fication (Mackay and Kondrak, 2005), Dutch di-
alect comparison (Wieling et al., 2007), translit-
eration identification (Nabende et al., 2010),
and transliteration generation (Nabende, 2009).
As mentioned earlier, we have first, tested two
pair HMM variants on manually verified English-
Russian datasets which we obtain from the previ-
ous shared task on machine transliteration (NEWS
2009) (Kumaran and Kellner, 2007). This pre-
liminary test is aimed at determining the effect of
pair HMM parameter changes on the quality of the
transliteration similarity estimates. For the first
pair HMM variant, no transitions are modeled be-
tween edit states; we only use transtion parame-
ters associated with transiting from a start state to
each of the edit operation states, and from each
of the edit operation states to an end state. The
</bodyText>
<figureCaption confidence="0.723734666666667">
Figure 1: Pair HMM with nine distinct transi-
tion parameters. Emission parameters are speci-
fied with emitting states and their size is dependent
</figureCaption>
<bodyText confidence="0.986702724137931">
on the characters used in the source and target lan-
guages
second pair HMM variant uses nine distinct tran-
sition parameters between the pair HMM’s states
as shown in Figure 1. The node M in Figure 1 rep-
resents the substitution state in which emission pa-
rameters encode relationships between each of the
source and target language characters. D denotes
the deletion state where emission parameters spec-
ify relationships between source language charac-
ters and a target language gap. I denotes the inser-
tion state where emission parameters encode rela-
tionships between target language characters and
a source language gap. Starting parameters for the
pair HMM in Figure 1 are assoicated with transit-
ing from the M state to one of the edit operation
states including transiting back to M.
The pair HMM parameters are estimated using
the well-known Baum-Welch Expectation Maxi-
mization (EM) algorithm (Baum et al., 1970).
For each pair HMM variant, the training algorithm
starts with a uniform distribution for substitution,
deletion, insertion, and transition parameters, and
iterates through the data until a local maximum.
A method referred to as stratified tenfold cross
validation (Olson and Delen, 2008) is used to eval-
uate the two pair HMM variants. In each fold,
7056 pairs of English-Russian names from the pre-
vious shared task on machine transliteration (Ku-
</bodyText>
<figure confidence="0.8872915">
1-
1-8D-8I-TM
</figure>
<page confidence="0.964037">
77
</page>
<table confidence="0.999423">
Pair HMM Model CVA CVMRR
phmm00edtrans Viterbi 0.788 0.809
Forward 0.927 0.954
phmm09edtrans Viterbi 0.943 0.952
Forward 0.987 0.991
</table>
<tableCaption confidence="0.969347">
Table 2: CVA and CVMRR results two pair HMM
</tableCaption>
<bodyText confidence="0.992842476190476">
variants on a preliminary transliteration identifica-
tio experiment. phmm00edtrans is the pair HMM
variant with no transition parameters between the
edit states while phmm09edtrans is the pair HMM
variant with nine distinct transition parameters.
maran and Kellner, 2007) are used for training and
784 name pairs for testing. The Cross Valida-
tion Accuracy (CVA) and Cross Validation Mean
Reciprocal Rank (CVMRR) results obtained from
applying the Forward and Viterbi algorithms of the
two pair HMM variants on this particular dataset
are shown in Table 2.
The CVA and CVMRR values in Table 2 sug-
gest that it is necessary to model for transition pa-
rameters when using pair HMMs for translitera-
tion similarity estimation. Table 2 also suggests
that it is better to use the Forward algorithm for a
given pair HMM variant. Based on the results in
Table 2, the pair HMM variant illustrated in Figure
1 is chosen for application in estimating transliter-
ation similarity for the mining task.
</bodyText>
<sectionHeader confidence="0.988651" genericHeader="method">
3 Experimental setup and Results
</sectionHeader>
<bodyText confidence="0.995886411764706">
To simplify the analysis of the source and tar-
get strings, the pair HMM system requires unique
whole number representations for each character
in the source and target language data. This is not
suitable for all the different types of writing sys-
tems. In this paper, we look at only the English
and Russian languages where many characters are
associated with a phonemic alphabet and where
numbered representations are hardly expected to
contribute to errors from loss of information in-
herent in the original orthography. A preliminary
run on Chinese-English1 datasets from the previ-
ous shared task on machine transliteration (NEWS
2009) resulted in an accuracy of 0.213 and MRR
of 0.327 using the pair HMM variant in Figure
1. In the following subsection we discuss some
data preprocessing steps on the English-Russian
</bodyText>
<footnote confidence="0.875765">
1In this case Chinese is the source language while English
is the target language
</footnote>
<bodyText confidence="0.948541">
Wikipedia dataset.
</bodyText>
<subsectionHeader confidence="0.994413">
3.1 English and Russian candidate
transliteration extraction
</subsectionHeader>
<bodyText confidence="0.99998329787234">
The English-Russian Wikipedia dataset that was
provided for the transliteration mining task is very
noisy meaning that it has various types of other en-
tities in addition to words for each language’s or-
thography. A first step in simplifying the translit-
eration mining process was to remove any unnec-
essary entities.
We observed the overlap of writing systems in
both the English and Russian Wikipedia datasets.
We therefore made sure that there is no topic
where the same writing system is used in both the
English and Russian data. Any strings that contain
characters that are not associated with the writ-
ing systems for English and Russian were also re-
moved.
We also observed the presence of many tempo-
ral and numerical expressions that are not neces-
sary on both the English and Russian Wikipedia
datasets. We applied different sets of rules to re-
move such expressions while leaving any neces-
sary words.
Using knowledge about the initial formatting
of strings in both the English and Russian data,
a set of rules was applied to split most of the
strings based on different characters. For ex-
ample almost all strings in the English side had
the underscore ‘ ’ character as a string separa-
tor. We also removed characters such as: colons,
semi-colons, commas, question marks, exclama-
tion marks, dashes, hyphens, forward and back
slashes, mathematical operator symbols, currency
symbols, etc. Some strings were also split based
on string patterns, for example where different
words are joined into one string and it was easy
to identify that the uppercase character for each
word still remained in the combined string just like
when it is alone. We also removed many abbrevia-
tions and titles in the datasets that were not neces-
sary for analysis during the transliteration mining
process.
After selecting candidate words based on most
of the criteria above, we determine all characters
in our extracted candidate transliteration data and
compare against those in the shared task’s seed
data (Kumaran et al., 2010) with the aim of find-
ing all characters that are missing in the seed data.
Matching transliteration pairs with the the miss-
</bodyText>
<page confidence="0.995617">
78
</page>
<bodyText confidence="0.9999936875">
ing characters are then hand picked from the can-
didate words dataset and added to the seed data
before training the pair HMM variant that is se-
lected from the previous section. The process for
identifying missing characters and words that have
them is carried out seperately for each language.
However, a matching word in the other language
is identified to constitute a transliteration pair that
can be added to the seed dataset. For the English-
Russian dataset, we use 142 transliteration pairs in
addition to the 1000 transliteration pairs in the ini-
tial seed data. We hence apply the Baum-Welch
algorithm for the selected pair HMM specification
from section 2 on a total of 1142 transliteration
pairs. The algorithm performed 182 iterations be-
fore converging for this particular dataset.
</bodyText>
<subsectionHeader confidence="0.904879">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999973275862069">
To obtain transliteration similarity measures, we
apply the Forward algorithm of the trained pair
HMM from section 3.1 to all the remaining
Wikipedia topics. For each word in an English
topic, the algorithm computes transliteration simi-
larity estimates for all words in the Russian topic.
After observing transliteration similarity estimates
for a subset of candidate transliteration words, we
specify a single threshold value (th) and use it
for identifying potential transliteration pairs. A
threshold value of 1 x 10−13 was chosen after
observing that many of the pairs that had a sim-
ilarity estimate above this threshold were indeed
transliteration pairs. Therefore, a pair of words
was taken as a potential transliteration pair only
when its transliteration estimate (tr sim) was such
that tr sim &gt; th. This resulted in a total of
299389 potential English-Russian transliteration
pairs. This collection of potential transliteration
pairs has been evaluated using a random set of cor-
responding English and Russian Wikipedia topics
as specified in the NEWS 2010 White paper for
the transliteration mining task (Kumaran et al.,
2010). Table 3 shows the precision, recall, and
f-score results2 that were obtained after applying
the Forward algorithm for the pair HMM of Fig-
ure 1.
Despite using the pair HMM method with its
basic probabilistic one-to-one mapping for each
</bodyText>
<footnote confidence="0.9829785">
2The numbers in Table 3 were obtained from a post eval-
uation after correcting a number of processing errors in the
pair HMM transliteration mining system. The errors initially
led to relatively lower values associated with the measures in
this Table. The values in this Table are therefore not part of
the initial shared task results
</footnote>
<table confidence="0.6302535">
Model precision recall f-score
phmm09edtrans 0.780 0.834 0.806
</table>
<tableCaption confidence="0.874146">
Table 3: Evaluation results for the Pair HMM of
</tableCaption>
<bodyText confidence="0.901725666666667">
Figure 1 on a random selection of 1000 corre-
sponding English Russian Wikipedia topics.
of the source target character representations, the
result in Table 3 suggests a promising applica-
tion of pair HMMs in mining transliterations from
Wikipedia.
</bodyText>
<sectionHeader confidence="0.998657" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999990724137931">
We have described the application of Pair HMMs
to mining transliterations from Wikipedia. The
transliteration mining evaluation results suggest
a valuable application of Pair HMMs to mining
transliterations. Currently, the pair HMM system
is considered to be best applicable to languages
whose writing system mostly uses a phonemic al-
phabet. Although an experimental test run was
done for Chinese-English data, a conclusion about
the general applicability of the pair HMM neces-
sitates additional tests using other language pairs
such as Hindi and Tamil which were also part of
the shared task.
As future work, we would like to investigate
the performance of Pair HMMs on additional writ-
ing systems. This may require additional modi-
fications to a pair HMM system to minimize on
input formatting errors for other types of writ-
ing systems. It is also necessary to determine the
transliteration mining performance of pair HMMs
when more tolerant criteria are used on the noisy
Wikipedia data. Currently, the pair HMM is ap-
plied in its most basic form, that is, no complex
modifications have been implemented for example
modeling for context in source and target language
words, and other factors that may affect the quality
of a transliteration similarity estimate; it should be
interesting to investigate perfromance of complex
pair HMM variants in transliteration mining.
</bodyText>
<sectionHeader confidence="0.998539" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.8292375">
Research in this paper is funded through a second
NPT (Uganda) Project.
</bodyText>
<sectionHeader confidence="0.985448" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.839235">
A Kumaran, Mitesh Khapra, and Haizhou Li. 2010.
Whitepaper on NEWS 2010 Shared Task on
</reference>
<page confidence="0.982477">
79
</page>
<reference confidence="0.997255613636364">
Transliteration Mining.
A Kumaran and Tobias Kellner. 2007. A Generic
Framework for Machine Transliteration. Proceed-
ings of the 301h Annual International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval (SIGIR 2007), pp 721–722, Ams-
terdam, The Netherlands.
Leonard E. Baum, Ted Petrie, George Soules, and Nor-
man Weiss. 1970. A Maximization Technique Oc-
curring in the Statistical Analysis of Probabilistic
Functions of Markov Chains. Annals of Mathemati-
cal Statistics, 41(1):164–171.
David L. Olson and Dursun Delen. 2008. Advanced
Data Mining Techniques. Springer.
Elena Rivas and Sean R. Eddy. 2001. Noncoding RNA
Gene Detection using Comparative Sequence Anal-
ysis. BMC Bioinformatics 2001, 2:8.
Martijn Wieling, Therese Leinonen, and John Ner-
bonne. 2007. Inducing Sound Segment Differences
using Pair Hidden Markov Models. In John Ner-
bonne, Mark Ellison, and Grzegorz Kondrak (eds.)
Computing Historical Phonology: 91h Meeting of
the ACL Special Interest Group for Computational
Morphology and Phonology Workshop, pp 48–56,
Prague, Czech Republic.
Peter Nabende. 2009. Transliteration System using
Pair HMMs with Weighted FSTs. Proceedings of
the Named Entities Workshop, NEWS’09, pp 100–
103, Suntec, Singapore.
Peter Nabende, Jorg Tiedemann, and John Nerbonne.
2010. Pair Hidden Markov Model for Named Entity
Matching. In Tarek Sobh (ed.) Innovations and Ad-
vances in Computer Sciences and Engineering, pp
497–502, Springer, Heidelberg.
Richard Durbin, Sean R. Eddy, Anders Krogh, Graeme
Mitchison. 1998. Biological Sequence Analysis:
Probabilistic Models of Proteins and Nucleic Acids.
Cambridge University Press, Cambridge, UK.
Wesley Mackay and Grzegorz Kondrak. 2005. Com-
puting Word Similarity and Identifying Cognates
with Pair Hidden Markov Models. Proceedings
of the ninth Conference on Computational Natural
Language Learning (CoNLL 2005), pp 40–47, Ann
Arbor, Michigan.
</reference>
<page confidence="0.998232">
80
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.344918">
<title confidence="0.999823">Mining Transliterations from Wikipedia using Pair HMMs</title>
<author confidence="0.961933">Peter</author>
<affiliation confidence="0.747926">Alfa-Informatica, University of The</affiliation>
<email confidence="0.929146">p.nabende@rug.nl</email>
<abstract confidence="0.971865">This paper describes the use of a pair Hidden Markov Model (pair HMM) system in mining transliteration pairs from noisy Wikipedia data. A pair HMM variant that uses nine transition parameters, and emission parameters associated with single character mappings between source and target language alphabets is identified and used in estimating transliteration sim- The system resulted in a 78% and 83% when evaluated on a random selection of English-Russian Wikipedia topics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Kumaran</author>
<author>Mitesh Khapra</author>
<author>Haizhou Li</author>
</authors>
<date>2010</date>
<booktitle>Whitepaper on NEWS 2010 Shared Task on Transliteration Mining.</booktitle>
<contexts>
<context position="765" citStr="Kumaran et al., 2010" startWordPosition="109" endWordPosition="112">Abstract This paper describes the use of a pair Hidden Markov Model (pair HMM) system in mining transliteration pairs from noisy Wikipedia data. A pair HMM variant that uses nine transition parameters, and emission parameters associated with single character mappings between source and target language alphabets is identified and used in estimating transliteration similarity. The system resulted in a precision of 78% and recall of 83% when evaluated on a random selection of English-Russian Wikipedia topics. 1 Introduction The transliteration mining task as defined in the NEWS 2010 White paper (Kumaran et al., 2010) required identifying single word transliteration pairs from a set of candidate transliteration pairs. In the case of Wikipedia data, we have a collection of corresponding source and target language topics that can be used for extracting candidate transliterations. We apply a pair HMM edit-distance based method to obtain transliteration similarity estimates. The similarity estimates for a given set of source and target language words are then compared with the aim of identifying potential transliteration pairs. Generally, the pair HMM method uses the notion of transforming a source string to a</context>
<context position="11792" citStr="Kumaran et al., 2010" startWordPosition="1867" endWordPosition="1870">. Some strings were also split based on string patterns, for example where different words are joined into one string and it was easy to identify that the uppercase character for each word still remained in the combined string just like when it is alone. We also removed many abbreviations and titles in the datasets that were not necessary for analysis during the transliteration mining process. After selecting candidate words based on most of the criteria above, we determine all characters in our extracted candidate transliteration data and compare against those in the shared task’s seed data (Kumaran et al., 2010) with the aim of finding all characters that are missing in the seed data. Matching transliteration pairs with the the miss78 ing characters are then hand picked from the candidate words dataset and added to the seed data before training the pair HMM variant that is selected from the previous section. The process for identifying missing characters and words that have them is carried out seperately for each language. However, a matching word in the other language is identified to constitute a transliteration pair that can be added to the seed dataset. For the EnglishRussian dataset, we use 142 </context>
<context position="13856" citStr="Kumaran et al., 2010" startWordPosition="2198" endWordPosition="2201"> x 10−13 was chosen after observing that many of the pairs that had a similarity estimate above this threshold were indeed transliteration pairs. Therefore, a pair of words was taken as a potential transliteration pair only when its transliteration estimate (tr sim) was such that tr sim &gt; th. This resulted in a total of 299389 potential English-Russian transliteration pairs. This collection of potential transliteration pairs has been evaluated using a random set of corresponding English and Russian Wikipedia topics as specified in the NEWS 2010 White paper for the transliteration mining task (Kumaran et al., 2010). Table 3 shows the precision, recall, and f-score results2 that were obtained after applying the Forward algorithm for the pair HMM of Figure 1. Despite using the pair HMM method with its basic probabilistic one-to-one mapping for each 2The numbers in Table 3 were obtained from a post evaluation after correcting a number of processing errors in the pair HMM transliteration mining system. The errors initially led to relatively lower values associated with the measures in this Table. The values in this Table are therefore not part of the initial shared task results Model precision recall f-scor</context>
</contexts>
<marker>Kumaran, Khapra, Li, 2010</marker>
<rawString>A Kumaran, Mitesh Khapra, and Haizhou Li. 2010. Whitepaper on NEWS 2010 Shared Task on Transliteration Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kumaran</author>
<author>Tobias Kellner</author>
</authors>
<title>A Generic Framework for Machine Transliteration.</title>
<date>2007</date>
<booktitle>Proceedings of the 301h Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR</booktitle>
<pages>721--722</pages>
<location>Amsterdam, The Netherlands.</location>
<contexts>
<context position="5677" citStr="Kumaran and Kellner, 2007" startWordPosition="869" endWordPosition="872">as is the case in standard HMMs. Pair HMMs originate from work in Biological sequence analysis (Durbin et al., 1998; Rivas and Eddy, 2001) from which variants were created and successfully applied in cognate identification (Mackay and Kondrak, 2005), Dutch dialect comparison (Wieling et al., 2007), transliteration identification (Nabende et al., 2010), and transliteration generation (Nabende, 2009). As mentioned earlier, we have first, tested two pair HMM variants on manually verified EnglishRussian datasets which we obtain from the previous shared task on machine transliteration (NEWS 2009) (Kumaran and Kellner, 2007). This preliminary test is aimed at determining the effect of pair HMM parameter changes on the quality of the transliteration similarity estimates. For the first pair HMM variant, no transitions are modeled between edit states; we only use transtion parameters associated with transiting from a start state to each of the edit operation states, and from each of the edit operation states to an end state. The Figure 1: Pair HMM with nine distinct transition parameters. Emission parameters are specified with emitting states and their size is dependent on the characters used in the source and targe</context>
</contexts>
<marker>Kumaran, Kellner, 2007</marker>
<rawString>A Kumaran and Tobias Kellner. 2007. A Generic Framework for Machine Transliteration. Proceedings of the 301h Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2007), pp 721–722, Amsterdam, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard E Baum</author>
<author>Ted Petrie</author>
<author>George Soules</author>
<author>Norman Weiss</author>
</authors>
<title>A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains.</title>
<date>1970</date>
<journal>Annals of Mathematical Statistics,</journal>
<volume>41</volume>
<issue>1</issue>
<contexts>
<context position="7144" citStr="Baum et al., 1970" startWordPosition="1111" endWordPosition="1114">of the source and target language characters. D denotes the deletion state where emission parameters specify relationships between source language characters and a target language gap. I denotes the insertion state where emission parameters encode relationships between target language characters and a source language gap. Starting parameters for the pair HMM in Figure 1 are assoicated with transiting from the M state to one of the edit operation states including transiting back to M. The pair HMM parameters are estimated using the well-known Baum-Welch Expectation Maximization (EM) algorithm (Baum et al., 1970). For each pair HMM variant, the training algorithm starts with a uniform distribution for substitution, deletion, insertion, and transition parameters, and iterates through the data until a local maximum. A method referred to as stratified tenfold cross validation (Olson and Delen, 2008) is used to evaluate the two pair HMM variants. In each fold, 7056 pairs of English-Russian names from the previous shared task on machine transliteration (Ku1- 1-8D-8I-TM 77 Pair HMM Model CVA CVMRR phmm00edtrans Viterbi 0.788 0.809 Forward 0.927 0.954 phmm09edtrans Viterbi 0.943 0.952 Forward 0.987 0.991 Tab</context>
</contexts>
<marker>Baum, Petrie, Soules, Weiss, 1970</marker>
<rawString>Leonard E. Baum, Ted Petrie, George Soules, and Norman Weiss. 1970. A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains. Annals of Mathematical Statistics, 41(1):164–171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Olson</author>
<author>Dursun Delen</author>
</authors>
<title>Advanced Data Mining Techniques.</title>
<date>2008</date>
<publisher>Springer.</publisher>
<contexts>
<context position="7433" citStr="Olson and Delen, 2008" startWordPosition="1153" endWordPosition="1156"> characters and a source language gap. Starting parameters for the pair HMM in Figure 1 are assoicated with transiting from the M state to one of the edit operation states including transiting back to M. The pair HMM parameters are estimated using the well-known Baum-Welch Expectation Maximization (EM) algorithm (Baum et al., 1970). For each pair HMM variant, the training algorithm starts with a uniform distribution for substitution, deletion, insertion, and transition parameters, and iterates through the data until a local maximum. A method referred to as stratified tenfold cross validation (Olson and Delen, 2008) is used to evaluate the two pair HMM variants. In each fold, 7056 pairs of English-Russian names from the previous shared task on machine transliteration (Ku1- 1-8D-8I-TM 77 Pair HMM Model CVA CVMRR phmm00edtrans Viterbi 0.788 0.809 Forward 0.927 0.954 phmm09edtrans Viterbi 0.943 0.952 Forward 0.987 0.991 Table 2: CVA and CVMRR results two pair HMM variants on a preliminary transliteration identificatio experiment. phmm00edtrans is the pair HMM variant with no transition parameters between the edit states while phmm09edtrans is the pair HMM variant with nine distinct transition parameters. ma</context>
</contexts>
<marker>Olson, Delen, 2008</marker>
<rawString>David L. Olson and Dursun Delen. 2008. Advanced Data Mining Techniques. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Rivas</author>
<author>Sean R Eddy</author>
</authors>
<title>Noncoding RNA Gene Detection using Comparative Sequence Analysis.</title>
<date>2001</date>
<journal>BMC Bioinformatics</journal>
<pages>2--8</pages>
<contexts>
<context position="5189" citStr="Rivas and Eddy, 2001" startWordPosition="798" endWordPosition="801">te transliterations. We expect the output to be ‘Johston, J KOxcTOx’ and ‘Atoll, aTOJIJI’ as the most likely single word transliterations from topic pair 1 after sorting out all the four transliteration similarity estimates in this particular case. We employ the pair HMM approach to estimate transliteration similarity for candidate source-target language words. A pair HMM has an emission state or states that generate two observation sequences instead of one observation sequence as is the case in standard HMMs. Pair HMMs originate from work in Biological sequence analysis (Durbin et al., 1998; Rivas and Eddy, 2001) from which variants were created and successfully applied in cognate identification (Mackay and Kondrak, 2005), Dutch dialect comparison (Wieling et al., 2007), transliteration identification (Nabende et al., 2010), and transliteration generation (Nabende, 2009). As mentioned earlier, we have first, tested two pair HMM variants on manually verified EnglishRussian datasets which we obtain from the previous shared task on machine transliteration (NEWS 2009) (Kumaran and Kellner, 2007). This preliminary test is aimed at determining the effect of pair HMM parameter changes on the quality of the t</context>
</contexts>
<marker>Rivas, Eddy, 2001</marker>
<rawString>Elena Rivas and Sean R. Eddy. 2001. Noncoding RNA Gene Detection using Comparative Sequence Analysis. BMC Bioinformatics 2001, 2:8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martijn Wieling</author>
<author>Therese Leinonen</author>
<author>John Nerbonne</author>
</authors>
<title>Inducing Sound Segment Differences using Pair Hidden Markov Models. In</title>
<date>2007</date>
<booktitle>Computing Historical Phonology: 91h Meeting of the ACL Special Interest Group for Computational Morphology and Phonology Workshop,</booktitle>
<pages>48--56</pages>
<editor>John Nerbonne, Mark Ellison, and Grzegorz Kondrak (eds.)</editor>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5349" citStr="Wieling et al., 2007" startWordPosition="822" endWordPosition="825">r sorting out all the four transliteration similarity estimates in this particular case. We employ the pair HMM approach to estimate transliteration similarity for candidate source-target language words. A pair HMM has an emission state or states that generate two observation sequences instead of one observation sequence as is the case in standard HMMs. Pair HMMs originate from work in Biological sequence analysis (Durbin et al., 1998; Rivas and Eddy, 2001) from which variants were created and successfully applied in cognate identification (Mackay and Kondrak, 2005), Dutch dialect comparison (Wieling et al., 2007), transliteration identification (Nabende et al., 2010), and transliteration generation (Nabende, 2009). As mentioned earlier, we have first, tested two pair HMM variants on manually verified EnglishRussian datasets which we obtain from the previous shared task on machine transliteration (NEWS 2009) (Kumaran and Kellner, 2007). This preliminary test is aimed at determining the effect of pair HMM parameter changes on the quality of the transliteration similarity estimates. For the first pair HMM variant, no transitions are modeled between edit states; we only use transtion parameters associated</context>
</contexts>
<marker>Wieling, Leinonen, Nerbonne, 2007</marker>
<rawString>Martijn Wieling, Therese Leinonen, and John Nerbonne. 2007. Inducing Sound Segment Differences using Pair Hidden Markov Models. In John Nerbonne, Mark Ellison, and Grzegorz Kondrak (eds.) Computing Historical Phonology: 91h Meeting of the ACL Special Interest Group for Computational Morphology and Phonology Workshop, pp 48–56, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Nabende</author>
</authors>
<title>Transliteration System using Pair HMMs with Weighted FSTs.</title>
<date>2009</date>
<booktitle>Proceedings of the Named Entities Workshop, NEWS’09,</booktitle>
<pages>100--103</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="5452" citStr="Nabende, 2009" startWordPosition="836" endWordPosition="837">M approach to estimate transliteration similarity for candidate source-target language words. A pair HMM has an emission state or states that generate two observation sequences instead of one observation sequence as is the case in standard HMMs. Pair HMMs originate from work in Biological sequence analysis (Durbin et al., 1998; Rivas and Eddy, 2001) from which variants were created and successfully applied in cognate identification (Mackay and Kondrak, 2005), Dutch dialect comparison (Wieling et al., 2007), transliteration identification (Nabende et al., 2010), and transliteration generation (Nabende, 2009). As mentioned earlier, we have first, tested two pair HMM variants on manually verified EnglishRussian datasets which we obtain from the previous shared task on machine transliteration (NEWS 2009) (Kumaran and Kellner, 2007). This preliminary test is aimed at determining the effect of pair HMM parameter changes on the quality of the transliteration similarity estimates. For the first pair HMM variant, no transitions are modeled between edit states; we only use transtion parameters associated with transiting from a start state to each of the edit operation states, and from each of the edit ope</context>
</contexts>
<marker>Nabende, 2009</marker>
<rawString>Peter Nabende. 2009. Transliteration System using Pair HMMs with Weighted FSTs. Proceedings of the Named Entities Workshop, NEWS’09, pp 100– 103, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Nabende</author>
<author>Jorg Tiedemann</author>
<author>John Nerbonne</author>
</authors>
<title>Pair Hidden Markov Model for Named Entity Matching.</title>
<date>2010</date>
<booktitle>In Tarek Sobh (ed.) Innovations and Advances in Computer Sciences and Engineering,</booktitle>
<pages>497--502</pages>
<publisher>Springer,</publisher>
<location>Heidelberg.</location>
<contexts>
<context position="5404" citStr="Nabende et al., 2010" startWordPosition="829" endWordPosition="832">stimates in this particular case. We employ the pair HMM approach to estimate transliteration similarity for candidate source-target language words. A pair HMM has an emission state or states that generate two observation sequences instead of one observation sequence as is the case in standard HMMs. Pair HMMs originate from work in Biological sequence analysis (Durbin et al., 1998; Rivas and Eddy, 2001) from which variants were created and successfully applied in cognate identification (Mackay and Kondrak, 2005), Dutch dialect comparison (Wieling et al., 2007), transliteration identification (Nabende et al., 2010), and transliteration generation (Nabende, 2009). As mentioned earlier, we have first, tested two pair HMM variants on manually verified EnglishRussian datasets which we obtain from the previous shared task on machine transliteration (NEWS 2009) (Kumaran and Kellner, 2007). This preliminary test is aimed at determining the effect of pair HMM parameter changes on the quality of the transliteration similarity estimates. For the first pair HMM variant, no transitions are modeled between edit states; we only use transtion parameters associated with transiting from a start state to each of the edit</context>
</contexts>
<marker>Nabende, Tiedemann, Nerbonne, 2010</marker>
<rawString>Peter Nabende, Jorg Tiedemann, and John Nerbonne. 2010. Pair Hidden Markov Model for Named Entity Matching. In Tarek Sobh (ed.) Innovations and Advances in Computer Sciences and Engineering, pp 497–502, Springer, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Durbin</author>
<author>Sean R Eddy</author>
<author>Anders Krogh</author>
<author>Graeme Mitchison</author>
</authors>
<title>Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids.</title>
<date>1998</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<contexts>
<context position="5166" citStr="Durbin et al., 1998" startWordPosition="794" endWordPosition="797">o the Russian candidate transliterations. We expect the output to be ‘Johston, J KOxcTOx’ and ‘Atoll, aTOJIJI’ as the most likely single word transliterations from topic pair 1 after sorting out all the four transliteration similarity estimates in this particular case. We employ the pair HMM approach to estimate transliteration similarity for candidate source-target language words. A pair HMM has an emission state or states that generate two observation sequences instead of one observation sequence as is the case in standard HMMs. Pair HMMs originate from work in Biological sequence analysis (Durbin et al., 1998; Rivas and Eddy, 2001) from which variants were created and successfully applied in cognate identification (Mackay and Kondrak, 2005), Dutch dialect comparison (Wieling et al., 2007), transliteration identification (Nabende et al., 2010), and transliteration generation (Nabende, 2009). As mentioned earlier, we have first, tested two pair HMM variants on manually verified EnglishRussian datasets which we obtain from the previous shared task on machine transliteration (NEWS 2009) (Kumaran and Kellner, 2007). This preliminary test is aimed at determining the effect of pair HMM parameter changes </context>
</contexts>
<marker>Durbin, Eddy, Krogh, Mitchison, 1998</marker>
<rawString>Richard Durbin, Sean R. Eddy, Anders Krogh, Graeme Mitchison. 1998. Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wesley Mackay</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Computing Word Similarity and Identifying Cognates with Pair Hidden Markov Models.</title>
<date>2005</date>
<booktitle>Proceedings of the ninth Conference on Computational Natural Language Learning (CoNLL</booktitle>
<pages>40--47</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="5300" citStr="Mackay and Kondrak, 2005" startWordPosition="814" endWordPosition="817">y single word transliterations from topic pair 1 after sorting out all the four transliteration similarity estimates in this particular case. We employ the pair HMM approach to estimate transliteration similarity for candidate source-target language words. A pair HMM has an emission state or states that generate two observation sequences instead of one observation sequence as is the case in standard HMMs. Pair HMMs originate from work in Biological sequence analysis (Durbin et al., 1998; Rivas and Eddy, 2001) from which variants were created and successfully applied in cognate identification (Mackay and Kondrak, 2005), Dutch dialect comparison (Wieling et al., 2007), transliteration identification (Nabende et al., 2010), and transliteration generation (Nabende, 2009). As mentioned earlier, we have first, tested two pair HMM variants on manually verified EnglishRussian datasets which we obtain from the previous shared task on machine transliteration (NEWS 2009) (Kumaran and Kellner, 2007). This preliminary test is aimed at determining the effect of pair HMM parameter changes on the quality of the transliteration similarity estimates. For the first pair HMM variant, no transitions are modeled between edit st</context>
</contexts>
<marker>Mackay, Kondrak, 2005</marker>
<rawString>Wesley Mackay and Grzegorz Kondrak. 2005. Computing Word Similarity and Identifying Cognates with Pair Hidden Markov Models. Proceedings of the ninth Conference on Computational Natural Language Learning (CoNLL 2005), pp 40–47, Ann Arbor, Michigan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>