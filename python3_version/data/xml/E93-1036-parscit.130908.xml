<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.996091">
Generalized Left-Corner Parsing
</title>
<author confidence="0.995408">
Mark-Jan Nederhof *
</author>
<affiliation confidence="0.999477">
University of Nijmegen, Department of Computer Science
</affiliation>
<address confidence="0.442022">
Toernooiveld, 6525 ED Nijmegen, The Netherlands
</address>
<email confidence="0.512625">
markjan©cs.kun.n1
</email>
<sectionHeader confidence="0.997166" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.977756888888889">
We show how techniques known from gen-
eralized LR parsing can be applied to left-
corner parsing. The resulting parsing algo-
rithm for context-free grammars has some
advantages over generalized LR parsing:
the sizes and generation times of the parsers
are smaller, the produced output is more
compact, and the basic parsing technique
can more easily be adapted to arbitrary
context-free grammars.
The algorithm can be seen as an optimiza-
tion of algorithms known from existing lit-
erature. A strong advantage of our presen-
tation is that it makes explicit the role of
left-corner parsing in these algorithms.
Keywords: Generalized LR parsing, left-
corner parsing, chart parsing, hidden left
recursion.
</bodyText>
<sectionHeader confidence="0.999527" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999793666666667">
Generalized LR parsing was first described by
Tomita [Tomita, 1986; Tomita, 1987]. It has been
regarded as the most efficient parsing technique for
context-free grammars. The technique has been
adapted to other formalisms than context-free gram-
mars in [Tomita, 1988].
A useful property of generalized LR parsing
(henceforth abbreviated to GLR parsing) is that in-
put is parsed in polynomial time. To be exact, if the
length of the right side of the longest rule is p, and
if the length of the input is n, then the time com-
plexity is 0(nP+1). Theoretically, this may be worse
</bodyText>
<note confidence="0.6323505">
*Supported by the Dutch Organization for Scientific
Research (NWO), under grant 00-62-518
</note>
<bodyText confidence="0.98726172972973">
than the time complexity of Earley&apos;s algorithm [Ear-
ley, 1970], which is 0(n3). For practical cases in
natural language processing however, GLR parsing
seems to give the best results.
The polynomial time complexity is established by
using a graph-structured stack, which is a generaliza-
tion of the notion of parse stack, in which pointers are
used to connect stack elements. If nondeterminism
occurs, then the search paths are investigated simul-
taneously, where the initial part of the parse stack
which is common to all search paths is represented
only once. If two search paths share the state of
the top elements of their imaginary individual parse
stacks, then the top element is represented only once,
so that any computation which thereupon pushes el-
ements onto the stack is performed only once.
Another useful property of GLR parsing is that
the output is a concise representation of all possi-
ble parses, the so called parse forest, which can be
seen as a generalization of the notion of parse tree.
(By some authors, parse forests are more specifically
called shared, shared-packed, or packed shared (parse)
forests.) The parse forests produced by the algorithm
can be represented using 0(e+1) space. Efficient
decoration of parse forests with attribute values has
been investigated in [Dekkers et al., 1992].
There are however some drawbacks to GLR pars-
ing. In order of decreasing importance, these are:
• The parsing technique is based on the use of LR
tables, which may be very large for grammars
describing natural languages.&apos; Related to this
is the large amount of time needed to construct
[Purdom, 1974] argues that grammars for program-
ming languages require LR tables which have a size which
is about linear in the size of the grammar. It is gener-
ally considered doubtful that similar observations can be
made for grammars for natural languages.
</bodyText>
<page confidence="0.998216">
305
</page>
<bodyText confidence="0.979917666666667">
a parser. Incremental construction of parsers
may in some cases alleviate this problem [Rek-
ers, 1992].
</bodyText>
<listItem confidence="0.713948076923077">
• The parse forests produced by the algorithm are
not as compact as they might be. This is be-
cause packing of subtrees is guided by the merg-
ing of search paths due to equal LR states, in-
stead of by the equality of the derived nonter-
minals. The solution presented in [Rekers, 1992]
implies much computational overhead.
• Adapting the technique to arbitrary grammars
requires the generalization to cyclic graph-
structured stacks [Nozohoor-Farshi, 19911,
which may complicate the implementation.
• A minor disadvantage is that the theoretical
time complexity worsens if p becomes larger.
</listItem>
<bodyText confidence="0.998852774193548">
The solution given in [Kipps, 1991] to obtain
a variant of the parsing technique which has
a fixed time complexity of 0(n3), independent
of p, implies an overhead in computation costs
which worsens instead of improves the time com-
plexity in practical cases.
These disadvantages of generalized LR parsing
are mainly consequences of the LR parsing tech-
nique, more than consequences of the use of graph-
structured stacks and parse forests.
Lang [Lang, 1974; Lang, 1988c] gives a general con-
struction of deterministic parsing algorithms from
nondeterministic push-down automata. The pro-
duced data structures have a strong similarity to
parse forests, as argued in [Billot and Lang, 1989;
Lang, 1991]. The general idea of Lang has been
applied to other formalisms than context-free gram-
mars in [Lang, 1988a; Lang, 1988b; Lang, 1988d].
The idea of a graph-structured stack, however,
does not immediately follow from Lang&apos;s construc-
tion. Instead, Lang uses the abstract notion of a
table to store information, without trying to find the
best implementation for this table.2
One of the parsing techniques which can with
some minor difficulties be derived from the con-
struction of Lang is generalized left-corner parsing
(henceforth abbreviated to GLC parsing).3 The
starting-point is left-corner parsing, which was first
formally defined in [Rosenkrantz and Lewis II, 1970].
Generalized left-corner parsing, albeit under a dif-
ferent name, has first been investigated in [Pratt,
</bodyText>
<footnote confidence="0.590976818181818">
2[Sikkel, 1990] argues that the way in which the ta-
ble is implemented (using a two-dimensional matrix as
in case of Earley&apos;s algorithm or using a graph-structured
stack) is only of secondary importance to the global be-
haviour of the parsing algorithm.
3The term &amp;quot;generalized left-corner parsing&amp;quot; has been
used before in [Demers, 1977] for a different parsing tech-
nique. Demers generalizes &amp;quot;left corner of a right side&amp;quot; to
be a prefix of a right side which does not necessarily con-
sist of one member, whereas we generalize LC parsing
with zero lookahead to grammars which are not LC(0).
</footnote>
<bodyText confidence="0.999076954545455">
1975]. (See also [Tanaka et at., 1979; Bear, 1983;
Sikkel and Op den Akker, 1992].) In [Shann, 1991]
it was shown that the parsing technique can be a se-
rious rival to generalized LR parsing with regard to
the time complexities. (Other papers discussing the
time complexity of GLC parsing are [Slocum, 1981;
Wiren, 1987].)
A functional variant of GLC parsing for defi-
nite clause grammars has been discussed in [Mat-
sumoto and Sugimura, 1987]. This algorithm does
not achieve a polynomial time complexity however,
because no &amp;quot;packing&amp;quot; takes place.
A variant of Earley&apos;s algorithm discussed in [Leiss,
1990] also is very similar to GLC parsing although
the top-down nature of Earley&apos;s algorithm is pre-
served.
GLC parsing has been rediscovered a number of
times (e.g. in [Leermakers, 1989; Leermakers, 1992],
[Schabes, 1991], and [Perlin, 1991]), but without any
mention of the connection with LC parsing, which
made the presentations unnecessarily difficult to un-
derstand. This also prevented discovery of a number
of optimizations which are obvious from the view-
point of left-corner parsing.
In this paper we reinvestigate GLC parsing in
combination with graph-structured stacks and parse
forests. It is shown that this parsing technique is not
subject to the four disadvantages of the algorithm of
Tomita.
The structure of this paper is as follows. In Sec-
tion 2 we explain nondeterministic LC parsing. This
parsing algorithm is the starting-point of Section 3,
which shows how a deterministic algorithm can be
defined which uses a graph-structured stack and pro-
duces parse forests. Section 4 discusses how this gen-
eralized LC parsing algorithm can be adapted to ar-
bitrary context-free grammars.
How the algorithm can be improved to operate
in cubic time is shown in Section 5. The improved
algorithm produces parse forests in a non-standard
representation, which requires only cubic space. One
more class of optimizations is discussed in Section 6.
Preliminary results with an implementation of our
algorithm are discussed in Section 7.
</bodyText>
<sectionHeader confidence="0.942702" genericHeader="introduction">
2 Left-corner parsing
</sectionHeader>
<bodyText confidence="0.999945923076923">
Before we define LC parsing, we first define some
notions strongly connected with this kind of parsing.
We define a spine to be a path in a parse tree
which begins at some node which is not the first son
of its father (or which does not have a father), then
proceeds downwards every time taking the leftmost
son, and finally ends in a leaf.
We define the relation L between nonterminals
such that B L A if and only if there is a rule A B a,
where a denotes some sequence of grammar symbols.
The transitive and reflexive closure of L is denoted
by L*, which is called the left-corner relation. Infor-
mally, we have that B L* A if and only if it is possible
</bodyText>
<page confidence="0.998618">
306
</page>
<bodyText confidence="0.9708796">
to have a spine in some parse tree in which B occurs
below A (or B = A). We pronounce B L* A as &amp;quot;B is
a left corner of A&amp;quot;.
We define the set GOAL to be the set consisting
of S, the start symbol, and of all nonterminals A
which occur in a rule of the form B--o a A /3 where a
is not c (the empty sequence of grammar symbols).
Informally, a nonterminal is in GOAL if and only if
it may occur at the first node of some spine.
We explain LC parsing by means of the small
context-free grammar below. No claims are made
about the linguistic relevance of this grammar. Note
that we have transformed lexical ambiguity into
grammatical ambiguity by introducing the nonter-
minals VorN and VorP.
</bodyText>
<table confidence="0.790922181818182">
—+ NP VP
--+ S PP
NP —■ &amp;quot;time&amp;quot;
NP &amp;quot;an&amp;quot; „arrow&amp;quot;
NP NP NP
NP VorN
VP VorN
VP - VorP NP
PP --+ VorP NP
VorN --0 &amp;quot;flies&amp;quot;
VorP —■ &amp;quot;like&amp;quot;
</table>
<bodyText confidence="0.969603375">
The algorithm reads the input from left to right.
The elements on the parse stack are either nonter-
minals (the goal elements) or items (the item ele-
ments). Items consist of a rule in which a dot has
been inserted somewhere in the right side to separate
the members which have been recognized from those
which have not.
Initially, the parse stack consists only of the start
symbol, which is the first goal, as indicate in Fig-
ure 1. The indicated parse corresponds with one of
the two possible readings of &amp;quot;time flies like an arrow&amp;quot;
according to the grammar above.
We define a nondeterministic LC parser by the
parsing steps which are possible according to the fol-
lowing clauses:
la. If the element on top of the stack is the nonter-
minal A and if the first symbol of the remaining
input is t, then we may remove t from the input
and push an item [B —o t . a] onto the stack,
provided B e A.
lb. If the element on top of the stack is the non-
terminal A, then we may push an item [B —o .]
onto the stack, provided B L* A. (The item [B
.] is derived from an epsilon rule B --o c.)
</bodyText>
<listItem confidence="0.875516411764706">
2. If the element on top of the stack is the item
[A —o a . t I3] and if the first symbol of the
remaining input is t, then we may remove t from
the input and replace the item by the item [A
t. fl].
3. If the top-most two elements on the stack are B
[A a .], then we may replace the item by an
item of the form [C —0 A . A, provided C L* B.
4. If the top-most three elements on the stack are
[B . A 7] A [A a .], then we may replace
these three elements by the item [B —0 13 A . 7].
5. If a step according to one of the previous clauses
ends with an item [A —oa.BI3] on top of the
stack, where B is a nonterminal, then we subse-
quently push B onto the stack.
6. If the stack consists only of the two elements S
[S—o a.] and if the input has been completely
</listItem>
<bodyText confidence="0.980360588235294">
read, then we may successfully terminate the
parsing process.
Note that only nonterminals from GOAL will oc-
cur as separate elements on the stack.
The nondeterministic LC parsing algorithm de-
fined above uses one symbol of lookahead in case of
terminal left corners. The algorithm is therefore de-
terministic for the LC(0) grammars, according to the
definition of LC(k) grammars in [Soisalon-Soininen
and Ukkonen, 1979]. (This definition is incompati-
ble with that of [Rosenkrantz and Lewis II, 1970].)
The exact formulation of the algorithm above is
chosen to simplify the treatment of generalized LC
parsing in the next section. The strict separation be-
tween goal elements and item elements has also been
achieved in [Perlin, 1991], as opposed to [Schabes,
1991].
</bodyText>
<sectionHeader confidence="0.89025" genericHeader="method">
3 Generalizing left-corner parsing
</sectionHeader>
<bodyText confidence="0.999530923076923">
The construction of Lang can be used to form deter-
ministic table-driver parsing algorithms from non-
deterministic push-down automata. Because left-
corner parsers are also push-down automata, Lang&apos;s
construction can also be applied to formulate a de-
terministic parsing algorithm based on LC parsing.
The parsing algorithm we propose in this pa-
per does however not follow straightforwardly from
Lang&apos;s construction. If we applied the construction
directly, then not as much sharing would be provided
as we would like. This is caused by the fact that
sharing of computation of different search paths is
interrupted if different elements occur on top of the
stack (or just beneath the top if elements below the
top are investigated).
To explain this more carefully we focus on Clause 3
of the nondeterministic LC parser. Assume the fol-
lowing situation. Two different search paths have
at the same time the same item element [A a
on top of the stack. The goal elements (say B&apos; and
B&amp;quot;) below that item element are different however in
both search paths.
This means that the step which replaces [A —o .]
by [C —o A . fl], which is done for both search paths
(provided both C e B&apos; and C e B&amp;quot;), is done sepa-
rately because B&apos; and B&amp;quot; differ. This is unfortunate
</bodyText>
<page confidence="0.966694">
307
</page>
<figure confidence="0.996652666666667">
Step Parse stack Input read
S
1 S NP . &amp;quot;time&amp;quot; .] &amp;quot;time&amp;quot;
2 S NP --,. NP . NP] NP
3 S NP —* NP . NP] NP [VorN ---■ &amp;quot;flies&amp;quot; .] &amp;quot;flies&amp;quot;
4 S NP -- NP . NP] NP [NP ---* VorN .]
5 S NP -- NP NP.]
6 S S —* NP . VP] VP
7 S S —). NP . VP] VP [VorP --+ &amp;quot;like&amp;quot; .] &amp;quot;like&amp;quot;
8 S S --,- NP . VP] VP [VP —+ VorP . NP] NP
9 S S ---4 NP . VP] VP [VP VorP . NP] NP [NP &amp;quot;an&amp;quot; . &apos;arrow&amp;quot;] &amp;quot;an&amp;quot;
10 S S --i- NP . VP] VP [VP --■ VorP . NP] NP [NP —&gt; &amp;quot;an&amp;quot; &amp;quot;arrow&amp;quot; .] &amp;quot;arrow&amp;quot;
11 S S —). NP . VP] VP [VP —&gt; VorP NP .]
12 S S NP VP.]
13
</figure>
<figureCaption confidence="0.999982">
Figure 1: One possible sequence of parsing steps while reading &amp;quot;time flies like an arrow&amp;quot;
</figureCaption>
<bodyText confidence="0.994814551282052">
because sharing of computation in this case is desir-
able both for efficiency reasons but also because it
would simplify the construction of a most-compact
parse forest.
Related to the fact that we propose to implement
the parse table by means of a graph-structured stack,
our solution to this problem lies in the introduc-
tion of goal elements consisting of sets of nontermi-
nals from GOAL, instead of single nonterminals from
GOAL.
As an example, Figure 2 shows the state of the
graph-structured stack for the situation just after
reading &amp;quot;time flies&amp;quot;. Note that this state represents
the states of two different search paths of a nonde-
terministic LC parser after reading &amp;quot;time flies&amp;quot;, one
of which is the state after Step 3 in Figure 1.
We see that the goals NP and VP are merged in
one goal element so that there is only one edge from
the item element labelled with [VorN —* &amp;quot;flies&amp;quot; .] to
those goals.
Merging goals in one stack element is of course
only useful if those goals have at least one left corner
in common. For the simplicity of the algorithm, we
even allow merging of two goals in one goal element
if these goals have anything to do with each other
with respect to the left-corner relation L*.
Formally, we define an equivalence relation — on
nonterminals, which is the reflexive, transitive, and
symmetric closure of L. An equivalence class of this
relation which includes nonterminal A will be de-
noted by [A]. Each goal element will now consist
of a subset of some equivalence class of
In the running example, the goal elements con-
sist of subsets of {S, NP, VP, PP}, which is the only
equivalence class in this example.
Figures 3 and 4 give the complete generalized LC
parsing algorithm. At this stage we do not want to
complicate the algorithm by allowing epsilon rules in
the grammar. Consequently, Clause lb of the non-
deterministic LC parser will have no corresponding
piece of code in the GLC parsing algorithm. For
the other clauses, we will indicate where they can
be retraced in the new algorithm. In Section 4 we
explain how our algorithm can be extended so that
also grammars with epsilon rules can be handled.
The nodes and arrows in the parse forest are con-
structed by means of two functions:
MAKE_NODE (X) constructs a node with label X,
which is a terminal or nonterminal. It returns (the
address of) that node.
A node is associated with a number of lists of sons,
which are other nodes in the forest. Each list rep-
resents an alternative derivation of the nonterminal
with which the node is labelled. Initially, a node is
associated with an empty collection of lists of sons.
ADD_SUBNODE (in, 1) adds a list of sons 1 to the
node m.
In the algorithm, an item element el labelled with
[A Xi ... X,, . a] is associated with a list of
nodes deriving X1.....Xm. This list is accessed by
SONS (el). A list consisting of exactly one node m is
denoted by &lt;m&gt;, and list concatenation is denoted
by the operator +.
A goal element g contains for every nonterminal A
such that A L* P for some P in g a value NODE (g,
A), which is the node representing some derivation
of A found at the current input position, provided
such a derivation exists, and NODE (g, A) is NIL
otherwise.
In the graph-structured stack there may be an edge
from an item element to a unique goal element, and
from a goal in a goal element to a number of item
elements. For item element el, SUCCESSOR (el)
yields the unique goal element to which there is an
edge from el. For goal element g and goal P in g,
SUCCESSORS (g, P) yields the zero or more item
elements to which there is an edge from P in g.
The global variables used by the algorithm are the
</bodyText>
<page confidence="0.986762">
308
</page>
<table confidence="0.910959666666667">
---. NP . NP
LVorN --+ &amp;quot;flies&amp;quot; .
—■ NP . VP 2
</table>
<figureCaption confidence="0.998525">
Figure 2: The graph-structured stack after reading time flies&amp;quot;
</figureCaption>
<bodyText confidence="0.99973341025641">
following.
ao al ... a„ The symbols in the input string.
I The current input position.
r The root of the parse forest. It has the value NIL
at the end of the algorithm if no parse has been
found.
F and Fnezt The sets of goal elements containing
goals to be fulfilled from the current and next
input position on, respectively.
I and &apos;next The sets of item elements labelled with
[A --- a . t ill such that a shift may be performed
through t at the current and next input position,
respectively.
F The set of pairs (g, A) such that a derivation from
A has been found for g at the current input po-
sition. In other words, F is the set of all pairs
(g, A) such that NODE (g, A) 0 NIL.
The graph-structured stack (which is initially
empty) and the rules of the grammar are implicit
global data structures.
In a straightforward implementation, the relation
L* is recorded by means of one large 8&apos; x s boolean
matrix, where s is the number of nonterminals in the
grammar, and s&apos; is the number of elements in GOAL.
We can do better however by using the fact that A
L* B is never true if A 76 B. We propose the storage
of L* for every equivalence class of ,--, separately, i.e.
we store one t&apos; x t boolean matrix for every class of
;-, with t members, t&apos; of which are in GOAL.
We furthermore need a list of all rules A —,. X a
for each terminal and nonterminal X. A small op-
timization of top-town filtering (see also Section 6)
can be achieved by grouping the rules in these lists
according to the left sides A.
Note that the storage of the relation L* is the main
obstacle to a linear-sized parser.
The time needed to generate a parser is determined
by the time needed to compute L* and the classes of
,-, which is quadratic in the size of the grammar.
</bodyText>
<sectionHeader confidence="0.988949" genericHeader="method">
4 Adapting the algorithm for
arbitrary context-free grammars
</sectionHeader>
<bodyText confidence="0.96066854">
The generalized LC parsing algorithm from the pre-
vious section is only specified for grammars without
epsilon rules. Allowing epsilon rules would not only
complicate the algorithm but would for some gram-
mars also introduce the danger of non-termination of
the parsing process.
There are two sources of non-termination for non-
deterministic LC and LR parsing: cyclicity and hid-
den left-recursion. A grammar is said to be cyclic
if there is some derivation of the form A --++ A. A
grammar is said to be hidden left-recursive if A —p
B a, B --P* c, and a —).* A [3, for some A, B, a,
and P. Hidden left recursion is a special case of left
recursion where the fact is &amp;quot;hidden&amp;quot; by an empty-
generating nonterminal. (A nonterminal is said to
be nonfalse if it generates the empty string.)
Both sources of non-termination have been studied
extensively in [Nederhof and Koster, 1993; Nederhof
and Sarbo, 1993].
An obvious way to avoid non-termination for non-
deterministic LC parsers in case of hidden left-
recursive grammars is the following. We general-
ize the relation L so that B L A if and only if
there is a rule A -4 p B [3, where p is a (possibly
empty) sequence of grammar symbols such that p
—•.* c. Clause lb is eliminated and to compensate
this, Clauses la and 3 are modified so that they take
into account prefixes of right sides which generate
the empty string:
la. If the element on top of the stack is the nonter-
minal A and if the first symbol of the remaining
input is t, then we may remove t from the input
and push an item [B -4 p t. a] onto the stack,
provided B L* A and p --0.* c.
3. If the top-most two elements on the stack are B
[A --). a •], then we may replace the item by an
item of the form [C -4 p A . fi], provided C L*
B and p ---).* c.
These clauses now allow for nonfalse members at
the beginning of right sides. To allow for other non-
false members we need an extra seventh clause: 4
7. If the element on top of the stack is the item [A
—&gt; a . B [3], then we may replace this item by
the item [A --+ a B . fi], provided B --,.&amp;quot; c.
The same idea can be used in a straightforward
way to make generalized LC parsing suitable for
4Actually, an eighth clause is necessary to handle the
special case where S, the start symbol, is nonfalse, and
the input is empty. We omit this clause for the sake of
clarity.
</bodyText>
<page confidence="0.997291">
309
</page>
<listItem confidence="0.984189612244898">
PARSE:
• r &lt;= NIL
• Create goal element g consisting of S, the start symbol
• F &lt;= {g}
• I
• F
• for i &lt;=0 to n do PARSE_WORD
• return r, as the root of the parse forest
PARSE_WORD:
• r next &lt;= 0
• &apos;next
• for all pairs (g, A) E F do
o NODE (g, A) NIL
• F=0
• t &lt;= MAKE_NODE (ai)
• FIND_CORNERS (2)
• SHIFT (2)
• r rnext
• I .# Inexi
FIND_CORNERS (t): /* cf. Clause la of the nondeterministic LC parser */
• for all goal elements g in F containing goals in class [B] do
o for all rules A ai a such that A E [B] do
• if A L* P for some goal P in g /* top-down filtering */
then
o MAKE_ITEM_ELEM ([A —4 ai . a], &lt;2&gt;, g)
SHIFT (t): /* cf. Clause 2 */
• for all item elements el in I labelled with [A —&gt; a . ai )3] do
o MAKE_ITEM_ELEM ([A a ai . SONS (el) + &lt;1&gt;, SUCCESSOR (el))
MAKE_ITEM_ELEM ([A —+ a . 0], I, g): /* cf. Clause 5 */
• Create item element el labelled with [A . )3]
• SONS (el) &lt;=1
• Create an edge from el to g
• if 13 = c
then
o REDUCE (el)
elseif = try, where t is a terminal
then
o Inert &lt;= Inert U { el}
elseif = Bry, where B is a nonterminal
then
o MAKE_GOAL (B, el)
MAKE_GOAL (A, el):
• if there is a goal element g in I&apos; next containing goals in class [A]
then
o Add goal A to g (provided it is not already there)
else
o Create goal element g consisting of A
o Add g to Fnext
• Create an edge from A in g to el
</listItem>
<figureCaption confidence="0.99746">
Figure 3: The generalized LC parsing algorithm
</figureCaption>
<page confidence="0.988644">
310
</page>
<listItem confidence="0.981020863636363">
REDUCE (el):
• Assume the label of el is [A .]
• Assume SUCCESSOR (el) is g
• if NODE (g, A) = NIL
then
o in = MAKE_NODE (A)
o NODE (g, A) m
o F F U{(g, A)}
o for all rules B A # do /* cf. Clause 3 */
• if B e P for some goal P in g /* top-down filtering */
then
o MAKEITEM_ELEM ([B A. #], &lt;m&gt;, g)
o if A is a goal in g
then
• if SUCCESSORS (g, A) 0 0
then
o for all el&apos; E SUCCESSORS (g, A) labelled with [B 3. A 71 do /* cf. Clause 4 */
• MAKE_ITEM_ELEM ([B # A. 7], SONS (el&apos;) &lt;m&gt;, SUCCESSOR (ell)
elseif i = n /* cf. Clause 6 */
then
o r in
• ADD_SUBNODE (NODE (g, A), SONS (el))
</listItem>
<figureCaption confidence="0.999582">
Figure 4: The generalized LC parsing algorithm (continued)
</figureCaption>
<bodyText confidence="0.973042722222222">
hidden left-recursive grammars, similar to the way
this is handled in [Schabes, 1991] and [Leermakers,
1992]. The only technical problem is that, in or-
der to be able to construct a complete parse for-
est, we need precomputed subforests which derive
the empty string in every way from nonfalse nonter-
minals. This precomputation consists of performing
mA MAKE_NODE (A) for each nonfalse nonter-
minal A, (where mA are specific variables, one for
each nonterminal A) and subsequently performing
ADD_SUBNODE (mA , &lt;me, , , me, &gt;) for each
rule A -.4 B1 Bk consisting only of nonfalse non-
terminals. The variables rnA now contain pointers
to the required subforests.
GLC parsing is guaranteed to terminate also for
cyclic grammars, in which case the infinite amount
of parses is reflected by cyclic forests, which are also
discussed in ENozohoor-Farshi, 19911.
</bodyText>
<sectionHeader confidence="0.943062" genericHeader="method">
5 Parsing in cubic time
</sectionHeader>
<bodyText confidence="0.999833318181819">
The size of parse forests, even of those which are
optimally dense, can be more than cubic in the length
of the input. More precisely, the number of nodes in
a parse forest is 0(nP+1), where p is the length of
the right side of the longest rule.
Using the normal representation of parse forests
does therefore not allow cubic parsing algorithms
for arbitrary grammars. There is however a kind
of shorthand for parse forests which allows a repre-
sentation which only requires cubic space.
For example, suppose that of some rule A a
/3, the prefix a of the right side derives the same
part of the input in more than one way, then these
derivations may be combined in a new kind of packed
node. Instead of the multiple derivations from a, this
packed node is then combined with the derivations
from # deriving subsequent input. We call packing of
derivations from prefixes of right sides subpacking to
distinguish this from normal packing of derivations
from one nonterminal.
Subpacking has been discussed in [Billot and Lang,
1989; Leiss, 1990; Leermakers, 1991]; see also [Shell,
1976].
Connected with cubic representation of parse
forests is cubic parsing. The GLC parsing algorithm
in Section 3 has a time complexity of 0(e+1). The
algorithm can be easily changed so that, with a lit-
tle amount of overhead, the time complexity is re-
duced to 0(n3), similar to the algorithms in [Perlin,
1991] and [Leermakers, 1992], and the algorithm pro-
duces parse forests with subpacking, which require
only 0(n3) space for storage.
We consider how this can be accomplished. First
we define the underlying rule of an item element la-
belled with [A . to be the rule A fl. Now
suppose that two item elements ell and e12 with the
same underlying rule, with the dot at the same posi-
tion and with the same successor are created at the
same input position, then we may perform subpack-
ing for the prefix of the right side before the dot.
From then on, we only need one of the item elements
e/i and el2 for continuing the parsing process.
Whether two item elements have one and the same
goal element as successors cannot be efficiently veri-
</bodyText>
<page confidence="0.99748">
311
</page>
<bodyText confidence="0.999907142857143">
fled. Therefore we propose to introduce a new kind
of stack element which takes over the role of all for-
mer item elements whose successors are one and the
same goal element and which have the same under-
lying rule.
We leave the details to the imagination of the
reader.
</bodyText>
<sectionHeader confidence="0.790355" genericHeader="method">
6 Optimization of top-down filtering
</sectionHeader>
<bodyText confidence="0.999968536585366">
One of the most time-costly activities of general-
ized LC parsing is the check whether for a goal el-
ement g and a nonterminal A there is some goal P
in g such that A L* P. This check, which is some-
times called top-down filtering, occurs in the routines
FIND_CORNERS and REDUCE. We propose some
optimizations to reduce the number of goals P in g
for which A L* P has to be checked.
The most straightforward optimization consists of
annotating every edge from an item element labelled
with [A --4 a . fl] to a goal element g with the sub-
set of goals in g which does not include those goals
P for which A L* P has already been found to be
false. This is the set of goals in g which are actu-
ally useful in top-down filtering when a new item
element labelled with [B A . 7] is created during a
REDUCE (see the piece of code in REDUCE corre-
sponding with Clause 3 of the nondeterministic LC
parser). The idea is that if A L* P does not hold
for goal P in g, then neither does B L* P if A L B.
This optimization can be realized very easily if sets
of goals are implemented as lists.
A second optimization is useful if L is such that
there are many nonterminals A such that there is
only one B with A L B. In case we have such a non-
terminal A which is not a goal, then no top-down
filtering needs to be performed when a new item el-
ement labelled with [B —&gt; A. a] is created during a
REDUCE. This can be explained by the fact that if
for some goal P we have A L* P, and if A 0 P, and if
there is only one B such that A L B, then we already
know that B L* P.
There are many more of these optimizations but
not all of these give better performance in all cases.
It depends heavily on the properties of L whether
the gain in time while performing the actual top-
down filtering (i.e. performing the tests A L* P for
some P in a particular subset of the goals in a goal
element g) outweighs the time needed to set up ex-
tra administration for the purpose of reducing those
subsets of the goals.
</bodyText>
<sectionHeader confidence="0.959545" genericHeader="conclusions">
7 Preliminary results
</sectionHeader>
<bodyText confidence="0.999965217391304">
Only recently the author has implemented a GLC
parser. The algorithm as presented in this paper has
been implemented almost literally, with the treat-
ment of epsilon rules as suggested in Section 4. A
small adaptation has been made to deal with termi-
nals of different lengths.
Also recently, some members of our department
have completed the implementation of a GLR parser.
Because both systems have been implemented us-
ing different programming languages, fair compari-
son of the two systems is difficult. Specific problems
which occurred concerning the efficient calculation of
LR tables and the correct treatment of epsilon rules
for GLR parsing suggest that GLR parsing requires
more effort to implement than GLC parsing.
Preliminary tests show that the division of nonter-
minals into equivalence classes yields disappointing
results. In all tested cases, one large class contained
most of the nonterminals.
The first optimization discussed in Section 6
proved to be very useful. The number of goals which
had to be considered could in some cases be reduced
to one fifth.
</bodyText>
<subsectionHeader confidence="0.54176">
Conclusions
</subsectionHeader>
<bodyText confidence="0.9967186">
We have discussed a parsing algorithm for context-
free grammars called generalized LC parsing. This
parsing algorithm has the following advantages over
generalized LR parsing (in order of decreasing im-
portance).
</bodyText>
<listItem confidence="0.974098727272727">
• The size of a parser is much smaller; if we neglect
the storage of the relation L* , the size is even
linear in the size of the grammar. Related to
this, only a little amount of time is needed to
generate a parser.
• The generated parse forests are as compact as
possible.
• Cyclic and hidden left-recursive grammars can
be handled more easily and more efficiently (Sec-
tion 4).
• As Section 5 shows, GLC parsing can more eas-
</listItem>
<bodyText confidence="0.918077904761905">
ily be made to run in cubic time for arbitrary
context-free grammars. Furthermore, this can
be done without much loss of efficiency in prac-
tical cases.
Because LR parsing is a more refined form of pars-
ing than LC parsing, generalized LR parsing may
at least for some grammars be more efficient than
generalized LC parsing.5 However, we feel that this
does not outweigh the disadvantages of the large sizes
and generation times of LR parsers in general, which
renders GLR parsing unfeasible in some natural lan-
guage applications.
GLC parsing does not suffer from these defects.
We therefore propose this parsing algorithm as a rea-
sonable alternative to GLR parsing. Because of the
small generation time of GLC parsers, we expect this
kind of parsing to be particularly appropriate dur-
ing the development of grammars, when grammars
&apos;The ratio between the time complexities of GLC
parsing and GLR parsing is smaller than some constant,
which is dependent on the gramma&apos;.
</bodyText>
<page confidence="0.995477">
312
</page>
<bodyText confidence="0.999586263157895">
change often and consequently new parsers have to
be generated many times.
As we have shown in this paper, the implementa-
tion of GLC parsing using a graph-structured stack
allows many optimizations. These optimizations
would be less straightforward and possibly less ef-
fective if a two-dimensional matrix was used for the
implementation of the parse table. Furthermore, ma-
trices require a large amount of space, especially for
long input, causing overhead for initialization (at
least if no optimizations are used).
In contrast, the time and space requirements of
GLC parsing using a graph-structured stack are only
a negligible quantity above that of nondeterministic
LC parsing if no nondeterminism occurs (e.g. if the
grammar is LC(0)). Only in the worst-case does a
graph-structured stack require the same amount of
space as a matrix.
In this paper we have not considered GLC parsing
with more lookahead than one symbol for terminal
left corners. The reason for this is that we feel that
one of the main advantages of our parsing algorithm
over GLR parsing is the small sizes of the parsers.
Adding more lookahead requires larger tables and
may therefore reduce the advantage of generalized
LC parsing over its LR counterpart.
On the other hand, the phenomenon reported in
[Billot and Lang, 1989] and [Lankhorst, 1991] that
the time complexity of GLR parsing sometimes wors-
ens if more lookahead is used, does possibly not apply
to GLC parsing. For GLR parsing, more lookahead
may result in more LR states, which may result in
less sharing of computation. For GLC parsing there
is however no relation between the amount of looka-
head and the amount of sharing of computation.
Therefore, a judicious use of extra lookahead may
on the whole be advantageous to the usefulness of
GLC parsing.
</bodyText>
<sectionHeader confidence="0.994675" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.915213">
The author is greatly indebted to Klaas Sikkel, Janos
Sarbo, Franc Grootjen, and Kees Koster, for many
fruitful discussions. Valuable correspondence with
Rene Leermakers, Jan Rekers, Masaru Tomita, and
Dick Grune is gratefully acknowledged.
</bodyText>
<sectionHeader confidence="0.998257" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997801061538462">
[Bear, 19831 J. Bear. A breadth-first parsing model.
In Proc. of the Eighth International Joint Con-
ference on Artificial Intelligence, volume 2, pages
696-698, Karlsruhe, West Germany, August 1983.
[Billot and Lang, 1989] S. Billot and B. Lang. The
structure of shared forests in ambiguous parsing.
In 27th Annual Meeting of the ACL [1], pages 143-
151.
[Dekkers et al., 1992] C. Dekkers, M.J. Nederhof,
and J.J. Sarbo. Coping with ambiguity in dec-
orated parse forests. In Coping with Linguistic
Ambiguity in Typed Feature Formalisms, Proceed-
ings of a Workshop held at ECAI 92, pages 11-19,
Vienna, Austria, August 1992.
[Demers, 19771 A.J. Demers. Generalized left cor-
ner parsing. In Conference Record of the Fourth
ACM Symposium on Principles of Programming
Languages, pages 170-182, Los Angeles, Califor-
nia, January 1977.
[Earley, 1970] J. Earley. An efficient context-free
parsing algorithm. Communications of the ACM,
13(2):94-102, February 1970.
[Kipps, 1991] J.R. Kipps. GLR parsing in time
0(n3). In [Tomita, 1991], chapter 4, pages 43-59.
[Lang, 1974] B. Lang. Deterministic techniques
for efficient non-deterministic parsers. In Au-
tomata, Languages and Programming, 2nd Col-
loquium, Lecture Notes in Computer Science,
volume 14, pages 255-269, Saarbriicken, 1974.
Springer-Verlag.
[Lang, 1988a] B. Lang. Complete evaluation of
Horn clauses: An automata theoretic approach.
Rapport de Recherche 913, Institut National de
Recherche en Informatique et en Automatique,
Rocquencourt, France, November 1988.
[Lang, 1988b1 B. Lang. Datalog automata. In Proc.
of the Third International Conference on Data
and Knowledge Bases: Improving Usability and
Responsiveness, pages 389-401, Jerusalem, June
1988.
[Lang, 1988c] B. Lang. Parsing incomplete sen-
tences. In Proc. of the 12th International Con-
ference on Computational Linguistics, volume 1,
pages 365-371, Budapest, August 1988.
[Lang, 1988d] B. Lang. The systematic construction
of Earley parsers: Application to the production of
0(n6) Earley parsers for tree adjoining grammars.
Unpublished paper, December 1988.
[Lang, 1991] B. Lang. Towards a uniform for-
mal framework for parsing. In M. Tomita, edi-
tor, Current Issues in Parsing Technology, chap-
ter 11, pages 153-171. Kluwer Academic Publish-
ers, 1991.
[Lankhorst, 19911 M. Lankhorst. An empirical com-
parison of generalized LR tables. In R. Heemels,
A. Nijholt, and K. Sikkel, editors, Tomita&apos;s Al-
gorithm: Extensions and Applications, Proc. of
the first Twente Workshop on Language Technol-
ogy, pages 87-93. University of Twente, September
1991. Memoranda Informatica 91-68.
[Leermakers, 1989] R. Leermakers. How to cover a
grammar. In 27th Annual Meeting of the ACL [1],
pages 135-142.
[Leermakers, 1991] R. Leermakers. Non-
deterministic recursive ascent parsing. In Fifth
</reference>
<page confidence="0.992758">
313
</page>
<reference confidence="0.999668471698113">
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics, Proceedings
of the Conference, pages 63-68, Berlin, Germany,
April 1991.
[Leermakers, 1992] R. Leermakers. A recursive as-
cent Earley parser. Information Processing Let-
ters, 41(2):87-91, February 1992.
[Leiss, 1990] H. Leiss. On Kilbury&apos;s modification of
Earley&apos;s algorithm. ACM Transactions on Pro-
gramming Languages and Systems, 12(4):610-640,
October 1990.
[Matsumoto and Sugimura, 19871
Y. Matsumoto and R. Sugimura. A parsing system
based on logic programming. In Proc. of the Tenth
International Joint Conference on Artificial Intel-
ligence, volume 2, pages 671-674, Milan, August
1987.
[Nederhof, 1992] M.J. Nederhof. Generalized left-
corner parsing. Technical report no. 92-21, Uni-
versity of Nijmegen, Department of Computer Sci-
ence, August 1992.
[Nederhof and Koster, 1993]
M.J. Nederhof and C.H.A. Koster. Top-down pars-
ing of left-recursive grammars. Technical report,
University of Nijmegen, Department of Computer
Science, 1993. forthcoming.
[Nederhof and Sarbo, 1993] M.J. Nederhof and J.J.
Sarbo. Increasing the applicability of LR parsing.
Submitted for publication, 1993.
[Nozohoor-Farshi, 19911 R. Nozohoor-Farshi. GLR
parsing for s-grammars. In [Tomita, 1991], chap-
ter 5, pages 61-75.
[Perlin, 1991] M. Perlin. LR recursive transition net-
works for Earley and Tomita parsing. In 29th An-
nual Meeting of the ACL [2], pages 98-105.
[Pratt, 1975] V.R. Pratt. LINGOL - A progress re-
port. In Advance Papers of the Fourth Interna-
tional Joint Conference on Artificial Intelligence,
pages 422-428, Tbilisi, Georgia, USSR, September
1975.
[Purdom, 1974] P. Purdom. The size of LALR (1)
parsers. BIT, 14:326-337,1974.
[Rekers, 1992] J. Rekers. Parser Generation for In-
teractive Environments. PhD thesis, University of
Amsterdam, 1992.
[Rosenkrantz and Lewis II, 19701 D.J. Rosenkrantz
and P.M. Lewis II. Deterministic left corner pars-
ing. In IEEE Conference Record of the 11th An-
nual Symposium on Switching and Automata The-
ory, pages 139-152,1970.
[Schabes, 1991] Y. Schabes. Polynomial time and
space shift-reduce parsing of arbitrary context-free
grammars. In 29th Annual Meeting of the ACL [2],
pages 106-113.
[Shann, 1991] P. Shann. Experiments with GLR and
chart parsing. In [Tomita, 1991], chapter 2, pages
17-34.
[Sheil, 1976] B.A. Sheil. Observations on context-
free parsing. Statistical Methods in Linguistics,
1976, pages 71-109.
[Sikkel, 1990] K. Sikkel. Cross-fertilization of Ear-
ley and Tomita. Memoranda informatica 90-69,
University of Twente, November 1990.
[Sikkel and Op den Akker, 1992]
K. Sikkel and R. op den Akker. Head-corner chart
parsing. In Computing Science in the Netherlands,
Utrecht, November 1992.
[Slocum, 1981] J. Slocum. A practical comparison of
parsing strategies. In 19th Annual Meeting of the
Association for Computational Linguistics, Pro-
ceedings of the Conference, pages 1-6, Stanford,
California, June—July 1981.
[Soisalon-Soininen and Ukkonen, 1979] E. Soisalon-
Soininen and E. Ukkonen. A method for trans-
forming grammars into LL(k) form. Acta Infor-
matica, 12:339-369,1979.
[Tanaka et al., 1979] H. Tanaka, T. Sato, and F. Mo-
toyoshi. Predictive control parser: Extended LIN-
GOL. In Proc. of the Sixth International Joint
Conference on Artificial Intelligence, volume 2,
pages 868-870, Tokyo, August 1979.
[Tomita, 1986] M. Tomita. Efficient Parsing for
Natural Language. Kluwer Academic Publishers,
1986.
[Tomita, 1987] M. Tomita. An efficient augmented-
context-free parsing algorithm. Computational
Linguistics, 13:31-46,1987.
[Tomita, 1988] M. Tomita. Graph-structured stack
and natural language parsing. In 26th Annual
Meeting of the Association for Computational Lin-
guistics, Proceedings of the Conference, pages 249-
257, Buffalo, New York, June 1988.
[Tomita, 1991] M. Tomita, editor. Generalized LR
Parsing. Kluwer Academic Publishers, 1991.
[Wiren, 1987] Mats Wiren. A comparison of rule-
invocation strategies in context-free chart pars-
ing. In Third Conference of the European Chap-
ter of the Association for Computational Linguis-
tics, Proceedings of the Conference, pages 226-233,
Copenhagen, Denmark, April 1987.
[1] 27th Annual Meeting of the Association for Com-
putational Linguistics, Proceedings of the Confer-
ence, Vancouver, British Columbia, June 1989.
[2] 29th Annual Meeting of the Association for Com-
putational Linguistics, Proceedings of the Confer-
ence, Berkeley, California, June 1991.
</reference>
<page confidence="0.999134">
314
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.360122">
<title confidence="0.997808">Generalized Left-Corner Parsing</title>
<author confidence="0.875448">Mark-Jan Nederhof</author>
<affiliation confidence="0.999663">University of Nijmegen, Department of Computer Science</affiliation>
<address confidence="0.974821">Toernooiveld, 6525 ED Nijmegen, The Netherlands</address>
<email confidence="0.441228">markjan©cs.kun.n1</email>
<abstract confidence="0.996583842105263">We show how techniques known from generalized LR parsing can be applied to leftcorner parsing. The resulting parsing algorithm for context-free grammars has some advantages over generalized LR parsing: the sizes and generation times of the parsers are smaller, the produced output is more compact, and the basic parsing technique can more easily be adapted to arbitrary context-free grammars. The algorithm can be seen as an optimization of algorithms known from existing literature. A strong advantage of our presentation is that it makes explicit the role of left-corner parsing in these algorithms. LR parsing, leftcorner parsing, chart parsing, hidden left recursion.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>A breadth-first parsing model.</title>
<date>1983</date>
<booktitle>In Proc. of the Eighth International Joint Conference on Artificial Intelligence,</booktitle>
<volume>2</volume>
<pages>696--698</pages>
<location>Karlsruhe, West Germany,</location>
<marker>1983</marker>
<rawString> [Bear, 19831 J. Bear. A breadth-first parsing model. In Proc. of the Eighth International Joint Conference on Artificial Intelligence, volume 2, pages 696-698, Karlsruhe, West Germany, August 1983.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Billot</author>
<author>B Lang</author>
</authors>
<title>The structure of shared forests in ambiguous parsing.</title>
<booktitle>In 27th Annual Meeting of the ACL [1],</booktitle>
<pages>143--151</pages>
<marker>[Billot and Lang, 1989]</marker>
<rawString>S. Billot and B. Lang. The structure of shared forests in ambiguous parsing. In 27th Annual Meeting of the ACL [1], pages 143-151.</rawString>
</citation>
<citation valid="false">
<authors>
<author>C Dekkers</author>
<author>M J Nederhof</author>
<author>J J Sarbo</author>
</authors>
<title>Coping with ambiguity in decorated parse forests. In Coping with Linguistic Ambiguity in Typed Feature Formalisms,</title>
<date>1992</date>
<booktitle>Proceedings of a Workshop held at ECAI 92,</booktitle>
<pages>11--19</pages>
<location>Vienna, Austria,</location>
<marker>[Dekkers et al., 1992]</marker>
<rawString>C. Dekkers, M.J. Nederhof, and J.J. Sarbo. Coping with ambiguity in decorated parse forests. In Coping with Linguistic Ambiguity in Typed Feature Formalisms, Proceedings of a Workshop held at ECAI 92, pages 11-19, Vienna, Austria, August 1992. [Demers, 19771 A.J. Demers. Generalized left corner parsing. In Conference Record of the Fourth ACM Symposium on Principles of Programming Languages, pages 170-182, Los Angeles, California, January 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Earley</author>
</authors>
<title>An efficient context-free parsing algorithm.</title>
<date>1970</date>
<journal>Communications of the ACM,</journal>
<pages>13--2</pages>
<marker>[Earley, 1970]</marker>
<rawString>J. Earley. An efficient context-free parsing algorithm. Communications of the ACM, 13(2):94-102, February 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Kipps</author>
</authors>
<title>GLR parsing in time 0(n3). In [Tomita,</title>
<date>1991</date>
<pages>43--59</pages>
<note>chapter 4,</note>
<marker>[Kipps, 1991]</marker>
<rawString>J.R. Kipps. GLR parsing in time 0(n3). In [Tomita, 1991], chapter 4, pages 43-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lang</author>
</authors>
<title>Deterministic techniques for efficient non-deterministic parsers.</title>
<date>1974</date>
<booktitle>In Automata, Languages and Programming, 2nd Colloquium, Lecture Notes in Computer Science,</booktitle>
<volume>14</volume>
<pages>255--269</pages>
<publisher>Springer-Verlag.</publisher>
<location>Saarbriicken,</location>
<marker>[Lang, 1974]</marker>
<rawString>B. Lang. Deterministic techniques for efficient non-deterministic parsers. In Automata, Languages and Programming, 2nd Colloquium, Lecture Notes in Computer Science, volume 14, pages 255-269, Saarbriicken, 1974. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lang</author>
</authors>
<title>Complete evaluation of Horn clauses: An automata theoretic approach. Rapport de Recherche 913, Institut National de Recherche en Informatique et en Automatique,</title>
<date>1988</date>
<booktitle>In Proc. of the Third International Conference on Data and Knowledge Bases: Improving Usability and Responsiveness,</booktitle>
<pages>389--401</pages>
<location>Rocquencourt, France,</location>
<marker>[Lang, 1988a]</marker>
<rawString>B. Lang. Complete evaluation of Horn clauses: An automata theoretic approach. Rapport de Recherche 913, Institut National de Recherche en Informatique et en Automatique, Rocquencourt, France, November 1988. [Lang, 1988b1 B. Lang. Datalog automata. In Proc. of the Third International Conference on Data and Knowledge Bases: Improving Usability and Responsiveness, pages 389-401, Jerusalem, June 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lang</author>
</authors>
<title>Parsing incomplete sentences.</title>
<date>1988</date>
<booktitle>In Proc. of the 12th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>365--371</pages>
<location>Budapest,</location>
<marker>[Lang, 1988c]</marker>
<rawString>B. Lang. Parsing incomplete sentences. In Proc. of the 12th International Conference on Computational Linguistics, volume 1, pages 365-371, Budapest, August 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lang</author>
</authors>
<title>The systematic construction of Earley parsers: Application to the production of 0(n6) Earley parsers for tree adjoining grammars. Unpublished paper,</title>
<date>1988</date>
<marker>[Lang, 1988d]</marker>
<rawString>B. Lang. The systematic construction of Earley parsers: Application to the production of 0(n6) Earley parsers for tree adjoining grammars. Unpublished paper, December 1988.</rawString>
</citation>
<citation valid="false">
<authors>
<author>B Lang</author>
</authors>
<title>Towards a uniform formal framework for parsing.</title>
<date>1991</date>
<journal>Memoranda Informatica</journal>
<booktitle>Current Issues in Parsing Technology, chapter 11,</booktitle>
<pages>153--171</pages>
<editor>In M. Tomita, editor,</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<institution>University of Twente,</institution>
<marker>[Lang, 1991]</marker>
<rawString>B. Lang. Towards a uniform formal framework for parsing. In M. Tomita, editor, Current Issues in Parsing Technology, chapter 11, pages 153-171. Kluwer Academic Publishers, 1991. [Lankhorst, 19911 M. Lankhorst. An empirical comparison of generalized LR tables. In R. Heemels, A. Nijholt, and K. Sikkel, editors, Tomita&apos;s Algorithm: Extensions and Applications, Proc. of the first Twente Workshop on Language Technology, pages 87-93. University of Twente, September 1991. Memoranda Informatica 91-68.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Leermakers</author>
</authors>
<title>How to cover a grammar.</title>
<booktitle>In 27th Annual Meeting of the ACL [1],</booktitle>
<pages>135--142</pages>
<marker>[Leermakers, 1989]</marker>
<rawString>R. Leermakers. How to cover a grammar. In 27th Annual Meeting of the ACL [1], pages 135-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leermakers</author>
</authors>
<title>Nondeterministic recursive ascent parsing.</title>
<date>1991</date>
<booktitle>In Fifth Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference,</booktitle>
<pages>63--68</pages>
<location>Berlin, Germany,</location>
<marker>[Leermakers, 1991]</marker>
<rawString>R. Leermakers. Nondeterministic recursive ascent parsing. In Fifth Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference, pages 63-68, Berlin, Germany, April 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leermakers</author>
</authors>
<title>A recursive ascent Earley parser.</title>
<date>1992</date>
<journal>Information Processing Letters,</journal>
<pages>41--2</pages>
<marker>[Leermakers, 1992]</marker>
<rawString>R. Leermakers. A recursive ascent Earley parser. Information Processing Letters, 41(2):87-91, February 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Leiss</author>
</authors>
<title>On Kilbury&apos;s modification of Earley&apos;s algorithm.</title>
<date>1990</date>
<journal>ACM Transactions on Programming Languages and Systems,</journal>
<booktitle>In Proc. of the Tenth International Joint Conference on Artificial Intelligence,</booktitle>
<volume>2</volume>
<pages>12--4</pages>
<location>Milan,</location>
<marker>[Leiss, 1990]</marker>
<rawString>H. Leiss. On Kilbury&apos;s modification of Earley&apos;s algorithm. ACM Transactions on Programming Languages and Systems, 12(4):610-640, October 1990. [Matsumoto and Sugimura, 19871 Y. Matsumoto and R. Sugimura. A parsing system based on logic programming. In Proc. of the Tenth International Joint Conference on Artificial Intelligence, volume 2, pages 671-674, Milan, August 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Nederhof</author>
</authors>
<title>Generalized leftcorner parsing.</title>
<date>1992</date>
<tech>Technical report no. 92-21,</tech>
<institution>University of Nijmegen, Department of Computer Science,</institution>
<marker>[Nederhof, 1992]</marker>
<rawString>M.J. Nederhof. Generalized leftcorner parsing. Technical report no. 92-21, University of Nijmegen, Department of Computer Science, August 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Nederhof</author>
<author>C H A Koster</author>
</authors>
<title>Top-down parsing of left-recursive grammars.</title>
<date>1993</date>
<tech>Technical report,</tech>
<pages>forthcoming.</pages>
<institution>University of Nijmegen, Department of Computer Science,</institution>
<marker>[Nederhof and Koster, 1993]</marker>
<rawString> M.J. Nederhof and C.H.A. Koster. Top-down parsing of left-recursive grammars. Technical report, University of Nijmegen, Department of Computer Science, 1993. forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Nederhof</author>
<author>J J Sarbo</author>
</authors>
<title>Increasing the applicability of LR parsing. Submitted for publication,</title>
<date>1993</date>
<pages>61--75</pages>
<marker>[Nederhof and Sarbo, 1993]</marker>
<rawString>M.J. Nederhof and J.J. Sarbo. Increasing the applicability of LR parsing. Submitted for publication, 1993. [Nozohoor-Farshi, 19911 R. Nozohoor-Farshi. GLR parsing for s-grammars. In [Tomita, 1991], chapter 5, pages 61-75.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Perlin</author>
</authors>
<title>LR recursive transition networks for Earley and Tomita parsing.</title>
<booktitle>In 29th Annual Meeting of the ACL [2],</booktitle>
<pages>98--105</pages>
<marker>[Perlin, 1991]</marker>
<rawString>M. Perlin. LR recursive transition networks for Earley and Tomita parsing. In 29th Annual Meeting of the ACL [2], pages 98-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V R Pratt</author>
</authors>
<title>LINGOL - A progress report.</title>
<date>1975</date>
<booktitle>In Advance Papers of the Fourth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>422--428</pages>
<location>Tbilisi, Georgia, USSR,</location>
<marker>[Pratt, 1975]</marker>
<rawString>V.R. Pratt. LINGOL - A progress report. In Advance Papers of the Fourth International Joint Conference on Artificial Intelligence, pages 422-428, Tbilisi, Georgia, USSR, September 1975.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Purdom</author>
</authors>
<title>The size of LALR (1) parsers.</title>
<journal>BIT,</journal>
<pages>14--326</pages>
<marker>[Purdom, 1974]</marker>
<rawString>P. Purdom. The size of LALR (1) parsers. BIT, 14:326-337,1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rekers</author>
</authors>
<title>Parser Generation for Interactive Environments. PhD thesis,</title>
<date>1992</date>
<booktitle>Rosenkrantz and Lewis II, 19701 D.J. Rosenkrantz</booktitle>
<pages>139--152</pages>
<institution>University of Amsterdam,</institution>
<marker>[Rekers, 1992]</marker>
<rawString>J. Rekers. Parser Generation for Interactive Environments. PhD thesis, University of Amsterdam, 1992. [Rosenkrantz and Lewis II, 19701 D.J. Rosenkrantz and P.M. Lewis II. Deterministic left corner parsing. In IEEE Conference Record of the 11th Annual Symposium on Switching and Automata Theory, pages 139-152,1970.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Y Schabes</author>
</authors>
<title>Polynomial time and space shift-reduce parsing of arbitrary context-free grammars.</title>
<booktitle>In 29th Annual Meeting of the ACL [2],</booktitle>
<pages>106--113</pages>
<marker>[Schabes, 1991]</marker>
<rawString>Y. Schabes. Polynomial time and space shift-reduce parsing of arbitrary context-free grammars. In 29th Annual Meeting of the ACL [2], pages 106-113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Shann</author>
</authors>
<title>Experiments with GLR and chart parsing.</title>
<date>1991</date>
<booktitle>In [Tomita,</booktitle>
<pages>17--34</pages>
<note>chapter 2,</note>
<marker>[Shann, 1991]</marker>
<rawString>P. Shann. Experiments with GLR and chart parsing. In [Tomita, 1991], chapter 2, pages 17-34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B A Sheil</author>
</authors>
<title>Observations on contextfree parsing. Statistical Methods in Linguistics,</title>
<date>1976</date>
<pages>71--109</pages>
<marker>[Sheil, 1976]</marker>
<rawString>B.A. Sheil. Observations on contextfree parsing. Statistical Methods in Linguistics, 1976, pages 71-109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sikkel</author>
</authors>
<title>Cross-fertilization of Earley and Tomita. Memoranda informatica 90-69,</title>
<date>1990</date>
<institution>University of Twente,</institution>
<marker>[Sikkel, 1990]</marker>
<rawString>K. Sikkel. Cross-fertilization of Earley and Tomita. Memoranda informatica 90-69, University of Twente, November 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sikkel</author>
<author>R op den Akker</author>
</authors>
<title>Head-corner chart parsing.</title>
<date>1992</date>
<booktitle>In Computing Science in the Netherlands,</booktitle>
<location>Utrecht,</location>
<marker>[Sikkel and Op den Akker, 1992]</marker>
<rawString> K. Sikkel and R. op den Akker. Head-corner chart parsing. In Computing Science in the Netherlands, Utrecht, November 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Slocum</author>
</authors>
<title>A practical comparison of parsing strategies.</title>
<date>1981</date>
<booktitle>In 19th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference,</booktitle>
<pages>1--6</pages>
<location>Stanford, California, June—July</location>
<marker>[Slocum, 1981]</marker>
<rawString>J. Slocum. A practical comparison of parsing strategies. In 19th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, pages 1-6, Stanford, California, June—July 1981.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E SoisalonSoininen</author>
<author>E Ukkonen</author>
</authors>
<title>A method for transforming grammars into LL(k) form.</title>
<journal>Acta Informatica,</journal>
<pages>12--339</pages>
<marker>[Soisalon-Soininen and Ukkonen, 1979]</marker>
<rawString>E. SoisalonSoininen and E. Ukkonen. A method for transforming grammars into LL(k) form. Acta Informatica, 12:339-369,1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tanaka</author>
<author>T Sato</author>
<author>F Motoyoshi</author>
</authors>
<title>Predictive control parser: Extended LINGOL.</title>
<date>1979</date>
<booktitle>In Proc. of the Sixth International Joint Conference on Artificial Intelligence,</booktitle>
<volume>2</volume>
<pages>868--870</pages>
<location>Tokyo,</location>
<marker>[Tanaka et al., 1979]</marker>
<rawString>H. Tanaka, T. Sato, and F. Motoyoshi. Predictive control parser: Extended LINGOL. In Proc. of the Sixth International Joint Conference on Artificial Intelligence, volume 2, pages 868-870, Tokyo, August 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
</authors>
<title>Efficient Parsing for Natural Language.</title>
<date>1986</date>
<publisher>Kluwer Academic Publishers,</publisher>
<marker>[Tomita, 1986]</marker>
<rawString>M. Tomita. Efficient Parsing for Natural Language. Kluwer Academic Publishers, 1986.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Tomita</author>
</authors>
<title>An efficient augmentedcontext-free parsing algorithm.</title>
<journal>Computational Linguistics,</journal>
<pages>13--31</pages>
<marker>[Tomita, 1987]</marker>
<rawString>M. Tomita. An efficient augmentedcontext-free parsing algorithm. Computational Linguistics, 13:31-46,1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
</authors>
<title>Graph-structured stack and natural language parsing.</title>
<date>1988</date>
<booktitle>In 26th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference,</booktitle>
<pages>249--257</pages>
<location>Buffalo, New York,</location>
<marker>[Tomita, 1988]</marker>
<rawString>M. Tomita. Graph-structured stack and natural language parsing. In 26th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, pages 249-257, Buffalo, New York, June 1988.</rawString>
</citation>
<citation valid="false">
<date>1991</date>
<editor>M. Tomita, editor. Generalized LR Parsing.</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<marker>[Tomita, 1991]</marker>
<rawString>M. Tomita, editor. Generalized LR Parsing. Kluwer Academic Publishers, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Wiren</author>
</authors>
<title>A comparison of ruleinvocation strategies in context-free chart parsing.</title>
<date>1987</date>
<booktitle>In Third Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference,</booktitle>
<pages>226--233</pages>
<location>Copenhagen, Denmark,</location>
<marker>[Wiren, 1987]</marker>
<rawString>Mats Wiren. A comparison of ruleinvocation strategies in context-free chart parsing. In Third Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference, pages 226-233, Copenhagen, Denmark, April 1987.</rawString>
</citation>
<citation valid="true">
<date>1989</date>
<booktitle>27th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference,</booktitle>
<location>Vancouver, British Columbia,</location>
<marker>[1]</marker>
<rawString>27th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, Vancouver, British Columbia, June 1989.</rawString>
</citation>
<citation valid="true">
<date>1991</date>
<booktitle>29th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference,</booktitle>
<location>Berkeley, California,</location>
<marker>[2]</marker>
<rawString>29th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, Berkeley, California, June 1991.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>