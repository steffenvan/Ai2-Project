<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.996976">
Greedy Decoding for Statistical Machine Translation in Almost Linear Time
</title>
<author confidence="0.980776">
Ulrich Germann
</author>
<affiliation confidence="0.945076">
USC Information Sciences Institute
</affiliation>
<address confidence="0.488241">
Marina del Rey, CA
</address>
<email confidence="0.998816">
germann@isi.edu
</email>
<sectionHeader confidence="0.995643" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999520545454546">
We present improvements to a greedy decod-
ing algorithm for statistical machine translation
that reduce its time complexity from at least
cubic ( when applied naively) to prac-
tically linear time&apos; without sacrificing trans-
lation quality. We achieve this by integrat-
ing hypothesis evaluation into hypothesis cre-
ation, tiling improvements over the translation
hypothesis at the end of each search iteration,
and by imposing restrictions on the amount of
word reordering during decoding.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.98618055">
Most of the current work in statistical machine translation
builds on word replacement models developed at IBM in
the early 1990s (Brown et al., 1990, 1993; Berger et al.,
1994, 1996). Based on the conventions established in
Brown et al. (1993), these models are commonly referred
to as the (IBM) Models 1-5.
One of the big challenges in building actual MT sys-
tems within this framework is that of decoding: finding
the translation candidate that maximizes the translation
probability for the given input . Knight (1999)
has shown the problem to be NP-complete.
Due to the complexity of the task, practical MT sys-
tems usually do not employ optimal decoders (that is,
decoders that are guaranteed to find an optimal solution
within the constraints of the framework), but rely on ap-
proximative algorithms instead. Empirical evidence sug-
gests that such algorithms can perform resonably well.
For example, Berger et al. (1994), attribute only 5% of
the translation errors of their Candide system, which uses
&apos;Technically, the complexity is still . However, the
</bodyText>
<footnote confidence="0.605806">
quadratic component has such a small coefficient that it does
not have any noticable effect on the translation speed for all
reasonable inputs.
</footnote>
<bodyText confidence="0.995975815789473">
a restricted stack search, to search errors. Using the same
evaluation metric (but different evaluation data), Wang
and Waibel (1997) report search error rates of 7.9% and
9.3%, respectively, for their decoders.
Och et al. (2001) and Germann et al. (2001) both im-
plemented optimal decoders and benchmarked approxi-
mative algorithms against them. Och et al. report word
error rates of 68.68% for optimal search (based on a vari-
ant of the A* algorithm), and 69.65% for the most re-
stricted version of a decoder that combines dynamic pro-
gramming with a beam search (Tillmann and Ney, 2000).
Germann et al. (2001) compare translations obtained
by a multi-stack decoder and a greedy hill-climbing al-
gorithm against those produced by an optimal integer
programming decoder that treats decoding as a variant
of the traveling-salesman problem (cf. Knight, 1999).
Their overall performance metric is the sentence error
rate (SER). For decoding with IBM Model 3, they report
SERs of about 57% (6-word sentences) and 76% (8-word
sentences) for optimal decoding, 58% and 75% for stack
decoding, and 60% and 75% for greedy decoding, which
is the focus of this paper.
All these numbers suggest that approximative algo-
rithms are a feasible choice for practical applications.
The purpose of this paper is to describe speed improve-
ments to the greedy decoder mentioned above. While ac-
ceptably fast for the kind of evaluation used in Germann
et al. (2001), namely sentences of up to 20 words, its
speed becomes an issue for more realistic applications.
Brute force translation of the 100 short news articles in
Chinese from the TIDES MT evaluation in June 2002
(878 segments; ca. 25k tokens) requires, without any
of the improvements described in this paper, over 440
CPU hours, using the simpler, “faster” algorithm (de-
scribed below). We will show that this time can be re-
duced to ca. 40 minutes without sacrificing translation
quality.
In the following, we first describe the underlying IBM
</bodyText>
<construct confidence="0.734753">
initial string: I do not understand the logic of these people .
pick fertilities: I not not understand the logic of these people .
replace words: Je ne pas comprends la logique de ces gens .
reorder: Je ne comprends pas la logique de ces gens .
insert spurious words: Je ne comprends pas la logique de ces gens -l`a .
</construct>
<figureCaption confidence="0.980152">
Figure 1: How the IBM models model the translation process. This is a hypothetical example and not taken from any
actual training or decoding logs.
</figureCaption>
<bodyText confidence="0.99653975">
model(s) of machine translation (Section 2) and our hill-
climbing algorithm (Section 3). In Section 4, we discuss
improvements to the algorithm and its implementation,
and the effect of restrictions on word reordering.
</bodyText>
<sectionHeader confidence="0.99006" genericHeader="method">
2 The IBM Translation Models
</sectionHeader>
<bodyText confidence="0.894662">
Brown et al. (1993) and Berger et al. (1994, 1996) view
the problem of translation as that of decoding a message
that has been distorted in a noisy channel.
Exploiting Bayes’ theorem
</bodyText>
<equation confidence="0.584722">
(1)
(2)
</equation>
<bodyText confidence="0.972886297297297">
is constant for any given input and can therefore
be ignored. is typically calculated using an n-gram
language model. For the sake of simplicity, we assume
here and everywhere else in the paper that the ultimate
task is to translate from a foreign language into English.
The model pictures the conversion from English to a
foreign language roughly as follows (cf. Fig. 1; note that
because of the noisy channel approach, the modeling is
“backwards”).
For each English word , a fertility (with )
is chosen. is called the fertility of .
Each word is replaced by foreign words.
After that, the linear order of the foreign words is
rearranged.
As a result, each foreign word is linked, by virtue of the
derivation history, to either nothing (the imaginary NULL
word), or exactly one word of the English source sen-
tence.
The triple with
, ,and
is called a sentence alignment. For all pairs
such that , we say that is aligned with
, and with , respectively.
Since each of the changes occurs with a certain prob-
ability, we can calculate the translation model probabil-
ity of as the product of the individual probabilities of
each of the changes. The product of the translation model
probability and the language model probability of is
called the alignmentprobability of .
Detailed formulas for the calculation of alignment
probabilities according to the various models can be
found in Brown et al. (1993). It should be noted here
that the calculation of the alignment probability of an
entire alignment ( ) has linear complexity. Well
will show below that by re-evaluating only fractions of
an alignment ( ), we can reduce the evaluation cost
to a constant time factor.
</bodyText>
<sectionHeader confidence="0.998997" genericHeader="method">
3 Decoding
</sectionHeader>
<subsectionHeader confidence="0.999942">
3.1 Decoding Algorithm
</subsectionHeader>
<bodyText confidence="0.999665">
The task of the decoder is to revert the process just de-
scribed. In this subsection we recapitulate the greedy hill-
climbing algorithm presented in Germann et al. (2001).
In contrast to all other decoders mentioned in Sec. 1,
this algorithm does not process the input one word at a
time to incrementally build up a full translation hypothe-
sis. Instead, it starts out with a complete gloss of the input
sentence, aligning each input word with the word that
maximizes the inverse (with respect to the noisy chan-
nel approach) translation probability . (Note that
for the calculation of the alignment probability, is
</bodyText>
<equation confidence="0.582009">
used.)
</equation>
<bodyText confidence="0.995482876404495">
The decoder then systematically tries out various types
of changes to the alignment: changing the translation of a
word, inserting extra words, reordering words, etc. These
they recast the problem of finding the best translation
for a given input as
Finally, a certain number of so-called spurious
words (words that have no counterpart in the origi-
nal English) are inserted into the foreign text. The
probability of the value of depends on the length
of the original English string.
change operations are described in more detail below. In
each search iteration, the algorithm makes a complete
pass over the alignment, evaluating all possible changes.
The simpler, “faster” version of the algorithm consid-
ers only one operation at a time. A more thorough variant
applies up to two word translation changes, or inserts
one zero fertility word in addition to a word translation
change before the effect of these changes is evaluated.
At the end of the iteration, the decoder permanently ap-
plies that change, or, in the case of , change combina-
tion, that leads to the biggest improvement in alignment
probability, and then starts the next iteration. This cycle
is repeated until no more improvements can be found.
The changes to the alignment that the decoder consid-
ers are as follows.
CHANGE the translation of a word: For a given for-
eign word , change the English word that is aligned
with . If has a fertility of 1, replace it with the new
word ; if it has a fertility of more than one, insert the
new word in the position that optimizes the alignment
probability. The list of candidates for is derived from
the inverse translation table ( ). Typically, the top
ten words on that list are considered, that is, for an input
of length , possible change operations are evaluated
during each CHANGE iteration.
In theory, a single CHANGE iteration in has a com-
plexity of : for each word , there is a certain prob-
ability that changing the word translation of requires
a pass over the complete English hypothesis in order to
find the best insertion point. This is the case when is
currently either spurious (that is, aligned with the NULL
word), or aligned with a word with a fertility of more
than one. The probability of this happening, however, is
fairly small, so that we can assume for all practical pur-
poses that a CHANGE iteration in has a complexity of
. Since allows up to two CHANGE operations
at a time, the respective complexities for are
in theory and in practice. We will argue below
that by exploiting the notion of change dependencies, the
complexity for CHANGE can be reduced to practically
for decoding as well, albeit with a fairly large
coefficient.
INSERT a so-called zero fertility word (i.e., an English
word that is not aligned to any foreign word) into the En-
glish string. Since all possible positions in the English
hypothesis have to be considered, ,
assuming a linear correlation between input length and
hypothesis length.
ERASE a zero fertility word. .
JOIN two English words. This is an asymmetrical op-
eration: one word, , stays where it is, the other one,
, is removed from the English hypothesis. All
foreign words originally aligned with are then
aligned with .
Even though a JOIN iteration has a complexity of
,2 empirical data indicates that its actual time con-
sumption is very small (cf. Fig. 6). This is because
the chances of success of a join operation can be deter-
mined very cheaply without actually performing the op-
eration. Suppose for the sake of simplicity that
is aligned with only one word . If the translation proba-
bility is zero (which is true most of the time),
the resulting alignment probability will be zero. There-
fore, we can safely skip such operations.
SWAP any two non-overlapping regions and
in the English string. The number of possible
swap operations in a string of length is
Thus, .
However, if we limit the size of the swapped regions to
a constant and their distance to a constant , we can re-
duce the number of swaps performed to a linear function
of the input length. For each start position (defined as
the first word of the first swap region), there are at most
swaps that can be performed within these limitations.
Therefore, .
It is obvious that the baseline version of this algorithm
is very inefficient. In the following subsection, we dis-
cuss the algorithm’s complexity in more detail. In Sec. 4,
we show how the decoding complexity can be reduced.
</bodyText>
<subsectionHeader confidence="0.999852">
3.2 Decoding Complexity
</subsectionHeader>
<bodyText confidence="0.97479419047619">
The total decoding complexity of the search algorithm is
the number of search iterations (I) times the number of
search steps per search iteration (S) times the evaluation
cost per search step (E):
We now show that the original implementation of the
algorithm has a complexity of (practically) for
decoding, and for decoding, if swap opera-
tions are restricted. With unrestricted swapping, the com-
plexity is . Since our argument is based on some
assumptions that cannot be proved formally, we cannot
provide a formal complexity proof.
. In the original implementation of the algo-
rithm, the entire alignment is evaluated after each search
step (global evaluation, or ). Therefore, the eval-
uation cost rises linearly with the length of the hypothe-
sized alignment: The evaluation requires two passes over
the English hypothesis (n-grams for the language model;
fertility probabilities) and two passes over the input string
(translation and distortion probabilities). We assume a
high correlation between input length and the hypothesis
length. Thus, .
</bodyText>
<footnote confidence="0.573988">
2There are possible join operations for an English
string consisting of non-zero-fertility words.
</footnote>
<figureCaption confidence="0.587854">
Figure 2: Runtimes for sentences of length 10–80. The
</figureCaption>
<bodyText confidence="0.99391675">
graph shows the average runtimes ( ) of 10 different
sample sentences of the respective length with swap op-
erations restricted to a maximum swap segment size of 5
and a maximum swap distance of 2.
. The original algorithm pursues a highly in-
efficient search strategy. At the end of each iteration, only
the single best improvement is executed; all others, even
when independent, are discarded. In other words, the al-
gorithm needs one search iteration per improvement. We
assume that there is a linear correlation between input
length and the number of improvements — an assump-
tion that is supported by the empirical data in Fig. 4.
Therefore, .
( , restricted swapping)
( , restricted swapping)
(no restrictions on swapping).
The number of search steps per iteration is the sum of
the number of search steps for CHANGE, SWAP, JOIN,
INSERT, and ERASE. The highest order term in this sum
is unrestricted SWAP with .
With restricted swapping, S has a theoretical complex-
ity of (due to JOIN) in decoding, but the con-
tribution of the JOIN operation to overall time consump-
tion is so small that it can be ignored for all practical pur-
poses. Therefore, the average complexity of in practice
is , and the total complexity of in practice is
In decoding, which combines up to two CHANGE
operations or one CHANGE operation and one INSERT
operation, has a practical complexity of , so that
.
We discuss below how can be reduced to practically
linear time for decoding as well.
</bodyText>
<sectionHeader confidence="0.989268" genericHeader="method">
4 Reducting Decoder Complexity
</sectionHeader>
<bodyText confidence="0.999911611111111">
Every change to the alignment affects only a few of the
individual probabilities that make up the overall align-
ment score: the n-gram contexts of those places in the
English hypothesis where a change occurs, plus a few
translation model probabilities. We call the — not neces-
sarily contiguous — area of an alignment that is affected
by a change the change’s local context.
With respect to an efficient implementation of the
greedy search, we can exploit the notion of local con-
texts in two ways. First, we can limit probability recal-
culations to the local context (that is, those probabilities
that actually are affected by the respective change), and
secondly, we can develop the notion of change dependen-
cies: Two changes are independent if their local contexts
do not overlap. As we will explain below, we can use
this notion to devise a scheme of improvement caching
and tiling (ICT) that greatly reduces the total number of
alignments considered during the search.
</bodyText>
<equation confidence="0.5461375">
Our argument is that local probability calculations and
ICT each reduce the complexity of the algorithm by prac-
</equation>
<bodyText confidence="0.980420352941176">
tically , that is, from to with .
Thus, the complexity for decreases from to
. If we limit the search space for the second oper-
ation (CHANGE or INSERT) in decoding to its lo-
cal context, decoding, too, has practically linear com-
plexity, even though with a much higher coefficient (cf
Fig. 6).
.
However, since there is a constant upper bound3 on the
size of local contexts, needs to be performed only
once for the initial gloss, therafter, recalculation of only
those probabilities affected by each change (
) suffices. This reduces the overall decoding com-
plexity from to with .
Even though profoundly trivial, this improvement sig-
nificantly reduces translation times, especially when im-
provements are not tiled (cf. below and Fig. 2).
</bodyText>
<subsectionHeader confidence="0.998228">
4.2 Improvement Caching and Tiling4 (ICT)
</subsectionHeader>
<bodyText confidence="0.9986148">
Based on the notions of local contexts and change depen-
dencies, we devised the following scheme of improve-
ment caching and tiling (ICT): During the search, we
keep track of the best possible change affecting each local
context. (In practice, we maintain a map that maps from
</bodyText>
<footnote confidence="0.976441666666667">
3In practice, 16 with a trigram language model: a swap of
two large segments over a large distance affects four points in
the English hypothesis, resulting in trigrams, plus
four individual distortion probabilities.
4Thanks to Daniel Marcu for alerting us to this term in this
context.
</footnote>
<figure confidence="0.993822214285714">
decoding time (seconds)
450
400
250
200
550
500
350
300
150
100
50
00 10 20 30 40 50 60 70 80
sentence length
</figure>
<bodyText confidence="0.9701405">
global probability recalculations, no improvement tiling
local probability calculations, no improvement tiling
global probability calculations, with improvement tiling
local probability calculations, with improvement tiling
</bodyText>
<subsectionHeader confidence="0.870685">
4.1 Local Probability Calculations
</subsectionHeader>
<bodyText confidence="0.9971555">
The complexity of calculating the alignment probabil-
ity globally (that is, over the entire alignment) is
</bodyText>
<construct confidence="0.743503454545455">
initial gloss us localities computer system suffer computer virus attack and refused service attack and
there various security loopholes instance everywhere
alignments checked: 768 u.s. citizens computer system opposed to the computer virus attack and rejecting service
possible improvements: 1 attack and there are various security loopholes publicize everywhere .
improvements applied: 1
alignments checked: 364 u.s. citizens computer system is opposed to the computer virus attack and rejecting
possible improvements: 1 service attack and there are various security loopholes publicize everywhere.
improvements applied: 1
alignments checked: 343 u.s. citizens computer system is opposed to the computer virus attack and rejecting service
possible improvements: 0 attack and there are various security loopholes publicize everywhere .
improvements applied: 0
</construct>
<figureCaption confidence="0.967470333333333">
Figure 3: A decoding trace using improvement caching and tiling (ICT). The search in the second and later iterations is
limited to areas where a change has been applied (marked in bold print) — note that the number of alignment checked
goes down over time. The higher number of alignments checked in the second iteration is due to the insertion of an
additional word, which increases the number of possible swap and insertion operations. Decoding without ICT results
in the same translation but requires 11 iterations and checks a total of 17701 alignments as opposed to 5 iterations with
a total of 4464 alignments with caching.
</figureCaption>
<figure confidence="0.903352727272727">
alignments checked: 1430
possible improvements: 28
improvements applied: 5
u.s. localities computer system opposed computer virus attack and rejecting service
alignments checked: 1541
possible improvements: 3
improvements applied: 3
u.s. citizens computer system opposed the computer virus attack and rejecting service
attack and there are various security loopholes publicize everywhere.
attack and there are
various security loopholes instance everywhere .
</figure>
<bodyText confidence="0.962851603773585">
the local context of each change that has been considered
to the best change possible that affects exactly this con-
text.) At the end of the search iteration , we apply a
very restricted stack search to find a good tiling of non-
overlapping changes, all of which are applied. The goal
of this stack search is to find a tiling that maximizes the
overal gain in alignment probability. Possible improve-
ments that overlap with higher-scoring ones are ignored.
In the following search iteration , we restrict the
search to changes that overlap with changes just applied.
We can safely assume that there are no improvements to
be found that are independent of the changes applied at
the end of iteration : If there were such improvements,
they would have been found in and applied after iteration
. Figure 3 illustrates the procedure.
We assume that improvements are, on average, evenly
distributed over the input text. Therefore, we can expect
the number of places where improvements can be applied
to grow with the input length at the same rate as the num-
ber of improvements. Without ICT, the number of iter-
ations grows linearly with the input length, as shown in
Fig. 4. With ICT, we can parallelize the improvement
process and thus reduce the number of iterations for each
search to a constant upper bound, which will be deter-
mined by the average ‘improvement density’ of the do-
main. One exception to this rule should be noted: since
the expected number of spurious words (words with no
counterpart in English) in the input is a function of the
input length, and since all changes in word translation
that involve the NULL word are mutually dependent, we
should expect to find a very weak effect of this on the
number of search iterations. Indeed, the scatter diagram
in Fig.4 suggests a slight increase in the number of itera-
tions as the input length increases.5
At the same time, however, the number of changes con-
sidered during each search iteration eventually decreases,
because subsequent search iterations are limited to areas
where a change was previously performed. Empirical ev-
idence as plotted on the right in Fig. 4 suggests that this
effect “neutralizes” the increase in iterations in depen-
dence of the input length: the total number of changes
considered indeed appears to grow linearly with the in-
put length. It should be noted that ICT, while it does
change the course of the search, primarily avoids re-
dundant search steps — it does not necessarily search a
smaller search space, but searches it only once. The to-
tal number of improvements found is roughly the same
(15,299 with ICT, 14,879 without for the entire test cor-
pus with a maximum swap distance of 2 and a maximum
swap segment size of 5).
5Another possible explanation for this increase, especially at
the left end, is that “improvement clusters” occur rarely enough
not to occur at all in shorter sentences.
</bodyText>
<figure confidence="0.981809608695652">
number of hypotheses checked (in thousand)
1750
1500
1250
1000
250
750
500
00 10 20 30 40 50 60 70 80 90 100
input length (in words/tokens)
without improvement caching and tiling
with improvement caching and tiling
number of search iterations
80
70
60
50
40
30
20
10
00 10 20 30 40 50 60 70 80 90 100
input length (in words/tokens)
</figure>
<figureCaption confidence="0.998921666666667">
Figure 4: Number of search iterations (left) and total number of alignments considered (right) during search in depen-
dence of input length. The data is taken from the translation of the Chinese testset from the TIDES MT evaluation in
June 2002. Translations were performed with a maximum swap distance of 2 and a maximum swap segment size of 5.
</figureCaption>
<bodyText confidence="0.9312945">
without improvement caching and tiling
with improvement caching and tiling
</bodyText>
<subsectionHeader confidence="0.998882">
4.3 Restrictions on Word Reordering
</subsectionHeader>
<bodyText confidence="0.9998201">
With , unlimited swapping swapping is by far the
biggest consumer of processing time during decoding.
When translating the Chinese test corpus from the 2002
TIDES MT evaluation6 without any limitations on swap-
ping, swapping operations account for over 98% of the
total search steps but for less than 5% of the improve-
ments; the total translation time (with ICT) is about 34
CPU hours. For comparison, translating with a maximum
swap segment size of 5 and a maximum swap distance of
2 takes ca. 40 minutes under otherwise unchanged cir-
cumstances.
It should be mentioned that in practice, it is generally
not a good idea to run the decoder with without restric-
tions on swapping. In order to cope with hardware and
time limitations, the sentences in the training data are typ-
ically limited in length. For example, the models used for
the experiments reported here were trained on data with
a sentence length limit of 40. Sentence pairs where one
of the sentences exceeded this limit were ignored in train-
ing. Therefore, any swap that involves a distortion greater
than that limit will result in the minimal (smoothed) dis-
tortion probability and most likely not lead to an improve-
ment. The question is: How much swapping is enough?
Is there any benefit to it at all? This is an interesting ques-
tion since virtually all efficient MT decoders (e.g. Till-
mann and Ney, 2000; Berger et al., 1994; Alshawi et al.,
2000; Vidal, 1997) impose limits on word reordering.
In order to determine the effect of swap restrictions on
decoder performance, we translated the Chinese test cor-
pus 101 times with restrictions on the maximum swap
</bodyText>
<footnote confidence="0.5190145">
6100 short news texts; 878 text segments; ca. 25K to-
kens/words.
</footnote>
<figureCaption confidence="0.949916">
Figure 5: BLEUscores for the Chinese test set ( de-
</figureCaption>
<bodyText confidence="0.996631266666667">
coding) in dependence of maximum swap distance and
maximum swap segment size.
distance (MSD) and the maximum swap segment size
(MSSS) ranging from 0 to 10 and evaluated the transla-
tions with the BLEU7 metric (Papineni et al., 2002). The
results are plotted in Fig. 5.
On the one hand, the plot seems to paint a pretty clear
picture on the low end: score improvements are compar-
atively large initially but level off quickly. Furthermore,
the slight slope suggests slow but continuous improve-
ments as swap restrictions are eased. For the Arabic
test data from the same evaluation, we obtained a sim-
ilar shape (although with a roughly level plateau). On
the other hand, the ‘bumpiness’ of the surface raises the
question as to which of these differences are statistically
</bodyText>
<footnote confidence="0.991991666666667">
7In a nutshell, the BLEU score measures the n-gram overlap
between system-produced test translations and a set of human
reference translations.
</footnote>
<figure confidence="0.991954571428571">
4
5
5
4
BLEU
score
0.145
0.144
0.143
0.142
0.141
0.140
0.139
0.138
10
9
7
6
8
10
8
9
6 7
maximum
swap distance
3
2
maximum
swap segment size
3
2
1
0
1
0
</figure>
<tableCaption confidence="0.975156">
Table 1: Decoder performance on the June 2002 TIDES MT evluation test set with multiple searches from randomized
starting points (MSD=2, MSSS=5).
</tableCaption>
<table confidence="0.977484428571428">
default best of best of best of best of best of best of best of best of best of best of
2 searches 3 searches 4 searches 5 searches 6 searches 7 searches 8 searches 9 searches 10 searches 11 searches
G1 BLEU 0.143 0.145 0.146 0.148 0.148 0.150 0.150 0.150 0.150 0.150 0.151
RSER* 93.7% 91.8% 89.8% 87.7% 86.1% 85.2% 83.9% 82.1% 81.2% 80.1% 77.9%
G2 BLEU 0.145 0.150 0.151 0.151 0.154 0.154 0.154 0.154 0.154 0.155 0.156
RSER 77.2% 69.1% 61.2% 55.0% 48.3% 42.5% 36.6% 30.5% 23.9% 20.0% 13.6%
* RSER = relative search error rate; percentage output sentences with suboptimal alignment probability
</table>
<bodyText confidence="0.99639515">
significant.
We are aware of several ways to determine the statisti-
cal significance of BLEU score differences. One is boot-
strap resampling (Efron and Tibshirani, 1993)8 to deter-
mine confidence intervals, another one splitting the test
corpus into a certain number of subcorpora (e.g. 30) and
then using the t-test to compare the average scores over
these subcorpora (cf. Papineni et al., 2001). Bootstrap
resampling for the various system outputs leads to very
similar confidence intervals of about 0.006 to 0.007 for
a one-sided test at a confidence level of .95. With the
t-score method, differences in score of 0.008 or higher
seem to be significant at the same level of confidence.
According to these metrics, none of the differences in the
plot are significant, although the shape of the plot sug-
gests that moderate swapping probably is a good idea.
In addition to limitations of the accuracy of the BLEU
method itself, variance in the decoders performance can
blur the picture. A third method to determine a confi-
dence corridor is therefore to perform several random-
ized searches and compare their performance. Follow-
ing a suggestion by Franz Josef Och (personal commu-
nications), we ran the decoder multiple times from ran-
domized starting glosses for each sentence and then used
the highest scoring one as the “official” system output.
This gives us a lower bound on the price in performance
that we pay for search errors. The results for up to ten
searches from randomized starting points in addition to
the baseline gloss are given in Tab. 1. Starting points
were randomized by randomly picking one of the top 10
translation candidates (instead of the top candidate) for
each input word, and performing a (small) random num-
ber of SWAP and INSERT operations before the actual
search started. In order to insure consistency across re-
peated runs, we used a pseudo random function. In our
experiments, we did not mix and decoding. The
practical reason for this is that decoding takes more
than ten times as long as decoding. As the table illus-
trates, running multiple searches in from randomized
starting points is more efficient that running once.
</bodyText>
<footnote confidence="0.8024325">
8Thanks to Franz Josef Och for pointing this option out to
us.
</footnote>
<bodyText confidence="0.999325882352941">
Choosing the best sentences from all decoder runs results
in a BLEU score of 0.157. Interestingly, the decoding
time from the default starting point is much lower (G1:
ca. 40 min. vs. ca. 1 hour; G2: ca. 9.5 hours vs. ca. 11.3
hours), and the score, on average, is higher than when
searching from a random starting point (G1: 0.143 vs.
0.127 (average); G2: 0.145 vs. 0.139 (average)). This
indicates that the default seeding strategy is a good one.
From the results of our experiments we conclude the
following.
First, Tab. 1 suggests that there is a good correla-
tion between IBM Model 4 scores and the BLEU met-
ric. Higher alignment probabilities lead to higher BLEU
scores. Even though hardly any of the score differ-
ences are statistically significant (see confidence intervals
above), there seems to be a trend.
Secondly, from the swapping experiment we conclude
that except for very local word reorderings, neither the
IBM models nor the BLEU metric are able to recognize
long distance dependencies (such as, for example, ac-
counting for fundamental word order differences when
translating from a SOV language into a SVO language).
This is hardly surprising, since both the language model
for decoding and the BLEU metric rely exclusively on n-
grams. This explains why swapping helps so little. For a
different approach that is based on dependency tree trans-
formations, see Alshawi et al. (2000).
Thirdly, the results of our experiments with random-
ized searches show that greedy decoding does not per-
form as well on longer sentences as one might conclude
from the findings in Germann et al. (2001). At the same
time, the speed improvements presented in this paper
make multiple searches feasible, allowing for an overall
faster and better decoder.
</bodyText>
<sectionHeader confidence="0.999634" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.996324833333333">
In this paper, we have analyzed the complexity of the
greedy decoding algorithm originally presented in Ger-
mann et al. (2001) and presented improvements that dras-
tically reduce the decoder’s complexity and speed to
practically linear time.
Experimental data suggests a good correlation between
</bodyText>
<figure confidence="0.986844">
G1 decoding
G2 decoding
INSERT
CHANGE
010 20 30 40 50 60 70 80
sentence length
</figure>
<figureCaption confidence="0.999956">
Figure 6: Time consumption of the various change types in
</figureCaption>
<bodyText confidence="0.982296333333333">
and decoding (with 10 translations per input word con-
sidered, a list of 498 candidates for INSERT, a maximum swap
distance of 2 and a maximum swap segment size of 5). The pro-
files shown are cumulative, so that the top curve reflects the total
decoding time. To put the times for decoding in perspective,
the dashed line in the lower plot reflects the total decoding time
in decoding. Operations not included in the figures consume
so little time that their plots cannot be discerned in the graphs.
The times shown are averages of 100 sentences each for length
10, 20, , 80.
IBM Model 4 scores and the BLEU metric. The speed
improvements discussed in this paper make multiple ran-
domized searches per sentence feasible, leading to a
faster and better decoder for machine translation with
IBM Model 4.
</bodyText>
<sectionHeader confidence="0.999344" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999941">
We are very grateful to Franz Josef Och for various very
helpful comments on the work reported in this paper.
This work was supported by DARPA-ITO grant N66001-
00-1-9814.
</bodyText>
<sectionHeader confidence="0.999479" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99025447368421">
Alshawi, Hiyan, Douglas, Shona, and Bangalore, Srini-
vas. 2000. Learning dependency translation models as
collections of finite-state head transducers. Computa-
tional Linguistics, 26(1):45–60.
Berger, Adam L., Brown, Peter F., Della Pietra,
Stephen A., Della Pietra, Vincent J., Gillet, John R.,
Lafferty, John D., Mercer, Robert L., Printz, Harry, and
Ureˇs, Luboˇs. 1994. The candide system for machine
translation. In: Proceedings of the Arpa Workshop on
Human Language Technology.
Berger, Adam L., Brown, Peter F., Della Pietra,
Stephen A., Della Pietra, Vincent J., Kehler, An-
drew S., and Mercer, Robert L. 1996. Language trans-
lation apparatus and method using context-based trans-
lation models. United States Patent 5,510,981.
Brown, Peter F., Cocke, John, Della Pietra, Stephen A.,
Della Pietra, Vincent J., Jelinek, Fredrick, Lafferty,
John D., Mercer, Robert L., and Roossin, Paul S. 1990.
A statistical approach to machine translation. Compu-
tational Linguistics, 16(2):79–85.
Brown, Peter F., Della Pietra, Vincent J., Della Pietra,
Stephen A., and Mercer, Robert L. 1993. The mathe-
matics of statistical machine translation: Parameter es-
timation. Computational Linguistics, 19(2):263–311.
Efron, Bradley and Tibshirani, Robert J. 1993. An Intro-
duction to the Bootstrap. Chapman &amp; Hall/CRC.
Germann, Ulrich, Jahr, Michael, Knight, Kevin, Marcu,
Daniel, and Yamada, Kenji. 2001. Fast decoding and
optimal decoding for machine translation. In: Proceed-
ings of the 39th ACL. Toulouse, France, 228–235.
Knight, Kevin. 1999. Decoding complexity in word-
replacement translation models. Computational Lin-
guistics, 25(4):607–615.
Och, Franz Josef, Ueffing, Nicola, and Ney, Hermann.
2001. An efficient A* search algorithm for statistical
machine translation. In: Proceedings of the ACL 2001
Workshop on Data-Driven Methods in Machine Trans-
lation. Toulouse, France, 55–62.
Papineni, Kishore, Roukos, Salim, Ward, Todd, and Zhu,
Wei-Jing. 2002. Bleu: a method for automatic eval-
uation of machine translation. In: Proceedings of the
40th ACL. Philadelphia, PA, 311–318.
Papineni, Kishore, Roukos, Salim, Ward, Tood, and Zhu,
Wei-Jing. 2001. Bleu: a method for automatic eval-
uation of machine translation. Tech. Rep. RC22176
(W0109-022), IBM Research Division, Thomas J.
Watson Research Center.
Tillmann, Christoph and Ney, Hermann. 2000. Word re-
ordering and DP-based search in statistical machine
translation. In: Proceedings of the 18th COLING.
Saarbr¨ucken, Germany, 850–856.
Vidal, Enrique. 1997. Finite-state speech-to-speech trans-
lation. In: Proceedings of the 22nd ICASSP. Munich,
Germany, 111–114.
Wang, Ye-Yi and Waibel, Alex. 1997. Decoding algo-
rithm in statistical machine translation. In: Proceed-
ings of the 35th ACL. Madrid, Spain, 366–372.
</reference>
<figure confidence="0.991320846153846">
11
10
JOIN
9
INSERT
7
6
CHANGE
4
3
SWAP
1
010 20 30 40 50 60 70 80
average time consumption (in sec.)
8
5
2
170
160
150
140
130
120
110
100
90
80
70
60
50
40
30
20
10
average time consumption (in sec.)
G1 total
decoding
time
SWAP
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.629873">
<title confidence="0.998145">Greedy Decoding for Statistical Machine Translation in Almost Linear Time</title>
<author confidence="0.673821">Ulrich</author>
<affiliation confidence="0.651401">USC Information Sciences</affiliation>
<author confidence="0.995444">Marina del Rey</author>
<email confidence="0.999867">germann@isi.edu</email>
<abstract confidence="0.9994625">We present improvements to a greedy decoding algorithm for statistical machine translation that reduce its time complexity from at least ( when applied naively) to linear sacrificing translation quality. We achieve this by integrating hypothesis evaluation into hypothesis creover the translation hypothesis at the end of each search iteration, and by imposing restrictions on the amount of word reordering during decoding.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
<author>Shona Douglas</author>
<author>Srinivas Bangalore</author>
</authors>
<title>Learning dependency translation models as collections of finite-state head transducers.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>1</issue>
<contexts>
<context position="24115" citStr="Alshawi et al., 2000" startWordPosition="4026" endWordPosition="4029">n length. For example, the models used for the experiments reported here were trained on data with a sentence length limit of 40. Sentence pairs where one of the sentences exceeded this limit were ignored in training. Therefore, any swap that involves a distortion greater than that limit will result in the minimal (smoothed) distortion probability and most likely not lead to an improvement. The question is: How much swapping is enough? Is there any benefit to it at all? This is an interesting question since virtually all efficient MT decoders (e.g. Tillmann and Ney, 2000; Berger et al., 1994; Alshawi et al., 2000; Vidal, 1997) impose limits on word reordering. In order to determine the effect of swap restrictions on decoder performance, we translated the Chinese test corpus 101 times with restrictions on the maximum swap 6100 short news texts; 878 text segments; ca. 25K tokens/words. Figure 5: BLEUscores for the Chinese test set ( decoding) in dependence of maximum swap distance and maximum swap segment size. distance (MSD) and the maximum swap segment size (MSSS) ranging from 0 to 10 and evaluated the translations with the BLEU7 metric (Papineni et al., 2002). The results are plotted in Fig. 5. On th</context>
<context position="29860" citStr="Alshawi et al. (2000)" startWordPosition="5003" endWordPosition="5006">als above), there seems to be a trend. Secondly, from the swapping experiment we conclude that except for very local word reorderings, neither the IBM models nor the BLEU metric are able to recognize long distance dependencies (such as, for example, accounting for fundamental word order differences when translating from a SOV language into a SVO language). This is hardly surprising, since both the language model for decoding and the BLEU metric rely exclusively on ngrams. This explains why swapping helps so little. For a different approach that is based on dependency tree transformations, see Alshawi et al. (2000). Thirdly, the results of our experiments with randomized searches show that greedy decoding does not perform as well on longer sentences as one might conclude from the findings in Germann et al. (2001). At the same time, the speed improvements presented in this paper make multiple searches feasible, allowing for an overall faster and better decoder. 5 Conclusions In this paper, we have analyzed the complexity of the greedy decoding algorithm originally presented in Germann et al. (2001) and presented improvements that drastically reduce the decoder’s complexity and speed to practically linear</context>
</contexts>
<marker>Alshawi, Douglas, Bangalore, 2000</marker>
<rawString>Alshawi, Hiyan, Douglas, Shona, and Bangalore, Srinivas. 2000. Learning dependency translation models as collections of finite-state head transducers. Computational Linguistics, 26(1):45–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Peter F Brown</author>
<author>Della Pietra</author>
<author>A Stephen</author>
<author>Della Pietra</author>
<author>J Vincent</author>
<author>John R Gillet</author>
<author>John D Lafferty</author>
<author>Robert L Mercer</author>
<author>Harry Printz</author>
<author>Luboˇs Ureˇs</author>
</authors>
<title>The candide system for machine translation. In:</title>
<date>1994</date>
<booktitle>Proceedings of the Arpa Workshop on Human Language Technology.</booktitle>
<marker>Berger, Brown, Pietra, Stephen, Pietra, Vincent, Gillet, Lafferty, Mercer, Printz, Ureˇs, 1994</marker>
<rawString>Berger, Adam L., Brown, Peter F., Della Pietra, Stephen A., Della Pietra, Vincent J., Gillet, John R., Lafferty, John D., Mercer, Robert L., Printz, Harry, and Ureˇs, Luboˇs. 1994. The candide system for machine translation. In: Proceedings of the Arpa Workshop on Human Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Peter F Brown</author>
<author>Della Pietra</author>
<author>A Stephen</author>
<author>Della Pietra</author>
<author>J Vincent</author>
<author>Andrew S Kehler</author>
<author>Robert L Mercer</author>
</authors>
<title>Language translation apparatus and method using context-based translation models. United States Patent 5,510,981.</title>
<date>1996</date>
<marker>Berger, Brown, Pietra, Stephen, Pietra, Vincent, Kehler, Mercer, 1996</marker>
<rawString>Berger, Adam L., Brown, Peter F., Della Pietra, Stephen A., Della Pietra, Vincent J., Kehler, Andrew S., and Mercer, Robert L. 1996. Language translation apparatus and method using context-based translation models. United States Patent 5,510,981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>John Cocke</author>
<author>Della Pietra</author>
<author>A Stephen</author>
<author>Della Pietra</author>
<author>J Vincent</author>
<author>Fredrick Jelinek</author>
<author>John D Lafferty</author>
<author>Robert L Mercer</author>
<author>Paul S Roossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>2</issue>
<contexts>
<context position="815" citStr="Brown et al., 1990" startWordPosition="118" endWordPosition="121">greedy decoding algorithm for statistical machine translation that reduce its time complexity from at least cubic ( when applied naively) to practically linear time&apos; without sacrificing translation quality. We achieve this by integrating hypothesis evaluation into hypothesis creation, tiling improvements over the translation hypothesis at the end of each search iteration, and by imposing restrictions on the amount of word reordering during decoding. 1 Introduction Most of the current work in statistical machine translation builds on word replacement models developed at IBM in the early 1990s (Brown et al., 1990, 1993; Berger et al., 1994, 1996). Based on the conventions established in Brown et al. (1993), these models are commonly referred to as the (IBM) Models 1-5. One of the big challenges in building actual MT systems within this framework is that of decoding: finding the translation candidate that maximizes the translation probability for the given input . Knight (1999) has shown the problem to be NP-complete. Due to the complexity of the task, practical MT systems usually do not employ optimal decoders (that is, decoders that are guaranteed to find an optimal solution within the constraints of</context>
</contexts>
<marker>Brown, Cocke, Pietra, Stephen, Pietra, Vincent, Jelinek, Lafferty, Mercer, Roossin, 1990</marker>
<rawString>Brown, Peter F., Cocke, John, Della Pietra, Stephen A., Della Pietra, Vincent J., Jelinek, Fredrick, Lafferty, John D., Mercer, Robert L., and Roossin, Paul S. 1990. A statistical approach to machine translation. Computational Linguistics, 16(2):79–85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Della Pietra</author>
<author>J Vincent</author>
<author>Della Pietra</author>
<author>A Stephen</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="910" citStr="Brown et al. (1993)" startWordPosition="134" endWordPosition="137">from at least cubic ( when applied naively) to practically linear time&apos; without sacrificing translation quality. We achieve this by integrating hypothesis evaluation into hypothesis creation, tiling improvements over the translation hypothesis at the end of each search iteration, and by imposing restrictions on the amount of word reordering during decoding. 1 Introduction Most of the current work in statistical machine translation builds on word replacement models developed at IBM in the early 1990s (Brown et al., 1990, 1993; Berger et al., 1994, 1996). Based on the conventions established in Brown et al. (1993), these models are commonly referred to as the (IBM) Models 1-5. One of the big challenges in building actual MT systems within this framework is that of decoding: finding the translation candidate that maximizes the translation probability for the given input . Knight (1999) has shown the problem to be NP-complete. Due to the complexity of the task, practical MT systems usually do not employ optimal decoders (that is, decoders that are guaranteed to find an optimal solution within the constraints of the framework), but rely on approximative algorithms instead. Empirical evidence suggests that</context>
<context position="4572" citStr="Brown et al. (1993)" startWordPosition="740" endWordPosition="743">of these people . replace words: Je ne pas comprends la logique de ces gens . reorder: Je ne comprends pas la logique de ces gens . insert spurious words: Je ne comprends pas la logique de ces gens -l`a . Figure 1: How the IBM models model the translation process. This is a hypothetical example and not taken from any actual training or decoding logs. model(s) of machine translation (Section 2) and our hillclimbing algorithm (Section 3). In Section 4, we discuss improvements to the algorithm and its implementation, and the effect of restrictions on word reordering. 2 The IBM Translation Models Brown et al. (1993) and Berger et al. (1994, 1996) view the problem of translation as that of decoding a message that has been distorted in a noisy channel. Exploiting Bayes’ theorem (1) (2) is constant for any given input and can therefore be ignored. is typically calculated using an n-gram language model. For the sake of simplicity, we assume here and everywhere else in the paper that the ultimate task is to translate from a foreign language into English. The model pictures the conversion from English to a foreign language roughly as follows (cf. Fig. 1; note that because of the noisy channel approach, the mod</context>
<context position="6141" citStr="Brown et al. (1993)" startWordPosition="1010" endWordPosition="1013"> word of the English source sentence. The triple with , ,and is called a sentence alignment. For all pairs such that , we say that is aligned with , and with , respectively. Since each of the changes occurs with a certain probability, we can calculate the translation model probability of as the product of the individual probabilities of each of the changes. The product of the translation model probability and the language model probability of is called the alignmentprobability of . Detailed formulas for the calculation of alignment probabilities according to the various models can be found in Brown et al. (1993). It should be noted here that the calculation of the alignment probability of an entire alignment ( ) has linear complexity. Well will show below that by re-evaluating only fractions of an alignment ( ), we can reduce the evaluation cost to a constant time factor. 3 Decoding 3.1 Decoding Algorithm The task of the decoder is to revert the process just described. In this subsection we recapitulate the greedy hillclimbing algorithm presented in Germann et al. (2001). In contrast to all other decoders mentioned in Sec. 1, this algorithm does not process the input one word at a time to incremental</context>
</contexts>
<marker>Brown, Pietra, Vincent, Pietra, Stephen, Mercer, 1993</marker>
<rawString>Brown, Peter F., Della Pietra, Vincent J., Della Pietra, Stephen A., and Mercer, Robert L. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bradley Efron</author>
<author>Robert J Tibshirani</author>
</authors>
<title>An Introduction to the Bootstrap.</title>
<date>1993</date>
<publisher>Chapman &amp; Hall/CRC.</publisher>
<contexts>
<context position="26415" citStr="Efron and Tibshirani, 1993" startWordPosition="4424" endWordPosition="4427">searches 7 searches 8 searches 9 searches 10 searches 11 searches G1 BLEU 0.143 0.145 0.146 0.148 0.148 0.150 0.150 0.150 0.150 0.150 0.151 RSER* 93.7% 91.8% 89.8% 87.7% 86.1% 85.2% 83.9% 82.1% 81.2% 80.1% 77.9% G2 BLEU 0.145 0.150 0.151 0.151 0.154 0.154 0.154 0.154 0.154 0.155 0.156 RSER 77.2% 69.1% 61.2% 55.0% 48.3% 42.5% 36.6% 30.5% 23.9% 20.0% 13.6% * RSER = relative search error rate; percentage output sentences with suboptimal alignment probability significant. We are aware of several ways to determine the statistical significance of BLEU score differences. One is bootstrap resampling (Efron and Tibshirani, 1993)8 to determine confidence intervals, another one splitting the test corpus into a certain number of subcorpora (e.g. 30) and then using the t-test to compare the average scores over these subcorpora (cf. Papineni et al., 2001). Bootstrap resampling for the various system outputs leads to very similar confidence intervals of about 0.006 to 0.007 for a one-sided test at a confidence level of .95. With the t-score method, differences in score of 0.008 or higher seem to be significant at the same level of confidence. According to these metrics, none of the differences in the plot are significant, </context>
</contexts>
<marker>Efron, Tibshirani, 1993</marker>
<rawString>Efron, Bradley and Tibshirani, Robert J. 1993. An Introduction to the Bootstrap. Chapman &amp; Hall/CRC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Germann</author>
<author>Michael Jahr</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Kenji Yamada</author>
</authors>
<title>Fast decoding and optimal decoding for machine translation. In:</title>
<date>2001</date>
<booktitle>Proceedings of the 39th ACL.</booktitle>
<pages>228--235</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="2122" citStr="Germann et al. (2001)" startWordPosition="329" endWordPosition="332">ests that such algorithms can perform resonably well. For example, Berger et al. (1994), attribute only 5% of the translation errors of their Candide system, which uses &apos;Technically, the complexity is still . However, the quadratic component has such a small coefficient that it does not have any noticable effect on the translation speed for all reasonable inputs. a restricted stack search, to search errors. Using the same evaluation metric (but different evaluation data), Wang and Waibel (1997) report search error rates of 7.9% and 9.3%, respectively, for their decoders. Och et al. (2001) and Germann et al. (2001) both implemented optimal decoders and benchmarked approximative algorithms against them. Och et al. report word error rates of 68.68% for optimal search (based on a variant of the A* algorithm), and 69.65% for the most restricted version of a decoder that combines dynamic programming with a beam search (Tillmann and Ney, 2000). Germann et al. (2001) compare translations obtained by a multi-stack decoder and a greedy hill-climbing algorithm against those produced by an optimal integer programming decoder that treats decoding as a variant of the traveling-salesman problem (cf. Knight, 1999). Th</context>
<context position="6609" citStr="Germann et al. (2001)" startWordPosition="1090" endWordPosition="1093">mentprobability of . Detailed formulas for the calculation of alignment probabilities according to the various models can be found in Brown et al. (1993). It should be noted here that the calculation of the alignment probability of an entire alignment ( ) has linear complexity. Well will show below that by re-evaluating only fractions of an alignment ( ), we can reduce the evaluation cost to a constant time factor. 3 Decoding 3.1 Decoding Algorithm The task of the decoder is to revert the process just described. In this subsection we recapitulate the greedy hillclimbing algorithm presented in Germann et al. (2001). In contrast to all other decoders mentioned in Sec. 1, this algorithm does not process the input one word at a time to incrementally build up a full translation hypothesis. Instead, it starts out with a complete gloss of the input sentence, aligning each input word with the word that maximizes the inverse (with respect to the noisy channel approach) translation probability . (Note that for the calculation of the alignment probability, is used.) The decoder then systematically tries out various types of changes to the alignment: changing the translation of a word, inserting extra words, reord</context>
<context position="30062" citStr="Germann et al. (2001)" startWordPosition="5038" endWordPosition="5041">ng distance dependencies (such as, for example, accounting for fundamental word order differences when translating from a SOV language into a SVO language). This is hardly surprising, since both the language model for decoding and the BLEU metric rely exclusively on ngrams. This explains why swapping helps so little. For a different approach that is based on dependency tree transformations, see Alshawi et al. (2000). Thirdly, the results of our experiments with randomized searches show that greedy decoding does not perform as well on longer sentences as one might conclude from the findings in Germann et al. (2001). At the same time, the speed improvements presented in this paper make multiple searches feasible, allowing for an overall faster and better decoder. 5 Conclusions In this paper, we have analyzed the complexity of the greedy decoding algorithm originally presented in Germann et al. (2001) and presented improvements that drastically reduce the decoder’s complexity and speed to practically linear time. Experimental data suggests a good correlation between G1 decoding G2 decoding INSERT CHANGE 010 20 30 40 50 60 70 80 sentence length Figure 6: Time consumption of the various change types in and </context>
</contexts>
<marker>Germann, Jahr, Knight, Marcu, Yamada, 2001</marker>
<rawString>Germann, Ulrich, Jahr, Michael, Knight, Kevin, Marcu, Daniel, and Yamada, Kenji. 2001. Fast decoding and optimal decoding for machine translation. In: Proceedings of the 39th ACL. Toulouse, France, 228–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
</authors>
<title>Decoding complexity in wordreplacement translation models.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>4</issue>
<contexts>
<context position="1186" citStr="Knight (1999)" startWordPosition="181" endWordPosition="182">nd by imposing restrictions on the amount of word reordering during decoding. 1 Introduction Most of the current work in statistical machine translation builds on word replacement models developed at IBM in the early 1990s (Brown et al., 1990, 1993; Berger et al., 1994, 1996). Based on the conventions established in Brown et al. (1993), these models are commonly referred to as the (IBM) Models 1-5. One of the big challenges in building actual MT systems within this framework is that of decoding: finding the translation candidate that maximizes the translation probability for the given input . Knight (1999) has shown the problem to be NP-complete. Due to the complexity of the task, practical MT systems usually do not employ optimal decoders (that is, decoders that are guaranteed to find an optimal solution within the constraints of the framework), but rely on approximative algorithms instead. Empirical evidence suggests that such algorithms can perform resonably well. For example, Berger et al. (1994), attribute only 5% of the translation errors of their Candide system, which uses &apos;Technically, the complexity is still . However, the quadratic component has such a small coefficient that it does n</context>
<context position="2718" citStr="Knight, 1999" startWordPosition="427" endWordPosition="428">ann et al. (2001) both implemented optimal decoders and benchmarked approximative algorithms against them. Och et al. report word error rates of 68.68% for optimal search (based on a variant of the A* algorithm), and 69.65% for the most restricted version of a decoder that combines dynamic programming with a beam search (Tillmann and Ney, 2000). Germann et al. (2001) compare translations obtained by a multi-stack decoder and a greedy hill-climbing algorithm against those produced by an optimal integer programming decoder that treats decoding as a variant of the traveling-salesman problem (cf. Knight, 1999). Their overall performance metric is the sentence error rate (SER). For decoding with IBM Model 3, they report SERs of about 57% (6-word sentences) and 76% (8-word sentences) for optimal decoding, 58% and 75% for stack decoding, and 60% and 75% for greedy decoding, which is the focus of this paper. All these numbers suggest that approximative algorithms are a feasible choice for practical applications. The purpose of this paper is to describe speed improvements to the greedy decoder mentioned above. While acceptably fast for the kind of evaluation used in Germann et al. (2001), namely sentenc</context>
</contexts>
<marker>Knight, 1999</marker>
<rawString>Knight, Kevin. 1999. Decoding complexity in wordreplacement translation models. Computational Linguistics, 25(4):607–615.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Nicola Ueffing</author>
<author>Hermann Ney</author>
</authors>
<title>An efficient A* search algorithm for statistical machine translation. In:</title>
<date>2001</date>
<booktitle>Proceedings of the ACL 2001 Workshop on Data-Driven Methods in Machine Translation.</booktitle>
<pages>55--62</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="2096" citStr="Och et al. (2001)" startWordPosition="324" endWordPosition="327">mpirical evidence suggests that such algorithms can perform resonably well. For example, Berger et al. (1994), attribute only 5% of the translation errors of their Candide system, which uses &apos;Technically, the complexity is still . However, the quadratic component has such a small coefficient that it does not have any noticable effect on the translation speed for all reasonable inputs. a restricted stack search, to search errors. Using the same evaluation metric (but different evaluation data), Wang and Waibel (1997) report search error rates of 7.9% and 9.3%, respectively, for their decoders. Och et al. (2001) and Germann et al. (2001) both implemented optimal decoders and benchmarked approximative algorithms against them. Och et al. report word error rates of 68.68% for optimal search (based on a variant of the A* algorithm), and 69.65% for the most restricted version of a decoder that combines dynamic programming with a beam search (Tillmann and Ney, 2000). Germann et al. (2001) compare translations obtained by a multi-stack decoder and a greedy hill-climbing algorithm against those produced by an optimal integer programming decoder that treats decoding as a variant of the traveling-salesman prob</context>
</contexts>
<marker>Och, Ueffing, Ney, 2001</marker>
<rawString>Och, Franz Josef, Ueffing, Nicola, and Ney, Hermann. 2001. An efficient A* search algorithm for statistical machine translation. In: Proceedings of the ACL 2001 Workshop on Data-Driven Methods in Machine Translation. Toulouse, France, 55–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation. In:</title>
<date>2002</date>
<booktitle>Proceedings of the 40th ACL.</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="24673" citStr="Papineni et al., 2002" startWordPosition="4120" endWordPosition="4123">illmann and Ney, 2000; Berger et al., 1994; Alshawi et al., 2000; Vidal, 1997) impose limits on word reordering. In order to determine the effect of swap restrictions on decoder performance, we translated the Chinese test corpus 101 times with restrictions on the maximum swap 6100 short news texts; 878 text segments; ca. 25K tokens/words. Figure 5: BLEUscores for the Chinese test set ( decoding) in dependence of maximum swap distance and maximum swap segment size. distance (MSD) and the maximum swap segment size (MSSS) ranging from 0 to 10 and evaluated the translations with the BLEU7 metric (Papineni et al., 2002). The results are plotted in Fig. 5. On the one hand, the plot seems to paint a pretty clear picture on the low end: score improvements are comparatively large initially but level off quickly. Furthermore, the slight slope suggests slow but continuous improvements as swap restrictions are eased. For the Arabic test data from the same evaluation, we obtained a similar shape (although with a roughly level plateau). On the other hand, the ‘bumpiness’ of the surface raises the question as to which of these differences are statistically 7In a nutshell, the BLEU score measures the n-gram overlap bet</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, Kishore, Roukos, Salim, Ward, Todd, and Zhu, Wei-Jing. 2002. Bleu: a method for automatic evaluation of machine translation. In: Proceedings of the 40th ACL. Philadelphia, PA, 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Tood Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2001</date>
<journal>Tech. Rep. RC22176 (W0109-022), IBM Research Division, Thomas J. Watson Research Center.</journal>
<contexts>
<context position="26641" citStr="Papineni et al., 2001" startWordPosition="4461" endWordPosition="4464"> 0.151 0.151 0.154 0.154 0.154 0.154 0.154 0.155 0.156 RSER 77.2% 69.1% 61.2% 55.0% 48.3% 42.5% 36.6% 30.5% 23.9% 20.0% 13.6% * RSER = relative search error rate; percentage output sentences with suboptimal alignment probability significant. We are aware of several ways to determine the statistical significance of BLEU score differences. One is bootstrap resampling (Efron and Tibshirani, 1993)8 to determine confidence intervals, another one splitting the test corpus into a certain number of subcorpora (e.g. 30) and then using the t-test to compare the average scores over these subcorpora (cf. Papineni et al., 2001). Bootstrap resampling for the various system outputs leads to very similar confidence intervals of about 0.006 to 0.007 for a one-sided test at a confidence level of .95. With the t-score method, differences in score of 0.008 or higher seem to be significant at the same level of confidence. According to these metrics, none of the differences in the plot are significant, although the shape of the plot suggests that moderate swapping probably is a good idea. In addition to limitations of the accuracy of the BLEU method itself, variance in the decoders performance can blur the picture. A third m</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Papineni, Kishore, Roukos, Salim, Ward, Tood, and Zhu, Wei-Jing. 2001. Bleu: a method for automatic evaluation of machine translation. Tech. Rep. RC22176 (W0109-022), IBM Research Division, Thomas J. Watson Research Center.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Tillmann</author>
<author>Hermann Ney</author>
</authors>
<title>Word reordering and DP-based search in statistical machine translation. In:</title>
<date>2000</date>
<booktitle>Proceedings of the 18th COLING. Saarbr¨ucken, Germany,</booktitle>
<pages>850--856</pages>
<contexts>
<context position="2451" citStr="Tillmann and Ney, 2000" startWordPosition="386" endWordPosition="389">ation speed for all reasonable inputs. a restricted stack search, to search errors. Using the same evaluation metric (but different evaluation data), Wang and Waibel (1997) report search error rates of 7.9% and 9.3%, respectively, for their decoders. Och et al. (2001) and Germann et al. (2001) both implemented optimal decoders and benchmarked approximative algorithms against them. Och et al. report word error rates of 68.68% for optimal search (based on a variant of the A* algorithm), and 69.65% for the most restricted version of a decoder that combines dynamic programming with a beam search (Tillmann and Ney, 2000). Germann et al. (2001) compare translations obtained by a multi-stack decoder and a greedy hill-climbing algorithm against those produced by an optimal integer programming decoder that treats decoding as a variant of the traveling-salesman problem (cf. Knight, 1999). Their overall performance metric is the sentence error rate (SER). For decoding with IBM Model 3, they report SERs of about 57% (6-word sentences) and 76% (8-word sentences) for optimal decoding, 58% and 75% for stack decoding, and 60% and 75% for greedy decoding, which is the focus of this paper. All these numbers suggest that a</context>
<context position="24072" citStr="Tillmann and Ney, 2000" startWordPosition="4017" endWordPosition="4021"> in the training data are typically limited in length. For example, the models used for the experiments reported here were trained on data with a sentence length limit of 40. Sentence pairs where one of the sentences exceeded this limit were ignored in training. Therefore, any swap that involves a distortion greater than that limit will result in the minimal (smoothed) distortion probability and most likely not lead to an improvement. The question is: How much swapping is enough? Is there any benefit to it at all? This is an interesting question since virtually all efficient MT decoders (e.g. Tillmann and Ney, 2000; Berger et al., 1994; Alshawi et al., 2000; Vidal, 1997) impose limits on word reordering. In order to determine the effect of swap restrictions on decoder performance, we translated the Chinese test corpus 101 times with restrictions on the maximum swap 6100 short news texts; 878 text segments; ca. 25K tokens/words. Figure 5: BLEUscores for the Chinese test set ( decoding) in dependence of maximum swap distance and maximum swap segment size. distance (MSD) and the maximum swap segment size (MSSS) ranging from 0 to 10 and evaluated the translations with the BLEU7 metric (Papineni et al., 2002</context>
</contexts>
<marker>Tillmann, Ney, 2000</marker>
<rawString>Tillmann, Christoph and Ney, Hermann. 2000. Word reordering and DP-based search in statistical machine translation. In: Proceedings of the 18th COLING. Saarbr¨ucken, Germany, 850–856.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Enrique Vidal</author>
</authors>
<title>Finite-state speech-to-speech translation. In:</title>
<date>1997</date>
<booktitle>Proceedings of the 22nd ICASSP.</booktitle>
<pages>111--114</pages>
<location>Munich, Germany,</location>
<contexts>
<context position="24129" citStr="Vidal, 1997" startWordPosition="4030" endWordPosition="4031"> the models used for the experiments reported here were trained on data with a sentence length limit of 40. Sentence pairs where one of the sentences exceeded this limit were ignored in training. Therefore, any swap that involves a distortion greater than that limit will result in the minimal (smoothed) distortion probability and most likely not lead to an improvement. The question is: How much swapping is enough? Is there any benefit to it at all? This is an interesting question since virtually all efficient MT decoders (e.g. Tillmann and Ney, 2000; Berger et al., 1994; Alshawi et al., 2000; Vidal, 1997) impose limits on word reordering. In order to determine the effect of swap restrictions on decoder performance, we translated the Chinese test corpus 101 times with restrictions on the maximum swap 6100 short news texts; 878 text segments; ca. 25K tokens/words. Figure 5: BLEUscores for the Chinese test set ( decoding) in dependence of maximum swap distance and maximum swap segment size. distance (MSD) and the maximum swap segment size (MSSS) ranging from 0 to 10 and evaluated the translations with the BLEU7 metric (Papineni et al., 2002). The results are plotted in Fig. 5. On the one hand, th</context>
</contexts>
<marker>Vidal, 1997</marker>
<rawString>Vidal, Enrique. 1997. Finite-state speech-to-speech translation. In: Proceedings of the 22nd ICASSP. Munich, Germany, 111–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ye-Yi Wang</author>
<author>Alex Waibel</author>
</authors>
<title>Decoding algorithm in statistical machine translation. In:</title>
<date>1997</date>
<booktitle>Proceedings of the 35th ACL.</booktitle>
<pages>366--372</pages>
<location>Madrid,</location>
<contexts>
<context position="2000" citStr="Wang and Waibel (1997)" startWordPosition="308" endWordPosition="311">al solution within the constraints of the framework), but rely on approximative algorithms instead. Empirical evidence suggests that such algorithms can perform resonably well. For example, Berger et al. (1994), attribute only 5% of the translation errors of their Candide system, which uses &apos;Technically, the complexity is still . However, the quadratic component has such a small coefficient that it does not have any noticable effect on the translation speed for all reasonable inputs. a restricted stack search, to search errors. Using the same evaluation metric (but different evaluation data), Wang and Waibel (1997) report search error rates of 7.9% and 9.3%, respectively, for their decoders. Och et al. (2001) and Germann et al. (2001) both implemented optimal decoders and benchmarked approximative algorithms against them. Och et al. report word error rates of 68.68% for optimal search (based on a variant of the A* algorithm), and 69.65% for the most restricted version of a decoder that combines dynamic programming with a beam search (Tillmann and Ney, 2000). Germann et al. (2001) compare translations obtained by a multi-stack decoder and a greedy hill-climbing algorithm against those produced by an opti</context>
</contexts>
<marker>Wang, Waibel, 1997</marker>
<rawString>Wang, Ye-Yi and Waibel, Alex. 1997. Decoding algorithm in statistical machine translation. In: Proceedings of the 35th ACL. Madrid, Spain, 366–372.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>