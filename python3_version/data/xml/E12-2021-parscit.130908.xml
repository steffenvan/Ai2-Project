<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.267639">
<title confidence="0.954077">
BRAT: a Web-based Tool for NLP-Assisted Text Annotation
</title>
<author confidence="0.919864">
Pontus Stenetorp1* Sampo Pyysalo2,3* Goran Topi´c1
Tomoko Ohta1,2,3 Sophia Ananiadou2,3 and Jun’ichi Tsujii4
</author>
<affiliation confidence="0.99421225">
1Department of Computer Science, The University of Tokyo, Tokyo, Japan
2School of Computer Science, University of Manchester, Manchester, UK
3National Centre for Text Mining, University of Manchester, Manchester, UK
4Microsoft Research Asia, Beijing, People’s Republic of China
</affiliation>
<email confidence="0.993277666666667">
{pontus,smp,goran,okap}@is.s.u-tokyo.ac.jp
sophia.ananiadou@manchester.ac.uk
jtsujii@microsoft.com
</email>
<sectionHeader confidence="0.995573" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999869647058824">
We introduce the brat rapid annotation tool
(BRAT), an intuitive web-based tool for text
annotation supported by Natural Language
Processing (NLP) technology. BRAT has
been developed for rich structured annota-
tion for a variety of NLP tasks and aims
to support manual curation efforts and in-
crease annotator productivity using NLP
techniques. We discuss several case stud-
ies of real-world annotation projects using
pre-release versions of BRAT and present
an evaluation of annotation assisted by se-
mantic class disambiguation on a multi-
category entity mention annotation task,
showing a 15% decrease in total annota-
tion time. BRAT is available under an open-
source license from: http://brat.nlplab.org
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999798882352941">
Manually-curated gold standard annotations are
a prerequisite for the evaluation and training of
state-of-the-art tools for most Natural Language
Processing (NLP) tasks. However, annotation is
also one of the most time-consuming and finan-
cially costly components of many NLP research
efforts, and can place heavy demands on human
annotators for maintaining annotation quality and
consistency. Yet, modern annotation tools are
generally technically oriented and many offer lit-
tle support to users beyond the minimum required
functionality. We believe that intuitive and user-
friendly interfaces as well as the judicious appli-
cation of NLP technology to support, not sup-
plant, human judgements can help maintain the
quality of annotations, make annotation more ac-
cessible to non-technical users such as subject
</bodyText>
<note confidence="0.980421">
*These authors contributed equally to this work
</note>
<figureCaption confidence="0.993963333333333">
Figure 1: Visualisation examples. Top: named en-
tity recognition, middle: dependency syntax, bot-
tom: verb frames.
</figureCaption>
<bodyText confidence="0.9926824">
domain experts, and improve annotation produc-
tivity, thus reducing both the human and finan-
cial cost of annotation. The tool presented in
this work, BRAT, represents our attempt to realise
these possibilities.
</bodyText>
<sectionHeader confidence="0.999606" genericHeader="introduction">
2 Features
</sectionHeader>
<subsectionHeader confidence="0.99816">
2.1 High-quality Annotation Visualisation
</subsectionHeader>
<bodyText confidence="0.998878230769231">
BRAT is based on our previously released open-
source STAV text annotation visualiser (Stene-
torp et al., 2011b), which was designed to help
users gain an understanding of complex annota-
tions involving a large number of different se-
mantic types, dense, partially overlapping text an-
notations, and non-projective sets of connections
between annotations. Both tools share a vector
graphics-based visualisation component, which
provide scalable detail and rendering. BRAT in-
tegrates PDF and EPS image format export func-
tionality to support use in e.g. figures in publica-
tions (Figure 1).
</bodyText>
<page confidence="0.985879">
102
</page>
<note confidence="0.9286165">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 102–107,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<figureCaption confidence="0.955193">
Figure 2: Screenshot of the main BRAT user-interface, showing a connection being made between the
annotations for “moving” and “Citibank”.
</figureCaption>
<subsectionHeader confidence="0.980866">
2.2 Intuitive Annotation Interface
</subsectionHeader>
<bodyText confidence="0.99994012">
We extended the capabilities of STAV by imple-
menting support for annotation editing. This was
done by adding functionality for recognising stan-
dard user interface gestures familiar from text ed-
itors, presentation software, and many other tools.
In BRAT, a span of text is marked for annotation
simply by selecting it with the mouse by “drag-
ging” or by double-clicking on a word. Similarly,
annotations are linked by clicking with the mouse
on one annotation and dragging a connection to
the other (Figure 2).
BRAT is browser-based and built entirely using
standard web technologies. It thus offers a fa-
miliar environment to annotators, and it is pos-
sible to start using BRAT simply by pointing a
standards-compliant modern browser to an instal-
lation. There is thus no need to install or dis-
tribute any additional annotation software or to
use browser plug-ins. The use of web standards
also makes it possible for BRAT to uniquely iden-
tify any annotation using Uniform Resource Iden-
tifiers (URIs), which enables linking to individual
annotations for discussions in e-mail, documents
and on web pages, facilitating easy communica-
tion regarding annotations.
</bodyText>
<subsectionHeader confidence="0.995682">
2.3 Versatile Annotation Support
</subsectionHeader>
<bodyText confidence="0.999988065217391">
BRAT is fully configurable and can be set up to
support most text annotation tasks. The most ba-
sic annotation primitive identifies a text span and
assigns it a type (or tag or label), marking for e.g.
POS-tagged tokens, chunks or entity mentions
(Figure 1 top). These base annotations can be
connected by binary relations – either directed or
undirected – which can be configured for e.g. sim-
ple relation extraction, or verb frame annotation
(Figure 1 middle and bottom). n-ary associations
of annotations are also supported, allowing the an-
notation of event structures such as those targeted
in the MUC (Sundheim, 1996), ACE (Doddington
et al., 2004), and BioNLP (Kim et al., 2011) In-
formation Extraction (IE) tasks (Figure 2). Addi-
tional aspects of annotations can be marked using
attributes, binary or multi-valued flags that can
be added to other annotations. Finally, annotators
can attach free-form text notes to any annotation.
In addition to information extraction tasks,
these annotation primitives allow BRAT to be
configured for use in various other tasks, such
as chunking (Abney, 1991), Semantic Role La-
beling (Gildea and Jurafsky, 2002; Carreras
and M`arquez, 2005), and dependency annotation
(Nivre, 2003) (See Figure 1 for examples). Fur-
ther, both the BRAT client and server implement
full support for the Unicode standard, which al-
low the tool to support the annotation of text us-
ing e.g. Chinese or Devan¯agaricharacters. BRAT
is distributed with examples from over 20 cor-
pora for a variety of tasks, involving texts in seven
different languages and including examples from
corpora such as those introduced for the CoNLL
shared tasks on language-independent named en-
tity recognition (Tjong Kim Sang and De Meul-
der, 2003) and multilingual dependency parsing
(Buchholz and Marsi, 2006).
BRAT also implements a fully configurable sys-
tem for checking detailed constraints on anno-
tation semantics, for example specifying that a
TRANSFER event must take exactly one of each
of GIVER, RECIPIENT and BENEFICIARY argu-
ments, each of which must have one of the types
PERSON, ORGANIZATION or GEO-POLITICAL
ENTITY, as well as a MONEY argument of type
</bodyText>
<page confidence="0.998819">
103
</page>
<figureCaption confidence="0.97906">
Figure 3: Incomplete TRANSFER event indicated
to the annotator
</figureCaption>
<bodyText confidence="0.999775166666667">
MONEY, and may optionally take a PLACE argu-
ment of type LOCATION (LDC, 2005). Constraint
checking is fully integrated into the annotation in-
terface and feedback is immediate, with clear vi-
sual effects marking incomplete or erroneous an-
notations (Figure 3).
</bodyText>
<subsectionHeader confidence="0.990457">
2.4 NLP Technology Integration
</subsectionHeader>
<bodyText confidence="0.999932413793104">
BRAT supports two standard approaches for inte-
grating the results of fully automatic annotation
tools into an annotation workflow: bulk anno-
tation imports can be performed by format con-
version tools distributed with BRAT for many
standard formats (such as in-line and column-
formatted BIO), and tools that provide standard
web service interfaces can be configured to be in-
voked from the user interface.
However, human judgements cannot be re-
placed or based on a completely automatic analy-
sis without some risk of introducing bias and re-
ducing annotation quality. To address this issue,
we have been studying ways to augment the an-
notation process with input from statistical and
machine learning methods to support the annota-
tion process while still involving human annotator
judgement for each annotation.
As a specific realisation based on this approach,
we have integrated a recently introduced ma-
chine learning-based semantic class disambigua-
tion system capable of offering multiple outputs
with probability estimates that was shown to be
able to reduce ambiguity on average by over 75%
while retaining the correct class in on average
99% of cases over six corpora (Stenetorp et al.,
2011a). Section 4 presents an evaluation of the
contribution of this component to annotator pro-
ductivity.
</bodyText>
<subsectionHeader confidence="0.895738">
2.5 Corpus Search Functionality
</subsectionHeader>
<bodyText confidence="0.995441">
BRAT implements a comprehensive set of search
functions, allowing users to search document col-
</bodyText>
<figureCaption confidence="0.998531">
Figure 4: The BRAT search dialog
</figureCaption>
<bodyText confidence="0.999825125">
lections for text span annotations, relations, event
structures, or simply text, with a rich set of search
options definable using a simple point-and-click
interface (Figure 4). Additionally, search results
can optionally be displayed using keyword-in-
context concordancing and sorted for browsing
using any aspect of the matched annotation (e.g.
type, text, or context).
</bodyText>
<sectionHeader confidence="0.998711" genericHeader="method">
3 Implementation
</sectionHeader>
<bodyText confidence="0.999840695652174">
BRAT is implemented using a client-server ar-
chitecture with communication over HTTP using
JavaScript Object Notation (JSON). The server is
a RESTful web service (Fielding, 2000) and the
tool can easily be extended or adapted to switch
out the server or client. The client user interface is
implemented using XHTML and Scalable Vector
Graphics (SVG), with interactivity implemented
using JavaScript with the jQuery library. The
client communicates with the server using Asyn-
chronous JavaScript and XML (AJAX), which
permits asynchronous messaging.
BRAT uses a stateless server back-end imple-
mented in Python and supports both the Common
Gateway Interface (CGI) and FastCGI protocols,
the latter allowing response times far below the
100 ms boundary for a “smooth” user experience
without noticeable delay (Card et al., 1983). For
server side annotation storage BRAT uses an easy-
to-process file-based stand-off format that can be
converted from or into other formats; there is no
need to perform database import or export to in-
terface with the data storage. The BRAT server in-
</bodyText>
<page confidence="0.996916">
104
</page>
<figureCaption confidence="0.9804215">
Figure 5: Example annotation from the BioNLP Shared Task 2011 Epigenetics and Post-translational
Modifications event extraction task.
</figureCaption>
<bodyText confidence="0.999512166666667">
stallation requires only a CGI-capable web server
and the set-up supports any number of annotators
who access the server using their browsers, on any
operating system, without separate installation.
Client-server communication is managed so
that all user edit operations are immediately sent
to the server, which consolidates them with the
stored data. There is no separate “save” operation
and thus a minimal risk of data loss, and as the
authoritative version of all annotations is always
maintained by the server, there is no chance of
conflicting annotations being made which would
need to be merged to produce an authoritative ver-
sion. The BRAT client-server architecture also
makes real-time collaboration possible: multiple
annotators can work on a single document simul-
taneously, seeing each others edits as they appear
in a document.
</bodyText>
<sectionHeader confidence="0.992439" genericHeader="method">
4 Case Studies
</sectionHeader>
<subsectionHeader confidence="0.998841">
4.1 Annotation Projects
</subsectionHeader>
<bodyText confidence="0.998774761904762">
BRAT has been used throughout its development
during 2011 in the annotation of six different cor-
pora by four research groups in efforts that have
in total involved the creation of well-over 50,000
annotations in thousands of documents compris-
ing hundreds of thousands of words.
These projects include structured event an-
notation for the domain of cancer biology,
Japanese verb frame annotation, and gene-
mutation-phenotype relation annotation. One
prominent effort making use of BRAT is the
BioNLP Shared Task 2011,1 in which the tool was
used in the annotation of the EPI and ID main
task corpora (Pyysalo et al., 2012). These two
information extraction tasks involved the annota-
tion of entities, relations and events in the epige-
netics and infectious diseases subdomains of biol-
ogy. Figure 5 shows an illustration of shared task
annotations.
Many other annotation efforts using BRAT are
still ongoing. We refer the reader to the BRAT
</bodyText>
<footnote confidence="0.978226">
1http://2011.bionlp-st.org
</footnote>
<table confidence="0.989880666666667">
Mode Total Type Selection
Normal 45:28 13:49
Rapid 39:24 (-6:04) 09:35 (-4:14)
</table>
<tableCaption confidence="0.9916284">
Table 1: Total annotation time, portion spent se-
lecting annotation type, and absolute improve-
ment for rapid mode.
website2 for further details on current and past an-
notation projects using BRAT.
</tableCaption>
<subsectionHeader confidence="0.966887">
4.2 Automatic Annotation Support
</subsectionHeader>
<bodyText confidence="0.999975555555556">
To estimate the contribution of the semantic class
disambiguation component to annotation produc-
tivity, we performed a small-scale experiment in-
volving an entity and process mention tagging
task. The annotation targets were of 54 dis-
tinct mention types (19 physical entity and 35
event/process types) marked using the simple
typed-span representation. To reduce confound-
ing effects from annotator productivity differ-
ences and learning during the task, annotation was
performed by a single experienced annotator with
a Ph.D. in biology in a closely related area who
was previously familiar with the annotation task.
The experiment was performed on publication
abstracts from the biomolecular science subdo-
main of glucose metabolism in cancer. The texts
were drawn from a pool of 1,750 initial candi-
dates using stratified sampling to select pairs of
10-document sets with similar overall statistical
properties.3 Four pairs of 10 documents (80 in to-
tal) were annotated in the experiment, with 10 in
each pair annotated with automatic support and 10
without, in alternating sequence to prevent learn-
ing effects from favouring either approach.
The results of this experiment are summarized
in Table 1 and Figure 6. In total 1,546 annotations
were created in normal mode and 1,541 annota-
</bodyText>
<footnote confidence="0.99985475">
2http://brat.nlplab.org
3Document word count and expected annotation count,
were estimated from the output of NERsuite, a freely avail-
able CRF-based NER tagger: http://nersuite.nlplab.org
</footnote>
<page confidence="0.997914">
105
</page>
<figure confidence="0.9911895">
3000
2500
Time (seconds) 2000
1500
1000
500
0
Normal Mode Rapid Mode
</figure>
<figureCaption confidence="0.82899">
Figure 6: Allocation of annotation time. GREEN
signifies time spent on selecting annotation type
and BLUE the remaining annotation time.
</figureCaption>
<bodyText confidence="0.99991647368421">
tions in rapid mode; the sets are thus highly com-
parable. We observe a 15.4% reduction in total
annotation time, and, as expected, this is almost
exclusively due to a reduction in the time the an-
notator spent selecting the type to assign to each
span, which is reduced by 30.7%; annotation time
is otherwise stable across the annotation modes
(Figure 6). The reduction in the time spent in se-
lecting the span is explained by the limiting of the
number of candidate types exposed to the annota-
tor, which were decreased from the original 54 to
an average of 2.88 by the semantic class disam-
biguation component (Stenetorp et al., 2011a).
Although further research is needed to establish
the benefits of this approach in various annotation
tasks, we view the results of this initial experi-
ment as promising regarding the potential of our
approach to using machine learning to support an-
notation efforts.
</bodyText>
<sectionHeader confidence="0.998911" genericHeader="related work">
5 Related Work and Conclusions
</sectionHeader>
<bodyText confidence="0.999963882352941">
We have introduced BRAT, an intuitive and user-
friendly web-based annotation tool that aims to
enhance annotator productivity by closely inte-
grating NLP technology into the annotation pro-
cess. BRAT has been and is being used for several
ongoing annotation efforts at a number of aca-
demic institutions and has so far been used for
the creation of well-over 50,000 annotations. We
presented an experiment demonstrating that inte-
grated machine learning technology can reduce
the time for type selection by over 30% and over-
all annotation time by 15% for a multi-type entity
mention annotation task.
The design and implementation of BRAT was
informed by experience from several annotation
tasks and research efforts spanning more than
a decade. A variety of previously introduced
annotation tools and approaches also served to
guide our design decisions, including the fast an-
notation mode of Knowtator (Ogren, 2006), the
search capabilities of the XConc tool (Kim et al.,
2008), and the design of web-based systems such
as MyMiner (Salgado et al., 2010), and GATE
Teamware (Cunningham et al., 2011). Using ma-
chine learning to accelerate annotation by sup-
porting human judgements is well documented in
the literature for tasks such as entity annotation
(Tsuruoka et al., 2008) and translation (Martinez-
G´omez et al., 2011), efforts which served as in-
spiration for our own approach.
BRAT, along with conversion tools and exten-
sive documentation, is freely available under the
open-source MIT license from its homepage at
http://brat.nlplab.org
</bodyText>
<sectionHeader confidence="0.994728" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9984639">
The authors would like to thank early adopters of
BRAT who have provided us with extensive feed-
back and feature suggestions. This work was sup-
ported by Grant-in-Aid for Specially Promoted
Research (MEXT, Japan), the UK Biotechnology
and Biological Sciences Research Council (BB-
SRC) under project Automated Biological Event
Extraction from the Literature for Drug Discov-
ery (reference number: BB/G013160/1), and the
Royal Swedish Academy of Sciences.
</bodyText>
<page confidence="0.997624">
106
</page>
<sectionHeader confidence="0.990283" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999102401869159">
Steven Abney. 1991. Parsing by chunks. Principle-
based parsing, 44:257–278.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-
X shared task on multilingual dependency parsing.
In Proceedings of the Tenth Conference on Com-
putational Natural Language Learning (CoNLL-X),
pages 149–164.
Stuart K. Card, Thomas P. Moran, and Allen Newell.
1983. The psychology of human-computer interac-
tion. Lawrence Erlbaum Associates, Hillsdale, New
Jersey.
Xavier Carreras and Lluis M`arquez. 2005. Introduc-
tion to the CoNLL-2005 shared task: Semantic Role
Labeling. In Proceedings of the 9th Conference on
Natural Language Learning, pages 152–164. Asso-
ciation for Computational Linguistics.
Hamish Cunningham, Diana Maynard, Kalina
Bontcheva, Valentin Tablan, Niraj Aswani, Ian
Roberts, Genevieve Gorrell, Adam Funk, Angus
Roberts, Danica Damljanovic, Thomas Heitz,
Mark A. Greenwood, Horacio Saggion, Johann
Petrak, Yaoyong Li, and Wim Peters. 2011. Text
Processing with GATE (Version 6).
George Doddington, Alexis Mitchell, Mark Przybocki,
Lance Ramshaw, Stephanie Strassel, and Ralph
Weischedel. 2004. The Automatic Content Extrac-
tion (ACE) program: Tasks, data, and evaluation. In
Proceedings of the 4th International Conference on
Language Resources and Evaluation, pages 837–
840.
Roy Fielding. 2000. REpresentational State Trans-
fer (REST). Architectural Styles and the Design
of Network-based Software Architectures. Univer-
sity of California, Irvine, page 120.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28(3):245–288.
Jin-Dong Kim, Tomoko Ohta, and Jun’ichi Tsujii.
2008. Corpus annotation for mining biomedi-
cal events from literature. BMC Bioinformatics,
9(1):10.
Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert
Bossy, Ngan Nguyen, and Jun’ichi Tsujii. 2011.
Overview of BioNLP Shared Task 2011. In Pro-
ceedings of BioNLP Shared Task 2011 Workshop,
pages 1–6, Portland, Oregon, USA, June. Associa-
tion for Computational Linguistics.
LDC. 2005. ACE (Automatic Content Extraction) En-
glish Annotation Guidelines for Events. Technical
report, Linguistic Data Consortium.
Pascual Martinez-G´omez, Germ´an Sanchis-Trilles,
and Francisco Casacuberta. 2011. Online learn-
ing via dynamic reranking for computer assisted
translation. In Alexander Gelbukh, editor, Compu-
tational Linguistics and Intelligent Text Processing,
volume 6609 of Lecture Notes in Computer Science,
pages 93–105. Springer Berlin / Heidelberg.
Joakim Nivre. 2003. An Efficient Algorithm for Pro-
jective Dependency Parsing. In Proceedings of the
8th International Workshop on Parsing Technolo-
gies, pages 149–160.
Philip V. Ogren. 2006. Knowtator: A prot´eg´e plug-in
for annotated corpus construction. In Proceedings
of the Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, Companion Volume:
Demonstrations, pages 273–275, New York City,
USA, June. Association for Computational Linguis-
tics.
Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-
livan, Chunhong Mao, Chunxia Wang, Bruno So-
bral, Junichi Tsujii, and Sophia Ananiadou. 2012.
Overview of the ID, EPI and REL tasks of BioNLP
Shared Task 2011. BMC Bioinformatics, 13(suppl.
8):S2.
David Salgado, Martin Krallinger, Marc Depaule,
Elodie Drula, and Ashish V Tendulkar. 2010.
Myminer system description. In Proceedings of the
Third BioCreative Challenge Evaluation Workshop
2010, pages 157–158.
Pontus Stenetorp, Sampo Pyysalo, Sophia Ananiadou,
and Jun’ichi Tsujii. 2011a. Almost total recall: Se-
mantic category disambiguation using large lexical
resources and approximate string matching. In Pro-
ceedings of the Fourth International Symposium on
Languages in Biology and Medicine.
Pontus Stenetorp, Goran Topi´c, Sampo Pyysalo,
Tomoko Ohta, Jin-Dong Kim, and Jun’ichi Tsujii.
2011b. BioNLP Shared Task 2011: Supporting Re-
sources. In Proceedings of BioNLP Shared Task
2011 Workshop, pages 112–120, Portland, Oregon,
USA, June. Association for Computational Linguis-
tics.
Beth M. Sundheim. 1996. Overview of results of
the MUC-6 evaluation. In Proceedings of the Sixth
Message Understanding Conference, pages 423–
442. Association for Computational Linguistics.
Erik F. Tjong Kim Sang and Fien De Meulder.
2003. Introduction to the CoNLL-2003 shared
task: Language-independent named entity recogni-
tion. In Proceedings of the Seventh Conference on
Natural Language Learning at HLT-NAACL 2003,
pages 142–147.
Yoshimasa Tsuruoka, Jun’ichi Tsujii, and Sophia Ana-
niadou. 2008. Accelerating the annotation of
sparse named entities by dynamic sentence selec-
tion. BMC Bioinformatics, 9(Suppl 11):S8.
</reference>
<page confidence="0.998684">
107
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.479889">
<title confidence="0.999549">a Web-based Tool for NLP-Assisted Text Annotation</title>
<author confidence="0.9735035">Sampo Goran Sophia</author>
<author confidence="0.9735035">Jun’ichi</author>
<affiliation confidence="0.985107">of Computer Science, The University of Tokyo, Tokyo, of Computer Science, University of Manchester, Manchester, Centre for Text Mining, University of Manchester, Manchester,</affiliation>
<address confidence="0.854971">Research Asia, Beijing, People’s Republic of</address>
<email confidence="0.999374">jtsujii@microsoft.com</email>
<abstract confidence="0.999879823529412">We introduce the brat rapid annotation tool an intuitive web-based tool for text annotation supported by Natural Language (NLP) technology. been developed for rich structured annotation for a variety of NLP tasks and aims to support manual curation efforts and increase annotator productivity using NLP techniques. We discuss several case studies of real-world annotation projects using versions of present an evaluation of annotation assisted by semantic class disambiguation on a multicategory entity mention annotation task, showing a 15% decrease in total annotatime. available under an open-</abstract>
<intro confidence="0.619952">source license from: http://brat.nlplab.org</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Parsing by chunks. Principlebased parsing,</title>
<date>1991</date>
<pages>44--257</pages>
<contexts>
<context position="5755" citStr="Abney, 1991" startWordPosition="858" endWordPosition="859">ions of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2). Additional aspects of annotations can be marked using attributes, binary or multi-valued flags that can be added to other annotations. Finally, annotators can attach free-form text notes to any annotation. In addition to information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1 for examples). Further, both the BRAT client and server implement full support for the Unicode standard, which allow the tool to support the annotation of text using e.g. Chinese or Devan¯agaricharacters. BRAT is distributed with examples from over 20 corpora for a variety of tasks, involving texts in seven different languages and including examples from corpora such as those introduced for the CoNLL shared tasks on language-independent named entity recogniti</context>
</contexts>
<marker>Abney, 1991</marker>
<rawString>Steven Abney. 1991. Parsing by chunks. Principlebased parsing, 44:257–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLLX shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>149--164</pages>
<contexts>
<context position="6458" citStr="Buchholz and Marsi, 2006" startWordPosition="967" endWordPosition="970">05), and dependency annotation (Nivre, 2003) (See Figure 1 for examples). Further, both the BRAT client and server implement full support for the Unicode standard, which allow the tool to support the annotation of text using e.g. Chinese or Devan¯agaricharacters. BRAT is distributed with examples from over 20 corpora for a variety of tasks, involving texts in seven different languages and including examples from corpora such as those introduced for the CoNLL shared tasks on language-independent named entity recognition (Tjong Kim Sang and De Meulder, 2003) and multilingual dependency parsing (Buchholz and Marsi, 2006). BRAT also implements a fully configurable system for checking detailed constraints on annotation semantics, for example specifying that a TRANSFER event must take exactly one of each of GIVER, RECIPIENT and BENEFICIARY arguments, each of which must have one of the types PERSON, ORGANIZATION or GEO-POLITICAL ENTITY, as well as a MONEY argument of type 103 Figure 3: Incomplete TRANSFER event indicated to the annotator MONEY, and may optionally take a PLACE argument of type LOCATION (LDC, 2005). Constraint checking is fully integrated into the annotation interface and feedback is immediate, wit</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLLX shared task on multilingual dependency parsing. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart K Card</author>
<author>Thomas P Moran</author>
<author>Allen Newell</author>
</authors>
<title>The psychology of human-computer interaction. Lawrence Erlbaum Associates,</title>
<date>1983</date>
<location>Hillsdale, New Jersey.</location>
<contexts>
<context position="9831" citStr="Card et al., 1983" startWordPosition="1489" endWordPosition="1492">extended or adapted to switch out the server or client. The client user interface is implemented using XHTML and Scalable Vector Graphics (SVG), with interactivity implemented using JavaScript with the jQuery library. The client communicates with the server using Asynchronous JavaScript and XML (AJAX), which permits asynchronous messaging. BRAT uses a stateless server back-end implemented in Python and supports both the Common Gateway Interface (CGI) and FastCGI protocols, the latter allowing response times far below the 100 ms boundary for a “smooth” user experience without noticeable delay (Card et al., 1983). For server side annotation storage BRAT uses an easyto-process file-based stand-off format that can be converted from or into other formats; there is no need to perform database import or export to interface with the data storage. The BRAT server in104 Figure 5: Example annotation from the BioNLP Shared Task 2011 Epigenetics and Post-translational Modifications event extraction task. stallation requires only a CGI-capable web server and the set-up supports any number of annotators who access the server using their browsers, on any operating system, without separate installation. Client-serve</context>
</contexts>
<marker>Card, Moran, Newell, 1983</marker>
<rawString>Stuart K. Card, Thomas P. Moran, and Allen Newell. 1983. The psychology of human-computer interaction. Lawrence Erlbaum Associates, Hillsdale, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Lluis M`arquez</author>
</authors>
<title>Introduction to the CoNLL-2005 shared task: Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th Conference on Natural Language Learning,</booktitle>
<pages>152--164</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Carreras, M`arquez, 2005</marker>
<rawString>Xavier Carreras and Lluis M`arquez. 2005. Introduction to the CoNLL-2005 shared task: Semantic Role Labeling. In Proceedings of the 9th Conference on Natural Language Learning, pages 152–164. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamish Cunningham</author>
<author>Diana Maynard</author>
<author>Kalina Bontcheva</author>
<author>Valentin Tablan</author>
<author>Niraj Aswani</author>
<author>Ian Roberts</author>
<author>Genevieve Gorrell</author>
<author>Adam Funk</author>
<author>Angus Roberts</author>
<author>Danica Damljanovic</author>
<author>Thomas Heitz</author>
<author>Mark A Greenwood</author>
<author>Horacio Saggion</author>
<author>Johann Petrak</author>
<author>Yaoyong Li</author>
<author>Wim Peters</author>
</authors>
<date>2011</date>
<journal>Text Processing with GATE (Version</journal>
<volume>6</volume>
<contexts>
<context position="16076" citStr="Cunningham et al., 2011" startWordPosition="2475" endWordPosition="2478"> the time for type selection by over 30% and overall annotation time by 15% for a multi-type entity mention annotation task. The design and implementation of BRAT was informed by experience from several annotation tasks and research efforts spanning more than a decade. A variety of previously introduced annotation tools and approaches also served to guide our design decisions, including the fast annotation mode of Knowtator (Ogren, 2006), the search capabilities of the XConc tool (Kim et al., 2008), and the design of web-based systems such as MyMiner (Salgado et al., 2010), and GATE Teamware (Cunningham et al., 2011). Using machine learning to accelerate annotation by supporting human judgements is well documented in the literature for tasks such as entity annotation (Tsuruoka et al., 2008) and translation (MartinezG´omez et al., 2011), efforts which served as inspiration for our own approach. BRAT, along with conversion tools and extensive documentation, is freely available under the open-source MIT license from its homepage at http://brat.nlplab.org Acknowledgements The authors would like to thank early adopters of BRAT who have provided us with extensive feedback and feature suggestions. This work was </context>
</contexts>
<marker>Cunningham, Maynard, Bontcheva, Tablan, Aswani, Roberts, Gorrell, Funk, Roberts, Damljanovic, Heitz, Greenwood, Saggion, Petrak, Li, Peters, 2011</marker>
<rawString>Hamish Cunningham, Diana Maynard, Kalina Bontcheva, Valentin Tablan, Niraj Aswani, Ian Roberts, Genevieve Gorrell, Adam Funk, Angus Roberts, Danica Damljanovic, Thomas Heitz, Mark A. Greenwood, Horacio Saggion, Johann Petrak, Yaoyong Li, and Wim Peters. 2011. Text Processing with GATE (Version 6).</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Doddington</author>
<author>Alexis Mitchell</author>
<author>Mark Przybocki</author>
<author>Lance Ramshaw</author>
<author>Stephanie Strassel</author>
<author>Ralph Weischedel</author>
</authors>
<title>The Automatic Content Extraction (ACE) program: Tasks, data, and evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<pages>837--840</pages>
<contexts>
<context position="5308" citStr="Doddington et al., 2004" startWordPosition="787" endWordPosition="790">and can be set up to support most text annotation tasks. The most basic annotation primitive identifies a text span and assigns it a type (or tag or label), marking for e.g. POS-tagged tokens, chunks or entity mentions (Figure 1 top). These base annotations can be connected by binary relations – either directed or undirected – which can be configured for e.g. simple relation extraction, or verb frame annotation (Figure 1 middle and bottom). n-ary associations of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2). Additional aspects of annotations can be marked using attributes, binary or multi-valued flags that can be added to other annotations. Finally, annotators can attach free-form text notes to any annotation. In addition to information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1 for examples). F</context>
</contexts>
<marker>Doddington, Mitchell, Przybocki, Ramshaw, Strassel, Weischedel, 2004</marker>
<rawString>George Doddington, Alexis Mitchell, Mark Przybocki, Lance Ramshaw, Stephanie Strassel, and Ralph Weischedel. 2004. The Automatic Content Extraction (ACE) program: Tasks, data, and evaluation. In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 837– 840.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Fielding</author>
</authors>
<title>REpresentational State Transfer (REST). Architectural Styles and the Design of Network-based Software Architectures.</title>
<date>2000</date>
<pages>120</pages>
<institution>University of California,</institution>
<location>Irvine,</location>
<contexts>
<context position="9185" citStr="Fielding, 2000" startWordPosition="1392" endWordPosition="1393">arch document colFigure 4: The BRAT search dialog lections for text span annotations, relations, event structures, or simply text, with a rich set of search options definable using a simple point-and-click interface (Figure 4). Additionally, search results can optionally be displayed using keyword-incontext concordancing and sorted for browsing using any aspect of the matched annotation (e.g. type, text, or context). 3 Implementation BRAT is implemented using a client-server architecture with communication over HTTP using JavaScript Object Notation (JSON). The server is a RESTful web service (Fielding, 2000) and the tool can easily be extended or adapted to switch out the server or client. The client user interface is implemented using XHTML and Scalable Vector Graphics (SVG), with interactivity implemented using JavaScript with the jQuery library. The client communicates with the server using Asynchronous JavaScript and XML (AJAX), which permits asynchronous messaging. BRAT uses a stateless server back-end implemented in Python and supports both the Common Gateway Interface (CGI) and FastCGI protocols, the latter allowing response times far below the 100 ms boundary for a “smooth” user experienc</context>
</contexts>
<marker>Fielding, 2000</marker>
<rawString>Roy Fielding. 2000. REpresentational State Transfer (REST). Architectural Styles and the Design of Network-based Software Architectures. University of California, Irvine, page 120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="5806" citStr="Gildea and Jurafsky, 2002" startWordPosition="864" endWordPosition="867">, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2). Additional aspects of annotations can be marked using attributes, binary or multi-valued flags that can be added to other annotations. Finally, annotators can attach free-form text notes to any annotation. In addition to information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1 for examples). Further, both the BRAT client and server implement full support for the Unicode standard, which allow the tool to support the annotation of text using e.g. Chinese or Devan¯agaricharacters. BRAT is distributed with examples from over 20 corpora for a variety of tasks, involving texts in seven different languages and including examples from corpora such as those introduced for the CoNLL shared tasks on language-independent named entity recognition (Tjong Kim Sang and De Meulder, 2003) and multil</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Corpus annotation for mining biomedical events from literature.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="15955" citStr="Kim et al., 2008" startWordPosition="2455" endWordPosition="2458">0,000 annotations. We presented an experiment demonstrating that integrated machine learning technology can reduce the time for type selection by over 30% and overall annotation time by 15% for a multi-type entity mention annotation task. The design and implementation of BRAT was informed by experience from several annotation tasks and research efforts spanning more than a decade. A variety of previously introduced annotation tools and approaches also served to guide our design decisions, including the fast annotation mode of Knowtator (Ogren, 2006), the search capabilities of the XConc tool (Kim et al., 2008), and the design of web-based systems such as MyMiner (Salgado et al., 2010), and GATE Teamware (Cunningham et al., 2011). Using machine learning to accelerate annotation by supporting human judgements is well documented in the literature for tasks such as entity annotation (Tsuruoka et al., 2008) and translation (MartinezG´omez et al., 2011), efforts which served as inspiration for our own approach. BRAT, along with conversion tools and extensive documentation, is freely available under the open-source MIT license from its homepage at http://brat.nlplab.org Acknowledgements The authors would </context>
</contexts>
<marker>Kim, Ohta, Tsujii, 2008</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, and Jun’ichi Tsujii. 2008. Corpus annotation for mining biomedical events from literature. BMC Bioinformatics, 9(1):10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Sampo Pyysalo</author>
<author>Tomoko Ohta</author>
<author>Robert Bossy</author>
<author>Ngan Nguyen</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Overview of BioNLP Shared Task</title>
<date>2011</date>
<booktitle>In Proceedings of BioNLP Shared Task 2011 Workshop,</booktitle>
<pages>1--6</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="5339" citStr="Kim et al., 2011" startWordPosition="793" endWordPosition="796"> annotation tasks. The most basic annotation primitive identifies a text span and assigns it a type (or tag or label), marking for e.g. POS-tagged tokens, chunks or entity mentions (Figure 1 top). These base annotations can be connected by binary relations – either directed or undirected – which can be configured for e.g. simple relation extraction, or verb frame annotation (Figure 1 middle and bottom). n-ary associations of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2). Additional aspects of annotations can be marked using attributes, binary or multi-valued flags that can be added to other annotations. Finally, annotators can attach free-form text notes to any annotation. In addition to information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1 for examples). Further, both the BRAT client an</context>
</contexts>
<marker>Kim, Pyysalo, Ohta, Bossy, Nguyen, Tsujii, 2011</marker>
<rawString>Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, Robert Bossy, Ngan Nguyen, and Jun’ichi Tsujii. 2011. Overview of BioNLP Shared Task 2011. In Proceedings of BioNLP Shared Task 2011 Workshop, pages 1–6, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>LDC</author>
</authors>
<title>ACE (Automatic Content Extraction) English Annotation Guidelines for Events.</title>
<date>2005</date>
<tech>Technical report,</tech>
<institution>Linguistic Data Consortium.</institution>
<contexts>
<context position="6956" citStr="LDC, 2005" startWordPosition="1051" endWordPosition="1052">recognition (Tjong Kim Sang and De Meulder, 2003) and multilingual dependency parsing (Buchholz and Marsi, 2006). BRAT also implements a fully configurable system for checking detailed constraints on annotation semantics, for example specifying that a TRANSFER event must take exactly one of each of GIVER, RECIPIENT and BENEFICIARY arguments, each of which must have one of the types PERSON, ORGANIZATION or GEO-POLITICAL ENTITY, as well as a MONEY argument of type 103 Figure 3: Incomplete TRANSFER event indicated to the annotator MONEY, and may optionally take a PLACE argument of type LOCATION (LDC, 2005). Constraint checking is fully integrated into the annotation interface and feedback is immediate, with clear visual effects marking incomplete or erroneous annotations (Figure 3). 2.4 NLP Technology Integration BRAT supports two standard approaches for integrating the results of fully automatic annotation tools into an annotation workflow: bulk annotation imports can be performed by format conversion tools distributed with BRAT for many standard formats (such as in-line and columnformatted BIO), and tools that provide standard web service interfaces can be configured to be invoked from the us</context>
</contexts>
<marker>LDC, 2005</marker>
<rawString>LDC. 2005. ACE (Automatic Content Extraction) English Annotation Guidelines for Events. Technical report, Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascual Martinez-G´omez</author>
<author>Germ´an Sanchis-Trilles</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Online learning via dynamic reranking for computer assisted translation.</title>
<date>2011</date>
<booktitle>Computational Linguistics and Intelligent Text Processing,</booktitle>
<volume>6609</volume>
<pages>93--105</pages>
<editor>In Alexander Gelbukh, editor,</editor>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<marker>Martinez-G´omez, Sanchis-Trilles, Casacuberta, 2011</marker>
<rawString>Pascual Martinez-G´omez, Germ´an Sanchis-Trilles, and Francisco Casacuberta. 2011. Online learning via dynamic reranking for computer assisted translation. In Alexander Gelbukh, editor, Computational Linguistics and Intelligent Text Processing, volume 6609 of Lecture Notes in Computer Science, pages 93–105. Springer Berlin / Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>An Efficient Algorithm for Projective Dependency Parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies,</booktitle>
<pages>149--160</pages>
<contexts>
<context position="5877" citStr="Nivre, 2003" startWordPosition="875" endWordPosition="876">dheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2). Additional aspects of annotations can be marked using attributes, binary or multi-valued flags that can be added to other annotations. Finally, annotators can attach free-form text notes to any annotation. In addition to information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), and dependency annotation (Nivre, 2003) (See Figure 1 for examples). Further, both the BRAT client and server implement full support for the Unicode standard, which allow the tool to support the annotation of text using e.g. Chinese or Devan¯agaricharacters. BRAT is distributed with examples from over 20 corpora for a variety of tasks, involving texts in seven different languages and including examples from corpora such as those introduced for the CoNLL shared tasks on language-independent named entity recognition (Tjong Kim Sang and De Meulder, 2003) and multilingual dependency parsing (Buchholz and Marsi, 2006). BRAT also impleme</context>
</contexts>
<marker>Nivre, 2003</marker>
<rawString>Joakim Nivre. 2003. An Efficient Algorithm for Projective Dependency Parsing. In Proceedings of the 8th International Workshop on Parsing Technologies, pages 149–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip V Ogren</author>
</authors>
<title>Knowtator: A prot´eg´e plug-in for annotated corpus construction.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Companion Volume: Demonstrations,</booktitle>
<pages>273--275</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="15893" citStr="Ogren, 2006" startWordPosition="2446" endWordPosition="2447"> and has so far been used for the creation of well-over 50,000 annotations. We presented an experiment demonstrating that integrated machine learning technology can reduce the time for type selection by over 30% and overall annotation time by 15% for a multi-type entity mention annotation task. The design and implementation of BRAT was informed by experience from several annotation tasks and research efforts spanning more than a decade. A variety of previously introduced annotation tools and approaches also served to guide our design decisions, including the fast annotation mode of Knowtator (Ogren, 2006), the search capabilities of the XConc tool (Kim et al., 2008), and the design of web-based systems such as MyMiner (Salgado et al., 2010), and GATE Teamware (Cunningham et al., 2011). Using machine learning to accelerate annotation by supporting human judgements is well documented in the literature for tasks such as entity annotation (Tsuruoka et al., 2008) and translation (MartinezG´omez et al., 2011), efforts which served as inspiration for our own approach. BRAT, along with conversion tools and extensive documentation, is freely available under the open-source MIT license from its homepage</context>
</contexts>
<marker>Ogren, 2006</marker>
<rawString>Philip V. Ogren. 2006. Knowtator: A prot´eg´e plug-in for annotated corpus construction. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Companion Volume: Demonstrations, pages 273–275, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Tomoko Ohta</author>
<author>Rafal Rak</author>
<author>Dan Sullivan</author>
<author>Chunhong Mao</author>
<author>Chunxia Wang</author>
<author>Bruno Sobral</author>
<author>Junichi Tsujii</author>
<author>Sophia Ananiadou</author>
</authors>
<date>2012</date>
<journal>BMC Bioinformatics,</journal>
<booktitle>Overview of the ID, EPI and REL tasks of BioNLP Shared Task</booktitle>
<volume>13</volume>
<pages>8--2</pages>
<contexts>
<context position="11721" citStr="Pyysalo et al., 2012" startWordPosition="1787" endWordPosition="1790">s BRAT has been used throughout its development during 2011 in the annotation of six different corpora by four research groups in efforts that have in total involved the creation of well-over 50,000 annotations in thousands of documents comprising hundreds of thousands of words. These projects include structured event annotation for the domain of cancer biology, Japanese verb frame annotation, and genemutation-phenotype relation annotation. One prominent effort making use of BRAT is the BioNLP Shared Task 2011,1 in which the tool was used in the annotation of the EPI and ID main task corpora (Pyysalo et al., 2012). These two information extraction tasks involved the annotation of entities, relations and events in the epigenetics and infectious diseases subdomains of biology. Figure 5 shows an illustration of shared task annotations. Many other annotation efforts using BRAT are still ongoing. We refer the reader to the BRAT 1http://2011.bionlp-st.org Mode Total Type Selection Normal 45:28 13:49 Rapid 39:24 (-6:04) 09:35 (-4:14) Table 1: Total annotation time, portion spent selecting annotation type, and absolute improvement for rapid mode. website2 for further details on current and past annotation proj</context>
</contexts>
<marker>Pyysalo, Ohta, Rak, Sullivan, Mao, Wang, Sobral, Tsujii, Ananiadou, 2012</marker>
<rawString>Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sullivan, Chunhong Mao, Chunxia Wang, Bruno Sobral, Junichi Tsujii, and Sophia Ananiadou. 2012. Overview of the ID, EPI and REL tasks of BioNLP Shared Task 2011. BMC Bioinformatics, 13(suppl. 8):S2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Salgado</author>
<author>Martin Krallinger</author>
<author>Marc Depaule</author>
<author>Elodie Drula</author>
<author>Ashish V Tendulkar</author>
</authors>
<title>Myminer system description.</title>
<date>2010</date>
<booktitle>In Proceedings of the Third BioCreative Challenge Evaluation Workshop</booktitle>
<pages>157--158</pages>
<contexts>
<context position="16031" citStr="Salgado et al., 2010" startWordPosition="2468" endWordPosition="2471">ted machine learning technology can reduce the time for type selection by over 30% and overall annotation time by 15% for a multi-type entity mention annotation task. The design and implementation of BRAT was informed by experience from several annotation tasks and research efforts spanning more than a decade. A variety of previously introduced annotation tools and approaches also served to guide our design decisions, including the fast annotation mode of Knowtator (Ogren, 2006), the search capabilities of the XConc tool (Kim et al., 2008), and the design of web-based systems such as MyMiner (Salgado et al., 2010), and GATE Teamware (Cunningham et al., 2011). Using machine learning to accelerate annotation by supporting human judgements is well documented in the literature for tasks such as entity annotation (Tsuruoka et al., 2008) and translation (MartinezG´omez et al., 2011), efforts which served as inspiration for our own approach. BRAT, along with conversion tools and extensive documentation, is freely available under the open-source MIT license from its homepage at http://brat.nlplab.org Acknowledgements The authors would like to thank early adopters of BRAT who have provided us with extensive fee</context>
</contexts>
<marker>Salgado, Krallinger, Depaule, Drula, Tendulkar, 2010</marker>
<rawString>David Salgado, Martin Krallinger, Marc Depaule, Elodie Drula, and Ashish V Tendulkar. 2010. Myminer system description. In Proceedings of the Third BioCreative Challenge Evaluation Workshop 2010, pages 157–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pontus Stenetorp</author>
<author>Sampo Pyysalo</author>
<author>Sophia Ananiadou</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Almost total recall: Semantic category disambiguation using large lexical resources and approximate string matching.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fourth International Symposium on Languages in Biology and Medicine.</booktitle>
<contexts>
<context position="2606" citStr="Stenetorp et al., 2011" startWordPosition="363" endWordPosition="367">ity of annotations, make annotation more accessible to non-technical users such as subject *These authors contributed equally to this work Figure 1: Visualisation examples. Top: named entity recognition, middle: dependency syntax, bottom: verb frames. domain experts, and improve annotation productivity, thus reducing both the human and financial cost of annotation. The tool presented in this work, BRAT, represents our attempt to realise these possibilities. 2 Features 2.1 High-quality Annotation Visualisation BRAT is based on our previously released opensource STAV text annotation visualiser (Stenetorp et al., 2011b), which was designed to help users gain an understanding of complex annotations involving a large number of different semantic types, dense, partially overlapping text annotations, and non-projective sets of connections between annotations. Both tools share a vector graphics-based visualisation component, which provide scalable detail and rendering. BRAT integrates PDF and EPS image format export functionality to support use in e.g. figures in publications (Figure 1). 102 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 102–10</context>
<context position="8359" citStr="Stenetorp et al., 2011" startWordPosition="1270" endWordPosition="1273">ess this issue, we have been studying ways to augment the annotation process with input from statistical and machine learning methods to support the annotation process while still involving human annotator judgement for each annotation. As a specific realisation based on this approach, we have integrated a recently introduced machine learning-based semantic class disambiguation system capable of offering multiple outputs with probability estimates that was shown to be able to reduce ambiguity on average by over 75% while retaining the correct class in on average 99% of cases over six corpora (Stenetorp et al., 2011a). Section 4 presents an evaluation of the contribution of this component to annotator productivity. 2.5 Corpus Search Functionality BRAT implements a comprehensive set of search functions, allowing users to search document colFigure 4: The BRAT search dialog lections for text span annotations, relations, event structures, or simply text, with a rich set of search options definable using a simple point-and-click interface (Figure 4). Additionally, search results can optionally be displayed using keyword-incontext concordancing and sorted for browsing using any aspect of the matched annotation</context>
<context position="14682" citStr="Stenetorp et al., 2011" startWordPosition="2253" endWordPosition="2256">rapid mode; the sets are thus highly comparable. We observe a 15.4% reduction in total annotation time, and, as expected, this is almost exclusively due to a reduction in the time the annotator spent selecting the type to assign to each span, which is reduced by 30.7%; annotation time is otherwise stable across the annotation modes (Figure 6). The reduction in the time spent in selecting the span is explained by the limiting of the number of candidate types exposed to the annotator, which were decreased from the original 54 to an average of 2.88 by the semantic class disambiguation component (Stenetorp et al., 2011a). Although further research is needed to establish the benefits of this approach in various annotation tasks, we view the results of this initial experiment as promising regarding the potential of our approach to using machine learning to support annotation efforts. 5 Related Work and Conclusions We have introduced BRAT, an intuitive and userfriendly web-based annotation tool that aims to enhance annotator productivity by closely integrating NLP technology into the annotation process. BRAT has been and is being used for several ongoing annotation efforts at a number of academic institutions </context>
</contexts>
<marker>Stenetorp, Pyysalo, Ananiadou, Tsujii, 2011</marker>
<rawString>Pontus Stenetorp, Sampo Pyysalo, Sophia Ananiadou, and Jun’ichi Tsujii. 2011a. Almost total recall: Semantic category disambiguation using large lexical resources and approximate string matching. In Proceedings of the Fourth International Symposium on Languages in Biology and Medicine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pontus Stenetorp</author>
<author>Goran Topi´c</author>
<author>Sampo Pyysalo</author>
<author>Tomoko Ohta</author>
<author>Jin-Dong Kim</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>BioNLP Shared Task 2011: Supporting Resources.</title>
<date>2011</date>
<booktitle>In Proceedings of BioNLP Shared Task 2011 Workshop,</booktitle>
<pages>112--120</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<marker>Stenetorp, Topi´c, Pyysalo, Ohta, Kim, Tsujii, 2011</marker>
<rawString>Pontus Stenetorp, Goran Topi´c, Sampo Pyysalo, Tomoko Ohta, Jin-Dong Kim, and Jun’ichi Tsujii. 2011b. BioNLP Shared Task 2011: Supporting Resources. In Proceedings of BioNLP Shared Task 2011 Workshop, pages 112–120, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth M Sundheim</author>
</authors>
<title>Overview of results of the MUC-6 evaluation.</title>
<date>1996</date>
<booktitle>In Proceedings of the Sixth Message Understanding Conference,</booktitle>
<pages>423--442</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5277" citStr="Sundheim, 1996" startWordPosition="784" endWordPosition="785">is fully configurable and can be set up to support most text annotation tasks. The most basic annotation primitive identifies a text span and assigns it a type (or tag or label), marking for e.g. POS-tagged tokens, chunks or entity mentions (Figure 1 top). These base annotations can be connected by binary relations – either directed or undirected – which can be configured for e.g. simple relation extraction, or verb frame annotation (Figure 1 middle and bottom). n-ary associations of annotations are also supported, allowing the annotation of event structures such as those targeted in the MUC (Sundheim, 1996), ACE (Doddington et al., 2004), and BioNLP (Kim et al., 2011) Information Extraction (IE) tasks (Figure 2). Additional aspects of annotations can be marked using attributes, binary or multi-valued flags that can be added to other annotations. Finally, annotators can attach free-form text notes to any annotation. In addition to information extraction tasks, these annotation primitives allow BRAT to be configured for use in various other tasks, such as chunking (Abney, 1991), Semantic Role Labeling (Gildea and Jurafsky, 2002; Carreras and M`arquez, 2005), and dependency annotation (Nivre, 2003)</context>
</contexts>
<marker>Sundheim, 1996</marker>
<rawString>Beth M. Sundheim. 1996. Overview of results of the MUC-6 evaluation. In Proceedings of the Sixth Message Understanding Conference, pages 423– 442. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Erik</author>
</authors>
<title>Tjong Kim Sang and Fien De Meulder.</title>
<date>2003</date>
<booktitle>In Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL</booktitle>
<pages>142--147</pages>
<marker>Erik, 2003</marker>
<rawString>Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition. In Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, pages 142–147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Jun’ichi Tsujii</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Accelerating the annotation of sparse named entities by dynamic sentence selection.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11--8</pages>
<contexts>
<context position="16253" citStr="Tsuruoka et al., 2008" startWordPosition="2503" endWordPosition="2506">experience from several annotation tasks and research efforts spanning more than a decade. A variety of previously introduced annotation tools and approaches also served to guide our design decisions, including the fast annotation mode of Knowtator (Ogren, 2006), the search capabilities of the XConc tool (Kim et al., 2008), and the design of web-based systems such as MyMiner (Salgado et al., 2010), and GATE Teamware (Cunningham et al., 2011). Using machine learning to accelerate annotation by supporting human judgements is well documented in the literature for tasks such as entity annotation (Tsuruoka et al., 2008) and translation (MartinezG´omez et al., 2011), efforts which served as inspiration for our own approach. BRAT, along with conversion tools and extensive documentation, is freely available under the open-source MIT license from its homepage at http://brat.nlplab.org Acknowledgements The authors would like to thank early adopters of BRAT who have provided us with extensive feedback and feature suggestions. This work was supported by Grant-in-Aid for Specially Promoted Research (MEXT, Japan), the UK Biotechnology and Biological Sciences Research Council (BBSRC) under project Automated Biological</context>
</contexts>
<marker>Tsuruoka, Tsujii, Ananiadou, 2008</marker>
<rawString>Yoshimasa Tsuruoka, Jun’ichi Tsujii, and Sophia Ananiadou. 2008. Accelerating the annotation of sparse named entities by dynamic sentence selection. BMC Bioinformatics, 9(Suppl 11):S8.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>