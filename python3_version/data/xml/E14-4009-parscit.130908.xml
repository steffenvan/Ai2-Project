<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.034151">
<title confidence="0.981507">
Tight Integration of Speech Disfluency Removal into SMT
</title>
<author confidence="0.949514">
Eunah Cho Jan Niehues Alex Waibel
</author>
<affiliation confidence="0.966666333333333">
Interactive Systems Lab
Institute of Anthropomatics
Karlsruhe Institute of Technology, Germany
</affiliation>
<email confidence="0.998495">
{eunah.cho,jan.niehues,alex.waibel}@kit.edu
</email>
<sectionHeader confidence="0.993888" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999676777777778">
Speech disfluencies are one of the main
challenges of spoken language processing.
Conventional disfluency detection systems
deploy a hard decision, which can have
a negative influence on subsequent appli-
cations such as machine translation. In
this paper we suggest a novel approach
in which disfluency detection is integrated
into the translation process.
We train a CRF model to obtain a disflu-
ency probability for each word. The SMT
decoder will then skip the potentially dis-
fluent word based on its disfluency prob-
ability. Using the suggested scheme, the
translation score of both the manual tran-
script and ASR output is improved by
around 0.35 BLEU points compared to the
CRF hard decision system.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99993395">
Disfluencies arise due to the spontaneous nature
of speech. There has been a great deal of effort to
detect disfluent words, remove them (Johnson and
Charniak, 2004; Fitzgerald et al., 2009) and use
the cleaned text for subsequent applications such
as machine translation (MT) (Wang et al., 2010;
Cho et al., 2013).
One potential drawback of conventional ap-
proaches is that the decision whether a token is
a disfluency or not is a hard decision. For an
MT system, this can pose a severe problem if the
removed token was not in fact a disfluency and
should have been kept for the correct translation.
Therefore, we pass the decision whether a word is
part of a disfluency or not on to the translation sys-
tem, so that we can use the additional knowledge
available in the translation system to make a more
reliable decision. In order to limit the complexity,
the search space is pruned prior to decoding and
represented in a word lattice.
</bodyText>
<sectionHeader confidence="0.99978" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999860837837838">
Disfluencies in spontaneous speech have been
studied from various points of view. In the noisy
channel model (Honal and Schultz, 2003), it is
assumed that clean text without any disfluencies
has passed through a noisy channel. The clean
string is retrieved based on language model (LM)
scores and five additional models. Another noisy
channel approach involves a phrase-level statisti-
cal MT system, where noisy tokens are translated
into clean tokens (Maskey et al., 2006). A tree ad-
joining grammar is combined with this noisy chan-
nel model in (Johnson and Charniak, 2004), using
a syntactic parser to build an LM.
Fitzgerald et al. (2009) present a method to de-
tect speech disfluencies using a conditional ran-
dom field (CRF) with lexical, LM, and parser
information features. While previous work has
been limited to the postprocessing step of the au-
tomatic speech recogition (ASR) system, further
approaches (Wang et al., 2010; Cho et al., 2013)
use extended CRF features or additional models
to clean manual speech transcripts and use them
as input for an MT system.
While ASR systems use lattices to encode hy-
potheses, lattices have been used for MT systems
with various purposes. Herrmann et al. (2013)
use lattices to encode different reordering variants.
Lattices have also been used as a segmentation tac-
tic for compound words (Dyer, 2009), where the
segmentation is encoded as input in the lattice.
One of the differences between our work and
previous work is that we integrate the disfluency
removal into an MT system. Our work is not lim-
ited to the preprocessing step of MT, instead we
use the translation model to detect and remove dis-
fluencies. Contrary to other systems where detec-
tion is limited on manual transcripts only, our sys-
</bodyText>
<page confidence="0.997729">
43
</page>
<note confidence="0.690923">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 43–47,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.997352125">
tem shows translation performance improvements
on the ASR output as well.
Since there are two possible classes for each to-
ken, the number of possible clean sentences is ex-
ponential with regard to the sentence length. Thus,
we restrict the search space by representing only
the most probable clean source sentences in a word
lattice.
</bodyText>
<sectionHeader confidence="0.573915" genericHeader="method">
3 Tight Integration using Lattices
</sectionHeader>
<bodyText confidence="0.988906">
In this chapter, we explain how the disfluency re-
moval is integrated into the MT process.
</bodyText>
<subsectionHeader confidence="0.998701">
3.1 Model
</subsectionHeader>
<bodyText confidence="0.9996935">
The conventional translation of texts from sponta-
neous speech can be formulated as
</bodyText>
<equation confidence="0.999236666666667">
eˆ = arg max p(e |arg maxp(fc|f)) (1)
e fc
with
I
p(fc|f) = p(ci|fi) (2)
i=1
</equation>
<bodyText confidence="0.974687">
where fc denotes the clean string
</bodyText>
<equation confidence="0.9916536">
fc = {f1, ... , fI  |ci = clean} (3)
for the disfluency decision class c of each token.
�
clean (4 )
c ∈ disfluent
</equation>
<bodyText confidence="0.9994254">
Thus, using the conventional models, disfluency
removal is applied to the original, potentially noisy
string in order to obtain the cleaned string first.
This clean string is then translated.
The potential drawback of a conventional
speech translation system is caused by the rough
estimation in Equation 1, as disfluency removal
does not depend on maximizing the translation
quality itself. For example, we can consider the
sentence Use what you build, build what you use.
Due to its repetitive pattern in words and structure,
the first clause is often detected as a disfluency us-
ing automatic means. To avoid this, we can change
the scheme how the clean string is chosen as fol-
lows:
</bodyText>
<equation confidence="0.963155">
eˆ = arg max(p(e|fc) · p(fc|f)) (5)
e,fc
</equation>
<bodyText confidence="0.9994228">
This way a clean string which maximizes the
translation quality is chosen. Thus, no instant de-
cision is made whether a token is a disfluency or
not. Instead, the disfluency probability of the to-
ken will be passed on to the MT process, using
the log linear combination of the probabilities as
shown in Equation 5.
In this work, we use a CRF (Lafferty et al.,
2001) model to obtain the disfluency probability
of each token.
</bodyText>
<subsectionHeader confidence="0.966042">
3.2 CRF Model Training
</subsectionHeader>
<bodyText confidence="0.999980761904762">
In order to build the CRF model, we used the
open source toolkit CRF++ (Kudoh, 2007). As
unigram features, we use lexical and LM features
adopted from Fitzgerald et al. (2009), and addi-
tional semantics-based features discussed in (Cho
et al., 2013). In addition to the unigram features,
we also use a bigram feature to model first-order
dependencies between labels.
We train the CRF with four classes; FL for filler
words, RC for (rough) copy, NC for non-copy and
0 for clean tokens. The class FL includes obvious
filler words (e.g. uh, uhm) as well as other dis-
course markers (e.g. you know, well in English).
The RC class covers identical or roughly simi-
lar repetitions as well as lexically different words
with the same meaning. The NC class represents
the case where the speaker changes what to speak
about or reformulates the sentence and restarts the
speech fragments. The disfluency probability Pd
of each token is calculated as the sum of probabil-
ities of each class.
</bodyText>
<subsectionHeader confidence="0.998262">
3.3 Lattice Implementation
</subsectionHeader>
<bodyText confidence="0.999886714285714">
We construct a word lattice which encodes long-
range reordering variants (Rottmann and Vogel,
2007; Niehues and Kolss, 2009). For translation
we extend this so that potentially disfluent words
can be skipped. A reordering lattice of the ex-
ample sentence Das sind die Vorteile, die sie uh
die sie haben. (En.gls: These are the advantages,
that you uh that you have.) is shown in Figure 1,
where words representing a disfluency are marked
in bold letters. In this sentence, the part die sie
uh was manually annotated as a disfluency, due to
repetition and usage of a filler word.
Table 1 shows the Pd obtained from the CRF
model for each token. As expected, the words die
sie uh obtain a high Pd from the CRF model.
In order to provide an option to avoid translating
a disfluent word, a new edge which skips the word
is introduced into the lattice when the word has a
higher Pd than a threshold θ. During decoding the
importance of this newly introduced edge is opti-
mized by weights based on the disfluency proba-
</bodyText>
<page confidence="0.993056">
44
</page>
<figure confidence="0.996771246376812">
die
uh
sie
sie
haben
20
30
26
23
das
die
Vorteile
die
sind
16
.
sie
haben
sie
uh
32
31
29
die
22
haben
sie
25
1
4
7
die
19
die
Vorteile
sind
das
10
,
13
,
sie
17
14
11
2
sie
28
8
5
0
die
die
uh
sie
die
Vorteile
sind
das
,
3
27
24
21
18
15
12
9
6
</figure>
<figureCaption confidence="0.991391">
Figure 1: Reordering lattice before adding alternative clean paths for an exemplary sentence
</figureCaption>
<figure confidence="0.997234567567567">
die
sie
uh 25
die
die
haben
haben
19
22
28
die
sie
1
sind
4
die
7
Vorteile
10
,
13
die 16
sie
uh 23
die
die
0
das
das
sie
2
sie
3
die
20
das
5
sind
8
die
11
Vorteile
14
,
17
die
die
26
haben
sie
29
sie
haben
31
.
32
das
6
sind
9
die
12
Vorteile
15
,
18
die
die die 30
21
sie
24
uh 27
die
die
</figure>
<figureCaption confidence="0.999574">
Figure 2: Extended lattice with alternative clean paths for an exemplary sentence
</figureCaption>
<table confidence="0.810641333333333">
das 0.000732 sie 0.953126
sind 0.004445 uh 0.999579
die 0.013451 die 0.029010
Vorteile 0.008183 sie 0.001426
, 0.035408 haben 0.000108
die 0.651642 . 0.000033
</table>
<tableCaption confidence="0.99476">
Table 1: Disfluency probability of each word
</tableCaption>
<bodyText confidence="0.9991694">
bility and transition probability. The extended lat-
tice for the given sentence with 0 = 0.5 is shown
in Figure 2, with alternative paths marked by a
dotted line. The optimal value of 0 was manually
tuned on the development set.
</bodyText>
<sectionHeader confidence="0.994913" genericHeader="method">
4 System Description
</sectionHeader>
<bodyText confidence="0.998861">
The training data for our MT system consists of
1.76 million sentences of German-English paral-
lel data. Parallel TED talks1 are used as in-domain
data and our translation models are adapted to the
domain. Before training, we apply preprocess-
ing such as text normalization, tokenization, and
smartcasing. Additionally, German compound
words are split.
To build the phrase table we use the Moses
package (Koehn et al., 2007). An LM is trained
on 462 million words in English using the SRILM
Toolkit (Stolcke, 2002). In order to extend source
word context, we use a bilingual LM (Niehues et
al., 2011). We use an in-house decoder (Vogel,
2003) with minimum error rate training (Venu-
gopal et al., 2005) for optimization.
</bodyText>
<footnote confidence="0.768827666666667">
For training and testing the CRF model, we use
61k annotated words of manual transcripts of uni-
1http://www.ted.com
</footnote>
<bodyText confidence="0.998915125">
versity lectures in German. For tuning and testing
the MT system, the same data is used along with
its English reference translation. In order to make
the best use of the data, we split it into three parts
and perform three-fold cross validation. There-
fore, the train/development data consists of around
40k words, or 2k sentences, while the test data
consists of around 20k words, or 1k sentences.
</bodyText>
<sectionHeader confidence="0.999357" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9999915">
In order to compare the effect of the tight inte-
gration with other disfluency removal strategies,
we conduct different experiments on manual tran-
scripts as well as on the ASR output.
</bodyText>
<subsectionHeader confidence="0.998109">
5.1 Manual Transcripts
</subsectionHeader>
<bodyText confidence="0.999912052631579">
As a baseline for manual transcripts, we use
the whole uncleaned data for development and
test. For “No uh”, we remove the obvious filler
words uh and uhm manually. In the CRF-hard
experiment, the token is removed if the label
output of the CRF model is a disfluency class.
The fourth experiment uses the tight integration
scheme, where new source paths which jump over
the potentially noisy words are inserted based on
the disfluency probabilities assigned by the CRF
model. In the next experiments, this method is
combined with other aforementioned approaches.
First, we apply the tight integration scheme after
we remove all obvious filler words. In the next
experiment, we first remove all words whose Pd
is higher than 0.9 as early pruning and then apply
the tight integration scheme. In a final experiment,
we conduct an oracle experiment, where all words
annotated as a disfluency are removed.
</bodyText>
<page confidence="0.998075">
45
</page>
<subsectionHeader confidence="0.994636">
5.2 ASR Output
</subsectionHeader>
<bodyText confidence="0.999901866666667">
The same experiments are applied to the ASR out-
put. Since the ASR output does not contain re-
liable punctuation marks, there is a mismatch be-
tween the training data of the CRF model, which is
manual transcripts with all punctuation marks, and
the test data. Thus, we insert punctuation marks
and augment sentence boundaries in the ASR out-
put using the monolingual translation system (Cho
et al., 2012). As the sentence boundaries differ
from the reference translation, we use the Leven-
shtein minimum edit distance algorithm (Matusov
et al., 2005) to align hypothesis for evaluation.
No optimization is conducted, but the scaling fac-
tors obtained when using the correponding setup
of manual transcripts are used for testing.
</bodyText>
<sectionHeader confidence="0.608256" genericHeader="evaluation">
5.3 Results
</sectionHeader>
<tableCaption confidence="0.798188333333333">
Table 2 shows the results of our experiments. The
scores are reported in case-sensitive BLEU (Pap-
ineni et al., 2002).
</tableCaption>
<table confidence="0.999690875">
System Dev Text ASR
Baseline 23.45 22.70 14.50
No uh 25.09 24.04 15.10
CRF-hard 25.32 24.50 15.15
Tight int. 25.30 24.59 15.19
No uh + Tight int. 25.41 24.68 15.33
Pruning + Tight int. 25.38 24.84 15.51
Oracle 25.57 24.87 -
</table>
<tableCaption confidence="0.8555105">
Table 2: Translation results for the investigated
disfluency removal strategies
</tableCaption>
<bodyText confidence="0.999581125">
Compared to the baseline where all disfluen-
cies are kept, the translation quality is improved
by 1.34 BLEU points for manual transcripts by
simply removing all obvious filler words. When
we take the output of the CRF as a hard deci-
sion, the performance is further improved by 0.46
BLEU points. When using the tight integration
scheme, we improve the translation quality around
0.1 BLEU points compared to the CRF-hard deci-
sion. The performance is further improved by re-
moving uh and uhm before applying the tight inte-
gration scheme. Finally the best score is achieved
by using the early pruning coupled with the tight
integration scheme. The translation score is 0.34
BLEU points higher than the CRF-hard decision.
This score is only 0.03 BLEU points less than the
oracle case, without all disfluencies.
Experiments on the ASR output also showed a
considerable improvement despite word errors and
consequently decreased accuracy of the CRF de-
tection. Compared to using only the CRF-hard de-
cision, using the coupled approach improved the
performance by 0.36 BLEU points, which is 1.0
BLEU point higher than the baseline.
</bodyText>
<table confidence="0.997433333333333">
System Precision Recall
CRF-hard 0.898 0.544
Pruning + Tight int. 0.937 0.521
</table>
<tableCaption confidence="0.999839">
Table 3: Detection performance comparison
</tableCaption>
<bodyText confidence="0.997011133333333">
Table 3 shows a comparison of the disfluency
detection performance on word tokens. While re-
call is slightly worse for the coupled approach,
precision is improved by 4% over the hard deci-
sion, indicating that the tight integration scheme
decides more accurately. Since deletions made by
a hard decision can not be recovered and losing a
meaningful word on the source side can be very
critical, we believe that precision is more impor-
tant for this task. Consequently we retain more
words on the source side with the tight integration
scheme, but the numbers of word tokens on the
translated target side are similar. The translation
model is able to leave out unnecessary words dur-
ing translation.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999980285714286">
We presented a novel scheme to integrate disflu-
ency removal into the MT process. Using this
scheme, it is possible to consider disfluency prob-
abilities during decoding and therefore to choose
words which can lead to better translation perfor-
mance. The disfluency probability of each token
is obtained from a CRF model, and is encoded in
the word lattice. Additional edges are added in the
word lattice, to bypass the words potentially rep-
resenting speech disfluencies.
We achieve the best performance using the tight
integration method coupled with early pruning.
This method yields an improvement of 2.1 BLEU
points for manual transcripts and 1.0 BLEU point
improvement over the baseline for ASR output.
Although the translation of ASR output is im-
proved using the suggested scheme, there is still
room to improve. In future work, we would like to
improve performance of disfluency detection for
ASR output by including acoustic features in the
model.
</bodyText>
<page confidence="0.999154">
46
</page>
<sectionHeader confidence="0.996543" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9998565">
The research leading to these results has received
funding from the European Union Seventh Frame-
work Programme (FP7/2007-2013) under grant
agreement n◦ 287658.
</bodyText>
<sectionHeader confidence="0.998474" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999748427083333">
Eunah Cho, Jan Niehues, and Alex Waibel. 2012.
Segmentation and Punctuation Prediction in Speech
Language Translation using a Monolingual Trans-
lation System. In Proceedings of the Interna-
tional Workshop for Spoken Language Translation
(IWSLT), Hong Kong, China.
Eunah Cho, Thanh-Le Ha, and Alex Waibel. 2013.
CRF-based Disfluency Detection using Seman-
tic Features for German to English Spoken Lan-
guage Translation. In Proceedings of the Interna-
tional Workshop for Spoken Language Translation
(IWSLT), Heidelberg, Germany.
Chris Dyer. 2009. Using a Maximum Entropy Model
to Build Segmentation Lattices for MT. In Proceed-
ings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics, Boulder, Colorado, USA, June. Association for
Computational Linguistics.
Erin Fitzgerald, Kieth Hall, and Frederick Jelinek.
2009. Reconstructing False Start Errors in Sponta-
neous Speech Text. In Proceedings of the European
Association for Computational Linguistics (EACL),
Athens, Greece.
Teresa Herrmann, Jan Niehues, and Alex Waibel.
2013. Combining Word Reordering Methods on
different Linguistic Abstraction Levels for Statisti-
cal Machine Translation. In Proceedings of the Sev-
enth Workshop on Syntax, Semantics and Structure
in Statistical Translation, Altanta, Georgia, USA,
June. Association for Computational Linguistics.
Matthias Honal and Tanja Schultz. 2003. Correction of
Disfluencies in Spontaneous Speech using a Noisy-
Channel Approach. In Eurospeech, Geneva.
Mark Johnson and Eugene Charniak. 2004. A TAG-
based Noisy Channel Model of Speech Repairs. In
Proceedings of the Association for Computational
Linguistics (ACL).
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the Association for Computational
Linguistics (ACL), Demonstration Session, Prague,
Czech Republic, June.
Taku Kudoh. 2007. CRF++: Yet Another CRF
Toolkit.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional Random Fields: Prob-
abilitic Models for Segmenting and Labeling Se-
quence Data. In ICML, Massachusetts, USA.
Sameer Maskey, Bowen Zhou, and Yuqing Gao. 2006.
A Phrase-Level Machine Translation Approach for
Disfluency Detection using Weighted Finite State
Tranducers. In Interspeech, Pittsburgh, PA.
Evgeny Matusov, Gregor Leusch, Oliver Bender, and
Herrmann Ney. 2005. Evaluating Machine Trans-
lation Output with Automatic Sentence Segmenta-
tion. In Proceedings of the International Workshop
on Spoken Language Translation (IWSLT), Boulder,
Colorado, USA, October.
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Proceedings of the 4th Workshop on Statistical Ma-
chine Translation, Athens, Greece.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Proceedings of the 6th Workshop on Statistical Ma-
chine Translation, Edinburgh, UK.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. Technical Re-
port RC22176 (W0109-022), IBM Research Divi-
sion, T. J. Watson Research Center.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In TMI, Sk¨ovde,
Sweden.
Andreas Stolcke. 2002. SRILM – An Extensible Lan-
guage Modeling Toolkit. Denver, Colorado, USA.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In WPT-
05, Ann Arbor, MI.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language
Processing and Knowledge Engineering, Beijing,
China.
Wen Wang, Gokhan Tur, Jing Zheng, and Necip Fazil
Ayan. 2010. Automatic Disfluency Removal for Im-
proving Spoken Language Translation. In Interna-
tional Conference on Acoustics, Speech, and Signal
Processing (ICASSP).
</reference>
<page confidence="0.999484">
47
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.965143">
<title confidence="0.99909">Tight Integration of Speech Disfluency Removal into SMT</title>
<author confidence="0.99551">Eunah Cho Jan Niehues Alex Waibel</author>
<affiliation confidence="0.996817333333333">Interactive Systems Institute of Karlsruhe Institute of Technology,</affiliation>
<abstract confidence="0.998041157894737">Speech disfluencies are one of the main challenges of spoken language processing. Conventional disfluency detection systems deploy a hard decision, which can have a negative influence on subsequent applications such as machine translation. In this paper we suggest a novel approach in which disfluency detection is integrated into the translation process. We train a CRF model to obtain a disfluency probability for each word. The SMT decoder will then skip the potentially disfluent word based on its disfluency probability. Using the suggested scheme, the translation score of both the manual transcript and ASR output is improved by around 0.35 BLEU points compared to the CRF hard decision system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eunah Cho</author>
<author>Jan Niehues</author>
<author>Alex Waibel</author>
</authors>
<title>Segmentation and Punctuation Prediction in Speech Language Translation using a Monolingual Translation System.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Workshop for Spoken Language Translation (IWSLT),</booktitle>
<location>Hong Kong, China.</location>
<contexts>
<context position="11761" citStr="Cho et al., 2012" startWordPosition="2027" endWordPosition="2030">ose Pd is higher than 0.9 as early pruning and then apply the tight integration scheme. In a final experiment, we conduct an oracle experiment, where all words annotated as a disfluency are removed. 45 5.2 ASR Output The same experiments are applied to the ASR output. Since the ASR output does not contain reliable punctuation marks, there is a mismatch between the training data of the CRF model, which is manual transcripts with all punctuation marks, and the test data. Thus, we insert punctuation marks and augment sentence boundaries in the ASR output using the monolingual translation system (Cho et al., 2012). As the sentence boundaries differ from the reference translation, we use the Levenshtein minimum edit distance algorithm (Matusov et al., 2005) to align hypothesis for evaluation. No optimization is conducted, but the scaling factors obtained when using the correponding setup of manual transcripts are used for testing. 5.3 Results Table 2 shows the results of our experiments. The scores are reported in case-sensitive BLEU (Papineni et al., 2002). System Dev Text ASR Baseline 23.45 22.70 14.50 No uh 25.09 24.04 15.10 CRF-hard 25.32 24.50 15.15 Tight int. 25.30 24.59 15.19 No uh + Tight int. 2</context>
</contexts>
<marker>Cho, Niehues, Waibel, 2012</marker>
<rawString>Eunah Cho, Jan Niehues, and Alex Waibel. 2012. Segmentation and Punctuation Prediction in Speech Language Translation using a Monolingual Translation System. In Proceedings of the International Workshop for Spoken Language Translation (IWSLT), Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eunah Cho</author>
<author>Thanh-Le Ha</author>
<author>Alex Waibel</author>
</authors>
<title>CRF-based Disfluency Detection using Semantic Features for German to English Spoken Language Translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop for Spoken Language Translation (IWSLT),</booktitle>
<location>Heidelberg, Germany.</location>
<marker>Cho, Thanh-Le Ha, Waibel, 2013</marker>
<rawString>Eunah Cho, Thanh-Le Ha, and Alex Waibel. 2013. CRF-based Disfluency Detection using Semantic Features for German to English Spoken Language Translation. In Proceedings of the International Workshop for Spoken Language Translation (IWSLT), Heidelberg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
</authors>
<title>Using a Maximum Entropy Model to Build Segmentation Lattices for MT.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado, USA,</location>
<contexts>
<context position="3252" citStr="Dyer, 2009" startWordPosition="527" endWordPosition="528">cal, LM, and parser information features. While previous work has been limited to the postprocessing step of the automatic speech recogition (ASR) system, further approaches (Wang et al., 2010; Cho et al., 2013) use extended CRF features or additional models to clean manual speech transcripts and use them as input for an MT system. While ASR systems use lattices to encode hypotheses, lattices have been used for MT systems with various purposes. Herrmann et al. (2013) use lattices to encode different reordering variants. Lattices have also been used as a segmentation tactic for compound words (Dyer, 2009), where the segmentation is encoded as input in the lattice. One of the differences between our work and previous work is that we integrate the disfluency removal into an MT system. Our work is not limited to the preprocessing step of MT, instead we use the translation model to detect and remove disfluencies. Contrary to other systems where detection is limited on manual transcripts only, our sys43 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 43–47, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational L</context>
</contexts>
<marker>Dyer, 2009</marker>
<rawString>Chris Dyer. 2009. Using a Maximum Entropy Model to Build Segmentation Lattices for MT. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Boulder, Colorado, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erin Fitzgerald</author>
<author>Kieth Hall</author>
<author>Frederick Jelinek</author>
</authors>
<title>Reconstructing False Start Errors in Spontaneous Speech Text.</title>
<date>2009</date>
<booktitle>In Proceedings of the European Association for Computational Linguistics (EACL),</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="1145" citStr="Fitzgerald et al., 2009" startWordPosition="169" endWordPosition="172">n which disfluency detection is integrated into the translation process. We train a CRF model to obtain a disfluency probability for each word. The SMT decoder will then skip the potentially disfluent word based on its disfluency probability. Using the suggested scheme, the translation score of both the manual transcript and ASR output is improved by around 0.35 BLEU points compared to the CRF hard decision system. 1 Introduction Disfluencies arise due to the spontaneous nature of speech. There has been a great deal of effort to detect disfluent words, remove them (Johnson and Charniak, 2004; Fitzgerald et al., 2009) and use the cleaned text for subsequent applications such as machine translation (MT) (Wang et al., 2010; Cho et al., 2013). One potential drawback of conventional approaches is that the decision whether a token is a disfluency or not is a hard decision. For an MT system, this can pose a severe problem if the removed token was not in fact a disfluency and should have been kept for the correct translation. Therefore, we pass the decision whether a word is part of a disfluency or not on to the translation system, so that we can use the additional knowledge available in the translation system to</context>
<context position="2545" citStr="Fitzgerald et al. (2009)" startWordPosition="409" endWordPosition="412"> spontaneous speech have been studied from various points of view. In the noisy channel model (Honal and Schultz, 2003), it is assumed that clean text without any disfluencies has passed through a noisy channel. The clean string is retrieved based on language model (LM) scores and five additional models. Another noisy channel approach involves a phrase-level statistical MT system, where noisy tokens are translated into clean tokens (Maskey et al., 2006). A tree adjoining grammar is combined with this noisy channel model in (Johnson and Charniak, 2004), using a syntactic parser to build an LM. Fitzgerald et al. (2009) present a method to detect speech disfluencies using a conditional random field (CRF) with lexical, LM, and parser information features. While previous work has been limited to the postprocessing step of the automatic speech recogition (ASR) system, further approaches (Wang et al., 2010; Cho et al., 2013) use extended CRF features or additional models to clean manual speech transcripts and use them as input for an MT system. While ASR systems use lattices to encode hypotheses, lattices have been used for MT systems with various purposes. Herrmann et al. (2013) use lattices to encode different</context>
<context position="5985" citStr="Fitzgerald et al. (2009)" startWordPosition="995" endWordPosition="998">,fc This way a clean string which maximizes the translation quality is chosen. Thus, no instant decision is made whether a token is a disfluency or not. Instead, the disfluency probability of the token will be passed on to the MT process, using the log linear combination of the probabilities as shown in Equation 5. In this work, we use a CRF (Lafferty et al., 2001) model to obtain the disfluency probability of each token. 3.2 CRF Model Training In order to build the CRF model, we used the open source toolkit CRF++ (Kudoh, 2007). As unigram features, we use lexical and LM features adopted from Fitzgerald et al. (2009), and additional semantics-based features discussed in (Cho et al., 2013). In addition to the unigram features, we also use a bigram feature to model first-order dependencies between labels. We train the CRF with four classes; FL for filler words, RC for (rough) copy, NC for non-copy and 0 for clean tokens. The class FL includes obvious filler words (e.g. uh, uhm) as well as other discourse markers (e.g. you know, well in English). The RC class covers identical or roughly similar repetitions as well as lexically different words with the same meaning. The NC class represents the case where the </context>
</contexts>
<marker>Fitzgerald, Hall, Jelinek, 2009</marker>
<rawString>Erin Fitzgerald, Kieth Hall, and Frederick Jelinek. 2009. Reconstructing False Start Errors in Spontaneous Speech Text. In Proceedings of the European Association for Computational Linguistics (EACL), Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Teresa Herrmann</author>
<author>Jan Niehues</author>
<author>Alex Waibel</author>
</authors>
<title>Combining Word Reordering Methods on different Linguistic Abstraction Levels for Statistical Machine Translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Seventh Workshop on Syntax, Semantics and Structure in Statistical Translation,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Altanta, Georgia, USA,</location>
<contexts>
<context position="3112" citStr="Herrmann et al. (2013)" startWordPosition="503" endWordPosition="506">ntactic parser to build an LM. Fitzgerald et al. (2009) present a method to detect speech disfluencies using a conditional random field (CRF) with lexical, LM, and parser information features. While previous work has been limited to the postprocessing step of the automatic speech recogition (ASR) system, further approaches (Wang et al., 2010; Cho et al., 2013) use extended CRF features or additional models to clean manual speech transcripts and use them as input for an MT system. While ASR systems use lattices to encode hypotheses, lattices have been used for MT systems with various purposes. Herrmann et al. (2013) use lattices to encode different reordering variants. Lattices have also been used as a segmentation tactic for compound words (Dyer, 2009), where the segmentation is encoded as input in the lattice. One of the differences between our work and previous work is that we integrate the disfluency removal into an MT system. Our work is not limited to the preprocessing step of MT, instead we use the translation model to detect and remove disfluencies. Contrary to other systems where detection is limited on manual transcripts only, our sys43 Proceedings of the 14th Conference of the European Chapter</context>
</contexts>
<marker>Herrmann, Niehues, Waibel, 2013</marker>
<rawString>Teresa Herrmann, Jan Niehues, and Alex Waibel. 2013. Combining Word Reordering Methods on different Linguistic Abstraction Levels for Statistical Machine Translation. In Proceedings of the Seventh Workshop on Syntax, Semantics and Structure in Statistical Translation, Altanta, Georgia, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Honal</author>
<author>Tanja Schultz</author>
</authors>
<title>Correction of Disfluencies in Spontaneous Speech using a NoisyChannel Approach. In</title>
<date>2003</date>
<booktitle>Eurospeech,</booktitle>
<location>Geneva.</location>
<contexts>
<context position="2040" citStr="Honal and Schultz, 2003" startWordPosition="326" endWordPosition="329">m, this can pose a severe problem if the removed token was not in fact a disfluency and should have been kept for the correct translation. Therefore, we pass the decision whether a word is part of a disfluency or not on to the translation system, so that we can use the additional knowledge available in the translation system to make a more reliable decision. In order to limit the complexity, the search space is pruned prior to decoding and represented in a word lattice. 2 Related Work Disfluencies in spontaneous speech have been studied from various points of view. In the noisy channel model (Honal and Schultz, 2003), it is assumed that clean text without any disfluencies has passed through a noisy channel. The clean string is retrieved based on language model (LM) scores and five additional models. Another noisy channel approach involves a phrase-level statistical MT system, where noisy tokens are translated into clean tokens (Maskey et al., 2006). A tree adjoining grammar is combined with this noisy channel model in (Johnson and Charniak, 2004), using a syntactic parser to build an LM. Fitzgerald et al. (2009) present a method to detect speech disfluencies using a conditional random field (CRF) with lex</context>
</contexts>
<marker>Honal, Schultz, 2003</marker>
<rawString>Matthias Honal and Tanja Schultz. 2003. Correction of Disfluencies in Spontaneous Speech using a NoisyChannel Approach. In Eurospeech, Geneva.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Eugene Charniak</author>
</authors>
<title>A TAGbased Noisy Channel Model of Speech Repairs.</title>
<date>2004</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="1119" citStr="Johnson and Charniak, 2004" startWordPosition="165" endWordPosition="168">e suggest a novel approach in which disfluency detection is integrated into the translation process. We train a CRF model to obtain a disfluency probability for each word. The SMT decoder will then skip the potentially disfluent word based on its disfluency probability. Using the suggested scheme, the translation score of both the manual transcript and ASR output is improved by around 0.35 BLEU points compared to the CRF hard decision system. 1 Introduction Disfluencies arise due to the spontaneous nature of speech. There has been a great deal of effort to detect disfluent words, remove them (Johnson and Charniak, 2004; Fitzgerald et al., 2009) and use the cleaned text for subsequent applications such as machine translation (MT) (Wang et al., 2010; Cho et al., 2013). One potential drawback of conventional approaches is that the decision whether a token is a disfluency or not is a hard decision. For an MT system, this can pose a severe problem if the removed token was not in fact a disfluency and should have been kept for the correct translation. Therefore, we pass the decision whether a word is part of a disfluency or not on to the translation system, so that we can use the additional knowledge available in</context>
<context position="2478" citStr="Johnson and Charniak, 2004" startWordPosition="397" endWordPosition="400">ding and represented in a word lattice. 2 Related Work Disfluencies in spontaneous speech have been studied from various points of view. In the noisy channel model (Honal and Schultz, 2003), it is assumed that clean text without any disfluencies has passed through a noisy channel. The clean string is retrieved based on language model (LM) scores and five additional models. Another noisy channel approach involves a phrase-level statistical MT system, where noisy tokens are translated into clean tokens (Maskey et al., 2006). A tree adjoining grammar is combined with this noisy channel model in (Johnson and Charniak, 2004), using a syntactic parser to build an LM. Fitzgerald et al. (2009) present a method to detect speech disfluencies using a conditional random field (CRF) with lexical, LM, and parser information features. While previous work has been limited to the postprocessing step of the automatic speech recogition (ASR) system, further approaches (Wang et al., 2010; Cho et al., 2013) use extended CRF features or additional models to clean manual speech transcripts and use them as input for an MT system. While ASR systems use lattices to encode hypotheses, lattices have been used for MT systems with variou</context>
</contexts>
<marker>Johnson, Charniak, 2004</marker>
<rawString>Mark Johnson and Eugene Charniak. 2004. A TAGbased Noisy Channel Model of Speech Repairs. In Proceedings of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL), Demonstration Session,</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="9413" citStr="Koehn et al., 2007" startWordPosition="1632" endWordPosition="1635">ice for the given sentence with 0 = 0.5 is shown in Figure 2, with alternative paths marked by a dotted line. The optimal value of 0 was manually tuned on the development set. 4 System Description The training data for our MT system consists of 1.76 million sentences of German-English parallel data. Parallel TED talks1 are used as in-domain data and our translation models are adapted to the domain. Before training, we apply preprocessing such as text normalization, tokenization, and smartcasing. Additionally, German compound words are split. To build the phrase table we use the Moses package (Koehn et al., 2007). An LM is trained on 462 million words in English using the SRILM Toolkit (Stolcke, 2002). In order to extend source word context, we use a bilingual LM (Niehues et al., 2011). We use an in-house decoder (Vogel, 2003) with minimum error rate training (Venugopal et al., 2005) for optimization. For training and testing the CRF model, we use 61k annotated words of manual transcripts of uni1http://www.ted.com versity lectures in German. For tuning and testing the MT system, the same data is used along with its English reference translation. In order to make the best use of the data, we split it i</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the Association for Computational Linguistics (ACL), Demonstration Session, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudoh</author>
</authors>
<date>2007</date>
<journal>CRF++: Yet Another CRF Toolkit.</journal>
<contexts>
<context position="5894" citStr="Kudoh, 2007" startWordPosition="982" endWordPosition="983">ow the clean string is chosen as follows: eˆ = arg max(p(e|fc) · p(fc|f)) (5) e,fc This way a clean string which maximizes the translation quality is chosen. Thus, no instant decision is made whether a token is a disfluency or not. Instead, the disfluency probability of the token will be passed on to the MT process, using the log linear combination of the probabilities as shown in Equation 5. In this work, we use a CRF (Lafferty et al., 2001) model to obtain the disfluency probability of each token. 3.2 CRF Model Training In order to build the CRF model, we used the open source toolkit CRF++ (Kudoh, 2007). As unigram features, we use lexical and LM features adopted from Fitzgerald et al. (2009), and additional semantics-based features discussed in (Cho et al., 2013). In addition to the unigram features, we also use a bigram feature to model first-order dependencies between labels. We train the CRF with four classes; FL for filler words, RC for (rough) copy, NC for non-copy and 0 for clean tokens. The class FL includes obvious filler words (e.g. uh, uhm) as well as other discourse markers (e.g. you know, well in English). The RC class covers identical or roughly similar repetitions as well as l</context>
</contexts>
<marker>Kudoh, 2007</marker>
<rawString>Taku Kudoh. 2007. CRF++: Yet Another CRF Toolkit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilitic Models for Segmenting and Labeling Sequence Data. In ICML,</title>
<date>2001</date>
<location>Massachusetts, USA.</location>
<contexts>
<context position="5728" citStr="Lafferty et al., 2001" startWordPosition="951" endWordPosition="954">u use. Due to its repetitive pattern in words and structure, the first clause is often detected as a disfluency using automatic means. To avoid this, we can change the scheme how the clean string is chosen as follows: eˆ = arg max(p(e|fc) · p(fc|f)) (5) e,fc This way a clean string which maximizes the translation quality is chosen. Thus, no instant decision is made whether a token is a disfluency or not. Instead, the disfluency probability of the token will be passed on to the MT process, using the log linear combination of the probabilities as shown in Equation 5. In this work, we use a CRF (Lafferty et al., 2001) model to obtain the disfluency probability of each token. 3.2 CRF Model Training In order to build the CRF model, we used the open source toolkit CRF++ (Kudoh, 2007). As unigram features, we use lexical and LM features adopted from Fitzgerald et al. (2009), and additional semantics-based features discussed in (Cho et al., 2013). In addition to the unigram features, we also use a bigram feature to model first-order dependencies between labels. We train the CRF with four classes; FL for filler words, RC for (rough) copy, NC for non-copy and 0 for clean tokens. The class FL includes obvious fill</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional Random Fields: Probabilitic Models for Segmenting and Labeling Sequence Data. In ICML, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Maskey</author>
<author>Bowen Zhou</author>
<author>Yuqing Gao</author>
</authors>
<title>A Phrase-Level Machine Translation Approach for Disfluency Detection using Weighted Finite State Tranducers. In Interspeech,</title>
<date>2006</date>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="2378" citStr="Maskey et al., 2006" startWordPosition="379" endWordPosition="382">reliable decision. In order to limit the complexity, the search space is pruned prior to decoding and represented in a word lattice. 2 Related Work Disfluencies in spontaneous speech have been studied from various points of view. In the noisy channel model (Honal and Schultz, 2003), it is assumed that clean text without any disfluencies has passed through a noisy channel. The clean string is retrieved based on language model (LM) scores and five additional models. Another noisy channel approach involves a phrase-level statistical MT system, where noisy tokens are translated into clean tokens (Maskey et al., 2006). A tree adjoining grammar is combined with this noisy channel model in (Johnson and Charniak, 2004), using a syntactic parser to build an LM. Fitzgerald et al. (2009) present a method to detect speech disfluencies using a conditional random field (CRF) with lexical, LM, and parser information features. While previous work has been limited to the postprocessing step of the automatic speech recogition (ASR) system, further approaches (Wang et al., 2010; Cho et al., 2013) use extended CRF features or additional models to clean manual speech transcripts and use them as input for an MT system. Whi</context>
</contexts>
<marker>Maskey, Zhou, Gao, 2006</marker>
<rawString>Sameer Maskey, Bowen Zhou, and Yuqing Gao. 2006. A Phrase-Level Machine Translation Approach for Disfluency Detection using Weighted Finite State Tranducers. In Interspeech, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeny Matusov</author>
<author>Gregor Leusch</author>
<author>Oliver Bender</author>
<author>Herrmann Ney</author>
</authors>
<title>Evaluating Machine Translation Output with Automatic Sentence Segmentation.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation (IWSLT),</booktitle>
<location>Boulder, Colorado, USA,</location>
<contexts>
<context position="11906" citStr="Matusov et al., 2005" startWordPosition="2049" endWordPosition="2052">t, where all words annotated as a disfluency are removed. 45 5.2 ASR Output The same experiments are applied to the ASR output. Since the ASR output does not contain reliable punctuation marks, there is a mismatch between the training data of the CRF model, which is manual transcripts with all punctuation marks, and the test data. Thus, we insert punctuation marks and augment sentence boundaries in the ASR output using the monolingual translation system (Cho et al., 2012). As the sentence boundaries differ from the reference translation, we use the Levenshtein minimum edit distance algorithm (Matusov et al., 2005) to align hypothesis for evaluation. No optimization is conducted, but the scaling factors obtained when using the correponding setup of manual transcripts are used for testing. 5.3 Results Table 2 shows the results of our experiments. The scores are reported in case-sensitive BLEU (Papineni et al., 2002). System Dev Text ASR Baseline 23.45 22.70 14.50 No uh 25.09 24.04 15.10 CRF-hard 25.32 24.50 15.15 Tight int. 25.30 24.59 15.19 No uh + Tight int. 25.41 24.68 15.33 Pruning + Tight int. 25.38 24.84 15.51 Oracle 25.57 24.87 - Table 2: Translation results for the investigated disfluency removal</context>
</contexts>
<marker>Matusov, Leusch, Bender, Ney, 2005</marker>
<rawString>Evgeny Matusov, Gregor Leusch, Oliver Bender, and Herrmann Ney. 2005. Evaluating Machine Translation Output with Automatic Sentence Segmentation. In Proceedings of the International Workshop on Spoken Language Translation (IWSLT), Boulder, Colorado, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Niehues</author>
<author>Muntsin Kolss</author>
</authors>
<title>A POS-Based Model for Long-Range Reorderings in SMT.</title>
<date>2009</date>
<booktitle>In Proceedings of the 4th Workshop on Statistical Machine Translation,</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="6936" citStr="Niehues and Kolss, 2009" startWordPosition="1153" endWordPosition="1156">des obvious filler words (e.g. uh, uhm) as well as other discourse markers (e.g. you know, well in English). The RC class covers identical or roughly similar repetitions as well as lexically different words with the same meaning. The NC class represents the case where the speaker changes what to speak about or reformulates the sentence and restarts the speech fragments. The disfluency probability Pd of each token is calculated as the sum of probabilities of each class. 3.3 Lattice Implementation We construct a word lattice which encodes longrange reordering variants (Rottmann and Vogel, 2007; Niehues and Kolss, 2009). For translation we extend this so that potentially disfluent words can be skipped. A reordering lattice of the example sentence Das sind die Vorteile, die sie uh die sie haben. (En.gls: These are the advantages, that you uh that you have.) is shown in Figure 1, where words representing a disfluency are marked in bold letters. In this sentence, the part die sie uh was manually annotated as a disfluency, due to repetition and usage of a filler word. Table 1 shows the Pd obtained from the CRF model for each token. As expected, the words die sie uh obtain a high Pd from the CRF model. In order t</context>
</contexts>
<marker>Niehues, Kolss, 2009</marker>
<rawString>Jan Niehues and Muntsin Kolss. 2009. A POS-Based Model for Long-Range Reorderings in SMT. In Proceedings of the 4th Workshop on Statistical Machine Translation, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Niehues</author>
<author>Teresa Herrmann</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Wider Context by Using Bilingual Language Models in Machine Translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 6th Workshop on Statistical Machine Translation,</booktitle>
<location>Edinburgh, UK.</location>
<contexts>
<context position="9589" citStr="Niehues et al., 2011" startWordPosition="1664" endWordPosition="1667">. 4 System Description The training data for our MT system consists of 1.76 million sentences of German-English parallel data. Parallel TED talks1 are used as in-domain data and our translation models are adapted to the domain. Before training, we apply preprocessing such as text normalization, tokenization, and smartcasing. Additionally, German compound words are split. To build the phrase table we use the Moses package (Koehn et al., 2007). An LM is trained on 462 million words in English using the SRILM Toolkit (Stolcke, 2002). In order to extend source word context, we use a bilingual LM (Niehues et al., 2011). We use an in-house decoder (Vogel, 2003) with minimum error rate training (Venugopal et al., 2005) for optimization. For training and testing the CRF model, we use 61k annotated words of manual transcripts of uni1http://www.ted.com versity lectures in German. For tuning and testing the MT system, the same data is used along with its English reference translation. In order to make the best use of the data, we split it into three parts and perform three-fold cross validation. Therefore, the train/development data consists of around 40k words, or 2k sentences, while the test data consists of ar</context>
</contexts>
<marker>Niehues, Herrmann, Vogel, Waibel, 2011</marker>
<rawString>Jan Niehues, Teresa Herrmann, Stephan Vogel, and Alex Waibel. 2011. Wider Context by Using Bilingual Language Models in Machine Translation. In Proceedings of the 6th Workshop on Statistical Machine Translation, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<journal>IBM Research Division, T. J. Watson Research Center.</journal>
<tech>Technical Report RC22176 (W0109-022),</tech>
<contexts>
<context position="12212" citStr="Papineni et al., 2002" startWordPosition="2097" endWordPosition="2101">n marks, and the test data. Thus, we insert punctuation marks and augment sentence boundaries in the ASR output using the monolingual translation system (Cho et al., 2012). As the sentence boundaries differ from the reference translation, we use the Levenshtein minimum edit distance algorithm (Matusov et al., 2005) to align hypothesis for evaluation. No optimization is conducted, but the scaling factors obtained when using the correponding setup of manual transcripts are used for testing. 5.3 Results Table 2 shows the results of our experiments. The scores are reported in case-sensitive BLEU (Papineni et al., 2002). System Dev Text ASR Baseline 23.45 22.70 14.50 No uh 25.09 24.04 15.10 CRF-hard 25.32 24.50 15.15 Tight int. 25.30 24.59 15.19 No uh + Tight int. 25.41 24.68 15.33 Pruning + Tight int. 25.38 24.84 15.51 Oracle 25.57 24.87 - Table 2: Translation results for the investigated disfluency removal strategies Compared to the baseline where all disfluencies are kept, the translation quality is improved by 1.34 BLEU points for manual transcripts by simply removing all obvious filler words. When we take the output of the CRF as a hard decision, the performance is further improved by 0.46 BLEU points. </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a Method for Automatic Evaluation of Machine Translation. Technical Report RC22176 (W0109-022), IBM Research Division, T. J. Watson Research Center.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kay Rottmann</author>
<author>Stephan Vogel</author>
</authors>
<title>Word Reordering in Statistical Machine Translation with a POS-Based Distortion Model.</title>
<date>2007</date>
<booktitle>In TMI, Sk¨ovde,</booktitle>
<contexts>
<context position="6910" citStr="Rottmann and Vogel, 2007" startWordPosition="1149" endWordPosition="1152">tokens. The class FL includes obvious filler words (e.g. uh, uhm) as well as other discourse markers (e.g. you know, well in English). The RC class covers identical or roughly similar repetitions as well as lexically different words with the same meaning. The NC class represents the case where the speaker changes what to speak about or reformulates the sentence and restarts the speech fragments. The disfluency probability Pd of each token is calculated as the sum of probabilities of each class. 3.3 Lattice Implementation We construct a word lattice which encodes longrange reordering variants (Rottmann and Vogel, 2007; Niehues and Kolss, 2009). For translation we extend this so that potentially disfluent words can be skipped. A reordering lattice of the example sentence Das sind die Vorteile, die sie uh die sie haben. (En.gls: These are the advantages, that you uh that you have.) is shown in Figure 1, where words representing a disfluency are marked in bold letters. In this sentence, the part die sie uh was manually annotated as a disfluency, due to repetition and usage of a filler word. Table 1 shows the Pd obtained from the CRF model for each token. As expected, the words die sie uh obtain a high Pd from</context>
</contexts>
<marker>Rottmann, Vogel, 2007</marker>
<rawString>Kay Rottmann and Stephan Vogel. 2007. Word Reordering in Statistical Machine Translation with a POS-Based Distortion Model. In TMI, Sk¨ovde, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM – An Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<location>Denver, Colorado, USA.</location>
<contexts>
<context position="9503" citStr="Stolcke, 2002" startWordPosition="1650" endWordPosition="1651">a dotted line. The optimal value of 0 was manually tuned on the development set. 4 System Description The training data for our MT system consists of 1.76 million sentences of German-English parallel data. Parallel TED talks1 are used as in-domain data and our translation models are adapted to the domain. Before training, we apply preprocessing such as text normalization, tokenization, and smartcasing. Additionally, German compound words are split. To build the phrase table we use the Moses package (Koehn et al., 2007). An LM is trained on 462 million words in English using the SRILM Toolkit (Stolcke, 2002). In order to extend source word context, we use a bilingual LM (Niehues et al., 2011). We use an in-house decoder (Vogel, 2003) with minimum error rate training (Venugopal et al., 2005) for optimization. For training and testing the CRF model, we use 61k annotated words of manual transcripts of uni1http://www.ted.com versity lectures in German. For tuning and testing the MT system, the same data is used along with its English reference translation. In order to make the best use of the data, we split it into three parts and perform three-fold cross validation. Therefore, the train/development </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM – An Extensible Language Modeling Toolkit. Denver, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Venugopal</author>
<author>Andreas Zollman</author>
<author>Alex Waibel</author>
</authors>
<title>Training and Evaluation Error Minimization Rules for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In WPT05,</booktitle>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="9689" citStr="Venugopal et al., 2005" startWordPosition="1680" endWordPosition="1684">erman-English parallel data. Parallel TED talks1 are used as in-domain data and our translation models are adapted to the domain. Before training, we apply preprocessing such as text normalization, tokenization, and smartcasing. Additionally, German compound words are split. To build the phrase table we use the Moses package (Koehn et al., 2007). An LM is trained on 462 million words in English using the SRILM Toolkit (Stolcke, 2002). In order to extend source word context, we use a bilingual LM (Niehues et al., 2011). We use an in-house decoder (Vogel, 2003) with minimum error rate training (Venugopal et al., 2005) for optimization. For training and testing the CRF model, we use 61k annotated words of manual transcripts of uni1http://www.ted.com versity lectures in German. For tuning and testing the MT system, the same data is used along with its English reference translation. In order to make the best use of the data, we split it into three parts and perform three-fold cross validation. Therefore, the train/development data consists of around 40k words, or 2k sentences, while the test data consists of around 20k words, or 1k sentences. 5 Experiments In order to compare the effect of the tight integrati</context>
</contexts>
<marker>Venugopal, Zollman, Waibel, 2005</marker>
<rawString>Ashish Venugopal, Andreas Zollman, and Alex Waibel. 2005. Training and Evaluation Error Minimization Rules for Statistical Machine Translation. In WPT05, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
</authors>
<title>SMT Decoder Dissected: Word Reordering.</title>
<date>2003</date>
<booktitle>In Int. Conf. on Natural Language Processing and Knowledge Engineering,</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="9631" citStr="Vogel, 2003" startWordPosition="1673" endWordPosition="1674"> system consists of 1.76 million sentences of German-English parallel data. Parallel TED talks1 are used as in-domain data and our translation models are adapted to the domain. Before training, we apply preprocessing such as text normalization, tokenization, and smartcasing. Additionally, German compound words are split. To build the phrase table we use the Moses package (Koehn et al., 2007). An LM is trained on 462 million words in English using the SRILM Toolkit (Stolcke, 2002). In order to extend source word context, we use a bilingual LM (Niehues et al., 2011). We use an in-house decoder (Vogel, 2003) with minimum error rate training (Venugopal et al., 2005) for optimization. For training and testing the CRF model, we use 61k annotated words of manual transcripts of uni1http://www.ted.com versity lectures in German. For tuning and testing the MT system, the same data is used along with its English reference translation. In order to make the best use of the data, we split it into three parts and perform three-fold cross validation. Therefore, the train/development data consists of around 40k words, or 2k sentences, while the test data consists of around 20k words, or 1k sentences. 5 Experim</context>
</contexts>
<marker>Vogel, 2003</marker>
<rawString>Stephan Vogel. 2003. SMT Decoder Dissected: Word Reordering. In Int. Conf. on Natural Language Processing and Knowledge Engineering, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wen Wang</author>
<author>Gokhan Tur</author>
<author>Jing Zheng</author>
<author>Necip Fazil Ayan</author>
</authors>
<title>Automatic Disfluency Removal for Improving Spoken Language Translation.</title>
<date>2010</date>
<booktitle>In International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</booktitle>
<contexts>
<context position="1250" citStr="Wang et al., 2010" startWordPosition="186" endWordPosition="189">ency probability for each word. The SMT decoder will then skip the potentially disfluent word based on its disfluency probability. Using the suggested scheme, the translation score of both the manual transcript and ASR output is improved by around 0.35 BLEU points compared to the CRF hard decision system. 1 Introduction Disfluencies arise due to the spontaneous nature of speech. There has been a great deal of effort to detect disfluent words, remove them (Johnson and Charniak, 2004; Fitzgerald et al., 2009) and use the cleaned text for subsequent applications such as machine translation (MT) (Wang et al., 2010; Cho et al., 2013). One potential drawback of conventional approaches is that the decision whether a token is a disfluency or not is a hard decision. For an MT system, this can pose a severe problem if the removed token was not in fact a disfluency and should have been kept for the correct translation. Therefore, we pass the decision whether a word is part of a disfluency or not on to the translation system, so that we can use the additional knowledge available in the translation system to make a more reliable decision. In order to limit the complexity, the search space is pruned prior to dec</context>
<context position="2833" citStr="Wang et al., 2010" startWordPosition="455" endWordPosition="458">al models. Another noisy channel approach involves a phrase-level statistical MT system, where noisy tokens are translated into clean tokens (Maskey et al., 2006). A tree adjoining grammar is combined with this noisy channel model in (Johnson and Charniak, 2004), using a syntactic parser to build an LM. Fitzgerald et al. (2009) present a method to detect speech disfluencies using a conditional random field (CRF) with lexical, LM, and parser information features. While previous work has been limited to the postprocessing step of the automatic speech recogition (ASR) system, further approaches (Wang et al., 2010; Cho et al., 2013) use extended CRF features or additional models to clean manual speech transcripts and use them as input for an MT system. While ASR systems use lattices to encode hypotheses, lattices have been used for MT systems with various purposes. Herrmann et al. (2013) use lattices to encode different reordering variants. Lattices have also been used as a segmentation tactic for compound words (Dyer, 2009), where the segmentation is encoded as input in the lattice. One of the differences between our work and previous work is that we integrate the disfluency removal into an MT system.</context>
</contexts>
<marker>Wang, Tur, Zheng, Ayan, 2010</marker>
<rawString>Wen Wang, Gokhan Tur, Jing Zheng, and Necip Fazil Ayan. 2010. Automatic Disfluency Removal for Improving Spoken Language Translation. In International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>