<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000774">
<title confidence="0.998243">
Fast Recursive Multi-class Classification of Pairs of Text Entities
for Biomedical Event Extraction
</title>
<author confidence="0.985951">
Xiao Liu, Antoine Bordes, Yves Grandvalet
</author>
<affiliation confidence="0.650780333333333">
Université de Technologie de Compiègne &amp; CNRS
Heudiasyc UMR 7253
60200 Compiègne Cedex, France
</affiliation>
<email confidence="0.996627">
firstname.lastname@hds.utc.fr
</email>
<sectionHeader confidence="0.99384" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997382428571428">
Biomedical event extraction from arti-
cles has become a popular research topic
driven by important applications, such as
the automatic update of dedicated knowl-
edge base. Most existing approaches are
either pipeline models of specific classi-
fiers, usually subject to cascading errors,
or joint structured models, more efficient
but also more costly and more involved to
train. We propose here a system based on
a pairwise model that transforms event ex-
traction into a simple multi-class problem
of classifying pairs of text entities. Such
pairs are recursively provided to the classi-
fier, so as to extract events involving other
events as arguments. Our model is more
direct than the usual pipeline approaches,
and speeds up inference compared to joint
models. We report here the best results
reported so far on the BioNLP 2011 and
2013 Genia tasks.
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999976701754386">
Huge amounts of biomedical documents, such
as molecular biology reports or genomic papers
are generated daily. Automatically organizing
their content in dedicated databases enables ad-
vanced search and eases information retrieval for
researchers in biology, medicine or other related
fields. Nowadays, these data sources are mostly
in the form of unstructured free text, which is
complex to incorporate into databases. Hence,
many text-mining research initiatives are orga-
nized around the issue of automatically extract-
ing information from biomedical text. Efforts
specifically dedicated to biomedical text are nec-
essary because standard Natural Language Pro-
cessing tools cannot be readily applied to extract
biomedical events since such texts, articles or re-
ports involve highly domain-specific jargon, syn-
tax and dependencies (Kim et al., 2011a).
This paper tackles the problem of event extrac-
tion from biomedical documents. Building on pre-
vious advances in named entity recognition (for
detecting gene or protein mentions for instance),
this task consists in associating to these entities the
related events expressed in the text. Such events
are of multiple types and involve at least one text
entity as argument and another one as trigger; they
can be quite complex since some events have sev-
eral arguments, and recursive in the sense that ar-
guments can themselves be events. An example of
event is given in Figure 1.
Biomedical event extraction is attracting more
and more attention, especially thanks to the or-
ganization of recurrent dedicated BioNLP chal-
lenges (Kim et al., 2009; Kim et al., 2011b; Kim
et al., 2013). We propose here a new approach
which relies on a single multi-class classifier for
recursively detecting events from (trigger, argu-
ment) pairs. Compared to standard pipeline ap-
proaches based on sequences of classifiers (Björne
and Salakoski, 2013; Hakala et al., 2013), we
avoid the intermediate problem of associating iso-
lated triggers to event types, relying on a tricky
multi-label classification problem. Instead, we di-
rectly extract compounds of events in the form
of (trigger, argument) pairs, simply relying on
a multi-class problem, whereby (trigger, argu-
ment) pairs are associated to event types. Con-
sidering pairs of words also allows us to char-
acterize examples by sophisticated joint features
such as shortest path in the dependency parse tree,
and hence to achieve much accurate trigger de-
tection than pipeline models. Besides, compared
to Markov random fields (Riedel and McCallum,
2011a), our discriminant model does not repre-
sent the full joint distribution of words and events.
We thus have a simpler inference process, which
results into drastically reduced training times (15
</bodyText>
<page confidence="0.965066">
692
</page>
<note confidence="0.9988935">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 692–701,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.8157475">
Figure 1: Part of a sentence and corresponding
extracted events for the BioNLP 2013 Genia task.
</figureCaption>
<bodyText confidence="0.999965">
times faster for processing about 800 training doc-
uments). In short, we propose in this work a
happy medium between pipeline and joint mod-
els. Our approach builds on our previous proposal
(Liu et al., 2013), where we detected triggers di-
rectly from (trigger, argument) pairs. Here, we
upgrade our scheme by adding a recursive clas-
sification process that considerably improves the
detection of complex events.
This paper is organized as follows: Section 2 in-
troduces the problem of biomedical event extrac-
tion and discusses related works. Section 3 de-
scribes our recursive model and its training pro-
cess. The post-processing procedures and the fea-
tures used are detailed in Sections 4 and 5. Sec-
tion 6 shows that our method achieves excellent
empirical results, with the best performance re-
ported so far on the BioNLP 2011 and 2013 Genia
tasks, and a reduced training duration compared to
the previously state-of-the-art models.
</bodyText>
<sectionHeader confidence="0.933974" genericHeader="introduction">
2 Context and Related Works
</sectionHeader>
<bodyText confidence="0.996391">
Biomedical event extraction aims at extracting
event formulas from sentences, defined as se-
quences of tokens (words, numbers, or symbols).
</bodyText>
<subsectionHeader confidence="0.929783">
2.1 Task Definition
</subsectionHeader>
<bodyText confidence="0.999848611111111">
Terminology regarding biomedical events, trig-
gers, etc. varies from one task or data set to an-
other; in the following, we use the definitions used
by the Genia (GE) task 1 of the BioNLP chal-
lenges. An event is constituted of two kinds of
elements: an event trigger and one or several ar-
guments. The event trigger is an entity, that is,
a sequence of consecutive tokens which indicates
that an event is mentioned in the text. The argu-
ments of an event are participants, which can be
proteins, genes or other biomedical events.
In the data settings of the GE task, protein
mentions are already annotated in the text. Fig-
ure 1 illustrates biomedical event extraction in
the GE task framework: given 3 proteins “Tax”,
“CBP” and “p300”, one must detect “recruit”
as an event trigger for two events of the Bind-
ing category , encoded by the formulas: (“re-
</bodyText>
<table confidence="0.999479">
Class Type Principal arg Optional arg
S Gene_expression theme (P)
V Transcription theme (P)
T Protein_catabolism theme (P)
Phosphorylation theme (P)
Localization theme (P)
B Binding theme (P) theme_2 (P)
I
N
R Regulation theme (P/E) cause (P/E)
E Positive_regulation theme (P/E) cause (P/E)
G Negative_regulation theme (P/E) cause (P/E)
</table>
<tableCaption confidence="0.8153875">
Table 1: Classes and types of events with their
arguments (P stands for Protein, E for Event).
</tableCaption>
<bodyText confidence="0.997123076923077">
cruit”, theme:“Tax”, theme_2:“CBP”) and (“re-
cruit”, theme:“Tax”, theme_2:“p300”).
A key part of the task is to detect the trigger en-
tities among the candidates sequences of tokens.
The BioNLP GE task considers 9 types of events.1
Table 1 lists these events. The 9 event types may
be merged into three broader categories: the first
5 (termed SVT) have a single theme argument; the
Binding event (or BIN) can accept up to two theme
arguments; the last 3 types (termed REG) also ac-
cept up to two arguments, a theme and an optional
cause. REG events can be recursive because their
arguments can be proteins or events.
</bodyText>
<subsectionHeader confidence="0.942071">
2.2 Related Works
</subsectionHeader>
<bodyText confidence="0.9995265">
Current approaches fall into two main cate-
gories: pipeline incremental models and global
joint methods. Pipeline approaches (Sætre et al.,
2009; Cohen et al., 2009; Quirk et al., 2011)
are the simplest way to tackle the problem of
event extraction. A sequence of specific classi-
fiers are ran on the text to successively (P1) de-
tect event triggers, (P2) assign them arguments,
(P3) detect event triggers whose arguments can
be events, and (P4) assign them arguments (steps
(P3) and (P4) can be ran multiple times). Such
systems are relatively easy to set up and experi-
enced many successes: the TEES system (Björne
et al., 2009; Bj[Pleaseinsertintopreamble]rne et
al., 2012; Björne and Salakoski, 2013) won the
BioNLP GE task in 2009 and ranked 2nd in 2013,
whereas the EVEX system won in 2013 (Van Lan-
deghem et al., 2011; Hakala et al., 2013). How-
ever, all these methods suffer from error cascad-
ing. Besides, prediction must be formalized as
</bodyText>
<footnote confidence="0.950866">
1The BioNLP 2013 challenge considered 13 types of
events, but we only dealt with the 9 types defined in the pre-
vious challenges, because there was not enough data on the
newly defined types for proper training or model selection.
</footnote>
<figure confidence="0.994607857142857">
Theme
Theme
Binding
Binding
Theme 2
Theme 2
allows Tax to recruit coactivator proteins CBP/p300 to
</figure>
<page confidence="0.99845">
693
</page>
<bodyText confidence="0.999723953488372">
a multi-label classification problem because some
words can participate in the definition of several
events of different types. Detecting triggers in iso-
lation of their arguments in steps (P1) and (P3) are
ill-posed intermediate problems, since the notion
of trigger is intrinsically tied to its argument. The
latter brings contextual information that is indis-
putably relevant for detection. Besides, rich fea-
tures coding for (trigger, argument) pairs (Miwa et
al., 2010) are only used by pipeline models for as-
signing arguments, whereas they could be useful
for trigger detection as well.
Global joint approaches (Riedel et al., 2009;
McClosky et al., 2011) aim at solving the event
extraction task at once, so as to resolve the
drawbacks of pipeline models. In (McClosky et
al., 2011), event annotations are converted into
pseudo-syntactic representations and the task is
solved as a syntactic extraction problem by tradi-
tional parsing methods. In (Riedel et al., 2009;
Riedel and McCallum, 2011a; Riedel et al., 2011;
Riedel and McCallum, 2011b), some models are
proposed based on the maximization of a global
score taking into account the annotations of nodes
and edges in a graph representing each sentence.
This maximization problem is formalized as an in-
teger linear program with consistency constraints,
and solved via dual decomposition. Such joint
models perform very well (winner of the BioNLP
2011 GE task), but suffer from consequential com-
puting costs, as all possible combinations of words
are considered as potential events. In the follow-
ing, we show that our model is able to reach better
accuracies than joint models while being compu-
tationally much cheaper.
A method based on the search-based structured
prediction paradigm (Vlachos and Craven, 2012)
has been proposed as an intermediate step between
joint and pipeline approaches, by turning the struc-
tured prediction problem into a sequence of multi-
class classification tasks. Our experiments demon-
strate that, despite being conceptually simpler, our
recursive pairwise model outperforms it.
</bodyText>
<sectionHeader confidence="0.998614" genericHeader="method">
3 Recursive Pairwise Model
</sectionHeader>
<bodyText confidence="0.999759166666667">
In this section, we present our recursive pair-
wise model. It directly extracts pairwise inter-
actions between entities, thereby contrasting with
the usual pipeline approaches, which require de-
tecting triggers as an intermediate problem. Our
approach proceeds in two steps:
</bodyText>
<listItem confidence="0.9640166">
1. Main (trigger, theme) pair extraction:
main event extraction step that detects the
triggers with one of their arguments;
2. Post-processing: step that adds extra-
arguments to BIN and REG events.
</listItem>
<bodyText confidence="0.9992345">
Step 1 is the main innovative part of our sys-
tem, and is detailed in the remainder of this sec-
tion. Step 2, which relies on more established
techniques, is described in Section 4.
</bodyText>
<subsectionHeader confidence="0.999134">
3.1 Direct Extraction of Simple Events
</subsectionHeader>
<bodyText confidence="0.99999596">
We process entities differently depending on
whether they are marked as proteins in the anno-
tation or not; the latter are termed candidate en-
tities. We denote CS = {ci}i the set of candi-
date entities, which is built from the sentence to-
kens (see Section 5 for details on its construction),
AS = {aj}j the set of candidate arguments (that
is, the proteins identified by a named-entity recog-
nizer beforehand) in a given sentence S, and the
set of event types (augmented by None) is Y.
The first steps of a pipeline model consist in pre-
dicting whether candidate entities ci E CS are trig-
gers or not and then, whether arguments aj E AS
can participate to a subset of events from Y. In-
stead, our pairwise model directly addresses the
problem of classifying the (candidate, argument)
pairs pij = (ci, aj) as events of type from Y.
This classification is based on Support Vector
Machines (SVMs), where the multi-class problem
is broken down in a series of one-vs-rest binary
problems, one for each event type. The final de-
cision associated to each pair pij is simply taken
as the event (including None) whose score is max-
imal. Classifying a pair pij as not-None jointly
detects the event trigger ci and its argument aj.
</bodyText>
<subsectionHeader confidence="0.999626">
3.2 Recursive Extraction of Complex Events
</subsectionHeader>
<bodyText confidence="0.9998845">
For simple SVT and BIN events, the set AS of
possible arguments is restricted to proteins, but the
events of class REG may have other events as ar-
guments, thus AS has to be enriched. Consider-
ing all possible events would be intractable, so that
the set of possible arguments is updated dynami-
cally in the process of extracting events. As here
possible arguments are exclusive to event types, in
practice it is simpler to update the set of pairs that
remain to be assessed.
Assume that an event has been actually pre-
dicted, that is, that pαβ = (cα, aβ) has been clas-
</bodyText>
<page confidence="0.994809">
694
</page>
<bodyText confidence="0.975327333333333">
Algorithm 1 Recursive pairwise event extraction
input sentence S, candidate entities CS = {ci}i
and labeled proteins AS = {aj}j
</bodyText>
<listItem confidence="0.9365336875">
1: initialize candidate pairs
PS = {(ci, aj), ci ∈ CS, aj ∈ AS}
2: initialize extracted events ES = ∅
3: score and label the pairs in PS
4: while PS =6 ∅ do
5: select the pair pαβ ∈ PS with highest score
6: update PS ← PS − {pαβ}
7: if ˆyαβ =6 None then
8: create event ˆeαβ = (cα, aβ, ˆyαβ)
9: update ES ← ES ∪ {ˆeαβ}
10: update PS ← PS ∪ {(ci, ˆeαβ)|ci ∈ CS}
11: censor pairs PS to avoid cycles
12: score and label the new {(ci, ˆeαβ)} pairs
13: end if
14: end while
15: return extracted events ES
</listItem>
<bodyText confidence="0.9999601875">
sified as ˆyαβ =6 None; the predicted event is de-
noted ˆeαβ = (cα, aβ, ˆyαβ). We create all pairs
with it as argument, {(ci, ˆeαβ)|ci ∈ CS}, and add
them to PS, so as to allow for the detection of re-
cursive events. We assume that recursive events
constitute a directed acyclic graph, where the an-
cestor of a candidate entity cannot be used as its
argument. The dynamic updating process is thus
constrained to prevent the creation of cycles.
Algorithm 1 summaries our event extraction
algorithm. For all events with a single argu-
ment, predicting yˆ variables directly responds to
the event extraction problem. When appropriate,
additional optional arguments are added after all
pairwise events have been extracted, by the post-
processing described in Section 4.
</bodyText>
<subsectionHeader confidence="0.999697">
3.3 Fitting the Pairwise Model
</subsectionHeader>
<bodyText confidence="0.999973936507937">
The prediction process described above relies on
a multi-class classifier. We stress again that, since
pairs are assigned to a single class, there is no need
to address the more difficult multi-label problem
encountered in standard pipeline approaches. An
entity may still be assigned to several events, pos-
sibly of different types, through the allocation of
labels to several pairs comprising this entity.
Training SVMs For each event type, a series
of binary linear SVMs is fitted to the avail-
able training data, using the implementation from
scikit-learn.org. As events are rare, each
binary classification problem is highly unbal-
anced. We thus use different losses for posi-
tive and negative examples (Morik et al., 1999;
Veropoulos et al., 1999), resulting in two hyper-
parameters that are set by cross-validation, so as to
maximize the F-score of the corresponding event
type taken in isolation.
For the SVT and BIN events, the training sets
are all composed of the possible (candidate, argu-
ment) pairs PS = {pij = (ci, aj)|ci ∈ CS, aj ∈
AS} readily extracted from all training sentences,
and they only differ in the definition of the posi-
tive and negative class, according to the true label
associated to each pair.
Creating the training sets for REG events is
more complicated: since they can take events as
arguments, new pairs are added to PS by consid-
ering all the events already detected, as sketched
in Algorithm 1. Hence, the sets of training exam-
ples are not deterministically known before train-
ing, but depend on predictions of all other clas-
sifiers. Training directly on them requires to use
either online algorithms or complex search-based
structured prediction procedures as in (Vlachos
and Craven, 2012). In this paper, we prefer to
use instead the true labels yαβ during the training
phase of REG and None classifiers: the training
sets are then the enriched sets of possible (candi-
date, argument) pairs PS = {pij = (ci, aj)|ci ∈
CS, aj ∈ AS} ∪ {piα = (ci, eαβ)|ci ∈ CS, ∃β :
yαβ =6 None}. This allows to know all train-
ing examples beforehand and hence to use stan-
dard batch SVM algorithms. The drawback is
that, since extracted events in test are imperfect,
this creates a divergence between training and test-
ing scenarios, which can lead to degraded perfor-
mance. However, as our experiments show, this
effect is marginal compared to the advantages of
using fast reliable batch training algorithms.
Score Combination As said earlier, the decision
rule simply consists in predicting the class corre-
sponding to the highest SVM score. This simple
scheme could be improved, either by using multi-
class classifiers or by using more refined combi-
nations optimizing a global criterion as proposed
in (Liu et al., 2013). Though this route deserves
to be thoroughly tested, we conjecture that only
marginal gains should be expected since the vast
majority of errors are due to the detection of an
event when there is none or to the absence of de-
tection of an existing event: when an event is de-
</bodyText>
<page confidence="0.995879">
695
</page>
<bodyText confidence="0.89575">
tected, its correct type is predominantly predicted.
</bodyText>
<subsectionHeader confidence="0.894627">
3.4 Computational Considerations
</subsectionHeader>
<bodyText confidence="0.996889428571429">
The pairwise structure leads to a simple inference
procedure, with a slight increase in computational
complexity compared to pipeline models. We de-
note m = card(CS), the number of candidate enti-
ties, n = card(AS), the number of annotated pro-
teins and m&apos; the number of detected triggers. The
complexity of a pipeline model is O(m&apos;(n+m&apos;)),
whereas that of our approach is O(m(n + m&apos;)).
This implies more calls to the classifying mech-
anism, but this is not too penalizing, since SVM-
based classification scales well with the number of
examples. Besides, this is still cheaper than joint
models such as (Riedel and McCallum, 2011a),
whose complexity is O(m(n2 + m)).
</bodyText>
<sectionHeader confidence="0.971922" genericHeader="method">
4 Post-Processing
</sectionHeader>
<bodyText confidence="0.9999472">
This section describes the post-processing car-
ried out once the (trigger, theme) pairs are de-
tected and labeled as events. The goal is to look
whether extra-arguments should be added to these
extracted events.
</bodyText>
<subsectionHeader confidence="0.999227">
4.1 Binding Theme Fusion
</subsectionHeader>
<bodyText confidence="0.999901">
This step attempts to merge several pairs la-
beled as Binding to create multiple arguments
events. We take the set of extracted Binding events
{(cα, aβ)} that share the same trigger cα, and all
combinations {(cα, aβ, aγ)|γ =� Q} are classified
by a binary SVM. Once a combination (cα, aβ, aγ)
is predicted as a correct merge, it is added to pre-
dicted events while both pairs (cα, aβ) and (cα, aγ)
are removed.
</bodyText>
<subsectionHeader confidence="0.95942">
4.2 Regulation Cause Assignment
</subsectionHeader>
<bodyText confidence="0.999917818181818">
This step looks for optional cause arguments that
may be added to the extracted REG events. Given
an extracted event (cα, aβ) and a candidate argu-
ment set AS = Jaγ} containing all the proteins of
the sentence 5 as well as all events extracted by
the classifier, all combinations {(cα, aβ, aγ)|γ =�
Q} are classified by a binary SVM. Since cause
argument could be another event, we extract them
incrementally in a dynamic process alike (trigger,
theme) pair extraction, also with constraints avoid-
ing the creation of cycles.
</bodyText>
<sectionHeader confidence="0.998892" genericHeader="method">
5 Features
</sectionHeader>
<bodyText confidence="0.999933083333334">
This section details our features as well as the data
preprocessing used by our system.
Pre-processing Tokenization and sentence split-
ting have an important impact on the quality of the
dependency parse trees as well as the way we han-
dle compound words that contain protein names.
Data is split in sentences using both the nltk
toolkit (nltk.org) and the sentence splitting
provided for the BioNLP GE task. High quality
dependency parse trees require a fine grained tok-
enization, whereas coarse tokenization conserves
some biomedical jargon that could also provide
essential information. Hence, two tokenizations
are used for different features. Tokenization1, pro-
vided by the organizers of the BioNLP GE task,
is a coarse tokenization that is used to character-
ize when a candidate entity and a protein are in
the same token. Tokenization2 is fined grained,
based on the Stanford parser (McClosky et al.,
2011) that is slightly modified for primary tok-
enization. It supplies the dependency parse, can-
didate entity match and most of our features. The
dependency parse trees are finally obtained us-
ing a phrase structure parser (McClosky et al.,
2010), using the post-processing of the Stanford
corenlp package (De Marneffe et al., 2006). We
used stems (obtained by Snowball stemmer pro-
vided in nltk) as base forms for the tokens.
Candidate set For each sentence 5, the set CS
is built with a gazetteer: candidate entities are
recursively added by searching first the longest
token sequences (from Tokenization2) from the
gazetteer. For entities with several tokens, a rep-
resentative head token is selected by a heuristic
based on the dependency parse.
Candidate entities Three types of tokens are
considered: the head token, its parent and child
nodes in the dependency tree, and the tokens be-
longing to a neighboring window of the entity. The
size k of the word window is a hyper-parameter of
our model. Table 2 lists all features which include
stems, part-of-speech (POS) tags, etc. Special care
was taken to design the feature for head token
since it plays an extremely important role in can-
didate entities. We hence employed features and
heuristics to deal with compound-words, hyphens
and prefixes, inspired by such tools developed in
the code of the UCLEED system (based on Tok-
</bodyText>
<page confidence="0.985438">
696
</page>
<bodyText confidence="0.81924305882353">
Candidate Base form (stem) of the head token.
entity
features
Base form of the head token without
’-’ or ’/’ before of after.
Sub-string after ’-’ in the head token.
POS of the head token.
First token of the entity is after ’-’ or ’/’.
Last token of the entity is before ’-’ or ’/’.
Head token has a special prefix: &amp;quot;over&amp;quot;,
&amp;quot;up&amp;quot;, &amp;quot;down&amp;quot;, &amp;quot;co&amp;quot;
Concat. of base form and POS of parents
of the head token in dependency parse.
Concat. of base form and POS of children
of the head token in dependency parse.
Base forms of k neighboring tokens
around the entity.
POS of k neighboring tokens around the
entity.
Neighborhood of the entity has ’-’ or ’/’.
Sentence has &amp;quot;mRNA&amp;quot;.
Entity is connected with another string
using Tokenization1.
Argument Argument is a protein.
features
POS of the head token.
Features extracted from IntAct when the
argument is a protein.
Base forms of k neighboring tokens
around the argument.
POS of k neighboring tokens around the
argument.
Concat. of base form and POS of children
of the head token in dependency parse.
</bodyText>
<table confidence="0.829246416666667">
Pairwise Token sequence between candidate and
features argument has proteins.
V-walk features between candidate and
argument with base forms.
E-walk features between candidate and
argument with base forms.
V-walk features between candidate and
argument with POS.
E-walk features between candidate and
argument with POS.
Candidate and the argument share a token
using Tokenization1.
</table>
<tableCaption confidence="0.9302055">
Table 2: Features used by our system. Most are
based on Tokenization2 except when specified.
</tableCaption>
<bodyText confidence="0.997259">
enization2).2 Protein names and POS in tokens are
substituted by the token PROT, e.g. transforming
&amp;quot;LPS-activated&amp;quot; into &amp;quot;PROT-activated&amp;quot;. There is
total of a 35,365 candidate features.
Arguments Table 2 also lists the argument fea-
tures, which are a subset of those for candidate en-
tities. Most head word features are removed, but
base forms and POS of the neighboring tokens and
of the parent node in the dependency tree are still
included. Assigning label from SVT or BIN event
classes to a (ci, eαβ) pair should never occur, be-
cause only regulation events could have another
event as argument. Therefore, we add a feature
that indicates whether the argument is a protein
</bodyText>
<page confidence="0.3481">
2Seegithub.com/riedelcastro/ucleed.
</page>
<figureCaption confidence="0.8685">
Figure 2: Example of E-walks and V-walks
features for encoding a dependency parse tree.
</figureCaption>
<bodyText confidence="0.998127947368421">
or a trigger entity. Proteins are also described us-
ing features extracted from the Uniprot knowledge
base (uniprot.org). There is total of 4,349 ar-
gument features.
Pairwise relations Our pairwise approach is
able to take advantage of features that code inter-
actions between candidate triggers and arguments,
such as those listed in Table 2. Hence, we have a
feature indicating if both elements of a pair belong
to the same token (based on Tokenization1).
But the most important pairwise features come
from the shortest path linking two candidate and
arguments in the dependency parse tree of the sen-
tence. Incorporating such dependency information
into the pairwise model relies on the process en-
coding the path into feature vectors. Many for-
matting methods have been proposed in previous
works. Following (Miwa et al., 2010), our sys-
tem use a combination of E-walks, that encode the
path into triplets (dep-tag, token, dep-tag), and V-
walks that encode it into triplets (token, dep-tag,
token), where tokens are encoded via stem and
POS tags, and dep-tags are the dependency labels.
Figure 2 illustrates this formatting: from the de-
pendency parse given on top, three V-walk and two
E-walk features are defined. These are inserted
in the feature vector using a bag-of-words pro-
cess, thus losing any relative ordering information.
These imperfect representations lose a lot of infor-
mation and can even add noise, especially when
the path is long. Therefore, we applied heuris-
tics from the UCLEED system to remove some
uninformative edges from the dependency parse.
Moreover, dependency parse features are added
only for pairs for which the (candidate, argument)
path length is below a threshold whose value is a
hyper-parameter. There is a total of 176,106 pair-
wise features.
</bodyText>
<page confidence="0.994801">
697
</page>
<table confidence="0.999913357142857">
Event Type TEES 2.1 EVEX Pipeline Our approach
or Class counterpart
Gene_expression 82.7 82.7 83.9 85.1
Transcription 55.0 55.0 61.7 62.8
Protein_catabol 56.3 56.3 66.7 68.8
Phosphorylation 72.6 71.5 81.8 81.8
Localization 63.3 60.7 56.9 57.7
SVT TOTAL 74.9 74.5 79.0 79.6
BIN TOTAL 43.3 42.9 41.6 42.4
Regulation 23.0 23.4 23.1 31.8
Positive_regul 38.7 39.2 36.5 46.3
Negative_regul 43.7 43.9 38.1 43.6
REG TOTAL 38.1 38.4 35.1 43.2
ALL TOTAL 50.7 51.0 50.8 54.4
</table>
<tableCaption confidence="0.9654175">
Table 3: F-scores on the test set of the BioNLP
2013 GE task.
</tableCaption>
<sectionHeader confidence="0.996848" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.99240425">
In this section, we evaluate empirically our sys-
tem in the framework (data, annotations and eval-
uation) of biomedical event extraction defined in
the GE tasks of the BioNLP challenges. More pre-
cisely, we present results on the test sets of the
fresh 2013 GE task, and of the 2011 edition to
compare to joint methods.
In order to assess the efficiency of our mod-
eling choices, we also implemented a pipeline
counterpart system, following the structure of
the TEES approach (Björne et al., 2009;
Bj[Pleaseinsertintopreamble]rne et al., 2012;
Björne and Salakoski, 2013) but using the same
feature set, pre-processing and a similar post-
processing as our system. This pipeline system
comprises four steps: (1) trigger classification,
which assigns event types from Y to candidate
entities cZ E CS using a multi-class SVM classi-
fier; (2) edge detection, which identifies the edges
between extracted triggers and proteins and be-
tween REG triggers and all the triggers; labels
from Yedge = {theme, cause, None} are as-
signed to those pairs; (3) binding theme fusion,
identical to as in Section 4.1; (4) theme-cause fu-
sion, as in Section 4.2, given two predicted pairs
(cZ, theme : a,3), (cZ, cause : ay), this step de-
cides whether they should be merged into a single
event (cZ, theme : a,3, cause : ay).
</bodyText>
<subsectionHeader confidence="0.998562">
6.1 Genia Shared Task 2013
</subsectionHeader>
<bodyText confidence="0.999966105263158">
For the BioNLP 2013 GE task, the hyper-
parameters of our system have been optimized on
the GE task development set (except for the regu-
larization parameters of the SVMs, which are se-
lected by cross-validation), after training on the
corresponding training sets: token window size is
2 for candidate entities and 1 for arguments, the
threshold for dependency path is 4. Using these
hyper-parameter values, the final model submit-
ted for test evaluation on the GE task server has
been trained on all documents from training and
development sets of BioNLP 2011 and 2013 GE
tasks. Detailed descriptions of the BioNLP 2011
and 2013 GE data are respectively given in (Kim
et al., 2011b) and (Kim et al., 2013).
Table 3 lists the detailed test F-scores, as
returned by the official challenge test server
(using the default approximate span &amp; recur-
sive matching evaluation setting). We com-
pare our model to the winner of the challenge,
EVEX (Hakala et al., 2013), and of the best
runner-up, TEES 2.1 (Björne and Salakoski,
2013), which are both pipeline approaches.
Our approach is slightly below TEES 2.1 on
BIN events, but overall, it outperforms all com-
petitors significantly (by more than 3%), with
a wide margin on REG events. Our pipeline
counterpart has an overall performance similar to
EVEX and TEES 2.1, while being better for SVT
and worse for BIN and REG events. These dis-
parities are due to the differences in features and
in processing details. The benefits of the pairwise
structure and the recursive process are demon-
strated by the considerable improvement upon the
pipeline counterpart (using the same features, pre-
and post-processing). In particular, the recursive
prediction process run on REG events brings about
a very substantial improvement (more than 8%).
</bodyText>
<subsectionHeader confidence="0.999441">
6.2 Genia Shared Task 2011
</subsectionHeader>
<bodyText confidence="0.99980075">
The best performing methods on the BioNLP
2013 GE task were pipeline approaches, but the
joint models that were performing better in the
previous challenge were not competing in 2013.
As these joint models are quite tricky to train,
we compare our system with joint models on
the BioNLP 2011 GE task, where trustworthy
performances have been publicly released. We
train our model using the training and develop-
ment sets available at the time of the challenge
and we then get an evaluation on the same test
data using the official test server maintained on-
line by BioNLP organizers. Table 4 lists the re-
sults of our approach, its pipeline counterpart, and
those of UCLEED (Riedel and McCallum, 2011a)
and TEES (Bj[Pleaseinsertintopreamble]rne et al.,
</bodyText>
<page confidence="0.995644">
698
</page>
<table confidence="0.999395333333333">
Event UCLEED SEARN TEES Pipeline Our approach
Class counterpart
SVT 73.5 71.8 n/a 71.8 74.0
BIN 48.8 45.8 n/a 40.0 50.5
REG 43.8 43.0 n/a 35.7 45.1
ALL 55.2 53.5 53.3 50.0 55.6
</table>
<tableCaption confidence="0.9647665">
Table 4: F-scores on the test set of the BioNLP
2011 GE task.
</tableCaption>
<bodyText confidence="0.999989074074074">
2012), which are respectively the best performing
joint model and best pipeline on this task. We
also added SEARN (Vlachos and Craven, 2012),
which is a hybrid between them.3
As for 2013 data, our system achieves a higher
F-score on all event classes compared to its
pipeline counterpart. The benefits of the pair-
wise structure and the recursive process are larger
here, thereby outperforming the overall F-score of
TEES (no detailed results available), which itself
performs better than our pipeline counterpart. Sys-
tematic improvements on all event classes are also
observed compared to the joint model UCLEED
and to the search-based structured prediction ap-
proach of SEARN. To our knowledge, our model
thus reaches the best overall performance reported
so far on this data set for a single model.4
By combining the use of the simple pair struc-
ture between triggers and arguments with a recur-
sive prediction process, our approach is able to
outperform pipeline models and to be at least at
par with models relying on much more sophisti-
cated structures. For this task, it is thus highly
beneficial to consider pairwise interactions from
beginning to end, but more complex dependen-
cies seem not to be essential, especially since they
come at a higher computational cost.
</bodyText>
<subsectionHeader confidence="0.996738">
6.3 Training Durations
</subsectionHeader>
<bodyText confidence="0.99996">
In this last section, we propose to illustrate the
lower complexity of our approach compared to
UCLEED by providing durations for training both
systems on BioNLP 2011 GE. These timings do
not involve preprocessing but only running cross-
validation on the training set and evaluation on
the development and test sets. For UCLEED,
</bodyText>
<footnote confidence="0.990277333333333">
3The results for UCLEED, TEES and SEARN mod-
els are reproduced from (Riedel and McCallum, 2011a;
Bj[Pleaseinsertintopreamble]rne et al., 2012; Vlachos and
Craven, 2012) respectively.
4We do not compare with the results of FAUST (Riedel et
al., 2011), which achieved the best F-score on this task (56.0)
because this is an ensemble of various models of UCLEED
and of the Stanford system (McClosky et al., 2011), which
makes it an unfair comparison.
</footnote>
<bodyText confidence="0.9998103125">
we used the code (in java &amp; scala) provided by
the authors5 and we chose BioNLP 2011 GE be-
cause this code was primarily designed to run
on it. Our code, in python, is publicly available
from github.com/XiaoLiuAI/RUPEE. Ex-
periments were conducted on the same computer,
with a quad-core Intel Xeon CPU and 16GB of
RAM. Both codes are multi-threaded and used
all 4 threads simultaneously. Under these condi-
tions, UCLEED requires around 8h30min to run
its 10 epochs,6 while our code completes training
in about 30min. Some of these differences may be
due to implementation choices, but we believe that
the 15 fold speed increase (for around 800 training
documents) is at least partially due to the lower
complexity of our approach.
</bodyText>
<sectionHeader confidence="0.999046" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999988227272727">
We introduced a recursive pairwise model de-
signed for biomedical event extraction. This pair-
wise model improves on the best current ap-
proaches of the BioNLP 2013 and 2011 GE tasks.
Our system breaks down the overall event extrac-
tion task into the classification of (trigger, theme)
pairs, assigned to event types. These (trigger,
theme) pairs enable to use joint features in off-the-
shelf classifiers, without resorting to costly global
inference models. We also implemented a recur-
sive procedure that deals with regulation events,
which may include other events in their definition.
All operations are run in a unified framework, us-
ing a single event classifier.
Our system is fast and more accurate than the
available pipeline models or joint models. Given
its simplicity and scalability, we believe that our
model is a strong basis for large-scale event extrac-
tion projects. Several refinements are possible, for
example by exploring other types features, or by
enabling the direct processing of triplets that may
be encountered in binding or regulation events.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999482">
This work was carried out in the framework of
the Labex MS2T funded by the French National
Agency for Research through the program “Invest-
ments for the future” (ANR-11-IDEX-0004-02),
and supported by the “young researchers” pro-
gram (EVEREST-12-JS02-005-01).
</bodyText>
<footnote confidence="0.988012666666667">
5Seegithub.com/riedelcastro/ucleed.
6UCLEED might be faster by using feature caching, but
we had to disable it because it was taking up too much RAM.
</footnote>
<page confidence="0.997641">
699
</page>
<sectionHeader confidence="0.989922" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999880926605505">
J. Björne and T. Salakoski. 2013. TEES 2.1: Auto-
mated annotation scheme learning in the BioNLP
2013 shared task. In Proceedings of BioNLP Shared
Task 2013 Workshop, Sofia, Bulgaria, August. Asso-
ciation for Computational Linguistics.
J. Björne, J. Heimonen, F. Ginter, A. Airola,
T. Pahikkala, and T. Salakoski. 2009. Extract-
ing complex biological events with rich graph-
based feature sets. In Proceedings of the BioNLP
2009 Workshop Companion Volume for Shared Task,
pages 10–18, Boulder, Colorado, June. Association
for Computational Linguistics.
J. Björne, F. Ginter, and T. Salakoski. 2012. University
of turku in the bionlp’11 shared task. BMC Bioinfor-
matics, 13(Suppl 11):S4.
K. B. Cohen, K. Verspoor, H. Johnson, C. Roeder,
P. Ogren, W. Baumgartner, E. White, and L. Hunter.
2009. High-precision biological event extraction
with a concept recognizer. In Proceedings of the
BioNLP 2009 Workshop Companion Volume for
Shared Task, pages 50–58, Boulder, Colorado, June.
Association for Computational Linguistics.
M.-C. De Marneffe, B. MacCartney, and C. D. Man-
ning. 2006. Generating typed dependency parses
from phrase structure parses. In Proceedings of
LREC, volume 6, pages 449–454.
K. Hakala, S. Van Landeghem, T. Salakoski, Y. Van de
Peer, and F. Ginter. 2013. EVEX in ST’13: Appli-
cation of a large-scale text mining resource to event
extraction and network construction. In Proceedings
of BioNLP Shared Task 2013 Workshop, Sofia, Bul-
garia, August. Association for Computational Lin-
guistics.
J.-D. Kim, T. Ohta, S. Pyysalo, Y. Kano, and J. Tsu-
jii. 2009. Overview of BioNLP’09 shared task
on event extraction. In Proceedings of the BioNLP
2009 Workshop Companion Volume for Shared Task,
pages 1–9, Boulder, Colorado, June. Association for
Computational Linguistics.
J.-D. Kim, T. Ohta, S. Pyysalo, Y. Kano, and J. Tsujii.
2011a. Extracting bio-molecular events from litera-
ture. Computational Intelligence, 27(4):513–540.
J.-D. Kim, Y. Wang, T. Takagi, and A. Yonezawa.
2011b. Overview of genia event task in bionlp
shared task 2011. In Proceedings of BioNLP Shared
Task 2011 Workshop, pages 7–15, Portland, Oregon,
USA, June. Association for Computational Linguis-
tics.
J.-D. Kim, Y. Wang, and Y. Yasunori. 2013. The
genia event extraction shared task, 2013 edition -
overview. In Proceedings of the BioNLP Shared
Task 2013 Workshop, pages 8–15, Sofia, Bulgaria,
August. Association for Computational Linguistics.
X. Liu, A. Bordes, and Y. Grandvalet. 2013. Biomed-
ical event extraction by multi-class classification of
pairs of text entities. In Proceedings of the BioNLP
Shared Task 2013 Workshop, pages 45–49, Sofia,
Bulgaria, August. Association for Computational
Linguistics.
D. McClosky, E. Charniak, and M. Johnson. 2010. Au-
tomatic domain adaptation for parsing. In Human
Language Technologies: The 2010 Annual Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistics, HLT ’10,
pages 28–36, Stroudsburg, PA, USA. Association
for Computational Linguistics.
D. McClosky, M. Surdeanu, and C. D. Manning. 2011.
Event extraction as dependency parsing. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies - Volume 1, HLT ’11, pages
1626–1635, Stroudsburg, PA, USA. Association for
Computational Linguistics.
M. Miwa, R. Sætre, J.-D. Kim, and J. Tsujii. 2010.
Event extraction with complex event classification
using rich features. J. Bioinformatics and Computa-
tional Biology, 8(1):131–146.
K. Morik, P. Brockhausen, and T. Joachims. 1999.
Combining statistical learning with a knowledge-
based approach - a case study in intensive care moni-
toring. In Proceedings of the Sixteenth International
Conference on Machine Learning (ICML 1999).
C. Quirk, P. Choudhury, M. Gamon, and L. Vander-
wende. 2011. MSR-NLP entry in BioNLP shared
task 2011. In Proceedings of BioNLP Shared Task
2011 Workshop, pages 155–163, Portland, Oregon,
USA, June. Association for Computational Linguis-
tics.
S. Riedel and A. McCallum. 2011a. Fast and robust
joint models for biomedical event extraction. In
Proceedings of the 2011 Conference on Empirical
Methods in Natural Language Processing, pages 1–
12, Edinburgh, Scotland, UK., July. Association for
Computational Linguistics.
S. Riedel and A. McCallum. 2011b. Robust biomed-
ical event extraction with dual decomposition and
minimal domain adaptation. In Proceedings of
BioNLP Shared Task 2011 Workshop, pages 46–50,
Portland, Oregon, USA, June. Association for Com-
putational Linguistics.
S. Riedel, H.-W. Chun, T. Takagi, and J. Tsujii. 2009.
A Markov logic approach to bio-molecular event ex-
traction. In Proceedings of the BioNLP 2009 Work-
shop Companion Volume for Shared Task, pages 41–
49, Boulder, Colorado, June. Association for Com-
putational Linguistics.
S. Riedel, D. McClosky, M. Surdeanu, A. McCallum,
and C. D. Manning. 2011. Model combination for
event extraction in BioNLP 2011. In Proceedings
</reference>
<page confidence="0.95282">
700
</page>
<reference confidence="0.999820333333333">
of BioNLP Shared Task 2011 Workshop, pages 51–
55, Portland, Oregon, USA, June. Association for
Computational Linguistics.
R. Sætre, M. Miwa, K. Yoshida, and J. Tsujii. 2009.
From protein-protein interaction to molecular event
extraction. In Proceedings of the BioNLP 2009
Workshop Companion Volume for Shared Task,
pages 103–106, Boulder, Colorado, June. Associa-
tion for Computational Linguistics.
S. Van Landeghem, F. Ginter, Y. Van de Peer, and
T. Salakoski. 2011. Evex: A pubmed-scale resource
for homology-based generalization of text mining
predictions. In Proceedings of BioNLP 2011 Work-
shop, pages 28–37, Portland, Oregon, USA, June.
Association for Computational Linguistics.
K. Veropoulos, C. Campbell, and N. Cristianini. 1999.
Controlling the sensitivity of support vector ma-
chines. In T. Dean, editor, Proceedings of the Inter-
national Joint Conference on Artificial Intelligence,
pages 55–60.
A. Vlachos and M. Craven. 2012. Biomedical
event extraction from abstracts and full papers using
search-based structured prediction. BMC bioinfor-
matics, 13(Suppl 11):S5.
</reference>
<page confidence="0.997981">
701
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.565778">
<title confidence="0.999416">Fast Recursive Multi-class Classification of Pairs of Text for Biomedical Event Extraction</title>
<author confidence="0.986107">Xiao Liu</author>
<author confidence="0.986107">Antoine Bordes</author>
<author confidence="0.986107">Yves</author>
<affiliation confidence="0.8947005">Université de Technologie de Compiègne &amp; Heudiasyc UMR</affiliation>
<address confidence="0.982115">60200 Compiègne Cedex,</address>
<email confidence="0.998016">firstname.lastname@hds.utc.fr</email>
<abstract confidence="0.987342909090909">Biomedical event extraction from articles has become a popular research topic driven by important applications, such as the automatic update of dedicated knowledge base. Most existing approaches are either pipeline models of specific classifiers, usually subject to cascading errors, or joint structured models, more efficient but also more costly and more involved to train. We propose here a system based on a pairwise model that transforms event extraction into a simple multi-class problem of classifying pairs of text entities. Such pairs are recursively provided to the classifier, so as to extract events involving other events as arguments. Our model is more direct than the usual pipeline approaches, and speeds up inference compared to joint models. We report here the best results reported so far on the BioNLP 2011 and 2013 Genia tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Björne</author>
<author>T Salakoski</author>
</authors>
<title>TEES 2.1: Automated annotation scheme learning in the BioNLP</title>
<date>2013</date>
<booktitle>In Proceedings of BioNLP Shared Task 2013 Workshop,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="3011" citStr="Björne and Salakoski, 2013" startWordPosition="459" endWordPosition="462">hey can be quite complex since some events have several arguments, and recursive in the sense that arguments can themselves be events. An example of event is given in Figure 1. Biomedical event extraction is attracting more and more attention, especially thanks to the organization of recurrent dedicated BioNLP challenges (Kim et al., 2009; Kim et al., 2011b; Kim et al., 2013). We propose here a new approach which relies on a single multi-class classifier for recursively detecting events from (trigger, argument) pairs. Compared to standard pipeline approaches based on sequences of classifiers (Björne and Salakoski, 2013; Hakala et al., 2013), we avoid the intermediate problem of associating isolated triggers to event types, relying on a tricky multi-label classification problem. Instead, we directly extract compounds of events in the form of (trigger, argument) pairs, simply relying on a multi-class problem, whereby (trigger, argument) pairs are associated to event types. Considering pairs of words also allows us to characterize examples by sophisticated joint features such as shortest path in the dependency parse tree, and hence to achieve much accurate trigger detection than pipeline models. Besides, compa</context>
<context position="7898" citStr="Björne and Salakoski, 2013" startWordPosition="1255" endWordPosition="1258">dels and global joint methods. Pipeline approaches (Sætre et al., 2009; Cohen et al., 2009; Quirk et al., 2011) are the simplest way to tackle the problem of event extraction. A sequence of specific classifiers are ran on the text to successively (P1) detect event triggers, (P2) assign them arguments, (P3) detect event triggers whose arguments can be events, and (P4) assign them arguments (steps (P3) and (P4) can be ran multiple times). Such systems are relatively easy to set up and experienced many successes: the TEES system (Björne et al., 2009; Bj[Pleaseinsertintopreamble]rne et al., 2012; Björne and Salakoski, 2013) won the BioNLP GE task in 2009 and ranked 2nd in 2013, whereas the EVEX system won in 2013 (Van Landeghem et al., 2011; Hakala et al., 2013). However, all these methods suffer from error cascading. Besides, prediction must be formalized as 1The BioNLP 2013 challenge considered 13 types of events, but we only dealt with the 9 types defined in the previous challenges, because there was not enough data on the newly defined types for proper training or model selection. Theme Theme Binding Binding Theme 2 Theme 2 allows Tax to recruit coactivator proteins CBP/p300 to 693 a multi-label classificati</context>
<context position="26962" citStr="Björne and Salakoski, 2013" startWordPosition="4448" endWordPosition="4451">s on the test set of the BioNLP 2013 GE task. 6 Experiments In this section, we evaluate empirically our system in the framework (data, annotations and evaluation) of biomedical event extraction defined in the GE tasks of the BioNLP challenges. More precisely, we present results on the test sets of the fresh 2013 GE task, and of the 2011 edition to compare to joint methods. In order to assess the efficiency of our modeling choices, we also implemented a pipeline counterpart system, following the structure of the TEES approach (Björne et al., 2009; Bj[Pleaseinsertintopreamble]rne et al., 2012; Björne and Salakoski, 2013) but using the same feature set, pre-processing and a similar postprocessing as our system. This pipeline system comprises four steps: (1) trigger classification, which assigns event types from Y to candidate entities cZ E CS using a multi-class SVM classifier; (2) edge detection, which identifies the edges between extracted triggers and proteins and between REG triggers and all the triggers; labels from Yedge = {theme, cause, None} are assigned to those pairs; (3) binding theme fusion, identical to as in Section 4.1; (4) theme-cause fusion, as in Section 4.2, given two predicted pairs (cZ, th</context>
<context position="28736" citStr="Björne and Salakoski, 2013" startWordPosition="4752" endWordPosition="4755">eter values, the final model submitted for test evaluation on the GE task server has been trained on all documents from training and development sets of BioNLP 2011 and 2013 GE tasks. Detailed descriptions of the BioNLP 2011 and 2013 GE data are respectively given in (Kim et al., 2011b) and (Kim et al., 2013). Table 3 lists the detailed test F-scores, as returned by the official challenge test server (using the default approximate span &amp; recursive matching evaluation setting). We compare our model to the winner of the challenge, EVEX (Hakala et al., 2013), and of the best runner-up, TEES 2.1 (Björne and Salakoski, 2013), which are both pipeline approaches. Our approach is slightly below TEES 2.1 on BIN events, but overall, it outperforms all competitors significantly (by more than 3%), with a wide margin on REG events. Our pipeline counterpart has an overall performance similar to EVEX and TEES 2.1, while being better for SVT and worse for BIN and REG events. These disparities are due to the differences in features and in processing details. The benefits of the pairwise structure and the recursive process are demonstrated by the considerable improvement upon the pipeline counterpart (using the same features,</context>
</contexts>
<marker>Björne, Salakoski, 2013</marker>
<rawString>J. Björne and T. Salakoski. 2013. TEES 2.1: Automated annotation scheme learning in the BioNLP 2013 shared task. In Proceedings of BioNLP Shared Task 2013 Workshop, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Björne</author>
<author>J Heimonen</author>
<author>F Ginter</author>
<author>A Airola</author>
<author>T Pahikkala</author>
<author>T Salakoski</author>
</authors>
<title>Extracting complex biological events with rich graphbased feature sets.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task,</booktitle>
<pages>10--18</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="7823" citStr="Björne et al., 2009" startWordPosition="1247" endWordPosition="1250">t approaches fall into two main categories: pipeline incremental models and global joint methods. Pipeline approaches (Sætre et al., 2009; Cohen et al., 2009; Quirk et al., 2011) are the simplest way to tackle the problem of event extraction. A sequence of specific classifiers are ran on the text to successively (P1) detect event triggers, (P2) assign them arguments, (P3) detect event triggers whose arguments can be events, and (P4) assign them arguments (steps (P3) and (P4) can be ran multiple times). Such systems are relatively easy to set up and experienced many successes: the TEES system (Björne et al., 2009; Bj[Pleaseinsertintopreamble]rne et al., 2012; Björne and Salakoski, 2013) won the BioNLP GE task in 2009 and ranked 2nd in 2013, whereas the EVEX system won in 2013 (Van Landeghem et al., 2011; Hakala et al., 2013). However, all these methods suffer from error cascading. Besides, prediction must be formalized as 1The BioNLP 2013 challenge considered 13 types of events, but we only dealt with the 9 types defined in the previous challenges, because there was not enough data on the newly defined types for proper training or model selection. Theme Theme Binding Binding Theme 2 Theme 2 allows Tax</context>
<context position="26887" citStr="Björne et al., 2009" startWordPosition="4440" endWordPosition="4443"> 38.1 38.4 35.1 43.2 ALL TOTAL 50.7 51.0 50.8 54.4 Table 3: F-scores on the test set of the BioNLP 2013 GE task. 6 Experiments In this section, we evaluate empirically our system in the framework (data, annotations and evaluation) of biomedical event extraction defined in the GE tasks of the BioNLP challenges. More precisely, we present results on the test sets of the fresh 2013 GE task, and of the 2011 edition to compare to joint methods. In order to assess the efficiency of our modeling choices, we also implemented a pipeline counterpart system, following the structure of the TEES approach (Björne et al., 2009; Bj[Pleaseinsertintopreamble]rne et al., 2012; Björne and Salakoski, 2013) but using the same feature set, pre-processing and a similar postprocessing as our system. This pipeline system comprises four steps: (1) trigger classification, which assigns event types from Y to candidate entities cZ E CS using a multi-class SVM classifier; (2) edge detection, which identifies the edges between extracted triggers and proteins and between REG triggers and all the triggers; labels from Yedge = {theme, cause, None} are assigned to those pairs; (3) binding theme fusion, identical to as in Section 4.1; (</context>
</contexts>
<marker>Björne, Heimonen, Ginter, Airola, Pahikkala, Salakoski, 2009</marker>
<rawString>J. Björne, J. Heimonen, F. Ginter, A. Airola, T. Pahikkala, and T. Salakoski. 2009. Extracting complex biological events with rich graphbased feature sets. In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task, pages 10–18, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Björne</author>
<author>F Ginter</author>
<author>T Salakoski</author>
</authors>
<date>2012</date>
<booktitle>University of turku in the bionlp’11 shared task. BMC Bioinformatics, 13(Suppl 11):S4.</booktitle>
<marker>Björne, Ginter, Salakoski, 2012</marker>
<rawString>J. Björne, F. Ginter, and T. Salakoski. 2012. University of turku in the bionlp’11 shared task. BMC Bioinformatics, 13(Suppl 11):S4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K B Cohen</author>
<author>K Verspoor</author>
<author>H Johnson</author>
<author>C Roeder</author>
<author>P Ogren</author>
<author>W Baumgartner</author>
<author>E White</author>
<author>L Hunter</author>
</authors>
<title>High-precision biological event extraction with a concept recognizer.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task,</booktitle>
<pages>50--58</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="7361" citStr="Cohen et al., 2009" startWordPosition="1167" endWordPosition="1170">ns. The BioNLP GE task considers 9 types of events.1 Table 1 lists these events. The 9 event types may be merged into three broader categories: the first 5 (termed SVT) have a single theme argument; the Binding event (or BIN) can accept up to two theme arguments; the last 3 types (termed REG) also accept up to two arguments, a theme and an optional cause. REG events can be recursive because their arguments can be proteins or events. 2.2 Related Works Current approaches fall into two main categories: pipeline incremental models and global joint methods. Pipeline approaches (Sætre et al., 2009; Cohen et al., 2009; Quirk et al., 2011) are the simplest way to tackle the problem of event extraction. A sequence of specific classifiers are ran on the text to successively (P1) detect event triggers, (P2) assign them arguments, (P3) detect event triggers whose arguments can be events, and (P4) assign them arguments (steps (P3) and (P4) can be ran multiple times). Such systems are relatively easy to set up and experienced many successes: the TEES system (Björne et al., 2009; Bj[Pleaseinsertintopreamble]rne et al., 2012; Björne and Salakoski, 2013) won the BioNLP GE task in 2009 and ranked 2nd in 2013, whereas</context>
</contexts>
<marker>Cohen, Verspoor, Johnson, Roeder, Ogren, Baumgartner, White, Hunter, 2009</marker>
<rawString>K. B. Cohen, K. Verspoor, H. Johnson, C. Roeder, P. Ogren, W. Baumgartner, E. White, and L. Hunter. 2009. High-precision biological event extraction with a concept recognizer. In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task, pages 50–58, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-C De Marneffe</author>
<author>B MacCartney</author>
<author>C D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<pages>449--454</pages>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>M.-C. De Marneffe, B. MacCartney, and C. D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC, volume 6, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hakala</author>
<author>S Van Landeghem</author>
<author>T Salakoski</author>
<author>Y Van de Peer</author>
<author>F Ginter</author>
</authors>
<title>EVEX in ST’13: Application of a large-scale text mining resource to event extraction and network construction.</title>
<date>2013</date>
<booktitle>In Proceedings of BioNLP Shared Task 2013 Workshop,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<marker>Hakala, Van Landeghem, Salakoski, Van de Peer, Ginter, 2013</marker>
<rawString>K. Hakala, S. Van Landeghem, T. Salakoski, Y. Van de Peer, and F. Ginter. 2013. EVEX in ST’13: Application of a large-scale text mining resource to event extraction and network construction. In Proceedings of BioNLP Shared Task 2013 Workshop, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-D Kim</author>
<author>T Ohta</author>
<author>S Pyysalo</author>
<author>Y Kano</author>
<author>J Tsujii</author>
</authors>
<title>Overview of BioNLP’09 shared task on event extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task,</booktitle>
<pages>1--9</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="2725" citStr="Kim et al., 2009" startWordPosition="414" endWordPosition="417">ty recognition (for detecting gene or protein mentions for instance), this task consists in associating to these entities the related events expressed in the text. Such events are of multiple types and involve at least one text entity as argument and another one as trigger; they can be quite complex since some events have several arguments, and recursive in the sense that arguments can themselves be events. An example of event is given in Figure 1. Biomedical event extraction is attracting more and more attention, especially thanks to the organization of recurrent dedicated BioNLP challenges (Kim et al., 2009; Kim et al., 2011b; Kim et al., 2013). We propose here a new approach which relies on a single multi-class classifier for recursively detecting events from (trigger, argument) pairs. Compared to standard pipeline approaches based on sequences of classifiers (Björne and Salakoski, 2013; Hakala et al., 2013), we avoid the intermediate problem of associating isolated triggers to event types, relying on a tricky multi-label classification problem. Instead, we directly extract compounds of events in the form of (trigger, argument) pairs, simply relying on a multi-class problem, whereby (trigger, a</context>
</contexts>
<marker>Kim, Ohta, Pyysalo, Kano, Tsujii, 2009</marker>
<rawString>J.-D. Kim, T. Ohta, S. Pyysalo, Y. Kano, and J. Tsujii. 2009. Overview of BioNLP’09 shared task on event extraction. In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task, pages 1–9, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-D Kim</author>
<author>T Ohta</author>
<author>S Pyysalo</author>
<author>Y Kano</author>
<author>J Tsujii</author>
</authors>
<title>Extracting bio-molecular events from literature.</title>
<date>2011</date>
<journal>Computational Intelligence,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="1984" citStr="Kim et al., 2011" startWordPosition="292" endWordPosition="295"> for researchers in biology, medicine or other related fields. Nowadays, these data sources are mostly in the form of unstructured free text, which is complex to incorporate into databases. Hence, many text-mining research initiatives are organized around the issue of automatically extracting information from biomedical text. Efforts specifically dedicated to biomedical text are necessary because standard Natural Language Processing tools cannot be readily applied to extract biomedical events since such texts, articles or reports involve highly domain-specific jargon, syntax and dependencies (Kim et al., 2011a). This paper tackles the problem of event extraction from biomedical documents. Building on previous advances in named entity recognition (for detecting gene or protein mentions for instance), this task consists in associating to these entities the related events expressed in the text. Such events are of multiple types and involve at least one text entity as argument and another one as trigger; they can be quite complex since some events have several arguments, and recursive in the sense that arguments can themselves be events. An example of event is given in Figure 1. Biomedical event extra</context>
<context position="28394" citStr="Kim et al., 2011" startWordPosition="4694" endWordPosition="4697">em have been optimized on the GE task development set (except for the regularization parameters of the SVMs, which are selected by cross-validation), after training on the corresponding training sets: token window size is 2 for candidate entities and 1 for arguments, the threshold for dependency path is 4. Using these hyper-parameter values, the final model submitted for test evaluation on the GE task server has been trained on all documents from training and development sets of BioNLP 2011 and 2013 GE tasks. Detailed descriptions of the BioNLP 2011 and 2013 GE data are respectively given in (Kim et al., 2011b) and (Kim et al., 2013). Table 3 lists the detailed test F-scores, as returned by the official challenge test server (using the default approximate span &amp; recursive matching evaluation setting). We compare our model to the winner of the challenge, EVEX (Hakala et al., 2013), and of the best runner-up, TEES 2.1 (Björne and Salakoski, 2013), which are both pipeline approaches. Our approach is slightly below TEES 2.1 on BIN events, but overall, it outperforms all competitors significantly (by more than 3%), with a wide margin on REG events. Our pipeline counterpart has an overall performance si</context>
</contexts>
<marker>Kim, Ohta, Pyysalo, Kano, Tsujii, 2011</marker>
<rawString>J.-D. Kim, T. Ohta, S. Pyysalo, Y. Kano, and J. Tsujii. 2011a. Extracting bio-molecular events from literature. Computational Intelligence, 27(4):513–540.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-D Kim</author>
<author>Y Wang</author>
<author>T Takagi</author>
<author>A Yonezawa</author>
</authors>
<title>Overview of genia event task in bionlp shared task 2011.</title>
<date>2011</date>
<booktitle>In Proceedings of BioNLP Shared Task 2011 Workshop,</booktitle>
<pages>7--15</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="1984" citStr="Kim et al., 2011" startWordPosition="292" endWordPosition="295"> for researchers in biology, medicine or other related fields. Nowadays, these data sources are mostly in the form of unstructured free text, which is complex to incorporate into databases. Hence, many text-mining research initiatives are organized around the issue of automatically extracting information from biomedical text. Efforts specifically dedicated to biomedical text are necessary because standard Natural Language Processing tools cannot be readily applied to extract biomedical events since such texts, articles or reports involve highly domain-specific jargon, syntax and dependencies (Kim et al., 2011a). This paper tackles the problem of event extraction from biomedical documents. Building on previous advances in named entity recognition (for detecting gene or protein mentions for instance), this task consists in associating to these entities the related events expressed in the text. Such events are of multiple types and involve at least one text entity as argument and another one as trigger; they can be quite complex since some events have several arguments, and recursive in the sense that arguments can themselves be events. An example of event is given in Figure 1. Biomedical event extra</context>
<context position="28394" citStr="Kim et al., 2011" startWordPosition="4694" endWordPosition="4697">em have been optimized on the GE task development set (except for the regularization parameters of the SVMs, which are selected by cross-validation), after training on the corresponding training sets: token window size is 2 for candidate entities and 1 for arguments, the threshold for dependency path is 4. Using these hyper-parameter values, the final model submitted for test evaluation on the GE task server has been trained on all documents from training and development sets of BioNLP 2011 and 2013 GE tasks. Detailed descriptions of the BioNLP 2011 and 2013 GE data are respectively given in (Kim et al., 2011b) and (Kim et al., 2013). Table 3 lists the detailed test F-scores, as returned by the official challenge test server (using the default approximate span &amp; recursive matching evaluation setting). We compare our model to the winner of the challenge, EVEX (Hakala et al., 2013), and of the best runner-up, TEES 2.1 (Björne and Salakoski, 2013), which are both pipeline approaches. Our approach is slightly below TEES 2.1 on BIN events, but overall, it outperforms all competitors significantly (by more than 3%), with a wide margin on REG events. Our pipeline counterpart has an overall performance si</context>
</contexts>
<marker>Kim, Wang, Takagi, Yonezawa, 2011</marker>
<rawString>J.-D. Kim, Y. Wang, T. Takagi, and A. Yonezawa. 2011b. Overview of genia event task in bionlp shared task 2011. In Proceedings of BioNLP Shared Task 2011 Workshop, pages 7–15, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-D Kim</author>
<author>Y Wang</author>
<author>Y Yasunori</author>
</authors>
<title>The genia event extraction shared task,</title>
<date>2013</date>
<booktitle>In Proceedings of the BioNLP Shared Task 2013 Workshop,</booktitle>
<pages>8--15</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="2763" citStr="Kim et al., 2013" startWordPosition="422" endWordPosition="425"> protein mentions for instance), this task consists in associating to these entities the related events expressed in the text. Such events are of multiple types and involve at least one text entity as argument and another one as trigger; they can be quite complex since some events have several arguments, and recursive in the sense that arguments can themselves be events. An example of event is given in Figure 1. Biomedical event extraction is attracting more and more attention, especially thanks to the organization of recurrent dedicated BioNLP challenges (Kim et al., 2009; Kim et al., 2011b; Kim et al., 2013). We propose here a new approach which relies on a single multi-class classifier for recursively detecting events from (trigger, argument) pairs. Compared to standard pipeline approaches based on sequences of classifiers (Björne and Salakoski, 2013; Hakala et al., 2013), we avoid the intermediate problem of associating isolated triggers to event types, relying on a tricky multi-label classification problem. Instead, we directly extract compounds of events in the form of (trigger, argument) pairs, simply relying on a multi-class problem, whereby (trigger, argument) pairs are associated to event</context>
<context position="28419" citStr="Kim et al., 2013" startWordPosition="4699" endWordPosition="4702">n the GE task development set (except for the regularization parameters of the SVMs, which are selected by cross-validation), after training on the corresponding training sets: token window size is 2 for candidate entities and 1 for arguments, the threshold for dependency path is 4. Using these hyper-parameter values, the final model submitted for test evaluation on the GE task server has been trained on all documents from training and development sets of BioNLP 2011 and 2013 GE tasks. Detailed descriptions of the BioNLP 2011 and 2013 GE data are respectively given in (Kim et al., 2011b) and (Kim et al., 2013). Table 3 lists the detailed test F-scores, as returned by the official challenge test server (using the default approximate span &amp; recursive matching evaluation setting). We compare our model to the winner of the challenge, EVEX (Hakala et al., 2013), and of the best runner-up, TEES 2.1 (Björne and Salakoski, 2013), which are both pipeline approaches. Our approach is slightly below TEES 2.1 on BIN events, but overall, it outperforms all competitors significantly (by more than 3%), with a wide margin on REG events. Our pipeline counterpart has an overall performance similar to EVEX and TEES 2.</context>
</contexts>
<marker>Kim, Wang, Yasunori, 2013</marker>
<rawString>J.-D. Kim, Y. Wang, and Y. Yasunori. 2013. The genia event extraction shared task, 2013 edition -overview. In Proceedings of the BioNLP Shared Task 2013 Workshop, pages 8–15, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Liu</author>
<author>A Bordes</author>
<author>Y Grandvalet</author>
</authors>
<title>Biomedical event extraction by multi-class classification of pairs of text entities.</title>
<date>2013</date>
<booktitle>In Proceedings of the BioNLP Shared Task 2013 Workshop,</booktitle>
<pages>45--49</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="4377" citStr="Liu et al., 2013" startWordPosition="671" endWordPosition="674">We thus have a simpler inference process, which results into drastically reduced training times (15 692 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 692–701, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Figure 1: Part of a sentence and corresponding extracted events for the BioNLP 2013 Genia task. times faster for processing about 800 training documents). In short, we propose in this work a happy medium between pipeline and joint models. Our approach builds on our previous proposal (Liu et al., 2013), where we detected triggers directly from (trigger, argument) pairs. Here, we upgrade our scheme by adding a recursive classification process that considerably improves the detection of complex events. This paper is organized as follows: Section 2 introduces the problem of biomedical event extraction and discusses related works. Section 3 describes our recursive model and its training process. The post-processing procedures and the features used are detailed in Sections 4 and 5. Section 6 shows that our method achieves excellent empirical results, with the best performance reported so far on </context>
<context position="17224" citStr="Liu et al., 2013" startWordPosition="2840" endWordPosition="2843"> drawback is that, since extracted events in test are imperfect, this creates a divergence between training and testing scenarios, which can lead to degraded performance. However, as our experiments show, this effect is marginal compared to the advantages of using fast reliable batch training algorithms. Score Combination As said earlier, the decision rule simply consists in predicting the class corresponding to the highest SVM score. This simple scheme could be improved, either by using multiclass classifiers or by using more refined combinations optimizing a global criterion as proposed in (Liu et al., 2013). Though this route deserves to be thoroughly tested, we conjecture that only marginal gains should be expected since the vast majority of errors are due to the detection of an event when there is none or to the absence of detection of an existing event: when an event is de695 tected, its correct type is predominantly predicted. 3.4 Computational Considerations The pairwise structure leads to a simple inference procedure, with a slight increase in computational complexity compared to pipeline models. We denote m = card(CS), the number of candidate entities, n = card(AS), the number of annotate</context>
</contexts>
<marker>Liu, Bordes, Grandvalet, 2013</marker>
<rawString>X. Liu, A. Bordes, and Y. Grandvalet. 2013. Biomedical event extraction by multi-class classification of pairs of text entities. In Proceedings of the BioNLP Shared Task 2013 Workshop, pages 45–49, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McClosky</author>
<author>E Charniak</author>
<author>M Johnson</author>
</authors>
<title>Automatic domain adaptation for parsing. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10,</booktitle>
<pages>28--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="20628" citStr="McClosky et al., 2010" startWordPosition="3409" endWordPosition="3412">edical jargon that could also provide essential information. Hence, two tokenizations are used for different features. Tokenization1, provided by the organizers of the BioNLP GE task, is a coarse tokenization that is used to characterize when a candidate entity and a protein are in the same token. Tokenization2 is fined grained, based on the Stanford parser (McClosky et al., 2011) that is slightly modified for primary tokenization. It supplies the dependency parse, candidate entity match and most of our features. The dependency parse trees are finally obtained using a phrase structure parser (McClosky et al., 2010), using the post-processing of the Stanford corenlp package (De Marneffe et al., 2006). We used stems (obtained by Snowball stemmer provided in nltk) as base forms for the tokens. Candidate set For each sentence 5, the set CS is built with a gazetteer: candidate entities are recursively added by searching first the longest token sequences (from Tokenization2) from the gazetteer. For entities with several tokens, a representative head token is selected by a heuristic based on the dependency parse. Candidate entities Three types of tokens are considered: the head token, its parent and child node</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2010</marker>
<rawString>D. McClosky, E. Charniak, and M. Johnson. 2010. Automatic domain adaptation for parsing. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10, pages 28–36, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McClosky</author>
<author>M Surdeanu</author>
<author>C D Manning</author>
</authors>
<title>Event extraction as dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>1626--1635</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9130" citStr="McClosky et al., 2011" startWordPosition="1459" endWordPosition="1462"> because some words can participate in the definition of several events of different types. Detecting triggers in isolation of their arguments in steps (P1) and (P3) are ill-posed intermediate problems, since the notion of trigger is intrinsically tied to its argument. The latter brings contextual information that is indisputably relevant for detection. Besides, rich features coding for (trigger, argument) pairs (Miwa et al., 2010) are only used by pipeline models for assigning arguments, whereas they could be useful for trigger detection as well. Global joint approaches (Riedel et al., 2009; McClosky et al., 2011) aim at solving the event extraction task at once, so as to resolve the drawbacks of pipeline models. In (McClosky et al., 2011), event annotations are converted into pseudo-syntactic representations and the task is solved as a syntactic extraction problem by traditional parsing methods. In (Riedel et al., 2009; Riedel and McCallum, 2011a; Riedel et al., 2011; Riedel and McCallum, 2011b), some models are proposed based on the maximization of a global score taking into account the annotations of nodes and edges in a graph representing each sentence. This maximization problem is formalized as an</context>
<context position="20389" citStr="McClosky et al., 2011" startWordPosition="3370" endWordPosition="3373"> split in sentences using both the nltk toolkit (nltk.org) and the sentence splitting provided for the BioNLP GE task. High quality dependency parse trees require a fine grained tokenization, whereas coarse tokenization conserves some biomedical jargon that could also provide essential information. Hence, two tokenizations are used for different features. Tokenization1, provided by the organizers of the BioNLP GE task, is a coarse tokenization that is used to characterize when a candidate entity and a protein are in the same token. Tokenization2 is fined grained, based on the Stanford parser (McClosky et al., 2011) that is slightly modified for primary tokenization. It supplies the dependency parse, candidate entity match and most of our features. The dependency parse trees are finally obtained using a phrase structure parser (McClosky et al., 2010), using the post-processing of the Stanford corenlp package (De Marneffe et al., 2006). We used stems (obtained by Snowball stemmer provided in nltk) as base forms for the tokens. Candidate set For each sentence 5, the set CS is built with a gazetteer: candidate entities are recursively added by searching first the longest token sequences (from Tokenization2)</context>
<context position="32538" citStr="McClosky et al., 2011" startWordPosition="5378" endWordPosition="5381">g durations for training both systems on BioNLP 2011 GE. These timings do not involve preprocessing but only running crossvalidation on the training set and evaluation on the development and test sets. For UCLEED, 3The results for UCLEED, TEES and SEARN models are reproduced from (Riedel and McCallum, 2011a; Bj[Pleaseinsertintopreamble]rne et al., 2012; Vlachos and Craven, 2012) respectively. 4We do not compare with the results of FAUST (Riedel et al., 2011), which achieved the best F-score on this task (56.0) because this is an ensemble of various models of UCLEED and of the Stanford system (McClosky et al., 2011), which makes it an unfair comparison. we used the code (in java &amp; scala) provided by the authors5 and we chose BioNLP 2011 GE because this code was primarily designed to run on it. Our code, in python, is publicly available from github.com/XiaoLiuAI/RUPEE. Experiments were conducted on the same computer, with a quad-core Intel Xeon CPU and 16GB of RAM. Both codes are multi-threaded and used all 4 threads simultaneously. Under these conditions, UCLEED requires around 8h30min to run its 10 epochs,6 while our code completes training in about 30min. Some of these differences may be due to impleme</context>
</contexts>
<marker>McClosky, Surdeanu, Manning, 2011</marker>
<rawString>D. McClosky, M. Surdeanu, and C. D. Manning. 2011. Event extraction as dependency parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 1626–1635, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Miwa</author>
<author>R Sætre</author>
<author>J-D Kim</author>
<author>J Tsujii</author>
</authors>
<title>Event extraction with complex event classification using rich features.</title>
<date>2010</date>
<journal>J. Bioinformatics and Computational Biology,</journal>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="8943" citStr="Miwa et al., 2010" startWordPosition="1428" endWordPosition="1431">pes for proper training or model selection. Theme Theme Binding Binding Theme 2 Theme 2 allows Tax to recruit coactivator proteins CBP/p300 to 693 a multi-label classification problem because some words can participate in the definition of several events of different types. Detecting triggers in isolation of their arguments in steps (P1) and (P3) are ill-posed intermediate problems, since the notion of trigger is intrinsically tied to its argument. The latter brings contextual information that is indisputably relevant for detection. Besides, rich features coding for (trigger, argument) pairs (Miwa et al., 2010) are only used by pipeline models for assigning arguments, whereas they could be useful for trigger detection as well. Global joint approaches (Riedel et al., 2009; McClosky et al., 2011) aim at solving the event extraction task at once, so as to resolve the drawbacks of pipeline models. In (McClosky et al., 2011), event annotations are converted into pseudo-syntactic representations and the task is solved as a syntactic extraction problem by traditional parsing methods. In (Riedel et al., 2009; Riedel and McCallum, 2011a; Riedel et al., 2011; Riedel and McCallum, 2011b), some models are propo</context>
<context position="24902" citStr="Miwa et al., 2010" startWordPosition="4110" endWordPosition="4113"> able to take advantage of features that code interactions between candidate triggers and arguments, such as those listed in Table 2. Hence, we have a feature indicating if both elements of a pair belong to the same token (based on Tokenization1). But the most important pairwise features come from the shortest path linking two candidate and arguments in the dependency parse tree of the sentence. Incorporating such dependency information into the pairwise model relies on the process encoding the path into feature vectors. Many formatting methods have been proposed in previous works. Following (Miwa et al., 2010), our system use a combination of E-walks, that encode the path into triplets (dep-tag, token, dep-tag), and Vwalks that encode it into triplets (token, dep-tag, token), where tokens are encoded via stem and POS tags, and dep-tags are the dependency labels. Figure 2 illustrates this formatting: from the dependency parse given on top, three V-walk and two E-walk features are defined. These are inserted in the feature vector using a bag-of-words process, thus losing any relative ordering information. These imperfect representations lose a lot of information and can even add noise, especially whe</context>
</contexts>
<marker>Miwa, Sætre, Kim, Tsujii, 2010</marker>
<rawString>M. Miwa, R. Sætre, J.-D. Kim, and J. Tsujii. 2010. Event extraction with complex event classification using rich features. J. Bioinformatics and Computational Biology, 8(1):131–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Morik</author>
<author>P Brockhausen</author>
<author>T Joachims</author>
</authors>
<title>Combining statistical learning with a knowledgebased approach - a case study in intensive care monitoring.</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth International Conference on Machine Learning (ICML</booktitle>
<contexts>
<context position="15217" citStr="Morik et al., 1999" startWordPosition="2497" endWordPosition="2500">irs are assigned to a single class, there is no need to address the more difficult multi-label problem encountered in standard pipeline approaches. An entity may still be assigned to several events, possibly of different types, through the allocation of labels to several pairs comprising this entity. Training SVMs For each event type, a series of binary linear SVMs is fitted to the available training data, using the implementation from scikit-learn.org. As events are rare, each binary classification problem is highly unbalanced. We thus use different losses for positive and negative examples (Morik et al., 1999; Veropoulos et al., 1999), resulting in two hyperparameters that are set by cross-validation, so as to maximize the F-score of the corresponding event type taken in isolation. For the SVT and BIN events, the training sets are all composed of the possible (candidate, argument) pairs PS = {pij = (ci, aj)|ci ∈ CS, aj ∈ AS} readily extracted from all training sentences, and they only differ in the definition of the positive and negative class, according to the true label associated to each pair. Creating the training sets for REG events is more complicated: since they can take events as arguments</context>
</contexts>
<marker>Morik, Brockhausen, Joachims, 1999</marker>
<rawString>K. Morik, P. Brockhausen, and T. Joachims. 1999. Combining statistical learning with a knowledgebased approach - a case study in intensive care monitoring. In Proceedings of the Sixteenth International Conference on Machine Learning (ICML 1999).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Quirk</author>
<author>P Choudhury</author>
<author>M Gamon</author>
<author>L Vanderwende</author>
</authors>
<title>MSR-NLP entry in BioNLP shared task 2011.</title>
<date>2011</date>
<booktitle>In Proceedings of BioNLP Shared Task 2011 Workshop,</booktitle>
<pages>155--163</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="7382" citStr="Quirk et al., 2011" startWordPosition="1171" endWordPosition="1174">sk considers 9 types of events.1 Table 1 lists these events. The 9 event types may be merged into three broader categories: the first 5 (termed SVT) have a single theme argument; the Binding event (or BIN) can accept up to two theme arguments; the last 3 types (termed REG) also accept up to two arguments, a theme and an optional cause. REG events can be recursive because their arguments can be proteins or events. 2.2 Related Works Current approaches fall into two main categories: pipeline incremental models and global joint methods. Pipeline approaches (Sætre et al., 2009; Cohen et al., 2009; Quirk et al., 2011) are the simplest way to tackle the problem of event extraction. A sequence of specific classifiers are ran on the text to successively (P1) detect event triggers, (P2) assign them arguments, (P3) detect event triggers whose arguments can be events, and (P4) assign them arguments (steps (P3) and (P4) can be ran multiple times). Such systems are relatively easy to set up and experienced many successes: the TEES system (Björne et al., 2009; Bj[Pleaseinsertintopreamble]rne et al., 2012; Björne and Salakoski, 2013) won the BioNLP GE task in 2009 and ranked 2nd in 2013, whereas the EVEX system won </context>
</contexts>
<marker>Quirk, Choudhury, Gamon, Vanderwende, 2011</marker>
<rawString>C. Quirk, P. Choudhury, M. Gamon, and L. Vanderwende. 2011. MSR-NLP entry in BioNLP shared task 2011. In Proceedings of BioNLP Shared Task 2011 Workshop, pages 155–163, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riedel</author>
<author>A McCallum</author>
</authors>
<title>Fast and robust joint models for biomedical event extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--12</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="3665" citStr="Riedel and McCallum, 2011" startWordPosition="561" endWordPosition="564">oid the intermediate problem of associating isolated triggers to event types, relying on a tricky multi-label classification problem. Instead, we directly extract compounds of events in the form of (trigger, argument) pairs, simply relying on a multi-class problem, whereby (trigger, argument) pairs are associated to event types. Considering pairs of words also allows us to characterize examples by sophisticated joint features such as shortest path in the dependency parse tree, and hence to achieve much accurate trigger detection than pipeline models. Besides, compared to Markov random fields (Riedel and McCallum, 2011a), our discriminant model does not represent the full joint distribution of words and events. We thus have a simpler inference process, which results into drastically reduced training times (15 692 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 692–701, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Figure 1: Part of a sentence and corresponding extracted events for the BioNLP 2013 Genia task. times faster for processing about 800 training documents). In short, we propose in this work a</context>
<context position="9469" citStr="Riedel and McCallum, 2011" startWordPosition="1513" endWordPosition="1516">vant for detection. Besides, rich features coding for (trigger, argument) pairs (Miwa et al., 2010) are only used by pipeline models for assigning arguments, whereas they could be useful for trigger detection as well. Global joint approaches (Riedel et al., 2009; McClosky et al., 2011) aim at solving the event extraction task at once, so as to resolve the drawbacks of pipeline models. In (McClosky et al., 2011), event annotations are converted into pseudo-syntactic representations and the task is solved as a syntactic extraction problem by traditional parsing methods. In (Riedel et al., 2009; Riedel and McCallum, 2011a; Riedel et al., 2011; Riedel and McCallum, 2011b), some models are proposed based on the maximization of a global score taking into account the annotations of nodes and edges in a graph representing each sentence. This maximization problem is formalized as an integer linear program with consistency constraints, and solved via dual decomposition. Such joint models perform very well (winner of the BioNLP 2011 GE task), but suffer from consequential computing costs, as all possible combinations of words are considered as potential events. In the following, we show that our model is able to reac</context>
<context position="18212" citStr="Riedel and McCallum, 2011" startWordPosition="3007" endWordPosition="3010"> The pairwise structure leads to a simple inference procedure, with a slight increase in computational complexity compared to pipeline models. We denote m = card(CS), the number of candidate entities, n = card(AS), the number of annotated proteins and m&apos; the number of detected triggers. The complexity of a pipeline model is O(m&apos;(n+m&apos;)), whereas that of our approach is O(m(n + m&apos;)). This implies more calls to the classifying mechanism, but this is not too penalizing, since SVMbased classification scales well with the number of examples. Besides, this is still cheaper than joint models such as (Riedel and McCallum, 2011a), whose complexity is O(m(n2 + m)). 4 Post-Processing This section describes the post-processing carried out once the (trigger, theme) pairs are detected and labeled as events. The goal is to look whether extra-arguments should be added to these extracted events. 4.1 Binding Theme Fusion This step attempts to merge several pairs labeled as Binding to create multiple arguments events. We take the set of extracted Binding events {(cα, aβ)} that share the same trigger cα, and all combinations {(cα, aβ, aγ)|γ =� Q} are classified by a binary SVM. Once a combination (cα, aβ, aγ) is predicted as a</context>
<context position="30212" citStr="Riedel and McCallum, 2011" startWordPosition="4996" endWordPosition="4999">roaches, but the joint models that were performing better in the previous challenge were not competing in 2013. As these joint models are quite tricky to train, we compare our system with joint models on the BioNLP 2011 GE task, where trustworthy performances have been publicly released. We train our model using the training and development sets available at the time of the challenge and we then get an evaluation on the same test data using the official test server maintained online by BioNLP organizers. Table 4 lists the results of our approach, its pipeline counterpart, and those of UCLEED (Riedel and McCallum, 2011a) and TEES (Bj[Pleaseinsertintopreamble]rne et al., 698 Event UCLEED SEARN TEES Pipeline Our approach Class counterpart SVT 73.5 71.8 n/a 71.8 74.0 BIN 48.8 45.8 n/a 40.0 50.5 REG 43.8 43.0 n/a 35.7 45.1 ALL 55.2 53.5 53.3 50.0 55.6 Table 4: F-scores on the test set of the BioNLP 2011 GE task. 2012), which are respectively the best performing joint model and best pipeline on this task. We also added SEARN (Vlachos and Craven, 2012), which is a hybrid between them.3 As for 2013 data, our system achieves a higher F-score on all event classes compared to its pipeline counterpart. The benefits of</context>
<context position="32223" citStr="Riedel and McCallum, 2011" startWordPosition="5328" endWordPosition="5331">neficial to consider pairwise interactions from beginning to end, but more complex dependencies seem not to be essential, especially since they come at a higher computational cost. 6.3 Training Durations In this last section, we propose to illustrate the lower complexity of our approach compared to UCLEED by providing durations for training both systems on BioNLP 2011 GE. These timings do not involve preprocessing but only running crossvalidation on the training set and evaluation on the development and test sets. For UCLEED, 3The results for UCLEED, TEES and SEARN models are reproduced from (Riedel and McCallum, 2011a; Bj[Pleaseinsertintopreamble]rne et al., 2012; Vlachos and Craven, 2012) respectively. 4We do not compare with the results of FAUST (Riedel et al., 2011), which achieved the best F-score on this task (56.0) because this is an ensemble of various models of UCLEED and of the Stanford system (McClosky et al., 2011), which makes it an unfair comparison. we used the code (in java &amp; scala) provided by the authors5 and we chose BioNLP 2011 GE because this code was primarily designed to run on it. Our code, in python, is publicly available from github.com/XiaoLiuAI/RUPEE. Experiments were conducted </context>
</contexts>
<marker>Riedel, McCallum, 2011</marker>
<rawString>S. Riedel and A. McCallum. 2011a. Fast and robust joint models for biomedical event extraction. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1– 12, Edinburgh, Scotland, UK., July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riedel</author>
<author>A McCallum</author>
</authors>
<title>Robust biomedical event extraction with dual decomposition and minimal domain adaptation.</title>
<date>2011</date>
<booktitle>In Proceedings of BioNLP Shared Task 2011 Workshop,</booktitle>
<pages>46--50</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="3665" citStr="Riedel and McCallum, 2011" startWordPosition="561" endWordPosition="564">oid the intermediate problem of associating isolated triggers to event types, relying on a tricky multi-label classification problem. Instead, we directly extract compounds of events in the form of (trigger, argument) pairs, simply relying on a multi-class problem, whereby (trigger, argument) pairs are associated to event types. Considering pairs of words also allows us to characterize examples by sophisticated joint features such as shortest path in the dependency parse tree, and hence to achieve much accurate trigger detection than pipeline models. Besides, compared to Markov random fields (Riedel and McCallum, 2011a), our discriminant model does not represent the full joint distribution of words and events. We thus have a simpler inference process, which results into drastically reduced training times (15 692 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 692–701, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Figure 1: Part of a sentence and corresponding extracted events for the BioNLP 2013 Genia task. times faster for processing about 800 training documents). In short, we propose in this work a</context>
<context position="9469" citStr="Riedel and McCallum, 2011" startWordPosition="1513" endWordPosition="1516">vant for detection. Besides, rich features coding for (trigger, argument) pairs (Miwa et al., 2010) are only used by pipeline models for assigning arguments, whereas they could be useful for trigger detection as well. Global joint approaches (Riedel et al., 2009; McClosky et al., 2011) aim at solving the event extraction task at once, so as to resolve the drawbacks of pipeline models. In (McClosky et al., 2011), event annotations are converted into pseudo-syntactic representations and the task is solved as a syntactic extraction problem by traditional parsing methods. In (Riedel et al., 2009; Riedel and McCallum, 2011a; Riedel et al., 2011; Riedel and McCallum, 2011b), some models are proposed based on the maximization of a global score taking into account the annotations of nodes and edges in a graph representing each sentence. This maximization problem is formalized as an integer linear program with consistency constraints, and solved via dual decomposition. Such joint models perform very well (winner of the BioNLP 2011 GE task), but suffer from consequential computing costs, as all possible combinations of words are considered as potential events. In the following, we show that our model is able to reac</context>
<context position="18212" citStr="Riedel and McCallum, 2011" startWordPosition="3007" endWordPosition="3010"> The pairwise structure leads to a simple inference procedure, with a slight increase in computational complexity compared to pipeline models. We denote m = card(CS), the number of candidate entities, n = card(AS), the number of annotated proteins and m&apos; the number of detected triggers. The complexity of a pipeline model is O(m&apos;(n+m&apos;)), whereas that of our approach is O(m(n + m&apos;)). This implies more calls to the classifying mechanism, but this is not too penalizing, since SVMbased classification scales well with the number of examples. Besides, this is still cheaper than joint models such as (Riedel and McCallum, 2011a), whose complexity is O(m(n2 + m)). 4 Post-Processing This section describes the post-processing carried out once the (trigger, theme) pairs are detected and labeled as events. The goal is to look whether extra-arguments should be added to these extracted events. 4.1 Binding Theme Fusion This step attempts to merge several pairs labeled as Binding to create multiple arguments events. We take the set of extracted Binding events {(cα, aβ)} that share the same trigger cα, and all combinations {(cα, aβ, aγ)|γ =� Q} are classified by a binary SVM. Once a combination (cα, aβ, aγ) is predicted as a</context>
<context position="30212" citStr="Riedel and McCallum, 2011" startWordPosition="4996" endWordPosition="4999">roaches, but the joint models that were performing better in the previous challenge were not competing in 2013. As these joint models are quite tricky to train, we compare our system with joint models on the BioNLP 2011 GE task, where trustworthy performances have been publicly released. We train our model using the training and development sets available at the time of the challenge and we then get an evaluation on the same test data using the official test server maintained online by BioNLP organizers. Table 4 lists the results of our approach, its pipeline counterpart, and those of UCLEED (Riedel and McCallum, 2011a) and TEES (Bj[Pleaseinsertintopreamble]rne et al., 698 Event UCLEED SEARN TEES Pipeline Our approach Class counterpart SVT 73.5 71.8 n/a 71.8 74.0 BIN 48.8 45.8 n/a 40.0 50.5 REG 43.8 43.0 n/a 35.7 45.1 ALL 55.2 53.5 53.3 50.0 55.6 Table 4: F-scores on the test set of the BioNLP 2011 GE task. 2012), which are respectively the best performing joint model and best pipeline on this task. We also added SEARN (Vlachos and Craven, 2012), which is a hybrid between them.3 As for 2013 data, our system achieves a higher F-score on all event classes compared to its pipeline counterpart. The benefits of</context>
<context position="32223" citStr="Riedel and McCallum, 2011" startWordPosition="5328" endWordPosition="5331">neficial to consider pairwise interactions from beginning to end, but more complex dependencies seem not to be essential, especially since they come at a higher computational cost. 6.3 Training Durations In this last section, we propose to illustrate the lower complexity of our approach compared to UCLEED by providing durations for training both systems on BioNLP 2011 GE. These timings do not involve preprocessing but only running crossvalidation on the training set and evaluation on the development and test sets. For UCLEED, 3The results for UCLEED, TEES and SEARN models are reproduced from (Riedel and McCallum, 2011a; Bj[Pleaseinsertintopreamble]rne et al., 2012; Vlachos and Craven, 2012) respectively. 4We do not compare with the results of FAUST (Riedel et al., 2011), which achieved the best F-score on this task (56.0) because this is an ensemble of various models of UCLEED and of the Stanford system (McClosky et al., 2011), which makes it an unfair comparison. we used the code (in java &amp; scala) provided by the authors5 and we chose BioNLP 2011 GE because this code was primarily designed to run on it. Our code, in python, is publicly available from github.com/XiaoLiuAI/RUPEE. Experiments were conducted </context>
</contexts>
<marker>Riedel, McCallum, 2011</marker>
<rawString>S. Riedel and A. McCallum. 2011b. Robust biomedical event extraction with dual decomposition and minimal domain adaptation. In Proceedings of BioNLP Shared Task 2011 Workshop, pages 46–50, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riedel</author>
<author>H-W Chun</author>
<author>T Takagi</author>
<author>J Tsujii</author>
</authors>
<title>A Markov logic approach to bio-molecular event extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task,</booktitle>
<pages>41--49</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="9106" citStr="Riedel et al., 2009" startWordPosition="1455" endWordPosition="1458">lassification problem because some words can participate in the definition of several events of different types. Detecting triggers in isolation of their arguments in steps (P1) and (P3) are ill-posed intermediate problems, since the notion of trigger is intrinsically tied to its argument. The latter brings contextual information that is indisputably relevant for detection. Besides, rich features coding for (trigger, argument) pairs (Miwa et al., 2010) are only used by pipeline models for assigning arguments, whereas they could be useful for trigger detection as well. Global joint approaches (Riedel et al., 2009; McClosky et al., 2011) aim at solving the event extraction task at once, so as to resolve the drawbacks of pipeline models. In (McClosky et al., 2011), event annotations are converted into pseudo-syntactic representations and the task is solved as a syntactic extraction problem by traditional parsing methods. In (Riedel et al., 2009; Riedel and McCallum, 2011a; Riedel et al., 2011; Riedel and McCallum, 2011b), some models are proposed based on the maximization of a global score taking into account the annotations of nodes and edges in a graph representing each sentence. This maximization pro</context>
</contexts>
<marker>Riedel, Chun, Takagi, Tsujii, 2009</marker>
<rawString>S. Riedel, H.-W. Chun, T. Takagi, and J. Tsujii. 2009. A Markov logic approach to bio-molecular event extraction. In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task, pages 41– 49, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riedel</author>
<author>D McClosky</author>
<author>M Surdeanu</author>
<author>A McCallum</author>
<author>C D Manning</author>
</authors>
<title>Model combination for event extraction in BioNLP</title>
<date>2011</date>
<booktitle>In Proceedings of BioNLP Shared Task 2011 Workshop,</booktitle>
<pages>51--55</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="9491" citStr="Riedel et al., 2011" startWordPosition="1517" endWordPosition="1520"> rich features coding for (trigger, argument) pairs (Miwa et al., 2010) are only used by pipeline models for assigning arguments, whereas they could be useful for trigger detection as well. Global joint approaches (Riedel et al., 2009; McClosky et al., 2011) aim at solving the event extraction task at once, so as to resolve the drawbacks of pipeline models. In (McClosky et al., 2011), event annotations are converted into pseudo-syntactic representations and the task is solved as a syntactic extraction problem by traditional parsing methods. In (Riedel et al., 2009; Riedel and McCallum, 2011a; Riedel et al., 2011; Riedel and McCallum, 2011b), some models are proposed based on the maximization of a global score taking into account the annotations of nodes and edges in a graph representing each sentence. This maximization problem is formalized as an integer linear program with consistency constraints, and solved via dual decomposition. Such joint models perform very well (winner of the BioNLP 2011 GE task), but suffer from consequential computing costs, as all possible combinations of words are considered as potential events. In the following, we show that our model is able to reach better accuracies th</context>
<context position="32378" citStr="Riedel et al., 2011" startWordPosition="5350" endWordPosition="5353"> computational cost. 6.3 Training Durations In this last section, we propose to illustrate the lower complexity of our approach compared to UCLEED by providing durations for training both systems on BioNLP 2011 GE. These timings do not involve preprocessing but only running crossvalidation on the training set and evaluation on the development and test sets. For UCLEED, 3The results for UCLEED, TEES and SEARN models are reproduced from (Riedel and McCallum, 2011a; Bj[Pleaseinsertintopreamble]rne et al., 2012; Vlachos and Craven, 2012) respectively. 4We do not compare with the results of FAUST (Riedel et al., 2011), which achieved the best F-score on this task (56.0) because this is an ensemble of various models of UCLEED and of the Stanford system (McClosky et al., 2011), which makes it an unfair comparison. we used the code (in java &amp; scala) provided by the authors5 and we chose BioNLP 2011 GE because this code was primarily designed to run on it. Our code, in python, is publicly available from github.com/XiaoLiuAI/RUPEE. Experiments were conducted on the same computer, with a quad-core Intel Xeon CPU and 16GB of RAM. Both codes are multi-threaded and used all 4 threads simultaneously. Under these con</context>
</contexts>
<marker>Riedel, McClosky, Surdeanu, McCallum, Manning, 2011</marker>
<rawString>S. Riedel, D. McClosky, M. Surdeanu, A. McCallum, and C. D. Manning. 2011. Model combination for event extraction in BioNLP 2011. In Proceedings of BioNLP Shared Task 2011 Workshop, pages 51– 55, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Sætre</author>
<author>M Miwa</author>
<author>K Yoshida</author>
<author>J Tsujii</author>
</authors>
<title>From protein-protein interaction to molecular event extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task,</booktitle>
<pages>103--106</pages>
<publisher>Association for</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="7341" citStr="Sætre et al., 2009" startWordPosition="1163" endWordPosition="1166">es sequences of tokens. The BioNLP GE task considers 9 types of events.1 Table 1 lists these events. The 9 event types may be merged into three broader categories: the first 5 (termed SVT) have a single theme argument; the Binding event (or BIN) can accept up to two theme arguments; the last 3 types (termed REG) also accept up to two arguments, a theme and an optional cause. REG events can be recursive because their arguments can be proteins or events. 2.2 Related Works Current approaches fall into two main categories: pipeline incremental models and global joint methods. Pipeline approaches (Sætre et al., 2009; Cohen et al., 2009; Quirk et al., 2011) are the simplest way to tackle the problem of event extraction. A sequence of specific classifiers are ran on the text to successively (P1) detect event triggers, (P2) assign them arguments, (P3) detect event triggers whose arguments can be events, and (P4) assign them arguments (steps (P3) and (P4) can be ran multiple times). Such systems are relatively easy to set up and experienced many successes: the TEES system (Björne et al., 2009; Bj[Pleaseinsertintopreamble]rne et al., 2012; Björne and Salakoski, 2013) won the BioNLP GE task in 2009 and ranked </context>
</contexts>
<marker>Sætre, Miwa, Yoshida, Tsujii, 2009</marker>
<rawString>R. Sætre, M. Miwa, K. Yoshida, and J. Tsujii. 2009. From protein-protein interaction to molecular event extraction. In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task, pages 103–106, Boulder, Colorado, June. Association for Computational Linguistics. S. Van Landeghem, F. Ginter, Y. Van de Peer, and T. Salakoski. 2011. Evex: A pubmed-scale resource for homology-based generalization of text mining predictions. In Proceedings of BioNLP 2011 Workshop, pages 28–37, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Veropoulos</author>
<author>C Campbell</author>
<author>N Cristianini</author>
</authors>
<title>Controlling the sensitivity of support vector machines. In</title>
<date>1999</date>
<booktitle>Proceedings of the International Joint Conference on Artificial Intelligence,</booktitle>
<pages>55--60</pages>
<editor>T. Dean, editor,</editor>
<contexts>
<context position="15243" citStr="Veropoulos et al., 1999" startWordPosition="2501" endWordPosition="2504">a single class, there is no need to address the more difficult multi-label problem encountered in standard pipeline approaches. An entity may still be assigned to several events, possibly of different types, through the allocation of labels to several pairs comprising this entity. Training SVMs For each event type, a series of binary linear SVMs is fitted to the available training data, using the implementation from scikit-learn.org. As events are rare, each binary classification problem is highly unbalanced. We thus use different losses for positive and negative examples (Morik et al., 1999; Veropoulos et al., 1999), resulting in two hyperparameters that are set by cross-validation, so as to maximize the F-score of the corresponding event type taken in isolation. For the SVT and BIN events, the training sets are all composed of the possible (candidate, argument) pairs PS = {pij = (ci, aj)|ci ∈ CS, aj ∈ AS} readily extracted from all training sentences, and they only differ in the definition of the positive and negative class, according to the true label associated to each pair. Creating the training sets for REG events is more complicated: since they can take events as arguments, new pairs are added to P</context>
</contexts>
<marker>Veropoulos, Campbell, Cristianini, 1999</marker>
<rawString>K. Veropoulos, C. Campbell, and N. Cristianini. 1999. Controlling the sensitivity of support vector machines. In T. Dean, editor, Proceedings of the International Joint Conference on Artificial Intelligence, pages 55–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Vlachos</author>
<author>M Craven</author>
</authors>
<title>Biomedical event extraction from abstracts and full papers using search-based structured prediction. BMC bioinformatics, 13(Suppl 11):S5.</title>
<date>2012</date>
<contexts>
<context position="10241" citStr="Vlachos and Craven, 2012" startWordPosition="1635" endWordPosition="1638">nnotations of nodes and edges in a graph representing each sentence. This maximization problem is formalized as an integer linear program with consistency constraints, and solved via dual decomposition. Such joint models perform very well (winner of the BioNLP 2011 GE task), but suffer from consequential computing costs, as all possible combinations of words are considered as potential events. In the following, we show that our model is able to reach better accuracies than joint models while being computationally much cheaper. A method based on the search-based structured prediction paradigm (Vlachos and Craven, 2012) has been proposed as an intermediate step between joint and pipeline approaches, by turning the structured prediction problem into a sequence of multiclass classification tasks. Our experiments demonstrate that, despite being conceptually simpler, our recursive pairwise model outperforms it. 3 Recursive Pairwise Model In this section, we present our recursive pairwise model. It directly extracts pairwise interactions between entities, thereby contrasting with the usual pipeline approaches, which require detecting triggers as an intermediate problem. Our approach proceeds in two steps: 1. Main</context>
<context position="16215" citStr="Vlachos and Craven, 2012" startWordPosition="2665" endWordPosition="2668"> they only differ in the definition of the positive and negative class, according to the true label associated to each pair. Creating the training sets for REG events is more complicated: since they can take events as arguments, new pairs are added to PS by considering all the events already detected, as sketched in Algorithm 1. Hence, the sets of training examples are not deterministically known before training, but depend on predictions of all other classifiers. Training directly on them requires to use either online algorithms or complex search-based structured prediction procedures as in (Vlachos and Craven, 2012). In this paper, we prefer to use instead the true labels yαβ during the training phase of REG and None classifiers: the training sets are then the enriched sets of possible (candidate, argument) pairs PS = {pij = (ci, aj)|ci ∈ CS, aj ∈ AS} ∪ {piα = (ci, eαβ)|ci ∈ CS, ∃β : yαβ =6 None}. This allows to know all training examples beforehand and hence to use standard batch SVM algorithms. The drawback is that, since extracted events in test are imperfect, this creates a divergence between training and testing scenarios, which can lead to degraded performance. However, as our experiments show, thi</context>
<context position="30648" citStr="Vlachos and Craven, 2012" startWordPosition="5071" endWordPosition="5074">ta using the official test server maintained online by BioNLP organizers. Table 4 lists the results of our approach, its pipeline counterpart, and those of UCLEED (Riedel and McCallum, 2011a) and TEES (Bj[Pleaseinsertintopreamble]rne et al., 698 Event UCLEED SEARN TEES Pipeline Our approach Class counterpart SVT 73.5 71.8 n/a 71.8 74.0 BIN 48.8 45.8 n/a 40.0 50.5 REG 43.8 43.0 n/a 35.7 45.1 ALL 55.2 53.5 53.3 50.0 55.6 Table 4: F-scores on the test set of the BioNLP 2011 GE task. 2012), which are respectively the best performing joint model and best pipeline on this task. We also added SEARN (Vlachos and Craven, 2012), which is a hybrid between them.3 As for 2013 data, our system achieves a higher F-score on all event classes compared to its pipeline counterpart. The benefits of the pairwise structure and the recursive process are larger here, thereby outperforming the overall F-score of TEES (no detailed results available), which itself performs better than our pipeline counterpart. Systematic improvements on all event classes are also observed compared to the joint model UCLEED and to the search-based structured prediction approach of SEARN. To our knowledge, our model thus reaches the best overall perfo</context>
<context position="32297" citStr="Vlachos and Craven, 2012" startWordPosition="5336" endWordPosition="5339"> complex dependencies seem not to be essential, especially since they come at a higher computational cost. 6.3 Training Durations In this last section, we propose to illustrate the lower complexity of our approach compared to UCLEED by providing durations for training both systems on BioNLP 2011 GE. These timings do not involve preprocessing but only running crossvalidation on the training set and evaluation on the development and test sets. For UCLEED, 3The results for UCLEED, TEES and SEARN models are reproduced from (Riedel and McCallum, 2011a; Bj[Pleaseinsertintopreamble]rne et al., 2012; Vlachos and Craven, 2012) respectively. 4We do not compare with the results of FAUST (Riedel et al., 2011), which achieved the best F-score on this task (56.0) because this is an ensemble of various models of UCLEED and of the Stanford system (McClosky et al., 2011), which makes it an unfair comparison. we used the code (in java &amp; scala) provided by the authors5 and we chose BioNLP 2011 GE because this code was primarily designed to run on it. Our code, in python, is publicly available from github.com/XiaoLiuAI/RUPEE. Experiments were conducted on the same computer, with a quad-core Intel Xeon CPU and 16GB of RAM. Bot</context>
</contexts>
<marker>Vlachos, Craven, 2012</marker>
<rawString>A. Vlachos and M. Craven. 2012. Biomedical event extraction from abstracts and full papers using search-based structured prediction. BMC bioinformatics, 13(Suppl 11):S5.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>