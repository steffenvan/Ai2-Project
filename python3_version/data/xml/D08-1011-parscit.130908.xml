<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998975">
Indirect-HMM-based Hypothesis Alignment for Combining Outputs
from Machine Translation Systems
</title>
<author confidence="0.999509">
Xiaodong He†, Mei Yang‡ *, Jianfeng Gao†, Patrick Nguyen†, and Robert Moore†
</author>
<affiliation confidence="0.8058445">
†Microsoft Research ‡Dept. of Electrical Engineering
One Microsoft Way University of Washington
</affiliation>
<address confidence="0.7895165">
Redmond, WA 98052 USA Seattle, WA 98195, USA
{xiaohe,jfgao, panguyen,
</address>
<email confidence="0.967384">
bobmoore}@microsoft.com
</email>
<sectionHeader confidence="0.99543" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997304352941177">
This paper presents a new hypothesis alignment method
for combining outputs of multiple machine translation
(MT) systems. An indirect hidden Markov model
(IHMM) is proposed to address the synonym matching
and word ordering issues in hypothesis alignment.
Unlike traditional HMMs whose parameters are trained
via maximum likelihood estimation (MLE), the
parameters of the IHMM are estimated indirectly from a
variety of sources including word semantic similarity,
word surface similarity, and a distance-based distortion
penalty. The IHMM-based method significantly
outperforms the state-of-the-art TER-based alignment
model in our experiments on NIST benchmark
datasets. Our combined SMT system using the
proposed method achieved the best Chinese-to-English
translation result in the constrained training track of the
2008 NIST Open MT Evaluation.
</bodyText>
<sectionHeader confidence="0.998956" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998926357142857">
System combination has been applied successfully
to various machine translation tasks. Recently,
confusion-network-based system combination
algorithms have been developed to combine
outputs of multiple machine translation (MT)
systems to form a consensus output (Bangalore, et
al. 2001, Matusov et al., 2006, Rosti et al., 2007,
Sim et al., 2007). A confusion network comprises a
sequence of sets of alternative words, possibly
including null’s, with associated scores. The
consensus output is then derived by selecting one
word from each set of alternatives, to produce the
sequence with the best overall score, which could
be assigned in various ways such as by voting, by
</bodyText>
<footnote confidence="0.7064675">
* Mei Yang performed this work when she was an intern with
Microsoft Research.
</footnote>
<page confidence="0.832371">
98
</page>
<email confidence="0.883086">
yangmei@u.washington.edu
</email>
<bodyText confidence="0.9996235">
using posterior probability estimates, or by using a
combination of these measures and other features.
Constructing a confusion network requires
choosing one of the hypotheses as the backbone
(also called “skeleton” in the literature), and other
hypotheses are aligned to it at the word level. High
quality hypothesis alignment is crucial to the
performance of the resulting system combination.
However, there are two challenging issues that
make MT hypothesis alignment difficult. First,
different hypotheses may use different
synonymous words to express the same meaning,
and these synonyms need to be aligned to each
other. Second, correct translations may have
different word orderings in different hypotheses
and these words need to be properly reordered in
hypothesis alignment.
In this paper, we propose an indirect hidden
Markov model (IHMM) for MT hypothesis
alignment. The HMM provides a way to model
both synonym matching and word ordering. Unlike
traditional HMMs whose parameters are trained
via maximum likelihood estimation (MLE), the
parameters of the IHMM are estimated indirectly
from a variety of sources including word semantic
similarity, word surface similarity, and a distance-
based distortion penalty, without using large
amount of training data. Our combined SMT
system using the proposed method gave the best
result on the Chinese-to-English test in the
constrained training track of the 2008 NIST Open
MT Evaluation (MT08).
</bodyText>
<sectionHeader confidence="0.994304" genericHeader="introduction">
2 Confusion-network-based MT system
combination
</sectionHeader>
<bodyText confidence="0.9962345">
The current state-of-the-art is confusion-network-
based MT system combination as described by
</bodyText>
<note confidence="0.8704565">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 98–107,
Honolulu, October 2008. c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.96153668">
Rosti and colleagues (Rosti et al., 2007a, Rosti et
al., 2007b). The major steps are illustrated in
Figure 1. In Fig. 1 (a), hypotheses from different
MT systems are first collected. Then in Fig. 1 (b),
one of the hypotheses is selected as the backbone
for hypothesis alignment. This is usually done by a
sentence-level minimum Bayes risk (MBR)
method which selects a hypothesis that has the
minimum average distance compared to all
hypotheses. The backbone determines the word
order of the combined output. Then as illustrated in
Fig. 1 (c), all other hypotheses are aligned to the
backbone. Note that in Fig. 1 (c) the symbol ε
denotes a null word, which is inserted by the
alignment normalization algorithm described in
section 3.4. Fig. 1 (c) also illustrates the handling
of synonym alignment (e.g., aligning “car” to
“sedan”), and word re-ordering of the hypothesis.
Then in Fig. 1 (d), a confusion network is
constructed based on the aligned hypotheses,
which consists of a sequence of sets in which each
word is aligned to a list of alternative words
(including null) in the same set. Then, a set of
global and local features are used to decode the
confusion network.
</bodyText>
<footnote confidence="0.83165525">
E1 he have good carEBaz=min
E2 he has nice sedangeE
E3 it a nice car _
E4 a sedan he has e.g., EB — E1
</footnote>
<figure confidence="0.269811166666667">
(a) hypothesis set (b) backbone selection
he have ε good car
he has ε nice sedan
it ε a nice car
he has a ε sedan
(c) hypothesis alignment (d) confusion network
</figure>
<figureCaption confidence="0.9892345">
Figure 1: Confusion-network-based MT system
combination.
</figureCaption>
<sectionHeader confidence="0.9745435" genericHeader="method">
3 Indirect-HMM-based Hypothesis
Alignment
</sectionHeader>
<bodyText confidence="0.999710125">
In confusion-network-based system combination
for SMT, a major difficulty is aligning hypotheses
to the backbone. One possible statistical model for
word alignment is the HMM, which has been
widely used for bilingual word alignment (Vogel et
al., 1996, Och and Ney, 2003). In this paper, we
propose an indirect-HMM method for monolingual
hypothesis alignment.
</bodyText>
<subsectionHeader confidence="0.824543">
3.1 IHMM for hypothesis alignment
</subsectionHeader>
<bodyText confidence="0.999204733333333">
Let denote the backbone,
�&apos; _ ( ,...,dj) a hypothesis to be aligned to e; ,
and the alignment that specifies
the position of the backbone word aligned to each
hypothesis word. We treat each word in the
backbone as an HMM state and the words in the
hypothesis as the observation sequence. We use a
first-order HMM, assuming that the emission
probability depends only on the
backbone word, and the transition probability
p(aj I aj_,,I) depends only on the position of the
last state and the length of the backbone. Treating
the alignment as hidden variable, the conditional
probability that the hypothesis is generated by the
backbone is given by
</bodyText>
<equation confidence="0.968785">
(1)
</equation>
<bodyText confidence="0.999958545454545">
As in HMM-based bilingual word alignment
(Och and Ney, 2003), we also associate a null with
each backbone word to allow generating
hypothesis words that do not align to any backbone
word.
In HMM-based hypothesis alignment, emission
probabilities model the similarity between a
backbone word and a hypothesis word, and will be
referred to as the similarity model. The transition
probabilities model word reordering, and will be
called the distortion model.
</bodyText>
<subsectionHeader confidence="0.999915">
3.2 Estimation of the similarity model
</subsectionHeader>
<bodyText confidence="0.998960875">
The similarity model, which specifies the emission
probabilities of the HMM, models the similarity
between a backbone word and a hypothesis word.
Since both words are in the same language, the
similarity model can be derived based on both
semantic similarity and surface similarity, and the
overall similarity model is a linear interpolation of
the two:
</bodyText>
<equation confidence="0.844357">
p(e�j |ei)=a•psem(e�j |ei)+(1—a)• psur(e�j |ei) (2)
EB he have ε good car
E4 a ε sedan he has
</equation>
<page confidence="0.976732">
99
</page>
<bodyText confidence="0.999486285714286">
where and reflect the
semantic and surface similarity between and
e; , respectively, and α is the interpolation factor.
Since the semantic similarity between two
target words is source-dependent, the semantic
similarity model is derived by using the source
word sequence as a hidden layer:
</bodyText>
<equation confidence="0.698487">
(3)
</equation>
<bodyText confidence="0.999287368421053">
where is the source sentence.
Moreover, in order to handle the case that two
target words are synonyms but neither of them has
counter-part in the source sentence, a null is
introduced on the source side, which is represented
by f0. The last step in (3) assumes that first ei
generates all source words including null. Then ej’
is generated by all source words including null.
In the common SMT scenario where a large
amount of bilingual parallel data is available, we
can estimate the translation probabilities from a
source word to a target word and vice versa via
conventional bilingual word alignment. Then both
p(fk I e;) and in (3) can be derived:
where is the translation model from
the source-to-target word alignment model, and
p(fk I e;) , which enforces the sum-to-1 constraint
over all words in the source sentence, takes the
following form,
</bodyText>
<equation confidence="0.96543975">
p r s
pr s
p (fk  |ei)

</equation>
<bodyText confidence="0.997510263157894">
where A2s (fk I e;) is the translation model from
the target-to-source word alignment model. In our
method, A2s (null I e;) for all target words is
simply a constant pnull, whose value is optimized
on held-out data 1.
The surface similarity model can be estimated
in several ways. A very simple model could be
based on exact match: the surface similarity model,
per,,. (elj I , would take the value 1.0 if e’= e, and
0 otherwise 2 . However, a smoothed surface
similarity model is used in our method. If the target
language uses alphabetic orthography, as English
does, we treat words as letter sequences and the
similarity measure can be the length of the longest
matched prefix (LMP) or the length of the longest
common subsequence (LCS) between them. Then,
this raw similarity measure is transformed to a
surface similarity score between 0 and 1 through
an exponential mapping,
</bodyText>
<equation confidence="0.608831">
(4)
</equation>
<bodyText confidence="0.999230083333333">
where is computed as
and is the raw similarity measure of ej’
ei, which is the length of the LMP or LCS of ej’
and ei. and p is a smoothing factor that
characterizes the mapping, Thus as p approaches
infinity, backs off to the exact match
model. We found the smoothed similarity model of
(4) yields slightly better results than the exact
match model. Both LMP- and LCS- based methods
achieve similar performance but the computation
of LMP is faster. Therefore, we only report results
of the LMP-based smoothed similarity model.
</bodyText>
<equation confidence="0.68206">
p.2, ( � i   |null )
</equation>
<subsectionHeader confidence="0.99724">
3.3 Estimation of the distortion model
</subsectionHeader>
<bodyText confidence="0.9969102">
The distortion model, which specifies the transition
probabilities of the HMM, models the first-order
dependencies of word ordering. In bilingual
HMM-based word alignment, it is commonly
assumed that transition probabilities
</bodyText>
<footnote confidence="0.494622666666667">
1 The other direction, , is available from the
source-to-target translation model.
2 Usually a small back-off value is assigned instead of 0.
</footnote>
<equation confidence="0.963983125">
(fk |ei)
2
K

(fk  |ei)
2
k
0
</equation>
<page confidence="0.803712">
100
</page>
<bodyText confidence="0.9992965">
Following Och and Ney (2003), we use a fixed
value p0 for the probability of jumping to a null
state, which can be optimized on held-out data, and
the overall distortion model becomes
</bodyText>
<equation confidence="0.885729333333333">
p(aj = i I aj_l = [J) depend only on the jump
distance (i - i&apos;) (Vogel et al., 1996):
(5)
</equation>
<bodyText confidence="0.9999649">
As suggested by Liang et al. (2006), we can
group the distortion parameters {c(d)}, d= i - i&apos;,
into a few buckets. In our implementation, 11
buckets are used for c(≤-4), c(-3), ... c(0), ..., c(5),
c(≥6). The probability mass for transitions with
jump distance larger than 6 and less than -4 is
uniformly divided. By doing this, only a handful of
c(d) parameters need to be estimated. Although it
is possible to estimate them using the EM
algorithm on a small development set, we found
that a particularly simple model, described below,
works surprisingly well in our experiments.
Since both the backbone and the hypothesis are
in the same language, It seems intuitive that the
distortion model should favor monotonic
alignment and only allow non-monotonic
alignment with a certain penalty. This leads us to
use a distortion model of the following form,
where K is a tuning factor optimized on held-out
data.
</bodyText>
<equation confidence="0.753215">
, d= –4, ..., 6 (6)
</equation>
<bodyText confidence="0.9955516">
As shown in Fig. 2, the value of distortion score
peaks at d=1, i.e., the monotonic alignment, and
decays for non-monotonic alignments depending
on how far it diverges from the monotonic
alignment.
</bodyText>
<figure confidence="0.947853">
1.0
c(d)
0.0
-4 1 6
</figure>
<figureCaption confidence="0.978609">
Figure 2, the distance-based distortion parameters
computed according to (6), where K=2.
</figureCaption>
<subsectionHeader confidence="0.997611">
3.4 Alignment normalization
</subsectionHeader>
<bodyText confidence="0.99992">
Given an HMM, the Viterbi alignment algorithm
can be applied to find the best alignment between
the backbone and the hypothesis,
</bodyText>
<equation confidence="0.857733">
(7)
</equation>
<bodyText confidence="0.999843769230769">
However, the alignment produced by the
algorithm cannot be used directly to build a
confusion network. There are two reasons for this.
First, the alignment produced may contain 1-N
mappings between the backbone and the
hypothesis whereas 1-1 mappings are required in
order to build a confusion network. Second, if
hypothesis words are aligned to a null in the
backbone or vice versa, we need to insert actual
nulls into the right places in the hypothesis and the
backbone, respectively. Therefore, we need to
normalize the alignment produced by Viterbi
search.
</bodyText>
<equation confidence="0.983372833333333">
EB ... e2 ε2 ...
...
Eh e1&apos; e2&apos; e3&apos; e4&apos;
(a) hypothesis words are aligned to the backbone null
EB e1 ε1 e2 ε2 e3 ε3
Eh e1&apos; e2&apos; ...
</equation>
<listItem confidence="0.417427">
(b) a backbone word is aligned to no hypothesis word
</listItem>
<figureCaption confidence="0.999279">
Figure 3: illustration of alignment normalization
</figureCaption>
<bodyText confidence="0.990255">
First, whenever more than one hypothesis
words are aligned to one backbone word, we keep
the link which gives the highest occupation
probability computed via the forward-backward
algorithm. The other hypothesis words originally
</bodyText>
<table confidence="0.8964955">
d
...
ε e2 ε ε
e2&apos; e3&apos; e4&apos;
... e1 e2 e3 ...
ε e1&apos;
</table>
<page confidence="0.994423">
101
</page>
<bodyText confidence="0.99991915">
aligned to the backbone word will be aligned to the
null associated with that backbone word.
Second, for the hypothesis words that are
aligned to a particular null on the backbone side, a
set of nulls are inserted around that backbone word
associated with the null such that no links cross
each other. As illustrated in Fig. 3 (a), if a
hypothesis word e2’ is aligned to the backbone
word e2, a null is inserted in front of the backbone
word e2 linked to the hypothesis word e1’ that
comes before e2’. Nulls are also inserted for other
hypothesis words such as e3’ and e4’ after the
backbone word e2. If there is no hypothesis word
aligned to that backbone word, all nulls are
inserted after that backbone word .3
For a backbone word that is aligned to no
hypothesis word, a null is inserted on the
hypothesis side, right after the hypothesis word
which is aligned to the immediately preceding
backbone word. An example is shown in Fig. 3 (b).
</bodyText>
<sectionHeader confidence="0.99994" genericHeader="method">
4 Related work
</sectionHeader>
<bodyText confidence="0.99995448">
The two main hypothesis alignment methods for
system combination in the previous literature are
GIZA++ and TER-based methods. Matusov et al.
(2006) proposed using GIZA++ to align words
between different MT hypotheses, where all
hypotheses of the test corpus are collected to create
hypothesis pairs for GIZA++ training. This
approach uses the conventional HMM model
bootstrapped from IBM Model-1 as implemented
in GIZA++, and heuristically combines results
from aligning in both directions. System
combination based on this approach gives an
improvement over the best single system.
However, the number of hypothesis pairs for
training is limited by the size of the test corpus.
Also, MT hypotheses from the same source
sentence are correlated with each other and these
hypothesis pairs are not i.i.d. data samples.
Therefore, GIZA++ training on such a data set may
be unreliable.
Bangalore et al. (2001) used a multiple string-
matching algorithm based on Levenshtein edit
distance, and later Sim et al. (2007) and Rosti et al.
(2007) extended it to a TER-based method for
hypothesis alignment. TER (Snover et al., 2006)
</bodyText>
<footnote confidence="0.743972">
3 This only happens if no hypothesis word is aligned to a
backbone word but some hypothesis words are aligned to the
null associated with that backbone word.
</footnote>
<bodyText confidence="0.999848022222223">
measures the minimum number of edits, including
substitution, insertion, deletion, and shift of blocks
of words, that are needed to modify a hypothesis so
that it exactly matches the other hypothesis. The
best alignment is the one that gives the minimum
number of translation edits. TER-based confusion
network construction and system combination has
demonstrated superior performance on various
large-scale MT tasks (Rosti. et al, 2007). However,
when searching for the optimal alignment, the
TER-based method uses a strict surface hard match
for counting edits. Therefore, it is not able to
handle synonym matching well. Moreover,
although TER-based alignment allows phrase
shifts to accommodate the non-monotonic word
ordering, all non-monotonic shifts are penalized
equally no matter how short or how long the move
is, and this penalty is set to be the same as that for
substitution, deletion, and insertion edits.
Therefore, its modeling of non-monotonic word
ordering is very coarse-grained.
In contrast to the GIZA++-based method, our
IHMM-based method has a similarity model
estimated using bilingual word alignment HMMs
that are trained on a large amount of bi-text data.
Moreover, the surface similarity information is
explicitly incorporated in our model, while it is
only used implicitly via parameter initialization for
IBM Model-1 training by Matusov et al. (2006).
On the other hand, the TER-based alignment
model is similar to a coarse-grained, non-
normalized version of our IHMM, in which the
similarity model assigns no penalty to an exact
surface match and a fixed penalty to all
substitutions, insertions, and deletions, and the
distortion model simply assigns no penalty to a
monotonic jump, and a fixed penalty to all other
jumps, equal to the non-exact-match penalty in the
similarity model.
There have been other hypothesis alignment
methods. Karakos, et al. (2008) proposed an ITG-
based method for hypothesis alignment, Rosti et al.
(2008) proposed an incremental alignment method,
and a heuristic-based matching algorithm was
proposed by Jayaraman and Lavie (2005).
</bodyText>
<sectionHeader confidence="0.998963" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.983716333333333">
In this section, we evaluate our IHMM-based
hypothesis alignment method on the Chinese-to-
English (C2E) test in the constrained training track
</bodyText>
<page confidence="0.997857">
102
</page>
<bodyText confidence="0.99999">
of the 2008 NIST Open MT Evaluation (NIST,
2008). We compare to the TER-based method used
by Rosti et al. (2007). In the following
experiments, the NIST BLEU score is used as the
evaluation metric (Papineni et al., 2002), which is
reported as a percentage in the following sections.
</bodyText>
<subsectionHeader confidence="0.993929">
5.1 Implementation details
</subsectionHeader>
<bodyText confidence="0.979853203703704">
In our implementation, the backbone is selected
with MBR. Only the top hypothesis from each
single system is considered as a backbone. A
uniform posteriori probability is assigned to all
hypotheses. TER is used as loss function in the
MBR computation.
Similar to (Rosti et al., 2007), each word in the
confusion network is associated with a word
posterior probability. Given a system S, each of its
hypotheses is assigned with a rank-based score of
1/(1+r)η, where r is the rank of the hypothesis, and
η is a rank smoothing parameter. The system
specific rank-based score of a word w for a given
system S is the sum of all the rank-based scores of
the hypotheses in system S that contain the word w
at the given position (after hypothesis alignment).
This score is then normalized by the sum of the
scores of all the alternative words at the same
position and from the same system S to generate
the system specific word posterior. Then, the total
word posterior of w over all systems is a sum of
these system specific posteriors weighted by
system weights.
Beside the word posteriors, we use language
model scores and a word count as features for
confusion network decoding.
Therefore, for an M-way system combination
that uses N LMs, a total of M+N+1 decoding
parameters, including M-1 system weights, one
rank smoothing factor, N language model weights,
and one weight for the word count feature, are
optimized using Powell’s method (Brent, 1973) to
maximize BLEU score on a development set4 .
Two language models are used in our
experiments. One is a trigram model estimated
from the English side of the parallel training data,
and the other is a 5-gram model trained on the
English GigaWord corpus from LDC using the
MSRLM toolkit (Nguyen et al, 2007).
4 The parameters of IHMM are not tuned by maximum-BLEU
training.
In order to reduce the fluctuation of BLEU
scores caused by the inconsistent translation output
length, an unsupervised length adaptation method
has been devised. We compute an expected length
ratio between the MT output and the source
sentences on the development set after maximum-
BLEU training. Then during test, we adapt the
length of the translation output by adjusting the
weight of the word count feature such that the
expected output/source length ratio is met. In our
experiments, we apply length adaptation to the
system combination output at the level of the
whole test corpus.
</bodyText>
<subsectionHeader confidence="0.995139">
5.2 Development and test data
</subsectionHeader>
<bodyText confidence="0.999984">
The development (dev) set used for system
combination parameter training contains 1002
sentences sampled from the previous NIST MT
Chinese-to-English test sets: 35% from MT04,
55% from MT05, and 10% from MT06-newswire.
The test set is the MT08 Chinese-to-English
“current” test set, which includes 1357 sentences
from both newswire and web-data genres. Both
dev and test sets have four references per sentence.
As inputs to the system combination, 10-best
hypotheses for each source sentence in the dev and
test sets are collected from each of the eight single
systems. All outputs on the MT08 test set were
true-cased before scoring using a log-linear
conditional Markov model proposed by Toutanova
et al. (2008). However, to save computation effort,
the results on the dev set are reported in case
insensitive BLEU (ciBLEU) score instead.
</bodyText>
<subsectionHeader confidence="0.993857">
5.3 Experimental results
</subsectionHeader>
<bodyText confidence="0.998808785714286">
In our main experiments, outputs from a total of
eight single MT systems were combined. As listed
in Table 1, Sys-1 is a tree-to-string system
proposed by Quirk et al., (2005); Sys-2 is a phrase-
based system with fast pruning proposed by Moore
and Quirk (2008); Sys-3 is a phrase-based system
with syntactic source reordering proposed by
Wang et al. (2007a); Sys-4 is a syntax-based pre-
ordering system proposed by Li et. al. (2007); Sys-
5 is a hierarchical system proposed by Chiang
(2007); Sys-6 is a lexicalized re-ordering system
proposed by Xiong et al. (2006); Sys-7 is a two-
pass phrase-based system with adapted LM
proposed by Foster and Kuhn (2007); and Sys-8 is
</bodyText>
<page confidence="0.998747">
103
</page>
<bodyText confidence="0.999608538461539">
a hierarchical system with two-pass rescoring
using a parser-based LM proposed by Wang et al.,
(2007b). All systems were trained within the
confines of the constrained training condition of
NIST MT08 evaluation. These single systems are
optimized with maximum-BLEU training on
different subsets of the previous NIST MT test
data. The bilingual translation models used to
compute the semantic similarity are from the word-
dependent HMMs proposed by He (2007), which
are trained on two million parallel sentence-pairs
selected from the training corpus allowed by the
constrained training condition of MT08.
</bodyText>
<subsubsectionHeader confidence="0.837604">
5.3.1 Comparison with TER alignment
</subsubsectionHeader>
<bodyText confidence="0.998111096774193">
In the IHMM-based method, the smoothing
factor for surface similarity model is set to ρ = 3,
the interpolation factor of the overall similarity
model is set to α = 0.3, and the controlling factor of
the distance-based distortion parameters is set to
K=2. These settings are optimized on the dev set.
Individual system results and system combination
results using both IHMM and TER alignment, on
both the dev and test sets, are presented in Table 1.
The TER-based hypothesis alignment tool used in
our experiments is the publicly available TER Java
program, TERCOM (Snover et al., 2006). Default
settings of TERCOM are used in the following
experiments.
On the dev set, the case insensitive BLEU score
of the IHMM-based 8-way system combination
output is about 5.8 points higher than that of the
best single system. Compared to the TER-based
method, the IHMM-based method is about 1.5
BLEU points better. On the MT08 test set, the
IHMM-based system combination gave a case
sensitive BLEU score of 30.89%. It outperformed
the best single system by 4.7 BLEU points and the
TER-based system combination by 1.0 BLEU
points. Note that the best single system on the dev
set and the test set are different. The different
single systems are optimized on different tuning
sets, so this discrepancy between dev set and test
set results is presumably due to differing degrees
of mismatch between the dev and test sets and the
various tuning sets.
</bodyText>
<tableCaption confidence="0.942964">
Table 1. Results of single and combined systems
on the dev set and the MT08 test set
</tableCaption>
<table confidence="0.999283833333333">
System Dev MT08
ciBLEU% BLEU%
System 1 34.08 21.75
System 2 33.78 20.42
System 3 34.75 21.69
System 4 37.85 25.52
System 5 37.80 24.57
System 6 37.28 24.40
System 7 32.37 25.51
System 8 34.98 26.24
TER 42.11 29.89
IHMM 43.62 30.89
</table>
<bodyText confidence="0.998288647058824">
In order to evaluate how well our method
performs when we combine more systems, we
collected MT outputs on MT08 from seven
additional single systems as summarized in Table
2. These systems belong to two groups. Sys-9 to
Sys-12 are in the first group. They are syntax-
augmented hierarchical systems similar to those
described by Shen et al. (2008) using different
Chinese word segmentation and language models.
The second group has Sys-13 to Sys-15. Sys-13 is
a phrasal system proposed by Koehn et al. (2003),
Sys-14 is a hierarchical system proposed by
Chiang (2007), and Sys-15 is a syntax-based
system proposed by Galley et al. (2006). All seven
systems were trained within the confines of the
constrained training condition of NIST MT08
evaluation.
We collected 10-best MT outputs only on the
MT08 test set from these seven extra systems. No
MT outputs on our dev set are available from them
at present. Therefore, we directly adopt system
combination parameters trained for the previous 8-
way system combination, except the system
weights, which are re-set by the following
heuristics: First, the total system weight mass 1.0 is
evenly divided among the three groups of single
systems: {Sys-1~8}, {Sys-9~12}, and {Sys-
13~15}. Each group receives a total system weight
mass of 1/3. Then the weight mass is further
divided in each group: in the first group, the
original weights of systems 1~8 are multiplied by
1/3; in the second and third groups, the weight
mass is evenly distributed within the group, i.e.,
1/12 for each system in group 2, and 1/9 for each
</bodyText>
<page confidence="0.997876">
104
</page>
<bodyText confidence="0.998424214285714">
system in group 35. Length adaptation is applied to
control the final output length, where the same
expected length ratio of the previous 8-way system
combination is adopted.
The results of the 15-way system combination
are presented in Table 3. It shows that the IHMM-
based method is still about 1 BLEU point better
than the TER-based method. Moreover, combining
15 single systems gives an output that has a NIST
BLEU score of 34.82%, which is 3.9 points better
than the best submission to the NIST MT08
constrained training track (NIST, 2008). To our
knowledge, this is the best result reported on this
task.
</bodyText>
<tableCaption confidence="0.942834">
Table 2. Results of seven additional single systems
on the NIST MT08 test set
</tableCaption>
<table confidence="0.99968">
System MT08
BLEU%
System 9 29.59
System 10 29.57
System 11 29.64
System 12 29.85
System 13 25.53
System 14 26.04
System 15 29.70
</table>
<tableCaption confidence="0.930707">
Table 3. Results of the 15-way system combination
on the NIST MT08 C2E test set
</tableCaption>
<figure confidence="0.3410595">
Sys. Comb. MT08
BLEU%
TER 33.81
IHMM 34.82
</figure>
<subsubsectionHeader confidence="0.37571">
5.3.2 Effect of the similarity model
</subsubsectionHeader>
<bodyText confidence="0.99992825">
In this section, we evaluate the effect of the
semantic similarity model and the surface
similarity model by varying the interpolation
weight α of (2). The results on both the dev and
test sets are reported in Table 4. In one extreme
case, α = 1, the overall similarity model is based
only on semantic similarity. This gives a case
insensitive BLEU score of 41.70% and a case
sensitive BLEU score of 28.92% on the dev and
test set, respectively. The accuracy is significantly
improved to 43.62% on the dev set and 30.89% on
test set when α = 0.3. In another extreme case, α =
</bodyText>
<footnote confidence="0.935389666666667">
5 This is just a rough guess because no dev set is available. We
believe a better set of system weights could be obtained if MT
outputs on a common dev set were available.
</footnote>
<bodyText confidence="0.9978875">
0, in which only the surface similarity model is
used for the overall similarity model, the
performance degrades by about 0.2 point.
Therefore, the surface similarity information seems
more important for monolingual hypothesis
alignment, but both sub-models are useful.
</bodyText>
<tableCaption confidence="0.997042">
Table 4. Effect of the similarity model
</tableCaption>
<table confidence="0.889671142857143">
Dev Test
ciBLEU% BLEU%
1.0 41.70 28.92
0.7 42.86 30.50
0.5 43.11 30.94
0.3 43.62 30.89
0.0 43.35 30.73
</table>
<subsubsectionHeader confidence="0.720662">
5.3.3 Effect of the distortion model
</subsubsectionHeader>
<bodyText confidence="0.99989225">
We investigate the effect of the distance-based
distortion model by varying the controlling factor
K in (6). For example, setting K=1.0 gives a linear-
decay distortion model, and setting K=2.0 gives a
quadratic smoothed distance-based distortion
model. As shown in Table 5, the optimal result can
be achieved using a properly smoothed distance-
based distortion model.
</bodyText>
<tableCaption confidence="0.984746">
Table 5. Effect of the distortion model
</tableCaption>
<table confidence="0.783835833333333">
Dev Test
ciBLEU% BLEU%
K=1.0 42.94 30.44
K=2.0 43.62 30.89
K=4.0 43.17 30.30
K=8.0 43.09 30.01
</table>
<sectionHeader confidence="0.9934" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999868142857143">
Synonym matching and word ordering are two
central issues for hypothesis alignment in
confusion-network-based MT system combination.
In this paper, an IHMM-based method is proposed
for hypothesis alignment. It uses a similarity model
for synonym matching and a distortion model for
word ordering. In contrast to previous methods, the
similarity model explicitly incorporates both
semantic and surface word similarity, which is
critical to monolingual word alignment, and a
smoothed distance-based distortion model is used
to model the first-order dependency of word
ordering, which is shown to be better than simpler
approaches.
</bodyText>
<equation confidence="0.9250714">
α =
α =
α =
α =
α =
</equation>
<page confidence="0.99617">
105
</page>
<bodyText confidence="0.99992">
Our experimental results show that the IHMM-
based hypothesis alignment method gave superior
results on the NIST MT08 C2E test set compared
to the TER-based method. Moreover, we show that
our system combination method can scale up to
combining more systems and produce a better
output that has a case sensitive BLEU score of
34.82, which is 3.9 BLEU points better than the
best official submission of MT08.
</bodyText>
<sectionHeader confidence="0.969888" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.6757228">
The authors are grateful to Chris Quirk, Arul
Menezes, Kristina Toutanova, William Dolan, Mu
Li, Chi-Ho Li, Dongdong Zhang, Long Jiang,
Ming Zhou, George Foster, Roland Kuhn, Jing
Zheng, Wen Wang, Necip Fazil Ayan, Dimitra
Vergyri, Nicolas Scheffer, Andreas Stolcke, Kevin
Knight, Jens-Soenke Voeckler, Spyros Matsoukas,
and Antti-Veikko Rosti for assistance with the MT
systems and/or for the valuable suggestions and
discussions.
</bodyText>
<sectionHeader confidence="0.99585" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999791373493976">
Srinivas Bangalore, German Bordel, and Giuseppe
Riccardi. 2001. Computing consensus translation
from multiple machine translation systems. In Proc.
of IEEE ASRU, pp. 351–354.
Richard Brent, 1973. Algorithms for Minimization
without Derivatives. Prentice-Hall, Chapter 7.
David Chiang. 2007. Hierarchical phrase-based
translation. Computational Linguistics, 33(2):201–
228.
George Foster and Roland Kuhn. 2007. Mixture-Model
Adaptation for SMT. In Proc. of the Second ACL
Workshop on Statistical Machine Translation. pp.
128 – 136.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang and Ignacio
Thayer. 2006. Scalable Inference and Training of
Context-Rich Syntactic Translation Models. In Proc.
of COLING-ACL, pp. 961–968.
Xiaodong He. 2007. Using Word-Dependent Transition
Models in HMM based Word Alignment for
Statistical Machine Translation. In Proc. of the
Second ACL Workshop on Statistical Machine
Translation.
Shyamsundar Jayaraman and Alon Lavie. 2005. Multi-
engine machine translation guided by explicit word
matching. In Proc. of EAMT. pp. 143 – 152.
Damianos Karakos, Jason Eisner, Sanjeev Khudanpur,
and Markus Dreyer. 2008. Machine Translation
System Combination using ITG-based Alignments.
In Proc. of ACL-HLT, pp. 81–84.
Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li, Ming
Zhou, Yi Guan. 2007. A Probabilistic Approach to
Syntax-based Reordering for Statistical Machine
Translation. In Proc. of ACL. pp. 720 – 727.
Percy Liang, Ben Taskar, and Dan Klein. 2006.
Alignment by Agreement. In Proc. of NAACL. pp
104 – 111.
Evgeny Matusov, Nicola Ueffing, and Hermann Ney.
2006. Computing consensus translation from
multiple machine translation systems using enhanced
hypotheses alignment. In Proc. of EACL, pp. 33–40.
Robert Moore and Chris Quirk. 2007. Faster Beam-
Search Decoding for Phrasal Statistical Machine
Translation. In Proc. of MT Summit XI.
Patrick Nguyen, Jianfeng Gao and Milind Mahajan.
2007. MSRLM: a scalable language modeling
toolkit. Microsoft Research Technical Report MSR-
TR-2007-144.
NIST. 2008. The 2008 NIST Open Machine Translation
Evaluation. www.nist.gov/speech/tests/mt/2008/doc/
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1):19–51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proc. of ACL,
pp. 311–318.
Koehn, Philipp, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase based translation. In Proc. of
NAACL. pp. 48 – 54.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005.
Dependency treelet translation: Syntactically
informed phrasal SMT. In Proc. of ACL. pp. 271–
279.
Antti-Veikko I. Rosti, Bing Xiang, Spyros Matsoukas,
Richard Schwartz, Necip Fazil Ayan, and Bonnie J.
Dorr. 2007a. Combining outputs from multiple
machine translation systems. In Proc. of NAACL-
HLT, pp. 228–235.
Antti-Veikko I. Rosti, Spyros Matsoukas, and Richard
Schwartz. 2007b. Improved Word-Level System
Combination for Machine Translation. In Proc. of
ACL, pp. 312–319.
Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas,
and Richard Schwartz. 2008. Incremental Hypothesis
Alignment for Building Confusion Networks with
Application to Machine Translation System
Combination, In Proc. of the Third ACL Workshop
on Statistical Machine Translation, pp. 183–186.
Libin Shen, Jinxi Xu, Ralph Weischedel. 2008. A New
String-to-Dependency Machine Translation
Algorithm with a Target Dependency Language
Model. In Proc. of ACL-HLT, pp. 577–585.
</reference>
<page confidence="0.934977">
106
</page>
<reference confidence="0.999758">
Khe Chai Sim, William J. Byrne, Mark J.F. Gales,
Hichem Sahbi, and Phil C. Woodland. 2007.
Consensus network decoding for statistical machine
translation system combination. In Proc. of ICASSP,
vol. 4. pp. 105–108.
Matthew Snover, Bonnie Dorr, Rich Schwartz, Linnea
Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proc. of AMTA.
Kristina Toutanova, Hisami Suzuki and Achim Ruopp.
2008. Applying Morphology Generation Models to
Machine Translation. In Proc. of ACL. pp. 514 – 522.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based Word Alignment In Statistical
Translation. In Proc. of COLING. pp. 836-841.
Chao Wang, Michael Collins, and Philipp Koehn.
2007a. Chinese Syntactic Reordering for Statistical
Machine Translation. In Proc. of EMNLP-CoNLL.
pp. 737-745.
Wen Wang, Andreas Stolcke, Jing Zheng. 2007b.
Reranking Machine Translation Hypotheses With
Structured and Web-based Language Models. In
Proc. of IEEE ASRU. pp. 159 – 164.
Deyi Xiong, Qun Liu and Shouxun Lin. 2006.
Maximum Entropy Based Phrase Reordering Model
for Statistical Machine Translation. In Proc. of ACL.
pp. 521 – 528.
</reference>
<page confidence="0.998701">
107
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.320418">
<title confidence="0.998383">Indirect-HMM-based Hypothesis Alignment for Combining from Machine Translation Systems</title>
<author confidence="0.998754">Mei Jianfeng Patrick</author>
<author confidence="0.998754">Robert</author>
<affiliation confidence="0.999369">Research of Electrical Engineering</affiliation>
<address confidence="0.782807">One Microsoft Way University of Washington Redmond, WA 98052 USA Seattle, WA 98195, USA</address>
<email confidence="0.990634">xiaohe@microsoft.com</email>
<email confidence="0.990634">jfgao@microsoft.com</email>
<email confidence="0.990634">bobmoore@microsoft.com</email>
<abstract confidence="0.999648">This paper presents a new hypothesis alignment method for combining outputs of multiple machine translation (MT) systems. An indirect hidden Markov model (IHMM) is proposed to address the synonym matching and word ordering issues in hypothesis alignment. Unlike traditional HMMs whose parameters are trained via maximum likelihood estimation (MLE), the of the IHMM are estimated a variety of sources including word semantic similarity, word surface similarity, and a distance-based distortion penalty. The IHMM-based method significantly outperforms the state-of-the-art TER-based alignment model in our experiments on NIST benchmark datasets. Our combined SMT system using the proposed method achieved the best Chinese-to-English translation result in the constrained training track of the</abstract>
<address confidence="0.582798">2008 NIST Open MT Evaluation.</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>German Bordel</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems.</title>
<date>2001</date>
<booktitle>In Proc. of IEEE ASRU,</booktitle>
<pages>351--354</pages>
<contexts>
<context position="1519" citStr="Bangalore, et al. 2001" startWordPosition="198" endWordPosition="201">y. The IHMM-based method significantly outperforms the state-of-the-art TER-based alignment model in our experiments on NIST benchmark datasets. Our combined SMT system using the proposed method achieved the best Chinese-to-English translation result in the constrained training track of the 2008 NIST Open MT Evaluation. 1 Introduction System combination has been applied successfully to various machine translation tasks. Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007). A confusion network comprises a sequence of sets of alternative words, possibly including null’s, with associated scores. The consensus output is then derived by selecting one word from each set of alternatives, to produce the sequence with the best overall score, which could be assigned in various ways such as by voting, by * Mei Yang performed this work when she was an intern with Microsoft Research. 98 yangmei@u.washington.edu using posterior probability estimates, or by using a combination of these measures and other features. </context>
<context position="14967" citStr="Bangalore et al. (2001)" startWordPosition="2439" endWordPosition="2442"> hypothesis pairs for GIZA++ training. This approach uses the conventional HMM model bootstrapped from IBM Model-1 as implemented in GIZA++, and heuristically combines results from aligning in both directions. System combination based on this approach gives an improvement over the best single system. However, the number of hypothesis pairs for training is limited by the size of the test corpus. Also, MT hypotheses from the same source sentence are correlated with each other and these hypothesis pairs are not i.i.d. data samples. Therefore, GIZA++ training on such a data set may be unreliable. Bangalore et al. (2001) used a multiple stringmatching algorithm based on Levenshtein edit distance, and later Sim et al. (2007) and Rosti et al. (2007) extended it to a TER-based method for hypothesis alignment. TER (Snover et al., 2006) 3 This only happens if no hypothesis word is aligned to a backbone word but some hypothesis words are aligned to the null associated with that backbone word. measures the minimum number of edits, including substitution, insertion, deletion, and shift of blocks of words, that are needed to modify a hypothesis so that it exactly matches the other hypothesis. The best alignment is the</context>
</contexts>
<marker>Bangalore, Bordel, Riccardi, 2001</marker>
<rawString>Srinivas Bangalore, German Bordel, and Giuseppe Riccardi. 2001. Computing consensus translation from multiple machine translation systems. In Proc. of IEEE ASRU, pp. 351–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Brent</author>
</authors>
<title>Algorithms for Minimization without Derivatives.</title>
<date>1973</date>
<journal>Prentice-Hall, Chapter</journal>
<volume>7</volume>
<contexts>
<context position="19348" citStr="Brent, 1973" startWordPosition="3148" endWordPosition="3149">t the same position and from the same system S to generate the system specific word posterior. Then, the total word posterior of w over all systems is a sum of these system specific posteriors weighted by system weights. Beside the word posteriors, we use language model scores and a word count as features for confusion network decoding. Therefore, for an M-way system combination that uses N LMs, a total of M+N+1 decoding parameters, including M-1 system weights, one rank smoothing factor, N language model weights, and one weight for the word count feature, are optimized using Powell’s method (Brent, 1973) to maximize BLEU score on a development set4 . Two language models are used in our experiments. One is a trigram model estimated from the English side of the parallel training data, and the other is a 5-gram model trained on the English GigaWord corpus from LDC using the MSRLM toolkit (Nguyen et al, 2007). 4 The parameters of IHMM are not tuned by maximum-BLEU training. In order to reduce the fluctuation of BLEU scores caused by the inconsistent translation output length, an unsupervised length adaptation method has been devised. We compute an expected length ratio between the MT output and t</context>
</contexts>
<marker>Brent, 1973</marker>
<rawString>Richard Brent, 1973. Algorithms for Minimization without Derivatives. Prentice-Hall, Chapter 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<pages>228</pages>
<contexts>
<context position="21693" citStr="Chiang (2007)" startWordPosition="3533" endWordPosition="3534">ion effort, the results on the dev set are reported in case insensitive BLEU (ciBLEU) score instead. 5.3 Experimental results In our main experiments, outputs from a total of eight single MT systems were combined. As listed in Table 1, Sys-1 is a tree-to-string system proposed by Quirk et al., (2005); Sys-2 is a phrasebased system with fast pruning proposed by Moore and Quirk (2008); Sys-3 is a phrase-based system with syntactic source reordering proposed by Wang et al. (2007a); Sys-4 is a syntax-based preordering system proposed by Li et. al. (2007); Sys5 is a hierarchical system proposed by Chiang (2007); Sys-6 is a lexicalized re-ordering system proposed by Xiong et al. (2006); Sys-7 is a twopass phrase-based system with adapted LM proposed by Foster and Kuhn (2007); and Sys-8 is 103 a hierarchical system with two-pass rescoring using a parser-based LM proposed by Wang et al., (2007b). All systems were trained within the confines of the constrained training condition of NIST MT08 evaluation. These single systems are optimized with maximum-BLEU training on different subsets of the previous NIST MT test data. The bilingual translation models used to compute the semantic similarity are from the</context>
<context position="24834" citStr="Chiang (2007)" startWordPosition="4056" endWordPosition="4057"> 8 34.98 26.24 TER 42.11 29.89 IHMM 43.62 30.89 In order to evaluate how well our method performs when we combine more systems, we collected MT outputs on MT08 from seven additional single systems as summarized in Table 2. These systems belong to two groups. Sys-9 to Sys-12 are in the first group. They are syntaxaugmented hierarchical systems similar to those described by Shen et al. (2008) using different Chinese word segmentation and language models. The second group has Sys-13 to Sys-15. Sys-13 is a phrasal system proposed by Koehn et al. (2003), Sys-14 is a hierarchical system proposed by Chiang (2007), and Sys-15 is a syntax-based system proposed by Galley et al. (2006). All seven systems were trained within the confines of the constrained training condition of NIST MT08 evaluation. We collected 10-best MT outputs only on the MT08 test set from these seven extra systems. No MT outputs on our dev set are available from them at present. Therefore, we directly adopt system combination parameters trained for the previous 8- way system combination, except the system weights, which are re-set by the following heuristics: First, the total system weight mass 1.0 is evenly divided among the three g</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201– 228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Mixture-Model Adaptation for SMT.</title>
<date>2007</date>
<booktitle>In Proc. of the Second ACL Workshop on Statistical Machine Translation.</booktitle>
<pages>128--136</pages>
<contexts>
<context position="21859" citStr="Foster and Kuhn (2007)" startWordPosition="3559" endWordPosition="3562">s from a total of eight single MT systems were combined. As listed in Table 1, Sys-1 is a tree-to-string system proposed by Quirk et al., (2005); Sys-2 is a phrasebased system with fast pruning proposed by Moore and Quirk (2008); Sys-3 is a phrase-based system with syntactic source reordering proposed by Wang et al. (2007a); Sys-4 is a syntax-based preordering system proposed by Li et. al. (2007); Sys5 is a hierarchical system proposed by Chiang (2007); Sys-6 is a lexicalized re-ordering system proposed by Xiong et al. (2006); Sys-7 is a twopass phrase-based system with adapted LM proposed by Foster and Kuhn (2007); and Sys-8 is 103 a hierarchical system with two-pass rescoring using a parser-based LM proposed by Wang et al., (2007b). All systems were trained within the confines of the constrained training condition of NIST MT08 evaluation. These single systems are optimized with maximum-BLEU training on different subsets of the previous NIST MT test data. The bilingual translation models used to compute the semantic similarity are from the worddependent HMMs proposed by He (2007), which are trained on two million parallel sentence-pairs selected from the training corpus allowed by the constrained train</context>
</contexts>
<marker>Foster, Kuhn, 2007</marker>
<rawString>George Foster and Roland Kuhn. 2007. Mixture-Model Adaptation for SMT. In Proc. of the Second ACL Workshop on Statistical Machine Translation. pp. 128 – 136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable Inference and Training of Context-Rich Syntactic Translation Models.</title>
<date>2006</date>
<booktitle>In Proc. of COLING-ACL,</booktitle>
<pages>961--968</pages>
<contexts>
<context position="24904" citStr="Galley et al. (2006)" startWordPosition="4066" endWordPosition="4069">luate how well our method performs when we combine more systems, we collected MT outputs on MT08 from seven additional single systems as summarized in Table 2. These systems belong to two groups. Sys-9 to Sys-12 are in the first group. They are syntaxaugmented hierarchical systems similar to those described by Shen et al. (2008) using different Chinese word segmentation and language models. The second group has Sys-13 to Sys-15. Sys-13 is a phrasal system proposed by Koehn et al. (2003), Sys-14 is a hierarchical system proposed by Chiang (2007), and Sys-15 is a syntax-based system proposed by Galley et al. (2006). All seven systems were trained within the confines of the constrained training condition of NIST MT08 evaluation. We collected 10-best MT outputs only on the MT08 test set from these seven extra systems. No MT outputs on our dev set are available from them at present. Therefore, we directly adopt system combination parameters trained for the previous 8- way system combination, except the system weights, which are re-set by the following heuristics: First, the total system weight mass 1.0 is evenly divided among the three groups of single systems: {Sys-1~8}, {Sys-9~12}, and {Sys13~15}. Each g</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang and Ignacio Thayer. 2006. Scalable Inference and Training of Context-Rich Syntactic Translation Models. In Proc. of COLING-ACL, pp. 961–968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaodong He</author>
</authors>
<title>Using Word-Dependent Transition Models in HMM based Word Alignment for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proc. of the Second ACL Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="22334" citStr="He (2007)" startWordPosition="3635" endWordPosition="3636">ring system proposed by Xiong et al. (2006); Sys-7 is a twopass phrase-based system with adapted LM proposed by Foster and Kuhn (2007); and Sys-8 is 103 a hierarchical system with two-pass rescoring using a parser-based LM proposed by Wang et al., (2007b). All systems were trained within the confines of the constrained training condition of NIST MT08 evaluation. These single systems are optimized with maximum-BLEU training on different subsets of the previous NIST MT test data. The bilingual translation models used to compute the semantic similarity are from the worddependent HMMs proposed by He (2007), which are trained on two million parallel sentence-pairs selected from the training corpus allowed by the constrained training condition of MT08. 5.3.1 Comparison with TER alignment In the IHMM-based method, the smoothing factor for surface similarity model is set to ρ = 3, the interpolation factor of the overall similarity model is set to α = 0.3, and the controlling factor of the distance-based distortion parameters is set to K=2. These settings are optimized on the dev set. Individual system results and system combination results using both IHMM and TER alignment, on both the dev and test</context>
</contexts>
<marker>He, 2007</marker>
<rawString>Xiaodong He. 2007. Using Word-Dependent Transition Models in HMM based Word Alignment for Statistical Machine Translation. In Proc. of the Second ACL Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shyamsundar Jayaraman</author>
<author>Alon Lavie</author>
</authors>
<title>Multiengine machine translation guided by explicit word matching.</title>
<date>2005</date>
<booktitle>In Proc. of EAMT.</booktitle>
<pages>143--152</pages>
<contexts>
<context position="17429" citStr="Jayaraman and Lavie (2005)" startWordPosition="2822" endWordPosition="2825">onnormalized version of our IHMM, in which the similarity model assigns no penalty to an exact surface match and a fixed penalty to all substitutions, insertions, and deletions, and the distortion model simply assigns no penalty to a monotonic jump, and a fixed penalty to all other jumps, equal to the non-exact-match penalty in the similarity model. There have been other hypothesis alignment methods. Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al. (2008) proposed an incremental alignment method, and a heuristic-based matching algorithm was proposed by Jayaraman and Lavie (2005). 5 Evaluation In this section, we evaluate our IHMM-based hypothesis alignment method on the Chinese-toEnglish (C2E) test in the constrained training track 102 of the 2008 NIST Open MT Evaluation (NIST, 2008). We compare to the TER-based method used by Rosti et al. (2007). In the following experiments, the NIST BLEU score is used as the evaluation metric (Papineni et al., 2002), which is reported as a percentage in the following sections. 5.1 Implementation details In our implementation, the backbone is selected with MBR. Only the top hypothesis from each single system is considered as a back</context>
</contexts>
<marker>Jayaraman, Lavie, 2005</marker>
<rawString>Shyamsundar Jayaraman and Alon Lavie. 2005. Multiengine machine translation guided by explicit word matching. In Proc. of EAMT. pp. 143 – 152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Damianos Karakos</author>
<author>Jason Eisner</author>
<author>Sanjeev Khudanpur</author>
<author>Markus Dreyer</author>
</authors>
<title>Machine Translation System Combination using ITG-based Alignments.</title>
<date>2008</date>
<booktitle>In Proc. of ACL-HLT,</booktitle>
<pages>81--84</pages>
<contexts>
<context position="17229" citStr="Karakos, et al. (2008)" startWordPosition="2793" endWordPosition="2796"> while it is only used implicitly via parameter initialization for IBM Model-1 training by Matusov et al. (2006). On the other hand, the TER-based alignment model is similar to a coarse-grained, nonnormalized version of our IHMM, in which the similarity model assigns no penalty to an exact surface match and a fixed penalty to all substitutions, insertions, and deletions, and the distortion model simply assigns no penalty to a monotonic jump, and a fixed penalty to all other jumps, equal to the non-exact-match penalty in the similarity model. There have been other hypothesis alignment methods. Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al. (2008) proposed an incremental alignment method, and a heuristic-based matching algorithm was proposed by Jayaraman and Lavie (2005). 5 Evaluation In this section, we evaluate our IHMM-based hypothesis alignment method on the Chinese-toEnglish (C2E) test in the constrained training track 102 of the 2008 NIST Open MT Evaluation (NIST, 2008). We compare to the TER-based method used by Rosti et al. (2007). In the following experiments, the NIST BLEU score is used as the evaluation metric (Papineni et al., 2002), which is reported</context>
</contexts>
<marker>Karakos, Eisner, Khudanpur, Dreyer, 2008</marker>
<rawString>Damianos Karakos, Jason Eisner, Sanjeev Khudanpur, and Markus Dreyer. 2008. Machine Translation System Combination using ITG-based Alignments. In Proc. of ACL-HLT, pp. 81–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chi-Ho Li</author>
<author>Minghui Li</author>
<author>Dongdong Zhang</author>
<author>Mu Li</author>
<author>Ming Zhou</author>
<author>Yi Guan</author>
</authors>
<title>A Probabilistic Approach to Syntax-based Reordering for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proc. of ACL.</booktitle>
<pages>720--727</pages>
<marker>Li, Li, Zhang, Li, Zhou, Guan, 2007</marker>
<rawString>Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li, Ming Zhou, Yi Guan. 2007. A Probabilistic Approach to Syntax-based Reordering for Statistical Machine Translation. In Proc. of ACL. pp. 720 – 727.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by Agreement.</title>
<date>2006</date>
<booktitle>In Proc. of NAACL.</booktitle>
<pages>104--111</pages>
<contexts>
<context position="10666" citStr="Liang et al. (2006)" startWordPosition="1710" endWordPosition="1713">rst-order dependencies of word ordering. In bilingual HMM-based word alignment, it is commonly assumed that transition probabilities 1 The other direction, , is available from the source-to-target translation model. 2 Usually a small back-off value is assigned instead of 0. (fk |ei) 2 K  (fk |ei) 2 k 0 100 Following Och and Ney (2003), we use a fixed value p0 for the probability of jumping to a null state, which can be optimized on held-out data, and the overall distortion model becomes p(aj = i I aj_l = [J) depend only on the jump distance (i - i&apos;) (Vogel et al., 1996): (5) As suggested by Liang et al. (2006), we can group the distortion parameters {c(d)}, d= i - i&apos;, into a few buckets. In our implementation, 11 buckets are used for c(≤-4), c(-3), ... c(0), ..., c(5), c(≥6). The probability mass for transitions with jump distance larger than 6 and less than -4 is uniformly divided. By doing this, only a handful of c(d) parameters need to be estimated. Although it is possible to estimate them using the EM algorithm on a small development set, we found that a particularly simple model, described below, works surprisingly well in our experiments. Since both the backbone and the hypothesis are in the </context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by Agreement. In Proc. of NAACL. pp 104 – 111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeny Matusov</author>
<author>Nicola Ueffing</author>
<author>Hermann Ney</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment.</title>
<date>2006</date>
<booktitle>In Proc. of EACL,</booktitle>
<pages>33--40</pages>
<contexts>
<context position="1541" citStr="Matusov et al., 2006" startWordPosition="202" endWordPosition="205"> significantly outperforms the state-of-the-art TER-based alignment model in our experiments on NIST benchmark datasets. Our combined SMT system using the proposed method achieved the best Chinese-to-English translation result in the constrained training track of the 2008 NIST Open MT Evaluation. 1 Introduction System combination has been applied successfully to various machine translation tasks. Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007). A confusion network comprises a sequence of sets of alternative words, possibly including null’s, with associated scores. The consensus output is then derived by selecting one word from each set of alternatives, to produce the sequence with the best overall score, which could be assigned in various ways such as by voting, by * Mei Yang performed this work when she was an intern with Microsoft Research. 98 yangmei@u.washington.edu using posterior probability estimates, or by using a combination of these measures and other features. Constructing a confusi</context>
<context position="14210" citStr="Matusov et al. (2006)" startWordPosition="2321" endWordPosition="2324">omes before e2’. Nulls are also inserted for other hypothesis words such as e3’ and e4’ after the backbone word e2. If there is no hypothesis word aligned to that backbone word, all nulls are inserted after that backbone word .3 For a backbone word that is aligned to no hypothesis word, a null is inserted on the hypothesis side, right after the hypothesis word which is aligned to the immediately preceding backbone word. An example is shown in Fig. 3 (b). 4 Related work The two main hypothesis alignment methods for system combination in the previous literature are GIZA++ and TER-based methods. Matusov et al. (2006) proposed using GIZA++ to align words between different MT hypotheses, where all hypotheses of the test corpus are collected to create hypothesis pairs for GIZA++ training. This approach uses the conventional HMM model bootstrapped from IBM Model-1 as implemented in GIZA++, and heuristically combines results from aligning in both directions. System combination based on this approach gives an improvement over the best single system. However, the number of hypothesis pairs for training is limited by the size of the test corpus. Also, MT hypotheses from the same source sentence are correlated wit</context>
<context position="16719" citStr="Matusov et al. (2006)" startWordPosition="2711" endWordPosition="2714">re penalized equally no matter how short or how long the move is, and this penalty is set to be the same as that for substitution, deletion, and insertion edits. Therefore, its modeling of non-monotonic word ordering is very coarse-grained. In contrast to the GIZA++-based method, our IHMM-based method has a similarity model estimated using bilingual word alignment HMMs that are trained on a large amount of bi-text data. Moreover, the surface similarity information is explicitly incorporated in our model, while it is only used implicitly via parameter initialization for IBM Model-1 training by Matusov et al. (2006). On the other hand, the TER-based alignment model is similar to a coarse-grained, nonnormalized version of our IHMM, in which the similarity model assigns no penalty to an exact surface match and a fixed penalty to all substitutions, insertions, and deletions, and the distortion model simply assigns no penalty to a monotonic jump, and a fixed penalty to all other jumps, equal to the non-exact-match penalty in the similarity model. There have been other hypothesis alignment methods. Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al. (2008) proposed an inc</context>
</contexts>
<marker>Matusov, Ueffing, Ney, 2006</marker>
<rawString>Evgeny Matusov, Nicola Ueffing, and Hermann Ney. 2006. Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment. In Proc. of EACL, pp. 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Moore</author>
<author>Chris Quirk</author>
</authors>
<title>Faster BeamSearch Decoding for Phrasal Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proc. of MT</booktitle>
<location>Summit XI.</location>
<marker>Moore, Quirk, 2007</marker>
<rawString>Robert Moore and Chris Quirk. 2007. Faster BeamSearch Decoding for Phrasal Statistical Machine Translation. In Proc. of MT Summit XI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Nguyen</author>
<author>Jianfeng Gao</author>
<author>Milind Mahajan</author>
</authors>
<title>MSRLM: a scalable language modeling toolkit. Microsoft Research</title>
<date>2007</date>
<tech>Technical Report MSRTR-2007-144.</tech>
<contexts>
<context position="19655" citStr="Nguyen et al, 2007" startWordPosition="3201" endWordPosition="3204">atures for confusion network decoding. Therefore, for an M-way system combination that uses N LMs, a total of M+N+1 decoding parameters, including M-1 system weights, one rank smoothing factor, N language model weights, and one weight for the word count feature, are optimized using Powell’s method (Brent, 1973) to maximize BLEU score on a development set4 . Two language models are used in our experiments. One is a trigram model estimated from the English side of the parallel training data, and the other is a 5-gram model trained on the English GigaWord corpus from LDC using the MSRLM toolkit (Nguyen et al, 2007). 4 The parameters of IHMM are not tuned by maximum-BLEU training. In order to reduce the fluctuation of BLEU scores caused by the inconsistent translation output length, an unsupervised length adaptation method has been devised. We compute an expected length ratio between the MT output and the source sentences on the development set after maximumBLEU training. Then during test, we adapt the length of the translation output by adjusting the weight of the word count feature such that the expected output/source length ratio is met. In our experiments, we apply length adaptation to the system com</context>
</contexts>
<marker>Nguyen, Gao, Mahajan, 2007</marker>
<rawString>Patrick Nguyen, Jianfeng Gao and Milind Mahajan. 2007. MSRLM: a scalable language modeling toolkit. Microsoft Research Technical Report MSRTR-2007-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<title>The</title>
<date>2008</date>
<booktitle>NIST Open Machine Translation Evaluation. www.nist.gov/speech/tests/mt/2008/doc/</booktitle>
<contexts>
<context position="17638" citStr="NIST, 2008" startWordPosition="2857" endWordPosition="2858">alty to a monotonic jump, and a fixed penalty to all other jumps, equal to the non-exact-match penalty in the similarity model. There have been other hypothesis alignment methods. Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al. (2008) proposed an incremental alignment method, and a heuristic-based matching algorithm was proposed by Jayaraman and Lavie (2005). 5 Evaluation In this section, we evaluate our IHMM-based hypothesis alignment method on the Chinese-toEnglish (C2E) test in the constrained training track 102 of the 2008 NIST Open MT Evaluation (NIST, 2008). We compare to the TER-based method used by Rosti et al. (2007). In the following experiments, the NIST BLEU score is used as the evaluation metric (Papineni et al., 2002), which is reported as a percentage in the following sections. 5.1 Implementation details In our implementation, the backbone is selected with MBR. Only the top hypothesis from each single system is considered as a backbone. A uniform posteriori probability is assigned to all hypotheses. TER is used as loss function in the MBR computation. Similar to (Rosti et al., 2007), each word in the confusion network is associated with</context>
<context position="26378" citStr="NIST, 2008" startWordPosition="4316" endWordPosition="4317"> group, i.e., 1/12 for each system in group 2, and 1/9 for each 104 system in group 35. Length adaptation is applied to control the final output length, where the same expected length ratio of the previous 8-way system combination is adopted. The results of the 15-way system combination are presented in Table 3. It shows that the IHMMbased method is still about 1 BLEU point better than the TER-based method. Moreover, combining 15 single systems gives an output that has a NIST BLEU score of 34.82%, which is 3.9 points better than the best submission to the NIST MT08 constrained training track (NIST, 2008). To our knowledge, this is the best result reported on this task. Table 2. Results of seven additional single systems on the NIST MT08 test set System MT08 BLEU% System 9 29.59 System 10 29.57 System 11 29.64 System 12 29.85 System 13 25.53 System 14 26.04 System 15 29.70 Table 3. Results of the 15-way system combination on the NIST MT08 C2E test set Sys. Comb. MT08 BLEU% TER 33.81 IHMM 34.82 5.3.2 Effect of the similarity model In this section, we evaluate the effect of the semantic similarity model and the surface similarity model by varying the interpolation weight α of (2). The results on</context>
</contexts>
<marker>NIST, 2008</marker>
<rawString>NIST. 2008. The 2008 NIST Open Machine Translation Evaluation. www.nist.gov/speech/tests/mt/2008/doc/</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="5592" citStr="Och and Ney, 2003" startWordPosition="845" endWordPosition="848">carEBaz=min E2 he has nice sedangeE E3 it a nice car _ E4 a sedan he has e.g., EB — E1 (a) hypothesis set (b) backbone selection he have ε good car he has ε nice sedan it ε a nice car he has a ε sedan (c) hypothesis alignment (d) confusion network Figure 1: Confusion-network-based MT system combination. 3 Indirect-HMM-based Hypothesis Alignment In confusion-network-based system combination for SMT, a major difficulty is aligning hypotheses to the backbone. One possible statistical model for word alignment is the HMM, which has been widely used for bilingual word alignment (Vogel et al., 1996, Och and Ney, 2003). In this paper, we propose an indirect-HMM method for monolingual hypothesis alignment. 3.1 IHMM for hypothesis alignment Let denote the backbone, �&apos; _ ( ,...,dj) a hypothesis to be aligned to e; , and the alignment that specifies the position of the backbone word aligned to each hypothesis word. We treat each word in the backbone as an HMM state and the words in the hypothesis as the observation sequence. We use a first-order HMM, assuming that the emission probability depends only on the backbone word, and the transition probability p(aj I aj_,,I) depends only on the position of the last st</context>
<context position="10385" citStr="Och and Ney (2003)" startWordPosition="1654" endWordPosition="1657">performance but the computation of LMP is faster. Therefore, we only report results of the LMP-based smoothed similarity model. p.2, ( � i  |null ) 3.3 Estimation of the distortion model The distortion model, which specifies the transition probabilities of the HMM, models the first-order dependencies of word ordering. In bilingual HMM-based word alignment, it is commonly assumed that transition probabilities 1 The other direction, , is available from the source-to-target translation model. 2 Usually a small back-off value is assigned instead of 0. (fk |ei) 2 K  (fk |ei) 2 k 0 100 Following Och and Ney (2003), we use a fixed value p0 for the probability of jumping to a null state, which can be optimized on held-out data, and the overall distortion model becomes p(aj = i I aj_l = [J) depend only on the jump distance (i - i&apos;) (Vogel et al., 1996): (5) As suggested by Liang et al. (2006), we can group the distortion parameters {c(d)}, d= i - i&apos;, into a few buckets. In our implementation, 11 buckets are used for c(≤-4), c(-3), ... c(0), ..., c(5), c(≥6). The probability mass for transitions with jump distance larger than 6 and less than -4 is uniformly divided. By doing this, only a handful of c(d) pa</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="17810" citStr="Papineni et al., 2002" startWordPosition="2885" endWordPosition="2888">alignment methods. Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al. (2008) proposed an incremental alignment method, and a heuristic-based matching algorithm was proposed by Jayaraman and Lavie (2005). 5 Evaluation In this section, we evaluate our IHMM-based hypothesis alignment method on the Chinese-toEnglish (C2E) test in the constrained training track 102 of the 2008 NIST Open MT Evaluation (NIST, 2008). We compare to the TER-based method used by Rosti et al. (2007). In the following experiments, the NIST BLEU score is used as the evaluation metric (Papineni et al., 2002), which is reported as a percentage in the following sections. 5.1 Implementation details In our implementation, the backbone is selected with MBR. Only the top hypothesis from each single system is considered as a backbone. A uniform posteriori probability is assigned to all hypotheses. TER is used as loss function in the MBR computation. Similar to (Rosti et al., 2007), each word in the confusion network is associated with a word posterior probability. Given a system S, each of its hypotheses is assigned with a rank-based score of 1/(1+r)η, where r is the rank of the hypothesis, and η is a r</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proc. of ACL, pp. 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase based translation.</title>
<date>2003</date>
<booktitle>In Proc. of NAACL.</booktitle>
<pages>48--54</pages>
<contexts>
<context position="24775" citStr="Koehn et al. (2003)" startWordPosition="4045" endWordPosition="4048">em 5 37.80 24.57 System 6 37.28 24.40 System 7 32.37 25.51 System 8 34.98 26.24 TER 42.11 29.89 IHMM 43.62 30.89 In order to evaluate how well our method performs when we combine more systems, we collected MT outputs on MT08 from seven additional single systems as summarized in Table 2. These systems belong to two groups. Sys-9 to Sys-12 are in the first group. They are syntaxaugmented hierarchical systems similar to those described by Shen et al. (2008) using different Chinese word segmentation and language models. The second group has Sys-13 to Sys-15. Sys-13 is a phrasal system proposed by Koehn et al. (2003), Sys-14 is a hierarchical system proposed by Chiang (2007), and Sys-15 is a syntax-based system proposed by Galley et al. (2006). All seven systems were trained within the confines of the constrained training condition of NIST MT08 evaluation. We collected 10-best MT outputs only on the MT08 test set from these seven extra systems. No MT outputs on our dev set are available from them at present. Therefore, we directly adopt system combination parameters trained for the previous 8- way system combination, except the system weights, which are re-set by the following heuristics: First, the total</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Koehn, Philipp, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase based translation. In Proc. of NAACL. pp. 48 – 54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Arul Menezes</author>
<author>Colin Cherry</author>
</authors>
<title>Dependency treelet translation: Syntactically informed phrasal SMT.</title>
<date>2005</date>
<booktitle>In Proc. of ACL.</booktitle>
<pages>271--279</pages>
<contexts>
<context position="21381" citStr="Quirk et al., (2005)" startWordPosition="3478" endWordPosition="3481">to the system combination, 10-best hypotheses for each source sentence in the dev and test sets are collected from each of the eight single systems. All outputs on the MT08 test set were true-cased before scoring using a log-linear conditional Markov model proposed by Toutanova et al. (2008). However, to save computation effort, the results on the dev set are reported in case insensitive BLEU (ciBLEU) score instead. 5.3 Experimental results In our main experiments, outputs from a total of eight single MT systems were combined. As listed in Table 1, Sys-1 is a tree-to-string system proposed by Quirk et al., (2005); Sys-2 is a phrasebased system with fast pruning proposed by Moore and Quirk (2008); Sys-3 is a phrase-based system with syntactic source reordering proposed by Wang et al. (2007a); Sys-4 is a syntax-based preordering system proposed by Li et. al. (2007); Sys5 is a hierarchical system proposed by Chiang (2007); Sys-6 is a lexicalized re-ordering system proposed by Xiong et al. (2006); Sys-7 is a twopass phrase-based system with adapted LM proposed by Foster and Kuhn (2007); and Sys-8 is 103 a hierarchical system with two-pass rescoring using a parser-based LM proposed by Wang et al., (2007b).</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>Chris Quirk, Arul Menezes, and Colin Cherry. 2005. Dependency treelet translation: Syntactically informed phrasal SMT. In Proc. of ACL. pp. 271– 279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko I Rosti</author>
<author>Bing Xiang</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
<author>Necip Fazil Ayan</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Combining outputs from multiple machine translation systems.</title>
<date>2007</date>
<booktitle>In Proc. of NAACLHLT,</booktitle>
<pages>228--235</pages>
<contexts>
<context position="1561" citStr="Rosti et al., 2007" startWordPosition="206" endWordPosition="209">orms the state-of-the-art TER-based alignment model in our experiments on NIST benchmark datasets. Our combined SMT system using the proposed method achieved the best Chinese-to-English translation result in the constrained training track of the 2008 NIST Open MT Evaluation. 1 Introduction System combination has been applied successfully to various machine translation tasks. Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007). A confusion network comprises a sequence of sets of alternative words, possibly including null’s, with associated scores. The consensus output is then derived by selecting one word from each set of alternatives, to produce the sequence with the best overall score, which could be assigned in various ways such as by voting, by * Mei Yang performed this work when she was an intern with Microsoft Research. 98 yangmei@u.washington.edu using posterior probability estimates, or by using a combination of these measures and other features. Constructing a confusion network requires </context>
<context position="3822" citStr="Rosti et al., 2007" startWordPosition="543" endWordPosition="546"> a distancebased distortion penalty, without using large amount of training data. Our combined SMT system using the proposed method gave the best result on the Chinese-to-English test in the constrained training track of the 2008 NIST Open MT Evaluation (MT08). 2 Confusion-network-based MT system combination The current state-of-the-art is confusion-networkbased MT system combination as described by Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 98–107, Honolulu, October 2008. c�2008 Association for Computational Linguistics Rosti and colleagues (Rosti et al., 2007a, Rosti et al., 2007b). The major steps are illustrated in Figure 1. In Fig. 1 (a), hypotheses from different MT systems are first collected. Then in Fig. 1 (b), one of the hypotheses is selected as the backbone for hypothesis alignment. This is usually done by a sentence-level minimum Bayes risk (MBR) method which selects a hypothesis that has the minimum average distance compared to all hypotheses. The backbone determines the word order of the combined output. Then as illustrated in Fig. 1 (c), all other hypotheses are aligned to the backbone. Note that in Fig. 1 (c) the symbol ε denotes a </context>
<context position="15096" citStr="Rosti et al. (2007)" startWordPosition="2461" endWordPosition="2464">GIZA++, and heuristically combines results from aligning in both directions. System combination based on this approach gives an improvement over the best single system. However, the number of hypothesis pairs for training is limited by the size of the test corpus. Also, MT hypotheses from the same source sentence are correlated with each other and these hypothesis pairs are not i.i.d. data samples. Therefore, GIZA++ training on such a data set may be unreliable. Bangalore et al. (2001) used a multiple stringmatching algorithm based on Levenshtein edit distance, and later Sim et al. (2007) and Rosti et al. (2007) extended it to a TER-based method for hypothesis alignment. TER (Snover et al., 2006) 3 This only happens if no hypothesis word is aligned to a backbone word but some hypothesis words are aligned to the null associated with that backbone word. measures the minimum number of edits, including substitution, insertion, deletion, and shift of blocks of words, that are needed to modify a hypothesis so that it exactly matches the other hypothesis. The best alignment is the one that gives the minimum number of translation edits. TER-based confusion network construction and system combination has demo</context>
<context position="17702" citStr="Rosti et al. (2007)" startWordPosition="2867" endWordPosition="2870">er jumps, equal to the non-exact-match penalty in the similarity model. There have been other hypothesis alignment methods. Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al. (2008) proposed an incremental alignment method, and a heuristic-based matching algorithm was proposed by Jayaraman and Lavie (2005). 5 Evaluation In this section, we evaluate our IHMM-based hypothesis alignment method on the Chinese-toEnglish (C2E) test in the constrained training track 102 of the 2008 NIST Open MT Evaluation (NIST, 2008). We compare to the TER-based method used by Rosti et al. (2007). In the following experiments, the NIST BLEU score is used as the evaluation metric (Papineni et al., 2002), which is reported as a percentage in the following sections. 5.1 Implementation details In our implementation, the backbone is selected with MBR. Only the top hypothesis from each single system is considered as a backbone. A uniform posteriori probability is assigned to all hypotheses. TER is used as loss function in the MBR computation. Similar to (Rosti et al., 2007), each word in the confusion network is associated with a word posterior probability. Given a system S, each of its hyp</context>
</contexts>
<marker>Rosti, Xiang, Matsoukas, Schwartz, Ayan, Dorr, 2007</marker>
<rawString>Antti-Veikko I. Rosti, Bing Xiang, Spyros Matsoukas, Richard Schwartz, Necip Fazil Ayan, and Bonnie J. Dorr. 2007a. Combining outputs from multiple machine translation systems. In Proc. of NAACLHLT, pp. 228–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko I Rosti</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
</authors>
<title>Improved Word-Level System Combination for Machine Translation.</title>
<date>2007</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>312--319</pages>
<contexts>
<context position="1561" citStr="Rosti et al., 2007" startWordPosition="206" endWordPosition="209">orms the state-of-the-art TER-based alignment model in our experiments on NIST benchmark datasets. Our combined SMT system using the proposed method achieved the best Chinese-to-English translation result in the constrained training track of the 2008 NIST Open MT Evaluation. 1 Introduction System combination has been applied successfully to various machine translation tasks. Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007). A confusion network comprises a sequence of sets of alternative words, possibly including null’s, with associated scores. The consensus output is then derived by selecting one word from each set of alternatives, to produce the sequence with the best overall score, which could be assigned in various ways such as by voting, by * Mei Yang performed this work when she was an intern with Microsoft Research. 98 yangmei@u.washington.edu using posterior probability estimates, or by using a combination of these measures and other features. Constructing a confusion network requires </context>
<context position="3822" citStr="Rosti et al., 2007" startWordPosition="543" endWordPosition="546"> a distancebased distortion penalty, without using large amount of training data. Our combined SMT system using the proposed method gave the best result on the Chinese-to-English test in the constrained training track of the 2008 NIST Open MT Evaluation (MT08). 2 Confusion-network-based MT system combination The current state-of-the-art is confusion-networkbased MT system combination as described by Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 98–107, Honolulu, October 2008. c�2008 Association for Computational Linguistics Rosti and colleagues (Rosti et al., 2007a, Rosti et al., 2007b). The major steps are illustrated in Figure 1. In Fig. 1 (a), hypotheses from different MT systems are first collected. Then in Fig. 1 (b), one of the hypotheses is selected as the backbone for hypothesis alignment. This is usually done by a sentence-level minimum Bayes risk (MBR) method which selects a hypothesis that has the minimum average distance compared to all hypotheses. The backbone determines the word order of the combined output. Then as illustrated in Fig. 1 (c), all other hypotheses are aligned to the backbone. Note that in Fig. 1 (c) the symbol ε denotes a </context>
<context position="15096" citStr="Rosti et al. (2007)" startWordPosition="2461" endWordPosition="2464">GIZA++, and heuristically combines results from aligning in both directions. System combination based on this approach gives an improvement over the best single system. However, the number of hypothesis pairs for training is limited by the size of the test corpus. Also, MT hypotheses from the same source sentence are correlated with each other and these hypothesis pairs are not i.i.d. data samples. Therefore, GIZA++ training on such a data set may be unreliable. Bangalore et al. (2001) used a multiple stringmatching algorithm based on Levenshtein edit distance, and later Sim et al. (2007) and Rosti et al. (2007) extended it to a TER-based method for hypothesis alignment. TER (Snover et al., 2006) 3 This only happens if no hypothesis word is aligned to a backbone word but some hypothesis words are aligned to the null associated with that backbone word. measures the minimum number of edits, including substitution, insertion, deletion, and shift of blocks of words, that are needed to modify a hypothesis so that it exactly matches the other hypothesis. The best alignment is the one that gives the minimum number of translation edits. TER-based confusion network construction and system combination has demo</context>
<context position="17702" citStr="Rosti et al. (2007)" startWordPosition="2867" endWordPosition="2870">er jumps, equal to the non-exact-match penalty in the similarity model. There have been other hypothesis alignment methods. Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al. (2008) proposed an incremental alignment method, and a heuristic-based matching algorithm was proposed by Jayaraman and Lavie (2005). 5 Evaluation In this section, we evaluate our IHMM-based hypothesis alignment method on the Chinese-toEnglish (C2E) test in the constrained training track 102 of the 2008 NIST Open MT Evaluation (NIST, 2008). We compare to the TER-based method used by Rosti et al. (2007). In the following experiments, the NIST BLEU score is used as the evaluation metric (Papineni et al., 2002), which is reported as a percentage in the following sections. 5.1 Implementation details In our implementation, the backbone is selected with MBR. Only the top hypothesis from each single system is considered as a backbone. A uniform posteriori probability is assigned to all hypotheses. TER is used as loss function in the MBR computation. Similar to (Rosti et al., 2007), each word in the confusion network is associated with a word posterior probability. Given a system S, each of its hyp</context>
</contexts>
<marker>Rosti, Matsoukas, Schwartz, 2007</marker>
<rawString>Antti-Veikko I. Rosti, Spyros Matsoukas, and Richard Schwartz. 2007b. Improved Word-Level System Combination for Machine Translation. In Proc. of ACL, pp. 312–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko I Rosti</author>
<author>Bing Zhang</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
</authors>
<title>Incremental Hypothesis Alignment for Building Confusion Networks with Application to Machine Translation System Combination,</title>
<date>2008</date>
<booktitle>In Proc. of the Third ACL Workshop on Statistical Machine Translation,</booktitle>
<pages>183--186</pages>
<contexts>
<context position="17303" citStr="Rosti et al. (2008)" startWordPosition="2805" endWordPosition="2808">1 training by Matusov et al. (2006). On the other hand, the TER-based alignment model is similar to a coarse-grained, nonnormalized version of our IHMM, in which the similarity model assigns no penalty to an exact surface match and a fixed penalty to all substitutions, insertions, and deletions, and the distortion model simply assigns no penalty to a monotonic jump, and a fixed penalty to all other jumps, equal to the non-exact-match penalty in the similarity model. There have been other hypothesis alignment methods. Karakos, et al. (2008) proposed an ITGbased method for hypothesis alignment, Rosti et al. (2008) proposed an incremental alignment method, and a heuristic-based matching algorithm was proposed by Jayaraman and Lavie (2005). 5 Evaluation In this section, we evaluate our IHMM-based hypothesis alignment method on the Chinese-toEnglish (C2E) test in the constrained training track 102 of the 2008 NIST Open MT Evaluation (NIST, 2008). We compare to the TER-based method used by Rosti et al. (2007). In the following experiments, the NIST BLEU score is used as the evaluation metric (Papineni et al., 2002), which is reported as a percentage in the following sections. 5.1 Implementation details In </context>
</contexts>
<marker>Rosti, Zhang, Matsoukas, Schwartz, 2008</marker>
<rawString>Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas, and Richard Schwartz. 2008. Incremental Hypothesis Alignment for Building Confusion Networks with Application to Machine Translation System Combination, In Proc. of the Third ACL Workshop on Statistical Machine Translation, pp. 183–186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Jinxi Xu</author>
<author>Ralph Weischedel</author>
</authors>
<title>A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model.</title>
<date>2008</date>
<booktitle>In Proc. of ACL-HLT,</booktitle>
<pages>577--585</pages>
<contexts>
<context position="24614" citStr="Shen et al. (2008)" startWordPosition="4019" endWordPosition="4022">tems on the dev set and the MT08 test set System Dev MT08 ciBLEU% BLEU% System 1 34.08 21.75 System 2 33.78 20.42 System 3 34.75 21.69 System 4 37.85 25.52 System 5 37.80 24.57 System 6 37.28 24.40 System 7 32.37 25.51 System 8 34.98 26.24 TER 42.11 29.89 IHMM 43.62 30.89 In order to evaluate how well our method performs when we combine more systems, we collected MT outputs on MT08 from seven additional single systems as summarized in Table 2. These systems belong to two groups. Sys-9 to Sys-12 are in the first group. They are syntaxaugmented hierarchical systems similar to those described by Shen et al. (2008) using different Chinese word segmentation and language models. The second group has Sys-13 to Sys-15. Sys-13 is a phrasal system proposed by Koehn et al. (2003), Sys-14 is a hierarchical system proposed by Chiang (2007), and Sys-15 is a syntax-based system proposed by Galley et al. (2006). All seven systems were trained within the confines of the constrained training condition of NIST MT08 evaluation. We collected 10-best MT outputs only on the MT08 test set from these seven extra systems. No MT outputs on our dev set are available from them at present. Therefore, we directly adopt system com</context>
</contexts>
<marker>Shen, Xu, Weischedel, 2008</marker>
<rawString>Libin Shen, Jinxi Xu, Ralph Weischedel. 2008. A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model. In Proc. of ACL-HLT, pp. 577–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khe Chai Sim</author>
<author>William J Byrne</author>
<author>Mark J F Gales</author>
<author>Hichem Sahbi</author>
<author>Phil C Woodland</author>
</authors>
<title>Consensus network decoding for statistical machine translation system combination.</title>
<date>2007</date>
<booktitle>In Proc. of ICASSP,</booktitle>
<volume>4</volume>
<pages>105--108</pages>
<contexts>
<context position="1580" citStr="Sim et al., 2007" startWordPosition="210" endWordPosition="213">e-art TER-based alignment model in our experiments on NIST benchmark datasets. Our combined SMT system using the proposed method achieved the best Chinese-to-English translation result in the constrained training track of the 2008 NIST Open MT Evaluation. 1 Introduction System combination has been applied successfully to various machine translation tasks. Recently, confusion-network-based system combination algorithms have been developed to combine outputs of multiple machine translation (MT) systems to form a consensus output (Bangalore, et al. 2001, Matusov et al., 2006, Rosti et al., 2007, Sim et al., 2007). A confusion network comprises a sequence of sets of alternative words, possibly including null’s, with associated scores. The consensus output is then derived by selecting one word from each set of alternatives, to produce the sequence with the best overall score, which could be assigned in various ways such as by voting, by * Mei Yang performed this work when she was an intern with Microsoft Research. 98 yangmei@u.washington.edu using posterior probability estimates, or by using a combination of these measures and other features. Constructing a confusion network requires choosing one of the</context>
<context position="15072" citStr="Sim et al. (2007)" startWordPosition="2456" endWordPosition="2459">l-1 as implemented in GIZA++, and heuristically combines results from aligning in both directions. System combination based on this approach gives an improvement over the best single system. However, the number of hypothesis pairs for training is limited by the size of the test corpus. Also, MT hypotheses from the same source sentence are correlated with each other and these hypothesis pairs are not i.i.d. data samples. Therefore, GIZA++ training on such a data set may be unreliable. Bangalore et al. (2001) used a multiple stringmatching algorithm based on Levenshtein edit distance, and later Sim et al. (2007) and Rosti et al. (2007) extended it to a TER-based method for hypothesis alignment. TER (Snover et al., 2006) 3 This only happens if no hypothesis word is aligned to a backbone word but some hypothesis words are aligned to the null associated with that backbone word. measures the minimum number of edits, including substitution, insertion, deletion, and shift of blocks of words, that are needed to modify a hypothesis so that it exactly matches the other hypothesis. The best alignment is the one that gives the minimum number of translation edits. TER-based confusion network construction and sys</context>
</contexts>
<marker>Sim, Byrne, Gales, Sahbi, Woodland, 2007</marker>
<rawString>Khe Chai Sim, William J. Byrne, Mark J.F. Gales, Hichem Sahbi, and Phil C. Woodland. 2007. Consensus network decoding for statistical machine translation system combination. In Proc. of ICASSP, vol. 4. pp. 105–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Rich Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proc. of AMTA.</booktitle>
<contexts>
<context position="15182" citStr="Snover et al., 2006" startWordPosition="2475" endWordPosition="2478">ombination based on this approach gives an improvement over the best single system. However, the number of hypothesis pairs for training is limited by the size of the test corpus. Also, MT hypotheses from the same source sentence are correlated with each other and these hypothesis pairs are not i.i.d. data samples. Therefore, GIZA++ training on such a data set may be unreliable. Bangalore et al. (2001) used a multiple stringmatching algorithm based on Levenshtein edit distance, and later Sim et al. (2007) and Rosti et al. (2007) extended it to a TER-based method for hypothesis alignment. TER (Snover et al., 2006) 3 This only happens if no hypothesis word is aligned to a backbone word but some hypothesis words are aligned to the null associated with that backbone word. measures the minimum number of edits, including substitution, insertion, deletion, and shift of blocks of words, that are needed to modify a hypothesis so that it exactly matches the other hypothesis. The best alignment is the one that gives the minimum number of translation edits. TER-based confusion network construction and system combination has demonstrated superior performance on various large-scale MT tasks (Rosti. et al, 2007). Ho</context>
<context position="23103" citStr="Snover et al., 2006" startWordPosition="3757" endWordPosition="3760">.3.1 Comparison with TER alignment In the IHMM-based method, the smoothing factor for surface similarity model is set to ρ = 3, the interpolation factor of the overall similarity model is set to α = 0.3, and the controlling factor of the distance-based distortion parameters is set to K=2. These settings are optimized on the dev set. Individual system results and system combination results using both IHMM and TER alignment, on both the dev and test sets, are presented in Table 1. The TER-based hypothesis alignment tool used in our experiments is the publicly available TER Java program, TERCOM (Snover et al., 2006). Default settings of TERCOM are used in the following experiments. On the dev set, the case insensitive BLEU score of the IHMM-based 8-way system combination output is about 5.8 points higher than that of the best single system. Compared to the TER-based method, the IHMM-based method is about 1.5 BLEU points better. On the MT08 test set, the IHMM-based system combination gave a case sensitive BLEU score of 30.89%. It outperformed the best single system by 4.7 BLEU points and the TER-based system combination by 1.0 BLEU points. Note that the best single system on the dev set and the test set a</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Rich Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proc. of AMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
</authors>
<title>Hisami Suzuki and Achim Ruopp.</title>
<date>2008</date>
<booktitle>In Proc. of ACL.</booktitle>
<pages>514--522</pages>
<marker>Toutanova, 2008</marker>
<rawString>Kristina Toutanova, Hisami Suzuki and Achim Ruopp. 2008. Applying Morphology Generation Models to Machine Translation. In Proc. of ACL. pp. 514 – 522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM-based Word Alignment In Statistical Translation.</title>
<date>1996</date>
<booktitle>In Proc. of COLING.</booktitle>
<pages>836--841</pages>
<contexts>
<context position="5572" citStr="Vogel et al., 1996" startWordPosition="841" endWordPosition="844">rk. E1 he have good carEBaz=min E2 he has nice sedangeE E3 it a nice car _ E4 a sedan he has e.g., EB — E1 (a) hypothesis set (b) backbone selection he have ε good car he has ε nice sedan it ε a nice car he has a ε sedan (c) hypothesis alignment (d) confusion network Figure 1: Confusion-network-based MT system combination. 3 Indirect-HMM-based Hypothesis Alignment In confusion-network-based system combination for SMT, a major difficulty is aligning hypotheses to the backbone. One possible statistical model for word alignment is the HMM, which has been widely used for bilingual word alignment (Vogel et al., 1996, Och and Ney, 2003). In this paper, we propose an indirect-HMM method for monolingual hypothesis alignment. 3.1 IHMM for hypothesis alignment Let denote the backbone, �&apos; _ ( ,...,dj) a hypothesis to be aligned to e; , and the alignment that specifies the position of the backbone word aligned to each hypothesis word. We treat each word in the backbone as an HMM state and the words in the hypothesis as the observation sequence. We use a first-order HMM, assuming that the emission probability depends only on the backbone word, and the transition probability p(aj I aj_,,I) depends only on the pos</context>
<context position="10625" citStr="Vogel et al., 1996" startWordPosition="1702" endWordPosition="1705">n probabilities of the HMM, models the first-order dependencies of word ordering. In bilingual HMM-based word alignment, it is commonly assumed that transition probabilities 1 The other direction, , is available from the source-to-target translation model. 2 Usually a small back-off value is assigned instead of 0. (fk |ei) 2 K  (fk |ei) 2 k 0 100 Following Och and Ney (2003), we use a fixed value p0 for the probability of jumping to a null state, which can be optimized on held-out data, and the overall distortion model becomes p(aj = i I aj_l = [J) depend only on the jump distance (i - i&apos;) (Vogel et al., 1996): (5) As suggested by Liang et al. (2006), we can group the distortion parameters {c(d)}, d= i - i&apos;, into a few buckets. In our implementation, 11 buckets are used for c(≤-4), c(-3), ... c(0), ..., c(5), c(≥6). The probability mass for transitions with jump distance larger than 6 and less than -4 is uniformly divided. By doing this, only a handful of c(d) parameters need to be estimated. Although it is possible to estimate them using the EM algorithm on a small development set, we found that a particularly simple model, described below, works surprisingly well in our experiments. Since both th</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. HMM-based Word Alignment In Statistical Translation. In Proc. of COLING. pp. 836-841.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chao Wang</author>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
</authors>
<title>Chinese Syntactic Reordering for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL.</booktitle>
<pages>737--745</pages>
<contexts>
<context position="21560" citStr="Wang et al. (2007" startWordPosition="3508" endWordPosition="3511">were true-cased before scoring using a log-linear conditional Markov model proposed by Toutanova et al. (2008). However, to save computation effort, the results on the dev set are reported in case insensitive BLEU (ciBLEU) score instead. 5.3 Experimental results In our main experiments, outputs from a total of eight single MT systems were combined. As listed in Table 1, Sys-1 is a tree-to-string system proposed by Quirk et al., (2005); Sys-2 is a phrasebased system with fast pruning proposed by Moore and Quirk (2008); Sys-3 is a phrase-based system with syntactic source reordering proposed by Wang et al. (2007a); Sys-4 is a syntax-based preordering system proposed by Li et. al. (2007); Sys5 is a hierarchical system proposed by Chiang (2007); Sys-6 is a lexicalized re-ordering system proposed by Xiong et al. (2006); Sys-7 is a twopass phrase-based system with adapted LM proposed by Foster and Kuhn (2007); and Sys-8 is 103 a hierarchical system with two-pass rescoring using a parser-based LM proposed by Wang et al., (2007b). All systems were trained within the confines of the constrained training condition of NIST MT08 evaluation. These single systems are optimized with maximum-BLEU training on diffe</context>
</contexts>
<marker>Wang, Collins, Koehn, 2007</marker>
<rawString>Chao Wang, Michael Collins, and Philipp Koehn. 2007a. Chinese Syntactic Reordering for Statistical Machine Translation. In Proc. of EMNLP-CoNLL. pp. 737-745.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wen Wang</author>
<author>Andreas Stolcke</author>
<author>Jing Zheng</author>
</authors>
<title>Reranking Machine Translation Hypotheses With Structured and Web-based Language Models.</title>
<date>2007</date>
<booktitle>In Proc. of IEEE ASRU.</booktitle>
<pages>159--164</pages>
<contexts>
<context position="21560" citStr="Wang et al. (2007" startWordPosition="3508" endWordPosition="3511">were true-cased before scoring using a log-linear conditional Markov model proposed by Toutanova et al. (2008). However, to save computation effort, the results on the dev set are reported in case insensitive BLEU (ciBLEU) score instead. 5.3 Experimental results In our main experiments, outputs from a total of eight single MT systems were combined. As listed in Table 1, Sys-1 is a tree-to-string system proposed by Quirk et al., (2005); Sys-2 is a phrasebased system with fast pruning proposed by Moore and Quirk (2008); Sys-3 is a phrase-based system with syntactic source reordering proposed by Wang et al. (2007a); Sys-4 is a syntax-based preordering system proposed by Li et. al. (2007); Sys5 is a hierarchical system proposed by Chiang (2007); Sys-6 is a lexicalized re-ordering system proposed by Xiong et al. (2006); Sys-7 is a twopass phrase-based system with adapted LM proposed by Foster and Kuhn (2007); and Sys-8 is 103 a hierarchical system with two-pass rescoring using a parser-based LM proposed by Wang et al., (2007b). All systems were trained within the confines of the constrained training condition of NIST MT08 evaluation. These single systems are optimized with maximum-BLEU training on diffe</context>
</contexts>
<marker>Wang, Stolcke, Zheng, 2007</marker>
<rawString>Wen Wang, Andreas Stolcke, Jing Zheng. 2007b. Reranking Machine Translation Hypotheses With Structured and Web-based Language Models. In Proc. of IEEE ASRU. pp. 159 – 164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Maximum Entropy Based Phrase Reordering Model for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proc. of ACL.</booktitle>
<pages>521--528</pages>
<contexts>
<context position="21768" citStr="Xiong et al. (2006)" startWordPosition="3543" endWordPosition="3546">ve BLEU (ciBLEU) score instead. 5.3 Experimental results In our main experiments, outputs from a total of eight single MT systems were combined. As listed in Table 1, Sys-1 is a tree-to-string system proposed by Quirk et al., (2005); Sys-2 is a phrasebased system with fast pruning proposed by Moore and Quirk (2008); Sys-3 is a phrase-based system with syntactic source reordering proposed by Wang et al. (2007a); Sys-4 is a syntax-based preordering system proposed by Li et. al. (2007); Sys5 is a hierarchical system proposed by Chiang (2007); Sys-6 is a lexicalized re-ordering system proposed by Xiong et al. (2006); Sys-7 is a twopass phrase-based system with adapted LM proposed by Foster and Kuhn (2007); and Sys-8 is 103 a hierarchical system with two-pass rescoring using a parser-based LM proposed by Wang et al., (2007b). All systems were trained within the confines of the constrained training condition of NIST MT08 evaluation. These single systems are optimized with maximum-BLEU training on different subsets of the previous NIST MT test data. The bilingual translation models used to compute the semantic similarity are from the worddependent HMMs proposed by He (2007), which are trained on two million</context>
</contexts>
<marker>Xiong, Liu, Lin, 2006</marker>
<rawString>Deyi Xiong, Qun Liu and Shouxun Lin. 2006. Maximum Entropy Based Phrase Reordering Model for Statistical Machine Translation. In Proc. of ACL. pp. 521 – 528.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>