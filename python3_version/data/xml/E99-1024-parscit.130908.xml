<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.713147">
Proceedings of EACL &apos;99
</note>
<title confidence="0.9989435">
Detection of Japanese Homophone Errors by a Decision List
Including a Written Word as a Default Evidence
</title>
<author confidence="0.995964">
Hiroyuki Shinnou
</author>
<affiliation confidence="0.9987085">
Ibaraki University
Dept. of Systems Engineering
</affiliation>
<address confidence="0.9246245">
4-12-1 Nakanarusawa
Hitachi, Ibaraki, 316-8511, JAPAN
</address>
<email confidence="0.969431">
shinnoalily.dse.ibaraki.ac.jp
</email>
<sectionHeader confidence="0.998242" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999980571428571">
In this paper, we propose a practical
method to detect Japanese homophone
errors in Japanese texts. It is very
important to detect homophone errors
in Japanese revision systems because
Japanese texts suffer from homophone
errors frequently. In order to detect ho-
mophone errors, we have only to solve
the homophone problem. We can use the
decision list to do it because the homo-
phone problem is equivalent to the word
sense disambiguation problem. However,
the homophone problem is different from
the word sense disambiguation problem
because the former can use the written
word but the latter cannot. In this pa-
per, we incorporate the written word into
the original decision list by obtaining the
identifying strength of the written word.
The improved decision list can raise the
F-measure of error detection.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994570203389831">
In this paper, we propose a method of detect-
ing Japanese homophone errors in Japanese texts.
Our method is based on a decision list proposed by
Yarowsky (Yarowsky, 1994; Yarowsky, 1995). We
improve the original decision list by using writ-
ten words in the default evidence. The improved
decision list can raise the F-measure of error de-
tection.
Most Japanese texts are written using Japanese
word processors. To input a word composed of
kanji characters, we first input the phonetic hira-
gana sequence for the word, and then convert it
to the desired kanji sequence. However, multiple
converted kanji sequences are generally produced,
and we must then choose the correct kanji se-
quence. Therefore, Japanese texts suffer from ho-
mophone errors caused by incorrect choices. Care-
lessness of choice alone is not the cause of homo-
phone errors; Ignorance of the difference among
homophone words is serious. For example, many
Japanese are not aware of the difference between
`&apos; and &apos;PA&apos;s&apos;, or between &apos;AS&apos; and &apos;VW&apos;.
In this paper, we define the term homophone
set as a set of words consisting of kanji charac-
ters that have the same phone 2. Then, we define
the term homophone word as a word in a ho-
mophone set. For example, the set {4.41. (proba-
bility), WI (establishment)} is a homophone set
because words in the set are composed of kanji
characters that have the same phone `ka-ku-ri-tu&apos;.
Thus, &apos;WV and Iii-SL&amp;quot; are homophone words. In
this paper, we name the problem of choosing the
correct word from the homophone set the homo-
phone problem. In order to detect homophone
errors, we make a list of homophone sets in ad-
vance, find a homophone word in the text, and
then solve the homophone problem for the homo-
phone word.
Many methods of solving the homophone prob-
lem have been proposed (Tochinai et al., 1986;
Ibuki et al., 1997; Oku and Matsuoka, 1997; Oku,
1994; Wakita and Kaneko, 1996). However, they
are restricted to the homophone problem, that is,
they are heuristic methods. On the other hand,
the homophone problem is equivalent to the word
sense disambiguation problem if the phone of the
homophone word is regarded as the word, and the
homophone word as the sense. Therefore, we can
solve the homophone problem by using various
`&apos; and have a same phone `i-shi&apos;. The
meaning of is a general will, and the meaning of
`&apos; is a strong positive will. &apos;AS&apos; and have
a same phone (cho-kkan&apos;. The meaning of &apos;Lae, is an
intuition through a feeling, and the meaning of
is an intuition through a latent knowledge.
2We ignore the difference of accents, stresses and
parts of speech. That is, the homophone set is the
set of words having the same expression in hiragana
characters.
</bodyText>
<page confidence="0.990525">
180
</page>
<bodyText confidence="0.985415695652174">
Proceedings of EACL &apos;99
statistical methods proposed for the word sense
disambiguation problem(Fujii, 1998). Take the
case of context-sensitive spelling error detection
3, which is equivalent to the homophone problem.
For that problem, some statistical methods have
been applied and succeeded(Golding, 1995; Gold-
ing and Schabes, 1996). Hence, statistical meth-
ods are certainly valid for the homophone prob-
lem. In particular, the decision list is valid for
the homophone problem(Shinnou, 1998). The de-
cision list arranges evidences to identify the word
sense in the order of strength of identifying the
sense. The word sense is judged by the evidence,
with the highest identifying strength, in the con-
text.
Although the homophone problem is equivalent
to the word sense disambiguation problem, the
former has a distinct difference from the latter.
In the homophone problem, almost all of the an-
swers are given correctly, because almost all of the
expressions written in the given text are correct.
It is difficult to decide which is the meaning of
&apos;crane&apos;, &apos;crane of animal&apos; or &apos;crane of tool&apos;. How-
ever, it is almost right that the correct expression
of in a text is not `2 but In
the homophone problem, the choice of the writ-
ten word results in high precision. We should use
this information. However, the method to always
choose the written word is useless for error detec-
tion because it doesn&apos;t detect errors at all. The
method used for the homophone problem should
be evaluated from the precision and the recall of
the error detection. In this paper, we evaluate it
by the F-measure to combine the precision and
the recall, and use the written word to raise the
F-measure of the original decision list.
We use the written word as an evidence of the
decision list. The problem is how much strength
to give to that evidence. If the strength is high,
the precision rises but the recall drops. On the
other hand, if the strength is low, the decision list
is not improved. In this paper, we calculate the
strength that gives the maximum F-measure in a
training corpus. As a result, our decision list can
raise the F-measure of error detection.
</bodyText>
<sectionHeader confidence="0.899915" genericHeader="method">
2 Homophone disambiguation by a
decision list
</sectionHeader>
<bodyText confidence="0.933564333333333">
In this section, we describe how to construct the
decision list and to apply it to the homophone
problem.
&apos;For example, confusion between &apos;peace&apos; and
&apos;piece&apos;, or between &apos;quiet&apos; and &apos;quite&apos; is the context-
sensitive spelling error.
</bodyText>
<subsectionHeader confidence="0.999433">
2.1 Construction of the decision list
</subsectionHeader>
<bodyText confidence="0.693166166666667">
The decision list is constructed by the following
steps.
step 1 Prepare homophone sets.
In this paper, we use the 12 homophone sets
shown in Table 1, which consist of homophone
words that tend to be mis-chosen.
</bodyText>
<tableCaption confidence="0.999505">
Table 1: Homophone sets
</tableCaption>
<table confidence="0.967584214285714">
Phone Homophone set
sa-i-ken { fr4, TA }
ka-i-hou { AT iik, RN a }
kyo-u-cho-u { taX, 3.04 }
ji-shi-n { fl ig-, 11$#&apos; }
ka-n-shi-n { 841,, Pk: }
ta-i-ga-i { Xn, .1-M.- }
u-n-ko-u { &apos;AC, Alt- }
do-u-shi { RI .&apos;,., IT7g± }
ka-te-i {ilfl, Slf`i }
ji-kko-u {&apos;&apos;f-T- }
syo-ku-ryo-u { ftf-1-, Art }
syo-u-ga-i 14 - I t
{,„ ., }
</table>
<tableCaption confidence="0.4195525">
step 2 Set context information, i.e. evidences, to
identify the homophone word.
</tableCaption>
<bodyText confidence="0.990278">
We use the following three kinds of evidence.
</bodyText>
<listItem confidence="0.951381333333333">
• word (w) in front of H: Expressed as w—
• word (w) behind H: Expressed as w+
• jiritu words 4 surrounding H: We pick up
the nearest three jiritu words in front of and
behind H respectively. We express them as
w ± 3.
</listItem>
<bodyText confidence="0.929671066666667">
step 3 Derive the frequency f rq(wi, ei) of the
collocation between the homophone word wi
in the homophone set {wi, w2, • ,w,} and
the evidence ei, by using a training corpus.
For example, let us consider the homophone set
{ ifia (running (of a ship, etc.)), AFT- (running
(of a train, etc.))). and the following two Japanese
sentences.
Sentence 1 I- 2ff0)1WE- — )1,-&amp;quot;ClIfi-Mor)
tQj
(A west wind of 3 m/s did not prevent the
plane from flying.)
4The jiritu word is defined as an independent word
which can form one bun-setu by itself. Nouns, verbs
and adjectives are examples.
</bodyText>
<page confidence="0.993975">
181
</page>
<table confidence="0.427851">
Proceedings of EACL &apos;99
</table>
<tableCaption confidence="0.970704">
Table 2: Answers and identifying strength for evidences
</tableCaption>
<table confidence="0.948707692307692">
Evid. Freq. of `Att&amp;quot;311 Ans. Identifying
Freq. of Strength
-1.&apos;
:+ (to+) 77 53 ile 0.538
0)— (of-) 252 282 iIi-T- 0.162
Afril ±3 (plane±3) 4 0 aa 5.358
••• --- •-• --- •-•
04r4+ (hour+) 14 11 AC 0.345
Rik ±3 (midnight±3) 0 48 itit- 8.910
ES ±3 (shorten±3) 0 4 Ari- 5.358
••• --- •-• --- • -
default 1468 1422 Ag 0.046
Sentence 2 FR-ONAMOLgfiliVEWV.rd 0 J
</table>
<bodyText confidence="0.9963575">
(Running hours in the early morning and dur-
ing the night were shortened.)
From sentence 1, we can extract the following
evidences for the word &apos;AK&apos;:
</bodyText>
<equation confidence="0.7822605">
&amp;quot;tz +&amp;quot;, &amp;quot;0) —&amp;quot; ±3&amp;quot; ±3&amp;quot;, &amp;quot;E ±3&amp;quot;,
±3&amp;quot;, &amp;quot;Z# ±3&amp;quot;, &amp;quot;&apos;1i±3&amp;quot;,
</equation>
<bodyText confidence="0.985073857142857">
and from sentence 2, we can extract the following
evidences for the word &apos;AFT&apos;:
&amp;quot;114 RAI +&amp;quot; , &amp;quot;0) ---&amp;quot; , &amp;quot;MA ±3&amp;quot;, &amp;quot;V-#11 ±3&amp;quot; ,
44r39 ±3&amp;quot;, &amp;quot;EN ±3&amp;quot;, &amp;quot;t ±r.
step 4 Define the strength est(wi, e1) of estimat-
ing that the homophone word wi is correct
given the evidence e:
</bodyText>
<equation confidence="0.6606345">
P(wi )
est(wi, ei) = log(Ekoi P(wk lei)
</equation>
<bodyText confidence="0.9655775">
where P(wi Iej) is approximately calculated
by:
</bodyText>
<equation confidence="0.991927">
f rq(wi, ei) + a
P (wile j) =
Ek f rq(wk, ei) + a
</equation>
<bodyText confidence="0.98607844">
a in the above expression is included to avoid
the unsatisfactory case of f rq(wi, ei) = 0. In
this paper, we set a = 0.15. We also use the
special evidence default. f rq(wi, default) is
defined as the frequency of w.
step 5 Pick the highest strength est(wk, ej)
among
5As in this paper, the addition of a small value is
an easy and effective way to avoid the unsatisfactory
case, as shown in (Yarowsky, 1994).
fest(tvi, ej), est(w2, ei), , est(w„, ej)},
and set the word wk as the answer for the
evidence ej. In this case, the identifying
strength is est(wk, ei).
For example, by steps 4 and 5 we can construct
the list shown in Table 2.
step 6 Fix the answer wki for each ej and sort
identifying strengths est(wk,, ej) in order of
dimension, but remove the evidence whose
identifying strength is less than the identi-
fying strength est(wk,, default) for the evi-
dence default from the list. This is the deci-
sion list.
After step 6, we obtain the decision list for the
homophone set { 11,1T} as shown in Table 3.
</bodyText>
<tableCaption confidence="0.998932">
Table 3: Example of decision list
</tableCaption>
<table confidence="0.999732545454545">
Rank Evid. Ans. Strength
1 n* ±3 (train±3) 15-- 9.453
2 IY, ±3 (ship±3) ilg 9.106
3 ig7&amp; ±3 Ali- 8.910
(midnight±3)
... ... ••• •-•
701 fisIrgi— (hour-) Ail 0.358
... ... •-• •&amp;quot;
746 Q)+ (of+) Ail 0.162
--- --- ••• •-•
760 default ila 0.046
</table>
<subsectionHeader confidence="0.997094">
2.2 Solving by a decision list
</subsectionHeader>
<bodyText confidence="0.99982275">
In order to solve the homophone problem by the
decision list, we first find the homophone word w
in the given text, and then extract evidences E for
the word w from the text:
</bodyText>
<page confidence="0.987495">
182
</page>
<bodyText confidence="0.9342609">
Proceedings of EACL &apos;99
Next, picking up the evidence from the deci-
sion list for the homophone set for the homophone
word to in order of rank, we check whether the ev-
idence is in the set E. If the evidence ei is in the
set E, the answer tvki for ei is judged to be the
correct expression for the homophone word w. If
wk, is equal to to, w is judged to be correct, and
if it is not equal, then it is shown that to may be
the error for wki
</bodyText>
<sectionHeader confidence="0.840576" genericHeader="method">
3 Use of the written word
</sectionHeader>
<bodyText confidence="0.990503333333333">
In this section, we describe the use of the writ-
ten word in the homophone problem and how to
incorporate it into the decision list.
</bodyText>
<subsectionHeader confidence="0.994172">
3.1 Evaluation of error detection systems
</subsectionHeader>
<bodyText confidence="0.971946208333333">
As described in the Introduction, the written word
cannot be used in the word sense disambiguation
problem, but it is useful for solving homophone
problems. The method used for the homophone
problem is trivial if the method is evaluated by
the precision of distinction using the following for-
mula:
number of correct discriminations
number of all discriminations
That is, if the expression is &apos;AVE&apos; (or `g_FP),
then we should clearly choose the word &apos;AV
(or the word `11,1T) from the homophone set {
Ag, ff }. This distinction method probably
has better precision than any other methods for
the word sense disambiguation problem. However,
this method is useless because it does not detect
errors at all.
The method for the homophone problem should
be evaluated from the standpoint of not error dis-
crimination but error detection. In this paper, we
use the F-measure (Eq.1) to combine the precision
P and the recall R defined as follows:
= number of real errors in detected errors
P
</bodyText>
<equation confidence="0.7855172">
R = number of real errors in detected errors
number of errors in the text
2P R
F = (1)
P R
</equation>
<subsectionHeader confidence="0.715503">
3.2 Use of the identifying strength of the
</subsectionHeader>
<bodyText confidence="0.971135416666667">
written word
The distinction method to choose the written
word is useless, but it has a very high precision
of error discrimination. Thus, it is valid to use
this method where it is difficult to use context to
solve the homophone problem.
The question is when to stop using the deci-
sion from context and use the written word. In
this paper, we regard the written word as a kind
of evidence on context, and give it an identifying
strength. Consequently we can use the written
word in the decision list.
</bodyText>
<subsectionHeader confidence="0.752393">
3.3 Calculation of the identifying
strength of the written word
</subsectionHeader>
<bodyText confidence="0.999955857142857">
First, let a be the identifying strength of the writ-
ten word. We name the set of evidences with
higher identifying strength than a the set a, and
the set of evidences with lower identifying strength
than a the set 0,
Let T be the number of homophone problems
for a homophone set. We solve them by the orig-
inal decision list DLO. Let G (or H) be the ratio
of the number of homophone problems by judged
by a (or 0 ) to T. Let g (or h) be the precision of
a (or )3), and p be the occurrence probability of
the homophone error.
The number of problems correctly solved by a
is as follows:
</bodyText>
<equation confidence="0.990736">
GT(1 — p), (2)
</equation>
<bodyText confidence="0.9857555">
and the number of problems incorrectly solved by
a is as follows:
</bodyText>
<equation confidence="0.936855">
GTp. (3)
</equation>
<bodyText confidence="0.99990675">
The number of problems detected as errors in Eq.2
and Eq.3 are GT(1— p)(1— g) and GTpg respec-
tively. Thus, the number of problems detected as
errors by a is as follows:
</bodyText>
<equation confidence="0.987431">
GT((1 — p)(I — g) + pg). (4)
</equation>
<bodyText confidence="0.9999635">
In the same way, the number of problems detected
as errors by 0 is as follows:
</bodyText>
<equation confidence="0.985348">
HT((1 — p)(1 — h)+ ph). (5)
</equation>
<bodyText confidence="0.998808">
Consequently the total number of problems de-
tected as errors is as follows:
</bodyText>
<equation confidence="0.890157">
T(G((1 — p)(1 — g) + pg) + H ((1 — p)(1 — h) + ph)).
</equation>
<bodyText confidence="0.94181425">
(6)
The number of correct detections in Eq.6 is
Tp(Gg + Hh). Therefore the precision Po is as
follows:
</bodyText>
<equation confidence="0.6202285">
Po = AGg + Hh)11G((1 — p)(1 — g) + pg)
+ H((1 — p)(1 — ph)}
</equation>
<bodyText confidence="0.98922475">
Because the number of real errors in T is Tp, the
recall Ro is Gg +Hh. By using Po and Ro, we can
get the F-measure Fo of DLO by Eq.1.
Next, we construct the decision list incorporat-
ing the written word into DLO. We name this deci-
sion list DL!. In DL I, we use the written word to
solve problems which we cannot judge by a. That
number of detected errors
</bodyText>
<page confidence="0.975506">
183
</page>
<figure confidence="0.988561875">
Proceedings of EACL &apos;99
livid. Ans. Strength
DLO
livid. Ans. Strength
a
x+ E
x- E
livid. Ans. Strength
a
x+ E
vri Lien
word Lien) X
(wri
word
DL1
=&gt;
</figure>
<figureCaption confidence="0.999998">
Figure 1: Construction of DL1
</figureCaption>
<bodyText confidence="0.998740538461538">
is, DL1 is the decision list to attach the written
word as the default evidence to a (see Fig.1).
Next, we calculate the precision and the recall
of DL1. Because a of DL1 is the same as that of
DLO, the number of problems detected as errors by
a is given by Eq.4. In the case of DL1, problems
judged by ft of DLO are judged by the written
word. Therefore, we detect no error from these
problems.
As a result, the number of problems detected as
errors by DL1 is given by Eq.4, and the number of
real errors in these detections is TGpg. Therefore,
the precision P1 of DL1 is as follows:
</bodyText>
<equation confidence="0.677734">
Pg
=
(1 — p)(1 — g) pg •
</equation>
<bodyText confidence="0.994517324324324">
Because the number of whole errors is Tp, the
recall R1 of DL1 is Gg. By using Pi. and R1, we
can get the F-measure F1 of DL1 by Eq.1.
Finally, we try to define the identifying strength
x. x is the value that yields the maximum F1 un-
der the condition F1 &gt; Fo. However, theoretical
calculation alone cannot give x, because p is un-
known, and functions of G,H,g, and h are also
unknown.
In this paper, we set p = 0.05, and get values of
G, H, g, and h by using the training corpus which
is the resource used to construct the original deci-
sion list DLO. Take the case of the homophone set
`iCT&apos;l. For this homophone set, we try to
get values of G, H, g, and h. The training corpus
has 2,890 sentences which include the word &apos;ii&apos;
or the word These 2,890 sentences are ho-
mophone problems for that homophone set. The
identifying strength of DLO for this homophone
set covers from 0.046 to 9.453 as shown in Table 3.
Next we give x a value. For example, we set x =
2.5. In this case, the number of problems judged
by a is 1,631, and the number of correct judgments
in them is 1,593. Thus, G = 1631/2890 = 0.564
and g = 1593/1631 = 0.977. In the same way,
under this assumption x = 2.5, the num-
ber of problems judged by fl is 1,259, and
the number of correct judgments in them
is 854. Thus, H = 1259/2890 = 0.436 and
h = 854/1259 = 0.678. As a result, if x = 2.5,
then Po = 0.225, Ro = 0.847, Fo = 0.356,
= 0.688, R1 = 0.551 and F1 = 0.612. In Fig.2,
Fig.3 and Fig.4, we show the experiment result
when x varies from 0.0 to 10.0 in units of 0.1. By
choosing the maximum value of F1 in Fig.4, we
can get the desired x. In this homophone set, we
obtain a = 3.0.
</bodyText>
<sectionHeader confidence="0.998916" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999824047619048">
First, we obtain each identifying strength of the
written word for the 12 homophone sets shown
in Table 1, by the above method. We show this
result in Table 4. LRO in this table means the
lowest rank of DLO. That is, LRO is the rank of
the de fault evidence. LR1 means the lowest rank
of DLL That is, LR1 is the rank of the evidence of
the written word. Moreover, LRO and LR1 mean
the sizes of each decision list DLO and DLL
Second, we extract sentences which include a
word in the 12 homophone sets from a corpus. We
note that this corpus is different from the training
corpus; the corpus is one year&apos;s worth of Mainichi
newspaper articles, and the training corpus is one
year&apos;s worth of Nikkei newspaper articles. The
extracted sentences are the test sentences of the
experiment. We assume that these sentences have
no homophone errors.
Last, we randomly select 5% of the test sen-
tences, and forcibly put homophone errors into
these selected sentences by changing the written
</bodyText>
<page confidence="0.993934">
184
</page>
<figure confidence="0.9842105">
Proceedings of EACL &apos;99
0.9
0.8
07
0.6
2
3
4
6
7
10
9
</figure>
<tableCaption confidence="0.994425">
Table 4: Identifying strength of the expression
</tableCaption>
<table confidence="0.987475866666667">
homophone set Identifying LRO LR1
strength
of expression
{ fr4, TA } 4.9 1062 844
{ Nft, Wit } 4.6 1104 671
{WC 5.013 } 4.3 1120 667
{ f113, 11 A. } 4.8 1134 622
{ 16,b, FA,b } 5.7 1007 424
{ 101-, M. } 3.9 921 921
{ Ala, ill-T- } 3.0 760 319
{ HZ, 51± } 4.5 811 788
{ it_kfi, 30.2 } 5.1 799 469
{ VOJ, VI&apos; } 4.3 760 665
{ kV-, kg } 4.7 697 255
{144, Pt i. } 5.1 695 397
</table>
<figure confidence="0.876311333333333">
0.5
0.4
0.3
</figure>
<figureCaption confidence="0.651612">
Figure 2: Precisions Po and P1
</figureCaption>
<figure confidence="0.9996628125">
0.2
0
o
&apos;DIA&apos;
0.9
0.8
0.7
0.8
0.5
0.4 WOO).
0.3 0005
000
0.2 GO 000
0l co 1
**4.0040
3 4 6 7 8 10
</figure>
<figureCaption confidence="0.968821">
Figure 3: Recalls Ro and R1
</figureCaption>
<figure confidence="0.999116533333333">
D1..1 0
511•0&apos; •
00 00000000
0
000 0000
0000
.0
0000.
0.7
0.6
05
0.4
0.3
0.2
4 5 6 10
</figure>
<figureCaption confidence="0.999912">
Figure 4: F-measures F0 and F1
</figureCaption>
<bodyText confidence="0.999940636363636">
homophone word to another homophone word.
As a result, the test sentences include 5% errors.
From these test sentences, we detect homophone
errors by DLO and DL1 respectively.
We conducted this experiment ten times, and
got the mean of the precision, the recall and the
F-measure. The result is shown in Table 5.
For all homophone sets, the F-measure of our
proposed DL1 is higher than the F-measure of the
original decision list DLO. Therefore, it is con-
cluded that our proposed method is effective.
</bodyText>
<sectionHeader confidence="0.999299" genericHeader="method">
5 Remarks
</sectionHeader>
<bodyText confidence="0.999919272727273">
The recall of DL1 is no more than the recall of
DLO. Our method aims to raise the F-measure
by raising the precision instead of sacrificing the
recall. We confirmed the validity of the method by
experiments in sections 3 and 4. Thus our method
has only a little effect if the recall is evaluated
with importance. However, we should note that
the F-measure of DL1 is always not worse than
the F-measure of DLO.
We set the occurrence probability of the homo-
phone error at p = 0.05. However, each homo-
phone set has its own p. We need decide p exactly
because the identifying strength of the written
word depends on p. However, DL1 will produce
better results than DLO if p is smaller than 0.05,
because the precision of judgment by the written
word improves without lowering the recall. The
recall does not fall due to smaller p because Ro
and R1 are independent of p. Moreover, from the
definitions of Po and Pi, we can confirm that the
precision of judgments by the written word im-
proves with smaller p.
</bodyText>
<page confidence="0.998581">
185
</page>
<tableCaption confidence="0.899491">
Proceedings of EACL &apos;99
Table 5: Result of experiments
</tableCaption>
<table confidence="0.998143210526316">
homophone set Number of DLO DL1
problems
Po Ro Fo Fi Ri Fi
{ fillg, Ira } 1,254 0.190 0.824 0.309 0.310 0.774 0.443
{ liiMC, PM } 1,938 0.295 0.899 0.443 0.573 0.835 0.680
{ tAX), 3034 } 4,845 0.583 0.957 0.724 0.616 0.934 0.742
{ illg, gift} 3,682 0.343 0.911 0.499 0.470 0.725 0.571
{ S,b, IML.&apos; } 2,032 0.773 0.987 0.867 0.804 0.981 0.884
{ XYI-, #Y1- } 618 0.708 0.980 0.822 0.806 0.980 0.885
{ ilg, if.fi } 588 0.127 0.745 0.217 0.289 0.420 0.342
{ HZ, 171± 1,436 0.391 0.939 0.552 0.440 0.913 0.594
}
1SVI 1,220 0.789 0.990 0.879 0.903 0.910 0.906
1
{ Zit, AFT } 1,563 0.548 0.966 0.700 0.617 0.911 0.736
{ AT4-, ka } 1,074 0.091 0.692 0.161 0.135 0.287 0.183
{ 14*, Iltr. 1,636 0.681 0.976 0.802 0.760 0.858 0.806
}
mean 1,824 0.460 0.906 0.581 0.560 0.794 0.648
</table>
<bodyText confidence="0.999761541666667">
The number of elements of all homophone sets
used in this paper was two, but the number of
elements of real homophone sets may be more.
However, the bigger this number is, the better
the result produced by our method, because the
precision of judgments by the default evidence of
DLO drops in this case, but that of DL1 does not.
Therefore, our method is better than the original
one even if the number of elements of the homo-
phone set increases.
Our method has an advantage that the size of
DL1 is smaller. The size of the decision list has
no relation to the precision and the recall, but a
small decision list has advantages of efficiency of
calculation and maintenance.
On the other hand, our method has a problem in
that it does not use the written word in the judg-
ment from a; Even the identifying strength of the
evidence in a must depend on the written word.
We intend to study the use of the written word
in the judgment from a. Moreover, homophone
errors in our experiments are artificial. We must
confirm the effectiveness of the proposed method
for actual homophone errors.
</bodyText>
<sectionHeader confidence="0.99979" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999977733333333">
In this paper, we used the decision list to solve the
homophone problem. This strategy was based on
the fact that the homophone problem is equivalent
to the word sense disambiguation problem. How-
ever, the homophone problem is different from the
word sense disambiguation problem because the
former can use the written word but the latter
cannot. In this paper, we incorporated the writ-
ten word into the original decision list by obtain-
ing the identifying strength of the written word.
We used 12 homophone sets in experiments. In
these experiments, our proposed decision list had
a higher F-measure than the original one. A fu-
ture task is to further integrate context and the
written word in the decision list.
</bodyText>
<sectionHeader confidence="0.998877" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999824666666667">
We used Nikkei Shibun CD-ROM &apos;90 and
Mainichi Shibun CD-ROM &apos;94 as the corpus. The
Nihon Keizai Shinbun company and the Mainichi
Shinbun company gave us permission of their col-
lections. We appreciate the assistance granted by
both companies.
</bodyText>
<sectionHeader confidence="0.999375" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999303117647059">
Atsushi Fujii. 1998. Corpus-Based Word
Sence Disambiguation (in Japanese). Journal
of Japanese Society for Artificial Intelligence,
13(6):904-911.
Andrew R. Golding and Yves Schabes. 1996.
Combining Trigram-based and Feature-based
Methods for Context-Sensitive Spelling Correc-
tion. In nth Annual Meeting of the Association
for Computational Linguistics, pages 71-78.
Andrew R. Golding. 1995. A Bayesian Hybrid
Method for Context-Sensitive Spelling Correc-
tion. In Third Workshop on Very Large Corpora
(WVLC-95), pages 39-53.
Jun Ibuki, Guowei Xu, Takahiro Saitoh, and Ku-
nio Matsui. 1997. A new approach for Japanese
Spelling Correction (in Japanese). SIG Notes
NL-117-21, IPSJ.
</reference>
<page confidence="0.987567">
186
</page>
<reference confidence="0.999440371428572">
Proceedings of EACL &apos;99
Masahiro Oku and Koji Matsuoka. 1997. A
Method for Detecting Japanese Homophone
Errors in Compound Nouns based on Char-
acter Cooccurrence and Its Evaluation (in
Japanese). Journal of Natural Language Pro-
cessing, 4(3):83-99.
Masahiro Oku. 1994. Handling Japanese Homo-
phone Errors in Revision Support System; RE-
VISE. In 4th Conference on Applied Natural
Language Processing (ANLP-94), pages 156-
161.
Hiroyuki Shinnou. 1998. Japanese Homohone
Disambiguation Using a Decision List Given
Added Weight to Evidences on Compounds (in
Japanese). Journal of Information Processing,
39(12):3200-3206.
Koji Tochinai, Taisuke Itoh, and Yasuhiro Suzuki.
1986. Kana-Kanji Translation System with Au-
tomatic Homonym Selection Using Character
Chain Matching (in Japanese). Journal of In-
formation Processing, 27(3):313-321.
Sakiko Waldta and Hiroshi Kaneko. 1996. Ex-
traction of Keywords for &amp;quot;Homonym Error
Checker&amp;quot; (in Japanese). SIG Notes NL-111-5,
IPSJ.
David Yarowsky. 1994. Decision Lists for Lex-
ical Ambiguity Resolution: Application to Ac-
cent Restoration in Spanish and French. In 32th
Annual Meeting of the Association for Compu-
tational Linguistics, pages 88-95.
David Yarowsky. 1995. Unsupervised Word Sense
Disambiguation Rivaling Supervised Methods.
In 33th Annual Meeting of the Association for
Computational Linguistics, pages 189-196.
</reference>
<page confidence="0.997931">
187
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.687077">
<note confidence="0.806916">Proceedings of EACL &apos;99</note>
<title confidence="0.967272">Detection of Japanese Homophone Errors by a Decision List Including a Written Word as a Default Evidence</title>
<author confidence="0.991792">Hiroyuki Shinnou</author>
<affiliation confidence="0.9987565">Ibaraki University Dept. of Systems Engineering</affiliation>
<address confidence="0.9954095">4-12-1 Nakanarusawa Ibaraki, 316-8511, JAPAN</address>
<email confidence="0.984376">shinnoalily.dse.ibaraki.ac.jp</email>
<abstract confidence="0.996824818181818">In this paper, we propose a practical method to detect Japanese homophone errors in Japanese texts. It is very important to detect homophone errors in Japanese revision systems because Japanese texts suffer from homophone errors frequently. In order to detect homophone errors, we have only to solve the homophone problem. We can use the decision list to do it because the homophone problem is equivalent to the word sense disambiguation problem. However, the homophone problem is different from the word sense disambiguation problem because the former can use the written word but the latter cannot. In this paper, we incorporate the written word into the original decision list by obtaining the identifying strength of the written word. The improved decision list can raise the F-measure of error detection.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Atsushi Fujii</author>
</authors>
<title>Corpus-Based Word Sence Disambiguation (in Japanese).</title>
<date>1998</date>
<journal>Journal of Japanese Society for Artificial Intelligence,</journal>
<pages>13--6</pages>
<contexts>
<context position="3894" citStr="Fujii, 1998" startWordPosition="646" endWordPosition="647">refore, we can solve the homophone problem by using various `&apos; and have a same phone `i-shi&apos;. The meaning of is a general will, and the meaning of `&apos; is a strong positive will. &apos;AS&apos; and have a same phone (cho-kkan&apos;. The meaning of &apos;Lae, is an intuition through a feeling, and the meaning of is an intuition through a latent knowledge. 2We ignore the difference of accents, stresses and parts of speech. That is, the homophone set is the set of words having the same expression in hiragana characters. 180 Proceedings of EACL &apos;99 statistical methods proposed for the word sense disambiguation problem(Fujii, 1998). Take the case of context-sensitive spelling error detection 3, which is equivalent to the homophone problem. For that problem, some statistical methods have been applied and succeeded(Golding, 1995; Golding and Schabes, 1996). Hence, statistical methods are certainly valid for the homophone problem. In particular, the decision list is valid for the homophone problem(Shinnou, 1998). The decision list arranges evidences to identify the word sense in the order of strength of identifying the sense. The word sense is judged by the evidence, with the highest identifying strength, in the context. A</context>
</contexts>
<marker>Fujii, 1998</marker>
<rawString>Atsushi Fujii. 1998. Corpus-Based Word Sence Disambiguation (in Japanese). Journal of Japanese Society for Artificial Intelligence, 13(6):904-911.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
<author>Yves Schabes</author>
</authors>
<title>Combining Trigram-based and Feature-based Methods for Context-Sensitive Spelling Correction.</title>
<date>1996</date>
<booktitle>In nth Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>71--78</pages>
<contexts>
<context position="4121" citStr="Golding and Schabes, 1996" startWordPosition="676" endWordPosition="680">&apos;. The meaning of &apos;Lae, is an intuition through a feeling, and the meaning of is an intuition through a latent knowledge. 2We ignore the difference of accents, stresses and parts of speech. That is, the homophone set is the set of words having the same expression in hiragana characters. 180 Proceedings of EACL &apos;99 statistical methods proposed for the word sense disambiguation problem(Fujii, 1998). Take the case of context-sensitive spelling error detection 3, which is equivalent to the homophone problem. For that problem, some statistical methods have been applied and succeeded(Golding, 1995; Golding and Schabes, 1996). Hence, statistical methods are certainly valid for the homophone problem. In particular, the decision list is valid for the homophone problem(Shinnou, 1998). The decision list arranges evidences to identify the word sense in the order of strength of identifying the sense. The word sense is judged by the evidence, with the highest identifying strength, in the context. Although the homophone problem is equivalent to the word sense disambiguation problem, the former has a distinct difference from the latter. In the homophone problem, almost all of the answers are given correctly, because almost</context>
</contexts>
<marker>Golding, Schabes, 1996</marker>
<rawString>Andrew R. Golding and Yves Schabes. 1996. Combining Trigram-based and Feature-based Methods for Context-Sensitive Spelling Correction. In nth Annual Meeting of the Association for Computational Linguistics, pages 71-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
</authors>
<title>A Bayesian Hybrid Method for Context-Sensitive Spelling Correction.</title>
<date>1995</date>
<booktitle>In Third Workshop on Very Large Corpora (WVLC-95),</booktitle>
<pages>39--53</pages>
<contexts>
<context position="4093" citStr="Golding, 1995" startWordPosition="674" endWordPosition="675">phone (cho-kkan&apos;. The meaning of &apos;Lae, is an intuition through a feeling, and the meaning of is an intuition through a latent knowledge. 2We ignore the difference of accents, stresses and parts of speech. That is, the homophone set is the set of words having the same expression in hiragana characters. 180 Proceedings of EACL &apos;99 statistical methods proposed for the word sense disambiguation problem(Fujii, 1998). Take the case of context-sensitive spelling error detection 3, which is equivalent to the homophone problem. For that problem, some statistical methods have been applied and succeeded(Golding, 1995; Golding and Schabes, 1996). Hence, statistical methods are certainly valid for the homophone problem. In particular, the decision list is valid for the homophone problem(Shinnou, 1998). The decision list arranges evidences to identify the word sense in the order of strength of identifying the sense. The word sense is judged by the evidence, with the highest identifying strength, in the context. Although the homophone problem is equivalent to the word sense disambiguation problem, the former has a distinct difference from the latter. In the homophone problem, almost all of the answers are giv</context>
</contexts>
<marker>Golding, 1995</marker>
<rawString>Andrew R. Golding. 1995. A Bayesian Hybrid Method for Context-Sensitive Spelling Correction. In Third Workshop on Very Large Corpora (WVLC-95), pages 39-53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Ibuki</author>
<author>Guowei Xu</author>
<author>Takahiro Saitoh</author>
<author>Kunio Matsui</author>
</authors>
<title>A new approach for Japanese Spelling Correction (in Japanese).</title>
<date>1997</date>
<journal>SIG Notes</journal>
<pages>117--21</pages>
<contexts>
<context position="2931" citStr="Ibuki et al., 1997" startWordPosition="481" endWordPosition="484">For example, the set {4.41. (probability), WI (establishment)} is a homophone set because words in the set are composed of kanji characters that have the same phone `ka-ku-ri-tu&apos;. Thus, &apos;WV and Iii-SL&amp;quot; are homophone words. In this paper, we name the problem of choosing the correct word from the homophone set the homophone problem. In order to detect homophone errors, we make a list of homophone sets in advance, find a homophone word in the text, and then solve the homophone problem for the homophone word. Many methods of solving the homophone problem have been proposed (Tochinai et al., 1986; Ibuki et al., 1997; Oku and Matsuoka, 1997; Oku, 1994; Wakita and Kaneko, 1996). However, they are restricted to the homophone problem, that is, they are heuristic methods. On the other hand, the homophone problem is equivalent to the word sense disambiguation problem if the phone of the homophone word is regarded as the word, and the homophone word as the sense. Therefore, we can solve the homophone problem by using various `&apos; and have a same phone `i-shi&apos;. The meaning of is a general will, and the meaning of `&apos; is a strong positive will. &apos;AS&apos; and have a same phone (cho-kkan&apos;. The meaning of &apos;Lae, is an intuit</context>
</contexts>
<marker>Ibuki, Xu, Saitoh, Matsui, 1997</marker>
<rawString>Jun Ibuki, Guowei Xu, Takahiro Saitoh, and Kunio Matsui. 1997. A new approach for Japanese Spelling Correction (in Japanese). SIG Notes NL-117-21, IPSJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masahiro Oku</author>
<author>Koji Matsuoka</author>
</authors>
<title>A Method for Detecting Japanese Homophone Errors in Compound Nouns based on Character Cooccurrence and Its Evaluation (in Japanese).</title>
<date>1997</date>
<journal>Journal of Natural Language Processing,</journal>
<pages>4--3</pages>
<contexts>
<context position="2955" citStr="Oku and Matsuoka, 1997" startWordPosition="485" endWordPosition="488"> {4.41. (probability), WI (establishment)} is a homophone set because words in the set are composed of kanji characters that have the same phone `ka-ku-ri-tu&apos;. Thus, &apos;WV and Iii-SL&amp;quot; are homophone words. In this paper, we name the problem of choosing the correct word from the homophone set the homophone problem. In order to detect homophone errors, we make a list of homophone sets in advance, find a homophone word in the text, and then solve the homophone problem for the homophone word. Many methods of solving the homophone problem have been proposed (Tochinai et al., 1986; Ibuki et al., 1997; Oku and Matsuoka, 1997; Oku, 1994; Wakita and Kaneko, 1996). However, they are restricted to the homophone problem, that is, they are heuristic methods. On the other hand, the homophone problem is equivalent to the word sense disambiguation problem if the phone of the homophone word is regarded as the word, and the homophone word as the sense. Therefore, we can solve the homophone problem by using various `&apos; and have a same phone `i-shi&apos;. The meaning of is a general will, and the meaning of `&apos; is a strong positive will. &apos;AS&apos; and have a same phone (cho-kkan&apos;. The meaning of &apos;Lae, is an intuition through a feeling, a</context>
</contexts>
<marker>Oku, Matsuoka, 1997</marker>
<rawString>Masahiro Oku and Koji Matsuoka. 1997. A Method for Detecting Japanese Homophone Errors in Compound Nouns based on Character Cooccurrence and Its Evaluation (in Japanese). Journal of Natural Language Processing, 4(3):83-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masahiro Oku</author>
</authors>
<title>Handling Japanese Homophone Errors in Revision Support System; REVISE.</title>
<date>1994</date>
<booktitle>In 4th Conference on Applied Natural Language Processing (ANLP-94),</booktitle>
<pages>156--161</pages>
<contexts>
<context position="2966" citStr="Oku, 1994" startWordPosition="489" endWordPosition="490">I (establishment)} is a homophone set because words in the set are composed of kanji characters that have the same phone `ka-ku-ri-tu&apos;. Thus, &apos;WV and Iii-SL&amp;quot; are homophone words. In this paper, we name the problem of choosing the correct word from the homophone set the homophone problem. In order to detect homophone errors, we make a list of homophone sets in advance, find a homophone word in the text, and then solve the homophone problem for the homophone word. Many methods of solving the homophone problem have been proposed (Tochinai et al., 1986; Ibuki et al., 1997; Oku and Matsuoka, 1997; Oku, 1994; Wakita and Kaneko, 1996). However, they are restricted to the homophone problem, that is, they are heuristic methods. On the other hand, the homophone problem is equivalent to the word sense disambiguation problem if the phone of the homophone word is regarded as the word, and the homophone word as the sense. Therefore, we can solve the homophone problem by using various `&apos; and have a same phone `i-shi&apos;. The meaning of is a general will, and the meaning of `&apos; is a strong positive will. &apos;AS&apos; and have a same phone (cho-kkan&apos;. The meaning of &apos;Lae, is an intuition through a feeling, and the mean</context>
</contexts>
<marker>Oku, 1994</marker>
<rawString>Masahiro Oku. 1994. Handling Japanese Homophone Errors in Revision Support System; REVISE. In 4th Conference on Applied Natural Language Processing (ANLP-94), pages 156-161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Shinnou</author>
</authors>
<title>Japanese Homohone Disambiguation Using a Decision List Given Added Weight to Evidences on Compounds (in Japanese).</title>
<date>1998</date>
<journal>Journal of Information Processing,</journal>
<pages>39--12</pages>
<contexts>
<context position="4279" citStr="Shinnou, 1998" startWordPosition="703" endWordPosition="704">nd parts of speech. That is, the homophone set is the set of words having the same expression in hiragana characters. 180 Proceedings of EACL &apos;99 statistical methods proposed for the word sense disambiguation problem(Fujii, 1998). Take the case of context-sensitive spelling error detection 3, which is equivalent to the homophone problem. For that problem, some statistical methods have been applied and succeeded(Golding, 1995; Golding and Schabes, 1996). Hence, statistical methods are certainly valid for the homophone problem. In particular, the decision list is valid for the homophone problem(Shinnou, 1998). The decision list arranges evidences to identify the word sense in the order of strength of identifying the sense. The word sense is judged by the evidence, with the highest identifying strength, in the context. Although the homophone problem is equivalent to the word sense disambiguation problem, the former has a distinct difference from the latter. In the homophone problem, almost all of the answers are given correctly, because almost all of the expressions written in the given text are correct. It is difficult to decide which is the meaning of &apos;crane&apos;, &apos;crane of animal&apos; or &apos;crane of tool&apos;</context>
</contexts>
<marker>Shinnou, 1998</marker>
<rawString>Hiroyuki Shinnou. 1998. Japanese Homohone Disambiguation Using a Decision List Given Added Weight to Evidences on Compounds (in Japanese). Journal of Information Processing, 39(12):3200-3206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koji Tochinai</author>
<author>Taisuke Itoh</author>
<author>Yasuhiro Suzuki</author>
</authors>
<title>Kana-Kanji Translation System with Automatic Homonym Selection Using Character Chain Matching (in Japanese).</title>
<date>1986</date>
<journal>Journal of Information Processing,</journal>
<pages>27--3</pages>
<contexts>
<context position="2911" citStr="Tochinai et al., 1986" startWordPosition="477" endWordPosition="480">rd in a homophone set. For example, the set {4.41. (probability), WI (establishment)} is a homophone set because words in the set are composed of kanji characters that have the same phone `ka-ku-ri-tu&apos;. Thus, &apos;WV and Iii-SL&amp;quot; are homophone words. In this paper, we name the problem of choosing the correct word from the homophone set the homophone problem. In order to detect homophone errors, we make a list of homophone sets in advance, find a homophone word in the text, and then solve the homophone problem for the homophone word. Many methods of solving the homophone problem have been proposed (Tochinai et al., 1986; Ibuki et al., 1997; Oku and Matsuoka, 1997; Oku, 1994; Wakita and Kaneko, 1996). However, they are restricted to the homophone problem, that is, they are heuristic methods. On the other hand, the homophone problem is equivalent to the word sense disambiguation problem if the phone of the homophone word is regarded as the word, and the homophone word as the sense. Therefore, we can solve the homophone problem by using various `&apos; and have a same phone `i-shi&apos;. The meaning of is a general will, and the meaning of `&apos; is a strong positive will. &apos;AS&apos; and have a same phone (cho-kkan&apos;. The meaning o</context>
</contexts>
<marker>Tochinai, Itoh, Suzuki, 1986</marker>
<rawString>Koji Tochinai, Taisuke Itoh, and Yasuhiro Suzuki. 1986. Kana-Kanji Translation System with Automatic Homonym Selection Using Character Chain Matching (in Japanese). Journal of Information Processing, 27(3):313-321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sakiko Waldta</author>
<author>Hiroshi Kaneko</author>
</authors>
<title>Extraction of Keywords for &amp;quot;Homonym Error Checker&amp;quot; (in Japanese).</title>
<date>1996</date>
<journal>SIG Notes</journal>
<pages>111--5</pages>
<marker>Waldta, Kaneko, 1996</marker>
<rawString>Sakiko Waldta and Hiroshi Kaneko. 1996. Extraction of Keywords for &amp;quot;Homonym Error Checker&amp;quot; (in Japanese). SIG Notes NL-111-5, IPSJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Decision Lists for Lexical Ambiguity Resolution: Application to Accent Restoration in Spanish and French.</title>
<date>1994</date>
<booktitle>In 32th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>88--95</pages>
<contexts>
<context position="1280" citStr="Yarowsky, 1994" startWordPosition="197" endWordPosition="198">one problem is equivalent to the word sense disambiguation problem. However, the homophone problem is different from the word sense disambiguation problem because the former can use the written word but the latter cannot. In this paper, we incorporate the written word into the original decision list by obtaining the identifying strength of the written word. The improved decision list can raise the F-measure of error detection. 1 Introduction In this paper, we propose a method of detecting Japanese homophone errors in Japanese texts. Our method is based on a decision list proposed by Yarowsky (Yarowsky, 1994; Yarowsky, 1995). We improve the original decision list by using written words in the default evidence. The improved decision list can raise the F-measure of error detection. Most Japanese texts are written using Japanese word processors. To input a word composed of kanji characters, we first input the phonetic hiragana sequence for the word, and then convert it to the desired kanji sequence. However, multiple converted kanji sequences are generally produced, and we must then choose the correct kanji sequence. Therefore, Japanese texts suffer from homophone errors caused by incorrect choices.</context>
<context position="9177" citStr="Yarowsky, 1994" startWordPosition="1602" endWordPosition="1603">imating that the homophone word wi is correct given the evidence e: P(wi ) est(wi, ei) = log(Ekoi P(wk lei) where P(wi Iej) is approximately calculated by: f rq(wi, ei) + a P (wile j) = Ek f rq(wk, ei) + a a in the above expression is included to avoid the unsatisfactory case of f rq(wi, ei) = 0. In this paper, we set a = 0.15. We also use the special evidence default. f rq(wi, default) is defined as the frequency of w. step 5 Pick the highest strength est(wk, ej) among 5As in this paper, the addition of a small value is an easy and effective way to avoid the unsatisfactory case, as shown in (Yarowsky, 1994). fest(tvi, ej), est(w2, ei), , est(w„, ej)}, and set the word wk as the answer for the evidence ej. In this case, the identifying strength is est(wk, ei). For example, by steps 4 and 5 we can construct the list shown in Table 2. step 6 Fix the answer wki for each ej and sort identifying strengths est(wk,, ej) in order of dimension, but remove the evidence whose identifying strength is less than the identifying strength est(wk,, default) for the evidence default from the list. This is the decision list. After step 6, we obtain the decision list for the homophone set { 11,1T} as shown in Table </context>
</contexts>
<marker>Yarowsky, 1994</marker>
<rawString>David Yarowsky. 1994. Decision Lists for Lexical Ambiguity Resolution: Application to Accent Restoration in Spanish and French. In 32th Annual Meeting of the Association for Computational Linguistics, pages 88-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised Word Sense Disambiguation Rivaling Supervised Methods.</title>
<date>1995</date>
<booktitle>In 33th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>189--196</pages>
<contexts>
<context position="1297" citStr="Yarowsky, 1995" startWordPosition="199" endWordPosition="200">quivalent to the word sense disambiguation problem. However, the homophone problem is different from the word sense disambiguation problem because the former can use the written word but the latter cannot. In this paper, we incorporate the written word into the original decision list by obtaining the identifying strength of the written word. The improved decision list can raise the F-measure of error detection. 1 Introduction In this paper, we propose a method of detecting Japanese homophone errors in Japanese texts. Our method is based on a decision list proposed by Yarowsky (Yarowsky, 1994; Yarowsky, 1995). We improve the original decision list by using written words in the default evidence. The improved decision list can raise the F-measure of error detection. Most Japanese texts are written using Japanese word processors. To input a word composed of kanji characters, we first input the phonetic hiragana sequence for the word, and then convert it to the desired kanji sequence. However, multiple converted kanji sequences are generally produced, and we must then choose the correct kanji sequence. Therefore, Japanese texts suffer from homophone errors caused by incorrect choices. Carelessness of </context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised Word Sense Disambiguation Rivaling Supervised Methods. In 33th Annual Meeting of the Association for Computational Linguistics, pages 189-196.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>