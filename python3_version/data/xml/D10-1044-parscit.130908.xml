<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001750">
<title confidence="0.9994565">
Discriminative Instance Weighting for Domain Adaptation
in Statistical Machine Translation
</title>
<author confidence="0.976506">
George Foster and Cyril Goutte and Roland Kuhn
</author>
<affiliation confidence="0.983982">
National Research Council Canada
</affiliation>
<address confidence="0.9406555">
283 Alexandre-Tach´e Blvd
Gatineau, QC J8X 3X7
</address>
<email confidence="0.996974">
first.last@nrc.gc.ca
</email>
<sectionHeader confidence="0.995579" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999831142857143">
We describe a new approach to SMT adapta-
tion that weights out-of-domain phrase pairs
according to their relevance to the target do-
main, determined by both how similar to it
they appear to be, and whether they belong to
general language or not. This extends previ-
ous work on discriminative weighting by us-
ing a finer granularity, focusing on the prop-
erties of instances rather than corpus com-
ponents, and using a simpler training proce-
dure. We incorporate instance weighting into
a mixture-model framework, and find that it
yields consistent improvements over a wide
range of baselines.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999862843137255">
Domain adaptation is a common concern when op-
timizing empirical NLP applications. Even when
there is training data available in the domain of inter-
est, there is often additional data from other domains
that could in principle be used to improve perfor-
mance. Realizing gains in practice can be challeng-
ing, however, particularly when the target domain is
distant from the background data. For developers
of Statistical Machine Translation (SMT) systems,
an additional complication is the heterogeneous na-
ture of SMT components (word-alignment model,
language model, translation model, etc.), which pre-
cludes a single universal approach to adaptation.
In this paper we study the problem of us-
ing a parallel corpus from a background domain
(OUT) to improve performance on a target do-
main (IN) for which a smaller amount of parallel
training material—though adequate for reasonable
performance—is also available. This is a standard
adaptation problem for SMT. It is difficult when IN
and OUT are dissimilar, as they are in the cases we
study. For simplicity, we assume that OUT is ho-
mogeneous. The techniques we develop can be ex-
tended in a relatively straightforward manner to the
more general case when OUT consists of multiple
sub-domains.
There is a fairly large body of work on SMT
adaptation. We introduce several new ideas. First,
we aim to explicitly characterize examples from
OUT as belonging to general language or not. Pre-
vious approaches have tried to find examples that
are similar to the target domain. This is less ef-
fective in our setting, where IN and OUT are dis-
parate. The idea of distinguishing between general
and domain-specific examples is due to Daum´e and
Marcu (2006), who used a maximum-entropy model
with latent variables to capture the degree of speci-
ficity. Daum´e (2007) applies a related idea in a
simpler way, by splitting features into general and
domain-specific versions. This highly effective ap-
proach is not directly applicable to the multinomial
models used for core SMT components, which have
no natural method for combining split features, so
we rely on an instance-weighting approach (Jiang
and Zhai, 2007) to downweight domain-specific ex-
amples in OUT. Within this framework, we use fea-
tures intended to capture degree of generality, in-
cluding the output from an SVM classifier that uses
the intersection between IN and OUT as positive ex-
amples.
Our second contribution is to apply instance
</bodyText>
<page confidence="0.9831">
451
</page>
<note confidence="0.818031">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 451–459,
MIT, Massachusetts, USA, 9-11 October 2010. c!2010 Crown in Right of Canada.
</note>
<bodyText confidence="0.999877885714286">
weighting at the level of phrase pairs. Sentence
pairs are the natural instances for SMT, but sen-
tences often contain a mix of domain-specific and
general language. For instance, the sentence Sim-
ilar improvements in haemoglobin levels were re-
ported in the scientific literature for other epoetins
would likely be considered domain-specific despite
the presence of general phrases like were reported
in. Phrase-level granularity distinguishes our work
from previous work by Matsoukas et al (2009), who
weight sentences according to sub-corpus and genre
membership.
Finally, we make some improvements to baseline
approaches. We train linear mixture models for con-
ditional phrase pair probabilities over IN and OUT
so as to maximize the likelihood of an empirical
joint phrase-pair distribution extracted from a de-
velopment set. This is a simple and effective alter-
native to setting weights discriminatively to maxi-
mize a metric such as BLEU. A similar maximum-
likelihood approach was used by Foster and Kuhn
(2007), but for language models only. For compar-
ison to information-retrieval inspired baselines, eg
(L¨u et al., 2007), we select sentences from OUT
using language model perplexities from IN. This
is a straightforward technique that is arguably bet-
ter suited to the adaptation task than the standard
method of treating representative IN sentences as
queries, then pooling the match results.
The paper is structured as follows. Section 2 de-
scribes our baseline techniques for SMT adaptation,
and section 3 describes the instance-weighting ap-
proach. Experiments are presented in section 4. Sec-
tion 5 covers relevant previous work on SMT adap-
tation, and section 6 concludes.
</bodyText>
<sectionHeader confidence="0.980056" genericHeader="method">
2 Baseline SMT Adaptation Techniques
</sectionHeader>
<bodyText confidence="0.999757210526316">
Standard SMT systems have a hierarchical param-
eter structure: top-level log-linear weights are used
to combine a small set of complex features, inter-
preted as log probabilities, many of which have their
own internal parameters and objectives. The top-
level weights are trained to maximize a metric such
as BLEU on a small development set of approxi-
mately 1000 sentence pairs. Thus, provided at least
this amount of IN data is available—as it is in our
setting—adapting these weights is straightforward.
We focus here instead on adapting the two most im-
portant features: the language model (LM), which
estimates the probability p(wIh) of a target word w
following an ngram h; and the translation models
(TM) p(slt) and p(t1s), which give the probability
of source phrase s translating to target phrase t, and
vice versa. We do not adapt the alignment procedure
for generating the phrase table from which the TM
distributions are derived.
</bodyText>
<subsectionHeader confidence="0.997542">
2.1 Simple Baselines
</subsectionHeader>
<bodyText confidence="0.999689071428571">
The natural baseline approach is to concatenate data
from IN and OUT. Its success depends on the two
domains being relatively close, and on the OUT cor-
pus not being so large as to overwhelm the contribu-
tion of IN.
When OUT is large and distinct, its contribution
can be controlled by training separate IN and OUT
models, and weighting their combination. An easy
way to achieve this is to put the domain-specific
LMs and TMs into the top-level log-linear model
and learn optimal weights with MERT (Och, 2003).
This has the potential drawback of increasing the
number of features, which can make MERT less sta-
ble (Foster and Kuhn, 2009).
</bodyText>
<subsectionHeader confidence="0.998639">
2.2 Linear Combinations
</subsectionHeader>
<bodyText confidence="0.999972368421053">
Apart from MERT difficulties, a conceptual problem
with log-linear combination is that it multiplies fea-
ture probabilities, essentially forcing different fea-
tures to agree on high-scoring candidates. This is
appropriate in cases where it is sanctioned by Bayes’
law, such as multiplying LM and TM probabilities,
but for adaptation a more suitable framework is of-
ten a mixture model in which each event may be
generated from some domain. This leads to a linear
combination of domain-specific probabilities, with
weights in [0, 1], normalized to sum to 1.
Linear weights are difficult to incorporate into the
standard MERT procedure because they are “hid-
den” within a top-level probability that represents
the linear combination.1 Following previous work
(Foster and Kuhn, 2007), we circumvent this prob-
lem by choosing weights to optimize corpus log-
likelihood, which is roughly speaking the training
criterion used by the LM and TM themselves.
</bodyText>
<footnote confidence="0.9933055">
1This precludes the use of exact line-maximization within
Powell’s algorithm (Och, 2003), for instance.
</footnote>
<page confidence="0.997787">
452
</page>
<bodyText confidence="0.969452">
For the LM, adaptive weights are set as follows:
</bodyText>
<equation confidence="0.976865">
!αˆ = argmax ˜p(w, h) log ! αipi(w|h), (1)
α w,h i
</equation>
<bodyText confidence="0.999953470588235">
where α is a weight vector containing an element αi
for each domain (just IN and OUT in our case), pi
are the corresponding domain-specific models, and
˜p(w, h) is an empirical distribution from a target-
language training corpus—we used the IN dev set
for this.
It is not immediately obvious how to formulate an
equivalent to equation (1) for an adapted TM, be-
cause there is no well-defined objective for learning
TMs from parallel corpora. This has led previous
workers to adopt ad hoc linear weighting schemes
(Finch and Sumita, 2008; Foster and Kuhn, 2007;
L¨u et al., 2007). However, we note that the final con-
ditional estimates p(s|t) from a given phrase table
maximize the likelihood of joint empirical phrase
pair counts over a word-aligned corpus. This sug-
gests a direct parallel to (1):
</bodyText>
<equation confidence="0.9793085">
!αˆ = argmax ˜p(s, t) log ! αipi(s|t), (2)
α s,t i
</equation>
<bodyText confidence="0.999969133333333">
where ˜p(s, t) is a joint empirical distribution ex-
tracted from the IN dev set using the standard pro-
cedure.2
An alternative form of linear combination is a
maximum a posteriori (MAP) combination (Bacchi-
ani et al., 2004). For the TM, this is:
where cI(s, t) is the count in the IN phrase table of
pair (s, t), po(s|t) is its probability under the OUT
TM, and cI(t) = &amp;quot;s, cI(s&apos;, t). This is motivated by
taking β po(s|t) to be the parameters of a Dirich-
let prior on phrase probabilities, then maximizing
posterior estimates p(s|t) given the IN corpus. In-
tuitively, it places more weight on OUT when less
evidence from IN is available. To set β, we used the
same criterion as for α, over a dev corpus:
</bodyText>
<equation confidence="0.96841975">
! cI(s, t) + β po(s|t)
βˆ = argmax ˜p(s, t) log
cI(t) + β .
� s,t
</equation>
<footnote confidence="0.757701">
2Using non-adapted IBM models trained on all available IN
and OUT data.
</footnote>
<bodyText confidence="0.99950225">
The MAP combination was used for TM probabil-
ities only, in part due to a technical difficulty in for-
mulating coherent counts when using standard LM
smoothing techniques (Kneser and Ney, 1995).3
</bodyText>
<subsectionHeader confidence="0.999722">
2.3 Sentence Selection
</subsectionHeader>
<bodyText confidence="0.99985675">
Motivated by information retrieval, a number of
approaches choose “relevant” sentence pairs from
OUT by matching individual source sentences from
IN (Hildebrand et al., 2005; L¨u et al., 2007), or
individual target hypotheses (Zhao et al., 2004).
The matching sentence pairs are then added to the
IN corpus, and the system is re-trained. Although
matching is done at the sentence level, this informa-
tion is subsequently discarded when all matches are
pooled.
To approximate these baselines, we implemented
a very simple sentence selection algorithm in which
parallel sentence pairs from OUT are ranked by the
perplexity of their target half according to the IN lan-
guage model. The number of top-ranked pairs to re-
tain is chosen to optimize dev-set BLEU score.
</bodyText>
<sectionHeader confidence="0.991402" genericHeader="method">
3 Instance Weighting
</sectionHeader>
<bodyText confidence="0.99997225">
The sentence-selection approach is crude in that it
imposes a binary distinction between useful and
non-useful parts of OUT. Matsoukas et al (2009)
generalize it by learning weights on sentence pairs
that are used when estimating relative-frequency
phrase-pair probabilities. The weight on each sen-
tence is a value in [0, 1] computed by a perceptron
with Boolean features that indicate collection and
genre membership.
We extend the Matsoukas et al approach in sev-
eral ways. First, we learn weights on individual
phrase pairs rather than sentences. Intuitively, as
suggested by the example in the introduction, this
is the right granularity to capture domain effects.
Second, rather than relying on a division of the cor-
pus into manually-assigned portions, we use features
intended to capture the usefulness of each phrase
pair. Finally, we incorporate the instance-weighting
model into a general linear combination, and learn
weights and mixing parameters simultaneously.
</bodyText>
<footnote confidence="0.779373666666667">
3Bacchiani et al (2004) solve this problem by reconstitut-
ing joint counts from smoothed conditional estimates and un-
smoothed marginals, but this seems somewhat unsatisfactory.
</footnote>
<equation confidence="0.9997405">
cI(s, t) + β po(s|t)
p(s|t) =
cI(t) + β
, (3)
</equation>
<page confidence="0.997091">
453
</page>
<note confidence="0.498192">
3.1 Model &amp;quot;s! ¯cλ(s!, t): pI(s |t) − po(s|t)
The overall adapted TM is a combination of the a log p(s|t) =kt p(s |t) p(s |t)
form: Bat
</note>
<equation confidence="0.987136">
po(
t)
s|
=cλ (s, t) + yu(sI t) (5)
&amp;quot;s! cλ (s!, t) + y
</equation>
<bodyText confidence="0.99916375">
where cλ(s, t) is a modified count for pair (s, t)
in OUT, u(s|t) is a prior distribution, and y is a
prior weight. The original OUT counts co(s, t) are
weighted by a logistic function wλ(s, t):
</bodyText>
<equation confidence="0.993746">
cλ(s, t) = co(s, t) wλ(s, t) (6)
= co(s, t) [1 + exp(− ! Aifi(s, t))]−1,
i
and:
!cλ! = cλ!i(s!, t).
s!
</equation>
<subsectionHeader confidence="0.99738">
3.2 Interpretation and Variants
</subsectionHeader>
<bodyText confidence="0.999735">
To motivate weighting joint OUT counts as in (6),
we begin with the “ideal” objective for setting
multinomial phrase probabilities 0 = {p(s|t), dst},
which is the likelihood with respect to the true IN
distribution pi(s, t). Jiang and Zhai (2007) sug-
gest the following derivation, making use of the true
OUT distribution po(s, t):
</bodyText>
<equation confidence="0.749183866666667">
a log p(s|t)
ay
a log p(s|t)
aAi
1 − at
p(s |t)
u(s|t) − ¯cλ(s,t)
¯cλ (t) cλ(t)2
1 − at cλ!i(s, CA(s,t)cλ!i(t)
p(s |t) t) CA(t) ca(t)2
1 fixed weight
−cI(t)/(cI(t) + 0)2 MAP
cλ!i(s, t) = fi(s, t)(1 − wλ(s, t))cλ(s, t)
where:
kt =&apos;
</equation>
<bodyText confidence="0.964672608695652">
where each fi(s, t) is a feature intended to charac- !0ˆ = argmax pf(s, t) log pθ(s|t) (8)
terize the usefulness of (s, t), weighted by Ai. θ s,t pf(s, t)po(s, t) log pθ(s|t)
The mixing parameters and feature weights (col- != argmax po (s, t)
lectively 0) are optimized simultaneously using dev- θ s,t pf(s, t)co(s, t) log pθ(s|t),
set maximum likelihood as before: !�argmax po (s, t)
! θ s,t
�ˆ = argmax ˜p(s, t) log p(s|t; 0). (7)
φ s,t
This is a somewhat less direct objective than used
by Matsoukas et al, who make an iterative approxi-
mation to expected TER. However, it is robust, effi-
cient, and easy to implement.4
To perform the maximization in (7), we used
the popular L-BFGS algorithm (Liu and Nocedal,
1989), which requires gradient information. Drop-
ping the conditioning on 0 for brevity, and let-
ting ¯cλ(s, t) = cλ(s, t) + yu(s|t), and ¯cλ(t) =
4Note that the probabilities in (7) need only be evaluated
over the support of ˜p(s, t), which is quite small when this dis-
tribution is derived from a dev set. Maximizing (7) is thus much
faster than a typical MERT run.
where co(s, t) are the counts from OUT, as in (6).
This has solutions:
</bodyText>
<equation confidence="0.97635325">
!
po(s|t) = pf(s,t)co(s,t)/
po(s,t)
p(s|t) = at pI(s|t) + (1 − at) po(s|t), (4)
</equation>
<bodyText confidence="0.9982286875">
where pI(s|t) is derived from the IN corpus us-
ing relative-frequency estimates, and po(s|t) is an
instance-weighted model derived from the OUT cor-
pus. This combination generalizes (2) and (3): we
use either at = a to obtain a fixed-weight linear
combination, or at = cI(t)/(cI(t) + 0) to obtain a
MAP combination.
We model po(s|t) using a MAP criterion over
weighted phrase-pair counts:
and from the similarity to (5), assuming y = 0, we
see that wλ(s, t) can be interpreted as approximat-
ing pf(s, t)/po(s, t). The logistic function, whose
outputs are in [0, 1], forces pp(s, t) &lt;_ po(s, t). This
is not unreasonable given the application to phrase
pairs from OUT, but it suggests that an interesting al-
ternative might be to use a plain log-linear weighting
</bodyText>
<equation confidence="0.987515666666667">
s!
pf(s!, t) co(s!
p6 (s!, t) t),
</equation>
<page confidence="0.989993">
454
</page>
<bodyText confidence="0.999906631578947">
function exp(Ei Aifi(s, t)), with outputs in [0, oo].
We have not yet tried this.
An alternate approximation to (8) would be to let
w,\(s, t) directly approximate pˆI(s, t). With the ad-
ditional assumption that (s, t) can be restricted to the
support of co(s, t), this is equivalent to a “flat” alter-
native to (6) in which each non-zero co(s, t) is set to
one. This variant is tested in the experiments below.
A final alternate approach would be to combine
weighted joint frequencies rather than conditional
estimates, ie: cI(s, t) + w,\(s, t)co(, s, t), suitably
normalized.5 Such an approach could be simulated
by a MAP-style combination in which separate 0(t)
values were maintained for each t. This would make
the model more powerful, but at the cost of having
to learn to downweight OUT separately for each t,
which we suspect would require more training data
for reliable performance. We have not explored this
strategy.
</bodyText>
<subsectionHeader confidence="0.999217">
3.3 Simple Features
</subsectionHeader>
<bodyText confidence="0.999129888888889">
We used 22 features for the logistic weighting
model, divided into two groups: one intended to re-
flect the degree to which a phrase pair belongs to
general language, and one intended to capture simi-
larity to the IN domain.
The 14 general-language features embody
straightforward cues: frequency, “centrality” as
reflected in model scores, and lack of burstiness.
They are:
</bodyText>
<listItem confidence="0.9994749">
• total number of tokens in the phrase pair (1);
• OUT corpus frequency (1);
• OUT-corpus frequencies of rarest source and
target words (2);
• perplexities for OUT IBM1 models, in both di-
rections (2);
• average and minimum source and target word
“document frequencies” in the OUT corpus,
using successive 100-line pseudo-documents6
(4); and
</listItem>
<bodyText confidence="0.5477798">
5We are grateful to an anonymous reviewer for pointing this
out.
6One of our experimental settings lacks document bound-
aries, and we used this approximation in both settings for con-
sistency.
</bodyText>
<listItem confidence="0.988188181818182">
• average and minimum source and target word
values from the OUT corpus of the following
statistic, intended to reflect degree of burstiness
(higher values indicate less bursty behaviour):
g/(L − L/(l + 1) + a), where g is the sum
over all sentences containing the word of the
distance (number of sentences) to the nearest
sentence that also contains the word, L is the
total number of sentences, l is the number of
sentences that contain the word, and a is a small
constant (4).
</listItem>
<bodyText confidence="0.991014">
The 8 similarity-to-IN features are based on word
frequencies and scores from various models trained
on the IN corpus:
</bodyText>
<listItem confidence="0.993350833333333">
• 1gram and 2gram source and target perplexities
according to the IN LM (4);7
• source and target OOV counts with respect to
IN (2); and
• perplexities for IN IBM1 models, in both direc-
tions (2).
</listItem>
<bodyText confidence="0.999179">
To avoid numerical problems, each feature was
normalized by subtracting its mean and dividing by
its standard deviation.
</bodyText>
<subsectionHeader confidence="0.987244">
3.4 SVM Feature
</subsectionHeader>
<bodyText confidence="0.990439444444444">
In addition to using the simple features directly, we
also trained an SVM classifier with these features
to distinguish between IN and OUT phrase pairs.
Phrase tables were extracted from the IN and OUT
training corpora (not the dev as was used for instance
weighting models), and phrase pairs in the intersec-
tion of the IN and OUT phrase tables were used as
positive examples, with two alternate definitions of
negative examples:
</bodyText>
<listItem confidence="0.9992615">
1. Pairs from OUT that are not in IN, but whose
source phrase is.
2. Pairs from OUT that are not in IN, but whose
source phrase is, and where the intersection of
IN and OUT translations for that source phrase
is empty.
</listItem>
<footnote confidence="0.996256666666667">
7In the case of the Chinese experiments below, source LMs
were trained using text segmented with the LDC segmenter, as
were the other Chinese models in our system.
</footnote>
<page confidence="0.998966">
455
</page>
<bodyText confidence="0.99985075">
The classifier trained using the 2nd definition had
higher accuracy on a development set. We used it to
score all phrase pairs in the OUT table, in order to
provide a feature for the instance-weighting model.
</bodyText>
<sectionHeader confidence="0.999704" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999876">
4.1 Corpora and System
</subsectionHeader>
<bodyText confidence="0.96476608">
We carried out translation experiments in two dif-
ferent settings. The first setting uses the Euro-
pean Medicines Agency (EMEA) corpus (Tiede-
mann, 2009) as IN, and the Europarl (EP) cor-
pus (www.statmt.org/europarl) as OUT,
for English/French translation in both directions.
The dev and test sets were randomly chosen from
the EMEA corpus. Figure 1 shows sample sentences
from these domains, which are widely divergent.
The second setting uses the news-related sub-
corpora for the NIST09 MT Chinese to English
evaluation8 as IN, and the remaining NIST paral-
lel Chinese/English corpora (UN, Hong Kong Laws,
and Hong Kong Hansard) as OUT. The dev cor-
pus was taken from the NIST05 evaluation set, aug-
mented with some randomly-selected material re-
served from the training set. The NIST06 and
NIST08 evaluation sets were used for testing. (Thus
the domain of the dev and test corpora matches IN.)
Compared to the EMEA/EP setting, the two do-
mains in the NIST setting are less homogeneous and
more similar to each other; there is also considerably
more IN text available.
The corpora for both settings are summarized in
table 1.
</bodyText>
<table confidence="0.9988753">
corpus sentence pairs
Europarl 1,328,360
EMEA train 11,770
EMEA dev 1,533
EMEA test 1,522
NIST OUT 6,677,729
NIST IN train 2,103,827
NIST IN dev 1,894
NIST06 test 1,664
NIST08 test 1,357
</table>
<tableCaption confidence="0.999808">
Table 1: Corpora
</tableCaption>
<page confidence="0.52178">
8www.itl.nist.gov/iad/mig//tests/mt/2009
</page>
<bodyText confidence="0.974197090909091">
The reference medicine for Silapo is
EPREX/ERYPO, which contains epoetin alfa.
Le m´edicament de r´ef´erence de Silapo est
EPREX/ERYPO, qui contient de l’´epo´etine alfa.
—
I would also like to point out to commissioner Liika-
nen that it is not easy to take a matter to a national
court.
Je voudrais pr´eciser, a` l’adresse du commissaire
Liikanen, qu’il n’est pas ais´e de recourir aux tri-
bunaux nationaux.
</bodyText>
<figureCaption confidence="0.997628">
Figure 1: Sentence pairs from EMEA (top) and Europarl
text.
</figureCaption>
<bodyText confidence="0.999920692307692">
We used a standard one-pass phrase-based sys-
tem (Koehn et al., 2003), with the following fea-
tures: relative-frequency TM probabilities in both
directions; a 4-gram LM with Kneser-Ney smooth-
ing; word-displacement distortion model; and word
count. Feature weights were set using Och’s MERT
algorithm (Och, 2003). The corpus was word-
aligned using both HMM and IBM2 models, and the
phrase table was the union of phrases extracted from
these separate alignments, with a length limit of 7.
It was filtered to retain the top 30 translations for
each source phrase using the TM part of the current
log-linear model.
</bodyText>
<subsectionHeader confidence="0.681265">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.999983166666667">
Table 2 shows results for both settings and all meth-
ods described in sections 2 and 3. The 1st block
contains the simple baselines from section 2.1. The
natural baseline (baseline) outperforms the pure IN
system only for EMEA/EP fren. Log-linear combi-
nation (loglin) improves on this in all cases, and also
beats the pure IN system.
The 2nd block contains the IR system, which was
tuned by selecting text in multiples of the size of the
EMEA training corpus, according to dev set perfor-
mance. This significantly underperforms log-linear
combination.
The 3rd block contains the mixture baselines. The
linear LM (lin lm), TM (lin tm) and MAP TM (map
tm) used with non-adapted counterparts perform in
all cases slightly worse than the log-linear combi-
nation, which adapts both LM and TM components.
However, when the linear LM is combined with a
</bodyText>
<page confidence="0.997208">
456
</page>
<table confidence="0.999915555555556">
method EMEA/EP NIST
fren enfr nst06 nst08
in 32.77 31.98 27.65 21.65
out 20.42 17.41 19.85 15.71
baseline 33.61 31.15 26.93 21.01
loglin 35.94 32.62 28.09 21.85
ir 33.75 31.91 —– —–
lin lm 35.61 31.55 28.02 21.68
lin tm 35.32 32.52 27.16 21.32
map tm 35.15 31.99 27.20 21.17
lm+lin tm 36.42 33.49 27.83 22.03
lm+map tm 36.28 33.31 28.05 22.11
iw all 36.55 33.73 28.74 22.28
iw all map 37.01 33.90 30.04 23.76
iw all flat 36.50 33.42 28.31 22.13
iw gen map 36.98 33.75 29.81 23.56
iw sim map 36.82 33.68 29.66 23.53
iw svm map 36.79 33.67 —– —–
</table>
<tableCaption confidence="0.95777925">
Table 2: Results, for EMEA/EP translation into English
(fren) and French (enfr); and for NIST Chinese to En-
glish translation with NIST06 and NIST08 evaluation
sets. Numbers are BLEU scores.
</tableCaption>
<bodyText confidence="0.996986642857143">
linear TM (lm+lin tm) or MAP TM (lm+map TM),
the results are much better than a log-linear com-
bination for the EMEA setting, and on a par for
NIST. This is consistent with the nature of these two
settings: log-linear combination, which effectively
takes the intersection of IN and OUT, does relatively
better on NIST, where the domains are broader and
closer together. Somewhat surprisingly, there do not
appear to be large systematic differences between
linear and MAP combinations.
The 4th block contains instance-weighting mod-
els trained on all features, used within a MAP TM
combination, and with a linear LM mixture. The
iw all map variant uses a non-0 y weight on a uni-
form prior in p,,(s t), and outperforms a version
with y = 0 (iw all) and the “flattened” variant de-
scribed in section 3.2. Clearly, retaining the origi-
nal frequencies is important for good performance,
and globally smoothing the final weighted frequen-
cies is crucial. This best instance-weighting model
beats the equivalant model without instance weights
by between 0.6 BLEU and 1.8 BLEU, and beats the
log-linear baseline by a large margin.
The final block in table 2 shows models trained
on feature subsets and on the SVM feature described
in 3.4. The general-language features have a slight
advantage over the similarity features, and both are
better than the SVM feature.
</bodyText>
<sectionHeader confidence="0.999618" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999993048780488">
We have already mentioned the closely related work
by Matsoukas et al (2009) on discriminative cor-
pus weighting, and Jiang and Zhai (2007) on (non-
discriminative) instance weighting. It is difficult to
directly compare the Matsoukas et al results with
ours, since our out-of-domain corpus is homoge-
neous; given heterogeneous training data, however,
it would be trivial to include Matsoukas-style iden-
tity features in our instance-weighting model. Al-
though these authors report better gains than ours,
they are with respect to a non-adapted baseline. Fi-
nally, we note that Jiang’s instance-weighting frame-
work is broader than we have presented above, en-
compassing among other possibilities the use of un-
labelled IN data, which is applicable to SMT settings
where source-only IN corpora are available.
It is also worth pointing out a connection with
Daum´e’s (2007) work that splits each feature into
domain-specific and general copies. At first glance,
this seems only peripherally related to our work,
since the specific/general distinction is made for fea-
tures rather than instances. However, for multino-
mial models like our LMs and TMs, there is a one to
one correspondence between instances and features,
eg the correspondence between a phrase pair (s, t)
and its conditional multinomial probability p(s1t).
As mentioned above, it is not obvious how to ap-
ply Daum´e’s approach to multinomials, which do
not have a mechanism for combining split features.
Recent work by Finkel and Manning (2009) which
re-casts Daum´e’s approach in a hierarchical MAP
framework may be applicable to this problem.
Moving beyond directly related work, major
themes in SMT adaptation include the IR (Hilde-
brand et al., 2005; L¨u et al., 2007; Zhao et al.,
2004) and mixture (Finch and Sumita, 2008; Fos-
ter and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u
et al., 2007) approaches for LMs and TMs described
above, as well as methods for exploiting monolin-
gual in-domain text, typically by translating it auto-
matically and then performing self training (Bertoldi
</bodyText>
<page confidence="0.994835">
457
</page>
<bodyText confidence="0.9991235">
and Federico, 2009; Ueffing et al., 2007; Schwenk
and Senellart, 2009). There has also been some
work on adapting the word alignment model prior to
phrase extraction (Civera and Juan, 2007; Wu et al.,
2005), and on dynamically choosing a dev set (Xu
et al., 2007). Other work includes transferring latent
topic distributions from source to target language for
LM adaptation, (Tam et al., 2007) and adapting fea-
tures at the sentence level to different categories of
sentence (Finch and Sumita, 2008).
</bodyText>
<sectionHeader confidence="0.99917" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999848365853659">
In this paper we have proposed an approach for
instance-weighting phrase pairs in an out-of-domain
corpus in order to improve in-domain performance.
Each out-of-domain phrase pair is characterized by
a set of simple features intended to reflect how use-
ful it will be. The features are weighted within a
logistic model to give an overall weight that is ap-
plied to the phrase pair’s frequency prior to making
MAP-smoothed relative-frequency estimates (dif-
ferent weights are learned for each conditioning
direction). These estimates are in turn combined
linearly with relative-frequency estimates from an
in-domain phrase table. Mixing, smoothing, and
instance-feature weights are learned at the same time
using an efficient maximum-likelihood procedure
that relies on only a small in-domain development
corpus.
We obtained positive results using a very sim-
ple phrase-based system in two different adaptation
settings: using English/French Europarl to improve
a performance on a small, specialized medical do-
main; and using non-news portions of the NIST09
training material to improve performance on the
news-related corpora. In both cases, the instance-
weighting approach improved over a wide range of
baselines, giving gains of over 2 BLEU points over
the best non-adapted baseline, and gains of between
0.6 and 1.8 over an equivalent mixture model (with
an identical training procedure but without instance
weighting).
In future work we plan to try this approach with
more competitive SMT systems, and to extend in-
stance weighting to other standard SMT components
such as the LM, lexical phrase weights, and lexical-
ized distortion. We will also directly compare with
a baseline similar to the Matsoukas et al approach in
order to measure the benefit from weighting phrase
pairs (or ngrams) rather than full sentences. Finally,
we intend to explore more sophisticated instance-
weighting features for capturing the degree of gen-
erality of phrase pairs.
</bodyText>
<sectionHeader confidence="0.998523" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999639325581395">
ACL. 2007. Proceedings of the 45th Annual Meeting of
the Association for Computational Linguistics (ACL),
Prague, Czech Republic, June.
Michel Bacchiani, Brian Roark, and Murat Saraclar.
2004. Language model adaptation with MAP esti-
mation and the perceptron algorithm. In NAACL04
(NAA, 2004).
Nicola Bertoldi and Marcello Federico. 2009. Do-
main adaptation for statistical machine translation with
monolingual resources. In WMT09 (WMT, 2009).
Jorge Civera and Alfons Juan. 2007. Domain adaptation
in Statistical Machine Translation with mixture mod-
elling. In WMT07 (WMT, 2007).
Hal Daum´e III and Daniel Marcu. 2006. Domain Adap-
tation for Statistical Classifiers. Journal of Artificial
Intelligence Research, 26:101–126.
Hal Daum´e III. 2007. Frustratingly Easy Domain Adap-
tation. In ACL-07 (ACL, 2007).
Andrew Finch and Eiichiro Sumita. 2008. Dynamic
model interpolation for statistical machine translation.
In Proceedings of the ACL Workshop on Statistical
Machine Translation, Columbus, June. WMT.
Jenny Rose Finkel and Christopher D. Manning. 2009.
Hierarchical Bayesian domain adaptation. In Proceed-
ings of the Human Language Technology Conference
of the North American Chapter of the Association for
Computational Linguistics (NAACL), Boulder, June.
NAACL.
George Foster and Roland Kuhn. 2007. Mixture-model
adaptation for SMT. In WMT07 (WMT, 2007).
George Foster and Roland Kuhn. 2009. Stabilizing min-
imum error rate training. In WMT09 (WMT, 2009).
Almut Silja Hildebrand, Matthias Eck, Stephan Vogel,
and Alex Waibel. 2005. Adaptation of the translation
model for statistical machine translation based on in-
formation retrieval. In Proceedings of the 10th EAMT
Conference, Budapest, May.
Jing Jiang and ChengXiang Zhai. 2007. Instance
Weighting for Domain Adaptation in NLP. In ACL-
07 (ACL, 2007).
Reinhard Kneser and Hermann Ney. 1995. Improved
backing-off for m-gram language modeling. In Pro-
ceedings of the International Conference on Acoustics,
</reference>
<page confidence="0.983246">
458
</page>
<reference confidence="0.999574871428572">
Speech, and Signal Processing (ICASSP) 1995, pages
181–184, Detroit, Michigan. IEEE.
Philipp Koehn and Josh Schroeder. 2007. Experiments
in domain adaptation for statistical machine transla-
tion. In Proceedings of the Second Workshop on Sta-
tistical Machine Translation, pages 224–227, Prague,
Czech Republic, June. Association for Computational
Linguistics.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of the Human Language Technology Conference
of the North American Chapter of the Association for
Computational Linguistics (NAACL), pages 127–133,
Edmonton, May. NAACL.
D. C. Liu and J. Nocedal. 1989. On the limited mem-
ory method for large scale optimization. Mathemati-
cal Programming B, 45(3):503–528.
Yajuan L¨u, Jin Huang, and Qun Liu. 2007. Improving
Statistical Machine Translation Performance by Train-
ing Data Selection and Optimization. In Proceedings
of the 2007 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), Prague, Czech
Republic.
Spyros Matsoukas, Antti-Veikko I. Rosti, and Bing
Zhang. 2009. Discriminative corpus weight estima-
tion for machine translation. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing (EMNLP), Singapore.
NAACL. 2004. Proceedings of the Human Language
Technology Conference of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL), Boston, May.
Franz Josef Och. 2003. Minimum error rate training for
statistical machine translation. In Proceedings of the
41th Annual Meeting of the Association for Computa-
tional Linguistics (ACL), Sapporo, July. ACL.
Holger Schwenk and Jean Senellart. 2009. Translation
model adaptation for an arabic/french news translation
system by lightly-supervised training. In Proceedings
of MT Summit XII, Ottawa, Canada, September. Inter-
national Association for Machine Translation.
Yik-Cheung Tam, Ian Lane, and Tanja Schultz. 2007.
Bilingual-LSA Based LM Adaptation for Spoken Lan-
guage Translation. In ACL-07 (ACL, 2007).
Jorg Tiedemann. 2009. News from opus - a collection
of multilingual parallel corpora with tools and inter-
faces. In N. Nicolov, K. Bontcheva, G. Angelova,
and R. Mitkov, editors, Recent Advances in Natural
Language Processing, volume V, pages 237–248. John
Benjamins, Amsterdam/Philadelphia.
Nicola Ueffing, Gholamreza Haffari, and Anoop Sarkar.
2007. Transductive learning for statistical machine
translation. In ACL-07 (ACL, 2007).
WMT. 2007. Proceedings of the ACL Workshop on Sta-
tistical Machine Translation, Prague, June.
WMT. 2009. Proceedings of the 4th Workshop on Statis-
tical Machine Translation, Athens, March.
Hua Wu, Haifeng Wang, and Zhanyi Liu. 2005.
Alignment model adaptation for domain-specific word
alignment. In Proceedings of the 43th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), Ann Arbor, Michigan, July. ACL.
Jia Xu, Yonggang Deng, Yuqing Gao, and Hermann Ney.
2007. Domain dependent statistical machine transla-
tion. In MT Summit XI, Copenhagen, September.
Bing Zhao, Matthias Eck, and Stephan Vogel. 2004.
Language model adaptation for statistical machine
translation with structured query models. In Proceed-
ings of the International Conference on Computational
Linguistics (COLING) 2004, Geneva, August.
</reference>
<page confidence="0.999115">
459
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.898072">
<title confidence="0.998993">Discriminative Instance Weighting for Domain in Statistical Machine Translation</title>
<author confidence="0.998296">Foster Goutte</author>
<affiliation confidence="0.998745">National Research Council</affiliation>
<address confidence="0.950409">283 Alexandre-Tach´e Gatineau, QC J8X</address>
<email confidence="0.995703">first.last@nrc.gc.ca</email>
<abstract confidence="0.999794533333333">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not. This extends previous work on discriminative weighting by using a finer granularity, focusing on the properties of instances rather than corpus components, and using a simpler training procedure. We incorporate instance weighting into a mixture-model framework, and find that it yields consistent improvements over a wide range of baselines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>ACL</author>
</authors>
<date>2007</date>
<booktitle>Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<location>Prague, Czech Republic,</location>
<marker>ACL, 2007</marker>
<rawString>ACL. 2007. Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL), Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Bacchiani</author>
<author>Brian Roark</author>
<author>Murat Saraclar</author>
</authors>
<title>Language model adaptation with MAP estimation and the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In NAACL04 (NAA,</booktitle>
<contexts>
<context position="9012" citStr="Bacchiani et al., 2004" startWordPosition="1452" endWordPosition="1456">s has led previous workers to adopt ad hoc linear weighting schemes (Finch and Sumita, 2008; Foster and Kuhn, 2007; L¨u et al., 2007). However, we note that the final conditional estimates p(s|t) from a given phrase table maximize the likelihood of joint empirical phrase pair counts over a word-aligned corpus. This suggests a direct parallel to (1): !αˆ = argmax ˜p(s, t) log ! αipi(s|t), (2) α s,t i where ˜p(s, t) is a joint empirical distribution extracted from the IN dev set using the standard procedure.2 An alternative form of linear combination is a maximum a posteriori (MAP) combination (Bacchiani et al., 2004). For the TM, this is: where cI(s, t) is the count in the IN phrase table of pair (s, t), po(s|t) is its probability under the OUT TM, and cI(t) = &amp;quot;s, cI(s&apos;, t). This is motivated by taking β po(s|t) to be the parameters of a Dirichlet prior on phrase probabilities, then maximizing posterior estimates p(s|t) given the IN corpus. Intuitively, it places more weight on OUT when less evidence from IN is available. To set β, we used the same criterion as for α, over a dev corpus: ! cI(s, t) + β po(s|t) βˆ = argmax ˜p(s, t) log cI(t) + β . � s,t 2Using non-adapted IBM models trained on all available</context>
<context position="11624" citStr="Bacchiani et al (2004)" startWordPosition="1887" endWordPosition="1890">at indicate collection and genre membership. We extend the Matsoukas et al approach in several ways. First, we learn weights on individual phrase pairs rather than sentences. Intuitively, as suggested by the example in the introduction, this is the right granularity to capture domain effects. Second, rather than relying on a division of the corpus into manually-assigned portions, we use features intended to capture the usefulness of each phrase pair. Finally, we incorporate the instance-weighting model into a general linear combination, and learn weights and mixing parameters simultaneously. 3Bacchiani et al (2004) solve this problem by reconstituting joint counts from smoothed conditional estimates and unsmoothed marginals, but this seems somewhat unsatisfactory. cI(s, t) + β po(s|t) p(s|t) = cI(t) + β , (3) 453 3.1 Model &amp;quot;s! ¯cλ(s!, t): pI(s |t) − po(s|t) The overall adapted TM is a combination of the a log p(s|t) =kt p(s |t) p(s |t) form: Bat po( t) s| =cλ (s, t) + yu(sI t) (5) &amp;quot;s! cλ (s!, t) + y where cλ(s, t) is a modified count for pair (s, t) in OUT, u(s|t) is a prior distribution, and y is a prior weight. The original OUT counts co(s, t) are weighted by a logistic function wλ(s, t): cλ(s, t) = c</context>
</contexts>
<marker>Bacchiani, Roark, Saraclar, 2004</marker>
<rawString>Michel Bacchiani, Brian Roark, and Murat Saraclar. 2004. Language model adaptation with MAP estimation and the perceptron algorithm. In NAACL04 (NAA, 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Bertoldi</author>
<author>Marcello Federico</author>
</authors>
<title>Domain adaptation for statistical machine translation with monolingual resources.</title>
<date>2009</date>
<booktitle>In WMT09 (WMT,</booktitle>
<marker>Bertoldi, Federico, 2009</marker>
<rawString>Nicola Bertoldi and Marcello Federico. 2009. Domain adaptation for statistical machine translation with monolingual resources. In WMT09 (WMT, 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Civera</author>
<author>Alfons Juan</author>
</authors>
<title>Domain adaptation in Statistical Machine Translation with mixture modelling.</title>
<date>2007</date>
<booktitle>In WMT07 (WMT,</booktitle>
<contexts>
<context position="26409" citStr="Civera and Juan, 2007" startWordPosition="4418" endWordPosition="4421">directly related work, major themes in SMT adaptation include the IR (Hildebrand et al., 2005; L¨u et al., 2007; Zhao et al., 2004) and mixture (Finch and Sumita, 2008; Foster and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk and Senellart, 2009). There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007). Other work includes transferring latent topic distributions from source to target language for LM adaptation, (Tam et al., 2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita, 2008). 6 Conclusion In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance. Each out-of-domain phrase pair is characterized by a set of simple features intended to reflect how useful it will be. The fea</context>
</contexts>
<marker>Civera, Juan, 2007</marker>
<rawString>Jorge Civera and Alfons Juan. 2007. Domain adaptation in Statistical Machine Translation with mixture modelling. In WMT07 (WMT, 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>Domain Adaptation for Statistical Classifiers.</title>
<date>2006</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>26--101</pages>
<marker>Daum´e, Marcu, 2006</marker>
<rawString>Hal Daum´e III and Daniel Marcu. 2006. Domain Adaptation for Statistical Classifiers. Journal of Artificial Intelligence Research, 26:101–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<title>Frustratingly Easy Domain Adaptation.</title>
<date>2007</date>
<booktitle>In ACL-07 (ACL,</booktitle>
<marker>Daum´e, 2007</marker>
<rawString>Hal Daum´e III. 2007. Frustratingly Easy Domain Adaptation. In ACL-07 (ACL, 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Finch</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Dynamic model interpolation for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL Workshop on Statistical Machine Translation,</booktitle>
<publisher>WMT.</publisher>
<location>Columbus,</location>
<contexts>
<context position="8480" citStr="Finch and Sumita, 2008" startWordPosition="1359" endWordPosition="1362">adaptive weights are set as follows: !αˆ = argmax ˜p(w, h) log ! αipi(w|h), (1) α w,h i where α is a weight vector containing an element αi for each domain (just IN and OUT in our case), pi are the corresponding domain-specific models, and ˜p(w, h) is an empirical distribution from a targetlanguage training corpus—we used the IN dev set for this. It is not immediately obvious how to formulate an equivalent to equation (1) for an adapted TM, because there is no well-defined objective for learning TMs from parallel corpora. This has led previous workers to adopt ad hoc linear weighting schemes (Finch and Sumita, 2008; Foster and Kuhn, 2007; L¨u et al., 2007). However, we note that the final conditional estimates p(s|t) from a given phrase table maximize the likelihood of joint empirical phrase pair counts over a word-aligned corpus. This suggests a direct parallel to (1): !αˆ = argmax ˜p(s, t) log ! αipi(s|t), (2) α s,t i where ˜p(s, t) is a joint empirical distribution extracted from the IN dev set using the standard procedure.2 An alternative form of linear combination is a maximum a posteriori (MAP) combination (Bacchiani et al., 2004). For the TM, this is: where cI(s, t) is the count in the IN phrase </context>
<context position="25955" citStr="Finch and Sumita, 2008" startWordPosition="4344" endWordPosition="4347">one correspondence between instances and features, eg the correspondence between a phrase pair (s, t) and its conditional multinomial probability p(s1t). As mentioned above, it is not obvious how to apply Daum´e’s approach to multinomials, which do not have a mechanism for combining split features. Recent work by Finkel and Manning (2009) which re-casts Daum´e’s approach in a hierarchical MAP framework may be applicable to this problem. Moving beyond directly related work, major themes in SMT adaptation include the IR (Hildebrand et al., 2005; L¨u et al., 2007; Zhao et al., 2004) and mixture (Finch and Sumita, 2008; Foster and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk and Senellart, 2009). There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007). Other work includes transferring latent topic distributions from sour</context>
</contexts>
<marker>Finch, Sumita, 2008</marker>
<rawString>Andrew Finch and Eiichiro Sumita. 2008. Dynamic model interpolation for statistical machine translation. In Proceedings of the ACL Workshop on Statistical Machine Translation, Columbus, June. WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Hierarchical Bayesian domain adaptation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<publisher>NAACL.</publisher>
<location>Boulder,</location>
<contexts>
<context position="25673" citStr="Finkel and Manning (2009)" startWordPosition="4297" endWordPosition="4300">t splits each feature into domain-specific and general copies. At first glance, this seems only peripherally related to our work, since the specific/general distinction is made for features rather than instances. However, for multinomial models like our LMs and TMs, there is a one to one correspondence between instances and features, eg the correspondence between a phrase pair (s, t) and its conditional multinomial probability p(s1t). As mentioned above, it is not obvious how to apply Daum´e’s approach to multinomials, which do not have a mechanism for combining split features. Recent work by Finkel and Manning (2009) which re-casts Daum´e’s approach in a hierarchical MAP framework may be applicable to this problem. Moving beyond directly related work, major themes in SMT adaptation include the IR (Hildebrand et al., 2005; L¨u et al., 2007; Zhao et al., 2004) and mixture (Finch and Sumita, 2008; Foster and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk an</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny Rose Finkel and Christopher D. Manning. 2009. Hierarchical Bayesian domain adaptation. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), Boulder, June. NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Mixture-model adaptation for SMT.</title>
<date>2007</date>
<booktitle>In WMT07 (WMT,</booktitle>
<contexts>
<context position="4475" citStr="Foster and Kuhn (2007)" startWordPosition="704" endWordPosition="707"> reported in. Phrase-level granularity distinguishes our work from previous work by Matsoukas et al (2009), who weight sentences according to sub-corpus and genre membership. Finally, we make some improvements to baseline approaches. We train linear mixture models for conditional phrase pair probabilities over IN and OUT so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set. This is a simple and effective alternative to setting weights discriminatively to maximize a metric such as BLEU. A similar maximumlikelihood approach was used by Foster and Kuhn (2007), but for language models only. For comparison to information-retrieval inspired baselines, eg (L¨u et al., 2007), we select sentences from OUT using language model perplexities from IN. This is a straightforward technique that is arguably better suited to the adaptation task than the standard method of treating representative IN sentences as queries, then pooling the match results. The paper is structured as follows. Section 2 describes our baseline techniques for SMT adaptation, and section 3 describes the instance-weighting approach. Experiments are presented in section 4. Section 5 covers </context>
<context position="7572" citStr="Foster and Kuhn, 2007" startWordPosition="1204" endWordPosition="1207">features to agree on high-scoring candidates. This is appropriate in cases where it is sanctioned by Bayes’ law, such as multiplying LM and TM probabilities, but for adaptation a more suitable framework is often a mixture model in which each event may be generated from some domain. This leads to a linear combination of domain-specific probabilities, with weights in [0, 1], normalized to sum to 1. Linear weights are difficult to incorporate into the standard MERT procedure because they are “hidden” within a top-level probability that represents the linear combination.1 Following previous work (Foster and Kuhn, 2007), we circumvent this problem by choosing weights to optimize corpus loglikelihood, which is roughly speaking the training criterion used by the LM and TM themselves. 1This precludes the use of exact line-maximization within Powell’s algorithm (Och, 2003), for instance. 452 For the LM, adaptive weights are set as follows: !αˆ = argmax ˜p(w, h) log ! αipi(w|h), (1) α w,h i where α is a weight vector containing an element αi for each domain (just IN and OUT in our case), pi are the corresponding domain-specific models, and ˜p(w, h) is an empirical distribution from a targetlanguage training corpu</context>
<context position="25978" citStr="Foster and Kuhn, 2007" startWordPosition="4348" endWordPosition="4352">en instances and features, eg the correspondence between a phrase pair (s, t) and its conditional multinomial probability p(s1t). As mentioned above, it is not obvious how to apply Daum´e’s approach to multinomials, which do not have a mechanism for combining split features. Recent work by Finkel and Manning (2009) which re-casts Daum´e’s approach in a hierarchical MAP framework may be applicable to this problem. Moving beyond directly related work, major themes in SMT adaptation include the IR (Hildebrand et al., 2005; L¨u et al., 2007; Zhao et al., 2004) and mixture (Finch and Sumita, 2008; Foster and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk and Senellart, 2009). There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007). Other work includes transferring latent topic distributions from source to target language f</context>
</contexts>
<marker>Foster, Kuhn, 2007</marker>
<rawString>George Foster and Roland Kuhn. 2007. Mixture-model adaptation for SMT. In WMT07 (WMT, 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Stabilizing minimum error rate training.</title>
<date>2009</date>
<booktitle>In WMT09 (WMT,</booktitle>
<contexts>
<context position="6770" citStr="Foster and Kuhn, 2009" startWordPosition="1081" endWordPosition="1084">baseline approach is to concatenate data from IN and OUT. Its success depends on the two domains being relatively close, and on the OUT corpus not being so large as to overwhelm the contribution of IN. When OUT is large and distinct, its contribution can be controlled by training separate IN and OUT models, and weighting their combination. An easy way to achieve this is to put the domain-specific LMs and TMs into the top-level log-linear model and learn optimal weights with MERT (Och, 2003). This has the potential drawback of increasing the number of features, which can make MERT less stable (Foster and Kuhn, 2009). 2.2 Linear Combinations Apart from MERT difficulties, a conceptual problem with log-linear combination is that it multiplies feature probabilities, essentially forcing different features to agree on high-scoring candidates. This is appropriate in cases where it is sanctioned by Bayes’ law, such as multiplying LM and TM probabilities, but for adaptation a more suitable framework is often a mixture model in which each event may be generated from some domain. This leads to a linear combination of domain-specific probabilities, with weights in [0, 1], normalized to sum to 1. Linear weights are d</context>
</contexts>
<marker>Foster, Kuhn, 2009</marker>
<rawString>George Foster and Roland Kuhn. 2009. Stabilizing minimum error rate training. In WMT09 (WMT, 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Almut Silja Hildebrand</author>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Adaptation of the translation model for statistical machine translation based on information retrieval.</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th EAMT Conference,</booktitle>
<location>Budapest,</location>
<contexts>
<context position="10020" citStr="Hildebrand et al., 2005" startWordPosition="1635" endWordPosition="1638">idence from IN is available. To set β, we used the same criterion as for α, over a dev corpus: ! cI(s, t) + β po(s|t) βˆ = argmax ˜p(s, t) log cI(t) + β . � s,t 2Using non-adapted IBM models trained on all available IN and OUT data. The MAP combination was used for TM probabilities only, in part due to a technical difficulty in formulating coherent counts when using standard LM smoothing techniques (Kneser and Ney, 1995).3 2.3 Sentence Selection Motivated by information retrieval, a number of approaches choose “relevant” sentence pairs from OUT by matching individual source sentences from IN (Hildebrand et al., 2005; L¨u et al., 2007), or individual target hypotheses (Zhao et al., 2004). The matching sentence pairs are then added to the IN corpus, and the system is re-trained. Although matching is done at the sentence level, this information is subsequently discarded when all matches are pooled. To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model. The number of top-ranked pairs to retain is chosen to optimize dev-set BLEU score. 3 Instance We</context>
<context position="25881" citStr="Hildebrand et al., 2005" startWordPosition="4329" endWordPosition="4333">s. However, for multinomial models like our LMs and TMs, there is a one to one correspondence between instances and features, eg the correspondence between a phrase pair (s, t) and its conditional multinomial probability p(s1t). As mentioned above, it is not obvious how to apply Daum´e’s approach to multinomials, which do not have a mechanism for combining split features. Recent work by Finkel and Manning (2009) which re-casts Daum´e’s approach in a hierarchical MAP framework may be applicable to this problem. Moving beyond directly related work, major themes in SMT adaptation include the IR (Hildebrand et al., 2005; L¨u et al., 2007; Zhao et al., 2004) and mixture (Finch and Sumita, 2008; Foster and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk and Senellart, 2009). There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 20</context>
</contexts>
<marker>Hildebrand, Eck, Vogel, Waibel, 2005</marker>
<rawString>Almut Silja Hildebrand, Matthias Eck, Stephan Vogel, and Alex Waibel. 2005. Adaptation of the translation model for statistical machine translation based on information retrieval. In Proceedings of the 10th EAMT Conference, Budapest, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Instance Weighting for Domain Adaptation in NLP.</title>
<date>2007</date>
<booktitle>In ACL07 (ACL,</booktitle>
<contexts>
<context position="2994" citStr="Jiang and Zhai, 2007" startWordPosition="473" endWordPosition="476">ss effective in our setting, where IN and OUT are disparate. The idea of distinguishing between general and domain-specific examples is due to Daum´e and Marcu (2006), who used a maximum-entropy model with latent variables to capture the degree of specificity. Daum´e (2007) applies a related idea in a simpler way, by splitting features into general and domain-specific versions. This highly effective approach is not directly applicable to the multinomial models used for core SMT components, which have no natural method for combining split features, so we rely on an instance-weighting approach (Jiang and Zhai, 2007) to downweight domain-specific examples in OUT. Within this framework, we use features intended to capture degree of generality, including the output from an SVM classifier that uses the intersection between IN and OUT as positive examples. Our second contribution is to apply instance 451 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 451–459, MIT, Massachusetts, USA, 9-11 October 2010. c!2010 Crown in Right of Canada. weighting at the level of phrase pairs. Sentence pairs are the natural instances for SMT, but sentences often contain a mix of dom</context>
<context position="12593" citStr="Jiang and Zhai (2007)" startWordPosition="2072" endWordPosition="2075">=cλ (s, t) + yu(sI t) (5) &amp;quot;s! cλ (s!, t) + y where cλ(s, t) is a modified count for pair (s, t) in OUT, u(s|t) is a prior distribution, and y is a prior weight. The original OUT counts co(s, t) are weighted by a logistic function wλ(s, t): cλ(s, t) = co(s, t) wλ(s, t) (6) = co(s, t) [1 + exp(− ! Aifi(s, t))]−1, i and: !cλ! = cλ!i(s!, t). s! 3.2 Interpretation and Variants To motivate weighting joint OUT counts as in (6), we begin with the “ideal” objective for setting multinomial phrase probabilities 0 = {p(s|t), dst}, which is the likelihood with respect to the true IN distribution pi(s, t). Jiang and Zhai (2007) suggest the following derivation, making use of the true OUT distribution po(s, t): a log p(s|t) ay a log p(s|t) aAi 1 − at p(s |t) u(s|t) − ¯cλ(s,t) ¯cλ (t) cλ(t)2 1 − at cλ!i(s, CA(s,t)cλ!i(t) p(s |t) t) CA(t) ca(t)2 1 fixed weight −cI(t)/(cI(t) + 0)2 MAP cλ!i(s, t) = fi(s, t)(1 − wλ(s, t))cλ(s, t) where: kt =&apos; where each fi(s, t) is a feature intended to charac- !0ˆ = argmax pf(s, t) log pθ(s|t) (8) terize the usefulness of (s, t), weighted by Ai. θ s,t pf(s, t)po(s, t) log pθ(s|t) The mixing parameters and feature weights (col- != argmax po (s, t) lectively 0) are optimized simultaneously</context>
<context position="24315" citStr="Jiang and Zhai (2007)" startWordPosition="4084" endWordPosition="4087">obally smoothing the final weighted frequencies is crucial. This best instance-weighting model beats the equivalant model without instance weights by between 0.6 BLEU and 1.8 BLEU, and beats the log-linear baseline by a large margin. The final block in table 2 shows models trained on feature subsets and on the SVM feature described in 3.4. The general-language features have a slight advantage over the similarity features, and both are better than the SVM feature. 5 Related Work We have already mentioned the closely related work by Matsoukas et al (2009) on discriminative corpus weighting, and Jiang and Zhai (2007) on (nondiscriminative) instance weighting. It is difficult to directly compare the Matsoukas et al results with ours, since our out-of-domain corpus is homogeneous; given heterogeneous training data, however, it would be trivial to include Matsoukas-style identity features in our instance-weighting model. Although these authors report better gains than ours, they are with respect to a non-adapted baseline. Finally, we note that Jiang’s instance-weighting framework is broader than we have presented above, encompassing among other possibilities the use of unlabelled IN data, which is applicable</context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>Jing Jiang and ChengXiang Zhai. 2007. Instance Weighting for Domain Adaptation in NLP. In ACL07 (ACL, 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Kneser</author>
<author>Hermann Ney</author>
</authors>
<title>Improved backing-off for m-gram language modeling.</title>
<date>1995</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</booktitle>
<pages>181--184</pages>
<publisher>IEEE.</publisher>
<location>Detroit, Michigan.</location>
<contexts>
<context position="9821" citStr="Kneser and Ney, 1995" startWordPosition="1607" endWordPosition="1610">g β po(s|t) to be the parameters of a Dirichlet prior on phrase probabilities, then maximizing posterior estimates p(s|t) given the IN corpus. Intuitively, it places more weight on OUT when less evidence from IN is available. To set β, we used the same criterion as for α, over a dev corpus: ! cI(s, t) + β po(s|t) βˆ = argmax ˜p(s, t) log cI(t) + β . � s,t 2Using non-adapted IBM models trained on all available IN and OUT data. The MAP combination was used for TM probabilities only, in part due to a technical difficulty in formulating coherent counts when using standard LM smoothing techniques (Kneser and Ney, 1995).3 2.3 Sentence Selection Motivated by information retrieval, a number of approaches choose “relevant” sentence pairs from OUT by matching individual source sentences from IN (Hildebrand et al., 2005; L¨u et al., 2007), or individual target hypotheses (Zhao et al., 2004). The matching sentence pairs are then added to the IN corpus, and the system is re-trained. Although matching is done at the sentence level, this information is subsequently discarded when all matches are pooled. To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentenc</context>
</contexts>
<marker>Kneser, Ney, 1995</marker>
<rawString>Reinhard Kneser and Hermann Ney. 1995. Improved backing-off for m-gram language modeling. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 1995, pages 181–184, Detroit, Michigan. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Josh Schroeder</author>
</authors>
<title>Experiments in domain adaptation for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>224--227</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="26005" citStr="Koehn and Schroeder, 2007" startWordPosition="4353" endWordPosition="4356">es, eg the correspondence between a phrase pair (s, t) and its conditional multinomial probability p(s1t). As mentioned above, it is not obvious how to apply Daum´e’s approach to multinomials, which do not have a mechanism for combining split features. Recent work by Finkel and Manning (2009) which re-casts Daum´e’s approach in a hierarchical MAP framework may be applicable to this problem. Moving beyond directly related work, major themes in SMT adaptation include the IR (Hildebrand et al., 2005; L¨u et al., 2007; Zhao et al., 2004) and mixture (Finch and Sumita, 2008; Foster and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk and Senellart, 2009). There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007). Other work includes transferring latent topic distributions from source to target language for LM adaptation, (Tam et a</context>
</contexts>
<marker>Koehn, Schroeder, 2007</marker>
<rawString>Philipp Koehn and Josh Schroeder. 2007. Experiments in domain adaptation for statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 224–227, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>127--133</pages>
<publisher>NAACL.</publisher>
<location>Edmonton,</location>
<contexts>
<context position="20677" citStr="Koehn et al., 2003" startWordPosition="3467" endWordPosition="3470">t 1,664 NIST08 test 1,357 Table 1: Corpora 8www.itl.nist.gov/iad/mig//tests/mt/2009 The reference medicine for Silapo is EPREX/ERYPO, which contains epoetin alfa. Le m´edicament de r´ef´erence de Silapo est EPREX/ERYPO, qui contient de l’´epo´etine alfa. — I would also like to point out to commissioner Liikanen that it is not easy to take a matter to a national court. Je voudrais pr´eciser, a` l’adresse du commissaire Liikanen, qu’il n’est pas ais´e de recourir aux tribunaux nationaux. Figure 1: Sentence pairs from EMEA (top) and Europarl text. We used a standard one-pass phrase-based system (Koehn et al., 2003), with the following features: relative-frequency TM probabilities in both directions; a 4-gram LM with Kneser-Ney smoothing; word-displacement distortion model; and word count. Feature weights were set using Och’s MERT algorithm (Och, 2003). The corpus was wordaligned using both HMM and IBM2 models, and the phrase table was the union of phrases extracted from these separate alignments, with a length limit of 7. It was filtered to retain the top 30 translations for each source phrase using the TM part of the current log-linear model. 4.2 Results Table 2 shows results for both settings and all </context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 127–133, Edmonton, May. NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D C Liu</author>
<author>J Nocedal</author>
</authors>
<title>On the limited memory method for large scale optimization.</title>
<date>1989</date>
<journal>Mathematical Programming B,</journal>
<volume>45</volume>
<issue>3</issue>
<contexts>
<context position="13626" citStr="Liu and Nocedal, 1989" startWordPosition="2265" endWordPosition="2268">ze the usefulness of (s, t), weighted by Ai. θ s,t pf(s, t)po(s, t) log pθ(s|t) The mixing parameters and feature weights (col- != argmax po (s, t) lectively 0) are optimized simultaneously using dev- θ s,t pf(s, t)co(s, t) log pθ(s|t), set maximum likelihood as before: !�argmax po (s, t) ! θ s,t �ˆ = argmax ˜p(s, t) log p(s|t; 0). (7) φ s,t This is a somewhat less direct objective than used by Matsoukas et al, who make an iterative approximation to expected TER. However, it is robust, efficient, and easy to implement.4 To perform the maximization in (7), we used the popular L-BFGS algorithm (Liu and Nocedal, 1989), which requires gradient information. Dropping the conditioning on 0 for brevity, and letting ¯cλ(s, t) = cλ(s, t) + yu(s|t), and ¯cλ(t) = 4Note that the probabilities in (7) need only be evaluated over the support of ˜p(s, t), which is quite small when this distribution is derived from a dev set. Maximizing (7) is thus much faster than a typical MERT run. where co(s, t) are the counts from OUT, as in (6). This has solutions: ! po(s|t) = pf(s,t)co(s,t)/ po(s,t) p(s|t) = at pI(s|t) + (1 − at) po(s|t), (4) where pI(s|t) is derived from the IN corpus using relative-frequency estimates, and po(s|</context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>D. C. Liu and J. Nocedal. 1989. On the limited memory method for large scale optimization. Mathematical Programming B, 45(3):503–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yajuan L¨u</author>
<author>Jin Huang</author>
<author>Qun Liu</author>
</authors>
<title>Improving Statistical Machine Translation Performance by Training Data Selection and Optimization.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<location>Prague, Czech Republic.</location>
<marker>L¨u, Huang, Liu, 2007</marker>
<rawString>Yajuan L¨u, Jin Huang, and Qun Liu. 2007. Improving Statistical Machine Translation Performance by Training Data Selection and Optimization. In Proceedings of the 2007 Conference on Empirical Methods in Natural Language Processing (EMNLP), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spyros Matsoukas</author>
<author>Antti-Veikko I Rosti</author>
<author>Bing Zhang</author>
</authors>
<title>Discriminative corpus weight estimation for machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<contexts>
<context position="3959" citStr="Matsoukas et al (2009)" startWordPosition="622" endWordPosition="625">ds in Natural Language Processing, pages 451–459, MIT, Massachusetts, USA, 9-11 October 2010. c!2010 Crown in Right of Canada. weighting at the level of phrase pairs. Sentence pairs are the natural instances for SMT, but sentences often contain a mix of domain-specific and general language. For instance, the sentence Similar improvements in haemoglobin levels were reported in the scientific literature for other epoetins would likely be considered domain-specific despite the presence of general phrases like were reported in. Phrase-level granularity distinguishes our work from previous work by Matsoukas et al (2009), who weight sentences according to sub-corpus and genre membership. Finally, we make some improvements to baseline approaches. We train linear mixture models for conditional phrase pair probabilities over IN and OUT so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set. This is a simple and effective alternative to setting weights discriminatively to maximize a metric such as BLEU. A similar maximumlikelihood approach was used by Foster and Kuhn (2007), but for language models only. For comparison to information-retrieval inspired bas</context>
<context position="10775" citStr="Matsoukas et al (2009)" startWordPosition="1758" endWordPosition="1761">, and the system is re-trained. Although matching is done at the sentence level, this information is subsequently discarded when all matches are pooled. To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model. The number of top-ranked pairs to retain is chosen to optimize dev-set BLEU score. 3 Instance Weighting The sentence-selection approach is crude in that it imposes a binary distinction between useful and non-useful parts of OUT. Matsoukas et al (2009) generalize it by learning weights on sentence pairs that are used when estimating relative-frequency phrase-pair probabilities. The weight on each sentence is a value in [0, 1] computed by a perceptron with Boolean features that indicate collection and genre membership. We extend the Matsoukas et al approach in several ways. First, we learn weights on individual phrase pairs rather than sentences. Intuitively, as suggested by the example in the introduction, this is the right granularity to capture domain effects. Second, rather than relying on a division of the corpus into manually-assigned </context>
<context position="24253" citStr="Matsoukas et al (2009)" startWordPosition="4074" endWordPosition="4077"> original frequencies is important for good performance, and globally smoothing the final weighted frequencies is crucial. This best instance-weighting model beats the equivalant model without instance weights by between 0.6 BLEU and 1.8 BLEU, and beats the log-linear baseline by a large margin. The final block in table 2 shows models trained on feature subsets and on the SVM feature described in 3.4. The general-language features have a slight advantage over the similarity features, and both are better than the SVM feature. 5 Related Work We have already mentioned the closely related work by Matsoukas et al (2009) on discriminative corpus weighting, and Jiang and Zhai (2007) on (nondiscriminative) instance weighting. It is difficult to directly compare the Matsoukas et al results with ours, since our out-of-domain corpus is homogeneous; given heterogeneous training data, however, it would be trivial to include Matsoukas-style identity features in our instance-weighting model. Although these authors report better gains than ours, they are with respect to a non-adapted baseline. Finally, we note that Jiang’s instance-weighting framework is broader than we have presented above, encompassing among other po</context>
</contexts>
<marker>Matsoukas, Rosti, Zhang, 2009</marker>
<rawString>Spyros Matsoukas, Antti-Veikko I. Rosti, and Bing Zhang. 2009. Discriminative corpus weight estimation for machine translation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP), Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NAACL</author>
</authors>
<date>2004</date>
<booktitle>Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<location>Boston,</location>
<marker>NAACL, 2004</marker>
<rawString>NAACL. 2004. Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), Boston, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<publisher>ACL.</publisher>
<location>Sapporo,</location>
<contexts>
<context position="6643" citStr="Och, 2003" startWordPosition="1061" endWordPosition="1062">dure for generating the phrase table from which the TM distributions are derived. 2.1 Simple Baselines The natural baseline approach is to concatenate data from IN and OUT. Its success depends on the two domains being relatively close, and on the OUT corpus not being so large as to overwhelm the contribution of IN. When OUT is large and distinct, its contribution can be controlled by training separate IN and OUT models, and weighting their combination. An easy way to achieve this is to put the domain-specific LMs and TMs into the top-level log-linear model and learn optimal weights with MERT (Och, 2003). This has the potential drawback of increasing the number of features, which can make MERT less stable (Foster and Kuhn, 2009). 2.2 Linear Combinations Apart from MERT difficulties, a conceptual problem with log-linear combination is that it multiplies feature probabilities, essentially forcing different features to agree on high-scoring candidates. This is appropriate in cases where it is sanctioned by Bayes’ law, such as multiplying LM and TM probabilities, but for adaptation a more suitable framework is often a mixture model in which each event may be generated from some domain. This leads</context>
<context position="20918" citStr="Och, 2003" startWordPosition="3503" endWordPosition="3504">lfa. — I would also like to point out to commissioner Liikanen that it is not easy to take a matter to a national court. Je voudrais pr´eciser, a` l’adresse du commissaire Liikanen, qu’il n’est pas ais´e de recourir aux tribunaux nationaux. Figure 1: Sentence pairs from EMEA (top) and Europarl text. We used a standard one-pass phrase-based system (Koehn et al., 2003), with the following features: relative-frequency TM probabilities in both directions; a 4-gram LM with Kneser-Ney smoothing; word-displacement distortion model; and word count. Feature weights were set using Och’s MERT algorithm (Och, 2003). The corpus was wordaligned using both HMM and IBM2 models, and the phrase table was the union of phrases extracted from these separate alignments, with a length limit of 7. It was filtered to retain the top 30 translations for each source phrase using the TM part of the current log-linear model. 4.2 Results Table 2 shows results for both settings and all methods described in sections 2 and 3. The 1st block contains the simple baselines from section 2.1. The natural baseline (baseline) outperforms the pure IN system only for EMEA/EP fren. Log-linear combination (loglin) improves on this in al</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training for statistical machine translation. In Proceedings of the 41th Annual Meeting of the Association for Computational Linguistics (ACL), Sapporo, July. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Schwenk</author>
<author>Jean Senellart</author>
</authors>
<title>Translation model adaptation for an arabic/french news translation system by lightly-supervised training.</title>
<date>2009</date>
<booktitle>In Proceedings of MT Summit XII,</booktitle>
<institution>International Association for Machine Translation.</institution>
<location>Ottawa, Canada,</location>
<contexts>
<context position="26291" citStr="Schwenk and Senellart, 2009" startWordPosition="4398" endWordPosition="4401">ing (2009) which re-casts Daum´e’s approach in a hierarchical MAP framework may be applicable to this problem. Moving beyond directly related work, major themes in SMT adaptation include the IR (Hildebrand et al., 2005; L¨u et al., 2007; Zhao et al., 2004) and mixture (Finch and Sumita, 2008; Foster and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk and Senellart, 2009). There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007). Other work includes transferring latent topic distributions from source to target language for LM adaptation, (Tam et al., 2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita, 2008). 6 Conclusion In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance. Each out</context>
</contexts>
<marker>Schwenk, Senellart, 2009</marker>
<rawString>Holger Schwenk and Jean Senellart. 2009. Translation model adaptation for an arabic/french news translation system by lightly-supervised training. In Proceedings of MT Summit XII, Ottawa, Canada, September. International Association for Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yik-Cheung Tam</author>
<author>Ian Lane</author>
<author>Tanja Schultz</author>
</authors>
<title>Bilingual-LSA Based LM Adaptation for Spoken Language Translation.</title>
<date>2007</date>
<booktitle>In ACL-07 (ACL,</booktitle>
<contexts>
<context position="26614" citStr="Tam et al., 2007" startWordPosition="4452" endWordPosition="4455">er, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk and Senellart, 2009). There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007). Other work includes transferring latent topic distributions from source to target language for LM adaptation, (Tam et al., 2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita, 2008). 6 Conclusion In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance. Each out-of-domain phrase pair is characterized by a set of simple features intended to reflect how useful it will be. The features are weighted within a logistic model to give an overall weight that is applied to the phrase pair’s frequency prior to making MAP-smoothed relative-frequency estimates (different weights are learned </context>
</contexts>
<marker>Tam, Lane, Schultz, 2007</marker>
<rawString>Yik-Cheung Tam, Ian Lane, and Tanja Schultz. 2007. Bilingual-LSA Based LM Adaptation for Spoken Language Translation. In ACL-07 (ACL, 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorg Tiedemann</author>
</authors>
<title>News from opus - a collection of multilingual parallel corpora with tools and interfaces.</title>
<date>2009</date>
<booktitle>Recent Advances in Natural Language Processing,</booktitle>
<volume>volume V,</volume>
<pages>237--248</pages>
<editor>In N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov, editors,</editor>
<publisher>John Benjamins, Amsterdam/Philadelphia.</publisher>
<contexts>
<context position="18929" citStr="Tiedemann, 2009" startWordPosition="3183" endWordPosition="3185">d OUT translations for that source phrase is empty. 7In the case of the Chinese experiments below, source LMs were trained using text segmented with the LDC segmenter, as were the other Chinese models in our system. 455 The classifier trained using the 2nd definition had higher accuracy on a development set. We used it to score all phrase pairs in the OUT table, in order to provide a feature for the instance-weighting model. 4 Experiments 4.1 Corpora and System We carried out translation experiments in two different settings. The first setting uses the European Medicines Agency (EMEA) corpus (Tiedemann, 2009) as IN, and the Europarl (EP) corpus (www.statmt.org/europarl) as OUT, for English/French translation in both directions. The dev and test sets were randomly chosen from the EMEA corpus. Figure 1 shows sample sentences from these domains, which are widely divergent. The second setting uses the news-related subcorpora for the NIST09 MT Chinese to English evaluation8 as IN, and the remaining NIST parallel Chinese/English corpora (UN, Hong Kong Laws, and Hong Kong Hansard) as OUT. The dev corpus was taken from the NIST05 evaluation set, augmented with some randomly-selected material reserved from</context>
</contexts>
<marker>Tiedemann, 2009</marker>
<rawString>Jorg Tiedemann. 2009. News from opus - a collection of multilingual parallel corpora with tools and interfaces. In N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov, editors, Recent Advances in Natural Language Processing, volume V, pages 237–248. John Benjamins, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Gholamreza Haffari</author>
<author>Anoop Sarkar</author>
</authors>
<title>Transductive learning for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL-07 (ACL,</booktitle>
<contexts>
<context position="26261" citStr="Ueffing et al., 2007" startWordPosition="4394" endWordPosition="4397">ork by Finkel and Manning (2009) which re-casts Daum´e’s approach in a hierarchical MAP framework may be applicable to this problem. Moving beyond directly related work, major themes in SMT adaptation include the IR (Hildebrand et al., 2005; L¨u et al., 2007; Zhao et al., 2004) and mixture (Finch and Sumita, 2008; Foster and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk and Senellart, 2009). There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007). Other work includes transferring latent topic distributions from source to target language for LM adaptation, (Tam et al., 2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita, 2008). 6 Conclusion In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve i</context>
</contexts>
<marker>Ueffing, Haffari, Sarkar, 2007</marker>
<rawString>Nicola Ueffing, Gholamreza Haffari, and Anoop Sarkar. 2007. Transductive learning for statistical machine translation. In ACL-07 (ACL, 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>WMT</author>
</authors>
<date>2007</date>
<booktitle>Proceedings of the ACL Workshop on Statistical Machine Translation,</booktitle>
<location>Prague,</location>
<marker>WMT, 2007</marker>
<rawString>WMT. 2007. Proceedings of the ACL Workshop on Statistical Machine Translation, Prague, June. WMT. 2009. Proceedings of the 4th Workshop on Statistical Machine Translation, Athens, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Wu</author>
<author>Haifeng Wang</author>
<author>Zhanyi Liu</author>
</authors>
<title>Alignment model adaptation for domain-specific word alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<publisher>ACL.</publisher>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="26427" citStr="Wu et al., 2005" startWordPosition="4422" endWordPosition="4425">major themes in SMT adaptation include the IR (Hildebrand et al., 2005; L¨u et al., 2007; Zhao et al., 2004) and mixture (Finch and Sumita, 2008; Foster and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk and Senellart, 2009). There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007). Other work includes transferring latent topic distributions from source to target language for LM adaptation, (Tam et al., 2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita, 2008). 6 Conclusion In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance. Each out-of-domain phrase pair is characterized by a set of simple features intended to reflect how useful it will be. The features are weighted</context>
</contexts>
<marker>Wu, Wang, Liu, 2005</marker>
<rawString>Hua Wu, Haifeng Wang, and Zhanyi Liu. 2005. Alignment model adaptation for domain-specific word alignment. In Proceedings of the 43th Annual Meeting of the Association for Computational Linguistics (ACL), Ann Arbor, Michigan, July. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jia Xu</author>
<author>Yonggang Deng</author>
<author>Yuqing Gao</author>
<author>Hermann Ney</author>
</authors>
<title>Domain dependent statistical machine translation.</title>
<date>2007</date>
<booktitle>In MT</booktitle>
<location>Summit XI, Copenhagen,</location>
<contexts>
<context position="26484" citStr="Xu et al., 2007" startWordPosition="4433" endWordPosition="4436"> et al., 2005; L¨u et al., 2007; Zhao et al., 2004) and mixture (Finch and Sumita, 2008; Foster and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk and Senellart, 2009). There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007). Other work includes transferring latent topic distributions from source to target language for LM adaptation, (Tam et al., 2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita, 2008). 6 Conclusion In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance. Each out-of-domain phrase pair is characterized by a set of simple features intended to reflect how useful it will be. The features are weighted within a logistic model to give an overall weight that i</context>
</contexts>
<marker>Xu, Deng, Gao, Ney, 2007</marker>
<rawString>Jia Xu, Yonggang Deng, Yuqing Gao, and Hermann Ney. 2007. Domain dependent statistical machine translation. In MT Summit XI, Copenhagen, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
</authors>
<title>Language model adaptation for statistical machine translation with structured query models.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING)</booktitle>
<location>Geneva,</location>
<contexts>
<context position="10092" citStr="Zhao et al., 2004" startWordPosition="1647" endWordPosition="1650">ver a dev corpus: ! cI(s, t) + β po(s|t) βˆ = argmax ˜p(s, t) log cI(t) + β . � s,t 2Using non-adapted IBM models trained on all available IN and OUT data. The MAP combination was used for TM probabilities only, in part due to a technical difficulty in formulating coherent counts when using standard LM smoothing techniques (Kneser and Ney, 1995).3 2.3 Sentence Selection Motivated by information retrieval, a number of approaches choose “relevant” sentence pairs from OUT by matching individual source sentences from IN (Hildebrand et al., 2005; L¨u et al., 2007), or individual target hypotheses (Zhao et al., 2004). The matching sentence pairs are then added to the IN corpus, and the system is re-trained. Although matching is done at the sentence level, this information is subsequently discarded when all matches are pooled. To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model. The number of top-ranked pairs to retain is chosen to optimize dev-set BLEU score. 3 Instance Weighting The sentence-selection approach is crude in that it imposes a bi</context>
<context position="25919" citStr="Zhao et al., 2004" startWordPosition="4338" endWordPosition="4341"> LMs and TMs, there is a one to one correspondence between instances and features, eg the correspondence between a phrase pair (s, t) and its conditional multinomial probability p(s1t). As mentioned above, it is not obvious how to apply Daum´e’s approach to multinomials, which do not have a mechanism for combining split features. Recent work by Finkel and Manning (2009) which re-casts Daum´e’s approach in a hierarchical MAP framework may be applicable to this problem. Moving beyond directly related work, major themes in SMT adaptation include the IR (Hildebrand et al., 2005; L¨u et al., 2007; Zhao et al., 2004) and mixture (Finch and Sumita, 2008; Foster and Kuhn, 2007; Koehn and Schroeder, 2007; L¨u et al., 2007) approaches for LMs and TMs described above, as well as methods for exploiting monolingual in-domain text, typically by translating it automatically and then performing self training (Bertoldi 457 and Federico, 2009; Ueffing et al., 2007; Schwenk and Senellart, 2009). There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan, 2007; Wu et al., 2005), and on dynamically choosing a dev set (Xu et al., 2007). Other work includes transferring </context>
</contexts>
<marker>Zhao, Eck, Vogel, 2004</marker>
<rawString>Bing Zhao, Matthias Eck, and Stephan Vogel. 2004. Language model adaptation for statistical machine translation with structured query models. In Proceedings of the International Conference on Computational Linguistics (COLING) 2004, Geneva, August.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>