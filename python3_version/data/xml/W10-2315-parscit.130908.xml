<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000053">
<title confidence="0.9936315">
Aggregating opinions: Explorations into Graphs and Media Content
Analysis
</title>
<author confidence="0.887483">
Gabriele Tatzl
</author>
<affiliation confidence="0.499969666666667">
SORA
Institute for Social Research &amp; Analysis
Vienna, Austria
</affiliation>
<email confidence="0.990965">
gt@sora.at
</email>
<note confidence="0.4605995">
Christoph Waldhauser
SORA
Institute for Social Research &amp; Analysis
Vienna, Austria
</note>
<email confidence="0.991146">
chw@sora.at
</email>
<sectionHeader confidence="0.993627" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999132">
Understanding, as opposed to reading is
vital for the extraction of opinions out
of a text. This is especially true, as
an author’s opinion is not always clearly
marked. Finding the overall opinion in
a text can be challenging to both hu-
man readers and computers alike. Me-
dia Content Analysis is a popular method
of extracting information out of a text, by
means of human coders. We describe the
difficulties humans have and the process
they use to extract opinions and offer a
formalization that could help to automate
opinion extraction within the Media Con-
tent Analysis framework.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999964433333334">
When humans read, they try to not only decode the
written language, but also link it with external in-
formation. This gives them access to meaning and
opinion of a text, that remain hidden from a mere
decoder. This process of reading can be organized
scientifically within the framework of Media Con-
tent Analysis (MCA). Reading, however, is expen-
sive in terms of time and money. Yet the volume
of textual data that is available for research grows
seemingly without bounds. Automating reading,
indeed doing MCA – at least to some degree – is a
very desirable advance for any practitioner in the
field.
The purpose of this short positional paper is to
introduce MCA as we use it in our day-to-day lives
and discuss challenges and possible solutions for
them, with regards to automation.
The remainder of this paper is organized as fol-
lows. First we give a brief introduction to Media
Content Analysis and it’s applications in the social
sciences in general. We will then focus on opin-
ion mining as an important task within the general
MCA framework. Special emphasis will be put on
the challenges humans (and computers alike) face,
when extracting opinions from a document. As a
contribution to the effort of overcoming these ob-
stacles, we offer a formalized interpretation of the
MCA opinion extraction process in section 4. Fi-
nally, some concluding remarks and suggestions
for an algorithmic implementation are made.
</bodyText>
<sectionHeader confidence="0.991379" genericHeader="method">
2 Media Content Analysis
</sectionHeader>
<bodyText confidence="0.992925111111111">
Media Content Analysis from a social science per-
spective is driven by research questions (e.g. How
does the perception of migrant groups vary in dif-
ferent media?) and practical questions of private
and public clients (e.g. In which context do nega-
tive opinions about a corporation occur?) in order
to investigate and evaluate the content of commu-
nication.
Media Content analysis can be generally de-
scribed as “systematic reading of a body of
texts, images, and symbolic matter” (Krippendorf,
2004). It “is applied to a wide variety of printed
matter, such as textbooks, comic strips, speeches,
and print advertising” (Krippendorf, 2004) or
more generally to any cultural artifact1. Addi-
tionally, Content Analysis is defined as an empir-
ical method for (I) systematic and inter-subjective
understandable description of textual and formal
characteristics and (II) for inquiring into social re-
ality that consists of inferring features of a non-
manifest context from features of a manifest writ-
ten text and other meaningful matters (Merten,
1995; Krippendorf, 2004; Fr¨uh, 2007).
There is a wide range of methods of research,
“(... ) from simple and extensive clas-
sifications of types of content for or-
ganizational or descriptive purposes to
</bodyText>
<footnote confidence="0.9649405">
1MCA is e.g. also used for comparing representations of
groups, issues and events to their real-world occurrences.
</footnote>
<page confidence="0.985288">
93
</page>
<note confidence="0.635638">
Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 93–97,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999978416666667">
deeply interpretative enquiries into spe-
cific examples of content, designed to
uncover subtle and hidden potential
meanings” (McQuail, 2005).
The methodology we use is based upon a broad
foundation of recent and widely approved litera-
ture (Riffe et al., 1998; Franzosi, 2008; Kaplan,
2004; Merten, 1995; Roberts, 2001; Krippen-
dorf, 2004; Neuendorf, 2007; R¨ossler, 2005; Fr¨uh,
2007; Weerakkody, 2009): The analysis typically
starts from the formulation of some specific re-
search questions, in terms of topics, actors and
patterns of interpretation that need to be investi-
gated. Based on theoretical foundations and oper-
ationalisation, categories (theoretically or empir-
ically grounded) and indicators are defined. All
categories together make up the codebook, which
is the instrument for the manual coding of text.
The codebook consists of different characteristics
for every variable and of instructions for the man-
ual coding. One can compare the codebook to the
perhaps more familiar questionnaire used in em-
pirical quantitative social science. In this under-
standing, the codebook is little more than ques-
tions on the text and some hints on how to answer
them. For instance, a question might concern a
statement’s speaker or subject actor and the way
she is arguing her opinion: Is the argumentation
of SACT in the statement rational?; possible an-
swer codes are 1—the argumentation is consistent
and rational, 2—the argumentation is not consis-
tent and not well explained, and 3—no valuation
possible.
In particular, variables are extracted on different
levels of the documents: some address the whole
document (article) and its source, some focus on
claims to be able to answer all the different re-
search questions. A core point in conducting em-
pirical research is the demand for validity (exter-
nal and internal) and reliability2 (pre-tests). These
quality checks have to be done carefully (Krippen-
dorf, 2004).
The work proceeds with the identification (the
manual annotation) of specific variables and indi-
cators by turning text into numbers and fill out the
codebook’s answer sheet (data entry mask). The
turning of text into numbers (coding process) is
at the moment a very cumbersome task, as it is
</bodyText>
<footnote confidence="0.531577">
2Reliability in Content Analysis is the amount of agree-
ment or correspondence among two or more coders (Krip-
pendorf, 2004; Neuendorf, 2007).
</footnote>
<bodyText confidence="0.999442318181818">
done manually. Humans, so called coders (usually
trained junior researchers), have to read each arti-
cle and de facto answer questions (the codebook)
on the text afterwards. Last but not least, the final
data file (cleaned manual codings) is used in statis-
tical analysis in order to answer the research ques-
tions. The significance of this methodology lies
precisely in its capacity to describe the mediated
public discourse and various forms and aspects of
diversity (i.e. diversity of opinions).
It should be considered that we conduct neither
discourse analysis (e.g. Hajer and Versteeg, 2005)
nor linguistic analysis (e.g. Livesey, 2001). Our
approach is an analysis of mediated public dis-
course (see inter alia Gerhards et al., 2007), which
implies certain methodological differences. This
methodology is especially useful for the analy-
sis of web media content and can be combined
with other approaches. In the LivingKnowledge
project3, the analysis of the mediated public dis-
course is combined with Multimodal Genre Anal-
ysis (Baldry and Thibault, 2005).
</bodyText>
<sectionHeader confidence="0.978015" genericHeader="method">
3 Opinion Mining in MCA
</sectionHeader>
<bodyText confidence="0.999985166666667">
Determining the degree to which a whole article
(entire content) or a statement in a text (part of
content) is positive, negative or neutral is not the
only but a very essential reason for conducting
Media Content Analysis. Applying the kind of
Media Content Analysis mentioned above, we are
able to describe the polarity of an opinion and the
degree of correlation between the polarity of an
opinion and the context of the opinion holder. An
opinion holder could be considered as the speaker
(person or organization) of a statement in the text.
The human coders are instructed by the codebook
(rules for coding) how opinions should be detected
and ranked (five point-scale4). We are firmly con-
vinced that it is not possible to detect opinions
across different use cases only by means of polar
words or opinion bearing words, because meaning
of these words is always dependent on the con-
</bodyText>
<footnote confidence="0.998579416666666">
3The research leading to these results has received
funding from the European Community’s Seventh Frame-
work Programme (FP7/2007-2013) under grant agreement
n◦231126 Living Knowledge: Living Knowledge – Facts,
Opinions and Bias in Time.
4Rate the opinion according to your interpretation of the
article: The overall opinion is very positive, if the topic is
mentioned with positive attributes and/or if a really positive
outcome of an event is reported and not criticized and/or if
the author of the article or more than half of the speakers
talking about a certain topic evaluates it as very positive (1 =
very positive).
</footnote>
<page confidence="0.998853">
94
</page>
<bodyText confidence="0.999892916666667">
tent’s context. If you only have a short view on
parts of the text, it can result in narrow incomplete
interpretations. Besides that, additional informa-
tion (which is not in the text) is often required
to interpret an opinion and to understand the el-
ements of social structure. It must be pointed out
that when human coders read an article, there is
a process of automatic inference. The proverbial
concept of reading vs. understanding captures this
notion with surprising accuracy. Correspondingly,
sentiment analysis is a rather challenging process
for humans as well as for computers.
</bodyText>
<sectionHeader confidence="0.955505" genericHeader="method">
4 Structuring opinions
</sectionHeader>
<bodyText confidence="0.984587972972973">
In the following we will try to formalize what usu-
ally happens inside a human coder, coding an arti-
cle. A typical research question in this sense might
be: is the opinion of article X, Θx positive, neu-
tral, or negative towards a topic Y 5? The tricky
part lies in the fact, that very few articles state their
opinions expressis verbis. Rather, articles contain
a number of statements on diverse facets of the ar-
ticle’s topic. These statements in turn are again
composed of reported actions or speech of sub-
ject actors6 (SACTs). All these elements can be
thought of as nodes in a tree: article being the root
node containing M statement nodes and N SACT
nodes. Note, that the N SACT nodes need not
be uniformly distributed between the M statement
nodes. Figure 1 displays the tree structure inherent
to Media Content Analysis.
Each node has a number of attributes, variables
in the codebook terminology, such as the name
of the author or SACT. Next to these obvious at-
tributes there are also latent ones, which are only
accessible by analyzing all child nodes and ag-
gregating the results (possibly with using exter-
nal information). Opinions of articles are one ex-
ample of latent attributes in Media Content Anal-
ysis. The process of aggregating all of a state-
ment’s SACTs’ opinions (Bmn) into a single state-
ment opinion (Bm), and further aggregating all of
an article’s statement opinions into a single article
opinion, lies at the hearth of opinion mining within
the Media Content Analysis framework. Figure 2
5Selecting only statements that deal with a certain topic Y
is beyond the scope of this paper. However, automating topic
selection is rather feasible by including background knowl-
edge on the topic itself. Background knowledge that is read-
ily available at a very early stage of MCA research question
formulation.
</bodyText>
<footnote confidence="0.942936">
6A subject actor is the person that effects a claim, e.g. if
the claim is a statement, it is the speaker
</footnote>
<figureCaption confidence="0.95719">
Figure 2: Aggregating SACTs’ opinions into a
statement opinion within the MCA framework
</figureCaption>
<bodyText confidence="0.997272266666667">
depicts the aggregating of SACTs’ opinions into a
statement opinion as a subtree.
To return to the more formalized notation in-
troduced above, Θx = f(g1, g2, ... , gm), with
gk(Bm1, Bm2, . . . , Bmn, E). A description of these
two classes of functions is not trivial. A function
(f) that aggregates statement opinions (gk, them-
selves aggregates of their SACTs’ opinions) into
an overall article opinion (B) requires to take into
account not only the opinion attributes of its state-
ment arguments, but also their relationships, an as-
sessment of their equal presentation and take hints
at the author’s intentions. This function will typ-
ically be a weighted mean of the values for the
opinion variable for the contained statements:
</bodyText>
<equation confidence="0.968284">
x =M
Ek=1 wk
</equation>
<bodyText confidence="0.999951272727273">
Estimating the weights wk needs to include the
aforementioned interstatement relationships and
presentation. For instance, in the aggregation of
two mildly negative statements and a very positive
one, do these opinions really cancel out? Diffi-
cult as this may be, aggregating SACTs’ opinions
into a single statement opinion is even more dif-
ficult. Here, external information (E) plays a cru-
cial role, e.g. can the three SACTs Bill Gates, Li-
nus Torvalds and an unnamed undergraduate com-
puter science student be equal contributors to any
</bodyText>
<figure confidence="0.978483052631579">
g()
e
e
e
Statementm
SACTm1 SACTm2
�
�Mk=1 wkgk
�Θ
95
SACT SACT SACT
Statement
11 12
SACTMN
21
Statement2 ... StatementM
1
Article
...
</figure>
<figureCaption confidence="0.999848">
Figure 1: Relationship among levels of a document
</figureCaption>
<bodyText confidence="0.889389">
d usecases seems unlikely at this time.
nces
ding a text.
</bodyText>
<subsectionHeader confidence="0.526283">
London an
</subsectionHeader>
<bodyText confidence="0.913335">
d Oakville.
</bodyText>
<sectionHeader confidence="0.9715" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.878788294117647">
96 efforts to create substantial ontologies of external
knowledge, the future certainly will show interest-
ing developments in this field.
In the meantime, thinking opinion extracting as
Robert
o Franzosi. 2008. Content analysis, volume 1 of
Sage benchmarks in social research methods. Sage,
Los Angeles.
training sets of manually coded articles could be
used to estimate the weights required to aggregate
opinions on higher levels of analysis. However,
Wern
er Fr¨uh. 2007. Inhaltanalyse. Theorie und
Praxis. UVK, Konstanz, 6. rev. ed. edition.
Gerhards, Anke Offerhaus, and Jochen Roose.
2007. The public attrobution of responsibility. de-
veloping an instrument for content an
</bodyText>
<figure confidence="0.74919925">
J¨urgen
alysis. K¨olner
Zeitschrift f¨ur Soziologie und Sozialpsychologie,
59:105–125.
</figure>
<figureCaption confidence="0.309938">
nmental Policy and Planning, 7(3):175–184.
</figureCaption>
<bodyText confidence="0.856532409090909">
d ongoing traversing a tree might help to create software that Reading and understanding text is daunting task
helps human coders in their work. Also, large for humans. It requires years if not decades of
achieving acceptable performance across diverse training and experience to uncover hidden mean-
topics an ings and latent opinions. However, the process of
reading is rather simple. We formalized this pro-
cess by focusing on the example of extracting and
aggregating opinions of an article. By rethinking
reading and understanding opinions as a tree, we
were able to structure the way humans use au-
tomatic inference to weight arguments and form
opinions. The aggregating functions are simple
themselves, however, estimating the right argu-
ments is tricky. It requires the inclusion of mas-
sive amounts of external knowledge. In our opin-
ion, this knowledge is currently not available in
machine accessible form. With the ever increas-
ing diffusion of semantic web data an
given statement. In structure, this class of func-
tions is also based on the weighted mean concept.
However, in estimating the weights, notions of
speaker interaction, speaker significance and ef-
fectiveness come into play. Many of these con-
cepts cannot be sufficiently included by means of
analyzing the text. Further, external information
is required. This information can be thought of
as an ontology or metadata, giving meaning to the
actions and speech of a SACT. In a manual cod-
ing process, this information has been learned by
the human coders through their past experience in
reading texts. This is one of the reasons junior re-
searchers, and not e.g. unskilled laborers, are used
for this task. External knowledge, quite often to a
substantial part, is critical in understan
Refere
Anthony Baldry and Paul J Thibault. 2005. Multi-
modal Transcription and Text Analysis. Equinox,
Marteen Hajer and Wytske Versteeg. 2005. A decade
of discourse analysis of environmental politics:
Achievements, challenges, perspectives. Journal of
Enviro
David Kaplan, editor. 2004. The SAGE handbook
of quantitative methodology for the social sciences.
Sage, Thousan
d Oaks.
</bodyText>
<reference confidence="0.999429576923077">
Klaus Krippendorf. 2004. Content analysis. An in-
troduction to its methodology. Sage, London, 2. ed
edition.
Sharon M Livesey. 2001. Eco-identity as discursive
struggle: Royal dutch/shell, brent spar and nigeria.
Journal of Business Communication, 38(1):58–91.
Denis McQuail. 2005. McQuail’s Mass Communica-
tion Theory. Sage, London, 5. ed edition.
Klaus Merten. 1995. Inhaltsanalyse. Einf¨uhrung
in Theorie, Methode und Praxis. Westdt. Verlag,
Opladen.
Kimberly A Neuendorf. 2007. The content analysis
guidebook. Sage, Thousand Oaks.
Daniel Riffe, Stephen Lacy, and Frederick Fico. 1998.
Analyzing media messages: using quantitative con-
tent analysis in research. Erlbaum, Mahwah.
C W Roberts. 2001. Content analysis. In Smelser and
Baltes (Smelser and Baltes, 2001).
Patrick R¨ossler. 2005. Inhaltsanalyse. UVK, Kon-
stanz.
Neil J Smelser and Paul B Baltes, editors. 2001. Inter-
national Encyclopedia of the Social &amp; Behavioral
Science. Elsevier, Amsterdam.
Niranjala Weerakkody. 2009. Research Methods
for Media and Communication. Oxford University
Press, Oxford.
</reference>
<page confidence="0.999689">
97
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.341317">
<title confidence="0.9887805">Aggregating opinions: Explorations into Graphs and Media Content Analysis</title>
<author confidence="0.989018">Gabriele</author>
<affiliation confidence="0.999903">Institute for Social Research &amp;</affiliation>
<address confidence="0.822475">Vienna,</address>
<email confidence="0.993739">gt@sora.at</email>
<author confidence="0.798086">Christoph</author>
<affiliation confidence="0.999663">Institute for Social Research &amp;</affiliation>
<address confidence="0.819484">Vienna,</address>
<email confidence="0.993935">chw@sora.at</email>
<abstract confidence="0.974697875">Understanding, as opposed to reading is vital for the extraction of opinions out of a text. This is especially true, as an author’s opinion is not always clearly marked. Finding the overall opinion in a text can be challenging to both human readers and computers alike. Media Content Analysis is a popular method of extracting information out of a text, by means of human coders. We describe the difficulties humans have and the process they use to extract opinions and offer a formalization that could help to automate opinion extraction within the Media Content Analysis framework.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Klaus Krippendorf</author>
</authors>
<title>Content analysis. An introduction to its methodology.</title>
<date>2004</date>
<location>Sage, London, 2.</location>
<note>ed edition.</note>
<contexts>
<context position="2803" citStr="Krippendorf, 2004" startWordPosition="455" endWordPosition="456">4. Finally, some concluding remarks and suggestions for an algorithmic implementation are made. 2 Media Content Analysis Media Content Analysis from a social science perspective is driven by research questions (e.g. How does the perception of migrant groups vary in different media?) and practical questions of private and public clients (e.g. In which context do negative opinions about a corporation occur?) in order to investigate and evaluate the content of communication. Media Content analysis can be generally described as “systematic reading of a body of texts, images, and symbolic matter” (Krippendorf, 2004). It “is applied to a wide variety of printed matter, such as textbooks, comic strips, speeches, and print advertising” (Krippendorf, 2004) or more generally to any cultural artifact1. Additionally, Content Analysis is defined as an empirical method for (I) systematic and inter-subjective understandable description of textual and formal characteristics and (II) for inquiring into social reality that consists of inferring features of a nonmanifest context from features of a manifest written text and other meaningful matters (Merten, 1995; Krippendorf, 2004; Fr¨uh, 2007). There is a wide range o</context>
<context position="4188" citStr="Krippendorf, 2004" startWordPosition="664" endWordPosition="666">mparing representations of groups, issues and events to their real-world occurrences. 93 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 93–97, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics deeply interpretative enquiries into specific examples of content, designed to uncover subtle and hidden potential meanings” (McQuail, 2005). The methodology we use is based upon a broad foundation of recent and widely approved literature (Riffe et al., 1998; Franzosi, 2008; Kaplan, 2004; Merten, 1995; Roberts, 2001; Krippendorf, 2004; Neuendorf, 2007; R¨ossler, 2005; Fr¨uh, 2007; Weerakkody, 2009): The analysis typically starts from the formulation of some specific research questions, in terms of topics, actors and patterns of interpretation that need to be investigated. Based on theoretical foundations and operationalisation, categories (theoretically or empirically grounded) and indicators are defined. All categories together make up the codebook, which is the instrument for the manual coding of text. The codebook consists of different characteristics for every variable and of instructions for the manual coding. One can</context>
<context position="5764" citStr="Krippendorf, 2004" startWordPosition="912" endWordPosition="914">entation of SACT in the statement rational?; possible answer codes are 1—the argumentation is consistent and rational, 2—the argumentation is not consistent and not well explained, and 3—no valuation possible. In particular, variables are extracted on different levels of the documents: some address the whole document (article) and its source, some focus on claims to be able to answer all the different research questions. A core point in conducting empirical research is the demand for validity (external and internal) and reliability2 (pre-tests). These quality checks have to be done carefully (Krippendorf, 2004). The work proceeds with the identification (the manual annotation) of specific variables and indicators by turning text into numbers and fill out the codebook’s answer sheet (data entry mask). The turning of text into numbers (coding process) is at the moment a very cumbersome task, as it is 2Reliability in Content Analysis is the amount of agreement or correspondence among two or more coders (Krippendorf, 2004; Neuendorf, 2007). done manually. Humans, so called coders (usually trained junior researchers), have to read each article and de facto answer questions (the codebook) on the text afte</context>
</contexts>
<marker>Krippendorf, 2004</marker>
<rawString>Klaus Krippendorf. 2004. Content analysis. An introduction to its methodology. Sage, London, 2. ed edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon M Livesey</author>
</authors>
<title>Eco-identity as discursive struggle: Royal dutch/shell, brent spar and nigeria.</title>
<date>2001</date>
<journal>Journal of Business Communication,</journal>
<volume>38</volume>
<issue>1</issue>
<contexts>
<context position="6838" citStr="Livesey, 2001" startWordPosition="1084" endWordPosition="1085"> called coders (usually trained junior researchers), have to read each article and de facto answer questions (the codebook) on the text afterwards. Last but not least, the final data file (cleaned manual codings) is used in statistical analysis in order to answer the research questions. The significance of this methodology lies precisely in its capacity to describe the mediated public discourse and various forms and aspects of diversity (i.e. diversity of opinions). It should be considered that we conduct neither discourse analysis (e.g. Hajer and Versteeg, 2005) nor linguistic analysis (e.g. Livesey, 2001). Our approach is an analysis of mediated public discourse (see inter alia Gerhards et al., 2007), which implies certain methodological differences. This methodology is especially useful for the analysis of web media content and can be combined with other approaches. In the LivingKnowledge project3, the analysis of the mediated public discourse is combined with Multimodal Genre Analysis (Baldry and Thibault, 2005). 3 Opinion Mining in MCA Determining the degree to which a whole article (entire content) or a statement in a text (part of content) is positive, negative or neutral is not the only </context>
</contexts>
<marker>Livesey, 2001</marker>
<rawString>Sharon M Livesey. 2001. Eco-identity as discursive struggle: Royal dutch/shell, brent spar and nigeria. Journal of Business Communication, 38(1):58–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Denis McQuail</author>
</authors>
<title>McQuail’s Mass Communication Theory.</title>
<date>2005</date>
<location>Sage, London, 5.</location>
<note>ed edition.</note>
<contexts>
<context position="3992" citStr="McQuail, 2005" startWordPosition="633" endWordPosition="634">. There is a wide range of methods of research, “(... ) from simple and extensive classifications of types of content for organizational or descriptive purposes to 1MCA is e.g. also used for comparing representations of groups, issues and events to their real-world occurrences. 93 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 93–97, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics deeply interpretative enquiries into specific examples of content, designed to uncover subtle and hidden potential meanings” (McQuail, 2005). The methodology we use is based upon a broad foundation of recent and widely approved literature (Riffe et al., 1998; Franzosi, 2008; Kaplan, 2004; Merten, 1995; Roberts, 2001; Krippendorf, 2004; Neuendorf, 2007; R¨ossler, 2005; Fr¨uh, 2007; Weerakkody, 2009): The analysis typically starts from the formulation of some specific research questions, in terms of topics, actors and patterns of interpretation that need to be investigated. Based on theoretical foundations and operationalisation, categories (theoretically or empirically grounded) and indicators are defined. All categories together m</context>
</contexts>
<marker>McQuail, 2005</marker>
<rawString>Denis McQuail. 2005. McQuail’s Mass Communication Theory. Sage, London, 5. ed edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Merten</author>
</authors>
<title>Inhaltsanalyse. Einf¨uhrung in Theorie, Methode und Praxis.</title>
<date>1995</date>
<publisher>Westdt. Verlag, Opladen.</publisher>
<contexts>
<context position="3345" citStr="Merten, 1995" startWordPosition="538" endWordPosition="539">g of a body of texts, images, and symbolic matter” (Krippendorf, 2004). It “is applied to a wide variety of printed matter, such as textbooks, comic strips, speeches, and print advertising” (Krippendorf, 2004) or more generally to any cultural artifact1. Additionally, Content Analysis is defined as an empirical method for (I) systematic and inter-subjective understandable description of textual and formal characteristics and (II) for inquiring into social reality that consists of inferring features of a nonmanifest context from features of a manifest written text and other meaningful matters (Merten, 1995; Krippendorf, 2004; Fr¨uh, 2007). There is a wide range of methods of research, “(... ) from simple and extensive classifications of types of content for organizational or descriptive purposes to 1MCA is e.g. also used for comparing representations of groups, issues and events to their real-world occurrences. 93 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 93–97, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics deeply interpretative enquiries into specific examples of content, designed to uncover subtle</context>
</contexts>
<marker>Merten, 1995</marker>
<rawString>Klaus Merten. 1995. Inhaltsanalyse. Einf¨uhrung in Theorie, Methode und Praxis. Westdt. Verlag, Opladen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kimberly A Neuendorf</author>
</authors>
<title>The content analysis guidebook. Sage, Thousand Oaks.</title>
<date>2007</date>
<contexts>
<context position="4205" citStr="Neuendorf, 2007" startWordPosition="667" endWordPosition="668">ions of groups, issues and events to their real-world occurrences. 93 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 93–97, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics deeply interpretative enquiries into specific examples of content, designed to uncover subtle and hidden potential meanings” (McQuail, 2005). The methodology we use is based upon a broad foundation of recent and widely approved literature (Riffe et al., 1998; Franzosi, 2008; Kaplan, 2004; Merten, 1995; Roberts, 2001; Krippendorf, 2004; Neuendorf, 2007; R¨ossler, 2005; Fr¨uh, 2007; Weerakkody, 2009): The analysis typically starts from the formulation of some specific research questions, in terms of topics, actors and patterns of interpretation that need to be investigated. Based on theoretical foundations and operationalisation, categories (theoretically or empirically grounded) and indicators are defined. All categories together make up the codebook, which is the instrument for the manual coding of text. The codebook consists of different characteristics for every variable and of instructions for the manual coding. One can compare the code</context>
<context position="6197" citStr="Neuendorf, 2007" startWordPosition="984" endWordPosition="985">nt in conducting empirical research is the demand for validity (external and internal) and reliability2 (pre-tests). These quality checks have to be done carefully (Krippendorf, 2004). The work proceeds with the identification (the manual annotation) of specific variables and indicators by turning text into numbers and fill out the codebook’s answer sheet (data entry mask). The turning of text into numbers (coding process) is at the moment a very cumbersome task, as it is 2Reliability in Content Analysis is the amount of agreement or correspondence among two or more coders (Krippendorf, 2004; Neuendorf, 2007). done manually. Humans, so called coders (usually trained junior researchers), have to read each article and de facto answer questions (the codebook) on the text afterwards. Last but not least, the final data file (cleaned manual codings) is used in statistical analysis in order to answer the research questions. The significance of this methodology lies precisely in its capacity to describe the mediated public discourse and various forms and aspects of diversity (i.e. diversity of opinions). It should be considered that we conduct neither discourse analysis (e.g. Hajer and Versteeg, 2005) nor</context>
</contexts>
<marker>Neuendorf, 2007</marker>
<rawString>Kimberly A Neuendorf. 2007. The content analysis guidebook. Sage, Thousand Oaks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Riffe</author>
<author>Stephen Lacy</author>
<author>Frederick Fico</author>
</authors>
<title>Analyzing media messages: using quantitative content analysis in research.</title>
<date>1998</date>
<journal>Erlbaum, Mahwah.</journal>
<contexts>
<context position="4110" citStr="Riffe et al., 1998" startWordPosition="652" endWordPosition="655">ent for organizational or descriptive purposes to 1MCA is e.g. also used for comparing representations of groups, issues and events to their real-world occurrences. 93 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 93–97, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics deeply interpretative enquiries into specific examples of content, designed to uncover subtle and hidden potential meanings” (McQuail, 2005). The methodology we use is based upon a broad foundation of recent and widely approved literature (Riffe et al., 1998; Franzosi, 2008; Kaplan, 2004; Merten, 1995; Roberts, 2001; Krippendorf, 2004; Neuendorf, 2007; R¨ossler, 2005; Fr¨uh, 2007; Weerakkody, 2009): The analysis typically starts from the formulation of some specific research questions, in terms of topics, actors and patterns of interpretation that need to be investigated. Based on theoretical foundations and operationalisation, categories (theoretically or empirically grounded) and indicators are defined. All categories together make up the codebook, which is the instrument for the manual coding of text. The codebook consists of different charact</context>
</contexts>
<marker>Riffe, Lacy, Fico, 1998</marker>
<rawString>Daniel Riffe, Stephen Lacy, and Frederick Fico. 1998. Analyzing media messages: using quantitative content analysis in research. Erlbaum, Mahwah.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C W Roberts</author>
</authors>
<title>Content analysis.</title>
<date>2001</date>
<booktitle>In Smelser and Baltes (Smelser and Baltes,</booktitle>
<contexts>
<context position="4169" citStr="Roberts, 2001" startWordPosition="662" endWordPosition="663">lso used for comparing representations of groups, issues and events to their real-world occurrences. 93 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 93–97, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics deeply interpretative enquiries into specific examples of content, designed to uncover subtle and hidden potential meanings” (McQuail, 2005). The methodology we use is based upon a broad foundation of recent and widely approved literature (Riffe et al., 1998; Franzosi, 2008; Kaplan, 2004; Merten, 1995; Roberts, 2001; Krippendorf, 2004; Neuendorf, 2007; R¨ossler, 2005; Fr¨uh, 2007; Weerakkody, 2009): The analysis typically starts from the formulation of some specific research questions, in terms of topics, actors and patterns of interpretation that need to be investigated. Based on theoretical foundations and operationalisation, categories (theoretically or empirically grounded) and indicators are defined. All categories together make up the codebook, which is the instrument for the manual coding of text. The codebook consists of different characteristics for every variable and of instructions for the man</context>
</contexts>
<marker>Roberts, 2001</marker>
<rawString>C W Roberts. 2001. Content analysis. In Smelser and Baltes (Smelser and Baltes, 2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick R¨ossler</author>
</authors>
<date>2005</date>
<location>Inhaltsanalyse. UVK, Konstanz.</location>
<marker>R¨ossler, 2005</marker>
<rawString>Patrick R¨ossler. 2005. Inhaltsanalyse. UVK, Konstanz.</rawString>
</citation>
<citation valid="true">
<date>2001</date>
<booktitle>International Encyclopedia of the Social &amp; Behavioral Science.</booktitle>
<editor>Neil J Smelser and Paul B Baltes, editors.</editor>
<publisher>Elsevier,</publisher>
<location>Amsterdam.</location>
<marker>2001</marker>
<rawString>Neil J Smelser and Paul B Baltes, editors. 2001. International Encyclopedia of the Social &amp; Behavioral Science. Elsevier, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niranjala Weerakkody</author>
</authors>
<title>Research Methods for Media and Communication.</title>
<date>2009</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="4253" citStr="Weerakkody, 2009" startWordPosition="673" endWordPosition="674">l-world occurrences. 93 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 93–97, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics deeply interpretative enquiries into specific examples of content, designed to uncover subtle and hidden potential meanings” (McQuail, 2005). The methodology we use is based upon a broad foundation of recent and widely approved literature (Riffe et al., 1998; Franzosi, 2008; Kaplan, 2004; Merten, 1995; Roberts, 2001; Krippendorf, 2004; Neuendorf, 2007; R¨ossler, 2005; Fr¨uh, 2007; Weerakkody, 2009): The analysis typically starts from the formulation of some specific research questions, in terms of topics, actors and patterns of interpretation that need to be investigated. Based on theoretical foundations and operationalisation, categories (theoretically or empirically grounded) and indicators are defined. All categories together make up the codebook, which is the instrument for the manual coding of text. The codebook consists of different characteristics for every variable and of instructions for the manual coding. One can compare the codebook to the perhaps more familiar questionnaire </context>
</contexts>
<marker>Weerakkody, 2009</marker>
<rawString>Niranjala Weerakkody. 2009. Research Methods for Media and Communication. Oxford University Press, Oxford.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>