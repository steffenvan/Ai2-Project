<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002193">
<title confidence="0.98766">
A SNoW based Supertagger with Application to NP Chunking
</title>
<author confidence="0.992115">
Libin Shen and Aravind K. Joshi
</author>
<affiliation confidence="0.882755666666667">
Department of Computer and Information Science
University of Pennsylvania
Philadelphia, PA 19104, USA
</affiliation>
<email confidence="0.997825">
libin,joshi @linc.cis.upenn.edu
</email>
<sectionHeader confidence="0.989674" genericHeader="abstract">
Abstract
1 Introduction
</sectionHeader>
<bodyText confidence="0.998703636363636">
In Lexicalized Tree-Adjoining Grammar (LTAG)
(Joshi and Schabes, 1997; XTAG-Group, 2001),
each word in a sentence is associated with an el-
ementary tree, or a supertag (Joshi and Srinivas,
1994). Supertagging is the process of assigning the
correct supertag to each word of an input sentence.
The following two facts make supertagging attrac-
tive. Firstly supertags encode much more syntac-
tical information than POS tags, which makes su-
pertagging a useful pre-parsing tool, so-called, al-
most parsing (Srinivas and Joshi, 1999). On the
</bodyText>
<footnote confidence="0.9422985">
1By the correct supertag we mean the supertag that an LTAG
parser would assign to a word in a sentence.
</footnote>
<bodyText confidence="0.999553743589744">
other hand, as the term ’supertagging’ suggests, the
time complexity of supertagging is similar to that of
POS tagging, which is linear in the length of the in-
put sentence.
In this paper, we will focus on the NP chunk-
ing task, and use it as an application of supertag-
ging. (Abney, 1991) proposed a two-phase pars-
ing model which includes chunking and attaching.
(Ramshaw and Marcus, 1995) approached chuck-
ing by using Transformation Based Learning(TBL).
Many machine learning techniques have been suc-
cessfully applied to chunking tasks, such as Regular-
ized Winnow (Zhang et al., 2001), SVMs (Kudo and
Matsumoto, 2001), CRFs (Sha and Pereira, 2003),
Maximum Entropy Model (Collins, 2002), Memory
Based Learning (Sang, 2002) and SNoW (Mu˜noz et
al., 1999).
The previous best result on chunking in literature
was achieved by Regularized Winnow (Zhang et al.,
2001), which took some of the parsing results given
by an English Slot Grammar-based parser as input to
the chunker. The use of parsing results contributed
absolute increase in F-score. However, this
approach conflicts with the purpose of chunking.
Ideally, a chunker geneates n-best results, and an at-
tacher uses chunking results to construct a parse.
The dilemma is that syntactic constraints are use-
ful in the chunking phase, but they are unavail-
able until the attaching phase. The reason is that
POS tags are not a good labeling system to encode
enough linguistic knowledge for chunking. How-
ever another labeling system, supertagging, can pro-
vide a great deal of syntactic information.
In an LTAG, each word is associated with a set of
possible elementary trees. An LTAG parser assigns
the correct elementary tree to each word of a sen-
tence, and uses the elementary trees of all the words
to build a parse tree for the sentence. Elementary
Supertagging is the tagging process of
assigning the correct elementary tree of
LTAG, or the correct supertag, to each
word of an input sentence1. In this pa-
per we propose to use supertags to expose
syntactic dependencies which are unavail-
able with POS tags. We first propose a
novel method of applying Sparse Network
of Winnow (SNoW) to sequential models.
Then we use it to construct a supertagger
that uses long distance syntactical depen-
dencies, and the supertagger achieves an
accuracy of . We apply the su-
pertagger to NP chunking. The use of su-
pertags in NP chunking gives rise to al-
most absolute increase (from
to ) in F-score under Transforma-
tion Based Learning(TBL) frame. The
surpertagger described here provides an
effective and efficient way to exploit syn-
tactic information.
trees, which we call supertags, contain more infor-
mation than POS tags, and they help to improve the
chunking accuracy.
Although supertags are able to encode long dis-
tance dependence, supertaggers trained with local
information in fact do not take full advantage of
complex information available in supertags.
In order to exploit syntactic dependencies in a
larger context, we propose a new model of supertag-
ging based on Sparse Network of Winnow (SNoW)
(Roth, 1998). We also propose a novel method of
applying SNoW to sequential models in a way anal-
ogous to the Projection-base Markov Model (PMM)
used in (Punyakanok and Roth, 2000). In contrast to
PMM, we construct a SNoW classifier for each POS
tag. For each word of an input sentence, its POS tag,
instead of the supertag of the previous word, is used
to select the corresponding SNoW classifier. This
method helps to avoid the sparse data problem and
forces SNoW to focus on difficult cases in the con-
text of supertagging task. Since PMM suffers from
the label bias problem (Lafferty et al., 2001), we
have used two methods to cope with this problem.
One method is to skip the local normalization step,
and the other is to combine the results of left-to-right
scan and right-to-left scan.
We test our supertagger on both the hand-coded
supertags used in (Chen et al., 1999) as well as
the supertags extracted from Penn Treebank(PTB)
(Marcus et al., 1994; Xia, 2001). On the dataset
used in (Chen et al., 1999), our supertagger achieves
an accuracy of .
We then apply our supertagger to NP chunking.
The purpose of this paper is to find a better way to
exploit syntactic information which is useful in NP
chunking, but not the machine learning part. So we
just use TBL, a well-known algorithm in the com-
munity of text chunking, as the machine learning
tool in our research. Using TBL also allows us to
easily evaluate the contribution of supertags with re-
spect to Ramshaw and Marcus’s original work, the
de facto baseline of NP chunking. The use of su-
pertags with TBL can be easily extended to other
machine learning algorithms.
We repeat Ramshaw and Marcus’ Transformation
Based NP chunking (Ramshaw and Marcus, 1995)
algorithm by substituting supertags for POS tags in
the dataset. The use of supertags gives rise to almost
absolute increase (from to ) in F-
score under Transformation Based Learning(TBL)
frame. This confirms our claim that using supertag-
ging as a labeling system helps to increase the over-
all performance of NP Chunking. The supertag-
ger presented in this paper provides an opportunity
for advanced machine learning techniques to im-
prove their performance on chunking tasks by ex-
ploiting more syntactic information encoded in the
supertags.
</bodyText>
<sectionHeader confidence="0.732114" genericHeader="introduction">
2 Supertagging and NP Chunking
</sectionHeader>
<bodyText confidence="0.999194848484848">
In (Srinivas, 1997) trigram models were used for su-
pertagging, in which Good-Turing discounting tech-
nique and Katz’s back-off model were employed.
The supertag for a word was determined by the lexi-
cal preference of the word, as well as by the contex-
tual preference of the previous two supertags. The
model was tested on WSJ section 20 of PTB, and
trained on section 0 through 24 except section 20.
The accuracy on the test data is 2 .
In (Srinivas, 1997), supertagging was used for
NP chunking and it achieved an F-score of .
(Chen, 2001) reported a similar result with a tri-
gram supertagger. In their approaches, they first su-
pertagged the test data and then uesd heuristic rules
to detect NP chunks. But it is hard to say whether
it is the use of supertags or the heuristic rules that
makes their system achieve the good results.
As a first attempt, we use fast TBL (Ngai and Flo-
rian, 2001), a TBL program, to repeat Ramshaw and
Marcus’ experiment on the standard dataset. Then
we use Srinivas’ supertagger (Srinivas, 1997) to su-
pertag both the training and test data. We run the
fast TBL for the second round by using supertags in-
stead of POS tags in the dataset. With POS tags we
achieve an F-score of , but with supertags we
only achieve an F-score of . This is not sur-
prising becuase Srinivas’ supertag was only trained
with a trigram model. Although supertags are able
to encode long distance dependence, supertaggers
trained with local information in fact do not take full
advantage of their strong capability. So we must use
long distance dependencies to train supertaggers to
take full advantage of the information in supertags.
</bodyText>
<footnote confidence="0.864045">
2This number is based on footnote 1 of (Chen et al., 1999).
A few supertags were grouped into equivalence classes for eval-
uation
</footnote>
<bodyText confidence="0.999960805555556">
The trigram model often fails in capturing the co-
occurrence dependence between a head word and
its dependents. Consider the phrase ”will join the
board as a nonexecutive director”. The occurrence
of join has influence on the lexical selection of as.
But join is outside the window of trigram. (Srini-
vas, 1997) proposed a head trigram model in which
the lexical selection of a word depended on the su-
pertags of the previous two head words , instead of
the supertags of the two words immediately leading
the word of interest. But the performance of this
model was worse than the traditional trigram model
because it discarded local information.
(Chen et al., 1999) combined the traditional tri-
gram model and head trigram model in their trigram
mixed model. In their model, context for the current
word was determined by the supertag of the previ-
ous word and context for the previous word accord-
ing to 6 manually defined rules. The mixed model
achieved an accuracy of on the same dataset
as that of (Srinivas, 1997). In (Chen et al., 1999),
three other models were proposed, but the mixed
model achieved the highest accuracy. In addition,
they combined all their models with pairwise voting,
yielding an accuracy of .
The mixed trigram model achieves better results
on supertagging because it can capture both lo-
cal and long distance dependencies to some extent.
However, we think that a better way to find useful
context is to use machine learning techniques but not
define the rules manually. One approach is to switch
to models like PMM, which can not only take advan-
tage of generative models with the Viterbi algorithm,
but also utilize the information in a larger contexts
through flexible feature sets. This is the basic idea
guiding the design of our supertagger.
</bodyText>
<sectionHeader confidence="0.997069" genericHeader="method">
3 SNoW
</sectionHeader>
<bodyText confidence="0.99856848">
Sparse Network of Winnow (SNoW) (Roth, 1998) is
a learning architecture that is specially tailored for
learning in the presence of a very large number of
features where the decision for a single sample de-
pends on only a small number of features. Further-
more, SNoW can also be used as a general purpose
multi-class classifier.
It is noted in (Mu˜noz et al., 1999) that one of
the important properites of the sparse architecture of
SNoW is that the complexity of processing an exam-
ple depends only on the number of features active in
it, , and is independent of the total number of fea-
tures, , observed over the life time of the system
and this is important in domains in which the total
number of features in very large, but only a small
number of them is active in each example.
As far as supertagging is concerned, word context
forms a very large space. However, for each word in
a given sentence, only a small part of features in the
space are related to the decision on supertag. Specif-
ically the supertag of a word is determined by the ap-
pearances of certain words, POS tags, or supertags
in its context. Therefore SNoW is suitable for the
supertagging task.
Supertagging can be viewed in term of the se-
quential model, which means that the selection of
the supertag for a word is influenced by the decisions
made on the previous few words. (Punyakanok and
Roth, 2000) proposed three methods of using classi-
fiers in sequential inference, which are HMM, PMM
and CSCL. Among these three models, PMM is the
most suitable for our task. The basic idea of PMM
is as follows.
Given an observation sequence , we find the
most likely state sequence given by maximiz-
ing
In this model, the output of SNoW is used to es-
timate and , where is the current
state, is the previous state, and is the current
observation. is separated to many sub-
functions according to previous state . In
practice, is estimated in a wider window
of the observed sequence, instead of only. Then
the problem is how to map the SNoW results into
probabilities. In (Punyakanok and Roth, 2000), the
sigmoid is defined as confidence,
where is the threshold for SNoW, is the dot
product of the weight vector and the example vec-
tor. The confidence is normalized by summing to 1
and used as the distribution mass .
</bodyText>
<equation confidence="0.88084">
(1)
</equation>
<sectionHeader confidence="0.985539" genericHeader="method">
4 Modeling Supertagging
</sectionHeader>
<subsectionHeader confidence="0.996381">
4.1 A Novel Sequential Model with SNoW
</subsectionHeader>
<bodyText confidence="0.994870613636363">
Firstly we have to decide how to treat POS tags. One
approach is to assign POS tags at the same time that
we do supertagging. The other approach is to as-
sign POS tags with a traditional POS tagger first,
and then use them as input to the supertagger. Su-
pertagging an unknown word becomes a problem for
supertagging due to the huge size of the supertag set,
Hence we use the second approach in our paper. We
first run the Brill POS tagger (Brill, 1995) on both
the training and the test data, and use POS tags as
part of the input.
Let be the sentence,
be the POS tags, and be
the supertags respectively. Given , we can find
the most likely supertag sequence given by
maximizing
Analogous to PMM, we decompose
into sub-classifiers. How-
ever, in our model, we divide it with respect to POS
tags as follows
(2)
There are several reasons for decomposing
with respect to the POS tag of
the current word, instead of the supertag of the pre-
vious word.
To avoid sparse-data problem. There are 479
supertags in the set of hand-coded supertags,
and almost 3000 supertags in the set of su-
pertags extracted from Penn Treebank.
Supertags related to the same POS tag are more
difficult to distinguish than supertags related to
different POS tags. Thus by defining a clas-
sifier on the POS tag of the current word but
not the POS tag of the previous word forces the
learning algorithm to focus on difficult cases.
Decomposition of the probability estimation
can decrease the complexity of the learning al-
gorithm and allows the use of different param-
eters for different POS tags.
For each POS , we construct a SNoW classifier
to estimate distribution accord-
ing to the previous supertags. Following the esti-
mation of distribution function in (Punyakanok and
Roth, 2000), we define confidence with a sigmoid
</bodyText>
<subsectionHeader confidence="0.980052">
4.2 Label Bias Problem
</subsectionHeader>
<bodyText confidence="0.987493655172414">
In (Lafferty et al., 2001), it is shown that PMM
and other non-generative finite-state models based
on next-state classifiers share a weakness which they
called the label bias problem: the transitions leaving
a given state compete only against each other, rather
than against all other transitions in the model. They
proposed Conditional Random Fields (CRFs) as so-
lution to this problem.
(Collins, 2002) proposed a new algorithm for pa-
rameter estimation as an alternate to CRF. The new
algorithm was similar to maximum-entropy model
except that it skipped the local normalization step.
Intuitively, it is the local normalization that makes
distribution mass of the transitions leaving a given
state incomparable with all other transitions.
It is noted in (Mu˜noz et al., 1999) that SNoW’s
output provides, in addition to the prediction, a ro-
bust confidence level in the prediction, which en-
ables its use in an inference algorithm that combines
predictors to produce a coherent inference. In that
paper, SNoW’s output is used to estimate the proba-
bility of open and close tags. In general, the proba-
bility of a tag can be estimated as follows
(5)
as one of the anonymous reviewers has suggested.
However, this makes probabilities comparable
only within the transitions of the same history .
An alternative to this approach is to use the SNoW’s
output directly in the prediction combination, which
</bodyText>
<equation confidence="0.5135605">
(4)
(3)
</equation>
<bodyText confidence="0.991887571428571">
where is the threshold of , and is set to 1.
The distribution mass is then defined with normal-
ized confidence
makes transitions of different history comparable,
since the SNoW’s output provides a robust confi-
dence level in the prediction. Furthermore, in order
to make sure that the confidences are not too sharp,
we use the confidence defined in (3).
In addition, we use two supertaggers, one scans
from left to right and the other scans from right to
left. Then we combine the results via pairwise vot-
ing as in (van Halteren et al., 1998; Chen et al.,
1999) as the final supertag. This approach of vot-
ing also helps to cope with the label bias problem.
</bodyText>
<subsectionHeader confidence="0.983106">
4.3 Contextual Model
</subsectionHeader>
<bodyText confidence="0.999560666666667">
is estimated within a 5-word window
plus two head supertags before the current word.
For each word , the basic features are
, ,and
, the two head supertags before the current
word. Thus
A basic feature is called active for word if and
only if the corresponding word/POS-tag/supertag
appears at a specified place around . For our
SNoW classifiers we use unigram and bigram of ba-
sic features as our feature set. A feature defined as a
bigram of two basic features is active if and only if
the two basic features are both active. The value of
a feature of is set to 1 if this feature is active for
, or 0 otherwise.
</bodyText>
<sectionHeader confidence="0.544818" genericHeader="method">
4.4 Related Work
</sectionHeader>
<bodyText confidence="0.9999874">
(Chen, 2001) implemented an MEMM model for su-
pertagging which is analogous to the POS tagging
model of (Ratnaparkhi, 1996). The feature sets used
in the MEMM model were similar to ours. In addi-
tion, prefix and suffix features were used to handle
rare words. Several MEMM supertaggers were im-
plemented based on distinct feature sets.
In (Mu˜noz et al., 1999), SNoW was used for
text chunking. The IOB tagging model in that pa-
per was similar to our model for supertagging, but
there are some differences. They did not decom-
pose the SNoW classifier with respect to POS tags.
They used two-level deterministic ( beam-width=1 )
search, in which the second level IOB classifier takes
the IOB output of the first classifier as input features.
</bodyText>
<sectionHeader confidence="0.965668" genericHeader="method">
5 Experimental Evaluation and Analysis
</sectionHeader>
<bodyText confidence="0.999726695652174">
In our experiments, we use the default settings of
the SNoW promotion parameter, demotion parame-
ter and the threshold value given by the SNoW sys-
tem. We train our model on the training data for 2
rounds, only counting the features that appear for at
least 5 times. We skip the normalization step in test,
and we use beam search with the width of 5.
In our first experiment, we use the same dataset
as that of (Chen et al., 1999) for our experiments.
We use WSJ section 00 through 24 expect section
20 as training data, and use section 20 as test data.
Both training and test data are first tagged by Brill’s
POS tagger (Brill, 1995). We use the same pair-
wise voting algorithm as in (Chen et al., 1999). We
run supertagging on the training data and use the su-
pertagging result to generate the mapping table used
in pairwise voting.
The SNoW supertagger scanning from left to
right achieves an accuracy of , and the one
scanning from right to left achieves an accuracy of
. By combining the results of these two su-
pertaggers with pairwise voting, we achieve an ac-
curacy of , an error reduction of com-
pared to , the best supertagging result to date
(Chen, 2001). Table 1 shows the comparison with
previous work.
Our algorithm, which is coded in Java, takes
about 10 minutes to supertag the test data with a
P3 1.13GHz processor. However, in (Chen, 2001),
the accuracy of was achieved by a Viterbi
search program that took about 5 days to supertag
the test data. The counterpart of our algorithm in
(Chen, 2001) is the beam search on Model 8 with
width of 5, which is the same as the beam width in
our algorithm. Compared with this program, our al-
gorithm achieves an error reduction of .
(Chen et al., 1999) achieved an accuracy of
by combination of 5 distinct supertaggers.
However, our result is achieved by combining out-
puts of two homogeneous supertaggers, which only
differ in scan direction.
Our next experiment is with the set of supertags
abstracted from PTB with Fei Xia’s LexTract (Xia,
2001). Xia extracted an LTAG-style grammar from
PTB, and repeated Srinivas’ experiment (Srinivas,
1997) on her supertag set. There are 2920 elemen-
</bodyText>
<table confidence="0.994583333333333">
model acc
Srinivas(97) trigram 91.37
Chen(99) trigram mix 91.79
Chen(99) voting 92.19
Chen(01) width=5 91.83
Chen(01) Viterbi 92.25
SNoW left-to-right 92.02
SNoW right-to-left 91.43
SNoW 92.41
</table>
<tableCaption confidence="0.998683">
Table 1: Comparison with previous work. Training
</tableCaption>
<listItem confidence="0.588428">
data is WSJ section 00 thorough 24 except section
20 of PTB. Test data is WSJ section 20. Size of tag
set is 479. acc = percentage of accuracy. The num-
ber of Srinivas(97) is based on footnote 1 of (Chen et
al., 1999). The number of Chen(01) width=5 is the
result of a beam search on Model 8 with the width
of 5.
</listItem>
<table confidence="0.941850666666667">
model acc (22) acc (23)
Xia(01) trigram 83.60 84.41
SNoW left-to-right 86.01 86.27
</table>
<tableCaption confidence="0.966726">
Table 2: Results on auto-extracted LTAG grammar.
</tableCaption>
<bodyText confidence="0.976324818181818">
Training data is WSJ section 02 thorough 21 of PTB.
Test data is WSJ section 22 and 23. Size of supertag
set is 2920. acc = percentage of accuracy.
tary trees in Xia’s grammar , so that the supertags
are more specialized and hence there is much more
ambiguity in supertagging. We have experimented
with our model on and her dataset. We train our
left-to-right model on WSJ section 02 through 21 of
PTB, and test on section 22 and 23. We achieve an
average error reduction of . The reason why
the accuracy is rather low is that systems using
have to cope with much more ambiguities due the
large size of the supertag set. The results are shown
in Table 2.
We test on both normalized and unnormalized
models with both hand coded supertag set and auto-
extracted supertag set. We use the left-to-right
SNoW model in these experiments. The results in
Table 3 show that skipping the local normalization
improves performance in all the systems. The ef-
fect of skipping normalization is more significant on
auto-extracted tags. We think this is because sparse
</bodyText>
<note confidence="0.5895234">
tag set size norm? acc (20/22/23)
auto 2920 yes NA / 85.77 / 85.98
auto 2920 no NA / 86.01 / 86.27
hand 479 yes 91.98 / NA / NA
hand 479 no 92.02 / NA / NA
</note>
<tableCaption confidence="0.9485785">
Table 3: Experiments on normalized and unnormal-
ized models using left-to-right SNoW supertagger.
</tableCaption>
<bodyText confidence="0.9569772">
size = size of the tag set. norm? = normalized or
not. acc = percentage of accuracy on section 20,
22 and 23. auto = auto-extracted tag set. hand =
hand coded tag set.
data is more vulnerable to the label bias problem.
</bodyText>
<sectionHeader confidence="0.92612" genericHeader="method">
6 Application to NP Chunking
</sectionHeader>
<bodyText confidence="0.968495612903226">
Now we come back to the NP chunking problem.
The standard dataset of NP chunking consists of
WSJ section 15-18 as train data and section 20 as test
data. In our approach, we substitute the supertags
for the POS tags in the dataset. The new data look
as follows.
For B Pnxs O
the B Dnx I
nine B Dnx I
months A NXN I
The first field is the word, the second is the su-
pertag of the word, and the last is the IOB tag.
We first use the fast TBL (Ngai and Florian, 2001),
a Transformation Based Learning algorithm, to re-
peat Ramshaw and Marcus’ experiment, and then
apply the same program to our new dataset. Since
section 15-18 and section 20 are in the standard data
set of NP chunking, we need to avoid using these
sections as training data for our supertagger. We
have trained another supertagger that is trained on
776K words in WSJ section 02-14 and 21-24, and it
is tuned with 44K words in WSJ section 19. We use
this supertagger to supertag section 15-18 and sec-
tion 20. We train an NP Chunker on section 15-18
with fast TBL, and test it on section 20.
There is a small problem with the supertag set that
we have been using, as far as NP chunking is con-
cerned. Two words with different POS tags may be
tagged with the same supertag. For example both de-
terminer (DT) and number (CD) can be tagged with
B Dnx. However this will be harmful in the case
</bodyText>
<table confidence="0.9982785">
model A P R F
RM95 - 91.80 92.27 92.03
Brill-POS 97.42 91.83 92.20 92.01
Tri-STAG 97.29 91.60 91.72 91.66
SNoW-STAG 97.66 92.76 92.34 92.55
SNoW-STAG2 97.70 92.86 93.05 92.95
GOLD-POS 97.91 93.17 93.51 93.34
GOLD-STAG 98.48 94.74 95.63 95.18
</table>
<tableCaption confidence="0.996672">
Table 4: Results on NP Chunking. Training data is
</tableCaption>
<bodyText confidence="0.99404012">
WSJ section 15-18 of PTB. Test data is WSJ section
20. A = Accuracy of IOB tagging. P = NP chunk
Precision. R = NP chunk Recall. F = F-score. Brill-
POS =fast TBL with Brill’s POS tags. Tri-STAG =
fast TBL with supertags given by Srinivas’ trigram-
based supertagger. SNoW-STAG =fast TBL with
supertags given by our SNoW supertagger. SNoW-
STAG2 =fast TBL with augmented supertags given
by our SNoW supertagger. GOLD-POS =fast TBL
with gold standard POS tags. GOLD-STAG =fast
TBL with gold standard supertags.
of NP Chunking. As a solution, we use augmented
supertags that have the POS tag of the lexical item
specified. An augmented supertag can also be re-
garded as concatenation of a supertag and a POS tag.
For B Pnxs(IN) O
the B Dnx(DT) I
nine B Dnx(CD) I
months A NXN(NNS) I
The results are shown in Table 4. The system
using augmented supertags achieves an F-score of
, or an error reduction of below the
baseline of using Brill POS tags. Although these two
systems are both trained with the same TBL algo-
rithm, we implicitly employ more linguistic knowl-
edge as the learning bias when we train the learn-
ing machine with supertags. Supertags encode more
syntactical information than POS tag do.
For example, in the sentence Three leading drug
companies ..., the POS tag of is VBG, or
present participle. Based on the local context of
, Three can be the subject of leading. How-
ever, the supertag of leading is B An, which repre-
sents a modifier of a noun. With this extra informa-
tion, the chunker can easily solve the ambiguity. We
find many instances like this in the test data.
It is important to note that the accuracy of su-
pertag itself is much lower than that of POS tag
while the use of supertags helps to improve the over-
all performance. On the other hand, since the accu-
racy of supertagging is rather lower, there is more
room left for improving.
If we use gold standard POS tags in the previ-
ous experiment, we can only achieve an F-score of
. However, if we use gold standard supertags
in our previous experiment, the F-score is as high
as . This tells us how much room there
is for further improvements. Improvements in su-
pertagging may give rise to further improvements in
chunking.
</bodyText>
<sectionHeader confidence="0.999573" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999367666666667">
We have proposed the use of supertags in the NP
chunking task in order to use more syntactical de-
pendencies which are unavailable with POS tags. In
order to train a supertagger with a larger context, we
have proposed a novel method of applying SNoW to
the sequential model and have applied it to supertag-
ging. Our algorithm takes advantage of rich feature
sets, avoids the sparse-data problem, and forces the
learning algorithm to focus on the difficult cases.
Being aware of the fact that our algorithm may suf-
fer from the label bias problem, we have used two
methods to cope with this problem, and achieved de-
sirable results.
We have tested our algorithms on both the hand-
coded tag set used in (Chen et al., 1999) and su-
pertags extracted for Penn Treebank(PTB). On the
same dataset as that of (Chen et al., 1999), our new
supertagger achieves an accuracy of . Com-
pared with the supertaggers with the same decoding
complexity (Chen, 2001), our algorithm achieves an
error reduction of .
We repeat Ramshaw and Marcus’ Transforma-
tion Based NP chunking (Ramshaw and Marcus,
1995) test by substituting supertags for POS tags
in the dataset. The use of supertags in NP chunk-
ing gives rise to almost absolute increase (from
to ) in F-score under Transformation
Based Learning(TBL) frame, or an error reduction
of .
The accuracy of with our individual TBL
chunker is close to results of POS-tag-based systems
using advanced machine learning algorithms, such
as by voted MBL chunkers (Sang, 2002),
by SNoW chunker (Mu˜noz et al., 1999). The
benefit of using a supertagger is obvious. The su-
pertagger provides an opportunity for advanced ma-
chine learning techniques to improve their perfor-
mance on chunking tasks by exploiting more syn-
tactic information encoded in the supertags.
To sum up, the supertagging algorithm presented
here provides an effective and efficient way to em-
ploy syntactic information.
</bodyText>
<sectionHeader confidence="0.998929" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999432">
We thank Vasin Punyakanok for help on the use of
SNoW in sequential inference, John Chen for help
on dataset and evaluation methods and comments
on the draft. We also thank Srinivas Bangalore and
three anonymous reviews for helpful comments.
</bodyText>
<sectionHeader confidence="0.999118" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999904550724637">
S. Abney. 1991. Parsing by chunks. In Principle-Based
Parsing. Kluwer Academic Publishers.
E. Brill. 1995. Transformation-based error-driven learn-
ing and natural language processing: A case study
in part-of-speech tagging. Computational Linguistics,
21(4):543–565.
J. Chen, B. Srinivas, and K. Vijay-Shanker. 1999. New
models for improving supertag disambiguation. In
Proceedings of the 9th EACL.
J. Chen. 2001. Towards Efficient Statistical Parsing us-
ing Lexicalized Grammatical Information. Ph.D. the-
sis, University of Delaware.
M. Collins. 2002. Discriminative training methods for
hidden markov models: Theory and experiments with
perceptron algorithms. In EMNLP 2002.
A. Joshi and Y. Schabes. 1997. Tree-adjoining gram-
mars. In G. Rozenberg and A. Salomaa, editors,
Handbook of Formal Languages, volume 3, pages 69
– 124. Springer.
A. Joshi and B. Srinivas. 1994. Disambiguation of su-
per parts of speech (or supertags): Almost parsing. In
COLING’94.
T. Kudo and Y. Matsumoto. 2001. Chunking with sup-
port vector machines. In Proceedings ofNAACL 2001.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Condi-
tional random fields: Probabilistic models for stgmen-
tation and labeling sequence data. In Proceedings of
ICML 2001.
M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz.
1994. Building a large annotated corpus of en-
glish: the penn treebank. Computational Linguistics,
19(2):313–330.
M. Mu˜noz, V. Punyakanok, D. Roth, and D. Zimak.
1999. A learning approach to shallow parsing. In Pro-
ceedings ofEMNLP-WVLC’99.
G. Ngai and R. Florian. 2001. Transformation-based
learning in the fast lane. In Proceedings of NAACL-
2001, pages 40–47.
V. Punyakanok and D. Roth. 2000. The use of classifiers
in sequential inference. In NIPS’00.
L. Ramshaw and M. Marcus. 1995. Text chunking using
transformation-based learning. In Proceedings of the
3rd WVLC.
A. Ratnaparkhi. 1996. A maximum entropy part-of-
speech tagger. In Proceedings ofEMNLP 96.
D. Roth. 1998. Learning to resolve natural language am-
biguities: A unified approach. In AAAI’98.
Erik F. Tjong Kim Sang. 2002. Memory-based shal-
low parsing. Journal of Machine Learning Research,
2:559–594.
F. Sha and F. Pereira. 2003. Shallow parsing with condi-
tional random fields. In Proceedings ofNAACL 2003.
B. Srinivas and A. Joshi. 1999. Supertagging: An ap-
proach to almost parsing. Computational Linguistics,
25(2).
B. Srinivas. 1997. Performance evaluation of supertag-
ging for partial parsing. In IWPT 1997.
H. van Halteren, J. Zavrel, and W. Daelmans. 1998. Im-
proving data driven wordclass tagging by system com-
bination. In Proceedings of COLING-ACL 98.
F. Xia. 2001. Automatic Grammar Generation From
Two Different Perspectives. Ph.D. thesis, University
of Pennsylvania.
XTAG-Group. 2001. A lexicalized tree adjoining gram-
mar for english. Technical Report 01-03, IRCS, Univ.
of Pennsylvania.
T. Zhang, F. Damerau, and D. Johnson. 2001. Text
chunking using regularized winnow. In Proceedings
ofACL 2001.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.492073">
<title confidence="0.999717">A SNoW based Supertagger with Application to NP Chunking</title>
<author confidence="0.999989">Shen K Joshi</author>
<affiliation confidence="0.999908">Department of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.99988">Philadelphia, PA 19104, USA</address>
<email confidence="0.997817">libin,joshi@linc.cis.upenn.edu</email>
<abstract confidence="0.493198"></abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>Parsing by chunks. In Principle-Based Parsing.</title>
<date>1991</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1170" citStr="Abney, 1991" startWordPosition="187" endWordPosition="188">acts make supertagging attractive. Firstly supertags encode much more syntactical information than POS tags, which makes supertagging a useful pre-parsing tool, so-called, almost parsing (Srinivas and Joshi, 1999). On the 1By the correct supertag we mean the supertag that an LTAG parser would assign to a word in a sentence. other hand, as the term ’supertagging’ suggests, the time complexity of supertagging is similar to that of POS tagging, which is linear in the length of the input sentence. In this paper, we will focus on the NP chunking task, and use it as an application of supertagging. (Abney, 1991) proposed a two-phase parsing model which includes chunking and attaching. (Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL). Many machine learning techniques have been successfully applied to chunking tasks, such as Regularized Winnow (Zhang et al., 2001), SVMs (Kudo and Matsumoto, 2001), CRFs (Sha and Pereira, 2003), Maximum Entropy Model (Collins, 2002), Memory Based Learning (Sang, 2002) and SNoW (Mu˜noz et al., 1999). The previous best result on chunking in literature was achieved by Regularized Winnow (Zhang et al., 2001), which took some of the p</context>
</contexts>
<marker>Abney, 1991</marker>
<rawString>S. Abney. 1991. Parsing by chunks. In Principle-Based Parsing. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="12549" citStr="Brill, 1995" startWordPosition="2152" endWordPosition="2153">mple vector. The confidence is normalized by summing to 1 and used as the distribution mass . (1) 4 Modeling Supertagging 4.1 A Novel Sequential Model with SNoW Firstly we have to decide how to treat POS tags. One approach is to assign POS tags at the same time that we do supertagging. The other approach is to assign POS tags with a traditional POS tagger first, and then use them as input to the supertagger. Supertagging an unknown word becomes a problem for supertagging due to the huge size of the supertag set, Hence we use the second approach in our paper. We first run the Brill POS tagger (Brill, 1995) on both the training and the test data, and use POS tags as part of the input. Let be the sentence, be the POS tags, and be the supertags respectively. Given , we can find the most likely supertag sequence given by maximizing Analogous to PMM, we decompose into sub-classifiers. However, in our model, we divide it with respect to POS tags as follows (2) There are several reasons for decomposing with respect to the POS tag of the current word, instead of the supertag of the previous word. To avoid sparse-data problem. There are 479 supertags in the set of hand-coded supertags, and almost 3000 s</context>
<context position="18026" citStr="Brill, 1995" startWordPosition="3105" endWordPosition="3106">we use the default settings of the SNoW promotion parameter, demotion parameter and the threshold value given by the SNoW system. We train our model on the training data for 2 rounds, only counting the features that appear for at least 5 times. We skip the normalization step in test, and we use beam search with the width of 5. In our first experiment, we use the same dataset as that of (Chen et al., 1999) for our experiments. We use WSJ section 00 through 24 expect section 20 as training data, and use section 20 as test data. Both training and test data are first tagged by Brill’s POS tagger (Brill, 1995). We use the same pairwise voting algorithm as in (Chen et al., 1999). We run supertagging on the training data and use the supertagging result to generate the mapping table used in pairwise voting. The SNoW supertagger scanning from left to right achieves an accuracy of , and the one scanning from right to left achieves an accuracy of . By combining the results of these two supertaggers with pairwise voting, we achieve an accuracy of , an error reduction of compared to , the best supertagging result to date (Chen, 2001). Table 1 shows the comparison with previous work. Our algorithm, which is</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>E. Brill. 1995. Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging. Computational Linguistics, 21(4):543–565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chen</author>
<author>B Srinivas</author>
<author>K Vijay-Shanker</author>
</authors>
<title>New models for improving supertag disambiguation.</title>
<date>1999</date>
<booktitle>In Proceedings of the 9th EACL.</booktitle>
<contexts>
<context position="4799" citStr="Chen et al., 1999" startWordPosition="789" endWordPosition="792">h word of an input sentence, its POS tag, instead of the supertag of the previous word, is used to select the corresponding SNoW classifier. This method helps to avoid the sparse data problem and forces SNoW to focus on difficult cases in the context of supertagging task. Since PMM suffers from the label bias problem (Lafferty et al., 2001), we have used two methods to cope with this problem. One method is to skip the local normalization step, and the other is to combine the results of left-to-right scan and right-to-left scan. We test our supertagger on both the hand-coded supertags used in (Chen et al., 1999) as well as the supertags extracted from Penn Treebank(PTB) (Marcus et al., 1994; Xia, 2001). On the dataset used in (Chen et al., 1999), our supertagger achieves an accuracy of . We then apply our supertagger to NP chunking. The purpose of this paper is to find a better way to exploit syntactic information which is useful in NP chunking, but not the machine learning part. So we just use TBL, a well-known algorithm in the community of text chunking, as the machine learning tool in our research. Using TBL also allows us to easily evaluate the contribution of supertags with respect to Ramshaw an</context>
<context position="7912" citStr="Chen et al., 1999" startWordPosition="1328" endWordPosition="1331">he fast TBL for the second round by using supertags instead of POS tags in the dataset. With POS tags we achieve an F-score of , but with supertags we only achieve an F-score of . This is not surprising becuase Srinivas’ supertag was only trained with a trigram model. Although supertags are able to encode long distance dependence, supertaggers trained with local information in fact do not take full advantage of their strong capability. So we must use long distance dependencies to train supertaggers to take full advantage of the information in supertags. 2This number is based on footnote 1 of (Chen et al., 1999). A few supertags were grouped into equivalence classes for evaluation The trigram model often fails in capturing the cooccurrence dependence between a head word and its dependents. Consider the phrase ”will join the board as a nonexecutive director”. The occurrence of join has influence on the lexical selection of as. But join is outside the window of trigram. (Srinivas, 1997) proposed a head trigram model in which the lexical selection of a word depended on the supertags of the previous two head words , instead of the supertags of the two words immediately leading the word of interest. But t</context>
<context position="15872" citStr="Chen et al., 1999" startWordPosition="2714" endWordPosition="2717">tput directly in the prediction combination, which (4) (3) where is the threshold of , and is set to 1. The distribution mass is then defined with normalized confidence makes transitions of different history comparable, since the SNoW’s output provides a robust confidence level in the prediction. Furthermore, in order to make sure that the confidences are not too sharp, we use the confidence defined in (3). In addition, we use two supertaggers, one scans from left to right and the other scans from right to left. Then we combine the results via pairwise voting as in (van Halteren et al., 1998; Chen et al., 1999) as the final supertag. This approach of voting also helps to cope with the label bias problem. 4.3 Contextual Model is estimated within a 5-word window plus two head supertags before the current word. For each word , the basic features are , ,and , the two head supertags before the current word. Thus A basic feature is called active for word if and only if the corresponding word/POS-tag/supertag appears at a specified place around . For our SNoW classifiers we use unigram and bigram of basic features as our feature set. A feature defined as a bigram of two basic features is active if and only</context>
<context position="17822" citStr="Chen et al., 1999" startWordPosition="3066" endWordPosition="3069">-level deterministic ( beam-width=1 ) search, in which the second level IOB classifier takes the IOB output of the first classifier as input features. 5 Experimental Evaluation and Analysis In our experiments, we use the default settings of the SNoW promotion parameter, demotion parameter and the threshold value given by the SNoW system. We train our model on the training data for 2 rounds, only counting the features that appear for at least 5 times. We skip the normalization step in test, and we use beam search with the width of 5. In our first experiment, we use the same dataset as that of (Chen et al., 1999) for our experiments. We use WSJ section 00 through 24 expect section 20 as training data, and use section 20 as test data. Both training and test data are first tagged by Brill’s POS tagger (Brill, 1995). We use the same pairwise voting algorithm as in (Chen et al., 1999). We run supertagging on the training data and use the supertagging result to generate the mapping table used in pairwise voting. The SNoW supertagger scanning from left to right achieves an accuracy of , and the one scanning from right to left achieves an accuracy of . By combining the results of these two supertaggers with </context>
<context position="19097" citStr="Chen et al., 1999" startWordPosition="3300" endWordPosition="3303">uction of compared to , the best supertagging result to date (Chen, 2001). Table 1 shows the comparison with previous work. Our algorithm, which is coded in Java, takes about 10 minutes to supertag the test data with a P3 1.13GHz processor. However, in (Chen, 2001), the accuracy of was achieved by a Viterbi search program that took about 5 days to supertag the test data. The counterpart of our algorithm in (Chen, 2001) is the beam search on Model 8 with width of 5, which is the same as the beam width in our algorithm. Compared with this program, our algorithm achieves an error reduction of . (Chen et al., 1999) achieved an accuracy of by combination of 5 distinct supertaggers. However, our result is achieved by combining outputs of two homogeneous supertaggers, which only differ in scan direction. Our next experiment is with the set of supertags abstracted from PTB with Fei Xia’s LexTract (Xia, 2001). Xia extracted an LTAG-style grammar from PTB, and repeated Srinivas’ experiment (Srinivas, 1997) on her supertag set. There are 2920 elemenmodel acc Srinivas(97) trigram 91.37 Chen(99) trigram mix 91.79 Chen(99) voting 92.19 Chen(01) width=5 91.83 Chen(01) Viterbi 92.25 SNoW left-to-right 92.02 SNoW ri</context>
<context position="26332" citStr="Chen et al., 1999" startWordPosition="4608" endWordPosition="4611">pendencies which are unavailable with POS tags. In order to train a supertagger with a larger context, we have proposed a novel method of applying SNoW to the sequential model and have applied it to supertagging. Our algorithm takes advantage of rich feature sets, avoids the sparse-data problem, and forces the learning algorithm to focus on the difficult cases. Being aware of the fact that our algorithm may suffer from the label bias problem, we have used two methods to cope with this problem, and achieved desirable results. We have tested our algorithms on both the handcoded tag set used in (Chen et al., 1999) and supertags extracted for Penn Treebank(PTB). On the same dataset as that of (Chen et al., 1999), our new supertagger achieves an accuracy of . Compared with the supertaggers with the same decoding complexity (Chen, 2001), our algorithm achieves an error reduction of . We repeat Ramshaw and Marcus’ Transformation Based NP chunking (Ramshaw and Marcus, 1995) test by substituting supertags for POS tags in the dataset. The use of supertags in NP chunking gives rise to almost absolute increase (from to ) in F-score under Transformation Based Learning(TBL) frame, or an error reduction of . The a</context>
</contexts>
<marker>Chen, Srinivas, Vijay-Shanker, 1999</marker>
<rawString>J. Chen, B. Srinivas, and K. Vijay-Shanker. 1999. New models for improving supertag disambiguation. In Proceedings of the 9th EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chen</author>
</authors>
<title>Towards Efficient Statistical Parsing using Lexicalized Grammatical Information.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Delaware.</institution>
<contexts>
<context position="6753" citStr="Chen, 2001" startWordPosition="1125" endWordPosition="1126">tic information encoded in the supertags. 2 Supertagging and NP Chunking In (Srinivas, 1997) trigram models were used for supertagging, in which Good-Turing discounting technique and Katz’s back-off model were employed. The supertag for a word was determined by the lexical preference of the word, as well as by the contextual preference of the previous two supertags. The model was tested on WSJ section 20 of PTB, and trained on section 0 through 24 except section 20. The accuracy on the test data is 2 . In (Srinivas, 1997), supertagging was used for NP chunking and it achieved an F-score of . (Chen, 2001) reported a similar result with a trigram supertagger. In their approaches, they first supertagged the test data and then uesd heuristic rules to detect NP chunks. But it is hard to say whether it is the use of supertags or the heuristic rules that makes their system achieve the good results. As a first attempt, we use fast TBL (Ngai and Florian, 2001), a TBL program, to repeat Ramshaw and Marcus’ experiment on the standard dataset. Then we use Srinivas’ supertagger (Srinivas, 1997) to supertag both the training and test data. We run the fast TBL for the second round by using supertags instead</context>
<context position="16631" citStr="Chen, 2001" startWordPosition="2858" endWordPosition="2859">ndow plus two head supertags before the current word. For each word , the basic features are , ,and , the two head supertags before the current word. Thus A basic feature is called active for word if and only if the corresponding word/POS-tag/supertag appears at a specified place around . For our SNoW classifiers we use unigram and bigram of basic features as our feature set. A feature defined as a bigram of two basic features is active if and only if the two basic features are both active. The value of a feature of is set to 1 if this feature is active for , or 0 otherwise. 4.4 Related Work (Chen, 2001) implemented an MEMM model for supertagging which is analogous to the POS tagging model of (Ratnaparkhi, 1996). The feature sets used in the MEMM model were similar to ours. In addition, prefix and suffix features were used to handle rare words. Several MEMM supertaggers were implemented based on distinct feature sets. In (Mu˜noz et al., 1999), SNoW was used for text chunking. The IOB tagging model in that paper was similar to our model for supertagging, but there are some differences. They did not decompose the SNoW classifier with respect to POS tags. They used two-level deterministic ( beam</context>
<context position="18552" citStr="Chen, 2001" startWordPosition="3202" endWordPosition="3203">ata. Both training and test data are first tagged by Brill’s POS tagger (Brill, 1995). We use the same pairwise voting algorithm as in (Chen et al., 1999). We run supertagging on the training data and use the supertagging result to generate the mapping table used in pairwise voting. The SNoW supertagger scanning from left to right achieves an accuracy of , and the one scanning from right to left achieves an accuracy of . By combining the results of these two supertaggers with pairwise voting, we achieve an accuracy of , an error reduction of compared to , the best supertagging result to date (Chen, 2001). Table 1 shows the comparison with previous work. Our algorithm, which is coded in Java, takes about 10 minutes to supertag the test data with a P3 1.13GHz processor. However, in (Chen, 2001), the accuracy of was achieved by a Viterbi search program that took about 5 days to supertag the test data. The counterpart of our algorithm in (Chen, 2001) is the beam search on Model 8 with width of 5, which is the same as the beam width in our algorithm. Compared with this program, our algorithm achieves an error reduction of . (Chen et al., 1999) achieved an accuracy of by combination of 5 distinct s</context>
<context position="26556" citStr="Chen, 2001" startWordPosition="4648" endWordPosition="4649">s advantage of rich feature sets, avoids the sparse-data problem, and forces the learning algorithm to focus on the difficult cases. Being aware of the fact that our algorithm may suffer from the label bias problem, we have used two methods to cope with this problem, and achieved desirable results. We have tested our algorithms on both the handcoded tag set used in (Chen et al., 1999) and supertags extracted for Penn Treebank(PTB). On the same dataset as that of (Chen et al., 1999), our new supertagger achieves an accuracy of . Compared with the supertaggers with the same decoding complexity (Chen, 2001), our algorithm achieves an error reduction of . We repeat Ramshaw and Marcus’ Transformation Based NP chunking (Ramshaw and Marcus, 1995) test by substituting supertags for POS tags in the dataset. The use of supertags in NP chunking gives rise to almost absolute increase (from to ) in F-score under Transformation Based Learning(TBL) frame, or an error reduction of . The accuracy of with our individual TBL chunker is close to results of POS-tag-based systems using advanced machine learning algorithms, such as by voted MBL chunkers (Sang, 2002), by SNoW chunker (Mu˜noz et al., 1999). The benef</context>
</contexts>
<marker>Chen, 2001</marker>
<rawString>J. Chen. 2001. Towards Efficient Statistical Parsing using Lexicalized Grammatical Information. Ph.D. thesis, University of Delaware.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In EMNLP</booktitle>
<contexts>
<context position="1569" citStr="Collins, 2002" startWordPosition="246" endWordPosition="247"> supertagging is similar to that of POS tagging, which is linear in the length of the input sentence. In this paper, we will focus on the NP chunking task, and use it as an application of supertagging. (Abney, 1991) proposed a two-phase parsing model which includes chunking and attaching. (Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL). Many machine learning techniques have been successfully applied to chunking tasks, such as Regularized Winnow (Zhang et al., 2001), SVMs (Kudo and Matsumoto, 2001), CRFs (Sha and Pereira, 2003), Maximum Entropy Model (Collins, 2002), Memory Based Learning (Sang, 2002) and SNoW (Mu˜noz et al., 1999). The previous best result on chunking in literature was achieved by Regularized Winnow (Zhang et al., 2001), which took some of the parsing results given by an English Slot Grammar-based parser as input to the chunker. The use of parsing results contributed absolute increase in F-score. However, this approach conflicts with the purpose of chunking. Ideally, a chunker geneates n-best results, and an attacher uses chunking results to construct a parse. The dilemma is that syntactic constraints are useful in the chunking phase, b</context>
<context position="14312" citStr="Collins, 2002" startWordPosition="2451" endWordPosition="2452">ssifier to estimate distribution according to the previous supertags. Following the estimation of distribution function in (Punyakanok and Roth, 2000), we define confidence with a sigmoid 4.2 Label Bias Problem In (Lafferty et al., 2001), it is shown that PMM and other non-generative finite-state models based on next-state classifiers share a weakness which they called the label bias problem: the transitions leaving a given state compete only against each other, rather than against all other transitions in the model. They proposed Conditional Random Fields (CRFs) as solution to this problem. (Collins, 2002) proposed a new algorithm for parameter estimation as an alternate to CRF. The new algorithm was similar to maximum-entropy model except that it skipped the local normalization step. Intuitively, it is the local normalization that makes distribution mass of the transitions leaving a given state incomparable with all other transitions. It is noted in (Mu˜noz et al., 1999) that SNoW’s output provides, in addition to the prediction, a robust confidence level in the prediction, which enables its use in an inference algorithm that combines predictors to produce a coherent inference. In that paper, </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In EMNLP 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Joshi</author>
<author>Y Schabes</author>
</authors>
<title>Tree-adjoining grammars.</title>
<date>1997</date>
<booktitle>Handbook of Formal Languages,</booktitle>
<volume>3</volume>
<pages>69--124</pages>
<editor>In G. Rozenberg and A. Salomaa, editors,</editor>
<publisher>Springer.</publisher>
<marker>Joshi, Schabes, 1997</marker>
<rawString>A. Joshi and Y. Schabes. 1997. Tree-adjoining grammars. In G. Rozenberg and A. Salomaa, editors, Handbook of Formal Languages, volume 3, pages 69 – 124. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Joshi</author>
<author>B Srinivas</author>
</authors>
<title>Disambiguation of super parts of speech (or supertags): Almost parsing.</title>
<date>1994</date>
<booktitle>In COLING’94.</booktitle>
<marker>Joshi, Srinivas, 1994</marker>
<rawString>A. Joshi and B. Srinivas. 1994. Disambiguation of super parts of speech (or supertags): Almost parsing. In COLING’94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>Chunking with support vector machines.</title>
<date>2001</date>
<booktitle>In Proceedings ofNAACL</booktitle>
<contexts>
<context position="1500" citStr="Kudo and Matsumoto, 2001" startWordPosition="234" endWordPosition="237">entence. other hand, as the term ’supertagging’ suggests, the time complexity of supertagging is similar to that of POS tagging, which is linear in the length of the input sentence. In this paper, we will focus on the NP chunking task, and use it as an application of supertagging. (Abney, 1991) proposed a two-phase parsing model which includes chunking and attaching. (Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL). Many machine learning techniques have been successfully applied to chunking tasks, such as Regularized Winnow (Zhang et al., 2001), SVMs (Kudo and Matsumoto, 2001), CRFs (Sha and Pereira, 2003), Maximum Entropy Model (Collins, 2002), Memory Based Learning (Sang, 2002) and SNoW (Mu˜noz et al., 1999). The previous best result on chunking in literature was achieved by Regularized Winnow (Zhang et al., 2001), which took some of the parsing results given by an English Slot Grammar-based parser as input to the chunker. The use of parsing results contributed absolute increase in F-score. However, this approach conflicts with the purpose of chunking. Ideally, a chunker geneates n-best results, and an attacher uses chunking results to construct a parse. The dile</context>
</contexts>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>T. Kudo and Y. Matsumoto. 2001. Chunking with support vector machines. In Proceedings ofNAACL 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for stgmentation and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of ICML</booktitle>
<contexts>
<context position="4523" citStr="Lafferty et al., 2001" startWordPosition="741" endWordPosition="744">twork of Winnow (SNoW) (Roth, 1998). We also propose a novel method of applying SNoW to sequential models in a way analogous to the Projection-base Markov Model (PMM) used in (Punyakanok and Roth, 2000). In contrast to PMM, we construct a SNoW classifier for each POS tag. For each word of an input sentence, its POS tag, instead of the supertag of the previous word, is used to select the corresponding SNoW classifier. This method helps to avoid the sparse data problem and forces SNoW to focus on difficult cases in the context of supertagging task. Since PMM suffers from the label bias problem (Lafferty et al., 2001), we have used two methods to cope with this problem. One method is to skip the local normalization step, and the other is to combine the results of left-to-right scan and right-to-left scan. We test our supertagger on both the hand-coded supertags used in (Chen et al., 1999) as well as the supertags extracted from Penn Treebank(PTB) (Marcus et al., 1994; Xia, 2001). On the dataset used in (Chen et al., 1999), our supertagger achieves an accuracy of . We then apply our supertagger to NP chunking. The purpose of this paper is to find a better way to exploit syntactic information which is useful</context>
<context position="13935" citStr="Lafferty et al., 2001" startWordPosition="2391" endWordPosition="2394">ferent POS tags. Thus by defining a classifier on the POS tag of the current word but not the POS tag of the previous word forces the learning algorithm to focus on difficult cases. Decomposition of the probability estimation can decrease the complexity of the learning algorithm and allows the use of different parameters for different POS tags. For each POS , we construct a SNoW classifier to estimate distribution according to the previous supertags. Following the estimation of distribution function in (Punyakanok and Roth, 2000), we define confidence with a sigmoid 4.2 Label Bias Problem In (Lafferty et al., 2001), it is shown that PMM and other non-generative finite-state models based on next-state classifiers share a weakness which they called the label bias problem: the transitions leaving a given state compete only against each other, rather than against all other transitions in the model. They proposed Conditional Random Fields (CRFs) as solution to this problem. (Collins, 2002) proposed a new algorithm for parameter estimation as an alternate to CRF. The new algorithm was similar to maximum-entropy model except that it skipped the local normalization step. Intuitively, it is the local normalizati</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for stgmentation and labeling sequence data. In Proceedings of ICML 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: the penn treebank.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="4879" citStr="Marcus et al., 1994" startWordPosition="802" endWordPosition="805">us word, is used to select the corresponding SNoW classifier. This method helps to avoid the sparse data problem and forces SNoW to focus on difficult cases in the context of supertagging task. Since PMM suffers from the label bias problem (Lafferty et al., 2001), we have used two methods to cope with this problem. One method is to skip the local normalization step, and the other is to combine the results of left-to-right scan and right-to-left scan. We test our supertagger on both the hand-coded supertags used in (Chen et al., 1999) as well as the supertags extracted from Penn Treebank(PTB) (Marcus et al., 1994; Xia, 2001). On the dataset used in (Chen et al., 1999), our supertagger achieves an accuracy of . We then apply our supertagger to NP chunking. The purpose of this paper is to find a better way to exploit syntactic information which is useful in NP chunking, but not the machine learning part. So we just use TBL, a well-known algorithm in the community of text chunking, as the machine learning tool in our research. Using TBL also allows us to easily evaluate the contribution of supertags with respect to Ramshaw and Marcus’s original work, the de facto baseline of NP chunking. The use of super</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1994. Building a large annotated corpus of english: the penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mu˜noz</author>
<author>V Punyakanok</author>
<author>D Roth</author>
<author>D Zimak</author>
</authors>
<title>A learning approach to shallow parsing.</title>
<date>1999</date>
<booktitle>In Proceedings ofEMNLP-WVLC’99.</booktitle>
<marker>Mu˜noz, Punyakanok, Roth, Zimak, 1999</marker>
<rawString>M. Mu˜noz, V. Punyakanok, D. Roth, and D. Zimak. 1999. A learning approach to shallow parsing. In Proceedings ofEMNLP-WVLC’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ngai</author>
<author>R Florian</author>
</authors>
<title>Transformation-based learning in the fast lane.</title>
<date>2001</date>
<booktitle>In Proceedings of NAACL2001,</booktitle>
<pages>40--47</pages>
<contexts>
<context position="7107" citStr="Ngai and Florian, 2001" startWordPosition="1188" endWordPosition="1192">he previous two supertags. The model was tested on WSJ section 20 of PTB, and trained on section 0 through 24 except section 20. The accuracy on the test data is 2 . In (Srinivas, 1997), supertagging was used for NP chunking and it achieved an F-score of . (Chen, 2001) reported a similar result with a trigram supertagger. In their approaches, they first supertagged the test data and then uesd heuristic rules to detect NP chunks. But it is hard to say whether it is the use of supertags or the heuristic rules that makes their system achieve the good results. As a first attempt, we use fast TBL (Ngai and Florian, 2001), a TBL program, to repeat Ramshaw and Marcus’ experiment on the standard dataset. Then we use Srinivas’ supertagger (Srinivas, 1997) to supertag both the training and test data. We run the fast TBL for the second round by using supertags instead of POS tags in the dataset. With POS tags we achieve an F-score of , but with supertags we only achieve an F-score of . This is not surprising becuase Srinivas’ supertag was only trained with a trigram model. Although supertags are able to encode long distance dependence, supertaggers trained with local information in fact do not take full advantage o</context>
<context position="22233" citStr="Ngai and Florian, 2001" startWordPosition="3867" endWordPosition="3870">ection 20, 22 and 23. auto = auto-extracted tag set. hand = hand coded tag set. data is more vulnerable to the label bias problem. 6 Application to NP Chunking Now we come back to the NP chunking problem. The standard dataset of NP chunking consists of WSJ section 15-18 as train data and section 20 as test data. In our approach, we substitute the supertags for the POS tags in the dataset. The new data look as follows. For B Pnxs O the B Dnx I nine B Dnx I months A NXN I The first field is the word, the second is the supertag of the word, and the last is the IOB tag. We first use the fast TBL (Ngai and Florian, 2001), a Transformation Based Learning algorithm, to repeat Ramshaw and Marcus’ experiment, and then apply the same program to our new dataset. Since section 15-18 and section 20 are in the standard data set of NP chunking, we need to avoid using these sections as training data for our supertagger. We have trained another supertagger that is trained on 776K words in WSJ section 02-14 and 21-24, and it is tuned with 44K words in WSJ section 19. We use this supertagger to supertag section 15-18 and section 20. We train an NP Chunker on section 15-18 with fast TBL, and test it on section 20. There is </context>
</contexts>
<marker>Ngai, Florian, 2001</marker>
<rawString>G. Ngai and R. Florian. 2001. Transformation-based learning in the fast lane. In Proceedings of NAACL2001, pages 40–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Punyakanok</author>
<author>D Roth</author>
</authors>
<title>The use of classifiers in sequential inference.</title>
<date>2000</date>
<booktitle>In NIPS’00.</booktitle>
<contexts>
<context position="4103" citStr="Punyakanok and Roth, 2000" startWordPosition="666" endWordPosition="669">which we call supertags, contain more information than POS tags, and they help to improve the chunking accuracy. Although supertags are able to encode long distance dependence, supertaggers trained with local information in fact do not take full advantage of complex information available in supertags. In order to exploit syntactic dependencies in a larger context, we propose a new model of supertagging based on Sparse Network of Winnow (SNoW) (Roth, 1998). We also propose a novel method of applying SNoW to sequential models in a way analogous to the Projection-base Markov Model (PMM) used in (Punyakanok and Roth, 2000). In contrast to PMM, we construct a SNoW classifier for each POS tag. For each word of an input sentence, its POS tag, instead of the supertag of the previous word, is used to select the corresponding SNoW classifier. This method helps to avoid the sparse data problem and forces SNoW to focus on difficult cases in the context of supertagging task. Since PMM suffers from the label bias problem (Lafferty et al., 2001), we have used two methods to cope with this problem. One method is to skip the local normalization step, and the other is to combine the results of left-to-right scan and right-to</context>
<context position="11129" citStr="Punyakanok and Roth, 2000" startWordPosition="1890" endWordPosition="1893">f them is active in each example. As far as supertagging is concerned, word context forms a very large space. However, for each word in a given sentence, only a small part of features in the space are related to the decision on supertag. Specifically the supertag of a word is determined by the appearances of certain words, POS tags, or supertags in its context. Therefore SNoW is suitable for the supertagging task. Supertagging can be viewed in term of the sequential model, which means that the selection of the supertag for a word is influenced by the decisions made on the previous few words. (Punyakanok and Roth, 2000) proposed three methods of using classifiers in sequential inference, which are HMM, PMM and CSCL. Among these three models, PMM is the most suitable for our task. The basic idea of PMM is as follows. Given an observation sequence , we find the most likely state sequence given by maximizing In this model, the output of SNoW is used to estimate and , where is the current state, is the previous state, and is the current observation. is separated to many subfunctions according to previous state . In practice, is estimated in a wider window of the observed sequence, instead of only. Then the probl</context>
<context position="13848" citStr="Punyakanok and Roth, 2000" startWordPosition="2376" endWordPosition="2379">related to the same POS tag are more difficult to distinguish than supertags related to different POS tags. Thus by defining a classifier on the POS tag of the current word but not the POS tag of the previous word forces the learning algorithm to focus on difficult cases. Decomposition of the probability estimation can decrease the complexity of the learning algorithm and allows the use of different parameters for different POS tags. For each POS , we construct a SNoW classifier to estimate distribution according to the previous supertags. Following the estimation of distribution function in (Punyakanok and Roth, 2000), we define confidence with a sigmoid 4.2 Label Bias Problem In (Lafferty et al., 2001), it is shown that PMM and other non-generative finite-state models based on next-state classifiers share a weakness which they called the label bias problem: the transitions leaving a given state compete only against each other, rather than against all other transitions in the model. They proposed Conditional Random Fields (CRFs) as solution to this problem. (Collins, 2002) proposed a new algorithm for parameter estimation as an alternate to CRF. The new algorithm was similar to maximum-entropy model except</context>
</contexts>
<marker>Punyakanok, Roth, 2000</marker>
<rawString>V. Punyakanok and D. Roth. 2000. The use of classifiers in sequential inference. In NIPS’00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ramshaw</author>
<author>M Marcus</author>
</authors>
<title>Text chunking using transformation-based learning.</title>
<date>1995</date>
<booktitle>In Proceedings of the 3rd WVLC.</booktitle>
<contexts>
<context position="1271" citStr="Ramshaw and Marcus, 1995" startWordPosition="200" endWordPosition="203">ation than POS tags, which makes supertagging a useful pre-parsing tool, so-called, almost parsing (Srinivas and Joshi, 1999). On the 1By the correct supertag we mean the supertag that an LTAG parser would assign to a word in a sentence. other hand, as the term ’supertagging’ suggests, the time complexity of supertagging is similar to that of POS tagging, which is linear in the length of the input sentence. In this paper, we will focus on the NP chunking task, and use it as an application of supertagging. (Abney, 1991) proposed a two-phase parsing model which includes chunking and attaching. (Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL). Many machine learning techniques have been successfully applied to chunking tasks, such as Regularized Winnow (Zhang et al., 2001), SVMs (Kudo and Matsumoto, 2001), CRFs (Sha and Pereira, 2003), Maximum Entropy Model (Collins, 2002), Memory Based Learning (Sang, 2002) and SNoW (Mu˜noz et al., 1999). The previous best result on chunking in literature was achieved by Regularized Winnow (Zhang et al., 2001), which took some of the parsing results given by an English Slot Grammar-based parser as input to the chunker. The use of pars</context>
<context position="5643" citStr="Ramshaw and Marcus, 1995" startWordPosition="935" endWordPosition="938">nking. The purpose of this paper is to find a better way to exploit syntactic information which is useful in NP chunking, but not the machine learning part. So we just use TBL, a well-known algorithm in the community of text chunking, as the machine learning tool in our research. Using TBL also allows us to easily evaluate the contribution of supertags with respect to Ramshaw and Marcus’s original work, the de facto baseline of NP chunking. The use of supertags with TBL can be easily extended to other machine learning algorithms. We repeat Ramshaw and Marcus’ Transformation Based NP chunking (Ramshaw and Marcus, 1995) algorithm by substituting supertags for POS tags in the dataset. The use of supertags gives rise to almost absolute increase (from to ) in Fscore under Transformation Based Learning(TBL) frame. This confirms our claim that using supertagging as a labeling system helps to increase the overall performance of NP Chunking. The supertagger presented in this paper provides an opportunity for advanced machine learning techniques to improve their performance on chunking tasks by exploiting more syntactic information encoded in the supertags. 2 Supertagging and NP Chunking In (Srinivas, 1997) trigram </context>
<context position="26694" citStr="Ramshaw and Marcus, 1995" startWordPosition="4668" endWordPosition="4671">t cases. Being aware of the fact that our algorithm may suffer from the label bias problem, we have used two methods to cope with this problem, and achieved desirable results. We have tested our algorithms on both the handcoded tag set used in (Chen et al., 1999) and supertags extracted for Penn Treebank(PTB). On the same dataset as that of (Chen et al., 1999), our new supertagger achieves an accuracy of . Compared with the supertaggers with the same decoding complexity (Chen, 2001), our algorithm achieves an error reduction of . We repeat Ramshaw and Marcus’ Transformation Based NP chunking (Ramshaw and Marcus, 1995) test by substituting supertags for POS tags in the dataset. The use of supertags in NP chunking gives rise to almost absolute increase (from to ) in F-score under Transformation Based Learning(TBL) frame, or an error reduction of . The accuracy of with our individual TBL chunker is close to results of POS-tag-based systems using advanced machine learning algorithms, such as by voted MBL chunkers (Sang, 2002), by SNoW chunker (Mu˜noz et al., 1999). The benefit of using a supertagger is obvious. The supertagger provides an opportunity for advanced machine learning techniques to improve their pe</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>L. Ramshaw and M. Marcus. 1995. Text chunking using transformation-based learning. In Proceedings of the 3rd WVLC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A maximum entropy part-ofspeech tagger.</title>
<date>1996</date>
<booktitle>In Proceedings ofEMNLP 96.</booktitle>
<contexts>
<context position="16741" citStr="Ratnaparkhi, 1996" startWordPosition="2876" endWordPosition="2877">he two head supertags before the current word. Thus A basic feature is called active for word if and only if the corresponding word/POS-tag/supertag appears at a specified place around . For our SNoW classifiers we use unigram and bigram of basic features as our feature set. A feature defined as a bigram of two basic features is active if and only if the two basic features are both active. The value of a feature of is set to 1 if this feature is active for , or 0 otherwise. 4.4 Related Work (Chen, 2001) implemented an MEMM model for supertagging which is analogous to the POS tagging model of (Ratnaparkhi, 1996). The feature sets used in the MEMM model were similar to ours. In addition, prefix and suffix features were used to handle rare words. Several MEMM supertaggers were implemented based on distinct feature sets. In (Mu˜noz et al., 1999), SNoW was used for text chunking. The IOB tagging model in that paper was similar to our model for supertagging, but there are some differences. They did not decompose the SNoW classifier with respect to POS tags. They used two-level deterministic ( beam-width=1 ) search, in which the second level IOB classifier takes the IOB output of the first classifier as in</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>A. Ratnaparkhi. 1996. A maximum entropy part-ofspeech tagger. In Proceedings ofEMNLP 96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
</authors>
<title>Learning to resolve natural language ambiguities: A unified approach.</title>
<date>1998</date>
<booktitle>In AAAI’98.</booktitle>
<contexts>
<context position="3936" citStr="Roth, 1998" startWordPosition="639" endWordPosition="640">nsformation Based Learning(TBL) frame. The surpertagger described here provides an effective and efficient way to exploit syntactic information. trees, which we call supertags, contain more information than POS tags, and they help to improve the chunking accuracy. Although supertags are able to encode long distance dependence, supertaggers trained with local information in fact do not take full advantage of complex information available in supertags. In order to exploit syntactic dependencies in a larger context, we propose a new model of supertagging based on Sparse Network of Winnow (SNoW) (Roth, 1998). We also propose a novel method of applying SNoW to sequential models in a way analogous to the Projection-base Markov Model (PMM) used in (Punyakanok and Roth, 2000). In contrast to PMM, we construct a SNoW classifier for each POS tag. For each word of an input sentence, its POS tag, instead of the supertag of the previous word, is used to select the corresponding SNoW classifier. This method helps to avoid the sparse data problem and forces SNoW to focus on difficult cases in the context of supertagging task. Since PMM suffers from the label bias problem (Lafferty et al., 2001), we have use</context>
<context position="9802" citStr="Roth, 1998" startWordPosition="1651" endWordPosition="1652">y of . The mixed trigram model achieves better results on supertagging because it can capture both local and long distance dependencies to some extent. However, we think that a better way to find useful context is to use machine learning techniques but not define the rules manually. One approach is to switch to models like PMM, which can not only take advantage of generative models with the Viterbi algorithm, but also utilize the information in a larger contexts through flexible feature sets. This is the basic idea guiding the design of our supertagger. 3 SNoW Sparse Network of Winnow (SNoW) (Roth, 1998) is a learning architecture that is specially tailored for learning in the presence of a very large number of features where the decision for a single sample depends on only a small number of features. Furthermore, SNoW can also be used as a general purpose multi-class classifier. It is noted in (Mu˜noz et al., 1999) that one of the important properites of the sparse architecture of SNoW is that the complexity of processing an example depends only on the number of features active in it, , and is independent of the total number of features, , observed over the life time of the system and this i</context>
</contexts>
<marker>Roth, 1998</marker>
<rawString>D. Roth. 1998. Learning to resolve natural language ambiguities: A unified approach. In AAAI’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
</authors>
<title>Memory-based shallow parsing.</title>
<date>2002</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>2--559</pages>
<contexts>
<context position="1605" citStr="Sang, 2002" startWordPosition="251" endWordPosition="252"> tagging, which is linear in the length of the input sentence. In this paper, we will focus on the NP chunking task, and use it as an application of supertagging. (Abney, 1991) proposed a two-phase parsing model which includes chunking and attaching. (Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL). Many machine learning techniques have been successfully applied to chunking tasks, such as Regularized Winnow (Zhang et al., 2001), SVMs (Kudo and Matsumoto, 2001), CRFs (Sha and Pereira, 2003), Maximum Entropy Model (Collins, 2002), Memory Based Learning (Sang, 2002) and SNoW (Mu˜noz et al., 1999). The previous best result on chunking in literature was achieved by Regularized Winnow (Zhang et al., 2001), which took some of the parsing results given by an English Slot Grammar-based parser as input to the chunker. The use of parsing results contributed absolute increase in F-score. However, this approach conflicts with the purpose of chunking. Ideally, a chunker geneates n-best results, and an attacher uses chunking results to construct a parse. The dilemma is that syntactic constraints are useful in the chunking phase, but they are unavailable until the at</context>
<context position="27106" citStr="Sang, 2002" startWordPosition="4738" endWordPosition="4739">e supertaggers with the same decoding complexity (Chen, 2001), our algorithm achieves an error reduction of . We repeat Ramshaw and Marcus’ Transformation Based NP chunking (Ramshaw and Marcus, 1995) test by substituting supertags for POS tags in the dataset. The use of supertags in NP chunking gives rise to almost absolute increase (from to ) in F-score under Transformation Based Learning(TBL) frame, or an error reduction of . The accuracy of with our individual TBL chunker is close to results of POS-tag-based systems using advanced machine learning algorithms, such as by voted MBL chunkers (Sang, 2002), by SNoW chunker (Mu˜noz et al., 1999). The benefit of using a supertagger is obvious. The supertagger provides an opportunity for advanced machine learning techniques to improve their performance on chunking tasks by exploiting more syntactic information encoded in the supertags. To sum up, the supertagging algorithm presented here provides an effective and efficient way to employ syntactic information. Acknowledgments We thank Vasin Punyakanok for help on the use of SNoW in sequential inference, John Chen for help on dataset and evaluation methods and comments on the draft. We also thank Sr</context>
</contexts>
<marker>Sang, 2002</marker>
<rawString>Erik F. Tjong Kim Sang. 2002. Memory-based shallow parsing. Journal of Machine Learning Research, 2:559–594.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sha</author>
<author>F Pereira</author>
</authors>
<title>Shallow parsing with conditional random fields.</title>
<date>2003</date>
<booktitle>In Proceedings ofNAACL</booktitle>
<contexts>
<context position="1530" citStr="Sha and Pereira, 2003" startWordPosition="239" endWordPosition="242">’supertagging’ suggests, the time complexity of supertagging is similar to that of POS tagging, which is linear in the length of the input sentence. In this paper, we will focus on the NP chunking task, and use it as an application of supertagging. (Abney, 1991) proposed a two-phase parsing model which includes chunking and attaching. (Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL). Many machine learning techniques have been successfully applied to chunking tasks, such as Regularized Winnow (Zhang et al., 2001), SVMs (Kudo and Matsumoto, 2001), CRFs (Sha and Pereira, 2003), Maximum Entropy Model (Collins, 2002), Memory Based Learning (Sang, 2002) and SNoW (Mu˜noz et al., 1999). The previous best result on chunking in literature was achieved by Regularized Winnow (Zhang et al., 2001), which took some of the parsing results given by an English Slot Grammar-based parser as input to the chunker. The use of parsing results contributed absolute increase in F-score. However, this approach conflicts with the purpose of chunking. Ideally, a chunker geneates n-best results, and an attacher uses chunking results to construct a parse. The dilemma is that syntactic constrai</context>
</contexts>
<marker>Sha, Pereira, 2003</marker>
<rawString>F. Sha and F. Pereira. 2003. Shallow parsing with conditional random fields. In Proceedings ofNAACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Srinivas</author>
<author>A Joshi</author>
</authors>
<title>Supertagging: An approach to almost parsing.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="771" citStr="Srinivas and Joshi, 1999" startWordPosition="110" endWordPosition="113"> of Pennsylvania Philadelphia, PA 19104, USA libin,joshi @linc.cis.upenn.edu Abstract 1 Introduction In Lexicalized Tree-Adjoining Grammar (LTAG) (Joshi and Schabes, 1997; XTAG-Group, 2001), each word in a sentence is associated with an elementary tree, or a supertag (Joshi and Srinivas, 1994). Supertagging is the process of assigning the correct supertag to each word of an input sentence. The following two facts make supertagging attractive. Firstly supertags encode much more syntactical information than POS tags, which makes supertagging a useful pre-parsing tool, so-called, almost parsing (Srinivas and Joshi, 1999). On the 1By the correct supertag we mean the supertag that an LTAG parser would assign to a word in a sentence. other hand, as the term ’supertagging’ suggests, the time complexity of supertagging is similar to that of POS tagging, which is linear in the length of the input sentence. In this paper, we will focus on the NP chunking task, and use it as an application of supertagging. (Abney, 1991) proposed a two-phase parsing model which includes chunking and attaching. (Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL). Many machine learning techniques h</context>
</contexts>
<marker>Srinivas, Joshi, 1999</marker>
<rawString>B. Srinivas and A. Joshi. 1999. Supertagging: An approach to almost parsing. Computational Linguistics, 25(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Srinivas</author>
</authors>
<title>Performance evaluation of supertagging for partial parsing.</title>
<date>1997</date>
<booktitle>In IWPT</booktitle>
<contexts>
<context position="6234" citStr="Srinivas, 1997" startWordPosition="1031" endWordPosition="1032">amshaw and Marcus, 1995) algorithm by substituting supertags for POS tags in the dataset. The use of supertags gives rise to almost absolute increase (from to ) in Fscore under Transformation Based Learning(TBL) frame. This confirms our claim that using supertagging as a labeling system helps to increase the overall performance of NP Chunking. The supertagger presented in this paper provides an opportunity for advanced machine learning techniques to improve their performance on chunking tasks by exploiting more syntactic information encoded in the supertags. 2 Supertagging and NP Chunking In (Srinivas, 1997) trigram models were used for supertagging, in which Good-Turing discounting technique and Katz’s back-off model were employed. The supertag for a word was determined by the lexical preference of the word, as well as by the contextual preference of the previous two supertags. The model was tested on WSJ section 20 of PTB, and trained on section 0 through 24 except section 20. The accuracy on the test data is 2 . In (Srinivas, 1997), supertagging was used for NP chunking and it achieved an F-score of . (Chen, 2001) reported a similar result with a trigram supertagger. In their approaches, they </context>
<context position="8292" citStr="Srinivas, 1997" startWordPosition="1392" endWordPosition="1394">t do not take full advantage of their strong capability. So we must use long distance dependencies to train supertaggers to take full advantage of the information in supertags. 2This number is based on footnote 1 of (Chen et al., 1999). A few supertags were grouped into equivalence classes for evaluation The trigram model often fails in capturing the cooccurrence dependence between a head word and its dependents. Consider the phrase ”will join the board as a nonexecutive director”. The occurrence of join has influence on the lexical selection of as. But join is outside the window of trigram. (Srinivas, 1997) proposed a head trigram model in which the lexical selection of a word depended on the supertags of the previous two head words , instead of the supertags of the two words immediately leading the word of interest. But the performance of this model was worse than the traditional trigram model because it discarded local information. (Chen et al., 1999) combined the traditional trigram model and head trigram model in their trigram mixed model. In their model, context for the current word was determined by the supertag of the previous word and context for the previous word according to 6 manually</context>
<context position="19490" citStr="Srinivas, 1997" startWordPosition="3362" endWordPosition="3363"> algorithm in (Chen, 2001) is the beam search on Model 8 with width of 5, which is the same as the beam width in our algorithm. Compared with this program, our algorithm achieves an error reduction of . (Chen et al., 1999) achieved an accuracy of by combination of 5 distinct supertaggers. However, our result is achieved by combining outputs of two homogeneous supertaggers, which only differ in scan direction. Our next experiment is with the set of supertags abstracted from PTB with Fei Xia’s LexTract (Xia, 2001). Xia extracted an LTAG-style grammar from PTB, and repeated Srinivas’ experiment (Srinivas, 1997) on her supertag set. There are 2920 elemenmodel acc Srinivas(97) trigram 91.37 Chen(99) trigram mix 91.79 Chen(99) voting 92.19 Chen(01) width=5 91.83 Chen(01) Viterbi 92.25 SNoW left-to-right 92.02 SNoW right-to-left 91.43 SNoW 92.41 Table 1: Comparison with previous work. Training data is WSJ section 00 thorough 24 except section 20 of PTB. Test data is WSJ section 20. Size of tag set is 479. acc = percentage of accuracy. The number of Srinivas(97) is based on footnote 1 of (Chen et al., 1999). The number of Chen(01) width=5 is the result of a beam search on Model 8 with the width of 5. mod</context>
</contexts>
<marker>Srinivas, 1997</marker>
<rawString>B. Srinivas. 1997. Performance evaluation of supertagging for partial parsing. In IWPT 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H van Halteren</author>
<author>J Zavrel</author>
<author>W Daelmans</author>
</authors>
<title>Improving data driven wordclass tagging by system combination.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL 98.</booktitle>
<marker>van Halteren, Zavrel, Daelmans, 1998</marker>
<rawString>H. van Halteren, J. Zavrel, and W. Daelmans. 1998. Improving data driven wordclass tagging by system combination. In Proceedings of COLING-ACL 98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Xia</author>
</authors>
<title>Automatic Grammar Generation From Two Different Perspectives.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="4891" citStr="Xia, 2001" startWordPosition="806" endWordPosition="807">elect the corresponding SNoW classifier. This method helps to avoid the sparse data problem and forces SNoW to focus on difficult cases in the context of supertagging task. Since PMM suffers from the label bias problem (Lafferty et al., 2001), we have used two methods to cope with this problem. One method is to skip the local normalization step, and the other is to combine the results of left-to-right scan and right-to-left scan. We test our supertagger on both the hand-coded supertags used in (Chen et al., 1999) as well as the supertags extracted from Penn Treebank(PTB) (Marcus et al., 1994; Xia, 2001). On the dataset used in (Chen et al., 1999), our supertagger achieves an accuracy of . We then apply our supertagger to NP chunking. The purpose of this paper is to find a better way to exploit syntactic information which is useful in NP chunking, but not the machine learning part. So we just use TBL, a well-known algorithm in the community of text chunking, as the machine learning tool in our research. Using TBL also allows us to easily evaluate the contribution of supertags with respect to Ramshaw and Marcus’s original work, the de facto baseline of NP chunking. The use of supertags with TB</context>
<context position="19392" citStr="Xia, 2001" startWordPosition="3349" endWordPosition="3350">terbi search program that took about 5 days to supertag the test data. The counterpart of our algorithm in (Chen, 2001) is the beam search on Model 8 with width of 5, which is the same as the beam width in our algorithm. Compared with this program, our algorithm achieves an error reduction of . (Chen et al., 1999) achieved an accuracy of by combination of 5 distinct supertaggers. However, our result is achieved by combining outputs of two homogeneous supertaggers, which only differ in scan direction. Our next experiment is with the set of supertags abstracted from PTB with Fei Xia’s LexTract (Xia, 2001). Xia extracted an LTAG-style grammar from PTB, and repeated Srinivas’ experiment (Srinivas, 1997) on her supertag set. There are 2920 elemenmodel acc Srinivas(97) trigram 91.37 Chen(99) trigram mix 91.79 Chen(99) voting 92.19 Chen(01) width=5 91.83 Chen(01) Viterbi 92.25 SNoW left-to-right 92.02 SNoW right-to-left 91.43 SNoW 92.41 Table 1: Comparison with previous work. Training data is WSJ section 00 thorough 24 except section 20 of PTB. Test data is WSJ section 20. Size of tag set is 479. acc = percentage of accuracy. The number of Srinivas(97) is based on footnote 1 of (Chen et al., 1999).</context>
</contexts>
<marker>Xia, 2001</marker>
<rawString>F. Xia. 2001. Automatic Grammar Generation From Two Different Perspectives. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>XTAG-Group</author>
</authors>
<title>A lexicalized tree adjoining grammar for english.</title>
<date>2001</date>
<tech>Technical Report 01-03,</tech>
<institution>IRCS, Univ. of Pennsylvania.</institution>
<marker>XTAG-Group, 2001</marker>
<rawString>XTAG-Group. 2001. A lexicalized tree adjoining grammar for english. Technical Report 01-03, IRCS, Univ. of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Zhang</author>
<author>F Damerau</author>
<author>D Johnson</author>
</authors>
<title>Text chunking using regularized winnow.</title>
<date>2001</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="1467" citStr="Zhang et al., 2001" startWordPosition="229" endWordPosition="232">uld assign to a word in a sentence. other hand, as the term ’supertagging’ suggests, the time complexity of supertagging is similar to that of POS tagging, which is linear in the length of the input sentence. In this paper, we will focus on the NP chunking task, and use it as an application of supertagging. (Abney, 1991) proposed a two-phase parsing model which includes chunking and attaching. (Ramshaw and Marcus, 1995) approached chucking by using Transformation Based Learning(TBL). Many machine learning techniques have been successfully applied to chunking tasks, such as Regularized Winnow (Zhang et al., 2001), SVMs (Kudo and Matsumoto, 2001), CRFs (Sha and Pereira, 2003), Maximum Entropy Model (Collins, 2002), Memory Based Learning (Sang, 2002) and SNoW (Mu˜noz et al., 1999). The previous best result on chunking in literature was achieved by Regularized Winnow (Zhang et al., 2001), which took some of the parsing results given by an English Slot Grammar-based parser as input to the chunker. The use of parsing results contributed absolute increase in F-score. However, this approach conflicts with the purpose of chunking. Ideally, a chunker geneates n-best results, and an attacher uses chunking resul</context>
</contexts>
<marker>Zhang, Damerau, Johnson, 2001</marker>
<rawString>T. Zhang, F. Damerau, and D. Johnson. 2001. Text chunking using regularized winnow. In Proceedings ofACL 2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>