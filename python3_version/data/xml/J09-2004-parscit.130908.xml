<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999449">
A Minimal Recursion Semantic Analysis
of Locatives
</title>
<author confidence="0.998033">
Fredrik Jørgensen*
</author>
<affiliation confidence="0.995655">
University of Oslo
</affiliation>
<author confidence="0.992913">
Jan Tore Lønning**
</author>
<affiliation confidence="0.995037">
University of Oslo
</affiliation>
<bodyText confidence="0.996297">
The article describes a pilot implementation of a grammar containing different types of locative
PPs. In particular, we investigate the distinction between static and directional locatives, and
between different types of directional locatives. Locatives may act as modifiers as well as referring
expressions depending on the syntactic context. We handle this with a single lexical entry.
The implementation is of Norwegian locatives, but English locatives are both discussed and
compared to Norwegian locatives. The semantic analysis is based on a proposal by Markus Kracht
(2002), and we show how this analysis can be incorporated into Minimal Recursion Semantics
(MRS) (Copestake et al. 2005). We discuss how the resulting system may be applied in a transfer-
based machine translation system, and how we can map from a shallow MRS representation to
a deeper semantic representation.
</bodyText>
<sectionHeader confidence="0.983394" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.951274333333333">
Locative prepositional phrases (PPs) pose several puzzles, both to syntax and semantics.
First, locatives may be either static (Example (1)), directional (Example (2)), or ambigu-
ous (Example (3)):
</bodyText>
<listItem confidence="0.998233333333333">
(1) Kim slept in Paris.
(2) Kim is driving into Paris.
(3) The mouse ran under the table.
</listItem>
<bodyText confidence="0.973271666666667">
As we see, the PP under the table may locate the whole event (Example (4)), it may
express the goal of motion (Example (5)), or it may express (parts of) the path of motion
(Example (6)):
</bodyText>
<listItem confidence="0.941813">
(4) The mouse ran around under the table.
(5) The mouse ran under the table and stayed there.
</listItem>
<footnote confidence="0.7544425">
* ILN, PO Box 1102 Blindern, 0317 Oslo, Norway. E-mail: fredrik.jorgensen@iln.uio.no.
** IFI, PO Box 1080 Blindern, 0316 Oslo, Norway. E-mail: jtl@ifi.uio.no.
Submission received: 29 June 2006; revised submission received: 16 November 2007; accepted for publication:
26 January 2008.
</footnote>
<note confidence="0.832856666666667">
© 2008 Association for Computational Linguistics
Computational Linguistics Volume 35, Number 2
(6) The mouse ran under the table into a hole in the wall.hole in the wall.
</note>
<bodyText confidence="0.6974775">
Second, we may use a combination of prepositions in order to express, for example,
the source of motion, as seen in Example (7):
</bodyText>
<listItem confidence="0.604353">
(7) A mouse appeared from under the table.
</listItem>
<bodyText confidence="0.999169666666667">
Here, under the table seems to refer to a location, and it is from that expresses the
directional component of the locative.
Third, we may see differences in the local interpretation of a PP and the same PP
in a wider context. One popular example is the verb put, where both a static and a
directional (goal) PP complement is accepted, and where both types of PP complements
are interpreted as the goal of the motion.
</bodyText>
<listItem confidence="0.998421857142857">
(8) Kim put the book on/onto the table.
Fourth, a preposition may not always be followed by an argument; consider down
in Example (9). When it occurs without an NP complement it may be followed by
another PP as in Example (10). How can the semantics of this construction be described
compositionally?
(9) A child ran down.
(10) A child ran down under the bridge.
</listItem>
<bodyText confidence="0.9536546">
Another example of this phenomenon is how intransitive locatives disambiguate
between different readings in Norwegian. The locatives inne and inn are static and direc-
tional (goal), in relation to a location which is inside in some (contextually determined)
sense. When one of these locatives is succeeded by a locative PP, the second PP is given
the same interpretation with respect to motion, as shown in Examples (11) and (12).
</bodyText>
<listItem confidence="0.9255995">
(11) Musa løp innestatic istatic hullet.
Mouse.DEF ran insidestatic instatic hole.DEF
‘The mouse ran insidestatic the hole.’
(12) Musa løp inngoal igoal hullet.
Mouse.DEF ran insidegoal ingoal hole.DEF
‘The mouse ran into the hole.’
</listItem>
<bodyText confidence="0.643381">
Furthermore, new readings are available when a PP is preceded by inn, as seen in
Examples (13) and (14).
</bodyText>
<listItem confidence="0.9618455">
(13) Helikopteret fløy overstatic or path byen.
Helicopter.DEF flew overstatic or path city.DEF.
‘The helicopter flew overstatic or path the city.’
(14) Helikopteret fløy inn overgoal byen.
Helicopter.DEF flew in overgoal city.DEF.
‘The helicopter flew [to above]/[in over] the city.’
</listItem>
<page confidence="0.979715">
230
</page>
<note confidence="0.472065">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
</note>
<bodyText confidence="0.957126294117647">
Finally, we see a variation in how different languages express locatives. Some
languages have rich case systems, whereas others use adpositions to express locatives.
The focus of this article is locative prepositions in Norwegian and English. We will not
consider locative case systems here, but we will see differences in which locatives are
lexicalized as prepositions, as shown in Example (15), where the Norwegian locative
derfra is a lexicalization of the corresponding English complex PP from there.
(15) Musa kom derfra.
Mouse.DEF came there-from.
‘The mouse came from (over) there.’
Our goal in this article consists of three parts. First, we take recent developments
within formal semantic approaches to locatives (in particular Kracht 2002) and show
how these can be implemented in Minimal Recursion Semantics (MRS; Copestake et al.
2005), a flat and computationally tractable semantic meta-language for first-order logic.
Second, we determine the degree to which the insights from this particular approach
to locatives can be implemented in a non-transformational, unification-based computa-
tional grammar based on HPSG (Pollard and Sag 1994). And third, we investigate what
consequences the current analysis has for syntax and the syntax–semantics interface.
Our implementation is of a fragment of Norwegian. Norwegian is in many respects
similar to English, and where they are similar we will use examples from English. There
are also some interesting differences, and we will use them to illustrate how the new
representations can be exploited in an experimental semantic transfer-based machine
translation system, like the LOGON system (Oepen et al. 2004), which uses transfer
representations based on MRS.
The rest of the article is organized as follows. In Section 2, we consider various
approaches to locatives, before we describe the formal semantic approach proposed
by Kracht (2002) and introduce MRS in Section 3. In Section 4, we start to present our
own solution to how these two approaches can be combined. We proceed to classify
Norwegian locative adverbs and prepositions and show how various constructions can
be handled in Section 5. In Section 6, we describe the main results from our imple-
mentation of a grammar producing the intended Kracht-style MRS representations. In
Section 7, we argue that the current analysis is useful for a range of NLP applications,
and sketch how it can be applied in a machine translation system. Finally we compare
our approach to other computational approaches in Section 8, discuss evaluation of the
analysis in Section 9, and conclude in Section 10.
</bodyText>
<sectionHeader confidence="0.879436" genericHeader="categories and subject descriptors">
2. Syntax and Semantics of Locatives
</sectionHeader>
<bodyText confidence="0.998932333333333">
In this section, we consider relevant linguistic literature on locatives which will serve as
a background for our proposal. We will return to a comparison between our approach
and other computational linguistic approaches in Section 8.
</bodyText>
<subsectionHeader confidence="0.83515">
2.1 Relevant Issues
</subsectionHeader>
<footnote confidence="0.54758">
There is a growing literature on language and space, but not all of it is relevant for
our purposes. We are interested in how locatives should be handled in a computational
grammar with a compositional semantic component, and in particular how static and
</footnote>
<page confidence="0.988936">
231
</page>
<note confidence="0.815878">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.6054415">
directional locatives are treated. There are basically three types of questions relevant to
our article, for which we will review relevant linguistic literature:
</bodyText>
<listItem confidence="0.38617625">
Q1. Formal Semantics: What do locatives denote?
Are locatives referential (denoting a location) or modificational (denoting a
property of events and entities)?
Q2. Syntax: Are locative PPs complements or adjuncts?
</listItem>
<bodyText confidence="0.998267103448276">
If we want our grammar to have compositional semantics, this question is
closely related to the previous one. Analyzing locative PPs as adjuncts is
hard to combine with the referential interpretation of locatives, as this
either requires that the modified phrase also denotes a location, or that
some additional machinery is introduced to map the location to a property.
Q3. How is the distinction between static and directional locatives handled?
Static and directional locatives differ both in syntactic distribution and
truth conditions, and as we have observed, occurrences of locatives may
be ambiguous between the two.
A prominent question in the literature on locative prepositions is the geometric
structure of particular prepositions: for example, what geometric relationship between
the ball and the cup has to be realized for an expression like the ball is in the cup to be
true (e.g., Herskovits 1986)? As interesting as these questions are, we think they belong
to the lexicon and the lexical semantic domain and fall outside the scope of this article.
There is also interesting work which relates the meaning of individual prepositions to var-
ious types of psychological studies; in particular, studies of under which conditions the
various prepositions are used (see, e.g., many of the references in Bloom et al. [1996] and
in van der Zee and Slack [2003]). But again this plays a complementary role to our work.
One particular question in the lexical semantics of prepositions is the distinction
between what Zwarts and Winter (2000), following Herskovits (1986), call projective
and non-projective prepositions. A non-projective preposition, like outside, requires
only spatial knowledge of the location of the two objects, while a projective preposition,
like behind, requires some further information about directions from the reference object.
Levinson (1996) makes a further distinction between three types of reference frames
called (i) intrinsic, where behind the house means on the other side of the house than
what would be classified as the front side of the house, (ii) extrinsic, where behind the house
is on the opposite side of the house than the speaker, and (iii) absolute, which applies
to expressions like north of the house. We also think that these distinctions belong to the
lexical semantic domain.
</bodyText>
<subsectionHeader confidence="0.997421">
2.2 Hjelmslev’s Theory of Cases
</subsectionHeader>
<bodyText confidence="0.999815">
One of the earliest contributions to the study of locatives is Hjelmslev’s (1935) theory of
cases. Hjelmslev views case as a relation between two objects (Q1 above), which may
be nominal or verbal (Q1/Q2). Cases may be either complements or modifiers (Q2),
and are expressed through adpositions or inflections. These observations are based on
data from a wide range of languages, including languages with locative case systems,
such as Hungarian and the Caucasian language Tabasaran. Hjelmslev proposes a three-
dimensional case system (Q3), where the dimensions express directionality, coherence,
and subjectivity. The directional dimension consists of approach, neutrality, and sep-
</bodyText>
<page confidence="0.952426">
232
</page>
<note confidence="0.470224">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
</note>
<bodyText confidence="0.999102153846154">
aration. The coherence dimension has two interpretations, inherence (enclosure) and
adherence (contact). And finally, the subjectivity dimension describes the dependence
relation between the point of view and the location, being either subjective, objective,
or neutral. For example, whereas behind or left of is dependent on the point of view,
under is not, according to Hjelmslev.
Hjelmslev’s theory of cases relates to all three questions, and it has formed the basis
of much of the later work done on locatives. Even though we will focus on languages
where locatives are expressed by prepositions in adpositions, and ignore languages
where locatives are expressed through inflectional case, it is a point for us to base our
approach on formalisms that also extend to languages where locatives are expressed by
case. When it comes to the dimensions, directionality is particularly important for the
questions we raised in the introduction, while the latter two dimensions relate to lexical
semantics, which we will not pursue here.
</bodyText>
<subsectionHeader confidence="0.996923">
2.3 Bierwisch’s Grammar of Locatives
</subsectionHeader>
<bodyText confidence="0.999965">
Bierwisch (1988) gives a detailed account of both syntactic and semantic aspects of loca-
tive prepositions in German, and is particularly interested in the relationship between
the denotation of locatives (Q1) and the consequences for the syntactic treatment of
locatives (Q2). Bierwisch notes that locative PPs serve as predicates (Example (16)),
arguments (Example (17)), and modificational adjuncts (Examples (18)–(19)) (examples
taken from [1988, page 5]; our translations).
</bodyText>
<listItem confidence="0.9928175">
(16) Er ist in der Schule.
He is in school.
(17) Der Brief liegt auf dem Tisch.
The letter is lying on the table.
(18) Ich kaufe das Buch in Berlin.
I will buy the book in Berlin.
(19) eine Br¨ucke ¨uber die Moldau
a bridge over Moldau
</listItem>
<bodyText confidence="0.9980546">
Bierwisch notes that even though predication, complementation, and modification
are clearly distinct syntactic relations, distinguishing between locatives as adverbial or
optional complements is in many cases arbitrary (Q2). Bierwisch argues that direction-
ality is a syntactic feature, ±DIR, on locatives. But as we shall see, a more complex in-
ventory of syntactic features corresponding to different types of directionality is needed.
Bierwisch (1988) discusses two different positions with respect to the denotations
of locative PPs (Q1): The referential interpretation, where locative PPs denote regions,
just like NPs denote things, and the modificational interpretation, where the locative
PPs denote properties of being located at a certain place:
The referential interpretation seems to be appropriate for PPs in argument position,
as e.g., Hans liegt im Bett can plausibly be said to express a relation between Hans and
a place denoted by im Bett. It is difficult to see, however, how on this account PPs
can serve as modifiers or predicatives — unless a place is construed as a property,
but that would violate the gist of the referential interpretation. The modificational
interpretation, on the other hand, concerns itself with PPs as adjuncts, but seems to be
</bodyText>
<page confidence="0.996408">
233
</page>
<note confidence="0.795269">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.94014">
in trouble with PPs in argument position. From this, one might be tempted to draw the
conclusion that both interpretations are partially right and that they both are needed.
(Bierwisch 1988, page 8)
We will not discuss predicatives in this article, but refer to Kracht (2002) for treatment
of adnominal locatives as a property of individuals. The duality with respect to the
interpretation of locatives as referential or modificational is central to our article, and we
will show, building on Kracht, how this can be handled in a computational grammar.
</bodyText>
<subsectionHeader confidence="0.996625">
2.4 Jackendoff’s Conceptual Semantics
</subsectionHeader>
<bodyText confidence="0.999897642857143">
Ray Jackendoff’s (1983, 1990) conceptual semantics is a decompositional theory of
meaning, heavily influenced by X-bar theory. Conceptual semantics organizes a reper-
toire of major conceptual categories, the semantic parts of speech, into function–
argument structures. Lexical entries are encoded as Lexical Conceptual Structures
(LCSs), as exemplified by the entry for the preposition in in (Example (20)), where
we find the lexeme, the part-of-speech category, the selectional restriction, and the
semantics on four separate lines.
Particularly interesting in our context is the semantic analysis of static and direc-
tional locatives (Q1/Q3), and how they combine with verbs (Q2). The LCSs of static
locatives are claimed to have one layer, a Place function (Example (20)), as opposed
to the LCS of directional locatives, which have two layers, a Path function as the
outer function, and a Place function as the inner function (Example (21)). According to
Jackendoff, there are five different Path functions: TO, FROM, TOWARD, AWAY-FROM,
and VIA. These map from a Place to a Path.
</bodyText>
<figure confidence="0.6971465">
(20) �in 1
� �P
� �NPj
[Place IN ( [Thing ]j) ]
(21) �into
� �P
� �NPj
[Path TO ( [Place IN ( [Thing ]j) ] ) ]
</figure>
<bodyText confidence="0.999789875">
Furthermore, Jackendoff (1990, page 45) treats directional locatives as arguments to
motion verbs, such that, for example, run subcategorizes for an optional directional
locative argument (Q2), where the optionality is represented with angle brackets, note
the LCS for run given in Example (22). In the analysis of Example (23) the optional PP
argument of run is coindexed with the PP into the room. Through co-indexing (j) this
results in the conceptual structure in Example (24), where the path denoted by the PP
enters into the function GO(subject entity, path) and thereby expresses the traversing of
the path. By convention, the entity indexed i is taken to be the subject position.
</bodyText>
<equation confidence="0.801388">
(22) �run
� �V
� �(PPj�
[Event GO ( [Thing ]i,[Path ]j) ]
1
</equation>
<page confidence="0.904668">
1
234
</page>
<bodyText confidence="0.344788">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
</bodyText>
<listItem confidence="0.8680835">
(23) [S [NP John [VP ran [PP into [NP the room ]]]]
(24) [Event GO ( [Thing JOHN ], [Path TO ( [Place IN ( [Thing ROOM ]) ]) ]) ]
</listItem>
<bodyText confidence="0.999806">
Jackendoff’s description clearly shows that matters are more complex than the usual
static/directional distinction. First, he introduces a finer classification between the dif-
ferent directionals. Second, he proposes there be a common core, the place, to different
prepositions (e.g., in and into) and to the different uses of a preposition (e.g., the place-
use and the TO- and VIA-uses of under). Both observations will be part of our analysis.
But there are several problems with Jackendoff’s approach. First, one will have to
specify for any verb which can be modified by a directional PP, that the modifier is an
optional part of the verb’s semantics (or LCS). Because one and the same verb (e.g.,
run) can be combined with several directional PPs at the same time, as in Example (6),
one would need a way to combine the semantics of the different locative PPs. Whether
this should be done by merging the directionals into a single path, or by accepting
multiple PP complements, is unclear in Jackendoff’s theory. We believe incorporating
the optional modifier’s semantics into the verb’s lexical entry leads to a very elaborate
and inflexible semantics, and would prefer to avoid this, if possible.
The second, and more serious, weakness is that static and directional locatives
are treated differently in the syntax. Static locatives are regarded as adjuncts, whereas
directional locatives are regarded as complements of motion verbs. Unless there is
provided syntactic evidence for this distinction, this violates the autonomy of syntax,
as the semantics of the construction (whether it is the event or its participants being
located) governs the syntactic analysis (whether the construction is analyzed as an
adjunct or a complement). There are of course different syntactic restrictions on what
kind of verbs static and directional PPs can modify, but this applies to many modifying
PPs, and is not in itself sufficient to warrant different syntactic analyses. We believe
that a uniform treatment of locatives, giving the same syntactic analysis independent of
directionality, would provide a more sound and consistent analysis.
</bodyText>
<subsectionHeader confidence="0.989814">
2.5 Fong’s Directionals as Diphasic Events
</subsectionHeader>
<bodyText confidence="0.999829785714286">
Fong (1997) analyzes directional locatives. She focuses on the locative cases of Finnish,
but includes comparisons to other languages, including English. Her main focus of
interest is on how directional locative case in Finnish and directional prepositions in
English can be used when there is no movement involved. In Finnish one uses expres-
sions which literally when translated into English would become forgot my wallet into my
car, and in English we have formulations like a bridge from Buda to Pest. Whereas other
approaches take the spatial use as basic, and consider the more abstract uses as derived,
Fong takes the opposite stand. The locative case is not in itself about paths. It has a
more abstract meaning, and can be used when there is an underlying ordered domain,
together with a proposition changing truth value, either from false to true or from true
to false along the ordering. This abstract structure can be mapped to a more concrete
structure, including space in English, and space or time in Finnish. Thus in Example (25)
there is an ordering in space such that Example (26) is false at the beginning of this
ordering, and true towards the end of the ordering.
</bodyText>
<listItem confidence="0.8967875">
(25) He went into the room.
(26) He is in the room.
</listItem>
<page confidence="0.993585">
235
</page>
<note confidence="0.293903">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.9978646">
Kracht (2002) compares his approach to Fong’s. One problem is that Fong’s ap-
proach does not extend to the VIA-reading (in Jackendoff’s terminology) of sentences
like Example (3). From our point of view, it is also a point that she does not describe a
compositional analysis. Also our focus in this article is strictly on the spatial readings of
the locatives.
</bodyText>
<subsectionHeader confidence="0.998146">
2.6 Zwarts’s Vector Space Semantics
</subsectionHeader>
<bodyText confidence="0.987587564102564">
In a series of papers, Zwarts (1997, 2003a, 2003b, 2005; Zwarts and Winter 2000) has
developed a semantics for locatives based on vectors. A main motivation for this pro-
posal is the observation that locatives may be modified by phrases expressing distance
or direction; for example, a measure phrase (ten meters), an adverb (diagonally), or a
dimensional adjective ( far), as seen in Example (27).
(27) Superman is far/diagonally/ten meters above the building.
Many approaches to locatives will consider above the building to denote a region and let
this be a set of points. It is then not obvious how the modifier ten meters can apply to
this region. Zwarts and Winter (2000) propose instead to let the locative PP denote a
set of vectors (Q1). Vectors are directed line segments between points in space. Loosely
speaking, we may say that above the building denotes the set of vertical vectors starting
in the building and ending above it. By then letting ten meters denote the vectors
having a length of ten meters, the modification can be considered set intersection,
and the result are all vectors of length ten meters starting in the building and ending
vertically above it. Syntactically, Zwarts and Winter consider locatives to be modifying
adjuncts. They mainly consider how nouns are modified. Because nouns denote sets
of individuals, and locatives denote sets of vectors, they assume a primitive semantic
function loc which maps individuals to their regions as sets of points (or vectors). This
is used for the landmark (e.g., the building in the locative PP above the building). When
a locative modifies a noun, the inverse function is used, such that the set of vectors
is turned into the set of objects which are located within the set of (endpoints of) the
vectors.
Even though this approach seems to solve the semantic problem of this particular
type of construction, we are not sure how general it can be made. The compositional
analysis of Zwarts and Winter (2000) is applied to modification of nouns and to pred-
icative uses of locatives; they do not consider verbal modification. We can see how the
approach can be adopted to verbal modification of static locatives in an event based
framework by introducing a function loc e, mapping events to regions, but we do not
see how it extends to directional locatives. In later articles, Zwarts (2003b, 2005) extend
the approach to the directional PPs. A directional PP does not denote a set of vectors,
but a set of paths. A path can be considered a sequence of vectors. For example, in John
went to the store, the path John followed can be formalized as a sequence of vectors,
{vi|i E I} for an ordered set I, where each vi has the store as its starting point, where
John successfully traverses their endpoints, and where the last vector also has the store
as its endpoint. Intuitively this is a correct description, but Zwarts (2003b, 2005) does not
show how this can be handled in a compositional grammar. It is a particular problem for
a compositional treatment that static PPs and directional PPs are ascribed denotations
of different types, unless they are also given different syntactic analyses (cf. discussion
on Jackendoff in Section 2.4).
</bodyText>
<page confidence="0.98405">
236
</page>
<bodyText confidence="0.443566">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
</bodyText>
<subsectionHeader confidence="0.995515">
2.7 Kracht’s Two-Layered Locatives
</subsectionHeader>
<bodyText confidence="0.995299411764706">
In Kracht (2002), a novel approach to the semantics of locatives is described. Kracht
presents a solution to Bierwisch’s (1988) problem of the duality of locatives, by claiming
that locatives consist of two layers (Q1/Q2). The lower layer, called a localizer phrase
(LP), defines a region or location, while the higher layer, called a modalizer phrase
(MP), defines events of motion with respect to this region (Q1).
Both from a semantic and syntactic point of view, Kracht claims a locative expres-
sion is structured as [MP M [LP L NP]]. Here, L is a localizer which together with the NP
forms an LP whose semantic contribution is a location. M is a modalizer which together
with the LP forms an MP, whose semantic contribution is an event modifier. The analysis
is motivated on the one hand by the dualistic nature of locative semantics, and on the
other hand by syntactic and morphological data. Locatives are realized differently in
different languages. Some languages use pre- or postpositions, whereas other languages
use locative case. In particular, case languages like Finnish, Hungarian, and Tsez realize
the two different layers as different suffixes. Still, whether the locative is expressed by an
adposition or case, the M+L most often form a unit. This is by far the most frequent case
for English, meaning that the preposition under in Example (3) is analyzed as shown in
Example (28).
</bodyText>
<equation confidence="0.919179">
MP
M+L NP
under ...
</equation>
<bodyText confidence="0.9860495">
In English, the two-layering is usually not explicit, but it is found in constructions
like Example (7), corresponding to:
</bodyText>
<equation confidence="0.87381375">
MP
M LP
L NP
from under ...
</equation>
<bodyText confidence="0.9891905">
MPs denote sets of events, and their syntactic function is that of adverbial modifi-
cation. The data Kracht discusses give support for five different types of modalizers or
modes, which are the heads of the MPs, denoting five different types of events.1 Thus,
if Kracht is right, the modes are true semantical interlingua predicates. The modes are:
</bodyText>
<listItem confidence="0.7903016">
1. static (st), corresponding to Jackendoff’s Place Function
2. coinitial (ci), corresponding to Jackendoff’s Path Function FROM
3. cofinal (cf), corresponding to Jackendoff’s Path Function TO
1 Kracht (2002) also mentions a sixth mode, the recessive mode, corresponding to Jackendoff’s
AWAY-FROM. But the data he discusses do not sufficiently support the existence of this mode.
</listItem>
<page confidence="0.985359">
237
</page>
<bodyText confidence="0.124141">
Computational Linguistics Volume 35, Number 2
</bodyText>
<listItem confidence="0.968784">
4. transitory (tr), corresponding to Jackendoff’s Path Function VIA
5. approximative (ap), corresponding to Jackendoff’s Path Function
TOWARDS
</listItem>
<bodyText confidence="0.967363066666667">
Kracht also claims that LPs only occur in restricted contexts, for example, as a comple-
ment selected by a verb or a preposition. The LP denotes a location, and the head of an
LP is a localizer function, which defines a location in relation to its complement.
Furthermore, Kracht claims that verbs may select a PP complement of a certain
mode syntactically, but only interact with the LP semantically. In other words, the
verb takes a location as the semantic argument. This is explained in more detail by
Kracht (2006). The principle governing this particular verb–PP interaction is called the
Emptiness Principle (where X corresponds to a preposition, and C to a PP for our
purposes):
Emptiness Principle. Suppose that X is a syntactic marker in the constituent C.
Suppose further that the presence of X in C is determined purely by non-semantic
rules (for example selection, agreement, Sandhi). Then the meaning of X is empty,
namely the identity function. (Kracht 2002, page 204)
Thus, we end up with a theory that explains both the dualistic nature of prepositions
semantically, and how the two-layering interacts with the syntax.
</bodyText>
<subsectionHeader confidence="0.981884">
2.8 Summary
</subsectionHeader>
<bodyText confidence="0.9999125">
In this section, we have looked at several theories on locatives. These theories each
have a different focus and different goals. Returning to our initial questions, we see that
both Kracht (2002) and Jackendoff (1990) preserve the two-layered nature of locatives.
But where Kracht’s solution allow directional locatives to be modificational adjuncts,
Jackendoff is committed to treating directionals as referential complements of motion
verbs. Furthermore, Fong’s (1997) diphasic events are insufficient to capture the nature
of Kracht’s transitory and approximative modes. In addition, neither Jackendoff nor
Fong provides a formalized compositional semantics to the same extent as Kracht.
Furthermore, we find Kracht’s approach to be of greater cross-linguistic validity, and
porting the analysis to languages with locative case or a mix of case and prepositions is
therefore possible. For these reasons, we have chosen Kracht’s proposal as the basis for
our implementation of locatives.
</bodyText>
<sectionHeader confidence="0.986" genericHeader="method">
3. Formal Background
</sectionHeader>
<bodyText confidence="0.999197">
In this section, we describe the formal semantic aspects of Kracht’s (2002) proposal, as
well as the framework of MRS (Copestake et al. 2005), a meta-level language for logical
representations.
</bodyText>
<subsectionHeader confidence="0.99973">
3.1 Formal Ontology and Formal Semantics
</subsectionHeader>
<bodyText confidence="0.9997624">
Kracht (2002) argues for his analysis in terms of modalizers and localizers from data—
in particular data regarding case—in several typologically different languages. He pro-
poses a formal ontology in which he specifies a formal semantics for the localizers and
modalizers, and furthermore shows how the fact that a verb can select an LP or NP can
be implemented in a grammar. Along the way he discusses several other phenomena,
</bodyText>
<page confidence="0.973065">
238
</page>
<bodyText confidence="0.986899034482759">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
like the lexical meaning of the different localizers, with varying degrees of rigor. We will
not have much to say about case or languages other than English and Norwegian. What
we will do here is to present Kracht’s formal ontology and semantics for the locatives
which will serve as a starting point for our analysis. When it comes to the integration
in a grammar, we will depart from his proposal. One should also keep in mind that his
ambition is not to give full-fledged analyses of sentences containing locatives; he only
discusses the relative contribution from the locatives.
To describe the semantics formally, Kracht uses a typed lambda calculus with the
following basic types:
t, the type of truth values
e, the type of objects
v, the type of events
i, the type of time points
p, the type of spatial points
r, the type of regions
j, the type of intervals
There are two ways to construct complex types. If α and β are types then so are α -4 β,
and α x β. We write φ : τ to express that the term φ is of type τ. A term of type t is a
formula. Its denotation in a model will be a member of the domain Dt, the set of truth
values. Each model will contain a non-empty set of individuals De and each term of type
e denotes a member of this domain. A simple formula, for example, man(cain) of type t
can be constructed if man : (e - 4t) and cain : e. The x-constructor allows a predicate to
take more than one argument, for example, brother : (e x e) -4 t, and brother(cain, abel) : t.
The domain of α -4 β, D(α→β), is the set of all functions from Dα to Dβ. The domain
of α x β, D(α×β), is Dα x Dβ. Functions are constructed by the use of lambda in the
normal way: if φ : α, x is a variable, and x : β then λxφ : α -4 β.
The events allow for a Davidsonian treatment of verbs and adverbs, where a sen-
tence like Example (30) denotes a set of events as in Example (31).
</bodyText>
<listItem confidence="0.7802035">
(30) Kim is driving.
(31) λe[drive(e,kim)]
</listItem>
<bodyText confidence="0.958017833333333">
The domain of events is a non-empty set Dv. Kracht assumes the set of time points to
be (isomorphic to) the set of reals, Di = R, and the set of space points to be (isomorphic
to) the Cartesian space Dp = R3. The type j is assumed to be a sub-type of i - 4t, and
its domain, Dj C D(i→t), is the set of intervals. The type of regions, r, is assumed to be a
sub-type of p - 4t. Its domain Dr C D(p→t) is the set of all path-connected sets of points.
For our purposes, we do not have to go further into the details here.2
</bodyText>
<footnote confidence="0.98940325">
2 We have made one simplification compared to the original proposal. We have not included groups for
modeling plurals because it is not relevant for the points we want to make in this article. Also, our
notation departs in some respects from the original one. Kracht uses partly curly bracket notation for
(characteristic functions of) sets, whereas we stick to a lambda notation.
</footnote>
<page confidence="0.987739">
239
</page>
<note confidence="0.293784">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.9979852">
For adverbial modification, Kracht claims the MP in Example (32) denotes a set of
events, as shown in Example (33). The nuclear sentence in Example (30) also denotes
the set of events in Example (31) and the modification works as an intersection between
the two sets. Hence Example (34) is represented as Example (35), where we use double
quotes to mark material which we have not yet fully analyzed.
</bodyText>
<listItem confidence="0.99940075">
(32) into Paris.
(33) Ae[“into Paris”(e)]
(34) Kim is driving into Paris.
(35) Ae[drive(e,kim) n “into Paris”(e)]
</listItem>
<bodyText confidence="0.999707733333333">
We now turn to the inner structure of the MP and the semantics of the LP. A sentence
like Example (34) says something about the relationship between the region where Kim
is driving and the region within the city of Paris. To achieve this, Kracht assumes a
primitive function taking objects to their regions, LOC. As objects can be moving, this
function has to be time-dependent, hence of type e -4 (i -4 r). Thus if t is a particular
time point, t : i, and the term paris of type e is the name of Paris, LOC paris(t), which is
of type r, expresses the region of Paris at time t.
The LP cannot denote such a simple region, however, but has to be a set of regions,
what Kracht calls a neighborhood. In the example, this will be the set of all regions
that can be claimed to be in Paris.3 Moreover, such neighborhoods may also vary
with time, cf. behind the car. Hence the denotation of the LP has to be a parameterized
neighborhood, of type i -4 (r -4 t).
An MP has the structure [M [L NP]]. If we assume the contribution from the NP to
be of type e, then the localizer, L, will be of type e -4 (i -4 (r - 4t)), and the modalizer,
M, of type (i -4 (r -4 t)) -4 (v -4 t).
To take an example, the English prepositions into and in have different modes—into
is cofinal whereas in is ambiguous between static and cofinal mode—but they share the
same localizer function IN. The common LP corresponding to the expressions in Paris
and into Paris will be IN paris. We could consider such localizers as primitive, but Kracht
takes one step further and assumes that there are basic relations between regions, called
local relations. For example, i, of type (r x r) - 4t, is a particular relation between two
regions locating the second region within the first region. The localizer IN can then be
analyzed as AxAtAr[i(LOC(x)(t),r)] and the LP corresponding to IN paris as AtAr[i(LOC
paris)(t), r)], where r is a variable ranging over regions. Other prepositions contribute a
different local content. Kracht thinks there is no upper bound on the possible different
localizers in a language.
If we write L for the logical representation of the LP, the static MP can be written
ST(L). Here ST is a modalizer, a function of type (i -4 (r -4 t)) -4 (v -4 t). Kracht
argues from cross-linguistic data for a finite set of modalizers, in addition to the
static mode, these being the four modes for directional PPs: coinitial, cofinal, transitory,
</bodyText>
<footnote confidence="0.776957166666667">
3 In this particular example, it could have worked to let in Paris denote the maximal region which is in
Paris, and to say that other regions were in Paris if they were subregions of this region. But that approach
does not work for The book is on the table. For the book to be on the table, it does not suffice that the
location of the book is contained in the maximal region which is on the table. The region where the book
is located has to make contact with, and be supported by, the table. Moreover, the sentence might be true
even though the whole book is not within the maximal region on the table.
</footnote>
<page confidence="0.927047">
240
</page>
<bodyText confidence="0.975042083333333">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
approximative. They each contribute a different function CI, CF, TR, AP (corresponding
to M) of the same type as ST. These modalizers are shorthand for more structured
functions which can—at least partly—be expressed in the lambda calculus. To achieve
this, Kracht assumes some basic functions. In addition to LOC : (e -4 (i -4 r)) introduced
previously, there is a function TIME : (v -4 (i - 4t)), taking an event to the set of time
points in that event, a function µ : (v - 4e), yielding the principal mover of an event,
and a function LOCv : (v -4 r), yielding the (time independent) region of an event.4 In
addition, there are several defined functions used, for example, CF*, II, PEND, to make
the representations simpler, and hiding some of the complexity. The cofinal reading
CF(L1) can then be spelled out as a series of equivalent representations (Examples
(36)–(42)) making use of such defined functions and relations.5
</bodyText>
<equation confidence="0.997860555555556">
(36) CF(L1)
(37) λLλe[CF*(µ(e),L, TIME(e))](L1)
(38) λe[CF*(µ(e),L1, TIME(e))]
(39) λe[PEND(II(µ(e),L1) fl TIME(e),TIME(e))]
(40) λe[PEND(λt[L1(t)(LOC(µ(e)(t))], TIME(e))]
(41) λe[--,dt(TIME(e)(t) &lt;-4 L1(t)(LOC(µ(e))(t)))∧
dt(TIME(e)(t) -4 lt&apos;(TIME(e)(t&apos;) ∧ t &lt; t&apos; ∧ L1(t&apos;)(LOC(µ(e))(t&apos;) ) ))]
(42) λe[lt E TIME(e)(--,L1(t)(LOC(µ(e))(t)))∧
dt(TIME(e)(t) -4 lt&apos;(TIME(e)(t&apos;) ∧ t &lt; t&apos; ∧ L1(t&apos;)(LOC(µ(e))(t&apos;) ) ))]
</equation>
<bodyText confidence="0.999646285714286">
In plain English, this says that the mover of the event starts in a region which is not one
of the regions in the neighborhood denoted by L, and ends in a region which is in the
neighborhood denoted by L. Similar definitions can be given for the coinitial reading
and for the transitory reading. To define the approximative reading, the representation
language has to be extended with a function representing distance in the underlying
metrical space. The static reading, ST(L), can through a series of equivalences be spelled
out as the following:
</bodyText>
<equation confidence="0.489493">
(43) ST(L) = λe[dt(TIME(e)(t) -4 (L(t)(LOCv(e)))]
</equation>
<bodyText confidence="0.676668">
For any time point t during the event e, the location of e belongs to L.
</bodyText>
<subsubsectionHeader confidence="0.303981">
3.1.1 Comparing Kracht’s and Zwarts’ Proposals. In Section 2, we compared Kracht’s pro-
</subsubsectionHeader>
<construct confidence="0.7411495">
posal briefly with some of the earlier proposals from the literature. Having the formal
apparatus on board, we will now compare it in more detail to Zwarts and Winter’s
(2000) proposal, to investigate if and how the two approaches can be combined. One
possibility is to try to merge the two proposals. We may extend Kracht’s semantics with
</construct>
<footnote confidence="0.979114">
4 Kracht uses the same function for LOC and LOCv, but we have simplified a little as it does not matter for
our purposes.
5 We refer to Kracht (2002) for the details of the calculations and functions in Examples (36)–(42).
</footnote>
<page confidence="0.986879">
241
</page>
<note confidence="0.284041">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.999919555555556">
vectors and let p be the type of vectors instead of points. The domain of regions, Dr
would still be a subset of D(p→t). A set of vectors would be a region if the set of endpoints
of the vectors is a path-connected set of points, and so forth.
Zwarts and Winter’s treatment of modification as intersection, as in ten meters
above the house, can be reconstructed within this framework if we consider it as LP-
modification. This means that ten meters, which intuitively is a set of vectors, V, hence
of type p - 4t, has to be lifted to type i -4 (r - 4t). One can take the temporal part to be
constant. For the regional part, a possibility is to admit all regions consisting of vectors
which are ten meters long, hence lift V to the following:
</bodyText>
<equation confidence="0.560528">
(44) λtλr[Vv(r(v) -4 V(v)]
</equation>
<bodyText confidence="0.999958636363636">
This is a little simplified, though, because for a hot air balloon to be ten meters above
the house one cannot request all parts of the balloon to be ten meters above the house.
But that is as much a challenge for Zwarts’ original proposal and it does not belong to
the compositional semantics to solve.
This analysis has a problem with compositionality, though. In an expression like
under the top, the preposition under is interpreted as M+L, and under the top as an MP.
We do not have a constituent corresponding to the LP part of under the top, which can be
modified by ten meters. Zwarts and Winter’s solution works, on the other hand, because
they only consider static PPs, or rather NP-modifying PPs. It remains to show how this
can be extended to directional PPs. We will hence ignore such modifiers for the rest of
this article.
</bodyText>
<subsectionHeader confidence="0.999123">
3.2 Introducing Minimal Recursion Semantics
</subsectionHeader>
<bodyText confidence="0.999231222222222">
MRS (Copestake et al. 2005) is a framework for semantic representations in large-scale
grammars. The main goals for MRS is to be expressively adequate allowing linguistic
meaning to be represented properly, to be compatible with other modules in a grammar,
to be computational tractable, and to support underspecification. The semantic repre-
sentations in MRS can be considered a meta-level language for representing an under-
lying object language which is typically first-order logic with generalized quantifiers.
Example (46) is an MRS structure for the sentence in Example (45). The basic building
blocks are the elementary predications (EPs), like dog(x) and chase(x,y), corresponding to
atomic formulas.
</bodyText>
<listItem confidence="0.942771">
(45) Every dog chases some cat.
(46) (h0, h7, {h1: every(x, h2, hA), h3: dog(x), h4: some(y, h5, hB), h6: cat(y),
h7: chase(x, y)}, {h0 =q h7, h2 =q h3, h5 =q h6})
</listItem>
<bodyText confidence="0.993928">
MRS is often described as a flat semantics, because the MRS structures are syntacti-
cally non-recursive. This is achieved by labeling all EPs with handles. In Example (46),
h3 is the label on the predication dog(x). In addition, an EP may have handles as argu-
ments (cf. the argument h2 of every(x, h2, hA)). Quantifiers introduce special relations
in an MRS, corresponding to generalized quantifiers. The first argument of a quantifier
relation is the bound variable, the second is the restriction, and the third is the body.
These handles are employed in the mapping from the flat meta-level representation to
the object-language expressions with explicit representations of scope.
</bodyText>
<page confidence="0.883021">
242
</page>
<bodyText confidence="0.964541285714286">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
Scope underspecification is represented in MRS by having handles in argument po-
sitions of EPs that are not the labels of other EPs. The handles are linked (or equated) in
the construction of object-language expressions. The unconstrained handle arguments
hA and hB in Example (46) may be linked in two ways to construct the expressions in
Examples (47) and (49), corresponding to the FOL expressions in Examples (48) and
(50), respectively.
</bodyText>
<listItem confidence="0.5106912">
(47) some(y, cat(y), every(x, dog(x), chase(x, y)))
(48) ly(cat(y) ∧ Vx(dog(x) → chase(x, y)))
(49) every(x, dog(x), some(y, cat(y), chase(x, y)))
(50) Vx(dog(x) → ly(cat(y) ∧ chase(x, y)))
To constrain the possible linkings of handles and thereby the possible scope relations,
MRSs may contain so-called equality modulo quantifiers. The constraint for the handle
h and the label l (of some EP), h =q l, called a qeq constraint, expresses that either h = l,
or some non-repeating chain of one or more labels of quantifier EPs intervene. An object-
language formula is described by the MRS structure only if it respects all the constraints
and all variables are bound.
</listItem>
<bodyText confidence="0.996842666666667">
The general form of an MRS can be considered a four-tuple (GT, LT, R, C) where
R (relations) is the bag of EPs, and C (constraints) is a bag of all the qeq constraints.
In addition, GT (global top) is the label of the topmost EP of the structure, while LT
(local top) is the label of the topmost EP of a sub-structure. The LT is needed for rules of
semantic composition. Furthermore, the GT is always qeq to the LT of the root phrase.
Semantic composition in MRS is performed as follows: The bag of EPs (R) and the
bag of qeq constraints (C) of the daughter nodes are appended on the mother node. Fur-
thermore, the global tops (GT) of the daughters are equated on the mother mode. Scopal
and intersective combination are treated differently. For intersective combination, the
local tops (LT) are equated. For example, if black corresponds to the expression in
Example (51) and cat corresponds to Example (52), then black cat corresponds to Example
(53). (The coindexation of x and y is done through the interaction with the grammar.)
</bodyText>
<equation confidence="0.993872333333333">
(51) (h0, h1, {h1: black(y)}, {})
(52) (h0, h5, {h5: cat(x)}, {})
(53) (h0, h1, {h1: black(y), h1: cat(y)}, {})
</equation>
<bodyText confidence="0.944302">
For scopal combination, the LT of the mother is equal to the LT of the scoping daughter,
and a qeq constraint is added between the scopal argument of the scoping daughter and
the label of the scoped-over daughter. One result is seen in Example (54), corresponding
to probably sleeps.
(54) (h0, h1, {h1: probably(h2), h3: sleep(x)}, {h2 =q h3})
For quantifiers, the scopal argument is the restriction of the quantifier, whereas
the body of the quantifier is left unconstrained. This means that the handle variable
in restriction position is qeq to the label of the restriction’s LT. For example, if every
</bodyText>
<page confidence="0.978312">
243
</page>
<note confidence="0.278252">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.9882055">
corresponds to the expression in Example (55) and cat corresponds to Example (56),
then every cat corresponds to Example (57).
</bodyText>
<equation confidence="0.897249">
(55) (h0, h1, {h2: every(x, h3, h4)}, {})
(56) (h0, h5, {h5: cat(x)}, {})
(57) (h0, h1, {h2: every(x, h3, h4), h5: cat(x)}, {h3 =q h5})
</equation>
<sectionHeader confidence="0.912669" genericHeader="method">
4. MRS Analysis of Locatives
</sectionHeader>
<bodyText confidence="0.999942230769231">
Kracht’s analysis is based on higher order functions and functional application. How
can that be ported to a system based on (first-order) predication where composition is
built by unification? And how shall the phenomena be described in a grammar? We
will work our way top down starting with how MPs are combined with other phrases
and then proceed to the inner structure of MPs. We will take as our starting point
the large-scale computational English Resource Grammar, ERG (Flickinger 2002),6 an
HPSG grammar using MRS as the format for semantic representation (see Flickinger
2002 and Section 6 of Copestake et al. 2005). ERG uses a Davidsonian approach where
verbs introduce events, and adverbial intersective modification involves coindexation
of the event variables of the verbal relation and the modifier relation. Because Kracht’s
approach is also event-based and he considers all adverbial locative PPs (i.e., MPs) as
intersective modifiers, the analysis of MPs can be expressed straightforwardly in MRSs
and is, in fact, similar to the analysis in ERG.
</bodyText>
<subsectionHeader confidence="0.99733">
4.1 MRS Analysis of Modalizer Phrases (MPs)
</subsectionHeader>
<bodyText confidence="0.999803571428571">
The MP can be represented with an EP containing an event variable. Schematically, the
MRS structures in Examples (58) and (59) are composed into Example (60). As we de-
scribed in the previous section, intersective adverbial modification in MRS is expressed
by coindexation of the labels of the intersected EPs. Shared labels are treated in MRS
as implicit conjunctions, and coindexation of labels will thus have the same effect as
conjoining the two EPs. (The event variables are coindexed through the interaction with
the grammar.)
</bodyText>
<equation confidence="0.797409">
(58) [A mouse appeared]&apos; =
(h0, h5, {h1: some(x, h2, h3), h4: mouse(x), h5: appear(e, x)},
{h0 =q h5, h2 =q h4})
</equation>
<listItem confidence="0.5236216">
(59) [from under the table... ]&apos; =
(h6, h7, {h7: “from under the table”(e&apos;)}, {...})
(60) [A mouse appeared from under the table]&apos; =
(h0, h5, {h1: some(x, h2, h3), h4: mouse(x), h5: appear(e, x),
h5: “from under the table”(e)}, {h2 =q h4,...})
</listItem>
<footnote confidence="0.680465">
6 For more information on ERG, seehttp://www.delph-in.net/erg/.
</footnote>
<page confidence="0.979945">
244
</page>
<bodyText confidence="0.586425">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
</bodyText>
<subsectionHeader confidence="0.99478">
4.2 MRS Analysis of Localizer Phrases (LPs)
</subsectionHeader>
<bodyText confidence="0.99995916">
We now turn to the question of the inner structure of the MP, the representation of the
LP, and how the MP is constructed from the LP. This is more delicate, as in Kracht’s
formalism an L representing an LP is a higher order function—of type (i -4 (r -4 t)).
This function occurs on the one hand as an argument to other functions, for example, to
the modalizer functions, ST, CF, CI, TR, AP as in Example (36), and on the other hand as
a functor (or relation) when the deeper semantics of the modalizers are spelled out, for
instance, as in Example (42).
Our solution is based on a division of semantic representations into several layers.
We will distinguish between a surface level and deeper levels. The surface level will
represent all semantic information that is grammaticalized, and it will be appropri-
ate for parsing and generation, and possibly other types of applications. The surface
representation does not have to represent all the deeper semantic meaning explicitly,
but the deeper meaning should be derivable from the surface representation. Thus,
for this particular example, it suffices with a surface representation corresponding to
Example (36) since we have demonstrated how Example (42) can be derived determin-
istically. Because an LP will always be argument to an M or to a verb, it is possible
to give representations where we only see such Ls in argument positions. We may
therefore consider the type (i -4 (r - 4t)) of parameterized neighborhoods a primitive
type l in our surface representation language. A modalizer function, like CI, takes first
a parameterized neighborhood, L, and then an event, and yields a truth value. It is of
type (i -4 (r -4 t)) -4 (v - 4t). This corresponds to being of type ((i -4 (r -4 t)) x v) -4 t,
or (l x v) - 4t. Hence it can be represented in MRS as a relation, ci mod, taking two
arguments. Ignoring the analysis of the table, this yields the MRS representation in
Example (62) for the MP in Example (61). The full semantic representation of Exam-
ple (7) is shown in Example (63).
</bodyText>
<listItem confidence="0.980732333333333">
(61) [MP from [LP under [NP the table ] ] ]
(62) (h0, h1, {h1: ci mod(e, l), h1: under loc(l, x), {})
(63) [A mouse appeared from under the table]&apos; =
</listItem>
<bodyText confidence="0.911848466666667">
(h0, h5, {h1: some(x, h2, h3), h4: mouse(x),
h5: appear(e, x), h5: ci mod(e, l), h5: under loc(l, y),
h9: def(y, h6, h7), h8: table(y)}, {h0 =q h5, h2 =q h4, h6 =q h8})
For applications, we can convert this simple surface interpretation to Kracht’s deep
representations by a simple translation procedure. In this respect we assume a similar
approach to that which Copestake et al. (2005, page 312) and ERG take for tense. In ERG,
tense is treated as a simple feature on events; there are no variables corresponding to,
for example, time points. Copestake et al. argue that such a representation is preferable
since it simplifies parsing and generation, and it suffices if it is possible to derive the
deeper representation from this representation. Consider our analysis of the MP into
Paris in Example (64). The meaning of in loc(l, paris) is that the localizer function
corresponding to in maps paris to l. This localizer function is what we saw as IN of type
e -4 (i -4 (r - 4t)) in Kracht’s formalism in Section 3.1. Hence Example (64) corresponds
directly to Example (65) in Kracht’s formalism. This is equivalent to Example (66), which
is the analysis according to Kracht. If we then use Kracht’s definition of IN in terms of
</bodyText>
<page confidence="0.977468">
245
</page>
<note confidence="0.224446">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.710678">
the local relation i this can be spelled out as Example (67), and if we use the definition
for CF this can be translated further into Example (68).
</bodyText>
<listItem confidence="0.885066714285714">
(64) h: cf mod(e,l), h: in loc(l, paris)
(65) CF(L)(e) ∧ IN(paris) = L
(66) CF(IN(paris))(e)
(67) CF(λtλr[i(LOC(paris)(t),r)])(e)
(68) It(TIME(e)(t) ∧ ¬i(LOC(paris)(t), LOC(µ(e))(t)))∧
dt(TIME(e)(t) → Its (TIME(e)(t&apos;) ∧ t ≤ t&apos;
∧ i(LOC(paris)(t&apos;), LOC(µ(e))(t&apos;) ) ) )
</listItem>
<bodyText confidence="0.993941785714285">
A similar translation can be applied in the case of the other mode relations, including
static. This means that from our simpler surface representations, we can construct
Kracht’s representations for application purposes when it is desirable.
The location variable l is unbound in the MRS representations. As with event vari-
ables in MRS, we assume an implicit quantifier for each location variable. But in contrast
to the event quantifier, we assume that this quantifier has a fixed narrow scope, that is,
it scopes over the modalizer and localizer relations, and is outscoped by all quantifiers
binding referential indices, including the quantifier introduced by the complement of
the PP. Moreover, this quantifier will be a quantifier claiming that there exists exactly
one such region. Though the quantifiers are not explicitly represented, the translation
into Kracht’s functional language proceeds as if they were there.
One could ask why we bother to decompose the preposition at all. Why do we
choose to analyze Example (61) as Example (62) when we could use the simpler
Example (69).
</bodyText>
<equation confidence="0.457575">
(69) (h0, h1, {h1: under(e, x)}, {})
</equation>
<bodyText confidence="0.998709916666667">
There are several reasons why we want to decompose. First, a preposition like
under can be interpreted in any of three ways {h1: st mod(e,l), h1: under loc(l,x)},
{h1: cf mod(e,l), h1: under loc(l,x)}, or {h1: tr mod(e,l), h1: under loc(l,x)}. A simple
translation procedure would have to propose all these three when the preposition is
translated into a deeper representation. But by having the mode explicitly represented,
we can to a certain degree disambiguate between the different modes during parsing.
As this disambiguation is performed during the syntactic analysis, we believe that
the disambiguated structure should also be reflected in the semantic representation.
Second, we will see in Section 5.2 that the decomposition simplifies the interpretation
of sentences where several prepositions co-occur. Third, we find anaphoric uses of
locative expressions, and an explicit representation is needed to describe the sentence
in Example (70).
</bodyText>
<listItem confidence="0.6142676">
(70) Kim traveled to Paris, and Sandy lives there.
Here, it is clear that the anaphoric there cannot point to the set of events denoted by the
MP to Paris. And as we want there to denote a location rather than an entity, we cannot
simply let it point to Paris either, unless we coerce Paris to a location. Rather, we let there
point to the location corresponding to the LP level of the PP to Paris.
</listItem>
<page confidence="0.982387">
246
</page>
<note confidence="0.387857">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
</note>
<sectionHeader confidence="0.908087" genericHeader="method">
5. Norwegian Locatives
</sectionHeader>
<bodyText confidence="0.999955555555556">
In this section, we will use Kracht’s (2002) theory for two purposes. We will first
show how locative prepositions can be classified along the modalizer and localizer
dimensions, and secondly use the theory to explain differences between Norwegian
and English locative prepositions. In Norwegian, we find no direct counterparts to
the English cofinal prepositions into and onto. Instead, one uses a combination of an
intransitive locative preposition, for example, inne (insidest) or inn (insidecf), followed
by the relevant preposition, for example, i (in) or p˚a (on). This was exemplified in the
sentences in Examples (11) and (12). We return to our analysis of these constructions in
Section 5.2. Thus, this section will focus mostly on the analysis of Norwegian locatives.
</bodyText>
<subsectionHeader confidence="0.995211">
5.1 Classes of Locatives
</subsectionHeader>
<bodyText confidence="0.9381955">
Looking at the selectional patterns of Norwegian prepositions, we identify three distinct
patterns:
</bodyText>
<listItem confidence="0.9463655">
1. PP transitive. These take PP complements. The most frequent are fra (from)
and til (to), with via/om (via) and mot (toward) as possible candidates. Note
that all these prepositions also occur with NP complements.
2. NP transitive. These take NP complements. All ordinary prepositions fall
into this class.
3. Intransitive. These take no complements, and are semantically equivalent
to a full PP with a contextually determined location. Examples are her
(herest), hit (herecf), inne (insidest), inn (insidecf), and innenfra (from inside).
</listItem>
<bodyText confidence="0.999590071428572">
Furthermore, the analysis we propose is decompositional, and we classify locatives
semantically along the modalizer and localizer dimensions. The modalizer dimension
seems to have an upper boundary, as Kracht (2002) claims to have found evidence for
five modalizers. The localizer dimension has in principle no upper boundary. In Table 1,
we show how the different types of locatives are distributed over the localizer and
modalizer dimensions. Prepositions in the same column share modalizer, and prepo-
sitions in the same row share localizer. For each Norwegian locative, the corresponding
English locative is listed in parentheses.
Recall that prepositions can function as heads of MPs and LPs. For Norwegian
and English, there is a general correspondence between the prepositions being heads
of static MPs and being LPs. It is also worth noting the transparent morphology the
intransitive prepositions show with respect to mode. The system is made up of a stem
and a suffix, as follows: -e (static), -efra (coinitial), - (cofinal), -om (transitory) and -over
(approximative).
</bodyText>
<subsectionHeader confidence="0.995772">
5.2 More on the Internal Structure of Locatives
</subsectionHeader>
<bodyText confidence="0.999685">
We follow Kracht (2002) in assuming that locatives have an MP structure of the form
[M [L NP]]. Syntactically, this can be realized in several different ways. Relating the
classes of prepositions to the MP structure above is done as shown subsequently. The
underlined constituents of the MP structure correspond to the preposition of the class.
</bodyText>
<page confidence="0.984151">
247
</page>
<table confidence="0.57186">
Computational Linguistics Volume 35, Number 2
</table>
<tableCaption confidence="0.993923">
Table 1
</tableCaption>
<table confidence="0.993875285714286">
Locatives classified with respect to mode.
st ci cf tr ap
PP transitive − fra (from) til (to) via (via) mot (toward)
NP transitive ved (at) fra (from) til (to) via (via) mot (toward)
p˚a (on) av (off) p˚a (onto) over (across) −
i (in) ut av (out of) i (into) gjennom −
(through)
under (under) − under (under) under (under) −
Intransitive/ her (here) herfra (from hit (here) − hitover
Alternatinga here) (toward here)
inne (inside) innenfra inn (inside) innom (−) innover
(from inside) (inward)
hjemme (at hjemmefra hjem (home) hjemom (−) hjemover
home) (from home) (homeward)
</table>
<tableCaption confidence="0.587058">
a See Section 5.2 for alternating prepositions.
</tableCaption>
<bodyText confidence="0.606077">
The relevant part of the semantics for the locative expression is also shown, using the
example sentences from Section 1.
</bodyText>
<listItem confidence="0.993877428571429">
1. PP transitive. These are analyzed as modalizers. They select for LP
complements, which in turn contribute with the localizer relation in order
to get at the full semantics of the locative.
M+L+NP
(7) [A mouse appeared from under the table ]&apos; _
... ci mod(e,l) ...
2. NP transitive. These are analyzed as combined modalizers and localizers.
The lexical preposition is decomposed to get a uniform analysis of the
locative PPs, and to facilitate a disambiguation of the modalizer part as
explained at the end of Section 4.2.
M+L+NP
(3) [The mouse ran under the table ]&apos; _
... st or cf or tr mod(e,l) ∧ under loc(l, x) ...
3. Intransitive. These are analyzed as a modalizer and a localizer. The
</listItem>
<bodyText confidence="0.937972">
localizer function is special in the sense that the landmark is contextually
determined. We have encoded this as a localizer relation taking only
one semantic argument, of type location.
</bodyText>
<figure confidence="0.314941">
M+LP
(15) [Musa kom derfra ]&apos; _
... ci mod(e,l) ∧ der loc(l) ...
</figure>
<bodyText confidence="0.99857275">
As mentioned, some intransitive prepositions may occur with a complement, as we
saw in Examples (11)–(14). We name these alternating locatives, and analyze them as
prepositions with an optional complement. When the alternating prepositions occur
with a complement, the mode relation scopes over both the contextually determined
</bodyText>
<page confidence="0.933358">
248
</page>
<bodyText confidence="0.935724333333333">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
location and the LP complement location. This analysis is based on the fact that the al-
ternating preposition introduces the mode, and does not merely disambiguate between
modes, as the cofinal reading of over is only available when preceded by an alternating
preposition, as shown in Examples (13) and (14). Thus, we end up with the following
analysis of alternating prepositions:
</bodyText>
<figure confidence="0.508767333333333">
4. Alternating. These are analyzed as a modalizer and a localizer, but take a
second optional LP complement, otherwise identical to intransitive
prepositions. Examples are inn (insidecf), inne (insidest), and ute (outside).
M + LP + LPoptional
(12) [Musa løp inn i hullet ]&apos; =
... cf mod(e,l) ∧ inne loc(l) ...
</figure>
<bodyText confidence="0.954659875">
The MRS for the LP complement analysis of Example (12) is given in Example (71)
(where we only show the elementary predications and omit the quantifiers). Note
that the sentence in Example (12) is syntactically and semantically ambiguous in our
grammar. It also has a reading where the PP i hullet is not a complement to inn, but
where both PPs modify the main event. The two different types of readings are shown
in Section 6.6.
(71) ... h4: mus(x), h5: løpe(e, x), h5: cf mod(e, l),
h5: inne loc(l), h5: i loc(l, y), h8: hull(y) ...
</bodyText>
<sectionHeader confidence="0.977475" genericHeader="method">
6. Implementation
</sectionHeader>
<bodyText confidence="0.99973425">
In this section, we first describe the framework the grammar was implemented in.
We then proceed to describing the classes of locative prepositions described in Sec-
tion 5. The implementation of Kracht’s (2002) emptiness principle will be central to our
grammar.
</bodyText>
<subsectionHeader confidence="0.845439">
6.1 Framework for the Implementation
</subsectionHeader>
<bodyText confidence="0.999943941176471">
MRS is a general format for representing different formal object languages and
may be combined with different syntactic models. It has in particular been com-
bined with HPSG grammars where it has been used in the large English Resource
Grammar (Flickinger 2002). HPSG (Pollard and Sag 1994) is a unification-based
non-transformational theory, using multiple inheritance type hierarchies and unifica-
tion of typed feature structures as central formal mechanisms. The analysis we have
presented so far is compatible with different syntactic models. We have made a small
fragment of an HPSG grammar to illustrate the analysis. This fragment was imple-
mented in the Linguistic Knowledge Builder (LKB) system (Copestake 2002). The LKB
system is an implementation environment for writing HPSG grammars. The grammar
was based on the Matrix “starter kit” for building HPSG grammars (Bender, Flickinger,
and Oepen 2002). The Matrix contains types for building MRSs as the semantic content
of a sentence compositionally. Principles restricting the syntax-semantics interface, as
described by Copestake, Lascarides, and Flickinger (2001), are also encoded in the
Matrix. For instance, a sign (phrase or word) only exposes its handle, main internal
argument, and external argument to the rest of the grammar, such that, for example, a
verb cannot control the arguments of its complement. The description of the grammar
</bodyText>
<page confidence="0.986869">
249
</page>
<note confidence="0.481077">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.99974125">
presented here deviates somewhat from the Matrix, in order to improve readability. We
also only present the relevant features of the grammar, as the actual descriptions of the
signs in the grammar are quite complex, having to deal with many other aspects of the
grammar. We refer to Jørgensen (2004) for details of the implementation.
</bodyText>
<subsectionHeader confidence="0.990958">
6.2 Goals
</subsectionHeader>
<bodyText confidence="0.9999338">
We want our implementation to give the correct syntactic and semantic (MRS) analyses,
while having minimal redundancy in the lexicon. We furthermore want to under-
specify ambiguities wherever possible. Corresponding loosely to questions Q1–Q3 in
Section 2, we need to consider the following dimensions that serve as the guidelines for
the grammar presented here:
</bodyText>
<listItem confidence="0.997875222222222">
1. Modalizer+Localizer/Localizer: Locative prepositions must have the
ability to denote sets of events (i.e., serving as M+L) and denote locations
(L), depending on the syntactic context.
2. Adjunct/Complement: Locative prepositions must have the ability
to serve as modificational adjuncts and as referential complements,
depending on the syntactic context.
3. Mode ambiguity: Mode ambiguous locative prepositions should display
this ambiguity in the semantics, and only be disambiguated semantically
when the syntactic context allows it.
</listItem>
<subsectionHeader confidence="0.957468">
6.3 NP Transitive Prepositions
</subsectionHeader>
<bodyText confidence="0.734256538461538">
For sentence (3), we want to obtain the MRS in Example (72). The HPSG representation
for the sign under is given in Figure 1. The bag of EPs provided by under is repre-
sented as a list which is the value of the MRS.RELS, and where, for example, the EP
‘h5: under loc(l, y)’ is represented by an AVM where under loc is the value of PRED, h5
the value of LABEL, l is the value of ARG0, and y the value of ARG1. Moreover, h5 is the
local top of this MRS and that is encoded as the value of MRS.HOOK.LTOP.
(72) [The mouse ran under the table]&apos; =
(h0, h5, {h1: def(x, h2, h3),
h4: mouse(x), h5: run(e,x),
h5: st or cf or tr mod(e,l), h5: under loc(l,y),
h9: def(y,h6,h7), h8: table(y)},
{h2 =q h4, h6 =q h8})
We arrive at the MRS in Example (72) as follows:
</bodyText>
<listItem confidence="0.997479714285714">
• Mode underspecification: The lexical entry for under introduces a
disjunctive modalizer relation (st or cf or tr mod rel).
• Combined M+L: Under introduces two semantic relations (in MRS.RELS),
one mod rel (st or cf or tr mod rel) and one loc rel (under loc rel).
• Event modification: The MOD contains a list of elements under may
modify. We see from Figure 1 that under modifies a verb, and that the
main variable of the verb (MOD&lt;MRS.HOOK.INDEX&gt;) is coindexed with
</listItem>
<page confidence="0.923363">
250
</page>
<bodyText confidence="0.464136">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
</bodyText>
<equation confidence="0.984776433333333">
�
� � � � � � � � � � � � � � � � � � � � � � � � � � �
� � �
� �
� �
� �
� �
� �
� �
� �
� �
� �
� �
� �
� �
� �
� � �
� �
� �
� �
� �
� �
� �
� �
� �
� � �
� �
�st or c/f or tr mod and loc lex item
STEM ( &amp;quot;under” \ )
PART-OF-SPEECH prep
� �
/ PART-OF-SPEECH verb
MOD \
\ MRS HOOK LLTOP h �
INDEX U
� �
/ PART-OF-SPEECH noun
COMPS \ LTOP h l \
\ MRS HOOK L/
INDEX yJ
�KEY-REL 1
��
LTOP h
HOOK
INDEX U event or loc
� �
PRED st or cf or tr mod rel
�
LABEL h �
1
MRS ARG0 U event or loc � �
/ARG1 l
RELS(
\ �
PRED under loc rel
�
LABEL h �
�
�ARG0 l �
� �ARG1 y
</equation>
<figureCaption confidence="0.957943">
Figure 1
</figureCaption>
<bodyText confidence="0.9887375">
Simplified AVM for the NP transitive preposition under.
the main variable of the preposition (MRS.HOOK.INDEX), treating the
preposition as an intersective modifier. (Disregard the underspecified
variable type event or loc for now, except for the fact that because the
verb’s MRS.HOOK.INDEX is an event, the underspecified type will also
be constrained to be an event in cases of adverbial modification.)
</bodyText>
<subsectionHeader confidence="0.988832">
6.4 PP Transitive Prepositions
</subsectionHeader>
<bodyText confidence="0.993396">
We now turn to the sentence in Example (7), for which we want to achieve the MRS in
Example (73).
</bodyText>
<equation confidence="0.941382666666667">
(73) [A mouse appeared from under the table]&apos; =
(h0, h5, {h1: some(x, h2, h3),
h4: mouse(x), h5: appear(e, x),
h5 : ci mod(e,l), h5 : under loc(l,y),
h9: def(y,h6,h7), h8 :table(y)},
{h2 =q h4, h6 =q h8})
</equation>
<page confidence="0.987193">
251
</page>
<note confidence="0.486051">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.999067357142857">
This is more complex, as we want to arrive at this MRS while still using the sign for
under from Figure 1. The representation for from acting as a PP transitive preposition is
given in Figure 2. We have two different entries for the preposition from in the lexicon,
one where it is PP transitive and one where it is NP transitive. The entry for the NP
transitive from is more or less identical to under, except that it introduces different
semantic relations (ci mod rel and at loc rel).
The two signs in Figure 1 and Figure 2 together correspond to our imple-
mentation of the emptiness principle, by unification of the constraint id rel on
COMPS&lt;MRS.KEY-REL&gt; in Figure 2 and MRS.KEY-REL in Figure 1. As we recall from
Section 2.7, the emptiness principle claims that when an element is fixed regardless
of the interpretation of the sentence, it is interpreted as the identity relation. Kracht’s
claim is more radical than our implementation, as he claims that any element may be
empty. We have only implemented the emptiness principle for prepositions.
The MRS in Example (73) is obtained as follows:
</bodyText>
<listItem confidence="0.99144125">
• Identity relations: The claim that any preposition can be semantically
empty corresponds in our type hierarchy to claiming that every relation
introduced by a preposition has an identity relation as a subtype of it,
as shown in Figure 3. Recall that empty elements must be syntactically
selected. Thus we constrain the selecting head, whether a verb or a
modalizer, to select a preposition with an empty element.
• Localizer–Static modalizer correspondence: As already noted, there
is a general correspondence between the static prepositions and the
prepositions that figure as complements of PP transitive prepositions.
• Selectional constraints: From selects a static preposition whose
key semantic relation is the identity relation. This is represented
in MRS.KEY-REL, a feature that every sign exposes according to the
</listItem>
<equation confidence="0.955522928571429">
ci-mod-lex-item
 STEM “from”
 PART-OF-SPEECH prep
  
 PART-OF-SPEECH prep
  
 �   KEY-REL id rel &amp; static mod rel  �
  � � 
   
 COMPS   LTOP h  
MRS
  HOOK  
 
 INDEX l loc
     � � 
  LTOP h
  HOOK 
 INDEX e 
  
    MRS
PRED coinitial mod rel �
  �
 
 LABEL h
RELS   
ARG0 e  
ARG1  
l
</equation>
<figureCaption confidence="0.948444">
Figure 2
</figureCaption>
<bodyText confidence="0.697126">
The PP transitive preposition from and LP selection.
</bodyText>
<page confidence="0.936854">
252
</page>
<figure confidence="0.9871878">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
prep relation
mode rel loc rel id rel
... static mode rel ...
static mode id rel
</figure>
<figureCaption confidence="0.883592">
Figure 3
</figureCaption>
<bodyText confidence="0.88285675">
A type hierarchy of prepositional relations.
principles for the Matrix (Bender, Flickinger, and Oepen 2002).
MRS.KEY-REL is constrained to be of a common subtype of
static mod rel and id rel, represented in the AVM by ‘&amp;’.
</bodyText>
<listItem confidence="0.965730666666667">
• Type constraint: The MRS.HOOK.INDEX, i.e., the external argument of the
complement, is constrained to be of type loc. Recall from Figure 1 that
this was underspecified as event or loc.
</listItem>
<subsectionHeader confidence="0.797527">
6.5 Intransitive Prepositions
</subsectionHeader>
<bodyText confidence="0.999947333333333">
Intransitive prepositions are implemented similarly to NP transitive prepositions, ex-
cept that they take no complements (empty COMPS list), and that they introduce a loc rel
with only one variable. The MRS we obtain is shown in Example (74).
</bodyText>
<equation confidence="0.8905566">
(74) [A mouse ran here]&apos; =
(h0, h5, {h1: some(x, h2, h3),
h4: mouse(x), h5: run(e,x),
h5 :st or cf mod(e,l), h5 :here loc(l)},
{h2 =q h4})
</equation>
<subsectionHeader confidence="0.99543">
6.6 Alternating Prepositions
</subsectionHeader>
<bodyText confidence="0.9999715">
Alternating prepositions are implemented as something between a PP transitive prepo-
sition and an intransitive preposition. They take optional static PP complements, which
in turn are interpreted as LPs (identical to LP selection for PP transitive prepositions).
The location variable of the internal loc rel and the complement loc rel are coindexed,
such that the mod rel predicates over both localizer relations. The MRSs for the syntactic
analysis of Example (10), where the second PP is a complement of down, is shown in
Example (75). As mentioned in Example (12) in Section 5.2, Example (10) is syntactically
and semantically ambiguous in our grammar. It has a reading where the PP under the
bridge is not a complement to down, but where both PPs modify the main event. This is
shown in Example (76).
</bodyText>
<listItem confidence="0.864941333333333">
(75) [A child ran (MP down (LP under the bridge))]&apos; =
(h0, h5, {h1: some(x, h2, h3), h4: child(x), h5: run(e, x),
h5 :cf mod(e,l), h5 :down loc(l), h5 :under loc(l,y),
</listItem>
<page confidence="0.994252">
253
</page>
<note confidence="0.43235">
Computational Linguistics Volume 35, Number 2
</note>
<equation confidence="0.988216">
h6: def(y,h7,h8), h9: bridge(y)},
{h2 =q h4, h7 =q h9})
(76) [A child ran (MP down) (MP under the bridge)]&apos; =
(h0, h5, {h1: some(x, h2, h3), h4: child(x), h5: run(e, x),
h5 :cf mod(e,l1), h5 :down loc(l1), h5 :st or cf mod(e,l2), h5:under loc(l2,y),
h6: def(y,h7,h8), h9: bridge(y)},
{h2 =q h4, h7 =q h9})
</equation>
<subsectionHeader confidence="0.967184">
6.7 PP Transitive Verbs
</subsectionHeader>
<bodyText confidence="0.999929315789474">
The mechanisms we introduce for LP selection and mode underspecification have until
now been used to describe complex locative PPs. But the same mechanisms can be
used for other heads selecting PP complements, for example, verbs. Recall Bierwisch’s
(1988) claim that liegen (lie) is a relation between the subject and a location. This
can now be implemented directly, by stating in the description of the verb that it
selects an LP complement, identical to the complement of the PP transitive (modalizer)
prepositions.
More interesting is the class of verbs known as put-verbs. Such verbs take both
static and cofinal complements, and express directionality in both cases as we saw in
Example (8). Kracht’s two-layering enables us to let the verb select the full PP (MP) as
the syntactic argument, but only the denotation of the LP as its semantic argument. The
verb can thus express the movement, while the PP contributes the goal of the movement
to the semantics. We encode this by describing the PP complement of the verb to be an
LP (denoting a location) of static or cofinal mode (in COMPS&lt;..., [MRS.KEY-REL]&gt;).
Thus, we arrive at the same semantics for both sentences in Example (8). At the same
time we constrain the verb to only select PPs of static or cofinal mode. A simplified
AVM for the verb put is shown in Figure 4. A similar treatment can be given to any
verb that semantically selects a location rather than an event as the denotation of the
PP complement.
</bodyText>
<subsectionHeader confidence="0.972164">
6.8 Summary
</subsectionHeader>
<bodyText confidence="0.999247">
We have achieved our goals for the implementation from Section 6.2 as follows:
</bodyText>
<listItem confidence="0.995981461538461">
1. Adjunct/Complement: All locatives have the ability to serve as
modificational adjuncts through the MOD list. All locatives have
the ability to serve as complements, by being selected by a head,
for example, a modalizer ( from) or a verb.
2. Modalizer+Localizer/Localizer: When serving as a modificational
adjunct, the item on the MOD list constrains the MRS.HOOK.INDEX
of the PP to be an event, namely, the PP denotes a set of events.
When serving as a complement, the selecting head may constrain
the MRS.HOOK.INDEX of the PP to be a location, and at the same time
specify the main semantic relation, the MRS.KEY-REL, to be an id rel,
which is a subtype of all mod rels.
3. Mode ambiguity: We introduce disjunctive semantic relations for
mod rels. These may be further constrained by the syntax, for
</listItem>
<page confidence="0.974401">
254
</page>
<equation confidence="0.992952320754717">

lptrans verb lex item
� �
  “put”
 STEM
 PART-OF-SPEECH verb
   
PART-OF-SPEECH noun
  ��
  
  
LTOP h2
  ,
HOOK  
MRS
  
INDEX y
 �
   
 COMPS PART-OF-SPEECH prep    ��
LTOPHOOK h3
MRSINDEX l loc
     
 KEY-REL static or cofinal mod rel &amp; id rel
    � � 
LTOP h1
  HOOK 
  
INDEX e
 
  
  
 
 PRED put rel 
 
  


  LABEL h1   MRS 
�   � 

   
  ARG0 e   RELS
 
 
  ARG1 x  


   
 
 ARG2 y 
ARG3 
l
</equation>
<figureCaption confidence="0.900542">
Figure 4
</figureCaption>
<bodyText confidence="0.96780675">
Simplified AVM for the verb put.
example, by specifying that only motion verbs may be modified by
directional modes. This particular feature has not been implemented
yet, however.
</bodyText>
<sectionHeader confidence="0.89565" genericHeader="method">
7. Machine Translation
</sectionHeader>
<bodyText confidence="0.949628125">
Our analysis can be applied in several types of applications. First of all, it serves as the
basis for a coherent analysis of locatives, for example, in that PP complements of both
prepositions and verbs are analyzed in a uniform manner. It also makes the syntax–
semantics interface clean, in implementing the dualistic nature of locatives as referential
and modificational. We believe one of the strengths of this analysis concerns the choice
of the level of representation. In an NLP system where spatial reasoning is required,
one may choose to spell out the details in the analysis, as shown in Section 4.2. In
other NLP applications, the superficial representation is sufficient, and one does not
want to introduce a complex model involving movers, time points, and parameterized
neighborhoods. In this section, we show how our analysis may serve as the best level for
representations in a transfer-based machine translation system, due to the interlingual
nature of the modes.
Kracht (2002) argues that the modes can be found across a wide range of lan-
guages, making them good candidates for true interlingua predicates. The localizer
�
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
</bodyText>
<page confidence="0.958817">
255
</page>
<bodyText confidence="0.941757583333333">
Computational Linguistics Volume 35, Number 2
functions, however, are language-dependent, and there exist different systems for loca-
tives in different languages. Also, whether the particular combination of modalizer
and localizer is lexicalized is language-specific, as we see in Section 7.2. We will
illustrate the flow in a semantic-based transfer MT system from Norwegian to
English, with two examples. The modes are treated as interlingua predicates, whereas
the localizer functions are language-dependent, and thus transferred by the transfer
module. In Section 7.1, we consider an NP transitive preposition, and show how a
mode-disambiguated preposition may translate differently from the mode-ambiguous
preposition. And in Section 7.2, we describe how an intransitive preposition is trans-
lated into a complex PP consisting of a PP transitive preposition and an intransitive
preposition.
</bodyText>
<subsectionHeader confidence="0.997704">
7.1 Translation of an NP Transitive Preposition
</subsectionHeader>
<bodyText confidence="0.999204666666667">
Consider the Norwegian preposition i (in). It is ambiguous between a static and a cofinal
reading, but may be disambiguated by the syntactic context. The translation flow of the
cofinal and ambiguous readings of the locative i (in) are shown in Example (77).
</bodyText>
<equation confidence="0.574198833333333">
icf ist/cf
1 analysis 1 1 analysis 1
{ cf mod(e,l), i loc(l, x) } { st or cf mod(e,l), i loc(l, x) }
(77) 1 transfer 1 1transfer1
{ cf mod(e,l), in loc(l, x) } { st or cf mod(e,l), in loc(l, x) }
1 generation 1 1 generation 1
</equation>
<bodyText confidence="0.519401">
into in
</bodyText>
<subsectionHeader confidence="0.998952">
7.2 Translation of an Intransitive Preposition
</subsectionHeader>
<bodyText confidence="0.998422272727273">
Intransitive locatives, or context-dependent locatives, provide more interesting mis-
matches between Norwegian and English locative expressions. In Table 1 from Sec-
tion 5.1, we see that Norwegian has a rich inventory for expressing context-dependent
spatial relations. One example is the Norwegian locative derfra, as seen in Example (15),
which translates to the English complex from there. These kinds of mismatches are
now easily explained. In Norwegian, we find a lexicalization for the combination
of the coinitial mode and the localizer function der loc (semantically interpreted as
distal, and contrasted by proximal/close). In English, we do not find this lexicalized
preposition, and the two semantic relations (modalizer and localizer, respectively) are
realized as separate lexical items. The translation flow of the locative derfra is shown in
Example (78).
</bodyText>
<page confidence="0.988009">
256
</page>
<figure confidence="0.592954375">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
derfra
1 analysis 1
{ ci mod(e,l), der loc(l) }
(78) 1 transfer 1
{ ci mod(e, l), there loc(l) }
1 generation 1
from there
</figure>
<bodyText confidence="0.921888125">
Translating in the other direction, we also receive a second possible translation:
fra der. This can be blocked, however, if the transfer mechanism allows for rule ordering
where rules can be optional or obligatory, as in the LOGON system (Oepen et al. 2004).
Then the rule choosing derfra is tried first and if it succeeds the other option is blocked.
8. Other Computational Approaches
In Section 2 we considered different linguistic approaches to locatives that were not
computational. We will here compare our approach to earlier computational approaches
with similar goals to ours.
</bodyText>
<subsectionHeader confidence="0.852623">
8.1 Creary et al.
</subsectionHeader>
<bodyText confidence="0.978041818181818">
Creary, Gawron, and Nerbonne (1989) describe a fully implemented system for database
queries. They propose to take locative PPs to be arguments rather than modifiers.
They observe that such an approach must explain occurrences of several PPs as in
Example (79).
(79) Al works on Mass Ave in Boston near MIT.
Their solution is to let each PP denote a region. The denotations of the three PPs are
intersected (as point sets) resulting in one region satisfying all three of them. This region
is then taken as an argument to the semantics of the verb.
Such a solution seems to work for this example. But all the examples in the article
are static PPs. This approach does not so easily extend to directional prepositions
because directional prepositions cannot be taken to denote regions.
</bodyText>
<subsectionHeader confidence="0.992821">
8.2 The Core Language Engine
</subsectionHeader>
<bodyText confidence="0.999814625">
In the Core Language Engine, ordinary PPs are considered modifiers (Alshawi 1992). Se-
mantically, an ordinary preposition is a relation between two arguments, the landmark
object, and the event denoted by the verb in the case of verbal modification. There is no
special treatment of locative prepositions and no distinction is made between directional
and static prepositions. This is in many ways a baseline approach to prepositions in
event-based computational grammars, and we sketched it in Example (69). In addition
to the ordinary PPs, four other classes of PPs are recognized where one is the class of
subcategorized prepositions which are semantically empty, as in handed a book to Mary.
</bodyText>
<page confidence="0.984068">
257
</page>
<note confidence="0.544554">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.911534">
We argued in Section 4.2 for why we think our refined analysis is an improvement over
the baseline approach.
</bodyText>
<subsectionHeader confidence="0.986153">
8.3 VerbMobil
</subsectionHeader>
<bodyText confidence="0.999952461538462">
In VerbMobil the semantics of prepositions are also considered relations between the
landmark and the event (or object) it modifies (Buscbeck-Wolf 1995). Syntactically,
directional PPs may be complements, but they are still considered semantic modifiers.
In addition to relations and arguments, the semantic representations in VerbMobil are
decorated with additional information which is exploited in the transfer step of the
translation. In particular, the representations for PPs and the lexical entries for preposi-
tions contain a feature ROLE as part of the argument (to be) filled by the landmark. This
ROLE can contain information like way rel for directionality, and its negation for static
PPs. In German, this property will correspond to whether the case of the landmark is
accusative or dative.
Though this extra ROLE information may be a useful tool in translation, it lacks
a denotational meaning. Moreover, this approach does not explain how we can make
reference to locations, nor the structure of the PP transitive prepositions.
</bodyText>
<subsectionHeader confidence="0.996936">
8.4 Trujillo’s Spatial Prepositions and Machine Translation
</subsectionHeader>
<bodyText confidence="0.983540695652174">
Trujillo (1995) analyzes locatives in the context of transfer-based machine translation.
He first develops a general format for a flat semantic representation called indexed
lexeme lists, and shows how transfer between English and Spanish can be carried out
on such representations. He then investigates differences in properties between English
and Spanish spatial prepositions, and discusses the proper semantic representation of
locatives and how this can be exploited in translation.
The semantic representations used by Trujillo are quite similar to MRSs and in-
troduce many properties that can also be found in the MRS formalism. One differ-
ence between the two is that indexed lexeme lists lack an equivalent to the scoping
mechanism in MRS, and Copestake et al. (2005) show how this can be a problem for
semantic disambiguation and translation. The MRS formalism can be considered an
improvement over the indexed lexeme lists.
Trujillo does not decompose the prepositions. Syntactically, both static and di-
rectional prepositions are considered adjuncts and semantically they are considered
modifiers. Prepositions denote relations between the event denoted by the verb and
the landmark object. Trujillo observes that prepositions can be stacked as in Exam-
ple (7) from the introduction, repeated as Example (80). He proposes an analysis where
the relevant parts are shown in Example (81) in a notation comparable to ours.
(80) The mouse appeared from under the table.
(81) mouse(x), table(y), appear(e, x), from(p, e, q), under(q, p, y)
As we see, Trujillo lets the prepositions take three arguments. To facilitate a comparison
with our implementation and with the English Resource Grammar in the next section,
we will call the three arguments ARG0, ARG1, and ARG2, respectively; for example, p is
</bodyText>
<page confidence="0.962208">
258
</page>
<bodyText confidence="0.976840526315789">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
the ARG0 of from(p, e, q), e is the ARG1, and q is the ARG2.7 The last two arguments, ARG1
and ARG2, are filled with the event being modified and the landmark, respectively, as
in the Core Language Engine approach. When the two prepositions are combined, the
lower preposition, under, modifies the object which is the ARG0 of from, and at the same
time the object which is the ARG0 of the lower preposition is taken to be the landmark,
the ARG2 of from.
Though this solution might work technically for translation purposes, we have
problems making sense out of the status of these objects. Trujillo (1995, page 172) says
that “these correspond to the place objects that Sondheimer (1978) proposes, although
for the purposes of this thesis they become place holders for spatial relations.” The ERG
also uses a representation with some of the same properties, and we will return to a
more detailed comparison to our proposal in the following section. Trujillo does not
decompose the prepositions, but he classifies the prepositions with respect to different
semantic properties including whether they are static or directional and different di-
rectionality types, and places them in a semantic type hierarchy. We think that such a
type hierarchy might be useful for selecting the translations of the locative part of a
preposition, but from our perspective, this belongs to the lexical semantic properties
and is beyond the scope of this article.
</bodyText>
<subsectionHeader confidence="0.994373">
8.5 The English Resource Grammar
</subsectionHeader>
<bodyText confidence="0.993787142857143">
The English Resource Grammar (Flickinger 2002)8 is similar to our proposal in using
MRS as the semantic formalism in a linguistic-based computational grammar, but the
treatment of locatives is different from ours. Because the ERG treatment of prepositions
is quite elaborate, treating different prepositions in different ways and interleaving the
semantic analysis with the grammar, we will not be able to give a full and fair presen-
tation of the full ERG analysis, but we will try to sketch some of its main properties
regarding locatives, and compare them to our approach.
8.5.1 Prepositions in ERG. In Example (82) we see a simplified logical representation
of the relevant aspects of the MRS representation ERG ascribes to Example (1). The
preposition introduces a relationship between its ARG1, the main event of the sentence,
e1, and its ARG2, the landmark Paris. In addition, prepositions, like verbs, introduce their
own events as an ARG0. This event is used as the main event of sentences where the PP
is used predicatively (Kim is in Paris), but e2 is not used in Example (82). An intransitive
preposition like down also modifies the main event and introduces its own event, as
seen in the ERG analysis of Example (9), shown in Example (83). This analysis is similar
to the ERG analysis of intersective adverbs, like fast. Syntactically, a locative PP can be
adjoined to any kind of VP and modify the VP event. In addition, there is a class of
directional verbs, like go, run, and drive, which can take a locative PP as an argument.
Semantically, however, this is interpreted as modification. Thus even though sentence
(2) gets two different syntactic analyses, they are both ascribed the same semantics (see
Example (84)).
</bodyText>
<equation confidence="0.368332">
(82) sleep(e1, kim) ∧ in(e2, e1, paris)
</equation>
<footnote confidence="0.934741333333333">
7 Trujillo used other names on the features in his implementation.
8 See http://www.delph-in.net/erg. ERG has developed during the time we have worked on this article.
We will here compare to the version of 17-mar-07.
</footnote>
<page confidence="0.9883">
259
</page>
<figure confidence="0.3842124">
Computational Linguistics Volume 35, Number 2
(83) some(x, child(x), run(e1, x) n down(e2, e1))
(84) drive(e1, kim) n into(e2, e1, paris)
(85) mouse(x) n run(e1,x) n under(e2,e1,y) n table(y)
(86) mouse(x) n run(e1, x) n underdir(e2, e1, y) n table(y)
</figure>
<bodyText confidence="0.995772535714286">
Only directional PPs can be arguments to directional verbs. There are three different
types of locative prepositions in ERG. Non-directional prepositions, like at, can head a
PP which is adjoined to a VP, but cannot head a PP which is argument to a directional
verb. Ambiguous prepositions, like in and under, can head PPs that are adjoined to
verbs, as well as PPs that are arguments to directional verbs. The two different syntactic
analyses the grammar ascribes to Example (3) are semantically both considered as event
modification, but the semantic predicate ascribed to the preposition is different in the
two cases. When the PP is argument to the verb the preposition is constrained to be
directional (Example (86)), but not when it is adjoined to the VP (Example (85)). The
third class of prepositions, represented by to, into, and onto, which we would classify as
directional, can head PPs in both types of constructions, but ascribe identical semantics
to the two (Example (84)).
The main differences between ERG and our proposal so far are the following.
ERG does not decompose prepositions semantically. ERG introduces a distinction be-
tween directional and static, but does not distinguish between different modes of
directionality. In ERG there is a correspondence between syntax and directionality, as
PPs that are syntactic arguments of motion verbs have to be read directionally. On
the other hand, unambiguously directional prepositions are also allowed to be non-
arguments and modify any VP. In our analysis, a semantically modifying PP is syn-
tactically always adjoined to the verb. We do not postulate a syntactic ambiguity in
Example (2). And even in semantically ambiguous sentences, like Example (3), we
assign only one syntactic structure and keep the mode underspecified in the syntax–
semantics interface.
8.5.2 Put-Verbs. Example (8) gets the analysis in ERG shown in Example (87). The main
point of the analysis is that put takes two individual arguments, corresponding to the
subject NP and the direct object NP, and one proposition, which again describes a spatial
relationship between two individuals corresponding to the direct object NP and the
complement of the locative preposition.
</bodyText>
<listItem confidence="0.678715">
(87) def(y,book(y),def(z,table(z),put(e1,kim,y,on/onto(e2,y,z))))9
(88) def(y,book(y),def(z,table(z), put(e1, kim, y, l), on(l, z)))
</listItem>
<bodyText confidence="0.999879">
The most likely way to read this semantic representation when the PP is on the table must
be as a resultative. The result of the action is that the relationship on holds between the
book and the table. Exactly the same type of analysis is applied in ERG when the PP is
</bodyText>
<footnote confidence="0.977070666666667">
9 We have simplified the representation a little, by not including the so-called propositional messages
(prpstn m), which is part of the ERG version we compare to, as they are without importance for
the discussion.
</footnote>
<page confidence="0.984432">
260
</page>
<bodyText confidence="0.943306125">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
the unambiguously directional onto the table, that is, now put is a relationship between
the subject, the object, and the proposition expressing that the relationship onto holds
between the book and the table. But what should it mean that the relation onto holds
between the two objects? In our analysis, as discussed in Section 6.7 and illustrated in
Example (88), the verb expresses a relationship between an object and a location directly.
The sentence with onto ends up with exactly the same semantic representation as the
sentence with on.
</bodyText>
<subsubsectionHeader confidence="0.587069">
8.5.3 Alternating Prepositions. When an intransitive preposition is followed by a PP, as
</subsubsectionHeader>
<bodyText confidence="0.997981875">
in Example (10), repeated here as Example (89), ERG provides two different analyses.
The first is that the two locatives both modify the main event, e1, of the sentence inde-
pendently of each other as in Example (90). This analysis corresponds to our analysis
where two PPs modify the same VP (note Example (76) in Section 6.6), presented in
logical form in Example (92). We read the second ERG analysis (Example (91)) as down
modifying the running event. At the same time down introduces its own event e2, and
this event is modified by under the bridge, in the same way as under the bridge would
modify a verb.
</bodyText>
<listItem confidence="0.998416444444445">
(89) A child ran down under the bridge.
(90) some(x, child(x), def(y, bridge(y), run(e1, x) ∧ down(e2, e1) ∧
under(e3, e1, y)))
(91) some(x, child(x), def(y, bridge(y), run(e1, x) ∧ down(e2, e1) ∧
under(e3, e2, y)))
(92) some(x, child(x), def(y, bridge(y), run(e1, x) ∧ cf mod(e1,l1) ∧
down loc(l1) ∧ st mod(e1,l2) ∧ under loc(l2,y)))
(93) some(x, child(x), def(y, bridge(y), run(e1, x) ∧ cf mod(e1,l1) ∧
down loc(l1) ∧ under loc(l1,y)))
</listItem>
<bodyText confidence="0.997298714285714">
We understand this as ERG recognizing the same ambiguity in Example (89) as we do,
and that ERG tries to capture the reading we analyzed as Example (75), presented in
logical form in Example (93), in this way. But it is neither obvious what kind of event
is introduced by down, nor how this event differs from the event introduced by run. We
think there is only one event involved here. In this event the child moves downward
and ends up under the bridge. Hence it is a cofinal movement where the location is
constrained both by down and under the bridge. In the first reading, where the two PPs
modify the VP independently (Example (92)), there is still only one event, but because
the two PPs might have different modes—e.g., down may be cofinal and under the bridge
may be static—two different locations are considered. The cofinal down considers the
location where the movement ends, while the static under considers the location of the
whole event.
Another difference between our approach and ERG is that ERG ascribes the same
two types of analysis to a sentence like Example (94).
</bodyText>
<listItem confidence="0.503727">
(94) A child went down from the bridge.
</listItem>
<page confidence="0.986594">
261
</page>
<note confidence="0.553331">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.654199">
We do not find this sentence ambiguous in the same way as Example (89). We think
it can only mean that both PPs modify the VP. This is the only possible analysis in
our approach, because from the bridge cannot be argument to down, as down in our
grammar only allows static PPs as complements (interpreted as LPs), whereas from is
unambiguously coinitial.
8.5.4 PP Transitive Prepositions. Example (7) gets an analysis like Example (95) in ERG,
and our analysis is presented in Example (96). The analysis in Example (95) resembles
the one in Example (91), namely, from is treated as if it were intransitive and its last
argument place is not filled; the variable u does not occur elsewhere. As with the
analysis in Example (91), we have problems in understanding exactly how the event
e2 in Example (95) is different from the main event e1.
</bodyText>
<equation confidence="0.313108">
(95) some(x, mouse(x), def(y, table(y), appear(e1, x) ∧ from(e2, e1, u) ∧
under(e3, e2, y)))
(96) some(x,mouse(x), def(y,table(y), appear(e1,x) ∧ ci mod(e1,l) ∧
under loc(l,y)))
</equation>
<bodyText confidence="0.427668625">
8.5.5 Lexicalized Locatives. ERG also contains a quite different analysis for some locative
and temporal prepositions and adverbs. We only consider the locative ones here. The
adverb (intransitive preposition) home in Example (97) is analyzed in ERG as a modifier
(adjective) on an individual y which is a definite place (Example (98)). In addition, it in-
troduces the unspec loc-relation which behaves as a preposition, taking the place y as its
landmark (ARG2), modifying the main event of the sentence, e1 (ARG1), and introducing
its own unused event, e2 (ARG0). Also the adjectival modifier home introduces its own
unused ARG0 event.
</bodyText>
<listItem confidence="0.35817925">
(97) The child went home.
(98) def(x,child(x), implicit q(y, place(y) ∧ home(e3,y), go(e1,x) ∧
unspec loc(e2,e1,y)))
(99) def(x, child(x), go(e1, x) ∧ cf mod(e1,l) ∧ home loc(l))
</listItem>
<bodyText confidence="0.600340181818182">
ERG’s lexicalized locatives (Example (98)) bear some similarities to our analysis
(Example (99)) if one considers the individual place y in Example (98) to correspond
to the location l. The unspec loc-relation in ERG corresponds to the modalizer cf mod
in our analysis. But whereas the unspec loc-relation is unrestricted and will represent
any directionality type or static, the modes in our analysis can be constrained by the
lexicon and syntax to only represent a set of possible modes. In this example the mode
will be unambiguously co-final. A more principal difference between ERG and our
analysis is that ERG introduces two quite different analyses of the locative intransi-
tive prepositions (adverbs), the one exemplified by Example (98) and the analysis in
Example (83) of Example (9). We ascribe the same type of analysis to Example (9) and
Example (97).
</bodyText>
<page confidence="0.930835">
262
</page>
<bodyText confidence="0.97397935">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
8.5.6 Consequences for Translation. Our analysis, following Kracht, is meant to be uni-
versal across different languages. A locative expression always has the same form
st/ci/cf/tr/ad(e,l) ∧ “localizer relation”(l,x). Which parts of the sentence contibute
which parts of this representation might vary across languages. In a transfer-based MT
system this means that the mode part will be interlingual, whereas the transfer rules
will cater for the localizer. In spirit, this is quite similar to the treatment of temporal
prepositions in the LOGON system (Oepen et al. 2004). On the ERG analysis, there is no
reason to expect such a parallelism between two languages. What we have classified
as an intransitive use of a locative preposition may be analyzed as either a simple
intersective adverb or as a noun combined with the unspec loc-relation in each of the
two languages. This yields four different types of transfer rules, and which rule type to
invoke for each word pair cannot be predicted without inspecting the relevant lexical
entries in the grammars for the two languages.
Moreover, there is also a third type of analyses of intransitive uses of locatives in
ERG, where the locative introduces an adjective, the noun place (sted in Norwegian),
and an implicit quantifier just like the lexicalized locative in Example (98). But instead
of the unspec loc-rel, it introduces a full transitive preposition, like from or to. This is
illustrated by Example (100) which in the Norwegian LOGON grammar is analyzed as
Example (101).
</bodyText>
<listItem confidence="0.655410666666667">
(100) Barnet gikk herfra.
Child.DEF went here-from.
‘The child went from here.’
(101) def(x,barn(x), def(y, sted(y) ∧ her(e3,y), g˚a(e1,x) ∧ fra(e2, e1, y)))
(102) def(x, child(x), implicit q(y, place(y) ∧ here(e3, y), go(e1, x) ∧
from(e2, e1, y)))
</listItem>
<bodyText confidence="0.999882714285714">
In this case, such an analysis works well for transfer into English because it can be
directly transferred into the representation for from here in Example (102). If we exchange
herfra with hit, a similar analysis of Norwegian would exchange fra with til in Exam-
ple (101). The most natural translation into English would be The child went here, and
one would need yet another transfer type. Thus one might end up with nine different
possible types of transfer relations between intransitive locative prepositions if both
languages allow for the three different types of analyses.
</bodyText>
<subsectionHeader confidence="0.97737">
8.6 NorGram
</subsectionHeader>
<bodyText confidence="0.99994">
NorGram is a computational Lexical Functional Grammar for Norwegian. It has been
extended to produce MRSs, as part of the LOGON system (Oepen et al. 2004).10 The
Norwegian MRSs are used as input to transfer into English MRSs. NorGram follows the
same design principles for MRS constructions for locatives as ERG, but departs from
ERG in the analysis of PP transitive prepositions. If the NorGram analysis had been
</bodyText>
<page confidence="0.8595495">
10 Seehttp://www.emmtee.netfortheLOGONproject.
263
</page>
<note confidence="0.596756">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.931252333333333">
applied to the English sentence in Example (7), we would get the analysis given in
Example (103).
(103) some(x,mouse(x), def(y,table(y), appear(e1,x) ∧ from(e2, e1, e3) ∧
under(e3, u, y)))
On this analysis, the first preposition from is transitive, and it takes the PP under the table,
or rather the event introduced by this preposition, as an argument. In contrast to ERG,
this analysis allows the last argument of a preposition like from to be an event, e3, as well
as an individual. Comparing this to our analysis in Example (96) and observing that e3
plays a similar role as intermediary here as the location l does in our analysis, we can
see some parallels, where from(e2, e1, e3) corresponds to ci mod(e1,l), and under(e3, u, y)
corresponds to under loc(l, y). Seen this way, the NorGram analysis of prepositions can
be thought of as relating the landmark, its ARG2, to both an LP as its ARG0, and an MP
as its ARG1. But the ARG0 and the ARG1 are never both used in the same analysis. This
means that, technically, one could use the NorGram formalism as a surface representa-
tion for these types of constructions and translate into our representation at a deeper
level. But such a translation would not be uniform; other correspondences would have
to be applied for other constructions. Moreover, we think our representation is cleaner
and conceptually clearer. All the introduced variables get used, and have a natural
interpretation in our analysis. In particular, the variable connecting the two parts, l,
is a location, whereas in the NorGram analysis, the connecting variable, is typed as an
event, and it is not clear what kind of denotation could be given to this event.
</bodyText>
<sectionHeader confidence="0.995031" genericHeader="evaluation">
9. Evaluation
</sectionHeader>
<bodyText confidence="0.999992333333333">
Because we have so far only made a pilot implementation of the analysis, it is not
possible to evaluate the grammar directly on a test corpus. The evaluation will therefore
consist of two parts. First, a short corpus study of the LOGON Corpus, in order to
examine the relevance of an analysis of locatives; and second, a description of the most
important dimensions found in the data set, both as a summarization of our approach
and as a brief comparison to ERG and Kracht, and also to construct a small test suite.
</bodyText>
<subsectionHeader confidence="0.961888">
9.1 A Short Corpus Study: The LOGON Corpus
</subsectionHeader>
<bodyText confidence="0.999982888888889">
In order to evaluate the relevance of our analysis of locatives, we have investigated the
distribution of prepositions in the LOGON Corpus. This corpus was developed as part
of the LOGON project, where semantic MRS-based transfer is combined with stochastic
ranking, translating texts from the hiking domain from Norwegian into English (Oepen
et al. 2004).11 The Norwegian part of the LOGON Corpus consists of 2,109 sentences
and 30,348 words. There are 2–3 reference translations into English of the sentences,
and ERG has been adopted to parse the English part. In the Norwegian part, 15.4% of
the word occurrences (4,667) are prepositions. This number is slightly higher than in
the Oslo Corpus12 (13.6%), a balanced corpus of Norwegian texts.
</bodyText>
<footnote confidence="0.952935333333333">
11 See http://www.emmtee.net for the LOGON project, and also http://www.hf.uio.no/tekstlab/
prosjekter/tourist/index.htm for the corpus.
12 http://www.tekstlab.uio.no/norsk/bokmaal/.
</footnote>
<page confidence="0.989523">
264
</page>
<bodyText confidence="0.94681875">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
We have classified the prepositions as being locative or not, and find that about 50%
of these (2,333) are locative. Furthermore, we have classified a subset of about one fifth
of the locative prepositions with respect to syntactic role. We find that approximately
50% are adverbial, approximately 30% are adnominal, and the rest occur in other types
of constructions, for example, predicative, or are difficult to classify. This preliminary
corpus study indicates that our analysis of adverbial locatives are relevant for approxi-
mately 25% of the prepositions occurring in the LOGON Corpus.
</bodyText>
<subsectionHeader confidence="0.984336">
9.2 Data Dimensions
</subsectionHeader>
<bodyText confidence="0.973398033333333">
As a basis for an evaluation of our analysis of locatives, we have gone through the data
found in (Kracht 2002) and the LOGON Corpus. We present the most relevant dimen-
sions herein, and compare them briefly to Kracht and ERG. In addition to motivating a
short test suite for evaluation, this section is also intended to demonstrate the degree to
which we cover the same fragment as Kracht does.
9.2.1 Adjunct Type. Locatives as adjuncts are either adnominal or adverbial. We analyze
adverbial locatives according to the five modes. We do not cover adnominal locatives in
our pilot implementation, and will therefore not include adnominal locatives in the test
suite.
Kracht: Adverbial locatives are analyzed according to the five modes. Adnominal static
locatives are treated similarly to static adverbials, but denote entities and not
events.13
ERG: All locatives in the lexicon are underspecified with respect to denotation type,
and are constrained by unification with the modified element to either an entity
(adnominal) or an event (adverbial).
9.2.2 Directionality. Directional locatives can (in the general case) modify directional
or motion verbs as in Example (t.2), but not static verbs as in Example (t.4). Static
locatives can modify both classes of verbs, as in Examples (t.1) and (t.3). We specify
on the directional prepositions that they only modify directional verbs, whereas static
prepositions can modify all verbs.
(t.1) Musa løp ved buret.
The mouse ran by the cage.
(t.2) Musa løp til buret.
The mouse ran to the cage.
(t.3) Musa satt ved buret.
The mouse sat by the cage.
(t.4) *Musa satt til buret.
*The mouse sat to the cage.
Kracht: Four of the five modes are directional. All modes denote events, but the four
directional modes predicate movement of an event participant, whereas the static
</bodyText>
<page confidence="0.9225735">
13 Directional adnominal locatives are also discussed (Kracht 2002, pages 199–202), but not treated formally.
265
</page>
<note confidence="0.55433">
Computational Linguistics Volume 35, Number 2
</note>
<bodyText confidence="0.958248315789474">
mode locates the event itself. Directional verbs are defined indirectly, in that
directional PPs only modify verbs denoting events that have an eligible mover.14
ERG: Directional prepositions are a subtype of ordinary prepositions. When selected
by a directional verb, the preposition is constrained to be of the directional sub-
type. But all locatives, directional or not, can modify all VPs; hence, for example,
Example (t.4) is accepted.
Note that the distinction between static and directional verbs is hard to make, and
that some verbs, for example, manner of motion verbs, can be coerced to a directional
reading when modified by an explicit directional locative as in Example (t.5). The
directional reading is not available when modified by an ambiguous locative, however
(Examples (t.6 and t.7)).
(t.5) Musa danset inn p˚a bordet.
The mouse danced onto the table.
(t.6) Musa danset p˚ast bordet.
The mouse danced onst the table.
(t.7) *Musa danset p˚acf bordet.
*The mouse danced oncf the table.
Also, this distinction is not only dependent on the inherent verb semantics, but also
affected by the nature of the construction, as in sentences like Example (104).
</bodyText>
<listItem confidence="0.657943">
(104) John smiled his way into the room.
</listItem>
<subsubsectionHeader confidence="0.839843">
9.2.3 Syntactic Role of the PP. The PP may serve as either argument or adjunct. This is a
</subsubsectionHeader>
<bodyText confidence="0.980046166666667">
theoretical distinction, but we have argued that put-verbs serve as good candidates for
verbs taking PP complements. We have also argued that PP arguments may be analyzed
as LPs, and that the complement of put-verbs are best interpreted as locations. Put-verbs
allow static and cofinal locatives, but not coinitial locatives. Thus, we follow Kracht
(2002) in that locatives are generally adjuncts, but may be selected as LPs under certain
circumstances. This is shown in Examples (t.8) and (t.9), where the complement PP is
analyzed as an LP, and where both static and directional (cofinal) locatives are accepted.
(t.8) John la musa p˚ast/cf bordet.
John laid the mouse on/onto the table.
(t.9) *John la musa fra vinduet.
*John laid the mouse from the window.
Kracht: Modificational PPs are adjuncts. Only when the PP is a mandatory argument,
or the selecting head enters a relationship with the LP or NP level of the PP, is the
PP regarded an argument.
ERG: A locative PP can be adjoined to any type of VP. In addition, directional verbs
take directional PPs as arguments. PP arguments of put-verbs may be either
directional or static, as described in Section 8.5. No treatment of location denoting
arguments.
</bodyText>
<page confidence="0.84341">
14 For details about this aspect we refer to the original article (Kracht 2002, pages 219–223).
266
</page>
<note confidence="0.397281">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
</note>
<subsubsectionHeader confidence="0.46733">
9.2.4 PP Transitivity. Norwegian locative prepositions may select PPs (Example (t.10)),
</subsubsectionHeader>
<bodyText confidence="0.927627897435897">
NPs (Example (t.11)), no complement (Example (t.12)) or alternate between no com-
plement and PP selection (Example (t.13)). As the alternating prepositions take optional
complements, they are ambiguous with respect to being the head of a complex PP or
the first of two separate PPs (Example (t.13)). Furthermore, under in Example (t.13)
is three-ways ambiguous with respect to mode (cf. Section 4.2). We also include an
alternating locative (Example (t.14)) where the succeeding PP is blocked from being an
LP complement, because the latter PP is coinitial mode, whereas alternating locatives
only may select static PP complements as LPs.
(t.10) Musa kom fra under bordet.
The mouse appeared from under the table.
(t.11) Musa løp under bordet.
The mouse ran under the table.
(t.12) Musa løp inn.
The mouse ran in.
(t.13) Musa løp ned under bordet.
The mouse ran down under the table.
(t.14) Musa løp ned fra bordet.
The mouse ran down from the table.
Kracht: Discusses PP and NP transitive locatives. PP transitive prepositions are treated
as pure modalizers, where the selected PP is an LP. No treatment of intransitive
and alternating locatives.
ERG: The analysis is discussed more in Section 8.5, where we gave examples of how
ERG handled the different constructions. In particular, ERG does not distinguish
between Examples (t.13) and (t.14) but ascribes the same number of analyses to
them.
9.2.5 Lexical Ambiguity. Locatives exhibit mode ambiguity; recall Example (t.11), where
under has three possible modes as discussed in Section 1 and at the end of Section 4.2.
The mode ambiguity may be resolved by the syntactic context, as we see in Exam-
ple (t.15). We underspecify the modes in the lexicon, and let the syntactic context
disambiguate where possible.
(t.15) Musa satt under bordet.
The mouse sat under the table.
Kracht: Does not treat lexical ambiguity directly.
ERG: Static/underspecified locatives are supertypes of directional locatives. Locatives
are constrained to be directional when selected by a directional verb.
9.2.6 Test Suite. Based on these dimensions, we have constructed a small test suite in
order to summarize and evaluate our approach. The test suite is given in Table 2.
We present the total number of syntactic and semantic analyses produced by ERG.
For our grammar we present the number of syntactic analyses and two numbers for
</bodyText>
<page confidence="0.989362">
267
</page>
<table confidence="0.347562">
Computational Linguistics Volume 35, Number 2
</table>
<tableCaption confidence="0.8261855">
Table 2
Test suite.
</tableCaption>
<table confidence="0.879392611111111">
Our Analyses Correct ERG Analyses
Test Syntactic Semantic Semantic Semantic Syntactic Semantic
Sentence (underspec.) (total) Analyses
1 1 1 1 2 1
1 1 1 1 2 1
1 1 1 1 1 1
0 0 0 0 1 1
0 0 0 1 1 1
(t.6)a 1 1 1 1 1 1
(t.7)b 0 0 0 0 0 0
(t.8) 1 1 1 1 1 1
(t.9) 0 0 0 0 0 0
(t.10) 1 1 1 1 1 1
(t.11) 1 1 3 3c 2 2
(t.12) 1 1 1 1 1 1
(t.13) 2 2 4 2 4 2
(t.14) 1 1 1 1 4 2
(t.15) 1 1 1 1 1 1
</table>
<tableCaption confidence="0.53318675">
a Only static readings are given in this row.
b Only directional readings given in this row.
c ERG does not distinguish between different directional modes. Given ERG’s distinctions the
correct number of analyses is 2.
</tableCaption>
<bodyText confidence="0.998269166666667">
the semantic analyses. The first is the number of different semantic representations
produced by the system. They may be underspecified with respect to mode. The second
number is the number of specified semantic analyses these underspecified analyses
represent. We compare these to what we believe are the correct number of semantic
analyses for each test sentence. We only include the analyses relevant to locatives from
ERG, excluding analyses with non-locative interpretations of the PP, or where one of the
prepositions in a complex locative PP is interpreted as a non-locative (e.g. analyses of
under as a degree specifier in Examples (t.10) and (t.13)).
From the test suite, we see two problems for our analysis. The first is the un-
dergeneration for Example (t.5), as we do not cope with static verbs and directional
modification. This was discussed in Section 9.2.2. The second problem we find in our
analysis of Example (t.13). For the reading where both locatives, ned and under bordet, are
MPs, our analysis takes ned to be cofinal whereas under bordet is ascribed three different
modalities. We do not find good arguments for claiming that this sentence has more
readings than the cofinal+static reading besides the PP transitive reading where the two
PPs are jointly cofinal. We have therefore indicated that the correct number of readings
is 2 in this example. ERG gets a better result in this example because the directional
reading of under is only obtained when under heads a PP which is argument to a
directional verb. Because a directional verb only takes one PP argument, that reading
is not obtainable in this sentence. On the other hand, ERG allows the PP from the table
in Example (t.14) to either modify down or the VP. These two analyses result in two
different semantic representations, which we find hard to motivate. Taking the correct
semantic analyses as our goal we see that our recall is 14/15 and our precision is 14/16,
whereas ERG achieves a recall of 14/14 and a precision of 14/16.
</bodyText>
<page confidence="0.950689">
268
</page>
<bodyText confidence="0.4144">
Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives
</bodyText>
<sectionHeader confidence="0.787576" genericHeader="conclusions">
10. Conclusion
</sectionHeader>
<bodyText confidence="0.9997825">
We have in this article described a treatment of locative prepositional phrases, which
on the one hand is compatible with a compositional formal semantics and on the other
hand is carried out in a framework for efficient computational grammars with an under-
specified semantics. We believe the main strengths of our approach are the following:
</bodyText>
<listItem confidence="0.947967">
1. Uniformity: Our analysis provides a uniform analysis of locatives,
resulting in the same form on the semantic analyses independent of their
syntactic realization.
2. Simplicity: We underspecify both mode ambiguity and the two roles of
prepositions (as modificational or referential), by implementing the
emptiness principle and claiming that any static preposition may serve as
the LP complement of modalizers like from. Only modalizers need two
lexical entries, all other locatives are encoded in a single lexical entry.
3. Denotational Soundness: All our representations have model-theoretic
denotations. The interpretations are intuitively sound. We do not have any
uninstantiated argument places.
</listItem>
<bodyText confidence="0.998503166666667">
Compared to other state-of-the-art approaches, we are able to give a far more
detailed semantic analysis of the locative prepositions, and at the same time preserve
a simple surface representation of the complex semantics of locative prepositions. This
can be used in a translation system where it will distinguish between the mode aspect,
which should be preserved from one language to the other, and the lexicalized locative
expression, which may vary more unsystematically between the two languages.
</bodyText>
<sectionHeader confidence="0.99765" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999947545454545">
We are grateful to our colleagues Stephan
Oepen and Dan Flickinger for many
enlightening discussions, for help
with the LKB system and ERG, and
for useful comments on the article.
Needless to say, they do not agree with
all we are saying and should not be
held responsible for any mistakes. We
are also grateful to the editors of the
special issue and to the reviewers for
their helpful advice.
</bodyText>
<sectionHeader confidence="0.999304" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999921390243902">
Alshawi, Hiyan, editor. 1992. The Core
Language Engine. The MIT Press,
Cambridge, MA.
Bender, Emily M., Dan Flickinger,
and Stephan Oepen. 2002. The
grammar Matrix: An open-source
starter-kit for the rapid development
of cross-linguistically consistent
broad-coverage precision grammars.
In John Carroll, Nelleke Oostdijk, and
Richard Sutcliffe, editors, Proceedings
of the Workshop on Grammar Engineering
and Evaluation at the 19th International
Conference on Computational Linguistics,
pages 8–14, Taiwan.
Bierwisch, Manfred. 1988. On the grammar
of local prepositions. In M. Bierwisch, W.
Motsch, and I. Zimmermann, editors,
Syntax, Semantix und Lexicon. Akademie
Verlag, Berlin, pages 1–65.
Bloom, Paul, Mary A. Peterson, Lynn Nadel,
and Merrill F. Garett, editors. 1996.
Language and Space. The MIT Press,
Cambridge, MA.
Buschbeck-Wolf, Bianka and
Rita N¨ubel. 1995. Die behandlung
¨ubersetzungsambiger pr¨apositionen im
transfer des verbmobil-demonstrators.
Technical Report 87, Verbmobil, IBM,
Heidelberg, Germany.
Copestake, Ann. 2002. Implementing
Typed Feature Structure Grammars.
CSLI Publications, Stanford, CA.
Copestake, Ann, Daniel Flickinger,
Carl Pollard, and Ivan A. Sag. 2005.
Minimal Recursion Semantics: An
introduction. Journal of Research on
Language and Computation, 3(4):281–332.
Copestake, Ann, Alex Lascarides, and
Dan Flickinger. 2001. An algebra for
semantic construction in constraint-based
</reference>
<page confidence="0.948532">
269
</page>
<reference confidence="0.993718804123712">
Computational Linguistics Volume 35, Number 2
grammars. In Proceedings of the 39th Annual
Meeting of the Association for Computational
Linguistics (ACL 2001), pages 132–139,
Toulouse.
Creary, Lewis G., J. Mark Gawron, and John
Nerbonne.1989. Reference to locations. In
Proceedings of the ACL 1989, pages 42–50,
Vancouver.
Flickinger, Dan. 2002. On building a more
efficient grammar by exploiting types. In
Stephan Oepen, Dan Flickinger, Jun-ichi
Tsujii, and Hans Uszkoreit, editors,
Collaborative Language Engineering. A Case
Study in Efficient Grammar-Based Processing,
CSLI Lecture Notes. CSLI Publications,
Stanford, CA, pages 1–17.
Fong, Vivienne. 1997. The Order of Things:
What Directional Locatives Denote. Ph.D.
thesis, Stanford University.
Herskovits, Annette. 1986. Language and
Spatial Cognition. Cambridge University
Press, Cambridge, England.
Hjelmslev, Louis. 1935. La cat´egorie des cas.
Acta Jutlandica, 7:1–184.
Jackendoff, Ray. 1983. Semantics and
Cognition. The MIT Press, Cambridge, MA.
Jackendoff, Ray. 1990. Semantic Structures.
The MIT Press, Cambridge, MA.
Jørgensen, Fredrik. 2004. The Semantic
Representation of Locatives in Machine
Translation. Master’s thesis, University
of Oslo. Available at http://wo.uio.no/
as/WebObjects/theses.woa/wa/these?
WORKID=22120.
Kracht, Marcus. 2002. On the semantics of
locatives. Linguistics and Philosophy,
25:157–232.
Kracht, Markus. 2006. Directionality
selection. In Patrick Saint-Dizier, editor,
Syntax and Semantics of Prepositions,
volume 29 of Text, Speech and Language
Technology. Springer Netherlands,
Dordrecht, pages 101–114.
Levinson, S. C. 1996. Frames of reference
and Molyneux’s question: Cross linguistic
evidence. In Paul Bloom, Mary A.
Peterson, Lynn Nadel, and Merrill F.
Garett, editors, Language and Space.
The MIT Press, Cambridge, MA,
pages 109–169.
Oepen, Stephan, Helge Dyvik, Jan Tore
Lønning, Erik Velldal, Dorothee Beermann,
John Carroll, Dan Flickinger, Lars Hellan,
Janne Bondi Johannessen, Paul Meurer,
Torbjørn Nordg˚ard, and Victoria Ros´en.
2004. Som a˚ kapp-ete med trollet? Towards
MRS-based Norwegian–English Machine
Translation. In Proceedings of the 10th
International Conference on Theoretical and
Methodological Issues in Machine Translation,
pages 11–20, Baltimore, MD.
Pollard, Carl and Ivan Sag. 1994. Head-Driven
Phrase Structure Grammar. University of
Chicago Press, Chicago, IL.
Saint-Dizier, Patrick, editor. 2006. Syntax and
Semantics of Prepositions, volume 29 of Text,
Speech and Language Technology. Springer
Netherlands, Dordrecht.
Trujillo, Arturo. 1995. Lexicalist Machine
Translation of Spatial Prepositions. Ph.D.
thesis, University of Cambridge.
van der Zee, Emile and Jon Slack, editors.
2003. Representing Direction in Language and
Space. Oxford University Press, Oxford.
Zwarts, Joost. 1997. Vectors as relative
positions: A compositional semantics
of modified PPs. Journal of Semantics,
14:57–86.
Zwarts, Joost. 2003a. Paths round a
prototype. In ACL-SIGSEM Workshop: The
Linguistic Dimensions of Prepositions and
their Use in Computational Formalisms and
Applications, pages 228–238, Toulouse.
Zwarts, Joost. 2003b. Vectors across spatial
domains: From place to size, orientation,
shape, and parts. In E. van der Zee and
J. Slack, editors, Representing Direction in
Language and Space. Oxford University
Press, Oxford, pages 39–68.
Zwarts, Joost. 2005. Prepositional aspect
and the algebra of paths. Linguistics and
Philosophy, 28(6):739–779.
Zwarts, Joost and Yoad Winter. 2000.
Vector space semantics: a model-theoretic
analysis of locative prepositions. Journal of
Logic, Language and Information, 9:169–211.
</reference>
<page confidence="0.981861">
270
</page>
<note confidence="0.512553">
This article has been cited by:
</note>
<reference confidence="0.91075575">
1. Timothy Baldwin, Valia Kordoni, Aline Villavicencio. 2009. Prepositions in Applications:
A Survey and Introduction to the Special IssuePrepositions in Applications: A Survey and
Introduction to the Special Issue. Computational Linguistics 35:2, 119-149. [Citation] [PDF]
[PDF Plus]
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.235190">
<title confidence="0.971269">A Minimal Recursion Semantic Analysis</title>
<affiliation confidence="0.7390825">of Locatives University of Oslo Tore University of Oslo</affiliation>
<abstract confidence="0.9769672">The article describes a pilot implementation of a grammar containing different types of locative PPs. In particular, we investigate the distinction between static and directional locatives, and between different types of directional locatives. Locatives may act as modifiers as well as referring expressions depending on the syntactic context. We handle this with a single lexical entry. The implementation is of Norwegian locatives, but English locatives are both discussed and compared to Norwegian locatives. The semantic analysis is based on a proposal by Markus Kracht (2002), and we show how this analysis can be incorporated into Minimal Recursion Semantics (MRS) (Copestake et al. 2005). We discuss how the resulting system may be applied in a transferbased machine translation system, and how we can map from a shallow MRS representation to a deeper semantic representation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>The Core Language Engine.</title>
<date>1992</date>
<editor>Alshawi, Hiyan, editor.</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1992</marker>
<rawString>Alshawi, Hiyan, editor. 1992. The Core Language Engine. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Emily M Bender</author>
<author>Dan Flickinger</author>
<author>Stephan Oepen</author>
</authors>
<title>The grammar Matrix: An open-source starter-kit for the rapid development of cross-linguistically consistent broad-coverage precision grammars. In</title>
<date>2002</date>
<booktitle>Proceedings of the Workshop on Grammar Engineering and Evaluation at the 19th International Conference on Computational Linguistics,</booktitle>
<pages>8--14</pages>
<editor>John Carroll, Nelleke Oostdijk, and Richard Sutcliffe, editors,</editor>
<marker>Bender, Flickinger, Oepen, 2002</marker>
<rawString>Bender, Emily M., Dan Flickinger, and Stephan Oepen. 2002. The grammar Matrix: An open-source starter-kit for the rapid development of cross-linguistically consistent broad-coverage precision grammars. In John Carroll, Nelleke Oostdijk, and Richard Sutcliffe, editors, Proceedings of the Workshop on Grammar Engineering and Evaluation at the 19th International Conference on Computational Linguistics, pages 8–14, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Bierwisch</author>
</authors>
<title>On the grammar of local prepositions.</title>
<date>1988</date>
<booktitle>Syntax, Semantix und Lexicon. Akademie Verlag,</booktitle>
<pages>1--65</pages>
<editor>In M. Bierwisch, W. Motsch, and I. Zimmermann, editors,</editor>
<location>Berlin,</location>
<contexts>
<context position="11932" citStr="Bierwisch (1988)" startWordPosition="1866" endWordPosition="1867">f much of the later work done on locatives. Even though we will focus on languages where locatives are expressed by prepositions in adpositions, and ignore languages where locatives are expressed through inflectional case, it is a point for us to base our approach on formalisms that also extend to languages where locatives are expressed by case. When it comes to the dimensions, directionality is particularly important for the questions we raised in the introduction, while the latter two dimensions relate to lexical semantics, which we will not pursue here. 2.3 Bierwisch’s Grammar of Locatives Bierwisch (1988) gives a detailed account of both syntactic and semantic aspects of locative prepositions in German, and is particularly interested in the relationship between the denotation of locatives (Q1) and the consequences for the syntactic treatment of locatives (Q2). Bierwisch notes that locative PPs serve as predicates (Example (16)), arguments (Example (17)), and modificational adjuncts (Examples (18)–(19)) (examples taken from [1988, page 5]; our translations). (16) Er ist in der Schule. He is in school. (17) Der Brief liegt auf dem Tisch. The letter is lying on the table. (18) Ich kaufe das Buch </context>
<context position="14141" citStr="Bierwisch 1988" startWordPosition="2211" endWordPosition="2212">ss a relation between Hans and a place denoted by im Bett. It is difficult to see, however, how on this account PPs can serve as modifiers or predicatives — unless a place is construed as a property, but that would violate the gist of the referential interpretation. The modificational interpretation, on the other hand, concerns itself with PPs as adjuncts, but seems to be 233 Computational Linguistics Volume 35, Number 2 in trouble with PPs in argument position. From this, one might be tempted to draw the conclusion that both interpretations are partially right and that they both are needed. (Bierwisch 1988, page 8) We will not discuss predicatives in this article, but refer to Kracht (2002) for treatment of adnominal locatives as a property of individuals. The duality with respect to the interpretation of locatives as referential or modificational is central to our article, and we will show, building on Kracht, how this can be handled in a computational grammar. 2.4 Jackendoff’s Conceptual Semantics Ray Jackendoff’s (1983, 1990) conceptual semantics is a decompositional theory of meaning, heavily influenced by X-bar theory. Conceptual semantics organizes a repertoire of major conceptual categor</context>
</contexts>
<marker>Bierwisch, 1988</marker>
<rawString>Bierwisch, Manfred. 1988. On the grammar of local prepositions. In M. Bierwisch, W. Motsch, and I. Zimmermann, editors, Syntax, Semantix und Lexicon. Akademie Verlag, Berlin, pages 1–65.</rawString>
</citation>
<citation valid="true">
<title>Language and Space.</title>
<date>1996</date>
<editor>Bloom, Paul, Mary A. Peterson, Lynn Nadel, and Merrill F. Garett, editors.</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="9053" citStr="[1996]" startWordPosition="1429" endWordPosition="1429">ar prepositions: for example, what geometric relationship between the ball and the cup has to be realized for an expression like the ball is in the cup to be true (e.g., Herskovits 1986)? As interesting as these questions are, we think they belong to the lexicon and the lexical semantic domain and fall outside the scope of this article. There is also interesting work which relates the meaning of individual prepositions to various types of psychological studies; in particular, studies of under which conditions the various prepositions are used (see, e.g., many of the references in Bloom et al. [1996] and in van der Zee and Slack [2003]). But again this plays a complementary role to our work. One particular question in the lexical semantics of prepositions is the distinction between what Zwarts and Winter (2000), following Herskovits (1986), call projective and non-projective prepositions. A non-projective preposition, like outside, requires only spatial knowledge of the location of the two objects, while a projective preposition, like behind, requires some further information about directions from the reference object. Levinson (1996) makes a further distinction between three types of ref</context>
</contexts>
<marker>1996</marker>
<rawString>Bloom, Paul, Mary A. Peterson, Lynn Nadel, and Merrill F. Garett, editors. 1996. Language and Space. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Buschbeck-Wolf</author>
</authors>
<institution>Bianka and</institution>
<marker>Buschbeck-Wolf, </marker>
<rawString>Buschbeck-Wolf, Bianka and</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rita N¨ubel</author>
</authors>
<title>Die behandlung ¨ubersetzungsambiger pr¨apositionen im transfer des verbmobil-demonstrators.</title>
<date>1995</date>
<tech>Technical Report 87,</tech>
<location>Verbmobil, IBM, Heidelberg, Germany.</location>
<marker>N¨ubel, 1995</marker>
<rawString>Rita N¨ubel. 1995. Die behandlung ¨ubersetzungsambiger pr¨apositionen im transfer des verbmobil-demonstrators. Technical Report 87, Verbmobil, IBM, Heidelberg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Implementing Typed Feature Structure Grammars.</title>
<date>2002</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="60918" citStr="Copestake 2002" startWordPosition="10038" endWordPosition="10039">fferent syntactic models. It has in particular been combined with HPSG grammars where it has been used in the large English Resource Grammar (Flickinger 2002). HPSG (Pollard and Sag 1994) is a unification-based non-transformational theory, using multiple inheritance type hierarchies and unification of typed feature structures as central formal mechanisms. The analysis we have presented so far is compatible with different syntactic models. We have made a small fragment of an HPSG grammar to illustrate the analysis. This fragment was implemented in the Linguistic Knowledge Builder (LKB) system (Copestake 2002). The LKB system is an implementation environment for writing HPSG grammars. The grammar was based on the Matrix “starter kit” for building HPSG grammars (Bender, Flickinger, and Oepen 2002). The Matrix contains types for building MRSs as the semantic content of a sentence compositionally. Principles restricting the syntax-semantics interface, as described by Copestake, Lascarides, and Flickinger (2001), are also encoded in the Matrix. For instance, a sign (phrase or word) only exposes its handle, main internal argument, and external argument to the rest of the grammar, such that, for example,</context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>Copestake, Ann. 2002. Implementing Typed Feature Structure Grammars. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Daniel Flickinger</author>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Minimal Recursion Semantics: An introduction.</title>
<date>2005</date>
<journal>Journal of Research on Language and Computation,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="821" citStr="Copestake et al. 2005" startWordPosition="117" endWordPosition="120">ferent types of locative PPs. In particular, we investigate the distinction between static and directional locatives, and between different types of directional locatives. Locatives may act as modifiers as well as referring expressions depending on the syntactic context. We handle this with a single lexical entry. The implementation is of Norwegian locatives, but English locatives are both discussed and compared to Norwegian locatives. The semantic analysis is based on a proposal by Markus Kracht (2002), and we show how this analysis can be incorporated into Minimal Recursion Semantics (MRS) (Copestake et al. 2005). We discuss how the resulting system may be applied in a transferbased machine translation system, and how we can map from a shallow MRS representation to a deeper semantic representation. 1. Introduction Locative prepositional phrases (PPs) pose several puzzles, both to syntax and semantics. First, locatives may be either static (Example (1)), directional (Example (2)), or ambiguous (Example (3)): (1) Kim slept in Paris. (2) Kim is driving into Paris. (3) The mouse ran under the table. As we see, the PP under the table may locate the whole event (Example (4)), it may express the goal of moti</context>
<context position="4980" citStr="Copestake et al. 2005" startWordPosition="791" endWordPosition="794">ian and English. We will not consider locative case systems here, but we will see differences in which locatives are lexicalized as prepositions, as shown in Example (15), where the Norwegian locative derfra is a lexicalization of the corresponding English complex PP from there. (15) Musa kom derfra. Mouse.DEF came there-from. ‘The mouse came from (over) there.’ Our goal in this article consists of three parts. First, we take recent developments within formal semantic approaches to locatives (in particular Kracht 2002) and show how these can be implemented in Minimal Recursion Semantics (MRS; Copestake et al. 2005), a flat and computationally tractable semantic meta-language for first-order logic. Second, we determine the degree to which the insights from this particular approach to locatives can be implemented in a non-transformational, unification-based computational grammar based on HPSG (Pollard and Sag 1994). And third, we investigate what consequences the current analysis has for syntax and the syntax–semantics interface. Our implementation is of a fragment of Norwegian. Norwegian is in many respects similar to English, and where they are similar we will use examples from English. There are also s</context>
<context position="28668" citStr="Copestake et al. 2005" startWordPosition="4579" endWordPosition="4582">racht’s transitory and approximative modes. In addition, neither Jackendoff nor Fong provides a formalized compositional semantics to the same extent as Kracht. Furthermore, we find Kracht’s approach to be of greater cross-linguistic validity, and porting the analysis to languages with locative case or a mix of case and prepositions is therefore possible. For these reasons, we have chosen Kracht’s proposal as the basis for our implementation of locatives. 3. Formal Background In this section, we describe the formal semantic aspects of Kracht’s (2002) proposal, as well as the framework of MRS (Copestake et al. 2005), a meta-level language for logical representations. 3.1 Formal Ontology and Formal Semantics Kracht (2002) argues for his analysis in terms of modalizers and localizers from data— in particular data regarding case—in several typologically different languages. He proposes a formal ontology in which he specifies a formal semantics for the localizers and modalizers, and furthermore shows how the fact that a verb can select an LP or NP can be implemented in a grammar. Along the way he discusses several other phenomena, 238 Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives lik</context>
<context position="40140" citStr="Copestake et al. 2005" startWordPosition="6630" endWordPosition="6633">antics to solve. This analysis has a problem with compositionality, though. In an expression like under the top, the preposition under is interpreted as M+L, and under the top as an MP. We do not have a constituent corresponding to the LP part of under the top, which can be modified by ten meters. Zwarts and Winter’s solution works, on the other hand, because they only consider static PPs, or rather NP-modifying PPs. It remains to show how this can be extended to directional PPs. We will hence ignore such modifiers for the rest of this article. 3.2 Introducing Minimal Recursion Semantics MRS (Copestake et al. 2005) is a framework for semantic representations in large-scale grammars. The main goals for MRS is to be expressively adequate allowing linguistic meaning to be represented properly, to be compatible with other modules in a grammar, to be computational tractable, and to support underspecification. The semantic representations in MRS can be considered a meta-level language for representing an underlying object language which is typically first-order logic with generalized quantifiers. Example (46) is an MRS structure for the sentence in Example (45). The basic building blocks are the elementary pr</context>
<context position="45563" citStr="Copestake et al. 2005" startWordPosition="7525" endWordPosition="7528">acht’s analysis is based on higher order functions and functional application. How can that be ported to a system based on (first-order) predication where composition is built by unification? And how shall the phenomena be described in a grammar? We will work our way top down starting with how MPs are combined with other phrases and then proceed to the inner structure of MPs. We will take as our starting point the large-scale computational English Resource Grammar, ERG (Flickinger 2002),6 an HPSG grammar using MRS as the format for semantic representation (see Flickinger 2002 and Section 6 of Copestake et al. 2005). ERG uses a Davidsonian approach where verbs introduce events, and adverbial intersective modification involves coindexation of the event variables of the verbal relation and the modifier relation. Because Kracht’s approach is also event-based and he considers all adverbial locative PPs (i.e., MPs) as intersective modifiers, the analysis of MPs can be expressed straightforwardly in MRSs and is, in fact, similar to the analysis in ERG. 4.1 MRS Analysis of Modalizer Phrases (MPs) The MP can be represented with an EP containing an event variable. Schematically, the MRS structures in Examples (58</context>
<context position="49698" citStr="Copestake et al. (2005" startWordPosition="8231" endWordPosition="8234">ample (61). The full semantic representation of Example (7) is shown in Example (63). (61) [MP from [LP under [NP the table ] ] ] (62) (h0, h1, {h1: ci mod(e, l), h1: under loc(l, x), {}) (63) [A mouse appeared from under the table]&apos; = (h0, h5, {h1: some(x, h2, h3), h4: mouse(x), h5: appear(e, x), h5: ci mod(e, l), h5: under loc(l, y), h9: def(y, h6, h7), h8: table(y)}, {h0 =q h5, h2 =q h4, h6 =q h8}) For applications, we can convert this simple surface interpretation to Kracht’s deep representations by a simple translation procedure. In this respect we assume a similar approach to that which Copestake et al. (2005, page 312) and ERG take for tense. In ERG, tense is treated as a simple feature on events; there are no variables corresponding to, for example, time points. Copestake et al. argue that such a representation is preferable since it simplifies parsing and generation, and it suffices if it is possible to derive the deeper representation from this representation. Consider our analysis of the MP into Paris in Example (64). The meaning of in loc(l, paris) is that the localizer function corresponding to in maps paris to l. This localizer function is what we saw as IN of type e -4 (i -4 (r - 4t)) in </context>
<context position="81356" citStr="Copestake et al. (2005)" startWordPosition="13587" endWordPosition="13590">ntation called indexed lexeme lists, and shows how transfer between English and Spanish can be carried out on such representations. He then investigates differences in properties between English and Spanish spatial prepositions, and discusses the proper semantic representation of locatives and how this can be exploited in translation. The semantic representations used by Trujillo are quite similar to MRSs and introduce many properties that can also be found in the MRS formalism. One difference between the two is that indexed lexeme lists lack an equivalent to the scoping mechanism in MRS, and Copestake et al. (2005) show how this can be a problem for semantic disambiguation and translation. The MRS formalism can be considered an improvement over the indexed lexeme lists. Trujillo does not decompose the prepositions. Syntactically, both static and directional prepositions are considered adjuncts and semantically they are considered modifiers. Prepositions denote relations between the event denoted by the verb and the landmark object. Trujillo observes that prepositions can be stacked as in Example (7) from the introduction, repeated as Example (80). He proposes an analysis where the relevant parts are sho</context>
</contexts>
<marker>Copestake, Flickinger, Pollard, Sag, 2005</marker>
<rawString>Copestake, Ann, Daniel Flickinger, Carl Pollard, and Ivan A. Sag. 2005. Minimal Recursion Semantics: An introduction. Journal of Research on Language and Computation, 3(4):281–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Alex Lascarides</author>
<author>Dan Flickinger</author>
</authors>
<title>An algebra for semantic construction in constraint-based Computational Linguistics Volume 35, Number 2 grammars.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>132--139</pages>
<location>Toulouse.</location>
<marker>Copestake, Lascarides, Flickinger, 2001</marker>
<rawString>Copestake, Ann, Alex Lascarides, and Dan Flickinger. 2001. An algebra for semantic construction in constraint-based Computational Linguistics Volume 35, Number 2 grammars. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL 2001), pages 132–139, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lewis G Creary</author>
<author>J Mark Gawron</author>
<author>John Nerbonne 1989</author>
</authors>
<title>Reference to locations.</title>
<date>1989</date>
<booktitle>In Proceedings of the ACL</booktitle>
<pages>42--50</pages>
<location>Vancouver.</location>
<marker>Creary, Gawron, 1989, 1989</marker>
<rawString>Creary, Lewis G., J. Mark Gawron, and John Nerbonne.1989. Reference to locations. In Proceedings of the ACL 1989, pages 42–50, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2002</date>
<booktitle>Collaborative Language Engineering. A Case Study in Efficient Grammar-Based Processing, CSLI Lecture Notes. CSLI Publications,</booktitle>
<pages>1--17</pages>
<editor>In Stephan Oepen, Dan Flickinger, Jun-ichi Tsujii, and Hans Uszkoreit, editors,</editor>
<location>Stanford, CA,</location>
<contexts>
<context position="45432" citStr="Flickinger 2002" startWordPosition="7505" endWordPosition="7506">(56) (h0, h5, {h5: cat(x)}, {}) (57) (h0, h1, {h2: every(x, h3, h4), h5: cat(x)}, {h3 =q h5}) 4. MRS Analysis of Locatives Kracht’s analysis is based on higher order functions and functional application. How can that be ported to a system based on (first-order) predication where composition is built by unification? And how shall the phenomena be described in a grammar? We will work our way top down starting with how MPs are combined with other phrases and then proceed to the inner structure of MPs. We will take as our starting point the large-scale computational English Resource Grammar, ERG (Flickinger 2002),6 an HPSG grammar using MRS as the format for semantic representation (see Flickinger 2002 and Section 6 of Copestake et al. 2005). ERG uses a Davidsonian approach where verbs introduce events, and adverbial intersective modification involves coindexation of the event variables of the verbal relation and the modifier relation. Because Kracht’s approach is also event-based and he considers all adverbial locative PPs (i.e., MPs) as intersective modifiers, the analysis of MPs can be expressed straightforwardly in MRSs and is, in fact, similar to the analysis in ERG. 4.1 MRS Analysis of Modalizer</context>
<context position="60461" citStr="Flickinger 2002" startWordPosition="9971" endWordPosition="9972">c(l), h5: i loc(l, y), h8: hull(y) ... 6. Implementation In this section, we first describe the framework the grammar was implemented in. We then proceed to describing the classes of locative prepositions described in Section 5. The implementation of Kracht’s (2002) emptiness principle will be central to our grammar. 6.1 Framework for the Implementation MRS is a general format for representing different formal object languages and may be combined with different syntactic models. It has in particular been combined with HPSG grammars where it has been used in the large English Resource Grammar (Flickinger 2002). HPSG (Pollard and Sag 1994) is a unification-based non-transformational theory, using multiple inheritance type hierarchies and unification of typed feature structures as central formal mechanisms. The analysis we have presented so far is compatible with different syntactic models. We have made a small fragment of an HPSG grammar to illustrate the analysis. This fragment was implemented in the Linguistic Knowledge Builder (LKB) system (Copestake 2002). The LKB system is an implementation environment for writing HPSG grammars. The grammar was based on the Matrix “starter kit” for building HPS</context>
<context position="83983" citStr="Flickinger 2002" startWordPosition="14010" endWordPosition="14011">to our proposal in the following section. Trujillo does not decompose the prepositions, but he classifies the prepositions with respect to different semantic properties including whether they are static or directional and different directionality types, and places them in a semantic type hierarchy. We think that such a type hierarchy might be useful for selecting the translations of the locative part of a preposition, but from our perspective, this belongs to the lexical semantic properties and is beyond the scope of this article. 8.5 The English Resource Grammar The English Resource Grammar (Flickinger 2002)8 is similar to our proposal in using MRS as the semantic formalism in a linguistic-based computational grammar, but the treatment of locatives is different from ours. Because the ERG treatment of prepositions is quite elaborate, treating different prepositions in different ways and interleaving the semantic analysis with the grammar, we will not be able to give a full and fair presentation of the full ERG analysis, but we will try to sketch some of its main properties regarding locatives, and compare them to our approach. 8.5.1 Prepositions in ERG. In Example (82) we see a simplified logical </context>
</contexts>
<marker>Flickinger, 2002</marker>
<rawString>Flickinger, Dan. 2002. On building a more efficient grammar by exploiting types. In Stephan Oepen, Dan Flickinger, Jun-ichi Tsujii, and Hans Uszkoreit, editors, Collaborative Language Engineering. A Case Study in Efficient Grammar-Based Processing, CSLI Lecture Notes. CSLI Publications, Stanford, CA, pages 1–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivienne Fong</author>
</authors>
<title>The Order of Things: What Directional Locatives Denote.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="18881" citStr="Fong (1997)" startWordPosition="2980" endWordPosition="2981"> (whether it is the event or its participants being located) governs the syntactic analysis (whether the construction is analyzed as an adjunct or a complement). There are of course different syntactic restrictions on what kind of verbs static and directional PPs can modify, but this applies to many modifying PPs, and is not in itself sufficient to warrant different syntactic analyses. We believe that a uniform treatment of locatives, giving the same syntactic analysis independent of directionality, would provide a more sound and consistent analysis. 2.5 Fong’s Directionals as Diphasic Events Fong (1997) analyzes directional locatives. She focuses on the locative cases of Finnish, but includes comparisons to other languages, including English. Her main focus of interest is on how directional locative case in Finnish and directional prepositions in English can be used when there is no movement involved. In Finnish one uses expressions which literally when translated into English would become forgot my wallet into my car, and in English we have formulations like a bridge from Buda to Pest. Whereas other approaches take the spatial use as basic, and consider the more abstract uses as derived, Fo</context>
</contexts>
<marker>Fong, 1997</marker>
<rawString>Fong, Vivienne. 1997. The Order of Things: What Directional Locatives Denote. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annette Herskovits</author>
</authors>
<title>Language and Spatial Cognition.</title>
<date>1986</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England.</location>
<contexts>
<context position="8633" citStr="Herskovits 1986" startWordPosition="1360" endWordPosition="1361">ome additional machinery is introduced to map the location to a property. Q3. How is the distinction between static and directional locatives handled? Static and directional locatives differ both in syntactic distribution and truth conditions, and as we have observed, occurrences of locatives may be ambiguous between the two. A prominent question in the literature on locative prepositions is the geometric structure of particular prepositions: for example, what geometric relationship between the ball and the cup has to be realized for an expression like the ball is in the cup to be true (e.g., Herskovits 1986)? As interesting as these questions are, we think they belong to the lexicon and the lexical semantic domain and fall outside the scope of this article. There is also interesting work which relates the meaning of individual prepositions to various types of psychological studies; in particular, studies of under which conditions the various prepositions are used (see, e.g., many of the references in Bloom et al. [1996] and in van der Zee and Slack [2003]). But again this plays a complementary role to our work. One particular question in the lexical semantics of prepositions is the distinction be</context>
</contexts>
<marker>Herskovits, 1986</marker>
<rawString>Herskovits, Annette. 1986. Language and Spatial Cognition. Cambridge University Press, Cambridge, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Louis Hjelmslev</author>
</authors>
<title>La cat´egorie des cas.</title>
<date>1935</date>
<journal>Acta Jutlandica,</journal>
<pages>7--1</pages>
<marker>Hjelmslev, 1935</marker>
<rawString>Hjelmslev, Louis. 1935. La cat´egorie des cas. Acta Jutlandica, 7:1–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>Semantics and Cognition.</title>
<date>1983</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Jackendoff, 1983</marker>
<rawString>Jackendoff, Ray. 1983. Semantics and Cognition. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>Semantic Structures.</title>
<date>1990</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="15765" citStr="Jackendoff (1990" startWordPosition="2473" endWordPosition="2474">ic and directional locatives (Q1/Q3), and how they combine with verbs (Q2). The LCSs of static locatives are claimed to have one layer, a Place function (Example (20)), as opposed to the LCS of directional locatives, which have two layers, a Path function as the outer function, and a Place function as the inner function (Example (21)). According to Jackendoff, there are five different Path functions: TO, FROM, TOWARD, AWAY-FROM, and VIA. These map from a Place to a Path. (20) �in 1 � �P � �NPj [Place IN ( [Thing ]j) ] (21) �into � �P � �NPj [Path TO ( [Place IN ( [Thing ]j) ] ) ] Furthermore, Jackendoff (1990, page 45) treats directional locatives as arguments to motion verbs, such that, for example, run subcategorizes for an optional directional locative argument (Q2), where the optionality is represented with angle brackets, note the LCS for run given in Example (22). In the analysis of Example (23) the optional PP argument of run is coindexed with the PP into the room. Through co-indexing (j) this results in the conceptual structure in Example (24), where the path denoted by the PP enters into the function GO(subject entity, path) and thereby expresses the traversing of the path. By convention,</context>
<context position="27733" citStr="Jackendoff (1990)" startWordPosition="4445" endWordPosition="4446">he constituent C. Suppose further that the presence of X in C is determined purely by non-semantic rules (for example selection, agreement, Sandhi). Then the meaning of X is empty, namely the identity function. (Kracht 2002, page 204) Thus, we end up with a theory that explains both the dualistic nature of prepositions semantically, and how the two-layering interacts with the syntax. 2.8 Summary In this section, we have looked at several theories on locatives. These theories each have a different focus and different goals. Returning to our initial questions, we see that both Kracht (2002) and Jackendoff (1990) preserve the two-layered nature of locatives. But where Kracht’s solution allow directional locatives to be modificational adjuncts, Jackendoff is committed to treating directionals as referential complements of motion verbs. Furthermore, Fong’s (1997) diphasic events are insufficient to capture the nature of Kracht’s transitory and approximative modes. In addition, neither Jackendoff nor Fong provides a formalized compositional semantics to the same extent as Kracht. Furthermore, we find Kracht’s approach to be of greater cross-linguistic validity, and porting the analysis to languages with </context>
</contexts>
<marker>Jackendoff, 1990</marker>
<rawString>Jackendoff, Ray. 1990. Semantic Structures. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fredrik Jørgensen</author>
</authors>
<title>The Semantic Representation of Locatives in Machine Translation. Master’s thesis,</title>
<date>2004</date>
<institution>University of Oslo.</institution>
<note>Available at http://wo.uio.no/ as/WebObjects/theses.woa/wa/these? WORKID=22120.</note>
<contexts>
<context position="61954" citStr="Jørgensen (2004)" startWordPosition="10199" endWordPosition="10200">oded in the Matrix. For instance, a sign (phrase or word) only exposes its handle, main internal argument, and external argument to the rest of the grammar, such that, for example, a verb cannot control the arguments of its complement. The description of the grammar 249 Computational Linguistics Volume 35, Number 2 presented here deviates somewhat from the Matrix, in order to improve readability. We also only present the relevant features of the grammar, as the actual descriptions of the signs in the grammar are quite complex, having to deal with many other aspects of the grammar. We refer to Jørgensen (2004) for details of the implementation. 6.2 Goals We want our implementation to give the correct syntactic and semantic (MRS) analyses, while having minimal redundancy in the lexicon. We furthermore want to underspecify ambiguities wherever possible. Corresponding loosely to questions Q1–Q3 in Section 2, we need to consider the following dimensions that serve as the guidelines for the grammar presented here: 1. Modalizer+Localizer/Localizer: Locative prepositions must have the ability to denote sets of events (i.e., serving as M+L) and denote locations (L), depending on the syntactic context. 2. A</context>
</contexts>
<marker>Jørgensen, 2004</marker>
<rawString>Jørgensen, Fredrik. 2004. The Semantic Representation of Locatives in Machine Translation. Master’s thesis, University of Oslo. Available at http://wo.uio.no/ as/WebObjects/theses.woa/wa/these? WORKID=22120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcus Kracht</author>
</authors>
<title>On the semantics of locatives.</title>
<date>2002</date>
<journal>Linguistics and Philosophy,</journal>
<pages>25--157</pages>
<contexts>
<context position="707" citStr="Kracht (2002)" startWordPosition="101" endWordPosition="102">ore Lønning** University of Oslo The article describes a pilot implementation of a grammar containing different types of locative PPs. In particular, we investigate the distinction between static and directional locatives, and between different types of directional locatives. Locatives may act as modifiers as well as referring expressions depending on the syntactic context. We handle this with a single lexical entry. The implementation is of Norwegian locatives, but English locatives are both discussed and compared to Norwegian locatives. The semantic analysis is based on a proposal by Markus Kracht (2002), and we show how this analysis can be incorporated into Minimal Recursion Semantics (MRS) (Copestake et al. 2005). We discuss how the resulting system may be applied in a transferbased machine translation system, and how we can map from a shallow MRS representation to a deeper semantic representation. 1. Introduction Locative prepositional phrases (PPs) pose several puzzles, both to syntax and semantics. First, locatives may be either static (Example (1)), directional (Example (2)), or ambiguous (Example (3)): (1) Kim slept in Paris. (2) Kim is driving into Paris. (3) The mouse ran under the </context>
<context position="4882" citStr="Kracht 2002" startWordPosition="777" endWordPosition="778">tions to express locatives. The focus of this article is locative prepositions in Norwegian and English. We will not consider locative case systems here, but we will see differences in which locatives are lexicalized as prepositions, as shown in Example (15), where the Norwegian locative derfra is a lexicalization of the corresponding English complex PP from there. (15) Musa kom derfra. Mouse.DEF came there-from. ‘The mouse came from (over) there.’ Our goal in this article consists of three parts. First, we take recent developments within formal semantic approaches to locatives (in particular Kracht 2002) and show how these can be implemented in Minimal Recursion Semantics (MRS; Copestake et al. 2005), a flat and computationally tractable semantic meta-language for first-order logic. Second, we determine the degree to which the insights from this particular approach to locatives can be implemented in a non-transformational, unification-based computational grammar based on HPSG (Pollard and Sag 1994). And third, we investigate what consequences the current analysis has for syntax and the syntax–semantics interface. Our implementation is of a fragment of Norwegian. Norwegian is in many respects </context>
<context position="14227" citStr="Kracht (2002)" startWordPosition="2226" endWordPosition="2227">ver, how on this account PPs can serve as modifiers or predicatives — unless a place is construed as a property, but that would violate the gist of the referential interpretation. The modificational interpretation, on the other hand, concerns itself with PPs as adjuncts, but seems to be 233 Computational Linguistics Volume 35, Number 2 in trouble with PPs in argument position. From this, one might be tempted to draw the conclusion that both interpretations are partially right and that they both are needed. (Bierwisch 1988, page 8) We will not discuss predicatives in this article, but refer to Kracht (2002) for treatment of adnominal locatives as a property of individuals. The duality with respect to the interpretation of locatives as referential or modificational is central to our article, and we will show, building on Kracht, how this can be handled in a computational grammar. 2.4 Jackendoff’s Conceptual Semantics Ray Jackendoff’s (1983, 1990) conceptual semantics is a decompositional theory of meaning, heavily influenced by X-bar theory. Conceptual semantics organizes a repertoire of major conceptual categories, the semantic parts of speech, into function– argument structures. Lexical entries</context>
<context position="20169" citStr="Kracht (2002)" startWordPosition="3199" endWordPosition="3200">. It has a more abstract meaning, and can be used when there is an underlying ordered domain, together with a proposition changing truth value, either from false to true or from true to false along the ordering. This abstract structure can be mapped to a more concrete structure, including space in English, and space or time in Finnish. Thus in Example (25) there is an ordering in space such that Example (26) is false at the beginning of this ordering, and true towards the end of the ordering. (25) He went into the room. (26) He is in the room. 235 Computational Linguistics Volume 35, Number 2 Kracht (2002) compares his approach to Fong’s. One problem is that Fong’s approach does not extend to the VIA-reading (in Jackendoff’s terminology) of sentences like Example (3). From our point of view, it is also a point that she does not describe a compositional analysis. Also our focus in this article is strictly on the spatial readings of the locatives. 2.6 Zwarts’s Vector Space Semantics In a series of papers, Zwarts (1997, 2003a, 2003b, 2005; Zwarts and Winter 2000) has developed a semantics for locatives based on vectors. A main motivation for this proposal is the observation that locatives may be m</context>
<context position="23892" citStr="Kracht (2002)" startWordPosition="3822" endWordPosition="3823">here John successfully traverses their endpoints, and where the last vector also has the store as its endpoint. Intuitively this is a correct description, but Zwarts (2003b, 2005) does not show how this can be handled in a compositional grammar. It is a particular problem for a compositional treatment that static PPs and directional PPs are ascribed denotations of different types, unless they are also given different syntactic analyses (cf. discussion on Jackendoff in Section 2.4). 236 Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives 2.7 Kracht’s Two-Layered Locatives In Kracht (2002), a novel approach to the semantics of locatives is described. Kracht presents a solution to Bierwisch’s (1988) problem of the duality of locatives, by claiming that locatives consist of two layers (Q1/Q2). The lower layer, called a localizer phrase (LP), defines a region or location, while the higher layer, called a modalizer phrase (MP), defines events of motion with respect to this region (Q1). Both from a semantic and syntactic point of view, Kracht claims a locative expression is structured as [MP M [LP L NP]]. Here, L is a localizer which together with the NP forms an LP whose semantic c</context>
<context position="26003" citStr="Kracht (2002)" startWordPosition="4169" endWordPosition="4170">ample (7), corresponding to: MP M LP L NP from under ... MPs denote sets of events, and their syntactic function is that of adverbial modification. The data Kracht discusses give support for five different types of modalizers or modes, which are the heads of the MPs, denoting five different types of events.1 Thus, if Kracht is right, the modes are true semantical interlingua predicates. The modes are: 1. static (st), corresponding to Jackendoff’s Place Function 2. coinitial (ci), corresponding to Jackendoff’s Path Function FROM 3. cofinal (cf), corresponding to Jackendoff’s Path Function TO 1 Kracht (2002) also mentions a sixth mode, the recessive mode, corresponding to Jackendoff’s AWAY-FROM. But the data he discusses do not sufficiently support the existence of this mode. 237 Computational Linguistics Volume 35, Number 2 4. transitory (tr), corresponding to Jackendoff’s Path Function VIA 5. approximative (ap), corresponding to Jackendoff’s Path Function TOWARDS Kracht also claims that LPs only occur in restricted contexts, for example, as a complement selected by a verb or a preposition. The LP denotes a location, and the head of an LP is a localizer function, which defines a location in rela</context>
<context position="27339" citStr="Kracht 2002" startWordPosition="4382" endWordPosition="4383"> only interact with the LP semantically. In other words, the verb takes a location as the semantic argument. This is explained in more detail by Kracht (2006). The principle governing this particular verb–PP interaction is called the Emptiness Principle (where X corresponds to a preposition, and C to a PP for our purposes): Emptiness Principle. Suppose that X is a syntactic marker in the constituent C. Suppose further that the presence of X in C is determined purely by non-semantic rules (for example selection, agreement, Sandhi). Then the meaning of X is empty, namely the identity function. (Kracht 2002, page 204) Thus, we end up with a theory that explains both the dualistic nature of prepositions semantically, and how the two-layering interacts with the syntax. 2.8 Summary In this section, we have looked at several theories on locatives. These theories each have a different focus and different goals. Returning to our initial questions, we see that both Kracht (2002) and Jackendoff (1990) preserve the two-layered nature of locatives. But where Kracht’s solution allow directional locatives to be modificational adjuncts, Jackendoff is committed to treating directionals as referential compleme</context>
<context position="28775" citStr="Kracht (2002)" startWordPosition="4595" endWordPosition="4596">onal semantics to the same extent as Kracht. Furthermore, we find Kracht’s approach to be of greater cross-linguistic validity, and porting the analysis to languages with locative case or a mix of case and prepositions is therefore possible. For these reasons, we have chosen Kracht’s proposal as the basis for our implementation of locatives. 3. Formal Background In this section, we describe the formal semantic aspects of Kracht’s (2002) proposal, as well as the framework of MRS (Copestake et al. 2005), a meta-level language for logical representations. 3.1 Formal Ontology and Formal Semantics Kracht (2002) argues for his analysis in terms of modalizers and localizers from data— in particular data regarding case—in several typologically different languages. He proposes a formal ontology in which he specifies a formal semantics for the localizers and modalizers, and furthermore shows how the fact that a verb can select an LP or NP can be implemented in a grammar. Along the way he discusses several other phenomena, 238 Jørgensen and Lønning Minimal Recursion Semantic Analysis of Locatives like the lexical meaning of the different localizers, with varying degrees of rigor. We will not have much to </context>
<context position="38339" citStr="Kracht (2002)" startWordPosition="6309" endWordPosition="6310">nt e, the location of e belongs to L. 3.1.1 Comparing Kracht’s and Zwarts’ Proposals. In Section 2, we compared Kracht’s proposal briefly with some of the earlier proposals from the literature. Having the formal apparatus on board, we will now compare it in more detail to Zwarts and Winter’s (2000) proposal, to investigate if and how the two approaches can be combined. One possibility is to try to merge the two proposals. We may extend Kracht’s semantics with 4 Kracht uses the same function for LOC and LOCv, but we have simplified a little as it does not matter for our purposes. 5 We refer to Kracht (2002) for the details of the calculations and functions in Examples (36)–(42). 241 Computational Linguistics Volume 35, Number 2 vectors and let p be the type of vectors instead of points. The domain of regions, Dr would still be a subset of D(p→t). A set of vectors would be a region if the set of endpoints of the vectors is a path-connected set of points, and so forth. Zwarts and Winter’s treatment of modification as intersection, as in ten meters above the house, can be reconstructed within this framework if we consider it as LPmodification. This means that ten meters, which intuitively is a set </context>
<context position="55247" citStr="Kracht (2002)" startWordPosition="9115" endWordPosition="9116">idates. Note that all these prepositions also occur with NP complements. 2. NP transitive. These take NP complements. All ordinary prepositions fall into this class. 3. Intransitive. These take no complements, and are semantically equivalent to a full PP with a contextually determined location. Examples are her (herest), hit (herecf), inne (insidest), inn (insidecf), and innenfra (from inside). Furthermore, the analysis we propose is decompositional, and we classify locatives semantically along the modalizer and localizer dimensions. The modalizer dimension seems to have an upper boundary, as Kracht (2002) claims to have found evidence for five modalizers. The localizer dimension has in principle no upper boundary. In Table 1, we show how the different types of locatives are distributed over the localizer and modalizer dimensions. Prepositions in the same column share modalizer, and prepositions in the same row share localizer. For each Norwegian locative, the corresponding English locative is listed in parentheses. Recall that prepositions can function as heads of MPs and LPs. For Norwegian and English, there is a general correspondence between the prepositions being heads of static MPs and be</context>
</contexts>
<marker>Kracht, 2002</marker>
<rawString>Kracht, Marcus. 2002. On the semantics of locatives. Linguistics and Philosophy, 25:157–232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Kracht</author>
</authors>
<title>Directionality selection.</title>
<date>2006</date>
<booktitle>Syntax and Semantics of Prepositions,</booktitle>
<volume>29</volume>
<pages>101--114</pages>
<editor>In Patrick Saint-Dizier, editor,</editor>
<publisher>Springer</publisher>
<location>Netherlands, Dordrecht,</location>
<marker>Kracht, 2006</marker>
<rawString>Kracht, Markus. 2006. Directionality selection. In Patrick Saint-Dizier, editor, Syntax and Semantics of Prepositions, volume 29 of Text, Speech and Language Technology. Springer Netherlands, Dordrecht, pages 101–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Levinson</author>
</authors>
<title>Frames of reference and Molyneux’s question: Cross linguistic evidence.</title>
<date>1996</date>
<editor>In Paul Bloom, Mary A. Peterson, Lynn Nadel, and Merrill F. Garett, editors, Language and Space.</editor>
<contexts>
<context position="9598" citStr="Levinson (1996)" startWordPosition="1506" endWordPosition="1507">ons are used (see, e.g., many of the references in Bloom et al. [1996] and in van der Zee and Slack [2003]). But again this plays a complementary role to our work. One particular question in the lexical semantics of prepositions is the distinction between what Zwarts and Winter (2000), following Herskovits (1986), call projective and non-projective prepositions. A non-projective preposition, like outside, requires only spatial knowledge of the location of the two objects, while a projective preposition, like behind, requires some further information about directions from the reference object. Levinson (1996) makes a further distinction between three types of reference frames called (i) intrinsic, where behind the house means on the other side of the house than what would be classified as the front side of the house, (ii) extrinsic, where behind the house is on the opposite side of the house than the speaker, and (iii) absolute, which applies to expressions like north of the house. We also think that these distinctions belong to the lexical semantic domain. 2.2 Hjelmslev’s Theory of Cases One of the earliest contributions to the study of locatives is Hjelmslev’s (1935) theory of cases. Hjelmslev v</context>
</contexts>
<marker>Levinson, 1996</marker>
<rawString>Levinson, S. C. 1996. Frames of reference and Molyneux’s question: Cross linguistic evidence. In Paul Bloom, Mary A. Peterson, Lynn Nadel, and Merrill F. Garett, editors, Language and Space.</rawString>
</citation>
<citation valid="false">
<pages>109--169</pages>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA,</location>
<marker></marker>
<rawString>The MIT Press, Cambridge, MA, pages 109–169.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stephan Oepen</author>
<author>Helge Dyvik</author>
<author>Jan Tore Lønning</author>
<author>Erik Velldal</author>
<author>Dorothee Beermann</author>
<author>John Carroll</author>
<author>Dan Flickinger</author>
<author>Lars Hellan</author>
<author>Janne Bondi Johannessen</author>
<author>Paul Meurer</author>
<author>Torbjørn Nordg˚ard</author>
<author>Victoria Ros´en</author>
</authors>
<title>Som a˚ kapp-ete med trollet? Towards MRS-based Norwegian–English Machine Translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>11--20</pages>
<location>Baltimore, MD.</location>
<marker>Oepen, Dyvik, Lønning, Velldal, Beermann, Carroll, Flickinger, Hellan, Johannessen, Meurer, Nordg˚ard, Ros´en, 2004</marker>
<rawString>Oepen, Stephan, Helge Dyvik, Jan Tore Lønning, Erik Velldal, Dorothee Beermann, John Carroll, Dan Flickinger, Lars Hellan, Janne Bondi Johannessen, Paul Meurer, Torbjørn Nordg˚ard, and Victoria Ros´en. 2004. Som a˚ kapp-ete med trollet? Towards MRS-based Norwegian–English Machine Translation. In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation, pages 11–20, Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, IL.</location>
<contexts>
<context position="5284" citStr="Pollard and Sag 1994" startWordPosition="833" endWordPosition="836">se.DEF came there-from. ‘The mouse came from (over) there.’ Our goal in this article consists of three parts. First, we take recent developments within formal semantic approaches to locatives (in particular Kracht 2002) and show how these can be implemented in Minimal Recursion Semantics (MRS; Copestake et al. 2005), a flat and computationally tractable semantic meta-language for first-order logic. Second, we determine the degree to which the insights from this particular approach to locatives can be implemented in a non-transformational, unification-based computational grammar based on HPSG (Pollard and Sag 1994). And third, we investigate what consequences the current analysis has for syntax and the syntax–semantics interface. Our implementation is of a fragment of Norwegian. Norwegian is in many respects similar to English, and where they are similar we will use examples from English. There are also some interesting differences, and we will use them to illustrate how the new representations can be exploited in an experimental semantic transfer-based machine translation system, like the LOGON system (Oepen et al. 2004), which uses transfer representations based on MRS. The rest of the article is orga</context>
<context position="60490" citStr="Pollard and Sag 1994" startWordPosition="9974" endWordPosition="9977">8: hull(y) ... 6. Implementation In this section, we first describe the framework the grammar was implemented in. We then proceed to describing the classes of locative prepositions described in Section 5. The implementation of Kracht’s (2002) emptiness principle will be central to our grammar. 6.1 Framework for the Implementation MRS is a general format for representing different formal object languages and may be combined with different syntactic models. It has in particular been combined with HPSG grammars where it has been used in the large English Resource Grammar (Flickinger 2002). HPSG (Pollard and Sag 1994) is a unification-based non-transformational theory, using multiple inheritance type hierarchies and unification of typed feature structures as central formal mechanisms. The analysis we have presented so far is compatible with different syntactic models. We have made a small fragment of an HPSG grammar to illustrate the analysis. This fragment was implemented in the Linguistic Knowledge Builder (LKB) system (Copestake 2002). The LKB system is an implementation environment for writing HPSG grammars. The grammar was based on the Matrix “starter kit” for building HPSG grammars (Bender, Flickinge</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Pollard, Carl and Ivan Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<title>Syntax and Semantics of Prepositions,</title>
<date>2006</date>
<booktitle>Text, Speech and Language Technology.</booktitle>
<volume>29</volume>
<editor>Saint-Dizier, Patrick, editor.</editor>
<publisher>Springer</publisher>
<location>Netherlands, Dordrecht.</location>
<contexts>
<context position="26886" citStr="(2006)" startWordPosition="4311" endWordPosition="4311">Function VIA 5. approximative (ap), corresponding to Jackendoff’s Path Function TOWARDS Kracht also claims that LPs only occur in restricted contexts, for example, as a complement selected by a verb or a preposition. The LP denotes a location, and the head of an LP is a localizer function, which defines a location in relation to its complement. Furthermore, Kracht claims that verbs may select a PP complement of a certain mode syntactically, but only interact with the LP semantically. In other words, the verb takes a location as the semantic argument. This is explained in more detail by Kracht (2006). The principle governing this particular verb–PP interaction is called the Emptiness Principle (where X corresponds to a preposition, and C to a PP for our purposes): Emptiness Principle. Suppose that X is a syntactic marker in the constituent C. Suppose further that the presence of X in C is determined purely by non-semantic rules (for example selection, agreement, Sandhi). Then the meaning of X is empty, namely the identity function. (Kracht 2002, page 204) Thus, we end up with a theory that explains both the dualistic nature of prepositions semantically, and how the two-layering interacts </context>
</contexts>
<marker>2006</marker>
<rawString>Saint-Dizier, Patrick, editor. 2006. Syntax and Semantics of Prepositions, volume 29 of Text, Speech and Language Technology. Springer Netherlands, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arturo Trujillo</author>
</authors>
<title>Lexicalist Machine Translation of Spatial Prepositions.</title>
<date>1995</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge.</institution>
<contexts>
<context position="80597" citStr="Trujillo (1995)" startWordPosition="13472" endWordPosition="13473">es for prepositions contain a feature ROLE as part of the argument (to be) filled by the landmark. This ROLE can contain information like way rel for directionality, and its negation for static PPs. In German, this property will correspond to whether the case of the landmark is accusative or dative. Though this extra ROLE information may be a useful tool in translation, it lacks a denotational meaning. Moreover, this approach does not explain how we can make reference to locations, nor the structure of the PP transitive prepositions. 8.4 Trujillo’s Spatial Prepositions and Machine Translation Trujillo (1995) analyzes locatives in the context of transfer-based machine translation. He first develops a general format for a flat semantic representation called indexed lexeme lists, and shows how transfer between English and Spanish can be carried out on such representations. He then investigates differences in properties between English and Spanish spatial prepositions, and discusses the proper semantic representation of locatives and how this can be exploited in translation. The semantic representations used by Trujillo are quite similar to MRSs and introduce many properties that can also be found in</context>
<context position="83064" citStr="Trujillo (1995" startWordPosition="13866" endWordPosition="13867">Locatives the ARG0 of from(p, e, q), e is the ARG1, and q is the ARG2.7 The last two arguments, ARG1 and ARG2, are filled with the event being modified and the landmark, respectively, as in the Core Language Engine approach. When the two prepositions are combined, the lower preposition, under, modifies the object which is the ARG0 of from, and at the same time the object which is the ARG0 of the lower preposition is taken to be the landmark, the ARG2 of from. Though this solution might work technically for translation purposes, we have problems making sense out of the status of these objects. Trujillo (1995, page 172) says that “these correspond to the place objects that Sondheimer (1978) proposes, although for the purposes of this thesis they become place holders for spatial relations.” The ERG also uses a representation with some of the same properties, and we will return to a more detailed comparison to our proposal in the following section. Trujillo does not decompose the prepositions, but he classifies the prepositions with respect to different semantic properties including whether they are static or directional and different directionality types, and places them in a semantic type hierarch</context>
</contexts>
<marker>Trujillo, 1995</marker>
<rawString>Trujillo, Arturo. 1995. Lexicalist Machine Translation of Spatial Prepositions. Ph.D. thesis, University of Cambridge.</rawString>
</citation>
<citation valid="true">
<title>Representing Direction in Language and Space.</title>
<date>2003</date>
<editor>van der Zee, Emile and Jon Slack, editors.</editor>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="9089" citStr="[2003]" startWordPosition="1437" endWordPosition="1437">eometric relationship between the ball and the cup has to be realized for an expression like the ball is in the cup to be true (e.g., Herskovits 1986)? As interesting as these questions are, we think they belong to the lexicon and the lexical semantic domain and fall outside the scope of this article. There is also interesting work which relates the meaning of individual prepositions to various types of psychological studies; in particular, studies of under which conditions the various prepositions are used (see, e.g., many of the references in Bloom et al. [1996] and in van der Zee and Slack [2003]). But again this plays a complementary role to our work. One particular question in the lexical semantics of prepositions is the distinction between what Zwarts and Winter (2000), following Herskovits (1986), call projective and non-projective prepositions. A non-projective preposition, like outside, requires only spatial knowledge of the location of the two objects, while a projective preposition, like behind, requires some further information about directions from the reference object. Levinson (1996) makes a further distinction between three types of reference frames called (i) intrinsic, </context>
</contexts>
<marker>2003</marker>
<rawString>van der Zee, Emile and Jon Slack, editors. 2003. Representing Direction in Language and Space. Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Zwarts</author>
</authors>
<title>Vectors as relative positions: A compositional semantics of modified PPs.</title>
<date>1997</date>
<journal>Journal of Semantics,</journal>
<pages>14--57</pages>
<contexts>
<context position="20587" citStr="Zwarts (1997" startWordPosition="3270" endWordPosition="3271">e at the beginning of this ordering, and true towards the end of the ordering. (25) He went into the room. (26) He is in the room. 235 Computational Linguistics Volume 35, Number 2 Kracht (2002) compares his approach to Fong’s. One problem is that Fong’s approach does not extend to the VIA-reading (in Jackendoff’s terminology) of sentences like Example (3). From our point of view, it is also a point that she does not describe a compositional analysis. Also our focus in this article is strictly on the spatial readings of the locatives. 2.6 Zwarts’s Vector Space Semantics In a series of papers, Zwarts (1997, 2003a, 2003b, 2005; Zwarts and Winter 2000) has developed a semantics for locatives based on vectors. A main motivation for this proposal is the observation that locatives may be modified by phrases expressing distance or direction; for example, a measure phrase (ten meters), an adverb (diagonally), or a dimensional adjective ( far), as seen in Example (27). (27) Superman is far/diagonally/ten meters above the building. Many approaches to locatives will consider above the building to denote a region and let this be a set of points. It is then not obvious how the modifier ten meters can apply</context>
</contexts>
<marker>Zwarts, 1997</marker>
<rawString>Zwarts, Joost. 1997. Vectors as relative positions: A compositional semantics of modified PPs. Journal of Semantics, 14:57–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Zwarts</author>
</authors>
<title>Paths round a prototype.</title>
<date>2003</date>
<booktitle>In ACL-SIGSEM Workshop: The Linguistic Dimensions of Prepositions and their Use in Computational Formalisms and Applications,</booktitle>
<pages>228--238</pages>
<location>Toulouse.</location>
<contexts>
<context position="22915" citStr="Zwarts (2003" startWordPosition="3659" endWordPosition="3660">f (endpoints of) the vectors. Even though this approach seems to solve the semantic problem of this particular type of construction, we are not sure how general it can be made. The compositional analysis of Zwarts and Winter (2000) is applied to modification of nouns and to predicative uses of locatives; they do not consider verbal modification. We can see how the approach can be adopted to verbal modification of static locatives in an event based framework by introducing a function loc e, mapping events to regions, but we do not see how it extends to directional locatives. In later articles, Zwarts (2003b, 2005) extend the approach to the directional PPs. A directional PP does not denote a set of vectors, but a set of paths. A path can be considered a sequence of vectors. For example, in John went to the store, the path John followed can be formalized as a sequence of vectors, {vi|i E I} for an ordered set I, where each vi has the store as its starting point, where John successfully traverses their endpoints, and where the last vector also has the store as its endpoint. Intuitively this is a correct description, but Zwarts (2003b, 2005) does not show how this can be handled in a compositional</context>
</contexts>
<marker>Zwarts, 2003</marker>
<rawString>Zwarts, Joost. 2003a. Paths round a prototype. In ACL-SIGSEM Workshop: The Linguistic Dimensions of Prepositions and their Use in Computational Formalisms and Applications, pages 228–238, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Zwarts</author>
</authors>
<title>Vectors across spatial domains: From place to size, orientation, shape, and parts.</title>
<date>2003</date>
<booktitle>Representing Direction in Language and Space.</booktitle>
<pages>39--68</pages>
<editor>In E. van der Zee and J. Slack, editors,</editor>
<publisher>Oxford University Press,</publisher>
<location>Oxford,</location>
<contexts>
<context position="22915" citStr="Zwarts (2003" startWordPosition="3659" endWordPosition="3660">f (endpoints of) the vectors. Even though this approach seems to solve the semantic problem of this particular type of construction, we are not sure how general it can be made. The compositional analysis of Zwarts and Winter (2000) is applied to modification of nouns and to predicative uses of locatives; they do not consider verbal modification. We can see how the approach can be adopted to verbal modification of static locatives in an event based framework by introducing a function loc e, mapping events to regions, but we do not see how it extends to directional locatives. In later articles, Zwarts (2003b, 2005) extend the approach to the directional PPs. A directional PP does not denote a set of vectors, but a set of paths. A path can be considered a sequence of vectors. For example, in John went to the store, the path John followed can be formalized as a sequence of vectors, {vi|i E I} for an ordered set I, where each vi has the store as its starting point, where John successfully traverses their endpoints, and where the last vector also has the store as its endpoint. Intuitively this is a correct description, but Zwarts (2003b, 2005) does not show how this can be handled in a compositional</context>
</contexts>
<marker>Zwarts, 2003</marker>
<rawString>Zwarts, Joost. 2003b. Vectors across spatial domains: From place to size, orientation, shape, and parts. In E. van der Zee and J. Slack, editors, Representing Direction in Language and Space. Oxford University Press, Oxford, pages 39–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Zwarts</author>
</authors>
<title>Prepositional aspect and the algebra of paths.</title>
<date>2005</date>
<journal>Linguistics and Philosophy,</journal>
<volume>28</volume>
<issue>6</issue>
<marker>Zwarts, 2005</marker>
<rawString>Zwarts, Joost. 2005. Prepositional aspect and the algebra of paths. Linguistics and Philosophy, 28(6):739–779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Zwarts</author>
<author>Yoad Winter</author>
</authors>
<title>Vector space semantics: a model-theoretic analysis of locative prepositions.</title>
<date>2000</date>
<journal>Journal of Logic, Language and Information,</journal>
<pages>9--169</pages>
<contexts>
<context position="9268" citStr="Zwarts and Winter (2000)" startWordPosition="1462" endWordPosition="1465">sting as these questions are, we think they belong to the lexicon and the lexical semantic domain and fall outside the scope of this article. There is also interesting work which relates the meaning of individual prepositions to various types of psychological studies; in particular, studies of under which conditions the various prepositions are used (see, e.g., many of the references in Bloom et al. [1996] and in van der Zee and Slack [2003]). But again this plays a complementary role to our work. One particular question in the lexical semantics of prepositions is the distinction between what Zwarts and Winter (2000), following Herskovits (1986), call projective and non-projective prepositions. A non-projective preposition, like outside, requires only spatial knowledge of the location of the two objects, while a projective preposition, like behind, requires some further information about directions from the reference object. Levinson (1996) makes a further distinction between three types of reference frames called (i) intrinsic, where behind the house means on the other side of the house than what would be classified as the front side of the house, (ii) extrinsic, where behind the house is on the opposite</context>
<context position="20632" citStr="Zwarts and Winter 2000" startWordPosition="3275" endWordPosition="3278">g, and true towards the end of the ordering. (25) He went into the room. (26) He is in the room. 235 Computational Linguistics Volume 35, Number 2 Kracht (2002) compares his approach to Fong’s. One problem is that Fong’s approach does not extend to the VIA-reading (in Jackendoff’s terminology) of sentences like Example (3). From our point of view, it is also a point that she does not describe a compositional analysis. Also our focus in this article is strictly on the spatial readings of the locatives. 2.6 Zwarts’s Vector Space Semantics In a series of papers, Zwarts (1997, 2003a, 2003b, 2005; Zwarts and Winter 2000) has developed a semantics for locatives based on vectors. A main motivation for this proposal is the observation that locatives may be modified by phrases expressing distance or direction; for example, a measure phrase (ten meters), an adverb (diagonally), or a dimensional adjective ( far), as seen in Example (27). (27) Superman is far/diagonally/ten meters above the building. Many approaches to locatives will consider above the building to denote a region and let this be a set of points. It is then not obvious how the modifier ten meters can apply to this region. Zwarts and Winter (2000) pro</context>
<context position="22534" citStr="Zwarts and Winter (2000)" startWordPosition="3592" endWordPosition="3595"> denote sets of vectors, they assume a primitive semantic function loc which maps individuals to their regions as sets of points (or vectors). This is used for the landmark (e.g., the building in the locative PP above the building). When a locative modifies a noun, the inverse function is used, such that the set of vectors is turned into the set of objects which are located within the set of (endpoints of) the vectors. Even though this approach seems to solve the semantic problem of this particular type of construction, we are not sure how general it can be made. The compositional analysis of Zwarts and Winter (2000) is applied to modification of nouns and to predicative uses of locatives; they do not consider verbal modification. We can see how the approach can be adopted to verbal modification of static locatives in an event based framework by introducing a function loc e, mapping events to regions, but we do not see how it extends to directional locatives. In later articles, Zwarts (2003b, 2005) extend the approach to the directional PPs. A directional PP does not denote a set of vectors, but a set of paths. A path can be considered a sequence of vectors. For example, in John went to the store, the pat</context>
</contexts>
<marker>Zwarts, Winter, 2000</marker>
<rawString>Zwarts, Joost and Yoad Winter. 2000. Vector space semantics: a model-theoretic analysis of locative prepositions. Journal of Logic, Language and Information, 9:169–211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Valia Kordoni</author>
<author>Aline Villavicencio</author>
</authors>
<title>Prepositions in Applications: A Survey and Introduction to the Special IssuePrepositions in Applications: A Survey and Introduction to the Special Issue.</title>
<date>2009</date>
<journal>Computational Linguistics</journal>
<volume>35</volume>
<pages>119--149</pages>
<note>[Citation] [PDF] [PDF Plus]</note>
<marker>Baldwin, Kordoni, Villavicencio, 2009</marker>
<rawString>1. Timothy Baldwin, Valia Kordoni, Aline Villavicencio. 2009. Prepositions in Applications: A Survey and Introduction to the Special IssuePrepositions in Applications: A Survey and Introduction to the Special Issue. Computational Linguistics 35:2, 119-149. [Citation] [PDF] [PDF Plus]</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>