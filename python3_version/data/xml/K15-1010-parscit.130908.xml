<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000981">
<title confidence="0.9990705">
Contrastive Analysis with Predictive Power: Typology Driven Estimation
of Grammatical Error Distributions in ESL
</title>
<note confidence="0.4891265">
Yevgeni Berzak Roi Reichart Boris Katz
CSAIL MIT Technion IIT CSAIL MIT
</note>
<email confidence="0.957896">
berzak@mit.edu roiri@ie.technion.ac.il boris@mit.edu
</email>
<sectionHeader confidence="0.993964" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954666666667">
This work examines the impact of cross-
linguistic transfer on grammatical errors in
English as Second Language (ESL) texts.
Using a computational framework that for-
malizes the theory of Contrastive Analy-
sis (CA), we demonstrate that language
specific error distributions in ESL writ-
ing can be predicted from the typologi-
cal properties of the native language and
their relation to the typology of English.
Our typology driven model enables to ob-
tain accurate estimates of such distribu-
tions without access to any ESL data for
the target languages. Furthermore, we
present a strategy for adjusting our method
to low-resource languages that lack typo-
logical documentation using a bootstrap-
ping approach which approximates native
language typology from ESL texts. Fi-
nally, we show that our framework is in-
strumental for linguistic inquiry seeking
to identify first language factors that con-
tribute to a wide range of difficulties in
second language acquisition.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999961907407408">
The study of cross-linguistic transfer, whereby
properties of a native language influence perfor-
mance in a foreign language, has a long tradi-
tion in Linguistics and Second Language Acqui-
sition (SLA). Much of the linguistic work on this
topic was carried out within the framework of
Contrastive Analysis (CA), a theoretical approach
that aims to explain difficulties in second language
learning in terms of the relations between struc-
tures in the native and foreign languages.
The basic hypothesis of CA was formulated by
Lado (1957), who suggested that “we can predict
and describe the patterns that will cause difficulty
in learning, and those that will not cause difficulty,
by comparing systematically the language and cul-
ture to be learned with the native language and
culture of the student”. In particular, Lado pos-
tulated that divergences between the native and
foreign languages will negatively affect learning
and lead to increased error rates in the foreign lan-
guage. This and subsequent hypotheses were soon
met with criticism, targeting their lack of ability to
provide reliable predictions, leading to an ongoing
debate on the extent to which foreign language er-
rors can be explained and predicted by examining
native language structure.
Differently from the SLA tradition, which em-
phasizes manual analysis of error case studies
(Odlin, 1989), we address the heart of this contro-
versy from a computational data-driven perspec-
tive, focusing on the issue of predictive power. We
provide a formalization of the CA framework, and
demonstrate that the relative frequency of gram-
matical errors in ESL can be reliably predicted
from the typological properties of the native lan-
guage and their relation to the typology of English
using a regression model.
Tested on 14 languages in a leave-one-out fash-
ion, our model achieves a Mean Average Error
(MAE) reduction of 21.8% in predicting the lan-
guage specific relative frequency of the 20 most
common ESL structural error types, as compared
to the relative frequency of each of the error types
in the training data, yielding improvements across
all the languages and the large majority of the er-
ror types. Our regression model also outperforms
a stronger, nearest neighbor based baseline, that
projects the error distribution of a target language
from its typologically closest language.
While our method presupposes the existence of
typological annotations for the test languages, we
also demonstrate its viability in low-resource sce-
narios for which such annotations are not avail-
able. To address this setup, we present a bootstrap-
</bodyText>
<page confidence="0.992051">
94
</page>
<note confidence="0.980045">
Proceedings of the 19th Conference on Computational Language Learning, pages 94–102,
Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.998759325581395">
ping framework in which the typological features
required for prediction of grammatical errors are
approximated from automatically extracted ESL
morpho-syntactic features using the method of
(Berzak et al., 2014). Despite the noise intro-
duced in this process, our bootstrapping strategy
achieves an error reduction of 13.9% compared to
the average frequency baseline.
Finally, the utilization of typological features as
predictors, enables to shed light on linguistic fac-
tors that could give rise to different error types
in ESL. For example, in accordance with com-
mon linguistic knowledge, feature analysis of the
model suggests that the main contributor to in-
creased rates of determiner omission in ESL is the
lack of determiners in the native language. A more
complex case of missing pronouns is intriguingly
tied by the model to native language subject pro-
noun marking on verbs.
To summarize, the main contribution of this
work is a CA inspired computational framework
for learning language specific grammatical error
distributions in ESL. Our approach is both predic-
tive and explanatory. It enables us to obtain im-
proved estimates for language specific error distri-
butions without access to ESL error annotations
for the target language. Coupling grammatical
errors with typological information also provides
meaningful explanations to some of the linguistic
factors that drive the observed error rates.
The paper is structured as follows. Section 2
surveys related linguistic and computational work
on cross-linguistic transfer. Section 3 describes
the ESL corpus and the typological data used in
this study. In section 4 we motivate our native lan-
guage oriented approach by providing a variance
analysis for ESL errors across native languages.
Section 5 presents the regression model for pre-
diction of ESL error distributions. The bootstrap-
ping framework which utilizes automatically in-
ferred typological features is described in section
6. Finally, we present the conclusion and direc-
tions for future work in section 7.
</bodyText>
<sectionHeader confidence="0.999795" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999789421052632">
Cross linguistic-transfer was extensively studied
in SLA, Linguistics and Psychology (Odlin, 1989;
Gass and Selinker, 1992; Jarvis and Pavlenko,
2007). Within this area of research, our work is
most closely related to the Contrastive Analysis
(CA) framework. Rooted in the comparative lin-
guistics tradition, CA was first suggested by Fries
(1945) and formalized by Lado (1957). In essence,
CA examines foreign language performance, with
a particular focus on learner difficulties, in light
of a structural comparison between the native and
the foreign languages. From its inception, CA was
criticized for the lack of a solid predictive theory
(Wardhaugh, 1970; Whitman and Jackson, 1972),
leading to an ongoing scientific debate on the rele-
vance of comparison based approaches. Important
to our study is that the type of evidence used in
this debate typically relies on small scale manual
case study analysis. Our work seeks to reexamine
the issue of predictive power of CA based methods
using a computational, data-driven approach.
Computational work touching on cross-
linguistic transfer was mainly conducted in
relation to the Native Language Identification
(NLI) task, in which the goal is to determine the
native language of the author of an ESL text.
Much of this work focuses on experimentation
with different feature sets (Tetreault et al., 2013),
including features derived from the CA frame-
work (Wong and Dras, 2009). A related line of
inquiry which is closer to our work deals with the
identification of ESL syntactic patterns that are
specific to speakers of different native languages
(Swanson and Charniak, 2013; Swanson and
Charniak, 2014). Our approach differs from this
research direction by focusing on grammatical
errors, and emphasizing prediction of language
specific patterns rather than their identification.
Previous work on grammatical error correction
that examined determiner and preposition errors
(Rozovskaya and Roth, 2011; Rozovskaya and
Roth, 2014) incorporated native language specific
priors in models that are otherwise trained on stan-
dard English text. Our work extends the native
language tailored treatment of grammatical errors
to a much larger set of error types. More impor-
tantly, this approach is limited by the availabil-
ity of manual error annotations for the target lan-
guage in order to obtain the required error counts.
Our framework enables to bypass this annotation
bottleneck by predicting language specific priors
from typological information.
The current investigation is most closely re-
lated to studies that demonstrate that ESL sig-
nal can be used to infer pairwise similarities be-
tween native languages (Nagata and Whittaker,
2013; Berzak et al., 2014) and in particular, tie
</bodyText>
<page confidence="0.99802">
95
</page>
<bodyText confidence="0.999924909090909">
the similarities to the typological characteristics of
these languages (Berzak et al., 2014). Our work
inverts the direction of this analysis by starting
with typological features, and utilizing them to
predict error patterns in ESL. We also show that
the two approaches can be combined in a boot-
strapping strategy by first inferring typological
properties from automatically extracted morpho-
syntactic ESL features, and in turn, using these
properties for prediction of language specific error
distributions in ESL.
</bodyText>
<sectionHeader confidence="0.999096" genericHeader="method">
3 Data
</sectionHeader>
<subsectionHeader confidence="0.998636">
3.1 ESL Corpus
</subsectionHeader>
<bodyText confidence="0.999974620689655">
We obtain ESL essays from the Cambridge First
Certificate in English (FCE) learner corpus (Yan-
nakoudakis et al., 2011), a publicly available sub-
set of the Cambridge Learner Corpus (CLC)1. The
corpus contains upper-intermediate level essays
by native speakers of 16 languages2. Discarding
Swedish and Dutch, which have only 16 docu-
ments combined, we take into consideration the
remaining following 14 languages, with the cor-
responding number of documents in parenthesis:
Catalan (64), Chinese (66), French (146), Ger-
man (69), Greek (74), Italian (76), Japanese (82),
Korean (86), Polish (76), Portuguese (68), Rus-
sian (83), Spanish (200), Thai (63) and Turkish
(75). The resulting dataset contains 1228 docu-
ments with an average of 379 words per document.
The FCE corpus has an elaborate error anno-
tation scheme (Nicholls, 2003) and high quality
of error annotations, making it particularly suit-
able for our investigation. The annotation scheme
encompasses 75 different error types, covering a
wide range of grammatical errors on different lev-
els of granularity. As the typological features used
in this work refer mainly to structural properties,
we filter out spelling errors, punctuation errors and
open class semantic errors, remaining with a list of
grammatical errors that are typically related to lan-
guage structure. We focus on the 20 most frequent
error types3 in this list, which are presented and
</bodyText>
<footnote confidence="0.8276556">
1http://www.cambridge.org/gb/elt/
catalogue/subject/custom/item3646603
2We plan to extend our analysis to additional proficiency
levels and languages when error annotated data for these
learner profiles will be publicly available.
3Filtered errors that would have otherwise appeared in the
top 20 list, with their respective rank in brackets: Spelling (1),
Replace Punctuation (2), Replace Verb (3), Missing Punctu-
ation (7), Replace (8), Replace Noun (9) Unnecessary Punc-
tuation (13), Replace Adjective (18), Replace Adverb (20).
</footnote>
<bodyText confidence="0.9999375">
exemplified in table 1. In addition to concentrat-
ing on the most important structural ESL errors,
this cutoff prevents us from being affected by data
sparsity issues associated with less frequent errors.
</bodyText>
<subsectionHeader confidence="0.999615">
3.2 Typological Database
</subsectionHeader>
<bodyText confidence="0.999967078947368">
We use the World Atlas of Language Structures
(WALS; Dryer and Haspelmath, 2013), a repos-
itory of typological features of the world’s lan-
guages, as our source of linguistic knowledge
about the native languages of the ESL corpus au-
thors. The features in WALS are divided into
11 categories: Phonology, Morphology, Nominal
Categories, Nominal Syntax, Verbal Categories,
Word Order, Simple Clauses, Complex Sentences,
Lexicon, Sign Languages and Other. Table 2
presents examples of WALS features belonging to
different categories. The features can be associ-
ated with different variable types, including bi-
nary, categorical and ordinal, making their encod-
ing a challenging task. Our strategy for addressing
this issue is feature binarization (see section 5.3).
An important challenge introduced by the
WALS database is incomplete documentation.
Previous studies (Daum´e III, 2009; Georgi et
al., 2010) have estimated that only 14% of all
the language-feature combinations in the database
have documented values. While this issue is most
acute for low-resource languages, even the well
studied languages in our ESL dataset are lacking a
significant portion of the feature values, inevitably
hindering the effectiveness of our approach.
We perform several preprocessing steps in or-
der to select the features that will be used in this
study. First, as our focus is on structural fea-
tures that can be expressed in written form, we
discard all the features associated with the cate-
gories Phonology, Lexicon4, Sign Languages and
Other. We further discard 24 features which either
have a documented value for only one language,
or have the same value in all the languages. The
resulting feature-set contains 119 features, with an
average of 2.9 values per feature, and 92.6 docu-
mented features per language.
</bodyText>
<sectionHeader confidence="0.9075135" genericHeader="method">
4 Variance Analysis of Grammatical
Errors in ESL
</sectionHeader>
<bodyText confidence="0.9997245">
To motivate a native language based treatment of
grammatical error distributions in ESL, we begin
</bodyText>
<footnote confidence="0.796726333333333">
4The discarded Lexicon features refer to properties such
as the number of words in the language that denote colors,
and identity of word pairs such as “hand” and “arm”.
</footnote>
<page confidence="0.992297">
96
</page>
<table confidence="0.999085047619048">
Rank Code Name Example Count KW MW
1 TV Verb Tense I hope I give have given you enough details 3324 ** 34
2 RT Replace Preposition on in July 3311 ** 31
3 MD Missing Determiner I went for the interview 2967 ** 57
4 FV Wrong Verb Form had time to played play 1789 ** 21
5 W Word Order Probably our homes will probably be 1534 ** 34
6 MT Missing Preposition explain to you 1435 ** 22
7 UD Unnecessary Determiner a course at the Cornell University 1321
8 UT Unnecessary Preposition we need it on each minute 1079
9 MA Missing Pronoun because it is the best conference 984 ** 33
10 AGV Verb Agreement the teachers was were very experienced 916 ** 21
11 FN Wrong Form Noun because of my study studies 884 ** 24
12 RA Replace Pronoun she just met Sally, which who 847 ** 17
13 AGN Noun Agreement two month months ago 816 ** 24
14 RD Replace Determiner of a the last few years 676 ** 35
15 DJ Wrongly Derived Adjective The mother was pride proud 608 * 8
16 DN Wrongly Derived Noun working place workplace 536
17 DY Wrongly Derived Adverb Especial Especially 414 ** 14
18 UA Unnecessary Pronoun feel ourselves comfortable 391 * 9
19 MC Missing Conjunction reading, and playing piano at home 346 * 11
20 RC Replace Conjunction not just the car, and but also the train 226
</table>
<tableCaption confidence="0.998232">
Table 1: The 20 most frequent error types in the FCE corpus that are related to language structure. In
</tableCaption>
<bodyText confidence="0.991594571428571">
the Example column, words marked in italics are corrections for the words marked in bold. The Count
column lists the overall count of each error type in the corpus. The KW column depicts the result of
the Kruskal-Wallis test whose null hypothesis is that the relative error frequencies for different native
languages are drawn from the same distribution. Error types for which this hypothesis is rejected with
p &lt; 0.01 are denoted with ‘*’. Error types with p &lt; 0.001 are marked with ‘**’. The MW column
denotes the number of language pairs (out of the total 91 pairs) which pass the post-hoc Mann-Whitney
test with p &lt; 0.01.
</bodyText>
<table confidence="0.9993092">
ID Category Name Values
23A Morphology Locus of No case marking,
Marking Core cases only,
in the Core and non-core,
Clause No syncretism
67A Verbal The Future Inflectional future,
Categories Tense No inflectional
future.
30A Nominal Number of None, Two, Three,
Categories Genders Four, Five or more.
87A Word Order Order of AN, NA, No
Adjective dominant order,
and Noun Only internally
headed relative
clauses.
</table>
<tableCaption confidence="0.999352">
Table 2: Examples of WALS features.
</tableCaption>
<bodyText confidence="0.980594161290323">
by examining whether there is a statistically sig-
nificant difference in ESL error rates based on the
native language of the learners. This analysis pro-
vides empirical justification for our approach, and
to the best of our knowledge was not conducted in
previous studies.
To this end, we perform a Kruskal-Wallis (KW)
test (Kruskal and Wallis, 1952) for each error
type5. We treat the relative error frequency per
word in each document as a sample6 (i.e. the rel-
ative frequencies of all the error types in a docu-
ment sum to 1). The samples are associated with
14 groups, according to the native language of the
document’s author. For each error type, the null
hypothesis of the test is that error fraction sam-
ples of all the native languages are drawn from the
same underlying distribution. In other words, re-
jection of the null hypothesis implies a significant
difference between the relative error frequencies
of at least one language pair.
As shown in table 1, we can reject the null hy-
pothesis for 16 of the 20 grammatical error types
with p &lt; 0.01, where Unnecessary Determiner,
Unnecessary Preposition, Wrongly Derived Noun,
and Replace Conjunction are the error types that
do not exhibit dependence on the native language.
5We chose the non-parametric KW rank-based test over
ANOVA, as according to the Shapiro-Wilk (1965) and Lev-
ene (1960) tests, the assumptions of normality and homo-
geneity of variance do not hold for our data. In practice, the
ANOVA test yields similar results to those of the KW test.
</bodyText>
<footnote confidence="0.988491333333333">
6We also performed the KW test on the absolute error fre-
quencies (i.e. raw counts) per word, obtaining similar results
to the ones reported here on the relative frequencies per word.
</footnote>
<page confidence="0.99941">
97
</page>
<bodyText confidence="0.999899666666667">
Furthermore, the null hypothesis can be rejected
for 13 error types with p &lt; 0.001. These results
suggest that the relative error rates of the major-
ity of the common structural grammatical errors
in our corpus indeed differ between native speak-
ers of different languages.
We further extend our analysis by perform-
ing pairwise post-hoc Mann-Whitney (MW) tests
(Mann and Whitney, 1947) in order to determine
the number of language pairs that significantly dif-
fer with respect to their native speakers’ error frac-
tions in ESL. Table 1 presents the number of lan-
guage pairs that pass this test with p &lt; 0.01 for
each error type. This inspection suggests Miss-
ing Determiner as the error type with the strongest
dependence on the author’s native language, fol-
lowed by Replace Determiner, Verb Tense, Word
Order, Missing Pronoun and Replace Preposition.
</bodyText>
<sectionHeader confidence="0.9988115" genericHeader="method">
5 Predicting Language Specific Error
Distributions in ESL
</sectionHeader>
<subsectionHeader confidence="0.998243">
5.1 Task Definition
</subsectionHeader>
<bodyText confidence="0.9999894">
Given a language l E L, our task is to predict for
this language the relative error frequency yl,e of
each error type e E E, where L is the set of all na-
tive languages, E is the set of grammatical errors,
and Ee yl,e = 1.
</bodyText>
<subsectionHeader confidence="0.997122">
5.2 Model
</subsectionHeader>
<bodyText confidence="0.999485666666667">
In order to predict the error distribution of a native
language, we train regression models on individ-
ual error types:
</bodyText>
<equation confidence="0.934084">
ˆy0l,e = θl,e - f(tl, teng) (1)
</equation>
<bodyText confidence="0.999246818181818">
In this equation ˆy0l,e is the predicted relative fre-
quency of an error of type e for ESL documents
authored by native speakers of language l, and
f(tl, teng) is a feature vector derived from the ty-
pological features of the native language tl and the
typological features of English teng.
The model parameters θl,e are obtained using
Ordinary Least Squares (OLS) on the training data
D, which consists of typological feature vectors
paired with relative error frequencies of the re-
maining 13 languages:
</bodyText>
<equation confidence="0.962459">
D = I(f(tl,, teng), ye,l,)1l0 E L, l0 =� l1 (2)
</equation>
<bodyText confidence="0.963290333333333">
To guarantee that the individual relative error fre-
quency estimates sum to 1 for each language, we
renormalize them to obtain the final predictions:
</bodyText>
<equation confidence="0.7467845">
ˆyb,e (3)
Ee ˆy0l,e
</equation>
<subsectionHeader confidence="0.874769">
5.3 Features
</subsectionHeader>
<bodyText confidence="0.999990875">
Our feature set can be divided into two subsets.
The first subset, used in a version of our model
called Reg, contains the typological features of the
native language. In a second version of our model,
called RegCA, we also utilize additional features
that explicitly encode differences between the ty-
pological features of the native language, and the
and the typological features of English.
</bodyText>
<subsubsectionHeader confidence="0.809514">
5.3.1 Typological Features
</subsubsectionHeader>
<bodyText confidence="0.99996875">
In the Reg model, we use the typological fea-
tures of the native language that are documented
in WALS. As mentioned in section 3.2, WALS
features belong to different variable types, and are
hence challenging to encode. We address this is-
sue by binarizing all the features. Given k possible
values vk for a given WALS feature ti, we generate
k binary typological features of the form:
</bodyText>
<equation confidence="0.9595355">
1 if tl,i = vk (4)
0 otherwise
</equation>
<bodyText confidence="0.9980126">
When a WALS feature of a given language does
not have a documented value, all k entries of the
feature for that language are assigned the value of
0. This process transforms the original 119 WALS
features into 340 binary features.
</bodyText>
<subsectionHeader confidence="0.756935">
5.3.2 Divergences from English
</subsectionHeader>
<bodyText confidence="0.992103625">
In the spirit of CA, in the model RegCA, we also
utilize features that explicitly encode differences
between the typological features of the native lan-
guage and those of English. These features are
also binary, and take the value 1 when the value of
a WALS feature in the native language is different
fr
om the corresponding value in English:
We encode 104 such features, in accordance with
the typological features of English available in
WALS. The features are activated only when a ty-
pological feature of English has a corresponding
documented feature in the native language. The
addition of these divergence features bri
ngs the to-
tal number of features in our feature set to 444.
</bodyText>
<equation confidence="0.931801833333333">
ˆyl,e =
fi,k(tl, teng) =
1 if
tl,i=�teng,ifi(tl, teng) =
0 (5)
otherwise
</equation>
<page confidence="0.996631">
98
</page>
<sectionHeader confidence="0.847783" genericHeader="evaluation">
5.4 Results
</sectionHeader>
<bodyText confidence="0.988592538461539">
We evaluate the model predictions using two met-
rics. The first metric, Absolute Error, measures the
distance between the predicted and the true rela-
tive frequency of each grammatical error type7:
Absolute Error = |ˆyl,e − yl,e |(6)
When averaged across different predictions we re-
fer to this metric as Mean Absolute Error (MAE).
The second evaluation score is the Kullback-
Leibler divergence DKL, a standard measure for
evaluating the difference between two distribu-
tions. This metric is used to evaluate the pre-
dicted grammatical error distribution of a native
language:
</bodyText>
<equation confidence="0.948399">
�
DKL(yl||ˆyl) =
e
</equation>
<table confidence="0.997357285714286">
Base NN Reg RegCA
MAE 1.28 1.11 1.02 1.0
Error Reduction - 13.3 20.4 21.8
#Languages - 9/14 12/14 14/14
#Mistakes - 11/20 15/20 14/20
AVG DKL 0.052 0.046 0.033 0.032
#Languages - 10/14 14/14 14/14
</table>
<tableCaption confidence="0.985661">
Table 3: Results for prediction of relative error fre-
</tableCaption>
<bodyText confidence="0.9979104375">
quencies using the MAE metric across languages
and error types, and the DKL metric averaged
across languages. #Languages and #Mistakes de-
note the number of languages and grammatical er-
ror types on which a model outperforms Base.
Table 3 summarizes the grammatical error pre-
diction results8. The baseline model Base sets the
relative frequencies of the grammatical errors of a
test language to the respective relative error fre-
quencies in the training data. We also consider
a stronger, language specific model called Near-
est Neighbor (NN), which projects the error distri-
bution of a target language from the typologically
closest language in the training set, according to
the cosine similarity measure. This baseline pro-
vides a performance improvement for the majority
</bodyText>
<footnote confidence="0.856008">
7For clarity of presentation, all the reported results on this
metric are multiplied by 100.
8As described in section 5.2, we report the performance
</footnote>
<bodyText confidence="0.98968805">
of regression models trained and evaluated on relative error
frequencies obtained by normalizing the rates of the different
error types. We also experimented with training and evaluat-
ing the models on absolute error counts per word, obtaining
results that are similar to those reported here.
of the languages and error types, with an average
error reduction of 13.3% on the MAE metric com-
pared to Base, and improving from 0.052 to 0.046
on the KL divergence metric, thus emphasizing the
general advantage of a native language adapted ap-
proach to ESL error prediction.
Our regression model introduces further sub-
stantial performance improvements. The Reg
model, which uses the typological features of the
native language for predicting ESL relative er-
ror frequencies, achieves 20.4% MAE reduction
over the Base model. The RegCA version of
the regression model, which also incorporates dif-
ferences between the typological features of the
native language and English, surpasses the Reg
model, reaching an average error reduction of
21.8% from the Base model, with improvements
across all the languages and the majority of the
error types. Strong performance improvements
are also obtained on the KL divergence measure,
where the RegCA model scores 0.032, compared
to the baseline score of 0.052.
To illustrate the outcome of our approach, con-
sider the example in table 4, which compares the
top 10 predicted errors for Japanese using the Base
and RegCA models. In this example, RegCA cor-
rectly places Missing Determiner as the most com-
mon error in Japanese, with a significantly higher
relative frequency than in the training data. Sim-
ilarly, it provides an accurate prediction for the
Missing Preposition error, whose frequency and
rank are underestimated by the Base model. Fur-
thermore, RegCA correctly predicts the frequency
of Replace Preposition and Word Order to be
lower than the average in the training data.
</bodyText>
<subsectionHeader confidence="0.997084">
5.5 Feature Analysis
</subsectionHeader>
<bodyText confidence="0.999848">
An important advantage of our typology-based ap-
proach are the clear semantics of the features,
which facilitate the interpretation of the model. In-
spection of the model parameters allows us to gain
insight into the typological features that are poten-
tially involved in causing different types of ESL
errors. Although such inspection is unlikely to
provide a comprehensive coverage of all the rel-
evant causes for the observed learner difficulties,
it can serve as a valuable starting point for ex-
ploratory linguistic analysis and formulation of a
cross-linguistic transfer theory.
Table 5 lists the most salient typological fea-
tures, as determined by the feature weights aver-
</bodyText>
<figure confidence="0.847504666666667">
yl,e ln yl,e
ˆyl,e
(7)
</figure>
<page confidence="0.990136">
99
</page>
<table confidence="0.999454454545455">
Rank Base Frac. RegCA Frac. True Frac.
1 Replace Preposition 0.14 Missing Determiner 0.18 Missing Determiner 0.20
2 Tense Verb 0.14 Tense Verb 0.12 Tense Verb 0.12
3 Missing Determiner 0.12 Replace Preposition 0.12 Replace Preposition 0.10
4 Wrong Verb Form 0.07 Missing Preposition 0.08 Missing Preposition 0.08
5 Word Order 0.06 Unnecessary Determiner 0.06 Unnecessary Preposition 0.06
6 Missing Preposition 0.06 Wrong Verb Form 0.05 Unnecessary Determiner 0.05
7 Unnecessary Determiner 0.06 Unnecessary Preposition 0.05 Replace Determiner 0.05
8 Unnecessary Preposition 0.04 Wrong Noun Form 0.05 Wrong Verb Form 0.05
9 Missing Pronoun 0.04 Word Order 0.05 Word Order 0.04
10 Wrong Noun Form 0.04 Verb Agreement 0.04 Wrong Noun Form 0.06
</table>
<tableCaption confidence="0.999222">
Table 4: Comparison between the fractions and ranks of the top 10 predicted error types by the Base
</tableCaption>
<bodyText confidence="0.964557962962963">
and RegCA models for Japanese. As opposed to the Base method, the RegCA model correctly predicts
Missing Determiner to be the most frequent error committed by native speakers of Japanese. It also
correctly predicts Missing Preposition to be more frequent and Replace Preposition and Word Order to
be less frequent than in the training data.
aged across the models of different languages, for
the error types Missing Determiner and Missing
Pronoun. In the case of determiners, the model
identifies the lack of definite and indefinite arti-
cles in the native language as the strongest factors
related to increased rates of determiner omission.
Conversely, features that imply the presence of an
article system in the native language, such as ‘In-
definite word same as one’ and ‘Definite word dis-
tinct from demonstrative’ are indicative of reduced
error rates of this type.
A particularly intriguing example concerns the
Missing Pronoun error. The most predictive typo-
logical factor for increased pronoun omissions is
pronominal subject marking on the verb in the na-
tive language. Differently from the case of deter-
miners, it is not the lack of the relevant structure in
the native language, but rather its different encod-
ing that seems to drive erroneous pronoun omis-
sion. Decreased error rates of this type correlate
most strongly with obligatory pronouns in subject
position, as well as a verbal person marking sys-
tem similar to the one in English.
</bodyText>
<subsectionHeader confidence="0.643374">
6 Bootstrapping with ESL-based
Typology
</subsectionHeader>
<bodyText confidence="0.998386555555556">
Thus far, we presupposed the availability of sub-
stantial typological information for our target lan-
guages in order to predict their ESL error distribu-
tions. However, the existing typological documen-
tation for the majority of the world’s languages is
scarce, limiting the applicability of this approach
for low-resource languages.
We address this challenge for scenarios in
which an unannotated collection of ESL texts au-
</bodyText>
<table confidence="0.998572772727273">
Missing Determiner
37A Definite Articles: Different from English .057
38A Indefinite Articles: No definite or indefinite article .055
37A Definite Articles: No definite or indefinite article .055
49A Number of Cases: 6-7 case .052
100A Alignment of Verbal Person Marking: Accusative -.073
38A Indefinite Article: Indefinite word same as ’one’ -.050
52A Comitatives and Instrumentals: Identity -.044
37A Definite Articles: -.036
Definite word distinct from demonstrative
Missing Pronoun
101A Expression of Pronominal Subjects: .015
Subject affixes on verb
71A The Prohibitive: Different from English .012
38A Indefinite Articles: Indefinite word same as ’one’ .011
71A The Prohibitive: Special imperative + normal negative .010
104A Order of Person Markers on the Verb: -.016
A &amp; P do not or do not both occur on the verb
102A Verbal Person Marking: Only the A argument -.013
101A Expression of Pronominal Subjects: -.011
Obligatory pronouns in subject position
71A The Prohibitive: Normal imperative + normal negative -.010
</table>
<tableCaption confidence="0.960267">
Table 5: The most predictive typological features
</tableCaption>
<bodyText confidence="0.991118411764706">
of the RegCA model for the errors Missing De-
terminer and Missing Pronoun. The right column
depicts the feature weight averaged across all the
languages. Missing determiners are related to the
absence of a determiner system in the native lan-
guage. Missing pronouns are correlated with sub-
ject pronoun marking on the verb.
thored by native speakers of the target language is
available. Given such data, we propose a boot-
strapping strategy which uses the method pro-
posed in (Berzak et al., 2014) in order to approx-
imate the typology of the native language from
morpho-syntactic features in ESL. The inferred ty-
pological features serve, in turn, as a proxy for the
true typology of that language in order to predict
its speakers’ ESL grammatical error rates with our
regression model.
</bodyText>
<page confidence="0.974211">
100
</page>
<bodyText confidence="0.9997718">
To put this framework into effect, we use the
FCE corpus to train a log-linear model for native
language classification using morpho-syntactic
features obtained from the output of the Stanford
Parser (de Marneffe et al., 2006):
</bodyText>
<equation confidence="0.985675333333333">
exp(θ · f(x, l))
p(l|x; θ) = (8)
El0EL exp(θ · f (x,l&apos;))
</equation>
<bodyText confidence="0.999984">
where l is the native language, x is the observed
English document and θ are the model parameters.
We then derive pairwise similarities between lan-
guages by averaging the uncertainty of the model
with respect to each language pair:
</bodyText>
<equation confidence="0.937766">
p(l&apos;|x; θ) if l&apos; =� l
1 otherwise
(9)
</equation>
<bodyText confidence="0.9998849">
In this equation, x is an ESL document, θ are
the parameters of the native language classifica-
tion model and Dl is a set of documents whose
native language is l. For each pair of languages l
and l&apos; the matrix S&apos;ESL contains an entry S&apos;ESLl,l0
which represents the average probability of con-
fusing l for l&apos;, and an entry S&apos;ESLl0,l, which cap-
tures the opposite confusion. A similarity estimate
for a language pair is then obtained by averaging
these two scores:
</bodyText>
<equation confidence="0.979883">
SESLl,l, = SESLl,,l = 2 (S0
1ESLl,l, + S0ESLl,,l) (10)
</equation>
<bodyText confidence="0.999953076923077">
As shown in (Berzak et al., 2014), given the simi-
larity matrix SESL, one can obtain an approxima-
tion for the typology of a native language by pro-
jecting the typological features from its most sim-
ilar languages. Here, we use the typology of the
closest language, an approach that yields 70.7%
accuracy in predicting the typological features of
our set of languages.
In the bootstrapping setup, we train the regres-
sion models on the true typology of the languages
in the training set, and use the approximate typol-
ogy of the test language to predict the relative error
rates of its speakers in ESL.
</bodyText>
<subsectionHeader confidence="0.560079">
6.1 Results
</subsectionHeader>
<bodyText confidence="0.999803769230769">
Table 6 summarizes the error prediction results us-
ing approximate typological features for the test
languages. As can be seen, our approach contin-
ues to provide substantial performance gains de-
spite the inaccuracy of the typological informa-
tion used for the test languages. The best per-
forming method, RegCA reduces the MAE of Base
by 13.9%, with performance improvements for
most of the languages and error types. Perfor-
mance gains are also obtained on the DKL met-
ric, whereby RegCA scores 0.041, compared to the
Base score of 0.052, improving on 11 out of our 14
languages.
</bodyText>
<table confidence="0.999196571428571">
Base NN Reg RegCA
MAE 1.28 1.12 1.13 1.10
Error Reduction - 12.6 11.6 13.9
#Languages - 11/14 11/14 11/14
#Mistakes - 10/20 10/20 11/20
AVG DKL 0.052 0.048 0.043 0.041
#Languages - 10/14 11/14 11/14
</table>
<tableCaption confidence="0.899551">
Table 6: Results for prediction of relative error fre-
</tableCaption>
<bodyText confidence="0.98540075">
quencies using the bootstrapping approach. In this
setup, the true typology of the test language is sub-
stituted with approximate typology derived from
morpho-syntactic ESL features.
</bodyText>
<sectionHeader confidence="0.989246" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999951892857143">
We present a computational framework for pre-
dicting native language specific grammatical er-
ror distributions in ESL, based on the typological
properties of the native language and their compat-
ibility with the typology of English. Our regres-
sion model achieves substantial performance im-
provements as compared to a language oblivious
baseline, as well as a language dependent near-
est neighbor baseline. Furthermore, we address
scenarios in which the typology of the native lan-
guage is not available, by bootstrapping typologi-
cal features from ESL texts. Finally, inspection of
the model parameters allows us to identify native
language properties which play a pivotal role in
generating different types of grammatical errors.
In addition to the theoretical contribution, the
outcome of our work has a strong potential to be
beneficial in practical setups. In particular, it can
be utilized for developing educational curricula
that focus on the areas of difficulty that are charac-
teristic of different native languages. Furthermore,
the derived error frequencies can be integrated as
native language specific priors in systems for au-
tomatic error correction. In both application ar-
eas, previous work relied on the existence of error
tagged ESL data for the languages of interest. Our
approach paves the way for addressing these chal-
lenges even in the absence of such data.
</bodyText>
<figure confidence="0.997503714285714">
S&apos;ESLl,l0 =
⎧
⎨
⎩
E
1
|Dl |(x,l)EDl
</figure>
<page confidence="0.992346">
101
</page>
<sectionHeader confidence="0.998878" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9996405">
This material is based upon work supported by
the Center for Brains, Minds, and Machines
(CBMM), funded by NSF STC award CCF-
1231216.
</bodyText>
<sectionHeader confidence="0.998845" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999873287234043">
Yevgeni Berzak, Roi Reichart, and Boris Katz. 2014.
Reconstructing native language typology from for-
eign language usage. In Proceedings of the Eigh-
teenth Conference on Computational Natural Lan-
guage Learning, pages 21–29. Association for Com-
putational Linguistics, June.
Hal Daum´e III. 2009. Non-parametric Bayesian areal
linguistics. In Proceedings of human language tech-
nologies: The 2009 annual conference of the north
american chapter of the association for computa-
tional linguistics, pages 593–601. Association for
Computational Linguistics.
Marie-Catherine de Marneffe, Bill MacCartney,
Christopher D Manning, et al. 2006. Generating
typed dependency parses from phrase structure
parses. In Proceedings of LREC, volume 6, pages
449–454.
Charles C Fries. 1945. Teaching and learning english
as a foreign language.
Susan M Gass and Larry Selinker. 1992. Language
Transfer in Language Learning: Revised edition,
volume 5. John Benjamins Publishing.
Ryan Georgi, Fei Xia, and William Lewis. 2010.
Comparing language similarity across genetic and
typologically-based groupings. In Proceedings of
the 23rd International Conference on Computa-
tional Linguistics, pages 385–393. Association for
Computational Linguistics.
Scott Jarvis and Aneta Pavlenko. 2007. Crosslinguis-
tic influence in language and cognition. Routledge.
William H Kruskal and W Allen Wallis. 1952. Use of
ranks in one-criterion variance analysis. Journal of
the American statistical Association, 47(260):583–
621.
Robert Lado. 1957. Linguistics across cultures: Ap-
plied linguistics for language teachers.
Howard Levene. 1960. Robust tests for equality of
variances. Contributions to probability and statis-
tics: Essays in honor of Harold Hotelling, 2:278–
292.
Henry B Mann and Donald R Whitney. 1947. On a test
of whether one of two random variables is stochasti-
cally larger than the other. The annals of mathemat-
ical statistics, pages 50–60.
Ryo Nagata and Edward Whittaker. 2013. Recon-
structing an indo-european family tree from non-
native english texts. In Proceedings of the 51st An-
nual Meeting of the Association for Computational
Linguistics, pages 1137–1147, Sofia, Bulgaria. As-
sociation for Computational Linguistics.
Diane Nicholls. 2003. The cambridge learner corpus:
Error coding and analysis for lexicography and elt.
In Proceedings of the Corpus Linguistics 2003 con-
ference, pages 572–581.
Terence Odlin. 1989. Language transfer: Cross-
linguistic influence in language learning. Cam-
bridge University Press.
Alla Rozovskaya and Dan Roth. 2011. Algorithm se-
lection and model adaptation for esl correction tasks.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies-Volume 1, pages 924–933.
Association for Computational Linguistics.
Alla Rozovskaya and Dan Roth. 2014. Building a
state-of-the-art grammatical error correction system.
Transactions of the Association for Computational
Linguistics, 2(10):419–434.
Samuel Sanford Shapiro and Martin B Wilk. 1965.
An analysis of variance test for normality (complete
samples). Biometrika, pages 591–611.
Ben Swanson and Eugene Charniak. 2013. Extract-
ing the native language signal for second language
acquisition. In HLT-NAACL, pages 85–94.
Ben Swanson and Eugene Charniak. 2014. Data
driven language transfer hypotheses. EACL 2014,
page 169.
Joel Tetreault, Daniel Blanchard, and Aoife Cahill.
2013. A report on the first native language identi-
fication shared task. In Proceedings of the Eighth
Workshop on Innovative Use of NLP for Building
Educational Applications, pages 48–57. Citeseer.
Ronald Wardhaugh. 1970. The contrastive analysis
hypothesis. TESOL quarterly, pages 123–130.
Randal L Whitman and Kenneth L Jackson. 1972. The
unpredictability of contrastive analysis. Language
learning, 22(1):29–41.
Sze-Meng Jojo Wong and Mark Dras. 2009. Con-
trastive analysis and native language identification.
In Proceedings of the Australasian Language Tech-
nology Association Workshop, pages 53–61. Cite-
seer.
Helen Yannakoudakis, Ted Briscoe, and Ben Medlock.
2011. A new dataset and method for automatically
grading ESOL texts. In ACL, pages 180–189.
</reference>
<page confidence="0.998625">
102
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.960784">
<title confidence="0.9958935">Contrastive Analysis with Predictive Power: Typology Driven Estimation of Grammatical Error Distributions in ESL</title>
<author confidence="0.999763">Yevgeni Berzak Roi Reichart Boris Katz</author>
<affiliation confidence="0.99156">CSAIL MIT Technion IIT CSAIL MIT</affiliation>
<email confidence="0.994181">berzak@mit.eduroiri@ie.technion.ac.ilboris@mit.edu</email>
<abstract confidence="0.99917224">This work examines the impact of crosslinguistic transfer on grammatical errors in English as Second Language (ESL) texts. Using a computational framework that formalizes the theory of Contrastive Analy- (CA), we demonstrate that error distributions ESL writing can be predicted from the typological properties of the native language and their relation to the typology of English. Our typology driven model enables to obtain accurate estimates of such distributions without access to any ESL data for the target languages. Furthermore, we present a strategy for adjusting our method to low-resource languages that lack typological documentation using a bootstrapping approach which approximates native language typology from ESL texts. Finally, we show that our framework is instrumental for linguistic inquiry seeking to identify first language factors that contribute to a wide range of difficulties in second language acquisition.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yevgeni Berzak</author>
<author>Roi Reichart</author>
<author>Boris Katz</author>
</authors>
<title>Reconstructing native language typology from foreign language usage.</title>
<date>2014</date>
<booktitle>In Proceedings of the Eighteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>21--29</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics,</institution>
<contexts>
<context position="4188" citStr="Berzak et al., 2014" startWordPosition="640" endWordPosition="643">r method presupposes the existence of typological annotations for the test languages, we also demonstrate its viability in low-resource scenarios for which such annotations are not available. To address this setup, we present a bootstrap94 Proceedings of the 19th Conference on Computational Language Learning, pages 94–102, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics ping framework in which the typological features required for prediction of grammatical errors are approximated from automatically extracted ESL morpho-syntactic features using the method of (Berzak et al., 2014). Despite the noise introduced in this process, our bootstrapping strategy achieves an error reduction of 13.9% compared to the average frequency baseline. Finally, the utilization of typological features as predictors, enables to shed light on linguistic factors that could give rise to different error types in ESL. For example, in accordance with common linguistic knowledge, feature analysis of the model suggests that the main contributor to increased rates of determiner omission in ESL is the lack of determiners in the native language. A more complex case of missing pronouns is intriguingly </context>
<context position="8722" citStr="Berzak et al., 2014" startWordPosition="1339" endWordPosition="1342">ext. Our work extends the native language tailored treatment of grammatical errors to a much larger set of error types. More importantly, this approach is limited by the availability of manual error annotations for the target language in order to obtain the required error counts. Our framework enables to bypass this annotation bottleneck by predicting language specific priors from typological information. The current investigation is most closely related to studies that demonstrate that ESL signal can be used to infer pairwise similarities between native languages (Nagata and Whittaker, 2013; Berzak et al., 2014) and in particular, tie 95 the similarities to the typological characteristics of these languages (Berzak et al., 2014). Our work inverts the direction of this analysis by starting with typological features, and utilizing them to predict error patterns in ESL. We also show that the two approaches can be combined in a bootstrapping strategy by first inferring typological properties from automatically extracted morphosyntactic ESL features, and in turn, using these properties for prediction of language specific error distributions in ESL. 3 Data 3.1 ESL Corpus We obtain ESL essays from the Cambr</context>
<context position="30324" citStr="Berzak et al., 2014" startWordPosition="4878" endWordPosition="4881">bject position 71A The Prohibitive: Normal imperative + normal negative -.010 Table 5: The most predictive typological features of the RegCA model for the errors Missing Determiner and Missing Pronoun. The right column depicts the feature weight averaged across all the languages. Missing determiners are related to the absence of a determiner system in the native language. Missing pronouns are correlated with subject pronoun marking on the verb. thored by native speakers of the target language is available. Given such data, we propose a bootstrapping strategy which uses the method proposed in (Berzak et al., 2014) in order to approximate the typology of the native language from morpho-syntactic features in ESL. The inferred typological features serve, in turn, as a proxy for the true typology of that language in order to predict its speakers’ ESL grammatical error rates with our regression model. 100 To put this framework into effect, we use the FCE corpus to train a log-linear model for native language classification using morpho-syntactic features obtained from the output of the Stanford Parser (de Marneffe et al., 2006): exp(θ · f(x, l)) p(l|x; θ) = (8) El0EL exp(θ · f (x,l&apos;)) where l is the native </context>
<context position="31720" citStr="Berzak et al., 2014" startWordPosition="5123" endWordPosition="5126">th respect to each language pair: p(l&apos;|x; θ) if l&apos; =� l 1 otherwise (9) In this equation, x is an ESL document, θ are the parameters of the native language classification model and Dl is a set of documents whose native language is l. For each pair of languages l and l&apos; the matrix S&apos;ESL contains an entry S&apos;ESLl,l0 which represents the average probability of confusing l for l&apos;, and an entry S&apos;ESLl0,l, which captures the opposite confusion. A similarity estimate for a language pair is then obtained by averaging these two scores: SESLl,l, = SESLl,,l = 2 (S0 1ESLl,l, + S0ESLl,,l) (10) As shown in (Berzak et al., 2014), given the similarity matrix SESL, one can obtain an approximation for the typology of a native language by projecting the typological features from its most similar languages. Here, we use the typology of the closest language, an approach that yields 70.7% accuracy in predicting the typological features of our set of languages. In the bootstrapping setup, we train the regression models on the true typology of the languages in the training set, and use the approximate typology of the test language to predict the relative error rates of its speakers in ESL. 6.1 Results Table 6 summarizes the e</context>
</contexts>
<marker>Berzak, Reichart, Katz, 2014</marker>
<rawString>Yevgeni Berzak, Roi Reichart, and Boris Katz. 2014. Reconstructing native language typology from foreign language usage. In Proceedings of the Eighteenth Conference on Computational Natural Language Learning, pages 21–29. Association for Computational Linguistics, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<title>Non-parametric Bayesian areal linguistics.</title>
<date>2009</date>
<booktitle>In Proceedings of human language technologies: The</booktitle>
<pages>593--601</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Daum´e, 2009</marker>
<rawString>Hal Daum´e III. 2009. Non-parametric Bayesian areal linguistics. In Proceedings of human language technologies: The 2009 annual conference of the north american chapter of the association for computational linguistics, pages 593–601. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<pages>449--454</pages>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, Christopher D Manning, et al. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC, volume 6, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles C Fries</author>
</authors>
<title>Teaching and learning english as a foreign language.</title>
<date>1945</date>
<contexts>
<context position="6365" citStr="Fries (1945)" startWordPosition="977" endWordPosition="978">ression model for prediction of ESL error distributions. The bootstrapping framework which utilizes automatically inferred typological features is described in section 6. Finally, we present the conclusion and directions for future work in section 7. 2 Related Work Cross linguistic-transfer was extensively studied in SLA, Linguistics and Psychology (Odlin, 1989; Gass and Selinker, 1992; Jarvis and Pavlenko, 2007). Within this area of research, our work is most closely related to the Contrastive Analysis (CA) framework. Rooted in the comparative linguistics tradition, CA was first suggested by Fries (1945) and formalized by Lado (1957). In essence, CA examines foreign language performance, with a particular focus on learner difficulties, in light of a structural comparison between the native and the foreign languages. From its inception, CA was criticized for the lack of a solid predictive theory (Wardhaugh, 1970; Whitman and Jackson, 1972), leading to an ongoing scientific debate on the relevance of comparison based approaches. Important to our study is that the type of evidence used in this debate typically relies on small scale manual case study analysis. Our work seeks to reexamine the issu</context>
</contexts>
<marker>Fries, 1945</marker>
<rawString>Charles C Fries. 1945. Teaching and learning english as a foreign language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan M Gass</author>
<author>Larry Selinker</author>
</authors>
<title>Language Transfer in Language Learning: Revised edition, volume 5.</title>
<date>1992</date>
<publisher>John Benjamins Publishing.</publisher>
<contexts>
<context position="6141" citStr="Gass and Selinker, 1992" startWordPosition="940" endWordPosition="943"> 3 describes the ESL corpus and the typological data used in this study. In section 4 we motivate our native language oriented approach by providing a variance analysis for ESL errors across native languages. Section 5 presents the regression model for prediction of ESL error distributions. The bootstrapping framework which utilizes automatically inferred typological features is described in section 6. Finally, we present the conclusion and directions for future work in section 7. 2 Related Work Cross linguistic-transfer was extensively studied in SLA, Linguistics and Psychology (Odlin, 1989; Gass and Selinker, 1992; Jarvis and Pavlenko, 2007). Within this area of research, our work is most closely related to the Contrastive Analysis (CA) framework. Rooted in the comparative linguistics tradition, CA was first suggested by Fries (1945) and formalized by Lado (1957). In essence, CA examines foreign language performance, with a particular focus on learner difficulties, in light of a structural comparison between the native and the foreign languages. From its inception, CA was criticized for the lack of a solid predictive theory (Wardhaugh, 1970; Whitman and Jackson, 1972), leading to an ongoing scientific </context>
</contexts>
<marker>Gass, Selinker, 1992</marker>
<rawString>Susan M Gass and Larry Selinker. 1992. Language Transfer in Language Learning: Revised edition, volume 5. John Benjamins Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Georgi</author>
<author>Fei Xia</author>
<author>William Lewis</author>
</authors>
<title>Comparing language similarity across genetic and typologically-based groupings.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>385--393</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="12350" citStr="Georgi et al., 2010" startWordPosition="1886" endWordPosition="1889"> categories: Phonology, Morphology, Nominal Categories, Nominal Syntax, Verbal Categories, Word Order, Simple Clauses, Complex Sentences, Lexicon, Sign Languages and Other. Table 2 presents examples of WALS features belonging to different categories. The features can be associated with different variable types, including binary, categorical and ordinal, making their encoding a challenging task. Our strategy for addressing this issue is feature binarization (see section 5.3). An important challenge introduced by the WALS database is incomplete documentation. Previous studies (Daum´e III, 2009; Georgi et al., 2010) have estimated that only 14% of all the language-feature combinations in the database have documented values. While this issue is most acute for low-resource languages, even the well studied languages in our ESL dataset are lacking a significant portion of the feature values, inevitably hindering the effectiveness of our approach. We perform several preprocessing steps in order to select the features that will be used in this study. First, as our focus is on structural features that can be expressed in written form, we discard all the features associated with the categories Phonology, Lexicon</context>
</contexts>
<marker>Georgi, Xia, Lewis, 2010</marker>
<rawString>Ryan Georgi, Fei Xia, and William Lewis. 2010. Comparing language similarity across genetic and typologically-based groupings. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 385–393. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Jarvis</author>
<author>Aneta Pavlenko</author>
</authors>
<title>Crosslinguistic influence in language and cognition.</title>
<date>2007</date>
<publisher>Routledge.</publisher>
<contexts>
<context position="6169" citStr="Jarvis and Pavlenko, 2007" startWordPosition="944" endWordPosition="947">us and the typological data used in this study. In section 4 we motivate our native language oriented approach by providing a variance analysis for ESL errors across native languages. Section 5 presents the regression model for prediction of ESL error distributions. The bootstrapping framework which utilizes automatically inferred typological features is described in section 6. Finally, we present the conclusion and directions for future work in section 7. 2 Related Work Cross linguistic-transfer was extensively studied in SLA, Linguistics and Psychology (Odlin, 1989; Gass and Selinker, 1992; Jarvis and Pavlenko, 2007). Within this area of research, our work is most closely related to the Contrastive Analysis (CA) framework. Rooted in the comparative linguistics tradition, CA was first suggested by Fries (1945) and formalized by Lado (1957). In essence, CA examines foreign language performance, with a particular focus on learner difficulties, in light of a structural comparison between the native and the foreign languages. From its inception, CA was criticized for the lack of a solid predictive theory (Wardhaugh, 1970; Whitman and Jackson, 1972), leading to an ongoing scientific debate on the relevance of c</context>
</contexts>
<marker>Jarvis, Pavlenko, 2007</marker>
<rawString>Scott Jarvis and Aneta Pavlenko. 2007. Crosslinguistic influence in language and cognition. Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William H Kruskal</author>
<author>W Allen Wallis</author>
</authors>
<title>Use of ranks in one-criterion variance analysis.</title>
<date>1952</date>
<journal>Journal of the American statistical Association,</journal>
<volume>47</volume>
<issue>260</issue>
<pages>621</pages>
<contexts>
<context position="16356" citStr="Kruskal and Wallis, 1952" startWordPosition="2589" endWordPosition="2592">l future, Categories Tense No inflectional future. 30A Nominal Number of None, Two, Three, Categories Genders Four, Five or more. 87A Word Order Order of AN, NA, No Adjective dominant order, and Noun Only internally headed relative clauses. Table 2: Examples of WALS features. by examining whether there is a statistically significant difference in ESL error rates based on the native language of the learners. This analysis provides empirical justification for our approach, and to the best of our knowledge was not conducted in previous studies. To this end, we perform a Kruskal-Wallis (KW) test (Kruskal and Wallis, 1952) for each error type5. We treat the relative error frequency per word in each document as a sample6 (i.e. the relative frequencies of all the error types in a document sum to 1). The samples are associated with 14 groups, according to the native language of the document’s author. For each error type, the null hypothesis of the test is that error fraction samples of all the native languages are drawn from the same underlying distribution. In other words, rejection of the null hypothesis implies a significant difference between the relative error frequencies of at least one language pair. As sho</context>
</contexts>
<marker>Kruskal, Wallis, 1952</marker>
<rawString>William H Kruskal and W Allen Wallis. 1952. Use of ranks in one-criterion variance analysis. Journal of the American statistical Association, 47(260):583– 621.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Lado</author>
</authors>
<title>Linguistics across cultures: Applied linguistics for language teachers.</title>
<date>1957</date>
<contexts>
<context position="1751" citStr="Lado (1957)" startWordPosition="265" endWordPosition="266">to a wide range of difficulties in second language acquisition. 1 Introduction The study of cross-linguistic transfer, whereby properties of a native language influence performance in a foreign language, has a long tradition in Linguistics and Second Language Acquisition (SLA). Much of the linguistic work on this topic was carried out within the framework of Contrastive Analysis (CA), a theoretical approach that aims to explain difficulties in second language learning in terms of the relations between structures in the native and foreign languages. The basic hypothesis of CA was formulated by Lado (1957), who suggested that “we can predict and describe the patterns that will cause difficulty in learning, and those that will not cause difficulty, by comparing systematically the language and culture to be learned with the native language and culture of the student”. In particular, Lado postulated that divergences between the native and foreign languages will negatively affect learning and lead to increased error rates in the foreign language. This and subsequent hypotheses were soon met with criticism, targeting their lack of ability to provide reliable predictions, leading to an ongoing debate</context>
<context position="6395" citStr="Lado (1957)" startWordPosition="982" endWordPosition="983"> ESL error distributions. The bootstrapping framework which utilizes automatically inferred typological features is described in section 6. Finally, we present the conclusion and directions for future work in section 7. 2 Related Work Cross linguistic-transfer was extensively studied in SLA, Linguistics and Psychology (Odlin, 1989; Gass and Selinker, 1992; Jarvis and Pavlenko, 2007). Within this area of research, our work is most closely related to the Contrastive Analysis (CA) framework. Rooted in the comparative linguistics tradition, CA was first suggested by Fries (1945) and formalized by Lado (1957). In essence, CA examines foreign language performance, with a particular focus on learner difficulties, in light of a structural comparison between the native and the foreign languages. From its inception, CA was criticized for the lack of a solid predictive theory (Wardhaugh, 1970; Whitman and Jackson, 1972), leading to an ongoing scientific debate on the relevance of comparison based approaches. Important to our study is that the type of evidence used in this debate typically relies on small scale manual case study analysis. Our work seeks to reexamine the issue of predictive power of CA ba</context>
</contexts>
<marker>Lado, 1957</marker>
<rawString>Robert Lado. 1957. Linguistics across cultures: Applied linguistics for language teachers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Howard Levene</author>
</authors>
<title>Robust tests for equality of variances. Contributions to probability and statistics: Essays in honor of Harold Hotelling,</title>
<date>1960</date>
<pages>2--278</pages>
<contexts>
<context position="17354" citStr="Levene (1960)" startWordPosition="2760" endWordPosition="2762">nguages are drawn from the same underlying distribution. In other words, rejection of the null hypothesis implies a significant difference between the relative error frequencies of at least one language pair. As shown in table 1, we can reject the null hypothesis for 16 of the 20 grammatical error types with p &lt; 0.01, where Unnecessary Determiner, Unnecessary Preposition, Wrongly Derived Noun, and Replace Conjunction are the error types that do not exhibit dependence on the native language. 5We chose the non-parametric KW rank-based test over ANOVA, as according to the Shapiro-Wilk (1965) and Levene (1960) tests, the assumptions of normality and homogeneity of variance do not hold for our data. In practice, the ANOVA test yields similar results to those of the KW test. 6We also performed the KW test on the absolute error frequencies (i.e. raw counts) per word, obtaining similar results to the ones reported here on the relative frequencies per word. 97 Furthermore, the null hypothesis can be rejected for 13 error types with p &lt; 0.001. These results suggest that the relative error rates of the majority of the common structural grammatical errors in our corpus indeed differ between native speakers</context>
</contexts>
<marker>Levene, 1960</marker>
<rawString>Howard Levene. 1960. Robust tests for equality of variances. Contributions to probability and statistics: Essays in honor of Harold Hotelling, 2:278– 292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henry B Mann</author>
<author>Donald R Whitney</author>
</authors>
<title>On a test of whether one of two random variables is stochastically larger than the other. The annals of mathematical statistics,</title>
<date>1947</date>
<pages>50--60</pages>
<contexts>
<context position="18090" citStr="Mann and Whitney, 1947" startWordPosition="2883" endWordPosition="2886"> test yields similar results to those of the KW test. 6We also performed the KW test on the absolute error frequencies (i.e. raw counts) per word, obtaining similar results to the ones reported here on the relative frequencies per word. 97 Furthermore, the null hypothesis can be rejected for 13 error types with p &lt; 0.001. These results suggest that the relative error rates of the majority of the common structural grammatical errors in our corpus indeed differ between native speakers of different languages. We further extend our analysis by performing pairwise post-hoc Mann-Whitney (MW) tests (Mann and Whitney, 1947) in order to determine the number of language pairs that significantly differ with respect to their native speakers’ error fractions in ESL. Table 1 presents the number of language pairs that pass this test with p &lt; 0.01 for each error type. This inspection suggests Missing Determiner as the error type with the strongest dependence on the author’s native language, followed by Replace Determiner, Verb Tense, Word Order, Missing Pronoun and Replace Preposition. 5 Predicting Language Specific Error Distributions in ESL 5.1 Task Definition Given a language l E L, our task is to predict for this la</context>
</contexts>
<marker>Mann, Whitney, 1947</marker>
<rawString>Henry B Mann and Donald R Whitney. 1947. On a test of whether one of two random variables is stochastically larger than the other. The annals of mathematical statistics, pages 50–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryo Nagata</author>
<author>Edward Whittaker</author>
</authors>
<title>Reconstructing an indo-european family tree from nonnative english texts.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1137--1147</pages>
<institution>Sofia, Bulgaria. Association for Computational Linguistics.</institution>
<contexts>
<context position="8700" citStr="Nagata and Whittaker, 2013" startWordPosition="1335" endWordPosition="1338">rained on standard English text. Our work extends the native language tailored treatment of grammatical errors to a much larger set of error types. More importantly, this approach is limited by the availability of manual error annotations for the target language in order to obtain the required error counts. Our framework enables to bypass this annotation bottleneck by predicting language specific priors from typological information. The current investigation is most closely related to studies that demonstrate that ESL signal can be used to infer pairwise similarities between native languages (Nagata and Whittaker, 2013; Berzak et al., 2014) and in particular, tie 95 the similarities to the typological characteristics of these languages (Berzak et al., 2014). Our work inverts the direction of this analysis by starting with typological features, and utilizing them to predict error patterns in ESL. We also show that the two approaches can be combined in a bootstrapping strategy by first inferring typological properties from automatically extracted morphosyntactic ESL features, and in turn, using these properties for prediction of language specific error distributions in ESL. 3 Data 3.1 ESL Corpus We obtain ESL</context>
</contexts>
<marker>Nagata, Whittaker, 2013</marker>
<rawString>Ryo Nagata and Edward Whittaker. 2013. Reconstructing an indo-european family tree from nonnative english texts. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1137–1147, Sofia, Bulgaria. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diane Nicholls</author>
</authors>
<title>The cambridge learner corpus: Error coding and analysis for lexicography and elt.</title>
<date>2003</date>
<booktitle>In Proceedings of the Corpus Linguistics 2003 conference,</booktitle>
<pages>572--581</pages>
<contexts>
<context position="10114" citStr="Nicholls, 2003" startWordPosition="1557" endWordPosition="1558">r-intermediate level essays by native speakers of 16 languages2. Discarding Swedish and Dutch, which have only 16 documents combined, we take into consideration the remaining following 14 languages, with the corresponding number of documents in parenthesis: Catalan (64), Chinese (66), French (146), German (69), Greek (74), Italian (76), Japanese (82), Korean (86), Polish (76), Portuguese (68), Russian (83), Spanish (200), Thai (63) and Turkish (75). The resulting dataset contains 1228 documents with an average of 379 words per document. The FCE corpus has an elaborate error annotation scheme (Nicholls, 2003) and high quality of error annotations, making it particularly suitable for our investigation. The annotation scheme encompasses 75 different error types, covering a wide range of grammatical errors on different levels of granularity. As the typological features used in this work refer mainly to structural properties, we filter out spelling errors, punctuation errors and open class semantic errors, remaining with a list of grammatical errors that are typically related to language structure. We focus on the 20 most frequent error types3 in this list, which are presented and 1http://www.cambridg</context>
</contexts>
<marker>Nicholls, 2003</marker>
<rawString>Diane Nicholls. 2003. The cambridge learner corpus: Error coding and analysis for lexicography and elt. In Proceedings of the Corpus Linguistics 2003 conference, pages 572–581.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terence Odlin</author>
</authors>
<title>Language transfer: Crosslinguistic influence in language learning.</title>
<date>1989</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="2574" citStr="Odlin, 1989" startWordPosition="394" endWordPosition="395"> with the native language and culture of the student”. In particular, Lado postulated that divergences between the native and foreign languages will negatively affect learning and lead to increased error rates in the foreign language. This and subsequent hypotheses were soon met with criticism, targeting their lack of ability to provide reliable predictions, leading to an ongoing debate on the extent to which foreign language errors can be explained and predicted by examining native language structure. Differently from the SLA tradition, which emphasizes manual analysis of error case studies (Odlin, 1989), we address the heart of this controversy from a computational data-driven perspective, focusing on the issue of predictive power. We provide a formalization of the CA framework, and demonstrate that the relative frequency of grammatical errors in ESL can be reliably predicted from the typological properties of the native language and their relation to the typology of English using a regression model. Tested on 14 languages in a leave-one-out fashion, our model achieves a Mean Average Error (MAE) reduction of 21.8% in predicting the language specific relative frequency of the 20 most common E</context>
<context position="6116" citStr="Odlin, 1989" startWordPosition="938" endWordPosition="939">sfer. Section 3 describes the ESL corpus and the typological data used in this study. In section 4 we motivate our native language oriented approach by providing a variance analysis for ESL errors across native languages. Section 5 presents the regression model for prediction of ESL error distributions. The bootstrapping framework which utilizes automatically inferred typological features is described in section 6. Finally, we present the conclusion and directions for future work in section 7. 2 Related Work Cross linguistic-transfer was extensively studied in SLA, Linguistics and Psychology (Odlin, 1989; Gass and Selinker, 1992; Jarvis and Pavlenko, 2007). Within this area of research, our work is most closely related to the Contrastive Analysis (CA) framework. Rooted in the comparative linguistics tradition, CA was first suggested by Fries (1945) and formalized by Lado (1957). In essence, CA examines foreign language performance, with a particular focus on learner difficulties, in light of a structural comparison between the native and the foreign languages. From its inception, CA was criticized for the lack of a solid predictive theory (Wardhaugh, 1970; Whitman and Jackson, 1972), leading </context>
</contexts>
<marker>Odlin, 1989</marker>
<rawString>Terence Odlin. 1989. Language transfer: Crosslinguistic influence in language learning. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alla Rozovskaya</author>
<author>Dan Roth</author>
</authors>
<title>Algorithm selection and model adaptation for esl correction tasks.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>924--933</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7970" citStr="Rozovskaya and Roth, 2011" startWordPosition="1221" endWordPosition="1224">ts (Tetreault et al., 2013), including features derived from the CA framework (Wong and Dras, 2009). A related line of inquiry which is closer to our work deals with the identification of ESL syntactic patterns that are specific to speakers of different native languages (Swanson and Charniak, 2013; Swanson and Charniak, 2014). Our approach differs from this research direction by focusing on grammatical errors, and emphasizing prediction of language specific patterns rather than their identification. Previous work on grammatical error correction that examined determiner and preposition errors (Rozovskaya and Roth, 2011; Rozovskaya and Roth, 2014) incorporated native language specific priors in models that are otherwise trained on standard English text. Our work extends the native language tailored treatment of grammatical errors to a much larger set of error types. More importantly, this approach is limited by the availability of manual error annotations for the target language in order to obtain the required error counts. Our framework enables to bypass this annotation bottleneck by predicting language specific priors from typological information. The current investigation is most closely related to studie</context>
</contexts>
<marker>Rozovskaya, Roth, 2011</marker>
<rawString>Alla Rozovskaya and Dan Roth. 2011. Algorithm selection and model adaptation for esl correction tasks. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 924–933. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alla Rozovskaya</author>
<author>Dan Roth</author>
</authors>
<title>Building a state-of-the-art grammatical error correction system.</title>
<date>2014</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>2</volume>
<issue>10</issue>
<contexts>
<context position="7998" citStr="Rozovskaya and Roth, 2014" startWordPosition="1225" endWordPosition="1228">, including features derived from the CA framework (Wong and Dras, 2009). A related line of inquiry which is closer to our work deals with the identification of ESL syntactic patterns that are specific to speakers of different native languages (Swanson and Charniak, 2013; Swanson and Charniak, 2014). Our approach differs from this research direction by focusing on grammatical errors, and emphasizing prediction of language specific patterns rather than their identification. Previous work on grammatical error correction that examined determiner and preposition errors (Rozovskaya and Roth, 2011; Rozovskaya and Roth, 2014) incorporated native language specific priors in models that are otherwise trained on standard English text. Our work extends the native language tailored treatment of grammatical errors to a much larger set of error types. More importantly, this approach is limited by the availability of manual error annotations for the target language in order to obtain the required error counts. Our framework enables to bypass this annotation bottleneck by predicting language specific priors from typological information. The current investigation is most closely related to studies that demonstrate that ESL </context>
</contexts>
<marker>Rozovskaya, Roth, 2014</marker>
<rawString>Alla Rozovskaya and Dan Roth. 2014. Building a state-of-the-art grammatical error correction system. Transactions of the Association for Computational Linguistics, 2(10):419–434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Sanford Shapiro</author>
<author>Martin B Wilk</author>
</authors>
<title>An analysis of variance test for normality (complete samples).</title>
<date>1965</date>
<journal>Biometrika,</journal>
<pages>591--611</pages>
<marker>Shapiro, Wilk, 1965</marker>
<rawString>Samuel Sanford Shapiro and Martin B Wilk. 1965. An analysis of variance test for normality (complete samples). Biometrika, pages 591–611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Swanson</author>
<author>Eugene Charniak</author>
</authors>
<title>Extracting the native language signal for second language acquisition.</title>
<date>2013</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>85--94</pages>
<contexts>
<context position="7643" citStr="Swanson and Charniak, 2013" startWordPosition="1178" endWordPosition="1181">mputational, data-driven approach. Computational work touching on crosslinguistic transfer was mainly conducted in relation to the Native Language Identification (NLI) task, in which the goal is to determine the native language of the author of an ESL text. Much of this work focuses on experimentation with different feature sets (Tetreault et al., 2013), including features derived from the CA framework (Wong and Dras, 2009). A related line of inquiry which is closer to our work deals with the identification of ESL syntactic patterns that are specific to speakers of different native languages (Swanson and Charniak, 2013; Swanson and Charniak, 2014). Our approach differs from this research direction by focusing on grammatical errors, and emphasizing prediction of language specific patterns rather than their identification. Previous work on grammatical error correction that examined determiner and preposition errors (Rozovskaya and Roth, 2011; Rozovskaya and Roth, 2014) incorporated native language specific priors in models that are otherwise trained on standard English text. Our work extends the native language tailored treatment of grammatical errors to a much larger set of error types. More importantly, thi</context>
</contexts>
<marker>Swanson, Charniak, 2013</marker>
<rawString>Ben Swanson and Eugene Charniak. 2013. Extracting the native language signal for second language acquisition. In HLT-NAACL, pages 85–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Swanson</author>
<author>Eugene Charniak</author>
</authors>
<title>Data driven language transfer hypotheses. EACL</title>
<date>2014</date>
<pages>169</pages>
<contexts>
<context position="7672" citStr="Swanson and Charniak, 2014" startWordPosition="1182" endWordPosition="1185">roach. Computational work touching on crosslinguistic transfer was mainly conducted in relation to the Native Language Identification (NLI) task, in which the goal is to determine the native language of the author of an ESL text. Much of this work focuses on experimentation with different feature sets (Tetreault et al., 2013), including features derived from the CA framework (Wong and Dras, 2009). A related line of inquiry which is closer to our work deals with the identification of ESL syntactic patterns that are specific to speakers of different native languages (Swanson and Charniak, 2013; Swanson and Charniak, 2014). Our approach differs from this research direction by focusing on grammatical errors, and emphasizing prediction of language specific patterns rather than their identification. Previous work on grammatical error correction that examined determiner and preposition errors (Rozovskaya and Roth, 2011; Rozovskaya and Roth, 2014) incorporated native language specific priors in models that are otherwise trained on standard English text. Our work extends the native language tailored treatment of grammatical errors to a much larger set of error types. More importantly, this approach is limited by the </context>
</contexts>
<marker>Swanson, Charniak, 2014</marker>
<rawString>Ben Swanson and Eugene Charniak. 2014. Data driven language transfer hypotheses. EACL 2014, page 169.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
<author>Daniel Blanchard</author>
<author>Aoife Cahill</author>
</authors>
<title>A report on the first native language identification shared task.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<pages>48--57</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="7372" citStr="Tetreault et al., 2013" startWordPosition="1134" endWordPosition="1137">n the relevance of comparison based approaches. Important to our study is that the type of evidence used in this debate typically relies on small scale manual case study analysis. Our work seeks to reexamine the issue of predictive power of CA based methods using a computational, data-driven approach. Computational work touching on crosslinguistic transfer was mainly conducted in relation to the Native Language Identification (NLI) task, in which the goal is to determine the native language of the author of an ESL text. Much of this work focuses on experimentation with different feature sets (Tetreault et al., 2013), including features derived from the CA framework (Wong and Dras, 2009). A related line of inquiry which is closer to our work deals with the identification of ESL syntactic patterns that are specific to speakers of different native languages (Swanson and Charniak, 2013; Swanson and Charniak, 2014). Our approach differs from this research direction by focusing on grammatical errors, and emphasizing prediction of language specific patterns rather than their identification. Previous work on grammatical error correction that examined determiner and preposition errors (Rozovskaya and Roth, 2011; </context>
</contexts>
<marker>Tetreault, Blanchard, Cahill, 2013</marker>
<rawString>Joel Tetreault, Daniel Blanchard, and Aoife Cahill. 2013. A report on the first native language identification shared task. In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications, pages 48–57. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Wardhaugh</author>
</authors>
<title>The contrastive analysis hypothesis. TESOL quarterly,</title>
<date>1970</date>
<pages>123--130</pages>
<contexts>
<context position="6678" citStr="Wardhaugh, 1970" startWordPosition="1025" endWordPosition="1026">udied in SLA, Linguistics and Psychology (Odlin, 1989; Gass and Selinker, 1992; Jarvis and Pavlenko, 2007). Within this area of research, our work is most closely related to the Contrastive Analysis (CA) framework. Rooted in the comparative linguistics tradition, CA was first suggested by Fries (1945) and formalized by Lado (1957). In essence, CA examines foreign language performance, with a particular focus on learner difficulties, in light of a structural comparison between the native and the foreign languages. From its inception, CA was criticized for the lack of a solid predictive theory (Wardhaugh, 1970; Whitman and Jackson, 1972), leading to an ongoing scientific debate on the relevance of comparison based approaches. Important to our study is that the type of evidence used in this debate typically relies on small scale manual case study analysis. Our work seeks to reexamine the issue of predictive power of CA based methods using a computational, data-driven approach. Computational work touching on crosslinguistic transfer was mainly conducted in relation to the Native Language Identification (NLI) task, in which the goal is to determine the native language of the author of an ESL text. Muc</context>
</contexts>
<marker>Wardhaugh, 1970</marker>
<rawString>Ronald Wardhaugh. 1970. The contrastive analysis hypothesis. TESOL quarterly, pages 123–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Randal L Whitman</author>
<author>Kenneth L Jackson</author>
</authors>
<title>The unpredictability of contrastive analysis.</title>
<date>1972</date>
<booktitle>Language learning,</booktitle>
<pages>22--1</pages>
<contexts>
<context position="6706" citStr="Whitman and Jackson, 1972" startWordPosition="1027" endWordPosition="1030">guistics and Psychology (Odlin, 1989; Gass and Selinker, 1992; Jarvis and Pavlenko, 2007). Within this area of research, our work is most closely related to the Contrastive Analysis (CA) framework. Rooted in the comparative linguistics tradition, CA was first suggested by Fries (1945) and formalized by Lado (1957). In essence, CA examines foreign language performance, with a particular focus on learner difficulties, in light of a structural comparison between the native and the foreign languages. From its inception, CA was criticized for the lack of a solid predictive theory (Wardhaugh, 1970; Whitman and Jackson, 1972), leading to an ongoing scientific debate on the relevance of comparison based approaches. Important to our study is that the type of evidence used in this debate typically relies on small scale manual case study analysis. Our work seeks to reexamine the issue of predictive power of CA based methods using a computational, data-driven approach. Computational work touching on crosslinguistic transfer was mainly conducted in relation to the Native Language Identification (NLI) task, in which the goal is to determine the native language of the author of an ESL text. Much of this work focuses on ex</context>
</contexts>
<marker>Whitman, Jackson, 1972</marker>
<rawString>Randal L Whitman and Kenneth L Jackson. 1972. The unpredictability of contrastive analysis. Language learning, 22(1):29–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sze-Meng Jojo Wong</author>
<author>Mark Dras</author>
</authors>
<title>Contrastive analysis and native language identification.</title>
<date>2009</date>
<booktitle>In Proceedings of the Australasian Language Technology Association Workshop,</booktitle>
<pages>53--61</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="7444" citStr="Wong and Dras, 2009" startWordPosition="1146" endWordPosition="1149">hat the type of evidence used in this debate typically relies on small scale manual case study analysis. Our work seeks to reexamine the issue of predictive power of CA based methods using a computational, data-driven approach. Computational work touching on crosslinguistic transfer was mainly conducted in relation to the Native Language Identification (NLI) task, in which the goal is to determine the native language of the author of an ESL text. Much of this work focuses on experimentation with different feature sets (Tetreault et al., 2013), including features derived from the CA framework (Wong and Dras, 2009). A related line of inquiry which is closer to our work deals with the identification of ESL syntactic patterns that are specific to speakers of different native languages (Swanson and Charniak, 2013; Swanson and Charniak, 2014). Our approach differs from this research direction by focusing on grammatical errors, and emphasizing prediction of language specific patterns rather than their identification. Previous work on grammatical error correction that examined determiner and preposition errors (Rozovskaya and Roth, 2011; Rozovskaya and Roth, 2014) incorporated native language specific priors </context>
</contexts>
<marker>Wong, Dras, 2009</marker>
<rawString>Sze-Meng Jojo Wong and Mark Dras. 2009. Contrastive analysis and native language identification. In Proceedings of the Australasian Language Technology Association Workshop, pages 53–61. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helen Yannakoudakis</author>
<author>Ted Briscoe</author>
<author>Ben Medlock</author>
</authors>
<title>A new dataset and method for automatically grading ESOL texts.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<pages>180--189</pages>
<contexts>
<context position="9405" citStr="Yannakoudakis et al., 2011" startWordPosition="1444" endWordPosition="1448">ogical characteristics of these languages (Berzak et al., 2014). Our work inverts the direction of this analysis by starting with typological features, and utilizing them to predict error patterns in ESL. We also show that the two approaches can be combined in a bootstrapping strategy by first inferring typological properties from automatically extracted morphosyntactic ESL features, and in turn, using these properties for prediction of language specific error distributions in ESL. 3 Data 3.1 ESL Corpus We obtain ESL essays from the Cambridge First Certificate in English (FCE) learner corpus (Yannakoudakis et al., 2011), a publicly available subset of the Cambridge Learner Corpus (CLC)1. The corpus contains upper-intermediate level essays by native speakers of 16 languages2. Discarding Swedish and Dutch, which have only 16 documents combined, we take into consideration the remaining following 14 languages, with the corresponding number of documents in parenthesis: Catalan (64), Chinese (66), French (146), German (69), Greek (74), Italian (76), Japanese (82), Korean (86), Polish (76), Portuguese (68), Russian (83), Spanish (200), Thai (63) and Turkish (75). The resulting dataset contains 1228 documents with a</context>
</contexts>
<marker>Yannakoudakis, Briscoe, Medlock, 2011</marker>
<rawString>Helen Yannakoudakis, Ted Briscoe, and Ben Medlock. 2011. A new dataset and method for automatically grading ESOL texts. In ACL, pages 180–189.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>