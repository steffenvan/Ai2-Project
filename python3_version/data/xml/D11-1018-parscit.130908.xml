<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000885">
<title confidence="0.977761">
Inducing Sentence Structure from Parallel Corpora for Reordering
</title>
<author confidence="0.978653">
John DeNero Jakob Uszkoreit
</author>
<affiliation confidence="0.935943">
Google Research Google Research
</affiliation>
<email confidence="0.996517">
denero@google.com uszkoreit@google.com
</email>
<sectionHeader confidence="0.996628" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99959480952381">
When translating among languages that differ
substantially in word order, machine transla-
tion (MT) systems benefit from syntactic pre-
ordering—an approach that uses features from
a syntactic parse to permute source words
into a target-language-like order. This paper
presents a method for inducing parse trees au-
tomatically from a parallel corpus, instead of
using a supervised parser trained on a tree-
bank. These induced parses are used to pre-
order source sentences. We demonstrate that
our induced parser is effective: it not only
improves a state-of-the-art phrase-based sys-
tem with integrated reordering, but also ap-
proaches the performance of a recent pre-
ordering method based on a supervised parser.
These results show that the syntactic structure
which is relevant to MT pre-ordering can be
learned automatically from parallel text, thus
establishing a new application for unsuper-
vised grammar induction.
</bodyText>
<sectionHeader confidence="0.998879" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.989253391304348">
Recent work in statistical machine translation (MT)
has demonstrated the effectiveness of syntactic pre-
ordering: an approach that permutes source sen-
tences into a target-like order as a pre-processing
step, using features of a source-side syntactic parse
(Collins et al., 2005; Xu et al., 2009). Syntac-
tic pre-ordering is particularly effective at apply-
ing structural transformations, such as the order-
ing change from a subject-verb-object (SVO) lan-
guage like English to a subject-object-verb (SOV)
language like Japanese. However, state-of-the-art
193
pre-ordering methods require a supervised syntac-
tic parser to provide structural information about
each sentence. We propose a method that learns
both a parsing model and a reordering model di-
rectly from a word-aligned parallel corpus. Our ap-
proach, which we call Structure Induction for Re-
ordering (STIR), requires no syntactic annotations
to train, but approaches the performance of a re-
cent syntactic pre-ordering method in a large-scale
English-Japanese MT system.
STIR predicts a pre-ordering via two pipelined
models: (1) parsing and (2) tree reordering. The
first model induces a binary parse, which defines
the space of possible reorderings. In particular, only
trees that properly separate verbs from their object
noun phrases will license an SVO to SOV trans-
formation. The second model locally permutes this
tree. Our approach resembles work with binary syn-
chronous grammars (Wu, 1997), but is distinct in its
emphasis on monolingual parsing as a first phase,
and in selecting reorderings without the aid of a
target-side language model.
The parsing model is trained to maximize the
conditional likelihood of trees that license the re-
orderings implied by observed word alignments in
a parallel corpus. This objective differs from those
of previous grammar induction models, which typ-
ically focus on succinctly explaining the observed
source language corpus via latent hierarchical struc-
ture (Pereira and Schabes, 1992; Klein and Man-
ning, 2002). Our convex objective allows us to train
a feature-rich log-linear parsing model, even without
supervised treebank data.
Focusing on pre-ordering for MT leads to a new
</bodyText>
<note confidence="0.948571">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 193–203,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.9998235">
perspective on the canonical NLP task of grammar
induction—one which marries the wide-spread sci-
entific interest in unsupervised parsing models with
a clear application and extrinsic evaluation method-
ology. To support this perspective, we highlight sev-
eral avenues of future research throughout the paper.
We evaluate STIR in a large-scale English-
Japanese machine translation system. We measure
how closely our predicted reorderings match those
implied by hand-annotated word alignments. STIR
approaches the performance of the state-of-the-art
pre-ordering method described in Genzel (2010),
which learns reordering rules for supervised tree-
bank parses. STIR gives a translation improvement
of 3.84 BLEU over a standard phrase-based system
with an integrated reordering model.
</bodyText>
<sectionHeader confidence="0.946079" genericHeader="introduction">
2 Parsing and Reordering Models
</sectionHeader>
<bodyText confidence="0.999897842105263">
STIR consists of two pipelined log-linear models for
parsing and reordering, as well as a third model for
inducing trees from parallel corpora, trees that serve
to train the first two models. This section describes
the domain and structure of each model, while Sec-
tion 3 describes features and learning objectives.
Figure 1 depicts the relationship between the three
models. For each aligned sentence pair in a paral-
lel corpus, the parallel parsing model selects a bi-
nary tree t over the source sentence, such that t li-
censes the reordering pattern implied by the word
alignment (Section 2.2). The monolingual parsing
model is trained to generate t without inspecting the
alignments or target sentences (Section 2.3). The
tree reordering model is trained to locally permute t
to produce the target order (Section 2.4). In the con-
text of an MT system, the monolingual parser and
tree reorderer are applied in sequence to pre-order
source sentences.
</bodyText>
<subsectionHeader confidence="0.973684">
2.1 Unlabeled Binary Trees
</subsectionHeader>
<bodyText confidence="0.999523875">
Unlabeled binary trees are central to the STIR
pipeline. We represent trees via their constituent
spans. Let [k, E) denote a span of indices of a 0-
indexed word sequence e, where i E [k, E) if k ≤
i &lt; E. [0, n) denotes the root span covering the
whole sequence, where n = |e|.
A tree t = (T , N) consists of a set of termi-
nal spans T and non-terminal spans N. Each non-
</bodyText>
<figureCaption confidence="0.98606275">
Figure 1: The training and reordering pipeline for STIR
contains three models. The inputs and outputs of each
model are indicated by solid arrows, while dashed arrows
indicate the source of training examples. The parallel
parsing model provides tree and reordering examples that
are used to train the other models. In an MT system, the
trained reordering pipeline (shaded) pre-orders a source
sentence without target-side or alignment information.
</figureCaption>
<bodyText confidence="0.73081225">
terminal span [k, E) E N has a split point m, where
k &lt; m &lt; E splits the span into child spans [k, m)
and [m, E). Formally, a pair (T , N) is a well-formed
tree over [0, n) if:
</bodyText>
<listItem confidence="0.99984525">
• The root span [0, n) E T U N.
• For each [k, E) E N, there exists exactly one m
such that {[k, m), [m, E)} C T U N.
• Terminal spans T are disjoint, but cover [0, n).
</listItem>
<bodyText confidence="0.999186">
These trees include multi-word terminal spans. It
is often convenient to refer to a split non-terminal
triple (k, m, E) that include a non-terminal span
[k, E) and its split point m. We denote the set of
these triples as
</bodyText>
<equation confidence="0.970535">
N+ = {(k, m, E) : {[k, E), [k, m), [m, E)}E T U N} .
</equation>
<subsectionHeader confidence="0.994736">
2.2 Parallel Parsing Model
</subsectionHeader>
<bodyText confidence="0.999264555555555">
The first step in the STIR pipeline is to select a bi-
nary parse of each source sentence in a parallel cor-
pus, one which licenses the reordering implied by
a word alignment. Let the triple (e, f, A) be an
aligned sentence pair, where e and f are word se-
quences and A is a set of links (i, j) indicating that
ei aligns to fj.
The set A provides ordering information over e.
To simplify definitions below, we first adjust A to
</bodyText>
<figure confidence="0.988015705882353">
Parallel
parsing
model
Tree
reordering
model
S O V
S V O
Monolingual
parsing
model
S V O
Parallel Trees &amp;
corpus rotations
S V O
s o v
S V O
</figure>
<page confidence="0.971746">
194
</page>
<equation confidence="0.869698777777778">
ignore all unaligned words in f. respects A&apos;. Then,
A&apos; = {(i, c(j)) : (i, j) E Al sT (k, `) = { wTφT(k, `) if [k, `) aligns
c(j) = |{j&apos; : j&apos; &lt; j n ]i such that (i, j&apos;) E Al|. contiguously
−oo otherwise
c(j) is the number of aligned words in f prior to
position j. Next, we define a projection function:
Imin j, max j + 11
jEJi jEJi
Ji = {j : (i,j) E A&apos;l ,
</equation>
<bodyText confidence="0.9911295">
and let ψ(i) = 0 if ei is unaligned. We can extend
this projection function to spans [k, `) of e via union:
</bodyText>
<equation confidence="0.87614525">
ψ(k, `) = U ψ(i) .
k&lt;i&lt;t
We say that a span [k, `) aligns contiguously if
b(i, j) E A&apos;, j E ψ(k, `) implies i E [k, `) ,
</equation>
<bodyText confidence="0.997903416666667">
which corresponds to the familiar definition that
[k, `) is one side of an extractable phrase pair. Un-
aligned spans do not align contiguously.
Given this notion of projection, we can relate
trees to alignments. A tree (T, N) over e respects
an alignment A&apos; if all [k, `) E T U N align con-
tiguously, and for every (k, m, `), the projections
ψ(k, m) and ψ(m, `) are adjacent. Projections are
adjacent if the left bound of one is the right bound
of the other, or if either is empty.
The parallel parsing model is a linear model over
trees that respect A&apos;, which factors over spans.
</bodyText>
<equation confidence="0.9992075">
s(t) = � wTφT (k, `) + � wNφN(k, m, `)
[k,t)ET (k,m,t)EN+
</equation>
<bodyText confidence="0.992700285714286">
where the weight vector w = (wT wN) scores fea-
tures φT on terminal spans and φN on non-terminal
spans and their split points.
Exact inference under this model can be per-
formed via a dynamic program that exploits the fol-
lowing recurrence. Let s(k, `) be the score of the
highest scoring binary tree over the span [k, `) that
</bodyText>
<equation confidence="0.9984795">
f(k, m, `) = s(k, m) + s(m, `) + wNφN(k, m, `)
{ f(k, m, `) if ψ(k, m) is
adjacent
to ψ(m, `)
−oo otherwise
s(k, `) = max [sT (k, `), sN(k, `)l
</equation>
<bodyText confidence="0.9997285">
Above, sT scores terminal spans while filtering out
those which are not contiguous. The function f
scores non-terminal spans by the sum of their child
scores and additional features φN of the parent
span. The recursive function sN maximizes over
split points while filtering out non-adjacent children.
The recurrence will assign a score of −oo to any
tree that does not respect A&apos;. Section 3 describes
the features of this model. s(k, `) can be computed
efficiently using the CKY algorithm.
</bodyText>
<subsectionHeader confidence="0.996107">
2.3 Monolingual Parsing Model
</subsectionHeader>
<bodyText confidence="0.993176333333333">
The monolingual parsing model is trained to select
the same trees as the parallel model, but without
any features or constraints that reference word align-
ments. Hence, it can be applied to a source sentence
before its translation is known.
This model also scores untyped binary trees ac-
cording to a linear model parameterized by some
w = (wT wN) that weights features on terminal and
non-terminal spans, respectively. We impose a max-
imum terminal length of L, but otherwise allow any
binary tree. The score s(k, `) of the maximal tree
over a span [k, `) satisfies the familiar recurrence:
</bodyText>
<equation confidence="0.951907142857143">
�
wTφT(k,`) if ` − k &lt; L
sM(k, `) =
−oo otherwise
s(k, `) = max I
sL(k, `), max f (k, m, `)J
m:k&lt;m&lt;t
</equation>
<bodyText confidence="0.995220333333333">
Inference under this recurrence can also be per-
formed using the CKY algorithm. Section 3 de-
scribes the feature functions and training method.
</bodyText>
<equation confidence="0.8687265">
sN(k, `) = max
m:k&lt;m&lt;t
</equation>
<page confidence="0.99007">
195
</page>
<subsectionHeader confidence="0.976585">
2.4 Tree Reordering Model
</subsectionHeader>
<bodyText confidence="0.9996224">
Given a binary tree (T, N) over a sentence e, we
can reorder e by (a) permuting the children of non-
terminals and (b) permuting the words of terminal
spans. Formally, a reordering r assigns each termi-
nal [k, E) E T a permutation u(k, E) of its words
and each split non-terminal (k, m, E) a permutation
b(k, m, E) of its subspans, which can be either mono-
tone or inverted, in the case of a binary tree. The per-
mutation u(k, E) of a non-terminal span [k, E) E/ T
is defined recursively as:
</bodyText>
<equation confidence="0.966447">
�
u(k, m) u(m, E) if b(k, m, E) is monotone
u(m, E) u(k, m) if b(k, m, E) is inverted
</equation>
<bodyText confidence="0.999863958333333">
In this paper, we use a reordering model that
selects each terminal u(k, E) and each split non-
terminal b(k, m, E) independently, conditioned on
the sentence e. While the sub-problems of choos-
ing u(k, E) and b(k, m, E) are formally similar, we
consider and evaluate them separately because the
former deals only with local reordering, while the
latter involves long-distance structural reordering.
Because our trees are binary, selecting b(k, m, E)
is a binary classification problem. Selecting u(k, E)
for a terminal is a multiclass prediction problem that
chooses among the (E − k)! permutations of ter-
minal [k, E). Development experiments in English-
Japanese yielded the best results with a maximum
terminal span length L = 2. Hence, in experiments,
terminal reordering is also binary classification.
Because each permutation is independent of all
the others, reordering inference via a single pass
through the tree is optimal. However, a more com-
plex search procedure would be necessary to main-
tain optimality if the decision of b(k, m, E) ref-
erenced other permutations, such as u([k, m)) or
u([m, E)). Coupling together inference in this way
represents a possible area of future study.
</bodyText>
<sectionHeader confidence="0.99784" genericHeader="method">
3 Features and Training Objectives
</sectionHeader>
<bodyText confidence="0.997663111111111">
Each of these linear models factors over features
on either terminal spans [k, E) or split non-terminals
(k, m, E). Features vary in concert with the learning
objectives and search spaces of each model.
Figure 2 shows an example sentence from our de-
velopment corpus, including the target (Japanese)
Target --nf w Ha tc wn i�tLj�Lt
Gloss pair [subj] list to add to was
Positions 0 1 2 3 4 5
</bodyText>
<figureCaption confidence="0.69012">
Figure 2: An example from our development corpus, an-
</figureCaption>
<bodyText confidence="0.97223325">
notated with the information flow (left) and annotations
and predictions (right). Alignments inform projections,
which are spans of the target associated with each source
word. The parallel parse may only include contiguous
spans. On the other hand, the induced parse may only
condition on the source sentence. The induced order
is restricted by the induced parse. In this example, the
induced order is incorrect because the subject and verb
form a constituent in the induced parse that cannot be sep-
arated correctly by the reordering model. This example
demonstrates the important role of the induced parser in
the STIR pipeline.
sentence, alignment, projections, parallel parser pre-
diction, monolingual parser prediction, and pre-
dicted permutation. The feature descriptions below
reference this example.
</bodyText>
<subsectionHeader confidence="0.999492">
3.1 Tree Reordering Features
</subsectionHeader>
<bodyText confidence="0.999978083333333">
The tree reordering model consists of two local clas-
sifiers: the first can invert the two children of a
non-terminal span, while the second can permute the
words of a terminal span. The non-terminal classi-
fier is trained on the trees that are selected by the
parallel parsing model; the weights are chosen to
minimize log loss of the correct permutation of each
span (i.e., a maximum entropy model).
The terminal model is a multi-class maximum en-
tropy model over the n! possible permutations of the
words in a terminal span. To make reordering more
robust to monolingual parsing errors, the terminal
</bodyText>
<figure confidence="0.9993438125">
Reference pair the lexicon to added
Order
Alignment
Projections
Induced
Parse
Induced
Parallel
Parse
Source
[ [ [ the lexicon] to ] [ pair added ] ]
Order
[0,2) [4,6)
pair added to the lexicon
[3,4)
∅ [2,3)
</figure>
<page confidence="0.993513">
196
</page>
<bodyText confidence="0.997552375">
model is trained on all contiguous spans of each sen-
tence up to length L, not just the terminal spans in-
cluded in the parallel parsing tree.
The feature templates we apply to each span can
be divided into the following five categories. Most
features are shared across the two models.
Statistics. From a large aligned parallel corpus, we
compute two statistics.
</bodyText>
<listItem confidence="0.973075875">
• PC(e) = count(e aligns contiguously) is the frac-
count(e)
tion of the time that a phrase e aligns con-
tiguously to some target phrase, for all
phrases up to length 4.
• PD(ei, ej) is the fraction of the time that
two co-occuring source words ei and ej
align to adjacent positions in the target.
</listItem>
<bodyText confidence="0.99902195">
The first statistic indicates whether a contigu-
ous phrase in the source should stay contiguous
after reordering. Features based on this statistic
apply to both terminal and short non-terminal
spans. The second statistic indicates when a
possibly discontiguous pair of words should be
adjacent after reordering. This statistic is ap-
plied to pairs of words that would end up ad-
jacent after an inversion: ek and e`−1 for span
[k, `). For instance, PC(added to) = 0.68 and
PD(lexicon, to) = 0.19.
Cluster. All source word types are clustered into
word classes, which together maximize likeli-
hood of the source side of a large parallel cor-
pus under a hidden Markov model, as in Uszko-
reit and Brants (2008). Indicator features based
on clusterings over c classes are defined over
words ek, em−1, em and e`−1, as well as word
sequences for spans up to length 4. Features are
included for a variety of clusterings with sizes
</bodyText>
<equation confidence="0.977812">
{ s 4
c E 2 ,2 ,...,211}
</equation>
<bodyText confidence="0.999687772727273">
POS. A supervised part-of-speech (POS) tagger
provides coarse tags drawn from a 12 tag set
T = {Verb, Noun, Pronoun, Conjunction,
Adjective, Adverb, Adposition, Determiner,
Number, Particle/Function word, Punctuation,
Other} (Petrov et al., 2011). Features based on
these tags are computed identically to the fea-
tures based on word classes.
Lexical. For a list of very common words in the
source language, we include lexical indicator
features for the boundary words ek and e`−1.
For instance, the word “to” triggers a reorder-
ing, as do prepositions in general.
Length. Length computed as `−k, length as a frac-
tion of sentence length, and quantized length
features all contribute structural information.
All features except POS are computed directly
from aligned parallel corpora. The Cluster and POS
features play a similar role of expressing reordering
patterns over collections of similar words. The ab-
lation study in Section 5 compares these two feature
sets directly.
</bodyText>
<subsectionHeader confidence="0.998579">
3.2 Monolingual Parsing Features
</subsectionHeader>
<bodyText confidence="0.998976857142857">
The monolingual parsing model is also trained dis-
criminatively, but involves structured prediction, as
in a conditional random field (Lafferty et al., 2001).
Conditional likelihood objectives have proven ef-
fective for supervised parsers (Finkel et al., 2008;
Petrov and Klein, 2008). Recall that the score of a
tree t = (T , N) factors over spans.
</bodyText>
<equation confidence="0.999122">
s(t) = X wTφT (k, `) + X wNφN(k, m, `)
[k,`)ET [k,`)EN
exp [s(t)]
P(t|e) =
P(t&apos;)EB(e) exp [s(tl)]
</equation>
<bodyText confidence="0.999747333333333">
where B(e) is the set of well-formed trees over e.
The parallel parsing model (Section 2.2) produces
a tree over the source sentence of each aligned sen-
tence pair; these trees serve as our training exam-
ples. We can maximize their conditional likelihood
according to this model via gradient methods. Each
tree t over sentence e has a cumulative feature vector
of dimension |w |= |wT |+|wN|, formed by stacking
the terminal and non-terminal vectors:
</bodyText>
<equation confidence="0.859574">
φ(t, e) = X φT (k, `) X φN(k, m, `)
([k,`)ET [k,`)EN
</equation>
<bodyText confidence="0.990151">
The contribution to the gradient objective from a tree
t for a sentence e is the difference between observed
</bodyText>
<page confidence="0.933503">
197
</page>
<bodyText confidence="0.998109849056604">
and expected feature vectors. In particular, terminal spans have features on the
L(w) = � log P(t|e) sequence of POS tags and word clusters they con-
(t,e) tain, while a split non-terminal (k, m, `) is scored
VL(w) = based on the tags/clusters of the following words and
(t,e) word pairs: ek, em−1, em, e`−1, (ek, em), (ek, e`−1),
� ⎡ and (em−1, em). The head word of a constituent of-
⎣φ(t, e) − P(t&apos;|e) · φ(t&apos;, e) ten appears at one of its boundary positions, and so
t�EB(e) these features provide a proxy for explicitly tracking
� constituent heads in a parser.
The second term in the gradient—the expected Context features also appear, inspired by the
feature vector—can be computed efficiently because constituent-context model of Klein and Manning
the feature vector φ(t&apos;) decomposes over the spans (2001). For a span [k, `), we add indicator fea-
of t&apos;. In particular, the inside-outside algorithm pro- tures on the POS tags and word clusters of the words
vides the quantities needed to compute the poste- (ek−1, e`) which directly surround the constituent.
rior probability of each terminal span [k, `) and each Features based on the statistic PC(e) are also
split non-terminal (k, m, `). Let, α(k, `) and β(k, `) scored in the parsing model on all spans of length
be the outside and inside scores of a span, respec- up to 4.
tively, computed using a log-sum semiring. Then, Length features score various structural aspects of
the log probablility that a terminal span [k, `) ap- each non-terminal (k, m, `), such as m−k
pears in the tree for e under the posterior distribu- `−k , m−k
tion P(t|e) is α(k, `) + wTφT(k, `) . Note that this k−m, etc.
terminal posterior does not include the inside score One particularly interesting direction for future
of the span. work is to train a single parsing model that licenses
The log probability that a non-terminal span [k, `) the reordering for several different languages. We
appears with split point m is might expect that a reasonable syntactic bracket-
α(k, `) + β(k, m) + β(m, `) + wNφN(k, m, `) ing of English would simultaneously license the
By the linearity of expectations, the expected feature head-final transformations necessary to produce a
vector for e can be computed by averaging the fea- Japanese or Korean ordering, and also the verb-
ture vectors of each terminal and split non-terminal subject-object ordering of formal Arabic.1
span, weighted by their posterior probabilities. 3.3 Parallel Parsing Features
In future work, one may consider training this The parallel parsing model does not run at transla-
model to maximize the likelihood of an entire forest tion time, but instead provides training examples to
of trees, in order to maintain uncertainty over which the other two models. Hence, defining an appropri-
tree licensed a particular alignment. ate learning objective for this model is more chal-
We are currently using l-BFGS to optimize this lenging.
objective over a relatively small training corpus, for In the end, we are interested in selecting trees that
35 iterations. For this reason, we only include lexi- we can learn to reproduce without an alignment (via
cal features for very common words. Distributed or the monolingual parsing model) and which can be
online training algorithms would perhaps allow for reordered reliably (via the tree reordering model).
more training data (and therefore more lexicalized Note that by construction, any tree selected by the
features) to be used in the future. parallel parsing model can be reordered perfectly.
The features of this parsing model share the same However, some of those trees will be easier to re-
types as the tree reordering models, but vary in their produce and reorder than others.
definition. The differences stem primarily from the
different purpose of the model: here, features are
not meant to decide how to reorder the sentence, but
instead how to bracket the sentence hierarchically so
that it can be reordered.
198
1An astute reviewer pointed out that no binary tree over an
S-V-O sentence can license both S-O-V and V-S-O orderings.
Hence, parse trees that are induced for multilingual reordering
will need n-ary branches.
</bodyText>
<subsectionHeader confidence="0.944714">
3.3.1 Reordering Loss Function
</subsectionHeader>
<bodyText confidence="0.9999206875">
In order to measure the effectiveness of a reorder-
ing pipeline, we would like a metric over permu-
tations. Fortunately, permutation loss for machine
translation is already an established component of
the METEOR metric, called a fragmentation penalty
(Lavie and Agarwal, 2007). We define a slight vari-
ant of METEOR’s fragmentation penalty that ranges
from 0 to 1.
Given a sentence e, a reference permutation σ*
of (0, · · · , |e |− 1), and a hypothesized permuta-
tion ˆσ, let chunks(ˆσ, σ*) be the minimum number
of “chunks” in ˆσ: the number of elements in a par-
tition of σˆ such that each contiguous subsequence is
also contiguous in σ*.
We can define the reordering score between two
permutations in terms of chunks.
</bodyText>
<equation confidence="0.990295">
R(ˆσ, σ*) = |σ* |−� ��1&amp;,a*) (1)
i
</equation>
<bodyText confidence="0.99838615">
If σˆ = σ*, then chunks(ˆσ, σ*) = 1. If no
two adjacent elements of σˆ are adjacent in σ*, then
chunks(ˆσ, σ*) = |σ|. Hence, the metric defined by
Equation 1 ranges from 0 to 1.
The reference permutation σ* of a source sen-
tence e can be defined from an aligned sentence pair
(e, f, A) by sorting the words ez of e by the left
bound of their projection ψ(i). Null-aligned words
are placed to the left of the next aligned word to their
right in the original order.
The reordering-specific loss functions defined in
Equation 1 has been shown to correlate with human
judgements of translation quality, especially for lan-
guage pairs with substantial reordering like English-
Japanese (Talbot et al., 2011). Other reordering-
specific loss functions also correlate with human
judgements (Birch et al., 2010). Future research
could experiment with alternative reordering-based
loss functions, such as Kendall’s Tau, as suggested
by Birch and Osborne (2011).
</bodyText>
<subsectionHeader confidence="0.803924">
3.3.2 Parallel Parsing Objective
</subsectionHeader>
<bodyText confidence="0.999977285714286">
We can train our reordering pipeline by dividing
an aligned parallel corpus into two halves, A and B,
where the monolingual parsing and tree reordering
models are trained on A, and their effectiveness is
evaluated on held-out set B. Then, the effectiveness
of the parallel parsing model is best measured on B,
given fully trained parsing and reordering models.
</bodyText>
<equation confidence="0.993713">
� �
[w · φ(t)] , σ* (2)
</equation>
<bodyText confidence="0.9997505">
Evaluating this objective involves training the
other two models. Therefore, we can only hope to
optimize this objective directly over a small dimen-
sional space, for instance using a grid search. For
this reason, we currently only include 4 features in
the parallel parsing model for a tree t:
</bodyText>
<listItem confidence="0.912884333333333">
1. The sum of log PC(e) for all terminals e in t
with length greater than 1.
2. The count of length-1 terminal spans in t.
3. The count of terminals of length greater than k.
4. An indicator feature of whether parentheses
and brackets are balanced in each span.
</listItem>
<bodyText confidence="0.999991333333334">
The model weights of features 3 and 4 above are
fixed to large negative constants to prefer terminal
spans of length up to k and spans with balanced
punctuation. The weight of feature 1 is fixed to 1,
and weight 2 was set via line search to 0.3. Ties
among trees were broken randomly.
Of course, the problem of selecting training trees
need not be directly tied to the end task of reorder-
ing, as in Equation 2. Instead, we might consider se-
lecting trees according to a likelihood objective on
the source side of a parallel corpus, similar to how
monolingual grammar induction models often opti-
mize corpus likelihood. In such a case, we could
imagine training models with far more parameters,
but we leave this research direction to future work.
</bodyText>
<sectionHeader confidence="0.999944" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.9998822">
Our approach to inducing hierarchical structure for
pre-ordering relates to several areas of previous
work, including other pre-ordering methods, re-
ordering models more generally, and models for the
unsupervised induction of syntactic structure.
</bodyText>
<subsectionHeader confidence="0.972674">
4.1 Pre-Ordering Models
</subsectionHeader>
<bodyText confidence="0.999782">
Our reordering pipeline is intentionally similar to
approaches that use a treebank-trained supervised
</bodyText>
<figure confidence="0.698108333333333">
� σ arg max
(e,v∗)EB R
tEB(e)
</figure>
<page confidence="0.994908">
199
</page>
<bodyText confidence="0.9999636875">
parser to reorder source sentences at training and
translation time (Xia and McCord, 2004; Collins
et al., 2005; Lee et al., 2010). Given a supervised
parser, a rule-based pre-ordering procedure can ei-
ther be specified by hand (Xu et al., 2009) or learned
automatically (Genzel, 2010). We consider our ap-
proach to be a direct extension of these approaches,
but one which induces structure from parallel cor-
pora rather than relying on a treebank.
Tromble (2009) show that some pre-ordering ben-
efits can be realized without a parsing step at all, by
instead casting pre-ordering as a permutation mod-
eling problem. While not splitting the task of pre-
ordering into parsing and tree rordering, that work
shows that pre-ordering models can be learned di-
rectly from parallel corpora.
</bodyText>
<subsectionHeader confidence="0.825932">
4.2 Integrated Reordering Models
</subsectionHeader>
<bodyText confidence="0.9999627">
Distortion models have been primary components
in machine translation models since the advent of
statistical MT (Brown et al., 1993). In modern
systems, reordering models are integrated into de-
coders as additional features in a discriminative log-
linear model, which also includes a language model,
translation features, etc. In these cases, reordering
models interact with the strong signal of a target-
side language model. Because ordering prediciton
is conflated with target-side generation, evaluations
are conducted on the entire generated output, which
cannot isolate reordering errors from other sorts of
errors, like lexical selection.
Despite these differences, certain integrated re-
ordering models are similar in character to syntactic
pre-ordering models. In particular, the tree rotation
model of Yamada and Knight (2001) posited that re-
ordering decisions involve rotations of a source-side
syntax tree. The parameters of such a model can be
trained by treating tree rotations as latent variables
in a factored translation model, which parameterizes
reordering and transfer separately but performs joint
inference (Dyer and Resnik, 2010). Syntactic re-
ordering and transfer can also be modeled jointly,
for instance in a tree-to-string translation system pa-
rameterized by a transducer grammar.
While the success of integrated reordering models
certainly highlights the importance of reordering in
machine translation systems, we see several advan-
tages to a pipelined, pre-ordering approach. First,
the pre-ordering model can be trained and evaluated
directly. Second, pre-ordering models need not fac-
tor according to the same dynamic program as the
translation model. Third, the same reordering can be
applied during training (for word alignment and rule
extraction) and translation time without adding com-
plexity to the extraction and decoding algorithms.
Of course, integrating our model into translation in-
ference represents a potentially fruitful avenue of fu-
ture research.
</bodyText>
<subsectionHeader confidence="0.996993">
4.3 Grammar Induction
</subsectionHeader>
<bodyText confidence="0.999979911764706">
The language processing community actively works
on the problem of automatically inducing grammat-
ical structure from a corpus of text (Pereira and
Schabes, 1992). Some success in this area has
been demonstrated via generative models (Klein and
Manning, 2002), which often benefit from well-
chosen priors (Cohen and Smith, 2009) or poste-
rior constraints (Ganchev et al., 2009). In princi-
ple, these models must discover the syntactic pat-
terns that govern a language from the sequences of
word tokens alone. These models are often evalu-
ated relative to reference treebank annotations.
Grammar induction in the context of machine
translation reordering offers different properties.
The alignment patterns in a parallel corpus pro-
vide an additional signal to models that is strongly
tied to syntactic properties of the aligned languages.
Also, the evaluation is straightforward—any syntac-
tic structure that supports the prediction of reorder-
ing is rewarded.
Kuhn (2004) applied alignment-based constraints
to the problem of inducing probabilistic context-free
grammars, and showed an improvement with respect
to Penn Treebank annotations over monolingual in-
duction. Their work is distinct from ours because it
focused on projecting distituents across languages,
but mirrors ours in demonstrating that there is a role
for aligned parallel corpora in grammar induction.
Snyder et al. (2009) also demonstrated that paral-
lel corpora can play a role in improving the quality
of grammar induction models. Their work differs
from ours in that it focuses on multilingual lexical
statistics and dependency relationships, rather than
reordering patterns.
</bodyText>
<page confidence="0.98332">
200
</page>
<table confidence="0.999898363636364">
Prec Parsing F1 Tree Reordering RO Pipeline
Rec accN accT R
Annotated word All features 82.0 87.8 84.8 97.3 93.6 87.7 80.5
alignments
All but POS 81.3 87.7 84.4 97.0 92.6 86.6 79.4
All but Cluster 81.2 87.9 84.4 95.9 93.2 83.8 77.8
All but POS &amp; Cluster 75.4 82.0 78.5 89.2 89.7 66.8 49.7
Learned alignments All features 72.5 61.0 66.3 91.6 83.3 72.0 49.5
Monotone order 34.9
Inverted order 30.8
Syntactic pre-ordering (Genzel, 2010) 66.0
</table>
<tableCaption confidence="0.9994975">
Table 1: Accuracy of individual monolingual parsing and reordering models, as well as complete pipelines trained on
annotated and learned word alignments.
</tableCaption>
<subsectionHeader confidence="0.99913">
4.4 Bilingual Grammar Induction
</subsectionHeader>
<bodyText confidence="0.9999816">
Also related to STIR is previous work on bilingual
grammar induction from parallel corpora using ITG
(Blunsom et al., 2009). These models have focused
on learning phrasal translations — which are the ter-
minal productions of a synchronous ITG — rather
than reordering patterns that occur higher in the tree.
Hence, while this paper shares formal machinery
and data sources with that line of work, the models
themselves target orthogonal aspects of the transla-
tion problem.
</bodyText>
<sectionHeader confidence="0.987748" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.99997675">
As training data for our models we used 14,000 En-
glish sentences that were sampled from the web,
translated into Japanese, and manually annotated
with word alignments. The annotation was carried
out by the original translators to promote consis-
tency of analysis. Talbot et al. (2011) describes this
corpus in further detail. A held-out test set of 396
manually aligned sentence pairs was used to evalu-
ate reordering accuracy. Statistics used for features
were computed from the full, unreordered, automat-
ically word aligned, parallel training corpus used for
the translation experiments described below.
</bodyText>
<subsectionHeader confidence="0.662552">
5.1 Individual Model Accuracy
</subsectionHeader>
<bodyText confidence="0.999970617647059">
We evaluate the accuracy of the monolingual parsing
models by their span F1, relative to the trees induced
by the parallel parsing model on the held-out set.
The first row of Table 1 shows that the model was
able to reliably replicate the parses induced from
alignments, at 84.8% F1. The following three lines
show that removing either POS or cluster features
degrades performance by only 0.4% F1, indicating
that POS features are largely redundant in the pres-
ence of automatically induced word class features.
Hence, no syntactic annotations are necessary at all
to train the model.
We report two accuracy measures for the tree re-
ordering model, one for non-terminal spans (accN)
and one for terminal spans (accT). The following
column, labeled RO, is the reordering score of the
tree reordering model applied to the oracle parallel
parser tree. This score is independent of the mono-
lingual parsing model.
The fifth line, labeled learned alignments, shows
the impact of replacing manual alignment anno-
tations with learned Model 1 alignments, trained
in both directions and combined with the refined
heuristic (Brown et al., 1993; Och et al., 1999).
The pipeline column shows the reordering score
of the full STIR pipeline compared to two simple
baselines: Monotone applies no reordering, while
inverted simply inverts the word order. STIR out-
performs all three other systems.
In the final line, we compare to the syntax-based
pre-ordering system described in Genzel (2010).
This approach first parses source sentences with a
supervised parser, then learns reordering rules that
permute those trees.
</bodyText>
<subsectionHeader confidence="0.997667">
5.2 Translation Quality
</subsectionHeader>
<bodyText confidence="0.997031333333333">
We apply STIR as a pre-ordering step in a state-
of-the-art phrase-based translation system from En-
glish to Japanese (Koehn et al., 2003). At training
</bodyText>
<page confidence="0.993652">
201
</page>
<bodyText confidence="0.99997119047619">
time, pre-ordering is applied to the source side of ev-
ery sentence pair in the training corpus before word
alignment and phrase extraction. Likewise, every in-
put sentence is pre-ordered at translation time.
Our baseline is the same system, but without pre-
ordering. Our implementation’s integrated distor-
tion model is expressed as a negative exponential
function of the distance between the current and pre-
vious source phrase, with a maximum jump width
of four words. Our in-house decoder is based on the
alignment template approach to translation and uses
a small set of standard feature functions during de-
coding (Och and Ney, 2004).
We compare to using an integrated lexicalized re-
ordering model (Koehn and Monz, 2005), a forest-
to-string translation model (Zhang et al., 2011) and
finally the syntactic pre-ordering technique of Gen-
zel (2010) applied to the phrase-based baseline. We
evaluate the impact of the proposed approach on
translation quality as measured by the BLEU score
on the token level (Papineni et al., 2002).
The translation model is trained on 700 million
tokens of parallel text, primarily extracted from the
web using automated parallel document identifica-
tion (Uszkoreit et al., 2010). Alignments were
learned using two iterations of Model 1 and two it-
erations of the HMM alignment model (Vogel et al.,
1996). Our dev and test data sets consist of 3100
and 1000 English sentences, respectively, that were
randomly sampled from the web and translated into
Japanese. The eval set is a larger, heterogenous
set containing 12,784 sentences. In all cases, the
final log-linear models were optimized on the dev
set using lattice-based Minimum Error Rate Train-
ing (Macherey et al., 2008).
Table 2 shows that STIR improves over the base-
line system by a large margin of 3.84% BLEU (test).
These gains are comparable in magnitude to those
reported in Genzel (2010). Our induced parses are
competitive with both systems that use syntactic
parsers and substantially outperform lexicalized re-
ordering.
</bodyText>
<sectionHeader confidence="0.99933" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999884">
We have demonstrated that induced parses suffice
for pre-ordering. We hope that future work in gram-
mar induction will also consider pre-ordering as an
</bodyText>
<table confidence="0.999644">
dev BLEU % eval
test
Baseline 18.65 19.02 13.60
Lexicalized Reordering 19.45 18.92 13.99
Forest-to-String 23.08 22.85 16.60
Syntactic Pre-ordering 22.59 23.28 16.31
STIR: annotated 22.46 22.86 16.39
STIR: learned 20.28 20.66 14.64
</table>
<tableCaption confidence="0.996405666666667">
Table 2: Translation quality, measured by BLEU, for En-
glish to Japanese. STIR results use both manually anno-
tated and learned alignments.
</tableCaption>
<bodyText confidence="0.574033">
extrinsic evaluation.
</bodyText>
<sectionHeader confidence="0.995826" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999495771428571">
Alexandra Birch and Miles Osborne. 2011. Reordering
metrics for MT. In Proceedings of the Association for
Computational Linguistics.
Alexandra Birch, Phil Blunsom, and Miles Osborne.
2010. Metrics for MT evaluation: Evaluating reorder-
ing. Machine Translation.
Phil Blunsom, Trevor Cohn, Chris Dyer, and Miles Os-
borne. 2009. A Gibbs sampler for phrasal syn-
chronous grammar induction. In Proceedings of the
Association for Computational Linguistics.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The mathematics
of statistical machine translation: Parameter estima-
tion. Computational Linguistics.
Shay Cohen and Noah Smith. 2009. Shared logistic
normal distributions for soft parameter tying in unsu-
pervised grammar induction. In Proceedings of the
North American Chapter of the Association for Com-
putational Linguistics.
Michael Collins, Philipp Koehn, and Ivona Kucerova.
2005. Clause restructuring for statistical machine
translation. In Proceedings of the Association for
Computational Linguistics.
Chris Dyer and Philip Resnik. 2010. Context-free re-
ordering, finite-state translation. In Proceedings of the
North American Chapter of the Association for Com-
putational Linguistics.
Jenny Rose Finkel, Alex Kleeman, and Christopher D.
Manning. 2008. Efficient, feature-based, conditional
random field parsing. In Proceedings of the Associa-
tion for Computational Linguistics.
Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar.
2009. Dependency grammar induction via bitext pro-
jection constraints. In Proceedings of the Association
for Computational Linguistics.
</reference>
<page confidence="0.971973">
202
</page>
<reference confidence="0.999516074766356">
Dmitriy Genzel. 2010. Automatically learning source-
side reordering rules for large scale machine transla-
tion. In Proceedings of the Conference on Computa-
tional Linguistics.
Dan Klein and Christopher D. Manning. 2001. Natu-
ral language grammar induction using a constituent-
context model. In Proceedings of Neural Information
Processing Systems.
Dan Klein and Christopher D. Manning. 2002. A gener-
ative constituent-context model for improved grammar
induction. In Proceedings of the Association for Com-
putational Linguistics.
Philipp Koehn and Christof Monz. 2005. Shared task:
Statistical machine translation between european lan-
guages. In Proceedings of the International Workshop
on Spoken Language Translation.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of the North American Chapter of the Association
for Computational Linguistics.
Jonas Kuhn. 2004. Experiments in parallel-text based
grammar induction. In Proceedings of the Association
for Computational Linguistics.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. In Pro-
ceedings of the International Conference on Machine
Learning.
Alon Lavie and Abhaya Agarwal. 2007. METEOR: An
automatic metric for mt evaluation with high levels of
correlation with human judgments. In Proceedings of
ACL Workshop on Statistical Machine Translation.
Young-Suk Lee, Bing Zhao, and Xiaoqiang Luo. 2010.
Constituent reordering and syntax models for English-
to-Japanese statistical machine translation. In Pro-
ceedings of the Conference on Computational Linguis-
tics.
Wolfgang Macherey, Franz Och, Ignacio Thayer, and
Jakob Uszkoreit. 2008. Lattice-based minimum er-
ror rate training for statistical machine translation. In
Proceedings of the Conference on Empirical Methods
in Natural Language Processing.
Franz Josef Och and Hermann Ney. 2004. The align-
ment template approach to statistical machine transla-
tion. Computational Linguistics.
Franz Josef Och, Christopher Tillman, and Hermann Ney.
1999. Improved alignment models for statistical ma-
chine translation. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic eval-
uation of machine translation. In Proceedings of the
Association for Computational Linguistics.
Fernando Pereira and Yves Schabes. 1992. Inside-
outside reestimation from partially bracketed corpora.
In Proceedings of the Association for Computational
Linguistics.
Slav Petrov and Dan Klein. 2008. Sparse multi-scale
grammars for discriminative latent variable parsing. In
Proceedings of the Conference on Empirical Methods
in Natural Language Processing.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011.
A universal part-of-speech tagset. Technical report.
Benjamin Snyder, Tahira Naseem, and Regina Barzilay.
2009. Unsupervised multilingual grammar induction.
In Proceedings of the Association for Computational
Linguistics.
David Talbot, Hideto Kazawa, Hiroshi Ichikawa, Ja-
son Katz-Brown, Masakazu Seno, and Franz J. Och.
2011. A lightweight evaluation framework for ma-
chine translation reordering. In Proceedings of the
Sixth Workshop on Statistical Machine Translation.
Roy Tromble. 2009. Learning linear ordering problems
for better translation. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing.
Jakob Uszkoreit and Thorsten Brants. 2008. Distributed
word clustering for large scale class-based language
modeling in machine translation. In Proceedings of
the Association for Computational Linguistics.
Jakob Uszkoreit, Jay Ponte, Ashok Popat, and Moshe Du-
biner. 2010. Large scale parallel document mining for
machine translation. In Proceedings of the Conference
on Computational Linguistics.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proceedings of the Conference on Computa-
tional linguistics.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics.
Fei Xia and Michael McCord. 2004. Improving a sta-
tistical mt system with automatically learned rewrite
patterns. In Proceedings of the Conference on Com-
putational Linguistics.
Peng Xu, Jaeho Kang, Michael Ringgard, and Franz Och.
2009. Using a dependency parser to improve smt for
subject-object-verb languages. In Proceedings of the
North American Chapter of the Association for Com-
putational Linguistics.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In Proceedings of the As-
sociation for Computational Linguistics.
Hao Zhang, Licheng Fang, Peng Xu, and Xiaoyun Wu.
2011. Binarized forest to string translation. In Pro-
ceedings of the Association for Computational Lin-
guistics.
</reference>
<page confidence="0.999182">
203
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.869697">
<title confidence="0.999934">Inducing Sentence Structure from Parallel Corpora for Reordering</title>
<author confidence="0.998226">John DeNero Jakob Uszkoreit</author>
<affiliation confidence="0.967839">Google Research Google Research</affiliation>
<email confidence="0.990474">denero@google.comuszkoreit@google.com</email>
<abstract confidence="0.995790090909091">When translating among languages that differ substantially in word order, machine translation (MT) systems benefit from syntactic preordering—an approach that uses features from a syntactic parse to permute source words into a target-language-like order. This paper presents a method for inducing parse trees automatically from a parallel corpus, instead of using a supervised parser trained on a treebank. These induced parses are used to preorder source sentences. We demonstrate that our induced parser is effective: it not only improves a state-of-the-art phrase-based system with integrated reordering, but also approaches the performance of a recent preordering method based on a supervised parser. These results show that the syntactic structure which is relevant to MT pre-ordering can be learned automatically from parallel text, thus establishing a new application for unsupervised grammar induction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alexandra Birch</author>
<author>Miles Osborne</author>
</authors>
<title>Reordering metrics for MT.</title>
<date>2011</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="23822" citStr="Birch and Osborne (2011)" startWordPosition="4072" endWordPosition="4075">left bound of their projection ψ(i). Null-aligned words are placed to the left of the next aligned word to their right in the original order. The reordering-specific loss functions defined in Equation 1 has been shown to correlate with human judgements of translation quality, especially for language pairs with substantial reordering like EnglishJapanese (Talbot et al., 2011). Other reorderingspecific loss functions also correlate with human judgements (Birch et al., 2010). Future research could experiment with alternative reordering-based loss functions, such as Kendall’s Tau, as suggested by Birch and Osborne (2011). 3.3.2 Parallel Parsing Objective We can train our reordering pipeline by dividing an aligned parallel corpus into two halves, A and B, where the monolingual parsing and tree reordering models are trained on A, and their effectiveness is evaluated on held-out set B. Then, the effectiveness of the parallel parsing model is best measured on B, given fully trained parsing and reordering models. � � [w · φ(t)] , σ* (2) Evaluating this objective involves training the other two models. Therefore, we can only hope to optimize this objective directly over a small dimensional space, for instance using</context>
</contexts>
<marker>Birch, Osborne, 2011</marker>
<rawString>Alexandra Birch and Miles Osborne. 2011. Reordering metrics for MT. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Birch</author>
<author>Phil Blunsom</author>
<author>Miles Osborne</author>
</authors>
<title>Metrics for MT evaluation: Evaluating reordering. Machine Translation.</title>
<date>2010</date>
<contexts>
<context position="23674" citStr="Birch et al., 2010" startWordPosition="4052" endWordPosition="4055">The reference permutation σ* of a source sentence e can be defined from an aligned sentence pair (e, f, A) by sorting the words ez of e by the left bound of their projection ψ(i). Null-aligned words are placed to the left of the next aligned word to their right in the original order. The reordering-specific loss functions defined in Equation 1 has been shown to correlate with human judgements of translation quality, especially for language pairs with substantial reordering like EnglishJapanese (Talbot et al., 2011). Other reorderingspecific loss functions also correlate with human judgements (Birch et al., 2010). Future research could experiment with alternative reordering-based loss functions, such as Kendall’s Tau, as suggested by Birch and Osborne (2011). 3.3.2 Parallel Parsing Objective We can train our reordering pipeline by dividing an aligned parallel corpus into two halves, A and B, where the monolingual parsing and tree reordering models are trained on A, and their effectiveness is evaluated on held-out set B. Then, the effectiveness of the parallel parsing model is best measured on B, given fully trained parsing and reordering models. � � [w · φ(t)] , σ* (2) Evaluating this objective involv</context>
</contexts>
<marker>Birch, Blunsom, Osborne, 2010</marker>
<rawString>Alexandra Birch, Phil Blunsom, and Miles Osborne. 2010. Metrics for MT evaluation: Evaluating reordering. Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phil Blunsom</author>
<author>Trevor Cohn</author>
<author>Chris Dyer</author>
<author>Miles Osborne</author>
</authors>
<title>A Gibbs sampler for phrasal synchronous grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="31175" citStr="Blunsom et al., 2009" startWordPosition="5228" endWordPosition="5231">ments All but POS 81.3 87.7 84.4 97.0 92.6 86.6 79.4 All but Cluster 81.2 87.9 84.4 95.9 93.2 83.8 77.8 All but POS &amp; Cluster 75.4 82.0 78.5 89.2 89.7 66.8 49.7 Learned alignments All features 72.5 61.0 66.3 91.6 83.3 72.0 49.5 Monotone order 34.9 Inverted order 30.8 Syntactic pre-ordering (Genzel, 2010) 66.0 Table 1: Accuracy of individual monolingual parsing and reordering models, as well as complete pipelines trained on annotated and learned word alignments. 4.4 Bilingual Grammar Induction Also related to STIR is previous work on bilingual grammar induction from parallel corpora using ITG (Blunsom et al., 2009). These models have focused on learning phrasal translations — which are the terminal productions of a synchronous ITG — rather than reordering patterns that occur higher in the tree. Hence, while this paper shares formal machinery and data sources with that line of work, the models themselves target orthogonal aspects of the translation problem. 5 Experimental Results As training data for our models we used 14,000 English sentences that were sampled from the web, translated into Japanese, and manually annotated with word alignments. The annotation was carried out by the original translators t</context>
</contexts>
<marker>Blunsom, Cohn, Dyer, Osborne, 2009</marker>
<rawString>Phil Blunsom, Trevor Cohn, Chris Dyer, and Miles Osborne. 2009. A Gibbs sampler for phrasal synchronous grammar induction. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics.</title>
<date>1993</date>
<contexts>
<context position="26906" citStr="Brown et al., 1993" startWordPosition="4586" endWordPosition="4589">ct extension of these approaches, but one which induces structure from parallel corpora rather than relying on a treebank. Tromble (2009) show that some pre-ordering benefits can be realized without a parsing step at all, by instead casting pre-ordering as a permutation modeling problem. While not splitting the task of preordering into parsing and tree rordering, that work shows that pre-ordering models can be learned directly from parallel corpora. 4.2 Integrated Reordering Models Distortion models have been primary components in machine translation models since the advent of statistical MT (Brown et al., 1993). In modern systems, reordering models are integrated into decoders as additional features in a discriminative loglinear model, which also includes a language model, translation features, etc. In these cases, reordering models interact with the strong signal of a targetside language model. Because ordering prediciton is conflated with target-side generation, evaluations are conducted on the entire generated output, which cannot isolate reordering errors from other sorts of errors, like lexical selection. Despite these differences, certain integrated reordering models are similar in character t</context>
<context position="33310" citStr="Brown et al., 1993" startWordPosition="5568" endWordPosition="5571">Hence, no syntactic annotations are necessary at all to train the model. We report two accuracy measures for the tree reordering model, one for non-terminal spans (accN) and one for terminal spans (accT). The following column, labeled RO, is the reordering score of the tree reordering model applied to the oracle parallel parser tree. This score is independent of the monolingual parsing model. The fifth line, labeled learned alignments, shows the impact of replacing manual alignment annotations with learned Model 1 alignments, trained in both directions and combined with the refined heuristic (Brown et al., 1993; Och et al., 1999). The pipeline column shows the reordering score of the full STIR pipeline compared to two simple baselines: Monotone applies no reordering, while inverted simply inverts the word order. STIR outperforms all three other systems. In the final line, we compare to the syntax-based pre-ordering system described in Genzel (2010). This approach first parses source sentences with a supervised parser, then learns reordering rules that permute those trees. 5.2 Translation Quality We apply STIR as a pre-ordering step in a stateof-the-art phrase-based translation system from English to</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay Cohen</author>
<author>Noah Smith</author>
</authors>
<title>Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="29109" citStr="Cohen and Smith, 2009" startWordPosition="4909" endWordPosition="4912">plied during training (for word alignment and rule extraction) and translation time without adding complexity to the extraction and decoding algorithms. Of course, integrating our model into translation inference represents a potentially fruitful avenue of future research. 4.3 Grammar Induction The language processing community actively works on the problem of automatically inducing grammatical structure from a corpus of text (Pereira and Schabes, 1992). Some success in this area has been demonstrated via generative models (Klein and Manning, 2002), which often benefit from wellchosen priors (Cohen and Smith, 2009) or posterior constraints (Ganchev et al., 2009). In principle, these models must discover the syntactic patterns that govern a language from the sequences of word tokens alone. These models are often evaluated relative to reference treebank annotations. Grammar induction in the context of machine translation reordering offers different properties. The alignment patterns in a parallel corpus provide an additional signal to models that is strongly tied to syntactic properties of the aligned languages. Also, the evaluation is straightforward—any syntactic structure that supports the prediction o</context>
</contexts>
<marker>Cohen, Smith, 2009</marker>
<rawString>Shay Cohen and Noah Smith. 2009. Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction. In Proceedings of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
<author>Ivona Kucerova</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1375" citStr="Collins et al., 2005" startWordPosition="197" endWordPosition="200">th integrated reordering, but also approaches the performance of a recent preordering method based on a supervised parser. These results show that the syntactic structure which is relevant to MT pre-ordering can be learned automatically from parallel text, thus establishing a new application for unsupervised grammar induction. 1 Introduction Recent work in statistical machine translation (MT) has demonstrated the effectiveness of syntactic preordering: an approach that permutes source sentences into a target-like order as a pre-processing step, using features of a source-side syntactic parse (Collins et al., 2005; Xu et al., 2009). Syntactic pre-ordering is particularly effective at applying structural transformations, such as the ordering change from a subject-verb-object (SVO) language like English to a subject-object-verb (SOV) language like Japanese. However, state-of-the-art 193 pre-ordering methods require a supervised syntactic parser to provide structural information about each sentence. We propose a method that learns both a parsing model and a reordering model directly from a word-aligned parallel corpus. Our approach, which we call Structure Induction for Reordering (STIR), requires no synt</context>
<context position="26075" citStr="Collins et al., 2005" startWordPosition="4452" endWordPosition="4455">g models with far more parameters, but we leave this research direction to future work. 4 Related Work Our approach to inducing hierarchical structure for pre-ordering relates to several areas of previous work, including other pre-ordering methods, reordering models more generally, and models for the unsupervised induction of syntactic structure. 4.1 Pre-Ordering Models Our reordering pipeline is intentionally similar to approaches that use a treebank-trained supervised � σ arg max (e,v∗)EB R tEB(e) 199 parser to reorder source sentences at training and translation time (Xia and McCord, 2004; Collins et al., 2005; Lee et al., 2010). Given a supervised parser, a rule-based pre-ordering procedure can either be specified by hand (Xu et al., 2009) or learned automatically (Genzel, 2010). We consider our approach to be a direct extension of these approaches, but one which induces structure from parallel corpora rather than relying on a treebank. Tromble (2009) show that some pre-ordering benefits can be realized without a parsing step at all, by instead casting pre-ordering as a permutation modeling problem. While not splitting the task of preordering into parsing and tree rordering, that work shows that p</context>
</contexts>
<marker>Collins, Koehn, Kucerova, 2005</marker>
<rawString>Michael Collins, Philipp Koehn, and Ivona Kucerova. 2005. Clause restructuring for statistical machine translation. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Philip Resnik</author>
</authors>
<title>Context-free reordering, finite-state translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="27921" citStr="Dyer and Resnik, 2010" startWordPosition="4733" endWordPosition="4736"> entire generated output, which cannot isolate reordering errors from other sorts of errors, like lexical selection. Despite these differences, certain integrated reordering models are similar in character to syntactic pre-ordering models. In particular, the tree rotation model of Yamada and Knight (2001) posited that reordering decisions involve rotations of a source-side syntax tree. The parameters of such a model can be trained by treating tree rotations as latent variables in a factored translation model, which parameterizes reordering and transfer separately but performs joint inference (Dyer and Resnik, 2010). Syntactic reordering and transfer can also be modeled jointly, for instance in a tree-to-string translation system parameterized by a transducer grammar. While the success of integrated reordering models certainly highlights the importance of reordering in machine translation systems, we see several advantages to a pipelined, pre-ordering approach. First, the pre-ordering model can be trained and evaluated directly. Second, pre-ordering models need not factor according to the same dynamic program as the translation model. Third, the same reordering can be applied during training (for word al</context>
</contexts>
<marker>Dyer, Resnik, 2010</marker>
<rawString>Chris Dyer and Philip Resnik. 2010. Context-free reordering, finite-state translation. In Proceedings of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Alex Kleeman</author>
<author>Christopher D Manning</author>
</authors>
<title>Efficient, feature-based, conditional random field parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="17128" citStr="Finkel et al., 2008" startWordPosition="2930" endWordPosition="2933">ized length features all contribute structural information. All features except POS are computed directly from aligned parallel corpora. The Cluster and POS features play a similar role of expressing reordering patterns over collections of similar words. The ablation study in Section 5 compares these two feature sets directly. 3.2 Monolingual Parsing Features The monolingual parsing model is also trained discriminatively, but involves structured prediction, as in a conditional random field (Lafferty et al., 2001). Conditional likelihood objectives have proven effective for supervised parsers (Finkel et al., 2008; Petrov and Klein, 2008). Recall that the score of a tree t = (T , N) factors over spans. s(t) = X wTφT (k, `) + X wNφN(k, m, `) [k,`)ET [k,`)EN exp [s(t)] P(t|e) = P(t&apos;)EB(e) exp [s(tl)] where B(e) is the set of well-formed trees over e. The parallel parsing model (Section 2.2) produces a tree over the source sentence of each aligned sentence pair; these trees serve as our training examples. We can maximize their conditional likelihood according to this model via gradient methods. Each tree t over sentence e has a cumulative feature vector of dimension |w |= |wT |+|wN|, formed by stacking th</context>
</contexts>
<marker>Finkel, Kleeman, Manning, 2008</marker>
<rawString>Jenny Rose Finkel, Alex Kleeman, and Christopher D. Manning. 2008. Efficient, feature-based, conditional random field parsing. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Dependency grammar induction via bitext projection constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="29157" citStr="Ganchev et al., 2009" startWordPosition="4917" endWordPosition="4920">e extraction) and translation time without adding complexity to the extraction and decoding algorithms. Of course, integrating our model into translation inference represents a potentially fruitful avenue of future research. 4.3 Grammar Induction The language processing community actively works on the problem of automatically inducing grammatical structure from a corpus of text (Pereira and Schabes, 1992). Some success in this area has been demonstrated via generative models (Klein and Manning, 2002), which often benefit from wellchosen priors (Cohen and Smith, 2009) or posterior constraints (Ganchev et al., 2009). In principle, these models must discover the syntactic patterns that govern a language from the sequences of word tokens alone. These models are often evaluated relative to reference treebank annotations. Grammar induction in the context of machine translation reordering offers different properties. The alignment patterns in a parallel corpus provide an additional signal to models that is strongly tied to syntactic properties of the aligned languages. Also, the evaluation is straightforward—any syntactic structure that supports the prediction of reordering is rewarded. Kuhn (2004) applied al</context>
</contexts>
<marker>Ganchev, Gillenwater, Taskar, 2009</marker>
<rawString>Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar. 2009. Dependency grammar induction via bitext projection constraints. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitriy Genzel</author>
</authors>
<title>Automatically learning sourceside reordering rules for large scale machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="4059" citStr="Genzel (2010)" startWordPosition="596" endWordPosition="597">putational Linguistics perspective on the canonical NLP task of grammar induction—one which marries the wide-spread scientific interest in unsupervised parsing models with a clear application and extrinsic evaluation methodology. To support this perspective, we highlight several avenues of future research throughout the paper. We evaluate STIR in a large-scale EnglishJapanese machine translation system. We measure how closely our predicted reorderings match those implied by hand-annotated word alignments. STIR approaches the performance of the state-of-the-art pre-ordering method described in Genzel (2010), which learns reordering rules for supervised treebank parses. STIR gives a translation improvement of 3.84 BLEU over a standard phrase-based system with an integrated reordering model. 2 Parsing and Reordering Models STIR consists of two pipelined log-linear models for parsing and reordering, as well as a third model for inducing trees from parallel corpora, trees that serve to train the first two models. This section describes the domain and structure of each model, while Section 3 describes features and learning objectives. Figure 1 depicts the relationship between the three models. For ea</context>
<context position="26248" citStr="Genzel, 2010" startWordPosition="4482" endWordPosition="4483">everal areas of previous work, including other pre-ordering methods, reordering models more generally, and models for the unsupervised induction of syntactic structure. 4.1 Pre-Ordering Models Our reordering pipeline is intentionally similar to approaches that use a treebank-trained supervised � σ arg max (e,v∗)EB R tEB(e) 199 parser to reorder source sentences at training and translation time (Xia and McCord, 2004; Collins et al., 2005; Lee et al., 2010). Given a supervised parser, a rule-based pre-ordering procedure can either be specified by hand (Xu et al., 2009) or learned automatically (Genzel, 2010). We consider our approach to be a direct extension of these approaches, but one which induces structure from parallel corpora rather than relying on a treebank. Tromble (2009) show that some pre-ordering benefits can be realized without a parsing step at all, by instead casting pre-ordering as a permutation modeling problem. While not splitting the task of preordering into parsing and tree rordering, that work shows that pre-ordering models can be learned directly from parallel corpora. 4.2 Integrated Reordering Models Distortion models have been primary components in machine translation mode</context>
<context position="30859" citStr="Genzel, 2010" startWordPosition="5183" endWordPosition="5184"> of grammar induction models. Their work differs from ours in that it focuses on multilingual lexical statistics and dependency relationships, rather than reordering patterns. 200 Prec Parsing F1 Tree Reordering RO Pipeline Rec accN accT R Annotated word All features 82.0 87.8 84.8 97.3 93.6 87.7 80.5 alignments All but POS 81.3 87.7 84.4 97.0 92.6 86.6 79.4 All but Cluster 81.2 87.9 84.4 95.9 93.2 83.8 77.8 All but POS &amp; Cluster 75.4 82.0 78.5 89.2 89.7 66.8 49.7 Learned alignments All features 72.5 61.0 66.3 91.6 83.3 72.0 49.5 Monotone order 34.9 Inverted order 30.8 Syntactic pre-ordering (Genzel, 2010) 66.0 Table 1: Accuracy of individual monolingual parsing and reordering models, as well as complete pipelines trained on annotated and learned word alignments. 4.4 Bilingual Grammar Induction Also related to STIR is previous work on bilingual grammar induction from parallel corpora using ITG (Blunsom et al., 2009). These models have focused on learning phrasal translations — which are the terminal productions of a synchronous ITG — rather than reordering patterns that occur higher in the tree. Hence, while this paper shares formal machinery and data sources with that line of work, the models </context>
<context position="33654" citStr="Genzel (2010)" startWordPosition="5624" endWordPosition="5625"> independent of the monolingual parsing model. The fifth line, labeled learned alignments, shows the impact of replacing manual alignment annotations with learned Model 1 alignments, trained in both directions and combined with the refined heuristic (Brown et al., 1993; Och et al., 1999). The pipeline column shows the reordering score of the full STIR pipeline compared to two simple baselines: Monotone applies no reordering, while inverted simply inverts the word order. STIR outperforms all three other systems. In the final line, we compare to the syntax-based pre-ordering system described in Genzel (2010). This approach first parses source sentences with a supervised parser, then learns reordering rules that permute those trees. 5.2 Translation Quality We apply STIR as a pre-ordering step in a stateof-the-art phrase-based translation system from English to Japanese (Koehn et al., 2003). At training 201 time, pre-ordering is applied to the source side of every sentence pair in the training corpus before word alignment and phrase extraction. Likewise, every input sentence is pre-ordered at translation time. Our baseline is the same system, but without preordering. Our implementation’s integrated</context>
<context position="35835" citStr="Genzel (2010)" startWordPosition="5977" endWordPosition="5978"> and two iterations of the HMM alignment model (Vogel et al., 1996). Our dev and test data sets consist of 3100 and 1000 English sentences, respectively, that were randomly sampled from the web and translated into Japanese. The eval set is a larger, heterogenous set containing 12,784 sentences. In all cases, the final log-linear models were optimized on the dev set using lattice-based Minimum Error Rate Training (Macherey et al., 2008). Table 2 shows that STIR improves over the baseline system by a large margin of 3.84% BLEU (test). These gains are comparable in magnitude to those reported in Genzel (2010). Our induced parses are competitive with both systems that use syntactic parsers and substantially outperform lexicalized reordering. 6 Conclusion We have demonstrated that induced parses suffice for pre-ordering. We hope that future work in grammar induction will also consider pre-ordering as an dev BLEU % eval test Baseline 18.65 19.02 13.60 Lexicalized Reordering 19.45 18.92 13.99 Forest-to-String 23.08 22.85 16.60 Syntactic Pre-ordering 22.59 23.28 16.31 STIR: annotated 22.46 22.86 16.39 STIR: learned 20.28 20.66 14.64 Table 2: Translation quality, measured by BLEU, for English to Japanes</context>
</contexts>
<marker>Genzel, 2010</marker>
<rawString>Dmitriy Genzel. 2010. Automatically learning sourceside reordering rules for large scale machine translation. In Proceedings of the Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Natural language grammar induction using a constituentcontext model.</title>
<date>2001</date>
<booktitle>In Proceedings of Neural Information Processing Systems.</booktitle>
<marker>Klein, Manning, 2001</marker>
<rawString>Dan Klein and Christopher D. Manning. 2001. Natural language grammar induction using a constituentcontext model. In Proceedings of Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>A generative constituent-context model for improved grammar induction.</title>
<date>2002</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3105" citStr="Klein and Manning, 2002" startWordPosition="460" endWordPosition="464">pproach resembles work with binary synchronous grammars (Wu, 1997), but is distinct in its emphasis on monolingual parsing as a first phase, and in selecting reorderings without the aid of a target-side language model. The parsing model is trained to maximize the conditional likelihood of trees that license the reorderings implied by observed word alignments in a parallel corpus. This objective differs from those of previous grammar induction models, which typically focus on succinctly explaining the observed source language corpus via latent hierarchical structure (Pereira and Schabes, 1992; Klein and Manning, 2002). Our convex objective allows us to train a feature-rich log-linear parsing model, even without supervised treebank data. Focusing on pre-ordering for MT leads to a new Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 193–203, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics perspective on the canonical NLP task of grammar induction—one which marries the wide-spread scientific interest in unsupervised parsing models with a clear application and extrinsic evaluation methodology. To support this perspective, </context>
<context position="29041" citStr="Klein and Manning, 2002" startWordPosition="4898" endWordPosition="4901">program as the translation model. Third, the same reordering can be applied during training (for word alignment and rule extraction) and translation time without adding complexity to the extraction and decoding algorithms. Of course, integrating our model into translation inference represents a potentially fruitful avenue of future research. 4.3 Grammar Induction The language processing community actively works on the problem of automatically inducing grammatical structure from a corpus of text (Pereira and Schabes, 1992). Some success in this area has been demonstrated via generative models (Klein and Manning, 2002), which often benefit from wellchosen priors (Cohen and Smith, 2009) or posterior constraints (Ganchev et al., 2009). In principle, these models must discover the syntactic patterns that govern a language from the sequences of word tokens alone. These models are often evaluated relative to reference treebank annotations. Grammar induction in the context of machine translation reordering offers different properties. The alignment patterns in a parallel corpus provide an additional signal to models that is strongly tied to syntactic properties of the aligned languages. Also, the evaluation is st</context>
</contexts>
<marker>Klein, Manning, 2002</marker>
<rawString>Dan Klein and Christopher D. Manning. 2002. A generative constituent-context model for improved grammar induction. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
</authors>
<title>Shared task: Statistical machine translation between european languages.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation.</booktitle>
<contexts>
<context position="34678" citStr="Koehn and Monz, 2005" startWordPosition="5786" endWordPosition="5789">re word alignment and phrase extraction. Likewise, every input sentence is pre-ordered at translation time. Our baseline is the same system, but without preordering. Our implementation’s integrated distortion model is expressed as a negative exponential function of the distance between the current and previous source phrase, with a maximum jump width of four words. Our in-house decoder is based on the alignment template approach to translation and uses a small set of standard feature functions during decoding (Och and Ney, 2004). We compare to using an integrated lexicalized reordering model (Koehn and Monz, 2005), a forestto-string translation model (Zhang et al., 2011) and finally the syntactic pre-ordering technique of Genzel (2010) applied to the phrase-based baseline. We evaluate the impact of the proposed approach on translation quality as measured by the BLEU score on the token level (Papineni et al., 2002). The translation model is trained on 700 million tokens of parallel text, primarily extracted from the web using automated parallel document identification (Uszkoreit et al., 2010). Alignments were learned using two iterations of Model 1 and two iterations of the HMM alignment model (Vogel et</context>
</contexts>
<marker>Koehn, Monz, 2005</marker>
<rawString>Philipp Koehn and Christof Monz. 2005. Shared task: Statistical machine translation between european languages. In Proceedings of the International Workshop on Spoken Language Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="33940" citStr="Koehn et al., 2003" startWordPosition="5666" endWordPosition="5669">., 1999). The pipeline column shows the reordering score of the full STIR pipeline compared to two simple baselines: Monotone applies no reordering, while inverted simply inverts the word order. STIR outperforms all three other systems. In the final line, we compare to the syntax-based pre-ordering system described in Genzel (2010). This approach first parses source sentences with a supervised parser, then learns reordering rules that permute those trees. 5.2 Translation Quality We apply STIR as a pre-ordering step in a stateof-the-art phrase-based translation system from English to Japanese (Koehn et al., 2003). At training 201 time, pre-ordering is applied to the source side of every sentence pair in the training corpus before word alignment and phrase extraction. Likewise, every input sentence is pre-ordered at translation time. Our baseline is the same system, but without preordering. Our implementation’s integrated distortion model is expressed as a negative exponential function of the distance between the current and previous source phrase, with a maximum jump width of four words. Our in-house decoder is based on the alignment template approach to translation and uses a small set of standard fe</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonas Kuhn</author>
</authors>
<title>Experiments in parallel-text based grammar induction.</title>
<date>2004</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="29746" citStr="Kuhn (2004)" startWordPosition="5008" endWordPosition="5009">(Ganchev et al., 2009). In principle, these models must discover the syntactic patterns that govern a language from the sequences of word tokens alone. These models are often evaluated relative to reference treebank annotations. Grammar induction in the context of machine translation reordering offers different properties. The alignment patterns in a parallel corpus provide an additional signal to models that is strongly tied to syntactic properties of the aligned languages. Also, the evaluation is straightforward—any syntactic structure that supports the prediction of reordering is rewarded. Kuhn (2004) applied alignment-based constraints to the problem of inducing probabilistic context-free grammars, and showed an improvement with respect to Penn Treebank annotations over monolingual induction. Their work is distinct from ours because it focused on projecting distituents across languages, but mirrors ours in demonstrating that there is a role for aligned parallel corpora in grammar induction. Snyder et al. (2009) also demonstrated that parallel corpora can play a role in improving the quality of grammar induction models. Their work differs from ours in that it focuses on multilingual lexica</context>
</contexts>
<marker>Kuhn, 2004</marker>
<rawString>Jonas Kuhn. 2004. Experiments in parallel-text based grammar induction. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Machine Learning.</booktitle>
<contexts>
<context position="17027" citStr="Lafferty et al., 2001" startWordPosition="2916" endWordPosition="2919">positions in general. Length. Length computed as `−k, length as a fraction of sentence length, and quantized length features all contribute structural information. All features except POS are computed directly from aligned parallel corpora. The Cluster and POS features play a similar role of expressing reordering patterns over collections of similar words. The ablation study in Section 5 compares these two feature sets directly. 3.2 Monolingual Parsing Features The monolingual parsing model is also trained discriminatively, but involves structured prediction, as in a conditional random field (Lafferty et al., 2001). Conditional likelihood objectives have proven effective for supervised parsers (Finkel et al., 2008; Petrov and Klein, 2008). Recall that the score of a tree t = (T , N) factors over spans. s(t) = X wTφT (k, `) + X wNφN(k, m, `) [k,`)ET [k,`)EN exp [s(t)] P(t|e) = P(t&apos;)EB(e) exp [s(tl)] where B(e) is the set of well-formed trees over e. The parallel parsing model (Section 2.2) produces a tree over the source sentence of each aligned sentence pair; these trees serve as our training examples. We can maximize their conditional likelihood according to this model via gradient methods. Each tree t</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Abhaya Agarwal</author>
</authors>
<title>METEOR: An automatic metric for mt evaluation with high levels of correlation with human judgments.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="22399" citStr="Lavie and Agarwal, 2007" startWordPosition="3821" endWordPosition="3824">reorder the sentence, but instead how to bracket the sentence hierarchically so that it can be reordered. 198 1An astute reviewer pointed out that no binary tree over an S-V-O sentence can license both S-O-V and V-S-O orderings. Hence, parse trees that are induced for multilingual reordering will need n-ary branches. 3.3.1 Reordering Loss Function In order to measure the effectiveness of a reordering pipeline, we would like a metric over permutations. Fortunately, permutation loss for machine translation is already an established component of the METEOR metric, called a fragmentation penalty (Lavie and Agarwal, 2007). We define a slight variant of METEOR’s fragmentation penalty that ranges from 0 to 1. Given a sentence e, a reference permutation σ* of (0, · · · , |e |− 1), and a hypothesized permutation ˆσ, let chunks(ˆσ, σ*) be the minimum number of “chunks” in ˆσ: the number of elements in a partition of σˆ such that each contiguous subsequence is also contiguous in σ*. We can define the reordering score between two permutations in terms of chunks. R(ˆσ, σ*) = |σ* |−� ��1&amp;,a*) (1) i If σˆ = σ*, then chunks(ˆσ, σ*) = 1. If no two adjacent elements of σˆ are adjacent in σ*, then chunks(ˆσ, σ*) = |σ|. Henc</context>
</contexts>
<marker>Lavie, Agarwal, 2007</marker>
<rawString>Alon Lavie and Abhaya Agarwal. 2007. METEOR: An automatic metric for mt evaluation with high levels of correlation with human judgments. In Proceedings of ACL Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
<author>Bing Zhao</author>
<author>Xiaoqiang Luo</author>
</authors>
<title>Constituent reordering and syntax models for Englishto-Japanese statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="26094" citStr="Lee et al., 2010" startWordPosition="4456" endWordPosition="4459"> parameters, but we leave this research direction to future work. 4 Related Work Our approach to inducing hierarchical structure for pre-ordering relates to several areas of previous work, including other pre-ordering methods, reordering models more generally, and models for the unsupervised induction of syntactic structure. 4.1 Pre-Ordering Models Our reordering pipeline is intentionally similar to approaches that use a treebank-trained supervised � σ arg max (e,v∗)EB R tEB(e) 199 parser to reorder source sentences at training and translation time (Xia and McCord, 2004; Collins et al., 2005; Lee et al., 2010). Given a supervised parser, a rule-based pre-ordering procedure can either be specified by hand (Xu et al., 2009) or learned automatically (Genzel, 2010). We consider our approach to be a direct extension of these approaches, but one which induces structure from parallel corpora rather than relying on a treebank. Tromble (2009) show that some pre-ordering benefits can be realized without a parsing step at all, by instead casting pre-ordering as a permutation modeling problem. While not splitting the task of preordering into parsing and tree rordering, that work shows that pre-ordering models </context>
</contexts>
<marker>Lee, Zhao, Luo, 2010</marker>
<rawString>Young-Suk Lee, Bing Zhao, and Xiaoqiang Luo. 2010. Constituent reordering and syntax models for Englishto-Japanese statistical machine translation. In Proceedings of the Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Macherey</author>
<author>Franz Och</author>
<author>Ignacio Thayer</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Lattice-based minimum error rate training for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="35661" citStr="Macherey et al., 2008" startWordPosition="5944" endWordPosition="5947">s of parallel text, primarily extracted from the web using automated parallel document identification (Uszkoreit et al., 2010). Alignments were learned using two iterations of Model 1 and two iterations of the HMM alignment model (Vogel et al., 1996). Our dev and test data sets consist of 3100 and 1000 English sentences, respectively, that were randomly sampled from the web and translated into Japanese. The eval set is a larger, heterogenous set containing 12,784 sentences. In all cases, the final log-linear models were optimized on the dev set using lattice-based Minimum Error Rate Training (Macherey et al., 2008). Table 2 shows that STIR improves over the baseline system by a large margin of 3.84% BLEU (test). These gains are comparable in magnitude to those reported in Genzel (2010). Our induced parses are competitive with both systems that use syntactic parsers and substantially outperform lexicalized reordering. 6 Conclusion We have demonstrated that induced parses suffice for pre-ordering. We hope that future work in grammar induction will also consider pre-ordering as an dev BLEU % eval test Baseline 18.65 19.02 13.60 Lexicalized Reordering 19.45 18.92 13.99 Forest-to-String 23.08 22.85 16.60 Syn</context>
</contexts>
<marker>Macherey, Och, Thayer, Uszkoreit, 2008</marker>
<rawString>Wolfgang Macherey, Franz Och, Ignacio Thayer, and Jakob Uszkoreit. 2008. Lattice-based minimum error rate training for statistical machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation. Computational Linguistics.</title>
<date>2004</date>
<contexts>
<context position="34591" citStr="Och and Ney, 2004" startWordPosition="5772" endWordPosition="5775">ing is applied to the source side of every sentence pair in the training corpus before word alignment and phrase extraction. Likewise, every input sentence is pre-ordered at translation time. Our baseline is the same system, but without preordering. Our implementation’s integrated distortion model is expressed as a negative exponential function of the distance between the current and previous source phrase, with a maximum jump width of four words. Our in-house decoder is based on the alignment template approach to translation and uses a small set of standard feature functions during decoding (Och and Ney, 2004). We compare to using an integrated lexicalized reordering model (Koehn and Monz, 2005), a forestto-string translation model (Zhang et al., 2011) and finally the syntactic pre-ordering technique of Genzel (2010) applied to the phrase-based baseline. We evaluate the impact of the proposed approach on translation quality as measured by the BLEU score on the token level (Papineni et al., 2002). The translation model is trained on 700 million tokens of parallel text, primarily extracted from the web using automated parallel document identification (Uszkoreit et al., 2010). Alignments were learned </context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Josef Och and Hermann Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Christopher Tillman</author>
<author>Hermann Ney</author>
</authors>
<title>Improved alignment models for statistical machine translation.</title>
<date>1999</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="33329" citStr="Och et al., 1999" startWordPosition="5572" endWordPosition="5575">annotations are necessary at all to train the model. We report two accuracy measures for the tree reordering model, one for non-terminal spans (accN) and one for terminal spans (accT). The following column, labeled RO, is the reordering score of the tree reordering model applied to the oracle parallel parser tree. This score is independent of the monolingual parsing model. The fifth line, labeled learned alignments, shows the impact of replacing manual alignment annotations with learned Model 1 alignments, trained in both directions and combined with the refined heuristic (Brown et al., 1993; Och et al., 1999). The pipeline column shows the reordering score of the full STIR pipeline compared to two simple baselines: Monotone applies no reordering, while inverted simply inverts the word order. STIR outperforms all three other systems. In the final line, we compare to the syntax-based pre-ordering system described in Genzel (2010). This approach first parses source sentences with a supervised parser, then learns reordering rules that permute those trees. 5.2 Translation Quality We apply STIR as a pre-ordering step in a stateof-the-art phrase-based translation system from English to Japanese (Koehn et</context>
</contexts>
<marker>Och, Tillman, Ney, 1999</marker>
<rawString>Franz Josef Och, Christopher Tillman, and Hermann Ney. 1999. Improved alignment models for statistical machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="34984" citStr="Papineni et al., 2002" startWordPosition="5835" endWordPosition="5838">evious source phrase, with a maximum jump width of four words. Our in-house decoder is based on the alignment template approach to translation and uses a small set of standard feature functions during decoding (Och and Ney, 2004). We compare to using an integrated lexicalized reordering model (Koehn and Monz, 2005), a forestto-string translation model (Zhang et al., 2011) and finally the syntactic pre-ordering technique of Genzel (2010) applied to the phrase-based baseline. We evaluate the impact of the proposed approach on translation quality as measured by the BLEU score on the token level (Papineni et al., 2002). The translation model is trained on 700 million tokens of parallel text, primarily extracted from the web using automated parallel document identification (Uszkoreit et al., 2010). Alignments were learned using two iterations of Model 1 and two iterations of the HMM alignment model (Vogel et al., 1996). Our dev and test data sets consist of 3100 and 1000 English sentences, respectively, that were randomly sampled from the web and translated into Japanese. The eval set is a larger, heterogenous set containing 12,784 sentences. In all cases, the final log-linear models were optimized on the de</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Yves Schabes</author>
</authors>
<title>Insideoutside reestimation from partially bracketed corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3079" citStr="Pereira and Schabes, 1992" startWordPosition="456" endWordPosition="459">y permutes this tree. Our approach resembles work with binary synchronous grammars (Wu, 1997), but is distinct in its emphasis on monolingual parsing as a first phase, and in selecting reorderings without the aid of a target-side language model. The parsing model is trained to maximize the conditional likelihood of trees that license the reorderings implied by observed word alignments in a parallel corpus. This objective differs from those of previous grammar induction models, which typically focus on succinctly explaining the observed source language corpus via latent hierarchical structure (Pereira and Schabes, 1992; Klein and Manning, 2002). Our convex objective allows us to train a feature-rich log-linear parsing model, even without supervised treebank data. Focusing on pre-ordering for MT leads to a new Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 193–203, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics perspective on the canonical NLP task of grammar induction—one which marries the wide-spread scientific interest in unsupervised parsing models with a clear application and extrinsic evaluation methodology. To </context>
<context position="28944" citStr="Pereira and Schabes, 1992" startWordPosition="4883" endWordPosition="4886"> and evaluated directly. Second, pre-ordering models need not factor according to the same dynamic program as the translation model. Third, the same reordering can be applied during training (for word alignment and rule extraction) and translation time without adding complexity to the extraction and decoding algorithms. Of course, integrating our model into translation inference represents a potentially fruitful avenue of future research. 4.3 Grammar Induction The language processing community actively works on the problem of automatically inducing grammatical structure from a corpus of text (Pereira and Schabes, 1992). Some success in this area has been demonstrated via generative models (Klein and Manning, 2002), which often benefit from wellchosen priors (Cohen and Smith, 2009) or posterior constraints (Ganchev et al., 2009). In principle, these models must discover the syntactic patterns that govern a language from the sequences of word tokens alone. These models are often evaluated relative to reference treebank annotations. Grammar induction in the context of machine translation reordering offers different properties. The alignment patterns in a parallel corpus provide an additional signal to models t</context>
</contexts>
<marker>Pereira, Schabes, 1992</marker>
<rawString>Fernando Pereira and Yves Schabes. 1992. Insideoutside reestimation from partially bracketed corpora. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Sparse multi-scale grammars for discriminative latent variable parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="17153" citStr="Petrov and Klein, 2008" startWordPosition="2934" endWordPosition="2937">all contribute structural information. All features except POS are computed directly from aligned parallel corpora. The Cluster and POS features play a similar role of expressing reordering patterns over collections of similar words. The ablation study in Section 5 compares these two feature sets directly. 3.2 Monolingual Parsing Features The monolingual parsing model is also trained discriminatively, but involves structured prediction, as in a conditional random field (Lafferty et al., 2001). Conditional likelihood objectives have proven effective for supervised parsers (Finkel et al., 2008; Petrov and Klein, 2008). Recall that the score of a tree t = (T , N) factors over spans. s(t) = X wTφT (k, `) + X wNφN(k, m, `) [k,`)ET [k,`)EN exp [s(t)] P(t|e) = P(t&apos;)EB(e) exp [s(tl)] where B(e) is the set of well-formed trees over e. The parallel parsing model (Section 2.2) produces a tree over the source sentence of each aligned sentence pair; these trees serve as our training examples. We can maximize their conditional likelihood according to this model via gradient methods. Each tree t over sentence e has a cumulative feature vector of dimension |w |= |wT |+|wN|, formed by stacking the terminal and non-termin</context>
</contexts>
<marker>Petrov, Klein, 2008</marker>
<rawString>Slav Petrov and Dan Klein. 2008. Sparse multi-scale grammars for discriminative latent variable parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2011</date>
<tech>Technical report.</tech>
<contexts>
<context position="16111" citStr="Petrov et al., 2011" startWordPosition="2772" endWordPosition="2775">her maximize likelihood of the source side of a large parallel corpus under a hidden Markov model, as in Uszkoreit and Brants (2008). Indicator features based on clusterings over c classes are defined over words ek, em−1, em and e`−1, as well as word sequences for spans up to length 4. Features are included for a variety of clusterings with sizes { s 4 c E 2 ,2 ,...,211} POS. A supervised part-of-speech (POS) tagger provides coarse tags drawn from a 12 tag set T = {Verb, Noun, Pronoun, Conjunction, Adjective, Adverb, Adposition, Determiner, Number, Particle/Function word, Punctuation, Other} (Petrov et al., 2011). Features based on these tags are computed identically to the features based on word classes. Lexical. For a list of very common words in the source language, we include lexical indicator features for the boundary words ek and e`−1. For instance, the word “to” triggers a reordering, as do prepositions in general. Length. Length computed as `−k, length as a fraction of sentence length, and quantized length features all contribute structural information. All features except POS are computed directly from aligned parallel corpora. The Cluster and POS features play a similar role of expressing re</context>
</contexts>
<marker>Petrov, Das, McDonald, 2011</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011. A universal part-of-speech tagset. Technical report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Tahira Naseem</author>
<author>Regina Barzilay</author>
</authors>
<title>Unsupervised multilingual grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="30165" citStr="Snyder et al. (2009)" startWordPosition="5066" endWordPosition="5069">at is strongly tied to syntactic properties of the aligned languages. Also, the evaluation is straightforward—any syntactic structure that supports the prediction of reordering is rewarded. Kuhn (2004) applied alignment-based constraints to the problem of inducing probabilistic context-free grammars, and showed an improvement with respect to Penn Treebank annotations over monolingual induction. Their work is distinct from ours because it focused on projecting distituents across languages, but mirrors ours in demonstrating that there is a role for aligned parallel corpora in grammar induction. Snyder et al. (2009) also demonstrated that parallel corpora can play a role in improving the quality of grammar induction models. Their work differs from ours in that it focuses on multilingual lexical statistics and dependency relationships, rather than reordering patterns. 200 Prec Parsing F1 Tree Reordering RO Pipeline Rec accN accT R Annotated word All features 82.0 87.8 84.8 97.3 93.6 87.7 80.5 alignments All but POS 81.3 87.7 84.4 97.0 92.6 86.6 79.4 All but Cluster 81.2 87.9 84.4 95.9 93.2 83.8 77.8 All but POS &amp; Cluster 75.4 82.0 78.5 89.2 89.7 66.8 49.7 Learned alignments All features 72.5 61.0 66.3 91.</context>
</contexts>
<marker>Snyder, Naseem, Barzilay, 2009</marker>
<rawString>Benjamin Snyder, Tahira Naseem, and Regina Barzilay. 2009. Unsupervised multilingual grammar induction. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Talbot</author>
<author>Hideto Kazawa</author>
<author>Hiroshi Ichikawa</author>
<author>Jason Katz-Brown</author>
<author>Masakazu Seno</author>
<author>Franz J Och</author>
</authors>
<title>A lightweight evaluation framework for machine translation reordering.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="23575" citStr="Talbot et al., 2011" startWordPosition="4038" endWordPosition="4041">acent in σ*, then chunks(ˆσ, σ*) = |σ|. Hence, the metric defined by Equation 1 ranges from 0 to 1. The reference permutation σ* of a source sentence e can be defined from an aligned sentence pair (e, f, A) by sorting the words ez of e by the left bound of their projection ψ(i). Null-aligned words are placed to the left of the next aligned word to their right in the original order. The reordering-specific loss functions defined in Equation 1 has been shown to correlate with human judgements of translation quality, especially for language pairs with substantial reordering like EnglishJapanese (Talbot et al., 2011). Other reorderingspecific loss functions also correlate with human judgements (Birch et al., 2010). Future research could experiment with alternative reordering-based loss functions, such as Kendall’s Tau, as suggested by Birch and Osborne (2011). 3.3.2 Parallel Parsing Objective We can train our reordering pipeline by dividing an aligned parallel corpus into two halves, A and B, where the monolingual parsing and tree reordering models are trained on A, and their effectiveness is evaluated on held-out set B. Then, the effectiveness of the parallel parsing model is best measured on B, given fu</context>
<context position="31830" citStr="Talbot et al. (2011)" startWordPosition="5333" endWordPosition="5336">ning phrasal translations — which are the terminal productions of a synchronous ITG — rather than reordering patterns that occur higher in the tree. Hence, while this paper shares formal machinery and data sources with that line of work, the models themselves target orthogonal aspects of the translation problem. 5 Experimental Results As training data for our models we used 14,000 English sentences that were sampled from the web, translated into Japanese, and manually annotated with word alignments. The annotation was carried out by the original translators to promote consistency of analysis. Talbot et al. (2011) describes this corpus in further detail. A held-out test set of 396 manually aligned sentence pairs was used to evaluate reordering accuracy. Statistics used for features were computed from the full, unreordered, automatically word aligned, parallel training corpus used for the translation experiments described below. 5.1 Individual Model Accuracy We evaluate the accuracy of the monolingual parsing models by their span F1, relative to the trees induced by the parallel parsing model on the held-out set. The first row of Table 1 shows that the model was able to reliably replicate the parses ind</context>
</contexts>
<marker>Talbot, Kazawa, Ichikawa, Katz-Brown, Seno, Och, 2011</marker>
<rawString>David Talbot, Hideto Kazawa, Hiroshi Ichikawa, Jason Katz-Brown, Masakazu Seno, and Franz J. Och. 2011. A lightweight evaluation framework for machine translation reordering. In Proceedings of the Sixth Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Tromble</author>
</authors>
<title>Learning linear ordering problems for better translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="26424" citStr="Tromble (2009)" startWordPosition="4512" endWordPosition="4513">e-Ordering Models Our reordering pipeline is intentionally similar to approaches that use a treebank-trained supervised � σ arg max (e,v∗)EB R tEB(e) 199 parser to reorder source sentences at training and translation time (Xia and McCord, 2004; Collins et al., 2005; Lee et al., 2010). Given a supervised parser, a rule-based pre-ordering procedure can either be specified by hand (Xu et al., 2009) or learned automatically (Genzel, 2010). We consider our approach to be a direct extension of these approaches, but one which induces structure from parallel corpora rather than relying on a treebank. Tromble (2009) show that some pre-ordering benefits can be realized without a parsing step at all, by instead casting pre-ordering as a permutation modeling problem. While not splitting the task of preordering into parsing and tree rordering, that work shows that pre-ordering models can be learned directly from parallel corpora. 4.2 Integrated Reordering Models Distortion models have been primary components in machine translation models since the advent of statistical MT (Brown et al., 1993). In modern systems, reordering models are integrated into decoders as additional features in a discriminative logline</context>
</contexts>
<marker>Tromble, 2009</marker>
<rawString>Roy Tromble. 2009. Learning linear ordering problems for better translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakob Uszkoreit</author>
<author>Thorsten Brants</author>
</authors>
<title>Distributed word clustering for large scale class-based language modeling in machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="15623" citStr="Uszkoreit and Brants (2008)" startWordPosition="2691" endWordPosition="2695">hould stay contiguous after reordering. Features based on this statistic apply to both terminal and short non-terminal spans. The second statistic indicates when a possibly discontiguous pair of words should be adjacent after reordering. This statistic is applied to pairs of words that would end up adjacent after an inversion: ek and e`−1 for span [k, `). For instance, PC(added to) = 0.68 and PD(lexicon, to) = 0.19. Cluster. All source word types are clustered into word classes, which together maximize likelihood of the source side of a large parallel corpus under a hidden Markov model, as in Uszkoreit and Brants (2008). Indicator features based on clusterings over c classes are defined over words ek, em−1, em and e`−1, as well as word sequences for spans up to length 4. Features are included for a variety of clusterings with sizes { s 4 c E 2 ,2 ,...,211} POS. A supervised part-of-speech (POS) tagger provides coarse tags drawn from a 12 tag set T = {Verb, Noun, Pronoun, Conjunction, Adjective, Adverb, Adposition, Determiner, Number, Particle/Function word, Punctuation, Other} (Petrov et al., 2011). Features based on these tags are computed identically to the features based on word classes. Lexical. For a li</context>
</contexts>
<marker>Uszkoreit, Brants, 2008</marker>
<rawString>Jakob Uszkoreit and Thorsten Brants. 2008. Distributed word clustering for large scale class-based language modeling in machine translation. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakob Uszkoreit</author>
<author>Jay Ponte</author>
<author>Ashok Popat</author>
<author>Moshe Dubiner</author>
</authors>
<title>Large scale parallel document mining for machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="35165" citStr="Uszkoreit et al., 2010" startWordPosition="5862" endWordPosition="5865">ure functions during decoding (Och and Ney, 2004). We compare to using an integrated lexicalized reordering model (Koehn and Monz, 2005), a forestto-string translation model (Zhang et al., 2011) and finally the syntactic pre-ordering technique of Genzel (2010) applied to the phrase-based baseline. We evaluate the impact of the proposed approach on translation quality as measured by the BLEU score on the token level (Papineni et al., 2002). The translation model is trained on 700 million tokens of parallel text, primarily extracted from the web using automated parallel document identification (Uszkoreit et al., 2010). Alignments were learned using two iterations of Model 1 and two iterations of the HMM alignment model (Vogel et al., 1996). Our dev and test data sets consist of 3100 and 1000 English sentences, respectively, that were randomly sampled from the web and translated into Japanese. The eval set is a larger, heterogenous set containing 12,784 sentences. In all cases, the final log-linear models were optimized on the dev set using lattice-based Minimum Error Rate Training (Macherey et al., 2008). Table 2 shows that STIR improves over the baseline system by a large margin of 3.84% BLEU (test). Thes</context>
</contexts>
<marker>Uszkoreit, Ponte, Popat, Dubiner, 2010</marker>
<rawString>Jakob Uszkoreit, Jay Ponte, Ashok Popat, and Moshe Dubiner. 2010. Large scale parallel document mining for machine translation. In Proceedings of the Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the Conference on Computational linguistics.</booktitle>
<contexts>
<context position="35289" citStr="Vogel et al., 1996" startWordPosition="5884" endWordPosition="5887">z, 2005), a forestto-string translation model (Zhang et al., 2011) and finally the syntactic pre-ordering technique of Genzel (2010) applied to the phrase-based baseline. We evaluate the impact of the proposed approach on translation quality as measured by the BLEU score on the token level (Papineni et al., 2002). The translation model is trained on 700 million tokens of parallel text, primarily extracted from the web using automated parallel document identification (Uszkoreit et al., 2010). Alignments were learned using two iterations of Model 1 and two iterations of the HMM alignment model (Vogel et al., 1996). Our dev and test data sets consist of 3100 and 1000 English sentences, respectively, that were randomly sampled from the web and translated into Japanese. The eval set is a larger, heterogenous set containing 12,784 sentences. In all cases, the final log-linear models were optimized on the dev set using lattice-based Minimum Error Rate Training (Macherey et al., 2008). Table 2 shows that STIR improves over the baseline system by a large margin of 3.84% BLEU (test). These gains are comparable in magnitude to those reported in Genzel (2010). Our induced parses are competitive with both systems</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. HMM-based word alignment in statistical translation. In Proceedings of the Conference on Computational linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics.</journal>
<contexts>
<context position="2547" citStr="Wu, 1997" startWordPosition="376" endWordPosition="377">r Reordering (STIR), requires no syntactic annotations to train, but approaches the performance of a recent syntactic pre-ordering method in a large-scale English-Japanese MT system. STIR predicts a pre-ordering via two pipelined models: (1) parsing and (2) tree reordering. The first model induces a binary parse, which defines the space of possible reorderings. In particular, only trees that properly separate verbs from their object noun phrases will license an SVO to SOV transformation. The second model locally permutes this tree. Our approach resembles work with binary synchronous grammars (Wu, 1997), but is distinct in its emphasis on monolingual parsing as a first phase, and in selecting reorderings without the aid of a target-side language model. The parsing model is trained to maximize the conditional likelihood of trees that license the reorderings implied by observed word alignments in a parallel corpus. This objective differs from those of previous grammar induction models, which typically focus on succinctly explaining the observed source language corpus via latent hierarchical structure (Pereira and Schabes, 1992; Klein and Manning, 2002). Our convex objective allows us to train </context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Michael McCord</author>
</authors>
<title>Improving a statistical mt system with automatically learned rewrite patterns.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="26053" citStr="Xia and McCord, 2004" startWordPosition="4448" endWordPosition="4451"> could imagine training models with far more parameters, but we leave this research direction to future work. 4 Related Work Our approach to inducing hierarchical structure for pre-ordering relates to several areas of previous work, including other pre-ordering methods, reordering models more generally, and models for the unsupervised induction of syntactic structure. 4.1 Pre-Ordering Models Our reordering pipeline is intentionally similar to approaches that use a treebank-trained supervised � σ arg max (e,v∗)EB R tEB(e) 199 parser to reorder source sentences at training and translation time (Xia and McCord, 2004; Collins et al., 2005; Lee et al., 2010). Given a supervised parser, a rule-based pre-ordering procedure can either be specified by hand (Xu et al., 2009) or learned automatically (Genzel, 2010). We consider our approach to be a direct extension of these approaches, but one which induces structure from parallel corpora rather than relying on a treebank. Tromble (2009) show that some pre-ordering benefits can be realized without a parsing step at all, by instead casting pre-ordering as a permutation modeling problem. While not splitting the task of preordering into parsing and tree rordering, </context>
</contexts>
<marker>Xia, McCord, 2004</marker>
<rawString>Fei Xia and Michael McCord. 2004. Improving a statistical mt system with automatically learned rewrite patterns. In Proceedings of the Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Xu</author>
<author>Jaeho Kang</author>
<author>Michael Ringgard</author>
<author>Franz Och</author>
</authors>
<title>Using a dependency parser to improve smt for subject-object-verb languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1393" citStr="Xu et al., 2009" startWordPosition="201" endWordPosition="204">ng, but also approaches the performance of a recent preordering method based on a supervised parser. These results show that the syntactic structure which is relevant to MT pre-ordering can be learned automatically from parallel text, thus establishing a new application for unsupervised grammar induction. 1 Introduction Recent work in statistical machine translation (MT) has demonstrated the effectiveness of syntactic preordering: an approach that permutes source sentences into a target-like order as a pre-processing step, using features of a source-side syntactic parse (Collins et al., 2005; Xu et al., 2009). Syntactic pre-ordering is particularly effective at applying structural transformations, such as the ordering change from a subject-verb-object (SVO) language like English to a subject-object-verb (SOV) language like Japanese. However, state-of-the-art 193 pre-ordering methods require a supervised syntactic parser to provide structural information about each sentence. We propose a method that learns both a parsing model and a reordering model directly from a word-aligned parallel corpus. Our approach, which we call Structure Induction for Reordering (STIR), requires no syntactic annotations </context>
<context position="26208" citStr="Xu et al., 2009" startWordPosition="4475" endWordPosition="4478">cal structure for pre-ordering relates to several areas of previous work, including other pre-ordering methods, reordering models more generally, and models for the unsupervised induction of syntactic structure. 4.1 Pre-Ordering Models Our reordering pipeline is intentionally similar to approaches that use a treebank-trained supervised � σ arg max (e,v∗)EB R tEB(e) 199 parser to reorder source sentences at training and translation time (Xia and McCord, 2004; Collins et al., 2005; Lee et al., 2010). Given a supervised parser, a rule-based pre-ordering procedure can either be specified by hand (Xu et al., 2009) or learned automatically (Genzel, 2010). We consider our approach to be a direct extension of these approaches, but one which induces structure from parallel corpora rather than relying on a treebank. Tromble (2009) show that some pre-ordering benefits can be realized without a parsing step at all, by instead casting pre-ordering as a permutation modeling problem. While not splitting the task of preordering into parsing and tree rordering, that work shows that pre-ordering models can be learned directly from parallel corpora. 4.2 Integrated Reordering Models Distortion models have been primar</context>
</contexts>
<marker>Xu, Kang, Ringgard, Och, 2009</marker>
<rawString>Peng Xu, Jaeho Kang, Michael Ringgard, and Franz Och. 2009. Using a dependency parser to improve smt for subject-object-verb languages. In Proceedings of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="27605" citStr="Yamada and Knight (2001)" startWordPosition="4686" endWordPosition="4689">tional features in a discriminative loglinear model, which also includes a language model, translation features, etc. In these cases, reordering models interact with the strong signal of a targetside language model. Because ordering prediciton is conflated with target-side generation, evaluations are conducted on the entire generated output, which cannot isolate reordering errors from other sorts of errors, like lexical selection. Despite these differences, certain integrated reordering models are similar in character to syntactic pre-ordering models. In particular, the tree rotation model of Yamada and Knight (2001) posited that reordering decisions involve rotations of a source-side syntax tree. The parameters of such a model can be trained by treating tree rotations as latent variables in a factored translation model, which parameterizes reordering and transfer separately but performs joint inference (Dyer and Resnik, 2010). Syntactic reordering and transfer can also be modeled jointly, for instance in a tree-to-string translation system parameterized by a transducer grammar. While the success of integrated reordering models certainly highlights the importance of reordering in machine translation syste</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A syntax-based statistical translation model. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Licheng Fang</author>
<author>Peng Xu</author>
<author>Xiaoyun Wu</author>
</authors>
<title>Binarized forest to string translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="34736" citStr="Zhang et al., 2011" startWordPosition="5795" endWordPosition="5798">ut sentence is pre-ordered at translation time. Our baseline is the same system, but without preordering. Our implementation’s integrated distortion model is expressed as a negative exponential function of the distance between the current and previous source phrase, with a maximum jump width of four words. Our in-house decoder is based on the alignment template approach to translation and uses a small set of standard feature functions during decoding (Och and Ney, 2004). We compare to using an integrated lexicalized reordering model (Koehn and Monz, 2005), a forestto-string translation model (Zhang et al., 2011) and finally the syntactic pre-ordering technique of Genzel (2010) applied to the phrase-based baseline. We evaluate the impact of the proposed approach on translation quality as measured by the BLEU score on the token level (Papineni et al., 2002). The translation model is trained on 700 million tokens of parallel text, primarily extracted from the web using automated parallel document identification (Uszkoreit et al., 2010). Alignments were learned using two iterations of Model 1 and two iterations of the HMM alignment model (Vogel et al., 1996). Our dev and test data sets consist of 3100 an</context>
</contexts>
<marker>Zhang, Fang, Xu, Wu, 2011</marker>
<rawString>Hao Zhang, Licheng Fang, Peng Xu, and Xiaoyun Wu. 2011. Binarized forest to string translation. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>