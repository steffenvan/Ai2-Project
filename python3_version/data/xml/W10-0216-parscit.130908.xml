<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000146">
<title confidence="0.981324">
Sentiment Classification using Automatically Extracted Subgraph Features
</title>
<author confidence="0.998231">
Shilpa Arora, Elijah Mayfield, Carolyn Penstein-Ros´e and Eric Nyberg
</author>
<affiliation confidence="0.874133333333333">
Language Technologies Institute
Carnegie Mellon University
5000 Forbes Avenue, Pittsburgh, PA 15213
</affiliation>
<email confidence="0.990763">
{shilpaa, emayfiel, cprose, ehn}@cs.cmu.edu
</email>
<sectionHeader confidence="0.998555" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999691066666667">
In this work, we propose a novel representa-
tion of text based on patterns derived from lin-
guistic annotation graphs. We use a subgraph
mining algorithm to automatically derive fea-
tures as frequent subgraphs from the annota-
tion graph. This process generates a very large
number of features, many of which are highly
correlated. We propose a genetic program-
ming based approach to feature construction
which creates a fixed number of strong classi-
fication predictors from these subgraphs. We
evaluate the benefit gained from evolved struc-
tured features, when used in addition to the
bag-of-words features, for a sentiment classi-
fication task.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9922968">
In recent years, the topic of sentiment analysis has
been one of the more popular directions in the field
of language technologies. Recent work in super-
vised sentiment analysis has focused on innovative
approaches to feature creation, with the greatest im-
provements in performance with features that in-
sightfully capture the essence of the linguistic con-
structions used to express sentiment, e.g. (Wilson et
al., 2004), (Joshi and Ros´e, 2009)
In this spirit, we present a novel approach that
leverages subgraphs automatically extracted from
linguistic annotation graphs using efficient subgraph
mining algorithms (Yan and Han, 2002). The diffi-
culty with automatically deriving complex features
comes with the increased feature space size. Many
of these features are highly correlated and do not
131
provide any new information to the model. For ex-
ample, a feature of type unigram POS (e.g. “cam-
era NN”) doesn’t provide any additional informa-
tion beyond the unigram feature (e.g. “camera”),
for words that are often used with the same part of
speech. However, alongside several redundant fea-
tures, there are also features that provide new infor-
mation. It is these features that we aim to capture.
In this work, we propose an evolutionary ap-
proach that constructs complex features from sub-
graphs extracted from an annotation graph. A con-
stant number of these features are added to the un-
igram feature space, adding much of the represen-
tational benefits without the computational cost of a
drastic increase in feature space size.
In the remainder of the paper, we review prior
work on features commonly used for sentiment anal-
ysis. We then describe the annotation graph rep-
resentation proposed by Arora and Nyberg (2009).
Following this, we describe the frequent subgraph
mining algorithm proposed in Yan and Han (2002),
and used in this work to extract frequent subgraphs
from the annotation graphs. We then introduce our
novel feature evolution approach, and discuss our
experimental setup and results. Subgraph features
combined with the feature evolution approach gives
promising results, with an improvement in perfor-
mance over the baseline.
</bodyText>
<sectionHeader confidence="0.999953" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99976075">
Some of the recent work in sentiment analysis has
shown that structured features (features that capture
syntactic patterns in text), such as n-grams, depen-
dency relations, etc., improve performance beyond
</bodyText>
<note confidence="0.9847055">
Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 131–139,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.987332372881356">
the bag of words approach. Arora et al. (2009) show
that deep syntactic scope features constructed from
transitive closure of dependency relations give sig-
nificant improvement for identifying types of claims
in product reviews. Gamon (2004) found that using
deep linguistic features derived from phrase struc-
ture trees and part of speech annotations yields sig-
nificant improvements on the task of predicting sat-
isfaction ratings in customer feedback data. Wilson
et al. (2004) use syntactic clues derived from depen-
dency parse tree as features for predicting the inten-
sity of opinion phrases1.
Structured features that capture linguistic patterns
are often hand crafted by domain experts (Wilson
et al., 2005) after careful examination of the data.
Thus, they do not always generalize well across
datasets and domains. This also requires a signif-
icant amount of time and resources. By automati-
cally deriving structured features, we might be able
to learn new annotations faster.
Matsumoto et al. (2005) propose an approach that
uses frequent sub-sequence and sub-tree mining ap-
proaches (Asai et al., 2002; Pei et al., 2004) to derive
structured features such as word sub-sequences and
dependency sub-trees. They show that these features
outperform bag-of-words features for a sentiment
classification task and achieve the best performance
to date on a commonly-used movie review dataset.
Their approach presents an automatic procedure for
deriving features that capture long distance depen-
dencies without much expert intervention.
However, their approach is limited to sequences
or tree annotations. Often, features that combine
several annotations capture interesting characteris-
tics of text. For example, Wilson et al. (2004), Ga-
mon (2004) and Joshi and Ros´e (2009) show that
a combination of dependency relations and part of
speech annotations boosts performance. The anno-
tation graph representation proposed by Arora and
Nyberg (2009) is a formalism for representing sev-
eral linguistic annotations together on text. With an
annotation graph representation, instances are rep-
resented as graphs from which frequent subgraph
patterns may be extracted and used as features for
learning new annotations.
1Although, in this work we are classifying sentences and not
phrases, similar clues may be used for sentiment classification
in sentences as well
In this work, we use an efficient frequent sub-
graph mining algorithm (gSpan) (Yan and Han,
2002) to extract frequent subgraphs from a linguis-
tic annotation graph (Arora and Nyberg, 2009). An
annotation graph is a general representation for ar-
bitrary linguistic annotations. The annotation graph
and subgraph mining algorithm provide us a quick
way to test several alternative linguistic representa-
tions of text. In the next section, we present a formal
definition of the annotation graph and a motivating
example for subgraph features.
</bodyText>
<sectionHeader confidence="0.6845265" genericHeader="method">
3 Annotation Graph Representation and
Feature Subgraphs
</sectionHeader>
<bodyText confidence="0.994415333333333">
Arora and Nyberg (2009) define the annotation
graph as a quadruple: G = (N, E, E, A), where
N is the set of nodes, E is the set of edges, s.t.
E C N x N, and E = EN U EE is the set of la-
bels for nodes and edges. A : N U E → E is the
labeling function for nodes and edges. Examples of
node labels (EN) are tokens (unigrams) and annota-
tions such as part of speech, polarity etc. Examples
of edge labels (EE) are leftOf, dependency type etc.
The leftOf relation is defined between two adjacent
nodes. The dependency type relation is defined be-
tween a head word and its modifier.
Annotations may be represented in an annotation
graph in several ways. For example, a dependency
triple annotation ‘good amod movie’, may be repre-
sented as a d amod relation between the head word
‘movie’ and its modifier ‘good’, or as a node d amod
with edges ParentOfGov and ParentOfDep to the
head and the modifier words. An example of an an-
notation graph is shown in Figure 1.
The instance in Figure 1 describes a movie review
comment, ‘interesting, but not compelling.’. The
words ‘interesting’ and ‘compelling’ both have pos-
itive prior polarity, however, the phrase expresses
negative sentiment towards the movie. Heuristics for
special handling of negation have been proposed in
the literature. For example, Pang et al. (2002) ap-
pend every word following a negation, until a punc-
tuation, with a ‘NOT’ . Applying a similar technique
to our example gives us two sentiment bearing fea-
tures, one positive (‘interesting’) and one negative
(‘NOT-compelling’), and the model may not be as
sure about the predicted label, since there is both
</bodyText>
<page confidence="0.99678">
132
</page>
<bodyText confidence="0.9993474375">
positive and negative sentiment present.
In Figure 2, we show three discriminating sub-
graph features derived from the annotation graph in
Figure 1. These subgraph features capture the nega-
tive sentiment in our example phrase. The first fea-
ture in 2(a) captures the pattern using dependency
relations between words. A different review com-
ment may use the same linguistic construction but
with a different pair of words, for example “a pretty
good, but not excellent story.” This is the same lin-
guistic pattern but with different words the model
may not have seen before, and hence may not clas-
sify this instance correctly. This suggests that the
feature in 2(a) may be too specific.
In order to mine general features that capture the
rhetorical structure of language, we may add prior
polarity annotations to the annotation graph, us-
ing a lexicon such as Wilson et al. (2005). Fig-
ure 2(b) shows the subgraph in 2(a) with polar-
ity annotations. If we want to generalize the pat-
tern in 2(a) to any positive words, we may use the
feature subgraph in Figure 2(c) with X wild cards
on words that are polar or negating. This feature
subgraph captures the negative sentiment in both
phrases ‘interesting, but not compelling.’ and “a
pretty good, but not excellent story.”. Similar gener-
alization using wild cards on words may be applied
with other annotations such as part of speech anno-
tations as well. By choosing where to put the wild
card, we can get features similar to, but more pow-
erful than, the dependency back-off features in Joshi
and Ros´e (2009).
</bodyText>
<figureCaption confidence="0.9168595">
Figure 1: Annotation graph for sentence ‘interesting, but not
compelling.’ . Prefixes: ‘U’ for unigrams (tokens), ‘L’ for po-
larity, ‘D’ for dependency relation and ‘P’ for part of speech.
Edges with no label encode the ‘leftOf’ relation between words.
</figureCaption>
<sectionHeader confidence="0.986613" genericHeader="method">
4 Subgraph Mining Algorithms
</sectionHeader>
<bodyText confidence="0.998684">
In the previous section, we demonstrated that sub-
graphs from an annotation graph can be used to iden-
</bodyText>
<figure confidence="0.8195805">
D_conj-but
L_POSITIVE D_conj-but L_POSITIVE
</figure>
<figureCaption confidence="0.9999845">
Figure 2: Subgraph features from the annotation graph in
Figure 1
</figureCaption>
<bodyText confidence="0.999269761904762">
tify the rhetorical structure used to express senti-
ment. The subgraph patterns that represent general
linguistic structure will be more frequent than sur-
face level patterns. Hence, we use a frequent sub-
graph mining algorithm to find frequent subgraph
patterns, from which we construct features to use in
the supervised learning algorithm.
The goal in frequent subgraph mining is to find
frequent subgraphs in a collection of graphs. A
graph G′ is a subgraph of another graph G if there
exists a subgraph isomorphism2 from G′ to G, de-
noted by G′ ⊑ G.
Earlier approaches in frequent subgraph mining
(Inokuchi et al., 2000; Kuramochi and Karypis,
2001) used a two-step approach of first generating
the candidate subgraphs and then testing their fre-
quency in the graph database. The second step in-
volves a subgraph isomorphism test, which is NP-
complete. Although efficient isomorphism testing
algorithms have been developed making it practical
to use, with lots of candidate subgraphs to test, it can
</bodyText>
<footnote confidence="0.5339515">
2http://en.wikipedia.org/wiki/Subgraph_
isomorphism_problem
</footnote>
<figure confidence="0.760648216216216">
polQ
posQ
P_VBN
L_POSITIVE D_conj-but L_POSITIVE
U_interesting U_,
posQ
P_,
posQ
P_CC
U_but
posQ
P_RB
U_not
D_neg
U_compelling
P_JJ
posQ
polQ
posQ
P_.
U .
(a)
U_interesting
U_not
D_neg
U_compelling
polQ
L_POSITIVE D_conj-but L_POSITIVE
X X
D_neg
X
polQ
polQ
U_interesting U_not
D_neg
U_compelling
polQ
</figure>
<page confidence="0.995883">
133
</page>
<bodyText confidence="0.999950956521739">
still be very expensive for real applications.
gSpan (Yan and Han, 2002) uses an alternative
pattern growth based approach to frequent subgraph
mining, which extends graphs from a single sub-
graph directly, without candidate generation. For
each discovered subgraph G, new edges are added
recursively until all frequent supergraphs of G have
been discovered. gSpan uses a depth first search tree
(DFS) and restricts edge extension to only vertices
on the rightmost path. However, there can be multi-
ple DFS trees for a graph. gSpan introduces a set of
rules to select one of them as representative. Each
graph is represented by its unique canonical DFS
code, and the codes for two graphs are equivalent if
the graphs are isomorphic. This reduces the compu-
tational cost of the subgraph mining algorithm sub-
stantially, making gSpan orders of magnitude faster
than other subgraph mining algorithms. With sev-
eral implementations available 3, gSpan has been
commonly used for mining frequent subgraph pat-
terns (Kudo et al., 2004; Deshpande et al., 2005). In
this work, we use gSpan to mine frequent subgraphs
from the annotation graph.
</bodyText>
<sectionHeader confidence="0.858666" genericHeader="method">
5 Feature Construction using Genetic
Programming
</sectionHeader>
<bodyText confidence="0.99992">
A challenge to overcome when adding expressive-
ness to the feature space for any text classification
problem is the rapid increase in the feature space
size. Among this large set of new features, most
are not predictive or are very weak predictors, and
only a few carry novel information that improves
classification performance. Because of this, adding
more complex features often gives no improvement
or even worsens performance as the feature space’s
signal is drowned out by noise.
Riloff et al. (2006) propose a feature subsump-
tion approach to address this issue. They define a
hierarchy for features based on the information they
represent. A complex feature is only added if its
discriminative power is a delta above the discrimi-
native power of all its simpler forms. In this work,
we use a Genetic Programming (Koza, 1992) based
approach which evaluates interactions between fea-
</bodyText>
<footnote confidence="0.983655">
3http://www.cs.ucsb.edu/˜xyan/software/
gSpan.htm,http://www.kyb.mpg.de/bs/people/
nowozin/gboost/
</footnote>
<bodyText confidence="0.999950208333333">
tures and evolves complex features from them. The
advantage of the genetic programing based approach
over feature subsumption is that it allows us to eval-
uate a feature using multiple criteria. We show that
this approach performs better than feature subsump-
tion.
A lot of work has considered this genetic pro-
gramming problem (Smith and Bull, 2005). The
most similar approaches to ours are taken by Kraw-
iec (2002) and Otero et al. (2002), both of which use
genetic programming to build tree feature represen-
tations. None of this work was applied to a language
processing task, though there has been some sim-
ilar work to ours in that community, most notably
(Hirsch et al., 2007), which built search queries for
topic classification of documents. Our prior work
(Mayfield and Ros´e, 2010) introduced a new feature
construction method and was effective when using
unigram features; here we extend our approach to
feature spaces which are even larger and thus more
problematic.
The Genetic Programming (GP) paradigm is most
advantageous when applied to problems where there
is not a correct answer to a problem, but instead
there is a gradient of partial solutions which incre-
mentally improve in quality. Potential solutions are
represented as trees consisting of functions (non-leaf
nodes in the tree, which perform an action given
their child nodes as input) and terminals (leaf nodes
in the tree, often variables or constants in an equa-
tion). The tree (an individual) can then be inter-
preted as a program to be executed, and the output
of that program can be measured for fitness (a mea-
surement of the program’s quality). High-fitness in-
dividuals are selected for reproduction into a new
generation of candidate individuals through a breed-
ing process, where parts of each parent are combined
to form a new individual.
We apply this design to a language processing
task at the stage of feature construction - given many
weakly predictive features, we would like to com-
bine them in a way which produces a better feature.
For our functions we use boolean statements AND
and XOR, while our terminals are selected randomly
from the set of all unigrams and our new, extracted
subgraph features. Each leaf’s value, when applied
to a single sentence, is equal to 1 if that subgraph is
present in the sentence, and 0 if the subgraph is not
</bodyText>
<page confidence="0.993681">
134
</page>
<bodyText confidence="0.964889076923077">
present.
The tree in Figure 3 is a simplified example of our
evolved features. It combines three features, a uni-
gram feature ‘too’ (centre node) and two subgraph
features: 1) the subgraph in the leftmost node oc-
curs in collocations containing “more than” (e.g.,
“nothing more than” or “little more than”), 2) the
subgraph in the rightmost node occurs in negative
phrases such as “opportunism at its most glaring”
(JJS is a superlative adjective and PRP$ is a pos-
sessive pronoun). A single feature combining these
weak indicators can be more predictive than any part
alone.
</bodyText>
<figureCaption confidence="0.957597">
Figure 3: A tree constructed using subgraph features and GP
(Simplified for illustrative purposes)
</figureCaption>
<subsectionHeader confidence="0.997871">
5.2 Defining Fitness
</subsectionHeader>
<bodyText confidence="0.9999794">
Our definition of fitness is based on the concepts
of precision and recall, borrowed from informa-
tion retrieval. We define our set of documents
as being comprised of a set of positive documents
P0, P1, P2, ...Pu and a set of negative documents
N0, N1, N2, ...Nv. For a given individual I and doc-
ument D, we define hit(I, D) to equal 1 if the state-
ment I is true of that document and 0 otherwise. Pre-
cision and recall of an individual feature for predict-
ing positive documents5 is then defined as follows:
</bodyText>
<equation confidence="0.972947625">
u
E hit(I, Pi)
Prec(I) = u i=0 v (1)
E hit(I, Pi) + E hit(I, Ni)
i=0 i=0
u
E hit(I, Pi)
Rec(I) = i=0 u (2)
</equation>
<bodyText confidence="0.9973555">
We then weight these values to give significantly
more importance to precision, using the Fβ measure,
which gives the harmonic mean between precision
and recall:
</bodyText>
<figure confidence="0.972353636363636">
U_more
D_prep_than
XOR
U_too
XOR
D_poss
_�
U_�t�
POS_PRP$
_
PO4_JJ4
</figure>
<bodyText confidence="0.9994455">
In the rest of this section, we first describe the
feature construction process using genetic program-
ming. We then discuss how fitness of an individual
is measured for our classification task.
</bodyText>
<subsectionHeader confidence="0.982325">
5.1 Feature Construction Process
</subsectionHeader>
<bodyText confidence="0.999943384615385">
We divide our data into two sets, training and test.
We again divide our training data in half, and train
our GP features on only one half of this data4 This is
to avoid overfitting the final SVM model to the GP
features. In a single GP run, we produce one feature
to match each class value. For a sentiment classifica-
tion task, a feature is evolved to be predictive of the
positive instances, and another feature is evolved to
be predictive of the negative documents. We repeat
this procedure a total of 15 times (using different
seeds for random selection of features), producing
a total of 30 new features to be added to the feature
space.
</bodyText>
<footnote confidence="0.9377365">
4For genetic programming we used the ECJ toolkit
(http://cs.gmu.edu/˜eclab/projects/ecj/).
</footnote>
<equation confidence="0.989913333333333">
Fβ(I)
= (1 + β2) × (Prec(I) RRec(I )) (3)
(β2 × Prec(I)) ()
</equation>
<bodyText confidence="0.999609466666667">
In addition to this fitness function, we add two
penalties to the equation. The first penalty applies to
prevent trees from becoming overly complex. One
option to ensure that features remain moderately
simple is to simply have a maximum depth beyond
which trees cannot grow. Following the work of
Otero et al. (2002), we penalize trees based on the
number of nodes they contain. This discourages
bloat, i.e. sections of trees which do not contribute to
overall accuracy. This penalty, known as parsimony
pressure, is labeled PP in our fitness function.
The second penalty is based on the correlation be-
tween the feature being constructed, and the sub-
graphs and unigrams which appear as nodes within
that individual. Without this penalty, a feature may
</bodyText>
<footnote confidence="0.955882">
5Negative precision and recall are defined identically, with
obvious adjustments to test for negative documents instead of
positive.
</footnote>
<page confidence="0.998663">
135
</page>
<bodyText confidence="0.9888132">
often be redundant, taking much more complexity
to represent the same information that is captured
with a simple unigram. We measure correlation us-
ing Pearson’s product moment, defined for two vec-
tors X, Y as:
</bodyText>
<equation confidence="0.9690495">
E[(X − µX)(Y − µY )]
QXQY
</equation>
<bodyText confidence="0.991496166666667">
This results in a value from 1 (for perfect align-
ment) to -1 (for inverse alignment). We assign a
penalty for any correlation past a cutoff. This func-
tion is labeled CC (correlation constraint) in our fit-
ness function.
Our fitness function therefore is:
</bodyText>
<equation confidence="0.9985785">
Fitness = F1
8 + PP + CC (5)
</equation>
<sectionHeader confidence="0.998528" genericHeader="evaluation">
6 Experiments and Results
</sectionHeader>
<bodyText confidence="0.99998475">
We evaluate our approach on a sentiment classifi-
cation task, where the goal is to classify a movie
review sentence as expressing positive or negative
sentiment towards the movie.
</bodyText>
<subsectionHeader confidence="0.994278">
6.1 Data and Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999936">
Data: The dataset consists of snippets from Rot-
ten Tomatoes (Pang and Lee, 2005) 6. It consists
of 10662 snippets/sentences total with equal num-
ber positive and negative sentences (5331 each).
This dataset was created and used by Pang and Lee
(2005) to train a classifier for identifying positive
sentences in a full length review. We use the first
8000 (4000 positive, 4000 negative) sentences as
training data and evaluate on remaining 2662 (1331
positive, 1331 negative) sentences. We added part
of speech and dependency triple annotations to this
data using the Stanford parser (Klein and Manning,
2003).
Annotation Graph: For the annotation graph rep-
resentation, we used Unigrams (U), Part of Speech
(P) and Dependency Relation Type (D) as labels for
the nodes, and ParentOfGov and ParentOfDep as la-
bels for the edges. For a dependency triple such as
“amod good movie”, five nodes are added to the an-
notation graph as shown in Figure 4(a). ParentOf-
Gov and ParentOfDep edges are added from the
</bodyText>
<footnote confidence="0.9533835">
6http://www.cs.cornell.edu/people/pabo/
movie-review-data/rt-polaritydata.tar.gz
</footnote>
<figureCaption confidence="0.996036333333333">
Figure 4: Annotation graph and a feature subgraph for
dependency triple annotation “amod good camera”. (c)
shows an alternative representation with wild cards
</figureCaption>
<bodyText confidence="0.999413904761905">
dependency relation node D amod to the unigram
nodes U good and U movie. These edges are also
added for the part of speech nodes that correspond
to the two unigrams in the dependency relation, as
shown in Figure 4(a). This allows the algorithm to
find general patterns, based on a dependency rela-
tion between two part of speech nodes, two unigram
nodes or a combination of the two. For example,
a subgraph in Figure 4(b) captures a general pat-
tern where good modifies a noun. This feature ex-
ists in “amod good movie”, “amod good camera”
and other similar dependency triples. This feature is
similar to the the dependency back-off features pro-
posed in Joshi and Ros´e (2009).
The extra edges are an alternative to putting wild
cards on words, as proposed in section 3. On the
other hand, putting a wild card on every word in
the annotation graph for our example (Figure 4(c)),
will only give features based on dependency rela-
tions between part of speech annotations. Thus, the
wild card based approach is more restrictive than
</bodyText>
<figure confidence="0.99807152">
ParentofDep
ParentofDep
P_JJ
U_good
D_amod
ParentofGov
ParentofGov
U_movie
P_NN
P_NN
ParentofGov
D_amod
ParentofDep
U_good
D_amod
P_NN
P_JJ
ParentofDep
posQ
ParentofGov
posQ
X
X
PX,y =
(4)
</figure>
<page confidence="0.996953">
136
</page>
<bodyText confidence="0.995150375">
adding more edges. However, with lots of edges, the
complexity of the subgraph mining algorithm and
the number of subgraph features increases tremen-
dously.
Classifier: For our experiments we use Support
Vector Machines (SVM) with a linear kernel. We
use the SVM-light7 implementation of SVM with
default settings.
Parameters: The gSpan algorithm requires setting
the minimum support threshold (minsup) for the
subgraph patterns to extract. Support for a subgraph
is the number of graphs in the dataset that contain
the subgraph. We experimented with several values
for minimum support and minsup = 2 gave us the
best performance.
For Genetic Programming, we used the same pa-
rameter settings as described in Mayfield and Ros´e
(2010), which were tuned on a different dataset8
than one used in this work, but it is from the same
movie review domain. We also consider one alter-
ation to these settings. As we are introducing many
new and highly correlated features to our feature
space through subgraphs, we believe that a stricter
constraint must be placed on correlation between
features. To accomplish this, we can set our correla-
tion penalty cutoff to 0.3, lower than the 0.5 cutoff
used in prior work. Results for both settings are re-
ported.
Baselines: To the best of our knowledge, there is
no supervised machine learning result published on
this dataset. We compare our results with the fol-
lowing baselines:
</bodyText>
<listItem confidence="0.906871666666667">
• Unigram-only Baseline: In sentiment analysis,
unigram-only features have been a strong base-
line (Pang et al., 2002; Pang and Lee, 2004).
</listItem>
<bodyText confidence="0.8681355">
We only use unigrams that occur in at least
two sentences of the training data same as Mat-
sumoto et al. (2005). We also filter out stop
words using a small stop word list9.
</bodyText>
<listItem confidence="0.90935">
• x2 Baseline: For our training data, after filter-
ing infrequent unigrams and stop words, we get
</listItem>
<footnote confidence="0.988100666666667">
7http://svmlight.joachims.org/
8Full movie review data by Pang et al. (2002)
9http://nlp.stanford.edu/
IR-book/html/htmledition/
dropping-common-terms-stop-words-1.html
(with one modification: removed ‘will’, added ‘this’)
</footnote>
<bodyText confidence="0.99838125">
8424 features. Adding subgraph features in-
creases the total number of features to 44,161,
a factor of 5 increase in size. Feature selec-
tion can be used to reduce this size by select-
ing the most discriminative features. x2 feature
selection (Manning et al., 2008) is commonly
used in the literature. We compare two methods
of feature selection with x2, one which rejects
features if their x2 score is not significant at the
0.05 level, and one that reduces the number of
features to match the size of our feature space
with GP.
</bodyText>
<listItem confidence="0.931836777777778">
• Feature Subsumption (FS): Following the idea
in Riloff et al. (2006), a complex feature
C is discarded if IG(S) ≥ IG(C) − 6,
where IG is Information Gain and S is
a simple feature that representationally sub-
sumes C, i.e. the text spans that match S
are a superset of the text spans that match
C. In our work, complex features are sub-
graph features and simple features are uni-
gram features contained in them. For example,
(D amod) Edge ParentOfDep (U bad) is
a complex feature for which U bad is a sim-
ple feature. We tried same values for 6 E
{0.002, 0.001, 0.0005}, as suggested in Riloff
et al. (2006). Since all values gave us same
number of features, we only report a single re-
sult for feature subsumption.
• Correlation (Corr): As mentioned earlier,
some of the subgraph features are highly corre-
lated with unigram features and do not provide
new knowledge. A correlation based filter for
subgraph features can be used to discard a com-
plex feature C if its absolute correlation with its
simpler feature (unigram feature) is more than
a certain threshold. We use the same threshold
as used in the GP criterion, but as a hard filter
instead of a penalty.
</listItem>
<subsectionHeader confidence="0.900095">
6.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999040666666667">
In Table 1, we present our results. As can be
seen, subgraph features when added to the unigrams,
without any feature selection, decrease the perfor-
mance. x2 feature selection with fixed feature space
size provides a very small gain over unigrams. All
other feature selection approaches perform worse
</bodyText>
<page confidence="0.990343">
137
</page>
<table confidence="0.999242">
Settings #Features Acc. A
Uni 8424 75.66 -
Uni + Sub 44161 75.28 -0.38
Uni + Sub, x2 sig. 3407 74.68 -0.98
Uni + Sub, x2 size 8454 75.77 +0.11
Uni + Sub, (FS) 18234 75.47 -0.19
Uni + Sub, (Corr) 18980 75.24 -0.42
Uni + GP (U) † 8454 76.18 +0.52
Uni + GP (U+S) ‡ 8454 76.48 +0.82
Uni + GP (U+S) † 8454 76.93 +1.27
</table>
<tableCaption confidence="0.876127111111111">
Table 1: Experimental results for feature spaces with un-
igrams, with and without subgraph features. Feature se-
lection with 1) fixed significance level (x2 sig.), 2) fixed
feature space size (x2 size), 3) Feature Subsumption (FS)
and 4) Correlation based feature filtering (Corr)). GP fea-
tures for unigrams only {GP(U)}, or both unigrams and
subgraph features {GP(U+S)}. Both the settings from
Mayfield and Ros´e (2010) (‡) and more stringent correla-
tion constraint (†) are reported. #Features is the num-
</tableCaption>
<bodyText confidence="0.961064481481481">
ber of features in the training data. Acc is the accuracy
and A is the difference from unigram only baseline. Best
performing feature configuration is highlighted in bold.
than the unigram-only approach. With GP, we ob-
serve a marginally significant gain (p &lt; 0.1) in per-
formance over unigrams, calculated using one-way
ANOVA. Benefit from GP is more when subgraph
features are used in addition to the unigram features,
for constructing more complex pattern features. Ad-
ditionally, our performance is improved when we
constrain the correlation more severely than in previ-
ously published research, supporting our hypothesis
that this is a helpful way to respond to the problem
of redundancy in subgraph features.
A problem that we see with x2 feature selection is
that several top ranked features may be highly cor-
related. For example, the top 5 features based on x2
score are shown in Table 2; it is immediately obvi-
ous that the features are highly redundant.
With GP based feature construction, we can con-
sider this relationship between features, and con-
struct new features as a combination of selected un-
igram and subgraph features. With the correlation
criterion in the evolution process, we are able to
build combined features that provide new informa-
tion compared to unigrams.
The results we present are for the best perform-
</bodyText>
<table confidence="0.9935912">
(D advmod) Edge ParentOfDep (U too)
U too
U bad
U movie
(D amod) Edge ParentOfDep (U bad)
</table>
<tableCaption confidence="0.999255">
Table 2: Top features based on x2 score
</tableCaption>
<bodyText confidence="0.9891756">
ing parameter configuration that we tested, after a
series of experiments. We realize that this places us
in danger of overfitting to the particulars of this data
set, however, the data set is large enough to partially
mitigate this concern.
</bodyText>
<sectionHeader confidence="0.997352" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99999605">
We have shown that there is additional information
to be gained from text beyond words, and demon-
strated two methods for increasing this information -
a subgraph mining approach that finds common syn-
tactic patterns that capture sentiment-bearing rhetor-
ical structure in text, and a feature construction
technique that uses genetic programming to com-
bine these more complex features without the redun-
dancy, increasing the size of the feature space only
by a fixed amount. The increase in performance that
we see is small but consistent.
In the future, we would like to extend this work to
other datasets and other problems within the field of
sentiment analysis. With the availability of several
off-the-shelf linguistic annotators, we may add more
linguistic annotations to the annotation graph and
richer subgraph features may be discovered. There
is also additional refinement that can be performed
on our genetic programming fitness function, which
is expected to improve the quality of our features.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999864">
This work was funded in part by the DARPA Ma-
chine Reading program under contract FA8750-09-
C-0172, and in part by NSF grant DRL-0835426.
We would like to thank Dr. Xifeng Yan and Marisa
Thoma for the gSpan code.
</bodyText>
<sectionHeader confidence="0.99937" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.933185">
Shilpa Arora, Mahesh Joshi and Carolyn P. Ros´e. 2009.
Identifying Types of Claims in Online Customer Re-
</reference>
<page confidence="0.982358">
138
</page>
<reference confidence="0.999494568421053">
views. Proceedings of the HLT/NAACL.
Shilpa Arora and Eric Nyberg. 2009. Interactive Anno-
tation Learning with Indirect Feature Voting. Proceed-
ings of the HLT/NAACL (Student Research Work-
shop).
Tatsuya Asai, Kenji Abe, Shinji Kawasoe, Hiroshi
Sakamoto and Setsuo Arikawa. 2002. Efficient sub-
structure discovery from large semi-structured data.
Proceedings of SIAM Int. Conf. on Data Mining
(SDM).
Mukund Deshpande , Michihiro Kuramochi , Nikil Wale
and George Karypis. 2005. Frequent Substructure-
Based Approaches for Classifying Chemical Com-
pounds. IEEE Transactions on Knowledge and Data
Engineering.
Michael Gamon. 2004. Sentiment classification on cus-
tomer feedback data: noisy data, large feature vec-
tors, and the role of linguistic analysis, Proceedings
of COLING.
Laurence Hirsch, Robin Hirsch and Masoud Saeedi.
2007. Evolving Lucene Search Queries for Text Clas-
sification. Proceedings of the Genetic and Evolution-
ary Computation Conference.
Mahesh Joshi and Carolyn P. Ros´e. 2009. Generalizing
Dependency Features for Opinion Mining. Proceed-
ings of the ACL-IJCNLP Conference (Short Papers).
Akihiro Inokuchi, Takashi Washio and Hiroshi Motoda.
2000. An Apriori-based Algorithm for Mining Fre-
quent Substructures from Graph Data. Proceedings
of PKDD.
Dan Klein and Christopher D. Manning. 2003. Accurate
unlexicalized parsing. Proceedings of the main con-
ference of the ACL.
John Koza. 1992. Genetic Programming: On the Pro-
gramming of Computers by Means of Natural Selec-
tion. MIT Press.
Krzysztof Krawiec. 2002. Genetic programming-based
construction of features for machine learning and
knowledge discovery tasks. Genetic Programming and
Evolvable Machines.
Taku Kudo, Eisaku Maeda and Yuji Matsumoto. 2004.
An Application of Boosting to Graph Classification.
Proceedings of NIPS.
Michihiro Kuramochi and George Karypis. 2002. Fre-
quent Subgraph Discovery. Proceedings of ICDM.
Christopher D. Manning, Prabhakar Raghavan and Hin-
rich Schtze. 2008. Introduction to Information Re-
trieval. Proceedings of PAKDD.
Shotaro Matsumoto, Hiroya Takamura and Manabu Oku-
mura. 2005. Sentiment Classification Using Word
Sub-sequences and Dependency Sub-trees. Proceed-
ings of PAKDD.
Elijah Mayfield and Carolyn Penstein-Ros´e. 2010.
Using Feature Construction to Avoid Large Feature
Spaces in Text Classification. Proceedings of the Ge-
netic and Evolutionary Computation Conference.
Fernando Otero, Monique Silva, Alex Freitas and Julio
Nievola. 2002. Genetic Programming for Attribute
Construction in Data Mining. Proceedings of the Ge-
netic and Evolutionary Computation Conference.
Bo Pang, Lillian Lee and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment Classication using Ma-
chine Learning Techniques. Proceedings of EMNLP.
Bo Pang and Lillian Lee. 2004. A Sentimental Educa-
tion: Sentiment Analysis Using Subjectivity Summa-
rization Based on Minimum Cuts. Proceedings of the
main conference of ACL.
Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting
class relationships for sentiment categorization with
respect to rating scales. Proceedings of the main con-
ference of ACL.
Jian Pei, Jiawei Han, Behzad Mortazavi-asl, Jianyong
Wang, Helen Pinto, Qiming Chen, Umeshwar Dayal
and Mei-chun Hsu. 2004. Mining Sequential Pat-
terns by Pattern-Growth: The PrefixSpan Approach.
Proceedings of IEEE Transactions on Knowledge and
Data Engineering.
Ellen Riloff, Siddharth Patwardhan and Janyce Wiebe.
2006. Feature Subsumption for Opinion Analysis.
Proceedings of the EMNLP.
Matthew Smith and Larry Bull. 2005. Genetic Program-
ming with a Genetic Algorithm for Feature Construc-
tion and Selection. Genetic Programming and Evolv-
able Machines.
Theresa Wilson, Janyce Wiebe and Rebecca Hwa. 2004.
Just How Mad Are You? Finding Strong and Weak
Opinion Clauses. Proceedings of AAAI.
Theresa Wilson, Janyce Wiebe and Paul Hoff-
mann. 2005. Recognizing Contextual Polarity
in Phrase-Level Sentiment Analysis. Proceedings of
HLT/EMNLP.
Xifeng Yan and Jiawei Han. 2002. gSpan: Graph-
Based Substructure Pattern Mining. UIUC Techni-
cal Report, UIUCDCS-R-2002-2296 (shorter version
in ICDM’02).
</reference>
<page confidence="0.998859">
139
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.752327">
<title confidence="0.999667">Sentiment Classification using Automatically Extracted Subgraph Features</title>
<author confidence="0.924128">Shilpa Arora</author>
<author confidence="0.924128">Elijah Mayfield</author>
<author confidence="0.924128">Carolyn Penstein-Ros´e</author>
<author confidence="0.924128">Eric</author>
<affiliation confidence="0.9065015">Language Technologies Carnegie Mellon</affiliation>
<address confidence="0.99995">5000 Forbes Avenue, Pittsburgh, PA</address>
<email confidence="0.968879">emayfiel,cprose,</email>
<abstract confidence="0.996418375">In this work, we propose a novel representation of text based on patterns derived from linguistic annotation graphs. We use a subgraph mining algorithm to automatically derive features as frequent subgraphs from the annotation graph. This process generates a very large number of features, many of which are highly correlated. We propose a genetic programming based approach to feature construction which creates a fixed number of strong classification predictors from these subgraphs. We evaluate the benefit gained from evolved structured features, when used in addition to the bag-of-words features, for a sentiment classification task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shilpa Arora</author>
<author>Mahesh Joshi</author>
<author>Carolyn P Ros´e</author>
</authors>
<date>2009</date>
<booktitle>Identifying Types of Claims in Online Customer Reviews. Proceedings of the HLT/NAACL.</booktitle>
<marker>Arora, Joshi, Ros´e, 2009</marker>
<rawString>Shilpa Arora, Mahesh Joshi and Carolyn P. Ros´e. 2009. Identifying Types of Claims in Online Customer Reviews. Proceedings of the HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shilpa Arora</author>
<author>Eric Nyberg</author>
</authors>
<title>Interactive Annotation Learning with Indirect Feature Voting.</title>
<date>2009</date>
<booktitle>Proceedings of the HLT/NAACL (Student Research Workshop).</booktitle>
<contexts>
<context position="2669" citStr="Arora and Nyberg (2009)" startWordPosition="410" endWordPosition="413">s, there are also features that provide new information. It is these features that we aim to capture. In this work, we propose an evolutionary approach that constructs complex features from subgraphs extracted from an annotation graph. A constant number of these features are added to the unigram feature space, adding much of the representational benefits without the computational cost of a drastic increase in feature space size. In the remainder of the paper, we review prior work on features commonly used for sentiment analysis. We then describe the annotation graph representation proposed by Arora and Nyberg (2009). Following this, we describe the frequent subgraph mining algorithm proposed in Yan and Han (2002), and used in this work to extract frequent subgraphs from the annotation graphs. We then introduce our novel feature evolution approach, and discuss our experimental setup and results. Subgraph features combined with the feature evolution approach gives promising results, with an improvement in performance over the baseline. 2 Related Work Some of the recent work in sentiment analysis has shown that structured features (features that capture syntactic patterns in text), such as n-grams, dependen</context>
<context position="5473" citStr="Arora and Nyberg (2009)" startWordPosition="829" endWordPosition="832">e the best performance to date on a commonly-used movie review dataset. Their approach presents an automatic procedure for deriving features that capture long distance dependencies without much expert intervention. However, their approach is limited to sequences or tree annotations. Often, features that combine several annotations capture interesting characteristics of text. For example, Wilson et al. (2004), Gamon (2004) and Joshi and Ros´e (2009) show that a combination of dependency relations and part of speech annotations boosts performance. The annotation graph representation proposed by Arora and Nyberg (2009) is a formalism for representing several linguistic annotations together on text. With an annotation graph representation, instances are represented as graphs from which frequent subgraph patterns may be extracted and used as features for learning new annotations. 1Although, in this work we are classifying sentences and not phrases, similar clues may be used for sentiment classification in sentences as well In this work, we use an efficient frequent subgraph mining algorithm (gSpan) (Yan and Han, 2002) to extract frequent subgraphs from a linguistic annotation graph (Arora and Nyberg, 2009). A</context>
</contexts>
<marker>Arora, Nyberg, 2009</marker>
<rawString>Shilpa Arora and Eric Nyberg. 2009. Interactive Annotation Learning with Indirect Feature Voting. Proceedings of the HLT/NAACL (Student Research Workshop).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tatsuya Asai</author>
</authors>
<title>Kenji Abe, Shinji Kawasoe, Hiroshi Sakamoto and Setsuo Arikawa.</title>
<date>2002</date>
<booktitle>Proceedings of SIAM Int. Conf. on Data Mining (SDM).</booktitle>
<marker>Asai, 2002</marker>
<rawString>Tatsuya Asai, Kenji Abe, Shinji Kawasoe, Hiroshi Sakamoto and Setsuo Arikawa. 2002. Efficient substructure discovery from large semi-structured data. Proceedings of SIAM Int. Conf. on Data Mining (SDM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michihiro Kuramochi</author>
</authors>
<title>Frequent SubstructureBased Approaches for Classifying Chemical Compounds.</title>
<date>2005</date>
<journal>IEEE Transactions on Knowledge and Data Engineering.</journal>
<marker>Kuramochi, 2005</marker>
<rawString>Mukund Deshpande , Michihiro Kuramochi , Nikil Wale and George Karypis. 2005. Frequent SubstructureBased Approaches for Classifying Chemical Compounds. IEEE Transactions on Knowledge and Data Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
</authors>
<title>Sentiment classification on customer feedback data: noisy data, large feature vectors, and the role of linguistic analysis,</title>
<date>2004</date>
<booktitle>Proceedings of COLING.</booktitle>
<contexts>
<context position="3774" citStr="Gamon (2004)" startWordPosition="574" endWordPosition="575">hown that structured features (features that capture syntactic patterns in text), such as n-grams, dependency relations, etc., improve performance beyond Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 131–139, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics the bag of words approach. Arora et al. (2009) show that deep syntactic scope features constructed from transitive closure of dependency relations give significant improvement for identifying types of claims in product reviews. Gamon (2004) found that using deep linguistic features derived from phrase structure trees and part of speech annotations yields significant improvements on the task of predicting satisfaction ratings in customer feedback data. Wilson et al. (2004) use syntactic clues derived from dependency parse tree as features for predicting the intensity of opinion phrases1. Structured features that capture linguistic patterns are often hand crafted by domain experts (Wilson et al., 2005) after careful examination of the data. Thus, they do not always generalize well across datasets and domains. This also requires a </context>
<context position="5275" citStr="Gamon (2004)" startWordPosition="800" endWordPosition="802">rive structured features such as word sub-sequences and dependency sub-trees. They show that these features outperform bag-of-words features for a sentiment classification task and achieve the best performance to date on a commonly-used movie review dataset. Their approach presents an automatic procedure for deriving features that capture long distance dependencies without much expert intervention. However, their approach is limited to sequences or tree annotations. Often, features that combine several annotations capture interesting characteristics of text. For example, Wilson et al. (2004), Gamon (2004) and Joshi and Ros´e (2009) show that a combination of dependency relations and part of speech annotations boosts performance. The annotation graph representation proposed by Arora and Nyberg (2009) is a formalism for representing several linguistic annotations together on text. With an annotation graph representation, instances are represented as graphs from which frequent subgraph patterns may be extracted and used as features for learning new annotations. 1Although, in this work we are classifying sentences and not phrases, similar clues may be used for sentiment classification in sentences</context>
</contexts>
<marker>Gamon, 2004</marker>
<rawString>Michael Gamon. 2004. Sentiment classification on customer feedback data: noisy data, large feature vectors, and the role of linguistic analysis, Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurence Hirsch</author>
<author>Robin Hirsch</author>
<author>Masoud Saeedi</author>
</authors>
<title>Evolving Lucene Search Queries for Text Classification.</title>
<date>2007</date>
<booktitle>Proceedings of the Genetic and Evolutionary Computation Conference.</booktitle>
<contexts>
<context position="14340" citStr="Hirsch et al., 2007" startWordPosition="2279" endWordPosition="2282">ge of the genetic programing based approach over feature subsumption is that it allows us to evaluate a feature using multiple criteria. We show that this approach performs better than feature subsumption. A lot of work has considered this genetic programming problem (Smith and Bull, 2005). The most similar approaches to ours are taken by Krawiec (2002) and Otero et al. (2002), both of which use genetic programming to build tree feature representations. None of this work was applied to a language processing task, though there has been some similar work to ours in that community, most notably (Hirsch et al., 2007), which built search queries for topic classification of documents. Our prior work (Mayfield and Ros´e, 2010) introduced a new feature construction method and was effective when using unigram features; here we extend our approach to feature spaces which are even larger and thus more problematic. The Genetic Programming (GP) paradigm is most advantageous when applied to problems where there is not a correct answer to a problem, but instead there is a gradient of partial solutions which incrementally improve in quality. Potential solutions are represented as trees consisting of functions (non-le</context>
</contexts>
<marker>Hirsch, Hirsch, Saeedi, 2007</marker>
<rawString>Laurence Hirsch, Robin Hirsch and Masoud Saeedi. 2007. Evolving Lucene Search Queries for Text Classification. Proceedings of the Genetic and Evolutionary Computation Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mahesh Joshi</author>
<author>Carolyn P Ros´e</author>
</authors>
<title>Generalizing Dependency Features for Opinion Mining.</title>
<date>2009</date>
<booktitle>Proceedings of the ACL-IJCNLP Conference (Short Papers).</booktitle>
<marker>Joshi, Ros´e, 2009</marker>
<rawString>Mahesh Joshi and Carolyn P. Ros´e. 2009. Generalizing Dependency Features for Opinion Mining. Proceedings of the ACL-IJCNLP Conference (Short Papers).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akihiro Inokuchi</author>
</authors>
<title>Takashi Washio and Hiroshi Motoda.</title>
<date>2000</date>
<booktitle>Proceedings of PKDD.</booktitle>
<marker>Inokuchi, 2000</marker>
<rawString>Akihiro Inokuchi, Takashi Washio and Hiroshi Motoda. 2000. An Apriori-based Algorithm for Mining Frequent Substructures from Graph Data. Proceedings of PKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>Proceedings of the main conference of the ACL.</booktitle>
<contexts>
<context position="20804" citStr="Klein and Manning, 2003" startWordPosition="3377" endWordPosition="3380">perimental Setup Data: The dataset consists of snippets from Rotten Tomatoes (Pang and Lee, 2005) 6. It consists of 10662 snippets/sentences total with equal number positive and negative sentences (5331 each). This dataset was created and used by Pang and Lee (2005) to train a classifier for identifying positive sentences in a full length review. We use the first 8000 (4000 positive, 4000 negative) sentences as training data and evaluate on remaining 2662 (1331 positive, 1331 negative) sentences. We added part of speech and dependency triple annotations to this data using the Stanford parser (Klein and Manning, 2003). Annotation Graph: For the annotation graph representation, we used Unigrams (U), Part of Speech (P) and Dependency Relation Type (D) as labels for the nodes, and ParentOfGov and ParentOfDep as labels for the edges. For a dependency triple such as “amod good movie”, five nodes are added to the annotation graph as shown in Figure 4(a). ParentOfGov and ParentOfDep edges are added from the 6http://www.cs.cornell.edu/people/pabo/ movie-review-data/rt-polaritydata.tar.gz Figure 4: Annotation graph and a feature subgraph for dependency triple annotation “amod good camera”. (c) shows an alternative </context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. Proceedings of the main conference of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Koza</author>
</authors>
<title>Genetic Programming: On the Programming of Computers by Means of Natural Selection.</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="13508" citStr="Koza, 1992" startWordPosition="2155" endWordPosition="2156"> or are very weak predictors, and only a few carry novel information that improves classification performance. Because of this, adding more complex features often gives no improvement or even worsens performance as the feature space’s signal is drowned out by noise. Riloff et al. (2006) propose a feature subsumption approach to address this issue. They define a hierarchy for features based on the information they represent. A complex feature is only added if its discriminative power is a delta above the discriminative power of all its simpler forms. In this work, we use a Genetic Programming (Koza, 1992) based approach which evaluates interactions between fea3http://www.cs.ucsb.edu/˜xyan/software/ gSpan.htm,http://www.kyb.mpg.de/bs/people/ nowozin/gboost/ tures and evolves complex features from them. The advantage of the genetic programing based approach over feature subsumption is that it allows us to evaluate a feature using multiple criteria. We show that this approach performs better than feature subsumption. A lot of work has considered this genetic programming problem (Smith and Bull, 2005). The most similar approaches to ours are taken by Krawiec (2002) and Otero et al. (2002), both of</context>
</contexts>
<marker>Koza, 1992</marker>
<rawString>John Koza. 1992. Genetic Programming: On the Programming of Computers by Means of Natural Selection. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Krzysztof Krawiec</author>
</authors>
<title>Genetic programming-based construction of features for machine learning and knowledge discovery tasks. Genetic Programming and Evolvable Machines.</title>
<date>2002</date>
<contexts>
<context position="14075" citStr="Krawiec (2002)" startWordPosition="2233" endWordPosition="2235">work, we use a Genetic Programming (Koza, 1992) based approach which evaluates interactions between fea3http://www.cs.ucsb.edu/˜xyan/software/ gSpan.htm,http://www.kyb.mpg.de/bs/people/ nowozin/gboost/ tures and evolves complex features from them. The advantage of the genetic programing based approach over feature subsumption is that it allows us to evaluate a feature using multiple criteria. We show that this approach performs better than feature subsumption. A lot of work has considered this genetic programming problem (Smith and Bull, 2005). The most similar approaches to ours are taken by Krawiec (2002) and Otero et al. (2002), both of which use genetic programming to build tree feature representations. None of this work was applied to a language processing task, though there has been some similar work to ours in that community, most notably (Hirsch et al., 2007), which built search queries for topic classification of documents. Our prior work (Mayfield and Ros´e, 2010) introduced a new feature construction method and was effective when using unigram features; here we extend our approach to feature spaces which are even larger and thus more problematic. The Genetic Programming (GP) paradigm </context>
</contexts>
<marker>Krawiec, 2002</marker>
<rawString>Krzysztof Krawiec. 2002. Genetic programming-based construction of features for machine learning and knowledge discovery tasks. Genetic Programming and Evolvable Machines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Eisaku Maeda</author>
<author>Yuji Matsumoto</author>
</authors>
<title>An Application of Boosting to Graph Classification.</title>
<date>2004</date>
<booktitle>Proceedings of NIPS.</booktitle>
<contexts>
<context position="12522" citStr="Kudo et al., 2004" startWordPosition="1992" endWordPosition="1995"> restricts edge extension to only vertices on the rightmost path. However, there can be multiple DFS trees for a graph. gSpan introduces a set of rules to select one of them as representative. Each graph is represented by its unique canonical DFS code, and the codes for two graphs are equivalent if the graphs are isomorphic. This reduces the computational cost of the subgraph mining algorithm substantially, making gSpan orders of magnitude faster than other subgraph mining algorithms. With several implementations available 3, gSpan has been commonly used for mining frequent subgraph patterns (Kudo et al., 2004; Deshpande et al., 2005). In this work, we use gSpan to mine frequent subgraphs from the annotation graph. 5 Feature Construction using Genetic Programming A challenge to overcome when adding expressiveness to the feature space for any text classification problem is the rapid increase in the feature space size. Among this large set of new features, most are not predictive or are very weak predictors, and only a few carry novel information that improves classification performance. Because of this, adding more complex features often gives no improvement or even worsens performance as the featur</context>
</contexts>
<marker>Kudo, Maeda, Matsumoto, 2004</marker>
<rawString>Taku Kudo, Eisaku Maeda and Yuji Matsumoto. 2004. An Application of Boosting to Graph Classification. Proceedings of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michihiro Kuramochi</author>
<author>George Karypis</author>
</authors>
<title>Frequent Subgraph Discovery.</title>
<date>2002</date>
<booktitle>Proceedings of ICDM.</booktitle>
<marker>Kuramochi, Karypis, 2002</marker>
<rawString>Michihiro Kuramochi and George Karypis. 2002. Frequent Subgraph Discovery. Proceedings of ICDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
</authors>
<title>Prabhakar Raghavan and Hinrich Schtze.</title>
<date>2008</date>
<booktitle>Proceedings of PAKDD.</booktitle>
<marker>Manning, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan and Hinrich Schtze. 2008. Introduction to Information Retrieval. Proceedings of PAKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shotaro Matsumoto</author>
</authors>
<title>Hiroya Takamura and Manabu Okumura.</title>
<date>2005</date>
<booktitle>Proceedings of PAKDD.</booktitle>
<marker>Matsumoto, 2005</marker>
<rawString>Shotaro Matsumoto, Hiroya Takamura and Manabu Okumura. 2005. Sentiment Classification Using Word Sub-sequences and Dependency Sub-trees. Proceedings of PAKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elijah Mayfield</author>
<author>Carolyn Penstein-Ros´e</author>
</authors>
<title>Using Feature Construction to Avoid Large Feature Spaces in Text Classification.</title>
<date>2010</date>
<booktitle>Proceedings of the Genetic and Evolutionary Computation Conference.</booktitle>
<marker>Mayfield, Penstein-Ros´e, 2010</marker>
<rawString>Elijah Mayfield and Carolyn Penstein-Ros´e. 2010. Using Feature Construction to Avoid Large Feature Spaces in Text Classification. Proceedings of the Genetic and Evolutionary Computation Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Otero</author>
<author>Monique Silva</author>
<author>Alex Freitas</author>
<author>Julio Nievola</author>
</authors>
<title>Genetic Programming for Attribute Construction in Data Mining.</title>
<date>2002</date>
<booktitle>Proceedings of the Genetic and Evolutionary Computation Conference.</booktitle>
<contexts>
<context position="14099" citStr="Otero et al. (2002)" startWordPosition="2237" endWordPosition="2240">tic Programming (Koza, 1992) based approach which evaluates interactions between fea3http://www.cs.ucsb.edu/˜xyan/software/ gSpan.htm,http://www.kyb.mpg.de/bs/people/ nowozin/gboost/ tures and evolves complex features from them. The advantage of the genetic programing based approach over feature subsumption is that it allows us to evaluate a feature using multiple criteria. We show that this approach performs better than feature subsumption. A lot of work has considered this genetic programming problem (Smith and Bull, 2005). The most similar approaches to ours are taken by Krawiec (2002) and Otero et al. (2002), both of which use genetic programming to build tree feature representations. None of this work was applied to a language processing task, though there has been some similar work to ours in that community, most notably (Hirsch et al., 2007), which built search queries for topic classification of documents. Our prior work (Mayfield and Ros´e, 2010) introduced a new feature construction method and was effective when using unigram features; here we extend our approach to feature spaces which are even larger and thus more problematic. The Genetic Programming (GP) paradigm is most advantageous whe</context>
<context position="18868" citStr="Otero et al. (2002)" startWordPosition="3056" endWordPosition="3059">re a total of 15 times (using different seeds for random selection of features), producing a total of 30 new features to be added to the feature space. 4For genetic programming we used the ECJ toolkit (http://cs.gmu.edu/˜eclab/projects/ecj/). Fβ(I) = (1 + β2) × (Prec(I) RRec(I )) (3) (β2 × Prec(I)) () In addition to this fitness function, we add two penalties to the equation. The first penalty applies to prevent trees from becoming overly complex. One option to ensure that features remain moderately simple is to simply have a maximum depth beyond which trees cannot grow. Following the work of Otero et al. (2002), we penalize trees based on the number of nodes they contain. This discourages bloat, i.e. sections of trees which do not contribute to overall accuracy. This penalty, known as parsimony pressure, is labeled PP in our fitness function. The second penalty is based on the correlation between the feature being constructed, and the subgraphs and unigrams which appear as nodes within that individual. Without this penalty, a feature may 5Negative precision and recall are defined identically, with obvious adjustments to test for negative documents instead of positive. 135 often be redundant, taking </context>
</contexts>
<marker>Otero, Silva, Freitas, Nievola, 2002</marker>
<rawString>Fernando Otero, Monique Silva, Alex Freitas and Julio Nievola. 2002. Genetic Programming for Attribute Construction in Data Mining. Proceedings of the Genetic and Evolutionary Computation Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment Classication using Machine Learning Techniques.</title>
<date>2002</date>
<booktitle>Proceedings of EMNLP.</booktitle>
<contexts>
<context position="7784" citStr="Pang et al. (2002)" startWordPosition="1220" endWordPosition="1223"> ‘good amod movie’, may be represented as a d amod relation between the head word ‘movie’ and its modifier ‘good’, or as a node d amod with edges ParentOfGov and ParentOfDep to the head and the modifier words. An example of an annotation graph is shown in Figure 1. The instance in Figure 1 describes a movie review comment, ‘interesting, but not compelling.’. The words ‘interesting’ and ‘compelling’ both have positive prior polarity, however, the phrase expresses negative sentiment towards the movie. Heuristics for special handling of negation have been proposed in the literature. For example, Pang et al. (2002) append every word following a negation, until a punctuation, with a ‘NOT’ . Applying a similar technique to our example gives us two sentiment bearing features, one positive (‘interesting’) and one negative (‘NOT-compelling’), and the model may not be as sure about the predicted label, since there is both 132 positive and negative sentiment present. In Figure 2, we show three discriminating subgraph features derived from the annotation graph in Figure 1. These subgraph features capture the negative sentiment in our example phrase. The first feature in 2(a) captures the pattern using dependenc</context>
<context position="24181" citStr="Pang et al., 2002" startWordPosition="3926" endWordPosition="3929">ntroducing many new and highly correlated features to our feature space through subgraphs, we believe that a stricter constraint must be placed on correlation between features. To accomplish this, we can set our correlation penalty cutoff to 0.3, lower than the 0.5 cutoff used in prior work. Results for both settings are reported. Baselines: To the best of our knowledge, there is no supervised machine learning result published on this dataset. We compare our results with the following baselines: • Unigram-only Baseline: In sentiment analysis, unigram-only features have been a strong baseline (Pang et al., 2002; Pang and Lee, 2004). We only use unigrams that occur in at least two sentences of the training data same as Matsumoto et al. (2005). We also filter out stop words using a small stop word list9. • x2 Baseline: For our training data, after filtering infrequent unigrams and stop words, we get 7http://svmlight.joachims.org/ 8Full movie review data by Pang et al. (2002) 9http://nlp.stanford.edu/ IR-book/html/htmledition/ dropping-common-terms-stop-words-1.html (with one modification: removed ‘will’, added ‘this’) 8424 features. Adding subgraph features increases the total number of features to 44</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment Classication using Machine Learning Techniques. Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts.</title>
<date>2004</date>
<booktitle>Proceedings of the main conference of ACL.</booktitle>
<contexts>
<context position="24202" citStr="Pang and Lee, 2004" startWordPosition="3930" endWordPosition="3933"> and highly correlated features to our feature space through subgraphs, we believe that a stricter constraint must be placed on correlation between features. To accomplish this, we can set our correlation penalty cutoff to 0.3, lower than the 0.5 cutoff used in prior work. Results for both settings are reported. Baselines: To the best of our knowledge, there is no supervised machine learning result published on this dataset. We compare our results with the following baselines: • Unigram-only Baseline: In sentiment analysis, unigram-only features have been a strong baseline (Pang et al., 2002; Pang and Lee, 2004). We only use unigrams that occur in at least two sentences of the training data same as Matsumoto et al. (2005). We also filter out stop words using a small stop word list9. • x2 Baseline: For our training data, after filtering infrequent unigrams and stop words, we get 7http://svmlight.joachims.org/ 8Full movie review data by Pang et al. (2002) 9http://nlp.stanford.edu/ IR-book/html/htmledition/ dropping-common-terms-stop-words-1.html (with one modification: removed ‘will’, added ‘this’) 8424 features. Adding subgraph features increases the total number of features to 44,161, a factor of 5 i</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts. Proceedings of the main conference of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.</title>
<date>2005</date>
<booktitle>Proceedings of the main conference of ACL.</booktitle>
<contexts>
<context position="20277" citStr="Pang and Lee, 2005" startWordPosition="3293" endWordPosition="3296">µX)(Y − µY )] QXQY This results in a value from 1 (for perfect alignment) to -1 (for inverse alignment). We assign a penalty for any correlation past a cutoff. This function is labeled CC (correlation constraint) in our fitness function. Our fitness function therefore is: Fitness = F1 8 + PP + CC (5) 6 Experiments and Results We evaluate our approach on a sentiment classification task, where the goal is to classify a movie review sentence as expressing positive or negative sentiment towards the movie. 6.1 Data and Experimental Setup Data: The dataset consists of snippets from Rotten Tomatoes (Pang and Lee, 2005) 6. It consists of 10662 snippets/sentences total with equal number positive and negative sentences (5331 each). This dataset was created and used by Pang and Lee (2005) to train a classifier for identifying positive sentences in a full length review. We use the first 8000 (4000 positive, 4000 negative) sentences as training data and evaluate on remaining 2662 (1331 positive, 1331 negative) sentences. We added part of speech and dependency triple annotations to this data using the Stanford parser (Klein and Manning, 2003). Annotation Graph: For the annotation graph representation, we used Unig</context>
</contexts>
<marker>Pang, Lee, 2005</marker>
<rawString>Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. Proceedings of the main conference of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian Pei</author>
<author>Jiawei Han</author>
<author>Behzad Mortazavi-asl</author>
<author>Jianyong Wang</author>
<author>Helen Pinto</author>
</authors>
<title>Qiming Chen, Umeshwar Dayal and Mei-chun Hsu.</title>
<date>2004</date>
<booktitle>Proceedings of IEEE Transactions on Knowledge and Data Engineering.</booktitle>
<contexts>
<context position="4657" citStr="Pei et al., 2004" startWordPosition="712" endWordPosition="715">rom dependency parse tree as features for predicting the intensity of opinion phrases1. Structured features that capture linguistic patterns are often hand crafted by domain experts (Wilson et al., 2005) after careful examination of the data. Thus, they do not always generalize well across datasets and domains. This also requires a significant amount of time and resources. By automatically deriving structured features, we might be able to learn new annotations faster. Matsumoto et al. (2005) propose an approach that uses frequent sub-sequence and sub-tree mining approaches (Asai et al., 2002; Pei et al., 2004) to derive structured features such as word sub-sequences and dependency sub-trees. They show that these features outperform bag-of-words features for a sentiment classification task and achieve the best performance to date on a commonly-used movie review dataset. Their approach presents an automatic procedure for deriving features that capture long distance dependencies without much expert intervention. However, their approach is limited to sequences or tree annotations. Often, features that combine several annotations capture interesting characteristics of text. For example, Wilson et al. (2</context>
</contexts>
<marker>Pei, Han, Mortazavi-asl, Wang, Pinto, 2004</marker>
<rawString>Jian Pei, Jiawei Han, Behzad Mortazavi-asl, Jianyong Wang, Helen Pinto, Qiming Chen, Umeshwar Dayal and Mei-chun Hsu. 2004. Mining Sequential Patterns by Pattern-Growth: The PrefixSpan Approach. Proceedings of IEEE Transactions on Knowledge and Data Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Siddharth Patwardhan</author>
<author>Janyce Wiebe</author>
</authors>
<title>Feature Subsumption for Opinion Analysis.</title>
<date>2006</date>
<booktitle>Proceedings of the EMNLP.</booktitle>
<contexts>
<context position="13184" citStr="Riloff et al. (2006)" startWordPosition="2098" endWordPosition="2101">e use gSpan to mine frequent subgraphs from the annotation graph. 5 Feature Construction using Genetic Programming A challenge to overcome when adding expressiveness to the feature space for any text classification problem is the rapid increase in the feature space size. Among this large set of new features, most are not predictive or are very weak predictors, and only a few carry novel information that improves classification performance. Because of this, adding more complex features often gives no improvement or even worsens performance as the feature space’s signal is drowned out by noise. Riloff et al. (2006) propose a feature subsumption approach to address this issue. They define a hierarchy for features based on the information they represent. A complex feature is only added if its discriminative power is a delta above the discriminative power of all its simpler forms. In this work, we use a Genetic Programming (Koza, 1992) based approach which evaluates interactions between fea3http://www.cs.ucsb.edu/˜xyan/software/ gSpan.htm,http://www.kyb.mpg.de/bs/people/ nowozin/gboost/ tures and evolves complex features from them. The advantage of the genetic programing based approach over feature subsump</context>
<context position="25294" citStr="Riloff et al. (2006)" startWordPosition="4106" endWordPosition="4109"> ‘will’, added ‘this’) 8424 features. Adding subgraph features increases the total number of features to 44,161, a factor of 5 increase in size. Feature selection can be used to reduce this size by selecting the most discriminative features. x2 feature selection (Manning et al., 2008) is commonly used in the literature. We compare two methods of feature selection with x2, one which rejects features if their x2 score is not significant at the 0.05 level, and one that reduces the number of features to match the size of our feature space with GP. • Feature Subsumption (FS): Following the idea in Riloff et al. (2006), a complex feature C is discarded if IG(S) ≥ IG(C) − 6, where IG is Information Gain and S is a simple feature that representationally subsumes C, i.e. the text spans that match S are a superset of the text spans that match C. In our work, complex features are subgraph features and simple features are unigram features contained in them. For example, (D amod) Edge ParentOfDep (U bad) is a complex feature for which U bad is a simple feature. We tried same values for 6 E {0.002, 0.001, 0.0005}, as suggested in Riloff et al. (2006). Since all values gave us same number of features, we only report</context>
</contexts>
<marker>Riloff, Patwardhan, Wiebe, 2006</marker>
<rawString>Ellen Riloff, Siddharth Patwardhan and Janyce Wiebe. 2006. Feature Subsumption for Opinion Analysis. Proceedings of the EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Smith</author>
<author>Larry Bull</author>
</authors>
<title>Genetic Programming with a Genetic Algorithm for Feature Construction and Selection. Genetic Programming and Evolvable Machines.</title>
<date>2005</date>
<contexts>
<context position="14010" citStr="Smith and Bull, 2005" startWordPosition="2220" endWordPosition="2223"> delta above the discriminative power of all its simpler forms. In this work, we use a Genetic Programming (Koza, 1992) based approach which evaluates interactions between fea3http://www.cs.ucsb.edu/˜xyan/software/ gSpan.htm,http://www.kyb.mpg.de/bs/people/ nowozin/gboost/ tures and evolves complex features from them. The advantage of the genetic programing based approach over feature subsumption is that it allows us to evaluate a feature using multiple criteria. We show that this approach performs better than feature subsumption. A lot of work has considered this genetic programming problem (Smith and Bull, 2005). The most similar approaches to ours are taken by Krawiec (2002) and Otero et al. (2002), both of which use genetic programming to build tree feature representations. None of this work was applied to a language processing task, though there has been some similar work to ours in that community, most notably (Hirsch et al., 2007), which built search queries for topic classification of documents. Our prior work (Mayfield and Ros´e, 2010) introduced a new feature construction method and was effective when using unigram features; here we extend our approach to feature spaces which are even larger </context>
</contexts>
<marker>Smith, Bull, 2005</marker>
<rawString>Matthew Smith and Larry Bull. 2005. Genetic Programming with a Genetic Algorithm for Feature Construction and Selection. Genetic Programming and Evolvable Machines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Rebecca Hwa</author>
</authors>
<title>Just How Mad Are You? Finding Strong and Weak Opinion Clauses.</title>
<date>2004</date>
<booktitle>Proceedings of AAAI.</booktitle>
<contexts>
<context position="1369" citStr="Wilson et al., 2004" startWordPosition="199" endWordPosition="202">predictors from these subgraphs. We evaluate the benefit gained from evolved structured features, when used in addition to the bag-of-words features, for a sentiment classification task. 1 Introduction In recent years, the topic of sentiment analysis has been one of the more popular directions in the field of language technologies. Recent work in supervised sentiment analysis has focused on innovative approaches to feature creation, with the greatest improvements in performance with features that insightfully capture the essence of the linguistic constructions used to express sentiment, e.g. (Wilson et al., 2004), (Joshi and Ros´e, 2009) In this spirit, we present a novel approach that leverages subgraphs automatically extracted from linguistic annotation graphs using efficient subgraph mining algorithms (Yan and Han, 2002). The difficulty with automatically deriving complex features comes with the increased feature space size. Many of these features are highly correlated and do not 131 provide any new information to the model. For example, a feature of type unigram POS (e.g. “camera NN”) doesn’t provide any additional information beyond the unigram feature (e.g. “camera”), for words that are often us</context>
<context position="4010" citStr="Wilson et al. (2004)" startWordPosition="609" endWordPosition="612">Analysis and Generation of Emotion in Text, pages 131–139, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics the bag of words approach. Arora et al. (2009) show that deep syntactic scope features constructed from transitive closure of dependency relations give significant improvement for identifying types of claims in product reviews. Gamon (2004) found that using deep linguistic features derived from phrase structure trees and part of speech annotations yields significant improvements on the task of predicting satisfaction ratings in customer feedback data. Wilson et al. (2004) use syntactic clues derived from dependency parse tree as features for predicting the intensity of opinion phrases1. Structured features that capture linguistic patterns are often hand crafted by domain experts (Wilson et al., 2005) after careful examination of the data. Thus, they do not always generalize well across datasets and domains. This also requires a significant amount of time and resources. By automatically deriving structured features, we might be able to learn new annotations faster. Matsumoto et al. (2005) propose an approach that uses frequent sub-sequence and sub-tree mining a</context>
<context position="5261" citStr="Wilson et al. (2004)" startWordPosition="796" endWordPosition="799">ei et al., 2004) to derive structured features such as word sub-sequences and dependency sub-trees. They show that these features outperform bag-of-words features for a sentiment classification task and achieve the best performance to date on a commonly-used movie review dataset. Their approach presents an automatic procedure for deriving features that capture long distance dependencies without much expert intervention. However, their approach is limited to sequences or tree annotations. Often, features that combine several annotations capture interesting characteristics of text. For example, Wilson et al. (2004), Gamon (2004) and Joshi and Ros´e (2009) show that a combination of dependency relations and part of speech annotations boosts performance. The annotation graph representation proposed by Arora and Nyberg (2009) is a formalism for representing several linguistic annotations together on text. With an annotation graph representation, instances are represented as graphs from which frequent subgraph patterns may be extracted and used as features for learning new annotations. 1Although, in this work we are classifying sentences and not phrases, similar clues may be used for sentiment classificatio</context>
</contexts>
<marker>Wilson, Wiebe, Hwa, 2004</marker>
<rawString>Theresa Wilson, Janyce Wiebe and Rebecca Hwa. 2004. Just How Mad Are You? Finding Strong and Weak Opinion Clauses. Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis.</title>
<date>2005</date>
<booktitle>Proceedings of HLT/EMNLP.</booktitle>
<contexts>
<context position="4243" citStr="Wilson et al., 2005" startWordPosition="645" endWordPosition="648">nstructed from transitive closure of dependency relations give significant improvement for identifying types of claims in product reviews. Gamon (2004) found that using deep linguistic features derived from phrase structure trees and part of speech annotations yields significant improvements on the task of predicting satisfaction ratings in customer feedback data. Wilson et al. (2004) use syntactic clues derived from dependency parse tree as features for predicting the intensity of opinion phrases1. Structured features that capture linguistic patterns are often hand crafted by domain experts (Wilson et al., 2005) after careful examination of the data. Thus, they do not always generalize well across datasets and domains. This also requires a significant amount of time and resources. By automatically deriving structured features, we might be able to learn new annotations faster. Matsumoto et al. (2005) propose an approach that uses frequent sub-sequence and sub-tree mining approaches (Asai et al., 2002; Pei et al., 2004) to derive structured features such as word sub-sequences and dependency sub-trees. They show that these features outperform bag-of-words features for a sentiment classification task and</context>
<context position="8970" citStr="Wilson et al. (2005)" startWordPosition="1420" endWordPosition="1423">ptures the pattern using dependency relations between words. A different review comment may use the same linguistic construction but with a different pair of words, for example “a pretty good, but not excellent story.” This is the same linguistic pattern but with different words the model may not have seen before, and hence may not classify this instance correctly. This suggests that the feature in 2(a) may be too specific. In order to mine general features that capture the rhetorical structure of language, we may add prior polarity annotations to the annotation graph, using a lexicon such as Wilson et al. (2005). Figure 2(b) shows the subgraph in 2(a) with polarity annotations. If we want to generalize the pattern in 2(a) to any positive words, we may use the feature subgraph in Figure 2(c) with X wild cards on words that are polar or negating. This feature subgraph captures the negative sentiment in both phrases ‘interesting, but not compelling.’ and “a pretty good, but not excellent story.”. Similar generalization using wild cards on words may be applied with other annotations such as part of speech annotations as well. By choosing where to put the wild card, we can get features similar to, but mor</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe and Paul Hoffmann. 2005. Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis. Proceedings of HLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xifeng Yan</author>
<author>Jiawei Han</author>
</authors>
<title>gSpan: GraphBased Substructure Pattern Mining.</title>
<date>2002</date>
<tech>UIUC Technical Report, UIUCDCS-R-2002-2296</tech>
<note>(shorter version in ICDM’02).</note>
<contexts>
<context position="1584" citStr="Yan and Han, 2002" startWordPosition="229" endWordPosition="232">, the topic of sentiment analysis has been one of the more popular directions in the field of language technologies. Recent work in supervised sentiment analysis has focused on innovative approaches to feature creation, with the greatest improvements in performance with features that insightfully capture the essence of the linguistic constructions used to express sentiment, e.g. (Wilson et al., 2004), (Joshi and Ros´e, 2009) In this spirit, we present a novel approach that leverages subgraphs automatically extracted from linguistic annotation graphs using efficient subgraph mining algorithms (Yan and Han, 2002). The difficulty with automatically deriving complex features comes with the increased feature space size. Many of these features are highly correlated and do not 131 provide any new information to the model. For example, a feature of type unigram POS (e.g. “camera NN”) doesn’t provide any additional information beyond the unigram feature (e.g. “camera”), for words that are often used with the same part of speech. However, alongside several redundant features, there are also features that provide new information. It is these features that we aim to capture. In this work, we propose an evolutio</context>
<context position="5980" citStr="Yan and Han, 2002" startWordPosition="908" endWordPosition="911"> speech annotations boosts performance. The annotation graph representation proposed by Arora and Nyberg (2009) is a formalism for representing several linguistic annotations together on text. With an annotation graph representation, instances are represented as graphs from which frequent subgraph patterns may be extracted and used as features for learning new annotations. 1Although, in this work we are classifying sentences and not phrases, similar clues may be used for sentiment classification in sentences as well In this work, we use an efficient frequent subgraph mining algorithm (gSpan) (Yan and Han, 2002) to extract frequent subgraphs from a linguistic annotation graph (Arora and Nyberg, 2009). An annotation graph is a general representation for arbitrary linguistic annotations. The annotation graph and subgraph mining algorithm provide us a quick way to test several alternative linguistic representations of text. In the next section, we present a formal definition of the annotation graph and a motivating example for subgraph features. 3 Annotation Graph Representation and Feature Subgraphs Arora and Nyberg (2009) define the annotation graph as a quadruple: G = (N, E, E, A), where N is the set</context>
<context position="11573" citStr="Yan and Han, 2002" startWordPosition="1839" endWordPosition="1842">phism test, which is NPcomplete. Although efficient isomorphism testing algorithms have been developed making it practical to use, with lots of candidate subgraphs to test, it can 2http://en.wikipedia.org/wiki/Subgraph_ isomorphism_problem polQ posQ P_VBN L_POSITIVE D_conj-but L_POSITIVE U_interesting U_, posQ P_, posQ P_CC U_but posQ P_RB U_not D_neg U_compelling P_JJ posQ polQ posQ P_. U . (a) U_interesting U_not D_neg U_compelling polQ L_POSITIVE D_conj-but L_POSITIVE X X D_neg X polQ polQ U_interesting U_not D_neg U_compelling polQ 133 still be very expensive for real applications. gSpan (Yan and Han, 2002) uses an alternative pattern growth based approach to frequent subgraph mining, which extends graphs from a single subgraph directly, without candidate generation. For each discovered subgraph G, new edges are added recursively until all frequent supergraphs of G have been discovered. gSpan uses a depth first search tree (DFS) and restricts edge extension to only vertices on the rightmost path. However, there can be multiple DFS trees for a graph. gSpan introduces a set of rules to select one of them as representative. Each graph is represented by its unique canonical DFS code, and the codes f</context>
</contexts>
<marker>Yan, Han, 2002</marker>
<rawString>Xifeng Yan and Jiawei Han. 2002. gSpan: GraphBased Substructure Pattern Mining. UIUC Technical Report, UIUCDCS-R-2002-2296 (shorter version in ICDM’02).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>