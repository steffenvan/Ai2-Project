<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000122">
<title confidence="0.992519">
Preemptive Information Extraction using Unrestricted Relation Discovery
</title>
<author confidence="0.842294">
Yusuke Shinyama Satoshi Sekine
</author>
<affiliation confidence="0.735806">
New York University
</affiliation>
<address confidence="0.976958">
715, Broadway, 7th Floor
New York, NY, 10003
</address>
<email confidence="0.999431">
{yusuke,sekine}@cs.nyu.edu
</email>
<sectionHeader confidence="0.993912" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999874230769231">
We are trying to extend the boundary of
Information Extraction (IE) systems. Ex-
isting IE systems require a lot of time and
human effort to tune for a new scenario.
Preemptive Information Extraction is an
attempt to automatically create all feasible
IE systems in advance without human in-
tervention. We propose a technique called
Unrestricted Relation Discovery that dis-
covers all possible relations from texts and
presents them as tables. We present a pre-
liminary system that obtains reasonably
good results.
</bodyText>
<sectionHeader confidence="0.989926" genericHeader="keywords">
1 Background
</sectionHeader>
<bodyText confidence="0.999931796296296">
Every day, a large number of news articles are cre-
ated and reported, many of which are unique. But
certain types of events, such as hurricanes or mur-
ders, are reported again and again throughout a year.
The goal of Information Extraction, or IE, is to re-
trieve a certain type of news event from past articles
and present the events as a table whose columns are
filled with a name of a person or company, accord-
ing to its role in the event. However, existing IE
techniques require a lot of human labor. First, you
have to specify the type of information you want and
collect articles that include this information. Then,
you have to analyze the articles and manually craft
a set of patterns to capture these events. Most exist-
ing IE research focuses on reducing this burden by
helping people create such patterns. But each time
you want to extract a different kind of information,
you need to repeat the whole process: specify arti-
cles and adjust its patterns, either manually or semi-
automatically. There is a bit of a dangerous pitfall
here. First, it is hard to estimate how good the sys-
tem can be after months of work. Furthermore, you
might not know if the task is even doable in the first
place. Knowing what kind of information is easily
obtained in advance would help reduce this risk.
An IE task can be defined as finding a relation
among several entities involved in a certain type of
event. For example, in the MUC-6 management
succession scenario, one seeks a relation between
COMPANY, PERSON and POST involved with hir-
ing/firing events. For each row of an extracted ta-
ble, you can always read it as “COMPANY hired
(or fired) PERSON for POST.” The relation between
these entities is retained throughout the table. There
are many existing works on obtaining extraction pat-
terns for pre-defined relations (Riloff, 1996; Yangar-
ber et al., 2000; Agichtein and Gravano, 2000; Sudo
et al., 2003).
Unrestricted Relation Discovery is a technique to
automatically discover such relations that repeatedly
appear in a corpus and present them as a table, with
absolutely no human intervention. Unlike most ex-
isting IE research, a user does not specify the type
of articles or information wanted. Instead, a system
tries to find all the kinds of relations that are reported
multiple times and can be reported in tabular form.
This technique will open up the possibility of try-
ing new IE scenarios. Furthermore, the system itself
can be used as an IE system, since an obtained re-
lation is already presented as a table. If this system
works to a certain extent, tuning an IE system be-
comes a search problem: all the tables are already
built “preemptively.” A user only needs to search
for a relevant table.
</bodyText>
<page confidence="0.985786">
304
</page>
<note confidence="0.992871666666667">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 304–311,
New York, June 2006. c�2006 Association for Computational Linguistics
Article dump be-hit
2005 -09 -23 Katrina New Orleans
2005 -10 -02 Longwang Taiwan
2005 -11 -20 Gamma Florida
</note>
<keyword confidence="0.62255">
Keywords: storm, evacuate, coast, rain, hurricane
</keyword>
<tableCaption confidence="0.99804">
Table 1: Sample discovered relation.
</tableCaption>
<bodyText confidence="0.999849125">
We implemented a preliminary system for this
technique and obtained reasonably good perfor-
mance. Table 1 is a sample relation that was ex-
tracted as a table by our system. The columns of the
table show article dates, names of hurricanes and the
places they affected respectively. The headers of the
table and its keywords were also extracted automat-
ically.
</bodyText>
<sectionHeader confidence="0.982089" genericHeader="introduction">
2 Basic Idea
</sectionHeader>
<bodyText confidence="0.959843838709677">
In Unrestricted Relation Discovery, the discovery
process (i.e. creating new tables) can be formulated
as a clustering task. The key idea is to cluster a set
of articles that contain entities bearing a similar rela-
tion to each other in such a way that we can construct
a table where the entities that play the same role are
placed in the same column.
Suppose that there are two articles A and B,
and both report hurricane-related news. Article A
contains two entities “Katrina” and “New Orleans”,
and article B contains “Longwang” and “Taiwan”.
These entities are recognized by a Named Entity
(NE) tagger. We want to discover a relation among
them. First, we introduce a notion called “basic
pattern” to form a relation. A basic pattern is a
part of the text that is syntactically connected to
an entity. Some examples are “X is hit” or “Y’s
residents”. Figure 1 shows several basic patterns
connected to the entities “Katrina” and “New Or-
leans” in article A. Similarly, we obtain the basic
patterns for article B. Now, in Figure 2, both enti-
ties “Katrina” and “Longwang” have the basic pat-
tern “headed” in common. In this case, we connect
these two entities to each other. Furthermore, there
is also a common basic pattern “was-hit” shared by
“New Orleans” and “Taiwan”. Now, we found two
sets of entities that can be placed in correspondence
at the same time. What does this mean? We can infer
that both entity sets (“Katrina”-“New Orleans” and
“Longwang”-“Taiwan”) represent a certain relation
that has something in common: a hurricane name
</bodyText>
<figureCaption confidence="0.99699">
Figure 1: Obtaining basic patterns.
</figureCaption>
<figure confidence="0.668139">
article A Katrina New Orleans
article B Longwang Taiwan
</figure>
<figureCaption confidence="0.99623">
Figure 2: Finding a similar relation from two articles.
</figureCaption>
<bodyText confidence="0.9995475">
and the place it affected. By finding multiple par-
allel correspondences between two articles, we can
estimate the similarity of their relations.
Generally, in a clustering task, one groups items
by finding similar pairs. After finding a pair of arti-
cles that have a similar relation, we can bring them
into the same cluster. In this case, we cluster articles
by using their basic patterns as features. However,
each basic pattern is still connected to its entity so
that we can extract the name from it. We can con-
sider a basic pattern to represent something like the
“role” of its entity. In this example, the entities that
had “headed” as a basic pattern are hurricanes, and
the entities that had “was-hit” as a basic pattern are
the places it affected. By using basic patterns, we
can align the entities into the corresponding column
that represents a certain role in the relation. From
this example, we create a two-by-two table, where
each column represents the roles of the entities, and
each row represents a different article, as shown in
the bottom of Figure 2.
We can extend this table by finding another article
</bodyText>
<figure confidence="0.997274125">
1. 2.
. . . Katrina . . . New Orleans . . .
headed
threatened
is-category-5
...
was-hit
has-been-evacuated
-residents
...
article A
Basic patterns
for entity &amp;quot;New Orleans&amp;quot;
Basic patterns
for entity &amp;quot;Katrina&amp;quot;
article A
. . . Katrina . . . New Orleans . . .
1. 2.
headed
threatened
is-category-5
...
has-been-evacuated
-residents
...
was-hit
Common Pattern Common Pattern
&amp;quot;stroke&amp;quot; &amp;quot;was-hit&amp;quot;
article B
. . . Longwang . . . Taiwan . . .
1. 2.
hit
headed
swirling
’s-coast
was-pounded
was-hit
...
Obtained
Table
</figure>
<page confidence="0.99605">
305
</page>
<bodyText confidence="0.999990023809524">
in the same manner. In this way, we gradually extend
a table while retaining a relation among its columns.
In this example, the obtained table is just what an IE
system (whose task is to find a hurricane name and
the affected place) would create.
However, these articles might also include other
things, which could represent different relations. For
example, the governments might call for help or
some casualties might have been reported. To ob-
tain such relations, we need to choose different en-
tities from the articles. Several existing works have
tried to extract a certain type of relation by manu-
ally choosing different pairs of entities (Brin, 1998;
Ravichandran and Hovy, 2002). Hasegawa et al.
(2004) tried to extract multiple relations by choos-
ing entity types. We assume that we can find such
relations by trying all possible combinations from
a set of entities we have chosen in advance; some
combinations might represent a hurricane and gov-
ernment relation, and others might represent a place
and its casualties. To ensure that an article can have
several different relations, we let each article belong
to several different clusters.
In a real-world situation, only using basic patterns
sometimes gives undesired results. For example,
“(President) Bush flew to Texas” and “(Hurricane)
Katrina flew to New Orleans” both have a basic pat-
tern “flew to” in common, so “Bush” and “Kat-
rina” would be put into the same column. But we
want to separate them in different tables. To allevi-
ate this problem, we put an additional restriction on
clustering. We use a bag-of-words approach to dis-
criminate two articles: if the word-based similarity
between two articles is too small, we do not bring
them together into the same cluster (i.e. table). We
exclude names from the similarity calculation at this
stage because we want to link articles about the same
type of event, not the same instance. In addition, we
use the frequency of each basic pattern to compute
the similarity of relations, since basic patterns like
“say” or “have” appear in almost every article and it
is dangerous to rely on such expressions.
</bodyText>
<subsectionHeader confidence="0.892765">
Increasing Basic Patterns
</subsectionHeader>
<bodyText confidence="0.999988673076923">
In the above explanation, we have assumed that we
can obtain enough basic patterns from an article.
However, the actual number of basic patterns that
one can find from a single article is usually not
enough, because the number of sentences is rather
small in comparison to the variation of expressions.
So having two articles that have multiple basic pat-
terns in common is very unlikely. We extend the
number of articles for obtaining basic patterns by
using a cluster of comparable articles that report the
same event instead of a single article. We call this
cluster of articles a “basic cluster.” Using basic clus-
ters instead of single articles also helps to increase
the redundancy of data. We can give more confi-
dence to repeated basic patterns.
Note that the notion of “basic cluster” is different
from the clusters used for creating tables explained
above. In the following sections, a cluster for creat-
ing a table is called a “metacluster,” because this is
a cluster of basic clusters. A basic cluster consists
of a set of articles that report the same event which
happens at a certain time, and a metacluster consists
of a set of events that contain the same relation over
a certain period.
We try to increase the number of articles in a basic
cluster by looking at multiple news sources simulta-
neously. We use a clustering algorithm that uses a
vector-space-model to obtain basic clusters. Then
we apply cross-document coreference resolution to
connect entities of different articles within a basic
cluster. This way, we can increase the number of ba-
sic patterns connected to each entity. Also, it allows
us to give a weight to entities. We calculate their
weights using the number of occurrences within a
cluster and their position within an article. These
entities are used to obtain basic patterns later.
We also use a parser and tree normalizer to gen-
erate basic patterns. The format of basic patterns
is crucial to performance. We think a basic pat-
tern should be somewhat specific, since each pat-
tern should capture an entity with some relevant con-
text. But at the same time a basic pattern should
be general enough to reduce data sparseness. We
choose a predicate-argument structure as a natural
solution for this problem. Compared to traditional
constituent trees, a predicate-argument structure is
a higher-level representation of sentences that has
gained wide acceptance from the natural language
community recently. In this paper we used a logical
feature structure called GLARF proposed by Mey-
ers et al. (2001a). A GLARF converter takes a syn-
tactic tree as an input and augments it with several
</bodyText>
<page confidence="0.997178">
306
</page>
<figureCaption confidence="0.912573">
Figure 3: GLARF structure of the sentence “Katrina
hit Louisiana’s coast.”
</figureCaption>
<bodyText confidence="0.9997702">
features. Figure 3 shows a sample GLARF structure
obtained from the sentence “Katrina hit Louisiana’s
coast.” We used GLARF for two reasons: first,
unlike traditional constituent parsers, GLARF has
an ability to regularize several linguistic phenom-
ena such as participial constructions and coordina-
tion. This allows us to handle this syntactic variety
in a uniform way. Second, an output structure can
be easily converted into a directed graph that rep-
resents the relationship between each word, without
losing significant information from the original sen-
tence. Compared to an ordinary constituent tree, it is
easier to extract syntactic relationships. In the next
section, we discuss how we used this structure to
generate basic patterns.
</bodyText>
<sectionHeader confidence="0.998905" genericHeader="method">
3 Implementation
</sectionHeader>
<bodyText confidence="0.999992142857143">
The overall process to generate basic patterns and
discover relations from unannotated news articles is
shown in Figure 4. Theoretically this could be a
straight pipeline, but due to the nature of the im-
plementation we process some stages separately and
combine them in the later stage. In the following
subsection, we explain each component.
</bodyText>
<subsectionHeader confidence="0.999879">
3.1 Web Crawling and Basic Clustering
</subsectionHeader>
<bodyText confidence="0.9996835">
First of all, we need a lot of news articles from mul-
tiple news sources. We created a simple web crawler
that extract the main texts from web pages. We ob-
served that the crawler can correctly take the main
texts from about 90% of the pages from each news
site. We ran the crawler every day on several news
sites. Then we applied a simple clustering algorithm
to the obtained articles in order to find a set of arti-
</bodyText>
<figureCaption confidence="0.99948">
Figure 4: System overview.
</figureCaption>
<bodyText confidence="0.9965216">
cles that talk about exactly the same news and form
a basic cluster.
We eliminate stop words and stem all the other
words, then compute the similarity between two ar-
ticles by using a bag-of-words approach. In news
articles, a sentence that appears in the beginning of
an article is usually more important than the others.
So we preserved the word order to take into account
the location of each sentence. First we computed a
word vector from each article:
</bodyText>
<equation confidence="0.979964333333333">
�
Vw(A) = IDF(w)
s∈POS(w,A)
</equation>
<bodyText confidence="0.9999295">
where Vw(A) is a vector element of word w in article
A, IDF(w) is the inverse document frequency of
word w, and POS(w, A) is a list of w’s positions
in the article. avgwords is the average number of
words for all articles. Then we calculated the cosine
value of each pair of vectors:
</bodyText>
<equation confidence="0.556378">
Sim(A1, A2) = cos(V (A1) · V (A2))
</equation>
<bodyText confidence="0.997002">
We computed the similarity of all possible pairs of
articles from the same day, and selected the pairs
</bodyText>
<figure confidence="0.996042206896552">
’s
SUFFIX
Louisiana
T-POS
Katrina
coast
SBJ OBJ
hit
...
Newspapers
...
Basic
Clusters
Web
Crawling
Basic
Clustering
Coreference
Resolution
Parsing
GLARFing
Basic Pattern
Generation
Basic Patterns
Metaclustering
Metaclusters
(Tables)
i
exp(− avgwords)
</figure>
<page confidence="0.992005">
307
</page>
<bodyText confidence="0.9998795">
whose similarity exceeded a certain threshold (0.65
in this experiment) to form a basic cluster.
</bodyText>
<subsectionHeader confidence="0.999555">
3.2 Parsing and GLARFing
</subsectionHeader>
<bodyText confidence="0.99995625">
After getting a set of basic clusters, we pass them
to an existing statistical parser (Charniak, 2000) and
rule-based tree normalizer to obtain a GLARF struc-
ture for each sentence in every article. The current
implementation of a GLARF converter gives about
75% F-score using parser output. For the details of
GLARF representation and its conversion, see Mey-
ers et al. (2001b).
</bodyText>
<subsectionHeader confidence="0.998659">
3.3 NE Tagging and Coreference Resolution
</subsectionHeader>
<bodyText confidence="0.999868363636364">
In parallel with parsing and GLARFing, we also ap-
ply NE tagging and coreference resolution for each
article in a basic cluster. We used an HMM-based
NE tagger whose performance is about 85% in F-
score. This NE tagger produces ACE-type Named
Entities 1: PERSON, ORGANIZATION, GPE, LO-
CATION and FACILITY 2. After applying single-
document coreference resolution for each article, we
connect the entities among different articles in the
same basic cluster to obtain cross-document coref-
erence entities with simple string matching.
</bodyText>
<subsectionHeader confidence="0.988526">
3.4 Basic Pattern Generation
</subsectionHeader>
<bodyText confidence="0.999956111111111">
After getting a GLARF structure for each sentence
and a set of documents whose entities are tagged
and connected to each other, we merge the two out-
puts and create a big network of GLARF structures
whose nodes are interconnected across different sen-
tences/articles. Now we can generate basic patterns
for each entity. First, we compute the weight for
each cross-document entity E in a certain basic clus-
ter as follows:
</bodyText>
<equation confidence="0.9858855">
�WE = mentions(e) · exp(−C · firstsent(e))
e∈E
</equation>
<bodyText confidence="0.999817333333333">
where e ∈ E is an entity within one article and
mentions(e) and firstsent(e) are the number of
mentions of entity e in a document and the position
</bodyText>
<footnote confidence="0.9962166">
1The ACE task description can be found at
http://www.itl.nist.gov/iad/894.01/tests/ace/ and the ACE
guidelines at http://www.ldc.upenn.edu/Projects/ACE/
2The hurricane names used in the examples were recognized
as PERSON.
</footnote>
<figureCaption confidence="0.969397">
Figure 5: Basic patterns obtained from the sentence
“Katrina hit Louisiana’s coast.”
</figureCaption>
<bodyText confidence="0.999842588235294">
of the sentence where entity e first appeared, respec-
tively. C is a constant value which was 0.5 in this ex-
periment. To reduce combinatorial complexity, we
took only the five most highly weighted entities from
each basic cluster to generate basic patterns. We ob-
served these five entities can cover major relations
that are reported in a basic cluster.
Next, we obtain basic patterns from the GLARF
structures. We used only the first ten sentences
in each article for getting basic patterns, as most
important facts are usually written in the first few
sentences of a news article. Figure 5 shows all
the basic patterns obtained from the sentence “Ka-
trina hit Louisiana’s coast.” The shaded nodes
“Katrina” and “Louisiana” are entities from which
each basic pattern originates. We take a path
of GLARF nodes from each entity node until it
reaches any predicative node: noun, verb, or ad-
jective in this case. Since the nodes “hit” and
“coast” can be predicates in this example, we ob-
tain three unique paths “Louisiana+T-POS:coast
(Louisiana’s coast)”, “Katrina+SBJ:hit (Katrina
hit something)”, and “Katrina+SBJ:hit-OBJ:coast
(Katrina hit some coast)”.
To increase the specificity of patterns, we generate
extra basic patterns by adding a node that is imme-
diately connected to a predicative node. (From this
example, we generate two basic patterns: “hit” and
“hit-coast” from the “Katrina” node.)
Notice that in a GLARF structure, the type
of each argument such as subject or object is
preserved in an edge even if we extract a sin-
gle path of a graph. Now, we replace both
entities “Katrina” and “Louisiana” with variables
</bodyText>
<figure confidence="0.997298636363636">
Õs
SUFFIX
Louisiana
T-POS
GPE+T-POS:coast
Katrina
coast
SBJ OBJ
PER+SBJ:hit-OBJ:coast
hit
PER+SBJ:hit
</figure>
<page confidence="0.995292">
308
</page>
<bodyText confidence="0.999421454545455">
based on their NE tags and obtain parameter-
ized patterns: “GPE+T-POS:coast (Louisiana’s
coast)”, “PER+SBJ:hit (Katrina hit something)”,
and “PER+SBJ:hit-OBJ:coast (Katrina hit some
coast)”.
After taking all the basic patterns from every basic
cluster, we compute the Inverse Cluster Frequency
(ICF) of each unique basic pattern. ICF is similar
to the Inverse Document Frequency (IDF) of words,
which is used to calculate the weight of each basic
pattern for metaclustering.
</bodyText>
<subsectionHeader confidence="0.98855">
3.5 Metaclustering
</subsectionHeader>
<bodyText confidence="0.999962666666667">
Finally, we can perform metaclustering to obtain ta-
bles. We compute the similarity between each basic
cluster pair, as seen in Figure 6. XA and XB are
the set of cross-document entities from basic clusters
cA and cB, respectively. We examine all possible
mappings of relations (parallel mappings of multi-
ple entities) from both basic clusters, and find all the
mappings M whose similarity score exceeds a cer-
tain threshold. wordsim(cA, cB) is the bag-of-words
similarity of two clusters. As a weighting function
we used ICF:
We then sort the similarities of all possible pairs
of basic clusters, and try to build a metacluster by
taking the most strongly connected pair first. Note
that in this process we may assign one basic clus-
ter to several different metaclusters. When a link is
found between two basic clusters that were already
assigned to a metacluster, we try to put them into
all the existing metaclusters it belongs to. However,
we allow a basic cluster to be added only if it can
fill all the columns in that table. In other words, the
first two basic clusters (i.e. an initial two-row table)
determines its columns and therefore define the re-
lation of that table.
</bodyText>
<sectionHeader confidence="0.985941" genericHeader="evaluation">
4 Experiment and Evaluation
</sectionHeader>
<bodyText confidence="0.9219512">
We used twelve newspapers published mainly in the
U.S. We collected their articles over two months
(from Sep. 21, 2005 - Nov. 27, 2005). We obtained
643,767 basic patterns and 7,990 unique types. Then
we applied metaclustering to these basic clusters
</bodyText>
<table confidence="0.998370833333333">
Source articles 28,009
Basic clusters 5,543
Basic patterns (token) 643,767
Basic patterns (type) 7,990
Metaclusters 302
Metaclusters (rows ≥ 3) 101
</table>
<tableCaption confidence="0.99874">
Table 2: Articles and obtained metaclusters.
</tableCaption>
<bodyText confidence="0.999897">
and obtained 302 metaclusters (tables). We then re-
moved duplicated rows and took only the tables that
had 3 or more rows. Finally we had 101 tables. The
total number the of articles and clusters we used are
shown in Table 2.
</bodyText>
<subsectionHeader confidence="0.994153">
4.1 Evaluation Method
</subsectionHeader>
<bodyText confidence="0.9999925">
We evaluated the obtained tables as follows. For
each row in a table, we added a summary of the
source articles that were used to extract the rela-
tion. Then for each table, an evaluator looks into
every row and its source article, and tries to come
up with a sentence that explains the relation among
its columns. The description should be as specific as
possible. If at least half of the rows can fit the ex-
planation, the table is considered “consistent.” For
each consistent table, the evaluator wrote down the
sentence using variable names ($1, $2, ...) to refer
to its columns. Finally, we counted the number of
consistent tables. We also counted how many rows
in each table can fit the explanation.
</bodyText>
<subsectionHeader confidence="0.681413">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.999977230769231">
We evaluated 48 randomly chosen tables. Among
these tables, we found that 36 tables were consis-
tent. We also counted the total number of rows that
fit each description, shown in Table 3. Table 4 shows
the descriptions of the selected tables. The largest
consistent table was about hurricanes (Table 5). Al-
though we cannot exactly measure the recall of each
table, we tried to estimate the recall by comparing
this hurricane table to a manually created one (Table
6). We found 6 out of 9 hurricanes 3. It is worth
noting that most of these hurricane names were au-
tomatically disambiguated although our NE tagger
didn’t distinguish a hurricane name from a person
</bodyText>
<footnote confidence="0.994443">
3Hurricane Katrina and Longwang shown in the previous
examples are not included in this table. They appeared before
this period.
</footnote>
<equation confidence="0.9897825">
weight(p) = −log(clusters that include p
all clusters )
</equation>
<page confidence="0.693318">
309
</page>
<equation confidence="0.967705375">
for each cluster pair (cA, cB) {
XA = cA.entities
XB = cB.entities
for each entity mapping M = [(xA1, xB1), ..., (xA., xB.)] ∈ (21XAI × 2|XB|) {
for each entity pair (xAi, xBi) {
Pi = xAi.patterns ∩ xBi.patterns
pairscorei = Ep∈Pi weight(p)
mapscore = � pairscorei
</equation>
<figure confidence="0.684014">
}
if T1 &lt; |M |and T2 &lt; mapscore and T3 &lt; wordsim(cA.words, cB.words) {
link cA and cB with mapping M.
}
}
}
</figure>
<figureCaption confidence="0.998352">
Figure 6: Computing similarity of basic clusters.
</figureCaption>
<table confidence="0.897151625">
Tables:
Consistent tables 36 (75%)
Inconsistent tables 12
Total 48
Rows:
Rows that fit the description 118 (73%)
Rows not fitted 43
Total 161
</table>
<tableCaption confidence="0.993945">
Table 3: Evaluation results.
</tableCaption>
<table confidence="0.999494818181818">
Description Rows
Storm $1(PER) probably affected $2(GPE). 8/16
Nominee $2(PER) must be confirmed by $1(ORG). 4/7
$1(PER) urges $2(GPE) to make changes. 4/6
$1(GPE) launched an attack in $2(GPE). 3/5
$1(PER) ran against $2(PER) in an election. 4/5
$2(PER) visited $1(GPE) on a diplomatic mission. 2/4
$2(PER) beat $1(PER) in golf. 4/4
$2(GPE) soldier(s) were killed in $1(GPE). 3/3
$2(PER) ran for governor of $1(GPE). 2/3
Boxer $1(PER) fought boxer $2(PER). 3/3
</table>
<tableCaption confidence="0.988604">
Table 4: Description of obtained tables and the num-
</tableCaption>
<bodyText confidence="0.985998">
ber of fitted/total rows.
name. The second largest table (about nominations
of officials) is shown in Table 7.
We reviewed 10 incorrect rows from various ta-
bles and found 4 of them were due to coreference er-
rors and one error was due to a parse error. The other
4 errors were due to multiple basic patterns distant
from each other that happened to refer to a different
event reported in the same cluster. The causes of the
one remaining error was obscure. Most inconsistent
tables were a mixture of multiple relations and some
of their rows still looked consistent.
We have a couple of open questions. First, the
overall recall of our system might be lower than ex-
isting IE systems, as we are relying on a cluster of
comparable articles rather than a single document to
discover an event. We might be able to improve this
in the future by adjusting the basic clustering algo-
rithm or weighting schema of basic patterns. Sec-
ondly, some combinations of basic patterns looked
inherently vague. For example, we used the two ba-
sic patterns “pitched” and “’s-series” in the fol-
lowing sentence (the patterns are underlined):
Ervin Santana pitched 5 1-3 gutsy innings in his post-
season debut for the Angels, Adam Kennedy hit a go-
ahead triple that sent Yankees outfielders crashing to the
ground, and Los Angeles beat New York 5-3 Monday
night in the decisive Game 5 of their AL playoff series.
It is not clear whether this set of patterns can yield
any meaningful relation. We are not sure how much
this sort of table can affect overall IE performance.
</bodyText>
<sectionHeader confidence="0.998964" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.998529181818182">
In this paper we proposed Preemptive Information
Extraction as a new direction of IE research. As
its key technique, we presented Unrestricted Rela-
tion Discovery that tries to find parallel correspon-
dences between multiple entities in a document, and
perform clustering using basic patterns as features.
To increase the number of basic patterns, we used
a cluster of comparable articles instead of a single
document. We presented the implementation of our
preliminary system and its outputs. We obtained
dozens of usable tables.
</bodyText>
<page confidence="0.997293">
310
</page>
<note confidence="0.777473294117647">
Article 1:dump 2:coast
2005-09-21 Rita Texas
2005-09-23 Rita New Orleans
2005-09-25 Bush Texas
2005-09-26 Damrey Hainan
2005-09-27 Damrey Vietnam
2005-10-01 Rita Louisiana
2005-10-02 Otis Mexico
2005-10-04 Longwang China
2005-10-05 Stan Mexico
2005-10-06 Tammy Florida
2005-10-07 Tammy Georgia
2005-10-19 Wilma Florida
2005-10-25 Wilma Cuba
2005-10-25 Wilma Massachusetts
2005-10-28 Beta Nicaragua
2005-11-20 Gamma Florida
</note>
<reference confidence="0.998994555555556">
1. More than 2,000 National Guard troops were put on
active-duty alert to assist as Rita slammed into the string
of islands and headed west, perhaps toward Texas....
2. Typhoon Damrey smashed into Vietnam on Tuesday af-
ter killing nine people in China,...
3. Oil markets have been watching Wilma’s progress ner-
vously, ... but the threat to energy interests appears to
have eased as forecasters predict the storm will turn to-
ward Florida....
</reference>
<tableCaption confidence="0.783747">
Table 5: Hurricane table (“Storm $1(PER) probably
affected $2(GPE).”) and the actual expressions we
used for extraction.
</tableCaption>
<table confidence="0.9989498">
Hurricane Date (Affected Place) Articles
Philippe Sep 17-20 (?) 6
* Rita Sep 17-26 (Louisiana, Texas, etc.) 566
* Stan Oct 1-5 (Mexico, Nicaragua, etc.) 83
* Tammy Oct 5-? (Georgia, Alabama) 18
Vince Oct 8-11 (Portugal, Spain) 12
* Wilma Oct 15-25 (Cuba, Honduras, etc.) 368
Alpha Oct 22-24 (Haiti, Dominican Rep.) 80
* Beta Oct 26-31 (Nicaragua, Honduras) 55
* Gamma Nov 13-20 (Belize, etc.) 36
</table>
<tableCaption confidence="0.964177">
Table 6: Hurricanes in North America between mid-
</tableCaption>
<bodyText confidence="0.91022325">
Sep. and Nov. (from Wikipedia). Rows with a
star (*) were actually extracted. The number of the
source articles that contained a mention of the hurri-
cane is shown in the right column.
</bodyText>
<table confidence="0.996020375">
Article 1:confirm 2:be-confirmed
2005 -09 -21 Senate Roberts
2005 -10 -03 Supreme Court Miers
2005 -10 -20 Senate Bush
2005 -10 -26 Senate Sauerbrey
2005 -10 -31 Senate Mr. Alito
2005 -11 -04 Senate Alito
2005 -11 -17 Fed Bernanke
</table>
<tableCaption confidence="0.960304">
Table 7: Nomination table (“Nominee $2(PER)
must be confirmed by $1(ORG).”)
</tableCaption>
<sectionHeader confidence="0.992956" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999585">
This research was supported by the National Science
Foundation under Grant IIS-00325657. This paper
does not necessarily reflect the position of the U.S.
Government. We would like to thank Prof. Ralph
Grishman who provided useful suggestions and dis-
cussions.
</bodyText>
<sectionHeader confidence="0.999171" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999688675">
Eugene Agichtein and L. Gravano. 2000. Snowball: Ex-
tracting Relations from Large Plaintext Collections. In
Proceedings of the 5th ACM International Conference
on Digital Libraries (DL-00).
Sergey Brin. 1998. Extracting Patterns and Relations
from the World Wide Web. In WebDB Workshop at
EDBT ’98.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of NAACL-2000.
Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman.
2004. Discovering relations among named entities
from large corpora. In Proceedings of the Annual
Meeting of Association of Computational Linguistics
(ACL-04).
Adam Meyers, Ralph Grishman, Michiko Kosaka, and
Shubin Zhao. 2001a. Covering Treebanks with
GLARF. In ACL/EACL Workshop on Sharing Tools
and Resources for Research and Education.
Adam Meyers, Michiko Kosaka, Satoshi Sekine, Ralph
Grishman, and Shubin Zhao. 2001b. Parsing and
GLARFing. In Proceedings of RANLP-2001, Tzigov
Chark, Bulgaria.
Deepak Ravichandran and Eduard Hovy. 2002. Learning
surface text patterns for a question answering system.
In Proceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics (ACL).
Ellen Riloff. 1996. Automatically Generating Extrac-
tion Patterns from Untagged Text. In Proceedings of
the 13th National Conference on Artificial Intelligence
(AAAI-96).
Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.
2003. An Improved Extraction Pattern Representa-
tion Model for Automatic IE Pattern Acquisition. In
Proceedings of the Annual Meeting of Association of
Computational Linguistics (ACL-03).
Roman Yangarber, Ralph Grishman, Pasi Tapanainen,
and Silja Huttunen. 2000. Unsupervised Discovery
of Scenario-Level Patterns for Information Extraction.
In Proceedings of the 18th International Conference
on Computational Linguistics (COLING-00).
</reference>
<page confidence="0.999006">
311
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999426">Preemptive Information Extraction using Unrestricted Relation Discovery</title>
<author confidence="0.821089">Yusuke Shinyama Satoshi Sekine</author>
<address confidence="0.72095">New York 715, Broadway, 7th</address>
<author confidence="0.489476">New York</author>
<author confidence="0.489476">NY</author>
<abstract confidence="0.988648356164384">We are trying to extend the boundary of Information Extraction (IE) systems. Existing IE systems require a lot of time and human effort to tune for a new scenario. Preemptive Information Extraction is an attempt to automatically create all feasible IE systems in advance without human intervention. We propose a technique called Unrestricted Relation Discovery that discovers all possible relations from texts and presents them as tables. We present a preliminary system that obtains reasonably good results. 1 Background Every day, a large number of news articles are created and reported, many of which are unique. But certain types of events, such as hurricanes or murders, are reported again and again throughout a year. The goal of Information Extraction, or IE, is to retrieve a certain type of news event from past articles and present the events as a table whose columns are filled with a name of a person or company, according to its role in the event. However, existing IE techniques require a lot of human labor. First, you have to specify the type of information you want and collect articles that include this information. Then, you have to analyze the articles and manually craft a set of patterns to capture these events. Most existing IE research focuses on reducing this burden by helping people create such patterns. But each time you want to extract a different kind of information, need to repeat the whole process: specify articles and adjust its patterns, either manually or semiautomatically. There is a bit of a dangerous pitfall here. First, it is hard to estimate how good the system can be after months of work. Furthermore, you might not know if the task is even doable in the first place. Knowing what kind of information is easily obtained in advance would help reduce this risk. An IE task can be defined as finding a relation among several entities involved in a certain type of event. For example, in the MUC-6 management succession scenario, one seeks a relation between COMPANY, PERSON and POST involved with hiring/firing events. For each row of an extracted table, you can always read it as “COMPANY hired (or fired) PERSON for POST.” The relation between these entities is retained throughout the table. There are many existing works on obtaining extraction patterns for pre-defined relations (Riloff, 1996; Yangarber et al., 2000; Agichtein and Gravano, 2000; Sudo et al., 2003). Unrestricted Relation Discovery is a technique to automatically discover such relations that repeatedly appear in a corpus and present them as a table, with absolutely no human intervention. Unlike most existing IE research, a user does not specify the type of articles or information wanted. Instead, a system tries to find all the kinds of relations that are reported multiple times and can be reported in tabular form. This technique will open up the possibility of trying new IE scenarios. Furthermore, the system itself can be used as an IE system, since an obtained relation is already presented as a table. If this system works to a certain extent, tuning an IE system becomes a search problem: all the tables are already built “preemptively.” A user only needs to search for a relevant table. 304 of the Human Language Technology Conference of the North American Chapter of the pages York, June 2006. Association for Computational Linguistics Article dump be-hit</abstract>
<address confidence="0.940087666666667">2005 -09 -23 Katrina New Orleans 2005 -10 -02 Longwang Taiwan 2005 -11 -20 Gamma Florida</address>
<keyword confidence="0.928102">Keywords: storm, evacuate, coast, rain, hurricane</keyword>
<abstract confidence="0.994335888888889">Table 1: Sample discovered relation. We implemented a preliminary system for this technique and obtained reasonably good performance. Table 1 is a sample relation that was extracted as a table by our system. The columns of the table show article dates, names of hurricanes and the places they affected respectively. The headers of the table and its keywords were also extracted automatically. 2 Basic Idea In Unrestricted Relation Discovery, the discovery process (i.e. creating new tables) can be formulated as a clustering task. The key idea is to cluster a set of articles that contain entities bearing a similar relation to each other in such a way that we can construct a table where the entities that play the same role are placed in the same column. that there are two articles both report hurricane-related news. Article contains two entities “Katrina” and “New Orleans”, article “Longwang” and “Taiwan”. These entities are recognized by a Named Entity (NE) tagger. We want to discover a relation among them. First, we introduce a notion called “basic pattern” to form a relation. A basic pattern is a part of the text that is syntactically connected to entity. Some examples are is or Figure 1 shows several basic patterns connected to the entities “Katrina” and “New Orin article Similarly, we obtain the basic for article Now, in Figure 2, both entities “Katrina” and “Longwang” have the basic patin common. In this case, we connect these two entities to each other. Furthermore, there also a common basic pattern shared by “New Orleans” and “Taiwan”. Now, we found two sets of entities that can be placed in correspondence at the same time. What does this mean? We can infer that both entity sets (“Katrina”-“New Orleans” and “Longwang”-“Taiwan”) represent a certain relation has something in common: hurricane name Figure 1: Obtaining basic patterns. article A Katrina New Orleans article B Longwang Taiwan 2: a similar relation from two articles. the place it By finding multiple parallel correspondences between two articles, we can estimate the similarity of their relations. Generally, in a clustering task, one groups items by finding similar pairs. After finding a pair of articles that have a similar relation, we can bring them into the same cluster. In this case, we cluster articles by using their basic patterns as features. However, each basic pattern is still connected to its entity so that we can extract the name from it. We can consider a basic pattern to represent something like the “role” of its entity. In this example, the entities that as a basic pattern are and entities that had as a basic pattern are places it By using basic patterns, we can align the entities into the corresponding column that represents a certain role in the relation. From this example, we create a two-by-two table, where each column represents the roles of the entities, and each row represents a different article, as shown in the bottom of Figure 2. We can extend this table by finding another article 1. 2. . . . . . New Orleans . . . headed threatened is-category-5 ... was-hit has-been-evacuated -residents ... article A Basic for entity &amp;quot;New Orleans&amp;quot; Basic patterns for entity &amp;quot;Katrina&amp;quot; article A . . . . . New Orleans . . . 1. 2. headed threatened is-category-5 ... has-been-evacuated -residents ... was-hit Common Pattern Common Pattern article B . . . . . Taiwan . . . 1. 2. hit headed swirling ’s-coast was-pounded was-hit ... Obtained Table 305 in the same manner. In this way, we gradually extend a table while retaining a relation among its columns. In this example, the obtained table is just what an IE system (whose task is to find a hurricane name and the affected place) would create. However, these articles might also include other things, which could represent different relations. For example, the governments might call for help or some casualties might have been reported. To obtain such relations, we need to choose different entities from the articles. Several existing works have tried to extract a certain type of relation by manually choosing different pairs of entities (Brin, 1998; Ravichandran and Hovy, 2002). Hasegawa et al. (2004) tried to extract multiple relations by choosing entity types. We assume that we can find such relations by trying all possible combinations from a set of entities we have chosen in advance; some combinations might represent a hurricane and government relation, and others might represent a place and its casualties. To ensure that an article can have several different relations, we let each article belong to several different clusters. In a real-world situation, only using basic patterns sometimes gives undesired results. For example, Bush flew to and flew to New both have a basic patin common, so “Bush” and “Katrina” would be put into the same column. But we want to separate them in different tables. To alleviate this problem, we put an additional restriction on clustering. We use a bag-of-words approach to discriminate two articles: if the word-based similarity between two articles is too small, we do not bring them together into the same cluster (i.e. table). We exclude names from the similarity calculation at this stage because we want to link articles about the same type of event, not the same instance. In addition, we use the frequency of each basic pattern to compute the similarity of relations, since basic patterns like “say” or “have” appear in almost every article and it is dangerous to rely on such expressions. Increasing Basic Patterns In the above explanation, we have assumed that we can obtain enough basic patterns from an article. However, the actual number of basic patterns that one can find from a single article is usually not enough, because the number of sentences is rather small in comparison to the variation of expressions. So having two articles that have multiple basic patterns in common is very unlikely. We extend the number of articles for obtaining basic patterns by using a cluster of comparable articles that report the same event instead of a single article. We call this cluster of articles a “basic cluster.” Using basic clusters instead of single articles also helps to increase the redundancy of data. We can give more confidence to repeated basic patterns. Note that the notion of “basic cluster” is different from the clusters used for creating tables explained above. In the following sections, a cluster for creating a table is called a “metacluster,” because this is a cluster of basic clusters. A basic cluster consists a set of articles that report same eventwhich happens at a certain time, and a metacluster consists a set of events that contain same relationover a certain period. We try to increase the number of articles in a basic cluster by looking at multiple news sources simultaneously. We use a clustering algorithm that uses a vector-space-model to obtain basic clusters. Then we apply cross-document coreference resolution to connect entities of different articles within a basic cluster. This way, we can increase the number of basic patterns connected to each entity. Also, it allows us to give a weight to entities. We calculate their weights using the number of occurrences within a cluster and their position within an article. These entities are used to obtain basic patterns later. We also use a parser and tree normalizer to generate basic patterns. The format of basic patterns is crucial to performance. We think a basic pattern should be somewhat specific, since each pattern should capture an entity with some relevant context. But at the same time a basic pattern should be general enough to reduce data sparseness. We choose a predicate-argument structure as a natural solution for this problem. Compared to traditional constituent trees, a predicate-argument structure is a higher-level representation of sentences that has gained wide acceptance from the natural language community recently. In this paper we used a logical feature structure called GLARF proposed by Meyers et al. (2001a). A GLARF converter takes a syntactic tree as an input and augments it with several 306 3: GLARF structure of the sentence Louisiana’s features. Figure 3 shows a sample GLARF structure from the sentence hit Louisiana’s We used GLARF for two reasons: first, unlike traditional constituent parsers, GLARF has an ability to regularize several linguistic phenomena such as participial constructions and coordination. This allows us to handle this syntactic variety in a uniform way. Second, an output structure can be easily converted into a directed graph that represents the relationship between each word, without losing significant information from the original sentence. Compared to an ordinary constituent tree, it is easier to extract syntactic relationships. In the next section, we discuss how we used this structure to generate basic patterns. 3 Implementation The overall process to generate basic patterns and discover relations from unannotated news articles is shown in Figure 4. Theoretically this could be a straight pipeline, but due to the nature of the implementation we process some stages separately and combine them in the later stage. In the following subsection, we explain each component. 3.1 Web Crawling and Basic Clustering First of all, we need a lot of news articles from multiple news sources. We created a simple web crawler that extract the main texts from web pages. We observed that the crawler can correctly take the main texts from about 90% of the pages from each news site. We ran the crawler every day on several news sites. Then we applied a simple clustering algorithm the obtained articles in order to find a set of arti- Figure 4: System overview. cles that talk about exactly the same news and form a basic cluster. We eliminate stop words and stem all the other words, then compute the similarity between two articles by using a bag-of-words approach. In news articles, a sentence that appears in the beginning of an article is usually more important than the others. So we preserved the word order to take into account the location of each sentence. First we computed a word vector from each article: � = a vector element of word article the inverse document frequency of and a list of positions the article. the average number of words for all articles. Then we calculated the cosine value of each pair of vectors: = We computed the similarity of all possible pairs of articles from the same day, and selected the pairs ’s SUFFIX Louisiana T-POS Katrina coast SBJ OBJ hit ... Newspapers ...</abstract>
<title confidence="0.917923538461538">Basic Clusters Crawling Clustering Coreference Resolution Parsing GLARFing Basic Pattern Generation Basic Patterns Metaclustering Metaclusters</title>
<abstract confidence="0.990462478947369">(Tables) i 307 similarity exceeded a certain threshold in this experiment) to form a basic cluster. 3.2 Parsing and GLARFing After getting a set of basic clusters, we pass them to an existing statistical parser (Charniak, 2000) and rule-based tree normalizer to obtain a GLARF structure for each sentence in every article. The current implementation of a GLARF converter gives about 75% F-score using parser output. For the details of GLARF representation and its conversion, see Meyers et al. (2001b). 3.3 NE Tagging and Coreference Resolution In parallel with parsing and GLARFing, we also apply NE tagging and coreference resolution for each article in a basic cluster. We used an HMM-based NE tagger whose performance is about 85% in Fscore. This NE tagger produces ACE-type Named PERSON, ORGANIZATION, GPE, LOand FACILITY After applying singledocument coreference resolution for each article, we connect the entities among different articles in the same basic cluster to obtain cross-document coreference entities with simple string matching. 3.4 Basic Pattern Generation After getting a GLARF structure for each sentence and a set of documents whose entities are tagged and connected to each other, we merge the two outputs and create a big network of GLARF structures whose nodes are interconnected across different sentences/articles. Now we can generate basic patterns for each entity. First, we compute the weight for cross-document entity a certain basic cluster as follows: e∈E an entity within one article and the number of of entity a document and the position ACE task description can be found at http://www.itl.nist.gov/iad/894.01/tests/ace/ and the ACE guidelines at http://www.ldc.upenn.edu/Projects/ACE/ hurricane names used in the examples were recognized as PERSON. Figure 5: Basic patterns obtained from the sentence hit Louisiana’s the sentence where entity appeared, respeca constant value which was this experiment. To reduce combinatorial complexity, we took only the five most highly weighted entities from each basic cluster to generate basic patterns. We observed these five entities can cover major relations that are reported in a basic cluster. Next, we obtain basic patterns from the GLARF structures. We used only the first ten sentences in each article for getting basic patterns, as most important facts are usually written in the first few sentences of a news article. Figure 5 shows all basic patterns obtained from the sentence hit Louisiana’s The shaded nodes “Katrina” and “Louisiana” are entities from which each basic pattern originates. We take a path of GLARF nodes from each entity node until it reaches any predicative node: noun, verb, or adjective in this case. Since the nodes “hit” and “coast” can be predicates in this example, we obthree unique paths and hit some To increase the specificity of patterns, we generate extra basic patterns by adding a node that is immediately connected to a predicative node. (From this example, we generate two basic patterns: “hit” and “hit-coast” from the “Katrina” node.) Notice that in a GLARF structure, the type of each argument such as subject or object is preserved in an edge even if we extract a single path of a graph. Now, we replace both entities “Katrina” and “Louisiana” with variables Õs SUFFIX Louisiana T-POS GPE+T-POS:coast Katrina coast SBJ OBJ PER+SBJ:hit-OBJ:coast hit PER+SBJ:hit 308 based on their NE tags and obtain parameterpatterns: hit hit some After taking all the basic patterns from every basic cluster, we compute the Inverse Cluster Frequency (ICF) of each unique basic pattern. ICF is similar to the Inverse Document Frequency (IDF) of words, which is used to calculate the weight of each basic pattern for metaclustering. 3.5 Metaclustering Finally, we can perform metaclustering to obtain tables. We compute the similarity between each basic pair, as seen in Figure 6. the set of cross-document entities from basic clusters respectively. We examine all possible mappings of relations (parallel mappings of multiple entities) from both basic clusters, and find all the similarity score exceeds a certhreshold. the bag-of-words similarity of two clusters. As a weighting function we used ICF: We then sort the similarities of all possible pairs of basic clusters, and try to build a metacluster by taking the most strongly connected pair first. Note that in this process we may assign one basic cluster to several different metaclusters. When a link is found between two basic clusters that were already assigned to a metacluster, we try to put them into all the existing metaclusters it belongs to. However, we allow a basic cluster to be added only if it can fill all the columns in that table. In other words, the first two basic clusters (i.e. an initial two-row table) determines its columns and therefore define the relation of that table. 4 Experiment and Evaluation We used twelve newspapers published mainly in the U.S. We collected their articles over two months (from Sep. 21, 2005 - Nov. 27, 2005). We obtained 643,767 basic patterns and 7,990 unique types. Then we applied metaclustering to these basic clusters Source articles 28,009 Basic clusters 5,543 Basic patterns (token) 643,767 Basic patterns (type) 7,990 Metaclusters 302 (rows 101 Table 2: Articles and obtained metaclusters. and obtained 302 metaclusters (tables). We then removed duplicated rows and took only the tables that had 3 or more rows. Finally we had 101 tables. The total number the of articles and clusters we used are shown in Table 2. 4.1 Evaluation Method We evaluated the obtained tables as follows. For each row in a table, we added a summary of the source articles that were used to extract the relation. Then for each table, an evaluator looks into every row and its source article, and tries to come up with a sentence that explains the relation among its columns. The description should be as specific as possible. If at least half of the rows can fit the explanation, the table is considered “consistent.” For each consistent table, the evaluator wrote down the sentence using variable names ($1, $2, ...) to refer to its columns. Finally, we counted the number of consistent tables. We also counted how many rows in each table can fit the explanation. 4.2 Results We evaluated 48 randomly chosen tables. Among these tables, we found that 36 tables were consistent. We also counted the total number of rows that fit each description, shown in Table 3. Table 4 shows the descriptions of the selected tables. The largest consistent table was about hurricanes (Table 5). Although we cannot exactly measure the recall of each table, we tried to estimate the recall by comparing this hurricane table to a manually created one (Table We found 6 out of 9 hurricanes It is worth noting that most of these hurricane names were automatically disambiguated although our NE tagger didn’t distinguish a hurricane name from a person Katrina and Longwang shown in the previous examples are not included in this table. They appeared before this period. = that include p clusters) 309 each cluster pair each entity mapping ..., each entity pair } mapscore mapping } } } Figure 6: Computing similarity of basic clusters.</abstract>
<note confidence="0.906985">Tables: Consistent tables 36 (75%) Inconsistent tables 12 Total 48 Rows: Rows that fit the description 118 (73%) Rows not fitted 43 Total 161 Table 3: Evaluation results. Description Rows Storm $1(PER) probably affected $2(GPE). 8/16 Nominee $2(PER) must be confirmed by $1(ORG). 4/7</note>
<abstract confidence="0.974084037037037">1(PER) urges $2(GPE) to make changes. 4/6 $1(GPE) launched an attack in $2(GPE). 3/5 $1(PER) ran against $2(PER) in an election. 4/5 $2(PER) visited $1(GPE) on a diplomatic mission. 2/4 $2(PER) beat $1(PER) in golf. 4/4 $2(GPE) soldier(s) were killed in $1(GPE). 3/3 $2(PER) ran for governor of $1(GPE). 2/3 Boxer $1(PER) fought boxer $2(PER). 3/3 Table 4: Description of obtained tables and the number of fitted/total rows. name. The second largest table (about nominations of officials) is shown in Table 7. We reviewed 10 incorrect rows from various tables and found 4 of them were due to coreference errors and one error was due to a parse error. The other 4 errors were due to multiple basic patterns distant from each other that happened to refer to a different event reported in the same cluster. The causes of the one remaining error was obscure. Most inconsistent tables were a mixture of multiple relations and some of their rows still looked consistent. We have a couple of open questions. First, the overall recall of our system might be lower than existing IE systems, as we are relying on a cluster of comparable articles rather than a single document to discover an event. We might be able to improve this in the future by adjusting the basic clustering algorithm or weighting schema of basic patterns. Secondly, some combinations of basic patterns looked inherently vague. For example, we used the two bapatterns and in the following sentence (the patterns are underlined): Ervin Santana pitched 5 1-3 gutsy innings in his postseason debut for the Angels, Adam Kennedy hit a goahead triple that sent Yankees outfielders crashing to the ground, and Los Angeles beat New York 5-3 Monday night in the decisive Game 5 of their AL playoff series. It is not clear whether this set of patterns can yield any meaningful relation. We are not sure how much this sort of table can affect overall IE performance. 5 Conclusion In this paper we proposed Preemptive Information Extraction as a new direction of IE research. As its key technique, we presented Unrestricted Relation Discovery that tries to find parallel correspondences between multiple entities in a document, and perform clustering using basic patterns as features. To increase the number of basic patterns, we used a cluster of comparable articles instead of a single document. We presented the implementation of our preliminary system and its outputs. We obtained dozens of usable tables. 310 Article 1:dump 2:coast</abstract>
<address confidence="0.9845424375">2005-09-21 Rita Texas 2005-09-23 Rita New Orleans 2005-09-25 Bush Texas 2005-09-26 Damrey Hainan 2005-09-27 Damrey Vietnam 2005-10-01 Rita Louisiana 2005-10-02 Otis Mexico 2005-10-04 Longwang China 2005-10-05 Stan Mexico 2005-10-06 Tammy Florida 2005-10-07 Tammy Georgia 2005-10-19 Wilma Florida 2005-10-25 Wilma Cuba 2005-10-25 Wilma Massachusetts 2005-10-28 Beta Nicaragua 2005-11-20 Gamma Florida</address>
<abstract confidence="0.997896363636363">1. More than 2,000 National Guard troops were put on alert to assist as into the string islands and headed west, perhaps toward Typhoon Damrey into Tuesday after killing nine people in China,... Oil markets have been watching progress nervously, ... but the threat to energy interests appears to eased as forecasters predict storm turn to- Table 5: Hurricane table (“Storm $1(PER) probably affected $2(GPE).”) and the actual expressions we used for extraction.</abstract>
<title confidence="0.7288">Hurricane Date (Affected Place) Articles</title>
<author confidence="0.744459">Philippe Sep</author>
<note confidence="0.887220222222222">Rita Sep 17-26 (Louisiana, Texas, etc.) 566 * Stan Oct 1-5 (Mexico, Nicaragua, etc.) 83 * Tammy Oct 5-? (Georgia, Alabama) 18 Vince Oct 8-11 (Portugal, Spain) 12 * Wilma Oct 15-25 (Cuba, Honduras, etc.) 368 Alpha Oct 22-24 (Haiti, Dominican Rep.) 80 * Beta Oct 26-31 (Nicaragua, Honduras) 55 * Gamma Nov 13-20 (Belize, etc.) 36 Table 6: Hurricanes in North America between mid-</note>
<abstract confidence="0.8333814">Sep. and Nov. (from Wikipedia). Rows with a star (*) were actually extracted. The number of the source articles that contained a mention of the hurricane is shown in the right column. Article 1:confirm 2:be-confirmed</abstract>
<address confidence="0.809577142857143">2005 -09 -21 Senate Roberts 2005 -10 -03 Supreme Court Miers 2005 -10 -20 Senate Bush 2005 -10 -26 Senate Sauerbrey 2005 -10 -31 Senate Mr. Alito 2005 -11 -04 Senate Alito 2005 -11 -17 Fed Bernanke</address>
<note confidence="0.95798280952381">Table 7: Nomination table (“Nominee $2(PER) must be confirmed by $1(ORG).”) Acknowledgements This research was supported by the National Science Foundation under Grant IIS-00325657. This paper does not necessarily reflect the position of the U.S. Government. We would like to thank Prof. Ralph Grishman who provided useful suggestions and discussions. References Eugene Agichtein and L. Gravano. 2000. Snowball: Extracting Relations from Large Plaintext Collections. In Proceedings of the 5th ACM International Conference Digital Libraries Sergey Brin. 1998. Extracting Patterns and Relations the World Wide Web. In Workshop at Eugene Charniak. 2000. A maximum-entropy-inspired In of Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman. 2004. Discovering relations among named entities large corpora. In of the Annual</note>
<title confidence="0.735842">Meeting of Association of Computational Linguistics</title>
<author confidence="0.6739345">a Covering Treebanks with</author>
<title confidence="0.8117865">In Workshop on Sharing Tools Resources for Research and</title>
<author confidence="0.903311">Adam Meyers</author>
<author confidence="0.903311">Michiko Kosaka</author>
<author confidence="0.903311">Satoshi Sekine</author>
<author confidence="0.903311">Ralph</author>
<affiliation confidence="0.890264">Grishman, and Shubin Zhao. 2001b. Parsing and In of Tzigov</affiliation>
<address confidence="0.6766545">Chark, Bulgaria. Deepak Ravichandran and Eduard Hovy. 2002. Learning</address>
<abstract confidence="0.737277">surface text patterns for a question answering system. of the 40th Annual Meeting of the As-</abstract>
<title confidence="0.531598">for Computational Linguistics</title>
<author confidence="0.451193">Automatically Generating Extrac-</author>
<note confidence="0.981338">Patterns from Untagged Text. In of the 13th National Conference on Artificial Intelligence Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman. 2003. An Improved Extraction Pattern Representation Model for Automatic IE Pattern Acquisition. In Proceedings of the Annual Meeting of Association of</note>
<title confidence="0.69477">Linguistics</title>
<author confidence="0.6612075">Unsupervised Discovery</author>
<note confidence="0.77278425">of Scenario-Level Patterns for Information Extraction. of the 18th International Conference Computational Linguistics 311</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>More than 2,000 National Guard troops were put on active-duty alert to assist as Rita slammed into the string of islands and headed west, perhaps toward Texas....</title>
<marker></marker>
<rawString>1. More than 2,000 National Guard troops were put on active-duty alert to assist as Rita slammed into the string of islands and headed west, perhaps toward Texas....</rawString>
</citation>
<citation valid="false">
<title>Typhoon Damrey smashed into Vietnam on Tuesday after killing nine people in China,...</title>
<marker></marker>
<rawString>2. Typhoon Damrey smashed into Vietnam on Tuesday after killing nine people in China,...</rawString>
</citation>
<citation valid="false">
<title>Oil markets have been watching Wilma’s progress nervously, ... but the threat to energy interests appears to have eased as forecasters predict the storm will turn toward Florida....</title>
<marker></marker>
<rawString>3. Oil markets have been watching Wilma’s progress nervously, ... but the threat to energy interests appears to have eased as forecasters predict the storm will turn toward Florida....</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
<author>L Gravano</author>
</authors>
<title>Snowball: Extracting Relations from Large Plaintext Collections.</title>
<date>2000</date>
<booktitle>In Proceedings of the 5th ACM International Conference on Digital Libraries (DL-00).</booktitle>
<contexts>
<context position="2605" citStr="Agichtein and Gravano, 2000" startWordPosition="433" endWordPosition="436">in advance would help reduce this risk. An IE task can be defined as finding a relation among several entities involved in a certain type of event. For example, in the MUC-6 management succession scenario, one seeks a relation between COMPANY, PERSON and POST involved with hiring/firing events. For each row of an extracted table, you can always read it as “COMPANY hired (or fired) PERSON for POST.” The relation between these entities is retained throughout the table. There are many existing works on obtaining extraction patterns for pre-defined relations (Riloff, 1996; Yangarber et al., 2000; Agichtein and Gravano, 2000; Sudo et al., 2003). Unrestricted Relation Discovery is a technique to automatically discover such relations that repeatedly appear in a corpus and present them as a table, with absolutely no human intervention. Unlike most existing IE research, a user does not specify the type of articles or information wanted. Instead, a system tries to find all the kinds of relations that are reported multiple times and can be reported in tabular form. This technique will open up the possibility of trying new IE scenarios. Furthermore, the system itself can be used as an IE system, since an obtained relati</context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Eugene Agichtein and L. Gravano. 2000. Snowball: Extracting Relations from Large Plaintext Collections. In Proceedings of the 5th ACM International Conference on Digital Libraries (DL-00).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
</authors>
<title>Extracting Patterns and Relations from the World Wide Web. In</title>
<date>1998</date>
<booktitle>WebDB Workshop at EDBT ’98.</booktitle>
<contexts>
<context position="8161" citStr="Brin, 1998" startWordPosition="1376" endWordPosition="1377"> extend a table while retaining a relation among its columns. In this example, the obtained table is just what an IE system (whose task is to find a hurricane name and the affected place) would create. However, these articles might also include other things, which could represent different relations. For example, the governments might call for help or some casualties might have been reported. To obtain such relations, we need to choose different entities from the articles. Several existing works have tried to extract a certain type of relation by manually choosing different pairs of entities (Brin, 1998; Ravichandran and Hovy, 2002). Hasegawa et al. (2004) tried to extract multiple relations by choosing entity types. We assume that we can find such relations by trying all possible combinations from a set of entities we have chosen in advance; some combinations might represent a hurricane and government relation, and others might represent a place and its casualties. To ensure that an article can have several different relations, we let each article belong to several different clusters. In a real-world situation, only using basic patterns sometimes gives undesired results. For example, “(Pres</context>
</contexts>
<marker>Brin, 1998</marker>
<rawString>Sergey Brin. 1998. Extracting Patterns and Relations from the World Wide Web. In WebDB Workshop at EDBT ’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of NAACL-2000.</booktitle>
<contexts>
<context position="15310" citStr="Charniak, 2000" startWordPosition="2569" endWordPosition="2570">m(A1, A2) = cos(V (A1) · V (A2)) We computed the similarity of all possible pairs of articles from the same day, and selected the pairs ’s SUFFIX Louisiana T-POS Katrina coast SBJ OBJ hit ... Newspapers ... Basic Clusters Web Crawling Basic Clustering Coreference Resolution Parsing GLARFing Basic Pattern Generation Basic Patterns Metaclustering Metaclusters (Tables) i exp(− avgwords) 307 whose similarity exceeded a certain threshold (0.65 in this experiment) to form a basic cluster. 3.2 Parsing and GLARFing After getting a set of basic clusters, we pass them to an existing statistical parser (Charniak, 2000) and rule-based tree normalizer to obtain a GLARF structure for each sentence in every article. The current implementation of a GLARF converter gives about 75% F-score using parser output. For the details of GLARF representation and its conversion, see Meyers et al. (2001b). 3.3 NE Tagging and Coreference Resolution In parallel with parsing and GLARFing, we also apply NE tagging and coreference resolution for each article in a basic cluster. We used an HMM-based NE tagger whose performance is about 85% in Fscore. This NE tagger produces ACE-type Named Entities 1: PERSON, ORGANIZATION, GPE, LOC</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of NAACL-2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaaki Hasegawa</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
</authors>
<title>Discovering relations among named entities from large corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of the Annual Meeting of Association of Computational Linguistics (ACL-04).</booktitle>
<contexts>
<context position="8215" citStr="Hasegawa et al. (2004)" startWordPosition="1382" endWordPosition="1385"> among its columns. In this example, the obtained table is just what an IE system (whose task is to find a hurricane name and the affected place) would create. However, these articles might also include other things, which could represent different relations. For example, the governments might call for help or some casualties might have been reported. To obtain such relations, we need to choose different entities from the articles. Several existing works have tried to extract a certain type of relation by manually choosing different pairs of entities (Brin, 1998; Ravichandran and Hovy, 2002). Hasegawa et al. (2004) tried to extract multiple relations by choosing entity types. We assume that we can find such relations by trying all possible combinations from a set of entities we have chosen in advance; some combinations might represent a hurricane and government relation, and others might represent a place and its casualties. To ensure that an article can have several different relations, we let each article belong to several different clusters. In a real-world situation, only using basic patterns sometimes gives undesired results. For example, “(President) Bush flew to Texas” and “(Hurricane) Katrina fl</context>
</contexts>
<marker>Hasegawa, Sekine, Grishman, 2004</marker>
<rawString>Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman. 2004. Discovering relations among named entities from large corpora. In Proceedings of the Annual Meeting of Association of Computational Linguistics (ACL-04).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Meyers</author>
<author>Ralph Grishman</author>
<author>Michiko Kosaka</author>
<author>Shubin Zhao</author>
</authors>
<title>Covering Treebanks with GLARF.</title>
<date>2001</date>
<booktitle>In ACL/EACL Workshop on Sharing Tools and Resources for Research and Education.</booktitle>
<contexts>
<context position="12180" citStr="Meyers et al. (2001" startWordPosition="2043" endWordPosition="2047">rns is crucial to performance. We think a basic pattern should be somewhat specific, since each pattern should capture an entity with some relevant context. But at the same time a basic pattern should be general enough to reduce data sparseness. We choose a predicate-argument structure as a natural solution for this problem. Compared to traditional constituent trees, a predicate-argument structure is a higher-level representation of sentences that has gained wide acceptance from the natural language community recently. In this paper we used a logical feature structure called GLARF proposed by Meyers et al. (2001a). A GLARF converter takes a syntactic tree as an input and augments it with several 306 Figure 3: GLARF structure of the sentence “Katrina hit Louisiana’s coast.” features. Figure 3 shows a sample GLARF structure obtained from the sentence “Katrina hit Louisiana’s coast.” We used GLARF for two reasons: first, unlike traditional constituent parsers, GLARF has an ability to regularize several linguistic phenomena such as participial constructions and coordination. This allows us to handle this syntactic variety in a uniform way. Second, an output structure can be easily converted into a direct</context>
<context position="15582" citStr="Meyers et al. (2001" startWordPosition="2611" endWordPosition="2615">lution Parsing GLARFing Basic Pattern Generation Basic Patterns Metaclustering Metaclusters (Tables) i exp(− avgwords) 307 whose similarity exceeded a certain threshold (0.65 in this experiment) to form a basic cluster. 3.2 Parsing and GLARFing After getting a set of basic clusters, we pass them to an existing statistical parser (Charniak, 2000) and rule-based tree normalizer to obtain a GLARF structure for each sentence in every article. The current implementation of a GLARF converter gives about 75% F-score using parser output. For the details of GLARF representation and its conversion, see Meyers et al. (2001b). 3.3 NE Tagging and Coreference Resolution In parallel with parsing and GLARFing, we also apply NE tagging and coreference resolution for each article in a basic cluster. We used an HMM-based NE tagger whose performance is about 85% in Fscore. This NE tagger produces ACE-type Named Entities 1: PERSON, ORGANIZATION, GPE, LOCATION and FACILITY 2. After applying singledocument coreference resolution for each article, we connect the entities among different articles in the same basic cluster to obtain cross-document coreference entities with simple string matching. 3.4 Basic Pattern Generation </context>
</contexts>
<marker>Meyers, Grishman, Kosaka, Zhao, 2001</marker>
<rawString>Adam Meyers, Ralph Grishman, Michiko Kosaka, and Shubin Zhao. 2001a. Covering Treebanks with GLARF. In ACL/EACL Workshop on Sharing Tools and Resources for Research and Education.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Meyers</author>
<author>Michiko Kosaka</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
<author>Shubin Zhao</author>
</authors>
<title>Parsing and GLARFing.</title>
<date>2001</date>
<booktitle>In Proceedings of RANLP-2001, Tzigov Chark,</booktitle>
<contexts>
<context position="12180" citStr="Meyers et al. (2001" startWordPosition="2043" endWordPosition="2047">rns is crucial to performance. We think a basic pattern should be somewhat specific, since each pattern should capture an entity with some relevant context. But at the same time a basic pattern should be general enough to reduce data sparseness. We choose a predicate-argument structure as a natural solution for this problem. Compared to traditional constituent trees, a predicate-argument structure is a higher-level representation of sentences that has gained wide acceptance from the natural language community recently. In this paper we used a logical feature structure called GLARF proposed by Meyers et al. (2001a). A GLARF converter takes a syntactic tree as an input and augments it with several 306 Figure 3: GLARF structure of the sentence “Katrina hit Louisiana’s coast.” features. Figure 3 shows a sample GLARF structure obtained from the sentence “Katrina hit Louisiana’s coast.” We used GLARF for two reasons: first, unlike traditional constituent parsers, GLARF has an ability to regularize several linguistic phenomena such as participial constructions and coordination. This allows us to handle this syntactic variety in a uniform way. Second, an output structure can be easily converted into a direct</context>
<context position="15582" citStr="Meyers et al. (2001" startWordPosition="2611" endWordPosition="2615">lution Parsing GLARFing Basic Pattern Generation Basic Patterns Metaclustering Metaclusters (Tables) i exp(− avgwords) 307 whose similarity exceeded a certain threshold (0.65 in this experiment) to form a basic cluster. 3.2 Parsing and GLARFing After getting a set of basic clusters, we pass them to an existing statistical parser (Charniak, 2000) and rule-based tree normalizer to obtain a GLARF structure for each sentence in every article. The current implementation of a GLARF converter gives about 75% F-score using parser output. For the details of GLARF representation and its conversion, see Meyers et al. (2001b). 3.3 NE Tagging and Coreference Resolution In parallel with parsing and GLARFing, we also apply NE tagging and coreference resolution for each article in a basic cluster. We used an HMM-based NE tagger whose performance is about 85% in Fscore. This NE tagger produces ACE-type Named Entities 1: PERSON, ORGANIZATION, GPE, LOCATION and FACILITY 2. After applying singledocument coreference resolution for each article, we connect the entities among different articles in the same basic cluster to obtain cross-document coreference entities with simple string matching. 3.4 Basic Pattern Generation </context>
</contexts>
<marker>Meyers, Kosaka, Sekine, Grishman, Zhao, 2001</marker>
<rawString>Adam Meyers, Michiko Kosaka, Satoshi Sekine, Ralph Grishman, and Shubin Zhao. 2001b. Parsing and GLARFing. In Proceedings of RANLP-2001, Tzigov Chark, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Ravichandran</author>
<author>Eduard Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="8191" citStr="Ravichandran and Hovy, 2002" startWordPosition="1378" endWordPosition="1381">ble while retaining a relation among its columns. In this example, the obtained table is just what an IE system (whose task is to find a hurricane name and the affected place) would create. However, these articles might also include other things, which could represent different relations. For example, the governments might call for help or some casualties might have been reported. To obtain such relations, we need to choose different entities from the articles. Several existing works have tried to extract a certain type of relation by manually choosing different pairs of entities (Brin, 1998; Ravichandran and Hovy, 2002). Hasegawa et al. (2004) tried to extract multiple relations by choosing entity types. We assume that we can find such relations by trying all possible combinations from a set of entities we have chosen in advance; some combinations might represent a hurricane and government relation, and others might represent a place and its casualties. To ensure that an article can have several different relations, we let each article belong to several different clusters. In a real-world situation, only using basic patterns sometimes gives undesired results. For example, “(President) Bush flew to Texas” and</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Deepak Ravichandran and Eduard Hovy. 2002. Learning surface text patterns for a question answering system. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
</authors>
<title>Automatically Generating Extraction Patterns from Untagged Text.</title>
<date>1996</date>
<booktitle>In Proceedings of the 13th National Conference on Artificial Intelligence (AAAI-96).</booktitle>
<contexts>
<context position="2552" citStr="Riloff, 1996" startWordPosition="426" endWordPosition="427">ind of information is easily obtained in advance would help reduce this risk. An IE task can be defined as finding a relation among several entities involved in a certain type of event. For example, in the MUC-6 management succession scenario, one seeks a relation between COMPANY, PERSON and POST involved with hiring/firing events. For each row of an extracted table, you can always read it as “COMPANY hired (or fired) PERSON for POST.” The relation between these entities is retained throughout the table. There are many existing works on obtaining extraction patterns for pre-defined relations (Riloff, 1996; Yangarber et al., 2000; Agichtein and Gravano, 2000; Sudo et al., 2003). Unrestricted Relation Discovery is a technique to automatically discover such relations that repeatedly appear in a corpus and present them as a table, with absolutely no human intervention. Unlike most existing IE research, a user does not specify the type of articles or information wanted. Instead, a system tries to find all the kinds of relations that are reported multiple times and can be reported in tabular form. This technique will open up the possibility of trying new IE scenarios. Furthermore, the system itself </context>
</contexts>
<marker>Riloff, 1996</marker>
<rawString>Ellen Riloff. 1996. Automatically Generating Extraction Patterns from Untagged Text. In Proceedings of the 13th National Conference on Artificial Intelligence (AAAI-96).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoshi Sudo</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
</authors>
<title>An Improved Extraction Pattern Representation Model for Automatic IE Pattern Acquisition.</title>
<date>2003</date>
<booktitle>In Proceedings of the Annual Meeting of Association of Computational Linguistics (ACL-03).</booktitle>
<contexts>
<context position="2625" citStr="Sudo et al., 2003" startWordPosition="437" endWordPosition="440">this risk. An IE task can be defined as finding a relation among several entities involved in a certain type of event. For example, in the MUC-6 management succession scenario, one seeks a relation between COMPANY, PERSON and POST involved with hiring/firing events. For each row of an extracted table, you can always read it as “COMPANY hired (or fired) PERSON for POST.” The relation between these entities is retained throughout the table. There are many existing works on obtaining extraction patterns for pre-defined relations (Riloff, 1996; Yangarber et al., 2000; Agichtein and Gravano, 2000; Sudo et al., 2003). Unrestricted Relation Discovery is a technique to automatically discover such relations that repeatedly appear in a corpus and present them as a table, with absolutely no human intervention. Unlike most existing IE research, a user does not specify the type of articles or information wanted. Instead, a system tries to find all the kinds of relations that are reported multiple times and can be reported in tabular form. This technique will open up the possibility of trying new IE scenarios. Furthermore, the system itself can be used as an IE system, since an obtained relation is already presen</context>
</contexts>
<marker>Sudo, Sekine, Grishman, 2003</marker>
<rawString>Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman. 2003. An Improved Extraction Pattern Representation Model for Automatic IE Pattern Acquisition. In Proceedings of the Annual Meeting of Association of Computational Linguistics (ACL-03).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Yangarber</author>
<author>Ralph Grishman</author>
<author>Pasi Tapanainen</author>
<author>Silja Huttunen</author>
</authors>
<title>Unsupervised Discovery of Scenario-Level Patterns for Information Extraction.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (COLING-00).</booktitle>
<contexts>
<context position="2576" citStr="Yangarber et al., 2000" startWordPosition="428" endWordPosition="432">tion is easily obtained in advance would help reduce this risk. An IE task can be defined as finding a relation among several entities involved in a certain type of event. For example, in the MUC-6 management succession scenario, one seeks a relation between COMPANY, PERSON and POST involved with hiring/firing events. For each row of an extracted table, you can always read it as “COMPANY hired (or fired) PERSON for POST.” The relation between these entities is retained throughout the table. There are many existing works on obtaining extraction patterns for pre-defined relations (Riloff, 1996; Yangarber et al., 2000; Agichtein and Gravano, 2000; Sudo et al., 2003). Unrestricted Relation Discovery is a technique to automatically discover such relations that repeatedly appear in a corpus and present them as a table, with absolutely no human intervention. Unlike most existing IE research, a user does not specify the type of articles or information wanted. Instead, a system tries to find all the kinds of relations that are reported multiple times and can be reported in tabular form. This technique will open up the possibility of trying new IE scenarios. Furthermore, the system itself can be used as an IE sys</context>
</contexts>
<marker>Yangarber, Grishman, Tapanainen, Huttunen, 2000</marker>
<rawString>Roman Yangarber, Ralph Grishman, Pasi Tapanainen, and Silja Huttunen. 2000. Unsupervised Discovery of Scenario-Level Patterns for Information Extraction. In Proceedings of the 18th International Conference on Computational Linguistics (COLING-00).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>