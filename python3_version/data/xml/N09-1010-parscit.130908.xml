<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001375">
<title confidence="0.932047">
Adding More Languages Improves Unsupervised Multilingual
Part-of-Speech Tagging: A Bayesian Non-Parametric Approach
</title>
<author confidence="0.99897">
Benjamin Snyder, Tahira Naseem, Jacob Eisenstein, and Regina Barzilay
</author>
<affiliation confidence="0.9991855">
Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
</affiliation>
<email confidence="0.994568">
{bsnyder, tahira, jacobe, regina}@csail.mit.edu
</email>
<sectionHeader confidence="0.996619" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997337416666667">
We investigate the problem of unsupervised
part-of-speech tagging when raw parallel data
is available in a large number of languages.
Patterns of ambiguity vary greatly across lan-
guages and therefore even unannotated multi-
lingual data can serve as a learning signal. We
propose a non-parametric Bayesian model that
connects related tagging decisions across lan-
guages through the use of multilingual latent
variables. Our experiments show that perfor-
mance improves steadily as the number of lan-
guages increases.
</bodyText>
<sectionHeader confidence="0.998775" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999685421052632">
In this paper we investigate the problem of unsu-
pervised part-of-speech tagging when unannotated
parallel data is available in a large number of lan-
guages. Our goal is to develop a fully joint multilin-
gual model that scales well and shows improved per-
formance for individual languages as the total num-
ber of languages increases.
Languages exhibit ambiguity at multiple levels,
making unsupervised induction of their underlying
structure a difficult task. However, sources of lin-
guistic ambiguity vary across languages. For exam-
ple, the word fish in English can be used as either a
verb or a noun. In French, however, the noun pois-
son (fish) is entirely distinct from the verbal form
pˆecher (to fish). Previous work has leveraged this
idea by building models for unsupervised learning
from aligned bilingual data (Snyder et al., 2008).
However, aligned data is often available for many
languages. The benefits of bilingual learning vary
</bodyText>
<page confidence="0.982694">
83
</page>
<bodyText confidence="0.999966558823529">
markedly depending on which pair of languages is
selected, and without labeled data it is unclear how
to determine which supplementary language is most
helpful. In this paper, we show that it is possi-
ble to leverage all aligned languages simultaneously,
achieving accuracy that in most cases outperforms
even optimally chosen bilingual pairings.
Even in expressing the same meaning, languages
take different syntactic routes, leading to variation
in part-of-speech sequences. Therefore, an effec-
tive multilingual model must accurately model com-
mon linguistic structure, yet remain flexible to the
idiosyncrasies of each language. This tension only
becomes stronger as additional languages are added
to the mix. From a computational standpoint, the
main challenge is to ensure that the model scales
well as the number of languages increases. Care
must be taken to avoid an exponential increase in
the parameter space as well as the time complexity
of inference procedure.
We propose a non-parametric Bayesian model for
joint multilingual tagging. The topology of our
model connects tagging decisions within a language
as well as across languages. The model scales lin-
early with the number of languages, allowing us to
incorporate as many as are available. For each lan-
guage, the model contains an HMM-like substruc-
ture and connects these substructures to one another
by means of cross-lingual latent variables. These
variables, which we refer to as superlingual tags,
capture repeated multilingual patterns and thus re-
duce the overall uncertainty in tagging decisions.
We evaluate our model on a parallel corpus of
eight languages. The model is trained once using all
</bodyText>
<note confidence="0.806297">
Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 83–91,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.9997219375">
languages, and its performance is tested separately
for each on a held-out monolingual test set. When a
complete tag lexicon is provided, our unsupervised
model achieves an average accuracy of 95%, in com-
parison to 91% for an unsupervised monolingual
Bayesian HMM and 97.4% for its supervised coun-
terpart. Thus, on average, the gap between unsu-
pervised and supervised monolingual performance
is cut by nearly two thirds. We also examined sce-
narios where the tag lexicon is reduced in size. In
all cases, the multilingual model yielded substantial
performance gains. Finally, we examined the per-
formance of our model when trained on all possible
subsets of the eight languages. We found that perfor-
mance improves steadily as the number of available
languages increases.
</bodyText>
<sectionHeader confidence="0.99983" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998081945454545">
Bilingual Part-of-Speech Tagging Early work on
multilingual tagging focused on projecting annota-
tions from an annotated source language to a target
language (Yarowsky and Ngai, 2001; Feldman et al.,
2006). In contrast, we assume no labeled data at
all; our unsupervised model instead symmetrically
improves performance for all languages by learning
cross-lingual patterns in raw parallel data. An addi-
tional distinction is that projection-based work uti-
lizes pairs of languages, while our approach allows
for continuous improvement as languages are added
to the mix.
In recent work, Snyder et al. (2008) presented
a model for unsupervised part-of-speech tagging
trained from a bilingual parallel corpus. This bilin-
gual model and the model presented here share a
number of similarities: both are Bayesian graphi-
cal models building upon hidden Markov models.
However, the bilingual model explicitly joins each
aligned word-pair into a single coupled state. Thus,
the state-space of these joined nodes grows exponen-
tially in the number of languages. In addition, cross-
ing alignments must be removed so that the result-
ing graph structure remains acyclic. In contrast, our
multilingual model posits latent cross-lingual tags
without explicitly joining or directly connecting the
part-of-speech tags across languages. Besides per-
mitting crossing alignments, this structure allows the
model to scale gracefully with the number of lan-
guages.
Beyond Bilingual Learning While most work on
multilingual learning focuses on bilingual analysis,
some models operate on more than one pair of lan-
guages. For instance, Genzel (2005) describes a
method for inducing a multilingual lexicon from
a group of related languages. His model first in-
duces bilingual models for each pair of languages
and then combines them. Our work takes a different
approach by simultaneously learning from all lan-
guages, rather than combining bilingual results.
A related thread of research is multi-source ma-
chine translation (Och and Ney, 2001; Utiyama and
Isahara, 2006; Cohn and Lapata, 2007) where the
goal is to translate from multiple source languages to
a single target language. Rather than jointly training
all the languages together, these models train bilin-
gual models separately, and then use their output to
select a final translation. The selection criterion can
be learned at training time since these models have
access to the correct translation. In unsupervised set-
tings, however, we do not have a principled means
for selecting among outputs of different bilingual
models. By developing a joint multilingual model
we can automatically achieve performance that ri-
vals that of the best bilingual pairings.
</bodyText>
<sectionHeader confidence="0.992235" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.999959210526316">
We propose a non-parametric directed Bayesian
graphical model for multilingual part-of-speech tag-
ging using a parallel corpus. We perform a joint
training pass over the corpus, and then apply the
parameters learned for each language to a held-out
monolingual test set.
The core idea of our model is that patterns of
ambiguity vary across languages and therefore even
unannotated multilingual data can serve as a learn-
ing signal. Our model is able to simultaneously har-
ness this signal from all languages present in the
corpus. This goal is achieved by designing a sin-
gle graphical model that connects tagging decisions
within a language as well as across languages.
The model contains language-specific HMM sub-
structures connected to one another by cross-lingual
latent variables spanning two or more languages.
These variables, which we refer to as superlingual
tags, capture repeated cross-lingual patterns and
</bodyText>
<page confidence="0.99901">
84
</page>
<figureCaption confidence="0.992544">
Figure 1: Model structure for parallel sentences in English, French, Hebrew, and Urdu. In this example, there are three
superlingual tags, each connected to the part-of-speech tag of a word in each of the four languages.
</figureCaption>
<bodyText confidence="0.99813025">
thus reduce the overall uncertainty in tagging deci-
sions. To encourage the discovery of a compact set
of such cross-lingual patterns, we place a Dirichlet
process prior on the superlingual tag values.
</bodyText>
<subsectionHeader confidence="0.999941">
3.1 Model Structure
</subsectionHeader>
<bodyText confidence="0.99998878125">
For each language, our model includes an HMM-
like substructure with observed word nodes, hid-
den part-of-speech nodes, and directed transition
and emission edges. For each set of aligned words
in parallel sentences, we add a latent superlingual
variable to capture the cross-lingual context. A set
of directed edges connect this variable to the part-
of-speech nodes of the aligned words. Our model
assumes that the superlingual tags for parallel sen-
tences are unordered and are drawn independently
of one another.
Edges radiate outward from superlingual tags to
language-specific part-of-speech nodes. Thus, our
model implicitly assumes that superlingual tags are
drawn prior to the part-of-speech tags of all lan-
guages and probabilistically influence their selec-
tion. See Figure 1 for an example structure.
The particular model structure for each set of par-
allel sentences (i.e. the configuration of superlingual
tags and their edges) is determined by bilingual lexi-
cal alignments and — like the text itself — is consid-
ered an observed variable. In practice, these lexical
alignments are obtained using standard techniques
from machine translation.
Our model design has several benefits. Crossing
and many-to-many alignments may be used with-
out creating cycles in the graph, as all cross-lingual
information emanates from the hidden superlingual
tags. Furthermore, the model scales gracefully with
the number of languages, as the number of new
edges and nodes will be proportional to the number
of words for each additional language.
</bodyText>
<subsectionHeader confidence="0.999399">
3.2 Superlingual Tags
</subsectionHeader>
<bodyText confidence="0.9996724">
Each superlingual tag value specifies a set of dis-
tributions — one for each language’s part-of-speech
tagset. In order to learn repeated cross-lingual pat-
terns, we need to constrain the number of superlin-
gual tag values and thus the number of distributions
they provide. For example, we might allow the su-
perlingual tags to take on integer values from 1 to
K, with each integer value indexing a separate set
of distributions. Each set of distributions should cor-
respond to a discovered cross-lingual pattern in the
data. For example, one set of distributions might fa-
vor nouns in each language and another might favor
verbs.
Rather than fixing the number of superlingual
tag values to an arbitrary and predetermined size
1, ... , K, we allow them to range over the entire set
of integers. In order to encourage the desired multi-
lingual clustering behavior, we use a Dirichlet pro-
cess prior for the superlingual tags. This prior allows
high posterior probability only when a small number
</bodyText>
<page confidence="0.998653">
85
</page>
<bodyText confidence="0.9952675">
of values are used repeatedly. The actual number of
sampled values will be dictated by the data and the
number of languages.
More formally, suppose we have n lan-
guages, ℓ1, ... , ℓn. According to our genera-
tive model, a countably infinite sequence of sets
</bodyText>
<equation confidence="0.9778444">
hωℓ1
1 , ... , ωℓn
1 i, hωℓ1
2 , ... , ωℓn
2 i, ... is drawn from
</equation>
<bodyText confidence="0.996545875">
some base distribution. Each ωℓi is a distribution
over the parts-of-speech in language ℓ.
In parallel, an infinite sequence of mixing compo-
nents π1, π2, ... is drawn from a stick-breaking pro-
cess (Sethuraman, 1994). These components define
a distribution over the integers with most probabil-
ity mass placed on some initial set of values. The
two sequences hωℓ1
</bodyText>
<equation confidence="0.99641775">
1 , . . . , ωℓn
1 i, hωℓ1
2 , . . . , ωℓn
2 i . . .
</equation>
<bodyText confidence="0.958930857142857">
and π1, π2 ... now define the distribution over su-
perlingual tags and their associated distributions on
parts-of-speech. That is, each superlingual tag z ∈
N is drawn with probability πz, and indexes the set
of distributions hωℓ1
z , ... , ωℓn
z i.
</bodyText>
<subsectionHeader confidence="0.996611">
3.3 Part-of-Speech Tags
</subsectionHeader>
<bodyText confidence="0.997899428571429">
Finally, we need to define the generative probabili-
ties of the part-of-speech nodes. For each such node
there may be multiple incoming edges. There will
always be an incoming transition edge from the pre-
vious tag (in the same language). In addition, there
may be incoming edges from zero or more superlin-
gual tags. Each edge carries with it a distribution
over parts-of-speech and these distributions must be
combined into the single distribution from which the
tag is ultimately drawn.
We choose to combine these distributions as a
product of experts. More formally: for language ℓ
and tag position i, the part-of-speech tag yi is drawn
according to
</bodyText>
<equation confidence="0.998402">
φyi−1(yi) Hz ωℓz(yi) (1)
Z
</equation>
<bodyText confidence="0.999966466666667">
Where φyi−1 indicates the transition distribution,
and the z’s range over the values of the incoming
superlingual tags. The normalization term Z is ob-
tained by summing the numerator over all part-of-
speech tags yi in the tagset.
This parameterization allows for a relatively sim-
ple and small parameter space. It also leads to a
desirable property: for a tag to have high probabil-
ity each of the incoming distributions must allow it.
That is, any expert can “veto” a potential tag by as-
signing it low probability, generally leading to con-
sensus decisions.
We now formalize this description by giving the
stochastic process by which the observed data (raw
parallel text) is generated, according to our model.
</bodyText>
<sectionHeader confidence="0.90042" genericHeader="method">
3.4 Generative Process
</sectionHeader>
<bodyText confidence="0.999477333333333">
For n languages, we assume the existence of n
tagsets T1, ... , Tn and vocabularies, W1, ... , Wn,
one for each language. For clarity, the generative
process is described using only bigram transition
dependencies, but our experiments use a trigram
model.
</bodyText>
<listItem confidence="0.993310125">
1. Transition and Emission Parameters: For
each language ℓ and for each tag t ∈ Tℓ, draw
a transition distribution φℓt over tags Tℓ and
an emission distribution θℓ t over words Wℓ, all
from symmetric Dirichlet priors of appropriate
dimension.
2. Superlingual Tag Parameters:
Draw an infinite sequence of sets
</listItem>
<equation confidence="0.704828">
hωℓ1 1 , . . . ,ωℓn
1 i, hωℓ1
2 , ... , ωℓn
2 i, ... from
</equation>
<bodyText confidence="0.999710363636364">
base distribution G0. Each ωℓi is a distribution
over the tagset Tℓ. The base distribution G0 is
a product of n symmetric Dirichlets, where the
dimension of the ith such Dirichlet is the size
of the corresponding tagset Tℓi.
At the same time, draw an infinite sequence
of mixture weights π ∼ GEM(α), where
GEM(α) indicates the stick-breaking distribu-
tion (Sethuraman, 1994), and α = 1. These
parameters together define a prior distribution
over superlingual tags,
</bodyText>
<equation confidence="0.8026085">
00
p(z) = πkδk=z, (2)
k
or equivalently over the part-of-speech distri-
butions hωℓ1, ... , ωℓni that they index:
πkδ(ω;1,... ω;n)=(ωℓ1,...,ωℓn ). (3)
</equation>
<bodyText confidence="0.9996535">
In both cases, δv=v′ is defined as one when
v = v′ and zero otherwise. Distribution 3 is
said to be drawn from a Dirichlet process, con-
ventionally written as DP(α, G0).
</bodyText>
<equation confidence="0.9155795">
yi ∼
00
E
k
</equation>
<page confidence="0.963769">
86
</page>
<listItem confidence="0.9923211875">
3. Data: For each multilingual parallel sentence,
(a) Draw an alignment a specifying sets of
aligned indices across languages. Each
such set may consist of indices in any sub-
set of the languages. We leave the distri-
bution over alignments undefined, as we
consider alignments observed variables.
(b) For each set of indices in a, draw a super-
lingual tag value z according to Distribu-
tion 2.
(c) For each language ℓ, for i = 1,... (until
end-tag reached):
i. Draw a part-of-speech tag yi E Tℓ ac-
cording to Distribution 1
ii. Draw a word wi E Wℓ according to
the emission distribution θy,,.
</listItem>
<bodyText confidence="0.764216666666667">
To perform Bayesian inference under this model
we use a combination of sampling techniques, which
we describe in detail in the next section.
</bodyText>
<sectionHeader confidence="0.852138" genericHeader="method">
3.5 Inference
</sectionHeader>
<bodyText confidence="0.999737285714286">
Ideally we would like to predict the part-of-speech
tags which have highest marginal probability given
the observed words x and alignments a. More
specifically, since we are evaluating our accuracy per
tag-position, we would like to predict, for language
index ℓ and word index i, the single part-of-speech
tag:
</bodyText>
<equation confidence="0.982323">
P(yℓi = tlx,a)
</equation>
<bodyText confidence="0.672617">
which we can rewrite as the argmaxtETe of the inte-
gral,
</bodyText>
<equation confidence="0.9998075">
Z � � �
P yℓ i = t ���y−(ℓ,i), φ, θ, z, ω, x, a ·
� ��
P y−(ℓ,i), φ, θ, z, π, ω, ~~~x, a dy−(ℓ,i) dφ dθ dz dπ dω,
</equation>
<bodyText confidence="0.99990825">
in which we marginalize over the settings of all
tags other than yℓi (written as y−(ℓ,i)), the tran-
sition distributions φ = �φℓ �, emission distri-
�, superlingual tags z, and su-
</bodyText>
<equation confidence="0.888479">
t′
butions θ = �θℓ t′
perlingual tag parameters π = {π1, π2, ...} and
ω = {(ωℓ1
1 , ... , ωℓ&amp;quot;
1 ), (ωℓ1
2 , ... , ωℓ&amp;quot;
2 ) ...} (where t′
</equation>
<bodyText confidence="0.98925225">
ranges over all part-of-speech tags).
As these integrals are intractable to compute ex-
actly, we resort to the standard Monte Carlo approx-
imation. We collect N samples of the variables over
which we wish to marginalize but for which we can-
not compute closed-form integrals, where each sam-
ple samplek is drawn from P(samplekIx, a). We
then approximate the tag marginals as:
</bodyText>
<equation confidence="0.990863666666667">
Pk Pyℓ ��samplek, x, a~
P �yℓ i = t ~~x, a~ NLl i = t (4)
N
</equation>
<bodyText confidence="0.999981727272727">
We employ closed forms for integrating out the
emission parameters θ, transition parameters φ, and
superlingual tag parameters π and ω. We explic-
itly sample only part-of-speech tags y, superlingual
tags z, and the hyperparameters of the transition and
emission Dirichlet priors. To do so, we apply stan-
dard Markov chain sampling techniques: a Gibbs
sampler for the tags and a within-Gibbs Metropolis-
Hastings subroutine for the hyperparameters (Hast-
ings, 1970).
Our Gibbs sampler samples each part-of-speech
and superlingual tag separately, conditioned on the
current value of all other tags. In each case, we use
standard closed forms to integrate over all parameter
values, using currently sampled counts and hyperpa-
rameter pseudo-counts. We note that conjugacy is
technically broken by our use of a product form in
Distribution 1. Nevertheless, we consider the sam-
pled tags to have been generated separately by each
of the factors involved in the numerator. Thus our
method of using count-based closed forms should be
viewed as an approximation.
</bodyText>
<subsectionHeader confidence="0.999033">
3.6 Sampling Part-of-Speech Tags
</subsectionHeader>
<bodyText confidence="0.9997745">
To sample the part-of-speech tag for language ℓ at
position i we draw from
</bodyText>
<equation confidence="0.998089">
P(yℓi Iy−(ℓ,i), x, a, z) 0C
P(yℓi+1lyℓi,y−(ℓ,i), a, z) P(yℓi Iy−(ℓ,i), a, z)·
P(xℓi1xℓ −i,yℓ) ,
</equation>
<bodyText confidence="0.986913571428572">
where the first two terms are the generative proba-
bilities of (i) the current tag given the previous tag
and superlingual tags, and (ii) the next tag given the
current tag and superlingual tags. These two quan-
tities are similar to Distribution 1, except here we
integrate over the transition parameter φy,,−1 and the
superlingual tag parameters ωℓz. We end up with a
product of integrals. Each integral can be computed
in closed form using multinomial-Dirichlet conju-
gacy (and by making the above-mentioned simpli-
fying assumption that all other tags were gener-
ated separately by their transition and superlingual
argmax
tETe
</bodyText>
<page confidence="0.980715">
87
</page>
<bodyText confidence="0.998427">
parameters), just as in the monolingual Bayesian
HMM of (Goldwater and Griffiths, 2007).
For example, the closed form for integrating over
the parameter of a superlingual tag with value z is
given by:
</bodyText>
<equation confidence="0.991796">
J z= count(z, yi, E) + W0
Wℓ z(yi)P(Wℓ z|W0)dWℓ
count(z, E) + TℓW0
</equation>
<bodyText confidence="0.999957545454546">
where count(z, yi, E) is the number of times that tag
yi is observed together with superlingual tag z in
language E, count(z, E) is the total number of times
that superlingual tag z appears with an edge into lan-
guage E, and W0 is a hyperparameter.
The third term in the sampling formula is the
emission probability of the current word xℓi given
the current tag and all other words and sampled tags,
as well as a hyperparameter which is suppressed for
the sake of clarity. This quantity can be computed
exactly in closed form in a similar way.
</bodyText>
<subsectionHeader confidence="0.998752">
3.7 Sampling Superlingual Tags
</subsectionHeader>
<bodyText confidence="0.885355">
For each set of aligned words in the observed align-
ment a we need to sample a superlingual tag z.
Recall that z is an index into an infinite sequence
(Wℓ1
</bodyText>
<equation confidence="0.985442">
1 , ... , Wℓn
1 ), (Wℓ1
</equation>
<bodyText confidence="0.954696625">
2 , ... , Wℓn
2 ) ..., where each Wℓ z is
a distribution over the tagset Tℓ. The generative dis-
tribution over z is given by equation 2. In our sam-
pling scheme, however, we integrate over all possi-
ble settings of the mixing components π using the
standard Chinese Restaurant Process (CRP) closed
form (Antoniak, 1974):
</bodyText>
<equation confidence="0.98553325">
P(zi1z−i,y) a
� k1acount(zi) if zi E z−i
rJ P (yiℓ I z, y− (ℓ,i)) &apos; otherwise
ℓ k+α
</equation>
<bodyText confidence="0.999726875">
The first term is the product of closed form tag prob-
abilities of the aligned words, given z. The final term
is the standard CRP closed form for posterior sam-
pling from a Dirichlet process prior. In this term,
k is the total number of sampled superlingual tags,
count(zi) is the total number of times the value zi
occurs in the sampled tags, and α is the Dirichlet
process concentration parameter (see Step 2 in Sec-
tion 3.4).
Finally, we perform standard hyperparameter re-
estimation for the parameters of the Dirichlet distri-
bution priors on θ and φ (the transition and emis-
sion distributions) using Metropolis-Hastings. We
assume an improper uniform prior and use a Gaus-
sian proposal distribution with mean set to the pre-
vious value, and variance to one-tenth of the mean.
</bodyText>
<sectionHeader confidence="0.991998" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999990190476191">
We test our model in an unsupervised framework
where only raw parallel text is available for each
of the languages. In addition, we assume that for
each language a tag dictionary is available that cov-
ers some subset of words in the text. The task is to
learn an independent tagger for each language that
can annotate non-parallel raw text using the learned
parameters. All reported results are on non-parallel
monolingual test data.
Data For our experiments we use the Multext-
East parallel corpus (Erjavec, 2004) which has been
used before for multilingual learning (Feldman et
al., 2006; Snyder et al., 2008). The tagged portion of
the corpus includes a 100,000 word English text, Or-
well’s novel “Nineteen Eighty Four”, and its trans-
lation into seven languages: Bulgarian, Czech, Es-
tonian, Hungarian, Romanian, Slovene and Serbian.
The corpus also includes a tag lexicon for each of
these languages. We use the first 3/4 of the text for
learning and the last 1/4 as held-out non-parallel test
data.
The corpus provides sentence level alignments.
To obtain word level alignments, we run GIZA++
(Och and Ney, 2003) on all 28 pairings of the 8 lan-
guages. Since we want each latent superlingual vari-
able to span as many languages as possible, we ag-
gregate the pairwise lexical alignments into larger
sets of aligned words. These sets of aligned words
are generated as a preprocessing step. During sam-
pling they remain fixed and are treated as observed
data.
We use the set of 14 basic part-of-speech tags pro-
vided by the corpus. In our first experiment, we
assume that a complete tag lexicon is available, so
that for each word, its set of possible parts-of-speech
is known ahead of time. In this setting, the aver-
age number of possible tags per token is 1.39. We
also experimented with incomplete tag dictionaries,
where entries are only available for words appearing
more than five or ten times in the corpus. For other
words, the entire tagset of 14 tags is considered. In
these two scenarios, the average per-token tag ambi-
</bodyText>
<page confidence="0.997566">
88
</page>
<table confidence="0.998465083333333">
Lexicon: Full Lexicon: Frequency &gt; 5 Lexicon: Frequency &gt; 10
MONO BI MULTI MONO BI MULTI MONO BI MULTI
AVG BEST AVG BEST AVG BEST
BG 88.8 91.3 94.7 92.6 73.5 80.2 82.7 81.3 71.9 77.8 80.2 78.8
CS 93.7 97.0 97.7 98.2 72.2 79.0 79.7 83.0 66.7 75.3 76.7 79.4
EN 95.8 95.9 96.1 95.0 87.3 90.4 90.7 88.1 84.4 88.8 89.4 86.1
ET 92.5 93.4 94.3 94.6 72.5 76.5 77.5 80.6 68.3 72.9 74.9 77.9
HU 95.3 96.8 96.9 96.7 73.5 77.3 78.0 80.8 69.0 73.8 75.2 76.4
RO 90.1 91.8 94.0 95.1 77.1 82.7 84.4 86.1 73.0 80.5 82.1 83.1
SL 87.4 89.3 94.8 95.8 75.7 78.7 80.9 83.6 70.4 76.1 77.6 80.0
SR 84.5 90.2 94.5 92.3 66.3 75.9 79.4 78.8 63.7 72.4 76.1 75.9
Avg. 91.0 93.2 95.4 95.0 74.7 80.1 81.7 82.8 70.9 77.2 79.0 79.7
</table>
<tableCaption confidence="0.999851">
Table 1: Tagging accuracy for Bulgarian, Czech, English, Estonian, Hungarian, Romanian, Slovene, and Serbian. In
</tableCaption>
<bodyText confidence="0.97919026923077">
the first scenario, a complete tag lexicon is available for all the words. In the other two scenarios the tag lexicon
only includes words that appear more than five or ten times. Results are given for a monolingual Bayesian HMM
(Goldwater and Griffiths, 2007), a bilingual model (Snyder et al., 2008), and the multilingual model presented here.
In the case of the bilingual model, we present both the average accuracy over all pairings as well as the result from the
best performing pairing for each language. The best results for each language in each scenario are given in boldface.
guity is 4.65 and 5.58, respectively.
Training and testing In the full lexicon ex-
periment, each word is initialized with a random
part-of-speech tag from its dictionary entry. In the
two reduced lexicon experiments, we initialize the
tags with the result of our monolingual baseline (see
below) to reduce sampling time. In both cases,
we begin with 14 superlingual tag values — corre-
sponding to the parts-of-speech — and initially as-
sign them based on the most common initial part-of-
speech of words in each alignment.
We run our Gibbs sampler for 1,000 iterations,
and store the conditional tag probabilities for the last
100 iterations. We then approximate marginal tag
probabilities on the training data using Equation 4
and predict the highest probability tags. Finally, we
compute maximum likelihood transition and emis-
sion probabilities using these tag counts, and then
apply smoothed viterbi decoding to each held-out
monolingual test set. All reported results are aver-
aged over five runs of the sampler.
Monolingual and bilingual baselines We
reimplemented the Bayesian HMM model of Gold-
water and Griffiths (2007) (BHMM1) as our mono-
lingual baseline. It has a standard HMM structure
with conjugate Bayesian priors over transitions and
emissions. We note that our model, in the absence
of any superlingual tags, reduces to this Bayesian
HMM. As an additional baseline we use a bilingual
model (Snyder et al., 2008). It is a directed graphical
model that jointly tags two parallel streams of text
aligned at the word level. The structure of the model
consists of two parallel HMMs, one for each lan-
guage. The aligned words form joint nodes that are
shared by both HMMs. These joint nodes are sam-
pled from a probability distribution that is a prod-
uct of the transition and emission distributions in the
two languages and a coupling distribution.
We note that the numbers reported here for
the bilingual model differ slightly from those re-
ported by Snyder et al. (2008) for two reasons: we
use a slightly larger set of sentences, and an im-
proved sampling scheme. The new sampling scheme
marginalizes over the transition and coupling param-
eters by using the same count-based approximation
that we utilize for our multilingual model. This leads
to higher performance, and thus a stronger baseline.1
</bodyText>
<sectionHeader confidence="0.999962" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999896666666667">
Table 1 shows the tagging accuracy of our multilin-
gual model on the test data, when training is per-
formed on all eight languages together. Results from
both baselines are also reported. In the case of the
bilingual baseline, seven pairings are possible for
each language, and the results vary by pair. There-
</bodyText>
<footnote confidence="0.999547333333333">
1Another difference is that we use the English lexicon pro-
vided with the Multext-East corpus, whereas (Snyder et al.,
2008) augment this lexicon with tags found in WSJ.
</footnote>
<page confidence="0.999649">
89
</page>
<bodyText confidence="0.999980104166667">
fore, for each language, we present the average accu-
racy over all seven pairings, as well as the accuracy
of its highest performing pairing.
We provide results for three scenarios. In the first
case, a tag dictionary is provided for all words, lim-
iting them to a restricted set of possible tags. In the
other two scenarios, dictionary entries are limited to
words that appear more than five or ten times in the
corpus. All other words can be assigned any tag,
increasing the overall difficulty of the task. In the
full lexicon scenario, our model achieves an average
tagging accuracy of 95%, compared to 91% for the
monolingual baseline and 93.2% for the bilingual
baseline when averaged over all pairings. This ac-
curacy (95%) comes close to the performance of the
bilingual model when the best pairing for each lan-
guage is chosen by an oracle (95.4%). This demon-
strates that our multilingual model is able to effec-
tively learn from all languages. In the two reduced
lexicon scenarios, the gains are even more striking.
In both cases the average multilingual performance
outpaces even the best performing pairs.
Looking at individual languages, we see that in
all three scenarios, Czech, Estonian, Romanian, and
Slovene show their best performance with the mul-
tilingual model. Bulgarian and Serbian, on the
other hand, give somewhat better performance with
their optimal pairings under the bilingual model, but
their multilingual performance remains higher than
their average bilingual results. The performance of
English under the multilingual model is somewhat
lower, especially in the full lexicon scenario, where
it drops below monolingual performance. One pos-
sible explanation for this decrease lies in the fact that
English, by far, has the lowest trigram tag entropy of
all eight languages (Snyder et al., 2008). It is pos-
sible, therefore, that the signal it should be getting
from its own transitions is being drowned out by less
reliable information from other languages.
In order to test the performance of our model as
the number of languages increases, we ran the full
lexicon experiment with all possible subsets of the
eight languages. Figure 2 plots the average accuracy
as the number of languages varies. For comparison,
the monolingual and average bilingual baseline re-
sults are given, along with supervised monolingual
performance. Our multilingual model steadily gains
in accuracy as the number of available languages in-
</bodyText>
<figureCaption confidence="0.993048">
Figure 2: Performance of the multilingual model as the
number of languages varies. Performance of the mono-
lingual and average bilingual baselines as well as a su-
pervised monolingual performance are given for compar-
ison.
</figureCaption>
<bodyText confidence="0.99980475">
creases. Interestingly, it even outperforms the bilin-
gual baseline (by a small margin) when only two lan-
guages are available, which may be attributable to
the more flexible non-parametric dependencies em-
ployed here. Finally, notice that the gap between
monolingual supervised and unsupervised perfor-
mance is cut by nearly two thirds under the unsu-
pervised multilingual model.
</bodyText>
<sectionHeader confidence="0.999513" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999829818181818">
In this paper we’ve demonstrated that the benefits of
unsupervised multilingual learning increase steadily
with the number of available languages. Our model
scales gracefully as languages are added and effec-
tively incorporates information from them all, lead-
ing to substantial performance gains. In one experi-
ment, we cut the gap between unsupervised and su-
pervised performance by nearly two thirds. A fu-
ture challenge lies in incorporating constraints from
additional languages even when parallel text is un-
available.
</bodyText>
<sectionHeader confidence="0.998837" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9846185">
The authors acknowledge the support of the National Sci-
ence Foundation (CAREER grant IIS-0448168 and grant IIS-
0835445). Thanks to Tommi Jaakkola and members of the
MIT NLP group for helpful discussions. Any opinions, find-
ings, or recommendations expressed above are those of the au-
thors and do not necessarily reflect the views of the NSF.
</bodyText>
<page confidence="0.997112">
90
</page>
<sectionHeader confidence="0.993893" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999896434782609">
C. E. Antoniak. 1974. Mixtures of Dirichlet processes
with applications to Bayesian nonparametric prob-
lems. The Annals of Statistics, 2:1152–1174, Novem-
ber.
Trevor Cohn and Mirella Lapata. 2007. Machine trans-
lation by triangulation: Making effective use of multi-
parallel corpora. In Proceedings ofACL.
T. Erjavec. 2004. MULTEXT-East version 3: Multi-
lingual morphosyntactic specifications, lexicons and
corpora. In Fourth International Conference on Lan-
guage Resources and Evaluation, LREC, volume 4,
pages 1535–1538.
Anna Feldman, Jirka Hana, and Chris Brew. 2006.
A cross-language approach to rapid creation of new
morpho-syntactically annotated resources. In Pro-
ceedings ofLREC, pages 549–554.
Dmitriy Genzel. 2005. Inducing a multilingual dictio-
nary from a parallel multitext in related languages. In
Proceedings of the HLT/EMNLP, pages 875–882.
Sharon Goldwater and Thomas L. Griffiths. 2007.
A fully Bayesian approach to unsupervised part-of-
speech tagging. In Proceedings of the ACL, pages
744–751.
W. K. Hastings. 1970. Monte Carlo sampling meth-
ods using Markov chains and their applications.
Biometrika, 57:97–109.
Franz Josef Och and Hermann Ney. 2001. Statistical
multi-source translation. In MT Summit 2001, pages
253–258.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
J. Sethuraman. 1994. A constructive definition of Dirich-
let priors. Statistica Sinica, 4:639–650.
Benjamin Snyder, Tahira Naseem, Jacob Eisenstein, and
Regina Barzilay. 2008. Unsupervised multilingual
learning for POS tagging. In Proceedings of the
EMNLP, pages 1041–1050.
Masao Utiyama and Hitoshi Isahara. 2006. A com-
parison of pivot methods for phrase-based statistical
machine translation. In Proceedings of NAACL/HLT,
pages 484–491.
David Yarowsky and Grace Ngai. 2001. Inducing multi-
lingual POS taggers and NP bracketers via robust pro-
jection across aligned corpora. In Proceedings of the
NAACL, pages 1–8.
</reference>
<page confidence="0.999171">
91
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.844782">
<title confidence="0.992216">Adding More Languages Improves Unsupervised Part-of-Speech Tagging: A Bayesian Non-Parametric Approach</title>
<author confidence="0.997458">Tahira Naseem Snyder</author>
<author confidence="0.997458">Jacob Eisenstein</author>
<affiliation confidence="0.9748115">Computer Science and Artificial Intelligence Massachusetts Institute of</affiliation>
<email confidence="0.935342">tahira,jacobe,</email>
<abstract confidence="0.997452384615385">We investigate the problem of unsupervised part-of-speech tagging when raw parallel data is available in a large number of languages. Patterns of ambiguity vary greatly across languages and therefore even unannotated multilingual data can serve as a learning signal. We propose a non-parametric Bayesian model that connects related tagging decisions across languages through the use of multilingual latent variables. Our experiments show that performance improves steadily as the number of languages increases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C E Antoniak</author>
</authors>
<title>Mixtures of Dirichlet processes with applications to Bayesian nonparametric problems. The Annals of Statistics,</title>
<date>1974</date>
<pages>2--1152</pages>
<contexts>
<context position="20075" citStr="Antoniak, 1974" startWordPosition="3312" endWordPosition="3313"> sake of clarity. This quantity can be computed exactly in closed form in a similar way. 3.7 Sampling Superlingual Tags For each set of aligned words in the observed alignment a we need to sample a superlingual tag z. Recall that z is an index into an infinite sequence (Wℓ1 1 , ... , Wℓn 1 ), (Wℓ1 2 , ... , Wℓn 2 ) ..., where each Wℓ z is a distribution over the tagset Tℓ. The generative distribution over z is given by equation 2. In our sampling scheme, however, we integrate over all possible settings of the mixing components π using the standard Chinese Restaurant Process (CRP) closed form (Antoniak, 1974): P(zi1z−i,y) a � k1acount(zi) if zi E z−i rJ P (yiℓ I z, y− (ℓ,i)) &apos; otherwise ℓ k+α The first term is the product of closed form tag probabilities of the aligned words, given z. The final term is the standard CRP closed form for posterior sampling from a Dirichlet process prior. In this term, k is the total number of sampled superlingual tags, count(zi) is the total number of times the value zi occurs in the sampled tags, and α is the Dirichlet process concentration parameter (see Step 2 in Section 3.4). Finally, we perform standard hyperparameter reestimation for the parameters of the Diric</context>
</contexts>
<marker>Antoniak, 1974</marker>
<rawString>C. E. Antoniak. 1974. Mixtures of Dirichlet processes with applications to Bayesian nonparametric problems. The Annals of Statistics, 2:1152–1174, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Machine translation by triangulation: Making effective use of multiparallel corpora.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="6500" citStr="Cohn and Lapata, 2007" startWordPosition="985" endWordPosition="988">Beyond Bilingual Learning While most work on multilingual learning focuses on bilingual analysis, some models operate on more than one pair of languages. For instance, Genzel (2005) describes a method for inducing a multilingual lexicon from a group of related languages. His model first induces bilingual models for each pair of languages and then combines them. Our work takes a different approach by simultaneously learning from all languages, rather than combining bilingual results. A related thread of research is multi-source machine translation (Och and Ney, 2001; Utiyama and Isahara, 2006; Cohn and Lapata, 2007) where the goal is to translate from multiple source languages to a single target language. Rather than jointly training all the languages together, these models train bilingual models separately, and then use their output to select a final translation. The selection criterion can be learned at training time since these models have access to the correct translation. In unsupervised settings, however, we do not have a principled means for selecting among outputs of different bilingual models. By developing a joint multilingual model we can automatically achieve performance that rivals that of t</context>
</contexts>
<marker>Cohn, Lapata, 2007</marker>
<rawString>Trevor Cohn and Mirella Lapata. 2007. Machine translation by triangulation: Making effective use of multiparallel corpora. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Erjavec</author>
</authors>
<title>MULTEXT-East version 3: Multilingual morphosyntactic specifications, lexicons and corpora.</title>
<date>2004</date>
<booktitle>In Fourth International Conference on Language Resources and Evaluation, LREC,</booktitle>
<volume>4</volume>
<pages>1535--1538</pages>
<contexts>
<context position="21468" citStr="Erjavec, 2004" startWordPosition="3554" endWordPosition="3555">tion with mean set to the previous value, and variance to one-tenth of the mean. 4 Experimental Setup We test our model in an unsupervised framework where only raw parallel text is available for each of the languages. In addition, we assume that for each language a tag dictionary is available that covers some subset of words in the text. The task is to learn an independent tagger for each language that can annotate non-parallel raw text using the learned parameters. All reported results are on non-parallel monolingual test data. Data For our experiments we use the MultextEast parallel corpus (Erjavec, 2004) which has been used before for multilingual learning (Feldman et al., 2006; Snyder et al., 2008). The tagged portion of the corpus includes a 100,000 word English text, Orwell’s novel “Nineteen Eighty Four”, and its translation into seven languages: Bulgarian, Czech, Estonian, Hungarian, Romanian, Slovene and Serbian. The corpus also includes a tag lexicon for each of these languages. We use the first 3/4 of the text for learning and the last 1/4 as held-out non-parallel test data. The corpus provides sentence level alignments. To obtain word level alignments, we run GIZA++ (Och and Ney, 2003</context>
</contexts>
<marker>Erjavec, 2004</marker>
<rawString>T. Erjavec. 2004. MULTEXT-East version 3: Multilingual morphosyntactic specifications, lexicons and corpora. In Fourth International Conference on Language Resources and Evaluation, LREC, volume 4, pages 1535–1538.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Feldman</author>
<author>Jirka Hana</author>
<author>Chris Brew</author>
</authors>
<title>A cross-language approach to rapid creation of new morpho-syntactically annotated resources.</title>
<date>2006</date>
<booktitle>In Proceedings ofLREC,</booktitle>
<pages>549--554</pages>
<contexts>
<context position="4648" citStr="Feldman et al., 2006" startWordPosition="703" endWordPosition="706"> monolingual performance is cut by nearly two thirds. We also examined scenarios where the tag lexicon is reduced in size. In all cases, the multilingual model yielded substantial performance gains. Finally, we examined the performance of our model when trained on all possible subsets of the eight languages. We found that performance improves steadily as the number of available languages increases. 2 Related Work Bilingual Part-of-Speech Tagging Early work on multilingual tagging focused on projecting annotations from an annotated source language to a target language (Yarowsky and Ngai, 2001; Feldman et al., 2006). In contrast, we assume no labeled data at all; our unsupervised model instead symmetrically improves performance for all languages by learning cross-lingual patterns in raw parallel data. An additional distinction is that projection-based work utilizes pairs of languages, while our approach allows for continuous improvement as languages are added to the mix. In recent work, Snyder et al. (2008) presented a model for unsupervised part-of-speech tagging trained from a bilingual parallel corpus. This bilingual model and the model presented here share a number of similarities: both are Bayesian </context>
<context position="21543" citStr="Feldman et al., 2006" startWordPosition="3564" endWordPosition="3567">f the mean. 4 Experimental Setup We test our model in an unsupervised framework where only raw parallel text is available for each of the languages. In addition, we assume that for each language a tag dictionary is available that covers some subset of words in the text. The task is to learn an independent tagger for each language that can annotate non-parallel raw text using the learned parameters. All reported results are on non-parallel monolingual test data. Data For our experiments we use the MultextEast parallel corpus (Erjavec, 2004) which has been used before for multilingual learning (Feldman et al., 2006; Snyder et al., 2008). The tagged portion of the corpus includes a 100,000 word English text, Orwell’s novel “Nineteen Eighty Four”, and its translation into seven languages: Bulgarian, Czech, Estonian, Hungarian, Romanian, Slovene and Serbian. The corpus also includes a tag lexicon for each of these languages. We use the first 3/4 of the text for learning and the last 1/4 as held-out non-parallel test data. The corpus provides sentence level alignments. To obtain word level alignments, we run GIZA++ (Och and Ney, 2003) on all 28 pairings of the 8 languages. Since we want each latent superlin</context>
</contexts>
<marker>Feldman, Hana, Brew, 2006</marker>
<rawString>Anna Feldman, Jirka Hana, and Chris Brew. 2006. A cross-language approach to rapid creation of new morpho-syntactically annotated resources. In Proceedings ofLREC, pages 549–554.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitriy Genzel</author>
</authors>
<title>Inducing a multilingual dictionary from a parallel multitext in related languages.</title>
<date>2005</date>
<booktitle>In Proceedings of the HLT/EMNLP,</booktitle>
<pages>875--882</pages>
<contexts>
<context position="6059" citStr="Genzel (2005)" startWordPosition="917" endWordPosition="918">ws exponentially in the number of languages. In addition, crossing alignments must be removed so that the resulting graph structure remains acyclic. In contrast, our multilingual model posits latent cross-lingual tags without explicitly joining or directly connecting the part-of-speech tags across languages. Besides permitting crossing alignments, this structure allows the model to scale gracefully with the number of languages. Beyond Bilingual Learning While most work on multilingual learning focuses on bilingual analysis, some models operate on more than one pair of languages. For instance, Genzel (2005) describes a method for inducing a multilingual lexicon from a group of related languages. His model first induces bilingual models for each pair of languages and then combines them. Our work takes a different approach by simultaneously learning from all languages, rather than combining bilingual results. A related thread of research is multi-source machine translation (Och and Ney, 2001; Utiyama and Isahara, 2006; Cohn and Lapata, 2007) where the goal is to translate from multiple source languages to a single target language. Rather than jointly training all the languages together, these mode</context>
</contexts>
<marker>Genzel, 2005</marker>
<rawString>Dmitriy Genzel. 2005. Inducing a multilingual dictionary from a parallel multitext in related languages. In Proceedings of the HLT/EMNLP, pages 875–882.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Thomas L Griffiths</author>
</authors>
<title>A fully Bayesian approach to unsupervised part-ofspeech tagging.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>744--751</pages>
<contexts>
<context position="18825" citStr="Goldwater and Griffiths, 2007" startWordPosition="3074" endWordPosition="3077">en the previous tag and superlingual tags, and (ii) the next tag given the current tag and superlingual tags. These two quantities are similar to Distribution 1, except here we integrate over the transition parameter φy,,−1 and the superlingual tag parameters ωℓz. We end up with a product of integrals. Each integral can be computed in closed form using multinomial-Dirichlet conjugacy (and by making the above-mentioned simplifying assumption that all other tags were generated separately by their transition and superlingual argmax tETe 87 parameters), just as in the monolingual Bayesian HMM of (Goldwater and Griffiths, 2007). For example, the closed form for integrating over the parameter of a superlingual tag with value z is given by: J z= count(z, yi, E) + W0 Wℓ z(yi)P(Wℓ z|W0)dWℓ count(z, E) + TℓW0 where count(z, yi, E) is the number of times that tag yi is observed together with superlingual tag z in language E, count(z, E) is the total number of times that superlingual tag z appears with an edge into language E, and W0 is a hyperparameter. The third term in the sampling formula is the emission probability of the current word xℓi given the current tag and all other words and sampled tags, as well as a hyperpa</context>
<context position="24054" citStr="Goldwater and Griffiths, 2007" startWordPosition="4013" endWordPosition="4016">6.4 RO 90.1 91.8 94.0 95.1 77.1 82.7 84.4 86.1 73.0 80.5 82.1 83.1 SL 87.4 89.3 94.8 95.8 75.7 78.7 80.9 83.6 70.4 76.1 77.6 80.0 SR 84.5 90.2 94.5 92.3 66.3 75.9 79.4 78.8 63.7 72.4 76.1 75.9 Avg. 91.0 93.2 95.4 95.0 74.7 80.1 81.7 82.8 70.9 77.2 79.0 79.7 Table 1: Tagging accuracy for Bulgarian, Czech, English, Estonian, Hungarian, Romanian, Slovene, and Serbian. In the first scenario, a complete tag lexicon is available for all the words. In the other two scenarios the tag lexicon only includes words that appear more than five or ten times. Results are given for a monolingual Bayesian HMM (Goldwater and Griffiths, 2007), a bilingual model (Snyder et al., 2008), and the multilingual model presented here. In the case of the bilingual model, we present both the average accuracy over all pairings as well as the result from the best performing pairing for each language. The best results for each language in each scenario are given in boldface. guity is 4.65 and 5.58, respectively. Training and testing In the full lexicon experiment, each word is initialized with a random part-of-speech tag from its dictionary entry. In the two reduced lexicon experiments, we initialize the tags with the result of our monolingual </context>
<context position="25500" citStr="Goldwater and Griffiths (2007)" startWordPosition="4245" endWordPosition="4249">of words in each alignment. We run our Gibbs sampler for 1,000 iterations, and store the conditional tag probabilities for the last 100 iterations. We then approximate marginal tag probabilities on the training data using Equation 4 and predict the highest probability tags. Finally, we compute maximum likelihood transition and emission probabilities using these tag counts, and then apply smoothed viterbi decoding to each held-out monolingual test set. All reported results are averaged over five runs of the sampler. Monolingual and bilingual baselines We reimplemented the Bayesian HMM model of Goldwater and Griffiths (2007) (BHMM1) as our monolingual baseline. It has a standard HMM structure with conjugate Bayesian priors over transitions and emissions. We note that our model, in the absence of any superlingual tags, reduces to this Bayesian HMM. As an additional baseline we use a bilingual model (Snyder et al., 2008). It is a directed graphical model that jointly tags two parallel streams of text aligned at the word level. The structure of the model consists of two parallel HMMs, one for each language. The aligned words form joint nodes that are shared by both HMMs. These joint nodes are sampled from a probabil</context>
</contexts>
<marker>Goldwater, Griffiths, 2007</marker>
<rawString>Sharon Goldwater and Thomas L. Griffiths. 2007. A fully Bayesian approach to unsupervised part-ofspeech tagging. In Proceedings of the ACL, pages 744–751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W K Hastings</author>
</authors>
<title>Monte Carlo sampling methods using Markov chains and their applications.</title>
<date>1970</date>
<journal>Biometrika,</journal>
<pages>57--97</pages>
<contexts>
<context position="17317" citStr="Hastings, 1970" startWordPosition="2833" endWordPosition="2835">re each sample samplek is drawn from P(samplekIx, a). We then approximate the tag marginals as: Pk Pyℓ ��samplek, x, a~ P �yℓ i = t ~~x, a~ NLl i = t (4) N We employ closed forms for integrating out the emission parameters θ, transition parameters φ, and superlingual tag parameters π and ω. We explicitly sample only part-of-speech tags y, superlingual tags z, and the hyperparameters of the transition and emission Dirichlet priors. To do so, we apply standard Markov chain sampling techniques: a Gibbs sampler for the tags and a within-Gibbs MetropolisHastings subroutine for the hyperparameters (Hastings, 1970). Our Gibbs sampler samples each part-of-speech and superlingual tag separately, conditioned on the current value of all other tags. In each case, we use standard closed forms to integrate over all parameter values, using currently sampled counts and hyperparameter pseudo-counts. We note that conjugacy is technically broken by our use of a product form in Distribution 1. Nevertheless, we consider the sampled tags to have been generated separately by each of the factors involved in the numerator. Thus our method of using count-based closed forms should be viewed as an approximation. 3.6 Samplin</context>
</contexts>
<marker>Hastings, 1970</marker>
<rawString>W. K. Hastings. 1970. Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57:97–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Statistical multi-source translation.</title>
<date>2001</date>
<booktitle>In MT Summit</booktitle>
<pages>253--258</pages>
<contexts>
<context position="6449" citStr="Och and Ney, 2001" startWordPosition="977" endWordPosition="980">cale gracefully with the number of languages. Beyond Bilingual Learning While most work on multilingual learning focuses on bilingual analysis, some models operate on more than one pair of languages. For instance, Genzel (2005) describes a method for inducing a multilingual lexicon from a group of related languages. His model first induces bilingual models for each pair of languages and then combines them. Our work takes a different approach by simultaneously learning from all languages, rather than combining bilingual results. A related thread of research is multi-source machine translation (Och and Ney, 2001; Utiyama and Isahara, 2006; Cohn and Lapata, 2007) where the goal is to translate from multiple source languages to a single target language. Rather than jointly training all the languages together, these models train bilingual models separately, and then use their output to select a final translation. The selection criterion can be learned at training time since these models have access to the correct translation. In unsupervised settings, however, we do not have a principled means for selecting among outputs of different bilingual models. By developing a joint multilingual model we can auto</context>
</contexts>
<marker>Och, Ney, 2001</marker>
<rawString>Franz Josef Och and Hermann Ney. 2001. Statistical multi-source translation. In MT Summit 2001, pages 253–258.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="22069" citStr="Och and Ney, 2003" startWordPosition="3651" endWordPosition="3654">s (Erjavec, 2004) which has been used before for multilingual learning (Feldman et al., 2006; Snyder et al., 2008). The tagged portion of the corpus includes a 100,000 word English text, Orwell’s novel “Nineteen Eighty Four”, and its translation into seven languages: Bulgarian, Czech, Estonian, Hungarian, Romanian, Slovene and Serbian. The corpus also includes a tag lexicon for each of these languages. We use the first 3/4 of the text for learning and the last 1/4 as held-out non-parallel test data. The corpus provides sentence level alignments. To obtain word level alignments, we run GIZA++ (Och and Ney, 2003) on all 28 pairings of the 8 languages. Since we want each latent superlingual variable to span as many languages as possible, we aggregate the pairwise lexical alignments into larger sets of aligned words. These sets of aligned words are generated as a preprocessing step. During sampling they remain fixed and are treated as observed data. We use the set of 14 basic part-of-speech tags provided by the corpus. In our first experiment, we assume that a complete tag lexicon is available, so that for each word, its set of possible parts-of-speech is known ahead of time. In this setting, the averag</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Sethuraman</author>
</authors>
<title>A constructive definition of Dirichlet priors.</title>
<date>1994</date>
<journal>Statistica Sinica,</journal>
<pages>4--639</pages>
<contexts>
<context position="11575" citStr="Sethuraman, 1994" startWordPosition="1809" endWordPosition="1810"> tags. This prior allows high posterior probability only when a small number 85 of values are used repeatedly. The actual number of sampled values will be dictated by the data and the number of languages. More formally, suppose we have n languages, ℓ1, ... , ℓn. According to our generative model, a countably infinite sequence of sets hωℓ1 1 , ... , ωℓn 1 i, hωℓ1 2 , ... , ωℓn 2 i, ... is drawn from some base distribution. Each ωℓi is a distribution over the parts-of-speech in language ℓ. In parallel, an infinite sequence of mixing components π1, π2, ... is drawn from a stick-breaking process (Sethuraman, 1994). These components define a distribution over the integers with most probability mass placed on some initial set of values. The two sequences hωℓ1 1 , . . . , ωℓn 1 i, hωℓ1 2 , . . . , ωℓn 2 i . . . and π1, π2 ... now define the distribution over superlingual tags and their associated distributions on parts-of-speech. That is, each superlingual tag z ∈ N is drawn with probability πz, and indexes the set of distributions hωℓ1 z , ... , ωℓn z i. 3.3 Part-of-Speech Tags Finally, we need to define the generative probabilities of the part-of-speech nodes. For each such node there may be multiple in</context>
<context position="14449" citStr="Sethuraman, 1994" startWordPosition="2312" endWordPosition="2313"> tags Tℓ and an emission distribution θℓ t over words Wℓ, all from symmetric Dirichlet priors of appropriate dimension. 2. Superlingual Tag Parameters: Draw an infinite sequence of sets hωℓ1 1 , . . . ,ωℓn 1 i, hωℓ1 2 , ... , ωℓn 2 i, ... from base distribution G0. Each ωℓi is a distribution over the tagset Tℓ. The base distribution G0 is a product of n symmetric Dirichlets, where the dimension of the ith such Dirichlet is the size of the corresponding tagset Tℓi. At the same time, draw an infinite sequence of mixture weights π ∼ GEM(α), where GEM(α) indicates the stick-breaking distribution (Sethuraman, 1994), and α = 1. These parameters together define a prior distribution over superlingual tags, 00 p(z) = πkδk=z, (2) k or equivalently over the part-of-speech distributions hωℓ1, ... , ωℓni that they index: πkδ(ω;1,... ω;n)=(ωℓ1,...,ωℓn ). (3) In both cases, δv=v′ is defined as one when v = v′ and zero otherwise. Distribution 3 is said to be drawn from a Dirichlet process, conventionally written as DP(α, G0). yi ∼ 00 E k 86 3. Data: For each multilingual parallel sentence, (a) Draw an alignment a specifying sets of aligned indices across languages. Each such set may consist of indices in any subse</context>
</contexts>
<marker>Sethuraman, 1994</marker>
<rawString>J. Sethuraman. 1994. A constructive definition of Dirichlet priors. Statistica Sinica, 4:639–650.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Tahira Naseem</author>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Unsupervised multilingual learning for POS tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of the EMNLP,</booktitle>
<pages>1041--1050</pages>
<contexts>
<context position="1697" citStr="Snyder et al., 2008" startWordPosition="247" endWordPosition="250">at scales well and shows improved performance for individual languages as the total number of languages increases. Languages exhibit ambiguity at multiple levels, making unsupervised induction of their underlying structure a difficult task. However, sources of linguistic ambiguity vary across languages. For example, the word fish in English can be used as either a verb or a noun. In French, however, the noun poisson (fish) is entirely distinct from the verbal form pˆecher (to fish). Previous work has leveraged this idea by building models for unsupervised learning from aligned bilingual data (Snyder et al., 2008). However, aligned data is often available for many languages. The benefits of bilingual learning vary 83 markedly depending on which pair of languages is selected, and without labeled data it is unclear how to determine which supplementary language is most helpful. In this paper, we show that it is possible to leverage all aligned languages simultaneously, achieving accuracy that in most cases outperforms even optimally chosen bilingual pairings. Even in expressing the same meaning, languages take different syntactic routes, leading to variation in part-of-speech sequences. Therefore, an effe</context>
<context position="5047" citStr="Snyder et al. (2008)" startWordPosition="764" endWordPosition="767">. 2 Related Work Bilingual Part-of-Speech Tagging Early work on multilingual tagging focused on projecting annotations from an annotated source language to a target language (Yarowsky and Ngai, 2001; Feldman et al., 2006). In contrast, we assume no labeled data at all; our unsupervised model instead symmetrically improves performance for all languages by learning cross-lingual patterns in raw parallel data. An additional distinction is that projection-based work utilizes pairs of languages, while our approach allows for continuous improvement as languages are added to the mix. In recent work, Snyder et al. (2008) presented a model for unsupervised part-of-speech tagging trained from a bilingual parallel corpus. This bilingual model and the model presented here share a number of similarities: both are Bayesian graphical models building upon hidden Markov models. However, the bilingual model explicitly joins each aligned word-pair into a single coupled state. Thus, the state-space of these joined nodes grows exponentially in the number of languages. In addition, crossing alignments must be removed so that the resulting graph structure remains acyclic. In contrast, our multilingual model posits latent cr</context>
<context position="21565" citStr="Snyder et al., 2008" startWordPosition="3568" endWordPosition="3571">ntal Setup We test our model in an unsupervised framework where only raw parallel text is available for each of the languages. In addition, we assume that for each language a tag dictionary is available that covers some subset of words in the text. The task is to learn an independent tagger for each language that can annotate non-parallel raw text using the learned parameters. All reported results are on non-parallel monolingual test data. Data For our experiments we use the MultextEast parallel corpus (Erjavec, 2004) which has been used before for multilingual learning (Feldman et al., 2006; Snyder et al., 2008). The tagged portion of the corpus includes a 100,000 word English text, Orwell’s novel “Nineteen Eighty Four”, and its translation into seven languages: Bulgarian, Czech, Estonian, Hungarian, Romanian, Slovene and Serbian. The corpus also includes a tag lexicon for each of these languages. We use the first 3/4 of the text for learning and the last 1/4 as held-out non-parallel test data. The corpus provides sentence level alignments. To obtain word level alignments, we run GIZA++ (Och and Ney, 2003) on all 28 pairings of the 8 languages. Since we want each latent superlingual variable to span </context>
<context position="24095" citStr="Snyder et al., 2008" startWordPosition="4020" endWordPosition="4023"> 80.5 82.1 83.1 SL 87.4 89.3 94.8 95.8 75.7 78.7 80.9 83.6 70.4 76.1 77.6 80.0 SR 84.5 90.2 94.5 92.3 66.3 75.9 79.4 78.8 63.7 72.4 76.1 75.9 Avg. 91.0 93.2 95.4 95.0 74.7 80.1 81.7 82.8 70.9 77.2 79.0 79.7 Table 1: Tagging accuracy for Bulgarian, Czech, English, Estonian, Hungarian, Romanian, Slovene, and Serbian. In the first scenario, a complete tag lexicon is available for all the words. In the other two scenarios the tag lexicon only includes words that appear more than five or ten times. Results are given for a monolingual Bayesian HMM (Goldwater and Griffiths, 2007), a bilingual model (Snyder et al., 2008), and the multilingual model presented here. In the case of the bilingual model, we present both the average accuracy over all pairings as well as the result from the best performing pairing for each language. The best results for each language in each scenario are given in boldface. guity is 4.65 and 5.58, respectively. Training and testing In the full lexicon experiment, each word is initialized with a random part-of-speech tag from its dictionary entry. In the two reduced lexicon experiments, we initialize the tags with the result of our monolingual baseline (see below) to reduce sampling t</context>
<context position="25800" citStr="Snyder et al., 2008" startWordPosition="4296" endWordPosition="4299">ood transition and emission probabilities using these tag counts, and then apply smoothed viterbi decoding to each held-out monolingual test set. All reported results are averaged over five runs of the sampler. Monolingual and bilingual baselines We reimplemented the Bayesian HMM model of Goldwater and Griffiths (2007) (BHMM1) as our monolingual baseline. It has a standard HMM structure with conjugate Bayesian priors over transitions and emissions. We note that our model, in the absence of any superlingual tags, reduces to this Bayesian HMM. As an additional baseline we use a bilingual model (Snyder et al., 2008). It is a directed graphical model that jointly tags two parallel streams of text aligned at the word level. The structure of the model consists of two parallel HMMs, one for each language. The aligned words form joint nodes that are shared by both HMMs. These joint nodes are sampled from a probability distribution that is a product of the transition and emission distributions in the two languages and a coupling distribution. We note that the numbers reported here for the bilingual model differ slightly from those reported by Snyder et al. (2008) for two reasons: we use a slightly larger set o</context>
<context position="27120" citStr="Snyder et al., 2008" startWordPosition="4520" endWordPosition="4523">on and coupling parameters by using the same count-based approximation that we utilize for our multilingual model. This leads to higher performance, and thus a stronger baseline.1 5 Results Table 1 shows the tagging accuracy of our multilingual model on the test data, when training is performed on all eight languages together. Results from both baselines are also reported. In the case of the bilingual baseline, seven pairings are possible for each language, and the results vary by pair. There1Another difference is that we use the English lexicon provided with the Multext-East corpus, whereas (Snyder et al., 2008) augment this lexicon with tags found in WSJ. 89 fore, for each language, we present the average accuracy over all seven pairings, as well as the accuracy of its highest performing pairing. We provide results for three scenarios. In the first case, a tag dictionary is provided for all words, limiting them to a restricted set of possible tags. In the other two scenarios, dictionary entries are limited to words that appear more than five or ten times in the corpus. All other words can be assigned any tag, increasing the overall difficulty of the task. In the full lexicon scenario, our model achi</context>
<context position="28987" citStr="Snyder et al., 2008" startWordPosition="4825" endWordPosition="4828">Romanian, and Slovene show their best performance with the multilingual model. Bulgarian and Serbian, on the other hand, give somewhat better performance with their optimal pairings under the bilingual model, but their multilingual performance remains higher than their average bilingual results. The performance of English under the multilingual model is somewhat lower, especially in the full lexicon scenario, where it drops below monolingual performance. One possible explanation for this decrease lies in the fact that English, by far, has the lowest trigram tag entropy of all eight languages (Snyder et al., 2008). It is possible, therefore, that the signal it should be getting from its own transitions is being drowned out by less reliable information from other languages. In order to test the performance of our model as the number of languages increases, we ran the full lexicon experiment with all possible subsets of the eight languages. Figure 2 plots the average accuracy as the number of languages varies. For comparison, the monolingual and average bilingual baseline results are given, along with supervised monolingual performance. Our multilingual model steadily gains in accuracy as the number of a</context>
</contexts>
<marker>Snyder, Naseem, Eisenstein, Barzilay, 2008</marker>
<rawString>Benjamin Snyder, Tahira Naseem, Jacob Eisenstein, and Regina Barzilay. 2008. Unsupervised multilingual learning for POS tagging. In Proceedings of the EMNLP, pages 1041–1050.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A comparison of pivot methods for phrase-based statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL/HLT,</booktitle>
<pages>484--491</pages>
<contexts>
<context position="6476" citStr="Utiyama and Isahara, 2006" startWordPosition="981" endWordPosition="984">h the number of languages. Beyond Bilingual Learning While most work on multilingual learning focuses on bilingual analysis, some models operate on more than one pair of languages. For instance, Genzel (2005) describes a method for inducing a multilingual lexicon from a group of related languages. His model first induces bilingual models for each pair of languages and then combines them. Our work takes a different approach by simultaneously learning from all languages, rather than combining bilingual results. A related thread of research is multi-source machine translation (Och and Ney, 2001; Utiyama and Isahara, 2006; Cohn and Lapata, 2007) where the goal is to translate from multiple source languages to a single target language. Rather than jointly training all the languages together, these models train bilingual models separately, and then use their output to select a final translation. The selection criterion can be learned at training time since these models have access to the correct translation. In unsupervised settings, however, we do not have a principled means for selecting among outputs of different bilingual models. By developing a joint multilingual model we can automatically achieve performan</context>
</contexts>
<marker>Utiyama, Isahara, 2006</marker>
<rawString>Masao Utiyama and Hitoshi Isahara. 2006. A comparison of pivot methods for phrase-based statistical machine translation. In Proceedings of NAACL/HLT, pages 484–491.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
</authors>
<title>Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the NAACL,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="4625" citStr="Yarowsky and Ngai, 2001" startWordPosition="699" endWordPosition="702">supervised and supervised monolingual performance is cut by nearly two thirds. We also examined scenarios where the tag lexicon is reduced in size. In all cases, the multilingual model yielded substantial performance gains. Finally, we examined the performance of our model when trained on all possible subsets of the eight languages. We found that performance improves steadily as the number of available languages increases. 2 Related Work Bilingual Part-of-Speech Tagging Early work on multilingual tagging focused on projecting annotations from an annotated source language to a target language (Yarowsky and Ngai, 2001; Feldman et al., 2006). In contrast, we assume no labeled data at all; our unsupervised model instead symmetrically improves performance for all languages by learning cross-lingual patterns in raw parallel data. An additional distinction is that projection-based work utilizes pairs of languages, while our approach allows for continuous improvement as languages are added to the mix. In recent work, Snyder et al. (2008) presented a model for unsupervised part-of-speech tagging trained from a bilingual parallel corpus. This bilingual model and the model presented here share a number of similarit</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>David Yarowsky and Grace Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In Proceedings of the NAACL, pages 1–8.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>