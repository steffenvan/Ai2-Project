<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000336">
<title confidence="0.804552">
FastSum:
Fast and accurate query-based multi-document summarization
</title>
<author confidence="0.569509">
Frank Schilder and Ravikumar Kondadadi
</author>
<affiliation confidence="0.354913">
Research &amp; Development
</affiliation>
<address confidence="0.5639605">
Thomson Corp.
610 Opperman Drive, Eagan, MN 55123, USA
</address>
<email confidence="0.996325">
FirstName.LastName@Thomson.com
</email>
<sectionHeader confidence="0.995598" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9990463125">
We present a fast query-based multi-document
summarizer called FastSum based solely on
word-frequency features of clusters, docu-
ments and topics. Summary sentences are
ranked by a regression SVM. The summa-
rizer does not use any expensive NLP tech-
niques such as parsing, tagging of names or
even part of speech information. Still, the
achieved accuracy is comparable to the best
systems presented in recent academic com-
petitions (i.e., Document Understanding Con-
ference (DUC)). Because of a detailed fea-
ture analysis using Least Angle Regression
(LARS), FastSum can rely on a minimal set of
features leading to fast processing times: 1250
news documents in 60 seconds.
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999941405405405">
In this paper, we propose a simple method for effec-
tively generating query-based multi-document sum-
maries without any complex processing steps. It
only involves sentence splitting, filtering candidate
sentences and computing the word frequencies in
the documents of a cluster, topic description and the
topic title. We use a machine learning technique
called regression SVM, as proposed by (Li et al.,
2007). For the feature selection we use a new model
selection technique called Least Angle Regression
(LARS) (Efron et al., 2004).
Even though machine learning approaches dom-
inated the field of summarization systems in recent
DUC competitions, not much effort has been spent
in finding simple but effective features. Exceptions
are the SumBasic system that achieves reasonable
results with only one feature (i.e., word frequency
in document clusters) (Nenkova and Vanderwende,
2005). Our approach goes beyond SumBasic by
proposing an even more powerful feature that proves
to be the best predictor in all three recent DUC cor-
pora. In order to prove that our feature is more pre-
dictive than other features we provide a rigorous fea-
ture analysis by employing LARS.
Scalability is normally not considered when dif-
ferent summarization systems are compared. Pro-
cessing time of more than several seconds per sum-
mary should be considered unacceptable, in partic-
ular, if you bear in mind that using such a system
should help a user to process lots of data faster. Our
focus is on selecting the minimal set of features that
are computationally less expensive than other fea-
tures (i.e., full parse). Since FastSum can rely on
a minimal set of features determined by LARS, it
can process 1250 news documents in 60 seconds.1
A comparison test with the MEAD system2 showed
that FastSum is more than 4 times faster.
</bodyText>
<sectionHeader confidence="0.927294" genericHeader="method">
2 System description
</sectionHeader>
<bodyText confidence="0.996362875">
We use a machine learning approach to rank all sen-
tences in the topic cluster for summarizability. We
use some features from Microsoft’s PYTHY system
(Toutonova et al., 2007), but added two new fea-
tures, which turned out to be better predictors.
First, the pre-processing module carries out tok-
enization and sentence splitting. We also created
a sentence simplification component which is based
</bodyText>
<footnote confidence="0.9998415">
14-way/2.0GHz PIII Xeon 4096Mb Memory
2http://www.summarization.com/mead/
</footnote>
<page confidence="0.971741">
205
</page>
<reference confidence="0.219884">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 205–208,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</reference>
<bodyText confidence="0.999941925925926">
on a few regular expressions to remove unimportant
components of a sentence (e.g., As a matter offact,).
This processing step does not involve any syntac-
tic parsing though. For further processing, we ig-
nore all sentences that do not have at least two exact
word matches or at least three fuzzy matches with
the topic description.3
Features are mainly based on word frequencies of
words in the clusters, documents and topics. A clus-
ter contains 25 documents and is associated with a
topic. The topic contains a topic title and the topic
descriptions. The topic title is list of key words or
phrases describing the topic. The topic description
contains the actual query or queries (e.g., Describe
steps taken and worldwide reaction prior to intro-
duction of the Euro on January 1, 1999.).
The features we used can be divided into two sets;
word-based and sentence-based. Word-based fea-
tures are computed based on the probability of words
for the different containers (i.e., cluster, document,
topic title and description). At runtime, the different
probabilities of all words in a candidate sentence are
added up and normalized by length. Sentence-based
features include the length and position of the sen-
tence in the document. The starred features 1 and
4 are introduced by us, whereas the others can be
found in earlier literature.4
</bodyText>
<equation confidence="0.900262">
(
1 : ti E D
</equation>
<bodyText confidence="0.894628666666667">
where fD = 0 : otherwise
3 Content word frequency(3): the average content
word probability pc(ti) of all content words
</bodyText>
<footnote confidence="0.995819333333333">
3Fuzzy matches are defined by the OVERLAP similarity
(Bollegala et al., 2007) of at least 0.1.
4The numbers are used in the feature analysis, as in figure 2.
</footnote>
<bodyText confidence="0.91151425">
t1..|3 |in a sentence s. The content word proba-
bility is defined as pc(ti) = &apos;, where n is the
number of times the word occurred in the clus-
ter and N is the total number of words in the
</bodyText>
<equation confidence="0.98179375">
P|s|
i=1 pc(ti)
cluster:
|3|
</equation>
<bodyText confidence="0.977786606060606">
*4 Document frequency (4): the average document
probability pd(ti) of all content words t1..|3 |in
a sentence s. The document probability is de-
fined as pd(ti) = d , where d is the number of
documents the word ti occurred in for a given
cluster and D is the total number of documents
in the cluster: P |i=1pd(ti)
|3|
The remaining features are Headline frequency (5),
Sentence length (6), Sentence position (binary) (7),
and Sentence position (real) (8)
Eventually, each sentence is associated with a
score which is a linear combination of the above
mentioned feature values. We ignore all sentences
that do not have at least two exact word matches.5
In order to learn the feature weights, we trained a
SVM on the previous year’s data using the same fea-
ture set. We used a regression SVM. In regression,
the task is to estimate the functional dependence of
a dependent variable on a set of independent vari-
ables. In our case, the goal is to estimate the score
of a sentence based on the given feature set. In order
to get training data, we computed the word overlap
between the sentences from the document clusters
and the sentences in DUC model summaries. We
associated the word overlap score to the correspond-
ing sentence to generate the regression data. As a
last step, we use the pivoted QR decomposition to
handle redundancy. The basic idea is to avoid redun-
dancy by changing the relative importance of the rest
of the sentences based on the currently selected sen-
tence. The final summary is created from the ranked
sentence list after the redundancy removal step.
</bodyText>
<sectionHeader confidence="0.999973" genericHeader="evaluation">
3 Results
</sectionHeader>
<bodyText confidence="0.99941575">
We compared our system with the top performing
systems in the last two DUC competitions. With our
best performing features, we get ROUGE-2 (Lin,
2004) scores of 0.11 and 0.0925 on 2007 and 2006
</bodyText>
<footnote confidence="0.95021">
5This threshold was derived experimentally with previous
data.
</footnote>
<figureCaption confidence="0.465828333333333">
*1 Topic title frequency (1): ratio of number of
words ti in the sentence s that also appear in
the topic title T to the total number of words
</figureCaption>
<bodyText confidence="0.8226806">
P|s |fT (ti)
2 Topic description frequency (2): ratio of number
of words ti in the sentence s that also appear
in the topic description D to the total number
of words t1. 3 in the sentence s: � =1 fD(tz)
</bodyText>
<figure confidence="0.988032857142857">
I I 131
1
|
|
|
t
..
3
in the sentence s: i=�3
,where
(
1 : ti E T
fT =0 : otherwise
,
</figure>
<page confidence="0.708285">
206
</page>
<table confidence="0.57351525">
FastSum, 6 Top Systems and generic baseline for DUC 2007
ROUGE−2
0.00 0.02 0.04 0.06 0.08 0.10 0.12 0.14
IIIT MS LIP6 IDA Peking FastSum Catalonia gen. Baseline
</table>
<figureCaption confidence="0.880378333333333">
Figure 1: ROUGE-2 results including 95%-confidence
intervals for the top 6 systems, FastSum and the generic
baseline for DUC 2007
</figureCaption>
<bodyText confidence="0.999866464285714">
DUC data, respectively. These scores correspond
to rank 6th for DUC 2007 and the 2nd rank for
DUC 2006. Figure 1 shows a graphical compari-
son of our system with the top 6 systems in DUC
2007. According to an ANOVA test carried out by
the DUC organizers, these 6 systems are significant
better than the remaining 26 participating systems.
Note that our system is better than the PYTHY
system for 2006, if no sentence simplification was
carried out (DUC 2006: 0.089 (without simplifica-
tion); 0.096 (with simplification)). Sentence simpli-
fication is a computationally expensive process, be-
cause it requires a syntactic parse.
We evaluated the performance of the FastSum al-
gorithm using each of the features separately. Ta-
ble 1 shows the ROUGE score (recall) of the sum-
maries generated when we used each of the features
by themselves on 2006 and 2007 DUC data, trained
on the data from the respective previous year. Using
only the Document frequency feature by itself leads
to the second best system for DUC 2006 and to the
tenth best system for DUC 2007.
This first simple analysis of features indicates that
a more rigorous feature analysis would have bene-
fits for building simpler models. In addition, feature
selection could be guided by the complexity of the
features preferring those features that are computa-
tionally inexpensive.
</bodyText>
<table confidence="0.999093111111111">
Feature name 2007 2006
Title word frequency 0.096 0.0771
Topic word frequency 0.0996 0.0883
Content word frequency 0.1046 0.0839
Document frequency 0.1061 0.0903
Headline frequency 0.0938 0.0737
Sentence length 0.054 0.0438
Sentence position(binary) 0.0522 0.0484
Sentence position (real-valued) 0.0544 0.0458
</table>
<tableCaption confidence="0.999938">
Table 1: ROUGE-2 scores of individual features
</tableCaption>
<bodyText confidence="0.999968190476191">
We chose a so-called model selection algorithm
to find a minimal set of features. This problem can
be formulated as a shrinkage and selection method
for linear regression. The Least Angle Regres-
sion (LARS) (Efron et al., 2004) algorithm can be
used for computing the least absolute shrinkage and
selection operator (LASSO) (Tibshirani, 1996).At
each stage in LARS, the feature that is most corre-
lated with the response is added to the model. The
coefficient of the feature is set in the direction of the
sign of the feature’s correlation with the response.
We computed LARS on the DUC data sets from
the last three years. The graphical results for 2007
are shown in figure 2. In a LARS graph, features
are plotted on the x-axis and the corresponding co-
efficients are shown on y-axis. The value on the x-
axis is the ratio of norm of the coefficent vector to
the maximal norm with no constraint. The earlier a
feature appears on the x-axis, the better it is. Table
2 summarizes the best four features we determined
with LARS for the three available DUC data sets.
</bodyText>
<table confidence="0.9921125">
Year Top Features
2005 4 2 5 1
2006 4 3 2 1
2007 4 3 5 2
</table>
<tableCaption confidence="0.981872">
Table 2: The 4 top features for the DUC 2005, 2006 and
2007 data
</tableCaption>
<bodyText confidence="0.973712714285714">
Table 2 shows that feature 4, document frequency,
is consistently the most important feature for all
three data sets. Content word frequency (3), on the
other hand, comes in as second best feature for 2006
and 2007, but not for 2005. For the 2005 data, the
Topic description frequency is the second best fea-
ture. This observation is reflected by our single fea-
</bodyText>
<page confidence="0.981154">
207
</page>
<figure confidence="0.9982516">
10 8 2 3 4
LASSO
2007
0.0 0.2 0.4 0.6 0.8 1.0
|beta|/max|beta|
</figure>
<figureCaption confidence="0.999457">
Figure 2: Graphical output of LARS analysis:
</figureCaption>
<bodyText confidence="0.994714555555556">
Top features for 2007: 4 Document frequency, 3 Content word
frequency, 5 Headline frequency, 2 Topic description frequency
ture analysis for DUC 2006, as shown in table 1.
Similarly, Vanderwende et al. (2006) report that they
gave the Topic description frequency a much higher
weight than the Content word frequency.
Consequently, we have shown that our new fea-
ture Document frequency is consistently the best
feature for all three past DUC corpora.
</bodyText>
<sectionHeader confidence="0.997439" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999988921052632">
We proposed a fast query-based multi-document
summarizer called FastSum that produces state-of-
the-art summaries using a small set of predictors,
two of those are proposed by us: document fre-
quency and topic title frequency. A feature anal-
ysis using least angle regression (LARS) indicated
that the document frequency feature is the most use-
ful feature consistently for the last three DUC data
sets. Using document frequency alone can produce
competitive results for DUC 2006 and DUC 2007.
The two most useful feature that takes the topic de-
scription (i.e., the queries) into account is based on
the number of words in the topic description and the
topic title. Using a limited feature set of the 5 best
features generates summaries that are comparable to
the top systems of the DUC 2006 and 2007 main task
and can be generated in real-time, since no compu-
tationally expensive features (e.g., parsing) are used.
From these findings, we draw the following con-
clusions. Since a feature set mainly based on word
frequencies can produce state-of-the-art summaries,
we need to analyze further the current set-up for the
query-based multi-document summarization task. In
particular, we need to ask the question whether the
selection of relevant documents for the DUC top-
ics is in any way biased. For DUC, the document
clusters for a topic containing relevant documents
were always pre-selected by the assessors in prepa-
ration for DUC. Our analysis suggests that simple
word frequency computations of these clusters and
the documents alone can produce reasonable sum-
maries. However, the human selecting the relevant
documents may have already influenced the way
summaries can automatically be generated. Our sys-
tem and systems such as SumBasic or SumFocus
may just exploit the fact that relevant articles pre-
screened by humans contain a high density of good
content words for summarization.6
</bodyText>
<sectionHeader confidence="0.998949" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993542606060606">
D. Bollegala, Y. Matsuo, and M. Ishizuka. 2007. Mea-
suring Semantic Similarity between Words Using Web
Search Engines. In Proc. of 16th International World
Wide Web Conference (WWW 2007), pages 757–766,
Banff, Canada.
B. Efron, T. Hastie, I.M. Johnstone, and R. Tibshirani.
2004. Least angle regression. Annals of Statistics,
32(2):407–499.
S. Gupta, A. Nenkova, and D. Jurafsky. 2007. Measur-
ing Importance and Query Relevance in Topic-focused
Multi-document Summarization. In Proc. of the 45th
Annual Meeting of the Association for Computational
Linguistics, pages 193–196, Prague, Czech Republic.
S. Li, Y. Ouyang, W. Wang, and B. Sun. 2007. Multi-
document summarization using support vector regres-
sion. In Proceedings of DUC 2007, Rochester, USA.
C. Lin. 2004. Rouge: a package for automatic evaluation
of summaries. In Proceedings of the Workshop on Text
Summarization Branches Out (WAS 2004).
A. Nenkova and L. Vanderwende. 2005. The impact of
frequency on summarization. In MSR-TR-2005-101.
R. Tibshirani. 1996. Regression shrinkage and selection
via the lasso. J. Royal. Statist. Soc B., 58(1):267–288.
K. Toutonova, C. Brockett, J. Jagarlamudi, H. Suzuko,
and L. Vanderwende. 2007. The PYTHY Summa-
rization System: Microsoft Research at DUC2007. In
Proc. of DUC 2007, Rochester, USA.
L. Vanderwende, H. Suzuki, and C. Brockett. 2006. Mi-
crosoft Research at DUC 2006: Task-focused summa-
rization with sentence simplification and lexical ex-
pansion. In Proc. of DUC 2006, New York, USA.
6Cf. Gupta et al. (2007) who come to a similar conclusion
by comparing between word frequency and log-likelihood ratio.
</reference>
<figure confidence="0.999823666666667">
* * * ** *
* *
*
*
*
* * * * * * ** *
*
* * ** *
* * * ** *
* *
* *
*
*
* * ** *
* * * *
* * * *
* * ** *
* * * ** *
* * ** *
0 2 4 6 8
Standardized Coefficients
</figure>
<page confidence="0.953658">
208
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.307085">
<title confidence="0.999042">FastSum: Fast and accurate query-based multi-document summarization</title>
<author confidence="0.999462">Schilder Kondadadi</author>
<affiliation confidence="0.7813545">Research &amp; Development Thomson Corp.</affiliation>
<address confidence="0.998784">610 Opperman Drive, Eagan, MN 55123, USA</address>
<email confidence="0.998117">FirstName.LastName@Thomson.com</email>
<abstract confidence="0.987288">We present a fast query-based multi-document summarizer called FastSum based solely on word-frequency features of clusters, documents and topics. Summary sentences are ranked by a regression SVM. The summarizer does not use any expensive NLP techniques such as parsing, tagging of names or even part of speech information. Still, the achieved accuracy is comparable to the best systems presented in recent academic competitions (i.e., Document Understanding Conference (DUC)). Because of a detailed feature analysis using Least Angle Regression (LARS), FastSum can rely on a minimal set of leading to fast processing times:</abstract>
<intro confidence="0.556632">documents in</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Proceedings of ACL-08: HLT, Short Papers (Companion Volume),</booktitle>
<pages>205--208</pages>
<marker></marker>
<rawString>Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 205–208,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Columbus</author>
</authors>
<title>c�2008 Association for Computational Linguistics</title>
<date>2008</date>
<booktitle>In Proc. of 16th International World Wide Web Conference (WWW</booktitle>
<pages>757--766</pages>
<location>Ohio, USA,</location>
<marker>Columbus, 2008</marker>
<rawString>Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics D. Bollegala, Y. Matsuo, and M. Ishizuka. 2007. Measuring Semantic Similarity between Words Using Web Search Engines. In Proc. of 16th International World Wide Web Conference (WWW 2007), pages 757–766, Banff, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Efron</author>
<author>T Hastie</author>
<author>I M Johnstone</author>
<author>R Tibshirani</author>
</authors>
<title>Least angle regression.</title>
<date>2004</date>
<journal>Annals of Statistics,</journal>
<volume>32</volume>
<issue>2</issue>
<contexts>
<context position="1439" citStr="Efron et al., 2004" startWordPosition="211" endWordPosition="214">res leading to fast processing times: 1250 news documents in 60 seconds. 1 Introduction In this paper, we propose a simple method for effectively generating query-based multi-document summaries without any complex processing steps. It only involves sentence splitting, filtering candidate sentences and computing the word frequencies in the documents of a cluster, topic description and the topic title. We use a machine learning technique called regression SVM, as proposed by (Li et al., 2007). For the feature selection we use a new model selection technique called Least Angle Regression (LARS) (Efron et al., 2004). Even though machine learning approaches dominated the field of summarization systems in recent DUC competitions, not much effort has been spent in finding simple but effective features. Exceptions are the SumBasic system that achieves reasonable results with only one feature (i.e., word frequency in document clusters) (Nenkova and Vanderwende, 2005). Our approach goes beyond SumBasic by proposing an even more powerful feature that proves to be the best predictor in all three recent DUC corpora. In order to prove that our feature is more predictive than other features we provide a rigorous fe</context>
</contexts>
<marker>Efron, Hastie, Johnstone, Tibshirani, 2004</marker>
<rawString>B. Efron, T. Hastie, I.M. Johnstone, and R. Tibshirani. 2004. Least angle regression. Annals of Statistics, 32(2):407–499.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gupta</author>
<author>A Nenkova</author>
<author>D Jurafsky</author>
</authors>
<title>Measuring Importance and Query Relevance in Topic-focused Multi-document Summarization.</title>
<date>2007</date>
<booktitle>In Proc. of the 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>193--196</pages>
<location>Prague, Czech Republic.</location>
<marker>Gupta, Nenkova, Jurafsky, 2007</marker>
<rawString>S. Gupta, A. Nenkova, and D. Jurafsky. 2007. Measuring Importance and Query Relevance in Topic-focused Multi-document Summarization. In Proc. of the 45th Annual Meeting of the Association for Computational Linguistics, pages 193–196, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Li</author>
<author>Y Ouyang</author>
<author>W Wang</author>
<author>B Sun</author>
</authors>
<title>Multidocument summarization using support vector regression.</title>
<date>2007</date>
<booktitle>In Proceedings of DUC 2007,</booktitle>
<location>Rochester, USA.</location>
<contexts>
<context position="1315" citStr="Li et al., 2007" startWordPosition="191" endWordPosition="194">). Because of a detailed feature analysis using Least Angle Regression (LARS), FastSum can rely on a minimal set of features leading to fast processing times: 1250 news documents in 60 seconds. 1 Introduction In this paper, we propose a simple method for effectively generating query-based multi-document summaries without any complex processing steps. It only involves sentence splitting, filtering candidate sentences and computing the word frequencies in the documents of a cluster, topic description and the topic title. We use a machine learning technique called regression SVM, as proposed by (Li et al., 2007). For the feature selection we use a new model selection technique called Least Angle Regression (LARS) (Efron et al., 2004). Even though machine learning approaches dominated the field of summarization systems in recent DUC competitions, not much effort has been spent in finding simple but effective features. Exceptions are the SumBasic system that achieves reasonable results with only one feature (i.e., word frequency in document clusters) (Nenkova and Vanderwende, 2005). Our approach goes beyond SumBasic by proposing an even more powerful feature that proves to be the best predictor in all </context>
</contexts>
<marker>Li, Ouyang, Wang, Sun, 2007</marker>
<rawString>S. Li, Y. Ouyang, W. Wang, and B. Sun. 2007. Multidocument summarization using support vector regression. In Proceedings of DUC 2007, Rochester, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lin</author>
</authors>
<title>Rouge: a package for automatic evaluation of summaries.</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop on Text Summarization Branches Out (WAS</booktitle>
<marker>Lin, 2004</marker>
<rawString>C. Lin. 2004. Rouge: a package for automatic evaluation of summaries. In Proceedings of the Workshop on Text Summarization Branches Out (WAS 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Nenkova</author>
<author>L Vanderwende</author>
</authors>
<title>The impact of frequency on summarization.</title>
<date>2005</date>
<journal>J. Royal. Statist. Soc B.,</journal>
<booktitle>In MSR-TR-2005-101. R. Tibshirani.</booktitle>
<volume>58</volume>
<issue>1</issue>
<contexts>
<context position="1792" citStr="Nenkova and Vanderwende, 2005" startWordPosition="262" endWordPosition="265">ocuments of a cluster, topic description and the topic title. We use a machine learning technique called regression SVM, as proposed by (Li et al., 2007). For the feature selection we use a new model selection technique called Least Angle Regression (LARS) (Efron et al., 2004). Even though machine learning approaches dominated the field of summarization systems in recent DUC competitions, not much effort has been spent in finding simple but effective features. Exceptions are the SumBasic system that achieves reasonable results with only one feature (i.e., word frequency in document clusters) (Nenkova and Vanderwende, 2005). Our approach goes beyond SumBasic by proposing an even more powerful feature that proves to be the best predictor in all three recent DUC corpora. In order to prove that our feature is more predictive than other features we provide a rigorous feature analysis by employing LARS. Scalability is normally not considered when different summarization systems are compared. Processing time of more than several seconds per summary should be considered unacceptable, in particular, if you bear in mind that using such a system should help a user to process lots of data faster. Our focus is on selecting </context>
</contexts>
<marker>Nenkova, Vanderwende, 2005</marker>
<rawString>A. Nenkova and L. Vanderwende. 2005. The impact of frequency on summarization. In MSR-TR-2005-101. R. Tibshirani. 1996. Regression shrinkage and selection via the lasso. J. Royal. Statist. Soc B., 58(1):267–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutonova</author>
<author>C Brockett</author>
<author>J Jagarlamudi</author>
<author>H Suzuko</author>
<author>L Vanderwende</author>
</authors>
<title>The PYTHY Summarization System: Microsoft Research at DUC2007.</title>
<date>2007</date>
<booktitle>In Proc. of DUC 2007,</booktitle>
<location>Rochester, USA.</location>
<marker>Toutonova, Brockett, Jagarlamudi, Suzuko, Vanderwende, 2007</marker>
<rawString>K. Toutonova, C. Brockett, J. Jagarlamudi, H. Suzuko, and L. Vanderwende. 2007. The PYTHY Summarization System: Microsoft Research at DUC2007. In Proc. of DUC 2007, Rochester, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Vanderwende</author>
<author>H Suzuki</author>
<author>C Brockett</author>
</authors>
<title>Microsoft Research at DUC 2006: Task-focused summarization with sentence simplification and lexical expansion.</title>
<date>2006</date>
<booktitle>In Proc. of DUC</booktitle>
<location>New York, USA.</location>
<marker>Vanderwende, Suzuki, Brockett, 2006</marker>
<rawString>L. Vanderwende, H. Suzuki, and C. Brockett. 2006. Microsoft Research at DUC 2006: Task-focused summarization with sentence simplification and lexical expansion. In Proc. of DUC 2006, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gupta</author>
</authors>
<title>who come to a similar conclusion by comparing between word frequency and log-likelihood ratio.</title>
<date>2007</date>
<marker>Gupta, 2007</marker>
<rawString>6Cf. Gupta et al. (2007) who come to a similar conclusion by comparing between word frequency and log-likelihood ratio.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>