<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.992149">
Transliteration as Constrained Optimization
</title>
<author confidence="0.998821">
Dan Goldwasser Dan Roth
</author>
<affiliation confidence="0.9992755">
Department of Computer Science
University of Illinois
</affiliation>
<address confidence="0.795759">
Urbana, IL 61801
</address>
<email confidence="0.998909">
{goldwas1,danr}@uiuc.edu
</email>
<sectionHeader confidence="0.998598" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999308789473684">
This paper introduces a new method for iden-
tifying named-entity (NE) transliterations in
bilingual corpora. Recent works have shown
the advantage of discriminative approaches to
transliteration: given two strings (w,, wt) in
the source and target language, a classifier is
trained to determine if wt is the translitera-
tion of w,. This paper shows that the translit-
eration problem can be formulated as a con-
strained optimization problem and thus take
into account contextual dependencies and con-
straints among character bi-grams in the two
strings. We further explore several methods
for learning the objective function of the opti-
mization problem and show the advantage of
learning it discriminately. Our experiments
show that the new framework results in over
50% improvement in translating English NEs
to Hebrew.
</bodyText>
<sectionHeader confidence="0.999468" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999469333333333">
Named entity (NE) transliteration is the process of
transcribing a NE from a source language to some
target language based on phonetic similarity be-
tween the entities. Identifying transliteration pairs
is an important component in many linguistic appli-
cations which require identifying out-of-vocabulary
words, such as machine translation and multilingual
information retrieval (Klementiev and Roth, 2006b;
Hermjakob et al., 2008).
It may appear at first glance that identifying the
phonetic correlation between names based on an
orthographic analysis is a simple, straight-forward
</bodyText>
<figureCaption confidence="0.9988895">
Figure 1: Named entities transliteration pairs in English
and Hebrew and the character level mapping between the
two names. The Hebrew names can be romanized as ee-
ta-l-ya and a-ya
</figureCaption>
<bodyText confidence="0.999950428571429">
task; however in many cases a consistent deter-
ministic mapping between characters does not ex-
ist; rather, the mapping depends on the context the
characters appear in and on transliteration conven-
tions which may change across domains. Figure 1
exhibits two examples of NE transliterations in En-
glish and Hebrew, with the correct mapping across
the two scripts. Although the two Hebrew names
share a common prefix1, this prefix can be mapped
into a single English character or into two differ-
ent characters depending on the context it appears
in. Similarly, depending on the context it appears in,
the English character a can be mapped into different
characters or to an “empty” character.
</bodyText>
<footnote confidence="0.9666195">
1In all our example the Hebrew script is shown left-to-right
to simplify the visualization of the transliteration mapping.
</footnote>
<page confidence="0.969214">
353
</page>
<note confidence="0.9622025">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 353–362,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.999698272727273">
In recent years, as it became clear that solutions
that are based on linguistics rules are not satisfac-
tory, machine learning approaches have been de-
veloped to address this problem. The common ap-
proach adopted is therefore to view this problem
as a classification problem (Klementiev and Roth,
2006a; Tao et al., 2006) and train a discriminative
classifier. That is, given two strings, one in the
source and the other in the target language, extract
pairwise features, and train a classifier that deter-
mines if one is a transliteration of the other. Sev-
eral papers have followed up on this basic approach
and focused on semi-supervised approaches to this
problem or on extracting better features for the dis-
criminative classifier (Klementiev and Roth, 2006b;
Bergsma and Kondrak, 2007; Goldwasser and Roth,
2008). While it has been clear that the relevancy of
pairwise features is context sensitive and that there
are contextual constraints among them, the hope was
that a discriminative approach will be sufficient to
account for those by weighing features appropri-
ately. This has been shown to be difficult for lan-
guage pairs which are very different, such as English
and Hebrew (Goldwasser and Roth, 2008).
In this paper, we address these difficulties by
proposing to view the transliteration decision as a
globally phrased constrained optimization problem.
We formalize it as an optimization problem over
a set of local pairwise features – character n-gram
matches across the two string – and subject to legit-
imacy constraints.
We use a discriminatively trained classifier as a
way to learn the objective function for the global
constrained optimization problem. Our technical
approach follows a large body of work developed
over the last few years, following (Roth and Yih,
2004) that has formalized global decisions problems
in NLP as constrained optimization problems and
solved these optimization problems using Integer
Linear Programming (ILP) or other methods (Pun-
yakanok et al., 2005; Barzilay and Lapata, 2006;
Clarke and Lapata, ; Marciniak and Strube, 2005).
We investigate several ways to train our objective
function, which is represented as a dot product be-
tween a set of features chosen to represent a pair
(ws, wt), and a vector of initial weights. Our first
baseline makes use of all features extracted from a
pair, along with a simple counting method to deter-
mine initial weights. We then use a method simi-
lar to (Klementiev and Roth, 2006a; Goldwasser and
Roth, 2008) in order to discriminatively train a better
weight vector for the objective function.
Our key contribution is that we use a constrained
optimization approach also to determine a better fea-
ture representation for a given pair. (Bergsma and
Kondrak, 2007) attempted a related approach to re-
stricting the set of features representing a transliter-
ation candidate. However, rather than directly align-
ing the two strings as done there, we exploit the ex-
pressiveness of the ILP formulation and constraints
to generate a better representation of a pair. This
is the representation we then use to discriminatively
learn a better weight vector for the objective func-
tion used in our final model.
Our experiments focus on Hebrew-English
transliteration, which were shown to be very dif-
ficult in a previous work (Goldwasser and Roth,
2008). We show very significant improvements over
existing work with the same data set, proving the
advantage of viewing the transliteration decision as
a global inference problem. Furthermore, we show
the importance of using a discriminatively trained
objective function.
The rest of the paper is organized as follows. The
main algorithmic contribution of this paper is de-
scribed in Sec. 2. Our experimental study is de-
scribes in Sec. 3 and Sec. 4 concludes.
</bodyText>
<sectionHeader confidence="0.768166" genericHeader="method">
2 Using inference for transliteration
</sectionHeader>
<bodyText confidence="0.9972904">
In this section we present our transliteration decision
framework, which is based on solving a constrained
optimization problem with an objective function that
is discriminatively learned. Our framework consists
of three key elements:
</bodyText>
<listItem confidence="0.649406">
1. Decision Model When presented with a NE
</listItem>
<bodyText confidence="0.988437">
in the source language ws and a set of candi-
dates {wt}i in the target language, the decision
model ranks the candidate pairs (ws, wt) and
selects the “best” candidate pair. This is framed
as an optimization problem
</bodyText>
<equation confidence="0.998089">
wt = argmaxz{w · F(ws, wt)}, (1)
</equation>
<bodyText confidence="0.999183333333333">
where F is a feature vector representation of
the pair (ws, wt) and w is a vector of weights
assigned to each feature.
</bodyText>
<page confidence="0.996578">
354
</page>
<listItem confidence="0.9998678">
2. Representation A pair s = (ws, wt) of source
and target NEs is represented as a vector offea-
tures, each of which is a pair of character n-
grams, from ws and wt, resp. Starting with a
baseline representation introduced in (Klemen-
tiev and Roth, 2006a), denoted here AF(s),
we refine this representation to take into ac-
count dependencies among the individual n-
gram pairs. This refinement process is framed
as a constrained optimization problem:
</listItem>
<equation confidence="0.988177">
F(s)* = argmaxFCAF{w · AF(s)}, (2)
</equation>
<bodyText confidence="0.9351802">
subject to a set C of linear constraints. Here
AF is the initial representation (All−Features),
w is a vector of weights assigned to each fea-
ture and C is a set of constraints accounting for
interdependencies among features.
</bodyText>
<listItem confidence="0.797845666666667">
3. Weight Vector Each pairwise n-gram feature is
associated with a weight; this weigh vector is
used in both optimization formulations above.
</listItem>
<bodyText confidence="0.961924181818182">
The weight vector is determined by considering
the whole training corpus. The initial weight
vector is obtained generatively, by counting the
relative occurrence of substring pairs in posi-
tive examples. The representation is refined by
discriminatively training a classifier to maxi-
mize transliteration performance on the train-
ing data. In doing that, each example is rep-
resented using the feature vector representation
described above.
The three key operations described above are be-
ing used in several stages, with different parameters
(weight vectors and representations) as described
in Alg. 1. In each stage a different element is re-
fined. The input to this process is a training corpus
Tr=(DS,DT) consisting of NE transliteration pairs
s = (ws, wt), where ws, wt are NEs in the source
and target language, respectively. Each such sam-
ple point is initially represented as a feature vector
AF(s) (for All−Features), where features are pairs
of substrings from the two words (following (Kle-
mentiev and Roth, 2006a)).
Given the set of feature vectors generated by ap-
plying AF to Tr, we assign initial weights W to
the features ((1) in Alg. 1). These weights form
the initial objective function used to construct a new
feature based representation, Informative−Features,
IFW(s) ((2) in Alg. 1). Specifically, for an instance
s, IFW(s) is the solution of the optimization prob-
lem in Eq. 2, with W as the weight vector, AF(s)
as the representation, and a set of constraints ensur-
ing the “legitimacy” of the selected set of features
(Sec. 2.2.1).
</bodyText>
<figureCaption confidence="0.376488">
Algorithm 1: Transliteration Framework.
</figureCaption>
<bodyText confidence="0.999454">
The new feature extraction operator IFW(s) is
now used to construct a new representation of the
training corpus. With this representation, we train
discriminately a new weight vector WD. This
weight vector, now defines a new objective function
for the optimization problem in Eq. 2; WD is the
weight vector and AF(s) the representation. We de-
</bodyText>
<figure confidence="0.983576">
Input: Training Corpora Tr=(DS,DT)
Output: Transliteration model M
1. Initial Representation and Weights
For each sample s E Tr, use AF to generate a
feature vector
{(fs, ft)�, (fs, ft)2, . . . , (fs, ft)n} E {0, 1}n.
Define W:f → R s.t. foreach feature f=(fs, ft)
W(f) = #(fs,ft)#(fs,ft)
#(fs)
2. Inferring Informative Representation (W)
Modify the initial representation by solving the
following constrained optimization problem:
IFW(s)* = argmaxIF(s)c(AF(s))W · AF(s),
subject to constraints C.
3. Discriminative Training
</figure>
<bodyText confidence="0.720801090909091">
Train a discriminative model on Tr, using
{IF(s)}sETr.
Let WD be the new weight vector obtained by
discriminative training.
4. Inferring Informative Representation (WD)
Modify the initial representation by solving the
following constrained optimization problem. This
time, the objective function is determined by the
discriminatively trained weight vector WD.
IFWD(s)* = argmaxIF(s)c(AF(s))WD · AF(s),
subject to constraints C.
</bodyText>
<sectionHeader confidence="0.397754" genericHeader="method">
5. Decision Model
</sectionHeader>
<bodyText confidence="0.972303">
Given a word ws and a list of candidates
wt , w2t , ... wkt , the chosen transliteration is wt.,
determined by:
</bodyText>
<equation confidence="0.999621">
t* = argmaxi{WD · IFWD((ws,wit))}
X #(ft)
</equation>
<page confidence="0.986484">
355
</page>
<bodyText confidence="0.999808444444444">
note by IFWD(s) the solution of this optimization
problem for an instance s.
Given a representation and a weight vector, the
optimization problem in Eq. 1 is used to find the
transliteration of ws. Our best decision model makes
use of Eq. 1 using WD as the feature vector and
IFWD(s) as the feature representation of s.
The rest of this section provides details on the op-
erations and how we use them in different stages.
</bodyText>
<subsectionHeader confidence="0.997357">
2.1 Initial Representation and Weights
</subsectionHeader>
<bodyText confidence="0.999193852941176">
The feature space we consider consists of n po-
tential features, each feature f = (fs, ft) repre-
sents a pairing of character level n-grams, where
fs ∈ {Source-Language ∪ empty-string } and ft ∈
{Target-Language ∪ empty-string}. A given sample
(ws, wt) consisting of a pair of NEs is represented
as a features vector s ∈ {0,1}n. We say that a fea-
ture fi is active if fi = 1 and that s1 ⊂ s2, ⇐⇒
{fi}lfa= 1 in s11 ⊂ {fi}lfa=1 in s21. We represent
the active features corresponding to a pair as a bipar-
tite graph G = (V, E), in which each vertex v ∈ V
either represents the empty string, a single character
or a bi-gram. V S, VT denote the vertices represent-
ing source and target language n-grams respectively.
Each of these sets is composed of two disjoint sub-
sets: VS = VU ∪ VB , VT = VU ∪ VB consisting
of vertices representing the uni-gram and bi-gram
strings. Given a vertex v, degree(v, V&apos;)denotes the
degree of v in a subgraph of G, consisting only of
V &apos; ⊂ V ; index(v) is the index of the substring rep-
resented by v in the original string.
Edges in the bipartite graph represent active fea-
tures. The only deviation is that the vertex represent-
ing the empty string can be connected to any other
(non-empty) vertex.
Our initial feature extraction method follows the
one presented in (Klementiev and Roth, 2006a),
in which the feature space consists of n-gram pairs
from the two languages. Given a pair, each word
is decomposed into a set of character substrings of
up to a given length (including the empty string).
Features are generated by pairing substrings from
the two sets whose relative positions in the original
words differ by k or less places, or formally:
</bodyText>
<equation confidence="0.999259">
E = {e = (vi, vj)  |(vi ∈ VS ∧ vj ∈ VT) ⇒
(index(vj) + k ≥ index(vi) ≥ index(vj) − k) ∧
</equation>
<figureCaption confidence="0.84087275">
Figure 2: All possible unigram and bigram pairs gener-
ated by the AF operator. The Hebrew name can be ro-
manized as lo-n-do-n
(vi =6 vempty−string ∨ vj =6 vempty−string)}.
</figureCaption>
<bodyText confidence="0.99983944">
In our experiments we used k=1 which tested em-
pirically, achieved the best performance.
Figure 2 exhibits the active features in the exam-
ple using the graph representation. We refer to this
feature extraction method as All-Features (AF),
and define it formally as an operator AF : s →
{(fs, ft)i} that maps a sample point s = (ws, wt)
to a set of active features.
The initial sample representation generates fea-
tures by coupling substrings from the two terms
without considering the dependencies between the
possible consistent combinations. Ideally, given
a positive sample, it is desirable that paired sub-
strings would encode phonetic similarity or a dis-
tinctive context in which the two substrings corre-
late. However, AF simply pairs substrings from the
two words, resulting in a noisy representation of the
sample point. Given enough positive samples, we
assume that features appearing with distinctive fre-
quency will encode the desired relation. We use this
observation, and construct a weight vector, associ-
ating each feature with a positive number indicating
its relative occurrence frequency in the training data
representation formed by AF. This weight is com-
puted as follows:
</bodyText>
<sectionHeader confidence="0.348338" genericHeader="method">
Definition 1(Initial Feature Weights Vector) Let
</sectionHeader>
<equation confidence="0.948393">
W:f → R s.t. for each feature f={fs, ft},
W(f) = #(fs,ft) #(fs,ft)
#(fs) × #(ft)
</equation>
<bodyText confidence="0.9045965">
where #(fs, ft) is the number of occurrences of that
feature in the positive sample set, and #( fL), L =
{s, t} is the number of occurrences of an individual
substring, in any of the features extracted from pos-
itive samples in the training set.
,
</bodyText>
<page confidence="0.98069">
356
</page>
<bodyText confidence="0.9999560625">
These weights transform every example into a
weighted graph, where each edge is associated by W
with the weight assigned to the feature it represents.
As we empirically tested, this initialization assigns
high weights to features that preserve the phonetic
correlation between the two languages. The top part
of figure 5 presents several examples of weights as-
signed by W to features composed of different En-
glish and Hebrew substrings combinations. It can be
observed that combination which are phonetically
similar are associated with a higher weight. How-
ever, as it turns out, transliteration mappings do not
consist of “clean” and consistent mappings of pho-
netically similar substrings. In the following section
we explain how to use these weights to generate a
more compact representation of samples.
</bodyText>
<subsectionHeader confidence="0.971364">
2.2 Inferring Informative Representations
</subsectionHeader>
<bodyText confidence="0.999996227272727">
In this section we suggest a new feature extraction
method for determining the representation of a given
word pair. We use the strength of the active features
computed above, along with legitimacy constraints
on mappings between source and target strings to
find an optimal set of consistent active features that
represents a pair. This problem can be naturally en-
coded as a linear optimization problem, which seeks
to maximize a linear objective function determined
by W, over a set of variables representing the ac-
tive features selection, subject to a set of linear con-
straints representing the dependencies between se-
lections. We follow the formulation given by (Roth
and Yih, 2004), and define it as an Integer Linear
Programming (ILP) optimization problem, in which
each integer variable a(j�k), defined over {0, 1J, rep-
resents whether a feature pairing an n-gram j E S
with an n-gram k E T, is active. Although using ILP
is in general NP-hard, it has been used efficiently in
many natural language (see section 1). Our experi-
ence as well has been that this process is very effi-
cient due to the sparsity of the constraints used.
</bodyText>
<subsectionHeader confidence="0.923758">
2.2.1 Constraining Feature Dependencies
</subsectionHeader>
<bodyText confidence="0.997479205882353">
To limit the selection of active features in each
sample we require that each element in the decom-
position of ws into bi-grams should be paired with
an element in wt, and the vice-versa. We restrict
the possible pairs by allowing only a single n-gram
to be matched to any other n-gram, with one excep-
tion - we allow every bi-gram to be mapped into an
empty string. Viewed as a bipartite graph, we allow
each node (with the exception of the empty string)
to have only one connected edge. These constraints,
given the right objective function, should enforce an
alignment of bi-grams according to phonetic simi-
larity; for example, the word pairs described in Fig-
ure 1, depicts a character level alignment between
the words, where in some cases a bi-gram is mapped
into a single character and in other cases single char-
acters are mapped to each other, based on phonetic
similarity encoded by the two scripts. However, im-
posing these constraints over the entire set of candi-
date features would be too restrictive; it is unlikely
that one can consistently represent a single “correct”
phonetic mapping. We wish to represent both the
character level and bi-gram mapping between names
as both represent informative features on the corre-
spondence between the names over the two scripts.
To allow this, we decompose the problem into two
disjoint sets of constraints imposing 1-1 mappings,
one over the set of single character substrings and
the other over the bi-gram substrings. Given the bi-
partite graph generated by AF, we impose the fol-
lowing constraints:
Definition 2 (Transliteration Constraints) Let C
be the set of constraints, consisting of the following
predicates:
</bodyText>
<equation confidence="0.85242825">
Vv E VS, degree(v,VSUVU )&lt;1 n
Vv E VS, degree(v,VSUVB )&lt;1 n
Vv E VT, degree(v,VTUVU)&lt;1 n
Vv E VT, degree(v,VTUVB)&lt;1
</equation>
<bodyText confidence="0.982331428571429">
For example, Figure 2 shows the graph of all pos-
sible candidates produced by AF. In Figure 3, the
graph is decomposed into two graphs, each depict-
ing possible matches between the character level
uni-gram or bi-gram substrings. the ILP constraints
ensure that in each graph, every node (with the ex-
ception of the empty string) has a degree of one .
Figure 4 gives the results of the ILP process – a
unified graph in which every node has only a single
edge associated with it.
Definition 3 (Informative Feature Extraction (IF))
We define the Informative-Features(IF) feature
extraction operator, IF : s —* {(fs, ft)zJ as the
solution to the ILP problem in Eq. 2. Namely,
</bodyText>
<page confidence="0.996718">
357
</page>
<figureCaption confidence="0.995907333333333">
Figure 3: Find informative features by solving an ILP
problem. Dependencies between matching decisions are
modeled by allowing every node to be connected to a sin-
gle edge (except the node representing the empty-string).
Figure 4: The result of applying the IF operator by solv-
ing an ILP problem, represented as a pruned graph.
</figureCaption>
<equation confidence="0.789911">
IF(s)* = argmaxIF(s)C(AF(s))w · AF(s),
subject to constraints C.
</equation>
<bodyText confidence="0.99993625">
We will use this operator with w = W, defined
above, and denote it IFW, and also use it with a
different weight vector, trained discriminatively, as
described next.
</bodyText>
<subsectionHeader confidence="0.997314">
2.3 Discriminative Training
</subsectionHeader>
<bodyText confidence="0.999787583333333">
Using the IFW operator, we generate a better rep-
resentation of the training data, which is now used
to train a discriminative model. We use a linear
classifier trained with a regularized average percep-
tron update rule (Grove and Roth, 2001) as imple-
mented in SNoW, (Roth, 1998). This learning al-
gorithm provides a simple and general linear clas-
sifier that has been demonstrated to work well in
other NLP classification tasks, e.g. (Punyakanok
et al., 2005), and allows us to incorporate extensions
such as strength of features naturally into the train-
ing algorithm. We augment each sample in the train-
</bodyText>
<figureCaption confidence="0.9977056">
Figure 5: Several examples of weights assigned to fea-
tures generated by coupling English and Hebrew sub-
strings. Top figure: initial weights. Bottom figure: Dis-
criminatively learned weights. The Hebrew characters,
ordered left to right, can be romanized as y,z,t,sh
</figureCaption>
<bodyText confidence="0.999878242424242">
ing data with feature weights; given a sample, the
learner is presented with a real-valued feature vec-
tor instead of a binary vector. This can be viewed
as providing a better starting point for the learner,
which improves the learning rate (Golding and Roth,
1999; Ng and Jordan, 2001).
The weight vector learned by the discriminative
training is denoted WD. Given the new weight vec-
tor, we can define a new feature extraction opera-
tor, that we get by applying the objective function in
Eq. 2 with WD instead of W. Given a sample s, the
feature representation generated by this new infor-
mation extraction operator is denoted IFW,,,(s). The
key difference between W and WD is that the latter
was trained over a corpora containing both negative
and positive examples, and as a result WD contains
negative weights. To increase the impact of training
we multiplied the negative weights by 2.
Figure 5 presents some examples of the benefit
of discriminately learning the objective function; the
weighted edges in the top figure show the values as-
signed to features by W, while the bottom figure
shows the weights assigned by WD. In all cases,
phonetically similar characters were assigned higher
scores by WD, and character pairs not phonetically
similar were typically assigned negative weights. It
is also interesting to note a special phenomena oc-
curring in English-Hebrew transliterations. The En-
glish vowels will be paired to almost any Hebrew
character when generating pairs using AF, since
vowels in most cases are omitted in Hebrew, there
is no distinctive context in which English vowels
appear. We can see for example, in the top graph
</bodyText>
<page confidence="0.99656">
358
</page>
<bodyText confidence="0.8150765">
Decision Model 5 Ranking the transliteration can-
didates is done by evaluating:
</bodyText>
<equation confidence="0.936474">
s* = argmaxi WD · IFWD(si),
</equation>
<bodyText confidence="0.9997518">
presented in Figure 5 an edge matching a vowel to
a Hebrew character with a high weight, the bottom
graph showing the results of the discriminative train-
ing process show that this edge is associated with a
zero weight score.
</bodyText>
<subsectionHeader confidence="0.990828">
2.4 Decision Models
</subsectionHeader>
<bodyText confidence="0.9949226">
This section defines several transliteration decision
models given a word ws and a list of candidates
w1� , w2� , ... wk� . The models are used to identify the
correct transliteration pair from the set of candidates
{si = (ws, wi�)}i=1...k.
In all cases, the decision is formulated as in Eq. 1,
where different models differ by the representations
and weight vectors used.
Decision Model 1 Ranking the transliteration can-
didates is done by evaluating
</bodyText>
<equation confidence="0.983244">
s* = argmaxi W · AF(si),
</equation>
<bodyText confidence="0.9902878">
which selects the transliteration pair which maxi-
mizes the objective function based on the genera-
tively computed weight vector.
Decision Model 2 Ranking the transliteration can-
didates is done by evaluating:
</bodyText>
<equation confidence="0.958714">
s* = argmaxi WD · AF(si)).
</equation>
<bodyText confidence="0.991044428571429">
This decision model is essentially equivalent to the
transliteration models used in (Klementiev and
Roth, 2006a; Goldwasser and Roth, 2008), in which
a linear transliteration model was trained using a fea-
ture extraction method equivalent to AF.
Decision Model 3 Ranking the transliteration can-
didates is done by evaluating:
</bodyText>
<equation confidence="0.981494">
s* = argmaxi W · IFW(si),
</equation>
<bodyText confidence="0.996724">
which maximizes the objective function with the
generatively computed weight vector and the infor-
mative feature representation derived based on it.
Decision Model 4 Ranking the transliteration can-
didates is done by evaluating:
</bodyText>
<equation confidence="0.956482">
s* = argmaxi WD · IFW(si)),
</equation>
<bodyText confidence="0.999925909090909">
which conceptually resembles the transliteration
model presented in (Bergsma and Kondrak, 2007),
in that a discriminative classifier was trained and
used over a pruned feature set.
which maximize the objective function with the dis-
criminately derived weight vector and the informa-
tive features inferred based on it. This decision
model is the only model that incorporates discrim-
inative weights as part of the feature extraction pro-
cess; WD is used as the objective function used
when inferring IFWD.
</bodyText>
<sectionHeader confidence="0.996776" genericHeader="method">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999993954545455">
We evaluated our approach over a corpus of 300
English-Hebrew transliteration pairs, and used an-
other 250 different samples for training the models.
We constructed the test set by pairing each English
name with all Hebrew names in the corpus. The sys-
tem was evaluated on its ability to correctly iden-
tify the 300 transliteration pairs out of all the pos-
sible transliteration candidates. We measured per-
formance using the Mean Reciprocal Rank (MRR)
measure. This measure, originally introduced in
the field of information retrieval, is used to evaluate
systems that rank several options according to their
probability of correctness. MRR is a natural mea-
sure in our settings and has been used previously
for evaluating transliteration systems, for example
by (Tao et al., 2006).
Given a set Q of queries and their respective
responses ranked according to the system’s confi-
dence, we denote the rank of the correct response
to a query qi E Q as rank(qi). MRR is then de-
fined as the average of the multiplicative inverse of
the rank of the correct answer, that is:
</bodyText>
<equation confidence="0.9977806">
1
� 1
MRR =
|Q |rank(qi).
i=1...|Q|
</equation>
<bodyText confidence="0.999912375">
In our experiments we solved an ILP problem for
every transliteration candidate pairs, and computed
MRR with respect to the confidence of our decision
model across the candidates. Although this required
solving thousands of ILP instances, it posed no com-
putational burden as these instances typically con-
tained a small number of variables and constraints.
The entire test set is solved in less than 20 minutes
</bodyText>
<page confidence="0.997777">
359
</page>
<bodyText confidence="0.999374625">
using the publicly available GLPK package (http:
//www.gnu.org/software/glpk/).
The performance of the different models is sum-
marized in table 1, these results are based on a train-
ing set of 250 samples used to train the discrimi-
native transliteration models and also to construct
the initial weight vector W. Figure 6 shows perfor-
mance over different number of training examples.
Our evaluation is concerns with the core transliter-
ation and decision models presented here and does
not consider any data set optimizations that were in-
troduced in previous works, which we view as or-
thogonal additions, hence the difference with the re-
sults published in (Goldwasser and Roth, 2008).
The results clearly show that our final model,
model 5, outperform other models. Interestingly,
model 1, a simplistic model, significantly outper-
forms the discriminative model presented in (Kle-
mentiev and Roth, 2006b). We believe that this is
due to two reasons. It shows that discriminative
training over the representation obtained using AF
is not efficient; moreover, this phenomenon is ac-
centuated given that we train over a very small data
set, which favors generative estimation of weights.
This is also clear when comparing the performance
of model 1 to model 4, which shows that learning
over the representation obtained using constrained
optimization (IF) results in a very significant perfor-
mance improvement.
The improvement of using IFW is not automatic.
Model 3, which uses IFW, and model 1, which uses
AF, converge to nearly the same result. Both these
models use generative weights to make the translit-
eration decision, and this highlights the importance
of discriminative training. Both model 4 and model
5 use discriminatively trained weights and signifi-
cantly outperform model 3. These results indicate
that using constraint optimization to generate the ex-
amples’ representation in itself may not help; the ob-
jective function used in this inference has a signifi-
cant role in improved performance.
The benefit of discriminatively training the objec-
tive function becomes even clearer when compar-
ing the performance of model 5 to that of model 4,
which uses the original weight vector when inferring
the sample representation.
It can be assumed that this algorithm can bene-
fit from further iterations – generating a new feature
</bodyText>
<table confidence="0.999396375">
Decision Model MRR
Baseline model, used in (KR’06,GR’08)
Model 2 0.51
Models presented in this paper
Model 1 0.713
Model 3 0.715
Model 4 0.832
Model 5 0.848
</table>
<tableCaption confidence="0.98251075">
Table 1: Results of the different transliteration models,
trained using 250 samples. To facilitate readability (Kle-
mentiev and Roth, 2006b; Goldwasser and Roth, 2008)
are referenced as KR’06 and GR’08 respectively.
</tableCaption>
<figureCaption confidence="0.999096">
Figure 6: Results of the different constraint optimization
transliteration models. Performance is compared relative
to the number of samples used for training.
</figureCaption>
<bodyText confidence="0.9999785">
representations, training a model on it, and using the
resulting model as a new objective function. How-
ever, it turns out that after a single round, improved
weights due to additional training do not change the
feature representation; the inference process does
not yield a different outcome.
</bodyText>
<subsectionHeader confidence="0.988744">
3.1 Normalized Objective Function
</subsectionHeader>
<bodyText confidence="0.999216777777778">
Formulating the transliteration decision as an op-
timization problem also allows us to naturally en-
code other considerations into our objective func-
tion. in this case we give preference to matching
short words. We encode this preference as a normal-
ization factor for the objective function. When eval-
uating on pair (ws, wt), we divide the weight vector
length of the shorter word; our decision model now
becomes:
</bodyText>
<sectionHeader confidence="0.7294" genericHeader="method">
Decision Model 6 (Model 5 - LengthNormalization)
</sectionHeader>
<page confidence="0.909615">
360
</page>
<table confidence="0.996201">
Decision Model MRR
Model 5 0.848
Model 5 - LN 0.894
</table>
<tableCaption confidence="0.9106045">
Table 2: Results of using model 5 with and without a
normalized objective function. Both models were trained
</tableCaption>
<figureCaption confidence="0.881767833333333">
using 250 samples. The LN suffix in the model’s name
indicate that the objective function used length normal-
ization.
Figure 7: Results of using model 5 with and without a
normalized objective function. Performance is compared
relative to the number of samples used for training.
</figureCaption>
<bodyText confidence="0.612327">
Ranking the transliteration candidates is done by
evaluating:
</bodyText>
<equation confidence="0.744697">
s* = argmaxz WD · IFWD(sz)/min(|ws|,|wt|)
</equation>
<bodyText confidence="0.999872666666667">
As described in table 2 and figure 7, using
length normalization significantly improves the re-
sults. This can be attributed to the fact that typically
Hebrew names are shorter and therefore every pair
(ws, wt) considered by our model will be effected
differently by this normalization factor.
</bodyText>
<sectionHeader confidence="0.999847" genericHeader="discussions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999991142857143">
We introduced a new approach for identifying NE
transliteration, viewing the transliteration decision
as a global inference problem. We explored sev-
eral methods for combining discriminative learning
in a global constraint optimization framework and
showed that discriminatively learning the objective
function improves performance significantly.
From an algorithmic perspective, our key contri-
bution is the introduction of a new method, in which
learning and inference are used in an integrated way.
We use learning to generate an objective function for
the inference process; use the inference process to
generate a better representation for the learning pro-
cess, and iterate these stages.
From the transliteration perspective, our key con-
tribution is in deriving and showing the significance
of a good representation for a pair of NEs. Our
representation captures both phonetic similarity and
distinctive occurrence patterns across character level
matchings of the two input strings, while enforcing
the constraints induced by the interdependencies of
the individual matchings. As we show, this represen-
tation serves to improve the ability of a discrimina-
tive learning algorithm to weigh features appropri-
ately and results in significantly better transliteration
models. This representation can be viewed as a com-
promise between models that do not consider depen-
dencies between local decisions and those that try to
align the two strings. Achieving this compromise is
one of the advantages of the flexibility allowed by
the constrained optimization framework we use. We
plan to investigate using more constraints within this
framework, such as soft constraints which can pe-
nalize unlikely local decisions while not completely
eliminating the entire solution.
</bodyText>
<sectionHeader confidence="0.99765" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9997146">
We wish to thank Alex Klementiev and the anony-
mous reviewers for their insightful comments. This
work is partly supported by NSF grant SoD-HCER-
0613885 and DARPA funding under the Bootstrap
Learning Program.
</bodyText>
<sectionHeader confidence="0.999477" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999861214285714">
R. Barzilay and M. Lapata. 2006. Aggregation via Set
Partitioning for Natural Language Generation. In Pro-
ceedings of HLT/NAACL, pages 359–366, New York
City, USA, June. Association for Computational Lin-
guistics.
S. Bergsma and G. Kondrak. 2007. Alignment-based
discriminative string similarity. In Proceedings of the
45th Annual Meeting of the Association of Computa-
tional Linguistics, pages 656–663, Prague, Czech Re-
public, June. Association for Computational Linguis-
tics.
J. Clarke and M. Lapata. Modeling compression with
discourse constraints. In Proceedings of the 2007Joint
Conference on Empirical Methods in Natural Lan-
</reference>
<page confidence="0.980685">
361
</page>
<reference confidence="0.999619518518519">
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 1–11.
A. R. Golding and D. Roth. 1999. A Winnow based
approach to context-sensitive spelling correction. Ma-
chine Learning, 34(1-3):107–130.
D. Goldwasser and D. Roth. 2008. Active sample selec-
tion for named entity transliteration. In Proceedings
of ACL-08: HLT, Short Papers, Columbus, OH, USA,
Jun. Association for Computational Linguistics.
A. Grove and D. Roth. 2001. Linear concepts and hidden
variables. Machine Learning, 42(1/2):123–141.
Ulf Hermjakob, Kevin Knight, and Hal Daum´e III. 2008.
Name translation in statistical machine translation -
learning when to transliterate. In Proceedings ofACL-
08: HLT, pages 389–397, Columbus, Ohio, June. As-
sociation for Computational Linguistics.
A. Klementiev and D. Roth. 2006a. Named entity
transliteration and discovery from multilingual com-
parable corpora. In Proc. of the Annual Meeting of the
North American Association of Computational Lin-
guistics (NAACL), pages 82–88, June.
A. Klementiev and D. Roth. 2006b. Weakly supervised
named entity transliteration and discovery from mul-
tilingual comparable corpora. In Proc. of the Annual
Meeting of the ACL, July.
T. Marciniak and M. Strube. 2005. Beyond the Pipeline:
Discrete Optimization in NLP. In Proceedings of the
Ninth CoNLL, pages 136–143, Ann Arbor, Michigan,
June. Association for Computational Linguistics.
A. Y. Ng and M. I. Jordan. 2001. On discriminative vs.
generative classifiers: A comparison of logistic regres-
sion and naive bayes. In Neural Information Process-
ing Systems, pages 841–848.
V. Punyakanok, D. Roth, and W. Yih. 2005. The neces-
sity of syntactic parsing for semantic role labeling. In
Proc. of the International Joint Conference on Artifi-
cial Intelligence (IJCAI), pages 1117–1123.
D. Roth and W. Yih. 2004. A linear programming formu-
lation for global inference in natural language tasks. In
Hwee Tou Ng and Ellen Riloff, editors, Proc. of the
Annual Conference on Computational Natural Lan-
guage Learning (CoNLL), pages 1–8. Association for
Computational Linguistics.
D. Roth. 1998. Learning to resolve natural language am-
biguities: A unified approach. In Proceedings of the
National Conference on Artificial Intelligence (AAAI),
pages 806–813.
Tao Tao, Su-Youn Yoon, Andrew Fister, Richard Sproat,
and ChengXiang Zhai. 2006. Unsupervised named
entity transliteration using temporal and phonetic cor-
relation. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Processing,
pages 250–257, Sydney, Australia, July. Association
for Computational Linguistics.
</reference>
<page confidence="0.998264">
362
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.675719">
<title confidence="0.999953">Transliteration as Constrained Optimization</title>
<author confidence="0.999985">Dan Goldwasser Dan Roth</author>
<affiliation confidence="0.999832">Department of Computer University of</affiliation>
<address confidence="0.9478">Urbana, IL</address>
<abstract confidence="0.9846648">This paper introduces a new method for identifying named-entity (NE) transliterations in bilingual corpora. Recent works have shown the advantage of discriminative approaches to given two strings the source and target language, a classifier is to determine if the transliteraof This paper shows that the transliteration problem can be formulated as a constrained optimization problem and thus take into account contextual dependencies and constraints among character bi-grams in the two strings. We further explore several methods for learning the objective function of the optimization problem and show the advantage of learning it discriminately. Our experiments show that the new framework results in over improvement in translating English NEs to Hebrew.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>M Lapata</author>
</authors>
<title>Aggregation via Set Partitioning for Natural Language Generation.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT/NAACL,</booktitle>
<pages>359--366</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="4776" citStr="Barzilay and Lapata, 2006" startWordPosition="730" endWordPosition="733">problem over a set of local pairwise features – character n-gram matches across the two string – and subject to legitimacy constraints. We use a discriminatively trained classifier as a way to learn the objective function for the global constrained optimization problem. Our technical approach follows a large body of work developed over the last few years, following (Roth and Yih, 2004) that has formalized global decisions problems in NLP as constrained optimization problems and solved these optimization problems using Integer Linear Programming (ILP) or other methods (Punyakanok et al., 2005; Barzilay and Lapata, 2006; Clarke and Lapata, ; Marciniak and Strube, 2005). We investigate several ways to train our objective function, which is represented as a dot product between a set of features chosen to represent a pair (ws, wt), and a vector of initial weights. Our first baseline makes use of all features extracted from a pair, along with a simple counting method to determine initial weights. We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. Our key contribution is that we use a constra</context>
</contexts>
<marker>Barzilay, Lapata, 2006</marker>
<rawString>R. Barzilay and M. Lapata. 2006. Aggregation via Set Partitioning for Natural Language Generation. In Proceedings of HLT/NAACL, pages 359–366, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bergsma</author>
<author>G Kondrak</author>
</authors>
<title>Alignment-based discriminative string similarity.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>656--663</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="3539" citStr="Bergsma and Kondrak, 2007" startWordPosition="537" endWordPosition="540"> address this problem. The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al., 2006) and train a discriminative classifier. That is, given two strings, one in the source and the other in the target language, extract pairwise features, and train a classifier that determines if one is a transliteration of the other. Several papers have followed up on this basic approach and focused on semi-supervised approaches to this problem or on extracting better features for the discriminative classifier (Klementiev and Roth, 2006b; Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008). While it has been clear that the relevancy of pairwise features is context sensitive and that there are contextual constraints among them, the hope was that a discriminative approach will be sufficient to account for those by weighing features appropriately. This has been shown to be difficult for language pairs which are very different, such as English and Hebrew (Goldwasser and Roth, 2008). In this paper, we address these difficulties by proposing to view the transliteration decision as a globally phrased constrained optimization problem. We formalize it as an o</context>
<context position="5498" citStr="Bergsma and Kondrak, 2007" startWordPosition="852" endWordPosition="855">ective function, which is represented as a dot product between a set of features chosen to represent a pair (ws, wt), and a vector of initial weights. Our first baseline makes use of all features extracted from a pair, along with a simple counting method to determine initial weights. We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. Our key contribution is that we use a constrained optimization approach also to determine a better feature representation for a given pair. (Bergsma and Kondrak, 2007) attempted a related approach to restricting the set of features representing a transliteration candidate. However, rather than directly aligning the two strings as done there, we exploit the expressiveness of the ILP formulation and constraints to generate a better representation of a pair. This is the representation we then use to discriminatively learn a better weight vector for the objective function used in our final model. Our experiments focus on Hebrew-English transliteration, which were shown to be very difficult in a previous work (Goldwasser and Roth, 2008). We show very significant</context>
<context position="24406" citStr="Bergsma and Kondrak, 2007" startWordPosition="4002" endWordPosition="4005">s used in (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008), in which a linear transliteration model was trained using a feature extraction method equivalent to AF. Decision Model 3 Ranking the transliteration candidates is done by evaluating: s* = argmaxi W · IFW(si), which maximizes the objective function with the generatively computed weight vector and the informative feature representation derived based on it. Decision Model 4 Ranking the transliteration candidates is done by evaluating: s* = argmaxi WD · IFW(si)), which conceptually resembles the transliteration model presented in (Bergsma and Kondrak, 2007), in that a discriminative classifier was trained and used over a pruned feature set. which maximize the objective function with the discriminately derived weight vector and the informative features inferred based on it. This decision model is the only model that incorporates discriminative weights as part of the feature extraction process; WD is used as the objective function used when inferring IFWD. 3 Evaluation We evaluated our approach over a corpus of 300 English-Hebrew transliteration pairs, and used another 250 different samples for training the models. We constructed the test set by p</context>
</contexts>
<marker>Bergsma, Kondrak, 2007</marker>
<rawString>S. Bergsma and G. Kondrak. 2007. Alignment-based discriminative string similarity. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 656–663, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Clarke</author>
<author>M Lapata</author>
</authors>
<title>Modeling compression with discourse constraints.</title>
<booktitle>In Proceedings of the 2007Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>1--11</pages>
<marker>Clarke, Lapata, </marker>
<rawString>J. Clarke and M. Lapata. Modeling compression with discourse constraints. In Proceedings of the 2007Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 1–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A R Golding</author>
<author>D Roth</author>
</authors>
<title>A Winnow based approach to context-sensitive spelling correction.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--1</pages>
<contexts>
<context position="21262" citStr="Golding and Roth, 1999" startWordPosition="3486" endWordPosition="3489">trength of features naturally into the training algorithm. We augment each sample in the trainFigure 5: Several examples of weights assigned to features generated by coupling English and Hebrew substrings. Top figure: initial weights. Bottom figure: Discriminatively learned weights. The Hebrew characters, ordered left to right, can be romanized as y,z,t,sh ing data with feature weights; given a sample, the learner is presented with a real-valued feature vector instead of a binary vector. This can be viewed as providing a better starting point for the learner, which improves the learning rate (Golding and Roth, 1999; Ng and Jordan, 2001). The weight vector learned by the discriminative training is denoted WD. Given the new weight vector, we can define a new feature extraction operator, that we get by applying the objective function in Eq. 2 with WD instead of W. Given a sample s, the feature representation generated by this new information extraction operator is denoted IFW,,,(s). The key difference between W and WD is that the latter was trained over a corpora containing both negative and positive examples, and as a result WD contains negative weights. To increase the impact of training we multiplied th</context>
</contexts>
<marker>Golding, Roth, 1999</marker>
<rawString>A. R. Golding and D. Roth. 1999. A Winnow based approach to context-sensitive spelling correction. Machine Learning, 34(1-3):107–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Goldwasser</author>
<author>D Roth</author>
</authors>
<title>Active sample selection for named entity transliteration.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT, Short Papers,</booktitle>
<location>Columbus, OH, USA,</location>
<contexts>
<context position="3567" citStr="Goldwasser and Roth, 2008" startWordPosition="541" endWordPosition="544">common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al., 2006) and train a discriminative classifier. That is, given two strings, one in the source and the other in the target language, extract pairwise features, and train a classifier that determines if one is a transliteration of the other. Several papers have followed up on this basic approach and focused on semi-supervised approaches to this problem or on extracting better features for the discriminative classifier (Klementiev and Roth, 2006b; Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008). While it has been clear that the relevancy of pairwise features is context sensitive and that there are contextual constraints among them, the hope was that a discriminative approach will be sufficient to account for those by weighing features appropriately. This has been shown to be difficult for language pairs which are very different, such as English and Hebrew (Goldwasser and Roth, 2008). In this paper, we address these difficulties by proposing to view the transliteration decision as a globally phrased constrained optimization problem. We formalize it as an optimization problem over a s</context>
<context position="5244" citStr="Goldwasser and Roth, 2008" startWordPosition="812" endWordPosition="815">on problems and solved these optimization problems using Integer Linear Programming (ILP) or other methods (Punyakanok et al., 2005; Barzilay and Lapata, 2006; Clarke and Lapata, ; Marciniak and Strube, 2005). We investigate several ways to train our objective function, which is represented as a dot product between a set of features chosen to represent a pair (ws, wt), and a vector of initial weights. Our first baseline makes use of all features extracted from a pair, along with a simple counting method to determine initial weights. We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. Our key contribution is that we use a constrained optimization approach also to determine a better feature representation for a given pair. (Bergsma and Kondrak, 2007) attempted a related approach to restricting the set of features representing a transliteration candidate. However, rather than directly aligning the two strings as done there, we exploit the expressiveness of the ILP formulation and constraints to generate a better representation of a pair. This is the representation we then use to discriminat</context>
<context position="23845" citStr="Goldwasser and Roth, 2008" startWordPosition="3916" endWordPosition="3919">ws, wi�)}i=1...k. In all cases, the decision is formulated as in Eq. 1, where different models differ by the representations and weight vectors used. Decision Model 1 Ranking the transliteration candidates is done by evaluating s* = argmaxi W · AF(si), which selects the transliteration pair which maximizes the objective function based on the generatively computed weight vector. Decision Model 2 Ranking the transliteration candidates is done by evaluating: s* = argmaxi WD · AF(si)). This decision model is essentially equivalent to the transliteration models used in (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008), in which a linear transliteration model was trained using a feature extraction method equivalent to AF. Decision Model 3 Ranking the transliteration candidates is done by evaluating: s* = argmaxi W · IFW(si), which maximizes the objective function with the generatively computed weight vector and the informative feature representation derived based on it. Decision Model 4 Ranking the transliteration candidates is done by evaluating: s* = argmaxi WD · IFW(si)), which conceptually resembles the transliteration model presented in (Bergsma and Kondrak, 2007), in that a discriminative classifier w</context>
<context position="27016" citStr="Goldwasser and Roth, 2008" startWordPosition="4433" endWordPosition="4436">w.gnu.org/software/glpk/). The performance of the different models is summarized in table 1, these results are based on a training set of 250 samples used to train the discriminative transliteration models and also to construct the initial weight vector W. Figure 6 shows performance over different number of training examples. Our evaluation is concerns with the core transliteration and decision models presented here and does not consider any data set optimizations that were introduced in previous works, which we view as orthogonal additions, hence the difference with the results published in (Goldwasser and Roth, 2008). The results clearly show that our final model, model 5, outperform other models. Interestingly, model 1, a simplistic model, significantly outperforms the discriminative model presented in (Klementiev and Roth, 2006b). We believe that this is due to two reasons. It shows that discriminative training over the representation obtained using AF is not efficient; moreover, this phenomenon is accentuated given that we train over a very small data set, which favors generative estimation of weights. This is also clear when comparing the performance of model 1 to model 4, which shows that learning ov</context>
<context position="28984" citStr="Goldwasser and Roth, 2008" startWordPosition="4745" endWordPosition="4748">tively training the objective function becomes even clearer when comparing the performance of model 5 to that of model 4, which uses the original weight vector when inferring the sample representation. It can be assumed that this algorithm can benefit from further iterations – generating a new feature Decision Model MRR Baseline model, used in (KR’06,GR’08) Model 2 0.51 Models presented in this paper Model 1 0.713 Model 3 0.715 Model 4 0.832 Model 5 0.848 Table 1: Results of the different transliteration models, trained using 250 samples. To facilitate readability (Klementiev and Roth, 2006b; Goldwasser and Roth, 2008) are referenced as KR’06 and GR’08 respectively. Figure 6: Results of the different constraint optimization transliteration models. Performance is compared relative to the number of samples used for training. representations, training a model on it, and using the resulting model as a new objective function. However, it turns out that after a single round, improved weights due to additional training do not change the feature representation; the inference process does not yield a different outcome. 3.1 Normalized Objective Function Formulating the transliteration decision as an optimization prob</context>
</contexts>
<marker>Goldwasser, Roth, 2008</marker>
<rawString>D. Goldwasser and D. Roth. 2008. Active sample selection for named entity transliteration. In Proceedings of ACL-08: HLT, Short Papers, Columbus, OH, USA, Jun. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Grove</author>
<author>D Roth</author>
</authors>
<title>Linear concepts and hidden variables.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<pages>42--1</pages>
<contexts>
<context position="20373" citStr="Grove and Roth, 2001" startWordPosition="3341" endWordPosition="3344"> empty-string). Figure 4: The result of applying the IF operator by solving an ILP problem, represented as a pruned graph. IF(s)* = argmaxIF(s)C(AF(s))w · AF(s), subject to constraints C. We will use this operator with w = W, defined above, and denote it IFW, and also use it with a different weight vector, trained discriminatively, as described next. 2.3 Discriminative Training Using the IFW operator, we generate a better representation of the training data, which is now used to train a discriminative model. We use a linear classifier trained with a regularized average perceptron update rule (Grove and Roth, 2001) as implemented in SNoW, (Roth, 1998). This learning algorithm provides a simple and general linear classifier that has been demonstrated to work well in other NLP classification tasks, e.g. (Punyakanok et al., 2005), and allows us to incorporate extensions such as strength of features naturally into the training algorithm. We augment each sample in the trainFigure 5: Several examples of weights assigned to features generated by coupling English and Hebrew substrings. Top figure: initial weights. Bottom figure: Discriminatively learned weights. The Hebrew characters, ordered left to right, can</context>
</contexts>
<marker>Grove, Roth, 2001</marker>
<rawString>A. Grove and D. Roth. 2001. Linear concepts and hidden variables. Machine Learning, 42(1/2):123–141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Hermjakob</author>
<author>Kevin Knight</author>
<author>Hal Daum´e</author>
</authors>
<title>Name translation in statistical machine translation -learning when to transliterate.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL08: HLT,</booktitle>
<pages>389--397</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<marker>Hermjakob, Knight, Daum´e, 2008</marker>
<rawString>Ulf Hermjakob, Kevin Knight, and Hal Daum´e III. 2008. Name translation in statistical machine translation -learning when to transliterate. In Proceedings ofACL08: HLT, pages 389–397, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Klementiev</author>
<author>D Roth</author>
</authors>
<title>Named entity transliteration and discovery from multilingual comparable corpora.</title>
<date>2006</date>
<booktitle>In Proc. of the Annual Meeting of the North American Association of Computational Linguistics (NAACL),</booktitle>
<pages>82--88</pages>
<contexts>
<context position="1407" citStr="Klementiev and Roth, 2006" startWordPosition="200" endWordPosition="203"> function of the optimization problem and show the advantage of learning it discriminately. Our experiments show that the new framework results in over 50% improvement in translating English NEs to Hebrew. 1 Introduction Named entity (NE) transliteration is the process of transcribing a NE from a source language to some target language based on phonetic similarity between the entities. Identifying transliteration pairs is an important component in many linguistic applications which require identifying out-of-vocabulary words, such as machine translation and multilingual information retrieval (Klementiev and Roth, 2006b; Hermjakob et al., 2008). It may appear at first glance that identifying the phonetic correlation between names based on an orthographic analysis is a simple, straight-forward Figure 1: Named entities transliteration pairs in English and Hebrew and the character level mapping between the two names. The Hebrew names can be romanized as eeta-l-ya and a-ya task; however in many cases a consistent deterministic mapping between characters does not exist; rather, the mapping depends on the context the characters appear in and on transliteration conventions which may change across domains. Figure 1</context>
<context position="3053" citStr="Klementiev and Roth, 2006" startWordPosition="458" endWordPosition="461">to an “empty” character. 1In all our example the Hebrew script is shown left-to-right to simplify the visualization of the transliteration mapping. 353 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 353–362, Honolulu, October 2008.c�2008 Association for Computational Linguistics In recent years, as it became clear that solutions that are based on linguistics rules are not satisfactory, machine learning approaches have been developed to address this problem. The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al., 2006) and train a discriminative classifier. That is, given two strings, one in the source and the other in the target language, extract pairwise features, and train a classifier that determines if one is a transliteration of the other. Several papers have followed up on this basic approach and focused on semi-supervised approaches to this problem or on extracting better features for the discriminative classifier (Klementiev and Roth, 2006b; Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008). While it has been clear that the relevancy of pairwise features is context sensitive</context>
<context position="5215" citStr="Klementiev and Roth, 2006" startWordPosition="808" endWordPosition="811">LP as constrained optimization problems and solved these optimization problems using Integer Linear Programming (ILP) or other methods (Punyakanok et al., 2005; Barzilay and Lapata, 2006; Clarke and Lapata, ; Marciniak and Strube, 2005). We investigate several ways to train our objective function, which is represented as a dot product between a set of features chosen to represent a pair (ws, wt), and a vector of initial weights. Our first baseline makes use of all features extracted from a pair, along with a simple counting method to determine initial weights. We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. Our key contribution is that we use a constrained optimization approach also to determine a better feature representation for a given pair. (Bergsma and Kondrak, 2007) attempted a related approach to restricting the set of features representing a transliteration candidate. However, rather than directly aligning the two strings as done there, we exploit the expressiveness of the ILP formulation and constraints to generate a better representation of a pair. This is the representati</context>
<context position="7463" citStr="Klementiev and Roth, 2006" startWordPosition="1179" endWordPosition="1183">a NE in the source language ws and a set of candidates {wt}i in the target language, the decision model ranks the candidate pairs (ws, wt) and selects the “best” candidate pair. This is framed as an optimization problem wt = argmaxz{w · F(ws, wt)}, (1) where F is a feature vector representation of the pair (ws, wt) and w is a vector of weights assigned to each feature. 354 2. Representation A pair s = (ws, wt) of source and target NEs is represented as a vector offeatures, each of which is a pair of character ngrams, from ws and wt, resp. Starting with a baseline representation introduced in (Klementiev and Roth, 2006a), denoted here AF(s), we refine this representation to take into account dependencies among the individual ngram pairs. This refinement process is framed as a constrained optimization problem: F(s)* = argmaxFCAF{w · AF(s)}, (2) subject to a set C of linear constraints. Here AF is the initial representation (All−Features), w is a vector of weights assigned to each feature and C is a set of constraints accounting for interdependencies among features. 3. Weight Vector Each pairwise n-gram feature is associated with a weight; this weigh vector is used in both optimization formulations above. The</context>
<context position="9075" citStr="Klementiev and Roth, 2006" startWordPosition="1434" endWordPosition="1438">feature vector representation described above. The three key operations described above are being used in several stages, with different parameters (weight vectors and representations) as described in Alg. 1. In each stage a different element is refined. The input to this process is a training corpus Tr=(DS,DT) consisting of NE transliteration pairs s = (ws, wt), where ws, wt are NEs in the source and target language, respectively. Each such sample point is initially represented as a feature vector AF(s) (for All−Features), where features are pairs of substrings from the two words (following (Klementiev and Roth, 2006a)). Given the set of feature vectors generated by applying AF to Tr, we assign initial weights W to the features ((1) in Alg. 1). These weights form the initial objective function used to construct a new feature based representation, Informative−Features, IFW(s) ((2) in Alg. 1). Specifically, for an instance s, IFW(s) is the solution of the optimization problem in Eq. 2, with W as the weight vector, AF(s) as the representation, and a set of constraints ensuring the “legitimacy” of the selected set of features (Sec. 2.2.1). Algorithm 1: Transliteration Framework. The new feature extraction ope</context>
<context position="12888" citStr="Klementiev and Roth, 2006" startWordPosition="2085" endWordPosition="2088">grams respectively. Each of these sets is composed of two disjoint subsets: VS = VU ∪ VB , VT = VU ∪ VB consisting of vertices representing the uni-gram and bi-gram strings. Given a vertex v, degree(v, V&apos;)denotes the degree of v in a subgraph of G, consisting only of V &apos; ⊂ V ; index(v) is the index of the substring represented by v in the original string. Edges in the bipartite graph represent active features. The only deviation is that the vertex representing the empty string can be connected to any other (non-empty) vertex. Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. Given a pair, each word is decomposed into a set of character substrings of up to a given length (including the empty string). Features are generated by pairing substrings from the two sets whose relative positions in the original words differ by k or less places, or formally: E = {e = (vi, vj) |(vi ∈ VS ∧ vj ∈ VT) ⇒ (index(vj) + k ≥ index(vi) ≥ index(vj) − k) ∧ Figure 2: All possible unigram and bigram pairs generated by the AF operator. The Hebrew name can be romanized as lo-n-do-n (vi =6 vempty−string ∨ vj =6 ve</context>
<context position="23816" citStr="Klementiev and Roth, 2006" startWordPosition="3912" endWordPosition="3915">he set of candidates {si = (ws, wi�)}i=1...k. In all cases, the decision is formulated as in Eq. 1, where different models differ by the representations and weight vectors used. Decision Model 1 Ranking the transliteration candidates is done by evaluating s* = argmaxi W · AF(si), which selects the transliteration pair which maximizes the objective function based on the generatively computed weight vector. Decision Model 2 Ranking the transliteration candidates is done by evaluating: s* = argmaxi WD · AF(si)). This decision model is essentially equivalent to the transliteration models used in (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008), in which a linear transliteration model was trained using a feature extraction method equivalent to AF. Decision Model 3 Ranking the transliteration candidates is done by evaluating: s* = argmaxi W · IFW(si), which maximizes the objective function with the generatively computed weight vector and the informative feature representation derived based on it. Decision Model 4 Ranking the transliteration candidates is done by evaluating: s* = argmaxi WD · IFW(si)), which conceptually resembles the transliteration model presented in (Bergsma and Kondrak, 2007), in that </context>
<context position="27233" citStr="Klementiev and Roth, 2006" startWordPosition="4464" endWordPosition="4468">construct the initial weight vector W. Figure 6 shows performance over different number of training examples. Our evaluation is concerns with the core transliteration and decision models presented here and does not consider any data set optimizations that were introduced in previous works, which we view as orthogonal additions, hence the difference with the results published in (Goldwasser and Roth, 2008). The results clearly show that our final model, model 5, outperform other models. Interestingly, model 1, a simplistic model, significantly outperforms the discriminative model presented in (Klementiev and Roth, 2006b). We believe that this is due to two reasons. It shows that discriminative training over the representation obtained using AF is not efficient; moreover, this phenomenon is accentuated given that we train over a very small data set, which favors generative estimation of weights. This is also clear when comparing the performance of model 1 to model 4, which shows that learning over the representation obtained using constrained optimization (IF) results in a very significant performance improvement. The improvement of using IFW is not automatic. Model 3, which uses IFW, and model 1, which uses</context>
<context position="28955" citStr="Klementiev and Roth, 2006" startWordPosition="4740" endWordPosition="4744">e. The benefit of discriminatively training the objective function becomes even clearer when comparing the performance of model 5 to that of model 4, which uses the original weight vector when inferring the sample representation. It can be assumed that this algorithm can benefit from further iterations – generating a new feature Decision Model MRR Baseline model, used in (KR’06,GR’08) Model 2 0.51 Models presented in this paper Model 1 0.713 Model 3 0.715 Model 4 0.832 Model 5 0.848 Table 1: Results of the different transliteration models, trained using 250 samples. To facilitate readability (Klementiev and Roth, 2006b; Goldwasser and Roth, 2008) are referenced as KR’06 and GR’08 respectively. Figure 6: Results of the different constraint optimization transliteration models. Performance is compared relative to the number of samples used for training. representations, training a model on it, and using the resulting model as a new objective function. However, it turns out that after a single round, improved weights due to additional training do not change the feature representation; the inference process does not yield a different outcome. 3.1 Normalized Objective Function Formulating the transliteration dec</context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>A. Klementiev and D. Roth. 2006a. Named entity transliteration and discovery from multilingual comparable corpora. In Proc. of the Annual Meeting of the North American Association of Computational Linguistics (NAACL), pages 82–88, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Klementiev</author>
<author>D Roth</author>
</authors>
<title>Weakly supervised named entity transliteration and discovery from multilingual comparable corpora.</title>
<date>2006</date>
<booktitle>In Proc. of the Annual Meeting of the ACL,</booktitle>
<contexts>
<context position="1407" citStr="Klementiev and Roth, 2006" startWordPosition="200" endWordPosition="203"> function of the optimization problem and show the advantage of learning it discriminately. Our experiments show that the new framework results in over 50% improvement in translating English NEs to Hebrew. 1 Introduction Named entity (NE) transliteration is the process of transcribing a NE from a source language to some target language based on phonetic similarity between the entities. Identifying transliteration pairs is an important component in many linguistic applications which require identifying out-of-vocabulary words, such as machine translation and multilingual information retrieval (Klementiev and Roth, 2006b; Hermjakob et al., 2008). It may appear at first glance that identifying the phonetic correlation between names based on an orthographic analysis is a simple, straight-forward Figure 1: Named entities transliteration pairs in English and Hebrew and the character level mapping between the two names. The Hebrew names can be romanized as eeta-l-ya and a-ya task; however in many cases a consistent deterministic mapping between characters does not exist; rather, the mapping depends on the context the characters appear in and on transliteration conventions which may change across domains. Figure 1</context>
<context position="3053" citStr="Klementiev and Roth, 2006" startWordPosition="458" endWordPosition="461">to an “empty” character. 1In all our example the Hebrew script is shown left-to-right to simplify the visualization of the transliteration mapping. 353 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 353–362, Honolulu, October 2008.c�2008 Association for Computational Linguistics In recent years, as it became clear that solutions that are based on linguistics rules are not satisfactory, machine learning approaches have been developed to address this problem. The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al., 2006) and train a discriminative classifier. That is, given two strings, one in the source and the other in the target language, extract pairwise features, and train a classifier that determines if one is a transliteration of the other. Several papers have followed up on this basic approach and focused on semi-supervised approaches to this problem or on extracting better features for the discriminative classifier (Klementiev and Roth, 2006b; Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008). While it has been clear that the relevancy of pairwise features is context sensitive</context>
<context position="5215" citStr="Klementiev and Roth, 2006" startWordPosition="808" endWordPosition="811">LP as constrained optimization problems and solved these optimization problems using Integer Linear Programming (ILP) or other methods (Punyakanok et al., 2005; Barzilay and Lapata, 2006; Clarke and Lapata, ; Marciniak and Strube, 2005). We investigate several ways to train our objective function, which is represented as a dot product between a set of features chosen to represent a pair (ws, wt), and a vector of initial weights. Our first baseline makes use of all features extracted from a pair, along with a simple counting method to determine initial weights. We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. Our key contribution is that we use a constrained optimization approach also to determine a better feature representation for a given pair. (Bergsma and Kondrak, 2007) attempted a related approach to restricting the set of features representing a transliteration candidate. However, rather than directly aligning the two strings as done there, we exploit the expressiveness of the ILP formulation and constraints to generate a better representation of a pair. This is the representati</context>
<context position="7463" citStr="Klementiev and Roth, 2006" startWordPosition="1179" endWordPosition="1183">a NE in the source language ws and a set of candidates {wt}i in the target language, the decision model ranks the candidate pairs (ws, wt) and selects the “best” candidate pair. This is framed as an optimization problem wt = argmaxz{w · F(ws, wt)}, (1) where F is a feature vector representation of the pair (ws, wt) and w is a vector of weights assigned to each feature. 354 2. Representation A pair s = (ws, wt) of source and target NEs is represented as a vector offeatures, each of which is a pair of character ngrams, from ws and wt, resp. Starting with a baseline representation introduced in (Klementiev and Roth, 2006a), denoted here AF(s), we refine this representation to take into account dependencies among the individual ngram pairs. This refinement process is framed as a constrained optimization problem: F(s)* = argmaxFCAF{w · AF(s)}, (2) subject to a set C of linear constraints. Here AF is the initial representation (All−Features), w is a vector of weights assigned to each feature and C is a set of constraints accounting for interdependencies among features. 3. Weight Vector Each pairwise n-gram feature is associated with a weight; this weigh vector is used in both optimization formulations above. The</context>
<context position="9075" citStr="Klementiev and Roth, 2006" startWordPosition="1434" endWordPosition="1438">feature vector representation described above. The three key operations described above are being used in several stages, with different parameters (weight vectors and representations) as described in Alg. 1. In each stage a different element is refined. The input to this process is a training corpus Tr=(DS,DT) consisting of NE transliteration pairs s = (ws, wt), where ws, wt are NEs in the source and target language, respectively. Each such sample point is initially represented as a feature vector AF(s) (for All−Features), where features are pairs of substrings from the two words (following (Klementiev and Roth, 2006a)). Given the set of feature vectors generated by applying AF to Tr, we assign initial weights W to the features ((1) in Alg. 1). These weights form the initial objective function used to construct a new feature based representation, Informative−Features, IFW(s) ((2) in Alg. 1). Specifically, for an instance s, IFW(s) is the solution of the optimization problem in Eq. 2, with W as the weight vector, AF(s) as the representation, and a set of constraints ensuring the “legitimacy” of the selected set of features (Sec. 2.2.1). Algorithm 1: Transliteration Framework. The new feature extraction ope</context>
<context position="12888" citStr="Klementiev and Roth, 2006" startWordPosition="2085" endWordPosition="2088">grams respectively. Each of these sets is composed of two disjoint subsets: VS = VU ∪ VB , VT = VU ∪ VB consisting of vertices representing the uni-gram and bi-gram strings. Given a vertex v, degree(v, V&apos;)denotes the degree of v in a subgraph of G, consisting only of V &apos; ⊂ V ; index(v) is the index of the substring represented by v in the original string. Edges in the bipartite graph represent active features. The only deviation is that the vertex representing the empty string can be connected to any other (non-empty) vertex. Our initial feature extraction method follows the one presented in (Klementiev and Roth, 2006a), in which the feature space consists of n-gram pairs from the two languages. Given a pair, each word is decomposed into a set of character substrings of up to a given length (including the empty string). Features are generated by pairing substrings from the two sets whose relative positions in the original words differ by k or less places, or formally: E = {e = (vi, vj) |(vi ∈ VS ∧ vj ∈ VT) ⇒ (index(vj) + k ≥ index(vi) ≥ index(vj) − k) ∧ Figure 2: All possible unigram and bigram pairs generated by the AF operator. The Hebrew name can be romanized as lo-n-do-n (vi =6 vempty−string ∨ vj =6 ve</context>
<context position="23816" citStr="Klementiev and Roth, 2006" startWordPosition="3912" endWordPosition="3915">he set of candidates {si = (ws, wi�)}i=1...k. In all cases, the decision is formulated as in Eq. 1, where different models differ by the representations and weight vectors used. Decision Model 1 Ranking the transliteration candidates is done by evaluating s* = argmaxi W · AF(si), which selects the transliteration pair which maximizes the objective function based on the generatively computed weight vector. Decision Model 2 Ranking the transliteration candidates is done by evaluating: s* = argmaxi WD · AF(si)). This decision model is essentially equivalent to the transliteration models used in (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008), in which a linear transliteration model was trained using a feature extraction method equivalent to AF. Decision Model 3 Ranking the transliteration candidates is done by evaluating: s* = argmaxi W · IFW(si), which maximizes the objective function with the generatively computed weight vector and the informative feature representation derived based on it. Decision Model 4 Ranking the transliteration candidates is done by evaluating: s* = argmaxi WD · IFW(si)), which conceptually resembles the transliteration model presented in (Bergsma and Kondrak, 2007), in that </context>
<context position="27233" citStr="Klementiev and Roth, 2006" startWordPosition="4464" endWordPosition="4468">construct the initial weight vector W. Figure 6 shows performance over different number of training examples. Our evaluation is concerns with the core transliteration and decision models presented here and does not consider any data set optimizations that were introduced in previous works, which we view as orthogonal additions, hence the difference with the results published in (Goldwasser and Roth, 2008). The results clearly show that our final model, model 5, outperform other models. Interestingly, model 1, a simplistic model, significantly outperforms the discriminative model presented in (Klementiev and Roth, 2006b). We believe that this is due to two reasons. It shows that discriminative training over the representation obtained using AF is not efficient; moreover, this phenomenon is accentuated given that we train over a very small data set, which favors generative estimation of weights. This is also clear when comparing the performance of model 1 to model 4, which shows that learning over the representation obtained using constrained optimization (IF) results in a very significant performance improvement. The improvement of using IFW is not automatic. Model 3, which uses IFW, and model 1, which uses</context>
<context position="28955" citStr="Klementiev and Roth, 2006" startWordPosition="4740" endWordPosition="4744">e. The benefit of discriminatively training the objective function becomes even clearer when comparing the performance of model 5 to that of model 4, which uses the original weight vector when inferring the sample representation. It can be assumed that this algorithm can benefit from further iterations – generating a new feature Decision Model MRR Baseline model, used in (KR’06,GR’08) Model 2 0.51 Models presented in this paper Model 1 0.713 Model 3 0.715 Model 4 0.832 Model 5 0.848 Table 1: Results of the different transliteration models, trained using 250 samples. To facilitate readability (Klementiev and Roth, 2006b; Goldwasser and Roth, 2008) are referenced as KR’06 and GR’08 respectively. Figure 6: Results of the different constraint optimization transliteration models. Performance is compared relative to the number of samples used for training. representations, training a model on it, and using the resulting model as a new objective function. However, it turns out that after a single round, improved weights due to additional training do not change the feature representation; the inference process does not yield a different outcome. 3.1 Normalized Objective Function Formulating the transliteration dec</context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>A. Klementiev and D. Roth. 2006b. Weakly supervised named entity transliteration and discovery from multilingual comparable corpora. In Proc. of the Annual Meeting of the ACL, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Marciniak</author>
<author>M Strube</author>
</authors>
<title>Beyond the Pipeline: Discrete Optimization in NLP.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth CoNLL,</booktitle>
<pages>136--143</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="4826" citStr="Marciniak and Strube, 2005" startWordPosition="738" endWordPosition="741">character n-gram matches across the two string – and subject to legitimacy constraints. We use a discriminatively trained classifier as a way to learn the objective function for the global constrained optimization problem. Our technical approach follows a large body of work developed over the last few years, following (Roth and Yih, 2004) that has formalized global decisions problems in NLP as constrained optimization problems and solved these optimization problems using Integer Linear Programming (ILP) or other methods (Punyakanok et al., 2005; Barzilay and Lapata, 2006; Clarke and Lapata, ; Marciniak and Strube, 2005). We investigate several ways to train our objective function, which is represented as a dot product between a set of features chosen to represent a pair (ws, wt), and a vector of initial weights. Our first baseline makes use of all features extracted from a pair, along with a simple counting method to determine initial weights. We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. Our key contribution is that we use a constrained optimization approach also to determine a bet</context>
</contexts>
<marker>Marciniak, Strube, 2005</marker>
<rawString>T. Marciniak and M. Strube. 2005. Beyond the Pipeline: Discrete Optimization in NLP. In Proceedings of the Ninth CoNLL, pages 136–143, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Y Ng</author>
<author>M I Jordan</author>
</authors>
<title>On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes.</title>
<date>2001</date>
<booktitle>In Neural Information Processing Systems,</booktitle>
<pages>841--848</pages>
<contexts>
<context position="21284" citStr="Ng and Jordan, 2001" startWordPosition="3490" endWordPosition="3493">rally into the training algorithm. We augment each sample in the trainFigure 5: Several examples of weights assigned to features generated by coupling English and Hebrew substrings. Top figure: initial weights. Bottom figure: Discriminatively learned weights. The Hebrew characters, ordered left to right, can be romanized as y,z,t,sh ing data with feature weights; given a sample, the learner is presented with a real-valued feature vector instead of a binary vector. This can be viewed as providing a better starting point for the learner, which improves the learning rate (Golding and Roth, 1999; Ng and Jordan, 2001). The weight vector learned by the discriminative training is denoted WD. Given the new weight vector, we can define a new feature extraction operator, that we get by applying the objective function in Eq. 2 with WD instead of W. Given a sample s, the feature representation generated by this new information extraction operator is denoted IFW,,,(s). The key difference between W and WD is that the latter was trained over a corpora containing both negative and positive examples, and as a result WD contains negative weights. To increase the impact of training we multiplied the negative weights by </context>
</contexts>
<marker>Ng, Jordan, 2001</marker>
<rawString>A. Y. Ng and M. I. Jordan. 2001. On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes. In Neural Information Processing Systems, pages 841–848.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Punyakanok</author>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>The necessity of syntactic parsing for semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI),</booktitle>
<pages>1117--1123</pages>
<contexts>
<context position="4749" citStr="Punyakanok et al., 2005" startWordPosition="725" endWordPosition="729">ze it as an optimization problem over a set of local pairwise features – character n-gram matches across the two string – and subject to legitimacy constraints. We use a discriminatively trained classifier as a way to learn the objective function for the global constrained optimization problem. Our technical approach follows a large body of work developed over the last few years, following (Roth and Yih, 2004) that has formalized global decisions problems in NLP as constrained optimization problems and solved these optimization problems using Integer Linear Programming (ILP) or other methods (Punyakanok et al., 2005; Barzilay and Lapata, 2006; Clarke and Lapata, ; Marciniak and Strube, 2005). We investigate several ways to train our objective function, which is represented as a dot product between a set of features chosen to represent a pair (ws, wt), and a vector of initial weights. Our first baseline makes use of all features extracted from a pair, along with a simple counting method to determine initial weights. We then use a method similar to (Klementiev and Roth, 2006a; Goldwasser and Roth, 2008) in order to discriminatively train a better weight vector for the objective function. Our key contributi</context>
<context position="20589" citStr="Punyakanok et al., 2005" startWordPosition="3377" endWordPosition="3380"> with w = W, defined above, and denote it IFW, and also use it with a different weight vector, trained discriminatively, as described next. 2.3 Discriminative Training Using the IFW operator, we generate a better representation of the training data, which is now used to train a discriminative model. We use a linear classifier trained with a regularized average perceptron update rule (Grove and Roth, 2001) as implemented in SNoW, (Roth, 1998). This learning algorithm provides a simple and general linear classifier that has been demonstrated to work well in other NLP classification tasks, e.g. (Punyakanok et al., 2005), and allows us to incorporate extensions such as strength of features naturally into the training algorithm. We augment each sample in the trainFigure 5: Several examples of weights assigned to features generated by coupling English and Hebrew substrings. Top figure: initial weights. Bottom figure: Discriminatively learned weights. The Hebrew characters, ordered left to right, can be romanized as y,z,t,sh ing data with feature weights; given a sample, the learner is presented with a real-valued feature vector instead of a binary vector. This can be viewed as providing a better starting point </context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2005</marker>
<rawString>V. Punyakanok, D. Roth, and W. Yih. 2005. The necessity of syntactic parsing for semantic role labeling. In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI), pages 1117–1123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<booktitle>In Hwee Tou Ng and Ellen Riloff, editors, Proc. of the Annual Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>1--8</pages>
<publisher>Association for Computational Linguistics.</publisher>
<contexts>
<context position="4539" citStr="Roth and Yih, 2004" startWordPosition="696" endWordPosition="699">lish and Hebrew (Goldwasser and Roth, 2008). In this paper, we address these difficulties by proposing to view the transliteration decision as a globally phrased constrained optimization problem. We formalize it as an optimization problem over a set of local pairwise features – character n-gram matches across the two string – and subject to legitimacy constraints. We use a discriminatively trained classifier as a way to learn the objective function for the global constrained optimization problem. Our technical approach follows a large body of work developed over the last few years, following (Roth and Yih, 2004) that has formalized global decisions problems in NLP as constrained optimization problems and solved these optimization problems using Integer Linear Programming (ILP) or other methods (Punyakanok et al., 2005; Barzilay and Lapata, 2006; Clarke and Lapata, ; Marciniak and Strube, 2005). We investigate several ways to train our objective function, which is represented as a dot product between a set of features chosen to represent a pair (ws, wt), and a vector of initial weights. Our first baseline makes use of all features extracted from a pair, along with a simple counting method to determine</context>
<context position="16603" citStr="Roth and Yih, 2004" startWordPosition="2702" endWordPosition="2705">ermining the representation of a given word pair. We use the strength of the active features computed above, along with legitimacy constraints on mappings between source and target strings to find an optimal set of consistent active features that represents a pair. This problem can be naturally encoded as a linear optimization problem, which seeks to maximize a linear objective function determined by W, over a set of variables representing the active features selection, subject to a set of linear constraints representing the dependencies between selections. We follow the formulation given by (Roth and Yih, 2004), and define it as an Integer Linear Programming (ILP) optimization problem, in which each integer variable a(j�k), defined over {0, 1J, represents whether a feature pairing an n-gram j E S with an n-gram k E T, is active. Although using ILP is in general NP-hard, it has been used efficiently in many natural language (see section 1). Our experience as well has been that this process is very efficient due to the sparsity of the constraints used. 2.2.1 Constraining Feature Dependencies To limit the selection of active features in each sample we require that each element in the decomposition of w</context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>D. Roth and W. Yih. 2004. A linear programming formulation for global inference in natural language tasks. In Hwee Tou Ng and Ellen Riloff, editors, Proc. of the Annual Conference on Computational Natural Language Learning (CoNLL), pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
</authors>
<title>Learning to resolve natural language ambiguities: A unified approach.</title>
<date>1998</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence (AAAI),</booktitle>
<pages>806--813</pages>
<contexts>
<context position="20410" citStr="Roth, 1998" startWordPosition="3350" endWordPosition="3351">g the IF operator by solving an ILP problem, represented as a pruned graph. IF(s)* = argmaxIF(s)C(AF(s))w · AF(s), subject to constraints C. We will use this operator with w = W, defined above, and denote it IFW, and also use it with a different weight vector, trained discriminatively, as described next. 2.3 Discriminative Training Using the IFW operator, we generate a better representation of the training data, which is now used to train a discriminative model. We use a linear classifier trained with a regularized average perceptron update rule (Grove and Roth, 2001) as implemented in SNoW, (Roth, 1998). This learning algorithm provides a simple and general linear classifier that has been demonstrated to work well in other NLP classification tasks, e.g. (Punyakanok et al., 2005), and allows us to incorporate extensions such as strength of features naturally into the training algorithm. We augment each sample in the trainFigure 5: Several examples of weights assigned to features generated by coupling English and Hebrew substrings. Top figure: initial weights. Bottom figure: Discriminatively learned weights. The Hebrew characters, ordered left to right, can be romanized as y,z,t,sh ing data wi</context>
</contexts>
<marker>Roth, 1998</marker>
<rawString>D. Roth. 1998. Learning to resolve natural language ambiguities: A unified approach. In Proceedings of the National Conference on Artificial Intelligence (AAAI), pages 806–813.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Tao</author>
<author>Su-Youn Yoon</author>
<author>Andrew Fister</author>
<author>Richard Sproat</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Unsupervised named entity transliteration using temporal and phonetic correlation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>250--257</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="3073" citStr="Tao et al., 2006" startWordPosition="462" endWordPosition="465"> all our example the Hebrew script is shown left-to-right to simplify the visualization of the transliteration mapping. 353 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 353–362, Honolulu, October 2008.c�2008 Association for Computational Linguistics In recent years, as it became clear that solutions that are based on linguistics rules are not satisfactory, machine learning approaches have been developed to address this problem. The common approach adopted is therefore to view this problem as a classification problem (Klementiev and Roth, 2006a; Tao et al., 2006) and train a discriminative classifier. That is, given two strings, one in the source and the other in the target language, extract pairwise features, and train a classifier that determines if one is a transliteration of the other. Several papers have followed up on this basic approach and focused on semi-supervised approaches to this problem or on extracting better features for the discriminative classifier (Klementiev and Roth, 2006b; Bergsma and Kondrak, 2007; Goldwasser and Roth, 2008). While it has been clear that the relevancy of pairwise features is context sensitive and that there are </context>
<context position="25601" citStr="Tao et al., 2006" startWordPosition="4195" endWordPosition="4198">cted the test set by pairing each English name with all Hebrew names in the corpus. The system was evaluated on its ability to correctly identify the 300 transliteration pairs out of all the possible transliteration candidates. We measured performance using the Mean Reciprocal Rank (MRR) measure. This measure, originally introduced in the field of information retrieval, is used to evaluate systems that rank several options according to their probability of correctness. MRR is a natural measure in our settings and has been used previously for evaluating transliteration systems, for example by (Tao et al., 2006). Given a set Q of queries and their respective responses ranked according to the system’s confidence, we denote the rank of the correct response to a query qi E Q as rank(qi). MRR is then defined as the average of the multiplicative inverse of the rank of the correct answer, that is: 1 � 1 MRR = |Q |rank(qi). i=1...|Q| In our experiments we solved an ILP problem for every transliteration candidate pairs, and computed MRR with respect to the confidence of our decision model across the candidates. Although this required solving thousands of ILP instances, it posed no computational burden as the</context>
</contexts>
<marker>Tao, Yoon, Fister, Sproat, Zhai, 2006</marker>
<rawString>Tao Tao, Su-Youn Yoon, Andrew Fister, Richard Sproat, and ChengXiang Zhai. 2006. Unsupervised named entity transliteration using temporal and phonetic correlation. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 250–257, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>