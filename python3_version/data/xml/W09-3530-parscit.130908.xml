<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.105516">
<title confidence="0.997056">
Name Transliteration with Bidirectional Perceptron Edit Models
</title>
<author confidence="0.873049">
Dayne Freitag Zhiqiang (John) Wang
</author>
<affiliation confidence="0.728886">
SRI International SRI International
</affiliation>
<email confidence="0.991465">
freitag@ai.sri.com johnwang@ai.sri.com
</email>
<sectionHeader confidence="0.993722" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99997795">
We report on our efforts as part of the
shared task on the NEWS 2009 Machine
Transliteration Shared Task. We applied
an orthographic perceptron character edit
model that we have used previously for
name transliteration, enhancing it in two
ways: by ranking possible transliterations
according to the sum of their scores ac-
cording to two models, one trained to gen-
erate left-to-right, and one right-to-left;
and by constraining generated strings to
be consistent with character bigrams ob-
served in the respective language’s train-
ing data. Our poor showing in the of-
ficial evaluation was due to a bug in
the script used to produce competition-
compliant output. Subsequent evaluation
shows that our approach yielded compara-
tively strong performance on all alphabetic
language pairs we attempted.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999906607142857">
While transliteration is a much simpler prob-
lem than another linguistic transduction prob-
lem, language translation, it is rarely trivial. At
least three phenomena complicate the automatic
transliteration between two languages using dif-
ferent scripts—differing phoneme sets, lossy or-
thography, and non-alphabetic orthographies (e.g.,
syllabaries).
For most language pairs, these difficulties stand
in the way of a rule-based treatment of the prob-
lem. For this reason, many machine learning ap-
proaches to the problem have been proposed. We
can draw a rough distinction between learning ap-
proaches that attempt to model the phonetics of
a transliteration problem explicitly, and those that
treat the problem as simply one of orthographic
transduction, leaving it to the learning algorithm
to acquire phonetic distinctions directly from or-
thographic features of the training data. For exam-
ple, Knight and Graehl (1998) address the prob-
lem through cascaded finite state transducers, with
explicit representations of the phonetics. Sub-
sequently, Al-Onaizan and Knight (2002) realize
improvements by adding a “spelling” (i.e., ortho-
graphic) model. There has been an increasing em-
phasis on purely orthographic models, probably
because they require less detailed domain knowl-
edge (e.g., (Lee and Chang, 2003)).
</bodyText>
<sectionHeader confidence="0.982325" genericHeader="introduction">
2 Approach
</sectionHeader>
<bodyText confidence="0.999980153846154">
The approach we explored as part of the NEWS
2009 Machine Transliteration Shared Task (Li et
al., 2009) is strictly orthographic. We view the
conversion of a name in one language to its rep-
resentation in another as the product of a series
of single-character edits, and seek to learn a char-
acter edit model that maximizes the score of cor-
rect name pairs. Our approach follows that de-
scribed in Freitag and Khadivi (2007), a “struc-
tured perceptron” with cheaply computed charac-
ter n-grams as features. Here, we give a brief
description, and present the successful enhance-
ments we tried specifically for the shared task.
</bodyText>
<subsectionHeader confidence="0.970131">
2.1 Perceptron Edit Model
</subsectionHeader>
<bodyText confidence="0.999887142857143">
Suppose we are given two sequences, sm1 ∈ E∗s
and tn1 ∈ E∗t . We desire a function A(s, t) H N
which assigns high scores to correct pairs s, t. If
we stipulate that this score is the sum of the indi-
vidual scores of a series of edits, we can find the
highest-scoring such series through a generaliza-
tion of the standard edit distance:
</bodyText>
<equation confidence="0.991455181818182">
A(si1,tj1) _
1
aǫ,tj (s, i, t, j) + A(si1, )
i−1
asi,ǫ(s, i, t, j) + A(s1 , tj1)
asi,tj(s, i, t, j) + A(si−1
1 , tj−1
1 )
I
max
(1)
</equation>
<page confidence="0.968765">
132
</page>
<note confidence="0.9831335">
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 132–135,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.99939095">
with A(0, 0) = 0. The function asi,tj(s, i, t, j)
represents the score of substituting tj for si; aǫ,tj
and asi,ǫ represent insertion and deletion, respec-
tively.
In the experiments reported in this paper, we as-
sume that each local function a is defined in terms
of p + q features, {f1, · · · , fp, fp+1, ·· · , fp+q},
defined over the source and target alphabets, re-
spectively, and that these features have the func-
tional form Σ∗ x N H R.
In this paper we exclusively use character n-
gram indicator features. The “order” of a model
is the size of the largest n-grams; for a model of
order 2, features would be the bigrams and uni-
grams immediately adjacent to a given string posi-
tion. Since the shared task is to generate target
strings, only features for preceding n-grams are
used in the target language.
The score of a particular edit is a linear combi-
nation of the corresponding feature values:
</bodyText>
<equation confidence="0.958732666666667">
p p+q
a(s,i,t,j) = E αk ·fk(s, i)+ E αk·fk(t, j)
k=1 k=p+1
</equation>
<bodyText confidence="0.99739624137931">
(2)
The weights αk are what we seek to optimize in
order to tune the model for our particular applica-
tion.
We optimize these weights through an exten-
sion of perceptron training for sequence labeling,
due to Collins (2002). Take α to be a model pa-
rameterization, and let Aα(s, t) return an optimal
edit sequence e, with its score v, given input se-
quences s and t under α. Elements of sequence
e are character pairs (cs, ct), with cs E Σs U {E}
and ct E Σt U {E}, where E represents the empty
string. Let Φ(s, t, e) be a feature vector for a
source string, target string, and corresponding edit
sequence.
Table 1 shows the training algorithm. Starting
with a zero parameter vector, we iterate through
the collection of source sequences. For each se-
quence, we pick two target sequences, one the
“true” transliteration t of the source string s, and
one chosen by searching for a string t′ that yields a
maximal score according to the current model Aα
(Line 6). If the model fails to assign t a higher
score than t′ (Line 9), we apply the perceptron
training update (Line 10).
Note that because generation constructs the tar-
get sequence, the search in Line 6 for a target
string t′ that yields maximal Aα(s, t′) is not triv-
ial, and does not correspond to a simple recurrence
</bodyText>
<listItem confidence="0.997120133333333">
1: Given training set S = {(s, t)}
2: V &lt;-- [], an empty list
3: α &lt;-- 0, a weight vector
4: for some number of iterations do
5: for (s, t) in S do
6: t′ &lt;-- maxargt′Aα(s, t′)
7: (e, v) &lt;-- Aα(s, t)
8: (e′, v′) &lt;-- Aα(s, t′)
9: if v′ &gt; v then
10: α &lt;-- α + Φ(s, t, e) − Φ(s, t′, e′)
11: end if
12: Append α to V
13: end for
14: end for
15: Return the mean α from V
</listItem>
<tableCaption confidence="0.968664">
Table 1: The training algorithm. Aα is the affinity
</tableCaption>
<bodyText confidence="0.929073555555556">
function under model parameters α, returning edit
sequence e and score v.
relation like Equation 1. Both in training and test-
ing, we use a beam search for target string gener-
ation. In training, this may mean that we find a t′
with lower score than the correct target t. In such
cases (Line 9 returns false), the model has cor-
rectly ordered the two alternative transliterations,
and does not require updating.
</bodyText>
<subsectionHeader confidence="0.991657">
2.2 Shared Task Extensions
</subsectionHeader>
<bodyText confidence="0.999861954545455">
This approach has been used effectively for prac-
tical transliteration of names from English to Ara-
bic and Mandarin (and vice versa). As part of
the NEWS shared task, we experimented with two
simple extensions, both of which yielded improve-
ments over the baseline described above. These
extensions were used in our official submission for
alphabetic language pairs. We treated English-to-
Chinese somewhat differently, as described below.
Simple character n-gram constraints. The
described approach sometimes violates target
language spelling conventions by interpolating
clearly inappropriate characters into a string that
is otherwise a reasonable transliteration. We take
this behavior as symptomatic of a kind of under-
training in some portion of the problem space,
a possible byproduct of 1-best perceptron train-
ing. One principled solution may be to optimize
against n-best lists (Bellare et al., 2009).
Instead, we address this shortcoming in a
straightforward way—by prohibiting the creation
of n-grams, for some small n, that do not occur
</bodyText>
<page confidence="0.996119">
133
</page>
<bodyText confidence="0.9999789375">
in the training data. Under a bigram restriction, if
‘ab’ is not seen in training, then an operation that
inserts ‘b’ after ‘a’ is disallowed. In essence, we
impose a very simple character language model of
the target domain.
Our non-standard English-to-Chinese contribu-
tions, which involved transliterating from English
to pinyin, employed a similar idea. In these exper-
iments, rather than character bigrams, the model
was constrained to produce only legal pinyin se-
quences.
Bidirectional generation. Character n-gram
restrictions yielded modest but universal improve-
ments on development data. Larger improvements
were obtained through an equally simple idea: In-
stead of a single left-to-right model, we trained
two models, one generating left-to-right, the other
right-to-left, each model constrained by n-gram ta-
bles, as described above. At evaluation time, each
of the constituent models was used to generate a
large number of candidate strings (100, typically).
All strings in the union of these two sets were then
assigned a score, which was the unweighted sum
of scores according to the constituent models, and
reranked according to this score. The 10 highest-
scoring were retained for evaluation.
A buggy implementation of this two-model idea
accounts for our poor showing in the official eval-
uation. Because of a trivial error in the script we
used to produce output, right-to-left models were
treated as if they were left-to-right. The resulting
strings and scores were consequently erroneous.
</bodyText>
<sectionHeader confidence="0.99897" genericHeader="background">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999957470588235">
We experimented with models of order 2 and
3 (2-gram and 3-gram features) on shared task
data for English to Hindi, Kannada, Russian, and
Tamil (Kumaran and Kellner, 2007). Based on
development accuracy scores, we found models
of order 3 to be consistently better than order 2,
and our submitted results use only order-3 models,
with one exception. English-to-native-Chinese (Li
et al., 2004) was treated as a special case. Using
trigram features in the target language results in
an explosion in the feature space, and a model that
is slow to train and performs poorly. Thus, only
for this language pair, we devised a mixed-order
model, one using trigram features over English
strings, and unigram features over Chinese. Be-
cause of the large target-language branching fac-
tor, the mixed-order native Chinese model remain-
</bodyText>
<table confidence="0.998712166666667">
Languages Accuracy Delta
EnHi 0.465 -0.033
EnHi baseline 0.421 -0.077
EnKa 0.396 -0.002
EnKa baseline 0.370 -0.028
EnRu 0.609 -0.004
EnRu baseline 0.588 -0.025
EnTa 0.475 +0.001
EnTa baseline 0.422 -0.052
EnCh standard 0.672 -0.059
EnCh non-standard 1 0.673 -0.236
EnCh non-standard 2 0.5 -0.409
</table>
<tableCaption confidence="0.993582">
Table 2: Post-contest accuracy on evaluation set,
</tableCaption>
<bodyText confidence="0.9878506">
including delta from highest-scoring contest par-
ticipant.
ing one of the slowest to train.
We trained all models for 20 epochs, evaluating
the 1-best accuracy of intervening models on the
development data. In all cases, we observed that
accuracy increased steadily for some number of it-
erations, after which it plateaued. Consequently,
for all language pairs, we submitted the predic-
tions of the latest model.
Table 2 lists accuracy reported by the official
evaluation script on the contest evaluation data.
All non-Chinese runs in the table are “standard,”
and are trained exclusively on shared task train-
ing data. Those labeled “baseline” are left-to-
right models with no character n-gram constraints.
These results were obtained after release of the
evaluation data, but differ from our official sub-
mission in only two ways: First, and most im-
portantly, the bug described previously was cor-
rected. Second, in some cases training runs that
had not completed at evaluation time were allowed
to run to the full 20 epochs, and the resulting mod-
els were used. The exceptions are Hindi and na-
tive Chinese, each of which reflect performance
at approximately 10 epochs. Without exception, a
beam of size 100 was used to generate these re-
sults.
With the exception of “EnCh standard,” all
results in the table employed the bidirectional
scheme described above. The Chinese non-
standard runs differ from standard only in that
models were trained to perform English-to-pinyin
transliteration, followed by a conversion from
pinyin to native Chinese using tables provided by
</bodyText>
<page confidence="0.997165">
134
</page>
<bodyText confidence="0.999933263157895">
the Unicode consortium. Non-standard Run 1 re-
tains pinyin tonal diacritics, while Run 2 omits
them. The mapping from pinyin to native Chi-
nese characters introduces indeterminacy, which
we accounted for in a simple fashion: First, in con-
structing a pinyin-to-Chinese conversion table, we
discarded any Chinese characters that were used
in the training data fewer than some small frac-
tion of cases. Then, given a ranked list of pinyin
transliterations, we generated all possible native
Chinese sequences, ranked by the product of ob-
served pinyin-to-Chinese probabilities, according
to training frequencies.
It will be observed that our non-standard
English-to-Chinese results lag considerably be-
hind the best results. We suspect this is due in
part to the fact that no additional training data was
used in these experiments–only a change in repre-
sentation.
</bodyText>
<sectionHeader confidence="0.998709" genericHeader="discussions">
4 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.999979333333333">
Treating the transliteration problem as one of or-
thographic transduction appears viable, particu-
larly for conversion between alphabetic languages.
An empirical character edit model based on a
structured perceptron and character n-gram fea-
tures, and using a simple training procedure that
discovers appropriate weights for latent character
alignment operations, yields performance that is
generally as good as alternative approaches ex-
plored in the shared task. The key is model com-
bination, particularly the combination of left-to-
right and right-to-left models, respectively.
In contrast to the alphabetic language pairs,
our performance on Chinese falls somewhat short.
Nevertheless, it is possible that simple modifica-
tions of the basic procedure would render it com-
petitive on English-Chinese, as well. In convert-
ing from English to native Chinese, we relied on
a mixed-order model, with order-3 English fea-
tures. It is possible that trigrams are too small
in some cases to identify the appropriate Chinese
character, and that 4-grams, if we can afford them,
will make the difference. There is virtue in the
idea of transliterating to pinyin as an intermediate
step; converting to tonal pinyin yields accuracy at
the same level as English-to-native-Chinese, even
with the indeterminacy it introduces. Future work
includes more principled approaches to resolving
this indeterminacy, and combined pinyin/native
models.
</bodyText>
<sectionHeader confidence="0.998088" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.501654625">
This material is based upon work supported by
the Defense Advanced Research Projects Agency
(DARPA) under Contract No. HR0011-06-C-
0023 (approved for public release, distribution un-
limited). Any opinions, findings and conclusions
or recommendations expressed in this material are
those of the authors and do not necessarily reflect
the view of DARPA.
</bodyText>
<sectionHeader confidence="0.960562" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999719942857143">
Y. Al-Onaizan and K. Knight. 2002. Machine translit-
eration of names in Arabic text. In Proceedings of
the ACL-02 workshop on computational approaches
to semitic languages.
K. Bellare, K. Crammer, and D. Freitag. 2009. Loss-
sensitive discriminative training of machine translit-
eration models. In Proceedings of the Student
Research Workshop and Doctoral Consortium at
NLT/NAACL 2009.
M. Collins. 2002. Discriminative training meth-
ods for hidden Markov models: theory and experi-
ments with perceptron algorithms. In Proceedings
ofEMNLP-2002.
D. Freitag and S. Khadivi. 2007. A sequence align-
ment model based on the averaged perceptron. In
Proceedings ofEMNLP-CoNLL 2007.
K. Knight and J. Graehl. 1998. Machine translitera-
tion. Computational Linguistics, 24(4).
A. Kumaran and T. Kellner. 2007. A generic frame-
work for machine transliteration. In Proceedings of
the 30th SIGIR.
C.-J. Lee and J.S. Chang. 2003. Acquisition
of English-Chinese transliterated word pairs from
parallel-aligned texts using a statistical machine
transliteration model. In Proceedings of the HLT-
NAACL 2003 Workshop on Building and Using Par-
allel Texts.
H. Li, M. Zhang, and J. Su. 2004. A joint source chan-
nel model for machine transliteration. In Proceed-
ings of the 42nd ACL.
H. Li, A. Kumaran, M. Zhang, and V. Pervouch-
ine. 2009. Whitepaper of NEWS 2009 Machine
Transliteration Shared Task. In Proceedings ofACL-
IJCNLP 2009 Named Entities Workshop (NEWS
2009).
</reference>
<page confidence="0.998773">
135
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.988387">
<title confidence="0.99975">Name Transliteration with Bidirectional Perceptron Edit Models</title>
<author confidence="0.999839">Dayne Freitag Zhiqiang Wang</author>
<affiliation confidence="0.999886">SRI International SRI International</affiliation>
<email confidence="0.997497">freitag@ai.sri.comjohnwang@ai.sri.com</email>
<abstract confidence="0.999569">We report on our efforts as part of the shared task on the NEWS 2009 Machine Transliteration Shared Task. We applied an orthographic perceptron character edit model that we have used previously for name transliteration, enhancing it in two ways: by ranking possible transliterations according to the sum of their scores according to two models, one trained to generate left-to-right, and one right-to-left; and by constraining generated strings to be consistent with character bigrams observed in the respective language’s training data. Our poor showing in the official evaluation was due to a bug in the script used to produce competitioncompliant output. Subsequent evaluation shows that our approach yielded comparatively strong performance on all alphabetic language pairs we attempted.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Al-Onaizan</author>
<author>K Knight</author>
</authors>
<title>Machine transliteration of names in Arabic text.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 workshop on computational</booktitle>
<contexts>
<context position="2057" citStr="Al-Onaizan and Knight (2002)" startWordPosition="299" endWordPosition="302"> problem. For this reason, many machine learning approaches to the problem have been proposed. We can draw a rough distinction between learning approaches that attempt to model the phonetics of a transliteration problem explicitly, and those that treat the problem as simply one of orthographic transduction, leaving it to the learning algorithm to acquire phonetic distinctions directly from orthographic features of the training data. For example, Knight and Graehl (1998) address the problem through cascaded finite state transducers, with explicit representations of the phonetics. Subsequently, Al-Onaizan and Knight (2002) realize improvements by adding a “spelling” (i.e., orthographic) model. There has been an increasing emphasis on purely orthographic models, probably because they require less detailed domain knowledge (e.g., (Lee and Chang, 2003)). 2 Approach The approach we explored as part of the NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009) is strictly orthographic. We view the conversion of a name in one language to its representation in another as the product of a series of single-character edits, and seek to learn a character edit model that maximizes the score of correct name pairs. </context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Y. Al-Onaizan and K. Knight. 2002. Machine transliteration of names in Arabic text. In Proceedings of the ACL-02 workshop on computational approaches to semitic languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Bellare</author>
<author>K Crammer</author>
<author>D Freitag</author>
</authors>
<title>Losssensitive discriminative training of machine transliteration models.</title>
<date>2009</date>
<booktitle>In Proceedings of the Student Research Workshop and Doctoral Consortium at NLT/NAACL</booktitle>
<contexts>
<context position="7536" citStr="Bellare et al., 2009" startWordPosition="1293" endWordPosition="1296">se extensions were used in our official submission for alphabetic language pairs. We treated English-toChinese somewhat differently, as described below. Simple character n-gram constraints. The described approach sometimes violates target language spelling conventions by interpolating clearly inappropriate characters into a string that is otherwise a reasonable transliteration. We take this behavior as symptomatic of a kind of undertraining in some portion of the problem space, a possible byproduct of 1-best perceptron training. One principled solution may be to optimize against n-best lists (Bellare et al., 2009). Instead, we address this shortcoming in a straightforward way—by prohibiting the creation of n-grams, for some small n, that do not occur 133 in the training data. Under a bigram restriction, if ‘ab’ is not seen in training, then an operation that inserts ‘b’ after ‘a’ is disallowed. In essence, we impose a very simple character language model of the target domain. Our non-standard English-to-Chinese contributions, which involved transliterating from English to pinyin, employed a similar idea. In these experiments, rather than character bigrams, the model was constrained to produce only lega</context>
</contexts>
<marker>Bellare, Crammer, Freitag, 2009</marker>
<rawString>K. Bellare, K. Crammer, and D. Freitag. 2009. Losssensitive discriminative training of machine transliteration models. In Proceedings of the Student Research Workshop and Doctoral Consortium at NLT/NAACL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for hidden Markov models: theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings ofEMNLP-2002.</booktitle>
<contexts>
<context position="4730" citStr="Collins (2002)" startWordPosition="788" endWordPosition="789">ms; for a model of order 2, features would be the bigrams and unigrams immediately adjacent to a given string position. Since the shared task is to generate target strings, only features for preceding n-grams are used in the target language. The score of a particular edit is a linear combination of the corresponding feature values: p p+q a(s,i,t,j) = E αk ·fk(s, i)+ E αk·fk(t, j) k=1 k=p+1 (2) The weights αk are what we seek to optimize in order to tune the model for our particular application. We optimize these weights through an extension of perceptron training for sequence labeling, due to Collins (2002). Take α to be a model parameterization, and let Aα(s, t) return an optimal edit sequence e, with its score v, given input sequences s and t under α. Elements of sequence e are character pairs (cs, ct), with cs E Σs U {E} and ct E Σt U {E}, where E represents the empty string. Let Φ(s, t, e) be a feature vector for a source string, target string, and corresponding edit sequence. Table 1 shows the training algorithm. Starting with a zero parameter vector, we iterate through the collection of source sequences. For each sequence, we pick two target sequences, one the “true” transliteration t of t</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for hidden Markov models: theory and experiments with perceptron algorithms. In Proceedings ofEMNLP-2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Freitag</author>
<author>S Khadivi</author>
</authors>
<title>A sequence alignment model based on the averaged perceptron.</title>
<date>2007</date>
<booktitle>In Proceedings ofEMNLP-CoNLL</booktitle>
<contexts>
<context position="2722" citStr="Freitag and Khadivi (2007)" startWordPosition="411" endWordPosition="414">ling” (i.e., orthographic) model. There has been an increasing emphasis on purely orthographic models, probably because they require less detailed domain knowledge (e.g., (Lee and Chang, 2003)). 2 Approach The approach we explored as part of the NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009) is strictly orthographic. We view the conversion of a name in one language to its representation in another as the product of a series of single-character edits, and seek to learn a character edit model that maximizes the score of correct name pairs. Our approach follows that described in Freitag and Khadivi (2007), a “structured perceptron” with cheaply computed character n-grams as features. Here, we give a brief description, and present the successful enhancements we tried specifically for the shared task. 2.1 Perceptron Edit Model Suppose we are given two sequences, sm1 ∈ E∗s and tn1 ∈ E∗t . We desire a function A(s, t) H N which assigns high scores to correct pairs s, t. If we stipulate that this score is the sum of the individual scores of a series of edits, we can find the highest-scoring such series through a generalization of the standard edit distance: A(si1,tj1) _ 1 aǫ,tj (s, i, t, j) + A(si1</context>
</contexts>
<marker>Freitag, Khadivi, 2007</marker>
<rawString>D. Freitag and S. Khadivi. 2007. A sequence alignment model based on the averaged perceptron. In Proceedings ofEMNLP-CoNLL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="1903" citStr="Knight and Graehl (1998)" startWordPosition="278" endWordPosition="281">y, and non-alphabetic orthographies (e.g., syllabaries). For most language pairs, these difficulties stand in the way of a rule-based treatment of the problem. For this reason, many machine learning approaches to the problem have been proposed. We can draw a rough distinction between learning approaches that attempt to model the phonetics of a transliteration problem explicitly, and those that treat the problem as simply one of orthographic transduction, leaving it to the learning algorithm to acquire phonetic distinctions directly from orthographic features of the training data. For example, Knight and Graehl (1998) address the problem through cascaded finite state transducers, with explicit representations of the phonetics. Subsequently, Al-Onaizan and Knight (2002) realize improvements by adding a “spelling” (i.e., orthographic) model. There has been an increasing emphasis on purely orthographic models, probably because they require less detailed domain knowledge (e.g., (Lee and Chang, 2003)). 2 Approach The approach we explored as part of the NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009) is strictly orthographic. We view the conversion of a name in one language to its representation </context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>K. Knight and J. Graehl. 1998. Machine transliteration. Computational Linguistics, 24(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kumaran</author>
<author>T Kellner</author>
</authors>
<title>A generic framework for machine transliteration.</title>
<date>2007</date>
<booktitle>In Proceedings of the 30th SIGIR.</booktitle>
<contexts>
<context position="9367" citStr="Kumaran and Kellner, 2007" startWordPosition="1578" endWordPosition="1581">d sum of scores according to the constituent models, and reranked according to this score. The 10 highestscoring were retained for evaluation. A buggy implementation of this two-model idea accounts for our poor showing in the official evaluation. Because of a trivial error in the script we used to produce output, right-to-left models were treated as if they were left-to-right. The resulting strings and scores were consequently erroneous. 3 Evaluation We experimented with models of order 2 and 3 (2-gram and 3-gram features) on shared task data for English to Hindi, Kannada, Russian, and Tamil (Kumaran and Kellner, 2007). Based on development accuracy scores, we found models of order 3 to be consistently better than order 2, and our submitted results use only order-3 models, with one exception. English-to-native-Chinese (Li et al., 2004) was treated as a special case. Using trigram features in the target language results in an explosion in the feature space, and a model that is slow to train and performs poorly. Thus, only for this language pair, we devised a mixed-order model, one using trigram features over English strings, and unigram features over Chinese. Because of the large target-language branching fa</context>
</contexts>
<marker>Kumaran, Kellner, 2007</marker>
<rawString>A. Kumaran and T. Kellner. 2007. A generic framework for machine transliteration. In Proceedings of the 30th SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-J Lee</author>
<author>J S Chang</author>
</authors>
<title>Acquisition of English-Chinese transliterated word pairs from parallel-aligned texts using a statistical machine transliteration model.</title>
<date>2003</date>
<booktitle>In Proceedings of the HLTNAACL 2003 Workshop on Building and Using Parallel Texts.</booktitle>
<contexts>
<context position="2288" citStr="Lee and Chang, 2003" startWordPosition="334" endWordPosition="337">se that treat the problem as simply one of orthographic transduction, leaving it to the learning algorithm to acquire phonetic distinctions directly from orthographic features of the training data. For example, Knight and Graehl (1998) address the problem through cascaded finite state transducers, with explicit representations of the phonetics. Subsequently, Al-Onaizan and Knight (2002) realize improvements by adding a “spelling” (i.e., orthographic) model. There has been an increasing emphasis on purely orthographic models, probably because they require less detailed domain knowledge (e.g., (Lee and Chang, 2003)). 2 Approach The approach we explored as part of the NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009) is strictly orthographic. We view the conversion of a name in one language to its representation in another as the product of a series of single-character edits, and seek to learn a character edit model that maximizes the score of correct name pairs. Our approach follows that described in Freitag and Khadivi (2007), a “structured perceptron” with cheaply computed character n-grams as features. Here, we give a brief description, and present the successful enhancements we tried s</context>
</contexts>
<marker>Lee, Chang, 2003</marker>
<rawString>C.-J. Lee and J.S. Chang. 2003. Acquisition of English-Chinese transliterated word pairs from parallel-aligned texts using a statistical machine transliteration model. In Proceedings of the HLTNAACL 2003 Workshop on Building and Using Parallel Texts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Li</author>
<author>M Zhang</author>
<author>J Su</author>
</authors>
<title>A joint source channel model for machine transliteration.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd ACL.</booktitle>
<contexts>
<context position="9588" citStr="Li et al., 2004" startWordPosition="1612" endWordPosition="1615">ial evaluation. Because of a trivial error in the script we used to produce output, right-to-left models were treated as if they were left-to-right. The resulting strings and scores were consequently erroneous. 3 Evaluation We experimented with models of order 2 and 3 (2-gram and 3-gram features) on shared task data for English to Hindi, Kannada, Russian, and Tamil (Kumaran and Kellner, 2007). Based on development accuracy scores, we found models of order 3 to be consistently better than order 2, and our submitted results use only order-3 models, with one exception. English-to-native-Chinese (Li et al., 2004) was treated as a special case. Using trigram features in the target language results in an explosion in the feature space, and a model that is slow to train and performs poorly. Thus, only for this language pair, we devised a mixed-order model, one using trigram features over English strings, and unigram features over Chinese. Because of the large target-language branching factor, the mixed-order native Chinese model remainLanguages Accuracy Delta EnHi 0.465 -0.033 EnHi baseline 0.421 -0.077 EnKa 0.396 -0.002 EnKa baseline 0.370 -0.028 EnRu 0.609 -0.004 EnRu baseline 0.588 -0.025 EnTa 0.475 +</context>
</contexts>
<marker>Li, Zhang, Su, 2004</marker>
<rawString>H. Li, M. Zhang, and J. Su. 2004. A joint source channel model for machine transliteration. In Proceedings of the 42nd ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Li</author>
<author>A Kumaran</author>
<author>M Zhang</author>
<author>V Pervouchine</author>
</authors>
<date>2009</date>
<booktitle>Whitepaper of NEWS 2009 Machine Transliteration Shared Task. In Proceedings ofACLIJCNLP 2009 Named Entities Workshop (NEWS</booktitle>
<contexts>
<context position="2405" citStr="Li et al., 2009" startWordPosition="354" endWordPosition="357">netic distinctions directly from orthographic features of the training data. For example, Knight and Graehl (1998) address the problem through cascaded finite state transducers, with explicit representations of the phonetics. Subsequently, Al-Onaizan and Knight (2002) realize improvements by adding a “spelling” (i.e., orthographic) model. There has been an increasing emphasis on purely orthographic models, probably because they require less detailed domain knowledge (e.g., (Lee and Chang, 2003)). 2 Approach The approach we explored as part of the NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009) is strictly orthographic. We view the conversion of a name in one language to its representation in another as the product of a series of single-character edits, and seek to learn a character edit model that maximizes the score of correct name pairs. Our approach follows that described in Freitag and Khadivi (2007), a “structured perceptron” with cheaply computed character n-grams as features. Here, we give a brief description, and present the successful enhancements we tried specifically for the shared task. 2.1 Perceptron Edit Model Suppose we are given two sequences, sm1 ∈ E∗s and tn1 ∈ E∗</context>
</contexts>
<marker>Li, Kumaran, Zhang, Pervouchine, 2009</marker>
<rawString>H. Li, A. Kumaran, M. Zhang, and V. Pervouchine. 2009. Whitepaper of NEWS 2009 Machine Transliteration Shared Task. In Proceedings ofACLIJCNLP 2009 Named Entities Workshop (NEWS 2009).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>