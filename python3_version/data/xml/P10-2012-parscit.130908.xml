<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003240">
<title confidence="0.993505">
Cognitively Plausible Models of Human Language Processing
</title>
<author confidence="0.998381">
Frank Keller
</author>
<affiliation confidence="0.999924">
School of Informatics, University of Edinburgh
</affiliation>
<address confidence="0.98521">
10 Crichton Street, Edinburgh EH8 9AB, UK
</address>
<email confidence="0.995347">
keller@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.993793" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999850333333333">
We pose the development of cognitively
plausible models of human language pro-
cessing as a challenge for computational
linguistics. Existing models can only deal
with isolated phenomena (e.g., garden
paths) on small, specifically selected data
sets. The challenge is to build models that
integrate multiple aspects of human lan-
guage processing at the syntactic, seman-
tic, and discourse level. Like human lan-
guage processing, these models should be
incremental, predictive, broad coverage,
and robust to noise. This challenge can
only be met if standardized data sets and
evaluation measures are developed.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999941521739131">
In many respects, human language processing is
the ultimate goldstandard for computational lin-
guistics. Humans understand and generate lan-
guage with amazing speed and accuracy, they are
able to deal with ambiguity and noise effortlessly
and can adapt to new speakers, domains, and reg-
isters. Most surprisingly, they achieve this compe-
tency on the basis of limited training data (Hart
and Risley, 1995), using learning algorithms that
are largely unsupervised.
Given the impressive performance of humans
as language processors, it seems natural to turn
to psycholinguistics, the discipline that studies hu-
man language processing, as a source of informa-
tion about the design of efficient language pro-
cessing systems. Indeed, psycholinguists have un-
covered an impressive array of relevant facts (re-
viewed in Section 2), but computational linguists
are often not aware of this literature, and results
about human language processing rarely inform
the design, implementation, or evaluation of artifi-
cial language processing systems.
At the same time, research in psycholinguis-
tics is often oblivious of work in computational
linguistics (CL). To test their theories, psycholin-
guists construct computational models of hu-
man language processing, but these models of-
ten fall short of the engineering standards that
are generally accepted in the CL community
(e.g., broad coverage, robustness, efficiency): typ-
ical psycholinguistic models only deal with iso-
lated phenomena and fail to scale to realistic data
sets. A particular issue is evaluation, which is typ-
ically anecdotal, performed on a small set of hand-
crafted examples (see Sections 3).
In this paper, we propose a challenge that re-
quires the combination of research efforts in com-
putational linguistics and psycholinguistics: the
development of cognitively plausible models of
human language processing. This task can be de-
composed into a modeling challenge (building
models that instantiate known properties of hu-
man language processing) and a data and evalu-
ation challenge (accounting for experimental find-
ings and evaluating against standardized data sets),
which we will discuss in turn.
</bodyText>
<sectionHeader confidence="0.945946" genericHeader="method">
2 Modeling Challenge
</sectionHeader>
<subsectionHeader confidence="0.864445">
2.1 Key Properties
</subsectionHeader>
<bodyText confidence="0.8781665">
The first part of the challenge is to develop a model
that instantiates key properties of human language
processing, as established by psycholinguistic ex-
perimentation (see Table 1 for an overview and
representative references).1 A striking property of
the human language processor is its efficiency and
robustness. For the vast majority of sentences, it
will effortlessly and rapidly deliver the correct
analysis, even in the face of noise and ungrammat-
icalities. There is considerable experimental evi-
1Here an in the following, we will focus on sentence
processing, which is often regarded as a central aspect of
human language processing. A more comprehensive answer
to our modeling challenge should also include phonological
and morphological processing, semantic inference, discourse
processing, and other non-syntactic aspects of language pro-
cessing. Furthermore, established results regarding the inter-
face between language processing and non-linguistic cogni-
tion (e.g., the sensorimotor system) should ultimately be ac-
counted for in a fully comprehensive model.
</bodyText>
<page confidence="0.980177">
60
</page>
<note confidence="0.755537">
Proceedings of the ACL 2010 Conference Short Papers, pages 60–67,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<table confidence="0.995679571428571">
Property Evidence Rank Model Stack
Surp Pred
Efficiency and robustness Ferreira et al. (2001); Sanford and Sturt (2002) − − − +
Broad coverage Crocker and Brants (2000) + + − +
Incrementality and connectedness Tanenhaus et al. (1995); Sturt and Lombardo (2005) + + + +
Prediction Kamide et al. (2003); Staub and Clifton (2006) − f + −
Memory cost Gibson (1998); Vasishth and Lewis (2006) − − + +
</table>
<tableCaption confidence="0.9967555">
Table 1: Key properties of human language processing and their instantiation in various models of sentence processing (see
Section 2 for details)
</tableCaption>
<bodyText confidence="0.999966676470588">
dence that shallow processing strategies are used
to achieve this. The processor also achieves broad
coverage: it can deal with a wide variety of syntac-
tic constructions, and is not restricted by the do-
main, register, or modality of the input.
Human language processing is also word-by-
word incremental. There is strong evidence that
a new word is integrated as soon as it is avail-
able into the representation of the sentence thus
far. Readers and listeners experience differential
processing difficulty during this integration pro-
cess, depending on the properties of the new word
and its relationship to the preceding context. There
is evidence that the processor instantiates a strict
form of incrementality by building only fully con-
nected trees. Furthermore, the processor is able
to make predictions about upcoming material on
the basis of sentence prefixes. For instance, listen-
ers can predict an upcoming post-verbal element
based on the semantics of the preceding verb. Or
they can make syntactic predictions, e.g., if they
encounter the word either, they predict an upcom-
ing or and the type of complement that follows it.
Another key property of human language pro-
cessing is the fact that it operates with limited
memory, and that structures in memory are subject
to decay and interference. In particular, the pro-
cessor is known to incur a distance-based memory
cost: combining the head of a phrase with its syn-
tactic dependents is more difficult the more depen-
dents have to be integrated and the further away
they are. This integration process is also subject
to interference from similar items that have to be
held in memory at the same time.
</bodyText>
<subsectionHeader confidence="0.998203">
2.2 Current Models
</subsectionHeader>
<bodyText confidence="0.998715137254902">
The challenge is to develop a computational model
that captures the key properties of human language
processing outlined in the previous section. A
number of relevant models have been developed,
mostly based on probabilistic parsing techniques,
but none of them instantiates all the key proper-
ties discussed above (Table 1 gives an overview of
model properties).2
The earliest approaches were ranking-based
models (Rank), which make psycholinguistic pre-
dictions based on the ranking of the syntactic
analyses produced by a probabilistic parser. Ju-
rafsky (1996) assumes that processing difficulty
is triggered if the correct analysis falls below a
certain probability threshold (i.e., is pruned by
the parser). Similarly, Crocker and Brants (2000)
assume that processing difficulty ensures if the
highest-ranked analysis changes from one word to
the next. Both approaches have been shown to suc-
cessfully model garden path effects. Being based
on probabilistic parsing techniques, ranking-based
models generally achieve a broad coverage, but
their efficiency and robustness has not been evalu-
ated. Also, they are not designed to capture syntac-
tic prediction or memory effects (other than search
with a narrow beam in Brants and Crocker 2000).
The ranking-based approach has been gener-
alized by surprisal models (Surp), which pre-
dict processing difficulty based on the change in
the probability distribution over possible analy-
ses from one word to the next (Hale, 2001; Levy,
2008; Demberg and Keller, 2008a; Ferrara Boston
et al., 2008; Roark et al., 2009). These models
have been successful in accounting for a range of
experimental data, and they achieve broad cover-
age. They also instantiate a limited form of predic-
tion, viz., they build up expectations about the next
word in the input. On the other hand, the efficiency
and robustness of these models has largely not
been evaluated, and memory costs are not mod-
eled (again except for restrictions in beam size).
The prediction model (Pred) explicitly predicts
syntactic structure for upcoming words (Demberg
and Keller, 2008b, 2009), thus accounting for ex-
perimental results on predictive language process-
ing. It also implements a strict form of incre-
2We will not distinguish between model and linking the-
ory, i.e., the set of assumptions that links model quantities
to behavioral data (e.g., more probably structures are easier
to process). It is conceivable, for instance, that a stack-based
model is combined with a linking theory based on surprisal.
</bodyText>
<page confidence="0.997531">
61
</page>
<table confidence="0.9169762">
Factor Evidence
Word senses Roland and Jurafsky (2002)
Selectional re- Garnsey et al. (1997); Pickering and
strictions Traxler(1998)
Thematic roles McRae et al. (1998); Pickering et al.
(2000)
Discourse ref- Altmann and Steedman (1988); Grod-
erence ner and Gibson (2005)
Discourse Stewart et al. (2000); Kehler et al.
coherence (2008)
</table>
<tableCaption confidence="0.99888">
Table 2: Semantic factors in human language processing
</tableCaption>
<bodyText confidence="0.999932">
mentality by building fully connected trees. Mem-
ory costs are modeled directly as a distance-based
penalty that is incurred when a prediction has to be
verified later in the sentence. However, the current
implementation of the prediction model is neither
robust and efficient nor offers broad coverage.
Recently, a stack-based model (Stack) has been
proposed that imposes explicit, cognitively mo-
tivated memory constraints on the parser, in ef-
fect limiting the stack size available to the parser
(Schuler et al., 2010). This delivers robustness, ef-
ficiency, and broad coverage, but does not model
syntactic prediction. Unlike the other models dis-
cussed here, no psycholinguistic evaluation has
been conducted on the stack-based model, so its
cognitive plausibility is preliminary.
</bodyText>
<subsectionHeader confidence="0.999129">
2.3 Beyond Parsing
</subsectionHeader>
<bodyText confidence="0.999994733333334">
There is strong evidence that human language pro-
cessing is driven by an interaction of syntactic, se-
mantic, and discourse processes (see Table 2 for
an overview and references). Considerable exper-
imental work has focused on the semantic prop-
erties of the verb of the sentence, and verb sense,
selectional restrictions, and thematic roles have all
been shown to interact with syntactic ambiguity
resolution. Another large body of research has elu-
cidated the interaction of discourse processing and
syntactic processing. The most-well known effect
is probably that of referential context: syntactic
ambiguities can be resolved if a discourse con-
text is provided that makes one of the syntactic
alternatives more plausible. For instance, in a con-
text that provides two possible antecedents for a
noun phrase, the processor will prefer attaching a
PP or a relative clause such that it disambiguates
between the two antecedents; garden paths are re-
duced or disappear. Other results point to the im-
portance of discourse coherence for sentence pro-
cessing, an example being implicit causality.
The challenge facing researchers in compu-
tational and psycholinguistics therefore includes
the development of language processing models
that combine syntactic processing with semantic
and discourse processing. So far, this challenge is
largely unmet: there are some examples of models
that integrate semantic processes such as thematic
role assignment into a parsing model (Narayanan
and Jurafsky, 2002; Pad´o et al., 2009). However,
other semantic factors are not accounted for by
these models, and incorporating non-lexical as-
pects of semantics into models of sentence pro-
cessing is a challenge for ongoing research. Re-
cently, Dubey (2010) has proposed an approach
that combines a probabilistic parser with a model
of co-reference and discourse inference based on
probabilistic logic. An alternative approach has
been taken by Pynte et al. (2008) and Mitchell
et al. (2010), who combine a vector-space model
of semantics (Landauer and Dumais, 1997) with a
syntactic parser and show that this results in pre-
dictions of processing difficulty that can be vali-
dated against an eye-tracking corpus.
</bodyText>
<subsectionHeader confidence="0.998324">
2.4 Acquisition and Crosslinguistics
</subsectionHeader>
<bodyText confidence="0.999945214285714">
All models of human language processing dis-
cussed so far rely on supervised training data. This
raises another aspect of the modeling challenge:
the human language processor is the product of
an acquisition process that is largely unsupervised
and has access to only limited training data: chil-
dren aged 12–36 months are exposed to between
10 and 35 million words of input (Hart and Ris-
ley, 1995). The challenge therefore is to develop
a model of language acquisition that works with
such small training sets, while also giving rise to
a language processor that meets the key criteria
in Table 1. The CL community is in a good posi-
tion to rise to this challenge, given the significant
progress in unsupervised parsing in recent years
(starting from Klein and Manning 2002). How-
ever, none of the existing unsupervised models has
been evaluated against psycholinguistic data sets,
and they are not designed to meet even basic psy-
cholinguistic criteria such as incrementality.
A related modeling challenge is the develop-
ment of processing models for languages other
than English. There is a growing body of ex-
perimental research investigating human language
processing in other languages, but virtually all ex-
isting psycholinguistic models only work for En-
glish (the only exceptions we are aware of are
Dubey et al.’s (2008) and Ferrara Boston et al.’s
</bodyText>
<page confidence="0.996313">
62
</page>
<bodyText confidence="0.999547">
(2008) parsing models for German). Again, the
CL community has made significant progress in
crosslinguistic parsing, especially using depen-
dency grammar (Hajiˇc, 2009), and psycholinguis-
tic modeling could benefit from this in order to
meet the challenge of developing crosslinguisti-
cally valid models of human language processing.
</bodyText>
<sectionHeader confidence="0.985994" genericHeader="method">
3 Data and Evaluation Challenge
</sectionHeader>
<subsectionHeader confidence="0.99976">
3.1 Test Sets
</subsectionHeader>
<bodyText confidence="0.999863444444445">
The second key challenge that needs to be ad-
dressed in order to develop cognitively plausible
models of human language processing concerns
test data and model evaluation. Here, the state of
the art in psycholinguistic modeling lags signif-
icantly behind standards in the CL community.
Most of the models discussed in Section 2 have not
been evaluated rigorously. The authors typically
describe their performance on a small set of hand-
picked examples; no attempts are made to test on
a range of items from the experimental literature
and determine model fit directly against behavioral
measures (e.g., reading times). This makes it very
hard to obtain a realistic estimate of how well the
models achieve their aim of capturing human lan-
guage processing behavior.
We therefore suggest the development of stan-
dard test sets for psycholinguistic modeling, simi-
lar to what is commonplace for tasks in computa-
tional linguistics: parsers are evaluated against the
Penn Treebank, word sense disambiguation sys-
tems against the SemEval data sets, co-reference
systems against the Tipster or ACE corpora, etc.
Two types of test data are required for psycholin-
guistic modeling. The first type of test data con-
sists of a collection of representative experimental
results. This collection should contain the actual
experimental materials (sentences or discourse
fragments) used in the experiments, together with
the behavioral measurements obtained (reading
times, eye-movement records, rating judgments,
etc.). The experiments included in this test set
would be chosen to cover a wide range of ex-
perimental phenomena, e.g., garden paths, syntac-
tic complexity, memory effects, semantic and dis-
course factors. Such a test set will enable the stan-
dardized evaluation of psycholinguistic models by
comparing the model predictions (rankings, sur-
prisal values, memory costs, etc.) against behav-
ioral measures on a large set of items. This way
both the coverage of a model (how many phenom-
ena can it account for) and its accuracy (how well
does it fit the behavioral data) can be assessed.
Experimental test sets should be complemented
by test sets based on corpus data. In order to as-
sess the efficiency, robustness, and broad cover-
age of a model, a corpus of unrestricted, naturally
occurring text is required. The use of contextual-
ized language data makes it possible to assess not
only syntactic models, but also models that capture
discourse effects. These corpora need to be anno-
tated with behavioral measures, e.g., eye-tracking
or reading time data. Some relevant corpora have
already been constructed, see the overview in Ta-
ble 3, and various authors have used them for
model evaluation (Demberg and Keller, 2008a;
Pynte et al., 2008; Frank, 2009; Ferrara Boston
et al., 2008; Patil et al., 2009; Roark et al., 2009;
Mitchell et al., 2010).
However, the usefulness of the psycholinguis-
tic corpora in Table 3 is restricted by the absence
of gold-standard linguistic annotation (though the
French part of the Dundee corpus, which is syn-
tactically annotated). This makes it difficult to test
the accuracy of the linguistic structures computed
by a model, and restricts evaluation to behavioral
predictions. The challenge is therefore to collect
a standardized test set of naturally occurring text
or speech enriched not only with behavioral vari-
ables, but also with syntactic and semantic anno-
tation. Such a data set could for example be con-
structed by eye-tracking section 23 of the Penn
Treebank (which is also part of Propbank, and thus
has both syntactic and thematic role annotation).
In computational linguistics, the development
of new data sets is often stimulated by competi-
tions in which systems are compared on a stan-
dardized task, using a data set specifically de-
signed for the competition. Examples include the
CoNLL shared task, SemEval, or TREC in com-
putational syntax, semantics, and discourse, re-
spectively. A similar competition could be devel-
oped for computational psycholinguistics – maybe
along the lines of the model comparison chal-
lenges that held at the International Conference
on Cognitive Modeling. These challenges provide
standardized task descriptions and data sets; par-
ticipants can enter their cognitive models, which
were then compared using a pre-defined evalua-
tion metric.3
</bodyText>
<footnote confidence="0.995052">
3The ICCM 2009 challenge was the Dynamic Stock and
Flows Task, for more information see http://www.hss.
cmu.edu/departments/sds/ddmlab/modeldsf/.
</footnote>
<page confidence="0.998237">
63
</page>
<table confidence="0.9863675">
Corpus Language Words Participants Method Reference
Dundee Corpus English, French 50,000 10 Eye-tracking Kennedy and Pynte (2005)
Potsdam Corpus German 1,138 222 Eye-tracking Kliegl et al. (2006)
MIT Corpus English 3,534 23 Self-paced reading Bachrach (2008)
</table>
<tableCaption confidence="0.9981715">
Table 3: Test corpora that have been used for psycholinguistic modeling of sentence processing; note that the Potsdam Corpus
consists of isolated sentences, rather than of continuous text
</tableCaption>
<subsectionHeader confidence="0.997417">
3.2 Behavioral and Neural Data
</subsectionHeader>
<bodyText confidence="0.999990222222222">
As outlined in the previous section, a number of
authors have evaluated psycholinguistic models
against eye-tracking or reading time corpora. Part
of the data and evaluation challenge is to extend
this evaluation to neural data as provided by event-
related potential (ERP) or brain imaging studies
(e.g., using functional magnetic resonance imag-
ing, fMRI). Neural data sets are considerably more
complex than behavioral ones, and modeling them
is an important new task that the community is
only beginning to address. Some recent work has
evaluated models of word semantics against ERP
(Murphy et al., 2009) or fMRI data (Mitchell et al.,
2008).4 This is a very promising direction, and the
challenge is to extend this approach to the sentence
and discourse level (see Bachrach 2008). Again,
it will again be necessary to develop standardized
test sets of both experimental data and corpus data.
</bodyText>
<subsectionHeader confidence="0.994794">
3.3 Evaluation Measures
</subsectionHeader>
<bodyText confidence="0.999933954545455">
We also anticipate that the availability of new test
data sets will facilitate the development of new
evaluation measures that specifically test the va-
lidity of psycholinguistic models. Established CL
evaluation measures such as Parseval are of lim-
ited use, as they can only test the linguistic, but not
the behavioral or neural predictions of a model.
So far, many authors have relied on qualita-
tive evaluation: if a model predicts a difference
in (for instance) reading time between two types
of sentences where such a difference was also
found experimentally, then that counts as a suc-
cessful test. In most cases, no quantitative evalu-
ation is performed, as this would require model-
ing the reading times for individual item and in-
dividual participants. Suitable procedures for per-
forming such tests do not currently exist; linear
mixed effects models (Baayen et al., 2008) pro-
vide a way of dealing with item and participant
variation, but crucially do not enable direct com-
parisons between models in terms of goodness of
fit.
</bodyText>
<footnote confidence="0.9863265">
4These data sets were released as part of the NAACL-
2010 Workshop on Computational Neurolinguistics.
</footnote>
<bodyText confidence="0.999801444444444">
Further issues arise from the fact that we of-
ten want to compare model fit for multiple experi-
ments (ideally without reparametrizing the mod-
els), and that various mutually dependent mea-
sures are used for evaluation, e.g., processing ef-
fort at the sentence, word, and character level. An
important open challenge is there to develop eval-
uation measures and associated statistical proce-
dures that can deal with these problems.
</bodyText>
<sectionHeader confidence="0.998649" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999914411764706">
In this paper, we discussed the modeling and
data/evaluation challenges involved in developing
cognitively plausible models of human language
processing. Developing computational models is
of scientific importance in so far as models are im-
plemented theories: models of language process-
ing allow us to test scientific hypothesis about the
cognitive processes that underpin language pro-
cessing. This type of precise, formalized hypoth-
esis testing is only possible if standardized data
sets and uniform evaluation procedures are avail-
able, as outlined in the present paper. Ultimately,
this approach enables qualitative and quantitative
comparisons between theories, and thus enhances
our understanding of a key aspect of human cog-
nition, language processing.
There is also an applied side to the proposed
challenge. Once computational models of human
language processing are available, they can be
used to predict the difficulty that humans experi-
ence when processing text or speech. This is use-
ful for a number applications: for instance, nat-
ural language generation would benefit from be-
ing able to assess whether machine-generated text
or speech is easy to process. For text simplifica-
tion (e.g., for children or impaired readers), such a
model is even more essential. It could also be used
to assess the readability of text, which is of interest
in educational applications (e.g., essay scoring). In
machine translation, evaluating the fluency of sys-
tem output is crucial, and a model that predicts
processing difficulty could be used for this, or to
guide the choice between alternative translations,
and maybe even to inform human post-editing.
</bodyText>
<page confidence="0.999306">
64
</page>
<sectionHeader confidence="0.908569" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.926468">
Altmann, Gerry T. M. and Mark J. Steedman.
1988. Interaction with context during human
sentence processing. Cognition 30(3):191–238.
Baayen, R. H., D. J. Davidson, and D. M. Bates.
2008. Mixed-effects modeling with crossed ran-
dom effects for subjects and items. Journal of
Memory and Language to appear.
Bachrach, Asaf. 2008. Imaging Neural Correlates
of Syntactic Complexity in a Naturalistic Con-
text. Ph.D. thesis, Massachusetts Institute of
Technology, Cambridge, MA.
Brants, Thorsten and Matthew W. Crocker. 2000.
Probabilistic parsing and psychological plau-
sibility. In Proceedings of the 18th Interna-
tional Conference on Computational Linguis-
tics. Saarbr¨ucken/Luxembourg/Nancy, pages
111–117.
Crocker, Matthew W. and Thorsten Brants. 2000.
Wide-coverage probabilistic sentence process-
ing. Journal of Psycholinguistic Research
29(6):647–669.
Demberg, Vera and Frank Keller. 2008a. Data
from eye-tracking corpora as evidence for theo-
ries of syntactic processing complexity. Cogni-
tion 101(2):193–210.
Demberg, Vera and Frank Keller. 2008b. A psy-
cholinguistically motivated version of TAG. In
Proceedings of the 9th International Workshop
on Tree Adjoining Grammars and Related For-
malisms. T¨ubingen, pages 25–32.
Demberg, Vera and Frank Keller. 2009. A com-
putational model of prediction in human pars-
ing: Unifying locality and surprisal effects. In
Niels Taatgen and Hedderik van Rijn, editors,
Proceedings of the 31st Annual Conference of
the Cognitive Science Society. Cognitive Sci-
ence Society, Amsterdam, pages 1888–1893.
Dubey, Amit. 2010. The influence of discourse on
syntax: A psycholinguistic model of sentence
processing. In Proceedings of the 48th Annual
Meeting of the Association for Computational
Linguistics. Uppsala.
</bodyText>
<reference confidence="0.897796944444445">
Dubey, Amit, Frank Keller, and Patrick Sturt.
2008. A probabilistic corpus-based model of
syntactic parallelism. Cognition 109(3):326–
344.
Ferrara Boston, Marisa, John Hale, Reinhold
Kliegl, Umesh Patil, and Shravan Vasishth.
2008. Parsing costs as predictors of reading dif-
ficulty: An evaluation using the Potsdam Sen-
tence Corpus. Journal of Eye Movement Re-
search 2(1):1–12.
Ferreira, Fernanda, Kiel Christianson, and An-
drew Hollingworth. 2001. Misinterpretations of
garden-path sentences: Implications for models
of sentence processing and reanalysis. Journal
of Psycholinguistic Research 30(1):3–20.
Frank, Stefan L. 2009. Surprisal-based compar-
ison between a symbolic and a connectionist
model of sentence processing. In Niels Taat-
gen and Hedderik van Rijn, editors, Proceed-
ings of the 31st Annual Conference of the Cog-
nitive Science Society. Cognitive Science Soci-
ety, Amsterdam, pages 1139–1144.
Garnsey, Susan M., Neal J. Pearlmutter, Elisa-
beth M. Myers, and Melanie A. Lotocky. 1997.
The contributions of verb bias and plausibility
to the comprehension of temporarily ambiguous
sentences. Journal of Memory and Language
37(1):58–93.
Gibson, Edward. 1998. Linguistic complexity:
locality of syntactic dependencies. Cognition
68:1–76.
Grodner, Dan and Edward Gibson. 2005. Conse-
quences of the serial nature of linguistic input.
Cognitive Science 29:261–291.
Hajiˇc, Jan, editor. 2009. Proceedings of the 13th
Conference on Computational Natural Lan-
guage Learning: Shared Task. Association for
Computational Linguistics, Boulder, CO.
Hale, John. 2001. A probabilistic Earley parser as
a psycholinguistic model. In Proceedings of the
2nd Conference of the North American Chapter
of the Association for Computational Linguis-
tics. Association for Computational Linguistics,
Pittsburgh, PA, volume 2, pages 159–166.
Hart, Betty and Todd R. Risley. 1995. Meaning-
ful Differences in the Everyday Experience of
Young American Children. Paul H. Brookes,
Baltimore, MD.
Jurafsky, Daniel. 1996. A probabilistic model of
lexical and syntactic access and disambigua-
tion. Cognitive Science 20(2):137–194.
Kamide, Yuki, Gerry T. M. Altmann, and Sarah L.
Haywood. 2003. The time-course of prediction
in incremental sentence processing: Evidence
</reference>
<page confidence="0.998757">
65
</page>
<reference confidence="0.854663">
from anticipatory eye movements. Journal of
Memory and Language 49:133–156.
Kehler, Andrew, Laura Kertz, Hannah Rohde, and
Jeffrey L. Elman. 2008. Coherence and coref-
erence revisited. Journal of Semantics 25(1):1–
44.
Kennedy, Alan and Joel Pynte. 2005. Parafoveal-
on-foveal effects in normal reading. Vision Re-
search 45:153–168.
Klein, Dan and Christopher Manning. 2002. A
generative constituent-context model for im-
proved grammar induction. In Proceedings of
the 40th Annual Meeting of the Association for
Computational Linguistics. Philadelphia, pages
128–135.
Kliegl, Reinhold, Antje Nuthmann, and Ralf Eng-
bert. 2006. Tracking the mind during reading:
The influence of past, present, and future words
on fixation durations. Journal of Experimental
Psychology: General 135(1):12–35.
Landauer, Thomas K. and Susan T. Dumais. 1997.
A solution to Plato’s problem: The latent se-
mantic analysis theory of acquisition, induction
and representation of knowledge. Psychologi-
cal Review 104(2):211–240.
Levy, Roger. 2008. Expectation-based syntactic
comprehension. Cognition 106(3):1126–1177.
McRae, Ken, Michael J. Spivey-Knowlton, and
Michael K. Tanenhaus. 1998. Modeling the in-
fluence of thematic fit (and other constraints)
in on-line sentence comprehension. Journal of
Memory and Language 38(3):283–312.
Mitchell, Jeff, Mirella Lapata, Vera Demberg, and
Frank Keller. 2010. Syntactic and semantic fac-
tors in processing difficulty: An integrated mea-
sure. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Lin-
guistics. Uppsala.
Mitchell, Tom M., Svetlana V. Shinkareva, An-
drew Carlson, Kai-Min Chang, Vicente L.
Malave, Robert A. Mason, and Marcel Adam
Just3.2008. Predicting human brain activity as-
sociated with the meanings of nouns. Science
320(5880):1191–1195.
Murphy, Brian, Marco Baroni, and Massimo Poe-
sio. 2009. EEG responds to conceptual stimuli
and corpus semantics. In Proceedings of the
Conference on Empirical Methods in Natural
Language Processing. Singapore, pages 619–
627.
Narayanan, Srini and Daniel Jurafsky. 2002. A
Bayesian model predicts human parse prefer-
ence and reading time in sentence processing. In
Thomas G. Dietterich, Sue Becker, and Zoubin
Ghahramani, editors, Advances in Neural In-
formation Processing Systems 14. MIT Press,
Cambridge, MA, pages 59–65.
Pad´o, Ulrike, Matthew W. Crocker, and Frank
Keller. 2009. A probabilistic model of semantic
plausibility in sentence processing. Cognitive
Science 33(5):794–838.
Patil, Umesh, Shravan Vasishth, and Reinhold
Kliegl. 2009. Compound effect of probabilis-
tic disambiguation and memory retrievals on
sentence processing: Evidence from an eye-
tracking corpus. In A. Howes, D. Peebles,
and R. Cooper, editors, Proceedings of 9th In-
ternational Conference on Cognitive Modeling.
Manchester.
Pickering, Martin J. and Martin J. Traxler. 1998.
Plausibility and recovery from garden paths: An
eye-tracking study. Journal of Experimental
Psychology: Learning Memory and Cognition
24(4):940–961.
Pickering, Martin J., Matthew J. Traxler, and
Matthew W. Crocker. 2000. Ambiguity reso-
lution in sentence processing: Evidence against
frequency-based accounts. Journal of Memory
and Language 43(3):447–475.
Pynte, Joel, Boris New, and Alan Kennedy. 2008.
On-line contextual influences during reading
normal text: A multiple-regression analysis. Vi-
sion Research 48(21):2172–2183.
Roark, Brian, Asaf Bachrach, Carlos Cardenas,
and Christophe Pallier. 2009. Deriving lex-
ical and syntactic expectation-based measures
for psycholinguistic modeling via incremental
top-down parsing. In Proceedings of the Con-
ference on Empirical Methods in Natural Lan-
guage Processing. Singapore, pages 324–333.
Roland, Douglas and Daniel Jurafsky. 2002. Verb
sense and verb subcategorization probabilities.
In Paola Merlo and Suzanne Stevenson, editors,
The Lexical Basis of Sentence Processing: For-
mal, Computational, and Experimental Issues,
John Bejamins, Amsterdam, pages 325–346.
Sanford, Anthony J. and Patrick Sturt. 2002.
</reference>
<page confidence="0.861363">
66
</page>
<reference confidence="0.953605064516129">
Depth of processing in language comprehen-
sion: Not noticing the evidence. Trends in Cog-
nitive Sciences 6:382–386.
Schuler, William, Samir AbdelRahman, Tim
Miller, and Lane Schwartz. 2010. Broad-
coverage parsing using human-like mem-
ory constraints. Computational Linguistics
26(1):1–30.
Staub, Adrian and Charles Clifton. 2006. Syntac-
tic prediction in language comprehension: Evi-
dence from either ... or. Journal of Experimen-
tal Psychology: Learning, Memory, and Cogni-
tion 32:425–436.
Stewart, Andrew J., Martin J. Pickering, and An-
thony J. Sanford. 2000. The time course of the
influence of implicit causality information: Fo-
cusing versus integration accounts. Journal of
Memory and Language 42(3):423–443.
Sturt, Patrick and Vincenzo Lombardo. 2005.
Processing coordinated structures: Incremen-
tality and connectedness. Cognitive Science
29(2):291–305.
Tanenhaus, Michael K., Michael J. Spivey-
Knowlton, Kathleen M. Eberhard, and Julie C.
Sedivy. 1995. Integration of visual and linguis-
tic information in spoken language comprehen-
sion. Science 268:1632–1634.
Vasishth, Shravan and Richard L. Lewis. 2006.
Argument-head distance and processing com-
plexity: Explaining both locality and antilocal-
ity effects. Language 82(4):767–794.
</reference>
<page confidence="0.999438">
67
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.985494">
<title confidence="0.999827">Cognitively Plausible Models of Human Language Processing</title>
<author confidence="0.999257">Frank Keller</author>
<affiliation confidence="0.999992">School of Informatics, University of Edinburgh</affiliation>
<address confidence="0.999898">10 Crichton Street, Edinburgh EH8 9AB, UK</address>
<email confidence="0.998126">keller@inf.ed.ac.uk</email>
<abstract confidence="0.9992696875">We pose the development of cognitively plausible models of human language processing as a challenge for computational linguistics. Existing models can only deal with isolated phenomena (e.g., garden paths) on small, specifically selected data sets. The challenge is to build models that integrate multiple aspects of human language processing at the syntactic, semantic, and discourse level. Like human language processing, these models should be incremental, predictive, broad coverage, and robust to noise. This challenge can only be met if standardized data sets and evaluation measures are developed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amit Dubey</author>
<author>Frank Keller</author>
<author>Patrick Sturt</author>
</authors>
<title>A probabilistic corpus-based model of syntactic parallelism.</title>
<date>2008</date>
<journal>Cognition</journal>
<volume>109</volume>
<issue>3</issue>
<pages>344</pages>
<marker>Dubey, Keller, Sturt, 2008</marker>
<rawString>Dubey, Amit, Frank Keller, and Patrick Sturt. 2008. A probabilistic corpus-based model of syntactic parallelism. Cognition 109(3):326– 344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferrara Boston</author>
<author>John Hale Marisa</author>
<author>Reinhold Kliegl</author>
<author>Umesh Patil</author>
<author>Shravan Vasishth</author>
</authors>
<title>Parsing costs as predictors of reading difficulty: An evaluation using the Potsdam Sentence Corpus.</title>
<date>2008</date>
<journal>Journal of Eye Movement Research</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="7961" citStr="Boston et al., 2008" startWordPosition="1224" endWordPosition="1227">n path effects. Being based on probabilistic parsing techniques, ranking-based models generally achieve a broad coverage, but their efficiency and robustness has not been evaluated. Also, they are not designed to capture syntactic prediction or memory effects (other than search with a narrow beam in Brants and Crocker 2000). The ranking-based approach has been generalized by surprisal models (Surp), which predict processing difficulty based on the change in the probability distribution over possible analyses from one word to the next (Hale, 2001; Levy, 2008; Demberg and Keller, 2008a; Ferrara Boston et al., 2008; Roark et al., 2009). These models have been successful in accounting for a range of experimental data, and they achieve broad coverage. They also instantiate a limited form of prediction, viz., they build up expectations about the next word in the input. On the other hand, the efficiency and robustness of these models has largely not been evaluated, and memory costs are not modeled (again except for restrictions in beam size). The prediction model (Pred) explicitly predicts syntactic structure for upcoming words (Demberg and Keller, 2008b, 2009), thus accounting for experimental results on p</context>
<context position="16841" citStr="Boston et al., 2008" startWordPosition="2620" endWordPosition="2623">data. In order to assess the efficiency, robustness, and broad coverage of a model, a corpus of unrestricted, naturally occurring text is required. The use of contextualized language data makes it possible to assess not only syntactic models, but also models that capture discourse effects. These corpora need to be annotated with behavioral measures, e.g., eye-tracking or reading time data. Some relevant corpora have already been constructed, see the overview in Table 3, and various authors have used them for model evaluation (Demberg and Keller, 2008a; Pynte et al., 2008; Frank, 2009; Ferrara Boston et al., 2008; Patil et al., 2009; Roark et al., 2009; Mitchell et al., 2010). However, the usefulness of the psycholinguistic corpora in Table 3 is restricted by the absence of gold-standard linguistic annotation (though the French part of the Dundee corpus, which is syntactically annotated). This makes it difficult to test the accuracy of the linguistic structures computed by a model, and restricts evaluation to behavioral predictions. The challenge is therefore to collect a standardized test set of naturally occurring text or speech enriched not only with behavioral variables, but also with syntactic an</context>
</contexts>
<marker>Boston, Marisa, Kliegl, Patil, Vasishth, 2008</marker>
<rawString>Ferrara Boston, Marisa, John Hale, Reinhold Kliegl, Umesh Patil, and Shravan Vasishth. 2008. Parsing costs as predictors of reading difficulty: An evaluation using the Potsdam Sentence Corpus. Journal of Eye Movement Research 2(1):1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernanda Ferreira</author>
<author>Kiel Christianson</author>
<author>Andrew Hollingworth</author>
</authors>
<title>Misinterpretations of garden-path sentences: Implications for models of sentence processing and reanalysis.</title>
<date>2001</date>
<journal>Journal of Psycholinguistic Research</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="4307" citStr="Ferreira et al. (2001)" startWordPosition="634" endWordPosition="637">ge should also include phonological and morphological processing, semantic inference, discourse processing, and other non-syntactic aspects of language processing. Furthermore, established results regarding the interface between language processing and non-linguistic cognition (e.g., the sensorimotor system) should ultimately be accounted for in a fully comprehensive model. 60 Proceedings of the ACL 2010 Conference Short Papers, pages 60–67, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Property Evidence Rank Model Stack Surp Pred Efficiency and robustness Ferreira et al. (2001); Sanford and Sturt (2002) − − − + Broad coverage Crocker and Brants (2000) + + − + Incrementality and connectedness Tanenhaus et al. (1995); Sturt and Lombardo (2005) + + + + Prediction Kamide et al. (2003); Staub and Clifton (2006) − f + − Memory cost Gibson (1998); Vasishth and Lewis (2006) − − + + Table 1: Key properties of human language processing and their instantiation in various models of sentence processing (see Section 2 for details) dence that shallow processing strategies are used to achieve this. The processor also achieves broad coverage: it can deal with a wide variety of synta</context>
</contexts>
<marker>Ferreira, Christianson, Hollingworth, 2001</marker>
<rawString>Ferreira, Fernanda, Kiel Christianson, and Andrew Hollingworth. 2001. Misinterpretations of garden-path sentences: Implications for models of sentence processing and reanalysis. Journal of Psycholinguistic Research 30(1):3–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan L Frank</author>
</authors>
<title>Surprisal-based comparison between a symbolic and a connectionist model of sentence processing.</title>
<date>2009</date>
<booktitle>In Niels Taatgen and Hedderik</booktitle>
<pages>1139--1144</pages>
<editor>van Rijn, editors,</editor>
<location>Amsterdam,</location>
<contexts>
<context position="16812" citStr="Frank, 2009" startWordPosition="2617" endWordPosition="2618">sets based on corpus data. In order to assess the efficiency, robustness, and broad coverage of a model, a corpus of unrestricted, naturally occurring text is required. The use of contextualized language data makes it possible to assess not only syntactic models, but also models that capture discourse effects. These corpora need to be annotated with behavioral measures, e.g., eye-tracking or reading time data. Some relevant corpora have already been constructed, see the overview in Table 3, and various authors have used them for model evaluation (Demberg and Keller, 2008a; Pynte et al., 2008; Frank, 2009; Ferrara Boston et al., 2008; Patil et al., 2009; Roark et al., 2009; Mitchell et al., 2010). However, the usefulness of the psycholinguistic corpora in Table 3 is restricted by the absence of gold-standard linguistic annotation (though the French part of the Dundee corpus, which is syntactically annotated). This makes it difficult to test the accuracy of the linguistic structures computed by a model, and restricts evaluation to behavioral predictions. The challenge is therefore to collect a standardized test set of naturally occurring text or speech enriched not only with behavioral variable</context>
</contexts>
<marker>Frank, 2009</marker>
<rawString>Frank, Stefan L. 2009. Surprisal-based comparison between a symbolic and a connectionist model of sentence processing. In Niels Taatgen and Hedderik van Rijn, editors, Proceedings of the 31st Annual Conference of the Cognitive Science Society. Cognitive Science Society, Amsterdam, pages 1139–1144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan M Garnsey</author>
<author>Neal J Pearlmutter</author>
<author>Elisabeth M Myers</author>
<author>Melanie A Lotocky</author>
</authors>
<title>The contributions of verb bias and plausibility to the comprehension of temporarily ambiguous sentences.</title>
<date>1997</date>
<journal>Journal of Memory and Language</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context position="9031" citStr="Garnsey et al. (1997)" startWordPosition="1396" endWordPosition="1399">odel (Pred) explicitly predicts syntactic structure for upcoming words (Demberg and Keller, 2008b, 2009), thus accounting for experimental results on predictive language processing. It also implements a strict form of incre2We will not distinguish between model and linking theory, i.e., the set of assumptions that links model quantities to behavioral data (e.g., more probably structures are easier to process). It is conceivable, for instance, that a stack-based model is combined with a linking theory based on surprisal. 61 Factor Evidence Word senses Roland and Jurafsky (2002) Selectional re- Garnsey et al. (1997); Pickering and strictions Traxler(1998) Thematic roles McRae et al. (1998); Pickering et al. (2000) Discourse ref- Altmann and Steedman (1988); Groderence ner and Gibson (2005) Discourse Stewart et al. (2000); Kehler et al. coherence (2008) Table 2: Semantic factors in human language processing mentality by building fully connected trees. Memory costs are modeled directly as a distance-based penalty that is incurred when a prediction has to be verified later in the sentence. However, the current implementation of the prediction model is neither robust and efficient nor offers broad coverage. </context>
</contexts>
<marker>Garnsey, Pearlmutter, Myers, Lotocky, 1997</marker>
<rawString>Garnsey, Susan M., Neal J. Pearlmutter, Elisabeth M. Myers, and Melanie A. Lotocky. 1997. The contributions of verb bias and plausibility to the comprehension of temporarily ambiguous sentences. Journal of Memory and Language 37(1):58–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Gibson</author>
</authors>
<title>Linguistic complexity: locality of syntactic dependencies.</title>
<date>1998</date>
<journal>Cognition</journal>
<pages>68--1</pages>
<contexts>
<context position="4574" citStr="Gibson (1998)" startWordPosition="686" endWordPosition="687">n (e.g., the sensorimotor system) should ultimately be accounted for in a fully comprehensive model. 60 Proceedings of the ACL 2010 Conference Short Papers, pages 60–67, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Property Evidence Rank Model Stack Surp Pred Efficiency and robustness Ferreira et al. (2001); Sanford and Sturt (2002) − − − + Broad coverage Crocker and Brants (2000) + + − + Incrementality and connectedness Tanenhaus et al. (1995); Sturt and Lombardo (2005) + + + + Prediction Kamide et al. (2003); Staub and Clifton (2006) − f + − Memory cost Gibson (1998); Vasishth and Lewis (2006) − − + + Table 1: Key properties of human language processing and their instantiation in various models of sentence processing (see Section 2 for details) dence that shallow processing strategies are used to achieve this. The processor also achieves broad coverage: it can deal with a wide variety of syntactic constructions, and is not restricted by the domain, register, or modality of the input. Human language processing is also word-byword incremental. There is strong evidence that a new word is integrated as soon as it is available into the representation of the se</context>
</contexts>
<marker>Gibson, 1998</marker>
<rawString>Gibson, Edward. 1998. Linguistic complexity: locality of syntactic dependencies. Cognition 68:1–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Grodner</author>
<author>Edward Gibson</author>
</authors>
<title>Consequences of the serial nature of linguistic input.</title>
<date>2005</date>
<journal>Cognitive Science</journal>
<pages>29--261</pages>
<marker>Grodner, Gibson, 2005</marker>
<rawString>Grodner, Dan and Edward Gibson. 2005. Consequences of the serial nature of linguistic input. Cognitive Science 29:261–291.</rawString>
</citation>
<citation valid="true">
<date>2009</date>
<booktitle>Proceedings of the 13th Conference on Computational Natural Language Learning: Shared Task. Association for Computational Linguistics,</booktitle>
<editor>Hajiˇc, Jan, editor.</editor>
<location>Boulder, CO.</location>
<marker>2009</marker>
<rawString>Hajiˇc, Jan, editor. 2009. Proceedings of the 13th Conference on Computational Natural Language Learning: Shared Task. Association for Computational Linguistics, Boulder, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Hale</author>
</authors>
<title>A probabilistic Earley parser as a psycholinguistic model.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2nd Conference of the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>159--166</pages>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="7893" citStr="Hale, 2001" startWordPosition="1215" endWordPosition="1216">Both approaches have been shown to successfully model garden path effects. Being based on probabilistic parsing techniques, ranking-based models generally achieve a broad coverage, but their efficiency and robustness has not been evaluated. Also, they are not designed to capture syntactic prediction or memory effects (other than search with a narrow beam in Brants and Crocker 2000). The ranking-based approach has been generalized by surprisal models (Surp), which predict processing difficulty based on the change in the probability distribution over possible analyses from one word to the next (Hale, 2001; Levy, 2008; Demberg and Keller, 2008a; Ferrara Boston et al., 2008; Roark et al., 2009). These models have been successful in accounting for a range of experimental data, and they achieve broad coverage. They also instantiate a limited form of prediction, viz., they build up expectations about the next word in the input. On the other hand, the efficiency and robustness of these models has largely not been evaluated, and memory costs are not modeled (again except for restrictions in beam size). The prediction model (Pred) explicitly predicts syntactic structure for upcoming words (Demberg and</context>
</contexts>
<marker>Hale, 2001</marker>
<rawString>Hale, John. 2001. A probabilistic Earley parser as a psycholinguistic model. In Proceedings of the 2nd Conference of the North American Chapter of the Association for Computational Linguistics. Association for Computational Linguistics, Pittsburgh, PA, volume 2, pages 159–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Betty Hart</author>
<author>Todd R Risley</author>
</authors>
<title>Meaningful Differences in the Everyday Experience of Young American</title>
<date>1995</date>
<location>Baltimore, MD.</location>
<contexts>
<context position="1210" citStr="Hart and Risley, 1995" startWordPosition="176" endWordPosition="179">man language processing, these models should be incremental, predictive, broad coverage, and robust to noise. This challenge can only be met if standardized data sets and evaluation measures are developed. 1 Introduction In many respects, human language processing is the ultimate goldstandard for computational linguistics. Humans understand and generate language with amazing speed and accuracy, they are able to deal with ambiguity and noise effortlessly and can adapt to new speakers, domains, and registers. Most surprisingly, they achieve this competency on the basis of limited training data (Hart and Risley, 1995), using learning algorithms that are largely unsupervised. Given the impressive performance of humans as language processors, it seems natural to turn to psycholinguistics, the discipline that studies human language processing, as a source of information about the design of efficient language processing systems. Indeed, psycholinguists have uncovered an impressive array of relevant facts (reviewed in Section 2), but computational linguists are often not aware of this literature, and results about human language processing rarely inform the design, implementation, or evaluation of artificial la</context>
<context position="12744" citStr="Hart and Risley, 1995" startWordPosition="1968" endWordPosition="1972">el of semantics (Landauer and Dumais, 1997) with a syntactic parser and show that this results in predictions of processing difficulty that can be validated against an eye-tracking corpus. 2.4 Acquisition and Crosslinguistics All models of human language processing discussed so far rely on supervised training data. This raises another aspect of the modeling challenge: the human language processor is the product of an acquisition process that is largely unsupervised and has access to only limited training data: children aged 12–36 months are exposed to between 10 and 35 million words of input (Hart and Risley, 1995). The challenge therefore is to develop a model of language acquisition that works with such small training sets, while also giving rise to a language processor that meets the key criteria in Table 1. The CL community is in a good position to rise to this challenge, given the significant progress in unsupervised parsing in recent years (starting from Klein and Manning 2002). However, none of the existing unsupervised models has been evaluated against psycholinguistic data sets, and they are not designed to meet even basic psycholinguistic criteria such as incrementality. A related modeling cha</context>
</contexts>
<marker>Hart, Risley, 1995</marker>
<rawString>Hart, Betty and Todd R. Risley. 1995. Meaningful Differences in the Everyday Experience of Young American Children. Paul H. Brookes, Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
</authors>
<title>A probabilistic model of lexical and syntactic access and disambiguation.</title>
<date>1996</date>
<journal>Cognitive Science</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="6988" citStr="Jurafsky (1996)" startWordPosition="1075" endWordPosition="1077">be held in memory at the same time. 2.2 Current Models The challenge is to develop a computational model that captures the key properties of human language processing outlined in the previous section. A number of relevant models have been developed, mostly based on probabilistic parsing techniques, but none of them instantiates all the key properties discussed above (Table 1 gives an overview of model properties).2 The earliest approaches were ranking-based models (Rank), which make psycholinguistic predictions based on the ranking of the syntactic analyses produced by a probabilistic parser. Jurafsky (1996) assumes that processing difficulty is triggered if the correct analysis falls below a certain probability threshold (i.e., is pruned by the parser). Similarly, Crocker and Brants (2000) assume that processing difficulty ensures if the highest-ranked analysis changes from one word to the next. Both approaches have been shown to successfully model garden path effects. Being based on probabilistic parsing techniques, ranking-based models generally achieve a broad coverage, but their efficiency and robustness has not been evaluated. Also, they are not designed to capture syntactic prediction or m</context>
</contexts>
<marker>Jurafsky, 1996</marker>
<rawString>Jurafsky, Daniel. 1996. A probabilistic model of lexical and syntactic access and disambiguation. Cognitive Science 20(2):137–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuki Kamide</author>
<author>Gerry T M Altmann</author>
<author>Sarah L Haywood</author>
</authors>
<title>The time-course of prediction in incremental sentence processing: Evidence from anticipatory eye movements.</title>
<date>2003</date>
<journal>Journal of Memory and Language</journal>
<pages>49--133</pages>
<contexts>
<context position="4514" citStr="Kamide et al. (2003)" startWordPosition="672" endWordPosition="675">e interface between language processing and non-linguistic cognition (e.g., the sensorimotor system) should ultimately be accounted for in a fully comprehensive model. 60 Proceedings of the ACL 2010 Conference Short Papers, pages 60–67, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Property Evidence Rank Model Stack Surp Pred Efficiency and robustness Ferreira et al. (2001); Sanford and Sturt (2002) − − − + Broad coverage Crocker and Brants (2000) + + − + Incrementality and connectedness Tanenhaus et al. (1995); Sturt and Lombardo (2005) + + + + Prediction Kamide et al. (2003); Staub and Clifton (2006) − f + − Memory cost Gibson (1998); Vasishth and Lewis (2006) − − + + Table 1: Key properties of human language processing and their instantiation in various models of sentence processing (see Section 2 for details) dence that shallow processing strategies are used to achieve this. The processor also achieves broad coverage: it can deal with a wide variety of syntactic constructions, and is not restricted by the domain, register, or modality of the input. Human language processing is also word-byword incremental. There is strong evidence that a new word is integrated </context>
</contexts>
<marker>Kamide, Altmann, Haywood, 2003</marker>
<rawString>Kamide, Yuki, Gerry T. M. Altmann, and Sarah L. Haywood. 2003. The time-course of prediction in incremental sentence processing: Evidence from anticipatory eye movements. Journal of Memory and Language 49:133–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kehler</author>
<author>Laura Kertz</author>
<author>Hannah Rohde</author>
<author>Jeffrey L Elman</author>
</authors>
<title>Coherence and coreference revisited.</title>
<date>2008</date>
<journal>Journal of Semantics</journal>
<volume>25</volume>
<issue>1</issue>
<pages>44</pages>
<marker>Kehler, Kertz, Rohde, Elman, 2008</marker>
<rawString>Kehler, Andrew, Laura Kertz, Hannah Rohde, and Jeffrey L. Elman. 2008. Coherence and coreference revisited. Journal of Semantics 25(1):1– 44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Kennedy</author>
<author>Joel Pynte</author>
</authors>
<title>Parafovealon-foveal effects in normal reading.</title>
<date>2005</date>
<journal>Vision Research</journal>
<pages>45--153</pages>
<contexts>
<context position="18650" citStr="Kennedy and Pynte (2005)" startWordPosition="2895" endWordPosition="2898">ed for computational psycholinguistics – maybe along the lines of the model comparison challenges that held at the International Conference on Cognitive Modeling. These challenges provide standardized task descriptions and data sets; participants can enter their cognitive models, which were then compared using a pre-defined evaluation metric.3 3The ICCM 2009 challenge was the Dynamic Stock and Flows Task, for more information see http://www.hss. cmu.edu/departments/sds/ddmlab/modeldsf/. 63 Corpus Language Words Participants Method Reference Dundee Corpus English, French 50,000 10 Eye-tracking Kennedy and Pynte (2005) Potsdam Corpus German 1,138 222 Eye-tracking Kliegl et al. (2006) MIT Corpus English 3,534 23 Self-paced reading Bachrach (2008) Table 3: Test corpora that have been used for psycholinguistic modeling of sentence processing; note that the Potsdam Corpus consists of isolated sentences, rather than of continuous text 3.2 Behavioral and Neural Data As outlined in the previous section, a number of authors have evaluated psycholinguistic models against eye-tracking or reading time corpora. Part of the data and evaluation challenge is to extend this evaluation to neural data as provided by eventrel</context>
</contexts>
<marker>Kennedy, Pynte, 2005</marker>
<rawString>Kennedy, Alan and Joel Pynte. 2005. Parafovealon-foveal effects in normal reading. Vision Research 45:153–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher Manning</author>
</authors>
<title>A generative constituent-context model for improved grammar induction.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>128--135</pages>
<location>Philadelphia,</location>
<contexts>
<context position="13120" citStr="Klein and Manning 2002" startWordPosition="2033" endWordPosition="2036">human language processor is the product of an acquisition process that is largely unsupervised and has access to only limited training data: children aged 12–36 months are exposed to between 10 and 35 million words of input (Hart and Risley, 1995). The challenge therefore is to develop a model of language acquisition that works with such small training sets, while also giving rise to a language processor that meets the key criteria in Table 1. The CL community is in a good position to rise to this challenge, given the significant progress in unsupervised parsing in recent years (starting from Klein and Manning 2002). However, none of the existing unsupervised models has been evaluated against psycholinguistic data sets, and they are not designed to meet even basic psycholinguistic criteria such as incrementality. A related modeling challenge is the development of processing models for languages other than English. There is a growing body of experimental research investigating human language processing in other languages, but virtually all existing psycholinguistic models only work for English (the only exceptions we are aware of are Dubey et al.’s (2008) and Ferrara Boston et al.’s 62 (2008) parsing mode</context>
</contexts>
<marker>Klein, Manning, 2002</marker>
<rawString>Klein, Dan and Christopher Manning. 2002. A generative constituent-context model for improved grammar induction. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. Philadelphia, pages 128–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhold Kliegl</author>
<author>Antje Nuthmann</author>
<author>Ralf Engbert</author>
</authors>
<title>Tracking the mind during reading: The influence of past, present, and future words on fixation durations.</title>
<date>2006</date>
<journal>Journal of Experimental Psychology: General</journal>
<volume>135</volume>
<issue>1</issue>
<contexts>
<context position="18716" citStr="Kliegl et al. (2006)" startWordPosition="2905" endWordPosition="2908">model comparison challenges that held at the International Conference on Cognitive Modeling. These challenges provide standardized task descriptions and data sets; participants can enter their cognitive models, which were then compared using a pre-defined evaluation metric.3 3The ICCM 2009 challenge was the Dynamic Stock and Flows Task, for more information see http://www.hss. cmu.edu/departments/sds/ddmlab/modeldsf/. 63 Corpus Language Words Participants Method Reference Dundee Corpus English, French 50,000 10 Eye-tracking Kennedy and Pynte (2005) Potsdam Corpus German 1,138 222 Eye-tracking Kliegl et al. (2006) MIT Corpus English 3,534 23 Self-paced reading Bachrach (2008) Table 3: Test corpora that have been used for psycholinguistic modeling of sentence processing; note that the Potsdam Corpus consists of isolated sentences, rather than of continuous text 3.2 Behavioral and Neural Data As outlined in the previous section, a number of authors have evaluated psycholinguistic models against eye-tracking or reading time corpora. Part of the data and evaluation challenge is to extend this evaluation to neural data as provided by eventrelated potential (ERP) or brain imaging studies (e.g., using functio</context>
</contexts>
<marker>Kliegl, Nuthmann, Engbert, 2006</marker>
<rawString>Kliegl, Reinhold, Antje Nuthmann, and Ralf Engbert. 2006. Tracking the mind during reading: The influence of past, present, and future words on fixation durations. Journal of Experimental Psychology: General 135(1):12–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Susan T Dumais</author>
</authors>
<title>A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review</journal>
<volume>104</volume>
<issue>2</issue>
<contexts>
<context position="12165" citStr="Landauer and Dumais, 1997" startWordPosition="1874" endWordPosition="1877">as thematic role assignment into a parsing model (Narayanan and Jurafsky, 2002; Pad´o et al., 2009). However, other semantic factors are not accounted for by these models, and incorporating non-lexical aspects of semantics into models of sentence processing is a challenge for ongoing research. Recently, Dubey (2010) has proposed an approach that combines a probabilistic parser with a model of co-reference and discourse inference based on probabilistic logic. An alternative approach has been taken by Pynte et al. (2008) and Mitchell et al. (2010), who combine a vector-space model of semantics (Landauer and Dumais, 1997) with a syntactic parser and show that this results in predictions of processing difficulty that can be validated against an eye-tracking corpus. 2.4 Acquisition and Crosslinguistics All models of human language processing discussed so far rely on supervised training data. This raises another aspect of the modeling challenge: the human language processor is the product of an acquisition process that is largely unsupervised and has access to only limited training data: children aged 12–36 months are exposed to between 10 and 35 million words of input (Hart and Risley, 1995). The challenge there</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Landauer, Thomas K. and Susan T. Dumais. 1997. A solution to Plato’s problem: The latent semantic analysis theory of acquisition, induction and representation of knowledge. Psychological Review 104(2):211–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
</authors>
<title>Expectation-based syntactic comprehension.</title>
<date>2008</date>
<journal>Cognition</journal>
<volume>106</volume>
<issue>3</issue>
<contexts>
<context position="7905" citStr="Levy, 2008" startWordPosition="1217" endWordPosition="1218">hes have been shown to successfully model garden path effects. Being based on probabilistic parsing techniques, ranking-based models generally achieve a broad coverage, but their efficiency and robustness has not been evaluated. Also, they are not designed to capture syntactic prediction or memory effects (other than search with a narrow beam in Brants and Crocker 2000). The ranking-based approach has been generalized by surprisal models (Surp), which predict processing difficulty based on the change in the probability distribution over possible analyses from one word to the next (Hale, 2001; Levy, 2008; Demberg and Keller, 2008a; Ferrara Boston et al., 2008; Roark et al., 2009). These models have been successful in accounting for a range of experimental data, and they achieve broad coverage. They also instantiate a limited form of prediction, viz., they build up expectations about the next word in the input. On the other hand, the efficiency and robustness of these models has largely not been evaluated, and memory costs are not modeled (again except for restrictions in beam size). The prediction model (Pred) explicitly predicts syntactic structure for upcoming words (Demberg and Keller, 200</context>
</contexts>
<marker>Levy, 2008</marker>
<rawString>Levy, Roger. 2008. Expectation-based syntactic comprehension. Cognition 106(3):1126–1177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken McRae</author>
<author>Michael J Spivey-Knowlton</author>
<author>Michael K Tanenhaus</author>
</authors>
<title>Modeling the influence of thematic fit (and other constraints) in on-line sentence comprehension.</title>
<date>1998</date>
<journal>Journal of Memory and Language</journal>
<volume>38</volume>
<issue>3</issue>
<contexts>
<context position="9106" citStr="McRae et al. (1998)" startWordPosition="1406" endWordPosition="1409">rg and Keller, 2008b, 2009), thus accounting for experimental results on predictive language processing. It also implements a strict form of incre2We will not distinguish between model and linking theory, i.e., the set of assumptions that links model quantities to behavioral data (e.g., more probably structures are easier to process). It is conceivable, for instance, that a stack-based model is combined with a linking theory based on surprisal. 61 Factor Evidence Word senses Roland and Jurafsky (2002) Selectional re- Garnsey et al. (1997); Pickering and strictions Traxler(1998) Thematic roles McRae et al. (1998); Pickering et al. (2000) Discourse ref- Altmann and Steedman (1988); Groderence ner and Gibson (2005) Discourse Stewart et al. (2000); Kehler et al. coherence (2008) Table 2: Semantic factors in human language processing mentality by building fully connected trees. Memory costs are modeled directly as a distance-based penalty that is incurred when a prediction has to be verified later in the sentence. However, the current implementation of the prediction model is neither robust and efficient nor offers broad coverage. Recently, a stack-based model (Stack) has been proposed that imposes explic</context>
</contexts>
<marker>McRae, Spivey-Knowlton, Tanenhaus, 1998</marker>
<rawString>McRae, Ken, Michael J. Spivey-Knowlton, and Michael K. Tanenhaus. 1998. Modeling the influence of thematic fit (and other constraints) in on-line sentence comprehension. Journal of Memory and Language 38(3):283–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
<author>Vera Demberg</author>
<author>Frank Keller</author>
</authors>
<title>Syntactic and semantic factors in processing difficulty: An integrated measure.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Uppsala.</location>
<contexts>
<context position="12090" citStr="Mitchell et al. (2010)" startWordPosition="1863" endWordPosition="1866">ere are some examples of models that integrate semantic processes such as thematic role assignment into a parsing model (Narayanan and Jurafsky, 2002; Pad´o et al., 2009). However, other semantic factors are not accounted for by these models, and incorporating non-lexical aspects of semantics into models of sentence processing is a challenge for ongoing research. Recently, Dubey (2010) has proposed an approach that combines a probabilistic parser with a model of co-reference and discourse inference based on probabilistic logic. An alternative approach has been taken by Pynte et al. (2008) and Mitchell et al. (2010), who combine a vector-space model of semantics (Landauer and Dumais, 1997) with a syntactic parser and show that this results in predictions of processing difficulty that can be validated against an eye-tracking corpus. 2.4 Acquisition and Crosslinguistics All models of human language processing discussed so far rely on supervised training data. This raises another aspect of the modeling challenge: the human language processor is the product of an acquisition process that is largely unsupervised and has access to only limited training data: children aged 12–36 months are exposed to between 10</context>
<context position="16905" citStr="Mitchell et al., 2010" startWordPosition="2632" endWordPosition="2635">d coverage of a model, a corpus of unrestricted, naturally occurring text is required. The use of contextualized language data makes it possible to assess not only syntactic models, but also models that capture discourse effects. These corpora need to be annotated with behavioral measures, e.g., eye-tracking or reading time data. Some relevant corpora have already been constructed, see the overview in Table 3, and various authors have used them for model evaluation (Demberg and Keller, 2008a; Pynte et al., 2008; Frank, 2009; Ferrara Boston et al., 2008; Patil et al., 2009; Roark et al., 2009; Mitchell et al., 2010). However, the usefulness of the psycholinguistic corpora in Table 3 is restricted by the absence of gold-standard linguistic annotation (though the French part of the Dundee corpus, which is syntactically annotated). This makes it difficult to test the accuracy of the linguistic structures computed by a model, and restricts evaluation to behavioral predictions. The challenge is therefore to collect a standardized test set of naturally occurring text or speech enriched not only with behavioral variables, but also with syntactic and semantic annotation. Such a data set could for example be cons</context>
</contexts>
<marker>Mitchell, Lapata, Demberg, Keller, 2010</marker>
<rawString>Mitchell, Jeff, Mirella Lapata, Vera Demberg, and Frank Keller. 2010. Syntactic and semantic factors in processing difficulty: An integrated measure. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Uppsala.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Tom M Mitchell</author>
<author>Svetlana V Shinkareva</author>
<author>Andrew Carlson</author>
<author>Kai-Min Chang</author>
<author>Vicente L Malave</author>
<author>Robert A Mason</author>
<author>Marcel Adam</author>
</authors>
<title>Just3.2008. Predicting human brain activity associated with the meanings of nouns.</title>
<journal>Science</journal>
<volume>320</volume>
<issue>5880</issue>
<marker>Mitchell, Shinkareva, Carlson, Chang, Malave, Mason, Adam, </marker>
<rawString>Mitchell, Tom M., Svetlana V. Shinkareva, Andrew Carlson, Kai-Min Chang, Vicente L. Malave, Robert A. Mason, and Marcel Adam Just3.2008. Predicting human brain activity associated with the meanings of nouns. Science 320(5880):1191–1195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Murphy</author>
<author>Marco Baroni</author>
<author>Massimo Poesio</author>
</authors>
<title>EEG responds to conceptual stimuli and corpus semantics.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Singapore,</booktitle>
<pages>619--627</pages>
<contexts>
<context position="19605" citStr="Murphy et al., 2009" startWordPosition="3042" endWordPosition="3045">d Neural Data As outlined in the previous section, a number of authors have evaluated psycholinguistic models against eye-tracking or reading time corpora. Part of the data and evaluation challenge is to extend this evaluation to neural data as provided by eventrelated potential (ERP) or brain imaging studies (e.g., using functional magnetic resonance imaging, fMRI). Neural data sets are considerably more complex than behavioral ones, and modeling them is an important new task that the community is only beginning to address. Some recent work has evaluated models of word semantics against ERP (Murphy et al., 2009) or fMRI data (Mitchell et al., 2008).4 This is a very promising direction, and the challenge is to extend this approach to the sentence and discourse level (see Bachrach 2008). Again, it will again be necessary to develop standardized test sets of both experimental data and corpus data. 3.3 Evaluation Measures We also anticipate that the availability of new test data sets will facilitate the development of new evaluation measures that specifically test the validity of psycholinguistic models. Established CL evaluation measures such as Parseval are of limited use, as they can only test the lin</context>
</contexts>
<marker>Murphy, Baroni, Poesio, 2009</marker>
<rawString>Murphy, Brian, Marco Baroni, and Massimo Poesio. 2009. EEG responds to conceptual stimuli and corpus semantics. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Singapore, pages 619– 627.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
<author>Daniel Jurafsky</author>
</authors>
<title>A Bayesian model predicts human parse preference and reading time in sentence processing.</title>
<date>2002</date>
<booktitle>In Thomas G. Dietterich, Sue Becker, and Zoubin Ghahramani, editors, Advances in Neural Information Processing Systems 14.</booktitle>
<pages>59--65</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="11617" citStr="Narayanan and Jurafsky, 2002" startWordPosition="1788" endWordPosition="1791">clause such that it disambiguates between the two antecedents; garden paths are reduced or disappear. Other results point to the importance of discourse coherence for sentence processing, an example being implicit causality. The challenge facing researchers in computational and psycholinguistics therefore includes the development of language processing models that combine syntactic processing with semantic and discourse processing. So far, this challenge is largely unmet: there are some examples of models that integrate semantic processes such as thematic role assignment into a parsing model (Narayanan and Jurafsky, 2002; Pad´o et al., 2009). However, other semantic factors are not accounted for by these models, and incorporating non-lexical aspects of semantics into models of sentence processing is a challenge for ongoing research. Recently, Dubey (2010) has proposed an approach that combines a probabilistic parser with a model of co-reference and discourse inference based on probabilistic logic. An alternative approach has been taken by Pynte et al. (2008) and Mitchell et al. (2010), who combine a vector-space model of semantics (Landauer and Dumais, 1997) with a syntactic parser and show that this results </context>
</contexts>
<marker>Narayanan, Jurafsky, 2002</marker>
<rawString>Narayanan, Srini and Daniel Jurafsky. 2002. A Bayesian model predicts human parse preference and reading time in sentence processing. In Thomas G. Dietterich, Sue Becker, and Zoubin Ghahramani, editors, Advances in Neural Information Processing Systems 14. MIT Press, Cambridge, MA, pages 59–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrike Pad´o</author>
<author>Matthew W Crocker</author>
<author>Frank Keller</author>
</authors>
<title>A probabilistic model of semantic plausibility in sentence processing.</title>
<date>2009</date>
<journal>Cognitive Science</journal>
<volume>33</volume>
<issue>5</issue>
<marker>Pad´o, Crocker, Keller, 2009</marker>
<rawString>Pad´o, Ulrike, Matthew W. Crocker, and Frank Keller. 2009. A probabilistic model of semantic plausibility in sentence processing. Cognitive Science 33(5):794–838.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Umesh Patil</author>
<author>Shravan Vasishth</author>
<author>Reinhold Kliegl</author>
</authors>
<title>Compound effect of probabilistic disambiguation and memory retrievals on sentence processing: Evidence from an eyetracking corpus.</title>
<date>2009</date>
<booktitle>Proceedings of 9th International Conference on Cognitive Modeling.</booktitle>
<editor>In A. Howes, D. Peebles, and R. Cooper, editors,</editor>
<location>Manchester.</location>
<contexts>
<context position="16861" citStr="Patil et al., 2009" startWordPosition="2624" endWordPosition="2627">ess the efficiency, robustness, and broad coverage of a model, a corpus of unrestricted, naturally occurring text is required. The use of contextualized language data makes it possible to assess not only syntactic models, but also models that capture discourse effects. These corpora need to be annotated with behavioral measures, e.g., eye-tracking or reading time data. Some relevant corpora have already been constructed, see the overview in Table 3, and various authors have used them for model evaluation (Demberg and Keller, 2008a; Pynte et al., 2008; Frank, 2009; Ferrara Boston et al., 2008; Patil et al., 2009; Roark et al., 2009; Mitchell et al., 2010). However, the usefulness of the psycholinguistic corpora in Table 3 is restricted by the absence of gold-standard linguistic annotation (though the French part of the Dundee corpus, which is syntactically annotated). This makes it difficult to test the accuracy of the linguistic structures computed by a model, and restricts evaluation to behavioral predictions. The challenge is therefore to collect a standardized test set of naturally occurring text or speech enriched not only with behavioral variables, but also with syntactic and semantic annotatio</context>
</contexts>
<marker>Patil, Vasishth, Kliegl, 2009</marker>
<rawString>Patil, Umesh, Shravan Vasishth, and Reinhold Kliegl. 2009. Compound effect of probabilistic disambiguation and memory retrievals on sentence processing: Evidence from an eyetracking corpus. In A. Howes, D. Peebles, and R. Cooper, editors, Proceedings of 9th International Conference on Cognitive Modeling. Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin J Pickering</author>
<author>Martin J Traxler</author>
</authors>
<title>Plausibility and recovery from garden paths: An eye-tracking study.</title>
<date>1998</date>
<journal>Journal of Experimental Psychology: Learning Memory and Cognition</journal>
<volume>24</volume>
<issue>4</issue>
<marker>Pickering, Traxler, 1998</marker>
<rawString>Pickering, Martin J. and Martin J. Traxler. 1998. Plausibility and recovery from garden paths: An eye-tracking study. Journal of Experimental Psychology: Learning Memory and Cognition 24(4):940–961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin J Pickering</author>
<author>Matthew J Traxler</author>
<author>Matthew W Crocker</author>
</authors>
<title>Ambiguity resolution in sentence processing: Evidence against frequency-based accounts.</title>
<date>2000</date>
<journal>Journal of Memory and Language</journal>
<volume>43</volume>
<issue>3</issue>
<contexts>
<context position="9131" citStr="Pickering et al. (2000)" startWordPosition="1410" endWordPosition="1413"> 2009), thus accounting for experimental results on predictive language processing. It also implements a strict form of incre2We will not distinguish between model and linking theory, i.e., the set of assumptions that links model quantities to behavioral data (e.g., more probably structures are easier to process). It is conceivable, for instance, that a stack-based model is combined with a linking theory based on surprisal. 61 Factor Evidence Word senses Roland and Jurafsky (2002) Selectional re- Garnsey et al. (1997); Pickering and strictions Traxler(1998) Thematic roles McRae et al. (1998); Pickering et al. (2000) Discourse ref- Altmann and Steedman (1988); Groderence ner and Gibson (2005) Discourse Stewart et al. (2000); Kehler et al. coherence (2008) Table 2: Semantic factors in human language processing mentality by building fully connected trees. Memory costs are modeled directly as a distance-based penalty that is incurred when a prediction has to be verified later in the sentence. However, the current implementation of the prediction model is neither robust and efficient nor offers broad coverage. Recently, a stack-based model (Stack) has been proposed that imposes explicit, cognitively motivated</context>
</contexts>
<marker>Pickering, Traxler, Crocker, 2000</marker>
<rawString>Pickering, Martin J., Matthew J. Traxler, and Matthew W. Crocker. 2000. Ambiguity resolution in sentence processing: Evidence against frequency-based accounts. Journal of Memory and Language 43(3):447–475.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Pynte</author>
<author>Boris New</author>
<author>Alan Kennedy</author>
</authors>
<title>On-line contextual influences during reading normal text: A multiple-regression analysis.</title>
<date>2008</date>
<journal>Vision Research</journal>
<volume>48</volume>
<issue>21</issue>
<contexts>
<context position="12063" citStr="Pynte et al. (2008)" startWordPosition="1858" endWordPosition="1861">nge is largely unmet: there are some examples of models that integrate semantic processes such as thematic role assignment into a parsing model (Narayanan and Jurafsky, 2002; Pad´o et al., 2009). However, other semantic factors are not accounted for by these models, and incorporating non-lexical aspects of semantics into models of sentence processing is a challenge for ongoing research. Recently, Dubey (2010) has proposed an approach that combines a probabilistic parser with a model of co-reference and discourse inference based on probabilistic logic. An alternative approach has been taken by Pynte et al. (2008) and Mitchell et al. (2010), who combine a vector-space model of semantics (Landauer and Dumais, 1997) with a syntactic parser and show that this results in predictions of processing difficulty that can be validated against an eye-tracking corpus. 2.4 Acquisition and Crosslinguistics All models of human language processing discussed so far rely on supervised training data. This raises another aspect of the modeling challenge: the human language processor is the product of an acquisition process that is largely unsupervised and has access to only limited training data: children aged 12–36 month</context>
<context position="16799" citStr="Pynte et al., 2008" startWordPosition="2613" endWordPosition="2616">omplemented by test sets based on corpus data. In order to assess the efficiency, robustness, and broad coverage of a model, a corpus of unrestricted, naturally occurring text is required. The use of contextualized language data makes it possible to assess not only syntactic models, but also models that capture discourse effects. These corpora need to be annotated with behavioral measures, e.g., eye-tracking or reading time data. Some relevant corpora have already been constructed, see the overview in Table 3, and various authors have used them for model evaluation (Demberg and Keller, 2008a; Pynte et al., 2008; Frank, 2009; Ferrara Boston et al., 2008; Patil et al., 2009; Roark et al., 2009; Mitchell et al., 2010). However, the usefulness of the psycholinguistic corpora in Table 3 is restricted by the absence of gold-standard linguistic annotation (though the French part of the Dundee corpus, which is syntactically annotated). This makes it difficult to test the accuracy of the linguistic structures computed by a model, and restricts evaluation to behavioral predictions. The challenge is therefore to collect a standardized test set of naturally occurring text or speech enriched not only with behavi</context>
</contexts>
<marker>Pynte, New, Kennedy, 2008</marker>
<rawString>Pynte, Joel, Boris New, and Alan Kennedy. 2008. On-line contextual influences during reading normal text: A multiple-regression analysis. Vision Research 48(21):2172–2183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Asaf Bachrach</author>
<author>Carlos Cardenas</author>
<author>Christophe Pallier</author>
</authors>
<title>Deriving lexical and syntactic expectation-based measures for psycholinguistic modeling via incremental top-down parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Singapore,</booktitle>
<pages>324--333</pages>
<contexts>
<context position="7982" citStr="Roark et al., 2009" startWordPosition="1228" endWordPosition="1231"> based on probabilistic parsing techniques, ranking-based models generally achieve a broad coverage, but their efficiency and robustness has not been evaluated. Also, they are not designed to capture syntactic prediction or memory effects (other than search with a narrow beam in Brants and Crocker 2000). The ranking-based approach has been generalized by surprisal models (Surp), which predict processing difficulty based on the change in the probability distribution over possible analyses from one word to the next (Hale, 2001; Levy, 2008; Demberg and Keller, 2008a; Ferrara Boston et al., 2008; Roark et al., 2009). These models have been successful in accounting for a range of experimental data, and they achieve broad coverage. They also instantiate a limited form of prediction, viz., they build up expectations about the next word in the input. On the other hand, the efficiency and robustness of these models has largely not been evaluated, and memory costs are not modeled (again except for restrictions in beam size). The prediction model (Pred) explicitly predicts syntactic structure for upcoming words (Demberg and Keller, 2008b, 2009), thus accounting for experimental results on predictive language pr</context>
<context position="16881" citStr="Roark et al., 2009" startWordPosition="2628" endWordPosition="2631">robustness, and broad coverage of a model, a corpus of unrestricted, naturally occurring text is required. The use of contextualized language data makes it possible to assess not only syntactic models, but also models that capture discourse effects. These corpora need to be annotated with behavioral measures, e.g., eye-tracking or reading time data. Some relevant corpora have already been constructed, see the overview in Table 3, and various authors have used them for model evaluation (Demberg and Keller, 2008a; Pynte et al., 2008; Frank, 2009; Ferrara Boston et al., 2008; Patil et al., 2009; Roark et al., 2009; Mitchell et al., 2010). However, the usefulness of the psycholinguistic corpora in Table 3 is restricted by the absence of gold-standard linguistic annotation (though the French part of the Dundee corpus, which is syntactically annotated). This makes it difficult to test the accuracy of the linguistic structures computed by a model, and restricts evaluation to behavioral predictions. The challenge is therefore to collect a standardized test set of naturally occurring text or speech enriched not only with behavioral variables, but also with syntactic and semantic annotation. Such a data set c</context>
</contexts>
<marker>Roark, Bachrach, Cardenas, Pallier, 2009</marker>
<rawString>Roark, Brian, Asaf Bachrach, Carlos Cardenas, and Christophe Pallier. 2009. Deriving lexical and syntactic expectation-based measures for psycholinguistic modeling via incremental top-down parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Singapore, pages 324–333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Roland</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Verb sense and verb subcategorization probabilities.</title>
<date>2002</date>
<booktitle>In Paola Merlo and Suzanne Stevenson, editors, The Lexical Basis of Sentence Processing: Formal, Computational, and Experimental Issues,</booktitle>
<pages>325--346</pages>
<location>John Bejamins, Amsterdam,</location>
<contexts>
<context position="8993" citStr="Roland and Jurafsky (2002)" startWordPosition="1390" endWordPosition="1393">estrictions in beam size). The prediction model (Pred) explicitly predicts syntactic structure for upcoming words (Demberg and Keller, 2008b, 2009), thus accounting for experimental results on predictive language processing. It also implements a strict form of incre2We will not distinguish between model and linking theory, i.e., the set of assumptions that links model quantities to behavioral data (e.g., more probably structures are easier to process). It is conceivable, for instance, that a stack-based model is combined with a linking theory based on surprisal. 61 Factor Evidence Word senses Roland and Jurafsky (2002) Selectional re- Garnsey et al. (1997); Pickering and strictions Traxler(1998) Thematic roles McRae et al. (1998); Pickering et al. (2000) Discourse ref- Altmann and Steedman (1988); Groderence ner and Gibson (2005) Discourse Stewart et al. (2000); Kehler et al. coherence (2008) Table 2: Semantic factors in human language processing mentality by building fully connected trees. Memory costs are modeled directly as a distance-based penalty that is incurred when a prediction has to be verified later in the sentence. However, the current implementation of the prediction model is neither robust and</context>
</contexts>
<marker>Roland, Jurafsky, 2002</marker>
<rawString>Roland, Douglas and Daniel Jurafsky. 2002. Verb sense and verb subcategorization probabilities. In Paola Merlo and Suzanne Stevenson, editors, The Lexical Basis of Sentence Processing: Formal, Computational, and Experimental Issues, John Bejamins, Amsterdam, pages 325–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony J Sanford</author>
<author>Patrick Sturt</author>
</authors>
<title>Depth of processing in language comprehension: Not noticing the evidence. Trends in Cognitive Sciences 6:382–386.</title>
<date>2002</date>
<contexts>
<context position="4333" citStr="Sanford and Sturt (2002)" startWordPosition="638" endWordPosition="641">honological and morphological processing, semantic inference, discourse processing, and other non-syntactic aspects of language processing. Furthermore, established results regarding the interface between language processing and non-linguistic cognition (e.g., the sensorimotor system) should ultimately be accounted for in a fully comprehensive model. 60 Proceedings of the ACL 2010 Conference Short Papers, pages 60–67, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Property Evidence Rank Model Stack Surp Pred Efficiency and robustness Ferreira et al. (2001); Sanford and Sturt (2002) − − − + Broad coverage Crocker and Brants (2000) + + − + Incrementality and connectedness Tanenhaus et al. (1995); Sturt and Lombardo (2005) + + + + Prediction Kamide et al. (2003); Staub and Clifton (2006) − f + − Memory cost Gibson (1998); Vasishth and Lewis (2006) − − + + Table 1: Key properties of human language processing and their instantiation in various models of sentence processing (see Section 2 for details) dence that shallow processing strategies are used to achieve this. The processor also achieves broad coverage: it can deal with a wide variety of syntactic constructions, and is</context>
</contexts>
<marker>Sanford, Sturt, 2002</marker>
<rawString>Sanford, Anthony J. and Patrick Sturt. 2002. Depth of processing in language comprehension: Not noticing the evidence. Trends in Cognitive Sciences 6:382–386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Schuler</author>
<author>Samir AbdelRahman</author>
<author>Tim Miller</author>
<author>Lane Schwartz</author>
</authors>
<title>Broadcoverage parsing using human-like memory constraints.</title>
<date>2010</date>
<journal>Computational Linguistics</journal>
<volume>26</volume>
<issue>1</issue>
<contexts>
<context position="9846" citStr="Schuler et al., 2010" startWordPosition="1521" endWordPosition="1524">t et al. (2000); Kehler et al. coherence (2008) Table 2: Semantic factors in human language processing mentality by building fully connected trees. Memory costs are modeled directly as a distance-based penalty that is incurred when a prediction has to be verified later in the sentence. However, the current implementation of the prediction model is neither robust and efficient nor offers broad coverage. Recently, a stack-based model (Stack) has been proposed that imposes explicit, cognitively motivated memory constraints on the parser, in effect limiting the stack size available to the parser (Schuler et al., 2010). This delivers robustness, efficiency, and broad coverage, but does not model syntactic prediction. Unlike the other models discussed here, no psycholinguistic evaluation has been conducted on the stack-based model, so its cognitive plausibility is preliminary. 2.3 Beyond Parsing There is strong evidence that human language processing is driven by an interaction of syntactic, semantic, and discourse processes (see Table 2 for an overview and references). Considerable experimental work has focused on the semantic properties of the verb of the sentence, and verb sense, selectional restrictions,</context>
</contexts>
<marker>Schuler, AbdelRahman, Miller, Schwartz, 2010</marker>
<rawString>Schuler, William, Samir AbdelRahman, Tim Miller, and Lane Schwartz. 2010. Broadcoverage parsing using human-like memory constraints. Computational Linguistics 26(1):1–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrian Staub</author>
<author>Charles Clifton</author>
</authors>
<title>Syntactic prediction in language comprehension: Evidence from either ...</title>
<date>2006</date>
<journal>or. Journal of Experimental Psychology: Learning, Memory, and Cognition</journal>
<pages>32--425</pages>
<contexts>
<context position="4540" citStr="Staub and Clifton (2006)" startWordPosition="676" endWordPosition="679">nguage processing and non-linguistic cognition (e.g., the sensorimotor system) should ultimately be accounted for in a fully comprehensive model. 60 Proceedings of the ACL 2010 Conference Short Papers, pages 60–67, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Property Evidence Rank Model Stack Surp Pred Efficiency and robustness Ferreira et al. (2001); Sanford and Sturt (2002) − − − + Broad coverage Crocker and Brants (2000) + + − + Incrementality and connectedness Tanenhaus et al. (1995); Sturt and Lombardo (2005) + + + + Prediction Kamide et al. (2003); Staub and Clifton (2006) − f + − Memory cost Gibson (1998); Vasishth and Lewis (2006) − − + + Table 1: Key properties of human language processing and their instantiation in various models of sentence processing (see Section 2 for details) dence that shallow processing strategies are used to achieve this. The processor also achieves broad coverage: it can deal with a wide variety of syntactic constructions, and is not restricted by the domain, register, or modality of the input. Human language processing is also word-byword incremental. There is strong evidence that a new word is integrated as soon as it is available</context>
</contexts>
<marker>Staub, Clifton, 2006</marker>
<rawString>Staub, Adrian and Charles Clifton. 2006. Syntactic prediction in language comprehension: Evidence from either ... or. Journal of Experimental Psychology: Learning, Memory, and Cognition 32:425–436.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew J Stewart</author>
<author>Martin J Pickering</author>
<author>Anthony J Sanford</author>
</authors>
<title>The time course of the influence of implicit causality information: Focusing versus integration accounts.</title>
<date>2000</date>
<journal>Journal of Memory and Language</journal>
<volume>42</volume>
<issue>3</issue>
<contexts>
<context position="9240" citStr="Stewart et al. (2000)" startWordPosition="1427" endWordPosition="1430"> form of incre2We will not distinguish between model and linking theory, i.e., the set of assumptions that links model quantities to behavioral data (e.g., more probably structures are easier to process). It is conceivable, for instance, that a stack-based model is combined with a linking theory based on surprisal. 61 Factor Evidence Word senses Roland and Jurafsky (2002) Selectional re- Garnsey et al. (1997); Pickering and strictions Traxler(1998) Thematic roles McRae et al. (1998); Pickering et al. (2000) Discourse ref- Altmann and Steedman (1988); Groderence ner and Gibson (2005) Discourse Stewart et al. (2000); Kehler et al. coherence (2008) Table 2: Semantic factors in human language processing mentality by building fully connected trees. Memory costs are modeled directly as a distance-based penalty that is incurred when a prediction has to be verified later in the sentence. However, the current implementation of the prediction model is neither robust and efficient nor offers broad coverage. Recently, a stack-based model (Stack) has been proposed that imposes explicit, cognitively motivated memory constraints on the parser, in effect limiting the stack size available to the parser (Schuler et al.,</context>
</contexts>
<marker>Stewart, Pickering, Sanford, 2000</marker>
<rawString>Stewart, Andrew J., Martin J. Pickering, and Anthony J. Sanford. 2000. The time course of the influence of implicit causality information: Focusing versus integration accounts. Journal of Memory and Language 42(3):423–443.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Sturt</author>
<author>Vincenzo Lombardo</author>
</authors>
<title>Processing coordinated structures: Incrementality and connectedness.</title>
<date>2005</date>
<journal>Cognitive Science</journal>
<volume>29</volume>
<issue>2</issue>
<contexts>
<context position="4474" citStr="Sturt and Lombardo (2005)" startWordPosition="663" endWordPosition="666">Furthermore, established results regarding the interface between language processing and non-linguistic cognition (e.g., the sensorimotor system) should ultimately be accounted for in a fully comprehensive model. 60 Proceedings of the ACL 2010 Conference Short Papers, pages 60–67, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Property Evidence Rank Model Stack Surp Pred Efficiency and robustness Ferreira et al. (2001); Sanford and Sturt (2002) − − − + Broad coverage Crocker and Brants (2000) + + − + Incrementality and connectedness Tanenhaus et al. (1995); Sturt and Lombardo (2005) + + + + Prediction Kamide et al. (2003); Staub and Clifton (2006) − f + − Memory cost Gibson (1998); Vasishth and Lewis (2006) − − + + Table 1: Key properties of human language processing and their instantiation in various models of sentence processing (see Section 2 for details) dence that shallow processing strategies are used to achieve this. The processor also achieves broad coverage: it can deal with a wide variety of syntactic constructions, and is not restricted by the domain, register, or modality of the input. Human language processing is also word-byword incremental. There is strong</context>
</contexts>
<marker>Sturt, Lombardo, 2005</marker>
<rawString>Sturt, Patrick and Vincenzo Lombardo. 2005. Processing coordinated structures: Incrementality and connectedness. Cognitive Science 29(2):291–305.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael K Tanenhaus</author>
<author>Michael J SpiveyKnowlton</author>
<author>Kathleen M Eberhard</author>
<author>Julie C Sedivy</author>
</authors>
<title>Integration of visual and linguistic information in spoken language comprehension.</title>
<date>1995</date>
<journal>Science</journal>
<pages>268--1632</pages>
<contexts>
<context position="4447" citStr="Tanenhaus et al. (1995)" startWordPosition="659" endWordPosition="662"> of language processing. Furthermore, established results regarding the interface between language processing and non-linguistic cognition (e.g., the sensorimotor system) should ultimately be accounted for in a fully comprehensive model. 60 Proceedings of the ACL 2010 Conference Short Papers, pages 60–67, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Property Evidence Rank Model Stack Surp Pred Efficiency and robustness Ferreira et al. (2001); Sanford and Sturt (2002) − − − + Broad coverage Crocker and Brants (2000) + + − + Incrementality and connectedness Tanenhaus et al. (1995); Sturt and Lombardo (2005) + + + + Prediction Kamide et al. (2003); Staub and Clifton (2006) − f + − Memory cost Gibson (1998); Vasishth and Lewis (2006) − − + + Table 1: Key properties of human language processing and their instantiation in various models of sentence processing (see Section 2 for details) dence that shallow processing strategies are used to achieve this. The processor also achieves broad coverage: it can deal with a wide variety of syntactic constructions, and is not restricted by the domain, register, or modality of the input. Human language processing is also word-byword i</context>
</contexts>
<marker>Tanenhaus, SpiveyKnowlton, Eberhard, Sedivy, 1995</marker>
<rawString>Tanenhaus, Michael K., Michael J. SpiveyKnowlton, Kathleen M. Eberhard, and Julie C. Sedivy. 1995. Integration of visual and linguistic information in spoken language comprehension. Science 268:1632–1634.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shravan Vasishth</author>
<author>Richard L Lewis</author>
</authors>
<title>Argument-head distance and processing complexity: Explaining both locality and antilocality effects.</title>
<date>2006</date>
<journal>Language</journal>
<volume>82</volume>
<issue>4</issue>
<contexts>
<context position="4601" citStr="Vasishth and Lewis (2006)" startWordPosition="688" endWordPosition="691">nsorimotor system) should ultimately be accounted for in a fully comprehensive model. 60 Proceedings of the ACL 2010 Conference Short Papers, pages 60–67, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Property Evidence Rank Model Stack Surp Pred Efficiency and robustness Ferreira et al. (2001); Sanford and Sturt (2002) − − − + Broad coverage Crocker and Brants (2000) + + − + Incrementality and connectedness Tanenhaus et al. (1995); Sturt and Lombardo (2005) + + + + Prediction Kamide et al. (2003); Staub and Clifton (2006) − f + − Memory cost Gibson (1998); Vasishth and Lewis (2006) − − + + Table 1: Key properties of human language processing and their instantiation in various models of sentence processing (see Section 2 for details) dence that shallow processing strategies are used to achieve this. The processor also achieves broad coverage: it can deal with a wide variety of syntactic constructions, and is not restricted by the domain, register, or modality of the input. Human language processing is also word-byword incremental. There is strong evidence that a new word is integrated as soon as it is available into the representation of the sentence thus far. Readers an</context>
</contexts>
<marker>Vasishth, Lewis, 2006</marker>
<rawString>Vasishth, Shravan and Richard L. Lewis. 2006. Argument-head distance and processing complexity: Explaining both locality and antilocality effects. Language 82(4):767–794.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>