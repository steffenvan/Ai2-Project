<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000089">
<title confidence="0.9982705">
How Are Spelling Errors Generated and Corrected? A Study of Corrected
and Uncorrected Spelling Errors Using Keystroke Logs
</title>
<author confidence="0.996231">
Yukino Baba
</author>
<affiliation confidence="0.995443">
The University of Tokyo
</affiliation>
<email confidence="0.985759">
yukino.baba@gmail.com
</email>
<sectionHeader confidence="0.99724" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999743692307692">
This paper presents a comparative study of
spelling errors that are corrected as you type,
vs. those that remain uncorrected. First,
we generate naturally occurring online error
correction data by logging users’ keystrokes,
and by automatically deriving pre- and post-
correction strings from them. We then per-
form an analysis of this data against the errors
that remain in the final text as well as across
languages. Our analysis shows a clear distinc-
tion between the types of errors that are gen-
erated and those that remain uncorrected, as
well as across languages.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999941846153846">
When we type text using a keyboard, we generate
many spelling errors, both typographical (caused by
the keyboard layout and hand/finger movement) and
cognitive (caused by phonetic or orthographic sim-
ilarity) (Kukich, 1992). When the errors are caught
during typing, they are corrected on the fly, but un-
noticed errors will persist in the final text. Previ-
ous research on spelling correction has focused on
the latter type (which we call uncorrected errors),
presumably because the errors that are corrected on
the spot (referred to here as corrected errors) are
not recoded in the form of a text. However, study-
ing corrected errors is important for at least three
reasons. First, such data encapsulates the spelling
mistake and correction by the author, in contrast
to the case of uncorrected errors in which the in-
tended correction is typically assigned by a third
person (an annotator), or by an automatic method
(Whitelaw et al., 2009; Aramaki et al., 2010)1. Sec-
ondly, data on corrected errors will enable us to build
a spelling correction application that targets correc-
tion on the fly, which directly reduces the number of
keystrokes in typing. This is crucial for languages
that use transliteration-based text input methods,
such as Chinese and Japanese, where a spelling error
in the input Roman keystroke sequence will prevent
</bodyText>
<footnote confidence="0.890160666666667">
1Using web search query logs is one notable exception,
which only targets spelling errors in search queries (Gao et al.,
2010)
</footnote>
<figure confidence="0.7615095">
Hisami Suzuki
Microsoft Research
hisamis@microsoft.com
Keystroke
</figure>
<figureCaption confidence="0.999987">
Figure 1: Example of keystroke
</figureCaption>
<bodyText confidence="0.999939464285714">
the correct candidate words from appearing in the
list of candidates in their native scripts, thereby pre-
venting them from being entered altogether. Finally,
we can collect a large amount of spelling errors and
their corrections by logging keystrokes and extract-
ing the pre- and post-correction strings from them.
By learning the characteristics of corrected and un-
corrected errors, we can expect to use the data for
improving the correction of the errors that persisted
in the final text as well.
In this paper, we collect naturally occurring
spelling error data that are corrected by the users
online from keystroke logs, through the crowd-
sourcing infrastructure of Amazon’s Mechanical
Turk (MTurk). As detailed in Section 3, we dis-
play images to the worker of MTurk, and collect
the descriptions of these images, while logging their
keystrokes including the usage of backspace keys,
via a crowd-based text input service. We collected
logs for two typologically different languages, En-
glish and Japanese. An example of a log along
with the extracted pre- and post-correction strings
is shown in Figure 1. We then performed two com-
parative analyses: corrected vs. uncorrected errors
in English (Section 4.3), and English vs. Japanese
corrected errors (Section 4.4). Finally, we remark
on an additional cause of spelling errors observed in
all the data we analyzed (Section 4.5).
</bodyText>
<sectionHeader confidence="0.99989" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999731">
Studies on spelling error generation mechanisms are
found in earlier work such as Cooper (1983). In
particular, Grudin (1983) offers a detailed study of
the errors generated in the transcription typing sce-
nario, where the subjects are asked to transcribe a
text without correcting the errors they make. In a
more recent work, Aramaki et al. (2010) automati-
cally extracted error-correction candidate pairs from
Twitter data based on the assumption that these pairs
</bodyText>
<equation confidence="0.512687333333333">
m - i - s - s - s - p - BACKSPACE - BACKSPACE - p - e - l - l
Pre-correction strings Post-correction strings
missspell misspell
</equation>
<page confidence="0.987301">
373
</page>
<note confidence="0.681821">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 373–377,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999972173913044">
fall within a small edit distance, and that the errors
are not in the dictionary and substantially less fre-
quent than the correctly spelled counterpart. They
then studied the effect of five factors that cause er-
rors by building a classifier that uses the features as-
sociated with these classes and running ablation ex-
periments. They claim that finger movements cause
the spelling errors to be generated, but the uncor-
rected errors are characterized by visual factors such
as the visual similarity of confused letters. Their ex-
periments however target only the persisted errors,
and their claim is not based on the comparison of
generated and persisted errors.
Outside of English, Zheng et al. (2011) analyzed
the keystroke log of a commercial text input system
for Simplified Chinese, and compared the error pat-
terns in Chinese with those in English. Their use of
the keystroke log is different from ours in that they
did not directly log the input in pinyin (Romanized
Chinese by which native characters are input), but
the input pinyin sequences are recovered from the
Chinese words in the native script (hanzi) after the
character conversion has already applied.
</bodyText>
<sectionHeader confidence="0.98959" genericHeader="method">
3 Keystroke Data Collection
</sectionHeader>
<bodyText confidence="0.9996535">
Amazon’s Mechanical Turk (MTurk) is a web ser-
vice that enables crowdsourcing of tasks that are dif-
ficult for computers to solve, and has become an im-
portant infrastructure for gathering data and annota-
tion for NLP research in recent years (Snow et al.
2008). To the extent of our knowledge, our work
is the first to use this infrastructure to gather user
keystroke data.
</bodyText>
<subsectionHeader confidence="0.99958">
3.1 Task design
</subsectionHeader>
<bodyText confidence="0.999986">
In order to collect naturally occurring keystrokes,
we have designed two types of tasks, both of which
consist of writing something about images. In one
task type, we asked the workers to write a short
description of images (image description task); in
the other, the workers were presented with im-
ages of a person or an animal, and were asked to
guess and type what she/he was saying (let-them-
talk task). Using images as triggers for typing keeps
the underlying motivation of keystroke collection
hidden from the workers, simultaneously allowing
language-independent data collection. For the im-
age triggers, we used photos from the Flickr’s Your
Best Shot 2009/2010 groups. Examples of the tasks
and collected text are given in Figure 2.
</bodyText>
<figure confidence="0.605621">
Image Description Task Let-them-talk Task
</figure>
<figureCaption confidence="0.992589666666667">
Figure 2: Examples of tasks and collected text (Translated text:
“A flock of penguines are marching in the snow.” and “Mummy,
my feet can’t touch the bottom.”)
</figureCaption>
<subsectionHeader confidence="0.999338">
3.2 Task interface
</subsectionHeader>
<bodyText confidence="0.999993866666667">
For logging the keystrokes including the use of
backspaces, we designed an original interface for the
text boxes in the MTurk task. In order to simplify
the interpretation of the log, we disabled the cursor
movements and text highlighting via a mouse or the
arrow keys in the text box; the workers are therefore
forced to use the backspace key to make corrections.
In Japanese, many commercially available text in-
put methods (IMEs) have an auto-complete feature
which prevents us from collecting all keystrokes for
inputting a word. We therefore used an in-house
IME that has disabled this feature to collect logs.
This IME is hosted as a web service, and keystroke
logs are also collected through the service. For En-
glish, we used the service for log collection only.
</bodyText>
<sectionHeader confidence="0.984449" genericHeader="method">
4 Keystroke Log Analysis
</sectionHeader>
<subsectionHeader confidence="0.98467">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.998670222222222">
We used both keystroke-derived and previously
available error data for our analysis.
Keystroke-derived error pairs for English and
Japanese (en keystroke, ja keystroke): from the
raw keystroke logs collected using the method de-
scribed in Section 3, we extracted only those words
that included a use of the backspace key. We then
recovered the strings before and after correction by
the following steps (Cf. Figure 1):
</bodyText>
<listItem confidence="0.935567833333333">
• To recover the post-correction string, we
deleted the same number of characters preced-
ing a sequence of backspace keys.
• To recover the pre-correction string, we com-
pared the prefix of the backspace usage
(misssp in Figure 1) with the substrings
</listItem>
<bodyText confidence="0.990287222222222">
after error correction (miss, missp, ,
misspell), and considered that the prefix
was spell-corrected into the substring which is
the longest and with the smallest edit distance
En “A flock of penguins waddle towards
two trees over snow covered ground.”
”oh mummy. please dont take a clip. i
am naked and i feel shy. at least give
me a towel.”
</bodyText>
<figure confidence="0.819376333333333">
En
「ペンギンの群れが雪の中を行進しています。」 Ja 「お母さん、足つかへん。」
Ja
</figure>
<page confidence="0.993428">
374
</page>
<bodyText confidence="0.999346357142857">
(in this case, misssp is an error for missp,
so the pre-correction string is missspell).
We then lower-cased the pairs and extracted only
those within the edit distance of 2. The resulting data
which we used for our analysis consists of 44,104
pairs in English and 4,808 pairs in Japanese2.
Common English errors (en common): follow-
ing previous work (Zheng et al., 2011), we ob-
tained word pairs from Wikipedia3 and SpellGood4.
We lower-cased the entries from these sources, re-
moved the duplicates and the pairs that included
non-Roman alphabet characters, and extracted only
those pairs within the edit distance of 2. This left us
with 10,608 pairs.
</bodyText>
<subsectionHeader confidence="0.991127">
4.2 Factors that affect errors
</subsectionHeader>
<bodyText confidence="0.9934213">
Spelling errors have traditionally been classified into
four descriptive types: Deletion, Insertion, Substitu-
tion and Transposition (Damerau, 1964). For each
of these types, we investigated the potential causes
of error generation and correction, following previ-
ous work (Aramaki et al., 2010; Zheng et al., 2011).
Physical factors: (1) motor control of hands and fin-
gers; (2) distance between the keys; Visual factors:
(3) visual similarity of characters; (4) position in
a word; (5) same character repetition; Phonologi-
cal factors: (6) phonological similarity of charac-
ters/words.
In what follows, our discussion is based on the
frequency ratio of particular error types, where the
frequency ratio refers to the number of cases in
spelling errors divided by the total number of cases
in all data. For example, the frequency ratio of con-
sonant deletion is calculated by dividing the number
of missing consonants in errors by the total number
of consonants.
</bodyText>
<subsectionHeader confidence="0.996933">
4.3 Corrected vs. uncorrected errors in English
</subsectionHeader>
<bodyText confidence="0.998305">
In this subsection, we compare corrected and uncor-
rected errors of English, trying to uncover what fac-
tors facilitate the error correction.
Error types (Figure 3) Errors in en keystroke are
dominated by Substitution, while Deletion errors are
the most common in en common, indicating that
</bodyText>
<footnote confidence="0.998437">
2The data is available for research purposes under http:
//research.microsoft.com/research/downloads/
details/4eb8d4a0-9c4e-4891-8846-7437d9dbd869/
details.aspx
3http://en.wikipedia.org/wiki/Wikipedia:
Lists of common misspellings/For machines
4http://www.spellgood.net/sitemap.html
</footnote>
<figureCaption confidence="0.999898">
Figure 5: Positions of errors within words
</figureCaption>
<bodyText confidence="0.997469">
Substitution mistakes are easy to catch, while Dele-
tion mistakes tend to escape our attention. Zheng
et al. (2011) reports that their pinyin correction er-
rors are dominated by Deletion, which suggests that
their log does in fact reflect the characteristics of cor-
rected errors.
Position of error within a word (Figure 5) In
en keystroke, Deletion errors at the word-initial po-
sition are the most common, while Insertion and
Substitution errors tend to occur both at the be-
ginning and the end of a word. In contrast, in
en common, all error types are more prone to oc-
cur word-medially. This means that errors at word
edges are corrected more often than the word-
internal errors, which can be attributed to cognitive
effect known as the bathtub effect (Aitchison, 1994),
which states that we memorize words at the periph-
ery most effectively in English.
</bodyText>
<subsectionHeader confidence="0.845449">
Effect of character repetition (Figure 6) Dele-
</subsectionHeader>
<bodyText confidence="0.707133272727273">
tion errors where characters are repeated, as in
tomorow--*tomorrow, is observed significantly
more frequently than in a non-repeating context in
en common, but no such difference is observed in
en keystroke, showing that visually conspicuous er-
rors tend to be corrected.
Visual similarity in Substitution errors (Figure
4) We computed the visual similarity of characters
by
2x(the area of overlap between character A and B)
(area of character A+area of character B) follow-
</bodyText>
<figure confidence="0.997298947368421">
Substitution
Transposition
Substition
0.30 Similarity 0.90
0.30 Similarity 0.90
0.30 Similarity 0.90
en_keystroke ja_keystroke
Freq.
0.000
en—common
en—keystroke
Freq.
0000
ja—keystroke
Freq.
0.000
0 20 40 60 80 100
en_common
Ratio (%)
</figure>
<figureCaption confidence="0.945357333333333">
Figure 3: Ratios of error types
Figure 4: Visual similarities
of characters in substitution
</figureCaption>
<figure confidence="0.89456225">
Deletion errors Insertion
0 20 40 60 80 100
Density
0 20 40 60 80 100
Density
0−base position / (word length−1) (%)
0−base position / (word length−1) (%)
Substitution
Density
Transposition
0 20 40 60 80 100 0 20 40 60 80 100
0−base position / (word length−1) (%) 0−base position / (word length−1) (%)
Density
Deletion
Insertion
en_common
en_keystroke ja_keystroke
375
Substitution
Appeared Before Not Appeared Before To Appear Not to Appear
Freq. / max(Freq.)
0.0 0.4 0.8
Substituted Character
en-keystroke ja-keystroke
en-common
Not Repeated / Repeated
en-common
en-keystroke ja-keystroke
</figure>
<figureCaption confidence="0.7033245">
Figure 6: Effect of character
repetition in Deletion
</figureCaption>
<figure confidence="0.6671905">
Insertion
Diff=2 / Diff=1
en-common
en-keystroke ja-keystroke
</figure>
<figureCaption confidence="0.7221355">
Figure 7: Difference of posi-
tions within words in Trans-
</figureCaption>
<figure confidence="0.849578470588235">
position
Substitution
Transposition
Deletion
Ratio of Freq.
0.0 0.4 0.8
Ratio of Freq.
0.0 0.4 0.8
Freq./max(Freq.)
0.0 0.4 0.8
Ratio of Freq.
0.0 0.4 0.8
Vowel / Consonant
C−&gt;C C−&gt;V
V−&gt;C V−&gt;V
Inserted Character Substituted Character −&gt; Correct Character
en-common en-keystroke ja-keystroke
</figure>
<figureCaption confidence="0.999676">
Figure 8: Consonants/vowels in Insertion and Substitution
</figureCaption>
<bodyText confidence="0.931968961538462">
ing Aramaki et al. (2010)5. Figure 4 shows that in
en common, Substitution errors of visually similar
characters (e.g., yoqa→yoga) are in fact very
common, while in en keystroke, no such tendency
is observed.
Phonological similarity in Substitution errors
(Figure 8) In en keystroke, there is no notable
difference in consonant-to-consonant (C→C) and
vowel-to-vowel (V→V) errors, but in en common,
V→V errors are overwhelmingly more com-
mon, suggesting that C→C can easily be no-
ticed (e.g., eazy→easy) while V→V errors (e.g.,
visable→visible) are not. This tendency is
consistent with the previous work on the cognitive
distinction between consonants and vowels in En-
glish: consonants carry more lexical information
than vowels (Nespor et al., 2003), a claim also
supported by distributional evidence (Tanaka-Ishii,
2008). It may also be attributed to the fact that En-
glish vowel quality is not always reflected by the on-
thography in the straightforward maner.
Summarizing, we have observed both visual and
phonological factors affect the correction of errors.
Aramaki et al. (2010)’s experiments did not show
that C/V distinction affect the errors, while our data
shows that it does in the correction of errors.
</bodyText>
<subsectionHeader confidence="0.992802">
4.4 Errors in English vs. Japanese
</subsectionHeader>
<bodyText confidence="0.969985571428571">
From Figure 3, we can see that the general error
pattern is very similar between en keystroke and
ja keystroke. Looking into the details, we discov-
ered some characteristic errors in Japanese, which
are phonologically and orthographically motivated.
Syllable-based transposition errors (Figure 7)
When comparing the transposition errors by their
</bodyText>
<footnote confidence="0.9947815">
5We calculated the area using the Courier New font which
we used in our task interface.
</footnote>
<figureCaption confidence="0.999078">
Figure 9: Look-ahead and Look-behind in Substitution
</figureCaption>
<bodyText confidence="0.997099476190476">
distance, 1 being a transposition of adjacent char-
acters and 2 a transposition skipping a character, the
instances in en keystroke are mostly of distance of
1, while in ja keystroke, the distance of 2 also occurs
commonly (e.g., kotoro→tokoro). This is inter-
esting, because the Japanese writing system called
kana is a syllabary system, and our data suggests that
users may be typing a kana character (typically CV)
as a unit. Furthermore, 73% of these errors share
the vowel of the transposed syllables, which may be
serving as a strong condition for this type of error.
Errors in consonants/vowels (Figure 8) Errors
in ja keystroke are characterized by a smaller ra-
tio of insertion errors of vowels relative to conso-
nants, and by a relatively smaller ratio of V→V sub-
stitution errors. Both point to the relative robust-
ness of inputting vowels as opposed to consonants
in Japanese. Unlike English, Japanese only has five
vowels whose pronunciations are transparently car-
ried by the orthography; they are therefore expected
to be less prone to cognitive errors.
</bodyText>
<subsectionHeader confidence="0.994222">
4.5 Look-ahead and look-behind errors
</subsectionHeader>
<bodyText confidence="0.997600777777778">
In Substitution errors for all data we analyzed, sub-
stituting for the character that appeared before, or
are to appear in the word was common (Figure
9). In particular, in en keystroke and ja keystroke,
look-ahead errors are much more common than non-
look-ahead errors. Grudin (1983) reports cases
of permutation (e.g., gib→big) but our data in-
cludes non-permutation look-ahead errors such as
puclic→public and otigaga→otibaga.
</bodyText>
<sectionHeader confidence="0.999579" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999766833333333">
We have presented our collection methodology and
analysis of error correction logs across error types
(corrected vs. uncorrected) and languages (English
and Japanese). Our next step is to utilize the col-
lected data and analysis results to build online and
offline spelling correction models.
</bodyText>
<sectionHeader confidence="0.999332" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99971975">
This work was conducted during the internship of
the first author at Microsoft Research. We are grate-
ful to the colleagues for their help and feedback in
conducting this research.
</bodyText>
<page confidence="0.998614">
376
</page>
<sectionHeader confidence="0.998329" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999176512820513">
Aitchison, J. 1994. Words in the Mind. Blackwell.
Aramaki, E., R. Uno and M. Oka. 2010. TYPO Writer:
tlUe0)��6,..f7tRUAx60)b,? (TYPO
Writer: how do humans make typos?). In Proceedings
of the 16th Annual Meeting of the Natural Language
Society (in Japanese).
Cooper, W. E. (ed.) 1983. Cognitive Aspects of Skilled
Typewriting. Springer-Verlag.
Damerau, F. 1964. A technique for computer detection
and correction of spelling errors. Communications of
the ACM 7(3): 659-664.
Gao, J., X. Li, D. Micol, C. Quirk and X. Sun. 2010.
A large scale ranker-based system for search query
spelling correction. In Proceedings of COLING.
Grudin, J. T. 1983. Error patterns in novice and skilled
transcription typing. In Cooper, W.E. (ed.), Cognitive
Aspects of Skilled Typewriting. Springer-Verlag.
Kukich, K. 1992. Techniques for automatically correct-
ing words in text. In ACM Computing Surveys, 24(4).
Nespor, M., M. Pe˜na, and J. Mehler. 2003. On the differ-
ent roles of vowels and consonants in speech process-
ing and language acquisition. Lingue e Linguaggio,
pp. 221―247.
Snow, R., B. O’Connor, D. Jurafsky, and A. Ng. 2008.
Cheap and fast – but is it good?: evaluating non-expert
annotations for natural language tasks. In Proceedings
of EMNLP.
Tanaka-Ishii, K. 2008. a6,..VIT(E`-61 r03 20)Yl l(E
(On the uneven distribution of information in words).
In Proceedings of the 14th Annual Meeting of the Nat-
ural Language Society (in Japanese).
Whitelaw, Casey, Ben Hutchinson, Grace Y. Chung, and
Gerard Ellis. 2009. Using the web for language in-
dependent spellchecking and autocorrection. In Pro-
ceedings of ACL.
Zheng, Y., L. Xie, Z. Liu, M. Sun. Y. Zhang and L. Ru
2011. Why press backspace? Understanding user in-
put behaviors in Chinese pinyin input method. In Pro-
ceedings of ACL
</reference>
<page confidence="0.998399">
377
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.977494">
<title confidence="0.998567">How Are Spelling Errors Generated and Corrected? A Study of Corrected and Uncorrected Spelling Errors Using Keystroke Logs</title>
<author confidence="0.999812">Yukino Baba</author>
<affiliation confidence="0.999741">The University of Tokyo</affiliation>
<email confidence="0.999678">yukino.baba@gmail.com</email>
<abstract confidence="0.998123428571428">This paper presents a comparative study of spelling errors that are corrected as you type, vs. those that remain uncorrected. First, we generate naturally occurring online error correction data by logging users’ keystrokes, and by automatically deriving preand postcorrection strings from them. We then perform an analysis of this data against the errors that remain in the final text as well as across languages. Our analysis shows a clear distinction between the types of errors that are generated and those that remain uncorrected, as well as across languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Aitchison</author>
</authors>
<title>Words in the Mind.</title>
<date>1994</date>
<publisher>Blackwell.</publisher>
<contexts>
<context position="11987" citStr="Aitchison, 1994" startWordPosition="1922" endWordPosition="1923">n errors are dominated by Deletion, which suggests that their log does in fact reflect the characteristics of corrected errors. Position of error within a word (Figure 5) In en keystroke, Deletion errors at the word-initial position are the most common, while Insertion and Substitution errors tend to occur both at the beginning and the end of a word. In contrast, in en common, all error types are more prone to occur word-medially. This means that errors at word edges are corrected more often than the wordinternal errors, which can be attributed to cognitive effect known as the bathtub effect (Aitchison, 1994), which states that we memorize words at the periphery most effectively in English. Effect of character repetition (Figure 6) Deletion errors where characters are repeated, as in tomorow--*tomorrow, is observed significantly more frequently than in a non-repeating context in en common, but no such difference is observed in en keystroke, showing that visually conspicuous errors tend to be corrected. Visual similarity in Substitution errors (Figure 4) We computed the visual similarity of characters by 2x(the area of overlap between character A and B) (area of character A+area of character B) fol</context>
</contexts>
<marker>Aitchison, 1994</marker>
<rawString>Aitchison, J. 1994. Words in the Mind. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Aramaki</author>
<author>R Uno</author>
<author>M Oka</author>
</authors>
<title>TYPO Writer: tlUe0)��6,..f7tRUAx60)b,? (TYPO Writer: how do humans make typos?).</title>
<date>2010</date>
<booktitle>In Proceedings of the 16th Annual Meeting of the Natural Language Society (in Japanese).</booktitle>
<contexts>
<context position="1731" citStr="Aramaki et al., 2010" startWordPosition="275" endWordPosition="278">inal text. Previous research on spelling correction has focused on the latter type (which we call uncorrected errors), presumably because the errors that are corrected on the spot (referred to here as corrected errors) are not recoded in the form of a text. However, studying corrected errors is important for at least three reasons. First, such data encapsulates the spelling mistake and correction by the author, in contrast to the case of uncorrected errors in which the intended correction is typically assigned by a third person (an annotator), or by an automatic method (Whitelaw et al., 2009; Aramaki et al., 2010)1. Secondly, data on corrected errors will enable us to build a spelling correction application that targets correction on the fly, which directly reduces the number of keystrokes in typing. This is crucial for languages that use transliteration-based text input methods, such as Chinese and Japanese, where a spelling error in the input Roman keystroke sequence will prevent 1Using web search query logs is one notable exception, which only targets spelling errors in search queries (Gao et al., 2010) Hisami Suzuki Microsoft Research hisamis@microsoft.com Keystroke Figure 1: Example of keystroke t</context>
<context position="4072" citStr="Aramaki et al. (2010)" startWordPosition="646" endWordPosition="649">med two comparative analyses: corrected vs. uncorrected errors in English (Section 4.3), and English vs. Japanese corrected errors (Section 4.4). Finally, we remark on an additional cause of spelling errors observed in all the data we analyzed (Section 4.5). 2 Related Work Studies on spelling error generation mechanisms are found in earlier work such as Cooper (1983). In particular, Grudin (1983) offers a detailed study of the errors generated in the transcription typing scenario, where the subjects are asked to transcribe a text without correcting the errors they make. In a more recent work, Aramaki et al. (2010) automatically extracted error-correction candidate pairs from Twitter data based on the assumption that these pairs m - i - s - s - s - p - BACKSPACE - BACKSPACE - p - e - l - l Pre-correction strings Post-correction strings missspell misspell 373 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 373–377, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics fall within a small edit distance, and that the errors are not in the dictionary and substantially less frequent than the correctly spelled counterpart. They</context>
<context position="9892" citStr="Aramaki et al., 2010" startWordPosition="1602" endWordPosition="1605">eng et al., 2011), we obtained word pairs from Wikipedia3 and SpellGood4. We lower-cased the entries from these sources, removed the duplicates and the pairs that included non-Roman alphabet characters, and extracted only those pairs within the edit distance of 2. This left us with 10,608 pairs. 4.2 Factors that affect errors Spelling errors have traditionally been classified into four descriptive types: Deletion, Insertion, Substitution and Transposition (Damerau, 1964). For each of these types, we investigated the potential causes of error generation and correction, following previous work (Aramaki et al., 2010; Zheng et al., 2011). Physical factors: (1) motor control of hands and fingers; (2) distance between the keys; Visual factors: (3) visual similarity of characters; (4) position in a word; (5) same character repetition; Phonological factors: (6) phonological similarity of characters/words. In what follows, our discussion is based on the frequency ratio of particular error types, where the frequency ratio refers to the number of cases in spelling errors divided by the total number of cases in all data. For example, the frequency ratio of consonant deletion is calculated by dividing the number o</context>
<context position="14052" citStr="Aramaki et al. (2010)" startWordPosition="2232" endWordPosition="2235">stroke en-common Not Repeated / Repeated en-common en-keystroke ja-keystroke Figure 6: Effect of character repetition in Deletion Insertion Diff=2 / Diff=1 en-common en-keystroke ja-keystroke Figure 7: Difference of positions within words in Transposition Substitution Transposition Deletion Ratio of Freq. 0.0 0.4 0.8 Ratio of Freq. 0.0 0.4 0.8 Freq./max(Freq.) 0.0 0.4 0.8 Ratio of Freq. 0.0 0.4 0.8 Vowel / Consonant C−&gt;C C−&gt;V V−&gt;C V−&gt;V Inserted Character Substituted Character −&gt; Correct Character en-common en-keystroke ja-keystroke Figure 8: Consonants/vowels in Insertion and Substitution ing Aramaki et al. (2010)5. Figure 4 shows that in en common, Substitution errors of visually similar characters (e.g., yoqa→yoga) are in fact very common, while in en keystroke, no such tendency is observed. Phonological similarity in Substitution errors (Figure 8) In en keystroke, there is no notable difference in consonant-to-consonant (C→C) and vowel-to-vowel (V→V) errors, but in en common, V→V errors are overwhelmingly more common, suggesting that C→C can easily be noticed (e.g., eazy→easy) while V→V errors (e.g., visable→visible) are not. This tendency is consistent with the previous work on the cognitive distin</context>
</contexts>
<marker>Aramaki, Uno, Oka, 2010</marker>
<rawString>Aramaki, E., R. Uno and M. Oka. 2010. TYPO Writer: tlUe0)��6,..f7tRUAx60)b,? (TYPO Writer: how do humans make typos?). In Proceedings of the 16th Annual Meeting of the Natural Language Society (in Japanese).</rawString>
</citation>
<citation valid="true">
<title>Cognitive Aspects of Skilled Typewriting.</title>
<date>1983</date>
<editor>Cooper, W. E. (ed.)</editor>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="3820" citStr="(1983)" startWordPosition="607" endWordPosition="607">, via a crowd-based text input service. We collected logs for two typologically different languages, English and Japanese. An example of a log along with the extracted pre- and post-correction strings is shown in Figure 1. We then performed two comparative analyses: corrected vs. uncorrected errors in English (Section 4.3), and English vs. Japanese corrected errors (Section 4.4). Finally, we remark on an additional cause of spelling errors observed in all the data we analyzed (Section 4.5). 2 Related Work Studies on spelling error generation mechanisms are found in earlier work such as Cooper (1983). In particular, Grudin (1983) offers a detailed study of the errors generated in the transcription typing scenario, where the subjects are asked to transcribe a text without correcting the errors they make. In a more recent work, Aramaki et al. (2010) automatically extracted error-correction candidate pairs from Twitter data based on the assumption that these pairs m - i - s - s - s - p - BACKSPACE - BACKSPACE - p - e - l - l Pre-correction strings Post-correction strings missspell misspell 373 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 373–</context>
<context position="17142" citStr="(1983)" startWordPosition="2725" endWordPosition="2725">on errors. Both point to the relative robustness of inputting vowels as opposed to consonants in Japanese. Unlike English, Japanese only has five vowels whose pronunciations are transparently carried by the orthography; they are therefore expected to be less prone to cognitive errors. 4.5 Look-ahead and look-behind errors In Substitution errors for all data we analyzed, substituting for the character that appeared before, or are to appear in the word was common (Figure 9). In particular, in en keystroke and ja keystroke, look-ahead errors are much more common than nonlook-ahead errors. Grudin (1983) reports cases of permutation (e.g., gib→big) but our data includes non-permutation look-ahead errors such as puclic→public and otigaga→otibaga. 5 Conclusion We have presented our collection methodology and analysis of error correction logs across error types (corrected vs. uncorrected) and languages (English and Japanese). Our next step is to utilize the collected data and analysis results to build online and offline spelling correction models. Acknowledgments This work was conducted during the internship of the first author at Microsoft Research. We are grateful to the colleagues for their h</context>
</contexts>
<marker>1983</marker>
<rawString>Cooper, W. E. (ed.) 1983. Cognitive Aspects of Skilled Typewriting. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Damerau</author>
</authors>
<title>A technique for computer detection and correction of spelling errors.</title>
<date>1964</date>
<journal>Communications of the ACM</journal>
<volume>7</volume>
<issue>3</issue>
<pages>659--664</pages>
<contexts>
<context position="9747" citStr="Damerau, 1964" startWordPosition="1581" endWordPosition="1582">r analysis consists of 44,104 pairs in English and 4,808 pairs in Japanese2. Common English errors (en common): following previous work (Zheng et al., 2011), we obtained word pairs from Wikipedia3 and SpellGood4. We lower-cased the entries from these sources, removed the duplicates and the pairs that included non-Roman alphabet characters, and extracted only those pairs within the edit distance of 2. This left us with 10,608 pairs. 4.2 Factors that affect errors Spelling errors have traditionally been classified into four descriptive types: Deletion, Insertion, Substitution and Transposition (Damerau, 1964). For each of these types, we investigated the potential causes of error generation and correction, following previous work (Aramaki et al., 2010; Zheng et al., 2011). Physical factors: (1) motor control of hands and fingers; (2) distance between the keys; Visual factors: (3) visual similarity of characters; (4) position in a word; (5) same character repetition; Phonological factors: (6) phonological similarity of characters/words. In what follows, our discussion is based on the frequency ratio of particular error types, where the frequency ratio refers to the number of cases in spelling error</context>
</contexts>
<marker>Damerau, 1964</marker>
<rawString>Damerau, F. 1964. A technique for computer detection and correction of spelling errors. Communications of the ACM 7(3): 659-664.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gao</author>
<author>X Li</author>
<author>D Micol</author>
<author>C Quirk</author>
<author>X Sun</author>
</authors>
<title>A large scale ranker-based system for search query spelling correction.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="2233" citStr="Gao et al., 2010" startWordPosition="355" endWordPosition="358"> assigned by a third person (an annotator), or by an automatic method (Whitelaw et al., 2009; Aramaki et al., 2010)1. Secondly, data on corrected errors will enable us to build a spelling correction application that targets correction on the fly, which directly reduces the number of keystrokes in typing. This is crucial for languages that use transliteration-based text input methods, such as Chinese and Japanese, where a spelling error in the input Roman keystroke sequence will prevent 1Using web search query logs is one notable exception, which only targets spelling errors in search queries (Gao et al., 2010) Hisami Suzuki Microsoft Research hisamis@microsoft.com Keystroke Figure 1: Example of keystroke the correct candidate words from appearing in the list of candidates in their native scripts, thereby preventing them from being entered altogether. Finally, we can collect a large amount of spelling errors and their corrections by logging keystrokes and extracting the pre- and post-correction strings from them. By learning the characteristics of corrected and uncorrected errors, we can expect to use the data for improving the correction of the errors that persisted in the final text as well. In th</context>
</contexts>
<marker>Gao, Li, Micol, Quirk, Sun, 2010</marker>
<rawString>Gao, J., X. Li, D. Micol, C. Quirk and X. Sun. 2010. A large scale ranker-based system for search query spelling correction. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J T Grudin</author>
</authors>
<title>Error patterns in novice and skilled transcription typing.</title>
<date>1983</date>
<booktitle>Cognitive Aspects of Skilled Typewriting.</booktitle>
<editor>In Cooper, W.E. (ed.),</editor>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="3850" citStr="Grudin (1983)" startWordPosition="610" endWordPosition="611">t input service. We collected logs for two typologically different languages, English and Japanese. An example of a log along with the extracted pre- and post-correction strings is shown in Figure 1. We then performed two comparative analyses: corrected vs. uncorrected errors in English (Section 4.3), and English vs. Japanese corrected errors (Section 4.4). Finally, we remark on an additional cause of spelling errors observed in all the data we analyzed (Section 4.5). 2 Related Work Studies on spelling error generation mechanisms are found in earlier work such as Cooper (1983). In particular, Grudin (1983) offers a detailed study of the errors generated in the transcription typing scenario, where the subjects are asked to transcribe a text without correcting the errors they make. In a more recent work, Aramaki et al. (2010) automatically extracted error-correction candidate pairs from Twitter data based on the assumption that these pairs m - i - s - s - s - p - BACKSPACE - BACKSPACE - p - e - l - l Pre-correction strings Post-correction strings missspell misspell 373 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 373–377, Jeju, Republic of Korea, </context>
<context position="17142" citStr="Grudin (1983)" startWordPosition="2724" endWordPosition="2725">stitution errors. Both point to the relative robustness of inputting vowels as opposed to consonants in Japanese. Unlike English, Japanese only has five vowels whose pronunciations are transparently carried by the orthography; they are therefore expected to be less prone to cognitive errors. 4.5 Look-ahead and look-behind errors In Substitution errors for all data we analyzed, substituting for the character that appeared before, or are to appear in the word was common (Figure 9). In particular, in en keystroke and ja keystroke, look-ahead errors are much more common than nonlook-ahead errors. Grudin (1983) reports cases of permutation (e.g., gib→big) but our data includes non-permutation look-ahead errors such as puclic→public and otigaga→otibaga. 5 Conclusion We have presented our collection methodology and analysis of error correction logs across error types (corrected vs. uncorrected) and languages (English and Japanese). Our next step is to utilize the collected data and analysis results to build online and offline spelling correction models. Acknowledgments This work was conducted during the internship of the first author at Microsoft Research. We are grateful to the colleagues for their h</context>
</contexts>
<marker>Grudin, 1983</marker>
<rawString>Grudin, J. T. 1983. Error patterns in novice and skilled transcription typing. In Cooper, W.E. (ed.), Cognitive Aspects of Skilled Typewriting. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kukich</author>
</authors>
<title>Techniques for automatically correcting words in text.</title>
<date>1992</date>
<journal>In ACM Computing Surveys,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="993" citStr="Kukich, 1992" startWordPosition="152" endWordPosition="153">ata by logging users’ keystrokes, and by automatically deriving pre- and postcorrection strings from them. We then perform an analysis of this data against the errors that remain in the final text as well as across languages. Our analysis shows a clear distinction between the types of errors that are generated and those that remain uncorrected, as well as across languages. 1 Introduction When we type text using a keyboard, we generate many spelling errors, both typographical (caused by the keyboard layout and hand/finger movement) and cognitive (caused by phonetic or orthographic similarity) (Kukich, 1992). When the errors are caught during typing, they are corrected on the fly, but unnoticed errors will persist in the final text. Previous research on spelling correction has focused on the latter type (which we call uncorrected errors), presumably because the errors that are corrected on the spot (referred to here as corrected errors) are not recoded in the form of a text. However, studying corrected errors is important for at least three reasons. First, such data encapsulates the spelling mistake and correction by the author, in contrast to the case of uncorrected errors in which the intended </context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>Kukich, K. 1992. Techniques for automatically correcting words in text. In ACM Computing Surveys, 24(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nespor</author>
<author>M Pe˜na</author>
<author>J Mehler</author>
</authors>
<title>On the different roles of vowels and consonants in speech processing and language acquisition.</title>
<date>2003</date>
<booktitle>Lingue e Linguaggio,</booktitle>
<pages>221--247</pages>
<marker>Nespor, Pe˜na, Mehler, 2003</marker>
<rawString>Nespor, M., M. Pe˜na, and J. Mehler. 2003. On the different roles of vowels and consonants in speech processing and language acquisition. Lingue e Linguaggio, pp. 221―247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Snow</author>
<author>B O’Connor</author>
<author>D Jurafsky</author>
<author>A Ng</author>
</authors>
<title>Cheap and fast – but is it good?: evaluating non-expert annotations for natural language tasks.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<marker>Snow, O’Connor, Jurafsky, Ng, 2008</marker>
<rawString>Snow, R., B. O’Connor, D. Jurafsky, and A. Ng. 2008. Cheap and fast – but is it good?: evaluating non-expert annotations for natural language tasks. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Tanaka-Ishii</author>
</authors>
<title>a6,..VIT(E`-61 r03 20)Yl l(E (On the uneven distribution of information in words).</title>
<date>2008</date>
<booktitle>In Proceedings of the 14th Annual Meeting of the Natural Language Society (in Japanese).</booktitle>
<contexts>
<context position="14847" citStr="Tanaka-Ishii, 2008" startWordPosition="2352" endWordPosition="2353">served. Phonological similarity in Substitution errors (Figure 8) In en keystroke, there is no notable difference in consonant-to-consonant (C→C) and vowel-to-vowel (V→V) errors, but in en common, V→V errors are overwhelmingly more common, suggesting that C→C can easily be noticed (e.g., eazy→easy) while V→V errors (e.g., visable→visible) are not. This tendency is consistent with the previous work on the cognitive distinction between consonants and vowels in English: consonants carry more lexical information than vowels (Nespor et al., 2003), a claim also supported by distributional evidence (Tanaka-Ishii, 2008). It may also be attributed to the fact that English vowel quality is not always reflected by the onthography in the straightforward maner. Summarizing, we have observed both visual and phonological factors affect the correction of errors. Aramaki et al. (2010)’s experiments did not show that C/V distinction affect the errors, while our data shows that it does in the correction of errors. 4.4 Errors in English vs. Japanese From Figure 3, we can see that the general error pattern is very similar between en keystroke and ja keystroke. Looking into the details, we discovered some characteristic e</context>
</contexts>
<marker>Tanaka-Ishii, 2008</marker>
<rawString>Tanaka-Ishii, K. 2008. a6,..VIT(E`-61 r03 20)Yl l(E (On the uneven distribution of information in words). In Proceedings of the 14th Annual Meeting of the Natural Language Society (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Casey Whitelaw</author>
<author>Ben Hutchinson</author>
<author>Grace Y Chung</author>
<author>Gerard Ellis</author>
</authors>
<title>Using the web for language independent spellchecking and autocorrection.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1708" citStr="Whitelaw et al., 2009" startWordPosition="271" endWordPosition="274">s will persist in the final text. Previous research on spelling correction has focused on the latter type (which we call uncorrected errors), presumably because the errors that are corrected on the spot (referred to here as corrected errors) are not recoded in the form of a text. However, studying corrected errors is important for at least three reasons. First, such data encapsulates the spelling mistake and correction by the author, in contrast to the case of uncorrected errors in which the intended correction is typically assigned by a third person (an annotator), or by an automatic method (Whitelaw et al., 2009; Aramaki et al., 2010)1. Secondly, data on corrected errors will enable us to build a spelling correction application that targets correction on the fly, which directly reduces the number of keystrokes in typing. This is crucial for languages that use transliteration-based text input methods, such as Chinese and Japanese, where a spelling error in the input Roman keystroke sequence will prevent 1Using web search query logs is one notable exception, which only targets spelling errors in search queries (Gao et al., 2010) Hisami Suzuki Microsoft Research hisamis@microsoft.com Keystroke Figure 1:</context>
</contexts>
<marker>Whitelaw, Hutchinson, Chung, Ellis, 2009</marker>
<rawString>Whitelaw, Casey, Ben Hutchinson, Grace Y. Chung, and Gerard Ellis. 2009. Using the web for language independent spellchecking and autocorrection. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>L Ru</author>
</authors>
<title>Why press backspace? Understanding user input behaviors in Chinese pinyin input method.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL</booktitle>
<marker>Zhang, Ru, 2011</marker>
<rawString>Zheng, Y., L. Xie, Z. Liu, M. Sun. Y. Zhang and L. Ru 2011. Why press backspace? Understanding user input behaviors in Chinese pinyin input method. In Proceedings of ACL</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>