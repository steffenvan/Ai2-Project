<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001757">
<title confidence="0.9976405">
PageRanking WordNet Synsets:
An Application to Opinion Mining*
</title>
<author confidence="0.851013">
Andrea Esuli and Fabrizio Sebastiani
</author>
<affiliation confidence="0.689886">
Istituto di Scienza e Tecnologie dell’Informazione
</affiliation>
<address confidence="0.7773385">
Consiglio Nazionale delle Ricerche
Via Giuseppe Moruzzi, 1 – 56124 Pisa, Italy
</address>
<email confidence="0.998272">
{andrea.esuli,fabrizio.sebastiani}@isti.cnr.it
</email>
<sectionHeader confidence="0.996645" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999930875">
This paper presents an application of PageR-
ank, a random-walk model originally de-
vised for ranking Web search results, to
ranking WordNet synsets in terms of how
strongly they possess a given semantic prop-
erty. The semantic properties we use for ex-
emplifying the approach are positivity and
negativity, two properties of central impor-
tance in sentiment analysis. The idea derives
from the observation that WordNet may be
seen as a graph in which synsets are con-
nected through the binary relation “a term
belonging to synset sk occurs in the gloss
of synset si”, and on the hypothesis that
this relation may be viewed as a transmit-
ter of such semantic properties. The data
for this relation can be obtained from eX-
tended WordNet, a publicly available sense-
disambiguated version of WordNet. We ar-
gue that this relation is structurally akin to
the relation between hyperlinked Web pages,
and thus lends itself to PageRank analysis.
We report experimental results supporting
our intuitions.
</bodyText>
<sectionHeader confidence="0.999095" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9779857">
Recent years have witnessed an explosion of work
on opinion mining (aka sentiment analysis), the dis-
Phis work was partially supported by Project ONTOTEXT
“From Text to Knowledge for the Semantic Web”, funded by
the Provincia Autonoma di Trento under the 2004–2006 “Fondo
Unico per la Ricerca” funding scheme.
cipline that deals with the quantitative and qualita-
tive analysis of text for the purpose of determining
its opinion-related properties (ORPs). An important
part of this research has been the work on the auto-
matic determination of the ORPs of terms, as e.g.,
in determining whether an adjective tends to give a
positive, a negative, or a neutral nature to the noun
phrase it appears in. While many works (Esuli and
Sebastiani, 2005; Hatzivassiloglou and McKeown,
1997; Kamps et al., 2004; Takamura et al., 2005;
Turney and Littman, 2003) view the properties of
positivity and negativity as categorical (i.e., a term is
either positive or it is not), others (Andreevskaia and
Bergler, 2006b; Grefenstette et al., 2006; Kim and
Hovy, 2004; Subasic and Huettner, 2001) view them
as graded (i.e., a term may be positive to a certain
degree), with the underlying interpretation varying
from fuzzy to probabilistic.
Some authors go a step further and attach these
properties not to terms but to term senses (typ-
ically: WordNet synsets), on the assumption that
different senses of the same term may have dif-
ferent opinion-related properties (Andreevskaia and
Bergler, 2006a; Esuli and Sebastiani, 2006b; Ide,
2006; Wiebe and Mihalcea, 2006).
In this paper we contribute to this latter literature
with a novel method for ranking the entire set of
WordNet synsets, irrespectively of POS, according
to their ORPs. Two rankings are produced, one ac-
cording to positivity and one according to negativity.
The two rankings are independent, i.e., it is not the
case that one is the inverse of the other, since e.g.,
the least positive synsets may be negative or neutral
synsets alike.
</bodyText>
<page confidence="0.984619">
424
</page>
<note confidence="0.9254765">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 424–431,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.99981373015873">
The main hypothesis underlying our method is
that the positivity and negativity of WordNet synsets
can be determined by mining their glosses. It
crucially relies on the observation that the gloss
of a WordNet synset contains terms that them-
selves belong to synsets, and on the hypothesis that
the glosses of positive (resp. negative) synsets will
mostly contain terms belonging to positive (nega-
tive) synsets. This means that the binary relation
si ► sk (“the gloss of synset si contains a term
belonging to synset sk”), which induces a directed
graph on the set of WordNet synsets, may be thought
of as a channel through which positivity and nega-
tivity flow, from the definiendum (the synset si be-
ing defined) to the definiens (a synset sk that con-
tributes to the definition of si by virtue of its member
terms occurring in the gloss of si). In other words,
if a synset si is known to be positive (negative), this
can be viewed as an indication that the synsets sk to
which the terms occurring in the gloss of si belong,
are themselves positive (negative).
We obtain the data of the No. relation from eX-
tended WordNet (Harabagiu et al., 1999), an auto-
matically sense-disambiguated version of WordNet
in which every term occurrence in every gloss is
linked to the synset it is deemed to belong to.
In order to compute how polarity flows in the
graph of WordNet synsets we use the well known
PageRank algorithm (Brin and Page, 1998). PageR-
ank, a random-walk model for ranking Web search
results which lies at the basis of the Google search
engine, is probably the most important single contri-
bution to the fields of information retrieval and Web
search of the last ten years, and was originally de-
vised in order to detect how authoritativeness flows
in the Web graph and how it is conferred onto Web
sites. The advantages of PageRank are its strong
theoretical foundations, its fast convergence proper-
ties, and the effectiveness of its results. The reason
why PageRank, among all random-walk algorithms,
is particularly suited to our application will be dis-
cussed in the rest of the paper.
Note however that our method is not limited to
ranking synsets by positivity and negativity, and
could in principle be applied to the determination of
other semantic properties of synsets, such as mem-
bership in a domain, since for many other properties
we may hypothesize the existence of a similar “hy-
draulics” between synsets. We thus see positivity
and negativity only as proofs-of-concept for the po-
tential of the method.
The rest of the paper is organized as follows. Sec-
tion 2 reports on related work on the ORPs of lex-
ical items, highlighting the similarities and differ-
ences between the discussed methods and our own.
In Section 3 we turn to discussing our method; in or-
der to make the paper self-contained, we start with
a brief introduction of PageRank (Section 3.1) and
of the structure of eXtended WordNet (Section 3.2).
Section 4 describes the structure of our experiments,
while Section 5 discusses the results we have ob-
tained, comparing them with other results from the
literature. Section 6 concludes.
</bodyText>
<sectionHeader confidence="0.99969" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999736133333333">
Several works have recently tackled the automated
determination of term polarity. Hatzivassiloglou and
McKeown (1997) determine the polarity of adjec-
tives by mining pairs of conjoined adjectives from
text, and observing that conjunctions such as and
tend to conjoin adjectives of the same polarity while
conjunctions such as but tend to conjoin adjectives
of opposite polarity. Turney and Littman (2003) de-
termine the polarity of generic terms by computing
the pointwise mutual information (PMI) between the
target term and each of a set of “seed” terms of
known positivity or negativity, where the marginal
and joint probabilities needed for PMI computation
are equated to the fractions of documents from a
given corpus that contain the terms, individually or
jointly. Kamps et al. (2004) determine the polarity
of adjectives by checking whether the target adjec-
tive is closer to the term good or to the term bad
in the graph induced on WordNet by the synonymy
relation. Kim and Hovy (2004) determine the po-
larity of generic terms by means of two alternative
learning-free methods that use two sets of seed terms
of known positivity and negativity, and are based
on the frequency with which synonyms of the target
term also appear in the respective seed sets. Among
these works, (Turney and Littman, 2003) has proven
by far the most effective, but it is also by far the most
computationally intensive.
Some recent works have employed, as in the
present paper, the glosses from online dictionar-
</bodyText>
<page confidence="0.998643">
425
</page>
<bodyText confidence="0.999974230769231">
ies for term polarity detection. Andreevskaia and
Berger (2006a) extend a set of terms of known pos-
itivity/negativity by adding to them all the terms
whose glosses contain them; this algorithm does not
view glosses as a source for a graph of terms, and
is based on a different intuition than ours. Esuli
and Sebastiani (2005; 2006a) determine the ORPs of
generic terms by learning, in a semi-supervised way,
a binary term classifier from a set of training terms
that have been given vectorial representations by in-
dexing their WordNet glosses. The same authors
later extend their work to determining the ORPs
of WordNet synsets (Esuli and Sebastiani, 2006b).
However, there is a substantial difference between
these works and the present one, in that the former
simply view the glosses as sources of textual repre-
sentations for the terms/synsets, and not as inducing
a graph of synsets as we instead view them here.
The work closest in spirit to the present one is
probably that by Takamura et al. (2005), who de-
termine the polarity of terms by applying intuitions
from the theory of electron spins: two terms that ap-
pear one in the gloss of the other are viewed as akin
to two neighbouring electrons, which tend to acquire
the same “spin” (a notion viewed as akin to polarity)
due to their being neighbours. This work is simi-
lar to ours since a graph between terms is generated
from dictionary glosses, and since an iterative algo-
rithm that converges to a stable state is used, but the
algorithm is very different, and based on intuitions
from very different walks of life.
Some recent works have tackled the attribution
of opinion-related properties to word senses or
synsets (Ide, 2006; Wiebe and Mihalcea, 2006)1;
however, they do not use glosses in any significant
way, and are thus very different from our method.
The interested reader may also consult (Mihalcea,
2006) for other applications of random-walk models
to computational linguistics.
</bodyText>
<sectionHeader confidence="0.90578" genericHeader="method">
3 Ranking WordNet synsets by PageRank
</sectionHeader>
<subsectionHeader confidence="0.99677">
3.1 The PageRank algorithm
</subsectionHeader>
<bodyText confidence="0.97180204">
Let G = (N, L) be a directed graph, with N its set
of nodes and L its set of directed links; let Wo be
1Andreevskaia and Berger (2006a) also work on term
senses, rather than terms, but they evaluate their work on terms
only. This is the reason why they are listed in the preceding
paragraph and not here.
the |N |x |N |adjacency matrix of G, i.e., the ma-
trix such that W0[i, j] = 1 iff there is a link from
node ni to node nj. We will denote by B(i) =
{nj  |W0[j, i] = 11 the set of the backward neigh-
bours of ni, and by F(i) = {nj  |Wo[i, j] = 11
the set of the forward neighbours of ni. Let W be
the row-normalized adjacency matrix of G, i.e., the
matrix such that W[i, j] = 1
|F (i) |iff W0[i, j] = 1
and W[i, j] = 0 otherwise.
The input to PageRank is the row-normalized ad-
jacency matrix W, and its output is a vector a =
(a1, ... , a|N|), where ai represents the “score” of
node ni. When using PageRank for search results
ranking, ni is a Web site and ai measures its com-
puted authoritativeness; in our application ni is in-
stead a synset and ai measures the degree to which
ni has the semantic property of interest. PageRank
iteratively computes vector a based on the formula
</bodyText>
<equation confidence="0.97735325">
a(k−1)
+ (1 − α)ei (1)
|F(j)|
j
</equation>
<bodyText confidence="0.9910342">
where a(k)
i denotes the value of the i-th entry of vec-
tor a at the k-th iteration, ei is a constant such that
Ei e|N |i=1 = 1, and 0 &lt; α &lt; 1 is a control parameter.
In vectorial form, Equation 1 can be written as
</bodyText>
<equation confidence="0.999782">
a(k) = αa(k−1)W + (1 − α)e (2)
</equation>
<bodyText confidence="0.999955263157895">
The underlying intuition is that a node ni has a high
score when (recursively) it has many high-scoring
backward neighbours with few forward neighbours
each; a node nj thus passes its score aj along to
its forward neighbours F (j), but this score is sub-
divided equally among the members of F (j). This
mechanism (that is represented by the summation in
Equation 1) is then “smoothed” by the ei constants,
whose role is (see (Bianchini et al., 2005) for de-
tails) to avoid that scores flow and get trapped into
so-called “rank sinks” (i.e., cliques with backward
neighbours but no forward neighbours).
The computational properties of the PageRank al-
gorithm, and how to compute it efficiently, have
been widely studied; the interested reader may con-
sult (Bianchini et al., 2005).
In the original application of PageRank for rank-
ing Web search results the elements of e are usually
taken to be all equal to 1
</bodyText>
<equation confidence="0.972003">
|N|. However, it is possible
�
ai +- α
(k)
jEB(i)
</equation>
<page confidence="0.988411">
426
</page>
<bodyText confidence="0.99997905">
to give different values to different elements in e. In
fact, the value of ez amounts to an internal source
of score for nz that is constant across the iterations
and independent from its backward neighbours. For
instance, attributing a null ez value to all but a few
Web pages that are about a given topic can be used
in order to bias the ranking of Web pages in favour
of this topic (Haveliwala, 2003).
In this work we use the ez values as internal
sources of a given ORP (positivity or negativity),
by attributing a null ez value to all but a few “seed”
synsets known to possess that ORP. PageRank will
thus make the ORP flow from the seed synsets, at
a rate constant throughout the iterations, into other
synsets along the No. relation, until a stable state is
reached; the final az values can be used to rank the
synsets in terms of that ORP. Our method thus re-
quires two runs of PageRank; in the first e has non-
null scores for the positive seed synsets, while in the
second the same happens for the negative ones.
</bodyText>
<subsectionHeader confidence="0.997313">
3.2 eXtended WordNet
</subsectionHeader>
<bodyText confidence="0.999991357142857">
The transformation of WordNet into a graph based
on the No. relation would of course be non-
trivial, but is luckily provided by eXtended Word-
Net (Harabagiu et al., 1999), a publicly available
version of WordNet in which (among other things)
each term sk occurring in a WordNet gloss (ex-
cept those in example phrases) is lemmatized and
mapped to the synset in which it belongs2. We
use eXtended WordNet version 2.0-1.1, which refers
to WordNet version 2.0. The eXtended WordNet
resource has been automatically generated, which
means that the associations between terms and
synsets are likely to be sometimes incorrect, and this
of course introduces noise in our method.
</bodyText>
<subsectionHeader confidence="0.636565">
3.3 PageRank, (eXtended) WordNet, and ORP
flow
</subsectionHeader>
<bodyText confidence="0.989452857142857">
We now discuss the application of PageRank to
ranking WordNet synsets by positivity and negativ-
ity. Our algorithm consists in the following steps:
1. The graph G = (N, L) on which PageRank
will be applied is generated. We define N to
be the set of all WordNet synsets; in WordNet
2.0 there are 115,424 of them. We define L to
</bodyText>
<footnote confidence="0.845003">
2http://xwn.hlt.utdallas.edu/
</footnote>
<bodyText confidence="0.766741304347826">
contain a link from synset sz to synset sk iff the
gloss of sz contains at least a term belonging
to sk (terms occurring in the examples phrases
and terms occurring after a term that expresses
negation are not considered). Numbers, articles
and prepositions occurring in the glosses are
discarded, since they can be assumed to carry
no positivity and negativity, and since they do
not belong to a synset of their own. This leaves
only nouns, adjectives, verbs, and adverbs.
2. The graph G = (N, L) is “pruned” by remov-
ing “self-loops”, i.e., links going from a synset
sz into itself (since we assume that there is no
flow of semantics from a concept unto itself).
The row-normalized adjacency matrix W of G
is derived.
3. The ez values are loaded into the e vector; all
synsets other than the seed synsets of renowned
positivity (negativity) are given a value of 0.
The α control parameter is set to a fixed value.
We experiment with several different versions
of the e vector and several different values of
α; see Section 4.3 for details.
</bodyText>
<listItem confidence="0.980016444444444">
4. PageRank is executed using W and e, iter-
ating until a predefined termination condition
is reached. The termination condition we use
in this work consists in the fact that the co-
sine of the angle between a(k) and a(k+1) is
above a predefined threshold X (here we have
set X = 1 − 10−9).
5. We rank all the synsets of WordNet in descend-
ing order of their az score.
</listItem>
<bodyText confidence="0.928434384615384">
The process is run twice, once for positivity and
once for negativity.
The last question to be answered is: “why PageR-
ank?” Are the characteristics of PageRank more
suitable to the problem of ranking synsets than other
random-walk algorithms? The answer is yes, since
it seems reasonable that:
1. If terms contained in synset sk occur in the
glosses of many positive synsets, and if the pos-
itivity scores of these synsets are high, then it
is likely that sk is itself positive (the same hap-
pens for negativity). This justifies the summa-
tion of Equation 1.
</bodyText>
<page confidence="0.993146">
427
</page>
<bodyText confidence="0.854104555555556">
2. If the gloss of a positive synset that contains
a term in synset sk also contains many other
terms, then this is a weaker indication that sk is
itself positive (this justifies dividing by |F (j)|
in Equation 1).
3. The ranking resulting from the algorithm needs
to be biased in favour of a specific ORP; this
justifies the presence of the (1 − α)ez factor in
Equation 1).
The fact that PageRank is the “right” random-walk
algorithm for our application is also confirmed by
some experiments (not reported here for reasons of
space) we have run with slightly different variants of
the model (e.g., one in which we challenge intuition
2 above and thus avoid dividing by |F (j) |in Equa-
tion 1). These experiments have always returned
inferior results with respect to standard PageRank,
thereby confirming the correctness of our intuitions.
</bodyText>
<sectionHeader confidence="0.999243" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.986315">
4.1 The benchmark
</subsectionHeader>
<bodyText confidence="0.999934090909091">
To evaluate the quality of the rankings produced
by our experiments we have used the Micro-WNOp
corpus (Cerini et al., 2007) as a benchmark3. Micro-
WNOp consists in a set of 1,105 WordNet synsets,
each of which was manually assigned a triplet of
scores, one of positivity, one of negativity, one
of neutrality. The evaluation was performed by
five MSc students of linguistics, proficient second-
language speakers of English. Micro-WNOp is rep-
resentative of WordNet with respect to the different
parts of speech, in the sense that it contains synsets
of the different parts of speech in the same propor-
tions as in the entire WordNet. However, it is not
representative of WordNet with respect to ORPs,
since this would have brought about a corpus largely
composed of neutral synsets, which would be pretty
useless as a benchmark for testing automatically de-
rived lexical resources for opinion mining. It was
thus generated by randomly selecting 100 positive +
100 negative + 100 neutral terms from the General
Inquirer lexicon (see (Turney and Littman, 2003) for
details) and including all the synsets that contained
</bodyText>
<footnote confidence="0.750789">
3http://www.unipv.it/wnop/
</footnote>
<bodyText confidence="0.940813666666667">
at least one such term, without paying attention to
POS. See (Cerini et al., 2007) for more details.
The corpus is divided into three parts:
</bodyText>
<listItem confidence="0.96204075">
• Common: 110 synsets which all the evaluators
evaluated by working together, so as to align
their evaluation criteria.
• Group1: 496 synsets which were each inde-
pendently evaluated by three evaluators.
• Group2: 499 synsets which were each inde-
pendently evaluated by the other two evalua-
tors.
</listItem>
<bodyText confidence="0.9996825">
Each of these three parts has the same balance, in
terms of both parts of speech and ORPs, of Micro-
WNOp as a whole. We obtain the positivity (nega-
tivity) ranking from Micro-WNOp by averaging the
positivity (negativity) scores assigned by the evalua-
tors of each group into a single score, and by sorting
the synsets according to the resulting score. We use
Group1 as a validation set, i.e., in order to fine-tune
our method, and Group2 as a test set, i.e., in order
to evaluate our method once all the parameters have
been optimized on the validation set.
The result of applying PageRank to the graph G
induced by the No. relation, given a vector a of in-
ternal sources of positivity (negativity) score and a
value for the α parameter, is a ranking of all the
WordNet synsets in terms of positivity (negativity).
By using different a vectors and different values of
α we obtain different rankings, whose quality we
evaluate by comparing them against the ranking ob-
tained from Micro-WNOp.
</bodyText>
<subsectionHeader confidence="0.975783">
4.2 The effectiveness measure
</subsectionHeader>
<bodyText confidence="0.9995409">
A ranking :� is a partial order on a set of objects
N = {oi ... o|N|}. Given a pair (oz, oj) of objects,
oz may precede oj (oz -� oj), it may follow oz (oz r
oj), or it may be tied with oj (oz Pz� oj).
To evaluate the rankings produced by PageRank
we have used the p-normalized Kendall T distance
(noted Tp – see e.g., (Fagin et al., 2004)) between
the Micro-WNOp rankings and those predicted by
PageRank. A standard function for the evaluation of
rankings with ties, Tp is defined as
</bodyText>
<equation confidence="0.998608333333333">
nd + p · nu (3)
Z
Tp =
</equation>
<page confidence="0.993587">
428
</page>
<bodyText confidence="0.982641836363637">
where nd is the number of discordant pairs, i.e., null scores for all other synsets.
pairs of objects ordered one way in the gold stan- We have also tested a more complex version of
dard and the other way in the prediction; n,, is the e, with ei scores obtained from release 1.0 of Senti-
number of pairs ordered (i.e., not tied) in the gold WordNet (Esuli and Sebastiani, 2006b)5. This latter
standard and tied in the prediction, and p is a penal- is a lexical resource in which each WordNet synset
ization to be attributed to each such pair; and Z is is given a positivity score, a negativity score, and a
a normalization factor (equal to the number of pairs neutrality score. We produced an e vector (dubbed
that are ordered in the gold standard) whose aim is e4) in which the score assigned to a synset is propor-
to make the range of Tp coincide with the [0, 1] in- tional to the positivity (negativity) score assigned to
terval. Note that pairs tied in the gold standard are it by SentiWordNet, and in which all entries sum up
not considered in the evaluation. to 1. In a similar way we also produced a further e
The penalization factor is set to p = 1�, which vector (dubbed e5) through the scores of a newer re-
is equal to the probability that a ranking algorithm lease of SentiWordNet (release 1.1), resulting from a
correctly orders the pair by random guessing; there slight modification of the approach that had brought
is thus no advantage to be gained from either ran- about release 1.0 (Esuli and Sebastiani, 2007b).
dom guessing or assigning ties between objects. For PageRank is parametric on α, which determines
a prediction which perfectly coincides with the gold the balance between the contributions of the a(k−1)
standard Tp equals 0; for a prediction which is ex- vector and the e vector. A value of α = 0 makes
actly the inverse of the gold standard Tp equals 1. the a(k) vector coincide with e, and corresponds to
4.3 Setup discarding the contribution of the random-walk al-
In order to produce a ranking by positivity (nega- gorithm. Conversely, setting α = 1 corresponds
tivity) we need to provide an e vector as input to to discarding the contribution of e, and makes a(k)
PageRank. We have experimented with several dif- uniquely depend on the topology of the graph; the
ferent definitions of e, each for both positivity and result is an “unbiased” ranking. The desirable cases
negativity. For reasons of space, we only report re- are, of course, in between. As first hinted in Sec-
sults from the five most significant ones. tion 4.1, we thus optimize the α parameter on the
We have first tested a vector (hereafter dubbed synsets in Group1, and then test the algorithm with
e1) with all values uniformly set to 1 the optimal value of α on the synsets in Group2.
|�|. This is the All the 101 values of α from 0.0 to 1.0 with a step of
e vector originally used in (Brin and Page, 1998) .01 have been tested in the optimization phase. Op-
for Web page ranking, and brings about an unbiased timization is performed anew for each experiment,
(that is, with respect to particular properties) rank- which means that different values of α may be even-
ing of WordNet. Of course, it is not meant to be tually selected for different e vectors.
used for ranking by positivity or negativity; we have
used it as a baseline in order to evaluate the impact
of property-biased vectors.
The first sensible, albeit minimalistic, definition
of e we have used (dubbed e2) is that of a vec-
tor with uniform non-null ei scores assigned to the
synsets that contain the adjective good (bad), and
null scores for all other synsets. A further, still fairly
minimalistic definition we have used (dubbed e3) is
that of a vector with uniform non-null ei scores as-
signed to the synsets that contain at least one of the
seven “paradigmatic” positive (negative) adjectives
used as seeds in (Turney and Littman, 2003)4, and
5 Results
The results show that the use of PageRank in com-
bination with suitable vectors e almost always im-
proves the ranking, sometimes significantly so, with
respect to the original ranking embodied by the e
vector.
For positivity, the rankings produced using
PageRank and any of the vectors from e2 to e5 all
improve on the original rankings, with a relative im-
provement, measured as the relative decrease in Tp,
positive, fortunate, correct, superior, and the seven negative
ones are bad, nasty, poor, negative, unfortunate, wrong, in-
ferior.
5http://sentiwordnet.isti.cnr.it/
4The seven positive adjectives are good, nice, excellent,
429
ranging from −4.88% (e5) to −6.75% (e4). These
rankings are also all better than the rankings pro-
duced by using PageRank and the uniform-valued
vector e1, with a minimum relative improvement
of −5.04% (e3) and a maximum of −34.47% (e4).
This suggests that the key to good performance is
indeed a combination of positivity flow and internal
source of score.
For the negativity rankings, the performance of
both SentiWordNet-based vectors is still good, pro-
ducing a −4.31% (e4) and a −3.45% (e5) improve-
ment with respect to the original rankings. The
“minimalistic” vectors (i.e., e2 and e3) are not as
good as their positive counterparts. The reason
seems to be that the generation of a ranking by neg-
ativity seems a somehow harder task than the gen-
eration of a ranking by positivity; this is also shown
by the results obtained with the uniform-valued vec-
tor e1, in which the application of PageRank im-
proves with respect to e1 for positivity but deteri-
orates for negativity. However, against the baseline
constituted by the results obtained with the uniform-
valued vector e1 for negativity, our rankings show
a relevant improvement, ranging from −8.56% (e2)
to −48.27% (e4).
Our results are particularly significant for the e4
vectors, derived by SentiWordNet 1.0, for a num-
ber of reasons. First, e4 brings about the best value
of τp obtained in all our experiments (.325 for pos-
itivity, .284 for negativity). Second, the relative im-
provement with respect to e4 is the most marked
among the various choices for e (6.75% for positiv-
ity, 4.31% for negativity). Third, the improvement
is obtained with respect to an already high-quality
resource, obtained by the same techniques that, at
the term level, are still the best performers for po-
larity detection on the widely used General Inquirer
benchmark (Esuli and Sebastiani, 2005).
Finally, observe that the fact that e4 outperforms
all other choices for e (and e2 in particular) was not
necessarily to be expected. In fact, SentiWordNet
1.0 was built by a semi-supervised learning method
that uses vectors e2 as its only initial training data.
This paper thus shows that, starting from e2 as the
only manually annotated data, the best results are
obtained neither by the semi-supervised method that
generated SentiWordNet 1.0, nor by PageRank, but
by the concatenation of the former with the latter.
</bodyText>
<table confidence="0.999648583333333">
Positivity Negativity
e PageRank? TP A TP A
e1 before .500 .500
after .496 (-0.81%) .549 (9.83%)
e2 before .500 .500
after .467 (-6.65%) .502 (0.31%)
e3 before .500 .500
after .471 (-5.79%) .495 (-0.92%)
e4 before .349 .296
after .325 (-6.75%) .284 (-4.31%)
e5 before .400 .407
after .380 (-4.88%) .393 (-3.45%)
</table>
<tableCaption confidence="0.997917">
Table 1: Values of τp between predicted rankings
</tableCaption>
<bodyText confidence="0.987747714285714">
and gold standard rankings (smaller is better). For
each experiment the first line indicates the ranking
obtained from the original e vector (before the ap-
plication of PageRank), while the second line indi-
cates the ranking obtained after the application of
PageRank, with the relative improvement (a nega-
tive percentage indicates improvement).
</bodyText>
<sectionHeader confidence="0.999361" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999995052631579">
We have investigated the applicability of a random-
walk model to the problem of ranking synsets ac-
cording to positivity and negativity. However, we
conjecture that this model can be of more general
use, i.e., for the determination of other properties of
term senses, such as membership in a domain. This
paper thus presents a proof-of-concept of the model,
and the results of experiments support our intuitions.
Also, we see this work as a proof of concept
for the applicability of general random-walk algo-
rithms (and not just PageRank) to the determination
of the semantic properties of synsets. In a more re-
cent paper (Esuli and Sebastiani, 2007a) we have
investigated a related random-walk model, one in
which, symmetrically to the intuitions of the model
presented in this paper, semantics flows from the
definiens to the definiendum; a metaphor that proves
no less powerful than the one we have championed
in this paper.
</bodyText>
<sectionHeader confidence="0.996308" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.906831428571429">
Alina Andreevskaia and Sabine Bergler. 2006a. Mining Word-
Net for fuzzy sentiment: Sentiment tag extraction from
WordNet glosses. In Proceedings of the 11th Conference of
the European Chapter of the Association for Computational
Linguistics (EACL’06), pages 209–216, Trento, IT.
Alina Andreevskaia and Sabine Bergler. 2006b. Sentiment
tag extraction from WordNet glosses. In Proceedings of
</reference>
<page confidence="0.991538">
430
</page>
<reference confidence="0.99760749">
the 5th Conference on Language Resources and Evaluation
(LREC’06), Genova, IT.
Monica Bianchini, Marco Gori, and Franco Scarselli. 2005. In-
side PageRank. ACM Transactions on Internet Technology,
5(1):92–128.
Sergey Brin and Lawrence Page. 1998. The anatomy of a large-
scale hypertextual Web search engine. Computer Networks
and ISDN Systems, 30(1-7):107–117.
Sabrina Cerini, Valentina Compagnoni, Alice Demontis,
Maicol Formentelli, and Caterina Gandini. 2007. Micro-
WNOp: A gold standard for the evaluation of automati-
cally compiled lexical resources for opinion mining. In An-
drea Sans`o, editor, Language resources and linguistic the-
ory: Typology, second language acquisition, English linguis-
tics. Franco Angeli Editore, Milano, IT. Forthcoming.
Andrea Esuli and Fabrizio Sebastiani. 2005. Determining the
semantic orientation of terms through gloss analysis. In Pro-
ceedings of the 14th ACM International Conference on In-
formation and Knowledge Management (CIKM’05), pages
617–624, Bremen, DE.
Andrea Esuli and Fabrizio Sebastiani. 2006a. Determining
term subjectivity and term orientation for opinion mining. In
Proceedings of the 11th Conference of the European Chapter
of the Association for Computational Linguistics (EACL’06),
pages 193–200, Trento, IT.
Andrea Esuli and Fabrizio Sebastiani. 2006b. SENTIWORD-
NET: A publicly available lexical resource for opinion min-
ing. In Proceedings of the 5th Conference on Language Re-
sources and Evaluation (LREC’06), pages 417–422, Gen-
ova, IT.
Andrea Esuli and Fabrizio Sebastiani. 2007a. Random-
walk models of term semantics: An application to opinion-
related properties. Technical Report ISTI-009/2007, Isti-
tuto di Scienza e Tecnologie dell’Informazione, Consiglio
Nazionale dellle Ricerche, Pisa, IT.
Andrea Esuli and Fabrizio Sebastiani. 2007b. SENTIWORD-
NET: A high-coverage lexical resource for opinion mining.
Technical Report 2007-TR-02, Istituto di Scienza e Tecnolo-
gie dell’Informazione, Consiglio Nazionale delle Ricerche,
Pisa, IT.
Ronald Fagin, Ravi Kumar, Mohammad Mahdiany, D. Sivaku-
mar, and Erik Veez. 2004. Comparing and aggregating rank-
ings with ties. In Proceedings of ACM International Confer-
ence on Principles of Database Systems (PODS’04), pages
47–58, Paris, FR.
Gregory Grefenstette, Yan Qu, David A. Evans, and James G.
Shanahan. 2006. Validating the coverage of lexical re-
sources for affect analysis and automatically classifying new
words along semantic axes. In James G. Shanahan, Yan Qu,
and Janyce Wiebe, editors, Computing Attitude and Affect
in Text: Theories and Applications, pages 93–107. Springer,
Heidelberg, DE.
Sanda H. Harabagiu, George A. Miller, and Dan I. Moldovan.
1999. WordNet 2: A morphologically and semantically en-
hanced resource. In Proceedings of the ACL SIGLEX Work-
shop on Standardizing Lexical Resources, pages 1–8, Col-
lege Park, US.
Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997.
Predicting the semantic orientation of adjectives. In Pro-
ceedings of the 35th Annual Meeting of the Association
for Computational Linguistics (ACL’97), pages 174–181,
Madrid, ES.
Taher H. Haveliwala. 2003. Topic-sensitive PageRank:
A context-sensitive ranking algorithm for Web search.
IEEE Transactions on Knowledge and Data Engineering,
15(4):784–796.
Nancy Ide. 2006. Making senses: Bootstrapping sense-tagged
lists of semantically-related words. In Proceedings of the
7th International Conference on Computational Linguistics
and Intelligent Text Processing (CICLING’06), pages 13–27,
Mexico City, MX.
Jaap Kamps, Maarten Marx, Robert J. Mokken, and Maarten
De Rijke. 2004. Using WordNet to measure semantic ori-
entation of adjectives. In Proceedings of the 4th Interna-
tional Conference on Language Resources and Evaluation
(LREC’04), volume IV, pages 1115–1118, Lisbon, PT.
Soo-Min Kim and Eduard Hovy. 2004. Determining the
sentiment of opinions. In Proceedings of the 20th Inter-
national Conference on Computational Linguistics (COL-
ING’04), pages 1367–1373, Geneva, CH.
Rada Mihalcea. 2006. Random walks on text structures. In
Proceedings of the 7th International Conference on Com-
putational Linguistics and Intelligent Text Processing (CI-
CLING’06), pages 249–262, Mexico City, MX.
Pero Subasic and Alison Huettner. 2001. Affect analysis of text
using fuzzy semantic typing. IEEE Transactions on Fuzzy
Systems, 9(4):483–496.
Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005.
Extracting emotional polarity of words using spin model.
In Proceedings of the 43rd Annual Meeting of the Associ-
ation for Computational Linguistics (ACL’05), pages 133–
140, Ann Arbor, US.
Peter D. Turney and Michael L. Littman. 2003. Measur-
ing praise and criticism: Inference of semantic orientation
from association. ACM Transactions on Information Sys-
tems, 21(4):315–346.
Janyce Wiebe and Rada Mihalcea. 2006. Word sense and sub-
jectivity. In Proceedings of the 44th Annual Meeting of the
Association for Computational Linguistics (ACL’06), pages
1065–1072, Sydney, AU.
</reference>
<page confidence="0.998907">
431
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.681856">
<title confidence="0.9990295">PageRanking WordNet Synsets: Application to Opinion</title>
<author confidence="0.99519">Andrea Esuli</author>
<author confidence="0.99519">Fabrizio Sebastiani</author>
<affiliation confidence="0.793759">Istituto di Scienza e Tecnologie dell’Informazione Consiglio Nazionale delle Ricerche</affiliation>
<address confidence="0.865669">Via Giuseppe Moruzzi, 1 – 56124 Pisa, Italy</address>
<abstract confidence="0.99981672">This paper presents an application of PageRank, a random-walk model originally devised for ranking Web search results, to ranking WordNet synsets in terms of how strongly they possess a given semantic property. The semantic properties we use for exemplifying the approach are positivity and negativity, two properties of central importance in sentiment analysis. The idea derives from the observation that WordNet may be seen as a graph in which synsets are connected through the binary relation “a term to synset in the gloss synset and on the hypothesis that this relation may be viewed as a transmitter of such semantic properties. The data for this relation can be obtained from eXtended WordNet, a publicly available sensedisambiguated version of WordNet. We argue that this relation is structurally akin to the relation between hyperlinked Web pages, and thus lends itself to PageRank analysis. We report experimental results supporting our intuitions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>Mining WordNet for fuzzy sentiment: Sentiment tag extraction from WordNet glosses.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL’06),</booktitle>
<pages>209--216</pages>
<location>Trento, IT.</location>
<contexts>
<context position="2285" citStr="Andreevskaia and Bergler, 2006" startWordPosition="356" endWordPosition="359">nalysis of text for the purpose of determining its opinion-related properties (ORPs). An important part of this research has been the work on the automatic determination of the ORPs of terms, as e.g., in determining whether an adjective tends to give a positive, a negative, or a neutral nature to the noun phrase it appears in. While many works (Esuli and Sebastiani, 2005; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003) view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opinion-related properties (Andreevskaia and Bergler, 2006a; Esuli and Sebastiani, 2006b; Ide, 2006; Wiebe and Mihalcea, 2006). In this paper we contribute to this latter literature</context>
</contexts>
<marker>Andreevskaia, Bergler, 2006</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2006a. Mining WordNet for fuzzy sentiment: Sentiment tag extraction from WordNet glosses. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL’06), pages 209–216, Trento, IT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>Sentiment tag extraction from WordNet glosses.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC’06),</booktitle>
<location>Genova, IT.</location>
<contexts>
<context position="2285" citStr="Andreevskaia and Bergler, 2006" startWordPosition="356" endWordPosition="359">nalysis of text for the purpose of determining its opinion-related properties (ORPs). An important part of this research has been the work on the automatic determination of the ORPs of terms, as e.g., in determining whether an adjective tends to give a positive, a negative, or a neutral nature to the noun phrase it appears in. While many works (Esuli and Sebastiani, 2005; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003) view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opinion-related properties (Andreevskaia and Bergler, 2006a; Esuli and Sebastiani, 2006b; Ide, 2006; Wiebe and Mihalcea, 2006). In this paper we contribute to this latter literature</context>
</contexts>
<marker>Andreevskaia, Bergler, 2006</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2006b. Sentiment tag extraction from WordNet glosses. In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC’06), Genova, IT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Monica Bianchini</author>
<author>Marco Gori</author>
<author>Franco Scarselli</author>
</authors>
<title>Inside PageRank.</title>
<date>2005</date>
<journal>ACM Transactions on Internet Technology,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="11999" citStr="Bianchini et al., 2005" startWordPosition="2042" endWordPosition="2045">th iteration, ei is a constant such that Ei e|N |i=1 = 1, and 0 &lt; α &lt; 1 is a control parameter. In vectorial form, Equation 1 can be written as a(k) = αa(k−1)W + (1 − α)e (2) The underlying intuition is that a node ni has a high score when (recursively) it has many high-scoring backward neighbours with few forward neighbours each; a node nj thus passes its score aj along to its forward neighbours F (j), but this score is subdivided equally among the members of F (j). This mechanism (that is represented by the summation in Equation 1) is then “smoothed” by the ei constants, whose role is (see (Bianchini et al., 2005) for details) to avoid that scores flow and get trapped into so-called “rank sinks” (i.e., cliques with backward neighbours but no forward neighbours). The computational properties of the PageRank algorithm, and how to compute it efficiently, have been widely studied; the interested reader may consult (Bianchini et al., 2005). In the original application of PageRank for ranking Web search results the elements of e are usually taken to be all equal to 1 |N|. However, it is possible � ai +- α (k) jEB(i) 426 to give different values to different elements in e. In fact, the value of ez amounts to </context>
</contexts>
<marker>Bianchini, Gori, Scarselli, 2005</marker>
<rawString>Monica Bianchini, Marco Gori, and Franco Scarselli. 2005. Inside PageRank. ACM Transactions on Internet Technology, 5(1):92–128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The anatomy of a largescale hypertextual Web search engine.</title>
<date>1998</date>
<journal>Computer Networks and ISDN Systems,</journal>
<pages>30--1</pages>
<contexts>
<context position="4889" citStr="Brin and Page, 1998" startWordPosition="792" endWordPosition="795"> occurring in the gloss of si). In other words, if a synset si is known to be positive (negative), this can be viewed as an indication that the synsets sk to which the terms occurring in the gloss of si belong, are themselves positive (negative). We obtain the data of the No. relation from eXtended WordNet (Harabagiu et al., 1999), an automatically sense-disambiguated version of WordNet in which every term occurrence in every gloss is linked to the synset it is deemed to belong to. In order to compute how polarity flows in the graph of WordNet synsets we use the well known PageRank algorithm (Brin and Page, 1998). PageRank, a random-walk model for ranking Web search results which lies at the basis of the Google search engine, is probably the most important single contribution to the fields of information retrieval and Web search of the last ten years, and was originally devised in order to detect how authoritativeness flows in the Web graph and how it is conferred onto Web sites. The advantages of PageRank are its strong theoretical foundations, its fast convergence properties, and the effectiveness of its results. The reason why PageRank, among all random-walk algorithms, is particularly suited to ou</context>
<context position="23467" citStr="Brin and Page, 1998" startWordPosition="4072" endWordPosition="4075">ph; the ferent definitions of e, each for both positivity and result is an “unbiased” ranking. The desirable cases negativity. For reasons of space, we only report re- are, of course, in between. As first hinted in Secsults from the five most significant ones. tion 4.1, we thus optimize the α parameter on the We have first tested a vector (hereafter dubbed synsets in Group1, and then test the algorithm with e1) with all values uniformly set to 1 the optimal value of α on the synsets in Group2. |�|. This is the All the 101 values of α from 0.0 to 1.0 with a step of e vector originally used in (Brin and Page, 1998) .01 have been tested in the optimization phase. Opfor Web page ranking, and brings about an unbiased timization is performed anew for each experiment, (that is, with respect to particular properties) rank- which means that different values of α may be evening of WordNet. Of course, it is not meant to be tually selected for different e vectors. used for ranking by positivity or negativity; we have used it as a baseline in order to evaluate the impact of property-biased vectors. The first sensible, albeit minimalistic, definition of e we have used (dubbed e2) is that of a vector with uniform no</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Lawrence Page. 1998. The anatomy of a largescale hypertextual Web search engine. Computer Networks and ISDN Systems, 30(1-7):107–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabrina Cerini</author>
</authors>
<title>Valentina Compagnoni, Alice Demontis, Maicol Formentelli, and Caterina Gandini.</title>
<date>2007</date>
<booktitle>Language resources and linguistic theory: Typology, second language acquisition, English linguistics. Franco Angeli Editore,</booktitle>
<editor>In Andrea Sans`o, editor,</editor>
<publisher>Forthcoming.</publisher>
<location>Milano, IT.</location>
<marker>Cerini, 2007</marker>
<rawString>Sabrina Cerini, Valentina Compagnoni, Alice Demontis, Maicol Formentelli, and Caterina Gandini. 2007. MicroWNOp: A gold standard for the evaluation of automatically compiled lexical resources for opinion mining. In Andrea Sans`o, editor, Language resources and linguistic theory: Typology, second language acquisition, English linguistics. Franco Angeli Editore, Milano, IT. Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Determining the semantic orientation of terms through gloss analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th ACM International Conference on Information and Knowledge Management (CIKM’05),</booktitle>
<pages>617--624</pages>
<location>Bremen, DE.</location>
<contexts>
<context position="2028" citStr="Esuli and Sebastiani, 2005" startWordPosition="316" endWordPosition="319">partially supported by Project ONTOTEXT “From Text to Knowledge for the Semantic Web”, funded by the Provincia Autonoma di Trento under the 2004–2006 “Fondo Unico per la Ricerca” funding scheme. cipline that deals with the quantitative and qualitative analysis of text for the purpose of determining its opinion-related properties (ORPs). An important part of this research has been the work on the automatic determination of the ORPs of terms, as e.g., in determining whether an adjective tends to give a positive, a negative, or a neutral nature to the noun phrase it appears in. While many works (Esuli and Sebastiani, 2005; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003) view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), </context>
<context position="8403" citStr="Esuli and Sebastiani (2005" startWordPosition="1378" endWordPosition="1381">nyms of the target term also appear in the respective seed sets. Among these works, (Turney and Littman, 2003) has proven by far the most effective, but it is also by far the most computationally intensive. Some recent works have employed, as in the present paper, the glosses from online dictionar425 ies for term polarity detection. Andreevskaia and Berger (2006a) extend a set of terms of known positivity/negativity by adding to them all the terms whose glosses contain them; this algorithm does not view glosses as a source for a graph of terms, and is based on a different intuition than ours. Esuli and Sebastiani (2005; 2006a) determine the ORPs of generic terms by learning, in a semi-supervised way, a binary term classifier from a set of training terms that have been given vectorial representations by indexing their WordNet glosses. The same authors later extend their work to determining the ORPs of WordNet synsets (Esuli and Sebastiani, 2006b). However, there is a substantial difference between these works and the present one, in that the former simply view the glosses as sources of textual representations for the terms/synsets, and not as inducing a graph of synsets as we instead view them here. The work</context>
<context position="26939" citStr="Esuli and Sebastiani, 2005" startWordPosition="4646" endWordPosition="4649">ly significant for the e4 vectors, derived by SentiWordNet 1.0, for a number of reasons. First, e4 brings about the best value of τp obtained in all our experiments (.325 for positivity, .284 for negativity). Second, the relative improvement with respect to e4 is the most marked among the various choices for e (6.75% for positivity, 4.31% for negativity). Third, the improvement is obtained with respect to an already high-quality resource, obtained by the same techniques that, at the term level, are still the best performers for polarity detection on the widely used General Inquirer benchmark (Esuli and Sebastiani, 2005). Finally, observe that the fact that e4 outperforms all other choices for e (and e2 in particular) was not necessarily to be expected. In fact, SentiWordNet 1.0 was built by a semi-supervised learning method that uses vectors e2 as its only initial training data. This paper thus shows that, starting from e2 as the only manually annotated data, the best results are obtained neither by the semi-supervised method that generated SentiWordNet 1.0, nor by PageRank, but by the concatenation of the former with the latter. Positivity Negativity e PageRank? TP A TP A e1 before .500 .500 after .496 (-0.</context>
</contexts>
<marker>Esuli, Sebastiani, 2005</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2005. Determining the semantic orientation of terms through gloss analysis. In Proceedings of the 14th ACM International Conference on Information and Knowledge Management (CIKM’05), pages 617–624, Bremen, DE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Determining term subjectivity and term orientation for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL’06),</booktitle>
<pages>193--200</pages>
<location>Trento, IT.</location>
<contexts>
<context position="2791" citStr="Esuli and Sebastiani, 2006" startWordPosition="436" endWordPosition="439">ity and negativity as categorical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opinion-related properties (Andreevskaia and Bergler, 2006a; Esuli and Sebastiani, 2006b; Ide, 2006; Wiebe and Mihalcea, 2006). In this paper we contribute to this latter literature with a novel method for ranking the entire set of WordNet synsets, irrespectively of POS, according to their ORPs. Two rankings are produced, one according to positivity and one according to negativity. The two rankings are independent, i.e., it is not the case that one is the inverse of the other, since e.g., the least positive synsets may be negative or neutral synsets alike. 424 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 424–431, Prague, Czech Rep</context>
<context position="8734" citStr="Esuli and Sebastiani, 2006" startWordPosition="1431" endWordPosition="1434">on. Andreevskaia and Berger (2006a) extend a set of terms of known positivity/negativity by adding to them all the terms whose glosses contain them; this algorithm does not view glosses as a source for a graph of terms, and is based on a different intuition than ours. Esuli and Sebastiani (2005; 2006a) determine the ORPs of generic terms by learning, in a semi-supervised way, a binary term classifier from a set of training terms that have been given vectorial representations by indexing their WordNet glosses. The same authors later extend their work to determining the ORPs of WordNet synsets (Esuli and Sebastiani, 2006b). However, there is a substantial difference between these works and the present one, in that the former simply view the glosses as sources of textual representations for the terms/synsets, and not as inducing a graph of synsets as we instead view them here. The work closest in spirit to the present one is probably that by Takamura et al. (2005), who determine the polarity of terms by applying intuitions from the theory of electron spins: two terms that appear one in the gloss of the other are viewed as akin to two neighbouring electrons, which tend to acquire the same “spin” (a notion viewe</context>
<context position="20938" citStr="Esuli and Sebastiani, 2006" startWordPosition="3616" endWordPosition="3619">the p-normalized Kendall T distance (noted Tp – see e.g., (Fagin et al., 2004)) between the Micro-WNOp rankings and those predicted by PageRank. A standard function for the evaluation of rankings with ties, Tp is defined as nd + p · nu (3) Z Tp = 428 where nd is the number of discordant pairs, i.e., null scores for all other synsets. pairs of objects ordered one way in the gold stan- We have also tested a more complex version of dard and the other way in the prediction; n,, is the e, with ei scores obtained from release 1.0 of Sentinumber of pairs ordered (i.e., not tied) in the gold WordNet (Esuli and Sebastiani, 2006b)5. This latter standard and tied in the prediction, and p is a penal- is a lexical resource in which each WordNet synset ization to be attributed to each such pair; and Z is is given a positivity score, a negativity score, and a a normalization factor (equal to the number of pairs neutrality score. We produced an e vector (dubbed that are ordered in the gold standard) whose aim is e4) in which the score assigned to a synset is proporto make the range of Tp coincide with the [0, 1] in- tional to the positivity (negativity) score assigned to terval. Note that pairs tied in the gold standard ar</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006a. Determining term subjectivity and term orientation for opinion mining. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL’06), pages 193–200, Trento, IT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SENTIWORDNET: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC’06),</booktitle>
<pages>417--422</pages>
<location>Genova, IT.</location>
<contexts>
<context position="2791" citStr="Esuli and Sebastiani, 2006" startWordPosition="436" endWordPosition="439">ity and negativity as categorical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opinion-related properties (Andreevskaia and Bergler, 2006a; Esuli and Sebastiani, 2006b; Ide, 2006; Wiebe and Mihalcea, 2006). In this paper we contribute to this latter literature with a novel method for ranking the entire set of WordNet synsets, irrespectively of POS, according to their ORPs. Two rankings are produced, one according to positivity and one according to negativity. The two rankings are independent, i.e., it is not the case that one is the inverse of the other, since e.g., the least positive synsets may be negative or neutral synsets alike. 424 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 424–431, Prague, Czech Rep</context>
<context position="8734" citStr="Esuli and Sebastiani, 2006" startWordPosition="1431" endWordPosition="1434">on. Andreevskaia and Berger (2006a) extend a set of terms of known positivity/negativity by adding to them all the terms whose glosses contain them; this algorithm does not view glosses as a source for a graph of terms, and is based on a different intuition than ours. Esuli and Sebastiani (2005; 2006a) determine the ORPs of generic terms by learning, in a semi-supervised way, a binary term classifier from a set of training terms that have been given vectorial representations by indexing their WordNet glosses. The same authors later extend their work to determining the ORPs of WordNet synsets (Esuli and Sebastiani, 2006b). However, there is a substantial difference between these works and the present one, in that the former simply view the glosses as sources of textual representations for the terms/synsets, and not as inducing a graph of synsets as we instead view them here. The work closest in spirit to the present one is probably that by Takamura et al. (2005), who determine the polarity of terms by applying intuitions from the theory of electron spins: two terms that appear one in the gloss of the other are viewed as akin to two neighbouring electrons, which tend to acquire the same “spin” (a notion viewe</context>
<context position="20938" citStr="Esuli and Sebastiani, 2006" startWordPosition="3616" endWordPosition="3619">the p-normalized Kendall T distance (noted Tp – see e.g., (Fagin et al., 2004)) between the Micro-WNOp rankings and those predicted by PageRank. A standard function for the evaluation of rankings with ties, Tp is defined as nd + p · nu (3) Z Tp = 428 where nd is the number of discordant pairs, i.e., null scores for all other synsets. pairs of objects ordered one way in the gold stan- We have also tested a more complex version of dard and the other way in the prediction; n,, is the e, with ei scores obtained from release 1.0 of Sentinumber of pairs ordered (i.e., not tied) in the gold WordNet (Esuli and Sebastiani, 2006b)5. This latter standard and tied in the prediction, and p is a penal- is a lexical resource in which each WordNet synset ization to be attributed to each such pair; and Z is is given a positivity score, a negativity score, and a a normalization factor (equal to the number of pairs neutrality score. We produced an e vector (dubbed that are ordered in the gold standard) whose aim is e4) in which the score assigned to a synset is proporto make the range of Tp coincide with the [0, 1] in- tional to the positivity (negativity) score assigned to terval. Note that pairs tied in the gold standard ar</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006b. SENTIWORDNET: A publicly available lexical resource for opinion mining. In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC’06), pages 417–422, Genova, IT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Randomwalk models of term semantics: An application to opinionrelated properties.</title>
<date>2007</date>
<booktitle>Istituto di Scienza e Tecnologie dell’Informazione, Consiglio Nazionale dellle Ricerche,</booktitle>
<tech>Technical Report ISTI-009/2007,</tech>
<location>Pisa, IT.</location>
<contexts>
<context position="22085" citStr="Esuli and Sebastiani, 2007" startWordPosition="3824" endWordPosition="3827">ativity) score assigned to terval. Note that pairs tied in the gold standard are it by SentiWordNet, and in which all entries sum up not considered in the evaluation. to 1. In a similar way we also produced a further e The penalization factor is set to p = 1�, which vector (dubbed e5) through the scores of a newer reis equal to the probability that a ranking algorithm lease of SentiWordNet (release 1.1), resulting from a correctly orders the pair by random guessing; there slight modification of the approach that had brought is thus no advantage to be gained from either ran- about release 1.0 (Esuli and Sebastiani, 2007b). dom guessing or assigning ties between objects. For PageRank is parametric on α, which determines a prediction which perfectly coincides with the gold the balance between the contributions of the a(k−1) standard Tp equals 0; for a prediction which is ex- vector and the e vector. A value of α = 0 makes actly the inverse of the gold standard Tp equals 1. the a(k) vector coincide with e, and corresponds to 4.3 Setup discarding the contribution of the random-walk alIn order to produce a ranking by positivity (nega- gorithm. Conversely, setting α = 1 corresponds tivity) we need to provide an e </context>
</contexts>
<marker>Esuli, Sebastiani, 2007</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2007a. Randomwalk models of term semantics: An application to opinionrelated properties. Technical Report ISTI-009/2007, Istituto di Scienza e Tecnologie dell’Informazione, Consiglio Nazionale dellle Ricerche, Pisa, IT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SENTIWORDNET: A high-coverage lexical resource for opinion mining.</title>
<date>2007</date>
<booktitle>Istituto di Scienza e Tecnologie dell’Informazione, Consiglio Nazionale delle Ricerche,</booktitle>
<tech>Technical Report 2007-TR-02,</tech>
<location>Pisa, IT.</location>
<contexts>
<context position="22085" citStr="Esuli and Sebastiani, 2007" startWordPosition="3824" endWordPosition="3827">ativity) score assigned to terval. Note that pairs tied in the gold standard are it by SentiWordNet, and in which all entries sum up not considered in the evaluation. to 1. In a similar way we also produced a further e The penalization factor is set to p = 1�, which vector (dubbed e5) through the scores of a newer reis equal to the probability that a ranking algorithm lease of SentiWordNet (release 1.1), resulting from a correctly orders the pair by random guessing; there slight modification of the approach that had brought is thus no advantage to be gained from either ran- about release 1.0 (Esuli and Sebastiani, 2007b). dom guessing or assigning ties between objects. For PageRank is parametric on α, which determines a prediction which perfectly coincides with the gold the balance between the contributions of the a(k−1) standard Tp equals 0; for a prediction which is ex- vector and the e vector. A value of α = 0 makes actly the inverse of the gold standard Tp equals 1. the a(k) vector coincide with e, and corresponds to 4.3 Setup discarding the contribution of the random-walk alIn order to produce a ranking by positivity (nega- gorithm. Conversely, setting α = 1 corresponds tivity) we need to provide an e </context>
</contexts>
<marker>Esuli, Sebastiani, 2007</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2007b. SENTIWORDNET: A high-coverage lexical resource for opinion mining. Technical Report 2007-TR-02, Istituto di Scienza e Tecnologie dell’Informazione, Consiglio Nazionale delle Ricerche, Pisa, IT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Fagin</author>
<author>Ravi Kumar</author>
<author>Mohammad Mahdiany</author>
<author>D Sivakumar</author>
<author>Erik Veez</author>
</authors>
<title>Comparing and aggregating rankings with ties.</title>
<date>2004</date>
<booktitle>In Proceedings of ACM International Conference on Principles of Database Systems (PODS’04),</booktitle>
<pages>47--58</pages>
<location>Paris, FR.</location>
<contexts>
<context position="20390" citStr="Fagin et al., 2004" startWordPosition="3513" endWordPosition="3516"> a ranking of all the WordNet synsets in terms of positivity (negativity). By using different a vectors and different values of α we obtain different rankings, whose quality we evaluate by comparing them against the ranking obtained from Micro-WNOp. 4.2 The effectiveness measure A ranking :� is a partial order on a set of objects N = {oi ... o|N|}. Given a pair (oz, oj) of objects, oz may precede oj (oz -� oj), it may follow oz (oz r oj), or it may be tied with oj (oz Pz� oj). To evaluate the rankings produced by PageRank we have used the p-normalized Kendall T distance (noted Tp – see e.g., (Fagin et al., 2004)) between the Micro-WNOp rankings and those predicted by PageRank. A standard function for the evaluation of rankings with ties, Tp is defined as nd + p · nu (3) Z Tp = 428 where nd is the number of discordant pairs, i.e., null scores for all other synsets. pairs of objects ordered one way in the gold stan- We have also tested a more complex version of dard and the other way in the prediction; n,, is the e, with ei scores obtained from release 1.0 of Sentinumber of pairs ordered (i.e., not tied) in the gold WordNet (Esuli and Sebastiani, 2006b)5. This latter standard and tied in the prediction</context>
</contexts>
<marker>Fagin, Kumar, Mahdiany, Sivakumar, Veez, 2004</marker>
<rawString>Ronald Fagin, Ravi Kumar, Mohammad Mahdiany, D. Sivakumar, and Erik Veez. 2004. Comparing and aggregating rankings with ties. In Proceedings of ACM International Conference on Principles of Database Systems (PODS’04), pages 47–58, Paris, FR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
<author>Yan Qu</author>
<author>David A Evans</author>
<author>James G Shanahan</author>
</authors>
<title>Validating the coverage of lexical resources for affect analysis and automatically classifying new words along semantic axes.</title>
<date>2006</date>
<booktitle>Computing Attitude and Affect in Text: Theories and Applications,</booktitle>
<pages>93--107</pages>
<editor>In James G. Shanahan, Yan Qu, and Janyce Wiebe, editors,</editor>
<publisher>Springer,</publisher>
<location>Heidelberg, DE.</location>
<contexts>
<context position="2313" citStr="Grefenstette et al., 2006" startWordPosition="360" endWordPosition="363">f determining its opinion-related properties (ORPs). An important part of this research has been the work on the automatic determination of the ORPs of terms, as e.g., in determining whether an adjective tends to give a positive, a negative, or a neutral nature to the noun phrase it appears in. While many works (Esuli and Sebastiani, 2005; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003) view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opinion-related properties (Andreevskaia and Bergler, 2006a; Esuli and Sebastiani, 2006b; Ide, 2006; Wiebe and Mihalcea, 2006). In this paper we contribute to this latter literature with a novel method for ran</context>
</contexts>
<marker>Grefenstette, Qu, Evans, Shanahan, 2006</marker>
<rawString>Gregory Grefenstette, Yan Qu, David A. Evans, and James G. Shanahan. 2006. Validating the coverage of lexical resources for affect analysis and automatically classifying new words along semantic axes. In James G. Shanahan, Yan Qu, and Janyce Wiebe, editors, Computing Attitude and Affect in Text: Theories and Applications, pages 93–107. Springer, Heidelberg, DE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda H Harabagiu</author>
<author>George A Miller</author>
<author>Dan I Moldovan</author>
</authors>
<title>WordNet 2: A morphologically and semantically enhanced resource.</title>
<date>1999</date>
<booktitle>In Proceedings of the ACL SIGLEX Workshop on Standardizing Lexical Resources,</booktitle>
<pages>1--8</pages>
<location>College Park, US.</location>
<contexts>
<context position="4601" citStr="Harabagiu et al., 1999" startWordPosition="742" endWordPosition="745"> which induces a directed graph on the set of WordNet synsets, may be thought of as a channel through which positivity and negativity flow, from the definiendum (the synset si being defined) to the definiens (a synset sk that contributes to the definition of si by virtue of its member terms occurring in the gloss of si). In other words, if a synset si is known to be positive (negative), this can be viewed as an indication that the synsets sk to which the terms occurring in the gloss of si belong, are themselves positive (negative). We obtain the data of the No. relation from eXtended WordNet (Harabagiu et al., 1999), an automatically sense-disambiguated version of WordNet in which every term occurrence in every gloss is linked to the synset it is deemed to belong to. In order to compute how polarity flows in the graph of WordNet synsets we use the well known PageRank algorithm (Brin and Page, 1998). PageRank, a random-walk model for ranking Web search results which lies at the basis of the Google search engine, is probably the most important single contribution to the fields of information retrieval and Web search of the last ten years, and was originally devised in order to detect how authoritativeness </context>
<context position="13719" citStr="Harabagiu et al., 1999" startWordPosition="2355" endWordPosition="2358"> ORP. PageRank will thus make the ORP flow from the seed synsets, at a rate constant throughout the iterations, into other synsets along the No. relation, until a stable state is reached; the final az values can be used to rank the synsets in terms of that ORP. Our method thus requires two runs of PageRank; in the first e has nonnull scores for the positive seed synsets, while in the second the same happens for the negative ones. 3.2 eXtended WordNet The transformation of WordNet into a graph based on the No. relation would of course be nontrivial, but is luckily provided by eXtended WordNet (Harabagiu et al., 1999), a publicly available version of WordNet in which (among other things) each term sk occurring in a WordNet gloss (except those in example phrases) is lemmatized and mapped to the synset in which it belongs2. We use eXtended WordNet version 2.0-1.1, which refers to WordNet version 2.0. The eXtended WordNet resource has been automatically generated, which means that the associations between terms and synsets are likely to be sometimes incorrect, and this of course introduces noise in our method. 3.3 PageRank, (eXtended) WordNet, and ORP flow We now discuss the application of PageRank to ranking</context>
</contexts>
<marker>Harabagiu, Miller, Moldovan, 1999</marker>
<rawString>Sanda H. Harabagiu, George A. Miller, and Dan I. Moldovan. 1999. WordNet 2: A morphologically and semantically enhanced resource. In Proceedings of the ACL SIGLEX Workshop on Standardizing Lexical Resources, pages 1–8, College Park, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL’97),</booktitle>
<pages>174--181</pages>
<location>Madrid, ES.</location>
<contexts>
<context position="2064" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="320" endWordPosition="323">ct ONTOTEXT “From Text to Knowledge for the Semantic Web”, funded by the Provincia Autonoma di Trento under the 2004–2006 “Fondo Unico per la Ricerca” funding scheme. cipline that deals with the quantitative and qualitative analysis of text for the purpose of determining its opinion-related properties (ORPs). An important part of this research has been the work on the automatic determination of the ORPs of terms, as e.g., in determining whether an adjective tends to give a positive, a negative, or a neutral nature to the noun phrase it appears in. While many works (Esuli and Sebastiani, 2005; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003) view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different sen</context>
<context position="6698" citStr="Hatzivassiloglou and McKeown (1997)" startWordPosition="1091" endWordPosition="1094">Ps of lexical items, highlighting the similarities and differences between the discussed methods and our own. In Section 3 we turn to discussing our method; in order to make the paper self-contained, we start with a brief introduction of PageRank (Section 3.1) and of the structure of eXtended WordNet (Section 3.2). Section 4 describes the structure of our experiments, while Section 5 discusses the results we have obtained, comparing them with other results from the literature. Section 6 concludes. 2 Related work Several works have recently tackled the automated determination of term polarity. Hatzivassiloglou and McKeown (1997) determine the polarity of adjectives by mining pairs of conjoined adjectives from text, and observing that conjunctions such as and tend to conjoin adjectives of the same polarity while conjunctions such as but tend to conjoin adjectives of opposite polarity. Turney and Littman (2003) determine the polarity of generic terms by computing the pointwise mutual information (PMI) between the target term and each of a set of “seed” terms of known positivity or negativity, where the marginal and joint probabilities needed for PMI computation are equated to the fractions of documents from a given cor</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL’97), pages 174–181, Madrid, ES.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taher H Haveliwala</author>
</authors>
<title>Topic-sensitive PageRank: A context-sensitive ranking algorithm for Web search.</title>
<date>2003</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="12913" citStr="Haveliwala, 2003" startWordPosition="2208" endWordPosition="2209">nsult (Bianchini et al., 2005). In the original application of PageRank for ranking Web search results the elements of e are usually taken to be all equal to 1 |N|. However, it is possible � ai +- α (k) jEB(i) 426 to give different values to different elements in e. In fact, the value of ez amounts to an internal source of score for nz that is constant across the iterations and independent from its backward neighbours. For instance, attributing a null ez value to all but a few Web pages that are about a given topic can be used in order to bias the ranking of Web pages in favour of this topic (Haveliwala, 2003). In this work we use the ez values as internal sources of a given ORP (positivity or negativity), by attributing a null ez value to all but a few “seed” synsets known to possess that ORP. PageRank will thus make the ORP flow from the seed synsets, at a rate constant throughout the iterations, into other synsets along the No. relation, until a stable state is reached; the final az values can be used to rank the synsets in terms of that ORP. Our method thus requires two runs of PageRank; in the first e has nonnull scores for the positive seed synsets, while in the second the same happens for th</context>
</contexts>
<marker>Haveliwala, 2003</marker>
<rawString>Taher H. Haveliwala. 2003. Topic-sensitive PageRank: A context-sensitive ranking algorithm for Web search. IEEE Transactions on Knowledge and Data Engineering, 15(4):784–796.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
</authors>
<title>Making senses: Bootstrapping sense-tagged lists of semantically-related words.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th International Conference on Computational Linguistics and Intelligent Text Processing (CICLING’06),</booktitle>
<pages>13--27</pages>
<location>Mexico City, MX.</location>
<contexts>
<context position="2803" citStr="Ide, 2006" startWordPosition="440" endWordPosition="441">ical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opinion-related properties (Andreevskaia and Bergler, 2006a; Esuli and Sebastiani, 2006b; Ide, 2006; Wiebe and Mihalcea, 2006). In this paper we contribute to this latter literature with a novel method for ranking the entire set of WordNet synsets, irrespectively of POS, according to their ORPs. Two rankings are produced, one according to positivity and one according to negativity. The two rankings are independent, i.e., it is not the case that one is the inverse of the other, since e.g., the least positive synsets may be negative or neutral synsets alike. 424 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 424–431, Prague, Czech Republic, June </context>
<context position="9767" citStr="Ide, 2006" startWordPosition="1613" endWordPosition="1614">y of electron spins: two terms that appear one in the gloss of the other are viewed as akin to two neighbouring electrons, which tend to acquire the same “spin” (a notion viewed as akin to polarity) due to their being neighbours. This work is similar to ours since a graph between terms is generated from dictionary glosses, and since an iterative algorithm that converges to a stable state is used, but the algorithm is very different, and based on intuitions from very different walks of life. Some recent works have tackled the attribution of opinion-related properties to word senses or synsets (Ide, 2006; Wiebe and Mihalcea, 2006)1; however, they do not use glosses in any significant way, and are thus very different from our method. The interested reader may also consult (Mihalcea, 2006) for other applications of random-walk models to computational linguistics. 3 Ranking WordNet synsets by PageRank 3.1 The PageRank algorithm Let G = (N, L) be a directed graph, with N its set of nodes and L its set of directed links; let Wo be 1Andreevskaia and Berger (2006a) also work on term senses, rather than terms, but they evaluate their work on terms only. This is the reason why they are listed in the p</context>
</contexts>
<marker>Ide, 2006</marker>
<rawString>Nancy Ide. 2006. Making senses: Bootstrapping sense-tagged lists of semantically-related words. In Proceedings of the 7th International Conference on Computational Linguistics and Intelligent Text Processing (CICLING’06), pages 13–27, Mexico City, MX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaap Kamps</author>
<author>Maarten Marx</author>
<author>Robert J Mokken</author>
<author>Maarten De Rijke</author>
</authors>
<title>Using WordNet to measure semantic orientation of adjectives.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC’04), volume IV,</booktitle>
<pages>1115--1118</pages>
<location>Lisbon, PT.</location>
<marker>Kamps, Marx, Mokken, De Rijke, 2004</marker>
<rawString>Jaap Kamps, Maarten Marx, Robert J. Mokken, and Maarten De Rijke. 2004. Using WordNet to measure semantic orientation of adjectives. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC’04), volume IV, pages 1115–1118, Lisbon, PT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING’04),</booktitle>
<pages>1367--1373</pages>
<location>Geneva, CH.</location>
<contexts>
<context position="2333" citStr="Kim and Hovy, 2004" startWordPosition="364" endWordPosition="367">elated properties (ORPs). An important part of this research has been the work on the automatic determination of the ORPs of terms, as e.g., in determining whether an adjective tends to give a positive, a negative, or a neutral nature to the noun phrase it appears in. While many works (Esuli and Sebastiani, 2005; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003) view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opinion-related properties (Andreevskaia and Bergler, 2006a; Esuli and Sebastiani, 2006b; Ide, 2006; Wiebe and Mihalcea, 2006). In this paper we contribute to this latter literature with a novel method for ranking the entire set </context>
<context position="7572" citStr="Kim and Hovy (2004)" startWordPosition="1236" endWordPosition="1239">rity. Turney and Littman (2003) determine the polarity of generic terms by computing the pointwise mutual information (PMI) between the target term and each of a set of “seed” terms of known positivity or negativity, where the marginal and joint probabilities needed for PMI computation are equated to the fractions of documents from a given corpus that contain the terms, individually or jointly. Kamps et al. (2004) determine the polarity of adjectives by checking whether the target adjective is closer to the term good or to the term bad in the graph induced on WordNet by the synonymy relation. Kim and Hovy (2004) determine the polarity of generic terms by means of two alternative learning-free methods that use two sets of seed terms of known positivity and negativity, and are based on the frequency with which synonyms of the target term also appear in the respective seed sets. Among these works, (Turney and Littman, 2003) has proven by far the most effective, but it is also by far the most computationally intensive. Some recent works have employed, as in the present paper, the glosses from online dictionar425 ies for term polarity detection. Andreevskaia and Berger (2006a) extend a set of terms of kno</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2004. Determining the sentiment of opinions. In Proceedings of the 20th International Conference on Computational Linguistics (COLING’04), pages 1367–1373, Geneva, CH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>Random walks on text structures.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th International Conference on Computational Linguistics and Intelligent Text Processing (CICLING’06),</booktitle>
<pages>249--262</pages>
<location>Mexico City, MX.</location>
<contexts>
<context position="2830" citStr="Mihalcea, 2006" startWordPosition="444" endWordPosition="445"> either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opinion-related properties (Andreevskaia and Bergler, 2006a; Esuli and Sebastiani, 2006b; Ide, 2006; Wiebe and Mihalcea, 2006). In this paper we contribute to this latter literature with a novel method for ranking the entire set of WordNet synsets, irrespectively of POS, according to their ORPs. Two rankings are produced, one according to positivity and one according to negativity. The two rankings are independent, i.e., it is not the case that one is the inverse of the other, since e.g., the least positive synsets may be negative or neutral synsets alike. 424 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 424–431, Prague, Czech Republic, June 2007. c�2007 Association fo</context>
<context position="9794" citStr="Mihalcea, 2006" startWordPosition="1617" endWordPosition="1618">two terms that appear one in the gloss of the other are viewed as akin to two neighbouring electrons, which tend to acquire the same “spin” (a notion viewed as akin to polarity) due to their being neighbours. This work is similar to ours since a graph between terms is generated from dictionary glosses, and since an iterative algorithm that converges to a stable state is used, but the algorithm is very different, and based on intuitions from very different walks of life. Some recent works have tackled the attribution of opinion-related properties to word senses or synsets (Ide, 2006; Wiebe and Mihalcea, 2006)1; however, they do not use glosses in any significant way, and are thus very different from our method. The interested reader may also consult (Mihalcea, 2006) for other applications of random-walk models to computational linguistics. 3 Ranking WordNet synsets by PageRank 3.1 The PageRank algorithm Let G = (N, L) be a directed graph, with N its set of nodes and L its set of directed links; let Wo be 1Andreevskaia and Berger (2006a) also work on term senses, rather than terms, but they evaluate their work on terms only. This is the reason why they are listed in the preceding paragraph and not </context>
</contexts>
<marker>Mihalcea, 2006</marker>
<rawString>Rada Mihalcea. 2006. Random walks on text structures. In Proceedings of the 7th International Conference on Computational Linguistics and Intelligent Text Processing (CICLING’06), pages 249–262, Mexico City, MX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pero Subasic</author>
<author>Alison Huettner</author>
</authors>
<title>Affect analysis of text using fuzzy semantic typing.</title>
<date>2001</date>
<journal>IEEE Transactions on Fuzzy Systems,</journal>
<volume>9</volume>
<issue>4</issue>
<contexts>
<context position="2362" citStr="Subasic and Huettner, 2001" startWordPosition="368" endWordPosition="371">RPs). An important part of this research has been the work on the automatic determination of the ORPs of terms, as e.g., in determining whether an adjective tends to give a positive, a negative, or a neutral nature to the noun phrase it appears in. While many works (Esuli and Sebastiani, 2005; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003) view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opinion-related properties (Andreevskaia and Bergler, 2006a; Esuli and Sebastiani, 2006b; Ide, 2006; Wiebe and Mihalcea, 2006). In this paper we contribute to this latter literature with a novel method for ranking the entire set of WordNet synsets, irrespect</context>
</contexts>
<marker>Subasic, Huettner, 2001</marker>
<rawString>Pero Subasic and Alison Huettner. 2001. Affect analysis of text using fuzzy semantic typing. IEEE Transactions on Fuzzy Systems, 9(4):483–496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting emotional polarity of words using spin model.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>133--140</pages>
<location>Ann Arbor, US.</location>
<contexts>
<context position="2107" citStr="Takamura et al., 2005" startWordPosition="328" endWordPosition="331">”, funded by the Provincia Autonoma di Trento under the 2004–2006 “Fondo Unico per la Ricerca” funding scheme. cipline that deals with the quantitative and qualitative analysis of text for the purpose of determining its opinion-related properties (ORPs). An important part of this research has been the work on the automatic determination of the ORPs of terms, as e.g., in determining whether an adjective tends to give a positive, a negative, or a neutral nature to the noun phrase it appears in. While many works (Esuli and Sebastiani, 2005; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003) view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opi</context>
<context position="9083" citStr="Takamura et al. (2005)" startWordPosition="1492" endWordPosition="1495">in a semi-supervised way, a binary term classifier from a set of training terms that have been given vectorial representations by indexing their WordNet glosses. The same authors later extend their work to determining the ORPs of WordNet synsets (Esuli and Sebastiani, 2006b). However, there is a substantial difference between these works and the present one, in that the former simply view the glosses as sources of textual representations for the terms/synsets, and not as inducing a graph of synsets as we instead view them here. The work closest in spirit to the present one is probably that by Takamura et al. (2005), who determine the polarity of terms by applying intuitions from the theory of electron spins: two terms that appear one in the gloss of the other are viewed as akin to two neighbouring electrons, which tend to acquire the same “spin” (a notion viewed as akin to polarity) due to their being neighbours. This work is similar to ours since a graph between terms is generated from dictionary glosses, and since an iterative algorithm that converges to a stable state is used, but the algorithm is very different, and based on intuitions from very different walks of life. Some recent works have tackle</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting emotional polarity of words using spin model. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 133– 140, Ann Arbor, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Michael L Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="2134" citStr="Turney and Littman, 2003" startWordPosition="332" endWordPosition="335">cia Autonoma di Trento under the 2004–2006 “Fondo Unico per la Ricerca” funding scheme. cipline that deals with the quantitative and qualitative analysis of text for the purpose of determining its opinion-related properties (ORPs). An important part of this research has been the work on the automatic determination of the ORPs of terms, as e.g., in determining whether an adjective tends to give a positive, a negative, or a neutral nature to the noun phrase it appears in. While many works (Esuli and Sebastiani, 2005; Hatzivassiloglou and McKeown, 1997; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003) view the properties of positivity and negativity as categorical (i.e., a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opinion-related properties (An</context>
<context position="6984" citStr="Turney and Littman (2003)" startWordPosition="1136" endWordPosition="1139">rdNet (Section 3.2). Section 4 describes the structure of our experiments, while Section 5 discusses the results we have obtained, comparing them with other results from the literature. Section 6 concludes. 2 Related work Several works have recently tackled the automated determination of term polarity. Hatzivassiloglou and McKeown (1997) determine the polarity of adjectives by mining pairs of conjoined adjectives from text, and observing that conjunctions such as and tend to conjoin adjectives of the same polarity while conjunctions such as but tend to conjoin adjectives of opposite polarity. Turney and Littman (2003) determine the polarity of generic terms by computing the pointwise mutual information (PMI) between the target term and each of a set of “seed” terms of known positivity or negativity, where the marginal and joint probabilities needed for PMI computation are equated to the fractions of documents from a given corpus that contain the terms, individually or jointly. Kamps et al. (2004) determine the polarity of adjectives by checking whether the target adjective is closer to the term good or to the term bad in the graph induced on WordNet by the synonymy relation. Kim and Hovy (2004) determine t</context>
<context position="18514" citStr="Turney and Littman, 2003" startWordPosition="3181" endWordPosition="3184">WNOp is representative of WordNet with respect to the different parts of speech, in the sense that it contains synsets of the different parts of speech in the same proportions as in the entire WordNet. However, it is not representative of WordNet with respect to ORPs, since this would have brought about a corpus largely composed of neutral synsets, which would be pretty useless as a benchmark for testing automatically derived lexical resources for opinion mining. It was thus generated by randomly selecting 100 positive + 100 negative + 100 neutral terms from the General Inquirer lexicon (see (Turney and Littman, 2003) for details) and including all the synsets that contained 3http://www.unipv.it/wnop/ at least one such term, without paying attention to POS. See (Cerini et al., 2007) for more details. The corpus is divided into three parts: • Common: 110 synsets which all the evaluators evaluated by working together, so as to align their evaluation criteria. • Group1: 496 synsets which were each independently evaluated by three evaluators. • Group2: 499 synsets which were each independently evaluated by the other two evaluators. Each of these three parts has the same balance, in terms of both parts of speec</context>
<context position="24463" citStr="Turney and Littman, 2003" startWordPosition="4242" endWordPosition="4245">tivity or negativity; we have used it as a baseline in order to evaluate the impact of property-biased vectors. The first sensible, albeit minimalistic, definition of e we have used (dubbed e2) is that of a vector with uniform non-null ei scores assigned to the synsets that contain the adjective good (bad), and null scores for all other synsets. A further, still fairly minimalistic definition we have used (dubbed e3) is that of a vector with uniform non-null ei scores assigned to the synsets that contain at least one of the seven “paradigmatic” positive (negative) adjectives used as seeds in (Turney and Littman, 2003)4, and 5 Results The results show that the use of PageRank in combination with suitable vectors e almost always improves the ranking, sometimes significantly so, with respect to the original ranking embodied by the e vector. For positivity, the rankings produced using PageRank and any of the vectors from e2 to e5 all improve on the original rankings, with a relative improvement, measured as the relative decrease in Tp, positive, fortunate, correct, superior, and the seven negative ones are bad, nasty, poor, negative, unfortunate, wrong, inferior. 5http://sentiwordnet.isti.cnr.it/ 4The seven po</context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>Peter D. Turney and Michael L. Littman. 2003. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems, 21(4):315–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Word sense and subjectivity.</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics (ACL’06),</booktitle>
<pages>1065--1072</pages>
<location>Sydney, AU.</location>
<contexts>
<context position="2830" citStr="Wiebe and Mihalcea, 2006" startWordPosition="442" endWordPosition="445"> a term is either positive or it is not), others (Andreevskaia and Bergler, 2006b; Grefenstette et al., 2006; Kim and Hovy, 2004; Subasic and Huettner, 2001) view them as graded (i.e., a term may be positive to a certain degree), with the underlying interpretation varying from fuzzy to probabilistic. Some authors go a step further and attach these properties not to terms but to term senses (typically: WordNet synsets), on the assumption that different senses of the same term may have different opinion-related properties (Andreevskaia and Bergler, 2006a; Esuli and Sebastiani, 2006b; Ide, 2006; Wiebe and Mihalcea, 2006). In this paper we contribute to this latter literature with a novel method for ranking the entire set of WordNet synsets, irrespectively of POS, according to their ORPs. Two rankings are produced, one according to positivity and one according to negativity. The two rankings are independent, i.e., it is not the case that one is the inverse of the other, since e.g., the least positive synsets may be negative or neutral synsets alike. 424 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 424–431, Prague, Czech Republic, June 2007. c�2007 Association fo</context>
<context position="9794" citStr="Wiebe and Mihalcea, 2006" startWordPosition="1615" endWordPosition="1618">on spins: two terms that appear one in the gloss of the other are viewed as akin to two neighbouring electrons, which tend to acquire the same “spin” (a notion viewed as akin to polarity) due to their being neighbours. This work is similar to ours since a graph between terms is generated from dictionary glosses, and since an iterative algorithm that converges to a stable state is used, but the algorithm is very different, and based on intuitions from very different walks of life. Some recent works have tackled the attribution of opinion-related properties to word senses or synsets (Ide, 2006; Wiebe and Mihalcea, 2006)1; however, they do not use glosses in any significant way, and are thus very different from our method. The interested reader may also consult (Mihalcea, 2006) for other applications of random-walk models to computational linguistics. 3 Ranking WordNet synsets by PageRank 3.1 The PageRank algorithm Let G = (N, L) be a directed graph, with N its set of nodes and L its set of directed links; let Wo be 1Andreevskaia and Berger (2006a) also work on term senses, rather than terms, but they evaluate their work on terms only. This is the reason why they are listed in the preceding paragraph and not </context>
</contexts>
<marker>Wiebe, Mihalcea, 2006</marker>
<rawString>Janyce Wiebe and Rada Mihalcea. 2006. Word sense and subjectivity. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics (ACL’06), pages 1065–1072, Sydney, AU.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>