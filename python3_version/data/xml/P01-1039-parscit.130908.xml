<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001362">
<title confidence="0.961193">
Information Extraction From Voicemail
</title>
<author confidence="0.637742666666667">
Jing Huang and Geoffrey Zweig and Mukund Padmanabhan
IBM T. J. Watson Research Center
Yorktown Heights, NY 10598
</author>
<affiliation confidence="0.797109">
USA
</affiliation>
<email confidence="0.988837">
jhuang, gzweig, mukund@watson.ibm.com
</email>
<sectionHeader confidence="0.995665" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999687904761905">
In this paper we address the problem
of extracting key pieces of information
from voicemail messages, such as the
identity and phone number of the caller.
This task differs from the named entity
task in that the information we are inter-
ested in is a subset of the named entities
in the message, and consequently, the
need to pick the correct subset makes
the problem more difficult. Also, the
caller’s identity may include informa-
tion that is not typically associated with
a named entity. In this work, we present
three information extraction methods,
one based on hand-crafted rules, one
based on maximum entropy tagging,
and one based on probabilistic trans-
ducer induction. We evaluate their per-
formance on both manually transcribed
messages and on the output of a speech
recognition system.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999924044444445">
In recent years, the task of automatically extract-
ing information from data has grown in impor-
tance, as a result of an increase in the number of
publicly available archives and a realization of the
commercial value of the available data. One as-
pect of information extraction (IE) is the retrieval
of documents. Another aspect is that of identify-
ing words from a stream of text that belong in pre-
defined categories, for instance, “named entities”
such as proper names, organizations, or numerics.
Though most of the earlier IE work was done in
the context of text sources, recently a great deal of
work has also focused on extracting information
from speech sources. Examples of this are the
Spoken Document Retrieval (SDR) task (NIST,
1999), named entity (NE) extraction (DARPA,
1999; Miller et al., 2000; Kim and Woodland,
2000). The SDR task focused on Broadcast News
and the NE task focused on both Broadcast News
and telephone conversations.
In this paper, we focus on a source of con-
versational speech data, voicemail, that is found
in relatively large volumes in the real-world, and
that could benefit greatly from the use of IE tech-
niques. The goal here is to query one’s personal
voicemail for items of information, without hav-
ing to listen to the entire message. For instance,
“who called today?”, or “what is X’s phone num-
ber?”. Because of the importance of these key
pieces of information, in this paper, we focus pre-
cisely on extracting the identity and the phone
number of the caller. Other attempts at sum-
marizing voicemail have been made in the past
(Koumpis and Renals, 2000), however the goal
there was to compress a voicemail message by
summarizing it, and not to extract the answers to
specific questions.
An interesting aspect of this research is that be-
cause a transcription of the voicemail is not avail-
able, speech recognition algorithms have to be
used to convert the speech to text and the sub-
sequent IE algorithms must operate on the tran-
scription. One of the complications that we have
to deal with is the fact that the state-of-the-art ac-
curacy of speech recognition algorithms on this
type of data 1 is only in the neighborhood of 60-
70% (Huang et al., 2000).
The task that is most similar to our work
is named entity extraction from speech data
(DARPA, 1999). Although the goal of the named
entity task is similar - to identify the names of per-
sons, locations, organizations, and temporal and
numeric expressions - our task is different, and
in some ways more difficult. There are two main
reasons for this: first, caller and number informa-
tion constitute a small fraction of all named enti-
ties. Not all person-names belong to callers, and
not all digit strings specify phone-numbers. In
this sense, the algorithms we use must be more
precise than those for named entity detection.
Second, the caller’s identity may include infor-
mation that is not typically found in a named en-
tity, for example, “Joe on the third floor”, rather
than simply “Joe”. We discuss our definitions of
“caller” and “number” in Section 2.
To extract caller information from transcribed
speech text, we implemented three different sys-
tems, spanning both statistical and non-statistical
approaches. We evaluate these systems on man-
ual voicemail transcriptions as well as the out-
put of a speech recognizer. The first system is a
simple rule-based system that uses trigger phrases
to identify the information-bearing words. The
second system is a maximum entropy model that
tags the words in the transcription as belong-
ing to one of the categories, “caller’s identity”,
“phone number” or “other”. The third system is
a novel technique based on automatic stochastic-
transducer induction. It aims to learn rules auto-
matically from training data instead of requiring
hand-crafted rules from experts. Although the re-
sults with this system are not yet as good as the
other two, we consider it highly interesting be-
cause the technology is new and still open to sig-
nificant advances.
The rest of the paper is organized as follows:
Section 2 describes the database we are using;
Section 3 contains a description of the baseline
system; Section 4 describes the maximum en-
tropy model and the associated features; Section
</bodyText>
<footnote confidence="0.7146706">
1The large word error rate is due to the fact that the
speech is spontaneous, and characterized by poor grammar,
false starts, pauses, hesitations, etc. While this does not pose
a problem for a human listener, it causes significant prob-
lems for speech recognition algorithms.
</footnote>
<bodyText confidence="0.840355333333333">
5 discusses the transducer induction technique;
Section 6 contains our experimental results and
Section 7 concludes our discussions.
</bodyText>
<sectionHeader confidence="0.924628" genericHeader="method">
2 The Database
</sectionHeader>
<bodyText confidence="0.999691222222222">
Our work focuses on a database of voicemail mes-
sages gathered at IBM, and made publicly avail-
able through the LDC. This database and related
speech recognition work is described fully by
(Huang et al., 2000). We worked with approx-
imately messages, which we divided into
messages for training, for develop-
ment test set, and for evaluation test set. The
messages were manually transcribed 2, and then
a human tagger identified the portions of each
message that specified the caller and any return
numbers that were left. In this work, we take a
broad view of what constitutes a caller or num-
ber. The caller was defined to be the consecutive
sequence of words that best answered the ques-
tion “who called?”. The definition of a number
we used is a sequence of consecutive words that
enables a return call to be placed. Thus, for ex-
ample, a caller might be “Angela from P.C. Labs,”
or “Peggy Cole Reed Balla’s secretary”. Simi-
larly, a number may not be a digit string, for ex-
ample: “tieline eight oh five six,” or “pager one
three five”. No more than one caller was identi-
fied for a single message, though there could be
multiple numbers. The training of the maximum
entropy model and statistical transducer are done
on these annotated scripts.
</bodyText>
<sectionHeader confidence="0.979408" genericHeader="method">
3 A Baseline Rule-Based System
</sectionHeader>
<bodyText confidence="0.999214538461539">
In voicemail messages, people often identify
themselves and give their phone numbers in
highly stereotyped ways. So for example, some-
one might say, “Hi Joe it’s Harry...” or “Give
me a call back at extension one one eight four.”
Our baseline system takes advantage of this fact
by enumerating a set of transduction rules - in the
form of aflex program - that transduce out the key
information in a call.
The baseline system is built around the notion
of “trigger phrases”. These hand-crafted phases
are patterns that are used in the flex program to
recognize caller’s identity and phone numbers.
</bodyText>
<footnote confidence="0.718233">
2The manual transcription has a word error rate
</footnote>
<bodyText confidence="0.999513692307692">
Examples of trigger phrases are “Hi this is”, and
“Give me a call back at”. In order to identify
names and phone numbers as generally as pos-
sible, our baseline system has defined classes for
person-names and numbers.
In addition to trigger phrases, “trigger suf-
fixes” proved to be useful for identifying phone
numbers. For example, the phrase “thanks bye”
frequently occurs immediately after the caller’s
phone number. In general, a random sequence of
digits cannot be labeled as a phone number; but,
a sequence of digits followed by “thanks bye” is
almost certainly the caller’s phone number. So
when the flex program matches a sequence of dig-
its, it stores it; then it tries to match a trigger suf-
fix. If this is successful, the digit string is recog-
nized a phone number string. Otherwise the digit
string is ignored.
Our baseline system has about 200 rules. Its
creation was aided by an automatically generated
list of short, commonly occurring phrases that
were then manually scanned, generalized, and
added to the flex program. It is the simplest of
the systems presented, and achieves a good per-
formance level, but suffers from the fact that a
skilled person is required to identify the rules.
</bodyText>
<sectionHeader confidence="0.996262" genericHeader="method">
4 Maximum Entropy Model
</sectionHeader>
<bodyText confidence="0.99987372">
Maximum entropy modeling is a powerful frame-
work for constructing statistical models from
data. It has been used in a variety of difficult
classification tasks such as part-of-speech tagging
(Ratnaparkhi, 1996), prepositional phrase attach-
ment (Ratnaparkhi et al., 1994) and named en-
tity tagging (Borthwick et al., 1998), and achieves
state of the art performance. In the following, we
briefly describe the application of these models
to extracting caller’s information from voicemail
messages.
The problem of extracting the information per-
taining to the callers identity and phone number
can be thought of as a tagging problem, where the
tags are “caller’s identity,” “caller’s phone num-
ber” and “other.” The objective is to tag each
word in a message into one of these categories.
The information that can be used to predict a
word’s tag is the identity of the surrounding words
and their associated tags. Let denote the set
of possible word and tag contexts, called “histo-
ries”, and denote the set of tags. The maxent
model is then defined over ,and predicts
the conditional probability for a tag given
the history . The computation of this probabil-
ity depends on a set of binary-valued “features”
.
Given some training data and a set of features
the maximum entropy estimation procedure com-
putes a weight parameter for every feature
and parameterizes as follows:
where is a normalization constant.
The role of the features is to identify charac-
teristics in the histories that are strong predictors
of specific tags. (for example, the tag “caller” is
very often preceded by the word sequence “this
is”). If a feature is a very strong predictor of a
particular tag, then the corresponding would
be high. It is also possible that a particular fea-
ture may be a strong predictor of the absence of
a particular tag, in which case the associated
would be near zero.
Training a maximum entropy model involves
the selection of the features and the subsequent
estimation of weight parameters . The testing
procedure involves a search to enumerate the can-
didate tag sequences for a message and choos-
ing the one with highest probability. We use the
“beam search” technique of (Ratnaparkhi, 1996)
to search the space of all hypotheses.
</bodyText>
<subsectionHeader confidence="0.925544">
4.1 Features
</subsectionHeader>
<bodyText confidence="0.980187083333333">
Designing effective features is crucial to the max-
ent model. In the following sections, we de-
scribe the various feature functions that we ex-
perimented with. We first preprocess the text in
the following ways: (1) map rare words (with
counts less than ) to the symbol “UNKNOWN”;
(2) map words in a name dictionary to the sym-
bol “NAME.” The first step is a way to handle out
of vocabulary words in test data; the second step
takes advantage of known names. This mapping
makes the model focus on learning features which
help to predict the location of the caller identity
and leave the actual specific names later for ex-
traction.
4.1.1 Unigram lexical features
To compute unigram lexical features, we used
the neighboring two words, and the tags associ-
ated with the previous two words to define the
history as
The features are generated by scanning each
pair in the training data with feature tem-
plate in Table 1. Note that although the window is
two words on either side, the features are defined
in terms of the value of a single word.
</bodyText>
<table confidence="0.96272475">
Features
&amp;
&amp;
&amp;
&amp;
&amp;
&amp;
&amp;
</table>
<tableCaption confidence="0.961736">
Table 1: Unigram features of the current history
.
</tableCaption>
<subsectionHeader confidence="0.447653">
4.1.2 Bigram lexical features
</subsectionHeader>
<bodyText confidence="0.980862888888889">
The trigger phrases used in the rule-based ap-
proach generally consist of several words, and
turn out to be good predictors of the tags. In order
to incorporate this information in the maximum
entropy framework, we decided to use ngrams
that occur in the surrounding word context to gen-
erate features. Due to data sparsity and computa-
tional cost, we restricted ourselves to using only
bigrams. The bigram feature template is shown in
</bodyText>
<tableCaption confidence="0.980692">
Table 2.
</tableCaption>
<table confidence="0.999691375">
Features
&amp;
&amp;
&amp;
&amp;
&amp;
&amp;
&amp;
</table>
<tableCaption confidence="0.995117">
Table 2: Bigram features of the current history .
</tableCaption>
<subsubsectionHeader confidence="0.601412">
4.1.3 Dictionary features
</subsubsectionHeader>
<bodyText confidence="0.999762583333333">
First, a number dictionary is used to scan the
training data and generate a code for each word
which represents “number” or “other”. Sec-
ond, a multi-word dictionary is used to match
known pre-caller trigger prefixes and after-phone-
number trigger suffixes. The same code is as-
signed to each word in the matched string as ei-
ther “pre-caller” or “after-phone-number”. The
combined stream of codes is added to the history
and used to generate features the same way the
word sequence are used to generate lexical fea-
tures.
</bodyText>
<subsectionHeader confidence="0.966762">
4.2 Feature selection
</subsectionHeader>
<bodyText confidence="0.999456642857143">
In general, the feature templates define a very
large number of features, and some method is
needed to select only the most important ones. A
simple way of doing this is to discard the fea-
tures that are rarely seen in the data. Discard-
ing all features with fewer than occurrences
resulted in about features. We also ex-
perimented with a more sophisticated incremen-
tal scheme. This procedure starts with no features
and a uniform distribution , and sequen-
tially adds the features that most increase the data
likelihood. The procedure stops when the gain
in likelihood on a cross-validation set becomes
small.
</bodyText>
<sectionHeader confidence="0.993524" genericHeader="method">
5 Transducer Induction
</sectionHeader>
<bodyText confidence="0.999817222222222">
Our baseline system is essentially a hand speci-
fied transducer, and in this section, we describe
how such an item can be automatically induced
from labeled training data. The overall goal
is to take a set of labeled training examples in
which the caller and number information has been
tagged, and to learn a transducer such that when
voicemail messages are used as input, the trans-
ducer emits only the information-bearing words.
First we will present a brief description of how an
automaton structure for voicemail messages can
be learned from examples, and then we describe
how to convert this to an appropriate transducer
structure. Finally, we extend this process so that
the training procedure acts hierarchically on dif-
ferent portions of the messages at different times.
In contrast to the baseline flex system, the trans-
ducers that we induce are nondeterministic and
</bodyText>
<figureCaption confidence="0.983566">
Figure 1: Graph structure before and after a
merge.
</figureCaption>
<bodyText confidence="0.869627666666667">
stochastic – a given word sequence may align to
multiple paths through the transducer. In the case
that multiple alignments are possible, the lowest
cost transduction is preferred, with the costs being
determined by the transition probabilities encoun-
tered along the paths.
</bodyText>
<subsectionHeader confidence="0.989382">
5.1 Inducing Finite State Automata
</subsectionHeader>
<bodyText confidence="0.999984236842105">
Many techniques have evolved for inducing finite
state automata from word sequences, e.g. (Oncina
and Vidal, 1993; Stolcke and Omohundro, 1994;
Ron et al., 1998), and we chose to adapt the tech-
nique of (Ron et al., 1998). This is a simple
method for inducing acyclic automata, and is at-
tractive because of its simplicity and theoretical
guarantees. Here we present only an abbreviated
description of our implementation, and refer the
reader to (Ron et al., 1998) for a full description
of the original algorithm. In (Appelt and Martin,
1999), finite state transducers were also used for
named entity extraction, but they were hand spec-
ified.
The basic idea of the structure induction algo-
rithm is to start with a prefix tree, where arcs are
labeled with words, that exactly represents all the
word sequences in the training data, and then to
gradually transform it, by merging internal states,
into a directed acyclic graph that represents a gen-
eralization of the training data. An example of a
merge operation is shown in Figure 1.
The decision to merge two nodes is based on
the fact that a set of strings is rooted in each node
of the tree, specified by the paths to all the reach-
able leaf nodes. A merge of two nodes is permis-
sible when the corresponding sets of strings are
statistically indistinguishable from one another.
The precise definition of statistical similarity can
be found in (Ron et al., 1998), and amounts to
deeming two nodes indistinguishable unless one
of them has a frequently occurring suffix that is
rarely seen in the other. The exact ordering in
which we merged nodes is a variant of the process
described in (Ron et al., 1998) 3. The transition
probabilities are determined by aligning the train-
ing data to the induced automaton, and counting
the number of times each arc is used.
</bodyText>
<subsectionHeader confidence="0.999312">
5.2 Conversion to a Transducer
</subsectionHeader>
<bodyText confidence="0.999866916666667">
Once a structure is induced for the training data,
it can be converted into an information extract-
ing transducer in a straightforward manner. When
the automaton is learned, we keep track of which
words were found in information-bearing por-
tions of the call, and which were not. The struc-
ture of the transducer is identical to that of the au-
tomaton, but each arc makes a transduction. If the
arc is labeled with a word that was information-
bearing in the training data, then the word itself is
transduced out; otherwise, an epsilon is trans-
duced.
</bodyText>
<subsectionHeader confidence="0.999509">
5.3 Hierarchical Structure Induction
</subsectionHeader>
<bodyText confidence="0.999105">
Conceptually, it is possible to induce a structure
for voicemail messages in one step, using the al-
gorithm described in the previous sections. In
practice, we have found that this is a very diffi-
cult problem, and that it is expedient to break it
into a number of simpler sub-problems. This has
led us to develop a three-step induction process in
which only short segments of text are processed
at once.
First, all the examples of phone numbers are
gathered together, and a structure is induced.
Similarly, all the examples of caller’s identities
are collected, and a structure is induced for them
To further simplify the task, we replaced number
strings by the single symbol “NUMBER+”, and
person-names by the symbol “PERSON-NAME”.
The transition costs for these structures are esti-
mated by aligning the training data, and counting
</bodyText>
<footnote confidence="0.977531714285714">
3A frontier of nodes is maintained, and is initialized to
the children of the root. The weight of a node is defined as
the number of strings rooted in it. At each step, the heaviest
node is removed, and an attempt is made to merge it with an-
other fronteir node, in order of decreasing weight. If a merge
is possible, the result is placed on the frontier; otherwise, the
heaviest node’s children are added.
</footnote>
<figure confidence="0.997402791666667">
1
1
Hi
Hey
it’
s
Hi Hey
it’s
2
5
8
2
6
I
Joe
I Sally
I
Joe
Sally
3
4 6 7
3
4
5
</figure>
<figureCaption confidence="0.981107">
Figure 2: Induced structure for phone numbers (top), and a sub-graph of the second-level “number-
segment” structure in which it is embedded (bottom). For clarity, transition probabilities are not dis-
played.
</figureCaption>
<figure confidence="0.991771209302326">
NUMBER+
pager
area
country
2
code
toll
6
free
1
extension
beeper
home
tieline
4
NUMBER+
NUMBER+
extension
3
option
7
NUMBER+
9
8
outside
tie
5
line
external
call
reach 2
1
me
thanks
6
bye
7
I’m
3
at PHONE-NUMBER-STRUCTURE
4 5
ciao
8
</figure>
<bodyText confidence="0.994188258064516">
the number of times the different transitions out
of each state are taken. A phone number structure
induced in this way from a subset of the data is
shown at the top of Figure 2.
In the second step, occurrences of names and
numbers are replaced by single symbols, and the
segments of text immediately surrounding them
are extracted. This results in a database of ex-
amples like “Hi PERSON-NAME it’s CALLER-
STRUCTURE I wanted to ask you”, or “call me
at NUMBER-STRUCTURE thanks bye”. In this
example, the three words immediately preced-
ing and following the number or caller are used.
Using this database, a structure is induced for
these segments of text, and the result is essen-
tially an induced automaton that represents the
trigger phrases that were manually identified in
the baseline system. A small second level struc-
ture is shown at the bottom of Figure 2.
In the third step, the structure of a background
language model is induced. The structures dis-
covered in these three steps are then combined
into a single large automaton that allows any se-
quence of caller, number, and background seg-
ments. For the system we used in our experi-
ments, we used a unigram language model as the
background. In the case that information-bearing
patterns exist in the input, it is desirable for paths
through the non-background portions of the final
automaton to have a lower cost, and this is most
likely with a high perplexity background model.
</bodyText>
<sectionHeader confidence="0.988505" genericHeader="evaluation">
6 Experimental Results
</sectionHeader>
<bodyText confidence="0.999140266666667">
To evaluate the performance of different systems,
we use the conventional precision, recall and
their F-measure. Significantly, we insist on exact
matches for an answer to be counted as correct.
The reason for this is that any error is liable to ren-
der the information useless, or detrimental. For
example, an incorrect phone number can result in
unwanted phone charges, and unpleasant conver-
sations. This is different from typical named en-
tity evaluation, where partial matches are given
partial credit. Therefore, it should be understood
that the precision and recall rates computed with
this strict criterion cannot be compared to those
from named entity detection tasks.
A summary of our results is presented in Tables
</bodyText>
<table confidence="0.999778">
P/C R/C F/C P/N R/N F/N
baseline 73 68 70 81 83 82
ME1-U 88 75 81 90 78 84
ME1-B 89 80 84 88 78 83
ME2-U-f1 88 76 81 90 82 86
ME2-U-f12 87 78 82 90 83 86
ME2-B-f12 88 80 84 89 83 86
ME2-U-f12-I 87 78 82 89 81 85
ME2-B-f12-I 87 79 83 90 82 86
Transduction 21 43 29 52 78 63
</table>
<tableCaption confidence="0.9560375">
Table 3: Precision and recall rates for different
systems on manual voicemail transcriptions.
</tableCaption>
<table confidence="0.999694333333333">
P/C R/C F/C P/N R/N F/N
baseline 22 17 19 52 54 53
ME2-U-f1 24 16 19 56 52 54
</table>
<tableCaption confidence="0.971687">
Table 4: Precision and recall rates for different
systems on decoded voicemail messages.
</tableCaption>
<bodyText confidence="0.9961712">
3 and 4. Table 3 presents precision and recall rates
when manual word transcriptions are used; Table
4 presents these numbers when speech recogni-
tion transcripts are used. On the heading line, P
refers to precision, R to recall, F to F-measure, C
to caller-identity, and N to phone number. Thus
P/C denotes “precision on caller identity”.
In these tables, the maximum entropy model
is referred to as ME. ME1-U uses unigram lex-
ical features only; ME1-B uses bigram lexical
features only. ME1-B performs somewhat better
than ME1-U, but uses more than double number
of features.
ME2-U-f1 uses unigram lexical features and
number dictionary features. It improves the recall
of phone number by upon ME1-U. ME2-
U-f12 adds the trigger phrase dictionary features
to ME2-U-f1, and it improves the recall of caller
and phone numbers but degrades on the preci-
sion of both. Overall it improves a little on the
F-meansures. ME2-B-f12 uses bigram lexical
features, number dictionary features and trigger
phrase dictionary features. It has the best recall of
caller, again with over two times number of fea-
tures of ME2-U-f12.
The above variants of ME features are chosen
using simple count cutoff method. When the in-
cremental feature selection is used, ME2-U-f12-I
reduces the number of features from to
with minor performance loss; ME2-B-f12-I re-
</bodyText>
<table confidence="0.994338666666667">
P/C R/C F/C P/N R/N F/N
baseline 66 66 66 71 72 71
ME2-U-f1 83 72 77 84 81 83
</table>
<tableCaption confidence="0.940117666666667">
Table 5: Precision and recall rates for differ-
ent systems on replaced decoded voicemail mes-
sages.
</tableCaption>
<table confidence="0.999661">
P/C R/C F/C P/N R/N F/N
baseline 77 36 49 85 76 80
ME2-U-f1 73 41 52 85 79 82
</table>
<tableCaption confidence="0.985853">
Table 6: Precision and recall of time-overlap
</tableCaption>
<bodyText confidence="0.990080777777778">
for different systems on decoded voicemail mes-
sages.
duces the number of features from to
with minor performance loss. This shows that the
main power of the maxent model comes from a a
very small subset of the possible features. Thus, if
memory and speed are concerned, the incremen-
tal feature selection is highly recommended.
There are several observations that can be made
from these results. First, the maximum en-
tropy approach systematically beats the baseline
in terms of precision, and secondly it is better on
recall of the caller’s identity. We believe this is
because the baseline has an imperfect set of rules
for determining the end of a “caller identity” de-
scription. On the other hand, the baseline system
has higher recall for phone numbers. The results
of structure induction are worse than the other two
methods, however as this is a novel approach in a
developmental stage, we expect the performance
will improve in the future.
Another important point is that there is a signif-
icant difference in performance between manual
and decoded transcriptions. As expected, the pre-
cision and recall numbers are worse in the pres-
ence of transcription errors (the recognizer had a
word error rate of about 35%). The degradation
due to transcription errors could be caused by ei-
ther: (i) corruption of words in the context sur-
rounding the names and numbers; or (ii) corrup-
tion of the information itself. To investigate this,
we did the following experiment: we replaced the
regions of decoded text that correspond to the cor-
rect caller identity and phone number with the
correct manual transcription, and redid the test.
The results are shown in Table 5. Compared to
the results on the manual transcription, the recall
numbers for the maximum-entropy tagger are just
slightly ( ) worse, and precision is still high.
This indicates that the corruption of the informa-
tion content due to transcription errors is much
more important than the corruption of the context.
If measured by the string error rate, none of
our systems can be used to extract exact caller
and phone number information directly from de-
coded voicemail. However, they can be used to
locate the information in the message and high-
light those positions. To evaluate the effective-
ness of this approach, we computed precision and
recall numbers in terms of the temporal overlap
of the identified and true information bearing seg-
ments. Table 6 shows that the temporal loca-
tion of phone numbers can be reliably determined,
with an F-measure of 80%.
</bodyText>
<sectionHeader confidence="0.998828" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999970952380952">
In this paper, we have developed several tech-
niques for extracting key pieces of information
from voicemail messages. In contrast to tradi-
tional named entity tasks, we are interested in
identifying just a selected subset of the named
entities that occur. We implemented and tested
three methods on manual transcriptions and tran-
scriptions generated by a speech recognition sys-
tem. For a baseline, we used aflex program with a
set of hand-specified information extraction rules.
Two statistical systems are compared to the base-
line, one based on maximum entropy modeling,
and the other on transducer induction. Both the
baseline and the maximum entropy model per-
formed well on manually transcribed messages,
while the structure induction still needs improve-
ment. Although performance degrades signifi-
cantly in the presence of speech racognition er-
rors, it is still possible to reliably determine the
sound segments corresponding to phone num-
bers.
</bodyText>
<sectionHeader confidence="0.999244" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999608527272727">
Douglas E. Appelt and David Martin. 1999. Named
entity extraction from speech: Approach and re-
sults using the textpro system. In Proceedings of
the DARPA Broadcast News Workshop (DARPA,
1999).
Andrew Borthwick, John Sterling, Eugene Agichtein,
and Ralph Grishman. 1998. Nyu: Descrip-
tion of the mene named entity system as used
in MUC-7. In Seventh Message Understanding
Conference(MUC-7). ARPA.
DARPA. 1999. Proceedings of the DARPA Broadcast
News Workshop.
J. Huang, B. Kingsbury, L. Mangu, M. Padmanabhan,
G. Saon, and G. Zweig. 2000. Recent improve-
ments in speech recognition performance on large
vocabulary conversational speech (voicemail and
switchboard). In Sixth International Conference on
Spoken Language Processing, Beijing, China.
Ji-Hwan Kim and P.C. Woodland. 2000. A rule-based
named entity recognition system for speech input.
In Sixth International Conference on Spoken Lan-
guage Processing, Beijing, China.
Konstantinos Koumpis and Steve Renals. 2000. Tran-
scription and summarization of voicemail speech.
In Sixth International Conference on Spoken Lan-
guage Processing, Beijing, China.
David Miller, Sean Boisen, Richard Schwartz, Re-
becca Stone, and Ralph Weischedel. 2000. Named
entity extraction from noisy input: Speech and ocr.
In Proceedings ofANLP-NAACL 2000, pages 316–
324.
NIST. 1999. Proceedings of the Eighth Text REtrieval
Conference (TREC-8).
Jose Oncina and Enrique Vidal. 1993. Learning sub-
sequential transducers for pattern recognition in-
terpretation tasks. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 15(5):448–458.
Adwait Ratnaparkhi, Jeff Reynar, and Salim Roukos.
1994. A Maximum Entropy Model for Prepo-
sitional Phrase Attachment. In Proceedings of
the Human Language Technology Workshop, pages
250–255, Plainsboro, N.J. ARPA.
Adwait Ratnaparkhi. 1996. A Maximum Entropy
Part of Speech Tagger. In Eric Brill and Kenneth
Church, editors, Conference on Empirical Meth-
ods in Natural Language Processing, University of
Pennsylvania, May 17–18.
Dana Ron, Yoram Singer, and Naftali Tishby. 1998.
On the learnability and usage of acyclic probabilis-
tic finite automata. Journal of Computer and Sys-
tem Sciences, 56(2).
Andreas Stolcke and Stephen M. Omohundro. 1994.
Best-first model merging for hidden markov model
induction. Technical Report TR-94-003, Interna-
tional Computer Science Institute.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.977868">
<title confidence="0.999536">Information Extraction From Voicemail</title>
<author confidence="0.999296">Huang Zweig Padmanabhan</author>
<affiliation confidence="0.99993">IBM T. J. Watson Research Center</affiliation>
<address confidence="0.9952365">Yorktown Heights, NY 10598 USA</address>
<email confidence="0.999723">jhuang,gzweig,mukund@watson.ibm.com</email>
<abstract confidence="0.999477772727273">In this paper we address the problem of extracting key pieces of information from voicemail messages, such as the identity and phone number of the caller. This task differs from the named entity task in that the information we are interested in is a subset of the named entities in the message, and consequently, the need to pick the correct subset makes the problem more difficult. Also, the caller’s identity may include information that is not typically associated with a named entity. In this work, we present three information extraction methods, one based on hand-crafted rules, one based on maximum entropy tagging, and one based on probabilistic transducer induction. We evaluate their performance on both manually transcribed messages and on the output of a speech recognition system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas E Appelt</author>
<author>David Martin</author>
</authors>
<title>Named entity extraction from speech: Approach and results using the textpro system.</title>
<date>1999</date>
<booktitle>In Proceedings of the DARPA Broadcast News Workshop (DARPA,</booktitle>
<contexts>
<context position="15652" citStr="Appelt and Martin, 1999" startWordPosition="2633" endWordPosition="2636">tion probabilities encountered along the paths. 5.1 Inducing Finite State Automata Many techniques have evolved for inducing finite state automata from word sequences, e.g. (Oncina and Vidal, 1993; Stolcke and Omohundro, 1994; Ron et al., 1998), and we chose to adapt the technique of (Ron et al., 1998). This is a simple method for inducing acyclic automata, and is attractive because of its simplicity and theoretical guarantees. Here we present only an abbreviated description of our implementation, and refer the reader to (Ron et al., 1998) for a full description of the original algorithm. In (Appelt and Martin, 1999), finite state transducers were also used for named entity extraction, but they were hand specified. The basic idea of the structure induction algorithm is to start with a prefix tree, where arcs are labeled with words, that exactly represents all the word sequences in the training data, and then to gradually transform it, by merging internal states, into a directed acyclic graph that represents a generalization of the training data. An example of a merge operation is shown in Figure 1. The decision to merge two nodes is based on the fact that a set of strings is rooted in each node of the tre</context>
</contexts>
<marker>Appelt, Martin, 1999</marker>
<rawString>Douglas E. Appelt and David Martin. 1999. Named entity extraction from speech: Approach and results using the textpro system. In Proceedings of the DARPA Broadcast News Workshop (DARPA, 1999).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Borthwick</author>
<author>John Sterling</author>
<author>Eugene Agichtein</author>
<author>Ralph Grishman</author>
</authors>
<title>Nyu: Description of the mene named entity system as used in MUC-7.</title>
<date>1998</date>
<booktitle>In Seventh Message Understanding Conference(MUC-7).</booktitle>
<publisher>ARPA.</publisher>
<contexts>
<context position="9106" citStr="Borthwick et al., 1998" startWordPosition="1522" endWordPosition="1525"> short, commonly occurring phrases that were then manually scanned, generalized, and added to the flex program. It is the simplest of the systems presented, and achieves a good performance level, but suffers from the fact that a skilled person is required to identify the rules. 4 Maximum Entropy Model Maximum entropy modeling is a powerful framework for constructing statistical models from data. It has been used in a variety of difficult classification tasks such as part-of-speech tagging (Ratnaparkhi, 1996), prepositional phrase attachment (Ratnaparkhi et al., 1994) and named entity tagging (Borthwick et al., 1998), and achieves state of the art performance. In the following, we briefly describe the application of these models to extracting caller’s information from voicemail messages. The problem of extracting the information pertaining to the callers identity and phone number can be thought of as a tagging problem, where the tags are “caller’s identity,” “caller’s phone number” and “other.” The objective is to tag each word in a message into one of these categories. The information that can be used to predict a word’s tag is the identity of the surrounding words and their associated tags. Let denote t</context>
</contexts>
<marker>Borthwick, Sterling, Agichtein, Grishman, 1998</marker>
<rawString>Andrew Borthwick, John Sterling, Eugene Agichtein, and Ralph Grishman. 1998. Nyu: Description of the mene named entity system as used in MUC-7. In Seventh Message Understanding Conference(MUC-7). ARPA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>DARPA</author>
</authors>
<date>1999</date>
<booktitle>Proceedings of the DARPA Broadcast News Workshop.</booktitle>
<contexts>
<context position="1794" citStr="DARPA, 1999" startWordPosition="289" endWordPosition="290"> and a realization of the commercial value of the available data. One aspect of information extraction (IE) is the retrieval of documents. Another aspect is that of identifying words from a stream of text that belong in predefined categories, for instance, “named entities” such as proper names, organizations, or numerics. Though most of the earlier IE work was done in the context of text sources, recently a great deal of work has also focused on extracting information from speech sources. Examples of this are the Spoken Document Retrieval (SDR) task (NIST, 1999), named entity (NE) extraction (DARPA, 1999; Miller et al., 2000; Kim and Woodland, 2000). The SDR task focused on Broadcast News and the NE task focused on both Broadcast News and telephone conversations. In this paper, we focus on a source of conversational speech data, voicemail, that is found in relatively large volumes in the real-world, and that could benefit greatly from the use of IE techniques. The goal here is to query one’s personal voicemail for items of information, without having to listen to the entire message. For instance, “who called today?”, or “what is X’s phone number?”. Because of the importance of these key piece</context>
<context position="3300" citStr="DARPA, 1999" startWordPosition="554" endWordPosition="555">t to extract the answers to specific questions. An interesting aspect of this research is that because a transcription of the voicemail is not available, speech recognition algorithms have to be used to convert the speech to text and the subsequent IE algorithms must operate on the transcription. One of the complications that we have to deal with is the fact that the state-of-the-art accuracy of speech recognition algorithms on this type of data 1 is only in the neighborhood of 60- 70% (Huang et al., 2000). The task that is most similar to our work is named entity extraction from speech data (DARPA, 1999). Although the goal of the named entity task is similar - to identify the names of persons, locations, organizations, and temporal and numeric expressions - our task is different, and in some ways more difficult. There are two main reasons for this: first, caller and number information constitute a small fraction of all named entities. Not all person-names belong to callers, and not all digit strings specify phone-numbers. In this sense, the algorithms we use must be more precise than those for named entity detection. Second, the caller’s identity may include information that is not typically </context>
</contexts>
<marker>DARPA, 1999</marker>
<rawString>DARPA. 1999. Proceedings of the DARPA Broadcast News Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Huang</author>
<author>B Kingsbury</author>
<author>L Mangu</author>
<author>M Padmanabhan</author>
<author>G Saon</author>
<author>G Zweig</author>
</authors>
<title>Recent improvements in speech recognition performance on large vocabulary conversational speech (voicemail and switchboard).</title>
<date>2000</date>
<booktitle>In Sixth International Conference on Spoken Language Processing,</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="3199" citStr="Huang et al., 2000" startWordPosition="534" endWordPosition="537">mpis and Renals, 2000), however the goal there was to compress a voicemail message by summarizing it, and not to extract the answers to specific questions. An interesting aspect of this research is that because a transcription of the voicemail is not available, speech recognition algorithms have to be used to convert the speech to text and the subsequent IE algorithms must operate on the transcription. One of the complications that we have to deal with is the fact that the state-of-the-art accuracy of speech recognition algorithms on this type of data 1 is only in the neighborhood of 60- 70% (Huang et al., 2000). The task that is most similar to our work is named entity extraction from speech data (DARPA, 1999). Although the goal of the named entity task is similar - to identify the names of persons, locations, organizations, and temporal and numeric expressions - our task is different, and in some ways more difficult. There are two main reasons for this: first, caller and number information constitute a small fraction of all named entities. Not all person-names belong to callers, and not all digit strings specify phone-numbers. In this sense, the algorithms we use must be more precise than those for</context>
<context position="5854" citStr="Huang et al., 2000" startWordPosition="970" endWordPosition="973">ord error rate is due to the fact that the speech is spontaneous, and characterized by poor grammar, false starts, pauses, hesitations, etc. While this does not pose a problem for a human listener, it causes significant problems for speech recognition algorithms. 5 discusses the transducer induction technique; Section 6 contains our experimental results and Section 7 concludes our discussions. 2 The Database Our work focuses on a database of voicemail messages gathered at IBM, and made publicly available through the LDC. This database and related speech recognition work is described fully by (Huang et al., 2000). We worked with approximately messages, which we divided into messages for training, for development test set, and for evaluation test set. The messages were manually transcribed 2, and then a human tagger identified the portions of each message that specified the caller and any return numbers that were left. In this work, we take a broad view of what constitutes a caller or number. The caller was defined to be the consecutive sequence of words that best answered the question “who called?”. The definition of a number we used is a sequence of consecutive words that enables a return call to be </context>
</contexts>
<marker>Huang, Kingsbury, Mangu, Padmanabhan, Saon, Zweig, 2000</marker>
<rawString>J. Huang, B. Kingsbury, L. Mangu, M. Padmanabhan, G. Saon, and G. Zweig. 2000. Recent improvements in speech recognition performance on large vocabulary conversational speech (voicemail and switchboard). In Sixth International Conference on Spoken Language Processing, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ji-Hwan Kim</author>
<author>P C Woodland</author>
</authors>
<title>A rule-based named entity recognition system for speech input.</title>
<date>2000</date>
<booktitle>In Sixth International Conference on Spoken Language Processing,</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="1840" citStr="Kim and Woodland, 2000" startWordPosition="295" endWordPosition="298">al value of the available data. One aspect of information extraction (IE) is the retrieval of documents. Another aspect is that of identifying words from a stream of text that belong in predefined categories, for instance, “named entities” such as proper names, organizations, or numerics. Though most of the earlier IE work was done in the context of text sources, recently a great deal of work has also focused on extracting information from speech sources. Examples of this are the Spoken Document Retrieval (SDR) task (NIST, 1999), named entity (NE) extraction (DARPA, 1999; Miller et al., 2000; Kim and Woodland, 2000). The SDR task focused on Broadcast News and the NE task focused on both Broadcast News and telephone conversations. In this paper, we focus on a source of conversational speech data, voicemail, that is found in relatively large volumes in the real-world, and that could benefit greatly from the use of IE techniques. The goal here is to query one’s personal voicemail for items of information, without having to listen to the entire message. For instance, “who called today?”, or “what is X’s phone number?”. Because of the importance of these key pieces of information, in this paper, we focus prec</context>
</contexts>
<marker>Kim, Woodland, 2000</marker>
<rawString>Ji-Hwan Kim and P.C. Woodland. 2000. A rule-based named entity recognition system for speech input. In Sixth International Conference on Spoken Language Processing, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Konstantinos Koumpis</author>
<author>Steve Renals</author>
</authors>
<title>Transcription and summarization of voicemail speech.</title>
<date>2000</date>
<booktitle>In Sixth International Conference on Spoken Language Processing,</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="2602" citStr="Koumpis and Renals, 2000" startWordPosition="428" endWordPosition="431">cus on a source of conversational speech data, voicemail, that is found in relatively large volumes in the real-world, and that could benefit greatly from the use of IE techniques. The goal here is to query one’s personal voicemail for items of information, without having to listen to the entire message. For instance, “who called today?”, or “what is X’s phone number?”. Because of the importance of these key pieces of information, in this paper, we focus precisely on extracting the identity and the phone number of the caller. Other attempts at summarizing voicemail have been made in the past (Koumpis and Renals, 2000), however the goal there was to compress a voicemail message by summarizing it, and not to extract the answers to specific questions. An interesting aspect of this research is that because a transcription of the voicemail is not available, speech recognition algorithms have to be used to convert the speech to text and the subsequent IE algorithms must operate on the transcription. One of the complications that we have to deal with is the fact that the state-of-the-art accuracy of speech recognition algorithms on this type of data 1 is only in the neighborhood of 60- 70% (Huang et al., 2000). T</context>
</contexts>
<marker>Koumpis, Renals, 2000</marker>
<rawString>Konstantinos Koumpis and Steve Renals. 2000. Transcription and summarization of voicemail speech. In Sixth International Conference on Spoken Language Processing, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Miller</author>
<author>Sean Boisen</author>
<author>Richard Schwartz</author>
<author>Rebecca Stone</author>
<author>Ralph Weischedel</author>
</authors>
<title>Named entity extraction from noisy input: Speech and ocr.</title>
<date>2000</date>
<booktitle>In Proceedings ofANLP-NAACL 2000,</booktitle>
<pages>316--324</pages>
<contexts>
<context position="1815" citStr="Miller et al., 2000" startWordPosition="291" endWordPosition="294">ation of the commercial value of the available data. One aspect of information extraction (IE) is the retrieval of documents. Another aspect is that of identifying words from a stream of text that belong in predefined categories, for instance, “named entities” such as proper names, organizations, or numerics. Though most of the earlier IE work was done in the context of text sources, recently a great deal of work has also focused on extracting information from speech sources. Examples of this are the Spoken Document Retrieval (SDR) task (NIST, 1999), named entity (NE) extraction (DARPA, 1999; Miller et al., 2000; Kim and Woodland, 2000). The SDR task focused on Broadcast News and the NE task focused on both Broadcast News and telephone conversations. In this paper, we focus on a source of conversational speech data, voicemail, that is found in relatively large volumes in the real-world, and that could benefit greatly from the use of IE techniques. The goal here is to query one’s personal voicemail for items of information, without having to listen to the entire message. For instance, “who called today?”, or “what is X’s phone number?”. Because of the importance of these key pieces of information, in </context>
</contexts>
<marker>Miller, Boisen, Schwartz, Stone, Weischedel, 2000</marker>
<rawString>David Miller, Sean Boisen, Richard Schwartz, Rebecca Stone, and Ralph Weischedel. 2000. Named entity extraction from noisy input: Speech and ocr. In Proceedings ofANLP-NAACL 2000, pages 316– 324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<date>1999</date>
<booktitle>Proceedings of the Eighth Text REtrieval Conference (TREC-8).</booktitle>
<contexts>
<context position="1751" citStr="NIST, 1999" startWordPosition="283" endWordPosition="284">n the number of publicly available archives and a realization of the commercial value of the available data. One aspect of information extraction (IE) is the retrieval of documents. Another aspect is that of identifying words from a stream of text that belong in predefined categories, for instance, “named entities” such as proper names, organizations, or numerics. Though most of the earlier IE work was done in the context of text sources, recently a great deal of work has also focused on extracting information from speech sources. Examples of this are the Spoken Document Retrieval (SDR) task (NIST, 1999), named entity (NE) extraction (DARPA, 1999; Miller et al., 2000; Kim and Woodland, 2000). The SDR task focused on Broadcast News and the NE task focused on both Broadcast News and telephone conversations. In this paper, we focus on a source of conversational speech data, voicemail, that is found in relatively large volumes in the real-world, and that could benefit greatly from the use of IE techniques. The goal here is to query one’s personal voicemail for items of information, without having to listen to the entire message. For instance, “who called today?”, or “what is X’s phone number?”. B</context>
</contexts>
<marker>NIST, 1999</marker>
<rawString>NIST. 1999. Proceedings of the Eighth Text REtrieval Conference (TREC-8).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jose Oncina</author>
<author>Enrique Vidal</author>
</authors>
<title>Learning subsequential transducers for pattern recognition interpretation tasks.</title>
<date>1993</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>15</volume>
<issue>5</issue>
<contexts>
<context position="15224" citStr="Oncina and Vidal, 1993" startWordPosition="2560" endWordPosition="2563">erent portions of the messages at different times. In contrast to the baseline flex system, the transducers that we induce are nondeterministic and Figure 1: Graph structure before and after a merge. stochastic – a given word sequence may align to multiple paths through the transducer. In the case that multiple alignments are possible, the lowest cost transduction is preferred, with the costs being determined by the transition probabilities encountered along the paths. 5.1 Inducing Finite State Automata Many techniques have evolved for inducing finite state automata from word sequences, e.g. (Oncina and Vidal, 1993; Stolcke and Omohundro, 1994; Ron et al., 1998), and we chose to adapt the technique of (Ron et al., 1998). This is a simple method for inducing acyclic automata, and is attractive because of its simplicity and theoretical guarantees. Here we present only an abbreviated description of our implementation, and refer the reader to (Ron et al., 1998) for a full description of the original algorithm. In (Appelt and Martin, 1999), finite state transducers were also used for named entity extraction, but they were hand specified. The basic idea of the structure induction algorithm is to start with a </context>
</contexts>
<marker>Oncina, Vidal, 1993</marker>
<rawString>Jose Oncina and Enrique Vidal. 1993. Learning subsequential transducers for pattern recognition interpretation tasks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 15(5):448–458.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
<author>Jeff Reynar</author>
<author>Salim Roukos</author>
</authors>
<title>A Maximum Entropy Model for Prepositional Phrase Attachment.</title>
<date>1994</date>
<booktitle>In Proceedings of the Human Language Technology Workshop,</booktitle>
<pages>250--255</pages>
<publisher>ARPA.</publisher>
<location>Plainsboro, N.J.</location>
<contexts>
<context position="9056" citStr="Ratnaparkhi et al., 1994" startWordPosition="1513" endWordPosition="1516">tion was aided by an automatically generated list of short, commonly occurring phrases that were then manually scanned, generalized, and added to the flex program. It is the simplest of the systems presented, and achieves a good performance level, but suffers from the fact that a skilled person is required to identify the rules. 4 Maximum Entropy Model Maximum entropy modeling is a powerful framework for constructing statistical models from data. It has been used in a variety of difficult classification tasks such as part-of-speech tagging (Ratnaparkhi, 1996), prepositional phrase attachment (Ratnaparkhi et al., 1994) and named entity tagging (Borthwick et al., 1998), and achieves state of the art performance. In the following, we briefly describe the application of these models to extracting caller’s information from voicemail messages. The problem of extracting the information pertaining to the callers identity and phone number can be thought of as a tagging problem, where the tags are “caller’s identity,” “caller’s phone number” and “other.” The objective is to tag each word in a message into one of these categories. The information that can be used to predict a word’s tag is the identity of the surroun</context>
</contexts>
<marker>Ratnaparkhi, Reynar, Roukos, 1994</marker>
<rawString>Adwait Ratnaparkhi, Jeff Reynar, and Salim Roukos. 1994. A Maximum Entropy Model for Prepositional Phrase Attachment. In Proceedings of the Human Language Technology Workshop, pages 250–255, Plainsboro, N.J. ARPA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A Maximum Entropy Part of Speech Tagger.</title>
<date>1996</date>
<booktitle>In Eric Brill and Kenneth Church, editors, Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>17--18</pages>
<institution>University of Pennsylvania,</institution>
<contexts>
<context position="8996" citStr="Ratnaparkhi, 1996" startWordPosition="1507" endWordPosition="1508">ed. Our baseline system has about 200 rules. Its creation was aided by an automatically generated list of short, commonly occurring phrases that were then manually scanned, generalized, and added to the flex program. It is the simplest of the systems presented, and achieves a good performance level, but suffers from the fact that a skilled person is required to identify the rules. 4 Maximum Entropy Model Maximum entropy modeling is a powerful framework for constructing statistical models from data. It has been used in a variety of difficult classification tasks such as part-of-speech tagging (Ratnaparkhi, 1996), prepositional phrase attachment (Ratnaparkhi et al., 1994) and named entity tagging (Borthwick et al., 1998), and achieves state of the art performance. In the following, we briefly describe the application of these models to extracting caller’s information from voicemail messages. The problem of extracting the information pertaining to the callers identity and phone number can be thought of as a tagging problem, where the tags are “caller’s identity,” “caller’s phone number” and “other.” The objective is to tag each word in a message into one of these categories. The information that can be</context>
<context position="10973" citStr="Ratnaparkhi, 1996" startWordPosition="1839" endWordPosition="1840">eded by the word sequence “this is”). If a feature is a very strong predictor of a particular tag, then the corresponding would be high. It is also possible that a particular feature may be a strong predictor of the absence of a particular tag, in which case the associated would be near zero. Training a maximum entropy model involves the selection of the features and the subsequent estimation of weight parameters . The testing procedure involves a search to enumerate the candidate tag sequences for a message and choosing the one with highest probability. We use the “beam search” technique of (Ratnaparkhi, 1996) to search the space of all hypotheses. 4.1 Features Designing effective features is crucial to the maxent model. In the following sections, we describe the various feature functions that we experimented with. We first preprocess the text in the following ways: (1) map rare words (with counts less than ) to the symbol “UNKNOWN”; (2) map words in a name dictionary to the symbol “NAME.” The first step is a way to handle out of vocabulary words in test data; the second step takes advantage of known names. This mapping makes the model focus on learning features which help to predict the location o</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A Maximum Entropy Part of Speech Tagger. In Eric Brill and Kenneth Church, editors, Conference on Empirical Methods in Natural Language Processing, University of Pennsylvania, May 17–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dana Ron</author>
<author>Yoram Singer</author>
<author>Naftali Tishby</author>
</authors>
<title>On the learnability and usage of acyclic probabilistic finite automata.</title>
<date>1998</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>56</volume>
<issue>2</issue>
<contexts>
<context position="15272" citStr="Ron et al., 1998" startWordPosition="2568" endWordPosition="2571"> contrast to the baseline flex system, the transducers that we induce are nondeterministic and Figure 1: Graph structure before and after a merge. stochastic – a given word sequence may align to multiple paths through the transducer. In the case that multiple alignments are possible, the lowest cost transduction is preferred, with the costs being determined by the transition probabilities encountered along the paths. 5.1 Inducing Finite State Automata Many techniques have evolved for inducing finite state automata from word sequences, e.g. (Oncina and Vidal, 1993; Stolcke and Omohundro, 1994; Ron et al., 1998), and we chose to adapt the technique of (Ron et al., 1998). This is a simple method for inducing acyclic automata, and is attractive because of its simplicity and theoretical guarantees. Here we present only an abbreviated description of our implementation, and refer the reader to (Ron et al., 1998) for a full description of the original algorithm. In (Appelt and Martin, 1999), finite state transducers were also used for named entity extraction, but they were hand specified. The basic idea of the structure induction algorithm is to start with a prefix tree, where arcs are labeled with words, </context>
<context position="16523" citStr="Ron et al., 1998" startWordPosition="2786" endWordPosition="2789">rd sequences in the training data, and then to gradually transform it, by merging internal states, into a directed acyclic graph that represents a generalization of the training data. An example of a merge operation is shown in Figure 1. The decision to merge two nodes is based on the fact that a set of strings is rooted in each node of the tree, specified by the paths to all the reachable leaf nodes. A merge of two nodes is permissible when the corresponding sets of strings are statistically indistinguishable from one another. The precise definition of statistical similarity can be found in (Ron et al., 1998), and amounts to deeming two nodes indistinguishable unless one of them has a frequently occurring suffix that is rarely seen in the other. The exact ordering in which we merged nodes is a variant of the process described in (Ron et al., 1998) 3. The transition probabilities are determined by aligning the training data to the induced automaton, and counting the number of times each arc is used. 5.2 Conversion to a Transducer Once a structure is induced for the training data, it can be converted into an information extracting transducer in a straightforward manner. When the automaton is learned</context>
</contexts>
<marker>Ron, Singer, Tishby, 1998</marker>
<rawString>Dana Ron, Yoram Singer, and Naftali Tishby. 1998. On the learnability and usage of acyclic probabilistic finite automata. Journal of Computer and System Sciences, 56(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Stephen M Omohundro</author>
</authors>
<title>Best-first model merging for hidden markov model induction.</title>
<date>1994</date>
<tech>Technical Report TR-94-003,</tech>
<institution>International Computer Science Institute.</institution>
<contexts>
<context position="15253" citStr="Stolcke and Omohundro, 1994" startWordPosition="2564" endWordPosition="2567">ssages at different times. In contrast to the baseline flex system, the transducers that we induce are nondeterministic and Figure 1: Graph structure before and after a merge. stochastic – a given word sequence may align to multiple paths through the transducer. In the case that multiple alignments are possible, the lowest cost transduction is preferred, with the costs being determined by the transition probabilities encountered along the paths. 5.1 Inducing Finite State Automata Many techniques have evolved for inducing finite state automata from word sequences, e.g. (Oncina and Vidal, 1993; Stolcke and Omohundro, 1994; Ron et al., 1998), and we chose to adapt the technique of (Ron et al., 1998). This is a simple method for inducing acyclic automata, and is attractive because of its simplicity and theoretical guarantees. Here we present only an abbreviated description of our implementation, and refer the reader to (Ron et al., 1998) for a full description of the original algorithm. In (Appelt and Martin, 1999), finite state transducers were also used for named entity extraction, but they were hand specified. The basic idea of the structure induction algorithm is to start with a prefix tree, where arcs are l</context>
</contexts>
<marker>Stolcke, Omohundro, 1994</marker>
<rawString>Andreas Stolcke and Stephen M. Omohundro. 1994. Best-first model merging for hidden markov model induction. Technical Report TR-94-003, International Computer Science Institute.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>