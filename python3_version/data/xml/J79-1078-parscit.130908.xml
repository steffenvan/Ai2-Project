<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.629348">
American Journal of Computational Linguistics Microfiche 78
</note>
<sectionHeader confidence="0.447571" genericHeader="method">
LANGUAGE REPRESENTATION
</sectionHeader>
<author confidence="0.814961">
DAVID L. WALTZ, EDITOR
</author>
<affiliation confidence="0.626648666666667">
Coordinated Science Laboratory4
University of Illinois
Urbana 61801
</affiliation>
<title confidence="0.7144455">
Papers presented it-two sessions of TINLAP-2, the 1978 Meeting
of the Associatiou for Computational Linguistics, held with
joint sponsorship by the Association for Computing Machinery
and its Special Interest Group in Artificial Intelligence.
Copyright Q 1978, 1979
Association for Computing Machinery
Association for Computational Linguistics
TABLE OF CONTENTS
</title>
<table confidence="0.917251222222222">
TABLE or CONTENTS M W
Session 1 Language Representation and Psychology W I
EL U
CC Pi
0- LL
Testing the Psychological Reality of a Representatiob Model
Dedre Gentner 1 3
What Makes Something &amp;quot;Ad Hoc&amp;quot; 8 10
Roger C. Schenk
The Relation of Grammar to Cognition--a Synopsis 14 16
Leonard Talmy
On Primitives Prototypes, and Other Semantic AnomalLe9 25 27
Terry Winogard
Tanonomic Lattice Structures for Situation Recognition 33 35
William A. Woods
Session 2 Language Representation and Reference
Description Formation and Discourse Model Synthesis 42 44
Bonnie Lynn Webber
The Processing of Ftkferring Expressions within a Semantic Network 51 83
John R. Andel-gam
Reference Diaries 57 59
Herbert H. Clark. and Catherine Marshall ?
Subsequent Reference Syntactic and Rhetorical Constraints 64 66
David D. McDonald
Some PsycHolinguistio Constraints on the Construction and Interpretation of Definite
Descriptions 73 75
Andrew Ortony
</table>
<note confidence="0.74064975">
Bound Variables and Other Anaphors n 81
Barbara H. Partee ...
The Use of Focus as a Tool for Disambiguation of Definite Noun Phrases 86 87
Candace L. Sidner
</note>
<title confidence="0.659436">
Testing The Psychological Reality
of a Representational Model
Dedre Gentner
Bolt Beranek and Newman Inc
</title>
<sectionHeader confidence="0.853019" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.983521384615385">
A research program is described in which
a particular representational format for
meaning is tested as broadly as possible. In
this format, developed by the LNR research
group at The University of California at San
Diego, verbs art represented as interconnected
sets of subpredicates. These subpredicates
may be thought of as the almost inevitable
inferences that a listener makes when a verb
is used in a sentence. They confer a meaning
structure on the sentence in which the verb is
used. To be psychologically valid, thee
representations should capture (at least)
</bodyText>
<sectionHeader confidence="0.495056" genericHeader="method">
1 Similarity oP meaning
</sectionHeader>
<bodyText confidence="0.831092">
The more similar two verbs seem in
meaning to people, the more their
representations should overlap.
</bodyText>
<sectionHeader confidence="0.891892" genericHeader="method">
2 Confusability
</sectionHeader>
<bodyText confidence="0.996884333333333">
The more confusable two verb meanings
are, the more their representations
should overlap.
</bodyText>
<listItem confidence="0.4587545">
3. Memory for sentences containing the
verb
</listItem>
<bodyText confidence="0.89148775">
&apos;rhe sentence structures set up by the
verb&apos;s meaning should in part
determine the way in which sentences
are remembered.
</bodyText>
<sectionHeader confidence="0.964061" genericHeader="method">
4. Semantic integration
</sectionHeader>
<bodyText confidence="0.98919125">
The representations should allow for
the integration of information from
different sentences into discourse
structure
</bodyText>
<sectionHeader confidence="0.863112" genericHeader="method">
5 Acquisition patterns
</sectionHeader>
<bodyText confidence="0.9484578">
The structural partitions in the
representations should correspond to
the structures children acquire when
they are learning the meanings of the
verbs
</bodyText>
<sectionHeader confidence="0.500057" genericHeader="method">
6. Patterns of extension
</sectionHeader>
<bodyText confidence="0.9949112">
The representations should be
extendible so as to reflect the ways
in which people interpret verb
meanings when the verbs are used
outside their normal context.
</bodyText>
<sectionHeader confidence="0.853351" genericHeader="method">
7. Reaction times
</sectionHeader>
<bodyText confidence="0.958344308641976">
The time taken to comprehend a
sentence using a given verb should
reflect the structural complexity of
the verb meaning.
Experiments concerned with predictions
1-5 are described here. The results are
promising for a general approach of
representation of meaning in terms of
interrelated subpredicates, but do not clearly
distinguish between several similar
representations. For example, to test
prediction (2), I read people sentences
containing verbs with similar meanings, and
asked them to recall the sentences. The
deipwe of overlap in the semantic structures
was a good predictor of the number of
confusions between sentences. In another
sentence-memory experiment (prediction (3)),
semantically compldk verbs that provided more
underlying interconnections between the nouns
in a sentence led to better memory for the
nouns in the sentence than simple genera&amp;
verbs, or than other complex verbs that did
not provide such extra interconnections, To
test prediction (5), I tested children&apos;s
zomprehension of a set of possession verbs.
Both the order of acquisition among the verbs
and the kinds of errors fitted well with an
account of the acquisition of verb meaning in
terms of interconnected subpredicates.
This research illustrates a breadth-fir-it
approach to testing a representation. In the
breadth-first approach, many different
psychological predictions are made. Each
different area of prediction requires a set of
process assumptions, and in each case the
process assumptions used are those that seem
most plausible given previous research in the
field. If one representational format can
make correct predictions about a number of
different kinds of psychological phenomena,
then that representation stands a greater
chance of being generally useful than one
which was tested in only one depth-first way.
This paper describes a program of
research that tests a representational format
for verb meaning. This research grew out of
the LNR (Footnote 1) attempt to the represent
the Meanings of words in a psychologically
satisfying way. Verb meaning seemed a natural
place to start for two reasons: (1) verbs are
important: it is arguable that they provide
the central trganizing semantic structures in
sentence meanings; and (2) verbs are
tractable: their meanings are more easily
analyzed than those. of, for example, common
nouns.
Since different disciplines look at
meaning in different ways., it may be
worthwhile to describe the stance we took.
What we wanted was a system of representation
in which we could capture our intuitions about
what a word typically conveys; or more
specifically about the inferences a person
normally makes (or believes should be =vie)
when a word is used. The assumption is that
the same representations operate when a person
uses the word in speech as when the person
comprehends it; however the methodology of
experimental psychology makes it naturel to
spend more time pondering the input process
than the output process. This approach
differs from thinking of meaning in terms of
necessary and sufficient truth-conditions, as
many philosophers have done, or from thinking
about Meaning in generation rather than in
comprehension, as many linguists have done.
Each of those stances leads to useful
intuitions. Overall, there has been a
reassuring degree of convergence between the
representations proposed.
</bodyText>
<subsectionHeader confidence="0.770072">
Representation of Verb Meaning.
</subsectionHeader>
<bodyText confidence="0.98571640625">
There are many notational systems for
representation .of verb meaning (e.gâ€ž
Abrahamson, 1975, Chafe, 1970; Fillmore, 1971,
Genther, 1975, Lakoff, 1970; McCawley, 1968,
Rumelhart &amp; Levin, 1975; Schenk, 1972, 1975,
Talmy, 1975). These models of verb meaning
differ from One another in detail, but there
is widespread agreement on the idea that vero
meanings can be represented in terms of
interrelated sets of. subpredicates, such as
CAUSE or aHANGE. These subpredicates are not
merely eoncatenated within a word&apos;s
representation. Rather, they are
interrelated, in specific ways.
Representations of verb meaning include
notation for specifying the relationships
among the &apos;Subpredicates that make up a word&apos;s
meaning. The notation developed by the LNR
Group is a network format. In this system of
representation, verb meanings are expressed
in terms of subpredicates that stand for
states, changes of state, actionals, eta.
The Elements of Ver P Meamiln,g. Verbs
provide a system in which people can talk
about happenings in the world, implicitly
distinguishing several types of conceptual
possibilities. The simplest of these is the
Ptate. A. stative predicate conveys a
relationship that endures for a period of time
between two arguments, normally an object (or
person) and an object or value within the
conceptual field specified by the stative.
</bodyText>
<figureCaption confidence="0.7534755">
For example, consider the sentence shown in
Figure 1.
</figureCaption>
<bodyText confidence="0.888609933333333">
Ida owned a Cadillac from 1970 to 1977.
The verb own conveys that a relationship of
possession misted between Ida and the
Cadillac for some civration. Besides statives
for possession there are a large number of
other statives, including location (to be._ at,
to re:n.4112_0, etc.) and emotion (to hate, to
love, etc.).
In addition to simple stative
relationships, verbs can be used to convey
changes tof state. Following Chafe (1970) I
will refer to a change of state as a process.
For example, the sentence
Ida receives $10.00.
tells us
</bodyText>
<listItem confidence="0.7010018">
(1) that Ida now has $10.00
(2) that someone else had the $10.00 before,
(3) that a change has taken place from this
previous state of possession to the
present state.
</listItem>
<bodyText confidence="0.97507414893617">
More commonly, verbs express not simple
changes of state but causal changes of state.
We seem to be very interested in processes
that are volitionally caused by humans and
ether sentient beings. Figure 2 shows the
representation of the sentence
Ida gives Sam a rose.
An agent nay cause a change of state that
relates to another object. Or the same person
may act on both agent and experiencer of the
change of state. The lotational verb move can
be used in either way, as in the following
examples
a. Ida moved the car.
b. Ida moved to the front seat.
In both these cases the action taken by Ida is
unspecified. We often don&apos;t care exactly what
someone did to cause some process to occur.
However, there are also verbs in which the
causal action is partially or wholly
specified e.g., walX, saunter, meander,
stride, rya, sprint, Nice, trot, jpg. (See
Miller (1972) and Miller &amp; Jonnson-Laird
(1976) for a more extensive discussion of the
verbs of location.)
Thus, this system allows for the
representation of verbs as states, changes of
state, causal changes of state. simple
actions, and complex cases in wfflen specific
actions cause changes or state. Further
discussion of the LNR sysbem of verb semantics
can be found in the articles by Abrahamson,
Gentner, Munro, Rumelhart &amp; Levin, and
Rumelhart &amp; Norman in the Norman &amp; Rumelhart
(1975) volume.
There aPe certainly gaps in the system,
and aspects of verb meaning that are not
expressible in this simple vocabulary. Some
unresolved issues are discussed later in the
paper. However, the system seems plausible at
the arst level, and allows a fair range of
verb meanings to be captured at least roughly.
it
At this point in the research it staged
appropriate to begin testing the psychological
rightness of the system as so far stated
before going on to refine it.
</bodyText>
<sectionHeader confidence="0.314071" genericHeader="method">
EiushalagisaLkaitats1.11sJiadia.
</sectionHeader>
<subsectionHeader confidence="0.70673">
One advantage of psychological
</subsectionHeader>
<bodyText confidence="0.998522666666667">
experimentation (or of computer
implementation) is that it Forces one to make
explicit the assumptions &apos; underlying
representation and process. At least some of
the choices made can then be tested as
hypotheses. Some important assumptions are
</bodyText>
<listItem confidence="0.550594">
(1) a verb&apos;s representation captures the
</listItem>
<bodyText confidence="0.7332945">
set of immediate inferences that people
normally make when they hear or read a
sentence containing -the verb;
c21 in general, one verb leads to many
</bodyText>
<sectionHeader confidence="0.57946" genericHeader="method">
inferences
</sectionHeader>
<bodyText confidence="0.988759452054795">
(3) these networks of meaning components
are accessed during comprehension, by an
immediate and largely automatic process
(4) the set of components associated with
a given word is reasonably stable across
task and cbntexts
(5) surface memory for exact words fades
quite rapidly, so that after a short time,
only the representational network remains.
In testing these representations, I
took a very literal interpretation of &apos;the
notion of representation -- namely that
the nodes and arrows in a representation
correspond to the concepts and
relatiOnships that are stored when a
person comprehends a sentence containing a
verb. The more ferociously literal the
intet.pretation, the better the chances of
discovering counter-evidence.
Semantlg overlap. One psychological
criterion ip that the representations should
agree with people&apos;s intuitive notions of
synonymity and Similarity in meaning. One
straightforward measure of this overlap is the
degree to which people rate verbs as similar
in meaning. In a study of about 60 selected
verbs, I found that people&apos;s average rating of
the semantic similarity between two verbs
agreed very closely with the degree of
semantic overlap between their
representations.
A more subtle measure of psychological
similarity is the degree to which people
unconsciously confuse things in memory.
People in a sentence-memory experiment
probably try to keep their sentence traces
clear. But, suppose that within a short time
after hearing a verb in a sentence, a person
has only the representational network of
concepts and relationships, and not the
surface verb Assume further that some pieces
of the memory representation may be lost or
unaccessible at any time ithe &amp;quot;fallibility of
human memory&amp;quot; assumption). Then the more two
verb representations overlap, the more likely
Lt is that sentences containing the two verbe
will be confused in demory, despite people&apos;s
attempts to keep them straight. In an
experiment in sentence memory, using verbs of
varying semantic overlap, I found that
subjects did indeed confuse the verbs in
exactly the way predioted by the theory
(Gentner, 1974). The correlation between the
number of confusions subjects made between two
verbs and the semantic overlap between the
verbs, as predicated from the representations,
was quite high. In fact, the correlation
between representational overlap and number of
confusions was slightly higher (though not
significantly so) than the correlation between
the number of confusions and the rated
similarity between the vorbs. (The similarity
ratings were taken from the first-mentioned
study, with a different set 9r subjects).
Semantic complexity. Semantic complexity
refers to the number of underlying
subpredicates and intercObnections that...make
up the basic meaning of a verb. More complex
meanings correspond to mores specific actions
or events. For example, stri4 is more
specific than sz Its meaning contains more
subpredicates. We know more having heard
sentence (a) than sentence (b).
</bodyText>
<figure confidence="0.823445">
(a) Ida strode across the field.
(b) Ida went aeross the field.
</figure>
<bodyText confidence="0.983191812080537">
Various researchers have looked for evidence
that semantic complexity may affect
comprehensibility,, generally on the apsumption
that more complet semantic structures are
harder to process (Kintsch 1974; Thorndyke,
1977). However, the results have been
negative. There is no evidence that more
complex words lead either to longer
reaction-times or be greater processing loads
than do simpler words.. I believe&apos;tbat it&apos;s
incorrect to assume across the beard that
complexity is psychologically hard. Some
research of mine suggests that the effects of
semantic complexity in memory are more
particular.
Semantic. Complexity and- Connectivity.
Although the view that semantic complexity
leads to difficulty has not been supported,
there is another side to the complexity-issue.
The additional semantic components in a
complex verb may sa up additional connections
among the nouns in the sentence. In this
case, more _complex verbs should lead to a
richer and more highly interwoven sentence
representation, and thus to better memory for
the nouns in the sentence.
Notice that this prediction derives Mel
a fanatically literal interpretation of tire
verb representations: more paths in the
representation means more conceptual paths in
memory. This prediction is quite specific.
It is not simply a question of certain complex
versus simple verbs having some overall
effect, but rather of complex verbs providing
extra connections between the particular nouns
in question. This is clearly true for Ida and
her tenants in the case of se1,1 versus gill,
as can be seen in Fig 3a and 3b.
tested for this kind of improvement in
connectivity in a series of experiments in
sentence memory (Gentner, 1977). I react
people sentences that differed in the semantW
Connectivity of tpeir verbs, such as the
following pair of sentences&apos;
Ida gave her tenhnts a clock. (simple)
Ida sold her tenantb a clock. (complex
connective)
Then I gave the people the names of the
characters and asked them to recall le
sentences. As predicted, they were better
able to recall the noun tenants when the
complex connective verb eell. was used then
when the simple verb axe was used. More
semantic connections between tie two nouns led
to stronger memory connections.
To zee the specificity of the prediction,
consider a complex verb that mereiy amplifier
the simple verb and duss nat add condectiont
between the key nouns. For example, the vert
Rail (Fig 30) adds the information that the
method of transfer wasetly mailing or some such
long-distance transfer. Using mail leads to
more inferences (a more specific event
description) than using give. However, the
knowledge that the object was mailed leads to
few, if any, additional connections betwpeM
the agent, Igieâ€ž, and the recipient, tenants.
Therefore, the predicttori was that use of such
non-connecting specific verbs would lead to no
improvement over use ol general verbs in
memory between the nouns.
The results were exactly as predicted
The object nouns of complex connective verbs
were recalled better than those of general
verbs and non-connecting complex verbs. These
differences were not traceable to differences
in imagery or word-frequency. Thus
connectivity is beneficial to sentence metory
in a very specific way.
Acauisition. There may be a more direct
relationship between complexity and difficulty
in children than in adults. Young children
often fail to comprehend the full meanings of
semantically complex terms (e.g., Bowerman,
1975, Clark, 1973, Gentner, 1975, in press).
Working with the verbs of possession, I have
observed that childrpn act out the simple
verbs give and take correctly before they act
out the more complex verbs Duy. and trade.
Still later they learn the yet more complex
verbs 1204 gall and anend. The order in which
the verbs are learned is exactly the order of
increasing semantic complexity. This
complexity ordering can be made quite precise,
since the verbs are closely related in
meaning. The representation of a verb at the
nth level of simplicity is properly nested
within the representation of a verb at the
(n+1)th level. Further, when children around
4-6 years are apked to act out sell (as in
&amp;quot;Make Ernie sell Bert a boat.&amp;quot;) they act out
give instead (A boat is transferred from Erne
to Bert). Similarly, Dux is acted out ad
take. They systematically act out complex
verbs like simple verbs; and more
surprisingly, they choose the appropriate
simple verb. My interpretation, consistent
with Clark&apos;s 1(1973) semantic features
analysis, is that children learn these complex
verb meanings gradually, by adding components
to their partially correct representations.
At any given time, the child comprehends
language in terms of the Pomponents that he
has so far acquired.
$ementia Integration. Another important
psychological requirement is combinability.
The basic notions&apos;of state, change of state,
tause, and so on must be combinable into
networks larger than the individual sentence.
When two verbs share parts of their underlying
structure. this redundanpy should be utilized
to combine the two representations into onp
discourse structure. How can we test whether
this happens? One way is to arrange things so
that collapsing the redundancies between two
verbs should create the representation of a
third verb. Then the prediction is that
people should usa this third verb in recall.
In a study of semantic integration, I
read people short passages and tested their
memory by having them fill in blanks (Gentner,
1978). Every passage contained a general
verb, dlich as give. Half the passages also
contained additional semantic information,
such as the fact that the giver actually owed
the money he was giving. According to the
representational model, the integration of the
representation of give with that of owing
should have created the structure of nu, If
what people have, is ineir minds after hearing
the verbs is the network representations, and
if these representations are integrated during
discourse comprehension, then people who heard
giye and owe should end up with the
representation of eim. As predicted, subjects
nearing the extra material falsely recalled
the verb which best fit the composite
structure (e.g. rather than the verb
actually presented.
</bodyText>
<subsectionHeader confidence="0.769223">
Further Ipsges
</subsectionHeader>
<bodyText confidence="0.983626733333334">
I have dhde the assumption that a verb
carries with it a set of inferences that are
normally made during comprehension, as well as
several supporting assumptions. This view has
been fairly well supported by the research
presented here, but nevertheless it seems to
me an &apos;oversimplification. There remain a
great many questions, some large and some
small.
(1) Where should the line be drawn around a
word&apos;s meaning? As Clark and Clark (1977)
have put it, is word meaning more like a
dictionary or an encyclopedia? The extreme of
the dictionary approach would be to take a
minimal contrast approach, storing with a word
only enough to distingulsh it from all other
words. The extreme of the encyclopedia
approach would be to access the entire
long-term memory whenever any word is used.
The question is, how to define a reasonable
middle ground.
(2) What ism the process of expansion into a
semantic representation during comprehension?
a) Are there invariable inferences?. When
an incoming word is processed, is there
a set of inferences (such as the set I
have called the &amp;quot;almost-inevitable
Inferences&amp;quot; that is always made during
comprehension, or is there variation in
which inferences get made?
</bodyText>
<page confidence="0.716818">
6
</page>
<bodyText confidence="0.97287238028169">
b) If there is variation, is it
quantitative or qualitative? Do context
and the person&apos;s interests and attention
determine wirich inferences get made, so
that there are qualitative .differences
in what inferences get made? Or is the
difference merely quantitative, with the
radius of expansion varying with the
amount of attention (or energy, or
interest) that the persod brings to
bear?
The notion of at least quantitative
variation a seems haftt to avoid. It is a
fairly strong intuition that we process word
meanings with varying degrees of energy
Further, the phenomenon of instantiation
(Anderson, RC., Stevens, K.C., Shifrin, Z., &amp;
Qmborn, J. 1977) makes it clear that a model
of sentence comprehension must allow for
qualitative differences in the final set of
inferences stored. For example, compare the
sentences
Rover ate his dinner.
Mr. Pritchard ate his dinner.
The verb gat conveys vastly different action
sequences when used with different agents,
though its causal change-of-state structure
remains more-or-less constant. It is possible
that this qualitative variation can be
accounted for by simple underlying
quantitative processes spreading activation.
We may have to settle for a more complex
model, in which some parts of a verb&apos;s meaning
are almost always accessed while other
inferences develop out of the interaction of
the verb with its context, including its
pragmatic context. In Hewitt&apos;s (197b) terms,
there may be both if-added inferences and
if-needed inferences. Where in this model
(and whether) we want to draw a line between
meaning and knowledge-of-the-world is not at
all clear to me. (3) Carrying the notion of
variable werb mean4ng still further, how does
metaphorical extension work? Most common
verbs can be used in several related ways.
For example, consider the range Of meanings
that give can convey depending on the nbuns it
is used with
Ida gave Sam a rose
a job.
an heir.
an excuse
a talking to.
all his best ideas.
the time of his life.
Clearly the subpredicate structure varies
across these sentences, so much so that some
might want to describe this as a collection of
entirely different senSes of the same word.
This misses the structural similarities. Some
kind of metaphorical extension of meaning
seems a necessary part of a theory of verb
meaning, since it is generally the verb that
does most of the adjusting. A series of
studies by Albert Stevens and me suggests that
people faced with an odd sentence assume that
some of the subpredicates normally conveyed by
the verb are not meant to apply in the
sentence at hand A current project is to
model the rules for which subpredicates apply
in different contexts.
</bodyText>
<listItem confidence="0.937989764705882">
(4) I have so far treated nouns as nodes in
the semantic representation. Clearly in order
to analyze sentence interactions it is
necessary to have a representation of noun
meaning. Some progress been made with
abstract nouns, such as kinship terms. But
the truly nounlike nouns ---basic-level
nouns--- resist analysis. I believe that
these differences in amendability to analysis
reflect differences in the kind of meaning
that verbs and nouns have, and that a useful
representation of concrete noun meaning may be
quite different from that used for verbs,
prepositions and even abstract nouns.
(5) There are several aspects of the
representational scheme that need further
thought. To single out one issue, consider
</listItem>
<bodyText confidence="0.972898416666667">
the notion of change of state. The LNR
representation represents a verb like get,_ as
conveying a change from an initial state of
possession to a final state of possession.
Schank&apos;s Conceptual Dependency theory would
represent the entire sequence as a primitive
act. Many generative semanticists have
represented only the inchoative part of the
chain (the change to the final state) as
belonging to the assertion of the verb,
consi.dering the initial state to be more in
the nature of a vresupposition (e.g. Fillmore,
1966). All these positions seem to me to have
merit. The LNR use of change from initial to
final state allows a change-of-state verb to
hook automatically with relevant state
information. The use of acts as primitives
captures the psychological wholeness of
change. Thq use of the inchoative captgres
the intuition that people seem more interwated
in the results of an event --i.e. in the final
state-- than in the setting state. The
explicit change-of-state formats (LN A format
and inchoative format) have a natural way of
Capturing some kinds of metaphorical
extension by substituting a different stative
while preserving tte rest of the verb&apos;s
structube.
Summary
This work is just beginning. Neither the
representations nor the processes that are
assumed 0 operate on them come very close to
capturiqg the subtlety of human language use.
Still, the results of the experimental
investigation are promising some kind of
decompositional model along these lines.
</bodyText>
<figure confidence="0.8166845">
t
expenencer Â°bled from-time to-time
/ \
Ida Cadillac 1970 1977
</figure>
<figureCaption confidence="0.972832">
Figure 1. Ida owned a Cadillac from
</figureCaption>
<figure confidence="0.964572444444444">
1970-1977.
IPECIFIC VERB (FEW CONNECTING PATHS)
Figure )c.
event result
..
â€¢
: ....** /00 ... E %o
\ / E-..
â€¢
\I II .
â€¢-, Itta ..* Ida clock tenants &apos;... Ida
.. clock tenants i
â€¢ â€¢ ..
Ida mailed her tenants a clock
... .......
Iootnote
Agent from to
Ida rose Sap
</figure>
<figureCaption confidence="0.975926">
Figure 2. Ida gives Sam a rose.
</figureCaption>
<figure confidence="0.577129857142857">
Ida gave her tenants aclock
nmm RmwR
horn W
Ida E 0 O. E
It ,
Ido clock
GENERAL VERB (FEW CONNECTING PATHS)
</figure>
<figureCaption confidence="0.855883">
Figure 3a.
</figureCaption>
<bodyText confidence="0.730867">
Ida sold her tenants a clock
</bodyText>
<note confidence="0.844097571428571">
1. The reptp,titl.tional format shown here was
developed IIN a group of researchers at the
University of California at San Diego:
AdelettA. Abrahamson, Dedre Gentner, James A.
Levin, Stephen E. Palmer, and David E.
Rumelhart. The system is explained in detail
in Norman &amp; Rumelhart, 1975.
</note>
<figure confidence="0.992261684210526">
Ida POSSESSION)
Expenencerr Object Object
Experiencer
Event Result
4&apos;
CONTR
, â– 
Act 1 ..&apos; \ Act 2
, El E2â– 
. / â– 
&amp;quot;V It
Ida tenants
Result Result
tenants
: E Ull Of E
.6.â€¢â€¢â€¢ 31 $
tenants: money Ida
..
tenant!,
</figure>
<figureCaption confidence="0.937396">
SPECIFIC VERB (MANY CONNECTING PATHS)
Figure 3b.
</figureCaption>
<sectionHeader confidence="0.757327" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.623645428571429">
Abrahamson, A.A. Experimental analysis of tne
semantics of movement. In D.A. Norman, &amp; D.E.
Rumelhartg (Eds.), Explorations in Cognition.
San Francisco: W.H. Freeman &amp; Co., 1975.
Anderson, R.C., Stevens, K.C., Shifrin, Z., &amp;
Osborn, J. Instantation of &apos;Word Meanings in
C4-aintl, May 1977.
</reference>
<tableCaption confidence="0.678250888888889">
Bendix, E.H. Qpinnonential analysis of general
vocabulary&apos;: The semantic strudture of a set
of xerbs 10,EnCish, Hipdl, and Japanese. The
Hague; Mouton, 1966.
Bowerman, M. The acquisition of word meaning:
An investigation of some current conflicts.
Paper presented at the Third International
Child Language Symposium, London, September
1975.
</tableCaption>
<reference confidence="0.614397181818182">
Chafe, W.L. Meaning ,and the structure of
language. Chicago: University of Chicago
Press, 1970.
Clark, E.V. What&apos;s in a word: On the child&apos;s
acquIsition of semantics in â€¢ his first
language. In T.E. Moore (Ed.), Cognitive
development and- the acouisition of language,
New York: Academic Press, 1973.
Clark, H.H. &amp; Clark, E.V. psychology and
LAligalLt. New York: Harcourt Brace
Jovanovich, Inc., 1977.
</reference>
<figureCaption confidence="0.3418672">
Fillmore, C.J. Review of Bend x&apos;s Componential
analysis ofIgeneral vocabularv: The semantic
and Japanese. International Journal of
bezigiajAngillatjago 19661 32, Part II, No.
2. Publication 41.
</figureCaption>
<bodyText confidence="0.8839645">
Gentner, D. Towards a psychological theory of
the meaning 6f the possession verbs.
Unpublished dqctoral dissertation, University
of California, San Diego, 1974,
</bodyText>
<note confidence="0.5407918">
iorman, D. A., Rumelhart, D.E. &amp; 019 LNR
lesearch Group. Explorations in cognition.
3an Francisco: W.H. Freeman &amp; Comparly, 1975.
iumelhart, D.R. &amp; Levin, J.A. A language
3omprehension system. In D.A. Norman &amp; D.E.
</note>
<table confidence="0.851028533333333">
Rumelhart, Explgrations in cognition, San
Francisco: W.H. Freeman &amp; Co., 1975.
Schank, R. Conceptual Dependency: A Theory of
Natural Language Understanding, Cognitive
EuglIglagy., 1972, 34 552-631.
khank, R.C. The structure of episodes in
memory. In D. Bobrow &amp; A. Collins (Eds.),
Representation and understanding,- New York:
Academic &apos;ress, 1975.
Talmy, L. Semantic structures in Wtglish and
Atsugewi. Unpublished doctoral dissertation,
University of California, _Berkeley, 1972.
Thorndyke, P.W. Cognitive structures in
comprehension and memory of narrative
discourse. Cognitive labhologv, 1977, 94
77-110. &apos;
if
Gentner, D. Evidence for the psychological
reality of semantic -components: The verbkof
possession. In -D.A. Norman and &apos;D.E.
Rumelhart, FALlacatAcns_jaQgniljai, &apos;San
Francisco: W.H. .Freeman &amp; Co., 1975.
Gentner, D . On relational meaning: The
acquisition of verb meisning. Child
Development , in press.
Gentner, D. Semantic integration of word
meanings Volt Beranek and Newman Inc. Report
No. 3826, May 1978. Also to appear as a
Centet for the Study of Reading Technical
Report.
</table>
<tableCaption confidence="0.699514333333333">
Hewitt, C. Viewing control structures as
patterns of passing messages. M.I.T. Al
Working Paper 92, 1976.
</tableCaption>
<affiliation confidence="0.753526166666667">
Lakoff, G. Adverbs__ an modal opbrators.
Indiana University Linguistic6 Club Reprint.
Bloomington: Indiana University Linguistics
Club, 1970(a).
Lakoff, G. Irragu/Aritv and amntax. New York:
Holt, Rinehart and Winston, 1970(c),
</affiliation>
<note confidence="0.543321">
The role of semantics in
E. Bach and R.T. Harms (Eds.),
lax......mla_ln_lingztWroa. New Yoric
and Winston. 108(b).
</note>
<footnote confidence="0.741774">
McCawley, J.D.
grammar. In
&apos;ye
Holt, Rinehart.
</footnote>
<subsectionHeader confidence="0.9747332">
What &apos;Makes Something &amp;quot;Ad Hoc&apos;
by Roger C. Schenk,
Yale University
Department of Computer Science
New Haven, Conn. 06520
</subsectionHeader>
<bodyText confidence="0.860281774193549">
0
Only one of the questions posed before this
sespion really inspires me to take pen in hand.
&amp;quot;How general are various formalisms? Are they
really ad hoc solutions to relatively narrow
domains?&amp;quot;
That is not exactly my ravorite question. I
find the thought of having to address it palatable
only if I can delude myself into believing that
this is the last time I shall have to deal with
it So, proceeding on the basis of that
delusional belief, I shall begin.
Ad Hocness, I nave come to delieve, is a
disease that all new theories in the three fields
in which I consider myself well-versed, namely
linguistics, psychology and Artificial
Intelligence, contract at conception, sort of like
original sin This would not be so bad if it were
a disease for which there were a cure, but alas
there is none.
We are all familiar with the phrase &amp;quot;beauty
is in the eye of the beholder.&amp;quot; In this case we
have an instance of &amp;quot;the disease is in the eye of
the beholder&amp;quot; which of course explains why the
cure is so elusive. The beholder rarely wants to
do anything about it. To discuss this more
subjectively, let&apos;s take a neutral case. Before
doing so, wg shall have to point out what a case
can be expected to look like. A case of &amp;quot;ad
hocness&amp;quot; usually fits the fam (or should I say
the &amp;quot;ad hoc&amp;quot; form)
</bodyText>
<construct confidence="0.2897385">
Theory X is called &amp;quot;ad hoc&amp;quot; by group *ith
rival theory Y
</construct>
<tableCaption confidence="0.510473774193548">
The research described in this paper was supported
by the Advanced Research Projects Agency of the
Department of Defense and monitored by the Office
c:Nf Naval Research under contract N00014-75-C-1111.
To get to our neutral case, we shall sLartâ€˜ our
discussion where X is Conceptual Dependency and Y
is Transformational Generative Grammar. Before I
begin, I should note that there are conditions on
X and Y relative to each ether, namely that X must
be a theory that has been conceived at a date
later than Y was conceived s Furthermore Y should
have been ,dominating some academic field which X
is seeking to invade.
What makes a theory X assailable by Y as ad
hoc? There are a number of criteria:
1 - x must explain a phenomenon that Y chose
to ignore and that Y would rather go on
ignoring since I could not possibly explain
it.
2 - X must be fundamentally at variance with
Y, so that if X were right Y would be
necessarily wrong.
3 - X must Liae different criteria of judgment
of how a phenomena should be explained than Y
does.
The following rules are used for the
strategy to be followed in labelling an X as
ad hoc:
1 - Since X will undoubtedly show how its
theory explains a given particular
phenomenon, accuse X s theory of only working
</tableCaption>
<bodyText confidence="0.993686557692307">
in that case. This will put the burden of
proof for generality on X rather than Y and
also has the desirable effect of puttini X in
the position of not being able to prove
anything with out proving everything.
2 - Choose a phenomenon to explain in which
It is virtually impossible to explain
everything, thus giving game and set to Y.
Consider our hypothetical case Where
Conceptual Dependency is X and Tranformational
Grammar is Y. An examination of the literature
will show-that criteria I through 3 as well as the
two available strategies have been used by the
Transformationalists. In various articles and
public performances charges of &amp;quot;ad hocness&amp;quot; have
ii
been raised against Conceptual Dependency. We are
told that our structures only work for the
examples we discuss, that we have &amp;quot;no principled
way of going from a sentence to a
conceptyalization&amp;quot; (Dresher and Hornstein (1976))
or that &amp;quot;Shank provides no demonstration that his
scheme is more than a collection of heuristics
that happen to work on a specific class of
examples&amp;quot; (Weizenbaum (1976)). (If the reader is
wondering how Weizenbaum got to be a
transformationalist in my view, he need only read
Weizenbaum s further,remarks extolling Chomsky as
having met the criteria that he chants I have not
met.)
TO what extent are these charges valid? To
not knowing if one can extract a conceptualization
from any sentence (and its corroborating charge of
not proving that there exists a right Cl) diagram
for any sentence) I plead guilty. But of course,
I would be less than completely honest if I did
not also note that there does not exist any theory
or theorist Who would not also have to plead
guilty. Have the transformationalists shown us
that they have some principled way of extracting
conceptualizations from sentences or determining
the correct representation for any sentence?
Unless they are keeping their solution as a secret
plan not to be revealed until after the election,
I would have to imagine that the answer to this is
that they do not have a solution to the problem.
So clearly, they are no more or less ad hoc than
we are. (Of course I might note here that we do
have programs that suggest that we can do a large
class of examples and show that our parsers are at
least the beginning of some set of principles that
work, but I won t).
</bodyText>
<subsectionHeader confidence="0.816936">
What about Weizenbaum s attack? Perhaps it
</subsectionHeader>
<bodyText confidence="0.988100791666666">
is all heuristics. To this charge I plead no
contest. It might be that, in the end, we will
have built a working program that solves the
entire natural language problem and it will be
easily labelled as a grand set of heuristics.
Won&apos;t that be terrible! To quote Dresher and
Hornstein again, &amp;quot;Not only has work in Al not yet
made any contribution to a scientific theory of
language, there is no reason to believe that
(AI)...will ever lead to such theories&amp;quot;.
And what will they say after success has been
achieved and the ultimate natural language system
has been designed? The same thing of course.
Chomsky himself (personal communication) has
claimed that such an achievement would be no more
interesting than the achievement of the 16th
century clockmakers.
I mention all this in the hope of pointing
out that it is not just me and my theories that
are damned by criticisms of ad hotness. We are
all damned by them. Our ultimate success would
not be even recognize&amp; much less applauded by
those Who criticize OUT solutions as ad hoc.
Suppose every domain we worked on required yet
another ad hoc solution. This might well be the
case after all. What would we lose if this
happened? Nothing at all. That $ What artificial
intelligence is all about. Al is the designing
and testing of theories about human understanding
capabilities. There is, at the moment, no reason
to believe that people solve puzzles the way they
read newapapers or that they play chess the way
they answer questions. Of Course, we all hope
that there exist some general mechanisms that
solve all these problems in some neat way. We
hope this in large part because we are lazy. We
would not like to have to work on each problem
individually. We aiso hope this because we
believe our intuitions When they tell us how
reading a newspaper is a lot like watching a soap
opera. A word of caution is necessary here.
Beware of our intuitions. As a child you learned
how to do each of these things separately and were
pained to deal with each one of them. Of course,
we do expect there to be some general principles
that apply across domains., But if these
principles are affix â€” hopping or trace â€” deletion
we are all in trouble.
</bodyText>
<subsectionHeader confidence="0.976745">
Part II
</subsectionHeader>
<bodyText confidence="0.921122896551724">
Having said all this, now let me tell you
what I actually believe. I do not believe that
any of our theories are ad hoc. &apos;,Just because CD
needed to be modified by causal chaining rules,
and those by scripts and those by plans and goals
and themes, and those by triangles, does not mean
that what we are doing is ad hoc. We are no more
ad hoc in hypothesizing our primitive elements
than chemists were in hypothedzing theirs. I do
not know what the ultimate result will be. How
many elements make up the correct number, or what
other kinds of formalisms will need to be added to
those listed above is still unknown.
I. do know how Al does its research however.
We build a program to do a small class of examples
and when we are finished we rip it apart and build
a bigger and better program to do larger examples.
In so doing, ad hoc entities (oftimes called
kludges) cannot survive. If a formalism does not
keep handling more data it is either abandnsed or
moved down to a special purpose role within a
larger program.
Well, in ten years of research by my research
group what has survived? After ten years and
probably a hundred different kinds of programs,
Conceptual Dependency is still with us. It still
works for us. I challenge any other theory that
has been programmed to say the same! Is it ad
hoc? I leave that as an exercise for the reader.
</bodyText>
<subsectionHeader confidence="0.757111">
PART III
</subsectionHeader>
<bodyText confidence="0.980518944444444">
Just to give the reader a feel for the nature of
ad hoc thinking in Al that I believe to be worth
espousing, I will now consider a problem that I
have recently been working on. We have had a
problem in representing certain kinds of political
concepts in our old representation. Since we have
been very concerned with the problem of newspaper
story understanding it is very important that we
be able to handle such concepts in a clean
representation that will facilitate computer
understanding.
The problem we are attempting to solve can be
illustrated by looking at a recent New York Times
headline &amp;quot;Catawba Indians land claim supported.&amp;quot;
The problem here is to be able to represent what
&amp;quot;land claim&amp;quot; and &amp;quot;supported&amp;quot; mean. We know that a
land claim is more than What we might use to
12.
</bodyText>
<subsectionHeader confidence="0.707409">
represent it in Conceptual Dependency.
</subsectionHeader>
<bodyText confidence="0.997790275862069">
Something like &amp;quot;Indians MTRANS land be
possessed by Indians&amp;quot; is possibly true, but it
misses the point. A &amp;quot;land claim&amp;quot; is in a sense a
petition to 4 higher authority to resolve a
dispute between two parties. That is, the Indians
are saying to the U.S. Government, &amp;quot;this land is
ours&amp;quot;. It may not be possible to infer the
particulars of this land claim. Indians have been
known to take the land by force, to&apos;file documents
in government offices, to Complain to newsmen and
so on. The important point here is tHht we really
need not know, and in most cases a reader would
not bother to worry about, exactly which method
has been selected. Rather, a reader feels that he
understands such a sentence when he has been able
to identify the relationships and aims of the
parties involved.
A program must recognize that a &amp;quot;land claim&amp;quot;
is a type of petition to a higher authority to
resolve a dispute about land ownership. We do not
know who presently owns the land, but we know
enough about ownershio of property to infer that
there is probably a counter petition of some sort.
We also know about petitions to authority. They
usually get resolved by the authority. In this
case then, &amp;quot;supported&amp;quot; refers to the decision of
the authority in the case.
This information can be represented
graphically by a kina of triangle (example 1)
</bodyText>
<sectionHeader confidence="0.592701" genericHeader="method">
AUTHORITY
</sectionHeader>
<figure confidence="0.753044666666667">
(c)
Catawba Indians
(a)
</figure>
<bodyText confidence="0.9085596">
In this triangle (a) represents the dispute
between the Indians And the owners of the land,
(a) represents the appeal to authority to resolve
the dispute nade by the Indians, and (c)
represents the authority&apos;s decision.
</bodyText>
<subsectionHeader confidence="0.569081">
Triangles of this sort have, use in
representing any type of dispute.
</subsectionHeader>
<bodyText confidence="0.698791">
(2) and (3) such triangles For example, in
</bodyText>
<subsectionHeader confidence="0.6817845">
can also be
constructed
</subsectionHeader>
<bodyText confidence="0.612914">
(2) Burma appeals to UN to settle border dispute
with Thailand.
</bodyText>
<sectionHeader confidence="0.793704" genericHeader="method">
UN
</sectionHeader>
<subsectionHeader confidence="0.739253">
Thailatd
</subsectionHeader>
<bodyText confidence="0.977355265625">
(3) John complained to Bill&apos;s mother that Bill hit
him.
Of course, these triangles just suggest the
basic relationships involved. In order to add
substance to the bare bones of the triangles we
shall have to deal with some representational
issues that are being glossed over here. The
important point at this juncture is that there is
an essential similarity across (1), (2) and. (3),
that the similarity must be represented in some
way, and that that similarity can be exploited for
use in an understanding system.
The first representational problem we
encounter in trying to make explicit much of what
is implicit in the triangle representation is that
we will need to design a new set of ACTs to take
care of the various relationships.
In the primitive ACTs of Conceptual Dependency
we have a system that represents physical actions
by using a small set of basic actions that can
combine in various ways to describe detailed or
complex actions that underlie seemingly simple
#erbs and nouns. The primitive ACTs do not
account for intentionality and goals underlying
physical adtion. To account for such things we
devised a complex apparatus discussed in Schenk
and Abelson (1977). If we wish to account for
social events, we will need a system of basic
social ACTs to represent the social actions that
comprise the events. I term these &amp;quot;basit social
ACTs&amp;quot; rather than primitive ACTs because in the
end most social ACTs have some physical
manifestation4. Often their physical manifestation
is uninteresting however. For example a
government decision may be MTRANS-ed in a variety
of ways. The manner of the MTRANSe (written,
a9nounced in a speech, etc) is often not
significant with respect to the overall social
effect of the action. Furthermore the MTRAFS
Itself is only slightly interesting. The standard
inferences from MTRANS apply, but there are some
highly significant inferences that need to be made
that are not obviously available.
For example, the most significant inference
to be made from an authority&apos;s decision is that
simply by virtue of that decision something has
actually happened- That is, a government
authorization is a truly performati4e ACT. Thus, if
the government says some property is mine, or that
a man-is a criminal, then it is so by virtue of
their saying it. Similarly other authority
figures have the same power. A professor can say
a thesis is finished and a student has a Ph.D.
and these things are the case by virtue of his
saying it.
Not all authority&apos;s decisions are like this
to be sure. Sometimes an authority gives an order
and that order must be carried out for the
decision to have effect. Frequently these orders
come about as 4 result of a governmental decision
or authorization. If the government says the land
belongs to the Catawba Indians, then it does, but
they may have to send in the National Guard to get
the original owner off the property.
</bodyText>
<figure confidence="0.605556">
Other
Burma
</figure>
<figureCaption confidence="0.316628666666667">
Bill&apos;s Mother What I am proposing then is two basic social
ACTs - AUTHORIZE (abbreviated AUTH) and ORDER.
AUTH is something only an authority can do. (This
is a bit circular actually since if you actually
Bill can AUTH then that deftnes you as an authority.)
John
</figureCaption>
<bodyText confidence="0.992168166666667">
In a sense then, an authority is one Who When he
acts like he is doing an AUTH (that is he does the
physical ACTs that ordinarily correspond to an
AUTH) in fact causes some things to happen as a
result of the AUTH that were supposed to be the
results of the AUTH. In other words, you cannot
really tell if an AUTH has taken place until it
becomes clear that the person doing the AUTH &apos;titan
back up his AUTH in some way.). The object of the
AUTH is the authorization or new state of ehe
world. AUTH takes a recipient, namely the
relevant parties in the dispute.
</bodyText>
<tableCaption confidence="0.660538142857143">
ORDER is a frequent inference of AUTH. The
government can AMR the army to fight a war, bur
that doesn&apos;t, simply by virtue of the statement,
imply that they are fighting it. A subsequent
ORDER is required that carries with it the
implicit punishments that are relevant in carrying
out an order.
</tableCaption>
<bodyText confidence="0.991591446808511">
Why can t we do these things with CD
primitives we now have? What is the advantage of
these new ACTs? To answer these questions, we
need to look at the purpose of a primitive ACT.
It is possible to represent ORDER in CD for
example. The verb &apos;order&apos; means to MTRANS to
someone that they must do a particular action
or Lace some (usually implicit) conseqoence.
Thus, implicit in the verb &apos;order&apos; but explicit
in the PD representation for &apos;order&apos;, is the idea
that if the required ACT is not performed then
someone will possibly do something to harm the
recipient of the order in some way. This implied
punishment is a part of the concept &apos;order&apos; but is
It necessary that we think of it each time that we
understand an order to have taken place?
The same question can be asked with respect
to authorize . We understand What authorization
or governmental decision is, but we need not
access all that information each time we
understand the word. Consider the problem of
explaining the meaning of these words to a child
for example. It is very difficult to explain them
precisely because they are so complicated at the
level of physical primitive ACib Yet these ideas
are really not complicated at all at a social
level of ACTs. Such simple concepts such as ORDER
and AUTHORIZE form the basis of the organization
of societies. What is complex at one level is
simple at another. This idea of nested levels of
complexity, each with their own set of primitives,
is a very important one for the representation of
information in artificial intelligence. By
choosing a good set of primitives we can
effectively organize what we need to know. Thus,
ORDER and AUTHORIZE have inferences that come from
them just as the physical primitive ACs do, The
main difference is that these basic social ACTs
are not primitive in the same sense. They can be
broken down but we would rarely choose to do so.
The use of these new basic ACTs is much like
the dhe of the original primitive ACTs. We can
predict what will fill slots reasonably in a
conceptualization and make inferences about slot
fillers and consequent inferences as we would any
conceptualization. Thus we represent sentences
such as the following using AUTH
</bodyText>
<figure confidence="0.9553779">
(4) The Supreme Court decided segregation is
illegal.
0 R people of
S.C.â€¹..&gt;AUTH&lt;---segrtgation&lt;---IU. S.
US&lt;=.&gt;ORDER&lt;-- punishment
(5) The cop gave the speeder a ticket.
drive ---&gt;driver
---&lt;govt.
money
govt.
</figure>
<bodyText confidence="0.979149769230769">
In (4) we have chosen to ignore representing
segregation for the moment, since it is
obviously complex. Supreme Court decisions are
AUTHs. They also carry with them (as do most
AUTHS) an implicit ORDER for &apos;punishment&apos; if
certain circumstances are not met The
straightforward inference from (4) then is that
someone practicing segregation tan expect to be
punished.
Policemen are authorities also. In (5) the
ticket is a written manifestation of an AUTH that
either puts the driver in a DEFENDANT role in a
$TRIAL script or forces him to pay a fine. The
instrument of the AUTH is the actual PTRANS of the
ticket (left out here). The important point here
is that we could represenv (5) using PTRANS only.
However, what we would be describing is the
physical ACT itself when it is the social ACT that
Is significant here. (When I was young there was
much talk of bad kids getting &amp;quot;JD cards&amp;quot;. I never
understuvd what was so horrible about that.
Couldn&apos;t they just throw them away?) The social
significance of an ACT must be represented if it
is understood.
Now that we have presented these two ACTs
let&apos;s return to our triangle
</bodyText>
<sectionHeader confidence="0.691853" genericHeader="method">
AUTH
</sectionHeader>
<bodyText confidence="0.8094565">
(///\
, (followed by a possible ORDER)
</bodyText>
<sectionHeader confidence="0.644802" genericHeader="method">
DISPUTE
</sectionHeader>
<bodyText confidence="0.885388375">
The ACT PETITION represents an individual or
group&apos;s act of requesting AUTH&apos;s from an
authority. Thus a &amp;quot;civil suit&amp;quot; is a PETITION to
the courts using some legal scripts. A protest
demonstration is a PETITION to unstated
We have named one side of the triangle. The other
sides represent ACTs as well. The complete
triangle is as follows
</bodyText>
<equation confidence="0.531387">
0 driver
V
$TRIAL
&amp;DEFENDANT
It,
</equation>
<bodyText confidence="0.99957655">
authorities using some demonstration script. The
point here is that we cannot do away with the
scripts that describe the actual physical
manifestations of these events. However, the
scripts are instruments of the social ACT involved
â€” PETITION. The most important inference from
PETITION is, of course, that an AUTH is expected
that will resolve the issue that is the object of
the PETITION.
The issue that is the object of the PETITION
is the DISPUTE itself. DISPUTE takes two actors
(one orwhom may be quite passive). Thet object of
the DISPUTE is the issue involved. DISPUTE takes
no recipient as it is not an inherently directed
ACT. It is the ACT of PETITION that directs it to
a particular authority who can AUTH something that
will resolve it.
We are now ready to deal with sentence (1)
(Catawba Indians Land Claim Supported). The
representation using the new social ACTs is
</bodyText>
<figure confidence="0.921962428571429">
Indians0.&gt;DISPUTE&lt;--(OWN (land) &lt;0?)
/\
other
---&gt;US
Indians&lt;=&gt;PETITION&lt;--(OWN(land)&lt;=&gt;?)&lt;--I
It ---andians
II ---&gt;Indians
</figure>
<sectionHeader confidence="0.591874" genericHeader="method">
IJ I or other
U. S. &lt;=&gt;AUTH&lt;--(OWN(land)&lt;=&gt;Indians)1
</sectionHeader>
<bodyText confidence="0.968138707317073">
Since this representation is not as easy to
write as the triangular one, We shall continue to
use triangles in the remainder of the paper. Thus
(1) is
U.S. Gov&apos;t.
OWNS(land)&lt;=&gt;Indians
Indians Other
OWN(land)&lt;=&gt;?
We will leave out the arrows and the ACTS for
diagrammatic purposes, but the above triangle
should be understood as containing all the
information given in the CD diagram for (1).
(Actually the triangles contain more imformation.)
Triangles provide us with a method for
representing the social significance of actions.
As with any other representation scheme, the
advantage of the symbols we create can only be in
the new symbols or actions that they spawn. That
is, it is the inferences that come from the
triangles that are of key importance. When we
created the original primitive ACTs we said that
PROPEL was no more than the set of inferences that
it fired off. The same it true here, so we must
ask what these inferences are.
The first thing we can recognize about
potential inferences here is that they will come
fh two varieties. The first are the inferenced
that are fired off from the new social ACTs that
we have created. The second kind are those that
come from the triangles themselves. That is,
there should be patterns of triangles. that are
recognizable for the triangles they spawn as well.
as a set of inferences that come from the fact
that certain triangles exist.
Aq examples of this let us consider again
sentence (2)
(2) Burma appeals to UN to settle border dispute
with Thailand.
Since the representation of (2) involves a
PETITION we can employ the inference rules that
are fired by PETITION. Some of these are
</bodyText>
<listItem confidence="0.6006345">
a. For every PETITION we can expect
corresponding AUTH.
b. For every PETITION there was probably. a
DISPUTE that gave rise to it.
</listItem>
<bodyText confidence="0.9993328">
These rules lead us to the inferences available
from AUTH and DISPUTE. Of course., inferences from
inferences have a lower probability of truth, so
for (2) the inferences below would be somewhat
less certain.
</bodyText>
<listItem confidence="0.902587875">
c. An AUTH con cause a DISPUTE to end.
d. An AUTH can cause a PETITION to a higher
authority from the party unfavorably affected by
the AUTH.
e. An unfavorable AUTH can cause a rebellion, or
lacK of acceptance of the validity of the AUTH.
This can give rise to ORDERs to effect the AUTH in
the case of individnals versus governments or wars
in the case of goveillmental conflicts
f. An AUTH causes a new state of the world to
exist, often ending an old state in conflict with
the new state.
g. A DISPUTE can cause one party to PETITION.
h. A DISPUTE can cause a PROPEL to cause damage
to occur for individuals, or a WAR triangle to be
initiated for countries.
</listItem>
<bodyText confidence="0.995452166666667">
There are, of course, a great many more of these
kinds of inferences than we are listing here. The
above list is mostly 4.ntended to give the flavor
of basic social ACT inferences. It is important
to note that the social ACTs jgive rise to
inferences at both of the other levels of
representation besides those at the same level of
representation. That is, given a social ACT we
may be able to infer another social ACT, a new
primitive ACT, or a new triangular representation.
Thus, for (2) we have two representations to
start with one is at the standard CD level and
uses MTRANS, the other is at the social level and
uses PETITION. Both of these representations
would be available as output from the parser.
The MTRANS representation would fire off
inferences about the methods of communication
possibly used - that the UN now knows about the
problem and so on.
The PETITION representation would fire off
inferences about the expected AUTH from the UN.
Since we know how the UN does its AUTHS, this
would fire off a UN script of some kind that dealt
with voting and debate. PETITION would also cause
DISPUTE to be inferred which would cause
inferences about the kind of methods possibly
employed by the quarreling countries, both in
creating the DISPUTE and escalating it.
The existence of the PETITION-AUTH-DISPUTE
triangle would fire off an inference that the
country kind of triangle existed. Thus, a new
triangle that was lopsided showing possible
aggression from Thailand towards Burma would be
created. This triangle would in turn fire off
inferences about attempts to RESOLVE the DISPUTE
(one of which was (3) itself) and would predict an
escalation towards the WAR triangle with its
normal inferences if a RESOLVE did not take place.
Although the above is rather sketchy, the
point should be clear. We need additional
representational mechanisms to handle the many
levels at which statements can be interpreted.
Triangles provide us with a new set of inference
rules providing more power to the understanding
system. Are they ad hoc/ Of course they are. My
point is simply that such ad hoc mechanisms will
either solve the problem or help us create a more
general solution ehat will solve the problem. The
program that we are writing that uses triangles is
also ad hoc. Is is a kludge? No. If it were it
wouldn&apos;t be worth a thing. But, here again % if
the program we write can handle many examples as
we rewrite it because of What we have learned from
it, then it will hay been worthwhile.
The program below reads newspaper headlines
in English and generates, by use of triangles and
the inferences available from triangles, a
paraphrase of the input. This English para-
phrase is generated by the program.
*******************************************
</bodyText>
<sectionHeader confidence="0.98100325" genericHeader="method">
TRIANGLE analyzer loaded.
INPUT SENTENCE
(CATAWBA INDIAN LAND CLAIMS SUPPORTED)
(PARSE II) CON4
</sectionHeader>
<bodyText confidence="0.560105">
Expanding token CON4 =
</bodyText>
<sectionHeader confidence="0.981037" genericHeader="method">
(CON ((ACTOR (*PP* CLASS (1/GROUP)
CFEATURE (*AMERINDIAN*) TYPE
(*ETHNIC*) NAME (CATAWBA) TOK NPI)
.&lt;=&gt; (*PETITION*) OBJECT ((ACTOR
</sectionHeader>
<bodyText confidence="0.545312">
(*PP* CLASS (#REGION) TOK NP2 REL CON1)
</bodyText>
<sectionHeader confidence="0.7159075" genericHeader="method">
IS (*OWN* VAL NPI)) TOK CONI)
FROM NPI TO (*PP* CLASS (I/INSTITUTION)
MEM *COURT* TOK NP3)) TOK CON2)
lk ((ACTOR NP3 &lt;=&gt; (*AUTH*) OBJECT CON1
</sectionHeader>
<bodyText confidence="0.985882074074074">
RECIP1 NPL RECIP2 GAP1 FROM
GAP2) TOK CON3)) TOK CON4)
The Catawba Indians asked a Federal
Court to rule that they own the land.
The Catawba Indians requested a Federal
Court to rule that the land is owned by
them.
The Catawba Indians appealed to a Federal
Court.
The Catawba Indians asked a Federal Court
to rule that they own the land and it
decreeed that the land is owned by them.
[ Generating inferences from CON4 ]
&gt;(TELL -STORY)
The Catawba Indians and the other parties
disagreed over the ownership of the land.
The Catawba Indians requested a Federal
Court to rule that they own the land.
A, Federal Court decided theft the land is
owned by the Catawba Indians.
The other parties will probably appeal the
decision.
The other parties might use force against
the Latawba Indians to assert that they
own the land.
This program was written by Jaime Carbonell and
Stephen Slade.
</bodyText>
<sectionHeader confidence="0.930668" genericHeader="method">
References
</sectionHeader>
<bodyText confidence="0.999677545454546">
Dresher, B.E. and Hornbrein, N. [1976] On some
supposed contributions of artificial intelligpnce
to the scientific study of language, Cognition,
4(1976) 321-398.
Ichank, R.C. and Abe].son, R.P. [1977], Scripts,
Plans, Goals and Understanding An Inquiry into
Human nowledge Structures, Lawrence Erlbaum
Associates, Hillsdale, New Jersey.
Weizenbaum, J., [1976], Computer Power and Human
Reasoninp, W.H. Freeman and Company, San
Francisco.
</bodyText>
<page confidence="0.994971">
13
</page>
<subsectionHeader confidence="0.533271666666667">
The Relation of Grammar to Cognition--a Synopsis
Leonard Talmy
Program in Cognitive Science / Center for Human Information Processim
</subsectionHeader>
<bodyText confidence="0.993484484848486">
Abstract
A sentence tor other portion of discourse) is
taken to evoke in the listener a meaning complex,
here called a &amp;quot;cognitive representation&amp;quot;. The lex-
ical elements of the sentence, to simplify, by and
large specify the content of the cognitive represen-
tation, while the grammatical elements specify its
structure. Thus, looking systematically at the
actual notions specified by grammatical elements can
give us a handle for ascertaining the very makeup of
(linguistic-) cognitive structuring. We accordingly
examine a number of grammatically spec Tied notions,
observe the categories and systems in which they
pattern, and speculate on broader cognitive connec-
tions.
Some provisional findings have already emerged.
Grammatical specifications for structure are prepon-
derantly relativistic or topological, and exclude the
fixed or metrically Euclidean. The categories in
which grammatical notions pattern idtlude:
,plexity perspectival mode
state of boundedness level of synthesis
state of dividedness level of exemplarity
degree of extensionality axial characteristics
pattern of distribution scene-breakup &amp;quot;
Grammatical specification&apos;of structuring appears to
be the same, in certain abstract characteristics, as
the structuring of visual perception.
O. Introduction
A sentence (or other portibn of discourse) is
taken to evoke in the listener a particular kind of
experiential complex--here to be termed a &amp;quot;cognitive
representation&amp;quot; or &amp;quot;CP&amp;quot;.1 There appears to be a sig-
nificant way in which different portions of the lan-
guage input specify, pr code for, different portions
of the CR. The major finding, is that--for a first
approximation--the lexical fraction of a. sentence
codes mainly for the content, or substance, of a CR,
while the grammatical fraction of a sentence codes
mainly for the structure of a CR. Determining the
structure within a realm of phenomena has been a cen-
tral concern for analytic science, including linguis-
tics and psychology. With grammar seen in the above
light, it can be used in determining the structure,
of the language-related portion of human cognition,
with possible connections to further porrions. In
particular, looking systematically at the actual not-
ions specified by grammatical elements can give us a
handle for ascertaining the yery nakeup of (linguis-
tic-) cognitive structuring.4 The beginnings of such
an endeavor are the aims of this paper
Several ideas here require some immediate elab-
oration. The distinction between lexical and gram-
matical is made entirely formally--i.e., without any
reference to meaning--on the basis of the distinc-
tion between open-class and closed-class.3 All open-
class elemqnts--i.e., the stems of nouns, verbs, and
adjectives--are considered lexical. Everything else
is considered grammatical. Included here are all
closed-class morphemes and words--inflections,. par-
ticles, adpositons, conjunctions, demonstratives,
etc.--as well as syntactic constructions, grammatical
relations, categorial identities, word order, and
intonation. Terminologically here, &amp;quot;grammatical
element&amp;quot; will be used to refer to any of these.
The nature of content and of structure, and the
distinction between them, are not understood well
enough to be addressed analytically in this paper and
must be left to our intuitive sense of the matter.5
Taking them for granted, however, we can now more
finely characterize the linguistic-cognitive cross-
relationships noted earlien While most of a CR&apos;s
content is specified by the lexical fraction of a
sentence, the lexical items do usually specify some
structural notions along with the contentful ones.
The grammatical elements OT a sentence more unalloy-
edly specify only structural notions and specify them
more determinately in the case of conflict with a
lexical item, qtablishing perhaps the majority of a
CR&apos;s structure.Â°
In other work in the present direction--notably
Fillmore&apos;s (e.g., 1975, 1976)--concern has also been
with ascertaining structre, but the sentence elements
used as starting-points have generally been lexical
items with prominently inmixed structural specifica-
tions (like buy and sell). The present work, in pert
a complement to the other, takes advantage of gram-
mar&apos;s greater directness and completeness In speci-
fying structure.
This paper is divided into three sections. In
the first, a sampling of grammatical elements is ex-
amined for the notions that they specify, both as an
introduction to out method and for the aim of notic-
ing properties common to such notions as well as pro-
perties excluded from them. In the second, we pre-
sent a number of the categories in which grammatically
specified notions have been observed to pattern. In
the third, we speculate on broader cognitve connec-
tions.
</bodyText>
<page confidence="0.996036">
14
</page>
<sectionHeader confidence="0.491359" genericHeader="method">
1. The Nature of Grammatically Specified Notions
</sectionHeader>
<bodyText confidence="0.999631357142857">
In this section we examine a small sampling of
grammatical elements for the particular component
notions that they specjfy. The sample will give a
heuristic indication of the kinds of notions that get
grammatically specified as well as of kinds of no-
tions that possibly never do. The excluded kinds
will be seen as readily specifiable by lexical ele-
ments. A further comparison between the character-
istics of grammatically specified notions and of
lexically specified ones is then made. To indicate
the major finding at the outset, it seems that.gram-
matical specifications for structure are preponder-
antly relativistic or topological, and exclude the
fixed or metrically Euclidean.
</bodyText>
<subsectionHeader confidence="0.812101">
For a first simple case, many languages have in-
</subsectionHeader>
<bodyText confidence="0.956266371428572">
flections for the noun (English has and -1.
that specify the uniRlex or the multiplex instantia-
tion of &apos;the object specified by the noun. By con-
trast, no languages appear to have inflections that
specify the redness or blueness, etc.--i.e., the par-
ticular color--of the object specified by a noun.
In the preceding, the underlined are indtances of
&amp;quot;notions&amp;quot;. The first set are grammatically specified
add can be readily seen to play a structuring role
in -a CR.7 The second set are perhaps never found
specified by grammatical elements, though they are
everywhere found specified by lexical elements (such
as (red. and blue).
another
ohcer:ecne the
EnglirtrtatarinTisch4nroke.
grammatical element of this type specified the loca-
tion of an indicated object as being, in effect, on
the speaker-side or the non-speaker-side of a concep-
tual partition drawn through space (or t4me or other
qualitative dimension). This integral specification
can be analyzed as containing the following component
notions (enclosed by quotes):
a-b. a &apos;partition&apos; that divides a space into
&apos;regions&apos;/&apos;sides&apos;
c-e. the ilocatednes&apos; (a particular relation) of a
&apos;point&apos; (or object idealizable as a point)
&apos;within&apos; a region
f-g. a side that is the) &apos;same&apos; as or &apos;different&apos;
from
h-i. a &apos;currently indicated&apos; object and a &apos;currently
communicating&apos; entity
Notions that might at first be ascribed to such deic-
tics, such as of distance or perhaps size, prove not
to be,on the evidence of sentence-pairs like (2):
</bodyText>
<listItem confidence="0.9168875">
(2) a. This speck is smaller than that speck.
b. This planet is smaller than that planet.
</listItem>
<bodyText confidence="0.999590444444444">
The CRs evoked by (2a) and (b) differ greatly, in-
volving tiny objects millimeters apart or huge objects
parsecs apart. Yet the sentences differ only lexic-
ally, not grammatically. Hence, the CRs&apos; notions as
to the magnitude of size or distance cannot be traced
to the deictics (or to other grammatical elements) in
the sentences. Thus, the notional specifications of
a this or a that appear, in part, to be genuinely
topological: the establishment of a partition remains
a constant, but its position can vary unlimitedly (or,
using topology&apos;s characterizability as &amp;quot;rubber-sheet
geometry&amp;quot;, the partition&apos;s distance away can be
stretched indefinitely) without any constraints im-
posed by the deictics&apos; specifications per se. This
finding about the deictics alerts us to noticing
whether any grammatical elements make specifications
about magnitude. A spot check through English and
various other languages suggests that--while there are
apparently. grammatical specifications for relative
magnituded--there are possibly never any for absolute
or quantified magnitude, whether of size, distance,
or other parameters.
For a third case, we consider the type of adposi-
tion that specifies, for a moving object, certain
characteristics of path and of point- or frame-of-
reference! An example of this type is English through
as used, e.g., in:
</bodyText>
<listItem confidence="0.73133">
(3) a. I walked through the water.
</listItem>
<bodyText confidence="0.976299391304348">
b. I walked through the timeber (i.e.., woods).
In this usage, through specifies, broadly, &apos;motion
along a line that is within a medium&apos;. The component
notions contained here include:
4)
a-e. &apos;motion&apos;--i.e., &apos;one-to-one correspondences&apos;
between &apos;adjacent&apos; points of &apos;space&apos; and
adjacent points of &apos;time&apos;
f. motion that describes a &apos;line&apos;
g. the locatedness of a line within a &apos;medium&apos;
h-i. a medium, i.e., a region of bhree-dimensional
space set apart by the locatedness within it
of &apos;material&apos; that is in a pattern of dis-
tribution&apos; of a certain range of character
(still to be determined)
Again, with (3a) and (b) differing only lexically, any
notional differences in their CRs cannot be attributed
to through. Thus, not within the specificational
purvue of that element are: the &apos;kind nf substance&apos;
comprising the medium and the &apos;sensorimotor,character-
istics&apos; attendant on executing the motion--as, here,
those attendant on wading vs. weaving amidst obstacles.
With other sentence pairs like
</bodyText>
<listItem confidence="0.842165">
(5) a/b. I crawled/ran through the timber.
(6) a/b. I zig-zagged/arced throught the timber.
</listItem>
<bodyText confidence="0.970042375">
it can be further determined that &apos;rate of motion&apos; and
&apos;shape/contour of linear path&apos; are also not specified
by the grammatical element.
As one _step in a program to ascertain any proper-
ties common to grammatically specified notions, the
notions just found are gathered together in Table 1.
For heuristic purposes, the notions are very provis-
ionally divided into three groups on the basis of
their relation to topology. In group (a) are the
notions that properly belong, or are readily definable,
in the actual mathematical system of topology. In
group (b), the notions might not be part of topology
proper but intuitively seem like those that are--and
might be includable in a related mathematical system
that could be constructed. tn group (c) are the no-
tions that fall outside of any usual conception of a
mathematical system. The number of notions in the
first two groups combined is 13. while the third has
6--an indication of a preponderant propensity for
grammatical elements to specify quasi-topological no-
tions. The ratio in this direction is in fact im-
proved if we consider that even several notions,in
group (c)--the bottom three--resemble topological ones
in the sense of involving relativistic relationships
between quantities rather than absolutely fixed
quantities.
(7) Table 1: Some notions found to be specified
by graMmatical elements
a. topological
partition
region/side
point
line
locatedness
within
uniplexity
multiplexity
one-to-one
correspondences
For a complementary program of ascertaining any
properties excluded from grammatical specification,
the notions found above not to be specified by the
eleMents investigated are listed in Table 2. Rather
than topological, topology--like, or relativistic,
these notions involve Euclidean-geometric concepts
(e.g., set distance, size, contour), quantified mea-
sure, and various particularities of a quantity--in
sum, characteristics that are absolute or fixed.
</bodyText>
<listItem confidence="0.6466465">
(8) Table 2: Some notions seemingly never specified
grammatically
</listItem>
<bodyText confidence="0.9644765">
absolute/quantified magnitude kind ofisubstance
(of distance, size, etc.) speed
shape/contour of line color
sensorimotor characteristics
The provisional conclusion to be drawn from these
findings is that, if grammatical specifications largely
correspond to (linguistic-) cognitive structuring, then
the nature of that structuring is largely relativ-
istic.or tqpological rather than fixed or absolute.
In a search for contrasts between grammatical and
lexical specification, a difierence that presents
itself at this point is that the relativism vs. abso-
lutism restrictions do not apply to the latter. Lex-
ical items can specify topological and relativistic
concepts, as the very words listed in Table 1 attest
to. And they can also specify Euclidean or absolute
concepts. Thus, for the notion of color in Table 2,
there are such lexical items as red, blue; for con-
tour, there are circle, straight; for quantified
magnitude, there are inch, mile; for sensorimotor
characteristics, there are wade, nimble, effort.
For a further tcontrast between the grammatical
and the lexical type of specification, we consider
the full complement of both element-types in a single
whole sentence, viz., that seleeted in (9):
(9) A rustler lassoed the steers.
We first list the grammatical elements present in the
sentence and the notions that they specify:
</bodyText>
<listItem confidence="0.873332">
a. -ed: &apos;occurring at a time before that of
the present communication&apos;
b. the: &apos;has ready identifiability for the
addressee&apos;
c. a: &apos;not before in discussion or otherwise
readily indentifiable for addressee&apos;
d. -s: &apos;multiplex object&apos;
e. &apos;uniplex object&apos;
</listItem>
<bodyText confidence="0.941273928571429">
f, the grammatical category of &amp;quot;verb&amp;quot; for lasso:.
eventhood&apos;
g/h. the gram&apos;. category of &amp;quot;noun&amp;quot; for rustler/steer:
&apos;objecthood&apos; (one possible spec, of &amp;quot;N&amp;quot;)
i/j. the grammatical relations of &amp;quot;subject&amp;quot;/&amp;quot;object&amp;quot;
for rustler/steer:
&apos;agent&apos;/&apos;patient&apos; (among possible specs.)
k. active voice:
&apos;point-of-view at the agent&apos;
1. intonation, word-order, state of auxiliaries:
&apos;the speaker &amp;quot;knows&amp;quot; the situation
to be true and asserts it&apos;
The lexical items in the sentence can have their spec-
ifications characterized as follows:
</bodyText>
<listItem confidence="0.9003445">
(11) A tomplex of concepts involving:
a. rustler: property ownership, illegality, mode
</listItem>
<bodyText confidence="0.986632771428571">
of activity
appearance, physical makeup, relation
to animal kingdom
institution of breeding for intended
purposes, esp. human consumption
certain materials (a body and a lasso)
in certain configurations
movement sequences of materials&apos; parts
concomitant mental intentions, direc-
tings, monitorings, etc.
In surveying the lists, we can see these differ-
ences emerge: The grammatical elements are more num-
erous and their &apos;specifications seem simpler and more
structural. Together, their specifications seem to
determaine the main organizational and communicational
delineations of the CR evoked by the sentence. The
lexical elements are fewer in number, but their spec-
ifications are more complex and seem to comprise most,
of the content of the CR. The lexical specifications
are complex in three ways: compared to a grammatical
specification, each has a) more total information,
b) greater intricacy of information, and c) more dif-
ferent types of information together.
These grammatical-lexical differences can be set
into further relief by in turn varying one element-
typewhile keeping the other constant. Thus, varying
only the grammatical elements of (9), as is done in
(12), seems to alter the organizational and communic-
ational characteristics of the scene but to leave its
basic contents intact:
(12) Will the rustlers lasso a steer?
Varying only (9)&apos;s lexical elements, as in (13), shifts
us to a new scene altogether, and yet the essential
breakup of the scene and of the communitative setting
seem to remain the same:
</bodyText>
<listItem confidence="0.853267">
(13) A machine cancelled the stamps.
</listItem>
<subsectionHeader confidence="0.972948">
Categories of Grammatically Specified Notions
</subsectionHeader>
<bodyText confidence="0.999652857142857">
The preceding sampling of grammatical elements
has yielded a set of notions helpful toward discovering
common properties. But the set has been small and
haphazardly arrived at. With a broader and more sys-
tematic investigation, patterns of organization become
evident. Grammatically specified notions can be seen
to pattern in categories, and the categoriet, in turn,
</bodyText>
<figure confidence="0.9990611875">
b. topology-like
same
different
pattern of distribution
&amp;quot;adjacency&amp;quot; of points
(monotonicity).
c. non-topologidal
matter
space
time
motion
medium
currently indicated/
communicating entity
b. steer:
c. lasso:
</figure>
<page confidence="0.978516">
16
</page>
<bodyText confidence="0.99996205882353">
in integrated systems. In this section we look at
some of these categories and systems.
The grammatical elements here will not be treated
in isolation, but in association with lexical items.
That is, the grammatically specified structural no-
tions will be considered in interaction with that
portion of lexical specification that is also struc-
tural. This interaction entails cognitive processing,
and different cases of such processing will be con-
sidered along the way.
The note on methodology should be made that our
direction of analysis has been from grammatical spec-
ificatien to category, not the reverse. That is, the
categories considered below were discovered to be
relevant to the specifications of various grammatical
elements. They were not part of some a priori concep-
tual schema which then sought corroborative examples.
</bodyText>
<subsectionHeader confidence="0.74075">
2.1 Dimension / Kind of Quantity
</subsectionHeader>
<bodyText confidence="0.9997985">
The category of &amp;quot;dimension&amp;quot; has two member no-
tions, &apos;space&apos; and &apos;time&apos;. The kind of &amp;quot;quantity&amp;quot;
that exists in space is--in respectively continuous
or discrete form--&apos;matter&apos; or &apos;objects&apos;. The kind
of quantity existing in time is &apos;action&apos; or &apos;events&apos;
(&amp;quot;action&amp;quot; is meant to refei. to any obtaining circum-
stance not just (willed) motion). In tabular form,
these notions relate thus:
</bodyText>
<listItem confidence="0.966774">
(13) space: matter/objects
</listItem>
<bodyText confidence="0.959083285714286">
time: action/events
A number of grammatical and lexical referents are
specific with regard to one or the other pole of this
category. But since the category cross-cuts the ones
treated next, we will not exemplify it here but will
endeavor in the following, to present both space and
time examples side by side.
</bodyText>
<subsectionHeader confidence="0.941018">
2.2 Plexity
</subsectionHeader>
<bodyText confidence="0.999958925925926">
The category here to be termed &amp;quot;plexityn- is a
quantity&apos;s state of articulation into equivalent ele-
ments. Where the quantity consists of only one such
element, it is &amp;quot;uniplex&amp;quot;, and where it consists of
more than one, it is &amp;quot;multiplex&amp;quot;. When the quantity
involved is matter, plexity is, of course, equivalent
to the traditional category of &amp;quot;number&amp;quot; with its com-
ponent notions &amp;quot;singular&amp;quot; and &amp;quot;plural&amp;quot;. But the pre-
sent notions are intended to capture the generaliza-
tion from matter over to action, which the traditional
ones do not.9
Specifications as to plexity are made by both
lexical items and grammatical elements, and the in-
terplay between the two when they are both in associa-
tion must be noted. Example English lexical items
that basically specify a uniplex referent are--for
matter and action, respectively--bird and (to) sigh.
They can occur with grammatical elements that them-
selves specify a uniplexity, like those underlined
in (14a) (many languages have here a more regular,
overt system of markers than English). But they can
also occur with grammatical elements that specify a
multiplexity, as in (14b). In this association, such
elements can be thought to trigger a particular cog-
nitive operation--in this case, one of &amp;quot;multiplexing&amp;quot;
By this operation, an original solo referent is, in
effect, copied onto various points of space or time.
</bodyText>
<listItem confidence="0.928346333333333">
(14) matter action
a. uniplex A biFFI-Tqw in. He sighed (once).
b. multiplex Birds flew in. He kept sighing.
</listItem>
<bodyText confidence="0.960421095238095">
The reverse of the preceding circumstances is
also to be found in language. First, there are lex-
ical items that intrinsically specify a multiplexity.
English examples are furniture or timber (i.e., &apos;stan-
ding trees&apos;) for matter and breathe for action, as
used in (15a). And, too, there are grammatical ele-
ments able to appear in association here, as in (15b),
that signal an operation the reverse of multiplexing--
one that can be called &amp;quot;unit-excerpting&amp;quot;. By this
operation, a single one of the specified equivalent
units is taken and set in the foreground of attention.
(15) matter
action
a. multiplex Furniture overturned in the &apos;quake.
She breathed without pain.
b. uniplex A piece of furniture overturned...
She took a breath/breathed in...
The grammatical elements that above signaled multi-
plexing-- -sand keep -ing --have a directly manifested
surface form. The ones signaling unit-excerpting are
in part abstract in form, as represented in (16):
</bodyText>
<listItem confidence="0.865437">
(16) matter action
(a) Nunit of + Vdummy Ca) [--- + 4N
eg: a piece of furniture take a breath
or: + Prtcle (eg: in)
</listItem>
<subsectionHeader confidence="0.977948">
2.3 State of Boundedness
</subsectionHeader>
<bodyText confidence="0.980166090909091">
Another category of attributes specified both
grammatically and lexically for a quantity is its
&amp;quot;state of boundedness&amp;quot; When a quantity is specified
as &amp;quot;unbounded&amp;quot;, it is conceived as continuing on in-
definitely with no necessary characteristic of finite-
ness intrinsic to it., When a quantity is specified
as &amp;quot;bounded&amp;quot;, it is conceived astdemircated off as an
individuated unit entity.
Among English examples of lexical items, water
and (to) sleep seem basically to specify unbounded
quantities, whereas sea and (to) dress seem basically
to specify bounded ones. These specifications are
demonstrated by the worW respectively unacceptable
and acceptable occurrence with the grammatical element
&amp;quot;in NPextent-of-time&amp;quot;, which specifies boundedness:
(17) matter
action
a. unbounded *We flew over water in 1 hr.
*She slept in 8 hrs.
b. bounded We flew over a sea in 1 hr.
She dressed in 8 mins.
Now, there are grammatical elements suitable 1VIr
co-occurrence with unbounded-type lexical items which
therewith, in effect, trisger a cognitive operation
of &amp;quot;boundiing&amp;quot;. By this operation, a portion of the
specified unbounded quattity is demarcated and placed
in the foreground of attention. Examples of such
grammatical elements in English are:
(18) matter (a) N bounded-quantity of
action for N extent-of-time
Particular cases of them in use are:.
(19) We flew over 1 body, of. water in 1 hr.
She slept for 8 hin,
</bodyText>
<page confidence="0.994512">
17
</page>
<bodyText confidence="0.9994885">
The question arises whether the reverse of the
preceding circumstances is ever to be found in lan-
guage. Entailed would be the existence of grammat-
ical elements that, when used with lexical items
specifying a bounded quantity, Would trigger an oper-
ation of &amp;quot;debounding&amp;quot;. By this, e.g., the referent
of sea would be shifted to &apos;pelagic water&apos;, and that
of &amp;quot;raj tear, to take another lexical bounded case,
would shift to &apos;lachrymal fluid&apos;. It seems likely
that such grammatical elements exist; the closest
candidate known to the author is the French suffix
-Age, but this has a range of meanings and many act
currence restrictions--and does not, e.g., happen to
combine with he French words for &amp;quot;sea&amp;quot; or &amp;quot;tear&amp;quot;.10
</bodyText>
<subsectionHeader confidence="0.999091">
2.4 State of Dividedness
</subsectionHeader>
<bodyText confidence="0.983889304347826">
The category of &amp;quot;state of dividedness&amp;quot; refers to
a quantity&apos;s internal consistency. A quantity is
&amp;quot;discrete&amp;quot; (or &amp;quot;particulate&amp;quot;) if there are breaks in
its continuity. Otherwise, the quantity is &amp;quot;contin-
uous&amp;quot;.&amp;quot; Both lexical and grammatical elements are
sensitive, in their specifications, to the distinc-
tions of this category. But there appear to be no
grammatical elements that solely specify discreteness
or continuity for a quantity, and also none that sig-
nal an operation for reversing quantity&apos;s lexdcally
specified state of dividedness.14 In consequence,
there is difficulty in demonstrating this category
explicitly by itself, and so we defer its treatment
until the next section, where it can be seen ilk in-
teraction with the other categories.
2.1 - 2.4 The Disposition of a Quantity
The preceding four categories of attributes all
pertain to a quantity simultaneously and, taken to-
gether, can be considered to constitute a system of
attributes that may be termed a quantity&apos;s &amp;quot;dispdsi-
tion&amp;quot;. The particular intersections of the several
attributes will be the main object of attention here.
These, firstly, can be schematized as in (19):
</bodyText>
<figure confidence="0.749906571428571">
(19). discrete continuous
4 .
â€¢ ,
â€¢ â€¢ 9: foe
beige.
At fa g 1
1. fib, At
</figure>
<subsectionHeader confidence="0.379048">
Br^
</subsectionHeader>
<bodyText confidence="0.835948">
mulflplex
&lt;---boundid
+ the distinction between matter and action,
which cross-cuts all of the abovel3
Each intersection of attributes indicated here has
[&apos;eft found specified by various lexical items. An
example or two (most sgen earlier) is given for each
intersection in (20):14
</bodyText>
<listItem confidence="0.9065704">
(20) T: timber/furniture
(to) breathe
A: (a) family
(to) button up
a: (a) bird
</listItem>
<bodyText confidence="0.821409736842105">
(to) sigh
Now if the particular contentful referent for
which one chooses a lexical item happens to be wedded,
by that lexical item, to an unwanted set of structural
specifications, there generally are grammatical means
available for altering this to a desired set. Such
means range in directness from specifying the single
apt alteration to involving a circuitous sequence of
operations. A number of starting- and ending-pointÂ§
for alterations, and the means for accomplishing them,
are indicated in (21):
7(...4.A a stand of timber Trilkli a body of water
breathe for 1 hr. sleep for 1 hr.
&amp;quot;OTA6a a piece ofefurnit.
take a breath/
breathe in
A --ota a member of a fmly
go through a step
of buttoning up
</bodyText>
<figure confidence="0.880181375">
A-1J members of a fmly B -iuB tears (*tearage)
(A -4..a -4-A) (B -N-B)
button on and on zip on and on
a -Ã·&amp;quot;it trees
keep sighing
a--11..A a stand of trees
(a -A-&apos;.A)
sigh for a while
</figure>
<subsectionHeader confidence="0.995578">
2.5 Degree of Extensionality
</subsectionHeader>
<bodyText confidence="0.9990645">
Implicit in the vertical dimension of the Wie-
matic arrangement in (19) is a further category&amp;quot; that
can be called &amp;quot;degree of extensionality&amp;quot;. This cate-
gory has three member notions, terms for which are
given in (22) together with schematics of the notions
for the linear dimension:
</bodyText>
<listItem confidence="0.8290965">
(22) point bounded extent unbounded extent
â€¢
</listItem>
<subsectionHeader confidence="0.7243585">
Lexical items with either a matter or an action ref-
erent can make concurrent structural specifications
</subsectionHeader>
<bodyText confidence="0.968398631578948">
for their referent as to its basic degree of exten-
sionality. Three examples--specifying objects of
different linear extensionalitiesâ€”are the words
(23) speck ladder
Now a lexical referent that is perhaps most bas-
ically to be conceived as of one particular degree of
extensionality can, by various grammatical specifica-
tions that induce a shift, be idealized as being of
some other degree of extensionality. For a first ex-
ample, consider the event referent of climb a ladder,
which seems basically:of bounded linear extent-Fr--
time), as is in fact manifested in (24) in conjunction
with the Arammatical elementn i
&amp;quot;- NP extent-of-time&amp;quot;&apos;
(24) She climbed up the fire-ladder in 5 mins.
With a different accompanying grammatical element,
like the &amp;quot;at + NPpoint-or-time&amp;quot; in (25),(as well as
different contextual specifications), the event ref-
erent of the preceding can be shifted toward idealiz-
</bodyText>
<figure confidence="0.986144222222222">
k=unbounded
*--`A
otâ€˜iâ€ž
a
water
(to) sleep
B: (a) sea/tear
(to) zip up
river
</figure>
<page confidence="0.875359">
18
11
</page>
<bodyText confidence="0.99397134">
at.* as a point of at being point-dura-
tional:
(25) Moving along on the training course,
she climbed the fire-ladder at exactly midday.
This shift in the cognized extensionality Of the ev-
ent can be thought to involve a cognitilie process of
&amp;quot;reduction&amp;quot; or of &amp;quot;taking the long-range view&amp;quot;. The
shift can-also go in the other direction. The event
referent can be idealized as an unbounded extent from
the effect of grammatical elements like &amp;quot;keep -jng&amp;quot;,
-er and -er&amp;quot;, and &amp;quot;as + S&amp;quot;, as in (26):
(26) She kept climbing higher and higher up the
fire-ladder as we watched.
Here there&apos; would seem to nave taken place a cognitive
process ot &amp;quot;magnification&amp;quot; or of &amp;quot;taking the close-up
view&amp;quot;. In such a process, a perspective is estab-
lished whereby the existence of any exterior bounds
falls outside of view and attention--or, at most, are
asymptotic Hy ipproachable.
The preced/ng event referent was continuous,
but a discrete case can exhibit the same shifts of
extensiuoality. One such case, perhaps to be con-
sidered as most basically of bounded extent, is shown
with that degree of extensionality in (27a). But the
referent can also be idealized as a point, as in (27b)
(it is clear that the cows here did not all die at the
same moment, and yet the spread of their death ttmes
is conceptually collapsed into such a single moment).
Or, the referent can be idealized as an unbounded ex-
tent, as in (27c):
(27) a. The cows all died in a month.
b. When the cows all died, we sold our farm.
c. The cows kept dying (and dying)
until the serum finally arrived.
The alternative idealizations of extensionality
just seen as specifiable for an event referent are
generally also available for an object referent.
Thus, e.g., the referent of (a) box can be specified
for idealization as a point or as a bounded extent
(of area or volume). Some grammatical elements making
such specifications are illustrated in (28). Also set
forth here are the homologies between these and the
event-specific elements:
(28)
point The box is 20 ft. away from the wall.
I read the book 20 yrs. ago.
bounded extent The box is 2 ft. across.
I read the book in 2 hrs.
(point within The ball is in the box.
bounded extent She arrived as I was reading the book.
</bodyText>
<subsectionHeader confidence="0.99348">
2.6 Pattern of Distribution
</subsectionHeader>
<bodyText confidence="0.998685881355932">
The pattern of distribution of matter through
space or of action through time is a further category
of notions that can be both grammatically and lexic-
ally specified.16 For action through time--the only
dimension we will be looking at now--this category
together with the preceding one largely constitute
the traditional category of -&amp;quot;aspect&amp;quot;.
Several of the main patterns of distribution for
action through time are shown schematically in (29)
(the dots here, representing situatedness in comple-
mentary states, should really be adjacent, but they
are sketched apart with a connecting line to show the
crossing of state-interfaces). Shown, too, are ex-
aMple verbs whose basic distributional specifications
are as in the correoonding schematic:
(29)
one-way one-way full- steady- gradient
non- resettable cycle state
resettable
flash sleep widen
catry.
One can determine that these lexical items have the
specifications indicated by noting the grammatical
elements with which they can and cannot occur (or, to
put the latter case in our terms: ...grammatical ele-
ments toward whose specifications they will not
shift). A full demonstration is not in order here,
but a few examples show the principle: The resettable
type of a one-way event is distinguished from the
non-resettable type by its compatibility in sentences
like: He fell 3 times, which the other lacks: *He
died 3 times.. This same one-way form is distinguished
from a full-cycle form by its ability to appear in
sentences like: He fell and then got up, which the
latter cannot do: *The beacon flashed and then went
off.
We can now consider the cirsumstance where a verb
of one type appearswith grammatical elements of an-
other type and shifts in certain of its specificatjons
of distribution. For an example we again take die,
whose basic specifications can be adjudged as point-
durational one-way non-resettable--schematizable, now
more precisely, as: . This verb is used with its
basic specifications in a sentence like (30a).
(30) a. He died as she looked on.
b. He was (slowly) dying as she looked on.
But in a sentence like (30b), the grammatical ele-
ment &amp;quot;be + -ing&amp;quot; induces a shift. In effect, the
infinitesimal interval between the two states involved
for die--viz., &apos;aliveness&apos; and &apos;deadness&apos;--is spread
out, with the creation thereby of an extent-durational
gradient. This is the shift in the distribution pat-
tern&apos;s structural type. But concomitantly, a shift
in the basic contentful referent is engendered. In-
stead of &apos;dying&apos;, the new gradient refers tO &apos;mori-
bundity&apos;. The distinction becomes clear in lioting
that one can have been dying without having died,
and, correlatively, one can have died without having
been dying,17
</bodyText>
<subsectionHeader confidence="0.873745">
2.7 Perspectival Mode
</subsectionHeader>
<bodyText confidence="0.988829181818182">
A specified action (which, in our terms, can as
equally be static as involve change) has been seen to
have its own, perhaps most basic, pattern of distri-
bution through time. But, as it turns out; there can
be independent specification for a mode of attending
to the action that has a distinct temporal pattern
of distribution, one that is either equal or unequal
to the action&apos;s. In what we shall now consider,
there are two types of such &amp;quot;attentional&amp;quot; or &amp;quot;per-,
spectiAl mode&amp;quot; viz.:
die fall
</bodyText>
<page confidence="0.970941">
19
</page>
<bodyText confidence="0.971733526315789">
(31) The assuming of:
a. a steady-state long-range perspective point
with synoptic scope of attention
b. a moving close-up perspective point
with local spope of attention
To illustrate, we first consider an example with
a basically steady-state referent, viz., objects in
location. The (31a) type of perspectival mode--the
one more congruent with such a referent--holds in
(32a), multiply specified/determined there by the
set of grammatical elements shown underlined. But
by substituting grammatical elements coding for the
(31b) perspectival mode, as is done in (32b), the
scene evoked can be shifted to one where one&apos;s mental
gaze or &apos;one&apos;s own projected location jumps in turn
from object to object. In effect, a steady-state
multiplexity of objects has been converted to a
sequential multiplexity of events, viz., of concep-
tualized encounters with the objects.
</bodyText>
<listItem confidence="0.833914">
(32) a. There are houses here and there in the valley.
b. There is a house gltnximi_12aitilta through
the valley.
</listItem>
<bodyText confidence="0.875978291666667">
In a comparable case, the moving-perpective form,
shown in (33b), is the only mode that can be spec-
ified using everyday language. One must resort to
scientific language, as in (33a), in order to estab-
ish the synoptic perspective:
(33)
a. The telephone poles&apos; heights form a gradient that
correlates with their locations on the road.
b. The telephone poles get taller the further down
the road they are.
The reverse of the preceding circumstances is
also encountered. An example involving a sequential
multiplexity of ennts is shown in (34a) with the more
congruent moving-perspective mode specified. In (34b),
the same referent instead becomes the object of syn-
optic viewing. In metaphorical terms, the effect here
is as if the vertical time line is tilted up into pre-
sent-moment horizontality for integrated or summational
assessment.
(34)
a. I took an aspirin time after time during/
in the course of the last hour._
b. I have taken a number of aspirins in
the last hour.18
</bodyText>
<subsectionHeader confidence="0.717601">
2.8 Level of Synthesis
</subsectionHeader>
<bodyText confidence="0.98949862295082">
The category to be considered now pertains to
bounded quantities, like those schematized in the
A/B row in (19). One form of locution already seen
to specify such quantities is the particular type of
&apos;11P of NP&amp;quot; construction illustrated in (35a). Here
the second NP specifies the identity of the quantity
involved, itself conceptualized as without intrinsic
bounds, while the first NP specifies the bounding
(or &amp;quot;portion-taking&amp;quot;) per se of the quantity:
(35) a. a set of trees a body of water
b. a cluster of trees a puddle/drop of water
Now, beyond the fact alone of bounding off a portion,
the first NP can additionally specify the particular
:onfiguration or form that the portion takes, as in
(35b).19 Especially Especially with regard to internally dis-
crete quantities--as with a cluster of trees--the two
NPs can here be seen as coding for two different
&amp;quot;levels of synthesis&amp;quot;: The later NP specifies an
unsynthesized multiplexity, while the earlier NP spe-
cifies a particular geatalt synthesized therefrom.
There is a further cognitive distinction involved
here that language usually makes: either level of
synthesis can be placed in the foreground of attention
while the other level is placed in the background.
One grammatical form that specifies this involves
placing the foregrounded NP-type first, as shown in
(36a). With the use of this grammatical device,
moreover, predications can be made that pertain
solely to one level of synthesis or the other, as
seen in (36b):
(36) a. the cluster of trees / the trees in the cluster
b. That cluster of trees is small.
# The trees in that cluster a.me small.
There are certain surface forms, furthermore, whose
referents are keyed to applying to only one or the
other level of synthesis. Thus, together (toward
each other) tends to correlate with multiple objects,
while-E-(upon itself) tends to correlate with a
composite thereof:
(17) The bricks in the pyramid came crashing
together! in.
The pyramid of bricks came crashing
in (upon itself)/?together.
The preceding has involved shifting attention
from a multiplexity to the gestalt that it consti-
tutes. Also encountered in language are means for
specifying the reverse: shifting attention from a
gest-alt to the components that constitute it. This
procedure can take place when the starting lexical
item specifies an entity taken to be already at the
more synthetic level, as ts the case with iceberg in
(38a). By grammatical devices like those seen in
(38b), such an entity can be broken down from con-
ception as a coherent whole and presented in terms
of component parts and their interrelations:
(38) a. The iceberg broke in two.
b. The two halves of the iceberg broke apart
(*in two).
Again we encounter a surface form--in two--that cor-
relates with only one level of synthesis and not the
other. 20
</bodyText>
<subsectionHeader confidence="0.66716">
2.9 Level of Exemplarity
</subsectionHeader>
<bodyText confidence="0.999980066666667">
The specification for a multiplexity of objects
can have a further cognitive distinction made per-
taining to it. This distinction does not affect the
basic reference to all the members of the multiplex-
ity, but addresses how attention is-directed therein.
Either the full complement of the mu9tiplexity is in
the foreground of attention, with perhaps indiVidual
items here and there singled out in the background
of-attention. Or a single exemplar out of the multi-
plexity is placed in the foreground of attention,
with the remaining items more dimly conceived in the
background of attention. Perhaps most languages have
several grammatical devices for specifying this dis-
tinction as to the &amp;quot;level of exemplarity&amp;quot;. But Eng-
lish stands out in the extensiveness of.its forms:
</bodyText>
<page confidence="0.95875">
20
</page>
<table confidence="0.28113788">
23
there are different pairs of grammatical elements
that mark the distinction for a numbnr of distinct
types of multiplexity. A rather fullilist of these
pairs is illustrated in (39):
(39)
a. Oysters have siphons/a siphQh.
An oyster has siphons/a sipohon.&amp;quot;
b. All oysters have siphons/a siphon.
Every oyster has siphons/a siphon.
c. All the members raised their hand(s).
d. Each member raised his hand(s).
d. Many members raised their hand(s).
Many a member raised his hand(s).
e. Some members here and there raised their hand(s).
A member here and there raised his hand(s).
f. Members one after another raised their hand(s).
One member after another raised his hand(s).
g. Hardly any members raised their hand(s).
Hardly a member raised his hand(s).
h. No members raised their hand(s).
No member (Not a member) raised his hand(s).
i. She held a gun in both hands.
She held a gun in either hand.23
2.10 Other Categories and Processes
</table>
<bodyText confidence="0.96533353125">
More notional categories and cognitive processes
have been worked up than there is opportunity to pre-
sent here. Some of this other material is treated
in an earlier work, Talmy (1977) (which itself lacks
some of the material presented here). But we will
briefly indicate some of the concepts involved.
The adjectives in a pair like sick/well behave
differently in association with grammatiliTâ€”elements
specifying vectoral degree, as shown in (40). In this
they parallel the behgvior of certain spatial expres-
sions like at the border/past the border:
(40) sick/past the border.
He&apos;s slightly
*well/*at the border.
k- well/at the border.
He&apos;s almost 7 7
sick/-past the border.
This behavior can be accounted for by positing that
such adjectives are not simply &amp;quot;opposites&amp;quot;, byt, ra-
ther, imply for some semantic notion, e.g., that of
&apos;health&apos;, a particular abstract topological axis of
which each adjective labels a certain portion. The
forms her. seem in particular to imply a line bounded
at one ena; well refers to the end-point while sick
refers to the remainder of the line. These are the
lexical items&apos; &amp;quot;axial characteristics&amp;quot;, i.e., the
particular (topological) relations pach has to a par-
ticular semantic axis and to other items alang the
same axis. Certain grammatical.elements, like those
underlined in (40), a4so specify axial characteris-
tics. Used incompatibly, they can cause a shift in
an associated adjective&apos; specifications. Thus, in
(41), sick seems to label an end-point, and of a
cliff/went axis as well, that of &apos;feeling bad&apos;:
(41) (After eating the shrimp, he felt Worse and
worse and) he was almost sick at one point/
he finally got sick in 5 hrs.
Lexical expres.sionsylike cottage and hotel room
may be taken to have &amp;quot;associated characteristics&amp;quot;--
here, respectively, those of &apos;permanent residence&apos;
and &apos;temporary lodging&apos;. These attributes may mesh
or conflict with the specifications of another ele-
ment in the same sentence, e.g., with the directional
adverb home, which specifies a permanent residence.
In ;he case of conflict, as in (42b), the lexical item
is operated on by a coritive process that leaves its
essential characteristics intact but replaces its in-
cidental characteristics:
(42) a. He drove home to his cottage in the suburbs.
b. He drove home to his hotel room.
The &amp;quot;scene-breakup characteristics&amp;quot; of a lexical
item like serve refer to its basic specification of
a dyadic event, in particular, a social event invol-
ving the two roles of &apos;host&apos; and &apos;guest&apos;, as is mani-
fested in (43a). But in a sentence like (43b), such
a lexical item shifts to specifying a monadic event
comparable to a basically monadic lexical expression
like that in (43c). This shift in (42b) takes place
in accommodation of the subject-plus-reflexive&apos;s
single-role specification. (Though this grammatical
element is determinative in setting the role-number
as monadic, the verb&apos;s influence remains: blended in
here is the metaphoric suggestion of a dyad, as if
both-&apos;host&apos; and &apos;guest&apos; are to be found in the.&amp;quot;I&amp;quot;):
</bodyText>
<tableCaption confidence="0.83258403030303">
(43) a. The host served me some dessert from the kitchen.
b. I served myself some dessert from the kitchen.
c. I went and got some dessert from the kitchen.
A major aim in cognitive linguistics must be to
investigate the interactions between lexical and
grammatical specifications arising in a single sent-
ence. Included here are the cognitive accommodations
that take place where there are conflicting specifc-
cations. A number of interactions have been provision
ally identified, and four seem definitely established:
operations, shifts, blends (of two kinds: superimposed
and introjected), and juxtapositions. The last three
of these arP treated at length in Talmy (1977).
2.11 NastAng
The operations and shifts seen in 2.1 - 2.6 need
not take place singly. The outplia of one can serve
as the input to another, up to as many as five hier-
archical levels of &amp;quot;nesting&amp;quot;., While&apos;tbere are e num-
ber of interesting examples of this for different
types of matter and action, we will go directly to
illustrating one of the longest cases:
(44)
a. The beacon flashed (as I glanced over).
b. The beacon kept flashing.
c. The beacon flashed 5 times in a row.
d. The beacon kept flashing 5 times at a stretch.
e. The beacon flashed 5 times at a stretch for 3 hrs.
In (44a), the lexical verb flash appearS.with its
basic structural specification as a point-durational
full-cycle uniplex event. This undergoes the process
of multiplexing, to yield the unbounded multiplexity
in (44b). This then undergoPs bounding in (44t).
This bounded multiplexity is then first put through
</tableCaption>
<page confidence="0.998051">
21
</page>
<bodyText confidence="0.999711">
the process of reduction to become idealized as a
point, and this is in turn multiplexed, yielding
(44d). This new unbounded multiplexity is finally
then bounded in (44e). The nesting of structural
specifications in this last stage can be represented
schematically as in (45):
</bodyText>
<listItem confidence="0.9160415">
(45) [(.1..1) _ (lulls)
3. Further Cognitive Connections
</listItem>
<bodyText confidence="0.973921734375001">
Grammatically specified structuring appears to
be similar, in certain of its characteristics and
functions, to the structuring in other cognitive do-
mains, notably that of visual perception. In parti-
cular, the characteristic of being quasi-topological
can be pointed to, and three major functions can be
identified: classification, synoptics, and continuity.
The thinking here is not equally far along on all
these matters, but something of its directions can
be indicated.
Grammatical specifications can be seen to con-
stitute a classification with regard to the vast var-
iety of learned, conceived, and perceived material.
They gather different portions of the material toge-
ther into subdivisions distinct from each other. By
this, any particular currently cognized element is
associated with its implicit &amp;quot;subdivision-mates&amp;quot;.
An illustrative case here are the twenty-odd motion-
related prepositions in English, such as through and
into, which together subdivide the domain of &apos;paths
considered with respect to reference-objects&apos;. This
domain covers a great and varied range, but any par-
ticular &amp;quot;path&amp;quot; falls within the purvue of one or an-
other preposition, associated there w4th other &amp;quot;paths&amp;quot;
The associations are often language-specific and some-
times seem arbitrary or idiosynchratic. Thus, as szon
earlier, classed together by through are such dissim-
ilar cases as a straightforward liquid-parting course
(walking through water) and a_zig-zag obstacle-avoid-
ing course (walking through timber). The question
arises why such slistinctions should be effaced by
the grammatical system, while-they are observed by
the lexical and other cognitive systems. Why are
grammaticdl elementsâ€”say, such prepostions--not a
large and open class marking indefinitely many dis-
tinctions? One may speculate that the cognitive
function of such classification lies in rendering
contantful material manipulable--i.e., amenable to
transmission, storage, and processing--and that its
lack would render content an ineffective aggloTerstion.
The original assumption made in this paper about
grammatical specification involved the synoptic func-
tion. That is, thd grammatical elements of any par-
ticular sentence together specify the structure of
the cognitive representation evoked by that sentence.
Their specifications act as a scaffolding or framework
across which contentful material can be splayed or
draped. It can be speculated that such structure is
necess2ry for a disparate quantity of contentful mat-
erial to cohere in any sensible way or to be simul-
taneously cognized as a gestalt.
In the course of discourse, a great welter of
notions pass in rapid succession. But there are sev-
eral ways in which a cognitive continuity is main-
tained through this flux and a coherent gestalt is
summated over time. For one, there are cognitive
processes whereoy the successive notions generally can
be sensibly connected together or fit into a concep-
tual matrix. For another, rhetorical specifications
--all the yes buts, on the other hands, and a num-
:47_((
ber of subtler elements not generally recognized for
this--direct the illocutionary flow and make up the
&amp;quot;logical&amp;quot; tissue of the discourse. Through this, gram-
matical elements appear to play a determinative role.
Their specifications establish a structural level with
greater temporal constancy amidst more fleeting asp-
ects of content.
These forms of grammatically specified structuring
seem to parallel forms discernable in the operation of
visual perception.24 First, the perception of any
particular object is mediated by its association with
related objects in a classificatory schema.
Secondly, the welter of visual sensations cognized
at any given moment for some whole scene is rendered
coherent by the perception of structural delineations
running through it. One specialized form of this is
discernable when one intends to move through a space,
say, from one to the opposite corner of a restaurant.
The sensations of tables, chairs,etc. are, in effect,
perceived in simplified spatial arrangements as if from
an aerial view, and the plot of a course one could
follow through that is sensed.
Thirdly, in the course of motion through space
over time, there is a great flux of visual sensations
rushing past, but sense of continuity is maintained
by the perception of structure running through the
successive scenes. Two levels of &amp;quot;scene-structure
constancy&amp;quot; are maintained. In the first, the perceived
delineations afford greater permanence than the sensory
flux, but do slowly shift. Thls is the level where,
say, in walking past a table, its perceived,outline
is maintained but shifts gradually from a quadrilateral
to a trapezoid and back to a quadrilateral. A deeper
level of greater constancy is also maintained, from
which the table continues to be perceived as a rect-
angle no matter where one is in relation to it. For
a final parallel-gith grammatical specification, the
topology-like nature of visual perception is evident
here. For certain abstract characteristics of a scene
and its contents are maintained constant while other,
more metrical and Euclidean characteristic are free
to vary without relevance thereto.
4. Notes
1. The word &amp;quot;evoke&amp;quot; is used because the relationship
is not direct. The CR is an emergent, compounded by
Uarious cognitive processes out of the sentence ele-
ments&apos; referential meanings, understanding of the pre-
sent situation, general knowledge, etc.
Our term &amp;quot;cognitive representation&amp;quot; is similar
in purport to Fillmore&apos;s (1975) &amp;quot;scene&amp;quot; but is chosen
over that more specifically visual term. lre linguis-
tically evokPd somplex can have much. from other sense
modalities (notably som/kinesthetic and auditory) as
well as meta-modal aspects.
2. Comprehension, rather than production, is the dir-
ection we limit ourselves to in the initial endeavor.
This direction would seem to yield more immediately
reliable findings, since its starting point is with
more overtly manifest, hence handleable, forms like
grammatical elements rather than with meanings and
experiential complexes, which rely more on introspec-
tion and reports of introspection. Nevertheless, eact.
direction does involve both the manifest and the ex-
periential sides of language.
3. This is a classical linguistic distinction. A
class in which morphemes are formally gathered is con
gidered open if it is quite large and easily augment-
</bodyText>
<equation confidence="0.975991">
) â€” cis.&amp;quot; j]
</equation>
<page confidence="0.98606">
22
</page>
<bodyText confidence="0.998326214285715">
able relative to other classes. A class is considered covers &apos;boundlessness&apos; as it does &apos;internal seamless-
closed if it is relatively small and fixed in member- ness&apos;. However, the two categories can vary indepen-
ship. dently. Thus, in the preceding section, the lexical
examples given for unboundedness, water and sleep, hap-
pened also to be internally continuous; but the same
demonstration of unboundedness could have been made
with internally discrete examples like timber and breathe
12. There do exist certain mechanisms for such reversal.
Thus, taking an unbounded case, the continuity-spec-
ifying word water can be shifted toward being cognized
as discrete by the locution particles of water, as in:
(i) Water/Particles of water filled the vessel.
However, the grammatical complex used here does not
directly specify the shift but, like the one in Note 10,
seems to involve a several-atage route of cognitive
operations.
13. For schematizing action along the one-dimensional
time axis, an adaptation, of the two-dimensional A, B,
A, and B diagrams would be necessary--aid can be
readily visualized.
14. The lexical types for several of these intersec-
tions, it should be noted, do have traditional terms.
Thus, nominal forms of the a, A, and B types, respec-
tively, have been called count nouns, collective nouns,
and mass nouns. And verbal forms of the a and B types,
respectively, have been called punctual and durative
verbs. The matrix presented here augments, systemat-
izes, and generalizes the traditional notions.
</bodyText>
<listItem confidence="0.749295555555556">
15. It may be considered an extension of the cate-
gory of state-of-boundedness via the incorporation
of the notion of uniplexity.
4. Also includable here are &amp;quot;lexical complexes&amp;quot; like
lodge a complaint or zero in on. Excluded are adverbs,
which seem in all languages to derive from the other
three open classes rather than from any open class
of specifically adverbial stems.
5. Since the term &amp;quot;structure&amp;quot; has broad usage, we
</listItem>
<bodyText confidence="0.924964853658537">
can help focus in on the intended sense with alter-
native terms: &amp;quot;principles 9f organization&amp;quot;, &amp;quot;pattern
of delineations&amp;quot;, &amp;quot;schematic framework&amp;quot;.
6. The fact of dual lexical specifications that can
lead to conflict is a mojor issue that will be treated
below under shifts. Some grammatical elements also
cross the line andmakecontentful specifications along
with structural ones. This is a more tangential issue
that can be touched on here. The crossing ranges fvom
the incorporation of a single contentful notion to the
orderly interweaving of contentful and sturctural
notions. Thus, upon in We rode/sailed/rushed upon the
enemy incorporates the notion of &apos;attack&apos;,
equivalent to the paraphrase &apos;into attack upon&apos;. The
closed-class adverb tomorrow is equivalent to the
phrase &apos;during the day that occurs next after the day
during which I am now speaking&apos;, an example of an
organized interlacing.
7. One can note, for example, the effect on one&apos;s
internal cognitive representation in considering first
the sentence I looked at the cipa and then I looked at
the dogs. The addition of the grammatical element -s
has a major effect on the delineational breakup of--
tp put it visually--the scene before the mind&apos;s eye.
8. For example, augmentative and diminutive inflec-
tions, insofar as they refer to actual size, seem to
specify size relatively greater or lesser than the
norm for an object. And grammatical elements spec-
ifying distance (like English way and just appearing,
e.g., before y_a there) appear to specify notions of
&apos;far&apos; and &apos;ff,ar&apos; that are relative to the current
situation.
9. It is true that there are the traditional terms
&amp;quot;semelfactive&amp;quot; and &amp;quot;iterative&amp;quot; referring, respectively,
to one and more than one instantiation of an event. But
there is no real equivalent to number: &amp;quot;aspect&amp;quot; in-
cludes too much else about the temporal structure of
action. And in any case, none of the traditional
terms refer generally to both the dimensions:
10. The mechanism actually resorted-to by both English
and French in many such cases, including that of tear,
is the use of the plural, as in:
(i) Tears flowed through that channel in Hades.
There seems to be a sequence of cognitiye oper-
ttions here in getting from a bounded to an unbounded
Quantity. Speculatively, the bounded quantity is
tinrst treated as a uniplex entity, it is then multi-
pVexed, the resultant entities are conceived as spa-
ttally juxtaposed, and their boundaries are lastly
effaced.
11. The present category may be prone to confusion
with the preceding one. Contributory here is the
normal meaning range of continuous, which as easily
16. This category might be considered an extension
or generalization of the &amp;quot;disposition of a quantity&amp;quot;.
Clearly, this category and the preceding five all belong
together in treating the greater disposition Of a
quantity, but the relationships have not yet all been
worked out.
17. Our main purpose here is to note the shift in
structure type. The shift in content, which will /
doubtless prove to have some regulaitv is not clearly
understood at this point.
18. A major function of perfect forms in language in-
deed appears to be the one involved here. More par-
ticularly, the perfect seems able to specify the temp
oral counterpart of matter located within a bounded
extent of space, as in (1). That is, a sentence con-
taining the perfect, as in (ii), suggests a paraphrase
ltke that in (iii), which is homologous with (i):
(i) There were 5 aspirins on the table.
(ii) I have taken 5 aspirins in the last hour.
(iii) There were 5 aspirin-takings in the last hour.
(In support of this interprm.ation, as.pointed out.tp
me by Peyton Todd, the per, can be noted always to
involve a temporal span bounded&apos;at both ends.)
19. All three notion--identity of a quantity, portion-
taking of a quantity, configuration of the portion--
are generally specified simultaneously (or, &amp;quot;conflatedly&amp;quot;
--see Talmy (1975)) **lexical items that would fit
in the A/B row of (20). For example, (a)&amp;quot; tear spec-
ifies not only a certain shape of Quantum, but also the
</bodyText>
<page confidence="0.975173">
23
</page>
<bodyText confidence="0.4728678">
2 6
material involved: lachrymal fluid. Such words gener
ally do not participate in an &amp;quot;NP of NP&amp;quot; construction
--like *a tear of milkâ€”Unless they in fact accede to
a shift toward the type of word represented in drop.
</bodyText>
<listItem confidence="0.6150725">
20. There is a foursome of apt terms that can be ap-
plied to the two levels of synthesis in the two direc-
tions of shift, as indicated in (1). Employed here
Is the term &amp;quot;Figure&amp;quot; as it is used in my other work
(Talmy 1978, 1976):
(i) cluster: &amp;quot;composite Figure&amp;quot; iceberg: &amp;quot;meta-
</listItem>
<bodyText confidence="0.963204125">
Figure&amp;quot;
trees: &amp;quot;multiple Figures&amp;quot; 2 halves: &amp;quot;component
Figures&amp;quot;
21. For the plural form oysters, the plural form si-
phons is ambiguous as to whether there are one or more
siphons per oyster. All the other combinations unam-
biguously indicate the number of siphons per oyster.
Thus, the exemplar form is always unambiguous in this
reagard--one of its advantages over the full-complement
form. This same arrangement holds through the list.
22. I have longmondered what the differences between
each and every,might be. One apparent.difference shows
up here. Each seems to be the exemplar counterpart
of all the but not.of all without the (*Each oyster
has-a siphon makes a poor generic assertion). Every
iThot constrained in this way, though it does strike
me as more comfortably the counterpart of all without
the.
23. One more pair can be added to this list by adjoin-
ing two complementary unpaired forms from two different
languages. The English form some, as in some friends
of mine, requires the plural iiinias no singular coun-
terpart. The Italian form qualque, as in qualque amico
mio, requires the singular and lacks a plural.
</bodyText>
<listItem confidence="0.897412833333333">
24. It seems likely that the language-related portions
of the brain could have evolved to their present func-
tions only in the presence of these already existing
cognitive rAechanisms and have incorporated their oper-
ation.
5. References
Fillmore, C. 1975. An alternative to checklist theories
of meaning. In: Berkeley studies in syntax and sem-
antics, vol 1. University of California, Berkeley.
. 1976. The need for a frame semantics within
linguistics. In: Statistical methods in linguistics.
Stockholm: Skriptor.
</listItem>
<bodyText confidence="0.624185833333333">
Talmy, L. 1975. Semantics and syntax of motion. In:
Syntax and semantics, vol, 4. J. Kimball, ed. Acad-
emic Press.
. 1976. Semantic causative types. In: Syntax
and semantics, vol. 6. M. Shibatani, ed. Academic
Press.
----. 1977. Rubber-sheet cognition in language. In:
Papers from the 13th regional meeting, Chicago
linguistic society. University of Chicago.
. 1978. Figure and Grouna in complex sentences.
In: Universals of human language. Greenberg, Ferguson,
Moravcsik, eds. Stanford University,
</bodyText>
<page confidence="0.992573">
24
</page>
<note confidence="0.5795565">
2-7
On primitives, prototypes, and other semantic anomalies
</note>
<subsectionHeader confidence="0.869437">
Terry Winograd
Stanford University
</subsectionHeader>
<bodyText confidence="0.999920166666666">
Over the past few years, there have been a number of
papers arguing the relative merits of primitives and proto-
types as representations for the meaning, of natural
language. Much of the discussion has been both pug-
nacious and confused, with-each author setting up one or
another straw-man to knock down. Much of the .confusion
has resulted from a lack of agreement as to what it would
mean for a system to use primitives or prototypes. There
are several different dimensions along which semantic
foimalisms vary, and many of the arguments have blurred
these into a single distinction.
In this paper, I propose a framework within which to
compare a variety of semantic formalisms which have
been proposed in linp.iistics and artificial intelligence. The
paper lays out three dimensions (called ontological, logical,
and relational); describing the relevant options along each
and the implications of making alternative choices in the
design of a formalism. It does not attempt to demonstrate
that one oi another alternative is right, but instead tries to
clearly state the advantages and disadvantages of each in a
non-partisan way. It is more in the style of a text-book
than of a research paper. Its contribution will, I hope, be
in dissolving some non-issues which have occupied
previous discussion, and in focussing attention on the real
distinctions between alternative proposals. My own
prejudices are set fOrth in Winograd (1976) and Bobrow
and Winograd (1977). In addition to Giting primary
sources, I will make particular reference to the discussion
by Wilks (1977) since it is recent and sets out a number of
the same issues.
</bodyText>
<subsectionHeader confidence="0.654807">
The ontological dimension
</subsectionHeader>
<bodyText confidence="0.999877666666667">
The formalisms we want to compare are all based on the
use bf symbol structures to represent meaning. There are
deep philosophical questions as to how much of meaning
can be captured in a formal system, but such questions are
outside the scope athis paper. We will take it for granted
that meaning is to be characterized in terms of structured
relationships between discrete symbols. The first question,
then, is just what these symbols are. There are three basic
positions which have been taken:
LINGUISTIC. In many older accounts of meaning, the only
entities which take part in the formal structure are the
entities of language: woi ds, morphemes, phrases, and sen-
tences. The dictionary is an account of meaning within
this tradition. The meaning of a word is expressed in
terms of structures made up of other words, without any
direct appeal to concepts which lie outside the language.
PSYCHOLOGICAL. Most current work in Al and psycho-
linguistics assumes that the entities which are manipulated
in the formal theory represent some sort of concepts which
underlie language use, but are not themselves part of the
language. These concepts have psychological reality, in
that they correspond to functional components in the
memory and language activity of a person. Words and
sentences are seen as,corresponding to structures of under-
lying concepts. A psycholinguisttc theory includes an ac-
count of the processes by which language is translated into
conceptual structures, and generated from them. In the
case of Al systems (such as the conceptual dependency
formalism of Schank (1972)), the commitment to PSYCHO-
tObICAL entities is a global assumption which plays little
role in the methodology of the work. In -the case of
psychological experimentation (for example, much of the
work described by Clark tInd Clark (1977)), it is a hypo-
thesis to be tested explicitly. Some theoretical psycho-
logist Â§ (such as Miller and Johnson-Laird (1976) and
Fodor (1975)) have characterized it is a private &amp;quot;language
of thought&amp;quot;
THEORETICAL. A more cautious stance is taken by most
theorists who work within the generative linguistics para-
digm. They argue that the symbols of their formal seman-
tic theories need not correspond to functional psycho-
logical entities. The symbols and structures play a role.
similar to that of postulated theoretical entities in physics,
such as neutrinos and probability waves. A system based
OR them is justified in terms of its resulting overall
simplicity and ability to account for the observable
phenomena, not by finding psychological correlates for its
individual terms. This view shares with the psychological
view the notion of lexical decomposition. Words and sen-
tences of the language correspond to structures built tip of
non-linguistic symbols.
</bodyText>
<page confidence="0.995598">
25
</page>
<bodyText confidence="0.989910835164835">
There has been a certain amount of confusion within
both syntactic and semantic theory about whether there is
any psychological reality to the formal constructs postu-
lated by linguists. In the 60&apos;s, experiments were carried
out (e.g., Miller, 1962) looking for psychological correlates
of transformations, with generally negative results. Chom-
sky has repeatedly reiterated his official Stance that the
validity Of transformational theory is not based on any
assumption as to whether transformations play a functional
role in language comprehension or production. Similarly,
as Wilks (1977) points out, Katz&apos;s view of semantic mar-
kers shifted from PSYCHOLOGICAL (in Katz and Fodor,
1965) to THEORETICAL (in Katz, 1972).
In doing Al research, the issue can be finessed. In
building a program, one must develop a set of symbolic
structures which are used functionallyâ€”they play a direct
role in the memory and reasoning of the system. In this
sense they are purely psychological (the psychology of the
computer program, not of a person). &apos;When the program is
viewed as a &apos;theory of human language use&apos;, two routes
can be taken. If strong psychological equivalence is
clailned, there is an assumption that the internal organ-
ization and objects of the program correspond to the
organization and objects in the mind of a human language
user. An alternative position of weak psychological equiv-
alence is similar to that of the generative linguists. The
program as a whole is justified by its ability to match
human performance, but no claims are made about the
ways in which its organization maps onto psychological
phenomena. Since programs can be built without con-
fronting this issue, there has been a tendency by Al
researchers to handwave about it, taking whichever
viewpoint seems most advantageous in a given discussion.
Begging the fundamental question of
semantics
A persistent cause of misunderstanding in arguments
about semantics has been a lack of agreement over what a
&apos;semantic theory&apos; should -..chieve. From a philosophical
standpoint, the issue centers around what meaning is. The
fundamental question is that of the relationship between
symbols (words) and a world abdut which they speak.
From an Al standpoint, the question is operationalâ€”how
can a symbolic system be organized which accounts for the
phenomena of language use. As pointed out by Fodor
(1978), no answer to the second question, no matter how
clever or elegant, is an answer to the first. In creating a
system which accepts text, answers questions, or enteis
into a dialog, we have not created a theory of semantics,
we have created another class of objects for which such a
theory is needed.
This observation applies regardless of which of the
three choices is taken along the ontological dimension. In
taking words&apos; as the formal objects, we leave the semantic
problem completely unaddressed. In relying on psycho-
logical entities, we transform the question into the equally
difficult one &amp;quot;How are concepts &apos;related to the world which
they are concepts about?&amp;quot;. Similarly, with theoretical
bbjects we be the question by pushing it into a different
domain. As many people have argued, (e.g. Lewis (1972)
in discussing Katz and Fodor&apos;s theory of semantic
markers), translating English into IMarkerese&apos; doesn&apos;t
illuminate the fundamental nature of meaning any more
than translating it into French.
Wilks (1977) describes several papers which argue for
the ne&amp;ssity of a semantic theory along the general lines
of Tarski and recent wol k in model-theoretic semantics for
formal languages. He characteri7es them as ct iticistus of
semantic primitives and argues fliat they are based on
weak &apos;escape arguments&apos;. He is correct in concluding that
the concerns of these authors are oithogonal to the specific
technical debate about primitives, but wrong in assuming
that they are arguments in the same domain at all. In
creating for mal systems for representing and manipulating
structures corresponding to meaning, we are not forced to
answer the fundamental question of what meaning is. As
Wilks points out, this question has been asked for
thousands of years, and technical progreAs does not seem
to depend on clearing it up.
There are valid doubts about whether adequate
semantic formalisms (in the Al/opeiational sense) can be
developed without mote careful thought about the basic
questions. In particular, our unexamined assumptions
about the nature.of meaning can lead us down paths in the
problems we choose to look at, which may in the long run
conceal other more fruitful paths. However, this sort of
question has not been addressed in current Al work, and
for the purposes of setting up a clear framework for
understanding that work, we will continue to ignore it. A
characterization of a semantic formalism in terms of the
dimensions of this paper has nothing to say about the
fundamental nature of semantics.
</bodyText>
<subsectionHeader confidence="0.775389">
The logical dimension
</subsectionHeader>
<bodyText confidence="0.999850913043478">
As implied in the previous section, we are primarily
concerned with the operational implications of different
formalismsâ€”the ways in which they can be used in
language comprehension and production. Each symbol or
structure of symbols plays a role in, i-easoning processes
which underlie language activities, and there are a number
different approaches to &apos;dealing with them. There are three
basically different views of the logical status of the
individual concepts (or words):
ABSTRACTION. The tradition drawn from logic and
linguistics is to view the elements of a semantic formalism
as logical abstractionsâ€”predicates and constants within a
logical system. The meaning of a word is a structure of
semantic elements which express the logical &apos;truth
conditions determining its applicability. For example, if
we analyze one sense of &amp;quot;bachelor&amp;quot; as bAving the semantic
components HUMAN, MALE, and UNMARRIED, it is
implied that any object to which that sense of the word
could be properly applied will fit the truth conditions
corresponding to those terms. If &amp;quot;kill&amp;quot; is analyzed as a
structure of the form CAusE(X, DIE(Y)), then we can
safely deduce from the fact that &amp;quot;A killed B&amp;quot; that, among
other things. B died.
</bodyText>
<page confidence="0.990024">
26
</page>
<bodyText confidence="0.999884042253521">
There are many old and unsettled debates about the
status of such knowledge as analytic or synthetic. The
issue here is not that distinction, but the status of the
semantic analysis as leading to logical cOnsequences which
can be drawn from the the application of a given word.
PROTOTYPE. One of the currently fashionable trends in
Al is the development of languages and systems based on
some kind of frame or protoOpe representation. The basic
motivation comes from the observation that much of what
we know about the world is not in the form of simple
logical statements, but in knowledge about what is. typical
or expected. If we represent the meaning of &amp;quot;buy&amp;quot; and
&amp;quot;sell&amp;quot; in terms of -a CoMMERciAL-TRANsACTioN scenario
which includes the transfer ot money, we also want to be
able to apply it to cases which involve the e: change of
valued objects other than money. However, we do not
want to do this by creating an abstraction (e.g. the
exchanged object is a VALUED-OBJECr) and thereby lose
the information that it is usually money.
Many papers have been written on the advantages and
pzoblems of including prototypical information as a
fundamental part of a semantic representation. Formally,
such systems are distinct from those based on logical
abstraction only if issues of computational order and
resources are taken into account (See Winograd (1976), for
a discussion of these issues). However, it is important not
to focus teal narrowly on form rather than use: there is a
clear difference in approach between the adherents of the
alternate views. Some systems (such as Schank&apos;s (1972)
system of primitives) are clearly based on pi ototypes even
though they may not appear as such in the formal
characterization. The inferences tlsoy claw from semantic
decomposition are based .on typical expedtation: rather
than logical certainty.
Prototype-based systems have often gone along with a
psychological view of the status of the symbols they use.
Some of the motivation has come from psycholinguistic
experiments which indicate that in many cases people are
uncertain about the applicability of words to borderline
cases&apos;, although they have a clear- notion of the &apos;proto-
typical case&apos;. This applies to areas of the vocabulary as
varied as color terms (Berlin and Kay, 1969) and simple
nouns such as &amp;quot;cup&amp;quot;, &amp;quot;glass&amp;quot;, and &amp;quot;bowl&amp;quot; (Labov, 1973)..
The implication is that the semantic representation of
words is organized around a set of most typical&apos; cases
rather than around a checklist of logical criteria which
must be met for the word to be applied.
EXEMPLAR. Extending the prototype notion one step
furthc:, some psychologgirs have suggested that our
understanding of words is based on having exemplars
which are drawn from experience. Rather than haying_ra
semantic prototype for &amp;quot;fruit&amp;quot;, we may have an exemplary
fruit (e.g. a redepple) and understand the use of the word
by comparison to what we know about this apple. The
line between prototypes and exemplars is not sharp, but
there is a difference in emphasis. Prototypes emphasize
the presence of information which is typical to the class Of
objects described by a word, while exemplars emphasize
the ability to reason by comparing one specific object to
another specific object, which may have its own peculi-
arities which are not general to the class.
Although there has been some dfscussion of reasoning
by analogy (e.g. Moore and Newell, 1973), no system I
know of has really made use of exemplars in a substantial
way. There are many difficult issues surrounding the
selection of the important! or &apos;invariant&apos; aspects of the
exemplar in a specific context. Critics of Al (e.g. Dreyfus,
1972) see this as being impossible to adequately represent
in a formal system. Whether this turns out to be ulti-
mately true or not, we are far from having explored the
potential for such reasoning within Al programs.
</bodyText>
<subsectionHeader confidence="0.88856">
What is a primitive?
</subsectionHeader>
<bodyText confidence="0.99985780952381">
Before going on to the third dimensionâ€”the way in â€žwhich
the symbols within a semantic formalism dre inter-
related---it is useful to examine the notion of primitive
which plays a central role in arguments on semantics. In
understanding the propertiet of semantic primitives, it is
helpful to look at two otheil domains where primitives
have played an important role: chemistry and math-
ematics. Much of the thinking and discussion about
primitives draws on conscious or unconscious comparisons
with these two domains, often without recognition that
tho, differ in some critical ways.
Chemistry. One exemplar of a system based on primitives
is tlae.analysis of physical substances as structures made up
of elements. There are atomic elements (note how much
of the abstract vocabulary comes from this exemplar), and
well-defined rules for the ways they can be combined into
structures. Every substance, no matter how complex, can
be analyzed as a compound of these primitive elements.
The set of elements is experimentally determined and
dealt with as a fact of natureâ€”no two chemists would
imagine postulating different sets ot elements in their
theories. Similarly, the structural analysis of a substance is
not a matter of theoretical choice, but can be determined
empirically.
Mathematics. One of the methodolbgical advances in the
foundations ,of mathematics at the beginning of&apos; this
century was the understanding of how complex mathema-
tical systems could be constructed in a systematic way
from small sets of primitive concepts. Beginning with a
primitive basis (such as the notions of set, inclusion, and
the null set), one can define complex constructions, and
use these ii still further definitions to build up ever-
widening circles of complexity.. In doing this,, each new
term is defined in terms of previous terms and simple rules
of composition. Tit meaning of a complex term like
.!:abelian group&amp;quot; or &amp;quot;divisor field&amp;quot; can be reduced step by
step to primitives through these definitions: The choice of
primitives is not determined by the domain tb be covered.
For any field of mathematics, there are alternative
axiomatizations which take different things as primitive,
and define others in terms of them. Even with the same
set of primitives, there- aie alternative ways of defining
</bodyText>
<page confidence="0.996837">
27
</page>
<note confidence="0.346481">
30
</note>
<bodyText confidence="0.998096555555556">
higher order concepts. For example, there are different
ways of embedding the real numbers in the rational
numbers for which it is quite difficult to prove
equivalence.
These two examples illustrate some typical features of
primitives listed below (the terms used here are somewhat
expanded from those in Wilks, 1977). Not every system
based on primitives exhibits all of them, but they form a
part of our understanding of what it is to be &apos;primitive&apos;:
</bodyText>
<listItem confidence="0.99516445">
1. Finitude. A system contains a relatively small closed set
of primitives. AN it is applied to a wider range of things
(substances, mathematical constructs, vocabulary items),
the set of primitives remains fixed. The nufnber of
pi imitives should be substantially smaller than the number
Q( things which. can be reduced to combinations of
pi imitives.
2. Comprehensiveness. The set of pi imitives Coss the
range of phenomena. Every entity of interest can be
expressed as a structure of primitives. For example, a
chemist would be upset by a new substance which was not
built of the available elements, and unathematician would
reject a new definition which was not in terms of the
primitiVes of his or her axiomatization.
3. Completeness. A description of an entity in terms of
primitives is sufficient for generating all of the information
about the entity. There are no &apos;hidden propekies&apos;. This
does not mean that the information must be explicitâ€”a set
of mathematical definitions does not provide all of the
theofems, but it does provide a basis for proving all those
</listItem>
<bodyText confidence="0.782128">
which could be proved. in the case of substances, this
criterion does not apply. Information other than the
chemical structure (for example energy, phase, crystalline
structure, etc.) is needed for determining the properties of
a substance.
</bodyText>
<listItem confidence="0.918693166666667">
4. Independence. Primitives should not be definable in
terms of one another. This is clear in the case of chemical
elements, and in mathematics it provides a strong metric
for judging axiomatizations. There is a high value placed
on reducing the primitives to an absolutely minimal set.
5. Canonicality. The analysis of an entity as a structure of
primitives should be unique and unambiguous. Chemists
agree on the structure of a compound as a unique formula.
Within a particular axiomatization of a mathematical
system, there is one and only )ne way a term such as
&amp;quot;integer&amp;quot; is defined in terms of the primitives.
6. Irreducibility The meaning of a pnmitive cannot be
</listItem>
<bodyText confidence="0.991460241379311">
expanded within the same level of theory. There are many,
issues here as to what a &apos;level of theory&apos; is, but the
application is clear in chemistry. The primitiVe elements
can indeed be described as composite structures made up
of even more primitive sub-atomic particles. But in doing
so, we move from chemistry to atomic physics. For the
purposes of doing normal chemistry, it is more useful to
tieat them as primitives. It is important to recognize that
&apos;primitivity&apos; is always relative to an overall choice of the
scope of the theory.
In comparing the various formorsemantic primitives, we
will look at. the ways in which they match these criteria.
The relational dimension
The. notion of primitive- makes sense only within a system
of interrelated terms. The basic idea of composition from
primitives is only one of several possible ways of organ-
izing such sets of relationships:
PRIMMVIS. The most straightforward use of semantic
primitives would be a system in which the full meaning of
any word or phrase could be expressed as a strikture
whose components are chosen from a small set of primi-
tives, combined according to a well-defined se; of rules.
No existing system is pure in this sense, as discussed
below.
MUTUAL. Another approach is to have a web of mutually
related elements, with no primitive set on which ,to
&apos;bottom out&apos;. A standard dictionary describes word mean-
ing in this way. Words are defined using other words
which are defined using others, and so on, inevitably
leading to circularity. A mutually related system of terms
can be either DEFINITIONAL or DESCRIPTIVE. In a
DEFiNrriONAL system, each item &apos;is defined by giving a
structure made up of other items. The definition is
complete, in that no information which is available from
the term itself is lost by replacing it with the definition. In
a DESCRIPTIVE system, each term is described by
structures of other terms, but these do not necessarily
capture its full meaning. Although the dictionary is
normally thought of as being DEFINITIONAL, this is the
case only for very precise technical terms. For most of the
common, vocabulary, the dictionary definition&apos; i&amp; a quite
partial account of the meaning of the word.
DISTINGUISHED. In systems based on mutual relations, it
will often be the case that some terms tend be be used in
definitions or descriptions much more often- than others.
There may be small finite distinguished subsystems of terms
which form a standardized basis for a large number of
descriptions. These terms need not be primitive in the
senses discussed aboveâ€”they may be further reducible,
definable in terms of each other, and may provide only a
partial coverage of the meanings to be expressed.
However, there are organizational (and computational)
advantages to granting them a privileged status in the way
other definitions and descriptions are built up. In fact,
most of the argument in favor of semantic primitives for
Al systems has been (as we will see below) argument in
favor of having one or more preferred subsystems within a
mutually related system.
</bodyText>
<subsectionHeader confidence="0.86078">
Some examples
</subsectionHeader>
<bodyText confidence="0.996411">
The following table summarizes the dimensions and
choices deseribed above. In this section, we will use it to
characterize a number of existing formalisms.
</bodyText>
<page confidence="0.998075">
28
</page>
<table confidence="0.9571596">
Ontological Logical Relational
(
Linguistic Abstractio Primitives
Psychological (Prototype Mutual Definitional
Theoretical Exemplar Distinguishedj 10esctiptiv
</table>
<subsectionHeader confidence="0.643914">
Dimensions of choice in a semantic formalism
</subsectionHeader>
<bodyText confidence="0.99928027027027">
The traditional dictionary. The traditional dictionary is
dearly LINGUISTIC, based primarily on ABSTRACTION,
and MUTUAL relationships. It varies between being DEF-
INITIONAL and DESCRIPTIVE and at times does include
some PROTOTYPE information. The popular &apos;View of the
dictionary tends to ignore the PROTOTYPE and DESCRIP
TIVE aspects.
Theories from geeerative linguistics. Semantic theories
within the Choinskian tradition of generative linguistics
tend to be THEORErICAL, based on ABSTRACTION and
PRIMITIVES. Katz and Fodor (1964), Jackendoff (1976),
and Leech (1969) all fit these categories. There is an
occasional hint of PSYCHOLOGICAL relevance, but it does
not play a major role in the methodology. Within the
=tool of &apos;generative semantics&apos;, there are many approa-
ches. Much, of Fillmore&apos;s (1974, 1975) work is an exam-
ination .of how PROTOTYPE and EXEMPLAR systems can
provide insights which do not fit neatly into ABSTRAC-
TION. Some of the earlier work on &apos;underlying verbs&apos;
takes a more LINGUISTIC turn, in which the underlying
components are seen as closely related to actual lexical
items.
Semantics based on formal logic. Much of the work on the
semantics of natural language has been closely related to
work on the semantics of formal languages. This includes
the classical work on issues like references and more recent
attempts to view English as a formal language, as
developed in Montague grammar. On the first two
dimensions, this workâ€”is clearly THEORETICAL and
ABSTRACTION based. On the third, the relationship
between the symbols used for semantic representation
carries over that of an underlying logical system. From
the point of view of the semantic theory- (the relationship
between words and underlying entities), each p.edicate or
constant is a PRIMITIVE. The ,fact that these are related by
theorems, definitions, etc. within the logical system is
independent cif the semantic fortnalism ih the same sense
that the representation of elements in terms of sub-atomic
particles is independent of ordinary chemistry. The clarity
of this distinction (between the semantit rules and the
reasoning rules) is one of the advantages of this style of
work, not shared by most Al programs, which use data
structures and procedures which make no clear distinction.
Conceptual Dependency. Schank has been one of the most
insistent advocates of primitives, and his early (1972) work
was clearly PSYCHOLOGICAL based on PRIMITIVES. As
mentioned above, his attention to &apos;typical&apos; inferences
places it closer to PROTOTYPE than to ABSTRACTION. In
trying to expand his theory beyond the set of simple
actions for which it was initially developed he has
kradually shifted away from a strong PRIMITIVES based 3/
view, and has been one of the major developers of systems
based on DISTINGUISHED subsystems. Schank and
Abelson (1977), provide subsystems for actions, scales
reflecting a person&apos;s state, caases, scripts, goals, plans, goal
outcomes, interpersonal themes, and life themes. Their
students have carried out the same kind of actiVity in other
areas, such as the uses and classification of phisical ob-
jects. In all of this work, the emphasis is on findingta
plausible and useful set of terms, rather than on justifying
their primitive status. Most of the arguments are based on.
the pragmatics of doing language comprehension and
reasoning within the system.
KRL. KRL provides,a language for representation within
computer systems. As such, it is neutral between a
PSYCHOLOGICAL and THEORETICAL stance, but the
authors lean ,heavily towards the &apos;PSYCHOLOGICA4 in
developing their formalism. It is clearly based on
PROTOTYPES, and much of the discussion (see Bobrow
and Winograd, 1977) centers around this aspeet. It is
based on a MUTUAL DESCRIPTIVE set of relationships.
DISTINGUISHED subsystems have been deVeloped within
specific applications (see Bobrow, Wjnograd, et. al., 1977),
but -these have not been a part of the basic formalism.
</bodyText>
<subsectionHeader confidence="0.835644">
Preference Semantics. Wilks&apos; system of &apos;preference
</subsectionHeader>
<bodyText confidence="0.999173151515152">
semantics&apos; is one of the hardest to understand, since he
seems to combine many difTereht (and often incompatible)
views. He insists thgt his system is based on PRIMITIVES,
but it has few of the characteristics described above. In
fact, his discussion argues strongly for the possibility of a
MUTUAL DEFINITIONAL system, and he provides an
interesting set of DIsTiSiGUISHED subsystems (1977,
Appendix A). In stating that &amp;quot;primitives are to be found
in .all natural language understanding systems&amp;quot; (1977, p.
19) he seems to be using the term &apos;primitive&apos; to cover any
formal symbol used in a semantic system. He argues
against the PSYCHOLOGICAL basis, but alternates between
the other two possibilities along the ontological dimension.
He is LINGUISTIC in stating that his formalism is con-
sistent with the view that &amp;quot;Every semantic primitive can
appear as a surface word in a natural language&amp;quot;, and
THEORETICAL in arguing that the primitives are part ot an
interlingual &amp;quot;primitive language&amp;quot; which is a &amp;quot;useful
organizing hypothesis&amp;quot; which has no independent justi-
fication in psychological terms, and &amp;quot;has no correct
vocabulary, any more than English has&amp;quot;. His formulas
generally contain only ABSTRACTION information in their
structure, but have PROTOTYPE information (or in hi
terms, &apos;preferences&apos;) in the assignment of types of objects
to the nodes.
OWL. The OWL representation is much closer to a
LINGUISTIC base than any of the other listed here. It -is
described as a system of &apos;concepts&apos;, but its developers
(Szolovits, Hawkinson, and Martin, 1977) have paid a
good deal of attention to the way that natural language
words and collocations can be preserved in the repre-
sentation. It has a MUTUAL DESCRIPTIVE organization,
which focuses on ABSTRACTION sorts of information.
</bodyText>
<page confidence="0.836292">
2g
</page>
<bodyText confidence="0.994081">
although the semantics of the reasoning process are not
clearly enough specified to distinguish between this and
other choices on the logical dimension. The term
&apos;exemplar&apos; is used in OWL toâ€“refer to sub-classes of a
larger class, a&apos; concept related to but not the same as the
one described above.
Semantic networks. There are many versions of semantic
networks, and it is hard to say anything which applies
across the board. The majority have been argued on
PSYCHOLOGICAL grounds, have focussed on ABSTRAC-
TION information, although with some PROTOTYPE, and
have been a web of MUTUAL DESCRIPTION. The network
notation is well suited to MUTUAL (as opposed to
PrimmvE), but is general enough to be used for almost
anything.
</bodyText>
<subsectionHeader confidence="0.949846">
Properties ef s-emantic systems
</subsectionHeader>
<bodyText confidence="0.999474789473684">
The purpose of the classification given above is to providl.
a basis for comparing the merits and problems of
alternative formalisms. Rather than arguing whether
primitives are Tier or wrong, we will examine some
desirable properties for semantic systems and see what
they imply for the choices to be made along the three
dimensions. This paper cannot hope to cover the full range
of important issues, but as examples we will consider the
following properties:
The ability to state significant generalizations
Criteria for deciding on a set of semantic entities
Coverage of relevant semantic phenomena
Canon icality and its effects on memory form
Possibilities for dealing with extended meaning and
metaphor
The ability to state significant generalizations. The raison
d&apos;etre of a semantic theory is the desire to find regularities
in the way language conveys meaning. Rather than
enumerating the relationships among every possible set of
texts, we can assign formal semantic structures to texts in a
regular way, and systematically describe relationships
between these structures. The theory is interesting to the
extent that the formal semantic system allows us to find.
regularities .rand state broader generalizations than we
could at the surface level.
There are many possible views .as to what kinds of
generalizations are most interesting. Linguists look for
generalizations which predict the judgements of native
speakers as to whether sentences are well-formed. tome,
like Jackendoff (1976) also look for generalizations as to
the entailment relations between sentences. At work, such
as that of Rieger (1975) emphasizes inferential general-
izationsâ€”that certain inferences will be made whenever a
giâ€˜ven underlying semantic structure appears. 11 systems
in general are based on &apos;reasoning&apos; programs which make
use of semantic representations to do reasoaing which is
independent of the specific linguistic form in which the
knowledge was stated.
</bodyText>
<page confidence="0.302203">
32
</page>
<bodyText confidence="0.999696293103449">
In some discussions of primitives, it is implied that it is
necessary to have a system based on primitives in order to
make significant generalizations. It shoula be clear from
the discussion above that this is a confusion of categories.
Any system of formal semantics is based on generalization.
The specific choice to base it on primitive decomposition
may lead to a different set of generalizations, but not a
necessarily better one.
Criteria for deciding on a set of semantic entities. The
main factor influencing the choice and justification of
semantic entities within a formalism is the choice along the
ontological dimension. Those who take a LiNGuisTic
position need make no choiceâ€”the words of the language
are themselves the entities of the semantic theory. There
is work to be done in determining the relations between
them, but the set of entities is given from the beginning.
Those who take a THF.ORETICAL stance are free to create
semantic edifies at will, but must justify them by demon-
strating that the set chosen leads to generalizations and
simplifications which are not shared by alternative sets. In
the generative grammar tradition, a good deal of attention
is given to finding a highly valued set. Through careful
work, one can construct tests in the form of sentences
whose acceptability would be predicted by one possible
set, and not by another: Simplicity of stating the semantic
theory is used to choose between sets&apos;with equal coverage.
In the Al tradition, the selection of entities is mcire
intuitive and less careful. A system as a whole is claimed
to &apos;work&apos;, and there is little precise evaluation of which
aspects of the formalism were critical, and what might be
done with alternatives. In this context, there are only
vague intuitions and heuristics to guide the choice of
entities and their relationships. Wilks accepts this, in
noting that &amp;quot;no direct justification of the vocabulary [of
primitives] makes any sense&apos;
The must interesting problems arise if the formalism is
intended as a PSYCHOLOGICAL theory. In this case, the
determination of a set of semantic entities is an empirical
question. There is an implicit claim that there are
functional equivalents to the elements of the semantic
theory within the psychological activities of compre-
hending and generating.language. It is possible to invent
experiments which can choose between alternative theories
according to the detailed predictions they make about
human performance. Some of the distinctions above (such
as that between ABSTRACTION, PROTOTYPE and EXEM-
PLAR) grew out of -experiments of this type. However,
there is a large gap between the isolated examples handled
in experiments and the kind of coverage needed hr a
comprehensive semantic formalism. Those people in Al
who have built large-scale systems have not looked to
detailed psychological justifications, even though they
often informally describe their formalism as a
psychological theory. When Schank (1972) calls his
formalism &apos;conceptual dependency&apos;, or Jackendoff desc-
ribes his system as using cognitive primitives&apos; the appeal
to psychology is suggestive, not of direct relevance to the
methodologies they follow.
</bodyText>
<page confidence="0.99613">
30
</page>
<bodyText confidence="0.999157552238806">
Within a ESYCHOLOGICAL viewpoint, there are many
further issues as to the generality of the postulated
semantic entities. Are they idiosyncratic, or shared by all
competent speakers of a language? Are they language-
specific, or do they represent a more basic experiential
knowledge which cuts across cultures and lahguages? If
they are not language-specific, then are they innate or
learned? There has been some interesting work done on
these questions in very specific.semantic domains such as
the lexicon for describing colors, but once we move
outside of these limited domains, most of what can be
said is anecdotal or, purely speculative.
Coverage of relevant semantic phenomena. In developing
a comprehensive semantic theory, there are many aspects
of meaning which must be taken into, account. A
formalism which is developed for one aspect of meaning
(for example, the hierarchical relationships between the
classes named by common nouns) marbe inadequate or
completely irrelevant for others (for example, the ways in
which participants are related to events). In some cases, a
general approach cuts across several aspects. Much of the
discussion of primitives and prototypes above can be
applied both to classification (for example, Schank&apos;s (1972)
classification of acts vs. Lakoff&apos;s (1977) &apos;gestalts&apos;) and to
the case relationships between participants and an act
(Fillmore&apos;s (1968) notion of a primitive set of cases vs. the
Bobrow and Winograd (1977) notions of hierarchies of
prototypes with named `slots&apos;).
Existing semantic formalisms are all partial, and many
of the arguments in the literature are of the &amp;quot;I can do
something you can&apos;t do&amp;quot; style. It is clear, for example,
that PIMITIVES are not well suited for handling the broad
vocabulary of nouns and verbs describing the objects and
actions of our world, in all their variety. As Wilks says,
&amp;quot;No representation in primitives could be expected to
distinguish by its structure hammer, mallet, and axe.&amp;quot;
Formalisms based on ABSTRACTION are problematic when
we attempt to deal with lexical fields where there are no
clear criteria for whether a word applies.. This includes the
naming of siinple objects, such as &amp;quot;cup&amp;quot; and &amp;quot;bowl&apos;a
(l_abov,&apos; 1973), as well as the more obvious areas of
metaphor. On the other hand, alternatives, such as
PROTOTYPE systems based on MUTUAL relations have
been far less developed in the details of the generalizations
they allow, and the specification &apos;IT how they would deal
with any specific semantic domains.
It is clear that no formalism at this point has a claim to
&amp;quot;Anything you can do, I can do better.&amp;quot; Intuitions as to
which aspects of language are most central play the
leading &amp;le in determining which of the competing
theories seems most promising.
Canonical form and its effects on memory and reasoning.
In early work on semantic primitives, there was a good
deal of debate about the advantages provided by a
canonical form-for the representation of meaning. Two
words or sentences with the same meaning have identical
semantic representations in a formalism based on
canonical form. In other formalisms, they may have equi-
valent representations (anything inferrable from one would
be inferred from the other) which nevertheless differ in
form. Typically, PRIMITIVE systems tend to support a
canonical form, while MUTUAL organizations do not.
However, DISTINGUISHED subsystems can be used to cre-
ate a canonical form for their particular aspect of meaning
in a system which does not depend on primitives. By
choosing to always expand into the te&apos;rms of this subsystem
in the same way, all of the properties of canc tical form
</bodyText>
<sectionHeader confidence="0.653441" genericHeader="method">
MAY.
</sectionHeader>
<bodyText confidence="0.9868542">
In evaluating the benefits of canonical form, it is
important to take into account the procedural aspects. In
its simplest usage, each piece of input text is converted
immediately to canonical form and stored that way.
Inferences are based on the element of this expanded
form, ansl memory search depends on finding the form
corresponding to the query as a subset of what is. stored.
In a more sophisticated use, the canonical form is available
for porentiar expansion, but memory can include unex-
panded structures built up out of a vocabtllary of non-
primitive semantic entities. Expansion is done only when
needed for a specific task such as matching h new input to
previous knowledge in answering a- question. The
advantages and disadvantages of canonical form are
somewhat different for these two organizations. The
primary ones can be summarized:
I. Absence of ambiguity and vagueness. This propeny
applies to the canonical form after expansion. It is a
global property of systems based on expansion at
inputâ€”since meanings arc expanded into canonical struc
tures of primitives at the time they are analyzed, there is.
no remaining uncertainty about their meaning. This is
viewed as an advantage by those who emphasize the use of
the formalism in abstract reasoning, and as a disadvantage
by those (like Martin, 1976) who emphasize the impor-
tance of context and interpretation in using knowledge.
Martin argues that a semantic representation for natural
language must share its ability to represent imprecise
meanings.
2. Reasoning activity at input time. The process of
expansion to canonical form can be used as a procedural
driver for carrying out inference. Much of the work on
concept= dependency makes use of this organization.
The advantage is a unitorm way ot tnggenng standard
inferences. The disadvantages conk from the problems of
yiggering too muchâ€”of drawing inferences far below the
level of detail relevant to the particular context because
the canonical form demands expansion to that level.
3. Uniqueness for indexing and search. A canonical form
can be stored and indexed in a uniform way which makes
it possible to use straightforward algorithms for memory
search and consistency checking. These have the
advantages and disadvantages of most uniform procedures
for dealing with complex structuresâ€”they are easy to write
and understand, but they suffer from combinatorially
explosive inefficiency and tend to bog down for all but
tiny toy bodies of knowledge. One of the fundamental
technical differences among existing systems is in whether
they emphasize uniformity (as in most logic-based systems,
and in early versions of coaceptual dependency) or the
</bodyText>
<page confidence="0.944064">
33
31
</page>
<bodyText confidence="0.986949693877551">
provision of explicit tools for controlling memory search
and inference (as in KRL).
4. Association of inference rules with primitive elements.
In a system which is expected to expand meanings into
canonical form (either at input time or in the process of
reasoning), inference rules can be associated with the most
general primitives (e.g. GO, used in a sense which covers
all sorts of change, as in Jackendoff (1976)). In a system
which does not expand to a common base, the same
inference might have to be repeated in a number of places.
The disadvantage arises in the case where an inference is
associated with a higher-level meaning (such as &amp;quot;flee&amp;quot;
having implications not shared by other instances of
going). in a fully canonical system, it is, necessary to
recognize the particular combination of primitives which
triggers the inference. In systems like that of Rieger
(1975), there are discrimination nets, used to sort out the
appropriate inferences from the expandeci forms. This
again leads to a combinatorial problem which becomes
untenable in all but the smallest systems. Like the other
issues, this one is complicated by the ability to build
systems which partalce of canonical expansion to some
degree, either by expanding only along certain dimensions,
,or by operating with a mixture of expanded forms and
non-primitive-based forms from which they were derived.
Possibilities for dealing with extended meaning and
metaphor. A recurring theme in discussions of semantics
is that of metaphor. Any realistic view of language must
take into account the fact that words are used in ways
which defy simple- analytic characterization of their
meaning. There are explicitly poetic metaphors, conven-
tional metaphors (&amp;quot;His ideas were beyond me&amp;quot;, &amp;quot;Carter
named three lain targets in his war on inflation&amp;quot;), and a
wide range of cases in which meanings are extended
beyond their prototypical application. For-example, if we
define &amp;quot;spend&amp;quot; in terms of a commercial transaction, then
it must be extended to deal with &amp;quot;I spent a week -in
Boston.&amp;quot; In general, formal semantic theories have not
gone very far in dealing with these problems. Those who
base systems on PROTOTYPE or EXEMPLAR reasoning
argue that this is an important step towards dealing with
the fuzzier aspects of language. However, the compu-
tational details needed to make the power of such systems
clear have not been filled in. They either stick to trivial
cases (as in Moore and Newell, 1973), or operate in ways
which do not depend on going beyond standard logical
meaning. This area remains one of the most tantalizing
and difficult for future research.
3?
</bodyText>
<sectionHeader confidence="0.948758" genericHeader="method">
REFERENCES
</sectionHeader>
<reference confidence="0.858351524590164">
Berlin, B, and P. Kay, Basic color terms: their universality and
evolution, Berkeley: Univ. of California Press, 1969.
Bobrow, D.G. and T. Winograd. An overview of KRL, a Knowledge
Representation Language, Cognitiw Science 1:1 (January, 1977), 3-46
Bobrow, D.G., T Winograd, and the KRL Research Group,
Expenende with KR L-0: Me cycle of a knowledge representation
language. Proceedings of the Fifth International Joint Coilference on
Ar4ficial Intelligence (August, 1977), 213-222.
Clark, H.H., and E.V. Clark, Psychology of Language An
Introifuedion to Psycholinguiltics, New York: Harcourt Brace, 1977.
Dreyfus, H. L., What computers can&apos;t do: a critique of artificial
reason, New York: Harper &amp; Row, 1972.
Fillmore, C., The case for case, In Bach and HarmslEds.), Universals
in Linguistic Theory, Chicago: Holt, 1968E. 1-90.
Linguistics, Univ. of California Berkeley.
tics
F19117l4m.ore. C., The future of Semantics, Berkeley Studies in Syntax
and Semantics Dept. of
Fillmore, C., An Alternative to Checklist Theories of Meaning,
Proceedings of the First Annual Alerting of the Berkeley Linguistics
Society, Cogen et al. (Eds.), University of California, Berkeley, 1975.
Fodor, J.A., The Language of Thought, New York: Cromwell, 1975.
Fodor, 3.A.. Methodological &apos;solipsism as a research strategy in
psychology, _unpublished draft, 1978.
lackendoff, R.. Toward an explanatory semantic representation,
Linguistic Inquiry 7:1 (Winter, 1976) 89-150.
Katz, J.J., Semantic Theory. New York: Harper and Row, 1972.,
Katz, J.J., and J.A. Fodor, The Structure of a Semantic Theory, in J.
Fodor and J. Katz, (eds.) The Structure ef Language, Prentice Hall,
1964.
Labov, Wâ€ž The bdtmdanes of words and their meanings, in C-./. N.
Bailey and Roger Shuy (eds.), New Ways of Analyzmg Variation in
English, Georgetown Univ., 1973.
Lakoff, G., Linguistic Gestalts, Proceedings of the Chicago Linguistic
Society (CLS IV. 1977, 236-287.
Leech, G., Towards a semantic description of English, London:
Longman, 1969.
Lewis, 0., General semantics, in Davidson and Harman (eds.),
Semantics of Natural Language Dordrecht: Reidel. 1972.
Martin, W.A., A theory of English grammar, unputahed notes.
MIT, 1976.
Miller, G.A., Some psychological studies of grammar, American
Psycholagist 17 (1962), 748-762.
Miller, G.A., and P.N. Johnson-Laird,
Cambridge: Harvard University Press,
Moore J., and Newell. ..tte How can
Gregg (Ed.), Knowledge and Cognition,
Ellbaum Associates, 1973.
Rieg9r, C., Conceptual memory and inference, in R.C. Schank,
Conceptual hifinnatu n Processing, Amsterdam: North Holland,
P)75, 157-288.
Schank, R. C.,. Conceptual dependency: A theory of natural
language understanding, Cognitive Psychology, 1972, 552-631.
Schank, R.C. and R.P. Abelsonâ€ž Scripts Plans Goals and
Understanding, Hillsdale: Lawrence Erlbaum Associates, 1977.
S7olovits, P., IA. Hawkinson, and W.A. Martin, An Overview of
OWL, an language. for knowledge representation, M.I.T. LCS-TM-86,
1977.
Wilks, Y., Good and bad- arguments abtbt semantic primitives,
D.A.I. Research Report No. 42, University of Essex, May 1.977.
Winograd, T. Towards a Proceduial Understanding of Semantics&apos;,
</reference>
<table confidence="0.8013084">
Revue Intern atidnale de Philosophic 1976 fasc. 3-4 (117-118).
Language and Perception,
1976.
MERLIN understand?, In
Baltimore, Md.: Lawrence
</table>
<page confidence="0.781967">
32
</page>
<table confidence="0.853019833333333">
Taxonomic Lattice Structures for Situation Recognition.
William A. Woods
Bolt Beranek and Newman Inc&apos;.
50 Moulton Street
Cambridge, MA 02138
S
</table>
<sectionHeader confidence="0.31524" genericHeader="method">
1. The Role of a Knowledge Network for an
</sectionHeader>
<subsectionHeader confidence="0.853895">
Intelligent Machine
</subsectionHeader>
<bodyText confidence="0.998299453488372">
The kinds of intelligent computer
assistants that we wpuld like to be able
to construct are very much like
intelligent organisms in their own right.
Imagine for a moment an intelligent
organism trying to get along in the world
(find enough food, 10 stay out of trouble,
satisfy basic needs, etc.). The most
valuable service played by an internal
knowledge base for such an organism is to
repeatedly answer question t like &amp;quot;what&apos;s
going on out /there?&amp;quot;, &amp;quot;can it harm me?&amp;quot;,
&amp;quot;how can I avoid/placate it?&amp;quot;, &amp;quot;Is.it&apos;igood
to eat?&amp;quot;, &amp;quot;Is there any special thing I
should do about it?&amp;quot;, etc. TO support
this kind of activity, a substantial part
of the knowledge base must be organi-zed as
a recognition device for classifying and
identifying situations in the world. The
major purpose of this situation
recognition is to locate internal
procedures which are applicable
(appropriate, permitted, mandatory, etc.)
to the current situation.
In constructing an intelligent
computer assistant, the. roles of knowledge
are very similar. The basic goals of food
getting and danger avoidance are replaced
by goals of doing what the user wants and
avoiding things that the machine has been
instructed to avoid. However, the
fundamental problem ,0 of analyzing a
situation (one established either
linguistically or physically or by some
combination of the two) in order to
determine whether it is one for which
there are procedures to be executed, or
one which was to be avoided (or one which
might Lead to one that is to be avoided),
etc. is basically the same. For example,
One might want to instruct such a system
to remind the user in advance of any
upcoming scheduled meetings-, to inform him
if he tries to assign a resource that has
already been committed, to always print
out mesixIges in reverse chronological
order (when requested), to assume that
&amp;quot;the first&amp;quot; refers to the first day of the
upcoming month in a future scheduling
context and the first day of the current
month in a past context,. etc.
The principal role of the knowledge
network for such a system is essentially
to serve as a &amp;quot;coat rack&amp;quot; upon Which to
hang various pieces of advice for the
system to execute. Thus the notion of
procedural attachment becomes not just an
efficiency technique, but the main purpose
for the existence of the network. This
does not necessarily imply, however, that
the procedures involved consist of
low-level machine code. They may instead,
and probably usually will, be high level
specifications of things to be done or
goals to be achieved. The principal
structure that organizes all of these
procedures is a conceptual taxonomy of
situations about which the machine knows
something.
To support the above uses of
knowledge, an important characteristic
required of an efficient knowledge
representation seems to be a mechanism of
inheritance that will permit information
to be stored in its most general form and
yet still be triggered by any more
specific situation or instance to which it
applies. Moreover, the nodes in the
network (or, at least a major class of
nodes) should be interpretable as
situation descriptions. One of the most
fundamental kinds of information to be
stared in the knowledge base will be rules
of the form &amp;quot;if &lt;situation description&gt; is
satisfied then do,&lt;action description&gt;&amp;quot;,
or &amp;quot;if &lt;situation description&gt; then expect
</bodyText>
<sectionHeader confidence="0.271411" genericHeader="method">
&lt;situation description&gt;&amp;quot;. - Situation
</sectionHeader>
<subsectionHeader confidence="0.5608185">
descriptions are in general
characterizations of classes of situations
</subsectionHeader>
<bodyText confidence="0.9965389375">
that the machine could be in. -They are
not complete descriptions of world states,
but only partial descriptions that apply
to classes of worla states. (The machine
should never be assumed or required to
have a complete description of a world
state if it is ea deal with the real
world.) A situation in this partial sense
is defined by the results of certain
measurements, somputations, or recognition
procedures applied to the system&apos;s input.
Examples of sttuations might be &amp;quot;You have
a goal to achieve which is an example of
situation Y&amp;quot; &amp;quot;You are perceiving an
object of class V, &amp;quot;The user has asked
you to perform a task of type W&amp;quot;, etc.
</bodyText>
<page confidence="0.998009">
33
</page>
<bodyText confidence="0.986467078431373">
More specific situations might be:
&amp;quot;trying to schedule a meeting for three
people, two of which have busy schedules&amp;quot;,
&amp;quot;about to print a message from a user to
himself&amp;quot;, &amp;quot;about to refer to a date in a
recent previous year in a context where
precision but conciseness is required&amp;quot;.
The major references to. this
conceptual taxonomy by the intelligent
machine will be attempts to identlfy and
activate those situation descriptions, that
apply to its current situation or some
hypothesized situation in order to
consider any Ovice that may be stored
there. Note- that &amp;quot;considering advice of
type X&amp;quot; is itself an example of a
situation, so that this process can easily
become recursive and potentially
unmanagpable without appropriate care.
Conceptually, one might think of the
process of activating all of the
descriptions that are satisfied by the
current situation as one of taking a
description of the current situation and
matching it against descriptions stored in
the system. However, there are in general
many different ways in which the current
situation might be described, and it is
not clear how one sKould construct such a
description.
Moreover, until it is so recognized,
a situation consists of a collection of
unrelated events and conditions. The
process of recognizing the elements
currently being perceived as an instance
of a situation about which some
information is kno*n consists of
discovering that those elements can be
interpreted as filling roles in a
situation description known to the system.
In fact, the process of creating a
description of the current situation is
very much like the process of parsing a
sentence, and inherently uses the
knowledge structure of the system like a
parser uses a grammar in order to
construct the appropriate description.
Consequently, by the time a description of
the situation has been constructed, it has
already been effectively _matched against
the descriptions ;-n.--:&amp;he knowledge base.
</bodyText>
<sectionHeader confidence="0.785839" genericHeader="method">
2. Parsing Situations
</sectionHeader>
<bodyText confidence="0.993477153846154">
As suggested above, the process of
recognizing that a current situation is an
instance of an internal situation
description is similar to the process of
parsing a sentence, although considerably
more difficult due to a more open-ended
set,aof possible relationships among the
&amp;quot;constituents&amp;quot; 0( a situation. That is,
whereas the principal relationship between
constituents in sentences is merely
adjacency in the input. string, the
relationships among constituents of a
situation may be arbitrary (e.g. events,
preceding one another in time, people,
places, or physical objects in various
spatial relationships with each other,
objects in physical or legal possession of
people, people, in relationships of
authority to Other people, etc.) However,
the basic characteristic of parsers, that
the objects recognized are characterized
as structured objects assembled out of
recognizable parts according to known
rules of assembly, is shared by this task
of situation recognition.
Note that it is not sufficient merely
to characterize a situation as a member of
one of a finite number of known classes.
That is, where it is not sufficient for a
parser to simply say that its input is an
example of a declarative sentence (one
wants to be able to ask what the subject
is, what the verb is, whether the sentence
has past, present or future tense, etc.),
in a similar way it is insufficient to
merely say that an input situation is an
example of someone doing something. One
must generate a detailed description of
who is doing what to whom, etc.
It is also not sufficient to
characterize a situation as a single
instance of an existing concept with
values filled in for empty, slots. In
general, a situation description must be a
composite structured object, various
subparts of which will be instances of
other concepts assembled together in ways
that are formal-Ly permitted, in much the
same way that the description of a
sentence is put together from instances of
noun phrases, clauses, and prepositional
phrases. The specific instance built up
must keep track of which constituents of
the specific situation fill which roles of
the concepts being recognized. Moreover,
it cannot do so by simply filling in the
slots of those general concepts, since a
general concept may have multiple
instantiations in many situations.
Rather, new structures representing
instances of those concepts must be
constructed and pairings of constituent
roles from the concept and roLe fillers
from the current situation must be
associated with each new instance.
</bodyText>
<sectionHeader confidence="0.983144" genericHeader="method">
3. The Process of Situation Recognition
</sectionHeader>
<bodyText confidence="0.993875333333333">
The process of situation recognition
consists of detecting that a set of
participants of certain kinds stand in
some specified relationship to each other.
In general, when some set of participants
is present at the sensory interface of the
system (immediate input plus past memory),
the task of determining whether there is
some situation description in memory that
will account for the _relationships of
those inputs is not trivial. If the total
number of situation descriptions in the
system is sufficiently small, all of them
can be individually tested against the
input to see if any are satisfied. If the
</bodyText>
<page confidence="0.997569">
34
</page>
<bodyText confidence="0.995810142857143">
number of such descriptions is
sufficiently large, however, this is ntlf
feasible.
Alternatively, if there is some
particular participant that by virtue of
its type strongly suggests what situation
descriptions it might participate in, then
an index from this participant might
select a more manageable set of situation
descriptions to test. Even in this case,
however, the number of situations in which
the constituent could participate may
still be too large to test efficiently.
In the most difficult situation, no single
participant in the input is sufficiently
suggestive by itself to constrain the set
of possible patterns to a reasonable
number. However, it may still be that the
coincidence of several constituents and
relationships may suffice, providing that
the coincidence can be detected. It is
this problem of coincidence detection that
I believe to be crucial to solving the
gefferal situation recognition problem.
As an example, consider the following
fragment of a protocol of a commander
giving commands to an intelligent display
system:
</bodyText>
<subsectionHeader confidence="0.500576">
Cdr: Show me a display elf the
</subsectionHeader>
<bodyText confidence="0.966739">
eastern Mediterranean.
[computer produces display]
Cdr: Focus in more on Israel and
Jordan.
[computer does so]
Cdr: Not that much; I want to be
able to see Port Said and the
Island of Cyprus.
In the first, clause of.the third command
of this discourse, (i.e. &amp;quot;not that much&amp;quot;),
there is no single word that is strongly
suggestive of the interpretation of the
sentence. MoreoVer, there is nothing
explicit to suggest the relationship of
this clause to the one that follows the
semicolon. The latter, if interpreted in
isolation, would merely be a request for a
display, lox perhaps a succession of two
displays, Ohile in the context given, it
is a request to modify a previoud display.
There are. two methods that I believe
may be sufficient, either individually or
in &apos;combination, to model coincidence
fttection. One is the use of factored
knowledge structures that merge common
parts of alternative hypotheses. The
Other involves the use of a markable
classification structure in which the
individual recognition predicates
triggered by the ongoing discourse will
leave traces of theirt, having fired, so
that coincidences of such traces can be
efficiently detected. I have been
investigating a structure which I call a
&amp;quot;taxonomic lattice&amp;quot;, that combines some
featurei of both methods.
</bodyText>
<subsectionHeader confidence="0.980785">
3.1 Factored Knowledge Structures
&apos;Given a knowledge-based system with
</subsectionHeader>
<bodyText confidence="0.9989614">
large numbers of situation-action rules,
where it is infeasible to find the rules
that match a given situation by
systematically considering each rule, one
needs to haze some way of reducing the
computational load. As mentioned before,
one approath is to index the rules
according to some salient feature that
will be easily detectable in the irfput
situation and can then be used to find a
much more limited set of rules to apply.
This has been done in many systems,
including the LUNAR system for natural
language question answering [Woods, 1973,
1977]. In that system, rules for
interpreting the meanings of sentences
were indexed according to the verb of the
sentence and rules for interpreting &amp;Am
phrases were indewed by the head noun.
Although this approach reduces the number
of rules that need to be considered, it
has several limitations still. The first
is that there may be some values of the
index key for which there are still a
large number of rules to consider. In the
case of the LUNAR system, for example, the
verb &amp;quot;be&amp;quot; had a large number of rules to
account for different senses of the word.
Another is that there can be certain
constructions for which there is no single
easily detected feature that is strongly
constraining as to possible meaning. In
this case, there is no useful index key
that can be used to select a sufficiently
constrained set of rules to try.
</bodyText>
<subsectionHeader confidence="0.82682">
Another limitation Of this indexing
</subsectionHeader>
<bodyText confidence="0.999789032258065">
approach as the range of language becomes
more fluent is that in certain elliptical
sentences, the constraining key may be
ellipsed, and although one can have the
rules indexed by other keys as well, the
remaining ones may not sufficiently
constrain the set of ogles that need to be
considered. Finally, even when the set of
ruleis has been constrained to a relatively
small set, there is frequently a good deal
of sharing of common tests among different
rules, and considering each rule
independently results in repeating these
tests separately for each rule.
One approach to solving all of the
above problems is to use what I have been
calling a &amp;quot;factored knowledge structure&amp;quot;
for the recognition process. In such a
structure, the common parts of different
rules are-merged so that the process of
testing them is done only once. With such
structures, one can effectilely test all
of the rules in a very large set, and do
so efficiently, but never consider any
single rule individually. At each point
in a factored knowledge structure, a test
is made and some information gained about
the input. The result of this test
determines the next test to be made. As
each test is made and additional
information accumulated, the set of
</bodyText>
<page confidence="0.998302">
35
</page>
<bodyText confidence="0.99996403125">
possible rules that could be satisfied by
the input, given the values of the tests
so far made, is gradually narrowed until
eventually only rules that actually match
the input remain. Until the end of this
decision structure is reached, however,
none of these rules is actually considered
explicitly. This principle of factoring
together common parts of different
patterns to facilitate shared processing
is the basic technique that makes ATN
grammars _Woods, 1970] more efficient in
some sense ehan ordinary phrase structure
grammars. It has also been used by the
lexical retrieval component of the BBN
speech understanding system [Woods et al.,
1976; Wolf and Woods, 19771 and accounts
for the efficiency of the finite state
grammar approach of the CMU Harpy system
[Lowerre, 19761. A recent innovative use
of this principle appears in Rieger&apos;s
&amp;quot;trigger trees&amp;quot; for organizing spontaneous
computations [Rieger, 19771.
Whether factored together or not, the
task of accessing rules is not a simple
one. One problem is that rules don&apos;t
match the input letter-for-letter: rather,
they have variables in them with various
restrictions on what they can match. For
example a rule might say that whenever an
access is made to a classified file, then
a record of the person making the request
should be made. The description, &amp;quot;an
access to a classified file&amp;quot; needs to be
matched against the userts request (or
some subpart of it) and in that match, the
description &amp;quot;a classified file&amp;quot; will be
matched against some specific file name.
In this kind of situation, there is no
natural ordering of the rules, analogous
to the alphabetical ordering of words,
that will help in finding the rules that
are satisfied by the given situation. Nor
is a structure as simple as the dictionary
tree abOve adequate for this case.
Another problem is that a given
situation may be matched by several rules
simultaneously with differing degrees of
generality. For example, there may be a
rule that says &amp;quot;whenever access is made to
a top secret file (more specific than
classified), then check the need-to-know
status of the user for that information
and block access if not satisfied&amp;quot;. In
the case of a request to a top secret
file, both of the above rules must be
found, while in the case of an ordinary
classified file, only the first should.
The actual input, however, kali&apos; not
explicitly mention either &amp;quot;top-secret&amp;quot; or
&amp;quot;classified&amp;quot;, but will merely be some file
name that has many attributes and
properties, among which the attribute
&amp;quot;classified&amp;quot; is not particularly salient-.
</bodyText>
<subsectionHeader confidence="0.999616">
3.2 Markable Classification Structures 43g
</subsectionHeader>
<bodyText confidence="0.989861191176471">
Another technique that holds promise
for situation recognition is the use of a
markable classification structure in which
coincidences of relatively non-salient
events can be detected. The keystone of
this approach is a technique that Quillian
proposed for modeling certain aspects of
human associative memory [Quillian, 1966,
1968]. Quillian&apos;s technique of &amp;quot;semantic
intersection&amp;quot; consitted of propagating
traces of &amp;quot;activation&amp;quot; through a semantic
network structure so that connection paths
relating arbitrary concepts could be
detected. For example, his system was
able to connect concepts such as &amp;quot;plant&amp;quot;
and &amp;quot;nourishment&amp;quot; by discovering the
chain&amp;quot; equivalent to &amp;quot;plants draw
nourishment ftom the soil&amp;quot;. If the
appropriate information were in the
network, this technique would also find
chains of indirect connections such as
&amp;quot;Plants can be food for people&amp;quot; and
&amp;quot;People draw nourishment from food.&amp;quot; The
method was capable of finding paths of
arbitrary length.
/he problem of finding connections
between concepts in a knowledge network is
like the problem of finding a path through
a maze from a source node to some goal
node. At the lowest level, it requires a
trial and error search in a space that can
be large and potentially combinatoric.
That is, if one element of the input could
be connected to k different concepts, each
of which would in turn be connected to k
others, and so on, until finally a concept
that connected to the goal was discovered,
then the space in which one would have to
search to find a path of length n would
contain kn paths. However, if one started
from both ends (assuming a branching
factor of k also in the reverse
direction), one could find all the paths
of lqqgth n/2 from either end in only
2. k&apos;
If one then had an efficient way to
determine whether any of the paths from
the source node connected with Iny of the
paths from the&apos; goalnode, such search
from both ends would have a considerable
savings. This can be done quite
efficiently if the algorithm is capable of
putting marks in the structure of the maze
itself (or some structure isomorphic to
it), , so that it can tell when reaChing a
given node whether a path from the source
or the goal has already reached that node.
However, without such ability to mark the
nodes of the maze, the process of testing
whether a given path from the source can
hook up with a path from the goal would
involve a search. thnough all the paths
from the goal individually, and a search
down each such path to see if the node at
the end of the source path occurred
anywhere on that path. If this were
necessary, then all of the advantage of
searching from both ends would be lost.
</bodyText>
<page confidence="0.989551">
36
31
</page>
<bodyText confidence="0.999654714285714">
The use of the graph structure Itself to
hold marks is thus critical to gaining
advantage from this algorithm.
Essentially, the nodes of the graph serve
as rendezvous poi.nts where paths that are
compatible can meet each other. The
coincidence of a path from the source
meeting a path from the goal at some node
guarantees the discovery of a cOmplete
path without any path requiring more than
a simple test at the corresponding node in
the graph as each link is added to the
path.
What is needed for situation
recognition in a generalization of
Quillian&apos;s semantic intersection technique
in which the source and goal nodes are
replaced by a potentially large number of
concept nodes, some of which are
stimulated by immediate input, and some of
which are remembering recent activation in
the past. Moreover, what is significant
is not just simple paths between two
nodes, but the confluence of marks from
multiple sources in predetermined
patterns. Moreover, unlike Quillian, who
considered all connections identically in
searching for paths, we will consider
marker passing strategies in which marks
can&apos; be passed selectively along certain
links. Recently, Fahlman [1077] has
presented some interesting-formal machine
specifications of Quillian-type spreading
activation processes which have this
characteristic.
</bodyText>
<sectionHeader confidence="0.834403" genericHeader="method">
4. The Structure of Concepts
</sectionHeader>
<subsectionHeader confidence="0.515448">
In building up internal descriptions
</subsectionHeader>
<bodyText confidence="0.999880585365853">
of situations, one needs to make use of
concepts of objects, substances, times;
places, events, conditions, predicates,
functions, individuals, etc. Each such
internal concept will itself have a
structure and can be represented as a
configuration of attribUtes or parts,
satisfying certain restrictions and
standing in specified relationships to
each other. Brachman [1978] has developed
a set of epistemologically explicit
conventions for representing such concepts
in a &amp;quot;Structured Inheritance Network&amp;quot;, in
which interrelationships of various parts
of concepts to each other and to more
general and more specific concepts are
explicitly represented. The essential
characteristic of these networks is their
ability to represent descriptions of
structured objects of various degrees of
generality with explicit representation of
the inheritance relationships between
corresponding constituents of those
structures. A concept node in Brachman&apos;s
formulation consists of a set of dattrs (a
generalization of the notions of
attribute..., part, constituent, feature,
etc.) and a set of structural
relationships among them. Some of these
dattrs are represented directly at a given
node, and others are inherited indirectly
from other nodes in the network to whioh
they are related.
Let us assume that each concept that
the system understands is represented as a
node in one of these structured
inheritance networks. The network, as a
whole, then serves as a conceptual
taxonomy of all podtible &amp;quot;entities&amp;quot; that
the system can perceive or underttand.
Each node in this taxonomy can be thought
of as a micro schema for the recognition
of instances of that concept. Each has a
set of dattrs with individual restrictions
and a set of structural conditions that
relate the dattrs to one another. These
restrictions and structural conditions may
themselves be defined in terms of other
concepts defined by other micro schemata,
and so on until a level of primitively
defined, directly perceivable concepts is
reached.
Each concept in the taxonomy can be
thought of as having a level of
abstractness defined as the maximum depth
of nesting of its constituent structure.
Instances of primitively defined concepts
have level 0, constellations of those
concepts have level 1, a concept having
level 1 and lower concepts as dattr$ has
level 2, and so on. If a taxonoml
contained only level 0 and level 1
concepts, then the situation recognition
problem would be greatly simplified, since
one never needs to recognize portions of
the input as entities that participate as
constituents of larger entities. The
general problem, however, requires us to
do exactly that. More _seriously, the
general case requires us to recognite a
concept some of whose dattrs may have
restrictions defined in terms of the
concept itself. This is true, for
example, for the concept of noun phrase in
a taxonomy of syntactic constructions.
Such recursively defined concepts have no
maximum level of abstractness, although
any given instance will only involve a
finite number of levels of recursion.
This potential for recursive definition
must be kept in mind when formulating
algorithms for situation recognition.
</bodyText>
<sectionHeader confidence="0.949138" genericHeader="method">
5. The Need for Inheritance Structures
</sectionHeader>
<bodyText confidence="0.996337933333333">
As a result of having different
levels of abstraction in one&apos;s taxonomy,
an input situation will often satisfy
several situation descriptions
simultaneously, no one of which will
account for all of the input nor supplant
the relevance of the others. For example,
adding a ship to a display is
simultaneously an example of changing a
display and of displaying a ship. Advice
for both activities Mist be considered.
Moreover, a single description may have
sever-al different instantiations in the
current situation, with situation
descriptions becoming arbitrarily complex
</bodyText>
<page confidence="0.997945">
37
</page>
<bodyText confidence="0.999358409638554">
by the addition of various qualifiers, by
the conjunction and disjunction of
descriptions, etc. For example, one might
want to store advice associated with the
situation [wanting to display a large ship
at a location on the screen that is within
one unit distance from either the top,
bottom, or side of the screen when the
scale of the display is greater than
1:1000]. Finally, situation descriptions
may subsume other descriptions at lower
levels of detail, and advice from both may
be relevant and may either supplement or
contradict each other. For example,
displaying an aircraft carrier is a
special case of displaying a ship, and
there may be specific advice associated
with displaying carriers as well as more
general advice for displaying any ship.
Thus, conventions will be required to
determine which advice takes precedence
over the other if conflicts arise.
The or,ganization of large numbers of
such situation descriptions of varying
degrees of generality so that all
descriptions more general or more specific
than a given one can efficiently be found
is one thing we require of an intelligent
computer assistant. In order to build and
maintain such a structure, it is important
to store each rule at the appropriate
level of generality, relying on a
mechanism whereby more specific situations
automatically inherit information from
more general ones. That is, when one
wants to create a situation description
that is more specific than a given one in
some dimension, one does not want to have
to copy all of the attributes of the
general situation, but only those that are
changed. Aside from conserving memory
storage, avoiding such copying also
facilitates updating and maintaining the
consistency of the data base by avoiding
the creation of duplicate copies of
information that then may need to be
independently modified and could
accidentally be modified inconsistently.
For example, one may want to store
advice about displaying geographical
features, about displaying such features
that cover an area, about displaying
bodies of water, about displaying lakes,
etc. Thus, information about finding the
area covered by a feature would be stored
at the level of dealing with such
area-covering features. information about
displaying water inla certain color would
be stored at the level of displaying
bodies of water, and information about
having inlets and outlets would be stored
at the Level of lakes. In any specific
situation that the system finds itself,
many such concepts at different levels of
generality will be satisfied, and the
advice associated with all of them becomes
applicable. That is, any more specific
concept, including that of the current
situation, inherits a great deal of
information that is explicitly stored at
higher levels in the taxonomy.
In the case of the situation 1/0
descriptions that we are dealing with,
even the specification of what dattrs -a
given concept possesses is stored at the
most general level and inherited by more
specific concepts. Thus, for example, the
descriptions of attribute dattrs for color
and weight are stored for a general
concept of physical object. These dattrs
are then inherited by any more specific
concepts of physical objects, such as
planes, ships, desks, and pencils.
</bodyText>
<sectionHeader confidence="0.972778" genericHeader="method">
6. The Taxonomic Lattice
</sectionHeader>
<bodyText confidence="0.997509851851852">
I believe that a general solution to
the situation recognition problem can be
obtained by the use of a classification
structure in which traces of Individual
elements of complex concepts can intersect
to facilitate the discovery of
coincidences and connections that may not
be strongly inferable ,from constraining
expectations. The structure that I
propose to use is a version of Brachman&apos;s
structured inheritance networks, in which
descriptions of all potentially relevant
situations are stored with explicit
indications of general subsumpt.ion.of one
situation by another, and explicit
indications of the inheritance of dattrs
and of advice by one concept from another.
This structure, which I have called a
taxonomic lattice, is characterized by a
multitude of situation descriptions at
different levels of generality.
We say that a situation description
Si subsumes a description S2 if any
situation satisfying S2 will also satisfy
Si. In this case, Si is a more general
description than S2, and is placed higher
in the taxonomy. For example, [clisplaying
a portion of country] is a more specific
situation than [displaying a geographical
area], which is in turn more specific than
[dispaaying a displayable entity]. All Of
these are subsumed by a general concept
[purposive activity], which in turn is
more specific than [activity]. Moreover,
a given description can subsume many
incomparable descriptions and can itself
be subsumed by many incomparable
descriptions. For example, an instance of
[displaying a geographical area] is also
an instance of [accessing a geographical
area], [displaying, information], and
[using the display], and may possibly also
be an instance of [responding to a user
command].
The space of possible situation
descriptions forms a lattice under the
relation of subsumption. At tie top of
the lattice is a single, most general
situation we will call T, which is always
satisfied and can be thought of as the
disjunction of all possible situations.
Anything that is universally true can be
stored here. Conversely, at the bottom of
the lattice is a situation that is nevet
</bodyText>
<page confidence="0.996413">
38
</page>
<bodyText confidence="0.775713666666667">
Â£11
satisfied, which we call NIL; It can be
thought of as the conjunction of all
</bodyText>
<note confidence="0.730442333333333">
possible (including inconsistent)
situations. Assertions of negative
existence can be stored here.
</note>
<bodyText confidence="0.995917549019608">
At the &amp;quot;middle&amp;quot; level of the lattice
are a set of primitive perceptible
predicates -- descriptions whose truth in
the world are directly measurable by the
&amp;quot;sense organs&amp;quot; of the system. All classes
above this level are constructed by some
form of generalization operatton, and all
classes below are formed by some form of
specialization. At some point
sufficiently low in the lattice, one can
begin to form inconsistent descriptions by
the conjunction of incompatible concepts,
the imposition of impossible restrictions,
etc. There is nothing to prevent such
concepts from being formed; indeed, it is
necessary in order for the organism to
contemplate, store, and remember their
inconsistency.
There are a number of specific
relationships that can cause one situation
description to subsume another. A given
situation description can be made more
general by relaxing a condition on a
dattr, by eliminating the requirement for
a dattr, by relaxing the constraints of
its structural description, or by
explicitly disjoining it (or&apos;ing it) with
another description. A given description
can be made more specific by tightening
the conditions on a dattr, by adding a
dattr, by tightening the constraints of
its structural Oescription, or by
explicitly conjoining (and&apos;ing) it with
another description. These pperations
applied to any finite set of situation
descriptions induce a lattice structure of
possible situation descripfions that can
be formed by combinations of the elements
of the, initial set. We refer to this
structure as the virtual lattice induced
by a given set of situation descriptions.
Note that only a finite portion of this
lattice need be stored with explicit
connections from more specific to more
general concepts. By processing this
explicit lattice, one can test any given
description for membership in the virtual
lattice and assimilate any new situation
description into the explicit lattice in
the appropriate place corresponding to its
position in the virtual lattice.
</bodyText>
<subsectionHeader confidence="0.693217">
In operation, any situation
</subsectionHeader>
<bodyText confidence="0.999927230769231">
description about which information is
explicitly stored will be entered into the
explicit lattice. Any situation that the
machine can understand is in some sense
already in the virtual lattice and needs
only be &amp;quot;looked up&amp;quot; in it. One task we
have Set for ourselves to develop
efficient algorithms to tell whether a
given situation can be understood in terms
of the concepts of the lattice and if so,
to construct its corresponding description
and explicitly record its relations to
other concepts in the explicit lattice.
</bodyText>
<sectionHeader confidence="0.627545" genericHeader="method">
7. An Example
</sectionHeader>
<bodyText confidence="0.99528955882353">
As an example of the situation
recognition process using marker
propagation in a taxonomic lattice., let us
consider a simple case of interpreting the
intent of a simple English sentence. The
example chosen is not complex enough to
require all of the machinery discussed,
but is presented here to illustrate the
mechanism. The major features of the
situation recognition mechanism only
become critical in interpreting commands
that require several Sentences to build
up, or which depend on the current context
in compler, ways, but such situations are
difficult to illustrate.
For our example, suppose that the
system contained a concept for requests to
display a geographical region, and the
user&apos;s input request were &amp;quot;Show me the
eastern end of the Mediterranean.&amp;quot; The
concept [request] contains dattrs for the
requestor, the requestee, a description of
the state that the requestor desires, a
form of request (demand, order, polite
request, expression of preference, etc.),
and perbgps others, Requests can take
many forms. Assume that we have stored in
the system a rule that says &amp;quot;Any sentence
of the form: &apos;show me NP&apos; is a request to
display that NP.&amp;quot; This rule could be
stored in the lattice as a piece of advice
associated with the concept &amp;quot;A sentence of
the form: &apos;show me NP&apos;,&amp;quot; in such a way
that when a sentence of the indicated form
was found, an instance of a display
request would be created. At that point,
this resulting display request would be
placed in the lattice in such a way that
all more general concepts of which it is
an instance would be activated, and in
particular, the concept of a request to
display a geographical region would be
activated.
The parsing of the original sentence
can either be done by an ATN grammar, or
by a version of the taxonomic lattice
itself (one that characterizes a taxianomy
of sentence types). Let us assume here
that it is done by an ATN grammar that is
closely coupled to a taxonomic lattice,
with the ATN representing the syntactic
information about sentence form and the
taxonomic lattice representing general
semantic information. As the ATN grammar
picks up constituents of the sentence, it
reaches states where it makes hypotheses
about the syntactic roles &apos;that those
constituents play in the sentence (e.g..
&amp;quot;this is the subject&amp;quot;, &amp;quot;this is the verb&amp;quot;,
etc.)-. Such hypotheses are then entered
into the lattice, where they begin to
activate the recognition conditions of
concepts in the network. For example, in
the taxonomic lattice there is a concept
of an imperative sentence whose subject is
the system, whose verb is &amp;quot;show&amp;quot;, whose
indirect object is the user and whose
direct object is a displayable object.
</bodyText>
<page confidence="0.997946">
39
</page>
<bodyText confidence="0.99062392920354">
As the parsing proceeds, the ATN will
make assertions about the sentence. it is
building up, and it will not only be
building up syntactic representations of
constituents of the sentence, but will
also be building up representations of
possible meanings of those constituents.
In particular, it will be building up a
list of those concepts in the lattice of
which the current donstituent may be a
restriction or ifistance and a list of the
dattr-value-pairings that have been found
so far. If a parse path succeeds (i.e:
reaches a POP arc), then a node in the
taxonomic lattice corresponding teithat
hypothesis will be found or cpnstructed.
This node will have links to more general
and more specific concepts, and will have
its constituents linked to appropriate
dattrs of those concepts. At the point
when this concept node is
found/constructed, a process of activation
Spreading will be launched in the lattice
to find any advice that may be inherited
by that concept. This process will also
leave &amp;quot;footprints&amp;quot; in he lattice that
will facilitate the detection of concepts
of which the current one may itself be a
dattr (or part of a structural condition).
In the example above, wnen the parser
has parsed the initial portion of the
sentence &amp;quot;show me&amp;quot;, it has built up in its
internal registers the information
corresponding to the hypothesis that the
sentence is an imperative, with subject
&amp;quot;you&amp;quot; and indirect object &amp;quot;me&amp;quot;. Moreover,
it knows that (in input sentences) &amp;quot;you&amp;quot;
refers to the system itself, while &amp;quot;me&amp;quot;
refers to the speaker. It also knows that
the main verb is the verb &amp;quot;show&amp;quot;. Let us
suppose that at this point, the parser
decides to activate the corresponding
taxonomic lattice nodes for the concepts
[the system], [the user], and [the verb
show] (possibly with pointers to the
syntactic hypothesis being constructed
and/or the labels SUBJECT, OBJECT, VERB,
respectively). Ignoring for now whatever
information or advice may be found
associated with these cdncepts or their
generalizations, the footprints that they
leave inTthe network will intersect at a
node [display request] which has dattrs
for requeStor, requestee, form of request,
and requested thihg. They also intersect
at other concepts such as [imperative
sentence], [active sentence], [action],
and a more specific kind of display
request [region display request], whose
requested thing is a geographical region.
This latter concept was created and
inserted into the lattice precisely to
hold advice about how to display
geographical regions, and to serve as a
monitor for the occurrence of such
situations. Fig. 1 is a fragment of a
taxonomic lattice showing the concepts of
interest. (For details of the notation,
see Brachman [1978], Woods and Brachman
[1978].)
When the final noun phrase has been
parsed and given an interpretation, the
footprints that its activation leaves in
the network will awaken the [region
display request] node, which will then be
fully satisfied, and the parser will
create a corCesponding instance node, with
appropriate bindings for its dattrs. In
processing the noun phrase, the parser
will discover the adjective &amp;quot;eastern&amp;quot; and
the noun &amp;quot;Mediterranean&amp;quot; and will activate
the corresponding nodes in the taxonomic
lattice. The concept [east] is an
instance of [direction], ,which, among
other things, is the restriction for a
dattr of a concept [directionally
determined subregion] that defines the
meaning of such concepts as &amp;quot;north eastern
Idaho&amp;quot;. Another dattr of this same
concept has the restriction [geographical.
regianl, which is on the superc chain from
Mediterranean. Hence, footprints from
&amp;quot;eastern&amp;quot; and &amp;quot;Mediterranean&amp;quot; will
intersect at the concept [directionally
determined subregion], causing an insEance
of that concept to be constructed as a
possible meaning of the noun phrase. The
[directionally determined subregion]
concept itself has a superc connection to
[geographical region], which happens to be
the restriction for the &amp;quot;requested &apos;thing&amp;quot;
dattr of the concept [region display
request] which has already received marks
for its other dattrs. Thus, the
intersection of footprints from the
various constituents of the sentence at
this concept node has served to select
this node out of all the other nodes in
the network. Since the more general
concept [display request] is on a superc
chain from [region display request], it
will also be activated, and advice from
both places will be considered.
</bodyText>
<sectionHeader confidence="0.935388" genericHeader="method">
8. Conclusion
</sectionHeader>
<bodyText confidence="0.99973904">
In situation recognition, the nodes
of a taxonomIc lattice structure serve as
rendezvous points where footprihts.from
various constituent elements of a concept
can meet. This facilitates the detection
of coincidences of rented events, which
in many cases will not be suggestive in
isolation. The implementation of the
Kinds of operations described above
involves a system of marker passing
conventions for propagating the various
&amp;quot;footprints&amp;quot; around the network, detecting
coincidences, creating instance nodes, and
propagating further markers when
coincidences are found. A major portion
of our current research involves the
discovery of effective conventions for
such marker passing operations Other
issues include working out conventions for
how far markers should propagate
(amounting to decisions at to where to
rendezvous), deciding how much information
a mark carries with it and to what extent
marks are inherited, developing ways to
allow a node to remember partial
</bodyText>
<page confidence="0.994519">
40
</page>
<bodyText confidence="0.9551225">
intersections of marks in such a way that
it can Incrementally extend them as
additional marks accumulate, identifying
implications of r the marker passing
strategies on representaEional
conventions, etc.
</bodyText>
<sectionHeader confidence="0.975415" genericHeader="method">
9. References
</sectionHeader>
<reference confidence="0.626956074074074">
Brachman, R.J: (1978)
&amp;quot;A Structural Paradigm for Representing
Knowledge.,&amp;quot; Technical Report No. 3605,
Bolt Beranek .and Newman Inc., Cambridge
MA.
Fahlman, S.E. (1977)
&amp;quot;A System for Representing and Using
Real-World Knowledge,&amp;quot; Ph.D. dissertation,
Dept. of Electrical Engineering . and
Computer Science, M.I.T.
Lowerre, B.T. &apos;(1976)
&amp;quot;The HARPY Speech Recognition System,&amp;quot;
Technical Report, Department of Computer
Science, Carnegie-Mellon University,
Pittsburgh, Pau
Quillian, M.R. (1966)
&amp;quot;Semantic Memory,&amp;quot; Report
No. AFCRL-66-189, Bolt Beranek and Newman
Inc., Cambridge, Ma.
Quillian, M.R. (1968)
&amp;quot;Semantic Memory,&amp;quot; in Semantic InformatiQn
Processim (M. Minsky, ed.). Cambridge,
Ma:Ki.J.T. Press., pp. 27-70.
Rieger, C. (1977)
&amp;quot;Spontaneous Computation in
Models,&amp;quot; Cognitive Science
pp. 315-,354. &amp;quot;
</reference>
<note confidence="0.634239666666667">
Wolf, J.J. and W.A. Woods (1977)
&amp;quot;The HWIM Speech Understanding System,&amp;quot;
Conference Record, IEEE International
Conference on Acoustics, Speech, ana
Lanai Processing, Hartford, Conn., May:
Woods, W.A (1970)
</note>
<table confidence="0.838289">
&amp;quot;Transition Network Grammars for Natural
Language&apos;AnalySis,&amp;quot; CACM, Vol. 13&amp;quot; No. 10,
October (reprints available).
Woods, W.A. (1973)
&amp;quot;Progress in Natural Language
Understanding: An Application to Lunar
Geology,&amp;quot; AFIPS Conference Proceeding,
Vol. 42e 1973 National Computer Conference
and Exposition (reprints available).
</table>
<reference confidence="0.9083314">
Woods, W.A., M. Bates, G. Brown, B. Bruce,
C.-Cook, J. Klovstad, J. Makhoul,
8. Nash-Webber, R. Schwartz, J. Wolf,
V. Zile (1976)
Speech Understanding Systems - Final
Report, 30 October 1974 to 29 October
1976, BBN Report No. 3438, Vols. I-V, Bolt
Beranek and Newman Inc., Cambridge, Ma.
Woods, W.A. r1977),
&amp;quot;Semantics and Ouantification in Natural
Language Question Answering,&amp;quot; to appear in
Advances in Coyiputers, Vol. 17, New York:
TETEFEUE Press. (Also Report No. 3687,
Bolt Berane and Newman Inc., 1977).
Woods, W.A. and R.J. Brachman (1978)
&amp;quot;Research in Natural Language
Understanding&amp;quot; - Quarterly Technical
Progress Report No. 1 (BAN Report
No. 3742), Bolt Beranek and Newman Inc.,
Cambridge, MA
</reference>
<figure confidence="0.9903738">
Cognitive
1, No. 3,
â€¢
â€¢
`11f- â€¢
RbLEP
0.4)17.1bf- :#1144&amp;quot;4
tEWEC1Eg
1104
#14411141
Aga 414MI-g
cur NA (46
c.roo.A
Wo.
ve;1
blfga0
DETERMS/4
e0Lef
EA
L.
</figure>
<figureCaption confidence="0.7172355">
waxtegurium
Fig. 1
</figureCaption>
<page confidence="0.956618">
41
</page>
<figure confidence="0.594943666666667">
Descripticai Mormation and Discourse Model Synthesis
Bonnie Lynn Webber
Bolt Beranek and Newman Inc.
50 Moulton Street
Cambridge MA 02138 &lt;*l&gt;,
vy
</figure>
<sectionHeader confidence="0.892893" genericHeader="method">
1. Introduction
</sectionHeader>
<bodyText confidence="0.953378">
definite anaphora &lt;*2&gt;
notion of reference into
model of the discourse,
[1976], Levin &amp; GaZdman
[1978]. Stenning [1975].
on definite anaphora
[1978a&amp;b]) follows this
particular making the
assumptions:
</bodyText>
<listItem confidence="0.803227">
1. One objective of discourse is to
enable a speaker to communicate to a
listener a model s/he has of some
</listItem>
<bodyText confidence="0.982614090909091">
situation. Thus the ensuing
discourse is, on one level, an
attempt by the speaker to direct the
listener in synthesizing a similar
model.
2. Such a discourse mddel can be viewed
as a structured collection of
entities, organized by the roles
they fill with respect to one
another, the relations they
partibipate in, etc.
</bodyText>
<sectionHeader confidence="0.549986" genericHeader="method">
3. The function of a definite anaphoric
</sectionHeader>
<bodyText confidence="0.973421388235294">
expression is to refer to an entity
in the speaker&apos;s discourse model
(DMs). &lt;*3&gt; In using a definite
anaphor, the speaker assumes
(a) that on the basis of the
discourse thus far, a similar entity
&lt;*l&gt;. The author&apos;s current address is:
Department of Computer and Information
Sciences, The Moore School, University of
Pennsylvania, Philadelphia PA 19174.
&lt;*2&gt;. Although I will soon explain what
mean precisely by &amp;quot;definite anaphora&amp;quot;, the
term basically denotes a function that
some types of syntactic expressions can
serve. Expressions which can function as
definite anaphors include definite
pronouns and definite descriptions. Other
roles that definite pronouns and
descriptions can fill are discussed in
Geach [1962], Partee [1972], Norman &amp;
Rumelhart [1975] and Webber [1978a].
&lt;*3&gt;. A similar assumption is made by
Karttunen [1976], Levin &amp; Goldman [19781,
Lyons [1978] and Stenning [1975].
will be in the listener&apos;s model
(DML) as well and (b) that the
lisEener will be able to access that
entity via the given definite
description or dennite pronoun.
4. The referent of a definite anaphor
is thus an entity in DMs, which the
speaker presumes to have a
counterpart in DML. Discourse
entities may have the properties of
individuals, sets, events, actions,
states, facts, beliefs, hypotheses,
properties, generic classes, typical
set members, stuff, tpecific
quantities of stuff, etc.
5. In deciding which discourse entity a
definite anaphor refers to, a
listener&apos;s judgments stem in part
from how the entities in DML are
described. (When a discourse entity
E is the referent of a definite
anaphor A, one might distinguish
that description of E conveyed to
the listener by the immediately
preceding text and consider it A&apos;s
antecedent.)
The point of making these assumptions
explicit is to stress that insofar as
reasoning about discourse entities is
mediated by their descriptions, discourse
entity descriptions are critical to
anaphor resontien.
Now one consequence of these
assumptions about discourse models and
reference is that the task of
understanding definite anaphora can be
decomposed into several complementary
parts:
1. deciding whether a definite pronoun
or definite description is truly
anaphoric (i.e., is intended to
refer to some entity presumed to
already be in DML) or whether the
term fills some other role in the
discourse;
2. synthesizing a discourse model which
is similar to that of the speaker
and inhabited by similar discourse
entities;
Many researchers in linguistics,
psychology, philosophy and artificial
intelligence have recently begbn to
abandon a purely linguistic approach to
in favor of a
some kind of
cf. Karttunen
[1978], Lyons
My own research
(cf. Webber
approach, in
following five
</bodyText>
<page confidence="0.991615">
42
</page>
<bodyText confidence="0.829416">
gr
</bodyText>
<sectionHeader confidence="0.529375" genericHeader="method">
3. constraining the possible referents
</sectionHeader>
<bodyText confidence="0.966762116666667">
of a given anaphoric expression down
to one possible choice - the
&amp;quot;anaphor resolution&amp;quot; problem;
4. determining what other functions a
definite description is intended to
fill besides enabling the listener
to construct or get to its referent.
While I cannot hope in this short
paper to cover even one of these four
sub-tasks, what I shall try to do is
illustrate how the explicit data - i.e.,
the actual sentences of the discourse,
produced by a particvlar person (or a
particular computer program) in a
particular situation - provide material
for the model synthesis process. In
particular, I shall show (1) how
Indefinite noun phrases are associated
with the evocation of new discourse
entities, independently of any
higher-level expectations, and (2) how
those new discourse entities will
initiallY be described. I will claim that
such an initial description (ID) is
critical to both model synthesis and
anaphor resolution since it aliows the
listener to reason appropriately. about the
discourse entity in order to asstgn it to
an appropriate role vis-a-vis his or her
higher-level expectations. &lt;*4&gt;
Moreover, since it is possible for a
discourse-entity&apos;s current role assignment
to be found incorrect, it is the entity&apos;s
ID that allows .it to bo re-assigned to
another role with respect to the
listener&apos;s revised expectations.
In Section 2 I will consider
indefinite noun phrases vis-a-vis the
ditcourse entities they evoke and how
those entities are described. I will
contrast them briefly with non-anaphoric
definite noun phrases and then show that
all determined noun phrases, including odd
ones like &amp;quot;few orc eggs&amp;quot;, &amp;quot;many lemon gum
balls&amp;quot;, etc. pattern after either
definites or indefinites vis-a-vis the
discourse entities they evoke and how
those entities can be described. In
Section 3 I will show how this approach to
definite anaphora in terms of aiscourse
entities and their descriptions can
accommodate certain problematic cases of
anaphoric reference that have been
discussed in the linguistics and
philosophic literatures - the famous
&amp;quot;donkey&amp;quot; sentence (cf, Bartsch [1976],
Edmundson L19761, Hintikka &amp; Carlson
[19771) and the problem of reference in
disjunctive contexts (cf. Karttunen
[1977]). Finally, to show that it is not
</bodyText>
<reference confidence="0.806583135135135">
&lt;*4&gt;. From different points of view,
discussions of the relationship between
the explicit text and higher-level
organizing structures can be found in
Collins, Brown &amp; Larkin [19771 and Webber
[1978b1.
just definite and indefinite noun phrases
that can evoke entities in the listener&apos;s
discourse model, I will illustrate in
SeCtion 4 an example of deictically-evoked
entities and comment on the problem of
describing them appropriately.
2m Indefinite Noun Phrases and Discoutse
Entities
Except after a copula, indefinite
noun phrases &lt;*5&gt; may evoke a new
discourse entity into a listendr&apos;s
discaurse model. &lt;*6&gt; What. I want to
focus on here is appropriate IDs for them.
Consider the following sentences.
is. Wendy beught a yellow T-shirt that,
Bruce had liked.
b. It cost twenty dollars.
2a. Each third-grade girl brought a
pelican to Wendy&apos;s house.
b. She is roosting them on her front
lawn.
3a. If Bruce manages to catch a fish,
W. he will eat it for dialer.
4a. John didn&apos;t marry a Swedish woman.
b. She was Norwegian.
5a. Whether Bruce buys a mini-computer
or an Advent TV,
b. he will have to do the repairs on it
himself.
6. Every man who owns a donkey beats
it.
</reference>
<bodyText confidence="0.985431966666667">
I claimeo earlier that the initial
description (ID) of a newly-evoked
discourse entity is critical for both
model synthesis and anaphor resolution,
since the ID mediates all reasoning about
the entity until its assignment to some
role within the model. An entity&apos;s IL%
should imply neither more nor less about
it than is appropriate. Now consider what
an appropriate description would be for
the discourse entity that &amp;quot;it&amp;quot; refers to
in sentence lb. It is not &amp;quot;the yellow
&apos;t&apos;-shirt that Bruce had liked&amp;quot;, since
sentence la. can be uttered truthfully
even if Bruce had liked several yellow
T-shirts (and both speaker and listener
were aware of that fact). Nor is it &amp;quot;the
yellow T-shirt that Bruce bad liked and
that Wendy bought&amp;quot;, since sentence is. can
&lt;*5&gt;. I will often refer to these as
&amp;quot;existentials&amp;quot; because of their logiCal
interpretation as existential quantifiers.
&lt;*6&gt;. An indefinite noun phrase following
a copula functions together with the
copula as a predicate, e.g.
Beverly is a bargain hunter.
Bruce became a librarian.
As such, it is purely descriptive and does
not refer to any particular, librarian or
bargain hunter, cf. Kdho [1970].
</bodyText>
<page confidence="0.8150765">
43
116
</page>
<bodyText confidence="0.879676230769231">
be truthfully &apos;uttered even if Wendy had
bought several sOch T-shirts. What is ah
appiqpriate description for the referent
of &amp;quot;it&amp;quot; is something like &amp;quot;the yellow
T-shirt that Bruce had liked and that
Wendy bought and that was mentioned in
sentence la.&amp;quot;
What I am claiming is that in the
case of a singular existential that is not
within the scope of either negation, a
universal quantifier, a hypothetical (e.g.
&amp;quot;if&amp;quot;, &amp;quot;suppose&amp;quot;) or one Of several other
special contexts (cf. Webber [1978a1), the
entity it evokes will be appropriately
described via a conjunction of (1) the
description inherent in the noun phrase
(e.g. &amp;quot;yellow T-shirt that Bruce had
admired&amp;quot;); (2) a predicate that embodies
the remainder of the sentence (e.g. &amp;quot;which
Wendy bought&amp;quot;); and (3) a predicate that
relates that entity to the utterance
evoking it (e.g. &amp;quot;which was mentioned in
(or evoked by) sentence 6a.&amp;quot;). This is
the description that I am calling the
entity&apos;-s &amp;quot;initial description&amp;quot; or ID.
Given how I specified its components then,
it should not be surprising that I will
claim that the ID of an
existentially-evoked., discourse entity can
be derived from an appropriately
structured sentence-level logical
representation. Such a representation is
independently motivated by its use in
regular inference procedures.
Using a somewhat simplified version
of the formalism described in Webber
[1978a], a simple rule can be stated for
forming the ID of an existentially evoked
discourse entity - i.e.,
</bodyText>
<equation confidence="0.785394">
(Ex:C) . Fx ==&gt;
(Ez) . z = ix: Cx &amp; Fx &amp; evoke Soc
</equation>
<bodyText confidence="0.994299210526316">
Here (Ex:C) is an example of restricted
quantification, in which C represents an
arbitrary predicate which x satisfies. Fx
represents an arbitrary open sentence in
which x is free; i stands for Russell&apos;s
definiti operator, iota; and S is the,
label assigned to the proposition on the
left-hand side of the arrow. Informally,
this rule, which I shall call [RW-1], says
that if a proposition S states that there
is a member x of class C which makes Fy
true, then there exists an individual
describable as &amp;quot;the C whic F&apos;s which was
evoked by proposition V% This individual
is taken to be the discoute entity evoked
by the existential noun phrase. For
example, let Y stand for the predicate
corresponding to &amp;quot;yellow T-shirt that
Bruce had liked&amp;quot;. &lt;*7&gt; Then sentence la.
can be represented simply as
&lt;*7&gt;. I will .soon be more precise about
the representation of relative clause
containing noun phrases. Here, where the
descriptive part of the noun phrase can be
treated as an unanalyzed unit, the
predicate name Y is an adequate
representation.
(Ex:Y) . Bought Wendy, ,,x
Since this matches the left-hand side of
the above rule, it follows that
(Ez) . z = ix: Y x &amp; Bought Wendylx
&amp; evoke Slay,:
That Is. there is an individual
describmiMe as &amp;quot;the yellow T-shirt that
Bruce had-liked, that Wendy bought and
that was evoked by sentence la.&amp;quot; The
discourse entity so- described is the
referent of &amp;quot;it&amp;quot; in sentence lb.
Examples &amp;quot;26 illusUate singular
indefinite noun phrases in some of the
special contexts noted above. While I
will only be discussing examples 5 and 6
in this paper, notice that in all five
cases, the entity evoked by the indefinite
noun phrase is appropfiataly described by
taking into account at least the three
factors mentioned above That is, in
example 2 the referent of &amp;quot;them&amp;quot; can be
described uniquely as &amp;quot;the set of
pelicans, each of which, mentioned in
sentence 2a., some third arade girl
brought to Wendy&apos;s house.. &lt;*8&gt; In
example 3, the referent of &amp;quot;it&amp;quot; can be
described as &amp;quot;the fish mentioned in clause
3a. that Bruce has managed to catch, if
Bruce has managed to catch a fish&amp;quot;. In
example 4, the negation appears intended
to scope only &amp;quot;Swedish&amp;quot;. Thus the
discourse entity referent of &amp;quot;she&amp;quot; can be
described as &amp;quot;the woman mentioned in
sentence 4a. that John married&amp;quot;. (We
later learn in sentence 4b. that she is
Norwegian rather than Swedish.) IDs for
the- two other existentially-evoked
discourse entities in examples 5 and 6
will be discussea in Section 3.
Notice that a definite noun phrase in
the same. context as an indefinite noun
phrase will also evoke a discourse entity,
but one whose ID is somewhat different.
To see this, consider the following
sentences
&lt;*8&gt;. A fule similar to [RW-1] is given
in Webber [1978a] for existentials scoped
by universaIe. In all, six such rules are
given covering
</bodyText>
<sectionHeader confidence="0.685219142857143" genericHeader="method">
I independent existentials (sg/pl)
&amp;quot;1 saw (a cat, three cats) on the
stoop.&amp;quot;
2, definite descriptions (sg/pl)
&amp;quot;I saw the [cat, catsi. which hate
Sam.&amp;quot;
3. distribuEives
</sectionHeader>
<reference confidence="0.985416545454545">
&amp;quot;Each cat on the stoop-hates Sam.&amp;quot;
&amp;quot;The three cats each scratched Sam.&amp;quot;
4. universally quantified existentials
&amp;quot;Each boy gave each girl (a peach,
three peaches).&amp;quot;
5. class dependent definites
&amp;quot;Each boy gave a woman he knew the
(peach, two peaches) she wanted.&amp;quot;
6. class dependent distributives
&amp;quot;Each boy I know loves every woman
he meets.&amp;quot;
</reference>
<page confidence="0.999337">
44
</page>
<bodyText confidence="0.987126325581396">
Wendy bought the yellow T-shirt that
Bruce Iilad liked.
It cost twenty dollars.
Eadh_third grade girl has seen the
pelican on Wendy&apos;s lawn-.
They prefer it to the plasttc
flamingo she had there before.
John didn&apos;t marry the Swedish woman.
He threw her over for a Welsh.
ecdysiast.
In each case, -an appropriate description
for the discourse entity evoked by the
singular definite noun phrase is just that
singular definite noun phrase itself
&amp;quot;the yellow T-shirt that Bruce had, liked&amp;quot;,
&amp;quot;the pelican gn WendYls- lawn&amp;quot;, &amp;quot;the
Swedish woman&amp;quot;. While it is certainly
true- that the definiteness of these noun
phrases may be contingent on context
(i.e., identifiability within the
speaker&apos;s model of the underlying
situation) nevertheless unlike entities
evoked by indefinite noun phrases, those
evoked by definites do not dePend for
their appropriate IDs on the particular
sentences the definite noun phrases
appeared in-.
The same characteristic behavior of
definites and indefinites. discussed for
singular noun phrases holds for plural
noun phrases as well. That is, while both
indefinite and definite plural noun
phrases evoke discourse entities, the
unique initial descriptions that can be
assigned to those entities will differ in
the two cases. To see this, consider the
following example.
I saw the guys from &amp;quot;Itiss&amp;quot; on TV
today.
I saw the three guys from &amp;quot;Kiss&amp;quot; on
TV today.
I saw all three guys from &amp;quot;Kiss&amp;quot; on
TV today.
I saw some guys from &amp;quot;Kiss&amp;quot; on TV
today.
saw three guys from &amp;quot;Kiss&amp;quot; on TV
today.
11. They were being interviewed by Dick
Cavett.
Sentences 10a-c each contains a definite
plural noun phrase. That noun phrase
should evoke a discourse entity into the
listener&apos;s model, one appropriately
described as &amp;quot;the (set of) guys from
This can be verified by
following either of these sentences by
sentence 11 and considering what is the
referent of the definite Pronoun &amp;quot;they&amp;quot;.
&lt;* 9&gt;
&lt;*9&gt;. While sentences. 1.0b&amp;c. provide the
additional information that the number of
guys in &amp;quot;Kiss&amp;quot; is three [not actually true
BLW], that information is not needed in
order to describe the set uniquely.
Sentences.10d&amp;e, on the Other hand,
eaCha contains an indefinite plural noun
phrase. That noun phrase will evoke a
discourse entity appropriately described
as &amp;quot;the (set&amp;quot;of) guys from &apos;Kiss,&apos; that I
saw on TV today and that was mentioned in
Sentence 10d(e).&amp;quot; This is because either
sentence is conskttent with there being
other members of &amp;quot;Kiss&amp;quot; whom I didn&apos;t see
on TV today, as well as other members whom
I did see but whom I don&apos;t mean to include
in my statement. &lt;*10&gt; Notice again,that
the set size information provided in
sentence 10e. is not necessary for
describing that set uniquely. However, it
too may be useful later in resolving
definite anaphora.
4n interesting point is that there
seem to be no other patterns that English
determiners follow vis-a-vis discourse
entity IDs. To see this consider the
following sentences.
</bodyText>
<reference confidence="0.987384">
12a. Few linguists smoke since they know
it causes cancer.
b. Few linguists were at the party, but
they drank more than the whole Army
Corps of Engineers.
13a. Many linguists smoke although they
know it causes cancer.
b. Not many linguists smoke since they
know it causes cancer.
c. Many linguists don&apos;t smoke since
they know it causes cancer.
</reference>
<bodyText confidence="0.998795125">
In sentence 12a, the referent of &amp;quot;they&amp;quot; is
the discourse entity appropriately
described as &amp;quot;(the entire, set of)
linguists&amp;quot;. That is, &amp;quot;few &lt;x&gt;s&amp;quot; can evoke
the same discourse entity as the definite
noun phrase &amp;quot;the &lt;x&gt;s&amp;quot;. However as
However, it should not be ignored, as it
may be needed later in resolving a
definite anaphor like &amp;quot;the three guys&amp;quot;.
&lt;*10&gt;. This latter point is a subtle one,
and usage may vary from person to person.
That is, some people intend an indefinite
plural noun phrase contained in a sentence
S &amp;quot;Some &lt;x&gt;s P&amp;quot; - to refer to the
maKimal set - i.e., &amp;quot;the set of &lt;x&gt;s which
P&amp;quot;. Other people intend it to refer to
some subset of that set - &amp;quot;the set of &lt;x&gt;s
which P which I (the speaker) intended to
mention in sentence S. For a system to
cope with this variation in usage, it
would be better for procedures to derive
the latter, non-maximal set description,
which is always appropriate. If a system
is sophisticated enough to associate a
&amp;quot;belief space&amp;quot; with the speaker (cf. Cohen
[1978)), other procedures can later access
that belief space (if necessary or
desirable) to judge whether the maximal
set interpretation might have been
intended. (This will again become an
issue wheh I discuss) other determiners
like &amp;quot;many&amp;quot; and &amp;quot;several&amp;quot;.)
</bodyText>
<figure confidence="0.998284333333333">
7a.
b.
8a.
b.
9a.
b.
</figure>
<page confidence="0.952998">
45
</page>
<bodyText confidence="0.992262769230769">
(,Ig
sentence 12b. shows, &amp;quot;few &lt;x&gt;s&amp;quot; can also
pattern after the indefinite plural: the
referent of &amp;quot;they&amp;quot; is the entity
appropriately described as &amp;quot;the
just-mentioned set of linguists who were
at the party&amp;quot;. (We learn from &amp;quot;few&amp;quot; that
this set is small or smaller than the
speaker expects.)
&amp;quot;Many&amp;quot;, on the other hand, seems to
pattern only after the iridefinite plural.
In sentence 13a..J the referent of &amp;quot;they&amp;quot;
is appropriately described as &amp;quot;the
just-mentioned set of linguists who
smoke&amp;quot; (We learn from &amp;quot;many&amp;quot; that this
set of linguists is large or larger than
the speaker expects.) Sentence 13b. shows
that the reverse polarity &amp;quot;not many&amp;quot; acts
like &amp;quot;few&amp;quot; vis-a-vis evoking discourse
entities: the referent of &amp;quot;they&amp;quot; is the
entire set of linguists. However a%
sentence 13c. shows, a NEG which occurs in
the sentence auxiliaty does not effect
this same change in behavior: &amp;quot;they&amp;quot;
refers to the just-mentioned set of
linguists who don&apos;t smoke.
</bodyText>
<sectionHeader confidence="0.983328" genericHeader="method">
3. Two Interesting Reference Problems
</sectionHeader>
<bodyText confidence="0.999971684210526">
Recall that the purpose of this paper
is to point out the importance of
description formation to both discourse
model synthesis and reference resolution.
and to show that this process can, to an
important degree, be formalized. I have
taken as given the notion that a listener
is using both the discourse and his or her
knowledge of the world to synthesize a
model of what s/he believes to underlie
the discourse. Definite anaphora are
viewed as means by which the speaker
refers to entities in DMs that are
presumed to have counterparts in the
listener&apos;s model. What I want to show in
this section is that this approach to
definite anaphora can accommodate not only
straight-forward cases as discussed above,
but certain problematic cases as well.
</bodyText>
<subsectionHeader confidence="0.974159">
3.1 Parameterized Individuals
</subsectionHeader>
<bodyText confidence="0.936971428571429">
The problem of formally
characterizing the referent of &amp;quot;it&amp;quot; in
examples like 6 below has often been
discussed in the linguistics and
philosophy literatures cf. Bartsch
[1976], Edmundson (1976], Hintikka &amp;
Carlson (1977].
</bodyText>
<sectionHeader confidence="0.916675" genericHeader="method">
6. Every man who owns a donkey beats it.
</sectionHeader>
<bodyText confidence="0.998321083333333">
The problem has been taken to be that
while &amp;quot;it&amp;quot; intuitively seems -related to
the embedded noun phrase &amp;quot;a donkey&amp;quot;, there
is no way to represent this logically in
term g of simple quantifier scoping. 4What
I shall show is that an approach in terms
of discourse entities and their IDs makes
chis intuitive relationship simple both to
explain and to represent.
First notice that this problem arises
independently of how the matrix Â° noun
phrase is determined.
</bodyText>
<reference confidence="0.987112">
14. A man I know who owns a donkey beats
it.
15. The man who owns a donkey beats it.
16. Which man who owns a donkey beats
it?
17. No man who owns a donkey beats it.
</reference>
<bodyText confidence="0.995730976190476">
In all these examples, &amp;quot;it&amp;quot; seems
intuitively related to &amp;quot;e donkey&amp;quot;.
Informallyk one might describe its
referent as &amp;quot;the just-mentioned donkey he
owns&amp;quot;, where &amp;quot;he&amp;quot; is bound to whatever
value that &amp;quot;(each, a, the, which, no) man
who owns a donkey&amp;quot; may take. But this is
just a discourse entity of a rather
special type - one with a parameterized
ID, rather than a xigid one. I call such
entities &amp;quot;parameterized individuals&amp;quot;,
borrowing the term from Woods &amp; Brachman
(1978]. &lt;*11&gt;
Notice that parameterized individuals
behave somewhat differently from tho
&amp;quot;actual&amp;quot; discourse entities the sentences
evoke. &lt;*12&gt; That is, parameterized
individuals all have the same ID,
independent of how the noun phrase
containing the relative clause is
determined, On the other hand, the actual
discourse entities evoked by these
sentences do not. For example,
18a. Each man who owns a donkey beats it.
it = the donkey he owns
b. However, the donkeys are planning to
get back at them.
the donkeys = the set of lonkeys,
each of which some man
who owns a donkey owns
them = the set of men, each of whom
owns a dorikey
19a. Ie man I know who owns a donkey
beats it.
it = the donkey he owns
b. But the donkey is planning to get
back at him.
the donkey = the just-mentioned
donkey that the man I
know who owns a donkey
owns
him = the man I know who owns a
</bodyText>
<sectionHeader confidence="0.736861" genericHeader="method">
donkey
</sectionHeader>
<reference confidence="0.866034916666667">
20a. Which man who owns a donkey beats
if?
&lt;*11&gt;. The. phrase &amp;quot;parameterized
-individual&amp;quot; is being used somewhat loosely
to include &amp;quot;parameterized&amp;quot; sets, stuff,
etc. For example,
(i) No man who owns two donkeys beats
them.
them = the two donkeys he owns
&lt;*12&gt;. By &amp;quot;actual&amp;quot; discourse entities, I
mean ones that can be referred to
anaphorically in subsequent sentences.
</reference>
<page confidence="0.999264">
46
</page>
<bodyText confidence="0.939012260869565">
it = the donkey he owns
-- &amp;quot;None&amp;quot;
b.wAre the donkeys planning to get back
at (him, them, ???}?
the donkeys = ???
c.*Is the donkey.planning to get back
at Olin, them, ???)?
the donkey = ???
To show that this approach to
definite anaphora in terms of discourse
entities aqd their descriptions can
explicate &amp;quot;donkey&amp;quot; sentences as well, I
will have to introduce a bit more of the
formalism described in Webber [1978).
That bit involves an extension of
restricted quantification, cf. [RW-1]
above. In restricted quantification, a
quantification operator (e.g. V,E),1 the
variable of quantification and the class
it ranges over (noted implicitly as a
predicate) constitute a structural unit of
the representation. For example, &amp;quot;Every
boy is happy&amp;quot; can be represented as
</bodyText>
<figure confidence="0.974187285714286">
(Vx:Boy) . Happy x
This is truth functionally eqdivalent to
sat
(Vx) . Boy x ==&gt; Happy x
Similarly &amp;quot;Some boy is happy&amp;quot; can be
represented as
(Ex:Boy) . Happy x
</figure>
<figureCaption confidence="0.4834055">
which is truth functionally equivalent to
(Ex) . Boy x &amp; Happy x
</figureCaption>
<bodyText confidence="0.998439818181818">
The extension I will introduce will
permit the vtpresentation of noun phrases
with relate clauses as well as simple
noun phrases. Semantically, a relative
clause can be viewed as a predicate. One
way to provide for arbitrary predicates is
through the use of the abstraction
operator, represented as &amp;quot; &amp;quot; by Hughes &amp;
Cresswell [1968], following Church [1941].
For example, the nouns phrase &amp;quot;a peanut&amp;quot;
can be represented as
</bodyText>
<subsectionHeader confidence="0.818028">
(Ex :Peanut)
</subsectionHeader>
<bodyText confidence="0.999791">
while the noun phrase &amp;quot;a peanut that Wendy
gave to a gorilla&amp;quot; can be represented as
</bodyText>
<sectionHeader confidence="0.7098092" genericHeader="method">
(Ex: )(u:Peanut)[(Ey:Gorilla)
Gave Wendy,u,y])
In this case
)(u:Peanut)[(Ey:Gorilla)
Gave Wendyfuey]
</sectionHeader>
<bodyText confidence="0.898492102941176">
names a unary predicate which is true if
its argument is a peanut that Wendy gave
to some gorilla.
Using this notation, sentence 6 can
be represented as
(Vx: Mu:Man) [(Ey:Donkey) . Own upy])
Beat xrIT
By applying rule [RW-1] to the embedded
clause [(Ey:Donkey) . Own u], the entity
evoked by the existential can be
identified as
iy: Donkey.y &amp; Own uly &amp; evoke S6 11u
&amp;quot;the just-mentioned donkey that u owns&amp;quot;
&lt;*13&gt;
As I mentioned above, the semanticg of
restricted quantification is such that the
variable of quantification, here x,
satisfies the predicate in the
restriction. Thus if lc satisfies
1(u:Man)[(Ey:Donkey) . Own u,y], there
must be an entity identifiable as
iy: Donkey y &amp; Own xly &amp; evoke S6 py
&amp;quot;the just-mehtioned donkey x owns&amp;quot;
This is a parameterized individual -
parameterized by the variable in (Vx:...)
- that is a possible referent for &amp;quot;it&amp;quot; in
the matrix sentence - i.e.,
(Vs4)t(u:Man)[(Ey4Donkey) . Own ury])
Beat x, iy: Donkey y &amp; Own &apos;cry
&amp; evoke S6 1,y
&amp;quot;Very man who owns a donkey beats the
just-mentioned donkey-he owns&amp;quot;
I noted above that a sentence like
&amp;quot;Every man ,who owns a donkey beats it&amp;quot;
could sensibly be followed by a sentence
like &amp;quot;However, the donkeys are planning to
get back at them&amp;quot; (cf. example 18). Given
that I have shown how to account for the
referent of &amp;quot;it&amp;quot; in the first sentence in
terms of discourse entities and their
formally derivable descriptions, can the
referent of &amp;quot;the donkeys&amp;quot; be account for
in the same way? &lt;*14&gt;
To show that it can, I need to
present the rule for dealing with class
dependent definite descriptions that X
mentioned in footnote 8. This rule is
motivated by examples such as 21, where
the referent of &amp;quot;them&amp;quot; is presumably t0e
discourse entity evoked by the noun phrase
&amp;quot;the flower she picked&amp;quot;, -.where &amp;quot;she&amp;quot;
stands for the variable bound by &amp;quot;each
girl in the class&amp;quot;.
&lt;*13&gt;. In labeling each clause of a
complex sentence, I use the following
convention: if the matrix clause is
labelled S, its leftmost embedded clause
Will be labelled S.1, the leftmost
embedded clause in Si will be labelled
5.1.1, etc.
&lt;*14&gt;. I shall not take the time here to
discuss the path 4com the phrase &amp;quot;every
man wh-o owns a donkey&amp;quot; to the discourse
ehtity informally describable as &amp;quot;the set
of men, each of whom owns a donkey&amp;quot;, since
it is rather straightforward, cf. Webber
[1978a]. This entity is a possible
referent for &amp;quot;them&amp;quot; in sentence 18b.
</bodyText>
<page confidence="0.998569">
47
</page>
<reference confidence="0.919714">
21a. Each girl in the class gave Ivan the
flower she picked.
b. He arranged them artfully in an
empty Glenfiddach bottle.
</reference>
<bodyText confidence="0.9994081">
This is a definite noun phrase, but
because of its binding to the
distributively quantified noun phraSe
&amp;quot;each girl&amp;quot;, it will evoke a discourse
entity with the properties of a set rather
than an individual (cf. example 8). In
this case, it will be &amp;quot;the set of flUwers,
each of which was the flower that some
girl in the class picked&amp;quot;. Simplifying
for brevity here, this rule can be written
</bodyText>
<equation confidence="0.687304">
(Vx:K) . P xviy:C xly ==&gt;
(Ez) . z = (ul(ExrK) . u = iy:C x,y)
</equation>
<bodyText confidence="0.99924672">
where K represents an arbitrary unary
predicate which lc satisfies and both P and
C represent arbitrary binary predicates.
The right-hand side of this rule implies
that in case the left-hand side matches
some sentence, there will be a discoUrse
entity roughly describable as &amp;quot;the set of
u&apos;s, each of&apos; which is the thing that
stands in relation C to some member of K&amp;quot;.
Notice now that after the. &amp;quot;it&amp;quot; is
resolved in &amp;quot;Every man who owns a donkey
beats it&amp;quot; (see above), the sentence
matches the left-hand side of the above
rule - i.e., &amp;quot;Every man who owns a donkey
beats the just-mentioned donkey he owns.
Thus it follows that there is a discourse
entity describable as &amp;quot;the set of donkeys,
each of which is the just-mentioned donkey
that some man who Qwns a donkey owns&amp;quot; -
i.e.,
{wI(Ex:)(u:Man)[(Ey:Don-key) . Own Lily])
w = iz: Donkey z &amp; Own xrz
&amp; evoke S18,z)
This is a possible referent for &amp;quot;them&amp;quot; in
sentence 18b.
</bodyText>
<subsectionHeader confidence="0.986129">
3.2 Disjunction
</subsectionHeader>
<bodyText confidence="0.997953333333333">
The other class of problematic
examples that I want to discuss here in
terms of discourse entities and their
descriptions is one I first encountered in
Karttunen [1977]. Karttunen presents
examples like the following.
</bodyText>
<reference confidence="0.980959727272727">
22. Lf Wendy has a car or Bruce has a
bike, it will be in the garage.
23. Bruce can have either a bike or a
car, but he must keep it in the
garage.
24. Either Bruce has a new car or he has
borrowed his brother&apos;s. In any
case, it is blocking my driveway.
25. Whether Bruce buys a car or his
brother buys a bike, he will have-to
keep it in the garage.
</reference>
<bodyText confidence="0.88634">
The problem is again to determine just
what it is that &amp;quot;it&amp;quot; refers to.
I see two ways of approaching this
problem in terms of atcourse entities and
their IDs. One way holds that in each
sentence, each term of the disjunction
evokes a different discourse entity into
DML, each with a different ID:
</bodyText>
<reference confidence="0.944307625">
(22) &amp;quot;the car that Wendy has (if she has
a car)&amp;quot;
&amp;quot;the bike that Bruce has (if he has
a bike)&amp;quot;
(23) &amp;quot;the bike that Bruce will have (if
he chooses a bikeY&amp;quot;
&amp;quot;the car that Bruce will have (if he
chooses a car)&amp;quot;
(24) &amp;quot;the new car that Bruce has (if
Bruce has a new car)&amp;quot;
&amp;quot;Bruce&apos;s brother&apos;s car&amp;quot;
(25) ?the car Bruce will have bought (if
he buys a car)&amp;quot;
&amp;quot;the bike Bruce&apos;s brother will have
bought (if Bruce&apos;s brother buys a
bike)&amp;quot;
</reference>
<bodyText confidence="0.998651625">
The truth of the disjunction (which seems
in each case to be interpreted as
exclusive &amp;quot;or&amp;quot;) then guarantees there
being one and only one entity in the model
to which &amp;quot;it&amp;quot; refers. Notice that if the
terms were conjoined rather than
disjoined, the truth of the conjunction
would imply the simultaneoils existence of
two entities within the model. In that
case, either the referent of &amp;quot;it&amp;quot; would be
ambiguous or the sentence would just be
bizarre.
The other, I think nicer, way of
approaching the problem holds that each
sentence evokes only a single discourse
entity into the model, with the indecision
(i.e., the disjunction) embodied in its
ID. That ID is of the form &amp;quot;A if P,
otherwise B&amp;quot;. For example, the entity
evoked by sentence 22 would be describable
as &amp;quot;the can that Wendy has (if she hassa
car) or the bike that Bruce has
Qtherwise&amp;quot; that evoked by sentence 23
Would be describable as &amp;quot;the bike that
Bruce will have (if he chooses a bike) or
the car that Bruce will have otherwise&amp;quot;;
that evoked by, sentence 24, as &amp;quot;the new
cer that Bruce has (if he has a new car)
or Bruce&apos;s brother&apos;s car otherwise&amp;quot;; and
that evoked by sentence 25, as &amp;quot;the car
Bruce will have bought (if he buys a car)
or the bike Bruce&apos;s brother will have
bought otherwise&amp;quot;.
One advantage to this approach is
that additional properties which
truthfully follow from either ID can be
ascribed to the entity without committing
oneself to one description or the other.
This can be useful in anaphor resolution.
For examine, in sentence 24, the subject
</bodyText>
<page confidence="0.998998">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.859028">Journal of Computational Linguistics 78</note>
<title confidence="0.979736">LANGUAGE REPRESENTATION</title>
<author confidence="0.995514">DAVID L WALTZ</author>
<author confidence="0.995514">EDITOR</author>
<affiliation confidence="0.999147">Coordinated Science Laboratory4 University of Illinois</affiliation>
<address confidence="0.984078">Urbana 61801</address>
<abstract confidence="0.89047675">Papers presented it-two sessions of TINLAP-2, the 1978 Meeting of the Associatiou for Computational Linguistics, held with joint sponsorship by the Association for Computing Machinery and its Special Interest Group in Artificial Intelligence.</abstract>
<note confidence="0.998641">Copyright Q 1978, 1979</note>
<title confidence="0.674709">Association for Computing Machinery Association for Computational Linguistics TABLE OF CONTENTS</title>
<author confidence="0.589467">M W W I U Pi</author>
<note confidence="0.852659666666666">Session 1 Language Representation and Psychology EL LL CC 0-</note>
<title confidence="0.584564666666667">Testing the Psychological Reality of a Representatiob Model Dedre Gentner 1 3 What Makes Something &amp;quot;Ad Hoc&amp;quot; 8 10</title>
<author confidence="0.992518">Roger C Schenk</author>
<pubnum confidence="0.45704">Relation of Cognition--a Synopsis 14 16</pubnum>
<title confidence="0.3672255">Leonard Talmy On Primitives Prototypes, and Other Semantic AnomalLe9 25 27</title>
<author confidence="0.886129">Terry Winogard</author>
<phone confidence="0.229096">Tanonomic Lattice Structures for Situation Recognition 33 35</phone>
<author confidence="0.956392">William A Woods</author>
<note confidence="0.6575005">Session 2 Language Representation and Reference Formation Model Synthesis 42 44</note>
<author confidence="0.951264">Bonnie Lynn Webber</author>
<note confidence="0.657672">The Processing of Ftkferring Expressions within a Semantic Network 51 83 R. Reference Diaries 57</note>
<author confidence="0.955983">Catherine Marshall</author>
<phone confidence="0.218608">Subsequent Reference Syntactic and Rhetorical Constraints 64 66</phone>
<author confidence="0.995707">David D McDonald</author>
<affiliation confidence="0.816024">Some PsycHolinguistio Constraints on the Construction and Interpretation of Definite</affiliation>
<address confidence="0.720133">Descriptions 73</address>
<author confidence="0.951217">Andrew Ortony</author>
<note confidence="0.701505666666667">Bound Variables and Other Anaphors n 81 Barbara H. Partee ... Use of Focus as for Disambiguation of Definite Noun Phrases 86 87</note>
<author confidence="0.698812">Candace L Sidner</author>
<degree confidence="0.336839">Testing The Psychological</degree>
<title confidence="0.6888795">of a Representational Model Dedre Gentner</title>
<author confidence="0.80772">Bolt Beranek</author>
<author confidence="0.80772">Newman Inc</author>
<abstract confidence="0.999569646153846">A research program is described in which a particular representational format for meaning is tested as broadly as possible. this format, developed by the LNR research group at The University of California at San Diego, verbs art represented as interconnected sets of subpredicates. These subpredicates may be thought of as the almost inevitable inferences that a listener makes when a verb is used in a sentence. They confer a meaning structure on the sentence in which the verb is used. To be psychologically valid, thee representations should capture (at least) Similarity The more similar two verbs seem in meaning to people, the more their representations should overlap. 2 Confusability The more confusable two verb meanings are, the more their representations should overlap. 3. Memory for sentences containing the verb up by the verb&apos;s meaning should in part determine the way in which sentences are remembered. 4. Semantic integration representations should allow the integration of information from different sentences into discourse structure 5 Acquisition patterns The structural partitions in the representations should correspond to the structures children acquire when they are learning the meanings of the verbs 6. Patterns of extension The representations should be extendible so as to reflect the ways in which people interpret verb meanings when the verbs are used outside their normal context. times The time taken to comprehend a sentence using a given verb should reflect the structural complexity of the verb meaning. Experiments concerned with predictions 1-5 are described here. The results are for a general approach representation of meaning in terms of interrelated subpredicates, but do not clearly distinguish between several similar representations. For example, to test prediction (2), I read people sentences containing verbs with similar meanings, and asked them to recall the sentences. The deipwe of overlap in the semantic structures was a good predictor of the number of confusions between sentences. In another sentence-memory experiment (prediction (3)), semantically compldk verbs that provided more underlying interconnections between the nouns in a sentence led to better memory for the in the sentence than genera&amp; verbs, or than other complex verbs that did not provide such extra interconnections, To test prediction (5), I tested children&apos;s zomprehension of a set of possession verbs. Both the order of acquisition among the verbs kinds of errors fitted well with an account of the acquisition of verb meaning in terms of interconnected subpredicates. research illustrates a approach to testing a representation. In the breadth-first approach, many different psychological predictions are made. area of prediction requires a set process assumptions, and in each case the process assumptions used are those that seem plausible given previous research field. If one representational format can make correct predictions about a number of different kinds of psychological phenomena, then that representation stands a greater chance of being generally useful than one which was tested in only one depth-first way. This paper describes a program of research that tests a representational format for verb meaning. This research grew out of the LNR (Footnote 1) attempt to the represent the Meanings of words in a psychologically satisfying way. Verb meaning seemed a natural place to start for two reasons: (1) verbs are important: it is arguable that they provide the central trganizing semantic structures in sentence meanings; and (2) verbs are their more easily analyzed than those. of, for example, common nouns. Since different disciplines look at in different it may be worthwhile to describe the stance we took. What we wanted was a system of representation in which we could capture our intuitions about what a word typically conveys; or more specifically about the inferences a person normally makes (or believes should be =vie) when a word is used. The assumption is that the same representations operate when a person uses the word in speech as when the person comprehends it; however the methodology of experimental psychology makes it naturel to spend more time pondering the input process than the output process. This differs from thinking of meaning in terms of necessary and sufficient truth-conditions, as philosophers done, or from thinking about Meaning in generation rather than in comprehension, as many linguists have done. Each of those stances leads to useful intuitions. Overall, there has been reassuring degree of convergence between the representations proposed. Representation of Verb Meaning. There are many notational systems for representation .of verb meaning</abstract>
<address confidence="0.711684666666667">1975, Chafe, 1970; Fillmore, 1975, Lakoff, &amp; Levin, 1975,</address>
<abstract confidence="0.993738174664109">models of verb meaning differ from One another in detail, but there widespread on the idea that vero meanings can be represented in terms of interrelated sets of. subpredicates, such as CAUSE or aHANGE. These subpredicates are not merely eoncatenated within a word&apos;s representation. Rather, they are in Representations of verb meaning include notation for specifying the relationships among the &apos;Subpredicates that make up a word&apos;s meaning. The notation developed by the LNR Group is a network format. In this system of representation, verb meanings are expressed in terms of subpredicates that stand for changes of eta. Elements of Ver P Meamiln,g.Verbs provide a system in which people can talk about happenings in the world, implicitly distinguishing several types of conceptual possibilities. The simplest of these is the Ptate. A. stative predicate conveys a relationship that endures for a period of time between two arguments, normally an object (or person) and an object or value within the conceptual field specified by the stative. For example, consider the sentence shown in Figure 1. owned a Cadillac from 1970 to verb ownconveys that a relationship of possession misted between Ida and the Cadillac for some civration. Besides statives for possession there are a large number of statives, including location be._ at, re:n.4112_0,etc.) and emotion hate,to love, etc.). In addition to simple stative relationships, verbs can be used to convey changes tof state. Following Chafe (1970) I refer to a change of state as a process. For example, the sentence Ida receives $10.00. tells us (1) that Ida now has $10.00 (2) that someone else had the $10.00 before, (3) that a change has taken place from this previous state of possession to the present state. More commonly, verbs express not simple changes of state but causal changes of state. We seem to be very interested in processes that are volitionally caused by humans and ether sentient beings. Figure 2 shows the representation of the sentence Ida gives Sam a rose. An agent nay cause a change of state that relates to another object. Or the same person may act on both agent and experiencer of the of state. The lotational verb movecan be used in either way, as in the following examples a. Ida moved the car. b. Ida moved to the front seat. In both these cases the action taken by Ida is unspecified. We often don&apos;t care exactly what someone did to cause some process to occur. However, there are also verbs in which the causal action is partially or wholly e.g., walX,saunter, meander, stride,rya, sprint,Nice,trot,jpg. (See Miller (1972) and Miller &amp; Jonnson-Laird (1976) for a more extensive discussion of the verbs of location.) Thus, this system allows for the representation of verbs as states, changes of state, causal changes of state. simple actions, and complex cases in wfflen specific cause changes Further discussion of the LNR sysbem of verb semantics be found in the articles Gentner, Munro, Rumelhart &amp; Levin, and Rumelhart &amp; Norman in the Norman &amp; Rumelhart (1975) volume. There aPe certainly gaps in the system, and aspects of verb meaning that are not expressible in this simple vocabulary. Some unresolved issues are discussed later in the paper. However, the system seems plausible at the arst level, and allows a fair range of verb meanings to be captured at least roughly. it At this point in the research it staged to testing the psychological rightness of the system as so far stated before going on to refine it. EiushalagisaLkaitats1.11sJiadia. One advantage of psychological (or of is that one to make explicit the assumptions &apos; representation and process. At least some of made can then be tested as Some assumptions are a verb&apos;s captures the set of immediate inferences that people normally make when they hear or read a general, one verb leads to many inferences (3) these networks of meaning components are accessed during comprehension, by an immediate and largely automatic process (4) the set of components associated with a given word is reasonably stable across cbntexts (5) surface memory for exact words fades quite rapidly, so that after a short time, only the representational network remains. In testing these representations, I took a very literal interpretation of &apos;the notion of representation -namely that the nodes and arrows in a representation correspond to the concepts and relatiOnships that are stored when a person comprehends a sentence containing a verb. The more ferociously literal the intet.pretation, the better the chances of discovering counter-evidence. overlap.One psychological criterion ip that the representations should agree with people&apos;s intuitive notions of synonymity and Similarity in meaning. One straightforward measure of this overlap is the degree to which people rate verbs as similar in meaning. In a study of about 60 verbs, I found that people&apos;s average rating of the semantic similarity between two verbs agreed very closely with the degree of overlap representations. A more subtle measure of psychological similarity is the degree to which people unconsciously confuse things in memory. sentence-memory experiment try to keep their sentence clear. But, suppose that within a short time after hearing a verb in a sentence, a person has only the representational network of concepts and relationships, and not the verb Assume some pieces of the memory representation may be lost or unaccessible at any time ithe &amp;quot;fallibility of assumption). the more two verb representations overlap, the more likely is that sentences containing the two will be confused in demory, despite people&apos;s attempts to keep them straight. In experiment in sentence memory, using verbs of varying semantic overlap, I found that subjects did indeed confuse the verbs in exactly the way predioted by the theory 1974). The the of confusions made two and the semantic between the as predicated the representations, was quite high. In fact, the between representational overlap and number of confusions was slightly higher (though not significantly so) than the correlation between the number of confusions and the rated similarity between the vorbs. (The similarity ratings were taken from the first-mentioned with a different set complexity.Semantic complexity refers to the number of underlying subpredicates and intercObnections that...make up the basic meaning of a verb. More complex meanings correspond to mores specific actions events. For example, stri4is more than meaning contains more subpredicates. We know more having heard sentence (a) than sentence (b). (a) Ida strode across the field. (b) Ida went aeross the field. Various researchers have looked for evidence that semantic complexity may affect comprehensibility,, generally on the apsumption more complet structures harder to process (Kintsch 1974; Thorndyke, 1977). However, the results have negative. There is no evidence that more complex words lead either to longer reaction-times or be greater processing loads than do simpler words.. I believe&apos;tbat it&apos;s incorrect to assume across the beard that complexity is psychologically hard. Some research of mine suggests that the effects of complexity particular. Complexity Although the view that semantic complexity leads to difficulty has not been supported, is another side to the The additional semantic components in a verb may additional connections among the nouns in the sentence. In case, more _complex verbs should lead to a richer and more highly interwoven sentence and thus to bettermemory for the nouns in the sentence. Notice that this prediction derives Mel a fanatically literal interpretation of tire verb representations: more paths in the representation means more conceptual paths in memory. This prediction is quite specific. It is not simply a question of certain complex versus simple verbs having some overall effect, but rather of complex verbs providing extra connections between the particular nouns in question. This is clearly true for Ida and tenants in the case of se1,1versus gill, can be seen in Fig 3b. tested for this kind of improvement in connectivity in a series of experiments in (Gentner, 1977). I react sentences that differed in the of tpeir pair of Ida gave her tenhnts a clock. (simple) Ida sold her tenantb a clock. (complex connective) I gave the names of the characters and asked them to recall le sentences. As predicted, they were better to recall the noun tenantswhen the complex connective verb eell. was used then the verb was used. More connections between tie led to stronger memory connections. zee the specificity prediction, consider a complex verb that mereiy amplifier simple verb and duss natadd condectiont between the key nouns. For example, the vert 30) adds the information that the of transfer mailing or some such long-distance transfer. Using mail leads to more inferences (a more specific event than using give.However, knowledge that the object was mailed leads to few, if any, additional connections betwpeM agent, Igieâ€ž, and the recipient, tenants. Therefore, the predicttori was that use of such non-connecting specific verbs would lead to no improvement over use ol general verbs in memory between the nouns. The results were exactly as predicted The object nouns of complex connective verbs were recalled better than those of general verbs and non-connecting complex verbs. These differences were not traceable to differences in imagery or word-frequency. Thus connectivity is beneficial to sentence metory in a very specific way. Acauisition.There may be a more direct relationship between complexity and difficulty in children than in adults. Young children often fail to comprehend the full meanings of semantically complex terms (e.g., Bowerman, Clark, 1973,Gentner, 1975, in press). Working with the verbs of possession, I have observed that childrpn act out the simple giveand takecorrectly before they act the more complex verbs Duy. and trade. Still later they learn the yet more complex gall and anend.The order in which the verbs are learned is exactly the order of increasing semantic complexity. This complexity ordering can be made quite precise, since the verbs are closely related in meaning. The representation of a verb at the nth level of simplicity is properly nested within the representation of a verb at the (n+1)th level. Further, when children around years are apked to act out sell(as in &amp;quot;Make Ernie sell Bert a boat.&amp;quot;) they act out giveinstead (A boat is transferred from Erne to Bert). Similarly, Dux is acted out ad take.They systematically act out complex verbs like simple verbs; and more surprisingly, they choose the appropriate simple verb. My interpretation, consistent Clark&apos;s semantic features analysis, is that children learn these complex meanings gradually, by adding to their partially correct representations. At any given time, the child comprehends language in terms of the Pomponents that he has so far acquired. Integration.Another important psychological requirement is combinability. The basic notions&apos;of state, change of state, tause, and so on must be combinable into networks larger than the individual sentence. When two verbs share parts of their underlying structure. this redundanpy should be utilized to combine the two representations into onp discourse structure. How can we test whether this happens? One way is to arrange things so that collapsing the redundancies between two verbs should create the representation of a third verb. Then the prediction is that people should usa this third verb in recall. In a study of semantic integration, I read people short passages and tested their memory by having them fill in blanks (Gentner, 1978). Every passage contained a general dlich as give.Half the passages also contained additional semantic information, as the fact that the giver actually the money he was giving. According to representational model, the integration of the of givewith that of have created the structure of people is ineir minds after hearing the verbs is the network representations, and if these representations are integrated during discourse comprehension, then people who heard giyeand oweshould end up with the representation of eim. As predicted, subjects nearing the extra material falsely recalled the verb which best fit the composite structure (e.g. rather than the actually presented. Further Ipsges I have dhde the assumption that a verb carries with it a set of inferences that are normally made during comprehension, as well as several supporting assumptions. This view has been fairly well supported by the research here, but seems to me an &apos;oversimplification. There remain a great many questions, some large and some small. Where should the line around a word&apos;s meaning? As Clark and Clark (1977) have put it, is word meaning more like a dictionary or an encyclopedia? The extreme of the dictionary approach would be to take a minimal contrast approach, storing with a word only enough to distingulsh it from all other words. The extreme of the encyclopedia approach would be to access the entire long-term memory whenever any word is used. The question is, how to define a reasonable middle ground. (2) What ism the process of expansion into a semantic representation during comprehension? a) Are there invariable inferences?. When an incoming word is processed, is there a set of inferences (such as the set I have called the &amp;quot;almost-inevitable Inferences&amp;quot; that is always made during comprehension, or is there variation in which inferences get made? 6 If there is it quantitative or qualitative? Do context and the person&apos;s interests and attention wirichinferences get made, so that there are qualitative .differences in what inferences get made? Or is the difference merely quantitative, with the radius of expansion varying with the amount of attention (or energy, or interest) that the persod brings to bear? The notion of at least quantitative variation a seems haftt to avoid. It is fairly strong intuition that we process word meanings with varying degrees of energy the phenomenon of (Anderson, RC., Stevens, K.C., Shifrin, Z., &amp; Qmborn, J. 1977) makes it clear that a model of sentence comprehension must allow for qualitative differences in the final set of inferences stored. For example, compare sentences Rover ate his dinner. Mr. Pritchard ate his dinner. verb vastly different action sequences when used with different agents, though its causal change-of-state structure remains more-or-less constant. It is possible that this qualitative variation can be accounted for by simple underlying quantitative processes spreading activation. may have to settle more complex model, in which some parts of a verb&apos;s meaning are almost always accessed while other inferences develop out of the interaction of the verb with its context, including its pragmatic context. In Hewitt&apos;s (197b) terms, there may be both if-added inferences and if-needed inferences. Where in this model (and whether) we want to draw a line between meaning and knowledge-of-the-world is not at all clear to me. (3) Carrying the notion of variable werb mean4ng still further, how does metaphorical extension work? Most common verbs can be used in several related ways. For example, consider the range Of meanings givecan convey depending on the nbuns it is used with Ida gave Sam a rose a job. an heir. an excuse a talking to. all his best ideas. the time of his life. Clearly the subpredicate structure varies across these sentences, so much so that some want to describe this as of entirely different senSes of the same word. This misses the structural similarities. Some kind of metaphorical extension of meaning seems a necessary part of a theory of verb meaning, since it is generally the verb that does most of the adjusting. A series of studies by Albert Stevens and me suggests that people faced with an odd sentence assume that some of the subpredicates normally conveyed by the verb are not meant to apply in the sentence at hand A current project is to model the rules for which subpredicates apply in different contexts. (4) I have so far treated nouns as nodes in the semantic representation. Clearly in order to analyze sentence interactions it is necessary to have a representation of noun meaning. Some progress been made with nouns, such as terms. But the truly nounlike nouns ---basic-level resist I that these differences in amendability to analysis reflect differences in the kind of meaning that verbs and nouns have, and that a useful representation of concrete noun meaning may be different that for verbs, and even abstract (5) There are several aspects of the representational scheme that need further To out issue, consider the notion of change of state. The LNR representation represents a verb like get,_ as conveying a change from an initial state of to a final possession. Schank&apos;s Conceptual Dependency theory would represent the entire sequence as a primitive Many semanticists have represented only the inchoative part of the (the change to final state) as belonging to the assertion of the verb, consi.dering the initial state to be more in the nature of a vresupposition (e.g. Fillmore, 1966). All these positions seem to me to have The LNR use of change from initial state allows a change-of-state verb hook automatically with relevant state information. The use of acts as primitives captures the psychological wholeness of change. Thq use of the inchoative captgres the intuition that people seem more interwated in the results of an event --i.e. in the final than in the explicit change-of-state formats (LN A format and inchoative format) have a natural way of Capturing some kinds of metaphorical extension by substituting a different stative preserving tte of verb&apos;s structube. Summary This work is just beginning. Neither the representations nor the processes that are assumed 0 operate on them come very close to capturiqg the subtlety of human language use. the results of the investigation are promising some kind of decompositional model along these lines. t expenencer Â°bled from-time to-time / \ Ida Cadillac 1970 1977 Figure 1. Ida owned a Cadillac from 1970-1977. VERB (FEW CONNECTING Figure )c. event result .. â€¢ ....** E \ E-.. â€¢ \I II . -, ..* Ida clock tenants &apos;... Ida .. clock tenants i â€¢ â€¢ .. mailed her tenants a ... ....... Iootnote Agent from to Ida rose Sap Figure 2. Ida gives Sam a rose. Ida gave her tenants aclock horn W 0 O. E Ido clock GENERAL VERB (FEW CONNECTING PATHS) Figure 3a. her tenants a clock The was developed IIN a group of researchers at the</abstract>
<affiliation confidence="0.4169245">at San Diego: Abrahamson, James A.</affiliation>
<address confidence="0.392386">Levin, Stephen E. Palmer, and David E.</address>
<note confidence="0.970068333333333">Rumelhart. The system is explained in detail &amp; Rumelhart, 1975. Experiencer Event Result 4&apos; CONTR , â–  Act 1 ..&apos; \ Act 2 , El E2â– </note>
<abstract confidence="0.756957285714286">Ida tenants Result Result tenants : E Ull Of E $ money .. tenant!, SPECIFIC VERB (MANY CONNECTING PATHS) Figure 3b. References Abrahamson, A.A. Experimental analysis of tne semantics of movement. In D.A. Norman, &amp; D.E.</abstract>
<note confidence="0.877629647058824">(Eds.), in Cognition. San Francisco: W.H. Freeman &amp; Co., 1975. Anderson, R.C., Stevens, K.C., Shifrin, Z., &amp; J. of &apos;Word Meanings in 1977. E.H. analysis of general vocabulary&apos;: The semantic strudture of a set xerbs 10,EnCish, Hipdl, and Japanese.The Hague; Mouton, 1966. Bowerman, M. The acquisition of word meaning: An investigation of some current conflicts. Paper presented at the Third International Child Language Symposium, London, September 1975. W.L. ,and the structure of language.Chicago: Press, 1970.</note>
<abstract confidence="0.731303466666667">E.V. in a On the child&apos;s acquIsition of semantics in â€¢ his first In T.E. Moore (Ed.), development andthe acouisition of language, York: Academic Press, H.H. &amp; Clark, E.V. and LAligalLt. New York: Harcourt Brace Jovanovich, Inc., 1977. C.J. Review of Bend x&apos;s vocabularv: The semantic and Japanese. International Journal of 32, Part II, No. 2. Publication 41. Gentner, D. Towards a psychological theory of meaning possession verbs.</abstract>
<affiliation confidence="0.942003">Unpublished dqctoral dissertation, University California, San Diego,</affiliation>
<address confidence="0.607614">iorman, D. A., Rumelhart, D.E. &amp; 019 LNR</address>
<abstract confidence="0.72524384">lesearch Group. Explorations in cognition. 3an Francisco: W.H. Freeman &amp; Comparly, 1975. iumelhart, D.R. &amp; Levin, J.A. A language 3omprehension system. In D.A. Norman &amp; D.E. cognition,San W.H. Freeman &amp; Co., Schank, R. Conceptual Dependency: A Theory of Language Understanding, 1972, 552-631. khank, R.C. The structure of episodes in memory. In D. Bobrow &amp; A. Collins (Eds.), and New York: &apos;ress, L. structures in Wtglish and Atsugewi.Unpublished doctoral dissertation, of California, _Berkeley, Thorndyke, P.W. Cognitive structures in comprehension and memory of narrative labhologv,1977, 94 77-110. &apos; if Gentner, D. reality of possession. Rumelhart, Francisco: Evidence for the psychological semantic -components: The verbkof In -D.A. Norman and &apos;D.E. FALlacatAcns_jaQgniljai, &apos;San W.H. .Freeman &amp; Co., 1975. Gentner, D acquisition Development . On relational meaning: The verb meisning. , in press.</abstract>
<note confidence="0.610770888888889">Gentner, D. Semantic meanings Volt Beranek 3826, Centet for the Study Report. integration of word and Newman Inc. Report Also to appear as a of Reading Technical Hewitt, C. Viewing control structures as patterns of passing messages. M.I.T. Al Working Paper 92, 1976. G. an modal Indiana University Linguistic6 Club Reprint. Bloomington: Indiana University Linguistics Club, 1970(a). G. and amntax.New York: Holt, Rinehart and Winston, 1970(c), The role of semantics in E. Bach and R.T. Harms (Eds.), lax......mla_ln_lingztWroa. New Yoric and Winston. 108(b). McCawley, J.D. grammar. In &apos;ye Holt, Rinehart.</note>
<title confidence="0.61452">What &apos;Makes Something &amp;quot;Ad Hoc&apos;</title>
<author confidence="0.933239">C Roger</author>
<affiliation confidence="0.9936515">Yale University Department of Computer Science</affiliation>
<address confidence="0.983897">New Haven, Conn. 06520</address>
<abstract confidence="0.995622619365611">0 Only one of the questions posed before this sespion really inspires me to take pen in hand. &amp;quot;How general are various formalisms? Are they really ad hoc solutions to relatively narrow domains?&amp;quot; That is not exactly my ravorite question. I find the thought of having to address it palatable only if I can delude myself into believing that this is the last time I shall have to deal with it So, proceeding on the basis of that delusional belief, I shall begin. Ad Hocness, I nave come to delieve, is a disease that all new theories in the three fields in which I consider myself well-versed, namely linguistics, psychology and Intelligence, contract at conception, sort of like original sin This would not be so bad if it were a disease for which there were a cure, but alas there is none. We are all familiar with the phrase &amp;quot;beauty is in the eye of the beholder.&amp;quot; In this case we have an instance of &amp;quot;the disease is in the eye of the beholder&amp;quot; which of course explains why the cure is so elusive. The beholder rarely wants to do anything about it. To discuss this more subjectively, let&apos;s take a neutral case. doing so, wg shall have to point out what a case can be expected to look like. A case of &amp;quot;ad hocness&amp;quot; usually fits the fam (or should I say the &amp;quot;ad hoc&amp;quot; form) Theory X is called &amp;quot;ad hoc&amp;quot; by group *ith rival theory Y The research described in this paper was supported by the Advanced Research Projects Agency of the Department of Defense and monitored by the Office c:Nf Naval Research under contract N00014-75-C-1111. get to our neutral case, we shall discussion where X is Conceptual Dependency and Y is Transformational Generative Grammar. Before I begin, I should note that there are conditions on X and Y relative to each ether, namely that X must a theory that has at a date later than Y was conceived s Furthermore Y should have been ,dominating some academic field which X is seeking to invade. What makes a theory X assailable by Y as ad hoc? There are a number of criteria: 1 x must explain a phenomenon that Y chose to ignore and that Y would rather go on ignoring since I could not possibly explain it. 2 - X must be fundamentally at variance with Y, so that if X were right Y would be necessarily wrong. 3 - X must Liae different criteria of judgment of how a phenomena should be explained than Y does. The following rules are used for the strategy to be followed in labelling an X as ad hoc: 1 - Since X will undoubtedly show how its theory explains a given particular phenomenon, accuse X s theory of only working in that case. This will put the burden proof for generality on X rather than Y and also has the desirable effect of puttini X in the position of not being able to prove anything with out proving everything. 2 - Choose a phenomenon to explain in which It is virtually impossible to explain everything, thus giving game and set to Y. Consider our hypothetical case Where Conceptual Dependency is X and Tranformational Grammar is Y. An examination of the literature will show-that criteria I through 3 as well as the two available strategies have been used by the Transformationalists. In various articles and public performances charges of &amp;quot;ad hocness&amp;quot; have ii been raised against Conceptual Dependency. We are told that our structures only work for the examples we discuss, that we have &amp;quot;no principled way of going from a sentence to a conceptyalization&amp;quot; (Dresher and Hornstein (1976)) or that &amp;quot;Shank provides no demonstration that his scheme is more than a collection of heuristics that happen to work on a specific class of examples&amp;quot; (Weizenbaum (1976)). (If the reader is wondering how Weizenbaum got to be a transformationalist in my view, he need only read s extolling Chomsky as having met the criteria that he chants I have not met.) TO what extent are these charges valid? To not knowing if one can extract a conceptualization from any sentence (and its corroborating charge of not proving that there exists a right Cl) diagram for any sentence) I plead guilty. But of course, I would be less than completely honest if I did not also note that there does not exist any theory or theorist Who would not also have to plead guilty. Have the transformationalists shown us that they have some principled way of extracting conceptualizations from sentences or determining the correct representation for any sentence? Unless they are keeping their solution as a secret not to until after the election, I would have to imagine that the answer to this is that they do not have a solution to the problem. So clearly, they are no more or less ad hoc than we are. (Of course I might note here that we have programs that suggest that we can do a large class of examples and show that our parsers are at least the beginning of some set of principles that work, but I won t). What about Weizenbaum s attack? Perhaps it is all heuristics. To this charge I plead no contest. It might be that, in the end, we will have built a working program that solves the entire natural language problem and it will be easily labelled as a grand set of heuristics. Won&apos;t that be terrible! To quote Dresher Hornstein again, &amp;quot;Not only has work in Al not yet made any contribution to a scientific theory of language, there is no reason to believe that (AI)...will ever lead to such theories&amp;quot;. And what will they say after success has been achieved and the ultimate natural language system has been designed? The same thing of Chomsky himself (personal communication) has that such an achievement would be no interesting than the achievement of the 16th century clockmakers. I mention all this in the hope of pointing out that it is not just me and my theories that are damned by criticisms of ad hotness. We are all damned by them. Our ultimate success would not be even recognize&amp; much less applauded by Who criticize as ad hoc. Suppose every domain we worked on required yet ad hoc solution. This might well be case after all. What would we lose if this happened? Nothing at all. That $ What artificial intelligence is all about. Al is the designing and testing of theories about human understanding capabilities. There is, at the moment, no reason to believe that people solve puzzles the way they newapapers or play chess the way Of Course, we all hope there exist some general mechanisms solve all these problems in some neat way. We hope this in large part because we are lazy. We would not like to have to work on each problem We aiso because we believe our intuitions When they tell us how reading a newspaper is a lot like watching a soap opera. A word of caution is necessary here. of our As child you learned to do each of separately and were pained to deal with each one of them. Of course, we do expect there to be some general principles that apply across domains., But if these principles are affix â€” hopping or trace â€” deletion we are all in trouble. Part II Having said all this, now let me tell you what I actually believe. I do not believe that of our theories are ad hoc. because CD needed to be modified by causal chaining rules, and those by scripts and those by plans and goals and themes, and those by triangles, does not mean that what we are doing is ad hoc. We are no more ad hoc in hypothesizing our primitive elements than chemists were in hypothedzing theirs. I do know ultimate result will be. How many elements make up the correct number, or what other kinds of formalisms will need to be added to those listed above is still unknown. I. do know how Al does its research however. build a program to do small class of examples and when we are finished we rip it apart and build a bigger and better program to do larger examples. so doing, hoc entities called kludges) cannot survive. If a formalism does not keep handling more data it is either abandnsed or moved down to a special purpose role within a larger program. Well, in ten years of research by my research group what has survived? After ten years and probably a hundred different kinds of programs, Conceptual Dependency is still with us. It still works for us. I challenge any other theory that has been programmed to say the same! Is it ad hoc? I leave that as an exercise for the reader. PART III Just to give the reader a feel for the nature of ad hoc thinking in Al that I believe to be worth espousing, I will now consider a problem that I have recently been working on. We have had a problem in representing certain kinds of political concepts in our old representation. Since we have been very concerned with the problem of newspaper story understanding it is very important that we be able to handle such concepts in a clean representation that will facilitate computer understanding. The problem we are attempting to solve can be illustrated by looking at a recent New York Times headline &amp;quot;Catawba Indians land claim supported.&amp;quot; The problem here is to be able to represent what &amp;quot;land claim&amp;quot; and &amp;quot;supported&amp;quot; mean. We know that a land claim is more than What we might use to 12. represent it in Conceptual Dependency. Something like &amp;quot;Indians MTRANS land be possessed by Indians&amp;quot; is possibly true, but it misses the point. A &amp;quot;land claim&amp;quot; is in a sense a petition to 4 higher authority to resolve a dispute between two parties. That is, the Indians are saying to the U.S. Government, &amp;quot;this land is ours&amp;quot;. It may not be possible to infer the particulars of this land claim. Indians have been known to take the land by force, to&apos;file documents in government offices, to Complain to newsmen and so on. The important point here is tHht we really need not know, and in most cases a reader would not bother to worry about, exactly which method has been selected. Rather, a reader feels that he understands such a sentence when he has been able to identify the relationships and aims of the parties involved. A program must recognize that a &amp;quot;land claim&amp;quot; is a type of petition to a higher authority to resolve a dispute about land ownership. We do not know who presently owns the land, but we know enough about ownershio of property to infer that there is probably a counter petition of some sort. We also know about petitions to authority. They usually get resolved by the authority. In this case then, &amp;quot;supported&amp;quot; refers to the decision of the authority in the case. This information can be represented graphically by a kina of triangle (example 1) AUTHORITY Catawba Indians (a) In this triangle (a) represents the dispute between the Indians And the owners of the land, (a) represents the appeal to authority to resolve the dispute nade by the Indians, and (c) represents the authority&apos;s decision. of this sort use in representing any type of dispute. (2) and (3) such triangles For example, in can also be constructed (2) Burma appeals to UN to settle border dispute with Thailand. UN Thailatd (3) John complained to Bill&apos;s mother that Bill hit him. Of course, these triangles just suggest the basic relationships involved. In order to add substance to the bare bones of the triangles we shall have to deal with some representational issues that are being glossed over here. The important point at this juncture is that there is an essential similarity across (1), (2) and. (3), that the similarity must be represented in some way, and that that similarity can be exploited for use in an understanding system. The first representational problem we encounter in trying to make explicit much of what is implicit in the triangle representation is that we will need to design a new set of ACTs to take care of the various relationships. In the primitive ACTs of Conceptual Dependency we have a system that represents physical actions by using a small set of basic actions that can combine in various ways to describe detailed or complex actions that underlie seemingly simple account for intentionality and goals underlying physical adtion. To account for such things we devised a complex apparatus discussed in Schenk and Abelson (1977). If we wish to account social events, we will need a system of basic social ACTs to represent the social actions that comprise the events. I term these &amp;quot;basit social ACTs&amp;quot; rather than primitive ACTs because in the end most social ACTs have some physical manifestation4. Often their physical manifestation is uninteresting however. For example a government decision may be MTRANS-ed in a variety ways. The manner of the (written, a9nounced in a speech, etc) is often not significant with respect to the overall social effect of the action. Furthermore the MTRAFS Itself is only slightly interesting. The standard inferences from MTRANS apply, but there are some highly significant inferences that need to be made that are not obviously available. For example, the most significant inference to be made from an authority&apos;s decision is that simply by virtue of that decision something has actually happened- That is, a government authorization is a truly performati4e ACT. Thus, if the government says some property is mine, or that a man-is a criminal, then it is so by virtue of their saying it. Similarly other authority figures have the same power. A professor can say a thesis is finished and a student has a Ph.D. and these things are the case by virtue of his saying it. Not all authority&apos;s decisions are like this to be sure. Sometimes an authority gives an order and that order must be carried out for the decision to have effect. Frequently these orders come about as 4 result of a governmental decision or authorization. If the government says the land belongs to the Catawba Indians, then it does, but they may have to send in the National Guard to get the original owner off the property. Other Burma Bill&apos;s Mother What I am proposing then is two basic social ACTs - AUTHORIZE (abbreviated AUTH) and ORDER. AUTH is something only an authority can do. (This is a bit circular actually since if you actually can AUTH deftnes as authority.) John In a sense then, an authority is one Who When he acts like he is doing an AUTH (that is he does the physical ACTs that ordinarily correspond to an AUTH) in fact causes some things to happen as a result of the AUTH that were supposed to be the results of the AUTH. In other words, you cannot tell if an AUTH has taken place until clear that the person doing the AUTH back up his AUTH in some way.). The object of the AUTH is the authorization or new state of ehe world. AUTH takes a recipient, namely relevant parties in the dispute. ORDER is a frequent inference of AUTH. The government can AMR the army to fight a war, bur doesn&apos;t, simply by virtue of statement, that are it. A subsequent required that with it the implicit punishments that are relevant in carrying out an order. Why can t we do these things with CD primitives we now have? What is the advantage of new ACTs? To answer these questions, need to look at the purpose of a primitive ACT. is possible to represent ORDER for example. The verb &apos;order&apos; means to MTRANS to someone that they must do a particular action or Lace some (usually implicit) conseqoence. Thus, implicit in the verb &apos;order&apos; but in the PD representation for &apos;order&apos;, is the idea if the required ACT is not someone will possibly do something to harm the recipient of the order in some way. This implied punishment is a part of the concept &apos;order&apos; but is It necessary that we think of it each time that we understand an order to have taken place? The same question can be asked with respect to authorize . We understand What authorization or governmental decision is, but we need not access all that information each time we understand the word. Consider the problem of explaining the meaning of these words to a child for example. It is very difficult to explain them precisely because they are so complicated at the level of physical primitive ACib Yet these ideas a social ACTs. Such concepts such as ORDER and AUTHORIZE form the basis of the organization societies. What is complex at one level simple at another. This idea of nested levels of complexity, each with their own set of primitives, is a very important one for the representation of information in artificial intelligence. choosing a good set of primitives we can effectively organize what we need to know. Thus, ORDER and AUTHORIZE have inferences that come from them just as the physical primitive ACs do, The main difference is that these basic social ACTs are not primitive in the same sense. They can be broken down but we would rarely choose to do so. The use of these new basic ACTs is much like the original primitive ACTs. We can predict what will fill slots reasonably in a conceptualization and make inferences about slot and consequent as we would any conceptualization. Thus we represent sentences such as the following using AUTH The decided segregation is illegal. 0 R people of S.C.â€¹..&gt;AUTH&lt;---segrtgation&lt;---IU. S. (5) The cop gave the speeder a ticket. drive ---&gt;driver ---&lt;govt. money govt. In (4) we have chosen to ignore representing segregation for the moment, since it is obviously complex. Supreme Court decisions are AUTHs. They also carry with them (as do most AUTHS) an implicit ORDER for &apos;punishment&apos; if certain circumstances are not met straightforward inference from (4) then is that someone practicing segregation tan expect to be punished. Policemen are authorities also. In (5) the ticket is a written manifestation of an AUTH that either puts the driver in a DEFENDANT role in a $TRIAL script or forces him to pay a fine. The instrument of the AUTH is the actual PTRANS of the ticket (left out here). The important point here is that we could represenv (5) using PTRANS only. However, what we would be describing is the physical ACT itself when it is the social ACT that significant here. (When I was there much talk of bad kids getting &amp;quot;JD cards&amp;quot;. I never understuvd what was so horrible about that. Couldn&apos;t they just throw them away?) The social significance of an ACT must be represented if it is understood. that we have presented two let&apos;s return to our triangle AUTH (///\ , (followed by a possible ORDER) DISPUTE The ACT PETITION represents an individual or group&apos;s act of requesting AUTH&apos;s from an authority. Thus a &amp;quot;civil suit&amp;quot; is a PETITION to the courts using some legal scripts. A protest demonstration is a PETITION to unstated We have named one side of the triangle. The other sides represent ACTs as well. The complete triangle is as follows 0 driver V $TRIAL &amp;DEFENDANT It, using demonstration The point here is that we cannot do away with the scripts that describe the actual physical of events. However, the are instruments of social ACT â€” PETITION. The most important inference from PETITION is, of course, that an AUTH is expected will resolve that is the object of the PETITION. is the object PETITION the DISPUTE itself. DISPUTE actors orwhom may be quite passive). object of the DISPUTE is the issue involved. DISPUTE takes no recipient as it is not an inherently directed ACT. It is the ACT of PETITION that directs it to a particular authority who can AUTH something that will resolve it. We are now ready to deal with sentence (1) (Catawba Indians Land Claim Supported). The using the new ACTs is &lt;0?) /\ other ---&gt;US or U. S. &lt;=&gt;AUTH&lt;--(OWN(land)&lt;=&gt;Indians)1 Since this representation is not as easy to write as the triangular one, We shall continue to triangles in the remainder paper. Thus (1) is U.S. Gov&apos;t. OWNS(land)&lt;=&gt;Indians Indians Other OWN(land)&lt;=&gt;? We will leave out the arrows and the ACTS for diagrammatic purposes, but the above triangle should be understood as containing all the information given in the CD diagram for (1). (Actually the triangles contain more imformation.) provide a method for representing the social significance of actions. As with any other representation scheme, the advantage of the symbols we create can only be in the new symbols or actions that they spawn. is, it is the inferences that come from the triangles that are of key importance. When we created the original primitive ACTs we said that PROPEL was no more than the set of inferences that it fired off. The same it true here, so we must ask what these inferences are. The first thing we can recognize about potential inferences here is that they will come fh two varieties. The first are the inferenced that are fired off from the new social ACTs that we have created. The second kind are those that come from the triangles themselves. That should of triangles. that are for the triangles they spawn as as a set of inferences that come from the fact that certain triangles exist. Aq examples of this let us consider again sentence (2) (2) Burma appeals to UN to settle border dispute with Thailand. Since the representation of (2) involves a PETITION we can employ the inference rules that are fired by PETITION. Some of these are a. For every PETITION we can expect corresponding AUTH. b. For every PETITION there was probably. DISPUTE that gave rise to it. These rules lead us to the inferences available from AUTH and DISPUTE. Of course., inferences from have a lower probability of truth, for (2) the inferences below would be somewhat less certain. c. An AUTH con cause a DISPUTE to end. d. An AUTH can cause a PETITION to a higher authority from the party unfavorably affected by the AUTH. An unfavorable AUTH can cause a rebellion, lacK of acceptance of the validity of the AUTH. This can give rise to ORDERs to effect the AUTH in the case of individnals versus governments or wars in the case of goveillmental conflicts f. An AUTH causes a new state of the world to exist, often ending an old state in conflict with the new state. g. A DISPUTE can cause one party to PETITION. h. A DISPUTE can cause a PROPEL to cause damage to occur for individuals, or a WAR triangle to be initiated for countries. are, of course, a great many more of kinds of inferences than we are listing here. The list is mostly to give the flavor of basic social ACT inferences. It is important to note that the social ACTs jgive rise to of the other levels of representation besides those at the same level of That is, given ACT may be able to infer another social ACT, a new primitive ACT, or a new triangular representation. Thus, for (2) we have two representations to start with one is at the standard CD level uses MTRANS, the other is at the social level and uses PETITION. Both of these representations would be available as output from the parser. The MTRANS representation would fire off inferences about the methods of communication possibly used that the UN now knows about the problem and so on. The PETITION representation would fire off inferences about the expected AUTH from the UN. Since we know how the UN does its AUTHS, this would fire off a UN script of some kind that dealt with voting and debate. PETITION would also cause DISPUTE to be inferred which would cause inferences about the kind of methods possibly employed by the quarreling countries, both in creating the DISPUTE and escalating it. The existence of the PETITION-AUTH-DISPUTE triangle would fire off an inference that the country kind of triangle existed. Thus, a new triangle that was lopsided showing possible aggression from Thailand towards Burma would be created. This triangle would in turn fire off about attempts RESOLVE the DISPUTE (one of which was (3) itself) and would predict an escalation towards the WAR triangle with its normal inferences if a RESOLVE did not take place. Although the above is rather sketchy, the point should be clear. We need additional representational mechanisms to handle the many levels at which statements can be interpreted. Triangles provide us with a new set of inference rules providing more power to the understanding system. Are they ad hoc/ Of course they are. My point is simply that such ad hoc mechanisms will either solve the problem or help us create a more solution will the problem. The that we are writing triangles is also ad hoc. Is is a kludge? No. If it were it wouldn&apos;t be worth a thing. But, here again % if the program we write can handle many examples as we rewrite it because of What we have learned from it, then it will hay been worthwhile. The program below reads newspaper headlines in English and generates, by use of triangles and the inferences available from triangles, a paraphrase of the input. This English paraphrase is generated by the program. TRIANGLE analyzer loaded.</abstract>
<note confidence="0.925031304347826">INPUT SENTENCE (CATAWBA INDIAN LAND CLAIMS SUPPORTED) (PARSE II) CON4 Expanding token CON4 = (CON ((ACTOR (*PP* CLASS (1/GROUP) CFEATURE (*AMERINDIAN*) TYPE (*ETHNIC*) NAME (CATAWBA) TOK NPI) .&lt;=&gt; (*PETITION*) OBJECT ((ACTOR (*PP* CLASS (#REGION) TOK NP2 REL CON1) IS (*OWN* VAL NPI)) TOK CONI) FROM NPI TO (*PP* CLASS (I/INSTITUTION) MEM *COURT* TOK NP3)) TOK CON2) lk ((ACTOR NP3 &lt;=&gt; (*AUTH*) OBJECT CON1 RECIP1 NPL RECIP2 GAP1 FROM CON3)) TOK CON4) Catawba asked a Federal Court to rule that they own the land. The Catawba Indians requested a Federal to rule that the land by them. The Catawba Indians appealed to a Federal Court. The Catawba Indians asked a Federal Court</note>
<abstract confidence="0.849686266666667">to rule that they own the land and it the land is owned by them. [ Generating inferences from CON4 ] &gt;(TELL -STORY) The Catawba Indians and the other parties ownership of the land. The Catawba Indians requested a Federal Court to rule that they own the land. A, Federal Court decided theft the land is owned by the Catawba Indians. The other parties will probably appeal the decision. The other parties might use force against the Latawba Indians to assert that they own the land.</abstract>
<note confidence="0.921236428571429">This program was written by Jaime Carbonell and Stephen Slade. References Dresher, B.E. and Hornbrein, N. [1976] On some supposed contributions of artificial intelligpnce the scientific study of language, Cognition, Ichank, R.C. and Abe].son, R.P. [1977], Scripts, Goals and UnderstandingAn Inquiryinto nowledgeStructures, Lawrence Erlbaum Associates, Hillsdale, New Jersey. J., [1976], ComputerPower and Reasoninp,W.H. Freeman and Company, San Francisco. 13</note>
<title confidence="0.991214">The Relation of Grammar to Cognition--a Synopsis</title>
<author confidence="0.7570535">Leonard Talmy Program in Cognitive Science Center for Human Information Processim</author>
<abstract confidence="0.999426535714286">A sentence tor other portion of discourse) is taken to evoke in the listener a meaning complex, here called a &amp;quot;cognitive representation&amp;quot;. The lexical elements of the sentence, to simplify, by and specify the content of the cognitive representation, while the grammatical elements specify its structure. Thus, looking systematically at the actual notions specified by grammatical elements can give us a handle for ascertaining the very makeup of (linguistic-) cognitive structuring. We accordingly examine a number of grammatically spec Tied notions, observe the categories and systems in which they pattern, and speculate on broader cognitive connections. Some provisional findings have already emerged. Grammatical specifications for structure are preponderantly relativistic or topological, and exclude the fixed or metrically Euclidean. The categories in which grammatical notions pattern idtlude: ,plexity perspectival mode of boundedness level state of dividedness level of exemplarity degree of extensionality axial characteristics pattern of distribution scene-breakup &amp;quot; Grammatical specification&apos;of structuring appears to be the same, in certain abstract characteristics, as the structuring of visual perception.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A A Abrahamson</author>
</authors>
<title>Experimental analysis of tne semantics of movement. In</title>
<date>1975</date>
<publisher>W.H. Freeman &amp; Co.,</publisher>
<location>San Francisco:</location>
<contexts>
<context position="6699" citStr="Abrahamson, 1975" startWordPosition="1016" endWordPosition="1017">mental psychology makes it naturel to spend more time pondering the input process than the output process. This approach differs from thinking of meaning in terms of necessary and sufficient truth-conditions, as many philosophers have done, or from thinking about Meaning in generation rather than in comprehension, as many linguists have done. Each of those stances leads to useful intuitions. Overall, there has been a reassuring degree of convergence between the representations proposed. Representation of Verb Meaning. There are many notational systems for representation .of verb meaning (e.gâ€ž Abrahamson, 1975, Chafe, 1970; Fillmore, 1971, Genther, 1975, Lakoff, 1970; McCawley, 1968, Rumelhart &amp; Levin, 1975; Schenk, 1972, 1975, Talmy, 1975). These models of verb meaning differ from One another in detail, but there is widespread agreement on the idea that vero meanings can be represented in terms of interrelated sets of. subpredicates, such as CAUSE or aHANGE. These subpredicates are not merely eoncatenated within a word&apos;s representation. Rather, they are interrelated, in specific ways. Representations of verb meaning include notation for specifying the relationships among the &apos;Subpredicates that ma</context>
</contexts>
<marker>Abrahamson, 1975</marker>
<rawString>Abrahamson, A.A. Experimental analysis of tne semantics of movement. In D.A. Norman, &amp; D.E. Rumelhartg (Eds.), Explorations in Cognition. San Francisco: W.H. Freeman &amp; Co., 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Anderson</author>
<author>K C Stevens</author>
<author>Z Shifrin</author>
<author>J Osborn</author>
</authors>
<title>Instantation of &apos;Word Meanings in C4-aintl,</title>
<date>1977</date>
<marker>Anderson, Stevens, Shifrin, Osborn, 1977</marker>
<rawString>Anderson, R.C., Stevens, K.C., Shifrin, Z., &amp; Osborn, J. Instantation of &apos;Word Meanings in C4-aintl, May 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W L Chafe</author>
</authors>
<title>Meaning ,and the structure of language. Chicago:</title>
<date>1970</date>
<publisher>University of Chicago Press,</publisher>
<contexts>
<context position="6712" citStr="Chafe, 1970" startWordPosition="1018" endWordPosition="1019">makes it naturel to spend more time pondering the input process than the output process. This approach differs from thinking of meaning in terms of necessary and sufficient truth-conditions, as many philosophers have done, or from thinking about Meaning in generation rather than in comprehension, as many linguists have done. Each of those stances leads to useful intuitions. Overall, there has been a reassuring degree of convergence between the representations proposed. Representation of Verb Meaning. There are many notational systems for representation .of verb meaning (e.gâ€ž Abrahamson, 1975, Chafe, 1970; Fillmore, 1971, Genther, 1975, Lakoff, 1970; McCawley, 1968, Rumelhart &amp; Levin, 1975; Schenk, 1972, 1975, Talmy, 1975). These models of verb meaning differ from One another in detail, but there is widespread agreement on the idea that vero meanings can be represented in terms of interrelated sets of. subpredicates, such as CAUSE or aHANGE. These subpredicates are not merely eoncatenated within a word&apos;s representation. Rather, they are interrelated, in specific ways. Representations of verb meaning include notation for specifying the relationships among the &apos;Subpredicates that make up a word&apos;</context>
<context position="8442" citStr="Chafe (1970)" startWordPosition="1289" endWordPosition="1290">n two arguments, normally an object (or person) and an object or value within the conceptual field specified by the stative. For example, consider the sentence shown in Figure 1. Ida owned a Cadillac from 1970 to 1977. The verb own conveys that a relationship of possession misted between Ida and the Cadillac for some civration. Besides statives for possession there are a large number of other statives, including location (to be._ at, to re:n.4112_0, etc.) and emotion (to hate, to love, etc.). In addition to simple stative relationships, verbs can be used to convey changes tof state. Following Chafe (1970) I will refer to a change of state as a process. For example, the sentence Ida receives $10.00. tells us (1) that Ida now has $10.00 (2) that someone else had the $10.00 before, (3) that a change has taken place from this previous state of possession to the present state. More commonly, verbs express not simple changes of state but causal changes of state. We seem to be very interested in processes that are volitionally caused by humans and ether sentient beings. Figure 2 shows the representation of the sentence Ida gives Sam a rose. An agent nay cause a change of state that relates to another</context>
</contexts>
<marker>Chafe, 1970</marker>
<rawString>Chafe, W.L. Meaning ,and the structure of language. Chicago: University of Chicago Press, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E V Clark</author>
</authors>
<title>What&apos;s in a word: On the child&apos;s acquIsition of semantics in â€¢ his first language. In</title>
<date>1973</date>
<publisher>Academic Press,</publisher>
<location>New York:</location>
<contexts>
<context position="17596" citStr="Clark, 1973" startWordPosition="2743" endWordPosition="2744"> use ol general verbs in memory between the nouns. The results were exactly as predicted The object nouns of complex connective verbs were recalled better than those of general verbs and non-connecting complex verbs. These differences were not traceable to differences in imagery or word-frequency. Thus connectivity is beneficial to sentence metory in a very specific way. Acauisition. There may be a more direct relationship between complexity and difficulty in children than in adults. Young children often fail to comprehend the full meanings of semantically complex terms (e.g., Bowerman, 1975, Clark, 1973, Gentner, 1975, in press). Working with the verbs of possession, I have observed that childrpn act out the simple verbs give and take correctly before they act out the more complex verbs Duy. and trade. Still later they learn the yet more complex verbs 1204 gall and anend. The order in which the verbs are learned is exactly the order of increasing semantic complexity. This complexity ordering can be made quite precise, since the verbs are closely related in meaning. The representation of a verb at the nth level of simplicity is properly nested within the representation of a verb at the (n+1)t</context>
</contexts>
<marker>Clark, 1973</marker>
<rawString>Clark, E.V. What&apos;s in a word: On the child&apos;s acquIsition of semantics in â€¢ his first language. In T.E. Moore (Ed.), Cognitive development and- the acouisition of language, New York: Academic Press, 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Clark</author>
<author>E V Clark</author>
</authors>
<title>psychology and LAligalLt.</title>
<date>1977</date>
<publisher>Harcourt Brace Jovanovich, Inc.,</publisher>
<location>New York:</location>
<contexts>
<context position="20813" citStr="Clark and Clark (1977)" startWordPosition="3258" endWordPosition="3261">im. As predicted, subjects nearing the extra material falsely recalled the verb which best fit the composite structure (e.g. rather than the verb actually presented. Further Ipsges I have dhde the assumption that a verb carries with it a set of inferences that are normally made during comprehension, as well as several supporting assumptions. This view has been fairly well supported by the research presented here, but nevertheless it seems to me an &apos;oversimplification. There remain a great many questions, some large and some small. (1) Where should the line be drawn around a word&apos;s meaning? As Clark and Clark (1977) have put it, is word meaning more like a dictionary or an encyclopedia? The extreme of the dictionary approach would be to take a minimal contrast approach, storing with a word only enough to distingulsh it from all other words. The extreme of the encyclopedia approach would be to access the entire long-term memory whenever any word is used. The question is, how to define a reasonable middle ground. (2) What ism the process of expansion into a semantic representation during comprehension? a) Are there invariable inferences?. When an incoming word is processed, is there a set of inferences (su</context>
</contexts>
<marker>Clark, Clark, 1977</marker>
<rawString>Clark, H.H. &amp; Clark, E.V. psychology and LAligalLt. New York: Harcourt Brace Jovanovich, Inc., 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Berlin</author>
<author>P Kay</author>
</authors>
<title>Basic color terms: their universality and evolution,</title>
<date>1969</date>
<publisher>Univ. of California Press,</publisher>
<location>Berkeley:</location>
<marker>Berlin, Kay, 1969</marker>
<rawString>Berlin, B, and P. Kay, Basic color terms: their universality and evolution, Berkeley: Univ. of California Press, 1969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D G Bobrow</author>
<author>T Winograd</author>
</authors>
<title>An overview of KRL,</title>
<date>1977</date>
<journal>a Knowledge Representation Language, Cognitiw Science</journal>
<volume>1</volume>
<pages>3--46</pages>
<marker>Bobrow, Winograd, 1977</marker>
<rawString>Bobrow, D.G. and T. Winograd. An overview of KRL, a Knowledge Representation Language, Cognitiw Science 1:1 (January, 1977), 3-46</rawString>
</citation>
<citation valid="true">
<authors>
<author>D G Bobrow</author>
<author>T Winograd</author>
</authors>
<title>and the KRL Research Group, Expenende with KR L-0: Me cycle of a knowledge representation language.</title>
<date>1977</date>
<booktitle>Proceedings of the Fifth International Joint Coilference on Ar4ficial Intelligence</booktitle>
<pages>213--222</pages>
<marker>Bobrow, Winograd, 1977</marker>
<rawString>Bobrow, D.G., T Winograd, and the KRL Research Group, Expenende with KR L-0: Me cycle of a knowledge representation language. Proceedings of the Fifth International Joint Coilference on Ar4ficial Intelligence (August, 1977), 213-222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Clark</author>
<author>E V Clark</author>
</authors>
<title>Psychology of Language An Introifuedion to Psycholinguiltics,</title>
<date>1977</date>
<location>New York: Harcourt Brace,</location>
<contexts>
<context position="20813" citStr="Clark and Clark (1977)" startWordPosition="3258" endWordPosition="3261">im. As predicted, subjects nearing the extra material falsely recalled the verb which best fit the composite structure (e.g. rather than the verb actually presented. Further Ipsges I have dhde the assumption that a verb carries with it a set of inferences that are normally made during comprehension, as well as several supporting assumptions. This view has been fairly well supported by the research presented here, but nevertheless it seems to me an &apos;oversimplification. There remain a great many questions, some large and some small. (1) Where should the line be drawn around a word&apos;s meaning? As Clark and Clark (1977) have put it, is word meaning more like a dictionary or an encyclopedia? The extreme of the dictionary approach would be to take a minimal contrast approach, storing with a word only enough to distingulsh it from all other words. The extreme of the encyclopedia approach would be to access the entire long-term memory whenever any word is used. The question is, how to define a reasonable middle ground. (2) What ism the process of expansion into a semantic representation during comprehension? a) Are there invariable inferences?. When an incoming word is processed, is there a set of inferences (su</context>
</contexts>
<marker>Clark, Clark, 1977</marker>
<rawString>Clark, H.H., and E.V. Clark, Psychology of Language An Introifuedion to Psycholinguiltics, New York: Harcourt Brace, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H L Dreyfus</author>
</authors>
<title>What computers can&apos;t do: a critique of artificial reason,</title>
<date>1972</date>
<location>New York: Harper &amp; Row,</location>
<marker>Dreyfus, 1972</marker>
<rawString>Dreyfus, H. L., What computers can&apos;t do: a critique of artificial reason, New York: Harper &amp; Row, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fillmore</author>
</authors>
<title>The case for case,</title>
<date>1968</date>
<booktitle>In Bach and HarmslEds.), Universals in Linguistic Theory,</booktitle>
<pages>1--90</pages>
<location>Chicago: Holt,</location>
<marker>Fillmore, 1968</marker>
<rawString>Fillmore, C., The case for case, In Bach and HarmslEds.), Universals in Linguistic Theory, Chicago: Holt, 1968E. 1-90.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Univ Linguistics</author>
</authors>
<title>of California Berkeley. tics F19117l4m.ore. C., The future of Semantics,</title>
<booktitle>Berkeley Studies in Syntax and Semantics Dept. of</booktitle>
<marker>Linguistics, </marker>
<rawString>Linguistics, Univ. of California Berkeley. tics F19117l4m.ore. C., The future of Semantics, Berkeley Studies in Syntax and Semantics Dept. of</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fillmore</author>
</authors>
<title>An Alternative to Checklist Theories of Meaning,</title>
<date>1975</date>
<booktitle>Proceedings of the First Annual Alerting of the Berkeley Linguistics Society, Cogen</booktitle>
<institution>University of California, Berkeley,</institution>
<marker>Fillmore, 1975</marker>
<rawString>Fillmore, C., An Alternative to Checklist Theories of Meaning, Proceedings of the First Annual Alerting of the Berkeley Linguistics Society, Cogen et al. (Eds.), University of California, Berkeley, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Fodor</author>
</authors>
<title>The Language of Thought,</title>
<date>1975</date>
<location>New York: Cromwell,</location>
<marker>Fodor, 1975</marker>
<rawString>Fodor, J.A., The Language of Thought, New York: Cromwell, 1975. Fodor, 3.A.. Methodological &apos;solipsism as a research strategy in psychology, _unpublished draft, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R lackendoff</author>
</authors>
<title>Toward an explanatory semantic representation,</title>
<date>1976</date>
<journal>Linguistic Inquiry</journal>
<volume>7</volume>
<pages>89--150</pages>
<location>Winter,</location>
<marker>lackendoff, 1976</marker>
<rawString>lackendoff, R.. Toward an explanatory semantic representation, Linguistic Inquiry 7:1 (Winter, 1976) 89-150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Katz</author>
</authors>
<title>Semantic Theory. New York: Harper and Row,</title>
<date>1972</date>
<booktitle>The Structure ef Language,</booktitle>
<editor>Katz, J.J., and J.A. Fodor,</editor>
<publisher>Prentice Hall,</publisher>
<marker>Katz, 1972</marker>
<rawString>Katz, J.J., Semantic Theory. New York: Harper and Row, 1972., Katz, J.J., and J.A. Fodor, The Structure of a Semantic Theory, in J. Fodor and J. Katz, (eds.) The Structure ef Language, Prentice Hall, 1964.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wâ€ž Labov</author>
</authors>
<title>The bdtmdanes of words and their meanings,</title>
<date>1973</date>
<booktitle>New Ways of Analyzmg Variation in English, Georgetown Univ.,</booktitle>
<editor>in C-./. N. Bailey and Roger Shuy (eds.),</editor>
<marker>Labov, 1973</marker>
<rawString>Labov, Wâ€ž The bdtmdanes of words and their meanings, in C-./. N. Bailey and Roger Shuy (eds.), New Ways of Analyzmg Variation in English, Georgetown Univ., 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lakoff</author>
</authors>
<title>Linguistic Gestalts,</title>
<date>1977</date>
<booktitle>Proceedings of the Chicago Linguistic Society (CLS IV.</booktitle>
<pages>236--287</pages>
<marker>Lakoff, 1977</marker>
<rawString>Lakoff, G., Linguistic Gestalts, Proceedings of the Chicago Linguistic Society (CLS IV. 1977, 236-287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leech</author>
</authors>
<title>Towards a semantic description of English,</title>
<date>1969</date>
<location>London: Longman,</location>
<marker>Leech, 1969</marker>
<rawString>Leech, G., Towards a semantic description of English, London: Longman, 1969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lewis</author>
</authors>
<title>General semantics,</title>
<date>1972</date>
<booktitle>Semantics of Natural Language</booktitle>
<editor>in Davidson and Harman (eds.),</editor>
<location>Dordrecht: Reidel.</location>
<marker>Lewis, 1972</marker>
<rawString>Lewis, 0., General semantics, in Davidson and Harman (eds.), Semantics of Natural Language Dordrecht: Reidel. 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Martin</author>
</authors>
<title>A theory of English grammar, unputahed notes.</title>
<date>1976</date>
<publisher>MIT,</publisher>
<marker>Martin, 1976</marker>
<rawString>Martin, W.A., A theory of English grammar, unputahed notes. MIT, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
</authors>
<title>Some psychological studies of grammar,</title>
<date>1962</date>
<journal>American Psycholagist</journal>
<volume>17</volume>
<pages>748--762</pages>
<marker>Miller, 1962</marker>
<rawString>Miller, G.A., Some psychological studies of grammar, American Psycholagist 17 (1962), 748-762.</rawString>
</citation>
<citation valid="false">
<authors>
<author>G A Miller</author>
<author>P N Johnson-Laird</author>
</authors>
<publisher>Harvard University Press,</publisher>
<location>Cambridge:</location>
<marker>Miller, Johnson-Laird, </marker>
<rawString>Miller, G.A., and P.N. Johnson-Laird, Cambridge: Harvard University Press,</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Moore</author>
<author>Newell</author>
</authors>
<title>tte How can Gregg (Ed.), Knowledge and Cognition, Ellbaum Associates,</title>
<date>1973</date>
<marker>Moore, Newell, 1973</marker>
<rawString>Moore J., and Newell. ..tte How can Gregg (Ed.), Knowledge and Cognition, Ellbaum Associates, 1973.</rawString>
</citation>
<citation valid="false">
<authors>
<author>C Rieg9r</author>
</authors>
<title>Conceptual memory and inference,</title>
<booktitle>in R.C. Schank, Conceptual hifinnatu n Processing,</booktitle>
<pages>157--288</pages>
<location>Amsterdam: North Holland, P)75,</location>
<marker>Rieg9r, </marker>
<rawString>Rieg9r, C., Conceptual memory and inference, in R.C. Schank, Conceptual hifinnatu n Processing, Amsterdam: North Holland, P)75, 157-288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Schank</author>
</authors>
<title>Conceptual dependency: A theory of natural language understanding, Cognitive Psychology,</title>
<date>1972</date>
<pages>552--631</pages>
<marker>Schank, 1972</marker>
<rawString>Schank, R. C.,. Conceptual dependency: A theory of natural language understanding, Cognitive Psychology, 1972, 552-631.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Schank</author>
<author>R P Abelsonâ€ž</author>
</authors>
<title>Scripts Plans Goals and Understanding, Hillsdale: Lawrence Erlbaum Associates,</title>
<date>1977</date>
<marker>Schank, Abelsonâ€ž, 1977</marker>
<rawString>Schank, R.C. and R.P. Abelsonâ€ž Scripts Plans Goals and Understanding, Hillsdale: Lawrence Erlbaum Associates, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hawkinson</author>
<author>W A Martin</author>
</authors>
<title>An Overview of OWL, an language. for knowledge representation, M.I.T. LCS-TM-86,</title>
<date>1977</date>
<marker>Hawkinson, Martin, 1977</marker>
<rawString>S7olovits, P., IA. Hawkinson, and W.A. Martin, An Overview of OWL, an language. for knowledge representation, M.I.T. LCS-TM-86, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
</authors>
<title>Good and bad- arguments abtbt semantic primitives,</title>
<date></date>
<journal>D.A.I. Research Report</journal>
<volume>42</volume>
<institution>University of Essex,</institution>
<marker>Wilks, </marker>
<rawString>Wilks, Y., Good and bad- arguments abtbt semantic primitives, D.A.I. Research Report No. 42, University of Essex, May 1.977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>Towards a Proceduial Understanding of Semantics&apos;,</title>
<date>1978</date>
<tech>Technical Report No. 3605,</tech>
<institution>Bolt Beranek .and Newman Inc.,</institution>
<location>Brachman, R.J:</location>
<marker>Winograd, 1978</marker>
<rawString>Winograd, T. Towards a Proceduial Understanding of Semantics&apos;, Brachman, R.J: (1978) &amp;quot;A Structural Paradigm for Representing Knowledge.,&amp;quot; Technical Report No. 3605, Bolt Beranek .and Newman Inc., Cambridge MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Fahlman</author>
</authors>
<title>A System for Representing and Using Real-World Knowledge,&amp;quot;</title>
<date>1977</date>
<tech>Ph.D. dissertation,</tech>
<institution>Dept. of Electrical Engineering . and Computer Science, M.I.T.</institution>
<marker>Fahlman, 1977</marker>
<rawString>Fahlman, S.E. (1977) &amp;quot;A System for Representing and Using Real-World Knowledge,&amp;quot; Ph.D. dissertation, Dept. of Electrical Engineering . and Computer Science, M.I.T.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B T Lowerre</author>
</authors>
<title>The HARPY Speech Recognition System,&amp;quot;</title>
<date>1976</date>
<tech>Technical Report,</tech>
<institution>Department of Computer Science, Carnegie-Mellon University,</institution>
<location>Pittsburgh, Pau</location>
<marker>Lowerre, 1976</marker>
<rawString>Lowerre, B.T. &apos;(1976) &amp;quot;The HARPY Speech Recognition System,&amp;quot; Technical Report, Department of Computer Science, Carnegie-Mellon University, Pittsburgh, Pau</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Quillian</author>
</authors>
<title>Semantic Memory,&amp;quot;</title>
<date>1966</date>
<tech>Report No. AFCRL-66-189,</tech>
<institution>Bolt Beranek and Newman Inc.,</institution>
<location>Cambridge, Ma.</location>
<marker>Quillian, 1966</marker>
<rawString>Quillian, M.R. (1966) &amp;quot;Semantic Memory,&amp;quot; Report No. AFCRL-66-189, Bolt Beranek and Newman Inc., Cambridge, Ma.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Quillian</author>
</authors>
<title>Semantic Memory,&amp;quot;</title>
<date>1968</date>
<booktitle>in Semantic InformatiQn Processim</booktitle>
<pages>27--70</pages>
<editor>(M. Minsky, ed.). Cambridge,</editor>
<publisher>Ma:Ki.J.T. Press.,</publisher>
<marker>Quillian, 1968</marker>
<rawString>Quillian, M.R. (1968) &amp;quot;Semantic Memory,&amp;quot; in Semantic InformatiQn Processim (M. Minsky, ed.). Cambridge, Ma:Ki.J.T. Press., pp. 27-70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Rieger</author>
</authors>
<title>Spontaneous Computation in Models,&amp;quot;</title>
<date>1977</date>
<journal>Cognitive Science</journal>
<pages>315--354</pages>
<marker>Rieger, 1977</marker>
<rawString>Rieger, C. (1977) &amp;quot;Spontaneous Computation in Models,&amp;quot; Cognitive Science pp. 315-,354. &amp;quot;</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
<author>M Bates</author>
<author>G Brown</author>
<author>B Bruce</author>
<author>J Klovstad C-Cook</author>
<author>J Makhoul</author>
</authors>
<date>1976</date>
<marker>Woods, Bates, Brown, Bruce, C-Cook, Makhoul, 1976</marker>
<rawString>Woods, W.A., M. Bates, G. Brown, B. Bruce, C.-Cook, J. Klovstad, J. Makhoul, 8. Nash-Webber, R. Schwartz, J. Wolf, V. Zile (1976)</rawString>
</citation>
<citation valid="true">
<title>Speech Understanding Systems - Final Report,</title>
<date>1974</date>
<tech>BBN Report No. 3438, Vols. I-V,</tech>
<institution>Bolt Beranek and Newman Inc.,</institution>
<location>Cambridge, Ma.</location>
<note>to 29</note>
<marker>1974</marker>
<rawString>Speech Understanding Systems - Final Report, 30 October 1974 to 29 October 1976, BBN Report No. 3438, Vols. I-V, Bolt Beranek and Newman Inc., Cambridge, Ma.</rawString>
</citation>
<citation valid="false">
<authors>
<author>W A Woods</author>
</authors>
<title>r1977), &amp;quot;Semantics and Ouantification in Natural Language Question Answering,&amp;quot; to appear in</title>
<booktitle>Advances in Coyiputers,</booktitle>
<volume>17</volume>
<location>New York:</location>
<marker>Woods, </marker>
<rawString>Woods, W.A. r1977), &amp;quot;Semantics and Ouantification in Natural Language Question Answering,&amp;quot; to appear in Advances in Coyiputers, Vol. 17, New York:</rawString>
</citation>
<citation valid="true">
<authors>
<author>TETEFEUE Press</author>
</authors>
<date>1977</date>
<tech>Also Report No. 3687,</tech>
<institution>Bolt Berane and Newman Inc.,</institution>
<marker>Press, 1977</marker>
<rawString>TETEFEUE Press. (Also Report No. 3687, Bolt Berane and Newman Inc., 1977).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
<author>R J Brachman</author>
</authors>
<title>Research in Natural Language Understanding&amp;quot; - Quarterly</title>
<date>1978</date>
<tech>Technical Progress Report No. 1 (BAN Report No. 3742),</tech>
<institution>Bolt Beranek and Newman Inc.,</institution>
<location>Cambridge, MA</location>
<marker>Woods, Brachman, 1978</marker>
<rawString>Woods, W.A. and R.J. Brachman (1978) &amp;quot;Research in Natural Language Understanding&amp;quot; - Quarterly Technical Progress Report No. 1 (BAN Report No. 3742), Bolt Beranek and Newman Inc., Cambridge, MA</rawString>
</citation>
<citation valid="false">
<title>From different points of view, discussions of the relationship between the explicit text and higher-level organizing structures can be found</title>
<booktitle>in Collins, Brown &amp; Larkin [19771 and Webber [1978b1.</booktitle>
<marker></marker>
<rawString>&lt;*4&gt;. From different points of view, discussions of the relationship between the explicit text and higher-level organizing structures can be found in Collins, Brown &amp; Larkin [19771 and Webber [1978b1.</rawString>
</citation>
<citation valid="false">
<title>just definite and indefinite noun phrases that can evoke entities in the listener&apos;s discourse model, I will illustrate in SeCtion 4 an example of deictically-evoked entities and comment on the problem of describing them appropriately.</title>
<marker></marker>
<rawString>just definite and indefinite noun phrases that can evoke entities in the listener&apos;s discourse model, I will illustrate in SeCtion 4 an example of deictically-evoked entities and comment on the problem of describing them appropriately.</rawString>
</citation>
<citation valid="false">
<booktitle>2m Indefinite Noun Phrases and Discoutse Entities</booktitle>
<marker></marker>
<rawString>2m Indefinite Noun Phrases and Discoutse Entities</rawString>
</citation>
<citation valid="false">
<title>Except after a copula, indefinite noun phrases &lt;*5&gt; may evoke a new discourse entity into a listendr&apos;s discaurse model. &lt;*6&gt; What. I want to focus on here is appropriate IDs for them. Consider the following sentences.</title>
<marker></marker>
<rawString>Except after a copula, indefinite noun phrases &lt;*5&gt; may evoke a new discourse entity into a listendr&apos;s discaurse model. &lt;*6&gt; What. I want to focus on here is appropriate IDs for them. Consider the following sentences.</rawString>
</citation>
<citation valid="false">
<authors>
<author>is</author>
</authors>
<title>Wendy beught a yellow T-shirt that, Bruce had liked. b. It cost twenty dollars.</title>
<marker>is, </marker>
<rawString>is. Wendy beught a yellow T-shirt that, Bruce had liked. b. It cost twenty dollars.</rawString>
</citation>
<citation valid="false">
<authors>
<author>2a</author>
</authors>
<title>Each third-grade girl brought a pelican to Wendy&apos;s house.</title>
<contexts>
<context position="3627" citStr="(2)" startWordPosition="544" endWordPosition="544">s of extension The representations should be extendible so as to reflect the ways in which people interpret verb meanings when the verbs are used outside their normal context. 7. Reaction times The time taken to comprehend a sentence using a given verb should reflect the structural complexity of the verb meaning. Experiments concerned with predictions 1-5 are described here. The results are promising for a general approach of representation of meaning in terms of interrelated subpredicates, but do not clearly distinguish between several similar representations. For example, to test prediction (2), I read people sentences containing verbs with similar meanings, and asked them to recall the sentences. The deipwe of overlap in the semantic structures was a good predictor of the number of confusions between sentences. In another sentence-memory experiment (prediction (3)), semantically compldk verbs that provided more underlying interconnections between the nouns in a sentence led to better memory for the nouns in the sentence than simple genera&amp; verbs, or than other complex verbs that did not provide such extra interconnections, To test prediction (5), I tested children&apos;s zomprehension o</context>
<context position="5459" citStr="(2)" startWordPosition="825" endWordPosition="825">mber of different kinds of psychological phenomena, then that representation stands a greater chance of being generally useful than one which was tested in only one depth-first way. This paper describes a program of research that tests a representational format for verb meaning. This research grew out of the LNR (Footnote 1) attempt to the represent the Meanings of words in a psychologically satisfying way. Verb meaning seemed a natural place to start for two reasons: (1) verbs are important: it is arguable that they provide the central trganizing semantic structures in sentence meanings; and (2) verbs are tractable: their meanings are more easily analyzed than those. of, for example, common nouns. Since different disciplines look at meaning in different ways., it may be worthwhile to describe the stance we took. What we wanted was a system of representation in which we could capture our intuitions about what a word typically conveys; or more specifically about the inferences a person normally makes (or believes should be =vie) when a word is used. The assumption is that the same representations operate when a person uses the word in speech as when the person comprehends it; however t</context>
<context position="8578" citStr="(2)" startWordPosition="1317" endWordPosition="1317">r the sentence shown in Figure 1. Ida owned a Cadillac from 1970 to 1977. The verb own conveys that a relationship of possession misted between Ida and the Cadillac for some civration. Besides statives for possession there are a large number of other statives, including location (to be._ at, to re:n.4112_0, etc.) and emotion (to hate, to love, etc.). In addition to simple stative relationships, verbs can be used to convey changes tof state. Following Chafe (1970) I will refer to a change of state as a process. For example, the sentence Ida receives $10.00. tells us (1) that Ida now has $10.00 (2) that someone else had the $10.00 before, (3) that a change has taken place from this previous state of possession to the present state. More commonly, verbs express not simple changes of state but causal changes of state. We seem to be very interested in processes that are volitionally caused by humans and ether sentient beings. Figure 2 shows the representation of the sentence Ida gives Sam a rose. An agent nay cause a change of state that relates to another object. Or the same person may act on both agent and experiencer of the change of state. The lotational verb move can be used in either</context>
<context position="21220" citStr="(2)" startWordPosition="3331" endWordPosition="3331">theless it seems to me an &apos;oversimplification. There remain a great many questions, some large and some small. (1) Where should the line be drawn around a word&apos;s meaning? As Clark and Clark (1977) have put it, is word meaning more like a dictionary or an encyclopedia? The extreme of the dictionary approach would be to take a minimal contrast approach, storing with a word only enough to distingulsh it from all other words. The extreme of the encyclopedia approach would be to access the entire long-term memory whenever any word is used. The question is, how to define a reasonable middle ground. (2) What ism the process of expansion into a semantic representation during comprehension? a) Are there invariable inferences?. When an incoming word is processed, is there a set of inferences (such as the set I have called the &amp;quot;almost-inevitable Inferences&amp;quot; that is always made during comprehension, or is there variation in which inferences get made? 6 b) If there is variation, is it quantitative or qualitative? Do context and the person&apos;s interests and attention determine wirich inferences get made, so that there are qualitative .differences in what inferences get made? Or is the difference mere</context>
</contexts>
<marker>2a, </marker>
<rawString>2a. Each third-grade girl brought a pelican to Wendy&apos;s house.</rawString>
</citation>
<citation valid="false">
<authors>
<author>b</author>
</authors>
<title>She is roosting them on her front lawn.</title>
<marker>b, </marker>
<rawString>b. She is roosting them on her front lawn.</rawString>
</citation>
<citation valid="false">
<authors>
<author>3a</author>
</authors>
<title>If Bruce manages to catch a fish, W. he will eat it for dialer. 4a. John didn&apos;t marry a Swedish woman. b. She was Norwegian.</title>
<contexts>
<context position="3903" citStr="(3)" startWordPosition="585" endWordPosition="585">ctural complexity of the verb meaning. Experiments concerned with predictions 1-5 are described here. The results are promising for a general approach of representation of meaning in terms of interrelated subpredicates, but do not clearly distinguish between several similar representations. For example, to test prediction (2), I read people sentences containing verbs with similar meanings, and asked them to recall the sentences. The deipwe of overlap in the semantic structures was a good predictor of the number of confusions between sentences. In another sentence-memory experiment (prediction (3)), semantically compldk verbs that provided more underlying interconnections between the nouns in a sentence led to better memory for the nouns in the sentence than simple genera&amp; verbs, or than other complex verbs that did not provide such extra interconnections, To test prediction (5), I tested children&apos;s zomprehension of a set of possession verbs. Both the order of acquisition among the verbs and the kinds of errors fitted well with an account of the acquisition of verb meaning in terms of interconnected subpredicates. This research illustrates a breadth-fir-it approach to testing a represe</context>
<context position="8623" citStr="(3)" startWordPosition="1325" endWordPosition="1325"> Cadillac from 1970 to 1977. The verb own conveys that a relationship of possession misted between Ida and the Cadillac for some civration. Besides statives for possession there are a large number of other statives, including location (to be._ at, to re:n.4112_0, etc.) and emotion (to hate, to love, etc.). In addition to simple stative relationships, verbs can be used to convey changes tof state. Following Chafe (1970) I will refer to a change of state as a process. For example, the sentence Ida receives $10.00. tells us (1) that Ida now has $10.00 (2) that someone else had the $10.00 before, (3) that a change has taken place from this previous state of possession to the present state. More commonly, verbs express not simple changes of state but causal changes of state. We seem to be very interested in processes that are volitionally caused by humans and ether sentient beings. Figure 2 shows the representation of the sentence Ida gives Sam a rose. An agent nay cause a change of state that relates to another object. Or the same person may act on both agent and experiencer of the change of state. The lotational verb move can be used in either way, as in the following examples a. Ida mov</context>
<context position="11046" citStr="(3)" startWordPosition="1731" endWordPosition="1731">ng the psychological rightness of the system as so far stated before going on to refine it. EiushalagisaLkaitats1.11sJiadia. One advantage of psychological experimentation (or of computer implementation) is that it Forces one to make explicit the assumptions &apos; underlying representation and process. At least some of the choices made can then be tested as hypotheses. Some important assumptions are (1) a verb&apos;s representation captures the set of immediate inferences that people normally make when they hear or read a sentence containing -the verb; c21 in general, one verb leads to many inferences (3) these networks of meaning components are accessed during comprehension, by an immediate and largely automatic process (4) the set of components associated with a given word is reasonably stable across task and cbntexts (5) surface memory for exact words fades quite rapidly, so that after a short time, only the representational network remains. In testing these representations, I took a very literal interpretation of &apos;the notion of representation -- namely that the nodes and arrows in a representation correspond to the concepts and relatiOnships that are stored when a person comprehends a sent</context>
<context position="23195" citStr="(3)" startWordPosition="3641" endWordPosition="3641">r-less constant. It is possible that this qualitative variation can be accounted for by simple underlying quantitative processes spreading activation. We may have to settle for a more complex model, in which some parts of a verb&apos;s meaning are almost always accessed while other inferences develop out of the interaction of the verb with its context, including its pragmatic context. In Hewitt&apos;s (197b) terms, there may be both if-added inferences and if-needed inferences. Where in this model (and whether) we want to draw a line between meaning and knowledge-of-the-world is not at all clear to me. (3) Carrying the notion of variable werb mean4ng still further, how does metaphorical extension work? Most common verbs can be used in several related ways. For example, consider the range Of meanings that give can convey depending on the nbuns it is used with Ida gave Sam a rose a job. an heir. an excuse a talking to. all his best ideas. the time of his life. Clearly the subpredicate structure varies across these sentences, so much so that some might want to describe this as a collection of entirely different senSes of the same word. This misses the structural similarities. Some kind of metaphor</context>
</contexts>
<marker>3a, </marker>
<rawString>3a. If Bruce manages to catch a fish, W. he will eat it for dialer. 4a. John didn&apos;t marry a Swedish woman. b. She was Norwegian.</rawString>
</citation>
<citation valid="false">
<authors>
<author>5a</author>
</authors>
<title>Whether Bruce buys a mini-computer or an Advent TV,</title>
<contexts>
<context position="4190" citStr="(5)" startWordPosition="629" endWordPosition="629">ons. For example, to test prediction (2), I read people sentences containing verbs with similar meanings, and asked them to recall the sentences. The deipwe of overlap in the semantic structures was a good predictor of the number of confusions between sentences. In another sentence-memory experiment (prediction (3)), semantically compldk verbs that provided more underlying interconnections between the nouns in a sentence led to better memory for the nouns in the sentence than simple genera&amp; verbs, or than other complex verbs that did not provide such extra interconnections, To test prediction (5), I tested children&apos;s zomprehension of a set of possession verbs. Both the order of acquisition among the verbs and the kinds of errors fitted well with an account of the acquisition of verb meaning in terms of interconnected subpredicates. This research illustrates a breadth-fir-it approach to testing a representation. In the breadth-first approach, many different psychological predictions are made. Each different area of prediction requires a set of process assumptions, and in each case the process assumptions used are those that seem most plausible given previous research in the field. If o</context>
<context position="11269" citStr="(5)" startWordPosition="1765" endWordPosition="1765">ne to make explicit the assumptions &apos; underlying representation and process. At least some of the choices made can then be tested as hypotheses. Some important assumptions are (1) a verb&apos;s representation captures the set of immediate inferences that people normally make when they hear or read a sentence containing -the verb; c21 in general, one verb leads to many inferences (3) these networks of meaning components are accessed during comprehension, by an immediate and largely automatic process (4) the set of components associated with a given word is reasonably stable across task and cbntexts (5) surface memory for exact words fades quite rapidly, so that after a short time, only the representational network remains. In testing these representations, I took a very literal interpretation of &apos;the notion of representation -- namely that the nodes and arrows in a representation correspond to the concepts and relatiOnships that are stored when a person comprehends a sentence containing a verb. The more ferociously literal the intet.pretation, the better the chances of discovering counter-evidence. Semantlg overlap. One psychological criterion ip that the representations should agree with p</context>
<context position="24836" citStr="(5)" startWordPosition="3918" endWordPosition="3918">xts. (4) I have so far treated nouns as nodes in the semantic representation. Clearly in order to analyze sentence interactions it is necessary to have a representation of noun meaning. Some progress been made with abstract nouns, such as kinship terms. But the truly nounlike nouns ---basic-level nouns--- resist analysis. I believe that these differences in amendability to analysis reflect differences in the kind of meaning that verbs and nouns have, and that a useful representation of concrete noun meaning may be quite different from that used for verbs, prepositions and even abstract nouns. (5) There are several aspects of the representational scheme that need further thought. To single out one issue, consider the notion of change of state. The LNR representation represents a verb like get,_ as conveying a change from an initial state of possession to a final state of possession. Schank&apos;s Conceptual Dependency theory would represent the entire sequence as a primitive act. Many generative semanticists have represented only the inchoative part of the chain (the change to the final state) as belonging to the assertion of the verb, consi.dering the initial state to be more in the nature</context>
</contexts>
<marker>5a, </marker>
<rawString>5a. Whether Bruce buys a mini-computer or an Advent TV,</rawString>
</citation>
<citation valid="false">
<authors>
<author>b</author>
</authors>
<title>he will have to do the repairs on it himself.</title>
<marker>b, </marker>
<rawString>b. he will have to do the repairs on it himself.</rawString>
</citation>
<citation valid="false">
<title>Every man who owns a donkey beats it.</title>
<marker></marker>
<rawString>6. Every man who owns a donkey beats it.</rawString>
</citation>
<citation valid="false">
<title>Each cat on the stoop-hates Sam.&amp;quot; &amp;quot;The three cats each scratched Sam.&amp;quot;</title>
<marker></marker>
<rawString>&amp;quot;Each cat on the stoop-hates Sam.&amp;quot; &amp;quot;The three cats each scratched Sam.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>universally quantified existentials &amp;quot;Each boy gave each girl (a peach, three peaches).&amp;quot; 5. class dependent definites &amp;quot;Each boy gave a woman he knew the (peach, two peaches) she wanted.&amp;quot;</title>
<marker></marker>
<rawString>4. universally quantified existentials &amp;quot;Each boy gave each girl (a peach, three peaches).&amp;quot; 5. class dependent definites &amp;quot;Each boy gave a woman he knew the (peach, two peaches) she wanted.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>class dependent distributives &amp;quot;Each boy I know loves every woman he meets.&amp;quot;</title>
<marker></marker>
<rawString>6. class dependent distributives &amp;quot;Each boy I know loves every woman he meets.&amp;quot;</rawString>
</citation>
<citation valid="false">
<authors>
<author>12a</author>
</authors>
<title>Few linguists smoke since they know it causes cancer.</title>
<marker>12a, </marker>
<rawString>12a. Few linguists smoke since they know it causes cancer.</rawString>
</citation>
<citation valid="false">
<authors>
<author>b</author>
</authors>
<title>Few linguists were at the party, but they drank more than the whole Army Corps of Engineers.</title>
<marker>b, </marker>
<rawString>b. Few linguists were at the party, but they drank more than the whole Army Corps of Engineers.</rawString>
</citation>
<citation valid="false">
<authors>
<author>13a</author>
</authors>
<title>Many linguists smoke although they know it causes cancer.</title>
<marker>13a, </marker>
<rawString>13a. Many linguists smoke although they know it causes cancer.</rawString>
</citation>
<citation valid="false">
<authors>
<author>b</author>
</authors>
<title>Not many linguists smoke since they know it causes cancer.</title>
<marker>b, </marker>
<rawString>b. Not many linguists smoke since they know it causes cancer.</rawString>
</citation>
<citation valid="false">
<authors>
<author>c</author>
</authors>
<title>Many linguists don&apos;t smoke since they know it causes cancer.</title>
<marker>c, </marker>
<rawString>c. Many linguists don&apos;t smoke since they know it causes cancer.</rawString>
</citation>
<citation valid="false">
<title>A man I know who owns a donkey beats it. 15. The man who owns a donkey beats it.</title>
<marker></marker>
<rawString>14. A man I know who owns a donkey beats it. 15. The man who owns a donkey beats it.</rawString>
</citation>
<citation valid="false">
<title>Which man who owns a donkey beats it? 17. No man who owns a donkey beats it.</title>
<marker></marker>
<rawString>16. Which man who owns a donkey beats it? 17. No man who owns a donkey beats it.</rawString>
</citation>
<citation valid="false">
<authors>
<author>20a</author>
</authors>
<title>Which man who owns a donkey beats if?</title>
<marker>20a, </marker>
<rawString>20a. Which man who owns a donkey beats if?</rawString>
</citation>
<citation valid="false">
<authors>
<author>The</author>
</authors>
<title>phrase &amp;quot;parameterized -individual&amp;quot; is being used somewhat loosely to include &amp;quot;parameterized&amp;quot; sets, stuff, etc. For example,</title>
<marker>The, </marker>
<rawString>&lt;*11&gt;. The. phrase &amp;quot;parameterized -individual&amp;quot; is being used somewhat loosely to include &amp;quot;parameterized&amp;quot; sets, stuff, etc. For example,</rawString>
</citation>
<citation valid="false">
<title>(i) No man who owns two donkeys beats them.</title>
<marker></marker>
<rawString>(i) No man who owns two donkeys beats them.</rawString>
</citation>
<citation valid="false">
<authors>
<author>them</author>
</authors>
<title>the two donkeys he owns &lt;*12&gt;. By &amp;quot;actual&amp;quot; discourse entities, I mean ones that can be referred to anaphorically in subsequent sentences.</title>
<marker>them, </marker>
<rawString>them = the two donkeys he owns &lt;*12&gt;. By &amp;quot;actual&amp;quot; discourse entities, I mean ones that can be referred to anaphorically in subsequent sentences.</rawString>
</citation>
<citation valid="false">
<authors>
<author>21a</author>
</authors>
<title>Each girl in the class gave Ivan the flower she picked.</title>
<marker>21a, </marker>
<rawString>21a. Each girl in the class gave Ivan the flower she picked.</rawString>
</citation>
<citation valid="false">
<authors>
<author>b</author>
</authors>
<title>He arranged them artfully in an empty Glenfiddach bottle.</title>
<marker>b, </marker>
<rawString>b. He arranged them artfully in an empty Glenfiddach bottle.</rawString>
</citation>
<citation valid="false">
<title>Lf Wendy has a car or Bruce has a bike, it will be in the garage.</title>
<marker></marker>
<rawString>22. Lf Wendy has a car or Bruce has a bike, it will be in the garage.</rawString>
</citation>
<citation valid="false">
<title>Bruce can have either a bike or a car, but he must keep it in the garage.</title>
<marker></marker>
<rawString>23. Bruce can have either a bike or a car, but he must keep it in the garage.</rawString>
</citation>
<citation valid="false">
<title>Either Bruce has a new car or he has borrowed his brother&apos;s. In any case, it is blocking my driveway.</title>
<marker></marker>
<rawString>24. Either Bruce has a new car or he has borrowed his brother&apos;s. In any case, it is blocking my driveway.</rawString>
</citation>
<citation valid="false">
<title>Whether Bruce buys a car or his brother buys a bike, he will have-to keep it in the garage.</title>
<marker></marker>
<rawString>25. Whether Bruce buys a car or his brother buys a bike, he will have-to keep it in the garage.</rawString>
</citation>
<citation valid="false">
<title>(22) &amp;quot;the car that Wendy has (if she has</title>
<marker></marker>
<rawString>(22) &amp;quot;the car that Wendy has (if she has</rawString>
</citation>
<citation valid="false">
<title>a car)&amp;quot; &amp;quot;the bike that Bruce has (if he has a bike)&amp;quot;</title>
<marker></marker>
<rawString>a car)&amp;quot; &amp;quot;the bike that Bruce has (if he has a bike)&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>(23) &amp;quot;the bike that Bruce will have (if he chooses a bikeY&amp;quot; &amp;quot;the car that Bruce will have (if he chooses a car)&amp;quot;</title>
<marker></marker>
<rawString>(23) &amp;quot;the bike that Bruce will have (if he chooses a bikeY&amp;quot; &amp;quot;the car that Bruce will have (if he chooses a car)&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>(24) &amp;quot;the new car that Bruce has (if Bruce has a new car)&amp;quot; &amp;quot;Bruce&apos;s brother&apos;s car&amp;quot;</title>
<marker></marker>
<rawString>(24) &amp;quot;the new car that Bruce has (if Bruce has a new car)&amp;quot; &amp;quot;Bruce&apos;s brother&apos;s car&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>(25) ?the car Bruce will have bought (if he buys a car)&amp;quot; &amp;quot;the bike Bruce&apos;s brother will have bought (if Bruce&apos;s brother buys a bike)&amp;quot;</title>
<marker></marker>
<rawString>(25) ?the car Bruce will have bought (if he buys a car)&amp;quot; &amp;quot;the bike Bruce&apos;s brother will have bought (if Bruce&apos;s brother buys a bike)&amp;quot;</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>