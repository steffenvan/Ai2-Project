<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.85824725">
Lexicalized Context-Free Grammars
Yves Schabes and Richard C. Waters
Mitsubishi Electric Research Laboratories
201 Broadway, Cambridge, MA 02139
</note>
<email confidence="0.603433">
e-mail: schabes©merl.com and dick(Omerl.com
</email>
<bodyText confidence="0.999530090909091">
Lexicalized context-free grammar (L(.FG) is
an attractive compromise between the parsing ef-
ficiency of context-free grammar (CF() and the
elegance and lexical sensitivity of lexicalized tree-
adjoining grammar (LTA(). LCFG is a restricted
form of LTAG that can only generate context-
free languages and can be parsed in cubic time.
However, LCFG supports much of the elegance of
LTAG&apos;s analysis of English and shares with LTAG
the ability to lexicalize CFGs without changing
the trees generated.
</bodyText>
<sectionHeader confidence="0.441655" genericHeader="abstract">
Motivation
</sectionHeader>
<bodyText confidence="0.999948657142857">
Context-free grammar (CFG) has been a well ac-
cepted framework for computational linguistics for
a long time. While it has drawbacks, including the
inability to express some linguistic constructions,
it has the virtue of being computationally efficient,
0(0)-time in the worst case.
Recently there has been a gain in interest in
the so-called &apos;mildly&apos; context-sensitive formalisms
(Vijay-Shanker, 1987; Weir, 1988; Joshi, Vijay-
Shanker, and Weir, 1991; Vijay-Shanker and Weir,
1993a) that generate only a small superset of
context-free languages. One such formalism is lex-
icalized tree-adjoining grammar (LTAG) (Schabes,
Abeille, and Joshi, 1988; Abeille et al., 1990; Joshi
and Schabes, 1992), which provides a number
of attractive properties at the cost of decreased
efficiency, 0(7/6)-time in the worst case (Vijay-
Shanker, 1987; Schabes, 1991; Lang, 1990; Vijay-
Shanker and Weir, 1993b).
An LTAG lexicon consists of a set of trees each
of which contains one or more lexical items. These
elementary trees can be viewed as the elementary
clauses (including their transformational variants)
in which the lexical items participate. The trees
are combined by substitution and adjunction.
LTAG supports context-sensitive features that
can capture some language constructs not cap-
tured by CFG. However, the greatest virtue of
LTAG is that it is lexicalized and supports ex-
tended domains of locality. The lexical nature of
LTAG is of linguistic interest, since it is believed
that the descriptions of many linguistic phenom-
ena are dependent upon lexical data. The ex-
tended domains allow for the localization of most
syntactic and sernantic dependencies (e.g., filler-
gap and predicate-argument relationships).
A further interesting aspect of LTAG is its
ability to lexicalize CFGs. One can convert a CFG
into an LTAG that preserves the original trees
(Joshi and Schabes, 1992).
Lexicalized context-free grammar (LCFG) is
an attractive compromise between LTAG and
CFG, that combines many of the virtues of LTAG
with the efficiency of CFG. LCFG is a restricted
form of LTAG that places further limits on the el-
ementary trees that are possible and on the way
adjunction can be performed. These restrictions
limit LCFG to producing only context-free lan-
guages and allow LCFG to be parsed in 0(n3)-
time in the worst case. However, LCFG retains
most of the key features of LTAG enumerated
above.
In particular, most of the current LTAG gram-
mar for English (Abeille et al., 1990) follows the
restrictions of LCFG. This is of significant practi-
cal interest because it means that the processing
of these analyses does not require more computa-
tional resources than CFGs.
In addition, any CFG can be transformed
into an equivalent LCFG that generates the same
trees (and therefore the same strings). This re-
sult breaks new ground, because heretofore ev-
ery method of lexicalizing CFGs required context-
sensitive operations (Joshi and Schabes, 1992).
The following sections briefly, define LCFG,
discuss its relationship to the current LTAG gram-
mar for English, prove that LCFG can be used to
lexicalize CFG, and present a simple cubic-time
parser for LCFG. These topics are discussed in
greater detail in Schabes and Waters (1993).
</bodyText>
<page confidence="0.99427">
121
</page>
<subsectionHeader confidence="0.488839">
Lexicalized Context-Free Grammars
</subsectionHeader>
<bodyText confidence="0.999334333333333">
Like an LTAG, an LCFG consists of two sets of
trees: initial trees, which are combined by substi-
tution and auxiliary trees, which are combined by
adjunction. An LCFG is lexicalized in the sense
that every initial and auxiliary tree is required to
contain at least one terminal symbol on its fron-
tier.
More precisely, an LCFG is a five-tuple
(E, NT, I, A „9), where E is a set of terminal sym-
bols, NT is a set of non-terminal symbols, / and
A are sets of trees labeled by terminal and non-
terminal symbols, and S is a distinguished non-
terminal start symbol.
Each initial tree in the set / satisfies the fol-
lowing requirements.
</bodyText>
<figure confidence="0.990538444444444">
NP VP VP
A A A
N V VP* A N* VP* Adv
boy seems pretty smoothly
+wh) S
NP01 VP NP0 VP NP01 VP
I I A
V S NA E, V V NPI1
think left saw
</figure>
<figureCaption confidence="0.999935">
Figure 1: Sample trees.
</figureCaption>
<listItem confidence="0.902608666666667">
(i) Interior nodes are labeled by non-
terminal symbols.
(ii) The nodes on the frontier of the tree
consist of zero or more non-terminal
symbols and one or more terminal sym-
bols.
</listItem>
<bodyText confidence="0.805422727272727">
(iii) The non-terminal symbols on the
frontier are marked for substitution. By
convention, this is annotated in dia-
grams using a down arrow (1).
Each auxiliary tree in the set A satisfies the
following requirements.
(i) Interior nodes are labeled by non-
terminal symbols.
(ii) The nodes on the frontier consist of
zero or more non-terminal symbols and
one or more terminal symbols.
</bodyText>
<listItem confidence="0.683617363636364">
(iii) All but one of the non-terminal sym-
bols on the frontier are marked for sub-
stitution.
(iv) The remaining non-terminal on the
frontier of the tree is called the foot. The
label on the foot must be identical to
the label on the root node of the tree.
By convention, the foot is indicated in
diagrams using an asterisk (*).
(v) the foot must be in either the leftmost
or the rightmost position on the frontier.
</listItem>
<bodyText confidence="0.998522257142857">
Figure 1, shows seven elementary trees that
might appear in an LCFG for English. The trees
containing &apos;boy&apos;, &apos;saw&apos;, and &apos;left&apos; are initial trees.
The remainder are auxiliary trees.
Auxiliary trees whose feet are leftmost are
called left recursive. Similarly, auxiliary trees
whose feet are rightmost are called right recursive
auxiliary trees. The path from the root of an aux-
iliary tree to the foot is called the spine.
In LCFG, trees can be combined with substi-
tution and adjunction. As illustrated in Figure 2,
substitution replaces a node marked for substitu-
tion with a copy of an initial tree.
Adjunction inserts a copy of an auxiliary tree
into another tree in place of an interior node that
has the same label as the foot of the auxiliary tree.
The subtree that was previously connected to the
interior node is reconnected to the foot of the copy
of the auxiliary tree. If the auxiliary tree is left re-
cursive, this is referred to as left recursive adjunc-
tion (see Figure 3). If the auxiliary tree is right
recursive, this is referred to as right recursive ad-
junction (see Figure 4).
Crucially, adjunction is constrained by requir-
ing that a left recursive auxiliary tree cannot be
adjoined on any node that is on the spine of a
right recursive auxiliary tree and a right recursive
auxiliary tree cannot be adjoined on the spine of
a left recursive auxiliary tree.
An LCFG derivation must start with an initial
tree rooted in S. After that, this tree can be re-
peatedly extended using substitution and adjunc-
tion. A derivation is complete when every frontier
node is labeled with a terminal symbol.
The difference between LCFG and LTAG is
</bodyText>
<figureCaption confidence="0.966515">
Figure 2: Substitution.
</figureCaption>
<page confidence="0.8684095">
122
w4
</page>
<figureCaption confidence="0.9591345">
Figure 3: Left recursive adjunction. Figure 5: Adjunction in LTAG.
existence of an initial tree where the filler and gap
are local. This accounts nicely for the pair of sen-
tences below. However, other analyses of wh ques-
tions may not require the use of the auxiliary tree
above.
</figureCaption>
<figure confidence="0.941844">
w 3
</figure>
<figureCaption confidence="0.999491">
Figure 4: Right recursive adjunction.
</figureCaption>
<bodyText confidence="0.9997629">
that LTAG allows the foot of an auxiliary tree
to appear anywhere on the frontier and places no
limitations on the interaction of auxiliary trees.
In this unlimited situation, adjunction encodes
string wrapping and is therefore more power-
ful than concatenation (see Figure 5). However,
the restrictions imposed by LCFG guarantee that
no context-sensitive operations can be achieved.
They limit the languages that can be generated by
LCFGs to those that can be generated by CFGs.
</bodyText>
<subsectionHeader confidence="0.858606">
Coverage of LCFG and LTAG
</subsectionHeader>
<bodyText confidence="0.999970333333333">
The power of LCFG is significantly less than
LTAG. Surprisingly, it turns out that there are
only two situations where the current LTAG gram-
mar for English (Abeille et al., 1990) fails to satisfy
the restrictions imposed by LCFG.
The first situation, concerns certain verbs that
take more than one sentential complement. An ex-
ample of such a verb is deduce., which is associated
with the following auxiliary tree.
</bodyText>
<figure confidence="0.860446285714286">
A
NPri. VP
AN
V SI* PP
A
deduce P
from
</figure>
<bodyText confidence="0.9938098">
Since this tree contains a foot node in the cen-
ter of its frontier, it is not part of an LCFG. Hav-
ing the foot on the first sentential complement is
convenient, because it allows one to use the stan-
dard LTAG wh-analyses, which depends on the
</bodyText>
<listItem confidence="0.99743925">
(1) John deduced that Mary watered the
grass from seeing the hose.
(2) What did John deduce that Mary wa-
tered from seeing the hose.
</listItem>
<bodyText confidence="0.58984875">
The second situation, concerns the way the
current LTAG explains the ambiguous attach-
ments of adverbial modifiers. For example, in the
sentence:
</bodyText>
<listItem confidence="0.993581">
(3) John said Bill left yesterday.
</listItem>
<bodyText confidence="0.998498846153846">
the attachment of yesterday is ambiguous. The
two different LTAG derivations indicated in Fig-
ure 6 represent this conveniently.
Unfortunately, in Leff.; the high attachment
of yesterday is forbidden since a right auxiliary
tree (corresponding to yesterday) is adjoined on
the spines of a left auxiliary tree (corresponding to
John said). However, one could avoid this prob-
lem by designing a mechanism to recover the high
attachment reading from the low one.
Besides the two cases presented above, the
current LTAG for English uses only left and right
recursive auxiliary trees and does not allow any
</bodyText>
<figure confidence="0.992652833333333">
NP VP
I......-...... ..
John V 5* ••... ,
&apos;&apos;&apos;... VP
.116.
S
AC.•
VP* ADV
...&amp;quot;.. &apos;
NP VP I
I I
left
</figure>
<figureCaption confidence="0.951064">
Figure 6: Two LTAG derivations for John said Bill
left yesterday.
</figureCaption>
<figure confidence="0.977281">
said
yesterday
Bill V
</figure>
<page confidence="0.995028">
123
</page>
<bodyText confidence="0.9683641875">
interaction along the spine of these two kinds of
trees. This agrees with the intuition that most
English analyses do not require a context-sensitive
operation.
Lexicalization of CFGs
The lexicalization of grammar formalisms is of in-
terest from a number of perspectives. It is of in-
terest from a linguistic perspective, because most
current linguistic theories give lexical accounts of a
number of phenomena that used to be considered
purely syntactic. It is of interest from a computa-
tional perspective, because lexicalized grammars
can be parsed significantly more efficiently than
non-lexicalized ones (Schabes and Joshi, 1990).
Formally, a grammar is said `lexicalized&apos; (Sch-
abes, Abeille., and Joshi, 1988) if it consists of:
</bodyText>
<listItem confidence="0.9887692">
• a finite set of elementary structures of finite size,
each of which contains an overt (i.e., non-empty)
lexical item.
• a finite set of operations for creating derived
structures.
</listItem>
<bodyText confidence="0.999594054054054">
The overt lexical item in an elementary struc-
ture is referred to as its anchor. A lexicalized
grammar can be organized as a lexicon where each
lexical item is associated with a finite number of
structures for which that item is the anchor.
In general, CFGs are not lexicalized since rules
such as S —&gt; NP VP that do not locally introduce
lexical items are allowed. In contrast, the well-
known Greibach Normal Form (GNF) for CFGs
is lexicalized, because every production rule is re-
quired to be of the form A aa (where a is a
terminal syrnbol, A a non-terminal symbol and a
a possibly empty string of non-terminal symbols)
and therefore locally introduces a lexical item a.
It can be shown that for any CFG G (that does
not derive the empty string), there is a GNF gram-
mar G&apos; that derives the same language. However,
it may be impossible for the set of trees produced
by G&apos; to be the same as the set of trees produced
by G.
Therefore, GNF achieves a kind of lexicaliza-
tion of CFGs. However, it is only a weak lexical-
ization, because the set of trees is not necessarily
preserved. As discussed in the motivation section,
strong lexicalization that preserves tree sets is pos-
sible using LTAG. However, this is achieved at the
cost of significant additional parsing complexity.
Heretofore, several attempts have been made
to lexicalize CFG with formalisms weaker than
LTAG, but without success. In particular, it is
not sufficient to merely extend substitution so that
it applies to trees. Neither is it sufficient to rely
solely on the kind restricted adjunction used by
LCFG. However, as shown below, combining ex-
tended substitution with restricted adjunction al-
lows strong lexicalization of CFG, without intro-
ducing greater parsing complexity than (JFG.
</bodyText>
<construct confidence="0.859067666666667">
Theorem If C = (E, NT, P„9) is a finitely
ambiguous CFG which does not generate the
empty string (E), then there is an LCFG G&apos; =
(E, NT, I, A„5) generating the same language and
tree set as G. Furthermore G&apos; can be chosen so
that it utilizes only left-recursive auxiliary trees.
</construct>
<bodyText confidence="0.997579961538461">
As usual in the above, a CFG G is a four-
tuple, (E, NT, P„9), where E is a set of terminal
symbols, NT is a set of non-terminal symbols, P is
a set of production rules that rewrite non-terminal
symbols to strings of terminal and non-terminal
symbols, and S is a distinguished non-terrninal
symbol that is the start symbol of any derivation.
To prove the theorem we first prove a some-
what weaker theorem and then extend the proof
to the full theorem. In particular, we assume for
the moment that the set of rules for G does not
contain any empty rules of the form A E.
Step 1 We begin the construction of G&apos; by con-
structing a directed graph LCC that we call the
left corner derivation graph. Paths in LCC cor-
respond to leftmost paths from root to frontier in
(partial) derivation trees rooted at non-terminal
symbols in G.
LCG contains a node for every symbol in EU
NT and an arc for every rule in P as follows.
For each terminal and non-terminal symbol
X in G create a node in LCC labeled with
X. For each rule X —&gt; Y a in G create a
directed arc labeled with X —&gt; Y a from the
node labeled with X to the node labeled Y.
As an example, consider the example CFG in
</bodyText>
<figureCaption confidence="0.999941">
Figure 7 and the corresponding LCC shown in
Figure 8.
</figureCaption>
<bodyText confidence="0.999881">
The significance of LCC is that there is a one-
to-one correspondence between paths in LCC end-
ing on a non-terminal and left corner derivations in
G. A left corner derivation in a CFG is a partial
derivation starting from any non-terminal where
every expanded node (other than the root) is the
leftrnost child of its parent and the left corner is a
non-terminal. A left corner derivation is uniquely
identified by the list of rules applied. Since G does
not have any empty rules, every rule in G is rep-
resented in LCC. Therefore, every path in LCC
ending on a terminal corresponds to a left corner
derivation in G and vice versa.
</bodyText>
<page confidence="0.981257">
124
</page>
<figure confidence="0.9998544">
S A A
S B A
A B B
B A S
B —&gt;b
</figure>
<figureCaption confidence="0.96787">
Figure 7: An example grammar.
</figureCaption>
<figure confidence="0.99794925">
S—BA
A—&gt;B8
A B
B—&gt;AS
</figure>
<figureCaption confidence="0.999994">
Figure 8: The LCG created by Step 1.
</figureCaption>
<bodyText confidence="0.999592041666667">
Step 2 The set of initial trees I for G&apos; is con-
structed with reference to LCG. In particular, an
initial tree is created corresponding to each non-
cyclic path in LCG that starts at a non-terminal
symbol X and ends on a terminal symbol y. (A
non-cyclic path is a path that does not touch any
node twice.)
For each non-cyclic path in LCG from X to
y, construct an initial tree T as follows. Start
with a root labeled X. Apply the rules in the
path one after another, always expanding the
left corner node of T. While doing this, leave
all the non-left corner non-terminal symbols
in T unexpanded, and label them as substi-
tution nodes.
Given the previous example grammar, this
step produces the initial trees shown in Figure 9.
Each initial tree created is lexicalized, because
each one has a non-terminal syrnbol as the left
corner element of its frontier. There are a finite
number of initial trees, because the number of non-
cyclic paths in LCG must be finite. Each initial
tree is finite in size, because each non-cyclic path
in LCG is finite in length.
Most irnportantly, The set of initial trees is
the set of non-recursive left corner derivations in
G.
Step 3 This step constructs a set of left-
recursive auxiliary trees corresponding to the
cyclic path segments in LCG that were ignored in
the previous step. In particular, an auxiliary tree
is created corresponding to each minimal cyclic
path in LCG that starts at a non-terminal sym-
bol.
For each minimal cycle in LCG from X to it-
self, construct an auxiliary tree T by starting
with a root labeled X and repeatedly expand-
ing left corner frontier nodes using the rules
in the path as in Step 2. When all the rules in
the path have been used, the left corner fron-
tier node in T will be labeled X. Mark this
as the foot node of T. While doing the above,
leave all the other non-terminal symbols in T
unexpanded, and label them all substitution
nodes.
The LCG in Figure 8 has two minimal cyclic
paths (one from A to A via B and one from B to
B via A). This leads to the the two auxiliary trees
shown in Figure 10, one for A and one for B.
The auxiliary trees generated in this step are
not necessarily lexicalized. There are a finite num-
ber of auxiliary trees, since the number of minimal
cyclic paths in G must be finite. Each auxiliary
tree is finite in size, because each minimal-cycle in
LCG is finite in length.
The set of trees that can be created by corn-
bining the initial trees from Step 2 with the auxil-
iary trees from Step 3 by adjoining auxiliary trees
along the left edge is the set of every left corner
derivation in G. To see this, consider that ev-
ery path in LCG can be represented as an initial
non-cyclic path with zero or more minimal cycles
inserted into it.
The set of trees that can be created by corn-
bining the initial trees from Step 2 with the auxil-
iary trees from Step 3 using both substitution and
adjunction is the set of every derivation in G. To
see this, consider that every derivation in G can
be decomposed into a set of left corner derivations
in G that are combined with substitution. In par-
ticular, whenever a non-terminal node is not the
leftmost child of its parent, it is the head of a sep-
</bodyText>
<figure confidence="0.9246515">
S—&gt;AA
B-÷b
</figure>
<figureCaption confidence="0.998627">
Figure 9: Initial trees created by Step 2. Figure 10: Auxiliary trees created by Step 3.
</figureCaption>
<page confidence="0.995576">
125
</page>
<bodyText confidence="0.996466945945946">
arate left corner derivation.
Step 4 This step lexicalizes the set of auxiliary
trees built in step 3, without altering the trees that
can be derived.
For each auxiliary tree T built in step 3, con-
sider the frontier node A just to the right of
the foot. If this node is a terminal do nothing-.
Otherwise, remove T from the set of auxiliary
trees replace it with every tree that can be
constructed by substituting one of the initial
trees created in Step 2 for the node A in T.
In the case of our continuing example, Step 4
results in the set of auxiliary trees in Figure 11.
Note that since G is finitely ambiguous, there
must be a frontier node to the right of the foot of
an auxiliary tree T. If not, then T would corre-
spond to a derivation XX in G and G would be
infinitely ambiguous.
After Step 4, every auxiliary tree is lexicalized,
since every tree that does not have a terminal to
the right of its foot is replaced by one or more trees
that do. Since there were only a finite number of
finite initial and auxiliary trees to start with, there
are still only a finite number of finite auxiliary
trees.
The change in the auxiliary trees caused by
Step 4 does not alter the set of trees that can be
produced in any way, because the only change that
was made was to make substitutions that could be
made anyway, and when a substitutable node was
eliminated, this was only done after every possible
substitution at that node was performed.
Note that the initial trees are left anchored
and the auxiliary trees are almost left anchored
in the sense that the leftmost frontier node other
than the foot is a terminal. This facilitates effi-
cient left to right parsing.
</bodyText>
<figureCaption confidence="0.970336">
Figure 11: Auxiliary trees created by Step 4.
</figureCaption>
<bodyText confidence="0.965101625">
The procedure above creates a lexicalized
grammar that generates exactly the same trees as
G and therefore the same strings. The only re-
maining issue is the additional assumption that G
does not contain any empty rules.
If G contains an empty rule A e one first
uses standard methods to transform G into an
equivalent grammar H that does not have any
such rule. When doing this, create a table showing
how each new rule added is related to the empty
rules removed. Lexicalize H producing H&apos; using
the procedure above. Derivations in H&apos; result in
elements of the tree set of H. By means of the ta-
ble recording the relationship between G and H,
these trees can be converted to derivations in G.
0
</bodyText>
<subsectionHeader confidence="0.717436">
Additional issues
</subsectionHeader>
<bodyText confidence="0.999788578947368">
There are several places in the algorithm where
greater freedom of choice is possible. For instance,
when lexicalizing the auxiliary trees created in
Step 3, you need not do anything if there is any
frontier node that is a terminal and you can choose
to expand any frontier node you want. For in-
stance you might want to choose the node that
corresponds to the smallest number of initial trees.
Alternatively, everywhere in the procedure,
the word &apos;left&apos; can be replaced by &apos;right&apos; and vice
versa. This results in the creation of a set of right
anchored initial trees and right recursive auxiliary
trees. This can be of interest when the right cor-
ner derivation graph has less cycles than the left
corner one.
The number of trees in 6&amp;quot; is related to the
number of non-cyclic and minimal cycle paths in
LUG. In the worst case, this number rises very
fast as a function of the number of arcs in LUG,
(i.e., in the number of rules in G). (A fully con-
nected graph of 712 arcs between 7/ nodes has n!
acyclic paths and n! minimal cycles.) However, in
the typical case, this kind of an explosion of trees
is unlikely.
Just as there can be many ways for a CFG
to derive a given string, there can be many ways
for an LCFG to derive a given tree. For maximal
efficiency, it would be desirable for the grammar
G&apos; produced by the procedure above to have no
ambiguity in they way trees are derived. Unfortu-
nately, the longer the minimal cycles in LUG, the
greater the tree-generating ambiguity the proce-
dure will introduce in G&apos;. However, by modifying
the procedure to make use of constraints on what
auxiliary trees are allowed to adjoin on what nodes
in which initial trees, it should be possible to re-
duce or even eliminate this ambiguity.
All these issues are discussed at greater length
</bodyText>
<page confidence="0.996032">
126
</page>
<bodyText confidence="0.732311">
in Schabes and Waters (1993).
</bodyText>
<subsectionHeader confidence="0.791136">
Parsing LCFG
</subsectionHeader>
<bodyText confidence="0.999862848484849">
Since LCFG is a restricted case of tree-adjoining
grammar (TAG), standard 0(71.6)-time TAG
parsers (Vijay-Shanker, 1987; Schabes, 1991;
Lang, 1990) can be used for parsing LCFG. Fur-
ther, they can be straightforwardly modified to re-
quire at most 0(70)-time when applied to LCFG.
However, this still does not take full advantage of
the context-freeness of LCFG.
This section describes a simple bottom-up
recognizer for LCFG that is in the style of the
CKY parser for CFG. The virtue of this algo-
rithm is that it shows in a simple manner how the
0(7/3)-tirrie worst case complexity can be achieved
for LCFG. Schabes and Waters (1993) describes a
more practical and more elaborate (Earley-style)
recognizer for LCFG, which achieves the same
bounds.
Suppose that G = (E,NT,I,A„S&apos;) is an
LCFG and that al • • • (4, is an input string. We
can assume without loss of generalityl that every
node in I U A has at most two children.
Let 71 be a node in an elementary tree (identi-
fied by the name of the tree and the position of the
node in the tree). The central concept of the al-
gorithm is the concepts of spanning and covering.
7) spans a string ai+i • • • aj if and only if there is
sorne tree derived by G for which it is the case that
the fringe of the subtree rooted at y is ai+i • • • aj.
In particular, a non-terminal node spans aj if and
only if the label on the node is aj. A non-terminal
node spans ai+i • • aj if and only if ai+i • • aj is
the concatenation in left to right order of strings
spanned by the children of the node.
</bodyText>
<listItem confidence="0.963239230769231">
• If 71 does not subsume the foot node of an aux-
iliary tree then: n covers the string ai+i • • aj if
and only if it spans ai+i • • • a1.
• If 7) is on the spine of a right recursive auxiliary
tree T then: y covers ai+i • • • aj if and only if
71 spans some string that is the concatenation
of ai+i • • aj and a string spanned by the foot
of T. (This situation is illustrated by the right
drawing in Figure 12, in which 7) is labeled with
B.)
• If 7) is on the spine of a left recursive auxiliary
tree T then: y covers ai+i • • aj if and only if 71
spans some string that is the concatenation of a
</listItem>
<bodyText confidence="0.969042333333333">
string spanned by the foot of T and ai+i • • aj.
(This situation is illustrated by the left drawing
in Figure 12, in which y is labeled with B.)
</bodyText>
<footnote confidence="0.806888333333333">
&apos;It can be easily shown that by adding new nodes
any LCFG can be transformed into an equivalent
LCFG satisfying this condition.
</footnote>
<figure confidence="0.589418666666667">
AdA
a. •-• a. A.
A ,±1 j 1+1
</figure>
<figureCaption confidence="0.986087">
Figure 12: Coverage of nodes on the spine.
</figureCaption>
<bodyText confidence="0.9995534">
The algorithm stores pairs of the form (7), pos)
in an n by n array C. In a pair, pos is either t (for
top) or b (for bottom). For every node 7) in every
elementary tree in G, the algorithm guarantees the
following.
</bodyText>
<listItem confidence="0.971650666666667">
• (7i, b) E C[i, j] if and only if 7) covers ai+i • • -aj.
• (7), t) E C[i, j] if and only if 0,6) E C[i, j] or
ai+i • • aj is the concatenation (in either order)
</listItem>
<bodyText confidence="0.96978455">
of a string covered by 71 and a string covered by
an auxiliary tree that can be adjoined on 7).
The algorithm fills the upper diagonal portion
of the array C[i, j] (0 &lt; i &lt; j &lt; n) for increasing
values of j — i. The process starts by placing each
foot node in every cell C[i, i] and each terminal
node y in every cell C[i, i 1] where y is labeled
(4+1.
The algorithm then considers all possible ways
of combining covers into longer covers. In particu-
lar, it fills the cells C[i, i k] for increasing values
of k by combining elements from the cells C[i, j]
and C[j, i k] for all j such that i&lt; j&lt;i+k.
There are three situations where cornbination is
possible: sibling concatenation, left recursive con-
catenation, and right recursive concatenation.
Sibling concatenation is illustrated in Fig-
ure 13. Suppose that there is a node yo (labeled B)
with two children yi (labeled A) and in (labeled
A&apos;). If (7)1,t) E C[i, j] and (/)2, t) E C[j, i+ k] then
</bodyText>
<equation confidence="0.567685">
(7/o, b) E C[i, i k].
</equation>
<bodyText confidence="0.965372222222222">
Left recursive concatenation is illustrated in
Figure 14. Here, the cover of a node is combined
with the cover of a left auxiliary tree that can be
adjoined at the node. Right recursive concatena-
tion, which is shown in Figure 15 is analogous.
For simplicity, the recognizer is written in
two parts. A main procedure and a subpro-
cedure Add(node, pos, j), which adds the pair
(node, pos) into C[i, j].
</bodyText>
<figure confidence="0.72582">
a a
j + 1 k
</figure>
<figureCaption confidence="0.994762">
Figure 13: Sibling concatenation.
</figureCaption>
<equation confidence="0.338165">
ai+1 — ak
</equation>
<page confidence="0.833345">
127
</page>
<figure confidence="0.911028388888889">
Procedure recognizer
begin
a.
1+1 J
A*a.
J+1 k
;; foot node initialization (C[i, i])
for i = 0 to 71
for all foot node zi in A call
Add(7), b, i, i)
terminal node initialization (C[i,i I])
for i = 0 to n — 1
for all node y in A U I labeled by ai+1
call Add(?), t , 1, i + 1)
induction (C[i, i + k] = C[i, j] + C[j,i + k])
for k = 2 to 11
for i = 0 to n — k
for j = i + 1 to i + k — 1
</figure>
<construct confidence="0.903663666666667">
;; sibling concatenation
if (7/1,1) E C[i, j]
and (7/2, t) E C[j, i + k]
and yi is the left sibling of 712
with common parent yo
then Add(yo, b, i, i + k)
;; left recursive concatenation
if (i1, b) E C[i, j]
and (pt) C[j,i + k]
and p is the root node of a left recursive
auxiliary tree that can adjoin on y
then Add(y,t,i,i+ k)
;; right recursive concatenation
if b) E C[j, i+ k]
and (p,t) E C[i,
</construct>
<bodyText confidence="0.904848571428571">
and p is the root node of a right recursive
auxiliary tree that can adjoin on 71
then Add(?), 1, i, i + k)
If t) E C[0, n]
and 71 is labeled by S
and y is the root node of an initial tree in I
then return acceptance
otherwise return rejection
end
Note that the sole purpose of the codes t and b
is to insure that only one auxiliary tree can adjoin
on a node. The procedure could easily be mod-
ified to account for other constraints on the way
derivation should proceed such as those suggested
for LTAGs (Schabes and Shieber, 1992).
The procedure Add puts a pair into the array
C. If the pair is already present, nothing is done.
However, if it is new, it is added to C and other
pairs may be added as well. These correspond to
cases where the coverage is not increased: when
a node is the only child of its parent, when the
</bodyText>
<figureCaption confidence="0.967941">
Figure 14: Left recursive concatenation.
</figureCaption>
<figure confidence="0.991423">
A
a&amp;quot; ak a i+1 a k
</figure>
<figureCaption confidence="0.997866">
Figure 15: Right recursive concatenation.
</figureCaption>
<bodyText confidence="0.6773895">
node is recognized without adjunction, and when
substitution occurs.
</bodyText>
<construct confidence="0.8826136">
Procedure Add(?), pos, i, j)
begin
Put (7/, pos) in C[i, j]
if pos = t and y is the only child of a parent it
call Add(/L, b, i, j)
</construct>
<bodyText confidence="0.937705235294118">
if pos = t and y is the root node of an
initial tree, for each substitution node p
at which y can substitute call Add(p, t, i, j)
no adjunction
if pos =b
if the node n does not have an OA constraint
call Add(y, 1,i, j)
end
The 0(0) complexity of the recognizer fol-
lows from the three nested induction loops on k, i
and j. (Although the procedure Add is defined
recursively, the number of pairs added to C is
bounded by a constant that is independent of sen-
tence length.)
By recording how each pair was introduced in
each cell of the array C, one can easily extend the
recognizer to produce all derivations of the input.
</bodyText>
<sectionHeader confidence="0.902592" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.9999594">
LCFG combines rnuch of the power of LTAG with
the computational efficiency of CFG. It supports
most of the same linguistic analysis supported by
LTAG. In particular, most of the current LTA(.
for English falls into LCF(. In addition, LCF(
can lexicalize (.FG without altering the trees pro-
duced. Finally, LCFG can be parsed in 0(n3)-
time.
There are many directions in which the work
on LCFG described here could be extended. In
</bodyText>
<page confidence="0.993389">
128
</page>
<bodyText confidence="0.996946333333333">
particular, one could consider stochastic exten-
sions, LR parsing, and non-deterministic LR, pars-
ing.
</bodyText>
<sectionHeader confidence="0.992698" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9994">
We thank John Coleman who, by question-
ing whether the context-sensitivity of stochastic
LTAG was actually being used for English, trig-
gered this work. We thank Aravind Joshi, Fer-
nando Pereira, Stuart Shieber and B. Srinivas for
valuable discussions.
</bodyText>
<sectionHeader confidence="0.998789" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.998112363636363">
Abeille, Anne, Kathleen M. Bishop, Sharon Cote,
and Yves Schabes. 1990. A lexicalized tree
adjoining grammar for English. Technical Re-
port MS-CIS-90-24, Department of Computer
and Information Science, University of Penn-
sylvania.
Joshi, Aravind K. and Yves Schabes. 1992. Tree-
adjoining grammars and lexicalized gram-
mars. In Maurice Nivat and Andreas Podel-
ski, editors, Tree Automata and Languages.
Elsevier Science.
Joshi, Aravind K., K. Vijay-Shanker, and David
Weir. 1991. The convergence of rnildly
context-sensitive grarnmatical formalisms. In
Peter Sells, Stuart Shieber, and Tom Wasow,
editors, Foundational Issues in Natural Lan-
guage Processing. MIT Press, Cambridge MA.
Lang, Bernard. 1990. The systematic construc-
tions of Earley parsers: Application to the
production of 0(7/6) Earley parsers for Tree
Adjoining Grammars, In Proceedings of the
1st International Workshop on Tree Adjoining
Grammars, Dagstuhl Castle, FRG, August.
Schabes, Yves, Anne Abeille, and Aravind K.
Joshi. 1988. Parsing strategies with &apos;lexical-
ized&apos; grammars: Application to tree adjoining
grarnmars. In Proceedings of the 12Th Interna-
tional Conference on Computational Linguis-
tics (COLING&apos;88), Budapest, Hungary, Au-
gust.
Schabes, Yves and Aravind K. Joshi. 1990. Pars-
ing with lexicalized tree adjoining grammar.
In Masaru Tomita, editor, Current Issues
in Parsing Technologies. Kluwer Accademic
Publishers.
Schabes, Yves and Stuart Shieber. 1992. An al-
ternative conception of tree-adjoining deriva-
tion. In 20th Meeting of the Association for
Computational Linguistics (ACL&apos;92).
Schabes, Yves and Richard C. Waters. 1993. Lex-
icalized context-free grammar: A cubic-time
parsable formalism that strongly lexicalizes
context-free grammar. Technical Report 93-
04, Mitsubishi Electric Research Laboratories,
201 Broadway. Cambridge MA 02139.
Schabes, Yves. 1991. The valid prefix prop-
erty and left to right parsing of tree-adjoining
grammar. In Proceedings of the second Inter-
national Workshop on Parsing Technologies,
Cancun, Mexico, February.
Vijay-Shanker, K. and David Weir. 1993a. The
equivalence of four extensions of context-free
grammars. To appear in Mathematical Sys-
tems Theory.
Vijay-Shanker, K. and David Weir. 1993b. Pars-
ing some constrained grammar formalisms.
To appear in Computational Linguistics.
Vijay-Shanker, K. 1987. A Study of Tree Adjoin-
ing Grammars. Ph.D. thesis, Department of
Computer and Inforrnation Science, Univer-
sity of Pennsylvania.
Weir, David J. 1988. Character-
izing Mildly Context-Sensitive Grammar For-
malisms. Ph.D. thesis, Department of Com-
puter and Information Science, University of
Pennsylvania.
</reference>
<page confidence="0.998549">
129
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9999">Lexicalized Context-Free Grammars</title>
<author confidence="0.998209">Yves Schabes</author>
<author confidence="0.998209">Richard C Waters</author>
<affiliation confidence="0.998923">Mitsubishi Electric Research Laboratories</affiliation>
<address confidence="0.999945">201 Broadway, Cambridge, MA 02139</address>
<email confidence="0.99729">e-mail:schabes©merl.comanddick(Omerl.com</email>
<abstract confidence="0.978524090909091">Lexicalized context-free grammar (L(.FG) is an attractive compromise between the parsing efficiency of context-free grammar (CF() and the elegance and lexical sensitivity of lexicalized treeadjoining grammar (LTA(). LCFG is a restricted form of LTAG that can only generate contextfree languages and can be parsed in cubic time. However, LCFG supports much of the elegance of LTAG&apos;s analysis of English and shares with LTAG the ability to lexicalize CFGs without changing the trees generated. Motivation Context-free grammar (CFG) has been a well accepted framework for computational linguistics for a long time. While it has drawbacks, including the inability to express some linguistic constructions, it has the virtue of being computationally efficient, 0(0)-time in the worst case. Recently there has been a gain in interest in the so-called &apos;mildly&apos; context-sensitive formalisms (Vijay-Shanker, 1987; Weir, 1988; Joshi, Vijay- Shanker, and Weir, 1991; Vijay-Shanker and Weir, 1993a) that generate only a small superset of context-free languages. One such formalism is lexicalized tree-adjoining grammar (LTAG) (Schabes, Abeille, and Joshi, 1988; Abeille et al., 1990; Joshi and Schabes, 1992), which provides a number of attractive properties at the cost of decreased in the worst case (Vijay- Shanker, 1987; Schabes, 1991; Lang, 1990; Vijay- Shanker and Weir, 1993b). An LTAG lexicon consists of a set of trees each of which contains one or more lexical items. These elementary trees can be viewed as the elementary clauses (including their transformational variants) in which the lexical items participate. The trees are combined by substitution and adjunction. LTAG supports context-sensitive features that can capture some language constructs not captured by CFG. However, the greatest virtue of LTAG is that it is lexicalized and supports extended domains of locality. The lexical nature of LTAG is of linguistic interest, since it is believed that the descriptions of many linguistic phenomena are dependent upon lexical data. The extended domains allow for the localization of most syntactic and sernantic dependencies (e.g., fillergap and predicate-argument relationships). A further interesting aspect of LTAG is its ability to lexicalize CFGs. One can convert a CFG into an LTAG that preserves the original trees (Joshi and Schabes, 1992). Lexicalized context-free grammar (LCFG) is an attractive compromise between LTAG and CFG, that combines many of the virtues of LTAG with the efficiency of CFG. LCFG is a restricted form of LTAG that places further limits on the elementary trees that are possible and on the way adjunction can be performed. These restrictions limit LCFG to producing only context-free lanand allow LCFG to be parsed in time in the worst case. However, LCFG retains most of the key features of LTAG enumerated above. In particular, most of the current LTAG grammar for English (Abeille et al., 1990) follows the restrictions of LCFG. This is of significant practical interest because it means that the processing of these analyses does not require more computational resources than CFGs. In addition, any CFG can be transformed into an equivalent LCFG that generates the same trees (and therefore the same strings). This result breaks new ground, because heretofore every method of lexicalizing CFGs required contextsensitive operations (Joshi and Schabes, 1992). The following sections briefly, define LCFG, discuss its relationship to the current LTAG grammar for English, prove that LCFG can be used to lexicalize CFG, and present a simple cubic-time parser for LCFG. These topics are discussed in greater detail in Schabes and Waters (1993). 121 Lexicalized Context-Free Grammars Like an LTAG, an LCFG consists of two sets of trees: initial trees, which are combined by substitution and auxiliary trees, which are combined by adjunction. An LCFG is lexicalized in the sense that every initial and auxiliary tree is required to contain at least one terminal symbol on its frontier. More precisely, an LCFG is a five-tuple I, A „9), E is a set of terminal syma set of non-terminal symbols, / and sets of trees labeled by terminal and nonsymbols, and a distinguished nonterminal start symbol. Each initial tree in the set / satisfies the following requirements.</abstract>
<title confidence="0.873971333333333">NP VP VP A A A N V VP* A N* VP* Adv</title>
<abstract confidence="0.975845810483871">boy seems pretty smoothly VP VP VP I S NA NPI1 think left saw Figure 1: Sample trees. (i) Interior nodes are labeled by nonterminal symbols. (ii) The nodes on the frontier of the tree consist of zero or more non-terminal symbols and one or more terminal symbols. (iii) The non-terminal symbols on the frontier are marked for substitution. By convention, this is annotated in diagrams using a down arrow (1). Each auxiliary tree in the set A satisfies the following requirements. (i) Interior nodes are labeled by nonterminal symbols. (ii) The nodes on the frontier consist of zero or more non-terminal symbols and one or more terminal symbols. (iii) All but one of the non-terminal symbols on the frontier are marked for substitution. (iv) The remaining non-terminal on the of the tree is called the label on the foot must be identical to the label on the root node of the tree. By convention, the foot is indicated in diagrams using an asterisk (*). (v) the foot must be in either the leftmost or the rightmost position on the frontier. Figure 1, shows seven elementary trees that might appear in an LCFG for English. The trees containing &apos;boy&apos;, &apos;saw&apos;, and &apos;left&apos; are initial trees. The remainder are auxiliary trees. Auxiliary trees whose feet are leftmost are recursive. auxiliary trees feet are rightmost are called recursive auxiliary trees. The path from the root of an auxtree to the foot is called the In LCFG, trees can be combined with substitution and adjunction. As illustrated in Figure 2, substitution replaces a node marked for substitution with a copy of an initial tree. Adjunction inserts a copy of an auxiliary tree into another tree in place of an interior node that has the same label as the foot of the auxiliary tree. The subtree that was previously connected to the interior node is reconnected to the foot of the copy of the auxiliary tree. If the auxiliary tree is left recursive, this is referred to as left recursive adjunction (see Figure 3). If the auxiliary tree is right recursive, this is referred to as right recursive adjunction (see Figure 4). Crucially, adjunction is constrained by requiring that a left recursive auxiliary tree cannot be adjoined on any node that is on the spine of a right recursive auxiliary tree and a right recursive auxiliary tree cannot be adjoined on the spine of a left recursive auxiliary tree. An LCFG derivation must start with an initial rooted in that, this tree can be repeatedly extended using substitution and adjunction. A derivation is complete when every frontier node is labeled with a terminal symbol. The difference between LCFG and LTAG is Figure 2: Substitution. 122 Figure 3: Left recursive adjunction. Figure 5: Adjunction in LTAG. existence of an initial tree where the filler and gap are local. This accounts nicely for the pair of sen-tences below. However, other analyses of wh ques-tions may not require the use of the auxiliary tree above. w3 Figure 4: Right recursive adjunction. that LTAG allows the foot of an auxiliary tree to appear anywhere on the frontier and places no limitations on the interaction of auxiliary trees. In this unlimited situation, adjunction encodes string wrapping and is therefore more powerful than concatenation (see Figure 5). However, the restrictions imposed by LCFG guarantee that no context-sensitive operations can be achieved. They limit the languages that can be generated by LCFGs to those that can be generated by CFGs. Coverage of LCFG and LTAG The power of LCFG is significantly less than LTAG. Surprisingly, it turns out that there are only two situations where the current LTAG grammar for English (Abeille et al., 1990) fails to satisfy the restrictions imposed by LCFG. The first situation, concerns certain verbs that take more than one sentential complement. An exof such a verb is is associated with the following auxiliary tree. A VP AN PP A deduce P from Since this tree contains a foot node in the center of its frontier, it is not part of an LCFG. Having the foot on the first sentential complement is convenient, because it allows one to use the standard LTAG wh-analyses, which depends on the (1) John deduced that Mary watered the grass from seeing the hose. (2) What did John deduce that Mary watered from seeing the hose. The second situation, concerns the way the current LTAG explains the ambiguous attachments of adverbial modifiers. For example, in the sentence: (3) John said Bill left yesterday. attachment of ambiguous. The two different LTAG derivations indicated in Figure 6 represent this conveniently. Unfortunately, in Leff.; the high attachment forbidden since a right auxiliary (corresponding to adjoined on the spines of a left auxiliary tree (corresponding to said). one could avoid this problem by designing a mechanism to recover the high attachment reading from the low one. Besides the two cases presented above, the current LTAG for English uses only left and right recursive auxiliary trees and does not allow any NP VP .. V 5* , &apos;&apos;&apos;... VP S VP* ADV NP VP I I I left 6: Two LTAG derivations for said Bill left yesterday. said yesterday Bill V 123 interaction along the spine of these two kinds of trees. This agrees with the intuition that most English analyses do not require a context-sensitive operation. Lexicalization of CFGs The lexicalization of grammar formalisms is of interest from a number of perspectives. It is of interest from a linguistic perspective, because most current linguistic theories give lexical accounts of a number of phenomena that used to be considered purely syntactic. It is of interest from a computational perspective, because lexicalized grammars can be parsed significantly more efficiently than non-lexicalized ones (Schabes and Joshi, 1990). Formally, a grammar is said `lexicalized&apos; (Schabes, Abeille., and Joshi, 1988) if it consists of: • a finite set of elementary structures of finite size, each of which contains an overt (i.e., non-empty) lexical item. • a finite set of operations for creating derived structures. The overt lexical item in an elementary structure is referred to as its anchor. A lexicalized grammar can be organized as a lexicon where each lexical item is associated with a finite number of structures for which that item is the anchor. In general, CFGs are not lexicalized since rules as —&gt; NP VP do not locally introduce lexical items are allowed. In contrast, the wellknown Greibach Normal Form (GNF) for CFGs lexicalized, because every production rule is reto be of the form aa a is a syrnbol, non-terminal symbol and a a possibly empty string of non-terminal symbols) and therefore locally introduces a lexical item a. can be shown that for any CFG does not derive the empty string), there is a GNF gramderives the same language. However, it may be impossible for the set of trees produced be the same as the set of trees produced Therefore, GNF achieves a kind of lexicalizaof CFGs. However, it is only a lexicalization, because the set of trees is not necessarily preserved. As discussed in the motivation section, that preserves tree sets is possible using LTAG. However, this is achieved at the cost of significant additional parsing complexity. Heretofore, several attempts have been made to lexicalize CFG with formalisms weaker than LTAG, but without success. In particular, it is not sufficient to merely extend substitution so that it applies to trees. Neither is it sufficient to rely solely on the kind restricted adjunction used by LCFG. However, as shown below, combining extended substitution with restricted adjunction allows strong lexicalization of CFG, without introducing greater parsing complexity than (JFG. C = ambiguous CFG which does not generate the empty string (E), then there is an LCFG G&apos; = I, A„5) generating the same language and tree set as G. Furthermore G&apos; can be chosen so that it utilizes only left-recursive auxiliary trees. usual in the above, a CFG a four- (E, P„9), E is a set of terminal a set of non-terminal symbols, a set of production rules that rewrite non-terminal symbols to strings of terminal and non-terminal and a distinguished non-terrninal symbol that is the start symbol of any derivation. To prove the theorem we first prove a somewhat weaker theorem and then extend the proof to the full theorem. In particular, we assume for moment that the set of rules for not any empty rules of the form 1 We begin the construction of cona directed graph we call the corner derivation graph. in correspond to leftmost paths from root to frontier in (partial) derivation trees rooted at non-terminal in a node for every symbol in EU an arc for every rule in P as follows. For each terminal and non-terminal symbol a node in with each rule —&gt; Y a a arc labeled with —&gt; Y a the labeled with the node labeled Y. As an example, consider the example CFG in 7 and the corresponding in Figure 8. significance of that there is a onecorrespondence between paths in ending on a non-terminal and left corner derivations in left corner derivation in a CFG is a partial derivation starting from any non-terminal where every expanded node (other than the root) is the leftrnost child of its parent and the left corner is a non-terminal. A left corner derivation is uniquely by the list of rules applied. Since have any empty rules, every rule in repin every path in ending on a terminal corresponds to a left corner in vice versa.</abstract>
<date confidence="0.308399">124</date>
<title confidence="0.956578">S A A S B A A B B B A S</title>
<note confidence="0.452572333333333">B —&gt;b Figure 7: An example grammar. S—BA A—&gt;B8 A B B—&gt;AS 8: The by Step 1. 2 The set of initial trees conwith reference to particular, an</note>
<abstract confidence="0.993139842519684">initial tree is created corresponding to each nonpath in starts at a non-terminal ends on a terminal symbol y. (A non-cyclic path is a path that does not touch any node twice.) each non-cyclic path in construct an initial tree follows. Start a root labeled the rules in the path one after another, always expanding the corner node of doing this, leave all the non-left corner non-terminal symbols and label them as substitution nodes. Given the previous example grammar, this step produces the initial trees shown in Figure 9. Each initial tree created is lexicalized, because each one has a non-terminal syrnbol as the left corner element of its frontier. There are a finite number of initial trees, because the number of nonpaths in be finite. Each initial tree is finite in size, because each non-cyclic path finite in length. Most irnportantly, The set of initial trees is the set of non-recursive left corner derivations in G. Step 3 This step constructs a set of leftrecursive auxiliary trees corresponding to the cyclic path segments in LCG that were ignored in the previous step. In particular, an auxiliary tree is created corresponding to each minimal cyclic in starts at a non-terminal symbol. each minimal cycle in itconstruct an auxiliary tree starting a root labeled repeatedly expanding left corner frontier nodes using the rules in the path as in Step 2. When all the rules in the path have been used, the left corner fronnode in be labeled this the foot node of doing the above, all the other non-terminal symbols in unexpanded, and label them all substitution nodes. Figure 8 has two minimal cyclic (one from A via one from leads to the the two auxiliary trees in Figure 10, one for one for The auxiliary trees generated in this step are not necessarily lexicalized. There are a finite number of auxiliary trees, since the number of minimal paths in be finite. Each auxiliary tree is finite in size, because each minimal-cycle in finite in length. The set of trees that can be created by cornbining the initial trees from Step 2 with the auxiliary trees from Step 3 by adjoining auxiliary trees along the left edge is the set of every left corner in see this, consider that evpath in be represented as an initial non-cyclic path with zero or more minimal cycles inserted into it. The set of trees that can be created by cornbining the initial trees from Step 2 with the auxiliary trees from Step 3 using both substitution and is the set of every derivation in this, consider that every derivation in be decomposed into a set of left corner derivations are combined with substitution. In particular, whenever a non-terminal node is not the child of its parent, it is the head of a sep- S—&gt;AA B-÷b Figure 9: Initial trees created by Step 2. Figure 10: Auxiliary trees created by Step 3. 125 arate left corner derivation. Step 4 This step lexicalizes the set of auxiliary trees built in step 3, without altering the trees that can be derived. each auxiliary tree in step 3, conthe frontier node to the right of foot. If this node is a terminal do remove the set of auxiliary trees replace it with every tree that can be constructed by substituting one of the initial created in Step 2 for the node In the case of our continuing example, Step 4 results in the set of auxiliary trees in Figure 11. Note that since G is finitely ambiguous, there must be a frontier node to the right of the foot of auxiliary tree not, then correto a derivation G would be infinitely ambiguous. After Step 4, every auxiliary tree is lexicalized, since every tree that does not have a terminal to the right of its foot is replaced by one or more trees that do. Since there were only a finite number of finite initial and auxiliary trees to start with, there are still only a finite number of finite auxiliary trees. The change in the auxiliary trees caused by Step 4 does not alter the set of trees that can be produced in any way, because the only change that was made was to make substitutions that could be made anyway, and when a substitutable node was eliminated, this was only done after every possible substitution at that node was performed. Note that the initial trees are left anchored and the auxiliary trees are almost left anchored in the sense that the leftmost frontier node other than the foot is a terminal. This facilitates efficient left to right parsing. Figure 11: Auxiliary trees created by Step 4. The procedure above creates a lexicalized grammar that generates exactly the same trees as therefore the same strings. The only reissue is the additional assumption that does not contain any empty rules. G contains an empty rule A first standard methods to transform an grammar does not have any such rule. When doing this, create a table showing how each new rule added is related to the empty removed. Lexicalize procedure above. Derivations in in of the tree set of means of the tarecording the relationship between trees can be converted to derivations in 0 Additional issues There are several places in the algorithm where greater freedom of choice is possible. For instance, when lexicalizing the auxiliary trees created in Step 3, you need not do anything if there is any frontier node that is a terminal and you can choose to expand any frontier node you want. For instance you might want to choose the node that corresponds to the smallest number of initial trees. Alternatively, everywhere in the procedure, the word &apos;left&apos; can be replaced by &apos;right&apos; and vice versa. This results in the creation of a set of right anchored initial trees and right recursive auxiliary trees. This can be of interest when the right corner derivation graph has less cycles than the left corner one. The number of trees in 6&amp;quot; is related to the number of non-cyclic and minimal cycle paths in the worst case, this number rises very as a function of the number of arcs in in the number of rules in fully congraph of arcs between has n! acyclic paths and n! minimal cycles.) However, in the typical case, this kind of an explosion of trees is unlikely. Just as there can be many ways for a CFG to derive a given string, there can be many ways for an LCFG to derive a given tree. For maximal efficiency, it would be desirable for the grammar by the procedure above to have no ambiguity in they way trees are derived. Unfortuthe longer the minimal cycles in greater the tree-generating ambiguity the procedure will introduce in G&apos;. However, by modifying the procedure to make use of constraints on what auxiliary trees are allowed to adjoin on what nodes in which initial trees, it should be possible to reduce or even eliminate this ambiguity. All these issues are discussed at greater length 126 in Schabes and Waters (1993). Parsing LCFG Since LCFG is a restricted case of tree-adjoining (TAG), standard TAG parsers (Vijay-Shanker, 1987; Schabes, 1991; Lang, 1990) can be used for parsing LCFG. Further, they can be straightforwardly modified to require at most 0(70)-time when applied to LCFG. However, this still does not take full advantage of the context-freeness of LCFG. This section describes a simple bottom-up recognizer for LCFG that is in the style of the CKY parser for CFG. The virtue of this algorithm is that it shows in a simple manner how the worst case complexity can be achieved for LCFG. Schabes and Waters (1993) describes a more practical and more elaborate (Earley-style) recognizer for LCFG, which achieves the same bounds. that = (E,NT,I,A„S&apos;) an and that • • • (4, is an input string. We assume without loss of that every in U A at most two children. a node in an elementary tree (identified by the name of the tree and the position of the node in the tree). The central concept of the alis the concepts of spans a string • • • if and only if there is tree derived by which it is the case that fringe of the subtree rooted at y is • • • aj. In particular, a non-terminal node spans aj if and if the label on the node is A non-terminal spans • • aj if and only if • • aj is the concatenation in left to right order of strings spanned by the children of the node. If not subsume the foot node of an auxtree then: ncovers the string • • if only if it spans • • • a1. • If 7) is on the spine of a right recursive auxiliary y covers • • • aj if and only if some string that is the concatenation • • aj and a string spanned by the foot situation is illustrated by the right in Figure 12, in which labeled with B.) If on the spine of a left recursive auxiliary y covers • • aj if and only if spans some string that is the concatenation of a spanned by the foot of • • (This situation is illustrated by the left drawing in Figure 12, in which y is labeled with B.) &apos;It can be easily shown that by adding new nodes any LCFG can be transformed into an equivalent LCFG satisfying this condition. AdA •-• a. 1+1 Figure 12: Coverage of nodes on the spine. algorithm stores pairs of the form pos) an n by n array a pair, either or bottom). For every node every tree in algorithm guarantees the following. (7i, C[i, and only if 7) covers • • (7), j] and only if 0,6) j] • • aj is the concatenation (in either order) a string covered by a string covered by an auxiliary tree that can be adjoined on 7). The algorithm fills the upper diagonal portion the array j] &lt; i &lt; n) for increasing of process starts by placing each node in every cell C[i, each terminal y in every cell 1] where y is labeled The algorithm then considers all possible ways of combining covers into longer covers. In particuit fills the cells increasing values combining elements from the cells C[i, C[j, i all that j&lt;i+k. There are three situations where cornbination is possible: sibling concatenation, left recursive concatenation, and right recursive concatenation. Sibling concatenation is illustrated in Fig- 13. Suppose that there is a node (labeled B) two children (labeled A) and If j] b) E i Left recursive concatenation is illustrated in Figure 14. Here, the cover of a node is combined with the cover of a left auxiliary tree that can be adjoined at the node. Right recursive concatenation, which is shown in Figure 15 is analogous. For simplicity, the recognizer is written in two parts. A main procedure and a subpropos, j), adds the pair pos) j]. aa + 1 Figure 13: Sibling concatenation. — ak 127 Procedure recognizer begin a. 1+1 J A*a. foot node initialization i]) = to all foot node zi in i, i) node initialization = to n — 1 all node y in U I by ai+1 Add(?), , 1, i + 1) i + k] = C[i, j] + C[j,i + k]) = to = to n — + 1 + k — 1 ;; sibling concatenation (7/1,1) E C[i, (7/2,t) + k] is the left sibling of common parent + k) ;; left recursive concatenation (i1, j] C[j,i + k] the root node of a left recursive auxiliary tree that can adjoin on y k) ;; right recursive concatenation C[j, k] the root node of a right recursive tree that can adjoin on Add(?), i, i + k) n] labeled by y is the root node of an initial tree in then return acceptance otherwise return rejection end that the sole purpose of the codes is to insure that only one auxiliary tree can adjoin on a node. The procedure could easily be modified to account for other constraints on the way derivation should proceed such as those suggested for LTAGs (Schabes and Shieber, 1992). procedure a pair into the array the pair is already present, nothing is done. if it is new, it is added to other pairs may be added as well. These correspond to cases where the coverage is not increased: when a node is the only child of its parent, when the Figure 14: Left recursive concatenation. A a i+1a k Figure 15: Right recursive concatenation. node is recognized without adjunction, and when substitution occurs. Add(?), i, j) begin (7/, C[i, = t the only child of a parent Add(/L, i, j) = t y is the root node of an tree, for each substitution node which y can substitute call Add(p, i, j) no adjunction =b the node ndoes not have an OA constraint Add(y, j) end The 0(0) complexity of the recognizer folfrom the three nested induction loops on i the procedure defined the number of pairs added to bounded by a constant that is independent of sentence length.) By recording how each pair was introduced in cell of the array can easily extend the recognizer to produce all derivations of the input. Conclusion LCFG combines rnuch of the power of LTAG with the computational efficiency of CFG. It supports most of the same linguistic analysis supported by LTAG. In particular, most of the current LTA(. for English falls into LCF(. In addition, LCF( can lexicalize (.FG without altering the trees pro- Finally, LCFG can be parsed in time. There are many directions in which the work on LCFG described here could be extended. In 128 particular, one could consider stochastic extenand non-deterministic parsing. Acknowledgments We thank John Coleman who, by questioning whether the context-sensitivity of stochastic LTAG was actually being used for English, triggered this work. We thank Aravind Joshi, Fernando Pereira, Stuart Shieber and B. Srinivas for valuable discussions. REFERENCES Abeille, Anne, Kathleen M. Bishop, Sharon Cote, and Yves Schabes. 1990. A lexicalized tree adjoining grammar for English. Technical Report MS-CIS-90-24, Department of Computer and Information Science, University of Pennsylvania. Joshi, Aravind K. and Yves Schabes. 1992. Treeadjoining grammars and lexicalized grammars. In Maurice Nivat and Andreas Podeleditors, Automata and Languages.</abstract>
<note confidence="0.567917466666667">Elsevier Science. Joshi, Aravind K., K. Vijay-Shanker, and David Weir. 1991. The convergence of rnildly context-sensitive grarnmatical formalisms. In Peter Sells, Stuart Shieber, and Tom Wasow, Issues in Natural Lan- Processing. Press, Cambridge MA. Lang, Bernard. 1990. The systematic constructions of Earley parsers: Application to the of Earley parsers for Tree Grammars, In of the 1st International Workshop on Tree Adjoining Castle, FRG, August. Schabes, Yves, Anne Abeille, and Aravind K. Joshi. 1988. Parsing strategies with &apos;lexicalized&apos; grammars: Application to tree adjoining In of the International Conference on Computational Linguis- (COLING&apos;88), Hungary, August. Schabes, Yves and Aravind K. Joshi. 1990. Parsing with lexicalized tree adjoining grammar. Masaru Tomita, editor, Issues Parsing Technologies. Accademic Publishers. Schabes, Yves and Stuart Shieber. 1992. An alternative conception of tree-adjoining deriva- In Meeting of the Association for Computational Linguistics (ACL&apos;92). Schabes, Yves and Richard C. Waters. 1993. Lex-</note>
<abstract confidence="0.858643333333333">icalized context-free grammar: A cubic-time parsable formalism that strongly lexicalizes context-free grammar. Technical Report 93-</abstract>
<affiliation confidence="0.882265">04, Mitsubishi Electric Research Laboratories,</affiliation>
<address confidence="0.98733">201 Broadway. Cambridge MA 02139.</address>
<abstract confidence="0.875039333333333">Yves. 1991. The valid prefix property and left to right parsing of tree-adjoining In of the second Inter-</abstract>
<affiliation confidence="0.429187">national Workshop on Parsing Technologies,</affiliation>
<address confidence="0.444203">Cancun, Mexico, February. Vijay-Shanker, K. and David Weir. 1993a. The</address>
<abstract confidence="0.6265042">equivalence of four extensions of context-free appear in Mathematical Systems Theory. Vijay-Shanker, K. and David Weir. 1993b. Parsing some constrained grammar formalisms.</abstract>
<note confidence="0.91368">To appear in Computational Linguistics. K. 1987. A of Tree Adjoin- Grammars. thesis, Department of Computer and Inforrnation Science, Univer-</note>
<affiliation confidence="0.691782">sity of Pennsylvania.</affiliation>
<author confidence="0.885844">J David</author>
<affiliation confidence="0.800110333333333">izing Mildly Context-Sensitive Grammar For- Department of Computer and Information Science, University of</affiliation>
<address confidence="0.4756585">Pennsylvania. 129</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeille</author>
<author>Kathleen M Bishop</author>
<author>Sharon Cote</author>
<author>Yves Schabes</author>
</authors>
<title>A lexicalized tree adjoining grammar for English.</title>
<date>1990</date>
<tech>Technical Report MS-CIS-90-24,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="1357" citStr="Abeille et al., 1990" startWordPosition="192" endWordPosition="195">cepted framework for computational linguistics for a long time. While it has drawbacks, including the inability to express some linguistic constructions, it has the virtue of being computationally efficient, 0(0)-time in the worst case. Recently there has been a gain in interest in the so-called &apos;mildly&apos; context-sensitive formalisms (Vijay-Shanker, 1987; Weir, 1988; Joshi, VijayShanker, and Weir, 1991; Vijay-Shanker and Weir, 1993a) that generate only a small superset of context-free languages. One such formalism is lexicalized tree-adjoining grammar (LTAG) (Schabes, Abeille, and Joshi, 1988; Abeille et al., 1990; Joshi and Schabes, 1992), which provides a number of attractive properties at the cost of decreased efficiency, 0(7/6)-time in the worst case (VijayShanker, 1987; Schabes, 1991; Lang, 1990; VijayShanker and Weir, 1993b). An LTAG lexicon consists of a set of trees each of which contains one or more lexical items. These elementary trees can be viewed as the elementary clauses (including their transformational variants) in which the lexical items participate. The trees are combined by substitution and adjunction. LTAG supports context-sensitive features that can capture some language constructs</context>
<context position="3156" citStr="Abeille et al., 1990" startWordPosition="482" endWordPosition="485">Joshi and Schabes, 1992). Lexicalized context-free grammar (LCFG) is an attractive compromise between LTAG and CFG, that combines many of the virtues of LTAG with the efficiency of CFG. LCFG is a restricted form of LTAG that places further limits on the elementary trees that are possible and on the way adjunction can be performed. These restrictions limit LCFG to producing only context-free languages and allow LCFG to be parsed in 0(n3)- time in the worst case. However, LCFG retains most of the key features of LTAG enumerated above. In particular, most of the current LTAG grammar for English (Abeille et al., 1990) follows the restrictions of LCFG. This is of significant practical interest because it means that the processing of these analyses does not require more computational resources than CFGs. In addition, any CFG can be transformed into an equivalent LCFG that generates the same trees (and therefore the same strings). This result breaks new ground, because heretofore every method of lexicalizing CFGs required contextsensitive operations (Joshi and Schabes, 1992). The following sections briefly, define LCFG, discuss its relationship to the current LTAG grammar for English, prove that LCFG can be u</context>
<context position="8372" citStr="Abeille et al., 1990" startWordPosition="1393" endWordPosition="1396">ere on the frontier and places no limitations on the interaction of auxiliary trees. In this unlimited situation, adjunction encodes string wrapping and is therefore more powerful than concatenation (see Figure 5). However, the restrictions imposed by LCFG guarantee that no context-sensitive operations can be achieved. They limit the languages that can be generated by LCFGs to those that can be generated by CFGs. Coverage of LCFG and LTAG The power of LCFG is significantly less than LTAG. Surprisingly, it turns out that there are only two situations where the current LTAG grammar for English (Abeille et al., 1990) fails to satisfy the restrictions imposed by LCFG. The first situation, concerns certain verbs that take more than one sentential complement. An example of such a verb is deduce., which is associated with the following auxiliary tree. A NPri. VP AN V SI* PP A deduce P from Since this tree contains a foot node in the center of its frontier, it is not part of an LCFG. Having the foot on the first sentential complement is convenient, because it allows one to use the standard LTAG wh-analyses, which depends on the (1) John deduced that Mary watered the grass from seeing the hose. (2) What did Joh</context>
</contexts>
<marker>Abeille, Bishop, Cote, Schabes, 1990</marker>
<rawString>Abeille, Anne, Kathleen M. Bishop, Sharon Cote, and Yves Schabes. 1990. A lexicalized tree adjoining grammar for English. Technical Report MS-CIS-90-24, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>Yves Schabes</author>
</authors>
<title>Treeadjoining grammars and lexicalized grammars.</title>
<date>1992</date>
<booktitle>In Maurice Nivat and Andreas Podelski, editors, Tree Automata and Languages.</booktitle>
<publisher>Elsevier Science.</publisher>
<contexts>
<context position="1383" citStr="Joshi and Schabes, 1992" startWordPosition="196" endWordPosition="199">omputational linguistics for a long time. While it has drawbacks, including the inability to express some linguistic constructions, it has the virtue of being computationally efficient, 0(0)-time in the worst case. Recently there has been a gain in interest in the so-called &apos;mildly&apos; context-sensitive formalisms (Vijay-Shanker, 1987; Weir, 1988; Joshi, VijayShanker, and Weir, 1991; Vijay-Shanker and Weir, 1993a) that generate only a small superset of context-free languages. One such formalism is lexicalized tree-adjoining grammar (LTAG) (Schabes, Abeille, and Joshi, 1988; Abeille et al., 1990; Joshi and Schabes, 1992), which provides a number of attractive properties at the cost of decreased efficiency, 0(7/6)-time in the worst case (VijayShanker, 1987; Schabes, 1991; Lang, 1990; VijayShanker and Weir, 1993b). An LTAG lexicon consists of a set of trees each of which contains one or more lexical items. These elementary trees can be viewed as the elementary clauses (including their transformational variants) in which the lexical items participate. The trees are combined by substitution and adjunction. LTAG supports context-sensitive features that can capture some language constructs not captured by CFG. Howe</context>
<context position="3619" citStr="Joshi and Schabes, 1992" startWordPosition="555" endWordPosition="558">case. However, LCFG retains most of the key features of LTAG enumerated above. In particular, most of the current LTAG grammar for English (Abeille et al., 1990) follows the restrictions of LCFG. This is of significant practical interest because it means that the processing of these analyses does not require more computational resources than CFGs. In addition, any CFG can be transformed into an equivalent LCFG that generates the same trees (and therefore the same strings). This result breaks new ground, because heretofore every method of lexicalizing CFGs required contextsensitive operations (Joshi and Schabes, 1992). The following sections briefly, define LCFG, discuss its relationship to the current LTAG grammar for English, prove that LCFG can be used to lexicalize CFG, and present a simple cubic-time parser for LCFG. These topics are discussed in greater detail in Schabes and Waters (1993). 121 Lexicalized Context-Free Grammars Like an LTAG, an LCFG consists of two sets of trees: initial trees, which are combined by substitution and auxiliary trees, which are combined by adjunction. An LCFG is lexicalized in the sense that every initial and auxiliary tree is required to contain at least one terminal s</context>
</contexts>
<marker>Joshi, Schabes, 1992</marker>
<rawString>Joshi, Aravind K. and Yves Schabes. 1992. Treeadjoining grammars and lexicalized grammars. In Maurice Nivat and Andreas Podelski, editors, Tree Automata and Languages. Elsevier Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>K Vijay-Shanker</author>
<author>David Weir</author>
</authors>
<title>The convergence of rnildly context-sensitive grarnmatical formalisms.</title>
<date>1991</date>
<booktitle>Foundational Issues in Natural Language Processing.</booktitle>
<editor>In Peter Sells, Stuart Shieber, and Tom Wasow, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge MA.</location>
<marker>Joshi, Vijay-Shanker, Weir, 1991</marker>
<rawString>Joshi, Aravind K., K. Vijay-Shanker, and David Weir. 1991. The convergence of rnildly context-sensitive grarnmatical formalisms. In Peter Sells, Stuart Shieber, and Tom Wasow, editors, Foundational Issues in Natural Language Processing. MIT Press, Cambridge MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Lang</author>
</authors>
<title>The systematic constructions of Earley parsers: Application to the production of 0(7/6) Earley parsers for Tree Adjoining Grammars,</title>
<date>1990</date>
<booktitle>In Proceedings of the 1st International Workshop on Tree Adjoining Grammars, Dagstuhl</booktitle>
<location>Castle, FRG,</location>
<contexts>
<context position="1547" citStr="Lang, 1990" startWordPosition="223" endWordPosition="224">icient, 0(0)-time in the worst case. Recently there has been a gain in interest in the so-called &apos;mildly&apos; context-sensitive formalisms (Vijay-Shanker, 1987; Weir, 1988; Joshi, VijayShanker, and Weir, 1991; Vijay-Shanker and Weir, 1993a) that generate only a small superset of context-free languages. One such formalism is lexicalized tree-adjoining grammar (LTAG) (Schabes, Abeille, and Joshi, 1988; Abeille et al., 1990; Joshi and Schabes, 1992), which provides a number of attractive properties at the cost of decreased efficiency, 0(7/6)-time in the worst case (VijayShanker, 1987; Schabes, 1991; Lang, 1990; VijayShanker and Weir, 1993b). An LTAG lexicon consists of a set of trees each of which contains one or more lexical items. These elementary trees can be viewed as the elementary clauses (including their transformational variants) in which the lexical items participate. The trees are combined by substitution and adjunction. LTAG supports context-sensitive features that can capture some language constructs not captured by CFG. However, the greatest virtue of LTAG is that it is lexicalized and supports extended domains of locality. The lexical nature of LTAG is of linguistic interest, since it</context>
<context position="22581" citStr="Lang, 1990" startWordPosition="3977" endWordPosition="3978"> way trees are derived. Unfortunately, the longer the minimal cycles in LUG, the greater the tree-generating ambiguity the procedure will introduce in G&apos;. However, by modifying the procedure to make use of constraints on what auxiliary trees are allowed to adjoin on what nodes in which initial trees, it should be possible to reduce or even eliminate this ambiguity. All these issues are discussed at greater length 126 in Schabes and Waters (1993). Parsing LCFG Since LCFG is a restricted case of tree-adjoining grammar (TAG), standard 0(71.6)-time TAG parsers (Vijay-Shanker, 1987; Schabes, 1991; Lang, 1990) can be used for parsing LCFG. Further, they can be straightforwardly modified to require at most 0(70)-time when applied to LCFG. However, this still does not take full advantage of the context-freeness of LCFG. This section describes a simple bottom-up recognizer for LCFG that is in the style of the CKY parser for CFG. The virtue of this algorithm is that it shows in a simple manner how the 0(7/3)-tirrie worst case complexity can be achieved for LCFG. Schabes and Waters (1993) describes a more practical and more elaborate (Earley-style) recognizer for LCFG, which achieves the same bounds. Su</context>
</contexts>
<marker>Lang, 1990</marker>
<rawString>Lang, Bernard. 1990. The systematic constructions of Earley parsers: Application to the production of 0(7/6) Earley parsers for Tree Adjoining Grammars, In Proceedings of the 1st International Workshop on Tree Adjoining Grammars, Dagstuhl Castle, FRG, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Anne Abeille</author>
<author>Aravind K Joshi</author>
</authors>
<title>Parsing strategies with &apos;lexicalized&apos; grammars: Application to tree adjoining grarnmars.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12Th International Conference on Computational Linguistics (COLING&apos;88),</booktitle>
<location>Budapest, Hungary,</location>
<contexts>
<context position="1335" citStr="Schabes, Abeille, and Joshi, 1988" startWordPosition="187" endWordPosition="191">ee grammar (CFG) has been a well accepted framework for computational linguistics for a long time. While it has drawbacks, including the inability to express some linguistic constructions, it has the virtue of being computationally efficient, 0(0)-time in the worst case. Recently there has been a gain in interest in the so-called &apos;mildly&apos; context-sensitive formalisms (Vijay-Shanker, 1987; Weir, 1988; Joshi, VijayShanker, and Weir, 1991; Vijay-Shanker and Weir, 1993a) that generate only a small superset of context-free languages. One such formalism is lexicalized tree-adjoining grammar (LTAG) (Schabes, Abeille, and Joshi, 1988; Abeille et al., 1990; Joshi and Schabes, 1992), which provides a number of attractive properties at the cost of decreased efficiency, 0(7/6)-time in the worst case (VijayShanker, 1987; Schabes, 1991; Lang, 1990; VijayShanker and Weir, 1993b). An LTAG lexicon consists of a set of trees each of which contains one or more lexical items. These elementary trees can be viewed as the elementary clauses (including their transformational variants) in which the lexical items participate. The trees are combined by substitution and adjunction. LTAG supports context-sensitive features that can capture so</context>
</contexts>
<marker>Schabes, Abeille, Joshi, 1988</marker>
<rawString>Schabes, Yves, Anne Abeille, and Aravind K. Joshi. 1988. Parsing strategies with &apos;lexicalized&apos; grammars: Application to tree adjoining grarnmars. In Proceedings of the 12Th International Conference on Computational Linguistics (COLING&apos;88), Budapest, Hungary, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Aravind K Joshi</author>
</authors>
<title>Parsing with lexicalized tree adjoining grammar.</title>
<date>1990</date>
<booktitle>Current Issues in Parsing Technologies.</booktitle>
<editor>In Masaru Tomita, editor,</editor>
<publisher>Kluwer Accademic Publishers.</publisher>
<contexts>
<context position="10622" citStr="Schabes and Joshi, 1990" startWordPosition="1774" endWordPosition="1777">ction along the spine of these two kinds of trees. This agrees with the intuition that most English analyses do not require a context-sensitive operation. Lexicalization of CFGs The lexicalization of grammar formalisms is of interest from a number of perspectives. It is of interest from a linguistic perspective, because most current linguistic theories give lexical accounts of a number of phenomena that used to be considered purely syntactic. It is of interest from a computational perspective, because lexicalized grammars can be parsed significantly more efficiently than non-lexicalized ones (Schabes and Joshi, 1990). Formally, a grammar is said `lexicalized&apos; (Schabes, Abeille., and Joshi, 1988) if it consists of: • a finite set of elementary structures of finite size, each of which contains an overt (i.e., non-empty) lexical item. • a finite set of operations for creating derived structures. The overt lexical item in an elementary structure is referred to as its anchor. A lexicalized grammar can be organized as a lexicon where each lexical item is associated with a finite number of structures for which that item is the anchor. In general, CFGs are not lexicalized since rules such as S —&gt; NP VP that do no</context>
</contexts>
<marker>Schabes, Joshi, 1990</marker>
<rawString>Schabes, Yves and Aravind K. Joshi. 1990. Parsing with lexicalized tree adjoining grammar. In Masaru Tomita, editor, Current Issues in Parsing Technologies. Kluwer Accademic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Stuart Shieber</author>
</authors>
<title>An alternative conception of tree-adjoining derivation.</title>
<date>1992</date>
<booktitle>In 20th Meeting of the Association for Computational Linguistics (ACL&apos;92).</booktitle>
<contexts>
<context position="28025" citStr="Schabes and Shieber, 1992" startWordPosition="5099" endWordPosition="5102">n on y then Add(y,t,i,i+ k) ;; right recursive concatenation if b) E C[j, i+ k] and (p,t) E C[i, and p is the root node of a right recursive auxiliary tree that can adjoin on 71 then Add(?), 1, i, i + k) If t) E C[0, n] and 71 is labeled by S and y is the root node of an initial tree in I then return acceptance otherwise return rejection end Note that the sole purpose of the codes t and b is to insure that only one auxiliary tree can adjoin on a node. The procedure could easily be modified to account for other constraints on the way derivation should proceed such as those suggested for LTAGs (Schabes and Shieber, 1992). The procedure Add puts a pair into the array C. If the pair is already present, nothing is done. However, if it is new, it is added to C and other pairs may be added as well. These correspond to cases where the coverage is not increased: when a node is the only child of its parent, when the Figure 14: Left recursive concatenation. A a&amp;quot; ak a i+1 a k Figure 15: Right recursive concatenation. node is recognized without adjunction, and when substitution occurs. Procedure Add(?), pos, i, j) begin Put (7/, pos) in C[i, j] if pos = t and y is the only child of a parent it call Add(/L, b, i, j) if p</context>
</contexts>
<marker>Schabes, Shieber, 1992</marker>
<rawString>Schabes, Yves and Stuart Shieber. 1992. An alternative conception of tree-adjoining derivation. In 20th Meeting of the Association for Computational Linguistics (ACL&apos;92).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Richard C Waters</author>
</authors>
<title>Lexicalized context-free grammar: A cubic-time parsable formalism that strongly lexicalizes context-free grammar.</title>
<date>1993</date>
<booktitle>Mitsubishi Electric Research Laboratories, 201 Broadway. Cambridge MA</booktitle>
<tech>Technical Report 93-04,</tech>
<pages>02139</pages>
<contexts>
<context position="3901" citStr="Schabes and Waters (1993)" startWordPosition="601" endWordPosition="604">se analyses does not require more computational resources than CFGs. In addition, any CFG can be transformed into an equivalent LCFG that generates the same trees (and therefore the same strings). This result breaks new ground, because heretofore every method of lexicalizing CFGs required contextsensitive operations (Joshi and Schabes, 1992). The following sections briefly, define LCFG, discuss its relationship to the current LTAG grammar for English, prove that LCFG can be used to lexicalize CFG, and present a simple cubic-time parser for LCFG. These topics are discussed in greater detail in Schabes and Waters (1993). 121 Lexicalized Context-Free Grammars Like an LTAG, an LCFG consists of two sets of trees: initial trees, which are combined by substitution and auxiliary trees, which are combined by adjunction. An LCFG is lexicalized in the sense that every initial and auxiliary tree is required to contain at least one terminal symbol on its frontier. More precisely, an LCFG is a five-tuple (E, NT, I, A „9), where E is a set of terminal symbols, NT is a set of non-terminal symbols, / and A are sets of trees labeled by terminal and nonterminal symbols, and S is a distinguished nonterminal start symbol. Each</context>
<context position="22419" citStr="Schabes and Waters (1993)" startWordPosition="3953" endWordPosition="3956">n be many ways for an LCFG to derive a given tree. For maximal efficiency, it would be desirable for the grammar G&apos; produced by the procedure above to have no ambiguity in they way trees are derived. Unfortunately, the longer the minimal cycles in LUG, the greater the tree-generating ambiguity the procedure will introduce in G&apos;. However, by modifying the procedure to make use of constraints on what auxiliary trees are allowed to adjoin on what nodes in which initial trees, it should be possible to reduce or even eliminate this ambiguity. All these issues are discussed at greater length 126 in Schabes and Waters (1993). Parsing LCFG Since LCFG is a restricted case of tree-adjoining grammar (TAG), standard 0(71.6)-time TAG parsers (Vijay-Shanker, 1987; Schabes, 1991; Lang, 1990) can be used for parsing LCFG. Further, they can be straightforwardly modified to require at most 0(70)-time when applied to LCFG. However, this still does not take full advantage of the context-freeness of LCFG. This section describes a simple bottom-up recognizer for LCFG that is in the style of the CKY parser for CFG. The virtue of this algorithm is that it shows in a simple manner how the 0(7/3)-tirrie worst case complexity can be</context>
</contexts>
<marker>Schabes, Waters, 1993</marker>
<rawString>Schabes, Yves and Richard C. Waters. 1993. Lexicalized context-free grammar: A cubic-time parsable formalism that strongly lexicalizes context-free grammar. Technical Report 93-04, Mitsubishi Electric Research Laboratories, 201 Broadway. Cambridge MA 02139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
</authors>
<title>The valid prefix property and left to right parsing of tree-adjoining grammar.</title>
<date>1991</date>
<booktitle>In Proceedings of the second International Workshop on Parsing Technologies,</booktitle>
<location>Cancun, Mexico,</location>
<contexts>
<context position="1535" citStr="Schabes, 1991" startWordPosition="221" endWordPosition="222">utationally efficient, 0(0)-time in the worst case. Recently there has been a gain in interest in the so-called &apos;mildly&apos; context-sensitive formalisms (Vijay-Shanker, 1987; Weir, 1988; Joshi, VijayShanker, and Weir, 1991; Vijay-Shanker and Weir, 1993a) that generate only a small superset of context-free languages. One such formalism is lexicalized tree-adjoining grammar (LTAG) (Schabes, Abeille, and Joshi, 1988; Abeille et al., 1990; Joshi and Schabes, 1992), which provides a number of attractive properties at the cost of decreased efficiency, 0(7/6)-time in the worst case (VijayShanker, 1987; Schabes, 1991; Lang, 1990; VijayShanker and Weir, 1993b). An LTAG lexicon consists of a set of trees each of which contains one or more lexical items. These elementary trees can be viewed as the elementary clauses (including their transformational variants) in which the lexical items participate. The trees are combined by substitution and adjunction. LTAG supports context-sensitive features that can capture some language constructs not captured by CFG. However, the greatest virtue of LTAG is that it is lexicalized and supports extended domains of locality. The lexical nature of LTAG is of linguistic intere</context>
<context position="22568" citStr="Schabes, 1991" startWordPosition="3975" endWordPosition="3976">biguity in they way trees are derived. Unfortunately, the longer the minimal cycles in LUG, the greater the tree-generating ambiguity the procedure will introduce in G&apos;. However, by modifying the procedure to make use of constraints on what auxiliary trees are allowed to adjoin on what nodes in which initial trees, it should be possible to reduce or even eliminate this ambiguity. All these issues are discussed at greater length 126 in Schabes and Waters (1993). Parsing LCFG Since LCFG is a restricted case of tree-adjoining grammar (TAG), standard 0(71.6)-time TAG parsers (Vijay-Shanker, 1987; Schabes, 1991; Lang, 1990) can be used for parsing LCFG. Further, they can be straightforwardly modified to require at most 0(70)-time when applied to LCFG. However, this still does not take full advantage of the context-freeness of LCFG. This section describes a simple bottom-up recognizer for LCFG that is in the style of the CKY parser for CFG. The virtue of this algorithm is that it shows in a simple manner how the 0(7/3)-tirrie worst case complexity can be achieved for LCFG. Schabes and Waters (1993) describes a more practical and more elaborate (Earley-style) recognizer for LCFG, which achieves the sa</context>
</contexts>
<marker>Schabes, 1991</marker>
<rawString>Schabes, Yves. 1991. The valid prefix property and left to right parsing of tree-adjoining grammar. In Proceedings of the second International Workshop on Parsing Technologies, Cancun, Mexico, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David Weir</author>
</authors>
<title>The equivalence of four extensions of context-free grammars.</title>
<date>1993</date>
<note>To appear in Mathematical Systems Theory.</note>
<contexts>
<context position="1171" citStr="Vijay-Shanker and Weir, 1993" startWordPosition="165" endWordPosition="168">h of the elegance of LTAG&apos;s analysis of English and shares with LTAG the ability to lexicalize CFGs without changing the trees generated. Motivation Context-free grammar (CFG) has been a well accepted framework for computational linguistics for a long time. While it has drawbacks, including the inability to express some linguistic constructions, it has the virtue of being computationally efficient, 0(0)-time in the worst case. Recently there has been a gain in interest in the so-called &apos;mildly&apos; context-sensitive formalisms (Vijay-Shanker, 1987; Weir, 1988; Joshi, VijayShanker, and Weir, 1991; Vijay-Shanker and Weir, 1993a) that generate only a small superset of context-free languages. One such formalism is lexicalized tree-adjoining grammar (LTAG) (Schabes, Abeille, and Joshi, 1988; Abeille et al., 1990; Joshi and Schabes, 1992), which provides a number of attractive properties at the cost of decreased efficiency, 0(7/6)-time in the worst case (VijayShanker, 1987; Schabes, 1991; Lang, 1990; VijayShanker and Weir, 1993b). An LTAG lexicon consists of a set of trees each of which contains one or more lexical items. These elementary trees can be viewed as the elementary clauses (including their transformational v</context>
</contexts>
<marker>Vijay-Shanker, Weir, 1993</marker>
<rawString>Vijay-Shanker, K. and David Weir. 1993a. The equivalence of four extensions of context-free grammars. To appear in Mathematical Systems Theory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David Weir</author>
</authors>
<title>Parsing some constrained grammar formalisms.</title>
<date>1993</date>
<note>To appear in Computational Linguistics.</note>
<contexts>
<context position="1171" citStr="Vijay-Shanker and Weir, 1993" startWordPosition="165" endWordPosition="168">h of the elegance of LTAG&apos;s analysis of English and shares with LTAG the ability to lexicalize CFGs without changing the trees generated. Motivation Context-free grammar (CFG) has been a well accepted framework for computational linguistics for a long time. While it has drawbacks, including the inability to express some linguistic constructions, it has the virtue of being computationally efficient, 0(0)-time in the worst case. Recently there has been a gain in interest in the so-called &apos;mildly&apos; context-sensitive formalisms (Vijay-Shanker, 1987; Weir, 1988; Joshi, VijayShanker, and Weir, 1991; Vijay-Shanker and Weir, 1993a) that generate only a small superset of context-free languages. One such formalism is lexicalized tree-adjoining grammar (LTAG) (Schabes, Abeille, and Joshi, 1988; Abeille et al., 1990; Joshi and Schabes, 1992), which provides a number of attractive properties at the cost of decreased efficiency, 0(7/6)-time in the worst case (VijayShanker, 1987; Schabes, 1991; Lang, 1990; VijayShanker and Weir, 1993b). An LTAG lexicon consists of a set of trees each of which contains one or more lexical items. These elementary trees can be viewed as the elementary clauses (including their transformational v</context>
</contexts>
<marker>Vijay-Shanker, Weir, 1993</marker>
<rawString>Vijay-Shanker, K. and David Weir. 1993b. Parsing some constrained grammar formalisms. To appear in Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
</authors>
<title>A Study of Tree Adjoining Grammars.</title>
<date>1987</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer and Inforrnation Science, University of Pennsylvania.</institution>
<contexts>
<context position="1092" citStr="Vijay-Shanker, 1987" startWordPosition="155" endWordPosition="156"> languages and can be parsed in cubic time. However, LCFG supports much of the elegance of LTAG&apos;s analysis of English and shares with LTAG the ability to lexicalize CFGs without changing the trees generated. Motivation Context-free grammar (CFG) has been a well accepted framework for computational linguistics for a long time. While it has drawbacks, including the inability to express some linguistic constructions, it has the virtue of being computationally efficient, 0(0)-time in the worst case. Recently there has been a gain in interest in the so-called &apos;mildly&apos; context-sensitive formalisms (Vijay-Shanker, 1987; Weir, 1988; Joshi, VijayShanker, and Weir, 1991; Vijay-Shanker and Weir, 1993a) that generate only a small superset of context-free languages. One such formalism is lexicalized tree-adjoining grammar (LTAG) (Schabes, Abeille, and Joshi, 1988; Abeille et al., 1990; Joshi and Schabes, 1992), which provides a number of attractive properties at the cost of decreased efficiency, 0(7/6)-time in the worst case (VijayShanker, 1987; Schabes, 1991; Lang, 1990; VijayShanker and Weir, 1993b). An LTAG lexicon consists of a set of trees each of which contains one or more lexical items. These elementary tr</context>
<context position="22553" citStr="Vijay-Shanker, 1987" startWordPosition="3973" endWordPosition="3974">e above to have no ambiguity in they way trees are derived. Unfortunately, the longer the minimal cycles in LUG, the greater the tree-generating ambiguity the procedure will introduce in G&apos;. However, by modifying the procedure to make use of constraints on what auxiliary trees are allowed to adjoin on what nodes in which initial trees, it should be possible to reduce or even eliminate this ambiguity. All these issues are discussed at greater length 126 in Schabes and Waters (1993). Parsing LCFG Since LCFG is a restricted case of tree-adjoining grammar (TAG), standard 0(71.6)-time TAG parsers (Vijay-Shanker, 1987; Schabes, 1991; Lang, 1990) can be used for parsing LCFG. Further, they can be straightforwardly modified to require at most 0(70)-time when applied to LCFG. However, this still does not take full advantage of the context-freeness of LCFG. This section describes a simple bottom-up recognizer for LCFG that is in the style of the CKY parser for CFG. The virtue of this algorithm is that it shows in a simple manner how the 0(7/3)-tirrie worst case complexity can be achieved for LCFG. Schabes and Waters (1993) describes a more practical and more elaborate (Earley-style) recognizer for LCFG, which </context>
</contexts>
<marker>Vijay-Shanker, 1987</marker>
<rawString>Vijay-Shanker, K. 1987. A Study of Tree Adjoining Grammars. Ph.D. thesis, Department of Computer and Inforrnation Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David J Weir</author>
</authors>
<title>Characterizing Mildly Context-Sensitive Grammar Formalisms.</title>
<date>1988</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="1104" citStr="Weir, 1988" startWordPosition="157" endWordPosition="158"> parsed in cubic time. However, LCFG supports much of the elegance of LTAG&apos;s analysis of English and shares with LTAG the ability to lexicalize CFGs without changing the trees generated. Motivation Context-free grammar (CFG) has been a well accepted framework for computational linguistics for a long time. While it has drawbacks, including the inability to express some linguistic constructions, it has the virtue of being computationally efficient, 0(0)-time in the worst case. Recently there has been a gain in interest in the so-called &apos;mildly&apos; context-sensitive formalisms (Vijay-Shanker, 1987; Weir, 1988; Joshi, VijayShanker, and Weir, 1991; Vijay-Shanker and Weir, 1993a) that generate only a small superset of context-free languages. One such formalism is lexicalized tree-adjoining grammar (LTAG) (Schabes, Abeille, and Joshi, 1988; Abeille et al., 1990; Joshi and Schabes, 1992), which provides a number of attractive properties at the cost of decreased efficiency, 0(7/6)-time in the worst case (VijayShanker, 1987; Schabes, 1991; Lang, 1990; VijayShanker and Weir, 1993b). An LTAG lexicon consists of a set of trees each of which contains one or more lexical items. These elementary trees can be v</context>
</contexts>
<marker>Weir, 1988</marker>
<rawString>Weir, David J. 1988. Characterizing Mildly Context-Sensitive Grammar Formalisms. Ph.D. thesis, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>