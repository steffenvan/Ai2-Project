<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000383">
<title confidence="0.994634">
An exponential translation model for target language morphology
</title>
<author confidence="0.990559">
Michael Subotin
</author>
<affiliation confidence="0.9906835">
Paxfire, Inc.
Department of Linguistics &amp; UMIACS, University of Maryland
</affiliation>
<email confidence="0.993685">
msubotin@gmail.com
</email>
<sectionHeader confidence="0.998577" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999885722222222">
This paper presents an exponential model
for translation into highly inflected languages
which can be scaled to very large datasets. As
in other recent proposals, it predicts target-
side phrases and can be conditioned on source-
side context. However, crucially for the task
of modeling morphological generalizations, it
estimates feature parameters from the entire
training set rather than as a collection of sepa-
rate classifiers. We apply it to English-Czech
translation, using a variety of features captur-
ing potential predictors for case, number, and
gender, and one of the largest publicly avail-
able parallel data sets. We also describe gen-
eration and modeling of inflected forms un-
observed in training data and decoding proce-
dures for a model with non-local target-side
feature dependencies.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995574933333333">
Translation into languages with rich morphology
presents special challenges for phrase-based meth-
ods. Thus, Birch et al (2008) find that transla-
tion quality achieved by a popular phrase-based sys-
tem correlates significantly with a measure of target-
side, but not source-side morphological complexity.
Recently, several studies (Bojar, 2007; Avramidis
and Koehn, 2009; Ramanathan et al., 2009; Yen-
iterzi and Oflazer, 2010) proposed modeling target-
side morphology in a phrase-based factored mod-
els framework (Koehn and Hoang, 2007). Under
this approach linguistic annotation of source sen-
tences is analyzed using heuristics to identify rel-
evant structural phenomena, whose occurrences are
in turn used to compute additional relative frequency
(maximum likelihood) estimates predicting target-
side inflections. This approach makes it difficult
to handle the complex interplay between different
predictors for inflections. For example, the ac-
cusative case is usually preserved in translation, so
that nouns appearing in the direct object position of
English clauses tend to be translated to words with
accusative case markings in languages with richer
morphology, and vice versa. However, there are
exceptions. For example, some verbs that place
their object in the accusative case in Czech may be
rendered as prepositional constructions in English
(Naughton, 2005):
David was looking for Jana
David hledal Janu
</bodyText>
<subsubsectionHeader confidence="0.545676">
David searched Jana-ACC
</subsubsectionHeader>
<bodyText confidence="0.982866384615385">
Conversely, direct objects of some English verbs
can be translated by nouns with genitive case
markings in Czech:
David asked Jana where Karel was
David zeptal se Jany kde je Karel
David asked SELF Jana-GEN where is Karel
Furthermore, English noun modifiers are often
rendered by Czech possessive adjectives and a ver-
bal complement in one language is commonly trans-
lated by a nominalizing complement in another lan-
guage, so that the part of speech (POS) of its head
need not be preserved. These complications make it
difficult to model morphological phenomena using
</bodyText>
<page confidence="0.949101">
230
</page>
<note confidence="0.9791865">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 230–238,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999495">
closed-form estimates. This paper presents an alter-
native approach based on exponential phrase mod-
els, which can straightforwardly handle feature sets
with arbitrarily elaborate source-side dependencies.
</bodyText>
<sectionHeader confidence="0.92838" genericHeader="introduction">
2 Hierarchical phrase-based translation
</sectionHeader>
<bodyText confidence="0.9885542">
We take as our starting point David Chiang’s Hiero
system, which generalizes phrase-based translation
to substrings with gaps (Chiang, 2007). Consider
for instance the following set of context-free rules
with a single non-terminal symbol:
</bodyText>
<equation confidence="0.653527166666667">
(A, A) (A1 A2 , A1 A2 )
(A, A) ( d&apos; A1 id�ees A2 , A1 A2 ideas)
(A, A) ( incolores , colorless)
(A, A) ( vertes , green)
(A, A) (dormentA, sleep A)
(A, A) (furieusement , furiously)
</equation>
<bodyText confidence="0.950884473684211">
It is one of many rule sets that would suffice to
generate the English translation 1b for the French
sentence 1a.
1a. d’ incolores idees vertes dormentfurieusement
1b. colorless green ideas sleep furiously
As shown by Chiang (2007), a weighted gram-
mar of this form can be collected and scored by sim-
ple extensions of standard methods for phrase-based
translation and efficiently combined with a language
model in a CKY decoder to achieve large improve-
ments over a state-of-the-art phrase-based system.
The translation is chosen to be the target-side yield
of the highest-scoring synchronous parse consistent
with the source sentence. Although a variety of
scores interpolated into the decision rule for phrase-
based systems have been investigated over the years,
only a handful have been discovered to be consis-
tently useful. In this work we concentrate on ex-
tending the target-given-source phrase model1.
</bodyText>
<sectionHeader confidence="0.978117" genericHeader="method">
3 Exponential phrase models with shared
features
</sectionHeader>
<bodyText confidence="0.9953475">
The model used in this work is based on the familiar
equation for conditional exponential models:
</bodyText>
<footnote confidence="0.66783">
1To avoid confusion with features of the exponential mod-
els described below we shall use the term “model” rather than
“feature” for the terms interpolated using MERT.
</footnote>
<equation confidence="0.998838666666667">
w· f(X,Y)
EY&apos;EGEN(X) ew·
f(X,Y &apos;)
</equation>
<bodyText confidence="0.979193071428571">
where f(X, Y ) is a vector of feature functions,
w� is a corresponding weight vector, so that w� �
f(X, Y ) = Ei wifi(X, Y ), and GEN(X) is a
set of values corresponding to Y . For a target-
given-source phrase model the predicted outcomes
are target-side phrases ry, the model is conditioned
on a source-side phrase r&apos; together with some con-
text, and each GEN(X) consists of target phrases
ry co-occurring with a given source phrase r&apos; in the
grammar.
Maximum likelihood estimation for exponential
model finds the values of weights that maximize the
likelihood of the training data, or, equivalently, its
logarithm:
</bodyText>
<equation confidence="0.999700666666667">
M M
LL(w) = log H p(Ym|Xm) = log p(Ym|Xm)
m=1 m=1
</equation>
<bodyText confidence="0.999945769230769">
where the expressions range over all training in-
stances {m}. In this work we extend the objective
using an E2 regularizer (Ng, 2004; Gao et al., 2007).
We obtain the counts of instances and features from
the standard heuristics used to extract the grammar
from a word-aligned parallel corpus.
Exponential models and other classifiers have
been used in several recent studies to condition
phrase model probabilities on source-side context
(Chan et al 2007; Carpuat and Wu 2007a; Carpuat
and Wu 2007b). However, this has been gener-
ally accomplished by training independent classi-
fiers associated with different source phrases. This
approach is not well suited to modeling target-
language inflections, since parameters for the fea-
tures associated with morphological markings and
their predictors would be estimated separately from
many, generally very small training sets, thereby
preventing the model from making precisely the
kind of generalization beyond specific phrases that
we seek to obtain. Instead we continue the approach
proposed in Subotin (2008), where a single model
defined by the equations above is trained on all of the
data, so that parameters for features that are shared
by rule sets with difference source sides reflect cu-
mulative feature counts, while the standard relative
</bodyText>
<equation confidence="0.9852445">
e
p(Y |X) =
</equation>
<page confidence="0.947437">
231
</page>
<bodyText confidence="0.995459127659575">
frequency model can be obtained as a special case 4.2 Case
of maximum likelihood estimation for a model con- Among the inflection types of Czech nouns, the only
taining only the features for rules.2 Recently, Jeong type that is not generally observed in English and
et al (2010) independently proposed an exponential does not belong to derivational morphology is in-
model with shared features for target-side morphol- flection for case. Czech marks seven cases: nomi-
ogy in application to lexical scores in a treelet-based nal, genitive, dative, accusative, vocative, locative,
system. and instrumental. Not all of these forms are overtly
4 Features distinguished for all lexical items, and some words
The feature space for target-side inflection models that function syntactically as nouns do not inflect at
used in this work consists of features tracking the all. Czech adjectives also inflect for case and their
source phrase and the corresponding target phrase case has to match the case of their governing noun.
together with its complete morphological tag, which However, since the source sentence and its anno-
will be referred to as rule features for brevity. The tation contain a variety of predictors for case, we
feature space also includes features tracking the model it using only source-dependent features. The
source phrase together with the lemmatized repre- following feature types for case were included:
sentation of the target phrase, called lemma features • The structural role of the aligned source word
below. Since there is little ambiguity in lemmati- or the head of the smallest noun phrase con-
zation for Czech, the lemma representations were taining the aligned source word. Features were
for simplicity based on the most frequent lemma included for the roles of subject, direct object,
for each token. Finally, we include features associ- and nominal predicate.
ating aspects of source-side annotation with inflec- • The preposition governing the smallest noun
tions of aligned target words. The models include phrase containing the aligned source word, if
features for three general classes of morphological it is governed by a preposition.
types: number, case, and gender. We add inflec- • An indicator for the presence of a possessive
tion features for all words aligned to at least one En- marker modifying the aligned source word or
glish verb, adjective, noun, pronoun, or determiner, the head of the smallest noun phrase containing
excepting definite and indefinite articles. A sepa- the aligned source word.
rate feature type marks cases where an intended in- • An indicator for the presence of a numeral
flection category is not applicable to a target word modifying the aligned source word or the head
falling under these criteria due to a POS mismatch of the smallest noun phrase containing the
between aligned words. aligned source word.
4.1 Number • An indication that aligned source word modi-
The inflection for number is particularly easy to fied by quantifiers many, most, such, or half.
model in translating from English, since it is gen- These features would be more properly defined
erally marked on the source side, and POS taggers based on the identity of the target word aligned
based on the Penn treebank tag set attempt to infer to these quantifiers, but little ambiguity seems
it in cases where it is not. For word pairs whose to arise from this substitution in practice.
source-side word is a verb, we add a feature marking • The lemma of the verb governing the aligned
the number of its subject, with separate features for source word or the head of the smallest noun
noun and pronoun subjects. For word pairs whose phrase containing the aligned source word.
source side is an adjective, we add a feature marking This is the only lexicalized feature type used in
the number of the head of the smallest noun phrase the model and we include only those features
that contains it. which occur over 1,000 times in the training
data.
2Note that this model is estimated from the full parallel cor-
pus, rather than a held-out development set.
232
</bodyText>
<equation confidence="0.429767">
observed dependency: wx2 → wx3
r1 r2
assumed dependency: wy1 → wy3
</equation>
<figureCaption confidence="0.99868">
Figure 1: Inferring syntactic dependencies.
</figureCaption>
<bodyText confidence="0.99984975">
Features corresponding to aspects of the source
word itself and features corresponding to aspects of
the head of a noun phrase containing it were treated
as separate types.
</bodyText>
<subsectionHeader confidence="0.994281">
4.3 Gender
</subsectionHeader>
<bodyText confidence="0.99998405882353">
Czech nouns belong to one of three cases: feminine,
masculine, and neuter. Verbs and adjectives have to
agree with nouns for gender, although this agree-
ment is not marked in some forms of the verb. In
contrast to number and case, Czech gender generally
cannot be predicted from any aspect of the English
source sentence, which necessitates the use of fea-
tures that depend on another target-side word. This,
in turn, requires a more elaborate decoding proce-
dure, described in the next section. For verbs we
add a feature associating the gender of the verb with
the gender of its subject. For adjectives, we add a
feature tracking the gender of the governing nouns.
These dependencies are inferred from source-side
annotation via word alignments, as depicted in fig-
ure 1, without any use of target-side dependency
parses.
</bodyText>
<sectionHeader confidence="0.9651255" genericHeader="method">
5 Decoding with target-side model
dependencies
</sectionHeader>
<bodyText confidence="0.99834731372549">
The procedure for decoding with non-local target-
side feature dependencies is similar in its general
outlines to the standard method of decoding with a
language model, as described in Chiang (2007). The
search space is organized into arrays called charts,
each containing a set of items whose scores can be
compared with one another for the purposes of prun-
ing. Each rule that has matched the source sen-
tence belongs to a rule chart associated with its
location-anchored sequence of non-terminal and ter-
minal source-side symbols and any of its aspects
which may affect the score of a translation hypothe-
sis when it is combined with another rule. In the case
of the language model these aspects include any of
its target-side words that are part of still incomplete
n-grams. In the case of non-local target-side depen-
dencies this includes any information about features
needed for this rule’s estimate and tracking some
target-side inflection beyond it or features tracking
target-side inflections within this rule and needed for
computation of another rule’s estimate. We shall re-
fer to both these types of information as messages,
alluding to the fact that it will need to be conveyed to
another point in the derivation to finish the compu-
tation. Thus, a rule chart for a rule with one non-
terminal can be denoted as as (xi,
i+1Ax�,,+1, µ&gt;,
where we have introduced the symbol µ to represent
the set of messages associated with a given item in
the chart. Each item in the chart is associated with
a score s, based on any submodels and heuristic es-
timates that can already be computed for that item
and used to arrange the chart items into a priority
queue. Combinations of one or more rules that span
a substring of terminals are arranged into a differ-
ent type of chart which we shall call span charts. A
span chart has the form [i1, j1; µ1], where µ1 is a set
of messages, and its items are likewise prioritized by
a partial score s1.
The decoding procedure used in this work is based
on the cube pruning method, fully described in Chi-
ang (2007). Informally, whenever a rule chart is
combined with one or more span charts correspond-
ing to its non-terminals, we select best-scoring items
from each chart and update derivation scores by per-
forming any model computations that become pos-
sible once we combine the corresponding items.
Crucially, whenever an item in one of the charts
crosses a pruning threshold, we discard the rest of
that chart’s items, even though one of them could
generate a better-scoring partial derivation in com-
</bodyText>
<figure confidence="0.98425325">
wx3
wx
4
wy3
wx wx
1 2
wy wy
1 2
</figure>
<page confidence="0.995391">
233
</page>
<bodyText confidence="0.999988291666667">
bination with an item from another chart. It is there-
fore important to estimate incomplete model scores
as well as we can. We estimate these scores by com-
puting exponential models using all features without
non-local dependencies.
Schematically, our decoding procedure can be il-
lustrated by three elementary cases. We take the
example of computing an estimate for a rule whose
only terminal on both sides is a verb and which re-
quires a feature tracking the target-side gender in-
flection of the subject. We make use of a cache
storing all computed numerators and denominators
of the exponential model, which makes it easy to
recompute an estimate given an additional feature
and use the difference between it and the incomplete
estimate to update the score of the partial deriva-
tion. In the simplest case, illustrated in figure 2, the
non-local feature depends on the position within the
span of the rule’s non-terminal symbol, so that its
model estimate can be computed when its rule chart
is combined with the span chart for its non-terminal
symbol. This is accomplished using a feature mes-
sage, which indicates the gender inflection for the
subject and is denoted as mf(i), where the index
i refers to the position of its “recipient”. Figure 3
illustrates the case where the non-local feature lies
outside the rule’s span, but the estimated rule lies in-
side a non-terminal of the rule which contains the
feature dependency. This requires sending a rule
message m,(i), which includes information about
the estimated rule (which also serves as a pointer to
the score cache) and its feature dependency. The fi-
nal example, shown in figure 4, illustrates the case
where both types of messages need to be propagated
until we reach a rule chart that spans both ends of
the dependency. In this case, the full estimate for a
rule is computed while combining charts neither of
which corresponds directly to that rule.
A somewhat more formal account of the decod-
ing procedure is given in figure 5, which shows a
partial set of inference rules, generally following the
formalism used in Chiang (2007), but simplifying
it in several ways for brevity. Aside from the no-
tation introduced above, we also make use of two
updating functions. The message-updating function
um(p) takes a set of messages and outputs another
set that includes those messages m,(k) and mf(k)
whose destination k lies outside the span i, j of the
</bodyText>
<figure confidence="0.997281142857143">
A
A V
mf(2)
Sb
Score
cache
1 2
</figure>
<figureCaption confidence="0.60482">
Figure 2: Non-local dependency, case A.
</figureCaption>
<figure confidence="0.998368142857143">
A
Score
cache
Sb A
mr(1)
V
1 2
</figure>
<figureCaption confidence="0.836413">
Figure 3: Non-local dependency, case B.
</figureCaption>
<figure confidence="0.998897727272727">
A
1 2 3
Score
cache
A
Adv
A
mf(3)
V
mr(1)
Sb
</figure>
<figureCaption confidence="0.998464">
Figure 4: Non-local dependency, case C.
</figureCaption>
<page confidence="0.984377">
234
</page>
<figureCaption confidence="0.999837">
Figure 5: Simplified set of inference rules for decoding
with target-side model dependencies.
</figureCaption>
<bodyText confidence="0.991745">
chart. The score-updating function us(p) computes
those model estimates which can be completed us-
ing a message in the set p and returns the difference
between the new and old scores.
</bodyText>
<sectionHeader confidence="0.89544" genericHeader="method">
6 Modeling unobserved target inflections
</sectionHeader>
<bodyText confidence="0.999673608695652">
As a consequence of translating into a morphologi-
cally rich language, some inflected forms of target
words are unobserved in training data and cannot
be generated by the decoder under standard phrase-
based approaches. Exponential models with shared
features provide a straightforward way to estimate
probabilities of unobserved inflections. This is ac-
complished by extending the sets of target phrases
GEN(X) over which the model is normalized by
including some phrases which have not been ob-
served in the original sets. When additional rule
features with these unobserved target phrases are in-
cluded in the model, their weights will be estimated
even though they never appear in the training exam-
ples (i.e, in the numerator of their likelihoods).
We generate unobserved morphological variants
for target phrases starting from a generation proce-
dure for target words. Morphological variants for
words were generated using the ´UFAL MORPHO
tool (Kolovratn´ık and Pˇrikryl, 2008). The forms pro-
duced by the tool from the lemma of an observed in-
flected word form were subjected to several restric-
tions:
</bodyText>
<listItem confidence="0.996832416666667">
• For nouns, generated forms had to match the
original form for number.
• For verbs, generated forms had to match the
original form for tense and negation.
• For adjectives, generated forms had to match
the original form for degree of comparison and
negation.
• For pronouns, excepting relative and interrog-
ative pronouns, generated forms had to match
the original form for number, case, and gender.
• Non-standard inflection forms for all POS were
excluded.
</listItem>
<bodyText confidence="0.8851785">
The following criteria were used to select rules for
which expanded inflection sets were generated:
</bodyText>
<listItem confidence="0.6777765">
• The target phrase had to contain exactly one
word for which inflected forms could be gen-
erated according to the criteria given above.
• If the target phrase contained prepositions or
numerals, they had to be in a position not ad-
jacent to the inflected word. The rationale for
this criterion was the tendency of prepositions
and numerals to determine the inflection of ad-
jacent words.
• The lemmatized form of the phrase had to ac-
count for at least 25% of target phrases ex-
tracted for a given source phrase.
</listItem>
<bodyText confidence="0.9999308125">
The standard relative frequency estimates for the
p(X|Y ) phrase model and the lexical models do not
provide reasonable values for the decoder scores for
unobserved rules and words. In contrast, exponen-
tial models with surface and lemma features can be
straightforwardly trained for all of them. For the ex-
periments described below we trained an exponen-
tial model for the p(Y |X) lexical model. For greater
speed we estimate the probabilities for the other
two models using interpolated Kneser-Ney smooth-
ing (Chen and Goodman, 1998), where the surface
form of a rule or an aligned word pair plays to role
of a trigram, the pairing of the source surface form
with the lemmatized target form plays the role of a
bigram, and the source surface form alone plays the
role of a unigram.
</bodyText>
<page confidence="0.997777">
235
</page>
<sectionHeader confidence="0.902031" genericHeader="method">
7 Corpora and baselines
</sectionHeader>
<bodyText confidence="0.999905894736842">
We investigate the models using the 2009 edition
of the parallel treebank from ´UFAL (Bojar and
ˇZabokrtsk´y, 2009), containing 8,029,801 sentence
pairs from various genres. The corpus comes with
automatically generated annotation and a random-
ized split into training, development, and testing
sets. Thus, the annotation for the development and
testing sets provides a realistic reflection of what
could be obtained for arbitrary source text. The
English-side annotation follows the standards of the
Penn Treebank and includes dependency parses and
structural role labels such as subject and object. The
Czech side is labeled with several layers of annota-
tion, of which only the morphological tags and lem-
mas are used in this study. The Czech tags follow
the standards of the Prague Dependency Treebank
2.0.
The impact of the models on translation accuracy
was investigated for two experimental conditions:
</bodyText>
<listItem confidence="0.9847145">
• Small data set: trained on the news portion of
the data, containing 140,191 sentences; devel-
opment and testing sets containing 1500 sen-
tences of news text each.
• Large data set: trained on all the training data;
developing and testing sets each containing
1500 sentences of EU, news, and fiction data in
equal portions. The other genres were excluded
</listItem>
<bodyText confidence="0.958134139534884">
from the development and testing sets because
manual inspection showed them to contain a
considerable proportion of non-parallel sen-
tences pairs.
All conditions use word alignments produced by
sequential iterations of IBM model 1, HMM, and
IBM model 4 in GIZA++, followed by “diag-and”
symmetrization (Koehn et al., 2003). Thresholds
for phrase extraction and decoder pruning were set
to values typical for the baseline system (Chiang,
2007). Unaligned words at the outer edges of rules
or gaps were disallowed. A 5-gram language model
with modified interpolated Kneser-Ney smoothing
(Chen and Goodman, 1998) was trained by the
SRILM toolkit (Stolcke, 2002) on a set of 208 mil-
lion running words of text obtained by combining
the monolingual Czech text distributed by the 2010
ACL MT workshop with the Czech portion of the
training data. The decision rule was based on the
standard log-linear interpolation of several models,
with weights tuned by MERT on the development
set (Och, 2003). The baselines consisted of the lan-
guage model, two phrase translation models, two
lexical models, and a brevity penalty.
The proposed exponential phrase model contains
several modifications relative to a standard phrase
model (called baseline A below) with potential to
improve translation accuracy, including smoothed
estimates and estimates incorporating target-side
tags. To gain better insight into the role played by
different elements of the model, we also tested a sec-
ond baseline phrase model (baseline B), which at-
tempted to isolate the exponential model itself from
auxiliary modifications. Baseline B was different
from the experimental condition in using a gram-
mar limited to observed inflections and in replac-
ing the exponential p(Y X) phrase model by a rel-
ative frequency phrase model. It was different from
baseline A in computing the frequencies for the
p(Y X) phrase model based on counts of tagged
target phrases and in using the same smoothed es-
timates in the other models as were used in the ex-
perimental condition.
</bodyText>
<sectionHeader confidence="0.993953" genericHeader="method">
8 Parameter estimation
</sectionHeader>
<bodyText confidence="0.999593578947369">
Parameter estimation was performed using a modi-
fied version of the maximum entropy module from
SciPy (Jones et al., 2001) and the LBFGS-B algo-
rithm (Byrd et al., 1995). The objective included
an E2 regularizer with the regularization trade-off
set to 1. The amount of training data presented a
practical challenge for parameter estimation. Sev-
eral strategies were pursued to reduce the computa-
tional expenses. Following the approach of Mann
et al (2009), the training set was split into many
approximately equal portions, for which parameters
were estimated separately and then averaged for fea-
tures observed in multiple portions. The sets of tar-
get phrases for each source phrase prior to genera-
tion of additional inflected variants were truncated
by discarding extracted rules which were observed
with frequency less than the 200-th most frequent
target phrase for that source phrase.
Additional computational challenges remained
</bodyText>
<page confidence="0.992695">
236
</page>
<bodyText confidence="0.999970217391304">
due to an important difference between models with
shared features and usual phrase models. Features
appearing with source phrases found in development
and testing data share their weights with features ap-
pearing with other source phrases, so that filtering
the training set for development and testing data af-
fects the solution. Although there seems to be no
reason why this would positively affect translation
accuracy, to be methodologically strict we estimate
parameters for rule and lemma features without in-
flection features for larger models, and then com-
bine them with weights for inflection feature esti-
mated from a smaller portion of training data. This
should affect model performance negatively, since it
precludes learning trade-offs between evidence pro-
vided by the different kinds of features, and there-
fore it gives a conservative assessment of the re-
sults that could be obtained at greater computational
costs. The large data model used parameters for the
inflection features estimated from the small data set.
In the runs where exponential models were used they
replaced the corresponding baseline phrase transla-
tion model.
</bodyText>
<sectionHeader confidence="0.999147" genericHeader="conclusions">
9 Results and discussion
</sectionHeader>
<bodyText confidence="0.999851681818182">
Table 1 shows the results. Aside from the two base-
lines described in section 7 and the full exponen-
tial model, the table also reports results for an ex-
ponential model that excluded gender-based features
(and hence non-local target-side dependencies). The
highest scores were achieved by the full exponential
model, although baseline B produced surprisingly
disparate effects for the two data sets. This sug-
gests a complex interplay of the various aspects of
the model and training data whose exploration could
further improve the scores. Inclusion of gender-
based features produced small but consistent im-
provements. Table 2 shows a summary of the gram-
mars.
We further illustrate general properties of these
models using toy examples and the actual param-
eters estimated from the large data set. Table 3
shows representative rules with two different source
sides. The column marked “no infl.” shows model
estimates computed without inflection features. One
can see that for both rule sets the estimated probabil-
ities for rules observed a single time is only slightly
</bodyText>
<table confidence="0.998561">
Condition Small set Large set
Baseline A 0.1964 0.2562
Baseline B 0.2067 0.2522
Expon-gender 0.2114 0.2598
Expon+gender 0.2128 0.2615
</table>
<tableCaption confidence="0.9912445">
Table 1: BLUE scores on testing. See section 7 for a
description of the baselines.
</tableCaption>
<table confidence="0.999409">
Condition Total rules Observed rules
Small set 17,089,850 3,983,820
Large set 39,349,268 23,679,101
</table>
<tableCaption confidence="0.998132">
Table 2: Grammar sizes after and before generation of
unobserved inflections (all filtered for dev/test sets).
</tableCaption>
<bodyText confidence="0.999902764705882">
higher than probabilities for generated unobserved
rules. However, rules with relatively high counts
in the second set receive proportionally higher es-
timates, while the difference between the singleton
rule and the most frequent rule in the second set,
which was observed 3 times, is smoothed away to
an even greater extent. The last two columns show
model estimates when various inflection features are
included. There is a grammatical match between
nominative case for the target word and subject po-
sition for the aligned source word and between ac-
cusative case for the target word and direct object
role for the aligned source word. The other pair-
ings represent grammatical mismatches. One can
see that the probabilities for rules leading to correct
case matches are considerably higher than the alter-
natives with incorrect case matches.
</bodyText>
<table confidence="0.909783428571428">
rX Count Case No infl. Sb Obj
1 1 Dat 0.085 0.037 0.035
1 3 Acc 0.086 0.092 0.204
1 0 Nom 0.063 0.416 0.063
2 1 Instr 0.007 0.002 0.003
2 31 Nom 0.212 0.624 0.169
2 0 Acc 0.005 0.002 0.009
</table>
<tableCaption confidence="0.972774">
Table 3: The effect of inflection features on estimated
probabilities.
</tableCaption>
<page confidence="0.961894">
237
</page>
<bodyText confidence="0.9734735625">
10 Conclusion S.F. Chen and J.T. Goodman. 1998. An Empirical
This paper has introduced a scalable exponential Study of Smoothing Techniques for Language Mod-
phrase model for target languages with complex eling. Technical Report TR-10-98, Computer Science
morphology that can be trained on the full parallel Group, Harvard University.
corpus. We have showed how it can provide esti- D. Chiang. 2007. Hierarchical phrase-based translation.
mates for inflected forms unobserved in the training Computational Linguistics, 33(2):201-228.
data and described decoding procedures for features J. Gao, G. Andrew, M. Johnson and K. Toutanova. 2007.
with non-local target-side dependencies. The results A Comparative Study of Parameter Estimation Meth-
suggest that the model should be especially useful ods for Statistical Natural Language Processing. In
for languages with sparser resources, but that per- Proc. ACL 2007.
formance improvements can be obtained even for a M. Jeong, K. Toutanova, H. Suzuki, and C. Quirk. 2010.
very large parallel corpus. A Discriminative Lexicon Model for Complex Mor-
Acknowledgments phology. The Ninth Conference of the Association for
I would like to thank Philip Resnik, Amy Weinberg, Machine Translation in the Americas (AMTA-2010).
Hal Daum´e III, Chris Dyer, and the anonymous re- E. Jones, T. Oliphant, P. Peterson and others.
viewers for helpful comments relating to this work. SciPy: Open source scientific tools for Python.
</bodyText>
<sectionHeader confidence="0.700821" genericHeader="references">
References http://www.scipy.org/
</sectionHeader>
<reference confidence="0.996947783783784">
E. Avramidis and P. Koehn. 2008. Enriching Morpholog- P. Koehn and H. Hoang. 2007. Factored translation mod-
ically Poor Languages for Statistical Machine Transla- els. The Conference on Empirical Methods in Natural
tion. In Proc. ACL 2008. Language Processing (EMNLP), 2007.
A. Birch, M. Osborne and P. Koehn. 2008. Predicting P. Koehn, F.J. Och, and D. Marcu. 2003. Statistical
Success in Machine Translation. The Conference on Phrase-Based Translation. In Proceedings of the Hu-
Empirical Methods in Natural Language Processing man Language Technology Conference (HLT-NAACL
(EMNLP), 2008. 2003).
O. Bojar. 2007. English-to-Czech Factored Machine D. Kolovratn´ık and L. Pˇrikryl. 2008. Pro-
Translation. In Proceedings of the Second Workshop gram´atorsk´a dokumentace k projektu Morfo.
on Statistical Machine Translation. http://ufal.mff.cuni.cz/morfo/, 2008.
O. Bojar and Z. ˇZabokrtsk´y. 2009. Large Parallel G. Mann, R. McDonald, M. Mohri, N. Silberman, D.
Treebank with Rich Annotation. Charles University, Walker. 2009. Efficient Large-Scale Distributed
Prague. http://ufal.mff.cuni.cz/czeng/czeng09/, 2009. Training of Conditional Maximum Entropy Models.
R. H. Byrd, P. Lu and J. Nocedal. 1995. A Limited Mem- Advances in Neural Information Processing Systems
ory Algorithm for Bound Constrained Optimization. (NIPS), 2009.
SIAM Journal on Scientific and Statistical Computing, J. Naughton. 2005. Czech. An Essential Grammar. Rout-
16(5), pp. 1190-1208. ledge, 2005.
M. Carpuat and D. Wu. 2007a. Improving Statistical A.Y. Ng. 2004. Feature selection, L1 vs. L2 regular-
Machine Translation using Word Sense Disambigua- ization, and rotational invariance. In Proceedings of
tion. Joint Conference on Empirical Methods in Nat- the Twenty-first International Conference on Machine
ural Language Processing and Computational Natural Learning.
Language Learning (EMNLP-CoNLL 2007). F.J. Och. 2003. Minimum Error Rate Training for Statis-
M. Carpuat and D. Wu. 2007b. How Phrase Sense Dis- tical Machine Translation. In Proc. ACL 2003.
ambiguation outperforms Word Sense Disambiguation A. Ramanathan, H. Choudhary, A. Ghosh, P. Bhat-
for Statistical Machine Translation. 11th Conference tacharyya. 2009. Case markers and Morphology: Ad-
on Theoretical and Methodological Issues in Machine dressing the crux of the fluency problem in English-
Translation (TMI 2007) Hindi SMT. In Proc. ACL 2009.
Y.S. Chan, H.T. Ng, and D. Chiang. 2007. Word sense A. Stolcke. 2002. SRILM – An Extensible Language
disambiguation improves statistical machine transla- Modeling Toolkit. International Conference on Spo-
tion. In Proc. ACL 2007. ken Language Processing, 2002.
238 M. Subotin. 2008. Generalizing Local Translation Mod-
els. Proceedings of SSST-2, Second Workshop on
Syntax and Structure in Statistical Translation.
R. Yeniterzi and K. Oflazer. 2010. Syntax-to-
Morphology Mapping in Factored Phrase-Based Sta-
tistical Machine Translation from English to Turkish.
In Proc. ACL 2010.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.512812">
<title confidence="0.995484">An exponential translation model for target language morphology</title>
<author confidence="0.968017">Michael</author>
<email confidence="0.538816">Paxfire,</email>
<affiliation confidence="0.997407">Department of Linguistics &amp; UMIACS, University of</affiliation>
<email confidence="0.998366">msubotin@gmail.com</email>
<abstract confidence="0.999147526315789">This paper presents an exponential model for translation into highly inflected languages which can be scaled to very large datasets. As in other recent proposals, it predicts targetside phrases and can be conditioned on sourceside context. However, crucially for the task of modeling morphological generalizations, it estimates feature parameters from the entire training set rather than as a collection of separate classifiers. We apply it to English-Czech translation, using a variety of features capturing potential predictors for case, number, and gender, and one of the largest publicly available parallel data sets. We also describe generation and modeling of inflected forms unobserved in training data and decoding procedures for a model with non-local target-side feature dependencies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>