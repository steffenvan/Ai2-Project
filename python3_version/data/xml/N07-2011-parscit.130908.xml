<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.7337354">
Exploring Affect-Context Dependencies for Adaptive System Development
Kate Forbes-Riley
Learning R&amp;D Ctr.
Univ. Pittsburgh
Pittsburgh, PA 15260
</title>
<email confidence="0.987624">
forbesk@pitt.edu
</email>
<author confidence="0.579394">
Mihai Rotaru
</author>
<affiliation confidence="0.4184915">
Computer Science Dpt.
Univ. Pittsburgh
</affiliation>
<address confidence="0.353801">
Pittsburgh, PA 15260
</address>
<email confidence="0.995253">
mrotaru@cs.pitt.edu
</email>
<note confidence="0.936009">
Diane J. Litman
</note>
<title confidence="0.68177825">
Learning R&amp;D Ctr.
Computer Science Dpt.
Univ. Pittsburgh
Pittsburgh, PA 15260
</title>
<email confidence="0.991482">
litman@cs.pitt.edu
</email>
<note confidence="0.45397275">
Joel Tetreault
Learning R&amp;D Ctr.
Univ. Pittsburgh
Pittsburgh, PA 15260
</note>
<email confidence="0.995122">
tetreaul@pitt.edu
</email>
<sectionHeader confidence="0.993805" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999742">
We use x2 to investigate the context de-
pendency of student affect in our com-
puter tutoring dialogues, targeting uncer-
tainty in student answers in 3 automati-
cally monitorable contexts. Our results
show significant dependencies between
uncertain answers and specific contexts.
Identification and analysis of these depen-
dencies is our first step in developing an
adaptive version of our dialogue system.
</bodyText>
<sectionHeader confidence="0.998795" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999890318181818">
Detecting and adapting to user affect is being ex-
plored by many researchers to improve dialogue sys-
tem quality. Detection has received much atten-
tion (e.g., (Litman and Forbes-Riley, 2004; Lee and
Narayanan, 2005)), but less work has been done on
adaptation, due to the difficulty of developing re-
sponses and applying them at the right time. Most
work on adaptation takes a context-independent ap-
proach: use the same type of response after all in-
stances of an affective state. For example, Liu and
Picard (2005)’s health assessment system responds
with empathy to all instances of user stress.
Research suggests, however, that it may be more
effective to take a context-dependent approach: de-
velop multiple responses for each affective state,
whose use depends on the state’s context. E.g., in the
tutoring domain, Pon-Barry et al. (2006) show that
human tutors use multiple responses to uncertain
student answers, depending on the answer’s correct-
ness and prior context. In the information-seeking
domain, it is commonly believed that while an apol-
ogy is a good default response to user frustration (as
</bodyText>
<page confidence="0.993624">
41
</page>
<bodyText confidence="0.998844884615385">
in (Klein et al., 2002)), one context requires a differ-
ent response: after several frustrated user turns, the
call should be forwarded to a human operator.
A context-dependent approach to affect adapta-
tion must address 2 issues: in what contexts to adapt,
and what responses to use there. This paper ad-
dresses the first issue and targets student uncertainty
in our computer tutoring dialogues. Although our di-
alogues have a Question-Answer format, our system
contains 275 tutor questions. Treating each question
as a context is too labor-intensive for adaptation de-
velopment and creates a data sparsity issue. Instead
we treat automatically monitorable question proper-
ties as contexts. Here we examine 3 contexts: the di-
alogue act interpretation, and the discourse structure
depth and transition, of the prior tutor question. We
use x2 to investigate the context dependency of un-
certain student answers (correct and incorrect). Our
results show that some contexts are significantly as-
sociated with uncertain answers. Our next step will
be to use these significant dependencies to develop
system responses to uncertain answers in these con-
texts. These responses will be based both on our
hypotheses about why uncertainty is associated with
these contexts, and on analyses of human tutor re-
sponses to uncertain answers in these contexts.
</bodyText>
<subsectionHeader confidence="0.63623">
2 Student Uncertainty and Prior Context
</subsectionHeader>
<bodyText confidence="0.999617777777778">
ITSPOKE is a speech-enabled version of a text-
based tutoring system (VanLehn et al., 2002). The
student first types an essay answering one of 5 qual-
itative physics problems. ITSPOKE parses the es-
say, extracts dialogue topics concerning misconcep-
tions, then engages the student in dialogue. In this
study we used 2 ITSPOKE corpora containing 4590
student turns over 185 dialogues from 37 students.
Figure 1 shows an annotated dialogue excerpt.
</bodyText>
<note confidence="0.733525666666667">
Proceedings of NAACL HLT 2007, Companion Volume, pages 41–44,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
ITSPOKE4: Good. Does the packet have an acceleration? If yes please specify its direction. [SAQ, Advance, D1]
STUDENT4: horizontally forward yes [non-uncertain, incorrect]
ITSPOKE5: Well... To find the packet’s acceleration we will use Newton’s 2nd law. What is the definition of this law? [LAQ,
Push, D2]
</note>
<bodyText confidence="0.7886025">
STUDENT5: an object in motion tends to stay in motion until it’s act by an outside force [uncertain, incorrect]
ITSPOKE6: Well... Newton’s 2nd law says that the net force acting on an object equals the mass times the acceleration of the
object. We can define Newton’s 2nd law as F=m*a. Hence what can we determine about the acceleration of the packet given
that we know the net force acting on it is not zero and points straight down? [DAQ, Advance, D2]
</bodyText>
<figure confidence="0.492541333333333">
STUDENT6: I don’t know [uncertain, incorrect]
ITSPOKE7: Well... &lt; further discussion ofNewton’s 2nd law...&gt; So once again on the original question. Does the packet have an
acceleration? If yes please specify its direction.[SAQ, PopUp, D1]
</figure>
<figureCaption confidence="0.997023">
Figure 1: ITSPOKE Annotated Dialogue Excerpt
</figureCaption>
<subsectionHeader confidence="0.993767">
2.1 Uncertainty and Correctness Annotations
</subsectionHeader>
<bodyText confidence="0.963718527777778">
ITSPOKE, like most computer tutors, responds only
to student correctness. ITSPOKE labels each an-
swer as correct or incorrect1. If correct, ITSPOKE
moves on to the next question. If incorrect, then for
questions on simple topics, ITSPOKE gives the cor-
rect answer and moves on, while for questions on
complex topics (ITSPOKE4, Figure 1), ITSPOKE
initiates a sub-dialogue with remediation questions
(ITSPOKE5 - ITSPOKE6), before moving on.
Recent computer tutoring research has shown in-
terest in responding to student affect2 over cor-
rectness. Uncertainty is of particular interest: re-
searchers hypothesize that uncertainty and incorrect-
ness each create an opportunity to learn (VanLehn
et al., 2003). They cannot be equated, however.
First, an uncertain answer may be correct or incor-
rect (Pon-Barry et al., 2006). Second, uncertainty in-
dicates that the student perceives a possible miscon-
ception in their knowledge. Thus, system responses
to uncertain answers can address both the correct-
ness and the perceived misconception.
In our ITSPOKE corpora, each student answer
has been manually annotated as uncertain or non-
uncertain3: uncertain is used to label answers ex-
pressing uncertainty or confusion about the material;
non-uncertain is used to label all other answers.
1We have also manually labeled correctness in our data;
agreement between ITSPOKE and human is 0.79 Kappa (90%).
2We use ‘affect’ to cover emotions and attitudes that affect
how students communicate. Although some argue ‘emotion’
and ‘attitude’ should be distinguished, some speech researchers
find the narrow sense of ‘emotion’ too restrictive because it ex-
cludes states where emotion is present but not full-blown, in-
cluding arousal and attitude (Cowie and Cornelius, 2003).
3A second annotator relabeled our dataset, yielding inter-
annotator agreement of 0.73 Kappa (92%).
</bodyText>
<subsectionHeader confidence="0.998752">
2.2 Context Annotations
</subsectionHeader>
<bodyText confidence="0.999879615384615">
Here we examine 3 automatically monitorable tutor
question properties as our contexts for uncertainty:
Tutor Question Acts: In prior work one annotator
labeled 4 Tutor Question Acts in one ITSPOKE cor-
pus (Litman and Forbes-Riley, 2006)4: Short (SAQ),
Long (LAQ), and Deep Answer Question (DAQ) dis-
tinguish the question in terms of content and the type
of answer it requires. Repeat (RPT) labels variants
of “Can you repeat that?” after rejections. From
these annotations we built a hash table associating
each ITSPOKE question with a Question Act label;
with this table we automatically labeled ITSPOKE
questions in our second ITSPOKE corpus.
</bodyText>
<subsectionHeader confidence="0.452437">
Discourse Structure Depth/Transition: In prior
</subsectionHeader>
<bodyText confidence="0.999690117647059">
work we showed that the discourse structure Depth
and Transition for each ITSPOKE turn can be au-
tomatically annotated (Rotaru and Litman, 2006).
E.g., as shown in Figure 1, ITSPOKE4,7 have depth
1 and ITSPOKE5,6 have depth 2. We combine lev-
els 3 and above (3+) due to data sparsity. 6 Transi-
tion labels represent the turn’s position relative to the
prior ITSPOKE turn: NewTopLevel labels the first
question after an essay. Advance labels questions at
the same depth as the prior question (ITSPOKE4,6).
Push labels the first question in a sub-dialogue
(after an incorrect answer) (ITSPOKE5). After a
sub-dialogue, ITSPOKE asks the original question
again, labeled PopUp (ITSPOKE7), or moves on to
the next question, labeled PopUpAdv. SameGoal la-
bels both ITSPOKE RPTS (after rejections) and re-
peated questions after timeouts.
</bodyText>
<footnote confidence="0.714848333333333">
4Our Acts are based on related work (Graesser et al., 1995).
Two annotators labeled the Acts in 8 dialogues in a parallel hu-
man tutoring corpus, with agreement of 0.75 Kappa (90%).
</footnote>
<page confidence="0.99852">
42
</page>
<sectionHeader confidence="0.997489" genericHeader="method">
3 Uncertainty Context Dependencies
</sectionHeader>
<bodyText confidence="0.999860846153846">
We use the x2 test to investigate the context depen-
dency of uncertain (unc) or non-uncertain (nonunc)
student answers that are correct (C) or incorrect (I).
First, we compute an overall x2 value between each
context variable and the student answer variable. For
example, the Question Act variable (QACT) has 4
values: SAQ, LAQ, DAQ, RPT. The answer vari-
able (SANSWER) also has 4 values: uncC, uncI,
nonuncC, nonuncI. Table 1 (last column) shows the
x2 value between these variables is 203.38, which
greatly exceeds the critical value of 16.92 (p&lt; 0.05,
df=9), indicating a highly significant dependency.
Significance increases as the x2 value increases.
</bodyText>
<table confidence="0.999137944444444">
Dependency Obs. Exp. x2
QACT - SANSWER 203.38
LAQ - uncC + 72 22 133.98
LAQ - uncI + 43 27 11.17
LAQ - nonuncC - 96 151 50.13
LAQ - nonuncI = 48 60 3.10
DAQ - uncC = 22 22 0.01
DAQ - uncI + 37 27 4.57
DAQ - nonuncC = 135 149 3.53
DAQ - nonuncI = 63 59 0.35
SAQ - uncC - 285 328 41.95
SAQ - uncI - 377 408 17.10
SAQ - nonuncC + 2368 2271 66.77
SAQ - nonuncI - 875 898 5.31
RPT - uncC - 7 14 4.15
RPT - uncI = 22 18 1.25
RPT - nonuncC - 70 98 20.18
RPT - nonuncI + 70 39 33.59
</table>
<tableCaption confidence="0.867627">
Table 1: Tutor Question Act Dependencies (p&lt;.05:
critical x2=16.92 (df=9); critical x2=3.84 (df=1))
</tableCaption>
<bodyText confidence="0.99680921875">
However, this does not tell us which variable val-
ues are significantly dependent. To do this, we create
a binary variable from each value of the context and
answer variables. E.g., the binary variable for LAQ
has 2 values: “LAQ” and “Anything Else”, and the
binary variable for uncC has 2 values: “uncC” and
“Anything Else”. We then compute the x2 value be-
tween the binary variables. Table 1 shows this value
is 133.98, which greatly exceeds the critical value of
3.84 (p&lt; 0.05, df=1). The table also shows the ob-
served (72) and expected (22) counts. Comparison
determines the sign of the dependency: uncC occurs
significantly more than expected (+) after LAQ. The
“=” sign indicates a non-significant dependency.
Table 1 shows uncertain answers (uncC and uncI)
occur significantly more than expected after LAQs.
In contrast, non-uncertain answers occur signifi-
cantly less (-), or aren’t significantly dependent (=).
Also, uncI occurs significantly more than expected
after DAQs. We hypothesize that LAQs and DAQs
are associated with more uncertainty because they
are harder questions requiring definitions or deep
reasoning. Not surprisingly, uncertain (and incor-
rect) answers occur significantly less than expected
after SAQs (easier fill-in-the-blank questions). Un-
certainty shows very weak dependencies on RPTs.
Table 2 shows that Depth1 is associated with more
correctness and less uncertainty overall. Both types
of correct answer occur significantly more than ex-
pected, but this dependency is stronger for nonuncC.
Both incorrect answers occur significantly less than
expected, but this dependency is stronger for uncI.
</bodyText>
<table confidence="0.929341714285714">
Dependency Obs. Exp. x2
Depth# - SANSWER 53.85
Depth1 - uncC + 250 228 5.46
Depth1 - uncI - 230 283 27.55
Depth1 - nonuncC + 1661 1579 24.73
Depth1 - nonuncI - 575 625 12.66
Depth2 - uncC - 78 101 7.80
Depth2 - uncI + 156 125 11.26
Depth2 - nonuncC - 664 699 5.65
Depth2 - nonuncI + 304 277 4.80
Depth3+ - uncC = 58 57 0.05
Depth3+ - uncI + 93 70 9.76
Depth3+ - nonuncC - 344 391 15.66
Depth3+ - nonuncI + 177 155 4.94
</table>
<tableCaption confidence="0.6830915">
Table 2: Depth Dependencies (p&lt;.05: critical
x2=12.59 (df=6); critical x2=3.84 (df=1))
</tableCaption>
<bodyText confidence="0.998180125">
At Depths 2 and 3+, correct answers occur sig-
nificantly less than expected or show no signifi-
cance. Incorrect answers occur significantly more
than expected, and the dependencies are stronger for
uncI. We hypothesize that deeper depths are asso-
ciated with increased uncertainty and incorrectness
because they correspond to deeper knowledge gaps;
uncertainty here may also relate to a perceived lack
of cohesion between sub-topic and larger solution.
Table 3 shows Pushes have the same dependen-
cies as deeper depths (increased uncertainty and in-
correctness); however, here the uncI dependency is
only slightly stronger than nonuncI, which suggests
that increased uncertainty at deeper depths is more
reliably associated with remediation questions after
the Push. Although uncertainty shows only weak
</bodyText>
<page confidence="0.999485">
43
</page>
<bodyText confidence="0.9988155">
dependencies on PopUps, after PopUpAdvs the uncI
dependency is strong, with uncI occurring more than
expected. We hypothesize that this dependency re-
lates to students losing track of the original ques-
tion/larger topic. Uncertainty shows only weak de-
pendencies on Advances. After NewTopLevels, in-
correct answers occur less than expected, but the de-
pendency is stronger for nonuncI. After SameGoals,
incorrect answers occur more than expected, but the
dependency is stronger for nonuncI. Compared with
the RPT results, the SameGoal results suggest stu-
dents feel increased uncertainty after timeouts.
</bodyText>
<table confidence="0.999898038461538">
Dependency Obs. Exp. x2
TRANS - SANSWER 190.97
Push - uncC = 68 57 2.89
Push - uncI + 100 70 16.37
Push - nonuncC - 313 392 44.51
Push - nonuncI + 193 155 14.13
PopUp - uncC - 23 36 5.89
PopUp - uncI - 32 45 4.68
PopUp - nonuncC = 260 251 0.81
PopUp - nonuncI + 117 99 4.47
PopUpAdv - uncC = 8 13 2.50
PopUpAdv - uncI + 32 17 16.22
PopUpAdv - nonuncC - 76 93 7.72
PopUpAdv - nonuncI = 44 37 1.89
Advance - uncC = 217 205 1.70
Advance - uncI - 223 254 9.06
Advance - nonuncC + 1465 1416 8.66
Advance - nonuncI - 530 560 4.51
NewTopLevel - uncC = 53 54 0.04
NewTopLevel - uncI - 49 67 6.47
NewTopLevel - nonuncC + 463 375 57.33
NewTopLevel - nonuncI - 80 148 47.63
SameGoal - uncC = 17 21 0.70
SameGoal - uncI + 43 25 14.24
SameGoal - nonuncC - 92 152 44.25
SameGoal - nonuncI + 92 56 31.43
</table>
<tableCaption confidence="0.6922995">
Table 3: Transition Dependencies (p&lt;.05: critical
x2=25.00 (df=15); critical x2=3.84 (df=1))
</tableCaption>
<sectionHeader confidence="0.995372" genericHeader="method">
4 Current Directions
</sectionHeader>
<bodyText confidence="0.999989">
We analyzed dependencies between uncertain stu-
dent answers and 3 automatically monitorable con-
texts. We plan to examine more contexts, such as
a Topic Repetition variable that tracks similar ques-
tions about a topic (e.g. gravity) across dialogues.
Our next step will be to use the significant de-
pendencies to develop system responses to uncer-
tain answers in these contexts. These responses will
be based both on our hypotheses about why uncer-
tainty is significantly associated with these contexts,
as well as on analyses of human tutor responses
in these contexts, using our human tutoring corpus,
which was collected with our first ITSPOKE corpus
using the same experimental procedure.
We also plan to investigate context dependencies
for other affective states, such as student frustration.
</bodyText>
<sectionHeader confidence="0.998437" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.8770215">
NSF (#0631930, #0354420 and #0328431) and
ONR (N00014-04-1-0108) support this research.
</bodyText>
<sectionHeader confidence="0.997564" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999811735294117">
R. Cowie and R. R. Cornelius. 2003. Describing the
emotional states that are expressed in speech. Speech
Communication, 40:5–32.
A. Graesser, N. Person, and J. Magliano. 1995. Collabo-
rative dialog patterns in naturalistic one-on-one tutor-
ing. Applied Cognitive Psychology, 9:495–522.
J. Klein, Y. Moon, and R. Picard. 2002. This computer
responds to user frustration: Theory, design, and re-
sults. Interacting with Computers, 14:119–140.
C. M. Lee and S. Narayanan. 2005. Towards detect-
ing emotions in spoken dialogs. IEEE Transactions
on Speech and Audio Processing, 13(2), March.
D. Litman and K. Forbes-Riley. 2004. Predicting student
emotions in computer-human tutoring dialogues. In
Proc. ACL, pages 352–359.
D. J. Litman and K. Forbes-Riley. 2006. Correlations
between dialogue acts and learning in spoken tutoring
dialogues. Natural Language Engineering, 12(2).
K. Liu and R. W. Picard. 2005. Embedded empathy
in continuous, interactive health assessment. In CHI
Workshop on HCI Challenges in Health Assessment.
H. Pon-Barry, K. Schultz, E. Bratt, B. Clark, and S. Pe-
ters. 2006. Responding to student uncertainty in spo-
ken tutorial dialogue systems. International Journal
ofArtificial Intelligence in Education, 16:171–194.
M. Rotaru and D. Litman. 2006. Exploiting discourse
structure for spoken dialogue performance analysis. In
Proceedings of EMNLP, Sydney, Australia.
K. VanLehn, P. W. Jordan, and C. P. Ros´e et al. 2002. The
architecture of Why2-Atlas: A coach for qualitative
physics essay writing. In Proceedings ofITS.
K. VanLehn, S. Siler, and C. Murray. 2003. Why do
only some events cause learning during human tutor-
ing? Cognition and Instruction, 21(3):209–249.
</reference>
<page confidence="0.999294">
44
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.131842">
<title confidence="0.998734">Exploring Affect-Context Dependencies for Adaptive System Development</title>
<author confidence="0.763117">Kate</author>
<affiliation confidence="0.863237">Learning R&amp;D Univ.</affiliation>
<address confidence="0.751202">Pittsburgh, PA</address>
<email confidence="0.999541">forbesk@pitt.edu</email>
<author confidence="0.887274">Mihai</author>
<affiliation confidence="0.9992845">Computer Science Univ.</affiliation>
<address confidence="0.55053">Pittsburgh, PA</address>
<email confidence="0.998815">mrotaru@cs.pitt.edu</email>
<author confidence="0.989203">J Diane</author>
<affiliation confidence="0.923515333333333">Learning R&amp;D Computer Science Univ.</affiliation>
<address confidence="0.821044">Pittsburgh, PA</address>
<email confidence="0.99953">litman@cs.pitt.edu</email>
<author confidence="0.961152">Joel</author>
<affiliation confidence="0.987858">Learning R&amp;D Univ.</affiliation>
<address confidence="0.843817">Pittsburgh, PA</address>
<email confidence="0.999466">tetreaul@pitt.edu</email>
<abstract confidence="0.999625272727273">use to investigate the context dependency of student affect in our computer tutoring dialogues, targeting uncertainty in student answers in 3 automatically monitorable contexts. Our results show significant dependencies between uncertain answers and specific contexts. Identification and analysis of these dependencies is our first step in developing an adaptive version of our dialogue system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Cowie</author>
<author>R R Cornelius</author>
</authors>
<title>Describing the emotional states that are expressed in speech.</title>
<date>2003</date>
<journal>Speech Communication,</journal>
<pages>40--5</pages>
<contexts>
<context position="6776" citStr="Cowie and Cornelius, 2003" startWordPosition="1038" endWordPosition="1041">certain3: uncertain is used to label answers expressing uncertainty or confusion about the material; non-uncertain is used to label all other answers. 1We have also manually labeled correctness in our data; agreement between ITSPOKE and human is 0.79 Kappa (90%). 2We use ‘affect’ to cover emotions and attitudes that affect how students communicate. Although some argue ‘emotion’ and ‘attitude’ should be distinguished, some speech researchers find the narrow sense of ‘emotion’ too restrictive because it excludes states where emotion is present but not full-blown, including arousal and attitude (Cowie and Cornelius, 2003). 3A second annotator relabeled our dataset, yielding interannotator agreement of 0.73 Kappa (92%). 2.2 Context Annotations Here we examine 3 automatically monitorable tutor question properties as our contexts for uncertainty: Tutor Question Acts: In prior work one annotator labeled 4 Tutor Question Acts in one ITSPOKE corpus (Litman and Forbes-Riley, 2006)4: Short (SAQ), Long (LAQ), and Deep Answer Question (DAQ) distinguish the question in terms of content and the type of answer it requires. Repeat (RPT) labels variants of “Can you repeat that?” after rejections. From these annotations we bu</context>
</contexts>
<marker>Cowie, Cornelius, 2003</marker>
<rawString>R. Cowie and R. R. Cornelius. 2003. Describing the emotional states that are expressed in speech. Speech Communication, 40:5–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Graesser</author>
<author>N Person</author>
<author>J Magliano</author>
</authors>
<title>Collaborative dialog patterns in naturalistic one-on-one tutoring. Applied Cognitive Psychology,</title>
<date>1995</date>
<pages>9--495</pages>
<contexts>
<context position="8474" citStr="Graesser et al., 1995" startWordPosition="1304" endWordPosition="1307">ue to data sparsity. 6 Transition labels represent the turn’s position relative to the prior ITSPOKE turn: NewTopLevel labels the first question after an essay. Advance labels questions at the same depth as the prior question (ITSPOKE4,6). Push labels the first question in a sub-dialogue (after an incorrect answer) (ITSPOKE5). After a sub-dialogue, ITSPOKE asks the original question again, labeled PopUp (ITSPOKE7), or moves on to the next question, labeled PopUpAdv. SameGoal labels both ITSPOKE RPTS (after rejections) and repeated questions after timeouts. 4Our Acts are based on related work (Graesser et al., 1995). Two annotators labeled the Acts in 8 dialogues in a parallel human tutoring corpus, with agreement of 0.75 Kappa (90%). 42 3 Uncertainty Context Dependencies We use the x2 test to investigate the context dependency of uncertain (unc) or non-uncertain (nonunc) student answers that are correct (C) or incorrect (I). First, we compute an overall x2 value between each context variable and the student answer variable. For example, the Question Act variable (QACT) has 4 values: SAQ, LAQ, DAQ, RPT. The answer variable (SANSWER) also has 4 values: uncC, uncI, nonuncC, nonuncI. Table 1 (last column) s</context>
</contexts>
<marker>Graesser, Person, Magliano, 1995</marker>
<rawString>A. Graesser, N. Person, and J. Magliano. 1995. Collaborative dialog patterns in naturalistic one-on-one tutoring. Applied Cognitive Psychology, 9:495–522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Klein</author>
<author>Y Moon</author>
<author>R Picard</author>
</authors>
<title>This computer responds to user frustration: Theory, design, and results. Interacting with Computers,</title>
<date>2002</date>
<pages>14--119</pages>
<contexts>
<context position="2011" citStr="Klein et al., 2002" startWordPosition="299" endWordPosition="302">’s health assessment system responds with empathy to all instances of user stress. Research suggests, however, that it may be more effective to take a context-dependent approach: develop multiple responses for each affective state, whose use depends on the state’s context. E.g., in the tutoring domain, Pon-Barry et al. (2006) show that human tutors use multiple responses to uncertain student answers, depending on the answer’s correctness and prior context. In the information-seeking domain, it is commonly believed that while an apology is a good default response to user frustration (as 41 in (Klein et al., 2002)), one context requires a different response: after several frustrated user turns, the call should be forwarded to a human operator. A context-dependent approach to affect adaptation must address 2 issues: in what contexts to adapt, and what responses to use there. This paper addresses the first issue and targets student uncertainty in our computer tutoring dialogues. Although our dialogues have a Question-Answer format, our system contains 275 tutor questions. Treating each question as a context is too labor-intensive for adaptation development and creates a data sparsity issue. Instead we tr</context>
</contexts>
<marker>Klein, Moon, Picard, 2002</marker>
<rawString>J. Klein, Y. Moon, and R. Picard. 2002. This computer responds to user frustration: Theory, design, and results. Interacting with Computers, 14:119–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C M Lee</author>
<author>S Narayanan</author>
</authors>
<title>Towards detecting emotions in spoken dialogs.</title>
<date>2005</date>
<journal>IEEE Transactions on Speech and Audio Processing,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="1094" citStr="Lee and Narayanan, 2005" startWordPosition="149" endWordPosition="152">e x2 to investigate the context dependency of student affect in our computer tutoring dialogues, targeting uncertainty in student answers in 3 automatically monitorable contexts. Our results show significant dependencies between uncertain answers and specific contexts. Identification and analysis of these dependencies is our first step in developing an adaptive version of our dialogue system. 1 Introduction Detecting and adapting to user affect is being explored by many researchers to improve dialogue system quality. Detection has received much attention (e.g., (Litman and Forbes-Riley, 2004; Lee and Narayanan, 2005)), but less work has been done on adaptation, due to the difficulty of developing responses and applying them at the right time. Most work on adaptation takes a context-independent approach: use the same type of response after all instances of an affective state. For example, Liu and Picard (2005)’s health assessment system responds with empathy to all instances of user stress. Research suggests, however, that it may be more effective to take a context-dependent approach: develop multiple responses for each affective state, whose use depends on the state’s context. E.g., in the tutoring domain</context>
</contexts>
<marker>Lee, Narayanan, 2005</marker>
<rawString>C. M. Lee and S. Narayanan. 2005. Towards detecting emotions in spoken dialogs. IEEE Transactions on Speech and Audio Processing, 13(2), March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Litman</author>
<author>K Forbes-Riley</author>
</authors>
<title>Predicting student emotions in computer-human tutoring dialogues.</title>
<date>2004</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>352--359</pages>
<contexts>
<context position="1068" citStr="Litman and Forbes-Riley, 2004" startWordPosition="145" endWordPosition="148">etreaul@pitt.edu Abstract We use x2 to investigate the context dependency of student affect in our computer tutoring dialogues, targeting uncertainty in student answers in 3 automatically monitorable contexts. Our results show significant dependencies between uncertain answers and specific contexts. Identification and analysis of these dependencies is our first step in developing an adaptive version of our dialogue system. 1 Introduction Detecting and adapting to user affect is being explored by many researchers to improve dialogue system quality. Detection has received much attention (e.g., (Litman and Forbes-Riley, 2004; Lee and Narayanan, 2005)), but less work has been done on adaptation, due to the difficulty of developing responses and applying them at the right time. Most work on adaptation takes a context-independent approach: use the same type of response after all instances of an affective state. For example, Liu and Picard (2005)’s health assessment system responds with empathy to all instances of user stress. Research suggests, however, that it may be more effective to take a context-dependent approach: develop multiple responses for each affective state, whose use depends on the state’s context. E.</context>
</contexts>
<marker>Litman, Forbes-Riley, 2004</marker>
<rawString>D. Litman and K. Forbes-Riley. 2004. Predicting student emotions in computer-human tutoring dialogues. In Proc. ACL, pages 352–359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Litman</author>
<author>K Forbes-Riley</author>
</authors>
<title>Correlations between dialogue acts and learning in spoken tutoring dialogues.</title>
<date>2006</date>
<journal>Natural Language Engineering,</journal>
<volume>12</volume>
<issue>2</issue>
<contexts>
<context position="7135" citStr="Litman and Forbes-Riley, 2006" startWordPosition="1091" endWordPosition="1094">ough some argue ‘emotion’ and ‘attitude’ should be distinguished, some speech researchers find the narrow sense of ‘emotion’ too restrictive because it excludes states where emotion is present but not full-blown, including arousal and attitude (Cowie and Cornelius, 2003). 3A second annotator relabeled our dataset, yielding interannotator agreement of 0.73 Kappa (92%). 2.2 Context Annotations Here we examine 3 automatically monitorable tutor question properties as our contexts for uncertainty: Tutor Question Acts: In prior work one annotator labeled 4 Tutor Question Acts in one ITSPOKE corpus (Litman and Forbes-Riley, 2006)4: Short (SAQ), Long (LAQ), and Deep Answer Question (DAQ) distinguish the question in terms of content and the type of answer it requires. Repeat (RPT) labels variants of “Can you repeat that?” after rejections. From these annotations we built a hash table associating each ITSPOKE question with a Question Act label; with this table we automatically labeled ITSPOKE questions in our second ITSPOKE corpus. Discourse Structure Depth/Transition: In prior work we showed that the discourse structure Depth and Transition for each ITSPOKE turn can be automatically annotated (Rotaru and Litman, 2006). </context>
</contexts>
<marker>Litman, Forbes-Riley, 2006</marker>
<rawString>D. J. Litman and K. Forbes-Riley. 2006. Correlations between dialogue acts and learning in spoken tutoring dialogues. Natural Language Engineering, 12(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Liu</author>
<author>R W Picard</author>
</authors>
<title>Embedded empathy in continuous, interactive health assessment.</title>
<date>2005</date>
<booktitle>In CHI Workshop on HCI Challenges in Health Assessment.</booktitle>
<contexts>
<context position="1392" citStr="Liu and Picard (2005)" startWordPosition="201" endWordPosition="204">these dependencies is our first step in developing an adaptive version of our dialogue system. 1 Introduction Detecting and adapting to user affect is being explored by many researchers to improve dialogue system quality. Detection has received much attention (e.g., (Litman and Forbes-Riley, 2004; Lee and Narayanan, 2005)), but less work has been done on adaptation, due to the difficulty of developing responses and applying them at the right time. Most work on adaptation takes a context-independent approach: use the same type of response after all instances of an affective state. For example, Liu and Picard (2005)’s health assessment system responds with empathy to all instances of user stress. Research suggests, however, that it may be more effective to take a context-dependent approach: develop multiple responses for each affective state, whose use depends on the state’s context. E.g., in the tutoring domain, Pon-Barry et al. (2006) show that human tutors use multiple responses to uncertain student answers, depending on the answer’s correctness and prior context. In the information-seeking domain, it is commonly believed that while an apology is a good default response to user frustration (as 41 in (</context>
</contexts>
<marker>Liu, Picard, 2005</marker>
<rawString>K. Liu and R. W. Picard. 2005. Embedded empathy in continuous, interactive health assessment. In CHI Workshop on HCI Challenges in Health Assessment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Pon-Barry</author>
<author>K Schultz</author>
<author>E Bratt</author>
<author>B Clark</author>
<author>S Peters</author>
</authors>
<title>Responding to student uncertainty in spoken tutorial dialogue systems.</title>
<date>2006</date>
<booktitle>International Journal ofArtificial Intelligence in Education,</booktitle>
<pages>16--171</pages>
<contexts>
<context position="1719" citStr="Pon-Barry et al. (2006)" startWordPosition="251" endWordPosition="254"> but less work has been done on adaptation, due to the difficulty of developing responses and applying them at the right time. Most work on adaptation takes a context-independent approach: use the same type of response after all instances of an affective state. For example, Liu and Picard (2005)’s health assessment system responds with empathy to all instances of user stress. Research suggests, however, that it may be more effective to take a context-dependent approach: develop multiple responses for each affective state, whose use depends on the state’s context. E.g., in the tutoring domain, Pon-Barry et al. (2006) show that human tutors use multiple responses to uncertain student answers, depending on the answer’s correctness and prior context. In the information-seeking domain, it is commonly believed that while an apology is a good default response to user frustration (as 41 in (Klein et al., 2002)), one context requires a different response: after several frustrated user turns, the call should be forwarded to a human operator. A context-dependent approach to affect adaptation must address 2 issues: in what contexts to adapt, and what responses to use there. This paper addresses the first issue and t</context>
<context position="5843" citStr="Pon-Barry et al., 2006" startWordPosition="897" endWordPosition="900">ct, then for questions on simple topics, ITSPOKE gives the correct answer and moves on, while for questions on complex topics (ITSPOKE4, Figure 1), ITSPOKE initiates a sub-dialogue with remediation questions (ITSPOKE5 - ITSPOKE6), before moving on. Recent computer tutoring research has shown interest in responding to student affect2 over correctness. Uncertainty is of particular interest: researchers hypothesize that uncertainty and incorrectness each create an opportunity to learn (VanLehn et al., 2003). They cannot be equated, however. First, an uncertain answer may be correct or incorrect (Pon-Barry et al., 2006). Second, uncertainty indicates that the student perceives a possible misconception in their knowledge. Thus, system responses to uncertain answers can address both the correctness and the perceived misconception. In our ITSPOKE corpora, each student answer has been manually annotated as uncertain or nonuncertain3: uncertain is used to label answers expressing uncertainty or confusion about the material; non-uncertain is used to label all other answers. 1We have also manually labeled correctness in our data; agreement between ITSPOKE and human is 0.79 Kappa (90%). 2We use ‘affect’ to cover emo</context>
</contexts>
<marker>Pon-Barry, Schultz, Bratt, Clark, Peters, 2006</marker>
<rawString>H. Pon-Barry, K. Schultz, E. Bratt, B. Clark, and S. Peters. 2006. Responding to student uncertainty in spoken tutorial dialogue systems. International Journal ofArtificial Intelligence in Education, 16:171–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rotaru</author>
<author>D Litman</author>
</authors>
<title>Exploiting discourse structure for spoken dialogue performance analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="7733" citStr="Rotaru and Litman, 2006" startWordPosition="1184" endWordPosition="1187">an and Forbes-Riley, 2006)4: Short (SAQ), Long (LAQ), and Deep Answer Question (DAQ) distinguish the question in terms of content and the type of answer it requires. Repeat (RPT) labels variants of “Can you repeat that?” after rejections. From these annotations we built a hash table associating each ITSPOKE question with a Question Act label; with this table we automatically labeled ITSPOKE questions in our second ITSPOKE corpus. Discourse Structure Depth/Transition: In prior work we showed that the discourse structure Depth and Transition for each ITSPOKE turn can be automatically annotated (Rotaru and Litman, 2006). E.g., as shown in Figure 1, ITSPOKE4,7 have depth 1 and ITSPOKE5,6 have depth 2. We combine levels 3 and above (3+) due to data sparsity. 6 Transition labels represent the turn’s position relative to the prior ITSPOKE turn: NewTopLevel labels the first question after an essay. Advance labels questions at the same depth as the prior question (ITSPOKE4,6). Push labels the first question in a sub-dialogue (after an incorrect answer) (ITSPOKE5). After a sub-dialogue, ITSPOKE asks the original question again, labeled PopUp (ITSPOKE7), or moves on to the next question, labeled PopUpAdv. SameGoal l</context>
</contexts>
<marker>Rotaru, Litman, 2006</marker>
<rawString>M. Rotaru and D. Litman. 2006. Exploiting discourse structure for spoken dialogue performance analysis. In Proceedings of EMNLP, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K VanLehn</author>
<author>P W Jordan</author>
<author>C P Ros´e</author>
</authors>
<title>The architecture of Why2-Atlas: A coach for qualitative physics essay writing.</title>
<date>2002</date>
<booktitle>In Proceedings ofITS.</booktitle>
<marker>VanLehn, Jordan, Ros´e, 2002</marker>
<rawString>K. VanLehn, P. W. Jordan, and C. P. Ros´e et al. 2002. The architecture of Why2-Atlas: A coach for qualitative physics essay writing. In Proceedings ofITS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K VanLehn</author>
<author>S Siler</author>
<author>C Murray</author>
</authors>
<title>Why do only some events cause learning during human tutoring?</title>
<date>2003</date>
<journal>Cognition and Instruction,</journal>
<volume>21</volume>
<issue>3</issue>
<contexts>
<context position="5729" citStr="VanLehn et al., 2003" startWordPosition="878" endWordPosition="881">SPOKE labels each answer as correct or incorrect1. If correct, ITSPOKE moves on to the next question. If incorrect, then for questions on simple topics, ITSPOKE gives the correct answer and moves on, while for questions on complex topics (ITSPOKE4, Figure 1), ITSPOKE initiates a sub-dialogue with remediation questions (ITSPOKE5 - ITSPOKE6), before moving on. Recent computer tutoring research has shown interest in responding to student affect2 over correctness. Uncertainty is of particular interest: researchers hypothesize that uncertainty and incorrectness each create an opportunity to learn (VanLehn et al., 2003). They cannot be equated, however. First, an uncertain answer may be correct or incorrect (Pon-Barry et al., 2006). Second, uncertainty indicates that the student perceives a possible misconception in their knowledge. Thus, system responses to uncertain answers can address both the correctness and the perceived misconception. In our ITSPOKE corpora, each student answer has been manually annotated as uncertain or nonuncertain3: uncertain is used to label answers expressing uncertainty or confusion about the material; non-uncertain is used to label all other answers. 1We have also manually label</context>
</contexts>
<marker>VanLehn, Siler, Murray, 2003</marker>
<rawString>K. VanLehn, S. Siler, and C. Murray. 2003. Why do only some events cause learning during human tutoring? Cognition and Instruction, 21(3):209–249.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>