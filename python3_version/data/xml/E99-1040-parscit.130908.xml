<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026210">
<note confidence="0.687985">
Proceedings of EACL &apos;99
</note>
<title confidence="0.9450765">
Designing spelling correctors for inflected languages using
lexical transducers
</title>
<author confidence="0.927791">
I. Aldezabal, I. Alegria, 0. Ansa, J. M. Arriola and N. Ezeiza
</author>
<affiliation confidence="0.928107">
University of the Basque Country
</affiliation>
<address confidence="0.681927">
649 postakutxa, 20080 Donostia. Basque Country
</address>
<email confidence="0.491659">
i.alegria©si.ehu.es
</email>
<sectionHeader confidence="0.833095666666667" genericHeader="abstract">
I. Aduriz A. Da Costa
UZEI Hizkia
1 Introduction
</sectionHeader>
<bodyText confidence="0.999686555555556">
This paper describes the components used in
the design of the commercial XuxenII spelling
checker/corrector for Basque. It is a new version
of the Xuxen spelling corrector (Aduriz et al., 97)
which uses lexical transducers to improve the pro-
cess. A very important new feature is the use of
user dictionaries whose entries can recognise both
the original and inflected forms. In languages
with a high level of inflection such as Basque
spelling checking cannot be resolved without ad-
equate treatment of words from a morphological
standpoint. In addition to this, the morphologi-
cal treatment has other important features: cov-
erage, reusability of tools, orthogonality and secu-
rity. The tool is based in lexical transducers and
is built using the fst library of Inxighti . A lexi-
cal transducer (Karttunen, 94) is a finite-state au-
tomaton that maps inflected surface forms to lex-
ical forms, and can be seen as an evolution of two-
level morphology (Koskenniemi, 83) where the use
of diacritics and homographs can be avoided and
the intersection and composition of transducers
is possible. In addition, the process is very fast
and the transducer for the whole morphological
description can be compacted in less than 1Mbyte.
The design of the spelling corrector consists of four
main modules:
</bodyText>
<listItem confidence="0.998905">
• the standard checker,
• the recogniser using user-lexicons,
• the corrector of linguistic variants -proposals
for dialectal uses and competence errors-
• the corrector of typographical errors
</listItem>
<bodyText confidence="0.850841">
An important feature is its homogeneity. The
different steps are based on lexical transducers, far
from ad-hoc solutions.
</bodyText>
<footnote confidence="0.8952">
lInxight Software, Inc., a Xerox New Enterprise
Company (www.inxight.com)
</footnote>
<sectionHeader confidence="0.791865" genericHeader="method">
2 The Spelling Checker
</sectionHeader>
<bodyText confidence="0.999940714285714">
The spelling checker accepts as correct any word
which allows a correct standard morphological
breakdown. When a word is not recognised by
the checker, it is assumed to be a misspelling and
a warning is given to the user who has different
options, being one of most interesting including
its lemma in the user-lexicon.
</bodyText>
<subsectionHeader confidence="0.995853">
2.1 The user lexicons
</subsectionHeader>
<bodyText confidence="0.995905833333333">
The user-lexicon is offered in order to increase the
coverage and to manage specific terminology. Our
tool recognises all the possible inflections of a root.
The use of a lexical transducer for this purpose is
difficult because it is necessary to compile the new
entries with the affixes and the rules to update it
but this process is slow. The mechanism we have
implemented has the following two main compo-
nents in order to be able to treatment declensions:
1.. a general transducer which use standard rules
but totally opened lexicon. The result of the
analysis is not only if the word is known or
not, but also all the possible lemmas corre-
sponding to this word-form and the gram-
matical category of each one. The resulting
lexical transducer is very compact and fast.
2. a searcher of these hypothetical lemmas in
the user-lexicons. If one of them is found,
the checker will accept the word, otherwise it
will suppose that it has to be corrected.
For this process the system has an interface to
update the user lexicon because the part of speech
of the lemmas is necessary when they are added
to the user lexicon.
</bodyText>
<sectionHeader confidence="0.988938" genericHeader="method">
3 The Spelling Corrector
</sectionHeader>
<bodyText confidence="0.998361">
Although there is a wide bibliography about the
problem of correction (Kukich, 92), it is significa-
tive that almost all of them do not mention the
</bodyText>
<page confidence="0.990212">
265
</page>
<bodyText confidence="0.949468666666667">
Proceedings of EACL &apos;99
relation with morphology and assume that there
is a whole dictionary of words or that the sys-
tem works without lexical information. Oflazer
and Guzey (1994) face the problem of correcting
words in agglutinative languages.
</bodyText>
<subsectionHeader confidence="0.998431">
3.1 Correcting Competence Errors
</subsectionHeader>
<bodyText confidence="0.999985083333333">
The need of managing competence errors —also
named orthographic errors— has been mentioned
and reasoned by different authors (van Berkel &amp;
de Smedt, 88). When we faced the problem of cor-
recting misspelled words the main problem found
was that because of the recent standardisation and
the widespread dialectal use of Basque, compe-
tence errors or linguistic variants are more likely
and therefore their treatment becomes critical.
When we decided to use lexical transducers for
the treatment of linguistic variants, the following
procedure was applied to build the transducer:
</bodyText>
<listItem confidence="0.9000819">
1. Additional morphemes are linked to the stan-
dard ones using the possibility of expressing
two levels in the lexicon.
2. Definition of additional rules for competence
errors that do not need to be integrated with
the standard ones. It is possible and clearer
to put these rules in other plane near to the
surface and compose them with the standard
rules, because most of the additional rules are
due to phonetic changes.
</listItem>
<bodyText confidence="0.996481333333333">
When a word-form is not accepted the word is
checked against this second transducer. If the in-
correct form is recognised now —i.e. it contains
a competence error— the correct lexical level form
is directly obtained and, as the transducers are
bi-directional, the corrected surface form will be
generated from the lexical form using only stan-
dard transducer.
For example, the word-form beartzetikan, mis-
spelling of behartzetik (from the need) can be cor-
rected although the edit-distance is three. The
process of correction is the following:
</bodyText>
<listItem confidence="0.998462166666667">
• Decomposition into three morphemes: behar
(using a rule to guess the h), tze and tikan.
• tikan is a non-standard use of tik and as they
are linked in the lexicon is chosen.
• The standard generation of behar+tze+tik
obtains the correct word behartzetik.
</listItem>
<subsectionHeader confidence="0.993655">
3.2 Handling Typographical Errors
</subsectionHeader>
<bodyText confidence="0.9977815">
The treatment of typographical errors is quite
conventional and performs the following:
</bodyText>
<listItem confidence="0.977680333333333">
• Generating proposals to typographical errors
using Damerau&apos;s classification (edit distance
of one). These proposals are ranked in order
of trigramic probability.
• Spelling checking of proposals.
3.3 Results
</listItem>
<bodyText confidence="0.9996684">
The results are very good in the case of compe-
tence errors and not so good for typographical er-
rors because in the last case only errors with an
edit-distance of one have been planned. In 89right
proposal is generated and in 71possible to gener-
ate and test all the possible words with an edit-
distance higher, but the number of proposal would
be very high. The corrector has been integrated
in several tools. A demonstration can be seen in
http://ixa.si.ehu.es.
Acknowledgements This work has had partial
support from the Culture Department of the Gov-
ernment of the Basque Country. We would like to
thank to Xerox for letting us using their tools, and
also to Lauri Karttunen for his help.
</bodyText>
<sectionHeader confidence="0.996758" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999378034482759">
Aduriz I., Alegria I., Artola X., Ezeiza N., Sara-
sola K., Urkia M. (1997), A spelling corrector
for Basque based on morphology. Literary &amp;
Linguistic Computing, Vol. 12, No. 1. Oxford
University Press. Oxford.
Alegria I., Artola X., Sarasola K (1997). Improv-
ing a Robust Morphological Analyser using Lex-
ical Transducers. Recent Advances in Natural
Language Processing. Current Issues in Linguis-
tic Theory (CILT) series. John Benjamins pub-
lisher company. Vol. 136. pp 97-110.
Karttunen L. (1994). Constructing Lexical Trans-
ducers, Proc. of COLING&apos;94, 406-411.
Koskenniemi, K. (1983). Two-level Morphology:
A general Computational Model for Word-
Form Recognition and Production, University
of Helsinki, Department of General Linguistics.
Publications No. 11.
Kukich K. (1992). Techniques for automatically
correcting word in text. ACM Computing Sur-
veys, vol. 24, No. 4, 377-439.
Ofiazer K, Guzey C. (1994). Spelling Correction
in Aglutinative Languages, Proc. of ANLP-94,
Sttutgart.
Van Barkel B, De Smedt K. (1988). Triphone anal-
ysis: a combined method for the correction of
orthographic and typographical errors. Proced-
ings of the Second Conference ANLP (ACL),
pp.77-83.
</reference>
<page confidence="0.998474">
266
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.299371">
<note confidence="0.851765">Proceedings of EACL &apos;99</note>
<title confidence="0.9841925">Designing spelling correctors for inflected languages using lexical transducers</title>
<author confidence="0.997017">J M Arriola Ansa</author>
<author confidence="0.997017">N Ezeiza</author>
<affiliation confidence="0.997231">University of the Basque Country</affiliation>
<address confidence="0.961995">649 postakutxa, 20080 Donostia. Basque Country</address>
<email confidence="0.756484">i.alegria©si.ehu.es</email>
<author confidence="0.935428">I Aduriz A Da Costa</author>
<intro confidence="0.517593">UZEI Hizkia</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Aduriz</author>
<author>I Alegria</author>
<author>X Artola</author>
<author>N Ezeiza</author>
<author>K Sarasola</author>
<author>M Urkia</author>
</authors>
<title>A spelling corrector for Basque based on morphology.</title>
<date>1997</date>
<journal>Literary &amp; Linguistic Computing,</journal>
<volume>12</volume>
<publisher>Oxford University Press.</publisher>
<location>Oxford.</location>
<marker>Aduriz, Alegria, Artola, Ezeiza, Sarasola, Urkia, 1997</marker>
<rawString>Aduriz I., Alegria I., Artola X., Ezeiza N., Sarasola K., Urkia M. (1997), A spelling corrector for Basque based on morphology. Literary &amp; Linguistic Computing, Vol. 12, No. 1. Oxford University Press. Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Alegria</author>
<author>X Artola</author>
<author>K Sarasola</author>
</authors>
<title>Improving a Robust Morphological Analyser using Lexical Transducers. Recent Advances</title>
<date>1997</date>
<booktitle>in Natural Language Processing. Current Issues in Linguistic Theory (CILT) series. John Benjamins publisher company.</booktitle>
<volume>136</volume>
<pages>97--110</pages>
<marker>Alegria, Artola, Sarasola, 1997</marker>
<rawString>Alegria I., Artola X., Sarasola K (1997). Improving a Robust Morphological Analyser using Lexical Transducers. Recent Advances in Natural Language Processing. Current Issues in Linguistic Theory (CILT) series. John Benjamins publisher company. Vol. 136. pp 97-110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Karttunen</author>
</authors>
<title>Constructing Lexical Transducers,</title>
<date>1994</date>
<booktitle>Proc. of COLING&apos;94,</booktitle>
<pages>406--411</pages>
<marker>Karttunen, 1994</marker>
<rawString>Karttunen L. (1994). Constructing Lexical Transducers, Proc. of COLING&apos;94, 406-411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>Two-level Morphology: A general Computational Model for WordForm Recognition and Production,</title>
<date>1983</date>
<volume>11</volume>
<publisher>Publications</publisher>
<institution>University of Helsinki, Department of General Linguistics.</institution>
<marker>Koskenniemi, 1983</marker>
<rawString>Koskenniemi, K. (1983). Two-level Morphology: A general Computational Model for WordForm Recognition and Production, University of Helsinki, Department of General Linguistics. Publications No. 11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kukich</author>
</authors>
<title>Techniques for automatically correcting word in text.</title>
<date>1992</date>
<journal>ACM Computing Surveys,</journal>
<volume>24</volume>
<pages>377--439</pages>
<marker>Kukich, 1992</marker>
<rawString>Kukich K. (1992). Techniques for automatically correcting word in text. ACM Computing Surveys, vol. 24, No. 4, 377-439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ofiazer</author>
<author>C Guzey</author>
</authors>
<title>Spelling Correction in Aglutinative Languages,</title>
<date>1994</date>
<booktitle>Proc. of ANLP-94,</booktitle>
<location>Sttutgart.</location>
<marker>Ofiazer, Guzey, 1994</marker>
<rawString>Ofiazer K, Guzey C. (1994). Spelling Correction in Aglutinative Languages, Proc. of ANLP-94, Sttutgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Van Barkel</author>
<author>K De Smedt</author>
</authors>
<title>Triphone analysis: a combined method for the correction of orthographic and typographical errors.</title>
<date>1988</date>
<booktitle>Procedings of the Second Conference ANLP (ACL),</booktitle>
<pages>77--83</pages>
<marker>Van Barkel, De Smedt, 1988</marker>
<rawString>Van Barkel B, De Smedt K. (1988). Triphone analysis: a combined method for the correction of orthographic and typographical errors. Procedings of the Second Conference ANLP (ACL), pp.77-83.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>