<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9982795">
Experiments on the Automatic Induction of
German Semantic Verb Classes
</title>
<author confidence="0.987409">
Sabine Schulte im Walde*
</author>
<affiliation confidence="0.375977">
Universit¨at des Saarlandes
</affiliation>
<bodyText confidence="0.9997454">
This article presents clustering experiments on German verbs: A statistical grammar model for
German serves as the source for a distributional verb description at the lexical syntax–semantics
interface, and the unsupervised clustering algorithm k-means uses the empirical verb properties
to perform an automatic induction of verb classes. Various evaluation measures are applied to
compare the clustering results to gold standard German semantic verb classes under different
criteria. The primary goals of the experiments are (1) to empirically utilize and investigate the
well-established relationship between verb meaning and verb behavior within a cluster analysis
and (2) to investigate the required technical parameters of a cluster analysis with respect to this
specific linguistic task. The clustering methodology is developed on a small-scale verb set and
then applied to a larger-scale verb set including 883 German verbs.
</bodyText>
<sectionHeader confidence="0.96117" genericHeader="abstract">
1. Motivation
</sectionHeader>
<bodyText confidence="0.9996592">
Semantic verb classes generalize over verbs according to their semantic properties,
that is, they capture large amounts of verb meaning without defining the idiosyncratic
details for each verb. The classes refer to a general semantic level, and idiosyncratic
lexical semantic properties of the verbs are either added to the class description or
left underspecified. Examples for semantic verb classes are Position verbs such as liegen
‘lie’, sitzen ‘sit’, stehen ‘stand’, and Manner of Motion with a Vehicle verbs such as fahren
‘drive’, fliegen ‘fly’, rudern ‘row’. Manual definitions of semantic verb classes exist
for several languages, the most dominant examples concerning English (Levin 1993;
Baker, Fillmore, and Lowe 1998) and Spanish (V´azquez et al. 2000). On the one hand,
verb classes reduce redundancy in verb descriptions since they encode the common
properties of verbs. On the other hand, verb classes can predict and refine properties of
a verb that received insufficient empirical evidence, with reference to verbs in the same
class: Under this criterion, a verb classification is especially useful for the pervasive
problem of data sparseness in NLP, where little or no knowledge is provided for rare
events. For example, the English verb classification by Levin (1993) has been used in
NLP applications such as word sense disambiguation (Dorr and Jones 1996), machine
translation (Dorr 1997), document classification (Klavans and Kan 1998), and subcat-
egorization acquisition (Korhonen 2002). To my knowledge, no comparable German
verb classification is available so far; therefore, such a classification would provide a
principled basis for filling a gap in available lexical knowledge.
</bodyText>
<note confidence="0.7877802">
* Department of Computational Linguistics, Saarbr¨ucken, Germany. E-mail: schulte@coli.uni-sb.de.
Submission received:1 September 2003; revised submission received: 5 September 2005; accepted for
publication: 10 November 2005.
© 2006 Association for Computational Linguistics
Computational Linguistics Volume 32, Number 2
</note>
<bodyText confidence="0.99974380952381">
How can we obtain a semantic classification of verbs while avoiding tedious manual
definitions of the verbs and the classes? Few resources are semantically annotated
and provide semantic information off-the-shelf such as FrameNet (Baker, Fillmore,
and Lowe 1998; Fontenelle 2003) and PropBank (Palmer, Gildea, and Kingsbury 2005).
Instead, the automatic construction of semantic classes typically benefits from a long-
standing linguistic hypothesis that asserts a tight connection between the lexical
meaning of a verb and its behavior: To a certain extent, the lexical meaning of a verb
determines its behavior, particularly with respect to the choice of its arguments
(Pinker 1989; Levin 1993; Dorr and Jones 1996; Siegel and McKeown 2000; Merlo and
Stevenson 2001; Schulte im Walde and Brew 2002; Lapata and Brew 2004). Even though
the meaning–behavior relationship is not perfect, we can make this prediction: If we
induce a verb classification on the basis of verb features describing verb behavior, then
the resulting behavior classification should agree with a semantic classification to a
certain extent (yet to be determined). The aim of this work is to utilize this prediction
for the automatic acquisition of German semantic verb classes.
The verb behavior itself is commonly captured by the diathesis alternation of verbs:
alternative constructions at the syntax–semantics interface that express the same or a
similar conceptual idea of a verb (Lapata 1999; Schulte im Walde 2000; McCarthy 2001;
Merlo and Stevenson 2001; Joanis 2002). Consider example (1), where the most common
alternations of the Manner of Motion with a Vehicle verb fahren ‘drive’ are illustrated. The
conceptual participants are a vehicle, a driver, a passenger, and a direction. In (a), the
vehicle is expressed as the subject in a transitive verb construction, with a prepositional
phrase indicating the direction. In (b), the driver is expressed as the subject in a tran-
sitive verb construction, with a prepositional phrase indicating the direction. In (c), the
driver is expressed as the subject in a transitive verb construction, with an accusative
noun phrase indicating the vehicle. In (d), the driver is expressed as the subject in a
ditransitive verb construction, with an accusative noun phrase indicating the passenger,
and a prepositional phrase indicating the direction. Even if a certain participant is not
realized within an alternation, its contribution might be implicitly defined by the verb.
For example, in the German sentence in (a) the driver is not expressed overtly, but we
know that there is a driver, and in (b) and (d) the vehicle is not expressed overtly, but
we know that there is a vehicle. Verbs in the same semantic class are expected to overlap
in their alternation behavior to a certain extent. For example, the Manner of Motion with
a Vehicle verb fliegen ‘fly’ alternates between (a) such as in Der Airbus A380 fliegt nach
New York ‘The Airbus A380 flies to New York’, (b) in marked cases as in Der ¨altere
Pilot fliegt nach London ‘The older pilot flies to London’, (c) as in Pilot Schulze fliegt eine
Boing 747 ‘Pilot Schulze flies a Boing 747’, and (d) as in Der Pilot fliegt seine Passagiere nach
Thailand ‘The pilot flies his passengers to Thailand’; the Manner of Motion with a Vehicle
verb rudern ‘row’ alternates between (b) such as in Anna rudert ¨uber den See ‘Anna rows
over the lake’, (c) such as in Anna rudert das blaue Boot ‘Anna rows the blue boat’, and (d)
such as in Anna rudert ihren kleinen Bruder ¨uber den See ‘Anna rows her little brother over
the lake’.
</bodyText>
<figure confidence="0.921393090909091">
Example 1
(a) Der Wagen f¨ahrt in die Innenstadt.
‘The car drives to the city centre.’
(b) Die Frau f¨ahrt nach Hause.
‘The woman drives home.’
160
Schulte im Walde Induction of German Semantic Verb Classes
(c) Der Filius f¨ahrt einen blauen Ferrari.
‘The son drives a blue Ferrari.’
(d) Der Junge f¨ahrt seinen Vater zum Zug.
‘The boy drives his father to the train.’
</figure>
<bodyText confidence="0.999969259259259">
We decided to use diathesis alternations as an approach to characterizing verb behavior,
and to use the following verb features to stepwise describe diathesis alternations: (1)
syntactic structures, which are relevant for capturing argument functions; (2) preposi-
tions, which are relevant to distinguish, for example, directions from locations; and (3)
selectional preferences, which concern participant roles. A statistical grammar model
serves as the source for an empirical verb description for the three levels at the syntax–
semantics interface. Based on the empirical feature description, we then perform a
cluster analysis of the German verbs using k-means, a standard unsupervised hard
clustering technique as proposed by Forgy (1965). The clustering outcome cannot be a
perfect semantic verb classification, since the meaning–behavior relationship on which
the clustering relies is not perfect, and the clustering method is not perfect for the am-
biguous verb data. However, our primary goal is not necessarily to obtain the optimal
clustering result, but rather to assess the linguistic and technical conditions that are
crucial for a semantic cluster analysis. More specifically, (1) we perform an empirical
investigation of the relationship between verb meaning and verb behavior (that is, Can
we use the meaning–behavior relationship of verbs to induce verb classes, and to what
extent does the meaning–behavior relationship hold in the experiments?), and (2) we
investigate which technical parameters are suitable for the natural language task. The
resulting clustering methodology can then be applied to a larger-scale verb set.
The plan of the article is as follows. Section 2 describes the experimental setup
with respect to (1) gold standard verb classes for 168 German verbs, (2) the statistical
grammar model that provides empirical lexical information for German verbs at the
syntax–semantics interface, and (3) the clustering algorithm and evaluation methods.
Section 3 performs preliminary clustering experiments on the German gold standard
verbs, and Section 4 presents an application of the clustering technique in a large-scale
experiment. Section 5 discusses related work, and Section 6 presents the conclusions
and outlook for further work.
</bodyText>
<sectionHeader confidence="0.999454" genericHeader="keywords">
2. Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.944851">
2.1 German Semantic Verb Classes
</subsectionHeader>
<bodyText confidence="0.999919727272727">
A set of 168 German verbs was manually classified into 43 concise semantic verb classes.
The verb class labels refer to the common semantic properties of the verbs in a class
at a general conceptual level, and the idiosyncratic lexical semantic properties of the
verbs are left underspecified. The German verbs are provided with a coarse translation
into English, given here in brackets; we do not attempt to define subtle differences
in meaning or usage. The translated verb senses only refer to the respective semantic
class; if the verb translations in one class are too similar to distinguish among them,
a common translation is given. Even though the classification is primarily based on
semantic intuition and not on facts about syntactic behavior, the verbs grouped in
one class share certain aspects of their behavior. (Please note that this overlap does
not necessarily transfer to the English translations.) This agreement corresponds to the
</bodyText>
<page confidence="0.994439">
161
</page>
<note confidence="0.804308">
Computational Linguistics Volume 32, Number 2
</note>
<bodyText confidence="0.99991935483871">
long-standing linguistic hypothesis that asserts a tight connection between the meaning
components of a verb and its behavior (Pinker 1989; Levin 1993).
The purpose of the manual classification is to evaluate the reliability and perfor-
mance of the clustering experiments. The following facts refer to empirically relevant
properties of the classification: The class size is between 2 and 7, with an average of
3.9 verbs per class. Eight verbs are ambiguous with respect to class membership and
marked by subscripts. The classes include both high- and low-frequency verbs in order
to exercise the clustering technology in both data-rich and data-poor situations: The
corpus frequencies of the verbs range from 8 to 71,604 (within 35 million words of a
German newspaper corpus, cf. Section 2.2). The class labels are given on two semantic
levels: coarse labels such as Manner of Motion are subdivided into finer labels, such as
Locomotion, Rotation, Rush, Vehicle, Flotation. The fine-grained labels are relevant for the
clustering experiments, as the numbering indicates. As mentioned before, the classifi-
cation is primarily based on semantic intuition, not on facts about syntactic behavior.
As an extreme example, the Support class (23) contains the verb unterst¨utzen, which
syntactically requires a direct object, together with the verbs dienen, folgen, and helfen,
which dominantly subcategorize for an indirect object. The classification was checked
to ensure lack of bias, so class membership is not disproportionately made up of high-
frequency verbs, low-frequency verbs, strongly ambiguous verbs, verbs from specific
semantic areas, and so forth.
The classification deliberately sets high standards for the automatic induction
process: It would be easier (1) to define the verb classes on a purely syntactic basis,
since syntactic properties are easier to obtain automatically than semantic features,
or (2) to define larger classes of verbs, so that the distinction between the classes is
not based on fine-grained verb properties, or (3) to disregard clustering complications
such as verb ambiguity and low-frequency verbs. But the overall goal is not to achieve
a perfect clustering on the given 168 verbs but to investigate both the potential and
the limits of our clustering methodology that combines easily available data with a
simple algorithm. The task cannot be solved completely, but we can investigate the
bounds.
The classification is defined as follows:
</bodyText>
<listItem confidence="0.9797734">
1. Aspect: anfangen, aufh¨oren, beenden, beginnen, enden (start, stop,
finish, begin, end)
2. Propositional Attitude: ahnen, denken, glauben, vermuten, wissen
(guess, think, believe, assume, know)
• Desire
3. Wish: erhoffen, wollen, w¨unschen (hope, want, wish)
4. Need: bed¨urfen, ben¨otigen, brauchen (all: need/require)
5. Transfer of Possession (Obtaining): bekommen, erhalten, erlangen,
kriegen (all: receive/obtain)
• Transfer of Possession (Giving)
6. Gift: geben, leihen, schenken, spenden, stiften, vermachen,
¨uberschreiben (give, borrow, present, donate, donate,
bequeath, sign over)
7. Supply: bringen, liefern, schicken, vermitteln1, zustellen
(bring, deliver, send, convey, deliver)
</listItem>
<page confidence="0.989483">
162
</page>
<note confidence="0.826348">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<listItem confidence="0.979324547619047">
• Manner of Motion
8. Locomotion: gehen, klettern, kriechen, laufen, rennen,
schleichen, wandern (go, climb, creep, walk, run, sneak,
wander)
9. Rotation: drehen, rotieren (turn around, rotate)
10. Rush: eilen, hasten (both: hurry)
11. Vehicle: fahren, fliegen, rudern, segeln (drive, fly, row, sail)
12. Flotation: fließen, gleiten, treiben (float, glide, float)
• Emotion
13. Origin: ¨argern, freuen (be annoyed, be happy)
14. Expression: heulen1, lachen1, weinen (cry, laugh, cry)
15. Objection: ¨angstigen, ekeln, f¨urchten, scheuen (frighten,
disgust, fear, be afraid)
16. Facial Expression: g¨ahnen, grinsen, lachen2, l¨acheln, starren
(yawn, grin, laugh, smile, stare)
17. Perception: empfinden, erfahren1, f¨uhlen, h¨oren, riechen, sehen,
wahrnehmen (feel, experience, feel, hear, smell, see, perceive)
18. Manner of Articulation: fl¨ustern, rufen, schreien (whisper, shout, scream)
19. Moaning: heulen2, jammern, klagen, lamentieren (all: wail/moan/
complain)
20. Communication: kommunizieren, korrespondieren, reden, sprechen,
verhandeln (communicate, correspond, talk, talk, negotiate)
• Statement
21. Announcement: ank¨undigen, bekanntgeben, er¨offnen,
verk¨unden (all: announce)
22. Constitution: anordnen, bestimmen, festlegen (arrange,
determine, constitute)
23. Promise: versichern, versprechen, zusagen (ensure,
promise, promise)
24. Observation: bemerken, erkennen, erfahren2, feststellen, realisieren,
registrieren (notice, realize, get to know, observe, realize, realize)
25. Description: beschreiben, charakterisieren, darstellen1, interpretieren
(describe, characterize, describe, interpret)
26. Presentation: darstellen2, demonstrieren, pr¨asentieren, veranschaulichen,
vorf¨uhren (present, demonstrate, present, illustrate, demonstrate)
27. Speculation: gr¨ubeln, nachdenken, phantasieren, spekulieren (muse,
think about, fantasize, speculate)
28. Insistence: beharren, bestehen1, insistieren, pochen (all: insist)
29. Teaching: beibringen, lehren, unterrichten, vermitteln2 (all: teach)
• Position
30. Bring into Position: legen, setzen, stellen (lay, set, put upright)
31. Be in Position: liegen, sitzen, stehen (lie, sit, stand)
</listItem>
<page confidence="0.997252">
163
</page>
<note confidence="0.259727">
Computational Linguistics Volume 32, Number 2
</note>
<listItem confidence="0.98951695">
32. Production: bilden, erzeugen, herstellen, hervorbringen, produzieren
(all: generate/produce)
33. Renovation: dekorieren, erneuern, renovieren, reparieren (decorate,
renew, renovate, repair)
34. Support: dienen, folgen1, helfen, unterst¨utzen (serve, follow, help,
support)
35. Quantum Change: erh¨ohen, erniedrigen, senken, steigern, vergr¨oßern,
verklenern (increase, decrease, decrease, increase, enlarge,
diminish)
36. Opening: ¨offnen, schließen1 (open, close)
37. Existence: bestehen2, existieren, leben (exist, exist, live)
38. Consumption: essen, konsumieren, lesen, saufen, trinken (eat, consume,
read, booze, drink)
39. Elimination: eliminieren, entfernen, exekutieren, t¨oten, vernichten
(eliminate, delete, execute, kill, destroy)
40. Basis: basieren, beruhen, gr¨unden, st¨utzen (all: be based on)
41. Inference: folgern, schließen2 (conclude, infer)
42. Result: ergeben, erwachsen, folgen2, resultieren (all: follow/result)
43. Weather: blitzen, donnern, d¨ammern, nieseln, regnen, schneien
(lightning, thunder, dawn, drizzle, rain, snow)
</listItem>
<bodyText confidence="0.999947695652174">
The evidence used in the class creation process—including the choice of the
verbs—was provided by subjective conceptual knowledge, monolingual and bilingual
dictionary entries and corpus searches. Interannotator agreement has therefore not been
addressed, but the classes were created in close relation to the English classification
by Levin (1993) (as far as the English classes have German counterparts) and agree
with the German verb classification by Schumacher (1986), as far as the relevant verbs
are covered by his semantic ‘fields’. To overcome the drawback of a subjective class
definition, the classification was accompanied by a detailed class description. This
characterization is closely related to Fillmore’s scenes-and-frames semantics (Fillmore
1977, 1982), as computationally utilized in FrameNet (Baker, Fillmore, and Lowe 1998;
Fontenelle 2003); there is no reference to the German FrameNet version (Erk, Kowalski,
and Pinkal 2003)—as one might expect—just because the German version itself had
just started to be developed. The frame-semantic class definition contains a prose scene
description, predominant frame participant and modification roles, and frame variants
describing the scene. The frame roles have been developed on the basis of a large
German newspaper corpus from the 1990s (cf. Section 2.2). They capture the scene
description with idiosyncratic participant names and demarcate major and minor roles.
Since a scene might be activated by a number of frame embeddings, the predominant
frame variants from the corpus are listed, marked with participating roles, and at least
one example sentence for each verb utilizing the respective frame is given. The corpus
examples are annotated and illustrate the idiosyncratic combinations of lexical verb
meaning and conceptual constructions to capture variations in verb sense. Example 2
presents a verb class description for the class of Aspect verbs. For further class descrip-
</bodyText>
<page confidence="0.995117">
164
</page>
<note confidence="0.576554">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<bodyText confidence="0.998648681818182">
tions, the reader is referred to Schulte im Walde (2003a, pages 27–103). Verbs allowing a
frame variant are marked by “+,” verbs allowing the frame variant only in company of
an additional adverbial modifier are marked by “+adv,” and verbs not allowing a frame
variant are marked by “¬.” In the case of ambiguity, frame variants are only given for
the senses of the verbs with respect to the class label. The frame variants with their roles
marked represent the alternation potential of the verbs. For example, the causative–
inchoative alternation assumes the syntactic embeddings nXaY and nY, indicating that
the alternating verbs are realized by a transitive frame type (containing a nominative
NP ‘n’ with role X and an accusative NP ‘a’ with role Y) and the corresponding
intransitive frame type (with a nominative NP ‘n’ only, indicating the same role Y as for
the transitive accusative). Passivization of a verb–frame combination is indicated by [P].
Appendix 6 lists all possible frame variants with illustrative examples. Note that the cor-
pus examples are given in the old German spelling version, before the spelling reform
in 1998.
Semantic verb classes have been defined for several languages, for example, as the
earlier mentioned lexicographic resource FrameNet for English (Baker, Fillmore, and
Lowe 1998; Fontenelle 2003) and German (Erk, Kowalski, and Pinkal 2003); the lexical
semantic ontology WordNet for English (Miller et al. 1990; Fellbaum 1998); EuroWordNet
(Vossen 2004) for Dutch, Italian, Spanish, French, German, Czech, and Estonian, and
further languages as listed in WordNets in the World (Global WordNet Association,
www.globalwordnet.org); syntax–semantics based verb classes for English (Levin 1993),
Spanish (V´azquez et al. 2000), and French (Saint-Dizier 1998).
</bodyText>
<table confidence="0.660667">
Example 2
Aspect Verbs: anfangen, aufh¨oren, beenden, beginnen, enden
Scene: [E An event] begins or ends, either internally caused or externally caused by
[I an initiator]. The event may be specified with respect to [T tense], [L location],
[X an experiencer], or [R a result].
Frame Roles: I(nitiator), E(vent)
Modification Roles: T(emporal), L(ocal), (e)X(periencer), R(esult)
</table>
<subsectionHeader confidence="0.906598">
Frame Participating Verbs and Corpus Examples
</subsectionHeader>
<bodyText confidence="0.649808">
+ anfangen, aufh¨oren, beginnen / +adv enden / ¬ beenden
</bodyText>
<figure confidence="0.858600225806452">
nE
muß
must
Nun
Now
aber
though
anfangen.
begin
[E der Dialog]
the dialog
[E das Morden]
the killing
aufh¨oren.
stop
Erst
First
muß
must
[E Der Gottesdienst] beginnt.
The service begins
[E Das Schuljahr] beginnt [T im Februar].
The school year begins in February
[X F¨ur die Fl¨uchtlinge] beginnt nun [E ein Wettlauf gegen die Zeit].
For the fugitives begins now a race against time
[E Die Ferien] enden [R mit einem großen Fest].
The vacations end with a big party
[E Druckkunst] ... endet [R beim guten Buch].
The art of typesetting ... ends with a good book
[E Der Informationstag] ... endet [T um 14 Uhr].
The information day ... finishes at 2pm
</figure>
<page confidence="0.980952">
165
</page>
<bodyText confidence="0.7939175">
[P] [E Mit diesem ungerechten Krieg] muß sofort aufgeh¨ort werden.
With this unjust war must immediately be stopped
[T Vorher] d¨urfe [E mit der Aufl¨osung] nicht begonnen werden.
Before must with the closing not be started
</bodyText>
<subsectionHeader confidence="0.998159">
2.2 Empirical Distributions for German Verbs
</subsectionHeader>
<bodyText confidence="0.999958625">
We developed, implemented, and trained a statistical grammar model for German that
is based on the framework of head-lexicalized, probabilistic, context-free grammars.
The idea originates from Charniak (1997), with this work using an implementation
by Schmid (2000) for a training corpus of 35 million words from a collection of large
German newspaper corpora from the 1990s, including Frankfurter Rundschau, Stuttgarter
Zeitung, VDI-Nachrichten, die tageszeitung, German Law Corpus, Donaukurier, and Com-
puterzeitung. The statistical grammar model provides empirical lexical information,
specializing in but not restricted to the subcategorization behavior of verbs. Details of
</bodyText>
<page confidence="0.985116">
166
</page>
<figure confidence="0.99794282">
[E mit den Umbauarbeiten] k¨onnte
with the reconstruction work could
pE : mit Und
And
angefangen werden.
be begun
Computational Linguistics Volume 32, Number 2
...
[I er]
he
daß
that
...
sollte
should
[I ich]
I
und
and
noch
yet
aufh¨oren
stop
Vielleicht
Maybe
studieren.
study
[I wir]
we
[E die Sache]
the thing
angefangen haben,
have started
aE Nachdem
After
[I Die Polizei]
The police
[E die Gewaltt¨atigkeiten].
the violence
beendete
stopped
+ anfangen, aufh¨oren / ¬ beenden, beginnen, enden
nI
[T p¨unktlich]
in time
[I wir]
we
anfing.
begins
einfach
just
aufh¨oren.
stop
nicht
not
+ anfangen, beenden, beginnen / ¬ aufh¨oren, enden
nI
[T Nach dem Abi]
After the Abitur
beginnt
begins
[I Jens]
Jens
[L in Frankfurt]
in Frankfurt
[E seine Lehre] ...
his apprenticeship ...
Jetzt
Now
k¨onnen
can
[T vor dem Bescheid]
before the notification
angefangen werden
is started
...
...
aE Wenn
If
[E die Arbeiten]
the work
[P] W¨ahrend
[X f¨ur Senna]
While for Senna
...
...
...
ehe
before
begonnen wird
is begun
[E eine milit¨arische Aktion]
a military action
iE [I Ich]
habe
I have
daß
that
...
...
[E zu trinken].
to drink
[I der Alkoholiker] aufh¨ort
the alcoholic stops
+ anfangen, aufh¨oren, beginnen / ¬ beenden, enden
nI
[E das Rennen]
the race
beendet war ...
was finished ...
angefangen,
started
[E Hemden zu schneidern].
shirts to make
+ anfangen, beenden, beginnen / ¬ aufh¨oren, enden
nI
[I M¨anner]
men
[E Tango zu tanzen]
tango to dance
In dieser Stimmung begannen
In this mood began
...
[I der versammelte Hofstaat]
the gathered royal household
pE : mit Erst als
Only when
[E mit Klatschen] anfing,
with applause began
kann
can
...
...
...
...
[I Der Athlet]
The athlete
[E mit seinem Sport] aufh¨oren.
with his sports stop
[E mit eher katharsischen Werken].
with rather catharsic works
[I Man]
One
beginne
starts
+ anfangen, aufh¨oren, beginnen / ¬ beenden, enden
nI
+anfangen, aufh¨oren, beginnen / ¬ beenden, enden
nI
Schulte im Walde Induction of German Semantic Verb Classes
</figure>
<bodyText confidence="0.99630258">
the implementation, training, and exploitation of the grammar model can be found in
Schulte im Walde (2003a, chapter 3).
The German verbs are represented by distributional vectors, with features and
feature values in the distribution being acquired from the statistical grammar. The dis-
tributional description is based on the hypothesis that “each language can be described
in terms of a distributional structure, that is, in terms of the occurrence of parts relative
to other parts” (cf. Harris 1968). The verbs are described distributionally on three levels
at the syntax–semantics interface, each level refining the previous level. The first level
D1 encodes a purely syntactic definition of verb subcategorization, the second level
D2 encodes a syntactico-semantic definition of subcategorization with prepositional
preferences, and the third level D3 encodes a syntactico-semantic definition of sub-
categorization with prepositional and selectional preferences. Thus, the refinement of
verb features starts with a purely syntactic definition and incrementally adds semantic
information. The most elaborated description comes close to a definition of verb alterna-
tion behavior. We decided on this three-step procedure of verb descriptions because the
resulting clusters and particularly the changes in clusters that result from a change of
features should provide insight into the meaning–behavior relationship at the syntax–
semantics interface.
For D1, the statistical grammar model provides frequency distributions for Ger-
man verbs over 38 purely syntactic subcategorization frames (cf. Appendix 6). Based
on these frequencies, we can also calculate the probabilities. For D2, the grammar
provides frequencies for the different kinds of prepositional phrases within a frame
type; probabilities are computed by distributing the joint probability of a verb and a
PP frame over the prepositional phrases according to their frequencies in the corpus.
Prepositional phrases are referred to by case and preposition, such as mitDat, f¨urA,,. The
statistical grammar model does not learn the distinction between PP arguments and PP
adjuncts perfectly. Therefore, we did not restrict the PP features to PP arguments, but
to 30 PPs according to ‘reasonable’ appearance in the corpus, as defined by the 30 most
frequent PPs that appear with at least 10 different verbs. The subcategorization frame
information for D1 and D2 has been evaluated: Schulte im Walde (2002b) describes the
induction of a subcategorization lexicon from the grammar model for a total of 14,229
verbs with a frequency between 1 and 255,676 in the training corpus, and Schulte im
Walde (2002a) performs an evaluation of the subcategorization data against manually
created dictionary entries and shows that the lexical entries have potential for adding
to and improving manual verb definitions.
For the refinement of D3, the grammar provides selectional preference information
at a fine-grained level: It specifies the possible argument realizations in the form of
lexical heads, with reference to a specific verb–frame–slot combination. Obviously, we
would run into a sparse data problem if we tried to incorporate selectional preferences
into the verb descriptions at such a specific level. We are provided with detailed infor-
mation at the nominal level, but we need a generalization of the selectional preference
definition. A widely used resource for selectional preference information is the semantic
ontology WordNet (Miller et al. 1990; Fellbaum 1998); the University of T¨ubingen has
developed the German version of WordNet, GermaNet (Hamp and Feldweg 1997; Kunze
2000). The hierarchy is realized by means of synsets, sets of synonymous nouns, which
are organized by multiple inheritance hyponym/hypernym relationships. A noun can
appear in several synsets, according to its number of senses. The German noun hierar-
chy in GermaNet is utilized for the generalization of selectional preferences: For each
noun in a verb–frame–slot combination, the joint frequency is divided over the different
senses of the noun and propagated up the hierarchy. In case of multiple hypernym
</bodyText>
<page confidence="0.960665">
167
</page>
<note confidence="0.282645">
Computational Linguistics Volume 32, Number 2
</note>
<bodyText confidence="0.999977">
synsets, the frequency is divided again. The sum of frequencies over all top synsets
equals the total joint frequency. Repeating the frequency assignment and propagation
for all nouns appearing in a verb–frame–slot combination, the result defines a frequency
distribution of the verb–frame–slot combination over all GermaNet synsets. To restrict
the variety of noun concepts to a general level, only the frequency distributions over the
top GermaNet nodes1 are considered: Lebewesen ‘creature’, Sache ‘thing’, Besitz ‘prop-
erty’, Substanz ‘substance’, Nahrung ‘food’, Mittel ‘means’, Situation ‘situation’, Zustand
‘state’, Struktur ‘structure’, Physis ‘body’, Zeit ‘time’, Ort ‘space’, Attribut ‘attribute’,
Kognitives Objekt ‘cognitive object’, Kognitiver Prozess ‘cognitive process’. Since the 15
nodes are mutually exclusive and the node frequencies sum to the total joint verb-frame
frequency, we can use their frequencies to define a probability distribution.
Are selectional preferences equally necessary and informative for all frame types?
For example, selectional preferences for the direct object are expected to vary strongly
with respect to the subcategorizing verb (because the direct object is a highly frequent
argument type across all verbs and verb classes), but selectional preferences for a
subject in a transitive construction with a nonfinite clause are certainly less interesting
for refinement (because this frame type is more restricted with respect to the verbs it
is subcategorized for). We empirically investigated which of the overall frame roles
may be realized by different selectional preferences and are therefore relevant and
informative for a selectional preference distinction. As a result, in parts of the clustering
experiments we will concentrate on a specific choice of frame-slot combinations to be
refined by selectional preferences (with the relevant slots underlined): ‘n’, ‘na’, ‘nd’,
‘nad’, ‘ns-dass.’
Table 1 presents three verbs from different classes and their 10 most frequent frame
types at the three levels of verb definition and their probabilities. D1 for beginnen ‘begin’
defines ‘np’ and ‘n’ as the most probable frame types. After splitting the ‘np’ probability
over the different PP types in D2, a number of prominent PPs are left, the time indicat-
ing umAcc and nachDat, mitDat referring to the begun event, anDat as date, and inDat as
place indicator. It is obvious that not all PPs are argument PPs, but adjunct PPs also
represent a part of the verb behavior. D3 illustrates that typical selectional preferences
for beginner roles are Situation ‘situation’, Zustand ‘state’, Zeit ‘time’, Sache ‘thing’.
D3 has the potential to indicate verb alternation behavior, for example, ‘na(Situation)’
refers to the same role for the direct object in a transitive frame as “n(Situation)” in
an intransitive frame. essen ‘eat’ as an object-drop verb shows strong preferences for
both intransitive and transitive usage. As desired, the argument roles are dominated
by Lebewesen ‘creature’ for ‘n’ and ‘na’ and Nahrung ‘food’ for ‘na’. fahren ‘drive’
chooses typical manner of motion frames (‘n,’ ‘np,’ ‘na’) with the refining PPs being
directional (inAcc, zuDat, nachDat) or referring to a means of motion (mitDat, inDat, aufDat).
The selectional preferences show correct alternation behavior: Lebewesen ‘creature’ in
the object drop case for ‘n’ and ‘na,’ Sache ‘thing’ in the inchoative/causative case for
‘n’ and ‘na’.
In addition to the absolute verb descriptions above, a simple smoothing technique
is applied to the feature values. The goal of smoothing is to create more uniform
distributions, especially with regard to adjusting zero values, but also for assimilating
high and low frequencies and probabilities. The smoothed distributions are particularly
interesting for distributions with a large number of features, since they typically contain
</bodyText>
<footnote confidence="0.904454">
1 Since GermaNet had not been completed when we used the hierarchy, we manually added a few
hypernym definitions.
</footnote>
<page confidence="0.98886">
168
</page>
<note confidence="0.667443">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<tableCaption confidence="0.716753">
Table 1
Example distributions of German verbs.
</tableCaption>
<table confidence="0.5933268125">
Distribution
Verb D1 D2 D3
beginnen np 0.43 n 0.28 n(Situation) 0.12
‘begin’ n 0.28 np:umA,, 0.16 np:umA,,(Situation) 0.09
ni 0.09 ni 0.09 np:mitDat(Situation) 0.04
na 0.07 np:mitDat 0.08 ni(Lebewesen) 0.03
nd 0.04 na 0.07 n(Zustand) 0.03
nap 0.03 np:anDat 0.06 np:anDat(Situation) 0.03
nad 0.03 np:inDat 0.06 np:inDat(Situation) 0.03
nir 0.01 nd 0.04 n(Zeit) 0.03
ns-2 0.01 nad 0.03 n(Sache) 0.02
xp 0.01 np:nachDat 0.01 na(Situation) 0.02
essen na 0.42 na 0.42 na(Lebewesen) 0.33
‘eat’ n 0.26 n 0.26 na(Nahrung) 0.17
nad 0.10 nad 0.10 na(Sache) 0.09
np 0.06 nd 0.05 n(Lebewesen) 0.08
nd 0.05 ns-2 0.02 na(Lebewesen) 0.07
nap 0.04 np:aufDat 0.02 n(Nahrung) 0.06
ns-2 0.02 ns-w 0.01 n(Sache) 0.04
ns-w 0.01 ni 0.01 nd(Lebewesen) 0.04
ni 0.01 np:mitDat 0.01 nd(Nahrung) 0.02
nas-2 0.01 np:inDat 0.01 na(Attribut) 0.02
fahren n 0.34 n 0.34 n(Sache) 0.12
‘drive’ np 0.29 na 0.19 n(Lebewesen) 0.10
na 0.19 np:inA,, 0.05 na(Lebewesen) 0.08
nap 0.06 nad 0.04 na(Sache) 0.06
nad 0.04 np:zuDat 0.04 n(Ort) 0.06
nd 0.04 nd 0.04 na(Sache) 0.05
ni 0.01 np:nachDat 0.04 np:inA,,(Sache) 0.02
ns-2 0.01 np:mitDat 0.03 np:zuDat(Sache) 0.02
ndp 0.01 np:inDat 0.03 np:inA,,(Lebewesen) 0.02
ns-w 0.01 np:aufDat 0.02 np:nachDat(Sache) 0.02
</table>
<bodyText confidence="0.99984075">
persuasive zero values and severe outliers. Chen and Goodman (1998) present a concise
overview of smoothing techniques, with specific emphasis on language modeling. We
decided to apply the smoothing algorithm referred to as additive smoothing: The smooth-
ing is performed simply by adding 0.5 to all verb features, that is, the joint frequency
of each verb v and feature xi is changed by freq&apos;(v,xi) = freq(v,xi) + 0.5. The total verb
frequency is adapted to the changed feature values, representing the sum of all verb
feature values: vfreql = Eifreq&apos;(v,xi). Smoothed probability values are based on the
smoothed frequency distributions.
</bodyText>
<subsectionHeader confidence="0.99992">
2.3 Clustering Algorithm and Evaluation Techniques
</subsectionHeader>
<bodyText confidence="0.990782">
Clustering is a standard procedure in multivariate data analysis. It is designed to
allow exploration of the inherent natural structure of the data objects, where objects
in the same cluster are as similar as possible and objects in different clusters are as
dissimilar as possible. Equivalence classes induced by the clusters provide a means for
</bodyText>
<page confidence="0.981508">
169
</page>
<note confidence="0.28839">
Computational Linguistics Volume 32, Number 2
</note>
<bodyText confidence="0.99997898">
generalizing over the data objects and their features. The clustering of the German verbs
is performed by the k-means algorithm, a standard unsupervised clustering technique
as proposed by Forgy (1965). With k-means, initial verb clusters are iteratively reorgan-
ized by assigning each verb to its closest cluster and recalculating cluster centroids until
no further changes take place. Applying the k-means algorithm assumes (1) that verbs
are represented by distributional vectors and (2) that verbs that are closer to each other
in a mathematically defined way are also more similar to each other in a linguistic
way. k-Means depends on the following parameters: (1) The number of clusters is not
known beforehand, so the clustering experiments investigate this parameter. Related
to this parameter is the level of semantic concept: The more verb clusters are found,
the more specific the semantic concept, and vice versa. (2) k-means is sensitive to the
initial clusters, so the initialization is varied according to how much preprocessing we
invest: Both random clusters and hierarchically preprocessed clusters are used as initial
clusters for k-means. In the case of preprocessed clusters, the hierarchical clustering
is performed as bottom-up agglomerative clustering with the following criteria for
merging the clusters: single linkage (minimal distance between nearest neighbor verbs),
complete linkage (minimal distance between furthest neighbor verbs), average distance
between verbs, distance between cluster centroids, and Ward’s method (minimizing the
sum of squares when merging clusters). The merging method influences the shape of
the clusters; for example, single linkage causes a chaining effect in the shape of the
clusters, and complete linkage creates compact clusters. (3) In addition, there are several
possibilities for defining the similarity between distributional vectors. But which best
fits the idea of verb similarity? Table 2 presents an overview of relevant similarity
measures that are applied in the experiments. x and y refer to the verb object vectors,
their subscripts to the verb feature values. The Minkowski metric can be applied to
frequencies and probabilities. It is a generalization of the two well-known instances
q = 1 (Manhattan distance) and q = 2 (Euclidean distance). The Kullback–Leibler divergence
(KL) is a measure from information theory that determines the inefficiency of assuming
a model probability distribution given the true distribution (Cover and Thomas 1991).
The KL divergence is not defined in case yi = 0, so the probability distributions need
to be smoothed. Two variants of KL, information radius and skew divergence, perform a
default smoothing. Both variants can tolerate zero values in the distribution because
they work with a weighted average of the two distributions compared. Lee (2001) has
shown that the skew divergence is an effective measure for distributional similarity in
NLP. Similarly to Lee’s method, we set the weight w for the skew divergence to 0.9. The
cosine measures the similarity of the two object vectors x and y by calculating the cosine
of the angle between the feature vectors. The cosine measure can be applied to frequency
and probability values. For a detailed description of hierarchical clustering techniques
and an intuitive interpretation of the similarity measures, the reader is referred to, for
example, Kaufman and Rousseeuw (1990).
There is no agreed standard method for evaluating clustering experiments and
results, but a variety of evaluation measures from diverse areas such as theoretical
statistics, machine vision, and Web-page clustering are generally applicable. We used
the following two measures for the evaluation: (1) Hatzivassiloglou and McKeown
(1993) define and evaluate a cluster analysis of adjectives, based on common cluster
membership of object pairs in the clustering C and the manual classification M. Recall
and precision numbers are calculated in the standard way, with true positives the
number of common pairs in M and C, false positives the number of pairs in C, but
not M, and false negatives the number of pairs in M, but not C. We use the f-score pairF
(as harmonic mean between recall and precision), which provides an easy to understand
</bodyText>
<page confidence="0.984716">
170
</page>
<note confidence="0.578075">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<tableCaption confidence="0.859861">
Table 2
</tableCaption>
<figure confidence="0.298165222222222">
Data similarity measures.
Measure Definition
~~n
Minkowski metric / Lq norm Lq(x, y) = q i=1 |xi − yi|q
L1(x, y) = ~n
Manhattan distance / L1 norm i=1 |xi − yi|
~~n
Euclidean distance / L2 norm L2(x,y) = i=1(xi − yi)2
KL divergence / relative entropy D(x||y) = Eni=1 xi * log xi
</figure>
<equation confidence="0.984985375">
yi
Information radius IRad(x,y) = D(x ||x+y
2 ) + D(y||x+y
2 )
Skew divergence Skew(x,y) = D(x||w * y + (1 − w) * x)
~n i=1 xi ∗ yi
Cosine cos(x, y) =
~~n
</equation>
<bodyText confidence="0.999566375">
percentage. (2) The adjusted Rand index is a measure of agreement versus disagreement
between object pairs in clusterings that provides the most appropriate reference to
a null model (Hubert and Arabie 1985); cf. equation (1). The agreement in the two
partitions is represented by a contingency table C x M: tij denotes the number of verbs
common to classes Ci in the clustering partition C and Mj in the manual classification
M; the marginals ti. and t.j refer to the number of objects in Ci and Mj, respectively; the
expected number of common object pairs attributable to a particular cell (Ci,Mj) in the
contingency table is defined by ~ti. ��t.j ~/~n �. The upper bound for Randadj is 1, the lower
</bodyText>
<equation confidence="0.996235777777778">
2 2 2
bound is mostly 0, with only extreme cases below zero.
~~n
i=1 x2 i ∗i=1 y2 i
Randadj(C, M) = (2o − Ei 02.)i) i(t.j2 ) (1)
~
2 (� ~ti. � + � �t.j i (ti. 2 ) � j (t.j 2 )
1 �) −
i 2 j 2 (n 2)
</equation>
<bodyText confidence="0.999884333333333">
The above two measures were chosen as a result of comparing various evaluation
measures and their properties with respect to the linguistic task (Schulte im Walde
2003a, chapter 4).
</bodyText>
<sectionHeader confidence="0.881036" genericHeader="introduction">
3. Preliminary Clustering Experiments
</sectionHeader>
<bodyText confidence="0.999844454545455">
The 168 German verbs are associated with distributional vectors over frame types and
assigned to initial clusters. Then k-means is allowed to run for as many iterations as
it takes to reach a fixed point, and the resulting clusters are interpreted and evaluated
against the manual classes. The verbs are described by D1–D3, and each level refers to
frequencies and probabilities, with original and smoothed values. The initial clusters
for k-means are generated either randomly or by a preprocessing cluster analysis, that
is, hierarchical clustering as described in Section 2.3. For random cluster initialization
the verbs are randomly assigned to a cluster, with cluster numbers between 1 and the
number of manual classes. The experiments are performed with the number of k clusters
being fixed to the number of gold standard classes (43); optimization of the number of
clusters is addressed in Section 3.4.
</bodyText>
<page confidence="0.976432">
171
</page>
<figure confidence="0.366376">
Computational Linguistics Volume 32, Number 2
</figure>
<subsectionHeader confidence="0.993223">
3.1 Baseline and Upper Bound
</subsectionHeader>
<bodyText confidence="0.999826111111111">
The experiment baseline refers to 50 random clusterings: The verbs are randomly as-
signed to a cluster (with a cluster number between 1 and the number of manual classes),
and the resulting clustering is evaluated by the evaluation measures. The baseline value
is the average value of the 50 repetitions. The upper bound of the experiments (the
“optimum”) refers to the evaluation values on the manual classification; the manual
classification is adapted before calculating the upper bound by randomly deleting
additional senses (i.e., more than one sense) of a verb, so as to leave only one sense
for each verb, since k-means as a hard clustering algorithm cannot model ambiguity.
Table 3 lists the baseline and upper bound values for the clustering experiments.
</bodyText>
<subsectionHeader confidence="0.999253">
3.2 Experiment Results
</subsectionHeader>
<bodyText confidence="0.999896962962963">
The following tables present the results of the clustering experiments. Tables 4 to 7
each concentrate on one technical parameter of the clustering process; Tables 8 to 10
then focus on performing clustering with a fixed parameter set, in order to vary the
linguistically interesting parameters concerning the feature choice for the verbs. All
significance tests have been performed with χ2, df = 1, α = 0.05.
Table 4 illustrates the effect of the distribution units (frequencies and probabilities)
on the clustering result. The experiments use distributions on D1 and D2 with random
and preprocessed initialization, and the cosine as similarity measure (since it works
for both distribution units). To summarize the results, neither the differences between
frequencies and probabilities nor between original and smoothed values are significant.
Table 5 illustrates the usage of different similarity measures. As before, the exper-
iments are performed for D1 and D2 with random and preprocessed initialization.
The similarity measures are applied to the relevant probability distributions (as the
distribution unit that can be used for all measures). The tables point out that there
is no best-performing similarity measure in the clustering processes. On the larger
feature set, the Kullback–Leibler variants information radius and skew divergence tend
to outperform all other similarity measures. In fact, the skew divergence is the only
measure that shows significant differences for some parameter settings, as compared to
all other measures except information radius. In further experiments, we will therefore
concentrate on the two Kullback–Leibler variants.
Tables 6 and 7 compare the effects of varying the initialization of the k-means
algorithm. The experiments are performed for D1 and D2 with probability distrib-
utions, using the similarity measures information radius and skew divergence. For
random and hierarchical initialization, we cite both the evaluation scores for the
k-means initial cluster analysis (i.e., the output clustering from the random assignment
or the preprocessing hierarchical analysis), and for the k-means result. The manual
columns in the tables refer to a cluster analysis where the initial clusters provided to
</bodyText>
<tableCaption confidence="0.995669">
Table 3
</tableCaption>
<table confidence="0.860269">
k-means experiment baseline and upper bound.
Evaluation Baseline Optimum
PairF 2.08 95.81
Randadj −0.004 0.909
172
Schulte im Walde Induction of German Semantic Verb Classes
</table>
<tableCaption confidence="0.996135">
Table 4
</tableCaption>
<table confidence="0.993703375">
Comparing distributions on D1 and D2.
Distribution: D1 Distribution: D2
Probability Frequency Probability Frequency
Eval Initial Original Smoothed Original Smoothed Original Smoothed Original Smoothed
PairF Random 12.67 12.72 14.06 14.14 14.98 15.37 14.82 15.07
H-Ward 11.40 11.70 11.56 11.37 10.57 13.71 11.65 9.98
Randa Random 0.090 0.090 0.102 0.102 0.104 0.113 0.107 0.109
H-Ward 0.079 0.081 0.080 0.076 0.065 0.096 0.075 0.056
</table>
<tableCaption confidence="0.99436">
Table 5
</tableCaption>
<table confidence="0.98826275">
Comparing similarity measures on D1 and D2.
Similarity Measure
D1 D2
Eval Initial Cos L1 Eucl IRad Skew Cos L1 Eucl IRad Skew
PairF Random 12.67 13.11 13.85 14.19 14.13 14.98 15.20 16.10 16.15 18.01
H-Ward 11.40 13.65 12.88 13.07 12.64 10.57 15.51 13.11 17.49 19.30
Randa Random 0.090 0.094 0.101 0.101 0.105 0.104 0.109 0.123 0.118 0.142
H-Ward 0.079 0.099 0.093 0.097 0.094 0.065 0.116 0.092 0.142 0.158
</table>
<bodyText confidence="0.999906259259259">
k-means are the manual classification, that is, the gold standard. An optimal cluster
analysis should realize the “perfect” clustering and not perform any reorganization of
the clusters. In the experiments, k-means does perform iterations, so the clustering result
is suboptimal. This finding is caused by the syntax–semantics mismatches, which we
deliberately included in the definition of the gold standard (recall, e.g., that unterst¨utzen
is syntactically very different compared to the other three Support verbs). In addition,
the results not only show that the feature sets are suboptimal, but also that the loss
in quality is less for the linguistically refined feature level D2 compared to D1, as we
would have hoped. For random clustering initialization to k-means, the tables present
both the best and the average clustering results. The best results are paired with the
evaluation of their initial clusters, that is, the random clusterings. As the tables show, the
initial clusters receive low evaluation scores. Typically, the clusterings consist of clusters
with rather homogeneous numbers of verbs, but the perturbation within the clusters
is high, as expected. k-means is able to cope with the high degree of perturbation:
The resulting clusters improve significantly and are comparable with those based on
preprocessed hierarchical clustering; this competitiveness vanishes with an increasing
number of features. The average values of the random initialization experiments are
clearly below the best ones, but not significantly different. Cluster analyses as based on
agglomerative hierarchical clustering with single-linkage amalgamation are evaluated as
poor compared to the gold standard. This result is probably due to the chaining effect
in the clustering, which is characteristic for single linkage; the effect is observable in
the analysis, which typically contains one very large cluster and many clusters with
few verbs, mostly singletons. k-means obviously cannot compensate for this strong
bias in cluster sizes (and their respective centroids); the reorganization improves the
clusterings, but the result is still worse than for any other initialization. With average
distance and centroid distance amalgamation, both the clusterings and the evaluation
results are less extreme than with single linkage since the chaining effect is smoothed.
</bodyText>
<page confidence="0.992249">
173
</page>
<table confidence="0.571902">
Computational Linguistics Volume 32, Number 2
</table>
<tableCaption confidence="0.98757">
Table 6
</tableCaption>
<table confidence="0.991262933333333">
Comparing clustering initializations on D1.
k-means Initialization
Random
Eval Distance Manual Best Avg
PairF IRad 18.56 2.16 14.19 11.78
Skew 20.00 1.90 14.13 12.17
Randa IRad 0.150 −0.004 0.101 0.078
Skew 0.165 −0.005 0.105 0.083
k-means Initialization
Hierarchical
Eval Distance Single Complete Average Centroid Ward
PairF IRad 4.80 12.73 9.43 10.16 10.83 11.33 8.77 11.88 12.76 13.07
Skew 4.81 13.04 11.50 11.00 11.68 11.41 8.83 11.45 12.44 12.64
Randa IRad 0.000 0.088 0.055 0.065 0.067 0.072 0.039 0.079 0.094 0.097
Skew 0.000 0.090 0.077 0.072 0.075 0.073 0.041 0.072 0.092 0.094
</table>
<bodyText confidence="0.997669545454545">
The overall results are better than for single linkage, but only slightly improved by
k-means. Hierarchical clusters as based on complete-linkage amalgamation are more
compact, and result in a closer fit to the gold standard than the previous methods.
The hierarchical initialization is only slightly improved by k-means; in some cases
the k-means output is worse than its hierarchical initialization. Ward’s method seems
to work best on hierarchical clusters and k-means initialization. The cluster sizes are
more balanced and correspond to compact cluster shapes. As for complete linkage,
k-means improves the clusterings only slightly; in some cases the k-means output is
worse than its hierarchical initialization. A cluster analysis based on Ward’s hierarchical
clusters performs best of all the applied methods, especially with an increasing number
of features. The similarity of Ward’s clusters (and similarly complete linkage clusters)
</bodyText>
<tableCaption confidence="0.996572">
Table 7
</tableCaption>
<table confidence="0.991328666666667">
Comparing clustering initializations on D2.
k-means Initialization
Random
Eval Distance Manual Best Avg
PairF IRad 40.23 1.34 16.15 13.37
Skew 47.28 2.41 18.01 14.07
Randa IRad 0.358 0.001 0.118 0.093
Skew 0.429 −0.002 0.142 0.102
k-means Initialization
Hierarchical
Eval Distance Single Complete Average Centroid Ward
PairF IRad 5.06 11.12 15.37 14.44 10.50 10.64 9.16 12.90 17.86 17.49
Skew 5.20 10.64 15.21 13.81 10.02 10.02 9.04 10.91 15.86 15.23
Randa IRad 0.003 0.063 0.114 0.105 0.059 0.060 0.045 0.082 0.145 0.142
Skew 0.004 0.063 0.115 0.102 0.054 0.054 0.042 0.064 0.158 0.158
</table>
<page confidence="0.785465">
174
</page>
<note confidence="0.612996">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<bodyText confidence="0.998400285714286">
and k-means is not by chance, since these methods aim to optimize the same criterion,
the sum of distances between the verbs and their respective cluster centroids. Note
that for D2, Ward’s method actually significantly outperforms all other initialization
methods, complete linkage significantly outperforms all but Ward’s. Between single
linkage, average and centroid distance, there are no significant differences. For D1, there
are no significant differences between the initializations.
The low scores in the tables might be surprising to the reader, but they reflect the
difficulty of the task. As mentioned before, we deliberately set high demands for the
gold standard, especially with reference to the fine-grained, small classes. Compared
to related work (cf. Section 5), our results achieve lower scores because the task is
more difficult; for example, Merlo and Stevenson (2001) classify 60 verbs into 3 classes,
and Siegel and McKeown (2000) classify 56 verbs into 2 classes, as compared to our
clustering, which assigns 168 verbs to 43 classes. The following illustrations should
provide an intuition about the difficulty of the task:
</bodyText>
<listItem confidence="0.85221">
1. In a set of additional experiments, a random choice of a reduced number
</listItem>
<bodyText confidence="0.836009777777778">
of 5/10/15/20 classes from the gold standard is performed. The verbs
from the respective gold standard classes are clustered with the optimal
parameter set (see Table 8), which results in a pairwise f-score PairF of
22.19%. The random choice and the cluster analysis are repeated 20 times
for each reduced gold standard size of 5/10/15/20 classes, and the
average PairF is calculated: The results are 45.27/35.64/30.30/26.62%,
respectively. This shows that the clustering results are much better (with
the same kind of data and features and the same algorithm) when applied
to a smaller number of verbs and classes.
</bodyText>
<listItem confidence="0.886085272727273">
2. Imagine a gold standard of three classes with four members each, for
example, {{a, b, c, d}, {e, f, g, h}, {i, j, k, l}}. If a cluster analysis of these
elements into three clusters resulted in an almost perfect choice of {{a, b,
c, d, e}, {f, g, h}, {i, j, k, l}} where only e is assigned to a ”wrong” class,
the pairwise precision is 79%, the recall is 83%, and pairF is 81%, so the
decrease of pairF with only one mistake is almost 20%. If another cluster
analysis resulted in a choice with just one more mistake such as {{a, b,
c, d, e, i}, {f, g, h}, {j, k, l}} where i is also assigned to a ”wrong” class, the
result decreases by almost another 20%, to a precision of 57%, a recall of
67%, and pairF of 62%. The results show how much impact a few mistakes
may have on the pairwise f-score of the results.
</listItem>
<bodyText confidence="0.99987">
In addition to defining a difficult task, we also chose strong evaluation measures:
Evaluating pairs of objects results in lower numbers than evaluating the individual
objects. For example, the accuracy/purity measure (Stevenson and Joanis 2003; Korhonen,
Krymolowski, and Marx 2003) evaluates whether a verb is assigned to a correct cluster
with respect to the gold standard class of the majority of cluster members. That is, in
a first step each induced verb cluster is assigned a gold standard class according to
which class captures the majority of the cluster members. In a second step, each verb
in a cluster is evaluated as correct or wrong with respect to its gold standard class,
and accuracy/purity of the whole clustering is calculated as the proportion of correct
verbs divided by the total number of verbs. If we applied this measure to our optimal
clustering with a pairwise f-score PairF of 22.19%, we achieve an accuracy of 51.19%;
if we applied the measure to the above random choices of gold standard classes with
5/10/15/20 classes, we achieve accuracies of 68.20/60.73/57.82/55.48%.
</bodyText>
<page confidence="0.98705">
175
</page>
<note confidence="0.490464">
Computational Linguistics Volume 32, Number 2
</note>
<bodyText confidence="0.999947769230769">
The last series of experiments applies the algorithmic insights from the previous
experiments to a linguistic variation of parameters (cf. Schulte im Walde 2003b). The
verbs are described by probability distributions on different levels of linguistic infor-
mation (frames, prepositional phrases, and selectional preferences). A preprocessing
hierarchical cluster analysis is performed by Ward’s method, and k-means is applied
to re-organize the clusters. Similarities are measured by the skew divergence. Table 8
presents the first results comparing D1, D2, and D3, either on specified frame slots (‘n,’
‘na,’ ‘nd,’ ‘nad,’ ‘ns-dass’), on all noun phrase slots (NP), or on all noun phrase and
prepositional phrase slots (NP–PP). The number of features in each experiment is given
in square brackets. The table demonstrates that a purely syntactic verb description gives
rise to a verb clustering clearly above the baseline. Refining the coarse subcategorization
frames with prepositional phrases considerably improves the verb clustering results.
Adding selectional preferences to the verb description further improves the clustering
results, but the improvement is not as persuasive as in the first step, when refining
the purely syntactic verb descriptions with prepositional information. The difference
between D1 and D2 is significant, but neither the difference between D2 and D3 (in
any variation) nor the differences between the variants of D3 are significant. In the case
of adding role information to all NP (and all PP) slots, the problem might be caused
by sparse data, but for the linguistically chosen subset of argument slots we assume
additional linguistic reasons are directly relevant to the clustering outcome.
In order to choose the most informative frame roles for D3, we varied the selectional
preference slots by considering only single slots for refinements, or small combinations
of argument slots. The variations should provide insight into the contribution of slots
and slot combinations to the clustering. The experiments are performed on probability
distributions for D3; all other parameters were chosen as above. Table 9 shows that
refining only a single slot (the underlined slot in the respective frame type) in addition
to the D2 definitions results in little or no improvement. There is no frame-slot type
that consistently improves results, but success depends on the parameter instantiation.
The results do not match our linguistic intuitions: For example, we would expect the
arguments in the two highly frequent intransitive ‘na’ and transitive ‘na’ frames with
variable semantic roles to provide valuable information with respect to their selectional
preferences, but only those in ‘na’ actually improve D2. However, a subject in a transi-
tive construction with a non-finite clause ‘ni’, which is less variable with respect to verbs
and roles, does work better than ‘n’. In Table 10, selected slots are combined to define
selectional preference information, for example, n/na means that the nominative slot
in ‘na’, and both the nominative and accusative slot in ‘na’ are refined by selectional
preferences. It is obvious that the clustering effect does not represent a sum of its
parts, for example, both the information in ‘na’ and in ‘na’ improve Ward’s clustering
based on D2 (cf. Table 9), but it is not the case that ‘na’ improves the clustering, too.
</bodyText>
<tableCaption confidence="0.996623">
Table 8
</tableCaption>
<table confidence="0.940227625">
Comparing feature descriptions.
Distribution
Eval D1 D2 D3 D3 NP D3 NP–PP
[38] [183] [288] [906] [2,726]
PairF 12.64 18.81 22.19 19.29 21.11
Randadj 0.094 0.151 0.182 0.158 0.176
176
Schulte im Walde Induction of German Semantic Verb Classes
</table>
<tableCaption confidence="0.994059">
Table 9
</tableCaption>
<table confidence="0.2894215">
Comparing selectional preference slot definitions.
Distribution
</table>
<bodyText confidence="0.999482833333333">
As in Table 9, there is no combination of selectional preference frame definitions that
consistently improves the results. On the contrary, some additional D3 information
makes the result significantly worse, for example, ‘nad’. The specific combination of
selectional preferences as determined preexperimentally actually achieves the overall
best results, better than any other slot combination, and better than refining all NP slots
or refining all NP and all PP slots in the frame types (cf. Table 8).
</bodyText>
<subsectionHeader confidence="0.985305">
3.3 Experiment Interpretation
</subsectionHeader>
<bodyText confidence="0.999793">
For illustrative purposes, we present representative parts of the cluster analysis as based
on the following parameters: The clustering initialization is obtained from a hierarchical
analysis of the German verbs (Ward’s amalgamation method), the number of clusters
being the number of manual classes (43); the similarity measure is the skew divergence.
The cluster analysis is based on the verb description on D3, with selectional roles for
</bodyText>
<tableCaption confidence="0.993793">
Table 10
</tableCaption>
<table confidence="0.991481576923077">
Comparing selectional preference frame definitions.
Distribution
Eval D2 n na D3 n/na/nad
n/na nad
PairF 18.81 16.22 17.82 17.00 13.36 16.05
Randadj 0.151 0.125 0.137 0.128 0.088 0.118
Distribution
Eval D2 nd n/na/nd D3 np/ni/nr/ns-2/ns-dass
n/na/nad/nd
PairF 18.81 18.48 16.48 20.21 16.73
Randadj 0.151 0.150 0.124 0.161 0.131
Eval D2 n na
PairF 18.81 16.22 21.15
Randadj 0.151 0.125 0.176
Eval D2 nd nd
PairF 18.81 18.88 17.92
Randadj 0.151 0.152 0.143
D3
na nad nad nad
20.19 17.82 15.13 19.48
0.164 0.144 0.115 0.161
Distribution
D3
np ni nr ns-2 ns-dass
16.77 18.26 17.22 15.55 19.29
0.133 0.148 0.136 0.121 0.156
</table>
<page confidence="0.954498">
177
</page>
<figure confidence="0.884461846153846">
Computational Linguistics Volume 32, Number 2
‘n,’ ‘na,’ ‘nd,’ ‘nad,’ ‘ns-dass.’ We compare the clusters with the respective clusters by
D1 and D2.
(a) nieseln regnen schneien – Weather
(b) d¨ammern – Weather
(c) beginnen enden – Aspect
bestehen existieren – Existence
liegen sitzen stehen – Position
laufen – Manner of Motion: Locomotion
(d) kriechen rennen – Manner of Motion: Locomotion
eilen – Manner of Motion: Rush
gleiten – Manner of Motion: Flotation
starren – Facial Expression
</figure>
<listItem confidence="0.966590777777778">
(e) klettern wandern – Manner of Motion: Locomotion
fahren fliegen segeln – Manner of Motion: Vehicle
fließen – Manner of Motion: Flotation
(f) festlegen – Constitution
bilden – Production
erh¨ohen senken steigern vergr¨oßern verkleinern – Quantum Change
(g) t¨oten – Elimination
unterrichten – Teaching
(h) geben – Transfer of Possession (Giving): Gift
</listItem>
<bodyText confidence="0.999896043478261">
The weather verbs in cluster (a) strongly agree in their syntactic expression on D1 and
do not need D2 or D3 refinements for an improved class constitution. d¨ammern in cluster
(b) is ambiguous between a weather verb and expressing a sense of understanding;
this ambiguity is already idiosyncratically expressed in D1 frames, so d¨ammern is never
clustered together with the other weather verbs by D1–D3. Manner of Motion, Existence,
Position, and Aspect verbs are similar in their syntactic frame usage and therefore
merged together by D1, but adding PP information distinguishes the respective verb
classes: Manner of Motion verbs primarily demand directional PPs, Aspect verbs are
distinguished by patient mitDat and time and location prepositions, and Existence and
Position verbs are distinguished by locative prepositions, with Position verbs show-
ing more PP variation. The PP information is essential for distinguishing these verb
classes, and the coherence is partly destroyed by D3: Manner of Motion verbs (from the
subclasses Locomotion, Rotation, Rush, Vehicle, Flotation) are captured well by clusters (d)
and (e), since they use common alternations, but cluster (c) merges Existence, Position,
and Aspect verbs because verb-idiosyncratic demands on selectional roles destroy the
D2 class demarcation. Still, the verbs in cluster (c) are close in their (more general con-
ceptual) semantics, with a common sense of (bringing into versus being in) existence.
laufen fits into the cluster with its sense of “function.” Cluster (f) contains most verbs
of Quantum Change, together with one verb of Production and Constitution each. The
common conceptual level of this cluster therefore refers to a quantum change including
the quantum change from zero to something (as for the two verbs festlegen, ‘constitute,’
and bilden, ‘found’). The verbs in this cluster typically subcategorize for a direct object,
alternating with a reflexive usage, “nr” and “npr” with mostly aufAcc and umAcc. The
</bodyText>
<page confidence="0.99421">
178
</page>
<note confidence="0.765027">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<bodyText confidence="0.99997984">
selectional preferences help to distinguish this cluster: The verbs agree in demanding a
thing or situation as subject, and various objects such as attribute, cognitive object, state,
structure, or thing as object. Without selectional preferences (on D1 and D2), the change
of quantum verbs are not found together with the same degree of purity. There are verbs
as in cluster (g) whose properties are correctly stated as similar by D1–D3, so a common
cluster is justified, but the verbs only have coarse common meaning components; in this
case t¨oten ‘kill’ and unterrichten ‘teach’ agree in an action of one person or institution
towards another. geben in cluster (h) represents a singleton. Syntactically, this is caused
by being the only verb with a strong preference for “xa.” From the meaning point of
view, this specific frame represents an idiomatic expression, only possible with geben.
An overall interpretation of the clustering results gives insight into the relationship
between verb properties and clustering outcome. (1) The fact that there are verbs that
are clustered semantically on the basis of their corpus-based and knowledge-based
empirical properties indicates (a) a relationship between the meaning components of
the verbs and their behavior and (b) that the clustering algorithm is able to benefit from
the linguistic descriptions and to abstract away from the noise in the distributions. (2)
Low-frequency verbs were a problem in the clustering experiments. Their distributions
are noisier than those for more frequent verbs, so they typically constitute noisy clusters.
(3) As known beforehand, verb ambiguity cannot be modeled by the hard clustering
algorithm k-means. Ambiguous verbs were typically assigned either (a) to one of the
correct clusters or (b) to a cluster whose verbs have distributions that are similar to
the ambiguous distribution, or (c) to a singleton cluster. (4) The interpretation of the
clusterings unexpectedly points to meaning components of verbs that have not been
discovered by the manual classification. An example verb is laufen, expressing not only
a Manner of Motion but also a kind of existence when used in the sense of operation. The
discovery effect should be more impressive with an increasing number of verbs, since
manual judgement is more difficult, and also with a soft clustering technique, where
multiple cluster assignment is enabled. (5) In a similar way, the clustering interpretation
exhibits semantically related verb classes, that is, verb classes that are separated in
the manual classification, but semantically merged in a common cluster. For example,
Perception and Observation verbs are related in that all the verbs express an observation,
with the Perception verbs additionally referring to a physical ability, such as hearing. (6)
Related to the preceding issue, the manual verb classes as defined are demonstrated as
detailed and subtle. Compared to a more general classification that would appropriately
merge several classes, the clustering confirms that we defined a difficult task with subtle
classes. We were aware of this fact but preferred a fine-grained classification, since
it allows insight into verb and class properties. In this way, verbs that are similar in
meaning are often clustered incorrectly with respect to the gold standard.
To come to the main point, what exactly is the nature of the meaning–behavior
relationship? (1) Already a purely syntactic verb description allows a verb clustering
clearly above the baseline. The result is a (semantic) classification of verbs that agree in
their syntactic frame definitions, for example, most of the Support verbs. The clustering
fails for semantically similar verbs that differ in their syntactic behavior, for example,
unterst¨utzen, which belongs to the Support verbs but demands an accusative rather
than a dative object. In addition, it fails for syntactically similar verbs that are clus-
tered together even though they do not exhibit semantic similarity; for example, many
verbs from different semantic classes subcategorize for an accusative object, so they are
falsely clustered together. (2) Refining the syntactic verb information with prepositional
phrases is helpful for the semantic clustering, not only in the clustering of verbs where
the PPs are obligatory, but also in the clustering of verbs with optional PP arguments.
</bodyText>
<page confidence="0.993915">
179
</page>
<note confidence="0.498148">
Computational Linguistics Volume 32, Number 2
</note>
<bodyText confidence="0.999983810810811">
The improvement underlines the linguistic fact that verbs that are similar in their
meaning agree either on a specific prepositional complement (e.g., glauben/denken anAcc)
or on a more general kind of modification, for example, directional PPs for Manner of
Motion verbs. (3) Defining selectional preferences for arguments improves the clustering
results further, but the improvement is not as persuasive as when refining the purely
syntactic verb descriptions with prepositional information. For example, selectional
preferences help demarcate the Quantum Change class because the respective verbs agree
in their structural as well as selectional properties. But in the Consumption class, essen
and trinken have strong preferences for a food object, whereas konsumieren allows a
wider range of object types. In contrast, there are verbs that are very similar in their
behavior, especially with respect to a coarse definition of selectional roles, but they do
not belong to the same fine-grained semantic class, for example, t¨oten and unterrichten.
The effect could be due to (a) noisy or (b) sparse data, but the basic verb descriptions
appear reliable with respect to their desired linguistic content, and Table 8 illustrates
that even with little added information the effect exists (e.g., refining few arguments by
15 selectional roles results in 253 instead of 178 features, so the magnitude of feature
numbers does not change). Why do we encounter an indeterminism concerning the
encoding and effect of verb features, especially with respect to selectional preferences?
The meaning of verbs comprises both properties that are general for the respective
verb classes, and idiosyncratic properties that distinguish the verbs from each other.
As long as we define the verbs by those properties that represent the common parts of
the verb classes, a clustering can succeed. But by stepwise refining the verb description
and including lexical idiosyncrasy, the emphasis on the common properties vanishes.
From a theoretical point of view, the distinction between common and idiosyncratic
features is obvious, but from a practical point of view there is no perfect choice for
the encoding of verb features. The feature choice depends on the specific properties
of the desired verb classes, and even if classes are perfectly defined on a common
conceptual level, the relevant level of behavioral properties of the verb classes might
differ. Still, for a large-scale classification of verbs, we need to specify a combination
of linguistic verb features as a basis for the clustering. Which combination do we
choose? Both the theoretical assumption of encoding features of verb alternation as verb
behavior and the practical realization by encoding syntactic frame types, prepositional
phrases, and selectional preferences seem promising. In addition, we aimed at a (rather
linguistically than technically based) choice of selectional preferences that represents a
useful compromise for the conceptual needs of the verb classes. Therefore, this choice of
features best utilizes the meaning–behavior relationship and will be applied in a large-
scale clustering experiment (cf. Section 4).
</bodyText>
<subsectionHeader confidence="0.99465">
3.4 Optimizing the Number of Clusters
</subsectionHeader>
<bodyText confidence="0.999996222222222">
It is not a goal of this article to optimize the number of clusters in the cluster analysis.
We are not interested in the question of whether, for example, 40, 42, 43, or 45 clusters
represent the best semantic classification of 168 verbs. But there are two reasons why
it is interesting and relevant to investigate the properties of clusterings with respect to
different numbers of clusters. (1) The clustering methodology should basically work the
way we expect it to work, that is, the evaluation of the results should show deficiencies
for extreme numbers of clusters, but (possibly several) optimal values for various
numbers of clusters in between. (2) Even if we do not check for an exact number of
clusters, we should check the magnitude of the number of clusters, since the clustering
</bodyText>
<page confidence="0.990098">
180
</page>
<note confidence="0.761321">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<bodyText confidence="0.999145818181818">
methodology might be successful in capturing a rough verb classification with few verb
classes but not a fine-grained classification with many subtle distinctions.
Figure 1 illustrates the clustering results for the series of cluster analyses as
performed by k-means with hierarchical clustering initialization (Ward’s method) on
probability distributions, with skew divergence as the similarity measure. The feature
description refers to D2. The number of clusters is varied from 1 through the number
of verbs (168), and the results are evaluated by Randadj. A range of numbers of clusters
is determined as optimal (71) or near-optimal (approx. 58–78). The figure demonstrates
that having performed experiments on the parameters for clustering, it is worthwhile
exploring additional parameters: The optimal result is 0.188 for 71 clusters as compared
to 0.158 for 43 clusters reported previously.
</bodyText>
<sectionHeader confidence="0.940678" genericHeader="method">
4. Large-Scale Clustering Experiments
</sectionHeader>
<bodyText confidence="0.998695333333333">
So far, all clustering experiments were performed on a small scale, preliminary set of
168 manually chosen German verbs. One goal of this article was to develop a clustering
methodology with respect to the automatic acquisition of a large-scale German verb
classification. We therefore apply the insights on the theoretical relationship between
verb meaning and verb behavior and our findings regarding the clustering parameters
to a considerably larger amount of verb data.
We extracted all German verbs from our statistical grammar model that appeared
with an empirical frequency of between 500 and 10,000 in the training corpus (cf.
Section 2.2). This selection resulted in a total of 809 verbs, including 94 verbs from
the preliminary set of 168 verbs. We added the missing verbs from the preliminary
set, resulting in a total of 883 German verbs. The feature description of the German
verbs refers to the probability distribution over the coarse syntactic frame types, with
</bodyText>
<figureCaption confidence="0.885714">
Figure 1
</figureCaption>
<bodyText confidence="0.648068">
Varying the number of clusters (evaluation: Randadj).
</bodyText>
<page confidence="0.985693">
181
</page>
<note confidence="0.494586">
Computational Linguistics Volume 32, Number 2
</note>
<bodyText confidence="0.9995583125">
prepositional phrase information on the 30 chosen PPs and selectional preferences for
our empirically most successful combination ‘n,’ ‘na,’ ‘nd,’ ‘nad,’ and ‘ns-dass.’ As in
previous clustering experiments, the features are stepwise refined. k-means is provided
hierarchical clustering initialization (based on Ward’s method), with the similarity mea-
sure being skew divergence. The number of clusters is set to 100, which corresponds
to an average of 8.83 verbs per cluster, that is, not too fine-grained clusters but still
possible to interpret. The preliminary set of 168 verbs is a subset of the large-scale
set in order to provide an “auxiliary” evaluation of the clustering results: Considering
only the manually chosen verbs in the clustering result, this partial cluster analysis is
evaluated against the gold standard of 43 verb classes. Results were not expected to
match the results of our clustering experiments using only the preliminary verb set,
but to provide an indication of how different cluster analyses can be compared with
each other.
Tables 11 to 13 present the clustering results for the large-scale verb set for D1–D3 in
the rightmost columns, citing the evaluation scores of the initial (hierarchical) clusters
and the resulting k-means clusters. The subset of the 168 gold standard verbs is scattered
over 72 of the 100 resulting clusters. The results are compared to our previous results
for the 168 verbs in 43 clusters, and to the case where those 168 verbs are clustered
into 72 hierarchical classes. The large-scale clustering results once more confirm the
general insights (1) that the stepwise refinement of features improves the clustering and
(2) that Ward’s hierarchical clustering is seldom improved by the k-means application.
In addition, several of the large-scale cluster analyses were quite comparable with the
clustering results using the small-scale set of verbs, especially when compared to 72
clusters.
In the following, we present example clusters from the optimal large-scale cluster
analysis (according to the above evaluation): Ward’s hierarchical cluster analysis based
on subcategorization frames, PPs, and selectional preferences, without running k-means
on the hierarchical clustering. Some clusters are extremely good with respect to the se-
mantic overlap of the verbs, some clusters contain a number of similar verbs mixed with
semantically different verbs, and for some clusters it is difficult to recognize common
elements of meaning. The verbs that we think are semantically similar are marked in
bold face.
</bodyText>
<listItem confidence="0.957657">
(1) abschneiden ‘cut off’, anziehen ‘dress’, binden ‘bind’, entfernen ‘remove’,
tunen ‘tune’, wiegen ‘weigh’
(2) aufhalten ‘detain’, aussprechen ‘pronounce’, auszahlen ‘pay off’, durchsetzen
‘achieve’, entwickeln ‘develop’, verantworten ‘be responsible’, verdoppeln
‘double’, zur¨uckhalten ‘keep away’, zur¨uckziehen ‘draw back’, ¨andern
‘change’
</listItem>
<tableCaption confidence="0.99825">
Table 11
</tableCaption>
<table confidence="0.9482738">
Large-scale clustering on D1.
Small-Scale Large-Scale
Eval 43 Clusters 72 Clusters 72 Clusters
PairF 12.44 → 12.64 10.83 → 11.73 12.15 → 12.88
Randadj 0.092 → 0.094 0.084 → 0.091 0.094 → 0.102
</table>
<page confidence="0.632369">
182
</page>
<note confidence="0.484048">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<tableCaption confidence="0.994649">
Table 12
</tableCaption>
<table confidence="0.97181">
Large-scale clustering on D2.
Small-Scale Large-Scale
Eval 43 Clusters 72 Clusters 72 Clusters
PairF 18.64 → 18.81 17.56 → 18.81 18.22 → 16.96
Randadj 0.148 → 0.151 0.149 → 0.161 0.152 → 0.142
</table>
<tableCaption confidence="0.992853">
Table 13
</tableCaption>
<table confidence="0.9546702">
Large-scale clustering on D3 with n/na/nd/nad/ns-dass.
Small-Scale Large-Scale
Eval 43 Clusters 72 Clusters 72 Clusters
PairF 22.86 → 22.19 19.47 → 20.48 19.92 → 15.06
Randadj 0.190 → 0.182 0.165 → 0.174 0.170 → 0.115
</table>
<listItem confidence="0.997487384615385">
(3) anh¨oren ‘listen’, auswirken ‘affect’, einigen ‘agree’, lohnen ‘be worth’,
verhalten ‘behave’, wandeln ‘promenade’
(4) abholen ‘pick up’, ansehen ‘watch’, bestellen ‘order’, erwerben ‘purchase’,
holen ‘fetch’, kaufen ‘buy’, konsumieren ‘consume’, verbrennen ‘burn’,
verkaufen ‘sell’
(5) anschauen ‘watch’, erhoffen ‘wish’, vorstellen ‘imagine’, w¨unschen ‘wish’,
¨uberlegen ‘think about’
(6) danken ‘thank’, entkommen ‘escape’, gratulieren ‘congratulate’
(7) beschleunigen ‘speed up’, bilden ‘constitute’, darstellen ‘illustrate’, decken
‘cover’, erf¨ullen ‘fulfil’, erh¨ohen ‘raise’, erledigen ‘fulfil’, finanzieren
‘finance’, f¨ullen ‘fill’, l¨osen ‘solve’, rechtfertigen ‘justify’, reduzieren
‘reduce’, senken ‘lower’, steigern ‘increase’, verbessern ‘improve’,
vergr¨oßern ‘enlarge’, verkleinern ‘make smaller’, verringern ‘decrease’,
verschieben ‘shift’, versch¨arfen ‘intensify’, verst¨arken ‘intensify’,
ver¨andern ‘change’
(8) ahnen ‘guess’, bedauern ‘regret’, bef¨urchten ‘fear’, bezweifeln ‘doubt’,
merken ‘notice’, vermuten ‘assume’, weißen ‘whiten’, wissen ‘know’
(9) anbieten ‘offer’, bieten ‘offer’, erlauben ‘allow’, erleichtern ‘facilitate’,
erm¨oglichen ‘make possible’, er¨offnen ‘open’, untersagen ‘forbid’,
veranstalten ‘arrange’, verbieten ‘forbid’
(10) argumentieren ‘argue’, berichten ‘report’, folgern ‘conclude’, hinzuf¨ugen
‘add’, jammern ‘moan’, klagen ‘complain’, schimpfen ‘rail’, urteilen ‘judge’
(11) basieren ‘be based on’, beruhen ‘be based on’, resultieren ‘result from’,
stammen ‘stem from’
(12) befragen ‘interrogate’, entlassen ‘release’, ermorden ‘assassinate’, erschießen
‘shoot’, festnehmen ‘arrest’, t¨oten ‘kill’, verhaften ‘arrest’
</listItem>
<page confidence="0.99228">
183
</page>
<note confidence="0.424702">
Computational Linguistics Volume 32, Number 2
</note>
<listItem confidence="0.996843714285714">
(13) beziffern ‘amount to’, sch¨atzen ‘estimate’, veranschlagen ‘estimate’
(14) entschuldigen ‘apologize’, freuen ‘be glad’, wundern ‘be surprised’,
¨argern ‘be annoyed’
(15) nachdenken ‘think about’, profitieren ‘profit’, reden ‘talk’, spekulieren
‘speculate’, sprechen ‘talk’, tr¨aumen ‘dream’, verf¨ugen ‘decree’,
verhandeln ‘negotiate’
(16) mangeln ‘lack’, nieseln ‘drizzle’, regnen ‘rain’, schneien ‘snow’
</listItem>
<bodyText confidence="0.997006">
Clusters (1) to (3) are examples where the verbs do not share elements of meaning.
In the overall cluster analysis, such semantically incoherent clusters tend to be rather
large, that is, with more than 15–20 verb members. Clusters (4) to (7) are examples
of clusters where some of the verbs show overlap in meaning, but also contain con-
siderable noise. Cluster (4) mainly contains verbs of buying and selling, cluster (5)
contains verbs of wishing, cluster (6) contains verbs of expressing approval, and cluster
(7) contains verbs of quantum change. Clusters (8) to (16) are examples of clusters where
most or all verbs show a strong similarity in their semantic concept. Cluster (8) contains
verbs expressing a propositional attitude; the underlined verbs, in addition, indicate an
emotion. The only unmarked verb weißen can be explained, since some of its inflected
forms are ambiguous with respect to their base verb: either weißen or wissen, a verb
that belongs to the Aspect verb class. The verbs in cluster (9) describe a scene where
somebody or some situation makes something possible (in the positive or negative
sense); the only exception verb is veranstalten. The verbs in cluster (10) are connected
more loosely, all referring to a verbal discussion, with the underlined verbs denoting a
negative, complaining way of utterance. In cluster (11) all verbs refer to a basis, in cluster
(12) the verbs describe the process from arresting to releasing a suspect, and cluster (13)
contains verbs of estimating an amount of money. In cluster (14), all verbs except for
entschuldigen refer to an emotional state (with some origin for the emotion). The verbs
in cluster (15) except for profitieren all indicate thought (with or without talking) about
a certain matter. Finally in cluster (16), we can recognize the same weather verb cluster
as in the previously discussed small-scale cluster analyses.
We experimented with two variations in the clustering setup: (1) For the selection
of the verb data, we considered a random choice of German verbs in approximately
the same magnitude of number of verbs (900 verbs plus the preliminary verb set),
but without any restriction on the verb frequency. The clustering results are—both on
the basis of the evaluation and on the basis of a manual inspection of the resulting
clusters—much worse than in the preceding cluster analysis, since the large number of
low-frequency verbs destroys the clustering. (2) The number of target clusters was set
to 300 instead of 100, that is, the average number of verbs per cluster was 2.94 instead
of 8.83. The resulting clusters are numerically slightly worse than in the preceding
cluster analysis, but easier for inspection and therefore a preferred basis for a large-
scale resource. Several of the large, semantically incoherent clusters are split into smaller
and more coherent clusters, and the formerly coherent clusters often preserved their
constitution. To present one example, the following cluster from the 100-cluster analysis
anzeigen ‘announce’, aufkl¨aren ‘clarify’, beeindrucken ‘impress’, befreien ‘free’,
begeistern ‘inspire’, beruhigen ‘calm down’, entt¨auschen ‘disappoint’, retten
‘save’, sch¨utzen ‘protect’, st¨oren ‘disturb’, ¨uberraschen ‘surprise’, ¨uberzeugen
‘persuade’
</bodyText>
<page confidence="0.995564">
184
</page>
<note confidence="0.770345">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<bodyText confidence="0.51333">
is split into the following four clusters from the 300-cluster analysis:
</bodyText>
<listItem confidence="0.989909833333333">
(a) anzeigen ‘announce’, aufkl¨aren ‘clarify’
(b) beeindrucken ‘impress’, entt¨auschen ‘disappoint’, ¨uberraschen ‘surprise’,
¨uberzeugen ‘persuade’
(c) befreien ‘free’, beruhigen ‘calm down’, retten ‘save’, sch¨utzen ‘protect’,
st¨oren ‘disturb’
(d) begeistern
</listItem>
<bodyText confidence="0.999856928571429">
where cluster (a) shows a loose semantic coherence of declaration, the verbs in cluster
(b) are semantically very similar and describe an emotional impact of somebody or a
situation on a person, and the verbs in cluster (c) show a protective (and the negation:
nonprotective) influence of one person towards another.
Summarizing, the large-scale clustering experiment results in a mixture of semanti-
cally coherent and incoherent verb classes. Semantically incoherent verb classes and
clustering mistakes need to be split into finer and more coherent clusters, or to be
filtered from the classification. Semantically coherent verb classes need little manual
correction as a lexical resource. Interestingly, the coherence in verb classes refers to
different criteria on meaning coherence, such as synonymy (e.g., reduzieren ‘reduce’ and
verringern ‘decrease’), antonymy (e.g., reduzieren ‘reduce’ and erh¨ohen ‘raise’), situational
overlap (e.g., emotional state containing freuen ‘be glad’ and ¨argern ‘be annoyed’), and
participation in a common process/script (e.g., bestellen ‘order’, kaufen ‘buy’, verkaufen
‘sell’, and abholen ‘pick up’).
</bodyText>
<sectionHeader confidence="0.999519" genericHeader="method">
5. Related Work
</sectionHeader>
<bodyText confidence="0.999944391304348">
The following paragraphs describe related classification and clustering experiments on
the automatic induction of verb classes. The classifications refer to different class crite-
ria, for example, aspectual properties (Siegel and McKeown 2000), syntactic categories
(Merlo and Stevenson 2001; Merlo et al. 2002; Tsang, Stevenson, and Merlo 2002), and—
most similar to my approach—semantic categories (Schulte im Walde 2000; Joanis 2002).
The soft clustering approaches indicate how we might extend our hard clustering to
verb ambiguity, now that we have determined the relevant set of verb features.
Siegel and McKeown (2000) used three supervised and one unsupervised machine-
learning algorithm to perform an automatic aspectual classification of English verbs.
(1) For the supervised classification, 97,973 parsed sentences from medical discharge
summaries were used to extract frequencies for verbs on 14 linguistic indicators, such
as manner adverb, duration in PP, past tense, and perfect tense. Logistic regression,
decision tree induction, and genetic programming were applied to the verb data to
distinguish states and events. Comparing the ability of the learning methods to combine
the linguistic indicators was claimed to be difficult, as they rank differently depending
on the classification task and evaluation criteria. Decision trees achieved an accuracy
of 93.9%, as compared to the uninformed baseline of 83.8%. (2) For the unsupervised
clustering, 14,038 distinct verb–object pairs of varying frequencies were extracted from
75,289 parsed novel sentences. A random partition of the set of verbs was improved by
a hill-climbing method, which improved the partition by moving a verb to the cluster
that decreases the sum of distances most. For a small set of 56 verbs whose frequency
in the verb–object pairs was larger than 50, Siegel and McKeown (2000) claimed on
the basis of an evaluation of 19 verbs that their clustering algorithm discriminated
</bodyText>
<page confidence="0.99501">
185
</page>
<note confidence="0.58969">
Computational Linguistics Volume 32, Number 2
</note>
<bodyText confidence="0.99936536">
event verbs from stative verbs. Overall, they performed a comparably simpler task than
presented in this article, since the aspectual class criteria can be defined more objectively
and more clearly than semantic criteria based on situational similarity. Their choice
of features delimited their class criteria well, and they were able to achieve excellent
results.
In previous work on English, Schulte im Walde (2000) clustered 153 verbs into 30
verb classes taken from Levin (1993), using unsupervised hierarchical clustering. The
verbs were described by distributions over subcategorization frames as extracted from
maximum-probability parses using a robust statistical parser, and completed by assign-
ing WordNet classes as selectional preferences to the frame arguments. Using Levin’s
verb classification as a basis for evaluation, 61% of the verbs were classified correctly
into semantic classes. The clustering was most successful when utilizing syntactic sub-
categorization frames enriched with PP information; selectional preferences decreased
the performance of the clustering approach. The detailed encoding and therefore sparse
data made the clustering worse with the selectional preference information.
Merlo and Stevenson (2001) presented an automatic classification of three types of
English intransitive verbs, based on argument structure and crucially involving the-
matic relations. They selected 60 verbs with 20 verbs from each verb class, comprising
unergatives, unaccusatives, and object-drop verbs. The verbs in each verb class show
similarities with respect to their argument structure, in that they all can be used both as
transitives and intransitives. Therefore, argument structure alone does not distinguish
the classes, and subcategorization information is refined by thematic relations. Merlo
and Stevenson defined verb features based on linguistic heuristics that describe the
thematic relations between subject and object in transitive and intransitive verb usage.
The features included heuristics for transitivity, causativity, animacy, and syntactic fea-
tures. For example, the degree of animacy of the subject argument roles was estimated
as the ratio of occurrences of pronouns to all subjects for each verb, based on the
assumption that unaccusatives occur less frequently with an animate subject compared
to unergative and object-drop verbs. Each verb was described by a five-feature vector,
and the vector descriptions were fed into a decision tree algorithm. Compared with
a baseline performance of 33.9%, the decision trees classified the verbs into the three
classes with an accuracy of 69.8%. Further experiments demonstrated the contribution
of the different features within the classification. Compared to the current article, Merlo
and Stevenson (2001) performed a simpler task and classified a smaller number of 60
verbs into only three classes. The features of the verbs were restricted to those that
should capture the basic differences between the verb classes, in line with the idea that
the feature choice depends on the specific properties of the desired verb classes. But
using the same classification methodology for a large-scale experiment with an enlarged
number of verbs and classes faces more problems. For example, Joanis (2002) reported
an extension of their work that used 802 verbs from 14 classes from Levin (1993). He de-
fined an extensive feature space with 219 core features (such as part of speech, auxiliary
frequency, syntactic categories, and animacy as above) and 1,140 selectional preference
features taken from WordNet. As in Schulte im Walde (2000), the selectional preferences
did not improve the clustering. In recent work, Stevenson and Joanis (2003) compared
their supervised method for verb classification with semisupervised and unsupervised
techniques. In these experiments, they enlarged the number of gold standard English
verb classes to 14 classes related to Levin classes, with a total of 841 verbs. Low-
frequency and ambiguous verbs were excluded from the classes. They found that a
semisupervised approach where the classifier was trained with five seed verbs from
each verb class outperformed both a manual selection of features and the unsupervised
</bodyText>
<page confidence="0.995703">
186
</page>
<note confidence="0.827313">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<bodyText confidence="0.99962258974359">
approach of Dash, Liu, and Yao (1997), which used an entropy measure to organize data
into a multidimensional space.
The classification methodology from Merlo and Stevenson (2001) was applied to
multilinguality by Merlo et al. (2002) and Tsang, Stevenson, and Merlo (2002). Merlo
et al. (2002) showed that the classification paradigm is applicable in languages other
than English by using the same features as defined by Merlo and Stevenson (2001) for
the respective classification of 59 Italian verbs empirically based on the Parole corpus.
The resulting accuracy is 86.4%. In addition, they used the content of Chinese verb
features to refine the English verb classification, explained in more detail by Tsang,
Stevenson, and Merlo (2002). The English verbs were manually translated into Chinese
and given part-of-speech tag features, passive particles, causative particles, and sublex-
ical morphemic properties. Verb tags and particles in Chinese are overt expressions of
semantic information that is not expressed as clearly in English, and the multilingual
set of features outperformed either set of monolingual features, yielding an accuracy
of 83.5%.
Pereira, Tishby, and Lee (1993) describe a hierarchical soft clustering method that
clusters words according to their distribution in particular syntactic contexts. They
used an application of their method to nouns appearing as direct objects of verbs.
The clustering result was a hierarchy of noun clusters, where every noun belongs to
every cluster with a membership probability. The initial data for the clustering process
were frequencies of verb–noun pairs in a direct object relationship, as extracted from
parsed sentences from the Associated Press news wire corpus. On the basis of the
conditional verb–noun probabilities, the similarity of the distributions was determined
by the Kullback–Leibler divergence. The EM algorithm (Baum 1972) was used to learn
the hidden cluster membership probabilities, and deterministic annealing performed
the divisive hierarchical clustering. The resulting class-based model can be utilized for
estimating information for unseen events (cf. Dagan, Lee, and Pereira 1999).
Rooth et al. (1999) produced soft semantic clusters for English that represent a clas-
sification on verbs as well as on nouns. They gathered distributional data for verb–noun
pairs in specific grammatical relations from the British National Corpus. The extraction
was based on a lexicalized probabilistic context-free grammar (Carroll and Rooth 1998)
and contained the subject and object nouns for all intransitive and transitive verbs in the
parses—a total of 608,850 verb–noun types. Conditioning of the verbs and the nouns on
each other was done through hidden classes, and the joint probabilities of classes, verbs,
and nouns were trained by the EM algorithm. The resulting model defined conditional
membership probabilities for each verb and noun in each class; for example, the class of
communicative action contains the most probable verbs ask, nod, think, shape, smile and
the most probable nouns man, Ruth, Corbett, doctor, woman. The semantic classes were
utilized for the induction of a semantically annotated verb lexicon.
</bodyText>
<sectionHeader confidence="0.937947" genericHeader="method">
6. Conclusion and Outlook
</sectionHeader>
<bodyText confidence="0.9972015">
This article presented a clustering methodology for German verbs whose results agreed
with a manual classification in many respects and should prove useful as automatic
basis for a large-scale clustering. Without a doubt the cluster analysis needs manual
correction and completion, but represents a plausible foundation. Key issues of the clus-
tering methodology concern linguistic criteria on the one hand, and technical criteria on
the other hand.
Linguistic Criteria: The strategy of utilizing subcategorization frames, prepositional
information, and selectional preferences to define the verb features seems promising,
</bodyText>
<page confidence="0.989441">
187
</page>
<note confidence="0.598726">
Computational Linguistics Volume 32, Number 2
</note>
<bodyText confidence="0.99996434">
since the experiments illustrated a relation between the induced verb behavior and
the membership of the semantic verb classes. In addition, each level of representation
generated a positive effect on the clustering and improved upon the less informative
level. The experiments presented evidence for a linguistic limit on the usefulness of the
verb features: The meaning of verbs comprises both (1) properties that are general for
the respective verb classes and (2) idiosyncratic properties that distinguish the verbs
from each other. As long as we define the verbs by those properties that represent the
common parts of the verb classes, a clustering can succeed. But by stepwise refining
the verb description and including lexical idiosyncrasy, emphasis on the common prop-
erties vanishes. From the theoretical point of view, the distinction between common
and idiosyncratic features is obvious. But from the practical point of view, feature
choice then depends on the definition of the verb classes, and this definition might vary
according to the conceptual level and also according to the kind of semantic coherence
captured by the class. So far, we have concentrated on synonymy, but the large-scale
experiment, in particular, discovered additional semantic relations within a verb class,
such as participation in a process/script. However, the investigated feature combination
within this article seems to be a useful starting point for verb description.
Technical Criteria: We investigated the relationship between clustering idea, cluster-
ing parameters, and clustering result in order to develop a clustering methodology that
is suitable for the demands of natural language. The clustering initialization played an
important role: k-means needed compact, similarly-sized clusters in order to achieve a
linguistically meaningful classification. The linguistically most successful initial clus-
ters were therefore based on hierarchical clustering with complete linkage or Ward’s
method, as the resulting clusters are comparable in size and correspond to compact
cluster shapes. The hierarchical clustering achieved more similar clustering outputs
than k-means, which is due to the similarity of the clustering methods with respect to
the common clustering criterion of optimizing the sum of distances between verbs and
cluster centroids. The similarity measure used in the clustering experiments proved to
be of secondary importance, since the differences in clustering due to varying the mea-
sure were negligible. For larger object and feature sets, Kullback–Leibler variants tended
to outperform other measures, confirming language-based results on distributional
similarity (Lee 2001). Both frequencies and probabilities represented a useful basis for
the verb distributions. The number of clusters played a role concerning the magnitude
of numbers: Inducing fine-grained clusters as given in the manual classification proved
to be an ambitious goal because the feature distinction for the classes was also fine-
grained. Inducing coarse clusters provided a coarse classification that was subject to
less noise and easier to manually correct. The “optimal” number of clusters is always a
compromise and depends on the purpose of the classes, for example, as a fine-grained
lexical resource, or for an NLP application. In the latter case, the optimal number
should be determined by automatic means, that is, by trying different magnitudes
of cluster numbers, because the level of generalization depends on the purpose for
the abstraction.
There are various directions for future research. (1) The manual definition of the
German semantic verb classes will be extended in order to include a greater number
and a larger variety of verb classes. An extended classification would be useful as a
gold standard for further clustering experiments, and more generally as a resource for
NLP applications. (2) Low-frequency verbs require a specific handling in the clustering
procedure: Both the small-scale and the large-scale experiments showed that the low-
frequency verbs have a negative impact on the cluster coherence. An alternative model
for the low-frequency verbs might, for example, first take out of the cluster analysis
</bodyText>
<page confidence="0.994934">
188
</page>
<note confidence="0.815769">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<bodyText confidence="0.999968236842105">
those verbs below a certain frequency cutoff, and then assign the left-out verbs to the
nearest clusters. The cluster assignment should also be special, for example, using verb
features restricted to the reliable features, that is, above a certain frequency threshold.
For example, if we consider the D2 features of the low-frequency verb ekeln ‘disgust’
(frequency: 31) with a minimum feature frequency of 2, we get a strong overlap with the
distinguishing features of the verb f¨urchten ‘fear’. Future work will address these issues.
(3) Possible features for describing German verbs will include any kind of information
that helps to classify the verbs in a semantically appropriate way. Within this article,
we concentrated on defining the verb features with respect to alternation behavior.
Other features that are relevant for describing the behavior of verbs are their auxiliary
selection and adverbial combinations. In addition, if we try to address additional types
of semantic verb relations such as script-based relations, we will need to extend our
features. For example, Schulte im Walde and Melinger (2005) recently showed that
nouns in co-occurrence windows of verbs contribute to verb descriptions by encoding
scene information, rather than intrasentential functions. They proposed the integration
of window-based approaches into function-based approaches, a combination that has
not yet been applied. (4) Variations in the existing feature description are especially
relevant for the choice of selectional preferences. The experiment results demonstrated
that the 15 conceptual GermaNet top levels are not sufficient for all verbs. For example,
the verbs t¨oten and unterrichten require a finer version of selectional preferences in order
to be distinguished. It is worthwhile either to find a more appropriate level of selectional
preferences in WordNet or to apply a more sophisticated approach towards selectional
preferences such as that of Li and Abe (1998), in order to determine a more flexible
choice of selectional preferences. (5) With respect to a large-scale classification of verbs,
it will be interesting to apply classification techniques to the verb data. This would
require more data manually labeled with classes in order to train a classifier. But the
resulting classifier might abstract better than k-means over the different requirements
of the verb classes with respect to the feature description. (6) As an extension of the
existing clustering, a soft clustering algorithm will be applied to the German verbs.
Soft clustering enables us to assign verbs to multiple clusters and therefore address
the phenomenon of verb ambiguity. These clustering outcomes should be even more
useful for discovering new verb meaning components and semantically related classes,
compared with the hard clustering technique. (7) The verb clusters as resulting from
the cluster analysis will be used within an NLP application in order to prove the
usefulness of the clusters. For example, replacing verbs in a language model by the
respective verb classes might improve the language model’s robustness and accuracy,
as the class information provides more stable syntactic and semantic information than
the individual verbs.
</bodyText>
<sectionHeader confidence="0.987356" genericHeader="method">
Appendix A: Subcategorization Frame Types
</sectionHeader>
<bodyText confidence="0.999972444444444">
The syntactic part of the German verb behavior is captured by 38 subcategorization
frame types. The frames comprise maximally three arguments. Possible arguments
are nominative (n), dative (d) and accusative (a) noun phrases, reflexive pronouns
(r), prepositional phrases (p), expletive es (x), subordinated non-finite clauses (i), sub-
ordinated finite clauses (s-2 for verb second clauses, s-dass for dass-clauses, s-ob for
ob-clauses, s-w for indirect wh-questions), and copula constructions (k). The resulting
frame types are listed in Table A.1, accompanied by annotated verb–second example
clauses. The German examples are provided with English glosses; in cases where the
glosses are difficult to understand, an English translation is added.
</bodyText>
<page confidence="0.992097">
189
</page>
<figure confidence="0.921707598726114">
Computational Linguistics Volume 32, Number 2
Table A1
Subcategorization frame types.
Frame Type Example
n Natalien schwimmt.
Natalie swims
na Hansn sieht seine Freundina.
Hans sees his girlfriend
nd Ern glaubt den Leutend nicht.
He believes the people not
np Die Autofahrern achten besonders auf Kinderp.
The drivers watch out especially for children
nad Annan verspricht ihrem Vaterd ein tolles Geschenka.
Anna promises her father a great present
den Dieba
the thief
hindert
keeps
dem Publikumd
the audience
dankt
thanks
am Stehlenp.
from stealing
f¨ur sein Verst¨andnisp.
for their understanding
nap Die Verk¨auferinn
The saleslady
ndp Der Moderatorn
The moderator
ni Mein Freundn versucht immer, p¨unktlich zu kommeni.
My friend tries always in time to arrive
‘My friend always tries to arrive in time.’
nai Ern h¨ort seine Muttera ein Lied tr¨allerni.
He hears his mother a song sing
‘He hears his mother singing a song.’
ndi Helenen
Helene
verspricht
promises
ihrem Großvaterd
her grandfather
ihn bald zu besucheni.
him soon to visit
nr Die Kindern f¨urchten sichr.
The children are afraid themselves
nar Der Unternehmern
The businessman
erhofft
hopes
sichr
himself
schnellen Fortschritta.
quick progress
ndr Sien schließt sichr nach 10 Jahren wieder der Kirched an.
She associates herself after 10 years again the church with
npr Der Pastorn hat sichr als der Kirche w¨urdigp erwiesen.
The pastor has himself to the church worthy proven
nir Die alte Fraun stellt sichr vor, den Preis zu gewinneni.
The old women imagines herself the price to win
x Esx blitzt.
It lightenings
xa Esx gibt
There exist
viele B¨uchera.
many books
xd Esx graut mird.
It terrifies me
190
Schulte im Walde Induction of German Semantic Verb Classes
Table A1
(cont.)
Frame Type Example
xp Esx geht um einen tollen Preis f¨ur mein Sofap.
It is about a great price for my sofa
xr Esx rechnet sichr.
It calculates itself
‘It is worth it.’
xs-dass Esx heißt, dass Thomas sehr schlau ists−dass.
It says, that Thomas very intelligent is
hat
has
gesagt,
said,
ns-2 Der Professorn
The professor
er halte bald einen Vortrags−2.
he gives soon a talk
nas-2 Der Chefn schnauzt ihna an, er sei ein Idiots−2.
The chef bawls him out, he is an idiot
nds-2 Ern sagt seiner Freundind, sie sei zu krank zum Arbeitens−2.
He tells his girlfriend, she is too ill to work
hat
has
schon
already
angek¨undigt,
announced,
dass er bald kommts−dass.
that it soon arrives
ns-dass Der Wintern
Winter
nrs-2 Der Kleinen
The boy
sichr,
himself,
das M¨adchen bliebe bei ihms−2.
the girl stays with him
w
wishes
nas-dass Der Vatern
The father
fordert
requests
seine Tochtera
his daughter
auf, dass sie verreists−dass.
that she travels
nds-dass Ern sagt seiner Geliebtend, dass er verheiratet ists−dass
He tells his lover, that he married is
nrs-dass Der Kleinen
The boy
sichr,
himself,
dass seine Mutter bleibts−dass.
that his mother stays
w
wishes
ns-ob Der Professorn hat gefragt, ob die neue Forscherin interessant seis−ob
The professor has asked, whether the new researcher interesting is
nas-ob Antonn fragt seine Fraua, ob sie ihn liebts−ob.
Anton asks his wife, whether she him loves
nds-ob Der Nachbarn ruft der Fraud zu, ob sie verreists−ob
The neighbor shouts the woman whether she travels
nrs-ob Der Alten wird sichr erinnern, ob das M¨adchen dort wars−ob.
The old man will himself remember, whether the girl there was
ns-w Der Kleinen hat gefragt, wann die Tante endlich ankommts−w
The boy has asked, when the aunt finally arrives
nas-w Der Mannn fragt seine Freundina, warum sie ihn liebts−w.
The man asks his girlfriend, why she him loves
nds-w Der Vatern
The father
seiner Tochterd
his daughter
nicht, wer zu Besuch kommts−w.
not, who for a visit comes
¨at
verr
tells
nrs-w Das M¨adchenn erinnert sichr, wer zu Besuch kommts−w.
The girl remembers herself, who for a visit comes
k Der neue Nachbark ist ein ziemlicher Idiot.
The new neighbor is a complete idiot
¨unscht
¨unscht
191
Computational Linguistics Volume 32, Number 2
</figure>
<sectionHeader confidence="0.981315" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.589626307692308">
The work reported here was performed
while the author was a member of the
DFG-funded PhD program “Graduierten-
kolleg” Sprachliche Repr¨asentationen und ihre
Interpretation at the Institute for Natural
Language Processing (IMS), University of
Stuttgart, Germany. Many thanks to Helmut
Schmid, Stefan Evert, Frank Keller, Scott
McDonald, Alissa Melinger, Chris Brew,
Hinrich Sch¨utze, Jonas Kuhn, and the two
anonymous reviewers for their valuable
comments on previous versions of this
article.
</bodyText>
<sectionHeader confidence="0.972236" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999795262135922">
Baker, Collin F., Charles J. Fillmore, and
John B. Lowe. 1998. The Berkeley
FrameNet Project. In Proceedings of the 17th
International Conference on Computational
Linguistics and the 36th Annual Meeting of
the Association for Computational Linguistics,
pages 86–90, Montreal, Canada.
Baum, Leonard E. 1972. An inequality and
associated maximization technique in
statistical estimation for probabilistic
functions of Markov processes. Inequalities,
III:1–8.
Carroll, Glenn and Mats Rooth. 1998. Valence
induction with a head-lexicalized PCFG.
In Proceedings of the 3rd Conference on
Empirical Methods in Natural Language
Processing, Granada, Spain.
Charniak, Eugene. 1997. Statistical parsing
with a context-free grammar and word
statistics. In Proceedings of the 14th National
Conference on Artificial Intelligence,
Menlo Park, CA.
Chen, Stanley and Joshua Goodman. 1998.
An empirical study of smoothing
techniques for language modeling.
Technical Report TR-10-98, Center for
Research in Computing Technology,
Harvard University.
Cover, Thomas M. and Joy A. Thomas. 1991.
Elements of Information Theory.
Telecommunications. John Wiley &amp; Sons,
New York.
Dagan, Ido, Lillian Lee, and Fernando
Pereira. 1999. Similarity-based models of
word cooccurrence probabilities. Machine
Learning, 34(1–3):43–69. Special Issue on
Natural Language Learning.
Dash, Manoranjan, Hua Liu, and Jun Yao.
1997. Dimensionality reduction for
unsupervised data. In Proceedings of the
9th International Conference on Tools with
Artificial Intelligence, pages 532–539,
Newport Beach, CA.
Dorr, Bonnie J. 1997. Large-scale dictionary
construction for foreign language tutoring
and interlingual machine translation.
Machine Translation, 12(4):271–322.
Dorr, Bonnie J. and Doug Jones. 1996.
Role of word sense disambiguation in
lexical acquisition: Predicting semantics
from syntactic cues. In Proceedings
of the 16th International Conference on
Computational Linguistics, pages 322–327,
Copenhagen, Denmark.
Erk, Katrin, Andrea Kowalski, and
Manfred Pinkal. 2003. A corpus resource
for lexical semantics. In Proceedings
of the 5th International Workshop on
Computational Semantics, Tilburg, The
Netherlands.
Fellbaum, Christiane, editor. 1998.
WordNet—An Electronic Lexical Database.
Language, Speech, and Communication.
MIT Press, Cambridge, MA.
Fillmore, Charles J. 1977. Scenes-and-frames
semantics. In Antonio Zampolli, editor,
Linguistic Structures Processing, volume 59
of Fundamental Studies in Computer Science.
North Holland Publishing, Amsterdam.
Fillmore, Charles J. 1982. Frame Semantics.
In Linguistics in the Morning Calm,
pages 111–137, Hansin, Seoul, Korea.
Fontenelle, Thierry, editor. 2003. FrameNet
and Frame Semantics, volume 16(3) of
International Journal of Lexicography. Oxford
University Press.
Forgy, Edward W. 1965. Cluster analysis of
multivariate data: Efficiency vs.
interpretability of classifications.
Biometrics, 21:768–780.
Hamp, Birgit and Helmut Feldweg.
1997. GermaNet—A lexical-semantic
Net for German. In Proceedings of the
ACL Workshop on Automatic Information
Extraction and Building Lexical Semantic
Resources for NLP Applications, Madrid,
Spain.
Harris, Zellig. 1968. Distributional structure.
In Jerold J. Katz, editor, The Philosophy
of Linguistics, Oxford Readings in
Philosophy. Oxford University Press,
pages 26–47.
Hatzivassiloglou, Vasileios and Kathleen R.
McKeown. 1993. Towards the automatic
identificaton of adjectival scales:
Clustering adjectives according to
meaning. In Proceedings of the 31st Annual
Meeting of the Association
for Computational Linguistics,
pages 172–182, Columbus.
Hubert, Lawrence and Phipps Arabie.1985.
Comparing partitions. Journal of
Classification, 2:193–218.
</reference>
<page confidence="0.970705">
192
</page>
<note confidence="0.610289">
Schulte im Walde Induction of German Semantic Verb Classes
</note>
<reference confidence="0.99942893220339">
Joanis, Eric. 2002. Automatic verb
classification using a general feature space.
Master’s thesis, Department of Computer
Science, University of Toronto.
Kaufman, Leonard and Peter J. Rousseeuw.
1990. Finding Groups in Data—An
Introduction to Cluster Analysis. Probability
and Mathematical Statistics. John Wiley &amp;
Sons, Inc., New York.
Klavans, Judith L. and Min-Yen Kan. 1998.
The role of verbs in document analysis. In
Proceedings of the 17th International
Conference on Computational Linguistics,
pages 680–686, Montreal, Canada.
Korhonen, Anna. 2002. Subcategorization
Acquisition. Ph.D. thesis, University of
Cambridge, Computer Laboratory.
Technical Report UCAM-CL-TR-530.
Korhonen, Anna, Yuval Krymolowski, and
Zvika Marx. 2003. Clustering polysemic
subcategorization frame distributions
semantically. In Proceedings of the 41st
Annual Meeting of the Association for
Computational Linguistics, pages 64–71,
Sapporo, Japan.
Kunze, Claudia. 2000. Extension and use of
GermaNet, a lexical-semantic database. In
Proceedings of the 2nd International Conference
on Language Resources and Evaluation,
pages 999–1002, Athens, Greece.
Lapata, Maria. 1999. Acquiring lexical
generalizations from corpora: A case study
for diathesis alternations. In Proceedings of
the 37th Annual Meeting of the Association for
Computational Linguistics, pages 397–404,
College Park, MD.
Lapata, Mirella and Chris Brew. 2004. Verb
class disambiguation using informative
priors. Computational Linguistics,
30(1):45–73.
Lee, Lillian. 2001. On the effectiveness of the
skew divergence for statistical language
analysis. In Artificial Intelligence and
Statistics, pages 65–72.
Levin, Beth. 1993. English Verb Classes and
Alternations. The University of Chicago
Press.
Li, Hang and Naoki Abe. 1998. Generalizing
case frames using a thesaurus and the
MDL principle. Computational Linguistics,
24(2):217–244.
McCarthy, Diana. 2001. Lexical Acquisition at
the Syntax-Semantics Interface: Diathesis
Alternations, Subcategorization Frames and
Selectional Preferences. Ph.D. thesis,
University of Sussex.
Merlo, Paola and Suzanne Stevenson. 2001.
Automatic verb classification based on
statistical distributions of argument
structure. Computational Linguistics,
27(3):373–408.
Merlo, Paola, Suzanne Stevenson, Vivian
Tsang, and Gianluca Allaria. 2002. A
multilingual paradigm for automatic
verb classification. In Proceedings of the 40th
Annual Meeting of the Association for
Computational Linguistics,
pages 207–214, Philadelphia, PA.
Miller, George A., Richard Beckwith,
Christiane Fellbaum, Derek Gross, and
Katherine J. Miller. 1990. Introduction to
Wordnet: An on-line lexical database.
International Journal of Lexicography,
3(4):235–244.
Palmer, Martha, Dan Gildea, and Paul
Kingsbury. 2005. The Proposition Bank:
An annotated corpus of semantic roles.
Computational Linguistics, 31(1):71–106.
Pereira, Fernando, Naftali Tishby, and Lillian
Lee. 1993. Distributional clustering of
English words. In Proceedings of the 31st
Annual Meeting of the Association
for Computational Linguistics,
pages 183–190, Columbus, OH.
Pinker, Steven. 1989. Learnability and
Cognition: The Acquisition of Argument
Structure. MIT Press, Cambridge, MA.
Rooth, Mats, Stefan Riezler, Detlef Prescher,
Glenn Carroll, and Franz Beil. 1999.
Inducing a semantically annotated
lexicon via EM-based clustering. In
Proceedings of the 37th Annual Meeting
of the Association for Computational
Linguistics, Maryland, MD.
Saint-Dizier, Patrick. 1998. Alternations
and verb semantic classes for French:
Analysis and class formation. In Patrick
Saint-Dizier, editor, Predicative Forms
in Natural Language and in Lexical
Knowledge Bases. Kluwer Academic
Publishers, Dordrecht.
Schmid, Helmut. 2000. LoPar: Design and
implementation. Arbeitspapiere des
Sonderforschungsbereichs 340 Linguistic
Theory and the Foundations of Computational
Linguistics 149, Institut f¨ur Maschinelle
Sprachverarbeitung, Universit¨at Stuttgart.
Schulte im Walde, Sabine. 2000. Clustering
verbs semantically according to their
alternation behaviour. In Proceedings
of the 18th International Conference
on Computational Linguistics,
pages 747–753, Saarbr¨ucken, Germany.
Schulte im Walde, Sabine. 2002a.
Evaluating verb subcategorisation
frames learned by a German statistical
grammar against manual definitions
in the Duden Dictionary. In Proceedings
</reference>
<page confidence="0.976139">
193
</page>
<reference confidence="0.989962417910448">
Computational Linguistics Volume 32, Number 2
of the 10th EURALEX International Congress,
pages 187–197, Copenhagen, Denmark.
Schulte im Walde, Sabine. 2002b. A
subcategorisation lexicon for German
verbs induced from a lexicalised PCFG. In
Proceedings of the 3rd Conference on Language
Resources and Evaluation, volume IV,
pages 1351–1357, Las Palmas de Gran
Canaria, Spain.
Schulte im Walde, Sabine. 2003a. Experiments
on the automatic induction of German
semantic verb classes. Ph.D. thesis, Institut
f¨ur Maschinelle Sprachverarbeitung,
Universit¨at Stuttgart. Published as AIMS
Report 9(2).
Schulte im Walde, Sabine. 2003b.
Experiments on the choice of features for
learning verb classes. In Proceedings of the
10th Conference of the European Chapter of the
Association for Computational Linguistics,
pages 315–322, Budapest, Hungary.
Schulte im Walde, Sabine and Chris Brew.
2002. Inducing German semantic verb
classes from purely syntactic
subcategorisation information. In
Proceedings of the 40th Annual
Meeting of the Association for Computational
Linguistics, pages 223–230,
Philadelphia, PA.
Schulte im Walde, Sabine and Alissa
Melinger. 2005. Identifying semantic
relations and functional properties of
human verb associations. In Proceedings of
the joint Conference on Human Language
Technology and Empirial Methods in Natural
Language Processing, pages 612–619,
Vancouver, Canada.
Schumacher, Helmut.1986. Verben in Feldern.
de Gruyter, Berlin.
Siegel, Eric V. and Kathleen R. McKeown.
2000. Learning methods to combine
linguistic indicators: Improving aspectual
classification and Revealing Linguistic
Insights. Computational Linguistics,
26(4):595–628.
Stevenson, Suzanne and Eric Joanis. 2003.
Semi-supervised verb class discovery
using noisy features. In Proceedings of the
7th Conference on Natural Language
Learning, pages 71–78, Edmonton, Canada.
Tsang, Vivian, Suzanne Stevenson, and Paola
Merlo. 2002. Crosslinguistic transfer in
automatic verb classification. In
Proceedings of the 19th International
Conference on Computational Linguistics,
pages 1023–1029, Taipei, Taiwan.
V´azquez, Gloria, Ana Fern´andez, Irene
Castell´on, and Maria Antonia Marti. 2000.
Clasificaci´on verbal: Alternancias de di´atesis.
Number 3 in Quaderns de Sintagma.
Universitat de Lleida.
Vossen, Piek. 2004. EuroWordNet: A
multilingual database of autonomous and
language-specific wordnets connected via
an inter-lingual-index. International Journal
of Lexicography, 17(2):161–173.
</reference>
<page confidence="0.998788">
194
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9975405">Experiments on the Automatic Induction of German Semantic Verb Classes</title>
<author confidence="0.650176">Schulte im</author>
<abstract confidence="0.982440878787879">Universit¨at des Saarlandes This article presents clustering experiments on German verbs: A statistical grammar model for German serves as the source for a distributional verb description at the lexical syntax–semantics interface, and the unsupervised clustering algorithm k-means uses the empirical verb properties to perform an automatic induction of verb classes. Various evaluation measures are applied to compare the clustering results to gold standard German semantic verb classes under different criteria. The primary goals of the experiments are (1) to empirically utilize and investigate the well-established relationship between verb meaning and verb behavior within a cluster analysis and (2) to investigate the required technical parameters of a cluster analysis with respect to this specific linguistic task. The clustering methodology is developed on a small-scale verb set and then applied to a larger-scale verb set including 883 German verbs. 1. Motivation Semantic verb classes generalize over verbs according to their semantic properties, that is, they capture large amounts of verb meaning without defining the idiosyncratic details for each verb. The classes refer to a general semantic level, and idiosyncratic lexical semantic properties of the verbs are either added to the class description or underspecified. Examples for semantic verb classes are such as and of Motion with a Vehicle such as Manual definitions of semantic verb classes exist for several languages, the most dominant examples concerning English (Levin 1993; Baker, Fillmore, and Lowe 1998) and Spanish (V´azquez et al. 2000). On the one hand, verb classes reduce redundancy in verb descriptions since they encode the common properties of verbs. On the other hand, verb classes can predict and refine properties of a verb that received insufficient empirical evidence, with reference to verbs in the same class: Under this criterion, a verb classification is especially useful for the pervasive problem of data sparseness in NLP, where little or no knowledge is provided for rare events. For example, the English verb classification by Levin (1993) has been used in NLP applications such as word sense disambiguation (Dorr and Jones 1996), machine translation (Dorr 1997), document classification (Klavans and Kan 1998), and subcategorization acquisition (Korhonen 2002). To my knowledge, no comparable German verb classification is available so far; therefore, such a classification would provide a principled basis for filling a gap in available lexical knowledge. of Computational Linguistics, Saarbr¨ucken, Germany. E-mail: schulte@coli.uni-sb.de.</abstract>
<note confidence="0.95531325">Submission received:1 September 2003; revised submission received: 5 September 2005; accepted for publication: 10 November 2005. © 2006 Association for Computational Linguistics Computational Linguistics Volume 32, Number 2</note>
<abstract confidence="0.951332612244898">How can we obtain a semantic classification of verbs while avoiding tedious manual definitions of the verbs and the classes? Few resources are semantically annotated provide semantic information off-the-shelf such as Fillmore, Lowe 1998; Fontenelle 2003) and Gildea, and Kingsbury 2005). Instead, the automatic construction of semantic classes typically benefits from a longstanding linguistic hypothesis that asserts a tight connection between the lexical meaning of a verb and its behavior: To a certain extent, the lexical meaning of a verb determines its behavior, particularly with respect to the choice of its arguments (Pinker 1989; Levin 1993; Dorr and Jones 1996; Siegel and McKeown 2000; Merlo and Stevenson 2001; Schulte im Walde and Brew 2002; Lapata and Brew 2004). Even though the meaning–behavior relationship is not perfect, we can make this prediction: If we induce a verb classification on the basis of verb features describing verb behavior, then the resulting behavior classification should agree with a semantic classification to a certain extent (yet to be determined). The aim of this work is to utilize this prediction for the automatic acquisition of German semantic verb classes. The verb behavior itself is commonly captured by the diathesis alternation of verbs: alternative constructions at the syntax–semantics interface that express the same or a similar conceptual idea of a verb (Lapata 1999; Schulte im Walde 2000; McCarthy 2001; Merlo and Stevenson 2001; Joanis 2002). Consider example (1), where the most common of the of Motion with a Vehicle are illustrated. The conceptual participants are a vehicle, a driver, a passenger, and a direction. In (a), the vehicle is expressed as the subject in a transitive verb construction, with a prepositional phrase indicating the direction. In (b), the driver is expressed as the subject in a transitive verb construction, with a prepositional phrase indicating the direction. In (c), the driver is expressed as the subject in a transitive verb construction, with an accusative noun phrase indicating the vehicle. In (d), the driver is expressed as the subject in a ditransitive verb construction, with an accusative noun phrase indicating the passenger, and a prepositional phrase indicating the direction. Even if a certain participant is not realized within an alternation, its contribution might be implicitly defined by the verb. For example, in the German sentence in (a) the driver is not expressed overtly, but we know that there is a driver, and in (b) and (d) the vehicle is not expressed overtly, but we know that there is a vehicle. Verbs in the same semantic class are expected to overlap their alternation behavior to a certain extent. For example, the of Motion with Vehicle alternates between (a) such as in Airbus A380 fliegt nach York Airbus A380 flies to New York’, (b) in marked cases as in ¨altere fliegt nach London older pilot flies to London’, (c) as in Schulze fliegt eine 747 Schulze flies a Boing 747’, and (d) as in Pilot fliegt seine Passagiere nach pilot flies his passengers to Thailand’; the of Motion with a Vehicle alternates between (b) such as in rudert ¨uber den See rows the lake’, (c) such as in rudert das blaue Boot rows the blue boat’, and (d) as in rudert ihren kleinen Bruder ¨uber den See rows her little brother over the lake’. Example 1 (a) Der Wagen f¨ahrt in die Innenstadt. ‘The car drives to the city centre.’ (b) Die Frau f¨ahrt nach Hause. ‘The woman drives home.’ 160 Schulte im Walde Induction of German Semantic Verb Classes (c) Der Filius f¨ahrt einen blauen Ferrari. ‘The son drives a blue Ferrari.’ (d) Der Junge f¨ahrt seinen Vater zum Zug. ‘The boy drives his father to the train.’ We decided to use diathesis alternations as an approach to characterizing verb behavior, and to use the following verb features to stepwise describe diathesis alternations: (1) syntactic structures, which are relevant for capturing argument functions; (2) prepositions, which are relevant to distinguish, for example, directions from locations; and (3) selectional preferences, which concern participant roles. A statistical grammar model serves as the source for an empirical verb description for the three levels at the syntax– semantics interface. Based on the empirical feature description, we then perform a analysis of the German verbs using a standard unsupervised hard clustering technique as proposed by Forgy (1965). The clustering outcome cannot be a perfect semantic verb classification, since the meaning–behavior relationship on which the clustering relies is not perfect, and the clustering method is not perfect for the ambiguous verb data. However, our primary goal is not necessarily to obtain the optimal clustering result, but rather to assess the linguistic and technical conditions that are crucial for a semantic cluster analysis. More specifically, (1) we perform an empirical investigation of the relationship between verb meaning and verb behavior (that is, Can we use the meaning–behavior relationship of verbs to induce verb classes, and to what extent does the meaning–behavior relationship hold in the experiments?), and (2) we investigate which technical parameters are suitable for the natural language task. The resulting clustering methodology can then be applied to a larger-scale verb set. The plan of the article is as follows. Section 2 describes the experimental setup with respect to (1) gold standard verb classes for 168 German verbs, (2) the statistical grammar model that provides empirical lexical information for German verbs at the syntax–semantics interface, and (3) the clustering algorithm and evaluation methods. Section 3 performs preliminary clustering experiments on the German gold standard verbs, and Section 4 presents an application of the clustering technique in a large-scale experiment. Section 5 discusses related work, and Section 6 presents the conclusions and outlook for further work. 2. Experimental Setup 2.1 German Semantic Verb Classes A set of 168 German verbs was manually classified into 43 concise semantic verb classes. The verb class labels refer to the common semantic properties of the verbs in a class at a general conceptual level, and the idiosyncratic lexical semantic properties of the verbs are left underspecified. The German verbs are provided with a coarse translation into English, given here in brackets; we do not attempt to define subtle differences in meaning or usage. The translated verb senses only refer to the respective semantic class; if the verb translations in one class are too similar to distinguish among them, a common translation is given. Even though the classification is primarily based on semantic intuition and not on facts about syntactic behavior, the verbs grouped in one class share certain aspects of their behavior. (Please note that this overlap does not necessarily transfer to the English translations.) This agreement corresponds to the 161 Computational Linguistics Volume 32, Number 2 long-standing linguistic hypothesis that asserts a tight connection between the meaning components of a verb and its behavior (Pinker 1989; Levin 1993). The purpose of the manual classification is to evaluate the reliability and performance of the clustering experiments. The following facts refer to empirically relevant properties of the classification: The class size is between 2 and 7, with an average of 3.9 verbs per class. Eight verbs are ambiguous with respect to class membership and marked by subscripts. The classes include both highand low-frequency verbs in order to exercise the clustering technology in both data-rich and data-poor situations: The corpus frequencies of the verbs range from 8 to 71,604 (within 35 million words of a German newspaper corpus, cf. Section 2.2). The class labels are given on two semantic coarse labels such as of Motion subdivided into finer labels, such as Rotation, Rush, Vehicle, The fine-grained labels are relevant for the clustering experiments, as the numbering indicates. As mentioned before, the classification is primarily based on semantic intuition, not on facts about syntactic behavior. an extreme example, the (23) contains the verb which requires a direct object, together with the verbs folgen, and helfen, which dominantly subcategorize for an indirect object. The classification was checked to ensure lack of bias, so class membership is not disproportionately made up of highfrequency verbs, low-frequency verbs, strongly ambiguous verbs, verbs from specific semantic areas, and so forth. The classification deliberately sets high standards for the automatic induction process: It would be easier (1) to define the verb classes on a purely syntactic basis, since syntactic properties are easier to obtain automatically than semantic features, or (2) to define larger classes of verbs, so that the distinction between the classes is not based on fine-grained verb properties, or (3) to disregard clustering complications such as verb ambiguity and low-frequency verbs. But the overall goal is not to achieve a perfect clustering on the given 168 verbs but to investigate both the potential and the limits of our clustering methodology that combines easily available data with a simple algorithm. The task cannot be solved completely, but we can investigate the bounds. The classification is defined as follows: 1. anfangen, aufh¨oren, beenden, beginnen, enden (start, stop, finish, begin, end) Propositional ahnen, denken, glauben, vermuten, wissen (guess, think, believe, assume, know) • Desire 3. erhoffen, wollen, w¨unschen (hope, want, wish) 4. bed¨urfen, ben¨otigen, brauchen (all: need/require) Transfer of Possession bekommen, erhalten, kriegen (all: receive/obtain) • Transfer of Possession (Giving) 6. geben, leihen, schenken, spenden, stiften, vermachen, ¨uberschreiben (give, borrow, present, donate, donate, bequeath, sign over) 7. bringen, liefern, schicken, zustellen (bring, deliver, send, convey, deliver) 162 Schulte im Walde Induction of German Semantic Verb Classes • Manner of Motion 8. gehen, klettern, kriechen, laufen, rennen, schleichen, wandern (go, climb, creep, walk, run, sneak, wander)</abstract>
<note confidence="0.57414615">9. drehen, rotieren (turn around, rotate) 10. eilen, hasten (both: hurry) 11. fahren, fliegen, rudern, segeln (drive, fly, row, sail) 12. fließen, gleiten, treiben (float, glide, float) • Emotion 13. ¨argern, freuen (be annoyed, be happy) 14. weinen (cry, laugh, cry) 15. ¨angstigen, ekeln, f¨urchten, scheuen (frighten, disgust, fear, be afraid) Facial g¨ahnen, grinsen, l¨acheln, starren (yawn, grin, laugh, smile, stare) 17. empfinden, f¨uhlen, h¨oren, riechen, sehen, wahrnehmen (feel, experience, feel, hear, smell, see, perceive) Manner of fl¨ustern, rufen, schreien (whisper, shout, scream) 19. jammern, klagen, lamentieren (all: wail/moan/ complain) 20. kommunizieren, korrespondieren, reden, sprechen, verhandeln (communicate, correspond, talk, talk, negotiate) • Statement 21. ank¨undigen, bekanntgeben, er¨offnen, verk¨unden (all: announce) 22. anordnen, bestimmen, festlegen (arrange, determine, constitute) 23. versichern, versprechen, zusagen (ensure, promise, promise) 24. bemerken, erkennen, feststellen, realisieren, registrieren (notice, realize, get to know, observe, realize, realize) 25. beschreiben, charakterisieren, interpretieren (describe, characterize, describe, interpret) 26. demonstrieren, pr¨asentieren, veranschaulichen, vorf¨uhren (present, demonstrate, present, illustrate, demonstrate) 27. gr¨ubeln, nachdenken, phantasieren, spekulieren (muse, think about, fantasize, speculate) 28. beharren, insistieren, pochen (all: insist) 29. beibringen, lehren, unterrichten, teach) • Position Bring into legen, setzen, stellen (lay, set, put upright) Be in liegen, sitzen, stehen (lie, sit, stand) 163 Computational Linguistics Volume 32, Number 2 32. bilden, erzeugen, herstellen, hervorbringen, produzieren (all: generate/produce) 33. dekorieren, erneuern, renovieren, reparieren (decorate, renew, renovate, repair) 34. dienen, helfen, unterst¨utzen (serve, follow, help, support) Quantum erh¨ohen, erniedrigen, senken, steigern, vergr¨oßern, verklenern (increase, decrease, decrease, increase, enlarge, diminish) 36. ¨offnen, close) 37. existieren, leben (exist, exist, live) 38. essen, konsumieren, lesen, saufen, trinken (eat, consume, read, booze, drink) 39. eliminieren, entfernen, exekutieren, t¨oten, vernichten (eliminate, delete, execute, kill, destroy) 40. basieren, beruhen, gr¨unden, st¨utzen (all: be based on) 41. folgern, infer) 42. ergeben, erwachsen, resultieren (all: follow/result) 43. blitzen, donnern, d¨ammern, nieseln, regnen, schneien (lightning, thunder, dawn, drizzle, rain, snow)</note>
<abstract confidence="0.987158687872764">The evidence used in the class creation process—including the choice of the verbs—was provided by subjective conceptual knowledge, monolingual and bilingual dictionary entries and corpus searches. Interannotator agreement has therefore not been addressed, but the classes were created in close relation to the English classification by Levin (1993) (as far as the English classes have German counterparts) and agree with the German verb classification by Schumacher (1986), as far as the relevant verbs are covered by his semantic ‘fields’. To overcome the drawback of a subjective class definition, the classification was accompanied by a detailed class description. This characterization is closely related to Fillmore’s scenes-and-frames semantics (Fillmore 1982), as computationally utilized in Fillmore, and Lowe 1998; 2003); there is no reference to the German (Erk, Kowalski, and Pinkal 2003)—as one might expect—just because the German version itself had just started to be developed. The frame-semantic class definition contains a prose scene description, predominant frame participant and modification roles, and frame variants describing the scene. The frame roles have been developed on the basis of a large German newspaper corpus from the 1990s (cf. Section 2.2). They capture the scene description with idiosyncratic participant names and demarcate major and minor roles. Since a scene might be activated by a number of frame embeddings, the predominant frame variants from the corpus are listed, marked with participating roles, and at least one example sentence for each verb utilizing the respective frame is given. The corpus examples are annotated and illustrate the idiosyncratic combinations of lexical verb meaning and conceptual constructions to capture variations in verb sense. Example 2 a verb class description for the class of For further class descrip- 164 Schulte im Walde Induction of German Semantic Verb Classes tions, the reader is referred to Schulte im Walde (2003a, pages 27–103). Verbs allowing a frame variant are marked by “+,” verbs allowing the frame variant only in company of additional adverbial modifier are marked by and verbs not allowing a frame are marked by In the case of ambiguity, frame variants are only given for the senses of the verbs with respect to the class label. The frame variants with their roles marked represent the alternation potential of the verbs. For example, the causative– alternation assumes the syntactic embeddings and indicating that the alternating verbs are realized by a transitive frame type (containing a nominative ‘n’ with role an accusative NP ‘a’ with role and the corresponding frame type (with a nominative NP ‘n’ only, indicating the same role for the transitive accusative). Passivization of a verb–frame combination is indicated by [P]. Appendix 6 lists all possible frame variants with illustrative examples. Note that the corpus examples are given in the old German spelling version, before the spelling reform in 1998. Semantic verb classes have been defined for several languages, for example, as the mentioned lexicographic resource English (Baker, Fillmore, and Lowe 1998; Fontenelle 2003) and German (Erk, Kowalski, and Pinkal 2003); the lexical ontology WordNet for English (Miller et al. 1990; Fellbaum 1998); (Vossen 2004) for Dutch, Italian, Spanish, French, German, Czech, and Estonian, and languages as listed in in the World WordNet Association, www.globalwordnet.org); syntax–semantics based verb classes for English (Levin 1993), Spanish (V´azquez et al. 2000), and French (Saint-Dizier 1998). Example 2 aufh¨oren, beenden, beginnen, enden Scene: event] begins or ends, either internally caused or externally caused by initiator]. The event may be specified with respect to experiencer], or result]. Roles:I(nitiator), E(vent) Roles:T(emporal), L(ocal), (e)X(periencer), R(esult) Frame Participating Verbs and Corpus Examples anfangen, aufh¨oren, beginnen / / muß must Nun Now aber though begin Dialog] the dialog Morden] the killing stop Erst First muß must Gottesdienst] The service begins Schuljahr] Februar]. The school year begins in February die Fl¨uchtlinge] For the fugitives beginnt begins nun now Wettlauf gegen die Zeit]. a race against time Ferien] einem großen Fest]. The vacations end with a big party ... guten The art of typesetting ... ends with a good book Informationstag] The information day ... endet finishes 14 Uhr]. at 2pm ... 165 diesem ungerechten Krieg] muß sofort With this unjust war must immediately be d¨urfe der Aufl¨osung] nicht Before must with the closing not be started 2.2 Empirical Distributions for German Verbs We developed, implemented, and trained a statistical grammar model for German that is based on the framework of head-lexicalized, probabilistic, context-free grammars. The idea originates from Charniak (1997), with this work using an implementation by Schmid (2000) for a training corpus of 35 million words from a collection of large newspaper corpora from the 1990s, including Law and Com- The statistical grammar model provides empirical lexical information, specializing in but not restricted to the subcategorization behavior of verbs. Details of 166 den Umbauarbeiten] k¨onnte with the reconstruction work could And be begun Computational Linguistics Volume 32, Number 2 ... he daß that ... sollte should I und and noch yet aufh¨oren stop Vielleicht Maybe studieren. study we Sache] the thing have started After Polizei] The police Gewaltt¨atigkeiten]. the violence beendete stopped anfangen, aufh¨oren / beginnen, enden in time we begins einfach just stop nicht not anfangen, beenden, beginnen / enden dem Abi] After the Abitur beginnt begins Jens Frankfurt] in Frankfurt Lehre] ... his apprenticeship ... Jetzt Now k¨onnen can dem Bescheid] before the notification is started ... ... If Arbeiten] the work W¨ahrend Senna] While for Senna ... ... ... ehe before is begun milit¨arische Aktion] a military action habe I have daß that ... ... trinken]. to drink Alkoholiker] the alcoholic stops anfangen, aufh¨oren, beginnen / enden Rennen] the race ... was finished ... started zu schneidern]. shirts to make anfangen, beenden, beginnen / ¬aufh¨oren, enden men zu tanzen] tango to dance dieser Stimmung In this mood began ... versammelte Hofstaat] the gathered royal household als Only when Klatschen] with applause began kann can ... ... ... ... Athlet] The athlete seinem Sport] with his sports stop eher katharsischen Werken]. with rather catharsic works One beginne starts anfangen, aufh¨oren, beginnen / enden aufh¨oren, beginnen / enden Schulte im Walde Induction of German Semantic Verb Classes the implementation, training, and exploitation of the grammar model can be found in Schulte im Walde (2003a, chapter 3). The German verbs are represented by distributional vectors, with features and feature values in the distribution being acquired from the statistical grammar. The distributional description is based on the hypothesis that “each language can be described in terms of a distributional structure, that is, in terms of the occurrence of parts relative to other parts” (cf. Harris 1968). The verbs are described distributionally on three levels at the syntax–semantics interface, each level refining the previous level. The first level encodes a purely syntactic definition of verb subcategorization, the second level encodes a syntactico-semantic definition of subcategorization with prepositional and the third level encodes a syntactico-semantic definition of subcategorization with prepositional and selectional preferences. Thus, the refinement of verb features starts with a purely syntactic definition and incrementally adds semantic information. The most elaborated description comes close to a definition of verb alternation behavior. We decided on this three-step procedure of verb descriptions because the resulting clusters and particularly the changes in clusters that result from a change of features should provide insight into the meaning–behavior relationship at the syntax– semantics interface. the statistical grammar model provides frequency distributions for German verbs over 38 purely syntactic subcategorization frames (cf. Appendix 6). Based these frequencies, we can also calculate the probabilities. For the grammar provides frequencies for the different kinds of prepositional phrases within a frame type; probabilities are computed by distributing the joint probability of a verb and a PP frame over the prepositional phrases according to their frequencies in the corpus. phrases are referred to by case and preposition, such as The statistical grammar model does not learn the distinction between PP arguments and PP adjuncts perfectly. Therefore, we did not restrict the PP features to PP arguments, but to 30 PPs according to ‘reasonable’ appearance in the corpus, as defined by the 30 most frequent PPs that appear with at least 10 different verbs. The subcategorization frame for and has been evaluated: Schulte im Walde (2002b) describes the induction of a subcategorization lexicon from the grammar model for a total of 14,229 verbs with a frequency between 1 and 255,676 in the training corpus, and Schulte im Walde (2002a) performs an evaluation of the subcategorization data against manually created dictionary entries and shows that the lexical entries have potential for adding to and improving manual verb definitions. the refinement of the grammar provides selectional preference information at a fine-grained level: It specifies the possible argument realizations in the form of lexical heads, with reference to a specific verb–frame–slot combination. Obviously, we would run into a sparse data problem if we tried to incorporate selectional preferences into the verb descriptions at such a specific level. We are provided with detailed information at the nominal level, but we need a generalization of the selectional preference definition. A widely used resource for selectional preference information is the semantic et al. 1990; Fellbaum 1998); the University of T¨ubingen has the German version of WordNet, and Feldweg 1997; Kunze 2000). The hierarchy is realized by means of synsets, sets of synonymous nouns, which are organized by multiple inheritance hyponym/hypernym relationships. A noun can appear in several synsets, according to its number of senses. The German noun hierarchy in GermaNet is utilized for the generalization of selectional preferences: For each noun in a verb–frame–slot combination, the joint frequency is divided over the different senses of the noun and propagated up the hierarchy. In case of multiple hypernym 167 Computational Linguistics Volume 32, Number 2 synsets, the frequency is divided again. The sum of frequencies over all top synsets equals the total joint frequency. Repeating the frequency assignment and propagation for all nouns appearing in a verb–frame–slot combination, the result defines a frequency distribution of the verb–frame–slot combination over all GermaNet synsets. To restrict the variety of noun concepts to a general level, only the frequency distributions over the GermaNet are considered: ‘prop- Objekt object’, Prozess process’. Since the 15 nodes are mutually exclusive and the node frequencies sum to the total joint verb-frame frequency, we can use their frequencies to define a probability distribution. Are selectional preferences equally necessary and informative for all frame types? For example, selectional preferences for the direct object are expected to vary strongly with respect to the subcategorizing verb (because the direct object is a highly frequent argument type across all verbs and verb classes), but selectional preferences for a subject in a transitive construction with a nonfinite clause are certainly less interesting for refinement (because this frame type is more restricted with respect to the verbs it is subcategorized for). We empirically investigated which of the overall frame roles may be realized by different selectional preferences and are therefore relevant and informative for a selectional preference distinction. As a result, in parts of the clustering experiments we will concentrate on a specific choice of frame-slot combinations to be refined by selectional preferences (with the relevant slots underlined): ‘n’, ‘na’, ‘nd’, ‘nad’, ‘ns-dass.’ Table 1 presents three verbs from different classes and their 10 most frequent frame at the three levels of verb definition and their probabilities. for defines ‘np’ and ‘n’ as the most probable frame types. After splitting the ‘np’ probability the different PP types in a number of prominent PPs are left, the time indicatand to the begun event, as date, and as place indicator. It is obvious that not all PPs are argument PPs, but adjunct PPs also a part of the verb behavior. illustrates that typical selectional preferences beginner roles are has the potential to indicate verb alternation behavior, for example, ‘na(Situation)’ refers to the same role for the direct object in a transitive frame as “n(Situation)” in intransitive frame. as an object-drop verb shows strong preferences for both intransitive and transitive usage. As desired, the argument roles are dominated for ‘n’ and ‘na’ and for ‘na’. chooses typical manner of motion frames (‘n,’ ‘np,’ ‘na’) with the refining PPs being or referring to a means of motion selectional preferences show correct alternation behavior: in object drop case for ‘n’ and ‘na,’ in the inchoative/causative case for ‘n’ and ‘na’. In addition to the absolute verb descriptions above, a simple smoothing technique is applied to the feature values. The goal of smoothing is to create more uniform distributions, especially with regard to adjusting zero values, but also for assimilating high and low frequencies and probabilities. The smoothed distributions are particularly interesting for distributions with a large number of features, since they typically contain 1 Since GermaNet had not been completed when we used the hierarchy, we manually added a few hypernym definitions. 168 Schulte im Walde Induction of German Semantic Verb Classes Table 1 Example distributions of German verbs. Distribution Verb beginnen np 0.43 n 0.28 n(Situation) 0.12 ‘begin’ n 0.28 0.16 0.09 ni 0.09 ni 0.09 0.04 na 0.07 0.08 ni(Lebewesen) 0.03 nd 0.04 na 0.07 n(Zustand) 0.03 nap 0.03 0.06 0.03 nad 0.03 0.06 0.03 nir 0.01 nd 0.04 n(Zeit) 0.03 ns-2 0.01 nad 0.03 n(Sache) 0.02 xp 0.01 0.01 na(Situation) 0.02 essen na 0.42 na 0.42 na(Lebewesen) 0.33 ‘eat’ n 0.26 n 0.26 na(Nahrung) 0.17 nad 0.10 nad 0.10 na(Sache) 0.09 np 0.06 nd 0.05 n(Lebewesen) 0.08 nd 0.05 ns-2 0.02 na(Lebewesen) 0.07 nap 0.04 0.02 n(Nahrung) 0.06 ns-2 0.02 ns-w 0.01 n(Sache) 0.04 ns-w 0.01 ni 0.01 nd(Lebewesen) 0.04 ni 0.01 0.01 nd(Nahrung) 0.02 nas-2 0.01 0.01 na(Attribut) 0.02 fahren n 0.34 n 0.34 n(Sache) 0.12 ‘drive’ np 0.29 na 0.19 n(Lebewesen) 0.10 na 0.19 0.05 na(Lebewesen) 0.08 nap 0.06 nad 0.04 na(Sache) 0.06 nad 0.04 0.04 n(Ort) 0.06 nd 0.04 nd 0.04 na(Sache) 0.05 ni 0.01 0.04 0.02 ns-2 0.01 0.03 0.02 ndp 0.01 0.03 0.02 ns-w 0.01 0.02 0.02 persuasive zero values and severe outliers. Chen and Goodman (1998) present a concise overview of smoothing techniques, with specific emphasis on language modeling. We to apply the smoothing algorithm referred to as The smoothing is performed simply by adding 0.5 to all verb features, that is, the joint frequency each verb feature changed by The total verb frequency is adapted to the changed feature values, representing the sum of all verb values: = Smoothed probability values are based on the smoothed frequency distributions. 2.3 Clustering Algorithm and Evaluation Techniques Clustering is a standard procedure in multivariate data analysis. It is designed to allow exploration of the inherent natural structure of the data objects, where objects in the same cluster are as similar as possible and objects in different clusters are as dissimilar as possible. Equivalence classes induced by the clusters provide a means for 169 Computational Linguistics Volume 32, Number 2 generalizing over the data objects and their features. The clustering of the German verbs performed by the algorithm, a standard unsupervised clustering technique proposed by Forgy (1965). With initial verb clusters are iteratively reorganized by assigning each verb to its closest cluster and recalculating cluster centroids until further changes take place. Applying the algorithm assumes (1) that verbs are represented by distributional vectors and (2) that verbs that are closer to each other in a mathematically defined way are also more similar to each other in a linguistic depends on the following parameters: (1) The number of clusters is not known beforehand, so the clustering experiments investigate this parameter. Related to this parameter is the level of semantic concept: The more verb clusters are found, more specific the semantic concept, and vice versa. (2) is sensitive to the initial clusters, so the initialization is varied according to how much preprocessing we invest: Both random clusters and hierarchically preprocessed clusters are used as initial for In the case of preprocessed clusters, the hierarchical clustering is performed as bottom-up agglomerative clustering with the following criteria for merging the clusters: single linkage (minimal distance between nearest neighbor verbs), complete linkage (minimal distance between furthest neighbor verbs), average distance between verbs, distance between cluster centroids, and Ward’s method (minimizing the sum of squares when merging clusters). The merging method influences the shape of the clusters; for example, single linkage causes a chaining effect in the shape of the clusters, and complete linkage creates compact clusters. (3) In addition, there are several possibilities for defining the similarity between distributional vectors. But which best fits the idea of verb similarity? Table 2 presents an overview of relevant similarity that are applied in the experiments. to the verb object vectors, subscripts to the verb feature values. The metric be applied to frequencies and probabilities. It is a generalization of the two well-known instances and The divergence a measure from information theory that determines the inefficiency of assuming a model probability distribution given the true distribution (Cover and Thomas 1991). KL divergence is not defined in case so the probability distributions need be smoothed. Two variants of KL, radius perform a default smoothing. Both variants can tolerate zero values in the distribution because they work with a weighted average of the two distributions compared. Lee (2001) has shown that the skew divergence is an effective measure for distributional similarity in Similarly to Lee’s method, we set the weight the skew divergence to 0.9. The the similarity of the two object vectors calculating the cosine of the angle between the feature vectors. The cosine measure can be applied to frequency and probability values. For a detailed description of hierarchical clustering techniques and an intuitive interpretation of the similarity measures, the reader is referred to, for example, Kaufman and Rousseeuw (1990). There is no agreed standard method for evaluating clustering experiments and results, but a variety of evaluation measures from diverse areas such as theoretical statistics, machine vision, and Web-page clustering are generally applicable. We used the following two measures for the evaluation: (1) Hatzivassiloglou and McKeown (1993) define and evaluate a cluster analysis of adjectives, based on common cluster of object pairs in the clustering the manual classification Recall and precision numbers are calculated in the standard way, with true positives the of common pairs in false positives the number of pairs in but and false negatives the number of pairs in but not We use the (as harmonic mean between recall and precision), which provides an easy to understand 170 Schulte im Walde Induction of German Semantic Verb Classes Table 2 Data similarity measures. Measure Definition metric / norm distance / distance / divergence / relative entropy radius divergence percentage. (2) The adjusted Rand index is a measure of agreement versus disagreement between object pairs in clusterings that provides the most appropriate reference to a null model (Hubert and Arabie 1985); cf. equation (1). The agreement in the two is represented by a contingency table denotes the number of verbs to classes the clustering partition the manual classification the marginals andrefer to the number of objects in respectively; the number of common object pairs attributable to a particular cell the table is defined by The upper bound for is 1, the lower 2 2 2 bound is mostly 0, with only extreme cases below zero. ) (1) ~ i )� The above two measures were chosen as a result of comparing various evaluation measures and their properties with respect to the linguistic task (Schulte im Walde 2003a, chapter 4). 3. Preliminary Clustering Experiments The 168 German verbs are associated with distributional vectors over frame types and to initial clusters. Then is allowed to run for as many iterations as it takes to reach a fixed point, and the resulting clusters are interpreted and evaluated the manual classes. The verbs are described by and each level refers to frequencies and probabilities, with original and smoothed values. The initial clusters are generated either randomly or by a preprocessing cluster analysis, that is, hierarchical clustering as described in Section 2.3. For random cluster initialization the verbs are randomly assigned to a cluster, with cluster numbers between 1 and the of manual classes. The experiments are performed with the number of being fixed to the number of gold standard classes (43); optimization of the number of clusters is addressed in Section 3.4. 171 Computational Linguistics Volume 32, Number 2 3.1 Baseline and Upper Bound The experiment baseline refers to 50 random clusterings: The verbs are randomly assigned to a cluster (with a cluster number between 1 and the number of manual classes), and the resulting clustering is evaluated by the evaluation measures. The baseline value is the average value of the 50 repetitions. The upper bound of the experiments (the “optimum”) refers to the evaluation values on the manual classification; the manual classification is adapted before calculating the upper bound by randomly deleting additional senses (i.e., more than one sense) of a verb, so as to leave only one sense each verb, since as a hard clustering algorithm cannot model ambiguity. Table 3 lists the baseline and upper bound values for the clustering experiments. 3.2 Experiment Results The following tables present the results of the clustering experiments. Tables 4 to 7 each concentrate on one technical parameter of the clustering process; Tables 8 to 10 then focus on performing clustering with a fixed parameter set, in order to vary the linguistically interesting parameters concerning the feature choice for the verbs. All tests have been performed with = 4 illustrates the effect of the units and probabilities) the clustering result. The experiments use distributions on and with random and preprocessed initialization, and the cosine as similarity measure (since it works for both distribution units). To summarize the results, neither the differences between frequencies and probabilities nor between original and smoothed values are significant. 5 illustrates the usage of different measures. before, the experare performed for and with random and preprocessed initialization. The similarity measures are applied to the relevant probability distributions (as the distribution unit that can be used for all measures). The tables point out that there is no best-performing similarity measure in the clustering processes. On the larger feature set, the Kullback–Leibler variants information radius and skew divergence tend to outperform all other similarity measures. In fact, the skew divergence is the only measure that shows significant differences for some parameter settings, as compared to all other measures except information radius. In further experiments, we will therefore concentrate on the two Kullback–Leibler variants. 6 and 7 compare the effects of varying the the The experiments are performed for and with probability distributions, using the similarity measures information radius and skew divergence. For random and hierarchical initialization, we cite both the evaluation scores for the initial cluster analysis (i.e., the output clustering from the random assignment the preprocessing hierarchical analysis), and for the result. The columns in the tables refer to a cluster analysis where the initial clusters provided to Table 3 experiment baseline and upper bound.</abstract>
<title confidence="0.749997">Evaluation Baseline Optimum</title>
<address confidence="0.607262">PairF 2.08 95.81</address>
<date confidence="0.544251">0.909</date>
<note confidence="0.366794">172</note>
<title confidence="0.8683906">Schulte im Walde Induction of German Semantic Verb Classes Table 4 distributions on and Probability Frequency Probability Frequency Eval Initial Original Smoothed Original Smoothed Original Smoothed Original Smoothed</title>
<abstract confidence="0.931855435897436">PairF Random 12.67 12.72 14.06 14.14 14.98 15.37 14.82 15.07 H-Ward 11.40 11.70 11.56 11.37 10.57 13.71 11.65 9.98 Random 0.090 0.090 0.102 0.102 0.104 0.113 0.107 0.109 H-Ward 0.079 0.081 0.080 0.076 0.065 0.096 0.075 0.056 Table 5 similarity measures on and Similarity Measure Eval Initial Cos L1 Eucl IRad Skew Cos L1 Eucl IRad Skew PairF Random 12.67 13.11 13.85 14.19 14.13 14.98 15.20 16.10 16.15 18.01 H-Ward 11.40 13.65 12.88 13.07 12.64 10.57 15.51 13.11 17.49 19.30 Random 0.090 0.094 0.101 0.101 0.105 0.104 0.109 0.123 0.118 0.142 H-Ward 0.079 0.099 0.093 0.097 0.094 0.065 0.116 0.092 0.142 0.158 are the manual classification, that is, the gold standard. An optimal cluster analysis should realize the “perfect” clustering and not perform any reorganization of clusters. In the experiments, does perform iterations, so the clustering result is suboptimal. This finding is caused by the syntax–semantics mismatches, which we included in the definition of the gold standard (recall, e.g., that syntactically very different compared to the other three In addition, the results not only show that the feature sets are suboptimal, but also that the loss quality is less for the linguistically refined feature level compared to as we have hoped. For initialization to the tables present both the best and the average clustering results. The best results are paired with the evaluation of their initial clusters, that is, the random clusterings. As the tables show, the initial clusters receive low evaluation scores. Typically, the clusterings consist of clusters with rather homogeneous numbers of verbs, but the perturbation within the clusters high, as expected. is able to cope with the high degree of perturbation: The resulting clusters improve significantly and are comparable with those based on preprocessed hierarchical clustering; this competitiveness vanishes with an increasing number of features. The average values of the random initialization experiments are clearly below the best ones, but not significantly different. Cluster analyses as based on hierarchical clustering with are evaluated as poor compared to the gold standard. This result is probably due to the chaining effect in the clustering, which is characteristic for single linkage; the effect is observable in the analysis, which typically contains one very large cluster and many clusters with verbs, mostly singletons. obviously cannot compensate for this strong bias in cluster sizes (and their respective centroids); the reorganization improves the but the result is still worse than for any other initialization. With distance both the clusterings and the evaluation results are less extreme than with single linkage since the chaining effect is smoothed.</abstract>
<note confidence="0.698951631578947">173 Computational Linguistics Volume 32, Number 2 Table 6 clustering initializations on Initialization Random Eval Distance Manual Best Avg PairF IRad 18.56 2.16 14.19 11.78 Skew 20.00 1.90 14.13 12.17 IRad 0.150 0.101 0.078 Skew 0.165 0.105 0.083 Initialization Hierarchical Eval Distance Single Complete Average Centroid Ward PairF IRad 4.80 12.73 9.43 10.16 10.83 11.33 8.77 11.88 12.76 13.07 Skew 4.81 13.04 11.50 11.00 11.68 11.41 8.83 11.45 12.44 12.64 IRad 0.000 0.088 0.055 0.065 0.067 0.072 0.039 0.079 0.094 0.097 Skew 0.000 0.090 0.077 0.072 0.075 0.073 0.041 0.072 0.092 0.094 The overall results are better than for single linkage, but only slightly improved by</note>
<abstract confidence="0.900008384615385">Hierarchical clusters as based on are more compact, and result in a closer fit to the gold standard than the previous methods. hierarchical initialization is only slightly improved by in some cases output is worse than its hierarchical initialization. method work best on hierarchical clusters and initialization. The cluster sizes are more balanced and correspond to compact cluster shapes. As for complete linkage, improves the clusterings only slightly; in some cases the output is worse than its hierarchical initialization. A cluster analysis based on Ward’s hierarchical clusters performs best of all the applied methods, especially with an increasing number of features. The similarity of Ward’s clusters (and similarly complete linkage clusters) Table 7 clustering initializations on Initialization</abstract>
<note confidence="0.752460714285714">Random Eval Distance Manual Best Avg PairF IRad 40.23 1.34 16.15 13.37 Skew 47.28 2.41 18.01 14.07 IRad 0.358 0.001 0.118 0.093 Skew 0.429 0.142 0.102 Initialization Hierarchical Eval Distance Single Complete Average Centroid Ward PairF IRad 5.06 11.12 15.37 14.44 10.50 10.64 9.16 12.90 17.86 17.49 Skew 5.20 10.64 15.21 13.81 10.02 10.02 9.04 10.91 15.86 15.23 IRad 0.003 0.063 0.114 0.105 0.059 0.060 0.045 0.082 0.145 0.142 Skew 0.004 0.063 0.115 0.102 0.054 0.054 0.042 0.064 0.158 0.158 174</note>
<title confidence="0.410486">Schulte im Walde Induction of German Semantic Verb Classes</title>
<abstract confidence="0.964230540841585">is not by chance, since these methods aim to optimize the same criterion, the sum of distances between the verbs and their respective cluster centroids. Note for Ward’s method actually significantly outperforms all other initialization methods, complete linkage significantly outperforms all but Ward’s. Between single average and centroid distance, there are no significant differences. For there are no significant differences between the initializations. The low scores in the tables might be surprising to the reader, but they reflect the difficulty of the task. As mentioned before, we deliberately set high demands for the gold standard, especially with reference to the fine-grained, small classes. Compared to related work (cf. Section 5), our results achieve lower scores because the task is more difficult; for example, Merlo and Stevenson (2001) classify 60 verbs into 3 classes, and Siegel and McKeown (2000) classify 56 verbs into 2 classes, as compared to our clustering, which assigns 168 verbs to 43 classes. The following illustrations should provide an intuition about the difficulty of the task: 1. In a set of additional experiments, a random choice of a reduced number of 5/10/15/20 classes from the gold standard is performed. The verbs from the respective gold standard classes are clustered with the optimal set (see Table 8), which results in a pairwise f-score 22.19%. The random choice and the cluster analysis are repeated 20 times for each reduced gold standard size of 5/10/15/20 classes, and the calculated: The results are 45.27/35.64/30.30/26.62%, respectively. This shows that the clustering results are much better (with the same kind of data and features and the same algorithm) when applied to a smaller number of verbs and classes. 2. Imagine a gold standard of three classes with four members each, for b, c, f, g, j, k, If a cluster analysis of these into three clusters resulted in an almost perfect choice of b, d, g, j, k, only assigned to a ”wrong” class, pairwise precision is 79%, the recall is 83%, and 81%, so the of only one mistake is almost 20%. If another cluster resulted in a choice with just one more mistake such as b, d, e, g, k, also assigned to a ”wrong” class, the result decreases by almost another 20%, to a precision of 57%, a recall of and 62%. The results show how much impact a few mistakes have on the pairwise of the results. In addition to defining a difficult task, we also chose strong evaluation measures: Evaluating pairs of objects results in lower numbers than evaluating the individual For example, the (Stevenson and Joanis 2003; Korhonen, Krymolowski, and Marx 2003) evaluates whether a verb is assigned to a correct cluster with respect to the gold standard class of the majority of cluster members. That is, in a first step each induced verb cluster is assigned a gold standard class according to which class captures the majority of the cluster members. In a second step, each verb in a cluster is evaluated as correct or wrong with respect to its gold standard class, and accuracy/purity of the whole clustering is calculated as the proportion of correct verbs divided by the total number of verbs. If we applied this measure to our optimal with a pairwise 22.19%, we achieve an accuracy of 51.19%; if we applied the measure to the above random choices of gold standard classes with 5/10/15/20 classes, we achieve accuracies of 68.20/60.73/57.82/55.48%. 175 Computational Linguistics Volume 32, Number 2 The last series of experiments applies the algorithmic insights from the previous experiments to a linguistic variation of parameters (cf. Schulte im Walde 2003b). The verbs are described by probability distributions on different levels of linguistic information (frames, prepositional phrases, and selectional preferences). A preprocessing cluster analysis is performed by Ward’s method, and is applied to re-organize the clusters. Similarities are measured by the skew divergence. Table 8 the first results comparing and either on specified frame slots (‘n,’ ‘nd,’ ‘nad,’ ‘ns-dass’), on all noun phrase slots or on all noun phrase and phrase slots The number of features in each experiment is given in square brackets. The table demonstrates that a purely syntactic verb description gives rise to a verb clustering clearly above the baseline. Refining the coarse subcategorization frames with prepositional phrases considerably improves the verb clustering results. Adding selectional preferences to the verb description further improves the clustering results, but the improvement is not as persuasive as in the first step, when refining the purely syntactic verb descriptions with prepositional information. The difference and is significant, but neither the difference between and (in variation) nor the differences between the variants of are significant. In the case of adding role information to all NP (and all PP) slots, the problem might be caused by sparse data, but for the linguistically chosen subset of argument slots we assume additional linguistic reasons are directly relevant to the clustering outcome. order to choose the most informative frame roles for we varied the selectional preference slots by considering only single slots for refinements, or small combinations of argument slots. The variations should provide insight into the contribution of slots and slot combinations to the clustering. The experiments are performed on probability for all other parameters were chosen as above. Table 9 shows that refining only a single slot (the underlined slot in the respective frame type) in addition the definitions results in little or no improvement. There is no frame-slot type that consistently improves results, but success depends on the parameter instantiation. The results do not match our linguistic intuitions: For example, we would expect the arguments in the two highly frequent intransitive ‘na’ and transitive ‘na’ frames with variable semantic roles to provide valuable information with respect to their selectional but only those in ‘na’ actually improve However, a subject in a transitive construction with a non-finite clause ‘ni’, which is less variable with respect to verbs and roles, does work better than ‘n’. In Table 10, selected slots are combined to define preference information, for example, means that the nominative slot in ‘na’, and both the nominative and accusative slot in ‘na’ are refined by selectional preferences. It is obvious that the clustering effect does not represent a sum of its parts, for example, both the information in ‘na’ and in ‘na’ improve Ward’s clustering on (cf. Table 9), but it is not the case that ‘na’improves the clustering, too. Table 8 Comparing feature descriptions. Distribution Eval [38] [183] [288] NP NP–PP [906] [2,726] PairF 12.64 18.81 22.19 19.29 21.11 0.094 0.151 0.182 0.158 0.176 176 Schulte im Walde Induction of German Semantic Verb Classes Table 9 Comparing selectional preference slot definitions. Distribution As in Table 9, there is no combination of selectional preference frame definitions that improves the results. On the contrary, some additional information makes the result significantly worse, for example, ‘nad’. The specific combination of selectional preferences as determined preexperimentally actually achieves the overall best results, better than any other slot combination, and better than refining all NP slots or refining all NP and all PP slots in the frame types (cf. Table 8). 3.3 Experiment Interpretation For illustrative purposes, we present representative parts of the cluster analysis as based on the following parameters: The clustering initialization is obtained from a hierarchical analysis of the German verbs (Ward’s amalgamation method), the number of clusters being the number of manual classes (43); the similarity measure is the skew divergence. cluster analysis is based on the verb description on with selectional roles for Table 10 Comparing selectional preference frame definitions. Distribution Eval n nad PairF 18.81 16.22 17.82 17.00 13.36 16.05 0.151 0.125 0.137 0.128 0.088 0.118 Distribution Eval np/ni/nr/ns-2/ns-dass PairF 18.81 18.48 16.48 20.21 16.73 0.151 0.150 0.124 0.161 0.131 Eval n na PairF 18.81 16.22 21.15 0.151 0.125 0.176 Eval nd nd PairF 18.81 18.88 17.92 0.151 0.152 0.143 na nad nad nad 20.19 17.82 15.13 19.48 0.164 0.144 0.115 0.161 Distribution np ni nr ns-2 ns-dass 16.77 18.26 17.22 15.55 19.29 0.133 0.148 0.136 0.121 0.156 177 Computational Linguistics Volume 32, Number 2 ‘nad,’ ‘ns-dass.’ We compare the clusters with the respective clusters by and nieseln regnen schneien – d¨ammern – beginnen enden – existieren – sitzen stehen – – of Motion: Locomotion kriechen rennen – of Motion: Locomotion – of Motion: Rush – of Motion: Flotation – Expression klettern wandern – of Motion: Locomotion fliegen segeln – of Motion: Vehicle – of Motion: Flotation festlegen – – senken steigern vergr¨oßern verkleinern – Change t¨oten – – geben – of Possession (Giving): Gift weather verbs in cluster (a) strongly agree in their syntactic expression on and not need or refinements for an improved class constitution. cluster (b) is ambiguous between a weather verb and expressing a sense of understanding; ambiguity is already idiosyncratically expressed in frames, so never together with the other weather verbs by of Motion, Existence, are similar in their syntactic frame usage and therefore together by but adding PP information distinguishes the respective verb of Motion primarily demand directional PPs, are by patient and time and location prepositions, and are distinguished by locative prepositions, with showing more PP variation. The PP information is essential for distinguishing these verb and the coherence is partly destroyed by of Motion (from the Rotation, Rush, Vehicle, are captured well by clusters (d) (e), since they use common alternations, but cluster (c) merges Position, because verb-idiosyncratic demands on selectional roles destroy the class demarcation. Still, the verbs in cluster (c) are close in their (more general conceptual) semantics, with a common sense of (bringing into versus being in) existence. into the cluster with its sense of “function.” Cluster (f) contains most verbs together with one verb of The common conceptual level of this cluster therefore refers to a quantum change including quantum change from zero to something (as for the two verbs ‘constitute,’ ‘found’). The verbs in this cluster typically subcategorize for a direct object, with a reflexive usage, “nr” and “npr” with mostly andThe 178 Schulte im Walde Induction of German Semantic Verb Classes selectional preferences help to distinguish this cluster: The verbs agree in demanding a thing or situation as subject, and various objects such as attribute, cognitive object, state, or thing as object. Without selectional preferences (on and the change of quantum verbs are not found together with the same degree of purity. There are verbs in cluster (g) whose properties are correctly stated as similar by so a common cluster is justified, but the verbs only have coarse common meaning components; in this and agree in an action of one person or institution another. cluster (h) represents a singleton. Syntactically, this is caused by being the only verb with a strong preference for “xa.” From the meaning point of this specific frame represents an idiomatic expression, only possible with An overall interpretation of the clustering results gives insight into the relationship between verb properties and clustering outcome. (1) The fact that there are verbs that are clustered semantically on the basis of their corpus-based and knowledge-based empirical properties indicates (a) a relationship between the meaning components of the verbs and their behavior and (b) that the clustering algorithm is able to benefit from the linguistic descriptions and to abstract away from the noise in the distributions. (2) Low-frequency verbs were a problem in the clustering experiments. Their distributions are noisier than those for more frequent verbs, so they typically constitute noisy clusters. (3) As known beforehand, verb ambiguity cannot be modeled by the hard clustering Ambiguous verbs were typically assigned either (a) to one of the correct clusters or (b) to a cluster whose verbs have distributions that are similar to the ambiguous distribution, or (c) to a singleton cluster. (4) The interpretation of the clusterings unexpectedly points to meaning components of verbs that have not been by the manual classification. An example verb is expressing not only of Motion also a kind of existence when used in the sense of operation. The discovery effect should be more impressive with an increasing number of verbs, since manual judgement is more difficult, and also with a soft clustering technique, where multiple cluster assignment is enabled. (5) In a similar way, the clustering interpretation exhibits semantically related verb classes, that is, verb classes that are separated in the manual classification, but semantically merged in a common cluster. For example, are related in that all the verbs express an observation, the additionally referring to a physical ability, such as hearing. (6) Related to the preceding issue, the manual verb classes as defined are demonstrated as detailed and subtle. Compared to a more general classification that would appropriately merge several classes, the clustering confirms that we defined a difficult task with subtle classes. We were aware of this fact but preferred a fine-grained classification, since it allows insight into verb and class properties. In this way, verbs that are similar in meaning are often clustered incorrectly with respect to the gold standard. To come to the main point, what exactly is the nature of the meaning–behavior relationship? (1) Already a purely syntactic verb description allows a verb clustering clearly above the baseline. The result is a (semantic) classification of verbs that agree in syntactic frame definitions, for example, most of the The clustering fails for semantically similar verbs that differ in their syntactic behavior, for example, which belongs to the but demands an accusative rather than a dative object. In addition, it fails for syntactically similar verbs that are clustered together even though they do not exhibit semantic similarity; for example, many verbs from different semantic classes subcategorize for an accusative object, so they are falsely clustered together. (2) Refining the syntactic verb information with prepositional phrases is helpful for the semantic clustering, not only in the clustering of verbs where the PPs are obligatory, but also in the clustering of verbs with optional PP arguments. 179 Computational Linguistics Volume 32, Number 2 The improvement underlines the linguistic fact that verbs that are similar in their agree either on a specific prepositional complement (e.g., on a more general kind of modification, for example, directional PPs for of (3) Defining selectional preferences for arguments improves the clustering results further, but the improvement is not as persuasive as when refining the purely syntactic verb descriptions with prepositional information. For example, selectional help demarcate the Change because the respective verbs agree their structural as well as selectional properties. But in the strong preferences for a food object, whereas a wider range of object types. In contrast, there are verbs that are very similar in their behavior, especially with respect to a coarse definition of selectional roles, but they do belong to the same fine-grained semantic class, for example, The effect could be due to (a) noisy or (b) sparse data, but the basic verb descriptions appear reliable with respect to their desired linguistic content, and Table 8 illustrates that even with little added information the effect exists (e.g., refining few arguments by 15 selectional roles results in 253 instead of 178 features, so the magnitude of feature numbers does not change). Why do we encounter an indeterminism concerning the encoding and effect of verb features, especially with respect to selectional preferences? The meaning of verbs comprises both properties that are general for the respective verb classes, and idiosyncratic properties that distinguish the verbs from each other. As long as we define the verbs by those properties that represent the common parts of the verb classes, a clustering can succeed. But by stepwise refining the verb description and including lexical idiosyncrasy, the emphasis on the common properties vanishes. From a theoretical point of view, the distinction between common and idiosyncratic features is obvious, but from a practical point of view there is no perfect choice for the encoding of verb features. The feature choice depends on the specific properties of the desired verb classes, and even if classes are perfectly defined on a common conceptual level, the relevant level of behavioral properties of the verb classes might differ. Still, for a large-scale classification of verbs, we need to specify a combination of linguistic verb features as a basis for the clustering. Which combination do we choose? Both the theoretical assumption of encoding features of verb alternation as verb behavior and the practical realization by encoding syntactic frame types, prepositional phrases, and selectional preferences seem promising. In addition, we aimed at a (rather linguistically than technically based) choice of selectional preferences that represents a useful compromise for the conceptual needs of the verb classes. Therefore, this choice of features best utilizes the meaning–behavior relationship and will be applied in a largescale clustering experiment (cf. Section 4). 3.4 Optimizing the Number of Clusters It is not a goal of this article to optimize the number of clusters in the cluster analysis. We are not interested in the question of whether, for example, 40, 42, 43, or 45 clusters represent the best semantic classification of 168 verbs. But there are two reasons why it is interesting and relevant to investigate the properties of clusterings with respect to different numbers of clusters. (1) The clustering methodology should basically work the way we expect it to work, that is, the evaluation of the results should show deficiencies for extreme numbers of clusters, but (possibly several) optimal values for various numbers of clusters in between. (2) Even if we do not check for an exact number of clusters, we should check the magnitude of the number of clusters, since the clustering 180 Schulte im Walde Induction of German Semantic Verb Classes methodology might be successful in capturing a rough verb classification with few verb classes but not a fine-grained classification with many subtle distinctions. Figure 1 illustrates the clustering results for the series of cluster analyses as by with hierarchical clustering initialization (Ward’s method) on probability distributions, with skew divergence as the similarity measure. The feature refers to The number of clusters is varied from 1 through the number verbs (168), and the results are evaluated by A range of numbers of clusters is determined as optimal (71) or near-optimal (approx. 58–78). The figure demonstrates that having performed experiments on the parameters for clustering, it is worthwhile exploring additional parameters: The optimal result is 0.188 for 71 clusters as compared to 0.158 for 43 clusters reported previously. 4. Large-Scale Clustering Experiments So far, all clustering experiments were performed on a small scale, preliminary set of 168 manually chosen German verbs. One goal of this article was to develop a clustering methodology with respect to the automatic acquisition of a large-scale German verb classification. We therefore apply the insights on the theoretical relationship between verb meaning and verb behavior and our findings regarding the clustering parameters to a considerably larger amount of verb data. We extracted all German verbs from our statistical grammar model that appeared with an empirical frequency of between 500 and 10,000 in the training corpus (cf. Section 2.2). This selection resulted in a total of 809 verbs, including 94 verbs from the preliminary set of 168 verbs. We added the missing verbs from the preliminary set, resulting in a total of 883 German verbs. The feature description of the German verbs refers to the probability distribution over the coarse syntactic frame types, with Figure 1 the number of clusters (evaluation: 181 Computational Linguistics Volume 32, Number 2 prepositional phrase information on the 30 chosen PPs and selectional preferences for empirically most successful combination ‘n,’ ‘nad,’ and ‘ns-dass.’ As in clustering experiments, the features are stepwise refined. is provided hierarchical clustering initialization (based on Ward’s method), with the similarity measure being skew divergence. The number of clusters is set to 100, which corresponds to an average of 8.83 verbs per cluster, that is, not too fine-grained clusters but still possible to interpret. The preliminary set of 168 verbs is a subset of the large-scale set in order to provide an “auxiliary” evaluation of the clustering results: Considering only the manually chosen verbs in the clustering result, this partial cluster analysis is evaluated against the gold standard of 43 verb classes. Results were not expected to match the results of our clustering experiments using only the preliminary verb set, but to provide an indication of how different cluster analyses can be compared with each other. 11 to 13 present the clustering results for the large-scale verb set for in the rightmost columns, citing the evaluation scores of the initial (hierarchical) clusters the resulting clusters. The subset of the 168 gold standard verbs is scattered over 72 of the 100 resulting clusters. The results are compared to our previous results for the 168 verbs in 43 clusters, and to the case where those 168 verbs are clustered into 72 hierarchical classes. The large-scale clustering results once more confirm the general insights (1) that the stepwise refinement of features improves the clustering and that Ward’s hierarchical clustering is seldom improved by the application. In addition, several of the large-scale cluster analyses were quite comparable with the clustering results using the small-scale set of verbs, especially when compared to 72 clusters. In the following, we present example clusters from the optimal large-scale cluster analysis (according to the above evaluation): Ward’s hierarchical cluster analysis based subcategorization frames, PPs, and selectional preferences, without running on the hierarchical clustering. Some clusters are extremely good with respect to the semantic overlap of the verbs, some clusters contain a number of similar verbs mixed with semantically different verbs, and for some clusters it is difficult to recognize common elements of meaning. The verbs that we think are semantically similar are marked in bold face. abschneiden off’, aufhalten off’, responsible’, away’, back’, ‘change’ Table 11 clustering on Small-Scale Large-Scale Eval 43 Clusters 72 Clusters 72 Clusters PairF 182 Schulte im Walde Induction of German Semantic Verb Classes Table 12 clustering on Small-Scale Large-Scale Eval 43 Clusters 72 Clusters 72 Clusters PairF Table 13 clustering on with Small-Scale Large-Scale Eval 43 Clusters 72 Clusters 72 Clusters PairF anh¨oren worth’, abholen up’, anschauen about’ danken beschleunigen up’, smaller’, ahnen anbieten possible’, argumentieren basieren based on’, based on’, from’, from’ befragen 183 Computational Linguistics Volume 32, Number 2 beziffern to’, entschuldigen glad’, surprised’, annoyed’ nachdenken about’, mangeln Clusters (1) to (3) are examples where the verbs do not share elements of meaning. In the overall cluster analysis, such semantically incoherent clusters tend to be rather large, that is, with more than 15–20 verb members. Clusters (4) to (7) are examples of clusters where some of the verbs show overlap in meaning, but also contain considerable noise. Cluster (4) mainly contains verbs of buying and selling, cluster (5) contains verbs of wishing, cluster (6) contains verbs of expressing approval, and cluster (7) contains verbs of quantum change. Clusters (8) to (16) are examples of clusters where most or all verbs show a strong similarity in their semantic concept. Cluster (8) contains verbs expressing a propositional attitude; the underlined verbs, in addition, indicate an The only unmarked verb be explained, since some of its inflected are ambiguous with respect to their base verb: either a verb belongs to the class. The verbs in cluster (9) describe a scene where somebody or some situation makes something possible (in the positive or negative the only exception verb is The verbs in cluster (10) are connected more loosely, all referring to a verbal discussion, with the underlined verbs denoting a negative, complaining way of utterance. In cluster (11) all verbs refer to a basis, in cluster (12) the verbs describe the process from arresting to releasing a suspect, and cluster (13) contains verbs of estimating an amount of money. In cluster (14), all verbs except for to an emotional state (with some origin for the emotion). The verbs cluster (15) except for indicate thought (with or without talking) about a certain matter. Finally in cluster (16), we can recognize the same weather verb cluster as in the previously discussed small-scale cluster analyses. We experimented with two variations in the clustering setup: (1) For the selection of the verb data, we considered a random choice of German verbs in approximately the same magnitude of number of verbs (900 verbs plus the preliminary verb set), but without any restriction on the verb frequency. The clustering results are—both on the basis of the evaluation and on the basis of a manual inspection of the resulting clusters—much worse than in the preceding cluster analysis, since the large number of low-frequency verbs destroys the clustering. (2) The number of target clusters was set to 300 instead of 100, that is, the average number of verbs per cluster was 2.94 instead of 8.83. The resulting clusters are numerically slightly worse than in the preceding cluster analysis, but easier for inspection and therefore a preferred basis for a largescale resource. Several of the large, semantically incoherent clusters are split into smaller and more coherent clusters, and the formerly coherent clusters often preserved their constitution. To present one example, the following cluster from the 100-cluster analysis down’, ‘persuade’ 184 Schulte im Walde Induction of German Semantic Verb Classes is split into the following four clusters from the 300-cluster analysis: anzeigen beeindrucken befreien down’, (d) begeistern where cluster (a) shows a loose semantic coherence of declaration, the verbs in cluster (b) are semantically very similar and describe an emotional impact of somebody or a situation on a person, and the verbs in cluster (c) show a protective (and the negation: nonprotective) influence of one person towards another. Summarizing, the large-scale clustering experiment results in a mixture of semantically coherent and incoherent verb classes. Semantically incoherent verb classes and clustering mistakes need to be split into finer and more coherent clusters, or to be filtered from the classification. Semantically coherent verb classes need little manual correction as a lexical resource. Interestingly, the coherence in verb classes refers to criteria on meaning coherence, such as synonymy (e.g., and antonymy (e.g., and situational (e.g., emotional state containing glad’ and annoyed’), and in a common process/script (e.g., and up’). 5. Related Work The following paragraphs describe related classification and clustering experiments on the automatic induction of verb classes. The classifications refer to different class criteria, for example, aspectual properties (Siegel and McKeown 2000), syntactic categories (Merlo and Stevenson 2001; Merlo et al. 2002; Tsang, Stevenson, and Merlo 2002), and— most similar to my approach—semantic categories (Schulte im Walde 2000; Joanis 2002). The soft clustering approaches indicate how we might extend our hard clustering to verb ambiguity, now that we have determined the relevant set of verb features. Siegel and McKeown (2000) used three supervised and one unsupervised machinelearning algorithm to perform an automatic aspectual classification of English verbs. (1) For the supervised classification, 97,973 parsed sentences from medical discharge summaries were used to extract frequencies for verbs on 14 linguistic indicators, such manner adverb, duration past tense, and perfect tense. Logistic regression, decision tree induction, and genetic programming were applied to the verb data to distinguish states and events. Comparing the ability of the learning methods to combine the linguistic indicators was claimed to be difficult, as they rank differently depending on the classification task and evaluation criteria. Decision trees achieved an accuracy of 93.9%, as compared to the uninformed baseline of 83.8%. (2) For the unsupervised clustering, 14,038 distinct verb–object pairs of varying frequencies were extracted from 75,289 parsed novel sentences. A random partition of the set of verbs was improved by a hill-climbing method, which improved the partition by moving a verb to the cluster that decreases the sum of distances most. For a small set of 56 verbs whose frequency in the verb–object pairs was larger than 50, Siegel and McKeown (2000) claimed on the basis of an evaluation of 19 verbs that their clustering algorithm discriminated 185 Computational Linguistics Volume 32, Number 2 event verbs from stative verbs. Overall, they performed a comparably simpler task than presented in this article, since the aspectual class criteria can be defined more objectively and more clearly than semantic criteria based on situational similarity. Their choice of features delimited their class criteria well, and they were able to achieve excellent results. In previous work on English, Schulte im Walde (2000) clustered 153 verbs into 30 verb classes taken from Levin (1993), using unsupervised hierarchical clustering. The verbs were described by distributions over subcategorization frames as extracted from maximum-probability parses using a robust statistical parser, and completed by assigning WordNet classes as selectional preferences to the frame arguments. Using Levin’s verb classification as a basis for evaluation, 61% of the verbs were classified correctly into semantic classes. The clustering was most successful when utilizing syntactic subcategorization frames enriched with PP information; selectional preferences decreased the performance of the clustering approach. The detailed encoding and therefore sparse data made the clustering worse with the selectional preference information. Merlo and Stevenson (2001) presented an automatic classification of three types of English intransitive verbs, based on argument structure and crucially involving thematic relations. They selected 60 verbs with 20 verbs from each verb class, comprising unergatives, unaccusatives, and object-drop verbs. The verbs in each verb class show similarities with respect to their argument structure, in that they all can be used both as transitives and intransitives. Therefore, argument structure alone does not distinguish the classes, and subcategorization information is refined by thematic relations. Merlo and Stevenson defined verb features based on linguistic heuristics that describe the thematic relations between subject and object in transitive and intransitive verb usage. The features included heuristics for transitivity, causativity, animacy, and syntactic features. For example, the degree of animacy of the subject argument roles was estimated as the ratio of occurrences of pronouns to all subjects for each verb, based on the assumption that unaccusatives occur less frequently with an animate subject compared to unergative and object-drop verbs. Each verb was described by a five-feature vector, and the vector descriptions were fed into a decision tree algorithm. Compared with a baseline performance of 33.9%, the decision trees classified the verbs into the three classes with an accuracy of 69.8%. Further experiments demonstrated the contribution of the different features within the classification. Compared to the current article, Merlo and Stevenson (2001) performed a simpler task and classified a smaller number of 60 verbs into only three classes. The features of the verbs were restricted to those that should capture the basic differences between the verb classes, in line with the idea that the feature choice depends on the specific properties of the desired verb classes. But using the same classification methodology for a large-scale experiment with an enlarged number of verbs and classes faces more problems. For example, Joanis (2002) reported an extension of their work that used 802 verbs from 14 classes from Levin (1993). He defined an extensive feature space with 219 core features (such as part of speech, auxiliary frequency, syntactic categories, and animacy as above) and 1,140 selectional preference features taken from WordNet. As in Schulte im Walde (2000), the selectional preferences did not improve the clustering. In recent work, Stevenson and Joanis (2003) compared their supervised method for verb classification with semisupervised and unsupervised techniques. In these experiments, they enlarged the number of gold standard English verb classes to 14 classes related to Levin classes, with a total of 841 verbs. Lowfrequency and ambiguous verbs were excluded from the classes. They found that a semisupervised approach where the classifier was trained with five seed verbs from each verb class outperformed both a manual selection of features and the unsupervised 186 Schulte im Walde Induction of German Semantic Verb Classes approach of Dash, Liu, and Yao (1997), which used an entropy measure to organize data into a multidimensional space. The classification methodology from Merlo and Stevenson (2001) was applied to multilinguality by Merlo et al. (2002) and Tsang, Stevenson, and Merlo (2002). Merlo et al. (2002) showed that the classification paradigm is applicable in languages other than English by using the same features as defined by Merlo and Stevenson (2001) for the respective classification of 59 Italian verbs empirically based on the Parole corpus. The resulting accuracy is 86.4%. In addition, they used the content of Chinese verb features to refine the English verb classification, explained in more detail by Tsang, Stevenson, and Merlo (2002). The English verbs were manually translated into Chinese and given part-of-speech tag features, passive particles, causative particles, and sublexical morphemic properties. Verb tags and particles in Chinese are overt expressions of semantic information that is not expressed as clearly in English, and the multilingual set of features outperformed either set of monolingual features, yielding an accuracy of 83.5%. Pereira, Tishby, and Lee (1993) describe a hierarchical soft clustering method that clusters words according to their distribution in particular syntactic contexts. They used an application of their method to nouns appearing as direct objects of verbs. The clustering result was a hierarchy of noun clusters, where every noun belongs to every cluster with a membership probability. The initial data for the clustering process were frequencies of verb–noun pairs in a direct object relationship, as extracted from parsed sentences from the Associated Press news wire corpus. On the basis of the conditional verb–noun probabilities, the similarity of the distributions was determined by the Kullback–Leibler divergence. The EM algorithm (Baum 1972) was used to learn the hidden cluster membership probabilities, and deterministic annealing performed the divisive hierarchical clustering. The resulting class-based model can be utilized for estimating information for unseen events (cf. Dagan, Lee, and Pereira 1999). Rooth et al. (1999) produced soft semantic clusters for English that represent a classification on verbs as well as on nouns. They gathered distributional data for verb–noun pairs in specific grammatical relations from the British National Corpus. The extraction was based on a lexicalized probabilistic context-free grammar (Carroll and Rooth 1998) and contained the subject and object nouns for all intransitive and transitive verbs in the parses—a total of 608,850 verb–noun types. Conditioning of the verbs and the nouns on each other was done through hidden classes, and the joint probabilities of classes, verbs, and nouns were trained by the EM algorithm. The resulting model defined conditional membership probabilities for each verb and noun in each class; for example, the class of action contains the most probable verbs nod, think, shape, smile most probable nouns Ruth, Corbett, doctor, The semantic classes were utilized for the induction of a semantically annotated verb lexicon. 6. Conclusion and Outlook This article presented a clustering methodology for German verbs whose results agreed with a manual classification in many respects and should prove useful as automatic basis for a large-scale clustering. Without a doubt the cluster analysis needs manual correction and completion, but represents a plausible foundation. Key issues of the clustering methodology concern linguistic criteria on the one hand, and technical criteria on the other hand. The strategy of utilizing subcategorization frames, prepositional information, and selectional preferences to define the verb features seems promising, 187 Computational Linguistics Volume 32, Number 2 since the experiments illustrated a relation between the induced verb behavior and the membership of the semantic verb classes. In addition, each level of representation generated a positive effect on the clustering and improved upon the less informative level. The experiments presented evidence for a linguistic limit on the usefulness of the verb features: The meaning of verbs comprises both (1) properties that are general for the respective verb classes and (2) idiosyncratic properties that distinguish the verbs from each other. As long as we define the verbs by those properties that represent the common parts of the verb classes, a clustering can succeed. But by stepwise refining the verb description and including lexical idiosyncrasy, emphasis on the common properties vanishes. From the theoretical point of view, the distinction between common and idiosyncratic features is obvious. But from the practical point of view, feature choice then depends on the definition of the verb classes, and this definition might vary according to the conceptual level and also according to the kind of semantic coherence captured by the class. So far, we have concentrated on synonymy, but the large-scale experiment, in particular, discovered additional semantic relations within a verb class, such as participation in a process/script. However, the investigated feature combination within this article seems to be a useful starting point for verb description. We investigated the relationship between clustering idea, clustering parameters, and clustering result in order to develop a clustering methodology that is suitable for the demands of natural language. The clustering initialization played an role: needed compact, similarly-sized clusters in order to achieve a linguistically meaningful classification. The linguistically most successful initial clusters were therefore based on hierarchical clustering with complete linkage or Ward’s method, as the resulting clusters are comparable in size and correspond to compact cluster shapes. The hierarchical clustering achieved more similar clustering outputs which is due to the similarity of the clustering methods with respect to the common clustering criterion of optimizing the sum of distances between verbs and cluster centroids. The similarity measure used in the clustering experiments proved to be of secondary importance, since the differences in clustering due to varying the measure were negligible. For larger object and feature sets, Kullback–Leibler variants tended to outperform other measures, confirming language-based results on distributional similarity (Lee 2001). Both frequencies and probabilities represented a useful basis for the verb distributions. The number of clusters played a role concerning the magnitude of numbers: Inducing fine-grained clusters as given in the manual classification proved to be an ambitious goal because the feature distinction for the classes was also finegrained. Inducing coarse clusters provided a coarse classification that was subject to less noise and easier to manually correct. The “optimal” number of clusters is always a compromise and depends on the purpose of the classes, for example, as a fine-grained lexical resource, or for an NLP application. In the latter case, the optimal number should be determined by automatic means, that is, by trying different magnitudes of cluster numbers, because the level of generalization depends on the purpose for the abstraction. There are various directions for future research. (1) The manual definition of the German semantic verb classes will be extended in order to include a greater number and a larger variety of verb classes. An extended classification would be useful as a gold standard for further clustering experiments, and more generally as a resource for NLP applications. (2) Low-frequency verbs require a specific handling in the clustering procedure: Both the small-scale and the large-scale experiments showed that the lowfrequency verbs have a negative impact on the cluster coherence. An alternative model for the low-frequency verbs might, for example, first take out of the cluster analysis 188 Schulte im Walde Induction of German Semantic Verb Classes those verbs below a certain frequency cutoff, and then assign the left-out verbs to the nearest clusters. The cluster assignment should also be special, for example, using verb features restricted to the reliable features, that is, above a certain frequency threshold. example, if we consider the features of the low-frequency verb (frequency: 31) with a minimum feature frequency of 2, we get a strong overlap with the features of the verb Future work will address these issues. (3) Possible features for describing German verbs will include any kind of information that helps to classify the verbs in a semantically appropriate way. Within this article, we concentrated on defining the verb features with respect to alternation behavior. Other features that are relevant for describing the behavior of verbs are their auxiliary selection and adverbial combinations. In addition, if we try to address additional types of semantic verb relations such as script-based relations, we will need to extend our features. For example, Schulte im Walde and Melinger (2005) recently showed that nouns in co-occurrence windows of verbs contribute to verb descriptions by encoding scene information, rather than intrasentential functions. They proposed the integration of window-based approaches into function-based approaches, a combination that has not yet been applied. (4) Variations in the existing feature description are especially relevant for the choice of selectional preferences. The experiment results demonstrated that the 15 conceptual GermaNet top levels are not sufficient for all verbs. For example, verbs a finer version of selectional preferences in order to be distinguished. It is worthwhile either to find a more appropriate level of selectional preferences in WordNet or to apply a more sophisticated approach towards selectional preferences such as that of Li and Abe (1998), in order to determine a more flexible choice of selectional preferences. (5) With respect to a large-scale classification of verbs, it will be interesting to apply classification techniques to the verb data. This would require more data manually labeled with classes in order to train a classifier. But the classifier might abstract better than over the different requirements of the verb classes with respect to the feature description. (6) As an extension of the existing clustering, a soft clustering algorithm will be applied to the German verbs. Soft clustering enables us to assign verbs to multiple clusters and therefore address the phenomenon of verb ambiguity. These clustering outcomes should be even more useful for discovering new verb meaning components and semantically related classes, compared with the hard clustering technique. (7) The verb clusters as resulting from the cluster analysis will be used within an NLP application in order to prove the usefulness of the clusters. For example, replacing verbs in a language model by the respective verb classes might improve the language model’s robustness and accuracy, as the class information provides more stable syntactic and semantic information than the individual verbs. Appendix A: Subcategorization Frame Types The syntactic part of the German verb behavior is captured by 38 subcategorization frame types. The frames comprise maximally three arguments. Possible arguments are nominative (n), dative (d) and accusative (a) noun phrases, reflexive pronouns prepositional phrases (p), expletive subordinated non-finite clauses (i), subfinite clauses (s-2 for verb second clauses, s-dass for s-ob for s-w for indirect and copula constructions (k). The resulting frame types are listed in Table A.1, accompanied by annotated verb–second example clauses. The German examples are provided with English glosses; in cases where the glosses are difficult to understand, an English translation is added. 189 Computational Linguistics Volume 32, Number 2 Table A1 Subcategorization frame types. Frame Type Example Natalie swims Hans sees his girlfriend He believes the people not achten watch out besonders especially for children The drivers tolles Anna promises her father a great present the thief hindert keeps the audience dankt thanks from stealing sein for their understanding The saleslady The moderator versucht tries immer, always zu in time to arrive My friend ‘My friend always tries to arrive in time.’ Lied He hears his mother a song ‘He hears his mother singing a song.’ Helene verspricht promises her grandfather bald zu him soon to visit f¨urchten are afraid themselves The children The businessman erhofft hopes himself quick progress 10 Jahren wieder She associates herself after 10 years again the church with hat has himself der Kirche to the church worthy erwiesen. proven The pastor alte stellt imagines herself den Preis zu the price to win The old women It lightenings There exist many books It terrifies me 190 Schulte im Walde Induction of German Semantic Verb Classes Table A1 (cont.) Frame Type Example einen tollen Preis f¨ur mein It is about a great price for my sofa It calculates itself ‘It is worth it.’ Thomas sehr schlau It says, that Thomas very intelligent is hat has gesagt, said, The professor halte bald einen he gives soon a talk schnauzt bawls him an, out, sei ein he is an idiot The chef sie sei zu krank zum He tells his girlfriend, she is too ill to work hat has schon already angek¨undigt, announced, er bald that it soon arrives Winter The boy himself, M¨adchen bliebe bei the girl stays with him wishes The father fordert requests his daughter sie that she travels dass er verheiratet He tells his lover, that he married is The boy himself, seine Mutter that his mother stays wishes hat has gefragt, asked, die neue Forscherin interessant whether the new researcher interesting is The professor ob sie ihn Anton asks his wife, whether she him loves ruft shouts the woman sie whether she travels The neighbor wird will himself erinnern, remember, das M¨adchen dort whether the girl there was The old man hat has gefragt, asked, die Tante endlich when the aunt finally arrives The boy warum sie ihn The man asks his girlfriend, why she him loves The father his daughter zu Besuch not, who for a visit comes ¨at verr tells erinnert remembers herself, zu Besuch who for a visit comes The girl neue ist is ein a ziemlicher complete Idiot. idiot The new neighbor ¨unscht ¨unscht 191 Computational Linguistics Volume 32, Number 2 Acknowledgments The work reported here was performed while the author was a member of the DFG-funded PhD program “Graduierten- Repr¨asentationen und ihre the Institute for Natural</abstract>
<degree confidence="0.28389">Language Processing (IMS), University of Stuttgart, Germany. Many thanks to Helmut Schmid, Stefan Evert, Frank Keller, Scott McDonald, Alissa Melinger, Chris Brew,</degree>
<abstract confidence="0.9382">Hinrich Sch¨utze, Jonas Kuhn, and the two anonymous reviewers for their valuable comments on previous versions of this article.</abstract>
<note confidence="0.885069333333333">References Baker, Collin F., Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley Project. In of the 17th International Conference on Computational Linguistics and the 36th Annual Meeting of Association for Computational pages 86–90, Montreal, Canada. Baum, Leonard E. 1972. An inequality and</note>
<abstract confidence="0.854324">associated maximization technique in statistical estimation for probabilistic of Markov processes.</abstract>
<note confidence="0.64690625">III:1–8. Carroll, Glenn and Mats Rooth. 1998. Valence induction with a head-lexicalized PCFG. of the 3rd Conference on</note>
<affiliation confidence="0.749561">Empirical Methods in Natural Language</affiliation>
<address confidence="0.879694">Granada, Spain. Charniak, Eugene. 1997. Statistical parsing</address>
<abstract confidence="0.748096714285714">with a context-free grammar and word In of the 14th National on Artificial Menlo Park, CA. Chen, Stanley and Joshua Goodman. 1998. An empirical study of smoothing techniques for language modeling.</abstract>
<pubnum confidence="0.705859">Technical Report TR-10-98, Center for</pubnum>
<affiliation confidence="0.955996">Research in Computing Technology, Harvard University.</affiliation>
<address confidence="0.55567">Cover, Thomas M. and Joy A. Thomas. 1991.</address>
<affiliation confidence="0.275579">of Information Telecommunications. John Wiley &amp; Sons,</affiliation>
<address confidence="0.554735666666667">New York. Dagan, Ido, Lillian Lee, and Fernando Pereira. 1999. Similarity-based models of</address>
<abstract confidence="0.92091847368421">cooccurrence probabilities. 34(1–3):43–69. Special Issue on Natural Language Learning. Dash, Manoranjan, Hua Liu, and Jun Yao. 1997. Dimensionality reduction for data. In of the 9th International Conference on Tools with pages 532–539, Newport Beach, CA. Dorr, Bonnie J. 1997. Large-scale dictionary construction for foreign language tutoring and interlingual machine translation. 12(4):271–322. Dorr, Bonnie J. and Doug Jones. 1996. Role of word sense disambiguation in lexical acquisition: Predicting semantics syntactic cues. In of the 16th International Conference on pages 322–327,</abstract>
<address confidence="0.935199">Copenhagen, Denmark.</address>
<note confidence="0.8404124">Erk, Katrin, Andrea Kowalski, and Manfred Pinkal. 2003. A corpus resource lexical semantics. In of the 5th International Workshop on Tilburg, The Netherlands. Fellbaum, Christiane, editor. 1998. Electronic Lexical Language, Speech, and Communication. MIT Press, Cambridge, MA. Fillmore, Charles J. 1977. Scenes-and-frames semantics. In Antonio Zampolli, editor, Structures volume 59 Studies in Computer North Holland Publishing, Amsterdam. Fillmore, Charles J. 1982. Frame Semantics. in the Morning pages 111–137, Hansin, Seoul, Korea. Thierry, editor. 2003. Frame volume 16(3) of</note>
<affiliation confidence="0.896951">Journal of Oxford University Press.</affiliation>
<address confidence="0.828196">Forgy, Edward W. 1965. Cluster analysis of</address>
<abstract confidence="0.750898333333333">multivariate data: Efficiency vs. interpretability of classifications. 21:768–780. Hamp, Birgit and Helmut Feldweg. 1997. GermaNet—A lexical-semantic for German. In of the</abstract>
<title confidence="0.732606">ACL Workshop on Automatic Information</title>
<author confidence="0.404024">Extraction</author>
<author confidence="0.404024">Building Lexical Semantic</author>
<affiliation confidence="0.702319">for NLP Madrid,</affiliation>
<address confidence="0.691512">Spain.</address>
<note confidence="0.733106294117647">Harris, Zellig. 1968. Distributional structure. Jerold J. Katz, editor, Philosophy Oxford Readings in Philosophy. Oxford University Press, pages 26–47. Hatzivassiloglou, Vasileios and Kathleen R. McKeown. 1993. Towards the automatic identificaton of adjectival scales: Clustering adjectives according to In of the 31st Annual Meeting of the Association Computational pages 172–182, Columbus. Hubert, Lawrence and Phipps Arabie.1985. partitions. of 2:193–218. 192</note>
<title confidence="0.887829">Schulte im Walde Induction of German Semantic Verb Classes</title>
<author confidence="0.739827">Automatic verb</author>
<abstract confidence="0.828772">classification using a general feature space.</abstract>
<affiliation confidence="0.7071005">Master’s thesis, Department of Computer Science, University of Toronto.</affiliation>
<address confidence="0.865155">Kaufman, Leonard and Peter J. Rousseeuw.</address>
<author confidence="0.6106815">Groups in Data—An to Cluster Probability</author>
<affiliation confidence="0.53113">and Mathematical Statistics. John Wiley &amp;</affiliation>
<address confidence="0.318752">Sons, Inc., New York.</address>
<note confidence="0.978514">Klavans, Judith L. and Min-Yen Kan. 1998. The role of verbs in document analysis. In Proceedings of the 17th International on Computational pages 680–686, Montreal, Canada. Anna. 2002. Ph.D. thesis, University of</note>
<affiliation confidence="0.955973">Cambridge, Computer Laboratory.</affiliation>
<pubnum confidence="0.9505">Technical Report UCAM-CL-TR-530.</pubnum>
<note confidence="0.647601833333333">Korhonen, Anna, Yuval Krymolowski, and Zvika Marx. 2003. Clustering polysemic subcategorization frame distributions In of the 41st Annual Meeting of the Association for pages 64–71, Sapporo, Japan. Kunze, Claudia. 2000. Extension and use of GermaNet, a lexical-semantic database. In Proceedings of the 2nd International Conference Language Resources and pages 999–1002, Athens, Greece.</note>
<address confidence="0.363795">Lapata, Maria. 1999. Acquiring lexical</address>
<abstract confidence="0.902622454545455">generalizations from corpora: A case study diathesis alternations. In of the 37th Annual Meeting of the Association for pages 397–404, College Park, MD. Lapata, Mirella and Chris Brew. 2004. Verb class disambiguation using informative 30(1):45–73. Lee, Lillian. 2001. On the effectiveness of the skew divergence for statistical language In Intelligence and</abstract>
<note confidence="0.871484444444444">pages 65–72. Beth. 1993. Verb Classes and The University of Chicago Press. Li, Hang and Naoki Abe. 1998. Generalizing case frames using a thesaurus and the principle. 24(2):217–244. Diana. 2001. Acquisition at</note>
<title confidence="0.801483">the Syntax-Semantics Interface: Diathesis Alternations, Subcategorization Frames and</title>
<author confidence="0.87352">Ph D thesis</author>
<affiliation confidence="0.963515">University of Sussex.</affiliation>
<address confidence="0.856698">Merlo, Paola and Suzanne Stevenson. 2001.</address>
<abstract confidence="0.784314222222222">Automatic verb classification based on statistical distributions of argument 27(3):373–408. Merlo, Paola, Suzanne Stevenson, Vivian Tsang, and Gianluca Allaria. 2002. A multilingual paradigm for automatic classification. In of the 40th Annual Meeting of the Association for pages 207–214, Philadelphia, PA.</abstract>
<author confidence="0.6814645">George A Miller</author>
<author confidence="0.6814645">Richard Beckwith</author>
<author confidence="0.6814645">Christiane Fellbaum</author>
<author confidence="0.6814645">Derek Gross</author>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics and the 36th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>86--90</pages>
<location>Montreal, Canada.</location>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Baker, Collin F., Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of the 17th International Conference on Computational Linguistics and the 36th Annual Meeting of the Association for Computational Linguistics, pages 86–90, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard E Baum</author>
</authors>
<title>An inequality and associated maximization technique in statistical estimation for probabilistic functions of Markov processes. Inequalities,</title>
<date>1972</date>
<contexts>
<context position="92376" citStr="Baum 1972" startWordPosition="13985" endWordPosition="13986">rticular syntactic contexts. They used an application of their method to nouns appearing as direct objects of verbs. The clustering result was a hierarchy of noun clusters, where every noun belongs to every cluster with a membership probability. The initial data for the clustering process were frequencies of verb–noun pairs in a direct object relationship, as extracted from parsed sentences from the Associated Press news wire corpus. On the basis of the conditional verb–noun probabilities, the similarity of the distributions was determined by the Kullback–Leibler divergence. The EM algorithm (Baum 1972) was used to learn the hidden cluster membership probabilities, and deterministic annealing performed the divisive hierarchical clustering. The resulting class-based model can be utilized for estimating information for unseen events (cf. Dagan, Lee, and Pereira 1999). Rooth et al. (1999) produced soft semantic clusters for English that represent a classification on verbs as well as on nouns. They gathered distributional data for verb–noun pairs in specific grammatical relations from the British National Corpus. The extraction was based on a lexicalized probabilistic context-free grammar (Carro</context>
</contexts>
<marker>Baum, 1972</marker>
<rawString>Baum, Leonard E. 1972. An inequality and associated maximization technique in statistical estimation for probabilistic functions of Markov processes. Inequalities, III:1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glenn Carroll</author>
<author>Mats Rooth</author>
</authors>
<title>Valence induction with a head-lexicalized PCFG.</title>
<date>1998</date>
<booktitle>In Proceedings of the 3rd Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Granada,</location>
<contexts>
<context position="92994" citStr="Carroll and Rooth 1998" startWordPosition="14071" endWordPosition="14074">1972) was used to learn the hidden cluster membership probabilities, and deterministic annealing performed the divisive hierarchical clustering. The resulting class-based model can be utilized for estimating information for unseen events (cf. Dagan, Lee, and Pereira 1999). Rooth et al. (1999) produced soft semantic clusters for English that represent a classification on verbs as well as on nouns. They gathered distributional data for verb–noun pairs in specific grammatical relations from the British National Corpus. The extraction was based on a lexicalized probabilistic context-free grammar (Carroll and Rooth 1998) and contained the subject and object nouns for all intransitive and transitive verbs in the parses—a total of 608,850 verb–noun types. Conditioning of the verbs and the nouns on each other was done through hidden classes, and the joint probabilities of classes, verbs, and nouns were trained by the EM algorithm. The resulting model defined conditional membership probabilities for each verb and noun in each class; for example, the class of communicative action contains the most probable verbs ask, nod, think, shape, smile and the most probable nouns man, Ruth, Corbett, doctor, woman. The semant</context>
</contexts>
<marker>Carroll, Rooth, 1998</marker>
<rawString>Carroll, Glenn and Mats Rooth. 1998. Valence induction with a head-lexicalized PCFG. In Proceedings of the 3rd Conference on Empirical Methods in Natural Language Processing, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Statistical parsing with a context-free grammar and word statistics.</title>
<date>1997</date>
<booktitle>In Proceedings of the 14th National Conference on Artificial Intelligence,</booktitle>
<location>Menlo Park, CA.</location>
<contexts>
<context position="22316" citStr="Charniak (1997)" startWordPosition="3287" endWordPosition="3288">art of typesetting ... ends with a good book [E Der Informationstag] ... endet [T um 14 Uhr]. The information day ... finishes at 2pm 165 [P] [E Mit diesem ungerechten Krieg] muß sofort aufgeh¨ort werden. With this unjust war must immediately be stopped [T Vorher] d¨urfe [E mit der Aufl¨osung] nicht begonnen werden. Before must with the closing not be started 2.2 Empirical Distributions for German Verbs We developed, implemented, and trained a statistical grammar model for German that is based on the framework of head-lexicalized, probabilistic, context-free grammars. The idea originates from Charniak (1997), with this work using an implementation by Schmid (2000) for a training corpus of 35 million words from a collection of large German newspaper corpora from the 1990s, including Frankfurter Rundschau, Stuttgarter Zeitung, VDI-Nachrichten, die tageszeitung, German Law Corpus, Donaukurier, and Computerzeitung. The statistical grammar model provides empirical lexical information, specializing in but not restricted to the subcategorization behavior of verbs. Details of 166 [E mit den Umbauarbeiten] k¨onnte with the reconstruction work could pE : mit Und And angefangen werden. be begun Computationa</context>
</contexts>
<marker>Charniak, 1997</marker>
<rawString>Charniak, Eugene. 1997. Statistical parsing with a context-free grammar and word statistics. In Proceedings of the 14th National Conference on Artificial Intelligence, Menlo Park, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Chen</author>
<author>Joshua Goodman</author>
</authors>
<title>An empirical study of smoothing techniques for language modeling.</title>
<date>1998</date>
<tech>Technical Report TR-10-98,</tech>
<institution>Center for Research in Computing Technology, Harvard University.</institution>
<contexts>
<context position="34394" citStr="Chen and Goodman (1998)" startWordPosition="5134" endWordPosition="5137">-2 0.02 ns-w 0.01 n(Sache) 0.04 ns-w 0.01 ni 0.01 nd(Lebewesen) 0.04 ni 0.01 np:mitDat 0.01 nd(Nahrung) 0.02 nas-2 0.01 np:inDat 0.01 na(Attribut) 0.02 fahren n 0.34 n 0.34 n(Sache) 0.12 ‘drive’ np 0.29 na 0.19 n(Lebewesen) 0.10 na 0.19 np:inA,, 0.05 na(Lebewesen) 0.08 nap 0.06 nad 0.04 na(Sache) 0.06 nad 0.04 np:zuDat 0.04 n(Ort) 0.06 nd 0.04 nd 0.04 na(Sache) 0.05 ni 0.01 np:nachDat 0.04 np:inA,,(Sache) 0.02 ns-2 0.01 np:mitDat 0.03 np:zuDat(Sache) 0.02 ndp 0.01 np:inDat 0.03 np:inA,,(Lebewesen) 0.02 ns-w 0.01 np:aufDat 0.02 np:nachDat(Sache) 0.02 persuasive zero values and severe outliers. Chen and Goodman (1998) present a concise overview of smoothing techniques, with specific emphasis on language modeling. We decided to apply the smoothing algorithm referred to as additive smoothing: The smoothing is performed simply by adding 0.5 to all verb features, that is, the joint frequency of each verb v and feature xi is changed by freq&apos;(v,xi) = freq(v,xi) + 0.5. The total verb frequency is adapted to the changed feature values, representing the sum of all verb feature values: vfreql = Eifreq&apos;(v,xi). Smoothed probability values are based on the smoothed frequency distributions. 2.3 Clustering Algorithm and </context>
</contexts>
<marker>Chen, Goodman, 1998</marker>
<rawString>Chen, Stanley and Joshua Goodman. 1998. An empirical study of smoothing techniques for language modeling. Technical Report TR-10-98, Center for Research in Computing Technology, Harvard University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas M Cover</author>
<author>Joy A Thomas</author>
</authors>
<title>Elements of Information Theory.</title>
<date>1991</date>
<publisher>Telecommunications. John Wiley &amp; Sons,</publisher>
<location>New York.</location>
<contexts>
<context position="37935" citStr="Cover and Thomas 1991" startWordPosition="5668" endWordPosition="5671"> But which best fits the idea of verb similarity? Table 2 presents an overview of relevant similarity measures that are applied in the experiments. x and y refer to the verb object vectors, their subscripts to the verb feature values. The Minkowski metric can be applied to frequencies and probabilities. It is a generalization of the two well-known instances q = 1 (Manhattan distance) and q = 2 (Euclidean distance). The Kullback–Leibler divergence (KL) is a measure from information theory that determines the inefficiency of assuming a model probability distribution given the true distribution (Cover and Thomas 1991). The KL divergence is not defined in case yi = 0, so the probability distributions need to be smoothed. Two variants of KL, information radius and skew divergence, perform a default smoothing. Both variants can tolerate zero values in the distribution because they work with a weighted average of the two distributions compared. Lee (2001) has shown that the skew divergence is an effective measure for distributional similarity in NLP. Similarly to Lee’s method, we set the weight w for the skew divergence to 0.9. The cosine measures the similarity of the two object vectors x and y by calculating</context>
</contexts>
<marker>Cover, Thomas, 1991</marker>
<rawString>Cover, Thomas M. and Joy A. Thomas. 1991. Elements of Information Theory. Telecommunications. John Wiley &amp; Sons, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Lillian Lee</author>
<author>Fernando Pereira</author>
</authors>
<title>Similarity-based models of word cooccurrence probabilities.</title>
<date>1999</date>
<booktitle>Machine Learning, 34(1–3):43–69. Special Issue on Natural Language Learning.</booktitle>
<marker>Dagan, Lee, Pereira, 1999</marker>
<rawString>Dagan, Ido, Lillian Lee, and Fernando Pereira. 1999. Similarity-based models of word cooccurrence probabilities. Machine Learning, 34(1–3):43–69. Special Issue on Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manoranjan Dash</author>
<author>Hua Liu</author>
<author>Jun Yao</author>
</authors>
<title>Dimensionality reduction for unsupervised data.</title>
<date>1997</date>
<booktitle>In Proceedings of the 9th International Conference on Tools with Artificial Intelligence,</booktitle>
<pages>532--539</pages>
<location>Newport Beach, CA.</location>
<marker>Dash, Liu, Yao, 1997</marker>
<rawString>Dash, Manoranjan, Hua Liu, and Jun Yao. 1997. Dimensionality reduction for unsupervised data. In Proceedings of the 9th International Conference on Tools with Artificial Intelligence, pages 532–539, Newport Beach, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>Large-scale dictionary construction for foreign language tutoring and interlingual machine translation.</title>
<date>1997</date>
<journal>Machine Translation,</journal>
<volume>12</volume>
<issue>4</issue>
<contexts>
<context position="2481" citStr="Dorr 1997" startWordPosition="368" endWordPosition="369">ce redundancy in verb descriptions since they encode the common properties of verbs. On the other hand, verb classes can predict and refine properties of a verb that received insufficient empirical evidence, with reference to verbs in the same class: Under this criterion, a verb classification is especially useful for the pervasive problem of data sparseness in NLP, where little or no knowledge is provided for rare events. For example, the English verb classification by Levin (1993) has been used in NLP applications such as word sense disambiguation (Dorr and Jones 1996), machine translation (Dorr 1997), document classification (Klavans and Kan 1998), and subcategorization acquisition (Korhonen 2002). To my knowledge, no comparable German verb classification is available so far; therefore, such a classification would provide a principled basis for filling a gap in available lexical knowledge. * Department of Computational Linguistics, Saarbr¨ucken, Germany. E-mail: schulte@coli.uni-sb.de. Submission received:1 September 2003; revised submission received: 5 September 2005; accepted for publication: 10 November 2005. © 2006 Association for Computational Linguistics Computational Linguistics Vo</context>
</contexts>
<marker>Dorr, 1997</marker>
<rawString>Dorr, Bonnie J. 1997. Large-scale dictionary construction for foreign language tutoring and interlingual machine translation. Machine Translation, 12(4):271–322.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Doug Jones</author>
</authors>
<title>Role of word sense disambiguation in lexical acquisition: Predicting semantics from syntactic cues.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>322--327</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="2448" citStr="Dorr and Jones 1996" startWordPosition="362" endWordPosition="365">. 2000). On the one hand, verb classes reduce redundancy in verb descriptions since they encode the common properties of verbs. On the other hand, verb classes can predict and refine properties of a verb that received insufficient empirical evidence, with reference to verbs in the same class: Under this criterion, a verb classification is especially useful for the pervasive problem of data sparseness in NLP, where little or no knowledge is provided for rare events. For example, the English verb classification by Levin (1993) has been used in NLP applications such as word sense disambiguation (Dorr and Jones 1996), machine translation (Dorr 1997), document classification (Klavans and Kan 1998), and subcategorization acquisition (Korhonen 2002). To my knowledge, no comparable German verb classification is available so far; therefore, such a classification would provide a principled basis for filling a gap in available lexical knowledge. * Department of Computational Linguistics, Saarbr¨ucken, Germany. E-mail: schulte@coli.uni-sb.de. Submission received:1 September 2003; revised submission received: 5 September 2005; accepted for publication: 10 November 2005. © 2006 Association for Computational Linguis</context>
<context position="3813" citStr="Dorr and Jones 1996" startWordPosition="551" endWordPosition="554">of the verbs and the classes? Few resources are semantically annotated and provide semantic information off-the-shelf such as FrameNet (Baker, Fillmore, and Lowe 1998; Fontenelle 2003) and PropBank (Palmer, Gildea, and Kingsbury 2005). Instead, the automatic construction of semantic classes typically benefits from a longstanding linguistic hypothesis that asserts a tight connection between the lexical meaning of a verb and its behavior: To a certain extent, the lexical meaning of a verb determines its behavior, particularly with respect to the choice of its arguments (Pinker 1989; Levin 1993; Dorr and Jones 1996; Siegel and McKeown 2000; Merlo and Stevenson 2001; Schulte im Walde and Brew 2002; Lapata and Brew 2004). Even though the meaning–behavior relationship is not perfect, we can make this prediction: If we induce a verb classification on the basis of verb features describing verb behavior, then the resulting behavior classification should agree with a semantic classification to a certain extent (yet to be determined). The aim of this work is to utilize this prediction for the automatic acquisition of German semantic verb classes. The verb behavior itself is commonly captured by the diathesis al</context>
</contexts>
<marker>Dorr, Jones, 1996</marker>
<rawString>Dorr, Bonnie J. and Doug Jones. 1996. Role of word sense disambiguation in lexical acquisition: Predicting semantics from syntactic cues. In Proceedings of the 16th International Conference on Computational Linguistics, pages 322–327, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Andrea Kowalski</author>
<author>Manfred Pinkal</author>
</authors>
<title>A corpus resource for lexical semantics.</title>
<date>2003</date>
<booktitle>In Proceedings of the 5th International Workshop on Computational Semantics,</booktitle>
<location>Tilburg, The Netherlands.</location>
<marker>Erk, Kowalski, Pinkal, 2003</marker>
<rawString>Erk, Katrin, Andrea Kowalski, and Manfred Pinkal. 2003. A corpus resource for lexical semantics. In Proceedings of the 5th International Workshop on Computational Semantics, Tilburg, The Netherlands.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>WordNet—An Electronic Lexical Database. Language, Speech, and Communication.</booktitle>
<editor>Fellbaum, Christiane, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="34394" citStr="(1998)" startWordPosition="5137" endWordPosition="5137"> n(Sache) 0.04 ns-w 0.01 ni 0.01 nd(Lebewesen) 0.04 ni 0.01 np:mitDat 0.01 nd(Nahrung) 0.02 nas-2 0.01 np:inDat 0.01 na(Attribut) 0.02 fahren n 0.34 n 0.34 n(Sache) 0.12 ‘drive’ np 0.29 na 0.19 n(Lebewesen) 0.10 na 0.19 np:inA,, 0.05 na(Lebewesen) 0.08 nap 0.06 nad 0.04 na(Sache) 0.06 nad 0.04 np:zuDat 0.04 n(Ort) 0.06 nd 0.04 nd 0.04 na(Sache) 0.05 ni 0.01 np:nachDat 0.04 np:inA,,(Sache) 0.02 ns-2 0.01 np:mitDat 0.03 np:zuDat(Sache) 0.02 ndp 0.01 np:inDat 0.03 np:inA,,(Lebewesen) 0.02 ns-w 0.01 np:aufDat 0.02 np:nachDat(Sache) 0.02 persuasive zero values and severe outliers. Chen and Goodman (1998) present a concise overview of smoothing techniques, with specific emphasis on language modeling. We decided to apply the smoothing algorithm referred to as additive smoothing: The smoothing is performed simply by adding 0.5 to all verb features, that is, the joint frequency of each verb v and feature xi is changed by freq&apos;(v,xi) = freq(v,xi) + 0.5. The total verb frequency is adapted to the changed feature values, representing the sum of all verb feature values: vfreql = Eifreq&apos;(v,xi). Smoothed probability values are based on the smoothed frequency distributions. 2.3 Clustering Algorithm and </context>
<context position="100647" citStr="(1998)" startWordPosition="15216" endWordPosition="15216">a combination that has not yet been applied. (4) Variations in the existing feature description are especially relevant for the choice of selectional preferences. The experiment results demonstrated that the 15 conceptual GermaNet top levels are not sufficient for all verbs. For example, the verbs t¨oten and unterrichten require a finer version of selectional preferences in order to be distinguished. It is worthwhile either to find a more appropriate level of selectional preferences in WordNet or to apply a more sophisticated approach towards selectional preferences such as that of Li and Abe (1998), in order to determine a more flexible choice of selectional preferences. (5) With respect to a large-scale classification of verbs, it will be interesting to apply classification techniques to the verb data. This would require more data manually labeled with classes in order to train a classifier. But the resulting classifier might abstract better than k-means over the different requirements of the verb classes with respect to the feature description. (6) As an extension of the existing clustering, a soft clustering algorithm will be applied to the German verbs. Soft clustering enables us to</context>
</contexts>
<marker>1998</marker>
<rawString>Fellbaum, Christiane, editor. 1998. WordNet—An Electronic Lexical Database. Language, Speech, and Communication. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>Scenes-and-frames semantics.</title>
<date>1977</date>
<booktitle>Linguistic Structures Processing,</booktitle>
<volume>59</volume>
<editor>In Antonio Zampolli, editor,</editor>
<publisher>North Holland Publishing,</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="17652" citStr="Fillmore 1977" startWordPosition="2564" endWordPosition="2565">gual dictionary entries and corpus searches. Interannotator agreement has therefore not been addressed, but the classes were created in close relation to the English classification by Levin (1993) (as far as the English classes have German counterparts) and agree with the German verb classification by Schumacher (1986), as far as the relevant verbs are covered by his semantic ‘fields’. To overcome the drawback of a subjective class definition, the classification was accompanied by a detailed class description. This characterization is closely related to Fillmore’s scenes-and-frames semantics (Fillmore 1977, 1982), as computationally utilized in FrameNet (Baker, Fillmore, and Lowe 1998; Fontenelle 2003); there is no reference to the German FrameNet version (Erk, Kowalski, and Pinkal 2003)—as one might expect—just because the German version itself had just started to be developed. The frame-semantic class definition contains a prose scene description, predominant frame participant and modification roles, and frame variants describing the scene. The frame roles have been developed on the basis of a large German newspaper corpus from the 1990s (cf. Section 2.2). They capture the scene description w</context>
</contexts>
<marker>Fillmore, 1977</marker>
<rawString>Fillmore, Charles J. 1977. Scenes-and-frames semantics. In Antonio Zampolli, editor, Linguistic Structures Processing, volume 59 of Fundamental Studies in Computer Science. North Holland Publishing, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>Frame Semantics.</title>
<date>1982</date>
<booktitle>In Linguistics in the Morning Calm,</booktitle>
<pages>111--137</pages>
<location>Hansin, Seoul,</location>
<marker>Fillmore, 1982</marker>
<rawString>Fillmore, Charles J. 1982. Frame Semantics. In Linguistics in the Morning Calm, pages 111–137, Hansin, Seoul, Korea.</rawString>
</citation>
<citation valid="true">
<title>FrameNet and Frame Semantics,</title>
<date>2003</date>
<booktitle>of International Journal of Lexicography.</booktitle>
<volume>16</volume>
<issue>3</issue>
<editor>Fontenelle, Thierry, editor.</editor>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="89899" citStr="(2003)" startWordPosition="13615" endWordPosition="13615">But using the same classification methodology for a large-scale experiment with an enlarged number of verbs and classes faces more problems. For example, Joanis (2002) reported an extension of their work that used 802 verbs from 14 classes from Levin (1993). He defined an extensive feature space with 219 core features (such as part of speech, auxiliary frequency, syntactic categories, and animacy as above) and 1,140 selectional preference features taken from WordNet. As in Schulte im Walde (2000), the selectional preferences did not improve the clustering. In recent work, Stevenson and Joanis (2003) compared their supervised method for verb classification with semisupervised and unsupervised techniques. In these experiments, they enlarged the number of gold standard English verb classes to 14 classes related to Levin classes, with a total of 841 verbs. Lowfrequency and ambiguous verbs were excluded from the classes. They found that a semisupervised approach where the classifier was trained with five seed verbs from each verb class outperformed both a manual selection of features and the unsupervised 186 Schulte im Walde Induction of German Semantic Verb Classes approach of Dash, Liu, and</context>
</contexts>
<marker>2003</marker>
<rawString>Fontenelle, Thierry, editor. 2003. FrameNet and Frame Semantics, volume 16(3) of International Journal of Lexicography. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward W Forgy</author>
</authors>
<title>Cluster analysis of multivariate data: Efficiency vs. interpretability of classifications.</title>
<date>1965</date>
<journal>Biometrics,</journal>
<pages>21--768</pages>
<contexts>
<context position="7807" citStr="Forgy (1965)" startWordPosition="1205" endWordPosition="1206"> stepwise describe diathesis alternations: (1) syntactic structures, which are relevant for capturing argument functions; (2) prepositions, which are relevant to distinguish, for example, directions from locations; and (3) selectional preferences, which concern participant roles. A statistical grammar model serves as the source for an empirical verb description for the three levels at the syntax– semantics interface. Based on the empirical feature description, we then perform a cluster analysis of the German verbs using k-means, a standard unsupervised hard clustering technique as proposed by Forgy (1965). The clustering outcome cannot be a perfect semantic verb classification, since the meaning–behavior relationship on which the clustering relies is not perfect, and the clustering method is not perfect for the ambiguous verb data. However, our primary goal is not necessarily to obtain the optimal clustering result, but rather to assess the linguistic and technical conditions that are crucial for a semantic cluster analysis. More specifically, (1) we perform an empirical investigation of the relationship between verb meaning and verb behavior (that is, Can we use the meaning–behavior relations</context>
<context position="35614" citStr="Forgy (1965)" startWordPosition="5324" endWordPosition="5325">on Techniques Clustering is a standard procedure in multivariate data analysis. It is designed to allow exploration of the inherent natural structure of the data objects, where objects in the same cluster are as similar as possible and objects in different clusters are as dissimilar as possible. Equivalence classes induced by the clusters provide a means for 169 Computational Linguistics Volume 32, Number 2 generalizing over the data objects and their features. The clustering of the German verbs is performed by the k-means algorithm, a standard unsupervised clustering technique as proposed by Forgy (1965). With k-means, initial verb clusters are iteratively reorganized by assigning each verb to its closest cluster and recalculating cluster centroids until no further changes take place. Applying the k-means algorithm assumes (1) that verbs are represented by distributional vectors and (2) that verbs that are closer to each other in a mathematically defined way are also more similar to each other in a linguistic way. k-Means depends on the following parameters: (1) The number of clusters is not known beforehand, so the clustering experiments investigate this parameter. Related to this parameter </context>
</contexts>
<marker>Forgy, 1965</marker>
<rawString>Forgy, Edward W. 1965. Cluster analysis of multivariate data: Efficiency vs. interpretability of classifications. Biometrics, 21:768–780.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Birgit Hamp</author>
<author>Helmut Feldweg</author>
</authors>
<title>GermaNet—A lexical-semantic Net for German.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL Workshop on Automatic Information Extraction and Building Lexical Semantic Resources for NLP Applications,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="28412" citStr="Hamp and Feldweg 1997" startWordPosition="4231" endWordPosition="4234">ations in the form of lexical heads, with reference to a specific verb–frame–slot combination. Obviously, we would run into a sparse data problem if we tried to incorporate selectional preferences into the verb descriptions at such a specific level. We are provided with detailed information at the nominal level, but we need a generalization of the selectional preference definition. A widely used resource for selectional preference information is the semantic ontology WordNet (Miller et al. 1990; Fellbaum 1998); the University of T¨ubingen has developed the German version of WordNet, GermaNet (Hamp and Feldweg 1997; Kunze 2000). The hierarchy is realized by means of synsets, sets of synonymous nouns, which are organized by multiple inheritance hyponym/hypernym relationships. A noun can appear in several synsets, according to its number of senses. The German noun hierarchy in GermaNet is utilized for the generalization of selectional preferences: For each noun in a verb–frame–slot combination, the joint frequency is divided over the different senses of the noun and propagated up the hierarchy. In case of multiple hypernym 167 Computational Linguistics Volume 32, Number 2 synsets, the frequency is divided</context>
</contexts>
<marker>Hamp, Feldweg, 1997</marker>
<rawString>Hamp, Birgit and Helmut Feldweg. 1997. GermaNet—A lexical-semantic Net for German. In Proceedings of the ACL Workshop on Automatic Information Extraction and Building Lexical Semantic Resources for NLP Applications, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>Distributional structure. In</title>
<date>1968</date>
<booktitle>The Philosophy of Linguistics, Oxford Readings in Philosophy.</booktitle>
<pages>26--47</pages>
<editor>Jerold J. Katz, editor,</editor>
<publisher>Oxford University Press,</publisher>
<contexts>
<context position="25282" citStr="Harris 1968" startWordPosition="3771" endWordPosition="3772">anfangen, aufh¨oren, beginnen / ¬ beenden, enden nI Schulte im Walde Induction of German Semantic Verb Classes the implementation, training, and exploitation of the grammar model can be found in Schulte im Walde (2003a, chapter 3). The German verbs are represented by distributional vectors, with features and feature values in the distribution being acquired from the statistical grammar. The distributional description is based on the hypothesis that “each language can be described in terms of a distributional structure, that is, in terms of the occurrence of parts relative to other parts” (cf. Harris 1968). The verbs are described distributionally on three levels at the syntax–semantics interface, each level refining the previous level. The first level D1 encodes a purely syntactic definition of verb subcategorization, the second level D2 encodes a syntactico-semantic definition of subcategorization with prepositional preferences, and the third level D3 encodes a syntactico-semantic definition of subcategorization with prepositional and selectional preferences. Thus, the refinement of verb features starts with a purely syntactic definition and incrementally adds semantic information. The most e</context>
</contexts>
<marker>Harris, 1968</marker>
<rawString>Harris, Zellig. 1968. Distributional structure. In Jerold J. Katz, editor, The Philosophy of Linguistics, Oxford Readings in Philosophy. Oxford University Press, pages 26–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Towards the automatic identificaton of adjectival scales: Clustering adjectives according to meaning.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>172--182</pages>
<location>Columbus.</location>
<contexts>
<context position="39189" citStr="Hatzivassiloglou and McKeown (1993)" startWordPosition="5862" endWordPosition="5865">angle between the feature vectors. The cosine measure can be applied to frequency and probability values. For a detailed description of hierarchical clustering techniques and an intuitive interpretation of the similarity measures, the reader is referred to, for example, Kaufman and Rousseeuw (1990). There is no agreed standard method for evaluating clustering experiments and results, but a variety of evaluation measures from diverse areas such as theoretical statistics, machine vision, and Web-page clustering are generally applicable. We used the following two measures for the evaluation: (1) Hatzivassiloglou and McKeown (1993) define and evaluate a cluster analysis of adjectives, based on common cluster membership of object pairs in the clustering C and the manual classification M. Recall and precision numbers are calculated in the standard way, with true positives the number of common pairs in M and C, false positives the number of pairs in C, but not M, and false negatives the number of pairs in M, but not C. We use the f-score pairF (as harmonic mean between recall and precision), which provides an easy to understand 170 Schulte im Walde Induction of German Semantic Verb Classes Table 2 Data similarity measures.</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1993</marker>
<rawString>Hatzivassiloglou, Vasileios and Kathleen R. McKeown. 1993. Towards the automatic identificaton of adjectival scales: Clustering adjectives according to meaning. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, pages 172–182, Columbus.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lawrence Hubert</author>
<author>Phipps Arabie 1985</author>
</authors>
<title>Comparing partitions.</title>
<journal>Journal of Classification,</journal>
<pages>2--193</pages>
<marker>Hubert, 1985, </marker>
<rawString>Hubert, Lawrence and Phipps Arabie.1985. Comparing partitions. Journal of Classification, 2:193–218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Joanis</author>
</authors>
<title>Automatic verb classification using a general feature space.</title>
<date>2002</date>
<tech>Master’s thesis,</tech>
<institution>Department of Computer Science, University of Toronto.</institution>
<contexts>
<context position="4644" citStr="Joanis 2002" startWordPosition="682" endWordPosition="683">classification on the basis of verb features describing verb behavior, then the resulting behavior classification should agree with a semantic classification to a certain extent (yet to be determined). The aim of this work is to utilize this prediction for the automatic acquisition of German semantic verb classes. The verb behavior itself is commonly captured by the diathesis alternation of verbs: alternative constructions at the syntax–semantics interface that express the same or a similar conceptual idea of a verb (Lapata 1999; Schulte im Walde 2000; McCarthy 2001; Merlo and Stevenson 2001; Joanis 2002). Consider example (1), where the most common alternations of the Manner of Motion with a Vehicle verb fahren ‘drive’ are illustrated. The conceptual participants are a vehicle, a driver, a passenger, and a direction. In (a), the vehicle is expressed as the subject in a transitive verb construction, with a prepositional phrase indicating the direction. In (b), the driver is expressed as the subject in a transitive verb construction, with a prepositional phrase indicating the direction. In (c), the driver is expressed as the subject in a transitive verb construction, with an accusative noun phr</context>
<context position="84597" citStr="Joanis 2002" startWordPosition="12827" endWordPosition="12828"> glad’ and ¨argern ‘be annoyed’), and participation in a common process/script (e.g., bestellen ‘order’, kaufen ‘buy’, verkaufen ‘sell’, and abholen ‘pick up’). 5. Related Work The following paragraphs describe related classification and clustering experiments on the automatic induction of verb classes. The classifications refer to different class criteria, for example, aspectual properties (Siegel and McKeown 2000), syntactic categories (Merlo and Stevenson 2001; Merlo et al. 2002; Tsang, Stevenson, and Merlo 2002), and— most similar to my approach—semantic categories (Schulte im Walde 2000; Joanis 2002). The soft clustering approaches indicate how we might extend our hard clustering to verb ambiguity, now that we have determined the relevant set of verb features. Siegel and McKeown (2000) used three supervised and one unsupervised machinelearning algorithm to perform an automatic aspectual classification of English verbs. (1) For the supervised classification, 97,973 parsed sentences from medical discharge summaries were used to extract frequencies for verbs on 14 linguistic indicators, such as manner adverb, duration in PP, past tense, and perfect tense. Logistic regression, decision tree i</context>
<context position="89460" citStr="Joanis (2002)" startWordPosition="13545" endWordPosition="13546">tribution of the different features within the classification. Compared to the current article, Merlo and Stevenson (2001) performed a simpler task and classified a smaller number of 60 verbs into only three classes. The features of the verbs were restricted to those that should capture the basic differences between the verb classes, in line with the idea that the feature choice depends on the specific properties of the desired verb classes. But using the same classification methodology for a large-scale experiment with an enlarged number of verbs and classes faces more problems. For example, Joanis (2002) reported an extension of their work that used 802 verbs from 14 classes from Levin (1993). He defined an extensive feature space with 219 core features (such as part of speech, auxiliary frequency, syntactic categories, and animacy as above) and 1,140 selectional preference features taken from WordNet. As in Schulte im Walde (2000), the selectional preferences did not improve the clustering. In recent work, Stevenson and Joanis (2003) compared their supervised method for verb classification with semisupervised and unsupervised techniques. In these experiments, they enlarged the number of gold</context>
</contexts>
<marker>Joanis, 2002</marker>
<rawString>Joanis, Eric. 2002. Automatic verb classification using a general feature space. Master’s thesis, Department of Computer Science, University of Toronto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Kaufman</author>
<author>Peter J Rousseeuw</author>
</authors>
<title>Finding Groups in Data—An Introduction to Cluster Analysis. Probability and Mathematical Statistics.</title>
<date>1990</date>
<publisher>John Wiley &amp; Sons, Inc.,</publisher>
<location>New York.</location>
<contexts>
<context position="38853" citStr="Kaufman and Rousseeuw (1990)" startWordPosition="5815" endWordPosition="5818">rage of the two distributions compared. Lee (2001) has shown that the skew divergence is an effective measure for distributional similarity in NLP. Similarly to Lee’s method, we set the weight w for the skew divergence to 0.9. The cosine measures the similarity of the two object vectors x and y by calculating the cosine of the angle between the feature vectors. The cosine measure can be applied to frequency and probability values. For a detailed description of hierarchical clustering techniques and an intuitive interpretation of the similarity measures, the reader is referred to, for example, Kaufman and Rousseeuw (1990). There is no agreed standard method for evaluating clustering experiments and results, but a variety of evaluation measures from diverse areas such as theoretical statistics, machine vision, and Web-page clustering are generally applicable. We used the following two measures for the evaluation: (1) Hatzivassiloglou and McKeown (1993) define and evaluate a cluster analysis of adjectives, based on common cluster membership of object pairs in the clustering C and the manual classification M. Recall and precision numbers are calculated in the standard way, with true positives the number of common</context>
</contexts>
<marker>Kaufman, Rousseeuw, 1990</marker>
<rawString>Kaufman, Leonard and Peter J. Rousseeuw. 1990. Finding Groups in Data—An Introduction to Cluster Analysis. Probability and Mathematical Statistics. John Wiley &amp; Sons, Inc., New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith L Klavans</author>
<author>Min-Yen Kan</author>
</authors>
<title>The role of verbs in document analysis.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics,</booktitle>
<pages>680--686</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="2529" citStr="Klavans and Kan 1998" startWordPosition="372" endWordPosition="375">nce they encode the common properties of verbs. On the other hand, verb classes can predict and refine properties of a verb that received insufficient empirical evidence, with reference to verbs in the same class: Under this criterion, a verb classification is especially useful for the pervasive problem of data sparseness in NLP, where little or no knowledge is provided for rare events. For example, the English verb classification by Levin (1993) has been used in NLP applications such as word sense disambiguation (Dorr and Jones 1996), machine translation (Dorr 1997), document classification (Klavans and Kan 1998), and subcategorization acquisition (Korhonen 2002). To my knowledge, no comparable German verb classification is available so far; therefore, such a classification would provide a principled basis for filling a gap in available lexical knowledge. * Department of Computational Linguistics, Saarbr¨ucken, Germany. E-mail: schulte@coli.uni-sb.de. Submission received:1 September 2003; revised submission received: 5 September 2005; accepted for publication: 10 November 2005. © 2006 Association for Computational Linguistics Computational Linguistics Volume 32, Number 2 How can we obtain a semantic c</context>
</contexts>
<marker>Klavans, Kan, 1998</marker>
<rawString>Klavans, Judith L. and Min-Yen Kan. 1998. The role of verbs in document analysis. In Proceedings of the 17th International Conference on Computational Linguistics, pages 680–686, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
</authors>
<title>Subcategorization Acquisition.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge, Computer Laboratory.</institution>
<contexts>
<context position="2580" citStr="Korhonen 2002" startWordPosition="380" endWordPosition="381">er hand, verb classes can predict and refine properties of a verb that received insufficient empirical evidence, with reference to verbs in the same class: Under this criterion, a verb classification is especially useful for the pervasive problem of data sparseness in NLP, where little or no knowledge is provided for rare events. For example, the English verb classification by Levin (1993) has been used in NLP applications such as word sense disambiguation (Dorr and Jones 1996), machine translation (Dorr 1997), document classification (Klavans and Kan 1998), and subcategorization acquisition (Korhonen 2002). To my knowledge, no comparable German verb classification is available so far; therefore, such a classification would provide a principled basis for filling a gap in available lexical knowledge. * Department of Computational Linguistics, Saarbr¨ucken, Germany. E-mail: schulte@coli.uni-sb.de. Submission received:1 September 2003; revised submission received: 5 September 2005; accepted for publication: 10 November 2005. © 2006 Association for Computational Linguistics Computational Linguistics Volume 32, Number 2 How can we obtain a semantic classification of verbs while avoiding tedious manua</context>
</contexts>
<marker>Korhonen, 2002</marker>
<rawString>Korhonen, Anna. 2002. Subcategorization Acquisition. Ph.D. thesis, University of Cambridge, Computer Laboratory. Technical Report UCAM-CL-TR-530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
<author>Yuval Krymolowski</author>
<author>Zvika Marx</author>
</authors>
<title>Clustering polysemic subcategorization frame distributions semantically.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>64--71</pages>
<location>Sapporo, Japan.</location>
<marker>Korhonen, Krymolowski, Marx, 2003</marker>
<rawString>Korhonen, Anna, Yuval Krymolowski, and Zvika Marx. 2003. Clustering polysemic subcategorization frame distributions semantically. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 64–71, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Kunze</author>
</authors>
<title>Extension and use of GermaNet, a lexical-semantic database.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd International Conference on Language Resources and Evaluation,</booktitle>
<pages>999--1002</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="28425" citStr="Kunze 2000" startWordPosition="4235" endWordPosition="4236">exical heads, with reference to a specific verb–frame–slot combination. Obviously, we would run into a sparse data problem if we tried to incorporate selectional preferences into the verb descriptions at such a specific level. We are provided with detailed information at the nominal level, but we need a generalization of the selectional preference definition. A widely used resource for selectional preference information is the semantic ontology WordNet (Miller et al. 1990; Fellbaum 1998); the University of T¨ubingen has developed the German version of WordNet, GermaNet (Hamp and Feldweg 1997; Kunze 2000). The hierarchy is realized by means of synsets, sets of synonymous nouns, which are organized by multiple inheritance hyponym/hypernym relationships. A noun can appear in several synsets, according to its number of senses. The German noun hierarchy in GermaNet is utilized for the generalization of selectional preferences: For each noun in a verb–frame–slot combination, the joint frequency is divided over the different senses of the noun and propagated up the hierarchy. In case of multiple hypernym 167 Computational Linguistics Volume 32, Number 2 synsets, the frequency is divided again. The s</context>
</contexts>
<marker>Kunze, 2000</marker>
<rawString>Kunze, Claudia. 2000. Extension and use of GermaNet, a lexical-semantic database. In Proceedings of the 2nd International Conference on Language Resources and Evaluation, pages 999–1002, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Lapata</author>
</authors>
<title>Acquiring lexical generalizations from corpora: A case study for diathesis alternations.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>397--404</pages>
<location>College Park, MD.</location>
<contexts>
<context position="4566" citStr="Lapata 1999" startWordPosition="670" endWordPosition="671">elationship is not perfect, we can make this prediction: If we induce a verb classification on the basis of verb features describing verb behavior, then the resulting behavior classification should agree with a semantic classification to a certain extent (yet to be determined). The aim of this work is to utilize this prediction for the automatic acquisition of German semantic verb classes. The verb behavior itself is commonly captured by the diathesis alternation of verbs: alternative constructions at the syntax–semantics interface that express the same or a similar conceptual idea of a verb (Lapata 1999; Schulte im Walde 2000; McCarthy 2001; Merlo and Stevenson 2001; Joanis 2002). Consider example (1), where the most common alternations of the Manner of Motion with a Vehicle verb fahren ‘drive’ are illustrated. The conceptual participants are a vehicle, a driver, a passenger, and a direction. In (a), the vehicle is expressed as the subject in a transitive verb construction, with a prepositional phrase indicating the direction. In (b), the driver is expressed as the subject in a transitive verb construction, with a prepositional phrase indicating the direction. In (c), the driver is expressed</context>
</contexts>
<marker>Lapata, 1999</marker>
<rawString>Lapata, Maria. 1999. Acquiring lexical generalizations from corpora: A case study for diathesis alternations. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 397–404, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Chris Brew</author>
</authors>
<title>Verb class disambiguation using informative priors.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="3919" citStr="Lapata and Brew 2004" startWordPosition="569" endWordPosition="572">off-the-shelf such as FrameNet (Baker, Fillmore, and Lowe 1998; Fontenelle 2003) and PropBank (Palmer, Gildea, and Kingsbury 2005). Instead, the automatic construction of semantic classes typically benefits from a longstanding linguistic hypothesis that asserts a tight connection between the lexical meaning of a verb and its behavior: To a certain extent, the lexical meaning of a verb determines its behavior, particularly with respect to the choice of its arguments (Pinker 1989; Levin 1993; Dorr and Jones 1996; Siegel and McKeown 2000; Merlo and Stevenson 2001; Schulte im Walde and Brew 2002; Lapata and Brew 2004). Even though the meaning–behavior relationship is not perfect, we can make this prediction: If we induce a verb classification on the basis of verb features describing verb behavior, then the resulting behavior classification should agree with a semantic classification to a certain extent (yet to be determined). The aim of this work is to utilize this prediction for the automatic acquisition of German semantic verb classes. The verb behavior itself is commonly captured by the diathesis alternation of verbs: alternative constructions at the syntax–semantics interface that express the same or a</context>
</contexts>
<marker>Lapata, Brew, 2004</marker>
<rawString>Lapata, Mirella and Chris Brew. 2004. Verb class disambiguation using informative priors. Computational Linguistics, 30(1):45–73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lillian Lee</author>
</authors>
<title>On the effectiveness of the skew divergence for statistical language analysis.</title>
<date>2001</date>
<booktitle>In Artificial Intelligence and Statistics,</booktitle>
<pages>65--72</pages>
<contexts>
<context position="38275" citStr="Lee (2001)" startWordPosition="5725" endWordPosition="5726">stances q = 1 (Manhattan distance) and q = 2 (Euclidean distance). The Kullback–Leibler divergence (KL) is a measure from information theory that determines the inefficiency of assuming a model probability distribution given the true distribution (Cover and Thomas 1991). The KL divergence is not defined in case yi = 0, so the probability distributions need to be smoothed. Two variants of KL, information radius and skew divergence, perform a default smoothing. Both variants can tolerate zero values in the distribution because they work with a weighted average of the two distributions compared. Lee (2001) has shown that the skew divergence is an effective measure for distributional similarity in NLP. Similarly to Lee’s method, we set the weight w for the skew divergence to 0.9. The cosine measures the similarity of the two object vectors x and y by calculating the cosine of the angle between the feature vectors. The cosine measure can be applied to frequency and probability values. For a detailed description of hierarchical clustering techniques and an intuitive interpretation of the similarity measures, the reader is referred to, for example, Kaufman and Rousseeuw (1990). There is no agreed s</context>
<context position="97070" citStr="Lee 2001" startWordPosition="14671" endWordPosition="14672"> The hierarchical clustering achieved more similar clustering outputs than k-means, which is due to the similarity of the clustering methods with respect to the common clustering criterion of optimizing the sum of distances between verbs and cluster centroids. The similarity measure used in the clustering experiments proved to be of secondary importance, since the differences in clustering due to varying the measure were negligible. For larger object and feature sets, Kullback–Leibler variants tended to outperform other measures, confirming language-based results on distributional similarity (Lee 2001). Both frequencies and probabilities represented a useful basis for the verb distributions. The number of clusters played a role concerning the magnitude of numbers: Inducing fine-grained clusters as given in the manual classification proved to be an ambitious goal because the feature distinction for the classes was also finegrained. Inducing coarse clusters provided a coarse classification that was subject to less noise and easier to manually correct. The “optimal” number of clusters is always a compromise and depends on the purpose of the classes, for example, as a fine-grained lexical resou</context>
</contexts>
<marker>Lee, 2001</marker>
<rawString>Lee, Lillian. 2001. On the effectiveness of the skew divergence for statistical language analysis. In Artificial Intelligence and Statistics, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations.</title>
<date>1993</date>
<publisher>The University of Chicago Press.</publisher>
<contexts>
<context position="1767" citStr="Levin 1993" startWordPosition="255" endWordPosition="256">t is, they capture large amounts of verb meaning without defining the idiosyncratic details for each verb. The classes refer to a general semantic level, and idiosyncratic lexical semantic properties of the verbs are either added to the class description or left underspecified. Examples for semantic verb classes are Position verbs such as liegen ‘lie’, sitzen ‘sit’, stehen ‘stand’, and Manner of Motion with a Vehicle verbs such as fahren ‘drive’, fliegen ‘fly’, rudern ‘row’. Manual definitions of semantic verb classes exist for several languages, the most dominant examples concerning English (Levin 1993; Baker, Fillmore, and Lowe 1998) and Spanish (V´azquez et al. 2000). On the one hand, verb classes reduce redundancy in verb descriptions since they encode the common properties of verbs. On the other hand, verb classes can predict and refine properties of a verb that received insufficient empirical evidence, with reference to verbs in the same class: Under this criterion, a verb classification is especially useful for the pervasive problem of data sparseness in NLP, where little or no knowledge is provided for rare events. For example, the English verb classification by Levin (1993) has been</context>
<context position="3792" citStr="Levin 1993" startWordPosition="549" endWordPosition="550">definitions of the verbs and the classes? Few resources are semantically annotated and provide semantic information off-the-shelf such as FrameNet (Baker, Fillmore, and Lowe 1998; Fontenelle 2003) and PropBank (Palmer, Gildea, and Kingsbury 2005). Instead, the automatic construction of semantic classes typically benefits from a longstanding linguistic hypothesis that asserts a tight connection between the lexical meaning of a verb and its behavior: To a certain extent, the lexical meaning of a verb determines its behavior, particularly with respect to the choice of its arguments (Pinker 1989; Levin 1993; Dorr and Jones 1996; Siegel and McKeown 2000; Merlo and Stevenson 2001; Schulte im Walde and Brew 2002; Lapata and Brew 2004). Even though the meaning–behavior relationship is not perfect, we can make this prediction: If we induce a verb classification on the basis of verb features describing verb behavior, then the resulting behavior classification should agree with a semantic classification to a certain extent (yet to be determined). The aim of this work is to utilize this prediction for the automatic acquisition of German semantic verb classes. The verb behavior itself is commonly capture</context>
<context position="10541" citStr="Levin 1993" startWordPosition="1622" endWordPosition="1623">anslations in one class are too similar to distinguish among them, a common translation is given. Even though the classification is primarily based on semantic intuition and not on facts about syntactic behavior, the verbs grouped in one class share certain aspects of their behavior. (Please note that this overlap does not necessarily transfer to the English translations.) This agreement corresponds to the 161 Computational Linguistics Volume 32, Number 2 long-standing linguistic hypothesis that asserts a tight connection between the meaning components of a verb and its behavior (Pinker 1989; Levin 1993). The purpose of the manual classification is to evaluate the reliability and performance of the clustering experiments. The following facts refer to empirically relevant properties of the classification: The class size is between 2 and 7, with an average of 3.9 verbs per class. Eight verbs are ambiguous with respect to class membership and marked by subscripts. The classes include both high- and low-frequency verbs in order to exercise the clustering technology in both data-rich and data-poor situations: The corpus frequencies of the verbs range from 8 to 71,604 (within 35 million words of a </context>
<context position="17235" citStr="Levin (1993)" startWordPosition="2504" endWordPosition="2505">en (all: be based on) 41. Inference: folgern, schließen2 (conclude, infer) 42. Result: ergeben, erwachsen, folgen2, resultieren (all: follow/result) 43. Weather: blitzen, donnern, d¨ammern, nieseln, regnen, schneien (lightning, thunder, dawn, drizzle, rain, snow) The evidence used in the class creation process—including the choice of the verbs—was provided by subjective conceptual knowledge, monolingual and bilingual dictionary entries and corpus searches. Interannotator agreement has therefore not been addressed, but the classes were created in close relation to the English classification by Levin (1993) (as far as the English classes have German counterparts) and agree with the German verb classification by Schumacher (1986), as far as the relevant verbs are covered by his semantic ‘fields’. To overcome the drawback of a subjective class definition, the classification was accompanied by a detailed class description. This characterization is closely related to Fillmore’s scenes-and-frames semantics (Fillmore 1977, 1982), as computationally utilized in FrameNet (Baker, Fillmore, and Lowe 1998; Fontenelle 2003); there is no reference to the German FrameNet version (Erk, Kowalski, and Pinkal 200</context>
<context position="20637" citStr="Levin 1993" startWordPosition="3020" endWordPosition="3021">lling reform in 1998. Semantic verb classes have been defined for several languages, for example, as the earlier mentioned lexicographic resource FrameNet for English (Baker, Fillmore, and Lowe 1998; Fontenelle 2003) and German (Erk, Kowalski, and Pinkal 2003); the lexical semantic ontology WordNet for English (Miller et al. 1990; Fellbaum 1998); EuroWordNet (Vossen 2004) for Dutch, Italian, Spanish, French, German, Czech, and Estonian, and further languages as listed in WordNets in the World (Global WordNet Association, www.globalwordnet.org); syntax–semantics based verb classes for English (Levin 1993), Spanish (V´azquez et al. 2000), and French (Saint-Dizier 1998). Example 2 Aspect Verbs: anfangen, aufh¨oren, beenden, beginnen, enden Scene: [E An event] begins or ends, either internally caused or externally caused by [I an initiator]. The event may be specified with respect to [T tense], [L location], [X an experiencer], or [R a result]. Frame Roles: I(nitiator), E(vent) Modification Roles: T(emporal), L(ocal), (e)X(periencer), R(esult) Frame Participating Verbs and Corpus Examples + anfangen, aufh¨oren, beginnen / +adv enden / ¬ beenden nE muß must Nun Now aber though anfangen. begin [E d</context>
<context position="86659" citStr="Levin (1993)" startWordPosition="13141" endWordPosition="13142">asis of an evaluation of 19 verbs that their clustering algorithm discriminated 185 Computational Linguistics Volume 32, Number 2 event verbs from stative verbs. Overall, they performed a comparably simpler task than presented in this article, since the aspectual class criteria can be defined more objectively and more clearly than semantic criteria based on situational similarity. Their choice of features delimited their class criteria well, and they were able to achieve excellent results. In previous work on English, Schulte im Walde (2000) clustered 153 verbs into 30 verb classes taken from Levin (1993), using unsupervised hierarchical clustering. The verbs were described by distributions over subcategorization frames as extracted from maximum-probability parses using a robust statistical parser, and completed by assigning WordNet classes as selectional preferences to the frame arguments. Using Levin’s verb classification as a basis for evaluation, 61% of the verbs were classified correctly into semantic classes. The clustering was most successful when utilizing syntactic subcategorization frames enriched with PP information; selectional preferences decreased the performance of the clusterin</context>
<context position="89550" citStr="Levin (1993)" startWordPosition="13561" endWordPosition="13562">cle, Merlo and Stevenson (2001) performed a simpler task and classified a smaller number of 60 verbs into only three classes. The features of the verbs were restricted to those that should capture the basic differences between the verb classes, in line with the idea that the feature choice depends on the specific properties of the desired verb classes. But using the same classification methodology for a large-scale experiment with an enlarged number of verbs and classes faces more problems. For example, Joanis (2002) reported an extension of their work that used 802 verbs from 14 classes from Levin (1993). He defined an extensive feature space with 219 core features (such as part of speech, auxiliary frequency, syntactic categories, and animacy as above) and 1,140 selectional preference features taken from WordNet. As in Schulte im Walde (2000), the selectional preferences did not improve the clustering. In recent work, Stevenson and Joanis (2003) compared their supervised method for verb classification with semisupervised and unsupervised techniques. In these experiments, they enlarged the number of gold standard English verb classes to 14 classes related to Levin classes, with a total of 841</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Levin, Beth. 1993. English Verb Classes and Alternations. The University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Li</author>
<author>Naoki Abe</author>
</authors>
<title>Generalizing case frames using a thesaurus and the MDL principle.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>2</issue>
<contexts>
<context position="100647" citStr="Li and Abe (1998)" startWordPosition="15213" endWordPosition="15216">pproaches, a combination that has not yet been applied. (4) Variations in the existing feature description are especially relevant for the choice of selectional preferences. The experiment results demonstrated that the 15 conceptual GermaNet top levels are not sufficient for all verbs. For example, the verbs t¨oten and unterrichten require a finer version of selectional preferences in order to be distinguished. It is worthwhile either to find a more appropriate level of selectional preferences in WordNet or to apply a more sophisticated approach towards selectional preferences such as that of Li and Abe (1998), in order to determine a more flexible choice of selectional preferences. (5) With respect to a large-scale classification of verbs, it will be interesting to apply classification techniques to the verb data. This would require more data manually labeled with classes in order to train a classifier. But the resulting classifier might abstract better than k-means over the different requirements of the verb classes with respect to the feature description. (6) As an extension of the existing clustering, a soft clustering algorithm will be applied to the German verbs. Soft clustering enables us to</context>
</contexts>
<marker>Li, Abe, 1998</marker>
<rawString>Li, Hang and Naoki Abe. 1998. Generalizing case frames using a thesaurus and the MDL principle. Computational Linguistics, 24(2):217–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
</authors>
<title>Lexical Acquisition at the Syntax-Semantics Interface: Diathesis Alternations, Subcategorization Frames and Selectional Preferences.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Sussex.</institution>
<contexts>
<context position="4604" citStr="McCarthy 2001" startWordPosition="676" endWordPosition="677">ake this prediction: If we induce a verb classification on the basis of verb features describing verb behavior, then the resulting behavior classification should agree with a semantic classification to a certain extent (yet to be determined). The aim of this work is to utilize this prediction for the automatic acquisition of German semantic verb classes. The verb behavior itself is commonly captured by the diathesis alternation of verbs: alternative constructions at the syntax–semantics interface that express the same or a similar conceptual idea of a verb (Lapata 1999; Schulte im Walde 2000; McCarthy 2001; Merlo and Stevenson 2001; Joanis 2002). Consider example (1), where the most common alternations of the Manner of Motion with a Vehicle verb fahren ‘drive’ are illustrated. The conceptual participants are a vehicle, a driver, a passenger, and a direction. In (a), the vehicle is expressed as the subject in a transitive verb construction, with a prepositional phrase indicating the direction. In (b), the driver is expressed as the subject in a transitive verb construction, with a prepositional phrase indicating the direction. In (c), the driver is expressed as the subject in a transitive verb c</context>
</contexts>
<marker>McCarthy, 2001</marker>
<rawString>McCarthy, Diana. 2001. Lexical Acquisition at the Syntax-Semantics Interface: Diathesis Alternations, Subcategorization Frames and Selectional Preferences. Ph.D. thesis, University of Sussex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatic verb classification based on statistical distributions of argument structure.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>3</issue>
<contexts>
<context position="3864" citStr="Merlo and Stevenson 2001" startWordPosition="559" endWordPosition="562">e semantically annotated and provide semantic information off-the-shelf such as FrameNet (Baker, Fillmore, and Lowe 1998; Fontenelle 2003) and PropBank (Palmer, Gildea, and Kingsbury 2005). Instead, the automatic construction of semantic classes typically benefits from a longstanding linguistic hypothesis that asserts a tight connection between the lexical meaning of a verb and its behavior: To a certain extent, the lexical meaning of a verb determines its behavior, particularly with respect to the choice of its arguments (Pinker 1989; Levin 1993; Dorr and Jones 1996; Siegel and McKeown 2000; Merlo and Stevenson 2001; Schulte im Walde and Brew 2002; Lapata and Brew 2004). Even though the meaning–behavior relationship is not perfect, we can make this prediction: If we induce a verb classification on the basis of verb features describing verb behavior, then the resulting behavior classification should agree with a semantic classification to a certain extent (yet to be determined). The aim of this work is to utilize this prediction for the automatic acquisition of German semantic verb classes. The verb behavior itself is commonly captured by the diathesis alternation of verbs: alternative constructions at th</context>
<context position="51884" citStr="Merlo and Stevenson (2001)" startWordPosition="7865" endWordPosition="7868">, complete linkage significantly outperforms all but Ward’s. Between single linkage, average and centroid distance, there are no significant differences. For D1, there are no significant differences between the initializations. The low scores in the tables might be surprising to the reader, but they reflect the difficulty of the task. As mentioned before, we deliberately set high demands for the gold standard, especially with reference to the fine-grained, small classes. Compared to related work (cf. Section 5), our results achieve lower scores because the task is more difficult; for example, Merlo and Stevenson (2001) classify 60 verbs into 3 classes, and Siegel and McKeown (2000) classify 56 verbs into 2 classes, as compared to our clustering, which assigns 168 verbs to 43 classes. The following illustrations should provide an intuition about the difficulty of the task: 1. In a set of additional experiments, a random choice of a reduced number of 5/10/15/20 classes from the gold standard is performed. The verbs from the respective gold standard classes are clustered with the optimal parameter set (see Table 8), which results in a pairwise f-score PairF of 22.19%. The random choice and the cluster analysis</context>
<context position="84452" citStr="Merlo and Stevenson 2001" startWordPosition="12803" endWordPosition="12806">duce’ and verringern ‘decrease’), antonymy (e.g., reduzieren ‘reduce’ and erh¨ohen ‘raise’), situational overlap (e.g., emotional state containing freuen ‘be glad’ and ¨argern ‘be annoyed’), and participation in a common process/script (e.g., bestellen ‘order’, kaufen ‘buy’, verkaufen ‘sell’, and abholen ‘pick up’). 5. Related Work The following paragraphs describe related classification and clustering experiments on the automatic induction of verb classes. The classifications refer to different class criteria, for example, aspectual properties (Siegel and McKeown 2000), syntactic categories (Merlo and Stevenson 2001; Merlo et al. 2002; Tsang, Stevenson, and Merlo 2002), and— most similar to my approach—semantic categories (Schulte im Walde 2000; Joanis 2002). The soft clustering approaches indicate how we might extend our hard clustering to verb ambiguity, now that we have determined the relevant set of verb features. Siegel and McKeown (2000) used three supervised and one unsupervised machinelearning algorithm to perform an automatic aspectual classification of English verbs. (1) For the supervised classification, 97,973 parsed sentences from medical discharge summaries were used to extract frequencies </context>
<context position="87416" citStr="Merlo and Stevenson (2001)" startWordPosition="13239" endWordPosition="13242">from maximum-probability parses using a robust statistical parser, and completed by assigning WordNet classes as selectional preferences to the frame arguments. Using Levin’s verb classification as a basis for evaluation, 61% of the verbs were classified correctly into semantic classes. The clustering was most successful when utilizing syntactic subcategorization frames enriched with PP information; selectional preferences decreased the performance of the clustering approach. The detailed encoding and therefore sparse data made the clustering worse with the selectional preference information. Merlo and Stevenson (2001) presented an automatic classification of three types of English intransitive verbs, based on argument structure and crucially involving thematic relations. They selected 60 verbs with 20 verbs from each verb class, comprising unergatives, unaccusatives, and object-drop verbs. The verbs in each verb class show similarities with respect to their argument structure, in that they all can be used both as transitives and intransitives. Therefore, argument structure alone does not distinguish the classes, and subcategorization information is refined by thematic relations. Merlo and Stevenson defined</context>
<context position="88969" citStr="Merlo and Stevenson (2001)" startWordPosition="13464" endWordPosition="13467">d as the ratio of occurrences of pronouns to all subjects for each verb, based on the assumption that unaccusatives occur less frequently with an animate subject compared to unergative and object-drop verbs. Each verb was described by a five-feature vector, and the vector descriptions were fed into a decision tree algorithm. Compared with a baseline performance of 33.9%, the decision trees classified the verbs into the three classes with an accuracy of 69.8%. Further experiments demonstrated the contribution of the different features within the classification. Compared to the current article, Merlo and Stevenson (2001) performed a simpler task and classified a smaller number of 60 verbs into only three classes. The features of the verbs were restricted to those that should capture the basic differences between the verb classes, in line with the idea that the feature choice depends on the specific properties of the desired verb classes. But using the same classification methodology for a large-scale experiment with an enlarged number of verbs and classes faces more problems. For example, Joanis (2002) reported an extension of their work that used 802 verbs from 14 classes from Levin (1993). He defined an ext</context>
<context position="90652" citStr="Merlo and Stevenson (2001)" startWordPosition="13726" endWordPosition="13729">, they enlarged the number of gold standard English verb classes to 14 classes related to Levin classes, with a total of 841 verbs. Lowfrequency and ambiguous verbs were excluded from the classes. They found that a semisupervised approach where the classifier was trained with five seed verbs from each verb class outperformed both a manual selection of features and the unsupervised 186 Schulte im Walde Induction of German Semantic Verb Classes approach of Dash, Liu, and Yao (1997), which used an entropy measure to organize data into a multidimensional space. The classification methodology from Merlo and Stevenson (2001) was applied to multilinguality by Merlo et al. (2002) and Tsang, Stevenson, and Merlo (2002). Merlo et al. (2002) showed that the classification paradigm is applicable in languages other than English by using the same features as defined by Merlo and Stevenson (2001) for the respective classification of 59 Italian verbs empirically based on the Parole corpus. The resulting accuracy is 86.4%. In addition, they used the content of Chinese verb features to refine the English verb classification, explained in more detail by Tsang, Stevenson, and Merlo (2002). The English verbs were manually trans</context>
</contexts>
<marker>Merlo, Stevenson, 2001</marker>
<rawString>Merlo, Paola and Suzanne Stevenson. 2001. Automatic verb classification based on statistical distributions of argument structure. Computational Linguistics, 27(3):373–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
<author>Vivian Tsang</author>
<author>Gianluca Allaria</author>
</authors>
<title>A multilingual paradigm for automatic verb classification.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>207--214</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="84471" citStr="Merlo et al. 2002" startWordPosition="12807" endWordPosition="12810">ease’), antonymy (e.g., reduzieren ‘reduce’ and erh¨ohen ‘raise’), situational overlap (e.g., emotional state containing freuen ‘be glad’ and ¨argern ‘be annoyed’), and participation in a common process/script (e.g., bestellen ‘order’, kaufen ‘buy’, verkaufen ‘sell’, and abholen ‘pick up’). 5. Related Work The following paragraphs describe related classification and clustering experiments on the automatic induction of verb classes. The classifications refer to different class criteria, for example, aspectual properties (Siegel and McKeown 2000), syntactic categories (Merlo and Stevenson 2001; Merlo et al. 2002; Tsang, Stevenson, and Merlo 2002), and— most similar to my approach—semantic categories (Schulte im Walde 2000; Joanis 2002). The soft clustering approaches indicate how we might extend our hard clustering to verb ambiguity, now that we have determined the relevant set of verb features. Siegel and McKeown (2000) used three supervised and one unsupervised machinelearning algorithm to perform an automatic aspectual classification of English verbs. (1) For the supervised classification, 97,973 parsed sentences from medical discharge summaries were used to extract frequencies for verbs on 14 lin</context>
<context position="90706" citStr="Merlo et al. (2002)" startWordPosition="13735" endWordPosition="13738">ses to 14 classes related to Levin classes, with a total of 841 verbs. Lowfrequency and ambiguous verbs were excluded from the classes. They found that a semisupervised approach where the classifier was trained with five seed verbs from each verb class outperformed both a manual selection of features and the unsupervised 186 Schulte im Walde Induction of German Semantic Verb Classes approach of Dash, Liu, and Yao (1997), which used an entropy measure to organize data into a multidimensional space. The classification methodology from Merlo and Stevenson (2001) was applied to multilinguality by Merlo et al. (2002) and Tsang, Stevenson, and Merlo (2002). Merlo et al. (2002) showed that the classification paradigm is applicable in languages other than English by using the same features as defined by Merlo and Stevenson (2001) for the respective classification of 59 Italian verbs empirically based on the Parole corpus. The resulting accuracy is 86.4%. In addition, they used the content of Chinese verb features to refine the English verb classification, explained in more detail by Tsang, Stevenson, and Merlo (2002). The English verbs were manually translated into Chinese and given part-of-speech tag featur</context>
</contexts>
<marker>Merlo, Stevenson, Tsang, Allaria, 2002</marker>
<rawString>Merlo, Paola, Suzanne Stevenson, Vivian Tsang, and Gianluca Allaria. 2002. A multilingual paradigm for automatic verb classification. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 207–214, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine J Miller</author>
</authors>
<title>Introduction to Wordnet: An on-line lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="20357" citStr="Miller et al. 1990" startWordPosition="2982" endWordPosition="2985">ndicating the same role Y as for the transitive accusative). Passivization of a verb–frame combination is indicated by [P]. Appendix 6 lists all possible frame variants with illustrative examples. Note that the corpus examples are given in the old German spelling version, before the spelling reform in 1998. Semantic verb classes have been defined for several languages, for example, as the earlier mentioned lexicographic resource FrameNet for English (Baker, Fillmore, and Lowe 1998; Fontenelle 2003) and German (Erk, Kowalski, and Pinkal 2003); the lexical semantic ontology WordNet for English (Miller et al. 1990; Fellbaum 1998); EuroWordNet (Vossen 2004) for Dutch, Italian, Spanish, French, German, Czech, and Estonian, and further languages as listed in WordNets in the World (Global WordNet Association, www.globalwordnet.org); syntax–semantics based verb classes for English (Levin 1993), Spanish (V´azquez et al. 2000), and French (Saint-Dizier 1998). Example 2 Aspect Verbs: anfangen, aufh¨oren, beenden, beginnen, enden Scene: [E An event] begins or ends, either internally caused or externally caused by [I an initiator]. The event may be specified with respect to [T tense], [L location], [X an experie</context>
<context position="28290" citStr="Miller et al. 1990" startWordPosition="4213" endWordPosition="4216"> grammar provides selectional preference information at a fine-grained level: It specifies the possible argument realizations in the form of lexical heads, with reference to a specific verb–frame–slot combination. Obviously, we would run into a sparse data problem if we tried to incorporate selectional preferences into the verb descriptions at such a specific level. We are provided with detailed information at the nominal level, but we need a generalization of the selectional preference definition. A widely used resource for selectional preference information is the semantic ontology WordNet (Miller et al. 1990; Fellbaum 1998); the University of T¨ubingen has developed the German version of WordNet, GermaNet (Hamp and Feldweg 1997; Kunze 2000). The hierarchy is realized by means of synsets, sets of synonymous nouns, which are organized by multiple inheritance hyponym/hypernym relationships. A noun can appear in several synsets, according to its number of senses. The German noun hierarchy in GermaNet is utilized for the generalization of selectional preferences: For each noun in a verb–frame–slot combination, the joint frequency is divided over the different senses of the noun and propagated up the h</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>Miller, George A., Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine J. Miller. 1990. Introduction to Wordnet: An on-line lexical database. International Journal of Lexicography, 3(4):235–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Dan Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Palmer, Martha, Dan Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>183--190</pages>
<location>Columbus, OH.</location>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Pereira, Fernando, Naftali Tishby, and Lillian Lee. 1993. Distributional clustering of English words. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, pages 183–190, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Pinker</author>
</authors>
<title>Learnability and Cognition: The Acquisition of Argument Structure.</title>
<date>1989</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="3780" citStr="Pinker 1989" startWordPosition="547" endWordPosition="548">dious manual definitions of the verbs and the classes? Few resources are semantically annotated and provide semantic information off-the-shelf such as FrameNet (Baker, Fillmore, and Lowe 1998; Fontenelle 2003) and PropBank (Palmer, Gildea, and Kingsbury 2005). Instead, the automatic construction of semantic classes typically benefits from a longstanding linguistic hypothesis that asserts a tight connection between the lexical meaning of a verb and its behavior: To a certain extent, the lexical meaning of a verb determines its behavior, particularly with respect to the choice of its arguments (Pinker 1989; Levin 1993; Dorr and Jones 1996; Siegel and McKeown 2000; Merlo and Stevenson 2001; Schulte im Walde and Brew 2002; Lapata and Brew 2004). Even though the meaning–behavior relationship is not perfect, we can make this prediction: If we induce a verb classification on the basis of verb features describing verb behavior, then the resulting behavior classification should agree with a semantic classification to a certain extent (yet to be determined). The aim of this work is to utilize this prediction for the automatic acquisition of German semantic verb classes. The verb behavior itself is comm</context>
<context position="10528" citStr="Pinker 1989" startWordPosition="1620" endWordPosition="1621">f the verb translations in one class are too similar to distinguish among them, a common translation is given. Even though the classification is primarily based on semantic intuition and not on facts about syntactic behavior, the verbs grouped in one class share certain aspects of their behavior. (Please note that this overlap does not necessarily transfer to the English translations.) This agreement corresponds to the 161 Computational Linguistics Volume 32, Number 2 long-standing linguistic hypothesis that asserts a tight connection between the meaning components of a verb and its behavior (Pinker 1989; Levin 1993). The purpose of the manual classification is to evaluate the reliability and performance of the clustering experiments. The following facts refer to empirically relevant properties of the classification: The class size is between 2 and 7, with an average of 3.9 verbs per class. Eight verbs are ambiguous with respect to class membership and marked by subscripts. The classes include both high- and low-frequency verbs in order to exercise the clustering technology in both data-rich and data-poor situations: The corpus frequencies of the verbs range from 8 to 71,604 (within 35 millio</context>
</contexts>
<marker>Pinker, 1989</marker>
<rawString>Pinker, Steven. 1989. Learnability and Cognition: The Acquisition of Argument Structure. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
<author>Stefan Riezler</author>
<author>Detlef Prescher</author>
<author>Glenn Carroll</author>
<author>Franz Beil</author>
</authors>
<title>Inducing a semantically annotated lexicon via EM-based clustering.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Maryland, MD.</location>
<contexts>
<context position="92664" citStr="Rooth et al. (1999)" startWordPosition="14023" endWordPosition="14026">ng process were frequencies of verb–noun pairs in a direct object relationship, as extracted from parsed sentences from the Associated Press news wire corpus. On the basis of the conditional verb–noun probabilities, the similarity of the distributions was determined by the Kullback–Leibler divergence. The EM algorithm (Baum 1972) was used to learn the hidden cluster membership probabilities, and deterministic annealing performed the divisive hierarchical clustering. The resulting class-based model can be utilized for estimating information for unseen events (cf. Dagan, Lee, and Pereira 1999). Rooth et al. (1999) produced soft semantic clusters for English that represent a classification on verbs as well as on nouns. They gathered distributional data for verb–noun pairs in specific grammatical relations from the British National Corpus. The extraction was based on a lexicalized probabilistic context-free grammar (Carroll and Rooth 1998) and contained the subject and object nouns for all intransitive and transitive verbs in the parses—a total of 608,850 verb–noun types. Conditioning of the verbs and the nouns on each other was done through hidden classes, and the joint probabilities of classes, verbs, </context>
</contexts>
<marker>Rooth, Riezler, Prescher, Carroll, Beil, 1999</marker>
<rawString>Rooth, Mats, Stefan Riezler, Detlef Prescher, Glenn Carroll, and Franz Beil. 1999. Inducing a semantically annotated lexicon via EM-based clustering. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, Maryland, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Saint-Dizier</author>
</authors>
<title>Alternations and verb semantic classes for French: Analysis and class formation.</title>
<date>1998</date>
<booktitle>Predicative Forms in Natural Language and in Lexical Knowledge Bases.</booktitle>
<editor>In Patrick Saint-Dizier, editor,</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="20701" citStr="Saint-Dizier 1998" startWordPosition="3029" endWordPosition="3030">ined for several languages, for example, as the earlier mentioned lexicographic resource FrameNet for English (Baker, Fillmore, and Lowe 1998; Fontenelle 2003) and German (Erk, Kowalski, and Pinkal 2003); the lexical semantic ontology WordNet for English (Miller et al. 1990; Fellbaum 1998); EuroWordNet (Vossen 2004) for Dutch, Italian, Spanish, French, German, Czech, and Estonian, and further languages as listed in WordNets in the World (Global WordNet Association, www.globalwordnet.org); syntax–semantics based verb classes for English (Levin 1993), Spanish (V´azquez et al. 2000), and French (Saint-Dizier 1998). Example 2 Aspect Verbs: anfangen, aufh¨oren, beenden, beginnen, enden Scene: [E An event] begins or ends, either internally caused or externally caused by [I an initiator]. The event may be specified with respect to [T tense], [L location], [X an experiencer], or [R a result]. Frame Roles: I(nitiator), E(vent) Modification Roles: T(emporal), L(ocal), (e)X(periencer), R(esult) Frame Participating Verbs and Corpus Examples + anfangen, aufh¨oren, beginnen / +adv enden / ¬ beenden nE muß must Nun Now aber though anfangen. begin [E der Dialog] the dialog [E das Morden] the killing aufh¨oren. stop</context>
</contexts>
<marker>Saint-Dizier, 1998</marker>
<rawString>Saint-Dizier, Patrick. 1998. Alternations and verb semantic classes for French: Analysis and class formation. In Patrick Saint-Dizier, editor, Predicative Forms in Natural Language and in Lexical Knowledge Bases. Kluwer Academic Publishers, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>LoPar: Design and implementation.</title>
<date>2000</date>
<booktitle>Arbeitspapiere des Sonderforschungsbereichs 340 Linguistic Theory and the Foundations of Computational Linguistics 149, Institut f¨ur Maschinelle Sprachverarbeitung,</booktitle>
<location>Universit¨at Stuttgart.</location>
<contexts>
<context position="22373" citStr="Schmid (2000)" startWordPosition="3296" endWordPosition="3297">tionstag] ... endet [T um 14 Uhr]. The information day ... finishes at 2pm 165 [P] [E Mit diesem ungerechten Krieg] muß sofort aufgeh¨ort werden. With this unjust war must immediately be stopped [T Vorher] d¨urfe [E mit der Aufl¨osung] nicht begonnen werden. Before must with the closing not be started 2.2 Empirical Distributions for German Verbs We developed, implemented, and trained a statistical grammar model for German that is based on the framework of head-lexicalized, probabilistic, context-free grammars. The idea originates from Charniak (1997), with this work using an implementation by Schmid (2000) for a training corpus of 35 million words from a collection of large German newspaper corpora from the 1990s, including Frankfurter Rundschau, Stuttgarter Zeitung, VDI-Nachrichten, die tageszeitung, German Law Corpus, Donaukurier, and Computerzeitung. The statistical grammar model provides empirical lexical information, specializing in but not restricted to the subcategorization behavior of verbs. Details of 166 [E mit den Umbauarbeiten] k¨onnte with the reconstruction work could pE : mit Und And angefangen werden. be begun Computational Linguistics Volume 32, Number 2 ... [I er] he daß that </context>
</contexts>
<marker>Schmid, 2000</marker>
<rawString>Schmid, Helmut. 2000. LoPar: Design and implementation. Arbeitspapiere des Sonderforschungsbereichs 340 Linguistic Theory and the Foundations of Computational Linguistics 149, Institut f¨ur Maschinelle Sprachverarbeitung, Universit¨at Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Schulte im Walde</author>
<author>Sabine</author>
</authors>
<title>Clustering verbs semantically according to their alternation behaviour.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics,</booktitle>
<pages>747--753</pages>
<location>Saarbr¨ucken, Germany.</location>
<marker>Walde, Sabine, 2000</marker>
<rawString>Schulte im Walde, Sabine. 2000. Clustering verbs semantically according to their alternation behaviour. In Proceedings of the 18th International Conference on Computational Linguistics, pages 747–753, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Schulte im Walde</author>
<author>Sabine</author>
</authors>
<title>Evaluating verb subcategorisation frames learned by a German statistical grammar against manual definitions in the Duden Dictionary.</title>
<date>2002</date>
<booktitle>In Proceedings Computational Linguistics Volume 32, Number 2 of the 10th EURALEX International Congress,</booktitle>
<pages>187--197</pages>
<location>Copenhagen, Denmark.</location>
<marker>Walde, Sabine, 2002</marker>
<rawString>Schulte im Walde, Sabine. 2002a. Evaluating verb subcategorisation frames learned by a German statistical grammar against manual definitions in the Duden Dictionary. In Proceedings Computational Linguistics Volume 32, Number 2 of the 10th EURALEX International Congress, pages 187–197, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Schulte im Walde</author>
<author>Sabine</author>
</authors>
<title>A subcategorisation lexicon for German verbs induced from a lexicalised PCFG.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd Conference on Language Resources and Evaluation, volume IV,</booktitle>
<pages>1351--1357</pages>
<marker>Walde, Sabine, 2002</marker>
<rawString>Schulte im Walde, Sabine. 2002b. A subcategorisation lexicon for German verbs induced from a lexicalised PCFG. In Proceedings of the 3rd Conference on Language Resources and Evaluation, volume IV, pages 1351–1357, Las Palmas de Gran Canaria, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Schulte im Walde</author>
<author>Sabine</author>
</authors>
<title>Experiments on the automatic induction of German semantic verb classes.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>Institut f¨ur Maschinelle Sprachverarbeitung, Universit¨at Stuttgart.</institution>
<note>Published as AIMS Report 9(2).</note>
<marker>Walde, Sabine, 2003</marker>
<rawString>Schulte im Walde, Sabine. 2003a. Experiments on the automatic induction of German semantic verb classes. Ph.D. thesis, Institut f¨ur Maschinelle Sprachverarbeitung, Universit¨at Stuttgart. Published as AIMS Report 9(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Schulte im Walde</author>
<author>Sabine</author>
</authors>
<title>Experiments on the choice of features for learning verb classes.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>315--322</pages>
<location>Budapest, Hungary.</location>
<marker>Walde, Sabine, 2003</marker>
<rawString>Schulte im Walde, Sabine. 2003b. Experiments on the choice of features for learning verb classes. In Proceedings of the 10th Conference of the European Chapter of the Association for Computational Linguistics, pages 315–322, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Schulte im Walde</author>
<author>Sabine</author>
<author>Chris Brew</author>
</authors>
<title>Inducing German semantic verb classes from purely syntactic subcategorisation information.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>223--230</pages>
<marker>Walde, Sabine, Brew, 2002</marker>
<rawString>Schulte im Walde, Sabine and Chris Brew. 2002. Inducing German semantic verb classes from purely syntactic subcategorisation information. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 223–230,</rawString>
</citation>
<citation valid="false">
<location>Philadelphia, PA.</location>
<marker></marker>
<rawString>Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Schulte im Walde</author>
<author>Sabine</author>
<author>Alissa Melinger</author>
</authors>
<title>Identifying semantic relations and functional properties of human verb associations.</title>
<date>2005</date>
<booktitle>In Proceedings of the joint Conference on Human Language Technology and Empirial Methods in Natural Language Processing,</booktitle>
<pages>612--619</pages>
<location>Vancouver, Canada.</location>
<marker>Walde, Sabine, Melinger, 2005</marker>
<rawString>Schulte im Walde, Sabine and Alissa Melinger. 2005. Identifying semantic relations and functional properties of human verb associations. In Proceedings of the joint Conference on Human Language Technology and Empirial Methods in Natural Language Processing, pages 612–619, Vancouver, Canada.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Helmut 1986 Schumacher</author>
</authors>
<title>Verben in Feldern. de Gruyter,</title>
<location>Berlin.</location>
<marker>Schumacher, </marker>
<rawString>Schumacher, Helmut.1986. Verben in Feldern. de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric V Siegel</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Learning methods to combine linguistic indicators: Improving aspectual classification and Revealing Linguistic Insights.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>4</issue>
<contexts>
<context position="3838" citStr="Siegel and McKeown 2000" startWordPosition="555" endWordPosition="558">classes? Few resources are semantically annotated and provide semantic information off-the-shelf such as FrameNet (Baker, Fillmore, and Lowe 1998; Fontenelle 2003) and PropBank (Palmer, Gildea, and Kingsbury 2005). Instead, the automatic construction of semantic classes typically benefits from a longstanding linguistic hypothesis that asserts a tight connection between the lexical meaning of a verb and its behavior: To a certain extent, the lexical meaning of a verb determines its behavior, particularly with respect to the choice of its arguments (Pinker 1989; Levin 1993; Dorr and Jones 1996; Siegel and McKeown 2000; Merlo and Stevenson 2001; Schulte im Walde and Brew 2002; Lapata and Brew 2004). Even though the meaning–behavior relationship is not perfect, we can make this prediction: If we induce a verb classification on the basis of verb features describing verb behavior, then the resulting behavior classification should agree with a semantic classification to a certain extent (yet to be determined). The aim of this work is to utilize this prediction for the automatic acquisition of German semantic verb classes. The verb behavior itself is commonly captured by the diathesis alternation of verbs: alter</context>
<context position="51948" citStr="Siegel and McKeown (2000)" startWordPosition="7876" endWordPosition="7879">een single linkage, average and centroid distance, there are no significant differences. For D1, there are no significant differences between the initializations. The low scores in the tables might be surprising to the reader, but they reflect the difficulty of the task. As mentioned before, we deliberately set high demands for the gold standard, especially with reference to the fine-grained, small classes. Compared to related work (cf. Section 5), our results achieve lower scores because the task is more difficult; for example, Merlo and Stevenson (2001) classify 60 verbs into 3 classes, and Siegel and McKeown (2000) classify 56 verbs into 2 classes, as compared to our clustering, which assigns 168 verbs to 43 classes. The following illustrations should provide an intuition about the difficulty of the task: 1. In a set of additional experiments, a random choice of a reduced number of 5/10/15/20 classes from the gold standard is performed. The verbs from the respective gold standard classes are clustered with the optimal parameter set (see Table 8), which results in a pairwise f-score PairF of 22.19%. The random choice and the cluster analysis are repeated 20 times for each reduced gold standard size of 5/</context>
<context position="84404" citStr="Siegel and McKeown 2000" startWordPosition="12797" endWordPosition="12800">oherence, such as synonymy (e.g., reduzieren ‘reduce’ and verringern ‘decrease’), antonymy (e.g., reduzieren ‘reduce’ and erh¨ohen ‘raise’), situational overlap (e.g., emotional state containing freuen ‘be glad’ and ¨argern ‘be annoyed’), and participation in a common process/script (e.g., bestellen ‘order’, kaufen ‘buy’, verkaufen ‘sell’, and abholen ‘pick up’). 5. Related Work The following paragraphs describe related classification and clustering experiments on the automatic induction of verb classes. The classifications refer to different class criteria, for example, aspectual properties (Siegel and McKeown 2000), syntactic categories (Merlo and Stevenson 2001; Merlo et al. 2002; Tsang, Stevenson, and Merlo 2002), and— most similar to my approach—semantic categories (Schulte im Walde 2000; Joanis 2002). The soft clustering approaches indicate how we might extend our hard clustering to verb ambiguity, now that we have determined the relevant set of verb features. Siegel and McKeown (2000) used three supervised and one unsupervised machinelearning algorithm to perform an automatic aspectual classification of English verbs. (1) For the supervised classification, 97,973 parsed sentences from medical disch</context>
<context position="86030" citStr="Siegel and McKeown (2000)" startWordPosition="13043" endWordPosition="13046">, as they rank differently depending on the classification task and evaluation criteria. Decision trees achieved an accuracy of 93.9%, as compared to the uninformed baseline of 83.8%. (2) For the unsupervised clustering, 14,038 distinct verb–object pairs of varying frequencies were extracted from 75,289 parsed novel sentences. A random partition of the set of verbs was improved by a hill-climbing method, which improved the partition by moving a verb to the cluster that decreases the sum of distances most. For a small set of 56 verbs whose frequency in the verb–object pairs was larger than 50, Siegel and McKeown (2000) claimed on the basis of an evaluation of 19 verbs that their clustering algorithm discriminated 185 Computational Linguistics Volume 32, Number 2 event verbs from stative verbs. Overall, they performed a comparably simpler task than presented in this article, since the aspectual class criteria can be defined more objectively and more clearly than semantic criteria based on situational similarity. Their choice of features delimited their class criteria well, and they were able to achieve excellent results. In previous work on English, Schulte im Walde (2000) clustered 153 verbs into 30 verb cl</context>
</contexts>
<marker>Siegel, McKeown, 2000</marker>
<rawString>Siegel, Eric V. and Kathleen R. McKeown. 2000. Learning methods to combine linguistic indicators: Improving aspectual classification and Revealing Linguistic Insights. Computational Linguistics, 26(4):595–628.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suzanne Stevenson</author>
<author>Eric Joanis</author>
</authors>
<title>Semi-supervised verb class discovery using noisy features.</title>
<date>2003</date>
<booktitle>In Proceedings of the 7th Conference on Natural Language Learning,</booktitle>
<pages>71--78</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="53892" citStr="Stevenson and Joanis 2003" startWordPosition="8217" endWordPosition="8220">most 20%. If another cluster analysis resulted in a choice with just one more mistake such as {{a, b, c, d, e, i}, {f, g, h}, {j, k, l}} where i is also assigned to a ”wrong” class, the result decreases by almost another 20%, to a precision of 57%, a recall of 67%, and pairF of 62%. The results show how much impact a few mistakes may have on the pairwise f-score of the results. In addition to defining a difficult task, we also chose strong evaluation measures: Evaluating pairs of objects results in lower numbers than evaluating the individual objects. For example, the accuracy/purity measure (Stevenson and Joanis 2003; Korhonen, Krymolowski, and Marx 2003) evaluates whether a verb is assigned to a correct cluster with respect to the gold standard class of the majority of cluster members. That is, in a first step each induced verb cluster is assigned a gold standard class according to which class captures the majority of the cluster members. In a second step, each verb in a cluster is evaluated as correct or wrong with respect to its gold standard class, and accuracy/purity of the whole clustering is calculated as the proportion of correct verbs divided by the total number of verbs. If we applied this measu</context>
<context position="89899" citStr="Stevenson and Joanis (2003)" startWordPosition="13612" endWordPosition="13615">esired verb classes. But using the same classification methodology for a large-scale experiment with an enlarged number of verbs and classes faces more problems. For example, Joanis (2002) reported an extension of their work that used 802 verbs from 14 classes from Levin (1993). He defined an extensive feature space with 219 core features (such as part of speech, auxiliary frequency, syntactic categories, and animacy as above) and 1,140 selectional preference features taken from WordNet. As in Schulte im Walde (2000), the selectional preferences did not improve the clustering. In recent work, Stevenson and Joanis (2003) compared their supervised method for verb classification with semisupervised and unsupervised techniques. In these experiments, they enlarged the number of gold standard English verb classes to 14 classes related to Levin classes, with a total of 841 verbs. Lowfrequency and ambiguous verbs were excluded from the classes. They found that a semisupervised approach where the classifier was trained with five seed verbs from each verb class outperformed both a manual selection of features and the unsupervised 186 Schulte im Walde Induction of German Semantic Verb Classes approach of Dash, Liu, and</context>
</contexts>
<marker>Stevenson, Joanis, 2003</marker>
<rawString>Stevenson, Suzanne and Eric Joanis. 2003. Semi-supervised verb class discovery using noisy features. In Proceedings of the 7th Conference on Natural Language Learning, pages 71–78, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivian Tsang</author>
<author>Suzanne Stevenson</author>
<author>Paola Merlo</author>
</authors>
<title>Crosslinguistic transfer in automatic verb classification.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>1023--1029</pages>
<location>Taipei, Taiwan.</location>
<marker>Tsang, Stevenson, Merlo, 2002</marker>
<rawString>Tsang, Vivian, Suzanne Stevenson, and Paola Merlo. 2002. Crosslinguistic transfer in automatic verb classification. In Proceedings of the 19th International Conference on Computational Linguistics, pages 1023–1029, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gloria V´azquez</author>
<author>Ana Fern´andez</author>
<author>Irene Castell´on</author>
<author>Maria Antonia Marti</author>
</authors>
<title>Clasificaci´on verbal: Alternancias de di´atesis.</title>
<date>2000</date>
<journal>Number</journal>
<volume>3</volume>
<institution>Sintagma. Universitat de Lleida.</institution>
<note>in Quaderns de</note>
<marker>V´azquez, Fern´andez, Castell´on, Marti, 2000</marker>
<rawString>V´azquez, Gloria, Ana Fern´andez, Irene Castell´on, and Maria Antonia Marti. 2000. Clasificaci´on verbal: Alternancias de di´atesis. Number 3 in Quaderns de Sintagma. Universitat de Lleida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Piek Vossen</author>
</authors>
<title>EuroWordNet: A multilingual database of autonomous and language-specific wordnets connected via an inter-lingual-index.</title>
<date>2004</date>
<journal>International Journal of Lexicography,</journal>
<volume>17</volume>
<issue>2</issue>
<contexts>
<context position="20400" citStr="Vossen 2004" startWordPosition="2989" endWordPosition="2990">ccusative). Passivization of a verb–frame combination is indicated by [P]. Appendix 6 lists all possible frame variants with illustrative examples. Note that the corpus examples are given in the old German spelling version, before the spelling reform in 1998. Semantic verb classes have been defined for several languages, for example, as the earlier mentioned lexicographic resource FrameNet for English (Baker, Fillmore, and Lowe 1998; Fontenelle 2003) and German (Erk, Kowalski, and Pinkal 2003); the lexical semantic ontology WordNet for English (Miller et al. 1990; Fellbaum 1998); EuroWordNet (Vossen 2004) for Dutch, Italian, Spanish, French, German, Czech, and Estonian, and further languages as listed in WordNets in the World (Global WordNet Association, www.globalwordnet.org); syntax–semantics based verb classes for English (Levin 1993), Spanish (V´azquez et al. 2000), and French (Saint-Dizier 1998). Example 2 Aspect Verbs: anfangen, aufh¨oren, beenden, beginnen, enden Scene: [E An event] begins or ends, either internally caused or externally caused by [I an initiator]. The event may be specified with respect to [T tense], [L location], [X an experiencer], or [R a result]. Frame Roles: I(niti</context>
</contexts>
<marker>Vossen, 2004</marker>
<rawString>Vossen, Piek. 2004. EuroWordNet: A multilingual database of autonomous and language-specific wordnets connected via an inter-lingual-index. International Journal of Lexicography, 17(2):161–173.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>