<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014275">
<figure confidence="0.926063636363636">
Book Reviews
Semantic Structures
Ray Jackendoff
(Brandeis University)
Cambridge, MA: The MIT Press
(Current Studies in Linguistics 18),
1990, xiv + 322 pp.
Hardbound, ISBN 0-262-10043-6, $34.95
Reviewed by
Yorick Wilks
New Mexico State University
</figure>
<bodyText confidence="0.837734">
In this book a citation appears in passing to Roger Schank on page 93. On page 36
is a section on &amp;quot;preference rules&amp;quot; in which we are told that verbs prefer objects of
certain types, and that when these are not available in a sentence there may still be an
acceptable structure if not too many sentence constraints are broken. The preference
can even constitute a &amp;quot;default value.&amp;quot; All this is within a large project to construct
semantic or conceptual expressions of word meaning on which inference can be done
(p. 11), largely verb centered, and expressed in an internal &amp;quot;I-language&amp;quot; free from the
demands of model theoretic semantics. A typical coding is this (p. 53):
- drink
V
(NPi)
</bodyText>
<subsectionHeader confidence="0.419318">
[Event CAUSE ([Thing I i, [Event GO ([Thing LIQUID]j,
</subsectionHeader>
<bodyText confidence="0.976942789473684">
[Path TO ([Place IN ([Thing MOUTH OF ([Thing ii)DDI)D] _
Those in AT and CL who used to make a living 20 years ago writing down these
kinds of fantasy codings and making the parentheses match will feel a strong pang
of nostalgia if they open this book. If they also used to write about preference rules
as a way of using such structures in parsers, the pang will be even stronger. The fun
bit is that Jackendoff attributes all this nowhere but to his own earlier works. There
is no mention of those hundreds of Schank&apos;s students, and his student&apos;s students,
slaving over such codings (e.g., the systems described by Schank (1975), Schank and
Riesbeck (1981); or compare Wilks (1973)). Jackendoff overreaches himself when he
claims that preference rules will overcome the problem of Wittgensteinian &amp;quot;family
resemblances&amp;quot; and imprecise concept boundaries (p. 36). This is a real delusion of
grandeur, especially as a glance at, say, Charniak and Wilks (1976) would have shown
him not only lots of such conceptual codings, their relationship to preference rules,
etc., but even a brief tutorial on Wittgenstein explaining exactly why such systems
won&apos;t solve philosophical problems as well.
They say middle age is when everyone you meet reminds you of someone you&apos;ve
met before, and the academic equivalent must be that everyone&apos;s work starts to remind
you of your own. The true situation might be the very reverse of what I&apos;m suggesting:
perhaps the AT and CL semantics of the late 1960s and early 1970s was systematically
</bodyText>
<page confidence="0.98117">
95
</page>
<note confidence="0.316642">
Computational Linguistics Volume 18, Number 1
</note>
<bodyText confidence="0.999945367346939">
copying the ideas of contemporary linguists: Fodor, Katz, Weinreich, Givon, Gruber,
and even Jackendoff. A glance at the codings of those days shows that that is not
so, though everyone on both sides was probably more in Fillmore&apos;s debt than they
admitted at the time.
Anyone who doubts all this, or has memories only fifteen minutes old (a proven
research advantage in Al) should turn up the 1970s AT and CL codings of the word
drink as formal versions of glosses such as &amp;quot;animate entities causing liquids to move
towards human apertures.&amp;quot; But Jackendoff seems to have done a lot more work on
them and particularly on the explicit relationship of the lexical codings to related
syntactic structures, which was often left implicit in the structure of the parser in the
early CL work I referred to.
It may well be said that these superficial similarities are irrelevant (all this FOR,
WITH, IN, TO, FROM, etc., occurring identically in lexical codings in both traditions!).
They could have just grown up 95% alike by chance (like real mice and marsupial
mice in Australia) with no obvious causal influence on each other but only their re-
spective environments. Perhaps, too, one&apos;s lexical codings cannot be considered out
of a procedural context—for there is as yet no neutral or polythetic lexicon, however
much we might all want one—so all lexical codings are perhaps dependent on the
theory within which they play a role, and so superficial similarities may be irrele-
vant.
Following that line of argument, Jackendoff&apos;s structures could not be judged or
considered apart from their declared role, which is that of a lexicon within a linguistic
program closer, he says (p. 3), to Chomsky&apos;s original one in Syntactic Structures, than
to more recent grammatical theories, one where the semantics component is also gen-
erative and not merely &amp;quot;interpretive,&amp;quot; while avoiding a position where the semantics
is the main generative component, a position he identifies with Montague Grammar
and GB theory. All these are dusty struggles of long ago, and the lexical codings in this
book are not designed to play a part in any process that a reader of this journal would
recognize as computational. Indeed, they are in the good old high style of the imagi-
nary procedures of the transformational generative grammar tradition, simultaneously
denied to be procedures while plainly being described in that manner. Certainly they
have resulted in no serious computer programs. Being something of a throwback, as
it were, this book brings out just how much relations between AI/CL and linguistics
have improved, with a generally agreed-upon definition of what a process is and what
empirical evidence is. It was not always so.
Yet all this can make you wonder about Cognitive Science. Maybe the bargain
isn&apos;t quite what we thought: that of researchers working on similar problems but in
different conventional disciplines, reading each other&apos;s papers and getting together
sometimes in nice places to swap insights. Maybe it means some kind of giant ripoff,
where you don&apos;t have to acknowledge any sources, because in one&apos;s own discipline
one is doing theoretically based work, while the others, no matter how similar their
work seems, are just ad hockery and are ripe for pillage.
Oh, and by the way, Jackendoff works in the same university as James Puste-
jovsky (cf. Pustejovsky 1991) and he doesn&apos;t get a reference either, so, whatever the
NOT-ACQUAINTED function is, it isn&apos;t one of simple distance over time or space. If
computational linguists still need handcrafted lexical codings (though automatic con-
struction is now the name of the game, of course) they have a long and honorable
tradition of making up their own, and would not obviously profit from the ones in
this book.
</bodyText>
<page confidence="0.986381">
96
</page>
<figure confidence="0.4679365">
Book Reviews
References
</figure>
<reference confidence="0.99914">
Charniak, Eugene, and Wilks, Yorick (eds.)
(1976). Computational Semantics.
Amsterdam: North-Holland.
Pustejovsky, James (1991). The Generative
Lexicon: A Theory of Computational Lexical
Semantics. Cambridge, MA: The MIT
Press.
Schank, Roger (ed.) (1975). Conceptual
Information Processing. Amsterdam:
North-Holland.
Schank, Roger, and Riesbeck, Christopher K.
(eds.) (1981). Inside Computer
Understanding: Five Programs Plus
Miniatures. Hillsdale, NJ: Lawrence
Erlbaum Associates.
Wilks, Yorick (1973). &amp;quot;An artificial
intelligence approach to machine
translation.&amp;quot; In Computer Models of Thought
and Language, edited by Roger Schank and
Kenneth Colby. San Francisco: Freeman.
114-151.
Yorick Wilks has worked in natural language understanding and machine translation for over
20 years. His books include Grammar, Meaning, and the Machine Analysis of Language, Artificial
Believers (with Afzal Bairn), and Automatic Natural Language Parsing (edited with Karen Sparck
Jones). He is director of the Computing Research Laboratory, New Mexico State University, Las
Cruces, NM 88003; e-mail: yorick@nmsu.edu
</reference>
<page confidence="0.999691">
97
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.020648">
<title confidence="0.996837">Book Reviews Semantic Structures</title>
<author confidence="0.999967">Ray Jackendoff</author>
<affiliation confidence="0.993159">(Brandeis University)</affiliation>
<address confidence="0.959286">Cambridge, MA: The MIT Press</address>
<note confidence="0.920974">(Current Studies in Linguistics 18), 1990, xiv + 322 pp. Hardbound, ISBN 0-262-10043-6, $34.95 Reviewed by</note>
<author confidence="0.946179">Yorick Wilks</author>
<affiliation confidence="0.979341">New Mexico State University</affiliation>
<abstract confidence="0.996191524390244">In this book a citation appears in passing to Roger Schank on page 93. On page 36 is a section on &amp;quot;preference rules&amp;quot; in which we are told that verbs prefer objects of certain types, and that when these are not available in a sentence there may still be an acceptable structure if not too many sentence constraints are broken. The preference can even constitute a &amp;quot;default value.&amp;quot; All this is within a large project to construct semantic or conceptual expressions of word meaning on which inference can be done (p. 11), largely verb centered, and expressed in an internal &amp;quot;I-language&amp;quot; free from the demands of model theoretic semantics. A typical coding is this (p. 53): drink V (NPi) Ii, [Event LIQUID]j, OF ([Thing ii)DDI)D] _ Those in AT and CL who used to make a living 20 years ago writing down these kinds of fantasy codings and making the parentheses match will feel a strong pang of nostalgia if they open this book. If they also used to write about preference rules as a way of using such structures in parsers, the pang will be even stronger. The fun bit is that Jackendoff attributes all this nowhere but to his own earlier works. There is no mention of those hundreds of Schank&apos;s students, and his student&apos;s students, slaving over such codings (e.g., the systems described by Schank (1975), Schank and Riesbeck (1981); or compare Wilks (1973)). Jackendoff overreaches himself when he claims that preference rules will overcome the problem of Wittgensteinian &amp;quot;family resemblances&amp;quot; and imprecise concept boundaries (p. 36). This is a real delusion of grandeur, especially as a glance at, say, Charniak and Wilks (1976) would have shown him not only lots of such conceptual codings, their relationship to preference rules, etc., but even a brief tutorial on Wittgenstein explaining exactly why such systems won&apos;t solve philosophical problems as well. They say middle age is when everyone you meet reminds you of someone you&apos;ve met before, and the academic equivalent must be that everyone&apos;s work starts to remind you of your own. The true situation might be the very reverse of what I&apos;m suggesting: perhaps the AT and CL semantics of the late 1960s and early 1970s was systematically 95 Computational Linguistics Volume 18, Number 1 copying the ideas of contemporary linguists: Fodor, Katz, Weinreich, Givon, Gruber, and even Jackendoff. A glance at the codings of those days shows that that is not so, though everyone on both sides was probably more in Fillmore&apos;s debt than they admitted at the time. Anyone who doubts all this, or has memories only fifteen minutes old (a proven research advantage in Al) should turn up the 1970s AT and CL codings of the word formal versions of glosses such as &amp;quot;animate entities causing liquids to move towards human apertures.&amp;quot; But Jackendoff seems to have done a lot more work on them and particularly on the explicit relationship of the lexical codings to related syntactic structures, which was often left implicit in the structure of the parser in the early CL work I referred to. It may well be said that these superficial similarities are irrelevant (all this FOR, WITH, IN, TO, FROM, etc., occurring identically in lexical codings in both traditions!). They could have just grown up 95% alike by chance (like real mice and marsupial mice in Australia) with no obvious causal influence on each other but only their respective environments. Perhaps, too, one&apos;s lexical codings cannot be considered out of a procedural context—for there is as yet no neutral or polythetic lexicon, however much we might all want one—so all lexical codings are perhaps dependent on the theory within which they play a role, and so superficial similarities may be irrelevant. Following that line of argument, Jackendoff&apos;s structures could not be judged or considered apart from their declared role, which is that of a lexicon within a linguistic closer, he says (p. 3), to Chomsky&apos;s original one in Structures, to more recent grammatical theories, one where the semantics component is also generative and not merely &amp;quot;interpretive,&amp;quot; while avoiding a position where the semantics is the main generative component, a position he identifies with Montague Grammar and GB theory. All these are dusty struggles of long ago, and the lexical codings in this book are not designed to play a part in any process that a reader of this journal would recognize as computational. Indeed, they are in the good old high style of the imaginary procedures of the transformational generative grammar tradition, simultaneously denied to be procedures while plainly being described in that manner. Certainly they have resulted in no serious computer programs. Being something of a throwback, as it were, this book brings out just how much relations between AI/CL and linguistics have improved, with a generally agreed-upon definition of what a process is and what empirical evidence is. It was not always so. Yet all this can make you wonder about Cognitive Science. Maybe the bargain isn&apos;t quite what we thought: that of researchers working on similar problems but in different conventional disciplines, reading each other&apos;s papers and getting together sometimes in nice places to swap insights. Maybe it means some kind of giant ripoff, where you don&apos;t have to acknowledge any sources, because in one&apos;s own discipline one is doing theoretically based work, while the others, no matter how similar their work seems, are just ad hockery and are ripe for pillage. Oh, and by the way, Jackendoff works in the same university as James Puste- (cf. Pustejovsky 1991) and get a reference either, so, whatever the NOT-ACQUAINTED function is, it isn&apos;t one of simple distance over time or space. If computational linguists still need handcrafted lexical codings (though automatic construction is now the name of the game, of course) they have a long and honorable tradition of making up their own, and would not obviously profit from the ones in this book.</abstract>
<note confidence="0.921397875">96 Book Reviews References Charniak, Eugene, and Wilks, Yorick (eds.) Semantics. Amsterdam: North-Holland. James (1991). Generative Lexicon: A Theory of Computational Lexical MA: The MIT Press. Roger (ed.) (1975). Processing. North-Holland. Schank, Roger, and Riesbeck, Christopher K. (1981). Computer Understanding: Five Programs Plus NJ: Lawrence Erlbaum Associates. Wilks, Yorick (1973). &amp;quot;An artificial intelligence approach to machine In Models of Thought Language, by Roger Schank and Kenneth Colby. San Francisco: Freeman. 114-151.</note>
<title confidence="0.580447">Wilks worked in natural language understanding and machine translation for over years. His books include Meaning, and the Machine Analysis of Language, Artificial</title>
<author confidence="0.902162">Natural Language Parsing with Karen Sparck</author>
<affiliation confidence="0.897929">Jones). He is director of the Computing Research Laboratory, New Mexico State University, Las</affiliation>
<address confidence="0.86847">Cruces, NM 88003; e-mail: yorick@nmsu.edu</address>
<date confidence="0.365168">97</date>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Computational Semantics.</title>
<date>1976</date>
<editor>Charniak, Eugene, and Wilks, Yorick (eds.)</editor>
<publisher>North-Holland.</publisher>
<location>Amsterdam:</location>
<contexts>
<context position="1943" citStr="(1976)" startWordPosition="324" endWordPosition="324">he pang will be even stronger. The fun bit is that Jackendoff attributes all this nowhere but to his own earlier works. There is no mention of those hundreds of Schank&apos;s students, and his student&apos;s students, slaving over such codings (e.g., the systems described by Schank (1975), Schank and Riesbeck (1981); or compare Wilks (1973)). Jackendoff overreaches himself when he claims that preference rules will overcome the problem of Wittgensteinian &amp;quot;family resemblances&amp;quot; and imprecise concept boundaries (p. 36). This is a real delusion of grandeur, especially as a glance at, say, Charniak and Wilks (1976) would have shown him not only lots of such conceptual codings, their relationship to preference rules, etc., but even a brief tutorial on Wittgenstein explaining exactly why such systems won&apos;t solve philosophical problems as well. They say middle age is when everyone you meet reminds you of someone you&apos;ve met before, and the academic equivalent must be that everyone&apos;s work starts to remind you of your own. The true situation might be the very reverse of what I&apos;m suggesting: perhaps the AT and CL semantics of the late 1960s and early 1970s was systematically 95 Computational Linguistics Volume</context>
</contexts>
<marker>1976</marker>
<rawString>Charniak, Eugene, and Wilks, Yorick (eds.) (1976). Computational Semantics. Amsterdam: North-Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
</authors>
<title>The Generative Lexicon: A Theory of Computational Lexical Semantics.</title>
<date>1991</date>
<publisher>The MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>Pustejovsky, 1991</marker>
<rawString>Pustejovsky, James (1991). The Generative Lexicon: A Theory of Computational Lexical Semantics. Cambridge, MA: The MIT Press.</rawString>
</citation>
<citation valid="true">
<date>1975</date>
<booktitle>Conceptual Information Processing.</booktitle>
<editor>Schank, Roger (ed.)</editor>
<publisher>North-Holland.</publisher>
<location>Amsterdam:</location>
<contexts>
<context position="1616" citStr="(1975)" startWordPosition="276" endWordPosition="276">hing MOUTH OF ([Thing ii)DDI)D] _ Those in AT and CL who used to make a living 20 years ago writing down these kinds of fantasy codings and making the parentheses match will feel a strong pang of nostalgia if they open this book. If they also used to write about preference rules as a way of using such structures in parsers, the pang will be even stronger. The fun bit is that Jackendoff attributes all this nowhere but to his own earlier works. There is no mention of those hundreds of Schank&apos;s students, and his student&apos;s students, slaving over such codings (e.g., the systems described by Schank (1975), Schank and Riesbeck (1981); or compare Wilks (1973)). Jackendoff overreaches himself when he claims that preference rules will overcome the problem of Wittgensteinian &amp;quot;family resemblances&amp;quot; and imprecise concept boundaries (p. 36). This is a real delusion of grandeur, especially as a glance at, say, Charniak and Wilks (1976) would have shown him not only lots of such conceptual codings, their relationship to preference rules, etc., but even a brief tutorial on Wittgenstein explaining exactly why such systems won&apos;t solve philosophical problems as well. They say middle age is when everyone you </context>
</contexts>
<marker>1975</marker>
<rawString>Schank, Roger (ed.) (1975). Conceptual Information Processing. Amsterdam: North-Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Schank</author>
<author>Christopher K Riesbeck</author>
</authors>
<title>Inside Computer Understanding: Five Programs Plus Miniatures. Hillsdale, NJ: Lawrence Erlbaum Associates.</title>
<date>1981</date>
<contexts>
<context position="1644" citStr="Schank and Riesbeck (1981)" startWordPosition="277" endWordPosition="280">TH OF ([Thing ii)DDI)D] _ Those in AT and CL who used to make a living 20 years ago writing down these kinds of fantasy codings and making the parentheses match will feel a strong pang of nostalgia if they open this book. If they also used to write about preference rules as a way of using such structures in parsers, the pang will be even stronger. The fun bit is that Jackendoff attributes all this nowhere but to his own earlier works. There is no mention of those hundreds of Schank&apos;s students, and his student&apos;s students, slaving over such codings (e.g., the systems described by Schank (1975), Schank and Riesbeck (1981); or compare Wilks (1973)). Jackendoff overreaches himself when he claims that preference rules will overcome the problem of Wittgensteinian &amp;quot;family resemblances&amp;quot; and imprecise concept boundaries (p. 36). This is a real delusion of grandeur, especially as a glance at, say, Charniak and Wilks (1976) would have shown him not only lots of such conceptual codings, their relationship to preference rules, etc., but even a brief tutorial on Wittgenstein explaining exactly why such systems won&apos;t solve philosophical problems as well. They say middle age is when everyone you meet reminds you of someone </context>
</contexts>
<marker>Schank, Riesbeck, 1981</marker>
<rawString>Schank, Roger, and Riesbeck, Christopher K. (eds.) (1981). Inside Computer Understanding: Five Programs Plus Miniatures. Hillsdale, NJ: Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilks</author>
</authors>
<title>An artificial intelligence approach to machine translation.&amp;quot; In Computer Models of Thought and Language, edited by Roger Schank and Kenneth Colby.</title>
<date>1973</date>
<pages>114--151</pages>
<location>San Francisco:</location>
<contexts>
<context position="1669" citStr="Wilks (1973)" startWordPosition="283" endWordPosition="284">nd CL who used to make a living 20 years ago writing down these kinds of fantasy codings and making the parentheses match will feel a strong pang of nostalgia if they open this book. If they also used to write about preference rules as a way of using such structures in parsers, the pang will be even stronger. The fun bit is that Jackendoff attributes all this nowhere but to his own earlier works. There is no mention of those hundreds of Schank&apos;s students, and his student&apos;s students, slaving over such codings (e.g., the systems described by Schank (1975), Schank and Riesbeck (1981); or compare Wilks (1973)). Jackendoff overreaches himself when he claims that preference rules will overcome the problem of Wittgensteinian &amp;quot;family resemblances&amp;quot; and imprecise concept boundaries (p. 36). This is a real delusion of grandeur, especially as a glance at, say, Charniak and Wilks (1976) would have shown him not only lots of such conceptual codings, their relationship to preference rules, etc., but even a brief tutorial on Wittgenstein explaining exactly why such systems won&apos;t solve philosophical problems as well. They say middle age is when everyone you meet reminds you of someone you&apos;ve met before, and th</context>
</contexts>
<marker>Wilks, 1973</marker>
<rawString>Wilks, Yorick (1973). &amp;quot;An artificial intelligence approach to machine translation.&amp;quot; In Computer Models of Thought and Language, edited by Roger Schank and Kenneth Colby. San Francisco: Freeman. 114-151.</rawString>
</citation>
<citation valid="false">
<title>Yorick Wilks has worked in natural language understanding and machine translation for over 20 years. His books include Grammar, Meaning, and the Machine Analysis of Language, Artificial Believers (with Afzal Bairn), and Automatic Natural Language Parsing (edited with Karen Sparck Jones). He is director of the Computing Research Laboratory, New Mexico State University, Las Cruces, NM 88003; e-mail: yorick@nmsu.edu</title>
<marker></marker>
<rawString>Yorick Wilks has worked in natural language understanding and machine translation for over 20 years. His books include Grammar, Meaning, and the Machine Analysis of Language, Artificial Believers (with Afzal Bairn), and Automatic Natural Language Parsing (edited with Karen Sparck Jones). He is director of the Computing Research Laboratory, New Mexico State University, Las Cruces, NM 88003; e-mail: yorick@nmsu.edu</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>