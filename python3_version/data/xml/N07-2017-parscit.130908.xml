<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010085">
<title confidence="0.966339">
MOVER: Improving System Combination with Classification
</title>
<author confidence="0.955833">
D. Hillard†, B. Hoffmeister$, M. Ostendorf†, R. Schl¨uter$, H. Ney$
</author>
<affiliation confidence="0.821035">
†SSLI, Electrical Engineering Dept., University of Washington, Seattle, WA
</affiliation>
<email confidence="0.970739">
{hillard,mo}@ee.washington.edu
</email>
<affiliation confidence="0.576548">
$Informatik 6, Computer Science Dept., RWTH Aachen University, Aachen, Germany
</affiliation>
<email confidence="0.977277">
{hoffmeister,schlueter,ney}@cs.rwth-aachen.de
</email>
<sectionHeader confidence="0.995214" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99988175">
We present an improved system combination
technique, MOVER. Our approach obtains sig-
nificant improvements over ROVER, and is
consistently better across varying numbers of
component systems. A classifier is trained on
features from the system lattices, and selects
the final word hypothesis by learning cues to
choose the system that is most likely to be
correct at each word location. This approach
achieves the best result published to date on
the TC-STAR 2006 English speech recognition
evaluation set.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999974979591837">
State-of-the-art automatic speech recognition (ASR) sys-
tems today usually include multiple contrasting systems,
which are ultimately combined to produce the final hy-
pothesis. There is consensus that improvements from
combination are usually best when systems are suffi-
ciently different, but there is uncertainty about which sys-
tem combination method performs the best. In addition,
the success of commonly used combination techniques
varies depending on the number of systems that are com-
bined (Hoffmeister et al., 2007). In this work, we develop
a system combination method that outperforms all previ-
ously known techniques and is also robust to the number
of component systems. The relative improvements over
ROVER are particularly large for combination when only
using two systems.
The aim of system combination for ASR is to mini-
mize the expected word error rate (WER) given multiple
system outputs, which are ideally annotated with word
confidence information. The most widely used system
combination approach to date is ROVER (Fiscus, 1997).
It is a simple voting mechanism over just the top hy-
pothesis from each component system. Two alternatives
that incorporate information about multiple hypotheses
and leverage word posterior probabilities are confusion
network (CN) combination (Mangu et al., 2000; Ever-
mann and Woodland, 2000) and minimum Time Frame
Word Error (min-fWER) decoding (Hoffmeister et al.,
2006), discussed further in the next section. Previous
work found that among ROVER, CN combination, and
min-fWER combination, no one method was consistently
superior across varying numbers and types of systems
(Hoffmeister et al., 2007).
The main contribution of this work is to develop an
approach that always outperforms other possible system
combination methods. We train a classifier to learn which
system should be selected for each output word, using
features that describe the characteristics of the compo-
nent systems. ROVER alignments on the 1-best hypothe-
ses are used for decoding, but many of the features are
derived from the system lattices. The classifier learns a
selection strategy (i.e. a decision function) from a devel-
opment set and then is able to make better selections on
the evaluation data then the current 1-best or lattice-based
system combination approaches.
Next, Section 2 describes previous work in system
combination techniques. Section 3 describes our ap-
proach, and Section 4 provides experiments and results.
Finally, we summarize the approach and findings in Sec-
tion 5.
</bodyText>
<sectionHeader confidence="0.993926" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999456315789473">
Previous work in speech recognition system combination
has produced significant improvements over the results
possible with just a single system. The most popular, and
often best performing method is ROVER (Fiscus, 1997),
which selects the word that the most systems agree on
at a particular location (majority voting). An extended
version of ROVER also weights system votes by the word
confidence produced by the system (confidence voting).
Further improvements have been achieved by includ-
ing multiple system alternatives, with methods such as
Confusion Network Combination (CNC) (Evermann and
Woodland, 2000), or N-Best ROVER (Stolcke et al.,
2000), which is a special case of CNC. Alternatively, the
combination can be performed at the frame level (min-
fWER) (Hoffmeister et al., 2006). Recent work found
that the best system combination method depended on the
number of systems being combined (Hoffmeister et al.,
2007). When only two systems are available, approaches
considering multiple alternatives per system were bet-
</bodyText>
<page confidence="0.998381">
65
</page>
<note confidence="0.465385">
Proceedings of NAACL HLT 2007, Companion Volume, pages 65–68,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999790363636364">
ter, but as the number of systems increased the standard
ROVER with confidence scores was more robust and
sometimes even better than CNC or min-fWER combi-
nation.
Another approach (Zhang and Rudnicky, 2006) used
two stages of neural networks to select a system at each
word, with features that capture word frequency, posteri-
ors at the frame, word, and utterance level, LM back-off
mode, and system accuracy. They obtained consistent but
small improvements over ROVER: between 0.7 and 1.7%
relative gains for systems with about 30% WER.
</bodyText>
<sectionHeader confidence="0.994037" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.9999768">
We develop a system that uses the ROVER alignment but
learns to consistently make better decisions than those
of standard ROVER. We call the new system MOVER,
where the i stands for improved results, and/or intelligent
decisions. The following sections discuss the compo-
nents of our approach. First, we emulate the approach
of ROVER in our lattice preprocessing and system align-
ment. We then introduce new methods to extract hypoth-
esis features and train a classifier that selects the best
system at each slot in the alignment.
</bodyText>
<subsectionHeader confidence="0.998981">
3.1 Lattice Preparation
</subsectionHeader>
<bodyText confidence="0.999993866666667">
Our experiments use lattice sets from four different sites.
Naturally, these lattice sets differ in their vocabulary,
segmentation, and density. A compatible vocabulary is
essential for good combination performance. The main
problems are related to contractions, e.g. “you’ve” and
“you have”, and the alternatives in writing foreign names,
e.g. “Schr¨oder” and “Schroder”. In ASR this problem is
well-known and is addressed in scoring by using map-
pings that allow alternative forms of the same word.
Such a mapping is provided within the TC-STAR Eval-
uation Campaign and we used it to normalize the lat-
tices. In case of multiple alternative forms we used only
the most frequent one. Allowing multiple parallel alter-
natives would have distorted the posterior probabilities
derived from the lattice. Furthermore, we allowed only
one-to-one or one-to-many mappings. In the latter case
we distributed the time of the lattice arc according to the
character lengths of the target words.
In order to create comparable posterior probabilities
over the lattice sets we pruned them to equal average
density. The least dense lattice set defined the target
density: around 25 for the development and around 30
for the evaluation set.
Finally, we unified the segmentation by concatenat-
ing the lattices recording-wise. The concatenation was
complicated by segmentations with overlapping regions,
but our final concatenated lattices scored equally to the
original lattice sets. The unified segmentation is needed
for lattice-based system combination methods like frame-
based combination.
</bodyText>
<subsectionHeader confidence="0.999412">
3.2 System Alignments
</subsectionHeader>
<bodyText confidence="0.999977210526316">
In this work we decided to use the ROVER alignment as
the basis for our system combination approach. At first
glance the search space used by ROVER is very limited
because only the first-best hypothesis from each compo-
nent system is used. But the oracle error rate is often very
low, normally less than half of the best system’s error rate.
The ROVER alignment can be interpreted as a confu-
sion network with an equal number of arcs in each slot.
The number of arcs per slot equals the number of compo-
nent systems and thus makes the training and application
of a classifier straightforward.
For the production of the alignments we use a stan-
dard, dynamic programming-based matching algorithm
that minimizes the global cost between two hypothesis.
The local cost function is based on the time overlap of
two words and is identical to the one used by the ROVER
tool. We also did experiments with alternative local cost
functions based on word equalities, but could not outper-
form the simple, time overlap-based distance function.
</bodyText>
<subsectionHeader confidence="0.997228">
3.3 Hypothesis Features
</subsectionHeader>
<bodyText confidence="0.999972069767442">
We generate a cohort of features for each slot in the
alignment, which is then used as input to train the classi-
fier. The features incorporate knowledge about the scores
from the original systems, as well as comparisons among
each of the systems. The following paragraphs enumerate
the six classes of feature types used in our experiments
(with their names rendered in italics).
The primary, and most important feature class covers
the basic set of features which indicate string matches
among the top hypotheses from each system. In addition,
we include the systems’ frame-based word confidence.
These features are all the information available to the
standard ROVER with confidences voting.
An additional class of features provides extended con-
fidence information about each system’s hypothesis. This
feature class includes the confusion network (CN) word
confidence, CN slot entropy, and the number of alter-
natives in the CN slot. The raw language model and
acoustic scores are also available. In addition, it in-
cludes a frame-based confidence that is computed from
only the acoustic model, and a frame-based confidence
that is computed from only the language model score.
Frame-based confidences are calculated from the lattices
according to (Wessel et al., 1998); the CN-algorithm is
an extension of (Xue and Zhao, 2005).
The next class of features describes durational aspects
of the top hypothesis for each system, including: charac-
ter length, frame duration, frames per character, and if the
word is the empty or null word. A feature that normalizes
the frames per character by the average over a window
of ten words is also generated. Here we use characters
as a proxy for phones, because phone information is not
available from all component systems.
We also identify the system dependent top error words
for the development set, as well as the words that occur
to the left and right of the system errors. We encode this
information by indicating if a system word is on the list
of top ten errors or the top one hundred list, and likewise
if the left or right system context word is found in their
corresponding lists.
In order to provide comparisons across systems, we
compute the character distance (the cost of aligning the
words at the character level) between the system words
</bodyText>
<page confidence="0.956049">
66
</page>
<bodyText confidence="0.9995454375">
and provide that as a feature. In addition, we include the
confidence of a system word as computed by the frame-
wise posteriors of each of the other systems. This allows
each of the other systems to ‘score’ the hypothesis of
a system in question. These cross-system confidences
could also act as an indicator for when one system’s hy-
pothesis is an OOV-word for another system. We also
compute the standard, confidence-based ROVER hypoth-
esis at each slot, and indicate whether or not a system
agrees with ROVER’s decision.
The last set of features is computed relative to the
combined min-fWER decoding. A confidence for each
system word is calculated from the combined frame-wise
posteriors of all component systems. The final feature
indicates whether each system word agrees with the com-
bined systems’ min-fWER hypothesis.
</bodyText>
<subsectionHeader confidence="0.693495">
3.4 Classifier
</subsectionHeader>
<bodyText confidence="0.9999955">
After producing a set of features to characterize the sys-
tems, we train a classifier with these features that will
decide which system will propose the final hypothesis at
each slot in the multiple alignment. The target classes
include one for each system and a null class (which is
selected when none of the system outputs are chosen, i.e.
a system insertion).
The training data begins with the multiple alignment
of the hypothesis systems, which is then aligned to the
reference words. The learning target for each slot is the
set of systems which match the reference word, or the
null class if no systems match the reference word. Only
slots where there is disagreement between the systems’
1-best hypotheses are included in training and testing.
The classifier for our work is Boostexter (Schapire and
Singer, 2000) using real Adaboost.MH with logistic loss
(which outperformed exponential loss in preliminary ex-
periments). Boostexter trains a series of weak classifiers
(tree stumps), while also updating the weights of each
training sample such that examples that are harder to
classify receive more weight. The weak classifiers are
then combined with the weights learned in training to
predict the most likely class in testing. The main dimen-
sions for model tuning are feature selection and number
of iterations, which are selected on the development set
as described in the next section.
</bodyText>
<sectionHeader confidence="0.999644" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9992386">
We first perform experiments using cross-validation on
the development set to determine the impact of different
feature classes, and to select the optimal number of iter-
ations for Boostexter training. We then apply the models
to the evaluation set.
</bodyText>
<subsectionHeader confidence="0.975123">
4.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.947209625">
In our experiments we combine lattice sets for the English
task of the TC-STAR 2006 Evaluation Campaign from
four sites. The TC-STAR project partners kindly pro-
vided RWTH their development and evaluation lattices.
Systems and lattice sets are described in (Hoffmeister et
al., 2007).
Table 1 summarizes the best results achieved on the
single lattice sets. The latter columns show the results of
</bodyText>
<table confidence="0.9996155">
Viterbi min-fWER CN
dev eval dev eval dev eval
1 10.5 9.0 10.3 8.6 10.4 8.6
2 11.4 9.0 11.4 9.5 11.6 9.1
3 12.8 10.4 12.5 10.4 12.6 10.2
4 13.9 11.9 13.9 11.8 13.9 11.8
</table>
<tableCaption confidence="0.799349333333333">
Table 1: WER[%] results for single systems.
CN and min-fWER based posterior decoding (Mangu et
al., 2000; Wessel et al., 2001).
</tableCaption>
<subsectionHeader confidence="0.999435">
4.2 Feature analysis on development data
</subsectionHeader>
<bodyText confidence="0.999989857142857">
We evaluate the various feature classes from Section 3.3
on the development set with a cross validation testing
strategy. The results in Tables 2 and 3 are generated
with ten-fold cross validation, which maintains a clean
separation of training and testing data. The total number
oftraining samples (alignment slots where there is system
disagreement) is about 3,700 for the 2 system case, 5,500
for the 3 system case, and 6,800 for the 4 system case.
The WER results for different feature conditions on the
development set are presented in Table 2. The typical
ROVER with word confidences is provided in the first
row for comparison, and the remainder of the rows con-
tain the results for various configurations of features that
are made available to the classifier.
The basic features are just those that encode the same
information as ROVER, but the classifier is still able to
learn better decisions than ROVER with only these fea-
tures. Each of the following rows provides the results for
adding a single feature class to the basic features, so that
the impact of each type can be evaluated.
The last two rows contain combinations of feature
classes. First, the best three classes are added, and then
all features. Using just the best three classes achieves
almost the best results, but a small improvement is gained
when all features are added. The number of iterations in
training is also optimized on the development set by se-
lecting the number with the lowest average classification
error across the ten splits of the training data.
</bodyText>
<table confidence="0.999748">
Features 2 System 3 System 4 System
ROVER 10.2% 8.8% 9.0%
basic 9.4% 8.6% 8.5%
+confidences 9.3% 8.7% 8.4%
+durational 9.2% 8.6% 8.4%
+top error 9.0% 8.5% 8.4%
+comparisons 8.9% 8.6% 8.4%
+min-fWER 8.5% 8.5% 8.4%
+top+cmp+fWER 8.3% 8.3% 8.2%
all features 8.3% 8.2% 8.2%
</table>
<tableCaption confidence="0.9778505">
Table 2: WER results for development data with different
feature classes.
</tableCaption>
<page confidence="0.980671">
67
</page>
<table confidence="0.999934166666667">
2 System 3 System 4 System
ROVER (maj.) 10.8% 9.1% 9.1%
ROVER (conf.) 10.1% 8.8% 9.0%
min-fWER 9.6% 9.2 % 8.9 %
!ROVER 8.3% 8.2% 8.2%
oracle 6.5% 5.4% 4.7%
</table>
<tableCaption confidence="0.904205">
Table 3: WER[%] results for development data with
manual segmentation, and using cross-validation for
</tableCaption>
<sectionHeader confidence="0.379091" genericHeader="evaluation">
iROVER.
</sectionHeader>
<subsectionHeader confidence="0.973225">
4.3 Results on evaluation data
</subsectionHeader>
<bodyText confidence="0.999849777777778">
After analyzing the features and selecting the optimal
number of training iterations on the development data,
we train a final model on the full development set and
then apply it to the evaluation set. In all cases our clas-
sifier achieves a lower WER than ROVER (statistically
significant by NIST matched pairs test). Table 3 and Ta-
ble 4 present a comparison of the ROVER with majority
voting, confidence voting, frame-based combination, and
our improved ROVER (!ROVER).
</bodyText>
<sectionHeader confidence="0.999568" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.99997275">
In summary, we develop !ROVER, a method for sys-
tem combination that outperforms ROVER consistently
across varying numbers of component systems. The rela-
tive improvement compared to ROVER is especially large
for the case of combining two systems (14.5% on the
evaluation set). The relative improvements are larger than
any we know of to date, and the four system case achieves
the best published result on the TC-STAR English evalu-
ation set. The classifier requires relatively little training
data and utilizes features easily available from system
lattices.
Future work will investigate additional classifiers, clas-
sifier combination, and expanded training data. We are
also interested in applying a language model to decode
an alignment network that has been scored with our clas-
sifier.
</bodyText>
<sectionHeader confidence="0.995637" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.655512666666667">
G. Evermann and P. Woodland. 2000. Posterior probability
decoding, confidence estimation and system combination. In
NIST Speech Transcription Workshop.
</reference>
<table confidence="0.999780666666667">
2 System 3 System 4 System
ROVER(maj.) 9.0% 7.2% 7.3%
ROVER(conf.) 8.2% 7.1% 7.0%
min-fWER 7.6 % 7.4 % 7.2 %
!ROVER 7.1% 6.9% 6.7%
oracle 5.2% 4.1% 3.6%
</table>
<tableCaption confidence="0.997662">
Table 4: WER[%] results for evaluation data.
</tableCaption>
<reference confidence="0.999453393939394">
J.G. Fiscus. 1997. A post-processing system to yield reduced
word error rates: Recognizer Output Voting Error Reduction
(ROVER). In Proc. ASRU.
B. Hoffmeister, T. Klein, R. Schl¨uter, and H. Ney. 2006. Frame
based system combination and a comparison with weighted
ROVER and CNC. In Proc. ICSLP.
B. Hoffmeister, D. Hillard, S. Hahn, R. Sch¨ulter, M. Ostendorf,
and H. Ney. 2007. Cross-site and intra-site ASR system
combination: Comparisons on lattice and 1-best methods. In
Proc. ICASSP.
L. Mangu, E. Brill, and A. Stolcke. 2000. Finding consensus
in speech recognition: word error minimization and other
applications of confusion networks. Computer Speech and
Language, 14:373–400.
R. E. Schapire and Y. Singer. 2000. Boostexter: A boosting-
based system for text categorization. Machine Learning,
39(2/3):135–168.
A. Stolcke, H. Bratt, J. Butzberger, H. Franco, V. Gadde,
M. Plauche, C. Richey, E. Shriberg, K. Sonmez, J. Zheng,
and F. Weng. 2000. The SRI March 2000 Hub-5 conver-
sational speech transcription system. In NIST Speech Tran-
scription Workshop.
F. Wessel, K. Macherey, and R. Schl¨uter. 1998. Using word
probabilities as confidence measures. In Proc. ICASSP.
F. Wessel, R. Schl¨uter, and H. Ney. 2001. Explicit word error
minimization using word hypothesis posterior probabilities.
In Proc. ICASSP, volume 1.
Jian Xue and Yunxin Zhao. 2005. Improved confusion network
algorithm and shortest path search from word lattice. In
Proc. ICASSP.
R. Zhang and A. Rudnicky. 2006. Investigations of issues
for using multiple acoustic models to improve continuous
speech recognition. In Proc. ICSLP.
</reference>
<figure confidence="0.999264576923077">
1 2 3 4
10.5
9.5
8.5
11
10
9
8
ROVER(maj.)
ROVER(conf.)
min-fWER
iROVER
1 2 3 4
9.5
8.5
7.5
6.5
9
8
7
ROVER(maj.)
ROVER(conf.)
min-fWER
iROVER
[%] WER
[%] WER
</figure>
<page confidence="0.982853">
68
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.831963">
<title confidence="0.999968">Improving System Combination with Classification</title>
<author confidence="0.998882">B M R H</author>
<affiliation confidence="0.978061">Electrical Engineering Dept., University of Washington, Seattle,</affiliation>
<address confidence="0.86272">6, Computer Science Dept., RWTH Aachen University, Aachen,</address>
<abstract confidence="0.998321846153846">We present an improved system combination Our approach obtains significant improvements over ROVER, and is consistently better across varying numbers of component systems. A classifier is trained on features from the system lattices, and selects the final word hypothesis by learning cues to choose the system that is most likely to be correct at each word location. This approach achieves the best result published to date on English speech recognition evaluation set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Evermann</author>
<author>P Woodland</author>
</authors>
<title>Posterior probability decoding, confidence estimation and system combination.</title>
<date>2000</date>
<booktitle>In NIST Speech Transcription Workshop.</booktitle>
<contexts>
<context position="2222" citStr="Evermann and Woodland, 2000" startWordPosition="315" endWordPosition="319">ROVER are particularly large for combination when only using two systems. The aim of system combination for ASR is to minimize the expected word error rate (WER) given multiple system outputs, which are ideally annotated with word confidence information. The most widely used system combination approach to date is ROVER (Fiscus, 1997). It is a simple voting mechanism over just the top hypothesis from each component system. Two alternatives that incorporate information about multiple hypotheses and leverage word posterior probabilities are confusion network (CN) combination (Mangu et al., 2000; Evermann and Woodland, 2000) and minimum Time Frame Word Error (min-fWER) decoding (Hoffmeister et al., 2006), discussed further in the next section. Previous work found that among ROVER, CN combination, and min-fWER combination, no one method was consistently superior across varying numbers and types of systems (Hoffmeister et al., 2007). The main contribution of this work is to develop an approach that always outperforms other possible system combination methods. We train a classifier to learn which system should be selected for each output word, using features that describe the characteristics of the component systems</context>
<context position="4028" citStr="Evermann and Woodland, 2000" startWordPosition="592" endWordPosition="595"> 2 Previous Work Previous work in speech recognition system combination has produced significant improvements over the results possible with just a single system. The most popular, and often best performing method is ROVER (Fiscus, 1997), which selects the word that the most systems agree on at a particular location (majority voting). An extended version of ROVER also weights system votes by the word confidence produced by the system (confidence voting). Further improvements have been achieved by including multiple system alternatives, with methods such as Confusion Network Combination (CNC) (Evermann and Woodland, 2000), or N-Best ROVER (Stolcke et al., 2000), which is a special case of CNC. Alternatively, the combination can be performed at the frame level (minfWER) (Hoffmeister et al., 2006). Recent work found that the best system combination method depended on the number of systems being combined (Hoffmeister et al., 2007). When only two systems are available, approaches considering multiple alternatives per system were bet65 Proceedings of NAACL HLT 2007, Companion Volume, pages 65–68, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ter, but as the number of systems increased </context>
</contexts>
<marker>Evermann, Woodland, 2000</marker>
<rawString>G. Evermann and P. Woodland. 2000. Posterior probability decoding, confidence estimation and system combination. In NIST Speech Transcription Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Fiscus</author>
</authors>
<title>A post-processing system to yield reduced word error rates: Recognizer Output Voting Error Reduction (ROVER).</title>
<date>1997</date>
<booktitle>In Proc. ASRU.</booktitle>
<contexts>
<context position="1929" citStr="Fiscus, 1997" startWordPosition="275" endWordPosition="276">s varies depending on the number of systems that are combined (Hoffmeister et al., 2007). In this work, we develop a system combination method that outperforms all previously known techniques and is also robust to the number of component systems. The relative improvements over ROVER are particularly large for combination when only using two systems. The aim of system combination for ASR is to minimize the expected word error rate (WER) given multiple system outputs, which are ideally annotated with word confidence information. The most widely used system combination approach to date is ROVER (Fiscus, 1997). It is a simple voting mechanism over just the top hypothesis from each component system. Two alternatives that incorporate information about multiple hypotheses and leverage word posterior probabilities are confusion network (CN) combination (Mangu et al., 2000; Evermann and Woodland, 2000) and minimum Time Frame Word Error (min-fWER) decoding (Hoffmeister et al., 2006), discussed further in the next section. Previous work found that among ROVER, CN combination, and min-fWER combination, no one method was consistently superior across varying numbers and types of systems (Hoffmeister et al., </context>
<context position="3637" citStr="Fiscus, 1997" startWordPosition="536" endWordPosition="537">om a development set and then is able to make better selections on the evaluation data then the current 1-best or lattice-based system combination approaches. Next, Section 2 describes previous work in system combination techniques. Section 3 describes our approach, and Section 4 provides experiments and results. Finally, we summarize the approach and findings in Section 5. 2 Previous Work Previous work in speech recognition system combination has produced significant improvements over the results possible with just a single system. The most popular, and often best performing method is ROVER (Fiscus, 1997), which selects the word that the most systems agree on at a particular location (majority voting). An extended version of ROVER also weights system votes by the word confidence produced by the system (confidence voting). Further improvements have been achieved by including multiple system alternatives, with methods such as Confusion Network Combination (CNC) (Evermann and Woodland, 2000), or N-Best ROVER (Stolcke et al., 2000), which is a special case of CNC. Alternatively, the combination can be performed at the frame level (minfWER) (Hoffmeister et al., 2006). Recent work found that the bes</context>
</contexts>
<marker>Fiscus, 1997</marker>
<rawString>J.G. Fiscus. 1997. A post-processing system to yield reduced word error rates: Recognizer Output Voting Error Reduction (ROVER). In Proc. ASRU.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Hoffmeister</author>
<author>T Klein</author>
<author>R Schl¨uter</author>
<author>H Ney</author>
</authors>
<title>Frame based system combination and a comparison with weighted ROVER and CNC.</title>
<date>2006</date>
<booktitle>In Proc. ICSLP.</booktitle>
<marker>Hoffmeister, Klein, Schl¨uter, Ney, 2006</marker>
<rawString>B. Hoffmeister, T. Klein, R. Schl¨uter, and H. Ney. 2006. Frame based system combination and a comparison with weighted ROVER and CNC. In Proc. ICSLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Hoffmeister</author>
<author>D Hillard</author>
<author>S Hahn</author>
<author>R Sch¨ulter</author>
<author>M Ostendorf</author>
<author>H Ney</author>
</authors>
<title>Cross-site and intra-site ASR system combination: Comparisons on lattice and 1-best methods.</title>
<date>2007</date>
<booktitle>In Proc. ICASSP.</booktitle>
<marker>Hoffmeister, Hillard, Hahn, Sch¨ulter, Ostendorf, Ney, 2007</marker>
<rawString>B. Hoffmeister, D. Hillard, S. Hahn, R. Sch¨ulter, M. Ostendorf, and H. Ney. 2007. Cross-site and intra-site ASR system combination: Comparisons on lattice and 1-best methods. In Proc. ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Mangu</author>
<author>E Brill</author>
<author>A Stolcke</author>
</authors>
<title>Finding consensus in speech recognition: word error minimization and other applications of confusion networks.</title>
<date>2000</date>
<journal>Computer Speech and Language,</journal>
<pages>14--373</pages>
<contexts>
<context position="2192" citStr="Mangu et al., 2000" startWordPosition="311" endWordPosition="314">e improvements over ROVER are particularly large for combination when only using two systems. The aim of system combination for ASR is to minimize the expected word error rate (WER) given multiple system outputs, which are ideally annotated with word confidence information. The most widely used system combination approach to date is ROVER (Fiscus, 1997). It is a simple voting mechanism over just the top hypothesis from each component system. Two alternatives that incorporate information about multiple hypotheses and leverage word posterior probabilities are confusion network (CN) combination (Mangu et al., 2000; Evermann and Woodland, 2000) and minimum Time Frame Word Error (min-fWER) decoding (Hoffmeister et al., 2006), discussed further in the next section. Previous work found that among ROVER, CN combination, and min-fWER combination, no one method was consistently superior across varying numbers and types of systems (Hoffmeister et al., 2007). The main contribution of this work is to develop an approach that always outperforms other possible system combination methods. We train a classifier to learn which system should be selected for each output word, using features that describe the characteri</context>
<context position="13812" citStr="Mangu et al., 2000" startWordPosition="2177" endWordPosition="2180">English task of the TC-STAR 2006 Evaluation Campaign from four sites. The TC-STAR project partners kindly provided RWTH their development and evaluation lattices. Systems and lattice sets are described in (Hoffmeister et al., 2007). Table 1 summarizes the best results achieved on the single lattice sets. The latter columns show the results of Viterbi min-fWER CN dev eval dev eval dev eval 1 10.5 9.0 10.3 8.6 10.4 8.6 2 11.4 9.0 11.4 9.5 11.6 9.1 3 12.8 10.4 12.5 10.4 12.6 10.2 4 13.9 11.9 13.9 11.8 13.9 11.8 Table 1: WER[%] results for single systems. CN and min-fWER based posterior decoding (Mangu et al., 2000; Wessel et al., 2001). 4.2 Feature analysis on development data We evaluate the various feature classes from Section 3.3 on the development set with a cross validation testing strategy. The results in Tables 2 and 3 are generated with ten-fold cross validation, which maintains a clean separation of training and testing data. The total number oftraining samples (alignment slots where there is system disagreement) is about 3,700 for the 2 system case, 5,500 for the 3 system case, and 6,800 for the 4 system case. The WER results for different feature conditions on the development set are present</context>
</contexts>
<marker>Mangu, Brill, Stolcke, 2000</marker>
<rawString>L. Mangu, E. Brill, and A. Stolcke. 2000. Finding consensus in speech recognition: word error minimization and other applications of confusion networks. Computer Speech and Language, 14:373–400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Schapire</author>
<author>Y Singer</author>
</authors>
<title>Boostexter: A boostingbased system for text categorization.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<pages>39--2</pages>
<contexts>
<context position="12280" citStr="Schapire and Singer, 2000" startWordPosition="1926" endWordPosition="1929">iple alignment. The target classes include one for each system and a null class (which is selected when none of the system outputs are chosen, i.e. a system insertion). The training data begins with the multiple alignment of the hypothesis systems, which is then aligned to the reference words. The learning target for each slot is the set of systems which match the reference word, or the null class if no systems match the reference word. Only slots where there is disagreement between the systems’ 1-best hypotheses are included in training and testing. The classifier for our work is Boostexter (Schapire and Singer, 2000) using real Adaboost.MH with logistic loss (which outperformed exponential loss in preliminary experiments). Boostexter trains a series of weak classifiers (tree stumps), while also updating the weights of each training sample such that examples that are harder to classify receive more weight. The weak classifiers are then combined with the weights learned in training to predict the most likely class in testing. The main dimensions for model tuning are feature selection and number of iterations, which are selected on the development set as described in the next section. 4 Experiments We first </context>
</contexts>
<marker>Schapire, Singer, 2000</marker>
<rawString>R. E. Schapire and Y. Singer. 2000. Boostexter: A boostingbased system for text categorization. Machine Learning, 39(2/3):135–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>H Bratt</author>
<author>J Butzberger</author>
<author>H Franco</author>
<author>V Gadde</author>
<author>M Plauche</author>
<author>C Richey</author>
<author>E Shriberg</author>
<author>K Sonmez</author>
<author>J Zheng</author>
<author>F Weng</author>
</authors>
<title>Hub-5 conversational speech transcription system.</title>
<date>2000</date>
<booktitle>The SRI</booktitle>
<contexts>
<context position="4068" citStr="Stolcke et al., 2000" startWordPosition="599" endWordPosition="602">ition system combination has produced significant improvements over the results possible with just a single system. The most popular, and often best performing method is ROVER (Fiscus, 1997), which selects the word that the most systems agree on at a particular location (majority voting). An extended version of ROVER also weights system votes by the word confidence produced by the system (confidence voting). Further improvements have been achieved by including multiple system alternatives, with methods such as Confusion Network Combination (CNC) (Evermann and Woodland, 2000), or N-Best ROVER (Stolcke et al., 2000), which is a special case of CNC. Alternatively, the combination can be performed at the frame level (minfWER) (Hoffmeister et al., 2006). Recent work found that the best system combination method depended on the number of systems being combined (Hoffmeister et al., 2007). When only two systems are available, approaches considering multiple alternatives per system were bet65 Proceedings of NAACL HLT 2007, Companion Volume, pages 65–68, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ter, but as the number of systems increased the standard ROVER with confidence score</context>
</contexts>
<marker>Stolcke, Bratt, Butzberger, Franco, Gadde, Plauche, Richey, Shriberg, Sonmez, Zheng, Weng, 2000</marker>
<rawString>A. Stolcke, H. Bratt, J. Butzberger, H. Franco, V. Gadde, M. Plauche, C. Richey, E. Shriberg, K. Sonmez, J. Zheng, and F. Weng. 2000. The SRI March 2000 Hub-5 conversational speech transcription system. In NIST Speech Transcription Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Wessel</author>
<author>K Macherey</author>
<author>R Schl¨uter</author>
</authors>
<title>Using word probabilities as confidence measures.</title>
<date>1998</date>
<booktitle>In Proc. ICASSP.</booktitle>
<marker>Wessel, Macherey, Schl¨uter, 1998</marker>
<rawString>F. Wessel, K. Macherey, and R. Schl¨uter. 1998. Using word probabilities as confidence measures. In Proc. ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Wessel</author>
<author>R Schl¨uter</author>
<author>H Ney</author>
</authors>
<title>Explicit word error minimization using word hypothesis posterior probabilities.</title>
<date>2001</date>
<booktitle>In Proc. ICASSP,</booktitle>
<volume>1</volume>
<marker>Wessel, Schl¨uter, Ney, 2001</marker>
<rawString>F. Wessel, R. Schl¨uter, and H. Ney. 2001. Explicit word error minimization using word hypothesis posterior probabilities. In Proc. ICASSP, volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian Xue</author>
<author>Yunxin Zhao</author>
</authors>
<title>Improved confusion network algorithm and shortest path search from word lattice.</title>
<date>2005</date>
<booktitle>In Proc. ICASSP.</booktitle>
<contexts>
<context position="9652" citStr="Xue and Zhao, 2005" startWordPosition="1483" endWordPosition="1486"> class of features provides extended confidence information about each system’s hypothesis. This feature class includes the confusion network (CN) word confidence, CN slot entropy, and the number of alternatives in the CN slot. The raw language model and acoustic scores are also available. In addition, it includes a frame-based confidence that is computed from only the acoustic model, and a frame-based confidence that is computed from only the language model score. Frame-based confidences are calculated from the lattices according to (Wessel et al., 1998); the CN-algorithm is an extension of (Xue and Zhao, 2005). The next class of features describes durational aspects of the top hypothesis for each system, including: character length, frame duration, frames per character, and if the word is the empty or null word. A feature that normalizes the frames per character by the average over a window of ten words is also generated. Here we use characters as a proxy for phones, because phone information is not available from all component systems. We also identify the system dependent top error words for the development set, as well as the words that occur to the left and right of the system errors. We encode</context>
</contexts>
<marker>Xue, Zhao, 2005</marker>
<rawString>Jian Xue and Yunxin Zhao. 2005. Improved confusion network algorithm and shortest path search from word lattice. In Proc. ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zhang</author>
<author>A Rudnicky</author>
</authors>
<title>Investigations of issues for using multiple acoustic models to improve continuous speech recognition.</title>
<date>2006</date>
<booktitle>In Proc. ICSLP.</booktitle>
<contexts>
<context position="4789" citStr="Zhang and Rudnicky, 2006" startWordPosition="709" endWordPosition="712">evel (minfWER) (Hoffmeister et al., 2006). Recent work found that the best system combination method depended on the number of systems being combined (Hoffmeister et al., 2007). When only two systems are available, approaches considering multiple alternatives per system were bet65 Proceedings of NAACL HLT 2007, Companion Volume, pages 65–68, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics ter, but as the number of systems increased the standard ROVER with confidence scores was more robust and sometimes even better than CNC or min-fWER combination. Another approach (Zhang and Rudnicky, 2006) used two stages of neural networks to select a system at each word, with features that capture word frequency, posteriors at the frame, word, and utterance level, LM back-off mode, and system accuracy. They obtained consistent but small improvements over ROVER: between 0.7 and 1.7% relative gains for systems with about 30% WER. 3 Approach We develop a system that uses the ROVER alignment but learns to consistently make better decisions than those of standard ROVER. We call the new system MOVER, where the i stands for improved results, and/or intelligent decisions. The following sections discu</context>
</contexts>
<marker>Zhang, Rudnicky, 2006</marker>
<rawString>R. Zhang and A. Rudnicky. 2006. Investigations of issues for using multiple acoustic models to improve continuous speech recognition. In Proc. ICSLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>