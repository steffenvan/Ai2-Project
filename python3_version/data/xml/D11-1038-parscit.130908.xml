<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000951">
<title confidence="0.745845">
Learning to Simplify Sentences with Quasi-Synchronous Grammar and
Integer Programming
</title>
<author confidence="0.987571">
Kristian Woodsend and Mirella Lapata
</author>
<affiliation confidence="0.999345">
Institute for Language, Cognition and Computation
School of Informatics, University of Edinburgh
</affiliation>
<address confidence="0.992646">
10 Crichton Street, Edinburgh EH8 9AB
</address>
<email confidence="0.999211">
k.woodsend@ed.ac.uk,mlap@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.998603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998438">
Text simplification aims to rewrite text into
simpler versions, and thus make information
accessible to a broader audience. Most pre-
vious work simplifies sentences using hand-
crafted rules aimed at splitting long sentences,
or substitutes difficult words using a prede-
fined dictionary. This paper presents a data-
driven model based on quasi-synchronous
grammar, a formalism that can naturally
capture structural mismatches and complex
rewrite operations. We describe how such a
grammar can be induced from Wikipedia and
propose an integer linear programming model
for selecting the most appropriate simplifica-
tion from the space of possible rewrites gen-
erated by the grammar. We show experimen-
tally that our method creates simplifications
that significantly reduce the reading difficulty
of the input, while maintaining grammaticality
and preserving its meaning.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999114181818182">
Sentence simplification is perhaps one of the oldest
text rewriting problems. Given a source sentence,
the goal is to create a grammatical target that is
easier to read with simpler vocabulary and syntac-
tic structure. An example is shown in Table 1 in-
volving a broad spectrum of rewrite operations such
as deletion, substitution, insertion, and reordering.
The popularity of the simplification task stems from
its potential relevance to various applications. Ex-
amples include the development of reading aids for
people with aphasia (Carroll et al., 1999), non-native
Also contributing to the firmness in copper, the an-
alyst noted, was a report by Chicago purchasing
agents, which precedes the full purchasing agents re-
port that is due out today and gives an indication of
what the full report might hold.
Also contributing to the firmness in copper, the an-
alyst noted, was a report by Chicago purchasing
agents. The Chicago report precedes the full purchas-
ing agents report. The Chicago report gives an indica-
tion of what the full report might hold. The full report
is due out today.
</bodyText>
<tableCaption confidence="0.957128">
Table 1: Example of a source sentence (top) and its sim-
plification (bottom).
</tableCaption>
<bodyText confidence="0.9998014">
speakers (Siddharthan, 2003) and more generally in-
dividuals with low literacy (Watanabe et al., 2009).
A simplification component could be also used as
a preprocessing step to improve the performance
of parsers (Chandrasekar et al., 1996), summarizers
(Beigman Klebanov et al., 2004) and semantic role
labelers (Vickrey and Koller, 2008).
Simplification is related to, but different from
paraphrase extraction (Barzilay, 2003). We must not
only have access to paraphrases (i.e., rewrite rules),
but also be able to combine them to generate new
text, in a simpler language. The task is also dis-
tinct from sentence compression as it aims to ren-
der a sentence more accessible while preserving its
meaning. On the contrary, compression unavoidably
leads to some information loss as it creates shorter
sentences without necessarily reducing complexity.
In fact, one of the commonest simplification oper-
ations is sentence splitting which usually produces
longer rather than shorter output! Moreover, mod-
</bodyText>
<page confidence="0.987338">
409
</page>
<note confidence="0.957965">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 409–420,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999796625">
els developed for sentence compression have been
mostly designed with one rewrite operation in mind,
namely word deletion, and are thus unable to model
consistent syntactic effects such as reordering, sen-
tence splitting, changes in non-terminal categories,
and lexical substitution (but see Cohn and Lapata
2008 and Zhao et al. 2009 for notable exceptions).
In this paper we propose a sentence simplification
model that is able to handle structural mismatches
and complex rewriting operations. Our approach is
based on quasi-synchronous grammar (QG, Smith
and Eisner 2006), a formalism that is well suited for
text rewriting. Rather than postulating a strictly syn-
chronous structure over the source and target sen-
tences, QG identifies a “sloppy” alignment of parse
trees assuming that the target tree is in some way
“inspired by” the source tree. Specifically, our model
is formulated as an integer linear program and uses
QG to capture the space of all possible rewrites.
Given a source tree, it finds the best target tree li-
censed by the grammar subject to constraints such
as sentence length and reading ease. Our model is
conceptually simple and computationally efficient.
Furthermore, it finds globally optimal simplifica-
tions without resorting to heuristics or approxima-
tions during the decoding process.
Contrary to most previous approaches (see the
discussion in Section 2) which rely heavily on
hand-crafted rules, our model learns simplifi-
cation rewrites automatically from examples of
source-target sentences. Our work joins others in us-
ing Wikipedia to extract data appropriate for model
training (Yamangil and Nelken, 2008; Yatskar et al.,
2010; Zhu et al., 2010). Advantageously, the Sim-
ple English Wikipedia (henceforth SimpleEW) pro-
vides a large repository of simplified language; it
uses fewer words and simpler grammar than the or-
dinary English Wikipedia (henceforth MainEW) and
is aimed at non-native English speakers, children,
translators, people with learning disabilities or low
reading proficiency. We exploit Wikipedia and cre-
ate a (parallel) simplification corpus in two ways:
by aligning MainEW sentences to their SimpleEW
counterparts, and by extracting training instances
from SimpleEW revision histories, thus leveraging
Wikipedia’s collaborative editing process.
Our experimental results demonstrate that a sim-
plification model can be learned from Wikipedia
data alone without any manual effort. Perhaps un-
surprisingly, the quality of the QG grammar rules
greatly improves when these are learned from re-
vision histories which are less noisy than sentence
alignments. When compared against current state-
of-the-art methods (Zhu et al., 2010) our model
yields significantly simpler output that is both gram-
matical and meaning preserving.
</bodyText>
<sectionHeader confidence="0.999874" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999971351351351">
Sentence simplification has attracted a great deal
of attention due to its potential impact on society.
The literature is rife with attempts to simplify text
using mostly hand-crafted syntactic rules aimed at
splitting long and complicated sentences into sev-
eral simpler ones (Carroll et al., 1999; Chandrasekar
et al., 1996; Siddharthan, 2004; Vickrey and Koller,
2008). Other work focuses on lexical simplifications
and substitutes difficult words by more common
WordNet synonyms or paraphrases found in a pre-
defined dictionary (Devlin, 1999; Inui et al., 2003;
Kaji et al., 2002).
More recently, Yatskar et al. (2010) explore
data-driven methods to learn lexical simplifications
from Wikipedia revision histories. A key idea in
their work is to utilize SimpleEW edits, while rec-
ognizing that these may serve other functions, such
as vandalism removal or introduction of new con-
tent. Zhu et al. (2010) also use Wikipedia to learn
a sentence simplification model which is able to
perform four rewrite operations, namely substitu-
tion, reordering, splitting, and deletion. Inspired
by syntax-based SMT (Yamada and Knight, 2001),
their model consists of three components: a lan-
guage model P(s) whose role is to guarantee that the
simplification output is grammatical, a direct trans-
lation model P(s|c) capturing the probability that the
target sentence s is a simpler version of the source c,
and a decoder which searches for the simplifica-
tion s which maximizes P(s)P(s|c). The translation
model is the product of the aforementioned four
rewrite operations whose probabilities are estimated
from a parallel corpus of MainEW and SimpleEW
sentences using an expectation maximization algo-
rithm. Their decoder translates sentences into sim-
pler alternatives by greedily selecting the branch in
the source tree with the highest probability.
</bodyText>
<page confidence="0.995459">
410
</page>
<bodyText confidence="0.999972358974359">
Our own work formulates sentence simplification
in the framework of Quasi-synchronous grammar
(QG, Smith and Eisner 2006). QG allows to describe
non-isomorphic tree pairs (the grammar rules can
comprise trees of arbitrary depth, and fragments can
be mapped) and is thus suited to text-rewriting tasks
which typically involve a number of local modifi-
cations to the input text. We use quasi-synchronous
grammar to learn a wide range of rewrite opera-
tions capturing both lexical and structural simplifi-
cations naturally without any additional rule engi-
neering. In contrast to Yatskar et al. (2010) and Zhu
et al. (2010), simplification operations (e.g., substi-
tution or splitting) are not modeled explicitly; in-
stead, we leave it up to our grammar extraction algo-
rithm to learn appropriate rules that reflect the train-
ing data. Compared to Zhu et al., our model is con-
ceptually simpler and more general. The proposed
ILP formulation not only allows to efficiently search
through the space of many QG rules but also to in-
corporate constraints relating to grammaticality and
the task at hand without the added computational
cost of integrating a language model. Furthermore,
our learning framework is not limited to simplifi-
cation and could be easily adapted to other rewrit-
ing tasks. Indeed, the QG formalism has been pre-
viously applied to parser adaptation and projection
(Smith and Eisner, 2009), paraphrase identification
(Das and Smith, 2009), question answering (Wang
et al., 2007), and title generation (Woodsend et al.,
2010).
Finally, our work relates to a large body of recent
literature on Wikipedia and its potential for a wide
range of NLP tasks. Beyond text rewriting, examples
include semantic relatedness (Ponzetto and Strube,
2007), information extraction (Wu and Weld, 2010),
ontology induction (Nastase and Strube, 2008), and
the automatic creation of overview articles (Sauper
and Barzilay, 2009).
</bodyText>
<sectionHeader confidence="0.996532" genericHeader="method">
3 Sentence Simplification Model
</sectionHeader>
<bodyText confidence="0.999916086956522">
Our model takes a single sentence as input and cre-
ates a version that is simpler to read. This may
involve rendering syntactically complex structures
simpler (e.g., through sentence splitting), or sub-
stituting rare words with more common words or
phrases (e.g., such that a second language learner
may be familiar with), or deleting elements of the
original text in order to produce a relatively sim-
pler and shallower syntactic structure. In addition,
the output must be grammatical and coherent. These
constraints are global in their scope, and cannot be
adequately satisfied by optimizing each one of them
individually. Our approach therefore uses an ILP
formulation which will provide a globally optimal
solution. Given an input sentence, our model decon-
structs it into component phrases and clauses, each
of which is simplified (lexically and structurally)
through QG rewrite rules. We generate all possible
simplifications for a given input and use the ILP to
find the best target subject to grammaticality con-
straints. In what follows we first detail how we ex-
tract QG rewrite rules as these form the backbone of
our model and then formulate the ILP proper.
</bodyText>
<subsectionHeader confidence="0.997965">
3.1 Quasi-synchronous Grammar
</subsectionHeader>
<bodyText confidence="0.999979892857143">
Phrase alignment Our model operates on indi-
vidual sentences annotated with syntactic informa-
tion i.e., phrase structure trees. In our experiments,
we obtain this information from the Stanford parser
(Klein and Manning, 2003) but any other broadly
similar parser could be used instead. Given an input
sentence S1 or its parse tree T1, the QG constructs
a monolingual grammar for parsing, or generating,
possible translation trees T2. A grammar node in the
target tree T2 is modeled on a subset of nodes in the
source tree, with a rather loose alignment between
the trees.
We take aligned sentence pairs represented as
phrase structure trees and build up a list of leaf node
alignments based on lexical identity. We align direct
parent nodes where more than one child node aligns.
QG rules are created from aligned nodes above the
leaf node level if the all the nodes in the target tree
can be explained using nodes from the source. This
helps to improve the quality in what is inherently a
noisy process, and it is largely responsible for a rel-
atively small resulting grammar (see Table 2). Ex-
amples of phrase alignments (indicated with dotted
lines) are shown in Figure 1.
Syntactic simplification rules Each QG rule de-
scribes the transformations required from source to
target phrase sub-trees. It allows child (and possi-
bly grand-child) constituents to be deleted or re-
</bodyText>
<page confidence="0.989353">
411
</page>
<figure confidence="0.997523285714286">
ST
.
VP
VP
NP
.
NNP
</figure>
<page confidence="0.994607">
412
</page>
<bodyText confidence="0.999987625">
possible for the auxiliary sentence to come before or
after the main sentence. In the learning procedure,
we try both possible orderings, and record the order
in any QG rules successfully produced.
The resulting QG rule is a tuple of three phrase
structure elements: the source node, the node in the
target main sentence (the top level of this node is
typically the same as that of the source node), and
the phrase structure of the entire auxiliary sentence.1
In addition, there is a flag to indicate if the auxiliary
sentence comes before or after the main sentence.
This formalism is able to capture the operations re-
quired to split sentences containing coordinate or
subordinate clauses, parenthetical content, relative
clauses and apposition. An example of a sentence
splitting rule is illustrated in Figure 1.
</bodyText>
<subsectionHeader confidence="0.994841">
3.2 ILP-based Generation
</subsectionHeader>
<bodyText confidence="0.999982703703704">
We cast the problem of finding a suitable target sim-
plification given a source sentence as an integer lin-
ear program (ILP). Specifically, simplified text is
created from source sentence parse trees by identi-
fying and applying QG grammar rules. These will
have matching structure and may also require lexical
matching (shown using italics in the example rules
in Figure 1). The generation process starts at the root
node of the parse tree, applying QG rules to sub-
trees until leaf nodes are reached. We do not use the
Bayesian probability model proposed by Smith and
Eisner (2006) to identify the best sequence of sim-
plification rules. Instead, where there is more than
one matching rule, and so more than one simplifi-
cation is possible, the alternatives are all generated
and incorporated into the target phrase structure tree.
The ILP model operates over this phrase structure
tree and selects the phrase nodes from which to form
the target output.
Applying the QG rules on the source sentence
generates a number of auxiliary sentences. Let S be
this set of sentences. Let P be the set of nodes in the
phrase structure trees of the auxiliary sentences, and
Ps ⊂ P be the set of nodes in each sentence s ∈ S.
Let the sets Di ⊂ P, ∀i ∈ P capture the phrase de-
pendency information for each node i, where each
set Di contains the nodes that depend on the pres-
</bodyText>
<footnote confidence="0.636146666666667">
1Note that the target component comprises the second and
third elements as a pair, and variables from the source compo-
nent are split between them.
</footnote>
<bodyText confidence="0.997621772727273">
ence of i. In a similar fashion, the sets Ai ⊂ S, ∀i ∈ P
capture the indices of any auxiliary sentences that
depend on the presence of node i. C ⊂ P is the set
of nodes involving a choice of alternative simplifi-
cations (nodes in the tree where more than one QG
rewrite rule can be applied, as mentioned above);
Ci ⊂ P,i ∈ C are the sets of nodes that are direct
children of each such node, in other words they are
the individual simplifications. Let l(w) ibe the length
of each node i in words, and l(sy)
i its length in syl-
lables. As we shall see below counts of words and
syllables are important cues in assessing readability.
The model is cast as an binary integer linear
program. A vector of binary decision variables
x ∈ {0,1}|P |indicates if each node is to be part of
the output. A vector of auxiliary binary variables
y ∈ {0,1}|S |indicates which (auxiliary) sentences
have been chosen.
max ∑ gixi + hw + hsy
x i∈P
s.t. xj → xi ∀i ∈ P, j ∈ Di
xi → ys ∀i ∈ P,s ∈ Ai
xi → ys ∀s ∈ S,i ∈ Ps
∑ xj = xi ∀i ∈ C, j ∈ Ci
j∈Ci
∑ yi ≥ 1
s∈S
xi ∈ {0,1} ∀i ∈ P
ys ∈ {0,1} ∀s ∈ S.
Our objective function, given in Equation (1a),
is the summation of local and global compo-
nents. Each phrase is locally given a rewrite
penalty gi, where common lexical substitutions,
rewrites and simplifications are penalized less (as
we trust them more), compared to rarer QG rules.
The penalty is a simple log-probability measure,
gi = log (nr)r , where nr is the number of times the
QG rule r was seen in the training data, and Nr
the number of times all suitable rules for this
phrase node were seen. If no suitable rules exist, we
set gi = 0.
The other two components of the objective,
hw and hsy, are global in nature, and guide the ILP
</bodyText>
<page confidence="0.996381">
413
</page>
<bodyText confidence="0.999937814814815">
towards simpler language. They draw inspiration
from existing measures of readability (the ease with
which a document can be read and understood).
The primary aim of readability formulas is to assess
whether texts or books are suitable for students at
particular grade levels or ages (see Mitchell 1985 for
an overview). Intuitively, texts ought to be simpler if
they correspond to low reading levels. A commonly
used reading level measure is the Flesch-Kincaid
Grade Level (FKGL) index which estimates read-
ability as a combination of the average number of
syllables per word and the average number of words
per sentence. Unfortunately, this measure is non-
linear2 and cannot be incorporated directly into the
objective of the ILP. Instead, we propose a linear ap-
proximation. We provide the ILP with targets for the
average number of words per sentence (wps), and
syllables per word (spw). hw(x,y) then measures the
number of words below this target level that the ILP
has achieved:
When positive, this indicates that sentences are
shorter than target, and contributes positively to the
readability objective whilst encouraging the appli-
cation of sentence splitting and deletion-based QG
rules. Similarly, hsy(x,y) measures the number of
syllables below that expected, from the target aver-
age and the number of words the ILP has chosen:
</bodyText>
<equation confidence="0.985846">
hsy(x) = spw × E l(w)
i xi − E
i∈P i∈P
</equation>
<bodyText confidence="0.986291738095238">
This component of the objective encourages the
deletion or lexical substitution of complex words.
We can use the two target parameters (wps and spw)
to control how much simplification the ILP should
apply.
Constraint (1b) enforces grammatical correctness
by ensuring that the phrase dependencies are re-
spected and the resulting structure is a tree. Phrases
that depend on phrase i are contained in the set Di.
Variable xi is true, and therefore phrase i will be
included in the target output, if any of its depen-
dents xj ∈ Di are true.3 Constraint (1c) links main
2FKGL = 0.39( total words l+l g ( total syllables 1 −15.59
total sentences J total words J
3Constraints (1b), (1c) and (1d) are shown as dependencies
for clarity, but they were implemented as inequalities in the ILP.
phrases to auxiliary sentences, so that the latter can
only be included in the output if the main phrase
has also been chosen. This helps to control coher-
ence within the output text. Despite seeming similar
to (1c), the role of constraint (1d) is quite different.
It links phrase variables x to sentence variables y, to
ensure the logical integrity of the model is correct.
Where the QG provides alternative simplifications,
it makes sense of course to select only one. This is
controlled by constraint (1e), and by placing all al-
ternatives in the set Di for the node i.
With these constraints alone, and faced with a
source sentence that is particularly difficult to sim-
plify, it is possible for the ILP solver to return a “triv-
ial” solution of no output at all, as all other avail-
able solutions result in a negative objective value.
It is therefore necessary to impose a global mini-
mum output constraint (1f). In combination with the
dependency relations in (1c), this constraint ensures
that at least an element of the root sentence is present
in the output. Global maximum length constraints
are a frequently occurring aspect of ILP models used
in NLP applications. We decided not to incorporate
any such constraints into our model, as we did not
want to place limitations on the simplification of
original content.
</bodyText>
<sectionHeader confidence="0.99942" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999937875">
In this section we present our experimental setup
for assessing the performance of the simplification
model described above. We give details on the cor-
pora and grammars we used, model parameters, the
systems used for comparison with our approach, and
explain how the output was evaluated.
Grammar Extraction QG rules were learned
from revision histories and an aligned simplifica-
tion corpus, which we obtained from snapshots4 of
MainEW and SimpleEW. Wiki-related mark-up and
meta-information was removed to extract the plain
text from the articles.
SimpleEW revisions not only simplify the text of
existing articles, they may also introduce new con-
tent, vandalize or remove vandalism, or perform nu-
merous automatic “house-keeping” modifications.
</bodyText>
<footnote confidence="0.996729333333333">
4The snapshots for MainEW (enwiki) and SimpleEW (sim-
plewiki dated 2010-09-16 and 2010-09-13, respectively (both
available from http://download.wikimedia.org/).
</footnote>
<equation confidence="0.994107666666667">
l(w)
i xi.
hw(x,y) = wps × E yi − E
i∈S i∈P
l(sy)
i xi.
</equation>
<page confidence="0.990994">
414
</page>
<table confidence="0.999858333333333">
Corpora Syntactic Lexical Splitting
Revision 316 269 184
Aligned 312 96 254
</table>
<tableCaption confidence="0.992278">
Table 2: Number of QG rules extracted (after removing
singletons) from revision-based and aligned corpora.
</tableCaption>
<bodyText confidence="0.999277743589744">
We identified suitable revisions for simplification by
selecting those where the author had mentioned a
keyword (such as simple, clarification or grammar)
in the revision comments. Each selected revision
was compared to the previous version. Because the
entire article is stored at each revision, we needed to
identify and align modified sentences. We first iden-
tified modified sections using the Unix diff pro-
gram, and then individual sentences within the sec-
tions were aligned using the program dwdiff5. This
resulted in 14,831 paired sentences. With regard to
the aligned simplification corpus, we paired 15,000
articles from SimpleEW and MainEW following the
language link within the snapshot files. Within the
paired articles, we identified aligned sentences us-
ing macro alignment (at paragraph level) then mi-
cro alignment (at sentence level), using tf.idf scores
to measure similarity (Barzilay and Elhadad, 2003;
Nelken and Schieber, 2006).
All source-target sentences (resulting from revi-
sions or alignments) were parsed with the Stanford
parser (Klein and Manning, 2003) in order to la-
bel the text with syntactic information. QG rules
were created by aligning nodes in these sentences
as described earlier. A breakdown of the number
and type of rules we obtained from the revision
and aligned corpora (after removing rules appear-
ing only once) is given in Table 2. Examples of the
most frequently learned QG rules are shown in Ta-
ble 3. Rules (1)–(3) involve syntactic simplification
and rules (4)–(6) involve sentence splitting. Exam-
ples of common lexical simplifications found by our
grammar are: “discovered” “found”, “defeated”
“won against”, “may refer to” “could mean”,
“original” “first”, “requires” “needs”.
Sentence generation We generated simplified
versions of MainEW sentences. For each (parsed)
source sentence, we created and solved an ILP (see
Equation (1)) parametrized as follows: the number
</bodyText>
<footnote confidence="0.827292">
5http://os.ghalkes.nl/dwdiff.html
</footnote>
<tableCaption confidence="0.699503166666667">
Table 3: Examples of QG rules involving syntactic sim-
plification (1)–(3) and sentence division (4)–(6). The lat-
ter are shown as the tuple (source, target, aux). The trans-
form of nodes from S to ST (for example) rely on the
application of syntactic simplification rules rules. Boxed
subscripts show aligned nodes.
</tableCaption>
<bodyText confidence="0.999968366666667">
of target words per sentence (wps) was set to 8, and
syllables per word (spw) to 1.5. These two param-
eters were empirically tuned on the training set. To
solve the ILP model we used the ZIB Optimization
Suite software (Achterberg, 2007; Koch, 2004). The
solution was converted into a sentence by removing
nodes not chosen from the tree representation, then
concatenating the remaining leaf nodes in order.
Evaluation We evaluated our model on the same
dataset used in Zhu et al. (2010), an aligned cor-
pus of MainEW and SimpleEW sentences. The cor-
pus contains 100/131 source/target sentences and
was created automatically. Sentences from this cor-
pus (and their revisions) were excluded from train-
ing. We evaluated two versions of our model, one
with rewrite rules acquired from revision histories
of simplified documents and another one with rules
extracted from MainEW-SimpleEW aligned sen-
tences. These models were compared against Zhu
et al. (2010)6 who also learn simplification rules
from Wikipedia, and a simple baseline that uses
solely lexical simplifications7 provided by the Sim-
pleEW editor “SpencerK” (Spencer Kelly). An obvi-
ous idea would be to treat sentence simplification as
an English-to-English translation problem and use
an off-the-shelf system like Moses8 for the task.
However, we refrained from doing so as Zhu et al.
(2010) show that Moses performs poorly, it cannot
model rewrite operations that split sentences or drop
words and in most cases generates output identical
</bodyText>
<footnote confidence="0.96925675">
6We are grateful to Zhemin Zhu for providing us with his
test set and the output of his system.
7http://www.spencerwaterbed.com/soft/simple/
8http://www.statmt.org/moses/
</footnote>
<figure confidence="0.897136166666667">
1. (S, ST) ([NP1 VP2], [NP1 VP2 .])
2. (S, ST) ([VP1 ], [This VP1 .])
3. (NP, ST) ([NP1 , NP2], [NP1 was VP2 .])
4. (ST, ST, ST) ([S1 , and S2], [ST1], [ST2])
5. (ST, ST, ST) ([S1 : S2], [ST1 ], [ST2 ])
6. (ST, ST, ST) ([S1 , but S2], [ST1], [ST2])
</figure>
<page confidence="0.98335">
415
</page>
<note confidence="0.662267375">
MainEW Wonder has recorded several critically acclaimed albums and hit singles, and writes and produces songs
for many of his label mates and outside artists as well.
Zhu et al Wonder has recorded several praised albums and writes and produces songs. Many of his label mates
and outside artists as well.
AlignILP Wonder has recorded several critically acclaimed albums and hit singles. He produces songs for many
of his label mates and outside artists as well. He writes.
RevILP Wonder has recorded many critically acclaimed albums and hit singles. He writes. He makes songs for
many of his label mates and outside artists as well.
</note>
<figureCaption confidence="0.8317928">
SimpleEW He has recorded 23 albums and many hit singles, and written and produced songs for many of his label
mates and other artists as well.
MainEW The London journeys In 1790, Prince Nikolaus died and was succeeded by a thoroughly unmusical
prince who dismissed the entire musical establishment and put Haydn on a pension.
Zhu et al The London journeys in 1790, prince Nikolaus died and was succeeds by a son became prince. A son
became prince told the entire musical start and put he on a pension.
AlignILP The London journeys In 1790, Prince Nikolaus died. He was succeeded by a thoroughly unmusical
prince. He dismissed the entire musical establishment. He put Haydn on a pension.
RevILP The London journeys In 1790, Prince Nikolaus died. He was succeeded by a thoroughly unmusical
prince. He dismissed the whole musical establishment. He put Haydn on a pension.
</figureCaption>
<tableCaption confidence="0.787376">
SimpleEW The London journeys In 1790, Prince Nikolaus died and his son became prince. Haydn was put on a
pension.
Table 4: Example simplifications produced by the systems in this paper (RevILP, AlignILP) and Zhu et al.’s (2010)
model, compared to real Wikipedia text (MainEW: input source, SimpleEW: simplified target).
</tableCaption>
<bodyText confidence="0.999532125">
to the source.
We evaluated model output in two ways, using au-
tomatic evaluation measures and human judgments.
Intuitively, readability measures ought to be suit-
able for assessing the output of simplification sys-
tems. We report results with the well-known Flesch-
Kincaid Grade Level index (FKGL). Experiments
with other readability measures such as the Flesch
Reading Ease and the Coleman-Liau index obtained
similar results. In addition, we also assessed how the
system output differed from the human SimpleEW
gold standard by computing BLEU (Papineni et al.,
2002) and TERp (Snover et al., 2009). Both mea-
sures are commonly used to automatically evaluate
the quality of machine translation output. BLEU9
scores the target output by counting n-gram matches
with the reference, whereas TERp is similar to word
error rate, the only difference being that it allows
shifts and thus can account for word order differ-
ences. TERp also allows for stem, synonym, and
paraphrase substitutions which are common rewrite
operations in simplification.
In line with previous work on text rewriting
(e.g., Knight and Marcu 2002) we also evaluated
</bodyText>
<footnote confidence="0.993653">
9We calculated single-reference BLEU using the mteval-
v13a script (with the default settings).
</footnote>
<bodyText confidence="0.999323826086957">
system output by eliciting human judgments. We
conducted three experiments. In the first experi-
ment participants were presented with a source sen-
tence and its target simplification and asked to rate
whether the latter was easier to read compared to the
source. In the second experiment, they were asked
to rate the grammaticality of the simplified output.
In the third experiment, they judged how well the
simplification preserved the meaning of the source.
In all experiments participants used a five point rat-
ing scale where a high number indicates better per-
formance. We randomly selected and automatically
simplified 64 sentences from Zhu et al.’s (2010) test
corpus using the four models described above. We
also included gold standard simplifications. Our ma-
terials thus consisted of 320 (64 × 5) source-target
sentences.10 We collected ratings from 45 unpaid
volunteers, all self reported native English speakers.
The studies were conducted over the Internet using
a custom built web interface. Examples of our ex-
perimental items are given in Table 4 (we omit the
output of SpencerK as this is broadly similar to the
source sentence, modulo lexical substitutions).
</bodyText>
<footnote confidence="0.960374">
10A Latin square design ensured that subjects did not see two
different simplifications of the same sentence.
</footnote>
<page confidence="0.992777">
416
</page>
<table confidence="0.999727857142857">
Models FKGL BLEU TERP
MainEW 15.12 — —
SimpleEW 11.25 — —
SpencerK 14.67 0.47 0.51
Zhu et al 9.41 0.38 0.59
RevILP 10.92 0.42 0.60
AlignILP 12.36 0.34 0.85
</table>
<tableCaption confidence="0.990995">
Table 5: Model performance using automatic evaluation
measures.
</tableCaption>
<sectionHeader confidence="0.999319" genericHeader="conclusions">
5 Results
</sectionHeader>
<bodyText confidence="0.999940064516129">
The results of our automatic evaluation are summa-
rized in Table 5. The first column reports the FKGL
readability index of the source sentences (MainEW),
of their target simplifications (SimpleEW) and the
output of four models: a simple baseline that re-
lies on lexical substitution (SpencerK), Zhu et al.’s
(2010) model, and two versions of our model, one
trained on revision histories (RevILP) and another
one trained on the MainEW-SimpleEW aligned cor-
pus (AlignILP). As can be seen, the source sentences
have the highest reading level. Zhu et al.’s system
has the lowest reading level followed by our own
models and SpencerK. All models are significantly11
different in reading level from SimpleEW with the
exception of RevILP (using a one-way ANOVA with
post-hoc Tukey HSD tests). SpencerK is not signif-
icantly different in readability from MainEW; Re-
vILP is significantly different from Zhu et al. and
AlignILP. In sum, these results indicate that RevILP
is the closest to SimpleEW and that the provenance
of the QG rules has an impact on the model’s perfor-
mance.
Table 5 also shows BLEU and TERp scores with
SimpleEW as the reference. These scores can be
used to examine how close to the gold standard our
models are. SpencerK has the highest BLEU and
lowest TERp scores.12 This is expected as this base-
line performs only a very limited type of rewriting,
namely lexical substitution. AlignILP is most differ-
ent from the reference, followed by Zhu et al. (2010)
and RevILP. Taken together these results indicate
</bodyText>
<footnote confidence="0.99377525">
11All significance differences reported throughout this paper
are with a level less than 0.01.
12The perfect BLEU score is one and the perfect TERp score
is zero.
</footnote>
<table confidence="0.999557666666667">
Models Simplicity Grammaticality Meaning
SimpleEW 3.74 4.89 4.41
SpencerK 1.41 4.87 4.84
Zhu et al 2.92 3.43 3.44
RevILP 3.64 4.55 4.19
AlignILP 2.69 4.03 3.98
</table>
<tableCaption confidence="0.993777">
Table 6: Average human ratings for gold standard Sim-
pleEW sentences, a simple baseline (SpencerK) based on
lexical substitution, Zhu et al.’s 2010 model, and two ver-
sions of our ILP model (RevILP and AlignILP).
</tableCaption>
<table confidence="0.9984644">
Zhu et al AlignILP RevILP SimpleEW
SpencerK ❑♦4 ❑♦4 ❑#4 ❑#4
Zhu et al M♦4 ❑♦4 ❑♦4
AlignILP ❑♦N ❑♦4
RevILP ■*N
</table>
<tableCaption confidence="0.955335">
Table 7: ❑/■: is/not sig. diff. wrt simplicity; ♦/#: is/not
sig. diff. wrt grammaticality; 4/N: is/not sig. diff. wrt
meaning.
</tableCaption>
<bodyText confidence="0.940304925925926">
that the ILP models perform a fair amount of rewrit-
ing without simply rehashing the source sentence.
We now turn to the results of our judgment elic-
itation study. Table 6 reports the average ratings
for Simplicity (is the target sentence simpler than
the source?), Grammaticality (is the target sentence
grammatical?), and Meaning (does the target pre-
serve the meaning of the source?). With regard to
simplicity, our participants perceive the gold stan-
dard (SimpleEW) to be the simplest, followed by
RevILP, Zhu et al, and AlignILP. SpencerK is the
least simple model and the most grammatical one
as lexical substitutions do not change the structure
of the sentence. Interestingly, RevILP and AlignILP
are also rated highly with regard to grammaticality.
Zhu et al. (2010) is the least grammatical model.
Finally, RevILP preserves the meaning of the tar-
get as well as SimpleEW, whereas Zhu et al. yields
the most distortions. Again SpencerK is rated highly
amongst the other models as it is does not substan-
tially simplify and thus change the meaning of the
source.
Table 7 reports on pairwise comparisons between
all models and their statistical significance (again us-
ing a one-way ANOVA with post-hoc Tukey HSD
tests). RevILP is not significantly different from
SimpleEW on any dimension (Simplicity, Grammat-
</bodyText>
<page confidence="0.985713">
417
</page>
<note confidence="0.6965908">
Original story: There was once a sweet little maid who lived with her father and mother in a pretty little
cottage at the edge of the village. At the further end of the wood was another pretty cottage and in it lived
her grandmother. Everybody loved this little girl, her grandmother perhaps loved her most of all and gave
her a great many pretty things. Once she gave her a red cloak with a hood which she always wore, so people
called her Little Red Riding Hood.
</note>
<tableCaption confidence="0.963931166666667">
Generated simplification: There was once a sweet little maid. She lived with her father and mother in
a pretty little cottage at the edge of the village. At the further end of the wood it lived her grandmother.
Everybody loved this little girl. Her grandmother perhaps loved her most of all. She gave her a great many
pretty things. Once she gave her a red cloak with a hood, so persons called her Little Red Riding Hood.
Table 8: Excerpt of Little Red Riding Hood simplified by the RevILP model. Modifications to the original story are
highlighted in italics.
</tableCaption>
<bodyText confidence="0.999869823529411">
icality, Meaning), whereas Zhu et al. differs signif-
icantly from RevILP and SimpleEW on all dimen-
sions. It is also significantly different from Alig-
nILP in terms of grammaticality and meaning but
not simplicity. RevILP is significantly more simple
and grammatical than AlignILP but performs com-
parably with respect to preserving the meaning of
the source.
In sum, our results show that RevILP is the best
performing model. It creates sentences that are sim-
ple, grammatical and adhere to the meaning of
the source. The QG rules obtained from the revi-
sion histories produce better output compared to the
aligned corpus. As revision histories are created by
Wikipedia contributors, they tend to be a more ac-
curate data source than aligned sentences which are
obtained via an automatic and unavoidably noisy
procedure. Our results also show that a more gen-
eral model not restricted to specific rewrite opera-
tions like Zhu et al. (2010) obtains superior results
and has better coverage.
We also wanted to see whether a simplification
model trained on Wikipedia could be applied to an-
other domain. To this end, we used RevILP to sim-
plify five children stories from the Gutenburg13 col-
lection. The model simplified one sentence at a time
and was ran with the Wikipedia settings without any
modification. The mean FKGL on the simplified sto-
ries was 3.78. compared to 7.04 for the original ones.
An example of our system’s output on Little Red
Riding Hood is shown in Table 8.
Possible extensions and improvements to the cur-
rent model are many and varied. We have presented
an all-purpose simplification model without a target
</bodyText>
<footnote confidence="0.689836">
13http://www.gutenberg.org
</footnote>
<bodyText confidence="0.9997559375">
audience or application in mind. An interesting re-
search direction would be to simplify text accord-
ing to readability levels or text genres (e.g., news-
paper vs literary text). We could do this by incorpo-
rating readability-specific constraints to the ILP or
by changing the objective function (e.g., by favoring
more domain-specific rules). Finally, we would like
to extend the current model so as to simplify entire
documents both in terms of style and content.
Acknowledgments We are grateful to Lillian Lee
whose invited talk at CoNLL-2010 inspired this re-
search. We would also like to thank the members of
the Probabilistic Models of Language group at the
School of Informatics for valuable discussions and
comments. We acknowledge the support of EPSRC
through project grant EP/F055765/1.
</bodyText>
<sectionHeader confidence="0.99634" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.893083529411765">
Achterberg, Tobias. 2007. Constraint Integer Pro-
gramming. Ph.D. thesis, Technische Universit¨at
Berlin.
Barzilay, Regina. 2003. Information Fusion for
Multi-Document Summarization: Paraphrasing
and Generation. Ph.D. thesis, Columbia Univer-
sity.
Barzilay, Regina and Noemie Elhadad. 2003. Sen-
tence alignment for monolingual comparable cor-
pora. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing.
Sapporo, Japan, pages 25–32.
Beigman Klebanov, Beata, Kevin Knight, and
Daniel Marcu. 2004. Text simplification for
information-seeking applications. In Proceed-
ings of Ontologies, Dabases, and Applications of
Semantics (ODBASE) International Conference.
</reference>
<page confidence="0.991059">
418
</page>
<reference confidence="0.957892569892473">
Springer, Agia Napa, Cyprus, volume 3290 of
Lecture Notes in Computer Science, pages 735–
747.
Carroll, John, Guido Minnen, Darren Pearce,
Yvonne Canning, Siobhan Devlin, and John Tait.
1999. Simplifying text for language-impaired
readers. In Proceedings of the 9th Conference of
the European Chapter of the ACL. Bergen, Nor-
way, pages 269–270.
Chandrasekar, Raman, Christine Doran, and Ban-
galore Srinivas. 1996. Motivations and meth-
ods for text simplification. In Proceedings of the
16th International Conference on Computational
Linguistics. Copenhagen, Denmark, pages 1041–
1044.
Cohn, Trevor and Mirella Lapata. 2008. Sentence
compression beyond word deletion. In Pro-
ceedings of the 22nd International Conference
on Computational Linguistics. Manchester, UK,
pages 137–144.
Das, Dipanjan and Noah A. Smith. 2009. Paraphrase
identification as probabilistic quasi-synchronous
recognition. In Proceedings of the ACL-IJCNLP.
Suntec, Singapore, pages 468–476.
Devlin, Siobhan. 1999. Simplifying Natural Lan-
guage for Aphasic Readers. Ph.D. thesis, Univer-
sity of Sunderland.
Inui, Kentaro, Atsushi Fujita, Tetsuro Takahashi,
Ryu Iida, and Tomoya Iwakura. 2003. Text sim-
plification for reading assistance: A project note.
In Proceedings of the Second International Work-
shop on Paraphrasing. Association for Computa-
tional Linguistics, Sapporo, Japan, pages 9–16.
Kaji, Nobuhiro, Daisuke Kawahara, Sadao Kuro-
hashi, and Satoshi Sato. 2002. Verb paraphrase
based on case frame alignment. In Proceedings of
40th Annual Meeting of the Association for Com-
putational Linguistics. Association for Compu-
tational Linguistics, Philadelphia, Pennsylvania,
USA, pages 215–222.
Klein, Dan and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of
the 41st Annual Meeting of the Association of
Computational Linguistics. Sapporo, Japan, pages
423–430.
Knight, Kevin and Daniel Marcu. 2002. Summa-
rization beyond sentence extraction: a probabilis-
tic approach to sentence compression. Artificial
Intelligence 139(1):91–107.
Koch, Thorsten. 2004. Rapid Mathematical Pro-
totyping. Ph.D. thesis, Technische Universit¨at
Berlin.
Mitchell, James V. 1985. The Ninth Mental Mea-
surements Year-book. University of Nebraska
Press, Lincoln, Nebraska.
Nastase, Vivi and Michael Strube. 2008. Decoding
Wikipedia categories for knowledge acquisition.
In Proceedings of the 23rd Conference on Artifi-
cial Intelligence. pages 1219–1224.
Nelken, Rani and Stuart Schieber. 2006. Towards
robust context-sensitive sentence alignment for
monolingual corpora. In Proceedings of the 11th
Conference of the European Chapter of the As-
sociation for Computational Linguistics. Trento,
Italy, pages 161–168.
Papineni, Kishore, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a method for auto-
matic evaluation of machine translation. In Pro-
ceedings of the 40th ACL. Philadelphia, PA, pages
311–318.
Ponzetto, Simone Paolo and Michael Strube. 2007.
Knowledge derived from Wikipedia for comput-
ing semantic relatedness. Journal of Artificial In-
telligence Research 30:181–212.
Sauper, Christina and Regina Barzilay. 2009. Au-
tomatically generating Wikipedia articles: A
structure-aware approach. In Proceedings of the
Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Con-
ference on Natural Language Processing of the
AFNLP. Association for Computational Linguis-
tics, Suntec, Singapore, pages 208–216.
Siddharthan, Advaith. 2003. Syntactic Simplifica-
tion and Text Cohesion. Ph.D. thesis, University
of Cambridge, University of Cambridge.
Siddharthan, Advaith. 2004. Syntactic simplifica-
tion and text cohesion. in research on language
and computation. Research on Language and
Computation 4(1):77–109.
Smith, David and Jason Eisner. 2006. Quasi-
synchronous grammars: Alignment by soft pro-
jection of syntactic dependencies. In Proceedings
on the Workshop on Statistical Machine Transla-
</reference>
<page confidence="0.989987">
419
</page>
<reference confidence="0.999609351351351">
tion. Association for Computational Linguistics,
New York City, pages 23–30.
Smith, David A. and Jason Eisner. 2009. Parser
adaptation and projection with quasi-synchronous
grammar features. In Proceedings of the EMNLP.
Suntec, Singapore, pages 822–831.
Snover, Matthew, Nitin Madnani, Bonnie Dorr, and
Richard Schwartz. 2009. Fluency, adequacy,
or HTER? Exploring different human judgments
with a tunable MT metric. In Proceedings of the
Fourth Workshop on Statistical Machine Transla-
tion. Athens, Greece, pages 259–268.
Vickrey, David and Daphne Koller. 2008. Sentence
simplification for semantic role labeling. In Pro-
ceedings of ACL-08: HLT. Association for Com-
putational Linguistics, Columbus, Ohio, pages
344–352.
Wang, Mengqiu, Noah A. Smith, and Teruko Mita-
mura. 2007. What is the Jeopardy model? a quasi-
synchronous grammar for QA. In Proceedings
of the EMNLP-CoNLL. Prague, Czech Republic,
pages 22–32.
Watanabe, Willian Massami, Arnaldo Candido Ju-
nior, Vinicius Rodriguez de Uz˜eda, Renata Pon-
tin de Mattos Fortes, Thiago Alexandre Salgueiro
Pardo, and Sandra Maria Alu´sio. 2009. Facilita:
reading assistance for low-literacy readers. In
Proceedings of the 27th ACM International Con-
ference on Design of Communication. Blooming-
ton, IN.
Woodsend, Kristian, Yansong Feng, and Mirella
Lapata. 2010. Title generation with quasi-
synchronous grammar. In Proceedings of the
2010 Conference on Empirical Methods in Natu-
ral Language Processing. Association for Com-
putational Linguistics, Cambridge, MA, pages
513–523.
Wu, Fei and Daniel S. Weld. 2010. Open infor-
mation extraction using Wikipedia. In Proceed-
ings of the 48th Annual Meeting of the Associ-
ation for Computational Linguistics. Association
for Computational Linguistics, Uppsala, Sweden,
pages 118–127.
Yamada, Kenji and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proceed-
ings of 39th Annual Meeting of the Association
for Computational Linguistics. Toulouse, France,
pages 523–530.
Yamangil, Elif and Rani Nelken. 2008. Mining
Wikipedia revision histories for improving sen-
tence compression. In Proceedings of ACL-08:
HLT, Short Papers. Association for Computa-
tional Linguistics, Columbus, Ohio, pages 137–
140.
Yatskar, Mark, Bo Pang, Cristian Danescu-
Niculescu-Mizil, and Lillian Lee. 2010. For
the sake of simplicity: Unsupervised extrac-
tion of lexical simplifications from Wikipedia.
In Proceedings of the Annual Meeting of the
North American Chapter of the Association for
Computational Linguistics. pages 365–368.
Zhao, Shiqi, Xiang Lan, Ting Liu, and Sheng Li.
2009. Application-driven statistical paraphrase
generation. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural
Language Processing of the AFNLP. Singapore,
pages 834–842.
Zhu, Zhemin, Delphine Bernhard, and Iryna
Gurevych. 2010. A monolingual tree-based trans-
lation model for sentence simplification. In Pro-
ceedings of the 23rd International Conference on
Computational Linguistics. Beijing, China, pages
1353–1361.
</reference>
<page confidence="0.998372">
420
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.623571">
<title confidence="0.9839">Learning to Simplify Sentences with Quasi-Synchronous Grammar Integer Programming</title>
<author confidence="0.678677">Woodsend</author>
<affiliation confidence="0.9348435">Institute for Language, Cognition and School of Informatics, University of</affiliation>
<address confidence="0.88851">10 Crichton Street, Edinburgh EH8</address>
<abstract confidence="0.999454476190476">Text simplification aims to rewrite text into simpler versions, and thus make information accessible to a broader audience. Most previous work simplifies sentences using handcrafted rules aimed at splitting long sentences, or substitutes difficult words using a predefined dictionary. This paper presents a datadriven model based on quasi-synchronous grammar, a formalism that can naturally capture structural mismatches and complex rewrite operations. We describe how such a grammar can be induced from Wikipedia and propose an integer linear programming model for selecting the most appropriate simplification from the space of possible rewrites generated by the grammar. We show experimentally that our method creates simplifications that significantly reduce the reading difficulty of the input, while maintaining grammaticality and preserving its meaning.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Tobias Achterberg</author>
</authors>
<title>Constraint Integer Programming.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Technische Universit¨at Berlin.</institution>
<contexts>
<context position="23906" citStr="Achterberg, 2007" startWordPosition="3867" endWordPosition="3868">rametrized as follows: the number 5http://os.ghalkes.nl/dwdiff.html Table 3: Examples of QG rules involving syntactic simplification (1)–(3) and sentence division (4)–(6). The latter are shown as the tuple (source, target, aux). The transform of nodes from S to ST (for example) rely on the application of syntactic simplification rules rules. Boxed subscripts show aligned nodes. of target words per sentence (wps) was set to 8, and syllables per word (spw) to 1.5. These two parameters were empirically tuned on the training set. To solve the ILP model we used the ZIB Optimization Suite software (Achterberg, 2007; Koch, 2004). The solution was converted into a sentence by removing nodes not chosen from the tree representation, then concatenating the remaining leaf nodes in order. Evaluation We evaluated our model on the same dataset used in Zhu et al. (2010), an aligned corpus of MainEW and SimpleEW sentences. The corpus contains 100/131 source/target sentences and was created automatically. Sentences from this corpus (and their revisions) were excluded from training. We evaluated two versions of our model, one with rewrite rules acquired from revision histories of simplified documents and another one</context>
</contexts>
<marker>Achterberg, 2007</marker>
<rawString>Achterberg, Tobias. 2007. Constraint Integer Programming. Ph.D. thesis, Technische Universit¨at Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
</authors>
<title>Information Fusion for Multi-Document Summarization: Paraphrasing and Generation.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>Columbia University.</institution>
<contexts>
<context position="2768" citStr="Barzilay, 2003" startWordPosition="414" endWordPosition="415">t. The Chicago report gives an indication of what the full report might hold. The full report is due out today. Table 1: Example of a source sentence (top) and its simplification (bottom). speakers (Siddharthan, 2003) and more generally individuals with low literacy (Watanabe et al., 2009). A simplification component could be also used as a preprocessing step to improve the performance of parsers (Chandrasekar et al., 1996), summarizers (Beigman Klebanov et al., 2004) and semantic role labelers (Vickrey and Koller, 2008). Simplification is related to, but different from paraphrase extraction (Barzilay, 2003). We must not only have access to paraphrases (i.e., rewrite rules), but also be able to combine them to generate new text, in a simpler language. The task is also distinct from sentence compression as it aims to render a sentence more accessible while preserving its meaning. On the contrary, compression unavoidably leads to some information loss as it creates shorter sentences without necessarily reducing complexity. In fact, one of the commonest simplification operations is sentence splitting which usually produces longer rather than shorter output! Moreover, mod409 Proceedings of the 2011 C</context>
</contexts>
<marker>Barzilay, 2003</marker>
<rawString>Barzilay, Regina. 2003. Information Fusion for Multi-Document Summarization: Paraphrasing and Generation. Ph.D. thesis, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Noemie Elhadad</author>
</authors>
<title>Sentence alignment for monolingual comparable corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<pages>25--32</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="22325" citStr="Barzilay and Elhadad, 2003" startWordPosition="3618" endWordPosition="3621">ion, we needed to identify and align modified sentences. We first identified modified sections using the Unix diff program, and then individual sentences within the sections were aligned using the program dwdiff5. This resulted in 14,831 paired sentences. With regard to the aligned simplification corpus, we paired 15,000 articles from SimpleEW and MainEW following the language link within the snapshot files. Within the paired articles, we identified aligned sentences using macro alignment (at paragraph level) then micro alignment (at sentence level), using tf.idf scores to measure similarity (Barzilay and Elhadad, 2003; Nelken and Schieber, 2006). All source-target sentences (resulting from revisions or alignments) were parsed with the Stanford parser (Klein and Manning, 2003) in order to label the text with syntactic information. QG rules were created by aligning nodes in these sentences as described earlier. A breakdown of the number and type of rules we obtained from the revision and aligned corpora (after removing rules appearing only once) is given in Table 2. Examples of the most frequently learned QG rules are shown in Table 3. Rules (1)–(3) involve syntactic simplification and rules (4)–(6) involve </context>
</contexts>
<marker>Barzilay, Elhadad, 2003</marker>
<rawString>Barzilay, Regina and Noemie Elhadad. 2003. Sentence alignment for monolingual comparable corpora. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Sapporo, Japan, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beigman Klebanov</author>
<author>Kevin Knight Beata</author>
<author>Daniel Marcu</author>
</authors>
<title>Text simplification for information-seeking applications.</title>
<date>2004</date>
<booktitle>In Proceedings of Ontologies, Dabases, and Applications of Semantics (ODBASE) International Conference.</booktitle>
<contexts>
<context position="2625" citStr="Klebanov et al., 2004" startWordPosition="393" endWordPosition="396"> to the firmness in copper, the analyst noted, was a report by Chicago purchasing agents. The Chicago report precedes the full purchasing agents report. The Chicago report gives an indication of what the full report might hold. The full report is due out today. Table 1: Example of a source sentence (top) and its simplification (bottom). speakers (Siddharthan, 2003) and more generally individuals with low literacy (Watanabe et al., 2009). A simplification component could be also used as a preprocessing step to improve the performance of parsers (Chandrasekar et al., 1996), summarizers (Beigman Klebanov et al., 2004) and semantic role labelers (Vickrey and Koller, 2008). Simplification is related to, but different from paraphrase extraction (Barzilay, 2003). We must not only have access to paraphrases (i.e., rewrite rules), but also be able to combine them to generate new text, in a simpler language. The task is also distinct from sentence compression as it aims to render a sentence more accessible while preserving its meaning. On the contrary, compression unavoidably leads to some information loss as it creates shorter sentences without necessarily reducing complexity. In fact, one of the commonest simpl</context>
</contexts>
<marker>Klebanov, Beata, Marcu, 2004</marker>
<rawString>Beigman Klebanov, Beata, Kevin Knight, and Daniel Marcu. 2004. Text simplification for information-seeking applications. In Proceedings of Ontologies, Dabases, and Applications of Semantics (ODBASE) International Conference.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Agia Napa Springer</author>
<author>Cyprus</author>
</authors>
<booktitle>of Lecture Notes in Computer Science,</booktitle>
<volume>3290</volume>
<pages>735--747</pages>
<marker>Springer, Cyprus, </marker>
<rawString>Springer, Agia Napa, Cyprus, volume 3290 of Lecture Notes in Computer Science, pages 735– 747.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Guido Minnen</author>
<author>Darren Pearce</author>
<author>Yvonne Canning</author>
<author>Siobhan Devlin</author>
<author>John Tait</author>
</authors>
<title>Simplifying text for language-impaired readers.</title>
<date>1999</date>
<booktitle>In Proceedings of the 9th Conference of the European Chapter of the ACL.</booktitle>
<pages>269--270</pages>
<location>Bergen, Norway,</location>
<contexts>
<context position="1735" citStr="Carroll et al., 1999" startWordPosition="246" endWordPosition="249">ntaining grammaticality and preserving its meaning. 1 Introduction Sentence simplification is perhaps one of the oldest text rewriting problems. Given a source sentence, the goal is to create a grammatical target that is easier to read with simpler vocabulary and syntactic structure. An example is shown in Table 1 involving a broad spectrum of rewrite operations such as deletion, substitution, insertion, and reordering. The popularity of the simplification task stems from its potential relevance to various applications. Examples include the development of reading aids for people with aphasia (Carroll et al., 1999), non-native Also contributing to the firmness in copper, the analyst noted, was a report by Chicago purchasing agents, which precedes the full purchasing agents report that is due out today and gives an indication of what the full report might hold. Also contributing to the firmness in copper, the analyst noted, was a report by Chicago purchasing agents. The Chicago report precedes the full purchasing agents report. The Chicago report gives an indication of what the full report might hold. The full report is due out today. Table 1: Example of a source sentence (top) and its simplification (bo</context>
<context position="6616" citStr="Carroll et al., 1999" startWordPosition="993" endWordPosition="996">lity of the QG grammar rules greatly improves when these are learned from revision histories which are less noisy than sentence alignments. When compared against current stateof-the-art methods (Zhu et al., 2010) our model yields significantly simpler output that is both grammatical and meaning preserving. 2 Related Work Sentence simplification has attracted a great deal of attention due to its potential impact on society. The literature is rife with attempts to simplify text using mostly hand-crafted syntactic rules aimed at splitting long and complicated sentences into several simpler ones (Carroll et al., 1999; Chandrasekar et al., 1996; Siddharthan, 2004; Vickrey and Koller, 2008). Other work focuses on lexical simplifications and substitutes difficult words by more common WordNet synonyms or paraphrases found in a predefined dictionary (Devlin, 1999; Inui et al., 2003; Kaji et al., 2002). More recently, Yatskar et al. (2010) explore data-driven methods to learn lexical simplifications from Wikipedia revision histories. A key idea in their work is to utilize SimpleEW edits, while recognizing that these may serve other functions, such as vandalism removal or introduction of new content. Zhu et al. </context>
</contexts>
<marker>Carroll, Minnen, Pearce, Canning, Devlin, Tait, 1999</marker>
<rawString>Carroll, John, Guido Minnen, Darren Pearce, Yvonne Canning, Siobhan Devlin, and John Tait. 1999. Simplifying text for language-impaired readers. In Proceedings of the 9th Conference of the European Chapter of the ACL. Bergen, Norway, pages 269–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raman Chandrasekar</author>
<author>Christine Doran</author>
<author>Bangalore Srinivas</author>
</authors>
<title>Motivations and methods for text simplification.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics.</booktitle>
<pages>1041--1044</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="2580" citStr="Chandrasekar et al., 1996" startWordPosition="387" endWordPosition="390">hat the full report might hold. Also contributing to the firmness in copper, the analyst noted, was a report by Chicago purchasing agents. The Chicago report precedes the full purchasing agents report. The Chicago report gives an indication of what the full report might hold. The full report is due out today. Table 1: Example of a source sentence (top) and its simplification (bottom). speakers (Siddharthan, 2003) and more generally individuals with low literacy (Watanabe et al., 2009). A simplification component could be also used as a preprocessing step to improve the performance of parsers (Chandrasekar et al., 1996), summarizers (Beigman Klebanov et al., 2004) and semantic role labelers (Vickrey and Koller, 2008). Simplification is related to, but different from paraphrase extraction (Barzilay, 2003). We must not only have access to paraphrases (i.e., rewrite rules), but also be able to combine them to generate new text, in a simpler language. The task is also distinct from sentence compression as it aims to render a sentence more accessible while preserving its meaning. On the contrary, compression unavoidably leads to some information loss as it creates shorter sentences without necessarily reducing co</context>
<context position="6643" citStr="Chandrasekar et al., 1996" startWordPosition="997" endWordPosition="1000"> rules greatly improves when these are learned from revision histories which are less noisy than sentence alignments. When compared against current stateof-the-art methods (Zhu et al., 2010) our model yields significantly simpler output that is both grammatical and meaning preserving. 2 Related Work Sentence simplification has attracted a great deal of attention due to its potential impact on society. The literature is rife with attempts to simplify text using mostly hand-crafted syntactic rules aimed at splitting long and complicated sentences into several simpler ones (Carroll et al., 1999; Chandrasekar et al., 1996; Siddharthan, 2004; Vickrey and Koller, 2008). Other work focuses on lexical simplifications and substitutes difficult words by more common WordNet synonyms or paraphrases found in a predefined dictionary (Devlin, 1999; Inui et al., 2003; Kaji et al., 2002). More recently, Yatskar et al. (2010) explore data-driven methods to learn lexical simplifications from Wikipedia revision histories. A key idea in their work is to utilize SimpleEW edits, while recognizing that these may serve other functions, such as vandalism removal or introduction of new content. Zhu et al. (2010) also use Wikipedia t</context>
</contexts>
<marker>Chandrasekar, Doran, Srinivas, 1996</marker>
<rawString>Chandrasekar, Raman, Christine Doran, and Bangalore Srinivas. 1996. Motivations and methods for text simplification. In Proceedings of the 16th International Conference on Computational Linguistics. Copenhagen, Denmark, pages 1041– 1044.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Sentence compression beyond word deletion.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics.</booktitle>
<pages>137--144</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="3849" citStr="Cohn and Lapata 2008" startWordPosition="574" endWordPosition="577">ation operations is sentence splitting which usually produces longer rather than shorter output! Moreover, mod409 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 409–420, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics els developed for sentence compression have been mostly designed with one rewrite operation in mind, namely word deletion, and are thus unable to model consistent syntactic effects such as reordering, sentence splitting, changes in non-terminal categories, and lexical substitution (but see Cohn and Lapata 2008 and Zhao et al. 2009 for notable exceptions). In this paper we propose a sentence simplification model that is able to handle structural mismatches and complex rewriting operations. Our approach is based on quasi-synchronous grammar (QG, Smith and Eisner 2006), a formalism that is well suited for text rewriting. Rather than postulating a strictly synchronous structure over the source and target sentences, QG identifies a “sloppy” alignment of parse trees assuming that the target tree is in some way “inspired by” the source tree. Specifically, our model is formulated as an integer linear progr</context>
</contexts>
<marker>Cohn, Lapata, 2008</marker>
<rawString>Cohn, Trevor and Mirella Lapata. 2008. Sentence compression beyond word deletion. In Proceedings of the 22nd International Conference on Computational Linguistics. Manchester, UK, pages 137–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
</authors>
<title>Paraphrase identification as probabilistic quasi-synchronous recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP. Suntec, Singapore,</booktitle>
<pages>468--476</pages>
<contexts>
<context position="9599" citStr="Das and Smith, 2009" startWordPosition="1458" endWordPosition="1461">a. Compared to Zhu et al., our model is conceptually simpler and more general. The proposed ILP formulation not only allows to efficiently search through the space of many QG rules but also to incorporate constraints relating to grammaticality and the task at hand without the added computational cost of integrating a language model. Furthermore, our learning framework is not limited to simplification and could be easily adapted to other rewriting tasks. Indeed, the QG formalism has been previously applied to parser adaptation and projection (Smith and Eisner, 2009), paraphrase identification (Das and Smith, 2009), question answering (Wang et al., 2007), and title generation (Woodsend et al., 2010). Finally, our work relates to a large body of recent literature on Wikipedia and its potential for a wide range of NLP tasks. Beyond text rewriting, examples include semantic relatedness (Ponzetto and Strube, 2007), information extraction (Wu and Weld, 2010), ontology induction (Nastase and Strube, 2008), and the automatic creation of overview articles (Sauper and Barzilay, 2009). 3 Sentence Simplification Model Our model takes a single sentence as input and creates a version that is simpler to read. This ma</context>
</contexts>
<marker>Das, Smith, 2009</marker>
<rawString>Das, Dipanjan and Noah A. Smith. 2009. Paraphrase identification as probabilistic quasi-synchronous recognition. In Proceedings of the ACL-IJCNLP. Suntec, Singapore, pages 468–476.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siobhan Devlin</author>
</authors>
<title>Simplifying Natural Language for Aphasic Readers.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Sunderland.</institution>
<contexts>
<context position="6862" citStr="Devlin, 1999" startWordPosition="1030" endWordPosition="1031">tput that is both grammatical and meaning preserving. 2 Related Work Sentence simplification has attracted a great deal of attention due to its potential impact on society. The literature is rife with attempts to simplify text using mostly hand-crafted syntactic rules aimed at splitting long and complicated sentences into several simpler ones (Carroll et al., 1999; Chandrasekar et al., 1996; Siddharthan, 2004; Vickrey and Koller, 2008). Other work focuses on lexical simplifications and substitutes difficult words by more common WordNet synonyms or paraphrases found in a predefined dictionary (Devlin, 1999; Inui et al., 2003; Kaji et al., 2002). More recently, Yatskar et al. (2010) explore data-driven methods to learn lexical simplifications from Wikipedia revision histories. A key idea in their work is to utilize SimpleEW edits, while recognizing that these may serve other functions, such as vandalism removal or introduction of new content. Zhu et al. (2010) also use Wikipedia to learn a sentence simplification model which is able to perform four rewrite operations, namely substitution, reordering, splitting, and deletion. Inspired by syntax-based SMT (Yamada and Knight, 2001), their model con</context>
</contexts>
<marker>Devlin, 1999</marker>
<rawString>Devlin, Siobhan. 1999. Simplifying Natural Language for Aphasic Readers. Ph.D. thesis, University of Sunderland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kentaro Inui</author>
<author>Atsushi Fujita</author>
<author>Tetsuro Takahashi</author>
<author>Ryu Iida</author>
<author>Tomoya Iwakura</author>
</authors>
<title>Text simplification for reading assistance: A project note.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second International Workshop on Paraphrasing. Association for Computational Linguistics,</booktitle>
<pages>9--16</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="6881" citStr="Inui et al., 2003" startWordPosition="1032" endWordPosition="1035">oth grammatical and meaning preserving. 2 Related Work Sentence simplification has attracted a great deal of attention due to its potential impact on society. The literature is rife with attempts to simplify text using mostly hand-crafted syntactic rules aimed at splitting long and complicated sentences into several simpler ones (Carroll et al., 1999; Chandrasekar et al., 1996; Siddharthan, 2004; Vickrey and Koller, 2008). Other work focuses on lexical simplifications and substitutes difficult words by more common WordNet synonyms or paraphrases found in a predefined dictionary (Devlin, 1999; Inui et al., 2003; Kaji et al., 2002). More recently, Yatskar et al. (2010) explore data-driven methods to learn lexical simplifications from Wikipedia revision histories. A key idea in their work is to utilize SimpleEW edits, while recognizing that these may serve other functions, such as vandalism removal or introduction of new content. Zhu et al. (2010) also use Wikipedia to learn a sentence simplification model which is able to perform four rewrite operations, namely substitution, reordering, splitting, and deletion. Inspired by syntax-based SMT (Yamada and Knight, 2001), their model consists of three comp</context>
</contexts>
<marker>Inui, Fujita, Takahashi, Iida, Iwakura, 2003</marker>
<rawString>Inui, Kentaro, Atsushi Fujita, Tetsuro Takahashi, Ryu Iida, and Tomoya Iwakura. 2003. Text simplification for reading assistance: A project note. In Proceedings of the Second International Workshop on Paraphrasing. Association for Computational Linguistics, Sapporo, Japan, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobuhiro Kaji</author>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
<author>Satoshi Sato</author>
</authors>
<title>Verb paraphrase based on case frame alignment.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics,</booktitle>
<pages>215--222</pages>
<location>Philadelphia, Pennsylvania, USA,</location>
<contexts>
<context position="6901" citStr="Kaji et al., 2002" startWordPosition="1036" endWordPosition="1039"> meaning preserving. 2 Related Work Sentence simplification has attracted a great deal of attention due to its potential impact on society. The literature is rife with attempts to simplify text using mostly hand-crafted syntactic rules aimed at splitting long and complicated sentences into several simpler ones (Carroll et al., 1999; Chandrasekar et al., 1996; Siddharthan, 2004; Vickrey and Koller, 2008). Other work focuses on lexical simplifications and substitutes difficult words by more common WordNet synonyms or paraphrases found in a predefined dictionary (Devlin, 1999; Inui et al., 2003; Kaji et al., 2002). More recently, Yatskar et al. (2010) explore data-driven methods to learn lexical simplifications from Wikipedia revision histories. A key idea in their work is to utilize SimpleEW edits, while recognizing that these may serve other functions, such as vandalism removal or introduction of new content. Zhu et al. (2010) also use Wikipedia to learn a sentence simplification model which is able to perform four rewrite operations, namely substitution, reordering, splitting, and deletion. Inspired by syntax-based SMT (Yamada and Knight, 2001), their model consists of three components: a language m</context>
</contexts>
<marker>Kaji, Kawahara, Kurohashi, Sato, 2002</marker>
<rawString>Kaji, Nobuhiro, Daisuke Kawahara, Sadao Kurohashi, and Satoshi Sato. 2002. Verb paraphrase based on case frame alignment. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Philadelphia, Pennsylvania, USA, pages 215–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association of Computational Linguistics.</booktitle>
<pages>423--430</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="11520" citStr="Klein and Manning, 2003" startWordPosition="1757" endWordPosition="1760"> clauses, each of which is simplified (lexically and structurally) through QG rewrite rules. We generate all possible simplifications for a given input and use the ILP to find the best target subject to grammaticality constraints. In what follows we first detail how we extract QG rewrite rules as these form the backbone of our model and then formulate the ILP proper. 3.1 Quasi-synchronous Grammar Phrase alignment Our model operates on individual sentences annotated with syntactic information i.e., phrase structure trees. In our experiments, we obtain this information from the Stanford parser (Klein and Manning, 2003) but any other broadly similar parser could be used instead. Given an input sentence S1 or its parse tree T1, the QG constructs a monolingual grammar for parsing, or generating, possible translation trees T2. A grammar node in the target tree T2 is modeled on a subset of nodes in the source tree, with a rather loose alignment between the trees. We take aligned sentence pairs represented as phrase structure trees and build up a list of leaf node alignments based on lexical identity. We align direct parent nodes where more than one child node aligns. QG rules are created from aligned nodes above</context>
<context position="22486" citStr="Klein and Manning, 2003" startWordPosition="3641" endWordPosition="3644">e sections were aligned using the program dwdiff5. This resulted in 14,831 paired sentences. With regard to the aligned simplification corpus, we paired 15,000 articles from SimpleEW and MainEW following the language link within the snapshot files. Within the paired articles, we identified aligned sentences using macro alignment (at paragraph level) then micro alignment (at sentence level), using tf.idf scores to measure similarity (Barzilay and Elhadad, 2003; Nelken and Schieber, 2006). All source-target sentences (resulting from revisions or alignments) were parsed with the Stanford parser (Klein and Manning, 2003) in order to label the text with syntactic information. QG rules were created by aligning nodes in these sentences as described earlier. A breakdown of the number and type of rules we obtained from the revision and aligned corpora (after removing rules appearing only once) is given in Table 2. Examples of the most frequently learned QG rules are shown in Table 3. Rules (1)–(3) involve syntactic simplification and rules (4)–(6) involve sentence splitting. Examples of common lexical simplifications found by our grammar are: “discovered” “found”, “defeated” “won against”, “may refer to” “could me</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein, Dan and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting of the Association of Computational Linguistics. Sapporo, Japan, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Summarization beyond sentence extraction: a probabilistic approach to sentence compression.</title>
<date>2002</date>
<journal>Artificial Intelligence</journal>
<volume>139</volume>
<issue>1</issue>
<contexts>
<context position="28521" citStr="Knight and Marcu 2002" startWordPosition="4616" endWordPosition="4619"> the human SimpleEW gold standard by computing BLEU (Papineni et al., 2002) and TERp (Snover et al., 2009). Both measures are commonly used to automatically evaluate the quality of machine translation output. BLEU9 scores the target output by counting n-gram matches with the reference, whereas TERp is similar to word error rate, the only difference being that it allows shifts and thus can account for word order differences. TERp also allows for stem, synonym, and paraphrase substitutions which are common rewrite operations in simplification. In line with previous work on text rewriting (e.g., Knight and Marcu 2002) we also evaluated 9We calculated single-reference BLEU using the mtevalv13a script (with the default settings). system output by eliciting human judgments. We conducted three experiments. In the first experiment participants were presented with a source sentence and its target simplification and asked to rate whether the latter was easier to read compared to the source. In the second experiment, they were asked to rate the grammaticality of the simplified output. In the third experiment, they judged how well the simplification preserved the meaning of the source. In all experiments participan</context>
</contexts>
<marker>Knight, Marcu, 2002</marker>
<rawString>Knight, Kevin and Daniel Marcu. 2002. Summarization beyond sentence extraction: a probabilistic approach to sentence compression. Artificial Intelligence 139(1):91–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Koch</author>
</authors>
<date>2004</date>
<booktitle>Rapid Mathematical Prototyping. Ph.D. thesis,</booktitle>
<institution>Technische Universit¨at Berlin.</institution>
<contexts>
<context position="23919" citStr="Koch, 2004" startWordPosition="3869" endWordPosition="3870">ows: the number 5http://os.ghalkes.nl/dwdiff.html Table 3: Examples of QG rules involving syntactic simplification (1)–(3) and sentence division (4)–(6). The latter are shown as the tuple (source, target, aux). The transform of nodes from S to ST (for example) rely on the application of syntactic simplification rules rules. Boxed subscripts show aligned nodes. of target words per sentence (wps) was set to 8, and syllables per word (spw) to 1.5. These two parameters were empirically tuned on the training set. To solve the ILP model we used the ZIB Optimization Suite software (Achterberg, 2007; Koch, 2004). The solution was converted into a sentence by removing nodes not chosen from the tree representation, then concatenating the remaining leaf nodes in order. Evaluation We evaluated our model on the same dataset used in Zhu et al. (2010), an aligned corpus of MainEW and SimpleEW sentences. The corpus contains 100/131 source/target sentences and was created automatically. Sentences from this corpus (and their revisions) were excluded from training. We evaluated two versions of our model, one with rewrite rules acquired from revision histories of simplified documents and another one with rules e</context>
</contexts>
<marker>Koch, 2004</marker>
<rawString>Koch, Thorsten. 2004. Rapid Mathematical Prototyping. Ph.D. thesis, Technische Universit¨at Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James V Mitchell</author>
</authors>
<title>The Ninth Mental Measurements Year-book.</title>
<date>1985</date>
<publisher>University of Nebraska Press,</publisher>
<location>Lincoln, Nebraska.</location>
<contexts>
<context position="17063" citStr="Mitchell 1985" startWordPosition="2767" endWordPosition="2768">= log (nr)r , where nr is the number of times the QG rule r was seen in the training data, and Nr the number of times all suitable rules for this phrase node were seen. If no suitable rules exist, we set gi = 0. The other two components of the objective, hw and hsy, are global in nature, and guide the ILP 413 towards simpler language. They draw inspiration from existing measures of readability (the ease with which a document can be read and understood). The primary aim of readability formulas is to assess whether texts or books are suitable for students at particular grade levels or ages (see Mitchell 1985 for an overview). Intuitively, texts ought to be simpler if they correspond to low reading levels. A commonly used reading level measure is the Flesch-Kincaid Grade Level (FKGL) index which estimates readability as a combination of the average number of syllables per word and the average number of words per sentence. Unfortunately, this measure is nonlinear2 and cannot be incorporated directly into the objective of the ILP. Instead, we propose a linear approximation. We provide the ILP with targets for the average number of words per sentence (wps), and syllables per word (spw). hw(x,y) then </context>
</contexts>
<marker>Mitchell, 1985</marker>
<rawString>Mitchell, James V. 1985. The Ninth Mental Measurements Year-book. University of Nebraska Press, Lincoln, Nebraska.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Michael Strube</author>
</authors>
<title>Decoding Wikipedia categories for knowledge acquisition.</title>
<date>2008</date>
<booktitle>In Proceedings of the 23rd Conference on Artificial Intelligence.</booktitle>
<pages>1219--1224</pages>
<contexts>
<context position="9991" citStr="Nastase and Strube, 2008" startWordPosition="1517" endWordPosition="1520">o simplification and could be easily adapted to other rewriting tasks. Indeed, the QG formalism has been previously applied to parser adaptation and projection (Smith and Eisner, 2009), paraphrase identification (Das and Smith, 2009), question answering (Wang et al., 2007), and title generation (Woodsend et al., 2010). Finally, our work relates to a large body of recent literature on Wikipedia and its potential for a wide range of NLP tasks. Beyond text rewriting, examples include semantic relatedness (Ponzetto and Strube, 2007), information extraction (Wu and Weld, 2010), ontology induction (Nastase and Strube, 2008), and the automatic creation of overview articles (Sauper and Barzilay, 2009). 3 Sentence Simplification Model Our model takes a single sentence as input and creates a version that is simpler to read. This may involve rendering syntactically complex structures simpler (e.g., through sentence splitting), or substituting rare words with more common words or phrases (e.g., such that a second language learner may be familiar with), or deleting elements of the original text in order to produce a relatively simpler and shallower syntactic structure. In addition, the output must be grammatical and co</context>
</contexts>
<marker>Nastase, Strube, 2008</marker>
<rawString>Nastase, Vivi and Michael Strube. 2008. Decoding Wikipedia categories for knowledge acquisition. In Proceedings of the 23rd Conference on Artificial Intelligence. pages 1219–1224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rani Nelken</author>
<author>Stuart Schieber</author>
</authors>
<title>Towards robust context-sensitive sentence alignment for monolingual corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<pages>161--168</pages>
<location>Trento, Italy,</location>
<contexts>
<context position="22353" citStr="Nelken and Schieber, 2006" startWordPosition="3622" endWordPosition="3625">nd align modified sentences. We first identified modified sections using the Unix diff program, and then individual sentences within the sections were aligned using the program dwdiff5. This resulted in 14,831 paired sentences. With regard to the aligned simplification corpus, we paired 15,000 articles from SimpleEW and MainEW following the language link within the snapshot files. Within the paired articles, we identified aligned sentences using macro alignment (at paragraph level) then micro alignment (at sentence level), using tf.idf scores to measure similarity (Barzilay and Elhadad, 2003; Nelken and Schieber, 2006). All source-target sentences (resulting from revisions or alignments) were parsed with the Stanford parser (Klein and Manning, 2003) in order to label the text with syntactic information. QG rules were created by aligning nodes in these sentences as described earlier. A breakdown of the number and type of rules we obtained from the revision and aligned corpora (after removing rules appearing only once) is given in Table 2. Examples of the most frequently learned QG rules are shown in Table 3. Rules (1)–(3) involve syntactic simplification and rules (4)–(6) involve sentence splitting. Examples</context>
</contexts>
<marker>Nelken, Schieber, 2006</marker>
<rawString>Nelken, Rani and Stuart Schieber. 2006. Towards robust context-sensitive sentence alignment for monolingual corpora. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics. Trento, Italy, pages 161–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th ACL.</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="27974" citStr="Papineni et al., 2002" startWordPosition="4529" endWordPosition="4532">ext (MainEW: input source, SimpleEW: simplified target). to the source. We evaluated model output in two ways, using automatic evaluation measures and human judgments. Intuitively, readability measures ought to be suitable for assessing the output of simplification systems. We report results with the well-known FleschKincaid Grade Level index (FKGL). Experiments with other readability measures such as the Flesch Reading Ease and the Coleman-Liau index obtained similar results. In addition, we also assessed how the system output differed from the human SimpleEW gold standard by computing BLEU (Papineni et al., 2002) and TERp (Snover et al., 2009). Both measures are commonly used to automatically evaluate the quality of machine translation output. BLEU9 scores the target output by counting n-gram matches with the reference, whereas TERp is similar to word error rate, the only difference being that it allows shifts and thus can account for word order differences. TERp also allows for stem, synonym, and paraphrase substitutions which are common rewrite operations in simplification. In line with previous work on text rewriting (e.g., Knight and Marcu 2002) we also evaluated 9We calculated single-reference BL</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th ACL. Philadelphia, PA, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Michael Strube</author>
</authors>
<title>Knowledge derived from Wikipedia for computing semantic relatedness.</title>
<date>2007</date>
<journal>Journal of Artificial Intelligence Research</journal>
<pages>30--181</pages>
<contexts>
<context position="9900" citStr="Ponzetto and Strube, 2007" startWordPosition="1505" endWordPosition="1508">l cost of integrating a language model. Furthermore, our learning framework is not limited to simplification and could be easily adapted to other rewriting tasks. Indeed, the QG formalism has been previously applied to parser adaptation and projection (Smith and Eisner, 2009), paraphrase identification (Das and Smith, 2009), question answering (Wang et al., 2007), and title generation (Woodsend et al., 2010). Finally, our work relates to a large body of recent literature on Wikipedia and its potential for a wide range of NLP tasks. Beyond text rewriting, examples include semantic relatedness (Ponzetto and Strube, 2007), information extraction (Wu and Weld, 2010), ontology induction (Nastase and Strube, 2008), and the automatic creation of overview articles (Sauper and Barzilay, 2009). 3 Sentence Simplification Model Our model takes a single sentence as input and creates a version that is simpler to read. This may involve rendering syntactically complex structures simpler (e.g., through sentence splitting), or substituting rare words with more common words or phrases (e.g., such that a second language learner may be familiar with), or deleting elements of the original text in order to produce a relatively si</context>
</contexts>
<marker>Ponzetto, Strube, 2007</marker>
<rawString>Ponzetto, Simone Paolo and Michael Strube. 2007. Knowledge derived from Wikipedia for computing semantic relatedness. Journal of Artificial Intelligence Research 30:181–212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christina Sauper</author>
<author>Regina Barzilay</author>
</authors>
<title>Automatically generating Wikipedia articles: A structure-aware approach.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. Association for Computational Linguistics, Suntec, Singapore,</booktitle>
<pages>208--216</pages>
<contexts>
<context position="10068" citStr="Sauper and Barzilay, 2009" startWordPosition="1528" endWordPosition="1531">d, the QG formalism has been previously applied to parser adaptation and projection (Smith and Eisner, 2009), paraphrase identification (Das and Smith, 2009), question answering (Wang et al., 2007), and title generation (Woodsend et al., 2010). Finally, our work relates to a large body of recent literature on Wikipedia and its potential for a wide range of NLP tasks. Beyond text rewriting, examples include semantic relatedness (Ponzetto and Strube, 2007), information extraction (Wu and Weld, 2010), ontology induction (Nastase and Strube, 2008), and the automatic creation of overview articles (Sauper and Barzilay, 2009). 3 Sentence Simplification Model Our model takes a single sentence as input and creates a version that is simpler to read. This may involve rendering syntactically complex structures simpler (e.g., through sentence splitting), or substituting rare words with more common words or phrases (e.g., such that a second language learner may be familiar with), or deleting elements of the original text in order to produce a relatively simpler and shallower syntactic structure. In addition, the output must be grammatical and coherent. These constraints are global in their scope, and cannot be adequately</context>
</contexts>
<marker>Sauper, Barzilay, 2009</marker>
<rawString>Sauper, Christina and Regina Barzilay. 2009. Automatically generating Wikipedia articles: A structure-aware approach. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. Association for Computational Linguistics, Suntec, Singapore, pages 208–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Advaith Siddharthan</author>
</authors>
<title>Syntactic Simplification and Text Cohesion.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge, University of Cambridge.</institution>
<contexts>
<context position="2370" citStr="Siddharthan, 2003" startWordPosition="356" endWordPosition="357"> contributing to the firmness in copper, the analyst noted, was a report by Chicago purchasing agents, which precedes the full purchasing agents report that is due out today and gives an indication of what the full report might hold. Also contributing to the firmness in copper, the analyst noted, was a report by Chicago purchasing agents. The Chicago report precedes the full purchasing agents report. The Chicago report gives an indication of what the full report might hold. The full report is due out today. Table 1: Example of a source sentence (top) and its simplification (bottom). speakers (Siddharthan, 2003) and more generally individuals with low literacy (Watanabe et al., 2009). A simplification component could be also used as a preprocessing step to improve the performance of parsers (Chandrasekar et al., 1996), summarizers (Beigman Klebanov et al., 2004) and semantic role labelers (Vickrey and Koller, 2008). Simplification is related to, but different from paraphrase extraction (Barzilay, 2003). We must not only have access to paraphrases (i.e., rewrite rules), but also be able to combine them to generate new text, in a simpler language. The task is also distinct from sentence compression as </context>
</contexts>
<marker>Siddharthan, 2003</marker>
<rawString>Siddharthan, Advaith. 2003. Syntactic Simplification and Text Cohesion. Ph.D. thesis, University of Cambridge, University of Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Advaith Siddharthan</author>
</authors>
<title>Syntactic simplification and text cohesion. in research on language and computation.</title>
<date>2004</date>
<journal>Research on Language and Computation</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="6662" citStr="Siddharthan, 2004" startWordPosition="1001" endWordPosition="1002">n these are learned from revision histories which are less noisy than sentence alignments. When compared against current stateof-the-art methods (Zhu et al., 2010) our model yields significantly simpler output that is both grammatical and meaning preserving. 2 Related Work Sentence simplification has attracted a great deal of attention due to its potential impact on society. The literature is rife with attempts to simplify text using mostly hand-crafted syntactic rules aimed at splitting long and complicated sentences into several simpler ones (Carroll et al., 1999; Chandrasekar et al., 1996; Siddharthan, 2004; Vickrey and Koller, 2008). Other work focuses on lexical simplifications and substitutes difficult words by more common WordNet synonyms or paraphrases found in a predefined dictionary (Devlin, 1999; Inui et al., 2003; Kaji et al., 2002). More recently, Yatskar et al. (2010) explore data-driven methods to learn lexical simplifications from Wikipedia revision histories. A key idea in their work is to utilize SimpleEW edits, while recognizing that these may serve other functions, such as vandalism removal or introduction of new content. Zhu et al. (2010) also use Wikipedia to learn a sentence </context>
</contexts>
<marker>Siddharthan, 2004</marker>
<rawString>Siddharthan, Advaith. 2004. Syntactic simplification and text cohesion. in research on language and computation. Research on Language and Computation 4(1):77–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Quasisynchronous grammars: Alignment by soft projection of syntactic dependencies.</title>
<date>2006</date>
<booktitle>In Proceedings on the Workshop on Statistical Machine Translation. Association for Computational Linguistics,</booktitle>
<pages>23--30</pages>
<location>New York City,</location>
<contexts>
<context position="4110" citStr="Smith and Eisner 2006" startWordPosition="614" endWordPosition="617"> c�2011 Association for Computational Linguistics els developed for sentence compression have been mostly designed with one rewrite operation in mind, namely word deletion, and are thus unable to model consistent syntactic effects such as reordering, sentence splitting, changes in non-terminal categories, and lexical substitution (but see Cohn and Lapata 2008 and Zhao et al. 2009 for notable exceptions). In this paper we propose a sentence simplification model that is able to handle structural mismatches and complex rewriting operations. Our approach is based on quasi-synchronous grammar (QG, Smith and Eisner 2006), a formalism that is well suited for text rewriting. Rather than postulating a strictly synchronous structure over the source and target sentences, QG identifies a “sloppy” alignment of parse trees assuming that the target tree is in some way “inspired by” the source tree. Specifically, our model is formulated as an integer linear program and uses QG to capture the space of all possible rewrites. Given a source tree, it finds the best target tree licensed by the grammar subject to constraints such as sentence length and reading ease. Our model is conceptually simple and computationally effici</context>
<context position="8278" citStr="Smith and Eisner 2006" startWordPosition="1246" endWordPosition="1249">rget sentence s is a simpler version of the source c, and a decoder which searches for the simplification s which maximizes P(s)P(s|c). The translation model is the product of the aforementioned four rewrite operations whose probabilities are estimated from a parallel corpus of MainEW and SimpleEW sentences using an expectation maximization algorithm. Their decoder translates sentences into simpler alternatives by greedily selecting the branch in the source tree with the highest probability. 410 Our own work formulates sentence simplification in the framework of Quasi-synchronous grammar (QG, Smith and Eisner 2006). QG allows to describe non-isomorphic tree pairs (the grammar rules can comprise trees of arbitrary depth, and fragments can be mapped) and is thus suited to text-rewriting tasks which typically involve a number of local modifications to the input text. We use quasi-synchronous grammar to learn a wide range of rewrite operations capturing both lexical and structural simplifications naturally without any additional rule engineering. In contrast to Yatskar et al. (2010) and Zhu et al. (2010), simplification operations (e.g., substitution or splitting) are not modeled explicitly; instead, we lea</context>
<context position="14114" citStr="Smith and Eisner (2006)" startWordPosition="2198" endWordPosition="2201">rated in Figure 1. 3.2 ILP-based Generation We cast the problem of finding a suitable target simplification given a source sentence as an integer linear program (ILP). Specifically, simplified text is created from source sentence parse trees by identifying and applying QG grammar rules. These will have matching structure and may also require lexical matching (shown using italics in the example rules in Figure 1). The generation process starts at the root node of the parse tree, applying QG rules to subtrees until leaf nodes are reached. We do not use the Bayesian probability model proposed by Smith and Eisner (2006) to identify the best sequence of simplification rules. Instead, where there is more than one matching rule, and so more than one simplification is possible, the alternatives are all generated and incorporated into the target phrase structure tree. The ILP model operates over this phrase structure tree and selects the phrase nodes from which to form the target output. Applying the QG rules on the source sentence generates a number of auxiliary sentences. Let S be this set of sentences. Let P be the set of nodes in the phrase structure trees of the auxiliary sentences, and Ps ⊂ P be the set of </context>
</contexts>
<marker>Smith, Eisner, 2006</marker>
<rawString>Smith, David and Jason Eisner. 2006. Quasisynchronous grammars: Alignment by soft projection of syntactic dependencies. In Proceedings on the Workshop on Statistical Machine Translation. Association for Computational Linguistics, New York City, pages 23–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Parser adaptation and projection with quasi-synchronous grammar features.</title>
<date>2009</date>
<booktitle>In Proceedings of the EMNLP. Suntec, Singapore,</booktitle>
<pages>822--831</pages>
<contexts>
<context position="9550" citStr="Smith and Eisner, 2009" startWordPosition="1452" endWordPosition="1455">earn appropriate rules that reflect the training data. Compared to Zhu et al., our model is conceptually simpler and more general. The proposed ILP formulation not only allows to efficiently search through the space of many QG rules but also to incorporate constraints relating to grammaticality and the task at hand without the added computational cost of integrating a language model. Furthermore, our learning framework is not limited to simplification and could be easily adapted to other rewriting tasks. Indeed, the QG formalism has been previously applied to parser adaptation and projection (Smith and Eisner, 2009), paraphrase identification (Das and Smith, 2009), question answering (Wang et al., 2007), and title generation (Woodsend et al., 2010). Finally, our work relates to a large body of recent literature on Wikipedia and its potential for a wide range of NLP tasks. Beyond text rewriting, examples include semantic relatedness (Ponzetto and Strube, 2007), information extraction (Wu and Weld, 2010), ontology induction (Nastase and Strube, 2008), and the automatic creation of overview articles (Sauper and Barzilay, 2009). 3 Sentence Simplification Model Our model takes a single sentence as input and c</context>
</contexts>
<marker>Smith, Eisner, 2009</marker>
<rawString>Smith, David A. and Jason Eisner. 2009. Parser adaptation and projection with quasi-synchronous grammar features. In Proceedings of the EMNLP. Suntec, Singapore, pages 822–831.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Nitin Madnani</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
</authors>
<title>Fluency, adequacy, or HTER? Exploring different human judgments with a tunable MT metric.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation.</booktitle>
<pages>259--268</pages>
<location>Athens, Greece,</location>
<contexts>
<context position="28005" citStr="Snover et al., 2009" startWordPosition="4535" endWordPosition="4538">EW: simplified target). to the source. We evaluated model output in two ways, using automatic evaluation measures and human judgments. Intuitively, readability measures ought to be suitable for assessing the output of simplification systems. We report results with the well-known FleschKincaid Grade Level index (FKGL). Experiments with other readability measures such as the Flesch Reading Ease and the Coleman-Liau index obtained similar results. In addition, we also assessed how the system output differed from the human SimpleEW gold standard by computing BLEU (Papineni et al., 2002) and TERp (Snover et al., 2009). Both measures are commonly used to automatically evaluate the quality of machine translation output. BLEU9 scores the target output by counting n-gram matches with the reference, whereas TERp is similar to word error rate, the only difference being that it allows shifts and thus can account for word order differences. TERp also allows for stem, synonym, and paraphrase substitutions which are common rewrite operations in simplification. In line with previous work on text rewriting (e.g., Knight and Marcu 2002) we also evaluated 9We calculated single-reference BLEU using the mtevalv13a script </context>
</contexts>
<marker>Snover, Madnani, Dorr, Schwartz, 2009</marker>
<rawString>Snover, Matthew, Nitin Madnani, Bonnie Dorr, and Richard Schwartz. 2009. Fluency, adequacy, or HTER? Exploring different human judgments with a tunable MT metric. In Proceedings of the Fourth Workshop on Statistical Machine Translation. Athens, Greece, pages 259–268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vickrey</author>
<author>Daphne Koller</author>
</authors>
<title>Sentence simplification for semantic role labeling.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT. Association for Computational Linguistics,</booktitle>
<pages>344--352</pages>
<location>Columbus, Ohio,</location>
<contexts>
<context position="2679" citStr="Vickrey and Koller, 2008" startWordPosition="401" endWordPosition="404">a report by Chicago purchasing agents. The Chicago report precedes the full purchasing agents report. The Chicago report gives an indication of what the full report might hold. The full report is due out today. Table 1: Example of a source sentence (top) and its simplification (bottom). speakers (Siddharthan, 2003) and more generally individuals with low literacy (Watanabe et al., 2009). A simplification component could be also used as a preprocessing step to improve the performance of parsers (Chandrasekar et al., 1996), summarizers (Beigman Klebanov et al., 2004) and semantic role labelers (Vickrey and Koller, 2008). Simplification is related to, but different from paraphrase extraction (Barzilay, 2003). We must not only have access to paraphrases (i.e., rewrite rules), but also be able to combine them to generate new text, in a simpler language. The task is also distinct from sentence compression as it aims to render a sentence more accessible while preserving its meaning. On the contrary, compression unavoidably leads to some information loss as it creates shorter sentences without necessarily reducing complexity. In fact, one of the commonest simplification operations is sentence splitting which usual</context>
<context position="6689" citStr="Vickrey and Koller, 2008" startWordPosition="1003" endWordPosition="1006"> from revision histories which are less noisy than sentence alignments. When compared against current stateof-the-art methods (Zhu et al., 2010) our model yields significantly simpler output that is both grammatical and meaning preserving. 2 Related Work Sentence simplification has attracted a great deal of attention due to its potential impact on society. The literature is rife with attempts to simplify text using mostly hand-crafted syntactic rules aimed at splitting long and complicated sentences into several simpler ones (Carroll et al., 1999; Chandrasekar et al., 1996; Siddharthan, 2004; Vickrey and Koller, 2008). Other work focuses on lexical simplifications and substitutes difficult words by more common WordNet synonyms or paraphrases found in a predefined dictionary (Devlin, 1999; Inui et al., 2003; Kaji et al., 2002). More recently, Yatskar et al. (2010) explore data-driven methods to learn lexical simplifications from Wikipedia revision histories. A key idea in their work is to utilize SimpleEW edits, while recognizing that these may serve other functions, such as vandalism removal or introduction of new content. Zhu et al. (2010) also use Wikipedia to learn a sentence simplification model which </context>
</contexts>
<marker>Vickrey, Koller, 2008</marker>
<rawString>Vickrey, David and Daphne Koller. 2008. Sentence simplification for semantic role labeling. In Proceedings of ACL-08: HLT. Association for Computational Linguistics, Columbus, Ohio, pages 344–352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Noah A Smith</author>
<author>Teruko Mitamura</author>
</authors>
<title>What is the Jeopardy model? a quasisynchronous grammar for QA.</title>
<date>2007</date>
<booktitle>In Proceedings of the EMNLP-CoNLL.</booktitle>
<pages>22--32</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="9639" citStr="Wang et al., 2007" startWordPosition="1464" endWordPosition="1467">nceptually simpler and more general. The proposed ILP formulation not only allows to efficiently search through the space of many QG rules but also to incorporate constraints relating to grammaticality and the task at hand without the added computational cost of integrating a language model. Furthermore, our learning framework is not limited to simplification and could be easily adapted to other rewriting tasks. Indeed, the QG formalism has been previously applied to parser adaptation and projection (Smith and Eisner, 2009), paraphrase identification (Das and Smith, 2009), question answering (Wang et al., 2007), and title generation (Woodsend et al., 2010). Finally, our work relates to a large body of recent literature on Wikipedia and its potential for a wide range of NLP tasks. Beyond text rewriting, examples include semantic relatedness (Ponzetto and Strube, 2007), information extraction (Wu and Weld, 2010), ontology induction (Nastase and Strube, 2008), and the automatic creation of overview articles (Sauper and Barzilay, 2009). 3 Sentence Simplification Model Our model takes a single sentence as input and creates a version that is simpler to read. This may involve rendering syntactically comple</context>
</contexts>
<marker>Wang, Smith, Mitamura, 2007</marker>
<rawString>Wang, Mengqiu, Noah A. Smith, and Teruko Mitamura. 2007. What is the Jeopardy model? a quasisynchronous grammar for QA. In Proceedings of the EMNLP-CoNLL. Prague, Czech Republic, pages 22–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willian Massami Watanabe</author>
<author>Arnaldo Candido Junior</author>
</authors>
<title>Vinicius Rodriguez de Uz˜eda, Renata Pontin de Mattos Fortes, Thiago Alexandre Salgueiro Pardo, and Sandra Maria Alu´sio.</title>
<date>2009</date>
<booktitle>In Proceedings of the 27th ACM International Conference on Design of Communication.</booktitle>
<location>Bloomington, IN.</location>
<marker>Watanabe, Junior, 2009</marker>
<rawString>Watanabe, Willian Massami, Arnaldo Candido Junior, Vinicius Rodriguez de Uz˜eda, Renata Pontin de Mattos Fortes, Thiago Alexandre Salgueiro Pardo, and Sandra Maria Alu´sio. 2009. Facilita: reading assistance for low-literacy readers. In Proceedings of the 27th ACM International Conference on Design of Communication. Bloomington, IN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristian Woodsend</author>
<author>Yansong Feng</author>
<author>Mirella Lapata</author>
</authors>
<title>Title generation with quasisynchronous grammar.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics,</booktitle>
<pages>513--523</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="9685" citStr="Woodsend et al., 2010" startWordPosition="1471" endWordPosition="1474">roposed ILP formulation not only allows to efficiently search through the space of many QG rules but also to incorporate constraints relating to grammaticality and the task at hand without the added computational cost of integrating a language model. Furthermore, our learning framework is not limited to simplification and could be easily adapted to other rewriting tasks. Indeed, the QG formalism has been previously applied to parser adaptation and projection (Smith and Eisner, 2009), paraphrase identification (Das and Smith, 2009), question answering (Wang et al., 2007), and title generation (Woodsend et al., 2010). Finally, our work relates to a large body of recent literature on Wikipedia and its potential for a wide range of NLP tasks. Beyond text rewriting, examples include semantic relatedness (Ponzetto and Strube, 2007), information extraction (Wu and Weld, 2010), ontology induction (Nastase and Strube, 2008), and the automatic creation of overview articles (Sauper and Barzilay, 2009). 3 Sentence Simplification Model Our model takes a single sentence as input and creates a version that is simpler to read. This may involve rendering syntactically complex structures simpler (e.g., through sentence s</context>
</contexts>
<marker>Woodsend, Feng, Lapata, 2010</marker>
<rawString>Woodsend, Kristian, Yansong Feng, and Mirella Lapata. 2010. Title generation with quasisynchronous grammar. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Cambridge, MA, pages 513–523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Open information extraction using Wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics,</booktitle>
<pages>118--127</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="9944" citStr="Wu and Weld, 2010" startWordPosition="1511" endWordPosition="1514"> our learning framework is not limited to simplification and could be easily adapted to other rewriting tasks. Indeed, the QG formalism has been previously applied to parser adaptation and projection (Smith and Eisner, 2009), paraphrase identification (Das and Smith, 2009), question answering (Wang et al., 2007), and title generation (Woodsend et al., 2010). Finally, our work relates to a large body of recent literature on Wikipedia and its potential for a wide range of NLP tasks. Beyond text rewriting, examples include semantic relatedness (Ponzetto and Strube, 2007), information extraction (Wu and Weld, 2010), ontology induction (Nastase and Strube, 2008), and the automatic creation of overview articles (Sauper and Barzilay, 2009). 3 Sentence Simplification Model Our model takes a single sentence as input and creates a version that is simpler to read. This may involve rendering syntactically complex structures simpler (e.g., through sentence splitting), or substituting rare words with more common words or phrases (e.g., such that a second language learner may be familiar with), or deleting elements of the original text in order to produce a relatively simpler and shallower syntactic structure. In </context>
</contexts>
<marker>Wu, Weld, 2010</marker>
<rawString>Wu, Fei and Daniel S. Weld. 2010. Open information extraction using Wikipedia. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Uppsala, Sweden, pages 118–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntaxbased statistical translation model.</title>
<date>2001</date>
<booktitle>In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>523--530</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="7445" citStr="Yamada and Knight, 2001" startWordPosition="1119" endWordPosition="1122"> in a predefined dictionary (Devlin, 1999; Inui et al., 2003; Kaji et al., 2002). More recently, Yatskar et al. (2010) explore data-driven methods to learn lexical simplifications from Wikipedia revision histories. A key idea in their work is to utilize SimpleEW edits, while recognizing that these may serve other functions, such as vandalism removal or introduction of new content. Zhu et al. (2010) also use Wikipedia to learn a sentence simplification model which is able to perform four rewrite operations, namely substitution, reordering, splitting, and deletion. Inspired by syntax-based SMT (Yamada and Knight, 2001), their model consists of three components: a language model P(s) whose role is to guarantee that the simplification output is grammatical, a direct translation model P(s|c) capturing the probability that the target sentence s is a simpler version of the source c, and a decoder which searches for the simplification s which maximizes P(s)P(s|c). The translation model is the product of the aforementioned four rewrite operations whose probabilities are estimated from a parallel corpus of MainEW and SimpleEW sentences using an expectation maximization algorithm. Their decoder translates sentences </context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Yamada, Kenji and Kevin Knight. 2001. A syntaxbased statistical translation model. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics. Toulouse, France, pages 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elif Yamangil</author>
<author>Rani Nelken</author>
</authors>
<title>Mining Wikipedia revision histories for improving sentence compression.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT, Short Papers. Association for Computational Linguistics,</booktitle>
<pages>137--140</pages>
<location>Columbus, Ohio,</location>
<contexts>
<context position="5173" citStr="Yamangil and Nelken, 2008" startWordPosition="780" endWordPosition="783">t target tree licensed by the grammar subject to constraints such as sentence length and reading ease. Our model is conceptually simple and computationally efficient. Furthermore, it finds globally optimal simplifications without resorting to heuristics or approximations during the decoding process. Contrary to most previous approaches (see the discussion in Section 2) which rely heavily on hand-crafted rules, our model learns simplification rewrites automatically from examples of source-target sentences. Our work joins others in using Wikipedia to extract data appropriate for model training (Yamangil and Nelken, 2008; Yatskar et al., 2010; Zhu et al., 2010). Advantageously, the Simple English Wikipedia (henceforth SimpleEW) provides a large repository of simplified language; it uses fewer words and simpler grammar than the ordinary English Wikipedia (henceforth MainEW) and is aimed at non-native English speakers, children, translators, people with learning disabilities or low reading proficiency. We exploit Wikipedia and create a (parallel) simplification corpus in two ways: by aligning MainEW sentences to their SimpleEW counterparts, and by extracting training instances from SimpleEW revision histories, </context>
</contexts>
<marker>Yamangil, Nelken, 2008</marker>
<rawString>Yamangil, Elif and Rani Nelken. 2008. Mining Wikipedia revision histories for improving sentence compression. In Proceedings of ACL-08: HLT, Short Papers. Association for Computational Linguistics, Columbus, Ohio, pages 137– 140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Yatskar</author>
<author>Bo Pang</author>
<author>Cristian DanescuNiculescu-Mizil</author>
<author>Lillian Lee</author>
</authors>
<title>For the sake of simplicity: Unsupervised extraction of lexical simplifications from Wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of the Annual Meeting of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<pages>365--368</pages>
<contexts>
<context position="5195" citStr="Yatskar et al., 2010" startWordPosition="784" endWordPosition="787">he grammar subject to constraints such as sentence length and reading ease. Our model is conceptually simple and computationally efficient. Furthermore, it finds globally optimal simplifications without resorting to heuristics or approximations during the decoding process. Contrary to most previous approaches (see the discussion in Section 2) which rely heavily on hand-crafted rules, our model learns simplification rewrites automatically from examples of source-target sentences. Our work joins others in using Wikipedia to extract data appropriate for model training (Yamangil and Nelken, 2008; Yatskar et al., 2010; Zhu et al., 2010). Advantageously, the Simple English Wikipedia (henceforth SimpleEW) provides a large repository of simplified language; it uses fewer words and simpler grammar than the ordinary English Wikipedia (henceforth MainEW) and is aimed at non-native English speakers, children, translators, people with learning disabilities or low reading proficiency. We exploit Wikipedia and create a (parallel) simplification corpus in two ways: by aligning MainEW sentences to their SimpleEW counterparts, and by extracting training instances from SimpleEW revision histories, thus leveraging Wikipe</context>
<context position="6939" citStr="Yatskar et al. (2010)" startWordPosition="1042" endWordPosition="1045"> Sentence simplification has attracted a great deal of attention due to its potential impact on society. The literature is rife with attempts to simplify text using mostly hand-crafted syntactic rules aimed at splitting long and complicated sentences into several simpler ones (Carroll et al., 1999; Chandrasekar et al., 1996; Siddharthan, 2004; Vickrey and Koller, 2008). Other work focuses on lexical simplifications and substitutes difficult words by more common WordNet synonyms or paraphrases found in a predefined dictionary (Devlin, 1999; Inui et al., 2003; Kaji et al., 2002). More recently, Yatskar et al. (2010) explore data-driven methods to learn lexical simplifications from Wikipedia revision histories. A key idea in their work is to utilize SimpleEW edits, while recognizing that these may serve other functions, such as vandalism removal or introduction of new content. Zhu et al. (2010) also use Wikipedia to learn a sentence simplification model which is able to perform four rewrite operations, namely substitution, reordering, splitting, and deletion. Inspired by syntax-based SMT (Yamada and Knight, 2001), their model consists of three components: a language model P(s) whose role is to guarantee t</context>
<context position="8751" citStr="Yatskar et al. (2010)" startWordPosition="1321" endWordPosition="1324">e highest probability. 410 Our own work formulates sentence simplification in the framework of Quasi-synchronous grammar (QG, Smith and Eisner 2006). QG allows to describe non-isomorphic tree pairs (the grammar rules can comprise trees of arbitrary depth, and fragments can be mapped) and is thus suited to text-rewriting tasks which typically involve a number of local modifications to the input text. We use quasi-synchronous grammar to learn a wide range of rewrite operations capturing both lexical and structural simplifications naturally without any additional rule engineering. In contrast to Yatskar et al. (2010) and Zhu et al. (2010), simplification operations (e.g., substitution or splitting) are not modeled explicitly; instead, we leave it up to our grammar extraction algorithm to learn appropriate rules that reflect the training data. Compared to Zhu et al., our model is conceptually simpler and more general. The proposed ILP formulation not only allows to efficiently search through the space of many QG rules but also to incorporate constraints relating to grammaticality and the task at hand without the added computational cost of integrating a language model. Furthermore, our learning framework i</context>
</contexts>
<marker>Yatskar, Pang, DanescuNiculescu-Mizil, Lee, 2010</marker>
<rawString>Yatskar, Mark, Bo Pang, Cristian DanescuNiculescu-Mizil, and Lillian Lee. 2010. For the sake of simplicity: Unsupervised extraction of lexical simplifications from Wikipedia. In Proceedings of the Annual Meeting of the North American Chapter of the Association for Computational Linguistics. pages 365–368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Xiang Lan</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Application-driven statistical paraphrase generation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. Singapore,</booktitle>
<pages>834--842</pages>
<contexts>
<context position="3870" citStr="Zhao et al. 2009" startWordPosition="579" endWordPosition="582">nce splitting which usually produces longer rather than shorter output! Moreover, mod409 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 409–420, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics els developed for sentence compression have been mostly designed with one rewrite operation in mind, namely word deletion, and are thus unable to model consistent syntactic effects such as reordering, sentence splitting, changes in non-terminal categories, and lexical substitution (but see Cohn and Lapata 2008 and Zhao et al. 2009 for notable exceptions). In this paper we propose a sentence simplification model that is able to handle structural mismatches and complex rewriting operations. Our approach is based on quasi-synchronous grammar (QG, Smith and Eisner 2006), a formalism that is well suited for text rewriting. Rather than postulating a strictly synchronous structure over the source and target sentences, QG identifies a “sloppy” alignment of parse trees assuming that the target tree is in some way “inspired by” the source tree. Specifically, our model is formulated as an integer linear program and uses QG to cap</context>
</contexts>
<marker>Zhao, Lan, Liu, Li, 2009</marker>
<rawString>Zhao, Shiqi, Xiang Lan, Ting Liu, and Sheng Li. 2009. Application-driven statistical paraphrase generation. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP. Singapore, pages 834–842.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhemin Zhu</author>
<author>Delphine Bernhard</author>
<author>Iryna Gurevych</author>
</authors>
<title>A monolingual tree-based translation model for sentence simplification.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics.</booktitle>
<pages>1353--1361</pages>
<location>Beijing, China,</location>
<contexts>
<context position="5214" citStr="Zhu et al., 2010" startWordPosition="788" endWordPosition="791">constraints such as sentence length and reading ease. Our model is conceptually simple and computationally efficient. Furthermore, it finds globally optimal simplifications without resorting to heuristics or approximations during the decoding process. Contrary to most previous approaches (see the discussion in Section 2) which rely heavily on hand-crafted rules, our model learns simplification rewrites automatically from examples of source-target sentences. Our work joins others in using Wikipedia to extract data appropriate for model training (Yamangil and Nelken, 2008; Yatskar et al., 2010; Zhu et al., 2010). Advantageously, the Simple English Wikipedia (henceforth SimpleEW) provides a large repository of simplified language; it uses fewer words and simpler grammar than the ordinary English Wikipedia (henceforth MainEW) and is aimed at non-native English speakers, children, translators, people with learning disabilities or low reading proficiency. We exploit Wikipedia and create a (parallel) simplification corpus in two ways: by aligning MainEW sentences to their SimpleEW counterparts, and by extracting training instances from SimpleEW revision histories, thus leveraging Wikipedia’s collaborative</context>
<context position="7222" citStr="Zhu et al. (2010)" startWordPosition="1087" endWordPosition="1090">t al., 1999; Chandrasekar et al., 1996; Siddharthan, 2004; Vickrey and Koller, 2008). Other work focuses on lexical simplifications and substitutes difficult words by more common WordNet synonyms or paraphrases found in a predefined dictionary (Devlin, 1999; Inui et al., 2003; Kaji et al., 2002). More recently, Yatskar et al. (2010) explore data-driven methods to learn lexical simplifications from Wikipedia revision histories. A key idea in their work is to utilize SimpleEW edits, while recognizing that these may serve other functions, such as vandalism removal or introduction of new content. Zhu et al. (2010) also use Wikipedia to learn a sentence simplification model which is able to perform four rewrite operations, namely substitution, reordering, splitting, and deletion. Inspired by syntax-based SMT (Yamada and Knight, 2001), their model consists of three components: a language model P(s) whose role is to guarantee that the simplification output is grammatical, a direct translation model P(s|c) capturing the probability that the target sentence s is a simpler version of the source c, and a decoder which searches for the simplification s which maximizes P(s)P(s|c). The translation model is the p</context>
<context position="8773" citStr="Zhu et al. (2010)" startWordPosition="1326" endWordPosition="1329"> Our own work formulates sentence simplification in the framework of Quasi-synchronous grammar (QG, Smith and Eisner 2006). QG allows to describe non-isomorphic tree pairs (the grammar rules can comprise trees of arbitrary depth, and fragments can be mapped) and is thus suited to text-rewriting tasks which typically involve a number of local modifications to the input text. We use quasi-synchronous grammar to learn a wide range of rewrite operations capturing both lexical and structural simplifications naturally without any additional rule engineering. In contrast to Yatskar et al. (2010) and Zhu et al. (2010), simplification operations (e.g., substitution or splitting) are not modeled explicitly; instead, we leave it up to our grammar extraction algorithm to learn appropriate rules that reflect the training data. Compared to Zhu et al., our model is conceptually simpler and more general. The proposed ILP formulation not only allows to efficiently search through the space of many QG rules but also to incorporate constraints relating to grammaticality and the task at hand without the added computational cost of integrating a language model. Furthermore, our learning framework is not limited to simpl</context>
<context position="24156" citStr="Zhu et al. (2010)" startWordPosition="3906" endWordPosition="3909">es from S to ST (for example) rely on the application of syntactic simplification rules rules. Boxed subscripts show aligned nodes. of target words per sentence (wps) was set to 8, and syllables per word (spw) to 1.5. These two parameters were empirically tuned on the training set. To solve the ILP model we used the ZIB Optimization Suite software (Achterberg, 2007; Koch, 2004). The solution was converted into a sentence by removing nodes not chosen from the tree representation, then concatenating the remaining leaf nodes in order. Evaluation We evaluated our model on the same dataset used in Zhu et al. (2010), an aligned corpus of MainEW and SimpleEW sentences. The corpus contains 100/131 source/target sentences and was created automatically. Sentences from this corpus (and their revisions) were excluded from training. We evaluated two versions of our model, one with rewrite rules acquired from revision histories of simplified documents and another one with rules extracted from MainEW-SimpleEW aligned sentences. These models were compared against Zhu et al. (2010)6 who also learn simplification rules from Wikipedia, and a simple baseline that uses solely lexical simplifications7 provided by the Si</context>
<context position="31615" citStr="Zhu et al. (2010)" startWordPosition="5121" endWordPosition="5124">W; RevILP is significantly different from Zhu et al. and AlignILP. In sum, these results indicate that RevILP is the closest to SimpleEW and that the provenance of the QG rules has an impact on the model’s performance. Table 5 also shows BLEU and TERp scores with SimpleEW as the reference. These scores can be used to examine how close to the gold standard our models are. SpencerK has the highest BLEU and lowest TERp scores.12 This is expected as this baseline performs only a very limited type of rewriting, namely lexical substitution. AlignILP is most different from the reference, followed by Zhu et al. (2010) and RevILP. Taken together these results indicate 11All significance differences reported throughout this paper are with a level less than 0.01. 12The perfect BLEU score is one and the perfect TERp score is zero. Models Simplicity Grammaticality Meaning SimpleEW 3.74 4.89 4.41 SpencerK 1.41 4.87 4.84 Zhu et al 2.92 3.43 3.44 RevILP 3.64 4.55 4.19 AlignILP 2.69 4.03 3.98 Table 6: Average human ratings for gold standard SimpleEW sentences, a simple baseline (SpencerK) based on lexical substitution, Zhu et al.’s 2010 model, and two versions of our ILP model (RevILP and AlignILP). Zhu et al Align</context>
<context position="33209" citStr="Zhu et al. (2010)" startWordPosition="5383" endWordPosition="5386"> study. Table 6 reports the average ratings for Simplicity (is the target sentence simpler than the source?), Grammaticality (is the target sentence grammatical?), and Meaning (does the target preserve the meaning of the source?). With regard to simplicity, our participants perceive the gold standard (SimpleEW) to be the simplest, followed by RevILP, Zhu et al, and AlignILP. SpencerK is the least simple model and the most grammatical one as lexical substitutions do not change the structure of the sentence. Interestingly, RevILP and AlignILP are also rated highly with regard to grammaticality. Zhu et al. (2010) is the least grammatical model. Finally, RevILP preserves the meaning of the target as well as SimpleEW, whereas Zhu et al. yields the most distortions. Again SpencerK is rated highly amongst the other models as it is does not substantially simplify and thus change the meaning of the source. Table 7 reports on pairwise comparisons between all models and their statistical significance (again using a one-way ANOVA with post-hoc Tukey HSD tests). RevILP is not significantly different from SimpleEW on any dimension (Simplicity, Grammat417 Original story: There was once a sweet little maid who liv</context>
<context position="35708" citStr="Zhu et al. (2010)" startWordPosition="5811" endWordPosition="5814"> to preserving the meaning of the source. In sum, our results show that RevILP is the best performing model. It creates sentences that are simple, grammatical and adhere to the meaning of the source. The QG rules obtained from the revision histories produce better output compared to the aligned corpus. As revision histories are created by Wikipedia contributors, they tend to be a more accurate data source than aligned sentences which are obtained via an automatic and unavoidably noisy procedure. Our results also show that a more general model not restricted to specific rewrite operations like Zhu et al. (2010) obtains superior results and has better coverage. We also wanted to see whether a simplification model trained on Wikipedia could be applied to another domain. To this end, we used RevILP to simplify five children stories from the Gutenburg13 collection. The model simplified one sentence at a time and was ran with the Wikipedia settings without any modification. The mean FKGL on the simplified stories was 3.78. compared to 7.04 for the original ones. An example of our system’s output on Little Red Riding Hood is shown in Table 8. Possible extensions and improvements to the current model are m</context>
</contexts>
<marker>Zhu, Bernhard, Gurevych, 2010</marker>
<rawString>Zhu, Zhemin, Delphine Bernhard, and Iryna Gurevych. 2010. A monolingual tree-based translation model for sentence simplification. In Proceedings of the 23rd International Conference on Computational Linguistics. Beijing, China, pages 1353–1361.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>