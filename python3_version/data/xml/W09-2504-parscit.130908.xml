<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000049">
<title confidence="0.992273">
Augmenting WordNet-based Inference with Argument Mapping
</title>
<author confidence="0.992355">
Idan Szpektor
</author>
<affiliation confidence="0.868821666666667">
Department of Computer Science
Bar-Ilan University
Ramat Gan, Israel
</affiliation>
<email confidence="0.994008">
szpekti@cs.biu.ac.il
</email>
<author confidence="0.991262">
Ido Dagan
</author>
<affiliation confidence="0.868525666666667">
Department of Computer Science
Bar-Ilan University
Ramat Gan, Israel
</affiliation>
<email confidence="0.996488">
dagan@cs.biu.ac.il
</email>
<sectionHeader confidence="0.993853" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999790833333333">
WordNet is a useful resource for lexi-
cal inference in applications. Inference
over predicates, however, often requires
a change in argument positions, which
is not specified in WordNet. We pro-
pose a novel framework for augmenting
WordNet-based inferences over predicates
with corresponding argument mappings.
We further present a concrete implementa-
tion of this framework, which yields sub-
stantial improvement to WordNet-based
inference.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997115">
WordNet (Miller, 1995), a manually constructed
lexical database, is probably the mostly used re-
source for lexical inference in NLP tasks, such
as Question Answering (QA), Information Extrac-
tion (IE), Information Retrieval and Textual En-
tailment (RTE) (Moldovan and Mihalcea, 2000;
Pasca and Harabagiu, 2001; Bar-Haim et al., 2006;
Giampiccolo et al., 2007).
Inference using WordNet typically involves lex-
ical substitutions for words in text based on
WordNet relations, a process known as lexical
chains (Barzilay and Elhadad, 1997; Moldovan
and Novischi, 2002). For example, the an-
swer to “From which country was Louisiana ac-
quired?” can be inferred from “The United
States bought up Louisiana from France” using the
chains ‘France ⇒ European country ⇒ country’
and ‘buy up ⇒ buy ⇒ acquire’.
When performing inference between predicates
there is an additional complexity on top of lex-
ical substitution: the syntactic relationship be-
tween the predicate and its arguments may change
as well. For example, ‘X buy Y for Z ⇒
X pay Z for Y ’.
Currently, argument mappings are not specified
for WordNet’s relations. Therefore, correct Word-
Net inference chains over predicates can be per-
formed only for substitution relations (mainly syn-
onyms and hypernyms, e.g. ‘buy ⇒ acquire’), for
which argument positions do not change. Other
relation types that may be used for inference can-
not be utilized when the predicate arguments need
to be traced as well. Examples include the Word-
Net ‘entailment’ relation (e.g. ‘buy ⇒ pay’) and
relations between morphologically derived words
(e.g. ‘acquire ⇔ acquisition’).
Our goal is to obtain argument mappings for
WordNet relations that are often used for infer-
ence. In this paper we address several prominent
WordNet relations, including verb-noun deriva-
tions and the verb-verb ’entailment’ and ’cause’
relations, referred henceforth as inferential rela-
tions. Under the Textual Entailment paradigm,
all these relations can be viewed as express-
ing entailment. Accordingly, we propose a
novel framework, called Argument-mapped Word-
Net (AmWN), that represents argument map-
pings for inferential relations as entailment rules.
These rules are augmented with subcategorization
frames and functional roles, which are proposed
as a generally-needed extension for predicative en-
tailment rules.
Following our new representation scheme, we
present a concrete implementation of AmWN for
a large number of WordNet’s relations. The map-
pings for these relations are populated by com-
bining information from manual and corpus-based
resources, which provides broader coverage com-
pared to prior work and more accurate mappings.
Table 1 shows typical inference chains obtained
</bodyText>
<page confidence="0.984011">
27
</page>
<note confidence="0.901418333333333">
Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 27–35,
Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP
Rule Chains
</note>
<table confidence="0.60941125">
shopping:n of Xobj ⇒ buying:n of Xobj ⇒ buy:v Xobj ⇒ pay:v for Xmod
vote:v on Xmod ⇒ decide:v on Xmod ⇒ debate:v Xobj
Xobj’s sentence:n ⇒ condemn:v Xobj ⇒ convict:v Xobj ⇒ Xobj’s conviction:n
Xind−obj’s teacher:n ⇒ teach:v to Xind−obj ⇒ Xsubj learn:v
</table>
<tableCaption confidence="0.884992">
Table 1: Examples for inference chains obtained using AmWN. Arguments are subscripted with func-
tional roles, e.g. subject (subj) and indirect-object (ind-obj). For brevity, predicate frames are omitted.
</tableCaption>
<bodyText confidence="0.984228222222222">
using our implementation.
To further improve WordNet-based inference
for NLP applications, we address the phenom-
ena of rare WordNet senses. Rules generated for
such senses might hurt inference accuracy since
they are often applied incorrectly to texts when
matched against inappropriate, but more frequent
senses of the rule words. Since word sense disam-
biguation (WSD) solutions are typically not suf-
ficiently robust yet, most applications do not cur-
rently apply WSD methods. Hence, we propose
to optionally filter out such rules using a novel
corpus-based validation algorithm.
We tested both WordNet and AmWN on a test
set derived from a standard IE benchmark. The
results show that AmWN substantially improves
WordNet-based inference in terms of both recall
and precision1.
</bodyText>
<sectionHeader confidence="0.726809" genericHeader="method">
2 Argument-Mapping Entailment Rules
</sectionHeader>
<bodyText confidence="0.999849888888889">
In our framework we represent argument map-
pings for inferential relations between predicates
through an extension of entailment rules over syn-
tactic representations. As defined in earlier works,
an entailment rule specifies an inference rela-
tion between an entailing template and an en-
tailed template, where templates are parse sub-
trees with argument variables (Szpektor and Da-
gan, 2008). For example, ‘X subj
</bodyText>
<equation confidence="0.9658415">
←−− buy obj
−−→ Y
⇒ ‘X subj ←−−pay prep−for
−−−−−−→ Y ”.
</equation>
<bodyText confidence="0.978722928571429">
When a rule is applied to a text, a new conse-
quent is inferred by instantiating the entailed tem-
plate variables with the argument instantiations of
the entailing template in the text. In our example,
“IBM paid for Cognos” can be inferred from “IBM
bought Cognos”. This way, the syntactic structure
of the rule templates specifies the required argu-
ment positions for correct argument mapping.
However, representing entailment rule structure
only by syntactic argument positions is insufficient
for predicative rules. Correct argument mapping
1We plan to make our AmWN publicly available.
depends also on the specific syntactic functional
roles of the arguments (subject, object etc.) and on
the suitable subcategorization frame (frame) for
the predicate mention - a set of functional roles
that a predicate may occur with. For example,
‘X’s buyout ⇒ buy X’ is incorrectly applied to
“IBM’s buyout of Cognos” if roles are ignored,
since ‘IBM’ plays the subject role while X needs
to be an object.
Seeking to address this issue, we were inspired
by the Nomlex database (Macleod et al., 1998)
(see Section 3.2.1) and explicitly specify argu-
ment mapping for each frame and functional role.
As in Nomlex, we avoid the use of semantic
roles and stick to the syntactic level, augment-
ing the representation of templates with: (a) a
syntactic functional role for each argument; (b)
the valid predicate frame for this template men-
tions. We note that such functional roles typically
coincide with dependency relations of the verbal
form. A rule example is ‘Xsubj break{intrans} ⇒
damage{trans} Xobj’2. More examples are shown
in Table 1.
Unlike Nomlex records, our templates can be
partial: they may contain only some of the possi-
ble predicate arguments, e.g. ‘buy{trans} Xobj’,
where the subject, included in the frame, is omit-
ted. Partial templates are necessary for matching
predicate occurrences that include only some of
the possible arguments, as in “Cognos was bought
yesterday”. Additionally, some resources, such as
automatic rule learning methods (Lin and Pantel,
2001; Sekine, 2005), can provide only partial ar-
gument information, and we would want to repre-
sent such knowledge as well.
In our framework we follow (Szpektor and Da-
gan, 2008) and use only rules between unary tem-
plates, containing a single argument. Such tem-
plates can describe any argument mapping by de-
2Functional roles are denoted by subscripts of the argu-
ments and frames by subscripts of the predicate. We short-
hand trans for transitive frame {subject, object} and intrans
for intransitive {subject}. For brevity, we will not show all
template information when examples are self explanatory.
</bodyText>
<page confidence="0.997787">
28
</page>
<bodyText confidence="0.997858615384615">
composing templates with several arguments into
unary ones, while preserving the specification of
the subcategorization frame.
To apply a rule, the entailing template must be
first matched in the text, which includes match-
ing the template’s syntactic dependency structure,
functional roles, and frame. Such procedure re-
quires texts to be annotated with these types of in-
formation. This can be reasonably performed with
existing tools and resources, as described for our
own text processing in Section 4.
Explicitly matching frames and functional roles
in rules avoids incorrect rule applications. For ex-
ample, ‘Xobj’s buyout ⇒ buy Xobj’ would be ap-
plied only to “Cognos’s buyout by IBM” follow-
ing proper role annotation of the text, but not to
“IBM’s buyout of Cognos”. As another example,
‘Xsubj break{intrans} ⇒ damage{trans} Xobj’
would be applied only to the intransitive occur-
rence of ‘break’, e.g. “The vase broke”, but not
to “John broke the vase”.
Ambiguous cases may occur during annotation.
For example, the role of ‘John’ in “John’s invita-
tion was well intended” could be either subject or
object. Such recognized ambiguities should be left
unannotated, blocking incorrect rule application.
</bodyText>
<sectionHeader confidence="0.971462" genericHeader="method">
3 Argument Mapping for WordNet
</sectionHeader>
<bodyText confidence="0.9999072">
Following our extension of entailment rules, we
present Argument-mapped WordNet (AmWN), a
framework for extending WordNet’s inferential re-
lations with argument mapping at the syntactic
representation level.
</bodyText>
<subsectionHeader confidence="0.999357">
3.1 Argument Mapping Representation
</subsectionHeader>
<bodyText confidence="0.999941333333333">
The AmWN structure follows that of WordNet: a
directed graph whose nodes are WordNet synsets
and edges are relations between synsets. Since
we focus on entailment between predicates, we
include only predicative synsets: all verb synsets
and noun synsets identified as predicates (see Sec-
tion 3.2). In addition, only WordNet relations that
correspond to some type of entailment are consid-
ered, as detailed in Section 3.2.
In our framework, different subcategorization
frames are treated as having different “meanings”,
since different frames may correspond to differ-
ent entailment rules. Each WordNet synset is split
into several nodes, one for each of its frames. We
take frame descriptions for verbs from WordNet3.
</bodyText>
<footnote confidence="0.986066">
3We also tried using VerbNet (Kipper et al., 2000), with-
</footnote>
<figureCaption confidence="0.996306">
Figure 1: A description of ‘buy/purchase X ⇒
</figureCaption>
<bodyText confidence="0.986700333333333">
pay for X’ as a mapping edge in AmWN.
Since WordNet does not provide frames for noun
predicates, these are taken from Nomlex-plus (see
Section 3.2).
There are two types of graph edges that rep-
resent entailment rules between nodes: mapping
edges and substitution edges. Mapping edges
specify entailment rules that require argument
mapping, where the entailing and entailed tem-
plate predicates are replaced by synsets. Thus, an
edge represents all rules between entailing and en-
tailed synset members, as in Figure 1.
Substitution edges connect pairs of predicates,
of the same part-of-speech, which preserve argu-
ment positions in inference. This is analogous to
how WordNet may be currently used for inference
via the synonym and hypernym relations. Unlike
WordNet, substitution edges in AmWN may con-
nect only nodes that have the same subcategoriza-
tion frame.
AmWN is utilized by generating rule chains for
a given input unary template. First, starting nodes
that match the input predicate are selected. Then,
rules are generated by traversing either incoming
or outgoing graph edges transitively, depending
on the entailment direction requested. Specific
synset-ids, if known, may also be added to the in-
put to constrain the relevant starting nodes for the
input predicate. Table 1 shows examples of rule
chains from AmWN.
</bodyText>
<subsectionHeader confidence="0.999846">
3.2 Argument Mapping Population
</subsectionHeader>
<bodyText confidence="0.99996625">
After defining the AmWN representation, we next
describe our implementation of AmWN. We first
populate the AmWN graph with substitution edges
for WordNet’s hypernyms and synonyms (as self
edges), e.g. ‘buy ⇔ purchase’ and ‘buy ⇒ ac-
quire’. The following subsections describe how
mapping edges are created based on various man-
ual and corpus-based information resources.
</bodyText>
<subsectionHeader confidence="0.706813">
3.2.1 Nominalization Relations
</subsectionHeader>
<bodyText confidence="0.949702">
The relation between a verb and its nominaliza-
tions, e.g. between ‘employ’ and ‘employment’,
out any current performance improvement.
</bodyText>
<page confidence="0.98876">
29
</page>
<figure confidence="0.985281">
:ORTH &amp;quot;employment&amp;quot;
:VERB &amp;quot;employ&amp;quot;
:VERB-SUBC ((NOM-NP
:SUBJECT ((DET-POSS)
(N-N-MOD)
(PP :PVAL (&amp;quot;by&amp;quot;)))
:OBJECT ((DET-POSS)
(PP :PVAL (&amp;quot;of&amp;quot;)))
</figure>
<figureCaption confidence="0.996508">
Figure 2: Part of the employment Nomlex entry,
</figureCaption>
<bodyText confidence="0.993488071428572">
describing the possible syntactic dependency posi-
tions for each role of the transitive frame. It states,
for example, that the verbal ‘object’ role can be
mapped to employment either as a possessive or as
the complement of the preposition ‘of’.
is described in WordNet by the derivationally re-
lated relation. To add argument mappings for
these relations we utilize Nomlex-plus (Meyers
et al., 2004), a database of around 5000 English
nominalizations. Nomlex specifies for each ver-
bal subcategorization frame of each nominaliza-
tion how its argument positions are mapped to
functional roles of related verbs.
For each Nomlex entry, we extract all possible
argument mappings between the verbal and nom-
inal forms, as well as between different argument
realizations of the noun. For example, the map-
pings ‘Xobj’s employment ⇔ employ Xobj’ and
‘Xobj’s employment ⇔ employment of Xobj’ are
derived from the entry in Figure 2.
The major challenge in integrating Nomlex and
WordNet is to identify for each Nomlex noun
which WordNet synsets describe its predicative
meanings. For example, one synset of ‘acquisi-
tion’ that is derivationally related to ‘acquire’ is
not predicative: “an ability that has been acquired
by training”. We mark noun synsets as predicative
if they are (transitive) hyponyms of the act high-
level synset.
Once predicative synsets are identified, we cre-
ate, for each synset, a node for each subcate-
gorization frame of its noun members, as found
in Nomlex-plus. In some nodes not all original
synset members are retained, since not all mem-
bers share all their frames. Mapping edges are
then added between nodes that have the same
frame. We add both noun-verb edges and noun
self-edges that map different realizations of the
same functional role (e.g. ‘Xobj’s employment ⇔
employment of Xobj’).
As rich as Nomlex-plus is, it still does not in-
clude all nominalizations. For example, the nouns
</bodyText>
<table confidence="0.999794333333333">
Lexical Relation Extracted Mappings
buy ⇒ pay buy for X ⇒ pay X
X buy ⇒ X pay
divorce ⇒ marry divorce from X ⇒ marry X
divorce from X ⇒ X marry
kill ⇒ die kill X ⇒ X die
kill among X ⇒ X die
breathe ⇒ inhale breathe X ⇒ inhale X
breathe in X ⇒ inhale X
remind ⇒ remember remind X ⇒ X remember
remind of X ⇒ remember X
teach ⇒ learn teach X ⇒ learn X
teach to X ⇒ X learn
give ⇒ have give X ⇒ have X
give to X ⇒ X have
</table>
<tableCaption confidence="0.9685025">
Table 2: Some argument mappings for WordNet
verb-verb relations discovered by unary-DIRT.
</tableCaption>
<bodyText confidence="0.999718636363636">
‘divorce’ (related to the verb ‘divorce’) and ‘strik-
ing’ are missing. WordNet has a much richer set
of nominalizations that we would like to use. To
do so, we inherit associated frames and argument
realizations for each nominalization synset from
its closest hypernym that does appear in Nomlex.
Thus, ‘divorce’ inherits its information from ‘sep-
aration’ and ‘striking’ inherits from ‘hit’. A by-
product of this process is the automatic extension
of Nomlex-plus with 5100 new nominalization en-
tries, based on the inherited information4.
</bodyText>
<subsectionHeader confidence="0.544775">
3.2.2 Verb-Verb Relations
</subsectionHeader>
<bodyText confidence="0.999897761904762">
There are two inferential relations between verbs
in WordNet that do not preserve argument posi-
tions: cause and entailment. Unlike for nomi-
nalizations, there is no broad-coverage manual re-
source of argument mapping for these relations.
Hence, we turn to unsupervised approaches that
learn entailment rules from corpus statistics.
Many algorithms were proposed for learning
entailment rules between templates from corpora
(Lin and Pantel, 2001; Szpektor et al., 2004;
Sekine, 2005), but typically with mediocre accu-
racy. However, we only search for rules between
verbs for which WordNet already indicates the ex-
istence of an entailment relation and are thus not
affected by rules that wrongly relate non-entailing
verbs. We acquired a rule-set containing the top
300 rules for every unary template in the Reuters
RCV1 corpus5 by implementing the unary-DIRT
algorithm (Szpektor and Dagan, 2008), which was
shown to have relatively high recall compared to
other algorithms.
</bodyText>
<footnote confidence="0.999919">
4We plan making this extension publicly available as well.
5http://about.reuters.com/researchandstandards/corpus/
</footnote>
<page confidence="0.996999">
30
</page>
<bodyText confidence="0.999986789473684">
To extract argument mappings, we identify all
AmWN node pairs whose synsets are related in
WordNet by a cause or an entailment relation.
For each pair, we look for unary-DIRT rules be-
tween any pair of members in the entailing and
entailed synsets. For example, the synset {buy,
purchase} entails {pay}, so we look for rules map-
ping either ‘buy ⇒ pay’ or ‘purchase ⇒ pay’. Ta-
ble 2 presents examples for discovered mappings.
While unary-DIRT rules are not annotated with
functional roles, they can be derived straightfor-
wardly from the verbal dependency relations avail-
able in the rule’s templates. The obtained rules are
then added to AmWN as mapping edges.
We only search for rules that map a functional
role in the frame of one verb to any role for the
other verb. Focusing on frame elements avoids ex-
tracting mapping rules learned for adjuncts, which
tend to be of low precision.
</bodyText>
<subsectionHeader confidence="0.998419">
3.3 Rule Filtering
</subsectionHeader>
<bodyText confidence="0.99951844">
In preliminary analysis we found two phenomena,
sense drifting and rare senses, which may reduce
the effectiveness of AmWN-based inference even
if each graph edge by itself, taken out of context, is
correct. To address these phenomena within prac-
tical inference we propose the following optional
methods for rule filtering.
Sense Drifting WordNet verbs typically have
a more fine-grained set of synsets than their re-
lated nominalizations. There are cases where sev-
eral verb synsets are related to the same nomi-
nal synset. Since entailment between a verb and
its nominalization is bidirectional, all such verb
synsets would end up entailing each other via the
nominal node.
Alas, some of these connected verb synsets rep-
resent quite different meanings, which results in
incorrect inferences. This problem, which we call
sense drifting, is demonstrated in Figure 3. To ad-
dress it, we constrain each rule generation chain
to include at most one verb-noun edge, which still
connects the noun and verb hierarchies.
Rare Senses Some word senses in WordNet are
rare. Thus, applying rules that correspond to such
senses yields many incorrect inferences, since
they are typically matched against other frequent
senses of the word. Such a rule is ‘have X ⇒ X
is born’, corresponding to a rare sense of ‘have’.
WSD is a possible solution for this problem. How-
ever, most state-of-the-art IE, QA and RTE sys-
tems do not rely on WSD methods, which are cur-
rently not sufficiently robust.
To circumvent the rare sense problem, we in-
stead filter out such rules. Each AmWN rule is
validated against our unary-DIRT rule-set, which,
being corpus-based, contains mostly rules for fre-
quent senses. A rule is directly-validated if it is
in the corpus-based rule-set, or if it is a nominal-
verb rule which describes a reliable morpholog-
ical change for a predicate. The AmWN graph-
path that generated each rule is automatically ex-
amined. A rule is considered valid if there is a
sequence of directly-validated intermediate rules
along the path whose transitive chaining generates
the rule. Invalid rules are filtered out.
To illustrate, suppose the rule ‘a ⇒ d’ was gen-
erated by the chain ‘a ⇒ b ⇒ c ⇒ d’. It is valid
if there is a rule chain along the path that yields ‘a
⇒ d’, e.g. {‘a ⇒ b’,‘b ⇒ c’,‘c ⇒ d’} or {‘a ⇒ b’,
‘b ⇒ d’}, whose rules are all directly-validated.
</bodyText>
<sectionHeader confidence="0.998817" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999973346153846">
We follow here the experimental setup presented
in (Szpektor and Dagan, 2008), testing the gener-
ated rules on the ACE 2005 event dataset6. This
standard IE benchmark includes 33 types of event
predicates such as Injure, Sue and Divorce7. The
ACE guidelines specify for each event its possi-
ble arguments. For example, some of the Injure
event arguments are Agent and Victim. All event
mentions, including their instantiated arguments,
are annotated in a corpus collected from various
sources (newswire articles, blogs, etc.).
To utilize the ACE dataset for evaluating rule
applications, each ACE event predicate was rep-
resented by a set of unary seed templates, one for
each event argument. Example seed templates for
Injure are ‘A injure’ and ‘injure V ’. Each event ar-
gument is mapped to the corresponding seed tem-
plate variable, e.g. ‘Agent’ to A and ‘Victim’ to V
in the above example.
We manually annotated each seed template with
a subcategorization frame and an argument func-
tional role, e.g. ‘injure{trans} Vobj’. We also in-
cluded relevant WordNet synset-ids, so only rules
fitting the target meaning of the event will be ex-
tracted. In this experiment, we focused only on
the core semantic arguments. Adjuncts (time and
</bodyText>
<footnote confidence="0.998235333333333">
6http://projects.ldc.upenn.edu/ace/
7Only 26 frequent event types that correspond to a unique
predicate were tested, following (Szpektor and Dagan, 2008).
</footnote>
<page confidence="0.999793">
31
</page>
<figure confidence="0.253584428571429">
Synset Members WordNet Gloss
(verb) collar, nail, apprehend, arrest, pick up, nab, cop take into custody
�
(noun) apprehension, arrest, catch, collar, pinch, the act of apprehending (especially apprehending
taking into custody a criminal)
�
(verb) get, catch, capture succeed in catching or seizing, especially after a chase
�
(noun) capture, seizure the act of taking of a person by force
�
(verb) seize take or capture by force
⇑ (hypernym)
(verb) kidnap, nobble, abduct, snatch take away to an undisclosed location against their will
and usually in order to extract a ransom
</figure>
<figureCaption confidence="0.999709">
Figure 3: A WordNet sense-drifting traversal, generating the incorrect inference ‘kidnap ⇒ arrest’.
</figureCaption>
<bodyText confidence="0.996769761904762">
place) were ignored since they typically don’t re-
quire argument mapping, the main target for our
assessment.
The ACE corpus was dependency-parsed with
Minipar (Lin, 1998) and annotated with functional
roles and frames for each predicate mention. The
functional roles for a verb mention were taken di-
rectly from the corresponding dependency tree re-
lations. Its frame was chosen to be the largest
WordNet frame of that verb that matched the men-
tion’s roles.
Nominalization frames and functional roles
in the text were annotated using our extended
Nomlex-plus database. For each nominal mention,
we found the largest Nomlex frame whose syntac-
tic argument positions matched those of the men-
tion’s arguments. The arguments were then anno-
tated with the specified roles of the chosen frame.
Ambiguous cases, where the same argument posi-
tion could match multiple roles, were left unanno-
tated, as discussed in Section 2.
Argument mentions for events were found in
the annotated corpus by matching either the seed
templates or the templates entailing them in some
rules. The matching procedure follows the one de-
scribed in Section 2. Templates are matched us-
ing a syntactic matcher that handles simple syn-
tactic variations such as passive-form and con-
junctions. For example, ‘wound{trans} Vobj
⇒ injure{trans} Vobj’ was matched in the text
“Hagelobj was woundedtrans in Vietnam”. A rule
application is considered correct if the matched ar-
gument is annotated in the corpus with the corre-
sponding ACE role.
We note that our system performance on the
ACE task as such is limited. First, WordNet does
not provide all types of needed rules. Second, the
system of our experimental setting is rather basic,
with limited matching capabilities and without a
WSD module. However, this test-set is still very
useful for relative comparison of WordNet and our
proposed AmWN.
</bodyText>
<sectionHeader confidence="0.999306" genericHeader="evaluation">
5 Results and Analysis
</sectionHeader>
<bodyText confidence="0.999076818181818">
We tested four different rule-set configurations:
a) only the seed templates, without any rules; b)
rules generated based on WordNet 3.0 without ar-
gument mapping, using only synonym and hyper-
nym relations; c) WordNet rules from (b), filtered
using our corpus-based validation method for rare
senses; d) rules generated from our AmWN.
Out of the 8953 non-substitutable inferential re-
lations that we identified in WordNet, our AmWN
implementation created mapping edges for 75% of
8325 Noun-Verb relations and 70% of 628 Verb-
Verb relations. Altogether 41549 mapping edges
between synset nodes were added. A manual er-
ror analysis of these mappings is provided in Sec-
tion 5.2.
Each configuration was evaluated for each ACE
event. We measured the percentage of correct ar-
gument mentions extracted out of all correct argu-
ment mentions annotated for the event (recall) and
out of all argument mentions extracted (precision),
and F1, their harmonic average. We report macro
averages over the 26 event types.
</bodyText>
<subsectionHeader confidence="0.675443">
5.1 Results
</subsectionHeader>
<bodyText confidence="0.999953428571429">
Table 3 summarizes the results for the different
configurations. As expected, matching only the
seed templates yields the highest precision but
lowest recall. Using the standard WordNet config-
uration actually decreases overall F1 performance.
Though recall increases relatively by 30%, thanks
to WordNet expansions, F1 is penalized by a sharp
</bodyText>
<page confidence="0.997677">
32
</page>
<table confidence="0.9997726">
Configuration R (%) P (%) F1
No Rules 13.5 63.0 20.7
WordNet 17.5 35.3 18.5
WordNet with rule validation 16.5 46.9 20.4
AmWN 20.8 43.9 24.2
</table>
<tableCaption confidence="0.995752">
Table 3: Recall (R), Precision (P) and F1 results
</tableCaption>
<bodyText confidence="0.983644703703703">
for the different tested configurations.
relative drop in precision (by 56%). The main rea-
son for this decline is the application of rules in-
volving infrequent word senses, as elaborated in
Section 3.3.
When our rule validation approach is applied
to standard WordNet expansions, a much higher
precision is achieved with only a small decline in
recall. This shows that our corpus-based filtering
method manages to avoid many of the noisy rules
for rare senses, while maintaining those that are
frequently involved in inference.
Finally, our main result shows that adding ar-
gument mapping improves performance substan-
tially. AmWN achieves a much higher recall
than WordNet. Recall increases relatively by 26%
over validated WordNet, and by 54% over the
no-rules baseline. Furthermore, precision drops
only slightly, by 6%, compared to validated Word-
Net. This shows that argument mapping increases
WordNet’s graph connectivity, while our rule-
validation method maintains almost the same pre-
cision for many more generated rules. The im-
provement in overall F1 performance is statisti-
cally significant compared to all other configura-
tions, according to the two-sided Wilcoxon signed
rank test at the level of 0.01 (Wilcoxon, 1945).
</bodyText>
<subsectionHeader confidence="0.994614">
5.2 Error Analysis
</subsectionHeader>
<bodyText confidence="0.9990632">
We manually analyzed the reasons for false pos-
itives (incorrect extractions) and false negatives
(missed extractions) of AmWN by sampling 300
extractions of each type.
From the false positives analysis (Table 4) we
see that practically all generated rules are correct
(99.4%), that is, they would be valid in some con-
texts. Almost all errors come from matching errors
(including parse errors) and context mismatches,
due to our limited IE implementation. The only
two incorrect rules sampled were due to an in-
correct Nomlex entry and a WordNet synset that
should have been split into two separate senses.
Considering that correct extractions resulted, per
our analysis, from correct rules, the analysis of this
</bodyText>
<table confidence="0.998859">
Reason % mentions
Context mismatch 57.2
Match error 33.6
Errors in gold-standard annotation 8.6
Incorrect Rule learned 0.6
</table>
<tableCaption confidence="0.706379">
Table 4: Distribution of reasons for false positives
(incorrect argument extractions).
</tableCaption>
<table confidence="0.9998905">
Reason % mentions
Rule not learned 67.7
Match error 18.0
Discourse analysis needed 12.0
Argument is predicative 1.3
Errors in gold-standard annotation 1.0
</table>
<tableCaption confidence="0.90913125">
Table 5: Distribution of reasons for false negatives
(missed argument mentions).
sample indicates that virtually all AmWN edges
that get utilized in practice are correct.
</tableCaption>
<bodyText confidence="0.99966128125">
Context mismatches, which constitute the ma-
jority of errors (57.2%), occur when the entail-
ing template of a rule is matched in inappropriate
contexts. This occurs typically when the match is
against another sense of the predicate, or when an
argument is not of the requested type (e.g. “The
Enron sentence” vs. “A one month sentence”). In
future work, we plan to address this problem by
utilizing context-sensitive application of rules in
the spirit of (Szpektor et al., 2008).
Table 5 presents the false negatives analysis.
Most missed extractions are due to rules that were
not learned (67.7%). These mainly involve com-
plex templates (‘file a lawsuit ⇔ sue’) and infer-
ence rules that are not synonyms/hypernyms (‘ex-
ecute ⇒ sentence’), which are not widely anno-
tated in WordNet. From further analysis, we found
that 10% of these misses are due to rules that are
generated from AmWN but filtered out by one of
our filtering methods (Section 3.3).
12% of the arguments cannot be extracted by
rules alone, due to required discourse analysis,
while 18% of the mentions were missed due to in-
correct syntactic matching. By assuming correct
matches in these cases and avoiding rule filtering,
we can estimate the upper bound recall of the rule-
set for the ACE dataset to be 40%.
In conclusion, for better performance the sys-
tem should be augmented with context modeling
and better template matching. Additionally, other
rule-bases, e.g. DIRT (Lin and Pantel, 2001),
should be added to increase rule coverage.
</bodyText>
<page confidence="0.997522">
33
</page>
<table confidence="0.9997415">
Configuration R (%) P (%) F1
AmWN 20.8 43.9 24.2
No nominalization mappings 18.1 45.5 21.8
No verb-verb mappings 19.3 43.8 22.8
No rule validation 22.0 30.4 20.9
No sense drift blocking 22.5 37.4 21.7
</table>
<tableCaption confidence="0.9993085">
Table 6: The Recall (R), Precision (P) and F1 re-
sults for ablation tests.
</tableCaption>
<subsectionHeader confidence="0.997874">
5.3 Component Analysis
</subsectionHeader>
<bodyText confidence="0.999981">
Table 6 presents ablations tests that assess the
marginal contribution of each AmWN component.
Nominal-verb and verb-verb mappings contribute
to the graph connectivity, hence the recall reduc-
tion when they are removed.
Complementary to recall components, rule fil-
tering improves precision. When removing the
corpus-based rule-validation, recall increases rel-
atively by 6% but precision drops relatively by
30%, showing the benefit of noisy-rule filtering.
Allowing sense drifting hurts precision, a rela-
tive drop of 22%. Yet, recall increases relatively
by 8%, indicating that some verb synsets, con-
nected via a shared nominal, entail each other even
though they are not connected directly. For exam-
ple, ‘found X ⇔ create X’ was generated only via
the shared nominal ‘founding’. In future work, we
plan to apply AmWN to a coarse-grained set of
WordNet synsets (Palmer et al., 2007) as a possi-
ble solution to sense drifting.
</bodyText>
<sectionHeader confidence="0.999976" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999970393939394">
Several works attempt to extend WordNet with ad-
ditional lexical semantic information (Moldovan
and Rus, 2001; Snow et al., 2006; Suchanek et al.,
2007; Clark et al., 2008). However, the only pre-
vious work we are aware of that enriches Word-
Net with argument mappings is (Novischi and
Moldovan, 2006). This work utilizes VerbNet’s
subcategorization frames to identify possible verb
arguments. Argument mapping is provided only
between verbs, ignoring relations between verbs
and nouns. Arguments are mapped based on the-
matic role names shared between frames of dif-
ferent verbs. However, the semantic interpretation
of thematic roles is generally inconsistent across
verbs (Lowe et al., 1997; Kaisser and Webber,
2007). Instead, we discover these mappings from
corpus statistics, offering an accurate approach (as
analyzed in Section 5.2).
A frame semantics approach for argument
mapping between predicates is proposed by the
FrameNet project (Baker et al., 1998). Currently,
FrameNet is the only resource for frame-semantic
argument mappings. However, it is manually con-
structed and currently covers much less predi-
cates and relations than WordNet. Furthermore,
frame-semantic parsers are less robust than syntac-
tic parsers, presently hindering the utilization of
this approach in applications (Burchardt and Pen-
nacchiotti, 2008).
Nomlex argument mapping patterns similar to
ours were derived for IE in (Meyers et al., 1998),
but they were not integrated with any additional
information, such as WordNet.
</bodyText>
<sectionHeader confidence="0.999573" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999923777777778">
We presented Argument-mapped WordNet
(AmWN), a novel framework for augment-
ing WordNet with argument mappings at the
syntactic representation level. With AmWN,
non-substitutable WordNet relations can also
be utilized correctly, increasing the coverage of
WordNet-based inference. The standard entail-
ment rule representation is augmented in our
work with functional roles and subcategorization
frames, shown to be a feasible extension needed
for correct rule application in general.
Our implementation of AmWN populates
WordNet with mappings based on combining
manual and corpus-based resources. It covers a
broader range of relations compared to prior work
and yields more accurate mappings. We also in-
troduced a novel corpus-based validation mecha-
nism, avoiding rules for infrequent senses. Our
experiments show that AmWN substantially im-
proves standard WordNet-based inference.
In future work we plan to add mappings be-
tween verbs and adjectives and between different
frames of a verb. We also want to incorporate
resources for additional subcategorization frames,
such as VerbNet. Finally, we plan to enhance our
text annotation based on noun-compound disam-
biguation (Lapata and Lascarides, 2003).
</bodyText>
<sectionHeader confidence="0.996511" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.994158833333333">
This work was partially supported by the NEGEV
project (www.negev-initiative.org), the PASCAL-
2 Network of Excellence of the European Commu-
nity FP7-ICT-2007-1-216886, the FBK-irst/Bar-
Ilan University collaboration and the Israel Sci-
ence Foundation grant 1112/08.
</bodyText>
<page confidence="0.998576">
34
</page>
<sectionHeader confidence="0.99589" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999922495145631">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The berkeley framenet project. In Proceed-
ings of ACL.
Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro,
Danilo Giampiccolo, Bernardo Magnini, and Idan
Szpektor. 2006. The second pascal recognising tex-
tual entailment challenge. In Second PASCAL Chal-
lenge Workshop for Recognizing Textual Entailment.
Regina Barzilay and Michael Elhadad. 1997. Using
lexical chains for text summarization. In Proceed-
ings of ACL.
Aljoscha Burchardt and Marco Pennacchiotti. 2008.
Fate: a framenet-annotated corpus for textual entail-
ment. In Proceedings of LREC.
Peter Clark, Christiane Fellbaum, Jerry R. Hobbs, Phil
Harrison, William R. Murray, and John Thompson.
2008. Augmenting WordNet for Deep Understand-
ing of Text. In Proceedings of STEP 2008.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
and Bill Dolan. 2007. The third pascal recogniz-
ing textual entailment challenge. In Proceedings of
the ACL-PASCAL Workshop on Textual Entailment
and Paraphrasing.
Michael Kaisser and Bonnie Webber. 2007. Question
answering based on semantic roles. In ACL 2007
Workshop on Deep Linguistic Processing.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000. Class-based construction of a verb lexicon.
In Proceedings of AAAI.
Mirella Lapata and Alex Lascarides. 2003. Detect-
ing novel compounds: The role of distributional ev-
idence. In Proceedings of EACL.
Dekang Lin and Patrick Pantel. 2001. Discovery of in-
ference rules for question answering. Natural Lan-
guage Engineering, 7(4):343–360.
Dekang Lin. 1998. Dependency-based evaluation of
minipar. In Proceedings of the Workshop on Eval-
uation of Parsing Systems at LREC 1998, Granada,
Spain.
John B. Lowe, Collin F. Baker, and Charles J. Fillmore.
1997. A frame-semantic approach to semantic an-
notation. In Proceedings of the SIGLEX Workshop
on Tagging Text with Lexical Semantics: Why, What,
and How?
Catherine Macleod, Ralph Grishman, Adam Meyers,
Leslie Barrett, and Ruth Reeves. 1998. NOMLEX:
A Lexicon of Nominalizations. In Proceedings of
EURALEX.
Adams Meyers, Catherine Macleod, Roman Yangarber,
Ralph Grishman, Leslie Barrett, and Ruth Reeves.
1998. Using nomlex to produce nominalization pat-
terns for information extraction. In Proceedings of
COLING.
Adam Meyers, Ruth Reeves, Catherine Macleod,
Rachel Szekeley, Veronkia Zielinska, and Brian
Young. 2004. The Cross-Breeding of Dictionaries.
In Proceedings of LREC.
George A. Miller. 1995. Wordnet: A lexical database
for english. In Communications of the ACM.
Dan Moldovan and Rada Mihalcea. 2000. Using
wordnet and lexical operators to improve internet
searches. IEEE Internet Computing, 4(1):34–43.
Dan Moldovan and Adrian Novischi. 2002. Lexical
chains for question answering. In Proceedings of
COLING.
Dan Moldovan and Vasile Rus. 2001. Logic form
transformation of wordnet and its applicability to
question answering. In Proceedings ofACL.
Adrian Novischi and Dan Moldovan. 2006. Question
answering with lexical chains propagating verb ar-
guments. In Proceedings ofACL.
Martha Palmer, Hoa Trang Dang, and Christiane
Fellbaum. 2007. Making fine-grained and
coarse-grained sense distinctions, both manually
and automatically. Natural Language Engineering,
13(2):137–163.
Marius Pasca and Sanda Harabagiu. 2001. The in-
formative role of wordnet in open-domain question
answering. In Proceedings of Workshop on WordNet
and Other Lexical Resources: Applications, Exten-
sions and Customizations.
Satoshi Sekine. 2005. Automatic paraphrase discovery
based on context and keywords between ne pairs. In
Proceedings of IWP.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous
evidence. In Proceedings of ACL.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: A core of semantic knowl-
edge - unifying wordnet and wikipedia. In Proceed-
ings of WWW2007.
Idan Szpektor and Ido Dagan. 2008. Learning entail-
ment rules for unary templates. In Proceedings of
COLING.
Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-
ture Coppola. 2004. Scaling web based acquisition
of entailment patterns. In Proceedings of EMNLP
2004.
Idan Szpektor, Ido Dagan, Roy Bar-Haim, and Jacob
Goldberger. 2008. Contextual preferences. In Pro-
ceedings of ACL.
Frank Wilcoxon. 1945. Individual comparisons by
ranking methods. Biometrics Bulletin, 1:80–83.
</reference>
<page confidence="0.999325">
35
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.111918">
<title confidence="0.999868">Augmenting WordNet-based Inference with Argument Mapping</title>
<author confidence="0.84006">Idan</author>
<affiliation confidence="0.879787">Department of Computer</affiliation>
<author confidence="0.4212">Bar-Ilan Ramat Gan</author>
<email confidence="0.999001">szpekti@cs.biu.ac.il</email>
<author confidence="0.994527">Ido Dagan</author>
<affiliation confidence="0.9999045">Department of Computer Science Bar-Ilan University</affiliation>
<address confidence="0.965349">Ramat Gan, Israel</address>
<email confidence="0.999374">dagan@cs.biu.ac.il</email>
<abstract confidence="0.987697538461539">WordNet is a useful resource for lexical inference in applications. Inference over predicates, however, often requires a change in argument positions, which is not specified in WordNet. We propose a novel framework for augmenting WordNet-based inferences over predicates with corresponding argument mappings. We further present a concrete implementation of this framework, which yields substantial improvement to WordNet-based inference.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The berkeley framenet project.</title>
<date>1998</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="31349" citStr="Baker et al., 1998" startWordPosition="4981" endWordPosition="4984">ation frames to identify possible verb arguments. Argument mapping is provided only between verbs, ignoring relations between verbs and nouns. Arguments are mapped based on thematic role names shared between frames of different verbs. However, the semantic interpretation of thematic roles is generally inconsistent across verbs (Lowe et al., 1997; Kaisser and Webber, 2007). Instead, we discover these mappings from corpus statistics, offering an accurate approach (as analyzed in Section 5.2). A frame semantics approach for argument mapping between predicates is proposed by the FrameNet project (Baker et al., 1998). Currently, FrameNet is the only resource for frame-semantic argument mappings. However, it is manually constructed and currently covers much less predicates and relations than WordNet. Furthermore, frame-semantic parsers are less robust than syntactic parsers, presently hindering the utilization of this approach in applications (Burchardt and Pennacchiotti, 2008). Nomlex argument mapping patterns similar to ours were derived for IE in (Meyers et al., 1998), but they were not integrated with any additional information, such as WordNet. 7 Conclusions We presented Argument-mapped WordNet (AmWN)</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The berkeley framenet project. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
<author>Lisa Ferro</author>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Idan Szpektor</author>
</authors>
<title>The second pascal recognising textual entailment challenge.</title>
<date>2006</date>
<booktitle>In Second PASCAL Challenge Workshop for Recognizing Textual Entailment.</booktitle>
<contexts>
<context position="1050" citStr="Bar-Haim et al., 2006" startWordPosition="140" endWordPosition="143">ot specified in WordNet. We propose a novel framework for augmenting WordNet-based inferences over predicates with corresponding argument mappings. We further present a concrete implementation of this framework, which yields substantial improvement to WordNet-based inference. 1 Introduction WordNet (Miller, 1995), a manually constructed lexical database, is probably the mostly used resource for lexical inference in NLP tasks, such as Question Answering (QA), Information Extraction (IE), Information Retrieval and Textual Entailment (RTE) (Moldovan and Mihalcea, 2000; Pasca and Harabagiu, 2001; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Inference using WordNet typically involves lexical substitutions for words in text based on WordNet relations, a process known as lexical chains (Barzilay and Elhadad, 1997; Moldovan and Novischi, 2002). For example, the answer to “From which country was Louisiana acquired?” can be inferred from “The United States bought up Louisiana from France” using the chains ‘France ⇒ European country ⇒ country’ and ‘buy up ⇒ buy ⇒ acquire’. When performing inference between predicates there is an additional complexity on top of lexical substitution: the syntactic relationship</context>
</contexts>
<marker>Bar-Haim, Dagan, Dolan, Ferro, Giampiccolo, Magnini, Szpektor, 2006</marker>
<rawString>Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo, Bernardo Magnini, and Idan Szpektor. 2006. The second pascal recognising textual entailment challenge. In Second PASCAL Challenge Workshop for Recognizing Textual Entailment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Michael Elhadad</author>
</authors>
<title>Using lexical chains for text summarization.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1251" citStr="Barzilay and Elhadad, 1997" startWordPosition="170" endWordPosition="173">this framework, which yields substantial improvement to WordNet-based inference. 1 Introduction WordNet (Miller, 1995), a manually constructed lexical database, is probably the mostly used resource for lexical inference in NLP tasks, such as Question Answering (QA), Information Extraction (IE), Information Retrieval and Textual Entailment (RTE) (Moldovan and Mihalcea, 2000; Pasca and Harabagiu, 2001; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Inference using WordNet typically involves lexical substitutions for words in text based on WordNet relations, a process known as lexical chains (Barzilay and Elhadad, 1997; Moldovan and Novischi, 2002). For example, the answer to “From which country was Louisiana acquired?” can be inferred from “The United States bought up Louisiana from France” using the chains ‘France ⇒ European country ⇒ country’ and ‘buy up ⇒ buy ⇒ acquire’. When performing inference between predicates there is an additional complexity on top of lexical substitution: the syntactic relationship between the predicate and its arguments may change as well. For example, ‘X buy Y for Z ⇒ X pay Z for Y ’. Currently, argument mappings are not specified for WordNet’s relations. Therefore, correct Wo</context>
</contexts>
<marker>Barzilay, Elhadad, 1997</marker>
<rawString>Regina Barzilay and Michael Elhadad. 1997. Using lexical chains for text summarization. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Marco Pennacchiotti</author>
</authors>
<title>Fate: a framenet-annotated corpus for textual entailment.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="31716" citStr="Burchardt and Pennacchiotti, 2008" startWordPosition="5031" endWordPosition="5035">sser and Webber, 2007). Instead, we discover these mappings from corpus statistics, offering an accurate approach (as analyzed in Section 5.2). A frame semantics approach for argument mapping between predicates is proposed by the FrameNet project (Baker et al., 1998). Currently, FrameNet is the only resource for frame-semantic argument mappings. However, it is manually constructed and currently covers much less predicates and relations than WordNet. Furthermore, frame-semantic parsers are less robust than syntactic parsers, presently hindering the utilization of this approach in applications (Burchardt and Pennacchiotti, 2008). Nomlex argument mapping patterns similar to ours were derived for IE in (Meyers et al., 1998), but they were not integrated with any additional information, such as WordNet. 7 Conclusions We presented Argument-mapped WordNet (AmWN), a novel framework for augmenting WordNet with argument mappings at the syntactic representation level. With AmWN, non-substitutable WordNet relations can also be utilized correctly, increasing the coverage of WordNet-based inference. The standard entailment rule representation is augmented in our work with functional roles and subcategorization frames, shown to b</context>
</contexts>
<marker>Burchardt, Pennacchiotti, 2008</marker>
<rawString>Aljoscha Burchardt and Marco Pennacchiotti. 2008. Fate: a framenet-annotated corpus for textual entailment. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Clark</author>
<author>Christiane Fellbaum</author>
<author>Jerry R Hobbs</author>
<author>Phil Harrison</author>
<author>William R Murray</author>
<author>John Thompson</author>
</authors>
<title>Augmenting WordNet for Deep Understanding of Text.</title>
<date>2008</date>
<booktitle>In Proceedings of STEP</booktitle>
<contexts>
<context position="30560" citStr="Clark et al., 2008" startWordPosition="4863" endWordPosition="4866">sion, a relative drop of 22%. Yet, recall increases relatively by 8%, indicating that some verb synsets, connected via a shared nominal, entail each other even though they are not connected directly. For example, ‘found X ⇔ create X’ was generated only via the shared nominal ‘founding’. In future work, we plan to apply AmWN to a coarse-grained set of WordNet synsets (Palmer et al., 2007) as a possible solution to sense drifting. 6 Related Work Several works attempt to extend WordNet with additional lexical semantic information (Moldovan and Rus, 2001; Snow et al., 2006; Suchanek et al., 2007; Clark et al., 2008). However, the only previous work we are aware of that enriches WordNet with argument mappings is (Novischi and Moldovan, 2006). This work utilizes VerbNet’s subcategorization frames to identify possible verb arguments. Argument mapping is provided only between verbs, ignoring relations between verbs and nouns. Arguments are mapped based on thematic role names shared between frames of different verbs. However, the semantic interpretation of thematic roles is generally inconsistent across verbs (Lowe et al., 1997; Kaisser and Webber, 2007). Instead, we discover these mappings from corpus statis</context>
</contexts>
<marker>Clark, Fellbaum, Hobbs, Harrison, Murray, Thompson, 2008</marker>
<rawString>Peter Clark, Christiane Fellbaum, Jerry R. Hobbs, Phil Harrison, William R. Murray, and John Thompson. 2008. Augmenting WordNet for Deep Understanding of Text. In Proceedings of STEP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The third pascal recognizing textual entailment challenge.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</booktitle>
<contexts>
<context position="1077" citStr="Giampiccolo et al., 2007" startWordPosition="144" endWordPosition="147">. We propose a novel framework for augmenting WordNet-based inferences over predicates with corresponding argument mappings. We further present a concrete implementation of this framework, which yields substantial improvement to WordNet-based inference. 1 Introduction WordNet (Miller, 1995), a manually constructed lexical database, is probably the mostly used resource for lexical inference in NLP tasks, such as Question Answering (QA), Information Extraction (IE), Information Retrieval and Textual Entailment (RTE) (Moldovan and Mihalcea, 2000; Pasca and Harabagiu, 2001; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Inference using WordNet typically involves lexical substitutions for words in text based on WordNet relations, a process known as lexical chains (Barzilay and Elhadad, 1997; Moldovan and Novischi, 2002). For example, the answer to “From which country was Louisiana acquired?” can be inferred from “The United States bought up Louisiana from France” using the chains ‘France ⇒ European country ⇒ country’ and ‘buy up ⇒ buy ⇒ acquire’. When performing inference between predicates there is an additional complexity on top of lexical substitution: the syntactic relationship between the predicate and </context>
</contexts>
<marker>Giampiccolo, Magnini, Dagan, Dolan, 2007</marker>
<rawString>Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007. The third pascal recognizing textual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Kaisser</author>
<author>Bonnie Webber</author>
</authors>
<title>Question answering based on semantic roles.</title>
<date>2007</date>
<booktitle>In ACL 2007 Workshop on Deep Linguistic Processing.</booktitle>
<contexts>
<context position="31104" citStr="Kaisser and Webber, 2007" startWordPosition="4945" endWordPosition="4948">ovan and Rus, 2001; Snow et al., 2006; Suchanek et al., 2007; Clark et al., 2008). However, the only previous work we are aware of that enriches WordNet with argument mappings is (Novischi and Moldovan, 2006). This work utilizes VerbNet’s subcategorization frames to identify possible verb arguments. Argument mapping is provided only between verbs, ignoring relations between verbs and nouns. Arguments are mapped based on thematic role names shared between frames of different verbs. However, the semantic interpretation of thematic roles is generally inconsistent across verbs (Lowe et al., 1997; Kaisser and Webber, 2007). Instead, we discover these mappings from corpus statistics, offering an accurate approach (as analyzed in Section 5.2). A frame semantics approach for argument mapping between predicates is proposed by the FrameNet project (Baker et al., 1998). Currently, FrameNet is the only resource for frame-semantic argument mappings. However, it is manually constructed and currently covers much less predicates and relations than WordNet. Furthermore, frame-semantic parsers are less robust than syntactic parsers, presently hindering the utilization of this approach in applications (Burchardt and Pennacch</context>
</contexts>
<marker>Kaisser, Webber, 2007</marker>
<rawString>Michael Kaisser and Bonnie Webber. 2007. Question answering based on semantic roles. In ACL 2007 Workshop on Deep Linguistic Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper</author>
<author>Hoa Trang Dang</author>
<author>Martha Palmer</author>
</authors>
<title>Class-based construction of a verb lexicon.</title>
<date>2000</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="10210" citStr="Kipper et al., 2000" startWordPosition="1569" endWordPosition="1572">us on entailment between predicates, we include only predicative synsets: all verb synsets and noun synsets identified as predicates (see Section 3.2). In addition, only WordNet relations that correspond to some type of entailment are considered, as detailed in Section 3.2. In our framework, different subcategorization frames are treated as having different “meanings”, since different frames may correspond to different entailment rules. Each WordNet synset is split into several nodes, one for each of its frames. We take frame descriptions for verbs from WordNet3. 3We also tried using VerbNet (Kipper et al., 2000), withFigure 1: A description of ‘buy/purchase X ⇒ pay for X’ as a mapping edge in AmWN. Since WordNet does not provide frames for noun predicates, these are taken from Nomlex-plus (see Section 3.2). There are two types of graph edges that represent entailment rules between nodes: mapping edges and substitution edges. Mapping edges specify entailment rules that require argument mapping, where the entailing and entailed template predicates are replaced by synsets. Thus, an edge represents all rules between entailing and entailed synset members, as in Figure 1. Substitution edges connect pairs o</context>
</contexts>
<marker>Kipper, Dang, Palmer, 2000</marker>
<rawString>Karin Kipper, Hoa Trang Dang, and Martha Palmer. 2000. Class-based construction of a verb lexicon. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>Detecting novel compounds: The role of distributional evidence.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL.</booktitle>
<marker>Lapata, Lascarides, 2003</marker>
<rawString>Mirella Lapata and Alex Lascarides. 2003. Detecting novel compounds: The role of distributional evidence. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of inference rules for question answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="7371" citStr="Lin and Pantel, 2001" startWordPosition="1128" endWordPosition="1131">nctional roles typically coincide with dependency relations of the verbal form. A rule example is ‘Xsubj break{intrans} ⇒ damage{trans} Xobj’2. More examples are shown in Table 1. Unlike Nomlex records, our templates can be partial: they may contain only some of the possible predicate arguments, e.g. ‘buy{trans} Xobj’, where the subject, included in the frame, is omitted. Partial templates are necessary for matching predicate occurrences that include only some of the possible arguments, as in “Cognos was bought yesterday”. Additionally, some resources, such as automatic rule learning methods (Lin and Pantel, 2001; Sekine, 2005), can provide only partial argument information, and we would want to represent such knowledge as well. In our framework we follow (Szpektor and Dagan, 2008) and use only rules between unary templates, containing a single argument. Such templates can describe any argument mapping by de2Functional roles are denoted by subscripts of the arguments and frames by subscripts of the predicate. We shorthand trans for transitive frame {subject, object} and intrans for intransitive {subject}. For brevity, we will not show all template information when examples are self explanatory. 28 com</context>
<context position="15756" citStr="Lin and Pantel, 2001" startWordPosition="2470" endWordPosition="2473">‘hit’. A byproduct of this process is the automatic extension of Nomlex-plus with 5100 new nominalization entries, based on the inherited information4. 3.2.2 Verb-Verb Relations There are two inferential relations between verbs in WordNet that do not preserve argument positions: cause and entailment. Unlike for nominalizations, there is no broad-coverage manual resource of argument mapping for these relations. Hence, we turn to unsupervised approaches that learn entailment rules from corpus statistics. Many algorithms were proposed for learning entailment rules between templates from corpora (Lin and Pantel, 2001; Szpektor et al., 2004; Sekine, 2005), but typically with mediocre accuracy. However, we only search for rules between verbs for which WordNet already indicates the existence of an entailment relation and are thus not affected by rules that wrongly relate non-entailing verbs. We acquired a rule-set containing the top 300 rules for every unary template in the Reuters RCV1 corpus5 by implementing the unary-DIRT algorithm (Szpektor and Dagan, 2008), which was shown to have relatively high recall compared to other algorithms. 4We plan making this extension publicly available as well. 5http://abou</context>
<context position="29104" citStr="Lin and Pantel, 2001" startWordPosition="4627" endWordPosition="4630"> are due to rules that are generated from AmWN but filtered out by one of our filtering methods (Section 3.3). 12% of the arguments cannot be extracted by rules alone, due to required discourse analysis, while 18% of the mentions were missed due to incorrect syntactic matching. By assuming correct matches in these cases and avoiding rule filtering, we can estimate the upper bound recall of the ruleset for the ACE dataset to be 40%. In conclusion, for better performance the system should be augmented with context modeling and better template matching. Additionally, other rule-bases, e.g. DIRT (Lin and Pantel, 2001), should be added to increase rule coverage. 33 Configuration R (%) P (%) F1 AmWN 20.8 43.9 24.2 No nominalization mappings 18.1 45.5 21.8 No verb-verb mappings 19.3 43.8 22.8 No rule validation 22.0 30.4 20.9 No sense drift blocking 22.5 37.4 21.7 Table 6: The Recall (R), Precision (P) and F1 results for ablation tests. 5.3 Component Analysis Table 6 presents ablations tests that assess the marginal contribution of each AmWN component. Nominal-verb and verb-verb mappings contribute to the graph connectivity, hence the recall reduction when they are removed. Complementary to recall components,</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of inference rules for question answering. Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Dependency-based evaluation of minipar.</title>
<date>1998</date>
<booktitle>In Proceedings of the Workshop on Evaluation of Parsing Systems at LREC</booktitle>
<location>Granada,</location>
<contexts>
<context position="21902" citStr="Lin, 1998" startWordPosition="3479" endWordPosition="3480"> � (verb) get, catch, capture succeed in catching or seizing, especially after a chase � (noun) capture, seizure the act of taking of a person by force � (verb) seize take or capture by force ⇑ (hypernym) (verb) kidnap, nobble, abduct, snatch take away to an undisclosed location against their will and usually in order to extract a ransom Figure 3: A WordNet sense-drifting traversal, generating the incorrect inference ‘kidnap ⇒ arrest’. place) were ignored since they typically don’t require argument mapping, the main target for our assessment. The ACE corpus was dependency-parsed with Minipar (Lin, 1998) and annotated with functional roles and frames for each predicate mention. The functional roles for a verb mention were taken directly from the corresponding dependency tree relations. Its frame was chosen to be the largest WordNet frame of that verb that matched the mention’s roles. Nominalization frames and functional roles in the text were annotated using our extended Nomlex-plus database. For each nominal mention, we found the largest Nomlex frame whose syntactic argument positions matched those of the mention’s arguments. The arguments were then annotated with the specified roles of the </context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Dependency-based evaluation of minipar. In Proceedings of the Workshop on Evaluation of Parsing Systems at LREC 1998, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John B Lowe</author>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
</authors>
<title>A frame-semantic approach to semantic annotation.</title>
<date>1997</date>
<booktitle>In Proceedings of the SIGLEX Workshop on Tagging Text with Lexical Semantics: Why,</booktitle>
<location>What, and How?</location>
<contexts>
<context position="31077" citStr="Lowe et al., 1997" startWordPosition="4941" endWordPosition="4944">c information (Moldovan and Rus, 2001; Snow et al., 2006; Suchanek et al., 2007; Clark et al., 2008). However, the only previous work we are aware of that enriches WordNet with argument mappings is (Novischi and Moldovan, 2006). This work utilizes VerbNet’s subcategorization frames to identify possible verb arguments. Argument mapping is provided only between verbs, ignoring relations between verbs and nouns. Arguments are mapped based on thematic role names shared between frames of different verbs. However, the semantic interpretation of thematic roles is generally inconsistent across verbs (Lowe et al., 1997; Kaisser and Webber, 2007). Instead, we discover these mappings from corpus statistics, offering an accurate approach (as analyzed in Section 5.2). A frame semantics approach for argument mapping between predicates is proposed by the FrameNet project (Baker et al., 1998). Currently, FrameNet is the only resource for frame-semantic argument mappings. However, it is manually constructed and currently covers much less predicates and relations than WordNet. Furthermore, frame-semantic parsers are less robust than syntactic parsers, presently hindering the utilization of this approach in applicati</context>
</contexts>
<marker>Lowe, Baker, Fillmore, 1997</marker>
<rawString>John B. Lowe, Collin F. Baker, and Charles J. Fillmore. 1997. A frame-semantic approach to semantic annotation. In Proceedings of the SIGLEX Workshop on Tagging Text with Lexical Semantics: Why, What, and How?</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Macleod</author>
<author>Ralph Grishman</author>
<author>Adam Meyers</author>
<author>Leslie Barrett</author>
<author>Ruth Reeves</author>
</authors>
<title>NOMLEX: A Lexicon of Nominalizations.</title>
<date>1998</date>
<booktitle>In Proceedings of EURALEX.</booktitle>
<contexts>
<context position="6393" citStr="Macleod et al., 1998" startWordPosition="974" endWordPosition="977">positions is insufficient for predicative rules. Correct argument mapping 1We plan to make our AmWN publicly available. depends also on the specific syntactic functional roles of the arguments (subject, object etc.) and on the suitable subcategorization frame (frame) for the predicate mention - a set of functional roles that a predicate may occur with. For example, ‘X’s buyout ⇒ buy X’ is incorrectly applied to “IBM’s buyout of Cognos” if roles are ignored, since ‘IBM’ plays the subject role while X needs to be an object. Seeking to address this issue, we were inspired by the Nomlex database (Macleod et al., 1998) (see Section 3.2.1) and explicitly specify argument mapping for each frame and functional role. As in Nomlex, we avoid the use of semantic roles and stick to the syntactic level, augmenting the representation of templates with: (a) a syntactic functional role for each argument; (b) the valid predicate frame for this template mentions. We note that such functional roles typically coincide with dependency relations of the verbal form. A rule example is ‘Xsubj break{intrans} ⇒ damage{trans} Xobj’2. More examples are shown in Table 1. Unlike Nomlex records, our templates can be partial: they may </context>
</contexts>
<marker>Macleod, Grishman, Meyers, Barrett, Reeves, 1998</marker>
<rawString>Catherine Macleod, Ralph Grishman, Adam Meyers, Leslie Barrett, and Ruth Reeves. 1998. NOMLEX: A Lexicon of Nominalizations. In Proceedings of EURALEX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adams Meyers</author>
<author>Catherine Macleod</author>
<author>Roman Yangarber</author>
<author>Ralph Grishman</author>
<author>Leslie Barrett</author>
<author>Ruth Reeves</author>
</authors>
<title>Using nomlex to produce nominalization patterns for information extraction.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="31811" citStr="Meyers et al., 1998" startWordPosition="5048" endWordPosition="5051">oach (as analyzed in Section 5.2). A frame semantics approach for argument mapping between predicates is proposed by the FrameNet project (Baker et al., 1998). Currently, FrameNet is the only resource for frame-semantic argument mappings. However, it is manually constructed and currently covers much less predicates and relations than WordNet. Furthermore, frame-semantic parsers are less robust than syntactic parsers, presently hindering the utilization of this approach in applications (Burchardt and Pennacchiotti, 2008). Nomlex argument mapping patterns similar to ours were derived for IE in (Meyers et al., 1998), but they were not integrated with any additional information, such as WordNet. 7 Conclusions We presented Argument-mapped WordNet (AmWN), a novel framework for augmenting WordNet with argument mappings at the syntactic representation level. With AmWN, non-substitutable WordNet relations can also be utilized correctly, increasing the coverage of WordNet-based inference. The standard entailment rule representation is augmented in our work with functional roles and subcategorization frames, shown to be a feasible extension needed for correct rule application in general. Our implementation of Am</context>
</contexts>
<marker>Meyers, Macleod, Yangarber, Grishman, Barrett, Reeves, 1998</marker>
<rawString>Adams Meyers, Catherine Macleod, Roman Yangarber, Ralph Grishman, Leslie Barrett, and Ruth Reeves. 1998. Using nomlex to produce nominalization patterns for information extraction. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Meyers</author>
<author>Ruth Reeves</author>
<author>Catherine Macleod</author>
<author>Rachel Szekeley</author>
<author>Veronkia Zielinska</author>
<author>Brian Young</author>
</authors>
<title>The Cross-Breeding of Dictionaries.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="12739" citStr="Meyers et al., 2004" startWordPosition="1959" endWordPosition="1962">ent performance improvement. 29 :ORTH &amp;quot;employment&amp;quot; :VERB &amp;quot;employ&amp;quot; :VERB-SUBC ((NOM-NP :SUBJECT ((DET-POSS) (N-N-MOD) (PP :PVAL (&amp;quot;by&amp;quot;))) :OBJECT ((DET-POSS) (PP :PVAL (&amp;quot;of&amp;quot;))) Figure 2: Part of the employment Nomlex entry, describing the possible syntactic dependency positions for each role of the transitive frame. It states, for example, that the verbal ‘object’ role can be mapped to employment either as a possessive or as the complement of the preposition ‘of’. is described in WordNet by the derivationally related relation. To add argument mappings for these relations we utilize Nomlex-plus (Meyers et al., 2004), a database of around 5000 English nominalizations. Nomlex specifies for each verbal subcategorization frame of each nominalization how its argument positions are mapped to functional roles of related verbs. For each Nomlex entry, we extract all possible argument mappings between the verbal and nominal forms, as well as between different argument realizations of the noun. For example, the mappings ‘Xobj’s employment ⇔ employ Xobj’ and ‘Xobj’s employment ⇔ employment of Xobj’ are derived from the entry in Figure 2. The major challenge in integrating Nomlex and WordNet is to identify for each N</context>
</contexts>
<marker>Meyers, Reeves, Macleod, Szekeley, Zielinska, Young, 2004</marker>
<rawString>Adam Meyers, Ruth Reeves, Catherine Macleod, Rachel Szekeley, Veronkia Zielinska, and Brian Young. 2004. The Cross-Breeding of Dictionaries. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: A lexical database for english.</title>
<date>1995</date>
<booktitle>In Communications of the ACM.</booktitle>
<contexts>
<context position="743" citStr="Miller, 1995" startWordPosition="96" endWordPosition="97">n, Israel szpekti@cs.biu.ac.il Ido Dagan Department of Computer Science Bar-Ilan University Ramat Gan, Israel dagan@cs.biu.ac.il Abstract WordNet is a useful resource for lexical inference in applications. Inference over predicates, however, often requires a change in argument positions, which is not specified in WordNet. We propose a novel framework for augmenting WordNet-based inferences over predicates with corresponding argument mappings. We further present a concrete implementation of this framework, which yields substantial improvement to WordNet-based inference. 1 Introduction WordNet (Miller, 1995), a manually constructed lexical database, is probably the mostly used resource for lexical inference in NLP tasks, such as Question Answering (QA), Information Extraction (IE), Information Retrieval and Textual Entailment (RTE) (Moldovan and Mihalcea, 2000; Pasca and Harabagiu, 2001; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Inference using WordNet typically involves lexical substitutions for words in text based on WordNet relations, a process known as lexical chains (Barzilay and Elhadad, 1997; Moldovan and Novischi, 2002). For example, the answer to “From which country was Louisiana</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. Wordnet: A lexical database for english. In Communications of the ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Moldovan</author>
<author>Rada Mihalcea</author>
</authors>
<title>Using wordnet and lexical operators to improve internet searches.</title>
<date>2000</date>
<journal>IEEE Internet Computing,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="1000" citStr="Moldovan and Mihalcea, 2000" startWordPosition="132" endWordPosition="135">ften requires a change in argument positions, which is not specified in WordNet. We propose a novel framework for augmenting WordNet-based inferences over predicates with corresponding argument mappings. We further present a concrete implementation of this framework, which yields substantial improvement to WordNet-based inference. 1 Introduction WordNet (Miller, 1995), a manually constructed lexical database, is probably the mostly used resource for lexical inference in NLP tasks, such as Question Answering (QA), Information Extraction (IE), Information Retrieval and Textual Entailment (RTE) (Moldovan and Mihalcea, 2000; Pasca and Harabagiu, 2001; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Inference using WordNet typically involves lexical substitutions for words in text based on WordNet relations, a process known as lexical chains (Barzilay and Elhadad, 1997; Moldovan and Novischi, 2002). For example, the answer to “From which country was Louisiana acquired?” can be inferred from “The United States bought up Louisiana from France” using the chains ‘France ⇒ European country ⇒ country’ and ‘buy up ⇒ buy ⇒ acquire’. When performing inference between predicates there is an additional complexity on top o</context>
</contexts>
<marker>Moldovan, Mihalcea, 2000</marker>
<rawString>Dan Moldovan and Rada Mihalcea. 2000. Using wordnet and lexical operators to improve internet searches. IEEE Internet Computing, 4(1):34–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Moldovan</author>
<author>Adrian Novischi</author>
</authors>
<title>Lexical chains for question answering.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="1281" citStr="Moldovan and Novischi, 2002" startWordPosition="174" endWordPosition="177"> substantial improvement to WordNet-based inference. 1 Introduction WordNet (Miller, 1995), a manually constructed lexical database, is probably the mostly used resource for lexical inference in NLP tasks, such as Question Answering (QA), Information Extraction (IE), Information Retrieval and Textual Entailment (RTE) (Moldovan and Mihalcea, 2000; Pasca and Harabagiu, 2001; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Inference using WordNet typically involves lexical substitutions for words in text based on WordNet relations, a process known as lexical chains (Barzilay and Elhadad, 1997; Moldovan and Novischi, 2002). For example, the answer to “From which country was Louisiana acquired?” can be inferred from “The United States bought up Louisiana from France” using the chains ‘France ⇒ European country ⇒ country’ and ‘buy up ⇒ buy ⇒ acquire’. When performing inference between predicates there is an additional complexity on top of lexical substitution: the syntactic relationship between the predicate and its arguments may change as well. For example, ‘X buy Y for Z ⇒ X pay Z for Y ’. Currently, argument mappings are not specified for WordNet’s relations. Therefore, correct WordNet inference chains over pr</context>
</contexts>
<marker>Moldovan, Novischi, 2002</marker>
<rawString>Dan Moldovan and Adrian Novischi. 2002. Lexical chains for question answering. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Moldovan</author>
<author>Vasile Rus</author>
</authors>
<title>Logic form transformation of wordnet and its applicability to question answering.</title>
<date>2001</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="30497" citStr="Moldovan and Rus, 2001" startWordPosition="4851" endWordPosition="4854">nefit of noisy-rule filtering. Allowing sense drifting hurts precision, a relative drop of 22%. Yet, recall increases relatively by 8%, indicating that some verb synsets, connected via a shared nominal, entail each other even though they are not connected directly. For example, ‘found X ⇔ create X’ was generated only via the shared nominal ‘founding’. In future work, we plan to apply AmWN to a coarse-grained set of WordNet synsets (Palmer et al., 2007) as a possible solution to sense drifting. 6 Related Work Several works attempt to extend WordNet with additional lexical semantic information (Moldovan and Rus, 2001; Snow et al., 2006; Suchanek et al., 2007; Clark et al., 2008). However, the only previous work we are aware of that enriches WordNet with argument mappings is (Novischi and Moldovan, 2006). This work utilizes VerbNet’s subcategorization frames to identify possible verb arguments. Argument mapping is provided only between verbs, ignoring relations between verbs and nouns. Arguments are mapped based on thematic role names shared between frames of different verbs. However, the semantic interpretation of thematic roles is generally inconsistent across verbs (Lowe et al., 1997; Kaisser and Webber</context>
</contexts>
<marker>Moldovan, Rus, 2001</marker>
<rawString>Dan Moldovan and Vasile Rus. 2001. Logic form transformation of wordnet and its applicability to question answering. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrian Novischi</author>
<author>Dan Moldovan</author>
</authors>
<title>Question answering with lexical chains propagating verb arguments.</title>
<date>2006</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="30687" citStr="Novischi and Moldovan, 2006" startWordPosition="4885" endWordPosition="4888"> a shared nominal, entail each other even though they are not connected directly. For example, ‘found X ⇔ create X’ was generated only via the shared nominal ‘founding’. In future work, we plan to apply AmWN to a coarse-grained set of WordNet synsets (Palmer et al., 2007) as a possible solution to sense drifting. 6 Related Work Several works attempt to extend WordNet with additional lexical semantic information (Moldovan and Rus, 2001; Snow et al., 2006; Suchanek et al., 2007; Clark et al., 2008). However, the only previous work we are aware of that enriches WordNet with argument mappings is (Novischi and Moldovan, 2006). This work utilizes VerbNet’s subcategorization frames to identify possible verb arguments. Argument mapping is provided only between verbs, ignoring relations between verbs and nouns. Arguments are mapped based on thematic role names shared between frames of different verbs. However, the semantic interpretation of thematic roles is generally inconsistent across verbs (Lowe et al., 1997; Kaisser and Webber, 2007). Instead, we discover these mappings from corpus statistics, offering an accurate approach (as analyzed in Section 5.2). A frame semantics approach for argument mapping between predi</context>
</contexts>
<marker>Novischi, Moldovan, 2006</marker>
<rawString>Adrian Novischi and Dan Moldovan. 2006. Question answering with lexical chains propagating verb arguments. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Hoa Trang Dang</author>
<author>Christiane Fellbaum</author>
</authors>
<title>Making fine-grained and coarse-grained sense distinctions, both manually and automatically.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="30331" citStr="Palmer et al., 2007" startWordPosition="4824" endWordPosition="4827">iltering improves precision. When removing the corpus-based rule-validation, recall increases relatively by 6% but precision drops relatively by 30%, showing the benefit of noisy-rule filtering. Allowing sense drifting hurts precision, a relative drop of 22%. Yet, recall increases relatively by 8%, indicating that some verb synsets, connected via a shared nominal, entail each other even though they are not connected directly. For example, ‘found X ⇔ create X’ was generated only via the shared nominal ‘founding’. In future work, we plan to apply AmWN to a coarse-grained set of WordNet synsets (Palmer et al., 2007) as a possible solution to sense drifting. 6 Related Work Several works attempt to extend WordNet with additional lexical semantic information (Moldovan and Rus, 2001; Snow et al., 2006; Suchanek et al., 2007; Clark et al., 2008). However, the only previous work we are aware of that enriches WordNet with argument mappings is (Novischi and Moldovan, 2006). This work utilizes VerbNet’s subcategorization frames to identify possible verb arguments. Argument mapping is provided only between verbs, ignoring relations between verbs and nouns. Arguments are mapped based on thematic role names shared b</context>
</contexts>
<marker>Palmer, Dang, Fellbaum, 2007</marker>
<rawString>Martha Palmer, Hoa Trang Dang, and Christiane Fellbaum. 2007. Making fine-grained and coarse-grained sense distinctions, both manually and automatically. Natural Language Engineering, 13(2):137–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pasca</author>
<author>Sanda Harabagiu</author>
</authors>
<title>The informative role of wordnet in open-domain question answering.</title>
<date>2001</date>
<booktitle>In Proceedings of Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations.</booktitle>
<contexts>
<context position="1027" citStr="Pasca and Harabagiu, 2001" startWordPosition="136" endWordPosition="139">ument positions, which is not specified in WordNet. We propose a novel framework for augmenting WordNet-based inferences over predicates with corresponding argument mappings. We further present a concrete implementation of this framework, which yields substantial improvement to WordNet-based inference. 1 Introduction WordNet (Miller, 1995), a manually constructed lexical database, is probably the mostly used resource for lexical inference in NLP tasks, such as Question Answering (QA), Information Extraction (IE), Information Retrieval and Textual Entailment (RTE) (Moldovan and Mihalcea, 2000; Pasca and Harabagiu, 2001; Bar-Haim et al., 2006; Giampiccolo et al., 2007). Inference using WordNet typically involves lexical substitutions for words in text based on WordNet relations, a process known as lexical chains (Barzilay and Elhadad, 1997; Moldovan and Novischi, 2002). For example, the answer to “From which country was Louisiana acquired?” can be inferred from “The United States bought up Louisiana from France” using the chains ‘France ⇒ European country ⇒ country’ and ‘buy up ⇒ buy ⇒ acquire’. When performing inference between predicates there is an additional complexity on top of lexical substitution: the</context>
</contexts>
<marker>Pasca, Harabagiu, 2001</marker>
<rawString>Marius Pasca and Sanda Harabagiu. 2001. The informative role of wordnet in open-domain question answering. In Proceedings of Workshop on WordNet and Other Lexical Resources: Applications, Extensions and Customizations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
</authors>
<title>Automatic paraphrase discovery based on context and keywords between ne pairs.</title>
<date>2005</date>
<booktitle>In Proceedings of IWP.</booktitle>
<contexts>
<context position="7386" citStr="Sekine, 2005" startWordPosition="1132" endWordPosition="1133">ly coincide with dependency relations of the verbal form. A rule example is ‘Xsubj break{intrans} ⇒ damage{trans} Xobj’2. More examples are shown in Table 1. Unlike Nomlex records, our templates can be partial: they may contain only some of the possible predicate arguments, e.g. ‘buy{trans} Xobj’, where the subject, included in the frame, is omitted. Partial templates are necessary for matching predicate occurrences that include only some of the possible arguments, as in “Cognos was bought yesterday”. Additionally, some resources, such as automatic rule learning methods (Lin and Pantel, 2001; Sekine, 2005), can provide only partial argument information, and we would want to represent such knowledge as well. In our framework we follow (Szpektor and Dagan, 2008) and use only rules between unary templates, containing a single argument. Such templates can describe any argument mapping by de2Functional roles are denoted by subscripts of the arguments and frames by subscripts of the predicate. We shorthand trans for transitive frame {subject, object} and intrans for intransitive {subject}. For brevity, we will not show all template information when examples are self explanatory. 28 composing template</context>
<context position="15794" citStr="Sekine, 2005" startWordPosition="2478" endWordPosition="2479">omatic extension of Nomlex-plus with 5100 new nominalization entries, based on the inherited information4. 3.2.2 Verb-Verb Relations There are two inferential relations between verbs in WordNet that do not preserve argument positions: cause and entailment. Unlike for nominalizations, there is no broad-coverage manual resource of argument mapping for these relations. Hence, we turn to unsupervised approaches that learn entailment rules from corpus statistics. Many algorithms were proposed for learning entailment rules between templates from corpora (Lin and Pantel, 2001; Szpektor et al., 2004; Sekine, 2005), but typically with mediocre accuracy. However, we only search for rules between verbs for which WordNet already indicates the existence of an entailment relation and are thus not affected by rules that wrongly relate non-entailing verbs. We acquired a rule-set containing the top 300 rules for every unary template in the Reuters RCV1 corpus5 by implementing the unary-DIRT algorithm (Szpektor and Dagan, 2008), which was shown to have relatively high recall compared to other algorithms. 4We plan making this extension publicly available as well. 5http://about.reuters.com/researchandstandards/cor</context>
</contexts>
<marker>Sekine, 2005</marker>
<rawString>Satoshi Sekine. 2005. Automatic paraphrase discovery based on context and keywords between ne pairs. In Proceedings of IWP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="30516" citStr="Snow et al., 2006" startWordPosition="4855" endWordPosition="4858">ering. Allowing sense drifting hurts precision, a relative drop of 22%. Yet, recall increases relatively by 8%, indicating that some verb synsets, connected via a shared nominal, entail each other even though they are not connected directly. For example, ‘found X ⇔ create X’ was generated only via the shared nominal ‘founding’. In future work, we plan to apply AmWN to a coarse-grained set of WordNet synsets (Palmer et al., 2007) as a possible solution to sense drifting. 6 Related Work Several works attempt to extend WordNet with additional lexical semantic information (Moldovan and Rus, 2001; Snow et al., 2006; Suchanek et al., 2007; Clark et al., 2008). However, the only previous work we are aware of that enriches WordNet with argument mappings is (Novischi and Moldovan, 2006). This work utilizes VerbNet’s subcategorization frames to identify possible verb arguments. Argument mapping is provided only between verbs, ignoring relations between verbs and nouns. Arguments are mapped based on thematic role names shared between frames of different verbs. However, the semantic interpretation of thematic roles is generally inconsistent across verbs (Lowe et al., 1997; Kaisser and Webber, 2007). Instead, w</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006. Semantic taxonomy induction from heterogenous evidence. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago: A core of semantic knowledge - unifying wordnet and wikipedia.</title>
<date>2007</date>
<booktitle>In Proceedings of WWW2007.</booktitle>
<contexts>
<context position="30539" citStr="Suchanek et al., 2007" startWordPosition="4859" endWordPosition="4862">se drifting hurts precision, a relative drop of 22%. Yet, recall increases relatively by 8%, indicating that some verb synsets, connected via a shared nominal, entail each other even though they are not connected directly. For example, ‘found X ⇔ create X’ was generated only via the shared nominal ‘founding’. In future work, we plan to apply AmWN to a coarse-grained set of WordNet synsets (Palmer et al., 2007) as a possible solution to sense drifting. 6 Related Work Several works attempt to extend WordNet with additional lexical semantic information (Moldovan and Rus, 2001; Snow et al., 2006; Suchanek et al., 2007; Clark et al., 2008). However, the only previous work we are aware of that enriches WordNet with argument mappings is (Novischi and Moldovan, 2006). This work utilizes VerbNet’s subcategorization frames to identify possible verb arguments. Argument mapping is provided only between verbs, ignoring relations between verbs and nouns. Arguments are mapped based on thematic role names shared between frames of different verbs. However, the semantic interpretation of thematic roles is generally inconsistent across verbs (Lowe et al., 1997; Kaisser and Webber, 2007). Instead, we discover these mappin</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: A core of semantic knowledge - unifying wordnet and wikipedia. In Proceedings of WWW2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Learning entailment rules for unary templates.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="5225" citStr="Szpektor and Dagan, 2008" startWordPosition="780" endWordPosition="784">hm. We tested both WordNet and AmWN on a test set derived from a standard IE benchmark. The results show that AmWN substantially improves WordNet-based inference in terms of both recall and precision1. 2 Argument-Mapping Entailment Rules In our framework we represent argument mappings for inferential relations between predicates through an extension of entailment rules over syntactic representations. As defined in earlier works, an entailment rule specifies an inference relation between an entailing template and an entailed template, where templates are parse subtrees with argument variables (Szpektor and Dagan, 2008). For example, ‘X subj ←−− buy obj −−→ Y ⇒ ‘X subj ←−−pay prep−for −−−−−−→ Y ”. When a rule is applied to a text, a new consequent is inferred by instantiating the entailed template variables with the argument instantiations of the entailing template in the text. In our example, “IBM paid for Cognos” can be inferred from “IBM bought Cognos”. This way, the syntactic structure of the rule templates specifies the required argument positions for correct argument mapping. However, representing entailment rule structure only by syntactic argument positions is insufficient for predicative rules. Corr</context>
<context position="7543" citStr="Szpektor and Dagan, 2008" startWordPosition="1157" endWordPosition="1161"> in Table 1. Unlike Nomlex records, our templates can be partial: they may contain only some of the possible predicate arguments, e.g. ‘buy{trans} Xobj’, where the subject, included in the frame, is omitted. Partial templates are necessary for matching predicate occurrences that include only some of the possible arguments, as in “Cognos was bought yesterday”. Additionally, some resources, such as automatic rule learning methods (Lin and Pantel, 2001; Sekine, 2005), can provide only partial argument information, and we would want to represent such knowledge as well. In our framework we follow (Szpektor and Dagan, 2008) and use only rules between unary templates, containing a single argument. Such templates can describe any argument mapping by de2Functional roles are denoted by subscripts of the arguments and frames by subscripts of the predicate. We shorthand trans for transitive frame {subject, object} and intrans for intransitive {subject}. For brevity, we will not show all template information when examples are self explanatory. 28 composing templates with several arguments into unary ones, while preserving the specification of the subcategorization frame. To apply a rule, the entailing template must be </context>
<context position="16206" citStr="Szpektor and Dagan, 2008" startWordPosition="2541" endWordPosition="2544">approaches that learn entailment rules from corpus statistics. Many algorithms were proposed for learning entailment rules between templates from corpora (Lin and Pantel, 2001; Szpektor et al., 2004; Sekine, 2005), but typically with mediocre accuracy. However, we only search for rules between verbs for which WordNet already indicates the existence of an entailment relation and are thus not affected by rules that wrongly relate non-entailing verbs. We acquired a rule-set containing the top 300 rules for every unary template in the Reuters RCV1 corpus5 by implementing the unary-DIRT algorithm (Szpektor and Dagan, 2008), which was shown to have relatively high recall compared to other algorithms. 4We plan making this extension publicly available as well. 5http://about.reuters.com/researchandstandards/corpus/ 30 To extract argument mappings, we identify all AmWN node pairs whose synsets are related in WordNet by a cause or an entailment relation. For each pair, we look for unary-DIRT rules between any pair of members in the entailing and entailed synsets. For example, the synset {buy, purchase} entails {pay}, so we look for rules mapping either ‘buy ⇒ pay’ or ‘purchase ⇒ pay’. Table 2 presents examples for di</context>
<context position="19746" citStr="Szpektor and Dagan, 2008" startWordPosition="3136" endWordPosition="3139">nge for a predicate. The AmWN graphpath that generated each rule is automatically examined. A rule is considered valid if there is a sequence of directly-validated intermediate rules along the path whose transitive chaining generates the rule. Invalid rules are filtered out. To illustrate, suppose the rule ‘a ⇒ d’ was generated by the chain ‘a ⇒ b ⇒ c ⇒ d’. It is valid if there is a rule chain along the path that yields ‘a ⇒ d’, e.g. {‘a ⇒ b’,‘b ⇒ c’,‘c ⇒ d’} or {‘a ⇒ b’, ‘b ⇒ d’}, whose rules are all directly-validated. 4 Experimental Setup We follow here the experimental setup presented in (Szpektor and Dagan, 2008), testing the generated rules on the ACE 2005 event dataset6. This standard IE benchmark includes 33 types of event predicates such as Injure, Sue and Divorce7. The ACE guidelines specify for each event its possible arguments. For example, some of the Injure event arguments are Agent and Victim. All event mentions, including their instantiated arguments, are annotated in a corpus collected from various sources (newswire articles, blogs, etc.). To utilize the ACE dataset for evaluating rule applications, each ACE event predicate was represented by a set of unary seed templates, one for each eve</context>
<context position="21049" citStr="Szpektor and Dagan, 2008" startWordPosition="3344" endWordPosition="3347"> Each event argument is mapped to the corresponding seed template variable, e.g. ‘Agent’ to A and ‘Victim’ to V in the above example. We manually annotated each seed template with a subcategorization frame and an argument functional role, e.g. ‘injure{trans} Vobj’. We also included relevant WordNet synset-ids, so only rules fitting the target meaning of the event will be extracted. In this experiment, we focused only on the core semantic arguments. Adjuncts (time and 6http://projects.ldc.upenn.edu/ace/ 7Only 26 frequent event types that correspond to a unique predicate were tested, following (Szpektor and Dagan, 2008). 31 Synset Members WordNet Gloss (verb) collar, nail, apprehend, arrest, pick up, nab, cop take into custody � (noun) apprehension, arrest, catch, collar, pinch, the act of apprehending (especially apprehending taking into custody a criminal) � (verb) get, catch, capture succeed in catching or seizing, especially after a chase � (noun) capture, seizure the act of taking of a person by force � (verb) seize take or capture by force ⇑ (hypernym) (verb) kidnap, nobble, abduct, snatch take away to an undisclosed location against their will and usually in order to extract a ransom Figure 3: A WordN</context>
</contexts>
<marker>Szpektor, Dagan, 2008</marker>
<rawString>Idan Szpektor and Ido Dagan. 2008. Learning entailment rules for unary templates. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Hristo Tanev</author>
<author>Ido Dagan</author>
<author>Bonaventure Coppola</author>
</authors>
<title>Scaling web based acquisition of entailment patterns.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="15779" citStr="Szpektor et al., 2004" startWordPosition="2474" endWordPosition="2477">this process is the automatic extension of Nomlex-plus with 5100 new nominalization entries, based on the inherited information4. 3.2.2 Verb-Verb Relations There are two inferential relations between verbs in WordNet that do not preserve argument positions: cause and entailment. Unlike for nominalizations, there is no broad-coverage manual resource of argument mapping for these relations. Hence, we turn to unsupervised approaches that learn entailment rules from corpus statistics. Many algorithms were proposed for learning entailment rules between templates from corpora (Lin and Pantel, 2001; Szpektor et al., 2004; Sekine, 2005), but typically with mediocre accuracy. However, we only search for rules between verbs for which WordNet already indicates the existence of an entailment relation and are thus not affected by rules that wrongly relate non-entailing verbs. We acquired a rule-set containing the top 300 rules for every unary template in the Reuters RCV1 corpus5 by implementing the unary-DIRT algorithm (Szpektor and Dagan, 2008), which was shown to have relatively high recall compared to other algorithms. 4We plan making this extension publicly available as well. 5http://about.reuters.com/researcha</context>
</contexts>
<marker>Szpektor, Tanev, Dagan, Coppola, 2004</marker>
<rawString>Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaventure Coppola. 2004. Scaling web based acquisition of entailment patterns. In Proceedings of EMNLP 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
<author>Roy Bar-Haim</author>
<author>Jacob Goldberger</author>
</authors>
<title>Contextual preferences.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="28123" citStr="Szpektor et al., 2008" startWordPosition="4463" endWordPosition="4466">reasons for false negatives (missed argument mentions). sample indicates that virtually all AmWN edges that get utilized in practice are correct. Context mismatches, which constitute the majority of errors (57.2%), occur when the entailing template of a rule is matched in inappropriate contexts. This occurs typically when the match is against another sense of the predicate, or when an argument is not of the requested type (e.g. “The Enron sentence” vs. “A one month sentence”). In future work, we plan to address this problem by utilizing context-sensitive application of rules in the spirit of (Szpektor et al., 2008). Table 5 presents the false negatives analysis. Most missed extractions are due to rules that were not learned (67.7%). These mainly involve complex templates (‘file a lawsuit ⇔ sue’) and inference rules that are not synonyms/hypernyms (‘execute ⇒ sentence’), which are not widely annotated in WordNet. From further analysis, we found that 10% of these misses are due to rules that are generated from AmWN but filtered out by one of our filtering methods (Section 3.3). 12% of the arguments cannot be extracted by rules alone, due to required discourse analysis, while 18% of the mentions were misse</context>
</contexts>
<marker>Szpektor, Dagan, Bar-Haim, Goldberger, 2008</marker>
<rawString>Idan Szpektor, Ido Dagan, Roy Bar-Haim, and Jacob Goldberger. 2008. Contextual preferences. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Wilcoxon</author>
</authors>
<title>Individual comparisons by ranking methods.</title>
<date>1945</date>
<journal>Biometrics Bulletin,</journal>
<pages>1--80</pages>
<contexts>
<context position="26379" citStr="Wilcoxon, 1945" startWordPosition="4193" endWordPosition="4194">substantially. AmWN achieves a much higher recall than WordNet. Recall increases relatively by 26% over validated WordNet, and by 54% over the no-rules baseline. Furthermore, precision drops only slightly, by 6%, compared to validated WordNet. This shows that argument mapping increases WordNet’s graph connectivity, while our rulevalidation method maintains almost the same precision for many more generated rules. The improvement in overall F1 performance is statistically significant compared to all other configurations, according to the two-sided Wilcoxon signed rank test at the level of 0.01 (Wilcoxon, 1945). 5.2 Error Analysis We manually analyzed the reasons for false positives (incorrect extractions) and false negatives (missed extractions) of AmWN by sampling 300 extractions of each type. From the false positives analysis (Table 4) we see that practically all generated rules are correct (99.4%), that is, they would be valid in some contexts. Almost all errors come from matching errors (including parse errors) and context mismatches, due to our limited IE implementation. The only two incorrect rules sampled were due to an incorrect Nomlex entry and a WordNet synset that should have been split </context>
</contexts>
<marker>Wilcoxon, 1945</marker>
<rawString>Frank Wilcoxon. 1945. Individual comparisons by ranking methods. Biometrics Bulletin, 1:80–83.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>