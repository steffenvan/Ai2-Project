<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<sectionHeader confidence="0.7623136" genericHeader="method">
RESOLVING LEXICAL AMBIGUITY IN A
DETERMINISTIC PARSER
Robert Milne
Intelligent Applications
10 Charlotte Square
</sectionHeader>
<bodyText confidence="0.937396285714286">
Edinburgh EH2 4DR Scotland
Lexical ambiguity and especially part-of-speech ambiguity is the source of much non-determinism in
parsing. As a result, the resolution of lexical ambiguity presents deterministic parsing with a major test.
If deterministic parsing is to be viable, it must be shown that lexical ambiguity can be resolved easily
deterministically. In this paper, it is shown that Marcus&apos;s &amp;quot;diagnostics&amp;quot; can be handled without any
mechanisms beyond what is required to parse grammatical sentences and reject ungrammatical
sentences. It is also shown that many other classes of ambiguity can be easily resolved as well.
</bodyText>
<sectionHeader confidence="0.997765" genericHeader="method">
1 INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999972465517241">
Lexical ambiguity, and especially part-of-speech ambigu-
ity, is the source of much non-determinism in parsing.
As a result, the resolution of lexical ambiguity presents
deterministic parsing (Marcus 1980) with a major test. If
deterministic parsing is to be viable, it should be shown
that lexical ambiguity can be resolved deterministically
for many situations in which people do not have trouble.
In this paper, it is shown that Marcus&apos;s &amp;quot;diagnostics&amp;quot; can
be handled without any mechanisms beyond what is
required to parse grammatical sentences and reject
ungrammatical sentences and that many other classes of
ambiguity can be easily resolved as well. This result is
possible because of the constraints on English from word
order and number agreement.
Although many high-level constituents can be
&amp;quot;moved&amp;quot; in English, the lower-level structure of some
constituents is relatively fixed. For example, after a
determiner, one expects a noun rather than a verb. In
this paper we also wish to ask, &amp;quot;How might this low-level
fixed order assist in the resolution of ambiguity?&amp;quot; We
will not give a definite answer to this question, but will
see that it is extremely useful in the resolution of ambigu-
ity.
The examples of ambiguity shown in this paper seem
to cause no apparent problems to a person reading them.
That is, all of these examples read easily and certainly do
not exhibit the garden path effect, except, of course, the
examples that are intended to be difficult. If a parser is
to be psychologically plausible, then it is desirable that it
handle these examples in such a way as to explain why
people have no apparent difficulty with most sentences,
despite the inherent ambiguity in them.
In parsing English, one of the major causes of non-
determinism is part-of-speech ambiguity. If a word can
be two parts of speech, then a non-deterministic parser
may have to explore both possibilities. If one claims to
be able to parse English deterministically, then the reso-
lution of part-of-speech ambiguity is a very important
area.
It should be noted that a non-deterministic parser does
not need to tackle the problem of local part-of-speech
ambiguity. If it should make an error, then it can back-
track and correct it. Alternatively, it could maintain all
possible parses at once and throw some of them away.
In deterministic parsing we are not allowed to use either
backtracking or parallelism. Although this problem has
been investigated for many non-deterministic parsers, it
has not been the critical problem that it is for determinis-
tic parsing. To handle ambiguity deterministically, we
must never make an error. As a result, our methods of
disambiguation must be reliable. We will see that many
cases of ambiguity can be resolved using standard tech-
niques that have been applied to non-deterministic
parsers.
If it is possible to handle all the examples of local
ambiguity presented here, with no additional mechanism,
device or feature than is needed for ordinary sentence
parsing, then our goal above can be considered met. One
</bodyText>
<footnote confidence="0.5769395">
.Copyright1986 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided that
the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page. To copy
otherwise, or to republish, requires a fee and/or specific permission.
0362-613X/86/ 010001-12$ 03.00
</footnote>
<note confidence="0.6054665">
Computational Linguistics, Volume 12, Number 1, January-March 1986 1
Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser
</note>
<bodyText confidence="0.999944625">
possible explanation for the fact that people do not
notice local ambiguities may be that there is no special
mechanism needed for them, so that nothing differing
from normal parsing is necessary.
Conversely, if it is necessary to add special mech-
anisms and routines to the parser just to handle these
examples of ambiguity, then this will not explain how
people can understand these examples so well and it can
be considered a weakness in the model.
To say part-of-speech ambiguity can be handled
deterministically but with the use of special mechanisms
would be no surprise and not very important. To say one
can handle part-of-speech ambiguity deterministically
with no special mechanisms is a more significant claim.
In this paper it is indeed suggested that many cases of
part-of-speech ambiguity can be handled by the parser
with no special mechanisms.
This paper is a summary of a section of the author&apos;s
Ph.D. thesis (Milne 1983) with the same title and
describes work done at the University of Edinburgh.
That thesis presents ROBIE, a deterministic parser that is
able to resolve lexical ambiguities and that is fully imple-
mented in PROLOG. ROME has two lookahead buffers
and does not use Marcus&apos;s Attention Shift mechanism.
This means that ROBIE scans the current token and one
more of lookahead. PARSIFAL scanned the current
token and two lookahead cells. In this paper, only local
ambiguities are addressed, that is, ambiguities that can be
resolved within the sentence. Global ambiguities, which
require context to resolve, are not discussed. For this
paper, it is assumed that the reader is familiar with deter-
ministic parsing and no other understanding of specific
parsing mechanisms is assumed.
In the rest of this paper, we look at lexical ambiguity
from simple examples to more complex ones. We start
with how words are defined within the parser to be
ambiguous and how the morphology can be used to
resolve ambiguities. Next we look at how word order
and finally various types of agreement can be used to
resolve most remaining ambiguities.
</bodyText>
<sectionHeader confidence="0.987757" genericHeader="method">
2 SYNTACTIC CONTEXT
</sectionHeader>
<subsectionHeader confidence="0.845636">
2.1 WORD DATA STRUCTURES
</subsectionHeader>
<bodyText confidence="0.999995756756757">
As a first approach to handling ambiguity, it was asked,
&amp;quot;If we construct a compound lexical entry for each word
composed of the features of each part of speech the word
can have and make no alterations to the grammar, how
wide a coverage of examples will we get?&amp;quot;
This approach was used by Winograd (1972) and was
found to be very effective for the following reason. Each
word has all the possible relevant features for it. There-
fore, the test will succeed for each possible part of speech
with which a word can be used. In this way, all applica-
ble rules will match. It may be that often only one rule
will match, or that the first rule tried is the correct rule.
The question is, how often will the rule that matches be
the correct rule?
All words in ROME are defined in the syntactic
dictionaries. Each word has a compound lexical entry
incorporating all the features for all the possible parts of
speech the word could have. This is exactly as was done
by Winograd (1972). For example, block is defined as a
noun and a verb, can is defined as a noun, auxiliary verb,
and verb, and hit is defined as a noun and a verb. The
features for each of these parts of speech are kept in the
dictionary and, when the word is looked up, they are
returned as a single ordered list of features. These
features are sub-grouped according to the part of speech
they are associated with. Hence, when the word block is
looked up, the result returned is both the noun and the
verb definition. In this way, all possibilities are returned.
In the English language, most words can have several
parts of speech. This fact must be reflected in a parser of
English and we do this with the multiple meanings above.
When the parser has enough information to decide which
is the correct part of speech, it ignores (removes) the
other possibilities. In this way, we have not built struc-
ture that is later thrown away. Although some may argue
that this is a form of parallelism, it seems necessary since
it reflects the inherent parallelism of language.
</bodyText>
<subsectionHeader confidence="0.998257">
2.2 MORPHOLOGY
</subsectionHeader>
<bodyText confidence="0.999764541666667">
The first part of the disambiguation process takes place
in the morphology. When ROBIE identifies a word that
has a morphological ending, the morphology must adjust
the features of the word. For example, when blocked is
identified, the feature &amp;quot;ed&amp;quot; must be added to the list of
features for block. At the same time, a portion of the
disambiguation takes place. If block is defined as both a
noun and a verb, then blocked is not a noun. The
morphology causes some features to be added, such as
&amp;quot;ed, past&amp;quot; and some features to be removed such as
&amp;quot;tenseless.&amp;quot; As features that are no longer applicable are
removed, so also are parts of speech and their associated
features that are no longer applicable. For blocked, the
features &amp;quot;noun, ns, n3p&amp;quot; will be removed and the
features &amp;quot;adjective, ed, past&amp;quot; will be added.
The morphology will identify words such as adverbs,
adjectives, and verbs in a similar way. The morphology
used is very similar to that of Winograd (1972) and of
Dewar, Bratley, and Thorne (1969); the part-of-speech
additions and deletions are taken from Marcus (1980).
Although this technique may seem obvious, it is included
to point out that a majority of the occurrences of part-of-
speech ambiguity can be resolved or reduced on the basis
of the morphology alone.
</bodyText>
<subsectionHeader confidence="0.993688">
2.3 DISAMBIGUATION
</subsectionHeader>
<bodyText confidence="0.999948833333333">
Now that we have allowed words to have multiple parts
of speech and the morphology can be used to trim some
of the ambiguity, we need a simple technique for disam-
biguating words to a single part of speech. Again, refer-
ring to Occam&apos;s Razor, what is preferable is a simple and
general technique for all types of disambiguation.
</bodyText>
<page confidence="0.842649">
2 Computational Linguistics, Volume 12, Number 1, January-March 1986
</page>
<subsectionHeader confidence="0.288543">
Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser
</subsectionHeader>
<bodyText confidence="0.999917413793104">
In ROBIE each rule matches the features of one or two
buffer cells. (The word buffer will be used interchangea-
bly with cell. That is, buffer and cell are the same
concept.) If the word block is in the first buffer cell, then
a pattern [noun] or a pattern [verb] will match. These
patterns do not relate to the other possible definitions of
a word. If a rule pattern has matched on the feature
&amp;quot;noun&amp;quot; in the first buffer cell, then ROBIE assumes that
this word is a noun. It would then be appropriate to
disambiguate the word as a noun. This is exactly as in
Winograd (1972).
In a non-deterministic parser, it is not essential to find
the correct rule first. If the parser runs an incorrect rule,
the parser may backtrack and change the category
assignment. But in a deterministic parser, there will
never be any backtracking, and this solution cannot be
used.
Since ROME does not backtrack, disambiguating the
word when the pattern matches will always result in the
same disambiguation as if the word were disambiguated
in the grammar rule. Once a rule runs assuming a buffer
contains a certain part of speech, it must be used as such
in the parser. The general disambiguation scheme is: if a
full pattern matches a word as a certain part of speech,
then it is disambiguated as that part of speech.
The compound lexical entries and pattern-matching
disambiguation alone will handle many examples of
ambiguity. In the rest of this paper we see just what this
can do for us.
</bodyText>
<subsectionHeader confidence="0.99805">
2.4 AN EXAMPLE
</subsectionHeader>
<bodyText confidence="0.990745142857143">
Given the above mechanisms — multiple definition and
disambiguation by the pattern matching, let us see how a
few simple examples are handled. Consider:
(1) The falling block needs painting.
We will look only at the words falling and block in this
example. The word falling is defined as a verb and an
adjective in the dictionary and block is defined as a noun
and a verb.
While parsing this example, after the word the has
initiated an NP and been attached to it as a determiner,
the rules to parse adjectives are activated. The rule
ADJECTIVE has the pattern [adj], and matches the word
falling. Falling is then attached and disambiguated as an
adjective. Recognition of falling as a verb does not
occur. As there are no more adjectives, ROBIE will acti-
vate the rules to parse the headnoun. (ROBIE&apos;s grammar
assumes that all words between the first noun and the
head noun of an NP are nouns; see section 2.6.) The rule
NOUN with the pattern [noun] will match on the word
block, and it will be attached as a noun. Hence block will
also be disambiguated without the verb use being consid-
ered by ROME.
Other ambiguities inside the noun phrase will be
handled in a similar way. This approach will usually
cover the situation of singular head nouns,
verb/adjective ambiguity and many other pre-nominal
ambiguities. This works because the noun phrase has a
very strict word order. When an ambiguous word is
found, only one of its meanings will be appropriate to the
word order of the noun phrase at that point. This
approach can be thought of as an extension of the basic
approach of the Harvard Predictive Analyzer (Kuno
1965).
This strategy will also often disambiguate main verbs.
For example, consider the following sentences:
</bodyText>
<listItem confidence="0.994001333333333">
(2) Tom hit Mary.
(3) Tom will hit Mary.
(4) The will gave the money to Mary.
</listItem>
<bodyText confidence="0.999813782608696">
In (2), hit is the main verb. In the dictionary, hit is
also defined as a noun, (as in card playing). The parser
will attach Tom as the subject of the sentence and then
activate the rules for the main verb. Since hit has the
feature &amp;quot;verb&amp;quot;, it will match that rule and be attached
and disambiguated as a verb. Again, other possible parts
of speech are not considered.
The word will could be a noun or a modal as sentences
(3) and (4) demonstrate. In (3), will cannot be part of
the headnoun with Tom, so the NP will be finished as
above. The rules for the auxiliary will then be activated
and the word will then matches the pattern [modal] and
is attached to the AUX.
In (4), the word will is used as a noun. Since it
follows the determiner, the rules for nouns will be acti-
vated. The word will then matches the pattern [noun]
and attaches to the NP as a noun.
The same approach will also disambiguate stop and run
in the following sentence. Since stop is sentence initial
and can be a tenseless verb, the rule IMPERATIVE will
match, and it will be disambiguated as a verb. The word
run, which can be a noun or a verb, will be handled as
will in (4).
</bodyText>
<listItem confidence="0.832768">
(5) Stop the run.
</listItem>
<subsectionHeader confidence="0.991168">
2.5 THE WORD TO
</subsectionHeader>
<bodyText confidence="0.999449333333333">
Now let us consider a more difficult example, the word
to. To is defined as an auxiliary verb and a preposition in
ROBIE, as illustrated by these sentences:
</bodyText>
<listItem confidence="0.9206225">
(6) I want to kiss you.
(7) I will go to the show with you.
</listItem>
<bodyText confidence="0.9633428">
In (6), to is the infinitive auxiliary, while in (7) to is a
preposition. This analysis is based on that of Marcus
(1980:118). Our two buffer cell lookahead is sufficient
to disambiguate these examples.
The buffer patterns for the above sentences are:
</bodyText>
<equation confidence="0.304815">
[to&amp;tenseless] -* embedded VP
[to&amp;ngstart] PP
</equation>
<bodyText confidence="0.663251636363636">
By looking at the following word, to can be disambigu-
ated. In (7), the word the cannot be a tenseless verb, so
the first pattern does not match. In (6), the second buff-
Computational Linguistics, Volume 12, Number 1, January-March 1986 3
Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser
er does not have the feature &amp;quot;ngstart&amp;quot;, so the rule doesn&apos;t
match.
However, the above patterns will accept ungrammat-
ical sentences. To reject ungrammatical sentences, we
can use verb subcategorisation as a supplement to the
above rules. One cannot say:
</bodyText>
<listItem confidence="0.9884145">
(8) *I want to the school with you.
(9) *I will hit to wash you.
</listItem>
<bodyText confidence="0.971093">
In English, only certain verbs can take infinitive
complements. To can only be used as an auxiliary verb
starting a VP when the verb can take an infinitive
complement. Hence, by activating the rules to handle the
VP usage only when the infinitive is allowed, the problem
is partly reduced. Also by classifying the verb for PPs
with the preposition to, the problem is simplified. This is
merely taking advantage of subcategorisation in verb
phrases. Taking advantage of this subcategorisation
greatly reduces, but does not eliminate, the possible
conflict.
We have seen what to do if the verb will only accept a
toPP or a VP. The final difficult situation arises whenev-
er the following three conditions are true:
</bodyText>
<listItem confidence="0.99956375">
• the verb will accept a toPP and a toVP,
• the item in the second buffer has the features
&amp;quot;tenseless&amp;quot; and &amp;quot;ngstart&amp;quot; and,
• the toPP is a required modifier of the verb.
</listItem>
<bodyText confidence="0.9997718">
Although this situation rarely arises, the above rule will
make the wrong decision if the ambiguous word is being
used as a noun. In this situation, ROBIE will make the
wrong decision, and has no capability to better decide.
By default, the principles of Right Association and Mini-
mal Attachment apply as discussed in Frazier and Fodor
(1978).
A free text analysis done on a cover story in TIME
magazine (1978) resulted in 55 occurrences of the word
to. The two rules mentioned above in conjunction with
verb subcategorisation gave the correct interpretation of
all of these. These rules were also checked on the
MECHO corpus (Milne 1983) and the ASHOK corpus
(Martin, Church, and Patil 1981). There were no
violations of these rules in either of these.
</bodyText>
<subsectionHeader confidence="0.999359">
2.6 ADJECTIVE/NOUN AND NOUN/NOUN AMBIGUITY
</subsectionHeader>
<bodyText confidence="0.987627714285714">
Adjective/noun ambiguity is beyond the present scope of
this research and is handled in a simple-minded way. If
the word following the ambiguous adjective/noun word
can be a noun, then the ambiguous word is used as an
adjective. In other words, all conflicts are resolved in
favour of the adjective usage. This problem arises in
these examples:
</bodyText>
<listItem confidence="0.967618">
(10) The plane is inclined at an angle of 30 degrees
above the horizontal.
(11) A block rests on a smooth horizontal table.
</listItem>
<bodyText confidence="0.999900166666667">
In (10), horizontal is a noun, while in (11), it is an
adjective. The above algorithm handles these cases.
This approach takes advantage of the lookahead of the
deterministic parser. A word should be used as an adjec-
tive if the following word can be an adjective or a noun.
However, this approach would fail on examples such as:
</bodyText>
<listItem confidence="0.9497265">
(12) The old can get in for half price.
(13) The large student residence blocks my view.
</listItem>
<subsectionHeader confidence="0.990574">
2.7 WHY DO THESE TECHNIQUES WORK?
</subsectionHeader>
<bodyText confidence="0.99999288">
In this section we have seen many examples of the reso-
lution of ambiguity. To handle these examples, we mere-
ly constructed a compound lexical entry for each word,
composed of the features of each part of speech the word
could be and allowed the pattern matching to perform
the disambiguation. This technique has been used by
Winograd (1972). Why does this work so well?
English has a fairly strict structural order for all the
examples presented here. Because of this, in each exam-
ple we have seen, the use of the word as a different part
of speech would be ungrammatical. Although these tech-
niques have been used for non-deterministic parsers,
their effectiveness has not been investigated for a deter-
ministic parser.
Most ambiguities are not recognised by people
because only one of the alternatives is grammatical. In
many situations, when fixed constituent structure is taken
into account, other uses of an ambiguous word are not
possible and probably not even recognised. Since fixed
constituent structure rules out most alternatives, we have
been able to handle the examples in this paper without
any special mechanisms. In the introduction to this
paper, it was stated that a clean and simple method of
handling ambiguity was desired. I feel that this goal has
been met for these examples.
</bodyText>
<sectionHeader confidence="0.992612" genericHeader="method">
3 THE ROLE OF AGREEMENT IN HANDLING AMBIGUITY
</sectionHeader>
<bodyText confidence="0.9989572">
Using the simple techniques presented in the last
sections, we can handle many cases of part-of-speech
ambiguity, but there are many examples we cannot
resolve. For example, the second of each pair of
sentences below would be disambiguated incorrectly.
</bodyText>
<listItem confidence="0.993240333333333">
(14) I know that boy is bad.
(15) I know that boys are bad.
(16) What boy did it?
(17) What boys do is not my business.
(18) The trash can be smelly.
(19) The trash can was smelly.
</listItem>
<bodyText confidence="0.998083">
Many people wonder what role person/number codes
and the relatively rigid constituent structure in the verb
group play in English. In this section, we will explore
their role by attempting to answer the question, &amp;quot;What
use is the fixed structure of the verb group and
person/number codes?&amp;quot;
</bodyText>
<page confidence="0.611751">
4 Computational Linguistics, Volume 12, Number 1, January-March 1986
</page>
<figure confidence="0.466483">
Robert MiMe Resolving Lexical Ambiguity in a Deterministic Parser
</figure>
<subsectionHeader confidence="0.997845">
3.1 UNGRAMMATICAL SENTENCES
</subsectionHeader>
<bodyText confidence="0.999955857142857">
Before we proceed, let us look at an assumption Marcus
made in his parser, that it would be given only grammat-
ical sentences. This assumption makes life easy for
someone writing a grammar, since there is no need to
worry about grammatical checking. Hence no provision
was made for ungrammatical sentences and the original
parser accepted such examples as:
</bodyText>
<listItem confidence="0.997648666666667">
(20) *A blocks are red.
(21) *The boy hit the girl the boy the girl.
(22) *Are the boy run?
</listItem>
<bodyText confidence="0.999634">
This simplification causes no problems in most
sentences, but can lead to trouble in more difficult exam-
ples. If the parser&apos;s grammar is loosely formulated
because it assumes it will be given grammatical examples
only, then ungrammatical sentences may be accepted. If
the syntactic analysis accepts ungrammatical sentences as
grammatical, then it is making an error. Using grammat-
ical constraints actually helps parsing efficiency and
disambiguation. In the next sections we look at the
consequences of this assumption as well as those of
rejecting ungrammatical sentences.
</bodyText>
<subsectionHeader confidence="0.998193">
3.2 SUBJECT/VERB AGREEMENT
</subsectionHeader>
<bodyText confidence="0.999326166666667">
We know that the verb group has a complicated but rela-
tively fixed constituent structure. Although verbals have
many forms, they must be mixed in a certain rigid order.
We also know that the first finite verbal element must
agree with the subject in person and number. That is,
one cannot say:
</bodyText>
<listItem confidence="0.99771175">
(23) *The boy are run.
(24) *The boy will had been run.
(25) *The boys had are red.
etc.
</listItem>
<bodyText confidence="0.999625533333333">
While Marcus&apos;s parser enforced these observations to
some extent, he did not follow them throughout his
parser. We want to enforce this agreement throughout
ROBIE. Checking the finite or main verb, to be sure that
it agrees in number with the subject, will lead to the
rejection of the above examples. This was done by
adding the agreement requirement into the pattern for
each relevant rule as will be explained later.
Buffers 1 and 2 must agree before a rule relating the
subject and verb can match. This check looks at the
number code of the NP and the person/number code of
the verb and checks whether they agree. The routine for
subject/verb agreement is very general and is used by all
the subject/verb rules. The routine can only check the
grammatical features of the buffers.
</bodyText>
<subsectionHeader confidence="0.948664">
3.3 MARCUS&apos;S DIAGNOSTICS
</subsectionHeader>
<bodyText confidence="0.951977928571429">
Marcus (1980) did handle some part-of-speech ambigui-
ties. The words to, what, which, that, and have could all
be used as several parts of speech. For each of these
words he also used a Diagnostic rule. These Diagnostic
rules matched when the word they were to diagnose
arrived in the first buffer position and the appropriate
packets were active. Each diagnostic would examine the
features of the three buffers cells and the contents of the
Active Node Stack. Once the diagnostic decided which
part of speech the word was being used as, it either
added the appropriate features, or explicitly ran a gram-
mar rule. Marcus did not give each word a compound
lexical entry as we have done here.
Most of the grammar rules in his parser were simple
and elegant, but the diagnostics tended to be very
complex and contained many conditionals. In some cases
they also seemed rather ad hoc and did not meet the goal
of a simple, elegant method of handling ambiguity.
For example, consider the THAT-DIAGNOSTIC:
[that][np] in the Packet CPOOL (Clause pool of rules)
&amp;quot;If there is no determiner of second
and there is not a qp of second
and the nbar of 2nd is none of massn,npl
and 2nd is not-modifiable
then attach as det
else if c is nbar
then label 1st pronoun, relative pronoun
else label 1st complementiser.&amp;quot;
</bodyText>
<equation confidence="0.443688">
(Marcus 1980:291)
</equation>
<bodyText confidence="0.9993404">
Notice that if the word that were to be used as a deter-
miner, then it would be attached after the NP was built!
This is his primary rule for disambiguating the word that.
Marcus&apos;s parser also had three other rules to handle
different cases.
It seems that these rules did not &amp;quot;elegantly capture
generalisations&amp;quot; as did the rest of his parser. I consider
these rules undesirable and feel that they should be
corrected to comply with my criteria for simple and
elegant techniques in resolving ambiguity. I wanted a
method that used no special mechanism, or routine, other
than that needed to parse grammatical sentences. These
diagnostics are certainly special mechanisms and do not
meet this goal. Can we cover the same examples in a
more simple and principled way?
In this section, we look at each of these diagnostics in
turn and show how they have been replaced in the newer
model. We also look at a few other examples of ambigui-
ty which Marcus did not handle, but are related to our
discussion here.
</bodyText>
<subsectionHeader confidence="0.82099">
3.4 HANDLING THE WORD TO
</subsectionHeader>
<bodyText confidence="0.99999325">
The handling of to by Marcus&apos;s diagnostic can be
replaced by the method outlined in Section 2.5. This
method was motivated to handle grammatical sentences
and meets our criterion for a simple approach.
</bodyText>
<subsectionHeader confidence="0.804076">
3.5 HANDLING WHAT AND WHICH
</subsectionHeader>
<bodyText confidence="0.992972">
For both what and which, the ambiguity lies between a
relative pronoun and a determiner. The following exam-
ples show various uses of both words:
</bodyText>
<table confidence="0.487332">
Computational Linguistics, Volume 12, Number 1, January-March 1986 5
Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser
</table>
<listItem confidence="0.9879458">
(26) Which boy wants a fish? det
(27) Which boys want fish? det
(28) The river which I saw has many fish. rel. pron.
(29) What boy wants a fish? det
(30) What boys want is fish. rel. pron.
</listItem>
<bodyText confidence="0.999484">
There is some debate about the part of speech to be
assigned the word which. Some linguists consider it to be
a quantifier (Chomsky 1965), while others consider it to
be a determiner (Akmajian and Heny 1975, Chapter 8).
We shall adopt the determiner analysis, making the prob-
lems for what and which similar.
To determine the correct part of speech for these two
words, Marcus (1980:286) used the following diagnos-
tics:
</bodyText>
<equation confidence="0.595531">
[which] -■ in the packet CPOOL
</equation>
<bodyText confidence="0.99491434375">
&amp;quot;If the NP above Current Node is not modified
then label 1st pronoun, relative pronoun
else label 1st quant,ngstart,ns,wh,npl.&amp;quot;
[what][t] in the packet NPOOL
&amp;quot;If 2nd is ngstart and 2nd is not det
then label 1st det,ns,npl,n3p,wh;
activate parse det
else label 1st pronoun,relpron,wh.&amp;quot;
These diagnostics would make the word in question a
relative pronoun if it occurred after a headnoun, or a
determiner if the word occurred at the start of a possible
noun phrase.
If we follow the approach in the last section, and give
each word a compound lexical entry composed of the
determiner and relative pronoun features, we find that
these words are always made determiners unless they
occur immediately after a headnoun. In other words, the
which examples are all parsed correctly, but (30) is
parsed incorrectly. This happens because the determiner
rule will always try to match before the rule for WH ques-
tions can take effect. This simple step gives the correct
analysis if the ambiguous word is to be a determiner, but
will still err on (30).
The rule to parse a relative pronoun and start a rela-
tive clause is active only after the headnoun has been
found. At this time, the rule for determiners is not
active. Therefore, if the word what or which is present
after a headnoun, the only rule that can match is the rule
to use it as a relative pronoun, and it will be used as a
relative pronoun. We have resolved the simple case of
what as a relative pronoun using only the simple tech-
niques of the last section. For these sentences
</bodyText>
<listItem confidence="0.990408">
(31) What block is red?
(32) Which boy hit her?
(33) Which is the right one?
</listItem>
<bodyText confidence="0.999238421052632">
ROBIE produces the correct analysis, but still errs on
(30). This error is because what is being used as a rela-
tive pronoun but does not follow a headnoun. Without
any additional changes to the parser, we get two things.
Firstly, if the word occurs after the headnoun, then the
NP-COMPLETE packet rules are active, and it will be a
relative pronoun. In fact, since relative clauses can occur
only after the end of an NP, this correctly resolves the
relative pronoun uses. If the word occurs at the start of
an NP, then it will be made a determiner.
This approach has exactly the same effect and cover-
age as did Marcus&apos;s diagnostics, but we have not needed
any special rules to implement it. It will now provide the
correct interpretation for which, but will make some
errors for the word what. Marcus&apos;s what-diagnostic will
treat what as a determiner whenever the item in the
second buffer could start a NP. This is usually correct,
but what will be treated as a determiner in all of the
following:
</bodyText>
<listItem confidence="0.999491">
(34) What boys want is fish.
(35) What blocks the road?
(36) What climbs trees?
(37) What boys did you see?
(38) What blocks are in the road?
(39) What climbs did you do?
</listItem>
<bodyText confidence="0.99978672972973">
In this paper, we are adopting the following analysis
for WH clefts such as (34). The initial WH word, what is
a relative pronoun and attached as the WH-COMP of the
subject S node. The subject is the phrase What boys
want. The main verb of the sentence is is and the
complement fish. The exact details are not important,
only that the word what or which is a not determiner at
the start of a WH cleft.
In sentences (34-36), the word what is not used as a
determiner. In the analysis we are using, it is a relative
pronoun and is used as the WH-COMP for the S. In
sentences (37-39), the word what is used as a determiner.
Marcus (1980:286) admits that this diagnostic produces
the incorrect result in this case. His diagnostic will make
what a determiner in all of these examples, as will my
analysis.
One can also see that each of the above pairs is a pair
of potential garden path sentences. For each pair, the
two buffers contain the same words. Hence our two-buf-
fer lookahead is not sufficient to choose the correct usage
of the word what. Using only two or three buffers, there
is no way to make what a relative pronoun when the
headnoun is plural but a determiner when it is singular
for all arbitrary sentences.
With regard to the Semantic Checking Hypothesis
(Milne 1982) then, it is suggested that this decision is
based on non-syntactic information. I believe that into-
nation is critical in these examples. Unfortunately there
is insufficient experimental evidence to determine for
certain whether this is true. Finally, the problem of what
and which as sentence initials, with no noun in the second
buffer seems to arise very rarely. I have found no exam-
ples of this problem in free text analysis.
The current parser (ROBIE) cannot obtain the extra
information provided by intonation to help resolve this
case. As a result it follows Marcus&apos;s diagnostic and
makes what a determiner in each of the above cases.
</bodyText>
<page confidence="0.90147">
6 Computational Linguistics, Volume 12, Number 1, January-March 1986
</page>
<note confidence="0.378721">
Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser
</note>
<bodyText confidence="0.997456333333333">
This is because what is defined as a determiner that can
agree with either a singular noun or a plural noun, as it
was in Marcus&apos;s parser.
</bodyText>
<subsectionHeader confidence="0.973017">
3.6 HANDLING THAT
</subsectionHeader>
<bodyText confidence="0.999911555555556">
In ROBIE, that is defined as a singular determiner, a
pronoun, a relative pronoun, and a complementiser.
Marcus had four diagnostics to handle the word that. We
have seen one of these at the start of this section. In this
sub-section we see how these four diagnostics can be
replaced in a simple way. Let us consider how to handle
the uses of that one at a time.
Firstly, as a determiner The following sentences illus-
trate the problem in identifying this usage.
</bodyText>
<equation confidence="0.9599775">
(40) I know that boy should do it.
(41) I know that boys should do it.
</equation>
<bodyText confidence="0.9753325">
Marcus assumed that PARSIFAL would be given only
grammatical sentences to parse. If determiner/number
agreement is not given to a parser, then it will, incorrect-
ly, make that a determiner in (41), producing the wrong
analysis. The way to prevent this is to enforce number
agreement in the rule DETERMINER by insisting that the
determiner agree with the noun in number. The deter-
miner usage will be grammatical only when the headnoun
has the same number. If we make this a condition for the
rule to match, then that will not be made a determiner in
(41) and ROBIE will get the correct parse.
For this case, the agreement check would make sure
that one of the following patterns match:
[det,ns] [noun,ns]
[det,npl] [noun,npl]
The above two cases are handled properly because
number agreement blocks the interpretation of the (41)
as a determiner. This approach leads to the correct pref-
erence, when there is an ambiguity and accounts for the
difficulty in (42) versus (43):
(42) That deer ate everything in my garden surprised
me.
(43) That deer ate everything in my garden last night.
The second experiment in Milne (1983), showed that
(42) is a garden path sentence, while (43) is not. In both
sentences, it is believed the subject uses the word that as
a determiner Deer is both singular and plural, so it fits
the above rule. In (42), that must be used as a complem-
entiser to make the sentence grammatical. The approach
outlined above will use that as a determiner in an ambig-
uous case such as this.
These two simple techniques, word order and agree-
ment, are sufficient to handle all the examples we have
just presented. In addition, free text analysis has shown
no violations to this approach (Milne 1983). These tech-
niques provide the same coverage as Marcus&apos;s diagnostic,
with the added bonus that the determiner is attached
before the NP is built.
That can only be a complementiser when a that S- is
expected. Hence the rules using that to start an embed-
ded sentence are only activated when the verb has the
feature THAT-COMP. The rules in THAT-COMP will fire
when that is followed by something that can start an NP.
This ensures that the S- will have a subject and means
that that will be taken as a pronoun in the following
sentences:
</bodyText>
<listItem confidence="0.570393333333333">
(44) I know that hit Mary.
(45) I know that will be true.
but it will be taken as a complementiser in these
sentences:
(46) I know that boys are mean.
(47) I know that Tom will hit Mary.
</listItem>
<bodyText confidence="0.947232722222222">
It seems that, unless the S- has a subject, the pronoun
use of that is preferred. Otherwise one would have a
complementiser followed by a trace, rather than a
unmarked complementiser, followed by a pronoun. This
rule provides more complete coverage than Marcus&apos;s
diagnostic since it examines the second buffer.
The rule to handle pronouns in general is of low prior-
ity and will only fire after all other uses have failed to
match. That is treated in the same way.
That will be identified as a relative pronoun only if it
occurs after a headnoun and the packet NP-COMPLETE
is active. This situation will be handled in the same
manner as the usual relative clause rules and will then
cover:
48) I know the boy that you saw.
49) I know the boy that hit you.
The most difficult case for that is when the verb is
subcategorised:
</bodyText>
<sectionHeader confidence="0.469488" genericHeader="method">
V NP S-
</sectionHeader>
<bodyText confidence="0.999066625">
That is, it can take an NP subject, followed by a that S-.
For these examples, ROBIE may have to decide if the
series of words following that is a relative clause or an
embedded sentence.
In the following sentences, the lookahead would have
to be more than three buffers. (Brackets indicate words
in the buffers. The last word is the disambiguating
word.)
</bodyText>
<listItem confidence="0.85244">
(50) I told the girl [that][the][boy] hit the story
(51) I told the girl [that][theilboy] will kiss her
</listItem>
<bodyText confidence="0.9380342">
It can be seen that in these sentences the disambiguat-
ing word is outside our three buffers. How do people
handle these, and what should our parser do? In Milne
(1983) it was shown that when the syntax could not
resolve the ambiguity with its two-buffer lookahead, the
decision of which interpretation to use might be made
using non-syntactic information. It was also stated that if
context can affect the interpretation of the sentence, then
non-syntactic information is being used to select the
Computational Linguistics, Volume 12, Number 1, January-March 1986 7
Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser
interpretation. The reader can experiment for himself
and see that context does affect the interpretation of
these sentences. Therefore it is predicted that non-syn-
tactic information is being used to interpret these
sentences, and that this problem should be resolved not
on a semantic basis but on a non-syntactic one.
This explains why some of these examples cause diffi-
culty and others do not. The psychological evidence
from cases using that is scant, and I feel no conclusions
can be reached here. My theory predicts that context
will strongly affect these examples and, if they are
strongly biased to the incorrect reading, a garden path
should result.
One well-known example in this area is (52):
</bodyText>
<listItem confidence="0.957951666666667">
(52) I told the girl that I liked the story.
(53) I told the girl whom I liked the story.
(54) I told the girl the story that I liked.
</listItem>
<bodyText confidence="0.999937">
These examples were tested in Milne (1983). The results
suggested that (52) was read faster than the other two
examples. Many of the subjects were questioned
informally after the experiment about their interpretation
of the sentence. All reported only one meaning; the S-
reading. None of the subjects said that they noticed the
relative clause reading, hence the result. The experiment
however, was not designed formally to distinguish these.
To handle the examples we have seen in this section,
Marcus had four diagnostics, one of which was very
complicated. I have just shown how to handle all four
cases of that without any special rules, merely substitut-
ing enforced agreement and rejecting ungrammatical
sentences.
</bodyText>
<subsectionHeader confidence="0.983322">
3.7 HANDLING THE WORD HAVE
</subsectionHeader>
<bodyText confidence="0.999959">
Let us now look at the elimination of Marcus&apos;s
HAVE-DIAGNOSTIC in relation to the use of agreement
we have been discussing in this section. The problem
with have is illustrated by the following sentences:
</bodyText>
<listItem confidence="0.989383">
(55) Have the students take the exam.
(56) Have the students taken the exam?
</listItem>
<bodyText confidence="0.9935776">
In these, we must decide if have is an auxiliary verb or a
main verb and whether the sentence is a yes-no question
or an imperative. The sentences have the same initial
string until the final morpheme on take. To handle this
case, Marcus (1980:211) used this rule:
</bodyText>
<figure confidence="0.738004">
&amp;quot;RULE HAVE-DIAG PRIORITY:5 IN SS-START
[have,tenseless][np][t]
If 2nd is ns,n3p or 3rd is tenseless
then run imperative next else
If 3rd is not verb
</figure>
<tableCaption confidence="0.338934666666667">
then run yes-no-question next
else if not sure, assume it&apos;s a y/n-q and run yes-no-
question next&amp;quot;.&amp;quot;
</tableCaption>
<bodyText confidence="0.988007666666667">
This rule seems to be necessary in order to distinguish
between the question and the imperative. If one tries to
ascertain exactly what occurs, the apparent complexity is
revealed. Note also that Marcus&apos;s rule defaults to a yes-
no question twice in this diagnostic. The following
sentences illustrate the distinction this rule makes.
</bodyText>
<listItem confidence="0.9962305">
(57) Have the boy take the exam.
(58) Have the boy taken the exam.
(59) Have the boys take the exam.
(60) Have the boys taken the exam?
</listItem>
<bodyText confidence="0.995934966666667">
It can be seen that YES-NO QUESTION should run
only when the NP following is plural and the verb has
&amp;quot;en&amp;quot; (i.e., taken). [Only (60) has a plural noun, the boys,
and the verb taken.] This can also be understood as: the
sentence is an imperative if the item in the 2nd buffer is
not plural and the verb is tenseless. Thus, the first three
examples above are Imperatives because either the noun
(boy) is singular (57 and 58) or the verb is tenseless (59).
The second part of the rule takes care of the fact that the
third buffer must contain a verb for the imperative, as
this would be the main verb of the embedded sentential
object.
Let us look more closely at the reason why only (60)
is a question. Firstly, if the sentence is a yes-no question,
then aux-inversion must occur. When this happens, Have
will be adjacent to the verb that was in the third buffer.
In order for ROBIE to continue, the verb must have an
&amp;quot;en&amp;quot; ending, or have and the next verb will not agree in
aspect. This is the basis for discrimination in the earlier
examples (57-60).
Secondly, in (57) and (58), the noun phrases are
singular and both sentences are imperatives. Had the
sentence been a yes-no question, have would need to
agree with the subject, which must then be plural.
Hence, in effect, Marcus&apos;s rule checks for number
agreement between the subject and verb, and checks that
the fixed order of the verb group is obeyed. Let us now
look at other situations where this is necessary.
PARSIFAL would accept the following ungrammatical
strings:
</bodyText>
<listItem confidence="0.99868925">
(61) *Are the boy running?
(62) *Has the boys run?
(63) *Has the boy kissing?
(64) *Has the boy kiss?
</listItem>
<bodyText confidence="0.9980755">
For a yes-no question, the inverted auxiliary must
agree with the verb after it has been inverted. To stop
these ungrammatical constructions, we must enforce verb
agreement. The pattern for the rule YES-NO QUESTION
should be:
[auxverb][np][verb], agree (auxverb,verb),agree (verb ,np) .
This constraint enforces agreement of the verb and
auxiliary verb and the subject and verb. Again this check
is based only on the linguistic features of the buffers.
Such a constraint effectively blocks the ungrammatical
constructions. (The parser will fail if the auxiliary has
been inverted, since the auxiliary will not be parsed.)
Also the subject NP must agree with the auxiliary verb,
so we can also add &amp;quot;agree(auxverb,np)&amp;quot; to the rule, as
</bodyText>
<page confidence="0.928947">
8 Computational Linguistics, Volume 12, Number 1, January-March 1986
</page>
<note confidence="0.477157">
Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser
</note>
<bodyText confidence="0.999242444444445">
we did with the HAVE-DIAGNOSTIC! So, by correcting
the yes-no question rule, the HAVE-DIAGNOSTIC is
redundant.
In this section we have seen that Marcus&apos;s
HAVE-DIAGNOSTIC can be replaced by merely exploit-
ing agreement. It should be pointed out that although
this approach has the same coverage as Marcus&apos;s diag-
nostic, it is wrong in some cases. Milne (1983) has a full
discussion.
</bodyText>
<subsectionHeader confidence="0.993261">
3.8 PLURAL HEAD NOUNS
</subsectionHeader>
<bodyText confidence="0.999954555555555">
There is a class of ambiguities that can be resolved mere-
ly by enforcing subject/verb agreement. In this section,
we see an example from the class of words with the
features noun, verb, final-s (plural). If we have two
words that can be a plural noun or a singular verb, we
can enumerate four cases. Let us look at these possibil-
ities and see that these cases can be disambiguated by
simple rules using subject/verb agreement. The follow-
ing examples illustrate all the possibilities:
</bodyText>
<listItem confidence="0.8700218">
(65) The soup pot cover handle screw is red.
(66) The soup pot cover handles screw tightly.
(67) *The soup pot cover handles screws tightly.
[68] The soup pot cover handle screws tightly.
[69] The soup pot cover handle screws are red.
</listItem>
<bodyText confidence="0.997039285714286">
Each of the words pot, cover, handle, and screw can be
either a noun or a verb. The &amp;quot;end of constituent&amp;quot; prob-
lem is to find out which word is used as the verb and
which words make up the complex headnoun. The possi-
ble distributions of the morpheme &amp;quot;s&amp;quot; among two words
gives us four cases. We deal with each of these in turn.
Case 1: In (65) each noun is singular. For this case all
ambiguous words must be nouns and part of the head-
noun. Due to subject/verb agreement, a singular noun
must match a 3rd person singular (v3s) verb, i.e, one
without the letter &amp;quot;s&amp;quot;. This case excludes that possibility
since none of the words have an &amp;quot;s&amp;quot; at the end. Hence
they must all be nouns.
Case 2: In (66) handles is a plural noun and each word
before it must be a noun. When a singular noun/verb
word follows handles, the word (screw) must be a verb
and handles is the last of the headnouns. It is not possi-
ble to use handles in this situation as a verb, and screw as
a noun because of subject/verb agreement.
Case 3: The examples in this case have two consec-
utive plural nouns as in (67), where both words have
noun/verb ambiguity. (Do not confuse plural &amp;quot;s&amp;quot; with
possessive &amp;quot;s&amp;quot;).
When the first plural is a noun, then the second one
can be a verb only if it is part of a different constituent.
Examples of this are the following. (Sentences beginning
with &amp;quot;?&amp;quot; are considered grammatical but unacceptable to
most readers.)
</bodyText>
<listItem confidence="0.978506714285714">
(70) ?The soup pot machine handles screws easily.
(71) The soup pot machine handles screw easily.
(72) Which years do you have costs figures for?
(73) Do you have a count of the number of sales
requests and the number of requests filled?
[(72) and (73) are from Martin, Church, and Patil
(1981).]
</listItem>
<bodyText confidence="0.999875404761905">
Because there is a non-plural headnoun followed by a
plural headnoun, this case is really a subset of Case 4. In
general, the problems and issues for Case 4 dominate the
resolution of this ambiguity.
Case 4: Sentences (68) and (69) both have the same
word initial string until after screws, but in (68) screws is
a verb while in (69) screws is part of the headnoun. In
this situation, where the final word in a series is plural,
each word before it must be a noun. The word itself can
be either a noun or a verb, depending on what follows.
These can be recognised as a pair of potential garden
path sentences, as discussed in Milne (1982). Therefore,
this is the case to which the Semantic Checking Hypoth-
esis applies and the predictions of Milne (1982) apply.
In that paper, the idea of potential garden path
sentences is presented. These are sentences that may or
may not lead to a garden path. Each garden path
sentence has a partner, which is similar but not a garden
path. It is proposed that the decision as to how to
resolve the ambiguity that may lead to a garden path
should be made by semantics and not by syntax. This
theory is called the Semantic Checking Hypothesis. For
full details see Milne (1983).
In this section, we have looked at resolving a simple
case of noun/verb ambiguity. In order to resolve this
ambiguity, it was necessary merely to exploit agreement
between the subject and verb in number and person.
Due to number and subject verb agreement, these
facts have a linguistic base. They rely on the fact that a
final &amp;quot;s&amp;quot; marks a plural noun but a singular verb. If the
verb is v3s (verb agrees with a 3rd person, singular
noun, as with the &amp;quot;s&amp;quot;), then the subject of the verb must
be singular, or else the sentence is ungrammatical. This
is why all the words before the v3s word must be nouns.
If any of these words were used as a verb, then subject-
verb agreement would be violated. This is why (67) is
ungrammatical. If the verb is v-3s (agrees with any
noun phrase except 3rd person, singular i.e., no &amp;quot;s&amp;quot;),
then the subject cannot be singular. (65) has no plural
subject and so cannot have a v-3s verb. In (66) handles
provides a plural subject, so screw, which is v-3s, can
agree.
</bodyText>
<subsectionHeader confidence="0.818624">
3.9 NOUN/MODAL AMBIGUITY
</subsectionHeader>
<bodyText confidence="0.999179">
We now consider noun/modal ambiguity as demon-
strated by can and will. Both can be either a noun or a
modal (i.e., could, should, would, can, will, might, etc.):
</bodyText>
<listItem confidence="0.68157975">
(74) The trash can was taken out.
(75) The trash can be taken out.
(76) The paper will was destroyed.
(77) The paper will be destroyed.
</listItem>
<table confidence="0.1802295">
Computational Linguistics, Volume 12, Number 1, January-March 1986 9
Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser
</table>
<bodyText confidence="0.983308009174312">
Each of these words is entered in the dictionary both
as a noun and a modal. Due to agreement requirements,
the modal/noun word can only be grammatically used as
a modal if the word following it is a tenseless verb, i.e.,
the pattern:
[modal][tenseless] modal usage
applies. Handling noun/modal ambiguity can be quite
easy; when the noun modal word appears in the first
buffer one merely has to look at the contents of the
second buffer to see if it contains a tenseless verb. This
can be complicated, though, if the auxiliary is inverted or
the sentence is an imperative. The following examples
show how this can arise:
(78) Let the paper will be read.
(79) Will the paper can be re-used?
In sentence (78) the fragment Let the paper implies
that will can only be used as a noun, as the sentence
already has one tensed verb. In the parser, the
noun/modal word is first encountered inside the NP
packets and the parser must decide whether to use the
word as part of the headnoun or to leave it in the buffer
to be used as a modal verb. These rules do not know
whether a verb has been found previously. Hence, not
all information from the sentence is used. If all the infor-
mation is available at the time the noun/modal ambiguity
is being resolved, these sentences would be unambiguous
and people would have no trouble reading them.
Subjects were asked to read the above examples in the
second experiment presented in Milne (1982). The
results showed convincingly that they are potential
garden paths. Many naive readers had considerably
more difficulty with them than with their more straight-
forward counterparts. This was predicted for reasons
explained below.
This result seems surprising. If the subjects used all
information available at the time the noun/modal word
was encountered, then they should have had no trouble
with these sentences. The fact that these are garden
paths indicates that the readers did not use all the infor-
mation available to them. Notice also that the ambiguity
can be reformulated as: &amp;quot;Do we have the end of a noun
phrase, or a complex headnoun?&amp;quot;
We have already seen a case where people do not
seem to use all the information available to them. In
Milne (1983), several end-of-NP problems were
presented that could lead to a garden path. In each of
these, it was shown that the ambiguity was resolved on
the basis of non-syntactic information, without regard to
the following words in the sentence. In other words, we
saw that the reader did not use all the information avail-
able. There is one crucial difference though. In the
previous cases, non-syntactic information was used
because the syntactic processor with its limited lookahead
was sometimes unable to choose the correct alternative.
In this case, the information necessary has already been
absorbed by the parser.
This suggests that the choice of alternatives is made
locally inside the NP parsing rules, without regard to
information about the type of sentence being parsed. In
other words, the two-buffer pattern applies regardless of
the rest of the sentence. This assumes that a
noun/modal word followed by a tenseless verb is being
used as a modal. This is similar to Fodor, Bever, and
Garrett&apos;s (1974) old canonical sentoid strategy: a
bottom-up analysis that took every N-V combination as a
new S. Let us look at why this might be true in the
parser.
When the parser starts to parse a NP, it creates a new
NP node and pushes it to the bottom item of the Active
Node Stack. This operation makes the NP node the
Current Active Node and parsing of the old Current
Active Node is suspended. If the parser is parsing an S
node, for example at the start of the sentence, then work
on this node will be suspended until the NP node has
been completed and dropped into the buffer.
In ROBIE, unlike PARSIFAL, the pattern matcher for
the grammar rules is allowed only to inspect the gram-
matical features of the two buffers. This means that the
parser is unable to examine the contents of the Active
Node Stack and, hence, the information that a tensed
verb has already been found is unavailable to the NP
parsing rules. This then suggests that the ambiguity will
be resolved on the basis of local information only.
It should be pointed out that although ROBIE does not
examine the Active Node Stack, the current packet
reflects its contents. For example, if the parser is parsing
the major S node, the packet SS-VP will be active, but if
the parser is parsing an embedded S node, the packet
Embedded-S will be active. This information can be
considered to provide local context to the parsing rules.
This is the same as in PARSIFAL.
This ambiguity is an end-of-NP problem and the
choice of alternatives is made on the basis of limited and
local information. This suggests that non-syntactic infor-
mation may be used to resolve the ambiguity. There is
one further possibility. The semantic choice mechanism
is attempting to find the end of an NP. So far it has
asked the question, &amp;quot;Can this item be part of the NP?&amp;quot;
However, the end-of-NP problem can be reformulated as,
&amp;quot;Is it better to use this as part of the NP, or the start of
the verb group?&amp;quot; It is conceivable that the end of NP
mechanism uses will as the start of the verb group in the
majority of occurrences, hence leading to the apparent
modal preference in these examples:
(80) The trash can hit the wall.
(81) The paper will hit the table.
Due to lack of data, it is not clear exactly what people do
in this situation and this would seem to provide an inter-
esting area for further investigation.
</bodyText>
<page confidence="0.718752">
10 Computational Linguistics, Volume 12, Number 1, January-March 1986
</page>
<figure confidence="0.3426655">
Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser
3.10 WHAT ABOUT HER
</figure>
<bodyText confidence="0.981691333333333">
Another problem is the word her, which can be used as a
pronoun or as a possessive pronoun. Note that we can
say:
</bodyText>
<listItem confidence="0.8931415">
(82) Tom kissed her.
(83) Tom kissed her sister.
</listItem>
<bodyText confidence="0.998239955555556">
Clearly in (82) her is a pronoun and in (83) her is a
possessive determiner. When multiple part-of-speech
definitions were added to ROBIE and the simple disam-
biguation method used, ROBIE always made her a posses-
sive determiner
This difficulty arose in Marcus&apos;s parser because the
rule to start a NP was ordered before the rule to parse a
pronoun. These rules were copied directly into ROBIE&apos;s
grammar. Since the word her has both the features
&amp;quot;ngstart&amp;quot; and &amp;quot;pronoun&amp;quot;, it could match both rules.
Unfortunately, as Marcus&apos;s rules were stated, it always
matched the NP starting rule, and hence was used as a
determiner by the parser. This indicates one problem
that can arise in the writing of a parser grammar.
To handle possessive determiners, PARSIFAL and
ROME have a rule with the pattern:
[poss np]
This rule will match a possessive pronoun after it has
been made into an NP. It will also match any possessive
NP, such as: the boy&apos;s or the boy&apos;s mother&apos;s. The rule then
adds the feature &amp;quot;determiner&amp;quot; to the NP, making it eligi-
ble for the NP starting rule. By degrading the possessive
NPs to determiners, both parsers easily handle examples
of left branching such as:
(84) The boy&apos;s mother&apos;s brother is his uncle.
Another problem arose in (82) because the possessive
NP rule was not sufficiently constrained. It is possible to
use her as a determiner only where the next word can be
part of a noun phrase with that determiner To enforce
this, the second buffer is checked to be certain that its
contents will take the determiner Using this approach,
her in (82) would not be converted to a possessive deter-
miner The rule DETERMINER can run only if the next
item will &amp;quot;take a determiner&amp;quot;.
This check is made by the syntactic category of the
following word, rather than by a specially marked
feature. This check could be done by having a list of all
the possible categories as the pattern of the second buff-
er. As an implementation detail, this is in the form of an
agreement check, merely to simplify this rule and to show
its generality.
The only remaining problem occurs when the verb can
take one or more objects and the item after the word her
can be either the second object, or an NP with her as a
determiner For example:
</bodyText>
<listItem confidence="0.921042666666667">
(85) I took her grapes.
(86) He saw her duck.
(87) I gave her food for the dog.
</listItem>
<bodyText confidence="0.999984518518519">
The examples presented above are all examples of
global ambiguity, which is discussed in more detail in
Milne (1983). In these cases the check of &amp;quot;Will-the next
word take a determiner?&amp;quot;, may or may not lead to the
wrong analysis. This problem also interacts with the
top-down component of verb phrase parsing and the
semantic restrictions presented by it.
The conflict between the determiner and possessive
usage can be modelled as a conflict of rule priorities. If
the possessive use is preferred, then this rule should
match first. Conversely, if the object use is preferred,
then the object rule should match first. Any error in
reading these examples would be due to one rule having
priority over the other, when the reverse should be the
case. Finally, notice that with no help from either into-
nation or context, either analysis is possible. That is,
there is not enough information in the sentence to deter-
mine a unique interpretation.
We have now shown how to replace all the diagnostics
Marcus used. In doing this, we enforced number and
verb agreement on the rules before they could run. This
was motivated to reject ungrammatical items, rather than
for the handling of ambiguity. While there are still a few
problems due to global ambiguity, the approach reported
here has the same coverage as Marcus&apos;s diagnostics, and
provides a better explanation of why people have trouble
on certain sentences.
</bodyText>
<sectionHeader confidence="0.995007" genericHeader="method">
4 POSSIBLE USES FOR AGREEMENT IN ENGLISH
</sectionHeader>
<bodyText confidence="0.9678568125">
In this paper, we have seen several occurrences of ambi-
guity, for each of which we have found a parallel situ-
ation that could lead to acceptance of ungrammatical
sentences by ROBIE. We then used person/number
codes or the fixed structure of the verb group to block
these unacceptable readings. Most of our ambiguity
problems were also handled by this method. Although
this has been used before with non-deterministic parsers,
it was not obvious that it would provide enough informa-
tion to enable deterministic parsing.
Once person/number codes are taken into account,
the number of potential ambiguous readings is dramat-
ically reduced. In many cases, only one of the ambiguous
possibilities was grammatical. It should be noted that
there are a few difficult cases which we have not had
time to describe in this paper; these are discussed in
detail in Milne (1983).
Marcus had a few rules to resolve part of speech ambi-
guity, but they were ad hoc. We have seen that we can
replace these rules very simply by merely exploiting
agreement.
In the introduction, it was stated that handling lexical
ambiguity was a major test for deterministic parsing. In
this paper we have seen that many cases of ambiguity can
be resolved in a simple way. This is possible because of
the constraints imposed by number agreement and word
order. In fact, many cases of the seemingly difficult
Computational Linguistics, Volume 12, Number 1, January-March 1986 11
Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser
problem of lexical ambiguity turn out •to be easily
resolved in a deterministic parser, since the deterministic
parser uses more information to make decisions.
</bodyText>
<sectionHeader confidence="0.992539" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.99956262962963">
Akmajian, A. and Heny, F. 1975 An Introduction to the Principles of
Transformational Syntax. MIT Press, Cambridge, Massachusetts.
Chomsky, Noam 1965 Aspects of the Theory of Syntax. MIT Press,
Cambridge, Massachusetts.
Dewar, H.; Bratley, P.; and Thorne, J. 1969 A Program for the
Syntactic Analysis of English Sentences. Communications of the
ACM 12(8).
Fodor, Jerry; Bever, T.; and Garrett, M. 1974 The Psychology of
Language. McGraw-Hill, New York, New York.
Fodor, Janet and Frazier, Lynn 1978 The Sausage Machine: A New
Two-Stage Parsing Mode. Cognition 6: 291-325.
Kuno, S. 1965 The Predictive Analyzer and a Path Elimination Tech-
nique. Communications of the ACM 8(10).
Marcus, Mitchell 1980 A Theory of Syntactic Recognition for Natural
Language. MIT Press, Cambridge, Massachusetts.
Martin, William; Church, K; and Patil, R. 1981 Preliminary Analysis
of a Breadth-First Parsing Algorithm: Theoretical and Experimental
Results. MIT Al Lab. Presented at Modeling Human Parsing Strat-
egies Symposium, Austin, Texas.
Milne, Robert 1982 Predicting Garden Path Sentences, Cognitive
Science 6: 349-373.
Milne, Robert 1983 Resolving Lexical Ambiguity in a Deterministic
Parser. D.Phil. Dissertation, University of Edinburgh, Edinburgh,
Scotland.
TIME 9 January 1978 Good Ole Burt; Cool-eyed Clint.
Winograd, Terry 1972 Understanding Natural Language. Academic
Press, New York, New York.
</reference>
<page confidence="0.956444">
12 Computational Linguistics, Volume 12, Number 1, January-March 1986
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.689053">
<title confidence="0.998544">RESOLVING LEXICAL AMBIGUITY IN</title>
<author confidence="0.999884">Robert Milne</author>
<affiliation confidence="0.968421">Intelligent</affiliation>
<address confidence="0.9106745">10 Charlotte Square Edinburgh EH2 4DR Scotland</address>
<abstract confidence="0.970558">Lexical ambiguity and especially part-of-speech ambiguity is the source of much non-determinism in parsing. As a result, the resolution of lexical ambiguity presents deterministic parsing with a major test. If deterministic parsing is to be viable, it must be shown that lexical ambiguity can be resolved easily deterministically. In this paper, it is shown that Marcus&apos;s &amp;quot;diagnostics&amp;quot; can be handled without any mechanisms beyond what is required to parse grammatical sentences and reject ungrammatical sentences. It is also shown that many other classes of ambiguity can be easily resolved as well.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Akmajian</author>
<author>F Heny</author>
</authors>
<title>An Introduction to the Principles of Transformational Syntax.</title>
<date>1975</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="26167" citStr="Akmajian and Heny 1975" startWordPosition="4473" endWordPosition="4476">relative pronoun and a determiner. The following examples show various uses of both words: Computational Linguistics, Volume 12, Number 1, January-March 1986 5 Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser (26) Which boy wants a fish? det (27) Which boys want fish? det (28) The river which I saw has many fish. rel. pron. (29) What boy wants a fish? det (30) What boys want is fish. rel. pron. There is some debate about the part of speech to be assigned the word which. Some linguists consider it to be a quantifier (Chomsky 1965), while others consider it to be a determiner (Akmajian and Heny 1975, Chapter 8). We shall adopt the determiner analysis, making the problems for what and which similar. To determine the correct part of speech for these two words, Marcus (1980:286) used the following diagnostics: [which] -■ in the packet CPOOL &amp;quot;If the NP above Current Node is not modified then label 1st pronoun, relative pronoun else label 1st quant,ngstart,ns,wh,npl.&amp;quot; [what][t] in the packet NPOOL &amp;quot;If 2nd is ngstart and 2nd is not det then label 1st det,ns,npl,n3p,wh; activate parse det else label 1st pronoun,relpron,wh.&amp;quot; These diagnostics would make the word in question a relative pronoun if</context>
</contexts>
<marker>Akmajian, Heny, 1975</marker>
<rawString>Akmajian, A. and Heny, F. 1975 An Introduction to the Principles of Transformational Syntax. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<title>Aspects of the Theory of Syntax.</title>
<date>1965</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="26098" citStr="Chomsky 1965" startWordPosition="4463" endWordPosition="4464">WHICH For both what and which, the ambiguity lies between a relative pronoun and a determiner. The following examples show various uses of both words: Computational Linguistics, Volume 12, Number 1, January-March 1986 5 Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser (26) Which boy wants a fish? det (27) Which boys want fish? det (28) The river which I saw has many fish. rel. pron. (29) What boy wants a fish? det (30) What boys want is fish. rel. pron. There is some debate about the part of speech to be assigned the word which. Some linguists consider it to be a quantifier (Chomsky 1965), while others consider it to be a determiner (Akmajian and Heny 1975, Chapter 8). We shall adopt the determiner analysis, making the problems for what and which similar. To determine the correct part of speech for these two words, Marcus (1980:286) used the following diagnostics: [which] -■ in the packet CPOOL &amp;quot;If the NP above Current Node is not modified then label 1st pronoun, relative pronoun else label 1st quant,ngstart,ns,wh,npl.&amp;quot; [what][t] in the packet NPOOL &amp;quot;If 2nd is ngstart and 2nd is not det then label 1st det,ns,npl,n3p,wh; activate parse det else label 1st pronoun,relpron,wh.&amp;quot; Th</context>
</contexts>
<marker>Chomsky, 1965</marker>
<rawString>Chomsky, Noam 1965 Aspects of the Theory of Syntax. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Dewar</author>
<author>P Bratley</author>
<author>J Thorne</author>
</authors>
<title>A Program for the Syntactic Analysis of English Sentences.</title>
<date>1969</date>
<journal>Communications of the ACM</journal>
<volume>12</volume>
<issue>8</issue>
<marker>Dewar, Bratley, Thorne, 1969</marker>
<rawString>Dewar, H.; Bratley, P.; and Thorne, J. 1969 A Program for the Syntactic Analysis of English Sentences. Communications of the ACM 12(8).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Fodor</author>
<author>T Bever</author>
<author>M Garrett</author>
</authors>
<date>1974</date>
<booktitle>The Psychology of Language.</booktitle>
<publisher>McGraw-Hill,</publisher>
<location>New York, New York.</location>
<marker>Fodor, Bever, Garrett, 1974</marker>
<rawString>Fodor, Jerry; Bever, T.; and Garrett, M. 1974 The Psychology of Language. McGraw-Hill, New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet Fodor</author>
<author>Lynn Frazier</author>
</authors>
<title>The Sausage Machine: A New Two-Stage Parsing Mode.</title>
<date>1978</date>
<journal>Cognition</journal>
<volume>6</volume>
<pages>291--325</pages>
<marker>Fodor, Frazier, 1978</marker>
<rawString>Fodor, Janet and Frazier, Lynn 1978 The Sausage Machine: A New Two-Stage Parsing Mode. Cognition 6: 291-325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kuno</author>
</authors>
<title>The Predictive Analyzer and a Path Elimination Technique.</title>
<date>1965</date>
<journal>Communications of the ACM</journal>
<volume>8</volume>
<issue>10</issue>
<contexts>
<context position="13343" citStr="Kuno 1965" startWordPosition="2251" endWordPosition="2252">. Hence block will also be disambiguated without the verb use being considered by ROME. Other ambiguities inside the noun phrase will be handled in a similar way. This approach will usually cover the situation of singular head nouns, verb/adjective ambiguity and many other pre-nominal ambiguities. This works because the noun phrase has a very strict word order. When an ambiguous word is found, only one of its meanings will be appropriate to the word order of the noun phrase at that point. This approach can be thought of as an extension of the basic approach of the Harvard Predictive Analyzer (Kuno 1965). This strategy will also often disambiguate main verbs. For example, consider the following sentences: (2) Tom hit Mary. (3) Tom will hit Mary. (4) The will gave the money to Mary. In (2), hit is the main verb. In the dictionary, hit is also defined as a noun, (as in card playing). The parser will attach Tom as the subject of the sentence and then activate the rules for the main verb. Since hit has the feature &amp;quot;verb&amp;quot;, it will match that rule and be attached and disambiguated as a verb. Again, other possible parts of speech are not considered. The word will could be a noun or a modal as senten</context>
</contexts>
<marker>Kuno, 1965</marker>
<rawString>Kuno, S. 1965 The Predictive Analyzer and a Path Elimination Technique. Communications of the ACM 8(10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
</authors>
<title>A Theory of Syntactic Recognition for Natural Language.</title>
<date>1980</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="958" citStr="Marcus 1980" startWordPosition="137" endWordPosition="138">If deterministic parsing is to be viable, it must be shown that lexical ambiguity can be resolved easily deterministically. In this paper, it is shown that Marcus&apos;s &amp;quot;diagnostics&amp;quot; can be handled without any mechanisms beyond what is required to parse grammatical sentences and reject ungrammatical sentences. It is also shown that many other classes of ambiguity can be easily resolved as well. 1 INTRODUCTION Lexical ambiguity, and especially part-of-speech ambiguity, is the source of much non-determinism in parsing. As a result, the resolution of lexical ambiguity presents deterministic parsing (Marcus 1980) with a major test. If deterministic parsing is to be viable, it should be shown that lexical ambiguity can be resolved deterministically for many situations in which people do not have trouble. In this paper, it is shown that Marcus&apos;s &amp;quot;diagnostics&amp;quot; can be handled without any mechanisms beyond what is required to parse grammatical sentences and reject ungrammatical sentences and that many other classes of ambiguity can be easily resolved as well. This result is possible because of the constraints on English from word order and number agreement. Although many high-level constituents can be &amp;quot;mov</context>
<context position="9551" citStr="Marcus (1980)" startWordPosition="1587" endWordPosition="1588">res to be added, such as &amp;quot;ed, past&amp;quot; and some features to be removed such as &amp;quot;tenseless.&amp;quot; As features that are no longer applicable are removed, so also are parts of speech and their associated features that are no longer applicable. For blocked, the features &amp;quot;noun, ns, n3p&amp;quot; will be removed and the features &amp;quot;adjective, ed, past&amp;quot; will be added. The morphology will identify words such as adverbs, adjectives, and verbs in a similar way. The morphology used is very similar to that of Winograd (1972) and of Dewar, Bratley, and Thorne (1969); the part-of-speech additions and deletions are taken from Marcus (1980). Although this technique may seem obvious, it is included to point out that a majority of the occurrences of part-ofspeech ambiguity can be resolved or reduced on the basis of the morphology alone. 2.3 DISAMBIGUATION Now that we have allowed words to have multiple parts of speech and the morphology can be used to trim some of the ambiguity, we need a simple technique for disambiguating words to a single part of speech. Again, referring to Occam&apos;s Razor, what is preferable is a simple and general technique for all types of disambiguation. 2 Computational Linguistics, Volume 12, Number 1, Janua</context>
<context position="15047" citStr="Marcus (1980" startWordPosition="2578" endWordPosition="2579"> run in the following sentence. Since stop is sentence initial and can be a tenseless verb, the rule IMPERATIVE will match, and it will be disambiguated as a verb. The word run, which can be a noun or a verb, will be handled as will in (4). (5) Stop the run. 2.5 THE WORD TO Now let us consider a more difficult example, the word to. To is defined as an auxiliary verb and a preposition in ROBIE, as illustrated by these sentences: (6) I want to kiss you. (7) I will go to the show with you. In (6), to is the infinitive auxiliary, while in (7) to is a preposition. This analysis is based on that of Marcus (1980:118). Our two buffer cell lookahead is sufficient to disambiguate these examples. The buffer patterns for the above sentences are: [to&amp;tenseless] -* embedded VP [to&amp;ngstart] PP By looking at the following word, to can be disambiguated. In (7), the word the cannot be a tenseless verb, so the first pattern does not match. In (6), the second buffComputational Linguistics, Volume 12, Number 1, January-March 1986 3 Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser er does not have the feature &amp;quot;ngstart&amp;quot;, so the rule doesn&apos;t match. However, the above patterns will accept ungrammatic</context>
<context position="22930" citStr="Marcus (1980)" startWordPosition="3908" endWordPosition="3909">that it agrees in number with the subject, will lead to the rejection of the above examples. This was done by adding the agreement requirement into the pattern for each relevant rule as will be explained later. Buffers 1 and 2 must agree before a rule relating the subject and verb can match. This check looks at the number code of the NP and the person/number code of the verb and checks whether they agree. The routine for subject/verb agreement is very general and is used by all the subject/verb rules. The routine can only check the grammatical features of the buffers. 3.3 MARCUS&apos;S DIAGNOSTICS Marcus (1980) did handle some part-of-speech ambiguities. The words to, what, which, that, and have could all be used as several parts of speech. For each of these words he also used a Diagnostic rule. These Diagnostic rules matched when the word they were to diagnose arrived in the first buffer position and the appropriate packets were active. Each diagnostic would examine the features of the three buffers cells and the contents of the Active Node Stack. Once the diagnostic decided which part of speech the word was being used as, it either added the appropriate features, or explicitly ran a grammar rule. </context>
<context position="24228" citStr="Marcus 1980" startWordPosition="4136" endWordPosition="4137">e grammar rules in his parser were simple and elegant, but the diagnostics tended to be very complex and contained many conditionals. In some cases they also seemed rather ad hoc and did not meet the goal of a simple, elegant method of handling ambiguity. For example, consider the THAT-DIAGNOSTIC: [that][np] in the Packet CPOOL (Clause pool of rules) &amp;quot;If there is no determiner of second and there is not a qp of second and the nbar of 2nd is none of massn,npl and 2nd is not-modifiable then attach as det else if c is nbar then label 1st pronoun, relative pronoun else label 1st complementiser.&amp;quot; (Marcus 1980:291) Notice that if the word that were to be used as a determiner, then it would be attached after the NP was built! This is his primary rule for disambiguating the word that. Marcus&apos;s parser also had three other rules to handle different cases. It seems that these rules did not &amp;quot;elegantly capture generalisations&amp;quot; as did the rest of his parser. I consider these rules undesirable and feel that they should be corrected to comply with my criteria for simple and elegant techniques in resolving ambiguity. I wanted a method that used no special mechanism, or routine, other than that needed to parse</context>
<context position="26342" citStr="Marcus (1980" startWordPosition="4505" endWordPosition="4506">xical Ambiguity in a Deterministic Parser (26) Which boy wants a fish? det (27) Which boys want fish? det (28) The river which I saw has many fish. rel. pron. (29) What boy wants a fish? det (30) What boys want is fish. rel. pron. There is some debate about the part of speech to be assigned the word which. Some linguists consider it to be a quantifier (Chomsky 1965), while others consider it to be a determiner (Akmajian and Heny 1975, Chapter 8). We shall adopt the determiner analysis, making the problems for what and which similar. To determine the correct part of speech for these two words, Marcus (1980:286) used the following diagnostics: [which] -■ in the packet CPOOL &amp;quot;If the NP above Current Node is not modified then label 1st pronoun, relative pronoun else label 1st quant,ngstart,ns,wh,npl.&amp;quot; [what][t] in the packet NPOOL &amp;quot;If 2nd is ngstart and 2nd is not det then label 1st det,ns,npl,n3p,wh; activate parse det else label 1st pronoun,relpron,wh.&amp;quot; These diagnostics would make the word in question a relative pronoun if it occurred after a headnoun, or a determiner if the word occurred at the start of a possible noun phrase. If we follow the approach in the last section, and give each word a</context>
<context position="29820" citStr="Marcus (1980" startWordPosition="5137" endWordPosition="5138"> adopting the following analysis for WH clefts such as (34). The initial WH word, what is a relative pronoun and attached as the WH-COMP of the subject S node. The subject is the phrase What boys want. The main verb of the sentence is is and the complement fish. The exact details are not important, only that the word what or which is a not determiner at the start of a WH cleft. In sentences (34-36), the word what is not used as a determiner. In the analysis we are using, it is a relative pronoun and is used as the WH-COMP for the S. In sentences (37-39), the word what is used as a determiner. Marcus (1980:286) admits that this diagnostic produces the incorrect result in this case. His diagnostic will make what a determiner in all of these examples, as will my analysis. One can also see that each of the above pairs is a pair of potential garden path sentences. For each pair, the two buffers contain the same words. Hence our two-buffer lookahead is not sufficient to choose the correct usage of the word what. Using only two or three buffers, there is no way to make what a relative pronoun when the headnoun is plural but a determiner when it is singular for all arbitrary sentences. With regard to </context>
<context position="38396" citStr="Marcus (1980" startWordPosition="6627" endWordPosition="6628">g enforced agreement and rejecting ungrammatical sentences. 3.7 HANDLING THE WORD HAVE Let us now look at the elimination of Marcus&apos;s HAVE-DIAGNOSTIC in relation to the use of agreement we have been discussing in this section. The problem with have is illustrated by the following sentences: (55) Have the students take the exam. (56) Have the students taken the exam? In these, we must decide if have is an auxiliary verb or a main verb and whether the sentence is a yes-no question or an imperative. The sentences have the same initial string until the final morpheme on take. To handle this case, Marcus (1980:211) used this rule: &amp;quot;RULE HAVE-DIAG PRIORITY:5 IN SS-START [have,tenseless][np][t] If 2nd is ns,n3p or 3rd is tenseless then run imperative next else If 3rd is not verb then run yes-no-question next else if not sure, assume it&apos;s a y/n-q and run yes-noquestion next&amp;quot;.&amp;quot; This rule seems to be necessary in order to distinguish between the question and the imperative. If one tries to ascertain exactly what occurs, the apparent complexity is revealed. Note also that Marcus&apos;s rule defaults to a yesno question twice in this diagnostic. The following sentences illustrate the distinction this rule make</context>
</contexts>
<marker>Marcus, 1980</marker>
<rawString>Marcus, Mitchell 1980 A Theory of Syntactic Recognition for Natural Language. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Martin</author>
<author>K Church</author>
<author>R Patil</author>
</authors>
<title>Preliminary Analysis of a Breadth-First Parsing Algorithm: Theoretical and Experimental Results. MIT Al Lab. Presented at Modeling Human Parsing Strategies Symposium,</title>
<date>1981</date>
<location>Austin, Texas.</location>
<marker>Martin, Church, Patil, 1981</marker>
<rawString>Martin, William; Church, K; and Patil, R. 1981 Preliminary Analysis of a Breadth-First Parsing Algorithm: Theoretical and Experimental Results. MIT Al Lab. Presented at Modeling Human Parsing Strategies Symposium, Austin, Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Milne</author>
</authors>
<date>1982</date>
<journal>Predicting Garden Path Sentences, Cognitive Science</journal>
<volume>6</volume>
<pages>349--373</pages>
<contexts>
<context position="30465" citStr="Milne 1982" startWordPosition="5250" endWordPosition="5251">produces the incorrect result in this case. His diagnostic will make what a determiner in all of these examples, as will my analysis. One can also see that each of the above pairs is a pair of potential garden path sentences. For each pair, the two buffers contain the same words. Hence our two-buffer lookahead is not sufficient to choose the correct usage of the word what. Using only two or three buffers, there is no way to make what a relative pronoun when the headnoun is plural but a determiner when it is singular for all arbitrary sentences. With regard to the Semantic Checking Hypothesis (Milne 1982) then, it is suggested that this decision is based on non-syntactic information. I believe that intonation is critical in these examples. Unfortunately there is insufficient experimental evidence to determine for certain whether this is true. Finally, the problem of what and which as sentence initials, with no noun in the second buffer seems to arise very rarely. I have found no examples of this problem in free text analysis. The current parser (ROBIE) cannot obtain the extra information provided by intonation to help resolve this case. As a result it follows Marcus&apos;s diagnostic and makes what</context>
<context position="45100" citStr="Milne (1982)" startWordPosition="7810" endWordPosition="7811">ral headnoun followed by a plural headnoun, this case is really a subset of Case 4. In general, the problems and issues for Case 4 dominate the resolution of this ambiguity. Case 4: Sentences (68) and (69) both have the same word initial string until after screws, but in (68) screws is a verb while in (69) screws is part of the headnoun. In this situation, where the final word in a series is plural, each word before it must be a noun. The word itself can be either a noun or a verb, depending on what follows. These can be recognised as a pair of potential garden path sentences, as discussed in Milne (1982). Therefore, this is the case to which the Semantic Checking Hypothesis applies and the predictions of Milne (1982) apply. In that paper, the idea of potential garden path sentences is presented. These are sentences that may or may not lead to a garden path. Each garden path sentence has a partner, which is similar but not a garden path. It is proposed that the decision as to how to resolve the ambiguity that may lead to a garden path should be made by semantics and not by syntax. This theory is called the Semantic Checking Hypothesis. For full details see Milne (1983). In this section, we hav</context>
<context position="48558" citStr="Milne (1982)" startWordPosition="8428" endWordPosition="8429">ed verb. In the parser, the noun/modal word is first encountered inside the NP packets and the parser must decide whether to use the word as part of the headnoun or to leave it in the buffer to be used as a modal verb. These rules do not know whether a verb has been found previously. Hence, not all information from the sentence is used. If all the information is available at the time the noun/modal ambiguity is being resolved, these sentences would be unambiguous and people would have no trouble reading them. Subjects were asked to read the above examples in the second experiment presented in Milne (1982). The results showed convincingly that they are potential garden paths. Many naive readers had considerably more difficulty with them than with their more straightforward counterparts. This was predicted for reasons explained below. This result seems surprising. If the subjects used all information available at the time the noun/modal word was encountered, then they should have had no trouble with these sentences. The fact that these are garden paths indicates that the readers did not use all the information available to them. Notice also that the ambiguity can be reformulated as: &amp;quot;Do we have </context>
</contexts>
<marker>Milne, 1982</marker>
<rawString>Milne, Robert 1982 Predicting Garden Path Sentences, Cognitive Science 6: 349-373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Milne</author>
</authors>
<title>Resolving Lexical Ambiguity in a Deterministic Parser.</title>
<date>1983</date>
<tech>D.Phil.</tech>
<institution>Dissertation, University of Edinburgh,</institution>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="5260" citStr="Milne 1983" startWordPosition="838" endWordPosition="839">hen this will not explain how people can understand these examples so well and it can be considered a weakness in the model. To say part-of-speech ambiguity can be handled deterministically but with the use of special mechanisms would be no surprise and not very important. To say one can handle part-of-speech ambiguity deterministically with no special mechanisms is a more significant claim. In this paper it is indeed suggested that many cases of part-of-speech ambiguity can be handled by the parser with no special mechanisms. This paper is a summary of a section of the author&apos;s Ph.D. thesis (Milne 1983) with the same title and describes work done at the University of Edinburgh. That thesis presents ROBIE, a deterministic parser that is able to resolve lexical ambiguities and that is fully implemented in PROLOG. ROME has two lookahead buffers and does not use Marcus&apos;s Attention Shift mechanism. This means that ROBIE scans the current token and one more of lookahead. PARSIFAL scanned the current token and two lookahead cells. In this paper, only local ambiguities are addressed, that is, ambiguities that can be resolved within the sentence. Global ambiguities, which require context to resolve, </context>
<context position="17366" citStr="Milne 1983" startWordPosition="2970" endWordPosition="2971">ely arises, the above rule will make the wrong decision if the ambiguous word is being used as a noun. In this situation, ROBIE will make the wrong decision, and has no capability to better decide. By default, the principles of Right Association and Minimal Attachment apply as discussed in Frazier and Fodor (1978). A free text analysis done on a cover story in TIME magazine (1978) resulted in 55 occurrences of the word to. The two rules mentioned above in conjunction with verb subcategorisation gave the correct interpretation of all of these. These rules were also checked on the MECHO corpus (Milne 1983) and the ASHOK corpus (Martin, Church, and Patil 1981). There were no violations of these rules in either of these. 2.6 ADJECTIVE/NOUN AND NOUN/NOUN AMBIGUITY Adjective/noun ambiguity is beyond the present scope of this research and is handled in a simple-minded way. If the word following the ambiguous adjective/noun word can be a noun, then the ambiguous word is used as an adjective. In other words, all conflicts are resolved in favour of the adjective usage. This problem arises in these examples: (10) The plane is inclined at an angle of 30 degrees above the horizontal. (11) A block rests on</context>
<context position="33054" citStr="Milne (1983)" startWordPosition="5694" endWordPosition="5695"> that will not be made a determiner in (41) and ROBIE will get the correct parse. For this case, the agreement check would make sure that one of the following patterns match: [det,ns] [noun,ns] [det,npl] [noun,npl] The above two cases are handled properly because number agreement blocks the interpretation of the (41) as a determiner. This approach leads to the correct preference, when there is an ambiguity and accounts for the difficulty in (42) versus (43): (42) That deer ate everything in my garden surprised me. (43) That deer ate everything in my garden last night. The second experiment in Milne (1983), showed that (42) is a garden path sentence, while (43) is not. In both sentences, it is believed the subject uses the word that as a determiner Deer is both singular and plural, so it fits the above rule. In (42), that must be used as a complementiser to make the sentence grammatical. The approach outlined above will use that as a determiner in an ambiguous case such as this. These two simple techniques, word order and agreement, are sufficient to handle all the examples we have just presented. In addition, free text analysis has shown no violations to this approach (Milne 1983). These techn</context>
<context position="35820" citStr="Milne (1983)" startWordPosition="6200" endWordPosition="6201"> take an NP subject, followed by a that S-. For these examples, ROBIE may have to decide if the series of words following that is a relative clause or an embedded sentence. In the following sentences, the lookahead would have to be more than three buffers. (Brackets indicate words in the buffers. The last word is the disambiguating word.) (50) I told the girl [that][the][boy] hit the story (51) I told the girl [that][theilboy] will kiss her It can be seen that in these sentences the disambiguating word is outside our three buffers. How do people handle these, and what should our parser do? In Milne (1983) it was shown that when the syntax could not resolve the ambiguity with its two-buffer lookahead, the decision of which interpretation to use might be made using non-syntactic information. It was also stated that if context can affect the interpretation of the sentence, then non-syntactic information is being used to select the Computational Linguistics, Volume 12, Number 1, January-March 1986 7 Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser interpretation. The reader can experiment for himself and see that context does affect the interpretation of these sentences. Therefor</context>
<context position="37167" citStr="Milne (1983)" startWordPosition="6422" endWordPosition="6423">ot on a semantic basis but on a non-syntactic one. This explains why some of these examples cause difficulty and others do not. The psychological evidence from cases using that is scant, and I feel no conclusions can be reached here. My theory predicts that context will strongly affect these examples and, if they are strongly biased to the incorrect reading, a garden path should result. One well-known example in this area is (52): (52) I told the girl that I liked the story. (53) I told the girl whom I liked the story. (54) I told the girl the story that I liked. These examples were tested in Milne (1983). The results suggested that (52) was read faster than the other two examples. Many of the subjects were questioned informally after the experiment about their interpretation of the sentence. All reported only one meaning; the Sreading. None of the subjects said that they noticed the relative clause reading, hence the result. The experiment however, was not designed formally to distinguish these. To handle the examples we have seen in this section, Marcus had four diagnostics, one of which was very complicated. I have just shown how to handle all four cases of that without any special rules, m</context>
<context position="41988" citStr="Milne (1983)" startWordPosition="7238" endWordPosition="7239">parsed.) Also the subject NP must agree with the auxiliary verb, so we can also add &amp;quot;agree(auxverb,np)&amp;quot; to the rule, as 8 Computational Linguistics, Volume 12, Number 1, January-March 1986 Robert Milne Resolving Lexical Ambiguity in a Deterministic Parser we did with the HAVE-DIAGNOSTIC! So, by correcting the yes-no question rule, the HAVE-DIAGNOSTIC is redundant. In this section we have seen that Marcus&apos;s HAVE-DIAGNOSTIC can be replaced by merely exploiting agreement. It should be pointed out that although this approach has the same coverage as Marcus&apos;s diagnostic, it is wrong in some cases. Milne (1983) has a full discussion. 3.8 PLURAL HEAD NOUNS There is a class of ambiguities that can be resolved merely by enforcing subject/verb agreement. In this section, we see an example from the class of words with the features noun, verb, final-s (plural). If we have two words that can be a plural noun or a singular verb, we can enumerate four cases. Let us look at these possibilities and see that these cases can be disambiguated by simple rules using subject/verb agreement. The following examples illustrate all the possibilities: (65) The soup pot cover handle screw is red. (66) The soup pot cover h</context>
<context position="45675" citStr="Milne (1983)" startWordPosition="7913" endWordPosition="7914">ntences, as discussed in Milne (1982). Therefore, this is the case to which the Semantic Checking Hypothesis applies and the predictions of Milne (1982) apply. In that paper, the idea of potential garden path sentences is presented. These are sentences that may or may not lead to a garden path. Each garden path sentence has a partner, which is similar but not a garden path. It is proposed that the decision as to how to resolve the ambiguity that may lead to a garden path should be made by semantics and not by syntax. This theory is called the Semantic Checking Hypothesis. For full details see Milne (1983). In this section, we have looked at resolving a simple case of noun/verb ambiguity. In order to resolve this ambiguity, it was necessary merely to exploit agreement between the subject and verb in number and person. Due to number and subject verb agreement, these facts have a linguistic base. They rely on the fact that a final &amp;quot;s&amp;quot; marks a plural noun but a singular verb. If the verb is v3s (verb agrees with a 3rd person, singular noun, as with the &amp;quot;s&amp;quot;), then the subject of the verb must be singular, or else the sentence is ungrammatical. This is why all the words before the v3s word must be n</context>
<context position="49322" citStr="Milne (1983)" startWordPosition="8555" endWordPosition="8556">re straightforward counterparts. This was predicted for reasons explained below. This result seems surprising. If the subjects used all information available at the time the noun/modal word was encountered, then they should have had no trouble with these sentences. The fact that these are garden paths indicates that the readers did not use all the information available to them. Notice also that the ambiguity can be reformulated as: &amp;quot;Do we have the end of a noun phrase, or a complex headnoun?&amp;quot; We have already seen a case where people do not seem to use all the information available to them. In Milne (1983), several end-of-NP problems were presented that could lead to a garden path. In each of these, it was shown that the ambiguity was resolved on the basis of non-syntactic information, without regard to the following words in the sentence. In other words, we saw that the reader did not use all the information available. There is one crucial difference though. In the previous cases, non-syntactic information was used because the syntactic processor with its limited lookahead was sometimes unable to choose the correct alternative. In this case, the information necessary has already been absorbed </context>
<context position="55420" citStr="Milne (1983)" startWordPosition="9634" endWordPosition="9635">ould be done by having a list of all the possible categories as the pattern of the second buffer. As an implementation detail, this is in the form of an agreement check, merely to simplify this rule and to show its generality. The only remaining problem occurs when the verb can take one or more objects and the item after the word her can be either the second object, or an NP with her as a determiner For example: (85) I took her grapes. (86) He saw her duck. (87) I gave her food for the dog. The examples presented above are all examples of global ambiguity, which is discussed in more detail in Milne (1983). In these cases the check of &amp;quot;Will-the next word take a determiner?&amp;quot;, may or may not lead to the wrong analysis. This problem also interacts with the top-down component of verb phrase parsing and the semantic restrictions presented by it. The conflict between the determiner and possessive usage can be modelled as a conflict of rule priorities. If the possessive use is preferred, then this rule should match first. Conversely, if the object use is preferred, then the object rule should match first. Any error in reading these examples would be due to one rule having priority over the other, when</context>
<context position="57617" citStr="Milne (1983)" startWordPosition="10000" endWordPosition="10001">roup to block these unacceptable readings. Most of our ambiguity problems were also handled by this method. Although this has been used before with non-deterministic parsers, it was not obvious that it would provide enough information to enable deterministic parsing. Once person/number codes are taken into account, the number of potential ambiguous readings is dramatically reduced. In many cases, only one of the ambiguous possibilities was grammatical. It should be noted that there are a few difficult cases which we have not had time to describe in this paper; these are discussed in detail in Milne (1983). Marcus had a few rules to resolve part of speech ambiguity, but they were ad hoc. We have seen that we can replace these rules very simply by merely exploiting agreement. In the introduction, it was stated that handling lexical ambiguity was a major test for deterministic parsing. In this paper we have seen that many cases of ambiguity can be resolved in a simple way. This is possible because of the constraints imposed by number agreement and word order. In fact, many cases of the seemingly difficult Computational Linguistics, Volume 12, Number 1, January-March 1986 11 Robert Milne Resolving</context>
</contexts>
<marker>Milne, 1983</marker>
<rawString>Milne, Robert 1983 Resolving Lexical Ambiguity in a Deterministic Parser. D.Phil. Dissertation, University of Edinburgh, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<title>Good Ole Burt; Cool-eyed Clint.</title>
<date>1978</date>
<journal>TIME</journal>
<volume>9</volume>
<contexts>
<context position="17070" citStr="(1978)" startWordPosition="2921" endWordPosition="2921">r a VP. The final difficult situation arises whenever the following three conditions are true: • the verb will accept a toPP and a toVP, • the item in the second buffer has the features &amp;quot;tenseless&amp;quot; and &amp;quot;ngstart&amp;quot; and, • the toPP is a required modifier of the verb. Although this situation rarely arises, the above rule will make the wrong decision if the ambiguous word is being used as a noun. In this situation, ROBIE will make the wrong decision, and has no capability to better decide. By default, the principles of Right Association and Minimal Attachment apply as discussed in Frazier and Fodor (1978). A free text analysis done on a cover story in TIME magazine (1978) resulted in 55 occurrences of the word to. The two rules mentioned above in conjunction with verb subcategorisation gave the correct interpretation of all of these. These rules were also checked on the MECHO corpus (Milne 1983) and the ASHOK corpus (Martin, Church, and Patil 1981). There were no violations of these rules in either of these. 2.6 ADJECTIVE/NOUN AND NOUN/NOUN AMBIGUITY Adjective/noun ambiguity is beyond the present scope of this research and is handled in a simple-minded way. If the word following the ambiguous </context>
</contexts>
<marker>1978</marker>
<rawString>TIME 9 January 1978 Good Ole Burt; Cool-eyed Clint.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Winograd</author>
</authors>
<title>Understanding Natural Language.</title>
<date>1972</date>
<publisher>Academic Press,</publisher>
<location>New York, New York.</location>
<contexts>
<context position="6734" citStr="Winograd (1972)" startWordPosition="1086" endWordPosition="1087">complex ones. We start with how words are defined within the parser to be ambiguous and how the morphology can be used to resolve ambiguities. Next we look at how word order and finally various types of agreement can be used to resolve most remaining ambiguities. 2 SYNTACTIC CONTEXT 2.1 WORD DATA STRUCTURES As a first approach to handling ambiguity, it was asked, &amp;quot;If we construct a compound lexical entry for each word composed of the features of each part of speech the word can have and make no alterations to the grammar, how wide a coverage of examples will we get?&amp;quot; This approach was used by Winograd (1972) and was found to be very effective for the following reason. Each word has all the possible relevant features for it. Therefore, the test will succeed for each possible part of speech with which a word can be used. In this way, all applicable rules will match. It may be that often only one rule will match, or that the first rule tried is the correct rule. The question is, how often will the rule that matches be the correct rule? All words in ROME are defined in the syntactic dictionaries. Each word has a compound lexical entry incorporating all the features for all the possible parts of speec</context>
<context position="9437" citStr="Winograd (1972)" startWordPosition="1570" endWordPosition="1571">s place. If block is defined as both a noun and a verb, then blocked is not a noun. The morphology causes some features to be added, such as &amp;quot;ed, past&amp;quot; and some features to be removed such as &amp;quot;tenseless.&amp;quot; As features that are no longer applicable are removed, so also are parts of speech and their associated features that are no longer applicable. For blocked, the features &amp;quot;noun, ns, n3p&amp;quot; will be removed and the features &amp;quot;adjective, ed, past&amp;quot; will be added. The morphology will identify words such as adverbs, adjectives, and verbs in a similar way. The morphology used is very similar to that of Winograd (1972) and of Dewar, Bratley, and Thorne (1969); the part-of-speech additions and deletions are taken from Marcus (1980). Although this technique may seem obvious, it is included to point out that a majority of the occurrences of part-ofspeech ambiguity can be resolved or reduced on the basis of the morphology alone. 2.3 DISAMBIGUATION Now that we have allowed words to have multiple parts of speech and the morphology can be used to trim some of the ambiguity, we need a simple technique for disambiguating words to a single part of speech. Again, referring to Occam&apos;s Razor, what is preferable is a sim</context>
<context position="10805" citStr="Winograd (1972)" startWordPosition="1808" endWordPosition="1809">xical Ambiguity in a Deterministic Parser In ROBIE each rule matches the features of one or two buffer cells. (The word buffer will be used interchangeably with cell. That is, buffer and cell are the same concept.) If the word block is in the first buffer cell, then a pattern [noun] or a pattern [verb] will match. These patterns do not relate to the other possible definitions of a word. If a rule pattern has matched on the feature &amp;quot;noun&amp;quot; in the first buffer cell, then ROBIE assumes that this word is a noun. It would then be appropriate to disambiguate the word as a noun. This is exactly as in Winograd (1972). In a non-deterministic parser, it is not essential to find the correct rule first. If the parser runs an incorrect rule, the parser may backtrack and change the category assignment. But in a deterministic parser, there will never be any backtracking, and this solution cannot be used. Since ROME does not backtrack, disambiguating the word when the pattern matches will always result in the same disambiguation as if the word were disambiguated in the grammar rule. Once a rule runs assuming a buffer contains a certain part of speech, it must be used as such in the parser. The general disambiguat</context>
<context position="18786" citStr="Winograd (1972)" startWordPosition="3216" endWordPosition="3217">rser. A word should be used as an adjective if the following word can be an adjective or a noun. However, this approach would fail on examples such as: (12) The old can get in for half price. (13) The large student residence blocks my view. 2.7 WHY DO THESE TECHNIQUES WORK? In this section we have seen many examples of the resolution of ambiguity. To handle these examples, we merely constructed a compound lexical entry for each word, composed of the features of each part of speech the word could be and allowed the pattern matching to perform the disambiguation. This technique has been used by Winograd (1972). Why does this work so well? English has a fairly strict structural order for all the examples presented here. Because of this, in each example we have seen, the use of the word as a different part of speech would be ungrammatical. Although these techniques have been used for non-deterministic parsers, their effectiveness has not been investigated for a deterministic parser. Most ambiguities are not recognised by people because only one of the alternatives is grammatical. In many situations, when fixed constituent structure is taken into account, other uses of an ambiguous word are not possib</context>
</contexts>
<marker>Winograd, 1972</marker>
<rawString>Winograd, Terry 1972 Understanding Natural Language. Academic Press, New York, New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>