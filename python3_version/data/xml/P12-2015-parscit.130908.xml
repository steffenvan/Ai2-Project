<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003565">
<title confidence="0.856048">
A Context-sensitive, Multi-faceted model of Lexico-Conceptual Affect
</title>
<author confidence="0.992568">
Tony Veale
</author>
<affiliation confidence="0.989256">
Web Science and Technology Division,
</affiliation>
<address confidence="0.8001845">
KAIST, Daejeon,
South Korea.
</address>
<email confidence="0.997279">
Tony.Veale@gmail.com
</email>
<sectionHeader confidence="0.997367" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999966416666667">
Since we can ‘spin’ words and concepts to
suit our affective needs, context is a major
determinant of the perceived affect of a
word or concept. We view this re-profiling
as a selective emphasis or de-emphasis of
the qualities that underpin our shared stere-
otype of a concept or a word meaning, and
construct our model of the affective lexicon
accordingly. We show how a large body of
affective stereotypes can be acquired from
the web, and also show how these are used
to create and interpret affective metaphors.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999979028571429">
The builders of affective lexica face the vexing
task of distilling the many and varied pragmatic
uses of a word or concept into an overall semantic
measure of affect. The task is greatly complicated
by the fact that in each context of use, speakers
may implicitly agree to focus on just a subset of
the salient features of a concept, and it is these fea-
tures that determine contextual affect. Naturally,
disagreements arise when speakers do not implicit-
ly arrive at such a consensus, as when people disa-
gree about hackers: advocates often focus on
qualities that emphasize curiosity or technical vir-
tuosity, while opponents focus on qualities that
emphasize criminality and a disregard for the law.
In each case, it is the same concept, Hacker, that is
being described, yet speakers can focus on differ-
ent qualities to arrive at different affective stances.
Any gross measure of affect (such as e.g., that
hackers are good or bad) must thus be grounded in
a nuanced model of the stereotypical properties
and behaviors of the underlying word-concept. As
different stereotypical qualities are highlighted or
de-emphasized in a given context – a particular
metaphor, say, might describe hackers as terrorists
or hackers as artists – we need to be able to re-
calculate the perceived affect of the word-concept.
This paper presents such a stereotype-grounded
model of the affective lexicon. After reviewing the
relevant background in section 2, we present the
basis of the model in section 3. Here we describe
how a large body of feature-rich stereotypes is ac-
quired from the web and from local n-grams. The
model is evaluated in section 4. We conclude by
showing the utility of the model to that most con-
textual of NLP phenomena – affective metaphor.
</bodyText>
<sectionHeader confidence="0.999455" genericHeader="related work">
2 Related Work and Ideas
</sectionHeader>
<bodyText confidence="0.999946041666666">
In its simplest form, an affect lexicon assigns an
affective score – along one or more dimensions –
to each word or sense. For instance, Whissell’s
(1989) Dictionary of Affect (or DoA) assigns a trio
of scores to each of its 8000+ words to describe
three psycholinguistic dimensions: pleasantness,
activation and imagery. In the DoA, the lowest
pleasantness score of 1.0 is assigned to words like
abnormal and ugly, while the highest, 3.0, is as-
signed to words like wedding and winning. Though
Whissell’s DoA is based on human ratings, Turney
(2002) shows how affective valence can be derived
from measures of word association in web texts.
Human intuitions are prized in matters of lexi-
cal affect. For reliable results on a large-scale, Mo-
hammad &amp; Turney (2010) and Mohammad &amp;
Yang (2011) thus used the Mechanical Turk to
elicit human ratings of the emotional content of
words. Ratings were sought along the eight dimen-
sions identified in Plutchik (1980) as primary emo-
tions: trust , anger, anticipation, disgust, fear, joy,
sadness and surprise. Automated tests were used to
exclude unsuitable raters. In all, 24,000+ word-
sense pairs were annotated by five different raters.
</bodyText>
<page confidence="0.992611">
75
</page>
<note confidence="0.684499">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 75–79,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999886272727273">
Liu et al. (2003) also present a multidimension-
al affective model that uses the six basic emotion
categories of Ekman (1993) as its dimensions:
happy, sad, angry, fearful, disgusted and surprised.
These authors base estimates of affect on the con-
tents of Open Mind, a common-sense knowledge-
base (Singh, 2002) harvested from contributions of
web volunteers. These contents are treated as sen-
tential objects, and a range of NLP models is used
to derive affective labels for the subset of contents
(~10%) that appear to convey an emotional stance.
These labels are then propagated to related con-
cepts (e.g., excitement is propagated from roller-
coasters to amusement parks) so that the implicit
affect of many other concepts can be determined.
Strapparava and Valitutti (2004) provide a set
of affective annotations for a subset of WordNet’s
synsets in a resource called Wordnet-affect. The
annotation labels, called a-labels, focus on the
cognitive dynamics of emotion, allowing one to
distinguish e.g. between words that denote an emo-
tion-eliciting situation and those than denote an
emotional response. Esuli and Sebastiani (2006)
also build directly on WordNet as their lexical plat-
form, using a semi-supervised learning algorithm
to assign a trio of numbers – positivity, negativity
and neutrality – to word senses in their newly de-
rived resource, SentiWordNet. (Wordnet-affect also
supports these three dimensions as a-labels, and
adds a fourth, ambiguous). Esuli &amp; Sebastiani
(2007) improve on their affect scores by running a
variant of the PageRank algorithm (see also Mihal-
cea and Tarau, 2004) on the graph structure that
tacitly connects word-senses in WordNet to each
other via the words used in their textual glosses.
These lexica attempt to capture the affective
profile of a word/sense when it is used in its most
normative and stereotypical guise, but they do so
without an explicit model of stereotypical mean-
ing. Veale &amp; Hao (2007) describe a web-based
approach to acquiring such a model. They note that
since the simile pattern “as ADJ as DET NOUN”
presupposes that NOUN is an exemplar of
ADJness, it follows that ADJ must be a highly sa-
lient property of NOUN. Veale &amp; Hao harvested
tens of thousands of instances of this pattern from
the Web, to extract sets of adjectival properties for
thousands of commonplace nouns. They show that
if one estimates the pleasantness of a term like
snake or artist as a weighted average of the pleas-
antness of its properties (like sneaky or creative) in
a resource like Whissell’s DoA, then the estimated
scores show a reliable correlation with the DoA’s
own scores. It thus makes computational sense to
calculate the affect of a word-concept as a function
of the affect of its most salient properties. Veale
(2011) later built on this work to show how a prop-
erty-rich stereotypical representation could be used
for non-literal matching and retrieval of creative
texts, such as metaphors and analogies.
Both Liu et al. (2003) and Veale &amp; Hao (2010)
argue for the importance of common-sense
knowledge in the determination of affect. We in-
corporate ideas from both here, while choosing to
build mainly on the latter, to construct a nuanced,
two-level model of the affective lexicon.
</bodyText>
<sectionHeader confidence="0.943929" genericHeader="method">
3 An Affective Lexicon of Stereotypes
</sectionHeader>
<bodyText confidence="0.999986060606061">
We construct the stereotype-based lexicon in two
stages. For the first layer, a large collection of ste-
reotypical descriptions is harvested from the web.
As in Liu et al. (2003), our goal is to acquire a
lightweight common-sense representation of many
everyday concepts. For the second layer, we link
these common-sense qualities in a support graph
that captures how they mutually support each other
in their co-description of a stereotypical idea. From
this graph we can estimate pleasantness and un-
pleasantness valence scores for each property and
behavior, and for the stereotypes that exhibit them.
Expanding on the approach in Veale (2011), we
use two kinds of query for harvesting stereotypes
from the web. The first, “as ADJ as a NOUN”, ac-
quires typical adjectival properties for noun con-
cepts; the second, “VERB+ing like a NOUN” and
“VERB+ed like a NOUN”, acquires typical verb
behaviors. Rather than use a wildcard * in both
positions (ADJ and NOUN, or VERB and NOUN),
which gives limited results with a search engine
like Google, we generate fully instantiated similes
from hypotheses generated via the Google n-grams
(Brants &amp; Franz, 2006). Thus, from the 3-gram “a
drooling zombie” we generate the query “drooling
like a zombie”, and from the 3-gram “a mindless
zombie” we generate “as mindless as a zombie”.
Only those queries that retrieve one or more
Web documents via the Google API indicate the
most promising associations. This still gives us
over 250,000 web-validated simile associations for
our stereotypical model, and we filter these manu-
ally, to ensure that the lexicon is both reusable and
</bodyText>
<page confidence="0.927041">
76
</page>
<bodyText confidence="0.997660046511628">
of the highest quality. We obtain rich descriptions
for many stereotypical ideas, such as Baby, which
is described via 163 typical properties and behav-
iors like crying, drooling and guileless. After this
phase, the lexicon maps each of 9,479 stereotypes
to a mix of 7,898 properties and behaviors.
We construct the second level of the lexicon by
automatically linking these properties and behav-
iors to each other in a support graph. The intuition
here is that properties which reinforce each other in
a single description (e.g. “as lush and green as a
jungle” or “as hot and humid as a sauna”) are more
likely to have a similar affect than properties which
do not support each other. We first gather all
Google 3-grams in which a pair of stereotypical
properties or behaviors X and Y are linked via co-
ordination, as in “hot and humid” or “kicking and
screaming”. A bidirectional link between X and Y
is added to the support graph if one or more stereo-
types in the lexicon contain both X and Y. If this is
not so, we also ask whether both descriptors ever
reinforce each other in Web similes, by posing the
web query “as X and Y as”. If this query has non-
zero hits, we still add a link between X and Y.
Let N denote this support graph, and N(p) de-
note the set of neighboring terms to p, that is, the
set of properties and behaviors that can mutually
support a property p. Since every edge in N repre-
sents an affective context, we can estimate the like-
lihood that p is ever used in a positive or negative
context if we know the positive or negative affect
of enough members of N(p). So if we label enough
vertices of N with + / – labels, we can interpolate a
positive/negative affect for all vertices p in N.
We thus build a reference set -R of typically
negative words, and a set +R of typically positive
words. Given a few seed members of -R (such as
sad, evil, etc.) and a few seed members of +R
(such as happy, wonderful, etc.), we find many
other candidates to add to +R and -R by consider-
ing neighbors of these seeds in N. After just three
iterations, +R and -R contain ~2000 words each.
For a property p, we define N+(p) and N-(p) as
</bodyText>
<listItem confidence="0.9867845">
(1) N+(p) = N(p) n +R
(2) N-(p) = N(p) n -R
</listItem>
<bodyText confidence="0.991834833333333">
We assign pos/neg valence scores to each property
p by interpolating from reference values to their
neighbors in N. Unlike that of Takamura et al.
(2005), the approach is non-iterative and involves
no feedback between the nodes of N, and thus, no
inter-dependence between adjacent affect scores:
</bodyText>
<figure confidence="0.9492934">
(3) pos(p) = |N+(p)|
|N+(p) U N-(p)|
(4) neg(p) = 1 - pos(p)
If a term S denotes a stereotypical idea and is de-
scribed via a set of typical properties and behaviors
typical(S) in the lexicon, then:
(5) pos(S) = pos(p)
IpEtypical(S)
|typical(S)|
(6) neg(S) = 1 - pos(S)
</figure>
<bodyText confidence="0.808198714285714">
Thus, (5) and (6) calculate the mean affect of the
properties and behaviors of S, as represented via
typical(S). We can now use (3) and (4) to separate
typical(S) into those elements that are more nega-
tive than positive (putting an unpleasant spin on S
in context) and those that are more positive than
negative (putting a pleasant spin on S in context):
</bodyText>
<listItem confidence="0.9086675">
(7) posTypical(S) = {p  |p E typical(S) n pos(p) &gt; 0.5}
(8) negTypical(S) = {p  |p E typical(S) n neg(p) &gt; 0.5}
</listItem>
<sectionHeader confidence="0.990226" genericHeader="method">
4 Empirical Evaluation
</sectionHeader>
<bodyText confidence="0.997319545454546">
In the process of populating +R and -R, we identi-
fy a reference set of 478 positive stereotype nouns
(such as saint and hero) and 677 negative stereo-
type nouns (such as tyrant and monster). We can
use these reference stereotypes to test the effec-
tiveness of (5) and (6), and thus, indirectly, of (3)
and (4) and of the affective lexicon itself. Thus, we
find that 96.7% of the stereotypes in +R are cor-
rectly assigned a positivity score greater than 0.5
(pos(S) &gt; neg(S)) by (5), while 96.2% of the stere-
otypes in -R are correctly assigned a negativity
score greater than 0.5 (neg(S) &gt; pos(S)) by (6).
We can also use +R and -R as a gold standard
for evaluating the separation of typical(S) into dis-
tinct positive and negative subsets posTypical(S)
and negTypical(S) via (7) and (8). The lexicon con-
tains 6,230 stereotypes with at least one property in
+RU-R. On average, +RU-R contains 6.51 of the
properties of each of these stereotypes, where, on
average, 2.95 are in +R while 3.56 are in -R.
In a perfect separation, (7) should yield a posi-
tive subset that contains only those properties in
</bodyText>
<page confidence="0.996659">
77
</page>
<bodyText confidence="0.993778">
The properties and behaviors that are contextually
relevant to the interpretation of T is S are given by
typical(S)n+R, while (8) should yield a negative
subset that contains only those in typical(S)n-R.
</bodyText>
<table confidence="0.9995386">
Macro Averages Positive Negative
(6230 stereotypes) properties properties
Precision .962 .98
Recall .975 .958
F-Score .968 .968
</table>
<tableCaption confidence="0.7801055">
Table 1. Average P/R/F1 scores for the affective
retrieval of +/- properties from 6,230 stereotypes.
</tableCaption>
<bodyText confidence="0.99762475">
Viewing the problem as a retrieval task then, in
which (7) and (8) are used to retrieve distinct posi-
tive and negative property sets for a stereotype S,
we report the encouraging results of Table 1 above.
</bodyText>
<sectionHeader confidence="0.934632" genericHeader="method">
5 Re-shaping Affect in Figurative Contexts
</sectionHeader>
<bodyText confidence="0.999978375">
The Google n-grams are a rich source of affective
metaphors of the form Target is Source, such as
“politicians are crooks”, “Apple is a cult”, “racism
is a disease” and “Steve Jobs is a god”. Let src(T)
denote the set of stereotypes that are commonly
used to describe T, where commonality is defined
as the presence of the corresponding copula meta-
phor in the Google n-grams. Thus, for example:
</bodyText>
<equation confidence="0.94867275">
src(racism) = {problem, disease, poison, sin,
crime, ideology, weapon, ...}
src(Hitler) = {monster, criminal, tyrant, idiot,
madman, vegetarian, racist, ...}
</equation>
<bodyText confidence="0.9995195">
Let srcTypical(T) denote the aggregation of all
properties ascribable to T via metaphors in src(T):
</bodyText>
<equation confidence="0.9869565">
U
(9) srcTypical (T) = MEsrc(T)
</equation>
<bodyText confidence="0.99982125">
We can also use the posTypical and negTypical
variants in (7) and (8) to focus only on metaphors
that project positive or negative qualities onto T.
In effect, (9) provides a feature representation
for a topic T as viewed through the prism of meta-
phor. This is useful when the source S in the meta-
phor T is S is not a known stereotype in the
lexicon, as happens e.g. in Apple is Scientology.
We can also estimate whether a given term S is
more positive than negative by taking the average
pos/neg valence of src(S). Such estimates are 87%
correct when evaluated using +R and -R examples.
</bodyText>
<equation confidence="0.882807333333333">
(10) salient (T,S) = |srcTypical(T) U typical(T)|
n
|srcTypical(S) U typical(S)|
In the context of T is S, the figurative perspective
M E src(S)Usrc(T)U{S} is deemed apt for T if:
(11) apt(M, T,S) = |salient(T,S) n typical(M) |&gt; 0
</equation>
<bodyText confidence="0.936076">
and the degree to which M is apt for T is given by:
</bodyText>
<equation confidence="0.9145385">
(12) aptness(M,T,S) = |salient(T, S) n typical(M)|
|typical(M)|
</equation>
<bodyText confidence="0.9875688">
We can construct an interpretation for T is S by
considering not just {S}, but the stereotypes in
src(T) that are apt for T in the context of T is S, as
well as the stereotypes that are commonly used to
describe S – that is, src(S) – that are also apt for T:
</bodyText>
<equation confidence="0.7753735">
(13) interpretation(T, S)
= {M|M E src(T)Usrc(S)U{S} n apt(M, T, S)}
</equation>
<bodyText confidence="0.99339225">
The elements {Mi} of interpretation(T, S) can now
be sorted by aptness(Mi T, S) to produce a ranked
list of interpretations (M1, M2 É Mn). For any in-
terpretation M, the salient features of M are thus:
</bodyText>
<equation confidence="0.544535">
(14) salient(M, T,S) = typical(M) n salient (T,S)
</equation>
<bodyText confidence="0.999687222222222">
So interpretation(T, S) is an expansion of the af-
fective metaphor T is S that includes the common
metaphors that are consistent with T qua S. For
instance, “Google is -Microsoft” (where - indicates
a negative spin) produces {monopoly, threat, bully,
giant, dinosaur, demon, ...}. For each Mi in inter-
pretation(T, S), salient(Mi, T, S) is an expansion of
Mi that includes all of the qualities that are apt for
T qua Mi (e.g. threatening, sprawling, evil, etc.).
</bodyText>
<sectionHeader confidence="0.986781" genericHeader="method">
6 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.970504375">
Metaphor is the perfect tool for influencing the
perceived affect of words and concepts in context.
The web application Metaphor Magnet provides a
proof-of-concept demonstration of this re-shaping
process at work, using the stereotype lexicon of §3,
the selective highlighting of (7)–(8), and the model
of metaphor in (9)–(14). It can be accessed at:
http://boundinanutshell.com/metaphor-magnet
</bodyText>
<equation confidence="0.673052">
typical(M)
</equation>
<page confidence="0.994317">
78
</page>
<sectionHeader confidence="0.978496" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<note confidence="0.8379042">
This research was supported by the WCU (World
Class University) program under the National Re-
search Foundation of Korea, and funded by the
Ministry of Education, Science and Technology of
Korea (Project No: R31-30007).
</note>
<sectionHeader confidence="0.997926" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999251428571429">
Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram
Version 1. Linguistic Data Consortium.
Paul Ekman. 1993. Facial expression of emotion. Amer-
ican Psychologist, 48:384-392.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
WordNet: A publicly available lexical resource for
opinion mining. Proc. of LREC-2006, the 5th Confer-
ence on Language Resources and Evaluation, 417-
422.
Andrea Esuli and Fabrizio Sebastiani. 2007. PageRank-
ing WordNet Synsets: An application to opinion min-
ing. Proc. of ACL-2007, the 45th Annual Meeting of
the Association for Computational Linguistics.
Hugo Liu, Henry Lieberman, and Ted Selker. 2003. A
Model of Textual Affect Sensing Using Real-World
Knowledge. Proceedings of the 8th international con-
ference on Intelligent user interfaces, pp. 125-132.
Rada Mihalcea and Paul Tarau. 2004. TextRank: Bring-
ing Order to Texts. Proceedings of EMNLP-04, the
2004 Conference on Empirical Methods in Natural
Language Processing.
Saif F. Mohammad and Peter D. Turney. 2010. Emo-
tions evoked by common words and phrases: Using
Mechanical Turk to create an emotional lexicon. Pro-
ceedings of the NAACL-HLT 2010 workshop on
Computational Approaches to Analysis and Genera-
tion of Emotion in Text. Los Angeles, CA.
Saif F. Mohammad and Tony Yang. 2011. Tracking
sentiment in mail: how genders differ on emotional
axes. Proceedings of the ACL 2011 WASSA work-
shop on Computational Approaches to Subjectivity
and Sentiment Analysis, Portland, Oregon.
Robert Plutchik. 1980. A general psycho-evolutionary
theory of emotion. Emotion: Theory, research and
experience, 2(1-2):1-135.
Push Singh. 2002. The public acquisition of com-
monsense knowledge. Proceedings of AAAI Spring
Symposium on Acquiring (and Using) Linguistic
(and World) Knowledge for Information Ac-
cess. Palo Alto, CA.
Carlo Strapparava and Alessandro Valitutti. 2004.
Wordnet-affect: an affective extension of Word-
net. Proceedings of LREC-2004, the 4th International
Conference on Language Resources and Evaluation,
Lisbon, Portugal.
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientation of words using
spin model. Proceedings of the 43rd Annual Meeting
of the ACL, 133–140.
Turney, P. D. Thumbs Up or Thumbs Down? Semantic
Orientation Applied to Unsupervised Classification
of Reviews. In Proceedings of ACL-2002, the 40th
Annual Meeting of the Association for Computation-
al Linguistics, pp. 417–424. June 2002.
Veale, T. and Hao, Y. Making Lexical Ontologies Func-
tional and Context-Sensitive. Proceedings of ACL-
2007, the 45th Annual Meeting of the Association of
Computational Linguistics, pp. 57–64. June 2007.
Veale, T. and Hao, Y. Detecting Ironic Intent in Crea-
tive Comparisons. Proceedings of ECAI’2010, the
19th European Conference on Artificial Intelligence,
Lisbon. August 2010.
Veale, T. Creative Language Retrieval: A Robust Hy-
brid of Information Retrieval and Linguistic Creativi-
ty. Proceedings of ACL’2011, the 49th Annual
Meeting of the Association of Computational Lin-
guistics. June 2011.
Whissell, C. The dictionary of affect in language. In R.
Plutchik and H. Kellerman (Eds.) Emotion: Theory
and research. Harcourt Brace, pp. 113-131. 1989.
</reference>
<page confidence="0.999015">
79
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.232252">
<title confidence="0.998605">A Context-sensitive, Multi-faceted model of Lexico-Conceptual Affect</title>
<author confidence="0.990976">Tony</author>
<affiliation confidence="0.775883">Web Science and Technology KAIST,</affiliation>
<address confidence="0.349778">South</address>
<email confidence="0.986673">Tony.Veale@gmail.com</email>
<abstract confidence="0.998324538461538">Since we can ‘spin’ words and concepts to suit our affective needs, context is a major determinant of the perceived affect of a word or concept. We view this re-profiling as a selective emphasis or de-emphasis of the qualities that underpin our shared stereotype of a concept or a word meaning, and construct our model of the affective lexicon accordingly. We show how a large body of affective stereotypes can be acquired from the web, and also show how these are used to create and interpret affective metaphors.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1T 5-gram Version 1. Linguistic Data Consortium.</title>
<date>2006</date>
<contexts>
<context position="8270" citStr="Brants &amp; Franz, 2006" startWordPosition="1347" endWordPosition="1350">or each property and behavior, and for the stereotypes that exhibit them. Expanding on the approach in Veale (2011), we use two kinds of query for harvesting stereotypes from the web. The first, “as ADJ as a NOUN”, acquires typical adjectival properties for noun concepts; the second, “VERB+ing like a NOUN” and “VERB+ed like a NOUN”, acquires typical verb behaviors. Rather than use a wildcard * in both positions (ADJ and NOUN, or VERB and NOUN), which gives limited results with a search engine like Google, we generate fully instantiated similes from hypotheses generated via the Google n-grams (Brants &amp; Franz, 2006). Thus, from the 3-gram “a drooling zombie” we generate the query “drooling like a zombie”, and from the 3-gram “a mindless zombie” we generate “as mindless as a zombie”. Only those queries that retrieve one or more Web documents via the Google API indicate the most promising associations. This still gives us over 250,000 web-validated simile associations for our stereotypical model, and we filter these manually, to ensure that the lexicon is both reusable and 76 of the highest quality. We obtain rich descriptions for many stereotypical ideas, such as Baby, which is described via 163 typical p</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram Version 1. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ekman</author>
</authors>
<title>Facial expression of emotion.</title>
<date>1993</date>
<journal>American Psychologist,</journal>
<pages>48--384</pages>
<contexts>
<context position="3974" citStr="Ekman (1993)" startWordPosition="649" endWordPosition="650">gs were sought along the eight dimensions identified in Plutchik (1980) as primary emotions: trust , anger, anticipation, disgust, fear, joy, sadness and surprise. Automated tests were used to exclude unsuitable raters. In all, 24,000+ wordsense pairs were annotated by five different raters. 75 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 75–79, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Liu et al. (2003) also present a multidimensional affective model that uses the six basic emotion categories of Ekman (1993) as its dimensions: happy, sad, angry, fearful, disgusted and surprised. These authors base estimates of affect on the contents of Open Mind, a common-sense knowledgebase (Singh, 2002) harvested from contributions of web volunteers. These contents are treated as sentential objects, and a range of NLP models is used to derive affective labels for the subset of contents (~10%) that appear to convey an emotional stance. These labels are then propagated to related concepts (e.g., excitement is propagated from rollercoasters to amusement parks) so that the implicit affect of many other concepts can</context>
</contexts>
<marker>Ekman, 1993</marker>
<rawString>Paul Ekman. 1993. Facial expression of emotion. American Psychologist, 48:384-392.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SentiWordNet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>Proc. of LREC-2006, the 5th Conference on Language Resources and Evaluation,</booktitle>
<pages>417--422</pages>
<contexts>
<context position="4979" citStr="Esuli and Sebastiani (2006)" startWordPosition="803" endWordPosition="806">that appear to convey an emotional stance. These labels are then propagated to related concepts (e.g., excitement is propagated from rollercoasters to amusement parks) so that the implicit affect of many other concepts can be determined. Strapparava and Valitutti (2004) provide a set of affective annotations for a subset of WordNet’s synsets in a resource called Wordnet-affect. The annotation labels, called a-labels, focus on the cognitive dynamics of emotion, allowing one to distinguish e.g. between words that denote an emotion-eliciting situation and those than denote an emotional response. Esuli and Sebastiani (2006) also build directly on WordNet as their lexical platform, using a semi-supervised learning algorithm to assign a trio of numbers – positivity, negativity and neutrality – to word senses in their newly derived resource, SentiWordNet. (Wordnet-affect also supports these three dimensions as a-labels, and adds a fourth, ambiguous). Esuli &amp; Sebastiani (2007) improve on their affect scores by running a variant of the PageRank algorithm (see also Mihalcea and Tarau, 2004) on the graph structure that tacitly connects word-senses in WordNet to each other via the words used in their textual glosses. Th</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. SentiWordNet: A publicly available lexical resource for opinion mining. Proc. of LREC-2006, the 5th Conference on Language Resources and Evaluation, 417-422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>PageRanking WordNet Synsets: An application to opinion mining.</title>
<date>2007</date>
<booktitle>Proc. of ACL-2007, the 45th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5335" citStr="Esuli &amp; Sebastiani (2007)" startWordPosition="857" endWordPosition="860">called Wordnet-affect. The annotation labels, called a-labels, focus on the cognitive dynamics of emotion, allowing one to distinguish e.g. between words that denote an emotion-eliciting situation and those than denote an emotional response. Esuli and Sebastiani (2006) also build directly on WordNet as their lexical platform, using a semi-supervised learning algorithm to assign a trio of numbers – positivity, negativity and neutrality – to word senses in their newly derived resource, SentiWordNet. (Wordnet-affect also supports these three dimensions as a-labels, and adds a fourth, ambiguous). Esuli &amp; Sebastiani (2007) improve on their affect scores by running a variant of the PageRank algorithm (see also Mihalcea and Tarau, 2004) on the graph structure that tacitly connects word-senses in WordNet to each other via the words used in their textual glosses. These lexica attempt to capture the affective profile of a word/sense when it is used in its most normative and stereotypical guise, but they do so without an explicit model of stereotypical meaning. Veale &amp; Hao (2007) describe a web-based approach to acquiring such a model. They note that since the simile pattern “as ADJ as DET NOUN” presupposes that NOUN</context>
</contexts>
<marker>Esuli, Sebastiani, 2007</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2007. PageRanking WordNet Synsets: An application to opinion mining. Proc. of ACL-2007, the 45th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hugo Liu</author>
<author>Henry Lieberman</author>
<author>Ted Selker</author>
</authors>
<title>A Model of Textual Affect Sensing Using Real-World Knowledge.</title>
<date>2003</date>
<booktitle>Proceedings of the 8th international conference on Intelligent user interfaces,</booktitle>
<pages>125--132</pages>
<contexts>
<context position="3867" citStr="Liu et al. (2003)" startWordPosition="630" endWordPosition="633">mad &amp; Yang (2011) thus used the Mechanical Turk to elicit human ratings of the emotional content of words. Ratings were sought along the eight dimensions identified in Plutchik (1980) as primary emotions: trust , anger, anticipation, disgust, fear, joy, sadness and surprise. Automated tests were used to exclude unsuitable raters. In all, 24,000+ wordsense pairs were annotated by five different raters. 75 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 75–79, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Liu et al. (2003) also present a multidimensional affective model that uses the six basic emotion categories of Ekman (1993) as its dimensions: happy, sad, angry, fearful, disgusted and surprised. These authors base estimates of affect on the contents of Open Mind, a common-sense knowledgebase (Singh, 2002) harvested from contributions of web volunteers. These contents are treated as sentential objects, and a range of NLP models is used to derive affective labels for the subset of contents (~10%) that appear to convey an emotional stance. These labels are then propagated to related concepts (e.g., excitement i</context>
<context position="6826" citStr="Liu et al. (2003)" startWordPosition="1112" endWordPosition="1115">stimates the pleasantness of a term like snake or artist as a weighted average of the pleasantness of its properties (like sneaky or creative) in a resource like Whissell’s DoA, then the estimated scores show a reliable correlation with the DoA’s own scores. It thus makes computational sense to calculate the affect of a word-concept as a function of the affect of its most salient properties. Veale (2011) later built on this work to show how a property-rich stereotypical representation could be used for non-literal matching and retrieval of creative texts, such as metaphors and analogies. Both Liu et al. (2003) and Veale &amp; Hao (2010) argue for the importance of common-sense knowledge in the determination of affect. We incorporate ideas from both here, while choosing to build mainly on the latter, to construct a nuanced, two-level model of the affective lexicon. 3 An Affective Lexicon of Stereotypes We construct the stereotype-based lexicon in two stages. For the first layer, a large collection of stereotypical descriptions is harvested from the web. As in Liu et al. (2003), our goal is to acquire a lightweight common-sense representation of many everyday concepts. For the second layer, we link these</context>
</contexts>
<marker>Liu, Lieberman, Selker, 2003</marker>
<rawString>Hugo Liu, Henry Lieberman, and Ted Selker. 2003. A Model of Textual Affect Sensing Using Real-World Knowledge. Proceedings of the 8th international conference on Intelligent user interfaces, pp. 125-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>TextRank: Bringing Order to Texts.</title>
<date>2004</date>
<booktitle>Proceedings of EMNLP-04, the 2004 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="5449" citStr="Mihalcea and Tarau, 2004" startWordPosition="876" endWordPosition="880">g one to distinguish e.g. between words that denote an emotion-eliciting situation and those than denote an emotional response. Esuli and Sebastiani (2006) also build directly on WordNet as their lexical platform, using a semi-supervised learning algorithm to assign a trio of numbers – positivity, negativity and neutrality – to word senses in their newly derived resource, SentiWordNet. (Wordnet-affect also supports these three dimensions as a-labels, and adds a fourth, ambiguous). Esuli &amp; Sebastiani (2007) improve on their affect scores by running a variant of the PageRank algorithm (see also Mihalcea and Tarau, 2004) on the graph structure that tacitly connects word-senses in WordNet to each other via the words used in their textual glosses. These lexica attempt to capture the affective profile of a word/sense when it is used in its most normative and stereotypical guise, but they do so without an explicit model of stereotypical meaning. Veale &amp; Hao (2007) describe a web-based approach to acquiring such a model. They note that since the simile pattern “as ADJ as DET NOUN” presupposes that NOUN is an exemplar of ADJness, it follows that ADJ must be a highly salient property of NOUN. Veale &amp; Hao harvested t</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. TextRank: Bringing Order to Texts. Proceedings of EMNLP-04, the 2004 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif F Mohammad</author>
<author>Peter D Turney</author>
</authors>
<title>Emotions evoked by common words and phrases: Using Mechanical Turk to create an emotional lexicon.</title>
<date>2010</date>
<booktitle>Proceedings of the NAACL-HLT 2010 workshop on Computational Approaches to Analysis and Generation of Emotion in Text.</booktitle>
<location>Los Angeles, CA.</location>
<contexts>
<context position="3240" citStr="Mohammad &amp; Turney (2010)" startWordPosition="532" endWordPosition="536">hissell’s (1989) Dictionary of Affect (or DoA) assigns a trio of scores to each of its 8000+ words to describe three psycholinguistic dimensions: pleasantness, activation and imagery. In the DoA, the lowest pleasantness score of 1.0 is assigned to words like abnormal and ugly, while the highest, 3.0, is assigned to words like wedding and winning. Though Whissell’s DoA is based on human ratings, Turney (2002) shows how affective valence can be derived from measures of word association in web texts. Human intuitions are prized in matters of lexical affect. For reliable results on a large-scale, Mohammad &amp; Turney (2010) and Mohammad &amp; Yang (2011) thus used the Mechanical Turk to elicit human ratings of the emotional content of words. Ratings were sought along the eight dimensions identified in Plutchik (1980) as primary emotions: trust , anger, anticipation, disgust, fear, joy, sadness and surprise. Automated tests were used to exclude unsuitable raters. In all, 24,000+ wordsense pairs were annotated by five different raters. 75 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 75–79, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Li</context>
</contexts>
<marker>Mohammad, Turney, 2010</marker>
<rawString>Saif F. Mohammad and Peter D. Turney. 2010. Emotions evoked by common words and phrases: Using Mechanical Turk to create an emotional lexicon. Proceedings of the NAACL-HLT 2010 workshop on Computational Approaches to Analysis and Generation of Emotion in Text. Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif F Mohammad</author>
<author>Tony Yang</author>
</authors>
<title>Tracking sentiment in mail: how genders differ on emotional axes.</title>
<date>2011</date>
<booktitle>Proceedings of the ACL 2011 WASSA workshop on Computational Approaches to Subjectivity and Sentiment Analysis,</booktitle>
<location>Portland, Oregon.</location>
<contexts>
<context position="3267" citStr="Mohammad &amp; Yang (2011)" startWordPosition="538" endWordPosition="541">f Affect (or DoA) assigns a trio of scores to each of its 8000+ words to describe three psycholinguistic dimensions: pleasantness, activation and imagery. In the DoA, the lowest pleasantness score of 1.0 is assigned to words like abnormal and ugly, while the highest, 3.0, is assigned to words like wedding and winning. Though Whissell’s DoA is based on human ratings, Turney (2002) shows how affective valence can be derived from measures of word association in web texts. Human intuitions are prized in matters of lexical affect. For reliable results on a large-scale, Mohammad &amp; Turney (2010) and Mohammad &amp; Yang (2011) thus used the Mechanical Turk to elicit human ratings of the emotional content of words. Ratings were sought along the eight dimensions identified in Plutchik (1980) as primary emotions: trust , anger, anticipation, disgust, fear, joy, sadness and surprise. Automated tests were used to exclude unsuitable raters. In all, 24,000+ wordsense pairs were annotated by five different raters. 75 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 75–79, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Liu et al. (2003)</context>
</contexts>
<marker>Mohammad, Yang, 2011</marker>
<rawString>Saif F. Mohammad and Tony Yang. 2011. Tracking sentiment in mail: how genders differ on emotional axes. Proceedings of the ACL 2011 WASSA workshop on Computational Approaches to Subjectivity and Sentiment Analysis, Portland, Oregon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Plutchik</author>
</authors>
<title>A general psycho-evolutionary theory of emotion. Emotion: Theory, research and experience,</title>
<date>1980</date>
<pages>2--1</pages>
<contexts>
<context position="3433" citStr="Plutchik (1980)" startWordPosition="567" endWordPosition="568">west pleasantness score of 1.0 is assigned to words like abnormal and ugly, while the highest, 3.0, is assigned to words like wedding and winning. Though Whissell’s DoA is based on human ratings, Turney (2002) shows how affective valence can be derived from measures of word association in web texts. Human intuitions are prized in matters of lexical affect. For reliable results on a large-scale, Mohammad &amp; Turney (2010) and Mohammad &amp; Yang (2011) thus used the Mechanical Turk to elicit human ratings of the emotional content of words. Ratings were sought along the eight dimensions identified in Plutchik (1980) as primary emotions: trust , anger, anticipation, disgust, fear, joy, sadness and surprise. Automated tests were used to exclude unsuitable raters. In all, 24,000+ wordsense pairs were annotated by five different raters. 75 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 75–79, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Liu et al. (2003) also present a multidimensional affective model that uses the six basic emotion categories of Ekman (1993) as its dimensions: happy, sad, angry, fearful, disgusted a</context>
</contexts>
<marker>Plutchik, 1980</marker>
<rawString>Robert Plutchik. 1980. A general psycho-evolutionary theory of emotion. Emotion: Theory, research and experience, 2(1-2):1-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Push Singh</author>
</authors>
<title>The public acquisition of commonsense knowledge.</title>
<date>2002</date>
<booktitle>Proceedings of AAAI Spring Symposium on Acquiring (and Using) Linguistic (and World) Knowledge for Information Access.</booktitle>
<location>Palo Alto, CA.</location>
<contexts>
<context position="4158" citStr="Singh, 2002" startWordPosition="678" endWordPosition="679"> used to exclude unsuitable raters. In all, 24,000+ wordsense pairs were annotated by five different raters. 75 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 75–79, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Liu et al. (2003) also present a multidimensional affective model that uses the six basic emotion categories of Ekman (1993) as its dimensions: happy, sad, angry, fearful, disgusted and surprised. These authors base estimates of affect on the contents of Open Mind, a common-sense knowledgebase (Singh, 2002) harvested from contributions of web volunteers. These contents are treated as sentential objects, and a range of NLP models is used to derive affective labels for the subset of contents (~10%) that appear to convey an emotional stance. These labels are then propagated to related concepts (e.g., excitement is propagated from rollercoasters to amusement parks) so that the implicit affect of many other concepts can be determined. Strapparava and Valitutti (2004) provide a set of affective annotations for a subset of WordNet’s synsets in a resource called Wordnet-affect. The annotation labels, ca</context>
</contexts>
<marker>Singh, 2002</marker>
<rawString>Push Singh. 2002. The public acquisition of commonsense knowledge. Proceedings of AAAI Spring Symposium on Acquiring (and Using) Linguistic (and World) Knowledge for Information Access. Palo Alto, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Alessandro Valitutti</author>
</authors>
<title>Wordnet-affect: an affective extension of Wordnet.</title>
<date>2004</date>
<booktitle>Proceedings of LREC-2004, the 4th International Conference on Language Resources and Evaluation,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="4622" citStr="Strapparava and Valitutti (2004)" startWordPosition="750" endWordPosition="753">ns: happy, sad, angry, fearful, disgusted and surprised. These authors base estimates of affect on the contents of Open Mind, a common-sense knowledgebase (Singh, 2002) harvested from contributions of web volunteers. These contents are treated as sentential objects, and a range of NLP models is used to derive affective labels for the subset of contents (~10%) that appear to convey an emotional stance. These labels are then propagated to related concepts (e.g., excitement is propagated from rollercoasters to amusement parks) so that the implicit affect of many other concepts can be determined. Strapparava and Valitutti (2004) provide a set of affective annotations for a subset of WordNet’s synsets in a resource called Wordnet-affect. The annotation labels, called a-labels, focus on the cognitive dynamics of emotion, allowing one to distinguish e.g. between words that denote an emotion-eliciting situation and those than denote an emotional response. Esuli and Sebastiani (2006) also build directly on WordNet as their lexical platform, using a semi-supervised learning algorithm to assign a trio of numbers – positivity, negativity and neutrality – to word senses in their newly derived resource, SentiWordNet. (Wordnet-</context>
</contexts>
<marker>Strapparava, Valitutti, 2004</marker>
<rawString>Carlo Strapparava and Alessandro Valitutti. 2004. Wordnet-affect: an affective extension of Wordnet. Proceedings of LREC-2004, the 4th International Conference on Language Resources and Evaluation, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting semantic orientation of words using spin model.</title>
<date>2005</date>
<booktitle>Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>133--140</pages>
<contexts>
<context position="11074" citStr="Takamura et al. (2005)" startWordPosition="1863" endWordPosition="1866"> build a reference set -R of typically negative words, and a set +R of typically positive words. Given a few seed members of -R (such as sad, evil, etc.) and a few seed members of +R (such as happy, wonderful, etc.), we find many other candidates to add to +R and -R by considering neighbors of these seeds in N. After just three iterations, +R and -R contain ~2000 words each. For a property p, we define N+(p) and N-(p) as (1) N+(p) = N(p) n +R (2) N-(p) = N(p) n -R We assign pos/neg valence scores to each property p by interpolating from reference values to their neighbors in N. Unlike that of Takamura et al. (2005), the approach is non-iterative and involves no feedback between the nodes of N, and thus, no inter-dependence between adjacent affect scores: (3) pos(p) = |N+(p)| |N+(p) U N-(p)| (4) neg(p) = 1 - pos(p) If a term S denotes a stereotypical idea and is described via a set of typical properties and behaviors typical(S) in the lexicon, then: (5) pos(S) = pos(p) IpEtypical(S) |typical(S)| (6) neg(S) = 1 - pos(S) Thus, (5) and (6) calculate the mean affect of the properties and behaviors of S, as represented via typical(S). We can now use (3) and (4) to separate typical(S) into those elements that </context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientation of words using spin model. Proceedings of the 43rd Annual Meeting of the ACL, 133–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL-2002, the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>417--424</pages>
<contexts>
<context position="3027" citStr="Turney (2002)" startWordPosition="499" endWordPosition="500">of NLP phenomena – affective metaphor. 2 Related Work and Ideas In its simplest form, an affect lexicon assigns an affective score – along one or more dimensions – to each word or sense. For instance, Whissell’s (1989) Dictionary of Affect (or DoA) assigns a trio of scores to each of its 8000+ words to describe three psycholinguistic dimensions: pleasantness, activation and imagery. In the DoA, the lowest pleasantness score of 1.0 is assigned to words like abnormal and ugly, while the highest, 3.0, is assigned to words like wedding and winning. Though Whissell’s DoA is based on human ratings, Turney (2002) shows how affective valence can be derived from measures of word association in web texts. Human intuitions are prized in matters of lexical affect. For reliable results on a large-scale, Mohammad &amp; Turney (2010) and Mohammad &amp; Yang (2011) thus used the Mechanical Turk to elicit human ratings of the emotional content of words. Ratings were sought along the eight dimensions identified in Plutchik (1980) as primary emotions: trust , anger, anticipation, disgust, fear, joy, sadness and surprise. Automated tests were used to exclude unsuitable raters. In all, 24,000+ wordsense pairs were annotate</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Turney, P. D. Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews. In Proceedings of ACL-2002, the 40th Annual Meeting of the Association for Computational Linguistics, pp. 417–424. June 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Veale</author>
<author>Y Hao</author>
</authors>
<title>Making Lexical Ontologies Functional and Context-Sensitive.</title>
<date>2007</date>
<booktitle>Proceedings of ACL2007, the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="5795" citStr="Veale &amp; Hao (2007)" startWordPosition="936" endWordPosition="939">wly derived resource, SentiWordNet. (Wordnet-affect also supports these three dimensions as a-labels, and adds a fourth, ambiguous). Esuli &amp; Sebastiani (2007) improve on their affect scores by running a variant of the PageRank algorithm (see also Mihalcea and Tarau, 2004) on the graph structure that tacitly connects word-senses in WordNet to each other via the words used in their textual glosses. These lexica attempt to capture the affective profile of a word/sense when it is used in its most normative and stereotypical guise, but they do so without an explicit model of stereotypical meaning. Veale &amp; Hao (2007) describe a web-based approach to acquiring such a model. They note that since the simile pattern “as ADJ as DET NOUN” presupposes that NOUN is an exemplar of ADJness, it follows that ADJ must be a highly salient property of NOUN. Veale &amp; Hao harvested tens of thousands of instances of this pattern from the Web, to extract sets of adjectival properties for thousands of commonplace nouns. They show that if one estimates the pleasantness of a term like snake or artist as a weighted average of the pleasantness of its properties (like sneaky or creative) in a resource like Whissell’s DoA, then the</context>
</contexts>
<marker>Veale, Hao, 2007</marker>
<rawString>Veale, T. and Hao, Y. Making Lexical Ontologies Functional and Context-Sensitive. Proceedings of ACL2007, the 45th Annual Meeting of the Association of Computational Linguistics, pp. 57–64. June 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Veale</author>
<author>Y Hao</author>
</authors>
<title>Detecting Ironic Intent in Creative Comparisons.</title>
<date>2010</date>
<booktitle>Proceedings of ECAI’2010, the 19th European Conference on Artificial Intelligence,</booktitle>
<location>Lisbon.</location>
<contexts>
<context position="6849" citStr="Veale &amp; Hao (2010)" startWordPosition="1117" endWordPosition="1120">ess of a term like snake or artist as a weighted average of the pleasantness of its properties (like sneaky or creative) in a resource like Whissell’s DoA, then the estimated scores show a reliable correlation with the DoA’s own scores. It thus makes computational sense to calculate the affect of a word-concept as a function of the affect of its most salient properties. Veale (2011) later built on this work to show how a property-rich stereotypical representation could be used for non-literal matching and retrieval of creative texts, such as metaphors and analogies. Both Liu et al. (2003) and Veale &amp; Hao (2010) argue for the importance of common-sense knowledge in the determination of affect. We incorporate ideas from both here, while choosing to build mainly on the latter, to construct a nuanced, two-level model of the affective lexicon. 3 An Affective Lexicon of Stereotypes We construct the stereotype-based lexicon in two stages. For the first layer, a large collection of stereotypical descriptions is harvested from the web. As in Liu et al. (2003), our goal is to acquire a lightweight common-sense representation of many everyday concepts. For the second layer, we link these common-sense qualities</context>
</contexts>
<marker>Veale, Hao, 2010</marker>
<rawString>Veale, T. and Hao, Y. Detecting Ironic Intent in Creative Comparisons. Proceedings of ECAI’2010, the 19th European Conference on Artificial Intelligence, Lisbon. August 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Veale</author>
</authors>
<title>Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity.</title>
<date>2011</date>
<booktitle>Proceedings of ACL’2011, the 49th Annual Meeting of the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="6616" citStr="Veale (2011)" startWordPosition="1080" endWordPosition="1081">ent property of NOUN. Veale &amp; Hao harvested tens of thousands of instances of this pattern from the Web, to extract sets of adjectival properties for thousands of commonplace nouns. They show that if one estimates the pleasantness of a term like snake or artist as a weighted average of the pleasantness of its properties (like sneaky or creative) in a resource like Whissell’s DoA, then the estimated scores show a reliable correlation with the DoA’s own scores. It thus makes computational sense to calculate the affect of a word-concept as a function of the affect of its most salient properties. Veale (2011) later built on this work to show how a property-rich stereotypical representation could be used for non-literal matching and retrieval of creative texts, such as metaphors and analogies. Both Liu et al. (2003) and Veale &amp; Hao (2010) argue for the importance of common-sense knowledge in the determination of affect. We incorporate ideas from both here, while choosing to build mainly on the latter, to construct a nuanced, two-level model of the affective lexicon. 3 An Affective Lexicon of Stereotypes We construct the stereotype-based lexicon in two stages. For the first layer, a large collection</context>
</contexts>
<marker>Veale, 2011</marker>
<rawString>Veale, T. Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity. Proceedings of ACL’2011, the 49th Annual Meeting of the Association of Computational Linguistics. June 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Whissell</author>
</authors>
<title>The dictionary of affect in language. In</title>
<date>1989</date>
<pages>113--131</pages>
<marker>Whissell, 1989</marker>
<rawString>Whissell, C. The dictionary of affect in language. In R. Plutchik and H. Kellerman (Eds.) Emotion: Theory and research. Harcourt Brace, pp. 113-131. 1989.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>