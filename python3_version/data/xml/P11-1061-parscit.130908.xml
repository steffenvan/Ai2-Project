<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<title confidence="0.9916155">
Unsupervised Part-of-Speech Tagging
with Bilingual Graph-Based Projections
</title>
<author confidence="0.996578">
Dipanjan Das* Slav Petrov
</author>
<affiliation confidence="0.909648">
Carnegie Mellon University Google Research
Pittsburgh, PA 15213, USA New York, NY 10011, USA
</affiliation>
<email confidence="0.998834">
dipanjan@cs.cmu.edu slav@google.com
</email>
<sectionHeader confidence="0.996661" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998240555555555">
We describe a novel approach for inducing
unsupervised part-of-speech taggers for lan-
guages that have no labeled training data, but
have translated text in a resource-rich lan-
guage. Our method does not assume any
knowledge about the target language (in par-
ticular no tagging dictionary is assumed),
making it applicable to a wide array of
resource-poor languages. We use graph-based
label propagation for cross-lingual knowl-
edge transfer and use the projected labels
as features in an unsupervised model (Berg-
Kirkpatrick et al., 2010). Across eight Eu-
ropean languages, our approach results in an
average absolute improvement of 10.4% over
a state-of-the-art baseline, and 16.7% over
vanilla hidden Markov models induced with
the Expectation Maximization algorithm.
</bodyText>
<sectionHeader confidence="0.998884" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999856272727273">
Supervised learning approaches have advanced the
state-of-the-art on a variety of tasks in natural lan-
guage processing, resulting in highly accurate sys-
tems. Supervised part-of-speech (POS) taggers,
for example, approach the level of inter-annotator
agreement (Shen et al., 2007, 97.3% accuracy for
English). However, supervised methods rely on la-
beled training data, which is time-consuming and
expensive to generate. Unsupervised learning ap-
proaches appear to be a natural solution to this prob-
lem, as they require only unannotated text for train-
</bodyText>
<footnote confidence="0.418014">
*This research was carried out during an internship at Google
Research.
</footnote>
<bodyText confidence="0.999863866666666">
ing models. Unfortunately, the best completely un-
supervised English POS tagger (that does not make
use of a tagging dictionary) reaches only 76.1% ac-
curacy (Christodoulopoulos et al., 2010), making its
practical usability questionable at best.
To bridge this gap, we consider a practically mo-
tivated scenario, in which we want to leverage ex-
isting resources from a resource-rich language (like
English) when building tools for resource-poor for-
eign languages.1 We assume that absolutely no la-
beled training data is available for the foreign lan-
guage of interest, but that we have access to parallel
data with a resource-rich language. This scenario is
applicable to a large set of languages and has been
considered by a number of authors in the past (Al-
shawi et al., 2000; Xi and Hwa, 2005; Ganchev et
al., 2009). Naseem et al. (2009) and Snyder et al.
(2009) study related but different multilingual gram-
mar and tagger induction tasks, where it is assumed
that no labeled data at all is available.
Our work is closest to that of Yarowsky and Ngai
(2001), but differs in two important ways. First,
we use a novel graph-based framework for project-
ing syntactic information across language bound-
aries. To this end, we construct a bilingual graph
over word types to establish a connection between
the two languages (§3), and then use graph label
propagation to project syntactic information from
English to the foreign language (§4). Second, we
treat the projected labels as features in an unsuper-
</bodyText>
<footnote confidence="0.9696115">
1For simplicity of exposition we refer to the resource-poor lan-
guage as the “foreign language.” Similarly, we use English
as the resource-rich language, but any other language with la-
beled resources could be used instead.
</footnote>
<page confidence="0.862249">
600
</page>
<note confidence="0.98061">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 600–609,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999205">
vised model (§5), rather than using them directly for
supervised training. To make the projection practi-
cal, we rely on the twelve universal part-of-speech
tags of Petrov et al. (2011). Syntactic universals are
a well studied concept in linguistics (Carnie, 2002;
Newmeyer, 2005), and were recently used in similar
form by Naseem et al. (2010) for multilingual gram-
mar induction. Because there might be some contro-
versy about the exact definitions of such universals,
this set of coarse-grained POS categories is defined
operationally, by collapsing language (or treebank)
specific distinctions to a set of categories that ex-
ists across all languages. These universal POS cat-
egories not only facilitate the transfer of POS in-
formation from one language to another, but also
relieve us from using controversial evaluation met-
rics,2 by establishing a direct correspondence be-
tween the induced hidden states in the foreign lan-
guage and the observed English labels.
We evaluate our approach on eight European lan-
guages (§6), and show that both our contributions
provide consistent and statistically significant im-
provements. Our final average POS tagging accu-
racy of 83.4% compares very favorably to the av-
erage accuracy of Berg-Kirkpatrick et al.’s mono-
lingual unsupervised state-of-the-art model (73.0%),
and considerably bridges the gap to fully supervised
POS tagging performance (96.6%).
</bodyText>
<sectionHeader confidence="0.975591" genericHeader="method">
2 Approach Overview
</sectionHeader>
<bodyText confidence="0.999961266666667">
The focus of this work is on building POS taggers
for foreign languages, assuming that we have an En-
glish POS tagger and some parallel text between
the two languages. Central to our approach (see
Algorithm 1) is a bilingual similarity graph built
from a sentence-aligned parallel corpus. As dis-
cussed in more detail in §3, we use two types of
vertices in our graph: on the foreign language side
vertices correspond to trigram types, while the ver-
tices on the English side are individual word types.
Graph construction does not require any labeled
data, but makes use of two similarity functions. The
edge weights between the foreign language trigrams
are computed using a co-occurence based similar-
ity function, designed to indicate how syntactically
</bodyText>
<footnote confidence="0.9751545">
2See Christodoulopoulos et al. (2010) for a discussion of met-
rics for evaluating unsupervised POS induction systems.
</footnote>
<construct confidence="0.671318">
Algorithm 1 Bilingual POS Induction
</construct>
<listItem confidence="0.993688428571428">
Require: Parallel English and foreign language
data De and Df, unlabeled foreign training data
Ff; English tagger.
Ensure: Of, a set of parameters learned using a
constrained unsupervised model (§5).
1: De`—&apos;f +— word-align-bitext(De, Df)
�
2: De +— pos-tag-supervised(De)
3: A extract-alignments(De`-&apos;f,De)
4: G construct-graph(Ff, Df, A)
5: G graph-propagate(G)
6: A extract-word-constraints(G)
7: Of +— pos-induce-constrained(Ff, A)
8: Return Of
</listItem>
<bodyText confidence="0.99736795">
similar the middle words of the connected trigrams
are (§3.2). To establish a soft correspondence be-
tween the two languages, we use a second similar-
ity function, which leverages standard unsupervised
word alignment statistics (§3.3).3
Since we have no labeled foreign data, our goal
is to project syntactic information from the English
side to the foreign side. To initialize the graph we
tag the English side of the parallel text using a su-
pervised model. By aggregating the POS labels of
the English tokens to types, we can generate label
distributions for the English vertices. Label propa-
gation can then be used to transfer the labels to the
peripheral foreign vertices (i.e. the ones adjacent to
the English vertices) first, and then among all of the
foreign vertices (§4). The POS distributions over the
foreign trigram types are used as features to learn a
better unsupervised POS tagger (§5). The follow-
ing three sections elaborate these different stages is
more detail.
</bodyText>
<sectionHeader confidence="0.988605" genericHeader="method">
3 Graph Construction
</sectionHeader>
<bodyText confidence="0.99970175">
In graph-based learning approaches one constructs
a graph whose vertices are labeled and unlabeled
examples, and whose weighted edges encode the
degree to which the examples they link have the
same label (Zhu et al., 2003). Graph construction
for structured prediction problems such as POS tag-
ging is non-trivial: on the one hand, using individ-
ual words as the vertices throws away the context
</bodyText>
<footnote confidence="0.993886">
3The word alignment methods do not use POS information.
</footnote>
<page confidence="0.997887">
601
</page>
<bodyText confidence="0.999954571428572">
necessary for disambiguation; on the other hand,
it is unclear how to define (sequence) similarity if
the vertices correspond to entire sentences. Altun
et al. (2005) proposed a technique that uses graph
based similarity between labeled and unlabeled parts
of structured data in a discriminative framework for
semi-supervised learning. More recently, Subra-
manya et al. (2010) defined a graph over the cliques
in an underlying structured prediction model. They
considered a semi-supervised POS tagging scenario
and showed that one can use a graph over trigram
types, and edge weights based on distributional sim-
ilarity, to improve a supervised conditional random
field tagger.
</bodyText>
<subsectionHeader confidence="0.997488">
3.1 Graph Vertices
</subsectionHeader>
<bodyText confidence="0.9999464">
We extend Subramanya et al.’s intuitions to our
bilingual setup. Because the information flow in
our graph is asymmetric (from English to the foreign
language), we use different types of vertices for each
language. The foreign language vertices (denoted by
Vf) correspond to foreign trigram types, exactly as
in Subramanya et al. (2010). On the English side,
however, the vertices (denoted by Ve) correspond to
word types. Because all English vertices are going
to be labeled, we do not need to disambiguate them
by embedding them in trigrams. Furthermore, we do
not connect the English vertices to each other, but
only to foreign language vertices.4
The graph vertices are extracted from the differ-
ent sides of a parallel corpus (De, Df) and an ad-
ditional unlabeled monolingual foreign corpus Ff,
which will be used later for training. We use two dif-
ferent similarity functions to define the edge weights
among the foreign vertices and between vertices
from different languages.
</bodyText>
<subsectionHeader confidence="0.99978">
3.2 Monolingual Similarity Function
</subsectionHeader>
<bodyText confidence="0.9994384">
Our monolingual similarity function (for connecting
pairs of foreign trigram types) is the same as the one
used by Subramanya et al. (2010). We briefly re-
view it here for completeness. We define a sym-
metric similarity function K(uZ7 uj) over two for-
</bodyText>
<footnote confidence="0.9946642">
4This is because we are primarily interested in learning foreign
language taggers, rather than improving supervised English
taggers. Note, however, that it would be possible to use our
graph-based framework also for completely unsupervised POS
induction in both languages, similar to Snyder et al. (2009).
</footnote>
<figure confidence="0.9562811">
Description Feature
Trigram + Context
Trigram
Left Context
Right Context
Center Word
Trigram − Center Word
Left Word + Right Context
Left Context + Right Word
Suffix HasSuffix(x3)
</figure>
<tableCaption confidence="0.9990285">
Table 1: Various features used for computing edge
weights between foreign trigram types.
</tableCaption>
<bodyText confidence="0.999992666666667">
eign language vertices uZ7 uj E Vf based on the
co-occurrence statistics of the nine feature concepts
given in Table 1. Each feature concept is akin to a
random variable and its occurrence in the text corre-
sponds to a particular instantiation of that random
variable. For each trigram type x2 x3 x4 in a se-
quence x1 x2 x3 x4 x5, we count how many times
that trigram type co-occurs with the different instan-
tiations of each concept, and compute the point-wise
mutual information (PMI) between the two.5 The
similarity between two trigram types is given by
summing over the PMI values over feature instan-
tiations that they have in common. This is similar to
stacking the different feature instantiations into long
(sparse) vectors and computing the cosine similarity
between them. Finally, note that while most feature
concepts are lexicalized, others, such as the suffix
concept, are not.
Given this similarity function, we define a near-
est neighbor graph, where the edge weight for the n
most similar vertices is set to the value of the simi-
larity function and to 0 for all other vertices. We use
N(u) to denote the neighborhood of vertex u, and
fixed n = 5 in our experiments.
</bodyText>
<subsectionHeader confidence="0.999676">
3.3 Bilingual Similarity Function
</subsectionHeader>
<bodyText confidence="0.969753625">
To define a similarity function between the English
and the foreign vertices, we rely on high-confidence
word alignments. Since our graph is built from a
parallel corpus, we can use standard word align-
ment techniques to align the English sentences De
5Note that many combinations are impossible giving a PMI
value of 0; e.g., when the trigram type and the feature instanti-
ation don’t have words in common.
</bodyText>
<equation confidence="0.9998205">
x1 x2 x3 x4 x5
x2 x3 x4
x1 x2
x4 x5
x3
x2 x4
x2 x4 x5
x1 x2 x4
</equation>
<page confidence="0.967713">
602
</page>
<bodyText confidence="0.9999295">
and their foreign language translations Df.6 Label
propagation in the graph will provide coverage and
high recall, and we therefore extract only intersected
high-confidence (&gt; 0.9) alignments De�f.
Based on these high-confidence alignments we
can extract tuples of the form [u H v], where u is
a foreign trigram type, whose middle word aligns
to an English word type v. Our bilingual similarity
function then sets the edge weights in proportion to
these tuple counts.
</bodyText>
<subsectionHeader confidence="0.979064">
3.4 Graph Initialization
</subsectionHeader>
<bodyText confidence="0.999991272727273">
So far the graph has been completely unlabeled. To
initialize the graph for label propagation we use a su-
pervised English tagger to label the English side of
the bitext.7 We then simply count the individual la-
bels of the English tokens and normalize the counts
to produce tag distributions over English word types.
These tag distributions are used to initialize the label
distributions over the English vertices in the graph.
Note that since all English vertices were extracted
from the parallel text, we will have an initial label
distribution for all vertices in Ve.
</bodyText>
<subsectionHeader confidence="0.983633">
3.5 Graph Example
</subsectionHeader>
<bodyText confidence="0.9999896">
A very small excerpt from an Italian-English graph
is shown in Figure 1. As one can see, only the
trigrams [suo incarceramento ,], [suo iter ,] and
[suo carattere ,] are connected to English words. In
this particular case, all English vertices are labeled
as nouns by the supervised tagger. In general, the
neighborhoods can be more diverse and we allow a
soft label distribution over the vertices. It is worth
noting that the middle words of the Italian trigrams
are nouns too, which exhibits the fact that the sim-
ilarity metric connects types having the same syn-
tactic category. In the label propagation stage, we
propagate the automatic English tags to the aligned
Italian trigram types, followed by further propaga-
tion solely among the Italian vertices.
</bodyText>
<footnote confidence="0.760329666666667">
6We ran six iterations of IBM Model 1 (Brown et al., 1993),
followed by six iterations of the HMM model (Vogel et al.,
1996) in both directions.
7We used a tagger based on a trigram Markov model (Brants,
2000) trained on the Wall Street Journal portion of the Penn
Treebank (Marcus et al., 1993), for its fast speed and reason-
able accuracy (96.7% on sections 22-24 of the treebank, but
presumably much lower on the (out-of-domain) parallel cor-
pus).
</footnote>
<figureCaption confidence="0.989931">
Figure 1: An excerpt from the graph for Italian. Three of
</figureCaption>
<bodyText confidence="0.65053675">
the Italian vertices are connected to an automatically la-
beled English vertex. Label propagation is used to propa-
gate these tags inwards and results in tag distributions for
the middle word of each Italian trigram.
</bodyText>
<sectionHeader confidence="0.993983" genericHeader="method">
4 POS Projection
</sectionHeader>
<bodyText confidence="0.999936368421053">
Given the bilingual graph described in the previous
section, we can use label propagation to project the
English POS labels to the foreign language. We use
label propagation in two stages to generate soft la-
bels on all the vertices in the graph. In the first stage,
we run a single step of label propagation, which
transfers the label distributions from the English
vertices to the connected foreign language vertices
(say, Vf�) at the periphery of the graph. Note that
because we extracted only high-confidence align-
ments, many foreign vertices will not be connected
to any English vertices. This stage of label propa-
gation results in a tag distribution ri over labels y,
which encodes the proportion of times the middle
word of ui E Vf aligns to English words vy tagged
with label y:
The second stage consists of running traditional
label propagation to propagate labels from these pe-
ripheral vertices Vf� to all foreign language vertices
</bodyText>
<figure confidence="0.974384043478261">
NOUN
[ imprisonment ]
NOUN
[ enactment ]
[ suo incarceramento , ]
[ al fidanzato e ]
[ suo iter , ]
[ suo fidanzato , ]
[ suo carattere , ]
[ il fidanzato , ]
[ del fidanzato , ]
[ character ]
NOUN
E
vy
(1)
E
y&apos;
E
vy1
#[ui H vy]
#[ui H vyI]
ri(y) =
</figure>
<page confidence="0.991776">
603
</page>
<bodyText confidence="0.974996">
in the graph, optimizing the following objective: 5 POS Induction
</bodyText>
<equation confidence="0.99326775">
C(q) = E wijkqi − qjk2
uiEVf \Vf� ,ujEN(ui)
E+ ν kqi − Uk2
uiEVf\Vf�
</equation>
<bodyText confidence="0.996834">
After running label propagation (LP), we com-
pute tag probabilities for foreign word types x by
marginalizing the POS tag distributions of foreign
trigrams ui = x− x x+ over the left and right con-
text words:
</bodyText>
<equation confidence="0.9774374">
s.t. E qi(y) = 1 ∀ui
y
qi(y) ≥ 0 ∀ui, y
qi = ri ∀ui ∈ V l (2)
f
</equation>
<bodyText confidence="0.99999156">
where the qi (i = 1, ... , |Vf|) are the label distribu-
tions over the foreign language vertices and µ and
ν are hyperparameters that we discuss in §6.4. We
use a squared loss to penalize neighboring vertices
that have different label distributions: kqi − qjk2 =
Ey(qi(y) − qj(y))2, and additionally regularize the
label distributions towards the uniform distribution
U over all possible labels Y. It can be shown that
this objective is convex in q.
The first term in the objective function is the graph
smoothness regularizer which encourages the distri-
butions of similar vertices (large wij) to be similar.
The second term is a regularizer and encourages all
type marginals to be uniform to the extent that is al-
lowed by the first two terms (cf. maximum entropy
principle). If an unlabeled vertex does not have a
path to any labeled vertex, this term ensures that the
converged marginal for this vertex will be uniform
over all tags, allowing the middle word of such an
unlabeled vertex to take on any of the possible tags.
While it is possible to derive a closed form so-
lution for this convex objective function, it would
require the inversion of a matrix of order |Vf|. In-
stead, we resort to an iterative update based method.
We formulate the update as follows:
</bodyText>
<equation confidence="0.92139">
ri(y) if ui ∈ Vfl
γi(y) (3) otherwise
κi
</equation>
<bodyText confidence="0.846001">
where ∀ui ∈ Vf \ Vfl, γi(y) and κi are defined as:
</bodyText>
<equation confidence="0.9932244">
E wijqj (y) + ν U(y) (4)
γi(y) = (m−1)
ujEN(ui)
Eκi = ν + wij (5)
ujEN(ui)
</equation>
<bodyText confidence="0.978525">
We ran this procedure for 10 iterations.
We then extract a set of possible tags tx(y) by elimi-
nating labels whose probability is below a threshold
value τ:
</bodyText>
<equation confidence="0.969864">
�
1 if p(y|x) ≥ τ
tx(y) = (7)
0 otherwise
</equation>
<bodyText confidence="0.9999645">
We describe how we choose τ in §6.4. This vector
tx is constructed for every word in the foreign vo-
cabulary and will be used to provide features for the
unsupervised foreign language POS tagger.
We develop our POS induction model based on
the feature-based HMM of Berg-Kirkpatrick et al.
(2010). For a sentence x and a state sequence z, a
first order Markov model defines a distribution:
</bodyText>
<equation confidence="0.998447">
PΘ(X = x,Z = z) = PΘ(Z1 = z1)·
jl���
i=1 PΘ(Zi+1 = zi+1  |Zi = zi)
�
PΘ(Xi = xi  |Zi=zi)
� Y �
emission
Eexp OTf(x&apos;, z)
x&apos;EVal(X)
</equation>
<bodyText confidence="0.936382142857143">
(9)
where Val(X) corresponds to the entire vocabulary.
This locally normalized log-linear model can look at
various aspects of the observation x, incorporating
overlapping features of the observation. In our ex-
periments, we used the same set of features as Berg-
Kirkpatrick et al. (2010): an indicator feature based
</bodyText>
<equation confidence="0.932666533333333">
qi (y) =
(m)
{
E
x−,x+
E
x−,x+,y,
(6)
qi(y�)
p(y|x) =
qi(y)
Y
transition
·
(8)
</equation>
<bodyText confidence="0.99344275">
In a traditional Markov model, the emission distri-
bution PΘ(Xi = xi  |Zi = zi) is a set of multinomi-
als. The feature-based model replaces the emission
distribution with a log-linear model, such that:
</bodyText>
<equation confidence="0.992817">
exp OTf(x, z)
PΘ(X = x  |Z = z) =
</equation>
<page confidence="0.985557">
604
</page>
<bodyText confidence="0.999168333333333">
on the word identity x, features checking whether x
contains digits or hyphens, whether the first letter of
x is upper case, and suffix features up to length 3.
All features were conjoined with the state z.
We trained this model by optimizing the following
objective function:
</bodyText>
<equation confidence="0.968433666666667">
PΘ(X = x(i), Z = z(i))
−C���2 (10)
2
</equation>
<bodyText confidence="0.999981545454546">
Note that this involves marginalizing out all possible
state configurations z for a sentence x, resulting in
a non-convex objective. To optimize this function,
we used L-BFGS, a quasi-Newton method (Liu and
Nocedal, 1989). For English POS tagging, Berg-
Kirkpatrick et al. (2010) found that this direct gra-
dient method performed better (&gt;7% absolute ac-
curacy) than using a feature-enhanced modification
of the Expectation-Maximization (EM) algorithm
(Dempster et al., 1977).8 Moreover, this route of
optimization outperformed a vanilla HMM trained
with EM by 12%.
We adopted this state-of-the-art model because it
makes it easy to experiment with various ways of
incorporating our novel constraint feature into the
log-linear emission model. This feature ft incor-
porates information from the smoothed graph and
prunes hidden states that are inconsistent with the
thresholded vector tx. The function A : F —* C
maps from the language specific fine-grained tagset
F to the coarser universal tagset C and is described
in detail in §6.2:
</bodyText>
<equation confidence="0.779617">
ft(x, z) = log(tx(y)), if A(z) = y (11)
</equation>
<bodyText confidence="0.999904888888889">
Note that when tx(y) = 1 the feature value is 0
and has no effect on the model, while its value is
−oc when tx(y) = 0 and constrains the HMM’s
state space. This formulation of the constraint fea-
ture is equivalent to the use of a tagging dictionary
extracted from the graph using a threshold T on the
posterior distribution of tags for a given word type
(Eq. 7). It would have therefore also been possible to
use the integer programming (IP) based approach of
</bodyText>
<footnote confidence="0.955583">
8See §3.1 of Berg-Kirkpatrick et al. (2010) for more details
about their modification of EM, and how gradients are com-
puted for L-BFGS.
</footnote>
<bodyText confidence="0.984829333333333">
Ravi and Knight (2009) instead of the feature-HMM
for POS induction on the foreign side. However, we
do not explore this possibility in the current work.
</bodyText>
<sectionHeader confidence="0.990465" genericHeader="method">
6 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999996">
Before presenting our results, we describe the
datasets that we used, as well as two baselines.
</bodyText>
<subsectionHeader confidence="0.9869">
6.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999979076923077">
We utilized two kinds of datasets in our experiments:
(i) monolingual treebanks9 and (ii) large amounts of
parallel text with English on one side. The availabil-
ity of these resources guided our selection of foreign
languages. For monolingual treebank data we re-
lied on the CoNLL-X and CoNLL-2007 shared tasks
on dependency parsing (Buchholz and Marsi, 2006;
Nivre et al., 2007). The parallel data came from the
Europarl corpus (Koehn, 2005) and the ODS United
Nations dataset (UN, 2006). Taking the intersection
of languages in these resources, and selecting lan-
guages with large amounts of parallel data, yields
the following set of eight Indo-European languages:
Danish, Dutch, German, Greek, Italian, Portuguese,
Spanish and Swedish.
Of course, we are primarily interested in apply-
ing our techniques to languages for which no la-
beled resources are available. However, we needed
to restrict ourselves to these languages in order to
be able to evaluate the performance of our approach.
We paid particular attention to minimize the number
of free parameters, and used the same hyperparam-
eters for all language pairs, rather than attempting
language-specific tuning. We hope that this will al-
low practitioners to apply our approach directly to
languages for which no resources are available.
</bodyText>
<subsectionHeader confidence="0.999989">
6.2 Part-of-Speech Tagset and HMM States
</subsectionHeader>
<bodyText confidence="0.999709714285714">
We use the universal POS tagset of Petrov et al.
(2011) in our experiments.10 This set C consists
of the following 12 coarse-grained tags: NOUN
(nouns), VERB (verbs), ADJ (adjectives), ADV
(adverbs), PRON (pronouns), DET (determiners),
ADP (prepositions or postpositions), NUM (numer-
als), CONJ (conjunctions), PRT (particles), PUNC
</bodyText>
<footnote confidence="0.995684333333333">
9We extracted only the words and their POS tags from the tree-
banks.
10Available at http://code.google.com/p/universal-pos-tags/.
</footnote>
<equation confidence="0.985391333333333">
L(0) = N �
i=1 log
Z
</equation>
<page confidence="0.994211">
605
</page>
<bodyText confidence="0.999984304347826">
(punctuation marks) and X (a catch-all for other
categories such as abbreviations or foreign words).
While there might be some controversy about the
exact definition of such a tagset, these 12 categories
cover the most frequent part-of-speech and exist in
one form or another in all of the languages that we
studied.
For each language under consideration, Petrov et
al. (2011) provide a mapping A from the fine-grained
language specific POS tags in the foreign treebank
to the universal POS tags. The supervised POS tag-
ging accuracies (on this tagset) are shown in the last
row of Table 2. The taggers were trained on datasets
labeled with the universal tags.
The number of latent HMM states for each lan-
guage in our experiments was set to the number of
fine tags in the language’s treebank. In other words,
the set of hidden states F was chosen to be the fine
set of treebank tags. Therefore, the number of fine
tags varied across languages for our experiments;
however, one could as well have fixed the set of
HMM states to be a constant across languages, and
created one mapping to the universal POS tagset.
</bodyText>
<subsectionHeader confidence="0.998047">
6.3 Various Models
</subsectionHeader>
<bodyText confidence="0.9999805">
To provide a thorough analysis, we evaluated three
baselines and two oracles in addition to two variants
of our graph-based approach. We were intentionally
lenient with our baselines:
</bodyText>
<listItem confidence="0.997746384615385">
• EM-HMM: A traditional HMM baseline, with
multinomial emission and transition distribu-
tions estimated by the Expectation Maximiza-
tion algorithm. We evaluated POS tagging ac-
curacy using the lenient many-to-1 evaluation
approach (Johnson, 2007).
• Feature-HMM: The vanilla feature-HMM of
Berg-Kirkpatrick et al. (2010) (i.e. no ad-
ditional constraint feature) served as a sec-
ond baseline. Model parameters were esti-
mated with L-BFGS and evaluation again used
a greedy many-to-1 mapping.
• Projection: Our third baseline incorporates
</listItem>
<bodyText confidence="0.8442247">
bilingual information by projecting POS tags
directly across alignments in the parallel data.
For unaligned words, we set the tag to the most
frequent tag in the corresponding treebank. For
each language, we took the same number of
sentences from the bitext as there are in its tree-
bank, and trained a supervised feature-HMM.
This can be seen as a rough approximation of
Yarowsky and Ngai (2001).
We tried two versions of our graph-based approach:
</bodyText>
<listItem confidence="0.5173295">
• No LP: Our first version takes advantage of
our bilingual graph, but extracts the constraint
</listItem>
<bodyText confidence="0.973303777777778">
feature after the first stage of label propagation
(Eq. 1). Because many foreign word types are
not aligned to an English word (see Table 3),
and we do not run label propagation on the for-
eign side, we expect the projected information
to have less coverage. Furthermore we expect
the label distributions on the foreign to be fairly
noisy, because the graph constraints have not
been taken into account yet.
</bodyText>
<listItem confidence="0.758691571428571">
• With LP: Our full model uses both stages
of label propagation (Eq. 2) before extracting
the constraint features. As a result, we are
able to extract the constraint feature for all for-
eign word types and furthermore expect the
projected tag distributions to be smoother and
more stable.
</listItem>
<bodyText confidence="0.860535">
Our oracles took advantage of the labeled treebanks:
</bodyText>
<listItem confidence="0.887968333333333">
• TB Dictionary: We extracted tagging dictio-
naries from the treebanks and and used them as
constraint features in the feature-based HMM.
Evaluation was done using the prespecified
mappings.
• Supervised: We trained the supervised model
of Brants (2000) on the original treebanks and
mapped the language-specific tags to the uni-
versal tags for evaluation.
</listItem>
<subsectionHeader confidence="0.993568">
6.4 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999932125">
While we tried to minimize the number of free pa-
rameters in our model, there are a few hyperparam-
eters that need to be set. Fortunately, performance
was stable across various values, and we were able
to use the same hyperparameters for all languages.
We used C = 1.0 as the L2 regularization con-
stant in (Eq. 10) and trained both EM and L-BFGS
for 1000 iterations. When extracting the vector
</bodyText>
<page confidence="0.996457">
606
</page>
<table confidence="0.989594125">
Model Danish Dutch German Greek Italian Portuguese Spanish Swedish Avg
EM-HMM 68.7 57.0 75.9 65.8 63.7 62.9 71.5 68.4 66.7
baselines Feature-HMM 69.1 65.1 81.3 71.8 68.1 78.4 80.2 70.1 73.0
Projection 73.6 77.0 83.2 79.3 79.7 82.6 80.1 74.7 78.8
our approach No LP 79.0 78.8 82.4 76.3 84.8 87.0 82.8 79.4 81.3
With LP 83.2 79.5 82.8 82.5 86.8 87.9 84.2 80.5 83.4
oracles TB Dictionary 93.1 94.7 93.5 96.6 96.4 94.0 95.8 85.5 93.7
Supervised 96.9 94.9 98.2 97.8 95.8 97.2 96.8 94.8 96.6
</table>
<tableCaption confidence="0.990424">
Table 2: Part-of-speech tagging accuracies for various baselines and oracles, as well as our approach. “Avg” denotes
macro-average across the eight languages.
</tableCaption>
<bodyText confidence="0.999740214285714">
t, used to compute the constraint feature from the
graph, we tried three threshold values for r (see
Eq. 7). Because we don’t have a separate develop-
ment set, we used the training set to select among
them and found 0.2 to work slightly better than 0.1
and 0.3. For seven out of eight languages a thresh-
old of 0.2 gave the best results for our final model,
which indicates that for languages without any val-
idation set, r = 0.2 can be used. For graph prop-
agation, the hyperparameter v was set to 2 x 10−6
and was not tuned. The graph was constructed using
2 million trigrams; we chose these by truncating the
parallel datasets up to the number of sentence pairs
that contained 2 million trigrams.
</bodyText>
<sectionHeader confidence="0.730278" genericHeader="evaluation">
6.5 Results
</sectionHeader>
<bodyText confidence="0.999987466666667">
Table 2 shows our complete set of results. As ex-
pected, the vanilla HMM trained with EM performs
the worst. The feature-HMM model works better for
all languages, generalizing the results achieved for
English by Berg-Kirkpatrick et al. (2010). Our “Pro-
jection” baseline is able to benefit from the bilingual
information and greatly improves upon the mono-
lingual baselines, but falls short of the “No LP”
model by 2.5% on an average. The “No LP” model
does not outperform direct projection for German
and Greek, but performs better for six out of eight
languages. Overall, it gives improvements ranging
from 1.1% for German to 14.7% for Italian, for an
average improvement of 8.3% over the unsupervised
feature-HMM model. For comparison, the com-
pletely unsupervised feature-HMM baseline accu-
racy on the universal POS tags for English is 79.4%,
and goes up to 88.7% with a treebank dictionary.
Our full model (“With LP”) outperforms the un-
supervised baselines and the “No LP” setting for all
languages. It falls short of the “Projection” base-
line for German, but is statistically indistinguish-
able in terms of accuracy. As indicated by bolding,
for seven out of eight languages the improvements
of the “With LP” setting are statistically significant
with respect to the other models, including the “No
LP” setting.11 Overall, it performs 10.4% better
than the hitherto state-of-the-art feature-HMM base-
line, and 4.6% better than direct projection, when we
macro-average the accuracy over all languages.
</bodyText>
<subsectionHeader confidence="0.87235">
6.6 Discussion
</subsectionHeader>
<bodyText confidence="0.959087875">
Our full model outperforms the “No LP” setting
because it has better vocabulary coverage and al-
lows the extraction of a larger set of constraint fea-
tures. We tabulate this increase in Table 3. For all
languages, the vocabulary sizes increase by several
thousand words. Although the tag distributions of
the foreign words (Eq. 6) are noisy, the results con-
firm that label propagation within the foreign lan-
guage part of the graph adds significant quality for
every language.
Figure 2 shows an excerpt of a sentence from the
Italian test set and the tags assigned by four different
models, as well as the gold tags. While the first three
models get three to four tags wrong, our best model
gets only one word wrong and is the most accurate
among the four models for this example. Examin-
ing the word fidanzato for the “No LP” and “With
LP” models is particularly instructive. As Figure 1
shows, this word has no high-confidence alignment
in the Italian-English bitext. As a result, its POS tag
needs to be induced in the “No LP” case, while the
11A word level paired-t-test is significant at p &lt; 0.01 for Dan-
ish, Greek, Italian, Portuguese, Spanish and Swedish, and
p &lt; 0.05 for Dutch.
</bodyText>
<page confidence="0.983898">
607
</page>
<table confidence="0.977853">
EM-HMM: si trovava in un parco con il fidanzato Paolo F. , 27 anni , rappresentante
CONJ NOUN DET DET NOUN ADP DET NOUN . NOUN .NUM NOUN. NOUN
Feature-HMM: PRON VERB ADP DET NOUN CONJ DET NOUN NOUN NOUN . ADP NOUN. VERB
No LP: VERB VERB ADP DET NOUN ADP DET ADJ NOUN ADJ . NUM NOUN. NOUN
With LP: VERB VERB ADP DET NOUN ADP DET NOUN NOUN NOUN . NUM NOUN . NOUN
Gold: PRON VERB ADP DET NOUN ADP DET NOUN NOUN NOUN .NUM NOUN. NOUN
Figure 2: Tags produced by the different models along with the reference set of tags for a part of a sentence from the
Italian test set. Italicized tags denote incorrect labels.
Language # words with constraints
“No LP” “With LP”
Danish 88,240 128, 391
Dutch 51,169 74,892
German 59,534 107,249
Greek 90,231 114,002
Italian 48,904 62,461
Portuguese 46,787 65,737
Spanish 72,215 82,459
Swedish 70,181 88,454
</table>
<tableCaption confidence="0.8917205">
Table 3: Size of the vocabularies for the “No LP” and
“With LP” models for which we can impose constraints.
</tableCaption>
<bodyText confidence="0.830663">
correct tag is available as a constraint feature in the
“With LP” case.
</bodyText>
<sectionHeader confidence="0.998199" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999875333333333">
We have shown the efficacy of graph-based label
propagation for projecting part-of-speech informa-
tion across languages. Because we are interested in
applying our techniques to languages for which no
labeled resources are available, we paid particular
attention to minimize the number of free parame-
ters and used the same hyperparameters for all lan-
guage pairs. Our results suggest that it is possible to
learn accurate POS taggers for languages which do
not have any annotated data, but have translations
into a resource-rich language. Our results outper-
form strong unsupervised baselines as well as ap-
proaches that rely on direct projections, and bridge
the gap between purely supervised and unsupervised
POS tagging models.
</bodyText>
<sectionHeader confidence="0.997633" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99995375">
We would like to thank Ryan McDonald for numer-
ous discussions on this topic. We would also like to
thank Amarnag Subramanya for helping us with the
implementation of label propagation and Shankar
Kumar for access to the parallel data. Finally, we
thank Kuzman Ganchev and the three anonymous
reviewers for helpful suggestions and comments on
earlier drafts of this paper.
</bodyText>
<sectionHeader confidence="0.999206" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999343125">
Hiyan Alshawi, Srinivas Bangalore, and Shona Douglas.
2000. Head-transducer models for speech translation
and their automatic acquisition from bilingual data.
Machine Translation, 15.
Yasemin Altun, David McAllester, and Mikhail Belkin.
2005. Maximum margin semi-supervised learning for
structured variables. In Proc. of NIPS.
Taylor Berg-Kirkpatrick, Alexandre B. Cˆot´e, John DeN-
ero, and Dan Klein. 2010. Painless unsupervised
learning with features. In Proc. of NAACL-HLT.
Thorsten Brants. 2000. TnT - a statistical part-of-speech
tagger. In Proc. ofANLP.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: parameter esti-
mation. Computational Linguistics, 19.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proc. of CoNLL.
Andrew Carnie. 2002. Syntax: A Generative Introduc-
tion (Introducing Linguistics). Blackwell Publishing.
Christos Christodoulopoulos, Sharon Goldwater, and
Mark Steedman. 2010. Two decades of unsupervised
POS induction: How far have we come? In Proc. of
EMNLP.
Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-
bin. 1977. Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statistical
Society, Series B, 39.
Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar.
2009. Dependency grammar induction via bitext pro-
jection constraints. In Proc. of ACL-IJCNLP.
</reference>
<page confidence="0.980082">
608
</page>
<reference confidence="0.999872509803921">
Mark Johnson. 2007. Why doesn’t EM find good HMM
POS-taggers? In Proc. of EMNLP-CoNLL.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In MT Summit.
Dong C. Liu and Jorge Nocedal. 1989. On the limited
memory BFGS method for large scale optimization.
Mathematical Programming, 45.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beat-
rice Santorini. 1993. Building a large annotated cor-
pus of English: the Penn treebank. Computational
Linguistics, 19.
Tahira Naseem, Benjamin Snyder, Jacob Eisenstein, and
Regina Barzilay. 2009. Multilingual part-of-speech
tagging: Two unsupervised approaches. JAIR, 36.
Tahira Naseem, Harr Chen, Regina Barzilay, and Mark
Johnson. 2010. Using universal linguistic knowledge
to guide grammar induction. In Proc. of EMNLP.
Frederick J. Newmeyer. 2005. Possible and Probable
Languages: A Generative Perspective on Linguistic
Typology. Oxford University Press.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDon-
ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007. The CoNLL 2007 shared task on dependency
parsing. In Proceedings of CoNLL.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011.
A universal part-of-speech tagset. ArXiv:1104.2086.
Sujith Ravi and Kevin Knight. 2009. Minimized models
for unsupervised part-of-speech tagging. In Proc. of
ACL-IJCNLP.
Libin Shen, Giorgio Satta, and Aravind Joshi. 2007.
Guided learning for bidirectional sequence classifica-
tion. In Proc. of ACL.
Benjamin Snyder, Tahira Naseem, and Regina Barzilay.
2009. Unsupervised multilingual grammar induction.
In Proc. of ACL-IJCNLP.
Amar Subramanya, Slav Petrov, and Fernando Pereira.
2010. Efficient graph-based semi-supervised learning
of structured tagging models. In Proc. of EMNLP.
UN. 2006. ODS UN parallel corpus.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proc. of COLING.
Chenhai Xi and Rebecca Hwa. 2005. A backoff
model for bootstrapping resources for non-English
languages. In Proc. of HLT-EMNLP.
David Yarowsky and Grace Ngai. 2001. Inducing multi-
lingual POS taggers and NP bracketers via robust pro-
jection across aligned corpora. In Proc. of NAACL.
Xiaojin Zhu, Zoubin Ghahramani, and John D. Lafferty.
2003. Semi-supervised learning using gaussian fields
and harmonic functions. In Proc. of ICML.
</reference>
<page confidence="0.998829">
609
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.928252">
<title confidence="0.997208">Unsupervised Part-of-Speech with Bilingual Graph-Based Projections</title>
<author confidence="0.99668">Petrov</author>
<affiliation confidence="0.999905">Carnegie Mellon University Google Research</affiliation>
<address confidence="0.996349">Pittsburgh, PA 15213, USA New York, NY 10011, USA</address>
<email confidence="0.999077">dipanjan@cs.cmu.eduslav@google.com</email>
<abstract confidence="0.996843578947368">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language. Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable to a wide array of resource-poor languages. We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as features in an unsupervised model (Berg- Kirkpatrick et al., 2010). Across eight European languages, our approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
<author>Srinivas Bangalore</author>
<author>Shona Douglas</author>
</authors>
<title>Head-transducer models for speech translation and their automatic acquisition from bilingual data.</title>
<date>2000</date>
<journal>Machine Translation,</journal>
<volume>15</volume>
<contexts>
<context position="2410" citStr="Alshawi et al., 2000" startWordPosition="359" endWordPosition="363">racy (Christodoulopoulos et al., 2010), making its practical usability questionable at best. To bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like English) when building tools for resource-poor foreign languages.1 We assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language. This scenario is applicable to a large set of languages and has been considered by a number of authors in the past (Alshawi et al., 2000; Xi and Hwa, 2005; Ganchev et al., 2009). Naseem et al. (2009) and Snyder et al. (2009) study related but different multilingual grammar and tagger induction tasks, where it is assumed that no labeled data at all is available. Our work is closest to that of Yarowsky and Ngai (2001), but differs in two important ways. First, we use a novel graph-based framework for projecting syntactic information across language boundaries. To this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project synta</context>
</contexts>
<marker>Alshawi, Bangalore, Douglas, 2000</marker>
<rawString>Hiyan Alshawi, Srinivas Bangalore, and Shona Douglas. 2000. Head-transducer models for speech translation and their automatic acquisition from bilingual data. Machine Translation, 15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasemin Altun</author>
<author>David McAllester</author>
<author>Mikhail Belkin</author>
</authors>
<title>Maximum margin semi-supervised learning for structured variables.</title>
<date>2005</date>
<booktitle>In Proc. of NIPS.</booktitle>
<contexts>
<context position="7930" citStr="Altun et al. (2005)" startWordPosition="1229" endWordPosition="1232">n graph-based learning approaches one constructs a graph whose vertices are labeled and unlabeled examples, and whose weighted edges encode the degree to which the examples they link have the same label (Zhu et al., 2003). Graph construction for structured prediction problems such as POS tagging is non-trivial: on the one hand, using individual words as the vertices throws away the context 3The word alignment methods do not use POS information. 601 necessary for disambiguation; on the other hand, it is unclear how to define (sequence) similarity if the vertices correspond to entire sentences. Altun et al. (2005) proposed a technique that uses graph based similarity between labeled and unlabeled parts of structured data in a discriminative framework for semi-supervised learning. More recently, Subramanya et al. (2010) defined a graph over the cliques in an underlying structured prediction model. They considered a semi-supervised POS tagging scenario and showed that one can use a graph over trigram types, and edge weights based on distributional similarity, to improve a supervised conditional random field tagger. 3.1 Graph Vertices We extend Subramanya et al.’s intuitions to our bilingual setup. Becaus</context>
</contexts>
<marker>Altun, McAllester, Belkin, 2005</marker>
<rawString>Yasemin Altun, David McAllester, and Mikhail Belkin. 2005. Maximum margin semi-supervised learning for structured variables. In Proc. of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Alexandre B Cˆot´e</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Painless unsupervised learning with features.</title>
<date>2010</date>
<booktitle>In Proc. of NAACL-HLT.</booktitle>
<marker>Berg-Kirkpatrick, Cˆot´e, DeNero, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick, Alexandre B. Cˆot´e, John DeNero, and Dan Klein. 2010. Painless unsupervised learning with features. In Proc. of NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT - a statistical part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In Proc. ofANLP.</booktitle>
<contexts>
<context position="14031" citStr="Brants, 2000" startWordPosition="2243" endWordPosition="2244">a soft label distribution over the vertices. It is worth noting that the middle words of the Italian trigrams are nouns too, which exhibits the fact that the similarity metric connects types having the same syntactic category. In the label propagation stage, we propagate the automatic English tags to the aligned Italian trigram types, followed by further propagation solely among the Italian vertices. 6We ran six iterations of IBM Model 1 (Brown et al., 1993), followed by six iterations of the HMM model (Vogel et al., 1996) in both directions. 7We used a tagger based on a trigram Markov model (Brants, 2000) trained on the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1993), for its fast speed and reasonable accuracy (96.7% on sections 22-24 of the treebank, but presumably much lower on the (out-of-domain) parallel corpus). Figure 1: An excerpt from the graph for Italian. Three of the Italian vertices are connected to an automatically labeled English vertex. Label propagation is used to propagate these tags inwards and results in tag distributions for the middle word of each Italian trigram. 4 POS Projection Given the bilingual graph described in the previous section, we can us</context>
<context position="26413" citStr="Brants (2000)" startWordPosition="4367" endWordPosition="4368">n into account yet. • With LP: Our full model uses both stages of label propagation (Eq. 2) before extracting the constraint features. As a result, we are able to extract the constraint feature for all foreign word types and furthermore expect the projected tag distributions to be smoother and more stable. Our oracles took advantage of the labeled treebanks: • TB Dictionary: We extracted tagging dictionaries from the treebanks and and used them as constraint features in the feature-based HMM. Evaluation was done using the prespecified mappings. • Supervised: We trained the supervised model of Brants (2000) on the original treebanks and mapped the language-specific tags to the universal tags for evaluation. 6.4 Experimental Setup While we tried to minimize the number of free parameters in our model, there are a few hyperparameters that need to be set. Fortunately, performance was stable across various values, and we were able to use the same hyperparameters for all languages. We used C = 1.0 as the L2 regularization constant in (Eq. 10) and trained both EM and L-BFGS for 1000 iterations. When extracting the vector 606 Model Danish Dutch German Greek Italian Portuguese Spanish Swedish Avg EM-HMM </context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. TnT - a statistical part-of-speech tagger. In Proc. ofANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<contexts>
<context position="13880" citStr="Brown et al., 1993" startWordPosition="2214" endWordPosition="2217"> In this particular case, all English vertices are labeled as nouns by the supervised tagger. In general, the neighborhoods can be more diverse and we allow a soft label distribution over the vertices. It is worth noting that the middle words of the Italian trigrams are nouns too, which exhibits the fact that the similarity metric connects types having the same syntactic category. In the label propagation stage, we propagate the automatic English tags to the aligned Italian trigram types, followed by further propagation solely among the Italian vertices. 6We ran six iterations of IBM Model 1 (Brown et al., 1993), followed by six iterations of the HMM model (Vogel et al., 1996) in both directions. 7We used a tagger based on a trigram Markov model (Brants, 2000) trained on the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1993), for its fast speed and reasonable accuracy (96.7% on sections 22-24 of the treebank, but presumably much lower on the (out-of-domain) parallel corpus). Figure 1: An excerpt from the graph for Italian. Three of the Italian vertices are connected to an automatically labeled English vertex. Label propagation is used to propagate these tags inwards and results in</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of CoNLL.</booktitle>
<contexts>
<context position="21563" citStr="Buchholz and Marsi, 2006" startWordPosition="3583" endWordPosition="3586">) instead of the feature-HMM for POS induction on the foreign side. However, we do not explore this possibility in the current work. 6 Experiments and Results Before presenting our results, we describe the datasets that we used, as well as two baselines. 6.1 Datasets We utilized two kinds of datasets in our experiments: (i) monolingual treebanks9 and (ii) large amounts of parallel text with English on one side. The availability of these resources guided our selection of foreign languages. For monolingual treebank data we relied on the CoNLL-X and CoNLL-2007 shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). The parallel data came from the Europarl corpus (Koehn, 2005) and the ODS United Nations dataset (UN, 2006). Taking the intersection of languages in these resources, and selecting languages with large amounts of parallel data, yields the following set of eight Indo-European languages: Danish, Dutch, German, Greek, Italian, Portuguese, Spanish and Swedish. Of course, we are primarily interested in applying our techniques to languages for which no labeled resources are available. However, we needed to restrict ourselves to these languages in order to be able to evaluate th</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carnie</author>
</authors>
<title>Syntax: A Generative Introduction (Introducing Linguistics).</title>
<date>2002</date>
<publisher>Blackwell Publishing.</publisher>
<contexts>
<context position="3810" citStr="Carnie, 2002" startWordPosition="584" endWordPosition="585">age as the “foreign language.” Similarly, we use English as the resource-rich language, but any other language with labeled resources could be used instead. 600 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 600–609, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics vised model (§5), rather than using them directly for supervised training. To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011). Syntactic universals are a well studied concept in linguistics (Carnie, 2002; Newmeyer, 2005), and were recently used in similar form by Naseem et al. (2010) for multilingual grammar induction. Because there might be some controversy about the exact definitions of such universals, this set of coarse-grained POS categories is defined operationally, by collapsing language (or treebank) specific distinctions to a set of categories that exists across all languages. These universal POS categories not only facilitate the transfer of POS information from one language to another, but also relieve us from using controversial evaluation metrics,2 by establishing a direct corres</context>
</contexts>
<marker>Carnie, 2002</marker>
<rawString>Andrew Carnie. 2002. Syntax: A Generative Introduction (Introducing Linguistics). Blackwell Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christos Christodoulopoulos</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Two decades of unsupervised POS induction: How far have we come?</title>
<date>2010</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="1828" citStr="Christodoulopoulos et al., 2010" startWordPosition="262" endWordPosition="265">speech (POS) taggers, for example, approach the level of inter-annotator agreement (Shen et al., 2007, 97.3% accuracy for English). However, supervised methods rely on labeled training data, which is time-consuming and expensive to generate. Unsupervised learning approaches appear to be a natural solution to this problem, as they require only unannotated text for train*This research was carried out during an internship at Google Research. ing models. Unfortunately, the best completely unsupervised English POS tagger (that does not make use of a tagging dictionary) reaches only 76.1% accuracy (Christodoulopoulos et al., 2010), making its practical usability questionable at best. To bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like English) when building tools for resource-poor foreign languages.1 We assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language. This scenario is applicable to a large set of languages and has been considered by a number of authors in the past (Alshawi et al., 2000; Xi and Hwa, 2005</context>
<context position="5745" citStr="Christodoulopoulos et al. (2010)" startWordPosition="886" endWordPosition="889">languages. Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus. As discussed in more detail in §3, we use two types of vertices in our graph: on the foreign language side vertices correspond to trigram types, while the vertices on the English side are individual word types. Graph construction does not require any labeled data, but makes use of two similarity functions. The edge weights between the foreign language trigrams are computed using a co-occurence based similarity function, designed to indicate how syntactically 2See Christodoulopoulos et al. (2010) for a discussion of metrics for evaluating unsupervised POS induction systems. Algorithm 1 Bilingual POS Induction Require: Parallel English and foreign language data De and Df, unlabeled foreign training data Ff; English tagger. Ensure: Of, a set of parameters learned using a constrained unsupervised model (§5). 1: De`—&apos;f +— word-align-bitext(De, Df) � 2: De +— pos-tag-supervised(De) 3: A extract-alignments(De`-&apos;f,De) 4: G construct-graph(Ff, Df, A) 5: G graph-propagate(G) 6: A extract-word-constraints(G) 7: Of +— pos-induce-constrained(Ff, A) 8: Return Of similar the middle words of the con</context>
</contexts>
<marker>Christodoulopoulos, Goldwater, Steedman, 2010</marker>
<rawString>Christos Christodoulopoulos, Sharon Goldwater, and Mark Steedman. 2010. Two decades of unsupervised POS induction: How far have we come? In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur P Dempster</author>
<author>Nan M Laird</author>
<author>Donald B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society, Series B,</journal>
<volume>39</volume>
<contexts>
<context position="19722" citStr="Dempster et al., 1977" startWordPosition="3270" endWordPosition="3273">l features were conjoined with the state z. We trained this model by optimizing the following objective function: PΘ(X = x(i), Z = z(i)) −C���2 (10) 2 Note that this involves marginalizing out all possible state configurations z for a sentence x, resulting in a non-convex objective. To optimize this function, we used L-BFGS, a quasi-Newton method (Liu and Nocedal, 1989). For English POS tagging, BergKirkpatrick et al. (2010) found that this direct gradient method performed better (&gt;7% absolute accuracy) than using a feature-enhanced modification of the Expectation-Maximization (EM) algorithm (Dempster et al., 1977).8 Moreover, this route of optimization outperformed a vanilla HMM trained with EM by 12%. We adopted this state-of-the-art model because it makes it easy to experiment with various ways of incorporating our novel constraint feature into the log-linear emission model. This feature ft incorporates information from the smoothed graph and prunes hidden states that are inconsistent with the thresholded vector tx. The function A : F —* C maps from the language specific fine-grained tagset F to the coarser universal tagset C and is described in detail in §6.2: ft(x, z) = log(tx(y)), if A(z) = y (11)</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Arthur P. Dempster, Nan M. Laird, and Donald B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, Series B, 39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Dependency grammar induction via bitext projection constraints.</title>
<date>2009</date>
<booktitle>In Proc. of ACL-IJCNLP.</booktitle>
<contexts>
<context position="2451" citStr="Ganchev et al., 2009" startWordPosition="368" endWordPosition="371">making its practical usability questionable at best. To bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like English) when building tools for resource-poor foreign languages.1 We assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language. This scenario is applicable to a large set of languages and has been considered by a number of authors in the past (Alshawi et al., 2000; Xi and Hwa, 2005; Ganchev et al., 2009). Naseem et al. (2009) and Snyder et al. (2009) study related but different multilingual grammar and tagger induction tasks, where it is assumed that no labeled data at all is available. Our work is closest to that of Yarowsky and Ngai (2001), but differs in two important ways. First, we use a novel graph-based framework for projecting syntactic information across language boundaries. To this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project syntactic information from English to the fore</context>
</contexts>
<marker>Ganchev, Gillenwater, Taskar, 2009</marker>
<rawString>Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar. 2009. Dependency grammar induction via bitext projection constraints. In Proc. of ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Why doesn’t EM find good HMM POS-taggers?</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL.</booktitle>
<contexts>
<context position="24582" citStr="Johnson, 2007" startWordPosition="4067" endWordPosition="4068">or our experiments; however, one could as well have fixed the set of HMM states to be a constant across languages, and created one mapping to the universal POS tagset. 6.3 Various Models To provide a thorough analysis, we evaluated three baselines and two oracles in addition to two variants of our graph-based approach. We were intentionally lenient with our baselines: • EM-HMM: A traditional HMM baseline, with multinomial emission and transition distributions estimated by the Expectation Maximization algorithm. We evaluated POS tagging accuracy using the lenient many-to-1 evaluation approach (Johnson, 2007). • Feature-HMM: The vanilla feature-HMM of Berg-Kirkpatrick et al. (2010) (i.e. no additional constraint feature) served as a second baseline. Model parameters were estimated with L-BFGS and evaluation again used a greedy many-to-1 mapping. • Projection: Our third baseline incorporates bilingual information by projecting POS tags directly across alignments in the parallel data. For unaligned words, we set the tag to the most frequent tag in the corresponding treebank. For each language, we took the same number of sentences from the bitext as there are in its treebank, and trained a supervised</context>
</contexts>
<marker>Johnson, 2007</marker>
<rawString>Mark Johnson. 2007. Why doesn’t EM find good HMM POS-taggers? In Proc. of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT Summit.</booktitle>
<contexts>
<context position="21647" citStr="Koehn, 2005" startWordPosition="3599" endWordPosition="3600">his possibility in the current work. 6 Experiments and Results Before presenting our results, we describe the datasets that we used, as well as two baselines. 6.1 Datasets We utilized two kinds of datasets in our experiments: (i) monolingual treebanks9 and (ii) large amounts of parallel text with English on one side. The availability of these resources guided our selection of foreign languages. For monolingual treebank data we relied on the CoNLL-X and CoNLL-2007 shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). The parallel data came from the Europarl corpus (Koehn, 2005) and the ODS United Nations dataset (UN, 2006). Taking the intersection of languages in these resources, and selecting languages with large amounts of parallel data, yields the following set of eight Indo-European languages: Danish, Dutch, German, Greek, Italian, Portuguese, Spanish and Swedish. Of course, we are primarily interested in applying our techniques to languages for which no labeled resources are available. However, we needed to restrict ourselves to these languages in order to be able to evaluate the performance of our approach. We paid particular attention to minimize the number o</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong C Liu</author>
<author>Jorge Nocedal</author>
</authors>
<title>On the limited memory BFGS method for large scale optimization.</title>
<date>1989</date>
<booktitle>Mathematical Programming,</booktitle>
<volume>45</volume>
<contexts>
<context position="19472" citStr="Liu and Nocedal, 1989" startWordPosition="3234" endWordPosition="3237"> distribution with a log-linear model, such that: exp OTf(x, z) PΘ(X = x |Z = z) = 604 on the word identity x, features checking whether x contains digits or hyphens, whether the first letter of x is upper case, and suffix features up to length 3. All features were conjoined with the state z. We trained this model by optimizing the following objective function: PΘ(X = x(i), Z = z(i)) −C���2 (10) 2 Note that this involves marginalizing out all possible state configurations z for a sentence x, resulting in a non-convex objective. To optimize this function, we used L-BFGS, a quasi-Newton method (Liu and Nocedal, 1989). For English POS tagging, BergKirkpatrick et al. (2010) found that this direct gradient method performed better (&gt;7% absolute accuracy) than using a feature-enhanced modification of the Expectation-Maximization (EM) algorithm (Dempster et al., 1977).8 Moreover, this route of optimization outperformed a vanilla HMM trained with EM by 12%. We adopted this state-of-the-art model because it makes it easy to experiment with various ways of incorporating our novel constraint feature into the log-linear emission model. This feature ft incorporates information from the smoothed graph and prunes hidde</context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>Dong C. Liu and Jorge Nocedal. 1989. On the limited memory BFGS method for large scale optimization. Mathematical Programming, 45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of English: the Penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<contexts>
<context position="14117" citStr="Marcus et al., 1993" startWordPosition="2256" endWordPosition="2259"> words of the Italian trigrams are nouns too, which exhibits the fact that the similarity metric connects types having the same syntactic category. In the label propagation stage, we propagate the automatic English tags to the aligned Italian trigram types, followed by further propagation solely among the Italian vertices. 6We ran six iterations of IBM Model 1 (Brown et al., 1993), followed by six iterations of the HMM model (Vogel et al., 1996) in both directions. 7We used a tagger based on a trigram Markov model (Brants, 2000) trained on the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1993), for its fast speed and reasonable accuracy (96.7% on sections 22-24 of the treebank, but presumably much lower on the (out-of-domain) parallel corpus). Figure 1: An excerpt from the graph for Italian. Three of the Italian vertices are connected to an automatically labeled English vertex. Label propagation is used to propagate these tags inwards and results in tag distributions for the middle word of each Italian trigram. 4 POS Projection Given the bilingual graph described in the previous section, we can use label propagation to project the English POS labels to the foreign language. We use </context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of English: the Penn treebank. Computational Linguistics, 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Benjamin Snyder</author>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Multilingual part-of-speech tagging: Two unsupervised approaches.</title>
<date>2009</date>
<journal>JAIR,</journal>
<volume>36</volume>
<contexts>
<context position="2473" citStr="Naseem et al. (2009)" startWordPosition="372" endWordPosition="375">ability questionable at best. To bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like English) when building tools for resource-poor foreign languages.1 We assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language. This scenario is applicable to a large set of languages and has been considered by a number of authors in the past (Alshawi et al., 2000; Xi and Hwa, 2005; Ganchev et al., 2009). Naseem et al. (2009) and Snyder et al. (2009) study related but different multilingual grammar and tagger induction tasks, where it is assumed that no labeled data at all is available. Our work is closest to that of Yarowsky and Ngai (2001), but differs in two important ways. First, we use a novel graph-based framework for projecting syntactic information across language boundaries. To this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project syntactic information from English to the foreign language (§4). Sec</context>
</contexts>
<marker>Naseem, Snyder, Eisenstein, Barzilay, 2009</marker>
<rawString>Tahira Naseem, Benjamin Snyder, Jacob Eisenstein, and Regina Barzilay. 2009. Multilingual part-of-speech tagging: Two unsupervised approaches. JAIR, 36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Harr Chen</author>
<author>Regina Barzilay</author>
<author>Mark Johnson</author>
</authors>
<title>Using universal linguistic knowledge to guide grammar induction.</title>
<date>2010</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="3891" citStr="Naseem et al. (2010)" startWordPosition="596" endWordPosition="599">rich language, but any other language with labeled resources could be used instead. 600 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 600–609, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics vised model (§5), rather than using them directly for supervised training. To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011). Syntactic universals are a well studied concept in linguistics (Carnie, 2002; Newmeyer, 2005), and were recently used in similar form by Naseem et al. (2010) for multilingual grammar induction. Because there might be some controversy about the exact definitions of such universals, this set of coarse-grained POS categories is defined operationally, by collapsing language (or treebank) specific distinctions to a set of categories that exists across all languages. These universal POS categories not only facilitate the transfer of POS information from one language to another, but also relieve us from using controversial evaluation metrics,2 by establishing a direct correspondence between the induced hidden states in the foreign language and the observ</context>
</contexts>
<marker>Naseem, Chen, Barzilay, Johnson, 2010</marker>
<rawString>Tahira Naseem, Harr Chen, Regina Barzilay, and Mark Johnson. 2010. Using universal linguistic knowledge to guide grammar induction. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick J Newmeyer</author>
</authors>
<title>Possible and Probable Languages: A Generative Perspective on Linguistic Typology.</title>
<date>2005</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="3827" citStr="Newmeyer, 2005" startWordPosition="586" endWordPosition="587">reign language.” Similarly, we use English as the resource-rich language, but any other language with labeled resources could be used instead. 600 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 600–609, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics vised model (§5), rather than using them directly for supervised training. To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011). Syntactic universals are a well studied concept in linguistics (Carnie, 2002; Newmeyer, 2005), and were recently used in similar form by Naseem et al. (2010) for multilingual grammar induction. Because there might be some controversy about the exact definitions of such universals, this set of coarse-grained POS categories is defined operationally, by collapsing language (or treebank) specific distinctions to a set of categories that exists across all languages. These universal POS categories not only facilitate the transfer of POS information from one language to another, but also relieve us from using controversial evaluation metrics,2 by establishing a direct correspondence between </context>
</contexts>
<marker>Newmeyer, 2005</marker>
<rawString>Frederick J. Newmeyer. 2005. Possible and Probable Languages: A Generative Perspective on Linguistic Typology. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proceedings of CoNLL.</booktitle>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2011</date>
<journal>ArXiv:1104.2086.</journal>
<contexts>
<context position="3732" citStr="Petrov et al. (2011)" startWordPosition="571" endWordPosition="574">eatures in an unsuper1For simplicity of exposition we refer to the resource-poor language as the “foreign language.” Similarly, we use English as the resource-rich language, but any other language with labeled resources could be used instead. 600 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 600–609, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics vised model (§5), rather than using them directly for supervised training. To make the projection practical, we rely on the twelve universal part-of-speech tags of Petrov et al. (2011). Syntactic universals are a well studied concept in linguistics (Carnie, 2002; Newmeyer, 2005), and were recently used in similar form by Naseem et al. (2010) for multilingual grammar induction. Because there might be some controversy about the exact definitions of such universals, this set of coarse-grained POS categories is defined operationally, by collapsing language (or treebank) specific distinctions to a set of categories that exists across all languages. These universal POS categories not only facilitate the transfer of POS information from one language to another, but also relieve us</context>
<context position="22594" citStr="Petrov et al. (2011)" startWordPosition="3746" endWordPosition="3749">terested in applying our techniques to languages for which no labeled resources are available. However, we needed to restrict ourselves to these languages in order to be able to evaluate the performance of our approach. We paid particular attention to minimize the number of free parameters, and used the same hyperparameters for all language pairs, rather than attempting language-specific tuning. We hope that this will allow practitioners to apply our approach directly to languages for which no resources are available. 6.2 Part-of-Speech Tagset and HMM States We use the universal POS tagset of Petrov et al. (2011) in our experiments.10 This set C consists of the following 12 coarse-grained tags: NOUN (nouns), VERB (verbs), ADJ (adjectives), ADV (adverbs), PRON (pronouns), DET (determiners), ADP (prepositions or postpositions), NUM (numerals), CONJ (conjunctions), PRT (particles), PUNC 9We extracted only the words and their POS tags from the treebanks. 10Available at http://code.google.com/p/universal-pos-tags/. L(0) = N � i=1 log Z 605 (punctuation marks) and X (a catch-all for other categories such as abbreviations or foreign words). While there might be some controversy about the exact definition of </context>
</contexts>
<marker>Petrov, Das, McDonald, 2011</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011. A universal part-of-speech tagset. ArXiv:1104.2086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Minimized models for unsupervised part-of-speech tagging.</title>
<date>2009</date>
<booktitle>In Proc. of ACL-IJCNLP.</booktitle>
<contexts>
<context position="20940" citStr="Ravi and Knight (2009)" startWordPosition="3482" endWordPosition="3485">(11) Note that when tx(y) = 1 the feature value is 0 and has no effect on the model, while its value is −oc when tx(y) = 0 and constrains the HMM’s state space. This formulation of the constraint feature is equivalent to the use of a tagging dictionary extracted from the graph using a threshold T on the posterior distribution of tags for a given word type (Eq. 7). It would have therefore also been possible to use the integer programming (IP) based approach of 8See §3.1 of Berg-Kirkpatrick et al. (2010) for more details about their modification of EM, and how gradients are computed for L-BFGS. Ravi and Knight (2009) instead of the feature-HMM for POS induction on the foreign side. However, we do not explore this possibility in the current work. 6 Experiments and Results Before presenting our results, we describe the datasets that we used, as well as two baselines. 6.1 Datasets We utilized two kinds of datasets in our experiments: (i) monolingual treebanks9 and (ii) large amounts of parallel text with English on one side. The availability of these resources guided our selection of foreign languages. For monolingual treebank data we relied on the CoNLL-X and CoNLL-2007 shared tasks on dependency parsing (B</context>
</contexts>
<marker>Ravi, Knight, 2009</marker>
<rawString>Sujith Ravi and Kevin Knight. 2009. Minimized models for unsupervised part-of-speech tagging. In Proc. of ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Giorgio Satta</author>
<author>Aravind Joshi</author>
</authors>
<title>Guided learning for bidirectional sequence classification.</title>
<date>2007</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="1297" citStr="Shen et al., 2007" startWordPosition="180" endWordPosition="183"> use the projected labels as features in an unsupervised model (BergKirkpatrick et al., 2010). Across eight European languages, our approach results in an average absolute improvement of 10.4% over a state-of-the-art baseline, and 16.7% over vanilla hidden Markov models induced with the Expectation Maximization algorithm. 1 Introduction Supervised learning approaches have advanced the state-of-the-art on a variety of tasks in natural language processing, resulting in highly accurate systems. Supervised part-of-speech (POS) taggers, for example, approach the level of inter-annotator agreement (Shen et al., 2007, 97.3% accuracy for English). However, supervised methods rely on labeled training data, which is time-consuming and expensive to generate. Unsupervised learning approaches appear to be a natural solution to this problem, as they require only unannotated text for train*This research was carried out during an internship at Google Research. ing models. Unfortunately, the best completely unsupervised English POS tagger (that does not make use of a tagging dictionary) reaches only 76.1% accuracy (Christodoulopoulos et al., 2010), making its practical usability questionable at best. To bridge this</context>
</contexts>
<marker>Shen, Satta, Joshi, 2007</marker>
<rawString>Libin Shen, Giorgio Satta, and Aravind Joshi. 2007. Guided learning for bidirectional sequence classification. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Tahira Naseem</author>
<author>Regina Barzilay</author>
</authors>
<title>Unsupervised multilingual grammar induction.</title>
<date>2009</date>
<booktitle>In Proc. of ACL-IJCNLP.</booktitle>
<contexts>
<context position="2498" citStr="Snyder et al. (2009)" startWordPosition="377" endWordPosition="380">est. To bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like English) when building tools for resource-poor foreign languages.1 We assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language. This scenario is applicable to a large set of languages and has been considered by a number of authors in the past (Alshawi et al., 2000; Xi and Hwa, 2005; Ganchev et al., 2009). Naseem et al. (2009) and Snyder et al. (2009) study related but different multilingual grammar and tagger induction tasks, where it is assumed that no labeled data at all is available. Our work is closest to that of Yarowsky and Ngai (2001), but differs in two important ways. First, we use a novel graph-based framework for projecting syntactic information across language boundaries. To this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project syntactic information from English to the foreign language (§4). Second, we treat the project</context>
<context position="10028" citStr="Snyder et al. (2009)" startWordPosition="1559" endWordPosition="1562">ices from different languages. 3.2 Monolingual Similarity Function Our monolingual similarity function (for connecting pairs of foreign trigram types) is the same as the one used by Subramanya et al. (2010). We briefly review it here for completeness. We define a symmetric similarity function K(uZ7 uj) over two for4This is because we are primarily interested in learning foreign language taggers, rather than improving supervised English taggers. Note, however, that it would be possible to use our graph-based framework also for completely unsupervised POS induction in both languages, similar to Snyder et al. (2009). Description Feature Trigram + Context Trigram Left Context Right Context Center Word Trigram − Center Word Left Word + Right Context Left Context + Right Word Suffix HasSuffix(x3) Table 1: Various features used for computing edge weights between foreign trigram types. eign language vertices uZ7 uj E Vf based on the co-occurrence statistics of the nine feature concepts given in Table 1. Each feature concept is akin to a random variable and its occurrence in the text corresponds to a particular instantiation of that random variable. For each trigram type x2 x3 x4 in a sequence x1 x2 x3 x4 x5, </context>
</contexts>
<marker>Snyder, Naseem, Barzilay, 2009</marker>
<rawString>Benjamin Snyder, Tahira Naseem, and Regina Barzilay. 2009. Unsupervised multilingual grammar induction. In Proc. of ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amar Subramanya</author>
<author>Slav Petrov</author>
<author>Fernando Pereira</author>
</authors>
<title>Efficient graph-based semi-supervised learning of structured tagging models.</title>
<date>2010</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<location>UN.</location>
<contexts>
<context position="8139" citStr="Subramanya et al. (2010)" startWordPosition="1258" endWordPosition="1262">Zhu et al., 2003). Graph construction for structured prediction problems such as POS tagging is non-trivial: on the one hand, using individual words as the vertices throws away the context 3The word alignment methods do not use POS information. 601 necessary for disambiguation; on the other hand, it is unclear how to define (sequence) similarity if the vertices correspond to entire sentences. Altun et al. (2005) proposed a technique that uses graph based similarity between labeled and unlabeled parts of structured data in a discriminative framework for semi-supervised learning. More recently, Subramanya et al. (2010) defined a graph over the cliques in an underlying structured prediction model. They considered a semi-supervised POS tagging scenario and showed that one can use a graph over trigram types, and edge weights based on distributional similarity, to improve a supervised conditional random field tagger. 3.1 Graph Vertices We extend Subramanya et al.’s intuitions to our bilingual setup. Because the information flow in our graph is asymmetric (from English to the foreign language), we use different types of vertices for each language. The foreign language vertices (denoted by Vf) correspond to forei</context>
<context position="9614" citStr="Subramanya et al. (2010)" startWordPosition="1494" endWordPosition="1497">in trigrams. Furthermore, we do not connect the English vertices to each other, but only to foreign language vertices.4 The graph vertices are extracted from the different sides of a parallel corpus (De, Df) and an additional unlabeled monolingual foreign corpus Ff, which will be used later for training. We use two different similarity functions to define the edge weights among the foreign vertices and between vertices from different languages. 3.2 Monolingual Similarity Function Our monolingual similarity function (for connecting pairs of foreign trigram types) is the same as the one used by Subramanya et al. (2010). We briefly review it here for completeness. We define a symmetric similarity function K(uZ7 uj) over two for4This is because we are primarily interested in learning foreign language taggers, rather than improving supervised English taggers. Note, however, that it would be possible to use our graph-based framework also for completely unsupervised POS induction in both languages, similar to Snyder et al. (2009). Description Feature Trigram + Context Trigram Left Context Right Context Center Word Trigram − Center Word Left Word + Right Context Left Context + Right Word Suffix HasSuffix(x3) Tabl</context>
</contexts>
<marker>Subramanya, Petrov, Pereira, 2010</marker>
<rawString>Amar Subramanya, Slav Petrov, and Fernando Pereira. 2010. Efficient graph-based semi-supervised learning of structured tagging models. In Proc. of EMNLP. UN. 2006. ODS UN parallel corpus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proc. of COLING.</booktitle>
<contexts>
<context position="13946" citStr="Vogel et al., 1996" startWordPosition="2226" endWordPosition="2229">s by the supervised tagger. In general, the neighborhoods can be more diverse and we allow a soft label distribution over the vertices. It is worth noting that the middle words of the Italian trigrams are nouns too, which exhibits the fact that the similarity metric connects types having the same syntactic category. In the label propagation stage, we propagate the automatic English tags to the aligned Italian trigram types, followed by further propagation solely among the Italian vertices. 6We ran six iterations of IBM Model 1 (Brown et al., 1993), followed by six iterations of the HMM model (Vogel et al., 1996) in both directions. 7We used a tagger based on a trigram Markov model (Brants, 2000) trained on the Wall Street Journal portion of the Penn Treebank (Marcus et al., 1993), for its fast speed and reasonable accuracy (96.7% on sections 22-24 of the treebank, but presumably much lower on the (out-of-domain) parallel corpus). Figure 1: An excerpt from the graph for Italian. Three of the Italian vertices are connected to an automatically labeled English vertex. Label propagation is used to propagate these tags inwards and results in tag distributions for the middle word of each Italian trigram. 4 </context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann. 1996. HMM-based word alignment in statistical translation. In Proc. of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenhai Xi</author>
<author>Rebecca Hwa</author>
</authors>
<title>A backoff model for bootstrapping resources for non-English languages. In</title>
<date>2005</date>
<booktitle>Proc. of HLT-EMNLP.</booktitle>
<contexts>
<context position="2428" citStr="Xi and Hwa, 2005" startWordPosition="364" endWordPosition="367">os et al., 2010), making its practical usability questionable at best. To bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language (like English) when building tools for resource-poor foreign languages.1 We assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language. This scenario is applicable to a large set of languages and has been considered by a number of authors in the past (Alshawi et al., 2000; Xi and Hwa, 2005; Ganchev et al., 2009). Naseem et al. (2009) and Snyder et al. (2009) study related but different multilingual grammar and tagger induction tasks, where it is assumed that no labeled data at all is available. Our work is closest to that of Yarowsky and Ngai (2001), but differs in two important ways. First, we use a novel graph-based framework for projecting syntactic information across language boundaries. To this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project syntactic information f</context>
</contexts>
<marker>Xi, Hwa, 2005</marker>
<rawString>Chenhai Xi and Rebecca Hwa. 2005. A backoff model for bootstrapping resources for non-English languages. In Proc. of HLT-EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
</authors>
<title>Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In</title>
<date>2001</date>
<booktitle>Proc. of NAACL.</booktitle>
<contexts>
<context position="2693" citStr="Yarowsky and Ngai (2001)" startWordPosition="411" endWordPosition="414">ource-poor foreign languages.1 We assume that absolutely no labeled training data is available for the foreign language of interest, but that we have access to parallel data with a resource-rich language. This scenario is applicable to a large set of languages and has been considered by a number of authors in the past (Alshawi et al., 2000; Xi and Hwa, 2005; Ganchev et al., 2009). Naseem et al. (2009) and Snyder et al. (2009) study related but different multilingual grammar and tagger induction tasks, where it is assumed that no labeled data at all is available. Our work is closest to that of Yarowsky and Ngai (2001), but differs in two important ways. First, we use a novel graph-based framework for projecting syntactic information across language boundaries. To this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project syntactic information from English to the foreign language (§4). Second, we treat the projected labels as features in an unsuper1For simplicity of exposition we refer to the resource-poor language as the “foreign language.” Similarly, we use English as the resource-rich language, but any</context>
<context position="25265" citStr="Yarowsky and Ngai (2001)" startWordPosition="4175" endWordPosition="4178">k et al. (2010) (i.e. no additional constraint feature) served as a second baseline. Model parameters were estimated with L-BFGS and evaluation again used a greedy many-to-1 mapping. • Projection: Our third baseline incorporates bilingual information by projecting POS tags directly across alignments in the parallel data. For unaligned words, we set the tag to the most frequent tag in the corresponding treebank. For each language, we took the same number of sentences from the bitext as there are in its treebank, and trained a supervised feature-HMM. This can be seen as a rough approximation of Yarowsky and Ngai (2001). We tried two versions of our graph-based approach: • No LP: Our first version takes advantage of our bilingual graph, but extracts the constraint feature after the first stage of label propagation (Eq. 1). Because many foreign word types are not aligned to an English word (see Table 3), and we do not run label propagation on the foreign side, we expect the projected information to have less coverage. Furthermore we expect the label distributions on the foreign to be fairly noisy, because the graph constraints have not been taken into account yet. • With LP: Our full model uses both stages of</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>David Yarowsky and Grace Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In Proc. of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojin Zhu</author>
<author>Zoubin Ghahramani</author>
<author>John D Lafferty</author>
</authors>
<title>Semi-supervised learning using gaussian fields and harmonic functions.</title>
<date>2003</date>
<booktitle>In Proc. of ICML.</booktitle>
<contexts>
<context position="7532" citStr="Zhu et al., 2003" startWordPosition="1165" endWordPosition="1168">en be used to transfer the labels to the peripheral foreign vertices (i.e. the ones adjacent to the English vertices) first, and then among all of the foreign vertices (§4). The POS distributions over the foreign trigram types are used as features to learn a better unsupervised POS tagger (§5). The following three sections elaborate these different stages is more detail. 3 Graph Construction In graph-based learning approaches one constructs a graph whose vertices are labeled and unlabeled examples, and whose weighted edges encode the degree to which the examples they link have the same label (Zhu et al., 2003). Graph construction for structured prediction problems such as POS tagging is non-trivial: on the one hand, using individual words as the vertices throws away the context 3The word alignment methods do not use POS information. 601 necessary for disambiguation; on the other hand, it is unclear how to define (sequence) similarity if the vertices correspond to entire sentences. Altun et al. (2005) proposed a technique that uses graph based similarity between labeled and unlabeled parts of structured data in a discriminative framework for semi-supervised learning. More recently, Subramanya et al.</context>
</contexts>
<marker>Zhu, Ghahramani, Lafferty, 2003</marker>
<rawString>Xiaojin Zhu, Zoubin Ghahramani, and John D. Lafferty. 2003. Semi-supervised learning using gaussian fields and harmonic functions. In Proc. of ICML.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>