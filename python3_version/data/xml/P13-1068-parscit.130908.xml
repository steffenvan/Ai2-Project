<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.994738">
Large tagset labeling using Feed Forward Neural Networks. Case
study on Romanian Language
</title>
<author confidence="0.816751">
Tiberiu Boros Radu Ion Dan Tufis
</author>
<sectionHeader confidence="0.422346" genericHeader="method">
Research Institute for
Artificial Intelligence &amp;quot;Mihai
</sectionHeader>
<keyword confidence="0.453601">
Draganescu&amp;quot;,
</keyword>
<sectionHeader confidence="0.917541333333333" genericHeader="method">
Romanian Academy
Research Institute for
Artificial Intelligence &amp;quot;Mihai
</sectionHeader>
<keyword confidence="0.688686">
Draganescu&amp;quot;,
</keyword>
<sectionHeader confidence="0.907481333333333" genericHeader="method">
Romanian Academy
Research Institute for
Artificial Intelligence &amp;quot;Mihai
</sectionHeader>
<keyword confidence="0.555822">
Draganescu&amp;quot;,
</keyword>
<address confidence="0.34691">
Romanian Academy
</address>
<email confidence="0.930805">
tibi@racai.ro radu@racai.ro tufis@racai.ro
</email>
<sectionHeader confidence="0.994559" genericHeader="method">
Abstract
</sectionHeader>
<bodyText confidence="0.981081409090909">
Standard methods for part-of-speech tagging
suffer from data sparseness when used on
highly inflectional languages (which require
large lexical tagset inventories). For this
reason, a number of alternative methods have
been proposed over the years. One of the
most successful methods used for this task,
called Tiered Tagging (Tufis, 1999), exploits
a reduced set of tags derived by removing
several recoverable features from the lexicon
morpho-syntactic descriptions. A second
phase is aimed at recovering the full set of
morpho-syntactic features. In this paper we
present an alternative method to Tiered
Tagging, based on local optimizations with
Neural Networks and we show how, by
properly encoding the input sequence in a
general Neural Network architecture, we
achieve results similar to the Tiered Tagging
methodology, significantly faster and without
requiring extensive linguistic knowledge as
implied by the previously mentioned method.
</bodyText>
<sectionHeader confidence="0.998878" genericHeader="method">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997651981132075">
Part-of-speech tagging is a key process for
various tasks such as `information extraction,
text-to-speech synthesis, word sense
disambiguation and machine translation. It is also
known as lexical ambiguity resolution and it
represents the process of assigning a uniquely
interpretable label to every word inside a
sentence. The labels are called POS tags and the
entire inventory of POS tags is called a tagset.
There are several approaches to part-of-speech
tagging, such as Hidden Markov Models (HMM)
(Brants, 2000), Maximum Entropy Classifiers
(Berger et al., 1996; Ratnaparkhi, 1996),
Bayesian Networks (Samuelsson, 1993), Neural
Networks (Marques and Lopes, 1996) and
Conditional Random Fields (CRF) (Lafferty et
al., 2001). All these methods are primarily
intended for English, which uses a relatively
small tagset inventory, compared to highly
inflectional languages. For the later mentioned
languages, the lexicon tagsets (called morpho-
syntactic descriptions (Calzolari and Monachini,
1995) or MSDs) may be 10-20 times or even
larger than the best known tagsets for English.
For instance Czech MSD tagset requires more
than 3000 labels (Collins et al., 1999), Slovene
more than 2000 labels (Erjavec and Krek, 2008),
and Romanian more than 1100 labels (Tufis,
1999). The standard tagging methods, using such
large tagsets, face serious data sparseness
problems due to lack of statistical evidence,
manifested by the non-robustness of the language
models. When tagging new texts that are not in
the same domain as the training data, the
accuracy decreases significantly. Even tagging
in-domain texts may not be satisfactorily
accurate.
One of the most successful methods used for
this task, called Tiered Tagging (Tufis, 1999),
exploits a reduced set of tags derived by
removing several recoverable features from the
lexicon morpho-syntactic descriptions.
According to the MULTEXT EAST lexical
specifications (Erjavec and Monachini, 1997),
the Romanian tagset consists of a number of 614
MSD tags (by exploiting the case and gender
regular syncretism) for wordforms and 10
punctuation tags (Tufis et al., 1997), which is
still significantly larger than the tagset of
English. The MULTEX EAST version 4
(Erjavec, 2010) contains specifications for a total
of 16 languages: Bulgarian, Croatian, Czech,
Estonian, English, Hungarian, Romanian,
</bodyText>
<page confidence="0.992012">
692
</page>
<bodyText confidence="0.885856571428572">
Serbian, Slovene, the Resian dialect of Slovene,
Macedonian, Persian, Polish, Russian, Slovak,
and Ukrainian
The strategy of the Tiered Tagging
methodology is to use a reduced tagset (called
CTAG-set), where a CTAG is a generalization of
a MSD, from which recoverable context-
irrelevant features are removed. For instance, the
attribute for gender (masculine `rn&apos; or feminine
&apos;f&apos;) from MSDs `Ncfsrn&apos; and `Ncmsrn&apos; is deleted
to obtain the CTAG `NSRN&apos;, because the gender
information can be deterministically recovered
based on the CTAG and the wordform itself. The
recovering of the left out attributes (Figure 1) is
based on the lexicons, linguistic rules and, in the
case of unknown words, on ML techniques
(Ceausu, 2006). When tagging with CTAGs, one
can use any statistical POS tagging method such
as HMMs, Maximum Entropy Classifiers,
Bayesian Networks, CRFs, etc., followed by the
CTAG to MSD recovery.
</bodyText>
<table confidence="0.947712333333333">
Training data
Training
Converting from
MSDs to CTAGS
Training a POS tagger Manual+automatic
rules for MSD recovery
Tagging
Labeling with CTAGS MSD Recovery
Text Tagged text
</table>
<figureCaption confidence="0.990462">
Figure 1 - Tiered Tagging methodology
</figureCaption>
<bodyText confidence="0.910543466666667">
The language dependent process of manually
inferring linguistic rules for MSD recovery
requires good knowledge of the target language
and also extensive amounts of time invested in
testing and re-design. It is difficult even for a
native speaker to create such rules without in-
depth linguistic knowledge.
In this article, we propose an alternative
solution based on local optimizations with feed-
forward neural networks. Our method eliminates
the need for the two stage processing, is much
faster at run time and is comparatively accurate
with the Tiered Tagging implemented in the TTL
tagger (Ion, 2007), available in the
METAS HARE Platforml.
</bodyText>
<footnote confidence="0.503239">
http://ws.racai.ro:9191/
</footnote>
<bodyText confidence="0.993524386363636">
2 Large tagset part-of-speech tagging
with feed-forward neural networks
Although removing the recoverable attributes, as
proposed in the Tiered Tagging approach, helps
the goal of squeezing the lexical tagset to a
reasonable size, valuable information for
contextual disambiguation is also lost. For
example, the gender agreement rule, valid in
many languages, cannot be exploited unless the
gender attribute is present in the tags.
Our proposal to deal with large tagsets without
removing contextually useful information is
based on Feed Forward Neural Networks
(FFNN). FFNN are known for their simplicity
and robustness in finding and recombining
patterns inside data.
Several neural network architectures have
been proposed for the task of part-of-speech
tagging. Schmid (1994) proposed a FFNN
architecture for part-of-speech tagging obtaining
a 96.22% accuracy. In his paper, he argues that
neural networks are preferable to other methods,
when the training set is small. He compares his
results with a HMM tagger (94.24%) and a
trigram tagger (96.02%), both trained and tested
on the same corpora as his FFNN tagger (the
Penn-Treebank corpus). A similar approach is
presented by Marques and Lopes (1996). In their
paper, the authors come to similar conclusions as
those presented in Schmid (1994). We support
these findings with an additional argument,
namely the better fit for managing large tagsets.
In both approaches mentioned before, the
network is trained so that from the input vector,
to output a real valued vector. Each value in the
output vector is generated by a distinct neuron,
and corresponds to a unique tag in the tagset (e.g.
100 tags means the network contains 100
neurons on the output layer). The input vector for
predicting the tag of the current word encodes
the tags for the previously tagged words and the
probable tags for the current and following two
words, estimated using Maximum Likelihood
Estimation (MLE):
</bodyText>
<equation confidence="0.996401571428571">
C(w, t)
p(t1w)
C(w, t) -
Input data
Output data
P(t1w) —
C (w)
</equation>
<bodyText confidence="0.90637525">
The probability of the word w
having tag t
The total number of times, the
word w appears with tag tin the
training corpus
The total number of times, the
C(w) - word w appears in the training
corpus
</bodyText>
<equation confidence="0.908055">
(1)
</equation>
<page confidence="0.993545">
693
</page>
<bodyText confidence="0.999977685714286">
In the case of out-of-vocabulary (OOV)
words, both approaches use suffix analysis to
determine the most probable tags that can be
assigned to the current word.
To clarify how these two methods work, if we
want to train the network to label the current
word, using a context window of 1 (previous tag,
current possible tags, and possible tags for the
next word) and if we have, say 100 tags in the
tagset, the input is a real valued vector of 300
sub-unit elements and the output is a vector
which contains 100 elements, also sub-unit real
numbers. As mentioned earlier, each value in the
output vector corresponds to a distinct tag from
tagset and the tag assigned to the current word is
chosen to correspond to the maximum value
inside the output vector.
The previously proposed methods still suffer
from the same issue of data sparseness when
applied to MSD tagging. However, in our
approach, we overcome the problem through a
different encoding of the input data (see section
2.1).
The power of neural networks results mainly
from their ability to attain activation functions
over different patterns via their learning
algorithm. By properly encoding the input
sequence, the network chooses which input
features contribute in determining the output
features for MSDs (e.g. patterns composed of
part of speech, gender, case, type etc. contribute
independently in selecting the optimal output
sequence). This way, we removed the need for
explicit MSD to CTAG conversion and MSD
recovery from CTAGs.
</bodyText>
<subsectionHeader confidence="0.979982">
2.1 The MSD binary encoding scheme
</subsectionHeader>
<bodyText confidence="0.999871304347826">
A MSD language independently encodes a part
of speech (POS) with the associated lexical
attribute values as a string of positional ordered
character codes (Erjavec, 2004). The first
character is an upper case character denoting the
part of speech (e.g. `N&apos; for nouns, `V&apos; for verbs,
`A&apos; for adjectives, etc.) and the following
characters (lower letters or `-`) specify the
instantiations of the characteristic lexical
attributes of the POS. For example, the MSD
`Ncfsrn&apos;, specifies a noun (the first character is
`N&apos;) the type of which is common (`c&apos;, the
second character), feminine gender (`f&apos;), singular
number (`s&apos;), in nominative/accusative case (`r&apos;)
and indefinite form (`n&apos;). If a specific attribute is
not relevant for a language, or for a given
combination of feature-values, the character `-&apos; is
used in the corresponding position. For a
language which does not morphologically mark
the gender and definiteness features, the earlier
exemplified MSD will be encoded as `Nc-sr-&apos;.
In order to derive a binary vector for each of
the 614 MSDs of Romanian we proceeded to:
</bodyText>
<listItem confidence="0.9855659375">
1. List and sort all possible POSes of
Romanian (16 POSes) and form a binary
vector with 16 positions in which position k
is equal 1 only if the respective MSD has
the corresponding POS (i.e. the k-th POS in
the sorted list of POSes);
2. List and sort all possible values of all lexical
attributes (disregarding the wildcard `-`) for
all POSes (94 values) and form another
binary vector with 94 positions such that the
k-th position of this vector is 1 if the
respective MSD has an attribute with the
corresponding value;
3. Concatenate the vectors from steps 1 and 2
and obtain the binary codification of a MSD
as a 110-position binary vector.
</listItem>
<subsectionHeader confidence="0.999431">
2.2 The training and tagging procedure
</subsectionHeader>
<bodyText confidence="0.999795736842105">
The tagger automatically assigns four dummy
tokens (two at the beginning and two at the end)
to the target utterance and the neural network is
trained to automatically assign a MSD given the
context (two previously assigned tags and the
possible tags for the current and following two
words) of the current word (see below for
details).
In our framework a training example consists
of the features extracted for a single word inside
an utterance as input and it&apos;s MSD within that
utterance as output. The features are extracted
from a window of 5 words centered on the
current word. A single word is characterized by a
vector that encodes either its assigned MSD or its
possible MSDs. To encode the possible MSDs
we use equation 2, where each possible attribute
a, has a single corresponding position inside the
encoded vector.
</bodyText>
<equation confidence="0.995855666666667">
C(w� a)
P(a�w) = (2)
C(w)
</equation>
<bodyText confidence="0.999626833333333">
Note that we changed the probability
estimates to account for attributes not tags.
To be precise, for every word wk, we obtain its
input features by concatenating a number of 5
vectors. The first two vectors encode the MSDs
assigned to the previous two words (wk-1 and wk-
</bodyText>
<page confidence="0.994716">
694
</page>
<bodyText confidence="0.99997534375">
2).The next three vectors are used to encode the
possible MSDs for the current word (wk) and the
following two words (wk+1 and wk+2).
During training, we also compute a list of
suffixes with associated MSDs, which is used at
run-time to build the possible MSDs vector for
unknown words. When such words are found
within the test data, we approximate their
possible MSDs vector using a variation of the
method proposed by Brants (2000).
When the tagger is applied to a new utterance,
the system iteratively calculates the output MSD
for each individual word. Once a label has been
assigned to a word, the word&apos;s associated vector
is edited so it will have the value of 1 for each
attribute present in its newly assigned MSD.
As a consequence of encoding each individual
attribute separately for MSDs, the tagger can
assign new tags (that were never associated with
the current word in the training corpus).
Although this is a nice behavior for dealing with
unknown words it is often the case that it assigns
attribute values that are not valid for the
wordform. To overcome these types of errors we
use an additional list of words with their allowed
MSDs. For an OOV word, the list is computed as
a union from all MSDs that appeared with the
suffixes that apply to that word.
When the tagger has to assign a MSD to a
given word, it selects one from the possible
wordform&apos;s MSDs in its wordform/MSDs
associated list using a simple distance function:
</bodyText>
<equation confidence="0.9839555">
n
mien 10k — ek
eÐ (3)
k=0
</equation>
<bodyText confidence="0.99123">
The length of the MSD
encoding (110 bits)
The output of the Neural
Network for the current word
e - Binary encoding for a MSD in P
</bodyText>
<sectionHeader confidence="0.998077" genericHeader="method">
3 Network hyperparameters
</sectionHeader>
<bodyText confidence="0.9998243">
In our experiments, we used a fully connected,
feed forward neural network with 3 layers (1
input layer, 1 hidden layer and 1 output layer)
and a sigmoid activation function (equation 3).
While other network architectures such as
recurrent neural networks may prove to be more
suitable for this task, they are extremely hard to
train, thus, we traded the advantages of such
architectures for the robustness and simplicity of
the feed-forward networks.
</bodyText>
<equation confidence="0.922846">
(3)
1+e-t
f(t) - Neuron output
</equation>
<bodyText confidence="0.968806461538462">
The weighted sum of all the
t - neuron outputs from the
previous layer
Based on the size of the vectors used for MSD
encoding, the output layer has 110 neurons and
the input layer is composed of 550 (5 x 110)
neurons.
In order to fully characterize our system, we
took into account the following parameters:
accuracy, runtime speed, training speed, hidden
layer configuration and the number of optimal
training iterations. These parameters have
complex dependencies and relations among each
other. For example, the accuracy, the optimal
number of training iterations, the training and the
runtime speed are all highly dependent on the
hidden layer configuration. Small hidden layer
give high training and runtime speeds, but often
under-fit the data. If the hidden layer is too large,
it can easily over-fit the data and also has a
negative impact on the training and runtime
speed. The number of optimal training iterations
changes with the size of the hidden layer (larger
layers usually require more training iterations).
To obtain the trade-offs between the above
mentioned parameters we devised a series of
experiments, in all of which we used the &amp;quot;1984&amp;quot;
MSD annotated corpus, which is composed of
118,025 words. We randomly kept out
approximately 1/10 (11,960 words) of the
training corpus for building a cross-validation
set. The baseline accuracy on the cross-validation
set (i.e. returning the most probable tag) is
93.29%. We also used an additional inflectional
wordform/MSD lexicon composed of
approximately 1 million hand-validated entries.
The list of all possible MSDs
P
- for the given word
</bodyText>
<equation confidence="0.837959">
n -
0 -
f(t) =
</equation>
<page confidence="0.880172">
695
</page>
<figure confidence="0.682136911764706">
Accuracy
1 Test set
0.995 Train set
0.99
0.985
0.98
0.975
0.97
1
5
9
13
17
21
25
29
33
37
41
45
49
53
57
61
65
69
73
77
81
85
89
93
97
Number of iterrations
</figure>
<figureCaption confidence="0.989322">
Figure 2 - 130 hidden layer network test and train set tagging accuracy as a function of the number of iterations
</figureCaption>
<bodyText confidence="0.9985764">
The first experiment was designed to
determine the trade-off between the run-time
speed and the size of the hidden layer. We made
a series of experiments disregarding the tagging
accuracy.
</bodyText>
<table confidence="0.964995866666667">
Hidden size Time (ms) Words/sec
50 1530 7816
70 1888 6334
90 2345 5100
110 2781 4300
130 3518 3399
150 5052 2367
170 5466 2188
190 6734 1776
210 7096 1685
230 8332 1435
250 9576 1248
270 10350 1155
290 11080 1079
310 12364 967
</table>
<tableCaption confidence="0.954918">
Table 1 - Execution time vs. number of neurons on
the hidden layer
</tableCaption>
<bodyText confidence="0.999942222222222">
Because, for a given number of neurons in the
hidden layer, the tagging speed is independent on
the tagging accuracy, we partially trained (using
one iteration and only 1000 training sentences)
several network configurations. The first network
only had 50 neurons in the hidden layer and for
the next networks, we incremented the hidden
layer size by 20 neurons until we reached 310
neurons. The total number of tested networks is
14. After this, we measured the time it took to
tag the 1984 test corpus (11,960 words) for each
individual network, as an average of 3 tagging
runs in order to reduce the impact of the
operating system load on the tagger (Table 1
shows the figures).
Determining the optimal size of the hidden
layer is a very delicate subject and there are no
perfect solutions, most of them being based on
trial and error: small-sized hidden layers lead to
under-fitting, while large hidden layers usually
cause over-fitting. Also, because of the trade-off
between runtime speed and the size of hidden
layers, and if runtime speed is an important
factor in a particular NLP application, then
hidden layers with smaller number of neurons are
preferable, as they surely do not over-fit the data
and offer a noticeable speed boost.
</bodyText>
<table confidence="0.984416666666667">
hidden Train set Cross
layer accuracy validation
accuracy
50 99.18 97.95
70 99.20 98.02
90 99.27 98.03
110 99.29 98.05
130 99.35 98.12
150 99.35 98.09
170 99.41 98.07
190 99.40 98.10
210 99.40 98.21
</table>
<tableCaption confidence="0.988924">
Table 2 - Train and test accuracy rates for different
hidden layer configurations
</tableCaption>
<bodyText confidence="0.999952545454545">
As shown in Table 1, the runtime speed of our
system shows a constant decay when we increase
the hidden layer size. The same decay can be
seen in the training speed, only this time by an
order of magnitude larger. Because training a
single network takes a lot of time, this
experiment was designed to estimate the size of
the hidden layer which offers good performance
in tagging. To do this, we individually trained a
number of networks in 30 iterations, using
various hidden layer configurations (50, 70, 90,
</bodyText>
<page confidence="0.998124">
696
</page>
<bodyText confidence="0.999947679245283">
110, 130, 150, 170, 190, and 210 neurons) and 5
initial random initializations of the weights. For
each configuration, we stored the accuracy of
reproducing the learning data (the tagging of the
training corpus) and the accuracy on the unseen
data (test sets). The results are shown in Table 2.
Although a hidden layer of 210 neurons did not
seem to over-fit the data, we stopped the
experiment, as the training time got significantly
longer.
The next experiment was designed to see how
the number of training iterations influences the
tagging performance of networks with different
hidden layer configurations. Intuitively, the
training process must be stopped when the
network begins to over-fit the data (i.e. the train
set accuracy increases, but the test set accuracy
drops). Our experiments indicate that this is not
always the case, as in some situations the
continuation of the training process leads to
better results on the cross-validation data (as
shown in Figure 2). So, the problem comes to
determining which is the most stable
configuration of the neural network (i.e. which
hidden unit size will be most likely to return
good results on the test set) and establish the
number of iterations it takes for the system to be
trained. To do this, we ran the training procedure
for 100 iterations and for each training iteration,
we computed the accuracy rate of every
individual network on the cross-validation set
(see Table 3 for the averaged values). As shown,
the network configuration using 130 neurons on
the hidden layer is most likely to produce better
results on the cross-validation set regardless of
the number of iterations.
Although, some other configurations provided
better figures for the maximum accuracy, their
average accuracy is lower than that of the 130
hidden unit network. Other good candidates are
the 90 and 110 hidden unit networks, but not the
larger valued ones, which display a lower
average accuracy and also significantly slower
tagging speeds.
The most suitable network configuration for a
given task depends on the language, MSD
encoding size, speed and accuracy requirements.
In our own daily applications we use the 130
hidden unit network. After observing the
behavior of the various networks on the cross-
validation set we determined that a good choice
is to stop the training procedure after 40
iterations.
</bodyText>
<table confidence="0.996544454545454">
Hidden Avg. acc. Max. acc. St. dev.
units
50 97.94 98.31 0.127002
70 98.03 98.31 0.12197
50 97.94 98.37 0.139762
70 98.03 98.43 0.124996
90 98.07 98.39 0.134487
110 98.08 98.45 0.127109
130 98.14 98.44 0.136072
150 98.01 98.36 0.143324
170 97.94 98.36 0.122834
</table>
<tableCaption confidence="0.990677666666667">
Table 3 - Average and maximum accuracy for various
hidden layer configuration calculated over 100
training iterations on the test set
</tableCaption>
<bodyText confidence="0.999982692307692">
To obtain the accuracy of the system, in our
last experiment we used the 130 hidden unit
network and we performed the training/testing
procedure on the 1984 corpus, using 10-fold
validation and 30 random initializations. The
final accuracy was computed as an average
between all the accuracy figures measured at the
end of the training process (after 40 iterations).
The first 1/10 of the 1984 corpus on which we
tuned the hyperparameters was not included in
the test data, but was used for training. The mean
accuracy of the system (98.41%) was measured
as an average of 270 values.
</bodyText>
<sectionHeader confidence="0.875136" genericHeader="method">
4 Comparison to other methods
</sectionHeader>
<bodyText confidence="0.999972761904762">
In his work, Ceausu (2006) presents a
different approach to MSD tagging using the
Maximum Entropy framework. He presents his
results on the same corpus we used for training
and testing (the 1984 corpus) and he compares
his method (98.45% accuracy) with the Tiered
Tagging methodology (97.50%) (Tufis and
Dragomirescu, 2004).
Our Neural Network approach obtained
similar (slightly lower) results (98.41%),
although it is arguable that our split/train
procedure is not identical to the one used in his
work (no details were given as how the 1/10 of
the training corpus was selected). Also, our POS
tagger detected cases where the annotation in the
Gold Standard was erroneous. One such example
is in &amp;quot;lame de ras&amp;quot; (English &amp;quot;razor blades&amp;quot;)
where &amp;quot;lame&amp;quot; (English &amp;quot;blades&amp;quot;) is a noun, &amp;quot;de&amp;quot;
(&amp;quot;for&amp;quot;) is a preposition and &amp;quot;ras&amp;quot; (&amp;quot;shaving&amp;quot;) is a
supine verb (with a past participle form) which
was incorrectly annotated as a noun.
</bodyText>
<page confidence="0.997735">
697
</page>
<sectionHeader confidence="0.9309" genericHeader="method">
5 Network pattern analysis
</sectionHeader>
<bodyText confidence="0.999981407407407">
Using feed-forward neural networks gives the
ability to outline what input features contribute to
the selection of various MSD attribute values in
the output layer which might help in reducing the
tagset and thus, redesigning the network
topology with beneficial effects both on the
speed and accuracy.
To determine what input features contribute to
the selection of certain MSD attribute values, one
can analyze the weights inside the neural
network and extract the input 4 output links that
are formed during training. We used the network
with 130 units on the hidden layer, which was
previously trained for 100 iterations. Based on
the input encoding, we divided the features into 5
groups (one group for each MSD inside the local
context — two previous MSDs, current and
following two possible MSDs). For a target
attribute value (noun, gender feminine, gender
masculine, etc.) and for each input group, we
selected the top 3 input values which support the
decision of assigning the target value to the
attribute (features that increase the output value)
and the top 3 features which discourage this
decision (features that decrease the output value).
For clarity, we will use the following notations
for the groups:
</bodyText>
<listItem confidence="0.9982361">
• G-2: group one — the assigned MSD for
the word at position i-2
• G-1: group two — the assigned MSD for
the word at position i-1
• G0: group three — the possible MSDs for
the word at position i
• G1: group four— the possible MSDs for
the word at position i+1
• G2: group five — the possible MSDs for
the word at position i+2
</listItem>
<bodyText confidence="0.734115842857143">
where i corresponds to the position of the word
which is currently being tagged. Also, we
classify the attribute values into two categories
(C): (P) want to see (support the decision) and
(N) don&apos;t want to see (discourage the decision).
Table 4 shows partial (G-1 G0 G1) examples of
two target attribute values (cat=Noun and gender
=Feminine) and their corresponding input
features used for discrimination.
Target Group C Attribute values
value
Noun G-1 P main (of a verb), article,
masculine (gender of a
noun/adjective
N particle, conjunctive particle,
auxiliary (of a verb),
demonstrative (of a pronoun)
G0 P noun, common/proper (of a
noun)
N adverb, pronoun, numeral,
interrogative/relative (of a
pronoun)
G1 P genitive/dative (of a
noun/adjective), particle,
punctuation
N conjunctive particle, strong (of
a pronoun), non-definite (of a
noun/adjective), exclamation
mark
Fem. G-1 P main (of a verb), preposition,
feminine (of a
noun/adjective)
N auxiliary (of a verb), particle,
demonstrative (of a pronoun)
G0 P feminine (of a
noun/adjective),
nominative/accusative (of a
noun/adjective), past (of a
verb)
N masculine (of a
noun/adjective), auxiliary (of a
verb), interrogative/relative (of
a pronoun), adverb
G1 P dative/genitive (of a
noun/adjective), indicative (of
a verb), feminine (of a
noun/adjective)
N conjunctive particle, future
particle, nominative/accusative
(of a noun/adjective)
Table 4 — P/N features for various attribute
values.
For instance, when deciding on whether to give a
noun (N) label to current position (G0), we can
see that the neural network has learned some
interesting dependencies: at position G-1 we find
an article (which frequently determines a noun)
and at the current position it is very important for
the word being tagged to actually be a common
or proper noun (either by lexicon lookup or by
suffix guessing) and not be an adverb, pronoun
or numeral (POSes that cannot be found in the
typical ambiguity class of a noun). At the next
position of the target (G1) we also find a noun in
genitive or dative, corresponding to a frequent
construction in Romanian, e.g. &amp;quot;masina
baiatului&amp;quot; being a sequence of two nouns, the
second at genitive/dative.
If the neural network outputs the feminine
gender to its current MSD, one may see that it
</bodyText>
<page confidence="0.996134">
698
</page>
<bodyText confidence="0.999944">
has actually learned the agreement rules (at least
locally): the feminine gender is present both
before (G-1) the target word as well as after it
(G1).
</bodyText>
<sectionHeader confidence="0.987956" genericHeader="conclusions">
6 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999985646153846">
We presented a new approach for large tagset
part-of-speech tagging using neural networks. An
advantage of using this methodology is that it
does not require extensive knowledge about the
grammar of the target language. When building a
new MSD tagger for a new language one is only
required to provide the training data and create
an appropriate MSD encoding system and as
shown, the MSD encoding algorithm is fairly
simple and our proposed version works for any
other MSD compatible encoding, regardless of
the language.
Observing which features do not participate in
any decision helps design custom topologies for
the Neural Network, and provides enhancements
in both speed and accuracy. The configurable
nature of our system allows users to provide their
own MSD encodings, which permits them to
mask certain features that are not useful for a
given NLP application.
If one wants to process a large amount of text
and is interested only in assigning grammatical
categories to words, he can use a MSD encoding
in which he strips off all unnecessary features.
Thus, the number of necessary neurons would
decrease, which assures faster training and
tagging. This is of course possible in any other
tagging approaches, but our framework supports
this by masking attributes inside the MSD
encoding configuration file, without having to
change anything else in the training corpus.
During testing the system only verifies if the
MSD encodings are identical and the displayed
accuracy directly reflects the performance of the
system on the simplified tagging schema.
We also proposed a methodology for selecting
a network configurations (i.e. number of hidden
units), which best suites the application
requirements. In our daily applications we use a
network with 130 hidden units, as it provides an
optimal speed/accuracy trade-off (approx. 3400
words per second with very good average
accuracy).
The tagger is implemented as part of a larger
application that is primarily intended for text-to-
speech (TTS) synthesis. The system is free for
non-commercial use and we provide both web
and desktop user-interfaces. It is part of the
METASHARE platform and available online2.
Our primary goal was to keep the system
language independent, thus all our design choices
are based on the necessity to avoid using
language specific knowledge, when possible. The
application supports various NLP related tasks
such as lexical stress prediction, syllabification,
letter-to-sound conversion, lemmatization,
diacritic restoration, prosody prediction from text
and the speech synthesizer uses unit-selection.
From the tagging perspective, our future plans
include testing the system on other highly
inflectional languages such as Czech and
Slovene and investigating different methods for
automatically determining a more suitable
custom network topology, such as genetic
algorithms.
</bodyText>
<sectionHeader confidence="0.999026" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.993801">
The work reported here was funded by the
project METANET4U by the European
Commission under the Grant Agreement No
270893
</bodyText>
<footnote confidence="0.962091">
2 http://ws.racai.ro:9191
</footnote>
<page confidence="0.988931">
699
</page>
<note confidence="0.5790954">
Lexicons and Corpora. In Proceedings of the
Seventh International Conference on Language
Resources and Evaluation (LREC&apos;10), Valletta,
Malta. European Language Resources Association
(ELRA) ISBN 2-9517408-6-7.
</note>
<sectionHeader confidence="0.695952" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.973929279411765">
Berger, A. L., Pietra, V. J. D. and Pietra, S. A. D.
1996. A maximum entropy approach to natural
language processing. Computational linguistics,
22(1), 39-71.
Brants, T. 2000. TnT: a statistical part-of-speech
tagger. In Proceedings of the sixth conference on
applied natural language processing (pp. 224-231).
Association for Computational Linguistics.
Calzolari, N. and Monachini M. (eds.). 1995.
Common Specifications and Notation for Lexicon
Encoding and Preliminary Proposal for the
Tagsets. MULTEXT Report, March.
Ceausu, A. 2006. Maximum entropy tiered tagging. In
Proceedings of the 11th ESSLLI Student Session
(pp. 173-179).
Collins, M., Ramshaw, L., Hajic, J. and Tillmann, C.
1999. A statistical parser for Czech. In Proceedings
of the 37th annual meeting of the Association for
Computational Linguistics on Computational
Linguistics (pp. 505-512). Association for
Computational Linguistics.
Erjavec, T. and Monachini, M. (Eds.). 1997.
Specifications and Notation for Lexicon Encoding.
Deliverable D1.1 F. Multext-East Project COP-
106.
Erjavec, T. 2004. MULTEXT-East version 3:
Multilingual morphosyntactic specifications,
lexicons and corpora. In Fourth International
Conference on Language Resources and
Evaluation, LREC (Vol. 4, pp. 1535-1538).
Erjavec, T. and Krek, S. 2008. The JOS
morphosyntactically tagged corpus of Slovene. In
Proceedings of the Sixth International Conference
on Language Resources and Evaluation, LREC&apos;08.
Erjavec, T. 2010. MULTEXT-East Version 4:
Multilingual Morphosyntactic Specifications,
Lafferty, J., McCallum, A. and Pereira, F. C. 2001.
Conditional random fields: Probabilistic models
for segmenting and labeling sequence data.
Marques, N. C. and Lopes, G. P. 1996. A neural
network approach to part-of-speech tagging. In
Proceedings of the 2nd Meeting for Computational
Processing of Spoken and Written Portuguese (pp.
21-22).
Ratnaparkhi, A. 1996. A maximum entropy model for
part-of-speech tagging. In Proceedings of the
conference on empirical methods in natural
language processing (Vol. 1, pp. 133-142).
Samuelsson, C. 1993. Morphological tagging based
entirely on Bayesian inference. In 9th Nordic
Conference on Computational Linguistics.
Schmid, H. 1994. Part-of-speech tagging with neural
networks. In Proceedings of the 15th conference on
Computational linguistics-Volume 1 (pp. 172-176).
Association for Computational Linguistics.
Tufis, D., Barbu A.M., Patra�cu V., Rotariu G. and
Popescu C. 1997. Corpora and Corpus-Based
Morpho-Lexical Processing. In Recent Advances
in Romanian Language Technology, (pp. 35-56).
Romanian Academy Publishing House, ISBN 973-
27-0626-0.
Tufis, D. 1999. Tiered tagging and combined
language models classifiers. In Text, Speech and
Dialogue (pp. 843-843). Springer
Berlin/Heidelberg.
Tufis, D., and Dragomirescu, L. 2004. Tiered tagging
revisited. In Proceedings of the 4th LREC
Conference (pp. 39-42).
</reference>
<page confidence="0.996415">
700
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.090894">
<title confidence="0.9716675">Large tagset labeling using Feed Forward Neural Networks. study on Romanian Language</title>
<author confidence="0.999626">Ion Dan</author>
<affiliation confidence="0.9379335">Research Institute Artificial Intelligence</affiliation>
<author confidence="0.682524">Romanian Academy</author>
<affiliation confidence="0.9373305">Research Institute Artificial Intelligence</affiliation>
<author confidence="0.682709">Romanian Academy</author>
<affiliation confidence="0.9317655">Research Institute Artificial Intelligence</affiliation>
<author confidence="0.692834">Romanian Academy</author>
<email confidence="0.495385">tibi@racai.roradu@racai.rotufis@racai.ro</email>
<abstract confidence="0.998509217391304">Standard methods for part-of-speech tagging suffer from data sparseness when used on highly inflectional languages (which require large lexical tagset inventories). For this reason, a number of alternative methods have been proposed over the years. One of the most successful methods used for this task, Tiered Tagging 1999), exploits a reduced set of tags derived by removing several recoverable features from the lexicon morpho-syntactic descriptions. A second phase is aimed at recovering the full set of morpho-syntactic features. In this paper we present an alternative method to Tiered Tagging, based on local optimizations with Neural Networks and we show how, by properly encoding the input sequence in a general Neural Network architecture, we achieve results similar to the Tiered Tagging methodology, significantly faster and without requiring extensive linguistic knowledge as implied by the previously mentioned method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>V J D Pietra</author>
<author>S A D Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<pages>39--71</pages>
<contexts>
<context position="1957" citStr="Berger et al., 1996" startWordPosition="271" endWordPosition="274"> by the previously mentioned method. 1 Introduction Part-of-speech tagging is a key process for various tasks such as `information extraction, text-to-speech synthesis, word sense disambiguation and machine translation. It is also known as lexical ambiguity resolution and it represents the process of assigning a uniquely interpretable label to every word inside a sentence. The labels are called POS tags and the entire inventory of POS tags is called a tagset. There are several approaches to part-of-speech tagging, such as Hidden Markov Models (HMM) (Brants, 2000), Maximum Entropy Classifiers (Berger et al., 1996; Ratnaparkhi, 1996), Bayesian Networks (Samuelsson, 1993), Neural Networks (Marques and Lopes, 1996) and Conditional Random Fields (CRF) (Lafferty et al., 2001). All these methods are primarily intended for English, which uses a relatively small tagset inventory, compared to highly inflectional languages. For the later mentioned languages, the lexicon tagsets (called morphosyntactic descriptions (Calzolari and Monachini, 1995) or MSDs) may be 10-20 times or even larger than the best known tagsets for English. For instance Czech MSD tagset requires more than 3000 labels (Collins et al., 1999),</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Berger, A. L., Pietra, V. J. D. and Pietra, S. A. D. 1996. A maximum entropy approach to natural language processing. Computational linguistics, 22(1), 39-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brants</author>
</authors>
<title>TnT: a statistical part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the sixth conference on applied natural language processing</booktitle>
<pages>224--231</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="1907" citStr="Brants, 2000" startWordPosition="266" endWordPosition="267">ng extensive linguistic knowledge as implied by the previously mentioned method. 1 Introduction Part-of-speech tagging is a key process for various tasks such as `information extraction, text-to-speech synthesis, word sense disambiguation and machine translation. It is also known as lexical ambiguity resolution and it represents the process of assigning a uniquely interpretable label to every word inside a sentence. The labels are called POS tags and the entire inventory of POS tags is called a tagset. There are several approaches to part-of-speech tagging, such as Hidden Markov Models (HMM) (Brants, 2000), Maximum Entropy Classifiers (Berger et al., 1996; Ratnaparkhi, 1996), Bayesian Networks (Samuelsson, 1993), Neural Networks (Marques and Lopes, 1996) and Conditional Random Fields (CRF) (Lafferty et al., 2001). All these methods are primarily intended for English, which uses a relatively small tagset inventory, compared to highly inflectional languages. For the later mentioned languages, the lexicon tagsets (called morphosyntactic descriptions (Calzolari and Monachini, 1995) or MSDs) may be 10-20 times or even larger than the best known tagsets for English. For instance Czech MSD tagset requ</context>
<context position="12600" citStr="Brants (2000)" startWordPosition="1991" endWordPosition="1992">, for every word wk, we obtain its input features by concatenating a number of 5 vectors. The first two vectors encode the MSDs assigned to the previous two words (wk-1 and wk694 2).The next three vectors are used to encode the possible MSDs for the current word (wk) and the following two words (wk+1 and wk+2). During training, we also compute a list of suffixes with associated MSDs, which is used at run-time to build the possible MSDs vector for unknown words. When such words are found within the test data, we approximate their possible MSDs vector using a variation of the method proposed by Brants (2000). When the tagger is applied to a new utterance, the system iteratively calculates the output MSD for each individual word. Once a label has been assigned to a word, the word&apos;s associated vector is edited so it will have the value of 1 for each attribute present in its newly assigned MSD. As a consequence of encoding each individual attribute separately for MSDs, the tagger can assign new tags (that were never associated with the current word in the training corpus). Although this is a nice behavior for dealing with unknown words it is often the case that it assigns attribute values that are n</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Brants, T. 2000. TnT: a statistical part-of-speech tagger. In Proceedings of the sixth conference on applied natural language processing (pp. 224-231). Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Calzolari</author>
<author>M Monachini</author>
</authors>
<date>1995</date>
<booktitle>Common Specifications and Notation for Lexicon Encoding and Preliminary Proposal for the Tagsets. MULTEXT Report,</booktitle>
<contexts>
<context position="2388" citStr="Calzolari and Monachini, 1995" startWordPosition="328" endWordPosition="331">e inventory of POS tags is called a tagset. There are several approaches to part-of-speech tagging, such as Hidden Markov Models (HMM) (Brants, 2000), Maximum Entropy Classifiers (Berger et al., 1996; Ratnaparkhi, 1996), Bayesian Networks (Samuelsson, 1993), Neural Networks (Marques and Lopes, 1996) and Conditional Random Fields (CRF) (Lafferty et al., 2001). All these methods are primarily intended for English, which uses a relatively small tagset inventory, compared to highly inflectional languages. For the later mentioned languages, the lexicon tagsets (called morphosyntactic descriptions (Calzolari and Monachini, 1995) or MSDs) may be 10-20 times or even larger than the best known tagsets for English. For instance Czech MSD tagset requires more than 3000 labels (Collins et al., 1999), Slovene more than 2000 labels (Erjavec and Krek, 2008), and Romanian more than 1100 labels (Tufis, 1999). The standard tagging methods, using such large tagsets, face serious data sparseness problems due to lack of statistical evidence, manifested by the non-robustness of the language models. When tagging new texts that are not in the same domain as the training data, the accuracy decreases significantly. Even tagging in-domai</context>
</contexts>
<marker>Calzolari, Monachini, 1995</marker>
<rawString>Calzolari, N. and Monachini M. (eds.). 1995. Common Specifications and Notation for Lexicon Encoding and Preliminary Proposal for the Tagsets. MULTEXT Report, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ceausu</author>
</authors>
<title>Maximum entropy tiered tagging.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th ESSLLI Student Session</booktitle>
<pages>173--179</pages>
<contexts>
<context position="4460" citStr="Ceausu, 2006" startWordPosition="650" endWordPosition="651"> The strategy of the Tiered Tagging methodology is to use a reduced tagset (called CTAG-set), where a CTAG is a generalization of a MSD, from which recoverable contextirrelevant features are removed. For instance, the attribute for gender (masculine `rn&apos; or feminine &apos;f&apos;) from MSDs `Ncfsrn&apos; and `Ncmsrn&apos; is deleted to obtain the CTAG `NSRN&apos;, because the gender information can be deterministically recovered based on the CTAG and the wordform itself. The recovering of the left out attributes (Figure 1) is based on the lexicons, linguistic rules and, in the case of unknown words, on ML techniques (Ceausu, 2006). When tagging with CTAGs, one can use any statistical POS tagging method such as HMMs, Maximum Entropy Classifiers, Bayesian Networks, CRFs, etc., followed by the CTAG to MSD recovery. Training data Training Converting from MSDs to CTAGS Training a POS tagger Manual+automatic rules for MSD recovery Tagging Labeling with CTAGS MSD Recovery Text Tagged text Figure 1 - Tiered Tagging methodology The language dependent process of manually inferring linguistic rules for MSD recovery requires good knowledge of the target language and also extensive amounts of time invested in testing and re-design.</context>
<context position="22092" citStr="Ceausu (2006)" startWordPosition="3611" endWordPosition="3612">he system, in our last experiment we used the 130 hidden unit network and we performed the training/testing procedure on the 1984 corpus, using 10-fold validation and 30 random initializations. The final accuracy was computed as an average between all the accuracy figures measured at the end of the training process (after 40 iterations). The first 1/10 of the 1984 corpus on which we tuned the hyperparameters was not included in the test data, but was used for training. The mean accuracy of the system (98.41%) was measured as an average of 270 values. 4 Comparison to other methods In his work, Ceausu (2006) presents a different approach to MSD tagging using the Maximum Entropy framework. He presents his results on the same corpus we used for training and testing (the 1984 corpus) and he compares his method (98.45% accuracy) with the Tiered Tagging methodology (97.50%) (Tufis and Dragomirescu, 2004). Our Neural Network approach obtained similar (slightly lower) results (98.41%), although it is arguable that our split/train procedure is not identical to the one used in his work (no details were given as how the 1/10 of the training corpus was selected). Also, our POS tagger detected cases where th</context>
</contexts>
<marker>Ceausu, 2006</marker>
<rawString>Ceausu, A. 2006. Maximum entropy tiered tagging. In Proceedings of the 11th ESSLLI Student Session (pp. 173-179).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>L Ramshaw</author>
<author>J Hajic</author>
<author>C Tillmann</author>
</authors>
<title>A statistical parser for Czech.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics</booktitle>
<pages>505--512</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2556" citStr="Collins et al., 1999" startWordPosition="358" endWordPosition="361">s (Berger et al., 1996; Ratnaparkhi, 1996), Bayesian Networks (Samuelsson, 1993), Neural Networks (Marques and Lopes, 1996) and Conditional Random Fields (CRF) (Lafferty et al., 2001). All these methods are primarily intended for English, which uses a relatively small tagset inventory, compared to highly inflectional languages. For the later mentioned languages, the lexicon tagsets (called morphosyntactic descriptions (Calzolari and Monachini, 1995) or MSDs) may be 10-20 times or even larger than the best known tagsets for English. For instance Czech MSD tagset requires more than 3000 labels (Collins et al., 1999), Slovene more than 2000 labels (Erjavec and Krek, 2008), and Romanian more than 1100 labels (Tufis, 1999). The standard tagging methods, using such large tagsets, face serious data sparseness problems due to lack of statistical evidence, manifested by the non-robustness of the language models. When tagging new texts that are not in the same domain as the training data, the accuracy decreases significantly. Even tagging in-domain texts may not be satisfactorily accurate. One of the most successful methods used for this task, called Tiered Tagging (Tufis, 1999), exploits a reduced set of tags d</context>
</contexts>
<marker>Collins, Ramshaw, Hajic, Tillmann, 1999</marker>
<rawString>Collins, M., Ramshaw, L., Hajic, J. and Tillmann, C. 1999. A statistical parser for Czech. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics (pp. 505-512). Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Erjavec</author>
<author>M Monachini</author>
</authors>
<date>1997</date>
<booktitle>Specifications and Notation for Lexicon Encoding. Deliverable D1.1 F. Multext-East Project COP106.</booktitle>
<contexts>
<context position="3334" citStr="Erjavec and Monachini, 1997" startWordPosition="473" endWordPosition="476">arge tagsets, face serious data sparseness problems due to lack of statistical evidence, manifested by the non-robustness of the language models. When tagging new texts that are not in the same domain as the training data, the accuracy decreases significantly. Even tagging in-domain texts may not be satisfactorily accurate. One of the most successful methods used for this task, called Tiered Tagging (Tufis, 1999), exploits a reduced set of tags derived by removing several recoverable features from the lexicon morpho-syntactic descriptions. According to the MULTEXT EAST lexical specifications (Erjavec and Monachini, 1997), the Romanian tagset consists of a number of 614 MSD tags (by exploiting the case and gender regular syncretism) for wordforms and 10 punctuation tags (Tufis et al., 1997), which is still significantly larger than the tagset of English. The MULTEX EAST version 4 (Erjavec, 2010) contains specifications for a total of 16 languages: Bulgarian, Croatian, Czech, Estonian, English, Hungarian, Romanian, 692 Serbian, Slovene, the Resian dialect of Slovene, Macedonian, Persian, Polish, Russian, Slovak, and Ukrainian The strategy of the Tiered Tagging methodology is to use a reduced tagset (called CTAG</context>
</contexts>
<marker>Erjavec, Monachini, 1997</marker>
<rawString>Erjavec, T. and Monachini, M. (Eds.). 1997. Specifications and Notation for Lexicon Encoding. Deliverable D1.1 F. Multext-East Project COP106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Erjavec</author>
</authors>
<title>MULTEXT-East version 3: Multilingual morphosyntactic specifications, lexicons and corpora.</title>
<date>2004</date>
<booktitle>In Fourth International Conference on Language Resources and Evaluation, LREC</booktitle>
<volume>4</volume>
<pages>1535--1538</pages>
<contexts>
<context position="9445" citStr="Erjavec, 2004" startWordPosition="1452" endWordPosition="1453">nt patterns via their learning algorithm. By properly encoding the input sequence, the network chooses which input features contribute in determining the output features for MSDs (e.g. patterns composed of part of speech, gender, case, type etc. contribute independently in selecting the optimal output sequence). This way, we removed the need for explicit MSD to CTAG conversion and MSD recovery from CTAGs. 2.1 The MSD binary encoding scheme A MSD language independently encodes a part of speech (POS) with the associated lexical attribute values as a string of positional ordered character codes (Erjavec, 2004). The first character is an upper case character denoting the part of speech (e.g. `N&apos; for nouns, `V&apos; for verbs, `A&apos; for adjectives, etc.) and the following characters (lower letters or `-`) specify the instantiations of the characteristic lexical attributes of the POS. For example, the MSD `Ncfsrn&apos;, specifies a noun (the first character is `N&apos;) the type of which is common (`c&apos;, the second character), feminine gender (`f&apos;), singular number (`s&apos;), in nominative/accusative case (`r&apos;) and indefinite form (`n&apos;). If a specific attribute is not relevant for a language, or for a given combination of </context>
</contexts>
<marker>Erjavec, 2004</marker>
<rawString>Erjavec, T. 2004. MULTEXT-East version 3: Multilingual morphosyntactic specifications, lexicons and corpora. In Fourth International Conference on Language Resources and Evaluation, LREC (Vol. 4, pp. 1535-1538).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Erjavec</author>
<author>S Krek</author>
</authors>
<title>The JOS morphosyntactically tagged corpus of Slovene.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation, LREC&apos;08.</booktitle>
<contexts>
<context position="2612" citStr="Erjavec and Krek, 2008" startWordPosition="367" endWordPosition="370">etworks (Samuelsson, 1993), Neural Networks (Marques and Lopes, 1996) and Conditional Random Fields (CRF) (Lafferty et al., 2001). All these methods are primarily intended for English, which uses a relatively small tagset inventory, compared to highly inflectional languages. For the later mentioned languages, the lexicon tagsets (called morphosyntactic descriptions (Calzolari and Monachini, 1995) or MSDs) may be 10-20 times or even larger than the best known tagsets for English. For instance Czech MSD tagset requires more than 3000 labels (Collins et al., 1999), Slovene more than 2000 labels (Erjavec and Krek, 2008), and Romanian more than 1100 labels (Tufis, 1999). The standard tagging methods, using such large tagsets, face serious data sparseness problems due to lack of statistical evidence, manifested by the non-robustness of the language models. When tagging new texts that are not in the same domain as the training data, the accuracy decreases significantly. Even tagging in-domain texts may not be satisfactorily accurate. One of the most successful methods used for this task, called Tiered Tagging (Tufis, 1999), exploits a reduced set of tags derived by removing several recoverable features from the</context>
</contexts>
<marker>Erjavec, Krek, 2008</marker>
<rawString>Erjavec, T. and Krek, S. 2008. The JOS morphosyntactically tagged corpus of Slovene. In Proceedings of the Sixth International Conference on Language Resources and Evaluation, LREC&apos;08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Erjavec</author>
</authors>
<title>MULTEXT-East Version 4: Multilingual Morphosyntactic Specifications,</title>
<date>2010</date>
<contexts>
<context position="3613" citStr="Erjavec, 2010" startWordPosition="521" endWordPosition="522"> not be satisfactorily accurate. One of the most successful methods used for this task, called Tiered Tagging (Tufis, 1999), exploits a reduced set of tags derived by removing several recoverable features from the lexicon morpho-syntactic descriptions. According to the MULTEXT EAST lexical specifications (Erjavec and Monachini, 1997), the Romanian tagset consists of a number of 614 MSD tags (by exploiting the case and gender regular syncretism) for wordforms and 10 punctuation tags (Tufis et al., 1997), which is still significantly larger than the tagset of English. The MULTEX EAST version 4 (Erjavec, 2010) contains specifications for a total of 16 languages: Bulgarian, Croatian, Czech, Estonian, English, Hungarian, Romanian, 692 Serbian, Slovene, the Resian dialect of Slovene, Macedonian, Persian, Polish, Russian, Slovak, and Ukrainian The strategy of the Tiered Tagging methodology is to use a reduced tagset (called CTAG-set), where a CTAG is a generalization of a MSD, from which recoverable contextirrelevant features are removed. For instance, the attribute for gender (masculine `rn&apos; or feminine &apos;f&apos;) from MSDs `Ncfsrn&apos; and `Ncmsrn&apos; is deleted to obtain the CTAG `NSRN&apos;, because the gender infor</context>
</contexts>
<marker>Erjavec, 2010</marker>
<rawString>Erjavec, T. 2010. MULTEXT-East Version 4: Multilingual Morphosyntactic Specifications,</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F C Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<contexts>
<context position="2118" citStr="Lafferty et al., 2001" startWordPosition="292" endWordPosition="295">synthesis, word sense disambiguation and machine translation. It is also known as lexical ambiguity resolution and it represents the process of assigning a uniquely interpretable label to every word inside a sentence. The labels are called POS tags and the entire inventory of POS tags is called a tagset. There are several approaches to part-of-speech tagging, such as Hidden Markov Models (HMM) (Brants, 2000), Maximum Entropy Classifiers (Berger et al., 1996; Ratnaparkhi, 1996), Bayesian Networks (Samuelsson, 1993), Neural Networks (Marques and Lopes, 1996) and Conditional Random Fields (CRF) (Lafferty et al., 2001). All these methods are primarily intended for English, which uses a relatively small tagset inventory, compared to highly inflectional languages. For the later mentioned languages, the lexicon tagsets (called morphosyntactic descriptions (Calzolari and Monachini, 1995) or MSDs) may be 10-20 times or even larger than the best known tagsets for English. For instance Czech MSD tagset requires more than 3000 labels (Collins et al., 1999), Slovene more than 2000 labels (Erjavec and Krek, 2008), and Romanian more than 1100 labels (Tufis, 1999). The standard tagging methods, using such large tagsets</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, J., McCallum, A. and Pereira, F. C. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N C Marques</author>
<author>G P Lopes</author>
</authors>
<title>A neural network approach to part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proceedings of the 2nd Meeting for Computational Processing of Spoken and Written Portuguese</booktitle>
<pages>21--22</pages>
<contexts>
<context position="2058" citStr="Marques and Lopes, 1996" startWordPosition="283" endWordPosition="286">various tasks such as `information extraction, text-to-speech synthesis, word sense disambiguation and machine translation. It is also known as lexical ambiguity resolution and it represents the process of assigning a uniquely interpretable label to every word inside a sentence. The labels are called POS tags and the entire inventory of POS tags is called a tagset. There are several approaches to part-of-speech tagging, such as Hidden Markov Models (HMM) (Brants, 2000), Maximum Entropy Classifiers (Berger et al., 1996; Ratnaparkhi, 1996), Bayesian Networks (Samuelsson, 1993), Neural Networks (Marques and Lopes, 1996) and Conditional Random Fields (CRF) (Lafferty et al., 2001). All these methods are primarily intended for English, which uses a relatively small tagset inventory, compared to highly inflectional languages. For the later mentioned languages, the lexicon tagsets (called morphosyntactic descriptions (Calzolari and Monachini, 1995) or MSDs) may be 10-20 times or even larger than the best known tagsets for English. For instance Czech MSD tagset requires more than 3000 labels (Collins et al., 1999), Slovene more than 2000 labels (Erjavec and Krek, 2008), and Romanian more than 1100 labels (Tufis, 1</context>
<context position="6734" citStr="Marques and Lopes (1996)" startWordPosition="993" endWordPosition="996">n for their simplicity and robustness in finding and recombining patterns inside data. Several neural network architectures have been proposed for the task of part-of-speech tagging. Schmid (1994) proposed a FFNN architecture for part-of-speech tagging obtaining a 96.22% accuracy. In his paper, he argues that neural networks are preferable to other methods, when the training set is small. He compares his results with a HMM tagger (94.24%) and a trigram tagger (96.02%), both trained and tested on the same corpora as his FFNN tagger (the Penn-Treebank corpus). A similar approach is presented by Marques and Lopes (1996). In their paper, the authors come to similar conclusions as those presented in Schmid (1994). We support these findings with an additional argument, namely the better fit for managing large tagsets. In both approaches mentioned before, the network is trained so that from the input vector, to output a real valued vector. Each value in the output vector is generated by a distinct neuron, and corresponds to a unique tag in the tagset (e.g. 100 tags means the network contains 100 neurons on the output layer). The input vector for predicting the tag of the current word encodes the tags for the pre</context>
</contexts>
<marker>Marques, Lopes, 1996</marker>
<rawString>Marques, N. C. and Lopes, G. P. 1996. A neural network approach to part-of-speech tagging. In Proceedings of the 2nd Meeting for Computational Processing of Spoken and Written Portuguese (pp. 21-22).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proceedings of the conference on empirical methods in natural language processing</booktitle>
<volume>1</volume>
<pages>133--142</pages>
<contexts>
<context position="1977" citStr="Ratnaparkhi, 1996" startWordPosition="275" endWordPosition="276">ntioned method. 1 Introduction Part-of-speech tagging is a key process for various tasks such as `information extraction, text-to-speech synthesis, word sense disambiguation and machine translation. It is also known as lexical ambiguity resolution and it represents the process of assigning a uniquely interpretable label to every word inside a sentence. The labels are called POS tags and the entire inventory of POS tags is called a tagset. There are several approaches to part-of-speech tagging, such as Hidden Markov Models (HMM) (Brants, 2000), Maximum Entropy Classifiers (Berger et al., 1996; Ratnaparkhi, 1996), Bayesian Networks (Samuelsson, 1993), Neural Networks (Marques and Lopes, 1996) and Conditional Random Fields (CRF) (Lafferty et al., 2001). All these methods are primarily intended for English, which uses a relatively small tagset inventory, compared to highly inflectional languages. For the later mentioned languages, the lexicon tagsets (called morphosyntactic descriptions (Calzolari and Monachini, 1995) or MSDs) may be 10-20 times or even larger than the best known tagsets for English. For instance Czech MSD tagset requires more than 3000 labels (Collins et al., 1999), Slovene more than 2</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Ratnaparkhi, A. 1996. A maximum entropy model for part-of-speech tagging. In Proceedings of the conference on empirical methods in natural language processing (Vol. 1, pp. 133-142).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Samuelsson</author>
</authors>
<title>Morphological tagging based entirely on Bayesian inference.</title>
<date>1993</date>
<booktitle>In 9th Nordic Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="2015" citStr="Samuelsson, 1993" startWordPosition="279" endWordPosition="280">speech tagging is a key process for various tasks such as `information extraction, text-to-speech synthesis, word sense disambiguation and machine translation. It is also known as lexical ambiguity resolution and it represents the process of assigning a uniquely interpretable label to every word inside a sentence. The labels are called POS tags and the entire inventory of POS tags is called a tagset. There are several approaches to part-of-speech tagging, such as Hidden Markov Models (HMM) (Brants, 2000), Maximum Entropy Classifiers (Berger et al., 1996; Ratnaparkhi, 1996), Bayesian Networks (Samuelsson, 1993), Neural Networks (Marques and Lopes, 1996) and Conditional Random Fields (CRF) (Lafferty et al., 2001). All these methods are primarily intended for English, which uses a relatively small tagset inventory, compared to highly inflectional languages. For the later mentioned languages, the lexicon tagsets (called morphosyntactic descriptions (Calzolari and Monachini, 1995) or MSDs) may be 10-20 times or even larger than the best known tagsets for English. For instance Czech MSD tagset requires more than 3000 labels (Collins et al., 1999), Slovene more than 2000 labels (Erjavec and Krek, 2008), a</context>
</contexts>
<marker>Samuelsson, 1993</marker>
<rawString>Samuelsson, C. 1993. Morphological tagging based entirely on Bayesian inference. In 9th Nordic Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Part-of-speech tagging with neural networks.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th conference on Computational</booktitle>
<volume>1</volume>
<pages>172--176</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="6306" citStr="Schmid (1994)" startWordPosition="926" endWordPosition="927"> the goal of squeezing the lexical tagset to a reasonable size, valuable information for contextual disambiguation is also lost. For example, the gender agreement rule, valid in many languages, cannot be exploited unless the gender attribute is present in the tags. Our proposal to deal with large tagsets without removing contextually useful information is based on Feed Forward Neural Networks (FFNN). FFNN are known for their simplicity and robustness in finding and recombining patterns inside data. Several neural network architectures have been proposed for the task of part-of-speech tagging. Schmid (1994) proposed a FFNN architecture for part-of-speech tagging obtaining a 96.22% accuracy. In his paper, he argues that neural networks are preferable to other methods, when the training set is small. He compares his results with a HMM tagger (94.24%) and a trigram tagger (96.02%), both trained and tested on the same corpora as his FFNN tagger (the Penn-Treebank corpus). A similar approach is presented by Marques and Lopes (1996). In their paper, the authors come to similar conclusions as those presented in Schmid (1994). We support these findings with an additional argument, namely the better fit </context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Schmid, H. 1994. Part-of-speech tagging with neural networks. In Proceedings of the 15th conference on Computational linguistics-Volume 1 (pp. 172-176). Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tufis</author>
<author>A M Barbu</author>
<author>V Patra�cu</author>
<author>G Rotariu</author>
<author>C Popescu</author>
</authors>
<title>Corpora and Corpus-Based Morpho-Lexical Processing.</title>
<date>1997</date>
<journal>ISBN</journal>
<booktitle>In Recent Advances in Romanian Language Technology,</booktitle>
<pages>35--56</pages>
<marker>Tufis, Barbu, Patra�cu, Rotariu, Popescu, 1997</marker>
<rawString>Tufis, D., Barbu A.M., Patra�cu V., Rotariu G. and Popescu C. 1997. Corpora and Corpus-Based Morpho-Lexical Processing. In Recent Advances in Romanian Language Technology, (pp. 35-56). Romanian Academy Publishing House, ISBN 973-27-0626-0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tufis</author>
</authors>
<title>Tiered tagging and combined language models classifiers.</title>
<date>1999</date>
<booktitle>In Text, Speech and Dialogue</booktitle>
<pages>843--843</pages>
<publisher>Springer Berlin/Heidelberg.</publisher>
<contexts>
<context position="766" citStr="Tufis, 1999" startWordPosition="98" endWordPosition="99">al Intelligence &amp;quot;Mihai Draganescu&amp;quot;, Romanian Academy Research Institute for Artificial Intelligence &amp;quot;Mihai Draganescu&amp;quot;, Romanian Academy Research Institute for Artificial Intelligence &amp;quot;Mihai Draganescu&amp;quot;, Romanian Academy tibi@racai.ro radu@racai.ro tufis@racai.ro Abstract Standard methods for part-of-speech tagging suffer from data sparseness when used on highly inflectional languages (which require large lexical tagset inventories). For this reason, a number of alternative methods have been proposed over the years. One of the most successful methods used for this task, called Tiered Tagging (Tufis, 1999), exploits a reduced set of tags derived by removing several recoverable features from the lexicon morpho-syntactic descriptions. A second phase is aimed at recovering the full set of morpho-syntactic features. In this paper we present an alternative method to Tiered Tagging, based on local optimizations with Neural Networks and we show how, by properly encoding the input sequence in a general Neural Network architecture, we achieve results similar to the Tiered Tagging methodology, significantly faster and without requiring extensive linguistic knowledge as implied by the previously mentioned</context>
<context position="2662" citStr="Tufis, 1999" startWordPosition="377" endWordPosition="378">s, 1996) and Conditional Random Fields (CRF) (Lafferty et al., 2001). All these methods are primarily intended for English, which uses a relatively small tagset inventory, compared to highly inflectional languages. For the later mentioned languages, the lexicon tagsets (called morphosyntactic descriptions (Calzolari and Monachini, 1995) or MSDs) may be 10-20 times or even larger than the best known tagsets for English. For instance Czech MSD tagset requires more than 3000 labels (Collins et al., 1999), Slovene more than 2000 labels (Erjavec and Krek, 2008), and Romanian more than 1100 labels (Tufis, 1999). The standard tagging methods, using such large tagsets, face serious data sparseness problems due to lack of statistical evidence, manifested by the non-robustness of the language models. When tagging new texts that are not in the same domain as the training data, the accuracy decreases significantly. Even tagging in-domain texts may not be satisfactorily accurate. One of the most successful methods used for this task, called Tiered Tagging (Tufis, 1999), exploits a reduced set of tags derived by removing several recoverable features from the lexicon morpho-syntactic descriptions. According </context>
</contexts>
<marker>Tufis, 1999</marker>
<rawString>Tufis, D. 1999. Tiered tagging and combined language models classifiers. In Text, Speech and Dialogue (pp. 843-843). Springer Berlin/Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tufis</author>
<author>L Dragomirescu</author>
</authors>
<title>Tiered tagging revisited.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th LREC Conference</booktitle>
<pages>39--42</pages>
<contexts>
<context position="22389" citStr="Tufis and Dragomirescu, 2004" startWordPosition="3655" endWordPosition="3658"> at the end of the training process (after 40 iterations). The first 1/10 of the 1984 corpus on which we tuned the hyperparameters was not included in the test data, but was used for training. The mean accuracy of the system (98.41%) was measured as an average of 270 values. 4 Comparison to other methods In his work, Ceausu (2006) presents a different approach to MSD tagging using the Maximum Entropy framework. He presents his results on the same corpus we used for training and testing (the 1984 corpus) and he compares his method (98.45% accuracy) with the Tiered Tagging methodology (97.50%) (Tufis and Dragomirescu, 2004). Our Neural Network approach obtained similar (slightly lower) results (98.41%), although it is arguable that our split/train procedure is not identical to the one used in his work (no details were given as how the 1/10 of the training corpus was selected). Also, our POS tagger detected cases where the annotation in the Gold Standard was erroneous. One such example is in &amp;quot;lame de ras&amp;quot; (English &amp;quot;razor blades&amp;quot;) where &amp;quot;lame&amp;quot; (English &amp;quot;blades&amp;quot;) is a noun, &amp;quot;de&amp;quot; (&amp;quot;for&amp;quot;) is a preposition and &amp;quot;ras&amp;quot; (&amp;quot;shaving&amp;quot;) is a supine verb (with a past participle form) which was incorrectly annotated as a noun. 6</context>
</contexts>
<marker>Tufis, Dragomirescu, 2004</marker>
<rawString>Tufis, D., and Dragomirescu, L. 2004. Tiered tagging revisited. In Proceedings of the 4th LREC Conference (pp. 39-42).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>