<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006223">
<title confidence="0.98888">
On-line Language Model Biasing for Statistical Machine Translation
</title>
<author confidence="0.869891">
Sankaranarayanan Ananthakrishnan, Rohit Prasad and Prem Natarajan
</author>
<affiliation confidence="0.762915">
Raytheon BBN Technologies
</affiliation>
<address confidence="0.636852">
Cambridge, MA 02138, U.S.A.
</address>
<email confidence="0.997769">
{sanantha,rprasad,pnataraj}@bbn.com
</email>
<sectionHeader confidence="0.995615" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998418952380952">
The language model (LM) is a critical com-
ponent in most statistical machine translation
(SMT) systems, serving to establish a proba-
bility distribution over the hypothesis space.
Most SMT systems use a static LM, inde-
pendent of the source language input. While
previous work has shown that adapting LMs
based on the input improves SMT perfor-
mance, none of the techniques has thus far
been shown to be feasible for on-line sys-
tems. In this paper, we develop a novel mea-
sure of cross-lingual similarity for biasing the
LM based on the test input. We also illustrate
an efficient on-line implementation that sup-
ports integration with on-line SMT systems by
transferring much of the computational load
off-line. Our approach yields significant re-
ductions in target perplexity compared to the
static LM, as well as consistent improvements
in SMT performance across language pairs
(English-Dari and English-Pashto).
</bodyText>
<sectionHeader confidence="0.999111" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.985611782608696">
While much of the focus in developing a statistical
machine translation (SMT) system revolves around
the translation model (TM), most systems do not
emphasize the role of the language model (LM). The
latter generally follows a n-gram structure and is es-
timated from a large, monolingual corpus of target
sentences. In most systems, the LM is independent
of the test input, i.e. fixed n-gram probabilities de-
termine the likelihood of all translation hypotheses,
regardless of the source input.
The views expressed are those of the author and do not reflect the official policy or position of
the Department of Defense or the U.S. Government.
Some previous work exists in LM adaptation for
SMT. Snover et al. (2008) used a cross-lingual infor-
mation retrieval (CLIR) system to select a subset of
target documents “comparable” to the source docu-
ment; bias LMs estimated from these subsets were
interpolated with a static background LM. Zhao
et al. (2004) converted initial SMT hypotheses to
queries and retrieved similar sentences from a large
monolingual collection. The latter were used to
build source-specific LMs that were then interpo-
lated with a background model. A similar approach
was proposed by Kim (2005). While feasible in off-
line evaluations where the test set is relatively static,
the above techniques are computationally expensive
and therefore not suitable for low-latency, interac-
tive applications of SMT. Examples include speech-
to-speech and web-based interactive translation sys-
tems, where test inputs are user-generated and pre-
clude off-line LM adaptation.
In this paper, we present a novel technique for
weighting a LM corpus at the sentence level based
on the source language input. The weighting scheme
relies on a measure of cross-lingual similarity evalu-
ated by projecting sparse vector representations of
the target sentences into the space of source sen-
tences using a transformation matrix computed from
the bilingual parallel data. The LM estimated from
this weighted corpus boosts the probability of rele-
vant target n-grams, while attenuating unrelated tar-
get segments. Our formulation, based on simple
ideas in linear algebra, alleviates run-time complex-
ity by pre-computing the majority of intermediate
products off-line.
Distribution Statement “A” (Approved for Public Release, Distribution Unlimited)
</bodyText>
<page confidence="0.980411">
445
</page>
<note confidence="0.63748">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 445–449,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.977247690140845">
2 Cross-Lingual Similarity We estimate the bilingual word co-occurrence
We propose a novel measure of cross-lingual simi- matrix Σ from an unsupervised, automatic word
larity that evaluates the likeness between an arbitrary alignment induced over the parallel training corpus
pair of source and target language sentences. The P. We use the GIZA++ toolkit (Al-Onaizan et al.,
proposed approach represents the source and target 1999) to estimate the parameters of IBM Model
sentences in sparse vector spaces defined by their 4 (Brown et al., 1993), and combine the forward
corresponding vocabularies, and relies on a bilingual and backward Viterbi alignments to obtain many-to-
projection matrix to transform vectors in the target many word alignments as described in Koehn et al.
language space to the source language space. (2003). The (m, n)th entry Em,n of this matrix is
Let S = {s1,... ,sM} and T = {t1,... ,tN}rep- the number of times source word sm aligns to target
resent the source and target language vocabularies. word tn in P.
Let u represent the candidate source sentence in a 3 Language Model Biasing
M-dimensional vector space, whose mth dimension In traditional LM training, n-gram counts are evalu-
um represents the count of vocabulary item sm in the ated assuming unit weight for each sentence. Our
sentence. Similarly, v represents the candidate tar- approach to LM biasing involves re-distributing
get sentence in a N-dimensional vector space. Thus, these weights to favor target sentences that are “sim-
u and v are sparse term-frequency vectors. Tra- ilar” to the candidate source sentence according to
ditionally, the cosine similarity measure is used to the measure of cross-lingual similarity developed in
evaluate the likeness of two term-frequency repre- Section 2. Thus, n-grams that appear in the trans-
sentations. However, u and v lie in different vector lation hypothesis for the candidate input will be as-
spaces. Thus, it is necessary to find a projection of signed high probability by the biased LM, and vice-
v in the source vocabulary vector space before sim- versa.
ilarity can be evaluated. Let u be the term-frequency representation of the
Assuming we are able to compute a M × N- candidate source sentence for which the LM must be
dimensional bilingual word co-occurrence matrix Σ biased. The set of vectors {v1, ... , vK} similarly
from the SMT parallel corpus, the matrix-vector represent the K target LM training sentences. We
product uˆ = Σv is a projection of the target sen- compute the similarity of the source sentence u to
tence in the source vector space. Those source terms each target sentence vj according to Equation 3.1:
of the M-dimensional vector uˆ will be emphasized Wj =S(u,vj)
that most frequently co-occur with the target terms 1
in v. In other words, uˆ can be interpreted as a “bag- = kukkΣvjkuT Σvj (3.1)
of-words” translation of v. The biased LM is estimated by weighting n-gram
The cross-lingual similarity between the candi- counts collected from the jth target sentence with
date source and target sentences then reduces to the the corresponding cross-lingual similarity Wj. How-
cosine similarity between the source term-frequency ever, this is computationally intensive because: (a)
vector u and the projected target term-frequency LM corpora usually consist of hundreds of thou-
vector ˆu, as shown in Equation 2.1: sands or millions of sentences; wj must be eval-
1 S(u, v) = kukkˆukuT uˆ uated at run-time for each of them, and (b) the
kukkΣvkuT Σv (2.1) entire LM must be re-estimated at run-time from
1 n-gram counts weighted by sentence-level cross-
In the above equation, we ensure that both u and lingual similarity.
uˆ are normalized to unit L2-norm. This prevents In order to alleviate the run-time complexity of
over- or under-estimation of cross-lingual similarity on-line LM biasing, we present an efficient method
due to sentence length mismatch. for obtaining biased counts of an arbitrary target
446
n-gram t. We define ct = [c1 t, ... , cK ]T to be
t
the indicator-count vector where cjt is the unbi-
ased count of t in target sentence j. Let w =
[w1,... ,wK]T be the vector representing cross-
lingual similarity between the candidate source sen-
tence and each of the K target sentences. Then, the
biased count of this n-gram, denoted by C*(t), is
given by Equation 3.2:
kuku (3.2)
The vector bt can be interpreted as the projection
of target n-gram t in the source space. Note that bt is
independent of the source input u, and can therefore
be pre-computed off-line. At run-time, the biased
count of any n-gram can be obtained via a simple
dot product. This adds very little on-line time com-
plexity because u is a sparse vector. Since bt is tech-
nically a dense vector, the space complexity of this
approach may seem very high. In practice, the mass
of bt is concentrated around a very small number of
source words that frequently co-occur with target n-
gram t; thus, it can be “sparsified” with little or no
loss of information by simply establishing a cutoff
threshold on its elements. Biased counts and proba-
bilities can be computed on demand for specific n-
grams without re-estimating the entire LM.
</bodyText>
<sectionHeader confidence="0.998151" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999219636363636">
We measure the utility of the proposed LM bias-
ing technique in two ways: (a) given a parallel test
corpus, by comparing source-conditional target per-
plexity with biased LMs to target perplexity with the
static LM, and (b) by comparing SMT performance
with static and biased LMs. We conduct experi-
ments on two resource-poor language pairs commis-
sioned under the DARPA Transtac speech-to-speech
translation initiative, viz. English-Dari (E2D) and
English-Pashto (E2P), on test sets with single as well
as multiple references.
</bodyText>
<table confidence="0.999896666666667">
Data set E2D E2P
TM Training 138k pairs 168k pairs
LM Training 179k sentences 302k sentences
Development 3,280 pairs 2,385 pairs
Test (1-ref) 2,819 pairs 1,113 pairs
Test (4-ref) - 564 samples
</table>
<tableCaption confidence="0.998118">
Table 1: Data configuration for perplexity/SMT experi-
ments. Multi-reference test set is not available for E2D.
LM training data in words: 2.4M (Dari), 3.4M (Pashto)
</tableCaption>
<subsectionHeader confidence="0.980185">
4.1 Data Configuration
</subsectionHeader>
<bodyText confidence="0.9997898">
Parallel data were made available under the Transtac
program for both language pairs evaluated in this pa-
per. We divided these into training, held-out devel-
opment, and test sets for building, tuning, and evalu-
ating the SMT system, respectively. These develop-
ment and test sets provide only one reference trans-
lation for each source sentence. For E2P, DARPA
has made available to all program participants an
additional evaluation set with multiple (four) refer-
ences for each test input. The Dari and Pashto mono-
lingual corpora for LM training are a superset of tar-
get sentences from the parallel training corpus, con-
sisting of additional untranslated sentences, as well
as data derived from other sources, such as the web.
Table 1 lists the corpora used in our experiments.
</bodyText>
<subsectionHeader confidence="0.99485">
4.2 Perplexity Analysis
</subsectionHeader>
<bodyText confidence="0.999952166666667">
For both Dari and Pashto, we estimated a static
trigram LM with unit sentence level weights that
served as a baseline. We tuned this LM by varying
the bigram and trigram frequency cutoff thresholds
to minimize perplexity on the held-out target sen-
tences. Finally, we evaluated test target perplexity
with the optimized baseline LM.
We then applied the proposed technique to es-
timate trigram LMs biased to source sentences in
the held-out and test sets. We evaluated source-
conditional target perplexity by computing the to-
tal log-probability of all target sentences in a par-
allel test corpus against the LM biased by the cor-
responding source sentences. Again, bigram and
trigram cutoff thresholds were tuned to minimize
source-conditional target perplexity on the held-out
set. The tuned biased LMs were used to compute
source-conditional target perplexity on the test set.
</bodyText>
<figure confidence="0.567193636363636">
C*(t) = cTt w
K
=
j=1
1 j
T
kukkΣvjk Σvj
1 T K 1 j
kuk u j=1 kΣvjkctΣvj
1 T b
= t
</figure>
<page confidence="0.993521">
447
</page>
<table confidence="0.999331">
Eval set Static Biased Reduction
E2D-1ref-dev 159.3 137.7 13.5%
E2D-1ref-tst 178.3 156.3 12.3%
E2P-1ref-dev 147.3 130.6 11.3%
E2P-1ref-tst 122.7 108.8 11.3%
</table>
<tableCaption confidence="0.996108">
Table 2: Reduction in perplexity using biased LMs.
</tableCaption>
<table confidence="0.9999462">
Test set BLEU 100-TER
E2D-1ref-tst Static Biased Static Biased
E2P-1ref-tst 14.4 14.8 29.6 30.5
E2P-4ref-tst 13.0 13.3 28.3 29.4
25.6 26.1 35.0 35.8
</table>
<tableCaption confidence="0.999946">
Table 3: SMT performance with static and biased LMs.
</tableCaption>
<bodyText confidence="0.999943625">
Witten-Bell discounting was used for smoothing
all LMs. Table 2 summarizes the reduction in target
perplexity using biased LMs; on the E2D and E2P
single-reference test sets, we obtained perplexity re-
ductions of 12.3% and 11.3%, respectively. This in-
dicates that the biased models are significantly better
predictors of the corresponding target sentences than
the static baseline LM.
</bodyText>
<subsectionHeader confidence="0.998204">
4.3 Translation Experiments
</subsectionHeader>
<bodyText confidence="0.999967848484848">
Having determined that target sentences of a parallel
test corpus better fit biased LMs estimated from the
corresponding source-weighted training corpus, we
proceeded to conduct SMT experiments on both lan-
guage pairs to demonstrate the utility of biased LMs
in improving translation performance.
We used an internally developed phrase-based
SMT system, similar to Moses (Koehn et al., 2007),
as a test-bed for our translation experiments. We
used GIZA++ to induce automatic word alignments
from the parallel training corpus. Phrase translation
rules (up to a maximum source span of 5 words)
were extracted from a combination of forward and
backward word alignments (Koehn et al., 2003).
The SMT decoder uses a log-linear model that com-
bines numerous features, including but not limited to
phrase translation probability, LM probability, and
distortion penalty, to estimate the posterior proba-
bility of target hypotheses. We used minimum error
rate training (MERT) (Och, 2003) to tune the feature
weights for maximum BLEU (Papineni et al., 2001)
on the development set. Finally, we evaluated SMT
performance on the test set in terms of BLEU and
TER (Snover et al., 2006).
The baseline SMT system used the static trigram
LM with cutoff frequencies optimized for minimum
perplexity on the development set. Biased LMs
(with n-gram cutoffs tuned as above) were estimated
for all source sentences in the development and test
sets, and were used to decode the corresponding in-
puts. Table 3 summarizes the consistent improve-
ment in BLEU/TER across multiple test sets and
language pairs.
</bodyText>
<sectionHeader confidence="0.99225" genericHeader="discussions">
5 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.999899875">
Existing methods for target LM biasing for SMT
rely on information retrieval to select a comparable
subset from the training corpus. A foreground LM
estimated from this subset is interpolated with the
static background LM. However, given the large size
of a typical LM corpus, these methods are unsuitable
for on-line, interactive SMT applications.
In this paper, we proposed a novel LM biasing
technique based on linear transformations of target
sentences in a sparse vector space. We adopted a
fine-grained approach, weighting individual target
sentences based on the proposed measure of cross-
lingual similarity, and by using the entire, weighted
corpus to estimate a biased LM. We then sketched an
implementation that improves the time and space ef-
ficiency of our method by pre-computing and “spar-
sifying” n-gram projections off-line during the train-
ing phase. Thus, our approach can be integrated
within on-line, low-latency SMT systems. Finally,
we showed that biased LMs yield significant reduc-
tions in target perplexity, and consistent improve-
ments in SMT performance.
While we used phrase-based SMT as a test-bed
for evaluating translation performance, it should be
noted that the proposed LM biasing approach is in-
dependent of SMT architecture. We plan to test its
effectiveness in hierarchical and syntax-based SMT
systems. We also plan to investigate the relative
usefulness of LM biasing as we move from low-
resource languages to those for which significantly
larger parallel corpora and LM training data are
available.
</bodyText>
<page confidence="0.99818">
448
</page>
<sectionHeader confidence="0.989361" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999718440677966">
Yaser Al-Onaizan, Jan Curin, Michael Jahr, Kevin
Knight, John Lafferty, Dan Melamed, Franz Josef Och,
David Purdy, Noah A. Smith, and David Yarowsky.
1999. Statistical machine translation: Final report.
Technical report, JHU Summer Workshop.
Peter E. Brown, Vincent J. Della Pietra, Stephen A.
Della Pietra, and Robert L. Mercer. 1993. The math-
ematics of statistical machine translation: parameter
estimation. Computational Linguistics, 19:263–311.
Woosung Kim. 2005. Language Model Adaptation for
Automatic Speech Recognition and Statistical Machine
Translation. Ph.D. thesis, The Johns Hopkins Univer-
sity, Baltimore, MD.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In NAACL
’03: Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology,
pages 48–54, Morristown, NJ, USA. Association for
Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the ACL on Inter-
active Poster and Demonstration Sessions, ACL ’07,
pages 177–180, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In ACL ’03: Pro-
ceedings of the 41st Annual Meeting on Association
for Computational Linguistics, pages 160–167, Mor-
ristown, NJ, USA. Association for Computational Lin-
guistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. BLEU: A method for automatic
evaluation of machine translation. In ACL ’02: Pro-
ceedings of the 40th Annual Meeting on Association
for Computational Linguistics, pages 311–318, Mor-
ristown, NJ, USA. Association for Computational Lin-
guistics.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings AMTA, pages 223–231, August.
Matthew Snover, Bonnie Dorr, and Richard Schwartz.
2008. Language and translation model adaptation us-
ing comparable corpora. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, EMNLP ’08, pages 857–866, Stroudsburg,
PA, USA. Association for Computational Linguistics.
Bing Zhao, Matthias Eck, and Stephan Vogel. 2004.
Language model adaptation for statistical machine
translation with structured query models. In Proceed-
ings of the 20th international conference on Compu-
tational Linguistics, COLING ’04, Stroudsburg, PA,
USA. Association for Computational Linguistics.
</reference>
<page confidence="0.999243">
449
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.246286">
<title confidence="0.999949">On-line Language Model Biasing for Statistical Machine Translation</title>
<author confidence="0.454748">Sankaranarayanan Ananthakrishnan</author>
<author confidence="0.454748">Rohit Prasad</author>
<author confidence="0.454748">Prem</author>
<affiliation confidence="0.409218">Raytheon BBN</affiliation>
<address confidence="0.993723">Cambridge, MA 02138,</address>
<abstract confidence="0.984043">The language model (LM) is a critical component in most statistical machine translation (SMT) systems, serving to establish a probability distribution over the hypothesis space. Most SMT systems use a static LM, independent of the source language input. While previous work has shown that adapting LMs based on the input improves SMT performance, none of the techniques has thus far been shown to be feasible for on-line systems. In this paper, we develop a novel measure of cross-lingual similarity for biasing the LM based on the test input. We also illustrate an efficient on-line implementation that supports integration with on-line SMT systems by transferring much of the computational load off-line. Our approach yields significant reductions in target perplexity compared to the static LM, as well as consistent improvements in SMT performance across language pairs (English-Dari and English-Pashto).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Jan Curin</author>
<author>Michael Jahr</author>
<author>Kevin Knight</author>
<author>John Lafferty</author>
<author>Dan Melamed</author>
<author>Franz Josef Och</author>
<author>David Purdy</author>
<author>Noah A Smith</author>
<author>David Yarowsky</author>
</authors>
<title>Statistical machine translation: Final report.</title>
<date>1999</date>
<tech>Technical report, JHU Summer Workshop.</tech>
<marker>Al-Onaizan, Curin, Jahr, Knight, Lafferty, Melamed, Och, Purdy, Smith, Yarowsky, 1999</marker>
<rawString>Yaser Al-Onaizan, Jan Curin, Michael Jahr, Kevin Knight, John Lafferty, Dan Melamed, Franz Josef Och, David Purdy, Noah A. Smith, and David Yarowsky. 1999. Statistical machine translation: Final report. Technical report, JHU Summer Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter E Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="4238" citStr="Brown et al., 1993" startWordPosition="634" endWordPosition="637">regon, June 19-24, 2011. c�2011 Association for Computational Linguistics 2 Cross-Lingual Similarity We estimate the bilingual word co-occurrence We propose a novel measure of cross-lingual simi- matrix Σ from an unsupervised, automatic word larity that evaluates the likeness between an arbitrary alignment induced over the parallel training corpus pair of source and target language sentences. The P. We use the GIZA++ toolkit (Al-Onaizan et al., proposed approach represents the source and target 1999) to estimate the parameters of IBM Model sentences in sparse vector spaces defined by their 4 (Brown et al., 1993), and combine the forward corresponding vocabularies, and relies on a bilingual and backward Viterbi alignments to obtain many-toprojection matrix to transform vectors in the target many word alignments as described in Koehn et al. language space to the source language space. (2003). The (m, n)th entry Em,n of this matrix is Let S = {s1,... ,sM} and T = {t1,... ,tN}rep- the number of times source word sm aligns to target resent the source and target language vocabularies. word tn in P. Let u represent the candidate source sentence in a 3 Language Model Biasing M-dimensional vector space, whose</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter E. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19:263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Woosung Kim</author>
</authors>
<title>Language Model Adaptation for Automatic Speech Recognition and Statistical Machine Translation.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>The Johns Hopkins University,</institution>
<location>Baltimore, MD.</location>
<contexts>
<context position="2368" citStr="Kim (2005)" startWordPosition="364" endWordPosition="365">ent of Defense or the U.S. Government. Some previous work exists in LM adaptation for SMT. Snover et al. (2008) used a cross-lingual information retrieval (CLIR) system to select a subset of target documents “comparable” to the source document; bias LMs estimated from these subsets were interpolated with a static background LM. Zhao et al. (2004) converted initial SMT hypotheses to queries and retrieved similar sentences from a large monolingual collection. The latter were used to build source-specific LMs that were then interpolated with a background model. A similar approach was proposed by Kim (2005). While feasible in offline evaluations where the test set is relatively static, the above techniques are computationally expensive and therefore not suitable for low-latency, interactive applications of SMT. Examples include speechto-speech and web-based interactive translation systems, where test inputs are user-generated and preclude off-line LM adaptation. In this paper, we present a novel technique for weighting a LM corpus at the sentence level based on the source language input. The weighting scheme relies on a measure of cross-lingual similarity evaluated by projecting sparse vector re</context>
</contexts>
<marker>Kim, 2005</marker>
<rawString>Woosung Kim. 2005. Language Model Adaptation for Automatic Speech Recognition and Statistical Machine Translation. Ph.D. thesis, The Johns Hopkins University, Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In NAACL ’03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>48--54</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="13052" citStr="Koehn et al., 2003" startWordPosition="2080" endWordPosition="2083">better fit biased LMs estimated from the corresponding source-weighted training corpus, we proceeded to conduct SMT experiments on both language pairs to demonstrate the utility of biased LMs in improving translation performance. We used an internally developed phrase-based SMT system, similar to Moses (Koehn et al., 2007), as a test-bed for our translation experiments. We used GIZA++ to induce automatic word alignments from the parallel training corpus. Phrase translation rules (up to a maximum source span of 5 words) were extracted from a combination of forward and backward word alignments (Koehn et al., 2003). The SMT decoder uses a log-linear model that combines numerous features, including but not limited to phrase translation probability, LM probability, and distortion penalty, to estimate the posterior probability of target hypotheses. We used minimum error rate training (MERT) (Och, 2003) to tune the feature weights for maximum BLEU (Papineni et al., 2001) on the development set. Finally, we evaluated SMT performance on the test set in terms of BLEU and TER (Snover et al., 2006). The baseline SMT system used the static trigram LM with cutoff frequencies optimized for minimum perplexity on the</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In NAACL ’03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 48–54, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondˇrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="12757" citStr="Koehn et al., 2007" startWordPosition="2033" endWordPosition="2036">ned perplexity reductions of 12.3% and 11.3%, respectively. This indicates that the biased models are significantly better predictors of the corresponding target sentences than the static baseline LM. 4.3 Translation Experiments Having determined that target sentences of a parallel test corpus better fit biased LMs estimated from the corresponding source-weighted training corpus, we proceeded to conduct SMT experiments on both language pairs to demonstrate the utility of biased LMs in improving translation performance. We used an internally developed phrase-based SMT system, similar to Moses (Koehn et al., 2007), as a test-bed for our translation experiments. We used GIZA++ to induce automatic word alignments from the parallel training corpus. Phrase translation rules (up to a maximum source span of 5 words) were extracted from a combination of forward and backward word alignments (Koehn et al., 2003). The SMT decoder uses a log-linear model that combines numerous features, including but not limited to phrase translation probability, LM probability, and distortion penalty, to estimate the posterior probability of target hypotheses. We used minimum error rate training (MERT) (Och, 2003) to tune the fe</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07, pages 177–180, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In ACL ’03: Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="13342" citStr="Och, 2003" startWordPosition="2125" endWordPosition="2126">oses (Koehn et al., 2007), as a test-bed for our translation experiments. We used GIZA++ to induce automatic word alignments from the parallel training corpus. Phrase translation rules (up to a maximum source span of 5 words) were extracted from a combination of forward and backward word alignments (Koehn et al., 2003). The SMT decoder uses a log-linear model that combines numerous features, including but not limited to phrase translation probability, LM probability, and distortion penalty, to estimate the posterior probability of target hypotheses. We used minimum error rate training (MERT) (Och, 2003) to tune the feature weights for maximum BLEU (Papineni et al., 2001) on the development set. Finally, we evaluated SMT performance on the test set in terms of BLEU and TER (Snover et al., 2006). The baseline SMT system used the static trigram LM with cutoff frequencies optimized for minimum perplexity on the development set. Biased LMs (with n-gram cutoffs tuned as above) were estimated for all source sentences in the development and test sets, and were used to decode the corresponding inputs. Table 3 summarizes the consistent improvement in BLEU/TER across multiple test sets and language pai</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In ACL ’03: Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 160–167, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2001</date>
<booktitle>In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="13411" citStr="Papineni et al., 2001" startWordPosition="2135" endWordPosition="2138">ion experiments. We used GIZA++ to induce automatic word alignments from the parallel training corpus. Phrase translation rules (up to a maximum source span of 5 words) were extracted from a combination of forward and backward word alignments (Koehn et al., 2003). The SMT decoder uses a log-linear model that combines numerous features, including but not limited to phrase translation probability, LM probability, and distortion penalty, to estimate the posterior probability of target hypotheses. We used minimum error rate training (MERT) (Och, 2003) to tune the feature weights for maximum BLEU (Papineni et al., 2001) on the development set. Finally, we evaluated SMT performance on the test set in terms of BLEU and TER (Snover et al., 2006). The baseline SMT system used the static trigram LM with cutoff frequencies optimized for minimum perplexity on the development set. Biased LMs (with n-gram cutoffs tuned as above) were estimated for all source sentences in the development and test sets, and were used to decode the corresponding inputs. Table 3 summarizes the consistent improvement in BLEU/TER across multiple test sets and language pairs. 5 Discussion and Future Work Existing methods for target LM biasi</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2001. BLEU: A method for automatic evaluation of machine translation. In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 311–318, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings AMTA,</booktitle>
<pages>223--231</pages>
<contexts>
<context position="13536" citStr="Snover et al., 2006" startWordPosition="2158" endWordPosition="2161"> (up to a maximum source span of 5 words) were extracted from a combination of forward and backward word alignments (Koehn et al., 2003). The SMT decoder uses a log-linear model that combines numerous features, including but not limited to phrase translation probability, LM probability, and distortion penalty, to estimate the posterior probability of target hypotheses. We used minimum error rate training (MERT) (Och, 2003) to tune the feature weights for maximum BLEU (Papineni et al., 2001) on the development set. Finally, we evaluated SMT performance on the test set in terms of BLEU and TER (Snover et al., 2006). The baseline SMT system used the static trigram LM with cutoff frequencies optimized for minimum perplexity on the development set. Biased LMs (with n-gram cutoffs tuned as above) were estimated for all source sentences in the development and test sets, and were used to decode the corresponding inputs. Table 3 summarizes the consistent improvement in BLEU/TER across multiple test sets and language pairs. 5 Discussion and Future Work Existing methods for target LM biasing for SMT rely on information retrieval to select a comparable subset from the training corpus. A foreground LM estimated fr</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings AMTA, pages 223–231, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
</authors>
<title>Language and translation model adaptation using comparable corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08,</booktitle>
<pages>857--866</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1869" citStr="Snover et al. (2008)" startWordPosition="284" endWordPosition="287"> around the translation model (TM), most systems do not emphasize the role of the language model (LM). The latter generally follows a n-gram structure and is estimated from a large, monolingual corpus of target sentences. In most systems, the LM is independent of the test input, i.e. fixed n-gram probabilities determine the likelihood of all translation hypotheses, regardless of the source input. The views expressed are those of the author and do not reflect the official policy or position of the Department of Defense or the U.S. Government. Some previous work exists in LM adaptation for SMT. Snover et al. (2008) used a cross-lingual information retrieval (CLIR) system to select a subset of target documents “comparable” to the source document; bias LMs estimated from these subsets were interpolated with a static background LM. Zhao et al. (2004) converted initial SMT hypotheses to queries and retrieved similar sentences from a large monolingual collection. The latter were used to build source-specific LMs that were then interpolated with a background model. A similar approach was proposed by Kim (2005). While feasible in offline evaluations where the test set is relatively static, the above techniques</context>
</contexts>
<marker>Snover, Dorr, Schwartz, 2008</marker>
<rawString>Matthew Snover, Bonnie Dorr, and Richard Schwartz. 2008. Language and translation model adaptation using comparable corpora. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 857–866, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
</authors>
<title>Language model adaptation for statistical machine translation with structured query models.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2106" citStr="Zhao et al. (2004)" startWordPosition="322" endWordPosition="325">the LM is independent of the test input, i.e. fixed n-gram probabilities determine the likelihood of all translation hypotheses, regardless of the source input. The views expressed are those of the author and do not reflect the official policy or position of the Department of Defense or the U.S. Government. Some previous work exists in LM adaptation for SMT. Snover et al. (2008) used a cross-lingual information retrieval (CLIR) system to select a subset of target documents “comparable” to the source document; bias LMs estimated from these subsets were interpolated with a static background LM. Zhao et al. (2004) converted initial SMT hypotheses to queries and retrieved similar sentences from a large monolingual collection. The latter were used to build source-specific LMs that were then interpolated with a background model. A similar approach was proposed by Kim (2005). While feasible in offline evaluations where the test set is relatively static, the above techniques are computationally expensive and therefore not suitable for low-latency, interactive applications of SMT. Examples include speechto-speech and web-based interactive translation systems, where test inputs are user-generated and preclude</context>
</contexts>
<marker>Zhao, Eck, Vogel, 2004</marker>
<rawString>Bing Zhao, Matthias Eck, and Stephan Vogel. 2004. Language model adaptation for statistical machine translation with structured query models. In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>