<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.276857">
<title confidence="0.959867">
Classifying Biological Full-Text Articles for Multi-Database Curation
</title>
<author confidence="0.966268">
Wen-Juan Hou, Chih Lee and Hsin-Hsi Chen
</author>
<affiliation confidence="0.9945805">
Department of Computer Science and Information Engineering,
National Taiwan University, Taipei, Taiwan
</affiliation>
<email confidence="0.993994">
{wjhou, clee}@nlg.csie.ntu.edu.tw; hhchen@csie.ntu.edu.tw
</email>
<sectionHeader confidence="0.993888" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999777">
In this paper, we propose an approach
for identifying curatable articles from a
large document set. This system
considers three parts of an article (title
and abstract, MeSH terms, and captions)
as its three individual representations
and utilizes two domain-specific
resources (UMLS and a tumor name list)
to reveal the deep knowledge contained
in the article. An SVM classifier is
trained and cross-validation is employed
to find the best combination of
representations. The experimental
results show overall high performance.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99991558490566">
Organism databases play a crucial role in
genomic and proteomic research. It stores the
up-to-date profile of each gene of the species
interested. For example, the Mouse Genome
Database (MGD) provides essential integration
of experimental knowledge for the mouse
system with information annotated from both
literature and online sources (Bult et al., 2004).
To provide biomedical scientists with easy
access to complete and accurate information,
curators have to constantly update databases
with new information. With the rapidly
growing rate of publication, it is impossible for
curators to read every published article. Since
fully automated curation systems have not met
the strict requirement of high accuracy and recall,
database curators still have to read some (if not
all) of the articles sent to them. Therefore, it
will be very helpful if a classification system can
correctly identify the curatable or relevant
articles in a large number of biological articles.
Recently, several attempts have been made to
classify documents from biomedical domain
(Hirschman et al., 2002). Couto et al. (2004)
used the information extracted from related web
resources to classify biomedical literature. Hou
et al. (2005) used the reference corpus to help
classifying gene annotation. The Genomics
Track (http://ir.ohsu.edu/genomics) of TREC
2004 and 2005 organized categorization tasks.
The former focused on simplified GO terms
while the latter included the triage for &amp;quot;tumor
biology&amp;quot;, &amp;quot;embryologic gene expression&amp;quot;,
&amp;quot;alleles of mutant phenotypes&amp;quot; and &amp;quot;GO&amp;quot; articles.
The increase of the numbers of participants at
Genomics Track shows that biological
classification problems attracted much attention.
This paper employs the domain-specific
knowledge and knowledge learned from full-text
articles to classify biological text. Given a
collection of articles, various methods are
explored to extract features to represent a
document. We use the experimental data
provided by the TREC 2005 Genomics Track to
evaluate different methods.
The rest of this paper is organized as follows.
Section 2 sketches the overview of the system
architecture. Section 3 specifies the test bed
used to evaluate the proposed methods. The
details of the proposed system are explained in
Section 4. The experimental results are shown
and discussed in Section 5. Finally, we make
conclusions and present some further work.
</bodyText>
<sectionHeader confidence="0.954598" genericHeader="method">
2 System Overview
</sectionHeader>
<bodyText confidence="0.975591842105263">
Figure 1 shows the overall architecture of the
proposed system. At first, we preprocess each
training article, and divide it into three parts,
including (1) title and abstract, (2) MeSH terms
assigned to this article, and (3) captions of
figures and tables. They are denoted as
&amp;quot;Abstract&amp;quot;, &amp;quot;MeSH&amp;quot;, and &amp;quot;Caption&amp;quot; in this paper,
respectively. Each part is considered as a
representation of an article. With the help of
domain-specific knowledge, we obtain more
detail representations of an article. In the
model selection phase, we perform feature
ranking on each representation of an article and
employ cross-validation to determine the
number of features to be kept. Moreover, we
use cross-validation to obtain the best
combination of all the representations. Finally,
a support vector machine (SVM) (Vapnik, 1995;
Hsu et al., 2003) classifier is obtained.
</bodyText>
<page confidence="0.998772">
159
</page>
<figureCaption confidence="0.99965">
Figure 1. System Architecture
</figureCaption>
<figure confidence="0.999533083333333">
A New
Full-Text
Article
Preprocessing
SVM
Classifier
Yes/No
Full-Text
Training
Articles
Preprocessing
Model
Selection
Abstract
Caption
MeSH
Multiple
Parts
Domain-Specific
Knowledge
AbsSEM/TM
CapSEM/TM
MeSHSEM
PartsSEM/TM
</figure>
<sectionHeader confidence="0.939986" genericHeader="method">
3 Experimental Data
</sectionHeader>
<bodyText confidence="0.99997675">
We train classifiers for classifying biomedical
articles on the Categorization Task of the TREC
2005 Genomics Track. The task uses data from
the Mouse Genome Informatics (MGI) system
(http://www.informatics.jax.org/) for four
categorization tasks, including tumor biology,
embryologic gene expression, alleles of mutant
phenotypes and GO annotation. Given a
document and a category, we have to identify
whether it is relevant to the given category.
The document set consists of some full-text
data obtained from three journals, i.e., Journal of
Biological Chemistry, Journal of Cell Biology
and Proceedings of the National Academy of
Science in 2002 and 2003. There are 5,837
training documents and 6,043 testing documents.
</bodyText>
<sectionHeader confidence="0.999691" genericHeader="method">
4 Methods
</sectionHeader>
<subsectionHeader confidence="0.999718">
4.1 Document Preprocessing
</subsectionHeader>
<bodyText confidence="0.999758166666667">
In the preprocessing phase, we perform acronym
expansion on the articles, remove the remaining
tags from the articles and extract three parts of
interest from each article. Abbreviations are
often used to replace long terms in writing
articles, but it is possible that several long terms
share the same short form, especially for
gene/protein names. To avoid ambiguity and
enhance clarity, the acronym expansion
operation replaces every tagged abbreviation
with its long form followed by itself in a pair of
parentheses.
</bodyText>
<subsectionHeader confidence="0.988784">
4.2 Employing Domain-Specific Knowledge
</subsectionHeader>
<bodyText confidence="0.986377411764706">
With the help of domain-specific knowledge, we
can extract the deeper knowledge in an article.
For example, with a gene name dictionary, we
can identify the gene names contained in an
article. Moreover, by further consulting
organism databases, we can get the properties of
the genes. Two domain-specific resources are
exploited in this study. One is the Unified
Medical Language System (UMLS) (Humphreys
et al., 1998) and the other is a list of tumor
names obtained from Mouse Tumor Biology
Database (MTB)1.
UMLS contains a huge dictionary of
biomedical terms – the UMLS Metathesaurus
and defines a hierarchy of semantic types – the
UMLS Semantic Network. Each concept in the
Metathesaurus contains a set of strings, which
are variants of each other and belong to one or
more semantic types in the Semantic Network.
Therefore, given a string, we can obtain a set of
semantic types to which it belongs. Then we
obtain another representation of the article by
gathering the semantic types found in the part of
the article. Consequently, we get another three
much deeper representations of an article after
this step. They are denoted as &amp;quot;AbstractSEM&amp;quot;,
&amp;quot;MeSHSEM&amp;quot; and &amp;quot;CaptionSEM&amp;quot;.
We use the list of tumor names on the Tumor
task. We first tokenize all the tumor names and
stem each unique token. With the resulting list
of unique stemmed tokens, we use it as a filter to
remove the tokens not in the list from the
&amp;quot;Abstract&amp;quot; and &amp;quot;Caption&amp;quot;, which produce
&amp;quot;AbstractTM&amp;quot; and &amp;quot;CaptionTM&amp;quot;.
</bodyText>
<subsectionHeader confidence="0.999209">
4.3 Model Selection
</subsectionHeader>
<bodyText confidence="0.999475">
As mentioned above, we generate several
representations for an article. In this section,
we explain how feature selection is done and
how the best combination of the representations
</bodyText>
<footnote confidence="0.955673">
1 http://tumor.informatics.jax.org/mtbwi/tumorSearch.do
</footnote>
<page confidence="0.993353">
160
</page>
<bodyText confidence="0.965049571428572">
of an article is obtained.
For each representation, we first rank all the
tokens in the training documents via the
chi-square test of independence. Postulating
the ranking perfectly reflects the effectiveness of
the tokens in classification, we then decide the
number of tokens to be used in SVM
classification by 4-fold cross-validation. In
cross-validation, we use the TF*IDF weighting
scheme. Each feature vector is then
normalized to a unit vector. We set C+ to ur* C-
because of the relatively small number of
positive examples, where C+ and C- are the
penalty constants on positive and negative
examples in SVMs. After that, we obtain the
optimal number of tokens and the corresponding
SVM parameters C- and gamma, a parameter in
the radial basis kernel. In the rest of this paper,
&amp;quot;Abstract30&amp;quot; denotes the &amp;quot;Abstract&amp;quot;
representation with top-30 tokens,
&amp;quot;CaptionSEM10&amp;quot; denotes &amp;quot;CaptionSEM&amp;quot; with
top-10 tokens, and so forth.
After feature selection is done for each
representation, we try to find the best
combination by the following algorithm.
Given the candidate representations with
selected features, we start with an initial set
containing some or zero representation. For
each iteration, we add one representation to the
set by picking the one that enhances the
cross-validation performance the most. The
iteration stops when we have exhausted all the
representations or adding more representation to
the set doesn’t improve the cross-validation
performance.
For classifying the documents with better
features, we run the algorithm twice. We first
start with an empty set and obtain the best
combination of the basic three representations,
e.g., &amp;quot;Abstract10&amp;quot;, &amp;quot;MeSH30&amp;quot; and &amp;quot;Caption10&amp;quot;.
Then, starting with this combination, we attempt
to incorporate the three semantic representations,
e.g., &amp;quot;Abstract30SEM&amp;quot;, &amp;quot;MeSH30SEM&amp;quot; and
&amp;quot;Caption10SEM&amp;quot;, and obtain the final
combination. Instead of using this algorithm to
incorporate the &amp;quot;AbstractTM&amp;quot; and &amp;quot;CaptionTM&amp;quot;
representations, we use them to replace their
unfiltered counterparts &amp;quot;Abstract&amp;quot; and &amp;quot;Caption&amp;quot;
when the cross-validation performance is better.
</bodyText>
<sectionHeader confidence="0.998976" genericHeader="evaluation">
5 Results and Discussions
</sectionHeader>
<bodyText confidence="0.999760740740741">
Table 1 lists the cross-validation results of each
representation for each category (in Normalized
Utility (NU)2 measure). For category Allele,
&amp;quot;Caption&amp;quot; and &amp;quot;AbstractSEM&amp;quot; perform the best
among the basic and semantic representations,
respectively. For category Expression,
&amp;quot;Caption&amp;quot; plays an important role in identifying
relevant documents, which agrees with the
finding by the winner of KDD CUP 2002 task 1
(Regev et al., 2002). Similarly, MeSH terms
are crucial to the GO category, which are used
by top-performing teams (Dayanik et al., 2004;
Fujita, 2004) in TREC Genomics 2004. For
category Tumor, MeSH terms are important, but
after semantic type extraction, &amp;quot;AbstractSEM&amp;quot;
exhibits relatively high cross-validation
performance. Since only 10 features are
selected for the &amp;quot;AbstractSEM&amp;quot;, using this
representation alone may be susceptible to
over-fitting. Finally, by comparing the
performance of the &amp;quot;AbstractTM&amp;quot; and
&amp;quot;Abstract&amp;quot;, we find the list of tumor names
helpful for filtering abstracts.
We list the results for the test data in Table 2.
Column &amp;quot;Experiment&amp;quot; identifies our proposed
methods. We show six experiments in Table 2:
one for Allele (AL), one for Expression (EX),
one for GO (GO) and three for Tumor (TU, TN
and TS). Column &amp;quot;cv NU&amp;quot; shows the
cross-validation NU measure, &amp;quot;NU&amp;quot; shows the
performance on the test data and column
&amp;quot;Combination&amp;quot; lists the combination of the
representations used for each experiment. In
this table, &amp;quot;M30&amp;quot; is the abbreviation for
&amp;quot;MeSH30&amp;quot;, &amp;quot;CS10&amp;quot; is for &amp;quot;CaptionSEM10&amp;quot;, and
so on. The combinations for the first 4
experiments, i.e., AL, EX, GO and TU, are
obtained by the algorithm described in Section
4.3, while the combination for TN is obtained by
substituting &amp;quot;AbstractTM30&amp;quot; for &amp;quot;Abstract30&amp;quot; in
the combination for TU. The experiment TS
only uses the &amp;quot;AbstractSEM10&amp;quot; because its
cross-validation performance beats all other
combinations for the Tumor category.
The combinations of the first 5 experiments
illustrate that adding other inferior
representations to the best one enhances the
performance, which implies that the inferior
ones may contain important exclusive
information. The cross-validation performance
fairly predicts the performance on the test data,
except for the last experiment TS, which relies
on only 10 features and is therefore susceptible
to over-fitting.
</bodyText>
<footnote confidence="0.9326365">
2 Please refer to the TREC 2005 Genomics Track Protocol
(http://ir.ohsu.edu/genomics/2005protocol.html).
</footnote>
<page confidence="0.983148">
161
</page>
<table confidence="0.9999153">
Allele Expression GO Tumor
# Tokens / NU # Tokens / NU # Tokens / NU # Tokens / NU
Abstract 10 / 0.7707 10 / 0.5586 10 / 0.4411 10 / 0.8055
MeSH 10 / 0.7965 10 / 0.6044 10 / 0.4968 30 / 0.8106
Caption 10 / 0.8179 10 / 0.7192 10 / 0.4091 10 / 0.7644
AbstractSEM 10 / 0.7209 10 / 0.4811 10 / 0.3493 10 / 0.8814
MeSHSEM 10 / 0.6942 10 / 0.4563 10 / 0.4403 10 / 0.7047
CaptionSEM 30 / 0.6789 10 / 0.5433 10 / 0.2551 30 / 0.7160
AbstractTM 30 / 0.8325
CaptionTM 10 / 0.7498
</table>
<tableCaption confidence="0.985425">
Table 1. Partial Cross-validation Results.
</tableCaption>
<table confidence="0.999692142857143">
Experiment cv NU NU Recall Precision F-score Combination
AL (for Allele) 0.8717 0.8423 0.9488 0.3439 0.5048 M30+C10+A10+CS10+AS10+MS10
EX (for Expression) 0.7691 0.7515 0.8190 0.1593 0.2667 M10+C10+CS10+MS10
GO (for GO) 0.5402 0.5332 0.8803 0.1873 0.3089 M10+C10+MS10
TU (for Tumor) 0.8742 0.8299 0.9000 0.0526 0.0994 M30+C30+A30+AS10+CS30
TN (for Tumor) 0.8764 0.8747 0.9500 0.0518 0.0982 M30+C30+AT30+AS10+CS30
TS (for Tumor) 0.8814 0.5699 0.6500 0.0339 0.0645 AS10
</table>
<tableCaption confidence="0.999328">
Table 2. Evaluation Results.
</tableCaption>
<table confidence="0.9997888">
Subtask NU (Best/Median) Recall (Best/Median) Precision (Best/Median) F-score (Best/Median)
Allele 0.8710/0.7773 0.9337/0.8720 0.4669/0.3153 0.6225/0.5010
Expression 0.8711/0.6413 0.9333/0.7286 0.1899/0.1164 0.3156/0.2005
GO Annotation 0.5870/0.4575 0.8861/0.5656 0.2122/0.3223 0.3424/0.4107
Tumor 0.9433/0.7610 1.0000/0.9500 0.0709/0.0213 0.1325/0.0417
</table>
<tableCaption confidence="0.99842">
Table 3. Best and Median Results for Each Subtask on TREC 2005 (Hersh et al., 2005).
</tableCaption>
<bodyText confidence="0.996018166666667">
To compare with our performance, we list the
best and median results for each subtask on the
genomics classification task of TREC 2005 in
Table 3. Comparing to Tables 2 and 3, it shows
our experimental results have overall high
performance.
</bodyText>
<sectionHeader confidence="0.998022" genericHeader="conclusions">
6 Conclusions and Further Work
</sectionHeader>
<bodyText confidence="0.999820529411765">
In this paper, we demonstrate how our system is
constructed. Three parts of an article are
extracted to represent its content. We
incorporate two domain-specific resources, i.e.,
UMLS and a list of tumor names. For each
categorization work, we propose an algorithm to
get the best combination of the representations
and train an SVM classifier out of this
combination. Evaluation results show overall
high performance in this study.
Except for MeSH terms, we can try other
sections in the article, e.g., Results, Discussions
and Conclusions as targets of feature extraction
besides the abstract and captions in the future.
Finally, we will try to make use of other
available domain-specific resources in hope of
enhancing the performance of this system.
</bodyText>
<sectionHeader confidence="0.999899" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<reference confidence="0.8884845">
Research of this paper was partially supported by
National Science Council, Taiwan, under the
contracts NSC94-2213-E-002-033 and
NSC94-2752-E-001-001-PAE.
</reference>
<sectionHeader confidence="0.964319" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99972485">
Bult, C.J., Blake, J.A., Richardson, J.E., Kadin, J.A., Eppig,
J.T. and the Mouse Genome Database Group. The Mouse
Genome Database (MGD): Integrating Biology with the
Genome. Nucleic Acids Research, 32, D476–D481, 2004.
Couto, F.M., Martins, B. and Silva, M.J. Classifying Biological
Articles Using Web Resources. Proceedings of the 2004
ACM Symposium on Applied Computing, 111-115, 2004.
Dayanik, A., Fradkin, D., Genkin, A., Kantor, P., Lewis, D.D.,
Madigan, D. and Menkov, V. DIMACS at the TREC 2004
Genomics Track. Proceedings of the Thirteenth Text
Retrieval Conference, 2004.
Fujita, S., Revisiting Again Document Length Hypotheses
TREC-2004 Genomics Track Experiments at Patolis.
Proceedings of the Thirteenth Text Retrieval Conference,
2004.
Hersh, W., Cohen, A., Yang, J., Bhuptiraju, R.T., Toberts, P.
and Hearst, M. TREC 2005 Genomics Track Overview.
Proceedings of the Fourteenth Text Retrieval Conference,
2005.
Hirschman, L., Park, J., Tsujii, J., Wong, L. and Wu, C.H.
Accomplishments and Challenges in Literature Data
Mining for Biology. Bioinformatics, 18(12): 1553-1561,
2002.
Hou, W.J., Lee, C., Lin, K.H.Y. and Chen, H.H. A Relevance
Detection Approach to Gene Annotation. Proceedings of the
First International Symposium on Semantic Mining in
Biomedicine, http://ceur-ws.org, 148: 15-23, 2005.
Hsu, C.W., Chang, C.C. and Lin, C.J. A Practical Guide to
Support Vector Classification. http://www.csie.ntu.edu.tw
/~cjlin/libsvm/index.html, 2003.
Humphreys, B.L., Lindberg, D.A., Schoolman, H.M. and
Barnett, G.O. The Unified Medical Language System: an
Informatics Research Collaboration. Journal of American
Medical Information Association, 5(1):1-11, 1998.
Regev, Y., Finkelstein-Landau, M. and Feldman, R. Rule-based
Extraction of Experimental Evidence in the Biomedical
Domain - the KDD Cup (Task 1). SIGKDD Explorations,
4(2):90-92, 2002.
Vapnik, V. The Nature of Statistical Learning Theory,
Springer-Verlag, 1995.
</reference>
<page confidence="0.997786">
162
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.663067">
<title confidence="0.999949">Classifying Biological Full-Text Articles for Multi-Database Curation</title>
<author confidence="0.999837">Wen-Juan Hou</author>
<author confidence="0.999837">Chih Lee</author>
<author confidence="0.999837">Hsin-Hsi Chen</author>
<affiliation confidence="0.99996">Department of Computer Science and Information Engineering,</affiliation>
<address confidence="0.678095">National Taiwan University, Taipei, Taiwan</address>
<email confidence="0.972848">wjhou@nlg.csie.ntu.edu.tw;hhchen@csie.ntu.edu.tw</email>
<email confidence="0.972848">clee@nlg.csie.ntu.edu.tw;hhchen@csie.ntu.edu.tw</email>
<abstract confidence="0.9997554">In this paper, we propose an approach for identifying curatable articles from a large document set. This system considers three parts of an article (title and abstract, MeSH terms, and captions) as its three individual representations and utilizes two domain-specific resources (UMLS and a tumor name list) to reveal the deep knowledge contained in the article. An SVM classifier is trained and cross-validation is employed to find the best combination of representations. The experimental results show overall high performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Research of this paper was partially supported by</title>
<booktitle>National Science Council, Taiwan, under the contracts</booktitle>
<pages>94--2213</pages>
<marker></marker>
<rawString>Research of this paper was partially supported by National Science Council, Taiwan, under the contracts NSC94-2213-E-002-033 and NSC94-2752-E-001-001-PAE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Bult</author>
<author>J A Blake</author>
<author>J E Richardson</author>
<author>J A Kadin</author>
<author>J T Eppig</author>
</authors>
<title>and the Mouse Genome Database Group. The Mouse Genome Database (MGD): Integrating Biology with the Genome.</title>
<date>2004</date>
<journal>Nucleic Acids Research,</journal>
<volume>32</volume>
<contexts>
<context position="1181" citStr="Bult et al., 2004" startWordPosition="160" endWordPosition="163">S and a tumor name list) to reveal the deep knowledge contained in the article. An SVM classifier is trained and cross-validation is employed to find the best combination of representations. The experimental results show overall high performance. 1 Introduction Organism databases play a crucial role in genomic and proteomic research. It stores the up-to-date profile of each gene of the species interested. For example, the Mouse Genome Database (MGD) provides essential integration of experimental knowledge for the mouse system with information annotated from both literature and online sources (Bult et al., 2004). To provide biomedical scientists with easy access to complete and accurate information, curators have to constantly update databases with new information. With the rapidly growing rate of publication, it is impossible for curators to read every published article. Since fully automated curation systems have not met the strict requirement of high accuracy and recall, database curators still have to read some (if not all) of the articles sent to them. Therefore, it will be very helpful if a classification system can correctly identify the curatable or relevant articles in a large number of biol</context>
</contexts>
<marker>Bult, Blake, Richardson, Kadin, Eppig, 2004</marker>
<rawString>Bult, C.J., Blake, J.A., Richardson, J.E., Kadin, J.A., Eppig, J.T. and the Mouse Genome Database Group. The Mouse Genome Database (MGD): Integrating Biology with the Genome. Nucleic Acids Research, 32, D476–D481, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F M Couto</author>
<author>B Martins</author>
<author>M J Silva</author>
</authors>
<title>Classifying Biological Articles Using Web Resources.</title>
<date>2004</date>
<booktitle>Proceedings of the 2004 ACM Symposium on Applied Computing,</booktitle>
<pages>111--115</pages>
<contexts>
<context position="1930" citStr="Couto et al. (2004)" startWordPosition="275" endWordPosition="278">ases with new information. With the rapidly growing rate of publication, it is impossible for curators to read every published article. Since fully automated curation systems have not met the strict requirement of high accuracy and recall, database curators still have to read some (if not all) of the articles sent to them. Therefore, it will be very helpful if a classification system can correctly identify the curatable or relevant articles in a large number of biological articles. Recently, several attempts have been made to classify documents from biomedical domain (Hirschman et al., 2002). Couto et al. (2004) used the information extracted from related web resources to classify biomedical literature. Hou et al. (2005) used the reference corpus to help classifying gene annotation. The Genomics Track (http://ir.ohsu.edu/genomics) of TREC 2004 and 2005 organized categorization tasks. The former focused on simplified GO terms while the latter included the triage for &amp;quot;tumor biology&amp;quot;, &amp;quot;embryologic gene expression&amp;quot;, &amp;quot;alleles of mutant phenotypes&amp;quot; and &amp;quot;GO&amp;quot; articles. The increase of the numbers of participants at Genomics Track shows that biological classification problems attracted much attention. This pa</context>
</contexts>
<marker>Couto, Martins, Silva, 2004</marker>
<rawString>Couto, F.M., Martins, B. and Silva, M.J. Classifying Biological Articles Using Web Resources. Proceedings of the 2004 ACM Symposium on Applied Computing, 111-115, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dayanik</author>
<author>D Fradkin</author>
<author>A Genkin</author>
<author>P Kantor</author>
<author>D D Lewis</author>
<author>D Madigan</author>
<author>V Menkov</author>
</authors>
<date>2004</date>
<booktitle>DIMACS at the TREC 2004 Genomics Track. Proceedings of the Thirteenth Text Retrieval Conference,</booktitle>
<contexts>
<context position="10117" citStr="Dayanik et al., 2004" startWordPosition="1509" endWordPosition="1512">hen the cross-validation performance is better. 5 Results and Discussions Table 1 lists the cross-validation results of each representation for each category (in Normalized Utility (NU)2 measure). For category Allele, &amp;quot;Caption&amp;quot; and &amp;quot;AbstractSEM&amp;quot; perform the best among the basic and semantic representations, respectively. For category Expression, &amp;quot;Caption&amp;quot; plays an important role in identifying relevant documents, which agrees with the finding by the winner of KDD CUP 2002 task 1 (Regev et al., 2002). Similarly, MeSH terms are crucial to the GO category, which are used by top-performing teams (Dayanik et al., 2004; Fujita, 2004) in TREC Genomics 2004. For category Tumor, MeSH terms are important, but after semantic type extraction, &amp;quot;AbstractSEM&amp;quot; exhibits relatively high cross-validation performance. Since only 10 features are selected for the &amp;quot;AbstractSEM&amp;quot;, using this representation alone may be susceptible to over-fitting. Finally, by comparing the performance of the &amp;quot;AbstractTM&amp;quot; and &amp;quot;Abstract&amp;quot;, we find the list of tumor names helpful for filtering abstracts. We list the results for the test data in Table 2. Column &amp;quot;Experiment&amp;quot; identifies our proposed methods. We show six experiments in Table 2: one f</context>
</contexts>
<marker>Dayanik, Fradkin, Genkin, Kantor, Lewis, Madigan, Menkov, 2004</marker>
<rawString>Dayanik, A., Fradkin, D., Genkin, A., Kantor, P., Lewis, D.D., Madigan, D. and Menkov, V. DIMACS at the TREC 2004 Genomics Track. Proceedings of the Thirteenth Text Retrieval Conference, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Fujita</author>
</authors>
<title>Revisiting Again Document Length Hypotheses TREC-2004 Genomics Track Experiments at Patolis.</title>
<date>2004</date>
<booktitle>Proceedings of the Thirteenth Text Retrieval Conference,</booktitle>
<contexts>
<context position="10132" citStr="Fujita, 2004" startWordPosition="1513" endWordPosition="1514">on performance is better. 5 Results and Discussions Table 1 lists the cross-validation results of each representation for each category (in Normalized Utility (NU)2 measure). For category Allele, &amp;quot;Caption&amp;quot; and &amp;quot;AbstractSEM&amp;quot; perform the best among the basic and semantic representations, respectively. For category Expression, &amp;quot;Caption&amp;quot; plays an important role in identifying relevant documents, which agrees with the finding by the winner of KDD CUP 2002 task 1 (Regev et al., 2002). Similarly, MeSH terms are crucial to the GO category, which are used by top-performing teams (Dayanik et al., 2004; Fujita, 2004) in TREC Genomics 2004. For category Tumor, MeSH terms are important, but after semantic type extraction, &amp;quot;AbstractSEM&amp;quot; exhibits relatively high cross-validation performance. Since only 10 features are selected for the &amp;quot;AbstractSEM&amp;quot;, using this representation alone may be susceptible to over-fitting. Finally, by comparing the performance of the &amp;quot;AbstractTM&amp;quot; and &amp;quot;Abstract&amp;quot;, we find the list of tumor names helpful for filtering abstracts. We list the results for the test data in Table 2. Column &amp;quot;Experiment&amp;quot; identifies our proposed methods. We show six experiments in Table 2: one for Allele (AL),</context>
</contexts>
<marker>Fujita, 2004</marker>
<rawString>Fujita, S., Revisiting Again Document Length Hypotheses TREC-2004 Genomics Track Experiments at Patolis. Proceedings of the Thirteenth Text Retrieval Conference, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Hersh</author>
<author>A Cohen</author>
<author>J Yang</author>
<author>R T Bhuptiraju</author>
<author>P Toberts</author>
<author>M Hearst</author>
</authors>
<title>Genomics Track Overview.</title>
<date>2005</date>
<booktitle>Proceedings of the Fourteenth Text Retrieval Conference,</booktitle>
<tech>TREC</tech>
<contexts>
<context position="13460" citStr="Hersh et al., 2005" startWordPosition="2014" endWordPosition="2017">94 M30+C30+A30+AS10+CS30 TN (for Tumor) 0.8764 0.8747 0.9500 0.0518 0.0982 M30+C30+AT30+AS10+CS30 TS (for Tumor) 0.8814 0.5699 0.6500 0.0339 0.0645 AS10 Table 2. Evaluation Results. Subtask NU (Best/Median) Recall (Best/Median) Precision (Best/Median) F-score (Best/Median) Allele 0.8710/0.7773 0.9337/0.8720 0.4669/0.3153 0.6225/0.5010 Expression 0.8711/0.6413 0.9333/0.7286 0.1899/0.1164 0.3156/0.2005 GO Annotation 0.5870/0.4575 0.8861/0.5656 0.2122/0.3223 0.3424/0.4107 Tumor 0.9433/0.7610 1.0000/0.9500 0.0709/0.0213 0.1325/0.0417 Table 3. Best and Median Results for Each Subtask on TREC 2005 (Hersh et al., 2005). To compare with our performance, we list the best and median results for each subtask on the genomics classification task of TREC 2005 in Table 3. Comparing to Tables 2 and 3, it shows our experimental results have overall high performance. 6 Conclusions and Further Work In this paper, we demonstrate how our system is constructed. Three parts of an article are extracted to represent its content. We incorporate two domain-specific resources, i.e., UMLS and a list of tumor names. For each categorization work, we propose an algorithm to get the best combination of the representations and train </context>
</contexts>
<marker>Hersh, Cohen, Yang, Bhuptiraju, Toberts, Hearst, 2005</marker>
<rawString>Hersh, W., Cohen, A., Yang, J., Bhuptiraju, R.T., Toberts, P. and Hearst, M. TREC 2005 Genomics Track Overview. Proceedings of the Fourteenth Text Retrieval Conference, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Hirschman</author>
<author>J Park</author>
<author>J Tsujii</author>
<author>L Wong</author>
<author>C H Wu</author>
</authors>
<title>Accomplishments and Challenges in Literature Data Mining for Biology.</title>
<date>2002</date>
<journal>Bioinformatics,</journal>
<volume>18</volume>
<issue>12</issue>
<pages>1553--1561</pages>
<contexts>
<context position="1909" citStr="Hirschman et al., 2002" startWordPosition="271" endWordPosition="274">o constantly update databases with new information. With the rapidly growing rate of publication, it is impossible for curators to read every published article. Since fully automated curation systems have not met the strict requirement of high accuracy and recall, database curators still have to read some (if not all) of the articles sent to them. Therefore, it will be very helpful if a classification system can correctly identify the curatable or relevant articles in a large number of biological articles. Recently, several attempts have been made to classify documents from biomedical domain (Hirschman et al., 2002). Couto et al. (2004) used the information extracted from related web resources to classify biomedical literature. Hou et al. (2005) used the reference corpus to help classifying gene annotation. The Genomics Track (http://ir.ohsu.edu/genomics) of TREC 2004 and 2005 organized categorization tasks. The former focused on simplified GO terms while the latter included the triage for &amp;quot;tumor biology&amp;quot;, &amp;quot;embryologic gene expression&amp;quot;, &amp;quot;alleles of mutant phenotypes&amp;quot; and &amp;quot;GO&amp;quot; articles. The increase of the numbers of participants at Genomics Track shows that biological classification problems attracted mu</context>
</contexts>
<marker>Hirschman, Park, Tsujii, Wong, Wu, 2002</marker>
<rawString>Hirschman, L., Park, J., Tsujii, J., Wong, L. and Wu, C.H. Accomplishments and Challenges in Literature Data Mining for Biology. Bioinformatics, 18(12): 1553-1561, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J Hou</author>
<author>C Lee</author>
<author>K H Y Lin</author>
<author>H H Chen</author>
</authors>
<title>A Relevance Detection Approach to Gene Annotation.</title>
<date>2005</date>
<booktitle>Proceedings of the First International Symposium on Semantic Mining in Biomedicine, http://ceur-ws.org,</booktitle>
<volume>148</volume>
<pages>15--23</pages>
<contexts>
<context position="2041" citStr="Hou et al. (2005)" startWordPosition="291" endWordPosition="294">ery published article. Since fully automated curation systems have not met the strict requirement of high accuracy and recall, database curators still have to read some (if not all) of the articles sent to them. Therefore, it will be very helpful if a classification system can correctly identify the curatable or relevant articles in a large number of biological articles. Recently, several attempts have been made to classify documents from biomedical domain (Hirschman et al., 2002). Couto et al. (2004) used the information extracted from related web resources to classify biomedical literature. Hou et al. (2005) used the reference corpus to help classifying gene annotation. The Genomics Track (http://ir.ohsu.edu/genomics) of TREC 2004 and 2005 organized categorization tasks. The former focused on simplified GO terms while the latter included the triage for &amp;quot;tumor biology&amp;quot;, &amp;quot;embryologic gene expression&amp;quot;, &amp;quot;alleles of mutant phenotypes&amp;quot; and &amp;quot;GO&amp;quot; articles. The increase of the numbers of participants at Genomics Track shows that biological classification problems attracted much attention. This paper employs the domain-specific knowledge and knowledge learned from full-text articles to classify biological </context>
</contexts>
<marker>Hou, Lee, Lin, Chen, 2005</marker>
<rawString>Hou, W.J., Lee, C., Lin, K.H.Y. and Chen, H.H. A Relevance Detection Approach to Gene Annotation. Proceedings of the First International Symposium on Semantic Mining in Biomedicine, http://ceur-ws.org, 148: 15-23, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C W Hsu</author>
<author>C C Chang</author>
<author>C J Lin</author>
</authors>
<title>A Practical Guide to Support Vector Classification. http://www.csie.ntu.edu.tw /~cjlin/libsvm/index.html,</title>
<date>2003</date>
<contexts>
<context position="4070" citStr="Hsu et al., 2003" startWordPosition="597" endWordPosition="600">e, and (3) captions of figures and tables. They are denoted as &amp;quot;Abstract&amp;quot;, &amp;quot;MeSH&amp;quot;, and &amp;quot;Caption&amp;quot; in this paper, respectively. Each part is considered as a representation of an article. With the help of domain-specific knowledge, we obtain more detail representations of an article. In the model selection phase, we perform feature ranking on each representation of an article and employ cross-validation to determine the number of features to be kept. Moreover, we use cross-validation to obtain the best combination of all the representations. Finally, a support vector machine (SVM) (Vapnik, 1995; Hsu et al., 2003) classifier is obtained. 159 Figure 1. System Architecture A New Full-Text Article Preprocessing SVM Classifier Yes/No Full-Text Training Articles Preprocessing Model Selection Abstract Caption MeSH Multiple Parts Domain-Specific Knowledge AbsSEM/TM CapSEM/TM MeSHSEM PartsSEM/TM 3 Experimental Data We train classifiers for classifying biomedical articles on the Categorization Task of the TREC 2005 Genomics Track. The task uses data from the Mouse Genome Informatics (MGI) system (http://www.informatics.jax.org/) for four categorization tasks, including tumor biology, embryologic gene expression</context>
</contexts>
<marker>Hsu, Chang, Lin, 2003</marker>
<rawString>Hsu, C.W., Chang, C.C. and Lin, C.J. A Practical Guide to Support Vector Classification. http://www.csie.ntu.edu.tw /~cjlin/libsvm/index.html, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B L Humphreys</author>
<author>D A Lindberg</author>
<author>H M Schoolman</author>
<author>G O Barnett</author>
</authors>
<title>The Unified Medical Language System: an Informatics Research Collaboration.</title>
<date>1998</date>
<journal>Journal of American Medical Information Association,</journal>
<pages>5--1</pages>
<contexts>
<context position="6110" citStr="Humphreys et al., 1998" startWordPosition="895" endWordPosition="898">id ambiguity and enhance clarity, the acronym expansion operation replaces every tagged abbreviation with its long form followed by itself in a pair of parentheses. 4.2 Employing Domain-Specific Knowledge With the help of domain-specific knowledge, we can extract the deeper knowledge in an article. For example, with a gene name dictionary, we can identify the gene names contained in an article. Moreover, by further consulting organism databases, we can get the properties of the genes. Two domain-specific resources are exploited in this study. One is the Unified Medical Language System (UMLS) (Humphreys et al., 1998) and the other is a list of tumor names obtained from Mouse Tumor Biology Database (MTB)1. UMLS contains a huge dictionary of biomedical terms – the UMLS Metathesaurus and defines a hierarchy of semantic types – the UMLS Semantic Network. Each concept in the Metathesaurus contains a set of strings, which are variants of each other and belong to one or more semantic types in the Semantic Network. Therefore, given a string, we can obtain a set of semantic types to which it belongs. Then we obtain another representation of the article by gathering the semantic types found in the part of the artic</context>
</contexts>
<marker>Humphreys, Lindberg, Schoolman, Barnett, 1998</marker>
<rawString>Humphreys, B.L., Lindberg, D.A., Schoolman, H.M. and Barnett, G.O. The Unified Medical Language System: an Informatics Research Collaboration. Journal of American Medical Information Association, 5(1):1-11, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Regev</author>
<author>M Finkelstein-Landau</author>
<author>R Feldman</author>
</authors>
<title>Rule-based Extraction of Experimental Evidence</title>
<date>2002</date>
<booktitle>in the Biomedical Domain - the KDD Cup (Task 1). SIGKDD Explorations,</booktitle>
<pages>4--2</pages>
<contexts>
<context position="10001" citStr="Regev et al., 2002" startWordPosition="1490" endWordPosition="1493">M&amp;quot; and &amp;quot;CaptionTM&amp;quot; representations, we use them to replace their unfiltered counterparts &amp;quot;Abstract&amp;quot; and &amp;quot;Caption&amp;quot; when the cross-validation performance is better. 5 Results and Discussions Table 1 lists the cross-validation results of each representation for each category (in Normalized Utility (NU)2 measure). For category Allele, &amp;quot;Caption&amp;quot; and &amp;quot;AbstractSEM&amp;quot; perform the best among the basic and semantic representations, respectively. For category Expression, &amp;quot;Caption&amp;quot; plays an important role in identifying relevant documents, which agrees with the finding by the winner of KDD CUP 2002 task 1 (Regev et al., 2002). Similarly, MeSH terms are crucial to the GO category, which are used by top-performing teams (Dayanik et al., 2004; Fujita, 2004) in TREC Genomics 2004. For category Tumor, MeSH terms are important, but after semantic type extraction, &amp;quot;AbstractSEM&amp;quot; exhibits relatively high cross-validation performance. Since only 10 features are selected for the &amp;quot;AbstractSEM&amp;quot;, using this representation alone may be susceptible to over-fitting. Finally, by comparing the performance of the &amp;quot;AbstractTM&amp;quot; and &amp;quot;Abstract&amp;quot;, we find the list of tumor names helpful for filtering abstracts. We list the results for the </context>
</contexts>
<marker>Regev, Finkelstein-Landau, Feldman, 2002</marker>
<rawString>Regev, Y., Finkelstein-Landau, M. and Feldman, R. Rule-based Extraction of Experimental Evidence in the Biomedical Domain - the KDD Cup (Task 1). SIGKDD Explorations, 4(2):90-92, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory,</title>
<date>1995</date>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="4051" citStr="Vapnik, 1995" startWordPosition="595" endWordPosition="596">to this article, and (3) captions of figures and tables. They are denoted as &amp;quot;Abstract&amp;quot;, &amp;quot;MeSH&amp;quot;, and &amp;quot;Caption&amp;quot; in this paper, respectively. Each part is considered as a representation of an article. With the help of domain-specific knowledge, we obtain more detail representations of an article. In the model selection phase, we perform feature ranking on each representation of an article and employ cross-validation to determine the number of features to be kept. Moreover, we use cross-validation to obtain the best combination of all the representations. Finally, a support vector machine (SVM) (Vapnik, 1995; Hsu et al., 2003) classifier is obtained. 159 Figure 1. System Architecture A New Full-Text Article Preprocessing SVM Classifier Yes/No Full-Text Training Articles Preprocessing Model Selection Abstract Caption MeSH Multiple Parts Domain-Specific Knowledge AbsSEM/TM CapSEM/TM MeSHSEM PartsSEM/TM 3 Experimental Data We train classifiers for classifying biomedical articles on the Categorization Task of the TREC 2005 Genomics Track. The task uses data from the Mouse Genome Informatics (MGI) system (http://www.informatics.jax.org/) for four categorization tasks, including tumor biology, embryolo</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vapnik, V. The Nature of Statistical Learning Theory, Springer-Verlag, 1995.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>