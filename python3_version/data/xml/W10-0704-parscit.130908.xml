<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011416">
<title confidence="0.9941075">
Consensus versus Expertise: A Case Study of Word Alignment with
Mechanical Turk
</title>
<author confidence="0.992298">
Qin Gao and Stephan Vogel
</author>
<affiliation confidence="0.9860415">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.631667">
5000 Forbes Avenue, Pittsburgh PA, 15213
</address>
<email confidence="0.999681">
{qing,stephan.vogel}@cs.cmu.edu
</email>
<sectionHeader confidence="0.997399" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999296764705883">
Word alignment is an important preprocessing step
for machine translation. The project aims at incorpo-
rating manual alignments from Amazon Mechanical
Turk (MTurk) to help improve word alignment qual-
ity. As a global crowdsourcing service, MTurk can
provide flexible and abundant labor force and there-
fore reduce the cost of obtaining labels. An easy-
to-use interface is developed to simplify the labeling
process. We compare the alignment results by Turk-
ers to that by experts, and incorporate the alignments
in a semi-supervised word alignment tool to improve
the quality of the labels. We also compared two pric-
ing strategies for word alignment task. Experimental
results show high precision of the alignments pro-
vided by Turkers and the semi-supervised approach
achieved 0.5% absolute reduction on alignment error
rate.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998868863636364">
Word alignment is used in various natural language
processing tasks. Most state-of-the-art statistical machine
translation systems rely on word alignment as a prepro-
cessing step. The quality of word alignment is usually
measured by AER, which is loosely related to BLEU
score (Lopez and Resnik, 2006). There has been re-
search on utilizing manually aligned corpus to assist auto-
matic word alignment, and obtains encouraging results on
alignment error rate. (Callison-Burch et al., 2004; Blun-
som and Cohn, 2006; Fraser and Marcu, 2006; Niehues
and Vogel, 2008; Taskar et al., 2005; Liu et al., 2005;
Moore, 2005). However, how to obtain large amount of
alignments with good quality is problematic. Labeling
word-aligned parallel corpora requires significant amount
of labor. In this paper we explore the possibility of us-
ing Amazon Mechanical Turk (MTurk) to obtain manual
word alignment faster, cheaper, with high quality.
Crowdsourcing is a way of getting random labor force
on-line with low cost. MTurk is one of the leading
providers for crowdsourcing marketplace. There have
been several research papers on using MTurk to help nat-
ural language processing tasks, Callison-Burch (2009)
used MTurk to evaluate machine translation results. Kit-
tur et al. (2008) showed the importance of validation
data set, the task is evaluating quality of Wikipedia arti-
cles. There are also experiments use the annotation from
MTurk in place of training data. For example (Kaisser et
al., 2008) and (Kaisser and Lowe, 2008) used MTurk to
build question answering datasets and choose summary
lengths that suite the need of the users.
Word alignment is a relatively complicate task for in-
experienced workers. The fact puts us in a dilemma,
we can either provide lengthy instructions and train the
workers, or we must face the problem that workers may
have their own standards. The former solution is im-
practical in the context of crowdsourcing because heavily
trained workers will expect higher payment, which de-
feats economical nature of crowdsourcing. Therefore we
are forced to face the uncertainty, and ask ourselves the
following questions: First, how consistent would the la-
bels from random labelers be, given minimal or no in-
structions? Second, how consistent would these intuitive
labels be consistent with the labels from expert labelers?
Third, if there is certain level of consistency between the
intuitive labels and the labels from experts, can we extract
most reliable links from the former? Last but not least,
given the alignment links, can we utilize them to help au-
tomatic word alignment without further human efforts?
The statistics on the data we get shows the internal
consistency among multiple MTurk alignments is greater
than 70%, and the precision is greater than 84% when
consider all the links. By applying majority vote and
consensus strategies, we can select links that have greater
than 95% accuracy. When applying the alignment links
on a new aligner that can perform constrained EM al-
gorithm for IBM models we observe 0.5% absolute im-
provements on alignment error rate. The average per-
word cost is about 2 cent per word.
The paper will be organized as follows, first we will
discuss the design principle of the task and the implemen-
tation of the application for word alignment in section
2. Section 3 describes the algorithm used in utilizing the
manual alignments. Section 4 presents the analysis on the
harvested data and the expert labels, and the the experi-
ment results of semi-supervised word alignment. Section
5 concludes the paper.
</bodyText>
<page confidence="0.989059">
30
</page>
<note confidence="0.884374">
Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 30–34,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.870153" genericHeader="method">
2 Design of the task
</sectionHeader>
<bodyText confidence="0.999761071428572">
In this task, we want to collect manual word alignment
data from MTurk workers, Figure 2 shows an example of
word alignment. There are two sentences which are trans-
lation of each other. There are links between words in two
sentences, indicating the words are translation pairs. No-
tice that one word can be aligned to zero or more words,
if a word is aligned to zero word, we can assume it is
aligned to a virtual empty word. Therefore, given a sen-
tence pair, we want workers to link words in source sen-
tence to one or more target words or the empty word.
In our experiment, we use a Chinese-English parallel
corpus and ask workers to alignment the words in Chi-
nese sentence to the words in English sentence. We do
not provide any alignment links from automatic aligner.
</bodyText>
<subsectionHeader confidence="0.994374">
2.1 Guidelines of design
</subsectionHeader>
<bodyText confidence="0.9999695">
MTurk represents a new pattern of market that has
yet be thoroughly studied. Mason and Watts (2009)
shows that higher payment does not guarantee results
with higher quality. Also, one should be aware that the
web-based interface is vulnerable to automatic scripts
that generate highly consistent yet meaningless results.
To ensure a better result, several measures must be com-
bined: 1) Require workers to take qualifications before
they can accept the tasks. 2) Implement an interface less
vulnerable to automatic scripts. 3) Build quality control
mechanism that filters inaccurate results, and finally 4)
Redesign the interface so that the time spent by careful
and careless workers does not differ too much, so there
is less incentives for workers to submit random results.
With these guidelines in mind, we put together several
elements into the HIT.
</bodyText>
<subsectionHeader confidence="0.662189">
Qualifications
</subsectionHeader>
<bodyText confidence="0.999974666666667">
We require the workers to take qualifications, which
requires them to pick correct translation of five Chinese
words. The Chinese word is rendered in bitmap.
</bodyText>
<subsectionHeader confidence="0.814459">
Interface implementation
</subsectionHeader>
<bodyText confidence="0.9999412">
We implemented the word alignment interface on
top of Google Web Toolkit, which enables developing
Javascript based Web application in Java. Because
all the content of the interface, including the content in
the final result, is generated dynamically in the run time,
it is much more difficult to hack than plain HTML forms.
Figure 1 shows a snapshot of the interface1. The labeling
procedure requires only mouse click. The worker need
to label all the words with a golden background2. To
complete the task, the worker needs to: 1) Click on the
</bodyText>
<footnote confidence="0.78184675">
1A demo of the latest version can be found at http://
alt-aligner.appspot.com, the source code of the
aligner is distributed under Apache License 2.0 on http://
code.google.com/p/alt-aligner/
</footnote>
<bodyText confidence="0.979274">
2If the document is printed in greyscale, the lightest background (ex-
cept the white one) is actually golden, the second lightest one is red and
the darkest one is dark blue.
Chinese word he want to label. 2) Click on the English
words he want the Chinese word to be linked, or click on
the empty word to the end of the sentence. 3) If he want to
delete a link, he need to click on the English word again,
otherwise he can move on to next unlabeled word, or to
modify links on another labeled word. 4) Only when all
required words are labeled, the user would be allowed to
click on submit button.
The interface has two more functionalities, first, it al-
lows to specify a subset of words in the sentence for user
to label, as shown in the snapshot, words with white back-
ground are not required to label. Secondly it supports
providing initial alignment on the sentence.
</bodyText>
<subsectionHeader confidence="0.862671">
Quality control
</subsectionHeader>
<bodyText confidence="0.999875615384615">
Quality control is a crucial component of the system.
For problems that have clear gold standard answers to a
portion of data, the quality control can be done by min-
gling the known into the unknown, and rejecting the sub-
missions with low qualities on known samples. However
in our situation it is not easy to do so because although
we have fully manual aligned sentences, we do not have
corpus in which the sentences are partially aligned, there-
fore if we want to use the method we have to let worker
label an additional sentence, which may double the effort
for the workers. Also we do not provide thorough stan-
dard for users, therefore before we know the divergence
of the alignments, we actually do not know how to set the
threshold, even with given gold standard labels. In addi-
tion, if the method will be applied on languages with low
resource, we cannot assume availability of gold standard
answers. Therefore, we only try to filter out answers base
on the consensus. The quality control works as follows.
Firstly we assign an alignment task to 2n + 1 workers.
For these submissions, we first try to build a majority an-
swer from these assignments. For each alignment link,
if it appears in more than n submissions. Then every in-
dividual assignments will be compared to the majority
alignment, so we can get the precision and recall rates.
If either precision or recall rate is lower than a threshold,
we will reject the submission.
</bodyText>
<subsectionHeader confidence="0.998765">
2.2 Pricing and worker base
</subsectionHeader>
<bodyText confidence="0.999952333333333">
We tried two pricing strategies. The first one fixes the
number of words that a worker need to label for each
HIT, and fix the rate for each HIT. The second one always
</bodyText>
<figureCaption confidence="0.998601">
Figure 1: A snapshot of the labeling interface.
</figureCaption>
<page confidence="0.998907">
31
</page>
<bodyText confidence="0.999945142857143">
asks workers to label every word in the sentence, in the
mean time we vary the rate for each HIT according to the
lengths of source sentences. For each strategy we tried
different rates, starting from 10 words per cent. However
we did not get enough workers even after the price raised
to 2 words per cent. The result indicates a limited worker
base of Chinese speakers.
</bodyText>
<sectionHeader confidence="0.987048" genericHeader="method">
3 Utilizing the manual alignments
</sectionHeader>
<bodyText confidence="0.999961">
As we can expect, given no explicit guideline for word
alignments, the variance of different assignments can be
fairly large, a question will raise what can we do with
the disagreements? As we will see later in the experi-
ment part, the labels are more likely to be consistent with
expert labels if more workers agree on it. Therefore, a
simple strategy is to use only the links that more workers
have consensus on them.
However the method instantly gives rise to a prob-
lem. Now the alignment is not “full alignments”, instead,
they are “partial”. The claim seems to be trivial but they
have completely different underlying assumptions. Fig-
ure 2 shows the comparison of partial alignments (the
bold link) and full alignments (the dashed and the bold
links). In the example, if full alignment is given, we can
assert 2005 is only aligned to 20054H&apos;, not to R�, or A)C,
but we cannot do that if only partial alignment is given.
In this paper we experiment with a novel method which
uses the partial alignment to constraint the EM algorithm
in the parameter estimation of IBM models.
IBM Models (Brown et. al., 1993) are a series of gen-
erative models for word alignment. GIZA++ (Och and
Ney, 2003) is the most widely used implementation of
IBM models and HMM (Vogel et al., 1996) where EM
algorithm is employed to estimate the model parameters.
In the E-step, it is possible to obtain sufficient statistics
from all possible alignments for simple models such as
Model 1 and Model 2. Meanwhile for fertility-based
models such as Model 3, 4, 5, enumerating all possible
alignments is NP-complete. In practice, we use sim-
pler models such as HMM or Model 2 to generate a
“center alignment” and then try to find better alignments
among the neighbors of it. The neighbors of an alignment
aJ1 = [a1, a2, · · · , aJ], aj E [0,I] is defined as align-
ments that can be generated from aJ1 by one of the oper-
ators: 1) Move operator m[i,j], that changes aj := i, i.e.
arbitrarily set word fj in source sentence to align to word
ei in target sentence; 2) Swap operator s[j1,j2] that ex-
changes aj1 and aj2. The algorithm will update the center
alignment as long as a better alignment can be found, and
finally outputs a local optimal alignment. The neighbor
alignments of the alignment are then used in collecting
the counts for the M Step.
In order to use partial manual alignments to constrain
the search space, we separate the algorithm into two
stages, first the seed alignment will be optimized towards
the constraints. Each iteration we only pick a new center
alignment with less inconsistent links than the original
one, until the alignment is consistent with all constraints.
After that, in each iteration we pick the alignment with
highest likelihood but does not introduce any inconsistent
links. The algorithm will output a local optimal align-
ment consistent with the partial alignment. When col-
lecting the counts for M-step, we also need to exclude all
alignments that are not consistent with the partial man-
ual alignment. The task can also be done by skipping the
inconsistent alignments in the neighborhood of the local
optimal alignment.
</bodyText>
<sectionHeader confidence="0.994044" genericHeader="evaluation">
4 Experiment and analysis
</sectionHeader>
<bodyText confidence="0.998911">
In this section we will show the analysis of the har-
vested MTurk alignments and the results of the semi-
supervised word alignment experiments.
</bodyText>
<subsectionHeader confidence="0.99805">
4.1 Consistency of the manual alignments
</subsectionHeader>
<bodyText confidence="0.999997157894737">
We first examine the internal consistency of the MTurk
alignments. We calculate the internal consistency rate
in both results. Because we requested three assignments
for every question, we classify the links in two different
ways. First, if a link appear in all three submissions, we
classify it as “consensus link”. Second, if a link appear in
more than one submissions, we classify it as “majority”,
otherwise it is classified as “minority”. Table 1 presents
the statistics of partial alignment and full alignment tasks.
Note that by spending the same amount of money, we get
more sentences aligned because for fixed rate partial sen-
tence alignment tasks, sometimes we may have overlaps
between tasks. Therefore we also calculate a subset of
full alignment tasks that consists of all the sentences in
partial alignment tasks. The statistics shows that although
generally full alignment tasks generates more links, the
partial alignment tasks gives denser alignments. It is in-
teresting to know whether the denser alignments lead to
higher recall rate or lower precision.
</bodyText>
<subsectionHeader confidence="0.999311">
4.2 Comparing MTurk and expert alignments
</subsectionHeader>
<bodyText confidence="0.9987419">
To exam the quality of alignments, we compared them
with expert alignments. Table 2 lists the precision, recall
and F-1 scores for partial and full alignment tasks. We
compare the consistency of all links, the links in majority
group and the consensus links.
As we can observe from the results, the Turkers tend
to label less links than the experts, Interestingly, the over-
all quality of partial alignment tasks is significantly better
than full alignment tasks. Despite the lower recall rate, it
is encouraging that the majority vote and consensus links
</bodyText>
<footnote confidence="0.352097">
2005年 Rq 夏天
</footnote>
<note confidence="0.674047">
The summer of 2005
</note>
<figureCaption confidence="0.994553">
Figure 2: Partial and full alignments
</figureCaption>
<page confidence="0.975757">
32
</page>
<table confidence="0.999962384615385">
Partial Full Full-Int
Number of sentences 135 239 135
Number of words 2,008 3,241 2,008
Consensus words 13,03 2,299 1,426
Consensus rate(%) 64.89 70.93 71.02
Total Links 7,508 9,767 6,114
Consensus Links 5,625 7,755 4,854
Consensus Rate(%) 74.92 79.40 79.39
Total Unique Links 3,186 3,989 2,506
Consensus Links 1,875 2,585 1,618
Consensus Rate(%) 58.85 64.80 64.54
In majority group 2,447 3,193 1,426
Majority rate(%) 76.80 80.04 71.06
</table>
<tableCaption confidence="0.996197666666667">
Table 1: Internal consistency of manual alignments, here
Full-Int means statistics of full alignment tasks on the
sentences that also aligned using partial alignment task
</tableCaption>
<table confidence="0.9994526">
All Links Majority Links Consensus Links
P. R. F. P. R. F. P. R. F.
P 0.84 0.88 0.86 0.95 0.76 0.84 0.98 0.60 0.74
F 0.88 0.70 0.78 0.96 0.61 0.75 0.99 0.51 0.68
I 0.87 0.71 0.79 0.95 0.62 0.75 0.98 0.52 0.68
</table>
<tableCaption confidence="0.99662">
Table 2: Consistency of MTurk alignments with expert
</tableCaption>
<bodyText confidence="0.9532931">
alignments, showing precision (P), recall (R) and F1 (F)
between MTurk and expert alignments. P, F, and I corre-
spond to Partial, Full and Full-Int in Table 1
yield very high precisions against expert alignments. Ta-
ble 3 lists the words with most errors. Most errors occur
on function words. A manual review shows that more
than 85% errors have function words on either Chinese
side or English side. The result, however, is as expected
because these words are hard to label and we did not pro-
vide clear rule for function words.
</bodyText>
<subsectionHeader confidence="0.998611">
4.3 Results of semi-supervised word alignment
</subsectionHeader>
<bodyText confidence="0.999797571428571">
In this experiment we try to use the alignment links in
the semi-supervised word alignment algorithm. We use
Chinese-English manually aligned corpus in the exper-
iments, which contains 21,863 sentence pairs, 424,683
Chinese words and 524,882 English words. First, we use
the parallel corpus to train IBM models without any man-
ual alignments, we run 5 iterations of model 1 and HMM,
</bodyText>
<table confidence="0.997428285714286">
Chinese English
FN FP FN FP
64 n, 16 , 122 the 15 ,
26 11 I 67 NULL 11 a
19 , 9 43 of 6 the
17 ^I 3 36 to 6 is
16 �H 3 �j 24 a 4 to
</table>
<tableCaption confidence="0.998508">
Table 3: Words that most errors occur, FN means a false
</tableCaption>
<bodyText confidence="0.9537669">
negative error occurred on the word, i.e. a link to this
word or from this word is missing. FP means false pos-
itive, accordingly. The manual alignment links comes
from majority vote.
3 iterations of model 3 and 6 iterations of model 4. Then
we resume the training procedure from the third itera-
tions of model 4. This time we load the manual alignment
links and perform 3 iterations of constrained EM. We also
experiment with 3 different sets of alignments. Table 4
presents the improvements on the alignment quality.
</bodyText>
<table confidence="0.99924725">
Unsupervised
Ch-En En-Ch
Prec. Recall AER Prec. Recall AER
68.22 46.88 44.43 65.35 55.05 40.24
All Links
Partial 68.28 47.09 44.26 65.86 55.63 39.68
Full-Int 68.28 47.09 44.26 65.85 55.63 39.69
Full 68.37 47.15 44.19 65.90 55.67 39.65
Majority Links
Partial 68.28 47.08 44.27 65.84 55.62 39.70
Full-Int 68.28 47.08 44.27 65.84 55.61 39.71
Full 68.37 47.13 44.20 65.88 55.65 39.67
Consensus Links
Partial 68.24 47.06 44.30 65.83 55.60 39.71
Full-Int 68.25 47.06 44.29 65.83 55.60 39.72
Full 68.31 47.10 44.25 65.86 55.63 39.68
</table>
<tableCaption confidence="0.9788035">
Table 4: The performance of using manual alignments in
semi-supervised word alignment
</tableCaption>
<bodyText confidence="0.999848571428571">
From the result we can see that given the same amount
of links the improvement of alignment error rate is gen-
erally the same for partial and full alignment tasks, how-
ever, if we consider the amount of money spent on the
task, the full alignment task collect much more data than
partial alignments, we consider full sentence alignment
more cost efficient in this sense.
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999959909090909">
In this pilot experiment, we explore the possibility of
using Amazon Mechanical Turk (MTurk) to collect bilin-
gual word alignment data to assist automatic word align-
ment. We develop a system including a word align-
ment interface based on Javascript and a quality control
scheme. To utilize the manual alignments, we develop a
semi-supervised word alignment algorithm that can per-
form constrained EM with partial alignments. The algo-
rithm enables us to use only the most reliable links by
majority vote or consensus. The effectiveness of these
methods is proven by small-scale experiments. The re-
sults show the manual alignments from MTurk have high
precision with expert word alignment, especially when
filtered by majority vote or consensus. We get small im-
provement on semi-supervised word alignment. Given
the promising results, it is interesting to see if the ten-
dency will carry on when we scale up the experiments.
However the experiment also shows some problems,
first the coverage of worker base on MTurk is limited.
Given small worker base for specific languages, the cost
efficiency for NLP tasks in those languages is question-
able.
</bodyText>
<page confidence="0.99874">
33
</page>
<sectionHeader confidence="0.996038" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997967125">
P. Blunsom and T. Cohn. 2006. Discriminative word align-
ment with conditional random fields. In Proceedings of the
21st International Conference on Computational Linguistics
and the 44th annual meeting of the Association for Compu-
tational Linguistics, pages 65–72.
P. F. Brown et. al. 1993. The mathematics of statistical ma-
chine translation: Parameter estimation. In Computational
Linguistics, volume 19(2), pages 263–331.
C. Callison-Burch, D. Talbot, and D. Osborne. 2004. Statistical
machine translation with word- and sentence-aligned parallel
corpora. In Proceedings of the 42nd Annual Meeting of the
Association for Computational Linguistics (ACL-2004).
C. Callison-Burch. 2009. Fast, cheap, and creative: Evaluat-
ing translation quality using Amazon’s Mechanical Turk. In
Proceedings of the 2009 Conference on Empirical Methods
in Natural Language Processing, pages 286–295. Associa-
tion for Computational Linguistics.
A. Fraser and D. Marcu. 2006. Semi-supervised training for
statistical word alignment. In ACL-44: Proceedings of the
21st International Conference on Computational Linguistics
and the 44th annual meeting of the Association for Compu-
tational Linguistics, pages 769–776.
M. Kaisser and J. B. Lowe. 2008. A research collection of
question answer sentence pairs. In Proceedings of The 6th
Language Resources and Evaluation Conference.
M. Kaisser, M. Hearst, and J.B. Lowe. 2008. Evidence for
varying search results summary lengths. In Proceedings of
the 46th Annual Meeting of the Association for Computa-
tional Linguistics.
A. Kittur, E. H. Chi, and B Suh. 2008. Crowdsourcing user
studies with mechanical turk. In CHI ’08: Proceeding of the
twenty-sixth annual SIGCHI conference on Human factors in
computing systems, pages 453–456.
Y. Liu, Q. Liu, and S. Lin. 2005. Log-linear models for word
alignment. In ACL ’05: Proceedings of the 43rd Annual
Meeting on Association for Computational Linguistics, pages
459–466.
A. Lopez and P. Resnik. 2006. Word-based alignment, phrase-
based translation: What’s the link? with philip resnik. In
Proceedings of the 7th Biennial Conference of the Associa-
tion for Machine Translation in the Americas (AMTA-2006).
W. Mason and D. J. Watts. 2009. Financial incentives and the
“performance of crowds”. In HCOMP ’09: Proceedings of
the ACM SIGKDD Workshop on Human Computation, pages
77–85.
R. C Moore. 2005. A discriminative framework for bilingual
word alignment. In Proceedings of the conference on Hu-
man Language Technology and Empirical Methods in Natu-
ral Language Processing, pages 81–88.
J. Niehues and S. Vogel. 2008. Discriminative word alignment
via alignment matrix modeling. In Proceedings of the Third
Workshop on Statistical Machine Translation, pages 18–25.
F. J. Och and H. Ney. 2003. A systematic comparison of vari-
ous statistical alignment models. In Computational Linguis-
tics, volume 1:29, pages 19–51.
B. Taskar, S. Lacoste-Julien, and D. Klein. 2005. A discrim-
inative matching approach to word alignment. In Proceed-
ings of the conference on Human Language Technology and
Empirical Methods in Natural Language Processing, pages
73–80.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM based word
alignment in statistical machine translation. In Proceedings
of 16th International Conference on Computational Linguis-
tics), pages 836–841.
</reference>
<page confidence="0.99932">
34
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.557572">
<title confidence="0.997589">Consensus versus Expertise: A Case Study of Word Alignment</title>
<author confidence="0.796365">Mechanical Turk</author>
<affiliation confidence="0.838307666666667">Gao Language Technologies Carnegie Mellon</affiliation>
<address confidence="0.996336">5000 Forbes Avenue, Pittsburgh PA,</address>
<abstract confidence="0.995888333333333">Word alignment is an important preprocessing step for machine translation. The project aims at incorporating manual alignments from Amazon Mechanical Turk (MTurk) to help improve word alignment quality. As a global crowdsourcing service, MTurk can provide flexible and abundant labor force and therefore reduce the cost of obtaining labels. An easyto-use interface is developed to simplify the labeling process. We compare the alignment results by Turkers to that by experts, and incorporate the alignments in a semi-supervised word alignment tool to improve the quality of the labels. We also compared two pricing strategies for word alignment task. Experimental results show high precision of the alignments provided by Turkers and the semi-supervised approach achieved 0.5% absolute reduction on alignment error rate.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Blunsom</author>
<author>T Cohn</author>
</authors>
<title>Discriminative word alignment with conditional random fields.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>65--72</pages>
<contexts>
<context position="1591" citStr="Blunsom and Cohn, 2006" startWordPosition="234" endWordPosition="238">Turkers and the semi-supervised approach achieved 0.5% absolute reduction on alignment error rate. 1 Introduction Word alignment is used in various natural language processing tasks. Most state-of-the-art statistical machine translation systems rely on word alignment as a preprocessing step. The quality of word alignment is usually measured by AER, which is loosely related to BLEU score (Lopez and Resnik, 2006). There has been research on utilizing manually aligned corpus to assist automatic word alignment, and obtains encouraging results on alignment error rate. (Callison-Burch et al., 2004; Blunsom and Cohn, 2006; Fraser and Marcu, 2006; Niehues and Vogel, 2008; Taskar et al., 2005; Liu et al., 2005; Moore, 2005). However, how to obtain large amount of alignments with good quality is problematic. Labeling word-aligned parallel corpora requires significant amount of labor. In this paper we explore the possibility of using Amazon Mechanical Turk (MTurk) to obtain manual word alignment faster, cheaper, with high quality. Crowdsourcing is a way of getting random labor force on-line with low cost. MTurk is one of the leading providers for crowdsourcing marketplace. There have been several research papers o</context>
</contexts>
<marker>Blunsom, Cohn, 2006</marker>
<rawString>P. Blunsom and T. Cohn. 2006. Discriminative word alignment with conditional random fields. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>19</volume>
<issue>2</issue>
<pages>263--331</pages>
<marker>Brown, 1993</marker>
<rawString>P. F. Brown et. al. 1993. The mathematics of statistical machine translation: Parameter estimation. In Computational Linguistics, volume 19(2), pages 263–331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
<author>D Talbot</author>
<author>D Osborne</author>
</authors>
<title>Statistical machine translation with word- and sentence-aligned parallel corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-2004).</booktitle>
<contexts>
<context position="1567" citStr="Callison-Burch et al., 2004" startWordPosition="230" endWordPosition="233">f the alignments provided by Turkers and the semi-supervised approach achieved 0.5% absolute reduction on alignment error rate. 1 Introduction Word alignment is used in various natural language processing tasks. Most state-of-the-art statistical machine translation systems rely on word alignment as a preprocessing step. The quality of word alignment is usually measured by AER, which is loosely related to BLEU score (Lopez and Resnik, 2006). There has been research on utilizing manually aligned corpus to assist automatic word alignment, and obtains encouraging results on alignment error rate. (Callison-Burch et al., 2004; Blunsom and Cohn, 2006; Fraser and Marcu, 2006; Niehues and Vogel, 2008; Taskar et al., 2005; Liu et al., 2005; Moore, 2005). However, how to obtain large amount of alignments with good quality is problematic. Labeling word-aligned parallel corpora requires significant amount of labor. In this paper we explore the possibility of using Amazon Mechanical Turk (MTurk) to obtain manual word alignment faster, cheaper, with high quality. Crowdsourcing is a way of getting random labor force on-line with low cost. MTurk is one of the leading providers for crowdsourcing marketplace. There have been s</context>
</contexts>
<marker>Callison-Burch, Talbot, Osborne, 2004</marker>
<rawString>C. Callison-Burch, D. Talbot, and D. Osborne. 2004. Statistical machine translation with word- and sentence-aligned parallel corpora. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
</authors>
<title>Fast, cheap, and creative: Evaluating translation quality using Amazon’s Mechanical Turk.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>286--295</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2269" citStr="Callison-Burch (2009)" startWordPosition="342" endWordPosition="343"> et al., 2005; Liu et al., 2005; Moore, 2005). However, how to obtain large amount of alignments with good quality is problematic. Labeling word-aligned parallel corpora requires significant amount of labor. In this paper we explore the possibility of using Amazon Mechanical Turk (MTurk) to obtain manual word alignment faster, cheaper, with high quality. Crowdsourcing is a way of getting random labor force on-line with low cost. MTurk is one of the leading providers for crowdsourcing marketplace. There have been several research papers on using MTurk to help natural language processing tasks, Callison-Burch (2009) used MTurk to evaluate machine translation results. Kittur et al. (2008) showed the importance of validation data set, the task is evaluating quality of Wikipedia articles. There are also experiments use the annotation from MTurk in place of training data. For example (Kaisser et al., 2008) and (Kaisser and Lowe, 2008) used MTurk to build question answering datasets and choose summary lengths that suite the need of the users. Word alignment is a relatively complicate task for inexperienced workers. The fact puts us in a dilemma, we can either provide lengthy instructions and train the workers</context>
</contexts>
<marker>Callison-Burch, 2009</marker>
<rawString>C. Callison-Burch. 2009. Fast, cheap, and creative: Evaluating translation quality using Amazon’s Mechanical Turk. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 286–295. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Fraser</author>
<author>D Marcu</author>
</authors>
<title>Semi-supervised training for statistical word alignment.</title>
<date>2006</date>
<booktitle>In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>769--776</pages>
<contexts>
<context position="1615" citStr="Fraser and Marcu, 2006" startWordPosition="239" endWordPosition="242">ervised approach achieved 0.5% absolute reduction on alignment error rate. 1 Introduction Word alignment is used in various natural language processing tasks. Most state-of-the-art statistical machine translation systems rely on word alignment as a preprocessing step. The quality of word alignment is usually measured by AER, which is loosely related to BLEU score (Lopez and Resnik, 2006). There has been research on utilizing manually aligned corpus to assist automatic word alignment, and obtains encouraging results on alignment error rate. (Callison-Burch et al., 2004; Blunsom and Cohn, 2006; Fraser and Marcu, 2006; Niehues and Vogel, 2008; Taskar et al., 2005; Liu et al., 2005; Moore, 2005). However, how to obtain large amount of alignments with good quality is problematic. Labeling word-aligned parallel corpora requires significant amount of labor. In this paper we explore the possibility of using Amazon Mechanical Turk (MTurk) to obtain manual word alignment faster, cheaper, with high quality. Crowdsourcing is a way of getting random labor force on-line with low cost. MTurk is one of the leading providers for crowdsourcing marketplace. There have been several research papers on using MTurk to help na</context>
</contexts>
<marker>Fraser, Marcu, 2006</marker>
<rawString>A. Fraser and D. Marcu. 2006. Semi-supervised training for statistical word alignment. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 769–776.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kaisser</author>
<author>J B Lowe</author>
</authors>
<title>A research collection of question answer sentence pairs.</title>
<date>2008</date>
<booktitle>In Proceedings of The 6th Language Resources and Evaluation Conference.</booktitle>
<contexts>
<context position="2590" citStr="Kaisser and Lowe, 2008" startWordPosition="393" endWordPosition="396">t faster, cheaper, with high quality. Crowdsourcing is a way of getting random labor force on-line with low cost. MTurk is one of the leading providers for crowdsourcing marketplace. There have been several research papers on using MTurk to help natural language processing tasks, Callison-Burch (2009) used MTurk to evaluate machine translation results. Kittur et al. (2008) showed the importance of validation data set, the task is evaluating quality of Wikipedia articles. There are also experiments use the annotation from MTurk in place of training data. For example (Kaisser et al., 2008) and (Kaisser and Lowe, 2008) used MTurk to build question answering datasets and choose summary lengths that suite the need of the users. Word alignment is a relatively complicate task for inexperienced workers. The fact puts us in a dilemma, we can either provide lengthy instructions and train the workers, or we must face the problem that workers may have their own standards. The former solution is impractical in the context of crowdsourcing because heavily trained workers will expect higher payment, which defeats economical nature of crowdsourcing. Therefore we are forced to face the uncertainty, and ask ourselves the </context>
</contexts>
<marker>Kaisser, Lowe, 2008</marker>
<rawString>M. Kaisser and J. B. Lowe. 2008. A research collection of question answer sentence pairs. In Proceedings of The 6th Language Resources and Evaluation Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kaisser</author>
<author>M Hearst</author>
<author>J B Lowe</author>
</authors>
<title>Evidence for varying search results summary lengths.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2561" citStr="Kaisser et al., 2008" startWordPosition="388" endWordPosition="391">obtain manual word alignment faster, cheaper, with high quality. Crowdsourcing is a way of getting random labor force on-line with low cost. MTurk is one of the leading providers for crowdsourcing marketplace. There have been several research papers on using MTurk to help natural language processing tasks, Callison-Burch (2009) used MTurk to evaluate machine translation results. Kittur et al. (2008) showed the importance of validation data set, the task is evaluating quality of Wikipedia articles. There are also experiments use the annotation from MTurk in place of training data. For example (Kaisser et al., 2008) and (Kaisser and Lowe, 2008) used MTurk to build question answering datasets and choose summary lengths that suite the need of the users. Word alignment is a relatively complicate task for inexperienced workers. The fact puts us in a dilemma, we can either provide lengthy instructions and train the workers, or we must face the problem that workers may have their own standards. The former solution is impractical in the context of crowdsourcing because heavily trained workers will expect higher payment, which defeats economical nature of crowdsourcing. Therefore we are forced to face the uncert</context>
</contexts>
<marker>Kaisser, Hearst, Lowe, 2008</marker>
<rawString>M. Kaisser, M. Hearst, and J.B. Lowe. 2008. Evidence for varying search results summary lengths. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kittur</author>
<author>E H Chi</author>
<author>B Suh</author>
</authors>
<title>Crowdsourcing user studies with mechanical turk.</title>
<date>2008</date>
<booktitle>In CHI ’08: Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems,</booktitle>
<pages>453--456</pages>
<contexts>
<context position="2342" citStr="Kittur et al. (2008)" startWordPosition="351" endWordPosition="355">e amount of alignments with good quality is problematic. Labeling word-aligned parallel corpora requires significant amount of labor. In this paper we explore the possibility of using Amazon Mechanical Turk (MTurk) to obtain manual word alignment faster, cheaper, with high quality. Crowdsourcing is a way of getting random labor force on-line with low cost. MTurk is one of the leading providers for crowdsourcing marketplace. There have been several research papers on using MTurk to help natural language processing tasks, Callison-Burch (2009) used MTurk to evaluate machine translation results. Kittur et al. (2008) showed the importance of validation data set, the task is evaluating quality of Wikipedia articles. There are also experiments use the annotation from MTurk in place of training data. For example (Kaisser et al., 2008) and (Kaisser and Lowe, 2008) used MTurk to build question answering datasets and choose summary lengths that suite the need of the users. Word alignment is a relatively complicate task for inexperienced workers. The fact puts us in a dilemma, we can either provide lengthy instructions and train the workers, or we must face the problem that workers may have their own standards. </context>
</contexts>
<marker>Kittur, Chi, Suh, 2008</marker>
<rawString>A. Kittur, E. H. Chi, and B Suh. 2008. Crowdsourcing user studies with mechanical turk. In CHI ’08: Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems, pages 453–456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Liu</author>
<author>Q Liu</author>
<author>S Lin</author>
</authors>
<title>Log-linear models for word alignment.</title>
<date>2005</date>
<booktitle>In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>459--466</pages>
<contexts>
<context position="1679" citStr="Liu et al., 2005" startWordPosition="251" endWordPosition="254">ate. 1 Introduction Word alignment is used in various natural language processing tasks. Most state-of-the-art statistical machine translation systems rely on word alignment as a preprocessing step. The quality of word alignment is usually measured by AER, which is loosely related to BLEU score (Lopez and Resnik, 2006). There has been research on utilizing manually aligned corpus to assist automatic word alignment, and obtains encouraging results on alignment error rate. (Callison-Burch et al., 2004; Blunsom and Cohn, 2006; Fraser and Marcu, 2006; Niehues and Vogel, 2008; Taskar et al., 2005; Liu et al., 2005; Moore, 2005). However, how to obtain large amount of alignments with good quality is problematic. Labeling word-aligned parallel corpora requires significant amount of labor. In this paper we explore the possibility of using Amazon Mechanical Turk (MTurk) to obtain manual word alignment faster, cheaper, with high quality. Crowdsourcing is a way of getting random labor force on-line with low cost. MTurk is one of the leading providers for crowdsourcing marketplace. There have been several research papers on using MTurk to help natural language processing tasks, Callison-Burch (2009) used MTur</context>
</contexts>
<marker>Liu, Liu, Lin, 2005</marker>
<rawString>Y. Liu, Q. Liu, and S. Lin. 2005. Log-linear models for word alignment. In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 459–466.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lopez</author>
<author>P Resnik</author>
</authors>
<title>Word-based alignment, phrasebased translation: What’s the link? with philip resnik.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Biennial Conference of the Association for Machine Translation in the Americas (AMTA-2006).</booktitle>
<contexts>
<context position="1383" citStr="Lopez and Resnik, 2006" startWordPosition="202" endWordPosition="205">emi-supervised word alignment tool to improve the quality of the labels. We also compared two pricing strategies for word alignment task. Experimental results show high precision of the alignments provided by Turkers and the semi-supervised approach achieved 0.5% absolute reduction on alignment error rate. 1 Introduction Word alignment is used in various natural language processing tasks. Most state-of-the-art statistical machine translation systems rely on word alignment as a preprocessing step. The quality of word alignment is usually measured by AER, which is loosely related to BLEU score (Lopez and Resnik, 2006). There has been research on utilizing manually aligned corpus to assist automatic word alignment, and obtains encouraging results on alignment error rate. (Callison-Burch et al., 2004; Blunsom and Cohn, 2006; Fraser and Marcu, 2006; Niehues and Vogel, 2008; Taskar et al., 2005; Liu et al., 2005; Moore, 2005). However, how to obtain large amount of alignments with good quality is problematic. Labeling word-aligned parallel corpora requires significant amount of labor. In this paper we explore the possibility of using Amazon Mechanical Turk (MTurk) to obtain manual word alignment faster, cheape</context>
</contexts>
<marker>Lopez, Resnik, 2006</marker>
<rawString>A. Lopez and P. Resnik. 2006. Word-based alignment, phrasebased translation: What’s the link? with philip resnik. In Proceedings of the 7th Biennial Conference of the Association for Machine Translation in the Americas (AMTA-2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Mason</author>
<author>D J Watts</author>
</authors>
<title>Financial incentives and the “performance of crowds”.</title>
<date>2009</date>
<booktitle>In HCOMP ’09: Proceedings of the ACM SIGKDD Workshop on Human Computation,</booktitle>
<pages>77--85</pages>
<contexts>
<context position="5764" citStr="Mason and Watts (2009)" startWordPosition="926" endWordPosition="929">airs. Notice that one word can be aligned to zero or more words, if a word is aligned to zero word, we can assume it is aligned to a virtual empty word. Therefore, given a sentence pair, we want workers to link words in source sentence to one or more target words or the empty word. In our experiment, we use a Chinese-English parallel corpus and ask workers to alignment the words in Chinese sentence to the words in English sentence. We do not provide any alignment links from automatic aligner. 2.1 Guidelines of design MTurk represents a new pattern of market that has yet be thoroughly studied. Mason and Watts (2009) shows that higher payment does not guarantee results with higher quality. Also, one should be aware that the web-based interface is vulnerable to automatic scripts that generate highly consistent yet meaningless results. To ensure a better result, several measures must be combined: 1) Require workers to take qualifications before they can accept the tasks. 2) Implement an interface less vulnerable to automatic scripts. 3) Build quality control mechanism that filters inaccurate results, and finally 4) Redesign the interface so that the time spent by careful and careless workers does not differ</context>
</contexts>
<marker>Mason, Watts, 2009</marker>
<rawString>W. Mason and D. J. Watts. 2009. Financial incentives and the “performance of crowds”. In HCOMP ’09: Proceedings of the ACM SIGKDD Workshop on Human Computation, pages 77–85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
</authors>
<title>A discriminative framework for bilingual word alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>81--88</pages>
<contexts>
<context position="1693" citStr="Moore, 2005" startWordPosition="255" endWordPosition="256">n Word alignment is used in various natural language processing tasks. Most state-of-the-art statistical machine translation systems rely on word alignment as a preprocessing step. The quality of word alignment is usually measured by AER, which is loosely related to BLEU score (Lopez and Resnik, 2006). There has been research on utilizing manually aligned corpus to assist automatic word alignment, and obtains encouraging results on alignment error rate. (Callison-Burch et al., 2004; Blunsom and Cohn, 2006; Fraser and Marcu, 2006; Niehues and Vogel, 2008; Taskar et al., 2005; Liu et al., 2005; Moore, 2005). However, how to obtain large amount of alignments with good quality is problematic. Labeling word-aligned parallel corpora requires significant amount of labor. In this paper we explore the possibility of using Amazon Mechanical Turk (MTurk) to obtain manual word alignment faster, cheaper, with high quality. Crowdsourcing is a way of getting random labor force on-line with low cost. MTurk is one of the leading providers for crowdsourcing marketplace. There have been several research papers on using MTurk to help natural language processing tasks, Callison-Burch (2009) used MTurk to evaluate </context>
</contexts>
<marker>Moore, 2005</marker>
<rawString>R. C Moore. 2005. A discriminative framework for bilingual word alignment. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Niehues</author>
<author>S Vogel</author>
</authors>
<title>Discriminative word alignment via alignment matrix modeling.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>18--25</pages>
<contexts>
<context position="1640" citStr="Niehues and Vogel, 2008" startWordPosition="243" endWordPosition="246">d 0.5% absolute reduction on alignment error rate. 1 Introduction Word alignment is used in various natural language processing tasks. Most state-of-the-art statistical machine translation systems rely on word alignment as a preprocessing step. The quality of word alignment is usually measured by AER, which is loosely related to BLEU score (Lopez and Resnik, 2006). There has been research on utilizing manually aligned corpus to assist automatic word alignment, and obtains encouraging results on alignment error rate. (Callison-Burch et al., 2004; Blunsom and Cohn, 2006; Fraser and Marcu, 2006; Niehues and Vogel, 2008; Taskar et al., 2005; Liu et al., 2005; Moore, 2005). However, how to obtain large amount of alignments with good quality is problematic. Labeling word-aligned parallel corpora requires significant amount of labor. In this paper we explore the possibility of using Amazon Mechanical Turk (MTurk) to obtain manual word alignment faster, cheaper, with high quality. Crowdsourcing is a way of getting random labor force on-line with low cost. MTurk is one of the leading providers for crowdsourcing marketplace. There have been several research papers on using MTurk to help natural language processing</context>
</contexts>
<marker>Niehues, Vogel, 2008</marker>
<rawString>J. Niehues and S. Vogel. 2008. Discriminative word alignment via alignment matrix modeling. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 18–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<contexts>
<context position="11621" citStr="Och and Ney, 2003" startWordPosition="1938" endWordPosition="1941">l but they have completely different underlying assumptions. Figure 2 shows the comparison of partial alignments (the bold link) and full alignments (the dashed and the bold links). In the example, if full alignment is given, we can assert 2005 is only aligned to 20054H&apos;, not to R�, or A)C, but we cannot do that if only partial alignment is given. In this paper we experiment with a novel method which uses the partial alignment to constraint the EM algorithm in the parameter estimation of IBM models. IBM Models (Brown et. al., 1993) are a series of generative models for word alignment. GIZA++ (Och and Ney, 2003) is the most widely used implementation of IBM models and HMM (Vogel et al., 1996) where EM algorithm is employed to estimate the model parameters. In the E-step, it is possible to obtain sufficient statistics from all possible alignments for simple models such as Model 1 and Model 2. Meanwhile for fertility-based models such as Model 3, 4, 5, enumerating all possible alignments is NP-complete. In practice, we use simpler models such as HMM or Model 2 to generate a “center alignment” and then try to find better alignments among the neighbors of it. The neighbors of an alignment aJ1 = [a1, a2, </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. In Computational Linguistics, volume 1:29, pages 19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Taskar</author>
<author>S Lacoste-Julien</author>
<author>D Klein</author>
</authors>
<title>A discriminative matching approach to word alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>73--80</pages>
<contexts>
<context position="1661" citStr="Taskar et al., 2005" startWordPosition="247" endWordPosition="250"> on alignment error rate. 1 Introduction Word alignment is used in various natural language processing tasks. Most state-of-the-art statistical machine translation systems rely on word alignment as a preprocessing step. The quality of word alignment is usually measured by AER, which is loosely related to BLEU score (Lopez and Resnik, 2006). There has been research on utilizing manually aligned corpus to assist automatic word alignment, and obtains encouraging results on alignment error rate. (Callison-Burch et al., 2004; Blunsom and Cohn, 2006; Fraser and Marcu, 2006; Niehues and Vogel, 2008; Taskar et al., 2005; Liu et al., 2005; Moore, 2005). However, how to obtain large amount of alignments with good quality is problematic. Labeling word-aligned parallel corpora requires significant amount of labor. In this paper we explore the possibility of using Amazon Mechanical Turk (MTurk) to obtain manual word alignment faster, cheaper, with high quality. Crowdsourcing is a way of getting random labor force on-line with low cost. MTurk is one of the leading providers for crowdsourcing marketplace. There have been several research papers on using MTurk to help natural language processing tasks, Callison-Burc</context>
</contexts>
<marker>Taskar, Lacoste-Julien, Klein, 2005</marker>
<rawString>B. Taskar, S. Lacoste-Julien, and D. Klein. 2005. A discriminative matching approach to word alignment. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 73–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>H Ney</author>
<author>C Tillmann</author>
</authors>
<title>HMM based word alignment in statistical machine translation.</title>
<date>1996</date>
<booktitle>In Proceedings of 16th International Conference on Computational Linguistics),</booktitle>
<pages>836--841</pages>
<contexts>
<context position="11703" citStr="Vogel et al., 1996" startWordPosition="1953" endWordPosition="1956">omparison of partial alignments (the bold link) and full alignments (the dashed and the bold links). In the example, if full alignment is given, we can assert 2005 is only aligned to 20054H&apos;, not to R�, or A)C, but we cannot do that if only partial alignment is given. In this paper we experiment with a novel method which uses the partial alignment to constraint the EM algorithm in the parameter estimation of IBM models. IBM Models (Brown et. al., 1993) are a series of generative models for word alignment. GIZA++ (Och and Ney, 2003) is the most widely used implementation of IBM models and HMM (Vogel et al., 1996) where EM algorithm is employed to estimate the model parameters. In the E-step, it is possible to obtain sufficient statistics from all possible alignments for simple models such as Model 1 and Model 2. Meanwhile for fertility-based models such as Model 3, 4, 5, enumerating all possible alignments is NP-complete. In practice, we use simpler models such as HMM or Model 2 to generate a “center alignment” and then try to find better alignments among the neighbors of it. The neighbors of an alignment aJ1 = [a1, a2, · · · , aJ], aj E [0,I] is defined as alignments that can be generated from aJ1 by</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>S. Vogel, H. Ney, and C. Tillmann. 1996. HMM based word alignment in statistical machine translation. In Proceedings of 16th International Conference on Computational Linguistics), pages 836–841.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>