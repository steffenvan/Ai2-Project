<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014736">
<title confidence="0.912812">
Reordering Constraint Based on Document-Level Context
</title>
<author confidence="0.965074">
Takashi Onishi and Masao Utiyama and Eiichiro Sumita
</author>
<affiliation confidence="0.978816">
Multilingual Translation Laboratory, MASTAR Project
National Institute of Information and Communications Technology
</affiliation>
<address confidence="0.570204">
3-5 Hikaridai, Keihanna Science City, Kyoto, JAPAN
</address>
<email confidence="0.999356">
{takashi.onishi,mutiyama,eiichiro.sumita}@nict.go.jp
</email>
<sectionHeader confidence="0.994813" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999625777777778">
One problem with phrase-based statistical ma-
chine translation is the problem of long-
distance reordering when translating between
languages with different word orders, such as
Japanese-English. In this paper, we propose a
method of imposing reordering constraints us-
ing document-level context. As the document-
level context, we use noun phrases which sig-
nificantly occur in context documents contain-
ing source sentences. Given a source sen-
tence, zones which cover the noun phrases are
used as reordering constraints. Then, in de-
coding, reorderings which violate the zones
are restricted. Experiment results for patent
translation tasks show a significant improve-
ment of 1.20% BLEU points in Japanese-
English translation and 1.41% BLEU points in
English-Japanese translation.
</bodyText>
<sectionHeader confidence="0.998785" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999906651162791">
Phrase-based statistical machine translation is use-
ful for translating between languages with similar
word orders. However, it has problems with long-
distance reordering when translating between lan-
guages with different word orders, such as Japanese-
English. These problems are especially crucial when
translating long sentences, such as patent sentences,
because many combinations of word orders cause
high computational costs and low translation qual-
ity.
In order to address these problems, various meth-
ods which use syntactic information have been pro-
posed. These include methods where source sen-
tences are divided into syntactic chunks or clauses
and the translations are merged later (Koehn and
Knight, 2003; Sudoh et al., 2010), methods where
syntactic constraints or penalties for reordering are
added to a decoder (Yamamoto et al., 2008; Cherry,
2008; Marton and Resnik, 2008; Xiong et al., 2010),
and methods where source sentences are reordered
into a similar word order as the target language in
advance (Katz-Brown and Collins, 2008; Isozaki
et al., 2010). However, these methods did not
use document-level context to constrain reorderings.
Document-level context is often available in real-life
situations. We think it is a promising clue to improv-
ing translation quality.
In this paper, we propose a method where re-
ordering constraints are added to a decoder using
document-level context. As the document-level con-
text, we use noun phrases which significantly oc-
cur in context documents containing source sen-
tences. Given a source sentence, zones which cover
the noun phrases are used as reordering constraints.
Then, in decoding, reorderings which violate the
zones are restricted. By using document-level con-
text, contextually-appropriate reordering constraints
are preferentially considered. As a result, the trans-
lation quality and speed can be improved. Ex-
periment results for the NTCIR-8 patent transla-
tion tasks show a significant improvement of 1.20%
BLEU points in Japanese-English translation and
1.41% BLEU points in English-Japanese translation.
</bodyText>
<sectionHeader confidence="0.950217" genericHeader="method">
2 Patent Translation
</sectionHeader>
<bodyText confidence="0.9997352">
Patent translation is difficult because of the amount
of new phrases and long sentences. Since a patent
document explains a newly-invented apparatus or
method, it contains many new phrases. Learning
phrase translations for these new phrases from the
</bodyText>
<page confidence="0.987274">
434
</page>
<note confidence="0.61649">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 434–438,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<equation confidence="0.853528666666667">
Source パッド 電極 1 1 は 、 第 1 の 絶縁 膜 で ある 層間 絶縁 膜 1 2 を 介し て 半導体 基
板 1 0 の 表面 に 形成 さ れ て いる 。
Reference the pad electrode 11 is formed on the top surface of the semiconductor substrate 10 through an
</equation>
<bodyText confidence="0.962893">
interlayer insulation film 12 that is a first insulation film .
Baseline output an interlayer insulating film 12 is formed on the surface of a semiconductor substrate 10 , a
pad electrode 11 via a first insulating film .
</bodyText>
<equation confidence="0.92157">
Source + Zone パッド 電極 1 1 は 、 &lt;zone&gt; 第 1 の &lt;zone&gt; 絶縁 膜 &lt;/zone&gt; で ある 層間 &lt;zone&gt; 絶
縁 膜 &lt;/zone&gt; 1 2 &lt;/zone&gt; を 介し て 半導体 基板 1 0 の 表面 に 形成 さ れ て いる 。
</equation>
<bodyText confidence="0.3960005">
Proposed output pad electrode 11 is formed on the surface of the semiconductor substrate 10 through the inter-
layer insulating film 12 of the first insulating film .
</bodyText>
<tableCaption confidence="0.99912">
Table 1: An example of patent translation.
</tableCaption>
<bodyText confidence="0.999284375">
training corpora is difficult because these phrases
occur only in that patent specification. Therefore,
when translating such phrases, a decoder has to com-
bine multiple smaller phrase translations. More-
over, sentences in patent documents tend to be long.
This results in a large number of combinations of
phrasal reorderings and a degradation of the transla-
tion quality and speed.
Table 1 shows how a failure in phrasal reorder-
ing can spoil the whole translation. In the baseline
output, the translation of “第 1 の 絶縁 膜 で ある
層間 絶縁 膜 1 2” (an interlayer insulation film
12 that is a first insulation film) is divided into two
blocks, “an interlayer insulating film 12” and “a first
insulating film”. In this case, a reordering constraint
to translate “第 1 の 絶縁 膜 で ある 層間 絶縁 膜
1 2” as a single block can reduce incorrect reorder-
ings and improve the translation quality. However,
it is difficult to predict what should be translated as
a single block.
Therefore, how to specify ranges for reordering
constraints is a very important problem. We propose
a solution for this problem that uses the very nature
of patent documents themselves.
</bodyText>
<sectionHeader confidence="0.985053" genericHeader="method">
3 Proposed Method
</sectionHeader>
<bodyText confidence="0.999713454545455">
In order to address the aforementioned problem, we
propose a method for specifying phrases in a source
sentence which are assumed to be translated as sin-
gle blocks using document-level context. We call
these phrases “coherent phrases”. When translat-
ing a document, for example a patent specification,
we first extract coherent phrase candidates from the
document. Then, when translating each sentence in
the document, we set zones which cover the coher-
ent phrase candidates and restrict reorderings which
violate the zones.
</bodyText>
<subsectionHeader confidence="0.9999">
3.1 Coherent phrases in patent documents
</subsectionHeader>
<bodyText confidence="0.99996255">
As mentioned in the previous section, specifying
coherent phrases is difficult when using only one
source sentence. However, we have observed that
document-level context can be a clue for specify-
ing coherent phrases. In a patent specification, for
example, noun phrases which indicate parts of the
invention are very important noun phrases. In pre-
vious example, “第 1 の 絶縁 膜 で ある 層間
縁 膜 1 2” is a part of the invention. Since this
is not language dependent, in other words, this noun
phrase is always a part of the invention in any other
language, this noun phrase should be translated as a
single block in every language. In this way, impor-
tant phrases in patent documents are assumed to be
coherent phrases.
We therefore treat the problem of specifying co-
herent phrases as a problem of specifying important
phrases, and we use these phrases as constraints on
reorderings. The details of the proposed method are
described below.
</bodyText>
<subsectionHeader confidence="0.999979">
3.2 Finding coherent phrases
</subsectionHeader>
<bodyText confidence="0.999911555555556">
We propose the following method for finding co-
herent phrases in patent sentences. First, we ex-
tract coherent phrase candidates from a patent docu-
ment. Next, the candidates are ranked by a criterion
which reflects the document-level context. Then,
we specify coherent phrases using the rankings. In
this method, using document-level context is criti-
cally important because we cannot rank the candi-
dates without it.
</bodyText>
<page confidence="0.996001">
435
</page>
<subsectionHeader confidence="0.911743">
3.2.1 Extracting coherent phrase candidates
</subsectionHeader>
<bodyText confidence="0.999861857142857">
Coherent phrase candidates are extracted from a
context document, a document that contains a source
sentence. We extract all noun phrases as co-
herent phrase candidates since most noun phrases
can be translated as single blocks in other lan-
guages (Koehn and Knight, 2003). These noun
phrases include nested noun phrases.
</bodyText>
<subsectionHeader confidence="0.992172">
3.2.2 Ranking with C-value
</subsectionHeader>
<bodyText confidence="0.9998746">
The candidates which have been extracted are nested
and have different lengths. A naive method can-
not rank these candidates properly. For example,
ranking by frequency cannot pick up an important
phrase which has a long length, yet, ranking by
length may give a long but unimportant phrase a
high rank. In order to select the appropriate coher-
ent phrases, measurements which give high rank to
phrases with high termhood are needed. As one such
measurement, we use C-value (Frantzi and Anani-
adou, 1996).
C-value is a measurement of automatic term
recognition and is suitable for extracting important
phrases from nested candidates. The C-value of a
phrase p is expressed in the following equation:
</bodyText>
<equation confidence="0.993317">
C-value(p)= {
(l(p)−1)n(p) (c(p)=0)
(l(p)−1) (n(p)−C(P)) (c(p)&gt;0)
</equation>
<bodyText confidence="0.9985698">
where
l(p) is the length of a phrase p,
n(p) is the frequency of p in a document,
t(p) is the total frequency of phrases which contain
p as a subphrase,
c(p) is the number of those phrases.
Since phrases which have a large C-value fre-
quently occur in a context document, these phrases
are considered to be a significant unit, i.e., a part of
the invention, and to be coherent phrases.
</bodyText>
<subsectionHeader confidence="0.973847">
3.2.3 Specifying coherent phrases
</subsectionHeader>
<bodyText confidence="0.999989230769231">
Given a source sentence, we find coherent phrase
candidates in the sentence in order to set zones for
reordering constraints. If a coherent phrase candi-
date is found in the source sentence, the phrase is re-
garded a coherent phrase and annotated with a zone
tag, which will be mentioned in the next section.
We check the coherent phrase candidates in the sen-
tence in descending C-value order, and stop when
the C-value goes below a certain threshold. Nested
zones are allowed, unless their zones conflict with
pre-existing zones. We then give the zone-tagged
sentence, an example is shown in Table 1, as a de-
coder input.
</bodyText>
<subsectionHeader confidence="0.999809">
3.3 Decoding with reordering constraints
</subsectionHeader>
<bodyText confidence="0.999786">
In decoding, reorderings which violate zones, such
as the baseline output in Table 1, are restricted and
we get a more appropriate translation, such as the
proposed output in Table 1.
We use the Moses decoder (Koehn et al., 2007;
Koehn and Haddow, 2009), which can specify re-
ordering constraints using &lt;zone&gt; and &lt;/zone&gt; tags.
Moses restricts reorderings which violate zones and
translates zones as single blocks.
</bodyText>
<sectionHeader confidence="0.999742" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999921090909091">
In order to evaluate the performance of the proposed
method, we conducted Japanese-English (J-E) and
English-Japanese (E-J) translation experiments us-
ing the NTCIR-8 patent translation task dataset (Fu-
jii et al., 2010). This dataset contains a training set of
3 million sentence pairs, a development set of 2,000
sentence pairs, and a test set of 1,251 (J-E) and 1,119
(E-J) sentence pairs. Moreover, this dataset contains
the patent specifications from which sentence pairs
are extracted. We used these patent specifications as
context documents.
</bodyText>
<subsectionHeader confidence="0.956982">
4.1 Baseline
</subsectionHeader>
<bodyText confidence="0.9999885">
We used Moses as a baseline system, with all the set-
tings except distortion limit (dl) at the default. The
distortion limit is a maximum distance of reorder-
ing. It is known that an appropriate distortion-limit
can improve translation quality and decoding speed.
Therefore, we examined the effect of a distortion-
limit. In experiments, we compared dl = 6, 10, 20,
30, 40, and −1 (unlimited). The feature weights
were optimized to maximize BLEU score by MERT
(Och, 2003) using the development set.
</bodyText>
<sectionHeader confidence="0.669667" genericHeader="method">
4.2 Compared methods
</sectionHeader>
<bodyText confidence="0.999951">
We compared two methods, the method of specify-
ing reordering constraints with a context document
</bodyText>
<page confidence="0.998853">
436
</page>
<table confidence="0.80097975">
w/o Context in ( this case) , ( the leading end) 15f of ( the segment operating body) ( ( 15 swings) in
( a direction opposite ) ) to ( the a arrow direction ) .
w/ Context in ( this case ) , ( ( the leading end ) 15f ) of ( ( ( the segment ) operating body ) 15 )
swings in a direction opposite to ( the a arrow direction ) .
</table>
<tableCaption confidence="0.992730666666667">
Table 3: An example of the zone-tagged source sentence. &lt;zone&gt; and &lt;/zone&gt; are replaced by “(” and “)”.
Table 2: BLEU score (%) and average decoding time
(sec/sentence) in J-E/E-J translation.
</tableCaption>
<bodyText confidence="0.9992578">
(w/ Context) and the method of specifying reorder-
ing constraints without a context document (w/o
Context). In both methods, the feature weights used
in decoding are the same value as those for the base-
line (dl = −1).
</bodyText>
<subsubsectionHeader confidence="0.946733">
4.2.1 Proposed method (w/ Context)
</subsubsectionHeader>
<bodyText confidence="0.9999054375">
In the proposed method, reordering constraints were
defined with a context document. For J-E transla-
tion, we used the CaboCha parser (Kudo and Mat-
sumoto, 2002) to analyze the context document. As
coherent phrase candidates, we extracted all sub-
trees whose heads are noun. For E-J translation, we
used the Charniak parser (Charniak, 2000) and ex-
tracted all noun phrases, labeled “NP”, as coherent
phrase candidates. The parsers are used only when
extracting coherent phrase candidates. When speci-
fying zones for each source sentence, strings which
match the coherent phrase candidates are defined to
be zones. Therefore, the proposed method is robust
against parsing errors. We tried various thresholds
of the C-value and selected the value that yielded
the highest BLEU score for the development set.
</bodyText>
<subsubsectionHeader confidence="0.898557">
4.2.2 w/o Context
</subsubsectionHeader>
<bodyText confidence="0.999952">
In this method, reordering constraints were defined
without a context document. For J-E translation,
we converted the dependency trees of source sen-
tences processed by the CaboCha parser into brack-
eted trees and used these as reordering constraints.
For E-J translation, we used all of the noun phrases
detected by the Charniak parser as reordering con-
straints.
</bodyText>
<subsectionHeader confidence="0.99087">
4.3 Results and Discussions
</subsectionHeader>
<bodyText confidence="0.999906647058823">
The experiment results are shown in Table 2. For
evaluation, we used the case-insensitive BLEU met-
ric (Papineni et al., 2002) with a single reference.
In both directions, our proposed method yielded
the highest BLEU scores. The absolute improve-
ment over the baseline (dl = −1) was 1.20% in J-E
translation and 1.41% in E-J translation. Accord-
ing to the bootstrap resampling test (Koehn, 2004),
the improvement over the baseline was statistically
significant (p&lt;0.01) in both directions. When com-
pared to the method without context, the absolute
improvement was 1.54% in J-E and 0.25% in E-J.
The improvement over the baseline was statistically
significant (p &lt; 0.01) in J-E and almost significant
(p &lt; 0.1) in E-J. These results show that the pro-
posed method using document-level context is effec-
tive in specifying reordering constraints.
Moreover, as shown in Table 3, although zone
setting without context is failed if source sen-
tences have parsing errors, the proposed method can
set zones appropriately using document-level con-
text. The Charniak parser tends to make errors on
noun phrases with ID numbers. This shows that
document-level context can possibly improve pars-
ing quality.
As for the distortion limit, while an appropriate
distortion-limit, 30 for J-E and 40 for E-J, improved
the translation quality, the gains from the proposed
method were significantly better than the gains from
the distortion limit. In general, imposing strong
constraints causes fast decoding but low translation
quality. However, the proposed method improves
the translation quality and speed by imposing appro-
priate constraints.
</bodyText>
<figure confidence="0.997038866666667">
J--+E
BLEU Time
E--+J
System dl
BLEU Time
6
10
20
30
40
−1
Baseline
35.39 3.5
38.14 4.9
38.39 8.5
38.32 11.5
38.42 13.9
37.80 18.4
27.83 4.8
30.15 6.9
30.65 11.9
30.72 16.0
29.96 19.6
30.35 28.7
w/o Context −1
w/ Context −1
30.01 8.7
31.55 12.0
38.96 5.9
39.21 8.0
</figure>
<page confidence="0.994209">
437
</page>
<sectionHeader confidence="0.997744" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999973">
In this paper, we proposed a method for imposing
reordering constraints using document-level context.
In the proposed method, coherent phrase candidates
are extracted from a context document in advance.
Given a source sentence, zones which cover the co-
herent phrase candidates are defined. Then, in de-
coding, reorderings which violate the zones are re-
stricted. Since reordering constraints reduce incor-
rect reorderings, the translation quality and speed
can be improved. The experiment results for the
NTCIR-8 patent translation tasks show a significant
improvement of 1.20% BLEU points for J-E trans-
lation and 1.41% BLEU points for E-J translation.
We think that the proposed method is indepen-
dent of language pair and domains. In the future,
we want to apply our proposed method to other lan-
guage pairs and domains.
</bodyText>
<sectionHeader confidence="0.997161" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999767792682927">
Eugene Charniak. 2000. A Maximum-Entropy-Inspired
Parser. In Proceedings of the 1st North American
chapter of the Association for Computational Linguis-
tics conference, pages 132–139.
Colin Cherry. 2008. Cohesive Phrase-Based Decoding
for Statistical Machine Translation. In Proceedings of
ACL-08: HLT, pages 72–80.
Katerina T. Frantzi and Sophia Ananiadou. 1996. Ex-
tracting Nested Collocations. In Proceedings of COL-
ING 1996, pages 41–46.
Atsushi Fujii, Masao Utiyama, Mikio Yamamoto, Take-
hito Utsuro, Terumasa Ehara, Hiroshi Echizen-ya, and
Sayori Shimohata. 2010. Overview of the Patent
Translation Task at the NTCIR-8 Workshop. In Pro-
ceedings of NTCIR-8 Workshop Meeting, pages 371–
376.
Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, and
Kevin Duh. 2010. Head Finalization: A Simple Re-
ordering Rule for SOV Languages. In Proceedings of
the Joint Fifth Workshop on Statistical Machine Trans-
lation and MetricsMATR, pages 244–251.
Jason Katz-Brown and Michael Collins. 2008. Syntac-
tic Reordering in Preprocessing for Japanese→English
Translation: MIT System Description for NTCIR-7
Patent Translation Task. In Proceedings of NTCIR-7
Workshop Meeting, pages 409–414.
Philipp Koehn and Barry Haddow. 2009. Edinburgh’s
Submission to all Tracks of the WMT 2009 Shared
Task with Reordering and Speed Improvements to
Moses. In Proceedings of the Fourth Workshop on Sta-
tistical Machine Translation, pages 160–164.
Philipp Koehn and Kevin Knight. 2003. Feature-Rich
Statistical Translation of Noun Phrases. In Proceed-
ings of the 41st Annual Meeting of the Association for
Computational Linguistics, pages 311–318.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Pro-
ceedings of the 45th Annual Meeting of the Associ-
ation for Computational Linguistics Companion Vol-
ume Proceedings of the Demo and Poster Sessions,
pages 177–180.
Philipp Koehn. 2004. Statistical Significance Tests for
Machine Translation Evaluation. In Proceedings of
EMNLP 2004, pages 388–395.
Taku Kudo and Yuji Matsumoto. 2002. Japanese De-
pendency Analysis using Cascaded Chunking. In Pro-
ceedings of CoNLL-2002, pages 63–69.
Yuval Marton and Philip Resnik. 2008. Soft Syntac-
tic Constraints for Hierarchical Phrased-Based Trans-
lation. In Proceedings of ACL-08: HLT, pages 1003–
1011.
Franz Josef Och. 2003. Minimum Error Rate Training in
Statistical Machine Translation. In Proceedings of the
41st Annual Meeting of the Association for Computa-
tional Linguistics, pages 160–167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings of 40th
Annual Meeting of the Association for Computational
Linguistics, pages 311–318.
Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, Tsutomu
Hirao, and Masaaki Nagata. 2010. Divide and Trans-
late: Improving Long Distance Reordering in Statisti-
cal Machine Translation. In Proceedings of the Joint
Fifth Workshop on Statistical Machine Translation and
MetricsMATR, pages 418–427.
Deyi Xiong, Min Zhang, and Haizhou Li. 2010. Learn-
ing Translation Boundaries for Phrase-Based Decod-
ing. In Human Language Technologies: The 2010
Annual Conference of the North American Chapter of
the Association for Computational Linguistics, pages
136–144.
Hirofumi Yamamoto, Hideo Okuma, and Eiichiro
Sumita. 2008. Imposing Constraints from the Source
Tree on ITG Constraints for SMT. In Proceedings
of the ACL-08: HLT Second Workshop on Syntax and
Structure in Statistical Translation (SSST-2), pages 1–
9.
</reference>
<page confidence="0.998262">
438
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.367858">
<title confidence="0.999301">Reordering Constraint Based on Document-Level Context</title>
<author confidence="0.741362">Onishi Utiyama</author>
<affiliation confidence="0.730463">Multilingual Translation Laboratory, MASTAR National Institute of Information and Communications</affiliation>
<address confidence="0.880607">3-5 Hikaridai, Keihanna Science City, Kyoto,</address>
<abstract confidence="0.975306052631579">One problem with phrase-based statistical machine translation is the problem of longdistance reordering when translating between languages with different word orders, such as Japanese-English. In this paper, we propose a method of imposing reordering constraints using document-level context. As the documentlevel context, we use noun phrases which significantly occur in context documents containing source sentences. Given a source sentence, zones which cover the noun phrases are used as reordering constraints. Then, in decoding, reorderings which violate the zones are restricted. Experiment results for patent translation tasks show a significant improvement of 1.20% BLEU points in Japanese- English translation and 1.41% BLEU points in English-Japanese translation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A Maximum-Entropy-Inspired Parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference,</booktitle>
<pages>132--139</pages>
<contexts>
<context position="12477" citStr="Charniak, 2000" startWordPosition="2042" endWordPosition="2043">) in J-E/E-J translation. (w/ Context) and the method of specifying reordering constraints without a context document (w/o Context). In both methods, the feature weights used in decoding are the same value as those for the baseline (dl = −1). 4.2.1 Proposed method (w/ Context) In the proposed method, reordering constraints were defined with a context document. For J-E translation, we used the CaboCha parser (Kudo and Matsumoto, 2002) to analyze the context document. As coherent phrase candidates, we extracted all subtrees whose heads are noun. For E-J translation, we used the Charniak parser (Charniak, 2000) and extracted all noun phrases, labeled “NP”, as coherent phrase candidates. The parsers are used only when extracting coherent phrase candidates. When specifying zones for each source sentence, strings which match the coherent phrase candidates are defined to be zones. Therefore, the proposed method is robust against parsing errors. We tried various thresholds of the C-value and selected the value that yielded the highest BLEU score for the development set. 4.2.2 w/o Context In this method, reordering constraints were defined without a context document. For J-E translation, we converted the </context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A Maximum-Entropy-Inspired Parser. In Proceedings of the 1st North American chapter of the Association for Computational Linguistics conference, pages 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
</authors>
<title>Cohesive Phrase-Based Decoding for Statistical Machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>72--80</pages>
<contexts>
<context position="1979" citStr="Cherry, 2008" startWordPosition="277" endWordPosition="278">neseEnglish. These problems are especially crucial when translating long sentences, such as patent sentences, because many combinations of word orders cause high computational costs and low translation quality. In order to address these problems, various methods which use syntactic information have been proposed. These include methods where source sentences are divided into syntactic chunks or clauses and the translations are merged later (Koehn and Knight, 2003; Sudoh et al., 2010), methods where syntactic constraints or penalties for reordering are added to a decoder (Yamamoto et al., 2008; Cherry, 2008; Marton and Resnik, 2008; Xiong et al., 2010), and methods where source sentences are reordered into a similar word order as the target language in advance (Katz-Brown and Collins, 2008; Isozaki et al., 2010). However, these methods did not use document-level context to constrain reorderings. Document-level context is often available in real-life situations. We think it is a promising clue to improving translation quality. In this paper, we propose a method where reordering constraints are added to a decoder using document-level context. As the document-level context, we use noun phrases whic</context>
</contexts>
<marker>Cherry, 2008</marker>
<rawString>Colin Cherry. 2008. Cohesive Phrase-Based Decoding for Statistical Machine Translation. In Proceedings of ACL-08: HLT, pages 72–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katerina T Frantzi</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Extracting Nested Collocations.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>41--46</pages>
<contexts>
<context position="8420" citStr="Frantzi and Ananiadou, 1996" startWordPosition="1352" endWordPosition="1356">blocks in other languages (Koehn and Knight, 2003). These noun phrases include nested noun phrases. 3.2.2 Ranking with C-value The candidates which have been extracted are nested and have different lengths. A naive method cannot rank these candidates properly. For example, ranking by frequency cannot pick up an important phrase which has a long length, yet, ranking by length may give a long but unimportant phrase a high rank. In order to select the appropriate coherent phrases, measurements which give high rank to phrases with high termhood are needed. As one such measurement, we use C-value (Frantzi and Ananiadou, 1996). C-value is a measurement of automatic term recognition and is suitable for extracting important phrases from nested candidates. The C-value of a phrase p is expressed in the following equation: C-value(p)= { (l(p)−1)n(p) (c(p)=0) (l(p)−1) (n(p)−C(P)) (c(p)&gt;0) where l(p) is the length of a phrase p, n(p) is the frequency of p in a document, t(p) is the total frequency of phrases which contain p as a subphrase, c(p) is the number of those phrases. Since phrases which have a large C-value frequently occur in a context document, these phrases are considered to be a significant unit, i.e., a part</context>
</contexts>
<marker>Frantzi, Ananiadou, 1996</marker>
<rawString>Katerina T. Frantzi and Sophia Ananiadou. 1996. Extracting Nested Collocations. In Proceedings of COLING 1996, pages 41–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujii</author>
</authors>
<title>Masao Utiyama, Mikio Yamamoto, Takehito Utsuro, Terumasa Ehara, Hiroshi Echizen-ya, and Sayori Shimohata.</title>
<date>2010</date>
<booktitle>Overview of the Patent Translation Task at the NTCIR-8 Workshop. In Proceedings of NTCIR-8 Workshop Meeting,</booktitle>
<pages>371--376</pages>
<marker>Fujii, 2010</marker>
<rawString>Atsushi Fujii, Masao Utiyama, Mikio Yamamoto, Takehito Utsuro, Terumasa Ehara, Hiroshi Echizen-ya, and Sayori Shimohata. 2010. Overview of the Patent Translation Task at the NTCIR-8 Workshop. In Proceedings of NTCIR-8 Workshop Meeting, pages 371– 376.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Isozaki</author>
<author>Katsuhito Sudoh</author>
<author>Hajime Tsukada</author>
<author>Kevin Duh</author>
</authors>
<title>Head Finalization: A Simple Reordering Rule for SOV Languages.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</booktitle>
<pages>244--251</pages>
<contexts>
<context position="2188" citStr="Isozaki et al., 2010" startWordPosition="309" endWordPosition="312">n quality. In order to address these problems, various methods which use syntactic information have been proposed. These include methods where source sentences are divided into syntactic chunks or clauses and the translations are merged later (Koehn and Knight, 2003; Sudoh et al., 2010), methods where syntactic constraints or penalties for reordering are added to a decoder (Yamamoto et al., 2008; Cherry, 2008; Marton and Resnik, 2008; Xiong et al., 2010), and methods where source sentences are reordered into a similar word order as the target language in advance (Katz-Brown and Collins, 2008; Isozaki et al., 2010). However, these methods did not use document-level context to constrain reorderings. Document-level context is often available in real-life situations. We think it is a promising clue to improving translation quality. In this paper, we propose a method where reordering constraints are added to a decoder using document-level context. As the document-level context, we use noun phrases which significantly occur in context documents containing source sentences. Given a source sentence, zones which cover the noun phrases are used as reordering constraints. Then, in decoding, reorderings which viol</context>
</contexts>
<marker>Isozaki, Sudoh, Tsukada, Duh, 2010</marker>
<rawString>Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, and Kevin Duh. 2010. Head Finalization: A Simple Reordering Rule for SOV Languages. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 244–251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Katz-Brown</author>
<author>Michael Collins</author>
</authors>
<title>Syntactic Reordering in Preprocessing for Japanese→English Translation: MIT System Description for NTCIR-7 Patent Translation Task.</title>
<date>2008</date>
<booktitle>In Proceedings of NTCIR-7 Workshop Meeting,</booktitle>
<pages>409--414</pages>
<contexts>
<context position="2165" citStr="Katz-Brown and Collins, 2008" startWordPosition="305" endWordPosition="308">ional costs and low translation quality. In order to address these problems, various methods which use syntactic information have been proposed. These include methods where source sentences are divided into syntactic chunks or clauses and the translations are merged later (Koehn and Knight, 2003; Sudoh et al., 2010), methods where syntactic constraints or penalties for reordering are added to a decoder (Yamamoto et al., 2008; Cherry, 2008; Marton and Resnik, 2008; Xiong et al., 2010), and methods where source sentences are reordered into a similar word order as the target language in advance (Katz-Brown and Collins, 2008; Isozaki et al., 2010). However, these methods did not use document-level context to constrain reorderings. Document-level context is often available in real-life situations. We think it is a promising clue to improving translation quality. In this paper, we propose a method where reordering constraints are added to a decoder using document-level context. As the document-level context, we use noun phrases which significantly occur in context documents containing source sentences. Given a source sentence, zones which cover the noun phrases are used as reordering constraints. Then, in decoding,</context>
</contexts>
<marker>Katz-Brown, Collins, 2008</marker>
<rawString>Jason Katz-Brown and Michael Collins. 2008. Syntactic Reordering in Preprocessing for Japanese→English Translation: MIT System Description for NTCIR-7 Patent Translation Task. In Proceedings of NTCIR-7 Workshop Meeting, pages 409–414.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Barry Haddow</author>
</authors>
<title>Edinburgh’s Submission to all Tracks of the WMT</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>160--164</pages>
<contexts>
<context position="10015" citStr="Koehn and Haddow, 2009" startWordPosition="1622" endWordPosition="1625">e next section. We check the coherent phrase candidates in the sentence in descending C-value order, and stop when the C-value goes below a certain threshold. Nested zones are allowed, unless their zones conflict with pre-existing zones. We then give the zone-tagged sentence, an example is shown in Table 1, as a decoder input. 3.3 Decoding with reordering constraints In decoding, reorderings which violate zones, such as the baseline output in Table 1, are restricted and we get a more appropriate translation, such as the proposed output in Table 1. We use the Moses decoder (Koehn et al., 2007; Koehn and Haddow, 2009), which can specify reordering constraints using &lt;zone&gt; and &lt;/zone&gt; tags. Moses restricts reorderings which violate zones and translates zones as single blocks. 4 Experiments In order to evaluate the performance of the proposed method, we conducted Japanese-English (J-E) and English-Japanese (E-J) translation experiments using the NTCIR-8 patent translation task dataset (Fujii et al., 2010). This dataset contains a training set of 3 million sentence pairs, a development set of 2,000 sentence pairs, and a test set of 1,251 (J-E) and 1,119 (E-J) sentence pairs. Moreover, this dataset contains th</context>
</contexts>
<marker>Koehn, Haddow, 2009</marker>
<rawString>Philipp Koehn and Barry Haddow. 2009. Edinburgh’s Submission to all Tracks of the WMT 2009 Shared Task with Reordering and Speed Improvements to Moses. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 160–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Feature-Rich Statistical Translation of Noun Phrases.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="1833" citStr="Koehn and Knight, 2003" startWordPosition="252" endWordPosition="255"> with similar word orders. However, it has problems with longdistance reordering when translating between languages with different word orders, such as JapaneseEnglish. These problems are especially crucial when translating long sentences, such as patent sentences, because many combinations of word orders cause high computational costs and low translation quality. In order to address these problems, various methods which use syntactic information have been proposed. These include methods where source sentences are divided into syntactic chunks or clauses and the translations are merged later (Koehn and Knight, 2003; Sudoh et al., 2010), methods where syntactic constraints or penalties for reordering are added to a decoder (Yamamoto et al., 2008; Cherry, 2008; Marton and Resnik, 2008; Xiong et al., 2010), and methods where source sentences are reordered into a similar word order as the target language in advance (Katz-Brown and Collins, 2008; Isozaki et al., 2010). However, these methods did not use document-level context to constrain reorderings. Document-level context is often available in real-life situations. We think it is a promising clue to improving translation quality. In this paper, we propose </context>
<context position="7842" citStr="Koehn and Knight, 2003" startWordPosition="1258" endWordPosition="1261">phrase candidates from a patent document. Next, the candidates are ranked by a criterion which reflects the document-level context. Then, we specify coherent phrases using the rankings. In this method, using document-level context is critically important because we cannot rank the candidates without it. 435 3.2.1 Extracting coherent phrase candidates Coherent phrase candidates are extracted from a context document, a document that contains a source sentence. We extract all noun phrases as coherent phrase candidates since most noun phrases can be translated as single blocks in other languages (Koehn and Knight, 2003). These noun phrases include nested noun phrases. 3.2.2 Ranking with C-value The candidates which have been extracted are nested and have different lengths. A naive method cannot rank these candidates properly. For example, ranking by frequency cannot pick up an important phrase which has a long length, yet, ranking by length may give a long but unimportant phrase a high rank. In order to select the appropriate coherent phrases, measurements which give high rank to phrases with high termhood are needed. As one such measurement, we use C-value (Frantzi and Ananiadou, 1996). C-value is a measure</context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>Philipp Koehn and Kevin Knight. 2003. Feature-Rich Statistical Translation of Noun Phrases. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<contexts>
<context position="9990" citStr="Koehn et al., 2007" startWordPosition="1618" endWordPosition="1621">l be mentioned in the next section. We check the coherent phrase candidates in the sentence in descending C-value order, and stop when the C-value goes below a certain threshold. Nested zones are allowed, unless their zones conflict with pre-existing zones. We then give the zone-tagged sentence, an example is shown in Table 1, as a decoder input. 3.3 Decoding with reordering constraints In decoding, reorderings which violate zones, such as the baseline output in Table 1, are restricted and we get a more appropriate translation, such as the proposed output in Table 1. We use the Moses decoder (Koehn et al., 2007; Koehn and Haddow, 2009), which can specify reordering constraints using &lt;zone&gt; and &lt;/zone&gt; tags. Moses restricts reorderings which violate zones and translates zones as single blocks. 4 Experiments In order to evaluate the performance of the proposed method, we conducted Japanese-English (J-E) and English-Japanese (E-J) translation experiments using the NTCIR-8 patent translation task dataset (Fujii et al., 2010). This dataset contains a training set of 3 million sentence pairs, a development set of 2,000 sentence pairs, and a test set of 1,251 (J-E) and 1,119 (E-J) sentence pairs. Moreover,</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical Significance Tests for Machine Translation Evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>388--395</pages>
<contexts>
<context position="13741" citStr="Koehn, 2004" startWordPosition="2243" endWordPosition="2244">e CaboCha parser into bracketed trees and used these as reordering constraints. For E-J translation, we used all of the noun phrases detected by the Charniak parser as reordering constraints. 4.3 Results and Discussions The experiment results are shown in Table 2. For evaluation, we used the case-insensitive BLEU metric (Papineni et al., 2002) with a single reference. In both directions, our proposed method yielded the highest BLEU scores. The absolute improvement over the baseline (dl = −1) was 1.20% in J-E translation and 1.41% in E-J translation. According to the bootstrap resampling test (Koehn, 2004), the improvement over the baseline was statistically significant (p&lt;0.01) in both directions. When compared to the method without context, the absolute improvement was 1.54% in J-E and 0.25% in E-J. The improvement over the baseline was statistically significant (p &lt; 0.01) in J-E and almost significant (p &lt; 0.1) in E-J. These results show that the proposed method using document-level context is effective in specifying reordering constraints. Moreover, as shown in Table 3, although zone setting without context is failed if source sentences have parsing errors, the proposed method can set zones</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical Significance Tests for Machine Translation Evaluation. In Proceedings of EMNLP 2004, pages 388–395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Japanese Dependency Analysis using Cascaded Chunking.</title>
<date>2002</date>
<booktitle>In Proceedings of CoNLL-2002,</booktitle>
<pages>63--69</pages>
<contexts>
<context position="12299" citStr="Kudo and Matsumoto, 2002" startWordPosition="2011" endWordPosition="2015"> arrow direction ) . Table 3: An example of the zone-tagged source sentence. &lt;zone&gt; and &lt;/zone&gt; are replaced by “(” and “)”. Table 2: BLEU score (%) and average decoding time (sec/sentence) in J-E/E-J translation. (w/ Context) and the method of specifying reordering constraints without a context document (w/o Context). In both methods, the feature weights used in decoding are the same value as those for the baseline (dl = −1). 4.2.1 Proposed method (w/ Context) In the proposed method, reordering constraints were defined with a context document. For J-E translation, we used the CaboCha parser (Kudo and Matsumoto, 2002) to analyze the context document. As coherent phrase candidates, we extracted all subtrees whose heads are noun. For E-J translation, we used the Charniak parser (Charniak, 2000) and extracted all noun phrases, labeled “NP”, as coherent phrase candidates. The parsers are used only when extracting coherent phrase candidates. When specifying zones for each source sentence, strings which match the coherent phrase candidates are defined to be zones. Therefore, the proposed method is robust against parsing errors. We tried various thresholds of the C-value and selected the value that yielded the hi</context>
</contexts>
<marker>Kudo, Matsumoto, 2002</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2002. Japanese Dependency Analysis using Cascaded Chunking. In Proceedings of CoNLL-2002, pages 63–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Soft Syntactic Constraints for Hierarchical Phrased-Based Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>1003--1011</pages>
<contexts>
<context position="2004" citStr="Marton and Resnik, 2008" startWordPosition="279" endWordPosition="282">hese problems are especially crucial when translating long sentences, such as patent sentences, because many combinations of word orders cause high computational costs and low translation quality. In order to address these problems, various methods which use syntactic information have been proposed. These include methods where source sentences are divided into syntactic chunks or clauses and the translations are merged later (Koehn and Knight, 2003; Sudoh et al., 2010), methods where syntactic constraints or penalties for reordering are added to a decoder (Yamamoto et al., 2008; Cherry, 2008; Marton and Resnik, 2008; Xiong et al., 2010), and methods where source sentences are reordered into a similar word order as the target language in advance (Katz-Brown and Collins, 2008; Isozaki et al., 2010). However, these methods did not use document-level context to constrain reorderings. Document-level context is often available in real-life situations. We think it is a promising clue to improving translation quality. In this paper, we propose a method where reordering constraints are added to a decoder using document-level context. As the document-level context, we use noun phrases which significantly occur in </context>
</contexts>
<marker>Marton, Resnik, 2008</marker>
<rawString>Yuval Marton and Philip Resnik. 2008. Soft Syntactic Constraints for Hierarchical Phrased-Based Translation. In Proceedings of ACL-08: HLT, pages 1003– 1011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="11218" citStr="Och, 2003" startWordPosition="1813" endWordPosition="1814">ains the patent specifications from which sentence pairs are extracted. We used these patent specifications as context documents. 4.1 Baseline We used Moses as a baseline system, with all the settings except distortion limit (dl) at the default. The distortion limit is a maximum distance of reordering. It is known that an appropriate distortion-limit can improve translation quality and decoding speed. Therefore, we examined the effect of a distortionlimit. In experiments, we compared dl = 6, 10, 20, 30, 40, and −1 (unlimited). The feature weights were optimized to maximize BLEU score by MERT (Och, 2003) using the development set. 4.2 Compared methods We compared two methods, the method of specifying reordering constraints with a context document 436 w/o Context in ( this case) , ( the leading end) 15f of ( the segment operating body) ( ( 15 swings) in ( a direction opposite ) ) to ( the a arrow direction ) . w/ Context in ( this case ) , ( ( the leading end ) 15f ) of ( ( ( the segment ) operating body ) 15 ) swings in a direction opposite to ( the a arrow direction ) . Table 3: An example of the zone-tagged source sentence. &lt;zone&gt; and &lt;/zone&gt; are replaced by “(” and “)”. Table 2: BLEU score</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="13474" citStr="Papineni et al., 2002" startWordPosition="2197" endWordPosition="2200">alue and selected the value that yielded the highest BLEU score for the development set. 4.2.2 w/o Context In this method, reordering constraints were defined without a context document. For J-E translation, we converted the dependency trees of source sentences processed by the CaboCha parser into bracketed trees and used these as reordering constraints. For E-J translation, we used all of the noun phrases detected by the Charniak parser as reordering constraints. 4.3 Results and Discussions The experiment results are shown in Table 2. For evaluation, we used the case-insensitive BLEU metric (Papineni et al., 2002) with a single reference. In both directions, our proposed method yielded the highest BLEU scores. The absolute improvement over the baseline (dl = −1) was 1.20% in J-E translation and 1.41% in E-J translation. According to the bootstrap resampling test (Koehn, 2004), the improvement over the baseline was statistically significant (p&lt;0.01) in both directions. When compared to the method without context, the absolute improvement was 1.54% in J-E and 0.25% in E-J. The improvement over the baseline was statistically significant (p &lt; 0.01) in J-E and almost significant (p &lt; 0.1) in E-J. These resu</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a Method for Automatic Evaluation of Machine Translation. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katsuhito Sudoh</author>
<author>Kevin Duh</author>
<author>Hajime Tsukada</author>
<author>Tsutomu Hirao</author>
<author>Masaaki Nagata</author>
</authors>
<title>Divide and Translate: Improving Long Distance Reordering in Statistical Machine Translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</booktitle>
<pages>418--427</pages>
<contexts>
<context position="1854" citStr="Sudoh et al., 2010" startWordPosition="256" endWordPosition="259">s. However, it has problems with longdistance reordering when translating between languages with different word orders, such as JapaneseEnglish. These problems are especially crucial when translating long sentences, such as patent sentences, because many combinations of word orders cause high computational costs and low translation quality. In order to address these problems, various methods which use syntactic information have been proposed. These include methods where source sentences are divided into syntactic chunks or clauses and the translations are merged later (Koehn and Knight, 2003; Sudoh et al., 2010), methods where syntactic constraints or penalties for reordering are added to a decoder (Yamamoto et al., 2008; Cherry, 2008; Marton and Resnik, 2008; Xiong et al., 2010), and methods where source sentences are reordered into a similar word order as the target language in advance (Katz-Brown and Collins, 2008; Isozaki et al., 2010). However, these methods did not use document-level context to constrain reorderings. Document-level context is often available in real-life situations. We think it is a promising clue to improving translation quality. In this paper, we propose a method where reorde</context>
</contexts>
<marker>Sudoh, Duh, Tsukada, Hirao, Nagata, 2010</marker>
<rawString>Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, Tsutomu Hirao, and Masaaki Nagata. 2010. Divide and Translate: Improving Long Distance Reordering in Statistical Machine Translation. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 418–427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Min Zhang</author>
<author>Haizhou Li</author>
</authors>
<title>Learning Translation Boundaries for Phrase-Based Decoding. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>136--144</pages>
<contexts>
<context position="2025" citStr="Xiong et al., 2010" startWordPosition="283" endWordPosition="286">lly crucial when translating long sentences, such as patent sentences, because many combinations of word orders cause high computational costs and low translation quality. In order to address these problems, various methods which use syntactic information have been proposed. These include methods where source sentences are divided into syntactic chunks or clauses and the translations are merged later (Koehn and Knight, 2003; Sudoh et al., 2010), methods where syntactic constraints or penalties for reordering are added to a decoder (Yamamoto et al., 2008; Cherry, 2008; Marton and Resnik, 2008; Xiong et al., 2010), and methods where source sentences are reordered into a similar word order as the target language in advance (Katz-Brown and Collins, 2008; Isozaki et al., 2010). However, these methods did not use document-level context to constrain reorderings. Document-level context is often available in real-life situations. We think it is a promising clue to improving translation quality. In this paper, we propose a method where reordering constraints are added to a decoder using document-level context. As the document-level context, we use noun phrases which significantly occur in context documents con</context>
</contexts>
<marker>Xiong, Zhang, Li, 2010</marker>
<rawString>Deyi Xiong, Min Zhang, and Haizhou Li. 2010. Learning Translation Boundaries for Phrase-Based Decoding. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 136–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hirofumi Yamamoto</author>
<author>Hideo Okuma</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Imposing Constraints from the Source Tree on ITG Constraints for SMT.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST-2),</booktitle>
<pages>1--9</pages>
<contexts>
<context position="1965" citStr="Yamamoto et al., 2008" startWordPosition="273" endWordPosition="276">rd orders, such as JapaneseEnglish. These problems are especially crucial when translating long sentences, such as patent sentences, because many combinations of word orders cause high computational costs and low translation quality. In order to address these problems, various methods which use syntactic information have been proposed. These include methods where source sentences are divided into syntactic chunks or clauses and the translations are merged later (Koehn and Knight, 2003; Sudoh et al., 2010), methods where syntactic constraints or penalties for reordering are added to a decoder (Yamamoto et al., 2008; Cherry, 2008; Marton and Resnik, 2008; Xiong et al., 2010), and methods where source sentences are reordered into a similar word order as the target language in advance (Katz-Brown and Collins, 2008; Isozaki et al., 2010). However, these methods did not use document-level context to constrain reorderings. Document-level context is often available in real-life situations. We think it is a promising clue to improving translation quality. In this paper, we propose a method where reordering constraints are added to a decoder using document-level context. As the document-level context, we use nou</context>
</contexts>
<marker>Yamamoto, Okuma, Sumita, 2008</marker>
<rawString>Hirofumi Yamamoto, Hideo Okuma, and Eiichiro Sumita. 2008. Imposing Constraints from the Source Tree on ITG Constraints for SMT. In Proceedings of the ACL-08: HLT Second Workshop on Syntax and Structure in Statistical Translation (SSST-2), pages 1– 9.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>