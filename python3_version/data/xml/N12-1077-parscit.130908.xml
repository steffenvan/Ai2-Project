<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.112965">
<title confidence="0.98713">
Measuring Word Relatedness Using Heterogeneous Vector Space Models
</title>
<author confidence="0.965715">
Wen-tau Yih
</author>
<affiliation confidence="0.936149">
Microsoft Research
</affiliation>
<address confidence="0.936695">
One Microsoft Way
Redmond, WA
</address>
<email confidence="0.998532">
scottyih@microsoft.com
</email>
<author confidence="0.923798">
Vahed Qazvinian*
</author>
<affiliation confidence="0.9902475">
Department of EECS
University of Michigan
</affiliation>
<address confidence="0.951465">
Ann Arbor, MI
</address>
<email confidence="0.999343">
vahed@umich.edu
</email>
<sectionHeader confidence="0.99565" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999738">
Noticing that different information sources of-
ten provide complementary coverage of word
sense and meaning, we propose a simple and
yet effective strategy for measuring lexical se-
mantics. Our model consists of a committee
of vector space models built on a text cor-
pus, Web search results and thesauruses, and
measures the semantic word relatedness us-
ing the averaged cosine similarity scores. De-
spite its simplicity, our system correlates with
human judgements better or similarly com-
pared to existing methods on several bench-
mark datasets, including WordSim353.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999822588235294">
Measuring the semantic relatedness of words is a
fundamental problem in natural language process-
ing and has many useful applications, including
textual entailment, word sense disambiguation, in-
formation retrieval and automatic thesaurus discov-
ery. Existing approaches can be roughly catego-
rized into two kinds: knowledge-based and corpus-
based, where the former includes graph-based algo-
rithms and similarity measures operating on a lexical
database such as WordNet (Budanitsky and Hirst,
2006; Agirre et al., 2009) and the latter consists
of various kinds of vector space models (VSMs)
constructed with the help of a large collection of
text (Reisinger and Mooney, 2010; Radinsky et al.,
2011). In this paper, we present a conceptually
simple model for solving this problem. Observing
that various kinds of information sources, such as
</bodyText>
<note confidence="0.520451">
* Work conducted while interning at Microsoft Research.
</note>
<bodyText confidence="0.999866">
general text corpora, Web search results and the-
sauruses, have different word and sense coverage,
we first build individual vector space models from
each of them separately. Given two words, each
VSM measures the semantic relatedness by the co-
sine similarity of the corresponding vectors in its
space. The final prediction is simply the averaged
cosine scores derived from these VSMs. Despite
its simplicity, our system surprisingly yields very
strong empirical performance. When comparing the
predictions with the human annotations on four dif-
ferent datasets, our system achieves higher correla-
tion than existing methods on two datasets and pro-
vides very competitive results on the others.
The rest of this paper is organized as follows. Sec-
tion 2 briefly reviews the related work. Section 3 de-
tails how we construct each individual vector space
model, followed by the experimental evaluation in
Section 4. Finally, Section 5 concludes the paper.
</bodyText>
<sectionHeader confidence="0.976107" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999836076923077">
Prior work on measuring lexical semantics can be
categorized as knowledge-based or corpus-based.
Knowledge-based methods leverage word relations
encoded in lexical databases such as WordNet and
provide graph-based similarity measures. Detailed
comparisons of these methods can be found in (Bu-
danitsky and Hirst, 2006). Corpus-based methods
assume related words tend to co-occur or to ap-
pear in similar context. For example, Gabrilovich
and Markovitch (2007) measure word relatedness by
whether they tend to occur in the same Wikipedia
topic. In contrast, Reisinger and Mooney (2010)
use the conventional “context vector” – neighboring
</bodyText>
<page confidence="0.906914666666667">
616
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 616–620,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</page>
<bodyText confidence="0.999893294117647">
terms of the occurrences of a target word – as the
word representation. In addition, they argue that it
is difficult to capture different senses of a word with
a single vector, and introduce a multi-prototype rep-
resentation. More recently, Radinsky et al. (2011)
analyze the temporal aspects of words and argue that
non-identical terms in two term vectors should also
be compared based on their temporal usage when
computing the similarity score. They construct the
vectors using Wikipedia titles, Flickr image tags,
and Del.icio.us bookmarks, and extract the temporal
frequency of each concept from 130 years of New
York Times archive. Methods that combine models
from different sources do exist. For instance, Agirre
et al. (2009) derive a WordNet-based measure us-
ing PageRank and combined it with several corpus-
based vector space models using SVMs.
</bodyText>
<sectionHeader confidence="0.994443" genericHeader="method">
3 Vector Space Models from
</sectionHeader>
<subsectionHeader confidence="0.519726">
Heterogeneous Sources
</subsectionHeader>
<bodyText confidence="0.999988871428572">
In this section, we describe how we construct vari-
ous vector space models (VSMs) to represent words,
including corpus-based, Web-based and thesaurus-
based methods.
Corpus-based VSMs follow the standard “distri-
butional hypothesis,” which states that words ap-
pearing in the same contexts tend to have simi-
lar meaning (Harris, 1954). Each target word is
thus represented by a high-dimensional sparse term-
vector that consists of words occurring in its con-
text. Given a corpus, we first collect terms within
a window of [−10,+10] centered at each occur-
rence of a target word. This bag-of-words repre-
sentation is then mapped to the TF-IDF term vector:
each term is weighted by log(freq) x log(N/df),
where freq is the number of times the term appears
in the collection, df the document frequency of the
term in the whole corpus and N the number of total
documents. We further employed two simple tech-
niques to improve the quality of these term-vectors:
vocabulary and term trimming. Top 1,500 terms
with high document frequency values are treated
as stopwords and removed from the vocabulary.
Moreover, we adopted a document-specific feature
selection method (Kolcz and Yih, 2007) designed
originally for text classification and retain only the
top 200 high-weighted terms for each term-vector1.
The corpus-based VSMs are created using English
Wikipedia (Snapshot of Nov. 2010), consisting of
917M words after preprocessing (markup tags re-
moval and sentence splitting).
Web-based VSMs leverage Web search results to
form a vector of each query (Sahami and Heilman,
2006). For each word to compare, we issue it as a
query and retrieve the set of relevant snippets (top
30 in our experiments) using a popular commercial
search engine, Bing. All these snippets together are
viewed as a pseudo-document and mapped to a TF-
IDF vector as in the corpus-based method. We do
not allow for automatic query expansion in our ex-
periments to ensure that the retrieved snippets are di-
rectly relevant to the target word and not expansions
based on synonyms, hypernyms or hyponyms. We
apply vocabulary trimming (top 1,000 terms with
high DF values), but not term-trimming as the vec-
tors have much fewer terms due to the small number
of snippets collected.
Both the corpus-based and Web-based VSMs rely
on the distributional hypothesis, which is often criti-
cized for two weaknesses. The first is that word pairs
that appear in the same context or co-occur are not
necessarily highly semantically related. For exam-
ple, “bread” and “butter” often have cosine scores
higher than synonyms using corpus-based vectors
because of the phrase “bread and butter”. The sec-
ond is that general corpora often have skewed cov-
erage of words due to the Zipf’s law. Regardless of
the size of the corpus, the number of occurrences
of a rarely used word is typically very low, which
makes the quality of the corresponding vector unre-
liable. To address these two issues, we include the
thesaurus-based VSMs in this work as well. For
each group of similar words (synset) defined in the
thesaurus, we treat it as a “document” and create a
document–word matrix, where each word is again
weighted using its TF-IDF value. Each column vec-
tor in this matrix is thus the thesaurus-based vec-
tor of the corresponding word. Notice that given
two words and their corresponding vectors, the co-
sine score is more general than simply checking
</bodyText>
<footnote confidence="0.99918575">
1In preliminary experiments, we found that active terms
with low TF-IDF values tend to be noise. By aggressively
removing them, the quality of the term-vectors can be signifi-
cantly improved.
</footnote>
<page confidence="0.99231">
617
</page>
<bodyText confidence="0.999987230769231">
whether these two words belong to a group of sim-
ilar words, as it judges how often they overlap in
various documents (i.e., sets of similar words). We
explored using two different thesauri in our exper-
iments: WordNet and the Encarta thesaurus devel-
oped by Bloomsbury Publishing, where the former
consists of 227,446 synsets and 190,052 words and
the latter contains 46,945 synsets and 50,184 words.
Compared to existing knowledge-based approaches,
our VSM transformation is very simple and straight-
forward. It is also easy to extend our method to other
languages as only a thesaurus is required rather than
a complete lexical database such as WordNet.
</bodyText>
<sectionHeader confidence="0.999167" genericHeader="method">
4 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.99897925">
In this section, we evaluate the quality of the VSMs
constructed using methods described in Section 3 on
different benchmark datasets, as well as the perfor-
mance when combining them.
</bodyText>
<subsectionHeader confidence="0.997278">
4.1 Benchmark datasets
</subsectionHeader>
<bodyText confidence="0.999936088235294">
We follow the standard evaluation method, which di-
rectly tests the correlation of the word relatedness
measures with human judgements on a set of word
pairs, using the Spearman’s rank correlation coeffi-
cient. Our study was conducted using four differ-
ent datasets, including WS-353, RG-65, MC-30 and
MTurk-287.
The WordSim353 dataset (WS-353) is the largest
among them and has been used extensively in re-
cent work. Originally collected by Finkelstein et
al. (2001), the dataset consists of 353 word pairs.
The degree of relatedness of each pair is assessed
on a 0-10 scale by 13-16 human judges, where the
mean is used as the final score. Examining the
relations between the words in each pair, Agirre
et al. (2009) further split this dataset into similar
pairs (WS-sim) and related pairs (WS-rel), where
the former contains synonyms, antonyms, identical
words and hyponyms/hypernyms and the latter cap-
ture other word relations. Collected by Rubenstein
and Goodenough (1965), RG-65 contains 65 pairs
of words that are either synonyms or unrelated, as-
sessed on a 0-4 scale by 51 human subjects. Taking
30 pairs from them, Miller and Charles (1991) cre-
ated the (MC-30) dataset by reassessing these word
pairs using 38 subjects. These 30 pairs of words
are also a subset of WS-353. Although these three
datasets contain overlapping word pairs, their scores
are different because of the degree of relatedness
were given by different human subjects. In addition
to these datasets, we also evaluate our VSMs on the
Mturk-287 dataset that consists of 287 word pairs
collected by (Radinsky et al., 2011) using Amazon
MTurk.
</bodyText>
<subsectionHeader confidence="0.862932">
4.2 Results and Analysis
</subsectionHeader>
<bodyText confidence="0.999882470588235">
Table 1 summarizes the results of various methods,
where the top part lists the performance of state-of-
the-art systems and the bottom shows the results of
individual vector space models, as well as combin-
ing these models using the averaged cosine scores.
We make several observations here. First, while
none of the four VSMs we tested outperforms the
best existing systems on the benchmark datasets,
surprisingly, using the averaged cosine scores of
these models, the performance is improved substan-
tially. It achieves higher Spearman’s rank coeffi-
cient on WS-353 and MTurk-287 than any other sys-
tems2 and are close to the state-of-the-art on MC-
30 and RG-65. Unlike some approach like (Hughes
and Ramage, 2007), which performs well on some
datasets but poorly on others, combing the VSMs
from heterogeneous sources is more robust. Individ-
ually, we notice that Wikipedia context VSM pro-
vides consistently strong results, while thesaurus-
based models work only reasonable on MC-30 and
RG-65, potentially because other datasets contain
more out-of-vocabulary words or proper nouns. Due
to the inherent ambiguity of the task, there is a high
variance among judgements from different annota-
tors. Therefore, it is unrealistic to assume any of the
methods can correlate perfectly to the mean human
judgement scores. In fact, the inter-agreement study
done on the WS-353 dataset indicates that the result
of our approach of combining heterogeneous VSMs
is close to the averaged human performance.
It is intriguing to see that by using the averaged
cosine scores, the performance can be improved
over the best individual model (i.e., Wikipedia). Ex-
amining the scores of some word pairs carefully sug-
</bodyText>
<footnote confidence="0.9876325">
2This may not be statistically significant. Without having
the exact output of existing systems, it is difficult to conduct a
robust statistical significance test given the small sizes of these
datasets.
</footnote>
<page confidence="0.978556">
618
</page>
<table confidence="0.999596333333333">
Method WS-353 WS-sim Spearman’s p RG-65 MTurk-287
WS-rel MC-30
(Radinsky et al., 2011) 0.80 - - - - 0.63
(Reisinger and Mooney, 2010) 0.77 - - - - -
(Agirre et al., 2009) 0.78 0.83 0.72 0.92 0.96 -
(Gabrilovich and Markovitch, 2007) 0.75 - - - - 0.59
(Hughes and Ramage, 2007) 0.55 - - 0.90 0.84 -
Web Search 0.56 0.56 0.54 0.48 0.44 0.44
Wikipedia 0.73 0.80 0.73 0.87 0.83 0.62
Bloomsbury 0.45 0.60 0.60 0.71 0.78 0.29
WordNet 0.37 0.49 0.49 0.79 0.78 0.25
Combining VSMs 0.81 0.87 0.77 0.89 0.89 0.68
</table>
<tableCaption confidence="0.9970695">
Table 1: The performance of the state-of-the-art methods and different vector space models on measuring semantic
word relatedness using the cosine similarity.
</tableCaption>
<bodyText confidence="0.99997764">
gests the broader coverage of different words and
senses could be the reason. For example, some
of the words in the datasets have multiple senses,
such as “jaguar vs. car” and “jaguar vs. cat”. Al-
though in previous work, researchers try to capture
word senses using different vectors (Reisinger and
Mooney, 2010) from the same text corpus, this is in
fact difficult in practice. The usage of words in a big
text corpus, which contains diversified topics, may
still be biased to one word sense. For example, in
the Wikipeida term vector that represents “jaguar”,
we found that most of the terms there are related to
“cat”. Although some terms are associated with the
“car” meaning, the signals are rather weak. Simi-
larly, WordNet does not indicate “jaguar” could be
related to “car” at all. In contrast, the “car” sense
of “jaguar” dominates the vector created using the
search engine. As a result, incorporating models
from different sources could be more effective than
relying on word sense discovering algorithms op-
erating solely on one corpus. Another similar but
different example is the pair of “bread” and “but-
ter”, which are treated as synonyms by corpus-based
VSMs, but is demoted after adding the thesaurus-
based models.
</bodyText>
<sectionHeader confidence="0.999265" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999532434782609">
In this paper we investigated the usefulness of het-
erogeneous information sources in improving mea-
sures of semantic word relatedness. Particularly, we
created vector space models using 4 data sources
from 3 categories (corpus-based, Web-based and
thesaurus-based) and found that simply averaging
the cosine similarity derived from these models
yields a very robust measure. Other than directly ap-
plying it to measuring semantic relatedness, our ap-
proach is complementary to more sophisticated sim-
ilarity measures such as developing kernel functions
for different structured data (Croce et al., 2011),
where the similarity between words serves as a basic
component.
While this result is interesting and encouraging, it
also raises several research questions, such as how
to enhance the quality of each vector space model
and whether the models can be combined more ef-
fectively3. We also would like to study whether sim-
ilar techniques can be useful when comparing longer
text segments like phrases or sentences, with poten-
tial applications in paraphrase detection and recog-
nizing textual entailment.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.976547727272727">
We thank Joseph Reisinger for providing his pro-
totype vectors for our initial study, Silviu-Petru
Cucerzan for helping process the Wikipedia files and
Geoffrey Zweig for preparing the Bloomsbury the-
saurus data. We are also grateful to Chris Meek
for valuable discussions and to anonymous review-
ers for their comments.
3We conducted some preliminary experiments (not reported
here) on tuning the weights of combining different models
based on cross-validation, but did not find consistent improve-
ments, perhaps due to the limited size of the data.
</bodyText>
<page confidence="0.998683">
619
</page>
<sectionHeader confidence="0.995885" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999726619047619">
E. Agirre, E. Alfonseca, K. Hall, J. Kravalova, M. Pas¸ca
and A. Soroa. 2009. A study on similarity and re-
latedness using distributional and wordnet-based ap-
proaches. In NAACL ’09, pages 19–27.
A. Budanitsky and G. Hirst. 2006. Evaluating wordnet-
based measures of lexical semantic relatedness. Com-
putational Linguistics, 32:13–47, March.
D. Croce, A. Moschitti, and R. Basili. 2011. Structured
lexical similarity via convolution kernels on depen-
dency trees. In Proceedings of EMNLP 2011, pages
1034–1046, July.
L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin,
Z. Solan, G. Wolfman, and E. Ruppin. 2001. Placing
search in context: The concept revisited. In WWW,
pages 406–414. ACM.
E. Gabrilovich and S. Markovitch. 2007. Computing se-
mantic relatedness using wikipedia-based explicit se-
mantic analysis. In IJCAI ’07, pages 1606–1611.
Z. Harris. 1954. Distributional structure. Word,
10(23):146–162.
T. Hughes and D. Ramage. 2007. Lexical semantic re-
latedness with random graph walks. In Proceedings of
EMNLP-CoNLL-2007, pages 581–589.
A. Kolcz and W. Yih. 2007. Raising the baseline for
high-precision text classifiers. In KDD ’07, pages
400–409.
G. Miller and W. Charles. 1991. Contextual correlates
of semantic similarity. Language and cognitive pro-
cesses, 6(1):1–28.
K. Radinsky, E. Agichtein, E. Gabrilovich, and
S. Markovitch. 2011. A word at a time: computing
word relatedness using temporal semantic analysis. In
WWW ’11, pages 337–346.
J. Reisinger and R. Mooney. 2010. Multi-prototype
vector-space models of word meaning. In NAACL ’10.
H. Rubenstein and J. Goodenough. 1965. Contextual
correlates of synonymy. Communications of the ACM,
8:627–633, October.
M. Sahami and T. Heilman. 2006. A web-based ker-
nel function for measuring the similarity of short text
snippets. In Proceedings of the 15th international con-
ference on World Wide Web, pages 377–386. ACM.
</reference>
<page confidence="0.99758">
620
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.117218">
<title confidence="0.998956">Measuring Word Relatedness Using Heterogeneous Vector Space Models</title>
<author confidence="0.776809">Wen-tau</author>
<affiliation confidence="0.784102">Microsoft</affiliation>
<address confidence="0.6735965">One Microsoft Redmond,</address>
<email confidence="0.999923">scottyih@microsoft.com</email>
<affiliation confidence="0.990552">Department of University of</affiliation>
<author confidence="0.635315">Ann Arbor</author>
<email confidence="0.999375">vahed@umich.edu</email>
<abstract confidence="0.941560928571429">Noticing that different information sources often provide complementary coverage of word sense and meaning, we propose a simple and yet effective strategy for measuring lexical semantics. Our model consists of a committee of vector space models built on a text corpus, Web search results and thesauruses, and measures the semantic word relatedness using the averaged cosine similarity scores. Despite its simplicity, our system correlates with human judgements better or similarly compared to existing methods on several benchmark datasets, including WordSim353.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>E Alfonseca</author>
<author>K Hall</author>
<author>J Kravalova</author>
<author>M Pas¸ca</author>
<author>A Soroa</author>
</authors>
<title>A study on similarity and relatedness using distributional and wordnet-based approaches.</title>
<date>2009</date>
<booktitle>In NAACL ’09,</booktitle>
<pages>pages</pages>
<marker>Agirre, Alfonseca, Hall, Kravalova, Pas¸ca, Soroa, 2009</marker>
<rawString>E. Agirre, E. Alfonseca, K. Hall, J. Kravalova, M. Pas¸ca and A. Soroa. 2009. A study on similarity and relatedness using distributional and wordnet-based approaches. In NAACL ’09, pages 19–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Budanitsky</author>
<author>G Hirst</author>
</authors>
<title>Evaluating wordnetbased measures of lexical semantic relatedness.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<pages>32--13</pages>
<contexts>
<context position="1319" citStr="Budanitsky and Hirst, 2006" startWordPosition="186" endWordPosition="189">human judgements better or similarly compared to existing methods on several benchmark datasets, including WordSim353. 1 Introduction Measuring the semantic relatedness of words is a fundamental problem in natural language processing and has many useful applications, including textual entailment, word sense disambiguation, information retrieval and automatic thesaurus discovery. Existing approaches can be roughly categorized into two kinds: knowledge-based and corpusbased, where the former includes graph-based algorithms and similarity measures operating on a lexical database such as WordNet (Budanitsky and Hirst, 2006; Agirre et al., 2009) and the latter consists of various kinds of vector space models (VSMs) constructed with the help of a large collection of text (Reisinger and Mooney, 2010; Radinsky et al., 2011). In this paper, we present a conceptually simple model for solving this problem. Observing that various kinds of information sources, such as * Work conducted while interning at Microsoft Research. general text corpora, Web search results and thesauruses, have different word and sense coverage, we first build individual vector space models from each of them separately. Given two words, each VSM </context>
<context position="2997" citStr="Budanitsky and Hirst, 2006" startWordPosition="444" endWordPosition="448">very competitive results on the others. The rest of this paper is organized as follows. Section 2 briefly reviews the related work. Section 3 details how we construct each individual vector space model, followed by the experimental evaluation in Section 4. Finally, Section 5 concludes the paper. 2 Background Prior work on measuring lexical semantics can be categorized as knowledge-based or corpus-based. Knowledge-based methods leverage word relations encoded in lexical databases such as WordNet and provide graph-based similarity measures. Detailed comparisons of these methods can be found in (Budanitsky and Hirst, 2006). Corpus-based methods assume related words tend to co-occur or to appear in similar context. For example, Gabrilovich and Markovitch (2007) measure word relatedness by whether they tend to occur in the same Wikipedia topic. In contrast, Reisinger and Mooney (2010) use the conventional “context vector” – neighboring 616 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 616–620, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics terms of the occurrences of a target word – as the wor</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>A. Budanitsky and G. Hirst. 2006. Evaluating wordnetbased measures of lexical semantic relatedness. Computational Linguistics, 32:13–47, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Croce</author>
<author>A Moschitti</author>
<author>R Basili</author>
</authors>
<title>Structured lexical similarity via convolution kernels on dependency trees.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP 2011,</booktitle>
<pages>1034--1046</pages>
<contexts>
<context position="14945" citStr="Croce et al., 2011" startWordPosition="2377" endWordPosition="2380">odels. 5 Conclusion In this paper we investigated the usefulness of heterogeneous information sources in improving measures of semantic word relatedness. Particularly, we created vector space models using 4 data sources from 3 categories (corpus-based, Web-based and thesaurus-based) and found that simply averaging the cosine similarity derived from these models yields a very robust measure. Other than directly applying it to measuring semantic relatedness, our approach is complementary to more sophisticated similarity measures such as developing kernel functions for different structured data (Croce et al., 2011), where the similarity between words serves as a basic component. While this result is interesting and encouraging, it also raises several research questions, such as how to enhance the quality of each vector space model and whether the models can be combined more effectively3. We also would like to study whether similar techniques can be useful when comparing longer text segments like phrases or sentences, with potential applications in paraphrase detection and recognizing textual entailment. Acknowledgments We thank Joseph Reisinger for providing his prototype vectors for our initial study, </context>
</contexts>
<marker>Croce, Moschitti, Basili, 2011</marker>
<rawString>D. Croce, A. Moschitti, and R. Basili. 2011. Structured lexical similarity via convolution kernels on dependency trees. In Proceedings of EMNLP 2011, pages 1034–1046, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Finkelstein</author>
<author>E Gabrilovich</author>
<author>Y Matias</author>
<author>E Rivlin</author>
<author>Z Solan</author>
<author>G Wolfman</author>
<author>E Ruppin</author>
</authors>
<title>Placing search in context: The concept revisited.</title>
<date>2001</date>
<booktitle>In WWW,</booktitle>
<pages>406--414</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9367" citStr="Finkelstein et al. (2001)" startWordPosition="1469" endWordPosition="1472">the VSMs constructed using methods described in Section 3 on different benchmark datasets, as well as the performance when combining them. 4.1 Benchmark datasets We follow the standard evaluation method, which directly tests the correlation of the word relatedness measures with human judgements on a set of word pairs, using the Spearman’s rank correlation coefficient. Our study was conducted using four different datasets, including WS-353, RG-65, MC-30 and MTurk-287. The WordSim353 dataset (WS-353) is the largest among them and has been used extensively in recent work. Originally collected by Finkelstein et al. (2001), the dataset consists of 353 word pairs. The degree of relatedness of each pair is assessed on a 0-10 scale by 13-16 human judges, where the mean is used as the final score. Examining the relations between the words in each pair, Agirre et al. (2009) further split this dataset into similar pairs (WS-sim) and related pairs (WS-rel), where the former contains synonyms, antonyms, identical words and hyponyms/hypernyms and the latter capture other word relations. Collected by Rubenstein and Goodenough (1965), RG-65 contains 65 pairs of words that are either synonyms or unrelated, assessed on a 0-</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2001</marker>
<rawString>L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan, G. Wolfman, and E. Ruppin. 2001. Placing search in context: The concept revisited. In WWW, pages 406–414. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>Computing semantic relatedness using wikipedia-based explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In IJCAI ’07,</booktitle>
<pages>1606--1611</pages>
<contexts>
<context position="3137" citStr="Gabrilovich and Markovitch (2007)" startWordPosition="466" endWordPosition="469">ction 3 details how we construct each individual vector space model, followed by the experimental evaluation in Section 4. Finally, Section 5 concludes the paper. 2 Background Prior work on measuring lexical semantics can be categorized as knowledge-based or corpus-based. Knowledge-based methods leverage word relations encoded in lexical databases such as WordNet and provide graph-based similarity measures. Detailed comparisons of these methods can be found in (Budanitsky and Hirst, 2006). Corpus-based methods assume related words tend to co-occur or to appear in similar context. For example, Gabrilovich and Markovitch (2007) measure word relatedness by whether they tend to occur in the same Wikipedia topic. In contrast, Reisinger and Mooney (2010) use the conventional “context vector” – neighboring 616 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 616–620, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics terms of the occurrences of a target word – as the word representation. In addition, they argue that it is difficult to capture different senses of a word with a single vector, and introduce a m</context>
<context position="12673" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="2007" endWordPosition="2010">triguing to see that by using the averaged cosine scores, the performance can be improved over the best individual model (i.e., Wikipedia). Examining the scores of some word pairs carefully sug2This may not be statistically significant. Without having the exact output of existing systems, it is difficult to conduct a robust statistical significance test given the small sizes of these datasets. 618 Method WS-353 WS-sim Spearman’s p RG-65 MTurk-287 WS-rel MC-30 (Radinsky et al., 2011) 0.80 - - - - 0.63 (Reisinger and Mooney, 2010) 0.77 - - - - - (Agirre et al., 2009) 0.78 0.83 0.72 0.92 0.96 - (Gabrilovich and Markovitch, 2007) 0.75 - - - - 0.59 (Hughes and Ramage, 2007) 0.55 - - 0.90 0.84 - Web Search 0.56 0.56 0.54 0.48 0.44 0.44 Wikipedia 0.73 0.80 0.73 0.87 0.83 0.62 Bloomsbury 0.45 0.60 0.60 0.71 0.78 0.29 WordNet 0.37 0.49 0.49 0.79 0.78 0.25 Combining VSMs 0.81 0.87 0.77 0.89 0.89 0.68 Table 1: The performance of the state-of-the-art methods and different vector space models on measuring semantic word relatedness using the cosine similarity. gests the broader coverage of different words and senses could be the reason. For example, some of the words in the datasets have multiple senses, such as “jaguar vs. car</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>E. Gabrilovich and S. Markovitch. 2007. Computing semantic relatedness using wikipedia-based explicit semantic analysis. In IJCAI ’07, pages 1606–1611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Harris</author>
</authors>
<date>1954</date>
<journal>Distributional structure. Word,</journal>
<volume>10</volume>
<issue>23</issue>
<contexts>
<context position="4772" citStr="Harris, 1954" startWordPosition="717" endWordPosition="718"> York Times archive. Methods that combine models from different sources do exist. For instance, Agirre et al. (2009) derive a WordNet-based measure using PageRank and combined it with several corpusbased vector space models using SVMs. 3 Vector Space Models from Heterogeneous Sources In this section, we describe how we construct various vector space models (VSMs) to represent words, including corpus-based, Web-based and thesaurusbased methods. Corpus-based VSMs follow the standard “distributional hypothesis,” which states that words appearing in the same contexts tend to have similar meaning (Harris, 1954). Each target word is thus represented by a high-dimensional sparse termvector that consists of words occurring in its context. Given a corpus, we first collect terms within a window of [−10,+10] centered at each occurrence of a target word. This bag-of-words representation is then mapped to the TF-IDF term vector: each term is weighted by log(freq) x log(N/df), where freq is the number of times the term appears in the collection, df the document frequency of the term in the whole corpus and N the number of total documents. We further employed two simple techniques to improve the quality of th</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Z. Harris. 1954. Distributional structure. Word, 10(23):146–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hughes</author>
<author>D Ramage</author>
</authors>
<title>Lexical semantic relatedness with random graph walks.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL-2007,</booktitle>
<pages>581--589</pages>
<contexts>
<context position="11254" citStr="Hughes and Ramage, 2007" startWordPosition="1778" endWordPosition="1781">mance of state-ofthe-art systems and the bottom shows the results of individual vector space models, as well as combining these models using the averaged cosine scores. We make several observations here. First, while none of the four VSMs we tested outperforms the best existing systems on the benchmark datasets, surprisingly, using the averaged cosine scores of these models, the performance is improved substantially. It achieves higher Spearman’s rank coefficient on WS-353 and MTurk-287 than any other systems2 and are close to the state-of-the-art on MC30 and RG-65. Unlike some approach like (Hughes and Ramage, 2007), which performs well on some datasets but poorly on others, combing the VSMs from heterogeneous sources is more robust. Individually, we notice that Wikipedia context VSM provides consistently strong results, while thesaurusbased models work only reasonable on MC-30 and RG-65, potentially because other datasets contain more out-of-vocabulary words or proper nouns. Due to the inherent ambiguity of the task, there is a high variance among judgements from different annotators. Therefore, it is unrealistic to assume any of the methods can correlate perfectly to the mean human judgement scores. In</context>
<context position="12717" citStr="Hughes and Ramage, 2007" startWordPosition="2017" endWordPosition="2020">res, the performance can be improved over the best individual model (i.e., Wikipedia). Examining the scores of some word pairs carefully sug2This may not be statistically significant. Without having the exact output of existing systems, it is difficult to conduct a robust statistical significance test given the small sizes of these datasets. 618 Method WS-353 WS-sim Spearman’s p RG-65 MTurk-287 WS-rel MC-30 (Radinsky et al., 2011) 0.80 - - - - 0.63 (Reisinger and Mooney, 2010) 0.77 - - - - - (Agirre et al., 2009) 0.78 0.83 0.72 0.92 0.96 - (Gabrilovich and Markovitch, 2007) 0.75 - - - - 0.59 (Hughes and Ramage, 2007) 0.55 - - 0.90 0.84 - Web Search 0.56 0.56 0.54 0.48 0.44 0.44 Wikipedia 0.73 0.80 0.73 0.87 0.83 0.62 Bloomsbury 0.45 0.60 0.60 0.71 0.78 0.29 WordNet 0.37 0.49 0.49 0.79 0.78 0.25 Combining VSMs 0.81 0.87 0.77 0.89 0.89 0.68 Table 1: The performance of the state-of-the-art methods and different vector space models on measuring semantic word relatedness using the cosine similarity. gests the broader coverage of different words and senses could be the reason. For example, some of the words in the datasets have multiple senses, such as “jaguar vs. car” and “jaguar vs. cat”. Although in previous</context>
</contexts>
<marker>Hughes, Ramage, 2007</marker>
<rawString>T. Hughes and D. Ramage. 2007. Lexical semantic relatedness with random graph walks. In Proceedings of EMNLP-CoNLL-2007, pages 581–589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kolcz</author>
<author>W Yih</author>
</authors>
<title>Raising the baseline for high-precision text classifiers.</title>
<date>2007</date>
<booktitle>In KDD ’07,</booktitle>
<pages>400--409</pages>
<contexts>
<context position="5617" citStr="Kolcz and Yih, 2007" startWordPosition="855" endWordPosition="858">f a target word. This bag-of-words representation is then mapped to the TF-IDF term vector: each term is weighted by log(freq) x log(N/df), where freq is the number of times the term appears in the collection, df the document frequency of the term in the whole corpus and N the number of total documents. We further employed two simple techniques to improve the quality of these term-vectors: vocabulary and term trimming. Top 1,500 terms with high document frequency values are treated as stopwords and removed from the vocabulary. Moreover, we adopted a document-specific feature selection method (Kolcz and Yih, 2007) designed originally for text classification and retain only the top 200 high-weighted terms for each term-vector1. The corpus-based VSMs are created using English Wikipedia (Snapshot of Nov. 2010), consisting of 917M words after preprocessing (markup tags removal and sentence splitting). Web-based VSMs leverage Web search results to form a vector of each query (Sahami and Heilman, 2006). For each word to compare, we issue it as a query and retrieve the set of relevant snippets (top 30 in our experiments) using a popular commercial search engine, Bing. All these snippets together are viewed as</context>
</contexts>
<marker>Kolcz, Yih, 2007</marker>
<rawString>A. Kolcz and W. Yih. 2007. Raising the baseline for high-precision text classifiers. In KDD ’07, pages 400–409.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>W Charles</author>
</authors>
<title>Contextual correlates of semantic similarity. Language and cognitive processes,</title>
<date>1991</date>
<pages>6--1</pages>
<contexts>
<context position="10049" citStr="Miller and Charles (1991)" startWordPosition="1582" endWordPosition="1585">elatedness of each pair is assessed on a 0-10 scale by 13-16 human judges, where the mean is used as the final score. Examining the relations between the words in each pair, Agirre et al. (2009) further split this dataset into similar pairs (WS-sim) and related pairs (WS-rel), where the former contains synonyms, antonyms, identical words and hyponyms/hypernyms and the latter capture other word relations. Collected by Rubenstein and Goodenough (1965), RG-65 contains 65 pairs of words that are either synonyms or unrelated, assessed on a 0-4 scale by 51 human subjects. Taking 30 pairs from them, Miller and Charles (1991) created the (MC-30) dataset by reassessing these word pairs using 38 subjects. These 30 pairs of words are also a subset of WS-353. Although these three datasets contain overlapping word pairs, their scores are different because of the degree of relatedness were given by different human subjects. In addition to these datasets, we also evaluate our VSMs on the Mturk-287 dataset that consists of 287 word pairs collected by (Radinsky et al., 2011) using Amazon MTurk. 4.2 Results and Analysis Table 1 summarizes the results of various methods, where the top part lists the performance of state-ofth</context>
</contexts>
<marker>Miller, Charles, 1991</marker>
<rawString>G. Miller and W. Charles. 1991. Contextual correlates of semantic similarity. Language and cognitive processes, 6(1):1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Radinsky</author>
<author>E Agichtein</author>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>A word at a time: computing word relatedness using temporal semantic analysis.</title>
<date>2011</date>
<booktitle>In WWW ’11,</booktitle>
<pages>337--346</pages>
<contexts>
<context position="1520" citStr="Radinsky et al., 2011" startWordPosition="220" endWordPosition="223"> natural language processing and has many useful applications, including textual entailment, word sense disambiguation, information retrieval and automatic thesaurus discovery. Existing approaches can be roughly categorized into two kinds: knowledge-based and corpusbased, where the former includes graph-based algorithms and similarity measures operating on a lexical database such as WordNet (Budanitsky and Hirst, 2006; Agirre et al., 2009) and the latter consists of various kinds of vector space models (VSMs) constructed with the help of a large collection of text (Reisinger and Mooney, 2010; Radinsky et al., 2011). In this paper, we present a conceptually simple model for solving this problem. Observing that various kinds of information sources, such as * Work conducted while interning at Microsoft Research. general text corpora, Web search results and thesauruses, have different word and sense coverage, we first build individual vector space models from each of them separately. Given two words, each VSM measures the semantic relatedness by the cosine similarity of the corresponding vectors in its space. The final prediction is simply the averaged cosine scores derived from these VSMs. Despite its simp</context>
<context position="3805" citStr="Radinsky et al. (2011)" startWordPosition="566" endWordPosition="569"> to occur in the same Wikipedia topic. In contrast, Reisinger and Mooney (2010) use the conventional “context vector” – neighboring 616 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 616–620, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics terms of the occurrences of a target word – as the word representation. In addition, they argue that it is difficult to capture different senses of a word with a single vector, and introduce a multi-prototype representation. More recently, Radinsky et al. (2011) analyze the temporal aspects of words and argue that non-identical terms in two term vectors should also be compared based on their temporal usage when computing the similarity score. They construct the vectors using Wikipedia titles, Flickr image tags, and Del.icio.us bookmarks, and extract the temporal frequency of each concept from 130 years of New York Times archive. Methods that combine models from different sources do exist. For instance, Agirre et al. (2009) derive a WordNet-based measure using PageRank and combined it with several corpusbased vector space models using SVMs. 3 Vector S</context>
<context position="10498" citStr="Radinsky et al., 2011" startWordPosition="1656" endWordPosition="1659">), RG-65 contains 65 pairs of words that are either synonyms or unrelated, assessed on a 0-4 scale by 51 human subjects. Taking 30 pairs from them, Miller and Charles (1991) created the (MC-30) dataset by reassessing these word pairs using 38 subjects. These 30 pairs of words are also a subset of WS-353. Although these three datasets contain overlapping word pairs, their scores are different because of the degree of relatedness were given by different human subjects. In addition to these datasets, we also evaluate our VSMs on the Mturk-287 dataset that consists of 287 word pairs collected by (Radinsky et al., 2011) using Amazon MTurk. 4.2 Results and Analysis Table 1 summarizes the results of various methods, where the top part lists the performance of state-ofthe-art systems and the bottom shows the results of individual vector space models, as well as combining these models using the averaged cosine scores. We make several observations here. First, while none of the four VSMs we tested outperforms the best existing systems on the benchmark datasets, surprisingly, using the averaged cosine scores of these models, the performance is improved substantially. It achieves higher Spearman’s rank coefficient </context>
<context position="12527" citStr="Radinsky et al., 2011" startWordPosition="1977" endWordPosition="1980"> dataset indicates that the result of our approach of combining heterogeneous VSMs is close to the averaged human performance. It is intriguing to see that by using the averaged cosine scores, the performance can be improved over the best individual model (i.e., Wikipedia). Examining the scores of some word pairs carefully sug2This may not be statistically significant. Without having the exact output of existing systems, it is difficult to conduct a robust statistical significance test given the small sizes of these datasets. 618 Method WS-353 WS-sim Spearman’s p RG-65 MTurk-287 WS-rel MC-30 (Radinsky et al., 2011) 0.80 - - - - 0.63 (Reisinger and Mooney, 2010) 0.77 - - - - - (Agirre et al., 2009) 0.78 0.83 0.72 0.92 0.96 - (Gabrilovich and Markovitch, 2007) 0.75 - - - - 0.59 (Hughes and Ramage, 2007) 0.55 - - 0.90 0.84 - Web Search 0.56 0.56 0.54 0.48 0.44 0.44 Wikipedia 0.73 0.80 0.73 0.87 0.83 0.62 Bloomsbury 0.45 0.60 0.60 0.71 0.78 0.29 WordNet 0.37 0.49 0.49 0.79 0.78 0.25 Combining VSMs 0.81 0.87 0.77 0.89 0.89 0.68 Table 1: The performance of the state-of-the-art methods and different vector space models on measuring semantic word relatedness using the cosine similarity. gests the broader covera</context>
</contexts>
<marker>Radinsky, Agichtein, Gabrilovich, Markovitch, 2011</marker>
<rawString>K. Radinsky, E. Agichtein, E. Gabrilovich, and S. Markovitch. 2011. A word at a time: computing word relatedness using temporal semantic analysis. In WWW ’11, pages 337–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Reisinger</author>
<author>R Mooney</author>
</authors>
<title>Multi-prototype vector-space models of word meaning.</title>
<date>2010</date>
<booktitle>In NAACL ’10.</booktitle>
<contexts>
<context position="1496" citStr="Reisinger and Mooney, 2010" startWordPosition="216" endWordPosition="219"> is a fundamental problem in natural language processing and has many useful applications, including textual entailment, word sense disambiguation, information retrieval and automatic thesaurus discovery. Existing approaches can be roughly categorized into two kinds: knowledge-based and corpusbased, where the former includes graph-based algorithms and similarity measures operating on a lexical database such as WordNet (Budanitsky and Hirst, 2006; Agirre et al., 2009) and the latter consists of various kinds of vector space models (VSMs) constructed with the help of a large collection of text (Reisinger and Mooney, 2010; Radinsky et al., 2011). In this paper, we present a conceptually simple model for solving this problem. Observing that various kinds of information sources, such as * Work conducted while interning at Microsoft Research. general text corpora, Web search results and thesauruses, have different word and sense coverage, we first build individual vector space models from each of them separately. Given two words, each VSM measures the semantic relatedness by the cosine similarity of the corresponding vectors in its space. The final prediction is simply the averaged cosine scores derived from thes</context>
<context position="3262" citStr="Reisinger and Mooney (2010)" startWordPosition="486" endWordPosition="489"> Section 5 concludes the paper. 2 Background Prior work on measuring lexical semantics can be categorized as knowledge-based or corpus-based. Knowledge-based methods leverage word relations encoded in lexical databases such as WordNet and provide graph-based similarity measures. Detailed comparisons of these methods can be found in (Budanitsky and Hirst, 2006). Corpus-based methods assume related words tend to co-occur or to appear in similar context. For example, Gabrilovich and Markovitch (2007) measure word relatedness by whether they tend to occur in the same Wikipedia topic. In contrast, Reisinger and Mooney (2010) use the conventional “context vector” – neighboring 616 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 616–620, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics terms of the occurrences of a target word – as the word representation. In addition, they argue that it is difficult to capture different senses of a word with a single vector, and introduce a multi-prototype representation. More recently, Radinsky et al. (2011) analyze the temporal aspects of words and argue that non</context>
<context position="12574" citStr="Reisinger and Mooney, 2010" startWordPosition="1987" endWordPosition="1990">approach of combining heterogeneous VSMs is close to the averaged human performance. It is intriguing to see that by using the averaged cosine scores, the performance can be improved over the best individual model (i.e., Wikipedia). Examining the scores of some word pairs carefully sug2This may not be statistically significant. Without having the exact output of existing systems, it is difficult to conduct a robust statistical significance test given the small sizes of these datasets. 618 Method WS-353 WS-sim Spearman’s p RG-65 MTurk-287 WS-rel MC-30 (Radinsky et al., 2011) 0.80 - - - - 0.63 (Reisinger and Mooney, 2010) 0.77 - - - - - (Agirre et al., 2009) 0.78 0.83 0.72 0.92 0.96 - (Gabrilovich and Markovitch, 2007) 0.75 - - - - 0.59 (Hughes and Ramage, 2007) 0.55 - - 0.90 0.84 - Web Search 0.56 0.56 0.54 0.48 0.44 0.44 Wikipedia 0.73 0.80 0.73 0.87 0.83 0.62 Bloomsbury 0.45 0.60 0.60 0.71 0.78 0.29 WordNet 0.37 0.49 0.49 0.79 0.78 0.25 Combining VSMs 0.81 0.87 0.77 0.89 0.89 0.68 Table 1: The performance of the state-of-the-art methods and different vector space models on measuring semantic word relatedness using the cosine similarity. gests the broader coverage of different words and senses could be the r</context>
</contexts>
<marker>Reisinger, Mooney, 2010</marker>
<rawString>J. Reisinger and R. Mooney. 2010. Multi-prototype vector-space models of word meaning. In NAACL ’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Rubenstein</author>
<author>J Goodenough</author>
</authors>
<title>Contextual correlates of synonymy.</title>
<date>1965</date>
<journal>Communications of the ACM,</journal>
<pages>8--627</pages>
<contexts>
<context position="9877" citStr="Rubenstein and Goodenough (1965)" startWordPosition="1551" endWordPosition="1554"> is the largest among them and has been used extensively in recent work. Originally collected by Finkelstein et al. (2001), the dataset consists of 353 word pairs. The degree of relatedness of each pair is assessed on a 0-10 scale by 13-16 human judges, where the mean is used as the final score. Examining the relations between the words in each pair, Agirre et al. (2009) further split this dataset into similar pairs (WS-sim) and related pairs (WS-rel), where the former contains synonyms, antonyms, identical words and hyponyms/hypernyms and the latter capture other word relations. Collected by Rubenstein and Goodenough (1965), RG-65 contains 65 pairs of words that are either synonyms or unrelated, assessed on a 0-4 scale by 51 human subjects. Taking 30 pairs from them, Miller and Charles (1991) created the (MC-30) dataset by reassessing these word pairs using 38 subjects. These 30 pairs of words are also a subset of WS-353. Although these three datasets contain overlapping word pairs, their scores are different because of the degree of relatedness were given by different human subjects. In addition to these datasets, we also evaluate our VSMs on the Mturk-287 dataset that consists of 287 word pairs collected by (R</context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>H. Rubenstein and J. Goodenough. 1965. Contextual correlates of synonymy. Communications of the ACM, 8:627–633, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sahami</author>
<author>T Heilman</author>
</authors>
<title>A web-based kernel function for measuring the similarity of short text snippets.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th international conference on World Wide Web,</booktitle>
<pages>377--386</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="6007" citStr="Sahami and Heilman, 2006" startWordPosition="913" endWordPosition="916">ectors: vocabulary and term trimming. Top 1,500 terms with high document frequency values are treated as stopwords and removed from the vocabulary. Moreover, we adopted a document-specific feature selection method (Kolcz and Yih, 2007) designed originally for text classification and retain only the top 200 high-weighted terms for each term-vector1. The corpus-based VSMs are created using English Wikipedia (Snapshot of Nov. 2010), consisting of 917M words after preprocessing (markup tags removal and sentence splitting). Web-based VSMs leverage Web search results to form a vector of each query (Sahami and Heilman, 2006). For each word to compare, we issue it as a query and retrieve the set of relevant snippets (top 30 in our experiments) using a popular commercial search engine, Bing. All these snippets together are viewed as a pseudo-document and mapped to a TFIDF vector as in the corpus-based method. We do not allow for automatic query expansion in our experiments to ensure that the retrieved snippets are directly relevant to the target word and not expansions based on synonyms, hypernyms or hyponyms. We apply vocabulary trimming (top 1,000 terms with high DF values), but not term-trimming as the vectors h</context>
</contexts>
<marker>Sahami, Heilman, 2006</marker>
<rawString>M. Sahami and T. Heilman. 2006. A web-based kernel function for measuring the similarity of short text snippets. In Proceedings of the 15th international conference on World Wide Web, pages 377–386. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>