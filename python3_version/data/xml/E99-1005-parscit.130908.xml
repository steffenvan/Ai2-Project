<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019212">
<note confidence="0.713135">
Proceedings of EACL &apos;99
</note>
<title confidence="0.992019">
Determinants of Adjective-Noun Plausibility
</title>
<author confidence="0.998347">
Maria Lapata and Scott McDonald and Frank Keller
</author>
<affiliation confidence="0.940597">
School of Cognitive Science
Division of Informatics, University of Edinburgh
2 Buccleuch Place, Edinburgh EH8 9LW, UK
</affiliation>
<email confidence="0.99655">
{mlap, scottm, keller}@cogsci.ed.ac.uk
</email>
<sectionHeader confidence="0.995645" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99988">
This paper explores the determinants of
adjective-noun plausibility by using cor-
relation analysis to compare judgements
elicited from human subjects with five
corpus-based variables: co-occurrence fre-
quency of the adjective-noun pair, noun fre-
quency, conditional probability of the noun
given the adjective, the log-likelihood ra-
tio, and Resnik&apos;s (1993) selectional asso-
ciation measure. The highest correlation is
obtained with the co-occurrence frequency,
which points to the strongly lexicalist and
collocational nature of adjective-noun com-
binations.
</bodyText>
<sectionHeader confidence="0.998985" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999751769230769">
Research on linguistic plausibility has focused mainly
on the effects of argument plausibility during the pro-
cessing of locally ambiguous sentences. Psycholin-
guists have investigated whether the plausibility of
the direct object affects reading times for sentences
like (1). Here, argument plausibility refers to &amp;quot;prag-
matic plausibility&amp;quot; or &amp;quot;local semantic fit&amp;quot; (Holmes et
al., 1989), and judgements of plausibility are typi-
cally obtained by asking subjects to rate sentence frag-
ments containing verb-argument combinations (as an
example consider the bracketed parts of the sentences
in (1)). Such experiments typically use an ordinal scale
for plausibility (e.g., from 1 to 7).
</bodyText>
<listItem confidence="0.8763515">
(1) a. [The senior senator regretted the decision]
had ever been made public.
</listItem>
<bodyText confidence="0.97579335483871">
b. [The senior senator regretted the reporter]
had ever seen the report.
The majority of research has focussed on investigating
the effect of rated plausibility for verb-object combi-
nations in human sentence processing (Garnsey et al.,
1997; Pickering and Traxler, 1998). However, plausi-
bility effects have also been observed for adjective-
noun combinations in a head-modifier relationship.
Murphy (1990) has shown that typical adjective-
noun phrases (e.g., salty olives) are easier to in-
terpret in comparison to atypical ones (e.g., sweet
olives). Murphy provides a schema-based explana-
tion for this finding by postulating that in typical
adjective-noun phrases, the adjective modifies part of
the noun&apos;s schema and consequently it is understood
more quickly, whereas in atypical combinations, the
adjective modifies non-schematic aspects of the noun,
which leads to interpretation difficulties.
Smadja (1991) argues that the reason people prefer
strong tea to powerful tea and powerful car to strong
car is neither purely syntactic nor purely semantic, but
rather lexical.
A similar argument is put forward by Cruse (1986),
who observes that the adjective spotless collocates
well with the noun kitchen, relatively worse with the
noun complexion and not all with the noun taste. Ac-
cording to Cruse, words like spotless have idiosyn-
cratic collocational restrictions: differences in the de-
gree of acceptability of the adjective and its collocates
do not seem to depend on the meaning of the individ-
ual words.
</bodyText>
<subsectionHeader confidence="0.991835">
1.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999869">
Acquiring plausibility ratings for word combinations
(e.g., adjective-noun, verb-object, noun-noun) can be
useful in particular for language generation. Consider
a generator which has to make a choice between spot-
less kitchen and flawless kitchen. An empirical model
of plausibility could predict that spotless kitchen is a
plausible lexical choice, while flawless kitchen is not.
Adjective-noun combinations can be hard to gen-
erate given their collocational status. For a generator
which selects words solely on semantic grounds with-
out taking into account lexical constraints, the choice
between spotless kitchen and flawless kitchen may
look equivalent. Current work in natural language gen-
eration (Knight and Hatzivassiloglou, 1995; Langk-
ilde and Knight, 1998) has shown that corpus-based
knowledge can be used to address lexical choice non-
compositionally.
</bodyText>
<page confidence="0.993749">
30
</page>
<bodyText confidence="0.981443166666667">
Proceedings of EACL &apos;99
In the work reported here we acquire plausibility
ratings for adjective-noun combinations by eliciting
judgements from human subjects, and examine the ex-
tent to which different corpus-based models correlate
with human intuitions about the &amp;quot;goodness of fit&amp;quot; for
a range of adjective-noun combinations.
The research presented in this paper is similar
in motivation to Resnik&apos;s (1993) work on selec-
tional restrictions. Resnik evaluated his information-
theoretic model of selectional constraints against hu-
man plausibility ratings for verb-object combinations,
and showed that, in most cases, his model assigned
higher selectional association scores to verb-object
combinations which were judged more plausible by
human subjects.
We test five corpus-based models against human
plausibility judgements:
</bodyText>
<listItem confidence="0.993742514285714">
1. Familiarity of adjective-noun pair. We opera-
tionalise familiarity as co-occurrence frequency
in a large corpus. We calculate the co-occurrence
frequency of adjective-noun pairs in order to ex-
amine whether high corpus frequency is corre-
lated with plausibility, and correspondingly low
corpus frequency with implausibility.
2. Familiarity of head noun. We compare rated
plausibility with the corpus frequency of the head
noun, the motivation being that highly frequent
nouns are more familiar than less frequent ones,
and consequently may affect the judged plausi-
bility of the whole noun phrase.
3. Conditional probability. Our inclusion of the
conditional probability, P (noun adjective), as
a predictor variable also relies on the predic-
tion that plausibility is correlated with corpus fre-
quency. It differs from simple co-occurrence fre-
quency in that it additionally takes the overall ad-
jective frequency into account.
4. Collocational status. We employ the log-
likelihood ratio as a measure of the collocational
status of the adjective-noun pair (Dunning, 1993;
Daille, 1996). If we assume that plausibility dif-
ferences between strong tea and powerful tea or
guilty verdict and guilty cat reflect differences in
collocational status (i.e., appearing together more
often than expected by their individual occur-
rence frequencies), as opposed to being semantic
in nature, then the log-likelihood ratio may also
predict adjective-noun plausibility.
5. Selectional association. Finally, we evaluate
plausibility ratings against Resnik&apos;s (1993) mea-
sure of selectional association. This measure
is attractive because it combines statistical
</listItem>
<bodyText confidence="0.990364">
and knowledge-based methods. By exploiting a
knowledge-based taxonomy, it can capture con-
ceptual information about lexical items and hence
can make predictions about word combinations
which have not been seen in the corpus.
In the following section we describe our method for
eliciting plausibility judgements for adjective-noun
combinations. Section 3 reports the results of using the
five corpus-based models as predictors of adjective-
noun plausibility. Finally, section 4 offers some dis-
cussion of future work, and section 5 concluding re-
marks.
</bodyText>
<sectionHeader confidence="0.914992" genericHeader="method">
2 Collecting Plausibility Ratings
</sectionHeader>
<bodyText confidence="0.999969875">
In order to evaluate the different corpus-based mod-
els of adjective-noun plausibility introduced above,
we first needed to establish an independent measure
of plausibility. The standard approach used in ex-
perimental psycholinguistics is to elicit judgements
from human subjects; in this section we describe our
method for assembling the set of experimental materi-
als and collecting plausibility ratings for these stimuli.
</bodyText>
<subsectionHeader confidence="0.99486">
2.1 Method
</subsectionHeader>
<bodyText confidence="0.999778741935484">
Materials and Design. The ideal test of any of
the proposed models of adjective-noun plausibility
will be with randomly-chosen materials. We chose
30 adjectives according to a set of minimal crite-
ria (detailed below), and paired each adjective with
a noun selected randomly from three different fre-
quency ranges, which were defined by co-occurrence
counts in the 100 million word British National Cor-
pus (BNC; Burnard (1995)). The experimental design
thus consisted of one factor, Frequency Band, with
three levels (High, Medium, and Low).
We chose the adjectives to be minimally ambigu-
ous: each adjective had exactly two senses according
to WordNet (Miller et al., 1990) and was unambigu-
ously tagged as &amp;quot;adjective&amp;quot; 98.6% of the time, mea-
sured as the number of different part-of-speech tags
assigned to the word in the BNC. The 30 adjectives
ranged in BNC frequency from 1.9 to 49.1 per million.
We identified adjective-noun pairs by using Gsearch
(Corley et al., 1999), a chart parser which detects syn-
tactic patterns in a tagged corpus by exploiting a user-
specified context free grammar and a syntactic query.
Gsearch was run on a lemmatised version of the BNC
so as to compile a comprehensive corpus count of all
nouns occurring in a modifier-head relationship with
each of the 30 adjectives. Examples of the syntac-
tic patterns the parser identified are given in Table 1.
From the syntactic analysis provided by the parser
we extracted a table containing the adjective and the
head of the noun phrase following it. In the case of
compound nouns, we only included sequences of two
</bodyText>
<page confidence="0.999192">
31
</page>
<bodyText confidence="0.996708066666667">
Proceedings of EACL &apos;99
nouns, and considered the rightmost occurring noun as
the head.
From the retrieved adjective-noun pairs, we re-
moved all pairs where the noun had a BNC frequency
of less than 10 per million, as we wanted to reduce
the risk of plausibility ratings being influenced by the
presence of a noun unfamiliar to the subjects. Finally,
for each adjective we divided the set of pairs into three
&amp;quot;bands&amp;quot; (High, Medium, and Low), based on an equal
division of the range of log-transformed co-occurrence
frequency, and randomly chose one noun from each
band. Example stimuli are shown in Table 2. The mean
log co-occurrence frequencies were 3.839, 2.066 and
.258, for the High, Medium, and Low groups, respec-
tively.
30 filler items were also included, in order to en-
sure subjects produced a wide range of plausibility
ratings. These consisted of 30 adjective-noun combi-
nations that were not found in a modifier-head relation
in the BNC, and were also judged highly implausible
by the authors.
Procedure. The experimental paradigm was mag-
nitude estimation (ME), a technique standardly used
in psychophysics to measure judgements of sensory
stimuli (Stevens, 1975), which Bard et al. (1996) and
Cowart (1997) have applied to the elicitation of lin-
guistic judgements. The ME procedure requires sub-
jects to estimate the magnitude of physical stimuli by
assigning numerical values proportional to the stimu-
lus magnitude they perceive. In contrast to the 5- or
7-point scale conventionally used to measure human
intuitions, ME employs an interval scale, and therefore
produces data for which parametric inferential statis-
tics are valid.
ME requires subjects to assign numbers to a series
of linguistic stimuli in a proportional fashion. Subjects
are first exposed to a modulus item, which they assign
an arbitrary number. All other stimuli are rated pro-
portional to the modulus. In this way, each subject can
establish their own rating scale, thus yielding maxi-
mally fine-graded data and avoiding the known prob-
lems with the conventional ordinal scales for linguistic
data (Bard et al., 1996; Cowart, 1997; Schiitze, 1996).
In the present experiment, subjects were presented
with adjective-noun pairs and were asked to rate the
degree of adjective-noun fit proportional to a modulus
item. The experiment was carried out using WebExp,
a set of Java-Classes for administering psycholinguis-
tic studies over the Word-Wide Web (Keller et al.,
1998). Subjects first saw a set of instructions that ex-
plained the ME technique and included some exam-
ples, and had to fill in a short questionnaire including
basic demographic information. Each subject saw all
120 items used in the experiment (3 x 30 experimental
items and 30 fillers).
Subjects. The experiment was completed by 24 un-
paid volunteers, all native speakers of English. Sub-
jects were recruited via postings to local Usenet news-
groups.
</bodyText>
<subsectionHeader confidence="0.902343">
2.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.99997455">
As is standard in magnitude estimation studies, statis-
tical tests were done using geometric means to nor-
malise the data (the geometric mean is the mean of
the logarithms of the ratings). An analysis of vari-
ance (ANovA) indicated that the Frequency Band ef-
fect was significant, in both by-subjects and by-items
analyses: F1(2, 46) = 79.09, p &lt; .001; F2(2, 58) =
19.99, p &lt; .001. The geometric mean of the ratings
for adjective-noun combinations in the High band was
2.966, compared to Medium items at 2.660 and Low
pairs at 2.271.1 Post-hoc Tukey tests indicated that the
differences between all pairs of conditions were sig-
nificant at a = .01, except for the difference between
the High and Medium bands in the by-items analysis,
which was significant at a = .05. These results are
perhaps unsurprising: pairs that are more familiar are
rated as more plausible than combinations that are less
familiar. In the next section we explore the linear re-
lationship between plausibility and co-occurrence fre-
quency further, using correlation analysis.
</bodyText>
<sectionHeader confidence="0.99973" genericHeader="method">
3 Corpus-based Modelling
</sectionHeader>
<subsectionHeader confidence="0.999722">
3.1 Method
</subsectionHeader>
<bodyText confidence="0.9999907">
We correlated rated plausibility (Plaus) with the
following five corpus-based variables: (1) log-
transformed co-occurrence frequency (CoocF), mea-
sured as the number of times the adjective-noun pair
occurs in the BNC; (2) log-transformed noun fre-
quency (NounF), measured as the number of times the
head noun occurs in the BNC; (3) conditional prob-
ability (CondP) of the noun given the adjective es-
timated as shown in equation (2); (4) collocational
status,2 estimated using the log-likelihood statistic
(LLRatio); and (5) Resnik&apos;s measure of selectional as-
sociation (SelAssoc), which measures the semantic fit
of a particular semantic class c as an argument to a
predicate pi. The selectional association between class
c and predicate pi is given in equations (3) and (4).
More specifically, selectional association represents
the contribution of a particular semantic class c to the
total quantity of information provided by a predicate
about the semantic class of its argument, when mea-
sured as the relative entropy between the prior distri-
</bodyText>
<footnote confidence="0.860427666666667">
I For comparison, the filler items had a mean rating of
.998.
2Mutual information, though potentially of interest as a
measure of collocational status, was not tested due to its
well-known property of overemphasising the significance of
rare events (Church and Hanks, 1990).
</footnote>
<page confidence="0.990449">
32
</page>
<table confidence="0.992268">
Proceedings of EACL &apos;99
Pattern Example
adjective noun educational material
adjective specifier noun usual weekly classes
adjective noun noun environmental health officers
</table>
<tableCaption confidence="0.99003">
Table 1: Example of noun-adjective patterns
</tableCaption>
<table confidence="0.999960571428572">
Adjective High Co-occurrence Band
Frequency Low
Medium
hungry animal 1.79 pleasure 1.38 application 0
guilty verdict 3.91 secret 2.56 cat 0
temporary job 4.71 post 2.07 cap .69
naughty girl 2.94 dog 1.6 lunch .69
</table>
<tableCaption confidence="0.99957">
Table 2: Example stimuli (with log co-occurrence frequencies in the BNC)
</tableCaption>
<bodyText confidence="0.981555333333333">
bution of classes p(c) and the posterior distribution
p(c I pi) of the argument classes for a particular pred-
icate pi.
</bodyText>
<equation confidence="0.945731">
(2) P (noun I adjective) = f (adjective, noun)
f (adjective)
c I
(3) A(pi, c) = P(c I pi) log P(Pi)
P(c)
= E P(c I pi) log
(4) P(c)
</equation>
<bodyText confidence="0.999986941176471">
In the case of adjective-noun combinations, the se-
lectional association measures the semantic fit of an
adjective and each of the semantic classes of the
nouns it co-occurs with. We estimated the probabilities
P(c I pi) and P(c) similarly to Resnik (1993) by us-
ing relative frequencies from the BNC, together with
WordNet (Miller et al., 1990) as a source of taxo-
nomic semantic class information. Although the se-
lectional association is a function of the predicate and
all semantic classes it potentially selects for, following
Resnik&apos;s method for verb-object evaluation, we com-
pared human plausibility judgements with the max-
imum value for the selectional association for each
adjective-noun combination.
Table 3 shows the models&apos; predictions for three
sample stimuli. The first row contains the geometric
mean of the subjects&apos; responses.
</bodyText>
<subsectionHeader confidence="0.642094">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.9976647">
The five corpus-based variables were submitted to a
correlation analysis (see Tables 5 and 4). The highest
correlation with judged plausibility was obtained with
the familiarity of the adjective-noun combination (as
operationalised by corpus co-occurrence frequency).
Three other variables were also significantly corre-
lated with plausibility ratings: the conditional prob-
ability P (noun I adjective), the log-likelihood ratio,
and Resnik&apos;s selectional association measure. We dis-
cuss each predictor variable in more detail:
</bodyText>
<listItem confidence="0.980112606060606">
1. Familiarity of adjective-noun pair. Log-
transformed corpus co-occurrence frequency
was significantly correlated with plausibility
(Pearson r = .570, n = 90, p &lt; .01). This
verifies the Frequency Band effect discovered
by the ANOVA, in an analysis which compares
the individual co-occurrence frequency for each
item with rated plausibility, instead of collapsing
30 pairs together into an equivalence class.
Familiarity appears to be a strong determinant of
adjective-noun plausibility.
2. Familiarity of head noun. Log frequency of
the head noun was not significantly correlated
with plausibility (r = .098), which suggests
that adjective-noun plausibility judgements are
not influenced by noun familiarity.
3. Conditional probability. The probability of the
noun given the adjective was significantly cor-
related with plausibility (r = .220, p &lt; .05).
This is unsurprising, as conditional probability
was also correlated with co-occurrence frequency
(r = .497, p &lt; .01).
4. Collocational status. The log-likelihood statis-
tic yielded a significant correlation with plausi-
bility (r = .350, p &lt; .01), a fact that supports
the collocational nature of plausible adjective-
noun combinations. The log-likelihood ratio was
in turn correlated with co-occurrence frequency
(r = .725, p &lt; .01) and conditional probability
(r = .405, p &lt; .01) .
5. Selectional association. Resnik&apos;s measure of se-
lectional association was also significantly corre-
lated with plausibility (r = —.269, p &lt; .05).
</listItem>
<page confidence="0.99785">
33
</page>
<table confidence="0.9936945">
Proceedings of EACL &apos;99
hungry animal hungry application hungry pleasure
Plaus 3.02 1.46 1.31
CoocF 1.79 1.38 0
NounF 9.63 9.69 8.67
CondP .003 .002 .0005
LLRatio 26.81 14.33 2.9
SelAssoc .5 .5 .22
</table>
<tableCaption confidence="0.999779">
Table 3: Models&apos; prediction for hungry and its three paired noun heads
</tableCaption>
<bodyText confidence="0.99942284">
However, it should be noted that selectional as-
sociation was negatively correlated with plausi-
bility, although Resnik found the measure was
positively correlated with the judged plausibil-
ity of verb-object combinations, consistent with
its information-theoretic motivation. Resnik&apos;s
metric was also negatively correlated with co-
occurrence frequency (r = —.226, p &lt; .05), but
there was no correlation with noun frequency,
conditional probability, or log-likelihood ratio.
Since several of the corpus-based variables were in-
tercorrelated, we also calculated the squared semipar-
tial correlations between plausibility and each corpus-
based variable. This allows the unique relationship be-
tween each predictor and plausibility (removing the
effects of the other independent variables) to be deter-
mined. Co-occurrence frequency accounted uniquely
for 15.52% of the variance in plausibility ratings,
while noun frequency, conditional probability, log-
likelihood ratio, and selectional association accounted
for .51%, .53%, .41% and 1.7% of the variance, re-
spectively. This confirms co-occurrence frequency as
the best predictor of adjective-noun plausibility.
One explanation for the negative correlation be-
tween selectional association and plausibility, also
pointed out by Resnik, is the difference between
verb-object and adjective-noun combinations: com-
binations of the latter type are more lexical than
conceptual in nature and hence cannot be accounted
for on purely semantic or syntactic grounds. The
abstraction provided by a semantic taxonomy is at
odds with the idiosyncratic (i.e., lexical) nature of
adjective-noun co-occurrences. Consider for instance
the adjective hungry. The class (entity) yields the
highest selectional association value for the high-
est rated pair hungry animal. But (entity) also
yields the highest association for the lowest rated pair
hungry application (A(hungry, (entity)) = .50
in both cases). The highest association for hungry
pleasure, on the other hand, is given by the class
(act) (A(hungry, (act)) = .22). This demonstrates
how the method tends to prefer the most frequent
classes in the taxonomy (e.g., (entity), (act)) over
less frequent, but intuitively more plausible classes
(e.g., (f ee ling) for pleasure and (use) for appli-
cation).
This is a general problem with the estimation of the
probability of a class of a given predicate in Resnik&apos;s
method, as the probability is assumed to be uniform
for all classes of a given noun with which the predicate
co-occurs. Although the improvements suggested by
Ribas (1994) try to remedy this by taking the different
senses of a given word into account and implement-
ing selectional restrictions in the form of weighted dis-
junctions, the experiments reported here indicate that
methods based on taxonomic knowledge have difficul-
ties capturing the idiosyncratic (i.e., lexicalist) nature
of adjective-noun combinations.
Finally, idiosyncrasies in WordNet itself influence
the performance of Resnik&apos;s model. One problem
is that sense distinctions in WordNet are often too
fine-grained (Palmer (1999) makes a similar observa-
tion). Furthermore, there is considerable redundancy
in the definition of word senses. Consider the noun
application: it has 27 classes in WordNet which in-
clude (code), (coding system), (software),
(communication), (writing) and (written
communicat ion). It is difficult to see how (code)
or (coding system) is not (software) or
(writing) is not (written communication).
The fine granularity and the degree of redundancy in
the taxonomy bias the estimation of the frequency of a
given class. Resnik&apos;s model cannot distinguish classes
which are genuinely frequent from classes which are
infrequent but yet overly specified.
</bodyText>
<sectionHeader confidence="0.998772" genericHeader="method">
4 Future Work
</sectionHeader>
<bodyText confidence="0.999859">
Although familiarity of the adjective-noun combina-
tion proved to be the most predictive measure of
judged plausibility, it is obvious that this measure will
fail for adjective-noun pairs that never co-occur at all
in the training corpus. Is a zero co-occurrence count
merely the result of insufficient evidence, or is it a
reflection of a linguistic constraint? We plan to con-
duct another rating experiment, this time with a selec-
tion of stimuli that have a co-occurrence frequency of
zero in the BNC. These data will allow a further test
of Resnik&apos;s selectional association measure.
</bodyText>
<page confidence="0.996344">
34
</page>
<table confidence="0.987504166666667">
Proceedings of EACL &apos;99
Plaus CoocF NounF CondP LLRatio SelAssoc
Min .770 0 6.988 .0002 .02 .100
Max 3.240 5.037 11.929 .2139 1734.88 1.000
Mean 2.632 2.054 9.411 .0165 176.24 .288
Std Dev .529 1.583 1.100 .0312 334.23 .170
</table>
<tableCaption confidence="0.988422">
Table 4: Descriptive statistics for the six experimental variables
</tableCaption>
<table confidence="0.999870714285714">
Plaus CoocF NounF CondP LLRatio
CoocF .570**
NounF .098 .221*
CondP .220* .497** .008
LLRatio .350** .725** .001 .405**
SelAssoc —.269* —.226* —.191 —.097 .015
*p &lt; .05 (2-tailed) **p &lt; .01 (2-tailed)
</table>
<tableCaption confidence="0.999875">
Table 5: Correlation matrix for plausibility and the five corpus-based variables
</tableCaption>
<bodyText confidence="0.999942">
We also plan to investigate the application of
similarity-based smoothing (Dagan et al., 1999) to
zero co-occurrence counts, as this method is specif-
ically aimed at distinguishing between unobserved
events which are likely to occur in language from
those that are not. Plausibility ratings provide a suit-
able test of the psychological validity of co-occurrence
frequencies &amp;quot;recreated&amp;quot; with this method.
</bodyText>
<sectionHeader confidence="0.999484" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999961433333333">
This paper explored the determinants of linguistic
plausibility, a concept that is potentially relevant for
lexical choice in natural language generation systems.
Adjective-noun plausibility served as a test bed for a
number of corpus-based models of linguistic plausi-
bility. Plausibility judgements were obtained from hu-
man subjects for 90 randomly selected adjective-noun
pairs. The ratings revealed a clear effect of familiarity
of the adjective-noun pair (operationalised by corpus
co-occurrence frequency).
In a correlation analysis we compared judged plau-
sibility with the predictions of five corpus-based vari-
ables. The highest correlation was obtained with the
co-occurrence frequency of the adjective-noun pair.
Conditional probability, the log-likelihood ratio, and
Resnik&apos;s (1993) selectional association measure were
also significantly correlated with plausibility ratings.
The correlation with Resnik&apos;s measure was negative,
contrary to the predictions of his model. This points to
a problem with his technique for estimating word class
frequencies, which is aggravated by the collocational
nature of noun-adjective combinations.
Overall, the results confirm the strongly lexicalist
and collocational nature of adjective-noun combina-
tions. This fact could be exploited in a generation
system by taking into account corpus co-occurrence
counts for adjective-noun pairs (which can be obtained
straightforwardly) during lexical choice. Future re-
search has to identify how this approach can be gener-
alised to unseen data.
</bodyText>
<sectionHeader confidence="0.994728" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999935">
The authors acknowledge the support of the Alexan-
der S. Onassis Foundation (Lapata), the UK Economic
and Social Research Council (Keller, Lapata), the Nat-
ural Sciences and Engineering Research Council of
Canada, and the ORS Awards Scheme (McDonald).
</bodyText>
<sectionHeader confidence="0.998513" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9991797">
Ellen Gurman Bard, Dan Robertson, and Antonella
Sorace. 1996. Magnitude estimation of linguistic
acceptability. Language, 72(1):32-68.
Lou Burnard, 1995. Users Guide for the British Na-
tional Corpus. British National Corpus Consor-
tium, Oxford University Computing Service.
Kenneth Ward Church and Patrick Hanks. 1990.
Word association norms, mutual informations,
and lexicography. Computational Linguistics,
16(1 ):22-29.
Martin Corley, Steffan Corley, Matthew W. Crocker,
Frank Keller, and Shari Trewin, 1999. Gsearch
User Manual. Human Communication Research
Centre, University of Edinburgh.
Wayne Cowart. 1997. Experimental Syntax: Applying
Objective Methods to Sentence Judgments. Sage
Publications, Thousand Oaks, CA.
D. A. Cruse. 1986. Lexical Semantics. Cam-
bridge Textbooks in Linguistics. Cambridge Uni-
versity Press, Cambridge.
</reference>
<page confidence="0.983214">
35
</page>
<reference confidence="0.999527527027027">
Proceedings of EACL &apos;99
Ido Dagan, Lillian Lee, and Fernando Pereira. 1999.
Similarity-based models of word cooccurrence
probabilities. Machine Learning, 34(1).
Beatrice Daille. 1996. Study and implementation
of combined techniques for automatic extraction of
terminology. In Judith Klavans and Philip Resnik,
editors, The Balancing Act: Combining Symbolic
and Statistical Approaches to Language, pages 49-
66. MIT Press, Cambridge, MA.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 19(1):61-74.
Susan M. Garnsey, Neal J. Pearlmutter, Elisabeth M.
Myers, and Melanie A. Lotocky. 1997. The contri-
butions of verb bias and plausibility to the compre-
hension of temporarily ambiguous sentences. Jour-
nal of Memory and Language, 37(1):58-93.
V. M. Holmes, L. Stowe, and L. Cupples. 1989.
Lexical expectations in parsing complement-verb
sentences. Journal of Memory and Language,
28(6):668-689.
Frank Keller, Martin Corley, Steffan Corley, Lars
Konieczny, and Amalia Todirascu. 1998. Web-
Exp: A Java toolbox for web-based psychological
experiments. Technical Report HCRC/TR-99, Hu-
man Communication Research Centre, University
of Edinburgh.
Kevin Knight and Vasileios Hatzivassiloglou. 1995.
Two-level, many paths generation. In Proceedings
of the 33rd Annual Meeting of the Association for
Computational Linguistics, pages 252-260, Cam-
bridge, MA.
Irene Langkilde and Kevin Knight. 1998. Gener-
ation that exploits corpus-based statistical knowl-
edge. In Proceedings of the 17th International Con-
ference on Computational Linguistics and 36th An-
nual Meeting of the Association for Computational
Linguistics, pages 704-710, Montreal.
George A. Miller, Richard Beckwith, Christiane
Fellbaum, Derek Gross, and Katherine J. Miller.
1990. Introduction to WordNet: an on-line lexical
database. International Journal of Lexicography,
3(4):235-244.
Gregory L. Murphy. 1990. Noun phrase interpreta-
tion and noun combination. Journal of Memory and
Language, 29(3):259-288.
Martha Palmer. 1999. Consistent criteria for sense
distinctions. Computers and the Humanities, to ap-
pear.
Martin J. Pickering and Martin J. Traxler. 1998. Plau-
sibility and recovery from garden paths: An eye-
tracking study. Journal of Experimental Psychol-
ogy: Learning Memory and Cognition, 24(4):940-
961.
Philip Stuart Resnik. 1993. Selection and Informa-
tion: A Class-Based Approach to Lexical Relation-
ships. Ph.D. thesis, University of Pennsylvania.
Francesc Ribas. 1994. On learning more appropri-
ate selectional restrictions. In Proceedings of the
32nd Annual Meeting of the Association for Com-
putational Linguistics, Las Cruces, NM.
Carson T. Schiitze. 1996. The Empirical Base of Lin-
guistics: Grammaticality Judgments and Linguis-
tic Methodology. University of Chicago Press,
Chicago.
Frank Smadja. 1991. Macrocoding the lexicon
with co-occurrence knowledge. In Uri Zernik, ed-
itor, Lexical Acquisition: Using Online Resources
to Build a Lexicon, pages 165-189. Erlbaum, Hills-
dale, NJ.
Stanley S. Stevens, editor. 1975. Psychophysics:
Introduction to its Perceptual, Neural, and Social
Prospects. John Wiley, New York.
</reference>
<page confidence="0.998945">
36
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.609511">
<note confidence="0.763239">Proceedings of EACL &apos;99</note>
<title confidence="0.931444">Determinants of Adjective-Noun Plausibility</title>
<author confidence="0.984014">Lapata McDonald Keller</author>
<affiliation confidence="0.999967">School of Cognitive Science Division of Informatics, University of Edinburgh</affiliation>
<address confidence="0.980195">2 Buccleuch Place, Edinburgh EH8 9LW, UK</address>
<email confidence="0.994645">mlap@cogsci.ed.ac.uk</email>
<email confidence="0.994645">scottm@cogsci.ed.ac.uk</email>
<email confidence="0.994645">keller@cogsci.ed.ac.uk</email>
<abstract confidence="0.9924228">This paper explores the determinants of adjective-noun plausibility by using correlation analysis to compare judgements elicited from human subjects with five corpus-based variables: co-occurrence frequency of the adjective-noun pair, noun frequency, conditional probability of the noun given the adjective, the log-likelihood ratio, and Resnik&apos;s (1993) selectional association measure. The highest correlation is obtained with the co-occurrence frequency, which points to the strongly lexicalist and collocational nature of adjective-noun combinations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ellen Gurman Bard</author>
<author>Dan Robertson</author>
<author>Antonella Sorace</author>
</authors>
<title>Magnitude estimation of linguistic acceptability.</title>
<date>1996</date>
<journal>Language,</journal>
<pages>72--1</pages>
<contexts>
<context position="10253" citStr="Bard et al. (1996)" startWordPosition="1543" endWordPosition="1546">muli are shown in Table 2. The mean log co-occurrence frequencies were 3.839, 2.066 and .258, for the High, Medium, and Low groups, respectively. 30 filler items were also included, in order to ensure subjects produced a wide range of plausibility ratings. These consisted of 30 adjective-noun combinations that were not found in a modifier-head relation in the BNC, and were also judged highly implausible by the authors. Procedure. The experimental paradigm was magnitude estimation (ME), a technique standardly used in psychophysics to measure judgements of sensory stimuli (Stevens, 1975), which Bard et al. (1996) and Cowart (1997) have applied to the elicitation of linguistic judgements. The ME procedure requires subjects to estimate the magnitude of physical stimuli by assigning numerical values proportional to the stimulus magnitude they perceive. In contrast to the 5- or 7-point scale conventionally used to measure human intuitions, ME employs an interval scale, and therefore produces data for which parametric inferential statistics are valid. ME requires subjects to assign numbers to a series of linguistic stimuli in a proportional fashion. Subjects are first exposed to a modulus item, which they </context>
</contexts>
<marker>Bard, Robertson, Sorace, 1996</marker>
<rawString>Ellen Gurman Bard, Dan Robertson, and Antonella Sorace. 1996. Magnitude estimation of linguistic acceptability. Language, 72(1):32-68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<title>Users Guide for the British National Corpus.</title>
<date>1995</date>
<institution>British National Corpus Consortium, Oxford University Computing Service.</institution>
<contexts>
<context position="7893" citStr="Burnard (1995)" startWordPosition="1152" endWordPosition="1153">cit judgements from human subjects; in this section we describe our method for assembling the set of experimental materials and collecting plausibility ratings for these stimuli. 2.1 Method Materials and Design. The ideal test of any of the proposed models of adjective-noun plausibility will be with randomly-chosen materials. We chose 30 adjectives according to a set of minimal criteria (detailed below), and paired each adjective with a noun selected randomly from three different frequency ranges, which were defined by co-occurrence counts in the 100 million word British National Corpus (BNC; Burnard (1995)). The experimental design thus consisted of one factor, Frequency Band, with three levels (High, Medium, and Low). We chose the adjectives to be minimally ambiguous: each adjective had exactly two senses according to WordNet (Miller et al., 1990) and was unambiguously tagged as &amp;quot;adjective&amp;quot; 98.6% of the time, measured as the number of different part-of-speech tags assigned to the word in the BNC. The 30 adjectives ranged in BNC frequency from 1.9 to 49.1 per million. We identified adjective-noun pairs by using Gsearch (Corley et al., 1999), a chart parser which detects syntactic patterns in a </context>
</contexts>
<marker>Burnard, 1995</marker>
<rawString>Lou Burnard, 1995. Users Guide for the British National Corpus. British National Corpus Consortium, Oxford University Computing Service.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual informations, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<pages>22--29</pages>
<contexts>
<context position="14366" citStr="Church and Hanks, 1990" startWordPosition="2200" endWordPosition="2203"> association between class c and predicate pi is given in equations (3) and (4). More specifically, selectional association represents the contribution of a particular semantic class c to the total quantity of information provided by a predicate about the semantic class of its argument, when measured as the relative entropy between the prior distriI For comparison, the filler items had a mean rating of .998. 2Mutual information, though potentially of interest as a measure of collocational status, was not tested due to its well-known property of overemphasising the significance of rare events (Church and Hanks, 1990). 32 Proceedings of EACL &apos;99 Pattern Example adjective noun educational material adjective specifier noun usual weekly classes adjective noun noun environmental health officers Table 1: Example of noun-adjective patterns Adjective High Co-occurrence Band Frequency Low Medium hungry animal 1.79 pleasure 1.38 application 0 guilty verdict 3.91 secret 2.56 cat 0 temporary job 4.71 post 2.07 cap .69 naughty girl 2.94 dog 1.6 lunch .69 Table 2: Example stimuli (with log co-occurrence frequencies in the BNC) bution of classes p(c) and the posterior distribution p(c I pi) of the argument classes for a</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Ward Church and Patrick Hanks. 1990. Word association norms, mutual informations, and lexicography. Computational Linguistics, 16(1 ):22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Corley</author>
<author>Steffan Corley</author>
<author>Matthew W Crocker</author>
<author>Frank Keller</author>
<author>Shari Trewin</author>
</authors>
<date>1999</date>
<institution>Gsearch User Manual. Human Communication Research Centre, University of Edinburgh.</institution>
<contexts>
<context position="8438" citStr="Corley et al., 1999" startWordPosition="1240" endWordPosition="1243">counts in the 100 million word British National Corpus (BNC; Burnard (1995)). The experimental design thus consisted of one factor, Frequency Band, with three levels (High, Medium, and Low). We chose the adjectives to be minimally ambiguous: each adjective had exactly two senses according to WordNet (Miller et al., 1990) and was unambiguously tagged as &amp;quot;adjective&amp;quot; 98.6% of the time, measured as the number of different part-of-speech tags assigned to the word in the BNC. The 30 adjectives ranged in BNC frequency from 1.9 to 49.1 per million. We identified adjective-noun pairs by using Gsearch (Corley et al., 1999), a chart parser which detects syntactic patterns in a tagged corpus by exploiting a userspecified context free grammar and a syntactic query. Gsearch was run on a lemmatised version of the BNC so as to compile a comprehensive corpus count of all nouns occurring in a modifier-head relationship with each of the 30 adjectives. Examples of the syntactic patterns the parser identified are given in Table 1. From the syntactic analysis provided by the parser we extracted a table containing the adjective and the head of the noun phrase following it. In the case of compound nouns, we only included seq</context>
</contexts>
<marker>Corley, Corley, Crocker, Keller, Trewin, 1999</marker>
<rawString>Martin Corley, Steffan Corley, Matthew W. Crocker, Frank Keller, and Shari Trewin, 1999. Gsearch User Manual. Human Communication Research Centre, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Cowart</author>
</authors>
<title>Experimental Syntax: Applying Objective Methods to Sentence Judgments. Sage Publications,</title>
<date>1997</date>
<location>Thousand Oaks, CA.</location>
<contexts>
<context position="10271" citStr="Cowart (1997)" startWordPosition="1548" endWordPosition="1549"> 2. The mean log co-occurrence frequencies were 3.839, 2.066 and .258, for the High, Medium, and Low groups, respectively. 30 filler items were also included, in order to ensure subjects produced a wide range of plausibility ratings. These consisted of 30 adjective-noun combinations that were not found in a modifier-head relation in the BNC, and were also judged highly implausible by the authors. Procedure. The experimental paradigm was magnitude estimation (ME), a technique standardly used in psychophysics to measure judgements of sensory stimuli (Stevens, 1975), which Bard et al. (1996) and Cowart (1997) have applied to the elicitation of linguistic judgements. The ME procedure requires subjects to estimate the magnitude of physical stimuli by assigning numerical values proportional to the stimulus magnitude they perceive. In contrast to the 5- or 7-point scale conventionally used to measure human intuitions, ME employs an interval scale, and therefore produces data for which parametric inferential statistics are valid. ME requires subjects to assign numbers to a series of linguistic stimuli in a proportional fashion. Subjects are first exposed to a modulus item, which they assign an arbitrar</context>
</contexts>
<marker>Cowart, 1997</marker>
<rawString>Wayne Cowart. 1997. Experimental Syntax: Applying Objective Methods to Sentence Judgments. Sage Publications, Thousand Oaks, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Cruse</author>
</authors>
<title>Lexical Semantics. Cambridge Textbooks in Linguistics.</title>
<date>1986</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="2731" citStr="Cruse (1986)" startWordPosition="393" endWordPosition="394"> atypical ones (e.g., sweet olives). Murphy provides a schema-based explanation for this finding by postulating that in typical adjective-noun phrases, the adjective modifies part of the noun&apos;s schema and consequently it is understood more quickly, whereas in atypical combinations, the adjective modifies non-schematic aspects of the noun, which leads to interpretation difficulties. Smadja (1991) argues that the reason people prefer strong tea to powerful tea and powerful car to strong car is neither purely syntactic nor purely semantic, but rather lexical. A similar argument is put forward by Cruse (1986), who observes that the adjective spotless collocates well with the noun kitchen, relatively worse with the noun complexion and not all with the noun taste. According to Cruse, words like spotless have idiosyncratic collocational restrictions: differences in the degree of acceptability of the adjective and its collocates do not seem to depend on the meaning of the individual words. 1.1 Motivation Acquiring plausibility ratings for word combinations (e.g., adjective-noun, verb-object, noun-noun) can be useful in particular for language generation. Consider a generator which has to make a choice</context>
</contexts>
<marker>Cruse, 1986</marker>
<rawString>D. A. Cruse. 1986. Lexical Semantics. Cambridge Textbooks in Linguistics. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Lillian Lee</author>
<author>Fernando Pereira</author>
</authors>
<title>Similarity-based models of word cooccurrence probabilities.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="23248" citStr="Dagan et al., 1999" startWordPosition="3555" endWordPosition="3558">LLRatio SelAssoc Min .770 0 6.988 .0002 .02 .100 Max 3.240 5.037 11.929 .2139 1734.88 1.000 Mean 2.632 2.054 9.411 .0165 176.24 .288 Std Dev .529 1.583 1.100 .0312 334.23 .170 Table 4: Descriptive statistics for the six experimental variables Plaus CoocF NounF CondP LLRatio CoocF .570** NounF .098 .221* CondP .220* .497** .008 LLRatio .350** .725** .001 .405** SelAssoc —.269* —.226* —.191 —.097 .015 *p &lt; .05 (2-tailed) **p &lt; .01 (2-tailed) Table 5: Correlation matrix for plausibility and the five corpus-based variables We also plan to investigate the application of similarity-based smoothing (Dagan et al., 1999) to zero co-occurrence counts, as this method is specifically aimed at distinguishing between unobserved events which are likely to occur in language from those that are not. Plausibility ratings provide a suitable test of the psychological validity of co-occurrence frequencies &amp;quot;recreated&amp;quot; with this method. 5 Conclusions This paper explored the determinants of linguistic plausibility, a concept that is potentially relevant for lexical choice in natural language generation systems. Adjective-noun plausibility served as a test bed for a number of corpus-based models of linguistic plausibility. P</context>
</contexts>
<marker>Dagan, Lee, Pereira, 1999</marker>
<rawString>Ido Dagan, Lillian Lee, and Fernando Pereira. 1999. Similarity-based models of word cooccurrence probabilities. Machine Learning, 34(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Daille</author>
</authors>
<title>Study and implementation of combined techniques for automatic extraction of terminology.</title>
<date>1996</date>
<booktitle>In Judith Klavans and</booktitle>
<pages>49--66</pages>
<editor>Philip Resnik, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="5895" citStr="Daille, 1996" startWordPosition="860" endWordPosition="861">ent nouns are more familiar than less frequent ones, and consequently may affect the judged plausibility of the whole noun phrase. 3. Conditional probability. Our inclusion of the conditional probability, P (noun adjective), as a predictor variable also relies on the prediction that plausibility is correlated with corpus frequency. It differs from simple co-occurrence frequency in that it additionally takes the overall adjective frequency into account. 4. Collocational status. We employ the loglikelihood ratio as a measure of the collocational status of the adjective-noun pair (Dunning, 1993; Daille, 1996). If we assume that plausibility differences between strong tea and powerful tea or guilty verdict and guilty cat reflect differences in collocational status (i.e., appearing together more often than expected by their individual occurrence frequencies), as opposed to being semantic in nature, then the log-likelihood ratio may also predict adjective-noun plausibility. 5. Selectional association. Finally, we evaluate plausibility ratings against Resnik&apos;s (1993) measure of selectional association. This measure is attractive because it combines statistical and knowledge-based methods. By exploitin</context>
</contexts>
<marker>Daille, 1996</marker>
<rawString>Beatrice Daille. 1996. Study and implementation of combined techniques for automatic extraction of terminology. In Judith Klavans and Philip Resnik, editors, The Balancing Act: Combining Symbolic and Statistical Approaches to Language, pages 49-66. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--1</pages>
<contexts>
<context position="5880" citStr="Dunning, 1993" startWordPosition="858" endWordPosition="859">at highly frequent nouns are more familiar than less frequent ones, and consequently may affect the judged plausibility of the whole noun phrase. 3. Conditional probability. Our inclusion of the conditional probability, P (noun adjective), as a predictor variable also relies on the prediction that plausibility is correlated with corpus frequency. It differs from simple co-occurrence frequency in that it additionally takes the overall adjective frequency into account. 4. Collocational status. We employ the loglikelihood ratio as a measure of the collocational status of the adjective-noun pair (Dunning, 1993; Daille, 1996). If we assume that plausibility differences between strong tea and powerful tea or guilty verdict and guilty cat reflect differences in collocational status (i.e., appearing together more often than expected by their individual occurrence frequencies), as opposed to being semantic in nature, then the log-likelihood ratio may also predict adjective-noun plausibility. 5. Selectional association. Finally, we evaluate plausibility ratings against Resnik&apos;s (1993) measure of selectional association. This measure is attractive because it combines statistical and knowledge-based method</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan M Garnsey</author>
<author>Neal J Pearlmutter</author>
<author>Elisabeth M Myers</author>
<author>Melanie A Lotocky</author>
</authors>
<title>The contributions of verb bias and plausibility to the comprehension of temporarily ambiguous sentences.</title>
<date>1997</date>
<journal>Journal of Memory and Language,</journal>
<pages>37--1</pages>
<contexts>
<context position="1849" citStr="Garnsey et al., 1997" startWordPosition="260" endWordPosition="263"> 1989), and judgements of plausibility are typically obtained by asking subjects to rate sentence fragments containing verb-argument combinations (as an example consider the bracketed parts of the sentences in (1)). Such experiments typically use an ordinal scale for plausibility (e.g., from 1 to 7). (1) a. [The senior senator regretted the decision] had ever been made public. b. [The senior senator regretted the reporter] had ever seen the report. The majority of research has focussed on investigating the effect of rated plausibility for verb-object combinations in human sentence processing (Garnsey et al., 1997; Pickering and Traxler, 1998). However, plausibility effects have also been observed for adjectivenoun combinations in a head-modifier relationship. Murphy (1990) has shown that typical adjectivenoun phrases (e.g., salty olives) are easier to interpret in comparison to atypical ones (e.g., sweet olives). Murphy provides a schema-based explanation for this finding by postulating that in typical adjective-noun phrases, the adjective modifies part of the noun&apos;s schema and consequently it is understood more quickly, whereas in atypical combinations, the adjective modifies non-schematic aspects of</context>
</contexts>
<marker>Garnsey, Pearlmutter, Myers, Lotocky, 1997</marker>
<rawString>Susan M. Garnsey, Neal J. Pearlmutter, Elisabeth M. Myers, and Melanie A. Lotocky. 1997. The contributions of verb bias and plausibility to the comprehension of temporarily ambiguous sentences. Journal of Memory and Language, 37(1):58-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V M Holmes</author>
<author>L Stowe</author>
<author>L Cupples</author>
</authors>
<title>Lexical expectations in parsing complement-verb sentences.</title>
<date>1989</date>
<journal>Journal of Memory and Language,</journal>
<pages>28--6</pages>
<contexts>
<context position="1235" citStr="Holmes et al., 1989" startWordPosition="165" endWordPosition="168">, and Resnik&apos;s (1993) selectional association measure. The highest correlation is obtained with the co-occurrence frequency, which points to the strongly lexicalist and collocational nature of adjective-noun combinations. 1 Introduction Research on linguistic plausibility has focused mainly on the effects of argument plausibility during the processing of locally ambiguous sentences. Psycholinguists have investigated whether the plausibility of the direct object affects reading times for sentences like (1). Here, argument plausibility refers to &amp;quot;pragmatic plausibility&amp;quot; or &amp;quot;local semantic fit&amp;quot; (Holmes et al., 1989), and judgements of plausibility are typically obtained by asking subjects to rate sentence fragments containing verb-argument combinations (as an example consider the bracketed parts of the sentences in (1)). Such experiments typically use an ordinal scale for plausibility (e.g., from 1 to 7). (1) a. [The senior senator regretted the decision] had ever been made public. b. [The senior senator regretted the reporter] had ever seen the report. The majority of research has focussed on investigating the effect of rated plausibility for verb-object combinations in human sentence processing (Garnse</context>
</contexts>
<marker>Holmes, Stowe, Cupples, 1989</marker>
<rawString>V. M. Holmes, L. Stowe, and L. Cupples. 1989. Lexical expectations in parsing complement-verb sentences. Journal of Memory and Language, 28(6):668-689.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Keller</author>
<author>Martin Corley</author>
<author>Steffan Corley</author>
<author>Lars Konieczny</author>
<author>Amalia Todirascu</author>
</authors>
<title>WebExp: A Java toolbox for web-based psychological experiments.</title>
<date>1998</date>
<tech>Technical Report HCRC/TR-99,</tech>
<institution>Human Communication Research Centre, University of Edinburgh.</institution>
<contexts>
<context position="11502" citStr="Keller et al., 1998" startWordPosition="1739" endWordPosition="1742">ll other stimuli are rated proportional to the modulus. In this way, each subject can establish their own rating scale, thus yielding maximally fine-graded data and avoiding the known problems with the conventional ordinal scales for linguistic data (Bard et al., 1996; Cowart, 1997; Schiitze, 1996). In the present experiment, subjects were presented with adjective-noun pairs and were asked to rate the degree of adjective-noun fit proportional to a modulus item. The experiment was carried out using WebExp, a set of Java-Classes for administering psycholinguistic studies over the Word-Wide Web (Keller et al., 1998). Subjects first saw a set of instructions that explained the ME technique and included some examples, and had to fill in a short questionnaire including basic demographic information. Each subject saw all 120 items used in the experiment (3 x 30 experimental items and 30 fillers). Subjects. The experiment was completed by 24 unpaid volunteers, all native speakers of English. Subjects were recruited via postings to local Usenet newsgroups. 2.2 Results and Discussion As is standard in magnitude estimation studies, statistical tests were done using geometric means to normalise the data (the geom</context>
</contexts>
<marker>Keller, Corley, Corley, Konieczny, Todirascu, 1998</marker>
<rawString>Frank Keller, Martin Corley, Steffan Corley, Lars Konieczny, and Amalia Todirascu. 1998. WebExp: A Java toolbox for web-based psychological experiments. Technical Report HCRC/TR-99, Human Communication Research Centre, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Two-level, many paths generation.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>252--260</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="3866" citStr="Knight and Hatzivassiloglou, 1995" startWordPosition="561" endWordPosition="564">n be useful in particular for language generation. Consider a generator which has to make a choice between spotless kitchen and flawless kitchen. An empirical model of plausibility could predict that spotless kitchen is a plausible lexical choice, while flawless kitchen is not. Adjective-noun combinations can be hard to generate given their collocational status. For a generator which selects words solely on semantic grounds without taking into account lexical constraints, the choice between spotless kitchen and flawless kitchen may look equivalent. Current work in natural language generation (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998) has shown that corpus-based knowledge can be used to address lexical choice noncompositionally. 30 Proceedings of EACL &apos;99 In the work reported here we acquire plausibility ratings for adjective-noun combinations by eliciting judgements from human subjects, and examine the extent to which different corpus-based models correlate with human intuitions about the &amp;quot;goodness of fit&amp;quot; for a range of adjective-noun combinations. The research presented in this paper is similar in motivation to Resnik&apos;s (1993) work on selectional restrictions. Resnik evaluated his informatio</context>
</contexts>
<marker>Knight, Hatzivassiloglou, 1995</marker>
<rawString>Kevin Knight and Vasileios Hatzivassiloglou. 1995. Two-level, many paths generation. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pages 252-260, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
<author>Kevin Knight</author>
</authors>
<title>Generation that exploits corpus-based statistical knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics and 36th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>704--710</pages>
<location>Montreal.</location>
<contexts>
<context position="3895" citStr="Langkilde and Knight, 1998" startWordPosition="565" endWordPosition="569">age generation. Consider a generator which has to make a choice between spotless kitchen and flawless kitchen. An empirical model of plausibility could predict that spotless kitchen is a plausible lexical choice, while flawless kitchen is not. Adjective-noun combinations can be hard to generate given their collocational status. For a generator which selects words solely on semantic grounds without taking into account lexical constraints, the choice between spotless kitchen and flawless kitchen may look equivalent. Current work in natural language generation (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998) has shown that corpus-based knowledge can be used to address lexical choice noncompositionally. 30 Proceedings of EACL &apos;99 In the work reported here we acquire plausibility ratings for adjective-noun combinations by eliciting judgements from human subjects, and examine the extent to which different corpus-based models correlate with human intuitions about the &amp;quot;goodness of fit&amp;quot; for a range of adjective-noun combinations. The research presented in this paper is similar in motivation to Resnik&apos;s (1993) work on selectional restrictions. Resnik evaluated his informationtheoretic model of selection</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Irene Langkilde and Kevin Knight. 1998. Generation that exploits corpus-based statistical knowledge. In Proceedings of the 17th International Conference on Computational Linguistics and 36th Annual Meeting of the Association for Computational Linguistics, pages 704-710, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine J Miller</author>
</authors>
<title>Introduction to WordNet: an on-line lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<pages>3--4</pages>
<contexts>
<context position="8140" citStr="Miller et al., 1990" startWordPosition="1189" endWordPosition="1192">proposed models of adjective-noun plausibility will be with randomly-chosen materials. We chose 30 adjectives according to a set of minimal criteria (detailed below), and paired each adjective with a noun selected randomly from three different frequency ranges, which were defined by co-occurrence counts in the 100 million word British National Corpus (BNC; Burnard (1995)). The experimental design thus consisted of one factor, Frequency Band, with three levels (High, Medium, and Low). We chose the adjectives to be minimally ambiguous: each adjective had exactly two senses according to WordNet (Miller et al., 1990) and was unambiguously tagged as &amp;quot;adjective&amp;quot; 98.6% of the time, measured as the number of different part-of-speech tags assigned to the word in the BNC. The 30 adjectives ranged in BNC frequency from 1.9 to 49.1 per million. We identified adjective-noun pairs by using Gsearch (Corley et al., 1999), a chart parser which detects syntactic patterns in a tagged corpus by exploiting a userspecified context free grammar and a syntactic query. Gsearch was run on a lemmatised version of the BNC so as to compile a comprehensive corpus count of all nouns occurring in a modifier-head relationship with ea</context>
<context position="15467" citStr="Miller et al., 1990" startWordPosition="2384" endWordPosition="2387">e frequencies in the BNC) bution of classes p(c) and the posterior distribution p(c I pi) of the argument classes for a particular predicate pi. (2) P (noun I adjective) = f (adjective, noun) f (adjective) c I (3) A(pi, c) = P(c I pi) log P(Pi) P(c) = E P(c I pi) log (4) P(c) In the case of adjective-noun combinations, the selectional association measures the semantic fit of an adjective and each of the semantic classes of the nouns it co-occurs with. We estimated the probabilities P(c I pi) and P(c) similarly to Resnik (1993) by using relative frequencies from the BNC, together with WordNet (Miller et al., 1990) as a source of taxonomic semantic class information. Although the selectional association is a function of the predicate and all semantic classes it potentially selects for, following Resnik&apos;s method for verb-object evaluation, we compared human plausibility judgements with the maximum value for the selectional association for each adjective-noun combination. Table 3 shows the models&apos; predictions for three sample stimuli. The first row contains the geometric mean of the subjects&apos; responses. 3.2 Results The five corpus-based variables were submitted to a correlation analysis (see Tables 5 and </context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine J. Miller. 1990. Introduction to WordNet: an on-line lexical database. International Journal of Lexicography, 3(4):235-244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory L Murphy</author>
</authors>
<title>Noun phrase interpretation and noun combination.</title>
<date>1990</date>
<journal>Journal of Memory and Language,</journal>
<pages>29--3</pages>
<contexts>
<context position="2012" citStr="Murphy (1990)" startWordPosition="284" endWordPosition="285">the bracketed parts of the sentences in (1)). Such experiments typically use an ordinal scale for plausibility (e.g., from 1 to 7). (1) a. [The senior senator regretted the decision] had ever been made public. b. [The senior senator regretted the reporter] had ever seen the report. The majority of research has focussed on investigating the effect of rated plausibility for verb-object combinations in human sentence processing (Garnsey et al., 1997; Pickering and Traxler, 1998). However, plausibility effects have also been observed for adjectivenoun combinations in a head-modifier relationship. Murphy (1990) has shown that typical adjectivenoun phrases (e.g., salty olives) are easier to interpret in comparison to atypical ones (e.g., sweet olives). Murphy provides a schema-based explanation for this finding by postulating that in typical adjective-noun phrases, the adjective modifies part of the noun&apos;s schema and consequently it is understood more quickly, whereas in atypical combinations, the adjective modifies non-schematic aspects of the noun, which leads to interpretation difficulties. Smadja (1991) argues that the reason people prefer strong tea to powerful tea and powerful car to strong car</context>
</contexts>
<marker>Murphy, 1990</marker>
<rawString>Gregory L. Murphy. 1990. Noun phrase interpretation and noun combination. Journal of Memory and Language, 29(3):259-288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
</authors>
<title>Consistent criteria for sense distinctions. Computers and the Humanities,</title>
<date>1999</date>
<note>to appear.</note>
<contexts>
<context position="21333" citStr="Palmer (1999)" startWordPosition="3255" endWordPosition="3256">un with which the predicate co-occurs. Although the improvements suggested by Ribas (1994) try to remedy this by taking the different senses of a given word into account and implementing selectional restrictions in the form of weighted disjunctions, the experiments reported here indicate that methods based on taxonomic knowledge have difficulties capturing the idiosyncratic (i.e., lexicalist) nature of adjective-noun combinations. Finally, idiosyncrasies in WordNet itself influence the performance of Resnik&apos;s model. One problem is that sense distinctions in WordNet are often too fine-grained (Palmer (1999) makes a similar observation). Furthermore, there is considerable redundancy in the definition of word senses. Consider the noun application: it has 27 classes in WordNet which include (code), (coding system), (software), (communication), (writing) and (written communicat ion). It is difficult to see how (code) or (coding system) is not (software) or (writing) is not (written communication). The fine granularity and the degree of redundancy in the taxonomy bias the estimation of the frequency of a given class. Resnik&apos;s model cannot distinguish classes which are genuinely frequent from classes </context>
</contexts>
<marker>Palmer, 1999</marker>
<rawString>Martha Palmer. 1999. Consistent criteria for sense distinctions. Computers and the Humanities, to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin J Pickering</author>
<author>Martin J Traxler</author>
</authors>
<title>Plausibility and recovery from garden paths: An eyetracking study.</title>
<date>1998</date>
<journal>Journal of Experimental Psychology: Learning Memory and Cognition,</journal>
<pages>24--4</pages>
<contexts>
<context position="1879" citStr="Pickering and Traxler, 1998" startWordPosition="264" endWordPosition="267"> of plausibility are typically obtained by asking subjects to rate sentence fragments containing verb-argument combinations (as an example consider the bracketed parts of the sentences in (1)). Such experiments typically use an ordinal scale for plausibility (e.g., from 1 to 7). (1) a. [The senior senator regretted the decision] had ever been made public. b. [The senior senator regretted the reporter] had ever seen the report. The majority of research has focussed on investigating the effect of rated plausibility for verb-object combinations in human sentence processing (Garnsey et al., 1997; Pickering and Traxler, 1998). However, plausibility effects have also been observed for adjectivenoun combinations in a head-modifier relationship. Murphy (1990) has shown that typical adjectivenoun phrases (e.g., salty olives) are easier to interpret in comparison to atypical ones (e.g., sweet olives). Murphy provides a schema-based explanation for this finding by postulating that in typical adjective-noun phrases, the adjective modifies part of the noun&apos;s schema and consequently it is understood more quickly, whereas in atypical combinations, the adjective modifies non-schematic aspects of the noun, which leads to inte</context>
</contexts>
<marker>Pickering, Traxler, 1998</marker>
<rawString>Martin J. Pickering and Martin J. Traxler. 1998. Plausibility and recovery from garden paths: An eyetracking study. Journal of Experimental Psychology: Learning Memory and Cognition, 24(4):940-961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Stuart Resnik</author>
</authors>
<title>Selection and Information: A Class-Based Approach to Lexical Relationships.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="15379" citStr="Resnik (1993)" startWordPosition="2371" endWordPosition="2372">ughty girl 2.94 dog 1.6 lunch .69 Table 2: Example stimuli (with log co-occurrence frequencies in the BNC) bution of classes p(c) and the posterior distribution p(c I pi) of the argument classes for a particular predicate pi. (2) P (noun I adjective) = f (adjective, noun) f (adjective) c I (3) A(pi, c) = P(c I pi) log P(Pi) P(c) = E P(c I pi) log (4) P(c) In the case of adjective-noun combinations, the selectional association measures the semantic fit of an adjective and each of the semantic classes of the nouns it co-occurs with. We estimated the probabilities P(c I pi) and P(c) similarly to Resnik (1993) by using relative frequencies from the BNC, together with WordNet (Miller et al., 1990) as a source of taxonomic semantic class information. Although the selectional association is a function of the predicate and all semantic classes it potentially selects for, following Resnik&apos;s method for verb-object evaluation, we compared human plausibility judgements with the maximum value for the selectional association for each adjective-noun combination. Table 3 shows the models&apos; predictions for three sample stimuli. The first row contains the geometric mean of the subjects&apos; responses. 3.2 Results The</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Philip Stuart Resnik. 1993. Selection and Information: A Class-Based Approach to Lexical Relationships. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francesc Ribas</author>
</authors>
<title>On learning more appropriate selectional restrictions.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Las Cruces, NM.</location>
<contexts>
<context position="20810" citStr="Ribas (1994)" startWordPosition="3180" endWordPosition="3181">ion for hungry pleasure, on the other hand, is given by the class (act) (A(hungry, (act)) = .22). This demonstrates how the method tends to prefer the most frequent classes in the taxonomy (e.g., (entity), (act)) over less frequent, but intuitively more plausible classes (e.g., (f ee ling) for pleasure and (use) for application). This is a general problem with the estimation of the probability of a class of a given predicate in Resnik&apos;s method, as the probability is assumed to be uniform for all classes of a given noun with which the predicate co-occurs. Although the improvements suggested by Ribas (1994) try to remedy this by taking the different senses of a given word into account and implementing selectional restrictions in the form of weighted disjunctions, the experiments reported here indicate that methods based on taxonomic knowledge have difficulties capturing the idiosyncratic (i.e., lexicalist) nature of adjective-noun combinations. Finally, idiosyncrasies in WordNet itself influence the performance of Resnik&apos;s model. One problem is that sense distinctions in WordNet are often too fine-grained (Palmer (1999) makes a similar observation). Furthermore, there is considerable redundancy </context>
</contexts>
<marker>Ribas, 1994</marker>
<rawString>Francesc Ribas. 1994. On learning more appropriate selectional restrictions. In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, Las Cruces, NM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carson T Schiitze</author>
</authors>
<title>The Empirical Base of Linguistics: Grammaticality Judgments and Linguistic Methodology.</title>
<date>1996</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="11181" citStr="Schiitze, 1996" startWordPosition="1692" endWordPosition="1693">uman intuitions, ME employs an interval scale, and therefore produces data for which parametric inferential statistics are valid. ME requires subjects to assign numbers to a series of linguistic stimuli in a proportional fashion. Subjects are first exposed to a modulus item, which they assign an arbitrary number. All other stimuli are rated proportional to the modulus. In this way, each subject can establish their own rating scale, thus yielding maximally fine-graded data and avoiding the known problems with the conventional ordinal scales for linguistic data (Bard et al., 1996; Cowart, 1997; Schiitze, 1996). In the present experiment, subjects were presented with adjective-noun pairs and were asked to rate the degree of adjective-noun fit proportional to a modulus item. The experiment was carried out using WebExp, a set of Java-Classes for administering psycholinguistic studies over the Word-Wide Web (Keller et al., 1998). Subjects first saw a set of instructions that explained the ME technique and included some examples, and had to fill in a short questionnaire including basic demographic information. Each subject saw all 120 items used in the experiment (3 x 30 experimental items and 30 filler</context>
</contexts>
<marker>Schiitze, 1996</marker>
<rawString>Carson T. Schiitze. 1996. The Empirical Base of Linguistics: Grammaticality Judgments and Linguistic Methodology. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>Macrocoding the lexicon with co-occurrence knowledge.</title>
<date>1991</date>
<booktitle>Lexical Acquisition: Using Online Resources to Build a Lexicon,</booktitle>
<pages>165--189</pages>
<editor>In Uri Zernik, editor,</editor>
<publisher>Erlbaum,</publisher>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="2517" citStr="Smadja (1991)" startWordPosition="357" endWordPosition="358">ffects have also been observed for adjectivenoun combinations in a head-modifier relationship. Murphy (1990) has shown that typical adjectivenoun phrases (e.g., salty olives) are easier to interpret in comparison to atypical ones (e.g., sweet olives). Murphy provides a schema-based explanation for this finding by postulating that in typical adjective-noun phrases, the adjective modifies part of the noun&apos;s schema and consequently it is understood more quickly, whereas in atypical combinations, the adjective modifies non-schematic aspects of the noun, which leads to interpretation difficulties. Smadja (1991) argues that the reason people prefer strong tea to powerful tea and powerful car to strong car is neither purely syntactic nor purely semantic, but rather lexical. A similar argument is put forward by Cruse (1986), who observes that the adjective spotless collocates well with the noun kitchen, relatively worse with the noun complexion and not all with the noun taste. According to Cruse, words like spotless have idiosyncratic collocational restrictions: differences in the degree of acceptability of the adjective and its collocates do not seem to depend on the meaning of the individual words. 1</context>
</contexts>
<marker>Smadja, 1991</marker>
<rawString>Frank Smadja. 1991. Macrocoding the lexicon with co-occurrence knowledge. In Uri Zernik, editor, Lexical Acquisition: Using Online Resources to Build a Lexicon, pages 165-189. Erlbaum, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley S Stevens</author>
<author>editor</author>
</authors>
<title>Psychophysics: Introduction to its Perceptual, Neural, and Social Prospects.</title>
<date>1975</date>
<publisher>John Wiley,</publisher>
<location>New York.</location>
<marker>Stevens, editor, 1975</marker>
<rawString>Stanley S. Stevens, editor. 1975. Psychophysics: Introduction to its Perceptual, Neural, and Social Prospects. John Wiley, New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>