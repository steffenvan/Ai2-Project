<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003073">
<title confidence="0.998968">
A Symbolic Approach to Near-Deterministic Surface Realisation using Tree
Adjoining Grammar
</title>
<author confidence="0.952106">
Claire Gardent Eric Kow
</author>
<affiliation confidence="0.75708">
CNRS/LORIA INRIA/LORIA/UHP
Nancy, France Nancy, France
</affiliation>
<email confidence="0.997812">
claire.gardent@loria.fr eric.kow@loria.fr
</email>
<sectionHeader confidence="0.995617" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999673">
Surface realisers divide into those used in
generation (NLG geared realisers) and those
mirroring the parsing process (Reversible re-
alisers). While the first rely on grammars not
easily usable for parsing, it is unclear how
the second type of realisers could be param-
eterised to yield from among the set of pos-
sible paraphrases, the paraphrase appropri-
ate to a given generation context. In this pa-
per, we present a surface realiser which com-
bines a reversible grammar (used for pars-
ing and doing semantic construction) with a
symbolic means of selecting paraphrases.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991090551020408">
In generation, the surface realisation task consists in
mapping a semantic representation into a grammati-
cal sentence.
Depending on their use, on their degree of non-
determinism and on the type of grammar they as-
sume, existing surface realisers can be divided into
two main categories namely, NLG (Natural Lan-
guage Generation) geared realisers and reversible
realisers.
NLG geared realisers are meant as modules in a
full-blown generation system and as such, they are
constrained to be deterministic: a generation system
must output exactly one text, no less, no more. In or-
der to ensure this determinism, NLG geared realisers
generally rely on theories of grammar which sys-
tematically link form to function such as systemic
functional grammar (SFG, (Matthiessen and Bate-
man, 1991)) and, to a lesser extent, Meaning Text
328
Theory (MTT, (Mel’cuk, 1988)). In these theories, a
sentence is associated not just with a semantic rep-
resentation but with a semantic representation en-
riched with additional syntactic, pragmatic and/or
discourse information. This additional information
is then used to constrain the realiser output.1 One
drawback of these NLG geared realisers however, is
that the grammar used is not usually reversible i.e.,
cannot be used both for parsing and for generation.
Given the time and expertise involved in developing
a grammar, this is a non-trivial drawback.
Reversible realisers on the other hand, are meant
to mirror the parsing process. They are used on a
grammar developed for parsing and equipped with a
compositional semantics. Given a string and such
a grammar, a parser will assign the input string
all the semantic representations associated with that
string by the grammar. Conversely, given a seman-
tic representation and the same grammar, a realiser
will assign the input semantics all the strings as-
sociated with that semantics by the grammar. In
such approaches, non-determinism is usually han-
dled by statistical filtering: treebank induced prob-
abilities are used to select from among the possible
paraphrases, the most probable one. Since the most
probable paraphrase is not necessarily the most ap-
propriate one in a given context, it is unclear how-
ever, how such realisers could be integrated into a
generation system.
In this paper, we present a surface realiser which
</bodyText>
<footnote confidence="0.874665">
1On the other hand, one of our reviewers noted that “de-
terminism” often comes more from defaults when input con-
straints are not supplied. One might see these realisers as being
less deterministic than advertised; however, the point is that it
is possible to supply the constraints that ensure determinism.
</footnote>
<note confidence="0.94021">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 328–335,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999837375">
combines reversibility with a symbolic approach to
determinism. The grammar used is fully reversible
(it is used for parsing) and the realisation algorithm
can be constrained by the input so as to ensure a
unique output conforming to the requirement of a
given (generation) context. We show both that the
grammar used has a good paraphrastic power (it
is designed in such a way that grammatical para-
phrases are assigned the same semantic representa-
tions) and that the realisation algorithm can be used
either to generate all the grammatical paraphrases of
a given input or just one provided the input is ade-
quately constrained.
The paper is structured as follows. Section 2 in-
troduces the grammar used namely, a Feature Based
Lexicalised Tree Adjoining Grammar enriched with
a compositional semantics. Importantly, this gram-
mar is compiled from a more abstract specification
(a so-called “meta-grammar”) and as we shall see, it
is this feature which permits a natural and system-
atic coupling of semantic literals with syntactic an-
notations. Section 3 defines the surface realisation
algorithm used to generate sentences from semantic
formulae. This algorithm is non-deterministic and
produces all paraphrases associated by the gram-
mar with the input semantics. We then go on to
show (section 4) how this algorithm can be used
on a semantic input enriched with syntactic or more
abstract control annotations and further, how these
annotations can be used to select from among the
set of admissible paraphrases precisely these which
obey the constraints expressed in the added annota-
tions. Section 5 reports on a quantitative evaluation
based on the use of a core tree adjoining grammar
for French. The evaluation gives an indication of the
paraphrasing power of the grammar used as well as
some evidence of the deterministic nature of the re-
aliser. Section 6 relates the proposed approach to
existing work and section 7 concludes with pointers
for further research.
</bodyText>
<sectionHeader confidence="0.872015" genericHeader="method">
2 The grammar
</sectionHeader>
<bodyText confidence="0.999841407407407">
We use a unification based version of LTAG namely,
Feature-based TAG. A Feature-based TAG (FTAG,
(Vijay-Shanker and Joshi, 1988)) consists of a set
of (auxiliary or initial) elementary trees and of two
tree composition operations: substitution and ad-
junction. Initial trees are trees whose leaves are la-
belled with substitution nodes (marked with a dow-
narrow) or terminal categories. Auxiliary trees are
distinguished by a foot node (marked with a star)
whose category must be the same as that of the root
node. Substitution inserts a tree onto a substitution
node of some other tree while adjunction inserts an
auxiliary tree into a tree. In an FTAG, the tree nodes
are furthermore decorated with two feature struc-
tures (called top and bottom) which are unified dur-
ing derivation as follows. On substitution, the top
of the substitution node is unified with the top of the
root node of the tree being substituted in. On adjunc-
tion, the top of the root of the auxiliary tree is uni-
fied with the top of the node where adjunction takes
place; and the bottom features of the foot node are
unified with the bottom features of this node. At the
end of a derivation, the top and bottom of all nodes
in the derived tree are unified.
To associate semantic representations with natu-
ral language expressions, the FTAG is modified as
proposed in (Gardent and Kallmeyer, 2003).
</bodyText>
<equation confidence="0.9233095">
run(r,s)
⇒ name(j,john), run(r,j), often(r)
</equation>
<figureCaption confidence="0.996765">
Figure 1: Flat Semantics for “John often runs”
</figureCaption>
<bodyText confidence="0.979730533333333">
Each elementary tree is associated with a flat se-
mantic representation. For instance, in Figure 1,2
the trees for John, runs and often are associated with
the semantics name(j,john), run(r,s) and often(x) re-
spectively.
Importantly, the arguments of a semantic functor
are represented by unification variables which occur
both in the semantic representation of this functor
and on some nodes of the associated syntactic tree.
For instance in Figure 1, the semantic index s oc-
curring in the semantic representation of runs also
occurs on the subject substitution node of the asso-
ciated elementary tree.
2Cx/Cx abbreviate a node with category C and a top/bottom
feature structure including the feature-value pair { index : x}.
</bodyText>
<equation confidence="0.898231">
S
NPJs VP-
V
runs
VPx
often VP*
often(x)
NPj
John
name(j,john)
</equation>
<page confidence="0.981704">
329
</page>
<bodyText confidence="0.999254142857143">
The value of semantic arguments is determined by
the unifications resulting from adjunction and sub-
stitution. For instance, the semantic index s in the
tree for runs is unified during substitution with the
semantic indices labelling the root nodes of the tree
for John. As a result, the semantics of John often
runs is
</bodyText>
<equation confidence="0.635184">
(1) {name(j,john),run(r,j),often(r)j
</equation>
<bodyText confidence="0.999954384615385">
The grammar used describes a core fragment of
French and contains around 6 000 elementary trees.
It covers some 35 basic subcategorisation frames
and for each of these frames, the set of argument re-
distributions (active, passive, middle, neuter, reflex-
ivisation, impersonal, passive impersonal) and of ar-
gument realisations (cliticisation, extraction, omis-
sion, permutations, etc.) possible for this frame. As
a result, it captures most grammatical paraphrases
that is, paraphrases due to diverging argument real-
isations or to different meaning preserving alterna-
tion (e.g., active/passive or clefted/non-clefted sen-
tence).
</bodyText>
<sectionHeader confidence="0.921396" genericHeader="method">
3 The surface realiser, GenI
</sectionHeader>
<bodyText confidence="0.9999745">
The basic surface realisation algorithm used is a bot-
tom up, tabular realisation algorithm (Kay, 1996)
optimised for TAGs. It follows a three step strat-
egy which can be summarised as follows. Given an
empty agenda, an empty chart and an input seman-
tics 0:
Lexical selection. Select all elementary trees
whose semantics subsumes (part of) 0. Store
these trees in the agenda. Auxiliary trees
devoid of substitution nodes are stored in a
separate agenda called the auxiliary agenda.
Substitution phase. Retrieve a tree from the
agenda, add it to the chart and try to combine it
by substitution with trees present in the chart.
Add any resulting derived tree to the agenda.
Stop when the agenda is empty.
Adjunction phase. Move the chart trees to the
agenda and the auxiliary agenda trees to the
chart. Retrieve a tree from the agenda, add it
to the chart and try to combine it by adjunction
with trees present in the chart. Add any result-
ing derived tree to the agenda. Stop when the
agenda is empty.
When processing stops, the yield of any syntacti-
cally complete tree whose semantics is 0 yields an
output i.e., a sentence.
The workings of this algorithm can be illustrated
by the following example. Suppose that the input se-
mantics is (1). In a first step (lexical selection), the
elementary trees selected are the ones for John, runs,
often. Their semantics subsumes part of the input se-
mantics. The trees for John and runs are placed on
the agenda, the one for often is placed on the auxil-
iary agenda.
The second step (the substitution phase) consists
in systematically exploring the possibility of com-
bining two trees by substitution. Here, the tree for
John is substituted into the one for runs, and the re-
sulting derived tree for John runs is placed on the
agenda. Trees on the agenda are processed one by
one in this fashion. When the agenda is empty, in-
dicating that all combinations have been tried, we
prepare for the next phase.
All items containing an empty substitution node
are erased from the chart (here, the tree anchored by
runs). The agenda is then reinitialised to the content
of the chart and the chart to the content of the aux-
iliary agenda (here often). The adjunction phase
proceeds much like the previous phase, except that
now all possible adjunctions are performed. When
the agenda is empty once more, the items in the chart
whose semantics matches the input semantics are se-
lected, and their strings printed out, yielding in this
case the sentence John often runs.
</bodyText>
<sectionHeader confidence="0.96723" genericHeader="method">
4 Paraphrase selection
</sectionHeader>
<bodyText confidence="0.999758666666667">
The surface realisation algorithm just sketched is
non-deterministic. Given a semantic formula, it
might produce several outputs. For instance, given
the appropriate grammar for French, the input in (2a)
will generate the set of paraphrases partly given in
(2b-2k).
</bodyText>
<listItem confidence="0.996279555555556">
(2) a. lj:jean(j) la:aime(e,j,m) l.:marie(m)
b. Jean aime Marie
c. Marie est aim´ee par Jean
d. C’est Jean qui aime Marie
e. C’est Jean par qui Marie est aim´ee
f. C’est par Jean qu’est aim´ee Marie
g. C’est Jean dont est aim´ee Marie
h. C’est Jean dont Marie est aim´ee
i. C’est Marie qui est aim´ee par Jean
</listItem>
<page confidence="0.835797">
330
</page>
<bodyText confidence="0.972248438202247">
j. C’est Marie qu’aime Jean any of the paraphrases listed in (2c-2k). Intuitively,
k. C’est Marie que Jean aime the syntactic constraints to be expressed are those
To select from among all possible paraphrases of given in (3b).
a given input, exactly one paraphrase, NLG geared (3) a. Jean aime Marie
realisers use symbolic information to encode syn- b. Canonical Nominal Subject, Active verb form,
tactic, stylistic or pragmatic constraints on the out- Canonical Nominal Object
put. Thus for instance, both REALPRO (Lavoie and c. lj:jean(j) la:aime(e,j,m) l.:marie(m)
Rambow, 1997) and SURGE (Elhadad and Robin,
1999) assume that the input associates semantic lit-
erals with low level syntactic and lexical informa-
tion mostly leaving the realiser to just handle in-
flection, word order, insertion of grammatical words
and agreement. Similarly, KPML (Matthiessen and
Bateman, 1991) assumes access to ideational, inter-
personal and textual information which roughly cor-
responds to semantic, mood/voice, theme/rheme and
focus/ground information.
In what follows, we first show that the semantic
input assumed by the realiser sketched in the previ-
ous section can be systematically enriched with syn-
tactic information so as to ensure determinism. We
then indicate how the satisfiability of this enriched
input could be controlled.
4.1 At most one realisation
In the realisation algorithm sketched in Section 3,
non-determinism stems from lexical ambiguity:3 for
each (combination of) literal(s) l in the input there
usually is more than one TAG elementary tree whose
semantics subsumes l. Thus each (combination of)
literal(s) in the input selects a set of elementary
trees and the realiser output is the set of combi-
nations of selected lexical trees which are licensed
by the grammar operations (substitution and adjunc-
tion) and whose semantics is the input.
One way to enforce determinism consists in en-
suring that each literal in the input selects exactly
one elementary tree. For instance, suppose we want
to generate (2b), repeated here as (3a), rather than
The question is how precisely to formulate these
constraints, how to associate them with the seman-
tic input assumed in Section 3 and how to ensure
that the constraints used do enforce uniqueness of
selection (i.e., that for each input literal, exactly one
elementary tree is selected)? To answer this, we rely
on a feature of the grammar used, namely that each
elementary tree is associated with a linguistically
meaningful unique identifier.
The reason for this is that the grammar is com-
piled from a higher level description where tree frag-
ments are first encapsulated into so-called classes
and then explicitly combined (by inheritance, con-
junction and disjunction) to produce the grammar
elementary trees (cf. (Crabb´e and Duchier, 2004)).
More generally, each elementary tree in the gram-
mar is associated with the set of classes used to pro-
duce that tree and importantly, this set of classes
(we will call this the tree identifier) provides a dis-
tinguishing description (a unique identifier) for that
tree: a tree is defined by a specific combination of
classes and conversely, a specific combination of
classes yields a unique tree.4 Thus the set of classes
associated by the compilation process with a given
elementary tree can be used to uniquely identify that
tree.
Given this, surface realisation is constrained as
follows.
1. Each tree identifier Id(tree) is mapped into a
simplified set of tree properties TPt. There
are two reasons for this simplification. First,
some classes are irrelevant. For instance, the
class used to enforce subject-verb agreement
is needed to ensure this agreement but does
not help in selecting among competing trees.
Second, a given class C can be defined to be
3Given two TAG trees, there might also be several ways
of combining them thereby inducing more non-determinism.
However in practice we found that most of this non-
determinism is due either to over-generation (cases where the
grammar is not sufficiently constrained and allows for one tree
to adjoin to another tree in several places) or to spurious deriva-
tion (distinct derivations with identical semantics). The few re-
maining cases that are linguistically correct are due to varying
modifier positions and could be constrained by a sophisticated
feature decorations in the elementary tree.
4This is not absolutely true as a tree identifier only reflects
part of the compilation process. In practice, they are few ex-
ceptions though so that distinct trees whose tree identifiers are
identical can be manually distinguished.
331
</bodyText>
<listItem confidence="0.876696444444445">
equivalent to the combination of other classes
C1 ... Cn and consequently a tree identifier
containing C, C1 ... Cn can be reduced to in-
clude either C or C1 ... Cn.
2. Each literal li in the input is associated with a
tree property set TPi (i.e., the input we gener-
ate from is enriched with syntactic information)
3. During realisation, for each literal/tree property
pair (li : TPi) in the enriched input semantics,
</listItem>
<bodyText confidence="0.884362666666667">
lexical selection is constrained to retrieve only
those trees (i) whose semantics subsumes li and
(ii) whose tree properties are TPi
Since each literal is associated with a (simpli-
fied) tree identifier and each tree identifier uniquely
identifies an elementary tree, realisation produces at
most one realisation.
Examples 4a-4c illustrates the kind of constraints
used by the realiser.
</bodyText>
<figure confidence="0.993924789473684">
(4) a. l,;:jean(j)/ProperName
la:aime(e,j,m)/[CanonicalNominalSubject,
ActiveVerbForm, CanonicalNominalObject]
l,,,,:marie(m)/ProperName
Jean aime Marie
* Jean est aim´e de Marie
b. l.:le(c)/Det
l.:chien(c)/Noun
ld:dort(e1,c)/RelativeSubject
l,.:ronfle(e2,c)/CanonicalSubject
Le chien qui dort ronfle
* Le chien qui ronfle dort
c. l,;:jean(j)/ProperName
l,:promise(e1,j,m,e2)/[CanonicalNominalSubject,
ActiveVerbForm, CompletiveObject]
l,,,,:marie(m)/ProperName
le2:partir(e2,j)/InfinitivalVerb
Jean promet a` marie de partir
* Jean promet a` marie qu’il partira
</figure>
<subsectionHeader confidence="0.942958">
4.2 At least one realisation
</subsectionHeader>
<bodyText confidence="0.999972053571429">
For a realiser to be usable by a generation system,
there must be some means to ensure that its input
is satisfiable i.e., that it can be realised. How can
this be done without actually carrying out realisation
i.e., without checking that the input is satisfiable?
Existing realisers indicate two types of answers to
that dilemma.
A first possibility would be to draw on (Yang et
al., 1991)’s proposal and compute the enriched in-
put based on the traversal of a systemic network.
More specifically, one possibility would be to con-
sider a systemic network such as NIGEL, precom-
pile all the functional features associated with each
possible traversal of the network, map them onto the
corresponding tree properties and use the resulting
set of tree properties to ensure the satisfiability of
the enriched input.
Another option would be to check the well
formedness of the input at some level of the linguis-
tic theory on which the realiser is based. Thus for
instance, REALPRO assumes as input a well formed
deep syntactic structure (DSyntS) as defined by
Meaning Text Theory (MTT) and similarly, SURGE
takes as input a functional description (FD) which in
essence is an underspecified grammatical structure
within the SURGE grammar. In both cases, there
is no guarantee that the input be satisfiable since
all the other levels of the linguistic theory must be
verified for this to be true. In MTT, the DSyntS
must first be mapped onto a surface syntactic struc-
ture and then successively onto the other levels of
the theory while in SURGE, the input FD can be re-
alised only if it provides consistent information for
a complete top-down traversal of the grammar right
down to the lexical level. In short, in both cases, the
well formedness of the input can be checked with
respect to some criteria (e.g., well formedness of a
deep syntactic structure in MTT, well formedness of
a FD in SURGE) but this well formedness does not
guarantee satisfiability. Nonetheless this basic well
formedness check is important as it provides some
guidance as to what an acceptable input to the re-
aliser should look like.
We adopt a similar strategy and resort to the no-
tion of polarity neutral input to control the well
formedness of the enriched input. The proposal
draws on ideas from (Koller and Striegnitz, 2002;
Gardent and Kow, 2005) and aims to determine
whether for a given input (a set of TAG elemen-
tary trees whose semantics equate the input seman-
tics), syntactic requirements and resources cancel
out. More specifically, the aim is to determine
whether given the input set of elementary trees, each
substitution and each adjunction requirement is sat-
isfied by exactly one elementary tree of the appro-
priate syntactic category and semantic index.
</bodyText>
<page confidence="0.971456">
332
</page>
<bodyText confidence="0.982233903030303">
Roughly,5 the technique consists in (automati- suite includes cases involving the following types of
cally) associating with each elementary tree a po- paraphrases:
larity signature reflecting its substitution/adjunction • Grammatical variations in the realisations of
requirements and resources and in computing the the arguments (cleft, cliticisation, question, rel-
grand polarity of each possible combination of trees ativisation, subject-inversion, etc.) or of the
covering the input semantics. Each such combina- verb (active/passive, impersonal)
tion whose total polarity is non-null is then filtered • Variations in the realisation of modifiers (e.g.,
out (not considered for realisation) as it cannot pos- relative clause vs adjective, predicative vs non-
sibly lead to a valid derivation (either a requirement predicative adjective)
cannot be satisfied or a resource cannot be used). • Variations in the position of modifiers (e.g.,
In the context of a generation system, polarity pre- vs post-nominal adjective)
checking can be used to check the satisfiability of the • Variations licensed by a morpho-derivational
input or more interestingly, to correct an ill formed link (e.g., to arrive/arrival)
input i.e., an input which can be detected as being On a test set of 80 cases, the paraphrastic level
unsatisfiable. varies between 1 and over 50 with an average of
To check a given input, it suffices to compute its 18 paraphrases per input (taking 36 as upper cut
polarity count. If it is non-null, the input is unsatis- off point in the paraphrases count). Figure 5 gives
fiable and should be revised. This is not very useful a more detailed description of the distribution of
however, as the enriched input ensures determinism the paraphrastic variation. In essence, 42% of the
and thereby make realisation very easy, indeed al- sentences with one finite verb accept 1 to 3 para-
most as easy as polarity checking. phrases (cases of intransitive verbs), 44% accept 4
More interestingly, polarity checking can be used to 28 paraphrases (verbs of arity 2) and 13% yield
to suggest ways of fixing an ill formed input. In such more than 29 paraphrases (ditransitives). For sen-
a case, the enriched input is stripped of its control tences containing two finite verbs, the ratio is 5%
annotations, realisation proceeds on the basis of this for 1 to 3 paraphrases, 36% for 4 to 14 paraphrases
simplified input and polarity checking is used to pre- and 59% for more than 14 paraphrases. Finally, sen-
select all polarity neutral combinations of elemen- tences containing 3 finite verbs all accept more than
tary trees. A closest match (i.e. the polarity neutral 29 paraphrases.
combination with the greatest number of control an- Two things are worth noting here. First, the para-
notations in common with the ill formed input) to phrase figures might seem low wrt to e.g., work by
the ill formed input is then proposed as a probably (Velldal and Oepen, 2006) which mentions several
satisfiable alternative. thousand outputs for one given input and an average
5 Evaluation number of realisations per input varying between
To evaluate both the paraphrastic power of the re- 85.7 and 102.2. Admittedly, the French grammar
aliser and the impact of the control annotations on we are using has a much more limited coverage than
non-determinism, we used a graduated test-suite the ERG (the grammar used by (Velldal and Oepen,
which was built by (i) parsing a set of sentences, (ii) 2006)) and it is possible that its paraphrastic power
selecting the correct meaning representations from is lower. However, the counts we give only take
the parser output and (iii) generating from these into account valid paraphrases of the input. In other
meaning representations. The gradation in the test words, overgeneration and spurious derivations are
suite complexity was obtained by partitioning the excluded from the toll. This does not seem to be the
input into sentences containing one, two or three fi- case in (Velldal and Oepen, 2006)’s approach where
nite verbs and by choosing cases allowing for differ- the count seems to include all sentences associated
ent paraphrasing patterns. More specifically, the test by the grammar with the input semantics.
Second, although the test set may seem small it is
important to keep in mind that it represents 80 inputs
5Lack of space prevents us from giving much details here.
We refer the reader to (Koller and Striegnitz, 2002; Gardent and
Kow, 2005) for more details.
333
tions with distinct modifier adjunctions. Both cases
can be handled by modifying the grammar in such
a way that those differences are reflected in the tree
properties.
6 Related work
The approach presented here combines a reversible
grammar realiser with a symbolic approach to para-
phrase selection. We now compare it to existing sur-
faces realisers.
NLG geared realisers. Prominent general
purpose NLG geared realisers include REALPRO,
SURGE, KPML, NITROGEN and HALOGEN. Fur-
thermore, HALOGEN has been shown to achieve
broad coverage and high quality output on a set of 2
400 input automatically derived from the Penn tree-
bank.
The main difference between these and the
present approach is that our approach is based on a
reversible grammar whilst NLG geared realisers are
not. This has several important consequences.
First, it means that one and the same grammar and
lexicon can be used both for parsing and for gener-
ation. Given the complexity involved in developing
such resources, this is an important feature.
Second, as demonstrated in the Redwood Lingo
Treebank, reversibility makes it easy to rapidly cre-
ate very large evaluation suites: it suffices to parse a
set of sentences and select from the parser output the
correct semantics. In contrast, NLG geared realis-
ers either work on evaluation sets of restricted size
(500 input for SURGE, 210 for KPML) or require
the time expensive implementation of a preprocessor
transforming e.g., Penn Treebank trees into a format
suitable for the realisers. For instance, (Callaway,
2003) reports that the implementation of such a pro-
cessor for SURGE was the most time consuming part
of the evaluation with the resulting component con-
taining 4000 lines of code and 900 rules.
Third, a reversible grammar can be exploited to
support not only realisation but also its reverse,
namely semantic construction. Indeed, reversibility
is ensured through a compositional semantics that is,
through a tight coupling between syntax and seman-
tics. In contrast, NLG geared realisers often have
to reconstruct this association in rather ad hoc ways.
Thus for instance, (Yang et al., 1991) resorts to ad
with distinct grammatical and paraphrastic proper-
ties. In effect, these 80 test cases yields 1 528 dis-
tinct well-formed sentences. This figure compares
favourably with the size of the largest regression test
suite used by a symbolic NLG realiser namely, the
SURGE test suite which contains 500 input each
corresponding to a single sentence. It also compares
reasonably with other more recent evaluations (Call-
away, 2003; Langkilde-Geary, 2002) which derive
their input data from the Penn Treebank by trans-
forming each sentence tree into a format suitable for
the realiser (Callaway, 2003). For these approaches,
the test set size varies between roughly 1 000 and
almost 3 000 sentences. But again, it is worth stress-
ing that these evaluations aim at assessing coverage
and correctness (does the realiser find the sentence
used to derive the input by parsing it?) rather than
the paraphrastic power of the grammar. They fail to
provide a systematic assessment of how many dis-
tinct grammatical paraphrases are associated with
each given input.
To verify the claim that tree properties can be used
to ensure determinism (cf. footnote 4), we started
by eliminating from the output all ill-formed sen-
tences. We then automatically associated each well-
formed output with its set of tree properties. Finally,
for each input semantics, we did a systematic pair-
wise comparison of the tree property sets associated
with the input realisations and we checked whether
for any given input, there were two (or more) dis-
tinct paraphrases whose tree properties were the
same. We found that such cases represented slightly
over 2% of the total number of (input,realisations)
pairs. Closer investigation of the faulty data indi-
cates two main reasons for non-determinism namely,
trees with alternating order of arguments and deriva-
334
hoc “mapping tables” to associate substitution nodes
with semantic indices and “fr-nodes” to constrain
adjunction to the correct nodes. More generally, the
lack of a clearly defined compositional semantics in
NLG geared realisers makes it difficult to see how
the grammar they use could be exploited to also sup-
port semantic construction.
Fourth, the grammar can be used both to gener-
ate and to detect paraphrases. It could be used for
instance, in combination with the parser and the se-
mantic construction module described in (Gardent
and Parmentier, 2005), to support textual entailment
recognition or answer detection in question answer-
ing.
Reversible realisers. The realiser presented here
differs in mainly two ways from existing reversible
realisers such as (White, 2004)’s CCG system or
the HPSG ERG based realiser (Carroll and Oepen,
2005).
First, it permits a symbolic selection of the out-
put paraphrase. In contrast, existing reversible re-
alisers use statistical information to select from the
produced output the most plausible paraphrase.
Second, particular attention has been paid to the
treatment of paraphrases in the grammar. Recall
that TAG elementary trees are grouped into families
and further, that the specific TAG we use is com-
piled from a highly factorised description. We rely
on these features to associate one and the same se-
mantic to large sets of trees denoting semantically
equivalent but syntactically distinct configurations
(cf. (Gardent, 2006)).
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999966882352941">
The realiser presented here, GENI, exploits a gram-
mar which is produced semi-automatically by com-
piling a high level grammar description into a Tree
Adjoining Grammar. We have argued that a side-
effect of this compilation process – namely, the as-
sociation with each elementary tree of a set of tree
properties – can be used to constrain the realiser
output. The resulting system combines the advan-
tages of two orthogonal approaches. From the re-
versible approach, it takes the reusability, the ability
to rapidly create very large test suites and the capac-
ity to both generate and detect paraphrases. From
the NLG geared paradigm, it takes the ability to
symbolically constrain the realiser output to a given
generation context.
GENI is free (GPL) software and is available at
http://trac.loria.fr/˜geni.
</bodyText>
<sectionHeader confidence="0.996441" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999844047619048">
Charles B. Callaway. 2003. Evaluating coverage for large sym-
bolic NLG grammars. In 18th IJCAI, pages 811–817, Aug.
J. Carroll and S. Oepen. 2005. High efficiency realization for a
wide-coverage unification grammar. 2nd IJCNLP.
B. Crabb´e and D. Duchier. 2004. Metagrammar redux. In
CSLP, Copenhagen.
M. Elhadad and J. Robin. 1999. SURGE: a comprehensive
plug-in syntactic realization component for text generation.
Computational Linguistics.
C. Gardent and L. Kallmeyer. 2003. Semantic construction in
FTAG. In 10th EACL, Budapest, Hungary.
C. Gardent and E. Kow. 2005. Generating and selecting gram-
matical paraphrases. ENLG, Aug.
C. Gardent and Y. Parmentier. 2005. Large scale semantic con-
struction for Tree Adjoining Grammars. LACL05.
C. Gardent. 2006. Integration d’une dimension semantique
dans les grammaires d’arbres adjoints. TALN.
M. Kay. 1996. Chart Generation. In 34th ACL, pages 200–204,
Santa Cruz, California.
A. Koller and K. Striegnitz. 2002. Generation as dependency
parsing. In 40th ACL, Philadelphia.
I. Langkilde-Geary. 2002. An empirical verification of cover-
age and correctness for a general-purpose sentence genera-
tor. In Proceedings of the INLG.
B. Lavoie and O. Rambow. 1997. RealPro–a fast, portable
sentence realizer. ANLP’97.
C. Matthiessen and J.A. Bateman. 1991. Text generation
and systemic-functional linguistics: experiences from En-
glish and Japanese. Frances Pinter Publishers and St. Mar-
tin’s Press, London and New York.
I.A. Mel’cuk. 1988. Dependency Syntax: Theorie and Prac-
tice. State University Press of New York.
Erik Velldal and Stephan Oepen. 2006. Statistical ranking in
tactical generation. In EMNLP, Sydney, Australia.
K. Vijay-Shanker and AK Joshi. 1988. Feature Structures
Based Tree Adjoining Grammars. Proceedings of the 12th
conference on Computational linguistics, 55:v2.
M. White. 2004. Reining in CCG chart realization. In INLG,
pages 182–191.
G. Yang, K. McKoy, and K. Vijay-Shanker. 1991. From func-
tional specification to syntactic structure. ComputationalIn-
telligence, 7:207–219.
</reference>
<page confidence="0.999162">
335
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.858964">
<title confidence="0.967205">A Symbolic Approach to Near-Deterministic Surface Realisation using Tree Adjoining Grammar</title>
<author confidence="0.998773">Claire Gardent Eric Kow</author>
<affiliation confidence="0.997257">CNRS/LORIA INRIA/LORIA/UHP</affiliation>
<address confidence="0.951666">Nancy, France Nancy, France</address>
<email confidence="0.967822">claire.gardent@loria.freric.kow@loria.fr</email>
<abstract confidence="0.999869071428572">Surface realisers divide into those used in generation (NLG geared realisers) and those mirroring the parsing process (Reversible realisers). While the first rely on grammars not easily usable for parsing, it is unclear how the second type of realisers could be parameterised to yield from among the set of possible paraphrases, the paraphrase appropriate to a given generation context. In this paper, we present a surface realiser which combines a reversible grammar (used for parsing and doing semantic construction) with a symbolic means of selecting paraphrases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Charles B Callaway</author>
</authors>
<title>Evaluating coverage for large symbolic NLG grammars.</title>
<date>2003</date>
<booktitle>In 18th IJCAI,</booktitle>
<pages>811--817</pages>
<contexts>
<context position="26691" citStr="Callaway, 2003" startWordPosition="4293" endWordPosition="4294">n. Given the complexity involved in developing such resources, this is an important feature. Second, as demonstrated in the Redwood Lingo Treebank, reversibility makes it easy to rapidly create very large evaluation suites: it suffices to parse a set of sentences and select from the parser output the correct semantics. In contrast, NLG geared realisers either work on evaluation sets of restricted size (500 input for SURGE, 210 for KPML) or require the time expensive implementation of a preprocessor transforming e.g., Penn Treebank trees into a format suitable for the realisers. For instance, (Callaway, 2003) reports that the implementation of such a processor for SURGE was the most time consuming part of the evaluation with the resulting component containing 4000 lines of code and 900 rules. Third, a reversible grammar can be exploited to support not only realisation but also its reverse, namely semantic construction. Indeed, reversibility is ensured through a compositional semantics that is, through a tight coupling between syntax and semantics. In contrast, NLG geared realisers often have to reconstruct this association in rather ad hoc ways. Thus for instance, (Yang et al., 1991) resorts to ad</context>
</contexts>
<marker>Callaway, 2003</marker>
<rawString>Charles B. Callaway. 2003. Evaluating coverage for large symbolic NLG grammars. In 18th IJCAI, pages 811–817, Aug.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>S Oepen</author>
</authors>
<title>High efficiency realization for a wide-coverage unification grammar. 2nd IJCNLP.</title>
<date>2005</date>
<contexts>
<context position="29954" citStr="Carroll and Oepen, 2005" startWordPosition="4811" endWordPosition="4814">lisers makes it difficult to see how the grammar they use could be exploited to also support semantic construction. Fourth, the grammar can be used both to generate and to detect paraphrases. It could be used for instance, in combination with the parser and the semantic construction module described in (Gardent and Parmentier, 2005), to support textual entailment recognition or answer detection in question answering. Reversible realisers. The realiser presented here differs in mainly two ways from existing reversible realisers such as (White, 2004)’s CCG system or the HPSG ERG based realiser (Carroll and Oepen, 2005). First, it permits a symbolic selection of the output paraphrase. In contrast, existing reversible realisers use statistical information to select from the produced output the most plausible paraphrase. Second, particular attention has been paid to the treatment of paraphrases in the grammar. Recall that TAG elementary trees are grouped into families and further, that the specific TAG we use is compiled from a highly factorised description. We rely on these features to associate one and the same semantic to large sets of trees denoting semantically equivalent but syntactically distinct config</context>
</contexts>
<marker>Carroll, Oepen, 2005</marker>
<rawString>J. Carroll and S. Oepen. 2005. High efficiency realization for a wide-coverage unification grammar. 2nd IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Crabb´e</author>
<author>D Duchier</author>
</authors>
<title>Metagrammar redux.</title>
<date>2004</date>
<booktitle>In CSLP,</booktitle>
<location>Copenhagen.</location>
<marker>Crabb´e, Duchier, 2004</marker>
<rawString>B. Crabb´e and D. Duchier. 2004. Metagrammar redux. In CSLP, Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Elhadad</author>
<author>J Robin</author>
</authors>
<title>SURGE: a comprehensive plug-in syntactic realization component for text generation. Computational Linguistics.</title>
<date>1999</date>
<contexts>
<context position="12550" citStr="Elhadad and Robin, 1999" startWordPosition="2032" endWordPosition="2035">n 330 j. C’est Marie qu’aime Jean any of the paraphrases listed in (2c-2k). Intuitively, k. C’est Marie que Jean aime the syntactic constraints to be expressed are those To select from among all possible paraphrases of given in (3b). a given input, exactly one paraphrase, NLG geared (3) a. Jean aime Marie realisers use symbolic information to encode syn- b. Canonical Nominal Subject, Active verb form, tactic, stylistic or pragmatic constraints on the out- Canonical Nominal Object put. Thus for instance, both REALPRO (Lavoie and c. lj:jean(j) la:aime(e,j,m) l.:marie(m) Rambow, 1997) and SURGE (Elhadad and Robin, 1999) assume that the input associates semantic literals with low level syntactic and lexical information mostly leaving the realiser to just handle inflection, word order, insertion of grammatical words and agreement. Similarly, KPML (Matthiessen and Bateman, 1991) assumes access to ideational, interpersonal and textual information which roughly corresponds to semantic, mood/voice, theme/rheme and focus/ground information. In what follows, we first show that the semantic input assumed by the realiser sketched in the previous section can be systematically enriched with syntactic information so as t</context>
</contexts>
<marker>Elhadad, Robin, 1999</marker>
<rawString>M. Elhadad and J. Robin. 1999. SURGE: a comprehensive plug-in syntactic realization component for text generation. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gardent</author>
<author>L Kallmeyer</author>
</authors>
<title>Semantic construction in FTAG.</title>
<date>2003</date>
<booktitle>In 10th EACL,</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="6947" citStr="Gardent and Kallmeyer, 2003" startWordPosition="1110" endWordPosition="1113"> bottom) which are unified during derivation as follows. On substitution, the top of the substitution node is unified with the top of the root node of the tree being substituted in. On adjunction, the top of the root of the auxiliary tree is unified with the top of the node where adjunction takes place; and the bottom features of the foot node are unified with the bottom features of this node. At the end of a derivation, the top and bottom of all nodes in the derived tree are unified. To associate semantic representations with natural language expressions, the FTAG is modified as proposed in (Gardent and Kallmeyer, 2003). run(r,s) ⇒ name(j,john), run(r,j), often(r) Figure 1: Flat Semantics for “John often runs” Each elementary tree is associated with a flat semantic representation. For instance, in Figure 1,2 the trees for John, runs and often are associated with the semantics name(j,john), run(r,s) and often(x) respectively. Importantly, the arguments of a semantic functor are represented by unification variables which occur both in the semantic representation of this functor and on some nodes of the associated syntactic tree. For instance in Figure 1, the semantic index s occurring in the semantic represent</context>
</contexts>
<marker>Gardent, Kallmeyer, 2003</marker>
<rawString>C. Gardent and L. Kallmeyer. 2003. Semantic construction in FTAG. In 10th EACL, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gardent</author>
<author>E Kow</author>
</authors>
<title>Generating and selecting grammatical paraphrases.</title>
<date>2005</date>
<publisher>ENLG,</publisher>
<contexts>
<context position="20230" citStr="Gardent and Kow, 2005" startWordPosition="3249" endWordPosition="3252">rt, in both cases, the well formedness of the input can be checked with respect to some criteria (e.g., well formedness of a deep syntactic structure in MTT, well formedness of a FD in SURGE) but this well formedness does not guarantee satisfiability. Nonetheless this basic well formedness check is important as it provides some guidance as to what an acceptable input to the realiser should look like. We adopt a similar strategy and resort to the notion of polarity neutral input to control the well formedness of the enriched input. The proposal draws on ideas from (Koller and Striegnitz, 2002; Gardent and Kow, 2005) and aims to determine whether for a given input (a set of TAG elementary trees whose semantics equate the input semantics), syntactic requirements and resources cancel out. More specifically, the aim is to determine whether given the input set of elementary trees, each substitution and each adjunction requirement is satisfied by exactly one elementary tree of the appropriate syntactic category and semantic index. 332 Roughly,5 the technique consists in (automati- suite includes cases involving the following types of cally) associating with each elementary tree a po- paraphrases: larity signat</context>
<context position="25131" citStr="Gardent and Kow, 2005" startWordPosition="4040" endWordPosition="4043">ed by partitioning the excluded from the toll. This does not seem to be the input into sentences containing one, two or three fi- case in (Velldal and Oepen, 2006)’s approach where nite verbs and by choosing cases allowing for differ- the count seems to include all sentences associated ent paraphrasing patterns. More specifically, the test by the grammar with the input semantics. Second, although the test set may seem small it is important to keep in mind that it represents 80 inputs 5Lack of space prevents us from giving much details here. We refer the reader to (Koller and Striegnitz, 2002; Gardent and Kow, 2005) for more details. 333 tions with distinct modifier adjunctions. Both cases can be handled by modifying the grammar in such a way that those differences are reflected in the tree properties. 6 Related work The approach presented here combines a reversible grammar realiser with a symbolic approach to paraphrase selection. We now compare it to existing surfaces realisers. NLG geared realisers. Prominent general purpose NLG geared realisers include REALPRO, SURGE, KPML, NITROGEN and HALOGEN. Furthermore, HALOGEN has been shown to achieve broad coverage and high quality output on a set of 2 400 in</context>
</contexts>
<marker>Gardent, Kow, 2005</marker>
<rawString>C. Gardent and E. Kow. 2005. Generating and selecting grammatical paraphrases. ENLG, Aug.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gardent</author>
<author>Y Parmentier</author>
</authors>
<title>Large scale semantic construction for Tree Adjoining Grammars.</title>
<date>2005</date>
<contexts>
<context position="29664" citStr="Gardent and Parmentier, 2005" startWordPosition="4768" endWordPosition="4771">rminism namely, trees with alternating order of arguments and deriva334 hoc “mapping tables” to associate substitution nodes with semantic indices and “fr-nodes” to constrain adjunction to the correct nodes. More generally, the lack of a clearly defined compositional semantics in NLG geared realisers makes it difficult to see how the grammar they use could be exploited to also support semantic construction. Fourth, the grammar can be used both to generate and to detect paraphrases. It could be used for instance, in combination with the parser and the semantic construction module described in (Gardent and Parmentier, 2005), to support textual entailment recognition or answer detection in question answering. Reversible realisers. The realiser presented here differs in mainly two ways from existing reversible realisers such as (White, 2004)’s CCG system or the HPSG ERG based realiser (Carroll and Oepen, 2005). First, it permits a symbolic selection of the output paraphrase. In contrast, existing reversible realisers use statistical information to select from the produced output the most plausible paraphrase. Second, particular attention has been paid to the treatment of paraphrases in the grammar. Recall that TAG</context>
</contexts>
<marker>Gardent, Parmentier, 2005</marker>
<rawString>C. Gardent and Y. Parmentier. 2005. Large scale semantic construction for Tree Adjoining Grammars. LACL05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gardent</author>
</authors>
<title>Integration d’une dimension semantique dans les grammaires d’arbres adjoints.</title>
<date>2006</date>
<booktitle>In 34th ACL,</booktitle>
<pages>200--204</pages>
<location>Santa Cruz, California.</location>
<contexts>
<context position="30583" citStr="Gardent, 2006" startWordPosition="4910" endWordPosition="4911">mits a symbolic selection of the output paraphrase. In contrast, existing reversible realisers use statistical information to select from the produced output the most plausible paraphrase. Second, particular attention has been paid to the treatment of paraphrases in the grammar. Recall that TAG elementary trees are grouped into families and further, that the specific TAG we use is compiled from a highly factorised description. We rely on these features to associate one and the same semantic to large sets of trees denoting semantically equivalent but syntactically distinct configurations (cf. (Gardent, 2006)). 7 Conclusion The realiser presented here, GENI, exploits a grammar which is produced semi-automatically by compiling a high level grammar description into a Tree Adjoining Grammar. We have argued that a sideeffect of this compilation process – namely, the association with each elementary tree of a set of tree properties – can be used to constrain the realiser output. The resulting system combines the advantages of two orthogonal approaches. From the reversible approach, it takes the reusability, the ability to rapidly create very large test suites and the capacity to both generate and detec</context>
</contexts>
<marker>Gardent, 2006</marker>
<rawString>C. Gardent. 2006. Integration d’une dimension semantique dans les grammaires d’arbres adjoints. TALN. M. Kay. 1996. Chart Generation. In 34th ACL, pages 200–204, Santa Cruz, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Koller</author>
<author>K Striegnitz</author>
</authors>
<title>Generation as dependency parsing.</title>
<date>2002</date>
<booktitle>In 40th ACL,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="20206" citStr="Koller and Striegnitz, 2002" startWordPosition="3245" endWordPosition="3248"> to the lexical level. In short, in both cases, the well formedness of the input can be checked with respect to some criteria (e.g., well formedness of a deep syntactic structure in MTT, well formedness of a FD in SURGE) but this well formedness does not guarantee satisfiability. Nonetheless this basic well formedness check is important as it provides some guidance as to what an acceptable input to the realiser should look like. We adopt a similar strategy and resort to the notion of polarity neutral input to control the well formedness of the enriched input. The proposal draws on ideas from (Koller and Striegnitz, 2002; Gardent and Kow, 2005) and aims to determine whether for a given input (a set of TAG elementary trees whose semantics equate the input semantics), syntactic requirements and resources cancel out. More specifically, the aim is to determine whether given the input set of elementary trees, each substitution and each adjunction requirement is satisfied by exactly one elementary tree of the appropriate syntactic category and semantic index. 332 Roughly,5 the technique consists in (automati- suite includes cases involving the following types of cally) associating with each elementary tree a po- pa</context>
<context position="25107" citStr="Koller and Striegnitz, 2002" startWordPosition="4036" endWordPosition="4039">e suite complexity was obtained by partitioning the excluded from the toll. This does not seem to be the input into sentences containing one, two or three fi- case in (Velldal and Oepen, 2006)’s approach where nite verbs and by choosing cases allowing for differ- the count seems to include all sentences associated ent paraphrasing patterns. More specifically, the test by the grammar with the input semantics. Second, although the test set may seem small it is important to keep in mind that it represents 80 inputs 5Lack of space prevents us from giving much details here. We refer the reader to (Koller and Striegnitz, 2002; Gardent and Kow, 2005) for more details. 333 tions with distinct modifier adjunctions. Both cases can be handled by modifying the grammar in such a way that those differences are reflected in the tree properties. 6 Related work The approach presented here combines a reversible grammar realiser with a symbolic approach to paraphrase selection. We now compare it to existing surfaces realisers. NLG geared realisers. Prominent general purpose NLG geared realisers include REALPRO, SURGE, KPML, NITROGEN and HALOGEN. Furthermore, HALOGEN has been shown to achieve broad coverage and high quality out</context>
</contexts>
<marker>Koller, Striegnitz, 2002</marker>
<rawString>A. Koller and K. Striegnitz. 2002. Generation as dependency parsing. In 40th ACL, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Langkilde-Geary</author>
</authors>
<title>An empirical verification of coverage and correctness for a general-purpose sentence generator.</title>
<date>2002</date>
<booktitle>In Proceedings of the INLG.</booktitle>
<contexts>
<context position="27735" citStr="Langkilde-Geary, 2002" startWordPosition="4458" endWordPosition="4459">een syntax and semantics. In contrast, NLG geared realisers often have to reconstruct this association in rather ad hoc ways. Thus for instance, (Yang et al., 1991) resorts to ad with distinct grammatical and paraphrastic properties. In effect, these 80 test cases yields 1 528 distinct well-formed sentences. This figure compares favourably with the size of the largest regression test suite used by a symbolic NLG realiser namely, the SURGE test suite which contains 500 input each corresponding to a single sentence. It also compares reasonably with other more recent evaluations (Callaway, 2003; Langkilde-Geary, 2002) which derive their input data from the Penn Treebank by transforming each sentence tree into a format suitable for the realiser (Callaway, 2003). For these approaches, the test set size varies between roughly 1 000 and almost 3 000 sentences. But again, it is worth stressing that these evaluations aim at assessing coverage and correctness (does the realiser find the sentence used to derive the input by parsing it?) rather than the paraphrastic power of the grammar. They fail to provide a systematic assessment of how many distinct grammatical paraphrases are associated with each given input. T</context>
</contexts>
<marker>Langkilde-Geary, 2002</marker>
<rawString>I. Langkilde-Geary. 2002. An empirical verification of coverage and correctness for a general-purpose sentence generator. In Proceedings of the INLG.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lavoie</author>
<author>O Rambow</author>
</authors>
<date>1997</date>
<note>RealPro–a fast, portable sentence realizer. ANLP’97.</note>
<marker>Lavoie, Rambow, 1997</marker>
<rawString>B. Lavoie and O. Rambow. 1997. RealPro–a fast, portable sentence realizer. ANLP’97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Matthiessen</author>
<author>J A Bateman</author>
</authors>
<title>Text generation and systemic-functional linguistics: experiences from English and Japanese. Frances Pinter Publishers and St.</title>
<date>1991</date>
<publisher>Martin’s Press,</publisher>
<location>London and New York.</location>
<contexts>
<context position="1583" citStr="Matthiessen and Bateman, 1991" startWordPosition="238" endWordPosition="242">r degree of nondeterminism and on the type of grammar they assume, existing surface realisers can be divided into two main categories namely, NLG (Natural Language Generation) geared realisers and reversible realisers. NLG geared realisers are meant as modules in a full-blown generation system and as such, they are constrained to be deterministic: a generation system must output exactly one text, no less, no more. In order to ensure this determinism, NLG geared realisers generally rely on theories of grammar which systematically link form to function such as systemic functional grammar (SFG, (Matthiessen and Bateman, 1991)) and, to a lesser extent, Meaning Text 328 Theory (MTT, (Mel’cuk, 1988)). In these theories, a sentence is associated not just with a semantic representation but with a semantic representation enriched with additional syntactic, pragmatic and/or discourse information. This additional information is then used to constrain the realiser output.1 One drawback of these NLG geared realisers however, is that the grammar used is not usually reversible i.e., cannot be used both for parsing and for generation. Given the time and expertise involved in developing a grammar, this is a non-trivial drawback</context>
<context position="12811" citStr="Matthiessen and Bateman, 1991" startWordPosition="2071" endWordPosition="2074">y one paraphrase, NLG geared (3) a. Jean aime Marie realisers use symbolic information to encode syn- b. Canonical Nominal Subject, Active verb form, tactic, stylistic or pragmatic constraints on the out- Canonical Nominal Object put. Thus for instance, both REALPRO (Lavoie and c. lj:jean(j) la:aime(e,j,m) l.:marie(m) Rambow, 1997) and SURGE (Elhadad and Robin, 1999) assume that the input associates semantic literals with low level syntactic and lexical information mostly leaving the realiser to just handle inflection, word order, insertion of grammatical words and agreement. Similarly, KPML (Matthiessen and Bateman, 1991) assumes access to ideational, interpersonal and textual information which roughly corresponds to semantic, mood/voice, theme/rheme and focus/ground information. In what follows, we first show that the semantic input assumed by the realiser sketched in the previous section can be systematically enriched with syntactic information so as to ensure determinism. We then indicate how the satisfiability of this enriched input could be controlled. 4.1 At most one realisation In the realisation algorithm sketched in Section 3, non-determinism stems from lexical ambiguity:3 for each (combination of) li</context>
</contexts>
<marker>Matthiessen, Bateman, 1991</marker>
<rawString>C. Matthiessen and J.A. Bateman. 1991. Text generation and systemic-functional linguistics: experiences from English and Japanese. Frances Pinter Publishers and St. Martin’s Press, London and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I A Mel’cuk</author>
</authors>
<title>Dependency Syntax: Theorie and Practice.</title>
<date>1988</date>
<publisher>State University Press of</publisher>
<location>New York.</location>
<marker>Mel’cuk, 1988</marker>
<rawString>I.A. Mel’cuk. 1988. Dependency Syntax: Theorie and Practice. State University Press of New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Velldal</author>
<author>Stephan Oepen</author>
</authors>
<title>Statistical ranking in tactical generation.</title>
<date>2006</date>
<booktitle>In EMNLP,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="23606" citStr="Velldal and Oepen, 2006" startWordPosition="3793" endWordPosition="3796">is of this for 1 to 3 paraphrases, 36% for 4 to 14 paraphrases simplified input and polarity checking is used to pre- and 59% for more than 14 paraphrases. Finally, senselect all polarity neutral combinations of elemen- tences containing 3 finite verbs all accept more than tary trees. A closest match (i.e. the polarity neutral 29 paraphrases. combination with the greatest number of control an- Two things are worth noting here. First, the paranotations in common with the ill formed input) to phrase figures might seem low wrt to e.g., work by the ill formed input is then proposed as a probably (Velldal and Oepen, 2006) which mentions several satisfiable alternative. thousand outputs for one given input and an average 5 Evaluation number of realisations per input varying between To evaluate both the paraphrastic power of the re- 85.7 and 102.2. Admittedly, the French grammar aliser and the impact of the control annotations on we are using has a much more limited coverage than non-determinism, we used a graduated test-suite the ERG (the grammar used by (Velldal and Oepen, which was built by (i) parsing a set of sentences, (ii) 2006)) and it is possible that its paraphrastic power selecting the correct meaning</context>
</contexts>
<marker>Velldal, Oepen, 2006</marker>
<rawString>Erik Velldal and Stephan Oepen. 2006. Statistical ranking in tactical generation. In EMNLP, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>AK Joshi</author>
</authors>
<title>Feature Structures Based Tree Adjoining Grammars.</title>
<date>1988</date>
<booktitle>Proceedings of the 12th conference on Computational linguistics,</booktitle>
<pages>55--2</pages>
<contexts>
<context position="5711" citStr="Vijay-Shanker and Joshi, 1988" startWordPosition="895" endWordPosition="898">e set of admissible paraphrases precisely these which obey the constraints expressed in the added annotations. Section 5 reports on a quantitative evaluation based on the use of a core tree adjoining grammar for French. The evaluation gives an indication of the paraphrasing power of the grammar used as well as some evidence of the deterministic nature of the realiser. Section 6 relates the proposed approach to existing work and section 7 concludes with pointers for further research. 2 The grammar We use a unification based version of LTAG namely, Feature-based TAG. A Feature-based TAG (FTAG, (Vijay-Shanker and Joshi, 1988)) consists of a set of (auxiliary or initial) elementary trees and of two tree composition operations: substitution and adjunction. Initial trees are trees whose leaves are labelled with substitution nodes (marked with a downarrow) or terminal categories. Auxiliary trees are distinguished by a foot node (marked with a star) whose category must be the same as that of the root node. Substitution inserts a tree onto a substitution node of some other tree while adjunction inserts an auxiliary tree into a tree. In an FTAG, the tree nodes are furthermore decorated with two feature structures (called</context>
</contexts>
<marker>Vijay-Shanker, Joshi, 1988</marker>
<rawString>K. Vijay-Shanker and AK Joshi. 1988. Feature Structures Based Tree Adjoining Grammars. Proceedings of the 12th conference on Computational linguistics, 55:v2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M White</author>
</authors>
<title>Reining in CCG chart realization.</title>
<date>2004</date>
<booktitle>In INLG,</booktitle>
<pages>182--191</pages>
<contexts>
<context position="29884" citStr="White, 2004" startWordPosition="4801" endWordPosition="4802"> clearly defined compositional semantics in NLG geared realisers makes it difficult to see how the grammar they use could be exploited to also support semantic construction. Fourth, the grammar can be used both to generate and to detect paraphrases. It could be used for instance, in combination with the parser and the semantic construction module described in (Gardent and Parmentier, 2005), to support textual entailment recognition or answer detection in question answering. Reversible realisers. The realiser presented here differs in mainly two ways from existing reversible realisers such as (White, 2004)’s CCG system or the HPSG ERG based realiser (Carroll and Oepen, 2005). First, it permits a symbolic selection of the output paraphrase. In contrast, existing reversible realisers use statistical information to select from the produced output the most plausible paraphrase. Second, particular attention has been paid to the treatment of paraphrases in the grammar. Recall that TAG elementary trees are grouped into families and further, that the specific TAG we use is compiled from a highly factorised description. We rely on these features to associate one and the same semantic to large sets of tr</context>
</contexts>
<marker>White, 2004</marker>
<rawString>M. White. 2004. Reining in CCG chart realization. In INLG, pages 182–191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Yang</author>
<author>K McKoy</author>
<author>K Vijay-Shanker</author>
</authors>
<title>From functional specification to syntactic structure.</title>
<date>1991</date>
<journal>ComputationalIntelligence,</journal>
<pages>7--207</pages>
<contexts>
<context position="18302" citStr="Yang et al., 1991" startWordPosition="2922" endWordPosition="2925">(e1,j,m,e2)/[CanonicalNominalSubject, ActiveVerbForm, CompletiveObject] l,,,,:marie(m)/ProperName le2:partir(e2,j)/InfinitivalVerb Jean promet a` marie de partir * Jean promet a` marie qu’il partira 4.2 At least one realisation For a realiser to be usable by a generation system, there must be some means to ensure that its input is satisfiable i.e., that it can be realised. How can this be done without actually carrying out realisation i.e., without checking that the input is satisfiable? Existing realisers indicate two types of answers to that dilemma. A first possibility would be to draw on (Yang et al., 1991)’s proposal and compute the enriched input based on the traversal of a systemic network. More specifically, one possibility would be to consider a systemic network such as NIGEL, precompile all the functional features associated with each possible traversal of the network, map them onto the corresponding tree properties and use the resulting set of tree properties to ensure the satisfiability of the enriched input. Another option would be to check the well formedness of the input at some level of the linguistic theory on which the realiser is based. Thus for instance, REALPRO assumes as input </context>
<context position="27277" citStr="Yang et al., 1991" startWordPosition="4385" endWordPosition="4388">. For instance, (Callaway, 2003) reports that the implementation of such a processor for SURGE was the most time consuming part of the evaluation with the resulting component containing 4000 lines of code and 900 rules. Third, a reversible grammar can be exploited to support not only realisation but also its reverse, namely semantic construction. Indeed, reversibility is ensured through a compositional semantics that is, through a tight coupling between syntax and semantics. In contrast, NLG geared realisers often have to reconstruct this association in rather ad hoc ways. Thus for instance, (Yang et al., 1991) resorts to ad with distinct grammatical and paraphrastic properties. In effect, these 80 test cases yields 1 528 distinct well-formed sentences. This figure compares favourably with the size of the largest regression test suite used by a symbolic NLG realiser namely, the SURGE test suite which contains 500 input each corresponding to a single sentence. It also compares reasonably with other more recent evaluations (Callaway, 2003; Langkilde-Geary, 2002) which derive their input data from the Penn Treebank by transforming each sentence tree into a format suitable for the realiser (Callaway, 20</context>
</contexts>
<marker>Yang, McKoy, Vijay-Shanker, 1991</marker>
<rawString>G. Yang, K. McKoy, and K. Vijay-Shanker. 1991. From functional specification to syntactic structure. ComputationalIntelligence, 7:207–219.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>