<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.982373">
N-best Reranking by Multitask Learning
</title>
<author confidence="0.9628">
Kevin Duh Katsuhito Sudoh Hajime Tsukada Hideki Isozaki Masaaki Nagata
</author>
<affiliation confidence="0.775097">
NTT Communication Science Laboratories
</affiliation>
<address confidence="0.918049">
2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237, Japan
</address>
<email confidence="0.987862">
{kevinduh,sudoh,tsukada,isozaki}@cslab.kecl.ntt.co.jp
nagata.masaaki@lab.ntt.co.jp
</email>
<sectionHeader confidence="0.993748" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999967714285714">
We propose a new framework for N-best
reranking on sparse feature sets. The idea
is to reformulate the reranking problem as
a Multitask Learning problem, where each
N-best list corresponds to a distinct task.
This is motivated by the observation that
N-best lists often show significant differ-
ences in feature distributions. Training a
single reranker directly on this heteroge-
nous data can be difficult.
Our proposed meta-algorithm solves this
challenge by using multitask learning
(such as ℓ1/ℓ2 regularization) to discover
common feature representations across N-
best lists. This meta-algorithm is simple to
implement, and its modular approach al-
lows one to plug-in different learning algo-
rithms from existing literature. As a proof
of concept, we show statistically signifi-
cant improvements on a machine transla-
tion system involving millions of features.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.959630901960784">
Many natural language processing applications,
such as machine translation (MT), parsing, and
language modeling, benefit from the N-best
reranking framework (Shen et al., 2004; Collins
and Koo, 2005; Roark et al., 2007). The advan-
tage of N-best reranking is that it abstracts away
the complexities of first-pass decoding, allowing
the researcher to try new features and learning al-
gorithms with fast experimental turnover.
In the N-best reranking scenario, the training
data consists of sets of hypotheses (i.e. N-best
lists) generated by a first-pass system, along with
their labels. Given a new N-best list, the goal is
to rerank it such that the best hypothesis appears
near the top of the list. Existing research have fo-
cused on training a single reranker directly on the
entire data. This approach is reasonable if the data
is homogenous, but it fails when features vary sig-
nificantly across different N-best lists. In partic-
ular, when one employs sparse feature sets, one
seldom finds features that are simultaneously ac-
tive on multiple N-best lists.
In this case, we believe it is more advantageous
to view the N-best reranking problem as a multi-
task learning problem, where each N-best list cor-
responds to a distinct task. Multitask learning, a
subfield of machine learning, focuses on how to
effectively train on a set of different but related
datasets (tasks). Our heterogenous N-best list data
fits nicely with this assumption.
The contribution of this work is three-fold:
1. We introduce the idea of viewing N-best
reranking as a multitask learning problem.
This view is particularly apt to any general
reranking problem with sparse feature sets.
2. We propose a simple meta-algorithm that
first discovers common feature representa-
tions across N-bests (via multitask learning)
before training a conventional reranker. Thus
it is easily applicable to existing systems.
3. We demonstrate that our proposed method
outperforms the conventional reranking ap-
proach on a English-Japanese biomedical
machine translation task involving millions
of features.
The paper is organized as follows: Section 2 de-
scribes the feature sparsity problem and Section 3
presents our multitask solution. The effectiveness
of our proposed approach is validated by experi-
ments demonstrated in Section 4. Finally, Sections
5 and 6 discuss related work and conclusions.
</bodyText>
<sectionHeader confidence="0.8531" genericHeader="method">
2 The Problem of Sparse Feature Sets
</sectionHeader>
<bodyText confidence="0.9830745">
For concreteness, we will describe N-best rerank-
ing in terms of machine translation (MT), though
</bodyText>
<page confidence="0.985148">
375
</page>
<note confidence="0.9617075">
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 375–383,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9988606">
our approach is agnostic to the application. In MT
reranking, the goal is to translate a foreign lan-
guage sentence f into an English sentence e by
picking from a set of likely translations. A stan-
dard approach is to use a linear model:
</bodyText>
<equation confidence="0.88991">
e� = arg max w - h(e, f) (1)
e∈N(D
</equation>
<bodyText confidence="0.977755117647059">
where h(e, f) is a D-dimensional feature vector,
w is the weight vector to be trained, and N(f) is
the set of likely translations of f, i.e. the N-best
list. The feature h(e, f) can be any quantity de-
fined in terms of the sentence pair, such as transla-
tion model and language model probabilities.
Here we are interested in situations where the
feature definitions can be quite sparse. A com-
mon methodology in reranking is to first design
feature templates based on linguistic intuition and
domain knowledge. Then, numerous features are
instantiated based on the training data seen. For
example, the work of (Watanabe et al., 2007) de-
fines feature templates based on bilingual word
alignments, which lead to extraction of heavily-
lexicalized features of the form:
h(e, f) = { 1 if foreign word “Monsieur”
</bodyText>
<sectionHeader confidence="0.533578" genericHeader="method">
0 otherwise
</sectionHeader>
<bodyText confidence="0.998113875">
and English word “Mr.”
co-occur in e,f
One can imagine that such features are sparse
because it may only fire for input sentences that
contain the word “Monsieur”. For all other input
sentences, it is an useless, inactive feature.
Another common feature involves word ngram
templates, for example:
</bodyText>
<equation confidence="0.661511666666667">
h(e, f) = { 1 if English trigram
0 otherwise
“Mr. Smith said” occurs in e
</equation>
<bodyText confidence="0.999922571428571">
In this case, all possible trigrams seen in the N-
best list are extracted as features. One can see
that this kind of feature can be very sensitive to
the first-pass decoder: if the decoder has loose re-
ordering constraints, then we may extract expo-
nentially many nonsense ngram features such as
“Smith said Mr.” and “said Smith Mr.”. Granted,
the reranker training algorithm may learn that
these nonsense ngrams are indicative of poor hy-
potheses, but it is unlikely that the exact same non-
sense ngrams will appear given a different test sen-
tence.
In summary, the following issues compound to
create extremely sparse feature sets:
</bodyText>
<listItem confidence="0.958655666666667">
1. Feature templates are heavily-lexicalized,
which causes the number of features to grow
unbounded as the the amount of data in-
creases.
2. The input (f) has high variability (e.g. large
vocabulary size), so that features for different
inputs are rarely shared.
3. The N-best list output also exhibits high vari-
ability (e.g. many different word reorder-
ings). Larger N may improve reranking per-
formance, but may also increase feature spar-
sity.
</listItem>
<bodyText confidence="0.9928608">
When the number of features is too large, even
popular reranking algorithms such as SVM (Shen
et al., 2004) and MIRA (Watanabe et al., 2007;
Chiang et al., 2009) may fail. Our goal here is to
address this situation.
</bodyText>
<sectionHeader confidence="0.977419" genericHeader="method">
3 Proposed Reranking Framework
</sectionHeader>
<bodyText confidence="0.9997704">
In the following, we first give an intuitive com-
parison between single vs. multiple task learning
(Section 3.1), before presenting the general meta-
algorithm (Section 3.2) and particular instantia-
tions (Section 3.3).
</bodyText>
<subsectionHeader confidence="0.999694">
3.1 Single vs. Multiple Tasks
</subsectionHeader>
<bodyText confidence="0.9956746">
Given a set of I input sentences {f&apos;}, the training
data for reranking consists of a set of I N-best lists
{(H&apos;, y&apos;)}&apos;=1,...,z, where H&apos; are features and y&apos;
are labels.
To clarify the notation:1 for an input sentence
f&apos;, there is a N-best list N(f&apos;). For a N-best list
N(f&apos;), there are N feature vectors corresponding
to the N hypotheses, each with dimension D. The
collection of feature vectors for N(f&apos;) is repre-
sented by H&apos;, which can be seen as a D x N
matrix. Finally, the N-dimensional vector of la-
bels y&apos; indicates the translation quality of each hy-
pothesis in N(f&apos;). The purpose of the reranker
training algorithm is to find good parameters from
{(H&apos;, y&apos;)}.
</bodyText>
<footnote confidence="0.999287333333333">
1Generally we use bold font h to represent a vector, bold-
capital font H to represent a matrix. Script h and h(·) may
be scalar, function, or sentence (depends on context).
</footnote>
<page confidence="0.999003">
376
</page>
<bodyText confidence="0.999792333333333">
The conventional method of training a single
reranker (single task formulation) involves opti-
mizing a generic objective such as:
</bodyText>
<equation confidence="0.970151">
L(w, Hi, yi) + λΩ(w) (4)
</equation>
<bodyText confidence="0.9999535">
where w ∈ RD is the reranker trained on all lists,
and L(·) is some loss function. Ω(w) is an op-
tional regularizer, whose effect is traded-off by the
constant λ. For example, the SVM reranker for
MT (Shen et al., 2004) defines L(·) to be some
function of sentence-level BLEU score, and Ω(w)
to be the large margin regularizer.2
On the other hand, multitask learning involves
solving for multiple weights, w1, w2, . . . ,wI,
one for each N-best list. One class of multitask
learning algorithms, Joint Regularization, solves
the following objective:
</bodyText>
<equation confidence="0.914813">
L(wi, Hi, yi) + λΩ(w1, .., wI)
(5)
</equation>
<bodyText confidence="0.998369782608695">
The loss decomposes by task but the joint regu-
larizer Ω(w1, .., wI) couples together the different
weight parameters. The key is to note that multi-
ple weights allow the algorithm to fit the heteroge-
nous data better, compared to a single weight vec-
tor. Yet these weights are still tied together so that
some information can be shared across N-best lists
(tasks).
One instantiation of Eq. 5 is ℓ1/ℓ2 regular-
ization: Ω(w1,..,wI) °_ ||W||1,2, where W =
[w1|w2|... |wI]T is a I-by-D matrix of stacked
weight vectors. The norm is computed by first tak-
ing the 2-norm on columns of W, then taking a
1-norm on the resulting D-length vector. This en-
courages the optimizer to choose a small subset of
features that are useful across all tasks.
For example, suppose two different sets of
weight vectors Wa and Wb for a 2 lists, 4 fea-
tures reranking problem. The ℓ1/ℓ2 norm for Wa
is 14; the ℓ1/ℓ2 norm for Wb is 12. If both have
the same loss L(·) in Eq. 5, the multitask opti-
mizer would prefer Wb since more features are
shared:
</bodyText>
<equation confidence="0.938356666666667">
W. : [ 4 0 0 3 [ 4 3 0 0
0 4 3 0] Wb : 0 4 3 0]
4 4 3 314 4 5 3 012
</equation>
<footnote confidence="0.998847">
2In MT, evaluation metrics like BLEU do not exactly de-
compose across sentences, so for some training algorithms
this loss is an approximation.
</footnote>
<subsectionHeader confidence="0.992642">
3.2 Proposed Meta-algorithm
</subsectionHeader>
<bodyText confidence="0.947223">
We are now ready to present our general reranking
meta-algorithm (see Algorithm 1), termed Rerank-
ing by Multitask Learning (RML) .
Algorithm 1 Reranking by Multitask Learning
Input: N-best data {(Hi, yi)}i=1,...,I
</bodyText>
<listItem confidence="0.984930285714286">
Output: Common feature representation hc(e, f)
and weight vector wc
1: [optional] RandomHashing({Hi})
2: W = MultitaskLearn({(Hi, yi)})
3: hc = ExtractCommonFeature(W)
4: {Hic} = RemapFeature({Hi}, hc)
5: wc = ConventionalReranker({(Hi c, yi)})
</listItem>
<bodyText confidence="0.999976176470588">
The first step, random hashing, is optional. Ran-
dom hashing is an effective trick for reducing the
dimension of sparse feature sets without suffer-
ing losses in fidelity (Weinberger et al., 2009;
Ganchev and Dredze, 2008). It works by collaps-
ing random subsets of features. This step can be
performed to speed-up multitask learning later. In
some cases, the original feature dimension may be
so large that hashed representations may be neces-
sary.
The next two steps are key. A multitask learn-
ing algorithm is run on the N-best lists, and a com-
mon feature space shared by all lists is extracted.
For example, if one uses the multitask objective
of Eq. 5, the result of step 2 is a set of weights
W. ExtractCommonFeature(W) then returns the
feature id’s (either from original or hashed repre-
sentation) that receive nonzero weight in any of
W.3 The new features hc(e, f) are expected to
have lower dimension than the original features
h(e, f). Section 3.3 describes in detail different
multitask methods that can be plugged-in to this
step.
The final two steps involve a conventional
reranker. In step 4, we remap the N-best list
data according to the new feature representations
hc(e, f). In step 5, we train a conventional
reranker on this common representation, which by
now should have overcome sparsity issues. Us-
ing a conventional reranker at the end allows us
to exploit existing rerankers designed for specific
NLP applications. In a sense, our meta-algorithm
simply involves a change of representation for
the conventional reranking scenario, where the
</bodyText>
<footnote confidence="0.849775">
3For example in Wb, features 1-3 have nonzero weights
and are extracted. Feature 4 is discarded.
</footnote>
<figure confidence="0.70116775">
I
i=1
arg min
w
arg min
w ,..,wz
I
i=1
</figure>
<page confidence="0.983262">
377
</page>
<bodyText confidence="0.9994745">
new representation is found by multitask methods
which are well-suited to heterogenous data.
</bodyText>
<subsectionHeader confidence="0.99834">
3.3 Multitask Objective Functions
</subsectionHeader>
<bodyText confidence="0.999580166666667">
Here, we describe various multitask methods that
can be plugged in Step 2 of Algorithm 1. Our
goal is to demonstrate that a wide range of existing
methods from the multitask learning literature can
be brought to our problem. We categorize multi-
task methods into two major approaches:
</bodyText>
<listItem confidence="0.882406">
1. Joint Regularization: Eq. 5 is an exam-
</listItem>
<bodyText confidence="0.9098986">
ple of joint regularization, with E1/E2 norm being
a particular regularizer. The idea is to use the reg-
ularizer to ensure that the learned functions of re-
lated tasks are close to each other. The popular
E1/E2 objective can be optimized by various meth-
ods, such as boosting (Obozinski et al., 2009) and
convex programming (Argyriou et al., 2008). Yet
another regularizer is the E1/E∞ norm (Quattoni et
al., 2009), which replaces the 2-norm with a max.
One could also define a regularizer to ensure
that each task-specific wi is close to some average
parameter, e.g. Ei ||wi − wav9||2. If we inter-
pret wav9 as a prior, we begin to see links to Hier-
archical Bayesian methods for multitask learning
(Finkel and Manning, 2009; Daume, 2009).
</bodyText>
<listItem confidence="0.943894333333333">
2. Shared Subspace: This approach assumes
that there is an underlying feature subspace that
is common to all tasks. Early works on multi-
</listItem>
<bodyText confidence="0.977229588235294">
task learning implement this by neural networks,
where different tasks have different output layers
but share the same hidden layer (Caruana, 1997).
Another method is to write the weight vector
as two parts w = [u; v] and let the task-specific
function be uT · h(e, f) + vT · O · h(e, f) (Ando
and Zhang, 2005). O is a D′ xD matrix that maps
the original features to a subspace common to all
tasks. The new feature representation is computed
by the projection h,(e, f) °= O · h(e, f).
Multitask learning is a vast field and relates to
areas like collaborative filtering (Yu and Tresp,
2005) and domain adaptation. Most methods as-
sume some common representation and is thus ap-
plicable to our framework. The reader is urged to
refer to citations in, e.g. (Argyriou et al., 2008) for
a survey.
</bodyText>
<sectionHeader confidence="0.998813" genericHeader="method">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999413666666667">
As a proof of concept, we perform experiments
on a MT system with millions of features. We
use a hierarchical phrase-based system (Chiang,
</bodyText>
<figure confidence="0.9970129">
100
10−1
10−2
10−3
10−4
10−5
10−6
10−7
100 101 102 103 104
x
</figure>
<figureCaption confidence="0.784906">
Figure 1: This log-log plot shows that there are
many rare features and few common features. The
</figureCaption>
<bodyText confidence="0.993006115384615">
probability that a feature occurs in x number of N-
best lists behaves according to the power-law x−α,
where α = 2.28.
2007) to generate N-best lists (N=100). Sparse
features used in reranking are extracted according
to (Watanabe et al., 2007). Specifically, the major-
ity are lexical features involving joint occurrences
of words within the N-best lists and source sen-
tences.
It is worth noting that the fact that the first pass
system is a hierarchical system is not essential to
the feature extraction step; similar features can be
extracted with other systems as first-pass, e.g. a
phrase-based system. That said, the extent of the
feature sparsity problem may depend on the per-
formance of the first-pass system.
We experiment with medical domain MT, where
large numbers of technical vocabulary cause spar-
sity challenges. Our corpora consists of English
abstracts from PubMed4 with their Japanese trans-
lations. The first-pass system is built on hierarchi-
cal phrases extracted from 17k sentence pairs and
target (Japanese) language models trained on 800k
medical-domain sentences. For our reranking ex-
periments, we used 500 lists as the training set5,
500 lists as held-out, and another 500 for test.
</bodyText>
<subsectionHeader confidence="0.991907">
4.1 Data Characteristics
</subsectionHeader>
<bodyText confidence="0.9998506">
We present some statistics to illustrate the feature
sparsity problem: From 500 N-best lists, we ex-
tracted a total of 2.4 million distinct features. By
type, 75% of these features occur in only one N-
best list in the dataset. Less than 3% of features
</bodyText>
<footnote confidence="0.976502166666667">
4A database of the U.S. National Library of Medicine.
5In MT, training data for reranking is sometimes referred
to as “dev set” to distinguish from the data used in first-pass.
Also, while the 17k bitext may seem small compared to other
MT work, we note that 1st pass translation quality (around 28
BLEU) is high enough to evaluate reranking methods.
</footnote>
<equation confidence="0.677724">
P(feature occurs in x lists)
</equation>
<page confidence="0.986927">
378
</page>
<bodyText confidence="0.999953322580645">
occur in ten or more lists. The distribution of fea-
ture occurrence is clearly Zipfian, as seen in the
power-law plot in Figure 1.
We can also observe the feature growth rate (Ta-
ble 1). This is the number of new features intro-
duced when an additional N-best list is seen. It is
important to note that on average, 2599 new fea-
tures are added everytime a new N-best list is seen.
This is as much as 2599/4188 = 62% of the ac-
tive features. Imagine an online training algorithm
(e.g. MIRA or perceptron) on this kind of data:
whenever a loss occurs and we update the weight
vector, less than half of the weight vector update
applies to data we have seen thus far. Herein lies
the potential for overfitting.
From observing the feature grow rate, one may
hypothesize that adding large numbers of N-best
lists to the training set (500 in the experiments
here) may not necessarily improve results. While
adding data potentially improves the estimation
process, it also increases the feature space dramat-
ically. Thus we see the need for a feature extrac-
tion procedure.
(Watanabe et al., 2007) also reports the possibil-
ity of overfitting in their dataset (Arabic-English
newswire translation), especially when domain
differences are present. Here we observe this ten-
dency already on the same domain, which is likely
due to the highly-specialized vocabulary and the
complex sentence structures common in research
paper abstracts.
</bodyText>
<subsectionHeader confidence="0.98635">
4.2 MT Results
</subsectionHeader>
<bodyText confidence="0.999371">
Our goal is to compare different feature represen-
tations in reranking: The baseline reranker uses
the original sparse feature representation. This is
compared to feature representations discovered by
three different multitask learning methods:
</bodyText>
<listItem confidence="0.9783035">
• Joint Regularization (Obozinski et al., 2009)
• Shared Subspace (Ando and Zhang, 2005)
• Unsupervised Multitask Feature Selection
(Abernethy et al., 2007).6
</listItem>
<bodyText confidence="0.9979235">
We use existing implementations of the above
methods.7 The conventional reranker (Step 5, Al-
</bodyText>
<footnote confidence="0.98926075">
6This is not a standard multitask algorithm since most
multitask algorithms are supervised. We include it to see
if unsupervised or semi-supervised multitask algorithms is
promising. Intuitively, the method tries to select subsets of
features that are correlated across multiple tasks using ran-
dom sampling (MCMC). Features that co-occur in different
tasks form a high probability path.
7Available at http://multitask.cs.berkeley.edu
</footnote>
<table confidence="0.999790461538462">
Nbest id #NewFt #SoFar #Active
1 3900 3900 3900
2 7535 11435 7913
3 6078 17513 7087
4 3868 21381 4747
5 1896 23277 2645
6 3542 26819 4747
....
100 2440 289118 4299
101 1639 290757 2390
102 3468 294225 4755
103 2350 296575 3824
Average 2599 – 4188
</table>
<tableCaption confidence="0.998734">
Table 1: Feature growth rate: For N-best list i in
</tableCaption>
<bodyText confidence="0.993709518518518">
the table, we have (#NewFt = number of new fea-
tures introduced since N-best i − 1) ; (#SoFar =
Total number of features defined so far); and (#Ac-
tive = number of active features for N-best i). E.g.,
we extracted 7535 new features from N-best 2;
combined with the 3900 from N-best 1, the total
features so far is 11435.
gorithm 1) used in all cases is SVM,,,k.8 Our
initial experiments show that the SVM baseline
performance is comparable to MIRA training, so
we use SVM throughout. The labels for the SVM
are derived as in (Shen et al., 2004), where top
10% of hypotheses by smoothed sentence-BLEU
is ranked before the bottom 90%. All multitask
learning methods work on hashed features of di-
mension 4000 (Step 1, Algorithm 1). This speeds
up the training process.
All hyperparameters of the multitask method
are tuned on the held-out set. In particular, the
most important is the number of common features
to extract, which we pick from {250, 500, 1000}.
Table 2 shows the results by BLEU (Papineni
et al., 2002) and PER. The Oracle results are ob-
tained by choosing the best hypothesis per N-best
list by sentence-level BLEU, which achieved 36.9
BLEU in both Train and Test. A summary of our
observations is:
</bodyText>
<listItem confidence="0.936713666666667">
1. The baseline (All sparse features) overfits. It
achieves the oracle BLEU score on the train
set (36.9) but performs poorly on the test
(28.6).
2. Similar overfitting occurs when traditional ℓ1
regularization is used to select features on
</listItem>
<footnote confidence="0.997761">
8Available at http://svmlight.joachims.org
</footnote>
<page confidence="0.999022">
379
</page>
<bodyText confidence="0.964033444444444">
the sparse feature representation9. ℓ1 reg-
ularization is a good method of handling
sparse features for classification problems,
but in reranking the lack of tying between
lists makes this regularizer inappropriate. A
small set of around 1200 features are chosen:
they perform well independently on each task
in the training data, but there is little sharing
with the test data.
3. All three multitask methods obtained features
that outperformed the baseline. The BLEU
scores are 28.8, 28.9, 29.1 for Unsupervised
Feature Selection, Joint Regularization, and
Shared Subspace, respectively, which all out-
perform the 28.6 baseline. All improvements
are statistically significant by bootstrap sam-
pling test (1000 samples, p &lt; 0.05) (Zhang
et al., 2004).
</bodyText>
<listItem confidence="0.78767175">
4. Shared Subspace performed the best. We
conjecture this is because its feature projec-
tion can create new feature combinations that
is more expressive than the feature selection
used by the two other methods.
5. PER results are qualitatively similar to BLEU
results.
6. As a further analysis, we are interested in see-
</listItem>
<bodyText confidence="0.95625985">
ing whether multitask learning extracts novel
features, especially those that have low fre-
quency. Thus, we tried an additional feature
representation (feature threshold) which only
keeps features that occur in more than x N-
bests, and concatenate these high-frequency
features to the multitask features. The fea-
ture threshold alone achieves nice BLEU re-
sults (29.0 for x &gt; 10), but the combination
outperforms it by statistically significant mar-
gins (29.3-29.6). This implies that multitask
learning is extracting features that comple-
ment well with high frequency features.
For the multitask features, improvements of 0.2
to 1.0 BLEU are modest but consistent. Figure
2 shows the BLEU of bootstrap samples obtained
as part of the statistical significance test. We see
that multitask almost never underperform base-
line in any random sampling of the data. This im-
plies that the proposed meta-algorithm is very sta-
</bodyText>
<footnote confidence="0.9956485">
9Optimized by the Vowpal Wabbit toolkit:
http://hunch.net/vw/
</footnote>
<bodyText confidence="0.965902055555556">
ble, i.e. it is not a method that sometimes improves
and sometimes degrades.
Finally, a potential question to ask is: what
kinds of features are being selected by the
multitask learning algorithms? We found that
that two kinds of features are usually selected:
one is general features that are not lexicalized,
such as “count of phrases”, “count of dele-
tions/insertions”, “number of punctuation marks”.
The other kind is lexicalized features, such as
those in Equations 2 and 3, but involving functions
words (like the Japanese characters “wa”, “ga”,
“ni”, “de”) or special characters (such as numeral
symbol and punctuation). These are features that
can be expected to be widely applicable, and it is
promising that multitask learning is able to recover
these from the millions of potential features. 10
BLEU(shared subspace)−BLEU(baseline sparse feature)
</bodyText>
<figureCaption confidence="0.92716025">
Figure 2: BLEU difference of 1000 bootstrap sam-
ples. 95% confidence interval is [.15, .90] The
proposed approach therefore seems to be a stable
method.
</figureCaption>
<sectionHeader confidence="0.997562" genericHeader="method">
5 Related Work in NLP
</sectionHeader>
<bodyText confidence="0.844761666666667">
Previous reranking work in NLP can be classified
into two different research focuses:
1. Engineering better features: In MT, (Och
and others, 2004) investigates features extracted
from a wide variety of syntactic representations,
such as parse tree probability on the outputs. Al-
though their results show that the proposed syntac-
tic features gave little improvements, they point to
some potential reasons, such as domain mismatch
for the parser and overfitting by the reranking
10Note: In order to do this analysis, we needed to run Joint
Regularization on the original feature representation, since
the hashed representations are less interpretable. This turns
out to be computationally prohibitive in the time being so we
only ran on a smaller data set of 50 lists. Recently new op-
timization methods that are orders of magnitude faster have
been developed (Liu et al., 2009), which makes larger-scale
experiments possible.
</bodyText>
<figure confidence="0.996484555555556">
Bootstrap samples
300
250
200
150
100
50
0
−0.2 0 0.2 0.4 0.6 0.8 1 1.2
</figure>
<page confidence="0.982432">
380
</page>
<table confidence="0.999633888888889">
Feature Representation #Feature Train Test Test
BLEU BLEU PER
(baselines)
First pass 20 29.5 28.5 38.3
All sparse features (Main baseline) 2.4M 36.9 28.6 38.2
All sparse features w/ ℓ, regularization 1200 36.5 28.5 38.6
Random hash representation 4000 33.0 28.5 38.2
(multitask learning)
Unsupervised FeatureSelect 500 32.0 28.8 37.7
Joint Regularization 250 31.8 28.9 37.5
Shared Subspace 1000 32.9 29.1 37.3
(combination w/ high-frequency features) 3k 31.7 27.9 38.2
(a) Feature threshold x &gt; 100
(b) Feature threshold x &gt; 10 60k 35.8 29.0 37.9
Unsupervised FeatureSelect + (b) 60.5k 36.2 29.3 37.6
Joint Regularization + (b) 60.25k 36.1 29.4 37.5
Shared Subspace + (b) 61k 36.2 29.6 37.3
Oracle (best possible) – 36.9 36.9 33.1
</table>
<tableCaption confidence="0.8473375">
Table 2: Results for different feature sets, with corresponding feature size and train/test BLEU/PER. All
multitask features give statistically significant improvements over the baselines (boldfaced), e.g. Shared
Subspace: 29.1 BLEU vs Baseline: 28.6 BLEU. Combinations of multitask features with high frequency
features also give significant improvements over the high frequency features alone.
</tableCaption>
<bodyText confidence="0.9925543125">
method. Recent work by (Chiang et al., 2009) de-
scribes new features for hierarchical phrase-based
MT, while (Collins and Koo, 2005) describes
features for parsing. Evaluation campaigns like
WMT (Callison-Burch et al., 2009) and IWSLT
(Paul, 2009) also contains a wealth of information
for feature engineering in various MT tasks.
2. Designing better training algorithms: N-
best reranking can be seen as a subproblem of
structured prediction, so many general structured
prediction algorithms (c.f. (Bakir et al., 2007))
can be applied. In fact, some structured predic-
tion algorithms, such as the MIRA algorithm used
in dependency parsing (McDonald et al., 2005)
and MT (Watanabe et al., 2007) uses iterative
sets of N-best lists in its training process. Other
training algorithms include perceptron-style algo-
rithms (Liang et al., 2006), MaxEnt (Charniak and
Johnson, 2005), and boosting variants (Kudo et al.,
2005).
The division into two research focuses is conve-
nient, but may be suboptimal if the training algo-
rithm and features do not match well together. Our
work can be seen as re-connecting the two focuses,
where the training algorithm is explicitly used to
help discover better features.
Multitask learning is currently an active subfield
within machine learning. There has already been
some applications in NLP: For example, (Col-
lobert and Weston, 2008) uses a deep neural net-
work architecture for multitask learning on part-
of-speech tagging, chunking, semantic role label-
ing, etc. They showed that jointly learning these
related tasks lead to overall improvements. (De-
selaers et al., 2009) applies similar methods for
machine transliteration. In information extraction,
learning different relation types can be naturally
cast as a multitask problem (Jiang, 2009; Carlson
et al., 2009). Our work can be seen as following
the same philosophy, but applied to N-best lists.
In other areas, (Reichart et al., 2008) introduced
an active learning strategy for annotating multitask
linguistic data. (Blitzer et al., 2006) applies the
multitask algorithm of (Ando and Zhang, 2005)
to domain adaptation problems in NLP. We expect
that more novel applications of multitask learning
will appear in NLP as the techniques become scal-
able and standard.
</bodyText>
<sectionHeader confidence="0.998605" genericHeader="discussions">
6 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.99652925">
N-best reranking is a beneficial framework for ex-
perimenting with large feature sets, but unfortu-
nately feature sparsity leads to overfitting. We ad-
dressed this by re-casting N-best lists as multitask
</bodyText>
<page confidence="0.995572">
381
</page>
<bodyText confidence="0.999965454545455">
learning data. Our MT experiments show consis-
tent statistically significant improvements.
From the Bayesian view, multitask formulation
of N-best lists is actually very natural: Each N-
best is generated by a different data-generating
distribution since the input sentences are different,
i.e. p(e|f1) 7� p(e|f2). Yet these N-bests are re-
lated since the general p(e|f) distribution depends
on the same first-pass models.
The multitask learning perspective opens up
interesting new possibilities for future work, e.g.:
</bodyText>
<listItem confidence="0.9779296875">
• Different ways to partition data into tasks,
e.g. clustering lists by document structure, or
hierarchical clustering of data
• Multitask learning on lattices or N-best lists
with larger N. It is possible that a larger hy-
pothesis space may improve the estimation of
task-specific weights.
• Comparing multitask learning to sparse on-
line learning of batch data, e.g. (Tsuruoka et
al., 2009).
• Modifying the multitask objective to incorpo-
rate application-specific loss/decoding, such
as Minimum Bayes Risk (Kumar and Byrne,
2004)
• Using multitask learning to aid large-scale
feature engineering and visualization.
</listItem>
<sectionHeader confidence="0.997608" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999366">
We have received numerous helpful comments
throughout the course of this work. In partic-
ular, we would like to thank Albert Au Yeung,
Jun Suzuki, Shinji Watanabe, and the three anony-
mous reviewers for their valuable suggestions.
</bodyText>
<sectionHeader confidence="0.998586" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999879258064516">
Jacob Abernethy, Peter Bartlett, and Alexander
Rakhlin. 2007. Multitask learning with expert ad-
vice. In COLT.
Rie Ando and Tong Zhang. 2005. A framework for
learning predictive structures from multiple tasks
and unlabeled data. JMLR.
Andreas Argyriou, Theodoros Evgeniou, and Massim-
iliano Pontil. 2008. Convex multitask feature learn-
ing. Machine Learning, 73(3).
G. Bakir, T. Hofmann, B. Scholkopf, A. Smola,
B. Taskar, and S. V. N. Vishwanathan, editors. 2007.
Predicting structured data. MIT Press.
J. Blitzer, R. McDonald, and F. Pereira. 2006. Domain
adaptation with structural correspondence learning.
In EMNLP.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Josh Schroeder. 2009. Findings of the 2009
workshop on statistical machine translation. In
WMT.
Andrew Carlson, Justin Betteridge, Estevam Hruschka,
and Tom Mitchell. 2009. Coupling semi-supervised
learning of categories and relations. In NAACL
Workshop on Semi-supervised learning for NLP
(SSLNLP).
Rich Caruana. 1997. Multitask learning. Machine
Learning, 28.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and maxent discriminative
reranking. In ACL.
David Chiang, Wei Wang, and Kevin Knight. 2009.
11,001 new features for statistical machine transla-
tion. In NAACL.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2).
Michael Collins and Terry Koo. 2005. Discriminative
reranking for natural langauge parsing. Computa-
tional Linguistics, 31(1).
Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: deep
neural networks with multitask learning. In ICML.
Hal Daume. 2009. Bayesian multitask learning with
latent hierarchies. In UAI.
Thomas Deselaers, Sasa Hasan, Oliver Bender, and
Hermann Ney. 2009. A deep learning approach to
machine transliteration. In WMT.
Jenny Rose Finkel and Chris Manning. 2009. Hier-
archical Bayesian domain adaptation. In NAACL-
HLT.
Kuzman Ganchev and Mark Dredze. 2008. Small sta-
tistical models by random feature mixing. In ACL-
2008 Workshop on Mobile Language Processing.
Jing Jiang. 2009. Multitask transfer learning for
weakly-supervised relation extraction. In ACL.
Taku Kudo, Jun Suzuki, and Hideki Isozaki. 2005.
Boosting-based parse reranking with subtree fea-
tures. In ACL.
Shankar Kumar and William Byrne. 2004. Minimum
bayes-risk decoding for statistical machine transla-
tion. In HLT-NAACL.
P. Liang, A. Bouchard-Cote, D. Klein, and B. Taskar.
2006. An end-to-end discriminative approach to ma-
chine translation. In ACL.
</reference>
<page confidence="0.979037">
382
</page>
<reference confidence="0.999537391304348">
J. Liu, S. Ji, and J. Ye. 2009. Multi-task feature learn-
ing via efficient l2,1-norm minimization. In UAI.
Ryan McDonald, Koby Crammer, and Fernando
Pereira. 2005. Online large margin training of de-
pendency parsers. In ACL.
Guillaume Obozinski, Ben Taskar, and Michael Jor-
dan. 2009. Joint covariate selection and joint sub-
space selection for multiple classification problems.
Statistics and Computing.
F.J. Och et al. 2004. A smorgasbord of features for
statistical machine translation. In HLT/NAACL.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic
evaluation of machine translation. In ACL.
Michael Paul. 2009. Overview of the iwslt 2009 eval-
uation campaign. In IWSLT.
Ariadna Quattoni, Xavier Carreras, Michael Collins,
and Trevor Darrell. 2009. An efficient projection
for L1-Linfinity regularization. In ICML.
Roi Reichart, Katrin Tomanek, Udo Hahn, and Ari
Rappoport. 2008. Multi-task active learning for lin-
guistic annotations. In ACL.
Brian Roark, Murat Saraclar, and Michael Collins.
2007. Discriminative n-gram language modeling.
Computer Speech and Language, 21(2).
Libin Shen, Anoop Sarkar, and Franz Och. 2004. Dis-
criminative reranking for machine translation. In
HLT-NAACL.
Yoshimasa Tsuruoka, Jun’ichi Tsujii, and Sophia Ana-
niadou. 2009. Stochastic gradient descent training
for l1-regularized log-linear models with cumulative
penalty. In ACL-IJCNLP.
Taro Watanabe, Jun Suzuki, Hajime Tsukada, and
Hideki Isozaki. 2007. Online large-margin train-
ing for statistical machine translation. In EMNLP-
CoNLL.
Kilian Weinberger, Anirban Dasgupta, John Langford,
Alex Smola, and Josh Attenberg. 2009. Feature
hashing for large scale multitask learning. In ICML.
Kai Yu and Volker Tresp. 2005. Learning to learn and
collaborative filtering. In NIPS-2005 Workshop on
Inductive Transfer.
Ying Zhang, Stephan Vogel, and Alex Waibel. 2004.
Interpreting BLEU/NIST scores: How much im-
provement do we need to have a better system? In
LREC.
</reference>
<page confidence="0.999356">
383
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.959810">
<title confidence="0.999901">N-best Reranking by Multitask Learning</title>
<author confidence="0.999124">Kevin Duh Katsuhito Sudoh Hajime Tsukada Hideki Isozaki Masaaki</author>
<affiliation confidence="0.999413">NTT Communication Science</affiliation>
<address confidence="0.994828">2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237,</address>
<email confidence="0.981368">nagata.masaaki@lab.ntt.co.jp</email>
<abstract confidence="0.999277863636364">We propose a new framework for N-best reranking on sparse feature sets. The idea is to reformulate the reranking problem as a Multitask Learning problem, where each N-best list corresponds to a distinct task. This is motivated by the observation that N-best lists often show significant differences in feature distributions. Training a single reranker directly on this heterogenous data can be difficult. Our proposed meta-algorithm solves this challenge by using multitask learning as regularization) to discover common feature representations across Nbest lists. This meta-algorithm is simple to implement, and its modular approach allows one to plug-in different learning algorithms from existing literature. As a proof of concept, we show statistically significant improvements on a machine translation system involving millions of features.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jacob Abernethy</author>
<author>Peter Bartlett</author>
<author>Alexander Rakhlin</author>
</authors>
<title>Multitask learning with expert advice.</title>
<date>2007</date>
<booktitle>In COLT.</booktitle>
<contexts>
<context position="18001" citStr="Abernethy et al., 2007" startWordPosition="2992" endWordPosition="2995">erences are present. Here we observe this tendency already on the same domain, which is likely due to the highly-specialized vocabulary and the complex sentence structures common in research paper abstracts. 4.2 MT Results Our goal is to compare different feature representations in reranking: The baseline reranker uses the original sparse feature representation. This is compared to feature representations discovered by three different multitask learning methods: • Joint Regularization (Obozinski et al., 2009) • Shared Subspace (Ando and Zhang, 2005) • Unsupervised Multitask Feature Selection (Abernethy et al., 2007).6 We use existing implementations of the above methods.7 The conventional reranker (Step 5, Al6This is not a standard multitask algorithm since most multitask algorithms are supervised. We include it to see if unsupervised or semi-supervised multitask algorithms is promising. Intuitively, the method tries to select subsets of features that are correlated across multiple tasks using random sampling (MCMC). Features that co-occur in different tasks form a high probability path. 7Available at http://multitask.cs.berkeley.edu Nbest id #NewFt #SoFar #Active 1 3900 3900 3900 2 7535 11435 7913 3 607</context>
</contexts>
<marker>Abernethy, Bartlett, Rakhlin, 2007</marker>
<rawString>Jacob Abernethy, Peter Bartlett, and Alexander Rakhlin. 2007. Multitask learning with expert advice. In COLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rie Ando</author>
<author>Tong Zhang</author>
</authors>
<title>A framework for learning predictive structures from multiple tasks and unlabeled data.</title>
<date>2005</date>
<publisher>JMLR.</publisher>
<contexts>
<context position="13504" citStr="Ando and Zhang, 2005" startWordPosition="2242" endWordPosition="2245">.g. Ei ||wi − wav9||2. If we interpret wav9 as a prior, we begin to see links to Hierarchical Bayesian methods for multitask learning (Finkel and Manning, 2009; Daume, 2009). 2. Shared Subspace: This approach assumes that there is an underlying feature subspace that is common to all tasks. Early works on multitask learning implement this by neural networks, where different tasks have different output layers but share the same hidden layer (Caruana, 1997). Another method is to write the weight vector as two parts w = [u; v] and let the task-specific function be uT · h(e, f) + vT · O · h(e, f) (Ando and Zhang, 2005). O is a D′ xD matrix that maps the original features to a subspace common to all tasks. The new feature representation is computed by the projection h,(e, f) °= O · h(e, f). Multitask learning is a vast field and relates to areas like collaborative filtering (Yu and Tresp, 2005) and domain adaptation. Most methods assume some common representation and is thus applicable to our framework. The reader is urged to refer to citations in, e.g. (Argyriou et al., 2008) for a survey. 4 Experiments and Results As a proof of concept, we perform experiments on a MT system with millions of features. We us</context>
<context position="17933" citStr="Ando and Zhang, 2005" startWordPosition="2983" endWordPosition="2986">(Arabic-English newswire translation), especially when domain differences are present. Here we observe this tendency already on the same domain, which is likely due to the highly-specialized vocabulary and the complex sentence structures common in research paper abstracts. 4.2 MT Results Our goal is to compare different feature representations in reranking: The baseline reranker uses the original sparse feature representation. This is compared to feature representations discovered by three different multitask learning methods: • Joint Regularization (Obozinski et al., 2009) • Shared Subspace (Ando and Zhang, 2005) • Unsupervised Multitask Feature Selection (Abernethy et al., 2007).6 We use existing implementations of the above methods.7 The conventional reranker (Step 5, Al6This is not a standard multitask algorithm since most multitask algorithms are supervised. We include it to see if unsupervised or semi-supervised multitask algorithms is promising. Intuitively, the method tries to select subsets of features that are correlated across multiple tasks using random sampling (MCMC). Features that co-occur in different tasks form a high probability path. 7Available at http://multitask.cs.berkeley.edu Nbe</context>
<context position="27605" citStr="Ando and Zhang, 2005" startWordPosition="4514" endWordPosition="4517">, semantic role labeling, etc. They showed that jointly learning these related tasks lead to overall improvements. (Deselaers et al., 2009) applies similar methods for machine transliteration. In information extraction, learning different relation types can be naturally cast as a multitask problem (Jiang, 2009; Carlson et al., 2009). Our work can be seen as following the same philosophy, but applied to N-best lists. In other areas, (Reichart et al., 2008) introduced an active learning strategy for annotating multitask linguistic data. (Blitzer et al., 2006) applies the multitask algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP. We expect that more novel applications of multitask learning will appear in NLP as the techniques become scalable and standard. 6 Discussion and Conclusion N-best reranking is a beneficial framework for experimenting with large feature sets, but unfortunately feature sparsity leads to overfitting. We addressed this by re-casting N-best lists as multitask 381 learning data. Our MT experiments show consistent statistically significant improvements. From the Bayesian view, multitask formulation of N-best lists is actually very natural: Each Nbest is generate</context>
</contexts>
<marker>Ando, Zhang, 2005</marker>
<rawString>Rie Ando and Tong Zhang. 2005. A framework for learning predictive structures from multiple tasks and unlabeled data. JMLR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Argyriou</author>
<author>Theodoros Evgeniou</author>
<author>Massimiliano Pontil</author>
</authors>
<date>2008</date>
<booktitle>Convex multitask feature learning. Machine Learning,</booktitle>
<volume>73</volume>
<issue>3</issue>
<contexts>
<context position="12666" citStr="Argyriou et al., 2008" startWordPosition="2093" endWordPosition="2096">t can be plugged in Step 2 of Algorithm 1. Our goal is to demonstrate that a wide range of existing methods from the multitask learning literature can be brought to our problem. We categorize multitask methods into two major approaches: 1. Joint Regularization: Eq. 5 is an example of joint regularization, with E1/E2 norm being a particular regularizer. The idea is to use the regularizer to ensure that the learned functions of related tasks are close to each other. The popular E1/E2 objective can be optimized by various methods, such as boosting (Obozinski et al., 2009) and convex programming (Argyriou et al., 2008). Yet another regularizer is the E1/E∞ norm (Quattoni et al., 2009), which replaces the 2-norm with a max. One could also define a regularizer to ensure that each task-specific wi is close to some average parameter, e.g. Ei ||wi − wav9||2. If we interpret wav9 as a prior, we begin to see links to Hierarchical Bayesian methods for multitask learning (Finkel and Manning, 2009; Daume, 2009). 2. Shared Subspace: This approach assumes that there is an underlying feature subspace that is common to all tasks. Early works on multitask learning implement this by neural networks, where different tasks h</context>
<context position="13970" citStr="Argyriou et al., 2008" startWordPosition="2325" endWordPosition="2328">er method is to write the weight vector as two parts w = [u; v] and let the task-specific function be uT · h(e, f) + vT · O · h(e, f) (Ando and Zhang, 2005). O is a D′ xD matrix that maps the original features to a subspace common to all tasks. The new feature representation is computed by the projection h,(e, f) °= O · h(e, f). Multitask learning is a vast field and relates to areas like collaborative filtering (Yu and Tresp, 2005) and domain adaptation. Most methods assume some common representation and is thus applicable to our framework. The reader is urged to refer to citations in, e.g. (Argyriou et al., 2008) for a survey. 4 Experiments and Results As a proof of concept, we perform experiments on a MT system with millions of features. We use a hierarchical phrase-based system (Chiang, 100 10−1 10−2 10−3 10−4 10−5 10−6 10−7 100 101 102 103 104 x Figure 1: This log-log plot shows that there are many rare features and few common features. The probability that a feature occurs in x number of Nbest lists behaves according to the power-law x−α, where α = 2.28. 2007) to generate N-best lists (N=100). Sparse features used in reranking are extracted according to (Watanabe et al., 2007). Specifically, the m</context>
</contexts>
<marker>Argyriou, Evgeniou, Pontil, 2008</marker>
<rawString>Andreas Argyriou, Theodoros Evgeniou, and Massimiliano Pontil. 2008. Convex multitask feature learning. Machine Learning, 73(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bakir</author>
<author>T Hofmann</author>
<author>B Scholkopf</author>
</authors>
<title>Predicting structured data.</title>
<date>2007</date>
<editor>A. Smola, B. Taskar, and S. V. N. Vishwanathan, editors.</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="26040" citStr="Bakir et al., 2007" startWordPosition="4271" endWordPosition="4274">ith high frequency features also give significant improvements over the high frequency features alone. method. Recent work by (Chiang et al., 2009) describes new features for hierarchical phrase-based MT, while (Collins and Koo, 2005) describes features for parsing. Evaluation campaigns like WMT (Callison-Burch et al., 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al., 2005). The division into two research focuses is convenient, but may be suboptimal if the training algorithm and features do not match well together. Our work can be seen as re-connecting the two focuses, wh</context>
</contexts>
<marker>Bakir, Hofmann, Scholkopf, 2007</marker>
<rawString>G. Bakir, T. Hofmann, B. Scholkopf, A. Smola, B. Taskar, and S. V. N. Vishwanathan, editors. 2007. Predicting structured data. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Domain adaptation with structural correspondence learning.</title>
<date>2006</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="27547" citStr="Blitzer et al., 2006" startWordPosition="4505" endWordPosition="4508"> for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jointly learning these related tasks lead to overall improvements. (Deselaers et al., 2009) applies similar methods for machine transliteration. In information extraction, learning different relation types can be naturally cast as a multitask problem (Jiang, 2009; Carlson et al., 2009). Our work can be seen as following the same philosophy, but applied to N-best lists. In other areas, (Reichart et al., 2008) introduced an active learning strategy for annotating multitask linguistic data. (Blitzer et al., 2006) applies the multitask algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP. We expect that more novel applications of multitask learning will appear in NLP as the techniques become scalable and standard. 6 Discussion and Conclusion N-best reranking is a beneficial framework for experimenting with large feature sets, but unfortunately feature sparsity leads to overfitting. We addressed this by re-casting N-best lists as multitask 381 learning data. Our MT experiments show consistent statistically significant improvements. From the Bayesian view, multitask formulation of N-b</context>
</contexts>
<marker>Blitzer, McDonald, Pereira, 2006</marker>
<rawString>J. Blitzer, R. McDonald, and F. Pereira. 2006. Domain adaptation with structural correspondence learning. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<title>workshop on statistical machine translation.</title>
<date>2009</date>
<journal>Findings of the</journal>
<booktitle>In WMT.</booktitle>
<contexts>
<context position="25747" citStr="Callison-Burch et al., 2009" startWordPosition="4226" endWordPosition="4229">6.9 33.1 Table 2: Results for different feature sets, with corresponding feature size and train/test BLEU/PER. All multitask features give statistically significant improvements over the baselines (boldfaced), e.g. Shared Subspace: 29.1 BLEU vs Baseline: 28.6 BLEU. Combinations of multitask features with high frequency features also give significant improvements over the high frequency features alone. method. Recent work by (Chiang et al., 2009) describes new features for hierarchical phrase-based MT, while (Collins and Koo, 2005) describes features for parsing. Evaluation campaigns like WMT (Callison-Burch et al., 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et</context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Schroeder, 2009</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, Christof Monz, and Josh Schroeder. 2009. Findings of the 2009 workshop on statistical machine translation. In WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Estevam Hruschka</author>
<author>Tom Mitchell</author>
</authors>
<title>Coupling semi-supervised learning of categories and relations.</title>
<date>2009</date>
<booktitle>In NAACL Workshop on Semi-supervised learning for NLP (SSLNLP).</booktitle>
<contexts>
<context position="27318" citStr="Carlson et al., 2009" startWordPosition="4469" endWordPosition="4472">cover better features. Multitask learning is currently an active subfield within machine learning. There has already been some applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jointly learning these related tasks lead to overall improvements. (Deselaers et al., 2009) applies similar methods for machine transliteration. In information extraction, learning different relation types can be naturally cast as a multitask problem (Jiang, 2009; Carlson et al., 2009). Our work can be seen as following the same philosophy, but applied to N-best lists. In other areas, (Reichart et al., 2008) introduced an active learning strategy for annotating multitask linguistic data. (Blitzer et al., 2006) applies the multitask algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP. We expect that more novel applications of multitask learning will appear in NLP as the techniques become scalable and standard. 6 Discussion and Conclusion N-best reranking is a beneficial framework for experimenting with large feature sets, but unfortunately feature sparsi</context>
</contexts>
<marker>Carlson, Betteridge, Hruschka, Mitchell, 2009</marker>
<rawString>Andrew Carlson, Justin Betteridge, Estevam Hruschka, and Tom Mitchell. 2009. Coupling semi-supervised learning of categories and relations. In NAACL Workshop on Semi-supervised learning for NLP (SSLNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich Caruana</author>
</authors>
<date>1997</date>
<booktitle>Multitask learning. Machine Learning,</booktitle>
<volume>28</volume>
<contexts>
<context position="13341" citStr="Caruana, 1997" startWordPosition="2208" endWordPosition="2209"> 2009), which replaces the 2-norm with a max. One could also define a regularizer to ensure that each task-specific wi is close to some average parameter, e.g. Ei ||wi − wav9||2. If we interpret wav9 as a prior, we begin to see links to Hierarchical Bayesian methods for multitask learning (Finkel and Manning, 2009; Daume, 2009). 2. Shared Subspace: This approach assumes that there is an underlying feature subspace that is common to all tasks. Early works on multitask learning implement this by neural networks, where different tasks have different output layers but share the same hidden layer (Caruana, 1997). Another method is to write the weight vector as two parts w = [u; v] and let the task-specific function be uT · h(e, f) + vT · O · h(e, f) (Ando and Zhang, 2005). O is a D′ xD matrix that maps the original features to a subspace common to all tasks. The new feature representation is computed by the projection h,(e, f) °= O · h(e, f). Multitask learning is a vast field and relates to areas like collaborative filtering (Yu and Tresp, 2005) and domain adaptation. Most methods assume some common representation and is thus applicable to our framework. The reader is urged to refer to citations in,</context>
</contexts>
<marker>Caruana, 1997</marker>
<rawString>Rich Caruana. 1997. Multitask learning. Machine Learning, 28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-fine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="26395" citStr="Charniak and Johnson, 2005" startWordPosition="4326" endWordPosition="4329">9) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al., 2005). The division into two research focuses is convenient, but may be suboptimal if the training algorithm and features do not match well together. Our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features. Multitask learning is currently an active subfield within machine learning. There has already been some applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on partof-speech tagging, chunking, semantic </context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarseto-fine n-best parsing and maxent discriminative reranking. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Wei Wang</author>
<author>Kevin Knight</author>
</authors>
<title>11,001 new features for statistical machine translation.</title>
<date>2009</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="6545" citStr="Chiang et al., 2009" startWordPosition="1037" endWordPosition="1040">e feature sets: 1. Feature templates are heavily-lexicalized, which causes the number of features to grow unbounded as the the amount of data increases. 2. The input (f) has high variability (e.g. large vocabulary size), so that features for different inputs are rarely shared. 3. The N-best list output also exhibits high variability (e.g. many different word reorderings). Larger N may improve reranking performance, but may also increase feature sparsity. When the number of features is too large, even popular reranking algorithms such as SVM (Shen et al., 2004) and MIRA (Watanabe et al., 2007; Chiang et al., 2009) may fail. Our goal here is to address this situation. 3 Proposed Reranking Framework In the following, we first give an intuitive comparison between single vs. multiple task learning (Section 3.1), before presenting the general metaalgorithm (Section 3.2) and particular instantiations (Section 3.3). 3.1 Single vs. Multiple Tasks Given a set of I input sentences {f&apos;}, the training data for reranking consists of a set of I N-best lists {(H&apos;, y&apos;)}&apos;=1,...,z, where H&apos; are features and y&apos; are labels. To clarify the notation:1 for an input sentence f&apos;, there is a N-best list N(f&apos;). For a N-best list</context>
<context position="25568" citStr="Chiang et al., 2009" startWordPosition="4201" endWordPosition="4204">pervised FeatureSelect + (b) 60.5k 36.2 29.3 37.6 Joint Regularization + (b) 60.25k 36.1 29.4 37.5 Shared Subspace + (b) 61k 36.2 29.6 37.3 Oracle (best possible) – 36.9 36.9 33.1 Table 2: Results for different feature sets, with corresponding feature size and train/test BLEU/PER. All multitask features give statistically significant improvements over the baselines (boldfaced), e.g. Shared Subspace: 29.1 BLEU vs Baseline: 28.6 BLEU. Combinations of multitask features with high frequency features also give significant improvements over the high frequency features alone. method. Recent work by (Chiang et al., 2009) describes new features for hierarchical phrase-based MT, while (Collins and Koo, 2005) describes features for parsing. Evaluation campaigns like WMT (Callison-Burch et al., 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonal</context>
</contexts>
<marker>Chiang, Wang, Knight, 2009</marker>
<rawString>David Chiang, Wei Wang, and Kevin Knight. 2009. 11,001 new features for statistical machine translation. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Terry Koo</author>
</authors>
<title>Discriminative reranking for natural langauge parsing.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="1373" citStr="Collins and Koo, 2005" startWordPosition="185" endWordPosition="188">enge by using multitask learning (such as ℓ1/ℓ2 regularization) to discover common feature representations across Nbest lists. This meta-algorithm is simple to implement, and its modular approach allows one to plug-in different learning algorithms from existing literature. As a proof of concept, we show statistically significant improvements on a machine translation system involving millions of features. 1 Introduction Many natural language processing applications, such as machine translation (MT), parsing, and language modeling, benefit from the N-best reranking framework (Shen et al., 2004; Collins and Koo, 2005; Roark et al., 2007). The advantage of N-best reranking is that it abstracts away the complexities of first-pass decoding, allowing the researcher to try new features and learning algorithms with fast experimental turnover. In the N-best reranking scenario, the training data consists of sets of hypotheses (i.e. N-best lists) generated by a first-pass system, along with their labels. Given a new N-best list, the goal is to rerank it such that the best hypothesis appears near the top of the list. Existing research have focused on training a single reranker directly on the entire data. This appr</context>
<context position="25655" citStr="Collins and Koo, 2005" startWordPosition="4214" endWordPosition="4217">6.1 29.4 37.5 Shared Subspace + (b) 61k 36.2 29.6 37.3 Oracle (best possible) – 36.9 36.9 33.1 Table 2: Results for different feature sets, with corresponding feature size and train/test BLEU/PER. All multitask features give statistically significant improvements over the baselines (boldfaced), e.g. Shared Subspace: 29.1 BLEU vs Baseline: 28.6 BLEU. Combinations of multitask features with high frequency features also give significant improvements over the high frequency features alone. method. Recent work by (Chiang et al., 2009) describes new features for hierarchical phrase-based MT, while (Collins and Koo, 2005) describes features for parsing. Evaluation campaigns like WMT (Callison-Burch et al., 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in i</context>
</contexts>
<marker>Collins, Koo, 2005</marker>
<rawString>Michael Collins and Terry Koo. 2005. Discriminative reranking for natural langauge parsing. Computational Linguistics, 31(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
</authors>
<title>A unified architecture for natural language processing: deep neural networks with multitask learning.</title>
<date>2008</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="26886" citStr="Collobert and Weston, 2008" startWordPosition="4404" endWordPosition="4408">raining process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al., 2005). The division into two research focuses is convenient, but may be suboptimal if the training algorithm and features do not match well together. Our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features. Multitask learning is currently an active subfield within machine learning. There has already been some applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jointly learning these related tasks lead to overall improvements. (Deselaers et al., 2009) applies similar methods for machine transliteration. In information extraction, learning different relation types can be naturally cast as a multitask problem (Jiang, 2009; Carlson et al., 2009). Our work can be seen as following the same philosophy, but applied to N-best lists. In other areas, (Reichart et al., 2008) introduced an active learning strategy for</context>
</contexts>
<marker>Collobert, Weston, 2008</marker>
<rawString>Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: deep neural networks with multitask learning. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daume</author>
</authors>
<title>Bayesian multitask learning with latent hierarchies.</title>
<date>2009</date>
<booktitle>In UAI.</booktitle>
<contexts>
<context position="13056" citStr="Daume, 2009" startWordPosition="2163" endWordPosition="2164">that the learned functions of related tasks are close to each other. The popular E1/E2 objective can be optimized by various methods, such as boosting (Obozinski et al., 2009) and convex programming (Argyriou et al., 2008). Yet another regularizer is the E1/E∞ norm (Quattoni et al., 2009), which replaces the 2-norm with a max. One could also define a regularizer to ensure that each task-specific wi is close to some average parameter, e.g. Ei ||wi − wav9||2. If we interpret wav9 as a prior, we begin to see links to Hierarchical Bayesian methods for multitask learning (Finkel and Manning, 2009; Daume, 2009). 2. Shared Subspace: This approach assumes that there is an underlying feature subspace that is common to all tasks. Early works on multitask learning implement this by neural networks, where different tasks have different output layers but share the same hidden layer (Caruana, 1997). Another method is to write the weight vector as two parts w = [u; v] and let the task-specific function be uT · h(e, f) + vT · O · h(e, f) (Ando and Zhang, 2005). O is a D′ xD matrix that maps the original features to a subspace common to all tasks. The new feature representation is computed by the projection h,</context>
</contexts>
<marker>Daume, 2009</marker>
<rawString>Hal Daume. 2009. Bayesian multitask learning with latent hierarchies. In UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Deselaers</author>
<author>Sasa Hasan</author>
<author>Oliver Bender</author>
<author>Hermann Ney</author>
</authors>
<title>A deep learning approach to machine transliteration.</title>
<date>2009</date>
<booktitle>In WMT.</booktitle>
<contexts>
<context position="27123" citStr="Deselaers et al., 2009" startWordPosition="4441" endWordPosition="4445">y be suboptimal if the training algorithm and features do not match well together. Our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features. Multitask learning is currently an active subfield within machine learning. There has already been some applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jointly learning these related tasks lead to overall improvements. (Deselaers et al., 2009) applies similar methods for machine transliteration. In information extraction, learning different relation types can be naturally cast as a multitask problem (Jiang, 2009; Carlson et al., 2009). Our work can be seen as following the same philosophy, but applied to N-best lists. In other areas, (Reichart et al., 2008) introduced an active learning strategy for annotating multitask linguistic data. (Blitzer et al., 2006) applies the multitask algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP. We expect that more novel applications of multitask learning will appear in NLP</context>
</contexts>
<marker>Deselaers, Hasan, Bender, Ney, 2009</marker>
<rawString>Thomas Deselaers, Sasa Hasan, Oliver Bender, and Hermann Ney. 2009. A deep learning approach to machine transliteration. In WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Chris Manning</author>
</authors>
<title>Hierarchical Bayesian domain adaptation.</title>
<date>2009</date>
<booktitle>In NAACLHLT.</booktitle>
<contexts>
<context position="13042" citStr="Finkel and Manning, 2009" startWordPosition="2159" endWordPosition="2162">the regularizer to ensure that the learned functions of related tasks are close to each other. The popular E1/E2 objective can be optimized by various methods, such as boosting (Obozinski et al., 2009) and convex programming (Argyriou et al., 2008). Yet another regularizer is the E1/E∞ norm (Quattoni et al., 2009), which replaces the 2-norm with a max. One could also define a regularizer to ensure that each task-specific wi is close to some average parameter, e.g. Ei ||wi − wav9||2. If we interpret wav9 as a prior, we begin to see links to Hierarchical Bayesian methods for multitask learning (Finkel and Manning, 2009; Daume, 2009). 2. Shared Subspace: This approach assumes that there is an underlying feature subspace that is common to all tasks. Early works on multitask learning implement this by neural networks, where different tasks have different output layers but share the same hidden layer (Caruana, 1997). Another method is to write the weight vector as two parts w = [u; v] and let the task-specific function be uT · h(e, f) + vT · O · h(e, f) (Ando and Zhang, 2005). O is a D′ xD matrix that maps the original features to a subspace common to all tasks. The new feature representation is computed by the</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny Rose Finkel and Chris Manning. 2009. Hierarchical Bayesian domain adaptation. In NAACLHLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Mark Dredze</author>
</authors>
<title>Small statistical models by random feature mixing.</title>
<date>2008</date>
<booktitle>In ACL2008 Workshop on Mobile Language Processing.</booktitle>
<contexts>
<context position="10392" citStr="Ganchev and Dredze, 2008" startWordPosition="1710" endWordPosition="1713">-algorithm (see Algorithm 1), termed Reranking by Multitask Learning (RML) . Algorithm 1 Reranking by Multitask Learning Input: N-best data {(Hi, yi)}i=1,...,I Output: Common feature representation hc(e, f) and weight vector wc 1: [optional] RandomHashing({Hi}) 2: W = MultitaskLearn({(Hi, yi)}) 3: hc = ExtractCommonFeature(W) 4: {Hic} = RemapFeature({Hi}, hc) 5: wc = ConventionalReranker({(Hi c, yi)}) The first step, random hashing, is optional. Random hashing is an effective trick for reducing the dimension of sparse feature sets without suffering losses in fidelity (Weinberger et al., 2009; Ganchev and Dredze, 2008). It works by collapsing random subsets of features. This step can be performed to speed-up multitask learning later. In some cases, the original feature dimension may be so large that hashed representations may be necessary. The next two steps are key. A multitask learning algorithm is run on the N-best lists, and a common feature space shared by all lists is extracted. For example, if one uses the multitask objective of Eq. 5, the result of step 2 is a set of weights W. ExtractCommonFeature(W) then returns the feature id’s (either from original or hashed representation) that receive nonzero </context>
</contexts>
<marker>Ganchev, Dredze, 2008</marker>
<rawString>Kuzman Ganchev and Mark Dredze. 2008. Small statistical models by random feature mixing. In ACL2008 Workshop on Mobile Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
</authors>
<title>Multitask transfer learning for weakly-supervised relation extraction.</title>
<date>2009</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="27295" citStr="Jiang, 2009" startWordPosition="4467" endWordPosition="4468">d to help discover better features. Multitask learning is currently an active subfield within machine learning. There has already been some applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jointly learning these related tasks lead to overall improvements. (Deselaers et al., 2009) applies similar methods for machine transliteration. In information extraction, learning different relation types can be naturally cast as a multitask problem (Jiang, 2009; Carlson et al., 2009). Our work can be seen as following the same philosophy, but applied to N-best lists. In other areas, (Reichart et al., 2008) introduced an active learning strategy for annotating multitask linguistic data. (Blitzer et al., 2006) applies the multitask algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP. We expect that more novel applications of multitask learning will appear in NLP as the techniques become scalable and standard. 6 Discussion and Conclusion N-best reranking is a beneficial framework for experimenting with large feature sets, but unfor</context>
</contexts>
<marker>Jiang, 2009</marker>
<rawString>Jing Jiang. 2009. Multitask transfer learning for weakly-supervised relation extraction. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Jun Suzuki</author>
<author>Hideki Isozaki</author>
</authors>
<title>Boosting-based parse reranking with subtree features.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="26438" citStr="Kudo et al., 2005" startWordPosition="4333" endWordPosition="4336"> engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al., 2005). The division into two research focuses is convenient, but may be suboptimal if the training algorithm and features do not match well together. Our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features. Multitask learning is currently an active subfield within machine learning. There has already been some applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jointl</context>
</contexts>
<marker>Kudo, Suzuki, Isozaki, 2005</marker>
<rawString>Taku Kudo, Jun Suzuki, and Hideki Isozaki. 2005. Boosting-based parse reranking with subtree features. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>William Byrne</author>
</authors>
<title>Minimum bayes-risk decoding for statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL.</booktitle>
<marker>Kumar, Byrne, 2004</marker>
<rawString>Shankar Kumar and William Byrne. 2004. Minimum bayes-risk decoding for statistical machine translation. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>A Bouchard-Cote</author>
<author>D Klein</author>
<author>B Taskar</author>
</authors>
<title>An end-to-end discriminative approach to machine translation.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="26358" citStr="Liang et al., 2006" startWordPosition="4321" endWordPosition="4324">., 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al., 2005). The division into two research focuses is convenient, but may be suboptimal if the training algorithm and features do not match well together. Our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features. Multitask learning is currently an active subfield within machine learning. There has already been some applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on parto</context>
</contexts>
<marker>Liang, Bouchard-Cote, Klein, Taskar, 2006</marker>
<rawString>P. Liang, A. Bouchard-Cote, D. Klein, and B. Taskar. 2006. An end-to-end discriminative approach to machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Liu</author>
<author>S Ji</author>
<author>J Ye</author>
</authors>
<title>Multi-task feature learning via efficient l2,1-norm minimization.</title>
<date>2009</date>
<booktitle>In UAI.</booktitle>
<contexts>
<context position="24272" citStr="Liu et al., 2009" startWordPosition="4001" endWordPosition="4004">y on the outputs. Although their results show that the proposed syntactic features gave little improvements, they point to some potential reasons, such as domain mismatch for the parser and overfitting by the reranking 10Note: In order to do this analysis, we needed to run Joint Regularization on the original feature representation, since the hashed representations are less interpretable. This turns out to be computationally prohibitive in the time being so we only ran on a smaller data set of 50 lists. Recently new optimization methods that are orders of magnitude faster have been developed (Liu et al., 2009), which makes larger-scale experiments possible. Bootstrap samples 300 250 200 150 100 50 0 −0.2 0 0.2 0.4 0.6 0.8 1 1.2 380 Feature Representation #Feature Train Test Test BLEU BLEU PER (baselines) First pass 20 29.5 28.5 38.3 All sparse features (Main baseline) 2.4M 36.9 28.6 38.2 All sparse features w/ ℓ, regularization 1200 36.5 28.5 38.6 Random hash representation 4000 33.0 28.5 38.2 (multitask learning) Unsupervised FeatureSelect 500 32.0 28.8 37.7 Joint Regularization 250 31.8 28.9 37.5 Shared Subspace 1000 32.9 29.1 37.3 (combination w/ high-frequency features) 3k 31.7 27.9 38.2 (a) Fe</context>
</contexts>
<marker>Liu, Ji, Ye, 2009</marker>
<rawString>J. Liu, S. Ji, and J. Ye. 2009. Multi-task feature learning via efficient l2,1-norm minimization. In UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="26183" citStr="McDonald et al., 2005" startWordPosition="4294" endWordPosition="4297">, 2009) describes new features for hierarchical phrase-based MT, while (Collins and Koo, 2005) describes features for parsing. Evaluation campaigns like WMT (Callison-Burch et al., 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al., 2005). The division into two research focuses is convenient, but may be suboptimal if the training algorithm and features do not match well together. Our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features. Multitask learning is currently an active subfield within machi</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large margin training of dependency parsers. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guillaume Obozinski</author>
<author>Ben Taskar</author>
<author>Michael Jordan</author>
</authors>
<title>Joint covariate selection and joint subspace selection for multiple classification problems. Statistics and Computing.</title>
<date>2009</date>
<contexts>
<context position="12619" citStr="Obozinski et al., 2009" startWordPosition="2086" endWordPosition="2089"> Here, we describe various multitask methods that can be plugged in Step 2 of Algorithm 1. Our goal is to demonstrate that a wide range of existing methods from the multitask learning literature can be brought to our problem. We categorize multitask methods into two major approaches: 1. Joint Regularization: Eq. 5 is an example of joint regularization, with E1/E2 norm being a particular regularizer. The idea is to use the regularizer to ensure that the learned functions of related tasks are close to each other. The popular E1/E2 objective can be optimized by various methods, such as boosting (Obozinski et al., 2009) and convex programming (Argyriou et al., 2008). Yet another regularizer is the E1/E∞ norm (Quattoni et al., 2009), which replaces the 2-norm with a max. One could also define a regularizer to ensure that each task-specific wi is close to some average parameter, e.g. Ei ||wi − wav9||2. If we interpret wav9 as a prior, we begin to see links to Hierarchical Bayesian methods for multitask learning (Finkel and Manning, 2009; Daume, 2009). 2. Shared Subspace: This approach assumes that there is an underlying feature subspace that is common to all tasks. Early works on multitask learning implement t</context>
<context position="17892" citStr="Obozinski et al., 2009" startWordPosition="2976" endWordPosition="2979">ossibility of overfitting in their dataset (Arabic-English newswire translation), especially when domain differences are present. Here we observe this tendency already on the same domain, which is likely due to the highly-specialized vocabulary and the complex sentence structures common in research paper abstracts. 4.2 MT Results Our goal is to compare different feature representations in reranking: The baseline reranker uses the original sparse feature representation. This is compared to feature representations discovered by three different multitask learning methods: • Joint Regularization (Obozinski et al., 2009) • Shared Subspace (Ando and Zhang, 2005) • Unsupervised Multitask Feature Selection (Abernethy et al., 2007).6 We use existing implementations of the above methods.7 The conventional reranker (Step 5, Al6This is not a standard multitask algorithm since most multitask algorithms are supervised. We include it to see if unsupervised or semi-supervised multitask algorithms is promising. Intuitively, the method tries to select subsets of features that are correlated across multiple tasks using random sampling (MCMC). Features that co-occur in different tasks form a high probability path. 7Availabl</context>
</contexts>
<marker>Obozinski, Taskar, Jordan, 2009</marker>
<rawString>Guillaume Obozinski, Ben Taskar, and Michael Jordan. 2009. Joint covariate selection and joint subspace selection for multiple classification problems. Statistics and Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>A smorgasbord of features for statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT/NAACL.</booktitle>
<marker>Och, 2004</marker>
<rawString>F.J. Och et al. 2004. A smorgasbord of features for statistical machine translation. In HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="19840" citStr="Papineni et al., 2002" startWordPosition="3306" endWordPosition="3309">that the SVM baseline performance is comparable to MIRA training, so we use SVM throughout. The labels for the SVM are derived as in (Shen et al., 2004), where top 10% of hypotheses by smoothed sentence-BLEU is ranked before the bottom 90%. All multitask learning methods work on hashed features of dimension 4000 (Step 1, Algorithm 1). This speeds up the training process. All hyperparameters of the multitask method are tuned on the held-out set. In particular, the most important is the number of common features to extract, which we pick from {250, 500, 1000}. Table 2 shows the results by BLEU (Papineni et al., 2002) and PER. The Oracle results are obtained by choosing the best hypothesis per N-best list by sentence-level BLEU, which achieved 36.9 BLEU in both Train and Test. A summary of our observations is: 1. The baseline (All sparse features) overfits. It achieves the oracle BLEU score on the train set (36.9) but performs poorly on the test (28.6). 2. Similar overfitting occurs when traditional ℓ1 regularization is used to select features on 8Available at http://svmlight.joachims.org 379 the sparse feature representation9. ℓ1 regularization is a good method of handling sparse features for classificati</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Paul</author>
</authors>
<title>Overview of the iwslt 2009 evaluation campaign.</title>
<date>2009</date>
<booktitle>In IWSLT.</booktitle>
<contexts>
<context position="25770" citStr="Paul, 2009" startWordPosition="4232" endWordPosition="4233">feature sets, with corresponding feature size and train/test BLEU/PER. All multitask features give statistically significant improvements over the baselines (boldfaced), e.g. Shared Subspace: 29.1 BLEU vs Baseline: 28.6 BLEU. Combinations of multitask features with high frequency features also give significant improvements over the high frequency features alone. method. Recent work by (Chiang et al., 2009) describes new features for hierarchical phrase-based MT, while (Collins and Koo, 2005) describes features for parsing. Evaluation campaigns like WMT (Callison-Burch et al., 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Ch</context>
</contexts>
<marker>Paul, 2009</marker>
<rawString>Michael Paul. 2009. Overview of the iwslt 2009 evaluation campaign. In IWSLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ariadna Quattoni</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
<author>Trevor Darrell</author>
</authors>
<title>An efficient projection for L1-Linfinity regularization.</title>
<date>2009</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="12733" citStr="Quattoni et al., 2009" startWordPosition="2104" endWordPosition="2107">te that a wide range of existing methods from the multitask learning literature can be brought to our problem. We categorize multitask methods into two major approaches: 1. Joint Regularization: Eq. 5 is an example of joint regularization, with E1/E2 norm being a particular regularizer. The idea is to use the regularizer to ensure that the learned functions of related tasks are close to each other. The popular E1/E2 objective can be optimized by various methods, such as boosting (Obozinski et al., 2009) and convex programming (Argyriou et al., 2008). Yet another regularizer is the E1/E∞ norm (Quattoni et al., 2009), which replaces the 2-norm with a max. One could also define a regularizer to ensure that each task-specific wi is close to some average parameter, e.g. Ei ||wi − wav9||2. If we interpret wav9 as a prior, we begin to see links to Hierarchical Bayesian methods for multitask learning (Finkel and Manning, 2009; Daume, 2009). 2. Shared Subspace: This approach assumes that there is an underlying feature subspace that is common to all tasks. Early works on multitask learning implement this by neural networks, where different tasks have different output layers but share the same hidden layer (Caruan</context>
</contexts>
<marker>Quattoni, Carreras, Collins, Darrell, 2009</marker>
<rawString>Ariadna Quattoni, Xavier Carreras, Michael Collins, and Trevor Darrell. 2009. An efficient projection for L1-Linfinity regularization. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roi Reichart</author>
<author>Katrin Tomanek</author>
<author>Udo Hahn</author>
<author>Ari Rappoport</author>
</authors>
<title>Multi-task active learning for linguistic annotations.</title>
<date>2008</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="27443" citStr="Reichart et al., 2008" startWordPosition="4491" endWordPosition="4494">me applications in NLP: For example, (Collobert and Weston, 2008) uses a deep neural network architecture for multitask learning on partof-speech tagging, chunking, semantic role labeling, etc. They showed that jointly learning these related tasks lead to overall improvements. (Deselaers et al., 2009) applies similar methods for machine transliteration. In information extraction, learning different relation types can be naturally cast as a multitask problem (Jiang, 2009; Carlson et al., 2009). Our work can be seen as following the same philosophy, but applied to N-best lists. In other areas, (Reichart et al., 2008) introduced an active learning strategy for annotating multitask linguistic data. (Blitzer et al., 2006) applies the multitask algorithm of (Ando and Zhang, 2005) to domain adaptation problems in NLP. We expect that more novel applications of multitask learning will appear in NLP as the techniques become scalable and standard. 6 Discussion and Conclusion N-best reranking is a beneficial framework for experimenting with large feature sets, but unfortunately feature sparsity leads to overfitting. We addressed this by re-casting N-best lists as multitask 381 learning data. Our MT experiments show</context>
</contexts>
<marker>Reichart, Tomanek, Hahn, Rappoport, 2008</marker>
<rawString>Roi Reichart, Katrin Tomanek, Udo Hahn, and Ari Rappoport. 2008. Multi-task active learning for linguistic annotations. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Murat Saraclar</author>
<author>Michael Collins</author>
</authors>
<title>Discriminative n-gram language modeling.</title>
<date>2007</date>
<journal>Computer Speech and Language,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="1394" citStr="Roark et al., 2007" startWordPosition="189" endWordPosition="192"> learning (such as ℓ1/ℓ2 regularization) to discover common feature representations across Nbest lists. This meta-algorithm is simple to implement, and its modular approach allows one to plug-in different learning algorithms from existing literature. As a proof of concept, we show statistically significant improvements on a machine translation system involving millions of features. 1 Introduction Many natural language processing applications, such as machine translation (MT), parsing, and language modeling, benefit from the N-best reranking framework (Shen et al., 2004; Collins and Koo, 2005; Roark et al., 2007). The advantage of N-best reranking is that it abstracts away the complexities of first-pass decoding, allowing the researcher to try new features and learning algorithms with fast experimental turnover. In the N-best reranking scenario, the training data consists of sets of hypotheses (i.e. N-best lists) generated by a first-pass system, along with their labels. Given a new N-best list, the goal is to rerank it such that the best hypothesis appears near the top of the list. Existing research have focused on training a single reranker directly on the entire data. This approach is reasonable if</context>
</contexts>
<marker>Roark, Saraclar, Collins, 2007</marker>
<rawString>Brian Roark, Murat Saraclar, and Michael Collins. 2007. Discriminative n-gram language modeling. Computer Speech and Language, 21(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Anoop Sarkar</author>
<author>Franz Och</author>
</authors>
<title>Discriminative reranking for machine translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="1350" citStr="Shen et al., 2004" startWordPosition="181" endWordPosition="184">m solves this challenge by using multitask learning (such as ℓ1/ℓ2 regularization) to discover common feature representations across Nbest lists. This meta-algorithm is simple to implement, and its modular approach allows one to plug-in different learning algorithms from existing literature. As a proof of concept, we show statistically significant improvements on a machine translation system involving millions of features. 1 Introduction Many natural language processing applications, such as machine translation (MT), parsing, and language modeling, benefit from the N-best reranking framework (Shen et al., 2004; Collins and Koo, 2005; Roark et al., 2007). The advantage of N-best reranking is that it abstracts away the complexities of first-pass decoding, allowing the researcher to try new features and learning algorithms with fast experimental turnover. In the N-best reranking scenario, the training data consists of sets of hypotheses (i.e. N-best lists) generated by a first-pass system, along with their labels. Given a new N-best list, the goal is to rerank it such that the best hypothesis appears near the top of the list. Existing research have focused on training a single reranker directly on the</context>
<context position="6491" citStr="Shen et al., 2004" startWordPosition="1027" endWordPosition="1030"> following issues compound to create extremely sparse feature sets: 1. Feature templates are heavily-lexicalized, which causes the number of features to grow unbounded as the the amount of data increases. 2. The input (f) has high variability (e.g. large vocabulary size), so that features for different inputs are rarely shared. 3. The N-best list output also exhibits high variability (e.g. many different word reorderings). Larger N may improve reranking performance, but may also increase feature sparsity. When the number of features is too large, even popular reranking algorithms such as SVM (Shen et al., 2004) and MIRA (Watanabe et al., 2007; Chiang et al., 2009) may fail. Our goal here is to address this situation. 3 Proposed Reranking Framework In the following, we first give an intuitive comparison between single vs. multiple task learning (Section 3.1), before presenting the general metaalgorithm (Section 3.2) and particular instantiations (Section 3.3). 3.1 Single vs. Multiple Tasks Given a set of I input sentences {f&apos;}, the training data for reranking consists of a set of I N-best lists {(H&apos;, y&apos;)}&apos;=1,...,z, where H&apos; are features and y&apos; are labels. To clarify the notation:1 for an input senten</context>
<context position="8091" citStr="Shen et al., 2004" startWordPosition="1307" endWordPosition="1310">ranker training algorithm is to find good parameters from {(H&apos;, y&apos;)}. 1Generally we use bold font h to represent a vector, boldcapital font H to represent a matrix. Script h and h(·) may be scalar, function, or sentence (depends on context). 376 The conventional method of training a single reranker (single task formulation) involves optimizing a generic objective such as: L(w, Hi, yi) + λΩ(w) (4) where w ∈ RD is the reranker trained on all lists, and L(·) is some loss function. Ω(w) is an optional regularizer, whose effect is traded-off by the constant λ. For example, the SVM reranker for MT (Shen et al., 2004) defines L(·) to be some function of sentence-level BLEU score, and Ω(w) to be the large margin regularizer.2 On the other hand, multitask learning involves solving for multiple weights, w1, w2, . . . ,wI, one for each N-best list. One class of multitask learning algorithms, Joint Regularization, solves the following objective: L(wi, Hi, yi) + λΩ(w1, .., wI) (5) The loss decomposes by task but the joint regularizer Ω(w1, .., wI) couples together the different weight parameters. The key is to note that multiple weights allow the algorithm to fit the heterogenous data better, compared to a singl</context>
<context position="19370" citStr="Shen et al., 2004" startWordPosition="3227" endWordPosition="3230">3824 Average 2599 – 4188 Table 1: Feature growth rate: For N-best list i in the table, we have (#NewFt = number of new features introduced since N-best i − 1) ; (#SoFar = Total number of features defined so far); and (#Active = number of active features for N-best i). E.g., we extracted 7535 new features from N-best 2; combined with the 3900 from N-best 1, the total features so far is 11435. gorithm 1) used in all cases is SVM,,,k.8 Our initial experiments show that the SVM baseline performance is comparable to MIRA training, so we use SVM throughout. The labels for the SVM are derived as in (Shen et al., 2004), where top 10% of hypotheses by smoothed sentence-BLEU is ranked before the bottom 90%. All multitask learning methods work on hashed features of dimension 4000 (Step 1, Algorithm 1). This speeds up the training process. All hyperparameters of the multitask method are tuned on the held-out set. In particular, the most important is the number of common features to extract, which we pick from {250, 500, 1000}. Table 2 shows the results by BLEU (Papineni et al., 2002) and PER. The Oracle results are obtained by choosing the best hypothesis per N-best list by sentence-level BLEU, which achieved 3</context>
</contexts>
<marker>Shen, Sarkar, Och, 2004</marker>
<rawString>Libin Shen, Anoop Sarkar, and Franz Och. 2004. Discriminative reranking for machine translation. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Jun’ichi Tsujii</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Stochastic gradient descent training for l1-regularized log-linear models with cumulative penalty.</title>
<date>2009</date>
<booktitle>In ACL-IJCNLP.</booktitle>
<marker>Tsuruoka, Tsujii, Ananiadou, 2009</marker>
<rawString>Yoshimasa Tsuruoka, Jun’ichi Tsujii, and Sophia Ananiadou. 2009. Stochastic gradient descent training for l1-regularized log-linear models with cumulative penalty. In ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
<author>Jun Suzuki</author>
<author>Hajime Tsukada</author>
<author>Hideki Isozaki</author>
</authors>
<title>Online large-margin training for statistical machine translation.</title>
<date>2007</date>
<booktitle>In EMNLPCoNLL.</booktitle>
<contexts>
<context position="4756" citStr="Watanabe et al., 2007" startWordPosition="734" endWordPosition="737">e, f) is a D-dimensional feature vector, w is the weight vector to be trained, and N(f) is the set of likely translations of f, i.e. the N-best list. The feature h(e, f) can be any quantity defined in terms of the sentence pair, such as translation model and language model probabilities. Here we are interested in situations where the feature definitions can be quite sparse. A common methodology in reranking is to first design feature templates based on linguistic intuition and domain knowledge. Then, numerous features are instantiated based on the training data seen. For example, the work of (Watanabe et al., 2007) defines feature templates based on bilingual word alignments, which lead to extraction of heavilylexicalized features of the form: h(e, f) = { 1 if foreign word “Monsieur” 0 otherwise and English word “Mr.” co-occur in e,f One can imagine that such features are sparse because it may only fire for input sentences that contain the word “Monsieur”. For all other input sentences, it is an useless, inactive feature. Another common feature involves word ngram templates, for example: h(e, f) = { 1 if English trigram 0 otherwise “Mr. Smith said” occurs in e In this case, all possible trigrams seen in</context>
<context position="6523" citStr="Watanabe et al., 2007" startWordPosition="1033" endWordPosition="1036"> create extremely sparse feature sets: 1. Feature templates are heavily-lexicalized, which causes the number of features to grow unbounded as the the amount of data increases. 2. The input (f) has high variability (e.g. large vocabulary size), so that features for different inputs are rarely shared. 3. The N-best list output also exhibits high variability (e.g. many different word reorderings). Larger N may improve reranking performance, but may also increase feature sparsity. When the number of features is too large, even popular reranking algorithms such as SVM (Shen et al., 2004) and MIRA (Watanabe et al., 2007; Chiang et al., 2009) may fail. Our goal here is to address this situation. 3 Proposed Reranking Framework In the following, we first give an intuitive comparison between single vs. multiple task learning (Section 3.1), before presenting the general metaalgorithm (Section 3.2) and particular instantiations (Section 3.3). 3.1 Single vs. Multiple Tasks Given a set of I input sentences {f&apos;}, the training data for reranking consists of a set of I N-best lists {(H&apos;, y&apos;)}&apos;=1,...,z, where H&apos; are features and y&apos; are labels. To clarify the notation:1 for an input sentence f&apos;, there is a N-best list N(</context>
<context position="14549" citStr="Watanabe et al., 2007" startWordPosition="2427" endWordPosition="2430"> citations in, e.g. (Argyriou et al., 2008) for a survey. 4 Experiments and Results As a proof of concept, we perform experiments on a MT system with millions of features. We use a hierarchical phrase-based system (Chiang, 100 10−1 10−2 10−3 10−4 10−5 10−6 10−7 100 101 102 103 104 x Figure 1: This log-log plot shows that there are many rare features and few common features. The probability that a feature occurs in x number of Nbest lists behaves according to the power-law x−α, where α = 2.28. 2007) to generate N-best lists (N=100). Sparse features used in reranking are extracted according to (Watanabe et al., 2007). Specifically, the majority are lexical features involving joint occurrences of words within the N-best lists and source sentences. It is worth noting that the fact that the first pass system is a hierarchical system is not essential to the feature extraction step; similar features can be extracted with other systems as first-pass, e.g. a phrase-based system. That said, the extent of the feature sparsity problem may depend on the performance of the first-pass system. We experiment with medical domain MT, where large numbers of technical vocabulary cause sparsity challenges. Our corpora consis</context>
<context position="17250" citStr="Watanabe et al., 2007" startWordPosition="2885" endWordPosition="2888">ng algorithm (e.g. MIRA or perceptron) on this kind of data: whenever a loss occurs and we update the weight vector, less than half of the weight vector update applies to data we have seen thus far. Herein lies the potential for overfitting. From observing the feature grow rate, one may hypothesize that adding large numbers of N-best lists to the training set (500 in the experiments here) may not necessarily improve results. While adding data potentially improves the estimation process, it also increases the feature space dramatically. Thus we see the need for a feature extraction procedure. (Watanabe et al., 2007) also reports the possibility of overfitting in their dataset (Arabic-English newswire translation), especially when domain differences are present. Here we observe this tendency already on the same domain, which is likely due to the highly-specialized vocabulary and the complex sentence structures common in research paper abstracts. 4.2 MT Results Our goal is to compare different feature representations in reranking: The baseline reranker uses the original sparse feature representation. This is compared to feature representations discovered by three different multitask learning methods: • Joi</context>
<context position="26214" citStr="Watanabe et al., 2007" startWordPosition="4300" endWordPosition="4303">for hierarchical phrase-based MT, while (Collins and Koo, 2005) describes features for parsing. Evaluation campaigns like WMT (Callison-Burch et al., 2009) and IWSLT (Paul, 2009) also contains a wealth of information for feature engineering in various MT tasks. 2. Designing better training algorithms: Nbest reranking can be seen as a subproblem of structured prediction, so many general structured prediction algorithms (c.f. (Bakir et al., 2007)) can be applied. In fact, some structured prediction algorithms, such as the MIRA algorithm used in dependency parsing (McDonald et al., 2005) and MT (Watanabe et al., 2007) uses iterative sets of N-best lists in its training process. Other training algorithms include perceptron-style algorithms (Liang et al., 2006), MaxEnt (Charniak and Johnson, 2005), and boosting variants (Kudo et al., 2005). The division into two research focuses is convenient, but may be suboptimal if the training algorithm and features do not match well together. Our work can be seen as re-connecting the two focuses, where the training algorithm is explicitly used to help discover better features. Multitask learning is currently an active subfield within machine learning. There has already </context>
</contexts>
<marker>Watanabe, Suzuki, Tsukada, Isozaki, 2007</marker>
<rawString>Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki Isozaki. 2007. Online large-margin training for statistical machine translation. In EMNLPCoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilian Weinberger</author>
<author>Anirban Dasgupta</author>
<author>John Langford</author>
<author>Alex Smola</author>
<author>Josh Attenberg</author>
</authors>
<title>Feature hashing for large scale multitask learning.</title>
<date>2009</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="10365" citStr="Weinberger et al., 2009" startWordPosition="1706" endWordPosition="1709">ur general reranking meta-algorithm (see Algorithm 1), termed Reranking by Multitask Learning (RML) . Algorithm 1 Reranking by Multitask Learning Input: N-best data {(Hi, yi)}i=1,...,I Output: Common feature representation hc(e, f) and weight vector wc 1: [optional] RandomHashing({Hi}) 2: W = MultitaskLearn({(Hi, yi)}) 3: hc = ExtractCommonFeature(W) 4: {Hic} = RemapFeature({Hi}, hc) 5: wc = ConventionalReranker({(Hi c, yi)}) The first step, random hashing, is optional. Random hashing is an effective trick for reducing the dimension of sparse feature sets without suffering losses in fidelity (Weinberger et al., 2009; Ganchev and Dredze, 2008). It works by collapsing random subsets of features. This step can be performed to speed-up multitask learning later. In some cases, the original feature dimension may be so large that hashed representations may be necessary. The next two steps are key. A multitask learning algorithm is run on the N-best lists, and a common feature space shared by all lists is extracted. For example, if one uses the multitask objective of Eq. 5, the result of step 2 is a set of weights W. ExtractCommonFeature(W) then returns the feature id’s (either from original or hashed representa</context>
</contexts>
<marker>Weinberger, Dasgupta, Langford, Smola, Attenberg, 2009</marker>
<rawString>Kilian Weinberger, Anirban Dasgupta, John Langford, Alex Smola, and Josh Attenberg. 2009. Feature hashing for large scale multitask learning. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Yu</author>
<author>Volker Tresp</author>
</authors>
<title>Learning to learn and collaborative filtering.</title>
<date>2005</date>
<booktitle>In NIPS-2005 Workshop on Inductive Transfer.</booktitle>
<contexts>
<context position="13784" citStr="Yu and Tresp, 2005" startWordPosition="2293" endWordPosition="2296">l tasks. Early works on multitask learning implement this by neural networks, where different tasks have different output layers but share the same hidden layer (Caruana, 1997). Another method is to write the weight vector as two parts w = [u; v] and let the task-specific function be uT · h(e, f) + vT · O · h(e, f) (Ando and Zhang, 2005). O is a D′ xD matrix that maps the original features to a subspace common to all tasks. The new feature representation is computed by the projection h,(e, f) °= O · h(e, f). Multitask learning is a vast field and relates to areas like collaborative filtering (Yu and Tresp, 2005) and domain adaptation. Most methods assume some common representation and is thus applicable to our framework. The reader is urged to refer to citations in, e.g. (Argyriou et al., 2008) for a survey. 4 Experiments and Results As a proof of concept, we perform experiments on a MT system with millions of features. We use a hierarchical phrase-based system (Chiang, 100 10−1 10−2 10−3 10−4 10−5 10−6 10−7 100 101 102 103 104 x Figure 1: This log-log plot shows that there are many rare features and few common features. The probability that a feature occurs in x number of Nbest lists behaves accordi</context>
</contexts>
<marker>Yu, Tresp, 2005</marker>
<rawString>Kai Yu and Volker Tresp. 2005. Learning to learn and collaborative filtering. In NIPS-2005 Workshop on Inductive Transfer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Zhang</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Interpreting BLEU/NIST scores: How much improvement do we need to have a better system?</title>
<date>2004</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="21073" citStr="Zhang et al., 2004" startWordPosition="3497" endWordPosition="3500">ut in reranking the lack of tying between lists makes this regularizer inappropriate. A small set of around 1200 features are chosen: they perform well independently on each task in the training data, but there is little sharing with the test data. 3. All three multitask methods obtained features that outperformed the baseline. The BLEU scores are 28.8, 28.9, 29.1 for Unsupervised Feature Selection, Joint Regularization, and Shared Subspace, respectively, which all outperform the 28.6 baseline. All improvements are statistically significant by bootstrap sampling test (1000 samples, p &lt; 0.05) (Zhang et al., 2004). 4. Shared Subspace performed the best. We conjecture this is because its feature projection can create new feature combinations that is more expressive than the feature selection used by the two other methods. 5. PER results are qualitatively similar to BLEU results. 6. As a further analysis, we are interested in seeing whether multitask learning extracts novel features, especially those that have low frequency. Thus, we tried an additional feature representation (feature threshold) which only keeps features that occur in more than x Nbests, and concatenate these high-frequency features to t</context>
</contexts>
<marker>Zhang, Vogel, Waibel, 2004</marker>
<rawString>Ying Zhang, Stephan Vogel, and Alex Waibel. 2004. Interpreting BLEU/NIST scores: How much improvement do we need to have a better system? In LREC.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>