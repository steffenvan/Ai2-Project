<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999533">
A Constraint-Based Hypergraph Partitioning
Approach to Coreference Resolution
</title>
<author confidence="0.5945774">
Emili Sapena*
Universitat Polit`ecnica de Catalunya
Llu´ıs Padr´o**
Universitat Polit`ecnica de Catalunya
Jordi Turmo†
</author>
<bodyText confidence="0.979592352941176">
Universitat Polit`ecnica de Catalunya
This work is focused on research in machine learning for coreference resolution. Coreference
resolution is a natural language processing task that consists of determining the expressions in
a discourse that refer to the same entity.
The main contributions of this article are (i) a new approach to coreference resolution
based on constraint satisfaction, using a hypergraph to represent the problem and solving it
by relaxation labeling; and (ii) research towards improving coreference resolution performance
using world knowledge extracted from Wikipedia.
The developed approach is able to use an entity-mention classification model with more
expressiveness than the pair-based ones, and overcome the weaknesses of previous approaches
in the state of the art such as linking contradictions, classifications without context, and lack
of information evaluating pairs. Furthermore, the approach allows the incorporation of new
information by adding constraints, and research has been done in order to use world knowledge
to improve performances.
RelaxCor, the implementation of the approach, achieved results at the state-of-the-art level,
and participated in international competitions: SemEval-2010 and CoNLL-2011. RelaxCor
achieved second place in CoNLL-2011.
</bodyText>
<sectionHeader confidence="0.996906" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999479">
Coreference resolution is a natural language processing (NLP) task that consists of
determining which mentions in a discourse refer to the same entity or event. A men-
tion is a referring expression that has an entity or event as a referent. By referring
expression we mean noun phrases (NP), named entities (NEs), embedded nouns, and
pronouns (all but pleonastic and interrogative ones) whose meaning as a whole is a
</bodyText>
<affiliation confidence="0.413221">
* TALP Research Center, Universitat Polit`ecnica de Catalunya. E-mail: esapena®lsi.upc.edu.
** TALP Research Center, Universitat Polit`ecnica de Catalunya. E-mail: padro®lsi.upc.edu.
† TALP Research Center, Universitat Polit`ecnica de Catalunya. E-mail: turmo®lsi.upc.edu.
</affiliation>
<note confidence="0.8173288">
Submission received: 12 March 2012; revised submission received: 14 September 2012; accepted for
publication: 13 November 2012.
doi:10.1162/COLI a 00151
© 2013 Association for Computational Linguistics
Computational Linguistics Volume 39, Number 4
[[FC Barcelona]0 president Joan Laporta]1 has warned [Chelsea]2 off [star striker Lionel
Messi]3.
Aware of [[Chelsea]2 owner Roman Abramovich]4’s interest in [the young Argentine]3,
[Laporta]1 said last night: “[I]1 will answer as always, [Messi]3 is not for sale and [we]0
do not want to let [him]3 go.”
</note>
<figureCaption confidence="0.969191">
Figure 1
</figureCaption>
<bodyText confidence="0.995893119047619">
Example of coreference resolution. All the mentions are annotated with a subscript indicating
their coreference chain. Boldfaced mentions refer to the entity Lionel Messi.
reference to an entity or event in the real world, which is what we call referent. In
this article, we do not deal with coreference involving events, and focus only on entity
correference.
Coreference chains or entities are groups of referring expressions that have the
same referent. Thus, a coreference chain is formed by all mentions in a discourse that
refer to the same real entity. Given an arbitrary text as input, the goal of a coreference
resolution system is to find all the coreference chains. A partial entity is a set of
mentions considered coreferential during resolution.
Figure 1 shows the mentions of a newspaper article and their corresponding coref-
erence chains. Note that the difficulty of coreference resolution lies in the variety of
necessary knowledge sources. For instance, morphological and syntactic analysis is
needed to detect mentions, and semantic/world knowledge to know that Messi is a
star striker and a young Argentine.
Coreference resolution is a mandatory step in order to understand natural language.
In this sense, dealing with such a problem becomes important for tasks in which the
higher their comprehension of the discourse, the better such systems will perform—
tasks such as machine translation (Peral, Palomar, and Ferr´andez 1999), question an-
swering (Morton 2000), summarization (Azzam, Humphreys, and Gaizauskas 1999),
and information extraction.
One of the possible directions to follow in coreference resolution research is
the incorporation of new information such as world knowledge and discourse co-
herence. In some cases, this information cannot be expressed in terms of pairs of
mentions—that is, it is information that involves either several mentions at once or
partial entities. Furthermore, an experimental approach in this field should over-
come the weaknesses of previous state-of-the-art approaches, such as linking contra-
dictions, classifications without context, and a lack of information when evaluating
pairs.
This article presents an approach for coreference resolution based on constraint
satisfaction that represents the problem in a hypergraph and solves it by relaxation
labeling. One of the main goals of developing such an approach is the incorporation
of world knowledge and discourse coherence in order to improve performance while
addressing the problems mentioned previously.
The article is structured as follows. Section 2 summarizes the state of the art of
machine learning approaches to coreference resolution, highlighting their most rele-
vant parts with their corresponding issues. Section 3 defines our proposed approach
and Section 4 provides details about the implementation and the training methods.
The experiments and error analysis are described in Section 5. Section 6 presents our
approach to incorporate world knowledge in order to improve coreference resolution
performance. Experiments and a detailed error analysis are also included. Finally, we
discuss the conclusions of this article in Section 7.
</bodyText>
<page confidence="0.992261">
848
</page>
<note confidence="0.781886">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
</note>
<sectionHeader confidence="0.703093" genericHeader="method">
2. Coreference Resolution: State of the Art
</sectionHeader>
<bodyText confidence="0.997701066666667">
In this section we summarize the main machine-learning–based approaches to corefer-
ence resolution. For a wider study, we refer the reader to Mitkov (2002).
A coreference resolution system receives plain text as input, and returns the same
text with coreference annotations as output. Most existing coreference resolution sys-
tems can be considered instances of this general process, which consists of three main
steps: mention detection, characterization of mentions, and resolution (see Figure 2).
The first step is the detection of mentions, where text processing is needed in order
to find the boundaries of the mentions in the input text. Next, in the second step, the
identified mentions are characterized by gathering all the available knowledge about
them and their possible compatibility. Typically, machine learning systems introduce all
the knowledge by means of feature functions. Finally, the resolution itself is performed
in the third step. A generalization of the inner architecture of the resolution step is
difficult given the diversity of approaches and algorithms used for resolution. Even
so, the diverse approaches in current systems have at least two main processes in the
resolution: classification and linking.
</bodyText>
<listItem confidence="0.830615909090909">
• Classification. This process evaluates the compatibility of elements in
order to corefer. The elements can be mentions or partial entities. A typical
implementation is a binary classifier that assigns class CO (coreferential)
or NC (not coreferential) to a pair of mentions. It is also very typical to use
confidence values or probabilities associated with the class. Classifiers can
also use rankers and constraints.
• Linking. The linking process links mentions and partial entities in order
to form the final entities. This process may range from a simple heuristic,
such as single-link, to an elaborate algorithm such as clustering or graph
partitioning. The input of the linking process includes the output of the
classification process: classes and probabilities.
</listItem>
<subsectionHeader confidence="0.884198">
2.1 Classification Models
</subsectionHeader>
<bodyText confidence="0.998206571428571">
The models found in the state of the art for the classification process are: mention pairs,
rankers, and entity-mention.
Mention pairs. Classifiers based on the mention-pair model determine whether two
mentions corefer or not. To do so, a feature vector is generated for a pair of mentions
using a set of features. Given these features as input, the classifier returns a class:
CO (coreferent), or NC (not coreferent). In many cases, the classifier also returns a
confidence value about the decision taken. The class and the confidence value of each
</bodyText>
<figureCaption confidence="0.772053">
Figure 2
</figureCaption>
<bodyText confidence="0.624821">
Architecture of a coreference resolution system.
</bodyText>
<page confidence="0.992433">
849
</page>
<figure confidence="0.638927">
Computational Linguistics Volume 39, Number 4
Figure 3
A pairwise classifier does not have enough information to classify pairs (A. Smith, he) and (A.
Smith, she).
</figure>
<bodyText confidence="0.99855965">
evaluated pair of mentions will be taken into account by the linking process to obtain
the final result.
The mention-pair model has two main weaknesses: a lack of contextual infor-
mation and contradictions in classifications. Figure 3 shows an example of lack of
information. The figure is a representation of a document with four mentions (Alice
Smith, A. Smith, he, she). The edges between mentions represent the classification in
a mention-pair model; green means that the classifier returns the CO class, and red
(also marked with an X) returns the NC class. In this case, the lack of information is
due to the impossibility of determining the gender of A. Smith. Next, Figure 4 shows
a possible scenario with contradictions. In this scenario, the classifier has determined
that the pairs (A. Smith, he) and (A. Smith, she) corefer, which causes contradictions
when generating the final coreference chains given that the pairs (Alice Smith, he) and
(he, she) do not corefer.
Rankers. The rankers model overcomes the lack of contextual information found using
mention-pairs. Instead of directly considering whether mi and mj corefer, more perspec-
tive can be achieved by looking for the best candidate from a group of mentions to
corefer with an active mention. Rankers can still fall in contradictions, however, and
need to rely on the linking process to solve that.
Entity-mention. The entity-mention model classifies a partial entity and a mention, or
two partial entities, as coreferent or not. In some models, a partial entity even has its
</bodyText>
<figureCaption confidence="0.701267">
Figure 4
</figureCaption>
<bodyText confidence="0.651797">
Green edges mean that both mentions corefer, and red edges mean the opposite. An
independent classification of (A. Smith, he) and (A. Smith, she) produces contradictions.
</bodyText>
<page confidence="0.99333">
850
</page>
<note confidence="0.672584">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
</note>
<bodyText confidence="0.9999619">
own properties or features defined in the model in order to be compared with the
mentions. Due to the information that a partial entity gives to the classifier, in most
cases this model overcomes the lack of information and contradiction problems of the
mention-based models. For example, a partial entity may include the mentions Alice
Smith and A. Smith, whose genders are “female” and “unknown” respectively. In this
case, the partial entity is more likely to be linked with the subsequent mention she than
with he (Figures 3 and 4). The features used for entity-mention models are almost the
same as those used for mention-based models. The only difference is that the value of
an entity feature is determined by considering the particular values of the mentions
belonging to it.
</bodyText>
<subsectionHeader confidence="0.94302">
2.2 Resolution
</subsectionHeader>
<bodyText confidence="0.999489666666667">
The coreference resolution engines in the state of the art can be classified into three
paradigms depending on their resolution process (i.e., combinations of classification
and linking processes):
</bodyText>
<listItem confidence="0.9809713">
• Backward search approaches classify mentions with previous ones,
looking for the best antecedents. In this case, the linking step is typically
an heuristic that links mention pairs classified as positive (single-link).
• Two-step approaches perform the resolution in two separate steps. The
first step is to classify all of the elements, and then the second step is a
linking process using algorithms such as graph partitioning or clustering
to optimize the results given the classification output.
• One-step approaches directly run the linking process while classification
is performed on-line. In this manner, mention-group and entity-mention
models can be easily incorporated.
</listItem>
<bodyText confidence="0.998390857142857">
Figure 5 summarizes the classification of several systems in the state of the art,
up to 2011. Recently, the CoNLL-2012 shared task (Pradhan et al. 2012) offered an
evaluation framework similar to that of CoNLL-2011. The second column specifies
which resolution step is used. The third column shows the classification model used
by the system, and the fourth column identifies the algorithm followed in the linking
process.
More details about supervised machine learning systems can be found in Ng (2010).
</bodyText>
<sectionHeader confidence="0.924445" genericHeader="method">
3. A Constraint-Based Hypergraph Partitioning Approach to Coreference Resolution
</sectionHeader>
<bodyText confidence="0.9999792">
One of the possible directions to follow in coreference resolution research is the incorpo-
ration of new information such as world knowledge and discourse coherence. In some
cases, this information cannot be expressed in terms of pairs of mentions, that is, it is
information that involves either several mentions at once or partial entities. Therefore,
an experimental approach in this field needs the expressiveness of the entity-mention
model as well as the mention-pair model in order to use the most typical mention-pair
features. Furthermore, such an approach should overcome the weaknesses of previous
state-of-the-art approaches, such as linking contradictions, classifications without con-
text, and a lack of information when evaluating pairs. Also, the approach would be
more flexible if it could incorporate knowledge both automatically and manually.
</bodyText>
<page confidence="0.997007">
851
</page>
<table confidence="0.86641828">
Computational Linguistics Volume 39, Number 4
Approach Resolution Classification Model Linking process
Aone and Bennett (1995) backward mention pairs heuristic
McCarthy and Lehnert (1995) search
Soon, Ng, and Lim (2001)
Ponzetto and Strube (2006)
Yang, Su, and Tan (2006)
Ng and Cardie (2002)
Ng (2005)
Ng (2007)
Ji, Westbrook, and Grishman (2005)
Bengtson and Roth (2008)
Stoyanov et al. (2009)
Ng (2009)
Uryupina (2009)
Yang et al. (2003)
Denis and Baldridge (2008)
Yang et al. (2008)
Rahman and Ng (2011b)
Luo et al. (2004)
Luo (2007)
rankers
entity-
mention
global
optimization
Klenner and Ailloud (2008) two step mention pairs clustering
Nicolae and Nicolae (2006)
Denis and Baldridge (2007)
Klenner (2007)
Finkel and Manning (2008)
Bean et al. (2004)
Cardie and Wagstaff (1999)
Ng (2008)
graph partitioning
global
optimization
clustering
Culotta, Wick, and McCallum (2007) one step entity-
Finley and Joachims (2005) mention
Cai and Strube (2010)
Yang et al. (2004)
McCallum and Wellner (2005)
Haghighi and Klein (2007)
Poon and Domingos (2008)
hypergraph partitioning
clustering
graph partitioning
global
optimization
</table>
<figureCaption confidence="0.799094">
Figure 5
</figureCaption>
<bodyText confidence="0.9227952">
A classification of coreference resolution approaches in state-of-the-art machine-learning systems.
Given these prerequisites, we define an approach based on constraint satisfaction
that represents the problem in a hypergraph and solves it by relaxation labeling, re-
ducing coreference resolution to a hypergraph partitioning problem with a given set of
constraints. The main strengths of this system are:
</bodyText>
<listItem confidence="0.954007">
• Modeling the problem in terms of hypergraph partitioning avoids linking
contradictions and errors caused by a lack of information or context.
• Constraints are compatible with the mention-pair and entity-mention
models, which let us incorporate new information. Moreover, constraints
can be both automatically learned and manually written.
• Relaxation labeling is an iterative algorithm that performs function
optimization based on local information. It first determines the entities of
the mentions in which it has more confidence, mainly solving the problem
of lack of information for some pairs and the lack of context. The iterative
resolution facilitates the use of the entity-mention model.
</listItem>
<bodyText confidence="0.9527605">
The rest of this section describes the details of the approach. Section 3.1 describes
the problem representation in a (hyper)graph. Next, Section 3.2 explains how the
</bodyText>
<page confidence="0.996762">
852
</page>
<bodyText confidence="0.9029234">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
knowledge is represented as a set of constraints, and Section 3.3 explains how attach-
ing influence rules to the constraints means that the approach incorporates the entity-
mention model. Finally, Section 3.4 describes the relaxation labeling algorithm used for
resolution.
</bodyText>
<subsectionHeader confidence="0.999169">
3.1 Graph and Hypergraph Representations
</subsectionHeader>
<bodyText confidence="0.99980485">
The coreference resolution problem consists of a set of mentions that have to be
mapped to a minimal collection of individual entities. By representing the problem
in a hypergraph, we are reducing coreference resolution to a hypergraph partitioning
problem. Each partition obtained in the resolution process is finally considered
an entity.
The document mentions are represented as vertices in a hypergraph. Each of
these vertices is connected by hyperedges to other vertices. Hyperedges are assigned
a weight that indicates the confidence that adjacent mentions corefer. The larger the
hyperedge weight in absolute terms, the more reliable the hyperedge. In the case of the
mention-pair model, the problem is represented as a graph where edges connect pairs
of vertices.
Let G = G(V,E) be an undirected hypergraph, where V is a set of vertices and E is
a set of hyperedges. Let m = (m1,. . . , mn) be the set of mentions of a document with n
mentions to resolve. Each mention mi in the document is represented as a vertex vi E V.
A hyperedge eg E E is added to the hypergraph for each group (g) of vertices (v0, ... ,vN)
affected by a constraint, as shown in Figure 6. The subset of hyperedges that incide on
vi is E(vi).
A subset of constraints Cg C_ C restricts the compatibility of a group of mentions. Cg
is used to compute the weight value of the hyperedge eg. Let w(eg) E W be the weight
of the hyperedge eg:
</bodyText>
<equation confidence="0.964085">
�w(eg) = Ak (1)
k∈Cg
</equation>
<bodyText confidence="0.99390775">
where Ak is the weight associated with constraint k. The graph representing the mention-
pair model is a subcase of the hypergraph where |g |= 2. Figure 7 illustrates a graph. For
simplicity, in the case of the mention-pair model, an edge between mi and mj is called
eij. In addition, sometimes wij is used instead of w(eij).
</bodyText>
<footnote confidence="0.912396">
Figure 6
Example of hypergraph representing the mentions of a document connected by hyperedges
(mention-group model).
</footnote>
<page confidence="0.997343">
853
</page>
<figure confidence="0.875565">
Computational Linguistics Volume 39, Number 4
</figure>
<figureCaption confidence="0.582067">
Figure 7
Example of graph representing the mentions of a document connected by edges (mention-pair
model).
Figure 8
</figureCaption>
<figure confidence="0.851964">
Example of a mention-pair constraint (N = 2).
DIST SEN 1(0,1) &amp; DIST SEN 1(1,2) &amp;
AGREEMENT YES(0,1,2) &amp; ALIAS YES(0,2) &amp;
SRL ARG 0(0) &amp; SRL ARG 0(1) &amp; SRL ARG 0(2) &amp;
TYPE E(0) &amp; TYPE S(1) &amp; TYPE E(2)
</figure>
<figureCaption confidence="0.930491">
Figure 9
</figureCaption>
<bodyText confidence="0.591142">
Example of a mention-group constraint (N = 3).
</bodyText>
<subsectionHeader confidence="0.999653">
3.2 Constraints as Knowledge Representation
</subsectionHeader>
<bodyText confidence="0.997478578947368">
In this approach, knowledge is a set of weighted constraints where each constraint
contributes a piece of information that helps to determine the coreferential relations
between mentions. A constraint is a conjunction of feature-value pairs that are evaluated
over all the pairs or groups of mentions in a document. When a constraint applies to a
set of mentions, a corresponding hyperedge is added to the hypergraph, generating the
representation of the problem explained in Section 3.1 (Figure 6).
Let N be the order of a constraint, that is, the number of mentions expected by the
constraint (|g|). A pair constraint has order N = 2, and a group constraint has N &gt; 2.
The mentions evaluated by a constraint are numbered from 0 to N − 1 in the order they
are found in the document.
Figures 8 and 9 show examples of constraints for N = 2 and N = 3, respectively.
The constraint in Figure 8 requires that: The distance between the mentions is just
one sentence, their genders match, m0 is not the first mention of its sentence, m0 is
a maximal NP (the next parent node in the syntactic tree is the sentence itself), m1
also is a maximal NP, both mentions are ARG0 in semantic role labeling, and both
mentions are pronouns.1 The constraint in Figure 9 applies to three mentions and
requires that: The distance between consecutive mentions is one sentence, all three
mentions agree in both gender and number, m0 and m2 are aliases, all three mentions
are ARG0 in their respective sentences, and m0 and m2 are named entities and m1 is
</bodyText>
<equation confidence="0.8824432">
1 The argument system used is due to PropBank (Kingsbury and Palmer 2003).
DIST SEN 1(0,1) &amp; GENDER YES(0,1) &amp; ¬ FIRST(0) &amp;
MAXIMALNP(0) &amp; MAXIMALNP(1) &amp;
SRL ARG 0(0) &amp; SRL ARG 0(1) &amp;
TYPE P(0) &amp; TYPE P(1)
</equation>
<page confidence="0.994829">
854
</page>
<bodyText confidence="0.9662036">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
a common NP.2 There are many examples of negative constraints, that is, constraints
that restrict mentions from being in the same entity. For instance GENDER NO(0,1)
&amp; TYPE P(0) &amp; TYPE P(1) expresses that m1 and m0 are pronouns and do not match
in gender.
Each constraint has a weight that determines the hyperedge weight of the hyper-
graph (see Equation (1)). A constraint weight is a value that, in absolute terms, reflects
the confidence of the constraint. Moreover, this weight is signed, and the sign indicates
whether the adjacent mentions corefer (positive) or not (negative). The use of negative
information is not very extensive in state-of-the-art systems, but given the hypergraph
representation of the problem, where most of the mentions are interconnected, the
negative weights contribute information that cannot be obtained using only positive
weights. Moreover, in our experiments, the use of negative weights accelerates the
convergence of the resolution algorithm. The training process that determines the
weight of each constraint is explained in Section 4.3.
</bodyText>
<subsectionHeader confidence="0.941149">
3.3 Entity-Mention Model Using Influence Rules
</subsectionHeader>
<bodyText confidence="0.999620090909091">
We have explained how groups of mentions satisfying a constraint are connected by
hyperedges in the hypergraph. This section explains how the entity-mention model
is definitively incorporated to our constraint-based hypergraph approach. The entity-
mention model takes advantage of the concept of an entity during the resolution pro-
cess. This means that each mention belongs to an entity during resolution, and this
information can be used to make new decisions.
In order to incorporate the entity-mention model into our approach, we define
the influence rule, which is attached to a constraint. An influence rule expresses the
conditions that the mentions must meet during resolution before the influence of the
constraint takes effect.
An influence rule consists of two parts: condition and action.
</bodyText>
<listItem confidence="0.934265833333333">
• The condition of an influence rule is a conjunction of coreference relations
that the mentions must satisfy before the constraint has influence. This
condition is specified by joining mentions into groups, where each
group represents a partial entity specified by a subscript. For instance,
(0,1)A, (2)B means that mentions 0 and 1 belong to entity A and mention 2
belongs to entity B (A =� B).
• The action of an influence rule defines the desired coreference relation
and determines which mentions are influenced. It is expressed in the
same terms as the condition, specifying the mentions that are influenced
and the entity to which they should belong. For instance, an action can
be (3)B. This action indicates that mention 3 is influenced in order to
belong to entity B.
</listItem>
<bodyText confidence="0.9950135">
Figure 10 shows an example of an N = 4 constraint with an influence rule attached.
The constraint specifies the feature functions that the involved mentions must meet,
such as semantic role arguments, sentence distances, and agreements. The influence rule
then determines that when mentions 0 and 2 belong to the same entity, and mention 1
</bodyText>
<footnote confidence="0.681355">
2 Feature functions used in our experiments are explained in detail in Section 4.2.
</footnote>
<page confidence="0.996116">
855
</page>
<table confidence="0.996285333333333">
Computational Linguistics Volume 39, Number 4
Constraint:
SRL ARG 0(0) &amp; SRL ARG 1(1) &amp; SRL ARG 0(2) &amp; SRL ARG 1(3) &amp;
DIST SEN 0(0,1) &amp; DIST SEN 1(1,2) &amp; DIST SEN 0(2,3) &amp;
AGREEMENT YES(0,2) &amp; AGREEMENT YES(1,3)
Influence rule: (0,2)A, (1)B ⇒ (3)B
Example:
Charlie0 called Bob1.
He2 invited him3 to the party.
</table>
<figureCaption confidence="0.487476">
Figure 10
</figureCaption>
<bodyText confidence="0.9949804">
Artificial example of an entity-mention constraint. It takes advantage of the partial entities
during resolution. If mentions 0 and 2 tend to corefer, the structure indicates that mentions 1
and 3 may corefer in a different entity.
belongs to a different entity, mention 3 is influenced in order to belong to the same entity
as mention 1. This figure also contains some text to help understand why this kind of
constraint may be useful. A mention-pair approach could easily make the mistake of
classifying mentions 2 and 3 as coreferent. This is an example of introducing information
about discourse coherence using an entity-mention model.
In order to retain consistency with the mention-pair model, all the constraints used
in this approach are assigned a default influence rule that depends on the sign of the
edge weight. In the case that the weight is positive, the last mention is influenced
to belong to the same entity as the first mention, and a negative weight causes the
opposite. Figure 11 shows the default influence rules for mention-pair constraints with
both positive and negative weights.
Note that when influence rules are used, a hyperedge is added for each subset of
constraints that applies to the same group of mentions and has the same influence rule.
In the case that some constraints apply to the same group of mentions but have different
influence rules, a hyperedge is added to the graph for each influence rule. Therefore, in
Equation (1), Cg ⊆ C refers to the constraints that apply to the group and share the same
influence rule.
</bodyText>
<subsectionHeader confidence="0.995697">
3.4 Relaxation Labeling
</subsectionHeader>
<bodyText confidence="0.997941875">
Relaxation is a generic name for a family of iterative algorithms that perform function
optimization based on local information. They are closely related to neural nets and
gradient steps. Relaxation labeling has been successfully used in engineering fields to
solve systems of equations, in Artificial Intelligence for computer vision (Rosenfeld,
Hummel, and Zucker 1976), and in many other AI problems. The algorithm has also
been widely used to solve NLP problems such as part-of-speech tagging (Padr´o 1998),
chunking, knowledge integration, semantic parsing (Atserias 2006), and opinion mining
(Popescu and Etzioni 2005).
</bodyText>
<table confidence="0.833386888888889">
Description Conditions Action
Default influence rule for a (0)A (1)A
mention-pair constraint (positive weight)
Default influence rule for a (0)A (1)B
mention-pair constraint (negative weight)
Example of an influence rule for an (0,2)A, (1)B (3)B
entity-mention constraint
Figure 11
Default influence rules for mention-pair constraints.
</table>
<page confidence="0.995431">
856
</page>
<note confidence="0.588611">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
</note>
<figureCaption confidence="0.847071">
Figure 12
</figureCaption>
<bodyText confidence="0.99783371875">
Representation of Relax solving a graph. The vertices representing mentions are connected by
weighted edges eif. Each vertex has a vector hi of probabilities to belong to different partitions.
The figure shows h2, h3, and h4.
Relaxation labeling (Relax) solves our weighted constraint-based hypergraph par-
titioning problem by dealing with (hyper)edge weights as compatibility coefficients.3 In
this manner, each vertex is assigned to a partition satisfying as many constraints as
possible. In each step, the algorithm updates the probability of each vertex belonging
to a partition. This update is performed by transferring the probabilities of adjacent
vertices proportional to the edge weights.
Let V = {v1, v2, ... , vn} be a set of variables. In our approach, each vertex (vi) in the
hypergraph is a variable in the algorithm. Let Li be the number of different labels that
are possible for vi. The possible labels of each variable are the partitions that the vertex
can be assigned. Note that the number of partitions (entities) in a document is a priori
unknown, but it is at most the number of vertices (mentions) because, in an extreme
case, each mention in a document could refer to a different entity. Therefore, a vertex
with index i can be in the first i partitions (i.e., Li = i).
The aim of the algorithm is to find a weighted labeling such that global consistency
is maximized. A weighted labeling is a weight assignment for each possible label of
each variable: H = (h1, h2,. . . , hn), where each hi is a vector containing a weight for
each possible label of vi; that is, hi = (hi1, hi2,.. . , hiLi ). As relaxation is an iterative process,
these weights (of between 0 and 1) vary in time. We denote the probability for label l of
variable vi at time step t as hil(t), or simply hil when the time step is not relevant. Note
that the label assigned to a variable at the end of the process is the one with the highest
weight (max(hi)). Figure 12 shows an example.
Maximizing global consistency is defined as maximizing the average support for
each variable, which is defined as the weighted sum of the support received by each of
its possible labels—that is, �Li
l=1 hil × Sil, where Sil is the support received by that pair
from the context.
The support for a variable-label pair (Sil) expresses the compatibility of the as-
signment of label l to variable vi compared with the labels of neighboring variables,
according to the edge weights. Although several support functions may be used (Torras
</bodyText>
<page confidence="0.6728885">
3 For the rest of this section, there is no distinction between edges and hyperedges.
857
</page>
<note confidence="0.290825">
Computational Linguistics Volume 39, Number 4
</note>
<bodyText confidence="0.972449">
1989), we chose the following (Equation (2)), which defines the support as the sum of
the influences of the incident edges.
</bodyText>
<equation confidence="0.9940735">
�Sil = Inf(e) (2)
e∈E(vi)
</equation>
<bodyText confidence="0.9993545">
where Inf (e) is the influence of edge e. The influence of an edge is defined by its
weight and the influence rules attached to the constraints involved with this edge (see
Section 3.3). An influence rule determines how the current probabilities for the same
label of adjacent vertices (i) are combined.
The pseudo-code for the relaxation algorithm can be found in Figure 13. It consists
of the following steps:
</bodyText>
<listItem confidence="0.940438384615385">
1. Start with a random labeling, or with a better-informed initial state.
2. For each variable, compute the support that each label receives from the
current weights of adjacent variable labels following Equation 2.
3. Normalize support values between −1 and 1. Supports are divided by a
ScaleFactor. In case that after that a support is higher than 1 or −1 then its
value is cutted to 1 or −1, respectively. Given that constraint weights are
between 1 and −1 and a group of mentions is not generally affected by
more than 10 constraints, ScaleFactor is empirically set to 8 in our
experiments.
4. Update the weight of each variable label according to the support obtained
by each of them (that is, increase weight for labels with high support
[greater than zero], and decrease weight for those with low support
[less than zero]) according to the update function:
</listItem>
<equation confidence="0.917757">
hil(t + 1) = hiLi l(t) x (1 + Sil) (3)
Ek=1 hik(t) x (1 + Sik)
Initialize:
H := H0,
Main loop:
Repeat
For each variable vi
For each possible label l for vi
Sil = Ee∈E(vi) Inf(e)
End for
Normalize supports between -1 and 1
For each possible label l for vi
hi (t) × (1+Sil)
hl&apos;( &apos; t + 1) =
ELi
k=1 hik(t)×(1+Sik)
</equation>
<subsectionHeader confidence="0.9524635">
End for
End for
</subsectionHeader>
<bodyText confidence="0.888167">
Until no more significant changes
</bodyText>
<figureCaption confidence="0.674368">
Figure 13
</figureCaption>
<bodyText confidence="0.435101">
Relaxation labeling algorithm.
</bodyText>
<page confidence="0.986874">
858
</page>
<bodyText confidence="0.956842888888889">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
There are many functions that can be used to calculate the support (Torras
1989). The one we chose was also used by Padr´o (1998) and M`arquez,
Padr´o, and Rodr´ıguez (2000).
5. Iterate the process until the convergence criterion is met. The usual
criterion is to wait for no more changes in an iteration, or a maximum
change below some epsilon parameter (Equation (4)). But there is also a
maximum number of iterations where the process is stopped. This number
is a constant and does not depend on the size of the document.
</bodyText>
<equation confidence="0.981343">
max(hil(t + 1) − hil(t)) &lt; |e |Vi,l (4)
</equation>
<bodyText confidence="0.966079375">
Each combination of labels for the graph vertices is a partitioning (Q). The resolution
process searches the partitioning Q* which optimizes the goodness function F(Q, W),
which depends on the edge weights W. In this manner, Q* is optimal if:
F(Q*, W) &gt; F(Q, W), VQ (5)
A partitioning Q is directly obtained from the weighted labeling H assigning to
each variable the label with maximum probability. The supports and the weighted
labeling depend on the edge weights (Equation (2)). To satisfy Equation (6) is equivalent
to satisfying Equation (5). Many studies have been done towards the demonstration of
the consistency, convergence, and cost reduction advantages of the relaxation algorithm
(Rosenfeld, Hummel, and Zucker 1976; Hummel and Zucker 1983; Pelillo 1997). For
instance, Hummel and Zucker (1983) prove that maximizing average consistency
(left-hand-side term of Equation (6) produces labelings satisfying Equation (5) when
only binary constraints are used. Although there is no formal proof for higher order
constraints, the presented algorithm (that forces a stop after a number of iterations) has
proven useful for practical purposes in our case.
Li h*i Li hil x Sil Vh, Vi (6)
l=1 l x Sil &gt; l=1
Note that because the weight update for each label is independent of the others,
the algorithm can be straightforward parallelized. In the following, there are some
examples of the Relax implementation of the edge influences (Inf (e)) given the influence
rules attached to the constraints.
The simplest example is when mention m0 has a direct influence over mention
m1. The influence rule attached to the constraint is (0)A =&gt; (1)A. This is determined by
Equation (7) and is the kind of influence used in the mention-pair model.
</bodyText>
<equation confidence="0.9813615">
Inf (e) = w(e) x h0 (7)
l
</equation>
<bodyText confidence="0.999843666666667">
The next example requires that mention m0 and mention m1 tend to corefer during
the resolution in order to influence mention m2. The influence rule is (0, 1)A =&gt; (2)A.
In this case, the influence of the edge representing this influence rule is given by
Equation (8). Mentions m0 and m1 are tending to corefer (belong to the same entity: l)
when their values for label l are tending to 1 (and the other labels are tending to 0). In
this case, multiplying h0l and h1l achieves a value close to 1, and the influence is almost
</bodyText>
<page confidence="0.986386">
859
</page>
<figure confidence="0.88858">
Computational Linguistics Volume 39, Number 4
</figure>
<figureCaption confidence="0.935416">
Figure 14
</figureCaption>
<sectionHeader confidence="0.23941" genericHeader="method">
RELAXCOR resolution process.
</sectionHeader>
<bodyText confidence="0.99689375">
the weight of the edge. In other cases when the coreference between m0 and m1 is not
clear (or they are clearly not coreferent), at least one of the values of h0l and h1l is not
close to 1 and the value of their product rapidly decreases, so the influence of the edge
also decreases.
</bodyText>
<equation confidence="0.992025">
Inf (e) = w(e) x h0l x h1 (8)
l
</equation>
<bodyText confidence="0.999076">
Following the previous example, now suppose that in order for m0 to influence m2
it is required that m1 does not belong to the same entity as m0. In this case, h1l is negated
using its complementary value (1 − h0l ), as is shown in Equation (9). The corresponding
influence rule is (0)A, (1)B =:&gt; (2)A.
</bodyText>
<equation confidence="0.885984">
Inf (e) = w(e) x h0l x (1 − h1l ) (9)
</equation>
<bodyText confidence="0.99998125">
The complexity of the influence rules can be increased arbitrarily and, theoretically,
any number of mentions and entities can be involved. This last example (Equation (10))
shows how to represent (0,2)A, (1)B =:&gt; (3)B, an influence rule requiring m0 and m2 to
belong to the same entity, while m1 belongs to a different one in order to influence m3.
</bodyText>
<equation confidence="0.767084">
Inf (e) = w(e) x h1 l x (1 − h0l x h2l ) (10)
</equation>
<sectionHeader confidence="0.975245" genericHeader="method">
4. RelaxCor
</sectionHeader>
<bodyText confidence="0.999939818181818">
RELAXCOR is the coreference resolution system implemented in this work to perform
experiments and test the approach explained in Section 3. This section explains the
implementation and training methods, before the experiments and error analysis are
presented in the following sections. RELAXCOR is programmed in Perl and C++, is open
source, and is available for download from our research group’s Web site.4
The resolution process of RELAXCOR is shown in Figure 14. First, the mention
detection system determines the mentions of the input document and their boundaries.
The mention detection system is explained in Section 4.1. Alternatively, true mentions
can be used when available, allowing this step to be skipped. Next, for each pair or
group of mentions (depending on the model), the set of feature functions calculate their
values, and the set of model constraints is applied. The set of feature functions used
</bodyText>
<footnote confidence="0.845646">
4 http://nlp.lsi.upc.edu.
</footnote>
<page confidence="0.989807">
860
</page>
<bodyText confidence="0.949644857142857">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
by RELAXCOR and its knowledge sources are explained in Section 4.2. A (hyper)graph
is then generated using the applied constraints and their weights. Finally, relaxation
labeling is executed to find the partitioning that maximizes constraint satisfaction.
The training and development processes used in this work are described in Sec-
tions 4.3 and 4.4. The former explains the method for training the mention-pair model,
and the latter concerns the entity-mention model.
</bodyText>
<subsectionHeader confidence="0.998699">
4.1 Mention Detection
</subsectionHeader>
<bodyText confidence="0.991639">
RELAXCOR includes a mention detection system that uses part-of-speech and syntactic
information. Syntactic information may be obtained from dependency parsing or con-
stituent parsing. The system extracts one candidate mention for every:
</bodyText>
<listItem confidence="0.989044714285714">
• Noun phrase (NP).
• Pronoun.
• Named Entity.
• Capitalized common noun or proper name that appear two or more times
in the document. For instance, the NP an Internet business is a mention, but
also Internet is added in the case that the word is found once again in the
document.
</listItem>
<bodyText confidence="0.999955142857143">
The head of every candidate mention is then determined using part-of-speech
tags and a set of rules from Collins (1999) when constituent parsing is used, or using
dependency information otherwise. In case some NPs share the same head, the larger
NP is selected and the rest are discarded. Also, mention repetitions with exactly the
same boundaries are discarded. Note that a mention detection system in pipeline
configuration with the resolution process acts as a filter and the main objective at this
point is to achieve as much recall as possible.
</bodyText>
<subsectionHeader confidence="0.998696">
4.2 Knowledge Sources and Features
</subsectionHeader>
<bodyText confidence="0.999975764705882">
The system gathers knowledge using a set of feature functions that interpret and evalu-
ate the input information according to some criteria. Given a set of mentions numbered
from 0 to N − 1 following the order found in the document, each feature function
evaluates their compatibility in a specific aspect. RELAXCOR includes features from
all linguistic layers: lexical, syntactic, morphological, and semantic. Moreover, some
structural features of the discourse have also been used, such as distances, quotes, and
sentential positions. A feature function with only one argument indicates that it offers
information about only one mention. For example, REFLEXIVE(0) indicates that mention
0 is a reflexive pronoun. Figure 15 shows an exhaustive list of the features used and a
brief description of each one.
We use decision trees for constraint acquisition (see Section 4.3.2). Because the use
of binary features favors a better performance in this type of learning (Rounds 1980;
Safavian and Landgrebe 1991), all of the used feature functions are binary. The original
sources that had a list of possible values have been binarized by a set of feature functions
that each represent a different value. Even in numerical cases, there is a set of binary
features representing the most important specific values, and the rest are placed in
ranges.
</bodyText>
<page confidence="0.993869">
861
</page>
<table confidence="0.994507035714286">
Computational Linguistics Volume 39, Number 4
Distance and position Distance between X and Y in sentences:
DIST SEN 0(X,Y): same sentence, DIST SEN 1(X,Y): consecutive sentences
DIST SEN L3(X,Y): less than 3 sentences
Distance between X and Y in phrases:
DIST PHR 0(X,Y), DIST PHR 1(X,Y), DIST PHR L3(X,Y)
Distance between X and Y in mentions:
DIST MEN 0(X,Y), DIST MEN L3(X,Y), DIST MEN L10(X,Y)
APPOSITIVE(X,Y): One mention is in apposition with the other.
IN QUOTES(X): X is in quotes or inside a NP or a sentence in quotes.
FIRST(X): X is the first mention in the sentence.
Lexical STR MATCH(X,Y): String matching of X and Y
PRO STR(X,Y): Both are pronouns and strings match
PN STR(X,Y): Both are proper names and strings match
NONPRO STR(X,Y): String matching like in Soon, Ng, &amp; Lim (2001) and mentions are not pronouns.
HEAD MATCH(X,Y): String matching of NP heads.
TERM MATCH(X,Y): String matching of NP terms.
HEAD TERM(X): mentions head matches with the term.
Morphological The number of the mentions match:
NUMBER YES(X,Y,...), NUMBER NO(X,Y), NUMBER UN(X,Y)
The gender of both mentions match:
GENDER YES(X,Y,...), GENDER NO(X,Y), GENDER UN(X,Y)
Agreement: Gender and number of all mentions match:
AGREEMENT YES(X,Y,...), AGREEMENT NO(X,Y), AGREEMENT UN(X,Y)
Closest Agreement: X is the first agreement found looking backward from Y:
C AGREEMENT YES(X,Y), C AGREEMENT NO(X,Y), C AGREEMENT UN(X,Y)
THIRD PERSON(X): X is 3rd person.
PROPER NAME(X): X is a proper name.
NOUN(X): X is a common noun.
ANIMACY(X,Y,...): Animacy of mentions match.
REFLEXIVE(X): X is a reflexive pronoun.
POSSESSIVE(X): X is a possessive pronoun.
TYPE P/E/N(X): X is a pronoun (p), NE (e) or nominal (n).
Syntactic DEF NP(X): X is a definite NP.
DEM NP(X): X is a demonstrative NP.
INDEF NP(X): X is an indefinite NP.
NESTED(X,Y): One mention is included in the other.
SAME MAXIMALNP(X,Y): Both mentions have the same NP parent or they are nested.
MAXIMALNP(X): X is not included in any other NP.
EMBEDDED(X): X is a noun and is not a maximal NP.
C COMMANDS(X,Y): X C-Commands Y.
BINDING POS(X): Condition A of binding theory.
BINDING NEG(X): Conditions B and C of binding theory.
COORDINATE(X): X is a coordinate NP.
Semantic Semantic class of the mentions match (the same as Soon, Ng, and Lim (2001))
SEMCLASS YES(X,Y,...), SEMCLASS NO(X,Y), SEMCLASS UN(X,Y)
One mention is an alias of the other:
ALIAS YES(X,Y,...), ALIAS NO(X,Y),ALIAS UN(X,Y)
PERSON(X): X is a person.
ORGANIZATION(X): X is an organization.
LOCATION(X): X is a location.
SRL ARG N/0/1/2/X/M/L/Z(X): SRL argument of X.
SAME SRL ARG(X,Y,..): All mentions are the same argument (ARG0, ARG1, etc.).
SRL SAMEVERB(X,Y,...): The mentions have a semantic role for the same verb.
SRL SAME ROLE(X,Y,...): The same semantic role (agent, patient, etc.)
SAME SPEAKER(X,Y,...): The
</table>
<figureCaption confidence="0.73434">
Figure 15
</figureCaption>
<bodyText confidence="0.969572">
Feature functions used by RELAXCOR.
</bodyText>
<subsectionHeader confidence="0.994998">
4.3 Training and Development for the Mention-Pair Model
</subsectionHeader>
<bodyText confidence="0.9906276">
using the mention-pair model and the graph representation. The training
process applies a machine learning algorithm over the training data to obtain a set
of constraints. A weight is then assigned to each constraint, taking into account the
precision of the constraint finding coreferent mentions.
A machine learning process is appli
</bodyText>
<sectionHeader confidence="0.773251" genericHeader="method">
RELAXCOR
</sectionHeader>
<bodyText confidence="0.98609575">
ed to obtain the set of constraints. Constraints
can also be added writing them by hand. Adding manual constraints is expensive,
same speaker.
This section describes the training and development process for the implementation of
</bodyText>
<page confidence="0.990117">
862
</page>
<note confidence="0.594347">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
</note>
<figureCaption confidence="0.914414">
Figure 16
</figureCaption>
<sectionHeader confidence="0.266551" genericHeader="method">
RELAXCOR training process.
</sectionHeader>
<bodyText confidence="0.952573961538462">
however, given that it takes a group of linguistic experts many hours devoted to this
task. An alternative option is to use constraints from other coreference resolution
systems, such as the ones used in Lee et al. (2011). Our experiments are based on
automatically learned constraints.
Figure 16 shows the training process. First, a data selection process unbalances
the training data set and then a machine learning process obtains the constraints.
The learned constraints are then applied to the training data set and their precision
is evaluated. The precision of each constraint determines its weight. The develop-
ment process optimizes two parameters—balance and Nprune—in order to achieve max-
imum performance given a measure for the task. Figure 17 shows the development
process.
4.3.1 Data Selection. Generating an example for each possible pair of mentions in the
training data produces an unbalanced data set in which more than 99% of the examples
are negative (not coreferent). This bias towards negative examples makes the task of the
machine learning algorithms difficult. Many classifiers simply learn to classify every
example as negative, which achieves an accuracy of 99% but is not at all useful. In
the case of decision trees and rule induction, this imbalance is also counterproductive.
In addition, some corpora have more examples than the maximum affordable by the
learning algorithm, given our computational resources. In this case, it is necessary to
reduce the number of examples.
In order to reduce the amount of negative examples, a data selection process similar
to clustering is run using the positive examples as the centroids. We define the distance
between two examples as the number of features with different values. A negative
example is then discarded if the distance to all the positive examples is always greater
than a threshold, D. The value of D is empirically chosen depending on the corpora
and the computational resources available.
</bodyText>
<figureCaption confidence="0.636295">
Figure 17
</figureCaption>
<sectionHeader confidence="0.240828" genericHeader="method">
RELAXCOR development process.
</sectionHeader>
<page confidence="0.92128">
863
</page>
<note confidence="0.334174">
Computational Linguistics Volume 39, Number 4
</note>
<subsubsectionHeader confidence="0.763253">
4.3.2 Learning Constraints. Constraints are automatically generated by learning a deci-
</subsubsectionHeader>
<bodyText confidence="0.999189125">
sion tree and then extracting rules from its leaves using C4.5 software (Quinlan 1993).
The algorithm generates a set of rules for each path from the learned tree, then checks
whether the rules can be generalized by dropping conditions. These rules become our
set of constraints. Other studies have successfully used similar processes to extract
rules from a decision tree that are useful in constraint satisfaction algorithms (M`arquez,
Padr´o, and Rodr´ıguez 2000).
The weight assigned to a constraint (λk) is its precision over the training data (Pk),
but shifted by a balance value:
</bodyText>
<equation confidence="0.986951">
λk = Pk − balance (11)
</equation>
<bodyText confidence="0.999849214285714">
The precision here refers to the positive class, that is, the ratio between the number
of positive examples and the number of examples where the constraint applies. Note
that the data selection process (Section 4.3.1) discards some negative examples to learn
the constraints, but the weight of the constraints is calculated with the precision of the
constraint over the whole training data.
The balance parameter adjusts the constraint weights to improve the balance be-
tween precision and recall. On the one hand, a high balance value causes most of the
constraints to have a negative weight, with only the most precise having a positive
weight. In this case, the system is precise but the recall is low, given that many rela-
tions are not detected. On the other hand, a low value for balance causes many low-
precision constraints to have a positive weight, which increases recall but also decreases
precision (see Figure 18). The correct value for balance is thus a compromise solution
found in the development process, optimizing performance for a specific evaluation
measure.
</bodyText>
<figureCaption confidence="0.632511">
Figure 18
</figureCaption>
<bodyText confidence="0.973388">
The figure shows MUC’s precision (red), recall (green), and F1 (blue) for each balance value in
this experiment. Corpus: ACE-2002.
</bodyText>
<page confidence="0.991517">
864
</page>
<note confidence="0.549374">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
</note>
<subsubsectionHeader confidence="0.479985">
4.3.3 Pruning. As explained in Section 3.2, when a constraint applies to a set of mentions,
</subsubsectionHeader>
<bodyText confidence="0.9510228">
a corresponding hyperedge is added to the hypergraph. In the case of the mention-
pair model with automatically learned constraints, the most typical case is that each
pair of mentions satisfy at least one constraint, which produces an edge for each pair
of mentions. There are three main issues to take into account when the problem is
represented by an all-connected graph:
</bodyText>
<listItem confidence="0.87539528">
• The weight of an edge depends on the weights assigned to the constraints
according to Equation (1). Note that the calculation of edge weights is
independent of the graph adjacency. This implies that the larger the
number of adjacencies, the smaller the influence of a constraint.
Consequently, resolution has different results for large and small
documents.
• Regarding the second issue, it is notable that some kinds of mention pairs
are very weakly informative—for example, pairs such as (pronoun,
pronoun). Many stories or discourses have a few main characters (entities)
that monopolize the pronouns in the document. This produces many
positive training examples for pairs of pronouns matching in gender and
person, which may lead the algorithm to produce large coreferential
chains joining all these mentions, even for stories where there are many
different characters.
• Finally, the computational cost of solving an all-connected graph by
relaxation labeling is O(n3). This cost is easily deduced by examining the
algorithm in Figure 13. First, there is a loop for each variable vi, and the
number of variables is the number of mentions: n. Inside this, there is
another loop for each label l of vi, and the number of labels for vi is Li = i.
The cost for these two loops is O(n22 ). Inside the second loop, the support
is calculated. The calculation of the support Sil for a vertex vi and label l
is an iteration over the incident edges E(vi), which is equal to n in an
all-connected graph. Thus, the adjacency of the vertices depends on the
size of the document. Therefore, the final computation cost of the
algorithm is O(n32 ), or O(n3) taking out the constant value.
</listItem>
<bodyText confidence="0.948976357142857">
The pruning process turns E(vi) into a constant value Nprune. For each vertex’s
incidence list E(vi), only a maximum of Nprune edges remain and the others are pruned.
In particular, the process keeps the Nprune/2 edges with the largest positive weight and
the Nprune/2 with the largest negative weight. The value of Nprune is chosen empirically
by maximizing performance over the development data. After pruning, (i) the contribu-
tion of the edge weights does not depend on the size of the document; (ii) most edges of
the less informative pairs are discarded, avoiding further confusion without limitation
on distance or other restrictions that cause a loss of recall; and (iii) computational costs
are reduced from O(n3) to O(n2), given that the innermost loop has a constant number
of iterations (Nprune).
4.3.4 Reordering. Usually, the vertices of the graph would be placed in the same order
as the mentions are found in the document (chronological order). In this manner, vi
corresponds to mi. As suggested by Luo (2007), however, there is no need to generate
the model following that order. In our approach, the first variables have a lower number
</bodyText>
<page confidence="0.986468">
865
</page>
<note confidence="0.480652">
Computational Linguistics Volume 39, Number 4
</note>
<bodyText confidence="0.9997631">
of possible labels. Moreover, an error in the first variables has more influence on the
performance than an error in later ones. It is reasonable to expect that placing named
entities at the beginning is helpful for the algorithm, given that named entities are
usually the most informative mentions.
Reordering only affects the number of possible labels of the variables. The chrono-
logical order of the document is taken into account by the constraints, regardless of the
graph representation. Our experiments (Sapena, Padr´o, and Turmo 2010a) confirm that
placing named entity mentions first, then nominal mentions, and finally the pronouns,
increases the precision considerably. Inside each of these groups, the order is the same
as in the document.
</bodyText>
<subsectionHeader confidence="0.977245">
4.4 Training and Development for the Entity-Mention Model
</subsectionHeader>
<bodyText confidence="0.999994621621622">
The training process for the entity-mention model is, in theory, exactly the same as for
the mention-pair model, but with predefined influence rules and groups of N mentions
instead of pairs. For each combination of influence rule and N, the training process has
the same steps as explained in previous sections: Learn constraints, apply them to the
training data, calculate the weights, and perform the development process to find the
optimal balance value. The positive examples are those that satisfy the final condition
of the influence rule, and the rest are negative examples. A machine-learning process to
discover group constraints has a considerable cost, however, if all the training data need
to be evaluated. The number of combinations increases exponentially as the number
of implied mentions increases. Moreover, the ratio of positive to negative examples
is extremely low, and a data selection process like the one used for pair constraints
(Section 4.3.1) has a high computational cost.
For these reasons, the group constraints of our experiments are obtained using
only the examples that the mention-pair model could not solve. Thus, after training
and running RELAXCOR over an annotated data set using just pair constraints, its
errors are now used as examples for training the entity-mention model. The type of
errors are those in which three mentions (N = 3) corefer (0, 1, 2)A, but the mention-
pair model has determined that just two of them corefer and discarded the third one
(for example: (0,1)A, (2)B). Each time an error like this is found, the three mentions
correspond to a positive example (corefer) and all other combinations of three men-
tions between mentions 0 and 2 are considered negative examples. The influence rules
for the constraints learned this way are (0, 1)A ⇒ (2)A, (0, 2)A ⇒ (1)A, and (1, 2)A ⇒
(0)A, depending on which mention was wrongly classified by the mention-pair
model.
Note that when an entity-mention model has been trained this way, the resolution
system is executed using both the mention-pair and entity-mention models at the
same time.
Alternatively, constraints for the entity-mention model can be added manually
by writing them. Figure 19 shows an example of a manually written entity-mention
constraint (i.e., a group constraint with an influence rule). This kind of constraint has
great potential to take advantage of the structure of discourses. The example shows
how the algorithm can benefit from knowing that nested mentions have some kind of
relation. In the case that two coreferring mentions are related with two other mentions
with the potential to corefer, the entity-mention model can use this information to find
more coreference relations.
The rest of the training and development process is conducted in the same way
as for the mention-pair model. The weights of group constraints are obtained by
</bodyText>
<page confidence="0.992897">
866
</page>
<bodyText confidence="0.838720666666667">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
The Technical University of Catalonia, sometimes called UPC-Barcelona Tech, is
the largest engineering university in Catalonia, Spain. The objectives of the UPC
are based on internationalization, as it is [[Spain]0’s technical university with the
highest number of international PhD students]1 and [[Spain]2’s university with
the highest number of international master’s degree students]3...
</bodyText>
<figure confidence="0.733545">
Constraint: PN STR(0,2) &amp; HEAD MATCH(1,3) &amp; NESTED(0,1) &amp; NESTED(2,3)
Influence rule: (0,2)A, (1)B ⇒ (3)B
</figure>
<figureCaption confidence="0.943306">
Figure 19
</figureCaption>
<bodyText confidence="0.9480952">
Example of a manually written group constraint using an influence rule to take advantage of
the entity-mention model. The constraint expects four mentions where: two of them are proper
names and match in their complete strings, the other two match in their heads, mention 0 is
inside mention 1, and mention 2 is inside mention 3. The influence rule says that when mentions
0 and 2 belong to the same entity (A) but mention 1 belongs to another one (B), then mention 3
should belong to entity B in order to corefer with mention 1. (Text source: Wikipedia.
Annotations were manually done for this example.)
evaluating their precision over the training data, and the balance value is determined by
a development process. In our experiments, however, the number of group constraints
is typically lower than the number of pairwise ones, so there is no need for pruning.
</bodyText>
<sectionHeader confidence="0.871336" genericHeader="method">
4.5 Related Work
</sectionHeader>
<bodyText confidence="0.999802">
In Section 2, we introduced an overview of many approaches, with their classification
models and resolution processes (see Figure 5). Our approach can be classified simi-
larly as a one-step resolution that uses the entity-mention model for classification and
conducts hypergraph partitioning for the linking process. This classification matches
that of the COPA system described in Cai and Strube (2010). Both approaches represent
the problem in a hypergraph, where each mention is a vertex, and use hypergraph
partitioning in order to find the entities. The differences between these two approaches
are substantial, however. The most significant differences are as follows:
</bodyText>
<listItem confidence="0.9920008125">
• Hypergraph generation. RELAXCOR adds hyperedges to the hypergraph
for each group of mentions that satisfy a constraint, whereas COPA adds
a hyperedge for each group of mentions that satisfy a feature. Note that
the addition of hyperedge weights representing features cannot take
advantage of the nonlinear combinations offered by constraints. Actually,
in order to incorporate some nonlinearity, COPA needs combined features
to introduce information such as mention type (pronoun, proper name,
etc.) or distances.
• Resolution algorithm. RELAXCOR uses relaxation labeling in order to
satisfy as many constraints as possible. In fact, the hypergraph is just a
representation of the problem. COPA uses recursive 2-way partitioning, a
hypergraph partitioning algorithm. COPA’s main contribution is not the
resolution algorithm, but the hypergraph representation of the problem.
• Computational costs. RELAXCOR needs to train a decision tree in order to
extract a set of rules to use them as soft constraints. These constraints are
then applied to the training data to calculate their weight. COPA does not
</listItem>
<page confidence="0.975294">
867
</page>
<note confidence="0.473278">
Computational Linguistics Volume 39, Number 4
</note>
<bodyText confidence="0.989988666666667">
use constraints, which reduces the computational cost of the training
process. On the other hand, the cost of the resolution algorithm is O(n3) for
COPA whereas it is O(n2) in RELAXCOR thanks to the pruning process.
</bodyText>
<sectionHeader confidence="0.988017" genericHeader="evaluation">
5. Experiments and Results
</sectionHeader>
<bodyText confidence="0.999875533333333">
Several experiments have been performed on coreference resolution in order to test
our approach. This section includes a short explanation and result analysis of the
most significant experiments. First, there is an explanation of a set of experiments to
evaluate the performance of coreference resolution and mention detection. The scores
are compared with the state of the art in diverse corpora, measures, and languages.
Next, our participation in Semeval-2010 and CoNLL-2011 shared tasks is explained in
detail with performance, comparisons, and error analysis. Finally, a set of experiments
using the entity-mention model are described.
The framework used in our experiments consists of widely used corpora and mea-
sures to facilitate replication and comparison. Corpora used are ACE 2002 (NIST 2003),
the same portion of OntoNotes v2.0 used in Semeval-2010 (Recasens et al. 2010), and the
same portion of OntoNotes v4.0 used in CoNLL Shared Task 2011 (Pradhan et al. 2011).
Regarding the measures, we used MUC (Vilain et al. 1995), B3 (Bagga and Baldwin
1998), and two variants of CEAF (Luo 2005): mention-based (CEAFm) and entity-based
(CEAFe).
</bodyText>
<subsectionHeader confidence="0.992992">
5.1 Mention Detection
</subsectionHeader>
<bodyText confidence="0.999931470588235">
The performance of the mention detection system achieves a good recall, higher than
90%, but a low precision, as published in Sapena, Padr´o, and Turmo (2011) and repro-
duced in Table 1. The OntoNotes corpora have been used for this experiment, as they
were used in CoNLL-2011. Given that the mention detection in a pipeline combination
acts as a filter, recall should be kept high, as a loss of recall at the beginning would result
in a loss of performance in the rest of the process. At this point, however, the precision is
not a priority as long as it remains reasonable, given that the coreference resolution pro-
cess is able to determine that many mentions are singletons. Moreover, the evaluation
of precision on the OntoNotes corpora only take into account mentions included in a
coreference chain, not singletons. The RELAXCOR output, however, includes singletons.
This means that the precision value is not really evaluating the precision of the mention
detection system. A fair evaluation of mention detection should be performed in a
corpus with annotations of every referring expression, but such a corpus is not available
as far as we know.
The most typical error made by the system is to include extracted NPs that are
not referential (e.g., predicative and appositive phrases) and mentions with incorrect
boundaries. The incorrect boundaries are mainly due to errors in the predicted syntactic
</bodyText>
<tableCaption confidence="0.994373">
Table 1
</tableCaption>
<table confidence="0.866150714285714">
Mention detection results on OntoNotes (Corpus: CoNLL-2011 Shared Task).
OntoNotes Recall Precision F1
Development 92.45 27.34 42.20
Test 92.39 28.19 43.20
868
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
Table 2
Results on ACE-phase02.
bnews npaper nwire Global
Metric: CEAF CEAF B3
Model F1 F1 F1 F1 P R F1
RELAXCOR 69.5 67.3 72.1 69.7 85.3 66.8 74.9
MaxEnt+ILP (Denis 2007) – – – 66.2 81.4 65.6 72.7
Rankers (Denis 2007) 65.7 65.3 68.1 67.0 79.8 66.8 72.7
</table>
<bodyText confidence="0.9993946">
column and some mention annotation discrepancies. Furthermore, the coreference an-
notation of OntoNotes used in CoNLL-2011 included verbs as anaphors of some verbal
nominalizations. But verbs are not detected by our mention detection system, so most
of the missing mentions are verbs. The methodology of the mention detection system is
explained in Section 4.1.
</bodyText>
<subsectionHeader confidence="0.992702">
5.2 State-of-the-Art Comparison
</subsectionHeader>
<bodyText confidence="0.999789">
RELAXCOR performance has been compared several times with other published results
from state-of-the-art systems. We claimed Sapena, Padr´o, and Turmo (2010a) to have
the best performance for the ACE-phase02 corpus, using true mentions in the input and
evaluating with the CEAF and B3 measures. The table comparing scores with the best
results found at that moment is reproduced as Table 2.
The approach is also compared with the state of the art in two competitions:
SemEval-2010 (Sapena, Padr´o, and Turmo 2010b) and CoNLL-2011 (Sapena, Padr´o, and
Turmo 2011). RELAXCOR achieved one of the best performances in SemEval-2010, but
contradictory results across measures prevented the organization from determining a
</bodyText>
<figureCaption confidence="0.435726">
Figure 20
RELAXCOR (sapena) achieved the second position in the official closed track (CoNLL-2011).
</figureCaption>
<page confidence="0.984119">
869
</page>
<table confidence="0.426434">
Computational Linguistics Volume 39, Number 4
</table>
<tableCaption confidence="0.993073">
Table 3
</tableCaption>
<table confidence="0.9209495">
Results of RELAXCOR on development data (SemEval-2010).
– CEAF MUC B3
language R P F1 R P F1 R P F1
ca 69.7 69.7 69.7 27.4 77.9 40.6 67.9 96.1 79.6
es 70.8 70.8 70.8 30.3 76.2 43.4 68.9 95.0 79.8
en-closed 74.8 74.8 74.8 21.4 67.8 32.6 74.1 96.0 83.7
en-open 75.0 75.0 75.0 22.0 66.6 33.0 74.2 95.9 83.7
winner. In addition, RELAXCOR achieved second position in the CoNLL-2011 Shared
Task; Figure 20 reproduces the official table of results. Following sections describe the
shared tasks in detail.
</table>
<bodyText confidence="0.992621772727273">
Finally, the performance of RELAXCOR is again compared with two other state-of-
the-art systems in M`arquez, Recasens, and Sapena (2012).
5.2.1 SemEval-2010. The goal of SemEval-2010 task 1 (Recasens et al. 2010) was to eval-
uate and compare automatic coreference resolution systems for six different languages
in four evaluation settings and using four different evaluation measures. This complex
scenario aimed at providing insight into several aspects of coreference resolution, in-
cluding portability across languages, relevance of linguistic information at different
levels, and behavior of alternative scoring measures. The task attracted considerable
attention from a number of researchers, but only six teams submitted results. Moreover,
participating systems did not run their systems for all the languages and evaluation
settings, thus making direct comparisons among all the involved dimensions very
difficult.
RELAXCOR participated in the SemEval task for English, Catalan, and Spanish
(Sapena, Padr´o, and Turmo 2010b). At the time, the system was not ready to detect
mentions. Thus, participation was restricted to the gold-standard evaluation, which
included the manual annotated information and also provided the mention boundaries.
RELAXCOR results for development and test data sets are shown in Tables 3 and 4,
respectively. The version of RELAXCOR used in SemEval had a balance value fixed to
0.5, which proved to be an inadequate value. Thus, the results have high precision but
a very low recall. This situation produced high scores with the CEAF and B3 measures,
due in part to the annotated singletons. The system was penalized by measures based
on pair-linkage, however, particularly MUC. Although RELAXCOR had the highest
</bodyText>
<tableCaption confidence="0.993946">
Table 4
</tableCaption>
<table confidence="0.933636444444444">
Results of RELAXCOR on test data (SemEval-2010).
– CEAF MUC B3 BLANC
language R P F1 R P F1 R P F1 R P BLANC
Information: closed Annotation: gold
ca 70.5 70.5 70.5 29.3 77.3 42.5 68.6 95.8 79.9 56.0 81.8 59.7
es 66.6 66.6 66.6 14.8 73.8 24.7 65.3 97.5 78.2 53.4 81.8 55.6
en 75.6 75.6 75.6 21.9 72.4 33.7 74.8 97.0 84.5 57.0 83.4 61.3
Information: open Annotation: gold
en 75.8 75.8 75.8 22.6 70.5 34.2 75.2 96.7 84.6 58.0 83.8 62.7
</table>
<page confidence="0.991596">
870
</page>
<bodyText confidence="0.987137872340426">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
precision scores (even with MUC), the recall was low enough to finally obtain low
scores for F1.
Regarding the test scores of the comparison with other participants (Recasens et al.
2010), RELAXCOR obtained the best performance for Catalan (CEAF and B3), English
(closed: CEAF and B3; open: B3), and Spanish (B3). Moreover, RELAXCOR was the most
precise system under all metrics in all languages, except for CEAF in English-open and
Spanish. This confirms the robustness of the results of RELAXCOR, but also highlights
the necessity of searching for a balance value other than 0.5 to increase the recall of the
system without losing much by way of precision. Indeed, the idea of using development
(Section 4.3) to adapt the balance value occurred after these results were obtained.
The incorporation of WordNet to the English run of RELAXCOR was the only
difference between our implementation in the English-open and English-closed tasks.
The scores were slightly higher when using WordNet, but not significantly so (75.8%
vs. 75.6% for CEAF and 34.2% vs. 33.7% for MUC). Analyzing the MUC scores, note
that the recall improves (from 21.9% to 22.6%), while the precision decreases a little
(from 74.4% to 70.5%), which corresponds to the information and noise that WordNet
typically provides.
More recent results of RELAXCOR on the same corpora are published in M`arquez,
Recasens, and Sapena (2012).
5.2.2 CoNLL-2011. The CoNLL-2011 Shared Task was based on the English portion of
the OntoNotes 4.0 data5 (Pradhan et al. 2011). As is customary for CoNLL tasks, there
was a closed and an open track. For the closed track, systems were limited to using the
distributed resources, in order to allow a fair comparison of algorithm performance,
whereas the open track allowed for almost unrestricted use of external resources in
addition to the provided data. About 65 different groups demonstrated interest in the
shared task by registering on the task Web page. Of these, 23 groups submitted system
outputs on the test set during the evaluation week. Eighteen groups submitted only
closed track results, three groups only open track results, and two groups submitted
both closed and open track results.
RELAXCOR participated in the closed track CoNLL task (Sapena, Padr´o, and Turmo
2011). All the knowledge required by the feature functions was obtained from the
annotations of the corpus, and no external resources were used with the exception of
WordNet, gender and number information, and sense inventories. All of these were
allowed by the task organization and are available on their Web site.
The results obtained by RELAXCOR can be found in Tables 5 and 6. Due to the
lack of annotated singletons, mention-based metrics B3 and CEAF produce lower scores
(near 60% and 50%, respectively) than typically achieved with different annotations and
mapping policies (usually near 80% and 70%). Moreover, the requirement that systems
use automatic preprocessing and do their own mention detection increases the difficulty
of the task, which obviously decreases the scores in general. The official ranking score
was the arithmetic mean of the F-scores of MUC, B3, and CEAFe.
The MUC measure is link-based and does not take singletons into account, anyway.
Thus, it is the only one comparable with the state of the art at this point. The results
obtained with the MUC scorer show an improvement in RELAXCOR’s recall, a feature
that needed improvement given the remarkably low SemEval-2010 results with MUC.
Note that these improvements in MUC scores, specially in recall, are mainly due to
</bodyText>
<footnote confidence="0.439806">
5 CoNLL-2011 Shared Task Web site: http://conll.bbn.com.
</footnote>
<page confidence="0.986362">
871
</page>
<table confidence="0.424272">
Computational Linguistics Volume 39, Number 4
</table>
<tableCaption confidence="0.995816">
Table 5
</tableCaption>
<table confidence="0.99223675">
RELAXCOR results on the development data set (CoNLL-2011).
Measure Recall Precision F1
Mention detection 92.45 27.34 42.20
mention-based CEAF 55.27 55.27 55.27
entity-based CEAF 47.20 40.01 43.31
MUC 54.53 62.25 58.13
B3 63.72 73.83 68.40
(CEAFe+MUC+B3)/3 – – 56.61
</table>
<tableCaption confidence="0.994154">
Table 6
</tableCaption>
<table confidence="0.995316555555556">
RELAXCOR official test results (CoNLL-2011).
Measure Recall Precision F1
Mention detection 92.39 28.19 43.20
mention-based CEAF 53.51 53.51 53.51
entity-based CEAF 44.75 38.38 41.32
MUC 56.32 63.16 59.55
B3 62.16 72.08 67.09
BLANC 69.50 73.07 71.10
(CEAFe+MUC+B3)/3 – – 55.99
</table>
<bodyText confidence="0.9995724">
the introduction of the balance value in the development process but also to many
other refinements done in the whole process such as new feature functions and bug
fixing.
RELAXCOR achieved second position in the official closed track results, as shown
in Figure 20. The final column shows the official ranking score. The difference from
the system in first place is 1.8 points, which is statistically significant, whereas the
difference to third position is just 0.03 points and is not significant. The winning
system—Stanford (Lee et al. 2011)—does not use machine learning but combines
many heuristics to join mentions and partial entities, starting with the most precise
ones. It is thought that the difference between RELAXCOR and Stanford’s system is
mainly due to their use of sophisticated handwritten heuristics instead of our auto-
matically learned constraints. Note that Lee et al. (2011) solve coreferences by applying
first the most precise constraints. RELAXCOR also solves first the most precise con-
straints given that these ones have the highest weights and are the most influencing
ones.
</bodyText>
<subsectionHeader confidence="0.981189">
5.3 Languages
</subsectionHeader>
<bodyText confidence="0.999961142857143">
Sapena, Padr´o, and Turmo (2010b), and M`arquez, Recasens, and Sapena (2012) show the
performance of our approach for English, Catalan, and Spanish. The scores for Spanish
and Catalan do not seem as good as for English, because the system was originally
designed with the English language in mind. As a result, it does not include language-
specific features for Spanish and Catalan, such as whether a mention is an elliptical
subject or not. Despite this, RELAXCOR scores for Catalan and Spanish are the best
among the state of the art.
</bodyText>
<page confidence="0.994423">
872
</page>
<note confidence="0.735485">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
</note>
<tableCaption confidence="0.998432">
Table 7
</tableCaption>
<table confidence="0.951211818181818">
Comparison of RELAXCOR results using just the mention-pair model (N = 2) with those also
using the entity-mention model (N = 3) (Corpus: SemEval-2010).
Measure Precision Recall F1
CEAFm 81.73 81.73 81.73
MUC 72.92 54.17 62.17
B3 91.87 82.87 87.14
CEAFe 81.95 90.47 86.00
CEAFm 82.02 82.02 82.02
MUC 73.01 54.28 62.27
B3 91.59 83.12 87.15
CEAFe 82.10 90.63 86.15
</table>
<subsectionHeader confidence="0.871163">
5.4 Experiments with the Entity-Mention Model
</subsectionHeader>
<bodyText confidence="0.99996132">
Constraints for the entity-mention model are automatically obtained using the training
data examples that the mention-pair model could not solve, with predefined influence
rules and limited to N = 3. The training process is explained in Section 4.4. Experiments
with the entity-mention model are conducted using both models at the same time. The
goal of the experiments is to improve the performance of the mention-pair model itself.
Table 7 shows the experimental results using the SemEval-2010 English corpus. The
table compares the entity-mention results (RELAXCOR using N = 3 constraints with
influence rules, including the whole set of N = 2 constraints) with those using mention-
pairs (RELAXCOR using just N = 2 constraints). The entity-mention model outperforms
the mention-pair model. The number of really useful examples (i.e., mentions wrongly
classified by the mention-pair model but correctly classified by the entity-mention
model), however, is low. Consequently, the difference in their scores is not significant.
The N = 3 constraints have a good precision and also an acceptable recall, although
most of the mentions affected by these constraints were already affected and correctly
solved by the mention-pair model. Further research is needed in order to find more
useful constraints, either by writing more elaborate group constraints or finding a better
system that automatically finds them.
These results may be somewhat justified, because the entity-mention model uses
the same feature functions and, consequently, the same information as the mention-
pair model. In fact, only the new information is that information already included in
the conditions of the influence rules, which take into account the entities assigned to
each mention during resolution. In addition, group constraints can also include, in an
implicit way, information about the structure of the discourse. It seems clear, however,
that this new information is either minimal or not relevant enough. Figure 21 shows an
example of a learned entity-mention constraint.
</bodyText>
<equation confidence="0.689220625">
Constraint: GENDER NO (0,1) = 0 &amp; STR MATCH(0,1) = 0 &amp; ORGANIZA-
TION(0) = 0 &amp; POSSESSIVE(1) &amp; NUMBER NO(1,2) = 0 &amp; NUMBER UN(1,2)
= 0 &amp; DIST SEN L3(0,1) &amp; DIST SEN L3(0,2)
Influence rule: (0, 2)A ⇒ (1)A
Figure 21
Example of a learned N = 3 constraint.
N = 2
N = 3
</equation>
<page confidence="0.996435">
873
</page>
<note confidence="0.490669">
Computational Linguistics Volume 39, Number 4
</note>
<bodyText confidence="0.99998175">
Even though the obtained performance does not significantly outperform the
mention-pair model, we can draw some positive conclusions from these experiments.
First of all, the approach is ready to use either model (mention-pair or entity-mention)
in a constructive way. As soon as new feature functions specific to entity-mention
models appear, the results will reflect this. One research line to follow in this field is the
incorporation of feature functions following discourse theories, such as focusing and
centering. Another research line is the introduction of world knowledge using these
models, as explained in the next section.
</bodyText>
<sectionHeader confidence="0.898339" genericHeader="conclusions">
6. Adding World Knowledge to Coreference Resolution
</sectionHeader>
<bodyText confidence="0.995688571428572">
Often, common sense and world knowledge is essential to resolve coreferences. For
example, we can find coreferential mentions in any newspaper, such as {Obama, USA
President}, {Messi, Barcelona striker}, or {Beirut, the Lebanese capital}.
In order to know the importance of the coreference links that are missed due to
a lack of world knowledge, the partial and total scores of RELAXCOR on the test data
set of OntoNotes 2.0 (the same data set used for the English task in SemEval-2010) are
shown in Table 9 for each mention class described in Table 8. Analyzing the table, we
observe that PN N, CN P, and CN N are the classes with the lowest recall, especially
PN N and CN N. In addition, PN N and CN N have the lowest precision. The final
column shows the number of mentions corresponding to the class of that row and the
percentage representing the total number of coreferent mentions. Note that these three
classes together represent 27% of coreferent mentions.
According to M`arquez, Recasens, and Sapena (2012), Stoyanov et al. (2009), and
Pradhan et al. (2007), these results can be roughly generalized to any other system
using similar information, and even other languages. Therefore, these classes require
attention in order to improve global performance, and the fact that lexical, morpholog-
ical, syntactic, and semantic levels are not very useful to deal with them encourages
the research on adding world knowledge to coreference resolution systems. In state-
of-the-art systems, we can find some attempts to add world knowledge to coreference
resolution, using Wikipedia (Ponzetto and Strube 2006; Uryupina et al. 2011) or YAGO
and Freenet (Rahman and Ng 2011a).
</bodyText>
<tableCaption confidence="0.986881">
Table 8
</tableCaption>
<table confidence="0.985273285714286">
Description of the mention classes for English documents.
Class Description
PN E NPs headed by a Proper Name that Exactly match (excluding case and the
determiner) at least one preceding mention in the same coreference chain.
PN P NPs headed by a Proper Name that Partially match (i.e., head match or overlap,
excluding case) at least one preceding mention in the same coreference chain.
PN N NPs headed by a Proper Name that do Not match any preceding mention in
the same coreference chain.
CN E Same definitions as in PN E, PN P, and PN N,
CN P but referring to NPs headed by a Common Noun.
CN N
P 1∪2 First- and second-person pronouns that corefer with a preceding mention.
P 3G Gendered third-person pronouns that corefer with a preceding mention.
P 3U Ungendered third-person pronouns that corefer with a preceding mention.
</table>
<page confidence="0.979528">
874
</page>
<note confidence="0.78043">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
</note>
<tableCaption confidence="0.997932">
Table 9
</tableCaption>
<table confidence="0.990184">
Results of RELAXCOR in English OntoNotes from SemEval-2010 without world knowledge.
measure class Pre Rec F1 quantity
PN E 99.7 99.4 99.6 356 (18%)
PN P 94.5 77.9 85.4 222 (12%)
PN N 5.3 1.3 2.1 75 (04%)
CN E 97.3 71.8 82.6 149 (08%)
MUC CN P 87.3 36.0 51.0 172 (09%)
CN N 22.6 2.5 4.5 278 (14%)
P 1∪2 74.5 61.2 67.2 134 (07%)
P 3G 88.8 85.0 86.9 187 (10%)
P 3U 78.1 59.3 67.4 356 (18%)
MUC 74.4 59.9 66.4
CEAFm 83.0 83.0 83.0
B3 91.8 84.6 88.1
</table>
<bodyText confidence="0.9998266">
This section presents our approach to incorporating world knowledge to corefer-
ence resolution, represented in Figure 22. The nature of our model allows the integration
of world knowledge encoded not only as features, but also as constraints, which is a
more expressive and natural way.
The work presented in this section is intended as a proof-of-concept for the ability
of RELAXCOR to absorb knowledge from heterogeneous sources. Results show that
although the algorithm is able to successfully handle the added knowledge, the per-
formance is hardly increased due to the noisy nature of the knowledge automatically
extracted from Wikipedia.
The approach proceeds in two phases. First, given a document, the world know-
ledge potentially useful for the resolution of coreferences is acquired from Wikipedia,
and second, this knowledge is incorporated to RELAXCOR using two alternative
models: feature functions and constraints. These phases are described in Sections 6.1
and 6.2, respectively. Finally, Section 6.3 describes our experiments and analyzes their
results.
</bodyText>
<subsectionHeader confidence="0.999807">
6.1 Acquiring World Knowledge
</subsectionHeader>
<bodyText confidence="0.999954">
Our methodology to acquire world knowledge useful for coreference resolution consists
of finding the real-world entities occurring in the document (i.e., Entity Linking) and
extracting information related to them from Wikipedia.
</bodyText>
<figureCaption confidence="0.435442">
Figure 22
</figureCaption>
<bodyText confidence="0.279445">
Process to add information from Wikipedia to coreference resolution.
</bodyText>
<page confidence="0.989207">
875
</page>
<note confidence="0.540161">
Computational Linguistics Volume 39, Number 4
</note>
<bodyText confidence="0.988357465116279">
6.1.1 Entity Linking. One approach to finding real-world entities mentioned in a docu-
ment is to select the NE mentions of that document and to disambiguate them in order
to determine which entities in the real world—in our case, which Wikipedia entries—
are referred to by the mentions. Using every NE mention in a document, however, may
add noise to the process of coreference resolution. For instance, consider a document
with Bill Clinton and, some sentences later, Clinton. If we try to get information about
Clinton from Wikipedia, we obtain a page about the English family name Clinton with
a lot of non-relevant information that may lead to erroneous results. Given that Bill
Clinton appears in the same document, it seems more convenient to select the most
informative NE mention and discard the less informative ones, like Clinton, which are
probably pointing to the same real-world entity. This is why we just take into account
the most informative NE mentions, called MI mentions from now on.
We obtain MI mentions as follows: We build cliques formed by groups of mentions
where the ALIAS function is true for all the pairs, and all mentions in the group belong
to the same class (Person, Organization, or Location). Finally, the longest NE mention
from each group is selected as an MI mention.
After this selection process, each MI mention is disambiguated by using Google as
an information retrieval system to find the most relevant pages in Wikipedia. The query
is generated from the MI mention as the mention head plus all nouns, proper names,
and adjectives that appear immediately before it. From the results provided by Google,
we select as the real world entity for the MI mention the first URL that corresponds to
a Wikipedia entry and includes the head of the MI mention (or a string that matches as
an alias) in the title or in the first sentence of the first paragraph.6 If no result is found,
we assume that the MI mention does not exist in Wikipedia.
6.1.2 Information Extraction. For each Wikipedia entry obtained in the entity disambigua-
tion step, we extract information from the description, the infobox, and the categories
of the entry, and also from other Wikipedia pages linking to that entry, as found in
the “What Links Here” section. Concretely, we extract all names (i.e., official names,
nicknames, and aliases), as well as properties indicating the most descriptive aspects or
qualities of the entity.
The first paragraph of a Wikipedia entry is considered the description of the entry.
The description typically starts with the complete name of the entity, some aliases,
and the most descriptive properties of the entity. After preprocessing the text, the
first NE is extracted as the official name. Next, a set of patterns are used to extract
aliases (e.g., “sometimes called &lt;alias&gt;”) or properties (e.g., “&lt;mention&gt; be/become
NP-&lt;property&gt;”).7
From the infobox, all the contents of the following fields are extracted: fullname,
name, office, title, profession, company name, playername, occupation, nickname,
official name, native name, settlement type, type. In addition, all categories associ-
ated with the entry are also extracted as properties.
Finally, from each page that links to the current entry following the “What Links
Here” section, those sentences including the link are selected. From each one of them,
the anchor text used to link the entry is extracted as a name. In addition, the following
</bodyText>
<footnote confidence="0.9950825">
6 We also discard special Wikipedia pages, such as disambiguation pages or pages with names that do not
contain the character “:”.
7 We extract as properties both the NP (e.g., “American politician”) and its head (e.g., “politician”) in order
to get more general properties as well.
</footnote>
<page confidence="0.989797">
876
</page>
<note confidence="0.47842">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
</note>
<bodyText confidence="0.999646875">
expressions are extracted as properties using patterns: the set of nouns and adjectives
to the left of the anchor text, the set of NPs in apposition to the link, and the set of NPs
denoting a property of a list of entries in which one of them is the current one (e.g.,
“&lt;NP&gt;-&lt;property&gt; such as entry1, entry2, ..., entryn”).
We take the frequency of the extracted expression as the confidence value associated
with each expression—the most repeated expressions are the most reliable. In order to
avoid incorrect information as much as possible, we define a threshold below which
all the extracted names and properties are discarded.
</bodyText>
<subsectionHeader confidence="0.99972">
6.2 Incorporating World Knowledge to the Models
</subsectionHeader>
<bodyText confidence="0.969986166666667">
Two approaches for the incorporation of the knowledge extracted from Wikipedia have
been studied. The first is to add some feature functions for the mention-pair model that
evaluate whether a pair of mentions may corefer according to Wikipedia’s information,
similar to other state-of-the-art studies (Ponzetto and Strube 2006; Rahman and Ng
2011a). The second approach adds a set of constraints to the hypergraph connecting
groups of mentions, using the entity-mention model.
6.2.1 Feature Functions. In this approach, new feature functions are added to evaluate
pairs of mentions, and some learned constraints may use them as any other feature
function. These feature functions are only applied to pairs &lt; MI, X &gt;, where MI is a MI
mention and X is any other mention but a pronoun, and use the information extracted
from Wikipedia to determine their value. Concretely, the feature functions used in our
experiments are the following ones:
</bodyText>
<listItem confidence="0.95496">
• WIKI ALIAS(MI, X): returns true if the head of X is another MI mention of
the same entry as MI, or X matches one of the names extracted from
Wikipedia for MI.
• WIKI DESC(MI, X): returns true if all the X terms are included in one of the
properties extracted from Wikipedia for MI.
6.2.2 Constraints. In this approach, world knowledge is incorporated by adding con-
</listItem>
<bodyText confidence="0.99814775">
straints relating the mentions that may corefer given the extracted information about the
entities. In this case, the features of the previous model are now replaced by constraints.
In addition, other constraints can be added to take advantage of the entity-mention
model. The following is a list of constraints used in our experiments:
</bodyText>
<listItem confidence="0.9973804">
• Constraint cAlias is added for each pair of mentions that satisfy the same
conditions as WIKI ALIAS.
• Constraint cDesc is added for each pair of mentions that satisfy the same
conditions as WIKI DESC.
• Constraint cWiki3, a N = 3 constraint, is added for each combination of
three mentions (0, 1, 2) where 0 is a MI mention, 1 is a NE mention alias of
0, and 2 is a nominal mention or a NE mention that satisfies WIKI ALIAS
or WIKI DESC with 0. This constraint tries to link the nominal mention
with the closest NE mention that may corefer. The influence rule is
(0, 1)A ⇒ (2)A, that is, 2 is influenced when 0 and 1 corefer.
</listItem>
<page confidence="0.979167">
877
</page>
<note confidence="0.416157">
Computational Linguistics Volume 39, Number 4
</note>
<listItem confidence="0.948707">
• Constraint cStructWiki3, an N = 3 constraint, is added for each
</listItem>
<bodyText confidence="0.999561666666667">
combination of three mentions (0, 1, 2) where 0 is an MI mention, 1 is an
NP that satisfies WIKI ALIAS or WIKI DESC with 0, and 2 is an NE mention
alias of 0. In addition, the three mentions have the same syntactic function
and are found in consecutive sentences. The influence rule associated with
this constraint is (0, 2)A ⇒ (1)A, that is, 1 is influenced when 0 and 2 corefer.
Figure 23 shows examples of the constraints cWiki3 and cStructWiki3. The idea
behind cWiki3 is to link the nominal mention (2, The organization) with a closer men-
tion in the document than the MI mention (0, the Organization of Petroleum Exporting
Countries). Linking nearest mentions may take advantage of information given by other
constraints, such as syntactic patterns. When the Organization of Petroleum Exporting
Countries is tending to corefer with OPEC, mention The organization is influenced by
both mentions. The second case, cStructWiki3, takes advantage of a typical discourse
structure where the same entity is the subject of some consecutive sentences. First
mention 0, Google Inc., is the MI mention, whereas 2 (Google) is just an alias. Between
them we find a nominal mention (The company), which we expect to solve using world
knowledge. Both N = 3 constraints are expected to have high precision but low recall.
Note that cAlias and cWiki are equivalent to the feature functions of the previous
model. The difference is that, in the case of constraints, they are always applied when
WIKI ALIAS and WIKI DESC are true, and so their weight is added to the edge weight
of that pair in the hypergraph. In the model using feature functions, however, the
constraints learned by the model may or may not include those features.
</bodyText>
<subsectionHeader confidence="0.996609">
6.3 Experiments and Results
</subsectionHeader>
<bodyText confidence="0.996223277777778">
The experiments consist of the execution of RELAXCOR using each one of the models
to incorporate information. RELAXCOR + features incorporates the new features to the
original model and repeats the training process from the beginning. Constraints are
learned using these new feature functions mixed with all the others (a detailed list of
features is in Section 4.2). RELAXCOR + constraints incorporates the new constraints. In
this case, the learning process uses the constraints already learned for RELAXCOR and
adds the new constraints to the model. The training process is then applied normally to
compute the weight of the constraints using their precision in the training files.
Table 10 shows the results obtained when adding world knowledge compared with
the results of RELAXCOR without world knowledge. The first three columns list the
cWiki3
Output from the Organization of Petroleum Exporting Countries is already...
As a result, the effort by some oil ministers to get OPEC to approve...
The organization is scheduled to meet in Vienna...
cStructWiki3
Google Inc. is offering new applications...
The company is going to...
Predictably, Google has highlighted user profiles...
</bodyText>
<figureCaption confidence="0.472741">
Figure 23
</figureCaption>
<bodyText confidence="0.561506">
Examples of the application of N = 3 constraints cWiki3 and cStructWiki3.
</bodyText>
<page confidence="0.986987">
878
</page>
<note confidence="0.79484">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
</note>
<tableCaption confidence="0.990895">
Table 10
</tableCaption>
<note confidence="0.79832625">
Results of RELAXCOR on English OntoNotes 2.0 from SemEval-2010 with world knowledge.
The baseline is RELAXCOR using mention-pair model, features, is RELAXCOR using features
WIKI ALIAS and WIKI DESC, and constraints stands for RELAXCOR with the set of constraints
in Section 6.2.2. Gains over the baseline are boldfaced and losses are in italics.
</note>
<table confidence="0.999383642857143">
baseline features constraints
measure class Pre Rec F1 Pre Rec F1 Pre Rec F1
PN E 99.7 99.4 99.6 100 98.0 99.0 100 99.2 99.6
PN P 94.5 77.9 85.4 92.9 76.6 84.0 93.6 78.8 85.6
PN N 5.3 1.3 2.1 15.0 4.0 6.3 14.8 5.3 7.8
CN E 97.3 71.8 82.6 97.3 72.5 83.1 97.3 72.5 83.1
MUC CN P 87.3 36.0 51.0 90.2 43.0 58.3 89.2 43.0 58.0
CN N 22.6 2.5 4.5 32.1 3.2 5.9 31.0 3.2 5.9
P 1∪2 74.5 61.2 67.2 76.9 59.7 67.2 77.1 60.4 67.8
P 3G 88.8 85.0 86.9 87.6 86.6 87.1 87.6 86.6 87.1
P 3U 78.1 59.3 67.4 76.2 54.8 63.7 76.1 55.3 64.1
MUC 74.4 59.9 66.4 75.9 59.6 66.8 75.4 60.3 67.0
CEAFm 83.0 83.0 83.0 83.4 83.4 83.4 83.5 83.5 83.5
B3 91.8 84.6 88.1 92.6 84.5 88.4 92.3 84.7 88.4
</table>
<bodyText confidence="0.997136931034483">
results of RELAXCOR using the mention-pair model, as explained in Section 4, the next
three columns are the results of RELAXCOR adding the features of Section 6.2.1, and the
final three columns are the scores for RELAXCOR with the constraints of Section 6.2.2.
Note that the main improvements are focused around PN N, CN P, and CN N, as
expected. Moreover, the global scores also improve, but the global improvements are
not statistically significant.
Although there are improvements in our target classes (PN N, CN P, and CN N),
there are some collateral effects that decrease the performance for other classes such
as PN P and P 3U (ungendered pronouns: it). The latter is a strong decrease and, given
that the class P 3U represents 18% of the total coreferent mentions, this affects the global
results. This decrease in pronoun classification performance is related to the balance
value learned in the development process. One possible solution would be to have a
different balance value depending on the class.
Another phenomenon to take into account in the case of RELAXCOR + features is
that the improvement in global scores is in precision but not in recall. This is because
the development process is optimizing scores for the CEAF measure, which encourages
precision more than recall compared with the MUC scorer.
The improvements achieved seem too few given the necessary effort to extract the
knowledge. In general terms, we have found that, although performance is slightly
improved on average, few new coreference relations are found, taking into account
the expected potential for improvement. Moreover, some of these new relations do not
change the final output and, even worse, many of them are incorrect. In addition, some
coreferences that were correctly solved before this process are now incorrectly classified.
In particular, the recall of ungendered pronouns has decreased considerably.
Finally, it is interesting to remark that these improvements are achieved thanks to a
reduced number of mentions in test documents that end up having an actual Wikipedia-
influenced constraint (e.g., fewer than 1% of the mentions in features model). Thus, better
extraction procedures or a knowledge source more suitable for entities appearing in the
target documents should yield larger improvements.
</bodyText>
<page confidence="0.991498">
879
</page>
<note confidence="0.561813">
Computational Linguistics Volume 39, Number 4
</note>
<bodyText confidence="0.999774125">
More details on the extraction process and a detailed error analysis can be found in
Sapena (2012). The error analysis shows how the extracted knowledge was often redun-
dant (i.e., used only in cases where the algorithm already produced the right answer)
or noisy (due to errors in the entity disambiguation or information extraction steps).
Thus, we think that the experiments show that RELAXCOR is able to incorporate world
knowledge into the resolution model in an easy and natural way, and that further work
is required on acquiring more accurate and useful knowledge to feed the coreference
resolution process.
</bodyText>
<sectionHeader confidence="0.990852" genericHeader="acknowledgments">
7. Conclusions
</sectionHeader>
<bodyText confidence="0.923649921052632">
In this work, we defined an approach based on constraint satisfaction that represents
the problem in a hypergraph and solves it by relaxation labeling, reducing coreference
resolution to a hypergraph partitioning problem under a set of constraints. Our ap-
proach manages mention-pair and entity-mention models at the same time, and is able
to introduce new information by adding as many constraints as necessary. Furthermore,
our approach overcomes the weaknesses of previous approaches in state-of-the-art
systems, such as linking contradictions, classifications without context, and a lack of
information in evaluating pairs.
The presented system, RELAXCOR, achieved state-of-the-art results using only the
mention-pair model without new knowledge. Moreover, experiments with the entity-
mention model showed how it is able to introduce knowledge in a constructive way.
Although it is clearly necessary to incorporate world knowledge to move forward
in the field of coreference resolution, the process required to introduce such information
in a constructive way has not yet been found. In this work, we tested a methodology
that identified the real-world entities referred to in a document, extracted information
about them from Wikipedia, and then incorporated this information in two different
ways in the model. It seems that neither of the two forms work very well, however, and
that the results and errors are in the same direction: The slight improvement of the few
new relationships is offset by the added noise. Other state-of-the-art systems have better
improvements than ours (Ponzetto and Strube 2006; Uryupina et al. 2011; Rahman and
Ng 2011a), but these also seem too modest given the large amount of information used
and the room for improvement outlined in the Introduction.
The problem seems to lie with the extracted information rather than the model used
to incorporate it. The extracted information is biased in favor of the more famous and
popular entities (those in Wikipedia, and having larger entries). This causes the system
to find more information about these entities, including false positives, and causes an
imbalance against entities with little or no information in Wikipedia. Moreover, it is not
possible to use negative information in the absence of complete information.
Therefore, we believe that research in this field should focus on the extraction of
more reliable and concise information, so that the information added, no matter how
minimal, should always be constructive and avoid false positives. On the other hand,
we would need to find some process of reasoning to expand the scope of the information
obtained using logic and common sense. Only then could the full potential of the
knowledge base be exploited.
Acknowledgments from the European Community’s Seventh
This research was supported by the Spanish Framework Programme (FP7/2007-2013)
Science and Innovation Ministry, via the under grant agreement number 247762
KNOW2 project (TIN2009-14715-C04-04) and (FAUST).
</bodyText>
<page confidence="0.986718">
880
</page>
<note confidence="0.689518">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
</note>
<sectionHeader confidence="0.85706" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.922379888888889">
Aone, C. and S. W. Bennett. 1995. Evaluating
automated and manual acquisition
of anaphora resolution strategies.
In Proceedings of the Annual Meeting of the
Association for Computational Linguistics
(ACL 1995), pages 122–129.
Atserias, J. 2006. Towards Robustness in
Natural Language Understanding.
Ph.D. thesis, Departamento de
Lenguajes y Sistemas Inform´aticos,
Euskal Herriko Unibertsitatea,
Donosti, Spain.
Azzam, S., K. Humphreys, and
R. Gaizauskas. 1999. Using coreference
chains for text summarization.
In Proceedings of the Workshop on
Coreference and its Applications,
pages 77–84, Stroudsburg, PA.
Bagga, A. and B. Baldwin. 1998. Algorithms
for scoring coreference chains. In
Proceedings of the Linguistic Coreference
Workshop at LREC, pages 563–566,
Granada.
Bean, D., E. Riloff, S. Dumais, D. Marcu, and
S. Roukos. 2004. Unsupervised learning of
contextual role knowledge for coreference
resolution. In Proceedings of the Annual
Conference of the North American Chapter of
the Association for Computational Linguistics
(NAACL-HLT 2004), pages 297–304,
Boston, MA.
Bengtson, E. and D. Roth. 2008.
Understanding the value of features for
coreference resolution. In Proceedings of the
Conference on Empirical Methods in Natural
Language Processing (EMNLP 2008),
pages 294–303, Waikiki, HI.
Cai, J. and M. Strube. 2010. End-to-end
coreference resolution via hypergraph
partitioning. In Proceedings of the
23rd International Conference on
Computational Linguistics, pages 143–151,
Beijing.
Cardie, C. and K. Wagstaff. 1999. Noun
phrase coreference as clustering.
In Proceedings of the 1999 Joint SIGDAT
Conference on Empirical Methods in
Natural Language Processing and Very
Large Corpora (EMNLP-VLC 1999),
pages 82–89, College Park, MD.
Collins, M. 1999. Head-Driven Statistical
Models for Natural Language Parsing.
Ph.D. thesis, University of Pennsylvania.
Culotta, A., M. Wick, and A. McCallum.
2007. First-order probabilistic models for
coreference resolution. In Proceedings of the
Annual Conference of the North American
Chapter of the Association for Computational
Linguistics (NAACL-HLT 2007),
pages 81–88, Rochester, NY.
Denis, P. 2007. New Learning Models for
Robust Reference Resolution. Ph.D. thesis,
University of Texas at Austin.
Denis, P. and J. Baldridge. 2007. Joint
determination of anaphoricity and
coreference resolution using integer
programming. Proceedings of the Annual
Conference of the North American Chapter of
the Association for Computational Linguistics
(NAACL-HLT 2007), pages 236–243,
Rochester, NY.
Denis, P. and J. Baldridge. 2008. Specialized
models and ranking for coreference
resolution. Proceedings of the Conference on
Empirical Methods for Natural Language
Processing (EMNLP 2008).
Finkel, J. R. and C. D. Manning. 2008.
Enforcing transitivity in coreference
resolution. In Proceedings of the Annual
Meeting of the Association for Computational
Linguistics (ACL 2008), pages 45–48,
Columbus, OH.
Finley, T. and T. Joachims. 2005. Supervised
clustering with support vector machines.
ACM International Conference Proceedings
Series, 119:217–224.
Haghighi, A. and D. Klein. 2007.
Unsupervised coreference resolution
in a nonparametric bayesian model.
In Proceedings of the Annual Meeting of the
Association of Computational Linguistics
(ACL 2007), pages 848–855.
Hummel, R. A. and S. W. Zucker. 1983. On
the foundations of relaxation labeling
processes. IEEE Transactions on Pattern
Analysis and Machine Intelligence,
5(3):267–287.
Ji, H., D. Westbrook, and R. Grishman.
2005. Using semantic relations to refine
coreference decisions. Proceedings of the
Conference on Human Language Technology
and Empirical Methods in Natural Language
Processing (HLT-EMNLP 2005),
pages 17–24, Prague.
Kingsbury, P. and M. Palmer. 2003.
Propbank: the next level of treebank.
In Proceedings of Treebanks and Lexical
Theories, V¨axj¨o.
Klenner, M. 2007. Enforcing consistency on
coreference sets. In Proceedings of the
Conference on Recent Advances in Natural
Language Processing (RANLP 2007),
pages 323–328, Borovets.
Klenner, M. and ´E. Ailloud. 2008. Enhancing
Coreference Clustering. In Proceedings of
the Second Workshop on Anaphora Resolution
(WAR II, 2008), pages 31–40, Bergen.
</reference>
<page confidence="0.990494">
881
</page>
<note confidence="0.540542">
Computational Linguistics Volume 39, Number 4
</note>
<reference confidence="0.999192813559322">
Lee, H., Y. Peirsman, A. Chang,
N. Chambers, M. Surdeanu, and
D. Jurafsky. 2011. Stanford’s multi-pass
sieve coreference resolution system at the
CoNLL-2011 shared task. In Proceedings of
the Fifteenth Conference on Computational
Natural Language Learning: Shared Task,
pages 28–34, Portland, OR.
Luo, X. 2005. On coreference resolution
performance metrics. Proceedings of the
Joint Conference on Human Language
Technology and Empirical Methods in Natural
Language Processing (HLT-EMNLP 2005),
pages 25–32, Vancouver.
Luo, X. 2007. Coreference or not: A twin
model for coreference resolution. In
Proceedings of the Annual Conference of the
North American Chapter of the Association for
Computational Linguistics (NAACL-HLT
2007), pages 73–80, Rochester, NY.
Luo, X., A. Ittycheriah, H. Jing,
N. Kambhatla, and S. Roukos. 2004.
A mention-synchronous coreference
resolution algorithm based on the bell
tree. In Proceedings of the Annual Meeting
of the Association for Computational
Linguistics (ACL 2004), pages 135–142,
Barcelona.
M`arquez, L., L. Padr´o, and H. Rodriguez.
2000. A machine learning approach for
POS tagging. Machine Learning Journal,
39(1):59–91.
M`arquez, L., M. Recasens, and E. Sapena.
2012. Coreference resolution: An empirical
study based on SemEval-2010 shared
task 1. Journal on Language Resources and
Evaluation, Special Issue on SemEval-2010.
doi:10.1007/s510579-012-9194-z.
McCallum, A. and B. Wellner. 2005.
Conditional models of identity uncertainty
with application to noun coreference.
Advances in Neural Information Processing
Systems, 17:905–912.
McCarthy, J. F. and W. G. Lehnert. 1995.
Using decision trees for coreference
resolution. Proceedings of the Fourteenth
International Conference on Artificial
Intelligence, pages 1,050–1,055.
Mitkov, Ruslan. 2002. Anaphora Resolution.
Longman.
Morton, T. S. 2000. Using coreference in
question answering. NIST Special
Publication SP, pages 685–688.
Ng, V. 2005. Machine learning for coreference
resolution: From local classification to
global ranking. In Proceedings of the Annual
Meeting of the Association for Computational
Linguistics (ACL 2005), pages 157–164,
Ann Arbor, MI.
Ng, V. 2007. Shallow semantics for
coreference resolution. In Proceedings of the
International Joint Conference on Artificial
Intelligence (IJCAI 2007), pages 1,689–1,694,
Hyderabad.
Ng, V. 2008. Unsupervised models for
coreference resolution. In Proceedings of the
Conference on Empirical Methods in Natural
Language Processing (EMNLP 2008),
pages 640–649, Waikiki, HI.
Ng, V. 2009. Graph-cut-based anaphoricity
determination for coreference resolution.
In Proceedings of the Annual Conference of the
North American Chapter of the Association for
Computational Linguistics (ACL 2009),
pages 575–583, Suntec.
Ng, V. 2010. Supervised noun phrase
coreference research: The first fifteen
years. In Proceedings of the Annual Meeting
of the Association for Computational
Linguistics (ACL 2010), pages 1,396–1,411,
Uppsala.
Ng, V. and C. Cardie. 2002. Improving
machine learning approaches to
coreference resolution. In Proceedings
of the Annual Meeting of the Association for
Computational Linguistics (ACL 2002),
pages 104–111, Philadelphia, PA.
Nicolae, C. and G. Nicolae. 2006. Best
Cut: A graph algorithm for coreference
resolution. Proceedings of the Conference on
Empirical Methods for Natural Language
Processing (EMNLP 2006), pages 275–283,
Sydney.
NIST, US. 2003. The ACE 2003 Evaluation
Plan. US National Institute for Standards
and Technology (NIST), pages 1–8.
Padr´o, L. 1998. A Hybrid Environment for
Syntax–Semantic Tagging. Ph.D. thesis,
Departamento de Llenguatges i Sistemes
Inform`aics, Universitat Polit´ecnica de
Catalunya.
Pelillo, M. 1997. The dynamics of nonlinear
relaxation labeling processes. Journal
of Mathematical Imaging and Vision,
7(4):309–323.
Peral, J., M. Palomar, and A. Ferr´andez.
1999. Coreference-oriented interlingual
slot structure &amp; machine translation.
In Proceedings of the Workshop on
Coreference and its Applications,
pages 69–76, Stroudsburg, PA.
Ponzetto, S. P. and M. Strube. 2006.
Exploiting semantic role labeling,
WordNet and Wikipedia for
coreference resolution. In Proceedings
of the Human Language Technology
Conference of the North American Chapter
of the Association of Computational
</reference>
<page confidence="0.978977">
882
</page>
<reference confidence="0.999774462184874">
Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution
Linguistics (NAACL 2006), pages 192–199,
New York, NY.
Poon, H. and P. Domingos. 2008. Joint
unsupervised coreference resolution
with Markov Logic. In Proceedings of the
Conference on Empirical Methods in Natural
Language Processing (EMNLP 2008),
pages 650–659, Waikiki, HI.
Popescu, A. M. and O. Etzioni. 2005.
Extracting product features and opinions
from reviews. In Proceedings of the
Conference on Human Language Technology
and Empirical Methods in Natural Language
Processing (HLT-EMNLP 2005),
pages 339–346, Vancouver.
Pradhan, S., A. Moschitti, N. Xue,
O. Uryupina, and Y. Zhang. 2012.
CoNLL-2012 shared task: Modeling
multilingual unrestricted coreference in
OntoNotes. In Proceedings of the Conference
on Computational Natural Language Learning
(CoNLL 2012), pages 1–40, Jeju Island.
Pradhan, S., L. Ramshaw, M. Marcus,
M. Palmer, R. Weischedel, and N. Xue.
2011. CoNLL-2011 shared task: Modeling
unrestricted coreference in OntoNotes.
In Proceedings of the Conference on
Computational Natural Language Learning
(CoNLL 2011), pages 1–27, Portland, OR.
Pradhan, S. S., L. Ramshaw, R. Weischedel,
J. MacBride, and L. Micciulla. 2007.
Unrestricted coreference: Identifying
entities and events in OntoNotes. In
Proceedings of the International Conference
on Semantic Computing (ICSC 2007),
pages 446–453.
Quinlan, J. R. 1993. C4.5: Programs for
Machine Learning. Morgan Kaufmann.
Rahman, A. and V. Ng. 2011a. Coreference
resolution with world knowledge. In
Proceedings of the Annual Meeting of the
Association for Computational Linguistics
(ACL 2011), pages 814–824, Portland, OR.
Rahman, A. and V. Ng. 2011b. Narrowing
the modeling gap: A cluster-ranking
approach to coreference resolution.
Journal of Artificial Intelligence Research,
40(1):469–521.
Recasens, M., L. M`arquez, E. Sapena, M. A.
Marti, M. Taul´e, V. Hoste, M. Poesio,
and Y. Versley. 2010. SemEval-2010
Task 1: Coreference resolution in
multiple languages. In Proceedings of
the International Workshop on Semantic
Evaluations (SemEval-2010), pages 1–8,
Uppsala.
Rosenfeld, R., R. A. Hummel, and
S. W. Zucker. 1976. Scene labelling by
relaxation operations. IEEE Transactions
on Systems, Man and Cybernetics,
6(6):420–433.
Rounds, E. M. 1980. A combined
nonparametric approach to feature
selection and binary decision tree design.
Pattern Recognition, 12(5):313–317.
Safavian, S. R. and D. Landgrebe.1991.
A survey of decision tree classifier
methodology. IEEE Transactions on
Systems, Man and Cybernetics,
21(3):660–674.
Sapena, E. 2012. A Constraint-Based
Hypergraph Partitioning Approach to
Coreference Resolution. Ph.D. thesis,
Universitat Politecnica de Catalunya.
Sapena, E., L. Padr´o, and J. Turmo. 2010a.
A global relaxation labeling approach to
coreference resolution. In Proceedings
of the International Conference on
Computational Linguistics (COLING 2010),
pages 1,086–1,094, Beijing.
Sapena, E., L. Padr´o, and J. Turmo. 2010b.
RelaxCor: A global relaxation labeling
approach to coreference resolution.
In Proceedings of the ACL Workshop on
Semantic Evaluations (SemEval-2010),
pages 88–91, Uppsala.
Sapena, E., L. Padr´o, and J. Turmo. 2011.
RelaxCor participation in CoNLL shared
task on coreference resolution.
In Proceedings of the Fifteenth Conference
on Computational Natural Language
Learning: Shared Task, pages 35–39,
Portland, OR.
Soon, W. M., H. T. Ng, and D. C. Y. Lim.
2001. A machine learning approach to
coreference resolution of noun phrases.
Computational Linguistics, 27(4):521–544.
Stoyanov, V., N. Gilbert, C. Cardie, and
E. Riloff. 2009. Conundrums in noun
phrase coreference resolution: Making
sense of the state-of-the-art. In Proceedings
of the Joint Conference of the Annual
Meeting of the ACL and the International
Joint Conference on Natural Language
Processing (ACL-IJCNLP 2009),
pages 656–664, Suntec.
Torras, C. 1989. Relaxation and neural
learning: Points of convergence and
divergence. Journal of Parallel and
Distributed Computing, 6:217–244.
Uryupina, O. 2009. Detecting anaphoricity
and antecedenthood for coreference
resolution. Procesamiento del Lenguaje
Natural, pages 113–120.
Uryupina, O., M. Poesio, C. Giuliano, and
K. Tymoshenko. 2011. Disambiguation and
filtering methods in using Web knowledge
for coreference resolution. In Proceedings of
</reference>
<page confidence="0.978573">
883
</page>
<reference confidence="0.978376378378378">
Computational Linguistics Volume 39, Number 4
the International Florida Artificial Intelligence
Research Society Conference, pages 317–322,
Palm Beach, FL.
Vilain, M., J. Burger, J. Aberdeen,
D. Connolly, and L. Hirschman. 1995.
A model-theoretic coreference scoring
scheme. In Proceedings of the Message
Understanding Conference (MUC-6),
pages 45–52, Arlington, VA.
Yang, X., J. Su, J. Lang, C. L. Tan, T. Liu, and
S. Li. 2008. An entity-mention model for
coreference resolution with inductive logic
programming. In Proceedings of the Annual
Meeting of the Association for Computational
Linguistics (ACL 2008), pages 843–851,
Columbus, OH.
Yang, X., J. Su, and C. L. Tan. 2006.
Kernel-based pronoun resolution with
structured syntactic knowledge.
Proceedings of the 21st International
Conference on Computational Linguistics and
the 44th Annual Meeting of the Association for
Computational Linguistics (COLING-ACL
2006), pages 41–48, Sydney.
Yang, X., J. Su, G. Zhou, and C. L. Tan.
2004. An NP-cluster based approach to
coreference resolution. In Proceedings of the
International Conference on Computational
Linguistics (COLING 2004), pages 226–232,
Geneva.
Yang, X., G. Zhou, J. Su, and C. L. Tan. 2003.
Coreference resolution using competition
learning approach. In Proceedings of
the Annual Meeting of the Association for
Computational Linguistics (ACL 2003),
pages 176–183, Sapporo.
</reference>
<page confidence="0.998751">
884
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.402138">
<title confidence="0.8355095">A Constraint-Based Hypergraph Partitioning Approach to Coreference Resolution</title>
<affiliation confidence="0.979523333333333">Universitat Polit`ecnica de Catalunya Universitat Polit`ecnica de Catalunya Universitat Polit`ecnica de Catalunya</affiliation>
<note confidence="0.766655">This work is focused on research in machine learning for coreference resolution. Coreference</note>
<abstract confidence="0.993842230769231">resolution is a natural language processing task that consists of determining the expressions in a discourse that refer to the same entity. The main contributions of this article are (i) a new approach to coreference resolution based on constraint satisfaction, using a hypergraph to represent the problem and solving it by relaxation labeling; and (ii) research towards improving coreference resolution performance using world knowledge extracted from Wikipedia. The developed approach is able to use an entity-mention classification model with more expressiveness than the pair-based ones, and overcome the weaknesses of previous approaches in the state of the art such as linking contradictions, classifications without context, and lack of information evaluating pairs. Furthermore, the approach allows the incorporation of new information by adding constraints, and research has been done in order to use world knowledge to improve performances. the implementation of the approach, achieved results at the state-of-the-art level,</abstract>
<note confidence="0.9534085">participated in international competitions: SemEval-2010 and CoNLL-2011. achieved second place in CoNLL-2011.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Aone</author>
<author>S W Bennett</author>
</authors>
<title>Evaluating automated and manual acquisition of anaphora resolution strategies.</title>
<date>1995</date>
<contexts>
<context position="13951" citStr="Aone and Bennett (1995)" startWordPosition="2088" endWordPosition="2091">l approach in this field needs the expressiveness of the entity-mention model as well as the mention-pair model in order to use the most typical mention-pair features. Furthermore, such an approach should overcome the weaknesses of previous state-of-the-art approaches, such as linking contradictions, classifications without context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manni</context>
</contexts>
<marker>Aone, Bennett, 1995</marker>
<rawString>Aone, C. and S. W. Bennett. 1995. Evaluating automated and manual acquisition of anaphora resolution strategies.</rawString>
</citation>
<citation valid="true">
<date>1995</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>122--129</pages>
<contexts>
<context position="13951" citStr="(1995)" startWordPosition="2091" endWordPosition="2091">s field needs the expressiveness of the entity-mention model as well as the mention-pair model in order to use the most typical mention-pair features. Furthermore, such an approach should overcome the weaknesses of previous state-of-the-art approaches, such as linking contradictions, classifications without context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manni</context>
</contexts>
<marker>1995</marker>
<rawString>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 1995), pages 122–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Atserias</author>
</authors>
<title>Towards Robustness in Natural Language Understanding.</title>
<date>2006</date>
<booktitle>Ph.D. thesis, Departamento de Lenguajes y Sistemas Inform´aticos, Euskal Herriko Unibertsitatea,</booktitle>
<location>Donosti,</location>
<contexts>
<context position="26423" citStr="Atserias 2006" startWordPosition="4121" endWordPosition="4122">uence rule. 3.4 Relaxation Labeling Relaxation is a generic name for a family of iterative algorithms that perform function optimization based on local information. They are closely related to neural nets and gradient steps. Relaxation labeling has been successfully used in engineering fields to solve systems of equations, in Artificial Intelligence for computer vision (Rosenfeld, Hummel, and Zucker 1976), and in many other AI problems. The algorithm has also been widely used to solve NLP problems such as part-of-speech tagging (Padr´o 1998), chunking, knowledge integration, semantic parsing (Atserias 2006), and opinion mining (Popescu and Etzioni 2005). Description Conditions Action Default influence rule for a (0)A (1)A mention-pair constraint (positive weight) Default influence rule for a (0)A (1)B mention-pair constraint (negative weight) Example of an influence rule for an (0,2)A, (1)B (3)B entity-mention constraint Figure 11 Default influence rules for mention-pair constraints. 856 Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution Figure 12 Representation of Relax solving a graph. The vertices representing mentions are connected by weighted edges eif</context>
</contexts>
<marker>Atserias, 2006</marker>
<rawString>Atserias, J. 2006. Towards Robustness in Natural Language Understanding. Ph.D. thesis, Departamento de Lenguajes y Sistemas Inform´aticos, Euskal Herriko Unibertsitatea, Donosti, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Azzam</author>
<author>K Humphreys</author>
<author>R Gaizauskas</author>
</authors>
<title>Using coreference chains for text summarization.</title>
<date>1999</date>
<booktitle>In Proceedings of the Workshop on Coreference and its Applications,</booktitle>
<pages>77--84</pages>
<location>Stroudsburg, PA.</location>
<marker>Azzam, Humphreys, Gaizauskas, 1999</marker>
<rawString>Azzam, S., K. Humphreys, and R. Gaizauskas. 1999. Using coreference chains for text summarization. In Proceedings of the Workshop on Coreference and its Applications, pages 77–84, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bagga</author>
<author>B Baldwin</author>
</authors>
<title>Algorithms for scoring coreference chains.</title>
<date>1998</date>
<booktitle>In Proceedings of the Linguistic Coreference Workshop at LREC,</booktitle>
<pages>563--566</pages>
<location>Granada.</location>
<contexts>
<context position="58824" citStr="Bagga and Baldwin 1998" startWordPosition="9375" endWordPosition="9378">pation in Semeval-2010 and CoNLL-2011 shared tasks is explained in detail with performance, comparisons, and error analysis. Finally, a set of experiments using the entity-mention model are described. The framework used in our experiments consists of widely used corpora and measures to facilitate replication and comparison. Corpora used are ACE 2002 (NIST 2003), the same portion of OntoNotes v2.0 used in Semeval-2010 (Recasens et al. 2010), and the same portion of OntoNotes v4.0 used in CoNLL Shared Task 2011 (Pradhan et al. 2011). Regarding the measures, we used MUC (Vilain et al. 1995), B3 (Bagga and Baldwin 1998), and two variants of CEAF (Luo 2005): mention-based (CEAFm) and entity-based (CEAFe). 5.1 Mention Detection The performance of the mention detection system achieves a good recall, higher than 90%, but a low precision, as published in Sapena, Padr´o, and Turmo (2011) and reproduced in Table 1. The OntoNotes corpora have been used for this experiment, as they were used in CoNLL-2011. Given that the mention detection in a pipeline combination acts as a filter, recall should be kept high, as a loss of recall at the beginning would result in a loss of performance in the rest of the process. At thi</context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>Bagga, A. and B. Baldwin. 1998. Algorithms for scoring coreference chains. In Proceedings of the Linguistic Coreference Workshop at LREC, pages 563–566, Granada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bean</author>
<author>E Riloff</author>
<author>S Dumais</author>
<author>D Marcu</author>
<author>S Roukos</author>
</authors>
<title>Unsupervised learning of contextual role knowledge for coreference resolution.</title>
<date>2004</date>
<booktitle>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2004),</booktitle>
<pages>297--304</pages>
<location>Boston, MA.</location>
<contexts>
<context position="14579" citStr="Bean et al. (2004)" startWordPosition="2190" endWordPosition="2193">mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfaction that represents the problem in a hypergrap</context>
</contexts>
<marker>Bean, Riloff, Dumais, Marcu, Roukos, 2004</marker>
<rawString>Bean, D., E. Riloff, S. Dumais, D. Marcu, and S. Roukos. 2004. Unsupervised learning of contextual role knowledge for coreference resolution. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2004), pages 297–304, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Bengtson</author>
<author>D Roth</author>
</authors>
<title>Understanding the value of features for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>294--303</pages>
<location>Waikiki, HI.</location>
<contexts>
<context position="14197" citStr="Bengtson and Roth (2008)" startWordPosition="2128" endWordPosition="2131">e-of-the-art approaches, such as linking contradictions, classifications without context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCa</context>
</contexts>
<marker>Bengtson, Roth, 2008</marker>
<rawString>Bengtson, E. and D. Roth. 2008. Understanding the value of features for coreference resolution. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2008), pages 294–303, Waikiki, HI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cai</author>
<author>M Strube</author>
</authors>
<title>End-to-end coreference resolution via hypergraph partitioning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>143--151</pages>
<location>Beijing.</location>
<contexts>
<context position="14773" citStr="Cai and Strube (2010)" startWordPosition="2218" endWordPosition="2221"> and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfaction that represents the problem in a hypergraph and solves it by relaxation labeling, reducing coreference resolution to a hypergraph partitioning problem with a given set of constraints. The main strengths of this system are: • Modeling th</context>
<context position="56091" citStr="Cai and Strube (2010)" startWordPosition="8957" endWordPosition="8960"> balance value is determined by a development process. In our experiments, however, the number of group constraints is typically lower than the number of pairwise ones, so there is no need for pruning. 4.5 Related Work In Section 2, we introduced an overview of many approaches, with their classification models and resolution processes (see Figure 5). Our approach can be classified similarly as a one-step resolution that uses the entity-mention model for classification and conducts hypergraph partitioning for the linking process. This classification matches that of the COPA system described in Cai and Strube (2010). Both approaches represent the problem in a hypergraph, where each mention is a vertex, and use hypergraph partitioning in order to find the entities. The differences between these two approaches are substantial, however. The most significant differences are as follows: • Hypergraph generation. RELAXCOR adds hyperedges to the hypergraph for each group of mentions that satisfy a constraint, whereas COPA adds a hyperedge for each group of mentions that satisfy a feature. Note that the addition of hyperedge weights representing features cannot take advantage of the nonlinear combinations offered</context>
</contexts>
<marker>Cai, Strube, 2010</marker>
<rawString>Cai, J. and M. Strube. 2010. End-to-end coreference resolution via hypergraph partitioning. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 143–151, Beijing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cardie</author>
<author>K Wagstaff</author>
</authors>
<title>Noun phrase coreference as clustering.</title>
<date>1999</date>
<contexts>
<context position="14606" citStr="Cardie and Wagstaff (1999)" startWordPosition="2194" endWordPosition="2197">stic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfaction that represents the problem in a hypergraph and solves it by relaxati</context>
</contexts>
<marker>Cardie, Wagstaff, 1999</marker>
<rawString>Cardie, C. and K. Wagstaff. 1999. Noun phrase coreference as clustering.</rawString>
</citation>
<citation valid="true">
<date>1999</date>
<booktitle>In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP-VLC</booktitle>
<pages>82--89</pages>
<location>College Park, MD.</location>
<contexts>
<context position="14606" citStr="(1999)" startWordPosition="2197" endWordPosition="2197">hnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfaction that represents the problem in a hypergraph and solves it by relaxati</context>
<context position="37654" citStr="(1999)" startWordPosition="6022" endWordPosition="6022">tection system that uses part-of-speech and syntactic information. Syntactic information may be obtained from dependency parsing or constituent parsing. The system extracts one candidate mention for every: • Noun phrase (NP). • Pronoun. • Named Entity. • Capitalized common noun or proper name that appear two or more times in the document. For instance, the NP an Internet business is a mention, but also Internet is added in the case that the word is found once again in the document. The head of every candidate mention is then determined using part-of-speech tags and a set of rules from Collins (1999) when constituent parsing is used, or using dependency information otherwise. In case some NPs share the same head, the larger NP is selected and the rest are discarded. Also, mention repetitions with exactly the same boundaries are discarded. Note that a mention detection system in pipeline configuration with the resolution process acts as a filter and the main objective at this point is to achieve as much recall as possible. 4.2 Knowledge Sources and Features The system gathers knowledge using a set of feature functions that interpret and evaluate the input information according to some crit</context>
</contexts>
<marker>1999</marker>
<rawString>In Proceedings of the 1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora (EMNLP-VLC 1999), pages 82–89, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="37654" citStr="Collins (1999)" startWordPosition="6021" endWordPosition="6022">ntion detection system that uses part-of-speech and syntactic information. Syntactic information may be obtained from dependency parsing or constituent parsing. The system extracts one candidate mention for every: • Noun phrase (NP). • Pronoun. • Named Entity. • Capitalized common noun or proper name that appear two or more times in the document. For instance, the NP an Internet business is a mention, but also Internet is added in the case that the word is found once again in the document. The head of every candidate mention is then determined using part-of-speech tags and a set of rules from Collins (1999) when constituent parsing is used, or using dependency information otherwise. In case some NPs share the same head, the larger NP is selected and the rest are discarded. Also, mention repetitions with exactly the same boundaries are discarded. Note that a mention detection system in pipeline configuration with the resolution process acts as a filter and the main objective at this point is to achieve as much recall as possible. 4.2 Knowledge Sources and Features The system gathers knowledge using a set of feature functions that interpret and evaluate the input information according to some crit</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Collins, M. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Culotta</author>
<author>M Wick</author>
<author>A McCallum</author>
</authors>
<title>First-order probabilistic models for coreference resolution.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT</booktitle>
<pages>81--88</pages>
<location>Rochester, NY.</location>
<marker>Culotta, Wick, McCallum, 2007</marker>
<rawString>Culotta, A., M. Wick, and A. McCallum. 2007. First-order probabilistic models for coreference resolution. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2007), pages 81–88, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Denis</author>
</authors>
<title>New Learning Models for Robust Reference Resolution.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Texas at Austin.</institution>
<contexts>
<context position="60770" citStr="Denis 2007" startWordPosition="9688" endWordPosition="9689">t are not referential (e.g., predicative and appositive phrases) and mentions with incorrect boundaries. The incorrect boundaries are mainly due to errors in the predicted syntactic Table 1 Mention detection results on OntoNotes (Corpus: CoNLL-2011 Shared Task). OntoNotes Recall Precision F1 Development 92.45 27.34 42.20 Test 92.39 28.19 43.20 868 Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution Table 2 Results on ACE-phase02. bnews npaper nwire Global Metric: CEAF CEAF B3 Model F1 F1 F1 F1 P R F1 RELAXCOR 69.5 67.3 72.1 69.7 85.3 66.8 74.9 MaxEnt+ILP (Denis 2007) – – – 66.2 81.4 65.6 72.7 Rankers (Denis 2007) 65.7 65.3 68.1 67.0 79.8 66.8 72.7 column and some mention annotation discrepancies. Furthermore, the coreference annotation of OntoNotes used in CoNLL-2011 included verbs as anaphors of some verbal nominalizations. But verbs are not detected by our mention detection system, so most of the missing mentions are verbs. The methodology of the mention detection system is explained in Section 4.1. 5.2 State-of-the-Art Comparison RELAXCOR performance has been compared several times with other published results from state-of-the-art systems. We claimed </context>
</contexts>
<marker>Denis, 2007</marker>
<rawString>Denis, P. 2007. New Learning Models for Robust Reference Resolution. Ph.D. thesis, University of Texas at Austin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Denis</author>
<author>J Baldridge</author>
</authors>
<title>Joint determination of anaphoricity and coreference resolution using integer programming.</title>
<date>2007</date>
<booktitle>Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT</booktitle>
<pages>236--243</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="14519" citStr="Denis and Baldridge (2007)" startWordPosition="2180" endWordPosition="2183">assification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constr</context>
</contexts>
<marker>Denis, Baldridge, 2007</marker>
<rawString>Denis, P. and J. Baldridge. 2007. Joint determination of anaphoricity and coreference resolution using integer programming. Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2007), pages 236–243, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Denis</author>
<author>J Baldridge</author>
</authors>
<title>Specialized models and ranking for coreference resolution.</title>
<date>2008</date>
<booktitle>Proceedings of the Conference on Empirical Methods for Natural Language Processing (EMNLP</booktitle>
<contexts>
<context position="14292" citStr="Denis and Baldridge (2008)" startWordPosition="2144" endWordPosition="2147"> a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partition</context>
</contexts>
<marker>Denis, Baldridge, 2008</marker>
<rawString>Denis, P. and J. Baldridge. 2008. Specialized models and ranking for coreference resolution. Proceedings of the Conference on Empirical Methods for Natural Language Processing (EMNLP 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>C D Manning</author>
</authors>
<title>Enforcing transitivity in coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>45--48</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="14560" citStr="Finkel and Manning (2008)" startWordPosition="2186" endWordPosition="2189">d Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfaction that represents the pro</context>
</contexts>
<marker>Finkel, Manning, 2008</marker>
<rawString>Finkel, J. R. and C. D. Manning. 2008. Enforcing transitivity in coreference resolution. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2008), pages 45–48, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Finley</author>
<author>T Joachims</author>
</authors>
<title>Supervised clustering with support vector machines.</title>
<date>2005</date>
<booktitle>ACM International Conference Proceedings Series,</booktitle>
<pages>119--217</pages>
<contexts>
<context position="14743" citStr="Finley and Joachims (2005)" startWordPosition="2212" endWordPosition="2216"> Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfaction that represents the problem in a hypergraph and solves it by relaxation labeling, reducing coreference resolution to a hypergraph partitioning problem with a given set of constraints. The main strengths of </context>
</contexts>
<marker>Finley, Joachims, 2005</marker>
<rawString>Finley, T. and T. Joachims. 2005. Supervised clustering with support vector machines. ACM International Conference Proceedings Series, 119:217–224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haghighi</author>
<author>D Klein</author>
</authors>
<title>Unsupervised coreference resolution in a nonparametric bayesian model.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Meeting of the Association of Computational Linguistics (ACL</booktitle>
<pages>848--855</pages>
<contexts>
<context position="14846" citStr="Haghighi and Klein (2007)" startWordPosition="2230" endWordPosition="2233">Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfaction that represents the problem in a hypergraph and solves it by relaxation labeling, reducing coreference resolution to a hypergraph partitioning problem with a given set of constraints. The main strengths of this system are: • Modeling the problem in terms of hypergraph partitioning avoids linking contradictio</context>
</contexts>
<marker>Haghighi, Klein, 2007</marker>
<rawString>Haghighi, A. and D. Klein. 2007. Unsupervised coreference resolution in a nonparametric bayesian model. In Proceedings of the Annual Meeting of the Association of Computational Linguistics (ACL 2007), pages 848–855.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Hummel</author>
<author>S W Zucker</author>
</authors>
<title>On the foundations of relaxation labeling processes.</title>
<date>1983</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>5</volume>
<issue>3</issue>
<contexts>
<context position="32797" citStr="Hummel and Zucker 1983" startWordPosition="5196" endWordPosition="5199"> optimizes the goodness function F(Q, W), which depends on the edge weights W. In this manner, Q* is optimal if: F(Q*, W) &gt; F(Q, W), VQ (5) A partitioning Q is directly obtained from the weighted labeling H assigning to each variable the label with maximum probability. The supports and the weighted labeling depend on the edge weights (Equation (2)). To satisfy Equation (6) is equivalent to satisfying Equation (5). Many studies have been done towards the demonstration of the consistency, convergence, and cost reduction advantages of the relaxation algorithm (Rosenfeld, Hummel, and Zucker 1976; Hummel and Zucker 1983; Pelillo 1997). For instance, Hummel and Zucker (1983) prove that maximizing average consistency (left-hand-side term of Equation (6) produces labelings satisfying Equation (5) when only binary constraints are used. Although there is no formal proof for higher order constraints, the presented algorithm (that forces a stop after a number of iterations) has proven useful for practical purposes in our case. Li h*i Li hil x Sil Vh, Vi (6) l=1 l x Sil &gt; l=1 Note that because the weight update for each label is independent of the others, the algorithm can be straightforward parallelized. In the fol</context>
</contexts>
<marker>Hummel, Zucker, 1983</marker>
<rawString>Hummel, R. A. and S. W. Zucker. 1983. On the foundations of relaxation labeling processes. IEEE Transactions on Pattern Analysis and Machine Intelligence, 5(3):267–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ji</author>
<author>D Westbrook</author>
<author>R Grishman</author>
</authors>
<title>Using semantic relations to refine coreference decisions.</title>
<date>2005</date>
<booktitle>Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP</booktitle>
<pages>17--24</pages>
<location>Prague.</location>
<marker>Ji, Westbrook, Grishman, 2005</marker>
<rawString>Ji, H., D. Westbrook, and R. Grishman. 2005. Using semantic relations to refine coreference decisions. Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP 2005), pages 17–24, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kingsbury</author>
<author>M Palmer</author>
</authors>
<title>Propbank: the next level of treebank.</title>
<date>2003</date>
<booktitle>In Proceedings of Treebanks and Lexical Theories,</booktitle>
<location>V¨axj¨o.</location>
<contexts>
<context position="20585" citStr="Kingsbury and Palmer 2003" startWordPosition="3178" endWordPosition="3181">ch, m0 is not the first mention of its sentence, m0 is a maximal NP (the next parent node in the syntactic tree is the sentence itself), m1 also is a maximal NP, both mentions are ARG0 in semantic role labeling, and both mentions are pronouns.1 The constraint in Figure 9 applies to three mentions and requires that: The distance between consecutive mentions is one sentence, all three mentions agree in both gender and number, m0 and m2 are aliases, all three mentions are ARG0 in their respective sentences, and m0 and m2 are named entities and m1 is 1 The argument system used is due to PropBank (Kingsbury and Palmer 2003). DIST SEN 1(0,1) &amp; GENDER YES(0,1) &amp; ¬ FIRST(0) &amp; MAXIMALNP(0) &amp; MAXIMALNP(1) &amp; SRL ARG 0(0) &amp; SRL ARG 0(1) &amp; TYPE P(0) &amp; TYPE P(1) 854 Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution a common NP.2 There are many examples of negative constraints, that is, constraints that restrict mentions from being in the same entity. For instance GENDER NO(0,1) &amp; TYPE P(0) &amp; TYPE P(1) expresses that m1 and m0 are pronouns and do not match in gender. Each constraint has a weight that determines the hyperedge weight of the hypergraph (see Equation (1)). A constraint </context>
</contexts>
<marker>Kingsbury, Palmer, 2003</marker>
<rawString>Kingsbury, P. and M. Palmer. 2003. Propbank: the next level of treebank. In Proceedings of Treebanks and Lexical Theories, V¨axj¨o.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Klenner</author>
</authors>
<title>Enforcing consistency on coreference sets.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference on Recent Advances in Natural Language Processing (RANLP</booktitle>
<pages>323--328</pages>
<location>Borovets.</location>
<contexts>
<context position="14534" citStr="Klenner (2007)" startWordPosition="2184" endWordPosition="2185">process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfacti</context>
</contexts>
<marker>Klenner, 2007</marker>
<rawString>Klenner, M. 2007. Enforcing consistency on coreference sets. In Proceedings of the Conference on Recent Advances in Natural Language Processing (RANLP 2007), pages 323–328, Borovets.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Klenner</author>
<author>´E Ailloud</author>
</authors>
<title>Enhancing Coreference Clustering.</title>
<date>2008</date>
<booktitle>In Proceedings of the Second Workshop on Anaphora Resolution (WAR II,</booktitle>
<pages>31--40</pages>
<location>Bergen.</location>
<contexts>
<context position="14431" citStr="Klenner and Ailloud (2008)" startWordPosition="2167" endWordPosition="2170">y and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art ma</context>
</contexts>
<marker>Klenner, Ailloud, 2008</marker>
<rawString>Klenner, M. and ´E. Ailloud. 2008. Enhancing Coreference Clustering. In Proceedings of the Second Workshop on Anaphora Resolution (WAR II, 2008), pages 31–40, Bergen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Lee</author>
<author>Y Peirsman</author>
<author>A Chang</author>
<author>N Chambers</author>
<author>M Surdeanu</author>
<author>D Jurafsky</author>
</authors>
<title>Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>28--34</pages>
<location>Portland, OR.</location>
<contexts>
<context position="43320" citStr="Lee et al. (2011)" startWordPosition="6916" endWordPosition="6919"> learning process is appli RELAXCOR ed to obtain the set of constraints. Constraints can also be added writing them by hand. Adding manual constraints is expensive, same speaker. This section describes the training and development process for the implementation of 862 Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution Figure 16 RELAXCOR training process. however, given that it takes a group of linguistic experts many hours devoted to this task. An alternative option is to use constraints from other coreference resolution systems, such as the ones used in Lee et al. (2011). Our experiments are based on automatically learned constraints. Figure 16 shows the training process. First, a data selection process unbalances the training data set and then a machine learning process obtains the constraints. The learned constraints are then applied to the training data set and their precision is evaluated. The precision of each constraint determines its weight. The development process optimizes two parameters—balance and Nprune—in order to achieve maximum performance given a measure for the task. Figure 17 shows the development process. 4.3.1 Data Selection. Generating an</context>
<context position="69691" citStr="Lee et al. 2011" startWordPosition="11097" endWordPosition="11100">3 62.16 72.08 67.09 BLANC 69.50 73.07 71.10 (CEAFe+MUC+B3)/3 – – 55.99 the introduction of the balance value in the development process but also to many other refinements done in the whole process such as new feature functions and bug fixing. RELAXCOR achieved second position in the official closed track results, as shown in Figure 20. The final column shows the official ranking score. The difference from the system in first place is 1.8 points, which is statistically significant, whereas the difference to third position is just 0.03 points and is not significant. The winning system—Stanford (Lee et al. 2011)—does not use machine learning but combines many heuristics to join mentions and partial entities, starting with the most precise ones. It is thought that the difference between RELAXCOR and Stanford’s system is mainly due to their use of sophisticated handwritten heuristics instead of our automatically learned constraints. Note that Lee et al. (2011) solve coreferences by applying first the most precise constraints. RELAXCOR also solves first the most precise constraints given that these ones have the highest weights and are the most influencing ones. 5.3 Languages Sapena, Padr´o, and Turmo (</context>
</contexts>
<marker>Lee, Peirsman, Chang, Chambers, Surdeanu, Jurafsky, 2011</marker>
<rawString>Lee, H., Y. Peirsman, A. Chang, N. Chambers, M. Surdeanu, and D. Jurafsky. 2011. Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task, pages 28–34, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Luo</author>
</authors>
<title>On coreference resolution performance metrics.</title>
<date>2005</date>
<booktitle>Proceedings of the Joint Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP</booktitle>
<pages>25--32</pages>
<location>Vancouver.</location>
<contexts>
<context position="58861" citStr="Luo 2005" startWordPosition="9384" endWordPosition="9385">is explained in detail with performance, comparisons, and error analysis. Finally, a set of experiments using the entity-mention model are described. The framework used in our experiments consists of widely used corpora and measures to facilitate replication and comparison. Corpora used are ACE 2002 (NIST 2003), the same portion of OntoNotes v2.0 used in Semeval-2010 (Recasens et al. 2010), and the same portion of OntoNotes v4.0 used in CoNLL Shared Task 2011 (Pradhan et al. 2011). Regarding the measures, we used MUC (Vilain et al. 1995), B3 (Bagga and Baldwin 1998), and two variants of CEAF (Luo 2005): mention-based (CEAFm) and entity-based (CEAFe). 5.1 Mention Detection The performance of the mention detection system achieves a good recall, higher than 90%, but a low precision, as published in Sapena, Padr´o, and Turmo (2011) and reproduced in Table 1. The OntoNotes corpora have been used for this experiment, as they were used in CoNLL-2011. Given that the mention detection in a pipeline combination acts as a filter, recall should be kept high, as a loss of recall at the beginning would result in a loss of performance in the rest of the process. At this point, however, the precision is no</context>
</contexts>
<marker>Luo, 2005</marker>
<rawString>Luo, X. 2005. On coreference resolution performance metrics. Proceedings of the Joint Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP 2005), pages 25–32, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Luo</author>
</authors>
<title>Coreference or not: A twin model for coreference resolution.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT</booktitle>
<pages>73--80</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="14362" citStr="Luo (2007)" startWordPosition="2160" endWordPosition="2161">e if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A class</context>
<context position="50344" citStr="Luo (2007)" startWordPosition="8052" endWordPosition="8053">i) the contribution of the edge weights does not depend on the size of the document; (ii) most edges of the less informative pairs are discarded, avoiding further confusion without limitation on distance or other restrictions that cause a loss of recall; and (iii) computational costs are reduced from O(n3) to O(n2), given that the innermost loop has a constant number of iterations (Nprune). 4.3.4 Reordering. Usually, the vertices of the graph would be placed in the same order as the mentions are found in the document (chronological order). In this manner, vi corresponds to mi. As suggested by Luo (2007), however, there is no need to generate the model following that order. In our approach, the first variables have a lower number 865 Computational Linguistics Volume 39, Number 4 of possible labels. Moreover, an error in the first variables has more influence on the performance than an error in later ones. It is reasonable to expect that placing named entities at the beginning is helpful for the algorithm, given that named entities are usually the most informative mentions. Reordering only affects the number of possible labels of the variables. The chronological order of the document is taken </context>
</contexts>
<marker>Luo, 2007</marker>
<rawString>Luo, X. 2007. Coreference or not: A twin model for coreference resolution. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT 2007), pages 73–80, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Luo</author>
<author>A Ittycheriah</author>
<author>H Jing</author>
<author>N Kambhatla</author>
<author>S Roukos</author>
</authors>
<title>A mention-synchronous coreference resolution algorithm based on the bell tree.</title>
<date>2004</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2004),</booktitle>
<pages>135--142</pages>
<location>Barcelona.</location>
<contexts>
<context position="14351" citStr="Luo et al. (2004)" startWordPosition="2156" endWordPosition="2159">ld be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figur</context>
</contexts>
<marker>Luo, Ittycheriah, Jing, Kambhatla, Roukos, 2004</marker>
<rawString>Luo, X., A. Ittycheriah, H. Jing, N. Kambhatla, and S. Roukos. 2004. A mention-synchronous coreference resolution algorithm based on the bell tree. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2004), pages 135–142, Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L M`arquez</author>
<author>L Padr´o</author>
<author>H Rodriguez</author>
</authors>
<title>A machine learning approach for POS tagging.</title>
<date>2000</date>
<journal>Machine Learning Journal,</journal>
<volume>39</volume>
<issue>1</issue>
<marker>M`arquez, Padr´o, Rodriguez, 2000</marker>
<rawString>M`arquez, L., L. Padr´o, and H. Rodriguez. 2000. A machine learning approach for POS tagging. Machine Learning Journal, 39(1):59–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L M`arquez</author>
<author>M Recasens</author>
<author>E Sapena</author>
</authors>
<title>Coreference resolution: An empirical study based on</title>
<date>2012</date>
<booktitle>SemEval-2010 shared task 1. Journal on Language Resources and Evaluation, Special Issue on SemEval-2010.</booktitle>
<pages>10--1007</pages>
<marker>M`arquez, Recasens, Sapena, 2012</marker>
<rawString>M`arquez, L., M. Recasens, and E. Sapena. 2012. Coreference resolution: An empirical study based on SemEval-2010 shared task 1. Journal on Language Resources and Evaluation, Special Issue on SemEval-2010. doi:10.1007/s510579-012-9194-z.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>B Wellner</author>
</authors>
<title>Conditional models of identity uncertainty with application to noun coreference.</title>
<date>2005</date>
<booktitle>Advances in Neural Information Processing Systems,</booktitle>
<pages>17--905</pages>
<contexts>
<context position="14820" citStr="McCallum and Wellner (2005)" startWordPosition="2226" endWordPosition="2229">008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfaction that represents the problem in a hypergraph and solves it by relaxation labeling, reducing coreference resolution to a hypergraph partitioning problem with a given set of constraints. The main strengths of this system are: • Modeling the problem in terms of hypergraph partitioning a</context>
</contexts>
<marker>McCallum, Wellner, 2005</marker>
<rawString>McCallum, A. and B. Wellner. 2005. Conditional models of identity uncertainty with application to noun coreference. Advances in Neural Information Processing Systems, 17:905–912.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F McCarthy</author>
<author>W G Lehnert</author>
</authors>
<title>Using decision trees for coreference resolution.</title>
<date>1995</date>
<booktitle>Proceedings of the Fourteenth International Conference on Artificial Intelligence,</booktitle>
<pages>1--050</pages>
<contexts>
<context position="14012" citStr="McCarthy and Lehnert (1995)" startWordPosition="2096" endWordPosition="2099">entity-mention model as well as the mention-pair model in order to use the most typical mention-pair features. Furthermore, such an approach should overcome the weaknesses of previous state-of-the-art approaches, such as linking contradictions, classifications without context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2</context>
</contexts>
<marker>McCarthy, Lehnert, 1995</marker>
<rawString>McCarthy, J. F. and W. G. Lehnert. 1995. Using decision trees for coreference resolution. Proceedings of the Fourteenth International Conference on Artificial Intelligence, pages 1,050–1,055.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Anaphora Resolution.</title>
<date>2002</date>
<publisher>Longman.</publisher>
<contexts>
<context position="6220" citStr="Mitkov (2002)" startWordPosition="899" endWordPosition="900">ng methods. The experiments and error analysis are described in Section 5. Section 6 presents our approach to incorporate world knowledge in order to improve coreference resolution performance. Experiments and a detailed error analysis are also included. Finally, we discuss the conclusions of this article in Section 7. 848 Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution 2. Coreference Resolution: State of the Art In this section we summarize the main machine-learning–based approaches to coreference resolution. For a wider study, we refer the reader to Mitkov (2002). A coreference resolution system receives plain text as input, and returns the same text with coreference annotations as output. Most existing coreference resolution systems can be considered instances of this general process, which consists of three main steps: mention detection, characterization of mentions, and resolution (see Figure 2). The first step is the detection of mentions, where text processing is needed in order to find the boundaries of the mentions in the input text. Next, in the second step, the identified mentions are characterized by gathering all the available knowledge abo</context>
</contexts>
<marker>Mitkov, 2002</marker>
<rawString>Mitkov, Ruslan. 2002. Anaphora Resolution. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T S Morton</author>
</authors>
<title>Using coreference in question answering.</title>
<date>2000</date>
<journal>NIST Special Publication SP,</journal>
<pages>685--688</pages>
<contexts>
<context position="4246" citStr="Morton 2000" startWordPosition="614" endWordPosition="615">ficulty of coreference resolution lies in the variety of necessary knowledge sources. For instance, morphological and syntactic analysis is needed to detect mentions, and semantic/world knowledge to know that Messi is a star striker and a young Argentine. Coreference resolution is a mandatory step in order to understand natural language. In this sense, dealing with such a problem becomes important for tasks in which the higher their comprehension of the discourse, the better such systems will perform— tasks such as machine translation (Peral, Palomar, and Ferr´andez 1999), question answering (Morton 2000), summarization (Azzam, Humphreys, and Gaizauskas 1999), and information extraction. One of the possible directions to follow in coreference resolution research is the incorporation of new information such as world knowledge and discourse coherence. In some cases, this information cannot be expressed in terms of pairs of mentions—that is, it is information that involves either several mentions at once or partial entities. Furthermore, an experimental approach in this field should overcome the weaknesses of previous state-of-the-art approaches, such as linking contradictions, classifications wi</context>
</contexts>
<marker>Morton, 2000</marker>
<rawString>Morton, T. S. 2000. Using coreference in question answering. NIST Special Publication SP, pages 685–688.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
</authors>
<title>Machine learning for coreference resolution: From local classification to global ranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>157--164</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="14127" citStr="Ng (2005)" startWordPosition="2119" endWordPosition="2120">pproach should overcome the weaknesses of previous state-of-the-art approaches, such as linking contradictions, classifications without context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and</context>
</contexts>
<marker>Ng, 2005</marker>
<rawString>Ng, V. 2005. Machine learning for coreference resolution: From local classification to global ranking. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2005), pages 157–164, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
</authors>
<title>Shallow semantics for coreference resolution.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI</booktitle>
<pages>1--689</pages>
<location>Hyderabad.</location>
<contexts>
<context position="14137" citStr="Ng (2007)" startWordPosition="2121" endWordPosition="2122">ould overcome the weaknesses of previous state-of-the-art approaches, such as linking contradictions, classifications without context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims </context>
</contexts>
<marker>Ng, 2007</marker>
<rawString>Ng, V. 2007. Shallow semantics for coreference resolution. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI 2007), pages 1,689–1,694, Hyderabad.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
</authors>
<title>Unsupervised models for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>640--649</pages>
<location>Waikiki, HI.</location>
<contexts>
<context position="14616" citStr="Ng (2008)" startWordPosition="2198" endWordPosition="2199">1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfaction that represents the problem in a hypergraph and solves it by relaxation labelin</context>
</contexts>
<marker>Ng, 2008</marker>
<rawString>Ng, V. 2008. Unsupervised models for coreference resolution. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2008), pages 640–649, Waikiki, HI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
</authors>
<title>Graph-cut-based anaphoricity determination for coreference resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (ACL</booktitle>
<pages>575--583</pages>
<contexts>
<context position="14230" citStr="Ng (2009)" startWordPosition="2136" endWordPosition="2137">ictions, classifications without context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi </context>
</contexts>
<marker>Ng, 2009</marker>
<rawString>Ng, V. 2009. Graph-cut-based anaphoricity determination for coreference resolution. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (ACL 2009), pages 575–583, Suntec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
</authors>
<title>Supervised noun phrase coreference research: The first fifteen years.</title>
<date>2010</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2010),</booktitle>
<pages>1--396</pages>
<location>Uppsala.</location>
<contexts>
<context position="12878" citStr="Ng (2010)" startWordPosition="1937" endWordPosition="1938">s performed on-line. In this manner, mention-group and entity-mention models can be easily incorporated. Figure 5 summarizes the classification of several systems in the state of the art, up to 2011. Recently, the CoNLL-2012 shared task (Pradhan et al. 2012) offered an evaluation framework similar to that of CoNLL-2011. The second column specifies which resolution step is used. The third column shows the classification model used by the system, and the fourth column identifies the algorithm followed in the linking process. More details about supervised machine learning systems can be found in Ng (2010). 3. A Constraint-Based Hypergraph Partitioning Approach to Coreference Resolution One of the possible directions to follow in coreference resolution research is the incorporation of new information such as world knowledge and discourse coherence. In some cases, this information cannot be expressed in terms of pairs of mentions, that is, it is information that involves either several mentions at once or partial entities. Therefore, an experimental approach in this field needs the expressiveness of the entity-mention model as well as the mention-pair model in order to use the most typical menti</context>
</contexts>
<marker>Ng, 2010</marker>
<rawString>Ng, V. 2010. Supervised noun phrase coreference research: The first fifteen years. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2010), pages 1,396–1,411, Uppsala.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
<author>C Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>104--111</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="14117" citStr="Ng and Cardie (2002)" startWordPosition="2115" endWordPosition="2118">urthermore, such an approach should overcome the weaknesses of previous state-of-the-art approaches, such as linking contradictions, classifications without context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entity</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Ng, V. and C. Cardie. 2002. Improving machine learning approaches to coreference resolution. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2002), pages 104–111, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Nicolae</author>
<author>G Nicolae</author>
</authors>
<title>Best Cut: A graph algorithm for coreference resolution.</title>
<date>2006</date>
<booktitle>Proceedings of the Conference on Empirical Methods for Natural Language Processing (EMNLP</booktitle>
<pages>275--283</pages>
<location>Sydney.</location>
<contexts>
<context position="14492" citStr="Nicolae and Nicolae (2006)" startWordPosition="2176" endWordPosition="2179">er 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define </context>
</contexts>
<marker>Nicolae, Nicolae, 2006</marker>
<rawString>Nicolae, C. and G. Nicolae. 2006. Best Cut: A graph algorithm for coreference resolution. Proceedings of the Conference on Empirical Methods for Natural Language Processing (EMNLP 2006), pages 275–283, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>US NIST</author>
</authors>
<date>2003</date>
<booktitle>The ACE 2003 Evaluation Plan. US National Institute for Standards and Technology (NIST),</booktitle>
<pages>1--8</pages>
<contexts>
<context position="58564" citStr="NIST 2003" startWordPosition="9332" endWordPosition="9333">s. First, there is an explanation of a set of experiments to evaluate the performance of coreference resolution and mention detection. The scores are compared with the state of the art in diverse corpora, measures, and languages. Next, our participation in Semeval-2010 and CoNLL-2011 shared tasks is explained in detail with performance, comparisons, and error analysis. Finally, a set of experiments using the entity-mention model are described. The framework used in our experiments consists of widely used corpora and measures to facilitate replication and comparison. Corpora used are ACE 2002 (NIST 2003), the same portion of OntoNotes v2.0 used in Semeval-2010 (Recasens et al. 2010), and the same portion of OntoNotes v4.0 used in CoNLL Shared Task 2011 (Pradhan et al. 2011). Regarding the measures, we used MUC (Vilain et al. 1995), B3 (Bagga and Baldwin 1998), and two variants of CEAF (Luo 2005): mention-based (CEAFm) and entity-based (CEAFe). 5.1 Mention Detection The performance of the mention detection system achieves a good recall, higher than 90%, but a low precision, as published in Sapena, Padr´o, and Turmo (2011) and reproduced in Table 1. The OntoNotes corpora have been used for this</context>
</contexts>
<marker>NIST, 2003</marker>
<rawString>NIST, US. 2003. The ACE 2003 Evaluation Plan. US National Institute for Standards and Technology (NIST), pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Padr´o</author>
</authors>
<title>A Hybrid Environment for Syntax–Semantic Tagging.</title>
<date>1998</date>
<booktitle>Ph.D. thesis, Departamento de Llenguatges i Sistemes Inform`aics, Universitat Polit´ecnica de Catalunya.</booktitle>
<marker>Padr´o, 1998</marker>
<rawString>Padr´o, L. 1998. A Hybrid Environment for Syntax–Semantic Tagging. Ph.D. thesis, Departamento de Llenguatges i Sistemes Inform`aics, Universitat Polit´ecnica de Catalunya.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pelillo</author>
</authors>
<title>The dynamics of nonlinear relaxation labeling processes.</title>
<date>1997</date>
<journal>Journal of Mathematical Imaging and Vision,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="32812" citStr="Pelillo 1997" startWordPosition="5200" endWordPosition="5201">function F(Q, W), which depends on the edge weights W. In this manner, Q* is optimal if: F(Q*, W) &gt; F(Q, W), VQ (5) A partitioning Q is directly obtained from the weighted labeling H assigning to each variable the label with maximum probability. The supports and the weighted labeling depend on the edge weights (Equation (2)). To satisfy Equation (6) is equivalent to satisfying Equation (5). Many studies have been done towards the demonstration of the consistency, convergence, and cost reduction advantages of the relaxation algorithm (Rosenfeld, Hummel, and Zucker 1976; Hummel and Zucker 1983; Pelillo 1997). For instance, Hummel and Zucker (1983) prove that maximizing average consistency (left-hand-side term of Equation (6) produces labelings satisfying Equation (5) when only binary constraints are used. Although there is no formal proof for higher order constraints, the presented algorithm (that forces a stop after a number of iterations) has proven useful for practical purposes in our case. Li h*i Li hil x Sil Vh, Vi (6) l=1 l x Sil &gt; l=1 Note that because the weight update for each label is independent of the others, the algorithm can be straightforward parallelized. In the following, there a</context>
</contexts>
<marker>Pelillo, 1997</marker>
<rawString>Pelillo, M. 1997. The dynamics of nonlinear relaxation labeling processes. Journal of Mathematical Imaging and Vision, 7(4):309–323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Peral</author>
<author>M Palomar</author>
<author>A Ferr´andez</author>
</authors>
<title>Coreference-oriented interlingual slot structure &amp; machine translation.</title>
<date>1999</date>
<booktitle>In Proceedings of the Workshop on Coreference and its Applications,</booktitle>
<pages>69--76</pages>
<location>Stroudsburg, PA.</location>
<marker>Peral, Palomar, Ferr´andez, 1999</marker>
<rawString>Peral, J., M. Palomar, and A. Ferr´andez. 1999. Coreference-oriented interlingual slot structure &amp; machine translation. In Proceedings of the Workshop on Coreference and its Applications, pages 69–76, Stroudsburg, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S P Ponzetto</author>
<author>M Strube</author>
</authors>
<title>Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational</booktitle>
<contexts>
<context position="14071" citStr="Ponzetto and Strube (2006)" startWordPosition="2106" endWordPosition="2109">der to use the most typical mention-pair features. Furthermore, such an approach should overcome the weaknesses of previous state-of-the-art approaches, such as linking contradictions, classifications without context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culo</context>
<context position="75973" citStr="Ponzetto and Strube 2006" startWordPosition="12094" endWordPosition="12097">quez, Recasens, and Sapena (2012), Stoyanov et al. (2009), and Pradhan et al. (2007), these results can be roughly generalized to any other system using similar information, and even other languages. Therefore, these classes require attention in order to improve global performance, and the fact that lexical, morphological, syntactic, and semantic levels are not very useful to deal with them encourages the research on adding world knowledge to coreference resolution systems. In stateof-the-art systems, we can find some attempts to add world knowledge to coreference resolution, using Wikipedia (Ponzetto and Strube 2006; Uryupina et al. 2011) or YAGO and Freenet (Rahman and Ng 2011a). Table 8 Description of the mention classes for English documents. Class Description PN E NPs headed by a Proper Name that Exactly match (excluding case and the determiner) at least one preceding mention in the same coreference chain. PN P NPs headed by a Proper Name that Partially match (i.e., head match or overlap, excluding case) at least one preceding mention in the same coreference chain. PN N NPs headed by a Proper Name that do Not match any preceding mention in the same coreference chain. CN E Same definitions as in PN E,</context>
<context position="83710" citStr="Ponzetto and Strube 2006" startWordPosition="13353" endWordPosition="13356">onfidence value associated with each expression—the most repeated expressions are the most reliable. In order to avoid incorrect information as much as possible, we define a threshold below which all the extracted names and properties are discarded. 6.2 Incorporating World Knowledge to the Models Two approaches for the incorporation of the knowledge extracted from Wikipedia have been studied. The first is to add some feature functions for the mention-pair model that evaluate whether a pair of mentions may corefer according to Wikipedia’s information, similar to other state-of-the-art studies (Ponzetto and Strube 2006; Rahman and Ng 2011a). The second approach adds a set of constraints to the hypergraph connecting groups of mentions, using the entity-mention model. 6.2.1 Feature Functions. In this approach, new feature functions are added to evaluate pairs of mentions, and some learned constraints may use them as any other feature function. These feature functions are only applied to pairs &lt; MI, X &gt;, where MI is a MI mention and X is any other mention but a pronoun, and use the information extracted from Wikipedia to determine their value. Concretely, the feature functions used in our experiments are the f</context>
<context position="94507" citStr="Ponzetto and Strube 2006" startWordPosition="15136" endWordPosition="15139">, the process required to introduce such information in a constructive way has not yet been found. In this work, we tested a methodology that identified the real-world entities referred to in a document, extracted information about them from Wikipedia, and then incorporated this information in two different ways in the model. It seems that neither of the two forms work very well, however, and that the results and errors are in the same direction: The slight improvement of the few new relationships is offset by the added noise. Other state-of-the-art systems have better improvements than ours (Ponzetto and Strube 2006; Uryupina et al. 2011; Rahman and Ng 2011a), but these also seem too modest given the large amount of information used and the room for improvement outlined in the Introduction. The problem seems to lie with the extracted information rather than the model used to incorporate it. The extracted information is biased in favor of the more famous and popular entities (those in Wikipedia, and having larger entries). This causes the system to find more information about these entities, including false positives, and causes an imbalance against entities with little or no information in Wikipedia. Mor</context>
</contexts>
<marker>Ponzetto, Strube, 2006</marker>
<rawString>Ponzetto, S. P. and M. Strube. 2006. Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational</rawString>
</citation>
<citation valid="true">
<authors>
<author>Padr´o Sapena</author>
</authors>
<title>and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution Linguistics (NAACL</title>
<date>2006</date>
<pages>192--199</pages>
<location>New York, NY.</location>
<marker>Sapena, 2006</marker>
<rawString>Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution Linguistics (NAACL 2006), pages 192–199, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Poon</author>
<author>P Domingos</author>
</authors>
<title>Joint unsupervised coreference resolution with Markov Logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>650--659</pages>
<location>Waikiki, HI.</location>
<contexts>
<context position="14871" citStr="Poon and Domingos (2008)" startWordPosition="2234" endWordPosition="2237">Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfaction that represents the problem in a hypergraph and solves it by relaxation labeling, reducing coreference resolution to a hypergraph partitioning problem with a given set of constraints. The main strengths of this system are: • Modeling the problem in terms of hypergraph partitioning avoids linking contradictions and errors caused by a</context>
</contexts>
<marker>Poon, Domingos, 2008</marker>
<rawString>Poon, H. and P. Domingos. 2008. Joint unsupervised coreference resolution with Markov Logic. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2008), pages 650–659, Waikiki, HI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Popescu</author>
<author>O Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP</booktitle>
<pages>339--346</pages>
<location>Vancouver.</location>
<contexts>
<context position="26470" citStr="Popescu and Etzioni 2005" startWordPosition="4126" endWordPosition="4129">Relaxation is a generic name for a family of iterative algorithms that perform function optimization based on local information. They are closely related to neural nets and gradient steps. Relaxation labeling has been successfully used in engineering fields to solve systems of equations, in Artificial Intelligence for computer vision (Rosenfeld, Hummel, and Zucker 1976), and in many other AI problems. The algorithm has also been widely used to solve NLP problems such as part-of-speech tagging (Padr´o 1998), chunking, knowledge integration, semantic parsing (Atserias 2006), and opinion mining (Popescu and Etzioni 2005). Description Conditions Action Default influence rule for a (0)A (1)A mention-pair constraint (positive weight) Default influence rule for a (0)A (1)B mention-pair constraint (negative weight) Example of an influence rule for an (0,2)A, (1)B (3)B entity-mention constraint Figure 11 Default influence rules for mention-pair constraints. 856 Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution Figure 12 Representation of Relax solving a graph. The vertices representing mentions are connected by weighted edges eif. Each vertex has a vector hi of probabilities </context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Popescu, A. M. and O. Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP 2005), pages 339–346, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>A Moschitti</author>
<author>N Xue</author>
<author>O Uryupina</author>
<author>Y Zhang</author>
</authors>
<title>CoNLL-2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference on Computational Natural Language Learning (CoNLL</booktitle>
<pages>1--40</pages>
<location>Jeju Island.</location>
<contexts>
<context position="12527" citStr="Pradhan et al. 2012" startWordPosition="1881" endWordPosition="1884">nk). • Two-step approaches perform the resolution in two separate steps. The first step is to classify all of the elements, and then the second step is a linking process using algorithms such as graph partitioning or clustering to optimize the results given the classification output. • One-step approaches directly run the linking process while classification is performed on-line. In this manner, mention-group and entity-mention models can be easily incorporated. Figure 5 summarizes the classification of several systems in the state of the art, up to 2011. Recently, the CoNLL-2012 shared task (Pradhan et al. 2012) offered an evaluation framework similar to that of CoNLL-2011. The second column specifies which resolution step is used. The third column shows the classification model used by the system, and the fourth column identifies the algorithm followed in the linking process. More details about supervised machine learning systems can be found in Ng (2010). 3. A Constraint-Based Hypergraph Partitioning Approach to Coreference Resolution One of the possible directions to follow in coreference resolution research is the incorporation of new information such as world knowledge and discourse coherence. I</context>
</contexts>
<marker>Pradhan, Moschitti, Xue, Uryupina, Zhang, 2012</marker>
<rawString>Pradhan, S., A. Moschitti, N. Xue, O. Uryupina, and Y. Zhang. 2012. CoNLL-2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes. In Proceedings of the Conference on Computational Natural Language Learning (CoNLL 2012), pages 1–40, Jeju Island.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>L Ramshaw</author>
<author>M Marcus</author>
<author>M Palmer</author>
<author>R Weischedel</author>
<author>N Xue</author>
</authors>
<title>CoNLL-2011 shared task: Modeling unrestricted coreference in OntoNotes.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Computational Natural Language Learning (CoNLL</booktitle>
<pages>1--27</pages>
<location>Portland, OR.</location>
<contexts>
<context position="58737" citStr="Pradhan et al. 2011" startWordPosition="9360" endWordPosition="9363"> the state of the art in diverse corpora, measures, and languages. Next, our participation in Semeval-2010 and CoNLL-2011 shared tasks is explained in detail with performance, comparisons, and error analysis. Finally, a set of experiments using the entity-mention model are described. The framework used in our experiments consists of widely used corpora and measures to facilitate replication and comparison. Corpora used are ACE 2002 (NIST 2003), the same portion of OntoNotes v2.0 used in Semeval-2010 (Recasens et al. 2010), and the same portion of OntoNotes v4.0 used in CoNLL Shared Task 2011 (Pradhan et al. 2011). Regarding the measures, we used MUC (Vilain et al. 1995), B3 (Bagga and Baldwin 1998), and two variants of CEAF (Luo 2005): mention-based (CEAFm) and entity-based (CEAFe). 5.1 Mention Detection The performance of the mention detection system achieves a good recall, higher than 90%, but a low precision, as published in Sapena, Padr´o, and Turmo (2011) and reproduced in Table 1. The OntoNotes corpora have been used for this experiment, as they were used in CoNLL-2011. Given that the mention detection in a pipeline combination acts as a filter, recall should be kept high, as a loss of recall at</context>
<context position="66423" citStr="Pradhan et al. 2011" startWordPosition="10581" endWordPosition="10584">-open and English-closed tasks. The scores were slightly higher when using WordNet, but not significantly so (75.8% vs. 75.6% for CEAF and 34.2% vs. 33.7% for MUC). Analyzing the MUC scores, note that the recall improves (from 21.9% to 22.6%), while the precision decreases a little (from 74.4% to 70.5%), which corresponds to the information and noise that WordNet typically provides. More recent results of RELAXCOR on the same corpora are published in M`arquez, Recasens, and Sapena (2012). 5.2.2 CoNLL-2011. The CoNLL-2011 Shared Task was based on the English portion of the OntoNotes 4.0 data5 (Pradhan et al. 2011). As is customary for CoNLL tasks, there was a closed and an open track. For the closed track, systems were limited to using the distributed resources, in order to allow a fair comparison of algorithm performance, whereas the open track allowed for almost unrestricted use of external resources in addition to the provided data. About 65 different groups demonstrated interest in the shared task by registering on the task Web page. Of these, 23 groups submitted system outputs on the test set during the evaluation week. Eighteen groups submitted only closed track results, three groups only open tr</context>
</contexts>
<marker>Pradhan, Ramshaw, Marcus, Palmer, Weischedel, Xue, 2011</marker>
<rawString>Pradhan, S., L. Ramshaw, M. Marcus, M. Palmer, R. Weischedel, and N. Xue. 2011. CoNLL-2011 shared task: Modeling unrestricted coreference in OntoNotes. In Proceedings of the Conference on Computational Natural Language Learning (CoNLL 2011), pages 1–27, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S S Pradhan</author>
<author>L Ramshaw</author>
<author>R Weischedel</author>
<author>J MacBride</author>
<author>L Micciulla</author>
</authors>
<title>Unrestricted coreference: Identifying entities and events in OntoNotes.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Semantic Computing (ICSC</booktitle>
<pages>446--453</pages>
<contexts>
<context position="75433" citStr="Pradhan et al. (2007)" startWordPosition="12014" endWordPosition="12017">ed for the English task in SemEval-2010) are shown in Table 9 for each mention class described in Table 8. Analyzing the table, we observe that PN N, CN P, and CN N are the classes with the lowest recall, especially PN N and CN N. In addition, PN N and CN N have the lowest precision. The final column shows the number of mentions corresponding to the class of that row and the percentage representing the total number of coreferent mentions. Note that these three classes together represent 27% of coreferent mentions. According to M`arquez, Recasens, and Sapena (2012), Stoyanov et al. (2009), and Pradhan et al. (2007), these results can be roughly generalized to any other system using similar information, and even other languages. Therefore, these classes require attention in order to improve global performance, and the fact that lexical, morphological, syntactic, and semantic levels are not very useful to deal with them encourages the research on adding world knowledge to coreference resolution systems. In stateof-the-art systems, we can find some attempts to add world knowledge to coreference resolution, using Wikipedia (Ponzetto and Strube 2006; Uryupina et al. 2011) or YAGO and Freenet (Rahman and Ng 2</context>
</contexts>
<marker>Pradhan, Ramshaw, Weischedel, MacBride, Micciulla, 2007</marker>
<rawString>Pradhan, S. S., L. Ramshaw, R. Weischedel, J. MacBride, and L. Micciulla. 2007. Unrestricted coreference: Identifying entities and events in OntoNotes. In Proceedings of the International Conference on Semantic Computing (ICSC 2007), pages 446–453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="45337" citStr="Quinlan 1993" startWordPosition="7230" endWordPosition="7231">tive examples as the centroids. We define the distance between two examples as the number of features with different values. A negative example is then discarded if the distance to all the positive examples is always greater than a threshold, D. The value of D is empirically chosen depending on the corpora and the computational resources available. Figure 17 RELAXCOR development process. 863 Computational Linguistics Volume 39, Number 4 4.3.2 Learning Constraints. Constraints are automatically generated by learning a decision tree and then extracting rules from its leaves using C4.5 software (Quinlan 1993). The algorithm generates a set of rules for each path from the learned tree, then checks whether the rules can be generalized by dropping conditions. These rules become our set of constraints. Other studies have successfully used similar processes to extract rules from a decision tree that are useful in constraint satisfaction algorithms (M`arquez, Padr´o, and Rodr´ıguez 2000). The weight assigned to a constraint (λk) is its precision over the training data (Pk), but shifted by a balance value: λk = Pk − balance (11) The precision here refers to the positive class, that is, the ratio between </context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>Quinlan, J. R. 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rahman</author>
<author>V Ng</author>
</authors>
<title>Coreference resolution with world knowledge.</title>
<date>2011</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2011),</booktitle>
<pages>814--824</pages>
<location>Portland, OR.</location>
<contexts>
<context position="14331" citStr="Rahman and Ng (2011" startWordPosition="2152" endWordPosition="2155">Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning globa</context>
<context position="76036" citStr="Rahman and Ng 2011" startWordPosition="12106" endWordPosition="12109">n et al. (2007), these results can be roughly generalized to any other system using similar information, and even other languages. Therefore, these classes require attention in order to improve global performance, and the fact that lexical, morphological, syntactic, and semantic levels are not very useful to deal with them encourages the research on adding world knowledge to coreference resolution systems. In stateof-the-art systems, we can find some attempts to add world knowledge to coreference resolution, using Wikipedia (Ponzetto and Strube 2006; Uryupina et al. 2011) or YAGO and Freenet (Rahman and Ng 2011a). Table 8 Description of the mention classes for English documents. Class Description PN E NPs headed by a Proper Name that Exactly match (excluding case and the determiner) at least one preceding mention in the same coreference chain. PN P NPs headed by a Proper Name that Partially match (i.e., head match or overlap, excluding case) at least one preceding mention in the same coreference chain. PN N NPs headed by a Proper Name that do Not match any preceding mention in the same coreference chain. CN E Same definitions as in PN E, PN P, and PN N, CN P but referring to NPs headed by a Common N</context>
<context position="83730" citStr="Rahman and Ng 2011" startWordPosition="13357" endWordPosition="13360"> with each expression—the most repeated expressions are the most reliable. In order to avoid incorrect information as much as possible, we define a threshold below which all the extracted names and properties are discarded. 6.2 Incorporating World Knowledge to the Models Two approaches for the incorporation of the knowledge extracted from Wikipedia have been studied. The first is to add some feature functions for the mention-pair model that evaluate whether a pair of mentions may corefer according to Wikipedia’s information, similar to other state-of-the-art studies (Ponzetto and Strube 2006; Rahman and Ng 2011a). The second approach adds a set of constraints to the hypergraph connecting groups of mentions, using the entity-mention model. 6.2.1 Feature Functions. In this approach, new feature functions are added to evaluate pairs of mentions, and some learned constraints may use them as any other feature function. These feature functions are only applied to pairs &lt; MI, X &gt;, where MI is a MI mention and X is any other mention but a pronoun, and use the information extracted from Wikipedia to determine their value. Concretely, the feature functions used in our experiments are the following ones: • WIK</context>
<context position="94549" citStr="Rahman and Ng 2011" startWordPosition="15144" endWordPosition="15147">tion in a constructive way has not yet been found. In this work, we tested a methodology that identified the real-world entities referred to in a document, extracted information about them from Wikipedia, and then incorporated this information in two different ways in the model. It seems that neither of the two forms work very well, however, and that the results and errors are in the same direction: The slight improvement of the few new relationships is offset by the added noise. Other state-of-the-art systems have better improvements than ours (Ponzetto and Strube 2006; Uryupina et al. 2011; Rahman and Ng 2011a), but these also seem too modest given the large amount of information used and the room for improvement outlined in the Introduction. The problem seems to lie with the extracted information rather than the model used to incorporate it. The extracted information is biased in favor of the more famous and popular entities (those in Wikipedia, and having larger entries). This causes the system to find more information about these entities, including false positives, and causes an imbalance against entities with little or no information in Wikipedia. Moreover, it is not possible to use negative </context>
</contexts>
<marker>Rahman, Ng, 2011</marker>
<rawString>Rahman, A. and V. Ng. 2011a. Coreference resolution with world knowledge. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2011), pages 814–824, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rahman</author>
<author>V Ng</author>
</authors>
<title>Narrowing the modeling gap: A cluster-ranking approach to coreference resolution.</title>
<date>2011</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>40</volume>
<issue>1</issue>
<contexts>
<context position="14331" citStr="Rahman and Ng (2011" startWordPosition="2152" endWordPosition="2155">Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning globa</context>
<context position="76036" citStr="Rahman and Ng 2011" startWordPosition="12106" endWordPosition="12109">n et al. (2007), these results can be roughly generalized to any other system using similar information, and even other languages. Therefore, these classes require attention in order to improve global performance, and the fact that lexical, morphological, syntactic, and semantic levels are not very useful to deal with them encourages the research on adding world knowledge to coreference resolution systems. In stateof-the-art systems, we can find some attempts to add world knowledge to coreference resolution, using Wikipedia (Ponzetto and Strube 2006; Uryupina et al. 2011) or YAGO and Freenet (Rahman and Ng 2011a). Table 8 Description of the mention classes for English documents. Class Description PN E NPs headed by a Proper Name that Exactly match (excluding case and the determiner) at least one preceding mention in the same coreference chain. PN P NPs headed by a Proper Name that Partially match (i.e., head match or overlap, excluding case) at least one preceding mention in the same coreference chain. PN N NPs headed by a Proper Name that do Not match any preceding mention in the same coreference chain. CN E Same definitions as in PN E, PN P, and PN N, CN P but referring to NPs headed by a Common N</context>
<context position="83730" citStr="Rahman and Ng 2011" startWordPosition="13357" endWordPosition="13360"> with each expression—the most repeated expressions are the most reliable. In order to avoid incorrect information as much as possible, we define a threshold below which all the extracted names and properties are discarded. 6.2 Incorporating World Knowledge to the Models Two approaches for the incorporation of the knowledge extracted from Wikipedia have been studied. The first is to add some feature functions for the mention-pair model that evaluate whether a pair of mentions may corefer according to Wikipedia’s information, similar to other state-of-the-art studies (Ponzetto and Strube 2006; Rahman and Ng 2011a). The second approach adds a set of constraints to the hypergraph connecting groups of mentions, using the entity-mention model. 6.2.1 Feature Functions. In this approach, new feature functions are added to evaluate pairs of mentions, and some learned constraints may use them as any other feature function. These feature functions are only applied to pairs &lt; MI, X &gt;, where MI is a MI mention and X is any other mention but a pronoun, and use the information extracted from Wikipedia to determine their value. Concretely, the feature functions used in our experiments are the following ones: • WIK</context>
<context position="94549" citStr="Rahman and Ng 2011" startWordPosition="15144" endWordPosition="15147">tion in a constructive way has not yet been found. In this work, we tested a methodology that identified the real-world entities referred to in a document, extracted information about them from Wikipedia, and then incorporated this information in two different ways in the model. It seems that neither of the two forms work very well, however, and that the results and errors are in the same direction: The slight improvement of the few new relationships is offset by the added noise. Other state-of-the-art systems have better improvements than ours (Ponzetto and Strube 2006; Uryupina et al. 2011; Rahman and Ng 2011a), but these also seem too modest given the large amount of information used and the room for improvement outlined in the Introduction. The problem seems to lie with the extracted information rather than the model used to incorporate it. The extracted information is biased in favor of the more famous and popular entities (those in Wikipedia, and having larger entries). This causes the system to find more information about these entities, including false positives, and causes an imbalance against entities with little or no information in Wikipedia. Moreover, it is not possible to use negative </context>
</contexts>
<marker>Rahman, Ng, 2011</marker>
<rawString>Rahman, A. and V. Ng. 2011b. Narrowing the modeling gap: A cluster-ranking approach to coreference resolution. Journal of Artificial Intelligence Research, 40(1):469–521.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Recasens</author>
<author>L M`arquez</author>
<author>E Sapena</author>
<author>M A Marti</author>
<author>M Taul´e</author>
<author>V Hoste</author>
<author>M Poesio</author>
<author>Y Versley</author>
</authors>
<title>SemEval-2010 Task 1: Coreference resolution in multiple languages.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<pages>1--8</pages>
<location>Uppsala.</location>
<marker>Recasens, M`arquez, Sapena, Marti, Taul´e, Hoste, Poesio, Versley, 2010</marker>
<rawString>Recasens, M., L. M`arquez, E. Sapena, M. A. Marti, M. Taul´e, V. Hoste, M. Poesio, and Y. Versley. 2010. SemEval-2010 Task 1: Coreference resolution in multiple languages. In Proceedings of the International Workshop on Semantic Evaluations (SemEval-2010), pages 1–8, Uppsala.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rosenfeld</author>
<author>R A Hummel</author>
<author>S W Zucker</author>
</authors>
<title>Scene labelling by relaxation operations.</title>
<date>1976</date>
<journal>IEEE Transactions on Systems, Man and Cybernetics,</journal>
<volume>6</volume>
<issue>6</issue>
<marker>Rosenfeld, Hummel, Zucker, 1976</marker>
<rawString>Rosenfeld, R., R. A. Hummel, and S. W. Zucker. 1976. Scene labelling by relaxation operations. IEEE Transactions on Systems, Man and Cybernetics, 6(6):420–433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Rounds</author>
</authors>
<title>A combined nonparametric approach to feature selection and binary decision tree design.</title>
<date>1980</date>
<journal>Pattern Recognition,</journal>
<volume>12</volume>
<issue>5</issue>
<contexts>
<context position="39097" citStr="Rounds 1980" startWordPosition="6248" endWordPosition="6249">al, syntactic, morphological, and semantic. Moreover, some structural features of the discourse have also been used, such as distances, quotes, and sentential positions. A feature function with only one argument indicates that it offers information about only one mention. For example, REFLEXIVE(0) indicates that mention 0 is a reflexive pronoun. Figure 15 shows an exhaustive list of the features used and a brief description of each one. We use decision trees for constraint acquisition (see Section 4.3.2). Because the use of binary features favors a better performance in this type of learning (Rounds 1980; Safavian and Landgrebe 1991), all of the used feature functions are binary. The original sources that had a list of possible values have been binarized by a set of feature functions that each represent a different value. Even in numerical cases, there is a set of binary features representing the most important specific values, and the rest are placed in ranges. 861 Computational Linguistics Volume 39, Number 4 Distance and position Distance between X and Y in sentences: DIST SEN 0(X,Y): same sentence, DIST SEN 1(X,Y): consecutive sentences DIST SEN L3(X,Y): less than 3 sentences Distance bet</context>
</contexts>
<marker>Rounds, 1980</marker>
<rawString>Rounds, E. M. 1980. A combined nonparametric approach to feature selection and binary decision tree design. Pattern Recognition, 12(5):313–317.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S R Safavian</author>
<author>D Landgrebe 1991</author>
</authors>
<title>A survey of decision tree classifier methodology.</title>
<journal>IEEE Transactions on Systems, Man and Cybernetics,</journal>
<volume>21</volume>
<issue>3</issue>
<marker>Safavian, 1991, </marker>
<rawString>Safavian, S. R. and D. Landgrebe.1991. A survey of decision tree classifier methodology. IEEE Transactions on Systems, Man and Cybernetics, 21(3):660–674.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sapena</author>
</authors>
<title>A Constraint-Based Hypergraph Partitioning Approach to Coreference Resolution.</title>
<date>2012</date>
<tech>Ph.D. thesis,</tech>
<institution>Universitat Politecnica de Catalunya.</institution>
<contexts>
<context position="62751" citStr="Sapena (2012)" startWordPosition="10002" endWordPosition="10003"> on development data (SemEval-2010). – CEAF MUC B3 language R P F1 R P F1 R P F1 ca 69.7 69.7 69.7 27.4 77.9 40.6 67.9 96.1 79.6 es 70.8 70.8 70.8 30.3 76.2 43.4 68.9 95.0 79.8 en-closed 74.8 74.8 74.8 21.4 67.8 32.6 74.1 96.0 83.7 en-open 75.0 75.0 75.0 22.0 66.6 33.0 74.2 95.9 83.7 winner. In addition, RELAXCOR achieved second position in the CoNLL-2011 Shared Task; Figure 20 reproduces the official table of results. Following sections describe the shared tasks in detail. Finally, the performance of RELAXCOR is again compared with two other state-ofthe-art systems in M`arquez, Recasens, and Sapena (2012). 5.2.1 SemEval-2010. The goal of SemEval-2010 task 1 (Recasens et al. 2010) was to evaluate and compare automatic coreference resolution systems for six different languages in four evaluation settings and using four different evaluation measures. This complex scenario aimed at providing insight into several aspects of coreference resolution, including portability across languages, relevance of linguistic information at different levels, and behavior of alternative scoring measures. The task attracted considerable attention from a number of researchers, but only six teams submitted results. Mo</context>
<context position="66295" citStr="Sapena (2012)" startWordPosition="10562" endWordPosition="10563">incorporation of WordNet to the English run of RELAXCOR was the only difference between our implementation in the English-open and English-closed tasks. The scores were slightly higher when using WordNet, but not significantly so (75.8% vs. 75.6% for CEAF and 34.2% vs. 33.7% for MUC). Analyzing the MUC scores, note that the recall improves (from 21.9% to 22.6%), while the precision decreases a little (from 74.4% to 70.5%), which corresponds to the information and noise that WordNet typically provides. More recent results of RELAXCOR on the same corpora are published in M`arquez, Recasens, and Sapena (2012). 5.2.2 CoNLL-2011. The CoNLL-2011 Shared Task was based on the English portion of the OntoNotes 4.0 data5 (Pradhan et al. 2011). As is customary for CoNLL tasks, there was a closed and an open track. For the closed track, systems were limited to using the distributed resources, in order to allow a fair comparison of algorithm performance, whereas the open track allowed for almost unrestricted use of external resources in addition to the provided data. About 65 different groups demonstrated interest in the shared task by registering on the task Web page. Of these, 23 groups submitted system ou</context>
<context position="70340" citStr="Sapena (2012)" startWordPosition="11198" endWordPosition="11199">ombines many heuristics to join mentions and partial entities, starting with the most precise ones. It is thought that the difference between RELAXCOR and Stanford’s system is mainly due to their use of sophisticated handwritten heuristics instead of our automatically learned constraints. Note that Lee et al. (2011) solve coreferences by applying first the most precise constraints. RELAXCOR also solves first the most precise constraints given that these ones have the highest weights and are the most influencing ones. 5.3 Languages Sapena, Padr´o, and Turmo (2010b), and M`arquez, Recasens, and Sapena (2012) show the performance of our approach for English, Catalan, and Spanish. The scores for Spanish and Catalan do not seem as good as for English, because the system was originally designed with the English language in mind. As a result, it does not include languagespecific features for Spanish and Catalan, such as whether a mention is an elliptical subject or not. Despite this, RELAXCOR scores for Catalan and Spanish are the best among the state of the art. 872 Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution Table 7 Comparison of RELAXCOR results using j</context>
<context position="75382" citStr="Sapena (2012)" startWordPosition="12007" endWordPosition="12008"> set of OntoNotes 2.0 (the same data set used for the English task in SemEval-2010) are shown in Table 9 for each mention class described in Table 8. Analyzing the table, we observe that PN N, CN P, and CN N are the classes with the lowest recall, especially PN N and CN N. In addition, PN N and CN N have the lowest precision. The final column shows the number of mentions corresponding to the class of that row and the percentage representing the total number of coreferent mentions. Note that these three classes together represent 27% of coreferent mentions. According to M`arquez, Recasens, and Sapena (2012), Stoyanov et al. (2009), and Pradhan et al. (2007), these results can be roughly generalized to any other system using similar information, and even other languages. Therefore, these classes require attention in order to improve global performance, and the fact that lexical, morphological, syntactic, and semantic levels are not very useful to deal with them encourages the research on adding world knowledge to coreference resolution systems. In stateof-the-art systems, we can find some attempts to add world knowledge to coreference resolution, using Wikipedia (Ponzetto and Strube 2006; Uryupin</context>
<context position="92364" citStr="Sapena (2012)" startWordPosition="14812" endWordPosition="14813">r, the recall of ungendered pronouns has decreased considerably. Finally, it is interesting to remark that these improvements are achieved thanks to a reduced number of mentions in test documents that end up having an actual Wikipediainfluenced constraint (e.g., fewer than 1% of the mentions in features model). Thus, better extraction procedures or a knowledge source more suitable for entities appearing in the target documents should yield larger improvements. 879 Computational Linguistics Volume 39, Number 4 More details on the extraction process and a detailed error analysis can be found in Sapena (2012). The error analysis shows how the extracted knowledge was often redundant (i.e., used only in cases where the algorithm already produced the right answer) or noisy (due to errors in the entity disambiguation or information extraction steps). Thus, we think that the experiments show that RELAXCOR is able to incorporate world knowledge into the resolution model in an easy and natural way, and that further work is required on acquiring more accurate and useful knowledge to feed the coreference resolution process. 7. Conclusions In this work, we defined an approach based on constraint satisfactio</context>
</contexts>
<marker>Sapena, 2012</marker>
<rawString>Sapena, E. 2012. A Constraint-Based Hypergraph Partitioning Approach to Coreference Resolution. Ph.D. thesis, Universitat Politecnica de Catalunya.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sapena</author>
<author>L Padr´o</author>
<author>J Turmo</author>
</authors>
<title>A global relaxation labeling approach to coreference resolution.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING 2010),</booktitle>
<pages>1--086</pages>
<location>Beijing.</location>
<marker>Sapena, Padr´o, Turmo, 2010</marker>
<rawString>Sapena, E., L. Padr´o, and J. Turmo. 2010a. A global relaxation labeling approach to coreference resolution. In Proceedings of the International Conference on Computational Linguistics (COLING 2010), pages 1,086–1,094, Beijing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sapena</author>
<author>L Padr´o</author>
<author>J Turmo</author>
</authors>
<title>RelaxCor: A global relaxation labeling approach to coreference resolution.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<pages>88--91</pages>
<location>Uppsala.</location>
<marker>Sapena, Padr´o, Turmo, 2010</marker>
<rawString>Sapena, E., L. Padr´o, and J. Turmo. 2010b. RelaxCor: A global relaxation labeling approach to coreference resolution. In Proceedings of the ACL Workshop on Semantic Evaluations (SemEval-2010), pages 88–91, Uppsala.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sapena</author>
<author>L Padr´o</author>
<author>J Turmo</author>
</authors>
<title>RelaxCor participation in CoNLL shared task on coreference resolution.</title>
<date>2011</date>
<marker>Sapena, Padr´o, Turmo, 2011</marker>
<rawString>Sapena, E., L. Padr´o, and J. Turmo. 2011. RelaxCor participation in CoNLL shared task on coreference resolution.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>35--39</pages>
<location>Portland, OR.</location>
<marker></marker>
<rawString>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task, pages 35–39, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W M Soon</author>
<author>H T Ng</author>
<author>D C Y Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Soon, W. M., H. T. Ng, and D. C. Y. Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Stoyanov</author>
<author>N Gilbert</author>
<author>C Cardie</author>
<author>E Riloff</author>
</authors>
<title>Conundrums in noun phrase coreference resolution: Making sense of the state-of-the-art.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the Annual Meeting of the ACL and the International Joint Conference on Natural Language Processing (ACL-IJCNLP</booktitle>
<pages>656--664</pages>
<contexts>
<context position="14220" citStr="Stoyanov et al. (2009)" startWordPosition="2132" endWordPosition="2135">such as linking contradictions, classifications without context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005)</context>
<context position="75406" citStr="Stoyanov et al. (2009)" startWordPosition="12009" endWordPosition="12012">es 2.0 (the same data set used for the English task in SemEval-2010) are shown in Table 9 for each mention class described in Table 8. Analyzing the table, we observe that PN N, CN P, and CN N are the classes with the lowest recall, especially PN N and CN N. In addition, PN N and CN N have the lowest precision. The final column shows the number of mentions corresponding to the class of that row and the percentage representing the total number of coreferent mentions. Note that these three classes together represent 27% of coreferent mentions. According to M`arquez, Recasens, and Sapena (2012), Stoyanov et al. (2009), and Pradhan et al. (2007), these results can be roughly generalized to any other system using similar information, and even other languages. Therefore, these classes require attention in order to improve global performance, and the fact that lexical, morphological, syntactic, and semantic levels are not very useful to deal with them encourages the research on adding world knowledge to coreference resolution systems. In stateof-the-art systems, we can find some attempts to add world knowledge to coreference resolution, using Wikipedia (Ponzetto and Strube 2006; Uryupina et al. 2011) or YAGO a</context>
</contexts>
<marker>Stoyanov, Gilbert, Cardie, Riloff, 2009</marker>
<rawString>Stoyanov, V., N. Gilbert, C. Cardie, and E. Riloff. 2009. Conundrums in noun phrase coreference resolution: Making sense of the state-of-the-art. In Proceedings of the Joint Conference of the Annual Meeting of the ACL and the International Joint Conference on Natural Language Processing (ACL-IJCNLP 2009), pages 656–664, Suntec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Torras</author>
</authors>
<title>Relaxation and neural learning: Points of convergence and divergence.</title>
<date>1989</date>
<journal>Journal of Parallel and Distributed Computing,</journal>
<pages>6--217</pages>
<contexts>
<context position="31560" citStr="Torras 1989" startWordPosition="4992" endWordPosition="4993">) according to the update function: hil(t + 1) = hiLi l(t) x (1 + Sil) (3) Ek=1 hik(t) x (1 + Sik) Initialize: H := H0, Main loop: Repeat For each variable vi For each possible label l for vi Sil = Ee∈E(vi) Inf(e) End for Normalize supports between -1 and 1 For each possible label l for vi hi (t) × (1+Sil) hl&apos;( &apos; t + 1) = ELi k=1 hik(t)×(1+Sik) End for End for Until no more significant changes Figure 13 Relaxation labeling algorithm. 858 Sapena, Padr´o, and Turmo Constraint-Based Hypergraph Partitioning Coreference Resolution There are many functions that can be used to calculate the support (Torras 1989). The one we chose was also used by Padr´o (1998) and M`arquez, Padr´o, and Rodr´ıguez (2000). 5. Iterate the process until the convergence criterion is met. The usual criterion is to wait for no more changes in an iteration, or a maximum change below some epsilon parameter (Equation (4)). But there is also a maximum number of iterations where the process is stopped. This number is a constant and does not depend on the size of the document. max(hil(t + 1) − hil(t)) &lt; |e |Vi,l (4) Each combination of labels for the graph vertices is a partitioning (Q). The resolution process searches the partit</context>
</contexts>
<marker>Torras, 1989</marker>
<rawString>Torras, C. 1989. Relaxation and neural learning: Points of convergence and divergence. Journal of Parallel and Distributed Computing, 6:217–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Uryupina</author>
</authors>
<title>Detecting anaphoricity and antecedenthood for coreference resolution. Procesamiento del Lenguaje Natural,</title>
<date>2009</date>
<pages>113--120</pages>
<contexts>
<context position="14246" citStr="Uryupina (2009)" startWordPosition="2138" endWordPosition="2139">lassifications without context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007)</context>
</contexts>
<marker>Uryupina, 2009</marker>
<rawString>Uryupina, O. 2009. Detecting anaphoricity and antecedenthood for coreference resolution. Procesamiento del Lenguaje Natural, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Uryupina</author>
<author>M Poesio</author>
<author>C Giuliano</author>
<author>K Tymoshenko</author>
</authors>
<title>Disambiguation and filtering methods in using Web knowledge for coreference resolution.</title>
<date>2011</date>
<booktitle>In Proceedings of Computational Linguistics Volume 39, Number 4 the International Florida Artificial Intelligence Research Society Conference,</booktitle>
<pages>317--322</pages>
<location>Palm Beach, FL.</location>
<contexts>
<context position="75996" citStr="Uryupina et al. 2011" startWordPosition="12098" endWordPosition="12101"> (2012), Stoyanov et al. (2009), and Pradhan et al. (2007), these results can be roughly generalized to any other system using similar information, and even other languages. Therefore, these classes require attention in order to improve global performance, and the fact that lexical, morphological, syntactic, and semantic levels are not very useful to deal with them encourages the research on adding world knowledge to coreference resolution systems. In stateof-the-art systems, we can find some attempts to add world knowledge to coreference resolution, using Wikipedia (Ponzetto and Strube 2006; Uryupina et al. 2011) or YAGO and Freenet (Rahman and Ng 2011a). Table 8 Description of the mention classes for English documents. Class Description PN E NPs headed by a Proper Name that Exactly match (excluding case and the determiner) at least one preceding mention in the same coreference chain. PN P NPs headed by a Proper Name that Partially match (i.e., head match or overlap, excluding case) at least one preceding mention in the same coreference chain. PN N NPs headed by a Proper Name that do Not match any preceding mention in the same coreference chain. CN E Same definitions as in PN E, PN P, and PN N, CN P b</context>
<context position="94529" citStr="Uryupina et al. 2011" startWordPosition="15140" endWordPosition="15143">introduce such information in a constructive way has not yet been found. In this work, we tested a methodology that identified the real-world entities referred to in a document, extracted information about them from Wikipedia, and then incorporated this information in two different ways in the model. It seems that neither of the two forms work very well, however, and that the results and errors are in the same direction: The slight improvement of the few new relationships is offset by the added noise. Other state-of-the-art systems have better improvements than ours (Ponzetto and Strube 2006; Uryupina et al. 2011; Rahman and Ng 2011a), but these also seem too modest given the large amount of information used and the room for improvement outlined in the Introduction. The problem seems to lie with the extracted information rather than the model used to incorporate it. The extracted information is biased in favor of the more famous and popular entities (those in Wikipedia, and having larger entries). This causes the system to find more information about these entities, including false positives, and causes an imbalance against entities with little or no information in Wikipedia. Moreover, it is not possi</context>
</contexts>
<marker>Uryupina, Poesio, Giuliano, Tymoshenko, 2011</marker>
<rawString>Uryupina, O., M. Poesio, C. Giuliano, and K. Tymoshenko. 2011. Disambiguation and filtering methods in using Web knowledge for coreference resolution. In Proceedings of Computational Linguistics Volume 39, Number 4 the International Florida Artificial Intelligence Research Society Conference, pages 317–322, Palm Beach, FL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Vilain</author>
<author>J Burger</author>
<author>J Aberdeen</author>
<author>D Connolly</author>
<author>L Hirschman</author>
</authors>
<title>A model-theoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>In Proceedings of the Message Understanding Conference (MUC-6),</booktitle>
<pages>45--52</pages>
<location>Arlington, VA.</location>
<contexts>
<context position="58795" citStr="Vilain et al. 1995" startWordPosition="9370" endWordPosition="9373">guages. Next, our participation in Semeval-2010 and CoNLL-2011 shared tasks is explained in detail with performance, comparisons, and error analysis. Finally, a set of experiments using the entity-mention model are described. The framework used in our experiments consists of widely used corpora and measures to facilitate replication and comparison. Corpora used are ACE 2002 (NIST 2003), the same portion of OntoNotes v2.0 used in Semeval-2010 (Recasens et al. 2010), and the same portion of OntoNotes v4.0 used in CoNLL Shared Task 2011 (Pradhan et al. 2011). Regarding the measures, we used MUC (Vilain et al. 1995), B3 (Bagga and Baldwin 1998), and two variants of CEAF (Luo 2005): mention-based (CEAFm) and entity-based (CEAFe). 5.1 Mention Detection The performance of the mention detection system achieves a good recall, higher than 90%, but a low precision, as published in Sapena, Padr´o, and Turmo (2011) and reproduced in Table 1. The OntoNotes corpora have been used for this experiment, as they were used in CoNLL-2011. Given that the mention detection in a pipeline combination acts as a filter, recall should be kept high, as a loss of recall at the beginning would result in a loss of performance in th</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>Vilain, M., J. Burger, J. Aberdeen, D. Connolly, and L. Hirschman. 1995. A model-theoretic coreference scoring scheme. In Proceedings of the Message Understanding Conference (MUC-6), pages 45–52, Arlington, VA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Yang</author>
<author>J Su</author>
<author>J Lang</author>
<author>C L Tan</author>
<author>T Liu</author>
<author>S Li</author>
</authors>
<title>An entity-mention model for coreference resolution with inductive logic programming.</title>
<date>2008</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>843--851</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="14311" citStr="Yang et al. (2008)" startWordPosition="2148" endWordPosition="2151"> evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering grap</context>
</contexts>
<marker>Yang, Su, Lang, Tan, Liu, Li, 2008</marker>
<rawString>Yang, X., J. Su, J. Lang, C. L. Tan, T. Liu, and S. Li. 2008. An entity-mention model for coreference resolution with inductive logic programming. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2008), pages 843–851, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Yang</author>
<author>J Su</author>
<author>C L Tan</author>
</authors>
<title>Kernel-based pronoun resolution with structured syntactic knowledge.</title>
<date>2006</date>
<booktitle>Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL</booktitle>
<pages>41--48</pages>
<location>Sydney.</location>
<marker>Yang, Su, Tan, 2006</marker>
<rawString>Yang, X., J. Su, and C. L. Tan. 2006. Kernel-based pronoun resolution with structured syntactic knowledge. Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL 2006), pages 41–48, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Yang</author>
<author>J Su</author>
<author>G Zhou</author>
<author>C L Tan</author>
</authors>
<title>An NP-cluster based approach to coreference resolution.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING 2004),</booktitle>
<pages>226--232</pages>
<location>Geneva.</location>
<contexts>
<context position="14792" citStr="Yang et al. (2004)" startWordPosition="2222" endWordPosition="2225">engtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos (2008) hypergraph partitioning clustering graph partitioning global optimization Figure 5 A classification of coreference resolution approaches in state-of-the-art machine-learning systems. Given these prerequisites, we define an approach based on constraint satisfaction that represents the problem in a hypergraph and solves it by relaxation labeling, reducing coreference resolution to a hypergraph partitioning problem with a given set of constraints. The main strengths of this system are: • Modeling the problem in terms </context>
</contexts>
<marker>Yang, Su, Zhou, Tan, 2004</marker>
<rawString>Yang, X., J. Su, G. Zhou, and C. L. Tan. 2004. An NP-cluster based approach to coreference resolution. In Proceedings of the International Conference on Computational Linguistics (COLING 2004), pages 226–232, Geneva.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Yang</author>
<author>G Zhou</author>
<author>J Su</author>
<author>C L Tan</author>
</authors>
<title>Coreference resolution using competition learning approach.</title>
<date>2003</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>176--183</pages>
<location>Sapporo.</location>
<contexts>
<context position="14265" citStr="Yang et al. (2003)" startWordPosition="2140" endWordPosition="2143">ithout context, and a lack of information when evaluating pairs. Also, the approach would be more flexible if it could incorporate knowledge both automatically and manually. 851 Computational Linguistics Volume 39, Number 4 Approach Resolution Classification Model Linking process Aone and Bennett (1995) backward mention pairs heuristic McCarthy and Lehnert (1995) search Soon, Ng, and Lim (2001) Ponzetto and Strube (2006) Yang, Su, and Tan (2006) Ng and Cardie (2002) Ng (2005) Ng (2007) Ji, Westbrook, and Grishman (2005) Bengtson and Roth (2008) Stoyanov et al. (2009) Ng (2009) Uryupina (2009) Yang et al. (2003) Denis and Baldridge (2008) Yang et al. (2008) Rahman and Ng (2011b) Luo et al. (2004) Luo (2007) rankers entitymention global optimization Klenner and Ailloud (2008) two step mention pairs clustering Nicolae and Nicolae (2006) Denis and Baldridge (2007) Klenner (2007) Finkel and Manning (2008) Bean et al. (2004) Cardie and Wagstaff (1999) Ng (2008) graph partitioning global optimization clustering Culotta, Wick, and McCallum (2007) one step entityFinley and Joachims (2005) mention Cai and Strube (2010) Yang et al. (2004) McCallum and Wellner (2005) Haghighi and Klein (2007) Poon and Domingos </context>
</contexts>
<marker>Yang, Zhou, Su, Tan, 2003</marker>
<rawString>Yang, X., G. Zhou, J. Su, and C. L. Tan. 2003. Coreference resolution using competition learning approach. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL 2003), pages 176–183, Sapporo.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>