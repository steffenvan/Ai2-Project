<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011323">
<title confidence="0.980256">
Revisiting Pivot Language Approach for Machine Translation
</title>
<author confidence="0.975019">
Hua Wu and Haifeng Wang
</author>
<affiliation confidence="0.970433">
Toshiba (China) Research and Development Center
</affiliation>
<address confidence="0.962645">
5/F., Tower W2, Oriental Plaza, Beijing, 100738, China
</address>
<email confidence="0.995682">
{wuhua, wanghaifeng}@rdc.toshiba.com.cn
</email>
<sectionHeader confidence="0.997334" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999823041666667">
This paper revisits the pivot language ap-
proach for machine translation. First,
we investigate three different methods
for pivot translation. Then we employ
a hybrid method combining RBMT and
SMT systems to fill up the data gap
for pivot translation, where the source-
pivot and pivot-target corpora are inde-
pendent. Experimental results on spo-
ken language translation show that this
hybrid method significantly improves the
translation quality, which outperforms the
method using a source-target corpus of
the same size. In addition, we pro-
pose a system combination approach to
select better translations from those pro-
duced by various pivot translation meth-
ods. This method regards system com-
bination as a translation evaluation prob-
lem and formalizes it with a regression
learning model. Experimental results in-
dicate that our method achieves consistent
and significant improvement over individ-
ual translation outputs.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999948236363637">
Current statistical machine translation (SMT) sys-
tems rely on large parallel and monolingual train-
ing corpora to produce translations of relatively
higher quality. Unfortunately, large quantities of
parallel data are not readily available for some lan-
guages pairs, therefore limiting the potential use
of current SMT systems. In particular, for speech
translation, the translation task often focuses on a
specific domain such as the travel domain. It is es-
pecially difficult to obtain such a domain-specific
corpus for some language pairs such as Chinese to
Spanish translation.
To circumvent the data bottleneck, some re-
searchers have investigated to use a pivot language
approach (Cohn and Lapata, 2007; Utiyama and
Isahara, 2007; Wu and Wang 2007; Bertoldi et al.,
2008). This approach introduces a third language,
named the pivot language, for which there exist
large source-pivot and pivot-target bilingual cor-
pora. A pivot task was also designed for spoken
language translation in the evaluation campaign of
IWSLT 2008 (Paul, 2008), where English is used
as a pivot language for Chinese to Spanish trans-
lation.
Three different pivot strategies have been in-
vestigated in the literature. The first is based
on phrase table multiplication (Cohn and Lap-
ata 2007; Wu and Wang, 2007). It multiples
corresponding translation probabilities and lexical
weights in source-pivot and pivot-target transla-
tion models to induce a new source-target phrase
table. We name it the triangulation method. The
second is the sentence translation strategy, which
first translates the source sentence to the pivot sen-
tence, and then to the target sentence (Utiyama and
Isahara, 2007; Khalilov et al., 2008). We name it
the transfer method. The third is to use existing
models to build a synthetic source-target corpus,
from which a source-target model can be trained
(Bertoldi et al., 2008). For example, we can ob-
tain a source-pivot corpus by translating the pivot
sentence in the source-pivot corpus into the target
language with pivot-target translation models. We
name it the synthetic method.
The working condition with the pivot language
approach is that the source-pivot and pivot-target
parallel corpora are independent, in the sense that
they are not derived from the same set of sen-
tences, namely independently sourced corpora.
Thus, some linguistic phenomena in the source-
pivot corpus will lost if they do not exist in the
pivot-target corpus, and vice versa. In order to fill
up this data gap, we make use of rule-based ma-
chine translation (RBMT) systems to translate the
pivot sentences in the source-pivot or pivot-target
</bodyText>
<page confidence="0.996338">
154
</page>
<note confidence="0.999612">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 154–162,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.995638388059702">
corpus into target or source sentences. As a re-
sult, we can build a synthetic multilingual corpus,
which can be used to improve the translation qual-
ity. The idea of using RBMT systems to improve
the translation quality of SMT sysems has been
explored in Hu et al. (2007). Here, we re-examine
the hybrid method to fill up the data gap for pivot
translation.
Although previous studies proposed several
pivot translation methods, there are no studies to
combine different pivot methods for translation
quality improvement. In this paper, we first com-
pare the individual pivot methods and then in-
vestigate to improve pivot translation quality by
combining the outputs produced by different sys-
tems. We propose to regard system combination
as a translation evaluation problem. For transla-
tions from one of the systems, this method uses the
outputs from other translation systems as pseudo
references. A regression learning method is used
to infer a function that maps a feature vector
(which measures the similarity of a translation to
the pseudo references) to a score that indicates the
quality of the translation. Scores are first gener-
ated independently for each translation, then the
translations are ranked by their respective scores.
The candidate with the highest score is selected
as the final translation. This is achieved by opti-
mizing the regression learning model’s output to
correlate against a set of training examples, where
the source sentences are provided with several ref-
erence translations, instead of manually labeling
the translations produced by various systems with
quantitative assessments as described in (Albrecht
and Hwa, 2007; Duh, 2008). The advantage of
our method is that we do not need to manually la-
bel the translations produced by each translation
system, therefore enabling our method suitable for
translation selection among any systems without
additional manual work.
We conducted experiments for spoken language
translation on the pivot task in the IWSLT 2008
evaluation campaign, where Chinese sentences in
travel domain need to be translated into Spanish,
with English as the pivot language. Experimen-
tal results show that (1) the performances of the
three pivot methods are comparable when only
SMT systems are used. However, the triangulation
method and the transfer method significantly out-
perform the synthetic method when RBMT sys-
tems are used to improve the translation qual-
ity; (2) The hybrid method combining SMT and
RBMT system for pivot translation greatly im-
proves the translation quality. And this translation
quality is higher than that of those produced by the
system trained with a real Chinese-Spanish cor-
pus; (3) Our sentence-level translation selection
method consistently and significantly improves
the translation quality over individual translation
outputs in all of our experiments.
Section 2 briefly introduces the three pivot
translation methods. Section 3 presents the hy-
brid method combining SMT and RBMT sys-
tems. Section 4 describes the translation selec-
tion method. Experimental results are presented
in Section 5, followed by a discussion in Section
6. The last section draws conclusions.
</bodyText>
<sectionHeader confidence="0.997962" genericHeader="method">
2 Pivot Methods for Phrase-based SMT
</sectionHeader>
<subsectionHeader confidence="0.958722">
2.1 Triangulation Method
</subsectionHeader>
<bodyText confidence="0.999724333333333">
Following the method described in Wu and Wang
(2007), we train the source-pivot and pivot-target
translation models using the source-pivot and
pivot-target corpora, respectively. Based on these
two models, we induce a source-target translation
model, in which two important elements need to
be induced: phrase translation probability and lex-
ical weight.
Phrase Translation Probability We induce the
phrase translation probability by assuming the in-
dependence between the source and target phrases
when given the pivot phrase.
</bodyText>
<equation confidence="0.9875">
φ(¯s|¯t) = � φ(¯s|¯p)φ(¯p|¯t) (1)
p�
</equation>
<bodyText confidence="0.997574909090909">
Where ¯s, p¯ and t represent the phrases in the lan-
guages L3, Lp and Lt, respectively.
Lexical Weight According to the method de-
scribed in Koehn et al. (2003), there are two im-
portant elements in the lexical weight: word align-
ment information a in a phrase pair (¯s, ¯t) and lex-
ical translation probability w(s|t).
Let a1 and a2 represent the word alignment in-
formation inside the phrase pairs (¯s, ¯p) and (¯p, ¯t)
respectively, then the alignment information inside
(¯s, ¯t) can be obtained as shown in Eq. (2).
</bodyText>
<equation confidence="0.707661">
a = {(s, t)|]p : (s, p) E a1 &amp; (p, t) E a2} (2)
</equation>
<bodyText confidence="0.999432333333333">
Based on the the induced word alignment in-
formation, we estimate the co-occurring frequen-
cies of word pairs directly from the induced phrase
</bodyText>
<page confidence="0.998504">
155
</page>
<bodyText confidence="0.999442">
pairs. Then we estimate the lexical translation
probability as shown in Eq. (3).
</bodyText>
<equation confidence="0.9997665">
count(s, t) (3 )
w(s�t) = Es, count(st, t)
</equation>
<bodyText confidence="0.998584">
Where count(s, t) represents the co-occurring fre-
quency of the word pair (s, t).
</bodyText>
<subsectionHeader confidence="0.998009">
2.2 Transfer Method
</subsectionHeader>
<bodyText confidence="0.999681866666667">
The transfer method first translates from the
source language to the pivot language using a
source-pivot model, and then from the pivot lan-
guage to the target language using a pivot-target
model. Given a source sentence s, we can trans-
late it into n pivot sentences p1, p2, ..., pn using a
source-pivot translation system. Each pi can be
translated into m target sentences ti1, ti2, ..., tim.
We rescore all the n x m candidates using both
the source-pivot and pivot-target translation scores
following the method described in Utiyama and
Isahara (2007). If we use hfp and hpt to denote the
features in the source-pivot and pivot-target sys-
tems, respectively, we get the optimal target trans-
lation according to the following formula.
</bodyText>
<equation confidence="0.9727945">
(λspk hspk (s,p)+λpt
k hpt k (p, t)) (4)
</equation>
<bodyText confidence="0.99548275">
Where L is the number of features used in SMT
systems. λsp and λpt are feature weights set by
performing minimum error rate training as de-
scribed in Och (2003).
</bodyText>
<subsectionHeader confidence="0.998748">
2.3 Synthetic Method
</subsectionHeader>
<bodyText confidence="0.9998275">
There are two possible methods to obtain a source-
target corpus using the source-pivot and pivot-
target corpora. One is to obtain target transla-
tions for the source sentences in the source-pivot
corpus. This can be achieved by translating the
pivot sentences in source-pivot corpus to target
sentences with the pivot-target SMT system. The
other is to obtain source translations for the tar-
get sentences in the pivot-target corpus using the
pivot-source SMT system. And we can combine
these two source-target corpora to produced a fi-
nal synthetic corpus.
Given a pivot sentence, we can translate it into
n source or target sentences. These n translations
together with their source or target sentences are
used to create a synthetic bilingual corpus. Then
we build a source-target translation model using
this corpus.
</bodyText>
<sectionHeader confidence="0.959853" genericHeader="method">
3 Using RBMT Systems for Pivot
Translation
</sectionHeader>
<bodyText confidence="0.999939693877551">
Since the source-pivot and pivot-target parallel
corpora are independent, the pivot sentences in the
two corpora are distinct from each other. Thus,
some linguistic phenomena in the source-pivot
corpus will lost if they do not exist in the pivot-
target corpus, and vice versa. Here we use RBMT
systems to fill up this data gap. For many source-
target language pairs, the commercial pivot-source
and/or pivot-target RBMT systems are available
on markets. For example, for Chinese to Span-
ish translation, English to Chinese and English to
Spanish RBMT systems are available.
With the RBMT systems, we can create a syn-
thetic multilingual source-pivot-target corpus by
translating the pivot sentences in the pivot-source
or pivot-target corpus. The source-target pairs ex-
tracted from this synthetic multilingual corpus can
be used to build a source-target translation model.
Another way to use the synthetic multilingual cor-
pus is to add the source-pivot or pivot-target sen-
tence pairs in this corpus to the training data to re-
build the source-pivot or pivot-target SMT model.
The rebuilt models can be applied to the triangula-
tion method and the transfer method as described
in Section 2.
Moreover, the RBMT systems can also be used
to enlarge the size of bilingual training data. Since
it is easy to obtain monolingual corpora than bilin-
gual corpora, we use RBMT systems to translate
the available monolingual corpora to obtain syn-
thetic bilingual corpus, which are added to the
training data to improve the performance of SMT
systems. Even if no monolingual corpus is avail-
able, we can also use RBMT systems to translate
the sentences in the bilingual corpus to obtain al-
ternative translations. For example, we can use
source-pivot RBMT systems to provide alternative
translations for the source sentences in the source-
pivot corpus.
In addition to translating training data, the
source-pivot RBMT system can be used to trans-
late the test set into the pivot language, which
can be further translated into the target language
with the pivot-target RBMT system. The trans-
lated test set can be added to the training data to
further improve translation quality. The advantage
of this method is that the RBMT system can pro-
vide translations for sentences in the test set and
cover some out-of-vocabulary words in the test set
</bodyText>
<equation confidence="0.998622">
t� = argmax
t
L
k=1
</equation>
<page confidence="0.97223">
156
</page>
<bodyText confidence="0.999140333333333">
that are uncovered by the training data. It can also
change the distribution of some phrase pairs and
reinforce some phrase pairs relative to the test set.
</bodyText>
<sectionHeader confidence="0.964956" genericHeader="method">
4 Translation Selection
</sectionHeader>
<bodyText confidence="0.999963130434783">
We propose a method to select the optimal trans-
lation from those produced by various translation
systems. We regard sentence-level translation se-
lection as a machine translation (MT) evaluation
problem and formalize this problem with a regres-
sion learning model. For each translation, this
method uses the outputs from other translation
systems as pseudo references. The regression ob-
jective is to infer a function that maps a feature
vector (which measures the similarity of a trans-
lation from one system to the pseudo references)
to a score that indicates the quality of the transla-
tion. Scores are first generated independently for
each translation, then the translations are ranked
by their respective scores. The candidate with the
highest score is selected.
The similar ideas have been explored in previ-
ous studies. Albrecht and Hwa (2007) proposed
a method to evaluate MT outputs with pseudo
references using support vector regression as the
learner to evaluate translations. Duh (2008) pro-
posed a ranking method to compare the transla-
tions proposed by several systems. These two
methods require quantitative quality assessments
by human judges for the translations produced by
various systems in the training set. When we apply
such methods to translation selection, the relative
values of the scores assigned by the subject sys-
tems are important. In different data conditions,
the relative values of the scores assigned by the
subject systems may change. In order to train a re-
liable learner, we need to prepare a balanced train-
ing set, where the translations produced by differ-
ent systems under different conditions are required
to be manually evaluated. In extreme cases, we
need to relabel the training data to obtain better
performance. In this paper, we modify the method
in Albrecht and Hwa (2007) to only prepare hu-
man reference translations for the training exam-
ples, and then evaluate the translations produced
by the subject systems against the references us-
ing BLEU score (Papineni et al., 2002). We use
smoothed sentence-level BLEU score to replace
the human assessments, where we use additive
smoothing to avoid zero BLEU scores when we
calculate the n-gram precisions. In this case, we
</bodyText>
<table confidence="0.999133916666667">
ID Description
1-4 n-gram precisions against pseudo refer-
ences(1 &lt; n &lt; 4)
5-6 PER and WER
7-8 precision, recall, fragmentation from
METEOR (Lavie and Agarwal, 2007)
9-12 precisions and recalls of non-
consecutive bigrams with a gap
size of m (1 &lt; m &lt; 2)
13-14 longest common subsequences
15-19 n-gram precision against a target cor-
pus(1&lt;n&lt;5)
</table>
<tableCaption confidence="0.999811">
Table 1: Feature sets for regression learning
</tableCaption>
<bodyText confidence="0.999961444444444">
can easily retrain the learner under different con-
ditions, therefore enabling our method to be ap-
plied to sentence-level translation selection from
any sets of translation systems without any addi-
tional human work.
In regression learning, we infer a function
f that maps a multi-dimensional input vec-
tor x to a continuous real value y, such that
the error over a set of m training examples,
(x1, y1), (x2, y2), ..., (xm, yM), is minimized ac-
cording to a loss function. In the context of trans-
lation selection, y is assigned as the smoothed
BLEU score. The function f represents a math-
ematic model of the automatic evaluation metrics.
The input sentence is represented as a feature vec-
tor x, which are extracted from the input sen-
tence and the comparisons against the pseudo ref-
erences. We use the features as shown in Table 1.
</bodyText>
<sectionHeader confidence="0.999554" genericHeader="method">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.896908">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.999806272727273">
We performed experiments on spoken language
translation for the pivot task of IWSLT 2008. This
task translates Chinese to Spanish using English
as the pivot language. Table 2 describes the data
used for model training in this paper, including the
BTEC (Basic Travel Expression Corpus) Chinese-
English (CE) corpus and the BTEC English-
Spanish (ES) corpus provided by IWSLT 2008 or-
ganizers, the HIT olympic CE corpus (2004-863-
008)1 and the Europarl ES corpus2. There are
two kinds of BTEC CE corpus: BTEC CE1 and
</bodyText>
<footnote confidence="0.9999745">
1http://www.chineseldc.org/EN/purchasing.htm
2http://www.statmt.org/europarl/
</footnote>
<page confidence="0.972307">
157
</page>
<table confidence="0.9998365">
Corpus Size SW TW
BTEC CE1 20,000 164K 182K
BTEC CE2 18,972 177K 182K
HIT CE 51,791 490K 502K
BTEC ES 19,972 182K 185K
Europarl ES 400,000 8,485K 8,219K
</table>
<tableCaption confidence="0.9575735">
Table 2: Training data. SW and TW represent
source words and target words, respectively.
</tableCaption>
<bodyText confidence="0.997891896551724">
BTEC CE2. BTEC CE1 was distributed for the
pivot task in IWSLT 2008 while BTEC CE2 was
for the BTEC CE task, which is parallel to the
BTEC ES corpus. For Chinese-English transla-
tion, we mainly used BTEC CE1 corpus. We used
the BTEC CE2 corpus and the HIT Olympic cor-
pus for comparison experiments only. We used the
English parts of the BTEC CE1 corpus, the BTEC
ES corpus, and the HIT Olympic corpus (if in-
volved) to train a 5-gram English language model
(LM) with interpolated Kneser-Ney smoothing.
For English-Spanish translation, we selected 400k
sentence pairs from the Europarl corpus that are
close to the English parts of both the BTEC CE
corpus and the BTEC ES corpus. Then we built
a Spanish LM by interpolating an out-of-domain
LM trained on the Spanish part of this selected
corpus with the in-domain LM trained with the
BTEC corpus.
For Chinese-English-Spanish translation, we
used the development set (devset3) released for
the pivot task as the test set, which contains 506
source sentences, with 7 reference translations in
English and Spanish. To be capable of tuning pa-
rameters on our systems, we created a develop-
ment set of 1,000 sentences taken from the training
sets, with 3 reference translations in both English
and Spanish. This development set is also used to
train the regression learning model.
</bodyText>
<subsectionHeader confidence="0.997465">
5.2 Systems and Evaluation Method
</subsectionHeader>
<bodyText confidence="0.999787190476191">
We used two commercial RBMT systems in our
experiments: System A for Chinese-English bidi-
rectional translation and System B for English-
Chinese and English-Spanish translation. For
phrase-based SMT translation, we used the Moses
decoder (Koehn et al., 2007) and its support train-
ing scripts. We ran the decoder with its default
settings and then used Moses’ implementation of
minimum error rate training (Och, 2003) to tune
the feature weights on the development set.
To select translation among outputs produced
by different pivot translation systems, we used
SVM-light (Joachins, 1999) to perform support
vector regression with the linear kernel.
Translation quality was evaluated using both the
BLEU score proposed by Papineni et al. (2002)
and also the modified BLEU (BLEU-Fix) score3
used in the IWSLT 2008 evaluation campaign,
where the brevity calculation is modified to use
closest reference length instead of shortest refer-
ence length.
</bodyText>
<subsectionHeader confidence="0.958519">
5.3 Results by Using SMT Systems
</subsectionHeader>
<bodyText confidence="0.999997588235294">
We conducted the pivot translation experiments
using the BTEC CE1 and BTEC ES described
in Section 5.1. We used the three methods de-
scribed in Section 2 for pivot translation. For the
transfer method, we selected the optimal transla-
tions among 10 x 10 candidates. For the synthetic
method, we used the ES translation model to trans-
late the English part of the CE corpus to Spanish to
construct a synthetic corpus. And we also used the
BTEC CE1 corpus to build a EC translation model
to translate the English part of ES corpus into Chi-
nese. Then we combined these two synthetic cor-
pora to build a Chinese-Spanish translation model.
In our experiments, only 1-best Chinese or Span-
ish translation was used since using n-best results
did not greatly improve the translation quality. We
used the method described in Section 4 to select
translations from the translations produced by the
three systems. For each system, we used three
different alignment heuristics (grow, grow-diag,
grow-diag-final4) to obtain the final alignment re-
sults, and then constructed three different phrase
tables. Thus, for each system, we can get three
different translations for each input. These differ-
ent translations can serve as pseudo references for
the outputs of other systems. In our case, for each
sentence, we have 6 pseudo reference translations.
In addition, we found out that the grow heuristic
performed the best for all the systems. Thus, for
an individual system, we used the translation re-
sults produced using the grow alignment heuristic.
The translation results are shown in Table 3.
ASR and CRR represent different input condi-
tions, namely the result of automatic speech recog-
</bodyText>
<footnote confidence="0.9953096">
3https://www.slc.atr.jp/Corpus/IWSLT08/eval/IWSLT08
auto eval.tgz
4A description of the alignment heuristics can be found at
http://www.statmt.org/jhuws/?n=FactoredTraining.Training
Parameters
</footnote>
<page confidence="0.988025">
158
</page>
<table confidence="0.9518046">
Method BLEU BLEU-Fix
Triangulation 33.70/27.46 31.59/25.02
Transfer 33.52/28.34 31.36/26.20
Synthetic 34.35/27.21 32.00/26.07
Combination 38.14/29.32 34.76/27.39
</table>
<tableCaption confidence="0.9466">
Table 3: CRR/ASR translation results by using
</tableCaption>
<figure confidence="0.939457">
SMT systems
0.9❑
0.8❑
0.7❑
0.6❑
Coverage
0.5❑
0.4❑
0.3❑
0.2❑
0.1❑
0❑
SMT (Triangulation)❑
+EC RBMT❑
+EC RBMT+CE RBMT❑
+EC RBMT+CE RBMT+Test Set❑
1❑ 2❑ 3❑ 4❑ 5❑ 6❑ 7❑
Phrase length❑
</figure>
<bodyText confidence="0.998911090909091">
nition and correct recognition result, respectively.
Here, we used the 1-best ASR result. From the
translation results, it can be seen that three meth-
ods achieved comparable translation quality on
both ASR and CRR inputs, with the translation re-
sults on CRR inputs are much better than those on
ASR inputs because of the errors in the ASR in-
puts. The results also show that our translation se-
lection method is very effective, which achieved
absolute improvements of about 4 and 1 BLEU
scores on CRR and ASR inputs, respectively.
</bodyText>
<subsectionHeader confidence="0.5763815">
5.4 Results by Using both RBMT and SMT
Systems
</subsectionHeader>
<bodyText confidence="0.999690928571429">
In order to fill up the data gap as discussed in Sec-
tion 3, we used the RBMT System A to translate
the English sentences in the ES corpus into Chi-
nese. As described in Section 3, this corpus can
be used by the three pivot translation methods.
First, the synthetic Chinese-Spanish corpus can be
combined with those produced by the EC and ES
SMT systems, which were used in the synthetic
method. Second, the synthetic Chinese-English
corpus can be added into the BTEC CE1 corpus to
build the CE translation model. In this way, the in-
tersected English phrases in the CE corpus and ES
corpus becomes more, which enables the Chinese-
Spanish translation model induced using the trian-
gulation method to cover more phrase pairs. For
the transfer method, the CE translation quality can
be also improved, which would result in the im-
provement of the Spanish translation quality.
The translation results are shown in the columns
under ”EC RBMT” in Table 4. As compared with
those in Table 3, the translation quality was greatly
improved, with absolute improvements of at least
5.1 and 3.9 BLEU scores on CRR and ASR inputs
for system combination results. The above results
indicate that RBMT systems indeed can be used to
fill up the data gap for pivot translation.
In our experiments, we also used a CE RBMT
system to enlarge the size of training data by pro-
</bodyText>
<figureCaption confidence="0.999356">
Figure 1: Coverage on test source phrases
</figureCaption>
<bodyText confidence="0.999950333333333">
viding alternative English translations for the Chi-
nese part of the CE corpus. The translation results
are shown in the columns under “+CE RBMT” in
Table 4. From the translation results, it can be
seen that, enlarging the size of training data with
RBMT systems can further improve the translation
quality.
In addition to translating the training data, the
CE RBMT system can be also used to translate the
test set into English, which can be further trans-
lated into Spanish with the ES RBMT system B.56
The translated test set can be further added to the
training data to improve translation quality. The
columns under “+Test Set” in Table 4 describes
the translation results. The results show that trans-
lating the test set using RBMT systems greatly im-
proved the translation result, with further improve-
ments of about 2 and 1.5 BLEU scores on CRR
and ASR inputs, respectively.
The results also indicate that both the triangula-
tion method and the transfer method greatly out-
performed the synthetic method when we com-
bined both RBMT and SMT systems in our exper-
iments. Further analysis shows that the synthetic
method contributed little to system combination.
The selection results are almost the same as those
selected from the translations produced by the tri-
angulation and transfer methods.
In order to further analyze the translation re-
sults, we evaluated the above systems by examin-
ing the coverage of the phrase tables over the test
phrases. We took the triangulation method as a
case study, the results of which are shown in Fig-
</bodyText>
<footnote confidence="0.9990696">
5Although using the ES RBMT system B to translate the
training data did not improve the translation quality, it im-
proved the translation quality by translating the test set.
6The RBMT systems achieved a BLEU score of 24.36 on
the test set.
</footnote>
<page confidence="0.992192">
159
</page>
<table confidence="0.999531">
EC RBMT + CE RBMT + Test Set
Method BLEU BLEU-Fix BLEU BLEU-Fix BLEU BLEU-Fix
Triangulation 40.69/31.02 37.99/29.15 41.59/31.43 39.39/29.95 44.71/32.60 42.37/31.14
Transfer 42.06/31.72 39.73/29.35 43.40/33.05 40.73/30.06 45.91/34.52 42.86/31.92
Synthetic 39.10/29.73 37.26/28.45 39.90/30.00 37.90/28.66 41.16/31.30 37.99/29.36
Combination 43.21/33.23 40.58/31.17 45.09/34.10 42.88/31.73 47.06/35.62 44.94/32.99
</table>
<tableCaption confidence="0.981736">
Table 4: CRR/ASR translation results by using RBMT and SMT systems
</tableCaption>
<table confidence="0.999869">
Method BLEU BLEU-Fix
Triangulation 45.64/33.15 42.11/31.11
Transfer 47.18/34.56 43.61/32.17
Combination 48.42/36.42 45.42/33.52
</table>
<tableCaption confidence="0.9235795">
Table 5: CRR/ASR translation results by using ad-
ditional monolingual corpora
</tableCaption>
<bodyText confidence="0.9700495">
ure 1. It can be seen that using RBMT systems
to translate the training and/or test data can cover
more source phrases in the test set, which results
in translation quality improvement.
</bodyText>
<subsectionHeader confidence="0.93237">
5.5 Results by Using Monolingual Corpus
</subsectionHeader>
<bodyText confidence="0.9999917">
In addition to translating the limited bilingual cor-
pus, we also translated additional monolingual
corpus to further enlarge the size of the training
data. We assume that it is easier to obtain a mono-
lingual pivot corpus than to obtain a monolingual
source or target corpus. Thus, we translated the
English part of the HIT Olympic corpus into Chi-
nese and Spanish using EC and ES RBMT sys-
tems. The generated synthetic corpus was added to
the training data to train EC and ES SMT systems.
Here, we used the synthetic CE Olympic corpus
to train a model, which was interpolated with the
CE model trained with both the BTEC CE1 cor-
pus and the synthetic BTEC corpus to obtain an
interpolated CE translation model. Similarly, we
obtained an interpolated ES translation model. Ta-
ble 5 describes the translation results.7 The results
indicate that translating monolingual corpus using
the RBMT system further improved the translation
quality as compared with those in Table 4.
</bodyText>
<sectionHeader confidence="0.999863" genericHeader="method">
6 Discussion
</sectionHeader>
<subsectionHeader confidence="0.999927">
6.1 Effects of Different RBMT Systems
</subsectionHeader>
<bodyText confidence="0.992978">
In this section, we compare the effects of two
commercial RBMT systems with different transla-
</bodyText>
<footnote confidence="0.994029">
7Here we excluded the synthetic method since it greatly
falls behind the other two methods.
</footnote>
<table confidence="0.9995274">
Method Sys. A Sys. B Sys. A+B
Triangulation 40.69 39.28 41.01
Transfer 42.06 39.57 43.03
Synthetic 39.10 38.24 39.26
Combination 43.21 40.59 44.27
</table>
<tableCaption confidence="0.8562395">
Table 6: CRR translation results (BLEU scores)
by using different RBMT systems
</tableCaption>
<bodyText confidence="0.999486103448276">
tion accuracy on spoken language translation. The
goals are (1) to investigate whether a RBMT sys-
tem can improve pivot translation quality even if
its translation accuracy is not high, and (2) to com-
pare the effects of RBMT system with different
translation accuracy on pivot translation. Besides
the EC RBMT system A used in the above section,
we also used the EC RBMT system B for this ex-
periment.
We used the two systems to translate the test set
from English to Chinese, and then evaluated the
translation quality against Chinese references ob-
tained from the IWSLT 2008 evaluation campaign.
The BLEU scores are 43.90 and 29.77 for System
A and System B, respectively. This shows that
the translation quality of System B on spoken lan-
guage corpus is much lower than that of System A.
Then we applied these two different RBMT sys-
tems to translate the English part of the BTEC ES
corpus into Chinese as described in Section 5.4.
The translation results on CRR inputs are shown
in Table 6.8 We replicated some of the results in
Table 4 for the convenience of comparison. The
results indicate that the higher the translation ac-
curacy of the RBMT system is, the better the pivot
translation is. If we compare the results with those
only using SMT systems as described in Table 3,
the translation quality was greatly improved by at
least 3 BLEU scores, even if the translation ac-
</bodyText>
<footnote confidence="0.994817666666667">
8We omitted the ASR translation results since the trends
are the same as those for CRR inputs. And we only showed
BLEU scores since the trend for BLEU-Fix scores is similar.
</footnote>
<page confidence="0.981062">
160
</page>
<table confidence="0.9997832">
Method Multilingual + BTEC CE1
Triangulation 41.86/39.55 42.41/39.55
Transfer 42.46/39.09 43.84/40.34
Standard 42.21/40.23 42.21/40.23
Combination 43.75/40.34 44.68/41.14
</table>
<tableCaption confidence="0.82155">
Table 7: CRR translation results by using multilin-
gual corpus. ”/” separates the BLEU and BLEU-
fix scores.
</tableCaption>
<bodyText confidence="0.99803525">
curacy of System B is not so high. Combining
two RBMT systems further improved the transla-
tion quality, which indicates that the two systems
complement each other.
</bodyText>
<subsectionHeader confidence="0.946581">
6.2 Results by Using Multilingual Corpus
</subsectionHeader>
<bodyText confidence="0.999892133333333">
In this section, we compare the translation results
by using a multilingual corpus with those by us-
ing independently sourced corpora. BTEC CE2
and BTEC ES are from the same source sentences,
which can be taken as a multilingual corpus. The
two corpora were employed to build CE and ES
SMT models, which were used in the triangula-
tion method and the transfer method. We also ex-
tracted the Chinese-Spanish (CS) corpus to build a
standard CS translation system, which is denoted
as Standard. The comparison results are shown
in Table 7. The translation quality produced by
the systems using a multilingual corpus is much
higher than that produced by using independently
sourced corpora as described in Table 3, with an
absolute improvement of about 5.6 BLEU scores.
If we used the EC RBMT system, the translation
quality of those in Table 4 is comparable to that by
using the multilingual corpus, which indicates that
our method using RBMT systems to fill up the data
gap is effective. The results also indicate that our
translation selection method for pivot translation
outperforms the method using only a real source-
target corpus.
For comparison purpose, we added BTEC CE1
into the training data. The translation quality was
improved by only 1 BLEU score. This again
proves that our method to fill up the data gap is
more effective than that to increase the size of the
independently sourced corpus.
</bodyText>
<subsectionHeader confidence="0.999171">
6.3 Comparison with Related Work
</subsectionHeader>
<bodyText confidence="0.997738">
In IWSLT 2008, the best result for the pivot task
is achieved by Wang et al. (2008). In order to
compare the results, we added the bilingual HIT
</bodyText>
<table confidence="0.986205">
Ours Wang TSAL
BLEU 49.57 - 48.25
BLEU-Fix 46.74 45.10 45.27
</table>
<tableCaption confidence="0.999951">
Table 8: Comparison with related work
</tableCaption>
<bodyText confidence="0.999949846153846">
Olympic corpus into the CE training data.9 We
also compared our translation selection method
with that proposed in (Wang et al., 2008) that
is based on the target sentence average length
(TSAL). The translation results are shown in Ta-
ble 8. ”Wang” represents the results in Wang et al.
(2008). ”TSAL” represents the translation selec-
tion method proposed in Wang et al. (2008), which
is applied to our experiment. From the results, it
can be seen that our method outperforms the best
system in IWSLT 2008 and that our translation se-
lection method outperforms the method based on
target sentence average length.
</bodyText>
<sectionHeader confidence="0.999467" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.985737769230769">
In this paper, we have compared three differ-
ent pivot translation methods for spoken language
translation. Experimental results indicated that the
triangulation method and the transfer method gen-
erally outperform the synthetic method. Then we
showed that the hybrid method combining RBMT
and SMT systems can be used to fill up the data
gap between the source-pivot and pivot-target cor-
pora. By translating the pivot sentences in inde-
pendent corpora, the hybrid method can produce
translations whose quality is higher than those pro-
duced by the method using a source-target corpus
of the same size. We also showed that even if the
translation quality of the RBMT system is low, it
still greatly improved the translation quality.
In addition, we proposed a system combination
method to select better translations from outputs
produced by different pivot methods. This method
is developed through regression learning, where
only a small size of training examples with ref-
erence translations are required. Experimental re-
sults indicate that this method can consistently and
significantly improve translation quality over indi-
vidual translation outputs. And our system out-
performs the best system for the pivot task in the
IWSLT 2008 evaluation campaign.
</bodyText>
<footnote confidence="0.85422975">
9We used about 70k sentence pairs for CE model training,
while Wang et al. (2008) used about 100k sentence pairs, a
CE translation dictionary and more monolingual corpora for
model training.
</footnote>
<page confidence="0.997913">
161
</page>
<sectionHeader confidence="0.998327" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999919852272727">
Joshua S. Albrecht and Rebecca Hwa. 2007. Regres-
sion for Sentence-Level MT Evaluation with Pseudo
References. In Proceedings of the 45th Annual
Meeting of the Accosiation of Computational Lin-
guistics, pages 296–303.
Nicola Bertoldi, Madalina Barbaiani, Marcello Fed-
erico, and Roldano Cattoni. 2008. Phrase-Based
Statistical Machine Translation with Pivot Lan-
guages. In Proceedings of the International Work-
shop on Spoken Language Translation, pages 143-
149.
Tevor Cohn and Mirella Lapata. 2007. Machine Trans-
lation by Triangulation: Making Effective Use of
Multi-Parallel Corpora. In Proceedings of the 45th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 348–355.
Kevin Duh. 2008. Ranking vs. Regression in Machine
Translation Evaluation. In Proceedings of the Third
Workshop on Statistical Machine Translation, pages
191–194.
Xiaoguang Hu, Haifeng Wang, and Hua Wu. 2007.
Using RBMT Systems to Produce Bilingual Corpus
for SMT. In Proceedings of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, pages 287–295.
Thorsten Joachims. 1999. Making Large-Scale
SVM Learning Practical. In Bernhard Sch¨oelkopf,
Christopher Burges, and Alexander Smola, edi-
tors, Advances in Kernel Methods - Support Vector
Learning. MIT Press.
Maxim Khalilov, Marta R. Costa-Juss`a, Carlos A.
Henr´ıquez, Jos´e A.R. Fonollosa, Adolfo Hern´andez,
Jos´e B. Mari˜no, Rafael E. Banchs, Chen Boxing,
Min Zhang, Aiti Aw, and Haizhou Li. 2008. The
TALP &amp; I2R SMT Systems for IWSLT 2008. In
Proceedings of the International Workshop on Spo-
ken Language Translation, pages 116–123.
Philipp Koehn, Franz J. Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In HLT-
NAACL: Human Language Technology Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 127–133.
Philipp Koehn, Hieu Hoang, Alexanda Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the 45th Annual Meeting of the
Associa-tion for Computational Linguistics, demon-
stration session, pages 177–180.
Alon Lavie and Abhaya Agarwal. 2007. METEOR:
An Automatic Metric for MT Evaluation with High
Levels of Correlation with Human Judgments. In
Proceedings of Workshop on Statistical Machine
Translation at the 45th Annual Meeting of the As-
sociation of Computational Linguistics, pages 228–
231.
Franz J. Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings
of the 41st Annual Meeting of the Association for
Computational Linguistics, pages 160–167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. In Proceedings
of the 40th annual meeting of the Association for
Computational Linguistics, pages 311–318.
Michael Paul. 2008. Overview of the IWSLT 2008
Evaluation Campaign. In Proceedings of the In-
ternational Workshop on Spoken Language Trans-
lation, pages 1–17.
Masao Utiyama and Hitoshi Isahara. 2007. A Com-
parison of Pivot Methods for Phrase-Based Statisti-
cal Machine Translation. In Proceedings of human
language technology: the Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 484–491.
Haifeng Wang, Hua Wu, Xiaoguang Hu, Zhanyi Liu,
Jianfeng Li, Dengjun Ren, and Zhengyu Niu. 2008.
The TCH Machine Translation System for IWSLT
2008. In Proceedings of the International Workshop
on Spoken Language Translation, pages 124–131.
Hua Wu and Haifeng Wang. 2007. Pivot Lan-
guage Approach for Phrase-Based Statistical Ma-
chine Translation. In Proceedings of 45th Annual
Meeting of the Association for Computational Lin-
guistics, pages 856–863.
</reference>
<page confidence="0.997785">
162
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.952560">
<title confidence="0.999884">Revisiting Pivot Language Approach for Machine Translation</title>
<author confidence="0.997256">Wu Wang</author>
<affiliation confidence="0.978811">Toshiba (China) Research and Development Center</affiliation>
<address confidence="0.993233">5/F., Tower W2, Oriental Plaza, Beijing, 100738, China</address>
<abstract confidence="0.99916336">This paper revisits the pivot language approach for machine translation. First, we investigate three different methods for pivot translation. Then we employ a hybrid method combining RBMT and SMT systems to fill up the data gap for pivot translation, where the sourcepivot and pivot-target corpora are independent. Experimental results on spoken language translation show that this hybrid method significantly improves the translation quality, which outperforms the method using a source-target corpus of the same size. In addition, we propose a system combination approach to select better translations from those produced by various pivot translation methods. This method regards system combination as a translation evaluation problem and formalizes it with a regression learning model. Experimental results indicate that our method achieves consistent and significant improvement over individual translation outputs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Joshua S Albrecht</author>
<author>Rebecca Hwa</author>
</authors>
<title>Regression for Sentence-Level MT Evaluation with Pseudo References.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Accosiation of Computational Linguistics,</booktitle>
<pages>296--303</pages>
<contexts>
<context position="5597" citStr="Albrecht and Hwa, 2007" startWordPosition="867" endWordPosition="870">to the pseudo references) to a score that indicates the quality of the translation. Scores are first generated independently for each translation, then the translations are ranked by their respective scores. The candidate with the highest score is selected as the final translation. This is achieved by optimizing the regression learning model’s output to correlate against a set of training examples, where the source sentences are provided with several reference translations, instead of manually labeling the translations produced by various systems with quantitative assessments as described in (Albrecht and Hwa, 2007; Duh, 2008). The advantage of our method is that we do not need to manually label the translations produced by each translation system, therefore enabling our method suitable for translation selection among any systems without additional manual work. We conducted experiments for spoken language translation on the pivot task in the IWSLT 2008 evaluation campaign, where Chinese sentences in travel domain need to be translated into Spanish, with English as the pivot language. Experimental results show that (1) the performances of the three pivot methods are comparable when only SMT systems are u</context>
<context position="13841" citStr="Albrecht and Hwa (2007)" startWordPosition="2211" endWordPosition="2214">roblem with a regression learning model. For each translation, this method uses the outputs from other translation systems as pseudo references. The regression objective is to infer a function that maps a feature vector (which measures the similarity of a translation from one system to the pseudo references) to a score that indicates the quality of the translation. Scores are first generated independently for each translation, then the translations are ranked by their respective scores. The candidate with the highest score is selected. The similar ideas have been explored in previous studies. Albrecht and Hwa (2007) proposed a method to evaluate MT outputs with pseudo references using support vector regression as the learner to evaluate translations. Duh (2008) proposed a ranking method to compare the translations proposed by several systems. These two methods require quantitative quality assessments by human judges for the translations produced by various systems in the training set. When we apply such methods to translation selection, the relative values of the scores assigned by the subject systems are important. In different data conditions, the relative values of the scores assigned by the subject s</context>
</contexts>
<marker>Albrecht, Hwa, 2007</marker>
<rawString>Joshua S. Albrecht and Rebecca Hwa. 2007. Regression for Sentence-Level MT Evaluation with Pseudo References. In Proceedings of the 45th Annual Meeting of the Accosiation of Computational Linguistics, pages 296–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Bertoldi</author>
<author>Madalina Barbaiani</author>
<author>Marcello Federico</author>
<author>Roldano Cattoni</author>
</authors>
<title>Phrase-Based Statistical Machine Translation with Pivot Languages.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation,</booktitle>
<pages>143--149</pages>
<contexts>
<context position="1943" citStr="Bertoldi et al., 2008" startWordPosition="285" endWordPosition="288">her quality. Unfortunately, large quantities of parallel data are not readily available for some languages pairs, therefore limiting the potential use of current SMT systems. In particular, for speech translation, the translation task often focuses on a specific domain such as the travel domain. It is especially difficult to obtain such a domain-specific corpus for some language pairs such as Chinese to Spanish translation. To circumvent the data bottleneck, some researchers have investigated to use a pivot language approach (Cohn and Lapata, 2007; Utiyama and Isahara, 2007; Wu and Wang 2007; Bertoldi et al., 2008). This approach introduces a third language, named the pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. A pivot task was also designed for spoken language translation in the evaluation campaign of IWSLT 2008 (Paul, 2008), where English is used as a pivot language for Chinese to Spanish translation. Three different pivot strategies have been investigated in the literature. The first is based on phrase table multiplication (Cohn and Lapata 2007; Wu and Wang, 2007). It multiples corresponding translation probabilities and lexical weights in source-pivot</context>
</contexts>
<marker>Bertoldi, Barbaiani, Federico, Cattoni, 2008</marker>
<rawString>Nicola Bertoldi, Madalina Barbaiani, Marcello Federico, and Roldano Cattoni. 2008. Phrase-Based Statistical Machine Translation with Pivot Languages. In Proceedings of the International Workshop on Spoken Language Translation, pages 143-149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Machine Translation by Triangulation: Making Effective Use of Multi-Parallel Corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>348--355</pages>
<contexts>
<context position="1874" citStr="Cohn and Lapata, 2007" startWordPosition="273" endWordPosition="276">nolingual training corpora to produce translations of relatively higher quality. Unfortunately, large quantities of parallel data are not readily available for some languages pairs, therefore limiting the potential use of current SMT systems. In particular, for speech translation, the translation task often focuses on a specific domain such as the travel domain. It is especially difficult to obtain such a domain-specific corpus for some language pairs such as Chinese to Spanish translation. To circumvent the data bottleneck, some researchers have investigated to use a pivot language approach (Cohn and Lapata, 2007; Utiyama and Isahara, 2007; Wu and Wang 2007; Bertoldi et al., 2008). This approach introduces a third language, named the pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. A pivot task was also designed for spoken language translation in the evaluation campaign of IWSLT 2008 (Paul, 2008), where English is used as a pivot language for Chinese to Spanish translation. Three different pivot strategies have been investigated in the literature. The first is based on phrase table multiplication (Cohn and Lapata 2007; Wu and Wang, 2007). It multiples corres</context>
</contexts>
<marker>Cohn, Lapata, 2007</marker>
<rawString>Tevor Cohn and Mirella Lapata. 2007. Machine Translation by Triangulation: Making Effective Use of Multi-Parallel Corpora. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, pages 348–355.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Duh</author>
</authors>
<title>Ranking vs. Regression in Machine Translation Evaluation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>191--194</pages>
<contexts>
<context position="5609" citStr="Duh, 2008" startWordPosition="871" endWordPosition="872">) to a score that indicates the quality of the translation. Scores are first generated independently for each translation, then the translations are ranked by their respective scores. The candidate with the highest score is selected as the final translation. This is achieved by optimizing the regression learning model’s output to correlate against a set of training examples, where the source sentences are provided with several reference translations, instead of manually labeling the translations produced by various systems with quantitative assessments as described in (Albrecht and Hwa, 2007; Duh, 2008). The advantage of our method is that we do not need to manually label the translations produced by each translation system, therefore enabling our method suitable for translation selection among any systems without additional manual work. We conducted experiments for spoken language translation on the pivot task in the IWSLT 2008 evaluation campaign, where Chinese sentences in travel domain need to be translated into Spanish, with English as the pivot language. Experimental results show that (1) the performances of the three pivot methods are comparable when only SMT systems are used. However</context>
<context position="13989" citStr="Duh (2008)" startWordPosition="2235" endWordPosition="2236">bjective is to infer a function that maps a feature vector (which measures the similarity of a translation from one system to the pseudo references) to a score that indicates the quality of the translation. Scores are first generated independently for each translation, then the translations are ranked by their respective scores. The candidate with the highest score is selected. The similar ideas have been explored in previous studies. Albrecht and Hwa (2007) proposed a method to evaluate MT outputs with pseudo references using support vector regression as the learner to evaluate translations. Duh (2008) proposed a ranking method to compare the translations proposed by several systems. These two methods require quantitative quality assessments by human judges for the translations produced by various systems in the training set. When we apply such methods to translation selection, the relative values of the scores assigned by the subject systems are important. In different data conditions, the relative values of the scores assigned by the subject systems may change. In order to train a reliable learner, we need to prepare a balanced training set, where the translations produced by different sy</context>
</contexts>
<marker>Duh, 2008</marker>
<rawString>Kevin Duh. 2008. Ranking vs. Regression in Machine Translation Evaluation. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 191–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoguang Hu</author>
<author>Haifeng Wang</author>
<author>Hua Wu</author>
</authors>
<title>Using RBMT Systems to Produce Bilingual Corpus for SMT.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>287--295</pages>
<contexts>
<context position="4217" citStr="Hu et al. (2007)" startWordPosition="655" endWordPosition="658">rpus, and vice versa. In order to fill up this data gap, we make use of rule-based machine translation (RBMT) systems to translate the pivot sentences in the source-pivot or pivot-target 154 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 154–162, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP corpus into target or source sentences. As a result, we can build a synthetic multilingual corpus, which can be used to improve the translation quality. The idea of using RBMT systems to improve the translation quality of SMT sysems has been explored in Hu et al. (2007). Here, we re-examine the hybrid method to fill up the data gap for pivot translation. Although previous studies proposed several pivot translation methods, there are no studies to combine different pivot methods for translation quality improvement. In this paper, we first compare the individual pivot methods and then investigate to improve pivot translation quality by combining the outputs produced by different systems. We propose to regard system combination as a translation evaluation problem. For translations from one of the systems, this method uses the outputs from other translation syst</context>
</contexts>
<marker>Hu, Wang, Wu, 2007</marker>
<rawString>Xiaoguang Hu, Haifeng Wang, and Hua Wu. 2007. Using RBMT Systems to Produce Bilingual Corpus for SMT. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 287–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making Large-Scale SVM Learning Practical.</title>
<date>1999</date>
<booktitle>Advances in Kernel Methods - Support Vector Learning.</booktitle>
<editor>In Bernhard Sch¨oelkopf, Christopher Burges, and Alexander Smola, editors,</editor>
<publisher>MIT Press.</publisher>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making Large-Scale SVM Learning Practical. In Bernhard Sch¨oelkopf, Christopher Burges, and Alexander Smola, editors, Advances in Kernel Methods - Support Vector Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maxim Khalilov</author>
<author>Marta R Costa-Juss`a</author>
<author>Carlos A Henr´ıquez</author>
<author>Jos´e A R Fonollosa</author>
<author>Adolfo Hern´andez</author>
<author>Jos´e B Mari˜no</author>
<author>Rafael E Banchs</author>
<author>Chen Boxing</author>
<author>Min Zhang</author>
<author>Aiti Aw</author>
<author>Haizhou Li</author>
</authors>
<date>2008</date>
<booktitle>The TALP &amp; I2R SMT Systems for IWSLT</booktitle>
<pages>116--123</pages>
<marker>Khalilov, Costa-Juss`a, Henr´ıquez, Fonollosa, Hern´andez, Mari˜no, Banchs, Boxing, Zhang, Aw, Li, 2008</marker>
<rawString>Maxim Khalilov, Marta R. Costa-Juss`a, Carlos A. Henr´ıquez, Jos´e A.R. Fonollosa, Adolfo Hern´andez, Jos´e B. Mari˜no, Rafael E. Banchs, Chen Boxing, Min Zhang, Aiti Aw, and Haizhou Li. 2008. The TALP &amp; I2R SMT Systems for IWSLT 2008. In Proceedings of the International Workshop on Spoken Language Translation, pages 116–123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In HLTNAACL: Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>127--133</pages>
<contexts>
<context position="7885" citStr="Koehn et al. (2003)" startWordPosition="1219" endWordPosition="1222">lation models using the source-pivot and pivot-target corpora, respectively. Based on these two models, we induce a source-target translation model, in which two important elements need to be induced: phrase translation probability and lexical weight. Phrase Translation Probability We induce the phrase translation probability by assuming the independence between the source and target phrases when given the pivot phrase. φ(¯s|¯t) = � φ(¯s|¯p)φ(¯p|¯t) (1) p� Where ¯s, p¯ and t represent the phrases in the languages L3, Lp and Lt, respectively. Lexical Weight According to the method described in Koehn et al. (2003), there are two important elements in the lexical weight: word alignment information a in a phrase pair (¯s, ¯t) and lexical translation probability w(s|t). Let a1 and a2 represent the word alignment information inside the phrase pairs (¯s, ¯p) and (¯p, ¯t) respectively, then the alignment information inside (¯s, ¯t) can be obtained as shown in Eq. (2). a = {(s, t)|]p : (s, p) E a1 &amp; (p, t) E a2} (2) Based on the the induced word alignment information, we estimate the co-occurring frequencies of word pairs directly from the induced phrase 155 pairs. Then we estimate the lexical translation pro</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In HLTNAACL: Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, pages 127–133.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexanda Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondrej Bojar,</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Associa-tion for Computational Linguistics, demonstration session,</booktitle>
<pages>177--180</pages>
<location>Alexandra</location>
<contexts>
<context position="18888" citStr="Koehn et al., 2007" startWordPosition="3044" endWordPosition="3047">e sentences, with 7 reference translations in English and Spanish. To be capable of tuning parameters on our systems, we created a development set of 1,000 sentences taken from the training sets, with 3 reference translations in both English and Spanish. This development set is also used to train the regression learning model. 5.2 Systems and Evaluation Method We used two commercial RBMT systems in our experiments: System A for Chinese-English bidirectional translation and System B for EnglishChinese and English-Spanish translation. For phrase-based SMT translation, we used the Moses decoder (Koehn et al., 2007) and its support training scripts. We ran the decoder with its default settings and then used Moses’ implementation of minimum error rate training (Och, 2003) to tune the feature weights on the development set. To select translation among outputs produced by different pivot translation systems, we used SVM-light (Joachins, 1999) to perform support vector regression with the linear kernel. Translation quality was evaluated using both the BLEU score proposed by Papineni et al. (2002) and also the modified BLEU (BLEU-Fix) score3 used in the IWSLT 2008 evaluation campaign, where the brevity calcul</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexanda Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the 45th Annual Meeting of the Associa-tion for Computational Linguistics, demonstration session, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Abhaya Agarwal</author>
</authors>
<title>METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments.</title>
<date>2007</date>
<booktitle>In Proceedings of Workshop on Statistical Machine Translation at the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>228--231</pages>
<contexts>
<context position="15369" citStr="Lavie and Agarwal, 2007" startWordPosition="2458" endWordPosition="2461"> In this paper, we modify the method in Albrecht and Hwa (2007) to only prepare human reference translations for the training examples, and then evaluate the translations produced by the subject systems against the references using BLEU score (Papineni et al., 2002). We use smoothed sentence-level BLEU score to replace the human assessments, where we use additive smoothing to avoid zero BLEU scores when we calculate the n-gram precisions. In this case, we ID Description 1-4 n-gram precisions against pseudo references(1 &lt; n &lt; 4) 5-6 PER and WER 7-8 precision, recall, fragmentation from METEOR (Lavie and Agarwal, 2007) 9-12 precisions and recalls of nonconsecutive bigrams with a gap size of m (1 &lt; m &lt; 2) 13-14 longest common subsequences 15-19 n-gram precision against a target corpus(1&lt;n&lt;5) Table 1: Feature sets for regression learning can easily retrain the learner under different conditions, therefore enabling our method to be applied to sentence-level translation selection from any sets of translation systems without any additional human work. In regression learning, we infer a function f that maps a multi-dimensional input vector x to a continuous real value y, such that the error over a set of m traini</context>
</contexts>
<marker>Lavie, Agarwal, 2007</marker>
<rawString>Alon Lavie and Abhaya Agarwal. 2007. METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments. In Proceedings of Workshop on Statistical Machine Translation at the 45th Annual Meeting of the Association of Computational Linguistics, pages 228– 231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="9593" citStr="Och (2003)" startWordPosition="1523" endWordPosition="1524">ach pi can be translated into m target sentences ti1, ti2, ..., tim. We rescore all the n x m candidates using both the source-pivot and pivot-target translation scores following the method described in Utiyama and Isahara (2007). If we use hfp and hpt to denote the features in the source-pivot and pivot-target systems, respectively, we get the optimal target translation according to the following formula. (λspk hspk (s,p)+λpt k hpt k (p, t)) (4) Where L is the number of features used in SMT systems. λsp and λpt are feature weights set by performing minimum error rate training as described in Och (2003). 2.3 Synthetic Method There are two possible methods to obtain a sourcetarget corpus using the source-pivot and pivottarget corpora. One is to obtain target translations for the source sentences in the source-pivot corpus. This can be achieved by translating the pivot sentences in source-pivot corpus to target sentences with the pivot-target SMT system. The other is to obtain source translations for the target sentences in the pivot-target corpus using the pivot-source SMT system. And we can combine these two source-target corpora to produced a final synthetic corpus. Given a pivot sentence, </context>
<context position="19046" citStr="Och, 2003" startWordPosition="3072" endWordPosition="3073">aken from the training sets, with 3 reference translations in both English and Spanish. This development set is also used to train the regression learning model. 5.2 Systems and Evaluation Method We used two commercial RBMT systems in our experiments: System A for Chinese-English bidirectional translation and System B for EnglishChinese and English-Spanish translation. For phrase-based SMT translation, we used the Moses decoder (Koehn et al., 2007) and its support training scripts. We ran the decoder with its default settings and then used Moses’ implementation of minimum error rate training (Och, 2003) to tune the feature weights on the development set. To select translation among outputs produced by different pivot translation systems, we used SVM-light (Joachins, 1999) to perform support vector regression with the linear kernel. Translation quality was evaluated using both the BLEU score proposed by Papineni et al. (2002) and also the modified BLEU (BLEU-Fix) score3 used in the IWSLT 2008 evaluation campaign, where the brevity calculation is modified to use closest reference length instead of shortest reference length. 5.3 Results by Using SMT Systems We conducted the pivot translation ex</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz J. Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="15011" citStr="Papineni et al., 2002" startWordPosition="2400" endWordPosition="2403">ative values of the scores assigned by the subject systems may change. In order to train a reliable learner, we need to prepare a balanced training set, where the translations produced by different systems under different conditions are required to be manually evaluated. In extreme cases, we need to relabel the training data to obtain better performance. In this paper, we modify the method in Albrecht and Hwa (2007) to only prepare human reference translations for the training examples, and then evaluate the translations produced by the subject systems against the references using BLEU score (Papineni et al., 2002). We use smoothed sentence-level BLEU score to replace the human assessments, where we use additive smoothing to avoid zero BLEU scores when we calculate the n-gram precisions. In this case, we ID Description 1-4 n-gram precisions against pseudo references(1 &lt; n &lt; 4) 5-6 PER and WER 7-8 precision, recall, fragmentation from METEOR (Lavie and Agarwal, 2007) 9-12 precisions and recalls of nonconsecutive bigrams with a gap size of m (1 &lt; m &lt; 2) 13-14 longest common subsequences 15-19 n-gram precision against a target corpus(1&lt;n&lt;5) Table 1: Feature sets for regression learning can easily retrain t</context>
<context position="19374" citStr="Papineni et al. (2002)" startWordPosition="3119" endWordPosition="3122">m B for EnglishChinese and English-Spanish translation. For phrase-based SMT translation, we used the Moses decoder (Koehn et al., 2007) and its support training scripts. We ran the decoder with its default settings and then used Moses’ implementation of minimum error rate training (Och, 2003) to tune the feature weights on the development set. To select translation among outputs produced by different pivot translation systems, we used SVM-light (Joachins, 1999) to perform support vector regression with the linear kernel. Translation quality was evaluated using both the BLEU score proposed by Papineni et al. (2002) and also the modified BLEU (BLEU-Fix) score3 used in the IWSLT 2008 evaluation campaign, where the brevity calculation is modified to use closest reference length instead of shortest reference length. 5.3 Results by Using SMT Systems We conducted the pivot translation experiments using the BTEC CE1 and BTEC ES described in Section 5.1. We used the three methods described in Section 2 for pivot translation. For the transfer method, we selected the optimal translations among 10 x 10 candidates. For the synthetic method, we used the ES translation model to translate the English part of the CE co</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Paul</author>
</authors>
<title>Overview of the IWSLT</title>
<date>2008</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation,</booktitle>
<pages>1--17</pages>
<contexts>
<context position="2207" citStr="Paul, 2008" startWordPosition="327" endWordPosition="328">as the travel domain. It is especially difficult to obtain such a domain-specific corpus for some language pairs such as Chinese to Spanish translation. To circumvent the data bottleneck, some researchers have investigated to use a pivot language approach (Cohn and Lapata, 2007; Utiyama and Isahara, 2007; Wu and Wang 2007; Bertoldi et al., 2008). This approach introduces a third language, named the pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. A pivot task was also designed for spoken language translation in the evaluation campaign of IWSLT 2008 (Paul, 2008), where English is used as a pivot language for Chinese to Spanish translation. Three different pivot strategies have been investigated in the literature. The first is based on phrase table multiplication (Cohn and Lapata 2007; Wu and Wang, 2007). It multiples corresponding translation probabilities and lexical weights in source-pivot and pivot-target translation models to induce a new source-target phrase table. We name it the triangulation method. The second is the sentence translation strategy, which first translates the source sentence to the pivot sentence, and then to the target sentence</context>
</contexts>
<marker>Paul, 2008</marker>
<rawString>Michael Paul. 2008. Overview of the IWSLT 2008 Evaluation Campaign. In Proceedings of the International Workshop on Spoken Language Translation, pages 1–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A Comparison of Pivot Methods for Phrase-Based Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of human language technology: the Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>484--491</pages>
<contexts>
<context position="1901" citStr="Utiyama and Isahara, 2007" startWordPosition="277" endWordPosition="280">ora to produce translations of relatively higher quality. Unfortunately, large quantities of parallel data are not readily available for some languages pairs, therefore limiting the potential use of current SMT systems. In particular, for speech translation, the translation task often focuses on a specific domain such as the travel domain. It is especially difficult to obtain such a domain-specific corpus for some language pairs such as Chinese to Spanish translation. To circumvent the data bottleneck, some researchers have investigated to use a pivot language approach (Cohn and Lapata, 2007; Utiyama and Isahara, 2007; Wu and Wang 2007; Bertoldi et al., 2008). This approach introduces a third language, named the pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. A pivot task was also designed for spoken language translation in the evaluation campaign of IWSLT 2008 (Paul, 2008), where English is used as a pivot language for Chinese to Spanish translation. Three different pivot strategies have been investigated in the literature. The first is based on phrase table multiplication (Cohn and Lapata 2007; Wu and Wang, 2007). It multiples corresponding translation probabi</context>
<context position="9212" citStr="Utiyama and Isahara (2007)" startWordPosition="1452" endWordPosition="1455"> the co-occurring frequency of the word pair (s, t). 2.2 Transfer Method The transfer method first translates from the source language to the pivot language using a source-pivot model, and then from the pivot language to the target language using a pivot-target model. Given a source sentence s, we can translate it into n pivot sentences p1, p2, ..., pn using a source-pivot translation system. Each pi can be translated into m target sentences ti1, ti2, ..., tim. We rescore all the n x m candidates using both the source-pivot and pivot-target translation scores following the method described in Utiyama and Isahara (2007). If we use hfp and hpt to denote the features in the source-pivot and pivot-target systems, respectively, we get the optimal target translation according to the following formula. (λspk hspk (s,p)+λpt k hpt k (p, t)) (4) Where L is the number of features used in SMT systems. λsp and λpt are feature weights set by performing minimum error rate training as described in Och (2003). 2.3 Synthetic Method There are two possible methods to obtain a sourcetarget corpus using the source-pivot and pivottarget corpora. One is to obtain target translations for the source sentences in the source-pivot cor</context>
</contexts>
<marker>Utiyama, Isahara, 2007</marker>
<rawString>Masao Utiyama and Hitoshi Isahara. 2007. A Comparison of Pivot Methods for Phrase-Based Statistical Machine Translation. In Proceedings of human language technology: the Conference of the North American Chapter of the Association for Computational Linguistics, pages 484–491.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haifeng Wang</author>
<author>Hua Wu</author>
<author>Xiaoguang Hu</author>
<author>Zhanyi Liu</author>
<author>Jianfeng Li</author>
<author>Dengjun Ren</author>
<author>Zhengyu Niu</author>
</authors>
<date>2008</date>
<booktitle>The TCH Machine Translation System for IWSLT</booktitle>
<pages>124--131</pages>
<contexts>
<context position="31499" citStr="Wang et al. (2008)" startWordPosition="5100" endWordPosition="5103">h indicates that our method using RBMT systems to fill up the data gap is effective. The results also indicate that our translation selection method for pivot translation outperforms the method using only a real sourcetarget corpus. For comparison purpose, we added BTEC CE1 into the training data. The translation quality was improved by only 1 BLEU score. This again proves that our method to fill up the data gap is more effective than that to increase the size of the independently sourced corpus. 6.3 Comparison with Related Work In IWSLT 2008, the best result for the pivot task is achieved by Wang et al. (2008). In order to compare the results, we added the bilingual HIT Ours Wang TSAL BLEU 49.57 - 48.25 BLEU-Fix 46.74 45.10 45.27 Table 8: Comparison with related work Olympic corpus into the CE training data.9 We also compared our translation selection method with that proposed in (Wang et al., 2008) that is based on the target sentence average length (TSAL). The translation results are shown in Table 8. ”Wang” represents the results in Wang et al. (2008). ”TSAL” represents the translation selection method proposed in Wang et al. (2008), which is applied to our experiment. From the results, it can b</context>
</contexts>
<marker>Wang, Wu, Hu, Liu, Li, Ren, Niu, 2008</marker>
<rawString>Haifeng Wang, Hua Wu, Xiaoguang Hu, Zhanyi Liu, Jianfeng Li, Dengjun Ren, and Zhengyu Niu. 2008. The TCH Machine Translation System for IWSLT 2008. In Proceedings of the International Workshop on Spoken Language Translation, pages 124–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Wu</author>
<author>Haifeng Wang</author>
</authors>
<title>Pivot Language Approach for Phrase-Based Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>856--863</pages>
<contexts>
<context position="1919" citStr="Wu and Wang 2007" startWordPosition="281" endWordPosition="284"> of relatively higher quality. Unfortunately, large quantities of parallel data are not readily available for some languages pairs, therefore limiting the potential use of current SMT systems. In particular, for speech translation, the translation task often focuses on a specific domain such as the travel domain. It is especially difficult to obtain such a domain-specific corpus for some language pairs such as Chinese to Spanish translation. To circumvent the data bottleneck, some researchers have investigated to use a pivot language approach (Cohn and Lapata, 2007; Utiyama and Isahara, 2007; Wu and Wang 2007; Bertoldi et al., 2008). This approach introduces a third language, named the pivot language, for which there exist large source-pivot and pivot-target bilingual corpora. A pivot task was also designed for spoken language translation in the evaluation campaign of IWSLT 2008 (Paul, 2008), where English is used as a pivot language for Chinese to Spanish translation. Three different pivot strategies have been investigated in the literature. The first is based on phrase table multiplication (Cohn and Lapata 2007; Wu and Wang, 2007). It multiples corresponding translation probabilities and lexical</context>
<context position="7216" citStr="Wu and Wang (2007)" startWordPosition="1116" endWordPosition="1119">ish corpus; (3) Our sentence-level translation selection method consistently and significantly improves the translation quality over individual translation outputs in all of our experiments. Section 2 briefly introduces the three pivot translation methods. Section 3 presents the hybrid method combining SMT and RBMT systems. Section 4 describes the translation selection method. Experimental results are presented in Section 5, followed by a discussion in Section 6. The last section draws conclusions. 2 Pivot Methods for Phrase-based SMT 2.1 Triangulation Method Following the method described in Wu and Wang (2007), we train the source-pivot and pivot-target translation models using the source-pivot and pivot-target corpora, respectively. Based on these two models, we induce a source-target translation model, in which two important elements need to be induced: phrase translation probability and lexical weight. Phrase Translation Probability We induce the phrase translation probability by assuming the independence between the source and target phrases when given the pivot phrase. φ(¯s|¯t) = � φ(¯s|¯p)φ(¯p|¯t) (1) p� Where ¯s, p¯ and t represent the phrases in the languages L3, Lp and Lt, respectively. Le</context>
</contexts>
<marker>Wu, Wang, 2007</marker>
<rawString>Hua Wu and Haifeng Wang. 2007. Pivot Language Approach for Phrase-Based Statistical Machine Translation. In Proceedings of 45th Annual Meeting of the Association for Computational Linguistics, pages 856–863.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>