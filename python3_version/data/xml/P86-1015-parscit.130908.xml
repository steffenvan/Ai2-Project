<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.027856">
<title confidence="0.983697">
A MODEL OF REVISION IN NATURAL LANGUAGE GENERATION
</title>
<author confidence="0.9684885">
Marie M. Vaughan
David D. McDonald
</author>
<affiliation confidence="0.910248666666667">
Department of Computer and Information Science
University of Massachusetts
Amherst, Massachusetts 01003
</affiliation>
<sectionHeader confidence="0.860697" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999530722222222">
We outline a model of generation with
revision, focusing on improving textual coherence.
We argue that high quality text is more easily
produced by iteratively revising and regenerating, as
people do, rather than by using an architecturally
more complex single pass generator. As a general
area of study, the revision process presents
interesting problems: Recognition of flaws in text
requires a descriptive theory of what constitutes
well written prose and a parser which can build a
representation in those terms. Improving text
requires associating flaws with strategies for
improvement. The strategies, in turn, need to know
what adjustments to the decisions made during the
initial generation will produce appropriate
modifications to the text. We compare our treatment
of revision with those of Mann and Moore (1981),
Gabriel (1984), and Mann (1983).
</bodyText>
<sectionHeader confidence="0.998701" genericHeader="introduction">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.99969424137931">
Revision is a large part of the writing process
for people. This is one respect in which writing
differs from speech. In ordinary conversation we do
not rehearse what we are going to say; however,
when writing a text which may be used more than
once by an audience which is not present, we use a
multipass system of writing and rewriting to produce
optimal text. By reading what we write, we seem
better able to detect flaws in the text and see new
options for improvement.
Why most people are not able to produce
optimal text in one pass is an open and interesting
question. Flower and Hayes (1980) and Collins and
Gentner (1980) suggest that writers are unable to
juggle the excessive number of simultaneous
demands and constraints which arise in producing
well written text. Writers must concentrate not only
on expressing content and purpose, but also on the
discourse conventions of written prose: the
constraints on sentence, paragraph, and text
structure which are designed to make texts more
readable. Successive iterations of writing and
revising may allow the writer to reduce the number
of considerations demanding attention at a given
time.
The developers of natural language generation
systems must also address the problem of how to
produce high quality text. Most systems today
concentrate on the production of dialogs or
commentaries, where the texts are generally short
and the coherence is strengthened by nonlinguistic
context. However, in written documents coherence
must be maintained by the text alone. In addition,
written text must anticipate the questions of its
readers. The text must be clear and well organized
so that the reader may follow the points easily, and
it must be concise and interesting so as to hold the
reader&apos;s attention. These considerations place
greater demands on a generation system.
Most natural language generation systems
generate in a single pass with no revision. A
drawback of this approach is that the information
necessary for decision making must be structured so
that at any given point the generator has enough
information to make an optimal decision. While
many decisions require only local information,
decisions involving long range dependencies, such as
maintaining coherence, may require not only a
history of the decisions made so far, but also
predictions of what future decisions might be made
and the interactions between those decisions.
An alternative approach is a single pass
system which incorporates provisions for revision of
its internal representations at specific points in the
generation process (Mann &amp; Moore, 1981; Gabriel,
1984). Evaluating the result of a set of decisions
after they have been made allows a more
parsimonious distribution of knowledge since specific
</bodyText>
<page confidence="0.996447">
90
</page>
<bodyText confidence="0.999970119047619">
types of improvements may be evaluated at
different stages. Interactions among the decisions
made so far may also be evaluated rather than
predicted. The problem remains, however, of not
being able to take into account the interaction with
future decisions.
A third approach, and the one described in
this paper, is to use the writing process as a model
and to improve the text in successive passes. A
generation/revision system would include a
generator, a parser, and an evaluation component
which would assess the parse of what the generator
had produced and determine strategies for
improvement. Such a system would be able to tailor
the degree of refinement to the particular context
and audience. In an interactive situation the system
may make no refinements at all, as in &amp;quot;off the cuff&amp;quot;
speech; when writing a final report, where the
quality of the text is more important than the speed
of production, it may generate several drafts.
While single pass approaches may be
engineered to give them the ability to produce high
quality text, the parser-mediated revision approach
has several advantages. Using revision can reduce
the structural demands on the generator&apos;s
representations, and thus reduce the overall
complexity of the system. Since the revision
component is analyzing actual text with a parser, it
can assess long range dependencies naturally
without needing to keep a history within the
generator or having it predict what decisions it might
make later.
Revision also creates an interesting research
context for examining both computational and
psychological issues. In a closed loop system, the
generator and parser must interact closely. This
provides an opportunity to examine how these
processes differ and what knowledge may be shared
between them. In a similar vein, we may use a
computational model of the revision task to assess
the computational implications of proposed
psychological theories of the writing process.
</bodyText>
<sectionHeader confidence="0.998568" genericHeader="method">
2. DEFINING THE PROBLEM
</sectionHeader>
<bodyText confidence="0.999642431034483">
In order to make research into the problem of
revision tractable, we need to first delimit the
criteria by which to evaluate the text. They need to
be broad enough to make a significant improvement
in the readability of the text, narrow enough to be
defined in terms of a representation a parser could
build today, and have associated strategies for
improvement that are definable in terms understood
by the text planner and generator. In addition, we
would like to delegate to the revision component
those decisions which would be difficult for a
generator to make when initially producing the text.
As textual coherence often requires awareness of
long range dependencies, we will begin by
considering it an appropriate category of evaluation
for a revision component.
Coherence in text comes from a number of
different sources. One is simply the reference made
to earlier words and phrases in the text through
anaphoric and cataphoric pronominal references;
nominal, verbal and clausal substitution of phrases
with elements such as &apos;one&apos;, &apos;do&apos;, and &apos;so&apos;; ellipsis; and
the selection of the same item twice or two items
that are closely related. Coreferences create textual
cohesion since the interpretation of one element in
the text is dependent on another (Halliday and
Hansan. 1976).
Scinto (1983) describes a narrower type of
cohesion which operates between successive
predicational units of meaning (roughly clauses).
These units can be described in terms of their
&amp;quot;theme&amp;quot; (what is being talked about) and &amp;quot;rheme&amp;quot;
(what is being said about it). Thematic progression is
the organization of given and new information into
theme-rheme patterns in successive sentences.
Preliminary studies have shown (Glatt, 1982) that
thematic progressions in which the theme of a
sentence is coreferential with the theme or the
rheme of the immediately preceding sentence are
easier to comprehend than those with other thematic
progressions. This ease of comprehension can be
attributed to the fact that the connection of the
sentence with previous text comes early in the
sentence. It would appear that the longer the reader
must wait for the connection, the more difficult the
integration with previous information will be.
Another source of coherence is lexical
connectives, such as sentential adjuncts (&apos;first&apos;, for
example&apos;, &apos;however&apos;), adverbials (&apos;subsequently&apos;,
&apos;accordingly&apos;, &apos;actually&apos;), and subordinate and
coordinate conjunctions (&apos;while&apos;, &apos;because&apos;, but&apos;).
These connectives are used to express the abstract
relation between two propositions explicitly, rather
than leaving it to the reader to infer. Other ways of
combining sentences can function to increase
coherence as well. Chafe (1984) enumerates the
devices used to combine &amp;quot;idea units&amp;quot; in written text
including turning predications into modificatir
</bodyText>
<page confidence="0.993714">
91
</page>
<bodyText confidence="0.99959565">
with attributive adjectives, preposed and postposed
participles, and combining sentences using
complement and relative clauses, appositives, and
participle clauses. These structures function to
increase connectivity by making the text more
concise.
Paragraph structure also contributes to the
coherence of a text. &amp;quot;Paragraph&amp;quot; in this sense
(Longacre, 1979) refers to a structural unit which
does not necessarily correspond to the orthographic
unit indicated by an indentation of the text.
Paragraphs are characterized by closure (a beginning
and end) and internal unity. They may be marked
prosodically by intonation in speech or
orthographically by indentation in writing, and
structurally, such as by initial sentence adjuncts.
Paragraphs are recursive structures, and thus may
be composed of embedded paragraphs. In this
respect they are similar to Mann&apos;s rhetorical
discourse structures (Mann, 1984).
</bodyText>
<sectionHeader confidence="0.781038" genericHeader="method">
3_ A MODEL OF GENERATION AND REVISION
</sectionHeader>
<bodyText confidence="0.983674117647059">
In this section we will outline a model of
generation with revision, focusing on improving
textual coherence. First we establish a division of
labor within the generation/revision process. Then
we look at the phases of revision and consider the
capabilities necessary for recognizing deficiencies in
cohesion and how they may be repaired. In the
fourth section, we apply this model to the revision of
an example summary paragraph.
The initial generation of a text involves
making decisions of various kinds. Some are
conceptually based, such as what information to
include and what perspectives to take. Others are
grammatically based, such as what grammatical form
a concept may take in the particular syntactic
context in which it is being realized, or how
structures may be combined. Still others are
essentially stylistic and have many degrees of
freedom, such as choosing a variant of a clause or
whether to pied pipe in a relative clause.
The decisions that revision affects are at the
stylistic level; only stylistic decisions are free of fixed
constraints and may therefore be changed. Changes
to conceptually dictated decisions would shift the
meaning of the text. During initial generation,
euristics for maintaining local cohesion are used.
&apos;ging on the representations of simple local
Tidencies. By &amp;quot;local&amp;quot;, we mean specifically that
we restrict the scope of information available to the
generator to the sentence before, so that it can use
thematic progression heuristics, letting revision take
care of longer range coherence considerations.
The revision process can be modeled in terms of
three phases:
</bodyText>
<listItem confidence="0.99118375">
1) recognition, which determines where there
are potential problems in the text;
2) editing, which determines what strategies
for revision are appropriate and chooses which, if
any, to employ;
3) re-generation, which employs the chosen
strategy by directing the decision making in the
generation of the text at appropriate moments.
</listItem>
<bodyText confidence="0.999385411764706">
This division reflects an essential difference in the
types of decisions being made and the character of
representations being used in each phase.
The recognition phase is responsible for
parsing the text and building a representation rich
enough to be evaluated in terms of how well the text
coheres. Since in this model the system is evaluating
its own output, it need not rely only on the output
text in making its judgements; the original message
input to the generator is available as a basis for
comparing what was intended with what was
actually said. The goal is to notice the relationships
among the things mentioned in the text and the
degree to which the relationships appear explicitly.
For example, the representation must capture
whether a noun phrase is the first reference to an
object or a subsequent reference, and if it is a
subsequent reference, where and how it was
previously mentioned. The recognition phase
analyzes the text as it proceeds using a set of
evaluation criteria. Some of these criteria look
through the representation for specific flaws, such as
ambiguous referents, while others simply flag places
where optimizations may be possible, such as
predicate nominal or other simple sentence
structures which might be combined with other
sentences. Other criteria compare the representation
with the original plan in order to flag potential places
for revision such as parallel sub-plans not realized in
parallel text structure, or relations included in the
plan which are expressed implicitly, rather than
explicitly, in the text.
Once a potential problem has been noted, the
editing phase takes over. For each problem there is
</bodyText>
<page confidence="0.980522">
92
</page>
<bodyText confidence="0.9999132">
a set of one or more strategies for correcting it. For
example, if there is no previous referent for the
subject of a sentence, but there is a previous
reference to the object, the sentence might be
changed from active to passive; or if the subject has
a relation to previous referent which is not explicitly
mentioned in the text, more information may be
added through modification to make that implicit
connection explicit. The task of the editing phase is
to determine which, if any, of these strategies to
employ. (It may, for example decide not to take any
action until further text has been analyzed.)
However, what constitutes an improvement is not
always clear. While using the passive may
strengthen the coherency, active sentences are
generally preferred over passives. And while adding
more information may strengthen a referent, it may
also make the noun phrase too heavy if there are
already modifications. The criteria that choose
between strategies must take into account the fact
that the various dimensions along which the text
may be evaluated are often in conflict. Simple
evaluation functions will not suffice.
The final step is actually making the change
once the strategy has been chosen. This essentially
involves &amp;quot;marking&amp;quot; the input to the generator, so that
it will query the revision component at appropriate
decision points. For example, if the goal is to put two
sentences into parallel structure, the input plan
which produces the structure to be changed would
be marked. Then, when the generator reached that
unit, it would query the revision component as to
where the unit should be put in the text (e.g. a main
clause or a subordinate one) and how it should be
realized (e.g. active or passive).
Note that as the revision process proceeds, it is
continually dealing with a new text and plan, and
must update its representations accordingly. New
opportunities for changes will be created and
previous ones blocked. We have left open the
question of how the system decides when it is done.
With a limited set of evaluation criteria, the system
may simply run out of strategies for improvement.
The question will be more easily answered
empirically when the system is implemented.
An important architectural point of the design
is that the system is not able to look ahead to
consider later repercussions of a change; it is
constrained to decide upon a course of action
considering only the current state of the textual
analysis and the original plan. While this constraint
obviates the problems of the combinatorial explosion
Of potential versions and indefinite lookahead, we
must guard against the possibility of a choice causing
unforeseen problems in later steps of the revision
process. One way to avoid this problem is to keep a
version of the text for each change made and allow
the system to return to a previous draft if none of
the strategies available could sufficiently improve
the text.
</bodyText>
<sectionHeader confidence="0.974444" genericHeader="method">
4. PARAGRAPH ANALYSIS
</sectionHeader>
<bodyText confidence="0.999926131578947">
In this section we use the model outlined
above to describe how the revision component could
improve a generated text. What follows is an
example of the incremental revision of a summary
paragraph. The discussion at each step gives an
indication of the character of information needed
and the types of decisions made in the recognition,
editing, and regeneration phases.
The example is from the UMass COUNSELOR
Project, which is developing a natural language
discourse system based on the HYPO legal reasoning
system (Rissland, Valcarce, 8c Ashley, 1984). The
immediate context is a dialog between a lawyer and
the COUNSELOR system. Based on information from
the lawyer, the system has determined that the
lawyer&apos;s case might be argued along the dimension
&amp;quot;common employee transferred products or tools&amp;quot;.
The system summarizes a similar case that has been
argued along the same dimension as an example.
The information to be included in the summary is
chosen from the set of factual predicates that must
be satisfied in order for the particular dimension to
POT
In the initial generation of the summary, the
overall organization is guided by a default paragraph
organization for a case summary. The first sentence
functions to introduce the case and place it as an
example of the dimension in question. The body
presents the facts of the case organized according to
a partial ordering based on the chronology of the
events. The final sentence summarizes the case by
giving the action and decision. The choice of text
structure is guided by simple heuristics which
combine sentences when possible and choose a
structure for a new sentence based on thematic
progression, so that the subject of the new sentence
is related to the theme or rheme of the previous
sentence.
</bodyText>
<page confidence="0.997432">
93
</page>
<bodyText confidence="0.987363956989248">
(1) The case Telex vs. IBM was argued along
the dimension &amp;quot;common employee transferred
products or tools&amp;quot;. IBM developed the product
Merlin, which is a disk storage system. Merlin
competes with the T-6830, which was developed
by Telex. The manager on the Merlin
development project was Clemens. He left IBM in
1972 to work for Telex and took with him a copy
of the Merlin code. IBM sued Telex for
misappropriation of trade secret information and
won the case.
The recognition phase analyzes the text,
looking for both flaws in the text and missed
opportunities. The repetition of the word &amp;quot;develop&amp;quot;
in the second and third sentences alerts the editing
phase to consider whether a different word should
be chosen to avoid repetition, or the repetition
should be capitalized on to create parallel structure.
By examining the input message, it determines that
these clauses were realized from parallel plans, so it
chooses to realize them in parallel structure.
In the regeneration phase, the message is
marked so that the revision component can be
queried at the appropriate moments to control when
and how the information unit for &amp;quot;Telex developed
the T-6830&amp;quot; will be realized. After generation of the
second sentence, the generator has the choice of
attaching either &lt;develop Telex 1-6830&gt; or &lt;compete
Merlin T-6830&gt; as the next sentence. As one of these
has been marked, the revision component is queried.
Its goal is to make this sentence parallel to the
previous one, so it indicates that the marked unit,
&lt;develop ...&gt;, should be the next main clause and
should be realized in the active voice. Once that has
been accomplished, the default generation heuristics
take over to attach &lt;competes with...&gt; as a relative
clause:
(2) The case Telex vs. IBM was argued along
the dimension &amp;quot;common employee transferred
products or tools&amp;quot;. IBM developed the product
Merlin, which is a disk storage system. Telex
developed the 1-6830, which competes
with Merlin. The manager on the Merlin
development project was Clemens. He left IBM in
1972 to work for Telex and took with him a copy
of the Merlin code. IBM sued Telex for
misappropriation of trade secret information and
won the case.
Once the change is completed, the recognition
phase takes over once again. It notices that sentence
four no longer follows a preferred thematic
progression as &amp;quot;Merlin&amp;quot; is no longer a theme or
rheme of the previous sentence. It considers the
following possibilities:
-- Create a theme-theme progression by
moving sentence five before sentence four and
beginning it with &amp;quot;Telex&amp;quot;, as in: &amp;quot;Telex was who
Clemens worked for after he left IBM in 1972.&amp;quot;
(Note there are no other possibilities for preferred
thematic progressions without changing previous
sentences.)
-- Reject the previous change which created
the parallel structure and go back to the original
draft.
-- Leave the sentence as it is. Although there
is no preferred thematic progression, cohesion is
created by the repetition of &amp;quot;Merlin&amp;quot; in the two
sentences.
-- Create an internal paragraph break by using
&amp;quot;in 1972&amp;quot; as an initial adjunct. This signals to the
reader that there is a change of focus and reduces
the expectation of a strong connection with the
previous sentences.
The editor chooses the fourth strategy, since
not only does it allow the previous change to be
retained, but it imposes additional structure on the
paragraph. Again during the regeneration phase the
editor marks the information unit in the message
which is to be realized differently in the new draft.
Default generation heuristics choose to realize
&amp;quot;Clemens&amp;quot; as a name, rather than a pronoun as it had
been, and to attach &amp;quot;the manager...&amp;quot; as an appositive.
(3) The case Telex vs. IBM was argued along
the dimension &amp;quot;common employee transferred
products or tools&amp;quot;. IBM developed the product
Merlin, which is a disk storage system. Telex
developed the T-6830, which competes with
Merlin. In 1972, Clemens. the manager on
the Merlin development project, left IBM
to work for Telex and took with him a
copy of the Merlin code. IBM sued Telex for
misappropriation of trade secret information and
won the case.
</bodyText>
<sectionHeader confidence="0.986785" genericHeader="method">
5. OTHER REVISION SYSTEMS
</sectionHeader>
<bodyText confidence="0.876060222222222">
Few generation systems address the question
of using successive refinement to improve their
output. Some notable exceptions are KDS (Mann &amp;
Moore, 1981), Yh (Gabriel, 1982), and Penman
(Mann, 1983). KDS and Yh use a top down approach
where intermediate representations are evaluated
and improved before any text is actually generated;
Penman uses a cyclic approach similar to that
described here.
</bodyText>
<page confidence="0.998434">
94
</page>
<bodyText confidence="0.999962287878788">
KDS uses a hill climbing module to improve
text. Once a set of protosentences has been produced
and grossly organized, the hill climber attempts to
compose complex protosentences from simple ones
by applying a set of aggregation rules, which
correspond roughly to English clause combining
rules. Next, the hill climber uses a set of preference
rules to judge the relative quality of the resulting
units and repeatedly improves the set of
protosentences on the basis of those judgements.
Finally, a simple linguistic component realizes the
units as sentences.
There are two main differences between this
system and the one described in this paper. First,
KDS uses a quantitative measure of evaluation in the
form of preference rules which are stated
independently of any linguistic context. The score
assigned to a particular construction or combination
of units does not consider which rules have been
applied in nearby sentences. Consequently,
intersentential relations cannot be used to evaluate
the text for more global considerations. Secondly,
KDS evaluates an intermediate structure, rather than
the final text. Therefore, realization decisions, such
as those made by ICDS&apos;s Referring Phrase Generator,
have not yet been made. This makes evaluating the
strength of coherence difficult, since it is not possible
to determine whether a connection will be made
through modification.
Yh also uses a top down improvement
algorithm, however rather than having a single
improvement module which applies one time, it
evaluates and improves throughout the generation
process. The program consists of a set of experts
which do such things as construct phrases, construct
sentences, and supply words and idioms. The
&amp;quot;planner&amp;quot; tries to find a sequence of experts that will
transform the initial situation (initially a
specification to be generated) to a goal situation
(ultimately text). First, experts which group the
information into paragraph size sets are applied;
then other experts divide those sets into sentence
size chunks; next, sentence schemata experts
determine sentence structure; and finally experts
which choose lexical items and generate text apply.
After each expert applies, critics evaluate the result
and may call an expert to improve it. Like KDS, this
type of approach makes editing of global coherence
considerations difficult since structural decisions are
made before lexical choices.
The Penman System is the most similar to the
one described in this paper. The principle data flow
and division of labor into modules are the same:
planning, sentence generation, improvement.
However, an important difference is that Penman
does not parse the text in order to revise it. Rather it
uses quantitative measures, such as sentence length
and level of clause embeddings to flag potential
trouble spots. While this approach may improve text
along some dimensions, it will not be capable of
improving relations such as coherence, which depend
on understanding the text. A similarity between
Penman&apos;s revision module and the model described
in this paper is that neither has been implemented.
As the two systems mature, a more complete
comparison may be made.
</bodyText>
<sectionHeader confidence="0.998794" genericHeader="conclusions">
6. CONCLUSION
</sectionHeader>
<bodyText confidence="0.9999885">
Using the writing process as a model for
generation is effective as a means of improving the
quality of the text generated, especially when
considering intersentential relations such as
coherence. Decisions which increase coherence are
difficult for a generator to make on a first pass
without keeping an elaborate history of its previous
decisions and being able to predict future decisions.
Once the text has been generated however, revision
can take advantage of the global information
available to evaluate and improve coherence.
The next steps in the development of the
system proposed in this paper are clear: For the
recognition phase, a more comprehensive set of
evaluation criteria need to be enumerated and the
requirements they place on a parser specified. For
the editing phase, the relationships between
strategies for improving text, and changes in
generation decisions and variation in output text
need to be explored. Finally, a prototypical model of
the system needs to be implemented so that the
actual behavior of the system may be studied.
</bodyText>
<sectionHeader confidence="0.9726" genericHeader="references">
7_ ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.999597666666667">
We would like to thank John Brolio and Philip
Werner for their helpful commentary in the
preparation of this paper.
</bodyText>
<page confidence="0.997039">
95
</page>
<reference confidence="0.98977796969697">
E. REFERENCES
Chafe, Wallace L. (1985) &amp;quot;Linguistic Differences
Produced by Differences Between Speaking and
Writing&amp;quot;, in Olson, David K., Nancy Torrance, &amp;
Angela Hildyard, eds. Literacy, Language and
Learning: The nature and consequences of
reading and writing, Cambridge University
Press, pp. 105-123.
Clippinger, John, &amp; David D. McDonald (1983) &amp;quot;What
makes Good Writing Easier to Understand&amp;quot;, lJCA I
Proceedings, pp.730-732.
Collins, Allan &amp; Dedre Gentner (1980) &amp;quot;A Framework
for a Cognitive Theory of Writing&amp;quot;, in Gregg &amp;
Steinburg, eds, pp. 5 1-72.
Flower, Linda &amp; John Hayes (1980) &amp;quot;The Dynamics of
Composing: Making Plans and Juggling
Constraints&amp;quot;, in Gregg &amp; Steinberg, eds, pp. 31-50.
Gabriel, Richard (1984) &amp;quot;Deliberate Writing&amp;quot;, to
appear in McDonald &amp; Bolc, eds. Papers on
Natural Language Generation, Springer-
Verlag, 1987.
Glatt, Barabara S. (1982) &amp;quot;Defining Thematic
Progressions and Their Relationships to Reader
Comprehension&amp;quot;, in Nystrand, Martin, ed. What
Writers (BOW: the language, process, and
structure of written discourse, New York, NY:
Academic Press, pp. 87-104.
Gregg, L. St E.R. Steinberg, eds. (1980) Cognitive
Processes in Writthg, Hilldale, NJ: Lawrence
Erlbaum Associates.
Halliday, M.A.IC., &amp; Rusgaiya Hasan (1976) Cohesion
in English, London: Longman Group Ltd.
Hayes, John, &amp; Linda Fower (1980) &amp;quot;Identifying the
Organization of Writing Processes&amp;quot;, in Gregg &amp;
Steinberg (Eds), pp. 3-30.
Longacre, R.E. (1979) &amp;quot;The Paragraph as a
Grammatical Unit&amp;quot;, in Syntax and Semantics,
Vol. 12: Discourse and Syntax, Academic
Press, PP. 115-134-
Mann, William C. &amp; James Moore (1981) &amp;quot;Computer
Generation of Multiparagraph English Text&amp;quot;,
American Journal of Computational
Linguistics, Vol.7, No.1, Jan-Mar, pp.17-29.
Mann, William C. (1983) An Overview of the
Penman Text Generation System, USC/ISI
Technical Report RR-83-114.
Mann, William C. (1984) Discourse Structures for
Text GenerationIS1 Technical Report ISI/RR-
84-127.
McDonald, David D. (1985) &amp;quot;Recovering the Speaker&apos;s
Decisions during Mechanical Translation&amp;quot;,
Proceedings of the Conference on
Theoretical and Methodological Issues in
Machine Translation of Natural Languages,
Colgate University, pp.183-199.
McDonald, David D. &amp; James Pustejovsky (1985)
&amp;quot;Description-directed Natural Language
Generation&amp;quot;. IJCA I Proceedings, pp.799-805.
Rissland E., E. Valcarce, &amp; K. Ashley (1984)
&amp;quot;Explaining and Arguing with Examples&amp;quot;,
Proceedings of A A A I -81.
Scinto, Leonard, F.M. (1983) &amp;quot;Functional Connectivity
and the Communicative Structure of Text&amp;quot;, in
Petofi, Janos S. &amp; Emel Sozer, eds. (1983) Micro
and Macro Connexity of Texts, Hamburg:
Buske, pp.73-115-
</reference>
<page confidence="0.998369">
96
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.532293">
<title confidence="0.999466">A MODEL OF REVISION IN NATURAL LANGUAGE GENERATION</title>
<author confidence="0.9999515">Marie M Vaughan David D McDonald</author>
<affiliation confidence="0.9999865">Department of Computer and Information Science University of Massachusetts</affiliation>
<address confidence="0.999919">Amherst, Massachusetts 01003</address>
<abstract confidence="0.999481764705883">We outline a model of generation with revision, focusing on improving textual coherence. We argue that high quality text is more easily produced by iteratively revising and regenerating, as people do, rather than by using an architecturally more complex single pass generator. As a general area of study, the revision process presents interesting problems: Recognition of flaws in text requires a descriptive theory of what constitutes well written prose and a parser which can build a representation in those terms. Improving text requires associating flaws with strategies for improvement. The strategies, in turn, need to know what adjustments to the decisions made during the initial generation will produce appropriate modifications to the text. We compare our treatment</abstract>
<note confidence="0.645128">of revision with those of Mann and Moore (1981), Gabriel (1984), and Mann (1983).</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>E</author>
</authors>
<publisher>REFERENCES</publisher>
<marker>E, </marker>
<rawString>E. REFERENCES</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wallace L Chafe</author>
</authors>
<title>Linguistic Differences Produced by Differences Between Speaking and Writing&amp;quot;,</title>
<date>1985</date>
<booktitle>Literacy, Language and Learning: The nature and consequences of reading and writing, Cambridge</booktitle>
<pages>105--123</pages>
<editor>in Olson, David K., Nancy Torrance, &amp; Angela Hildyard, eds.</editor>
<publisher>University Press,</publisher>
<marker>Chafe, 1985</marker>
<rawString>Chafe, Wallace L. (1985) &amp;quot;Linguistic Differences Produced by Differences Between Speaking and Writing&amp;quot;, in Olson, David K., Nancy Torrance, &amp; Angela Hildyard, eds. Literacy, Language and Learning: The nature and consequences of reading and writing, Cambridge University Press, pp. 105-123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Clippinger</author>
<author>David D McDonald</author>
</authors>
<title>What makes Good Writing Easier to Understand&amp;quot;, lJCA I Proceedings,</title>
<date>1983</date>
<pages>730--732</pages>
<marker>Clippinger, McDonald, 1983</marker>
<rawString>Clippinger, John, &amp; David D. McDonald (1983) &amp;quot;What makes Good Writing Easier to Understand&amp;quot;, lJCA I Proceedings, pp.730-732.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allan Collins</author>
<author>Dedre Gentner</author>
</authors>
<title>A Framework for a Cognitive Theory of Writing&amp;quot;,</title>
<date>1980</date>
<booktitle>in Gregg &amp; Steinburg, eds,</booktitle>
<pages>5--1</pages>
<contexts>
<context position="1703" citStr="Collins and Gentner (1980)" startWordPosition="271" endWordPosition="274">sion is a large part of the writing process for people. This is one respect in which writing differs from speech. In ordinary conversation we do not rehearse what we are going to say; however, when writing a text which may be used more than once by an audience which is not present, we use a multipass system of writing and rewriting to produce optimal text. By reading what we write, we seem better able to detect flaws in the text and see new options for improvement. Why most people are not able to produce optimal text in one pass is an open and interesting question. Flower and Hayes (1980) and Collins and Gentner (1980) suggest that writers are unable to juggle the excessive number of simultaneous demands and constraints which arise in producing well written text. Writers must concentrate not only on expressing content and purpose, but also on the discourse conventions of written prose: the constraints on sentence, paragraph, and text structure which are designed to make texts more readable. Successive iterations of writing and revising may allow the writer to reduce the number of considerations demanding attention at a given time. The developers of natural language generation systems must also address the p</context>
</contexts>
<marker>Collins, Gentner, 1980</marker>
<rawString>Collins, Allan &amp; Dedre Gentner (1980) &amp;quot;A Framework for a Cognitive Theory of Writing&amp;quot;, in Gregg &amp; Steinburg, eds, pp. 5 1-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linda Flower</author>
<author>John Hayes</author>
</authors>
<title>The Dynamics of Composing: Making Plans and Juggling Constraints&amp;quot;,</title>
<date>1980</date>
<journal>in Gregg &amp; Steinberg,</journal>
<volume>eds,</volume>
<pages>31--50</pages>
<contexts>
<context position="1672" citStr="Flower and Hayes (1980)" startWordPosition="266" endWordPosition="269">(1983). 1. INTRODUCTION Revision is a large part of the writing process for people. This is one respect in which writing differs from speech. In ordinary conversation we do not rehearse what we are going to say; however, when writing a text which may be used more than once by an audience which is not present, we use a multipass system of writing and rewriting to produce optimal text. By reading what we write, we seem better able to detect flaws in the text and see new options for improvement. Why most people are not able to produce optimal text in one pass is an open and interesting question. Flower and Hayes (1980) and Collins and Gentner (1980) suggest that writers are unable to juggle the excessive number of simultaneous demands and constraints which arise in producing well written text. Writers must concentrate not only on expressing content and purpose, but also on the discourse conventions of written prose: the constraints on sentence, paragraph, and text structure which are designed to make texts more readable. Successive iterations of writing and revising may allow the writer to reduce the number of considerations demanding attention at a given time. The developers of natural language generation </context>
</contexts>
<marker>Flower, Hayes, 1980</marker>
<rawString>Flower, Linda &amp; John Hayes (1980) &amp;quot;The Dynamics of Composing: Making Plans and Juggling Constraints&amp;quot;, in Gregg &amp; Steinberg, eds, pp. 31-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Gabriel</author>
</authors>
<title>Deliberate Writing&amp;quot;, to appear</title>
<date>1984</date>
<booktitle>Papers on Natural Language Generation,</booktitle>
<editor>in McDonald &amp; Bolc, eds.</editor>
<publisher>SpringerVerlag,</publisher>
<contexts>
<context position="1038" citStr="Gabriel (1984)" startWordPosition="153" endWordPosition="154">architecturally more complex single pass generator. As a general area of study, the revision process presents interesting problems: Recognition of flaws in text requires a descriptive theory of what constitutes well written prose and a parser which can build a representation in those terms. Improving text requires associating flaws with strategies for improvement. The strategies, in turn, need to know what adjustments to the decisions made during the initial generation will produce appropriate modifications to the text. We compare our treatment of revision with those of Mann and Moore (1981), Gabriel (1984), and Mann (1983). 1. INTRODUCTION Revision is a large part of the writing process for people. This is one respect in which writing differs from speech. In ordinary conversation we do not rehearse what we are going to say; however, when writing a text which may be used more than once by an audience which is not present, we use a multipass system of writing and rewriting to produce optimal text. By reading what we write, we seem better able to detect flaws in the text and see new options for improvement. Why most people are not able to produce optimal text in one pass is an open and interesting</context>
<context position="3683" citStr="Gabriel, 1984" startWordPosition="578" endWordPosition="579">ng must be structured so that at any given point the generator has enough information to make an optimal decision. While many decisions require only local information, decisions involving long range dependencies, such as maintaining coherence, may require not only a history of the decisions made so far, but also predictions of what future decisions might be made and the interactions between those decisions. An alternative approach is a single pass system which incorporates provisions for revision of its internal representations at specific points in the generation process (Mann &amp; Moore, 1981; Gabriel, 1984). Evaluating the result of a set of decisions after they have been made allows a more parsimonious distribution of knowledge since specific 90 types of improvements may be evaluated at different stages. Interactions among the decisions made so far may also be evaluated rather than predicted. The problem remains, however, of not being able to take into account the interaction with future decisions. A third approach, and the one described in this paper, is to use the writing process as a model and to improve the text in successive passes. A generation/revision system would include a generator, a</context>
</contexts>
<marker>Gabriel, 1984</marker>
<rawString>Gabriel, Richard (1984) &amp;quot;Deliberate Writing&amp;quot;, to appear in McDonald &amp; Bolc, eds. Papers on Natural Language Generation, SpringerVerlag, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barabara S Glatt</author>
</authors>
<title>Defining Thematic Progressions and Their Relationships to Reader Comprehension&amp;quot;,</title>
<date>1982</date>
<pages>87--104</pages>
<editor>in Nystrand, Martin, ed.</editor>
<publisher>Academic Press,</publisher>
<location>New York, NY:</location>
<contexts>
<context position="7515" citStr="Glatt, 1982" startWordPosition="1184" endWordPosition="1185">ce or two items that are closely related. Coreferences create textual cohesion since the interpretation of one element in the text is dependent on another (Halliday and Hansan. 1976). Scinto (1983) describes a narrower type of cohesion which operates between successive predicational units of meaning (roughly clauses). These units can be described in terms of their &amp;quot;theme&amp;quot; (what is being talked about) and &amp;quot;rheme&amp;quot; (what is being said about it). Thematic progression is the organization of given and new information into theme-rheme patterns in successive sentences. Preliminary studies have shown (Glatt, 1982) that thematic progressions in which the theme of a sentence is coreferential with the theme or the rheme of the immediately preceding sentence are easier to comprehend than those with other thematic progressions. This ease of comprehension can be attributed to the fact that the connection of the sentence with previous text comes early in the sentence. It would appear that the longer the reader must wait for the connection, the more difficult the integration with previous information will be. Another source of coherence is lexical connectives, such as sentential adjuncts (&apos;first&apos;, for example&apos;</context>
</contexts>
<marker>Glatt, 1982</marker>
<rawString>Glatt, Barabara S. (1982) &amp;quot;Defining Thematic Progressions and Their Relationships to Reader Comprehension&amp;quot;, in Nystrand, Martin, ed. What Writers (BOW: the language, process, and structure of written discourse, New York, NY: Academic Press, pp. 87-104.</rawString>
</citation>
<citation valid="true">
<date>1980</date>
<booktitle>Cognitive Processes in Writthg, Hilldale, NJ: Lawrence Erlbaum Associates.</booktitle>
<editor>Gregg, L. St E.R. Steinberg, eds.</editor>
<contexts>
<context position="1672" citStr="(1980)" startWordPosition="269" endWordPosition="269">UCTION Revision is a large part of the writing process for people. This is one respect in which writing differs from speech. In ordinary conversation we do not rehearse what we are going to say; however, when writing a text which may be used more than once by an audience which is not present, we use a multipass system of writing and rewriting to produce optimal text. By reading what we write, we seem better able to detect flaws in the text and see new options for improvement. Why most people are not able to produce optimal text in one pass is an open and interesting question. Flower and Hayes (1980) and Collins and Gentner (1980) suggest that writers are unable to juggle the excessive number of simultaneous demands and constraints which arise in producing well written text. Writers must concentrate not only on expressing content and purpose, but also on the discourse conventions of written prose: the constraints on sentence, paragraph, and text structure which are designed to make texts more readable. Successive iterations of writing and revising may allow the writer to reduce the number of considerations demanding attention at a given time. The developers of natural language generation </context>
</contexts>
<marker>1980</marker>
<rawString>Gregg, L. St E.R. Steinberg, eds. (1980) Cognitive Processes in Writthg, Hilldale, NJ: Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A IC Halliday</author>
<author>Rusgaiya Hasan</author>
</authors>
<date>1976</date>
<booktitle>Cohesion in English,</booktitle>
<publisher>Longman Group Ltd.</publisher>
<location>London:</location>
<marker>Halliday, Hasan, 1976</marker>
<rawString>Halliday, M.A.IC., &amp; Rusgaiya Hasan (1976) Cohesion in English, London: Longman Group Ltd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Hayes</author>
<author>Linda Fower</author>
</authors>
<title>Identifying the Organization of Writing Processes&amp;quot;,</title>
<date>1980</date>
<journal>in Gregg &amp; Steinberg (Eds),</journal>
<pages>3--30</pages>
<marker>Hayes, Fower, 1980</marker>
<rawString>Hayes, John, &amp; Linda Fower (1980) &amp;quot;Identifying the Organization of Writing Processes&amp;quot;, in Gregg &amp; Steinberg (Eds), pp. 3-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Longacre</author>
</authors>
<title>The Paragraph as a Grammatical Unit&amp;quot;,</title>
<date>1979</date>
<booktitle>in Syntax and Semantics, Vol. 12: Discourse and Syntax,</booktitle>
<pages>115--134</pages>
<publisher>Academic Press,</publisher>
<contexts>
<context position="8967" citStr="Longacre, 1979" startWordPosition="1391" endWordPosition="1392">, rather than leaving it to the reader to infer. Other ways of combining sentences can function to increase coherence as well. Chafe (1984) enumerates the devices used to combine &amp;quot;idea units&amp;quot; in written text including turning predications into modificatir 91 with attributive adjectives, preposed and postposed participles, and combining sentences using complement and relative clauses, appositives, and participle clauses. These structures function to increase connectivity by making the text more concise. Paragraph structure also contributes to the coherence of a text. &amp;quot;Paragraph&amp;quot; in this sense (Longacre, 1979) refers to a structural unit which does not necessarily correspond to the orthographic unit indicated by an indentation of the text. Paragraphs are characterized by closure (a beginning and end) and internal unity. They may be marked prosodically by intonation in speech or orthographically by indentation in writing, and structurally, such as by initial sentence adjuncts. Paragraphs are recursive structures, and thus may be composed of embedded paragraphs. In this respect they are similar to Mann&apos;s rhetorical discourse structures (Mann, 1984). 3_ A MODEL OF GENERATION AND REVISION In this secti</context>
</contexts>
<marker>Longacre, 1979</marker>
<rawString>Longacre, R.E. (1979) &amp;quot;The Paragraph as a Grammatical Unit&amp;quot;, in Syntax and Semantics, Vol. 12: Discourse and Syntax, Academic Press, PP. 115-134-</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>James Moore</author>
</authors>
<title>Computer Generation of Multiparagraph English Text&amp;quot;,</title>
<date>1981</date>
<journal>American Journal of Computational Linguistics,</journal>
<pages>17--29</pages>
<location>Vol.7, No.1, Jan-Mar,</location>
<contexts>
<context position="1022" citStr="Mann and Moore (1981)" startWordPosition="149" endWordPosition="152">ather than by using an architecturally more complex single pass generator. As a general area of study, the revision process presents interesting problems: Recognition of flaws in text requires a descriptive theory of what constitutes well written prose and a parser which can build a representation in those terms. Improving text requires associating flaws with strategies for improvement. The strategies, in turn, need to know what adjustments to the decisions made during the initial generation will produce appropriate modifications to the text. We compare our treatment of revision with those of Mann and Moore (1981), Gabriel (1984), and Mann (1983). 1. INTRODUCTION Revision is a large part of the writing process for people. This is one respect in which writing differs from speech. In ordinary conversation we do not rehearse what we are going to say; however, when writing a text which may be used more than once by an audience which is not present, we use a multipass system of writing and rewriting to produce optimal text. By reading what we write, we seem better able to detect flaws in the text and see new options for improvement. Why most people are not able to produce optimal text in one pass is an open</context>
<context position="3667" citStr="Mann &amp; Moore, 1981" startWordPosition="574" endWordPosition="577">ry for decision making must be structured so that at any given point the generator has enough information to make an optimal decision. While many decisions require only local information, decisions involving long range dependencies, such as maintaining coherence, may require not only a history of the decisions made so far, but also predictions of what future decisions might be made and the interactions between those decisions. An alternative approach is a single pass system which incorporates provisions for revision of its internal representations at specific points in the generation process (Mann &amp; Moore, 1981; Gabriel, 1984). Evaluating the result of a set of decisions after they have been made allows a more parsimonious distribution of knowledge since specific 90 types of improvements may be evaluated at different stages. Interactions among the decisions made so far may also be evaluated rather than predicted. The problem remains, however, of not being able to take into account the interaction with future decisions. A third approach, and the one described in this paper, is to use the writing process as a model and to improve the text in successive passes. A generation/revision system would includ</context>
<context position="22192" citStr="Mann &amp; Moore, 1981" startWordPosition="3543" endWordPosition="3546"> case Telex vs. IBM was argued along the dimension &amp;quot;common employee transferred products or tools&amp;quot;. IBM developed the product Merlin, which is a disk storage system. Telex developed the T-6830, which competes with Merlin. In 1972, Clemens. the manager on the Merlin development project, left IBM to work for Telex and took with him a copy of the Merlin code. IBM sued Telex for misappropriation of trade secret information and won the case. 5. OTHER REVISION SYSTEMS Few generation systems address the question of using successive refinement to improve their output. Some notable exceptions are KDS (Mann &amp; Moore, 1981), Yh (Gabriel, 1982), and Penman (Mann, 1983). KDS and Yh use a top down approach where intermediate representations are evaluated and improved before any text is actually generated; Penman uses a cyclic approach similar to that described here. 94 KDS uses a hill climbing module to improve text. Once a set of protosentences has been produced and grossly organized, the hill climber attempts to compose complex protosentences from simple ones by applying a set of aggregation rules, which correspond roughly to English clause combining rules. Next, the hill climber uses a set of preference rules to</context>
</contexts>
<marker>Mann, Moore, 1981</marker>
<rawString>Mann, William C. &amp; James Moore (1981) &amp;quot;Computer Generation of Multiparagraph English Text&amp;quot;, American Journal of Computational Linguistics, Vol.7, No.1, Jan-Mar, pp.17-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
</authors>
<title>An Overview of the Penman Text Generation System, USC/ISI</title>
<date>1983</date>
<tech>Technical Report RR-83-114.</tech>
<contexts>
<context position="1055" citStr="Mann (1983)" startWordPosition="156" endWordPosition="157"> complex single pass generator. As a general area of study, the revision process presents interesting problems: Recognition of flaws in text requires a descriptive theory of what constitutes well written prose and a parser which can build a representation in those terms. Improving text requires associating flaws with strategies for improvement. The strategies, in turn, need to know what adjustments to the decisions made during the initial generation will produce appropriate modifications to the text. We compare our treatment of revision with those of Mann and Moore (1981), Gabriel (1984), and Mann (1983). 1. INTRODUCTION Revision is a large part of the writing process for people. This is one respect in which writing differs from speech. In ordinary conversation we do not rehearse what we are going to say; however, when writing a text which may be used more than once by an audience which is not present, we use a multipass system of writing and rewriting to produce optimal text. By reading what we write, we seem better able to detect flaws in the text and see new options for improvement. Why most people are not able to produce optimal text in one pass is an open and interesting question. Flower</context>
<context position="22237" citStr="Mann, 1983" startWordPosition="3552" endWordPosition="3553">ommon employee transferred products or tools&amp;quot;. IBM developed the product Merlin, which is a disk storage system. Telex developed the T-6830, which competes with Merlin. In 1972, Clemens. the manager on the Merlin development project, left IBM to work for Telex and took with him a copy of the Merlin code. IBM sued Telex for misappropriation of trade secret information and won the case. 5. OTHER REVISION SYSTEMS Few generation systems address the question of using successive refinement to improve their output. Some notable exceptions are KDS (Mann &amp; Moore, 1981), Yh (Gabriel, 1982), and Penman (Mann, 1983). KDS and Yh use a top down approach where intermediate representations are evaluated and improved before any text is actually generated; Penman uses a cyclic approach similar to that described here. 94 KDS uses a hill climbing module to improve text. Once a set of protosentences has been produced and grossly organized, the hill climber attempts to compose complex protosentences from simple ones by applying a set of aggregation rules, which correspond roughly to English clause combining rules. Next, the hill climber uses a set of preference rules to judge the relative quality of the resulting </context>
</contexts>
<marker>Mann, 1983</marker>
<rawString>Mann, William C. (1983) An Overview of the Penman Text Generation System, USC/ISI Technical Report RR-83-114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
</authors>
<date>1984</date>
<booktitle>Discourse Structures for Text GenerationIS1</booktitle>
<tech>Technical Report ISI/RR84-127.</tech>
<contexts>
<context position="9514" citStr="Mann, 1984" startWordPosition="1472" endWordPosition="1473"> coherence of a text. &amp;quot;Paragraph&amp;quot; in this sense (Longacre, 1979) refers to a structural unit which does not necessarily correspond to the orthographic unit indicated by an indentation of the text. Paragraphs are characterized by closure (a beginning and end) and internal unity. They may be marked prosodically by intonation in speech or orthographically by indentation in writing, and structurally, such as by initial sentence adjuncts. Paragraphs are recursive structures, and thus may be composed of embedded paragraphs. In this respect they are similar to Mann&apos;s rhetorical discourse structures (Mann, 1984). 3_ A MODEL OF GENERATION AND REVISION In this section we will outline a model of generation with revision, focusing on improving textual coherence. First we establish a division of labor within the generation/revision process. Then we look at the phases of revision and consider the capabilities necessary for recognizing deficiencies in cohesion and how they may be repaired. In the fourth section, we apply this model to the revision of an example summary paragraph. The initial generation of a text involves making decisions of various kinds. Some are conceptually based, such as what informatio</context>
</contexts>
<marker>Mann, 1984</marker>
<rawString>Mann, William C. (1984) Discourse Structures for Text GenerationIS1 Technical Report ISI/RR84-127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D McDonald</author>
</authors>
<title>Recovering the Speaker&apos;s Decisions during Mechanical Translation&amp;quot;,</title>
<date>1985</date>
<booktitle>Proceedings of the Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages,</booktitle>
<pages>183--199</pages>
<institution>Colgate University,</institution>
<marker>McDonald, 1985</marker>
<rawString>McDonald, David D. (1985) &amp;quot;Recovering the Speaker&apos;s Decisions during Mechanical Translation&amp;quot;, Proceedings of the Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages, Colgate University, pp.183-199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D McDonald</author>
<author>James Pustejovsky</author>
</authors>
<title>Description-directed Natural Language Generation&amp;quot;.</title>
<date>1985</date>
<booktitle>IJCA I Proceedings,</booktitle>
<pages>799--805</pages>
<marker>McDonald, Pustejovsky, 1985</marker>
<rawString>McDonald, David D. &amp; James Pustejovsky (1985) &amp;quot;Description-directed Natural Language Generation&amp;quot;. IJCA I Proceedings, pp.799-805.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Rissland</author>
<author>E Valcarce</author>
<author>K Ashley</author>
</authors>
<title>Explaining and Arguing with Examples&amp;quot;,</title>
<date>1984</date>
<journal>Proceedings of A A A I</journal>
<volume>81</volume>
<marker>Rissland, Valcarce, Ashley, 1984</marker>
<rawString>Rissland E., E. Valcarce, &amp; K. Ashley (1984) &amp;quot;Explaining and Arguing with Examples&amp;quot;, Proceedings of A A A I -81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Scinto</author>
<author>F M</author>
</authors>
<title>Functional Connectivity and the Communicative Structure of Text&amp;quot;,</title>
<date>1983</date>
<booktitle>Micro and Macro Connexity of Texts,</booktitle>
<pages>73--115</pages>
<editor>in Petofi, Janos S. &amp; Emel Sozer, eds.</editor>
<publisher>Buske,</publisher>
<location>Hamburg:</location>
<marker>Scinto, M, 1983</marker>
<rawString>Scinto, Leonard, F.M. (1983) &amp;quot;Functional Connectivity and the Communicative Structure of Text&amp;quot;, in Petofi, Janos S. &amp; Emel Sozer, eds. (1983) Micro and Macro Connexity of Texts, Hamburg: Buske, pp.73-115-</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>