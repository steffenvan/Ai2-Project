<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000144">
<title confidence="0.9975705">
Harnessing NLP Techniques in the Processes of
Multilingual Content Management
</title>
<author confidence="0.452662">
Anelia Belogay Diman Karagyozov
</author>
<affiliation confidence="0.429567">
Tetracom IS Ltd. Tetracom IS Ltd.
</affiliation>
<email confidence="0.984525">
anelia@tetracom.com diman@tetracom.com
</email>
<author confidence="0.993585">
Svetla Koeva Cristina Vertan
</author>
<affiliation confidence="0.984953">
Institute for Bulgarian Language Universitaet Hamburg
</affiliation>
<email confidence="0.993325">
svetla@dcl.bass.bg cristina.vertan@uni-hamburg.de
</email>
<author confidence="0.922859">
Adam Przepiórkowski Polivios Raxis
</author>
<affiliation confidence="0.531436666666667">
Instytut Podstaw Informatyki Polskiej
Atlantis Consulting SA
Akademii Nauk
</affiliation>
<email confidence="0.9748">
adamp@ipipan.waw.pl raxis@atlantisresearch.gr
</email>
<author confidence="0.992533">
Dan Cristea
</author>
<affiliation confidence="0.952858">
Universitatea Alexandru Ioan Cuza
</affiliation>
<email confidence="0.98912">
dcristea@info.uaic.ro
</email>
<sectionHeader confidence="0.992864" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999513454545455">
The emergence of the WWW as the main
source of distributing content opened the
floodgates of information. The sheer
volume and diversity of this content
necessitate an approach that will reinvent
the way it is analysed. The quantitative
route to processing information which
relies on content management tools
provides structural analysis. The
challenge we address is to evolve from
the process of streamlining data to a level
of understanding that assigns value to
content.
We present an open-source multilingual
platform ATALS that incorporates
human language technologies in the
process of multilingual web content
management. It complements a content
management software-as-a-service
component i-Publisher, used for creating,
running and managing dynamic content-
driven websites with a linguistic
platform. The platform enriches the
content of these websites with revealing
details and reduces the manual work of
classification editors by automatically
categorising content. The platform
ASSET supports six European languages.
We expect ASSET to serve as a basis for
future development of deep analysis tools
capable of generating abstractive
summaries and training models for
decision making systems.
</bodyText>
<sectionHeader confidence="0.961569" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999307823529412">
The advent of the Web revolutionized the way in
which content is manipulated and delivered. As a
result, digital content in various languages has
become widely available on the Internet and its
sheer volume and language diversity have
presented an opportunity for embracing new
methods and tools for content creation and
distribution. Although significant improvements
have been made in the field of web content
management lately, there is still a growing
demand for online content services that
incorporate language-based technology.
Existing software solutions and services such
as Google Docs, Slingshot and Amazon
implement some of the linguistic mechanisms
addressed in the platform. The most used open-
source multilingual web content management
</bodyText>
<page confidence="0.980773">
6
</page>
<bodyText confidence="0.979931052631579">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 6–10,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
systems (Joomla, Joom!Fish, TYPO3, Drupal)1
offer low level of multilingual content
management, providing abilities for building
multilingual sites. However, the available
services are narrowly focused on meeting the
needs of very specific target groups, thus leaving
unmet the rising demand for a comprehensive
solution for multilingual content management
addressing the issues posed by the growing
family of languages spoken within the EU.
We are going to demonstrate the open-source
content management platform ATLAS and as
proof of concept, a multilingual library i-
librarian, driven by the platform. The
demonstration aims to prove that people reading
websites powered by ATLAS can easily find
documents, kept in order via the automatic
classification, find context-sensitive content, find
similar documents in a massive multilingual data
collection, and get short summaries in different
languages that help the users to discern essential
information with unparalleled clarity.
The “Technologies behind the system” chapter
describes the implementation and the integration
approach of the core linguistic processing
framework and its key sub-components – the
categorisation, summarisation and machine-
translation engines. The chapter “i-Librarian – a
case study” outlines the functionalities of an
intelligent web application built with our system
and the benefits of using it. The chapter
“Evaluation” briefly discusses the user
evaluation of the new system. The last chapter
“Conclusion and Future Work” summarises the
main achievements of the system and suggests
improvements and extensions.
</bodyText>
<subsectionHeader confidence="0.985632">
Technologies behind the system
</subsectionHeader>
<bodyText confidence="0.9998541">
The linguistic framework ASSET employs
diverse natural language processing (NLP) tools
technologically and linguistically in a platform,
based on UIMA 2 . The UIMA pluggable
component architecture and software framework
are designed to analyse content and to structure
it. The ATLAS core annotation schema, as a
uniform representation model, normalizes and
harmonizes the heterogeneous nature of the NLP
tools3.
</bodyText>
<footnote confidence="0.813813666666667">
1 http://www.joomla.org/, http://www.joomfish.net/,
http://typo3.org/, http://drupal.org/
2 http://uima.apache.org/
3 The system exploits heterogeneous NLP tools, for
the supported natural languages, implemented in Java,
C++ and Perl. Examples are:
</footnote>
<bodyText confidence="0.999645230769231">
The processing of text in the system is split
into three sequentially executed tasks.
Firstly, the text is extracted from the input
source (text or binary documents) in the “pre-
processing” phase.
Secondly, the text is annotated by several NLP
tools, chained in a sequence in the “processing”
phase. The language processing tools are
integrated in a language processing chain (LPC),
so that the output of a given NLP tool is used as
an input for the next tool in the chain. The
baseline LPC for each of the supported languages
includes a sentence and paragraph splitter,
tokenizer, part of speech tagger, lemmatizer,
word sense disambiguation, noun phrase chunker
and named entity extractor (Cristea and Pistiol,
2008). The annotations produced by each LPC
along with additional statistical methods are
subsequently used for detection of keywords and
concepts, generation of summary of text, multi-
label text categorisation and machine translation.
Finally, the annotations are stored in a fusion
data store, comprising of relational database and
high-performance Lucene4 indexes.
The architecture of the language processing
framework is depicted in Figure 1.
</bodyText>
<figureCaption confidence="0.991856">
Figure 1. Architecture and communication channels in
our language processing framework.
</figureCaption>
<bodyText confidence="0.9999085">
The system architecture, shown in Figure 2, is
based on asynchronous message processing
</bodyText>
<footnote confidence="0.998266">
OpenNLP (http://incubator.apache.org/opennlp/),
RASP (http://ilexir.co.uk/applications/rasp/),
Morfeusz (http://sgjp.pl/morfeusz/), Panterra
(http://code.google.com/p/pantera-tagger/), ParsEst
(http://dcl.bas.bg/), TnT Tagger (http://www.coli.uni-
saarland.de/~thorsten/tnt/).
4 http://lucene.apache.org/
</footnote>
<page confidence="0.998835">
7
</page>
<bodyText confidence="0.727829">
patterns (Hohpe and Woolf, 2004) and thus
allows the processing framework to be easily
scaled horizontally.
</bodyText>
<figureCaption confidence="0.9966355">
Figure 2. Top-level architecture of our CMS and its
major components.
</figureCaption>
<subsectionHeader confidence="0.793126">
Text Categorisation
</subsectionHeader>
<bodyText confidence="0.9999330625">
We implemented a language independent text
categorisation tool, which works for user-defined
and controlled classification hierarchies. The
NLP framework converts the texts to a series of
natural numbers, prior sending the texts to the
categorisation engine. This conversion allows
high level compression of the feature space. The
categorisation engine employs different
algorithms, such as Naïve Bayesian, relative
entropy, Class-Feature Centroid (CFC) (Guan et.
al., 2009), and SVM. New algorithms can be
easily integrated because of the chosen OSGi-
based architecture (OSGi Alliance, 2009). A
tailored voting system for multi-label multi-class
tasks consolidates the results of each of the
categorisation algorithms.
</bodyText>
<subsectionHeader confidence="0.531447">
Summarisation (prototype phase)
</subsectionHeader>
<bodyText confidence="0.986614161290323">
The chosen implementation approach for
coherent text summarisation combines the well-
known LexRank algorithm (Erkan and Radev,
2004) and semantic graphs and word-sense
disambiguation techniques (Plaza and Diaz,
2011). Furthermore, we have automatically built
thesauri for the top-level domains in order to
produce domain-focused extractive summaries.
Finally, we apply clause-boundaries splitting in
order to truncate the irrelevant or subordinating
clauses in the sentences in the summary.
Machine Translation (prototype phase)
The machine translation (MT) sub-component
implements the hybrid MT paradigm, combining
an example-based (EBMT) component and a
Moses-based statistical approach (SMT). Firstly,
the input is processed by the example-based MT
engine and if the whole or important chunks of it
are found in the translation database, then the
translation equivalents are used and if necessary
combined (Gavrila, 2011). In all other cases the
input is processed by the categorisation sub-
component in order to select the top-level
domain and respectively, the most appropriate
SMT domain- and POS-translation model
(Niehues and Waibel, 2010).
The translation engine in the system, based on
MT Server Land (Federmann and Eisele, 2010),
is able to accommodate and use different third
party translation engines, such as the Google,
Bing, Lusy or Yahoo translators.
</bodyText>
<subsectionHeader confidence="0.696461">
Case Study: Multilingual Library
</subsectionHeader>
<bodyText confidence="0.999969703703704">
i-Librarian5 is a free online library that assists
authors, students, young researchers, scholars,
librarians and executives to easily create,
organise and publish various types of documents
in English, Bulgarian, German, Greek, Polish
and Romanian. Currently, a sample of the
publicly available library contains over 20 000
books in English.
On uploading a new document to i-Librarian,
the system automatically provides the user with
an extraction of the most relevant information
(concepts and named entities, keywords). Later
on, the retrieved information is used to generate
suggestions for classification in the library
catalogue, containing 86 categories, as well as a
list of similar documents. Finally, the system
compiles a summary and translates it in all
supported languages. Among the supported
formats are Microsoft Office documents, PDF,
OpenOffice documents, books in various
electronic formats, HTML pages and XML
documents. Users have exclusive rights to
manage content in the library at their discretion.
The current version of the system supports
English and Bulgarian. In early 2012 the Polish,
Greek, German and Romanian languages will be
in use.
</bodyText>
<footnote confidence="0.97317725">
5 i-Librarian web site is available at http://www.i-
librarian.eu/. One can access the i-Librarian demo content
using “demo@i-librarian.eu” for username and “sandbox”
for password.
</footnote>
<page confidence="0.998436">
8
</page>
<sectionHeader confidence="0.617436" genericHeader="background">
Evaluation
</sectionHeader>
<bodyText confidence="0.9979278">
The technical quality and performance of the
system is being evaluated as well as its appraisal
by prospective users. The technical evaluation
uses indicators that assess the following key
technical elements:
</bodyText>
<listItem confidence="0.98355675">
• overall quality and performance
attributes (MTBF6, uptime, response
time);
• performance of specific functional
elements (content management, machine
translation, cross-lingual content
retrieval, summarisation, text
categorisation).
</listItem>
<bodyText confidence="0.976064333333333">
The user evaluation assesses the level of
satisfaction with the system. We measure non
functional elements such as:
</bodyText>
<listItem confidence="0.999269">
• User friendliness and satisfaction, clarity
in responses and ease of use;
• Adequacy and completeness of the
provided data and functionality;
• Impact on certain user activities and the
</listItem>
<bodyText confidence="0.9983196">
degree of fulfilment of common tasks.
We have planned for three rounds of user
evaluation; all users are encouraged to try online
the system, freely, or by following the provided
base-line scenarios and accompanying exercises.
The main instrument for collecting user feedback
is an online interactive electronic questionnaire7.
The second round of user evaluation is
scheduled for Feb-March 2012, while the first
round took place in Q1 2011, with the
participation of 33 users. The overall user
impression was positive and the Mean value of
each indicator (in a 5-point Likert scale) was
measured on AVERAGE or ABOVE
AVERAGE.
</bodyText>
<figureCaption confidence="0.839761">
Figure 3. User evaluation – UI friendliness and ease
of use.
</figureCaption>
<footnote confidence="0.577485666666667">
6 Mean Time Between Failures
7 The electronic questionnaire is available at
http://ue.atlasproject.eu
</footnote>
<figureCaption confidence="0.9877195">
Figure 4. User evaluation – user satisfaction with the
available functionalities in the system.
Figure 5. User evaluation – users productivity
incensement.
</figureCaption>
<sectionHeader confidence="0.979073" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9892305">
ATLAS (Applied Technology for Language-
Aided CMS) is a European project funded under
the CIP ICT Policy Support Programme, Grant
Agreement 250467.
</bodyText>
<subsectionHeader confidence="0.485541">
Conclusion and Future Work
</subsectionHeader>
<bodyText confidence="0.977043260869565">
The abundance of knowledge allows us to widen
the application of NLP tools, developed in a
research environment. The tailor made voting
system maximizes the use of the different
categorisation algorithms. The novel summary
approach adopts state of the art techniques and
the automatic translation is provided by a cutting
edge hybrid machine translation system.
The content management platform and the
linguistic framework will be released as open-
source software. The language processing chains
for Greek, Romanian, Polish and German will be
fully implemented by the end of 2011. The
summarisation engine and machine translation
tools will be fully integrated in mid 2012.
We expect this platform to serve as a basis for
future development of tools that directly support
decision making and situation awareness. We
will use categorical and statistical analysis in
order to recognise events and patterns, to detect
opinions and predictions while processing
The user interface is friendly and
easy to use
</bodyText>
<figure confidence="0.999596404255319">
Poor
Below Average
Average
Good
Excellent
Below
Average
9%
Excellent
28%
Average
28%
Good
35%
Excellent
31%
I am satisfied with the functionalities
Good
28%
Below
Average
3%
Average
38%
Below
Average
Average
Good
Poor
Excellent
Excellent
13%
Good
The system increases your
47%
productivity
Below
Average
9%
Average
31%
Below
Average
Average
Good
Poor
Excellent
</figure>
<page confidence="0.980368">
9
</page>
<bodyText confidence="0.9962465">
extremely large volumes of disparate data
resources.
</bodyText>
<subsectionHeader confidence="0.563931">
Demonstration websites
</subsectionHeader>
<bodyText confidence="0.999434454545455">
The multilingual content management platform is
available for testing at http://i-
publisher.atlasproject.eu/atlas/i-publisher/demo .
One can access the CMS demo content using
“demo” for username and “sandbox2” for
password.
The multilingual library web site is available
at http://www.i-librarian.eu/. One can access the
i-Librarian demo content using “demo@i-
librarian.eu” for username and “sandbox” for
password.
</bodyText>
<sectionHeader confidence="0.999432" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999665707317073">
Dan Cristea and Ionut C. Pistol, 2008. Managing
Language Resources and Tools using a Hierarchy
of Annotation Schemas. In the proceedings of
workshop &apos;Sustainability of Language Resources
and Tools for Natural Language Processing&apos;,
LREC, 2008
Gregor Hohpe and Bobby Woolf. 2004. Enterprise
Integration Patterns: Designing, Building, and
Deploying Messaging Solutions. Addison-Wesley
Professional.
Hu Guan, Jingyu Zhou and Minyi Guo. A Class-
Feature-Centroid Classifier for Text
Categorization. 2009. WWW 2009 Madrid, Track:
Data Mining / Session: Learning, p201-210.
OSGi Alliance. 2009. OSGi Service Platform, Core
Specification, Release 4, Version 4.2.
Gunes Erkan and Dragomir R. Radev. 2004.
LexRank: Graph-based Centrality as Salience in
Text Summarization. Journal of Artificial
Intelligence Research 22 (2004), p457–479.
Laura Plaza and Alberto Diaz. 2011. Using Semantic
Graphs and Word Sense Disambiguation
Techniques to Improve Text Summarization.
Procesamiento del Lenguaje Natural, Revista nº 47
septiembre de 2011 (SEPLN 2011), pp 97-105.
Monica Gavrila. 2011. Constrained Recombination in
an Example-based Machine Translation System, In
the Proceedings of the EAMT-2011: the 15th
Annual Conference of the European Association
for Machine Translation, 30-31 May 2011, Leuven,
Belgium, p. 193-200
Jan Niehues and Alex Waibel. 2010. Domain
adaptation in statistical machine translation using
factored translation models. EAMT 2010:
Proceedings of the 14th Annual conference of the
European Association for Machine Translation, 27-
28 May 2010, Saint-Raphaël, France.
Christian Federmann and Andreas Eisele. 2010. MT
Server Land: An Open-Source MT Architecture.
The Prague Bulletin of Mathematical Linguistics.
NUMBER 94, 2010, p57–66
</reference>
<page confidence="0.997768">
10
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.102604">
<title confidence="0.9991525">Harnessing NLP Techniques in the Processes of Multilingual Content Management</title>
<author confidence="0.971924">Anelia Belogay Diman Karagyozov</author>
<affiliation confidence="0.981196">Tetracom IS Ltd. Tetracom IS Ltd.</affiliation>
<email confidence="0.984102">anelia@tetracom.comdiman@tetracom.com</email>
<author confidence="0.994489">Svetla Koeva Cristina Vertan</author>
<affiliation confidence="0.969204">Institute for Bulgarian Language Universitaet Hamburg</affiliation>
<title confidence="0.640672">svetla@dcl.bass.bg cristina.vertan@uni-hamburg.de Adam Przepiórkowski Polivios Raxis Instytut Podstaw Informatyki Polskiej Atlantis Consulting SA</title>
<author confidence="0.637442">Akademii Nauk</author>
<email confidence="0.488585">adamp@ipipan.waw.plraxis@atlantisresearch.gr</email>
<author confidence="0.807965">Dan Cristea Universitatea Alexandru Ioan Cuza</author>
<email confidence="0.966245">dcristea@info.uaic.ro</email>
<abstract confidence="0.999836470588235">The emergence of the WWW as the main source of distributing content opened the floodgates of information. The sheer volume and diversity of this content necessitate an approach that will reinvent the way it is analysed. The quantitative route to processing information which relies on content management tools provides structural analysis. The challenge we address is to evolve from the process of streamlining data to a level of understanding that assigns value to content. We present an open-source multilingual platform ATALS that incorporates human language technologies in the process of multilingual web content management. It complements a content management component i-Publisher, used for creating, running and managing dynamic contentdriven websites with a linguistic platform. The platform enriches the content of these websites with revealing details and reduces the manual work of classification editors by automatically categorising content. The platform ASSET supports six European languages. We expect ASSET to serve as a basis for future development of deep analysis tools capable of generating abstractive summaries and training models for decision making systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Dan Cristea</author>
<author>Ionut C Pistol</author>
</authors>
<title>Managing Language Resources and Tools using a Hierarchy of Annotation Schemas. In the proceedings of workshop &apos;Sustainability of Language Resources and Tools for Natural Language Processing&apos;,</title>
<date>2008</date>
<location>LREC,</location>
<marker>Cristea, Pistol, 2008</marker>
<rawString>Dan Cristea and Ionut C. Pistol, 2008. Managing Language Resources and Tools using a Hierarchy of Annotation Schemas. In the proceedings of workshop &apos;Sustainability of Language Resources and Tools for Natural Language Processing&apos;, LREC, 2008</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregor Hohpe</author>
<author>Bobby Woolf</author>
</authors>
<title>Enterprise Integration Patterns: Designing, Building, and Deploying Messaging Solutions.</title>
<date>2004</date>
<publisher>Addison-Wesley Professional.</publisher>
<contexts>
<context position="6686" citStr="Hohpe and Woolf, 2004" startWordPosition="910" endWordPosition="913">-performance Lucene4 indexes. The architecture of the language processing framework is depicted in Figure 1. Figure 1. Architecture and communication channels in our language processing framework. The system architecture, shown in Figure 2, is based on asynchronous message processing OpenNLP (http://incubator.apache.org/opennlp/), RASP (http://ilexir.co.uk/applications/rasp/), Morfeusz (http://sgjp.pl/morfeusz/), Panterra (http://code.google.com/p/pantera-tagger/), ParsEst (http://dcl.bas.bg/), TnT Tagger (http://www.coli.unisaarland.de/~thorsten/tnt/). 4 http://lucene.apache.org/ 7 patterns (Hohpe and Woolf, 2004) and thus allows the processing framework to be easily scaled horizontally. Figure 2. Top-level architecture of our CMS and its major components. Text Categorisation We implemented a language independent text categorisation tool, which works for user-defined and controlled classification hierarchies. The NLP framework converts the texts to a series of natural numbers, prior sending the texts to the categorisation engine. This conversion allows high level compression of the feature space. The categorisation engine employs different algorithms, such as Naïve Bayesian, relative entropy, Class-Fea</context>
</contexts>
<marker>Hohpe, Woolf, 2004</marker>
<rawString>Gregor Hohpe and Bobby Woolf. 2004. Enterprise Integration Patterns: Designing, Building, and Deploying Messaging Solutions. Addison-Wesley Professional.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hu Guan</author>
<author>Jingyu Zhou</author>
<author>Minyi Guo</author>
</authors>
<title>A ClassFeature-Centroid Classifier for Text Categorization.</title>
<date>2009</date>
<booktitle>WWW 2009 Madrid, Track: Data Mining / Session: Learning,</booktitle>
<pages>201--210</pages>
<marker>Guan, Zhou, Guo, 2009</marker>
<rawString>Hu Guan, Jingyu Zhou and Minyi Guo. A ClassFeature-Centroid Classifier for Text Categorization. 2009. WWW 2009 Madrid, Track: Data Mining / Session: Learning, p201-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>OSGi Alliance</author>
</authors>
<title>OSGi Service Platform, Core Specification, Release 4,</title>
<date>2009</date>
<journal>Version</journal>
<volume>4</volume>
<contexts>
<context position="7443" citStr="Alliance, 2009" startWordPosition="1019" endWordPosition="1020">ts. Text Categorisation We implemented a language independent text categorisation tool, which works for user-defined and controlled classification hierarchies. The NLP framework converts the texts to a series of natural numbers, prior sending the texts to the categorisation engine. This conversion allows high level compression of the feature space. The categorisation engine employs different algorithms, such as Naïve Bayesian, relative entropy, Class-Feature Centroid (CFC) (Guan et. al., 2009), and SVM. New algorithms can be easily integrated because of the chosen OSGibased architecture (OSGi Alliance, 2009). A tailored voting system for multi-label multi-class tasks consolidates the results of each of the categorisation algorithms. Summarisation (prototype phase) The chosen implementation approach for coherent text summarisation combines the wellknown LexRank algorithm (Erkan and Radev, 2004) and semantic graphs and word-sense disambiguation techniques (Plaza and Diaz, 2011). Furthermore, we have automatically built thesauri for the top-level domains in order to produce domain-focused extractive summaries. Finally, we apply clause-boundaries splitting in order to truncate the irrelevant or subor</context>
</contexts>
<marker>Alliance, 2009</marker>
<rawString>OSGi Alliance. 2009. OSGi Service Platform, Core Specification, Release 4, Version 4.2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gunes Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>LexRank: Graph-based Centrality as Salience in Text Summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research</journal>
<volume>22</volume>
<pages>457--479</pages>
<contexts>
<context position="7734" citStr="Erkan and Radev, 2004" startWordPosition="1055" endWordPosition="1058">his conversion allows high level compression of the feature space. The categorisation engine employs different algorithms, such as Naïve Bayesian, relative entropy, Class-Feature Centroid (CFC) (Guan et. al., 2009), and SVM. New algorithms can be easily integrated because of the chosen OSGibased architecture (OSGi Alliance, 2009). A tailored voting system for multi-label multi-class tasks consolidates the results of each of the categorisation algorithms. Summarisation (prototype phase) The chosen implementation approach for coherent text summarisation combines the wellknown LexRank algorithm (Erkan and Radev, 2004) and semantic graphs and word-sense disambiguation techniques (Plaza and Diaz, 2011). Furthermore, we have automatically built thesauri for the top-level domains in order to produce domain-focused extractive summaries. Finally, we apply clause-boundaries splitting in order to truncate the irrelevant or subordinating clauses in the sentences in the summary. Machine Translation (prototype phase) The machine translation (MT) sub-component implements the hybrid MT paradigm, combining an example-based (EBMT) component and a Moses-based statistical approach (SMT). Firstly, the input is processed by </context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>Gunes Erkan and Dragomir R. Radev. 2004. LexRank: Graph-based Centrality as Salience in Text Summarization. Journal of Artificial Intelligence Research 22 (2004), p457–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Plaza</author>
<author>Alberto Diaz</author>
</authors>
<title>Using Semantic Graphs and Word Sense Disambiguation Techniques to Improve Text Summarization.</title>
<date>2011</date>
<booktitle>Procesamiento del Lenguaje Natural, Revista nº 47 septiembre de</booktitle>
<pages>97--105</pages>
<contexts>
<context position="7818" citStr="Plaza and Diaz, 2011" startWordPosition="1066" endWordPosition="1069"> engine employs different algorithms, such as Naïve Bayesian, relative entropy, Class-Feature Centroid (CFC) (Guan et. al., 2009), and SVM. New algorithms can be easily integrated because of the chosen OSGibased architecture (OSGi Alliance, 2009). A tailored voting system for multi-label multi-class tasks consolidates the results of each of the categorisation algorithms. Summarisation (prototype phase) The chosen implementation approach for coherent text summarisation combines the wellknown LexRank algorithm (Erkan and Radev, 2004) and semantic graphs and word-sense disambiguation techniques (Plaza and Diaz, 2011). Furthermore, we have automatically built thesauri for the top-level domains in order to produce domain-focused extractive summaries. Finally, we apply clause-boundaries splitting in order to truncate the irrelevant or subordinating clauses in the sentences in the summary. Machine Translation (prototype phase) The machine translation (MT) sub-component implements the hybrid MT paradigm, combining an example-based (EBMT) component and a Moses-based statistical approach (SMT). Firstly, the input is processed by the example-based MT engine and if the whole or important chunks of it are found in </context>
</contexts>
<marker>Plaza, Diaz, 2011</marker>
<rawString>Laura Plaza and Alberto Diaz. 2011. Using Semantic Graphs and Word Sense Disambiguation Techniques to Improve Text Summarization. Procesamiento del Lenguaje Natural, Revista nº 47 septiembre de 2011 (SEPLN 2011), pp 97-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Monica Gavrila</author>
</authors>
<title>Constrained Recombination in an Example-based Machine Translation System,</title>
<date>2011</date>
<booktitle>In the Proceedings of the EAMT-2011: the 15th Annual Conference of the European Association for Machine Translation,</booktitle>
<pages>30--31</pages>
<location>Leuven, Belgium,</location>
<contexts>
<context position="8527" citStr="Gavrila, 2011" startWordPosition="1167" endWordPosition="1168">ce domain-focused extractive summaries. Finally, we apply clause-boundaries splitting in order to truncate the irrelevant or subordinating clauses in the sentences in the summary. Machine Translation (prototype phase) The machine translation (MT) sub-component implements the hybrid MT paradigm, combining an example-based (EBMT) component and a Moses-based statistical approach (SMT). Firstly, the input is processed by the example-based MT engine and if the whole or important chunks of it are found in the translation database, then the translation equivalents are used and if necessary combined (Gavrila, 2011). In all other cases the input is processed by the categorisation subcomponent in order to select the top-level domain and respectively, the most appropriate SMT domain- and POS-translation model (Niehues and Waibel, 2010). The translation engine in the system, based on MT Server Land (Federmann and Eisele, 2010), is able to accommodate and use different third party translation engines, such as the Google, Bing, Lusy or Yahoo translators. Case Study: Multilingual Library i-Librarian5 is a free online library that assists authors, students, young researchers, scholars, librarians and executives</context>
</contexts>
<marker>Gavrila, 2011</marker>
<rawString>Monica Gavrila. 2011. Constrained Recombination in an Example-based Machine Translation System, In the Proceedings of the EAMT-2011: the 15th Annual Conference of the European Association for Machine Translation, 30-31 May 2011, Leuven, Belgium, p. 193-200</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Niehues</author>
<author>Alex Waibel</author>
</authors>
<title>Domain adaptation in statistical machine translation using factored translation models.</title>
<date>2010</date>
<booktitle>EAMT 2010: Proceedings of the 14th Annual conference of the European Association for Machine Translation,</booktitle>
<pages>27--28</pages>
<location>Saint-Raphaël, France.</location>
<contexts>
<context position="8749" citStr="Niehues and Waibel, 2010" startWordPosition="1199" endWordPosition="1202">phase) The machine translation (MT) sub-component implements the hybrid MT paradigm, combining an example-based (EBMT) component and a Moses-based statistical approach (SMT). Firstly, the input is processed by the example-based MT engine and if the whole or important chunks of it are found in the translation database, then the translation equivalents are used and if necessary combined (Gavrila, 2011). In all other cases the input is processed by the categorisation subcomponent in order to select the top-level domain and respectively, the most appropriate SMT domain- and POS-translation model (Niehues and Waibel, 2010). The translation engine in the system, based on MT Server Land (Federmann and Eisele, 2010), is able to accommodate and use different third party translation engines, such as the Google, Bing, Lusy or Yahoo translators. Case Study: Multilingual Library i-Librarian5 is a free online library that assists authors, students, young researchers, scholars, librarians and executives to easily create, organise and publish various types of documents in English, Bulgarian, German, Greek, Polish and Romanian. Currently, a sample of the publicly available library contains over 20 000 books in English. On </context>
</contexts>
<marker>Niehues, Waibel, 2010</marker>
<rawString>Jan Niehues and Alex Waibel. 2010. Domain adaptation in statistical machine translation using factored translation models. EAMT 2010: Proceedings of the 14th Annual conference of the European Association for Machine Translation, 27-28 May 2010, Saint-Raphaël, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Federmann</author>
<author>Andreas Eisele</author>
</authors>
<title>MT Server Land: An Open-Source MT Architecture. The Prague Bulletin of Mathematical Linguistics.</title>
<date>2010</date>
<journal>NUMBER</journal>
<volume>94</volume>
<pages>57--66</pages>
<contexts>
<context position="8841" citStr="Federmann and Eisele, 2010" startWordPosition="1214" endWordPosition="1217">ning an example-based (EBMT) component and a Moses-based statistical approach (SMT). Firstly, the input is processed by the example-based MT engine and if the whole or important chunks of it are found in the translation database, then the translation equivalents are used and if necessary combined (Gavrila, 2011). In all other cases the input is processed by the categorisation subcomponent in order to select the top-level domain and respectively, the most appropriate SMT domain- and POS-translation model (Niehues and Waibel, 2010). The translation engine in the system, based on MT Server Land (Federmann and Eisele, 2010), is able to accommodate and use different third party translation engines, such as the Google, Bing, Lusy or Yahoo translators. Case Study: Multilingual Library i-Librarian5 is a free online library that assists authors, students, young researchers, scholars, librarians and executives to easily create, organise and publish various types of documents in English, Bulgarian, German, Greek, Polish and Romanian. Currently, a sample of the publicly available library contains over 20 000 books in English. On uploading a new document to i-Librarian, the system automatically provides the user with an </context>
</contexts>
<marker>Federmann, Eisele, 2010</marker>
<rawString>Christian Federmann and Andreas Eisele. 2010. MT Server Land: An Open-Source MT Architecture. The Prague Bulletin of Mathematical Linguistics. NUMBER 94, 2010, p57–66</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>