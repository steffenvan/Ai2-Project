<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<note confidence="0.7500135">
Graph-structured Stack and Natural Language Parsing
Maseru Tomita
Center for Machine Translation
and
</note>
<title confidence="0.502192">
Computer Science Department
Carnegie-Mellon University
Pittsburgh, PA 15213
</title>
<sectionHeader confidence="0.963032" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996126">
A general device for handling nondeterminism in stack
operations is described. The device, called a
Graph-structured Stack can eliminate duplication of
operations throughout the nondeterministic processes.
This paper then applies the graph-structured stack to
various natural language parsing methods, including
ATN, LR parsing, categorial grammar and principle-
based parsing. The relationship between the graph-
structured stack and a chart in chart parsing is also
discussed.
</bodyText>
<sectionHeader confidence="0.997052" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999941527777778">
A stack plays an important role in natural language
parsing. It is the stack which gives a parser context-
free (rather than regular) power by permitting
recursions. Most parsing systems make explicit use
of the stack. Augmented Transition Network (ATN)
[10] employs a stack for keeping track of return
addresses when it visits a sub-network. Shift-reduce
parsing uses a stack as a primary device; sentences
are parsed only by pushing an element onto the stack
or by reducing the stack in accordance with
grammatical rules. Implementation of principle-based
parsing [9, 1, 4] and categorial grammar [2] also often
requires a stack for storing partial parses already built.
Those parsing systems usually introduce backtracking
or pseudo parallelism to handle nondeterminism,
taking exponential time in the worst case.
This paper describes a general device, a
graph-structured stack. The graph-structured stack
was originally introduced in Tomita&apos;s generalized LR
parsing algorithm [7, 8]. This paper applies the graph-
structured stack to various other parsing methods.
Using the graph-structured stack, a system is
guaranteed not to replicate the same work and can
run in polynomial time. This is true for all of the
parsing systems mentioned above; ATN, shift-reduce
parsing, principle-based parsing, and perhaps any
other parsing systems which employ a stack.
The next section describes the graph-structure
stack itself. Sections 3, 4, 5 and 6 then describe the
use of the graph-structured stack in shift-reduce LR
parsing, ATN, Categorial Grammars, and principle-
based parsing, respectively. Section 7 discusses the
relationship between the graph-structured stack and
chart [5], demonstrating that chart parsing may be
viewed as a special case of shift-reduce parsing with
a graph-structured stack.
</bodyText>
<sectionHeader confidence="0.940959" genericHeader="introduction">
2. The Graph-structured Stack
</sectionHeader>
<bodyText confidence="0.988073">
In this section, we describe three key notions of the
graph-structured stack: splitting, combining and local
ambiguity packing.
</bodyText>
<subsectionHeader confidence="0.827932">
2.1. Splitting
</subsectionHeader>
<bodyText confidence="0.999452333333333">
When a stack must be reduced (or popped) in more
than one way, the top of the stack is split. Suppose
that the stack is in the following state. The left-most
element, A, is the bottom of the stack, and the right-
most element, E, is the top of the stack. In a graph-
structured stack, there can be more than one top,
whereas there can be only one bottom.
Suppose that the stack must be reduced in the
following three different ways.
</bodyText>
<sectionHeader confidence="0.509265" genericHeader="method">
&lt;-- CD Z
</sectionHeader>
<bodyText confidence="0.981204">
Then after the three reduce actions, the stack looks
</bodyText>
<page confidence="0.996505">
249
</page>
<figure confidence="0.785479333333333">
like:
/-- r
A B C G
</figure>
<subsectionHeader confidence="0.974596">
2.2. Combining
</subsectionHeader>
<bodyText confidence="0.9835535">
When an element needs to be shifted (pushed)
onto two or more tops of the stack, it is done only
once by combining the tops of the stack. For
example, if &amp;quot;I&amp;quot; is to be shifted to F, G and H in the
above example, then the stack will look like:
/-- \
</bodyText>
<sectionHeader confidence="0.710642" genericHeader="method">
H--/
</sectionHeader>
<subsectionHeader confidence="0.996404">
2.3. Local Ambiguity Packing
</subsectionHeader>
<bodyText confidence="0.999802">
If two or more branches of the stack turned out to
be identical, then they represent local ambiguity; the
Identical state of stack has been obtained in two or
more different ways. They are merged and treated as
a single branch. Suppose we have two rules:
</bodyText>
<sectionHeader confidence="0.7233045" genericHeader="method">
J &lt;-- F
J &lt;-- G
</sectionHeader>
<bodyText confidence="0.9874975">
After applying these two rules to the example above,
the stack will look like:
</bodyText>
<listItem confidence="0.427385">
•
</listItem>
<sectionHeader confidence="0.5211615" genericHeader="method">
A --- B C J
\-- H
</sectionHeader>
<bodyText confidence="0.999239">
The branch of the stack, &amp;quot;A-B-C-J&amp;quot;, has been
obtained in two ways, but they are merged and only
one is shown in the stack.
</bodyText>
<subsectionHeader confidence="0.7138115">
3. Graph-structured Stack and
Shift-reduce LR Parsing
</subsectionHeader>
<bodyText confidence="0.999979510638298">
In shift-reduce parsing, an input sentence is parsed
from left to right. The parser has a stack, and there
are two basic operations (actions) on the stack: shift
and reduce. The shift action pushes the next word in
the input sentence onto the top of the stack. The
reduce action reduces top elements of the stack
according to a context-free phrase structure rule In the
grammar.
One of the most efficient shift-reduce parsing
algorithms is LR parsing. The LR parsing algorithm
pre-compiles a grammar into a parsing table; at run
time, shift and reduce actions operating on the stack
are deterministically guided by the parsing table. No
backtracking or search is involved, and the algorithm
runs in linear time. This standard LR parsing
algorithm, however, can deal with only a small subset
of context-free grammars called LR grammars, which
are often sufficient for programming languages but
clearly not for natural languages. If, for example, a
grammar is ambiguous, then its LR table would have
multiple entries, and hence deterministic parsing
would no longer be possible.
Figures 3-1 and 3-2 show an example of a non-LR
grammar and its LR table. Grammar symbols starting
with &amp;quot;*&amp;quot; represent pre-terminals. Entries &amp;quot;sh If in the
action table (the left part of the table) indicate that the
action is to &apos;&apos;shift one word from input buffer onto the
stack, and go to state if. Entries &amp;quot;re if indicate that
the action is to &amp;quot;reduce constituents on the stack using
rule if. The entry &amp;quot;acc&amp;quot; stands for the action &amp;quot;accept&amp;quot;,
and blank spaces represent &amp;quot;error&amp;quot;. The goto table
(the right part of the table) decides to which state the
parser should go after a reduce action. The LR
parsing algorithm pushes state numbers (as well as
constituents) onto the stack; the state number on the
top of the stack indicates the current state. The exact
definition and operation of the LR parser can be found
in Aho and Ullman [3].
We can see that there are two multiple entries in
the action table; on the rows of state 11 and 12 at the
column labeled &amp;quot;&apos;prep&amp;quot;. Roughly speaking, this is the
situation where the parser encounters a preposition of
a PP right after a NP. If this PP does not modify the
NP, then the parser can go ahead to reduce the NP to
a higher nontemrinal such as PP or VP, using rule 6
or 7, respectively (re6 and re7 in the multiple entries).
If, on the other hand, the PP does modify the NP, then
</bodyText>
<page confidence="0.946526">
250
</page>
<listItem confidence="0.999258857142857">
(1) S --&gt; NP VP
(2) S --&gt; S PP
(3) NP --&gt; *n
(4) NP --&gt; *det *n
(5) NP --&gt; NP PP
(6) PP --&gt; *prep NP
(7) vP --&gt; *v NP
</listItem>
<figureCaption confidence="0.929919">
Figure 3-1: An Example Ambiguous Grammar
</figureCaption>
<figure confidence="0.976065357142857">
State *det *n *v *prep $ NP PP VP S
0 sh3 sh4 2 1
1 sh6 acc 5
2 sh7 sh6 9 8
3 sh10
4 re3 re3 re3
5 re2 re2
6 sh3 sh4 11
7 sh3 sh4 12
8 rel rel
9 re5 re5 re5
10 re4 re4 re4
11 re6 re6,sh6 re6 9
12 re7,sh6 re7 9
</figure>
<figureCaption confidence="0.989328">
Figure 3-2: LR Parsing Table with Multiple Entries
(derived from the grammar in fig 3-1)
</figureCaption>
<figure confidence="0.982526545454545">
/ s 1 \
/ \
/ a 1 \ \
/ \ \
/ / NP 12 \ \
/ / \ \
0---NP--2---v---7---NP--12---p---6---NP--11---p---6---NP--11---p---6
\ \ /
\ S -1 \•-- / \ NP
\ /
\ NP 6 /
</figure>
<figureCaption confidence="0.990777">
Figure 3-3: A Graph-structured Stack
</figureCaption>
<page confidence="0.979246">
251
</page>
<bodyText confidence="0.999657">
the parser must wait (sh6) until the PP is completed
so it can build a higher NP using rule 5.
With a graph-structured stack, these non-
deterministic phenomena can be handled efficiently in
polynomial time. Figure 3-3 shows the graph-
structured stack right after shifting the word &amp;quot;with&amp;quot; in
the sentence &amp;quot;I saw a man on the bed in the
apartment with a telescope.&amp;quot; Further description of
the generalized LR parsing algorithm may be found in
Tomita [7,8].
</bodyText>
<sectionHeader confidence="0.648407" genericHeader="method">
4. Graph-structured Stack and A&apos;TN
</sectionHeader>
<bodyText confidence="0.999431794117647">
An ATN parser employs a stack for saving local
registers and a state number when it visits a
subnetwork recursively. In general, an ATN is
nondeterministic, and the graph-structured stack Is
viable as may be seen in the following example.
Consider the simple ATN, shown in figure 4-1, for the
sentence &amp;quot;I saw a man with a telescope.&amp;quot;
After parsing &amp;quot;I saw&amp;quot;, the parser is in state S3 and
about to visit the NP subnetwork, pushing the current
environment (the current state symbol and all
registers) onto the stack. After parsing &amp;quot;a man&amp;quot;, the
stack is as shown in figure 4-2 (the top of the stack
represents the current environment).
Now, we are faced with a nondeterministic choice:
whether to return from the NP network (as state NP3
is final), or to continue to stay in the NP network,
expecting PP post nominals. In the case of returning
from NP, the top element (the current environment) is
popped from the stack and the second element of the
stack is reactivated as the current environment. The
DO register is assigned with the result from the NP
network, and the current state becomes S4.
At this moment, two processes (one in state NP3
and the other in state S4) are alive
nondetenninistically, and both of them are looking for
a PP. When &amp;quot;with&amp;quot; is parsed, both processes visit the
PP network, pushing the current environment onto the
stack. Since both processes are to visit the same
network PP, the current environment is pushed only
once to both NP3 and S4, and the rest of the PP is
parsed only once as shown in figure 4-3.
Eventually, both processes get to the final state S4,
and two sets of registers are produced as its final
results (figure 4-4).
</bodyText>
<sectionHeader confidence="0.9801585" genericHeader="method">
5. Graph-structured Stack and categorial
grammar
</sectionHeader>
<bodyText confidence="0.998832818181818">
Parsers based on categorial grammar can be
implemented as shift-reduce parsers with a stack.
Unlike phrase-structure rule based parsers,
Information about how to reduce constituents is
encoded in the complex category symbol of each
constituent with functor and argument features.
Basically, the parser parses a sentence strictly from
left to right, shifting words one-by-one onto the stack.
In doing so, two elements from the top of the stack are
inspected to see whether they can be reduced. The
two elements can be reduced in the following cases:
</bodyText>
<listItem confidence="0.950211125">
• x/ y —&gt; x (Forward Functional
Application)
•y• x\Y =&gt; X (Backward Functional
Application)
• x/Y Y/Z =&gt; X/Z (Forward Functional
Composition)
• y\ Z x/Y =&gt; X\ Z (Backward
Functional Composition)
</listItem>
<bodyText confidence="0.99085975">
When it reduces a stack, It does so non-destructively,
that is, the original stack is kept alive even after the
reduce action. An example categorial grammar is
presented In figure 5-1.
</bodyText>
<table confidence="0.720009">
SIM NP ((S\NP)\(EANP))/NP
Min (S\NP)/NP
with NP/N
a (NNANP)/NP,
telescope NP/N
</table>
<figureCaption confidence="0.964163">
Figure 5-1: An Example Categorial Grammar
</figureCaption>
<bodyText confidence="0.999546428571429">
The category, (S \NP), represents a verb phrase, as
it .becomes S if there is an NP on its left. The
categories, (NP\NP) and (S\NP)(S\NP), represent a
prepositional phrase, as it becomes a noun phrase or
a verb phrase if there is a noun phrase or a verb
phrase on its left, respectively. Thus, a preposition
such as &amp;quot;with&amp;quot; has two complex categories as in the
</bodyText>
<page confidence="0.993881">
252
</page>
<table confidence="0.9727576">
NP &gt; (S3) PP
(Si) &gt; (82) /----\
NP
&gt; [S4] &lt;----/
det PP
(NP1) &gt; (NP2) /----\
\ pron &gt; [NP3] &lt;----/
&gt; [NP4]
[I: final states
(): non-final states
</table>
<figure confidence="0.973359454545454">
NP
(PP2) &gt; [PP3]
A: Subj &lt;-- *
C: (Subj-verb-agreement)
A: Mods &lt;low *
Det &lt;-- *
A: Head &lt;-- *
A: Qua]. &lt;=x *
A: Head &lt;-- *
A: Prep &lt;-- *
A: PrepObj &lt;-- *
</figure>
<figureCaption confidence="0.93439">
Figure 4-1: A Simple ATN for &amp;quot;I saw a man with a telescope&amp;quot;
</figureCaption>
<figure confidence="0.979950538461539">
(PP1)
Sl-NP-S2
S2-v-S3
$3 -NP -S4
S4 -PP -S4
NP1-det-NP2
NP2 -n -NP3
NP3 -PP -NP3
NP1-pron-NP4
PP1-p-PP2
PP2-NP-PP3
bottom $3 NP3
[Subj: I [Det: a
</figure>
<figureCaption confidence="0.76962225">
MV: Head:
[root: see [root: man
tense: past]] Ni: Single]]
Figure 4-2: Graph-structured Stack in ATN Parsing &amp;quot;I saw a man&amp;quot;
</figureCaption>
<figure confidence="0.9300555625">
bottom
\ •
S3 NP3
[Subj: I [Det: a
NV: Head: man]
[root: see
tense: past]]
PP2 NP2
[Prep: with] [Det: a]
I.
54
[Subj: I
NV: [root: see
tense: past]
DO: [Det: a
Head: man]]
</figure>
<figureCaption confidence="0.96988">
Figure 4-3: Graph-structured Stack in ATN Parsing &amp;quot;I saw a man with a&amp;quot;
</figureCaption>
<table confidence="0.875132941176471">
bottom $4
[Subj: I
NV: [root: see
tense: past]
DO: [Det: a
Head: man]
Nods: [Prep: with
PrepObj: [Det: a
Head: telescope]]]
[Subj: I
NV: [root: see
tense: past]
DO: [Det: a
Head: nism0
Qual: [Prep: with
PrepObj: [Det: a
Head: telescope]]]
</table>
<figureCaption confidence="0.941348">
Figure 4-4: Graph-structured Stack in ATN Parsing &amp;quot;I saw a man with a telescope&amp;quot;
</figureCaption>
<figure confidence="0.9586265">
(S\NP)/N
bottom NP - (S\NP)/NP NP/N
</figure>
<figureCaption confidence="0.951939">
Figure 5-1: Graph-structured Stack in CG parsing
</figureCaption>
<figure confidence="0.9921774">
saw a&amp;quot;
(S\NP)/N
bottom ---- NP (S\NP)/NP NP/N
NP
S \NP
</figure>
<figureCaption confidence="0.976836">
Figure 5-2: Graph-structured Stack in CG parsing &amp;quot;I saw a man&amp;quot;
</figureCaption>
<figure confidence="0.992259333333333">
/ (S\NP)/N \
/ \
bottom --- NP --- (S\NP)/NP --- NP/N - - - N .....\ •
\ \ \ \ /-- (NP\NP) /NP
\ \
\ \ 1 - - - - &amp;quot;S\HP)/(S\HP))/NP
S\NP-
\ -/
//
</figure>
<figureCaption confidence="0.992209">
Figure 5-3: Graph-structured Stack in CG parsing &amp;quot;I saw a man with
</figureCaption>
<page confidence="0.994038">
254
</page>
<bodyText confidence="0.997443727272727">
example above. Nondeterminism in this formalism
can be similarly handled with the graph-structured
stack. After parsing &amp;quot;I saw a&amp;quot;, there is only one way to
reduce the stack; (S\NP) /NP and NP/N into
(S \ Np ) /N with Forward Functional Composition. The
graph-structured stack at this moment is shown in
figure 5-1.
After parsing &amp;quot;man&amp;quot;, a sequence of reductions takes
place, as shown in figure 5-2. Note that s \ NP is
obtained in two ways (s \ NP ) IN N s \NP and
s \ ) /NE, NP =&gt; S \NP), but packed into one node
with Local Ambiguity Packing described In section 2.3.
The preposition &amp;quot;with&amp;quot; has two complex categories;
both of them are pushed onto the graph-structured
stack, as in figure 5-3.
This example demonstrates that Categorial
Grammars can be implemented as shift-reduce
parsing with a graph-structured stack it is interesting
that this algorithm is almost equivalent to &amp;quot;lazy chart
parsing&amp;quot; described in Pareschi and Steedman 161
The relationship between the graph-structured stack
and a chart in chart parsing is discussed in section 7.
</bodyText>
<subsectionHeader confidence="0.8498385">
6. Graph-structured Stack and
Principle-based Parsing
</subsectionHeader>
<bodyText confidence="0.99991096">
Principle-based parsers, such as one based on the
GB theory, also use a stack to temporarily store partial
trees. These parsers may be seen as shift-reduce
parsers, as follows. Basically, the parser parses a
sentence strictly from left to right, shifting a word onto
the stack one-by-one. In doing so, two elements from
the top of the stack are always inspected to see
whether there are any ways to combine them with one
of the principles, such as augment attachment,
specifier attachment and pre- and post-head adjunct
attachment (remember, there are no outside phrase
structure rules in principle-based parsing).
Sometimes these principles conflict and there is
more than one way to combine constituents. In that
case, the graph-structure stack is viable to handle
nondeterminism without repetition of work Although
we do not present an example, the implementation of
principle-based parsing with a graph-structured stack
Is very similar to the implementation of Categorial
Grammars with a graph-structured stack. Only the
difference Is that, In categorial grammars, information
about when and how to reduce two constituents on
the top of the graph-structured stack is explicitely
encoded in category symbols, while in principle-based
parsing, it is defined implidtely as a set of principles.
</bodyText>
<sectionHeader confidence="0.821417" genericHeader="method">
7. Graph-structured Stack and Chart
</sectionHeader>
<subsectionHeader confidence="0.708575">
Some parsing methods, such as chart parsing, do
</subsectionHeader>
<bodyText confidence="0.999954625">
not explicitly use a stack. It is interesting to
Investigate the relationship between such parsing
methods and the graph-structured stack, and this
section discusses the correlation of the chart and the
graph-structured stack. We show that chart parsing
may be simulated as an exhaustive version of shift-
reduce parsing with the graph-structured stack, as
described informally below.
</bodyText>
<listItem confidence="0.573254875">
1. Push the next word onto the graph-
structured stack.
2. Non-destructively reduce the graph-
structured stack in all possible ways with
all applicable grammar rules; repeat
until no further reduce action is
applicable.
3. Go to 1.
</listItem>
<bodyText confidence="0.999967428571429">
A snapshot of the graph-structured stack in the
exhaustive shift-reduce parsers after parsing &amp;quot;I saw a
man on the bed in the apartment with&amp;quot; is presented in
figure 7-1 (slightly simplified, ignoring determiners, for
example). A snapshot of a chart parser after parsing
the same fragment of the sentence is also shown in
figure 7-2 (again, slightly simplified). It is clear that the
graph-structured stack in figure 7-1 and the chart in
figure 7-2 are essentially the same; in fact they are
topologically identical if we ignore the word boundary
symbols, &amp;quot;*&amp;quot;, in figure 7-2. It is also easy to observe
that the exhaustive version of shift-reduce parsing is
essentially a version of chart parsing which parses a
sentence from left to right.
</bodyText>
<page confidence="0.991796">
255
</page>
<figure confidence="0.998557066666667">
/ s \
/ \
// s \ \
\ \
/ NP \ \
/ \ \
bottom NP v NP
/P\ NP P NP
7
\ \
\
$ \ / \ NP
//
\
NP
</figure>
<figureCaption confidence="0.90037">
Figure 7-1: A Graph-structured Stack in an Exhaustive Shift-Reduce Parser
&amp;quot;I saw a man on the bed in the apartment with
</figureCaption>
<figure confidence="0.997446153846154">
/ 8 \
/ \
/ N \ \
/ \ \
/ / NP \ \
/ / \ \
*---NP---*---v---*---NP---*---p---*---NP---*---p---*---NP---*---p---*
\ \ / \ /
\
$ \----/ \ NP /
\
//
\ NP
</figure>
<figureCaption confidence="0.9556075">
&amp;quot;saw&amp;quot; &amp;quot;a man&amp;quot; &amp;quot;on&amp;quot; &amp;quot;tho bed&amp;quot; &amp;quot;in&amp;quot; &amp;quot;the apt&amp;quot; &amp;quot;with&amp;quot;
Figure 7-2: Chart in Chart Parsing
</figureCaption>
<bodyText confidence="0.387925">
&amp;quot;I saw a man on the bed in the apartment with&amp;quot;
</bodyText>
<page confidence="0.995716">
256
</page>
<sectionHeader confidence="0.952489" genericHeader="conclusions">
8. Summary
</sectionHeader>
<bodyText confidence="0.9999086">
The graph-structured stack was introduced in the
Generalized LR parsing algorithm [7, 8] to handle
nondeterminism in LR parsing. This paper extended
the general idea to several other parsing methods:
ATN, principle-based parsing and categorial grammar.
We suggest considering the graph-structure stack for
any problems which employ a stack
nondeterrninistically. It would be interesting to see
whether such problems are found outside the area of
natural language parsing.
</bodyText>
<sectionHeader confidence="0.98392" genericHeader="references">
9. Bibliography
</sectionHeader>
<reference confidence="0.997764214285714">
[1] Abney, S. and J. Cole.
A Government-Binding Parser.
In Proceedings of the North Eastern Linguistic
Society. XVI, 1985.
[2] Ades, A. E. and Steedman, M. J.
On the Order of Words.
Linguistics and Philosophy 4(4):517-558,
1982.
[3] Aho, A. V. and Ullman, J. D.
Principles of Compiler Design.
Addison Wesley, 1977.
[4] Barton, G. E. Jr.
Toward a Principle-Based Parser.
A.I. Memo 788, MIT Al Lab, 1984.
[5] Kay, M.
The MIND System.
Natural Language Processing.
Algorithmics Press, New York, 1973, pages
pp.155-188.
[6] Pareschi, R. and Steedman, M.
A Lazy Way to Chart-Parse with Categorial
Grammars.
25th Annual Meeting of the Association for
Computational linguistics :81-88, 1987.
[7] Tomita, M.
Efficient Parsing for Natural Language.
Kluwer Academic Publishers, Boston, MA,
1985.
[8] Tomita, M.
An Efficient Augmented-Context-Free Parsing
Algorithm.
Computational Linguistics 13(1-2):31-46,
January-June, 1987.
[9] Wehrli, E.
A Government-Binding Parser for French.
Working Paper 48, Institut pour les Etudes
Semantiques et Cognitives, Universite de
Geneve, 1984.
[10] Woods, W. A.
Transition Network Grammars for Natural
Language Analysis.
CACM13:pp.591-606, 1970.
</reference>
<page confidence="0.99718">
257
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.864780">
<title confidence="0.998598">Graph-structured Stack and Natural Language Parsing</title>
<author confidence="0.990218">Maseru Tomita</author>
<affiliation confidence="0.9933475">Center for Machine Translation and Computer Science Department Carnegie-Mellon University</affiliation>
<address confidence="0.999911">Pittsburgh, PA 15213</address>
<abstract confidence="0.988827454545454">A general device for handling nondeterminism in stack operations is described. The device, called a Stack eliminate duplication of operations throughout the nondeterministic processes. This paper then applies the graph-structured stack to various natural language parsing methods, including ATN, LR parsing, categorial grammar and principlebased parsing. The relationship between the graphstructured stack and a chart in chart parsing is also discussed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
<author>J Cole</author>
</authors>
<title>A Government-Binding Parser.</title>
<date>1985</date>
<booktitle>In Proceedings of the North Eastern Linguistic Society. XVI,</booktitle>
<contexts>
<context position="1250" citStr="[9, 1, 4]" startWordPosition="178" endWordPosition="180"> is also discussed. 1. Introduction A stack plays an important role in natural language parsing. It is the stack which gives a parser contextfree (rather than regular) power by permitting recursions. Most parsing systems make explicit use of the stack. Augmented Transition Network (ATN) [10] employs a stack for keeping track of return addresses when it visits a sub-network. Shift-reduce parsing uses a stack as a primary device; sentences are parsed only by pushing an element onto the stack or by reducing the stack in accordance with grammatical rules. Implementation of principle-based parsing [9, 1, 4] and categorial grammar [2] also often requires a stack for storing partial parses already built. Those parsing systems usually introduce backtracking or pseudo parallelism to handle nondeterminism, taking exponential time in the worst case. This paper describes a general device, a graph-structured stack. The graph-structured stack was originally introduced in Tomita&apos;s generalized LR parsing algorithm [7, 8]. This paper applies the graphstructured stack to various other parsing methods. Using the graph-structured stack, a system is guaranteed not to replicate the same work and can run in polyn</context>
</contexts>
<marker>[1]</marker>
<rawString>Abney, S. and J. Cole. A Government-Binding Parser. In Proceedings of the North Eastern Linguistic Society. XVI, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A E Ades</author>
<author>M J Steedman</author>
</authors>
<title>On the Order of Words.</title>
<date>1982</date>
<journal>Linguistics and Philosophy</journal>
<pages>4--4</pages>
<contexts>
<context position="1277" citStr="[2]" startWordPosition="184" endWordPosition="184">on A stack plays an important role in natural language parsing. It is the stack which gives a parser contextfree (rather than regular) power by permitting recursions. Most parsing systems make explicit use of the stack. Augmented Transition Network (ATN) [10] employs a stack for keeping track of return addresses when it visits a sub-network. Shift-reduce parsing uses a stack as a primary device; sentences are parsed only by pushing an element onto the stack or by reducing the stack in accordance with grammatical rules. Implementation of principle-based parsing [9, 1, 4] and categorial grammar [2] also often requires a stack for storing partial parses already built. Those parsing systems usually introduce backtracking or pseudo parallelism to handle nondeterminism, taking exponential time in the worst case. This paper describes a general device, a graph-structured stack. The graph-structured stack was originally introduced in Tomita&apos;s generalized LR parsing algorithm [7, 8]. This paper applies the graphstructured stack to various other parsing methods. Using the graph-structured stack, a system is guaranteed not to replicate the same work and can run in polynomial time. This is true fo</context>
</contexts>
<marker>[2]</marker>
<rawString>Ades, A. E. and Steedman, M. J. On the Order of Words. Linguistics and Philosophy 4(4):517-558, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>J D Ullman</author>
</authors>
<title>Principles of Compiler Design.</title>
<date>1977</date>
<publisher>Addison Wesley,</publisher>
<contexts>
<context position="5917" citStr="[3]" startWordPosition="976" endWordPosition="976">hift one word from input buffer onto the stack, and go to state if. Entries &amp;quot;re if indicate that the action is to &amp;quot;reduce constituents on the stack using rule if. The entry &amp;quot;acc&amp;quot; stands for the action &amp;quot;accept&amp;quot;, and blank spaces represent &amp;quot;error&amp;quot;. The goto table (the right part of the table) decides to which state the parser should go after a reduce action. The LR parsing algorithm pushes state numbers (as well as constituents) onto the stack; the state number on the top of the stack indicates the current state. The exact definition and operation of the LR parser can be found in Aho and Ullman [3]. We can see that there are two multiple entries in the action table; on the rows of state 11 and 12 at the column labeled &amp;quot;&apos;prep&amp;quot;. Roughly speaking, this is the situation where the parser encounters a preposition of a PP right after a NP. If this PP does not modify the NP, then the parser can go ahead to reduce the NP to a higher nontemrinal such as PP or VP, using rule 6 or 7, respectively (re6 and re7 in the multiple entries). If, on the other hand, the PP does modify the NP, then 250 (1) S --&gt; NP VP (2) S --&gt; S PP (3) NP --&gt; *n (4) NP --&gt; *det *n (5) NP --&gt; NP PP (6) PP --&gt; *prep NP (7) vP</context>
</contexts>
<marker>[3]</marker>
<rawString>Aho, A. V. and Ullman, J. D. Principles of Compiler Design. Addison Wesley, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E Jr Barton</author>
</authors>
<title>Toward a Principle-Based Parser.</title>
<date>1984</date>
<journal>A.I. Memo 788, MIT Al Lab,</journal>
<contexts>
<context position="1250" citStr="[9, 1, 4]" startWordPosition="178" endWordPosition="180"> is also discussed. 1. Introduction A stack plays an important role in natural language parsing. It is the stack which gives a parser contextfree (rather than regular) power by permitting recursions. Most parsing systems make explicit use of the stack. Augmented Transition Network (ATN) [10] employs a stack for keeping track of return addresses when it visits a sub-network. Shift-reduce parsing uses a stack as a primary device; sentences are parsed only by pushing an element onto the stack or by reducing the stack in accordance with grammatical rules. Implementation of principle-based parsing [9, 1, 4] and categorial grammar [2] also often requires a stack for storing partial parses already built. Those parsing systems usually introduce backtracking or pseudo parallelism to handle nondeterminism, taking exponential time in the worst case. This paper describes a general device, a graph-structured stack. The graph-structured stack was originally introduced in Tomita&apos;s generalized LR parsing algorithm [7, 8]. This paper applies the graphstructured stack to various other parsing methods. Using the graph-structured stack, a system is guaranteed not to replicate the same work and can run in polyn</context>
</contexts>
<marker>[4]</marker>
<rawString>Barton, G. E. Jr. Toward a Principle-Based Parser. A.I. Memo 788, MIT Al Lab, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>The MIND System. Natural Language Processing.</title>
<date>1973</date>
<pages>155--188</pages>
<publisher>Algorithmics Press,</publisher>
<location>New York,</location>
<contexts>
<context position="2352" citStr="[5]" startWordPosition="341" endWordPosition="341">he graph-structured stack, a system is guaranteed not to replicate the same work and can run in polynomial time. This is true for all of the parsing systems mentioned above; ATN, shift-reduce parsing, principle-based parsing, and perhaps any other parsing systems which employ a stack. The next section describes the graph-structure stack itself. Sections 3, 4, 5 and 6 then describe the use of the graph-structured stack in shift-reduce LR parsing, ATN, Categorial Grammars, and principlebased parsing, respectively. Section 7 discusses the relationship between the graph-structured stack and chart [5], demonstrating that chart parsing may be viewed as a special case of shift-reduce parsing with a graph-structured stack. 2. The Graph-structured Stack In this section, we describe three key notions of the graph-structured stack: splitting, combining and local ambiguity packing. 2.1. Splitting When a stack must be reduced (or popped) in more than one way, the top of the stack is split. Suppose that the stack is in the following state. The left-most element, A, is the bottom of the stack, and the rightmost element, E, is the top of the stack. In a graphstructured stack, there can be more than o</context>
</contexts>
<marker>[5]</marker>
<rawString>Kay, M. The MIND System. Natural Language Processing. Algorithmics Press, New York, 1973, pages pp.155-188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Pareschi</author>
<author>M Steedman</author>
</authors>
<title>A Lazy Way to Chart-Parse with Categorial Grammars.</title>
<date>1987</date>
<booktitle>25th Annual Meeting of the Association for Computational linguistics :81-88,</booktitle>
<marker>[6]</marker>
<rawString>Pareschi, R. and Steedman, M. A Lazy Way to Chart-Parse with Categorial Grammars. 25th Annual Meeting of the Association for Computational linguistics :81-88, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
</authors>
<title>Efficient Parsing for Natural Language.</title>
<date>1985</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Boston, MA,</location>
<contexts>
<context position="1661" citStr="[7, 8]" startWordPosition="236" endWordPosition="237">a primary device; sentences are parsed only by pushing an element onto the stack or by reducing the stack in accordance with grammatical rules. Implementation of principle-based parsing [9, 1, 4] and categorial grammar [2] also often requires a stack for storing partial parses already built. Those parsing systems usually introduce backtracking or pseudo parallelism to handle nondeterminism, taking exponential time in the worst case. This paper describes a general device, a graph-structured stack. The graph-structured stack was originally introduced in Tomita&apos;s generalized LR parsing algorithm [7, 8]. This paper applies the graphstructured stack to various other parsing methods. Using the graph-structured stack, a system is guaranteed not to replicate the same work and can run in polynomial time. This is true for all of the parsing systems mentioned above; ATN, shift-reduce parsing, principle-based parsing, and perhaps any other parsing systems which employ a stack. The next section describes the graph-structure stack itself. Sections 3, 4, 5 and 6 then describe the use of the graph-structured stack in shift-reduce LR parsing, ATN, Categorial Grammars, and principlebased parsing, respecti</context>
<context position="7516" citStr="[7,8]" startWordPosition="1315" endWordPosition="1315"> / \ \ 0---NP--2---v---7---NP--12---p---6---NP--11---p---6---NP--11---p---6 \ \ / \ S -1 \•-- / \ NP \ / \ NP 6 / Figure 3-3: A Graph-structured Stack 251 the parser must wait (sh6) until the PP is completed so it can build a higher NP using rule 5. With a graph-structured stack, these nondeterministic phenomena can be handled efficiently in polynomial time. Figure 3-3 shows the graphstructured stack right after shifting the word &amp;quot;with&amp;quot; in the sentence &amp;quot;I saw a man on the bed in the apartment with a telescope.&amp;quot; Further description of the generalized LR parsing algorithm may be found in Tomita [7,8]. 4. Graph-structured Stack and A&apos;TN An ATN parser employs a stack for saving local registers and a state number when it visits a subnetwork recursively. In general, an ATN is nondeterministic, and the graph-structured stack Is viable as may be seen in the following example. Consider the simple ATN, shown in figure 4-1, for the sentence &amp;quot;I saw a man with a telescope.&amp;quot; After parsing &amp;quot;I saw&amp;quot;, the parser is in state S3 and about to visit the NP subnetwork, pushing the current environment (the current state symbol and all registers) onto the stack. After parsing &amp;quot;a man&amp;quot;, the stack is as shown in f</context>
</contexts>
<marker>[7]</marker>
<rawString>Tomita, M. Efficient Parsing for Natural Language. Kluwer Academic Publishers, Boston, MA, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
</authors>
<title>An Efficient Augmented-Context-Free Parsing Algorithm.</title>
<date>1987</date>
<journal>Computational Linguistics</journal>
<pages>13--1</pages>
<location>January-June,</location>
<contexts>
<context position="1661" citStr="[7, 8]" startWordPosition="236" endWordPosition="237">a primary device; sentences are parsed only by pushing an element onto the stack or by reducing the stack in accordance with grammatical rules. Implementation of principle-based parsing [9, 1, 4] and categorial grammar [2] also often requires a stack for storing partial parses already built. Those parsing systems usually introduce backtracking or pseudo parallelism to handle nondeterminism, taking exponential time in the worst case. This paper describes a general device, a graph-structured stack. The graph-structured stack was originally introduced in Tomita&apos;s generalized LR parsing algorithm [7, 8]. This paper applies the graphstructured stack to various other parsing methods. Using the graph-structured stack, a system is guaranteed not to replicate the same work and can run in polynomial time. This is true for all of the parsing systems mentioned above; ATN, shift-reduce parsing, principle-based parsing, and perhaps any other parsing systems which employ a stack. The next section describes the graph-structure stack itself. Sections 3, 4, 5 and 6 then describe the use of the graph-structured stack in shift-reduce LR parsing, ATN, Categorial Grammars, and principlebased parsing, respecti</context>
<context position="7516" citStr="[7,8]" startWordPosition="1315" endWordPosition="1315"> / \ \ 0---NP--2---v---7---NP--12---p---6---NP--11---p---6---NP--11---p---6 \ \ / \ S -1 \•-- / \ NP \ / \ NP 6 / Figure 3-3: A Graph-structured Stack 251 the parser must wait (sh6) until the PP is completed so it can build a higher NP using rule 5. With a graph-structured stack, these nondeterministic phenomena can be handled efficiently in polynomial time. Figure 3-3 shows the graphstructured stack right after shifting the word &amp;quot;with&amp;quot; in the sentence &amp;quot;I saw a man on the bed in the apartment with a telescope.&amp;quot; Further description of the generalized LR parsing algorithm may be found in Tomita [7,8]. 4. Graph-structured Stack and A&apos;TN An ATN parser employs a stack for saving local registers and a state number when it visits a subnetwork recursively. In general, an ATN is nondeterministic, and the graph-structured stack Is viable as may be seen in the following example. Consider the simple ATN, shown in figure 4-1, for the sentence &amp;quot;I saw a man with a telescope.&amp;quot; After parsing &amp;quot;I saw&amp;quot;, the parser is in state S3 and about to visit the NP subnetwork, pushing the current environment (the current state symbol and all registers) onto the stack. After parsing &amp;quot;a man&amp;quot;, the stack is as shown in f</context>
</contexts>
<marker>[8]</marker>
<rawString>Tomita, M. An Efficient Augmented-Context-Free Parsing Algorithm. Computational Linguistics 13(1-2):31-46, January-June, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Wehrli</author>
</authors>
<title>A Government-Binding Parser for French. Working Paper 48, Institut pour les Etudes Semantiques et Cognitives, Universite de Geneve,</title>
<date>1984</date>
<contexts>
<context position="1250" citStr="[9, 1, 4]" startWordPosition="178" endWordPosition="180"> is also discussed. 1. Introduction A stack plays an important role in natural language parsing. It is the stack which gives a parser contextfree (rather than regular) power by permitting recursions. Most parsing systems make explicit use of the stack. Augmented Transition Network (ATN) [10] employs a stack for keeping track of return addresses when it visits a sub-network. Shift-reduce parsing uses a stack as a primary device; sentences are parsed only by pushing an element onto the stack or by reducing the stack in accordance with grammatical rules. Implementation of principle-based parsing [9, 1, 4] and categorial grammar [2] also often requires a stack for storing partial parses already built. Those parsing systems usually introduce backtracking or pseudo parallelism to handle nondeterminism, taking exponential time in the worst case. This paper describes a general device, a graph-structured stack. The graph-structured stack was originally introduced in Tomita&apos;s generalized LR parsing algorithm [7, 8]. This paper applies the graphstructured stack to various other parsing methods. Using the graph-structured stack, a system is guaranteed not to replicate the same work and can run in polyn</context>
</contexts>
<marker>[9]</marker>
<rawString>Wehrli, E. A Government-Binding Parser for French. Working Paper 48, Institut pour les Etudes Semantiques et Cognitives, Universite de Geneve, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Transition Network Grammars for Natural Language Analysis.</title>
<date>1970</date>
<pages>13--591</pages>
<contexts>
<context position="933" citStr="[10]" startWordPosition="129" endWordPosition="129">ation of operations throughout the nondeterministic processes. This paper then applies the graph-structured stack to various natural language parsing methods, including ATN, LR parsing, categorial grammar and principlebased parsing. The relationship between the graphstructured stack and a chart in chart parsing is also discussed. 1. Introduction A stack plays an important role in natural language parsing. It is the stack which gives a parser contextfree (rather than regular) power by permitting recursions. Most parsing systems make explicit use of the stack. Augmented Transition Network (ATN) [10] employs a stack for keeping track of return addresses when it visits a sub-network. Shift-reduce parsing uses a stack as a primary device; sentences are parsed only by pushing an element onto the stack or by reducing the stack in accordance with grammatical rules. Implementation of principle-based parsing [9, 1, 4] and categorial grammar [2] also often requires a stack for storing partial parses already built. Those parsing systems usually introduce backtracking or pseudo parallelism to handle nondeterminism, taking exponential time in the worst case. This paper describes a general device, a </context>
</contexts>
<marker>[10]</marker>
<rawString>Woods, W. A. Transition Network Grammars for Natural Language Analysis. CACM13:pp.591-606, 1970.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>