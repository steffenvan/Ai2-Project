<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.540464">
American Journal of Computational Linguistics Microfiche 70
TEXT UNDERSTANDING:
</note>
<title confidence="0.762573">
A SURVEY
</title>
<author confidence="0.63492">
ROBERT YOUNG
</author>
<affiliation confidence="0.709610666666667">
Department of Computer Sciences
University of Texas
Austin, Texas 78712
</affiliation>
<author confidence="0.538235">
Copyright J978
</author>
<affiliation confidence="0.412008">
Association for Computational Linguistics
TABLE OF CONTENTS
</affiliation>
<address confidence="0.844556">
Introduction 3
1. The Content of. Connected Discourse 5
1.1 The Nature of Discourse Content 5
1.1.1 Barclay, Bransford and FrAnkq 6
1.1.2 Frederiksen 8
1.1.3 Kintsch 10
1.1.4 Thorndyke 11
1.2 The Structure of Discourse Content 12
1.2 1 Bartlett . . 13
1.2.2 Crothers 14
1.2.3 Grimes and Meyer 15
1.2.4 Kintsch and van Dijk 19
1.3 Some Considerations Regarding Memory Experiments 25
1.4 Discussion and Conclusi.ons 26
2. The Form of Connected Discourse 31
2.1 Structural Analysis of Text - 31
2.2 Kintsch and van Dijk 34
2.3 Rumelhart 36
2.4 Mandler and Johnson 38
2.5 Tho rndyke 40
2.6 Text Grammar 42
2.7 Discussion and Conclusions 44
3. Computational Models of Text Understanding 47
3.1 The Necessity of World Knowledge 49
3.1.1 Cha rniak 49
3.1.2 Rieger 56
3.1.3 Schank 60
3.2 The Organization of World Knowledge 67
Abelson . 0 OOO 68
3.2.1 Schank and OO
3.2.2 Phillips
3.3 Other Work • a. • • . ;64
3.4 Discussion and Conclusions 87
4. Final Observations 91
References 92
Page 3
</address>
<sectionHeader confidence="0.946346" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.983080088888889">
The goal of this study is to examine work that has something to offer
toward the construction of a computable model of text understanding, and
therefore toward cognitive models in general. The reason for the criterion of
computability is that this rather strict requirement makes vague
generalizations impossible (or at least more difficult), and forces exact
specification of processes being hypothesized. (However, this criterion is
frequently difficult to apply, and in some instances the author s decision was
undoubtedly a subjective one.)
It should be clearly pointed out that no attempt is made here to deal
with the semantics of individual sentences. A familiarity with recent work in
semant/c representation in cognitive psychology, linguistics and artificial
intelligence is assumed (see Norman and Rumelhart [75], Schank and Colby [73]
and Steinberg and Jakbbovits [71]) Although many problems in representing
the meaning of individual sentences remain unsolved, this study focuses on
those aspects of meaning that are conveyed only by groups of connected
sentences texts. Additionally, only work that attempts to deal with the
semantics or understanding of texts, as opposed to statistical or syntactic
analysis, is considered. This focus on text has also led to the omission of
studies of non-textual memory and of computational systems that understand and
solve problems stated in English or carry on dialogue. This omission is not
meant to imply that work in these areas has no relevance to text
understanding, but the different focus and additional constraints of these
studies make such implications difficult to isolate.
Page 4
The study is divided into three parts, which occasionally overlap. The
first section deals with the content of connected text - that is, what exactly
does text communicate. The work in this section is primarily that of
experimental psychologists interested in memory and recall. The second
section deals with the structure of text, apart from its specific content.
This work has been done mainly by cultural anthropologists and those
interested in the theory of literature, but is also being investigated by
experimental psychologists. The third section discusses computational models
proppsed by computational linguists, which include attempts to implement in
computer programs some of the processes discussed in the other sections. Each
section is concluded with a discussion of the emerging model of text
understanding. Finally, some directions for needed research are suggested.
It is hoped that this kind of interdisciplinary survey will call attention of
workers in one area to work in other areas addressing the same problems. This
type of communication is valuable in two distinct ways. When similar
conclusions are reached in different disciplines frequently using different
methods and with somewhat different goals, these conclusions must be given
special credence. On the other hand, it is sometimts the case that one
discipline completely overlooks a problem or some aspect of it due to their
own interests and biases. Such omissions need to be brought into sharp focus.
Page 5
</bodyText>
<sectionHeader confidence="0.295376" genericHeader="method">
1.0 THE CONTENT OF CONNECTED DISCOURSE
</sectionHeader>
<bodyText confidence="0.954217230769231">
This section will present a brief survey of the recent work of some
experimental psychologists concerned with the process of understanding
connected discourse. The details of their experiments will not be presented,
but the types of experiments and general conclusions will be discussed, as
well as any models proposed by the investigators. These results seem to
converge toward a single model, in spite of apparent contradictions.
Psychological work on text understanding is relevant to computational models
because humans are still the only good text understanders. Also, although
some aspects of psychological research, such as forgetting, are not currently
included in any serious way in computational models, it would appear that such
models have a very useful role to play in pointing out where significant
details of the process of text understanding are being handled intuitively by
the theorist, and have not really been defined in the theory.
</bodyText>
<subsectionHeader confidence="0.992684">
1.1 The Nature Of Discourse Content
</subsectionHeader>
<bodyText confidence="0.9995805">
The nature (general characteristics and features) of the meaning of
connected text will be examined first. The principle focus of these studies
is to compare the understanding of a text to the actual text and attempt to
characteFize the types of differences that are found.
</bodyText>
<note confidence="0.59726">
Page 6
1.1.1 Barclay, Bransford And Franks -
</note>
<bodyText confidence="0.939787833333333">
Barclay, Bransford and Franks in a large body of work (Bransford, Barclay
and rranks 172], Barclay (73), Bransford and Franks (73), Bransford and
Mc(&apos;attell 1741 and Franks and Bransford (74)) argue for the existence of
semiotic representations independent of the surface input, and propose active
plotesqes operating on the input. They describe sentences as information
which is used by the understander to construct a description of a situation.
Furthotmoro, they claim that the information used to construct the semantic
de!wription is not wholly contained in the sentences, but that an understander
utT,. his previous knowledge to a great extent. They do not make any definite
prepoqals regarding the form of the semantic representations. Typical
expotiments performed to test these hypotheses consist of recognition or
recall of rompound sentences like:
</bodyText>
<listItem confidence="0.932177333333333">
1. Three turtles rested beside a floating log, and a fish swam beneath
them.
2. Three turtles rested on a floating log, and a fish swam beneath them.
</listItem>
<bodyText confidence="0.998202285714286">
The phy,dcal situation described by the second sentence is essentially the
SAW if the pronoun &amp;quot;them&amp;quot; is replaced uith &amp;quot;it&amp;quot;. This situation differs from
that described in the first sentence, however. When subjects were presented
with a sentence in which the pronoun substitution had been made, those who had
held the firitt sentence were able to make the distinction, while those who
had heard the second made no distinction. The explanation offered is that
subjects used their spatial knowledge to create situation descriptions, and
</bodyText>
<subsectionHeader confidence="0.527868">
Page 7
</subsectionHeader>
<bodyText confidence="0.977451625">
when two different sentences produce the same description, it is difficult to
distinguish them.
Similar investigations used a sequence of sentences, each comparing two
objects from a set of five according to some dimension (e.g. position,
height, speed, weight). Subjects who knew that a single situation was being
described had a better memory for the situation, but were less able to
distinguish sentences they had heard from those implied by the described
situation. Once again, the conclusion is that a non-linguistic representation
is created when a meaningful text is understood.
A final group of studies involved descriptive texts that were ambiguous
or difficult to comprehend without an appropriate context. The context might
be a picture of the described situation or a meaningful title for the text.
In every case the results indicated the understander attempted to build a,
description of the whole situation, and when this was very difficult or
impossible, comprehension was low. (Related studies by Anderson, Reynolds,
Schallert and Goetz (76] and Scallert [76] utilize texts, each with two
</bodyText>
<subsectionHeader confidence="0.680174333333333">
totally different meanings. Evidence is obtained that one or the other
alternative is almost always chosen for the entire text. The effect of
subjects backgrounds on interpretations of these ambiguous texts is also
</subsectionHeader>
<bodyText confidence="0.9668928">
Studied, and a correlation between background and chosen interpretation is
claimed.)
The principal conclusion of these studies is that the process of
understanding text involves constructing a consistent unified meaning, which
is not simply the set of individual sentence meanings. It differs in that
</bodyText>
<subsectionHeader confidence="0.614618">
Page 8
</subsectionHeader>
<bodyText confidence="0.872725">
additional knowledge and organization iq introduced by the understander.
</bodyText>
<subsectionHeader confidence="0.865612">
1.1.2 Frederiksen
</subsectionHeader>
<bodyText confidence="0.997845095238095">
Frederiksen [75a, 75b] continues this line of thought, treating the
understanding of a discourse as the semantic &apos;knowledge that is acquired in
listening to the discourse. This knowledge is acquired by processes that
utilize prior knowledge, context, etc. and includes information which is
inferred as well as that explicitly presented. Frederiksen also argues that
the processes involved in understanding a discourse are direqfly related to
the process limitations of the proo.essor. The two processes that he discusses
are overgeneralization and inference. Overgeneralization is the discarding of
detail information resulting in a more goneral concept. He suggests that
overgeneralization reduces the amount of information to be understood, thus
reducing the processing load on the understander. Inferred information is
information which is assumed to be true even if it is not explicitly present.
This process is clhimed to reduce the processing load by eliminating the
necessity of completely lunderstanding every sentence. Frederiksen performed
neutral recall experiments and recall eNperiments in which the context - the
task assigued to the subject prior to
plesentall on of the story - was changed..
His conclusions are that ovcrgeneralizatlon and inferences are incorporated
into the semantic representation of the story as it is understood, and that
the context can influence the amOunt of inferencing that is done during
comprehension.
</bodyText>
<subsectionHeader confidence="0.692009">
Page 9
</subsectionHeader>
<bodyText confidence="0.978519703703704">
Frederiksen uses a simple, informally defined semantic representation in
the above studies. It consists of set inclusion, identity, and logical
implication relationships that hold among the concepts of the text. He
indicates the need for-a detailed model of the semantic representation, and in
other work, Frederiksen [75c] begiris to define such a representational scheme.
He proposes the use of two networks: a semantic network and a logical
network. The semantic network contains the representation of individual
propositions while the logical network is composed of relations that hold
between propositions that exist in the semantic network. Frederiksen&apos;s system
is probably the most elaborate yet proposed using the basic ideas of case
grammar represented by semantic networks. He begins with the fundamental
ideas of object and action hierarchies, although his are quite large and
contain numerous distinctions. He proposes a system that distinguishes
sixteen verb, cases, and a large number of relations specifying states,
quantification location, manner, time, order, proximity, tense and aspect.
His logical network consists of relations drawn from propositional logic plus
causality, and he proposes several modal operators. The complexity of this
proposal gives the impression of representational power, but it seems that
Frederiksen is still primarily, oriented toward the representation of
indiyidUal propositions. Although he shows the representation of simple time
and causally ordered actions sequences, he has not yet demonstrated the
adequacy of his system for text, in general. And, he has utilized a number of
elements of quantified modal logic without demonstrating their usefulness for
modelling human understanding of discourse. His discussions do raise a number
of interesting questions about representation, and certainly deserve
Page 10
consideration in the development of any set of semantic types and relations.
</bodyText>
<subsectionHeader confidence="0.874141">
1.1.3 Kintsch
</subsectionHeader>
<bodyText confidence="0.980693476190476">
Kintsch (741 ( reviewed by van Dijk (75b)) attempts to set forth a fairly
complete theory of language understanding. Kintsch&apos;s basic representational
unit is the proposition, and he includes discusion of the usual difficult
problems of definiteness (including generic versus specific distinctions) of
noun phrases, quantification, modality, implication and presupposition,
location, time and tense. He proposes a text base which underlies discourses,
but his revised and elaborated thought on this is discussed in Section 1.2.
,He describes a model of discourse processing in which he makes a distinction
between episodic and semantic memory, argues that the processing operations
must be well defined (he suggests pattern matching and completion, abstraction
and generation) and argues that recall is essentially a different process from
recognition in that recall requires input organization while recognition does
not.
Kintsch reports a number of experiments undertaken to test aspects of hid
theory. One conclusion that he reaches is that the semantic representation is
partially independent of the actual input sentences. One kind of experiment
performed to test this was the performance of a cammtsn task by subjects who
had read substantially the same material but in forms or varying comnlexity.
In other experiments he notes that sentences containing multiple propositions
are much less likely to be recalled (complet.,,ly) than are single propositiOn
sentences. This also supports the idea of an undetlying representation. A
</bodyText>
<subsectionHeader confidence="0.484752">
Page 11
</subsectionHeader>
<bodyText confidence="0.988280384615385">
related conclusion is that the agent of a proposition is the most likely case
to be recalled. However, Kintsch did find that in passive sentences, the
subject, rather than the agent, was the most likely to be recalled. A final
conclusion concerns the presence of inferred information in memory. Kintsch
found that immediate recall showed some difference between implicit and
explicit propositions, but that after twenty minutes or more the difference
had disappeared and the two were indistinguishable to the subjeet. An
interesting side result was the distinct difference in reading and recognition
times for argumentative versus descriptive discourse. The argumentative
discourse required significantly more time in both tasks.. Kintsch also
includes reaction time experiments to study proposition retrieval,
determination of the truth or falsity of general propositions and processing
of complex lexical items but these will not be discussed.
</bodyText>
<subsectionHeader confidence="0.781565">
1.1.4 Thorndyke
</subsectionHeader>
<bodyText confidence="0.99369304">
Additional investigations on the role of inference in understanding text
have been carried out by Thorndyke [76]. He uses compound sentences asserting
a causal connection which is net familiar or obvious. For example:
The hamburger chain owner was afraid that his love for french fries would
ruin his marriage.
Sentences like these are imbedded in a meaningful text, and are followed later
in the text by a continuation sentence which references the previously
mentioned relationship. This continuation sentence might be neutral like
Page 12
He decided to see a marriage counselor in order to save his marriage.
or it might encourage one particular explanatory inference like
He decided to join weight watchers in order to save his marriage.
which strongly suggests the inference
He is fat from eating french fries.
Thorndyke uses recognition tests after the presentation of the story to
compare inferences that have been reinforced by a continuation sentence with
neutral and inappropriate inferences. He found the reinforced inferences much
more likely to be recognized as part of the text than the neutral inferences,
while recognition of inappropriate inferences was very unlikely.
Thorndyke suggests that although this evidence indicates that inferences
are made and stored as part of the understanding of a text, a more important
implication exists. This is that the role of inferencing is to aid in the
&apos;integration of new information into 0,e larger framework of the understanding
of a text when no appropriate understanding could be obtained from only the
explicitly stated information.
</bodyText>
<subsectionHeader confidence="0.99796">
1.2 The Structure Of Discourse Content
</subsectionHeader>
<bodyText confidence="0.999382">
Attempts to characterize the content of text necessarily lead to a
structuring of that content. Simple one-dimensional representations in which
propositions are connected only by co-reference or by time or causal ordering
</bodyText>
<subsectionHeader confidence="0.788121">
Page 13
</subsectionHeader>
<bodyText confidence="0.981126">
are adequate for only a restricted class of texts. The following studies all
propose some type of multi-level representation of content.
</bodyText>
<subsectionHeader confidence="0.976862">
1.2.1 Bartlett -
</subsectionHeader>
<bodyText confidence="0.999444066666667">
It seems appropriate to begin a discussion of memory structure with
Bartlett (32] since he is often referenced as the originator of several
currently popular hypotheses. It should be remembered that Bartlett was
concerned with memory in general and the phenomena associated with recall, and
did not restrict himself to the study of discourse. His principle conclusions
were that memories are not stored in isolated, static units, and that exact
recall is very rare. In fact, he often found cases of gross distortions in
the recall of his subjects. He suggests that instead, memory is composed of a
number of active, organized masses of past reactions and experiences, which he
designates schemata, and a small amount of outstanding detail. Remembering is
seen as a constructive process strongly affected by memories other than the
one being retrieved. His ideas of organization beyond the sentence, of
storage of something other than actual input sentences, and of active
processes that modify text prior to its reproduction in recall are all
currently enjoying wide acceptance.
</bodyText>
<equation confidence="0.4496205">
Page 14
1.2.2 Crothers
</equation>
<bodyText confidence="0.942742058823529">
Crothers [72] is concerned with the recall of short, expository
paragraphs containing material not likely to be familiar to his subjects. He
presents results obtained with paragraphs about hebulae. He proposes the
existence of a semantic representation underlying any particular discourse
which contains the meaning of the discourse, but does not reflect the details
of the surface form of the tet. Thus&apos;, a single semantic representation might
underlie numerbus actual discourses. His semantic representation assumes a
conceptual taxonomy showing the relationship of each known concept to its
superordinate concept (i.e. the familiar semantic hierarchy), but he does not
provide details on this. He also proposes an addit±onal set of hierarchies
showing the relationships of the concepts in a particular discourse. For
example, the following:
NEBULA
OR SEEN
11M, IMO som.
means that a nebula is either seen or it is not seen, where all of the
concepts are defined on the conceptual graph. Crothers does not Carefully
define his notation, so it is not clear exactly what may or may not occur at a
node. Primarily, concepts (words) OT connectives are used (e.g. NEBULA. IS
AND, OR, WHY). Since he deals only with expository, descriptive material he
finds no need to represent actions or time. Crothers performed recall
experiments on two different versions of the same material, and arrives at
three conclusions. First, he concludes that the surface paragraph is not a
Page 15
significant factor in recall, thus arguing for a surface-independent semantic
representation for the paragraphs. His- last two conclusions are negative
rejecting hypotheses he had previously suggested. The first of these is that
superordinate nodes in the meaning of the paragraph will be recalled more
frequently than subordinate nodes. The second rejected hypothesis is that
information not directly connected to the most superordinate node of the
paragraph is lass likely to be recalled than information that is connected.
Since his results do not support either of these hypotheses, Crothers suggests
that other variables, such as frequency of concepts, are probably also of
importance.
</bodyText>
<subsectionHeader confidence="0.526889">
1.2.3 Grimes And Meyer -
</subsectionHeader>
<bodyText confidence="0.999837333333333">
Grimes [75] has proposed an extended case grammar supplemented with what
he calls rhetorical predicates, which are higher-order predicates that take
other propositions as their arguments. He subdivides rhetorical predicates
into three groups: paratactic, hypotactic and neutral. Paratactic predicates
always take arguments of equal weight (i.e. no argument is subordinate to any
other argument). Hypotactic predicates have one dominant argument, to which
the others are subordinate. Neutral predicates may be used as either
paratactic or hypotactic predicates. The following is a list of some of the
rhetorical predicates proposed by Grimes, and their basic meaning:
</bodyText>
<figure confidence="0.802924666666667">
Page 16
Paratactic predicrtes
ALTERNATIVE Options, or
RESPONSE Question and answer, problem and
solution
Hypotactic predicates
ATTRIBUTION - Gives qualities of the dominant
proposition
EQUIVALENT - Gives restatement of the dominant
</figure>
<bodyText confidence="0.950799823529412">
proposition
SPECIFIC Gives more specific information
about a general dominant
proposition
EXPLANATION - Gives an abstract eXplanation for
the specific dominant
proposition
ANALOGY - Gives an analogy to support the
dominant proposition
Neutral predicates
COLLECTION - List of elements related in some
unspecified way
COVARIANCE - Causality, an antecedent and
consequent
Meyer [75] uses Grimes&apos; rhetorical predicates and most of his case-
grammar to create analyses of paragraphs she uses in recall experiments. For
example:
</bodyText>
<figure confidence="0.758922444444444">
Page 17
RESPONSE
PROBLEM
COLLECTION
need to generate electric power
protect environment
rational utilization of natural resources
SOLUTION
breeder reactors
</figure>
<bodyText confidence="0.906471">
would be the essentials of an analysis of a paragraph whi.ch stated that the
need to generate clearic power while protecting the environment and
rationally utilizing natural resources is a problem which breeder reactors
solves. Meyer indicates the hierarchical structure through the use of
indentation. Since the rhetorical predicates in the above example were tall
paratactic, nb indentation was lased. However, the following example:
finite reserves of natural resources
</bodyText>
<sectionHeader confidence="0.833987" genericHeader="method">
SPECIFIC
COLLECTION
</sectionHeader>
<bodyText confidence="0.90050275">
coal
oil
gas
shows the subordination of the specific set of resources to the general idea.
</bodyText>
<sectionHeader confidence="0.602229" genericHeader="method">
Meyer&apos;s analyses of expository paragraphs using this scheme always follow the
</sectionHeader>
<subsectionHeader confidence="0.959549">
author&apos;s organizational structure and always result in a purely hierarchical
</subsectionHeader>
<bodyText confidence="0.959208">
structure like those depicted above Meyer also recognizes h class of
sentences that can occur in expository paragraphs, but do not contribute any
Page 18
content to the passage. She calls these signalling because their function is,
to explicitly indicate the structure of the passage. She notes four types of
</bodyText>
<listItem confidence="0.983427833333333">
1. SpecificAtiOn of the structure (e.g. &amp;quot;Two options exist.&amp;quot;)
2. Prematurely revealed information abstracted from the remainder of the
passage (e.g. &amp;quot;The alternatives are solar energy, nuclear energy,
geothermal energy and laser fusion energy.&amp;quot;)
3. Summary statements
4. Pointer words (e.g. &amp;quot;unfortunately&amp;quot;, &amp;quot;an impOrtant point is&amp;quot;)
</listItem>
<bodyText confidence="0.999437545454545">
Meyer conducted recall experiments varying the position of certain material in
the content hierarchy of passages, and including or omitting certain
sIgnalling information. Her principle conclusion is that material
structurally higher in the content hierarchy is remembered substantially
better than identical information placed lower in the hierarchy in another
passage. She also notes that passages with identical structure but totally
different content exhibit very similar patterns of recall at the higher
levels. However, at the lower levels, the pattern of recall varied,
indicating content dependence. In regard to signalling, she concludes that it
has very little&apos; effect at the top level, but seems beneficial at the middle
levels.
</bodyText>
<subsectionHeader confidence="0.443871">
Page 19
</subsectionHeader>
<bodyText confidence="0.999931615384616">
In regard to a theoretical explanation of why the highest ideas are
recalled best, Meyer suggests three proposals and points out the weaknesses of
each. First, lower propositions might be subsumed by higher ones with the
passage of time. Immediate recall experiments show that the phenomenon occurs
even without a time lapse, however. Secondly, At is possible that all
propositions are stored but that retrieval is easier at the higher levels.
She criticizes this proposal because even cued recall experiments were unable
to retrieve the lower propositions. Finally, perhaps only higher ideas are
ever stored. But her results show that the loss of lower level propositions
begins immediately, but continues with time at a more rapid rate than for the
higher level propositions. Meyer suggests that probably some combination of
these processes is occurring, as well as other processes sensitive to the
structure of the passage as a whole.
</bodyText>
<subsectionHeader confidence="0.816727">
1.2.4 Kintsch And Van Dijk
</subsectionHeader>
<bodyText confidence="0.988483909090909">
Kintsch and van Dijk (van Dijk (74,75a,76), van Dijk and Kintsch
(forthcoming) and Kintsch and van Dijk (76)) present a model for the
organization of discourse as 4 whole, and a number of (sometimes informal)
experiments attempting to validate the model. Beginning at the lowest level,
a discourse representation consists of a set of propositions. A distinction
is made between two different types of representation, called text bases, as
to whether all implied information is made explicit or whether it is left
implicit. The notion of coherence is introduced, which is the property that
distinguishes a discourse from a random set of sentences. Referential
Page 20
identity has been suggested as a major test of coherence, but it is not an
adequate definition (see discussion of coherence and Bellert&apos;s proposals in
ection 3). Kintsch and van Dijk argue that coherence is more accurately-
cap,tured by the requirement that each proposition of the text base be
connected with one or more preceding propositions. Propositions are connected
if one is a condition for the other, with the strength of the connection
ranging from possible to necessary. Thus, an explicit text base is one
containing all of the propositions necessary for coherence, while an implicit
text base is one with some of these propositions deleted. The deleted
propositions are those that can be assumed known or which normally would be
inferred by the understander. Different types of discourse would have
different rules governing the deletion of propositions. For example, casual
converpation would allow more deletion than careful argumentation.
The text base is organized hierarchically under macro-structures, which
are higher brder propositions. Macro-structures may be related to their
propositional arguments by a number of macro-rules. Four of these rules are
suggested. -The first, information reduction, is a rule of generalization
which would explain the existence of the macro-structure
John is ill.
which had as its arguments propositions like
John has a fever.
John has the flu.
The second rule, deletion, would explain the relationship between
</bodyText>
<equation confidence="0.400817">
Page 21
</equation>
<bodyText confidence="0.997278">
Peter saw a ball.
and its subordinate propositions
Peter saw a ball.
The ball was blue.
The third rule, integration, combines a central event with its normal
pre-conditions, results and component actions. Thus
John went to Paris.
might have as its arguments
John took a cab to the station.
He bought tickets.
He went to Paris.
The fourth rule, construction, explains the relationship between a complex
fact and its component parts. For example, the macro-structure
Peter built a house.
might have as its arguments the event sequence
Peter laid a foundation.
Peter built walls.
Peter built a roof.
In general, two conditions hold for all macro-structures. First, the
</bodyText>
<subsectionHeader confidence="0.442076">
Page 22
</subsectionHeader>
<bodyText confidence="0.94667394117647">
macro-structure must be semantically implied by its micro-structure (i.e. its
propositional arguments). The exact meaning of the term implication is not
clearly stated by Kintsch and van Dijk. They sometimes refer to it as
entailment and treat it as a formal logical relation, but at other times say
that it is not logical in the strict sense. In any case, it is clear that
there are semantic rules or structures that allow creation of macro-structures
such as those above. The second condition is that the sequence of
macro-structures representing a coherent text base must itself be coherent.
kecalling the definition of toherence, this implies that no macro-structure
may delete information contained in its micro-structure which is a condition
for another macro-structure An important consequence of this is that the
macro-structures of. a text, taken by themselves, torm a coherent summary of
that text.
A final component of a text representation is the specification of the
fort or structure of the discourse, but discussion of this proposal will be
postponed until Section 2. Their investigations are primarily with narrative
text, and they call the narrative structure a schema.
</bodyText>
<tableCaption confidence="0.705786428571429">
Kintsch and van&apos;Dijk stiggest that the concept of -narrative st-ructure
combined with the idea of macro-structures leads them to the following
hypotheses regarding, comprehension and recall of narrative. First
macro-structures are primarily what is stored when a text is understood.
Recall uses macro-structures as a starting point in retrieval, and summaries
directly reflect the macro-structures. Secondly, since macro-structures are
essential to comprehension, they must be constructed at the time of reading.
</tableCaption>
<bodyText confidence="0.926526111111111">
Page 23
Finally, a narrative schema is necessary for the organization of the text
representation. Kintsch and van Dijk have done a number of summary, recall
and other experiments to test these hypotheses. Most use a 1600 word text
from The Decameron. In recall experiments, the propositions corresponding to
the macro-structures were found to be recalled most often, and were very
unlikely to disappear in delayed recall (nine days later). In contrast, many
other propositions recalled immediately were omitted in the delayed recall.
The propositions most likely to be recalled have the following functions:
</bodyText>
<listItem confidence="0.920923692307692">
1. Introduce main characters
2. Give major goals of characters
3. Describe actions leading to these goals
4. Describe events occurring to these characters leading to or from
their goals
while propositions having the following functions are likely to be forgotten:
1. Sotting description
2. Preparatory actions
3. Mental actions
4. Component actions
Page 24
5. Probable consequences of an action or an event
6. Meta-narrative statements by the author
</listItem>
<subsectionHeader confidence="0.714111">
Summarizing experiments showed that summaries of the story*were very much
</subsectionHeader>
<bodyText confidence="0.920516222222222">
like delayed recall. When a summary was written after presentation of each
successive part of the story, followed immediately by a complete summary,
propositions were included in the partial summaries that were omitted in the
final summary. A final group of recall experiments compared recall of a 70
word paragraph in isolation, to cued recall of the same paragraph imbedded in
an 850 word text. Surprisingly, the recalls were almost identical But when
the entire text was recalled, the reproduction of the particular paragraph was
much smaller and less accurate than in the first two cases. Their conclusions
from these results are that the recall of small amounts of text is a different
process from the recall of a long text, that recall of a long text relies .on
the macro-structure of the text as a means of organizing the text, that the
micro-structure is forgotten much more easily and that summarizing is based on
the macro-structure.
Finally, some experiments were done in which incorrect summaries were
presented prior to the presentation of the story. These were found to have
practically no influence on the final understanding of the story, and the
subjects were unable to accurately recall the incorrect summaries.
Page 25
</bodyText>
<subsectionHeader confidence="0.762992">
1.3 Some Consideratiot&apos;s Regarding Memory Experiments
</subsectionHeader>
<bodyText confidence="0.976181166666667">
Before attempting to describe an informal model based upon these
hypotheses and experimental results, some general criticisms of memory
experiments expressed by Spiro [75] deserve consideration. Spiro&apos;s principle
argument is that recall consists of active reconstruction processes, rather
than passive processes which merely reproduce that whicj1 was stored at the
time of comprehension. His general position is thus much like that of
Bartlett, and he observes that almoat all experimenters since Bartlett have
failed to replicate his findings of significant errors in recall. .As a
result, psychologists have tended to concentrate on the process of
understanding, or construction, and have treated recall as somethitg. of a
simple retrieval process. Spiro argues that for reconstructive errors to
occur, it is necessary that the input be understood in terms of some
pre-existing schema. Any text that results in the creation of a new schema
would not be subject to the same kind of effects of previous knowledge. The
interference caused by the pre-existence of schemata is even more pronounced
If other uses of the schema are made between the time of comprehension and the
time of recall. Spiro also points out that any experimental subject would be
unlikely to integrate material read or heard in an experiment into his general
knowledge since its truth and source are unknown. This coupled with the
desire to perform well, could easily result it a considerably modified process
of understanding text in experimental settings,. Spiro performed a number of
recall experiments which support his hypothesis. He used text about
interpersonal relationships and instructed the subjects that the experiment
was concerned with their reactions to the incidents described, thus maximally
</bodyText>
<equation confidence="0.763117">
Page 26
</equation>
<bodyText confidence="0.997902357142857">
involving their pre-existing strucLures in the understanding process. Spiro
found substantial errors ia the subjects recalls, which he explains as the
effect of interaction with pre-existing structures for interpersonal
relationships. (Kintsch and van Dijk [75] found similar results using stories
from the Bible.) Spiro concludes that most text recall experiments have not
shown these effects because they did not meet the required conditions, but
frequently involved the presentation of material that was totally new and
which was kept isolated by the subject. These criticisms not only are
relevant to the question of construction versus reconstruction, but also to
inferring discourse organization frot recall experiments, and indicate that
one must be very cautious in generalizing from the results of text recall
experiments due to the many interactions between the subject&apos;s knowledge, the
experimental setting, the type and content of the text and the
extra-experimental effects (or lack of them) in long term experiments.
</bodyText>
<subsectionHeader confidence="0.781017">
1.4 Discussion And Conclusions
</subsectionHeader>
<bodyText confidence="0.999397375">
A great deal of agreement is seen in the preceding studies. The idea
that the meaning of a text differs from the meaning of its individual
sentences, in that prior knowledge is used to infer implicit information
during comprehension, is generally accepted. The idea that this meaning must
be well structured, or coherent, is also expressed directly or indirectly by
most of the researchers. However, explicit disagreement exists on both the
nature of content structure, and its relationship to recall. Crothers and
Meyer disagree as to whether a neutral structure reflecting pre-existing
</bodyText>
<equation confidence="0.802568">
Page 27
</equation>
<bodyText confidence="0.978238918367347">
knowledge is built, or the author&apos;s structttre used. Kintsch and. van Dijk
essentially use both approaches since the time ordering in narrative is author
defined (although the concept of time is pre-existent), but the
macro-structures which hierarchically organize the text are pre-existent.
Meyer, Kintsch and van Dijk all agree that propositions higher in the
structure are more likely to be recalled, but Crorhers evidence did not
support this ctinclusion. Clearly, this hypothesis, if true, could be
confirmed only if it is tested against the appropriate content structure.
Spiro&apos;s comments regarding the use (pr lack of use) of pre-existing structures
are relevant. In the case of unfamiliar expository material, such as that
used by Crothers and Meyer, it seems reasanable to suppose that the author s
organization would be used to organize the semantic representation due to the
lack (or non-use) of any appropriate pre-existing content structures. Thus
Meyer&apos;s results support the importance of propositional level, and Crothers
results do not. Yowever, a familiar structure, like an action sequence, is
understood in the.same way regardless of presentation setting. Thus, Kintsch
and van Dijk found that the role of a proposition in the pre-existing
structure (the macro-structures) was primary in determining its importance.
It should be noted that even Meyer found variations in the recall of mid,--level
propositions that she could not explain by reference to the author&apos;s
organization. It is plausible to assume that these variations were caused by
individual differences in prior knowledge, resulting in differing content
structures.
Page 28
In light of this, it seems plausible to propose a general model that
distinguishes the following component processes .of text understanding
(realizing that like almost all distinctions, such as syntax versus semantics,
they are really inadequate, but useful, oversimplifications). First there is
the process of comprehensioh of the surface structure which builds a
representation that is independent of the surface form of the text. This
representation contains as much inferred information as is necessary to meet
some minimal level of understandability, or coherence. This representation is
organized hierarchically by higher level content structures which summarize or
generalize over a larger amount of detailed information. These higner-level
structures would normally be pre-existing (i.e. known to the understander)
although a text could result in the creation of new structures. Different
types of texts could certainly differ in the complexity of each of these
tasks, explaining the variation in difficulty of understanding.
The process(es) explaining forgetting, and the integration of new
information into prior knowledge, operates on this text representation. This
process is poorly understood, and there are no well defined hypotheses about
its operation. It appears to operate primarily on the content structure of a
text. So, for example, Spiro&apos;s subjects integrated information from the
stories they read into their general expectations about love and courtship,
and lost the specifics of the text, even recalling it with radical
modifications This process would explain the almost total loss of detail
information with time, as well as the interactions and distortions caused by
previous knowledge.
Page 29
Finally, recall is a retrieval process which operates on the current form
of the representation. If that form is relatively unchanged since
comprehension, recall may be almost distortion-free. But if significant
changes have occurred, recall will be distorted. As suggested by Kintsch and
van Dijk, summary is seen as recall to a controlled depth. Retrieval accesses
the higher-level organization first, and uses these structures to access more
detailed information. As retrieved information is generated as output text, a
test of coherence would be made. If something has been forgotten or Changed
so that a necessary explanation or link is missing, the retrieval process
would supply a probable piece of information from the general pre-existing
structures. This, along with modifications from integration into prior
knowledge, accounts for the reconstructive aspect of recall.
This general model does not account for the recall of very specific
surface details (e.g. words and constructions used in the input text) but as
suggested by Kintsch&apos;s work, it seems best to treat this as a process separate
from the general understanding of text. One other inadequacy of model is
that it specifies complete comprehension of all input propositions, including
assignment to an appropriate role in a higher level structure. Frederiksen
suggests that overgeneralization is a loss of detail which reduces the
processing load. The idea that partial processing is sometimes done on input
information is also suggested by Bobraw and Norman [75]. They describe such
processes as resource-limited. This kind of processing seems to be indicated
by facts such as loss of detail in immediate recall and the subjective
impression of partial comprehension in a number of situations (such as reading
very rapidly, reading while partially distracted or reading very complex
Page 30
material). However, while the idea of discarding comprehended ihformationA
could be described computationally, selective comprehension is a process that
requires further investigation.
One of the principle contributions of computational investigations with
this sort of model will be specification of the processes of comprehension,
which can only be done by specifying the nature of pre-existing memory
structures. Meyer&apos;s work is an example of the use of undefined basic
structures. She criticizes Crothers for requiring two graphs to represent a
text one of which is his fundamental hierarchy of knOwn concepts. She,
instead, simply doesn&apos;t define any of her predicates first or higher order,
apparently taking them as primitive. Assuming that one attempted to define
even the argument roles for the rhetorical predicates, enormous difficulty
would be encountered. Advocates of case systems have always had difficulty
defining the exact role of cases, or delimiting the class of entities that
could fill a case role. Consider how much more difficult it would be to
define what pairs of things could exist in the RESPONSE or COVARIANCE
relations, or exactly what the characteristics of these arguments are.
Kintsch and van Dijk attempt to set out much more well defined structures, but
even they have little to say about the set of structures that must exist, what
information they must contain and how the comprehension algorithms use the
text and the structures to build higher-level structures. The section on
computational models will consider algorithmic attempts at text understanding,
and should clearly indicate the complexity of these issues.
</bodyText>
<note confidence="0.753949">
Page 31
2.0 THE FORM OF CONNECTED DISCOURSE
The general model of text understanding suggested in the last section
</note>
<bodyText confidence="0.959910714285714">
describes the structured content of text representation. This section
contains work investigating a similar, yet distinct, type of structure - the
Abstract, underlying form of a text. (Not everyone would accept this
distinction, but it seems analogous to the distinction between the syntactic
structure of sentences and the semantic structure of their underlying
meaning.) Much of this work has been done by cultural anthxopologists Or by
those interested in literary analysis. Little of the traditional work has
been done with cognitive or computational models in mind, and hence tends to
rely on intuitive understanding of the terms. This less computational work
will be presented quite briefly, since the presentation is intended to suggest
the kinds of results that have been obtained, rather than the details of these
conclusions. It is necessary to define these ideas in a computational way
that can be integrated into the models of text understanding, and some recent
work has begun this task.
</bodyText>
<subsectionHeader confidence="0.996367">
2.1 Structural Analysis Of Text
</subsectionHeader>
<bodyText confidence="0.99846296875">
Most modern work in the structural analysis of texts has roots in the
work of the Russian structuralist, Propp [68]. Propp was concerned with the
form of Russian folktales. and developed a method for describing the
similarities he found in a corpus of 100 folktales. The major structural unit
that he developed , he designated a function. These functions act like
meta-actions in that they describe major events or event complexes that were
Page 32
repeatedly found in the tales. For example, Absentation is the function that
describes the situation in which one of the members of the family absents
himself from home, and Trickery is the function which describes a villain&apos;s
attempt to deceive his victim in order to take possession of him or his
belongings. Propp found thirty-one such functions to be adequate to describe
the events in the tales that he studied. Importantly, the ordering of the
functions was found to be fixed. Some functions are optional, but if they are
present their position is fixed with respect to the other functions. All of
the functions are defined in terms of actors that participate in the
situations they describe. Propp did some analysis of the restrictions on the
assignment of various characters to these functional roles. He notes that the
same character is likely to play a fixed set of roles, which he designates a
sphere of action. These spheres of action include such familiar story roles
as hero, villain and false hero. Finally, Propp notes that a single folktale
may be composed of a sequence of basic tales. He designates the basic tale a
&amp;quot;move&amp;quot;. Thus, a folktale.may be a one-move or a multi-move tale, with each
move conforming to the definition of a tale. These rules capture the
similarity of the folktales which could differ widely in the details of
characters, setting, specific actions, etc. It is clear that Propp&apos;s rules
could be expressed formally, and that is what Klein et al (74] did by writing
a computer program to generate the function sequences of a number of
folktales, using Propp&apos;s definitions.
The ideas of Propp have been refined and generalized by Barthes, Bremond,
Greimas and Todorov (their work is not generally available in English but is
reviewed in van Dijk (72] and Weinold (721). Their work has been directed
</bodyText>
<subsectionHeader confidence="0.485233">
Page 33
</subsectionHeader>
<bodyText confidence="0.978792">
toward the redefinition of Propp&apos;s functions as propositions, and of actors as
case relations of these propositions. They have also attempted to generalize
the functions by making them less specific, and to apply them to other forms
df texts. However, Hendricks [72] demonstrates the flexibility of Propp&apos;s
original functions by using them to analyze part of the Bradbury novel
</bodyText>
<subsectionHeader confidence="0.656089">
Something Wicked This Way Comes.
</subsectionHeader>
<bodyText confidence="0.999797833333333">
Chafe [72, 75] discusses the process of &amp;quot;verbalization&amp;quot;, by which he
means the translation of non-verbal knowledge into verbal output. One of the
proposed component processes of verbalization is breaking the knowledge into
smaller chunks according to patterns, which are called &amp;quot;schemata&amp;quot;. These
schemata are grammar like descriptions of possible verbal sequences. Thus, he
notes that a certain class of stories will always be of the form:
</bodyText>
<sectionHeader confidence="0.644158" genericHeader="method">
PLOT + MORAL
</sectionHeader>
<bodyText confidence="0.993023272727273">
Chafe also mentions such schemata as TRICK and VISIT as occurring in the
stories he has analyzed. He explicitly states that, at this time, schematic
analysis of a story is done by &amp;quot;imagination aid intuition&amp;quot;. He discusses
aspects of the schematic analysis of several simple tales, but these are
mostly illustrative rather than complete, in any sense.
Colby [73] analyzes Eskimo folktales, identifying &amp;quot;eidons&amp;quot;, which are
similar to Propp&apos;s functions, and producing a grammar capable of generating
some of these tales. Colby observes that most native speakers are probably
not very familiar with story grammars of this type (or the knowledge they
represent), since only a few individuals are able to generate such tales
Nonetheless, it seems reasonable to assume that the same type of structure can
</bodyText>
<subsectionHeader confidence="0.468223">
Page 34
</subsectionHeader>
<bodyText confidence="0.9957872">
be found in more conventional stories
Although most work in this area has involved analysis of some form of
traditional narrative, Labov and Waletzky [67] present analyses of oral
versions of personal experiences. Even in this informal type of narrative,
they find five regular components: an orientation, a complication, an
evaluation, the resolution and a coda or moral. The last two components are
optional. A totally different type of material is examined by Becker [65] who
discusses patterns in expository paragraphs.
All of these analyses rely on the intuitive understanding of the analyzer
to grasp the meaning of the structures from informal descriptions and to find
these structures in the text being analyzed. For this reason, the particular
structures that have been suggested are of less interest than is the general
result that quite regular high level patterns are found in texts of many
types, which may be characterized independently of the specific textual
content.
</bodyText>
<subsectionHeader confidence="0.99944">
2.2 Kintsch And Van Dijk
</subsectionHeader>
<bodyText confidence="0.996932">
In addition to the content macro-structures (discussed in section 1.2.4)
Kintsch and van Dijk (75) and van Dijk [75a, 76] discuss even higher level
ff super-structures&amp;quot;, used to organize the content of a text according to the
type of the text, which are derived from the work in structural analysis of
texts. They limit their work to narratives, which they define as a specific
type of action discourse. Narrative categories such as Episode Setting,
</bodyText>
<subsectionHeader confidence="0.639711">
Page 35
</subsectionHeader>
<bodyText confidence="0.953679428571429">
Complication, etc. are super-structures under which are organized either more
narrative categories or the content macro-structures of the text. Van Dijk
[75a] presents a fairly complete example. It includes a 160D word text from
The Decameron, a propositional analysis of the story, the content
macro-structures of the story and the narrative categories under which the
macro-structures are organized. The following abbreviated fragment should
give an indication of the kind of analysis being proposed.
</bodyText>
<figure confidence="0.717833666666667">
NARRATIVE
1
1 1
STORY MORAL
1
1 1
EPISODE1
1
111.1.■■■■■■•■ ......... M.4110
1 1
SETTING HAPPENING
1 1
1 1
COMPLICATION RESOLUTION
1 1 1
Landoll() loses his fortune
1
(detail propositions about this loss)
</figure>
<subsectionHeader confidence="0.831861">
Some experiments were done to test the role of the understander&apos;s notion
</subsectionHeader>
<bodyText confidence="0.94479025">
of narrative structure. An Apache myth and three Decameron stories, which
were of comparable difficulty at the sentence level, we,re presented. They
differed in that the Apache myth had an organization not familiar to the
subjects. There was much greater variety in the propositions different people
</bodyText>
<subsectionHeader confidence="0.479653">
Page 36
</subsectionHeader>
<bodyText confidence="0.998902714285714">
used in the recall of the myth than in the other three stories. Another
experiment compared recalls of subjects who had read a normal story to those
of subjects who had read scrambled versions of the same story. The recalls
were indistinguishable by judges. Both of these groups of experiments
indicate the active role of one&apos;s expectations about the form of a discourse
in organizing the representation of that discourse. When this is impossible,
as in the Apache myth, recall is less organized and more random.
</bodyText>
<subsectionHeader confidence="0.989435">
2.3 Rumelhart
</subsectionHeader>
<bodyText confidence="0.999881">
Rumelhart (74, 751 proposes a story grammar that is capable of producing
structures similar to those described by Kintsch and van Dijk (section 2.2)
His grammar contains rules like the following:
</bodyText>
<listItem confidence="0.947377333333333">
1. STORY -&gt; SETTING + EPISODE
2. EPISODE -&gt; EVENT + REACTION
3. REACTION -&gt; INTERNAL-RESPONSE + OVERT-RESPONSE
</listItem>
<bodyText confidence="0.998525333333333">
Using these rules, he describes the syntactic structure of simple stories.
The following fragment illustrates the types of structures derived (ignoring
the parenthesized predicates for now):
</bodyText>
<figure confidence="0.951704769230769">
Page 37
STORY
SETTING (AND) EPISODE (INITIATE)
1
1
EVENT (CAUSE) REACTION (MOTIVATE)
1
(propositions describing Margie&apos;s 1
balloon being popped) 1
1
1 1
INTERNAL-RESPONSE OVERT-RESPONSE
1 1
</figure>
<subsectionHeader confidence="0.34891">
Margie is sad Margie cries
</subsectionHeader>
<bodyText confidence="0.815833333333333">
Associated with most syntactic story rules are semantic rules which are used
to generate a corresponding semantic structure for the story. The semantic
rules for the syntactic rules given above are:
</bodyText>
<sectionHeader confidence="0.949702333333333" genericHeader="method">
I. ALLOW (SETTING, EPISODE)
2. INITIATE (EVENT, REACTION)
3. MOTIVATE (INTERNAL-RESPONSE, OVERT-RESPONSE)
</sectionHeader>
<bodyText confidence="0.915745875">
where the semantic predicates are intended to mean what is suggested by their
names (e.g. the SETTING ALLOWs the EPISODE to occur). The figure given above
contains the appropriate semantic predicate, in parentheses, at each node in
the syntactic structure. (Rumelhart uses a completely separate semantic
structure.)
Page 38
Rumelhart discusses some elementary summarization rules that operate on
the semantic structure of a story. Some illustrative rules are:
</bodyText>
<listItem confidence="0.824788333333333">
1. MOTIVATE (thought, response) =&gt; response
2. INITIATE (X, Y) =&gt; Y
3. INITIATE (X, Y) =&gt; Y (because 1 when 1 after) X
</listItem>
<bodyText confidence="0.908446">
These rules could produce the either of the following summaries (for the
EPISODE in the story fragment given above):
</bodyText>
<listItem confidence="0.9785525">
1. Margie cried.
2. Margie cried because her balloon had popped.
</listItem>
<bodyText confidence="0.99932">
Rumelhart&apos;s ideas are intended to be primarily illustrative (&amp;quot;a tentative
beginning of a theory&amp;quot;), and deal with very simplified stories. They do argue
clearly for the notion of both a syntactic and a semantic structure for the
representation of a story&apos;s meaning. The syntactic structure allows
production of the semantic st-ucture, which is justified by its usefulness in
producing summaries.
</bodyText>
<subsectionHeader confidence="0.620892">
2.4 Mandler And Johnson
</subsectionHeader>
<bodyText confidence="0.937882933333334">
Mandler and Johnson [77] discuss an extended form of Rumelhart&apos;s story
grammar, which they propose as a basis for text recall studies. The extended
Page 39
grammar allows multiple episodes and does not utilize the additional structure
containing the semantic interpretation which Rumelhart suggests. Mandler and
Johnson feel that this second structure is unwieldy and frequently redundant.
Conjunction, time-ordering and causality are included as categories in the
grammar. They observe that restrictions imposed on a story by this type of
grammar include allowing only a single protagonist per episode, and
prohibiting the realization of higher level nodes in the actual text. They
demonstrate the utility of their grammar on several stories, including &amp;quot;The
War of the Ghosts&amp;quot;. They also note that a transformational component remains
to be developed which would provide for deletions and reorderings of the ideal
story structure. They discuss a set of predictions for recall studies, which
are suggested by this definition of story. structure. These include:
</bodyText>
<listItem confidence="0.919576777777778">
1. Accuracy will be better as the story is complete and ordered as
defined by the ideal structure.
2. Elaborations will be poorly recalled.
3. Optional nodes&apos; realizations will be less well recalled.
4. Causality will be better recalled than simple time-ordering.
5. Inversions should be fewer as the story is closer to the ideal
St ructure.
6. Omissions and violations of the ideal structure will be reflected by
additions and distortions.
</listItem>
<bodyText confidence="0.972598769230769">
Page 40
Unfortunately, the only experimental work reported is a comparison of recalls
of students from first grade, fourth grade and university levels, on a set of
stories which are very near the ideal structure. Hopefully, this is only the
beginning stage of validation of the proposed model. An interesting result
from this experiment is the probability of recall of a proposition as a
function of its role For university students, Settings (introduction of
characters) and Beginnings (initiation of event sequences) were best
remembered. Attempts and Outcomes (which together formed Goal Paths) were
next best recalled. Reactions (mental events) and Endings (which were usually
either very predictable or omitted in the stories used) were least well
recalled. These results are in harmony with the results reported by Kintsch
and van Dijk (which are discussed in Section 1.2.4).
</bodyText>
<subsectionHeader confidence="0.842624">
2.5 Thorndyke
</subsectionHeader>
<bodyText confidence="0.950112666666666">
Thorndyke [77] attempts to validate the basic notion of underlying text
form as a necessary part of a text understanding. He applies a story
structure grammar, which is nearly identical to that proposed by Rumelhart, to
two stories, &amp;quot;Circle Island&amp;quot; (analyzed by Frederiksen [75b]) and &amp;quot;The Old
Farmer&amp;quot; (given by Rumelhart [74J), each of which results in a straightforward
hierarchical structure. The initial rule of the grammar is
STORY —&gt; SETTING + THEME 1- PLOT + RESOLUTION
Thorndyke wishes to test the effects of violating this rule. He does so by
performing recall, summary and recognition experiments on four variations of
Page 41
the stories. These are a normal form of the story, a story with the Theme
moved to the end, a story with the Theme omitted and a descriptive version
which omits causal and temporal continuity, using only stative or single
action sentences. In comprehensibility judgements and recall tests, the
normal form story was best, the Theme-after form next, with the last two cases
more dependent on the particular story. Recalls of the Theme-after passages
also showed a strong tendency to relocate the Theme to its normal position,
near the beginning of the story. There was also a tendency in the more
structured passages for higher-level propositions to have a higher probability
of recall. Summarizations showed that, of the recalled propositions, the
higher-level ones were much more likely to be included as part of the summary.
Summaries of the descriptive presentations yielded a wider selection of
propositions. In recognition tests, the more structured passages produced
more recognition errors when the test proposition was consistent with the
story, while the less structured passages produced more accurate recognition.
In attempts to separate the effects of content and structure, Thorndyke
tested the four stories obtained by using each of the original plots with two
character / object sets. He found that the Farmer plot was always more
comprehensible. He also found that presentation of a second story using the
same plot structure improved later recall of the first story.
Thorndyke concludes that text structures are basic to comprehension,
although some are inherently more complex than others. The distinction
between structure and content is supported by the positive effect of repeated
structure prior to recall. And finally, the structural position of a
Page 42
proposition has significant influence on both recall and summarization.
</bodyText>
<subsectionHeader confidence="0.992265">
2.6 Text Grammar
</subsectionHeader>
<bodyText confidence="0.989817888888889">
&amp;quot;Text grammar&amp;quot; is the designation used for another currently active line
of investigation into the structure of text. The fundamental ideas of text
grammar are discussed by van Dijk [72], Ihwe (72), Kummer (72), Petofi (72]
and Petofi and Rieser [73]. (Unfortunately, a great portion of the work is
not available in English.) The principle concern is the formulation of
generative descriptions of texts, rather than individual sentences, and is
usually approached using a model similar to that of the generative semantics
school of linguistics. Van Dijk suggests the following five components of a
text grammar:
</bodyText>
<listItem confidence="0.949939">
1. Semantic formation rules for the meanings of texts, as a whole.
2. Transformations which operate on this text meaning.
3. Transformations which produce a sequence of sentential semantic
representations from the text meaning.
4. Transformations which produce a sequence of sentential syntactic
representations (including lexical items) from the, sequence of
sentential semantic representations.
</listItem>
<sectionHeader confidence="0.468279" genericHeader="method">
5. Rules pairing syntactic representations with morphonological
representations.
</sectionHeader>
<subsectionHeader confidence="0.488886">
Page 43
</subsectionHeader>
<bodyText confidence="0.992415361111111">
These components would operate in the order given to generate a text. He
emphasizes this is only the outline of a theory, and that most of the hard
details remain to be specified. A significant amount of work has been done on
components 1 and 2, formally defining representations of text. This has
included numerous examinations of the use of some extended predicate calculus
as a basic representation (primarily addressing the meaning of individual
sentences and objects) but has also led to psychologically motivated
investigations (as discussed in Section 1.2.4) and to studies in the general
structure of textual types (as discussed in Section 2.2). Discussions of
components 3 and 4 have been mostly descriptive, indicating phenomena that
must be accounted for without actually defining them. Many of these phenomena
seen best Characterized as operations operating on two or more underlying
propositions. These phenomena include anaphora (including pronominalization
and article selection), sentence stress, contrast, use of clausal
conjunctions, and verb tense determination. Of course, certain literary
styles may alter the &amp;quot;normal&amp;quot; rules, choosing repetition over
pronominalization omission of causal connection, repetition of certain
sentence forms, etc. Operations which occur on a single proposition include:
semantic transformations, such as personification and the use of metaphor;
syntactic transformations, such as inversions and other stylistic operations;
and phonological transformations, such as those producing rhyme, alliteration
and meter. The set of realization rules used to produce a particular text
from its generated underlying structure is assumed to be limited by the type
of text that is being generated (e.g. mystery, narrative, etc.), which is
Indicated by some underlying abstract type marker. The selected rules will
Page 44
also determine the textual characteristics usually referred to as style or
literary merit.
It seems that any complete text understanding model must have a set of
rules relating the underlying structure of the text - individual and groups of
propositions together with global aspects of the text - to its surface
realization. Although using a generative model, text grammarians are
concerned with identifying and characterizing these relationships, and the
results of their investigations should be of definite value in describing text
understanding, once their research has reached the point of clearly defining
the nature of these surface phenomena in terms of the meaning of text.
</bodyText>
<subsectionHeader confidence="0.548419">
2.7 Discussion And Conclusions
</subsectionHeader>
<bodyText confidence="0.952195277108434">
The principal hypotheses of these investigators is that there is are very
high level structures which organize content structures in the representation
of a text. This section was begun with the warning that the distinction
between these two different types of structures might be difficult to define.
It seems clear that although each proposal that has been considered claims to
be concerned with this high level structure, some confusion exists. The
interactions between the abstract structures and the content structures are
not characterized at all. Thus, Kintsch and van Dijk do not describe the
restrictions on what type of events may realize a COMPLICATION category.
Similarly, Rumelhart does not explain how the correct semantic rule would be
selected when a choice is possible (e.g. Two sequential EVENTs may be related
by either CAUSE or ALLOW). Mandler and Johnson, and to some extent Thorndyke,
Page 45
create additional confusion by mixing syntactic categories with categories
that would usually be considered semantic. Thus, conjunction time ordering
and causality may appear in the &amp;quot;syntactic&amp;quot; structure of a story. Although
this difficulty in distinguishing between the two types of structures may
suggest that there is no distinction, the evidence provided by the existence
of describable classes of texts seems to indioate that some type of high level
structures do exist. It remains to clearly define the nature of these
structures, and to explain their relationship with content structures, without
repeating the fallacy of creating a multitude of subcategories (e.g. many
different EVENT subtypes) which are alleged to be purely syntactic categories.
These structures fit neatly into the model discussed in the conclusion of
the content section (section 1.4). They are the highest level of structure,
under which content structures are organized. This is consistent with the
hypothesis of Kintsch and van Dijk (discussed in section 1.2.4) that the
structural description of a text is one of the important aspects of its
representation. They specifically suggest that these structures organize
macro-structures, which provide the content organization of the text. This is
quite consistent with the results of structural analysis which, as Hendricks
[73] points out, ordinarily uses a summary or synopsis, not the actual text.
as a basis for analysis. (Recall that macro-structures are proposed as the
basis for summary generation). Of course very simple or very novel texts
might not have any structure of this type, since no appropriate structure
would be pre-existent. Of course, the problem of learning these structure is
as difficult to explain (if not more difficult) as the learning of content
structures. Such acquisition is simply not well understood. The work of the
Page 46
text grammarians suggests the complexity and eiversity of linguistic phenomena
that may be related to underlying textual representation. This work also
suggests that many aspects of a text, other than its literal meaning and
general type, may require explicit representation. Although a sound
computational representation of stylistic aspects of texts may seem a distant
goal, it is still important to retain it as part of the goal of understanding
text, and to realize that the richness of human use of language will be only
partially accounted for without this component.
Page 47
3.0 COMPUTATIONAL MODELS OF TEXT UNDERSTANDING
This section will survey computational work on the process of text
understanding. Computational models will be seen to be of value in at least
two ways. First, many of the features postulated in other models will be
found in these computational models, frequently motivated primarily by
computational concerns. This tends to support these hypotheses. Secondly,
many points passed over very quickly by other workers are seen to offer
formidable problems when one attempts to set out a full computational
description. The discovery of inadequate description is essential in
developing sound models. &amp;quot;Computational&amp;quot; will be taken to mean any model that
is actually programmable or that is formally defined. The work selected for
discussion in this section is generally treated in more detail than that in
previous sections. The reason for this is that if the complexity of
&apos;computationally specifying certain representations and processes is to be made
clear, it is impossible to treat these matters cursorily. This, in turn, has
necessitated greater selectivity on the part of the author in choosing work
that seems to best convey certain types of problems.
Bellert [70] attempts to define the notion of the coherence of a text,
and in doing so suggests some of the same conclusions reached by computational
linguists in their text understanding work. Coherence refers to the property
of a set of utterances which make it a connected discourse rather than a
random collection of utterances. Referential identity has often been
suggested as an indication of coherence, but it is clearly insufficient. For
example:
Page 48
John drinks a lot of coffee. John married a blonde.
Both sentences refer to John, but do not form a coherent discourse.
Furthermore, referential identity is unnecessary. Consider the two sentences:
There has been a drought. People are starving.
These are coherent without any explicit referential identity. Bellert defines
a coherent text as one in which the semantic interpretation of each sentence
is dependent on the semantic interpretation of the preceding sentences. The
semantic interpretation of a sentence is defined as the set of conclusions
that can be inferred from that sentence. She suggests that there are two
types of conclusions that may be drawn:
</bodyText>
<listItem confidence="0.856685">
1. those drawn only from knowledge of the language
2. those drawn from knowledge of the world
</listItem>
<bodyText confidence="0.958728833333333">
Both types of conclusions are absolutely necessary in understanding text and
may be appropriately drawn when the coherence of the text requires. She
concludes that &amp;quot;an utterance has meaning only in the entire context and
through our knowledge of the world&amp;quot;. The rest of the work discussed in this
section will strongly reinforce these conclusions.
The discussion is divided into two sections. The first contains earlier
work that supports the claim that world knowledge is essential to the
understanding of text. The closely related problem of making implicitly
conveyed information explicit is also a principle concern. The second section
Page 49
describes later work in which the orAanization of world knowledge is
recognized as a critical question for text understanding.
</bodyText>
<subsectionHeader confidence="0.9560155">
3.1 The Necessity Of World Knowledge
3.1.1 Charniak
</subsectionHeader>
<bodyText confidence="0.995306555555555">
Charniak&apos;s work [72, 74, 76] is probably the first attempt to set out in
a well defined fashion the dimension of information processing that must be
carried on in the understanding of a story. The tetm &amp;quot;understanding&amp;quot; is
necessarily vague, but Charniak suggests an intuitive definition. Consider
the following story fragment:
Fred was goipg to the store. Today was Jack&apos;s birthday and Fred was going
to get a present.
It should be clear that if a human had read and understood this fragment that
he would be able to answer such questions as
</bodyText>
<reference confidence="0.868755428571429">
1. Why is Fred going to the store?
2. Who is Fred buying the present for?
3. Why is Fred buying a present?
Charniak claims that a semantic representation of this fragment (i.e. an
understanding of it) should explicitly contain the answers to ordinary
questions such as these. Note the important point that this type of
Page 50
</reference>
<bodyText confidence="0.967069666666667">
Understanding could be attained only through the use of general &apos;knowledge of
the world, along with the explicit statements of the text. Knowledge required
to answer the above questions would include such facts as:
</bodyText>
<listItem confidence="0.666812">
1. A person having a birthday is likely to receive presents.
2. Presents are often bought at stores.
</listItem>
<bodyText confidence="0.9836481875">
So Charniak&apos;s goal becomes outlihing an answer to the question of how common
sense knowledge may be incorporated into the process of understanding natural
language. A closely related goal is the determination of how much knowledge
of this type is required by the basic problems of natural language, such as
the resolution of pronominal reference.
Charniak breaks the problem of processing natural language into two
parts. The first part is the translation of natural language into a form that
is convenient for use in making deductions. This internal representation is
like the understanding that a person would be capable of obtaining without
context. The internal representation is a canonical propositional form.
Thus, either of the sentences
Jack caught a cold.
Jack came down with a cold.
might be represented by the proposition
(BECOME-SICK-WITH JACK COLD)
which represents the explicit meaning of either of the sentences. The second
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.425134">
<note confidence="0.847021">Journal of Computational Linguistics 70</note>
<title confidence="0.9264235">TEXT UNDERSTANDING: A SURVEY</title>
<author confidence="0.996942">ROBERT YOUNG</author>
<affiliation confidence="0.9996935">Department of Computer University of</affiliation>
<address confidence="0.993219">Austin, Texas 78712</address>
<note confidence="0.832412">Copyright J978 Association for Computational Linguistics TABLE OF CONTENTS</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Why is Fred going to the store?</title>
<marker>1.</marker>
<rawString>Why is Fred going to the store?</rawString>
</citation>
<citation valid="false">
<title>Who is Fred buying the present for?</title>
<marker>2.</marker>
<rawString>Who is Fred buying the present for?</rawString>
</citation>
<citation valid="false">
<title>Why is Fred buying a present? Charniak claims that a semantic representation of this fragment (i.e. an understanding of it) should explicitly contain the answers to ordinary questions such as these. Note the important point that this type of</title>
<journal>Page</journal>
<volume>50</volume>
<marker>3.</marker>
<rawString>Why is Fred buying a present? Charniak claims that a semantic representation of this fragment (i.e. an understanding of it) should explicitly contain the answers to ordinary questions such as these. Note the important point that this type of Page 50</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>