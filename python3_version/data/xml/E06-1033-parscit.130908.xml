<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000068">
<title confidence="0.9994375">
Adaptive Transformation-based Learning for
Improving Dictionary Tagging
</title>
<author confidence="0.989768">
Burcu Karagol-Ayan, David Doermann, and Amy Weinberg
</author>
<affiliation confidence="0.9914085">
Institute for Advanced Computer Studies (UMIACS)
University of Maryland
</affiliation>
<address confidence="0.960849">
College Park, MD 20742
</address>
<email confidence="0.999798">
{burcu,doermann,weinberg}@umiacs.umd.edu
</email>
<sectionHeader confidence="0.995657" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998218125">
We present an adaptive technique that en-
ables users to produce a high quality dic-
tionary parsed into its lexicographic com-
ponents (headwords, pronunciations, parts
of speech, translations, etc.) using an
extremely small amount of user provided
training data. We use transformation-
based learning (TBL) as a postprocessor at
two points in our system to improve per-
formance. The results using two dictio-
naries show that the tagging accuracy in-
creases from 83% and 91% to 93% and
94% for individual words or “tokens”, and
from 64% and 83% to 90% and 93% for
contiguous “phrases” such as definitions
or examples of usage.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999698666666667">
The availability and use of electronic resources
such as electronic dictionaries has increased tre-
mendously in recent years and their use in
Natural Language Processing (NLP) systems is
widespread. For languages with limited electronic
resources, i.e. low-density languages, however,
we cannot use automated techniques based on par-
allel corpora (Gale and Church, 1991; Melamed,
2000; Resnik, 1999; Utsuro et al., 2002), compa-
rable corpora (Fung and Yee, 1998), or multilin-
gual thesauri (Vossen, 1998). Yet for these low-
density languages, printed bilingual dictionaries
often offer effective mapping from the low-density
language to a high-density language, such as En-
glish.
Dictionaries can have different formats and can
provide a variety of information. However, they
typically have a consistent layout of entries and a
</bodyText>
<figure confidence="0.970291">
1 Headword 5 Translation
2 POS 6 Example of usage
3 Sense number 7 Example of usage translation
4 Synonym 8 Subcategorization
</figure>
<figureCaption confidence="0.992255">
Figure 1: Sample tagged dictionary entries. Eight
tags are identified and tagged in the given entries.
</figureCaption>
<bodyText confidence="0.999829571428571">
consistent structure within entries. Publishers of
dictionaries often use a combination of features to
impose this structure including (1) changes in font
style, font-size, etc. that make implicit the lexico-
graphic information1, such as headwords, pronun-
ciations, parts of speech (POS), and translations,
(2) keywords that provide an explicit interpreta-
tion of the lexicographic information, and (3) var-
ious separators that impose an overall structure on
the entry. For example, a boldface font may in-
dicate a headword, italics may indicate an exam-
ple of usage, keywords may designate the POS,
commas may separate different translations, and a
numbering system may identify different senses of
a word.
We developed an entry tagging system that rec-
ognizes, parses, and tags the entries of a printed
dictionary to reproduce the representation elec-
tronically (Karagol-Ayan et al., 2003). The sys-
tem aims to use features as described above and
the consistent layout and structure of the dictio-
</bodyText>
<footnote confidence="0.931398">
1For the purposes of this paper, we will refer to the lexi-
cographic information as tag when necessary.
</footnote>
<page confidence="0.993947">
257
</page>
<bodyText confidence="0.999668673913044">
naries to capture and recover the lexicographic in-
formation in the entries. Each token2 or group of
tokens (phrase)3 in an entry associates with a tag
indicating its lexicographic information in the en-
try. Figure 1 shows sample tagged entries in which
eight different types of lexicographic information
are identified and marked. The system gets for-
mat and style information from a document image
analyzer module (Ma and Doermann, 2003) and
is retargeted at many levels with minimal human
assistance.
A major requirement for a human aided dic-
tionary tagging application is the need to mini-
mize human generated training data.4 This re-
quirement limits the effectiveness of data driven
methods for initial training. We chose rule-based
tagging that uses the structure to analyze and tag
tokens as our baseline, because it outperformed
the baseline results of an HMM tagger. The ap-
proach has demonstrated promising results, but we
will show its shortcomings can be improved by ap-
plying a transformation-based learning (TBL) post
processing technique.
TBL (Brill, 1995) is a rule-based machine learn-
ing method with some attractive qualities that
make it suitable for language related tasks. First,
the resulting rules are easily reviewed and under-
stood. Second, it is error-driven, thus directly min-
imizes the error rate (Florian and Ngai, 2001).
Furthermore, TBL can be applied to other annota-
tion systems’ output to improve performance. Fi-
nally, it makes use of the features of the token and
those in the neighborhood surrounding it.
In this paper, we describe an adaptive TBL
based technique to improve the performance of the
rule-based entry tagger, especially targeting cer-
tain shortcomings. We first investigate how using
TBL to improve the accurate rendering of tokens’
font style affects the rule-based tagging accuracy.
We then apply TBL on tags of the tokens. In our
experiments with two dictionaries, the range of
font style accuracies is increased from 84%-94%
to 97%-98%, and the range of tagging accuracies
is increased from 83%-90% to 93%-94% for to-
kens, and from 64%-83% to 90%-93% for phrases.
Section 2 discusses the rule-based entry tagging
</bodyText>
<footnote confidence="0.962801">
2Token is a set of glyphs (i.e., a visual representation of a
set of characters) in the OCRed output. Each punctuation is
counted as a token as well.
3In Figure 1, not on time is a phrase consisting of 3 tokens.
4For our experiments we required hand tagging of no
more than eight pages that took around three hours of human
effort.
</footnote>
<bodyText confidence="0.997728">
method. In Section 3, we briefly describe TBL,
and Section 4 recounts how we apply TBL to im-
prove the performance of the rule-based method.
Section 5 explains the experiments and results, and
we conclude with future work.
</bodyText>
<sectionHeader confidence="0.955492" genericHeader="method">
2 A Rule-based Dictionary Entry Tagger
</sectionHeader>
<bodyText confidence="0.999808975609756">
The rule-based entry tagger (Karagol-Ayan et al.,
2003) utilizes the repeating structure of the dic-
tionaries to identify and tag the linguistic role
of tokens or sets of tokens. Rule-based tagging
uses three different types of clues—font style, key-
words and separators—to tag the entries in a sys-
tematic way. The method accommodates noise in-
troduced by the document analyzer by allowing
for a relaxed matching of OCRed output to tags.
For each dictionary, a human operator must spec-
ify the lexicographic information used in that par-
ticular dictionary, along with the clues for each
tag. This process can be performed in a few hours.
The rule-based method alone achieved token accu-
racy between 73%-87% and phrase accuracy be-
tween 75%-89% in experiments conducted using
three different dictionaries5.
The rule-based method has demonstrated prom-
ising results, but has two shortcomings. First, the
method does not consider the relations between
different tags in the entries. While not a prob-
lem for some dictionaries, for others ordering the
relations between tags may be the only informa-
tion that will tag a token correctly. Consider the
dictionary entries in Figure 1. In this dictionary,
the word “a” represents POS when in italic font,
and part of a translation if in normal font. How-
ever if the font is incorrect (font errors are more
likely to happen with short tokens), the only way
to mark correctly the tag involves checking the
neighboring tokens and tags to determine its rel-
ative position within the entry. When the token
has an incorrect font or OCR errors exist, and
the other clues are ambiguous or inconclusive, the
rule-based method may yield incorrect results.
Second, the rule-based method can produce in-
correct splitting and/or merging of phrases. An er-
roneous merge of two tokens as a phrase may take
place either because of a font error in one of the
tokens or the lack of a separator, such as a punctu-
ation mark. A phrase may split erroneously either
</bodyText>
<footnote confidence="0.66939625">
5Using HMMs for entry tagging on the same set of dic-
tionaries produced slightly lower performance, resulting in
token accuracy between 73%-88% and phrase accuracy be-
tween 57%-85%.
</footnote>
<page confidence="0.990453">
258
</page>
<bodyText confidence="0.99996175">
as a result of a font error or an ambiguous separa-
tor. For instance, a comma may be used after an
example of usage to separate it from its translation
or within it as a normal punctuation mark.
</bodyText>
<sectionHeader confidence="0.996837" genericHeader="method">
3 TBL
</sectionHeader>
<bodyText confidence="0.999988628571429">
TBL (Brill, 1995), a rule-based machine learning
algorithm, has been applied to various NLP tasks.
TBL starts with an initial state, and it requires a
correctly annotated training corpus, or truth, for
the learning (or training) process. The iterative
learning process acquires an ordered list of rules
or transformations that correct the errors in this
initial state. At each iteration, the transformation
which achieved the largest benefit during appli-
cation is selected. During the learning process,
the templates of allowable transformations limit
the search space for possible transformation rules.
The proposed transformations are formed by in-
stantiation of the transformation templates in the
context of erroneous tags. The learning algorithm
stops when no improvement can be made to the
current state of the training data or when a pre-
specified threshold is reached.
A transformation modifies a tag when its con-
text (such as neighboring tags or tokens) matches
the context described by the transformation. Two
parts comprise a transformation: a rewrite rule—
what to replace— and a triggering environment—
when to replace. A typical rewrite rule is: Change
the annotation from aa to ab, and a typical trig-
gering environment is: The preceding word is wa.
The system’s output is the final state of this data
after applying all transformations in the order they
are produced.
To overcome the lengthy training time associ-
ated with this approach, we used fnTBL, a fast ver-
sion of TBL that preserves the performance of the
algorithm (Ngai and Florian, 2001). Our research
contribution shows this method is effective when
applied to a miniscule set of training data.
</bodyText>
<sectionHeader confidence="0.76448" genericHeader="method">
4 Application of TBL to Entry Tagging
</sectionHeader>
<bodyText confidence="0.87731775">
In this section, we describe how we used TBL in
the context of tagging dictionary entries.
We apply TBL at two points: to render correctly
the font style of the tokens and to label correctly
the tags of the tokens6. Although our ultimate goal
6In reality, TBL improves the accuracy of tags and phrase
boundary flags. In this paper, whenever we say “application
of TBL to tagging”, we mean tags and phrase boundary flags
</bodyText>
<figureCaption confidence="0.996534">
Figure 2: Phases of TBL application
</figureCaption>
<bodyText confidence="0.98397141025641">
is improving tagging results, font style plays a cru-
cial role in identifying tags. The rule-based entry
tagger relies on font style, which can be also incor-
rect. Therefore we also investigate whether im-
proving font style accuracy will further improve
tagging results. We apply TBL in three configu-
rations: (1) to improve font style, (2) to improve
tagging and (3) to improve both, one after another.
Figure 2 shows the phases of TBL application.
First we have the rule-based entry tagging results
with the font style assigned by document image
analysis (Result1), then we apply TBL to tagging
using this result (Result2). We also apply TBL to
improve the font style accuracy, and we feed these
changed font styles to the rule-based method (Re-
sult3). We then apply TBL to tagging using this
result (Result4). Finally, in order to find the upper
bound when we use the manually corrected font
styles in the ground truth data, we feed correct font
styles to the rule-based method (Result5), and then
apply TBL to tagging using this result (Result6).
In the transformation templates, we use the to-
kens themselves as features, i.e. the items in the
triggering environment, because the token’s con-
tent is useful in indicating the role. For instance
a comma and a period may have different func-
tionalities when tagging the dictionary. However,
when transformations are allowed to make refer-
ence to tokens, i.e., when lexicalized transforma-
tions are allowed, some relevant information may
be lost because of sparsity. To overcome the data
sparseness problem, we also assign a type to each
token that classifies the token’s content. We use
eight types: punctuation, symbol, numeric, upper-
case, capitalized, lowercase, non-Latin, and other.
For TBL on font style, the transformation tem-
plates contain three features: the token, the token’s
type, and the token’s font. For TBL on tagging, we
together.
</bodyText>
<page confidence="0.992107">
259
</page>
<bodyText confidence="0.999458588235294">
use four features: the token, the token’s type, the
token’s font style, and the token’s tag.
The initial state annotations for font style are
assigned by document image analysis. The rule-
based entry tagging method assigns the initial state
of the tokens’ tags. The templates for font style ac-
curacy improvement consist of those from study-
ing the data and all templates using all features
within a window of five tokens (i.e., two preced-
ing tokens, the current token, and two following
tokens). For tagging accuracy improvement, we
prepared the transformation templates by studying
dictionaries and errors in the entry tagging results.
The objective function for evaluating transforma-
tions in both cases is the classification accuracy,
and the objective is to minimize the number of er-
rors.
</bodyText>
<sectionHeader confidence="0.999693" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999973322580645">
We performed our experiments on a Cebuano-
English dictionary (Wolff, 1972) consisting of
1163 pages, 4 font styles, and 18 tags, and on
an Iraqi Arabic-English dictionary (Woodhead and
Beene, 2003) consisting of 507 pages, 3 font
styles, and 26 tags. For our experiments, we used
a publicly available implementation of TBL’s fast
version, fnTBL7, described in Section 3.
We used eight randomly selected pages from the
dictionaries to train TBL, and six additional ran-
domly selected pages for testing. The font style
and tag of each token on these pages are manually
corrected from an initial run. Our goal is to mea-
sure the effect of TBL on font style and tagging
that have the same noisy input. For the Cebuano
dictionary, the training data contains 156 entries,
8370 tokens, and 6691 non-punctuation tokens,
and the test data contains 137 entries, 6251 tokens,
and 4940 non-punctuation tokens. For the Iraqi
Arabic dictionary, the training data contains 232
entries, 6130 tokens, and 4621 non-punctuation
tokens, and the test data contains 175 entries, 4708
tokens, 3467 non-punctuation tokens.
For evaluation, we used the percentage of accu-
racy for non-punctuation tokens, i.e., the number
of correctly identified tags divided by total num-
ber of tokens/phrases. The learning phase of TBL
took less than one minute for each run, and ap-
plication of learned transformations to the whole
dictionary less than two minutes.
We report how TBL affects accuracy of tagging
</bodyText>
<subsectionHeader confidence="0.476583">
7http://nlp.cs.jhu.edu/rflorian/fntbl
</subsectionHeader>
<bodyText confidence="0.9996915">
when applied to font styles, tags, and font styles
and tags together. To find the upper bound tag-
ging results with correct font styles, we also ran
rule-based entry tagger using manually corrected
font styles, and applied TBL for tagging accuracy
improvement to these results. We should note that
feeding the correct font to the rule-based entry tag-
ger does not necessarily mean the data is totally
correct, it may still contain noise from document
image analysis or ambiguity in the entry.
We conducted three sets of experiments to ob-
serve the effects of TBL (Section 5.1), the effects
of different training data (Section 5.2), and the ef-
fects of training data size (Section 5.3).
</bodyText>
<subsectionHeader confidence="0.38838">
5.1 TBL on Font Styles and Tags
</subsectionHeader>
<table confidence="0.998267">
Cebuano Iraqi Arabic
Original 84.43 94.15
TBL(font) 97.07 98.13
</table>
<tableCaption confidence="0.961824">
Table 1: Font style accuracy results for non-
punctuation tokens
</tableCaption>
<bodyText confidence="0.998805857142857">
We report the accuracy of font styles on the test
data before and after applying TBL to the font
style of the non-punctuation tokens in Table 1. The
initial font style accuracy of Cebuano dictionary
was much less than the Iraqi Arabic dictionary, but
applying TBL resulted in similar font style accu-
racy for both dictionaries (97% and 98%).
</bodyText>
<table confidence="0.99949625">
Cebuano Iraqi Arabic
Token Phrase Token Phrase
RB 83.25 64.08 90.89 82.72
RB+TBL(tag) 91.44 87.37 94.05 92.33
TBL(font)+RB 87.99 72.44 91.46 83.48
TBL(font)+RB+TBL(tag) 93.06 90.19 94.30 92.58
GT(font)+RB 90.76 74.71 91.74 83.90
GT(font)+RB+TBL(tag) 95.74 92.29 94.54 93.11
</table>
<tableCaption confidence="0.8974335">
Table 2: Tagging accuracy results for non-punctu-
ation tokens and phrases for two dictionaries
</tableCaption>
<bodyText confidence="0.914739916666667">
The results of tagging accuracy experiments
are presented in Table 2. In the tables, RB is
rule-based method, TBL(tag) is the TBL run on
tags, TBL(font) is the TBL run on font style, and
GT(font) is the ground truth font style. In each
case, we begin with font style information pro-
vided by document image analysis. We tabulate
percentages of tagging accuracy of individual non-
punctuation tokens and phrases8. The results for
8In phrase accuracy, if a group of consequent tokens is
assigned one tag as a phrase in the ground truth, the tagging
of the phrase is considered correct only if the same group of
</bodyText>
<page confidence="0.988879">
260
</page>
<bodyText confidence="0.999584244897959">
token and phrase accuracy are presented for three
different sets: The entry tagger using the font
style (1) provided by document image analysis,
(2) after TBL is applied to font style, and (3) cor-
rected manually, i.e. the ground truth. All re-
sults reported, except the token accuracies for two
cases for the Iraqi Arabic dictionary, namely us-
ing TBL(font) vs. GT(font) and using TBL(font)
and TBL(tag) together vs. using GT(font) and
TBL(tag), are statistically significant within the
95% confidence interval with two-tailed paired t-
tests9.
Using TBL(font) instead of initial font styles
improved initial accuracy as much as 4.74% for
tokens, and 8.36% for phrases in the Cebuano dic-
tionary which has a much lower initial font style
accuracy than the Iraqi Arabic dictionary. Using
the GT(font) further increased the tagging accu-
racy by 2.77% for tokens and 2.27% for phrases
for the Cebuano dictionary. As for the Iraqi Ara-
bic dictionary, using TBL(font) and GT(font) re-
sulted in an improvement of 0.57% and 0.85% for
tokens and 0.74% and 1.18% for phrases respec-
tively. The improvements in these two dictionar-
ies differ because the initial font style accuracy
for the Iraqi Arabic dictionary is very high while
for the Cebuano dictionary potentially very useful
font style information (namely, the font style for
POS tokens) is often incorrect in the initial run.
Using TBL(tag) alone improved rule-based
method results by 8.19% and 3.16% for tokens
and by 23.25% and 9.61% for phrases in Cebuano
and Iraqi Arabic dictionaries respectively. The last
two rows in Table 2 show the upper bound. For
the two dictionaries, our results using TBL(font)
and TBL(tag) together is 2.68% and 0.24% for
token accuracy and 2.10% and 0.53% for phrase
accuracy less than the upper bound of using the
GT(font) and TBL(tag) together.
Applying TBL to font styles resulted in a higher
accuracy than applying TBL to tagging. Since the
number of tag types (18 and 26) is much larger
than that of font style types (4 and 3), TBL appli-
cation on tags requires more training data than the
font style to perform as well as TBL application
on font style.
In summary, applying TBL using the same tem-
plates to two different dictionaries using very lim-
ited training data resulted in performance increase,
</bodyText>
<footnote confidence="0.520293">
tokens was assigned the same tag as a phrase in the result.
9We did the t-tests on the results of individual entries.
</footnote>
<bodyText confidence="0.999279">
and the greatest increases we observed are in
phrase accuracy. Applying TBL to font style first
increased the accuracy even further.
</bodyText>
<subsectionHeader confidence="0.998942">
5.2 Effect of Training Data
</subsectionHeader>
<bodyText confidence="0.9998115">
We conducted experiments to measure the robust-
ness of our method with different training data.
For this purpose, we trained TBL on eight pages
randomly selected from the 14 pages for which we
have ground truth, for each dictionary. We used
the remaining six pages for testing. We did this ten
times, and calculated the average accuracy and the
standard deviation. Table 3 presents the average
accuracy and standard deviation. The accuracy re-
sults are consistent with the results we presented
in Table 2, and the standard deviation is between
0.56-2.28. These results suggest that using differ-
ent training data does not affect the performance
dramatically.
</bodyText>
<subsectionHeader confidence="0.997775">
5.3 Effect of Training Data Size
</subsectionHeader>
<bodyText confidence="0.999960333333333">
The problem to which we apply TBL has one im-
portant challenge and differs from other tasks in
which TBL has been applied. Each dictionary has
a different structure and different noise patterns,
hence, TBL must be trained for each dictionary.
This requires preparing ground truth manually for
each dictionary before applying TBL. Moreover,
although each dictionary has hundreds of pages, it
is not feasible to use a significant portion of the
dictionary for training. Therefore the training data
should be small enough for someone to annotate
ground truth in a short amount of time. One of our
goals is to calculate the quantity of training data
necessary for a reasonable improvement in tagging
accuracy. For this purpose, we investigated the
effect of the training data size by increasing the
training data size for TBL one entry at a time. The
entries are added in the order of the number of er-
rors they contain, starting with the entry with max-
imum errors. We then tested the system trained
with these entries on two test pages10.
Figure 3 shows the number of font style and tag-
ging errors for non-punctuation tokens on two test
pages as a function of the number of entries in the
training data. The tagging results are presented
when using font style from document image anal-
ysis and font style after TBL. In these graphs, the
</bodyText>
<footnote confidence="0.92145475">
10We used two test data pages because if such a method
will determine the minimum training data required to obtain
a reasonable performance, the test data should be extremely
limited to reduce human provided data.
</footnote>
<page confidence="0.983433">
261
</page>
<table confidence="0.79911275">
Cebuano Iraqi Arabic
Token Phrase Token Phrase
RB 81.46±1.14 62.38±1.09 92.10±0.69 85.05±1.64
RB + TBL(tag) 89.34 ±0.96 85.17 ±1.55 94.94 ±0.56 93.25 ±0.87
TBL(font) + RB 87.40 ±1.69 71.97 ±1.26 93.20 ±1.02 85.49 ±1.13
TBL(font) + RB + TBL(tag) 93.13 ±1.58 90.48 ±0.80 94.88 ±0.56 93.03 ±0.70
GT(font) + RB 89.25 ±1.57 73.13 ±1.02 93.02 ±0.58 85.03 ±2.28
GT(font) + RB + TBL(tag) 95.31 ±1.43 91.89 ±1.80 95.32 ±0.65 93.36 ±0.81
</table>
<tableCaption confidence="0.942507">
Table 3: Average tagging accuracy results with standard deviation for ten runs using different eight pages
for training, and six pages for testing
</tableCaption>
<figureCaption confidence="0.880534">
Figure 3: The number of errors in two test pages as a function of the number of entries in the training
data for two dictionaries
</figureCaption>
<figure confidence="0.9970128">
Number of Errors
300
250
200
150
100
50
0
# of Errors in Font Style
# of Errors in Tagging with TBL(tag)
# of Errors in Tagging with TBL(font)-TBL(tag)
0 20 40 60 80 100 120 140
Number of Entries in Training Data for Cebuano Dictionary
0 20 40 60 80 100 120
Number of Entries in Training Data for Iraqi Arabic Dictionary
Number of Errors in Test Data
160
140
120
100
80
60
40
20
0
</figure>
<listItem confidence="0.660872">
# of Errors in Font Style
# of Errors in Tagging with TBL(tag)
# of Errors in Tagging with TBL(font)-TBL(tag)
</listItem>
<bodyText confidence="0.999545">
number of errors declines dramatically with the
addition of the first entries. For the tags, the de-
cline is not as steep as the decline in font style. The
main reason involves the number of tags (18 and
26), which are more than the number of font styles
(4 and 3). The method of adding entries to train-
ing data one by one, and finding the point when
the number of errors on selected entries stabilizes,
can determine minimum training data size to get a
reasonable performance increase. lexicalized
</bodyText>
<subsectionHeader confidence="0.997436">
5.4 Example Results
</subsectionHeader>
<bodyText confidence="0.999911043478261">
Table 4 presents some learned transformations for
Cebuano dictionary. Table 5 shows how these
transformations change the font style and tags of
tokens from Figure 4. The first column gives the
tagging results before applying TBL. The con-
secutive columns shows how different TBL runs
changes these results. The tags with * indicate
incorrect tags, the tags with + indicate corrected
tags, and the tags with - indicate introduced er-
rors. The font style of tokens is also represented.
The No column in Tables 4 and 5 gives the applied
transformation number.
For these entries, using TBL on font styles and
tagging together gives correct results in all cases.
Using TBL only on tagging gives the correct tag-
ging only for the last entry.
TBL introduces new errors in some cases. One
error we observed occurs when an example of us-
age translation is assigned a tag before any exam-
ple of usage tag in an entry. This case is illustrated
when applying transformation 9 to the token Abaa
because of a misrecognized comma before the to-
ken.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999688133333333">
In this paper, we introduced a new dictionary en-
try tagging system in which TBL improves tag-
ging accuracy. TBL is applied at two points, –
on font style and tagging– and yields high per-
formance even with limited user provided training
data. For two different dictionaries, we achieved
an increase from 84% and 94% to 97% and 98%
in font style accuracy, from 83% and 91% to 93%
and 94% in tagging accuracy of tokens, and from
64% and 83% to 90% and 93% in tagging accu-
racy of phrases. If the initial font style is not ac-
curate, first improving font style with TBL further
assisted the tagging accuracy as much as 2.62%
for tokens and 2.82% for phrases compared to us-
ing TBL only for tagging. This result cannot be
</bodyText>
<page confidence="0.98875">
262
</page>
<table confidence="0.999382">
No Triggering Environment Change To
10 typen_2 = lowercase and typen_1 = punctuation and typen = capitalized and normal
fontn+1 = normal and fontn+2 = normal
15 fontn_1 = italic and typen = lowercase and typen+1 = lowercase and fontn+2 = italic italic
18 tokenn = the first token in the entry bold
1 tokenn = a and tagn_1 = translation and tagn+1 = translation translation
4 tag[n_7,n_1] = example and tokenn_1 = , and fontn = bold example translation
2 typen = lowercase and fontn = normal and tagn_1 = translation and fontn_1 = normal translation
9 tokenn_1 = , and fontn = italic and typen = capitalized example translation
8 tagn_2 = example translation and tagn_1 = separator and continuation
tagn = example translation and typen = capitalized of a phrase
11 tagn_2 = example and tagn_1 = separator and tagn = example and typen = capitalized continuation of a phrase
</table>
<tableCaption confidence="0.994655">
Table 4: Some sample transformations used for Cebuano dictionary entries in Figure 4. Here, continua-
</tableCaption>
<bodyText confidence="0.968511222222222">
tion of a phrase indicates this token merges with the previous one to form a phrase.
attributed to a low rule-based baseline as a simi-
lar, even a slightly lower baseline is obtained from
an HMM trained system. Results came from a
method used to compensate for extremely lim-
ited training data. The similarity of performance
across two different dictionaries shows the method
as adaptive and able to be applied genericly.
In the future, we plan to investigate the sources
of errors introduced by TBL and whether these
can be avoided by post-processing TBL results us-
ing heuristics. We will also examine the effects
of using TBL to increase the training data size in
a bootstrapped manner. We will apply TBL to
a few pages, then correct these and use them as
new training data in another run. Since TBL im-
proves accuracy, manually preparing training data
will take less time.
</bodyText>
<sectionHeader confidence="0.995027" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.97859">
The partial support of this research under contract
MDA-9040-2C-0406 is gratefully acknowledged.
</bodyText>
<sectionHeader confidence="0.981709" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.945027783333334">
Eric Brill. 1995. Transformation-based error-driven
learning and natural language processing: A case
study in part of speech tagging. Computational Lin-
guistics, 4(21):543–565.
Radu Florian and Grace Ngai. 2001. Multidimen-
sional transformational-based learning. Proceed-
ings of the 5th Conference on Computational Nat-
ural Language Learning, CoNLL 2001, pages 1–8,
July.
Pascale Fung and Lo Yuen Yee. 1998. An IR approach
for translating new words from nonparallel, com-
parable texts. In Christian Boitet and Pete White-
lock, editors, Proceedings of the 36th Annual Meet-
ing of the Association for Computational Linguis-
tics and 17th International Conference on Compu-
tational Linguistics, pages 414–420, San Francisco,
California. Morgan Kaufmann Publishers.
William A. Gale and Kenneth W. Church. 1991. A
program for aligning sentences in bilingual corpora.
In Proceedings of the 29th Annual Meeting of the
ACL, pages 177–184, Berkeley, California, June.
Burcu Karagol-Ayan, David Doermann, and Bonnie
Dorr. 2003. Acquisition of bilingual MT lexicons
from OCRed dictionaries. In Proceedings of the
9th MT Summit, pages 208–215, New Orleans, LA,
September.
Huanfeng Ma and David Doermann. 2003. Bootstrap-
ping structured page segmentation. In Proceedings
of SPIE Conference Document Recognition and Re-
trieval, Santa Clara, CA, January.
I. Dan Melamed. 2000. Models of translational equiv-
alence among words. Computational Linguistics,
26(2):221–249, June.
Grace Ngai and Radu Florian. 2001. Transformation-
based learning in the fast lane. In Proceedings of
the 2nd Conference of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL), pages 40–47, Pittsburgh, PA, June.
Philip Resnik. 1999. Mining the web for bilingual text.
In Proceedings of the 37th Annual Meeting of the As-
sociation for Computational Linguistics (ACL’99),
University of Maryland, College Park, Maryland,
June.
Takehito Utsuro, Takashi Horiuchi, Yasunobu Chiba,
and Takeshi Hamamoto. 2002. Semi-automatic
compilation of bilingual lexicon entries from cross-
lingually relevant news articles on WWW news
sites. In Fifth Conference of the Association for
Machine Translation in the Americas, AMTA-2002,
pages 165–176, Tiburon, California.
Piek Vossen. 1998. EuroWordNet: A Multilingual
Database with Lexical Semantic Networks. Kluwer
Academic Publishers, Dordrecht.
John U. Wolff. 1972. A Dictionary of Cebuano Visaya.
Southeast Asia Program, Cornell University. Ithaca,
New York.
D. R. Woodhead and Wayne Beene, editors. 2003.
A Dictionary of Iraqi Arabic: Arabic–English Dic-
tionary. Georgetown University Press, Washington
D.C.
</reference>
<page confidence="0.80404">
263
264
</page>
<figureCaption confidence="0.998316">
Figure 4: Cebuano-English dictionary entry samples
</figureCaption>
<bodyText confidence="0.981521358974359">
RB RB + TBL (tag) TBL (font) + RB TBL (font) + RB + TBL (tag)
Tag Token(s) No Tag Token(s) No Tag Token(s) No Tag Token(s)
abaa particle abaa particle 18 +hw abaa hw abaa
*hw indicating *hw indicating
disapproval disapproval
+tr particle indicating tr particle indicating
disapproval disapproval
*ex Abaa! 9 -ex-tr Abaa! *ex Abaa! 11 Abaa!
+ex Mah´ug ka
gani dih`a!
*ex Mah´ug ka *ex Mah´ug ka *ex Mah´ug ka
gani dih`a! gani dih`a! gani dih`a!
*ex-tr Stop that! 8 +ex-tr Stop that! *ex-tr Stop that! 8 +ex-tr Stop that!
You might fall! You might fall!
*ex-tr You might fall! *ex-tr You might fall!
*tr emit 1 emit a short grunt *tr emit 2 emit a short grunt
when hit in when hit in
the pit of the the pit of the
+tr stomach or +tr stomach or
when exerting when exerting
an effort an effort
*pos a *pos a
short grunt when short grunt when
*tr hit in the pit *tr hit in the pit
of the stomach or of the stomach or
when exerting an effort when exerting an effort
*ex Miagunt´u *ex Miagunt´u 15 Miagunt´u Miagunt´u
+ex siya ex siya
dihang naig dihang naig
sa kutukutu, sa kutukutu,
*al-sp siya *al-sp siya
*ex dihang naig *ex dihang naig
sa kutukutu, sa kutukutu,
*al-sp The 4 The 10 The The
+ex-tr basketball court +ex-tr basketball court ex-tr basketball court
will be asphalted. will be asphalted. will be asphalted.
*ex-tr basketball court
will be asphalted.
hw: headword; tr: translation; al-sp: alternative spelling of headword; pos: POS; ex: example of usage; ex-tr: example of usage translation
</bodyText>
<tableCaption confidence="0.9968585">
Table 5: Illustration of TBL application to the incorrect tags in the sample entries shown in Figure 4.
* indicates incorrect tags, + indicates corrected tags, and - indicates introduced errors.
</tableCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.981026">
<title confidence="0.998775">Adaptive Transformation-based Learning for Improving Dictionary Tagging</title>
<author confidence="0.999098">Burcu Karagol-Ayan</author>
<author confidence="0.999098">David Doermann</author>
<author confidence="0.999098">Amy Weinberg</author>
<affiliation confidence="0.999709">Institute for Advanced Computer Studies (UMIACS) University of Maryland</affiliation>
<address confidence="0.999899">College Park, MD 20742</address>
<abstract confidence="0.998971117647059">We present an adaptive technique that enables users to produce a high quality dictionary parsed into its lexicographic components (headwords, pronunciations, parts of speech, translations, etc.) using an extremely small amount of user provided training data. We use transformationbased learning (TBL) as a postprocessor at two points in our system to improve performance. The results using two dictionaries show that the tagging accuracy increases from 83% and 91% to 93% and 94% for individual words or “tokens”, and from 64% and 83% to 90% and 93% for contiguous “phrases” such as definitions or examples of usage.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>4</volume>
<issue>21</issue>
<contexts>
<context position="4113" citStr="Brill, 1995" startWordPosition="634" endWordPosition="635">ed at many levels with minimal human assistance. A major requirement for a human aided dictionary tagging application is the need to minimize human generated training data.4 This requirement limits the effectiveness of data driven methods for initial training. We chose rule-based tagging that uses the structure to analyze and tag tokens as our baseline, because it outperformed the baseline results of an HMM tagger. The approach has demonstrated promising results, but we will show its shortcomings can be improved by applying a transformation-based learning (TBL) post processing technique. TBL (Brill, 1995) is a rule-based machine learning method with some attractive qualities that make it suitable for language related tasks. First, the resulting rules are easily reviewed and understood. Second, it is error-driven, thus directly minimizes the error rate (Florian and Ngai, 2001). Furthermore, TBL can be applied to other annotation systems’ output to improve performance. Finally, it makes use of the features of the token and those in the neighborhood surrounding it. In this paper, we describe an adaptive TBL based technique to improve the performance of the rule-based entry tagger, especially targ</context>
<context position="8169" citStr="Brill, 1995" startWordPosition="1319" endWordPosition="1320">ses. An erroneous merge of two tokens as a phrase may take place either because of a font error in one of the tokens or the lack of a separator, such as a punctuation mark. A phrase may split erroneously either 5Using HMMs for entry tagging on the same set of dictionaries produced slightly lower performance, resulting in token accuracy between 73%-88% and phrase accuracy between 57%-85%. 258 as a result of a font error or an ambiguous separator. For instance, a comma may be used after an example of usage to separate it from its translation or within it as a normal punctuation mark. 3 TBL TBL (Brill, 1995), a rule-based machine learning algorithm, has been applied to various NLP tasks. TBL starts with an initial state, and it requires a correctly annotated training corpus, or truth, for the learning (or training) process. The iterative learning process acquires an ordered list of rules or transformations that correct the errors in this initial state. At each iteration, the transformation which achieved the largest benefit during application is selected. During the learning process, the templates of allowable transformations limit the search space for possible transformation rules. The proposed </context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based error-driven learning and natural language processing: A case study in part of speech tagging. Computational Linguistics, 4(21):543–565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Florian</author>
<author>Grace Ngai</author>
</authors>
<title>Multidimensional transformational-based learning.</title>
<date>2001</date>
<booktitle>Proceedings of the 5th Conference on Computational Natural Language Learning, CoNLL</booktitle>
<pages>1--8</pages>
<contexts>
<context position="4389" citStr="Florian and Ngai, 2001" startWordPosition="676" endWordPosition="679">hose rule-based tagging that uses the structure to analyze and tag tokens as our baseline, because it outperformed the baseline results of an HMM tagger. The approach has demonstrated promising results, but we will show its shortcomings can be improved by applying a transformation-based learning (TBL) post processing technique. TBL (Brill, 1995) is a rule-based machine learning method with some attractive qualities that make it suitable for language related tasks. First, the resulting rules are easily reviewed and understood. Second, it is error-driven, thus directly minimizes the error rate (Florian and Ngai, 2001). Furthermore, TBL can be applied to other annotation systems’ output to improve performance. Finally, it makes use of the features of the token and those in the neighborhood surrounding it. In this paper, we describe an adaptive TBL based technique to improve the performance of the rule-based entry tagger, especially targeting certain shortcomings. We first investigate how using TBL to improve the accurate rendering of tokens’ font style affects the rule-based tagging accuracy. We then apply TBL on tags of the tokens. In our experiments with two dictionaries, the range of font style accuracie</context>
</contexts>
<marker>Florian, Ngai, 2001</marker>
<rawString>Radu Florian and Grace Ngai. 2001. Multidimensional transformational-based learning. Proceedings of the 5th Conference on Computational Natural Language Learning, CoNLL 2001, pages 1–8, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Lo Yuen Yee</author>
</authors>
<title>An IR approach for translating new words from nonparallel, comparable texts.</title>
<date>1998</date>
<booktitle>Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,</booktitle>
<pages>414--420</pages>
<editor>In Christian Boitet and Pete Whitelock, editors,</editor>
<publisher>Morgan Kaufmann Publishers.</publisher>
<location>San Francisco, California.</location>
<contexts>
<context position="1361" citStr="Fung and Yee, 1998" startWordPosition="198" endWordPosition="201">and 94% for individual words or “tokens”, and from 64% and 83% to 90% and 93% for contiguous “phrases” such as definitions or examples of usage. 1 Introduction The availability and use of electronic resources such as electronic dictionaries has increased tremendously in recent years and their use in Natural Language Processing (NLP) systems is widespread. For languages with limited electronic resources, i.e. low-density languages, however, we cannot use automated techniques based on parallel corpora (Gale and Church, 1991; Melamed, 2000; Resnik, 1999; Utsuro et al., 2002), comparable corpora (Fung and Yee, 1998), or multilingual thesauri (Vossen, 1998). Yet for these lowdensity languages, printed bilingual dictionaries often offer effective mapping from the low-density language to a high-density language, such as English. Dictionaries can have different formats and can provide a variety of information. However, they typically have a consistent layout of entries and a 1 Headword 5 Translation 2 POS 6 Example of usage 3 Sense number 7 Example of usage translation 4 Synonym 8 Subcategorization Figure 1: Sample tagged dictionary entries. Eight tags are identified and tagged in the given entries. consiste</context>
</contexts>
<marker>Fung, Yee, 1998</marker>
<rawString>Pascale Fung and Lo Yuen Yee. 1998. An IR approach for translating new words from nonparallel, comparable texts. In Christian Boitet and Pete Whitelock, editors, Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, pages 414–420, San Francisco, California. Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the ACL,</booktitle>
<pages>177--184</pages>
<location>Berkeley, California,</location>
<contexts>
<context position="1269" citStr="Gale and Church, 1991" startWordPosition="183" endWordPosition="186">sults using two dictionaries show that the tagging accuracy increases from 83% and 91% to 93% and 94% for individual words or “tokens”, and from 64% and 83% to 90% and 93% for contiguous “phrases” such as definitions or examples of usage. 1 Introduction The availability and use of electronic resources such as electronic dictionaries has increased tremendously in recent years and their use in Natural Language Processing (NLP) systems is widespread. For languages with limited electronic resources, i.e. low-density languages, however, we cannot use automated techniques based on parallel corpora (Gale and Church, 1991; Melamed, 2000; Resnik, 1999; Utsuro et al., 2002), comparable corpora (Fung and Yee, 1998), or multilingual thesauri (Vossen, 1998). Yet for these lowdensity languages, printed bilingual dictionaries often offer effective mapping from the low-density language to a high-density language, such as English. Dictionaries can have different formats and can provide a variety of information. However, they typically have a consistent layout of entries and a 1 Headword 5 Translation 2 POS 6 Example of usage 3 Sense number 7 Example of usage translation 4 Synonym 8 Subcategorization Figure 1: Sample ta</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>William A. Gale and Kenneth W. Church. 1991. A program for aligning sentences in bilingual corpora. In Proceedings of the 29th Annual Meeting of the ACL, pages 177–184, Berkeley, California, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burcu Karagol-Ayan</author>
<author>David Doermann</author>
<author>Bonnie Dorr</author>
</authors>
<title>Acquisition of bilingual MT lexicons from OCRed dictionaries.</title>
<date>2003</date>
<booktitle>In Proceedings of the 9th MT Summit,</booktitle>
<pages>208--215</pages>
<location>New Orleans, LA,</location>
<contexts>
<context position="2836" citStr="Karagol-Ayan et al., 2003" startWordPosition="425" endWordPosition="428">tions, parts of speech (POS), and translations, (2) keywords that provide an explicit interpretation of the lexicographic information, and (3) various separators that impose an overall structure on the entry. For example, a boldface font may indicate a headword, italics may indicate an example of usage, keywords may designate the POS, commas may separate different translations, and a numbering system may identify different senses of a word. We developed an entry tagging system that recognizes, parses, and tags the entries of a printed dictionary to reproduce the representation electronically (Karagol-Ayan et al., 2003). The system aims to use features as described above and the consistent layout and structure of the dictio1For the purposes of this paper, we will refer to the lexicographic information as tag when necessary. 257 naries to capture and recover the lexicographic information in the entries. Each token2 or group of tokens (phrase)3 in an entry associates with a tag indicating its lexicographic information in the entry. Figure 1 shows sample tagged entries in which eight different types of lexicographic information are identified and marked. The system gets format and style information from a docum</context>
<context position="5852" citStr="Karagol-Ayan et al., 2003" startWordPosition="922" endWordPosition="925">phs (i.e., a visual representation of a set of characters) in the OCRed output. Each punctuation is counted as a token as well. 3In Figure 1, not on time is a phrase consisting of 3 tokens. 4For our experiments we required hand tagging of no more than eight pages that took around three hours of human effort. method. In Section 3, we briefly describe TBL, and Section 4 recounts how we apply TBL to improve the performance of the rule-based method. Section 5 explains the experiments and results, and we conclude with future work. 2 A Rule-based Dictionary Entry Tagger The rule-based entry tagger (Karagol-Ayan et al., 2003) utilizes the repeating structure of the dictionaries to identify and tag the linguistic role of tokens or sets of tokens. Rule-based tagging uses three different types of clues—font style, keywords and separators—to tag the entries in a systematic way. The method accommodates noise introduced by the document analyzer by allowing for a relaxed matching of OCRed output to tags. For each dictionary, a human operator must specify the lexicographic information used in that particular dictionary, along with the clues for each tag. This process can be performed in a few hours. The rule-based method </context>
</contexts>
<marker>Karagol-Ayan, Doermann, Dorr, 2003</marker>
<rawString>Burcu Karagol-Ayan, David Doermann, and Bonnie Dorr. 2003. Acquisition of bilingual MT lexicons from OCRed dictionaries. In Proceedings of the 9th MT Summit, pages 208–215, New Orleans, LA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huanfeng Ma</author>
<author>David Doermann</author>
</authors>
<title>Bootstrapping structured page segmentation.</title>
<date>2003</date>
<booktitle>In Proceedings of SPIE Conference Document Recognition and Retrieval,</booktitle>
<location>Santa Clara, CA,</location>
<contexts>
<context position="3485" citStr="Ma and Doermann, 2003" startWordPosition="533" endWordPosition="536">atures as described above and the consistent layout and structure of the dictio1For the purposes of this paper, we will refer to the lexicographic information as tag when necessary. 257 naries to capture and recover the lexicographic information in the entries. Each token2 or group of tokens (phrase)3 in an entry associates with a tag indicating its lexicographic information in the entry. Figure 1 shows sample tagged entries in which eight different types of lexicographic information are identified and marked. The system gets format and style information from a document image analyzer module (Ma and Doermann, 2003) and is retargeted at many levels with minimal human assistance. A major requirement for a human aided dictionary tagging application is the need to minimize human generated training data.4 This requirement limits the effectiveness of data driven methods for initial training. We chose rule-based tagging that uses the structure to analyze and tag tokens as our baseline, because it outperformed the baseline results of an HMM tagger. The approach has demonstrated promising results, but we will show its shortcomings can be improved by applying a transformation-based learning (TBL) post processing </context>
</contexts>
<marker>Ma, Doermann, 2003</marker>
<rawString>Huanfeng Ma and David Doermann. 2003. Bootstrapping structured page segmentation. In Proceedings of SPIE Conference Document Recognition and Retrieval, Santa Clara, CA, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Models of translational equivalence among words.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>2</issue>
<contexts>
<context position="1284" citStr="Melamed, 2000" startWordPosition="187" endWordPosition="188">aries show that the tagging accuracy increases from 83% and 91% to 93% and 94% for individual words or “tokens”, and from 64% and 83% to 90% and 93% for contiguous “phrases” such as definitions or examples of usage. 1 Introduction The availability and use of electronic resources such as electronic dictionaries has increased tremendously in recent years and their use in Natural Language Processing (NLP) systems is widespread. For languages with limited electronic resources, i.e. low-density languages, however, we cannot use automated techniques based on parallel corpora (Gale and Church, 1991; Melamed, 2000; Resnik, 1999; Utsuro et al., 2002), comparable corpora (Fung and Yee, 1998), or multilingual thesauri (Vossen, 1998). Yet for these lowdensity languages, printed bilingual dictionaries often offer effective mapping from the low-density language to a high-density language, such as English. Dictionaries can have different formats and can provide a variety of information. However, they typically have a consistent layout of entries and a 1 Headword 5 Translation 2 POS 6 Example of usage 3 Sense number 7 Example of usage translation 4 Synonym 8 Subcategorization Figure 1: Sample tagged dictionary</context>
</contexts>
<marker>Melamed, 2000</marker>
<rawString>I. Dan Melamed. 2000. Models of translational equivalence among words. Computational Linguistics, 26(2):221–249, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grace Ngai</author>
<author>Radu Florian</author>
</authors>
<title>Transformationbased learning in the fast lane.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2nd Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>40--47</pages>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="9711" citStr="Ngai and Florian, 2001" startWordPosition="1562" endWordPosition="1565">ghboring tags or tokens) matches the context described by the transformation. Two parts comprise a transformation: a rewrite rule— what to replace— and a triggering environment— when to replace. A typical rewrite rule is: Change the annotation from aa to ab, and a typical triggering environment is: The preceding word is wa. The system’s output is the final state of this data after applying all transformations in the order they are produced. To overcome the lengthy training time associated with this approach, we used fnTBL, a fast version of TBL that preserves the performance of the algorithm (Ngai and Florian, 2001). Our research contribution shows this method is effective when applied to a miniscule set of training data. 4 Application of TBL to Entry Tagging In this section, we describe how we used TBL in the context of tagging dictionary entries. We apply TBL at two points: to render correctly the font style of the tokens and to label correctly the tags of the tokens6. Although our ultimate goal 6In reality, TBL improves the accuracy of tags and phrase boundary flags. In this paper, whenever we say “application of TBL to tagging”, we mean tags and phrase boundary flags Figure 2: Phases of TBL applicati</context>
</contexts>
<marker>Ngai, Florian, 2001</marker>
<rawString>Grace Ngai and Radu Florian. 2001. Transformationbased learning in the fast lane. In Proceedings of the 2nd Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 40–47, Pittsburgh, PA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Mining the web for bilingual text.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL’99),</booktitle>
<institution>University of Maryland, College Park,</institution>
<location>Maryland,</location>
<contexts>
<context position="1298" citStr="Resnik, 1999" startWordPosition="189" endWordPosition="190"> the tagging accuracy increases from 83% and 91% to 93% and 94% for individual words or “tokens”, and from 64% and 83% to 90% and 93% for contiguous “phrases” such as definitions or examples of usage. 1 Introduction The availability and use of electronic resources such as electronic dictionaries has increased tremendously in recent years and their use in Natural Language Processing (NLP) systems is widespread. For languages with limited electronic resources, i.e. low-density languages, however, we cannot use automated techniques based on parallel corpora (Gale and Church, 1991; Melamed, 2000; Resnik, 1999; Utsuro et al., 2002), comparable corpora (Fung and Yee, 1998), or multilingual thesauri (Vossen, 1998). Yet for these lowdensity languages, printed bilingual dictionaries often offer effective mapping from the low-density language to a high-density language, such as English. Dictionaries can have different formats and can provide a variety of information. However, they typically have a consistent layout of entries and a 1 Headword 5 Translation 2 POS 6 Example of usage 3 Sense number 7 Example of usage translation 4 Synonym 8 Subcategorization Figure 1: Sample tagged dictionary entries. Eigh</context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Philip Resnik. 1999. Mining the web for bilingual text. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL’99), University of Maryland, College Park, Maryland, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takehito Utsuro</author>
<author>Takashi Horiuchi</author>
<author>Yasunobu Chiba</author>
<author>Takeshi Hamamoto</author>
</authors>
<title>Semi-automatic compilation of bilingual lexicon entries from crosslingually relevant news articles on WWW news sites.</title>
<date>2002</date>
<booktitle>In Fifth Conference of the Association for Machine Translation in the Americas, AMTA-2002,</booktitle>
<pages>165--176</pages>
<location>Tiburon, California.</location>
<contexts>
<context position="1320" citStr="Utsuro et al., 2002" startWordPosition="191" endWordPosition="194">ccuracy increases from 83% and 91% to 93% and 94% for individual words or “tokens”, and from 64% and 83% to 90% and 93% for contiguous “phrases” such as definitions or examples of usage. 1 Introduction The availability and use of electronic resources such as electronic dictionaries has increased tremendously in recent years and their use in Natural Language Processing (NLP) systems is widespread. For languages with limited electronic resources, i.e. low-density languages, however, we cannot use automated techniques based on parallel corpora (Gale and Church, 1991; Melamed, 2000; Resnik, 1999; Utsuro et al., 2002), comparable corpora (Fung and Yee, 1998), or multilingual thesauri (Vossen, 1998). Yet for these lowdensity languages, printed bilingual dictionaries often offer effective mapping from the low-density language to a high-density language, such as English. Dictionaries can have different formats and can provide a variety of information. However, they typically have a consistent layout of entries and a 1 Headword 5 Translation 2 POS 6 Example of usage 3 Sense number 7 Example of usage translation 4 Synonym 8 Subcategorization Figure 1: Sample tagged dictionary entries. Eight tags are identified </context>
</contexts>
<marker>Utsuro, Horiuchi, Chiba, Hamamoto, 2002</marker>
<rawString>Takehito Utsuro, Takashi Horiuchi, Yasunobu Chiba, and Takeshi Hamamoto. 2002. Semi-automatic compilation of bilingual lexicon entries from crosslingually relevant news articles on WWW news sites. In Fifth Conference of the Association for Machine Translation in the Americas, AMTA-2002, pages 165–176, Tiburon, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Piek Vossen</author>
</authors>
<title>EuroWordNet: A Multilingual Database with Lexical Semantic Networks.</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="1402" citStr="Vossen, 1998" startWordPosition="206" endWordPosition="207">rom 64% and 83% to 90% and 93% for contiguous “phrases” such as definitions or examples of usage. 1 Introduction The availability and use of electronic resources such as electronic dictionaries has increased tremendously in recent years and their use in Natural Language Processing (NLP) systems is widespread. For languages with limited electronic resources, i.e. low-density languages, however, we cannot use automated techniques based on parallel corpora (Gale and Church, 1991; Melamed, 2000; Resnik, 1999; Utsuro et al., 2002), comparable corpora (Fung and Yee, 1998), or multilingual thesauri (Vossen, 1998). Yet for these lowdensity languages, printed bilingual dictionaries often offer effective mapping from the low-density language to a high-density language, such as English. Dictionaries can have different formats and can provide a variety of information. However, they typically have a consistent layout of entries and a 1 Headword 5 Translation 2 POS 6 Example of usage 3 Sense number 7 Example of usage translation 4 Synonym 8 Subcategorization Figure 1: Sample tagged dictionary entries. Eight tags are identified and tagged in the given entries. consistent structure within entries. Publishers o</context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>Piek Vossen. 1998. EuroWordNet: A Multilingual Database with Lexical Semantic Networks. Kluwer Academic Publishers, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John U Wolff</author>
</authors>
<title>A Dictionary of</title>
<date>1972</date>
<institution>Cebuano Visaya. Southeast Asia Program, Cornell University.</institution>
<location>Ithaca, New York.</location>
<contexts>
<context position="13085" citStr="Wolff, 1972" startWordPosition="2119" endWordPosition="2120">templates for font style accuracy improvement consist of those from studying the data and all templates using all features within a window of five tokens (i.e., two preceding tokens, the current token, and two following tokens). For tagging accuracy improvement, we prepared the transformation templates by studying dictionaries and errors in the entry tagging results. The objective function for evaluating transformations in both cases is the classification accuracy, and the objective is to minimize the number of errors. 5 Experiments We performed our experiments on a CebuanoEnglish dictionary (Wolff, 1972) consisting of 1163 pages, 4 font styles, and 18 tags, and on an Iraqi Arabic-English dictionary (Woodhead and Beene, 2003) consisting of 507 pages, 3 font styles, and 26 tags. For our experiments, we used a publicly available implementation of TBL’s fast version, fnTBL7, described in Section 3. We used eight randomly selected pages from the dictionaries to train TBL, and six additional randomly selected pages for testing. The font style and tag of each token on these pages are manually corrected from an initial run. Our goal is to measure the effect of TBL on font style and tagging that have </context>
</contexts>
<marker>Wolff, 1972</marker>
<rawString>John U. Wolff. 1972. A Dictionary of Cebuano Visaya. Southeast Asia Program, Cornell University. Ithaca, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Woodhead</author>
<author>Wayne Beene</author>
<author>editors</author>
</authors>
<title>A Dictionary of Iraqi Arabic: Arabic–English Dictionary.</title>
<date>2003</date>
<publisher>Georgetown University Press,</publisher>
<location>Washington D.C.</location>
<marker>Woodhead, Beene, editors, 2003</marker>
<rawString>D. R. Woodhead and Wayne Beene, editors. 2003. A Dictionary of Iraqi Arabic: Arabic–English Dictionary. Georgetown University Press, Washington D.C.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>