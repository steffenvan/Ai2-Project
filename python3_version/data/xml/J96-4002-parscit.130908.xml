<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9953225">
An Algorithm to Align Words for
Historical Comparison
</title>
<author confidence="0.961956">
Michael A. Covington*
</author>
<affiliation confidence="0.83525">
The University of Georgia
</affiliation>
<bodyText confidence="0.9983096">
The first step in applying the comparative method to a pair of words suspected of being cognate is
to align the segments of each word that appear to correspond. Finding the right alignment may
require searching. For example, Latin do &apos;I give&apos; lines up with the middle do in Greek diclomi,
not the initial di.
This paper presents an algorithm for finding probably correct alignments on the basis of
phonetic similarity. The algorithm consists of an evaluation metric and a guided search procedure.
The search algorithm can be extended to implement special handling of metathesis, assimilation,
or other phenomena that require looking ahead in the string, and can return any number of
alignments that meet some criterion of goodness, not just the one best. It can serve as a front end
to computer implementations of the comparative method.
</bodyText>
<sectionHeader confidence="0.983587" genericHeader="method">
1. The Problem
</sectionHeader>
<bodyText confidence="0.987078952380953">
The first step in applying the comparative method to a pair of words suspected of
being cognate is to align the segments of each word that appear to correspond. This
alignment step is not necessarily trivial. For example, the correct alignment of Latin
da with Greek dickimi is
--do--
didomi
and not
do---- d - - - - ----do
didomi dido i di domi
or numerous other possibilities. The segments of two words may be misaligned be-
cause of affixes (living or fossilized), reduplication, and sound changes that alter the
number of segments, such as elision or monophthongization.
Alignment is a neglected part of the computerization of the comparative method.
The computer programs developed by Frantz (1970), Hewson (1974), and Wimbish
(1989) require the alignments to be specified in their input. The Reconstruction Engine
of Lowe and Mazaudon (1994) requires the linguist to specify hypothetical sound
changes and canonical syllable structure. The cognateness tester of Guy (1994) ignores
the order of segments, matching any segment in one word with any segment in the
other.
This paper presents a guided search algorithm for finding the best alignment of
one word with another, where both words are given in a broad phonetic transcription.
</bodyText>
<note confidence="0.538083">
* Artificial Intelligence Center, The University of Georgia, Athens, Georgia 30602-7415. E-mail:
</note>
<email confidence="0.729859">
mcovingt@ai.uga.edu
</email>
<note confidence="0.8721075">
© 1996 Association for Computational Linguistics
Computational Linguistics Volume 22, Number 4
</note>
<bodyText confidence="0.9983285">
The algorithm compares surface forms and does not look for sound laws or phono-
logical rules; it is meant to correspond to the linguist&apos;s first look at unfamiliar data.
A prototype implementation has been built in Prolog and tested on a corpus of 82
known cognate pairs from various languages. Somewhat surprisingly, it needs little or
no knowledge of phonology beyond the distinction between vowels, consonants, and
glides.
</bodyText>
<sectionHeader confidence="0.980259" genericHeader="method">
2. Alignments
</sectionHeader>
<bodyText confidence="0.965290552631579">
If the two words to be aligned are identical, the task of aligning them is trivial. In all
other cases, the problem is one of inexact string matching, i.e., finding the alignment
that minimizes the difference between the two words. A dynamic programming algo-
rithm for inexact string matching is well known (Sankoff &amp; Kruskal 1983, Ukkonen
1985, Waterman 1995), but I do not use it, for several reasons. First, the strings being
aligned are relatively short, so the efficiency of dynamic programming on long strings
is not needed. Second, dynamic programming normally gives only one alignment for
each pair of strings, but comparative reconstruction may need the n best alternatives,
or all that meet some criterion. Third, the tree search algorithm lends itself to modifi-
cation for special handling of metathesis or assimilation. More about this later; first I
need to sketch what the aligner is supposed to accomplish.
An alignment can be viewed as a way of stepping through two words concurrently,
consuming all the segments of each. At each step, the aligner can perform either a
match or skip. A match is what happens when the aligner consumes a segment from
each of the two words in a single step, thereby aligning the two segments with each
other (whether or not they are phonologically similar) A skip is what happens when
it consumes a segment from one word while leaving the other word alone. Thus, the
alignment
a b c -
-bde
is produced by skipping a, then matching b with b, then matching c with d, then
skipping e. Here as elsewhere, hyphens in either string correspond to skipped segments
in the other.&apos;
The aligner is not allowed to perform, in succession, a skip on one string and then
a skip on the other, because the result would be equivalent to a match (of possibly
dissimilar segments). That is, of the three alignments
a b - c a - b c a b c
a - d c a d - c a d c
only the third one is permitted; pursuing all three would waste time because they
are equivalent as far as linguistic claims are concerned. (Determining whether b and d
actually correspond is a question of historical reconstruction, not of alignment.) I call
this restriction the no-alternating-skips rule.
To identify the best alignment, the algorithm must assign a penalty (cost) to every
skip or match. The best alignment is the one with the lowest total penalty. As a first
1 Traditionally, the problem is formulated in terms of operations to turn one string into the other. Skips
in string 1 and string 2 are called deletions and insertions respectively, and matches of dissimilar
segments are called substitutions. This terminology is inappropriate for historical linguistics, since the
ultimate goal is to derive the two strings from a common ancestor.
</bodyText>
<page confidence="0.993007">
482
</page>
<figure confidence="0.642957285714286">
Covington An Algorithm to Align Words
approximation, we can use the following penalties:
0.0 for an exact match;
0.5 for aligning a vowel with a different vowel, or a consonant with a
different consonant;
1.0 for a complete mismatch;
0.5 for a skip (so that two alternating skips—the disallowed case—would
have the same penalty as the mismatch to which they are equivalent).
Then the possible alignments of Spanish el and French le (phonetically [la]) are:
e 1
1 a 2 complete mismatches = 2.0
-el
l- 2 skips + 1 vowel pair = 1.5
el -
</figure>
<bodyText confidence="0.915401">
- 1 a 2 skips + 1 exact match = 1.0
The third of these has the lowest penalty (and is the etymologically correct alignment).
</bodyText>
<sectionHeader confidence="0.882955" genericHeader="method">
3. The Search Space
</sectionHeader>
<bodyText confidence="0.9477404">
Figure 1 shows, in the form of a tree, all of the moves that the aligner might try while
attempting to align two three-letter words (English [hz] and German [hat]). We know
that these words correspond segment-by-segment,2 but the aligner does not. It has to
work through numerous alternatives in order to conclude that
h x z
hat
is indeed the best alignment.
The alignment algorithm is simply a depth-first search of this tree, beginning at
the top of Figure 1. That is, at each position in the pair of input strings, the aligner tries
first a match, then a skip on the first word, then a skip on the second, and computes
all the consequences of each. After completing each alignment it backs up to the most
recent untried alternative and tries a different one. &amp;quot;Dead ends&amp;quot; in the tree are places
where further computation is blocked by the no-alternating-skip rule.
As should be evident, the search tree can be quite large even if the words being
aligned are fairly short. Table 1 gives the number of possible alignments for words of
various lengths; when both words are of length n, there are about 3&amp;quot;-1 alignments,
not counting dead ends. Without the no-alternating-skip rule, the number would be
about 5&amp;quot;/2. Exact formulas are given in the appendix.
Fortunately, the aligner can greatly narrow the search by putting the evaluation
metric to use as it works. The key idea is to abandon any branch of the search tree
</bodyText>
<footnote confidence="0.7681765">
2 Actually, as an anonymous reviewer points out, the exact correspondence is between German hat and
earlier English hath. The current English -s ending may be analogical. This does not affect the validity
of the example because /t/ and /s/ are certainly in corresponding positions, regardless of their
phonological history.
</footnote>
<page confidence="0.998962">
483
</page>
<figure confidence="0.999165188405797">
Volume 22, Number 4
Computational Linguistics
hat
Si
-h-
ha hat
1.5 S2
SI -he
ha-
Start 2.0
0.5 Si
Si --h
hat
ha
1.0 hat
S2
25
10
10
Dead end
20
S2
--hez
hat--
25
hez-
-hat
Dead end
10
S2 h-az 20
hat- 20
30
15
Dead end
10
Si
hez-
h-at
15
Dead end
10
S2
-hez
hat-
25
Dead end 25
2 0
-hez
ha-t
s2 -hez Dead end
ha--
25
52
15 hat-
Dead end
15
SI
El Ail
1.5 S2 2.0 Si
he--
-hat
Dead end
30
25
Dead end
2.5
Si hmz--
20 --hat
25
</figure>
<figureCaption confidence="0.991796">
Figure 1
</figureCaption>
<bodyText confidence="0.782069">
Search space for aligning English /hz/ with German /hat/.
</bodyText>
<page confidence="0.992849">
484
</page>
<figure confidence="0.8273280625">
Covington An Algorithm to Align Words
Table 1
Number of alignments as a function of lengths of
words.
Lengths of words Alignments
2 2 3
2 3 5
2 4 8
2 5 12
3 3 9
3 4 15
3 5 24
4 4 27
4 5 46
5 5 83
10 10 26,797
</figure>
<bodyText confidence="0.997519411764706">
as soon as the accumulated penalty exceeds the total penalty of the best alignment
found so far. Figure 2 shows the search tree after pruning according to this principle.
The total amount of work is roughly cut in half. With larger trees, the saving can be
even greater.
To ensure that a relatively good alignment is found early, it is important, at each
stage, to try matches before trying skips. Otherwise the aligner would start by gener-
ating a large number of useless displacements of each string relative to the other, all
of which have high penalties and do not narrow the search space much. Even so, the
algorithm is quite able to skip affixes when appropriate. For example, when asked to
align Greek diclOmi with Latin c/O, it tries only three alignments, of which the best two
are:
diclomi diclomi
d--6-- --d6--
Choosing the right one of these is then a task for the linguist rather than the alignment
algorithm. However, it would be easy to modify the algorithm to use a lower penalty
for skips at the beginning or end of a word than skips elsewhere; the algorithm would
then be more willing to postulate prefixes and suffixes than infixes.
</bodyText>
<sectionHeader confidence="0.677976" genericHeader="method">
4. The Full Evaluation Metric
</sectionHeader>
<bodyText confidence="0.999947">
Table 2 shows an evaluation metric developed by trial and error using the 82 cognate
pairs shown in the subsequent tables. To avoid floating-point rounding errors, all
penalties are integers, and the penalty for a complete mismatch is now 100 rather
than 1.0. The principles that emerge are that syllabicity is paramount, consonants
matter more than vowels, and affixes tend to be contiguous.
Somewhat surprisingly, it was not necessary to use information about place of
articulation in this evaluation metric (although there are a few places where it might
have helped). This accords with Anttila&apos;s (1989, 230) observation that great phonetic
subtlety is not needed to align words; what one wants to do is find the exact matches
and align the syllabic peaks, matching segments of comparable syllabicity (vowels
with vowels and consonants with consonants).
</bodyText>
<page confidence="0.998411">
485
</page>
<figureCaption confidence="0.974739">
Figure 2
Same tree as in Figure 1, after pruning.
</figureCaption>
<figure confidence="0.9351265">
Start
Computational Linguistics Volume 22, Number 4
</figure>
<page confidence="0.737388">
486
</page>
<table confidence="0.311326">
Covington An Algorithm to Align Words
</table>
<tableCaption confidence="0.607408">
Table 2
</tableCaption>
<figure confidence="0.9799742">
Evaluation metric developed from actual data.
Penalty Conditions
0 Exact match of consonants or glides (w, y)
5 Exact match of vowels (reflecting the fact that
the aligner should prefer to match consonants
rather than vowels if it must choose between the two)
10 Match of two vowels that differ only in length,
or i and y, or u and w
30 Match of two dissimilar vowels
60 Match of two dissimilar consonants
100 Match of two segments with no discernible similarity
40 Skip preceded by another skip in the same word
(reflecting the fact that affixes tend to be
contiguous)
50 Skip not preceded by another skip in the same word
</figure>
<bodyText confidence="0.999883944444445">
It follows that the input to the aligner should be in broad phonetic transcrip-
tion, using symbols with closely similar values in both langauges. Excessively narrow
phonetic transcriptions do not help; they introduce too many subtle mismatches that
should have been ignored.
Phonemic transcriptions are acceptable insofar as they are also broad phonetic, but,
unlike comparative reconstruction, alignment does not benefit by taking phonemes as
the starting point. One reason is that alignment deals with syntagmatic rather than
paradigmatic relations between sounds; what counts is the place of the sound in the
word, not the place of the sound in the sound system. Another reason is that earlier
and later languages are tied together more by the physical nature of the sounds than
by the structure of the system. The physical sounds are handed down from earlier
generations but the system of contrasts is constructed anew by every child learning
to talk.
The aligner &apos;s only job is to line up words to maximize phonetic similarity. In the
absence of known sound correspondences, it can do no more. Its purpose is to simulate
a linguist&apos;s first look at unfamiliar data. Linguistic research is a bootstrapping process
in which data leads to analysis and analysis leads to more and better-interpreted data.
In its present form, the aligner does not participate in this process.
</bodyText>
<sectionHeader confidence="0.987767" genericHeader="method">
5. Results on Actual Data
</sectionHeader>
<bodyText confidence="0.988654">
Tables 3 to 10 show how the aligner performed on 82 cognate pairs in various lan-
guages. (Tables 5-8 are loosely based on the Swadesh word lists of Ringe 1992.)
</bodyText>
<footnote confidence="0.785744">
3 To briefly address Ringe&apos;s main point: if the &amp;quot;best&amp;quot; alignment of a pair of words is used, the likelihood
of finding a chance similarity is much higher than when using a fixed, canonical alignment.
</footnote>
<page confidence="0.978807">
487
</page>
<table confidence="0.441012">
Computational Linguistics Volume 22, Number 4
</table>
<tableCaption confidence="0.992059">
Table 3
</tableCaption>
<table confidence="0.99015925">
Alignments obtained with test set of Spanish-French cognate pairs.
yo : je &apos;I&apos; yo
tu : tu &apos;you&apos; 2 a
nosotros : nous &apos;you&apos; tu
quien : qui &apos;who?&apos; t
que: quoi &apos;what?&apos; nosotros
todos : tous &apos;all&apos; nu
una : une &apos;one&apos; (f.sg.) kyen
dos : deux &apos;two&apos; k i - -
tres : troix &apos;three&apos; k - e
hombre : homme &apos;man&apos; kw a
t odo s
tu- - -
u n a
Un -
dos
d -
tr-es
t rwa -
omb r e
</table>
<bodyText confidence="0.999142631578947">
These are &amp;quot;difficult&amp;quot; language pairs. On closely similar languages, such as Span-
ish/Italian or German/Danish, the aligner would have performed much better. Even
so, on Spanish and French—chosen because they are historically close but phonologi-
cally very different—the aligner performed almost flawlessly (Tables 3 and 4). Its only
clear mistake is that it missed the 1:r correspondence in arbre : tirbol, but so would the
linguist without other data.
With English and German it did almost as well (Tables 5 and 6). The s in this
is aligned with the wrong s in dieses because that alignment gave greater phonetic
similarity; taking off the inflectional ending would have prevented this mistake. The
alignments of mouth with Mund and eye with Auge gave the aligner some trouble; in
each case it produced two alternatives, each getting part of the alignment right.
English and Latin (Tables 7 and 8) are much harder to pair up, since they are
separated by millennia of phonological and morphological change, including Grimm&apos;s
Law. Nonetheless, the aligner did reasonably well with them, correctly aligning, for
example, star with stella and round with rotundus. In some cases it was just plain
wrong, e.g., aligning tooth with the -tis ending of dentis. In others it was indecisive;
although it found the correct alignment of fish with piscis, it could not distinguish it
from three alternatives. In all of these cases, eliminating the inflectional endings would
have resulted in correct or nearly correct alignments.
</bodyText>
<page confidence="0.990459">
488
</page>
<table confidence="0.652516">
Covington An Algorithm to Align Words
</table>
<tableCaption confidence="0.908073">
Table 4
Alignments obtained with test set of Spanish-French cognate pairs
</tableCaption>
<equation confidence="0.800319294117647">
(continued).
cirbol : arbre &apos;tree&apos;
pluma : plume &apos;feather&apos;
cabeza &apos;head&apos; : cap &apos;promontory&apos;
boca : bouche &apos;mouth&apos;
pie : pied &apos;foot&apos;
corazdn : coeur &apos;heart&apos;
ver: voir &apos;see&apos;
venir : venir &apos;come&apos;
decir : dire &apos;say&apos;
pobre : pauvre &apos;poor&apos;
arb-ol
arbra-
p 1 um a
p 1 inn -
kabe0a
kap- - -
</equation>
<figure confidence="0.845987857142857">
boka
b u § -
p y e
p y e
koraeon
k r - - - -
b - e r
v w a r
benir
vanir
deOir
d - - i r
pobre
povra
</figure>
<bodyText confidence="0.990224777777778">
Table 9 shows that the algorithm works well with non-Indo-European languages,
in this case Fox and Menomini cognates chosen more or less randomly from Bloomfield
(1941). Apart from some minor trouble with the suffix of the first item, the aligner had
smooth sailing.
Finally, Table 10 shows how the aligner fared with some word pairs involving
Latin, Greek, Sanskrit, and Avestan, again without knowledge of morphology Because
it knows nothing about place of articulation or Grimm&apos;s Law, it cannot tell whether
the d in daughter corresponds with the th or the g in Greek thugater. But on centum :
hekaton and cen turn : satom the aligner performed perfectly.
</bodyText>
<sectionHeader confidence="0.952628" genericHeader="method">
6. Improving the Alignment Algorithm
</sectionHeader>
<bodyText confidence="0.999602666666667">
This alignment algorithm and its evaluation metric are, in effect, a formal reconstruc-
tion of something that historical linguists do intuitively. As such, they provide an
empirical test of theories about how historical reconstruction is practiced.
There are limits to how well an aligner can perform, given that it knows nothing
about comparative reconstruction or regularity of correspondences. Nonetheless, the
present algorithm could be improved in several ways.
</bodyText>
<page confidence="0.995362">
489
</page>
<figure confidence="0.708261515151515">
Computational Linguistics Volume 22, Number 4
Table 5
Alignments obtained with test set of English-German cognate pairs.
this : dieses
that : das
what: was
not : nicht
long : lang
man : Mann
flesh : Fleisch
blood : Blut
feather: Feder
hair : Haar
6 i - - s
dizas
6 x t
da s
wa t
vas
na-t
nixt
1013
1 a D
mw n
man
fle-g
f 1 ay §
b 1 a d
blut
f eoar
f edar
h w r
ha r
</figure>
<bodyText confidence="0.9997915">
One obvious improvement would be to implement feature-based phonology. Im-
plicitly, the aligner already uses two features, vocalicity and vowel length. A fuller
set of features would have given a better alignment of piscis with fish, preferring f:p
to f:k. Features are not all of equal importance for the evaluation metric; syllabicity,
for instance, will surely be more important than nasality. Using multivariate statistical
techniques and a set of known &amp;quot;good&amp;quot; alignments, the relative importance of each
feature could be calculated.
Another improvement would be to enable the aligner to recognize assimilation,
metathesis, and even reduplication, and assign lower penalties to them than to arbi-
trary mismatches. The need to do this is one reason for using tree search rather than
the standard dynamic programming algorithm for inexact string matching. Dynamic
programming is, in effect, a breadth-first search of the tree in Figure 1; Ukkonen&apos;s
(1985) improvement of it is a narrowed breadth-first search with iterative broadening.
Both of these rely on computing parts of the tree first, then stringing partial solutions
together to get a complete solution (that is what &amp;quot;dynamic programming&amp;quot; means).
They do their partial computations in an order that precludes &amp;quot;looking ahead&amp;quot; along
the string to undo an assimilation, metathesis, or reduplication. By contrast, my depth-
first search algorithm can look ahead without difficulty.
</bodyText>
<page confidence="0.995077">
490
</page>
<figure confidence="0.903312">
Covington An Algorithm to Align Words
Table 6
Alignments obtained with test set of English-German cognate pairs
(continued).
ear: Ohr
eye : Auge
nose : Nase
mouth : Mund
tongue: Zunge
foot : Fufl
knee: Knie
hand : Hand
heart : Herz
liver: Leber
ir
or
a--y ay- -
awga awg a
nowz-
na-za
maw-0
m-unt
t-au-
tsuua
fut
fus
-niy
kni-
hnd
hant
hart-
herts
livar
lebar
maw0 -
m- un t
</figure>
<bodyText confidence="0.681640352941177">
Another crucial difference between my algorithm and dynamic programming is
that, by altering the tree pruning criterion, my algorithm can easily generate, not just
the best alignment or those that are tied for the best position, but the n best alignments,
or all alignments that are sufficiently close to the best (by any computable criterion).
Multilateral alignments are needed when more than two languages are being com-
pared at once. For example,
el -
- 1 a
i 1 -
is the etymologically correct three-way alignment of the masculine singular definite
article in Spanish, French, and Italian. Multilateral alignments can be generated by
aligning the second word with the first, then the third word with the second (and
implicitly also the first), and so on, but it would be advantageous to apply the eval-
uation metric to the whole set rather than just the pairs that are chained together.
Multilateral alignment is also an important problem in DNA sequence analysis, and
no general algorithm for it is known, but research is proceeding apace (Kececioglu
1993, Waterman 1995).
</bodyText>
<page confidence="0.997263">
491
</page>
<note confidence="0.580925">
Computational Linguistics Volume 22, Number 4
</note>
<tableCaption confidence="0.9100485">
Table 7
Alignments obtained with test set of English-Latin cognate pairs.
</tableCaption>
<figure confidence="0.92458337735849">
and : ante
at : ad
blow :flare
ear : auris
eat : edere
fish : piscis
flow :fluere
star : stela
full : pltnus
grass : gra-men
heart : cordis (gen.)
horn : coma
I: ego
wnd-
ante
wt
ad
bl--ow=
flare-
i-r--
awris
iyt---
e-dere
---fi§
pi skis
flow---
fl-uere
star--
stella
-ful
p1 nus
gr--ws
gramen
har--t
kordis
horn-
korna
--ay
ego-
f - - - i §
pi skis
f---ul
p1 nus
grw--s
gramen
hart--
kordis
f i - - - §
piskis
grws - -
gr amen
f i §- - -
pi skis
</figure>
<listItem confidence="0.865573166666667">
7. From Here to the Comparative Method
Comparative reconstruction consists of three essential steps:
1. Align the segments in the (putative) cognates;
2. Find correspondence sets (corresponding to proto-allophones);
3. Identify some correspondence sets as phonetically conditioned variants
of others (thereby reconstructing proto-phonemes).
</listItem>
<page confidence="0.994994">
492
</page>
<table confidence="0.558245">
Covington An Algorithm to Align Words
</table>
<tableCaption confidence="0.827532">
Table 8
Alignments obtained with test set of English-Latin cognate pairs
(continued).
</tableCaption>
<table confidence="0.969947458333333">
knee : genii --niy ma wn t on
mother: mdter genu - me - n s - -
mountain : mins ma 6 a r nyuw-
name: nO-men ma t e r n owu s
new: novus mawn t on
one: Rnus me - n - -s
round: rotundus n e ym - -
sew: suere no -men
sit : sedere n y uw - -
three : tres n - owu s
tooth : dentis (gen.) won - -
thin : tennis -Onus
r a - wn d - -
r o t undus
sow---
s-uere
sit - - -
sedere
Oriy
tres
---tuw0
denti-s
Oin---
tenuis
</table>
<bodyText confidence="0.996623615384615">
Kay (1964) noted that the &amp;quot;right&amp;quot; set of alignments (of each of the cognate pairs) is
the set that produces the smallest total number of sound correspondences. Steps 1
and 2 could therefore be automated by generating all possible alignments of all of the
cognate pairs, then choosing the set of alignments that gives the fewest correspondence
sets.
As Kay notes, this is not practical. Suppose the putative cognates are each 3 seg-
ments long. There are then 9 different alignments of each cognate pair, and if 100
cognate pairs are to be considered, there are 9100 :----- 2.65 x 1095 sets of alignments to
choose from, far too many to try on even the fastest computer.
However, a guided search along the same lines might well be worthwhile. First
choose one alignment for each cognate pair—the best according to the evaluation met-
ric, or if several are equally good, choose one arbitrarily. Construct the entire set of
correspondence sets. Then go back and try one or two alternative alignments for each
</bodyText>
<page confidence="0.998398">
493
</page>
<note confidence="0.579846">
Computational Linguistics Volume 22, Number 4
</note>
<tableCaption confidence="0.944762">
Table 9
</tableCaption>
<construct confidence="0.555550545454546">
Alignments obtained with test set of Fox-Menomini cognate pairs.
kiinwaawa : kenuaq &apos;you (pl.)&apos;
niina : nenah &apos;I&apos;
naapeewa : naapecw &apos;man&apos;
waapimini : waapemen &apos;maize&apos;
nameesa : nameeqs &apos;fish (n.)&apos;
okimaawa : okeemaaw &apos;chief&apos;
iis&apos;iipa: seeqsep &apos;duck (n.)&apos;
ahkohkwa : ahkeeh &apos;kettle&apos;
pemaatesiweni : pemaatesewen &apos;life&apos;
asenya : aqsen &apos;stone (n.)&apos;
</construct>
<figure confidence="0.994349875">
kInwawa-
ken--uaq
nina-
nenah
napewa
napEw-
wapimini
wapemen-
name-sa
namEqs-
okimawa
okemaw-
gI-§Ipa
seqsep-
ahkohkwa
ahkEh---
pernatesiweni
pematesewen-
a - senya
aqsen- -
k I nwawa -
kenu- -aq
gIg-Ipa
seqsep-
</figure>
<bodyText confidence="0.995954">
cognate pair, noting whether the size of the set of correspondence sets decreases. If so,
adopt the new alignment instead of the previous one. For a set of 100 cognate pairs,
this requires a total of only a few hundred steps, and the result should be close to the
optimal solution. Reduction of correspondence sets to proto-phonemes is, of course,
a separate task requiring a knowledge base of phonological features and information
about phonetic plausibility.
</bodyText>
<subsectionHeader confidence="0.705565">
Appendix: Size of the Search Space
</subsectionHeader>
<bodyText confidence="0.999578">
The total number of alignments of a pair of words of lengths m and n can be calculated
as follows.&apos; Recall that a match consumes a segment of both words; a skip consumes a
</bodyText>
<footnote confidence="0.572058">
4 For assistance with mathematics here I am greatly indebted to E. Rodney Canfield. I also want to thank
other mathematicians Who offered helpful advice, among them John Kececioglu, Jeff Clark, Jan Willem
Nienhuys, Oscar Lanzi III, Les Reid, and other participants in sci.math on the Internet.
</footnote>
<page confidence="0.990828">
494
</page>
<figure confidence="0.88611675862069">
Covington An Algorithm to Align Words
Table 10
Alignments obtained with cognate pairs from other languages.
k=0
Greek didomi : Latin c/a &apos;I give&apos;
Greek thugater : German Tochter &apos;daughter&apos;
English daughter : Greek thugater &apos;daughter&apos;
Latin ager : Sanskrit ajras &apos;field&apos;
Sanskrit bhara-mi : Greek phercT &apos;I carry&apos;
Latin centum : Greek hekaton &apos;100&apos;
Latin centum : Avestan satam &apos;100&apos;
didomi didomi
--do-- d- -a- -
thuga at
tox- tar
bha r mi
phe r - - 0
--kenturn
heka- ton
kenturn
sa- tam
bha
phe
r am i
r - -
--dotar d- -otar do-- tar
thugater thuga ter ate ter
a-ger ag-er age r - -
ajras ajras aj-ras
</figure>
<bodyText confidence="0.9970202">
segment from one word but not the other. The complete alignment has to consume all
the segments of both words. Accordingly, any alignment containing k matches must
also contain m - k skips on the first word and n - k skips on the second word. The
number of matches k in turn ranges from 0 to min(m, n). Thus, in general, the number
of possible alignments is
</bodyText>
<equation confidence="0.841467666666667">
min(m,n)
Alignments(m, n) = E number of alignments containing k matches
k=0
</equation>
<bodyText confidence="0.999945333333333">
Without the no-alternate-skip rule, the number of alignments containing k matches is
simply the number of ways of partitioning a set of k + (m - k) + (n- k) =m+n- k
moves into k matches, m - k skips on word 1, and n - k skips on word 2:
</bodyText>
<equation confidence="0.99780925">
inir(11411)
(m + n — k)!
Alignments (m, n) =
k! (m - k)! (n - k)!
</equation>
<bodyText confidence="0.99973725">
(To give you an idea of the magnitude, this is close to 5n/2 for cases where m = n and
n &lt;20 or so.)
With the no-alternate-skip rule, the number of alignments is exponentially smaller
(about 3&amp;quot;-1 when m = n) and can be calculated from the recurrence relation
</bodyText>
<equation confidence="0.807899">
n-2 m-2
a(m, n) = a (m — 1,n —1) + E a (m - 1,i) + E a(i, n -1)
i=o i=o
</equation>
<bodyText confidence="0.9659605">
with the initial conditions a(0, n) = a(m, 0) = 1; for a derivation of this formula see
Covington and Canfield (in preparation).
</bodyText>
<page confidence="0.996282">
495
</page>
<figure confidence="0.431193">
Computational Linguistics Volume 22, Number 4
References
</figure>
<reference confidence="0.999852373134328">
Anttila, Raimo. 1989. Historical and
Comparative Linguistics. Second revised
edition. Amsterdam Studies in the Theory
and History of Linguistic Science, IV:
Current Issues in Linguistic Theory, 6.
Benjamins, Amsterdam.
Bloomfield, Leonard. 1941. Algonquian. In
C. Osgood, editor, Linguistic Structures of
Native America. Viking Fund Publications
in Anthropology, 6. Reprint, Johnson
Reprint Corporation, New York, 1963,
pages 85-129.
Covington, Michael A. and Canfield, E.
Rodney. In preparation. The number of
distinct alignments of two strings.
Research report, Artificial Intelligence
Center, The University of Georgia.
Frantz, Donald G. 1970. A PL/1 program to
assist the comparative linguist.
Communications of the ACM, 13:353-356.
Guy, Jacques B. M. 1994. An algorithm for
identifying cognates in bilingual wordlists
and its applicability to machine
translation. Journal of Quantitative
Linguistics, 1:35-42.
Hewson, John. 1974. Comparative
reconstruction on the computer. In John
M. Anderson and Charles Jones, editors,
Historical Linguistics I: Syntax, Morphology,
Internal and Comparative Reconstruction.
North Holland, Amsterdam, pages
191-197.
Kay, Martin. 1964. The logic of cognate
recognition in historical linguistics.
Memorandum RM-4224-PR. The RAND
Corporation, Santa Monica.
Kececioglu, John. 1993. The maximum
weight trace problem in multiple
sequence alignment. In A. Apostolico et
al., editors, Combinatorial Pattern Matching:
4th Annual Symposium, Springer, Berlin,
pages 106-119.
Lowe, John B. and Martine Mazaudon.
1994. The reconstruction engine: A
computer implementation of the
comparative method. Computational
Linguistics, 20:381-417.
Ringe, Donald A., Jr. 1992. On Calculating the
Factor of Chance in Language Comparison.
American Philosophical Society,
Philadelphia.
Sankoff, David and Joseph B. Kruskal,
editors. 1983. Time Warps, String Edits, and
Macromolecules: The Theory and Practice of
Sequence Comparison. Addison-Wesley,
Reading, MA.
Ukkonen, Esko. 1985. Algorithms for
approximate string matching. Information
and Control, 64:100-118.
Waterman, Michael S. 1995. Introduction to
Computational Biology: Maps, Sequences and
Genomes. Chapman &amp; Hall, London.
Wimbish, John S. 1989. WORDSURV: A
program for analyzing language survey
word lists. Summer Institute of
Linguistics, Dallas. Cited by Lowe and
Mazaudon. 1994.
</reference>
<page confidence="0.999126">
496
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9993085">An Algorithm to Align Words for Historical Comparison</title>
<author confidence="0.999934">Michael A Covington</author>
<affiliation confidence="0.989349">The University of Georgia</affiliation>
<abstract confidence="0.995801645161291">The first step in applying the comparative method to a pair of words suspected of being cognate is to align the segments of each word that appear to correspond. Finding the right alignment may searching. For example, Latin give&apos; lines up with the middle Greek diclomi, the initial This paper presents an algorithm for finding probably correct alignments on the basis of phonetic similarity. The algorithm consists of an evaluation metric and a guided search procedure. The search algorithm can be extended to implement special handling of metathesis, assimilation, or other phenomena that require looking ahead in the string, and can return any number of alignments that meet some criterion of goodness, not just the one best. It can serve as a front end to computer implementations of the comparative method. 1. The Problem The first step in applying the comparative method to a pair of words suspected of being cognate is to align the segments of each word that appear to correspond. This alignment step is not necessarily trivial. For example, the correct alignment of Latin Greek didomi and not - i di domi or numerous other possibilities. The segments of two words may be misaligned because of affixes (living or fossilized), reduplication, and sound changes that alter the number of segments, such as elision or monophthongization. Alignment is a neglected part of the computerization of the comparative method. The computer programs developed by Frantz (1970), Hewson (1974), and Wimbish (1989) require the alignments to be specified in their input. The Reconstruction Engine of Lowe and Mazaudon (1994) requires the linguist to specify hypothetical sound changes and canonical syllable structure. The cognateness tester of Guy (1994) ignores the order of segments, matching any segment in one word with any segment in the other. This paper presents a guided search algorithm for finding the best alignment of one word with another, where both words are given in a broad phonetic transcription.</abstract>
<note confidence="0.855133">Artificial Intelligence Center, The University of Georgia, Athens, Georgia 30602-7415. E-mail:</note>
<email confidence="0.873816">mcovingt@ai.uga.edu</email>
<note confidence="0.865749">1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 4 The algorithm compares surface forms and does not look for sound laws or phono-</note>
<abstract confidence="0.995330647058824">logical rules; it is meant to correspond to the linguist&apos;s first look at unfamiliar data. A prototype implementation has been built in Prolog and tested on a corpus of 82 known cognate pairs from various languages. Somewhat surprisingly, it needs little or no knowledge of phonology beyond the distinction between vowels, consonants, and glides. 2. Alignments If the two words to be aligned are identical, the task of aligning them is trivial. In all cases, the problem is one of string matching, finding the alignment that minimizes the difference between the two words. A dynamic programming algorithm for inexact string matching is well known (Sankoff &amp; Kruskal 1983, Ukkonen 1985, Waterman 1995), but I do not use it, for several reasons. First, the strings being aligned are relatively short, so the efficiency of dynamic programming on long strings is not needed. Second, dynamic programming normally gives only one alignment for pair of strings, but comparative reconstruction may need the alternatives, or all that meet some criterion. Third, the tree search algorithm lends itself to modification for special handling of metathesis or assimilation. More about this later; first I need to sketch what the aligner is supposed to accomplish. An alignment can be viewed as a way of stepping through two words concurrently, consuming all the segments of each. At each step, the aligner can perform either a match is what happens when the aligner consumes a segment from each of the two words in a single step, thereby aligning the two segments with each other (whether or not they are phonologically similar) A skip is what happens when it consumes a segment from one word while leaving the other word alone. Thus, the alignment a b c -bde produced by skipping matching matching as elsewhere, hyphens in either string correspond to skipped segments in the other.&apos; The aligner is not allowed to perform, in succession, a skip on one string and then a skip on the other, because the result would be equivalent to a match (of possibly dissimilar segments). That is, of the three alignments a b c a b c a b c a d c a d c a d c only the third one is permitted; pursuing all three would waste time because they equivalent as far as linguistic claims are concerned. (Determining whether actually correspond is a question of historical reconstruction, not of alignment.) I call restriction the rule. identify the best alignment, the algorithm must assign a to every skip or match. The best alignment is the one with the lowest total penalty. As a first 1 Traditionally, the problem is formulated in terms of operations to turn one string into the other. Skips string 1 and string 2 are called and insertions and matches of dissimilar are called terminology is inappropriate for historical linguistics, since the ultimate goal is to derive the two strings from a common ancestor. 482 Covington An Algorithm to Align Words approximation, we can use the following penalties: 0.0 for an exact match; 0.5 for aligning a vowel with a different vowel, or a consonant with a different consonant; 1.0 for a complete mismatch; 0.5 for a skip (so that two alternating skips—the disallowed case—would have the same penalty as the mismatch to which they are equivalent). the possible alignments of Spanish French [la]) are: e 1 1 a 2 complete mismatches = 2.0 -el skips + 1 vowel pair = 1.5 1 a 2 skips + 1 exact match The third of these has the lowest penalty (and is the etymologically correct alignment). 3. The Search Space Figure 1 shows, in the form of a tree, all of the moves that the aligner might try while attempting to align two three-letter words (English [hz] and German [hat]). We know these words correspond but the aligner does not. It has to work through numerous alternatives in order to conclude that h x hat is indeed the best alignment. The alignment algorithm is simply a depth-first search of this tree, beginning at top of 1. That is, at each position the pair of input strings, the aligner tries first a match, then a skip on the first word, then a skip on the second, and computes all the consequences of each. After completing each alignment it backs up to the most recent untried alternative and tries a different one. &amp;quot;Dead ends&amp;quot; in the tree are places where further computation is blocked by the no-alternating-skip rule. As should be evident, the search tree can be quite large even if the words being aligned are fairly short. Table 1 gives the number of possible alignments for words of lengths; when both words are of length are about alignments, not counting dead ends. Without the no-alternating-skip rule, the number would be about 5&amp;quot;/2. Exact formulas are given in the appendix. Fortunately, the aligner can greatly narrow the search by putting the evaluation metric to use as it works. The key idea is to abandon any branch of the search tree Actually, as an anonymous reviewer points out, the exact correspondence is between German English current English -s ending may be analogical. This does not affect the validity of the example because /t/ and /s/ are certainly in corresponding positions, regardless of their phonological history.</abstract>
<note confidence="0.838922333333333">483 Volume 22, Number 4 Computational Linguistics</note>
<abstract confidence="0.787478652173913">hat -hha hat 1.5 S2 SI -he ha- Start 2.0 0.5 Si --h hat ha 1.0 hat S2 25 10 10 Dead end 20 S2 --hez hat-- 25 hez- -hat Dead end 10 S2 h-az hat- 20 20 30 15 Dead end 10 hez-h-at 15 Dead end 10 S2 -hez hat- 25 Dead end 25 2 0 -hez ha-t s2 -hez Dead end ha-- 25 hat- Dead end 15</abstract>
<title confidence="0.738186">SI</title>
<author confidence="0.9367135">El_Ail Si</author>
<email confidence="0.876134">-hat</email>
<abstract confidence="0.650029882352941">Dead end 30 25 Dead end 2.5 Si 20 --hat 25 Figure 1 Search space for aligning English /hz/ with German /hat/. 484 Covington An Algorithm to Align Words Table 1 Number of alignments as a function of lengths of words. Lengths of words Alignments 2 2 3</abstract>
<phone confidence="0.7258293">2 3 5 2 4 8 2 5 12 3 3 9 3 4 15 3 5 24 4 4 27 4 5 46 5 5 83 10 10 26,797</phone>
<abstract confidence="0.953403433333333">soon the accumulated penalty exceeds the total penalty of the best alignment found so far. Figure 2 shows the search tree after pruning according to this principle. The total amount of work is roughly cut in half. With larger trees, the saving can be even greater. To ensure that a relatively good alignment is found early, it is important, at each stage, to try matches before trying skips. Otherwise the aligner would start by generating a large number of useless displacements of each string relative to the other, all of which have high penalties and do not narrow the search space much. Even so, the algorithm is quite able to skip affixes when appropriate. For example, when asked to Greek Latin tries only three alignments, of which the best two are: Choosing the right one of these is then a task for the linguist rather than the alignment algorithm. However, it would be easy to modify the algorithm to use a lower penalty for skips at the beginning or end of a word than skips elsewhere; the algorithm would then be more willing to postulate prefixes and suffixes than infixes. 4. The Full Evaluation Metric Table 2 shows an evaluation metric developed by trial and error using the 82 cognate pairs shown in the subsequent tables. To avoid floating-point rounding errors, all penalties are integers, and the penalty for a complete mismatch is now 100 rather than 1.0. The principles that emerge are that syllabicity is paramount, consonants matter more than vowels, and affixes tend to be contiguous. Somewhat surprisingly, it was not necessary to use information about place of articulation in this evaluation metric (although there are a few places where it might have helped). This accords with Anttila&apos;s (1989, 230) observation that great phonetic subtlety is not needed to align words; what one wants to do is find the exact matches and align the syllabic peaks, matching segments of comparable syllabicity (vowels with vowels and consonants with consonants). 485 Figure 2 Same tree as in Figure 1, after pruning.</abstract>
<note confidence="0.890532">Start Computational Linguistics Volume 22, Number 4 486</note>
<title confidence="0.42138275">Covington An Algorithm to Align Words Table 2 Evaluation metric developed from actual data. Penalty Conditions</title>
<abstract confidence="0.960873258426966">0 Exact match of consonants or glides (w, y) 5 Exact match of vowels (reflecting the fact that the aligner should prefer to match consonants rather than vowels if it must choose between the two) 10 Match of two vowels that differ only in length, y, or w 30 Match of two dissimilar vowels 60 Match of two dissimilar consonants 100 Match of two segments with no discernible similarity 40 Skip preceded by another skip in the same word (reflecting the fact that affixes tend to be contiguous) 50 Skip not preceded by another skip in the same word It follows that the input to the aligner should be in broad phonetic transcription, using symbols with closely similar values in both langauges. Excessively narrow phonetic transcriptions do not help; they introduce too many subtle mismatches that should have been ignored. Phonemic transcriptions are acceptable insofar as they are also broad phonetic, but, unlike comparative reconstruction, alignment does not benefit by taking phonemes as the starting point. One reason is that alignment deals with syntagmatic rather than paradigmatic relations between sounds; what counts is the place of the sound in the word, not the place of the sound in the sound system. Another reason is that earlier and later languages are tied together more by the physical nature of the sounds than by the structure of the system. The physical sounds are handed down from earlier generations but the system of contrasts is constructed anew by every child learning to talk. The aligner &apos;s only job is to line up words to maximize phonetic similarity. In the absence of known sound correspondences, it can do no more. Its purpose is to simulate a linguist&apos;s first look at unfamiliar data. Linguistic research is a bootstrapping process in which data leads to analysis and analysis leads to more and better-interpreted data. In its present form, the aligner does not participate in this process. 5. Results on Actual Data Tables 3 to 10 show how the aligner performed on 82 cognate pairs in various languages. (Tables 5-8 are loosely based on the Swadesh word lists of Ringe 1992.) 3 To briefly address Ringe&apos;s main point: if the &amp;quot;best&amp;quot; alignment of a pair of words is used, the likelihood of finding a chance similarity is much higher than when using a fixed, canonical alignment. 487 Computational Linguistics Volume 22, Number 4 Table 3 Alignments obtained with test set of Spanish-French cognate pairs. yo : je &apos;I&apos; yo 2 a : tu tu t : nous : tous : une (f.sg.) : deux : troix : homme nosotros nu kyen k i - k e kw a t odo s tu- - u n a dos d tr-es t rwa omb r e These are &amp;quot;difficult&amp;quot; language pairs. On closely similar languages, such as Spanish/Italian or German/Danish, the aligner would have performed much better. Even so, on Spanish and French—chosen because they are historically close but phonologically very different—the aligner performed almost flawlessly (Tables 3 and 4). Its only mistake is that it missed the in : tirbol, so would the linguist without other data. English and German it did almost as well (Tables 5 and 6). The aligned with the wrong that alignment gave greater phonetic similarity; taking off the inflectional ending would have prevented this mistake. The of the aligner some trouble; in each case it produced two alternatives, each getting part of the alignment right. English and Latin (Tables 7 and 8) are much harder to pair up, since they are separated by millennia of phonological and morphological change, including Grimm&apos;s Law. Nonetheless, the aligner did reasonably well with them, correctly aligning, for some cases it was just plain e.g., aligning the of others it was indecisive; it found the correct alignment of could not distinguish it from three alternatives. In all of these cases, eliminating the inflectional endings would have resulted in correct or nearly correct alignments. 488 Covington An Algorithm to Align Words Table 4 Alignments obtained with test set of Spanish-French cognate pairs (continued). : arbre : plume : : bouche : pied : coeur voir : venir : dire : pauvre arb-ol arbrap 1 um a p 1 inn kabe0a kap- - boka b u § p y e p y e koraeon k r - - - b e r v w a r benir vanir deOir d - i r pobre povra Table 9 shows that the algorithm works well with non-Indo-European languages, in this case Fox and Menomini cognates chosen more or less randomly from Bloomfield (1941). Apart from some minor trouble with the suffix of the first item, the aligner had smooth sailing. Finally, Table 10 shows how the aligner fared with some word pairs involving Latin, Greek, Sanskrit, and Avestan, again without knowledge of morphology Because it knows nothing about place of articulation or Grimm&apos;s Law, it cannot tell whether with the the Greek on : turn : satom aligner performed perfectly. 6. Improving the Alignment Algorithm This alignment algorithm and its evaluation metric are, in effect, a formal reconstruction of something that historical linguists do intuitively. As such, they provide an empirical test of theories about how historical reconstruction is practiced. There are limits to how well an aligner can perform, given that it knows nothing about comparative reconstruction or regularity of correspondences. Nonetheless, the present algorithm could be improved in several ways. 489 Computational Linguistics Volume 22, Number 4 Table 5 Alignments obtained with test set of English-German cognate pairs. this : dieses that : das what: was not : nicht long : lang man : Mann flesh : Fleisch blood : Blut feather: Feder hair : Haar 6 i - s dizas 6 x t da s wa t vas na-t nixt 1013 1 a D mw n man fle-g f 1 ay § d blut f eoar f edar h w r ha r improvement would be to implement feature-based phonology. Implicitly, the aligner already uses two features, vocalicity and vowel length. A fuller of features would have given a better alignment of are not all of equal importance for the evaluation metric; syllabicity, for instance, will surely be more important than nasality. Using multivariate statistical techniques and a set of known &amp;quot;good&amp;quot; alignments, the relative importance of each feature could be calculated. Another improvement would be to enable the aligner to recognize assimilation, metathesis, and even reduplication, and assign lower penalties to them than to arbitrary mismatches. The need to do this is one reason for using tree search rather than the standard dynamic programming algorithm for inexact string matching. Dynamic programming is, in effect, a breadth-first search of the tree in Figure 1; Ukkonen&apos;s (1985) improvement of it is a narrowed breadth-first search with iterative broadening. Both of these rely on computing parts of the tree first, then stringing partial solutions together to get a complete solution (that is what &amp;quot;dynamic programming&amp;quot; means). They do their partial computations in an order that precludes &amp;quot;looking ahead&amp;quot; along the string to undo an assimilation, metathesis, or reduplication. By contrast, my depthfirst search algorithm can look ahead without difficulty. 490 Covington An Algorithm to Align Words Table 6 Alignments obtained with test set of English-German cognate pairs (continued).</abstract>
<degree confidence="0.912527333333333">ear: Ohr eye : Auge nose : Nase mouth : Mund tongue: Zunge foot : Fufl knee: Knie hand : Hand heart : Herz</degree>
<abstract confidence="0.9539334">liver: Leber ir or a--y ay- awga awg a nowzna-za maw-0 m-unt t-autsuua fut fus -niy knihnd hant hartherts livar lebar maw0 mun t Another crucial difference between my algorithm and dynamic programming is that, by altering the tree pruning criterion, my algorithm can easily generate, not just best alignment or those that are tied for the best position, but the alignments, or all alignments that are sufficiently close to the best (by any computable criterion). Multilateral alignments are needed when more than two languages are being compared at once. For example, el - 1 1 is the etymologically correct three-way alignment of the masculine singular definite article in Spanish, French, and Italian. Multilateral alignments can be generated by aligning the second word with the first, then the third word with the second (and implicitly also the first), and so on, but it would be advantageous to apply the evaluation metric to the whole set rather than just the pairs that are chained together. Multilateral alignment is also an important problem in DNA sequence analysis, and no general algorithm for it is known, but research is proceeding apace (Kececioglu 1993, Waterman 1995). 491 Computational Linguistics Volume 22, Number 4 Table 7 Alignments obtained with test set of English-Latin cognate pairs. and : ante at : ad blow :flare ear : auris eat : edere fish : piscis flow :fluere star : stela full : pltnus : : cordis horn : coma I: ego wndante wt ad bl--ow= flarei-r-awris iyt--e-dere ---fi§ pi skis flow--fl-uere star-stella -ful p1 nus gr--ws gramen har--t kordis hornkorna --ay egof - - i § pi skis f---ul p1 nus grw--s gramen hart-kordis f i - - - § piskis grws - gr amen f i §- - pi skis 7. From Here to the Comparative Method Comparative reconstruction consists of three essential steps: 1. Align the segments in the (putative) cognates; 2. Find correspondence sets (corresponding to proto-allophones); 3. Identify some correspondence sets as phonetically conditioned variants of others (thereby reconstructing proto-phonemes). 492 Covington An Algorithm to Align Words Table 8 Alignments obtained with test set of English-Latin cognate pairs (continued). knee : genii genu ma wn t on me n s - mother: mdter mountain : mins new: novus one: Rnus round: rotundus sew: suere sit : sedere three : tres : dentis thin : tennis ma t e r nyuwowu t me n - -s n e ym no -men n y uw n owu s won - -Onus r a wn d r o t undus s-uere sit - sedere tres denti-s tenuis Kay (1964) noted that the &amp;quot;right&amp;quot; set of alignments (of each of the cognate pairs) is the set that produces the smallest total number of sound correspondences. Steps 1 and 2 could therefore be automated by generating all possible alignments of all of the cognate pairs, then choosing the set of alignments that gives the fewest correspondence sets. As Kay notes, this is not practical. Suppose the putative cognates are each 3 segments long. There are then 9 different alignments of each cognate pair, and if 100 pairs are to be considered, there are :----- 2.65 sets of alignments to choose from, far too many to try on even the fastest computer. However, a guided search along the same lines might well be worthwhile. First for each cognate pair—the best according to the evaluation metric, or if several are equally good, choose one arbitrarily. Construct the entire set of correspondence sets. Then go back and try one or two alternative alignments for each 493 Computational Linguistics Volume 22, Number 4 Table 9 Alignments obtained with test set of Fox-Menomini cognate pairs. : kenuaq (pl.)&apos; niina : nenah &apos;I&apos; : naapecw : waapemen : nameeqs (n.)&apos; : okeemaaw seeqsep (n.)&apos; : ahkeeh : pemaatesewen : aqsen (n.)&apos; kInwawaken--uaq ninanenah napewa napEwwapimini wapemenname-sa namEqsokimawa okemawgI-§Ipa seqsepahkohkwa ahkEh--pernatesiweni pematesewena senya aqsen- k I nwawa kenu- -aq seqseppair, whether the size of the set of correspondence sets decreases. If so, adopt the new alignment instead of the previous one. For a set of 100 cognate pairs, this requires a total of only a few hundred steps, and the result should be close to the optimal solution. Reduction of correspondence sets to proto-phonemes is, of course, a separate task requiring a knowledge base of phonological features and information about phonetic plausibility. Appendix: Size of the Search Space total number of alignments of a pair of words of lengths m and be calculated as follows.&apos; Recall that a match consumes a segment of both words; a skip consumes a 4 For assistance with mathematics here I am greatly indebted to E. Rodney Canfield. I also want to thank other mathematicians Who offered helpful advice, among them John Kececioglu, Jeff Clark, Jan Willem Nienhuys, Oscar Lanzi III, Les Reid, and other participants in sci.math on the Internet. 494 Covington An Algorithm to Align Words Table 10 Alignments obtained with cognate pairs from other languages. k=0 : c/a &apos;I give&apos; : : : : carry&apos; : : didomi didomi d- at toxtar r mi r - - --kenturn hekaton kenturn satam i r - - --dotar d- -otar do-tar ter ate ter a-ger ag-er age r - ajras ajras aj-ras segment from one word but not the other. The complete alignment has to consume all segments of both words. Accordingly, any alignment containing must contain on the first word and k on the second word. The of matches turn ranges from 0 to min(m, in general, the number of possible alignments is min(m,n) = of alignments containing k=0 the no-alternate-skip rule, the number of alignments containing is the number of ways of partitioning a set of (m - + k) k into m on word 1, and k on word 2: inir(11411) + n n) = (m k)! give you an idea of the magnitude, this is close to 5n/2 for cases where = or so.) With the no-alternate-skip rule, the number of alignments is exponentially smaller when m = can be calculated from the recurrence relation n-2 m-2 n) = a (m — —1) + (m - 1,i) + n -1) i=o i=o the initial conditions a(0, = a(m, = 1; a derivation of this formula see Covington and Canfield (in preparation).</abstract>
<note confidence="0.920498894736842">495 Computational Linguistics Volume 22, Number 4 References Raimo. 1989. and Linguistics. revised edition. Amsterdam Studies in the Theory and History of Linguistic Science, IV: Current Issues in Linguistic Theory, 6. Benjamins, Amsterdam. Bloomfield, Leonard. 1941. Algonquian. In Osgood, editor, Structures of America. Fund Publications in Anthropology, 6. Reprint, Johnson Reprint Corporation, New York, 1963, pages 85-129. Covington, Michael A. and Canfield, E. Rodney. In preparation. The number of distinct alignments of two strings. Research report, Artificial Intelligence</note>
<affiliation confidence="0.666984">Center, The University of Georgia.</affiliation>
<address confidence="0.509947">Frantz, Donald G. 1970. A PL/1 program to</address>
<abstract confidence="0.983530333333333">assist the comparative linguist. of the ACM, Guy, Jacques B. M. 1994. An algorithm for identifying cognates in bilingual wordlists and its applicability to machine of Quantitative</abstract>
<note confidence="0.707386777777778">Hewson, John. 1974. Comparative reconstruction on the computer. In John M. Anderson and Charles Jones, editors, Historical Linguistics I: Syntax, Morphology, Internal and Comparative Reconstruction. North Holland, Amsterdam, pages 191-197. Kay, Martin. 1964. The logic of cognate recognition in historical linguistics.</note>
<author confidence="0.423024">The RAND</author>
<affiliation confidence="0.81714">Corporation, Santa Monica.</affiliation>
<address confidence="0.84889">Kececioglu, John. 1993. The maximum</address>
<abstract confidence="0.590530666666667">weight trace problem in multiple sequence alignment. In A. Apostolico et editors, Pattern Matching: Annual Symposium, Berlin, pages 106-119. Lowe, John B. and Martine Mazaudon. 1994. The reconstruction engine: A computer implementation of the method.</abstract>
<note confidence="0.615421428571429">Donald A., Jr. 1992. Calculating the Factor of Chance in Language Comparison. American Philosophical Society, Philadelphia. Sankoff, David and Joseph B. Kruskal, 1983. Warps, String Edits, and Macromolecules: The Theory and Practice of Comparison. Reading, MA. Ukkonen, Esko. 1985. Algorithms for string matching. Control, Michael S. 1995. to Computational Biology: Maps, Sequences and &amp; Hall, London. Wimbish, John S. 1989. WORDSURV: A program for analyzing language survey word lists. Summer Institute of Linguistics, Dallas. Cited by Lowe and Mazaudon. 1994. 496</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Raimo Anttila</author>
</authors>
<title>Historical and Comparative Linguistics. Second revised edition.</title>
<date>1989</date>
<booktitle>Amsterdam Studies in the Theory and History of Linguistic Science, IV: Current Issues in Linguistic Theory, 6. Benjamins,</booktitle>
<location>Amsterdam.</location>
<marker>Anttila, 1989</marker>
<rawString>Anttila, Raimo. 1989. Historical and Comparative Linguistics. Second revised edition. Amsterdam Studies in the Theory and History of Linguistic Science, IV: Current Issues in Linguistic Theory, 6. Benjamins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Bloomfield</author>
</authors>
<title>Algonquian. In</title>
<date>1941</date>
<booktitle>Linguistic Structures of Native America. Viking Fund Publications in Anthropology, 6. Reprint, Johnson Reprint Corporation,</booktitle>
<pages>85--129</pages>
<editor>C. Osgood, editor,</editor>
<location>New York,</location>
<contexts>
<context position="15884" citStr="Bloomfield (1941)" startWordPosition="2768" endWordPosition="2769"> Alignments obtained with test set of Spanish-French cognate pairs (continued). cirbol : arbre &apos;tree&apos; pluma : plume &apos;feather&apos; cabeza &apos;head&apos; : cap &apos;promontory&apos; boca : bouche &apos;mouth&apos; pie : pied &apos;foot&apos; corazdn : coeur &apos;heart&apos; ver: voir &apos;see&apos; venir : venir &apos;come&apos; decir : dire &apos;say&apos; pobre : pauvre &apos;poor&apos; arb-ol arbrap 1 um a p 1 inn - kabe0a kap- - - boka b u § - p y e p y e koraeon k r - - - - b - e r v w a r benir vanir deOir d - - i r pobre povra Table 9 shows that the algorithm works well with non-Indo-European languages, in this case Fox and Menomini cognates chosen more or less randomly from Bloomfield (1941). Apart from some minor trouble with the suffix of the first item, the aligner had smooth sailing. Finally, Table 10 shows how the aligner fared with some word pairs involving Latin, Greek, Sanskrit, and Avestan, again without knowledge of morphology Because it knows nothing about place of articulation or Grimm&apos;s Law, it cannot tell whether the d in daughter corresponds with the th or the g in Greek thugater. But on centum : hekaton and cen turn : satom the aligner performed perfectly. 6. Improving the Alignment Algorithm This alignment algorithm and its evaluation metric are, in effect, a for</context>
</contexts>
<marker>Bloomfield, 1941</marker>
<rawString>Bloomfield, Leonard. 1941. Algonquian. In C. Osgood, editor, Linguistic Structures of Native America. Viking Fund Publications in Anthropology, 6. Reprint, Johnson Reprint Corporation, New York, 1963, pages 85-129.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michael A Covington</author>
<author>E Rodney Canfield</author>
</authors>
<title>In preparation. The number of distinct alignments of two strings.</title>
<journal>Research report, Artificial Intelligence</journal>
<institution>Center, The University of Georgia.</institution>
<marker>Covington, Canfield, </marker>
<rawString>Covington, Michael A. and Canfield, E. Rodney. In preparation. The number of distinct alignments of two strings. Research report, Artificial Intelligence Center, The University of Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald G Frantz</author>
</authors>
<title>A PL/1 program to assist the comparative linguist.</title>
<date>1970</date>
<journal>Communications of the ACM,</journal>
<pages>13--353</pages>
<contexts>
<context position="1656" citStr="Frantz (1970)" startWordPosition="271" endWordPosition="272">cognate is to align the segments of each word that appear to correspond. This alignment step is not necessarily trivial. For example, the correct alignment of Latin da with Greek dickimi is --do-- didomi and not do---- d - - - - ----do didomi dido i di domi or numerous other possibilities. The segments of two words may be misaligned because of affixes (living or fossilized), reduplication, and sound changes that alter the number of segments, such as elision or monophthongization. Alignment is a neglected part of the computerization of the comparative method. The computer programs developed by Frantz (1970), Hewson (1974), and Wimbish (1989) require the alignments to be specified in their input. The Reconstruction Engine of Lowe and Mazaudon (1994) requires the linguist to specify hypothetical sound changes and canonical syllable structure. The cognateness tester of Guy (1994) ignores the order of segments, matching any segment in one word with any segment in the other. This paper presents a guided search algorithm for finding the best alignment of one word with another, where both words are given in a broad phonetic transcription. * Artificial Intelligence Center, The University of Georgia, Ath</context>
</contexts>
<marker>Frantz, 1970</marker>
<rawString>Frantz, Donald G. 1970. A PL/1 program to assist the comparative linguist. Communications of the ACM, 13:353-356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques B M Guy</author>
</authors>
<title>An algorithm for identifying cognates in bilingual wordlists and its applicability to machine translation.</title>
<date>1994</date>
<journal>Journal of Quantitative Linguistics,</journal>
<pages>1--35</pages>
<contexts>
<context position="1931" citStr="Guy (1994)" startWordPosition="311" endWordPosition="312">ssibilities. The segments of two words may be misaligned because of affixes (living or fossilized), reduplication, and sound changes that alter the number of segments, such as elision or monophthongization. Alignment is a neglected part of the computerization of the comparative method. The computer programs developed by Frantz (1970), Hewson (1974), and Wimbish (1989) require the alignments to be specified in their input. The Reconstruction Engine of Lowe and Mazaudon (1994) requires the linguist to specify hypothetical sound changes and canonical syllable structure. The cognateness tester of Guy (1994) ignores the order of segments, matching any segment in one word with any segment in the other. This paper presents a guided search algorithm for finding the best alignment of one word with another, where both words are given in a broad phonetic transcription. * Artificial Intelligence Center, The University of Georgia, Athens, Georgia 30602-7415. E-mail: mcovingt@ai.uga.edu © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 4 The algorithm compares surface forms and does not look for sound laws or phonological rules; it is meant to correspond to the l</context>
</contexts>
<marker>Guy, 1994</marker>
<rawString>Guy, Jacques B. M. 1994. An algorithm for identifying cognates in bilingual wordlists and its applicability to machine translation. Journal of Quantitative Linguistics, 1:35-42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Hewson</author>
</authors>
<title>Comparative reconstruction on the computer. In</title>
<date>1974</date>
<booktitle>Historical Linguistics I: Syntax, Morphology, Internal and Comparative Reconstruction. North</booktitle>
<pages>191--197</pages>
<editor>John M. Anderson and Charles Jones, editors,</editor>
<location>Holland, Amsterdam,</location>
<contexts>
<context position="1671" citStr="Hewson (1974)" startWordPosition="273" endWordPosition="274">lign the segments of each word that appear to correspond. This alignment step is not necessarily trivial. For example, the correct alignment of Latin da with Greek dickimi is --do-- didomi and not do---- d - - - - ----do didomi dido i di domi or numerous other possibilities. The segments of two words may be misaligned because of affixes (living or fossilized), reduplication, and sound changes that alter the number of segments, such as elision or monophthongization. Alignment is a neglected part of the computerization of the comparative method. The computer programs developed by Frantz (1970), Hewson (1974), and Wimbish (1989) require the alignments to be specified in their input. The Reconstruction Engine of Lowe and Mazaudon (1994) requires the linguist to specify hypothetical sound changes and canonical syllable structure. The cognateness tester of Guy (1994) ignores the order of segments, matching any segment in one word with any segment in the other. This paper presents a guided search algorithm for finding the best alignment of one word with another, where both words are given in a broad phonetic transcription. * Artificial Intelligence Center, The University of Georgia, Athens, Georgia 30</context>
</contexts>
<marker>Hewson, 1974</marker>
<rawString>Hewson, John. 1974. Comparative reconstruction on the computer. In John M. Anderson and Charles Jones, editors, Historical Linguistics I: Syntax, Morphology, Internal and Comparative Reconstruction. North Holland, Amsterdam, pages 191-197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>The logic of cognate recognition in historical linguistics. Memorandum RM-4224-PR. The RAND Corporation,</title>
<date>1964</date>
<location>Santa Monica.</location>
<contexts>
<context position="21579" citStr="Kay (1964)" startWordPosition="3770" endWordPosition="3771">oned variants of others (thereby reconstructing proto-phonemes). 492 Covington An Algorithm to Align Words Table 8 Alignments obtained with test set of English-Latin cognate pairs (continued). knee : genii --niy ma wn t on mother: mdter genu - me - n s - - mountain : mins ma 6 a r nyuwname: nO-men ma t e r n owu s new: novus mawn t on one: Rnus me - n - -s round: rotundus n e ym - - sew: suere no -men sit : sedere n y uw - - three : tres n - owu s tooth : dentis (gen.) won - - thin : tennis -Onus r a - wn d - - r o t undus sow--- s-uere sit - - - sedere Oriy tres ---tuw0 denti-s Oin--- tenuis Kay (1964) noted that the &amp;quot;right&amp;quot; set of alignments (of each of the cognate pairs) is the set that produces the smallest total number of sound correspondences. Steps 1 and 2 could therefore be automated by generating all possible alignments of all of the cognate pairs, then choosing the set of alignments that gives the fewest correspondence sets. As Kay notes, this is not practical. Suppose the putative cognates are each 3 segments long. There are then 9 different alignments of each cognate pair, and if 100 cognate pairs are to be considered, there are 9100 :----- 2.65 x 1095 sets of alignments to choos</context>
</contexts>
<marker>Kay, 1964</marker>
<rawString>Kay, Martin. 1964. The logic of cognate recognition in historical linguistics. Memorandum RM-4224-PR. The RAND Corporation, Santa Monica.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Kececioglu</author>
</authors>
<title>The maximum weight trace problem in multiple sequence alignment.</title>
<date>1993</date>
<booktitle>Combinatorial Pattern Matching: 4th Annual Symposium,</booktitle>
<pages>106--119</pages>
<editor>In A. Apostolico et al., editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin,</location>
<contexts>
<context position="20112" citStr="Kececioglu 1993" startWordPosition="3479" endWordPosition="3480">ample, el - - 1 a i 1 - is the etymologically correct three-way alignment of the masculine singular definite article in Spanish, French, and Italian. Multilateral alignments can be generated by aligning the second word with the first, then the third word with the second (and implicitly also the first), and so on, but it would be advantageous to apply the evaluation metric to the whole set rather than just the pairs that are chained together. Multilateral alignment is also an important problem in DNA sequence analysis, and no general algorithm for it is known, but research is proceeding apace (Kececioglu 1993, Waterman 1995). 491 Computational Linguistics Volume 22, Number 4 Table 7 Alignments obtained with test set of English-Latin cognate pairs. and : ante at : ad blow :flare ear : auris eat : edere fish : piscis flow :fluere star : stela full : pltnus grass : gra-men heart : cordis (gen.) horn : coma I: ego wndante wt ad bl--ow= flarei-r-- awris iyt--- e-dere ---fi§ pi skis flow--- fl-uere star-- stella -ful p1 nus gr--ws gramen har--t kordis hornkorna --ay egof - - - i § pi skis f---ul p1 nus grw--s gramen hart-- kordis f i - - - § piskis grws - - gr amen f i §- - - pi skis 7. From Here to the</context>
</contexts>
<marker>Kececioglu, 1993</marker>
<rawString>Kececioglu, John. 1993. The maximum weight trace problem in multiple sequence alignment. In A. Apostolico et al., editors, Combinatorial Pattern Matching: 4th Annual Symposium, Springer, Berlin, pages 106-119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John B Lowe</author>
<author>Martine Mazaudon</author>
</authors>
<title>The reconstruction engine: A computer implementation of the comparative method.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--381</pages>
<contexts>
<context position="1800" citStr="Lowe and Mazaudon (1994)" startWordPosition="291" endWordPosition="294"> the correct alignment of Latin da with Greek dickimi is --do-- didomi and not do---- d - - - - ----do didomi dido i di domi or numerous other possibilities. The segments of two words may be misaligned because of affixes (living or fossilized), reduplication, and sound changes that alter the number of segments, such as elision or monophthongization. Alignment is a neglected part of the computerization of the comparative method. The computer programs developed by Frantz (1970), Hewson (1974), and Wimbish (1989) require the alignments to be specified in their input. The Reconstruction Engine of Lowe and Mazaudon (1994) requires the linguist to specify hypothetical sound changes and canonical syllable structure. The cognateness tester of Guy (1994) ignores the order of segments, matching any segment in one word with any segment in the other. This paper presents a guided search algorithm for finding the best alignment of one word with another, where both words are given in a broad phonetic transcription. * Artificial Intelligence Center, The University of Georgia, Athens, Georgia 30602-7415. E-mail: mcovingt@ai.uga.edu © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Numbe</context>
</contexts>
<marker>Lowe, Mazaudon, 1994</marker>
<rawString>Lowe, John B. and Martine Mazaudon. 1994. The reconstruction engine: A computer implementation of the comparative method. Computational Linguistics, 20:381-417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald A Ringe</author>
</authors>
<title>On Calculating the Factor of Chance in Language Comparison.</title>
<date>1992</date>
<publisher>American Philosophical Society,</publisher>
<location>Philadelphia.</location>
<contexts>
<context position="13083" citStr="Ringe 1992" startWordPosition="2258" endWordPosition="2259"> talk. The aligner &apos;s only job is to line up words to maximize phonetic similarity. In the absence of known sound correspondences, it can do no more. Its purpose is to simulate a linguist&apos;s first look at unfamiliar data. Linguistic research is a bootstrapping process in which data leads to analysis and analysis leads to more and better-interpreted data. In its present form, the aligner does not participate in this process. 5. Results on Actual Data Tables 3 to 10 show how the aligner performed on 82 cognate pairs in various languages. (Tables 5-8 are loosely based on the Swadesh word lists of Ringe 1992.) 3 To briefly address Ringe&apos;s main point: if the &amp;quot;best&amp;quot; alignment of a pair of words is used, the likelihood of finding a chance similarity is much higher than when using a fixed, canonical alignment. 487 Computational Linguistics Volume 22, Number 4 Table 3 Alignments obtained with test set of Spanish-French cognate pairs. yo : je &apos;I&apos; yo tu : tu &apos;you&apos; 2 a nosotros : nous &apos;you&apos; tu quien : qui &apos;who?&apos; t que: quoi &apos;what?&apos; nosotros todos : tous &apos;all&apos; nu una : une &apos;one&apos; (f.sg.) kyen dos : deux &apos;two&apos; k i - - tres : troix &apos;three&apos; k - e hombre : homme &apos;man&apos; kw a t odo s tu- - - u n a Un - dos d - tr</context>
</contexts>
<marker>Ringe, 1992</marker>
<rawString>Ringe, Donald A., Jr. 1992. On Calculating the Factor of Chance in Language Comparison. American Philosophical Society, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Sankoff</author>
<author>Joseph B Kruskal</author>
<author>editors</author>
</authors>
<date>1983</date>
<booktitle>Time Warps, String Edits, and Macromolecules: The Theory and Practice of Sequence Comparison.</booktitle>
<publisher>Addison-Wesley,</publisher>
<location>Reading, MA.</location>
<marker>Sankoff, Kruskal, editors, 1983</marker>
<rawString>Sankoff, David and Joseph B. Kruskal, editors. 1983. Time Warps, String Edits, and Macromolecules: The Theory and Practice of Sequence Comparison. Addison-Wesley, Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esko Ukkonen</author>
</authors>
<title>Algorithms for approximate string matching.</title>
<date>1985</date>
<journal>Information and Control,</journal>
<pages>64--100</pages>
<contexts>
<context position="3185" citStr="Ukkonen 1985" startWordPosition="508" endWordPosition="509"> prototype implementation has been built in Prolog and tested on a corpus of 82 known cognate pairs from various languages. Somewhat surprisingly, it needs little or no knowledge of phonology beyond the distinction between vowels, consonants, and glides. 2. Alignments If the two words to be aligned are identical, the task of aligning them is trivial. In all other cases, the problem is one of inexact string matching, i.e., finding the alignment that minimizes the difference between the two words. A dynamic programming algorithm for inexact string matching is well known (Sankoff &amp; Kruskal 1983, Ukkonen 1985, Waterman 1995), but I do not use it, for several reasons. First, the strings being aligned are relatively short, so the efficiency of dynamic programming on long strings is not needed. Second, dynamic programming normally gives only one alignment for each pair of strings, but comparative reconstruction may need the n best alternatives, or all that meet some criterion. Third, the tree search algorithm lends itself to modification for special handling of metathesis or assimilation. More about this later; first I need to sketch what the aligner is supposed to accomplish. An alignment can be vie</context>
</contexts>
<marker>Ukkonen, 1985</marker>
<rawString>Ukkonen, Esko. 1985. Algorithms for approximate string matching. Information and Control, 64:100-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael S Waterman</author>
</authors>
<title>Introduction to Computational Biology: Maps, Sequences and Genomes.</title>
<date>1995</date>
<publisher>Chapman &amp; Hall,</publisher>
<location>London.</location>
<contexts>
<context position="3201" citStr="Waterman 1995" startWordPosition="510" endWordPosition="511">lementation has been built in Prolog and tested on a corpus of 82 known cognate pairs from various languages. Somewhat surprisingly, it needs little or no knowledge of phonology beyond the distinction between vowels, consonants, and glides. 2. Alignments If the two words to be aligned are identical, the task of aligning them is trivial. In all other cases, the problem is one of inexact string matching, i.e., finding the alignment that minimizes the difference between the two words. A dynamic programming algorithm for inexact string matching is well known (Sankoff &amp; Kruskal 1983, Ukkonen 1985, Waterman 1995), but I do not use it, for several reasons. First, the strings being aligned are relatively short, so the efficiency of dynamic programming on long strings is not needed. Second, dynamic programming normally gives only one alignment for each pair of strings, but comparative reconstruction may need the n best alternatives, or all that meet some criterion. Third, the tree search algorithm lends itself to modification for special handling of metathesis or assimilation. More about this later; first I need to sketch what the aligner is supposed to accomplish. An alignment can be viewed as a way of </context>
<context position="20128" citStr="Waterman 1995" startWordPosition="3481" endWordPosition="3482"> i 1 - is the etymologically correct three-way alignment of the masculine singular definite article in Spanish, French, and Italian. Multilateral alignments can be generated by aligning the second word with the first, then the third word with the second (and implicitly also the first), and so on, but it would be advantageous to apply the evaluation metric to the whole set rather than just the pairs that are chained together. Multilateral alignment is also an important problem in DNA sequence analysis, and no general algorithm for it is known, but research is proceeding apace (Kececioglu 1993, Waterman 1995). 491 Computational Linguistics Volume 22, Number 4 Table 7 Alignments obtained with test set of English-Latin cognate pairs. and : ante at : ad blow :flare ear : auris eat : edere fish : piscis flow :fluere star : stela full : pltnus grass : gra-men heart : cordis (gen.) horn : coma I: ego wndante wt ad bl--ow= flarei-r-- awris iyt--- e-dere ---fi§ pi skis flow--- fl-uere star-- stella -ful p1 nus gr--ws gramen har--t kordis hornkorna --ay egof - - - i § pi skis f---ul p1 nus grw--s gramen hart-- kordis f i - - - § piskis grws - - gr amen f i §- - - pi skis 7. From Here to the Comparative Met</context>
</contexts>
<marker>Waterman, 1995</marker>
<rawString>Waterman, Michael S. 1995. Introduction to Computational Biology: Maps, Sequences and Genomes. Chapman &amp; Hall, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Wimbish</author>
</authors>
<title>WORDSURV: A program for analyzing language survey word lists. Summer Institute of Linguistics, Dallas. Cited by Lowe and Mazaudon.</title>
<date>1989</date>
<contexts>
<context position="1691" citStr="Wimbish (1989)" startWordPosition="276" endWordPosition="277">f each word that appear to correspond. This alignment step is not necessarily trivial. For example, the correct alignment of Latin da with Greek dickimi is --do-- didomi and not do---- d - - - - ----do didomi dido i di domi or numerous other possibilities. The segments of two words may be misaligned because of affixes (living or fossilized), reduplication, and sound changes that alter the number of segments, such as elision or monophthongization. Alignment is a neglected part of the computerization of the comparative method. The computer programs developed by Frantz (1970), Hewson (1974), and Wimbish (1989) require the alignments to be specified in their input. The Reconstruction Engine of Lowe and Mazaudon (1994) requires the linguist to specify hypothetical sound changes and canonical syllable structure. The cognateness tester of Guy (1994) ignores the order of segments, matching any segment in one word with any segment in the other. This paper presents a guided search algorithm for finding the best alignment of one word with another, where both words are given in a broad phonetic transcription. * Artificial Intelligence Center, The University of Georgia, Athens, Georgia 30602-7415. E-mail: mc</context>
</contexts>
<marker>Wimbish, 1989</marker>
<rawString>Wimbish, John S. 1989. WORDSURV: A program for analyzing language survey word lists. Summer Institute of Linguistics, Dallas. Cited by Lowe and Mazaudon. 1994.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>