<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.140451">
<title confidence="0.995438">
Shallow Semantic Parsing for Spoken Language Understanding
</title>
<author confidence="0.995067">
Bonaventura Coppola and Alessandro Moschitti and Giuseppe Riccardi
</author>
<affiliation confidence="0.997595">
Department of Information Engineering and Computer Science - University of Trento, Italy
</affiliation>
<email confidence="0.972455">
icoppola,moschitti,riccardil@disi.unitn.it
</email>
<sectionHeader confidence="0.994127" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.978443090909091">
Most Spoken Dialog Systems are based on
speech grammars and frame/slot semantics.
The semantic descriptions of input utterances
are usually defined ad-hoc with no ability to
generalize beyond the target application do-
main or to learn from annotated corpora. The
approach we propose in this paper exploits
machine learning of frame semantics, bor-
rowing its theoretical model from computa-
tional linguistics. While traditional automatic
Semantic Role Labeling approaches on writ-
ten texts may not perform as well on spo-
ken dialogs, we show successful experiments
on such porting. Hence, we design and eval-
uate automatic FrameNet-based parsers both
for English written texts and for Italian dia-
log utterances. The results show that disflu-
encies of dialog data do not severely hurt per-
formance. Also, a small set of FrameNet-like
manual annotations is enough for realizing ac-
curate Semantic Role Labeling on the target
domains of typical Dialog Systems.
</bodyText>
<sectionHeader confidence="0.998987" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999438733333333">
Commercial services based on spoken dialog sys-
tems have consistently increased both in number and
in application scenarios (Gorin et al., 1997). De-
spite its success, current Spoken Language Under-
standing (SLU) technology is mainly based on sim-
ple conceptual annotation, where just very simple
semantic composition is attempted. In contrast, the
availability of richer semantic models as FrameNet
(Baker et al., 1998) is very appealing for the de-
sign of better dialog managers. The first step to en-
able the exploitation of frame semantics is to show
that accurate automatic semantic labelers can be de-
signed for processing conversational speech.
In this paper, we face the problem of perform-
ing shallow semantic analysis of speech transcrip-
</bodyText>
<page confidence="0.996372">
85
</page>
<bodyText confidence="0.999863">
tions from real-world dialogs. In particular, we ap-
ply Support Vector Machines (SVMs) and Kernel
Methods to the design of a semantic role labeler
(SRL) based on FrameNet. Exploiting Tree Kernels
(Collins and Duffy, 2002; Moschitti et al., 2008), we
can quickly port our system to different languages
and domains. In the experiments, we compare
results achieved on the English FrameNet against
those achieved on a smaller Italian FrameNet-like
corpus of spoken dialog transcriptions. They show
that the system is robust enough to disfluencies and
noise, and that it can be easily ported to new do-
mains and languages.
In the remainder of the paper, Section 2 presents
our basic Semantic Role Labeling approach, Sec-
tion 3 describes the experiments on the English
FrameNet and on our Italian dialog corpus, and Sec-
tion 4 draws the conclusions.
</bodyText>
<sectionHeader confidence="0.990175" genericHeader="method">
2 FrameNet-based Semantic Role Labeling
</sectionHeader>
<bodyText confidence="0.991104631578947">
Semantic frames represent prototypical events or
situations which individually define their own set
of actors, or frame participants. For example,
the COMMERCE SCENARIO frame includes partic-
ipants as SELLER, BUYER, GOODS, and MONEY.
The task of FrameNet-based shallow semantic pars-
ing can be implemented as a combination of multi-
ple specialized semantic labelers as those in (Car-
reras and M`arquez, 2005), one for each frame.
Therefore, the general semantic parsing work-flow
includes 4 main steps: (i) Target Word Detec-
tion, where the semantically relevant words bringing
predicative information (the frame targets) are de-
tected, e.g. the verb to purchase for the above exam-
ple; (ii) Frame Disambiguation, where the correct
frame for every target word (which may be ambigu-
ous) is determined, e.g. COMMERCE SCENARIO;
(iii) Boundary Detection (BD), where the sequences
of words realizing the frame elements (or predicate
</bodyText>
<subsubsectionHeader confidence="0.832642">
Proceedings of NAACL HLT 2009: Short Papers, pages 85–88,
</subsubsectionHeader>
<bodyText confidence="0.964540454545455">
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
arguments) are detected; and (iv) Role Classification
(RC) (or argument classification), which assigns se-
mantic labels to the frame elements detected in the
previous step, e.g. GOODS. Therefore, we imple-
ment the full task of FrameNet-based parsing by a
combination of multiple specialized SRL-like label-
ers, one for each frame (Coppola et al., 2008). For
the design of each single labeler, we use the state-of-
the-art strategy developed in (Pradhan et al., 2005;
Moschitti et al., 2008).
</bodyText>
<subsectionHeader confidence="0.995721">
2.1 Standard versus Structural Features
</subsectionHeader>
<bodyText confidence="0.99987465">
In machine learning tasks, the manual engineering
of effective features is a complex and time con-
suming process. For this reason, our SVM-based
SRL approach exploits the combination of two dif-
ferent models. We first used Polynomial Kernels
over handcrafted, linguistically-motivated, “stan-
dard” SRL features (Gildea and Jurafsky, 2002;
Pradhan et al., 2005; Xue and Palmer, 2004).
Nonetheless, since we aim at modeling an SRL sys-
tem for a new language (Italian) and a new domain
(dialog transcriptions), the above features may re-
sult ineffective. Thus, to achieve independence on
the application domain, we exploited Tree Kernels
(Collins and Duffy, 2002) over automatic structural
features proposed in (Moschitti et al., 2005; Mos-
chitti et al., 2008). These are complementary to stan-
dard features and are obtained by applying Tree Ker-
nels (Collins and Duffy, 2002; Moschitti et al., 2008)
to basic tree structures expressing the syntactic rela-
tion between arguments and predicates.
</bodyText>
<sectionHeader confidence="0.999272" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999964111111111">
Our purpose is to show that an accurate automatic
FrameNet parser can be designed with reasonable
effort for Italian conversational speech. For this pur-
pose, we designed and evaluated both a semantic
parser for the English FrameNet (Section 3.1) and
one for a corpus of Italian spoken dialogs (Section
3.2). The accuracy of the latter and its comparison
against the former can provide evidence to sustain
out thesis or not.
</bodyText>
<subsectionHeader confidence="0.999433">
3.1 Evaluation on the English FrameNet
</subsectionHeader>
<bodyText confidence="0.999991846153846">
In this experiment we trained and tested boundary
detectors (BD) and role classifiers (RC) as described
in Section 2. More in detail, (a) we trained 5 BDs
according to the syntactic categories of the possi-
ble target predicates, namely nouns, verbs, adjec-
tives, adverbs and prepositions; (b) we trained 782
one-versus-all multi-role classifiers RC, one for each
available frame and predicate syntactic category, for
a total of 5,345 binary classifiers; and (c) we ap-
plied the above models for recognizing predicate ar-
guments and their associated semantic labels in sen-
tences, where the frame label and the target predi-
cate were considered as given.
</bodyText>
<subsectionHeader confidence="0.830745">
3.1.1 Data Set
</subsectionHeader>
<bodyText confidence="0.999957166666667">
We exploited the FrameNet 1.3 data base. After
preprocessing and parsing the sentences with Char-
niak’s parser, we obtained 135,293 semantically-
annotated and syntactically-parsed sentences.
The above dataset was partitioned into three sub-
sets: 2% of data (2,782 sentences) for training the
BDs, 90% (121,798 sentences) for training RC, and
1% (1,345 sentences) as test set. The remaining data
were discarded. Accordingly, the number of pos-
itive and negative training examples for BD were:
2,764 positive and 37,497 negative examples for ver-
bal, 1,189 and 35,576 for nominal, 615 and 14,544
for adjectival, 0 and 40 for adverbial, and 7 and 177
for prepositional predicates (for a total of 4,575 and
87,834). For RC, the total numbers were 207,662
and 1,960,423, which divided by the number of role
types show the average number of 39 positive versus
367 negative examples per role label.
</bodyText>
<sectionHeader confidence="0.934889" genericHeader="method">
3.1.2 Results
</sectionHeader>
<bodyText confidence="0.999767375">
We tested several kernels over standard fea-
tures (Gildea and Jurafsky, 2002; Pradhan et al.,
2005) and structured features (Moschitti et al.,
2008): the Polynomial Kernel (PK, with a degree of
3), the Tree Kernel (TK) and its combination with
the bag of word kernel on the tree leaves (TKL).
Also, the combinations PK+TK and PK+TKL were
tested.
The 4 rows of Table 1 report the performance of
different classification tasks. They show in turn: (1)
the “pure” performance of the BD classifiers, i.e.
considering correct the classification decisions also
when a correctly classified tree node does not ex-
actly correspond to its argument’s word boundaries.
Such mismatch frequently happens when the parse
tree (which is automatically generated) contains in-
</bodyText>
<page confidence="0.978923">
86
</page>
<table confidence="0.999759666666667">
Eval sett. P PK F1 P TK F1 P PK+TK F1 P TKL F1 P PK+TKL
R R R R R F1
BD .887 .675 .767 .949 .652 .773 .915 .698 .792 .938 .659 .774 .908 .701 .791
BD pj .850 .647 .735 .919 .631 .748 .875 .668 .758 .906 .636 .747 .868 .670 .757
BD+RC .654 .498 .565 .697 .479 .568 .680 .519 .588 .689 .484 .569 .675 .521 .588
BD+RC pj .625 .476 .540 .672 .462 .548 .648 .495 .561 .663 .466 .547 .644 .497 .561
</table>
<tableCaption confidence="0.9581785">
Table 1: Results on FrameNet dataset: Polynomial Kernel, two different Tree Kernels, and their combinations (see
Section 3.1.2) with 2% training for BD and 90% for RC.
</tableCaption>
<bodyText confidence="0.9911658">
correct node attachments; (2) the real performance
of the BD classification when actually “projected”
(“pj”) on the tree leaves, i.e. when matching not
only the constituent node as in 1, but also exactly
matching the selected words (leaves) with those in
the FrameNet gold standard. This also implies the
exact automatic syntactic analysis for the subtree;
(3) the same as in (1), with the argument role classi-
fication (RC) also performed (frame element labels
must also match); (4) the same as in (2), with RC
also performed. For each classification task, the Pre-
cision, Recall and F1 measure achieved by means
of different kernel combinations are shown in the
columns of the table. Only for the best configuration
in Table 1 (PK+TK, results in bold) the amount of
training data for the BD model was increased from
2% to 90%, resulting in a popular splitting for this
task(Erk and Pado, 2006). Results are shown in Ta-
ble 2: the PK+TK kernel achieves 1.0 Precision,
0.732 Recall, and 0.847 F1. These figures can be
compared to 0.855 Precision, 0.669 Recall and 0.751
F1 of the system described in (Erk and Pado, 2006)
and trained over the same amount of data. In con-
clusion, our best learning scheme is currently capa-
ble of tagging FrameNet data with exact boundaries
and role labels at 63% F1. Our next steps will be (1)
further improving the RC models using FrameNet-
specific information (such as Frame and role inheri-
tance), and (2) introducing an effective Frame clas-
sifier to automatically choose Frame labels.
</bodyText>
<table confidence="0.992609">
Enhanced PK+TK
Eval Setting P R Fl
BD (nodes) 1.0 .732 .847
BD (words) .963 .702 .813
BD+RC (nodes) .784 .571 .661
BD+RC (words) .747 .545 .630
</table>
<tableCaption confidence="0.995764">
Table 2: Results on the FrameNet dataset. Best configu-
ration from Table 1, raised to 90% of training data for BD
and RC.
</tableCaption>
<table confidence="0.999815857142857">
Eval Setting P R F1 P R F1
PK
BD - - - .900 .869 .884
BD+RC - - - .769 .742 .756
TK PK+TK
BD .887 .856 .871 .905 .873 .889
BD+RC .765 .738 .751 .774 .747 .760
</table>
<tableCaption confidence="0.9926125">
Table 3: Experiment Results on the Italian dialog corpus
for different learning schemes and kernel combinations.
</tableCaption>
<subsectionHeader confidence="0.999662">
3.2 Evaluation on Italian Spoken Dialogs
</subsectionHeader>
<bodyText confidence="0.999963">
In this section, we present the results of BD and RC
of our FrameNet parser on the smaller Italian spoken
dialog corpus. We assume here as well that the target
word (i.e. the predicate for which arguments have to
be extracted) along with the correct frame are given.
</bodyText>
<subsectionHeader confidence="0.957936">
3.2.1 Data Set
</subsectionHeader>
<bodyText confidence="0.997778909090909">
The Italian dialog corpus includes 50 real human-
human dialogs recorded and manually transcribed at
the call center of the help-desk facility of an Ital-
ian Consortium for Information Systems. The di-
alogs are fluent and spontaneous conversations be-
tween a caller and an operator, concerning hard-
ware and software problems. The dialog turns con-
tain 1,677 annotated frame instances spanning 154
FrameNet frames and 20 new ad hoc frames spe-
cific for the domain. New frames mostly con-
cern data processing such as NAVIGATION, DIS-
PLAY DATA, LOSE DATA, CREATE DATA. Being
intended as a reference resource, this dataset in-
cludes partially human-validated syntactic analysis,
i.e. lower branches corrected to fit arguments. We
divided such dataset into 90% training (1,521 frame
instances) and 10% testing (156 frame instances).
Each frame instance brings its own set of frame par-
ticipant (or predicate argument) instances.
For BD, the very same approach as in Section 3.1
was followed. For RC, we also followed the same
approach but, in order to cope with data sparse-
</bodyText>
<page confidence="0.997548">
87
</page>
<bodyText confidence="0.999984">
ness, we also attempted a different RC strategy by
merging data related to different syntactic predicates
within the same frame. So, within each frame, we
merged data related to verbal predicates, nominal
predicates, and so on. Due to the short space avail-
able, we will just report results for this latter ap-
proach, which performed sensitively better.
</bodyText>
<sectionHeader confidence="0.935618" genericHeader="evaluation">
3.2.2 Results
</sectionHeader>
<bodyText confidence="0.9999905">
The results are reported in Table 3. Each ta-
ble block shows Precision, Recall and F1 for ei-
ther PK, TK, or PK+TK. The rows marked as BD
show the results for the task of marking the exact
constituent boundaries of every frame element (ar-
gument) found. The rows marked as BD+RC show
the results for the two-stage pipeline of both marking
the exact constituent boundaries and also assigning
the correct semantic label. A few observations hold.
First, the highest F1 has been achieved using the
PK+TK combination. On this concern, we under-
line that kernel combinations always gave the best
performance in any experiment we run.
Second, we emphasize that the F1 of PK is sur-
prisingly high, since it exploits the set of standard
SRL feature (Gildea and Jurafsky, 2002; Pradhan
et al., 2005), originally developed for English and
left unmodified for Italian. Nonetheless, their per-
formance is comparable to the Tree Kernels and,
as we said, their combination improves the result.
Concerning the structured features exploited by Tree
Kernels, we note that they work as well without any
tuning when ported to Italian dialogs.
Finally, the achieved F1 is extremely good. In
fact, our corresponding result on the FrameNet cor-
pus (Table 2) is P=0.784, R=0.571, F1=0.661,
where the corpus contains much more data, its sen-
tences come from a standard written text (no dis-
fluencies are present) and it is in English language,
which is morphologically simpler than Italian. On
the other hand, the Italian corpus includes optimal
syntactic annotation which exactly fits the frame se-
mantics, and the number of frames is lower than in
the FrameNet experiment.
</bodyText>
<sectionHeader confidence="0.999726" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999952666666667">
The good performance achieved for Italian dialogs
shows that FrameNet-based parsing is viable for la-
beling conversational speech in any language us-
ing a few training data. Moreover, the approach
works well for very specific domains, like help-
desk/customer conversations. Nonetheless, addi-
tional tests based on fully automatic transcription
and syntactic parsing are needed. However, our cur-
rent results show that future research on complex
spoken dialog systems is enabled to exploit automat-
ically generated frame semantics, which is our very
direction.
</bodyText>
<sectionHeader confidence="0.998278" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999278">
The authors wish to thank Daniele Pighin for the SRL subsys-
tem and Sara Tonelli for the Italian corpus. This work has been
partially funded by the European Commission - LUNA project
(contract n.33549), and by the Marie Curie Excellence Grant
for the ADAMACH project (contract n.022593).
</bodyText>
<sectionHeader confidence="0.999441" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999470727272727">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet project. In Proceed-
ings of COLING-ACL ’98, pages 86–90.
Xavier Carreras and Llu´ıs M`arquez. 2005. Introduction
to the CoNLL-2005 Shared Task: Semantic Role La-
beling. In Proceedings of CoNLL-2005.
Michael Collins and Nigel Duffy. 2002. New Ranking
Algorithms for Parsing and Tagging: Kernels over Dis-
crete structures, and the voted perceptron. In ACL02.
Bonaventura Coppola, Alessandro Moschitti, and
Daniele Pighin. 2008. Generalized framework for
syntax-based relation mining. In IEEE-ICDM 2008.
Katrin Erk and Sebastian Pado. 2006. Shalmaneser - a
flexible toolbox for semantic role assignment. In Pro-
ceedings of LREC 2006, Genoa, Italy.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic La-
beling of Semantic Roles. Computational Linguistics.
A. L. Gorin, G. Riccardi, and J. H. Wright. 1997. How
may i help you? Speech Communication.
Alessandro Moschitti, Bonaventura Coppola, Daniele
Pighin, and Roberto Basili. 2005. Engineering of syn-
tactic features for shallow semantic parsing. In ACL
WS on Feature Engineering for ML in NLP.
Alessandro Moschitti, Daniele Pighin, and Roberto
Basili. 2008. Tree kernels for semantic role labeling.
Computational Linguistics, 34(2):193–224.
Sameer Pradhan, Kadri Hacioglu, Valerie Krugler,
Wayne Ward, James H. Martin, and Daniel Jurafsky.
2005. Support Vector Learning for Semantic Argu-
ment Classification. Machine Learning.
Nianwen Xue and Martha Palmer. 2004. Calibrating
features for semantic role labeling. In Proceedings of
EMNLP 2004.
</reference>
<page confidence="0.999403">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.952460">
<title confidence="0.999384">Shallow Semantic Parsing for Spoken Language Understanding</title>
<author confidence="0.998743">Coppola Moschitti</author>
<affiliation confidence="0.996576">Department of Information Engineering and Computer Science - University of Trento, Italy</affiliation>
<email confidence="0.996268">icoppola,moschitti,riccardil@disi.unitn.it</email>
<abstract confidence="0.998282608695652">Most Spoken Dialog Systems are based on speech grammars and frame/slot semantics. The semantic descriptions of input utterances are usually defined ad-hoc with no ability to generalize beyond the target application domain or to learn from annotated corpora. The approach we propose in this paper exploits machine learning of frame semantics, borrowing its theoretical model from computational linguistics. While traditional automatic Semantic Role Labeling approaches on written texts may not perform as well on spoken dialogs, we show successful experiments on such porting. Hence, we design and evaluate automatic FrameNet-based parsers both for English written texts and for Italian dialog utterances. The results show that disfluencies of dialog data do not severely hurt performance. Also, a small set of FrameNet-like manual annotations is enough for realizing accurate Semantic Role Labeling on the target domains of typical Dialog Systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL ’98,</booktitle>
<pages>86--90</pages>
<contexts>
<context position="1646" citStr="Baker et al., 1998" startWordPosition="238" endWordPosition="241">t severely hurt performance. Also, a small set of FrameNet-like manual annotations is enough for realizing accurate Semantic Role Labeling on the target domains of typical Dialog Systems. 1 Introduction Commercial services based on spoken dialog systems have consistently increased both in number and in application scenarios (Gorin et al., 1997). Despite its success, current Spoken Language Understanding (SLU) technology is mainly based on simple conceptual annotation, where just very simple semantic composition is attempted. In contrast, the availability of richer semantic models as FrameNet (Baker et al., 1998) is very appealing for the design of better dialog managers. The first step to enable the exploitation of frame semantics is to show that accurate automatic semantic labelers can be designed for processing conversational speech. In this paper, we face the problem of performing shallow semantic analysis of speech transcrip85 tions from real-world dialogs. In particular, we apply Support Vector Machines (SVMs) and Kernel Methods to the design of a semantic role labeler (SRL) based on FrameNet. Exploiting Tree Kernels (Collins and Duffy, 2002; Moschitti et al., 2008), we can quickly port our syst</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In Proceedings of COLING-ACL ’98, pages 86–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Llu´ıs M`arquez</author>
</authors>
<title>Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of CoNLL-2005.</booktitle>
<marker>Carreras, M`arquez, 2005</marker>
<rawString>Xavier Carreras and Llu´ıs M`arquez. 2005. Introduction to the CoNLL-2005 Shared Task: Semantic Role Labeling. In Proceedings of CoNLL-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete structures, and the voted perceptron.</title>
<date>2002</date>
<booktitle>In ACL02.</booktitle>
<contexts>
<context position="2191" citStr="Collins and Duffy, 2002" startWordPosition="328" endWordPosition="331">t, the availability of richer semantic models as FrameNet (Baker et al., 1998) is very appealing for the design of better dialog managers. The first step to enable the exploitation of frame semantics is to show that accurate automatic semantic labelers can be designed for processing conversational speech. In this paper, we face the problem of performing shallow semantic analysis of speech transcrip85 tions from real-world dialogs. In particular, we apply Support Vector Machines (SVMs) and Kernel Methods to the design of a semantic role labeler (SRL) based on FrameNet. Exploiting Tree Kernels (Collins and Duffy, 2002; Moschitti et al., 2008), we can quickly port our system to different languages and domains. In the experiments, we compare results achieved on the English FrameNet against those achieved on a smaller Italian FrameNet-like corpus of spoken dialog transcriptions. They show that the system is robust enough to disfluencies and noise, and that it can be easily ported to new domains and languages. In the remainder of the paper, Section 2 presents our basic Semantic Role Labeling approach, Section 3 describes the experiments on the English FrameNet and on our Italian dialog corpus, and Section 4 dr</context>
<context position="5091" citStr="Collins and Duffy, 2002" startWordPosition="776" endWordPosition="779">manual engineering of effective features is a complex and time consuming process. For this reason, our SVM-based SRL approach exploits the combination of two different models. We first used Polynomial Kernels over handcrafted, linguistically-motivated, “standard” SRL features (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). Nonetheless, since we aim at modeling an SRL system for a new language (Italian) and a new domain (dialog transcriptions), the above features may result ineffective. Thus, to achieve independence on the application domain, we exploited Tree Kernels (Collins and Duffy, 2002) over automatic structural features proposed in (Moschitti et al., 2005; Moschitti et al., 2008). These are complementary to standard features and are obtained by applying Tree Kernels (Collins and Duffy, 2002; Moschitti et al., 2008) to basic tree structures expressing the syntactic relation between arguments and predicates. 3 Experiments Our purpose is to show that an accurate automatic FrameNet parser can be designed with reasonable effort for Italian conversational speech. For this purpose, we designed and evaluated both a semantic parser for the English FrameNet (Section 3.1) and one for </context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>Michael Collins and Nigel Duffy. 2002. New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete structures, and the voted perceptron. In ACL02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonaventura Coppola</author>
<author>Alessandro Moschitti</author>
<author>Daniele Pighin</author>
</authors>
<title>Generalized framework for syntax-based relation mining.</title>
<date>2008</date>
<booktitle>In IEEE-ICDM</booktitle>
<contexts>
<context position="4258" citStr="Coppola et al., 2008" startWordPosition="647" endWordPosition="650">rmined, e.g. COMMERCE SCENARIO; (iii) Boundary Detection (BD), where the sequences of words realizing the frame elements (or predicate Proceedings of NAACL HLT 2009: Short Papers, pages 85–88, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics arguments) are detected; and (iv) Role Classification (RC) (or argument classification), which assigns semantic labels to the frame elements detected in the previous step, e.g. GOODS. Therefore, we implement the full task of FrameNet-based parsing by a combination of multiple specialized SRL-like labelers, one for each frame (Coppola et al., 2008). For the design of each single labeler, we use the state-ofthe-art strategy developed in (Pradhan et al., 2005; Moschitti et al., 2008). 2.1 Standard versus Structural Features In machine learning tasks, the manual engineering of effective features is a complex and time consuming process. For this reason, our SVM-based SRL approach exploits the combination of two different models. We first used Polynomial Kernels over handcrafted, linguistically-motivated, “standard” SRL features (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). Nonetheless, since we aim at modeling an </context>
</contexts>
<marker>Coppola, Moschitti, Pighin, 2008</marker>
<rawString>Bonaventura Coppola, Alessandro Moschitti, and Daniele Pighin. 2008. Generalized framework for syntax-based relation mining. In IEEE-ICDM 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pado</author>
</authors>
<title>Shalmaneser - a flexible toolbox for semantic role assignment.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC 2006,</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="9670" citStr="Erk and Pado, 2006" startWordPosition="1544" endWordPosition="1547">tandard. This also implies the exact automatic syntactic analysis for the subtree; (3) the same as in (1), with the argument role classification (RC) also performed (frame element labels must also match); (4) the same as in (2), with RC also performed. For each classification task, the Precision, Recall and F1 measure achieved by means of different kernel combinations are shown in the columns of the table. Only for the best configuration in Table 1 (PK+TK, results in bold) the amount of training data for the BD model was increased from 2% to 90%, resulting in a popular splitting for this task(Erk and Pado, 2006). Results are shown in Table 2: the PK+TK kernel achieves 1.0 Precision, 0.732 Recall, and 0.847 F1. These figures can be compared to 0.855 Precision, 0.669 Recall and 0.751 F1 of the system described in (Erk and Pado, 2006) and trained over the same amount of data. In conclusion, our best learning scheme is currently capable of tagging FrameNet data with exact boundaries and role labels at 63% F1. Our next steps will be (1) further improving the RC models using FrameNetspecific information (such as Frame and role inheritance), and (2) introducing an effective Frame classifier to automatically</context>
</contexts>
<marker>Erk, Pado, 2006</marker>
<rawString>Katrin Erk and Sebastian Pado. 2006. Shalmaneser - a flexible toolbox for semantic role assignment. In Proceedings of LREC 2006, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles.</title>
<date>2002</date>
<journal>Computational</journal>
<contexts>
<context position="4770" citStr="Gildea and Jurafsky, 2002" startWordPosition="724" endWordPosition="727">sed parsing by a combination of multiple specialized SRL-like labelers, one for each frame (Coppola et al., 2008). For the design of each single labeler, we use the state-ofthe-art strategy developed in (Pradhan et al., 2005; Moschitti et al., 2008). 2.1 Standard versus Structural Features In machine learning tasks, the manual engineering of effective features is a complex and time consuming process. For this reason, our SVM-based SRL approach exploits the combination of two different models. We first used Polynomial Kernels over handcrafted, linguistically-motivated, “standard” SRL features (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). Nonetheless, since we aim at modeling an SRL system for a new language (Italian) and a new domain (dialog transcriptions), the above features may result ineffective. Thus, to achieve independence on the application domain, we exploited Tree Kernels (Collins and Duffy, 2002) over automatic structural features proposed in (Moschitti et al., 2005; Moschitti et al., 2008). These are complementary to standard features and are obtained by applying Tree Kernels (Collins and Duffy, 2002; Moschitti et al., 2008) to basic tree structures expressing the synt</context>
<context position="7535" citStr="Gildea and Jurafsky, 2002" startWordPosition="1169" endWordPosition="1172">ntences) as test set. The remaining data were discarded. Accordingly, the number of positive and negative training examples for BD were: 2,764 positive and 37,497 negative examples for verbal, 1,189 and 35,576 for nominal, 615 and 14,544 for adjectival, 0 and 40 for adverbial, and 7 and 177 for prepositional predicates (for a total of 4,575 and 87,834). For RC, the total numbers were 207,662 and 1,960,423, which divided by the number of role types show the average number of 39 positive versus 367 negative examples per role label. 3.1.2 Results We tested several kernels over standard features (Gildea and Jurafsky, 2002; Pradhan et al., 2005) and structured features (Moschitti et al., 2008): the Polynomial Kernel (PK, with a degree of 3), the Tree Kernel (TK) and its combination with the bag of word kernel on the tree leaves (TKL). Also, the combinations PK+TK and PK+TKL were tested. The 4 rows of Table 1 report the performance of different classification tasks. They show in turn: (1) the “pure” performance of the BD classifiers, i.e. considering correct the classification decisions also when a correctly classified tree node does not exactly correspond to its argument’s word boundaries. Such mismatch frequen</context>
<context position="13339" citStr="Gildea and Jurafsky, 2002" startWordPosition="2177" endWordPosition="2180">show the results for the task of marking the exact constituent boundaries of every frame element (argument) found. The rows marked as BD+RC show the results for the two-stage pipeline of both marking the exact constituent boundaries and also assigning the correct semantic label. A few observations hold. First, the highest F1 has been achieved using the PK+TK combination. On this concern, we underline that kernel combinations always gave the best performance in any experiment we run. Second, we emphasize that the F1 of PK is surprisingly high, since it exploits the set of standard SRL feature (Gildea and Jurafsky, 2002; Pradhan et al., 2005), originally developed for English and left unmodified for Italian. Nonetheless, their performance is comparable to the Tree Kernels and, as we said, their combination improves the result. Concerning the structured features exploited by Tree Kernels, we note that they work as well without any tuning when ported to Italian dialogs. Finally, the achieved F1 is extremely good. In fact, our corresponding result on the FrameNet corpus (Table 2) is P=0.784, R=0.571, F1=0.661, where the corpus contains much more data, its sentences come from a standard written text (no disfluen</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic Labeling of Semantic Roles. Computational Linguistics. A. L. Gorin, G. Riccardi, and J. H. Wright. 1997. How may i help you? Speech Communication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Bonaventura Coppola</author>
<author>Daniele Pighin</author>
<author>Roberto Basili</author>
</authors>
<title>Engineering of syntactic features for shallow semantic parsing.</title>
<date>2005</date>
<booktitle>In ACL WS on Feature Engineering for ML in NLP.</booktitle>
<contexts>
<context position="5162" citStr="Moschitti et al., 2005" startWordPosition="786" endWordPosition="789">process. For this reason, our SVM-based SRL approach exploits the combination of two different models. We first used Polynomial Kernels over handcrafted, linguistically-motivated, “standard” SRL features (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). Nonetheless, since we aim at modeling an SRL system for a new language (Italian) and a new domain (dialog transcriptions), the above features may result ineffective. Thus, to achieve independence on the application domain, we exploited Tree Kernels (Collins and Duffy, 2002) over automatic structural features proposed in (Moschitti et al., 2005; Moschitti et al., 2008). These are complementary to standard features and are obtained by applying Tree Kernels (Collins and Duffy, 2002; Moschitti et al., 2008) to basic tree structures expressing the syntactic relation between arguments and predicates. 3 Experiments Our purpose is to show that an accurate automatic FrameNet parser can be designed with reasonable effort for Italian conversational speech. For this purpose, we designed and evaluated both a semantic parser for the English FrameNet (Section 3.1) and one for a corpus of Italian spoken dialogs (Section 3.2). The accuracy of the l</context>
</contexts>
<marker>Moschitti, Coppola, Pighin, Basili, 2005</marker>
<rawString>Alessandro Moschitti, Bonaventura Coppola, Daniele Pighin, and Roberto Basili. 2005. Engineering of syntactic features for shallow semantic parsing. In ACL WS on Feature Engineering for ML in NLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Daniele Pighin</author>
<author>Roberto Basili</author>
</authors>
<title>Tree kernels for semantic role labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="2216" citStr="Moschitti et al., 2008" startWordPosition="332" endWordPosition="335">cher semantic models as FrameNet (Baker et al., 1998) is very appealing for the design of better dialog managers. The first step to enable the exploitation of frame semantics is to show that accurate automatic semantic labelers can be designed for processing conversational speech. In this paper, we face the problem of performing shallow semantic analysis of speech transcrip85 tions from real-world dialogs. In particular, we apply Support Vector Machines (SVMs) and Kernel Methods to the design of a semantic role labeler (SRL) based on FrameNet. Exploiting Tree Kernels (Collins and Duffy, 2002; Moschitti et al., 2008), we can quickly port our system to different languages and domains. In the experiments, we compare results achieved on the English FrameNet against those achieved on a smaller Italian FrameNet-like corpus of spoken dialog transcriptions. They show that the system is robust enough to disfluencies and noise, and that it can be easily ported to new domains and languages. In the remainder of the paper, Section 2 presents our basic Semantic Role Labeling approach, Section 3 describes the experiments on the English FrameNet and on our Italian dialog corpus, and Section 4 draws the conclusions. 2 Fr</context>
<context position="4394" citStr="Moschitti et al., 2008" startWordPosition="670" endWordPosition="673"> Proceedings of NAACL HLT 2009: Short Papers, pages 85–88, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics arguments) are detected; and (iv) Role Classification (RC) (or argument classification), which assigns semantic labels to the frame elements detected in the previous step, e.g. GOODS. Therefore, we implement the full task of FrameNet-based parsing by a combination of multiple specialized SRL-like labelers, one for each frame (Coppola et al., 2008). For the design of each single labeler, we use the state-ofthe-art strategy developed in (Pradhan et al., 2005; Moschitti et al., 2008). 2.1 Standard versus Structural Features In machine learning tasks, the manual engineering of effective features is a complex and time consuming process. For this reason, our SVM-based SRL approach exploits the combination of two different models. We first used Polynomial Kernels over handcrafted, linguistically-motivated, “standard” SRL features (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). Nonetheless, since we aim at modeling an SRL system for a new language (Italian) and a new domain (dialog transcriptions), the above features may result ineffective. Thus, to ac</context>
<context position="7607" citStr="Moschitti et al., 2008" startWordPosition="1180" endWordPosition="1183">number of positive and negative training examples for BD were: 2,764 positive and 37,497 negative examples for verbal, 1,189 and 35,576 for nominal, 615 and 14,544 for adjectival, 0 and 40 for adverbial, and 7 and 177 for prepositional predicates (for a total of 4,575 and 87,834). For RC, the total numbers were 207,662 and 1,960,423, which divided by the number of role types show the average number of 39 positive versus 367 negative examples per role label. 3.1.2 Results We tested several kernels over standard features (Gildea and Jurafsky, 2002; Pradhan et al., 2005) and structured features (Moschitti et al., 2008): the Polynomial Kernel (PK, with a degree of 3), the Tree Kernel (TK) and its combination with the bag of word kernel on the tree leaves (TKL). Also, the combinations PK+TK and PK+TKL were tested. The 4 rows of Table 1 report the performance of different classification tasks. They show in turn: (1) the “pure” performance of the BD classifiers, i.e. considering correct the classification decisions also when a correctly classified tree node does not exactly correspond to its argument’s word boundaries. Such mismatch frequently happens when the parse tree (which is automatically generated) conta</context>
</contexts>
<marker>Moschitti, Pighin, Basili, 2008</marker>
<rawString>Alessandro Moschitti, Daniele Pighin, and Roberto Basili. 2008. Tree kernels for semantic role labeling. Computational Linguistics, 34(2):193–224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Kadri Hacioglu</author>
<author>Valerie Krugler</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Support Vector Learning for Semantic Argument Classification.</title>
<date>2005</date>
<journal>Machine Learning.</journal>
<contexts>
<context position="4369" citStr="Pradhan et al., 2005" startWordPosition="666" endWordPosition="669">elements (or predicate Proceedings of NAACL HLT 2009: Short Papers, pages 85–88, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics arguments) are detected; and (iv) Role Classification (RC) (or argument classification), which assigns semantic labels to the frame elements detected in the previous step, e.g. GOODS. Therefore, we implement the full task of FrameNet-based parsing by a combination of multiple specialized SRL-like labelers, one for each frame (Coppola et al., 2008). For the design of each single labeler, we use the state-ofthe-art strategy developed in (Pradhan et al., 2005; Moschitti et al., 2008). 2.1 Standard versus Structural Features In machine learning tasks, the manual engineering of effective features is a complex and time consuming process. For this reason, our SVM-based SRL approach exploits the combination of two different models. We first used Polynomial Kernels over handcrafted, linguistically-motivated, “standard” SRL features (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). Nonetheless, since we aim at modeling an SRL system for a new language (Italian) and a new domain (dialog transcriptions), the above features may result</context>
<context position="7558" citStr="Pradhan et al., 2005" startWordPosition="1173" endWordPosition="1176">emaining data were discarded. Accordingly, the number of positive and negative training examples for BD were: 2,764 positive and 37,497 negative examples for verbal, 1,189 and 35,576 for nominal, 615 and 14,544 for adjectival, 0 and 40 for adverbial, and 7 and 177 for prepositional predicates (for a total of 4,575 and 87,834). For RC, the total numbers were 207,662 and 1,960,423, which divided by the number of role types show the average number of 39 positive versus 367 negative examples per role label. 3.1.2 Results We tested several kernels over standard features (Gildea and Jurafsky, 2002; Pradhan et al., 2005) and structured features (Moschitti et al., 2008): the Polynomial Kernel (PK, with a degree of 3), the Tree Kernel (TK) and its combination with the bag of word kernel on the tree leaves (TKL). Also, the combinations PK+TK and PK+TKL were tested. The 4 rows of Table 1 report the performance of different classification tasks. They show in turn: (1) the “pure” performance of the BD classifiers, i.e. considering correct the classification decisions also when a correctly classified tree node does not exactly correspond to its argument’s word boundaries. Such mismatch frequently happens when the pa</context>
<context position="13362" citStr="Pradhan et al., 2005" startWordPosition="2181" endWordPosition="2184">sk of marking the exact constituent boundaries of every frame element (argument) found. The rows marked as BD+RC show the results for the two-stage pipeline of both marking the exact constituent boundaries and also assigning the correct semantic label. A few observations hold. First, the highest F1 has been achieved using the PK+TK combination. On this concern, we underline that kernel combinations always gave the best performance in any experiment we run. Second, we emphasize that the F1 of PK is surprisingly high, since it exploits the set of standard SRL feature (Gildea and Jurafsky, 2002; Pradhan et al., 2005), originally developed for English and left unmodified for Italian. Nonetheless, their performance is comparable to the Tree Kernels and, as we said, their combination improves the result. Concerning the structured features exploited by Tree Kernels, we note that they work as well without any tuning when ported to Italian dialogs. Finally, the achieved F1 is extremely good. In fact, our corresponding result on the FrameNet corpus (Table 2) is P=0.784, R=0.571, F1=0.661, where the corpus contains much more data, its sentences come from a standard written text (no disfluencies are present) and i</context>
</contexts>
<marker>Pradhan, Hacioglu, Krugler, Ward, Martin, Jurafsky, 2005</marker>
<rawString>Sameer Pradhan, Kadri Hacioglu, Valerie Krugler, Wayne Ward, James H. Martin, and Daniel Jurafsky. 2005. Support Vector Learning for Semantic Argument Classification. Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Calibrating features for semantic role labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="4815" citStr="Xue and Palmer, 2004" startWordPosition="732" endWordPosition="735">zed SRL-like labelers, one for each frame (Coppola et al., 2008). For the design of each single labeler, we use the state-ofthe-art strategy developed in (Pradhan et al., 2005; Moschitti et al., 2008). 2.1 Standard versus Structural Features In machine learning tasks, the manual engineering of effective features is a complex and time consuming process. For this reason, our SVM-based SRL approach exploits the combination of two different models. We first used Polynomial Kernels over handcrafted, linguistically-motivated, “standard” SRL features (Gildea and Jurafsky, 2002; Pradhan et al., 2005; Xue and Palmer, 2004). Nonetheless, since we aim at modeling an SRL system for a new language (Italian) and a new domain (dialog transcriptions), the above features may result ineffective. Thus, to achieve independence on the application domain, we exploited Tree Kernels (Collins and Duffy, 2002) over automatic structural features proposed in (Moschitti et al., 2005; Moschitti et al., 2008). These are complementary to standard features and are obtained by applying Tree Kernels (Collins and Duffy, 2002; Moschitti et al., 2008) to basic tree structures expressing the syntactic relation between arguments and predicat</context>
</contexts>
<marker>Xue, Palmer, 2004</marker>
<rawString>Nianwen Xue and Martha Palmer. 2004. Calibrating features for semantic role labeling. In Proceedings of EMNLP 2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>