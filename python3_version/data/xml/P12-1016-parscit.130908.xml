<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.993897">
A Class-Based Agreement Model for
Generating Accurately Inflected Translations
</title>
<author confidence="0.986626">
Spence Green John DeNero
</author>
<affiliation confidence="0.991208">
Computer Science Department, Stanford University Google
</affiliation>
<email confidence="0.932332">
spenceg@stanford.edu denero@google.com
</email>
<figure confidence="0.969779571428571">
(1) 5PAJ�‚Ë@
é«Qå„�.
~
the-carSG.DEF.F&amp;M goSG.MASC with-speedSG.FEM
I. ë YK
�
�
</figure>
<sectionHeader confidence="0.94145" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99941725">
When automatically translating from a weakly
inflected source language like English to a tar-
get language with richer grammatical features
such as gender and dual number, the output
commonly contains morpho-syntactic agree-
ment errors. To address this issue, we present
a target-side, class-based agreement model.
Agreement is promoted by scoring a sequence
of fine-grained morpho-syntactic classes that
are predicted during decoding for each transla-
tion hypothesis. For English-to-Arabic transla-
tion, our model yields a +1.04 BLEU average
improvement over a state-of-the-art baseline.
The model does not require bitext or phrase ta-
ble annotations and can be easily implemented
as a feature in many phrase-based decoders.
</bodyText>
<sectionHeader confidence="0.999511" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997028047619048">
Languages vary in the degree to which surface forms
reflect grammatical relations. English is a weakly in-
flected language: it has a narrow verbal paradigm, re-
stricted nominal inflection (plurals), and only the ves-
tiges of a case system. Consequently, translation into
English—which accounts for much of the machine
translation (MT) literature (Lopez, 2008)—often in-
volves some amount of morpho-syntactic dimension-
ality reduction. Less attention has been paid to what
happens during translation from English: richer gram-
matical features such as gender, dual number, and
overt case are effectively latent variables that must
be inferred during decoding. Consider the output of
Google Translate for the simple English sentence in
Fig. 1. The correct translation is a monotone mapping
of the input. However, in Arabic, SVO word order
requires both gender and number agreement between
the subject oPAJ�‚Ë@ ‘the car’ and verb I. ë aK
`go&apos;. The
MT system selects the correct verb stem, but with
masculine inflection. Although the translation has
</bodyText>
<figure confidence="0.389114">
The car goes quickly
</figure>
<figureCaption confidence="0.9989844">
Figure 1: Ungrammatical Arabic output of Google Trans-
late for the English input The car goes quickly. The subject
should agree with the verb in both gender and number, but
the verb has masculine inflection. For clarity, the Arabic
tokens are arranged left-to-right.
</figureCaption>
<bodyText confidence="0.999969517241379">
the correct semantics, it is ultimately ungrammatical.
This paper addresses the problem of generating text
that conforms to morpho-syntactic agreement rules.
Agreement relations that cross statistical phrase
boundaries are not explicitly modeled in most phrase-
based MT systems (Avramidis and Koehn, 2008).
We address this shortcoming with an agreement
model that scores sequences of fine-grained morpho-
syntactic classes. First, bound morphemes in transla-
tion hypotheses are segmented. Next, the segments
are labeled with classes that encode both syntactic
category information (i.e., parts of speech) and gram-
matical features such as number and gender. Finally,
agreement is promoted by scoring the predicted class
sequences with a generative Markov model.
Our model scores hypotheses during decoding. Un-
like previous models for scoring syntactic relations,
our model does not require bitext annotations, phrase
table features, or decoder modifications. The model
can be implemented using the feature APIs of popular
phrase-based decoders such as Moses (Koehn et al.,
2007) and Phrasal (Cer et al., 2010).
Intuition might suggest that the standard n-gram
language model (LM) is sufficient to handle agree-
ment phenomena. However, LM statistics are sparse,
and they are made sparser by morphological varia-
tion. For English-to-Arabic translation, we achieve
a +1.04 BLEU average improvement by tiling our
model on top of a large LM.
</bodyText>
<page confidence="0.982114">
146
</page>
<note confidence="0.98578">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 146–155,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999821">
It has also been suggested that this setting requires
morphological generation because the bitext may not
contain all inflected variants (Minkov et al., 2007;
Toutanova et al., 2008; Fraser et al., 2012). However,
using lexical coverage experiments, we show that
there is ample room for translation quality improve-
ments through better selection of forms that already
exist in the translation model.
</bodyText>
<sectionHeader confidence="0.997903" genericHeader="method">
2 A Class-based Model of Agreement
</sectionHeader>
<subsectionHeader confidence="0.676497">
2.1 Morpho-syntactic Agreement
</subsectionHeader>
<bodyText confidence="0.999963185185185">
Morpho-syntactic agreement refers to a relationship
between two sentence elements a and b that must
have at least one matching grammatical feature.1
Agreement relations tend to be defined for partic-
ular syntactic configurations such as verb-subject,
noun-adjective, and pronoun-antecedent. In some
languages, agreement affects the surface forms of the
words. For example, from the perspective of gener-
ative grammatical theory, the lexicon entry for the
Arabic nominal 3.l���JI ‘the car’ contains a feminine
gender feature. When this nominal appears in the sub-
ject argument position, the verb-subject agreement
relationship triggers feminine inflection of the verb.
Our model treats agreement as a sequence of
scored, pairwise relations between adjacent words.
Of course, this assumption excludes some agreement
phenomena, but it is sufficient for many common
cases. We focus on English-Arabic translation as
an example of a translation direction that expresses
substantially more morphological information in the
target. These relations are best captured in a target-
side model because they are mostly unobserved (from
lexical clues) in the English source.
The agreement model scores sequences of morpho-
syntactic word classes, which express grammatical
features relevant to agreement. The model has three
components: a segmenter, a tagger, and a scorer.
</bodyText>
<subsectionHeader confidence="0.999242">
2.2 Morphological Segmentation
</subsectionHeader>
<bodyText confidence="0.9998724">
Segmentation is a procedure for converting raw sur-
face forms to component morphemes. In some lan-
guages, agreement relations exist between bound
morphemes, which are syntactically independent yet
phonologically dependent morphemes. For example,
</bodyText>
<footnote confidence="0.9255265">
1We use morpho-syntactic and grammatical agreement inter-
changeably, as is common in the literature.
</footnote>
<equation confidence="0.61275825">
Pron+Fem+Sg Verb+Masc+3+Pl Prt Conj
~ v� ~ J
it they write will and
�������� J
</equation>
<figureCaption confidence="0.933650285714286">
Figure 2: Segmentation and tagging of the Arabic token
ly.9 ‘and they will write it&apos;. This token has four seg-
ments with conflicting grammatical features. For example,
the number feature is singular for the pronominal object
and plural for the verb. Our model segments the raw to-
ken, tags each segment with a morpho-syntactic class (e.g.,
“Pron+Fem+Sg”), and then scores the class sequences.
</figureCaption>
<bodyText confidence="0.997612454545454">
the single raw token in Fig. 2 contains at least four
grammatically independent morphemes. Because the
morphemes bear conflicting grammatical features and
basic parts of speech (POS), we need to segment the
token before we can evaluate agreement relations.2
Segmentation is typically applied as a bitext pre-
processing step, and there is a rich literature on the
effect of different segmentation schemata on transla-
tion quality (Koehn and Knight, 2003; Habash and
Sadat, 2006; El Kholy and Habash, 2012). Unlike pre-
vious work, we segment each translation hypothesis
as it is generated (i.e., during decoding). This permits
greater modeling flexibility. For example, it may be
useful to count tokens with bound morphemes as a
unit during phrase extraction, but to score segmented
morphemes separately for agreement.
We treat segmentation as a character-level se-
quence modeling problem and train a linear-chain
conditional random field (CRF) model (Lafferty et
al., 2001). As a pre-processing step, we group con-
tiguous non-native characters (e.g., Latin characters
in Arabic text). The model assigns four labels:
</bodyText>
<listItem confidence="0.9999935">
• I: Continuation of a morpheme
• O: Outside morpheme (whitespace)
• B: Beginning of a morpheme
• F: Non-native character(s)
</listItem>
<footnote confidence="0.998913333333333">
2Segmentation also improves translation of compounding
languages such as German (Dyer, 2009) and Finnish (Macherey
et al., 2011).
</footnote>
<page confidence="0.994581">
147
</page>
<figure confidence="0.606976722222222">
Translation Model
e Target sequence of I words
f Source sequence of J words
a Sequence of K phrase alignments for (e, f)
ri Permutation of the alignments for target word order e
h Sequence of M feature functions
λ Sequence of learned weights for the M features
H A priority queue of hypotheses
Class-based Agreement Model
t E T Set of morpho-syntactic classes
s E S Set of all word segments
θseg Learned weights for the CRF-based segmenter
θtag Learned weights for the CRF-based tagger
φ , φt CRF potential functions (emission and transition)
τ Sequence of I target-side predicted classes
π T dimensional (log) prior distribution over classes
s� Sequence of l word segments
σ Model state: a tagged segment (s, t)
</figure>
<figureCaption confidence="0.9987115">
Figure 3: Notation used in this paper. The convention eZ
indicates a subsequence of a length I sequence.
</figureCaption>
<bodyText confidence="0.999868230769231">
The features are indicators for (character, position,
label) triples for a five character window and bigram
label transition indicators.
This formulation is inspired by the classic “IOB”
text chunking model (Ramshaw and Marcus, 1995),
which has been previously applied to Chinese seg-
mentation (Peng et al., 2004). It can be learned from
gold-segmented data, generally applies to languages
with bound morphemes, and does not require a hand-
compiled lexicon.3 Moreover, it has only four labels,
so Viterbi decoding is very fast. We learn the param-
eters Bseg using a quasi-Newton (QN) procedure with
h (lasso) regularization (Andrew and Gao, 2007).
</bodyText>
<subsectionHeader confidence="0.997526">
2.3 Morpho-syntactic Tagging
</subsectionHeader>
<bodyText confidence="0.999932888888889">
After segmentation, we tag each segment with a fine-
grained morpho-syntactic class. For this task we also
train a standard CRF model on full sentences with
gold classes and segmentation. We use the same QN
procedure as before to obtain Btag.
A translation derivation is a tuple (e, f, a) where
e is the target, f is the source, and a is an alignment
between the two. The CRF tagging model predicts a
target-side class sequence T*
</bodyText>
<equation confidence="0.9807835">
I
T* = arg max Btag - {0o(Ti, i, e) + Ot(Ti, Ti−1)}
τ
i=1
</equation>
<bodyText confidence="0.998220765957447">
where further notation is defined in Fig. 3.
3Mada, the standard tool for Arabic segmentation (Habash
and Rambow, 2005), relies on a manually compiled lexicon.
Set of Classes The tagger assigns morpho-syntactic
classes, which are coarse POS categories refined with
grammatical features such as gender and definiteness.
The coarse categories are the universal POS tag set
described by Petrov et al. (2012). More than 25 tree-
banks (in 22 languages) can be automatically mapped
to this tag set, which includes “Noun” (nominals),
“Verb” (verbs), “Adj” (adjectives), and “ADP” (pre-
and post-positions). Many of these treebanks also
contain per-token morphological annotations. It is
easy to combine the coarse categories with selected
grammatical annotations.
For Arabic, we used the coarse POS tags plus
definiteness and the so-called phi features (gender,
number, and person).4 For example, 3.����JI ‘the
car’ would be tagged “Noun+Def+Sg+Fem”. We
restricted the set of classes to observed combinations
in the training data, so the model implicitly disallows
incoherent classes like “Verb+Def”.
Features The tagging CRF includes emission fea-
tures 0o that indicate a class Ti appearing with various
orthographic characteristics of the word sequence
being tagged. In typical CRF inference, the entire
observation sequence is available throughout infer-
ence, so these features can be scored on observed
words in an arbitrary neighborhood around the cur-
rent position i. However, we conduct CRF inference
in tandem with the translation decoding procedure
(§3), creating an environment in which subsequent
words of the observation are not available; the MT
system has yet to generate the rest of the translation
when the tagging features for a position are scored.
Therefore, we only define emission features on the
observed words at the current and previous positions
of a class: 0o(Ti, ei, ei−1).
The emission features are word types, prefixes and
suffxes of up to three characters, and indicators for
digits and punctuation. None of these features are
language specific.
Bigram transition features Ot encode local agree-
ment relations. For example, the model learns that the
Arabic class “Noun+Fem” is followed by “Adj+Fem”
and not “Adj+Masc” (noun-adjective gender agree-
ment).
</bodyText>
<footnote confidence="0.9982835">
4Case is also relevant to agreement in Arabic, but it is mostly
indicated by diacritics, which are absent in unvocalized text.
</footnote>
<page confidence="0.986379">
148
</page>
<subsectionHeader confidence="0.985427">
2.4 Word Class Sequence Scoring
</subsectionHeader>
<bodyText confidence="0.999838538461539">
The CRF tagger model defines a conditional distribu-
tion p(τ|e; θtag) for a class sequence τ given a sen-
tence e and model parameters θtag. That is, the sam-
ple space is over class—not word—sequences. How-
ever, in MT, we seek a measure of sentence quality
q(e) that is comparable across different hypotheses
on the beam (much like the n-gram language model
score). Discriminative model scores have been used
as MT features (Galley and Manning, 2009), but we
obtained better results by scoring the 1-best class se-
quences with a generative model. We trained a simple
add-1 smoothed bigram language model over gold
class sequences in the same treebank training data:
</bodyText>
<equation confidence="0.992877666666667">
I
q(e) = p(τ) = p(τi|τi−1)
i=1
</equation>
<bodyText confidence="0.999977454545455">
We chose a bigram model due to the aggressive
recombination strategy in our phrase-based decoder.
For contexts in which the LM is guaranteed to back
off (for instance, after an unseen bigram), our decoder
maintains only the minimal state needed (perhaps only
a single word). In less restrictive decoders, higher
order scoring models could be used to score longer-
distance agreement relations.
We integrate the segmentation, tagging, and scor-
ing models into a self-contained component in the
translation decoder.
</bodyText>
<sectionHeader confidence="0.998987" genericHeader="method">
3 Inference during Translation Decoding
</sectionHeader>
<bodyText confidence="0.99983575">
Scoring the agreement model as part of translation
decoding requires a novel inference procedure. Cru-
cially, the inference procedure does not measurably
affect total MT decoding time.
</bodyText>
<subsectionHeader confidence="0.999035">
3.1 Phrase-based Translation Decoding
</subsectionHeader>
<bodyText confidence="0.99998025">
We consider the standard phrase-based approach to
MT (Och and Ney, 2004). The distribution p(e|f) is
modeled directly using a log-linear model, yielding
the following decision rule:
</bodyText>
<equation confidence="0.9301525">
� M
e* = arg max λmhm(e, f, a, lI) (1)
e,a,ll
m=1
</equation>
<bodyText confidence="0.999749666666667">
This decoding problem is NP-hard, thus a beam search
is often used (Fig. 4). The beam search relies on three
operations, two of which affect the agreement model:
</bodyText>
<figure confidence="0.583521583333333">
Input: implicitly defined search space
generate initial hypotheses and add to H
set Hfinal to 0
while H is not empty:
set Hext to 0
for each hypothesis η in H:
if η is a goal hypothesis:
add η to Hfinal
else Extend η and add to Hext lo-Score agreement
Recombine and Prune Hext
set H to Hext
Output: argmax of Hfinal
</figure>
<figureCaption confidence="0.945841">
Figure 4: Breadth-first beam search algorithm of Och and
Ney (2004). Typically, a hypothesis stack H is maintained
for each unique source coverage set.
</figureCaption>
<bodyText confidence="0.80930025">
Input: (eI1, n, is_goal)
run segmenter on attachment eIn+1 to get SL1
get model state σ = (s, t) for translation prefix en1
initialize π to −oo
</bodyText>
<equation confidence="0.9156036">
set π(t) = 0
compute τ* from parameters (s, SL1 , π, is_goal)
compute q(eIn+1) = p(τ*) under the generative LM
set model state σnew = (SL, τ*L) for prefix eI1
Output: q(eIn+1)
</equation>
<figureCaption confidence="0.900501">
Figure 5: Procedure for scoring agreement for each hy-
pothesis generated during the search algorithm of Fig. 4.
In the extended hypothesis e�1, the index n + 1 indicates
the start of the new attachment.
</figureCaption>
<listItem confidence="0.9996305">
• Extend a hypothesis with a new phrase pair
• Recombine hypotheses with identical states
</listItem>
<bodyText confidence="0.9922605">
We assume familiarity with these operations, which
are described in detail in (Och and Ney, 2004).
</bodyText>
<subsectionHeader confidence="0.995056">
3.2 Agreement Model Inference
</subsectionHeader>
<bodyText confidence="0.999992285714286">
The class-based agreement model is implemented as
a feature function hm in Eq. (1). Specifically, when
Extend generates a new hypothesis, we run the algo-
rithm shown in Fig. 5. The inputs are a translation
hypothesis eI1, an index n distinguishing the prefix
from the attachment, and a flag indicating if their
concatenation is a goal hypothesis.
The beam search maintains state for each deriva-
tion, the score of which is a linear combination of
the feature values. States in this program depend on
some amount of lexical history. With a trigram lan-
guage model, the state might be the last two words
of the translation prefix. Recombine can be applied
to any two hypotheses with equivalent states. As a
</bodyText>
<page confidence="0.995971">
149
</page>
<bodyText confidence="0.99992425">
result, two hypotheses with different full prefixes—
and thus potentially different sequences of agreement
relations—can be recombined.
Incremental Greedy Decoding Decoding with
the CRF-based tagger model in this setting requires
some slight modifications to the Viterbi algorithm.
We make a greedy approximation that permits recom-
bination and works well in practice. The agreement
model state is the last tagged segment (s, t) of the
concatenated hypothesis. We tag a new attachment by
assuming a prior distribution 7r over the starting posi-
tion such that 7r(t) = 0 and −oo for all other classes,
a deterministic distribution in the tropical semiring.
This forces the Viterbi path to go through t. We only
tag the final boundary symbol for goal hypotheses.
To accelerate tagger decoding in our experiments,
we also used tagging dictionaries for frequently ob-
served word types. For each word type observed more
than 100 times in the training data, we restricted the
set of possible classes to the set of observed classes.
</bodyText>
<subsectionHeader confidence="0.949052">
3.3 Translation Model Features
</subsectionHeader>
<bodyText confidence="0.969749090909091">
The agreement model score is one decoder feature
function. The output of the procedure in Fig. 5 is the
log probability of the class sequence of each attach-
ment. Summed over all attachments, this gives the
log probability of the whole class sequence.
We also add a new length penalty feature. To dis-
criminate between hypotheses that might have the
same number of raw tokens, but different underlying
segmentations, we add a penalty equal to the length
difference between the segmented and unsegmented
.
</bodyText>
<equation confidence="0.696431">
attachments s1 − en+1
</equation>
<sectionHeader confidence="0.999936" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999847413793104">
We compare our class-based model to previous ap-
proaches to scoring syntactic relations in MT.
Unification-based Formalisms Agreement rules
impose syntactic and semantic constraints on the
structure of sentences. A principled way to model
these constraints is with a unification-based gram-
mar (UBG). Johnson (2003) presented algorithms for
learning and parsing with stochastic UBGs. However,
training data for these formalisms remains extremely
limited, and it is unclear how to learn such knowledge-
rich representations from unlabeled data. One partial
solution is to manually extract unification rules from
phrase-structure trees. Williams and Koehn (2011)
annotated German trees, and extracted translation
rules from them. They then specified manual unifi-
cation rules, and applied a penalty according to the
number of unification failures in a hypothesis. In
contrast, our class-based model does not require any
manual rules and scores similar agreement phenom-
ena as probabilistic sequences.
Factored Translation Models Factored transla-
tion models (Koehn and Hoang, 2007) facilitate a
more data-oriented approach to agreement modeling.
Words are represented as a vector of features such as
lemma and POS. The bitext is annotated with separate
models, and the annotations are saved during phrase
extraction. Hassan et al. (2007) noticed that the target-
side POS sequences could be scored, much as we do
in this work. They used a target-side LM over Combi-
natorial Categorial Grammar (CCG) supertags, along
with a penalty for the number of operator violations,
and also modified the phrase probabilities based on
the tags. However, Birch et al. (2007) showed that
this approach captures the same re-ordering phenom-
ena as lexicalized re-ordering models, which were
not included in the baseline. Birch et al. (2007) then
investigated source-side CCG supertag features, but
did not show an improvement for Dutch-English.
Subotin (2011) recently extended factored transla-
tion models to hierarchical phrase-based translation
and developed a discriminative model for predicting
target-side morphology in English-Czech. His model
benefited from gold morphological annotations on
the target-side of the 8M sentence bitext.
In contrast to these methods, our model does not af-
fect phrase extraction and does not require annotated
translation rules.
Class-based LMs Class-based LMs (Brown et al.,
1992) reduce lexical sparsity by placing words in
equivalence classes. They have been widely used
for speech recognition, but not for MT. Och (1999)
showed a method for inducing bilingual word classes
that placed each phrase pair into a two-dimensional
equivalence class. To our knowledge, Uszkoreit and
Brants (2008) are the only recent authors to show an
improvement in a state-of-the-art MT system using
class-based LMs. They used a classical exchange al-
gorithm for clustering, and learned 512 classes from
</bodyText>
<page confidence="0.995385">
150
</page>
<bodyText confidence="0.999406387096774">
a large monolingual corpus. Then they mixed the
classes into a word-based LM. However, both Och
(1999) and Uszkoreit and Brants (2008) relied on
automatically induced classes. It is unclear if their
classes captured agreement information.
Monz (2011) recently investigated parameter es-
timation for POS-based language models, but his
classes did not include inflectional features.
Target-Side Syntactic LMs Our agreement model
is a form of syntactic LM, of which there is a long
history of research, especially in speech processing.5
Syntactic LMs have traditionally been too slow for
scoring during MT decoding. One exception was
the quadratic-time dependency language model pre-
sented by Galley and Manning (2009). They applied
a quadratic time dependency parser to every hypothe-
sis during decoding. However, to achieve quadratic
running time, they permitted ill-formed trees (e.g.,
parses with multiple roots). More recently, Schwartz
et al. (2011) integrated a right-corner, incremental
parser into Moses. They showed a large improve-
ment for Urdu-English, but decoding slowed by three
orders of magnitude.6 In contrast, our class-based
model encodes shallow syntactic information without
a noticeable effect on decoding time.
Our model can be viewed as a way to score local
syntactic relations without extensive decoder modifi-
cations. For long-distance relations, Shen et al. (2010)
proposed a new decoder that generates target-side
dependency trees. The target-side structure enables
scoring hypotheses with a trigram dependency LM.
</bodyText>
<sectionHeader confidence="0.999646" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999867">
We first evaluate the Arabic segmenter and tagger
components independently, then provide English-
Arabic translation quality results.
</bodyText>
<subsectionHeader confidence="0.90711">
5.1 Intrinsic Evaluation of Components
</subsectionHeader>
<bodyText confidence="0.999615">
Experimental Setup All experiments use the Penn
Arabic Treebank (ATB) (Maamouri et al., 2004) parts
1–3 divided into training/dev/test sections according
to the canonical split (Rambow et al., 2005).7
</bodyText>
<footnote confidence="0.9982834">
5See (Zhang, 2009) for a comprehensive survey.
6In principle, their parser should run in linear time. An imple-
mentation issue may account for the decoding slowdown. (p.c.)
7LDC catalog numbers: LDC2008E61 (ATBp1v4),
LDC2008E62 (ATBp2v3), and LDC2008E22 (ATBp3v3.1).
</footnote>
<table confidence="0.864588666666667">
FULL (%) INCREMENTAL (%)
Segmenter 98.6 –
Tagger 96.3 96.2
</table>
<tableCaption confidence="0.997943">
Table 1: Intrinsic evaluation accuracy [%] (development
set) for Arabic segmentation and tagging.
</tableCaption>
<bodyText confidence="0.9999365">
The ATB contains clitic-segmented text with per-
segment morphological analyses (in addition to
phrase-structure trees, which we discard). For train-
ing the segmenter, we used markers in the vocalized
section to construct the IOB character sequences. For
training the tagger, we automatically converted the
ATB morphological analyses to the fine-grained class
set. This procedure resulted in 89 classes.
For the segmentation evaluation, we report per-
character labeling accuracy.8 For the tagger, we re-
port per-token accuracy.
Results Tbl. 1 shows development set accuracy for
two settings. FULL is a standard evaluation in which
features may be defined over the whole sentence. This
includes next-character segmenter features and next-
word tagger features. INCREMENTAL emulates the MT
setting in which the models are restricted to current
and previous observation features. Since the seg-
menter operates at the character level, we can use
the same feature set. However, next-observation fea-
tures must be removed from the tagger. Nonetheless,
tagging accuracy only decreases by 0.1%.
</bodyText>
<subsectionHeader confidence="0.998396">
5.2 Translation Quality
</subsectionHeader>
<bodyText confidence="0.999907875">
Experimental Setup Our decoder is based on the
phrase-based approach to translation (Och and Ney,
2004) and contains various feature functions includ-
ing phrase relative frequency, word-level alignment
statistics, and lexicalized re-ordering models (Till-
mann, 2004; Och et al., 2004). We tuned the feature
weights on a development set using lattice-based min-
imum error rate training (MERT) (Macherey et al.,
</bodyText>
<footnote confidence="0.848249875">
The data was pre-processed with packages from the Stanford
Arabic parser (Green and Manning, 2010). The corpus split is
available at http://nlp.stanford.edu/projects/arabic.shtml.
8We ignore orthographic re-normalization performed by the
annotators. For example, they converted the contraction &apos;j, ll
back to `CJI CJ&apos; l Al. As a result, we can report accuracy since
the guess and gold segmentations have equal numbers of non-
whitespace characters.
</footnote>
<page confidence="0.98986">
151
</page>
<table confidence="0.993166166666667">
MT04 (tune) MT02 MT03 MT05 Avg
Baseline 18.14 23.87 18.88 22.60
+POS 18.11 −0.03 23.65 −0.22 18.99 +0.11 22.29 −0.31 −0.17
+POS+Agr 18.86 +0.72 24.84 +0.97 20.26 +1.38 23.48 +0.88 +1.04
genres nw nw nw nw
#sentences 1353 728 663 1056 2447
</table>
<tableCaption confidence="0.9974635">
Table 2: Translation quality results (BLEU-4 [%]) for newswire (nw) sets. Avg is the weighted averaged (by number of
sentences) of the individual test set gains. All improvements are statistically significant at p &lt; 0.01.
</tableCaption>
<table confidence="0.999069166666667">
MT06 MT08 Avg
Baseline 14.68 14.30
+POS 14.57 −0.11 14.30 +0.0 −0.06
+POS+Agr 15.04 +0.36 14.49 +0.19 +0.29
genres nw,bn,ng nw,ng,wb
#sentences 1797 1360 3157
</table>
<tableCaption confidence="0.816499">
Table 3: Mixed genre test set results (BLEU-4 [%]). The
MT06 result is statistically significant at p &lt; 0.01; MT08
is significant at p &lt; 0.02. The genres are: nw, broadcast
news (bn), newsgroups (ng), and weblog (wb).
</tableCaption>
<bodyText confidence="0.99969040625">
2008). For each set of results, we initialized MERT
with uniform feature weights.
We trained the translation model on 502 million
words of parallel text collected from a variety of
sources, including the Web. Word alignments were in-
duced using a hidden Markov model based alignment
model (Vogel et al., 1996) initialized with bilexical
parameters from IBM Model 1 (Brown et al., 1993).
Both alignment models were trained using two itera-
tions of the expectation maximization algorithm. Our
distributed 4-gram language model was trained on
600 million words of Arabic text, also collected from
many sources including the Web (Brants et al., 2007).
For development and evaluation, we used the NIST
Arabic-English data sets, each of which contains one
set of Arabic sentences and multiple English refer-
ences. To reverse the translation direction for each
data set, we chose the first English reference as the
source and the Arabic as the reference.
The NIST sets come in two varieties: newswire
(MT02-05) and mixed genre (MT06,08). Newswire
contains primarily Modern Standard Arabic (MSA),
while the mixed genre data sets also contain tran-
scribed speech and web text. Since the ATB contains
MSA, and significant lexical and syntactic differences
may exist between MSA and the mixed genres, we
achieved best results by tuning on MT04, the largest
newswire set.
We evaluated translation quality with BLEU-4 (Pa-
pineni et al., 2002) and computed statistical signifi-
cance with the approximate randomization method
of Riezler and Maxwell (2005).9
</bodyText>
<sectionHeader confidence="0.979947" genericHeader="method">
6 Discussion of Translation Results
</sectionHeader>
<bodyText confidence="0.99893388">
Tbl. 2 shows translation quality results on newswire,
while Tbl. 3 contains results for mixed genres. The
baseline is our standard system feature set. For
comparison, +POS indicates our class-based model
trained on the 11 coarse POS tags only (e.g., “Noun”).
Finally, +POS+Agr shows the class-based model
with the fine-grained classes (e.g., “Noun+Fem+Sg”).
The best result—a +1.04 BLEU average gain—
was achieved when the class-based model training
data, MT tuning set, and MT evaluation set contained
the same genre. We realized smaller, yet statistically
significant, gains on the mixed genre data sets. We
tried tuning on both MT06 and MT08, but obtained
insignificant gains. In the next section, we investigate
this issue further.
Tuning with a Treebank-Trained Feature The
class-based model is trained on the ATB, which is pre-
dominantly MSA text. This data set is syntactically
regular, meaning that it does not have highly dialectal
content, foreign scripts, disfluencies, etc. Conversely,
the mixed genre data sets contain more irregulari-
ties. For example, 57.4% of MT06 comes from non-
newswire genres. Of the 764 newsgroup sentences,
112 contain some Latin script tokens, while others
contain very little morphology:
</bodyText>
<footnote confidence="0.9900225">
9With the implementation of Clark et al. (2011), available at:
http://github.com/jhclark/multeval.
</footnote>
<page confidence="0.990668">
152
</page>
<figure confidence="0.62820625">
(2) ù�¢Ê b@
mix
Mix 1/2 cup apple vinegar
Start the program music match (MusicMatch)
</figure>
<bodyText confidence="0.9999668">
In these imperatives, there are no lexically marked
agreement relations to score. Ex. (2) is an excerpt
from a recipe that appears in full in MT06. Ex. (3)
is part of usage instructions for the MusicMatch soft-
ware. The ATB contains few examples like these, so
our class-based model probably does not effectively
discriminate between alternative hypotheses for these
types of sentences.
Phrase Table Coverage In a standard phrase-
based system, effective translation into a highly in-
flected target language requires that the phrase table
contain the inflected word forms necessary to con-
struct an output with correct agreement. If the requi-
site words are not present in the search space of the
decoder, then no feature function would be sufficient
to enforce morpho-syntactic agreement.
During development, we observed that the phrase
table of our large-scale English-Arabic system did
often contain the inflected forms that we desired the
system to select. In fact, correctly agreeing alterna-
tives often appeared in n-best translation lists. To
verify this observation, we computed the lexical cov-
erage of the MT05 reference sentences in the decoder
search space. The statistics below report the token-
level recall of reference unigrams:10
</bodyText>
<listItem confidence="0.999696">
• Baseline system translation output: 44.6%
• Phrase pairs matching source n-grams: 67.8%
</listItem>
<bodyText confidence="0.997321235294118">
The bottom category includes all lexical items that
the decoder could produce in a translation of the
source. This large gap between the unigram recall
of the actual translation output (top) and the lexical
coverage of the phrase-based model (bottom) indi-
cates that translation performance can be improved
dramatically by altering the translation model through
features such as ours, without expanding the search
space of the decoder.
10To focus on possibly inflected word forms, we excluded
numbers and punctuation from this analysis.
Human Evaluation We also manually evaluated
the MT05 output for improvements in agreement.11
Our system produced different output from the base-
line for 785 (74.3%) sentences. We randomly sam-
pled 100 of these sentences and counted agreement
errors of all types. The baseline contained 78 errors,
while our system produced 66 errors, a statistically
significant 15.4% error reduction at p &lt; 0.01 accord-
ing to a paired t-test.
In our output, a frequent source of remaining errors
was the case of so-called “deflected agreement”: inan-
imate plural nouns require feminine singular agree-
ment with modifiers. On the other hand, animate
plural nouns require the sound plural, which is indi-
cated by an appropriate masculine or feminine suffix.
For example, the inanimate plural :)AK�BñË@ ’states’ re-
quires the singular feminine adjective oYj:ÖÏ@ ‘united’,
not the sound plural u@Yj�JÖÏ@. The ATB does not con-
tain animacy annotations, so our agreement model
cannot discriminate between these two cases. How-
ever, Alkuhlani and Habash (2011) have recently
started annotating the ATB for animacy, and our
model could benefit as more data is released.
</bodyText>
<sectionHeader confidence="0.992563" genericHeader="conclusions">
7 Conclusion and Outlook
</sectionHeader>
<bodyText confidence="0.999829476190476">
Our class-based agreement model improves transla-
tion quality by promoting local agreement, but with
a minimal increase in decoding time and no addi-
tional storage requirements for the phrase table. The
model can be implemented with a standard CRF pack-
age, trained on existing treebanks for many languages,
and integrated easily with many MT feature APIs.
We achieved best results when the model training
data, MT tuning set, and MT evaluation set con-
tained roughly the same genre. Nevertheless, we also
showed an improvement, albeit less significant, on
mixed genre evaluation sets.
In principle, our class-based model should be more
robust to unseen word types and other phenomena that
make non-newswire genres challenging. However,
our analysis has shown that for Arabic, these genres
typically contain more Latin script and transliterated
words, and thus there is less morphology to score.
One potential avenue of future work would be to adapt
our component models to new genres by self-training
them on the target side of a large bitext.
</bodyText>
<footnote confidence="0.543285">
11The annotator was the first author.
</footnote>
<figure confidence="0.9982914">
�
(3) @YK.
start
l.×A�KQK.
program
1/4 �PñJ�Ó
miozik
•~~AÓ� MusicMatch
maatsh MusicMatch
Ég
vinegar
1/2 H. ñ»
1/2 cup
hA�®�K
apple
</figure>
<page confidence="0.995942">
153
</page>
<bodyText confidence="0.993568571428572">
Acknowledgments We thank Zhifei Li and Chris Manning
for helpful discussions, and Klaus Macherey, Wolfgang
Macherey, Daisy Stanton, and Richard Zens for engineer-
ing support. This work was conducted while the first au-
thor was an intern at Google. At Stanford, the first author
is supported by a National Science Foundation Graduate
Research Fellowship.
</bodyText>
<sectionHeader confidence="0.998925" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999923831683168">
S. Alkuhlani and N. Habash. 2011. A corpus for modeling
morpho-syntactic agreement in Arabic: Gender, number and
rationality. In ACL-HLT.
G. Andrew and J. Gao. 2007. Scalable training of ll-regularized
log-linear models. In ICML.
E. Avramidis and P. Koehn. 2008. Enriching morphologically
poor languages for statistical machine translation. In ACL.
A. Birch, M. Osborne, and P. Koehn. 2007. CCG supertags in
factored statistical machine translation. In WMT.
T. Brants, A. C. Popat, P. Xu, F. J. Och, and J. Dean. 2007. Large
language models in machine translation. In EMNLP-CoNLL.
P. F. Brown, P. V. deSouza, R. L. Mercer, V. J. Della Pietra,
and J. C. Lai. 1992. Class-based n-gram models of natural
language. Computational Linguistics, 18:467–479.
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer.
1993. The mathematics of statistical machine translation:
Parameter estimation. Computational Linguistics, 19(2):263–
313.
D. Cer, M. Galley, D. Jurafsky, and C. D. Manning. 2010. Phrasal:
A statistical machine translation toolkit for exploring new
model features. In HLT-NAACL, Demonstration Session.
J. H. Clark, C. Dyer, A. Lavie, and N. A. Smith. 2011. Better hy-
pothesis testing for statistical machine translation: Controlling
for optimizer instability. In ACL.
C. Dyer. 2009. Using a maximum entropy model to build seg-
mentation lattices for MT. In NAACL.
A. El Kholy and N. Habash. 2012. Orthographic and mor-
phological processing for English-Arabic statistical machine
translation. Machine Translation, 26(1-2):25–45.
A. Fraser, M. Weller, A. Cahill, and F. Cap. 2012. Modeling
inflection and word-formation in SMT. In EACL.
M. Galley and C. D. Manning. 2009. Quadratic-time dependency
parsing for machine translation. In ACL-IJCNLP.
S. Green and C. D. Manning. 2010. Better Arabic parsing:
baselines, evaluations, and analysis. In COLING.
N. Habash and O. Rambow. 2005. Arabic tokenization, part-of-
speech tagging and morphological disambiguation in one fell
swoop. In ACL.
N. Habash and F. Sadat. 2006. Arabic preprocessing schemes
for statistical machine translation. In NAACL.
H. Hassan, K. Sima&apos;an, and A. Way. 2007. Supertagged phrase-
based statistical machine translation. In ACL.
M. Johnson. 2003. Learning and parsing stochastic unification-
based grammars. In COLT.
P. Koehn and H. Hoang. 2007. Factored translation models. In
EMNLP-CoNLL.
P. Koehn and K. Knight. 2003. Empirical methods for compound
splitting. In EACL.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico,
N. Bertoldi, et al. 2007. Moses: Open source toolkit for sta-
tistical machine translation. In ACL, Demonstration Session.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional ran-
dom fields: Probablistic models for segmenting and labeling
sequence data. In ICML.
A. Lopez. 2008. Statistical machine translation. ACM Computing
Surveys, 40(8):1–49.
M. Maamouri, A. Bies, T. Buckwalter, and W. Mekki. 2004.
The Penn Arabic Treebank: Building a large-scale annotated
Arabic corpus. In NEMLAR.
W. Macherey, F. Och, I. Thayer, and J. Uszkoreit. 2008. Lattice-
based minimum error rate training for statistical machine trans-
lation. In EMNLP.
K. Macherey, A. Dai, D. Talbot, A. Popat, and F. Och. 2011.
Language-independent compound splitting with morphologi-
cal operations. In ACL.
E. Minkov, K. Toutanova, and H. Suzuki. 2007. Generating
complex morphology for machine translation. In ACL.
C. Monz. 2011. Statistical machine translation with local lan-
guage models. In EMNLP.
F. J. Och and H. Ney. 2004. The alignment template approach
to statistical machine translation. Computational Linguistics,
30(4):417–449.
F. J. Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Yamada,
A. Fraser, et al. 2004. A smorgasbord of features for sta-
tistical machine translation. In HLT-NAACL.
F. J. Och. 1999. An efficient method for determining bilingual
word classes. In EACL.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. BLEU: a
method for automatic evaluation of machine translation. In
ACL.
F. Peng, F. Feng, and A. McCallum. 2004. Chinese segmentation
and new word detection using conditional random fields. In
COLING.
S. Petrov, D. Das, and R. McDonald. 2012. A universal part-of-
speech tagset. In LREC.
O. Rambow, D. Chiang, M. Diab, N. Habash, R. Hwa, et al. 2005.
Parsing Arabic dialects. Technical report, Johns Hopkins
University.
L. A. Ramshaw and M. Marcus. 1995. Text chunking using
transformation-based learning. In Proc. of the Third Workshop
on Very Large Corpora.
S. Riezler and J. T. Maxwell. 2005. On some pitfalls in auto-
matic evaluation and significance testing in MT. In ACL-05
Workshop on Intrinsic and Extrinsic Evaluation Measures for
Machine Translation and/or Summarization (MTSE).
L. Schwartz, C. Callison-Burch, W. Schuler, and S. Wu. 2011.
Incremental syntactic language models for phrase-based trans-
lation. In ACL-HLT.
L. Shen, J. Xu, and R. Weischedel. 2010. String-to-dependency
statistical machine translation. Computational Linguistics,
36(4):649–671.
</reference>
<page confidence="0.997452">
154
</page>
<reference confidence="0.9995775625">
M. Subotin. 2011. An exponential translation model for target
language morphology. In ACL-HLT.
C. Tillmann. 2004. A unigram orientation model for statistical
machine translation. In NAACL.
K. Toutanova, H. Suzuki, and A. Ruopp. 2008. Applying mor-
phology generation models to machine translation. In ACL-
HLT.
J. Uszkoreit and T. Brants. 2008. Distributed word clustering
for large scale class-based language modeling in machine
translation. In ACL-HLT.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-based word
alignment in statistical translation. In COLING.
P. Williams and P. Koehn. 2011. Agreement constraints for
statistical machine translation into German. In WMT.
Y. Zhang. 2009. Structured Language Models for Statistical Ma-
chine Translation. Ph.D. thesis, Carnegie Mellon University.
</reference>
<page confidence="0.999013">
155
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.510788">
<title confidence="0.9998105">A Class-Based Agreement Model for Generating Accurately Inflected Translations</title>
<author confidence="0.999706">Spence Green John DeNero</author>
<affiliation confidence="0.998666">Computer Science Department, Stanford University Google</affiliation>
<email confidence="0.785733">spenceg@stanford.edudenero@google.com</email>
<abstract confidence="0.965998">I.ë YK � � Abstract When automatically translating from a weakly inflected source language like English to a target language with richer grammatical features such as gender and dual number, the output commonly contains morpho-syntactic agreement errors. To address this issue, we present a target-side, class-based agreement model. Agreement is promoted by scoring a sequence of fine-grained morpho-syntactic classes that are predicted during decoding for each translation hypothesis. For English-to-Arabic translaour model yields a BLEU average improvement over a state-of-the-art baseline. The model does not require bitext or phrase table annotations and can be easily implemented as a feature in many phrase-based decoders.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Alkuhlani</author>
<author>N Habash</author>
</authors>
<title>A corpus for modeling morpho-syntactic agreement in Arabic: Gender, number and rationality.</title>
<date>2011</date>
<booktitle>In ACL-HLT.</booktitle>
<contexts>
<context position="31703" citStr="Alkuhlani and Habash (2011)" startWordPosition="4907" endWordPosition="4910">ng to a paired t-test. In our output, a frequent source of remaining errors was the case of so-called “deflected agreement”: inanimate plural nouns require feminine singular agreement with modifiers. On the other hand, animate plural nouns require the sound plural, which is indicated by an appropriate masculine or feminine suffix. For example, the inanimate plural :)AK�BñË@ ’states’ requires the singular feminine adjective oYj:ÖÏ@ ‘united’, not the sound plural u@Yj�JÖÏ@. The ATB does not contain animacy annotations, so our agreement model cannot discriminate between these two cases. However, Alkuhlani and Habash (2011) have recently started annotating the ATB for animacy, and our model could benefit as more data is released. 7 Conclusion and Outlook Our class-based agreement model improves translation quality by promoting local agreement, but with a minimal increase in decoding time and no additional storage requirements for the phrase table. The model can be implemented with a standard CRF package, trained on existing treebanks for many languages, and integrated easily with many MT feature APIs. We achieved best results when the model training data, MT tuning set, and MT evaluation set contained roughly th</context>
</contexts>
<marker>Alkuhlani, Habash, 2011</marker>
<rawString>S. Alkuhlani and N. Habash. 2011. A corpus for modeling morpho-syntactic agreement in Arabic: Gender, number and rationality. In ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Andrew</author>
<author>J Gao</author>
</authors>
<title>Scalable training of ll-regularized log-linear models.</title>
<date>2007</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="9470" citStr="Andrew and Gao, 2007" startWordPosition="1431" endWordPosition="1434">ators for (character, position, label) triples for a five character window and bigram label transition indicators. This formulation is inspired by the classic “IOB” text chunking model (Ramshaw and Marcus, 1995), which has been previously applied to Chinese segmentation (Peng et al., 2004). It can be learned from gold-segmented data, generally applies to languages with bound morphemes, and does not require a handcompiled lexicon.3 Moreover, it has only four labels, so Viterbi decoding is very fast. We learn the parameters Bseg using a quasi-Newton (QN) procedure with h (lasso) regularization (Andrew and Gao, 2007). 2.3 Morpho-syntactic Tagging After segmentation, we tag each segment with a finegrained morpho-syntactic class. For this task we also train a standard CRF model on full sentences with gold classes and segmentation. We use the same QN procedure as before to obtain Btag. A translation derivation is a tuple (e, f, a) where e is the target, f is the source, and a is an alignment between the two. The CRF tagging model predicts a target-side class sequence T* I T* = arg max Btag - {0o(Ti, i, e) + Ot(Ti, Ti−1)} τ i=1 where further notation is defined in Fig. 3. 3Mada, the standard tool for Arabic s</context>
</contexts>
<marker>Andrew, Gao, 2007</marker>
<rawString>G. Andrew and J. Gao. 2007. Scalable training of ll-regularized log-linear models. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Avramidis</author>
<author>P Koehn</author>
</authors>
<title>Enriching morphologically poor languages for statistical machine translation.</title>
<date>2008</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2653" citStr="Avramidis and Koehn, 2008" startWordPosition="387" endWordPosition="390">tion. Although the translation has The car goes quickly Figure 1: Ungrammatical Arabic output of Google Translate for the English input The car goes quickly. The subject should agree with the verb in both gender and number, but the verb has masculine inflection. For clarity, the Arabic tokens are arranged left-to-right. the correct semantics, it is ultimately ungrammatical. This paper addresses the problem of generating text that conforms to morpho-syntactic agreement rules. Agreement relations that cross statistical phrase boundaries are not explicitly modeled in most phrasebased MT systems (Avramidis and Koehn, 2008). We address this shortcoming with an agreement model that scores sequences of fine-grained morphosyntactic classes. First, bound morphemes in translation hypotheses are segmented. Next, the segments are labeled with classes that encode both syntactic category information (i.e., parts of speech) and grammatical features such as number and gender. Finally, agreement is promoted by scoring the predicted class sequences with a generative Markov model. Our model scores hypotheses during decoding. Unlike previous models for scoring syntactic relations, our model does not require bitext annotations,</context>
</contexts>
<marker>Avramidis, Koehn, 2008</marker>
<rawString>E. Avramidis and P. Koehn. 2008. Enriching morphologically poor languages for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Birch</author>
<author>M Osborne</author>
<author>P Koehn</author>
</authors>
<title>CCG supertags in factored statistical machine translation.</title>
<date>2007</date>
<booktitle>In WMT.</booktitle>
<contexts>
<context position="19434" citStr="Birch et al. (2007)" startWordPosition="3042" endWordPosition="3045"> translation models (Koehn and Hoang, 2007) facilitate a more data-oriented approach to agreement modeling. Words are represented as a vector of features such as lemma and POS. The bitext is annotated with separate models, and the annotations are saved during phrase extraction. Hassan et al. (2007) noticed that the targetside POS sequences could be scored, much as we do in this work. They used a target-side LM over Combinatorial Categorial Grammar (CCG) supertags, along with a penalty for the number of operator violations, and also modified the phrase probabilities based on the tags. However, Birch et al. (2007) showed that this approach captures the same re-ordering phenomena as lexicalized re-ordering models, which were not included in the baseline. Birch et al. (2007) then investigated source-side CCG supertag features, but did not show an improvement for Dutch-English. Subotin (2011) recently extended factored translation models to hierarchical phrase-based translation and developed a discriminative model for predicting target-side morphology in English-Czech. His model benefited from gold morphological annotations on the target-side of the 8M sentence bitext. In contrast to these methods, our mo</context>
</contexts>
<marker>Birch, Osborne, Koehn, 2007</marker>
<rawString>A. Birch, M. Osborne, and P. Koehn. 2007. CCG supertags in factored statistical machine translation. In WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brants</author>
<author>A C Popat</author>
<author>P Xu</author>
<author>F J Och</author>
<author>J Dean</author>
</authors>
<title>Large language models in machine translation.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL.</booktitle>
<contexts>
<context position="26470" citStr="Brants et al., 2007" startWordPosition="4097" endWordPosition="4100">esults, we initialized MERT with uniform feature weights. We trained the translation model on 502 million words of parallel text collected from a variety of sources, including the Web. Word alignments were induced using a hidden Markov model based alignment model (Vogel et al., 1996) initialized with bilexical parameters from IBM Model 1 (Brown et al., 1993). Both alignment models were trained using two iterations of the expectation maximization algorithm. Our distributed 4-gram language model was trained on 600 million words of Arabic text, also collected from many sources including the Web (Brants et al., 2007). For development and evaluation, we used the NIST Arabic-English data sets, each of which contains one set of Arabic sentences and multiple English references. To reverse the translation direction for each data set, we chose the first English reference as the source and the Arabic as the reference. The NIST sets come in two varieties: newswire (MT02-05) and mixed genre (MT06,08). Newswire contains primarily Modern Standard Arabic (MSA), while the mixed genre data sets also contain transcribed speech and web text. Since the ATB contains MSA, and significant lexical and syntactic differences ma</context>
</contexts>
<marker>Brants, Popat, Xu, Och, Dean, 2007</marker>
<rawString>T. Brants, A. C. Popat, P. Xu, F. J. Och, and J. Dean. 2007. Large language models in machine translation. In EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>P V deSouza</author>
<author>R L Mercer</author>
<author>V J Della Pietra</author>
<author>J C Lai</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<pages>18--467</pages>
<contexts>
<context position="20174" citStr="Brown et al., 1992" startWordPosition="3147" endWordPosition="3150">uded in the baseline. Birch et al. (2007) then investigated source-side CCG supertag features, but did not show an improvement for Dutch-English. Subotin (2011) recently extended factored translation models to hierarchical phrase-based translation and developed a discriminative model for predicting target-side morphology in English-Czech. His model benefited from gold morphological annotations on the target-side of the 8M sentence bitext. In contrast to these methods, our model does not affect phrase extraction and does not require annotated translation rules. Class-based LMs Class-based LMs (Brown et al., 1992) reduce lexical sparsity by placing words in equivalence classes. They have been widely used for speech recognition, but not for MT. Och (1999) showed a method for inducing bilingual word classes that placed each phrase pair into a two-dimensional equivalence class. To our knowledge, Uszkoreit and Brants (2008) are the only recent authors to show an improvement in a state-of-the-art MT system using class-based LMs. They used a classical exchange algorithm for clustering, and learned 512 classes from 150 a large monolingual corpus. Then they mixed the classes into a word-based LM. However, both</context>
</contexts>
<marker>Brown, deSouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>P. F. Brown, P. V. deSouza, R. L. Mercer, V. J. Della Pietra, and J. C. Lai. 1992. Class-based n-gram models of natural language. Computational Linguistics, 18:467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>313</pages>
<contexts>
<context position="26210" citStr="Brown et al., 1993" startWordPosition="4057" endWordPosition="4060">s 1797 1360 3157 Table 3: Mixed genre test set results (BLEU-4 [%]). The MT06 result is statistically significant at p &lt; 0.01; MT08 is significant at p &lt; 0.02. The genres are: nw, broadcast news (bn), newsgroups (ng), and weblog (wb). 2008). For each set of results, we initialized MERT with uniform feature weights. We trained the translation model on 502 million words of parallel text collected from a variety of sources, including the Web. Word alignments were induced using a hidden Markov model based alignment model (Vogel et al., 1996) initialized with bilexical parameters from IBM Model 1 (Brown et al., 1993). Both alignment models were trained using two iterations of the expectation maximization algorithm. Our distributed 4-gram language model was trained on 600 million words of Arabic text, also collected from many sources including the Web (Brants et al., 2007). For development and evaluation, we used the NIST Arabic-English data sets, each of which contains one set of Arabic sentences and multiple English references. To reverse the translation direction for each data set, we chose the first English reference as the source and the Arabic as the reference. The NIST sets come in two varieties: ne</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263– 313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cer</author>
<author>M Galley</author>
<author>D Jurafsky</author>
<author>C D Manning</author>
</authors>
<title>Phrasal: A statistical machine translation toolkit for exploring new model features. In HLT-NAACL, Demonstration Session.</title>
<date>2010</date>
<contexts>
<context position="3453" citStr="Cer et al., 2010" startWordPosition="506" endWordPosition="509">xt, the segments are labeled with classes that encode both syntactic category information (i.e., parts of speech) and grammatical features such as number and gender. Finally, agreement is promoted by scoring the predicted class sequences with a generative Markov model. Our model scores hypotheses during decoding. Unlike previous models for scoring syntactic relations, our model does not require bitext annotations, phrase table features, or decoder modifications. The model can be implemented using the feature APIs of popular phrase-based decoders such as Moses (Koehn et al., 2007) and Phrasal (Cer et al., 2010). Intuition might suggest that the standard n-gram language model (LM) is sufficient to handle agreement phenomena. However, LM statistics are sparse, and they are made sparser by morphological variation. For English-to-Arabic translation, we achieve a +1.04 BLEU average improvement by tiling our model on top of a large LM. 146 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 146–155, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics It has also been suggested that this setting requires morphological generati</context>
</contexts>
<marker>Cer, Galley, Jurafsky, Manning, 2010</marker>
<rawString>D. Cer, M. Galley, D. Jurafsky, and C. D. Manning. 2010. Phrasal: A statistical machine translation toolkit for exploring new model features. In HLT-NAACL, Demonstration Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Clark</author>
<author>C Dyer</author>
<author>A Lavie</author>
<author>N A Smith</author>
</authors>
<title>Better hypothesis testing for statistical machine translation: Controlling for optimizer instability.</title>
<date>2011</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="28671" citStr="Clark et al. (2011)" startWordPosition="4438" endWordPosition="4441">ained insignificant gains. In the next section, we investigate this issue further. Tuning with a Treebank-Trained Feature The class-based model is trained on the ATB, which is predominantly MSA text. This data set is syntactically regular, meaning that it does not have highly dialectal content, foreign scripts, disfluencies, etc. Conversely, the mixed genre data sets contain more irregularities. For example, 57.4% of MT06 comes from nonnewswire genres. Of the 764 newsgroup sentences, 112 contain some Latin script tokens, while others contain very little morphology: 9With the implementation of Clark et al. (2011), available at: http://github.com/jhclark/multeval. 152 (2) ù�¢Ê b@ mix Mix 1/2 cup apple vinegar Start the program music match (MusicMatch) In these imperatives, there are no lexically marked agreement relations to score. Ex. (2) is an excerpt from a recipe that appears in full in MT06. Ex. (3) is part of usage instructions for the MusicMatch software. The ATB contains few examples like these, so our class-based model probably does not effectively discriminate between alternative hypotheses for these types of sentences. Phrase Table Coverage In a standard phrasebased system, effective transla</context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>J. H. Clark, C. Dyer, A. Lavie, and N. A. Smith. 2011. Better hypothesis testing for statistical machine translation: Controlling for optimizer instability. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Dyer</author>
</authors>
<title>Using a maximum entropy model to build segmentation lattices for MT.</title>
<date>2009</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="7967" citStr="Dyer, 2009" startWordPosition="1184" endWordPosition="1185">es as a unit during phrase extraction, but to score segmented morphemes separately for agreement. We treat segmentation as a character-level sequence modeling problem and train a linear-chain conditional random field (CRF) model (Lafferty et al., 2001). As a pre-processing step, we group contiguous non-native characters (e.g., Latin characters in Arabic text). The model assigns four labels: • I: Continuation of a morpheme • O: Outside morpheme (whitespace) • B: Beginning of a morpheme • F: Non-native character(s) 2Segmentation also improves translation of compounding languages such as German (Dyer, 2009) and Finnish (Macherey et al., 2011). 147 Translation Model e Target sequence of I words f Source sequence of J words a Sequence of K phrase alignments for (e, f) ri Permutation of the alignments for target word order e h Sequence of M feature functions λ Sequence of learned weights for the M features H A priority queue of hypotheses Class-based Agreement Model t E T Set of morpho-syntactic classes s E S Set of all word segments θseg Learned weights for the CRF-based segmenter θtag Learned weights for the CRF-based tagger φ , φt CRF potential functions (emission and transition) τ Sequence of I</context>
</contexts>
<marker>Dyer, 2009</marker>
<rawString>C. Dyer. 2009. Using a maximum entropy model to build segmentation lattices for MT. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A El Kholy</author>
<author>N Habash</author>
</authors>
<title>Orthographic and morphological processing for English-Arabic statistical machine translation.</title>
<date>2012</date>
<journal>Machine Translation,</journal>
<pages>26--1</pages>
<marker>El Kholy, Habash, 2012</marker>
<rawString>A. El Kholy and N. Habash. 2012. Orthographic and morphological processing for English-Arabic statistical machine translation. Machine Translation, 26(1-2):25–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Fraser</author>
<author>M Weller</author>
<author>A Cahill</author>
<author>F Cap</author>
</authors>
<title>Modeling inflection and word-formation in SMT.</title>
<date>2012</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="4180" citStr="Fraser et al., 2012" startWordPosition="616" endWordPosition="619">enomena. However, LM statistics are sparse, and they are made sparser by morphological variation. For English-to-Arabic translation, we achieve a +1.04 BLEU average improvement by tiling our model on top of a large LM. 146 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 146–155, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics It has also been suggested that this setting requires morphological generation because the bitext may not contain all inflected variants (Minkov et al., 2007; Toutanova et al., 2008; Fraser et al., 2012). However, using lexical coverage experiments, we show that there is ample room for translation quality improvements through better selection of forms that already exist in the translation model. 2 A Class-based Model of Agreement 2.1 Morpho-syntactic Agreement Morpho-syntactic agreement refers to a relationship between two sentence elements a and b that must have at least one matching grammatical feature.1 Agreement relations tend to be defined for particular syntactic configurations such as verb-subject, noun-adjective, and pronoun-antecedent. In some languages, agreement affects the surface</context>
</contexts>
<marker>Fraser, Weller, Cahill, Cap, 2012</marker>
<rawString>A. Fraser, M. Weller, A. Cahill, and F. Cap. 2012. Modeling inflection and word-formation in SMT. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Galley</author>
<author>C D Manning</author>
</authors>
<title>Quadratic-time dependency parsing for machine translation.</title>
<date>2009</date>
<booktitle>In ACL-IJCNLP.</booktitle>
<contexts>
<context position="12865" citStr="Galley and Manning, 2009" startWordPosition="1974" endWordPosition="1977">nder agreement). 4Case is also relevant to agreement in Arabic, but it is mostly indicated by diacritics, which are absent in unvocalized text. 148 2.4 Word Class Sequence Scoring The CRF tagger model defines a conditional distribution p(τ|e; θtag) for a class sequence τ given a sentence e and model parameters θtag. That is, the sample space is over class—not word—sequences. However, in MT, we seek a measure of sentence quality q(e) that is comparable across different hypotheses on the beam (much like the n-gram language model score). Discriminative model scores have been used as MT features (Galley and Manning, 2009), but we obtained better results by scoring the 1-best class sequences with a generative model. We trained a simple add-1 smoothed bigram language model over gold class sequences in the same treebank training data: I q(e) = p(τ) = p(τi|τi−1) i=1 We chose a bigram model due to the aggressive recombination strategy in our phrase-based decoder. For contexts in which the LM is guaranteed to back off (for instance, after an unseen bigram), our decoder maintains only the minimal state needed (perhaps only a single word). In less restrictive decoders, higher order scoring models could be used to scor</context>
<context position="21396" citStr="Galley and Manning (2009)" startWordPosition="3334" endWordPosition="3337">oth Och (1999) and Uszkoreit and Brants (2008) relied on automatically induced classes. It is unclear if their classes captured agreement information. Monz (2011) recently investigated parameter estimation for POS-based language models, but his classes did not include inflectional features. Target-Side Syntactic LMs Our agreement model is a form of syntactic LM, of which there is a long history of research, especially in speech processing.5 Syntactic LMs have traditionally been too slow for scoring during MT decoding. One exception was the quadratic-time dependency language model presented by Galley and Manning (2009). They applied a quadratic time dependency parser to every hypothesis during decoding. However, to achieve quadratic running time, they permitted ill-formed trees (e.g., parses with multiple roots). More recently, Schwartz et al. (2011) integrated a right-corner, incremental parser into Moses. They showed a large improvement for Urdu-English, but decoding slowed by three orders of magnitude.6 In contrast, our class-based model encodes shallow syntactic information without a noticeable effect on decoding time. Our model can be viewed as a way to score local syntactic relations without extensive</context>
</contexts>
<marker>Galley, Manning, 2009</marker>
<rawString>M. Galley and C. D. Manning. 2009. Quadratic-time dependency parsing for machine translation. In ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Green</author>
<author>C D Manning</author>
</authors>
<title>Better Arabic parsing: baselines, evaluations, and analysis.</title>
<date>2010</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="24635" citStr="Green and Manning, 2010" startWordPosition="3804" endWordPosition="3807">eatures must be removed from the tagger. Nonetheless, tagging accuracy only decreases by 0.1%. 5.2 Translation Quality Experimental Setup Our decoder is based on the phrase-based approach to translation (Och and Ney, 2004) and contains various feature functions including phrase relative frequency, word-level alignment statistics, and lexicalized re-ordering models (Tillmann, 2004; Och et al., 2004). We tuned the feature weights on a development set using lattice-based minimum error rate training (MERT) (Macherey et al., The data was pre-processed with packages from the Stanford Arabic parser (Green and Manning, 2010). The corpus split is available at http://nlp.stanford.edu/projects/arabic.shtml. 8We ignore orthographic re-normalization performed by the annotators. For example, they converted the contraction &apos;j, ll back to `CJI CJ&apos; l Al. As a result, we can report accuracy since the guess and gold segmentations have equal numbers of nonwhitespace characters. 151 MT04 (tune) MT02 MT03 MT05 Avg Baseline 18.14 23.87 18.88 22.60 +POS 18.11 −0.03 23.65 −0.22 18.99 +0.11 22.29 −0.31 −0.17 +POS+Agr 18.86 +0.72 24.84 +0.97 20.26 +1.38 23.48 +0.88 +1.04 genres nw nw nw nw #sentences 1353 728 663 1056 2447 Table 2:</context>
</contexts>
<marker>Green, Manning, 2010</marker>
<rawString>S. Green and C. D. Manning. 2010. Better Arabic parsing: baselines, evaluations, and analysis. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>O Rambow</author>
</authors>
<title>Arabic tokenization, part-ofspeech tagging and morphological disambiguation in one fell swoop.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="10107" citStr="Habash and Rambow, 2005" startWordPosition="1545" endWordPosition="1548">syntactic Tagging After segmentation, we tag each segment with a finegrained morpho-syntactic class. For this task we also train a standard CRF model on full sentences with gold classes and segmentation. We use the same QN procedure as before to obtain Btag. A translation derivation is a tuple (e, f, a) where e is the target, f is the source, and a is an alignment between the two. The CRF tagging model predicts a target-side class sequence T* I T* = arg max Btag - {0o(Ti, i, e) + Ot(Ti, Ti−1)} τ i=1 where further notation is defined in Fig. 3. 3Mada, the standard tool for Arabic segmentation (Habash and Rambow, 2005), relies on a manually compiled lexicon. Set of Classes The tagger assigns morpho-syntactic classes, which are coarse POS categories refined with grammatical features such as gender and definiteness. The coarse categories are the universal POS tag set described by Petrov et al. (2012). More than 25 treebanks (in 22 languages) can be automatically mapped to this tag set, which includes “Noun” (nominals), “Verb” (verbs), “Adj” (adjectives), and “ADP” (preand post-positions). Many of these treebanks also contain per-token morphological annotations. It is easy to combine the coarse categories with</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>N. Habash and O. Rambow. 2005. Arabic tokenization, part-ofspeech tagging and morphological disambiguation in one fell swoop. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>F Sadat</author>
</authors>
<title>Arabic preprocessing schemes for statistical machine translation.</title>
<date>2006</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="7114" citStr="Habash and Sadat, 2006" startWordPosition="1053" endWordPosition="1056">verb. Our model segments the raw token, tags each segment with a morpho-syntactic class (e.g., “Pron+Fem+Sg”), and then scores the class sequences. the single raw token in Fig. 2 contains at least four grammatically independent morphemes. Because the morphemes bear conflicting grammatical features and basic parts of speech (POS), we need to segment the token before we can evaluate agreement relations.2 Segmentation is typically applied as a bitext preprocessing step, and there is a rich literature on the effect of different segmentation schemata on translation quality (Koehn and Knight, 2003; Habash and Sadat, 2006; El Kholy and Habash, 2012). Unlike previous work, we segment each translation hypothesis as it is generated (i.e., during decoding). This permits greater modeling flexibility. For example, it may be useful to count tokens with bound morphemes as a unit during phrase extraction, but to score segmented morphemes separately for agreement. We treat segmentation as a character-level sequence modeling problem and train a linear-chain conditional random field (CRF) model (Lafferty et al., 2001). As a pre-processing step, we group contiguous non-native characters (e.g., Latin characters in Arabic te</context>
</contexts>
<marker>Habash, Sadat, 2006</marker>
<rawString>N. Habash and F. Sadat. 2006. Arabic preprocessing schemes for statistical machine translation. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hassan</author>
<author>K Sima&apos;an</author>
<author>A Way</author>
</authors>
<title>Supertagged phrasebased statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="19114" citStr="Hassan et al. (2007)" startWordPosition="2988" endWordPosition="2991">ules from them. They then specified manual unification rules, and applied a penalty according to the number of unification failures in a hypothesis. In contrast, our class-based model does not require any manual rules and scores similar agreement phenomena as probabilistic sequences. Factored Translation Models Factored translation models (Koehn and Hoang, 2007) facilitate a more data-oriented approach to agreement modeling. Words are represented as a vector of features such as lemma and POS. The bitext is annotated with separate models, and the annotations are saved during phrase extraction. Hassan et al. (2007) noticed that the targetside POS sequences could be scored, much as we do in this work. They used a target-side LM over Combinatorial Categorial Grammar (CCG) supertags, along with a penalty for the number of operator violations, and also modified the phrase probabilities based on the tags. However, Birch et al. (2007) showed that this approach captures the same re-ordering phenomena as lexicalized re-ordering models, which were not included in the baseline. Birch et al. (2007) then investigated source-side CCG supertag features, but did not show an improvement for Dutch-English. Subotin (2011</context>
</contexts>
<marker>Hassan, Sima&apos;an, Way, 2007</marker>
<rawString>H. Hassan, K. Sima&apos;an, and A. Way. 2007. Supertagged phrasebased statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnson</author>
</authors>
<title>Learning and parsing stochastic unificationbased grammars.</title>
<date>2003</date>
<booktitle>In COLT.</booktitle>
<contexts>
<context position="18099" citStr="Johnson (2003)" startWordPosition="2841" endWordPosition="2842">s sequence. We also add a new length penalty feature. To discriminate between hypotheses that might have the same number of raw tokens, but different underlying segmentations, we add a penalty equal to the length difference between the segmented and unsegmented . attachments s1 − en+1 4 Related Work We compare our class-based model to previous approaches to scoring syntactic relations in MT. Unification-based Formalisms Agreement rules impose syntactic and semantic constraints on the structure of sentences. A principled way to model these constraints is with a unification-based grammar (UBG). Johnson (2003) presented algorithms for learning and parsing with stochastic UBGs. However, training data for these formalisms remains extremely limited, and it is unclear how to learn such knowledgerich representations from unlabeled data. One partial solution is to manually extract unification rules from phrase-structure trees. Williams and Koehn (2011) annotated German trees, and extracted translation rules from them. They then specified manual unification rules, and applied a penalty according to the number of unification failures in a hypothesis. In contrast, our class-based model does not require any </context>
</contexts>
<marker>Johnson, 2003</marker>
<rawString>M. Johnson. 2003. Learning and parsing stochastic unificationbased grammars. In COLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
</authors>
<title>Factored translation models.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL.</booktitle>
<contexts>
<context position="18858" citStr="Koehn and Hoang, 2007" startWordPosition="2948" endWordPosition="2951">d, and it is unclear how to learn such knowledgerich representations from unlabeled data. One partial solution is to manually extract unification rules from phrase-structure trees. Williams and Koehn (2011) annotated German trees, and extracted translation rules from them. They then specified manual unification rules, and applied a penalty according to the number of unification failures in a hypothesis. In contrast, our class-based model does not require any manual rules and scores similar agreement phenomena as probabilistic sequences. Factored Translation Models Factored translation models (Koehn and Hoang, 2007) facilitate a more data-oriented approach to agreement modeling. Words are represented as a vector of features such as lemma and POS. The bitext is annotated with separate models, and the annotations are saved during phrase extraction. Hassan et al. (2007) noticed that the targetside POS sequences could be scored, much as we do in this work. They used a target-side LM over Combinatorial Categorial Grammar (CCG) supertags, along with a penalty for the number of operator violations, and also modified the phrase probabilities based on the tags. However, Birch et al. (2007) showed that this approa</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>P. Koehn and H. Hoang. 2007. Factored translation models. In EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>K Knight</author>
</authors>
<title>Empirical methods for compound splitting.</title>
<date>2003</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="7090" citStr="Koehn and Knight, 2003" startWordPosition="1049" endWordPosition="1052">ject and plural for the verb. Our model segments the raw token, tags each segment with a morpho-syntactic class (e.g., “Pron+Fem+Sg”), and then scores the class sequences. the single raw token in Fig. 2 contains at least four grammatically independent morphemes. Because the morphemes bear conflicting grammatical features and basic parts of speech (POS), we need to segment the token before we can evaluate agreement relations.2 Segmentation is typically applied as a bitext preprocessing step, and there is a rich literature on the effect of different segmentation schemata on translation quality (Koehn and Knight, 2003; Habash and Sadat, 2006; El Kholy and Habash, 2012). Unlike previous work, we segment each translation hypothesis as it is generated (i.e., during decoding). This permits greater modeling flexibility. For example, it may be useful to count tokens with bound morphemes as a unit during phrase extraction, but to score segmented morphemes separately for agreement. We treat segmentation as a character-level sequence modeling problem and train a linear-chain conditional random field (CRF) model (Lafferty et al., 2001). As a pre-processing step, we group contiguous non-native characters (e.g., Latin</context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>P. Koehn and K. Knight. 2003. Empirical methods for compound splitting. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL, Demonstration Session.</booktitle>
<contexts>
<context position="3422" citStr="Koehn et al., 2007" startWordPosition="500" endWordPosition="503">tion hypotheses are segmented. Next, the segments are labeled with classes that encode both syntactic category information (i.e., parts of speech) and grammatical features such as number and gender. Finally, agreement is promoted by scoring the predicted class sequences with a generative Markov model. Our model scores hypotheses during decoding. Unlike previous models for scoring syntactic relations, our model does not require bitext annotations, phrase table features, or decoder modifications. The model can be implemented using the feature APIs of popular phrase-based decoders such as Moses (Koehn et al., 2007) and Phrasal (Cer et al., 2010). Intuition might suggest that the standard n-gram language model (LM) is sufficient to handle agreement phenomena. However, LM statistics are sparse, and they are made sparser by morphological variation. For English-to-Arabic translation, we achieve a +1.04 BLEU average improvement by tiling our model on top of a large LM. 146 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 146–155, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics It has also been suggested that this setting </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, et al. 2007. Moses: Open source toolkit for statistical machine translation. In ACL, Demonstration Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probablistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="7608" citStr="Lafferty et al., 2001" startWordPosition="1128" endWordPosition="1131">terature on the effect of different segmentation schemata on translation quality (Koehn and Knight, 2003; Habash and Sadat, 2006; El Kholy and Habash, 2012). Unlike previous work, we segment each translation hypothesis as it is generated (i.e., during decoding). This permits greater modeling flexibility. For example, it may be useful to count tokens with bound morphemes as a unit during phrase extraction, but to score segmented morphemes separately for agreement. We treat segmentation as a character-level sequence modeling problem and train a linear-chain conditional random field (CRF) model (Lafferty et al., 2001). As a pre-processing step, we group contiguous non-native characters (e.g., Latin characters in Arabic text). The model assigns four labels: • I: Continuation of a morpheme • O: Outside morpheme (whitespace) • B: Beginning of a morpheme • F: Non-native character(s) 2Segmentation also improves translation of compounding languages such as German (Dyer, 2009) and Finnish (Macherey et al., 2011). 147 Translation Model e Target sequence of I words f Source sequence of J words a Sequence of K phrase alignments for (e, f) ri Permutation of the alignments for target word order e h Sequence of M featu</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probablistic models for segmenting and labeling sequence data. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lopez</author>
</authors>
<title>Statistical machine translation.</title>
<date>2008</date>
<journal>ACM Computing Surveys,</journal>
<volume>40</volume>
<issue>8</issue>
<contexts>
<context position="1379" citStr="Lopez, 2008" startWordPosition="193" endWordPosition="194">-Arabic translation, our model yields a +1.04 BLEU average improvement over a state-of-the-art baseline. The model does not require bitext or phrase table annotations and can be easily implemented as a feature in many phrase-based decoders. 1 Introduction Languages vary in the degree to which surface forms reflect grammatical relations. English is a weakly inflected language: it has a narrow verbal paradigm, restricted nominal inflection (plurals), and only the vestiges of a case system. Consequently, translation into English—which accounts for much of the machine translation (MT) literature (Lopez, 2008)—often involves some amount of morpho-syntactic dimensionality reduction. Less attention has been paid to what happens during translation from English: richer grammatical features such as gender, dual number, and overt case are effectively latent variables that must be inferred during decoding. Consider the output of Google Translate for the simple English sentence in Fig. 1. The correct translation is a monotone mapping of the input. However, in Arabic, SVO word order requires both gender and number agreement between the subject oPAJ�‚Ë@ ‘the car’ and verb I. ë aK `go&apos;. The MT system selects </context>
</contexts>
<marker>Lopez, 2008</marker>
<rawString>A. Lopez. 2008. Statistical machine translation. ACM Computing Surveys, 40(8):1–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Maamouri</author>
<author>A Bies</author>
<author>T Buckwalter</author>
<author>W Mekki</author>
</authors>
<title>The Penn Arabic Treebank: Building a large-scale annotated Arabic corpus.</title>
<date>2004</date>
<booktitle>In NEMLAR.</booktitle>
<contexts>
<context position="22497" citStr="Maamouri et al., 2004" startWordPosition="3490" endWordPosition="3493">noticeable effect on decoding time. Our model can be viewed as a way to score local syntactic relations without extensive decoder modifications. For long-distance relations, Shen et al. (2010) proposed a new decoder that generates target-side dependency trees. The target-side structure enables scoring hypotheses with a trigram dependency LM. 5 Experiments We first evaluate the Arabic segmenter and tagger components independently, then provide EnglishArabic translation quality results. 5.1 Intrinsic Evaluation of Components Experimental Setup All experiments use the Penn Arabic Treebank (ATB) (Maamouri et al., 2004) parts 1–3 divided into training/dev/test sections according to the canonical split (Rambow et al., 2005).7 5See (Zhang, 2009) for a comprehensive survey. 6In principle, their parser should run in linear time. An implementation issue may account for the decoding slowdown. (p.c.) 7LDC catalog numbers: LDC2008E61 (ATBp1v4), LDC2008E62 (ATBp2v3), and LDC2008E22 (ATBp3v3.1). FULL (%) INCREMENTAL (%) Segmenter 98.6 – Tagger 96.3 96.2 Table 1: Intrinsic evaluation accuracy [%] (development set) for Arabic segmentation and tagging. The ATB contains clitic-segmented text with persegment morphological </context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, Mekki, 2004</marker>
<rawString>M. Maamouri, A. Bies, T. Buckwalter, and W. Mekki. 2004. The Penn Arabic Treebank: Building a large-scale annotated Arabic corpus. In NEMLAR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Macherey</author>
<author>F Och</author>
<author>I Thayer</author>
<author>J Uszkoreit</author>
</authors>
<title>Latticebased minimum error rate training for statistical machine translation.</title>
<date>2008</date>
<booktitle>In EMNLP.</booktitle>
<marker>Macherey, Och, Thayer, Uszkoreit, 2008</marker>
<rawString>W. Macherey, F. Och, I. Thayer, and J. Uszkoreit. 2008. Latticebased minimum error rate training for statistical machine translation. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Macherey</author>
<author>A Dai</author>
<author>D Talbot</author>
<author>A Popat</author>
<author>F Och</author>
</authors>
<title>Language-independent compound splitting with morphological operations.</title>
<date>2011</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="8003" citStr="Macherey et al., 2011" startWordPosition="1188" endWordPosition="1191">e extraction, but to score segmented morphemes separately for agreement. We treat segmentation as a character-level sequence modeling problem and train a linear-chain conditional random field (CRF) model (Lafferty et al., 2001). As a pre-processing step, we group contiguous non-native characters (e.g., Latin characters in Arabic text). The model assigns four labels: • I: Continuation of a morpheme • O: Outside morpheme (whitespace) • B: Beginning of a morpheme • F: Non-native character(s) 2Segmentation also improves translation of compounding languages such as German (Dyer, 2009) and Finnish (Macherey et al., 2011). 147 Translation Model e Target sequence of I words f Source sequence of J words a Sequence of K phrase alignments for (e, f) ri Permutation of the alignments for target word order e h Sequence of M feature functions λ Sequence of learned weights for the M features H A priority queue of hypotheses Class-based Agreement Model t E T Set of morpho-syntactic classes s E S Set of all word segments θseg Learned weights for the CRF-based segmenter θtag Learned weights for the CRF-based tagger φ , φt CRF potential functions (emission and transition) τ Sequence of I target-side predicted classes π T d</context>
</contexts>
<marker>Macherey, Dai, Talbot, Popat, Och, 2011</marker>
<rawString>K. Macherey, A. Dai, D. Talbot, A. Popat, and F. Och. 2011. Language-independent compound splitting with morphological operations. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Minkov</author>
<author>K Toutanova</author>
<author>H Suzuki</author>
</authors>
<title>Generating complex morphology for machine translation.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="4134" citStr="Minkov et al., 2007" startWordPosition="608" endWordPosition="611">del (LM) is sufficient to handle agreement phenomena. However, LM statistics are sparse, and they are made sparser by morphological variation. For English-to-Arabic translation, we achieve a +1.04 BLEU average improvement by tiling our model on top of a large LM. 146 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 146–155, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics It has also been suggested that this setting requires morphological generation because the bitext may not contain all inflected variants (Minkov et al., 2007; Toutanova et al., 2008; Fraser et al., 2012). However, using lexical coverage experiments, we show that there is ample room for translation quality improvements through better selection of forms that already exist in the translation model. 2 A Class-based Model of Agreement 2.1 Morpho-syntactic Agreement Morpho-syntactic agreement refers to a relationship between two sentence elements a and b that must have at least one matching grammatical feature.1 Agreement relations tend to be defined for particular syntactic configurations such as verb-subject, noun-adjective, and pronoun-antecedent. In</context>
</contexts>
<marker>Minkov, Toutanova, Suzuki, 2007</marker>
<rawString>E. Minkov, K. Toutanova, and H. Suzuki. 2007. Generating complex morphology for machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Monz</author>
</authors>
<title>Statistical machine translation with local language models.</title>
<date>2011</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="20933" citStr="Monz (2011)" startWordPosition="3267" endWordPosition="3268">ed a method for inducing bilingual word classes that placed each phrase pair into a two-dimensional equivalence class. To our knowledge, Uszkoreit and Brants (2008) are the only recent authors to show an improvement in a state-of-the-art MT system using class-based LMs. They used a classical exchange algorithm for clustering, and learned 512 classes from 150 a large monolingual corpus. Then they mixed the classes into a word-based LM. However, both Och (1999) and Uszkoreit and Brants (2008) relied on automatically induced classes. It is unclear if their classes captured agreement information. Monz (2011) recently investigated parameter estimation for POS-based language models, but his classes did not include inflectional features. Target-Side Syntactic LMs Our agreement model is a form of syntactic LM, of which there is a long history of research, especially in speech processing.5 Syntactic LMs have traditionally been too slow for scoring during MT decoding. One exception was the quadratic-time dependency language model presented by Galley and Manning (2009). They applied a quadratic time dependency parser to every hypothesis during decoding. However, to achieve quadratic running time, they p</context>
</contexts>
<marker>Monz, 2011</marker>
<rawString>C. Monz. 2011. Statistical machine translation with local language models. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="13956" citStr="Och and Ney, 2004" startWordPosition="2143" endWordPosition="2146">imal state needed (perhaps only a single word). In less restrictive decoders, higher order scoring models could be used to score longerdistance agreement relations. We integrate the segmentation, tagging, and scoring models into a self-contained component in the translation decoder. 3 Inference during Translation Decoding Scoring the agreement model as part of translation decoding requires a novel inference procedure. Crucially, the inference procedure does not measurably affect total MT decoding time. 3.1 Phrase-based Translation Decoding We consider the standard phrase-based approach to MT (Och and Ney, 2004). The distribution p(e|f) is modeled directly using a log-linear model, yielding the following decision rule: � M e* = arg max λmhm(e, f, a, lI) (1) e,a,ll m=1 This decoding problem is NP-hard, thus a beam search is often used (Fig. 4). The beam search relies on three operations, two of which affect the agreement model: Input: implicitly defined search space generate initial hypotheses and add to H set Hfinal to 0 while H is not empty: set Hext to 0 for each hypothesis η in H: if η is a goal hypothesis: add η to Hfinal else Extend η and add to Hext lo-Score agreement Recombine and Prune Hext s</context>
<context position="15455" citStr="Och and Ney, 2004" startWordPosition="2411" endWordPosition="2414">s, t) for translation prefix en1 initialize π to −oo set π(t) = 0 compute τ* from parameters (s, SL1 , π, is_goal) compute q(eIn+1) = p(τ*) under the generative LM set model state σnew = (SL, τ*L) for prefix eI1 Output: q(eIn+1) Figure 5: Procedure for scoring agreement for each hypothesis generated during the search algorithm of Fig. 4. In the extended hypothesis e�1, the index n + 1 indicates the start of the new attachment. • Extend a hypothesis with a new phrase pair • Recombine hypotheses with identical states We assume familiarity with these operations, which are described in detail in (Och and Ney, 2004). 3.2 Agreement Model Inference The class-based agreement model is implemented as a feature function hm in Eq. (1). Specifically, when Extend generates a new hypothesis, we run the algorithm shown in Fig. 5. The inputs are a translation hypothesis eI1, an index n distinguishing the prefix from the attachment, and a flag indicating if their concatenation is a goal hypothesis. The beam search maintains state for each derivation, the score of which is a linear combination of the feature values. States in this program depend on some amount of lexical history. With a trigram language model, the sta</context>
<context position="24233" citStr="Och and Ney, 2004" startWordPosition="3745" endWordPosition="3748">FULL is a standard evaluation in which features may be defined over the whole sentence. This includes next-character segmenter features and nextword tagger features. INCREMENTAL emulates the MT setting in which the models are restricted to current and previous observation features. Since the segmenter operates at the character level, we can use the same feature set. However, next-observation features must be removed from the tagger. Nonetheless, tagging accuracy only decreases by 0.1%. 5.2 Translation Quality Experimental Setup Our decoder is based on the phrase-based approach to translation (Och and Ney, 2004) and contains various feature functions including phrase relative frequency, word-level alignment statistics, and lexicalized re-ordering models (Tillmann, 2004; Och et al., 2004). We tuned the feature weights on a development set using lattice-based minimum error rate training (MERT) (Macherey et al., The data was pre-processed with packages from the Stanford Arabic parser (Green and Manning, 2010). The corpus split is available at http://nlp.stanford.edu/projects/arabic.shtml. 8We ignore orthographic re-normalization performed by the annotators. For example, they converted the contraction &apos;j</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>F. J. Och and H. Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4):417–449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>D Gildea</author>
<author>S Khudanpur</author>
<author>A Sarkar</author>
<author>K Yamada</author>
<author>A Fraser</author>
</authors>
<title>A smorgasbord of features for statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="24412" citStr="Och et al., 2004" startWordPosition="3769" endWordPosition="3772">ulates the MT setting in which the models are restricted to current and previous observation features. Since the segmenter operates at the character level, we can use the same feature set. However, next-observation features must be removed from the tagger. Nonetheless, tagging accuracy only decreases by 0.1%. 5.2 Translation Quality Experimental Setup Our decoder is based on the phrase-based approach to translation (Och and Ney, 2004) and contains various feature functions including phrase relative frequency, word-level alignment statistics, and lexicalized re-ordering models (Tillmann, 2004; Och et al., 2004). We tuned the feature weights on a development set using lattice-based minimum error rate training (MERT) (Macherey et al., The data was pre-processed with packages from the Stanford Arabic parser (Green and Manning, 2010). The corpus split is available at http://nlp.stanford.edu/projects/arabic.shtml. 8We ignore orthographic re-normalization performed by the annotators. For example, they converted the contraction &apos;j, ll back to `CJI CJ&apos; l Al. As a result, we can report accuracy since the guess and gold segmentations have equal numbers of nonwhitespace characters. 151 MT04 (tune) MT02 MT03 MT</context>
</contexts>
<marker>Och, Gildea, Khudanpur, Sarkar, Yamada, Fraser, 2004</marker>
<rawString>F. J. Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Yamada, A. Fraser, et al. 2004. A smorgasbord of features for statistical machine translation. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>An efficient method for determining bilingual word classes.</title>
<date>1999</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="20317" citStr="Och (1999)" startWordPosition="3172" endWordPosition="3173">n (2011) recently extended factored translation models to hierarchical phrase-based translation and developed a discriminative model for predicting target-side morphology in English-Czech. His model benefited from gold morphological annotations on the target-side of the 8M sentence bitext. In contrast to these methods, our model does not affect phrase extraction and does not require annotated translation rules. Class-based LMs Class-based LMs (Brown et al., 1992) reduce lexical sparsity by placing words in equivalence classes. They have been widely used for speech recognition, but not for MT. Och (1999) showed a method for inducing bilingual word classes that placed each phrase pair into a two-dimensional equivalence class. To our knowledge, Uszkoreit and Brants (2008) are the only recent authors to show an improvement in a state-of-the-art MT system using class-based LMs. They used a classical exchange algorithm for clustering, and learned 512 classes from 150 a large monolingual corpus. Then they mixed the classes into a word-based LM. However, both Och (1999) and Uszkoreit and Brants (2008) relied on automatically induced classes. It is unclear if their classes captured agreement informat</context>
</contexts>
<marker>Och, 1999</marker>
<rawString>F. J. Och. 1999. An efficient method for determining bilingual word classes. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="27250" citStr="Papineni et al., 2002" startWordPosition="4221" endWordPosition="4225">s. To reverse the translation direction for each data set, we chose the first English reference as the source and the Arabic as the reference. The NIST sets come in two varieties: newswire (MT02-05) and mixed genre (MT06,08). Newswire contains primarily Modern Standard Arabic (MSA), while the mixed genre data sets also contain transcribed speech and web text. Since the ATB contains MSA, and significant lexical and syntactic differences may exist between MSA and the mixed genres, we achieved best results by tuning on MT04, the largest newswire set. We evaluated translation quality with BLEU-4 (Papineni et al., 2002) and computed statistical significance with the approximate randomization method of Riezler and Maxwell (2005).9 6 Discussion of Translation Results Tbl. 2 shows translation quality results on newswire, while Tbl. 3 contains results for mixed genres. The baseline is our standard system feature set. For comparison, +POS indicates our class-based model trained on the 11 coarse POS tags only (e.g., “Noun”). Finally, +POS+Agr shows the class-based model with the fine-grained classes (e.g., “Noun+Fem+Sg”). The best result—a +1.04 BLEU average gain— was achieved when the class-based model training d</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Peng</author>
<author>F Feng</author>
<author>A McCallum</author>
</authors>
<title>Chinese segmentation and new word detection using conditional random fields.</title>
<date>2004</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="9139" citStr="Peng et al., 2004" startWordPosition="1378" endWordPosition="1381">ions (emission and transition) τ Sequence of I target-side predicted classes π T dimensional (log) prior distribution over classes s� Sequence of l word segments σ Model state: a tagged segment (s, t) Figure 3: Notation used in this paper. The convention eZ indicates a subsequence of a length I sequence. The features are indicators for (character, position, label) triples for a five character window and bigram label transition indicators. This formulation is inspired by the classic “IOB” text chunking model (Ramshaw and Marcus, 1995), which has been previously applied to Chinese segmentation (Peng et al., 2004). It can be learned from gold-segmented data, generally applies to languages with bound morphemes, and does not require a handcompiled lexicon.3 Moreover, it has only four labels, so Viterbi decoding is very fast. We learn the parameters Bseg using a quasi-Newton (QN) procedure with h (lasso) regularization (Andrew and Gao, 2007). 2.3 Morpho-syntactic Tagging After segmentation, we tag each segment with a finegrained morpho-syntactic class. For this task we also train a standard CRF model on full sentences with gold classes and segmentation. We use the same QN procedure as before to obtain Bta</context>
</contexts>
<marker>Peng, Feng, McCallum, 2004</marker>
<rawString>F. Peng, F. Feng, and A. McCallum. 2004. Chinese segmentation and new word detection using conditional random fields. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Das</author>
<author>R McDonald</author>
</authors>
<title>A universal part-ofspeech tagset.</title>
<date>2012</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="10392" citStr="Petrov et al. (2012)" startWordPosition="1588" endWordPosition="1591">tuple (e, f, a) where e is the target, f is the source, and a is an alignment between the two. The CRF tagging model predicts a target-side class sequence T* I T* = arg max Btag - {0o(Ti, i, e) + Ot(Ti, Ti−1)} τ i=1 where further notation is defined in Fig. 3. 3Mada, the standard tool for Arabic segmentation (Habash and Rambow, 2005), relies on a manually compiled lexicon. Set of Classes The tagger assigns morpho-syntactic classes, which are coarse POS categories refined with grammatical features such as gender and definiteness. The coarse categories are the universal POS tag set described by Petrov et al. (2012). More than 25 treebanks (in 22 languages) can be automatically mapped to this tag set, which includes “Noun” (nominals), “Verb” (verbs), “Adj” (adjectives), and “ADP” (preand post-positions). Many of these treebanks also contain per-token morphological annotations. It is easy to combine the coarse categories with selected grammatical annotations. For Arabic, we used the coarse POS tags plus definiteness and the so-called phi features (gender, number, and person).4 For example, 3.����JI ‘the car’ would be tagged “Noun+Def+Sg+Fem”. We restricted the set of classes to observed combinations in th</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>S. Petrov, D. Das, and R. McDonald. 2012. A universal part-ofspeech tagset. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Rambow</author>
<author>D Chiang</author>
<author>M Diab</author>
<author>N Habash</author>
<author>R Hwa</author>
</authors>
<title>Parsing Arabic dialects.</title>
<date>2005</date>
<tech>Technical report,</tech>
<institution>Johns Hopkins University.</institution>
<contexts>
<context position="22602" citStr="Rambow et al., 2005" startWordPosition="3505" endWordPosition="3508">hout extensive decoder modifications. For long-distance relations, Shen et al. (2010) proposed a new decoder that generates target-side dependency trees. The target-side structure enables scoring hypotheses with a trigram dependency LM. 5 Experiments We first evaluate the Arabic segmenter and tagger components independently, then provide EnglishArabic translation quality results. 5.1 Intrinsic Evaluation of Components Experimental Setup All experiments use the Penn Arabic Treebank (ATB) (Maamouri et al., 2004) parts 1–3 divided into training/dev/test sections according to the canonical split (Rambow et al., 2005).7 5See (Zhang, 2009) for a comprehensive survey. 6In principle, their parser should run in linear time. An implementation issue may account for the decoding slowdown. (p.c.) 7LDC catalog numbers: LDC2008E61 (ATBp1v4), LDC2008E62 (ATBp2v3), and LDC2008E22 (ATBp3v3.1). FULL (%) INCREMENTAL (%) Segmenter 98.6 – Tagger 96.3 96.2 Table 1: Intrinsic evaluation accuracy [%] (development set) for Arabic segmentation and tagging. The ATB contains clitic-segmented text with persegment morphological analyses (in addition to phrase-structure trees, which we discard). For training the segmenter, we used m</context>
</contexts>
<marker>Rambow, Chiang, Diab, Habash, Hwa, 2005</marker>
<rawString>O. Rambow, D. Chiang, M. Diab, N. Habash, R. Hwa, et al. 2005. Parsing Arabic dialects. Technical report, Johns Hopkins University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ramshaw</author>
<author>M Marcus</author>
</authors>
<title>Text chunking using transformation-based learning.</title>
<date>1995</date>
<booktitle>In Proc. of the Third Workshop on Very Large Corpora.</booktitle>
<contexts>
<context position="9060" citStr="Ramshaw and Marcus, 1995" startWordPosition="1365" endWordPosition="1368">sed segmenter θtag Learned weights for the CRF-based tagger φ , φt CRF potential functions (emission and transition) τ Sequence of I target-side predicted classes π T dimensional (log) prior distribution over classes s� Sequence of l word segments σ Model state: a tagged segment (s, t) Figure 3: Notation used in this paper. The convention eZ indicates a subsequence of a length I sequence. The features are indicators for (character, position, label) triples for a five character window and bigram label transition indicators. This formulation is inspired by the classic “IOB” text chunking model (Ramshaw and Marcus, 1995), which has been previously applied to Chinese segmentation (Peng et al., 2004). It can be learned from gold-segmented data, generally applies to languages with bound morphemes, and does not require a handcompiled lexicon.3 Moreover, it has only four labels, so Viterbi decoding is very fast. We learn the parameters Bseg using a quasi-Newton (QN) procedure with h (lasso) regularization (Andrew and Gao, 2007). 2.3 Morpho-syntactic Tagging After segmentation, we tag each segment with a finegrained morpho-syntactic class. For this task we also train a standard CRF model on full sentences with gold</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>L. A. Ramshaw and M. Marcus. 1995. Text chunking using transformation-based learning. In Proc. of the Third Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riezler</author>
<author>J T Maxwell</author>
</authors>
<title>On some pitfalls in automatic evaluation and significance testing in MT.</title>
<date>2005</date>
<booktitle>In ACL-05 Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization (MTSE).</booktitle>
<contexts>
<context position="27360" citStr="Riezler and Maxwell (2005)" startWordPosition="4237" endWordPosition="4240">rce and the Arabic as the reference. The NIST sets come in two varieties: newswire (MT02-05) and mixed genre (MT06,08). Newswire contains primarily Modern Standard Arabic (MSA), while the mixed genre data sets also contain transcribed speech and web text. Since the ATB contains MSA, and significant lexical and syntactic differences may exist between MSA and the mixed genres, we achieved best results by tuning on MT04, the largest newswire set. We evaluated translation quality with BLEU-4 (Papineni et al., 2002) and computed statistical significance with the approximate randomization method of Riezler and Maxwell (2005).9 6 Discussion of Translation Results Tbl. 2 shows translation quality results on newswire, while Tbl. 3 contains results for mixed genres. The baseline is our standard system feature set. For comparison, +POS indicates our class-based model trained on the 11 coarse POS tags only (e.g., “Noun”). Finally, +POS+Agr shows the class-based model with the fine-grained classes (e.g., “Noun+Fem+Sg”). The best result—a +1.04 BLEU average gain— was achieved when the class-based model training data, MT tuning set, and MT evaluation set contained the same genre. We realized smaller, yet statistically sig</context>
</contexts>
<marker>Riezler, Maxwell, 2005</marker>
<rawString>S. Riezler and J. T. Maxwell. 2005. On some pitfalls in automatic evaluation and significance testing in MT. In ACL-05 Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization (MTSE).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Schwartz</author>
<author>C Callison-Burch</author>
<author>W Schuler</author>
<author>S Wu</author>
</authors>
<title>Incremental syntactic language models for phrase-based translation.</title>
<date>2011</date>
<booktitle>In ACL-HLT.</booktitle>
<contexts>
<context position="21632" citStr="Schwartz et al. (2011)" startWordPosition="3368" endWordPosition="3371">t his classes did not include inflectional features. Target-Side Syntactic LMs Our agreement model is a form of syntactic LM, of which there is a long history of research, especially in speech processing.5 Syntactic LMs have traditionally been too slow for scoring during MT decoding. One exception was the quadratic-time dependency language model presented by Galley and Manning (2009). They applied a quadratic time dependency parser to every hypothesis during decoding. However, to achieve quadratic running time, they permitted ill-formed trees (e.g., parses with multiple roots). More recently, Schwartz et al. (2011) integrated a right-corner, incremental parser into Moses. They showed a large improvement for Urdu-English, but decoding slowed by three orders of magnitude.6 In contrast, our class-based model encodes shallow syntactic information without a noticeable effect on decoding time. Our model can be viewed as a way to score local syntactic relations without extensive decoder modifications. For long-distance relations, Shen et al. (2010) proposed a new decoder that generates target-side dependency trees. The target-side structure enables scoring hypotheses with a trigram dependency LM. 5 Experiments</context>
</contexts>
<marker>Schwartz, Callison-Burch, Schuler, Wu, 2011</marker>
<rawString>L. Schwartz, C. Callison-Burch, W. Schuler, and S. Wu. 2011. Incremental syntactic language models for phrase-based translation. In ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
<author>J Xu</author>
<author>R Weischedel</author>
</authors>
<title>String-to-dependency statistical machine translation.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>4</issue>
<contexts>
<context position="22067" citStr="Shen et al. (2010)" startWordPosition="3432" endWordPosition="3435">every hypothesis during decoding. However, to achieve quadratic running time, they permitted ill-formed trees (e.g., parses with multiple roots). More recently, Schwartz et al. (2011) integrated a right-corner, incremental parser into Moses. They showed a large improvement for Urdu-English, but decoding slowed by three orders of magnitude.6 In contrast, our class-based model encodes shallow syntactic information without a noticeable effect on decoding time. Our model can be viewed as a way to score local syntactic relations without extensive decoder modifications. For long-distance relations, Shen et al. (2010) proposed a new decoder that generates target-side dependency trees. The target-side structure enables scoring hypotheses with a trigram dependency LM. 5 Experiments We first evaluate the Arabic segmenter and tagger components independently, then provide EnglishArabic translation quality results. 5.1 Intrinsic Evaluation of Components Experimental Setup All experiments use the Penn Arabic Treebank (ATB) (Maamouri et al., 2004) parts 1–3 divided into training/dev/test sections according to the canonical split (Rambow et al., 2005).7 5See (Zhang, 2009) for a comprehensive survey. 6In principle, </context>
</contexts>
<marker>Shen, Xu, Weischedel, 2010</marker>
<rawString>L. Shen, J. Xu, and R. Weischedel. 2010. String-to-dependency statistical machine translation. Computational Linguistics, 36(4):649–671.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Subotin</author>
</authors>
<title>An exponential translation model for target language morphology.</title>
<date>2011</date>
<booktitle>In ACL-HLT.</booktitle>
<contexts>
<context position="19715" citStr="Subotin (2011)" startWordPosition="3085" endWordPosition="3086">et al. (2007) noticed that the targetside POS sequences could be scored, much as we do in this work. They used a target-side LM over Combinatorial Categorial Grammar (CCG) supertags, along with a penalty for the number of operator violations, and also modified the phrase probabilities based on the tags. However, Birch et al. (2007) showed that this approach captures the same re-ordering phenomena as lexicalized re-ordering models, which were not included in the baseline. Birch et al. (2007) then investigated source-side CCG supertag features, but did not show an improvement for Dutch-English. Subotin (2011) recently extended factored translation models to hierarchical phrase-based translation and developed a discriminative model for predicting target-side morphology in English-Czech. His model benefited from gold morphological annotations on the target-side of the 8M sentence bitext. In contrast to these methods, our model does not affect phrase extraction and does not require annotated translation rules. Class-based LMs Class-based LMs (Brown et al., 1992) reduce lexical sparsity by placing words in equivalence classes. They have been widely used for speech recognition, but not for MT. Och (199</context>
</contexts>
<marker>Subotin, 2011</marker>
<rawString>M. Subotin. 2011. An exponential translation model for target language morphology. In ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Tillmann</author>
</authors>
<title>A unigram orientation model for statistical machine translation.</title>
<date>2004</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="24393" citStr="Tillmann, 2004" startWordPosition="3766" endWordPosition="3768">. INCREMENTAL emulates the MT setting in which the models are restricted to current and previous observation features. Since the segmenter operates at the character level, we can use the same feature set. However, next-observation features must be removed from the tagger. Nonetheless, tagging accuracy only decreases by 0.1%. 5.2 Translation Quality Experimental Setup Our decoder is based on the phrase-based approach to translation (Och and Ney, 2004) and contains various feature functions including phrase relative frequency, word-level alignment statistics, and lexicalized re-ordering models (Tillmann, 2004; Och et al., 2004). We tuned the feature weights on a development set using lattice-based minimum error rate training (MERT) (Macherey et al., The data was pre-processed with packages from the Stanford Arabic parser (Green and Manning, 2010). The corpus split is available at http://nlp.stanford.edu/projects/arabic.shtml. 8We ignore orthographic re-normalization performed by the annotators. For example, they converted the contraction &apos;j, ll back to `CJI CJ&apos; l Al. As a result, we can report accuracy since the guess and gold segmentations have equal numbers of nonwhitespace characters. 151 MT04 </context>
</contexts>
<marker>Tillmann, 2004</marker>
<rawString>C. Tillmann. 2004. A unigram orientation model for statistical machine translation. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>H Suzuki</author>
<author>A Ruopp</author>
</authors>
<title>Applying morphology generation models to machine translation.</title>
<date>2008</date>
<booktitle>In ACLHLT.</booktitle>
<contexts>
<context position="4158" citStr="Toutanova et al., 2008" startWordPosition="612" endWordPosition="615">t to handle agreement phenomena. However, LM statistics are sparse, and they are made sparser by morphological variation. For English-to-Arabic translation, we achieve a +1.04 BLEU average improvement by tiling our model on top of a large LM. 146 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 146–155, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics It has also been suggested that this setting requires morphological generation because the bitext may not contain all inflected variants (Minkov et al., 2007; Toutanova et al., 2008; Fraser et al., 2012). However, using lexical coverage experiments, we show that there is ample room for translation quality improvements through better selection of forms that already exist in the translation model. 2 A Class-based Model of Agreement 2.1 Morpho-syntactic Agreement Morpho-syntactic agreement refers to a relationship between two sentence elements a and b that must have at least one matching grammatical feature.1 Agreement relations tend to be defined for particular syntactic configurations such as verb-subject, noun-adjective, and pronoun-antecedent. In some languages, agreeme</context>
</contexts>
<marker>Toutanova, Suzuki, Ruopp, 2008</marker>
<rawString>K. Toutanova, H. Suzuki, and A. Ruopp. 2008. Applying morphology generation models to machine translation. In ACLHLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Uszkoreit</author>
<author>T Brants</author>
</authors>
<title>Distributed word clustering for large scale class-based language modeling in machine translation.</title>
<date>2008</date>
<booktitle>In ACL-HLT.</booktitle>
<contexts>
<context position="20486" citStr="Uszkoreit and Brants (2008)" startWordPosition="3195" endWordPosition="3198">et-side morphology in English-Czech. His model benefited from gold morphological annotations on the target-side of the 8M sentence bitext. In contrast to these methods, our model does not affect phrase extraction and does not require annotated translation rules. Class-based LMs Class-based LMs (Brown et al., 1992) reduce lexical sparsity by placing words in equivalence classes. They have been widely used for speech recognition, but not for MT. Och (1999) showed a method for inducing bilingual word classes that placed each phrase pair into a two-dimensional equivalence class. To our knowledge, Uszkoreit and Brants (2008) are the only recent authors to show an improvement in a state-of-the-art MT system using class-based LMs. They used a classical exchange algorithm for clustering, and learned 512 classes from 150 a large monolingual corpus. Then they mixed the classes into a word-based LM. However, both Och (1999) and Uszkoreit and Brants (2008) relied on automatically induced classes. It is unclear if their classes captured agreement information. Monz (2011) recently investigated parameter estimation for POS-based language models, but his classes did not include inflectional features. Target-Side Syntactic L</context>
</contexts>
<marker>Uszkoreit, Brants, 2008</marker>
<rawString>J. Uszkoreit and T. Brants. 2008. Distributed word clustering for large scale class-based language modeling in machine translation. In ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>H Ney</author>
<author>C Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation. In</title>
<date>1996</date>
<booktitle>In WMT.</booktitle>
<contexts>
<context position="26134" citStr="Vogel et al., 1996" startWordPosition="4045" endWordPosition="4048">06 +POS+Agr 15.04 +0.36 14.49 +0.19 +0.29 genres nw,bn,ng nw,ng,wb #sentences 1797 1360 3157 Table 3: Mixed genre test set results (BLEU-4 [%]). The MT06 result is statistically significant at p &lt; 0.01; MT08 is significant at p &lt; 0.02. The genres are: nw, broadcast news (bn), newsgroups (ng), and weblog (wb). 2008). For each set of results, we initialized MERT with uniform feature weights. We trained the translation model on 502 million words of parallel text collected from a variety of sources, including the Web. Word alignments were induced using a hidden Markov model based alignment model (Vogel et al., 1996) initialized with bilexical parameters from IBM Model 1 (Brown et al., 1993). Both alignment models were trained using two iterations of the expectation maximization algorithm. Our distributed 4-gram language model was trained on 600 million words of Arabic text, also collected from many sources including the Web (Brants et al., 2007). For development and evaluation, we used the NIST Arabic-English data sets, each of which contains one set of Arabic sentences and multiple English references. To reverse the translation direction for each data set, we chose the first English reference as the sou</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-based word alignment in statistical translation. In COLING. P. Williams and P. Koehn. 2011. Agreement constraints for statistical machine translation into German. In WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
</authors>
<title>Structured Language Models for Statistical Machine Translation.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="22623" citStr="Zhang, 2009" startWordPosition="3510" endWordPosition="3511">cations. For long-distance relations, Shen et al. (2010) proposed a new decoder that generates target-side dependency trees. The target-side structure enables scoring hypotheses with a trigram dependency LM. 5 Experiments We first evaluate the Arabic segmenter and tagger components independently, then provide EnglishArabic translation quality results. 5.1 Intrinsic Evaluation of Components Experimental Setup All experiments use the Penn Arabic Treebank (ATB) (Maamouri et al., 2004) parts 1–3 divided into training/dev/test sections according to the canonical split (Rambow et al., 2005).7 5See (Zhang, 2009) for a comprehensive survey. 6In principle, their parser should run in linear time. An implementation issue may account for the decoding slowdown. (p.c.) 7LDC catalog numbers: LDC2008E61 (ATBp1v4), LDC2008E62 (ATBp2v3), and LDC2008E22 (ATBp3v3.1). FULL (%) INCREMENTAL (%) Segmenter 98.6 – Tagger 96.3 96.2 Table 1: Intrinsic evaluation accuracy [%] (development set) for Arabic segmentation and tagging. The ATB contains clitic-segmented text with persegment morphological analyses (in addition to phrase-structure trees, which we discard). For training the segmenter, we used markers in the vocaliz</context>
</contexts>
<marker>Zhang, 2009</marker>
<rawString>Y. Zhang. 2009. Structured Language Models for Statistical Machine Translation. Ph.D. thesis, Carnegie Mellon University.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>