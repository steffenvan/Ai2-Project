<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.158246">
<title confidence="0.941048">
Dialogue Management for Telephone Information Systems
</title>
<author confidence="0.913376">
Scott McGlashan and Norman Fraser and Nigel Gilbert
</author>
<affiliation confidence="0.960002">
Social and Computer Sciences Research Group
University of Surrey
</affiliation>
<address confidence="0.777237">
Guildford, U.K.
Eric Bilange Paul Heisterkamp Nick Youd
Cap Gemini Innovation Daimler-Benz AG Logica Cambridge Ltd
118 rue de Tocqueville Wilhelm-Runge-Strasse 11 104 Hills Road
5017 Paris, France D-7900 Ulm, Germany Cambridge, U.K.
</address>
<sectionHeader confidence="0.97065" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995953333333333">
A distributed approach to spoken dialogue
management for real-time telephone informa-
tion systems is outlined.
</bodyText>
<sectionHeader confidence="0.997856" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99996125">
The approach to dialogue management described here
has been developed as part of the Sundial project
(Speech UNderstanding in DIALogue) whose goal is to
build real-time integrated computer systems capable of
maintaining co-operative dialogues with users over stan-
dard telephone lines.1 Systems have been developed for
four languages — French, German, Italian and English
— within the task domains of flight reservations and en-
quiries and train enquiries.
Each system consists of five components: a speech
recognition component inputs acoustic speech signals
from the telephone and outputs a word lattice; a parser
extracts a plausible string from the lattice and assigns it
syntactic and semantic representations; a dialogue man-
ager gives these representations an interpretation, de-
cides how the dialogue may continue and, if it is the
system&apos;s turn to speak, plans a system utterance; a text
generator constructs a detailed linguistic representation
from the plan; and a text-to-speech system synthesizes
the representation for transmission by telephone.&apos;
</bodyText>
<sectionHeader confidence="0.9684335" genericHeader="method">
2 Two Problems of Dialogue
Management
</sectionHeader>
<bodyText confidence="0.9971134">
The SUNDIAL dialogue manager addresses two prob-
lems facing spoken dialogue systems. The first is that,
for maximum usefulness, dialogue management needs to
be generic: i.e. the dialogue manager module must
be able to interpret and generate utterances in more
</bodyText>
<footnote confidence="0.9947792">
1SUNDIAL is partly funded by the Commission of the
European Communities under the ESPRIT II programme as
project P2218.
2See Peckham (1991) for an overview of the Sundial
system.
</footnote>
<bodyText confidence="0.998738538461538">
than one language and across more than one task do-
main. The second problem is that dialogue management
must provide co-operative interaction with the user.
To achieve this, the system needs to produce utterances
which are perceived by the user as natural, coherent and
helpful within the context of the dialogue. The purpose
and modality of the dialogue forms part of this context:
in our case, task-driven spoken dialogues. The system
needs to deal with inconsistent task information, such
as that obtained when the speech recognizer and parser
yield a plausible but incorrect interpretation; for exam-
ple, the user said / want to fly to Lannion, but the system
understands London rather than Lannion.
</bodyText>
<sectionHeader confidence="0.991986" genericHeader="method">
3 A Distributed Solution
</sectionHeader>
<bodyText confidence="0.999867307692308">
The Sundial solution to these problems lies, in part,
in the distributed architecture of the dialogue man-
ager. The dialogue manager is responsible for providing
a co-operative interaction with the user (Gerlach and
Horacek, 1989). From the user&apos;s point of view, system
utterances must be appropriate and helpful to the user
in the current dialogue context. To achieve this, both
interpretation of user utterances and planning of system
utterances must be informed by the past and current
states of the interaction. Co-operative dialogue manage-
ment, therefore, requires the construction and mainte-
nance of an interactional model: i.e. a model which
specifies the layers of structure which can be distin-
guished in dialogues. Following Grosz and Sidner (1986)
we distinguish linguistic structure, attentional, or belief
structure, and intentional structure. Intentional struc-
ture is further differentiated into dialogue structure and
task structure (Bunt, 1989). However, rather than us-
ing a unitary model where these layers are given as
a single structured representation, we have adopted a
distributed model where these layers are distributed
across a. number of modules. Each module consists of a
partial model of the interaction, rules for updating the
model as well as associated dialogue management func-
tions. Fill:them lore, modules may need to collaborate
with each other in order to determine how to update
</bodyText>
<page confidence="0.992503">
245
</page>
<bodyText confidence="0.998075228070175">
their model: their update rules may depend upon infor-
mation maintained in another module.
The interactional model is falsification definite since
agents assume rather than infer that their belief model
corresponds to that of the other agent. This places an
obligation on agents to make explicit the state of their
belief model so as to give the other agent the opportunity
to correct or modify it. For example, if the system utters
You want to. go to London in response to the user&apos;s re-
quest, the user has an opportunity to contest the current
state of the system&apos;s belief model.
The Sundial dialogue manager consists of five mod-
ules. The linguistic interface module interfaces the di-
alogue manager with the parser and is responsible for
maintaining a linguistic model of system and user utter-
ances. The dialogue module is responsible for maintain-
ing a model of dialogue context, building an interpre-
tation of user utterances and determining how the dia-
logue should continue. Dialogue structure is based on the
framework of Roulet and Moeschler in which dialogue
is hierarchically structured irrto exchanges, interventions
and dialogue acts (Moeschler, 1989). In order to deter-
mine the appropriate contextual interpretation of user
utterances, the dialogue module interacts with the belief
module which maintains a model of belief containing not
just concepts created directly as a result of user utter-
ances, but also inferential extensions. For example, if the
system initiated an exchange to determine the departure
date of a flight, this exchange can be closed if the belief
model can interpret the user&apos;s utterance as referencing
a &apos;date&apos; concept. The belief module requires context in-
formation from the dialogue module in order to guide
the interpretation process. For example, thc second can
reference date or flight. concepts (the second of May or
the second flight) depending on the context. The belief
module additionally cooperates with the message plan-
ning module in order to provide semantic descriptions of
concepts referenced in the plan of system utterances.
Finally, the task module is responsible for maintaining
a model of the task structure of the dialogue, consult-
ing domain-specific application databases and informing
the dialogue module of the current state of the task.
Typically, this involves deciding whether sufficient task
information has been provided by the user and, if not,
which additional parameters are required. Less frequent
are interactions which arise when a user provides suffi-
cient, but incorrect, information: for example, there is
no flight to the stated destination city. Rather than sim-
ply informing the dialogue module that the task cannot
be satisfied, the task module attempts to relax task pa-
rameters and suggest alternative values for them (Guy-
omard and Siroux, 1988). For example, if there are no
flights available in the morning of the given departure
day, flights in the afternoon may be suggested. In such
cases, system utterances are selected and formulated so
as to make explicit to the user the fact that an alterna-
tive is being offered.
</bodyText>
<sectionHeader confidence="0.987523" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.999929611111111">
The Sundial dialogue manager has been implemented
in Quintus Prolog and tested on a variety of different
hardware platforms. It has been integrated with the
rest of the Sundial system and successfully manages a
range of English, French, and German spoken (public
network) telephone dialogues relating to flight enquiries,
flight reservations, and train enquiries. Language and
task can be changed in the dialogue manager simply
by resetting switches which govern the choice of static
knowledge bases consulted during dialogue management.
Current average response times for the entire Sundial
system (including speech recognition and synthesis) are
around 10 seconds, with the dialogue manager taking
1-2 seconds. However, a significant amount of optimiza-
tion has still to be carried out, and it is expected that
response times will approach real time within the next
six months. The lexicon currently contains around 300
entries for each language.
</bodyText>
<sectionHeader confidence="0.99766" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999861071428571">
Two problems facing dialogue management in tele-
phone information systems — co-operative interaction
and portability across languages and task domains —
have been addressed by the dialogue manager in the
Sundial system. Our solution has been to distribute
the interactional model, as well as functions dealing
with co-operative interaction, across a number of semi-
independent modules. Each module is an expert on a
local part of the interactional model. The language of
spoken interaction and the application task can both be
changed by instructing the relevant modules to consult
different knowledge bases. In this way the generic Sun-
dial dialogue manager can be customized for specific lan-
guages and applications.
</bodyText>
<sectionHeader confidence="0.992171" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.836571782608696">
Harry C. Bunt. Towards a dynamic interopreta-
tion theory of utterances in dialogue. In Ben A.G.
Elsendoorn and Herman Houma, editors, Working
models of human perception. Academic Press, 1989.
Michael Gerlach and Helmut Horacek. Dialog control
in a natural language system. In Proceeding of the 4111
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, 1989. Manchester.
Barbara J. Grosz and Candace L. Sidner. Attentions,
intentions, and the structure of discourse. Compu-
tational Linguistics, 12(3):175-204, July-September
1986.
Marc Guyomard and Jaques Siroux. An approach to
co-operation in man machine oral dialogue. In ERGO-
IA, 1988.
Jacques Moeschler. Modelisation du dialogue,
representation de l&apos;inference argumentative. Hermes,
1989.
Jeremy Peckham. Speech understanding and dialogue
over the telephone: an overview of progress in the
Sundial project. In Proceedings of the 2nd European
Conference on Speech Communication and Technol-
ogy, pages 1469-1472,1991.
</reference>
<page confidence="0.998727">
246
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.615850">
<title confidence="0.999847">Dialogue Management for Telephone Information Systems</title>
<author confidence="0.997095">Scott McGlashan</author>
<author confidence="0.997095">Norman Fraser</author>
<author confidence="0.997095">Nigel Gilbert</author>
<affiliation confidence="0.999674">Social and Computer Sciences Research Group University of Surrey</affiliation>
<address confidence="0.663972">Guildford, U.K.</address>
<author confidence="0.971557">Eric Bilange Paul Heisterkamp Nick Youd</author>
<affiliation confidence="0.990542">Cap Gemini Innovation Daimler-Benz AG Logica Cambridge Ltd</affiliation>
<address confidence="0.997">118 rue de Tocqueville Wilhelm-Runge-Strasse 11 104 Hills Road 5017 Paris, France D-7900 Ulm, Germany Cambridge, U.K.</address>
<abstract confidence="0.98713825">A distributed approach to spoken dialogue management for real-time telephone information systems is outlined.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Harry C Bunt</author>
</authors>
<title>Towards a dynamic interopretation theory of utterances in dialogue.</title>
<date>1989</date>
<editor>In Ben A.G. Elsendoorn and Herman Houma, editors,</editor>
<publisher>Academic Press,</publisher>
<contexts>
<context position="3756" citStr="Bunt, 1989" startWordPosition="564" endWordPosition="565"> context. To achieve this, both interpretation of user utterances and planning of system utterances must be informed by the past and current states of the interaction. Co-operative dialogue management, therefore, requires the construction and maintenance of an interactional model: i.e. a model which specifies the layers of structure which can be distinguished in dialogues. Following Grosz and Sidner (1986) we distinguish linguistic structure, attentional, or belief structure, and intentional structure. Intentional structure is further differentiated into dialogue structure and task structure (Bunt, 1989). However, rather than using a unitary model where these layers are given as a single structured representation, we have adopted a distributed model where these layers are distributed across a. number of modules. Each module consists of a partial model of the interaction, rules for updating the model as well as associated dialogue management functions. Fill:them lore, modules may need to collaborate with each other in order to determine how to update 245 their model: their update rules may depend upon information maintained in another module. The interactional model is falsification definite s</context>
</contexts>
<marker>Bunt, 1989</marker>
<rawString>Harry C. Bunt. Towards a dynamic interopretation theory of utterances in dialogue. In Ben A.G. Elsendoorn and Herman Houma, editors, Working models of human perception. Academic Press, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gerlach</author>
<author>Helmut Horacek</author>
</authors>
<title>Dialog control in a natural language system.</title>
<date>1989</date>
<booktitle>In Proceeding of the 4111 Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<location>Manchester.</location>
<contexts>
<context position="3027" citStr="Gerlach and Horacek, 1989" startWordPosition="455" endWordPosition="458">odality of the dialogue forms part of this context: in our case, task-driven spoken dialogues. The system needs to deal with inconsistent task information, such as that obtained when the speech recognizer and parser yield a plausible but incorrect interpretation; for example, the user said / want to fly to Lannion, but the system understands London rather than Lannion. 3 A Distributed Solution The Sundial solution to these problems lies, in part, in the distributed architecture of the dialogue manager. The dialogue manager is responsible for providing a co-operative interaction with the user (Gerlach and Horacek, 1989). From the user&apos;s point of view, system utterances must be appropriate and helpful to the user in the current dialogue context. To achieve this, both interpretation of user utterances and planning of system utterances must be informed by the past and current states of the interaction. Co-operative dialogue management, therefore, requires the construction and maintenance of an interactional model: i.e. a model which specifies the layers of structure which can be distinguished in dialogues. Following Grosz and Sidner (1986) we distinguish linguistic structure, attentional, or belief structure, a</context>
</contexts>
<marker>Gerlach, Horacek, 1989</marker>
<rawString>Michael Gerlach and Helmut Horacek. Dialog control in a natural language system. In Proceeding of the 4111 Conference of the European Chapter of the Association for Computational Linguistics, 1989. Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attentions, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--3</pages>
<contexts>
<context position="3554" citStr="Grosz and Sidner (1986)" startWordPosition="537" endWordPosition="540">s responsible for providing a co-operative interaction with the user (Gerlach and Horacek, 1989). From the user&apos;s point of view, system utterances must be appropriate and helpful to the user in the current dialogue context. To achieve this, both interpretation of user utterances and planning of system utterances must be informed by the past and current states of the interaction. Co-operative dialogue management, therefore, requires the construction and maintenance of an interactional model: i.e. a model which specifies the layers of structure which can be distinguished in dialogues. Following Grosz and Sidner (1986) we distinguish linguistic structure, attentional, or belief structure, and intentional structure. Intentional structure is further differentiated into dialogue structure and task structure (Bunt, 1989). However, rather than using a unitary model where these layers are given as a single structured representation, we have adopted a distributed model where these layers are distributed across a. number of modules. Each module consists of a partial model of the interaction, rules for updating the model as well as associated dialogue management functions. Fill:them lore, modules may need to collabo</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara J. Grosz and Candace L. Sidner. Attentions, intentions, and the structure of discourse. Computational Linguistics, 12(3):175-204, July-September 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Guyomard</author>
<author>Jaques Siroux</author>
</authors>
<title>An approach to co-operation in man machine oral dialogue.</title>
<date>1988</date>
<booktitle>In ERGOIA,</booktitle>
<contexts>
<context position="7033" citStr="Guyomard and Siroux, 1988" startWordPosition="1084" endWordPosition="1088">in-specific application databases and informing the dialogue module of the current state of the task. Typically, this involves deciding whether sufficient task information has been provided by the user and, if not, which additional parameters are required. Less frequent are interactions which arise when a user provides sufficient, but incorrect, information: for example, there is no flight to the stated destination city. Rather than simply informing the dialogue module that the task cannot be satisfied, the task module attempts to relax task parameters and suggest alternative values for them (Guyomard and Siroux, 1988). For example, if there are no flights available in the morning of the given departure day, flights in the afternoon may be suggested. In such cases, system utterances are selected and formulated so as to make explicit to the user the fact that an alternative is being offered. 4 Implementation The Sundial dialogue manager has been implemented in Quintus Prolog and tested on a variety of different hardware platforms. It has been integrated with the rest of the Sundial system and successfully manages a range of English, French, and German spoken (public network) telephone dialogues relating to f</context>
</contexts>
<marker>Guyomard, Siroux, 1988</marker>
<rawString>Marc Guyomard and Jaques Siroux. An approach to co-operation in man machine oral dialogue. In ERGOIA, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques Moeschler</author>
</authors>
<title>Modelisation du dialogue, representation de l&apos;inference argumentative. Hermes,</title>
<date>1989</date>
<contexts>
<context position="5373" citStr="Moeschler, 1989" startWordPosition="827" endWordPosition="828">t state of the system&apos;s belief model. The Sundial dialogue manager consists of five modules. The linguistic interface module interfaces the dialogue manager with the parser and is responsible for maintaining a linguistic model of system and user utterances. The dialogue module is responsible for maintaining a model of dialogue context, building an interpretation of user utterances and determining how the dialogue should continue. Dialogue structure is based on the framework of Roulet and Moeschler in which dialogue is hierarchically structured irrto exchanges, interventions and dialogue acts (Moeschler, 1989). In order to determine the appropriate contextual interpretation of user utterances, the dialogue module interacts with the belief module which maintains a model of belief containing not just concepts created directly as a result of user utterances, but also inferential extensions. For example, if the system initiated an exchange to determine the departure date of a flight, this exchange can be closed if the belief model can interpret the user&apos;s utterance as referencing a &apos;date&apos; concept. The belief module requires context information from the dialogue module in order to guide the interpretati</context>
</contexts>
<marker>Moeschler, 1989</marker>
<rawString>Jacques Moeschler. Modelisation du dialogue, representation de l&apos;inference argumentative. Hermes, 1989.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jeremy Peckham</author>
</authors>
<title>Speech understanding and dialogue over the telephone: an overview of progress in the Sundial project.</title>
<booktitle>In Proceedings of the 2nd European Conference on Speech Communication and Technology,</booktitle>
<pages>1469--1472</pages>
<marker>Peckham, </marker>
<rawString>Jeremy Peckham. Speech understanding and dialogue over the telephone: an overview of progress in the Sundial project. In Proceedings of the 2nd European Conference on Speech Communication and Technology, pages 1469-1472,1991.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>