<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000267">
<title confidence="0.946926">
Extractive Summarization Based on Event Term Clustering
</title>
<author confidence="0.965255">
Maofu Liu1,2, Wenjie Li1, Mingli Wu1 and Qin Lu1
</author>
<affiliation confidence="0.927884">
1Department of Computing
</affiliation>
<author confidence="0.754291">
The Hong Kong Polytechnic University
</author>
<affiliation confidence="0.255074">
{csmfliu, cswjli, csmlwu,
</affiliation>
<email confidence="0.804562">
csluqin}@comp.polyu.edu.hk
</email>
<sectionHeader confidence="0.996568" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999701727272727">
Event-based summarization extracts and
organizes summary sentences in terms of
the events that the sentences describe. In
this work, we focus on semantic relations
among event terms. By connecting terms
with relations, we build up event term
graph, upon which relevant terms are
grouped into clusters. We assume that each
cluster represents a topic of documents.
Then two summarization strategies are
investigated, i.e. selecting one term as the
representative of each topic so as to cover
all the topics, or selecting all terms in one
most significant topic so as to highlight the
relevant information related to this topic.
The selected terms are then responsible to
pick out the most appropriate sentences
describing them. The evaluation of
clustering-based summarization on DUC
2001 document sets shows encouraging
improvement over the well-known
PageRank-based summarization.
</bodyText>
<sectionHeader confidence="0.999473" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999569">
Event-based extractive summarization has emerged
recently (Filatova and Hatzivassiloglou, 2004). It
extracts and organizes summary sentences in terms
of the events that sentences describe.
We follow the common agreement that event
can be formulated as “[Who] did [What] to [Whom]
[When] and [Where]” and “did [What]” denotes
the key element of an event, i.e. the action within
the formulation. We approximately define the
verbs and action nouns as the event terms which
can characterize or partially characterize the event
occurrences.
</bodyText>
<affiliation confidence="0.999583">
2College of Computer Science and Technology
Wuhan University of Science and Technology
</affiliation>
<email confidence="0.970644">
mfliu_china@hotmail.com
</email>
<bodyText confidence="0.999509153846154">
Most existing event-based summarization
approaches rely on the statistical features derived
from documents and generally associated with
single events, but they neglect the relations among
events. However, events are commonly related
with one another especially when the documents to
be summarized are about the same or very similar
topics. Li et al (2006) report that the improved
performance can be achieved by taking into
account of event distributional similarities, but it
does not benefit much from semantic similarities.
This motivated us to further investigate whether
event-based summarization can take advantage of
the semantic relations of event terms, and most
importantly, how to make use of those relations.
Our idea is grouping the terms connected by the
relations into the clusters, which are assumed to
represent some topics described in documents.
In the past, various clustering approaches have
been investigated in document summarization.
Hatzivassiloglou et al (2001) apply clustering
method to organize the highly similar paragraphs
into tight clusters based on primitive or composite
features. Then one paragraph per cluster is selected
to form the summary by extraction or by
reformulation. Zha (2002) uses spectral graph
clustering algorithm to partition sentences into
topical groups. Within each cluster, the saliency
scores of terms and sentences are calculated using
mutual reinforcement principal, which assigns high
salience scores to the sentences that contain many
terms with high salience scores. The sentences and
key phrases are selected by their saliency scores to
generate the summary. The similar work based on
topic or event is also reported in (Guo and Stylios,
2005).
The granularity of clustering units mentioned
above is rather coarse, either sentence or paragraph.
In this paper, we define event term as clustering
</bodyText>
<page confidence="0.985089">
185
</page>
<bodyText confidence="0.911971708333333">
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 185–188,
Prague, June 2007. c�2007 Association for Computational Linguistics
unit and implement a clustering algorithm based on
semantic relations. We extract event terms from
documents and construct the event term graph by
linking terms with the relations. We then regard a
group of closely related terms as a topic and make
the following two alterative assumptions:
(1) If we could find the most significant topic as
the main topic of documents and select all terms in
it, we could summarize the documents with this
main topic.
(2) If we could find all topics and pick out one
term as the representative of each topic, we could
obtain the condensed version of topics described in
the documents.
Based on these two assumptions, a set of cluster
ranking, term selection and ranking and sentence
extraction strategies are developed. The remainder
of this paper is organized as follows. Section 2
introduces the proposed extractive summarization
approach based on event term clustering. Section 3
presents experiments and evaluations. Finally,
Section 4 concludes the paper.
</bodyText>
<sectionHeader confidence="0.9419785" genericHeader="method">
2 Summarization Based on Event Term
Clustering
</sectionHeader>
<subsectionHeader confidence="0.998793">
2.1 Event Term Graph
</subsectionHeader>
<bodyText confidence="0.991657888888889">
We introduce VerbOcean (Chklovski and Pantel,
2004), a broad-coverage repository of semantic
verb relations, into event-based summarization.
Different from other thesaurus like WordNet,
VerbOcean provides five types of semantic verb
relations at finer level. This just fits in with our
idea to introduce event term relations into
summarization. Currently, only the stronger-than
relation is explored. When two verbs are similar,
one may denote a more intense, thorough,
comprehensive or absolute action. In the case of
change-of-state verbs, one may denote a more
complete change. This is identified as the stronger-
than relation in (Timothy and Patrick, 2004). In
this paper, only stronger-than is taken into account
but we consider extending our future work with
other applicable relations types.
The event term graph connected by term
semantic relations is defined formally as
, where V is a set of event terms and E
is a set of relation links connecting the event terms
in V. The graph is directed if the semantic relation
has the characteristic of the asymmetric. Otherwise,
it is undirected. Figure 1 shows a sample of event
term graph built from one DUC 2001 document set.
It is a directed graph as the stronger-than relation
in VerbOcean exhibits the conspicuous asymmetric
characteristic. For example, “fight” means to
attempt to harm by blows or with weapons, while
“resist” means to keep from giving in. Therefore, a
directed link from “fight” to “resist” is shown in
the following Figure 1.
Relations link terms together and form the event
term graph. Based upon it, term significance is
evaluated and in turn sentence is judged whether to
be extracted in the summary.
</bodyText>
<figureCaption confidence="0.964165">
Figure 1. Terms connected by semantic relations
</figureCaption>
<subsectionHeader confidence="0.986489">
2.2 Event Term Clustering
</subsectionHeader>
<bodyText confidence="0.999946">
Note that in Figure 1, some linked event terms,
such as “kill”, “rob”, “threaten” and “infect”, are
semantically closely related. They may describe
the same or similar topic somehow. In contrast,
“toler”, “resist” and “fight” are clearly involved in
another topic; although they are also reachable
from “kill”. Based on this observation, a clustering
algorithm is required to group the similar and
related event terms into the cluster of the topic.
In this work, event terms are clustered by the
DBSCAN, a density-based clustering algorithm
proposed in (Easter et al, 1996). The key idea
behind it is that for each term of a cluster the
neighborhood of a given radius has to contain at
least a minimum number of terms, i.e. the density
in the neighborhood has to exceed some threshold.
By using this algorithm, we need to figure out
appropriate values for two basic parameters,
namely, Eps (denoting the searching radius from
each term) and MinPts (denoting the minimum
number of terms in the neighborhood of the term).
We assign one semantic relation step to Eps since
there is no clear distance concept in the event term
</bodyText>
<equation confidence="0.655529">
G =(V,E )
</equation>
<page confidence="0.98133">
186
</page>
<bodyText confidence="0.999539125">
graph. The value of Eps is experimentally set in
our experiments. We also make some modification
on Easter’s DBSCAN in order to accommodate to
our task.
Figure 2 shows the seven term clusters
generated by the modified DBSCAN clustering
algorithm from the graph in Figure 1. We represent
each cluster by the starting event term in bold font.
</bodyText>
<figureCaption confidence="0.988131">
Figure 2. Term clusters generated from Figure 1
</figureCaption>
<subsectionHeader confidence="0.996118">
2.3 Cluster Ranking
</subsectionHeader>
<bodyText confidence="0.998649">
The significance of the cluster is calculated by
</bodyText>
<equation confidence="0.9918195">
sc(Ci)= ∑dt / ∑ ∑dt
t∈ Ci Ci∈ C t∈ Ci
</equation>
<bodyText confidence="0.999551">
where is the degree of the term t in the term
</bodyText>
<equation confidence="0.471026">
dt
graph. C is the set of term clusters obtained by the
modified DBSCAN clustering algorithm and is
Ci
</equation>
<bodyText confidence="0.9770278">
the ith one. Obviously, the significance of the
cluster is calculated from global point of view, i.e.
the sum of the degree of all terms in the same
cluster is divided by the total degree of the terms in
all clusters.
</bodyText>
<subsectionHeader confidence="0.998964">
2.4 Term Selection and Ranking
</subsectionHeader>
<bodyText confidence="0.9943304">
Representative terms are selected according to the
significance of the event terms calculated within
each cluster (i.e. from local point of view) or in all
clusters (i.e. from global point of view) by
LOCAL: st(t) dt / d t
</bodyText>
<equation confidence="0.97662875">
= ∑ or
t∈
GLOBAL: st(t) = dt / ∑ ∑ dt
ci∈ C t∈ ci
</equation>
<bodyText confidence="0.943545214285714">
Then two strategies are developed to select the
representative terms from the clusters.
(1) One Cluster All Terms (OCAT) selects all
terms within the first rank cluster. The selected
terms are then ranked according to their
significance.
(2) One Term All Cluster (OTAC) selects one
most significant term from each cluster. Notice that
because terms compete with each other within
clusters, it is not surprising to see st(t1) &lt; st(t2 )
even when sc(c1) &gt; sc(c2) , (t1 ∈ c1, t2 ∈ c2) . To
address this problem, the representative terms are
ranked according to the significance of the clusters
they belong to.
</bodyText>
<subsectionHeader confidence="0.999412">
2.5 Sentence Evaluation and Extraction
</subsectionHeader>
<bodyText confidence="0.9999772">
A representative event term may associate to more
than one sentence. We extract only one of them as
the description of the event. To this end, sentences
are compared according to the significance of the
terms in them. MAX compares the maximum
significance scores, while SUM compares the sum
of the significance scores. The sentence with either
higher MAX or SUM wins the competition and is
picked up as a candidate summary sentence. If the
sentence in the first place has been selected by
another term, the one in the second place is chosen.
The ranks of these candidates are the same as the
ranks of the terms they are selected for. Finally,
candidate sentences are selected in the summary
until the length limitation is reached.
</bodyText>
<sectionHeader confidence="0.999771" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.988101235294117">
We evaluate the proposed approaches on DUC
2001 corpus which contains 30 English document
sets. There are 431 event terms on average in each
document set. The automatic evaluation tool,
ROUGE (Lin and Hovy, 2003), is run to evaluate
the quality of the generated summaries (200 words
in length). The tool presents three values including
unigram-based ROUGE-1, bigram-based ROUGE-
2 and ROUGE-W which is based on longest
common subsequence weighted by the length.
Google’s PageRank (Page and Brin, 1998) is
one of the most popular ranking algorithms. It is
also graph-based and has been successfully applied
in summarization. Table 1 lists the result of our
implementation of PageRank based on event terms.
We then compare it with the results of the event
term clustering-based approaches illustrated in
</bodyText>
<tableCaption confidence="0.921203">
Table 2.
</tableCaption>
<figure confidence="0.938879119047619">
PageRank
ROUGE-1 0.32749
threaten
kill
ambush
please
satisfy
fear
feel suffer
rob
toler
infect
endure
resist
fight
consider
rush move
live
expect
survive
pass
undergo
announce
run
list public
manage
offer
investigate
report
accept
publish
prepare
accept
honor
study
file
place
found
ci
187
ROUGE-2 0.05670
ROUGE-W 0.11500
</figure>
<tableCaption confidence="0.8051865">
Table 1. Evaluations of PageRank-based
Summarization
</tableCaption>
<table confidence="0.99992575">
LOCAL+OTAC MAX SUM
ROUGE-1 0.32771 0.33243
ROUGE-2 0.05334 0.05569
ROUGE-W 0.11633 0.11718
GLOBAL+OTAC MAX SUM
ROUGE-1 0.32549 0.32966
ROUGE-2 0.05254 0.05257
ROUGE-W 0.11670 0.11641
LOCAL+OCAT MAX SUM
ROUGE-1 0.33519 0.33397
ROUGE-2 0.05662 0.05869
ROUGE-W 0.11917 0.11849
GLOBAL+OCAT MAX SUM
ROUGE-1 0.33568 0.33872
ROUGE-2 0.05506 0.05933
ROUGE-W 0.11795 0.12011
</table>
<tableCaption confidence="0.818">
Table 2. Evaluations of Clustering-based
Summarization
</tableCaption>
<bodyText confidence="0.999177857142857">
The experiments show that both assumptions are
reasonable. It is encouraging to find that our event
term clustering-based approaches could outperform
the PageRank-based approach. The results based
on the second assumption are even better. This
suggests indeed there is a main topic in a DUC
2001 document set.
</bodyText>
<sectionHeader confidence="0.99961" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999976538461538">
In this paper, we put forward to apply clustering
algorithm on the event term graph connected by
semantic relations derived from external linguistic
resource. The experiment results based on our two
assumptions are encouraging. Event term
clustering-based approaches perform better than
PageRank-based approach. Current approaches
simply utilize the degrees of event terms in the
graph. In the future, we would like to further
explore and integrate more information derived
from documents in order to achieve more
significant results using the event term clustering-
based approaches.
</bodyText>
<sectionHeader confidence="0.999261" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.93553">
The work described in this paper was fully
supported by a grant from the Research Grants
Council of the Hong Kong Special Administrative
Region, China (Project No. PolyU5181/03E).
</bodyText>
<sectionHeader confidence="0.996258" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999909130434783">
Chin-Yew Lin and Eduard Hovy. 2003. Automatic
Evaluation of Summaries using N-gram
Cooccurrence Statistics. In Proceedings of HLT/
NAACL 2003, pp71-78.
Elena Filatova and Vasileios Hatzivassiloglou. 2004.
Event-based Extractive Summarization. In
Proceedings of ACL 2004 Workshop on
Summarization, pp104-111.
Hongyuan Zha. 2002. Generic Summarization and
keyphrase Extraction using Mutual Reinforcement
Principle and Sentence Clustering. In Proceedings
of the 25th annual international ACM SIGIR
conference on Research and development in
information retrieval, 2002. pp113-120.
Lawrence Page and Sergey Brin, Motwani Rajeev
and Winograd Terry. 1998. The PageRank
CitationRanking: Bring Order to the Web.
Technical Report,Stanford University.
Martin Easter, Hans-Peter Kriegel, Jörg Sander, et al.
1996. A Density-Based Algorithm for Discovering
Clusters in Large Spatial Databases with Noise. In
Proceedings of the 2nd International Conference
on Knowledge Discovery and Data Mining, Menlo
Park, CA, 1996. 226-231.
Lawrence Page, Sergey Brin, Rajeev Motwani and
Terry Winograd. 1998. The PageRank
CitationRanking: Bring Order to the Web.
Technical Report,Stanford University.
Timothy Chklovski and Patrick Pantel. 2004.
VerbOcean: Mining the Web for Fine-Grained
Semantic Verb Relations. In Proceedings of
Conference on Empirical Methods in Natural
Language Processing, 2004.
Vasileios Hatzivassiloglou, Judith L. Klavans,
Melissa L. Holcombe, et al. 2001. Simfinder: A
Flexible Clustering Tool for Summarization. In
Workshop on Automatic Summarization, NAACL,
2001.
Wenjie Li, Wei Xu, Mingli Wu, et al. 2006.
Extractive Summarization using Inter- and Intra-
Event Relevance. In Proceedings of ACL 2006,
pp369-376.
Yi Guo and George Stylios. 2005. An intelligent
summarization system based on cognitive
psychology. Journal of Information Sciences,
Volume 174, Issue 1-2, Jun. 2005, pp1-36.
</reference>
<page confidence="0.997511">
188
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.392742">
<title confidence="0.999658">Extractive Summarization Based on Event Term Clustering</title>
<author confidence="0.969581">Mingli</author>
<author confidence="0.969581">Qin</author>
<affiliation confidence="0.9812925">of Computing The Hong Kong Polytechnic University</affiliation>
<email confidence="0.812931">csmfliu@comp.polyu.edu.hk</email>
<email confidence="0.812931">cswjli@comp.polyu.edu.hk</email>
<email confidence="0.812931">csmlwu@comp.polyu.edu.hk</email>
<email confidence="0.812931">csluqin@comp.polyu.edu.hk</email>
<abstract confidence="0.98408047826087">Event-based summarization extracts and organizes summary sentences in terms of the events that the sentences describe. In this work, we focus on semantic relations among event terms. By connecting terms with relations, we build up event term graph, upon which relevant terms are grouped into clusters. We assume that each cluster represents a topic of documents. Then two summarization strategies are investigated, i.e. selecting one term as the representative of each topic so as to cover all the topics, or selecting all terms in one most significant topic so as to highlight the relevant information related to this topic. The selected terms are then responsible to pick out the most appropriate sentences describing them. The evaluation of clustering-based summarization on DUC 2001 document sets shows encouraging improvement over the well-known PageRank-based summarization.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Eduard Hovy</author>
</authors>
<title>Automatic Evaluation of Summaries using N-gram Cooccurrence Statistics.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT/ NAACL</booktitle>
<pages>71--78</pages>
<contexts>
<context position="10498" citStr="Lin and Hovy, 2003" startWordPosition="1686" endWordPosition="1689">ither higher MAX or SUM wins the competition and is picked up as a candidate summary sentence. If the sentence in the first place has been selected by another term, the one in the second place is chosen. The ranks of these candidates are the same as the ranks of the terms they are selected for. Finally, candidate sentences are selected in the summary until the length limitation is reached. 3 Experiments We evaluate the proposed approaches on DUC 2001 corpus which contains 30 English document sets. There are 431 event terms on average in each document set. The automatic evaluation tool, ROUGE (Lin and Hovy, 2003), is run to evaluate the quality of the generated summaries (200 words in length). The tool presents three values including unigram-based ROUGE-1, bigram-based ROUGE2 and ROUGE-W which is based on longest common subsequence weighted by the length. Google’s PageRank (Page and Brin, 1998) is one of the most popular ranking algorithms. It is also graph-based and has been successfully applied in summarization. Table 1 lists the result of our implementation of PageRank based on event terms. We then compare it with the results of the event term clustering-based approaches illustrated in Table 2. Pag</context>
</contexts>
<marker>Lin, Hovy, 2003</marker>
<rawString>Chin-Yew Lin and Eduard Hovy. 2003. Automatic Evaluation of Summaries using N-gram Cooccurrence Statistics. In Proceedings of HLT/ NAACL 2003, pp71-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Filatova</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Event-based Extractive Summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL 2004 Workshop on Summarization,</booktitle>
<pages>104--111</pages>
<contexts>
<context position="1220" citStr="Filatova and Hatzivassiloglou, 2004" startWordPosition="169" endWordPosition="172">uments. Then two summarization strategies are investigated, i.e. selecting one term as the representative of each topic so as to cover all the topics, or selecting all terms in one most significant topic so as to highlight the relevant information related to this topic. The selected terms are then responsible to pick out the most appropriate sentences describing them. The evaluation of clustering-based summarization on DUC 2001 document sets shows encouraging improvement over the well-known PageRank-based summarization. 1 Introduction Event-based extractive summarization has emerged recently (Filatova and Hatzivassiloglou, 2004). It extracts and organizes summary sentences in terms of the events that sentences describe. We follow the common agreement that event can be formulated as “[Who] did [What] to [Whom] [When] and [Where]” and “did [What]” denotes the key element of an event, i.e. the action within the formulation. We approximately define the verbs and action nouns as the event terms which can characterize or partially characterize the event occurrences. 2College of Computer Science and Technology Wuhan University of Science and Technology mfliu_china@hotmail.com Most existing event-based summarization approach</context>
</contexts>
<marker>Filatova, Hatzivassiloglou, 2004</marker>
<rawString>Elena Filatova and Vasileios Hatzivassiloglou. 2004. Event-based Extractive Summarization. In Proceedings of ACL 2004 Workshop on Summarization, pp104-111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongyuan Zha</author>
</authors>
<title>Generic Summarization and keyphrase Extraction using Mutual Reinforcement Principle and Sentence Clustering.</title>
<date>2002</date>
<booktitle>In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="2997" citStr="Zha (2002)" startWordPosition="436" endWordPosition="437">antage of the semantic relations of event terms, and most importantly, how to make use of those relations. Our idea is grouping the terms connected by the relations into the clusters, which are assumed to represent some topics described in documents. In the past, various clustering approaches have been investigated in document summarization. Hatzivassiloglou et al (2001) apply clustering method to organize the highly similar paragraphs into tight clusters based on primitive or composite features. Then one paragraph per cluster is selected to form the summary by extraction or by reformulation. Zha (2002) uses spectral graph clustering algorithm to partition sentences into topical groups. Within each cluster, the saliency scores of terms and sentences are calculated using mutual reinforcement principal, which assigns high salience scores to the sentences that contain many terms with high salience scores. The sentences and key phrases are selected by their saliency scores to generate the summary. The similar work based on topic or event is also reported in (Guo and Stylios, 2005). The granularity of clustering units mentioned above is rather coarse, either sentence or paragraph. In this paper, </context>
</contexts>
<marker>Zha, 2002</marker>
<rawString>Hongyuan Zha. 2002. Generic Summarization and keyphrase Extraction using Mutual Reinforcement Principle and Sentence Clustering. In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval, 2002. pp113-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Motwani Rajeev</author>
<author>Winograd Terry</author>
</authors>
<title>The PageRank CitationRanking: Bring Order to the Web. Technical Report,Stanford University.</title>
<date>1998</date>
<marker>Page, Brin, Rajeev, Terry, 1998</marker>
<rawString>Lawrence Page and Sergey Brin, Motwani Rajeev and Winograd Terry. 1998. The PageRank CitationRanking: Bring Order to the Web. Technical Report,Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Easter</author>
<author>Hans-Peter Kriegel</author>
<author>Jörg Sander</author>
</authors>
<title>A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise.</title>
<date>1996</date>
<booktitle>In Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>226--231</pages>
<location>Menlo Park, CA,</location>
<contexts>
<context position="7164" citStr="Easter et al, 1996" startWordPosition="1095" endWordPosition="1098"> semantic relations 2.2 Event Term Clustering Note that in Figure 1, some linked event terms, such as “kill”, “rob”, “threaten” and “infect”, are semantically closely related. They may describe the same or similar topic somehow. In contrast, “toler”, “resist” and “fight” are clearly involved in another topic; although they are also reachable from “kill”. Based on this observation, a clustering algorithm is required to group the similar and related event terms into the cluster of the topic. In this work, event terms are clustered by the DBSCAN, a density-based clustering algorithm proposed in (Easter et al, 1996). The key idea behind it is that for each term of a cluster the neighborhood of a given radius has to contain at least a minimum number of terms, i.e. the density in the neighborhood has to exceed some threshold. By using this algorithm, we need to figure out appropriate values for two basic parameters, namely, Eps (denoting the searching radius from each term) and MinPts (denoting the minimum number of terms in the neighborhood of the term). We assign one semantic relation step to Eps since there is no clear distance concept in the event term G =(V,E ) 186 graph. The value of Eps is experimen</context>
</contexts>
<marker>Easter, Kriegel, Sander, 1996</marker>
<rawString>Martin Easter, Hans-Peter Kriegel, Jörg Sander, et al. 1996. A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise. In Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining, Menlo Park, CA, 1996. 226-231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The PageRank CitationRanking: Bring Order to the Web. Technical Report,Stanford University.</title>
<date>1998</date>
<marker>Page, Brin, Motwani, Winograd, 1998</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani and Terry Winograd. 1998. The PageRank CitationRanking: Bring Order to the Web. Technical Report,Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Chklovski</author>
<author>Patrick Pantel</author>
</authors>
<title>VerbOcean: Mining the Web for Fine-Grained Semantic Verb Relations.</title>
<date>2004</date>
<booktitle>In Proceedings of Conference on Empirical Methods in Natural Language Processing,</booktitle>
<contexts>
<context position="4888" citStr="Chklovski and Pantel, 2004" startWordPosition="730" endWordPosition="733"> pick out one term as the representative of each topic, we could obtain the condensed version of topics described in the documents. Based on these two assumptions, a set of cluster ranking, term selection and ranking and sentence extraction strategies are developed. The remainder of this paper is organized as follows. Section 2 introduces the proposed extractive summarization approach based on event term clustering. Section 3 presents experiments and evaluations. Finally, Section 4 concludes the paper. 2 Summarization Based on Event Term Clustering 2.1 Event Term Graph We introduce VerbOcean (Chklovski and Pantel, 2004), a broad-coverage repository of semantic verb relations, into event-based summarization. Different from other thesaurus like WordNet, VerbOcean provides five types of semantic verb relations at finer level. This just fits in with our idea to introduce event term relations into summarization. Currently, only the stronger-than relation is explored. When two verbs are similar, one may denote a more intense, thorough, comprehensive or absolute action. In the case of change-of-state verbs, one may denote a more complete change. This is identified as the strongerthan relation in (Timothy and Patric</context>
</contexts>
<marker>Chklovski, Pantel, 2004</marker>
<rawString>Timothy Chklovski and Patrick Pantel. 2004. VerbOcean: Mining the Web for Fine-Grained Semantic Verb Relations. In Proceedings of Conference on Empirical Methods in Natural Language Processing, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Judith L Klavans</author>
<author>Melissa L Holcombe</author>
</authors>
<title>Simfinder: A Flexible Clustering Tool for Summarization.</title>
<date>2001</date>
<booktitle>In Workshop on Automatic Summarization, NAACL,</booktitle>
<contexts>
<context position="2760" citStr="Hatzivassiloglou et al (2001)" startWordPosition="398" endWordPosition="401">port that the improved performance can be achieved by taking into account of event distributional similarities, but it does not benefit much from semantic similarities. This motivated us to further investigate whether event-based summarization can take advantage of the semantic relations of event terms, and most importantly, how to make use of those relations. Our idea is grouping the terms connected by the relations into the clusters, which are assumed to represent some topics described in documents. In the past, various clustering approaches have been investigated in document summarization. Hatzivassiloglou et al (2001) apply clustering method to organize the highly similar paragraphs into tight clusters based on primitive or composite features. Then one paragraph per cluster is selected to form the summary by extraction or by reformulation. Zha (2002) uses spectral graph clustering algorithm to partition sentences into topical groups. Within each cluster, the saliency scores of terms and sentences are calculated using mutual reinforcement principal, which assigns high salience scores to the sentences that contain many terms with high salience scores. The sentences and key phrases are selected by their salie</context>
</contexts>
<marker>Hatzivassiloglou, Klavans, Holcombe, 2001</marker>
<rawString>Vasileios Hatzivassiloglou, Judith L. Klavans, Melissa L. Holcombe, et al. 2001. Simfinder: A Flexible Clustering Tool for Summarization. In Workshop on Automatic Summarization, NAACL, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenjie Li</author>
<author>Wei Xu</author>
<author>Mingli Wu</author>
</authors>
<title>Extractive Summarization using Inter- and IntraEvent Relevance.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>369--376</pages>
<contexts>
<context position="2128" citStr="Li et al (2006)" startWordPosition="305" endWordPosition="308">tion. We approximately define the verbs and action nouns as the event terms which can characterize or partially characterize the event occurrences. 2College of Computer Science and Technology Wuhan University of Science and Technology mfliu_china@hotmail.com Most existing event-based summarization approaches rely on the statistical features derived from documents and generally associated with single events, but they neglect the relations among events. However, events are commonly related with one another especially when the documents to be summarized are about the same or very similar topics. Li et al (2006) report that the improved performance can be achieved by taking into account of event distributional similarities, but it does not benefit much from semantic similarities. This motivated us to further investigate whether event-based summarization can take advantage of the semantic relations of event terms, and most importantly, how to make use of those relations. Our idea is grouping the terms connected by the relations into the clusters, which are assumed to represent some topics described in documents. In the past, various clustering approaches have been investigated in document summarizatio</context>
</contexts>
<marker>Li, Xu, Wu, 2006</marker>
<rawString>Wenjie Li, Wei Xu, Mingli Wu, et al. 2006. Extractive Summarization using Inter- and IntraEvent Relevance. In Proceedings of ACL 2006, pp369-376.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Guo</author>
<author>George Stylios</author>
</authors>
<title>An intelligent summarization system based on cognitive psychology.</title>
<date>2005</date>
<journal>Journal of Information Sciences,</journal>
<volume>174</volume>
<pages>1--2</pages>
<contexts>
<context position="3480" citStr="Guo and Stylios, 2005" startWordPosition="508" endWordPosition="511">imitive or composite features. Then one paragraph per cluster is selected to form the summary by extraction or by reformulation. Zha (2002) uses spectral graph clustering algorithm to partition sentences into topical groups. Within each cluster, the saliency scores of terms and sentences are calculated using mutual reinforcement principal, which assigns high salience scores to the sentences that contain many terms with high salience scores. The sentences and key phrases are selected by their saliency scores to generate the summary. The similar work based on topic or event is also reported in (Guo and Stylios, 2005). The granularity of clustering units mentioned above is rather coarse, either sentence or paragraph. In this paper, we define event term as clustering 185 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 185–188, Prague, June 2007. c�2007 Association for Computational Linguistics unit and implement a clustering algorithm based on semantic relations. We extract event terms from documents and construct the event term graph by linking terms with the relations. We then regard a group of closely related terms as a topic and make the following two alterative assumptions: (1) If we could </context>
</contexts>
<marker>Guo, Stylios, 2005</marker>
<rawString>Yi Guo and George Stylios. 2005. An intelligent summarization system based on cognitive psychology. Journal of Information Sciences, Volume 174, Issue 1-2, Jun. 2005, pp1-36.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>