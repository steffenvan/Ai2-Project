<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.936616333333333">
A Model for Matching Semantic Maps
between Languages (French/English,
English/French)
</title>
<author confidence="0.978935">
Sabine Ploux∗ Hyungsuk Ji∗
</author>
<affiliation confidence="0.432969">
Institut des Sciences Cognitives Institut des Sciences Cognitives
</affiliation>
<bodyText confidence="0.999821714285714">
This article describes a spatial modelfor matching semantic values between two languages, French
and English. Based on semantic similarity links, the model constructs a map that represents a
word in the source language. Then the algorithm projects the map values onto a space in the target
language. The new space abides by the semantic similarity links specific to the second language.
Then the two maps are projected onto the same plane in order to detect overlapping values. For
instructional purposes, the different steps are presented here using a few examples. The entire set
of results is available at the following address: http://dico.isc.cnrs.fr.
</bodyText>
<sectionHeader confidence="0.984265" genericHeader="abstract">
1. Goals
</sectionHeader>
<bodyText confidence="0.964403588235294">
This article presents a spatial model that projects the semantic space of a source lan-
guage word onto a semantic space in the chosen target language. Although the study
presented in this article can be described from various angles, we place it within the
framework of artifactual simulations of the translation process, and more specifically,
access to the target language’s lexicon. The model is described as a construction pro-
cess designed to reproduce cognitive functions and their extensions. Future research
will include the study of the psycholinguistic validity of such a spatial representation.
Now let us briefly describe the scientific basis of the study.
• Three major areas are generally distinguished in the study of the
translation process (see Vinay and Darbelnet [1996]), the lexicon (or the
study of notions), sentence generation (putting words together), and the
message (which brings communicative factors into play). The first area
involves choosing the right word, which is usually left up to the
intuition and expertise of the translator. Our model deals with accessing
the lexicon of the target language starting from a notion in the source
language. The utility of this research lies in the fact that different
languages break down reality in different ways.
</bodyText>
<listItem confidence="0.976854714285714">
• Although the translation process has been mastered by a number of
experts, it is usually still dependent upon the utilization of tools like
dictionaries. The model proposed here relies on semantic maps and
offers an alternative method based on the concepts of lexical access and
lexical neighborhood.
• The work by Anderson (1983) and Collins and Loftus (1975) on the
organization of the lexicon is based on priming and the automatic
</listItem>
<footnote confidence="0.433058">
∗ UMR 5015 CNRS-Universit´e Lyon I, 67 bd Pinel, F-69 675 Bron Cedex. E-mail:{ploux,ji}@isc.cnrs.fr.
© 2003 Association for Computational Linguistics
</footnote>
<note confidence="0.797171">
Computational Linguistics Volume 29, Number 2
</note>
<bodyText confidence="0.999810428571429">
spreading of activation to the prime’s neighboring concepts. As an
alternative to these local semantic networks, Masson (1995) proposed a
connectionist model that takes into account the subjects’ reaction time
during priming experiments (the correspondence is based on the
assumption that semantic or phonologic proximity and ease of access are
correlated). Rouibah, Ploux, and Ji (2001) showed that experimental data
on interactions between phonology and semantics could be simulated by
distances on lexical maps. One advantage of this proposal is that
experimental and artifactual findings converge; another is its ability to
describe a real lexicon. Although the relevance of our model to the
representation of the mental lexicon will not be discussed in this article
(attempts to gain insight into this correlation are currently underway in
other studies), this point is not unrelated to the suitability of our
approach to modeling translation as a cognitive function.
</bodyText>
<sectionHeader confidence="0.853386" genericHeader="keywords">
2. Description of the Model
</sectionHeader>
<bodyText confidence="0.98839075">
No two lexicons are related by a one-to-one correspondence (Abplanalp 1998). In
other words, the way words are used to refer to extralinguistic reality varies across
languages. Some examples of this are cross-language differences in color naming and,
borrowing Chuquet and Paillard’s (1989) English-French examples, differences like:
</bodyText>
<listItem confidence="0.999839666666667">
• room: pi`ece, chambre, bureau
(or in an abstract domain)
• esprit: mind, spirit, wit
</listItem>
<bodyText confidence="0.9998195">
Certain authors (Abplanalp 1998) insist how impossible it is to translate at the
word level and propose recourse to the conceptual level as a theoretical alternative.
Concepts are thought to depend on human cognitive abilities that are general and
shared by all. Although the correspondence between words and concepts remains a
controversial topic of study (Reboul 2000), the concept/word opposition is neverthe-
less relevant to any model of translation, even an artifactual one like ours. As we shall
see, even when heeding the specific organization and breakdown of each individual
language, the matching operation does not take place at the word level but at the
substrate level (defined below), where the set of meanings of each word “cuts out” a
form.
First, we will present the model we devised to describe the organization of lan-
guages. Then we will explain the source-to-target spreading method used.
</bodyText>
<subsectionHeader confidence="0.768804">
2.1 A Model Based on Semantic Similarity
</subsectionHeader>
<bodyText confidence="0.999644875">
The model was initially developed on the basis of a semantic similarity: synonymy.
Note, however, that the data and the model are independent, so this same framework
can be used to organize other types of similarity (contextual, phonological [Rouibah,
Ploux, and Ji 2001], etc.). Other authors also organize the lexicon or other kinds of
knowledge on the basis of similarity. For example, in Edelman’s (1998) spatial model
of internal representations of the world’s objects, spatial proximity reflects object simi-
larity. WordNet (Fellbaum 1998) and EuroWordNet (Vossen 1998) organize the lexicon
conceptually as a network of terms, each of which is associated with a partition into
</bodyText>
<page confidence="0.995287">
156
</page>
<note confidence="0.941459">
Ploux and Ji A Model for Matching Semantic Maps
</note>
<bodyText confidence="0.90193">
Synsets (a Synset being a small group of synonyms that label a concept). Our model
differs from Edelman’s in that it deals with lexical semantics, not perceived objects. It
also differs from Miller’s (1990) approach, in three respects:
</bodyText>
<listItem confidence="0.999537333333333">
• the grain of the semantic units
• the lexical structure generation mode
• the resulting geometry and organization
</listItem>
<bodyText confidence="0.999777">
Most models1 use separate units to represent words or concepts (symbols, points in a
space, nodes on a graph, etc.). Relationships between units are expressed as proximity
links (in spatial models) or as arcs between nodes (in networks). Our model is spa-
tial, but it differs from local models in that each term is represented by a region in the
space, part of which it shares with other terms. This region is constructed automatically
according to lexical similarity links (such as those given by a synonym dictionary). It
is not the result of supervised learning, nor is it a manual, ontological description of
how the lexicon is organized. The next section will break the semantic-space construc-
tion process into steps in presenting the initial data, the granular approach, and the
resulting organization.
</bodyText>
<subsectionHeader confidence="0.998215">
2.2 Method
</subsectionHeader>
<bodyText confidence="0.989378789473684">
2.2.1 Initial Data. Three databases were used: two synonym databases (one containing
French terms and one containing English terms) and a translation database (French-
English, English-French) that maps each term to similar words in the other language.
The links between an entry and the terms that follow it were not chosen “by hand.” The
data were taken mainly from published dictionaries and thesauruses.2 It is updated
and supplemented regularly by the addition of new links between words (synonymy
or translation links). The method used to generate the French synonym database (de-
scribed in detail in Ploux (1997) was applied again to generate the English and trans-
lation databases. The first step required creating an intermediate database containing
the set of all links attested in available work in lexicography. In this preliminary
database, a term was deemed similar to another term if at least one lexicographer had
established the link. The final database was obtained through symmetrization of the
links produced in the first step. While maintaining the shifts in meaning that occur
when there is nontransitivity and that, as we shall see, are essential for developing the
model, we created new links to symmetrize any initially one-directional ones.3 Table 1
gives a typical example of the structure of the initial data. Table 2 gives a global eval-
uation of the number of entries and links in the lexical databases. Note that we are
not attempting here to define the term synonymy. We rely on lexicographic publica-
tions, which as Edmonds and Hirst (2002) remarked, “have always treated synonymy
</bodyText>
<footnote confidence="0.754264090909091">
1 Masson’s (1995) model assigns each concept a basin of attraction in a multidimensional space of
activation. This framework authorizes a certain form of internal variability for the set of patterns
corresponding to a concept. Nevertheless the basins are disjoint and do not overlap as do the nodes in
local semantic networks. Furthermore, this model, built essentially for the purposes of validating
hypotheses and comparing psycholinguistic results, is applicable only to a highly limited vocabulary
and is therefore a poor representative of the natural lexicon.
2 For the French database, we used files compiled by the National Institute for the French Language
(INALF: Institut National de la Langue Fran¸caise) from seven different 19th- and 20th-century
synonym dictionaries; for the English and translation databases, we used files obtained from the
French company MEMODATA.
3 Note that symmetrization does not make the semantic spaces of the two terms equivalent.
</footnote>
<page confidence="0.984286">
157
</page>
<note confidence="0.860299">
Computational Linguistics Volume 29, Number 2
</note>
<tableCaption confidence="0.994709">
Table 1
</tableCaption>
<table confidence="0.252036">
Format of data files.
Headword: Similar1, Similar2, Similar3, .. .
insensible: apathetic, benumbed, callous, comatose, impassive, impercep-
(extracted from the tible, impercipient, indiscernible, insensitive, pachydermatous,
similar English word senseless, thick-skinned, unaffected, unaware, unconscious, un-
database) detectable, unfeeling, unsympathetic
insensible: adamantin, anesth´esi´e, apathique, aride, assoupi, blas´e, calleux,
(extracted from the calme, cruel, de marbre, dess´ech´e, dur, d´etach´e, endormi, endurci,
similar French word engourdi, flegmatique, ...
database) imperceptible, insensitive, numb, unfeeling
insensible:
(extracted from the
French-English
translation
database)
</table>
<tableCaption confidence="0.910261">
Table 2
</tableCaption>
<subsectionHeader confidence="0.774303">
Number of entries and links in the lexical databases.
</subsectionHeader>
<bodyText confidence="0.972889875">
Number of entries Mean number of Mean number of terms
synonyms per entry proposed by the translation
database
French 54,690 7.5 2.3
English 148,247 6.8 1.9
as near-synonymy.”4 However, having more flexible semantic links does not detract
from the accuracy of the model. No other operations are carried out on the data sets
before application of the model.
</bodyText>
<subsubsectionHeader confidence="0.561423">
2.2.2 Semantic Units. To represent variations in a word’s meaning, each word is asso-
</subsubsectionHeader>
<bodyText confidence="0.842218571428572">
ciated with a spatial form (or space) (Ploux 1997; Ploux amd Victorri 1998). The points
in the space are finer units of meaning than the word itself. In our computational
simulation, the points are represented by cliques. A clique is a set of terms related
to each other by synonymy.5 The conjunction of all terms in the same clique crys-
tallizes and constrains the meaning given to the word. These cliques thus constitute
good candidates for generating the substrate upon which the form will take shape.
The presentation of the results and the features of the model will be illustrated using
examples from the headword good for English and from the headword insensible for
French. The Appendix provides the full results, as well as the definition of the word
insensible taken from a French dictionary. These examples are illustrative of the main
characteristics of the entire data set.
4 Moreover, for the two languages under study here, there are notable differences in how lexicographers
understand and use the concept of synonymy. Synonymy relations in French dictionaries, for example,
are not always symmetrical and are rarely transitive. What is more, the links have a broader scope. For
instance, the words abri (shelter) and even masure (shed) are given as synonyms of maison (house). To
make the databases homogeneous during the matching operation, a new version of the English
database was supplemented with certain hypernym links often given as synonyms in French
dictionaries. The software offers the user the opportunity to see the output obtained using the two
versions of the English database, displayed under the headings standard search and enriched search.
5 By definition, this is a maximal, connected component of the synonym graph. Words are placed at the
nodes of the graph, and arcs between two nodes represent a synonymy link.
</bodyText>
<page confidence="0.990892">
158
</page>
<note confidence="0.620281">
Ploux and Ji A Model for Matching Semantic Maps
</note>
<bodyText confidence="0.939222">
The synonym list contains a heterogeneous set of scrambled terms:
</bodyText>
<listItem confidence="0.99393875">
• For the French headword insensible, some of the terms represent a moral
value (dur, sans-coeur, ... ), others a physical value (inerte, engourdi, ... ),
and still others a perceptual value (imperceptible, inapparent ... ).
• The headword good includes many similar terms. As a first
</listItem>
<bodyText confidence="0.995934833333333">
approximation, only the most representative are given here. Some of the
terms represent a generic value (right, sound, ... ), others refer to a
capability (able, ... ) or have an affect-related value (benevolent, ... ), while
still others represent a quality of taste (tasty, ... ).
The clique list contains the cliques generated from this set of terms. Cliques represent
rather precise units of meaning.6
</bodyText>
<listItem confidence="0.882412222222222">
• Here are some examples of cliques representing the moral value of the
French headword insensible:
20: cruel, dur, impitoyable, implacable, inexorable, inflexible,
inhumain, insensible
21: cruel, dur, impitoyable, implacable, inexorable, inflexible,
insensible, s´ev`ere
22: cruel, dur, implacable, inflexible, inhumain, insensible, rigide
23: cruel, dur, implacable, inflexible, insensible, rigide, s´ev`ere
Some examples of cliques representing the physical value:
2: anesth´esi´e, insensible
50: endormi, engourdi, inerte, insensible
51: engourdi, froid, inerte, insensible
52: engourdi, immobile, inerte, insensible, paralys´e
And some examples of cliques representing the perceptual value:
69: imperceptible, inapparent, insensible, invisible
70: imperceptible, indiscernable, insaisissable, insensible, invisible
71: imperceptible, indiscernable, insensible, l´eger
• Here are some examples of cliques representing the more prominent
senses of the English headword good:
84: dependable, good, reliable, safe, secure
87: dependable, good, reliable, solid, sound
102: fair, good, honest, honourable, just, right, upright
Some examples of cliques representing a more specific meaning of
aptitude or ability:
6: able, adequate, capable, competent, effective, good
7: able, adroit, clever, dexterous, expert, good, skilful
8: able, capable, clever, expert, good, skilful
</listItem>
<footnote confidence="0.654925">
6 The cliques are numbered here in the order in which the results are presented on the Web site
(alphabetical order).
</footnote>
<page confidence="0.985248">
159
</page>
<note confidence="0.383693">
Computational Linguistics Volume 29, Number 2
</note>
<bodyText confidence="0.615473">
And some examples of cliques with affect-related values:
</bodyText>
<listItem confidence="0.899192666666667">
111: friendly, gentle, good, kind, kindly, nice, sweet
112: friendly, good, gracious, kind, kindly, nice, sweet
113: friendly, good, helpful, kind
Note that a given term may belong to several cliques (this characteristic is due to
the nontransitivity of the relation). It appears in each clique with a precise meaning
that is constrained by the presence of its neighbors.
• For example, the following cliques have terms in common; the first has a
stronger moral value than the second:
15: calme, flegmatique, froid, impassible, imperturbable, insensible
18: calme, immobile, inanim´e, insensible
• In the same manner, there are shared terms in the next two cliques of
good, the first related to taste, the second to personal qualities:
</listItem>
<bodyText confidence="0.9409732">
80: delectable, delicious, good, lovely, savoury, scrumptious, tasty
82: delicious, good, lovely, nice, pleasant
This last point brings us to the study of semantic variations. The following clique
path, in which each clique shares at least one term with the next, moves in a relatively
continuous way from one value to another.
</bodyText>
<listItem confidence="0.9441647">
• Transition from a moral value to a physical value:
21: cruel, dur, impitoyable, implacable, inexorable, inflexible,
insensible, s´ev`ere
34: dur, froid, impitoyable, implacable, insensible, s´ev`ere
35: dur, froid, inaccessible, indiff´erent, insensible
39: dur, impassible, indiff´erent, insensible, stoique
15: calme, flegmatique, froid, impassible, imperturbable, insensible
16: calme, froid, inanim´e, insensible
63: froid, inanim´e, inerte, insensible
83: inanim´e, inerte, insensible, mort
</listItem>
<bodyText confidence="0.997615909090909">
The continuity between the moral and physical values has its
counterpart in their usage. For example, one can use the term engourdi in
French to qualify the disposition of a person who exhibits little moral
reactivity, as in:
Il allait comme dans un songe, l’esprit engourdi, paralys´e, sans chagrin
vibrant, saisi par une sorte d’engourdissement moral qui l’empˆechait de
souffrir, ´eprouvant mˆeme un all´egement qu’augmentaient les exhalaisons
ti`edes ´epandues dans la nuit.7 (Maupassant 1881, page 350)
Moreover, as we shall see later, this type of continuous link between two
values, which acts as a metaphor here, is expressed more explicitly in the
English example below.
</bodyText>
<footnote confidence="0.94660425">
7 Although the term engourdi is not specifically translated, to help the reader understand this fine shade
of meaning, here is a translation of the above passage (Maupassant 2002): He walked as if he were in a
dream; his thoughts were paralyzed, although he felt no great grief, for he was in a state of mental torpor that
prevented him from suffering, and he even felt a sense of relief which was increased by the mildness of the night.
</footnote>
<page confidence="0.995136">
160
</page>
<note confidence="0.940382">
Ploux and Ji A Model for Matching Semantic Maps
</note>
<tableCaption confidence="0.998853">
Table 3
</tableCaption>
<table confidence="0.9959450625">
Evaluation of clique granularity.
Entry Number of cliques Number of distinc- Number of Synsets
containing entry tions found in pub- in WordNet
lished dictionaries
d´efendre 44 9–13 —
distraction 39 3–10 —
fou 319 10–23 —
jouer 95 15–46 —
maison 123 9–42 —
vert 50 9 —
blue 54 22–34 26
house 82 11–24 11
good 193 24–50 30
look 104 18–73 13
mind 87 41–68 13
play 240 77–84 47
</table>
<listItem confidence="0.994791">
• Transition from a taste-related value to an affective value:
</listItem>
<bodyText confidence="0.956483181818182">
80: delectable, delicious, good, lovely, savoury, scrumptious, tasty
78: delectable, delicious, excellent, exquisite, good, lovely,
scrumptious
77: delectable, delicious, enjoyable, good, pleasant
79: delectable, delicious, good, lovely, pleasant
82: delicious, good, lovely, nice, pleasant
114: friendly, good, kind, kindly, nice, pleasant, sweet
111: friendly, gentle, good, kind, kindly, nice, sweet
By contrast, for the French headword insensible, there is greater discontinuity between
the perceptual value and the others. At the present stage of our project, clique lists are
in alphabetical order, and the underlying semantic topology has not yet been built.
The geometric model we are now going to present achieves this step. Table 3 contains
an evaluation of the granularity generated by the cliques.
2.2.3 Output Geometry and Organization. To construct the semantic space, a con-
ventional correspondence factorial analysis8 (Benz´ecri 1992) was conducted between
the cliques and the synonyms. For each entry, the initial matrix Mij contains nc rows
(where nc stands for the number of cliques) and ns columns (where ns stands for the
number of terms). It is defined by the formula Mij = 1 if clique i contains term j, and 0
if not. The results showed that the χ2 distances9 calculated using this method furnish
a coherent representation of semantic variations. Table 4 presents the configurations
8 Correspondence analysis is a factor analysis method that uses categorical variables (that is,
noncontinuous or discretized ones).
</bodyText>
<equation confidence="0.835943875">
9
n
E
j=1
xij
x − xkj 2
x.j xi. xk.
d(ci, ck) =
</equation>
<bodyText confidence="0.991591666666667">
where ci and ck are two cliques, n is the number of synonymous terms, xi. the number of terms in ci
(respectively ck), x.j the frequency of term tj and x the sum of the frequencies of all terms (or the total
number of terms in all cliques).
</bodyText>
<page confidence="0.992052">
161
</page>
<note confidence="0.40857">
Computational Linguistics Volume 29, Number 2
</note>
<tableCaption confidence="0.998531">
Table 4
</tableCaption>
<table confidence="0.9412892">
Comparison of Euclidean distance and x2 distance on the principal plane for the above cliques.
Euclidian distance x2 distance
d(c23, c12) 1.7855 1.7357
d(c17, c23) 0.6306 0.0170
d(c12, c17) 1.2382 1.17213
</table>
<figureCaption confidence="0.967339">
Figure 1
</figureCaption>
<bodyText confidence="0.969932333333333">
Two-cluster semantic space for the French headword insensible.
on the principal plane for the Euclidean distance and the χ2 distance, reduced to the
same proportion. The headword fast has many cliques, including
</bodyText>
<listItem confidence="0.999920666666667">
• c12: express, fast, quick, rapid, swift
• c17: fast, fastened, fixed, secure
• c23: fast, firm, lasting, stable, tight
</listItem>
<bodyText confidence="0.9990407">
The values obtained using the χ2 distance are more suited to semantic categorization
than those obtained using Euclidean distance; cliques representing the same class
are closer together (even if they do not share a larger number of terms) than ones
representing different meanings.
The dimension of the geometric space is equal to the smaller of the two numbers, ns
or nc. To show the results visually, the projections onto the principal axes are presented
in Figures 1 and 2. (The horizontal axis in the figures is the best representative of the
form delineated by the cluster of points such that the distances between the points are
maintained to the optimal degree; the vertical axis, perpendicular to the first, is the
second best representative, and so on.) Cliques are represented by points, and each
</bodyText>
<page confidence="0.99053">
162
</page>
<note confidence="0.869532">
Ploux and Ji A Model for Matching Semantic Maps
</note>
<figureCaption confidence="0.976474">
Figure 2
</figureCaption>
<bodyText confidence="0.98199975">
Three-cluster semantic space for the English headword good.
term by the region in the space delineated by the set of cliques that contains it.10 Using
the examples again, let us review the main characteristics of the resulting organization.
The same type of organization is found in all cases.
</bodyText>
<listItem confidence="0.969157944444444">
2.2.4 Distinguishing Semantic Values. The model plots the different values on the
map. Distinct notions are clearly separate, and gradual variations are maintained.
• In the insensible example (Figure 1), we can see two clusters as a first
approximation, one smaller cluster labeled by the terms imperceptible,
inapparent, indiscernable, n´egligeable, etc., and representing the perceptual
value of the word, and one larger cluster containing the moral and
physical values. In the center of the second cluster, we find the terms
dur, inhumain, sans-coeur, cruel, etc., which are prototypes of the word’s
moral value. Two branches come out of this center, one that qualifies a
more specific value (r´efractaire, rebelle, imp´en´etrable, etc.), and one that
leads to the physical value.11
• In the good example (Figure 2), the cliques and terms are plotted on the
map in accordance with the proximities of the values and their links. On
the principal plane, the cluster of points extends in two directions: the
first axis represents the capability value, and the second the affective
value. The affective value gradually turns into a taste-related value (tasty,
... ). These two main directions are interconnected by the generic value
(right, true, ... ) located near the origin.
</listItem>
<footnote confidence="0.59716925">
10 An appropriate algorithm generates the envelope (i.e., the set of cliques that contains the term) for a
given term.
11 In all figures in this article, the principal classes are outlined. (A publication about the principles of this
automatic classification model is now in preparation; only the results are given here.)
</footnote>
<page confidence="0.993468">
163
</page>
<note confidence="0.405317">
Computational Linguistics Volume 29, Number 2
</note>
<tableCaption confidence="0.983285">
Table 5
</tableCaption>
<subsectionHeader confidence="0.638997">
Some examples of spatial interconnections between semantic values.
</subsectionHeader>
<bodyText confidence="0.948916714285714">
Entry Value at the origin (labeled by Examples of off-centered values
a prototype) (labeled by prototypes)
d´efendre prot´eger 1. excuser 2. interdire, .. .
maison domicile 1. commerce 2. lign´ee, .. .
insensible sans-coeur 1. imperceptible, 2. engourdi, .. .
home abode 1. family, 2. interior, ...
good right 1. able, 2. delicious, .. .
</bodyText>
<subsubsectionHeader confidence="0.746915">
2.2.5 Spatially Interconnecting the Values. Table 5 shows the hierarchy of the spatial
</subsubsectionHeader>
<bodyText confidence="0.9994885">
organization. The middle column contains the generic values (when they exist) that
interconnect the different meanings of the word. Highly specific values are far from
the origin. This organization follows directly from the calculation of the profile matrix,
which assigns more weight to infrequent terms and to cliques containing few elements.
</bodyText>
<subsectionHeader confidence="0.999372">
2.3 Matching
</subsectionHeader>
<bodyText confidence="0.991752733333333">
As stated above, the breakdown and overlapping of the lexicon varies from one lan-
guage to the next. However, several studies (Illes and Francis 1999; Ikeda 1998) have
found evidence that the two languages of a bilingual person access a common se-
mantic system. To handle the problem of lexical differences in our translation model,
connections link semantic units rather than words. Because they are finer-grained than
words, semantic units are assumed to be less sensitive to the way a given language
“cuts up” the world, and as such, they are better candidates for achieving a closer
fit between the two languages. For a given set of cliques in the source language, the
model constructs the set of cliques to be used for the translation. The two spaces
(one associated with each set of cliques) are then projected onto a map that maintains
the matches. The example of insensible is a good representative of the various pat-
terns that can appear. It has two very different, nearly homonymic semantic values,
as well as some other values whose meanings overlap considerably. For this reason,
we present the results for the matching operation using this example. The four steps
in this construction process are described below.
Step 1. Constructing the source semantic space. In order to build a semantic
space in the target language associated with a term in the source
language, the system starts by generating the set of all cliques containing
the requested word. This step is identical to the one described in
Section 2.2.2.
Step 2. Searching for relevant target language units for translation. For all
initial terms similar to the input word, the translation database furnishes
the corresponding terms in the target language. Some of these terms are
relevant to the initial generic meaning; others are clearly far removed
from that meaning. For example, the synonyms timide and l´eger of the
term insensible can be translated respectively as (... , shy, ... ) for timide
and (... , airy, ... ) for l´eger, neither of which is useful in generating this
headword’s target semantic space. To find the relevant senses, the model
compares the source language cliques to the cliques generated from the
set of terms proposed by the translation database. Target clique relevance
</bodyText>
<page confidence="0.986579">
164
</page>
<note confidence="0.783849">
Ploux and Ji A Model for Matching Semantic Maps
</note>
<bodyText confidence="0.999895">
is calculated as follows: Let S be a clique in the source language
composed of the terms (tsi)i=1···nS, and let C be clique (tjc )i=j···nC in the
target language. The model evaluates the relevance of the translation
based on the rank of matrix MSC, composed of zeroes and ones,
calculated using the formula MSC[i][j] = 1, if tjc translates tsi, and
MSC[i][j] = 0, otherwise. The rank defines a spreading parameter (in the
model, a rank of zero means that the two cliques are unrelated and the
target clique represents an out-of-range meaning in the translation
operation; a rank of three or more represents a highly cohesive semantic
link).
If this last constraint is imposed on all cliques, the model will output a
relatively small number of terms belonging to the target’s semantic
field.12
Step 3. Constructing the source-point/target-point geometry. The factorial
analysis algorithm (presented in Section 2.2.3) is followed to determine
the correspondences between the source cliques and the target cliques
that were retained in step 2, because they are relevant to at least one
clique in the source language. The correspondences are determined by
taking the product of the following matrices:
</bodyText>
<equation confidence="0.81264">
Mtr = MScs ∗ Tsc ∗ M�C cs
</equation>
<bodyText confidence="0.9998969">
where MScs is the source-clique/source-term matrix defined as in
monolingual processing (see Section 2), Tsc is the matrix that defines the
translation between the source terms and the target terms (Tsc[i][j] = 1 if
and only if term j translates term i in the initial database), and Mc§ is the
transposed target-clique/target-term matrix.
For a subset of the French cliques of insensible, the closest three English
cliques are given below for each French clique, along with a table of the
corresponding distances calculated on the principal plane (Table 6). The
maps reproduced in Figures 3–5 summarize the resulting distances for
the headword insensible.
</bodyText>
<listItem confidence="0.969796636363636">
• cf28: cruel, dur, f´eroce, impitoyable, implacable, inexorable,
inhumain, insensible
ce67: cruel, ferocious, fierce, ruthless, savage
ce84: cruel, inhuman, merciless, pitiless, ruthless, savage
ce28: bitter, cruel, fierce, ruthless, savage
• cf40: dur, indiff´erent, inhumain, insensible, sans-coeur
ce36: callous, hard, hardened
ce33: callous, cruel, hard, hard-hearted, heartless
ce92: difficult, hard, tough
• cf78: imperm´eable, insensible, rebelle, r´efractaire, sourd
ce148: insensitive, unmoved
</listItem>
<footnote confidence="0.589768">
12 Our software proposes two types of lexical access. The first is more restrictive and sets the rank at
three or more; the second supplies a broader vocabulary and sets the rank at two or more.
</footnote>
<page confidence="0.981677">
165
</page>
<table confidence="0.472524">
Computational Linguistics Volume 29, Number 2
</table>
<tableCaption confidence="0.989172">
Table 6
</tableCaption>
<table confidence="0.972516538461538">
Distances between French and English cliques on the principal plane. (For all cliques, the
distances ranged between 0.0035 and 4.0183.)
cf28 cf40 cf50 cf51 cf68 cf71 cf78
ce17 2.6483 2.1008 0.3486 0.1542 3.2331 3.6239 1.3379
ce28 0.2567 0.3009 2.0498 2.3846 3.1128 3.5984 1.0726
ce33 0.5407 0.0543 1.7672 2.1031 3.0130 3.5002 0.7897
ce36 0.5625 0.0439 1.7467 2.0831 2.9967 3.4839 0.7670
ce40 1.3223 0.7680 1.0502 1.3933 2.6981 3.1721 0.0907
ce67 0.1151 0.4404 2.1912 2.5256 3.1666 3.6503 1.2135
ce84 0.2228 0.3323 2.0854 2.4206 3.1108 3.5959 1.1056
ce87 2.3812 1.8385 0.0813 0.2630 3.2189 3.6326 1.0886
ce89 2.5708 2.0272 0.2656 0.0944 3.2805 3.6799 1.2730
ce92 0.5461 0.0633 1.7609 2.0965 3.0209 3.5081 0.7856
ce97 2.5336 1.9861 0.2365 0.1846 3.1868 3.5866 1.2240
ce98 2.3637 1.8176 0.0676 0.3000 3.1508 3.5641 1.0598
ce100 2.2895 1.7453 0.0164 0.3593 3.1568 3.5761 0.9926
ce112 3.0294 2.7339 2.8600 3.0620 0.3066 0.7473 2.5137
ce114 3.6318 3.3733 3.5037 3.6875 0.4153 0.0788 3.1821
ce129 2.9849 2.6955 2.8534 3.0606 0.3108 0.7718 2.4883
ce130 1.3400 0.7892 0.9756 1.3163 2.8715 3.3439 0.0867
ce137 3.1895 2.9208 3.1005 3.3031 0.0685 0.5290 2.7350
ce148 1.3696 0.8147 0.9837 1.3268 2.7454 3.2172 0.0551
ce149 3.6058 3.3440 3.4678 3.6514 0.3879 0.1143 3.1488
ce152 3.6335 3.3752 3.5061 3.6899 0.4171 0.0765 3.1843
ce130: impassive, indifferent, phlegmatic, stoical
ce40: callous, impassive, insensible, unfeeling
</table>
<listItem confidence="0.8641532">
• cf50: engourdi, froid, inerte, insensible
ce100: dull, inanimate, inert, lifeless
ce98: dull, expressionless
ce87: dead, inanimate, inert, lifeless
• cf51: engourdi, immobile, inerte, insensible, paralys´e
ce89: dead, numb, paralytic
ce17: asleep, numb
ce97: dull, dulled
• cf68: imperceptible, insensible, invisible
ce137: imperceptible, indiscernible, invisible
ce112: frivolous, indifferent, insignificant, trifling, unimportant
ce129: impalpable, imperceptible, intangible, invisible
• cf71: imperceptible, insensible, insignifiant, l´eger
ce152: light, slight, trifling, trivial
ce114: frivolous, light, trifling, trivial
</listItem>
<bodyText confidence="0.9375546">
ce149: insignificant, slight, trifling, trivial, unimportant
Step 4. Defining the lexical regions. As above, for each language, a term is
represented by the clique region that contains it.
The next section will use examples to illustrate the results obtained. The entire set
of results is available at http://dico.isc.cnrs.fr.
</bodyText>
<page confidence="0.995088">
166
</page>
<note confidence="0.918876">
Ploux and Ji A Model for Matching Semantic Maps
</note>
<figureCaption confidence="0.890335">
Figure 3
</figureCaption>
<bodyText confidence="0.624922">
English-French space matching for the English headword insensible.
</bodyText>
<sectionHeader confidence="0.999371" genericHeader="introduction">
3. Results
</sectionHeader>
<bodyText confidence="0.999852">
The advantages of the model presented are (1) access to an extended lexicon and a
broad semantic field and (2) coherence of the matching between the semantic values in
each language. The results for insensible will be used again in this section to illustrate
the second advantage.
</bodyText>
<subsectionHeader confidence="0.999763">
3.1 Access to an Extended Semantic Field and Lexicon
</subsectionHeader>
<bodyText confidence="0.9999402">
The model fulfills two functions: It searches for a suitable lexicon and organizes the
terms found. For each entry, the initial data provides a short list of terms representing
certain prototypes of the word’s translation. Table 1 lists the four English terms pro-
posed as translations for the French word insensible. It can happen that certain semantic
values in the source language are not represented in the translation database. For ex-
ample, insensible has no corresponding French word in our database of English word
translations. However, the model builds the appropriate values in French (Figure 3).
The model builds a much larger vocabulary that includes the initial terms from
the translation database and some semantic neighbors. Table 7 presents an overall
evaluation of the results.
</bodyText>
<tableCaption confidence="0.960554">
Table 7
</tableCaption>
<table confidence="0.34798">
Assessment of lexical access spreading to the target language.
</table>
<tableCaption confidence="0.4941004">
Mean number of terms supplied by the
translation database from a sample of 60
terms
Mean number of terms supplied by the
semantic maps of the same sample
</tableCaption>
<footnote confidence="0.604441">
14.1 92.9
</footnote>
<page confidence="0.932235">
167
</page>
<figure confidence="0.752904">
Computational Linguistics Volume 29, Number 2
</figure>
<figureCaption confidence="0.990138">
Figure 4
</figureCaption>
<bodyText confidence="0.878051">
Two-cluster separation of the French and English spaces for the French headword insensible.
</bodyText>
<subsectionHeader confidence="0.999845">
3.2 Coherence of the Semantic Matching
</subsectionHeader>
<bodyText confidence="0.99927188">
The final step in the model consists of establishing a correspondence between the
semantic values of the cliques and the terms in the two languages. By application
of the above algorithm, the cliques and terms of the two languages are plotted on
the same map. This map thus provides a summary of the semantic proximities in
each language. In order to demonstrate the coherence of the semantic-value matching
after projection onto the target language, the clusters obtained from the French and
English cliques for the term insensible are superimposed on one another. Figures 4 and
5 present the division of the output into two and four clusters. (The French clusters in
these figures are marked by a darker line and set in a darker typeface than the English
ones.) As in the two-cluster semantic space for the French word insensible, Figure 4
separates the perceptual value from the other values.
The three-cluster separation then differentiates the physical-moral value from the
moral value. Figure 5 shows the division within the physical-moral value between
what is more specifically physical and what pertains to emotional insensitivity (emo-
tionless, r´efractaire, etc.) or to the inability to discern that sensitivity (imp´en´etrable, etc.).
Note that although all values initially present in the monolingual space are rep-
resented, a reorganization process still takes place during pairing with the target lan-
guage. In French, the terms (r´efractaire, inacessible, ... ) were separated from the terms
(inerte, engourdi, ... ) by the group made up of the terms (dur, sans-coeur, ... ), but now
they are located close to the center. This layout probably results from (1) the effect
of the greater number of terms like (inert, numb, sluggish, chilly, ... ), which, in En-
glish, unlike in French, encompass emotional and physical insensitivity and therefore
bring these two values closer together on the map, and (2) the prototypical, cen-
tral nature of this value in English, as expressed by the terms (impassive, insensible,
insensitive, ... ).
</bodyText>
<page confidence="0.9971">
168
</page>
<note confidence="0.930205">
Ploux and Ji A Model for Matching Semantic Maps
</note>
<figureCaption confidence="0.960936">
Figure 5
</figureCaption>
<bodyText confidence="0.801943">
Four-cluster separation of the French and English spaces for the French headword insensible.
</bodyText>
<sectionHeader confidence="0.996038" genericHeader="method">
4. Discussion
</sectionHeader>
<bodyText confidence="0.999978">
We have presented a model for matching a semantic space in a source language and a
semantic space in a target language. This model, currently built from lexical similarity
relations (synonymy or near-synonymy and translations), uses several representation
levels: cliques, which represent very precise units of meaning; terms, which are repre-
sented geometrically by a region in the space containing a set of cliques; and clusters,
which are generated from the results of a spatialization process that singles out a term’s
main semantic values. (Again, this last representation level is merely mentioned in the
present article; the method used to generate it and the rationale for its use in semantic
classification will be described in detail in a forthcoming publication.) The matching
between the French and English spaces is achieved by mapping the cliques of the two
languages to each other. The model software allows a user to choose a candidate word
in the target language according to its synonym neighborhood. A map showing each
language’s neighborhoods and separate clusters for each semantic value helps the user
make the choice. This system and its interactive interface is a useful tool appreciated
by researchers, translators, writers, and other users. Although this alone is enough
to justify the model, it would be worthwhile to incorporate it into a more complete
automatic language processing system. We are now working on enhancing the system
by including context relations, and by bringing to bear a word’s argument structure,
qualia structure, and lexical inheritance.
Within the past 10 years, original contributions have been made in the areas of
compositional semantics and lexical context assignment (see Ide and Veronis [1998] for
the state of the art on word sense disambiguation). Most studies have dealt with the
sentence, but some have looked at the discourse and text levels. Based on a generative
framework, Pustejovski (1995) proposed a computational model that adds a represen-
tation of a word’s structures (event structure, argument structure, qualia structure, and
</bodyText>
<page confidence="0.995558">
169
</page>
<note confidence="0.639634">
Computational Linguistics Volume 29, Number 2
</note>
<bodyText confidence="0.999308230769231">
lexical inheritance structure), along with transformation rules for combining units. In
their study, Asher and Lascarides (1995) showed that lexical semantics and discourse
structure may interfere with discourse structure and devised heuristics to disentangle
the effects of these two interacting levels. Other authors (Foltz, Kintsch, and Lan-
dauer 1998; Kintsch 2001; Sch¨utze 1998) have developed an approach based solely on
automatic corpus analysis in which co-occurrences and their frequencies are used to
generate the semantic space associated with a given word. Edmonds and Hirst (2002)
proposed a model with two tiers: a fine-grained synonym tier and a coarse conceptual
tier. Unlike Edmonds and Hirst’s approach, which rests on an ontological model and
conceptual representations, our model is capable of detecting semantic distinctions
solely on the basis of similarity links. This feature is one of the model’s assets, but it is
also a limitation, which provides the incentive for the enhancements we are currently
developing. Here is a brief preview of our ongoing projects:
</bodyText>
<listItem confidence="0.958453928571429">
• Certain words are poorly represented in terms of synonymy. This is the
case for words that are essentially nonpolysemous, like computer or daisy,
and thus have very few synonyms. Such entities are better delineated by
an ontological, hierarchical representation and by their qualia structure
than by synonymy links. Grammatical words also have few synonyms,
so they too need to be represented in a formalism more suited to their
own features than the one proposed in this article.
• Usage contexts or domains of application are not currently given for the
different semantic values detected by the model. For example, the
perceptual value of the word insensible is employed to modify external
phenomena, whereas the moral and physical values apply to animate
beings. It would thus be useful, as in a standard dictionary, to specify
the different types of terms the values obtained can modify.
• Our research should help improve map drawing. At the present time,
</listItem>
<bodyText confidence="0.8917115">
map neighborhoods rely solely on semantic criteria, which sometimes
leads to the map’s including terms with similar meanings but different
syntactic category memberships than the initial word.
These projects should contribute to furthering research on language and automatic
language processing. As stated in the article’s introduction, we are also working on the
cognitive relevance of our model. We have already conducted an initial study aimed
at determining whether a spatial model is an appropriate way of representing the
structure of the mental lexicon. Our work on this problem draws from a preliminary
study (Rouibah, Ploux, and Ji 2001) which proposes a homomorphism between lexical
distance (the organizing principal of our model) and reaction time (the parameter used
in lexical access experiments). This idea is based on the finding that lexical distance is
subject to the same effects as reaction time.
</bodyText>
<sectionHeader confidence="0.980779" genericHeader="method">
Appendix
</sectionHeader>
<bodyText confidence="0.770869666666667">
Example of a classification, for the French term insensible (taken from Le Petit Robert
version 1.2). Rough English translations are given in parentheses.
insensible:
</bodyText>
<listItem confidence="0.949929">
• I Qui ne sent pas, ne ressent rien. (Not sensing, feeling nothing.)
</listItem>
<page confidence="0.989643">
170
</page>
<bodyText confidence="0.53447">
Ploux and Ji A Model for Matching Semantic Maps
</bodyText>
<listItem confidence="0.992223142857143">
1. Qui n’a pas de sensibilit´e physique. inanim´e, mort. (Having no
physical sensitivity. inanimate, dead.)
2. Qui n’´eprouve pas les sensations habituelles, normales. (Not
experiencing the usual, normal sensations) (insensible a` la
douleur, au froid, a` la chaleur. (insensitive to pain, to cold, to
heat.)
3. Qui n’a pas de sensibilit´e morale; qui n’a pas ou a peu
</listItem>
<bodyText confidence="0.692982333333333">
d’´emotions. (Having no moral sensitivity; having few if any
emotions.) apathique, calme, d´etach´e, froid, impassible,
imperturbable, indiff´erent. cruel, dur, ´egoiste, endurci,
impitoyable, implacable, inexorable. imperm ´eable, indiff ´erent.
sourd. ´etranger, ferm ´e, inaccessible; r ´efractaire. (apathetic, calm,
detached, cold, impassible, imperturbable, indifferent. cruel,
hard, egotistical, hardened, pitiless, implacable, inexorable.
impervious, indifferent. deaf. foreign, closed, inaccessible;
resistant.)
</bodyText>
<listItem confidence="0.827972833333333">
• II
1. Qu’on ne sent pas, qu’on ne per¸coit pas ou qui est a` peine
sensible, perceptible. imperceptible, l´eger. (Not being sensed, not
being perceived or being just barely sensible, perceptible.
imperceptible, slight.)
2. Graduel, progressif. (Gradual, progressive.)
</listItem>
<bodyText confidence="0.722486333333333">
System output for a request to generate the semantic space associated with the French
headword insensible.
Your query was: insensible. There are 71 synonyms and 93 cliques.
</bodyText>
<tableCaption confidence="0.924867">
Table 8
</tableCaption>
<bodyText confidence="0.943672083333333">
Synonym list for the headword insensible (French lexical database).
insensible: adamantin, anesth´esi´e, apathique, aride, assoupi, blas´e, calleux, calme,
cruel, de marbre, dess´ech´e, dur, d´etach´e, endormi, endurci, engourdi,
flegmatique, frigide, froid, f´eroce, glacial, glac´e, immobile, impassi-
ble, imperceptible, imperm´eable, imperturbable, impitoyable, impla-
cable, imp´en´etrable, inabordable, inaccessible, inanim´e, inapparent,
indiff´erent, indiscernable, indolent, indolore, inerte, inexorable, in-
flexible, inhumain, ininflammable, insaisissable, insignifiant, invisi-
ble, invuln´erable, l´eger, l´ethargique, mort, neutre, n´egligeable, obtus,
paralys´e, progressif, rebelle, rigide, r´efractaire, sans coeur, sans en-
trailles, sans coeur, sec, sourd, stoicien, stoique, suprasensible, s ´ev `ere,
timide, ´egoiste, ´etranger, ´etroit.
</bodyText>
<page confidence="0.994342">
171
</page>
<note confidence="0.59983">
Computational Linguistics Volume 29, Number 2
</note>
<tableCaption confidence="0.991199">
Table 9
</tableCaption>
<bodyText confidence="0.550893">
Clique list for the headword insensible (French lexical database).
</bodyText>
<equation confidence="0.986745185185185">
1 : adamantin, dur, insensible
2 : anesth´esi´e, insensible
3 : apathique, endormi, indolent, insensible
4 : apathique, endormi, inerte, insensible
5 : apathique, flegmatique, impassible, imperturbable, indiff´erent, insensible
6 : apathique, indiff´erent, indolent, insensible
7 : apathique, inerte, insensible, mort
8 : apathique, insensible, l´ethargique
9 : aride, dess´ech´e, froid, insensible, sec
10 : aride, froid, indiff´erent, insensible, sec
11 : aride, froid, insensible, sec, s´ev`ere
12 : assoupi, endormi, engourdi, insensible
13 : blas´e, flegmatique, froid, indiff´erent, insensible
14 : calleux, dur, endurci, insensible
15 : calme, flegmatique, froid, impassible, imperturbable, insensible
16 : calme, froid, inanim´e, insensible
17 : calme, immobile, impassible, insensible
18 : calme, immobile, inanim´e, insensible
19 : cruel, dur, f´eroce, impitoyable, implacable, inexorable, inhumain, insensible
20 : cruel, dur, impitoyable, implacable, inexorable, inflexible, inhumain, insensible
21 : cruel, dur, impitoyable, implacable, inexorable, inflexible, insensible, s´ev`ere
22 : cruel, dur, implacable, inflexible, inhumain, insensible, rigide
23 : cruel, dur, implacable, inflexible, insensible, rigide, s´ev`ere
24 : cruel, dur, indiff´erent, inhumain, insensible
25 : de marbre, glacial, impassible, insensible
26 : dess´ech´e, dur, froid, insensible, sec
27 : dur, endurci, impitoyable, implacable, inflexible, insensible
28 : dur, endurci, impitoyable, insensible, sans coeur
29 : dur, endurci, indiff´erent, insensible, sans coeur, sec
30 : dur, froid, glacial, impassible, insensible
31 : dur, froid, glacial, insensible, sec
32 : dur, froid, impassible, implacable, insensible
33 : dur, froid, impassible, indiff´erent, insensible
34 : dur, froid, impitoyable, implacable, insensible, s´ev`ere
35 : dur, froid, inaccessible, indiff´erent, insensible
36 : dur, froid, indiff´erent, insensible, sec
37 : dur, froid, insensible, sec, s´ev`ere
38 : dur, impassible, implacable, inflexible, insensible
39 : dur, impassible, indiff´erent, insensible, stoique
40 : dur, impitoyable, inhumain, insensible, sans coeur
41 : dur, indiff´erent, inhumain, insensible, sans coeur
42 : dur, inhumain, insensible, sans coeur
43 : dur, inhumain, insensible, sans entrailles
44 : dur, insensible, invuln´erable
45 : dur, insensible, rigide, sec, s´ev`ere
46 : dur, insensible, rigide, stoique, s ´ev `ere
47 : d´etach´e, flegmatique, imperturbable, indiff´erent, insensible
48 : d´etach´e, indiff´erent, insensible, ´etranger
49 : endormi, engourdi, indolent, insensible
50 : endormi, engourdi, inerte, insensible
51 : engourdi, froid, inerte, insensible
52 : engourdi, immobile, inerte, insensible, paralys´e
53 : engourdi, insensible, l´ethargique
54 : engourdi, insensible, rigide
</equation>
<page confidence="0.8703422">
55 : flegmatique, froid, impassible, imperturbable, indiff´erent, insensible
56 : frigide, froid, glac´e, insensible
57 : froid, glacial, glac´e, impassible, insensible
...
172
</page>
<note confidence="0.973795">
Ploux and Ji A Model for Matching Semantic Maps
</note>
<tableCaption confidence="0.990572">
Table 10
</tableCaption>
<table confidence="0.904739772727273">
Examples of cliques generated in the target language for the headword insensible.
...
3 apathetic, cold, dull, indifferent, languid
4 apathetic, cold, unfeeling
5 apathetic, cool, impassive, indifferent
6 apathetic, cool, indifferent, unconcerned
7 apathetic, dull, languid, sluggish
8 apathetic, impassive, indifferent, languid
9 apathetic, impassive, indifferent, phlegmatic
...
14 apathetic, phlegmatic, sluggish
15 arid, dried, parched
16 arid, dry, parched
17 asleep, numb
18 austere, bare
19 austere, bitter, harsh, severe
20 austere, cold
21 austere, grave, hard, harsh, severe
22 austere, hard, hard-hearted, harsh, stern
23 austere, hard, hard-hearted, heartless, stern
24 austere, hard, harsh, rigid, severe, stern, strict
...
28 bitter, cruel, fierce, ruthless, savage
29 bitter, cruel, harsh, ruthless
30 bitter, cruel, harsh, severe
31 callous, cold, dead, indifferent
32 callous, cold, senseless, unfeeling
33 callous, cruel, hard, hard-hearted, heartless
34 callous, cruel, hard-hearted, heartless, unfeeling
35 callous, cruel, heartless, inhuman
36 callous, hard, hardened
37 callous, hard-hearted, insensitive, unfeeling
38 callous, hardened, insensitive, unfeeling
39 callous, impassive, indifferent
40 callous, impassive, insensible, unfeeling
41 callous, insensible, insensitive, unfeeling
42 callous, insensible, senseless, unfeeling
43 calm, calmness, composure, cool, quiet
44 calm, composed, cool, impassive, imperturbable
45 calm, composed, cool, quiet
...
54 cold, dead, frigid, indifferent
55 cold, dry, dull, frigid, languid
56 cold, dull, frigid, indifferent, languid
</table>
<page confidence="0.865178333333333">
57 cold, freezing, frigid, frosty, icy
58 cold, frigid, frosty, frozen, icy
59 cold, frigid, icy, indifferent
60 cold, senseless, unconscious
61 cool, detached, indifferent, unconcerned
62 cool, emotionless, impassive, imperturbable
63 cool, impassive, indifferent, stoical
64 cramped, dry, stiff
173
</page>
<table confidence="0.925840632653061">
Computational Linguistics Volume 29, Number 2
65 cramped, stiff, tight
66 crisp, frosty
67 cruel, ferocious, fierce, ruthless, savage
68 cruel, grave, hard, harsh, severe
69 cruel, hard, hard-hearted, harsh, stern
...
77 cruel, heartless, inexorable, pitiless, relentless
78 cruel, heartless, inexorable, relentless, stern
79 cruel, heartless, inhuman, merciless, pitiless, ruthless
80 cruel, heartless, merciless, pitiless, relentless, ruthless, unfeeling
81 cruel, implacable, inexorable, pitiless, relentless
82 cruel, implacable, merciless, pitiless, relentless
83 cruel, inexorable, relentless, severe, stern
84 cruel, inhuman, merciless, pitiless, ruthless, savage
85 dead, extinct, inanimate, lifeless
86 dead, idle, inert
87 dead, inanimate, inert, lifeless
88 dead, indifferent, inert
89 dead, numb, paralytic
90 deaf, indifferent
91 difficult, hard, stiff
92 difficult, hard, tough
93 difficult, obscure
94 dozing, drowsy
95 drowsy, lethargic, sleepy
96 dry, severe, stiff
97 dull, dulled
...
98 dull, expressionless
99 dull, faint, languid
100 dull, inanimate, inert, lifeless
101 dull, indifferent, inert, languid
102 dull, indifferent, inert, neutral
103 dull, inert, languid, lethargic, sluggish
...
111 frivolous, idle, light, trivial
112 frivolous, indifferent, insignificant, trifling, unimportant
113 frivolous, insignificant, trifling, trivial, unimportant
114 frivolous, light, trifling, trivial
115 hard, hardened, tough
116 hard, heartless, relentless, unyielding
117 hard, inflexible, relentless, stern
118 hard, inflexible, relentless, unyielding
119 hard, inflexible, rigid, stern
120 hard, inflexible, rigid, stiff, stubborn, unyielding
121 hard, inflexible, rigid, tough, unyielding
122 hard, rigid, severe, tough
...
</table>
<footnote confidence="0.961977625">
128 immobile, inert, motionless
129 impalpable, imperceptible, intangible, invisible
130 impassive, indifferent, phlegmatic, stoical
131 impassive, indifferent, unmoved
132 impenetrable, inaccessible, unapproachable
133 impenetrable, incomprehensible, inscrutable, unfathomable
134 impenetrable, incomprehensible, obscure
135 impenetrable, unapproachable, unfathomable
</footnote>
<page confidence="0.977928">
174
</page>
<note confidence="0.717518">
Ploux and Ji A Model for Matching Semantic Maps
</note>
<table confidence="0.990523416666667">
136 imperceptible, indiscernible, insensible
137 imperceptible, indiscernible, invisible
138 implacable, inexorable, inflexible, relentless
...
146 inflexible, intractable, stubborn, unyielding
147 insensible, senseless, unconscious
148 insensitive, unmoved
149 insignificant, slight, trifling, trivial, unimportant
150 lethargic, phlegmatic, sluggish
151 lethargic, sleepy, sluggish
152 light, slight, trifling, trivial
...
</table>
<tableCaption confidence="0.988683">
Table 11
</tableCaption>
<figure confidence="0.739856774193548">
Clique list for the headword good (English standard lexical database).
...
6 : able, adequate, capable, competent, effective, good
7 : able, adroit, clever, dexterous, expert, good, skilful
8 : able, capable, clever, expert, good, skilful
9 : able, capable, competent, effective, efficient, good
10 : absolutely delicious, delectable, delicious, good, gorgeous, lovely, scrumptious,
yummy
11 : adept, expert, good, practiced, proficient, skilful, skilled, skillful
12 : adequate, competent, good, satisfactory, sufficient
13 : adequate, full, good
14 : admirable, commendable, deserving, good, meritorious, worthy
15 : admirable, deserving, estimable, good, meritorious, worthy
...
27 : advantageous, beneficial, good, helpful, salutary
28 : advantageous, beneficial, good, propitious
29 : agreeable, enjoyable, good, pleasant
30 : agreeable, good, good-natured
31 : agreeable, good, lovely, nice, pleasant, sweet
32 : appetising, appetizing, delicious, good, lovely, nice, savory, savoury, tasty
33 : attentive, good, obliging
34 : attentive, good, sweet, well-behaved
35 : auspicious, benign, good, propitious
36 : auspicious, good, promising, propitious
37 : beneficent, benevolent, benign, good, gracious, kind
38 : beneficent, benevolent, generous, good, kind
39 : beneficent, good, helpful, kind
40 : beneficial, benign, good, propitious
41 : beneficial, friendly, good, helpful
42 : beneficial, friendly, good, propitious
...
</figure>
<page confidence="0.810487666666667">
48 : benevolent, benign, good, gracious, kind, kindly
49 : benevolent, benign, good, gracious, propitious
50 : benevolent, friendly, good, gracious, kind, kindly
</page>
<figure confidence="0.3474285">
...
175
Computational Linguistics Volume 29, Number 2
56 : commendable, creditable, deserving, good, meritorious, worthy
57 : commendable, creditable, good, honorable, honourable, worthy
58 : commendable, creditable, good, honourable, meritorious, worthy
59 : commendable, deserving, exemplary, good
60 : competent, expert, good, skilful, skilled, skillful, versed
61 : considerable, fair, good, respectable
62 : considerable, fair, good, serious, substantial
63 : considerable, fair, good, sound, substantial
...
71 : creditable, estimable, good, honorable, honourable, worthy
72 : creditable, estimable, good, honourable, meritorious, worthy
73 : dear, good, near
74 : dear, good, precious, sweet
75 : dear, good, precious, valuable
76 : decorous, good, respectable
77 : delectable, delicious, enjoyable, good, pleasant
78 : delectable, delicious, excellent, exquisite, good, lovely, scrumptious
79 : delectable, delicious, good, lovely, pleasant
80 : delectable, delicious, good, lovely, savoury, scrumptious, tasty
81 : delectable, delicious, good, lovely, scrumptious, tasty, yummy
82 : delicious, good, lovely, nice, pleasant
83 : dependable, good, honest, reliable, true, trustworthy
84 : dependable, good, reliable, safe, secure
85 : dependable, good, reliable, safe, trustworthy
86 : dependable, good, reliable, secure, solid
...
92 : effective, efficient, good, serviceable
93 : effective, good, in effect, in force
94 : estimable, good, honorable, honourable, respectable, worthy
95 : excellence, good, goodness, merit, virtue, worth
96 : excellent, exemplary, good
97 : excellent, exquisite, fine, good, lovely
98 : excellent, good, noble, worthy
99 : exemplary, good, virtuous
100 : expert, good, practiced, skilful, skilled, skillful, versed, well-versed
101 : exquisite, fine, good, precious
102 : fair, good, honest, honourable, just, right, upright
103 : fair, good, honest, honourable, respectable
104 : fair, good, honest, honourable, righteous, upright
105 : fair, good, honest, serious
...
110 : fine, good, well
111 : friendly, gentle, good, kind, kindly, nice, sweet
112 : friendly, good, gracious, kind, kindly, nice, sweet
113 : friendly, good, helpful, kind
114 : friendly, good, kind, kindly, nice, pleasant, sweet
115 : friendly, good, propitious, well-disposed
116 : full, good, large
...
121 : gentle, good, noble
122 : genuine, good, honest, right, true
</figure>
<page confidence="0.94767375">
123 : genuine, good, real, solid
124 : genuine, good, real, true
125 : genuine, good, right, sound, true
126 : genuine, good, right, sound, valid
</page>
<figure confidence="0.810608846153846">
...
176
Ploux and Ji A Model for Matching Semantic Maps
134 : good, helpful, kind, obliging
135 : good, holy, righteous, virtuous
136 : good, honest, honorable, honourable, moral, righteous, upright, virtuous
137 : good, honest, honorable, honourable, respectable
138 : good, honest, honourable, just, right, true, upright
139 : good, honest, honourable, just, upright, virtuous
140 : good, honest, honourable, moral, right, upright
141 : good, honorable, honourable, virtuous, worthy
142 : good, honourable, meritorious, virtuous, worthy
...
</figure>
<sectionHeader confidence="0.532549" genericHeader="conclusions">
Acknowledgments We gratefully
</sectionHeader>
<bodyText confidence="0.652830666666667">
acknowledge support of the Agence
Universitaire de la Francophonie and the
FRANCIL network.
</bodyText>
<sectionHeader confidence="0.96912" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999799546666667">
Abplanalp, Laure. 1998. La pertinence et la
traduction. Travaux du centre de traduction
litt ´eraire, Lausanne, Switzerland.
Anderson, John R. 1983. The architecture of
cognition. Harvard University Press,
Cambridge.
Asher, Nicolas and Alex Lascarides. 1995.
Lexical disambiguation in a discourse
context. Journal of Semantics, 12(1):9–108.
Benz ´ecri, Jean-Paul. 1992. Correspondence
Analysis Handbook. Dekker, P, New York.
Chuquet, H ´el`ene and Michel Paillard. 1989.
Approches linguistiques des probl`emes de
traduction. Ophrys, Paris.
Collins, Allan M. and Elizabeth F. Loftus.
1975. A spreading-activation theory of
semantic processing. Psychological Review
82:407–428.
Edelman, Shimon. 1998. Representation is
representation of similarities. Behavioral
and Brain Sciences, 21(4):449–498.
Edmonds, Philip and Graeme Hirst. 2002.
Near-synonymy and lexical choice.
Computational Linguistics, 28(2):104–144.
Fellbaum, Christiane. 1998. WordNet: an
Electronic Lexical Database. MIT Press,
Cambridge.
Foltz, Peter W., Walter Kinsch, and Thomas
K. Landauer. 1998. The measurement of
textual coherence with latent semantic
analysis. Discourse Processes, 25:285–307.
Ide, Nancy and Jean Veronis. 1998. Word
sense disambiguation: The state of the art.
Computational Linguistics, 24(1):1–40.
Ikeda, Satoko. 1998. Manual response set in
a stroop-like task involving categorization
of English and Japanese words indicates
a common semantic representation.
Perceptual and Motor Skills, 87(2):467–474.
Illes, Judy and Wendy S. Francis. 1999.
Convergent cortical representation of
semantic processing in bilinguals. Brain
and Language, 70(3):347–363.
Kinsch, Walter. 2001. Predication. Cognitive
Science, 25:173–202.
Masson, Michael. 1995. A distributed
memory model of semantic priming.
Journal of Experimental Psychology: Learning,
Memory, and Cognition, 21(1):3–23.
Maupassant, Guy (de). 1881. Contes et
nouvelles. Gallimard, Biblioth `eque de la
Pl ´eiade, Paris.
Maupassant, Guy (de). 2002. Original Short
Stories, vol. 2, trans. Albert M. C.
McMaster and L. Quesada Project
Gutenberg Release. http://www2.cs.
cmu.edu/spok/metabook/maupassant.html.
Miller, George A. 1990. WordNet: An
on-line lexical database. International
Journal of Lexicography, 3(4):235–312.
Ploux, Sabine. 1997. Mod ´elisation et
traitement informatique de la synonymie.
Linguisticae Investigationes, 21(1):1–28.
Ploux, Sabine and Bernard Victorri. 1998.
Construction d’espaces s ´emantiques a`
l’aide de dictionnaires informatis ´es des
synonymes. Traitement automatique des
langues, 39(1):161–182.
Pustejovsky, James. 1995. Generative Lexicon.
MIT Press, Cambridge.
Reboul, Anne. 2000. Words, concepts,
mental representations and other
biological categories. In B. Peeters, editor,
The Lexicon-Encyclopedia Interface. Elsevier,
Amsterdam.
</reference>
<page confidence="0.94739">
177
</page>
<note confidence="0.349433">
Computational Linguistics Volume 29, Number 2
</note>
<reference confidence="0.998987611111111">
Rouibah, Aicha, Sabine Ploux, and
Hyungsuk Ji. 2001. Un mod `ele spatial des
repr ´esentations lexicales impliqu ´ees dans
la reconnaissance des mots ´ecrits. In
H ´el`ene Paugam-Moisy, Vincent Nyckees,
and Josiane Caron-Pargue (editors), La
cognition entre individu et soci´et´e.
Herm`es-Science, Paris.
Sch¨utze, Hinrich. 1998. Automatic sense
discrimination. Computational Linguistics,
24(1):97–124.
Vinay, Jean-Paul and Jean Darbelnet. 1996.
Stylistique compar´ee du fran¸cais et de
l’anglais. Didier, Paris.
Vossen, Piek, editor. 1998. EuroWordNet: A
Multilingual Database with Lexical Semantic
Networks. Kluwer Academic, Dordrecht,
the Netherlands.
</reference>
<page confidence="0.997162">
178
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.996652">A Model for Matching Semantic Maps Languages</title>
<author confidence="0.473341">Hyungsuk</author>
<affiliation confidence="0.478069">Institut des Sciences Cognitives Institut des Sciences Cognitives</affiliation>
<abstract confidence="0.981904121212121">This article describes a spatial modelfor matching semantic values between two languages, French and English. Based on semantic similarity links, the model constructs a map that represents a word in the source language. Then the algorithm projects the map values onto a space in the target language. The new space abides by the semantic similarity links specific to the second language. Then the two maps are projected onto the same plane in order to detect overlapping values. For instructional purposes, the different steps are presented here using a few examples. The entire set of results is available at the following address: http://dico.isc.cnrs.fr. 1. Goals This article presents a spatial model that projects the semantic space of a source language word onto a semantic space in the chosen target language. Although the study presented in this article can be described from various angles, we place it within the framework of artifactual simulations of the translation process, and more specifically, access to the target language’s lexicon. The model is described as a construction process designed to reproduce cognitive functions and their extensions. Future research will include the study of the psycholinguistic validity of such a spatial representation. Now let us briefly describe the scientific basis of the study. • Three major areas are generally distinguished in the study of the translation process (see Vinay and Darbelnet [1996]), the lexicon (or the study of notions), sentence generation (putting words together), and the message (which brings communicative factors into play). The first area involves choosing the right word, which is usually left up to the intuition and expertise of the translator. Our model deals with accessing the lexicon of the target language starting from a notion in the source language. The utility of this research lies in the fact that different languages break down reality in different ways. • Although the translation process has been mastered by a number of experts, it is usually still dependent upon the utilization of tools like dictionaries. The model proposed here relies on semantic maps and offers an alternative method based on the concepts of lexical access and lexical neighborhood. • The work by Anderson (1983) and Collins and Loftus (1975) on the organization of the lexicon is based on priming and the automatic 5015 CNRS-Universit´e Lyon I, 67 bd Pinel, F-69 675 Bron Cedex.</abstract>
<note confidence="0.685334">Association for Computational Linguistics Computational Linguistics Volume 29, Number 2</note>
<abstract confidence="0.977306488505747">spreading of activation to the prime’s neighboring concepts. As an alternative to these local semantic networks, Masson (1995) proposed a connectionist model that takes into account the subjects’ reaction time during priming experiments (the correspondence is based on the assumption that semantic or phonologic proximity and ease of access are correlated). Rouibah, Ploux, and Ji (2001) showed that experimental data on interactions between phonology and semantics could be simulated by distances on lexical maps. One advantage of this proposal is that experimental and artifactual findings converge; another is its ability to describe a real lexicon. Although the relevance of our model to the representation of the mental lexicon will not be discussed in this article (attempts to gain insight into this correlation are currently underway in other studies), this point is not unrelated to the suitability of our approach to modeling translation as a cognitive function. 2. Description of the Model No two lexicons are related by a one-to-one correspondence (Abplanalp 1998). In other words, the way words are used to refer to extralinguistic reality varies across languages. Some examples of this are cross-language differences in color naming and, borrowing Chuquet and Paillard’s (1989) English-French examples, differences like: room: chambre, bureau (or in an abstract domain) • mind, spirit, wit Certain authors (Abplanalp 1998) insist how impossible it is to translate at the word level and propose recourse to the conceptual level as a theoretical alternative. Concepts are thought to depend on human cognitive abilities that are general and shared by all. Although the correspondence between words and concepts remains a controversial topic of study (Reboul 2000), the concept/word opposition is nevertheless relevant to any model of translation, even an artifactual one like ours. As we shall see, even when heeding the specific organization and breakdown of each individual language, the matching operation does not take place at the word level but at the substrate level (defined below), where the set of meanings of each word “cuts out” a form. First, we will present the model we devised to describe the organization of languages. Then we will explain the source-to-target spreading method used. 2.1 A Model Based on Semantic Similarity The model was initially developed on the basis of a semantic similarity: synonymy. Note, however, that the data and the model are independent, so this same framework can be used to organize other types of similarity (contextual, phonological [Rouibah, Ploux, and Ji 2001], etc.). Other authors also organize the lexicon or other kinds of knowledge on the basis of similarity. For example, in Edelman’s (1998) spatial model of internal representations of the world’s objects, spatial proximity reflects object similarity. WordNet (Fellbaum 1998) and EuroWordNet (Vossen 1998) organize the lexicon conceptually as a network of terms, each of which is associated with a partition into 156 Ploux and Ji A Model for Matching Semantic Maps (a a small group of synonyms that label a concept). Our model differs from Edelman’s in that it deals with lexical semantics, not perceived objects. It also differs from Miller’s (1990) approach, in three respects: • the grain of the semantic units • the lexical structure generation mode • the resulting geometry and organization use separate units to represent words or concepts (symbols, points in a space, nodes on a graph, etc.). Relationships between units are expressed as proximity links (in spatial models) or as arcs between nodes (in networks). Our model is spatial, but it differs from local models in that each term is represented by a region in the space, part of which it shares with other terms. This region is constructed automatically according to lexical similarity links (such as those given by a synonym dictionary). It is not the result of supervised learning, nor is it a manual, ontological description of how the lexicon is organized. The next section will break the semantic-space construction process into steps in presenting the initial data, the granular approach, and the resulting organization. 2.2 Method Initial Data. databases were used: two synonym databases (one containing French terms and one containing English terms) and a translation database (French- English, English-French) that maps each term to similar words in the other language. The links between an entry and the terms that follow it were not chosen “by hand.” The were taken mainly from published dictionaries and It is updated and supplemented regularly by the addition of new links between words (synonymy or translation links). The method used to generate the French synonym database (described in detail in Ploux (1997) was applied again to generate the English and translation databases. The first step required creating an intermediate database containing the set of all links attested in available work in lexicography. In this preliminary database, a term was deemed similar to another term if at least one lexicographer had established the link. The final database was obtained through symmetrization of the links produced in the first step. While maintaining the shifts in meaning that occur when there is nontransitivity and that, as we shall see, are essential for developing the we created new links to symmetrize any initially one-directional Table 1 gives a typical example of the structure of the initial data. Table 2 gives a global evaluation of the number of entries and links in the lexical databases. Note that we are attempting here to define the term We rely on lexicographic publications, which as Edmonds and Hirst (2002) remarked, “have always treated synonymy 1 Masson’s (1995) model assigns each concept a basin of attraction in a multidimensional space of activation. This framework authorizes a certain form of internal variability for the set of patterns corresponding to a concept. Nevertheless the basins are disjoint and do not overlap as do the nodes in local semantic networks. Furthermore, this model, built essentially for the purposes of validating hypotheses and comparing psycholinguistic results, is applicable only to a highly limited vocabulary and is therefore a poor representative of the natural lexicon. 2 For the French database, we used files compiled by the National Institute for the French Language Institut National de la Langue from seven different 19thand 20th-century synonym dictionaries; for the English and translation databases, we used files obtained from the French company MEMODATA. 3 Note that symmetrization does not make the semantic spaces of the two terms equivalent. 157 Computational Linguistics Volume 29, Number 2 Table 1 Format of data files. . insensible: (extracted from the similar English word database) insensible: (extracted from the similar French word database) insensible: (extracted from the French-English translation database) apathetic, benumbed, callous, comatose, impassive, impercep-tible, impercipient, indiscernible, insensitive, pachydermatous, senseless, thick-skinned, unaffected, unaware, unconscious, un-detectable, unfeeling, unsympathetic adamantin, anesth´esi´e, apathique, aride, assoupi, blas´e, calleux, calme, cruel, de marbre, dess´ech´e, dur, d´etach´e, endormi, endurci, flegmatique, imperceptible, insensitive, numb, unfeeling Table 2 Number of entries and links in the lexical databases. Number of entries Mean number of Mean number of terms synonyms per entry proposed by the translation database French 54,690 7.5 2.3 English 148,247 6.8 1.9 However, having more flexible semantic links does not detract from the accuracy of the model. No other operations are carried out on the data sets before application of the model. Semantic Units. represent variations in a word’s meaning, each word is associated with a spatial form (or space) (Ploux 1997; Ploux amd Victorri 1998). The points in the space are finer units of meaning than the word itself. In our computational the points are represented by cliques. A a set of terms related each other by The conjunction of all terms in the same clique crystallizes and constrains the meaning given to the word. These cliques thus constitute good candidates for generating the substrate upon which the form will take shape. The presentation of the results and the features of the model will be illustrated using from the headword English and from the headword French. The Appendix provides the full results, as well as the definition of the word from a French dictionary. These examples are illustrative of the main characteristics of the entire data set. 4 Moreover, for the two languages under study here, there are notable differences in how lexicographers understand and use the concept of synonymy. Synonymy relations in French dictionaries, for example, are not always symmetrical and are rarely transitive. What is more, the links have a broader scope. For the words and even are given as synonyms of To make the databases homogeneous during the matching operation, a new version of the English database was supplemented with certain hypernym links often given as synonyms in French dictionaries. The software offers the user the opportunity to see the output obtained using the two of the English database, displayed under the headings search 5 By definition, this is a maximal, connected component of the synonym graph. Words are placed at the nodes of the graph, and arcs between two nodes represent a synonymy link. 158 Ploux and Ji A Model for Matching Semantic Maps The synonym list contains a heterogeneous set of scrambled terms: For the French headword some of the terms represent a moral sans-coeur, others a physical value engourdi, still others a perceptual value inapparent The headword many similar terms. As a first approximation, only the most representative are given here. Some of the represent a generic value sound, others refer to a or have an affect-related value while others represent a quality of taste The clique list contains the cliques generated from this set of terms. Cliques represent precise units of • Here are some examples of cliques representing the moral value of the headword 20: cruel, dur, impitoyable, implacable, inexorable, inflexible, inhumain, insensible 21: cruel, dur, impitoyable, implacable, inexorable, inflexible, insensible, s´ev`ere 22: cruel, dur, implacable, inflexible, inhumain, insensible, rigide 23: cruel, dur, implacable, inflexible, insensible, rigide, s´ev`ere Some examples of cliques representing the physical value: 2: anesth´esi´e, insensible 50: endormi, engourdi, inerte, insensible 51: engourdi, froid, inerte, insensible 52: engourdi, immobile, inerte, insensible, paralys´e And some examples of cliques representing the perceptual value: 69: imperceptible, inapparent, insensible, invisible 70: imperceptible, indiscernable, insaisissable, insensible, invisible 71: imperceptible, indiscernable, insensible, l´eger • Here are some examples of cliques representing the more prominent of the English headword 84: dependable, good, reliable, safe, secure 87: dependable, good, reliable, solid, sound 102: fair, good, honest, honourable, just, right, upright Some examples of cliques representing a more specific meaning of aptitude or ability: 6: able, adequate, capable, competent, effective, good 7: able, adroit, clever, dexterous, expert, good, skilful 8: able, capable, clever, expert, good, skilful 6 The cliques are numbered here in the order in which the results are presented on the Web site (alphabetical order).</abstract>
<note confidence="0.7445375">159 Computational Linguistics Volume 29, Number 2 And some examples of cliques with affect-related values: 111: friendly, gentle, good, kind, kindly, nice, sweet 112: friendly, good, gracious, kind, kindly, nice, sweet 113: friendly, good, helpful, kind</note>
<abstract confidence="0.99396834893617">Note that a given term may belong to several cliques (this characteristic is due to the nontransitivity of the relation). It appears in each clique with a precise meaning that is constrained by the presence of its neighbors. • For example, the following cliques have terms in common; the first has a stronger moral value than the second: 15: calme, flegmatique, froid, impassible, imperturbable, insensible 18: calme, immobile, inanim´e, insensible • In the same manner, there are shared terms in the next two cliques of the first related to taste, the second to personal qualities: 80: delectable, delicious, good, lovely, savoury, scrumptious, tasty 82: delicious, good, lovely, nice, pleasant This last point brings us to the study of semantic variations. The following clique path, in which each clique shares at least one term with the next, moves in a relatively continuous way from one value to another. • Transition from a moral value to a physical value: 21: cruel, dur, impitoyable, implacable, inexorable, inflexible, insensible, s´ev`ere 34: dur, froid, impitoyable, implacable, insensible, s´ev`ere 35: dur, froid, inaccessible, indiff´erent, insensible 39: dur, impassible, indiff´erent, insensible, stoique 15: calme, flegmatique, froid, impassible, imperturbable, insensible 16: calme, froid, inanim´e, insensible 63: froid, inanim´e, inerte, insensible 83: inanim´e, inerte, insensible, mort The continuity between the moral and physical values has its in their usage. For example, one can use the term French to qualify the disposition of a person who exhibits little moral reactivity, as in: Il allait comme dans un songe, l’esprit engourdi, paralys´e, sans chagrin vibrant, saisi par une sorte d’engourdissement moral qui l’empˆechait de souffrir, ´eprouvant mˆeme un all´egement qu’augmentaient les exhalaisons ´epandues dans la (Maupassant 1881, page 350) Moreover, as we shall see later, this type of continuous link between two values, which acts as a metaphor here, is expressed more explicitly in the English example below. Although the term not specifically translated, to help the reader understand this fine shade meaning, here is a translation of the above passage (Maupassant 2002): walked as if he were in a dream; his thoughts were paralyzed, although he felt no great grief, for he was in a state of mental torpor that prevented him from suffering, and he even felt a sense of relief which was increased by the mildness of the night. 160 Ploux and Ji A Model for Matching Semantic Maps Table 3 Evaluation of clique granularity. Entry Number of cliques containing entry of Number of Synsets in WordNet found in lished dictionaries d´efendre 44 9–13 — distraction 39 3–10 — fou 319 10–23 — jouer 95 15–46 — maison 123 9–42 — vert 50 9 — blue 54 22–34 26 house 82 11–24 11 good 193 24–50 30 look 104 18–73 13 mind 87 41–68 13 play 240 77–84 47 • Transition from a taste-related value to an affective value: 80: delectable, delicious, good, lovely, savoury, scrumptious, tasty 78: delectable, delicious, excellent, exquisite, good, lovely, scrumptious 77: delectable, delicious, enjoyable, good, pleasant 79: delectable, delicious, good, lovely, pleasant 82: delicious, good, lovely, nice, pleasant 114: friendly, good, kind, kindly, nice, pleasant, sweet 111: friendly, gentle, good, kind, kindly, nice, sweet contrast, for the French headword there is greater discontinuity between the perceptual value and the others. At the present stage of our project, clique lists are in alphabetical order, and the underlying semantic topology has not yet been built. The geometric model we are now going to present achieves this step. Table 3 contains an evaluation of the granularity generated by the cliques. Output Geometry and Organization. construct the semantic space, a concorrespondence factorial 1992) was conducted between cliques and the synonyms. For each entry, the initial matrix for the number of cliques) and (where for the of terms). It is defined by the formula if clique term and 0 not. The results showed that the using this method furnish a coherent representation of semantic variations. Table 4 presents the configurations 8 Correspondence analysis is a factor analysis method that uses categorical variables (that is, noncontinuous or discretized ones). 9 n E = two cliques, the number of synonymous terms, number of terms in frequency of term sum of the frequencies of all terms (or the total number of terms in all cliques). 161 Computational Linguistics Volume 29, Number 2 Table 4 of Euclidean distance and on the principal plane for the above cliques. Euclidian distance Figure 1 semantic space for the French headword the principal plane for the Euclidean distance and the reduced to the proportion. The headword many cliques, including • c12: express, fast, quick, rapid, swift • c17: fast, fastened, fixed, secure • c23: fast, firm, lasting, stable, tight values obtained using the are more suited to semantic categorization than those obtained using Euclidean distance; cliques representing the same class are closer together (even if they do not share a larger number of terms) than ones representing different meanings. dimension of the geometric space is equal to the smaller of the two numbers, To show the results visually, the projections onto the principal axes are presented in Figures 1 and 2. (The horizontal axis in the figures is the best representative of the form delineated by the cluster of points such that the distances between the points are maintained to the optimal degree; the vertical axis, perpendicular to the first, is the second best representative, and so on.) Cliques are represented by points, and each 162 Ploux and Ji A Model for Matching Semantic Maps Figure 2 semantic space for the English headword by the region in the space delineated by the set of cliques that contains Using the examples again, let us review the main characteristics of the resulting organization. The same type of organization is found in all cases. Distinguishing Semantic Values. model plots the different values on the map. Distinct notions are clearly separate, and gradual variations are maintained. In the (Figure 1), we can see two clusters as a first one smaller cluster labeled by the terms indiscernable, etc., and representing the perceptual value of the word, and one larger cluster containing the moral and physical values. In the center of the second cluster, we find the terms inhumain, sans-coeur, cruel, which are prototypes of the word’s moral value. Two branches come out of this center, one that qualifies a specific value rebelle, imp´en´etrable, and one that to the physical In the (Figure 2), the cliques and terms are plotted on the map in accordance with the proximities of the values and their links. On the principal plane, the cluster of points extends in two directions: the first axis represents the capability value, and the second the affective The affective value gradually turns into a taste-related value These two main directions are interconnected by the generic value true, located near the origin. 10 An appropriate algorithm generates the envelope (i.e., the set of cliques that contains the term) for a given term. 11 In all figures in this article, the principal classes are outlined. (A publication about the principles of this automatic classification model is now in preparation; only the results are given here.) 163 Computational Linguistics Volume 29, Number 2 Table 5 Some examples of spatial interconnections between semantic values. Entry Value at the origin (labeled by Examples of off-centered values a prototype) (labeled by prototypes) prot´eger 1. excuser 2. interdire, . domicile 1. commerce 2. lign´ee, . sans-coeur 1. imperceptible, 2. engourdi, . abode 1. family, 2. interior, right 1. able, 2. delicious, . Spatially Interconnecting the Values. 5 shows the hierarchy of the spatial organization. The middle column contains the generic values (when they exist) that interconnect the different meanings of the word. Highly specific values are far from the origin. This organization follows directly from the calculation of the profile matrix, which assigns more weight to infrequent terms and to cliques containing few elements. 2.3 Matching As stated above, the breakdown and overlapping of the lexicon varies from one language to the next. However, several studies (Illes and Francis 1999; Ikeda 1998) have found evidence that the two languages of a bilingual person access a common semantic system. To handle the problem of lexical differences in our translation model, connections link semantic units rather than words. Because they are finer-grained than words, semantic units are assumed to be less sensitive to the way a given language “cuts up” the world, and as such, they are better candidates for achieving a closer fit between the two languages. For a given set of cliques in the source language, the model constructs the set of cliques to be used for the translation. The two spaces (one associated with each set of cliques) are then projected onto a map that maintains matches. The example of a good representative of the various patterns that can appear. It has two very different, nearly homonymic semantic values, as well as some other values whose meanings overlap considerably. For this reason, we present the results for the matching operation using this example. The four steps in this construction process are described below. 1. Constructing the source semantic In order to build a semantic space in the target language associated with a term in the source language, the system starts by generating the set of all cliques containing the requested word. This step is identical to the one described in Section 2.2.2. 2. Searching for relevant target language units for For all initial terms similar to the input word, the translation database furnishes the corresponding terms in the target language. Some of these terms are relevant to the initial generic meaning; others are clearly far removed that meaning. For example, the synonyms the be translated respectively as for for neither of which is useful in generating this headword’s target semantic space. To find the relevant senses, the model compares the source language cliques to the cliques generated from the set of terms proposed by the translation database. Target clique relevance 164 Ploux and Ji A Model for Matching Semantic Maps calculated as follows: Let a clique in the source language of the terms and let clique the target language. The model evaluates the relevance of the translation on the rank of matrix composed of zeroes and ones, using the formula = if translates and = otherwise. The rank defines a spreading parameter (in the model, a rank of zero means that the two cliques are unrelated and the target clique represents an out-of-range meaning in the translation operation; a rank of three or more represents a highly cohesive semantic link). If this last constraint is imposed on all cliques, the model will output a relatively small number of terms belonging to the target’s semantic 3. Constructing the source-point/target-point The factorial analysis algorithm (presented in Section 2.2.3) is followed to determine the correspondences between the source cliques and the target cliques that were retained in step 2, because they are relevant to at least one clique in the source language. The correspondences are determined by taking the product of the following matrices: ∗ cs is the source-clique/source-term matrix defined as in processing (see Section 2), is the matrix that defines the between the source terms and the target terms = if only if term term the initial database), and the transposed target-clique/target-term matrix. a subset of the French cliques of the closest three English cliques are given below for each French clique, along with a table of the corresponding distances calculated on the principal plane (Table 6). The maps reproduced in Figures 3–5 summarize the resulting distances for headword • cruel, dur, f´eroce, impitoyable, implacable, inexorable, inhumain, insensible cruel, ferocious, fierce, ruthless, savage cruel, inhuman, merciless, pitiless, ruthless, savage bitter, cruel, fierce, ruthless, savage • dur, indiff´erent, inhumain, insensible, sans-coeur callous, hard, hardened callous, cruel, hard, hard-hearted, heartless difficult, hard, tough • imperm´eable, insensible, rebelle, r´efractaire, sourd insensitive, unmoved 12 Our software proposes two types of lexical access. The first is more restrictive and sets the rank at three or more; the second supplies a broader vocabulary and sets the rank at two or more. 165 Computational Linguistics Volume 29, Number 2 Table 6 Distances between French and English cliques on the principal plane. (For all cliques, the ranged between and</abstract>
<phone confidence="0.57719925">2.6483 2.1008 0.3486 0.1542 3.2331 3.6239 1.3379 0.2567 0.3009 2.0498 2.3846 3.1128 3.5984 1.0726 0.5407 0.0543 1.7672 2.1031 3.0130 3.5002 0.7897 0.5625 0.0439 1.7467 2.0831 2.9967 3.4839 0.7670 1.3223 0.7680 1.0502 1.3933 2.6981 3.1721 0.0907 0.1151 0.4404 2.1912 2.5256 3.1666 3.6503 1.2135 0.2228 0.3323 2.0854 2.4206 3.1108 3.5959 1.1056 2.3812 1.8385 0.0813 0.2630 3.2189 3.6326 1.0886 2.5708 2.0272 0.2656 0.0944 3.2805 3.6799 1.2730 0.5461 0.0633 1.7609 2.0965 3.0209 3.5081 0.7856 2.5336 1.9861 0.2365 0.1846 3.1868 3.5866 1.2240 2.3637 1.8176 0.0676 0.3000 3.1508 3.5641 1.0598</phone>
<address confidence="0.6721132">2.2895 1.7453 0.0164 0.3593 3.1568 3.5761 0.9926 3.0294 2.7339 2.8600 3.0620 0.3066 0.7473 2.5137 3.6318 3.3733 3.5037 3.6875 0.4153 0.0788 3.1821 2.9849 2.6955 2.8534 3.0606 0.3108 0.7718 2.4883 1.3400 0.7892 0.9756 1.3163 2.8715 3.3439 0.0867</address>
<phone confidence="0.661137">3.1895 2.9208 3.1005 3.3031 0.0685 0.5290 2.7350 1.3696 0.8147 0.9837 1.3268 2.7454 3.2172 0.0551 3.6058 3.3440 3.4678 3.6514 0.3879 0.1143 3.1488 3.6335 3.3752 3.5061 3.6899 0.4171 0.0765 3.1843</phone>
<email confidence="0.526644">impassive,indifferent,phlegmatic,stoical</email>
<abstract confidence="0.987642757142857">callous, impassive, insensible, unfeeling • engourdi, froid, inerte, insensible dull, inanimate, inert, lifeless dull, expressionless dead, inanimate, inert, lifeless • engourdi, immobile, inerte, insensible, paralys´e dead, numb, paralytic asleep, numb dull, dulled • imperceptible, insensible, invisible imperceptible, indiscernible, invisible frivolous, indifferent, insignificant, trifling, unimportant impalpable, imperceptible, intangible, invisible • imperceptible, insensible, insignifiant, l´eger light, slight, trifling, trivial frivolous, light, trifling, trivial insignificant, slight, trifling, trivial, unimportant 4. Defining the lexical As above, for each language, a term is represented by the clique region that contains it. The next section will use examples to illustrate the results obtained. The entire set of results is available at http://dico.isc.cnrs.fr. 166 Ploux and Ji A Model for Matching Semantic Maps Figure 3 space matching for the English headword 3. Results The advantages of the model presented are (1) access to an extended lexicon and a broad semantic field and (2) coherence of the matching between the semantic values in language. The results for be used again in this section to illustrate the second advantage. 3.1 Access to an Extended Semantic Field and Lexicon The model fulfills two functions: It searches for a suitable lexicon and organizes the terms found. For each entry, the initial data provides a short list of terms representing certain prototypes of the word’s translation. Table 1 lists the four English terms proas translations for the French word It can happen that certain semantic values in the source language are not represented in the translation database. For exno corresponding French word in our database of English word translations. However, the model builds the appropriate values in French (Figure 3). The model builds a much larger vocabulary that includes the initial terms from the translation database and some semantic neighbors. Table 7 presents an overall evaluation of the results. Table 7 Assessment of lexical access spreading to the target language. Mean number of terms supplied by the translation database from a sample of 60 terms Mean number of terms supplied by the semantic maps of the same sample 14.1 92.9 167 Computational Linguistics Volume 29, Number 2 Figure 4 separation of the French and English spaces for the French headword 3.2 Coherence of the Semantic Matching The final step in the model consists of establishing a correspondence between the semantic values of the cliques and the terms in the two languages. By application of the above algorithm, the cliques and terms of the two languages are plotted on the same map. This map thus provides a summary of the semantic proximities in each language. In order to demonstrate the coherence of the semantic-value matching after projection onto the target language, the clusters obtained from the French and cliques for the term superimposed on one another. Figures 4 and 5 present the division of the output into two and four clusters. (The French clusters in these figures are marked by a darker line and set in a darker typeface than the English As in the two-cluster semantic space for the French word Figure 4 separates the perceptual value from the other values. The three-cluster separation then differentiates the physical-moral value from the moral value. Figure 5 shows the division within the physical-moral value between is more specifically physical and what pertains to emotional insensitivity r´efractaire, or to the inability to discern that sensitivity Note that although all values initially present in the monolingual space are represented, a reorganization process still takes place during pairing with the target lan- In French, the terms inacessible, were separated from the terms engourdi, by the group made up of the terms sans-coeur, but now they are located close to the center. This layout probably results from (1) the effect the greater number of terms like numb, sluggish, chilly, which, in English, unlike in French, encompass emotional and physical insensitivity and therefore bring these two values closer together on the map, and (2) the prototypical, cennature of this value in English, as expressed by the terms insensible, 168 Ploux and Ji A Model for Matching Semantic Maps Figure 5 separation of the French and English spaces for the French headword 4. Discussion We have presented a model for matching a semantic space in a source language and a semantic space in a target language. This model, currently built from lexical similarity relations (synonymy or near-synonymy and translations), uses several representation levels: cliques, which represent very precise units of meaning; terms, which are represented geometrically by a region in the space containing a set of cliques; and clusters, which are generated from the results of a spatialization process that singles out a term’s main semantic values. (Again, this last representation level is merely mentioned in the present article; the method used to generate it and the rationale for its use in semantic classification will be described in detail in a forthcoming publication.) The matching between the French and English spaces is achieved by mapping the cliques of the two languages to each other. The model software allows a user to choose a candidate word in the target language according to its synonym neighborhood. A map showing each language’s neighborhoods and separate clusters for each semantic value helps the user make the choice. This system and its interactive interface is a useful tool appreciated by researchers, translators, writers, and other users. Although this alone is enough to justify the model, it would be worthwhile to incorporate it into a more complete automatic language processing system. We are now working on enhancing the system by including context relations, and by bringing to bear a word’s argument structure, qualia structure, and lexical inheritance. Within the past 10 years, original contributions have been made in the areas of compositional semantics and lexical context assignment (see Ide and Veronis [1998] for the state of the art on word sense disambiguation). Most studies have dealt with the sentence, but some have looked at the discourse and text levels. Based on a generative framework, Pustejovski (1995) proposed a computational model that adds a representation of a word’s structures (event structure, argument structure, qualia structure, and 169 Computational Linguistics Volume 29, Number 2 lexical inheritance structure), along with transformation rules for combining units. In their study, Asher and Lascarides (1995) showed that lexical semantics and discourse structure may interfere with discourse structure and devised heuristics to disentangle the effects of these two interacting levels. Other authors (Foltz, Kintsch, and Landauer 1998; Kintsch 2001; Sch¨utze 1998) have developed an approach based solely on automatic corpus analysis in which co-occurrences and their frequencies are used to generate the semantic space associated with a given word. Edmonds and Hirst (2002) proposed a model with two tiers: a fine-grained synonym tier and a coarse conceptual tier. Unlike Edmonds and Hirst’s approach, which rests on an ontological model and conceptual representations, our model is capable of detecting semantic distinctions solely on the basis of similarity links. This feature is one of the model’s assets, but it is also a limitation, which provides the incentive for the enhancements we are currently developing. Here is a brief preview of our ongoing projects: • Certain words are poorly represented in terms of synonymy. This is the for words that are essentially nonpolysemous, like and thus have very few synonyms. Such entities are better delineated by an ontological, hierarchical representation and by their qualia structure than by synonymy links. Grammatical words also have few synonyms, so they too need to be represented in a formalism more suited to their own features than the one proposed in this article. • Usage contexts or domains of application are not currently given for the different semantic values detected by the model. For example, the value of the word employed to modify external phenomena, whereas the moral and physical values apply to animate beings. It would thus be useful, as in a standard dictionary, to specify the different types of terms the values obtained can modify. • Our research should help improve map drawing. At the present time, map neighborhoods rely solely on semantic criteria, which sometimes leads to the map’s including terms with similar meanings but different syntactic category memberships than the initial word.</abstract>
<intro confidence="0.852409">These projects should contribute to furthering research on language and automatic</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Laure Abplanalp</author>
</authors>
<title>La pertinence et la traduction. Travaux du centre de traduction litt ´eraire,</title>
<date>1998</date>
<location>Lausanne, Switzerland.</location>
<contexts>
<context position="3837" citStr="Abplanalp 1998" startWordPosition="586" endWordPosition="587">tics could be simulated by distances on lexical maps. One advantage of this proposal is that experimental and artifactual findings converge; another is its ability to describe a real lexicon. Although the relevance of our model to the representation of the mental lexicon will not be discussed in this article (attempts to gain insight into this correlation are currently underway in other studies), this point is not unrelated to the suitability of our approach to modeling translation as a cognitive function. 2. Description of the Model No two lexicons are related by a one-to-one correspondence (Abplanalp 1998). In other words, the way words are used to refer to extralinguistic reality varies across languages. Some examples of this are cross-language differences in color naming and, borrowing Chuquet and Paillard’s (1989) English-French examples, differences like: • room: pi`ece, chambre, bureau (or in an abstract domain) • esprit: mind, spirit, wit Certain authors (Abplanalp 1998) insist how impossible it is to translate at the word level and propose recourse to the conceptual level as a theoretical alternative. Concepts are thought to depend on human cognitive abilities that are general and shared</context>
</contexts>
<marker>Abplanalp, 1998</marker>
<rawString>Abplanalp, Laure. 1998. La pertinence et la traduction. Travaux du centre de traduction litt ´eraire, Lausanne, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R Anderson</author>
</authors>
<title>The architecture of cognition.</title>
<date>1983</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="2461" citStr="Anderson (1983)" startWordPosition="380" endWordPosition="381">ly left up to the intuition and expertise of the translator. Our model deals with accessing the lexicon of the target language starting from a notion in the source language. The utility of this research lies in the fact that different languages break down reality in different ways. • Although the translation process has been mastered by a number of experts, it is usually still dependent upon the utilization of tools like dictionaries. The model proposed here relies on semantic maps and offers an alternative method based on the concepts of lexical access and lexical neighborhood. • The work by Anderson (1983) and Collins and Loftus (1975) on the organization of the lexicon is based on priming and the automatic ∗ UMR 5015 CNRS-Universit´e Lyon I, 67 bd Pinel, F-69 675 Bron Cedex. E-mail:{ploux,ji}@isc.cnrs.fr. © 2003 Association for Computational Linguistics Computational Linguistics Volume 29, Number 2 spreading of activation to the prime’s neighboring concepts. As an alternative to these local semantic networks, Masson (1995) proposed a connectionist model that takes into account the subjects’ reaction time during priming experiments (the correspondence is based on the assumption that semantic or</context>
</contexts>
<marker>Anderson, 1983</marker>
<rawString>Anderson, John R. 1983. The architecture of cognition. Harvard University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolas Asher</author>
<author>Alex Lascarides</author>
</authors>
<title>Lexical disambiguation in a discourse context.</title>
<date>1995</date>
<journal>Journal of Semantics,</journal>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="37922" citStr="Asher and Lascarides (1995)" startWordPosition="5886" endWordPosition="5889">de in the areas of compositional semantics and lexical context assignment (see Ide and Veronis [1998] for the state of the art on word sense disambiguation). Most studies have dealt with the sentence, but some have looked at the discourse and text levels. Based on a generative framework, Pustejovski (1995) proposed a computational model that adds a representation of a word’s structures (event structure, argument structure, qualia structure, and 169 Computational Linguistics Volume 29, Number 2 lexical inheritance structure), along with transformation rules for combining units. In their study, Asher and Lascarides (1995) showed that lexical semantics and discourse structure may interfere with discourse structure and devised heuristics to disentangle the effects of these two interacting levels. Other authors (Foltz, Kintsch, and Landauer 1998; Kintsch 2001; Sch¨utze 1998) have developed an approach based solely on automatic corpus analysis in which co-occurrences and their frequencies are used to generate the semantic space associated with a given word. Edmonds and Hirst (2002) proposed a model with two tiers: a fine-grained synonym tier and a coarse conceptual tier. Unlike Edmonds and Hirst’s approach, which </context>
</contexts>
<marker>Asher, Lascarides, 1995</marker>
<rawString>Asher, Nicolas and Alex Lascarides. 1995. Lexical disambiguation in a discourse context. Journal of Semantics, 12(1):9–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benz ´ecri</author>
<author>Jean-Paul</author>
</authors>
<title>Correspondence Analysis Handbook.</title>
<date>1992</date>
<publisher>Dekker, P,</publisher>
<location>New York.</location>
<marker>´ecri, Jean-Paul, 1992</marker>
<rawString>Benz ´ecri, Jean-Paul. 1992. Correspondence Analysis Handbook. Dekker, P, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H ´el`ene Chuquet</author>
<author>Michel Paillard</author>
</authors>
<title>Approches linguistiques des probl`emes de traduction. Ophrys,</title>
<date>1989</date>
<location>Paris.</location>
<marker>Chuquet, Paillard, 1989</marker>
<rawString>Chuquet, H ´el`ene and Michel Paillard. 1989. Approches linguistiques des probl`emes de traduction. Ophrys, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allan M Collins</author>
<author>Elizabeth F Loftus</author>
</authors>
<title>A spreading-activation theory of semantic processing. Psychological Review 82:407–428.</title>
<date>1975</date>
<contexts>
<context position="2491" citStr="Collins and Loftus (1975)" startWordPosition="383" endWordPosition="386">tuition and expertise of the translator. Our model deals with accessing the lexicon of the target language starting from a notion in the source language. The utility of this research lies in the fact that different languages break down reality in different ways. • Although the translation process has been mastered by a number of experts, it is usually still dependent upon the utilization of tools like dictionaries. The model proposed here relies on semantic maps and offers an alternative method based on the concepts of lexical access and lexical neighborhood. • The work by Anderson (1983) and Collins and Loftus (1975) on the organization of the lexicon is based on priming and the automatic ∗ UMR 5015 CNRS-Universit´e Lyon I, 67 bd Pinel, F-69 675 Bron Cedex. E-mail:{ploux,ji}@isc.cnrs.fr. © 2003 Association for Computational Linguistics Computational Linguistics Volume 29, Number 2 spreading of activation to the prime’s neighboring concepts. As an alternative to these local semantic networks, Masson (1995) proposed a connectionist model that takes into account the subjects’ reaction time during priming experiments (the correspondence is based on the assumption that semantic or phonologic proximity and ease</context>
</contexts>
<marker>Collins, Loftus, 1975</marker>
<rawString>Collins, Allan M. and Elizabeth F. Loftus. 1975. A spreading-activation theory of semantic processing. Psychological Review 82:407–428.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shimon Edelman</author>
</authors>
<title>Representation is representation of similarities.</title>
<date>1998</date>
<journal>Behavioral and Brain Sciences,</journal>
<volume>21</volume>
<issue>4</issue>
<marker>Edelman, 1998</marker>
<rawString>Edelman, Shimon. 1998. Representation is representation of similarities. Behavioral and Brain Sciences, 21(4):449–498.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Edmonds</author>
<author>Graeme Hirst</author>
</authors>
<title>Near-synonymy and lexical choice.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>2</issue>
<contexts>
<context position="8604" citStr="Edmonds and Hirst (2002)" startWordPosition="1346" endWordPosition="1349">ink. The final database was obtained through symmetrization of the links produced in the first step. While maintaining the shifts in meaning that occur when there is nontransitivity and that, as we shall see, are essential for developing the model, we created new links to symmetrize any initially one-directional ones.3 Table 1 gives a typical example of the structure of the initial data. Table 2 gives a global evaluation of the number of entries and links in the lexical databases. Note that we are not attempting here to define the term synonymy. We rely on lexicographic publications, which as Edmonds and Hirst (2002) remarked, “have always treated synonymy 1 Masson’s (1995) model assigns each concept a basin of attraction in a multidimensional space of activation. This framework authorizes a certain form of internal variability for the set of patterns corresponding to a concept. Nevertheless the basins are disjoint and do not overlap as do the nodes in local semantic networks. Furthermore, this model, built essentially for the purposes of validating hypotheses and comparing psycholinguistic results, is applicable only to a highly limited vocabulary and is therefore a poor representative of the natural lex</context>
<context position="38387" citStr="Edmonds and Hirst (2002)" startWordPosition="5954" endWordPosition="5957">inguistics Volume 29, Number 2 lexical inheritance structure), along with transformation rules for combining units. In their study, Asher and Lascarides (1995) showed that lexical semantics and discourse structure may interfere with discourse structure and devised heuristics to disentangle the effects of these two interacting levels. Other authors (Foltz, Kintsch, and Landauer 1998; Kintsch 2001; Sch¨utze 1998) have developed an approach based solely on automatic corpus analysis in which co-occurrences and their frequencies are used to generate the semantic space associated with a given word. Edmonds and Hirst (2002) proposed a model with two tiers: a fine-grained synonym tier and a coarse conceptual tier. Unlike Edmonds and Hirst’s approach, which rests on an ontological model and conceptual representations, our model is capable of detecting semantic distinctions solely on the basis of similarity links. This feature is one of the model’s assets, but it is also a limitation, which provides the incentive for the enhancements we are currently developing. Here is a brief preview of our ongoing projects: • Certain words are poorly represented in terms of synonymy. This is the case for words that are essential</context>
</contexts>
<marker>Edmonds, Hirst, 2002</marker>
<rawString>Edmonds, Philip and Graeme Hirst. 2002. Near-synonymy and lexical choice. Computational Linguistics, 28(2):104–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: an Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="5676" citStr="Fellbaum 1998" startWordPosition="872" endWordPosition="873">arget spreading method used. 2.1 A Model Based on Semantic Similarity The model was initially developed on the basis of a semantic similarity: synonymy. Note, however, that the data and the model are independent, so this same framework can be used to organize other types of similarity (contextual, phonological [Rouibah, Ploux, and Ji 2001], etc.). Other authors also organize the lexicon or other kinds of knowledge on the basis of similarity. For example, in Edelman’s (1998) spatial model of internal representations of the world’s objects, spatial proximity reflects object similarity. WordNet (Fellbaum 1998) and EuroWordNet (Vossen 1998) organize the lexicon conceptually as a network of terms, each of which is associated with a partition into 156 Ploux and Ji A Model for Matching Semantic Maps Synsets (a Synset being a small group of synonyms that label a concept). Our model differs from Edelman’s in that it deals with lexical semantics, not perceived objects. It also differs from Miller’s (1990) approach, in three respects: • the grain of the semantic units • the lexical structure generation mode • the resulting geometry and organization Most models1 use separate units to represent words or conc</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, Christiane. 1998. WordNet: an Electronic Lexical Database. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter W Foltz</author>
<author>Walter Kinsch</author>
<author>Thomas K Landauer</author>
</authors>
<title>The measurement of textual coherence with latent semantic analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<pages>25--285</pages>
<marker>Foltz, Kinsch, Landauer, 1998</marker>
<rawString>Foltz, Peter W., Walter Kinsch, and Thomas K. Landauer. 1998. The measurement of textual coherence with latent semantic analysis. Discourse Processes, 25:285–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Jean Veronis</author>
</authors>
<title>Word sense disambiguation: The state of the art.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Ide, Veronis, 1998</marker>
<rawString>Ide, Nancy and Jean Veronis. 1998. Word sense disambiguation: The state of the art. Computational Linguistics, 24(1):1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoko Ikeda</author>
</authors>
<title>Manual response set in a stroop-like task involving categorization of English and Japanese words indicates</title>
<date>1998</date>
<contexts>
<context position="24570" citStr="Ikeda 1998" startWordPosition="3817" endWordPosition="3818">.. . 2.2.5 Spatially Interconnecting the Values. Table 5 shows the hierarchy of the spatial organization. The middle column contains the generic values (when they exist) that interconnect the different meanings of the word. Highly specific values are far from the origin. This organization follows directly from the calculation of the profile matrix, which assigns more weight to infrequent terms and to cliques containing few elements. 2.3 Matching As stated above, the breakdown and overlapping of the lexicon varies from one language to the next. However, several studies (Illes and Francis 1999; Ikeda 1998) have found evidence that the two languages of a bilingual person access a common semantic system. To handle the problem of lexical differences in our translation model, connections link semantic units rather than words. Because they are finer-grained than words, semantic units are assumed to be less sensitive to the way a given language “cuts up” the world, and as such, they are better candidates for achieving a closer fit between the two languages. For a given set of cliques in the source language, the model constructs the set of cliques to be used for the translation. The two spaces (one as</context>
</contexts>
<marker>Ikeda, 1998</marker>
<rawString>Ikeda, Satoko. 1998. Manual response set in a stroop-like task involving categorization of English and Japanese words indicates</rawString>
</citation>
<citation valid="true">
<title>a common semantic representation. Perceptual and Motor Skills,</title>
<date></date>
<marker></marker>
<rawString>a common semantic representation. Perceptual and Motor Skills, 87(2):467–474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judy Illes</author>
<author>Wendy S Francis</author>
</authors>
<title>Convergent cortical representation of semantic processing in bilinguals.</title>
<date>1999</date>
<journal>Brain and Language,</journal>
<volume>70</volume>
<issue>3</issue>
<contexts>
<context position="24557" citStr="Illes and Francis 1999" startWordPosition="3813" endWordPosition="3816"> 1. able, 2. delicious, .. . 2.2.5 Spatially Interconnecting the Values. Table 5 shows the hierarchy of the spatial organization. The middle column contains the generic values (when they exist) that interconnect the different meanings of the word. Highly specific values are far from the origin. This organization follows directly from the calculation of the profile matrix, which assigns more weight to infrequent terms and to cliques containing few elements. 2.3 Matching As stated above, the breakdown and overlapping of the lexicon varies from one language to the next. However, several studies (Illes and Francis 1999; Ikeda 1998) have found evidence that the two languages of a bilingual person access a common semantic system. To handle the problem of lexical differences in our translation model, connections link semantic units rather than words. Because they are finer-grained than words, semantic units are assumed to be less sensitive to the way a given language “cuts up” the world, and as such, they are better candidates for achieving a closer fit between the two languages. For a given set of cliques in the source language, the model constructs the set of cliques to be used for the translation. The two s</context>
</contexts>
<marker>Illes, Francis, 1999</marker>
<rawString>Illes, Judy and Wendy S. Francis. 1999. Convergent cortical representation of semantic processing in bilinguals. Brain and Language, 70(3):347–363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Kinsch</author>
</authors>
<date>2001</date>
<journal>Predication. Cognitive Science,</journal>
<pages>25--173</pages>
<marker>Kinsch, 2001</marker>
<rawString>Kinsch, Walter. 2001. Predication. Cognitive Science, 25:173–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Masson</author>
</authors>
<title>A distributed memory model of semantic priming.</title>
<date>1995</date>
<journal>Journal of Experimental Psychology: Learning, Memory, and Cognition,</journal>
<volume>21</volume>
<issue>1</issue>
<contexts>
<context position="2887" citStr="Masson (1995)" startWordPosition="442" endWordPosition="443">tionaries. The model proposed here relies on semantic maps and offers an alternative method based on the concepts of lexical access and lexical neighborhood. • The work by Anderson (1983) and Collins and Loftus (1975) on the organization of the lexicon is based on priming and the automatic ∗ UMR 5015 CNRS-Universit´e Lyon I, 67 bd Pinel, F-69 675 Bron Cedex. E-mail:{ploux,ji}@isc.cnrs.fr. © 2003 Association for Computational Linguistics Computational Linguistics Volume 29, Number 2 spreading of activation to the prime’s neighboring concepts. As an alternative to these local semantic networks, Masson (1995) proposed a connectionist model that takes into account the subjects’ reaction time during priming experiments (the correspondence is based on the assumption that semantic or phonologic proximity and ease of access are correlated). Rouibah, Ploux, and Ji (2001) showed that experimental data on interactions between phonology and semantics could be simulated by distances on lexical maps. One advantage of this proposal is that experimental and artifactual findings converge; another is its ability to describe a real lexicon. Although the relevance of our model to the representation of the mental l</context>
</contexts>
<marker>Masson, 1995</marker>
<rawString>Masson, Michael. 1995. A distributed memory model of semantic priming. Journal of Experimental Psychology: Learning, Memory, and Cognition, 21(1):3–23.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Guy Maupassant</author>
</authors>
<title>1881. Contes et nouvelles. Gallimard, Biblioth `eque de la Pl ´eiade,</title>
<location>Paris.</location>
<marker>Maupassant, </marker>
<rawString>Maupassant, Guy (de). 1881. Contes et nouvelles. Gallimard, Biblioth `eque de la Pl ´eiade, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guy Maupassant</author>
</authors>
<title>Project Gutenberg Release.</title>
<date>2002</date>
<journal>Original Short Stories,</journal>
<volume>2</volume>
<note>http://www2.cs. cmu.edu/spok/metabook/maupassant.html.</note>
<contexts>
<context position="17551" citStr="Maupassant 2002" startWordPosition="2675" endWordPosition="2676">ans un songe, l’esprit engourdi, paralys´e, sans chagrin vibrant, saisi par une sorte d’engourdissement moral qui l’empˆechait de souffrir, ´eprouvant mˆeme un all´egement qu’augmentaient les exhalaisons ti`edes ´epandues dans la nuit.7 (Maupassant 1881, page 350) Moreover, as we shall see later, this type of continuous link between two values, which acts as a metaphor here, is expressed more explicitly in the English example below. 7 Although the term engourdi is not specifically translated, to help the reader understand this fine shade of meaning, here is a translation of the above passage (Maupassant 2002): He walked as if he were in a dream; his thoughts were paralyzed, although he felt no great grief, for he was in a state of mental torpor that prevented him from suffering, and he even felt a sense of relief which was increased by the mildness of the night. 160 Ploux and Ji A Model for Matching Semantic Maps Table 3 Evaluation of clique granularity. Entry Number of cliques Number of distinc- Number of Synsets containing entry tions found in pub- in WordNet lished dictionaries d´efendre 44 9–13 — distraction 39 3–10 — fou 319 10–23 — jouer 95 15–46 — maison 123 9–42 — vert 50 9 — blue 54 22–34</context>
</contexts>
<marker>Maupassant, 2002</marker>
<rawString>Maupassant, Guy (de). 2002. Original Short Stories, vol. 2, trans. Albert M. C. McMaster and L. Quesada Project Gutenberg Release. http://www2.cs. cmu.edu/spok/metabook/maupassant.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: An on-line lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<marker>Miller, 1990</marker>
<rawString>Miller, George A. 1990. WordNet: An on-line lexical database. International Journal of Lexicography, 3(4):235–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Ploux</author>
</authors>
<title>Mod ´elisation et traitement informatique de la synonymie.</title>
<date>1997</date>
<journal>Linguisticae Investigationes,</journal>
<volume>21</volume>
<issue>1</issue>
<contexts>
<context position="7653" citStr="Ploux (1997)" startWordPosition="1192" endWordPosition="1193">1 Initial Data. Three databases were used: two synonym databases (one containing French terms and one containing English terms) and a translation database (FrenchEnglish, English-French) that maps each term to similar words in the other language. The links between an entry and the terms that follow it were not chosen “by hand.” The data were taken mainly from published dictionaries and thesauruses.2 It is updated and supplemented regularly by the addition of new links between words (synonymy or translation links). The method used to generate the French synonym database (described in detail in Ploux (1997) was applied again to generate the English and translation databases. The first step required creating an intermediate database containing the set of all links attested in available work in lexicography. In this preliminary database, a term was deemed similar to another term if at least one lexicographer had established the link. The final database was obtained through symmetrization of the links produced in the first step. While maintaining the shifts in meaning that occur when there is nontransitivity and that, as we shall see, are essential for developing the model, we created new links to </context>
<context position="10921" citStr="Ploux 1997" startWordPosition="1677" endWordPosition="1678">: (extracted from the French-English translation database) Table 2 Number of entries and links in the lexical databases. Number of entries Mean number of Mean number of terms synonyms per entry proposed by the translation database French 54,690 7.5 2.3 English 148,247 6.8 1.9 as near-synonymy.”4 However, having more flexible semantic links does not detract from the accuracy of the model. No other operations are carried out on the data sets before application of the model. 2.2.2 Semantic Units. To represent variations in a word’s meaning, each word is associated with a spatial form (or space) (Ploux 1997; Ploux amd Victorri 1998). The points in the space are finer units of meaning than the word itself. In our computational simulation, the points are represented by cliques. A clique is a set of terms related to each other by synonymy.5 The conjunction of all terms in the same clique crystallizes and constrains the meaning given to the word. These cliques thus constitute good candidates for generating the substrate upon which the form will take shape. The presentation of the results and the features of the model will be illustrated using examples from the headword good for English and from the </context>
</contexts>
<marker>Ploux, 1997</marker>
<rawString>Ploux, Sabine. 1997. Mod ´elisation et traitement informatique de la synonymie. Linguisticae Investigationes, 21(1):1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Ploux</author>
<author>Bernard Victorri</author>
</authors>
<title>Construction d’espaces s ´emantiques a` l’aide de dictionnaires informatis ´es des synonymes. Traitement automatique des langues,</title>
<date>1998</date>
<pages>39--1</pages>
<marker>Ploux, Victorri, 1998</marker>
<rawString>Ploux, Sabine and Bernard Victorri. 1998. Construction d’espaces s ´emantiques a` l’aide de dictionnaires informatis ´es des synonymes. Traitement automatique des langues, 39(1):161–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
</authors>
<title>Generative Lexicon.</title>
<date>1995</date>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<marker>Pustejovsky, 1995</marker>
<rawString>Pustejovsky, James. 1995. Generative Lexicon. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Reboul</author>
</authors>
<title>Words, concepts, mental representations and other biological categories.</title>
<date>2000</date>
<booktitle>The Lexicon-Encyclopedia Interface.</booktitle>
<editor>In B. Peeters, editor,</editor>
<publisher>Elsevier,</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="4553" citStr="Reboul 2000" startWordPosition="694" endWordPosition="695">me examples of this are cross-language differences in color naming and, borrowing Chuquet and Paillard’s (1989) English-French examples, differences like: • room: pi`ece, chambre, bureau (or in an abstract domain) • esprit: mind, spirit, wit Certain authors (Abplanalp 1998) insist how impossible it is to translate at the word level and propose recourse to the conceptual level as a theoretical alternative. Concepts are thought to depend on human cognitive abilities that are general and shared by all. Although the correspondence between words and concepts remains a controversial topic of study (Reboul 2000), the concept/word opposition is nevertheless relevant to any model of translation, even an artifactual one like ours. As we shall see, even when heeding the specific organization and breakdown of each individual language, the matching operation does not take place at the word level but at the substrate level (defined below), where the set of meanings of each word “cuts out” a form. First, we will present the model we devised to describe the organization of languages. Then we will explain the source-to-target spreading method used. 2.1 A Model Based on Semantic Similarity The model was initial</context>
</contexts>
<marker>Reboul, 2000</marker>
<rawString>Reboul, Anne. 2000. Words, concepts, mental representations and other biological categories. In B. Peeters, editor, The Lexicon-Encyclopedia Interface. Elsevier, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aicha Rouibah</author>
<author>Sabine Ploux</author>
<author>Hyungsuk Ji</author>
</authors>
<title>Un mod `ele spatial des repr ´esentations lexicales impliqu ´ees dans la reconnaissance des mots ´ecrits.</title>
<date>2001</date>
<booktitle>In H ´el`ene Paugam-Moisy, Vincent Nyckees, and Josiane Caron-Pargue (editors), La cognition entre individu et soci´et´e. Herm`es-Science,</booktitle>
<location>Paris.</location>
<marker>Rouibah, Ploux, Ji, 2001</marker>
<rawString>Rouibah, Aicha, Sabine Ploux, and Hyungsuk Ji. 2001. Un mod `ele spatial des repr ´esentations lexicales impliqu ´ees dans la reconnaissance des mots ´ecrits. In H ´el`ene Paugam-Moisy, Vincent Nyckees, and Josiane Caron-Pargue (editors), La cognition entre individu et soci´et´e. Herm`es-Science, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>Sch¨utze, Hinrich. 1998. Automatic sense discrimination. Computational Linguistics, 24(1):97–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Paul Vinay</author>
<author>Jean Darbelnet</author>
</authors>
<title>Stylistique compar´ee du fran¸cais et de l’anglais.</title>
<date>1996</date>
<location>Didier, Paris.</location>
<marker>Vinay, Darbelnet, 1996</marker>
<rawString>Vinay, Jean-Paul and Jean Darbelnet. 1996. Stylistique compar´ee du fran¸cais et de l’anglais. Didier, Paris.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>EuroWordNet: A Multilingual Database with Lexical Semantic Networks. Kluwer Academic,</booktitle>
<editor>Vossen, Piek, editor.</editor>
<location>Dordrecht, the Netherlands.</location>
<contexts>
<context position="37396" citStr="[1998]" startWordPosition="5811" endWordPosition="5811">system and its interactive interface is a useful tool appreciated by researchers, translators, writers, and other users. Although this alone is enough to justify the model, it would be worthwhile to incorporate it into a more complete automatic language processing system. We are now working on enhancing the system by including context relations, and by bringing to bear a word’s argument structure, qualia structure, and lexical inheritance. Within the past 10 years, original contributions have been made in the areas of compositional semantics and lexical context assignment (see Ide and Veronis [1998] for the state of the art on word sense disambiguation). Most studies have dealt with the sentence, but some have looked at the discourse and text levels. Based on a generative framework, Pustejovski (1995) proposed a computational model that adds a representation of a word’s structures (event structure, argument structure, qualia structure, and 169 Computational Linguistics Volume 29, Number 2 lexical inheritance structure), along with transformation rules for combining units. In their study, Asher and Lascarides (1995) showed that lexical semantics and discourse structure may interfere with </context>
</contexts>
<marker>1998</marker>
<rawString>Vossen, Piek, editor. 1998. EuroWordNet: A Multilingual Database with Lexical Semantic Networks. Kluwer Academic, Dordrecht, the Netherlands.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>