<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.974675">
On Jointly Recognizing and Aligning Bilingual Named Entities
</title>
<author confidence="0.99159">
Yufeng Chen, Chengqing Zong Keh-Yih Su
</author>
<affiliation confidence="0.985912">
Institute of Automation, Chinese Academy of Sciences Behavior Design Corporation
</affiliation>
<address confidence="0.538522">
Beijing, China Hsinchu, Taiwan, R.O.C.
</address>
<email confidence="0.988124">
{chenyf,cqzong}@nlpr.ia.ac.cn bdc.kysu@gmail.com
</email>
<sectionHeader confidence="0.997247" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.989505217391304">
We observe that (1) how a given named en-
tity (NE) is translated (i.e., either semanti-
cally or phonetically) depends greatly on its
associated entity type, and (2) entities within
an aligned pair should share the same type.
Also, (3) those initially detected NEs are an-
chors, whose information should be used to
give certainty scores when selecting candi-
dates. From this basis, an integrated model is
thus proposed in this paper to jointly identify
and align bilingual named entities between
Chinese and English. It adopts a new map-
ping type ratio feature (which is the propor-
tion of NE internal tokens that are semanti-
cally translated), enforces an entity type con-
sistency constraint, and utilizes additional
monolingual candidate certainty factors
(based on those NE anchors). The experi-
ments show that this novel approach has sub-
stantially raised the type-sensitive F-score of
identified NE-pairs from 68.4% to 81.7%
(42.1% F-score imperfection reduction) in
our Chinese-English NE alignment task.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999893137254903">
In trans-lingual language processing tasks, such
as machine translation and cross-lingual informa-
tion retrieval, named entity (NE) translation is
essential. Bilingual NE alignment, which links
source NEs and target NEs, is the first step to
train the NE translation model.
Since NE alignment can only be conducted af-
ter its associated NEs have first been identified,
the including-rate of the first recognition stage
significantly limits the final alignment perform-
ance. To alleviate the above error accumulation
problem, two strategies have been proposed in
the literature. The first strategy (Al-Onaizan and
Knight, 2002; Moore, 2003; Feng et al., 2004;
Lee et al., 2006) identifies NEs only on the
source side and then finds their corresponding
NEs on the target side. In this way, it avoids the
NE recognition errors which would otherwise be
brought into the alignment stage from the target
side; however, the NE errors from the source
side still remain.
To further reduce the errors from the source
side, the second strategy (Huang et al., 2003)
expands the NE candidate-sets in both languages
before conducting the alignment, which is done
by treating the original results as anchors, and
then re-generating further candidates by enlarg-
ing or shrinking those anchors&apos; boundaries. Of
course, this strategy will be in vain if the NE an-
chor is missed in the initial detection stage. In
our data-set, this strategy significantly raises the
NE-pair type-insensitive including-rate 1 from
83.9% to 96.1%, and is thus adopted in this paper.
Although the above expansion strategy has
substantially alleviated the error accumulation
problem, the final alignment accuracy is still not
good (type-sensitive F-score only 68.4%, as indi-
cated in Table 2 in Section 4.2). After having
examined the data, we found that: (1) How a
given NE is translated, either semantically
(called translation) or phonetically (called trans-
literation), depends greatly on its associated en-
tity type2. The mapping type ratio, which is the
percentage of NE internal tokens which are
translated semantically, can help with the recog-
nition of the associated NE type; (2) Entities
within an aligned pair should share the same type,
and this restriction should be integrated into NE
alignment as a constraint; (3) Those initially
identified monolingual NEs can act as anchors to
give monolingual candidate certainty scores
</bodyText>
<footnote confidence="0.709739583333333">
1 Which is the percentage of desired NE-pairs that are in-
cluded in the expanded set, and is the upper bound on NE
alignment performance (regardless of NE types).
2 The proportions of semantic translation, which denote the
ratios of semantically translated words among all the asso-
ciated NE words, for person names (PER), location names
(LOC), and organization names (ORG) approximates 0%,
28.6%, and 74.8% respectively in Chinese-English name
entity list (2005T34) released by the Linguistic Data Con-
sortium (LDC). Since the title, such as “sir” and “chairman”,
is not considered as a part of person names in this corpus,
PERs are all transliterated there.
</footnote>
<page confidence="0.937284">
631
</page>
<note confidence="0.94511">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 631–639,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999773">
(preference weightings) for the re-generated can-
didates.
Based on the above observation, a new joint
model which adopts the mapping type ratio, en-
forces the entity type consistency constraint, and
also utilizes the monolingual candidate certainty
factors is proposed in this paper to jointly iden-
tify and align bilingual NEs under an integrated
framework. This framework is decomposed into
three subtasks: Initial Detection, Expansion, and
Alignment&amp;Re-identification. The Initial Detec-
tion subtask first locates the initial NEs and their
associated NE types inside both the Chinese and
English sides. Afterwards, the Expansion subtask
re-generates the candidate-sets in both languages
to recover those initial NE recognition errors.
Finally, the Alignment&amp;Re-identification subtask
jointly recognizes and aligns bilingual NEs via
the proposed joint model presented in Section 3.
With this new approach, 41.8% imperfection re-
duction in type-sensitive F-score, from 68.4% to
81.6%, has been observed in our Chinese-
English NE alignment task.
</bodyText>
<sectionHeader confidence="0.995579" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.999841607142857">
The problem of NE recognition requires both
boundary identification and type classification.
However, the complexity of these tasks varies
with different languages. For example, Chinese
NE boundaries are especially difficult to identify
because Chinese is not a tokenized language. In
contrast, English NE boundaries are easier to
identify due to capitalization clues. On the other
hand, classification of English NE types can be
more challenging (Ji et al., 2006). Since align-
ment would force the linked NE pair to share the
same semantic meaning, the NE that is more re-
liably identified in one language can be used to
ensure its counterpart in another language. This
benefits both the NE boundary identification and
type classification processes, and it hints that
alignment can help to re-identify those initially
recognized NEs which had been less reliable.
As shown in the following example, although
the desired NE “北韩中央通信社” is recognized
partially as “北韩中央” in the initial recognition
stage, it would be more preferred if its English
counterpart “North Korean&apos;s Central News
Agency” is given. The reason for this is that
“News Agency” would prefer to be linked to “通
信社”, rather than to be deleted (which would
happen if “北韩中央” is chosen as the corre-
sponding Chinese NE).
</bodyText>
<figure confidence="0.82489425">
(I) The initial NE detection in a Chinese sentence:
官方的 &lt;ORG&gt;北韩中央&lt;/ORG&gt; 通信社引述海军...
(II) The initial NE detection of its English counterpart:
Official &lt;ORG&gt;North Korean&apos;s Central News Agency
&lt;/ORG&gt; quoted the navy&apos;s statement...
(III) The word alignment between two NEs:
(VI) The re-identified Chinese NE boundary after alignment:
官方的 &lt;ORG&gt;北韩中央通信社&lt;/ORG&gt; 引述海军声明...
</figure>
<bodyText confidence="0.999841615384615">
As another example, the word “lake” in the
English NE is linked to the Chinese character
“湖” as illustrated below, and this mapping is
found to be a translation and not a transliteration.
Since translation rarely occurs for personal
names (Chen et al., 2003), the desired NE type
“LOC” would be preferred to be shared between
the English NE “Lake Constance” and its corre-
sponding Chinese NE “康斯坦茨湖”. As a result,
the original incorrect type “PER” of the given
English NE is fixed, and the necessity of using
mapping type ratio and NE type consistency con-
straint becomes evident.
</bodyText>
<listItem confidence="0.680502">
(I) The initial NE detection result in a Chinese sentence:
在 &lt;LOC&gt;康斯坦茨湖&lt;/LOC&gt; 工作的一艘渡船船长...
(II) The initial NE detection of its English counterpart:
The captain of a ferry boat who works on &lt;PER&gt;Lake Con-
stance &lt;/PER&gt;...
</listItem>
<bodyText confidence="0.85587825">
(III) The word alignment between two NEs:
(VI) The re-identified English NE type after alignment:
The captain of a ferry boat who works on &lt;LOC&gt;Lake
Constance&lt;/LOC&gt;...
</bodyText>
<sectionHeader confidence="0.998493" genericHeader="method">
3 The Proposed Model
</sectionHeader>
<bodyText confidence="0.66379">
As mentioned in the introduction section, given a
Chinese-English sentence-pair ( , , with its
</bodyText>
<equation confidence="0.8963645">
CS ES)
initially recognized Chinese NEs
&lt;CNEi,CTypei &gt;S1,S&gt;_1 and English NEs
[ ENE, j ETypej ]T 1,T &gt;_ 1 ( CTypei and Etypej are
original NE types assigned to and ,
CNE i ENEj
</equation>
<bodyText confidence="0.999970666666667">
respectively), we will first re-generate two NE
candidate-sets from them by enlarging and
shrinking the boundaries of those initially recog-
</bodyText>
<equation confidence="0.67812425">
KC
nized NEs. Let RENE KE
R CNE and denote
1 1
</equation>
<bodyText confidence="0.6851255">
these two re-generated candidate sets for Chi-
nese and English NEs respectively ( K and KE
</bodyText>
<equation confidence="0.392661">
C
</equation>
<bodyText confidence="0.871281333333333">
are their set-sizes), and K = min (S, T) , then a
total K pairs of final Chinese and English NEs
will be picked up from the Cartesian product of
</bodyText>
<page confidence="0.943156">
632
</page>
<equation confidence="0.924754833333333">
RCNE and 1
KC RENE KE
1
ated linking score, which is defined as follows.
Let Score(RCNE  , R
k ENE[ ]
</equation>
<bodyText confidence="0.976865333333333">
k) denote the asso-
ciated linking score for a given candidate-pair
and RENE[ k], where and are
</bodyText>
<equation confidence="0.680051">
 k  [ k]
</equation>
<bodyText confidence="0.8119008">
the associated indexes of the re-generated Chi-
nese and English NE candidates, respectively.
Furthermore, let be the NE type to be re-
RTypek
assigned and shared by RCNE and
</bodyText>
<equation confidence="0.708303">
 k 
</equation>
<bodyText confidence="0.9541585">
(as they possess the same meaning). Assume
that RCNEk and RENE[k] are derived from ini-
tially recognized and , respectively,
CNEi ENEj
and MIC denotes their internal component map-
ping, to be defined in Section 3.1, then
ponent mapping MIC, given a pair of possible
NE configurations RCNE and and their
</bodyText>
<equation confidence="0.663247">
RENE
</equation>
<bodyText confidence="0.85246125">
associated RType. Since Chinese word segmen-
tation is problematic, especially for transliterated
words, the bilingual alignment factor
P MIC RType,RCNE,RENE in Eq (2) is derived
</bodyText>
<equation confidence="0.917641">

to be conditioned on RE (i.e., starting from
NE
</equation>
<bodyText confidence="0.97301">
the English part).
We define the internal component mapping
</bodyText>
<equation confidence="0.97855125">
MIC to be MIC cpn  n  ew n Mtype n n 
 [ , [ ] , ] 1 ,
N 

</equation>
<bodyText confidence="0.9273774">
where [ n, ew[n],Mtypen]
cpn  denotes a linked pair
consisting of a Chinese component
(which might contain several Chinese characters)
and an English word within
</bodyText>
<figure confidence="0.957082214285714">
ew [n ] RCNE and
, according to their associ-
RCNEk
RENE[ k]
,
cpn n
 
Score (RCNEk, RENE[k ) is defined as follows: RENE respectively, with their internal mapping
]
Score RCN type Mtypen to be either translation (abbreviated
( E , RENE )
 
k [ ]
k
</figure>
<equation confidence="0.942473818181818">
 M RType
, , RCNE RENE
, |
IC k  
k [ ]
k
 C NE CType 
i , , ,[ ,
CS ENE EType ES
],
 i j j
</equation>
<bodyText confidence="0.999887285714286">
Here, the “max” operator varies over each
possible internal component mapping MIC and
re-assigned type (PER, LOC, and ORG). For
brevity, we will drop those associated subscripts
from now on, if there is no confusion.
The associated probability factors in the above
linking score can be further derived as follows.
</bodyText>
<equation confidence="0.956696875">
 CNE CType CS
, , ,
[ , ],
ENE EType ES
 PMIC RType,RCNE,RENE
 P RCNE
  |CNE, CType, CS, RType PRENE  |ENE, EType, ES, RType
 P RType
  |,
CNE ENE, CType, EType
In the above equation,
P MIC RTyp
 e, RCNE, 
RENE
P RType CNE
  |, ENE, CType, EType
</equation>
<bodyText confidence="0.633234666666667">
gual Alignment Factor and the Bilingual Type
Re-assignment Factor respectively, to represent
the bilingual related scores (Section 3.1). Also,
</bodyText>
<equation confidence="0.9639485">
P RCNE CNE
  |,CType, CS, RType and
  |NE,EType,ES,RType are Monolin-
P RENE E
</equation>
<bodyText confidence="0.99863025">
gual Candidate Certainty Factors (Section 3.2)
used to assign preference to each selected RCNE
and RENE , based on the initially recognized
NEs (which act as anchors).
</bodyText>
<subsectionHeader confidence="0.999184">
3.1 Bilingual Related Factors
</subsectionHeader>
<bodyText confidence="0.798319">
The bilingual alignment factor mainly represents
the likelihood value of a specific internal com-
as TS) or transliteration (abbreviated as TL). In
total, there are N component mappings, with
NTS translation mappings [ 1, [ 1], NTS
cpnn  ew n TS]n 1 1
and NTL transliteration mappings
[ n , ew
</bodyText>
<equation confidence="0.976815">
cpn [ 2 ] , ] 2 NTL 1
  
2 n TL n , so that N NTS  NTL .
</equation>
<bodyText confidence="0.978647428571429">
Moreover, since the mapping type distribu-
tions of various NE types deviate greatly from
one another, as illustrated in the second footnote,
the associated mapping type ratio    NTS / N is
thus an important feature, and is included in the
internal component mapping configuration speci-
fied above. For example, the MIC between “康斯
坦茨湖” and “Constance Lake” is [康斯坦茨,
Constance, TL] and [湖, Lake, TS], so its asso-
ciated mapping type ratio will be “0.5” (i.e., 1/2).
Therefore, the internal mapping
P(MIC  |RType, RENE) is further deduced by in-
troducing the internal mapping type Mtypen and
the mapping type ratio  as follows:
</bodyText>
<equation confidence="0.998855227272727">
P(MIC  |RType, RENE)
N
P cpn ew Mtype
([ , , ] , |
 RType RENE
, )
 
n [ ]
n n n  1
N  P cpn Mtype ew RType
( |
 
n n , , )
[ ]
n
 
 
(  |, )
n 1   P Mtype ew RType
  n [ ]
n 
 P(  |RType)
</equation>
<bodyText confidence="0.999578142857143">
In the above equation, the mappings between
internal components are trained from the sylla-
ble/word alignment of NE pairs of different NE
types. In more detail , for transliteration, the
model adopted in (Huang et al., 2003), which
first Romanizes Chinese characters and then
transliterates them into English characters, is
</bodyText>
<figure confidence="0.995067772727273">

P
max
M IC RType k
,


(1)
 RCNE RENE
P M RType ,
 , ,
IC




(2)
and
 are the Bilin-

(3)

</figure>
<page confidence="0.966303">
633
</page>
<equation confidence="0.9073817">
used for P(cpnn  |TLn,ew[n],RType) . For transla-
tion, conditional probability is directly used for
P cpn 
( n |TSn, ew[n], RType) .
Lastly, the bilingual type re-assignment factor
P  RType  |CNE, ENE, CType, EType  proposed in
Eq (2) is derived as follows:
P RType RCNE RENE CType EType
  |, , ,  P RType CType EType
  |, 
</equation>
<bodyText confidence="0.998948">
As Eq (4) shows, both the Chinese initial NE
type and English initial NE type are adopted to
jointly identify their shared NE type RType .
</bodyText>
<subsectionHeader confidence="0.974905">
3.2 Monolingual Candidate Certainty Factors
</subsectionHeader>
<bodyText confidence="0.9997678">
On the other hand, the monolingual candidate
certainty factors in Eq (2) indicate the likelihood
that a re-generated NE candidate is the true NE
given its originally detected NE. For Chinese, it
is derived as follows:
</bodyText>
<equation confidence="0.9956036">
P RCNE CNE CType CS RType
(  |, , , )
 PLeftD, RightD, Str[RCNE]  |LenC, CType, RType
P(LeftD  |LenC, CType, RType) (5)
 P(RightD  |LenC, CType, RType)
</equation>
<bodyText confidence="0.887693">
Where, the subscript C denotes Chinese, and
LenC is the length of the originally recognized
</bodyText>
<equation confidence="0.7701935">
Chinese NE CN . and denote the
E LeftD RightD
</equation>
<bodyText confidence="0.729119">
left and right distance (which are the numbers of
Chinese characters) that R shrinks/enlarges
</bodyText>
<subsubsectionHeader confidence="0.318944">
CNE
</subsubsectionHeader>
<bodyText confidence="0.990307">
from the left and right boundary of its anchor
CNE , respectively. As in the above example,
assume that CN and are “AL rP�”
</bodyText>
<equation confidence="0.856223">
E R CNE
</equation>
<bodyText confidence="0.986111363636364">
and “ rPAAf_j4t” respectively, Le and
ftD
RightD will be “-1” and “+3”. Also, Str[RCNE]
stands for the associated Chinese string of RCNE,
ccm denotes the m-th Chinese character within
tributions. The corresponding weighting coeffi-
cients are obtained using the well-known Mini-
mum Error Rate Training (Och, 2003; com-
monly abbreviated as MERT) algorithm by
minimizing the number of associated errors in
the development set.
</bodyText>
<subsectionHeader confidence="0.889446">
3.3 Framework for the Proposed Model
</subsectionHeader>
<bodyText confidence="0.998256785714286">
The above model is implemented with a three-
stage framework: (A) Initial NE Recognition; (B)
NE-Candidate-Set Expansion; and (C) NE
Alignment&amp;Re-identification. The Following
Diagram gives the details of this framework:
For each given bilingual sentence-pair:
(A)Initial NE Recognition: generates the ini-
tial NE anchors with off-the-self packages.
(B)NE-Candidate-Set Expansion: For each
initially detected NE, several NE candi-
dates will be re-generated from the origi-
nal NE by allowing its boundaries to be
shrunk or enlarged within a pre-specified
range.
</bodyText>
<listItem confidence="0.9686775625">
(B.1) Create both RCNE and RENE
candidate-sets, which are ex-
panded from those initial NEs
identified in the previous stage.
(B.2) Construct an NE-pair candidate-
set (named NE-Pair-Candidate-
Set), which is the Cartesian
product of the RCNE and RENE
candidate-sets created above.
(C)NE Alignment&amp;Re-identification: Rank
each candidate in the NE-Pair-Candidate-
Set constructed above with the linking
score specified in Eq (1). Afterwards, con-
duct a beam search process to select the
top K non-overlapping NE-pairs from this
set.
</listItem>
<equation confidence="0.6214975">
m1 P(ccm  |ccm,, RType)

M
(4)
</equation>
<bodyText confidence="0.93895506060606">
that string, and M denotes the total number of Diagram 1. Steps to Generate the Final NE-Pairs
Chinese characters within RCNE.
On the English side, following Eq (5),
P RENE  |ENE, EType, ES, RType

similarly, except that Le and
ftD RightD will be
measured in number of English words. For in-
stance, with EN and as “Lake Con-
E RENE
stance” and “on Lake Constance” respectively,
LeftD and RightD will be “+1” and “0”. Also,
the bigram unit of the Chinese NE string is
ccm
replaced by the English word unit .
ewn
All the bilingual and monolingual factors
mentioned above, which are derived from Eq (1),
are weighted differently according to their con-
It is our observation that, four Chinese charac-
ters for both shrinking and enlarging, two Eng-
lish words for shrinking and three for enlarging
are enough in most cases. Under these conditions,
the including-rates for NEs with correct bounda-
ries are raised to 95.8% for Chinese and 97.4%
for English; and even the NE-pair including rate
is raised to 95.3%. Since the above range limita-
tion setting has an including-rate only 0.8%
lower than that can be obtained without any
range limitation (which is 96.1%), it is adopted
in this paper to greatly reduce the number of NE-
pair-candidates.
can be derived
</bodyText>
<page confidence="0.997759">
634
</page>
<sectionHeader confidence="0.999674" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9999965">
To evaluate the proposed joint approach, a prior
work (Huang et al., 2003) is re-implemented in
our environment as the baseline, in which the
translation cost, transliteration cost and tagging
cost are used. This model is selected for com-
parison because it not only adopts the same can-
didate-set expansion strategy as mentioned above,
but also utilizes the monolingual information
when selecting NE-pairs (however, only a simple
bi-gram model is used as the tagging cost in their
paper). Note that it enforces the same NE type
only when the tagging cost is evaluated:
</bodyText>
<equation confidence="0.9951962">
M
Ctag  minRType [ log( m1 P(ccm  |ccm1, RType))
.
N
 log( n1 P(ewn  |ewn1,RType))]
</equation>
<bodyText confidence="0.9999345">
To give a fairer comparison, the same train-
ing-set and testing-set are adopted. The training-
set includes two parts. The first part consists of
90,412 aligned sentence-pairs newswire data
from the Foreign Broadcast Information Service
(FBIS), which is denoted as Training-Set-I. The
second Part of the training set is the
LDC2005T34 bilingual NE dictionary3, which is
denoted as Training-Set-II. The required feature
information is then manually labeled throughout
the two training sets.
In our experiments, for the baseline system,
the translation cost and the transliteration cost
are trained on Training-Set-II, while the tagging
cost is trained on Training-Set-I. For the pro-
posed approach, the monolingual candidate cer-
tainty factors are trained on Training-Set-I, and
Training-Set-II is used to train the parameters
relating to bilingual alignment factors.
For the testing-set, 300 sentence pairs are ran-
domly selected from the LDC Chinese-English
News Text (LDC2005T06). The average length
of the Chinese sentences is 59.4 characters, while
the average length of the English sentences is
24.8 words. Afterwards, the answer keys for NE
recognition and alignment were annotated manu-
ally, and used as the gold standard to calculate
metrics of precision (P), recall (R), and F-score
(F) for both NE recognition (NER) and NE
alignment (NEA). In Total 765 Chinese NEs and
747 English NEs were manually labeled in the
testing-set, within which there are only 718 NE
pairs, including 214 PER, 371 LOC and 133
ORG NE-pairs. The number of NE pairs is less
</bodyText>
<footnote confidence="0.349577333333333">
3 The LDC2005T34 data-set consists of proofread bilingual
entries: 73,352 person names, 76,460 location names and
68,960 organization names.
</footnote>
<bodyText confidence="0.999209">
than that of NEs, because not all those recog-
nized NEs can be aligned.
Besides, the development-set for MERT
weight training is composed of 200 sentence
pairs selected from the LDC2005T06 corpus,
which includes 482 manually tagged NE pairs.
There is no overlap between the training-sets, the
development-set and the testing-set.
</bodyText>
<subsectionHeader confidence="0.996521">
4.1 Baseline System
</subsectionHeader>
<bodyText confidence="0.9998315">
Both the baseline and the proposed models share
the same initial detection subtask, which adopts
the Chinese NE recognizer reported by Wu et al.
(2005), which is a hybrid statistical model incor-
porating multi-knowledge sources, and the Eng-
lish NE recognizer included in the publicly
available Mallet toolkit4 to generate initial NEs.
Initial Chinese NEs and English NEs are recog-
nized by these two available packages respec-
tively.
</bodyText>
<table confidence="0.999521">
NE-type P (%): C/E R (%): C/E F (%): C/E
PER 80.2 / 79.2 87.7 / 85.3 83.8 / 82.1
LOC 89.8 / 85.9 87.3 / 81.5 88.5/ 83.6
ORG 78.6 / 82.9 82.8 / 79.6 80.6 / 81.2
ALL 83.4 / 82.1 86.0 / 82.6 84.7 / 82.3
</table>
<tableCaption confidence="0.999551">
Table 1. Initial Chinese/English NER
</tableCaption>
<bodyText confidence="0.9984915">
Table 1 shows the initial NE recognition per-
formances for both Chinese and English (the
largest entry in each column is highlighted for
visibility). From Table 1, it is observed that the
F-score of ORG type is the lowest among all NE
types for both English and Chinese. This is be-
cause many organization names are partially rec-
ognized or missed. Besides, not shown in the
table, the location names or abbreviated organi-
zation names tend to be incorrectly recognized as
person names. In general, the initial Chinese
NER outperforms the initial English NER, as the
NE type classification turns out to be a more dif-
ficult problem for this English NER system.
When those initially identified NEs are di-
rectly used for baseline alignment, only 64.1% F
score (regard of their name types) is obtained.
Such a low performance is mainly due to those
NE recognition errors which have been brought
into the alignment stage.
To diminish the effect of errors accumulating,
which stems from the recognition stage, the base-
line system also adopts the same expansion strat-
egy described in Section 3.3 to enlarge the possi-
</bodyText>
<footnote confidence="0.96204">
4 http://mallet.cs.umass.edu/index.php/Main_Page
</footnote>
<page confidence="0.998674">
635
</page>
<bodyText confidence="0.999876428571429">
ble NE candidate set. However, only a slight im-
provement (68.4% type-sensitive F-score) is ob-
tained, as shown in Table 2. Therefore, it is con-
jectured that the baseline alignment model is un-
able to achieve good performance if those fea-
tures/factors proposed in this paper are not
adopted.
</bodyText>
<subsectionHeader confidence="0.997767">
4.2 The Recognition and Alignment Joint
</subsectionHeader>
<bodyText confidence="0.9567965">
Model
To show the individual effect of each factor in
the joint model, a series of experiments, from
Exp0 to Exp11, are conducted. Exp0 is the basic
system, which ignores monolingual candidate
certainty scores, and also disregards mapping
type and NE type consistency constraint by ig-
noring P(Mtypen  |ew[n],RType) and P(  |RType) ,
</bodyText>
<equation confidence="0.912698">
n  |n, ew[n], RType
Mtype )
with P(cpnn  |ew[n]) in Eq (3).
</equation>
<bodyText confidence="0.98235">
To show the effect of enforcing NE type con-
sistency constraint on internal component map-
ping, Exp1 (named Exp0+RType) replaces
</bodyText>
<equation confidence="0.981835">
P(cpnn  |ew[n] ) in Exp0 with
P(cpnn |ew[n] , RType) ; On the other hand, Exp2
</equation>
<bodyText confidence="0.495681">
(named Exp0+MappingType) shows the effect of
introducing the component mapping type to Eq
(3) by replacing P c
</bodyText>
<equation confidence="0.999452">
( pnn  |ew[n]) in Exp0 by
)  P(Mtypen  |ew[ n] ) ; Then
Exp3 (named Exp2+MappingTypeRatio) further
P(  |RTy
</equation>
<bodyText confidence="0.9996797">
 pe) to Exp2, to manifest the con-
tribution from the mapping type ratio. In addition,
Exp4 (named Exp0+RTypeReassignment) adds
the NE type reassignment score, Eq (4), to Exp0
to show the effect of enforcing NE-type consis-
tency. Furthermore, Exp5 (named All-BiFactors)
shows the full power of the set of proposed bi-
lingual factors by turning on all the options men-
tioned above. As the bilingual alignment factors
would favor the candidates with shorter lengths,
</bodyText>
<equation confidence="0.914763166666667">
P cpnn ew n Mtypen n  RType RENE
([ , [ ], ] 1, |
N , ), Eq (3),

is further normalized into the following form:
1
</equation>
<bodyText confidence="0.999909777777778">
and is shown by Exp6 (named All-N-BiFactors).
To show the influence of additional informa-
tion carried by those initially recognized NEs,
Exp7 (named Exp6+LeftD/RightD) adds left and
right distance information into Exp6, as that
specified in Eq (5). To study the monolingual bi-
gram capability, Exp8 (named Exp6+Bigram)
adds the NEtype dependant bigram model of
each language to Exp6. We use SRI Language
Modeling Toolkit5 (SRILM) (Stolcke, 2002) to
train various character/word based bi-gram mod-
els with different NE types. Similar to what we
have done on the bilingual alignment factor
above, Exp9 (named Exp6+N-Bigram) adds the
normalized NEtype dependant bigram to Exp6
for removing the bias induced by having differ-
ent NE lengths. The normalized Chinese NEtype
dependant bigram score is defined as
</bodyText>
<equation confidence="0.98228575">
1
[ M
P(ccm  |ccm1,RType)]M . A Similar trans-
m1
</equation>
<bodyText confidence="0.923342714285714">
formation is also applied to the English side.
Lastly, Exp10 (named Fully-JointModel)
shows the full power of the proposed Recogni-
tion and Alignment Joint Model by adopting all
the normalized factors mentioned above. The
result of a MERT weighted version is further
shown by Exp11 (named Weighted-JointModel).
</bodyText>
<table confidence="0.999845740740741">
Model P (%) R (%) F (%)
Baseline 77.1 79.7 78.4
(67.1) (69.8) (68.4)
Exp0 67.9 70.3 69.1
(Basic System) (62.4) (64.8) (63.6)
Exp1 69.6 71.9 70.8
(Exp0 + Rtype) (65.7) (68.0) (66.8)
Exp2 70.5 73.0 71.7
(Exp0 + MappingType) (65.3) (67.5) (66.4)
Exp3 72.0 74.5 73.2
(Exp2 + MappingTypeRatio) (68.3) (70.8) (69.5)
Exp4 70.2 72.7 71.4
(Exp0 + RTypeReassignment) (66.7) (69.2) (67.9)
Exp5 76.2 78.5 77.3
(All-BiFactors) (72.3) (74.6) (73.4)
Exp6 77.7 79.9 78.8
(All-N-BiFactors) (73.5) (75.7) (74.6)
Exp7 83.5 85.8 84.6
(Exp6 + LeftD/RightD) (77.7) (80.1) (78.9)
Exp8 80.4 82.7 81.5
(Exp6 + Bigram) (75.5) (77.9) (76.7)
Exp9 82.7 85.1 83.9
(Exp6 + N-Bigram) (77.1) (79.6) (78.3)
Exp10 83.7 86.2 84.9
(Fully-JointModel) (78.1) (80.7) (79.4)
Exp11 85.9 88.4 87.1
(Weighted-Joint Model) (80.5) (83.0) (81.7)
</table>
<tableCaption confidence="0.883189">
Table 2. NEA Type-Insensitive (Type-Sensitive)
Performance
</tableCaption>
<bodyText confidence="0.9887785">
Since most papers in the literature are evalu-
ated only based on the boundaries of NEs, two
kinds of performance are thus given here. The
first one (named type-insensitive) only checks
the scope of each NE without taking its associ-
ated NE type into consideration, and is reported
</bodyText>
<figure confidence="0.6964334">
5 http://www.speech.sri.com/projects/srilm/
P(cpnn  |Mtypen,ew[n], RType) N

P(Mtypen  |ew[n],RType)
 

n1
J
 P(  |RType),
and also replacing P
(cpn
P(cpnn  |Mtypen
,ew[ ]
n
adds
</figure>
<page confidence="0.996392">
636
</page>
<bodyText confidence="0.999958375">
as the main data at Table 2. The second one
(named type-sensitive) would also evaluate the
associated NE type of each NE, and is given
within parentheses in Table 2. A large degrada-
tion is observed when NE type is also taken into
account. The highlighted entries are those that
are statistically better6 than that of the baseline
system.
</bodyText>
<subsectionHeader confidence="0.995775">
4.3 ME Approach with Primitive Features
</subsectionHeader>
<bodyText confidence="0.999947866666667">
Although the proposed model has been derived
above in a principled way, since all these pro-
posed features can also be directly integrated
with the well-known maximum entropy (ME)
(Berger et al., 1996) framework without making
any assumptions, one might wonder if it is still
worth to deriving a model after all the related
features have been proposed. To show that not
only the features but also the adopted model con-
tribute to the performance improvement, an ME
approach is tested as follows for comparison. It
directly adopts all those primitive features men-
tioned above as its inputs (including internal
component mapping, initial and final NE type,
NE bigram-based string, and left/right distance),
without involving any related probability factors
derived within the proposed model.
This ME method is implemented with a public
package YASMET7, and is tested under various
training-set sizes (400, 4,000, 40,000, and 90,412
sentence-pairs). All those training-sets are ex-
tracted from the Training-Set-I mentioned above
(a total of 298,302 NE pairs included are manu-
ally labeled). Since the ME approach is unable to
utilize the bilingual NE dictionary (Training-Set-
II), for fair comparison, this dictionary was also
not used to train our models here. Table 3 shows
the performance (F-score) using the same test-
ing-set. The data within parentheses are relative
improvements.
</bodyText>
<table confidence="0.999291571428572">
Model 400 4,000 40,000 90,412
ME framework 36.5 50.4 62.6 67.9
(0%) (0%) (0%) (0%)
Un-weighted- +4.6 +4.5 +4.3 +4.1
JointModel (+12.6%) (+8.9%) (+6.9%) (+6.0%)
Weighted- +5.0 +4.7 +4.6 +4.5
JointModel (+13.7%) (+9.3%) (+7.3%) (+6.6%)
</table>
<tableCaption confidence="0.7840155">
Table 3. Comparison between ME Framework
and Derived Model on the Testing-Set
</tableCaption>
<footnote confidence="0.517195666666667">
6 Statistical significance test is measured on 95% confidence
level on 1,000 re-sampling batches (Zhang et al., 2004)
7 http://www.fjoch.com/YASMET.html
</footnote>
<bodyText confidence="0.9998299">
The improvement indicated in Table 3 clearly
illustrates the benefit of deriving the model
shown in Eq (2). Since a reasonably derived
model not only shares the same training-set with
the primitive ME version above, but also enjoys
the additional knowledge introduced by the hu-
man (i.e., the assumptions/constraints implied by
the model), it is not surprising to find out that a
good model does help, and that it also becomes
more noticeable as the training-set gets smaller.
</bodyText>
<sectionHeader confidence="0.996816" genericHeader="method">
5 Error Analysis and Discussion
</sectionHeader>
<bodyText confidence="0.999937428571429">
Although the proposed model has substantially
improved the performance of both NE alignment
and recognition, some errors still remain. Having
examined those type-insensitive errors, we found
that they can be classified into four categories:
(A) Original NEs or their components are al-
ready not one-to-one mapped (23%). (B) NE
components are one-to-one linked, but the asso-
ciated NE anchors generated from the initial rec-
ognition stage are either missing or spurious
(24%). Although increasing the number of output
candidates generated from the initial recognition
stage might cover the missing problem, possible
side effects might also be expected (as the com-
plexity of the alignment task would also be in-
creased). (C) Mapping types are not assumed by
the model (27%). For example, one NE is abbre-
viated while its counterpart is not; or some loan-
words or out-of-vocabulary terms are translated
neither semantically nor phonetically. (D) Wrong
NE scopes are selected (26%). Errors of this type
are uneasy to resolve, and their possible solutions
are beyond the scope of this paper.
Examples of above category (C) are interest-
ing and are further illustrated as follows. As an
instance of abbreviation errors, a Chinese NE
“葛兰素制药厂 (GlaxoSmithKline Factory)” is
tagged as “葛兰素/PRR 制药厂/n”, while its
counterpart in the English side is simply abbrevi-
ated as “GSK” (or replaced by a pronoun “it”
sometimes). Linking “葛兰素” to “GSK” (or to
the pronoun “it”) is thus out of reach of our
model. It seems an abbreviation table (or even
anaphora analysis) is required to recover these
kind of errors.
As an example of errors resulting from loan-
words; Japanese kanji “明仁” (the name of a
Japanese emperor) is linked to the English word
“Akihito”. Here the Japanese kanji “明仁” is di-
rectly adopted as the corresponding Chinese
characters (as those characters were originally
borrowed from Chinese), which would be pro-
</bodyText>
<page confidence="0.994614">
637
</page>
<bodyText confidence="0.999973142857143">
nounced as “Mingren” in Chinese and thus devi-
ates greatly from the English pronunciation of
“Akihito”. Therefore, it is translated neither se-
mantically nor phonetically. Further extending
the model to cover this new conversion type
seems necessary; however, such a kind of exten-
sion is very likely to be language pair dependent.
</bodyText>
<sectionHeader confidence="0.897178" genericHeader="method">
6 Capability of the Proposed Model
</sectionHeader>
<bodyText confidence="0.999426375">
In addition to improving NE alignment, the pro-
posed joint model can also boost the perform-
ance of NE recognition in both languages. The
corresponding differences in performance (of the
weighted version) when compared with the ini-
tial NER (AP, AR and AF) are shown in Table 4.
Again, those marked entries indicate that they are
statistically better than that of the original NER.
</bodyText>
<table confidence="0.9995126">
NEtype AP (%): C/E AR (%): C/E AF (%): C/E
PER +5.4 / +6.4 +2.2 / +2.6 +3.9 / +4.6
LOC +4.0 / +3.4 -0.2 / +2.7 +1.8 / +3.0
ORG +7.0 / +3.9 +5.6 / +9.1 +6.2 / +6.4
ALL +5.3 /+5.2 +2.4 / +4.0 +3.9 / +4.6
</table>
<tableCaption confidence="0.999811">
Table 4. Improvement in Chinese/English NER
</tableCaption>
<bodyText confidence="0.999915209677419">
The result shows that the proposed joint model
has a clear win over the initial NER for either
Chinese or English NER. In particular, ORG
seems to have yielded the greatest gain amongst
NE types, which matches our previous observa-
tions that the boundaries of Chinese ORG are
difficult to identify with the information only
coming from the Chinese sentence, while the
type of English ORG is uneasy to classify with
the information only coming from the English
sentence.
Though not shown in the tables, it is also ob-
served that the proposed approach achieves a
28.9% reduction on the spurious (false positive)
and partial tags over the initial Chinese NER, as
well as 16.1% relative error reduction compared
with the initial English NER. In addition, total
27.2% wrong Chinese NEs and 40.7% wrong
English NEs are corrected into right NE types.
However, if the mapping type ratio is omitted,
only 21.1% wrong Chinese NE types and 34.8%
wrong English NE types can be corrected. This
clearly indicates that the ratio is essential for
identifying NE types.
With the benefits shown above, the alignment
model could thus be used to train the monolin-
gual NE recognition model via semi-supervised
learning. This advantage is important for updat-
ing the NER model from time to time, as various
domains frequently have different sets of NEs
and new NEs also emerge with time.
Since the Chinese NE recognizer we use is not
an open source toolkit, it cannot be used to carry
out semi-supervised learning. Therefore, only the
English NE recognizer and the alignment model
are updated during training iterations. In our ex-
periments, 50,412 sentence pairs are first ex-
tracted from Training-Set-I as unlabeled data.
Various labeled data-sets are then extracted from
the remaining data as different seed corpora (100,
400, 4,000 and 40,000 sentence-pairs). Table 5
shows the results of semi-supervised learning
after convergence for adopting only the English
NER model (NER-Only), the baseline alignment
model (NER+Baseline), and our un-weighted
joint model (NER+JointModel) respectively. The
Initial-NER row indicates the initial performance
of the NER model re-trained from different seed
corpora. The data within parentheses are relative
improvement over Initial-NER. Note that the
testing set is still the same as before.
As Table 5 shows, with the NER model alone,
the performance may even deteriorate after con-
vergence. This is due to the fact that maximizing
likelihood does not imply minimizing the error
rate. However, with additional mapping con-
straints from the aligned sentence of another lan-
guage, the alignment module could guide the
searching process to converge to a more desir-
able point in the parameter space; and these addi-
tional constraints become more effective as the
seed-corpus gets smaller.
</bodyText>
<table confidence="0.994834333333333">
Model 100 400 4,000 40,000
Initial-NER 36.7 58.6 71.4 79.1
(0%) (0%) (0%) (0%)
-2.3 -0.5 -0.3 -0.1
NER-Only (-6.3%) (-0.8%) (-0.4%) (-0.1%)
NER+Baseline +4.9 +3.4 +1.7 +0.7
(+13.4%) (5.8%) (2.4%) (0.9%)
NER+Joint +10.7 +8.7 +4.8 +2.3
Model (+29.2%) (+14.8%) (+6.7%) (+2.9%)
</table>
<tableCaption confidence="0.9499515">
Table 5. Testing-Set Performance for Semi-
Supervised Learning of English NE Recognition
</tableCaption>
<sectionHeader confidence="0.999071" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99999075">
In summary, our experiments show that the new
monolingual candidate certainty factors are more
effective than the tagging cost (only bigram
model) adopted in the baseline system. Moreover,
both the mapping type ratio and the entity type
consistency constraint are very helpful in identi-
fying the associated NE boundaries and types.
After having adopted the features and enforced
</bodyText>
<page confidence="0.995738">
638
</page>
<bodyText confidence="0.99995975">
the constraint mentioned above, the proposed
framework, which jointly recognizes and aligns
bilingual named entities, achieves a remarkable
42.1% imperfection reduction on type-sensitive
F-score (from 68.4% to 81.7%) in our Chinese-
English NE alignment task.
Although the experiments are conducted on
the Chinese-English language pair, it is expected
that the proposed approach can also be applied to
other language pairs, as no language dependent
linguistic feature (or knowledge) is adopted in
the model/algorithm used.
</bodyText>
<sectionHeader confidence="0.99895" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.980056">
The research work has been partially supported
by the National Natural Science Foundation of
China under Grants No. 60975053, 90820303,
and 60736014, the National Key Technology
R&amp;D Program under Grant No. 2006BAH03B02,
and also the Hi-Tech Research and Development
Program (“863” Program) of China under Grant
No. 2006AA010108-4.
</bodyText>
<sectionHeader confidence="0.998685" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999766087719298">
Al-Onaizan, Yaser, and Kevin Knight. 2002. Translat-
ing Named Entities Using Monolingual and Bilin-
gual resources. In Proceedings of the 40th Annual
Meeting of the Association for Computational Lin-
guistics (ACL), pages 400-408.
Berger, Adam L., Stephen A. Della Pietra and Vin-
cent J. Della Pietra. 1996. A Maximum Entropy
Approach to Natural Language Processing. Com-
putational Linguistics, 22(1):39-72, March.
Chen, Hsin-His, Changhua Yang and Ying Lin. 2003.
Learning Formulation and Transformation Rules
for Multilingual Named Entities. In Proceedings of
the ACL 2003 Workshop on Multilingual and
Mixed-language Named Entity Recognition, pages
1-8.
Feng, Donghui, Yajuan Lv and Ming Zhou. 2004. A
New Approach for English-Chinese Named Entity
Alignment. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing (EMNLP 2004), pages 372-379.
Huang, Fei, Stephan Vogel and Alex Waibel. 2003.
Automatic Extraction of Named Entity Translin-
gual Equivalence Based on Multi-Feature Cost
Minimization. In Proceedings of ACL’03, Work-
shop on Multilingual and Mixed-language Named
Entity Recognition. Sappora, Japan.
Ji, Heng and Ralph Grishman. 2006. Analysis and
Repair of Name Tagger Errors. In Proceedings of
COLING/ACL 06, Sydney, Australia.
Lee, Chun-Jen, Jason S. Chang and Jyh-Shing R. Jang.
2006. Alignment of Bilingual Named Entities in
Parallel Corpora Using Statistical Models and Mul-
tiple Knowledge Sources. ACM Transactions on
Asian Language Information Processing (TALIP),
5(2): 121-145.
Moore, R. C.. 2003. Learning Translations of Named-
Entity Phrases from Parallel Corpora. In Proceed-
ings of 10th Conference of the European Chapter
of ACL, Budapest, Hungary.
Och, Franz Josef. 2003. Minimum Error Rate Train-
ing in Statistical Machine Translation. In Proceed-
ings of the 41st Annual Conference of the Associa-
tion for Computational Linguistics (ACL). July 8-
10, 2003. Sapporo, Japan. Pages: 160-167.
Stolcke, A. 2002. SRILM -- An Extensible Language
Modeling Toolkit. Proc. Intl. Conf. on Spoken
Language Processing, vol. 2, pp. 901-904, Denver.
Wu, Youzheng, Jun Zhao and Bo Xu. 2005. Chinese
Named Entity Recognition Model Based on Multi-
ple Features. In Proceedings of HLT/EMNLP 2005,
pages 427-434.
Zhang, Ying, Stephan Vogel, and Alex Waibel, 2004.
Interpreting BLEU/NIST Scores: How Much Im-
provement Do We Need to Have a Better System?
In Proceedings of the 4th International Conference
on Language Resources and Evaluation, pages
2051--2054.
</reference>
<page confidence="0.998855">
639
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.916263">
<title confidence="0.999939">On Jointly Recognizing and Aligning Bilingual Named Entities</title>
<author confidence="0.998754">Yufeng Chen</author>
<author confidence="0.998754">Chengqing Zong Keh-Yih Su</author>
<affiliation confidence="0.999977">Institute of Automation, Chinese Academy of Sciences Behavior Design Corporation</affiliation>
<address confidence="0.948109">Beijing, China Hsinchu, Taiwan, R.O.C.</address>
<email confidence="0.987115">chenyf@nlpr.ia.ac.cnbdc.kysu@gmail.com</email>
<email confidence="0.987115">cqzong@nlpr.ia.ac.cnbdc.kysu@gmail.com</email>
<abstract confidence="0.999067208333333">We observe that (1) how a given named entity (NE) is translated (i.e., either semantically or phonetically) depends greatly on its associated entity type, and (2) entities within an aligned pair should share the same type. Also, (3) those initially detected NEs are anchors, whose information should be used to give certainty scores when selecting candidates. From this basis, an integrated model is thus proposed in this paper to jointly identify and align bilingual named entities between Chinese and English. It adopts a new mapping type ratio feature (which is the proportion of NE internal tokens that are semantically translated), enforces an entity type consistency constraint, and utilizes additional monolingual candidate certainty factors (based on those NE anchors). The experiments show that this novel approach has substantially raised the type-sensitive F-score of identified NE-pairs from 68.4% to 81.7% (42.1% F-score imperfection reduction) in our Chinese-English NE alignment task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<title>Translating Named Entities Using Monolingual and Bilingual resources.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>400--408</pages>
<contexts>
<context position="1915" citStr="Al-Onaizan and Knight, 2002" startWordPosition="280" endWordPosition="283">tion In trans-lingual language processing tasks, such as machine translation and cross-lingual information retrieval, named entity (NE) translation is essential. Bilingual NE alignment, which links source NEs and target NEs, is the first step to train the NE translation model. Since NE alignment can only be conducted after its associated NEs have first been identified, the including-rate of the first recognition stage significantly limits the final alignment performance. To alleviate the above error accumulation problem, two strategies have been proposed in the literature. The first strategy (Al-Onaizan and Knight, 2002; Moore, 2003; Feng et al., 2004; Lee et al., 2006) identifies NEs only on the source side and then finds their corresponding NEs on the target side. In this way, it avoids the NE recognition errors which would otherwise be brought into the alignment stage from the target side; however, the NE errors from the source side still remain. To further reduce the errors from the source side, the second strategy (Huang et al., 2003) expands the NE candidate-sets in both languages before conducting the alignment, which is done by treating the original results as anchors, and then re-generating further </context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Al-Onaizan, Yaser, and Kevin Knight. 2002. Translating Named Entities Using Monolingual and Bilingual resources. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 400-408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language Processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--1</pages>
<contexts>
<context position="26505" citStr="Berger et al., 1996" startWordPosition="4426" endWordPosition="4429"> (cpn P(cpnn |Mtypen ,ew[ ] n adds 636 as the main data at Table 2. The second one (named type-sensitive) would also evaluate the associated NE type of each NE, and is given within parentheses in Table 2. A large degradation is observed when NE type is also taken into account. The highlighted entries are those that are statistically better6 than that of the baseline system. 4.3 ME Approach with Primitive Features Although the proposed model has been derived above in a principled way, since all these proposed features can also be directly integrated with the well-known maximum entropy (ME) (Berger et al., 1996) framework without making any assumptions, one might wonder if it is still worth to deriving a model after all the related features have been proposed. To show that not only the features but also the adopted model contribute to the performance improvement, an ME approach is tested as follows for comparison. It directly adopts all those primitive features mentioned above as its inputs (including internal component mapping, initial and final NE type, NE bigram-based string, and left/right distance), without involving any related probability factors derived within the proposed model. This ME meth</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Berger, Adam L., Stephen A. Della Pietra and Vincent J. Della Pietra. 1996. A Maximum Entropy Approach to Natural Language Processing. Computational Linguistics, 22(1):39-72, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hsin-His Chen</author>
<author>Changhua Yang</author>
<author>Ying Lin</author>
</authors>
<title>Learning Formulation and Transformation Rules for Multilingual Named Entities.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="7485" citStr="Chen et al., 2003" startWordPosition="1144" endWordPosition="1147"> The initial NE detection in a Chinese sentence: 官方的 &lt;ORG&gt;北韩中央&lt;/ORG&gt; 通信社引述海军... (II) The initial NE detection of its English counterpart: Official &lt;ORG&gt;North Korean&apos;s Central News Agency &lt;/ORG&gt; quoted the navy&apos;s statement... (III) The word alignment between two NEs: (VI) The re-identified Chinese NE boundary after alignment: 官方的 &lt;ORG&gt;北韩中央通信社&lt;/ORG&gt; 引述海军声明... As another example, the word “lake” in the English NE is linked to the Chinese character “湖” as illustrated below, and this mapping is found to be a translation and not a transliteration. Since translation rarely occurs for personal names (Chen et al., 2003), the desired NE type “LOC” would be preferred to be shared between the English NE “Lake Constance” and its corresponding Chinese NE “康斯坦茨湖”. As a result, the original incorrect type “PER” of the given English NE is fixed, and the necessity of using mapping type ratio and NE type consistency constraint becomes evident. (I) The initial NE detection result in a Chinese sentence: 在 &lt;LOC&gt;康斯坦茨湖&lt;/LOC&gt; 工作的一艘渡船船长... (II) The initial NE detection of its English counterpart: The captain of a ferry boat who works on &lt;PER&gt;Lake Constance &lt;/PER&gt;... (III) The word alignment between two NEs: (VI) The re-ident</context>
</contexts>
<marker>Chen, Yang, Lin, 2003</marker>
<rawString>Chen, Hsin-His, Changhua Yang and Ying Lin. 2003. Learning Formulation and Transformation Rules for Multilingual Named Entities. In Proceedings of the ACL 2003 Workshop on Multilingual and Mixed-language Named Entity Recognition, pages 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donghui Feng</author>
<author>Yajuan Lv</author>
<author>Ming Zhou</author>
</authors>
<title>A New Approach for English-Chinese Named Entity Alignment.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2004),</booktitle>
<pages>372--379</pages>
<contexts>
<context position="1947" citStr="Feng et al., 2004" startWordPosition="286" endWordPosition="289">tasks, such as machine translation and cross-lingual information retrieval, named entity (NE) translation is essential. Bilingual NE alignment, which links source NEs and target NEs, is the first step to train the NE translation model. Since NE alignment can only be conducted after its associated NEs have first been identified, the including-rate of the first recognition stage significantly limits the final alignment performance. To alleviate the above error accumulation problem, two strategies have been proposed in the literature. The first strategy (Al-Onaizan and Knight, 2002; Moore, 2003; Feng et al., 2004; Lee et al., 2006) identifies NEs only on the source side and then finds their corresponding NEs on the target side. In this way, it avoids the NE recognition errors which would otherwise be brought into the alignment stage from the target side; however, the NE errors from the source side still remain. To further reduce the errors from the source side, the second strategy (Huang et al., 2003) expands the NE candidate-sets in both languages before conducting the alignment, which is done by treating the original results as anchors, and then re-generating further candidates by enlarging or shrin</context>
</contexts>
<marker>Feng, Lv, Zhou, 2004</marker>
<rawString>Feng, Donghui, Yajuan Lv and Ming Zhou. 2004. A New Approach for English-Chinese Named Entity Alignment. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2004), pages 372-379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Huang</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Automatic Extraction of Named Entity Translingual Equivalence Based on Multi-Feature Cost Minimization.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL’03, Workshop on Multilingual and Mixed-language Named Entity Recognition. Sappora,</booktitle>
<contexts>
<context position="2343" citStr="Huang et al., 2003" startWordPosition="355" endWordPosition="358">limits the final alignment performance. To alleviate the above error accumulation problem, two strategies have been proposed in the literature. The first strategy (Al-Onaizan and Knight, 2002; Moore, 2003; Feng et al., 2004; Lee et al., 2006) identifies NEs only on the source side and then finds their corresponding NEs on the target side. In this way, it avoids the NE recognition errors which would otherwise be brought into the alignment stage from the target side; however, the NE errors from the source side still remain. To further reduce the errors from the source side, the second strategy (Huang et al., 2003) expands the NE candidate-sets in both languages before conducting the alignment, which is done by treating the original results as anchors, and then re-generating further candidates by enlarging or shrinking those anchors&apos; boundaries. Of course, this strategy will be in vain if the NE anchor is missed in the initial detection stage. In our data-set, this strategy significantly raises the NE-pair type-insensitive including-rate 1 from 83.9% to 96.1%, and is thus adopted in this paper. Although the above expansion strategy has substantially alleviated the error accumulation problem, the final a</context>
<context position="12885" citStr="Huang et al., 2003" startWordPosition="2172" endWordPosition="2175">tio will be “0.5” (i.e., 1/2). Therefore, the internal mapping P(MIC |RType, RENE) is further deduced by introducing the internal mapping type Mtypen and the mapping type ratio  as follows: P(MIC |RType, RENE) N P cpn ew Mtype ([ , , ] , |  RType RENE , )   n [ ] n n n  1 N  P cpn Mtype ew RType ( |   n n , , ) [ ] n     ( |, ) n 1   P Mtype ew RType   n [ ] n   P( |RType) In the above equation, the mappings between internal components are trained from the syllable/word alignment of NE pairs of different NE types. In more detail , for transliteration, the model adopted in (Huang et al., 2003), which first Romanizes Chinese characters and then transliterates them into English characters, is  P max M IC RType k ,   (1)  RCNE RENE P M RType ,  , , IC     (2) and  are the Bilin (3)  633 used for P(cpnn |TLn,ew[n],RType) . For translation, conditional probability is directly used for P cpn  ( n |TSn, ew[n], RType) . Lastly, the bilingual type re-assignment factor P  RType |CNE, ENE, CType, EType  proposed in Eq (2) is derived as follows: P RType RCNE RENE CType EType  |, , ,  P RType CType EType  |,  As Eq (4) shows, both the Chinese initial NE type and English </context>
<context position="17253" citStr="Huang et al., 2003" startWordPosition="2914" endWordPosition="2917"> enlarging, two English words for shrinking and three for enlarging are enough in most cases. Under these conditions, the including-rates for NEs with correct boundaries are raised to 95.8% for Chinese and 97.4% for English; and even the NE-pair including rate is raised to 95.3%. Since the above range limitation setting has an including-rate only 0.8% lower than that can be obtained without any range limitation (which is 96.1%), it is adopted in this paper to greatly reduce the number of NEpair-candidates. can be derived 634 4 Experiments To evaluate the proposed joint approach, a prior work (Huang et al., 2003) is re-implemented in our environment as the baseline, in which the translation cost, transliteration cost and tagging cost are used. This model is selected for comparison because it not only adopts the same candidate-set expansion strategy as mentioned above, but also utilizes the monolingual information when selecting NE-pairs (however, only a simple bi-gram model is used as the tagging cost in their paper). Note that it enforces the same NE type only when the tagging cost is evaluated: M Ctag  minRType [ log( m1 P(ccm |ccm1, RType)) . N  log( n1 P(ewn |ewn1,RType))] To give a faire</context>
</contexts>
<marker>Huang, Vogel, Waibel, 2003</marker>
<rawString>Huang, Fei, Stephan Vogel and Alex Waibel. 2003. Automatic Extraction of Named Entity Translingual Equivalence Based on Multi-Feature Cost Minimization. In Proceedings of ACL’03, Workshop on Multilingual and Mixed-language Named Entity Recognition. Sappora, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>Analysis and Repair of Name Tagger Errors.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL 06,</booktitle>
<location>Sydney, Australia.</location>
<marker>Ji, Grishman, 2006</marker>
<rawString>Ji, Heng and Ralph Grishman. 2006. Analysis and Repair of Name Tagger Errors. In Proceedings of COLING/ACL 06, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chun-Jen Lee</author>
<author>Jason S Chang</author>
<author>Jyh-Shing R Jang</author>
</authors>
<title>Alignment of Bilingual Named Entities in Parallel Corpora Using Statistical Models and Multiple Knowledge Sources.</title>
<date>2006</date>
<journal>ACM Transactions on Asian Language Information Processing (TALIP),</journal>
<volume>5</volume>
<issue>2</issue>
<pages>121--145</pages>
<contexts>
<context position="1966" citStr="Lee et al., 2006" startWordPosition="290" endWordPosition="293">ine translation and cross-lingual information retrieval, named entity (NE) translation is essential. Bilingual NE alignment, which links source NEs and target NEs, is the first step to train the NE translation model. Since NE alignment can only be conducted after its associated NEs have first been identified, the including-rate of the first recognition stage significantly limits the final alignment performance. To alleviate the above error accumulation problem, two strategies have been proposed in the literature. The first strategy (Al-Onaizan and Knight, 2002; Moore, 2003; Feng et al., 2004; Lee et al., 2006) identifies NEs only on the source side and then finds their corresponding NEs on the target side. In this way, it avoids the NE recognition errors which would otherwise be brought into the alignment stage from the target side; however, the NE errors from the source side still remain. To further reduce the errors from the source side, the second strategy (Huang et al., 2003) expands the NE candidate-sets in both languages before conducting the alignment, which is done by treating the original results as anchors, and then re-generating further candidates by enlarging or shrinking those anchors&apos;</context>
</contexts>
<marker>Lee, Chang, Jang, 2006</marker>
<rawString>Lee, Chun-Jen, Jason S. Chang and Jyh-Shing R. Jang. 2006. Alignment of Bilingual Named Entities in Parallel Corpora Using Statistical Models and Multiple Knowledge Sources. ACM Transactions on Asian Language Information Processing (TALIP), 5(2): 121-145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
</authors>
<title>Learning Translations of NamedEntity Phrases from Parallel Corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of 10th Conference of the European Chapter of ACL,</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="1928" citStr="Moore, 2003" startWordPosition="284" endWordPosition="285">e processing tasks, such as machine translation and cross-lingual information retrieval, named entity (NE) translation is essential. Bilingual NE alignment, which links source NEs and target NEs, is the first step to train the NE translation model. Since NE alignment can only be conducted after its associated NEs have first been identified, the including-rate of the first recognition stage significantly limits the final alignment performance. To alleviate the above error accumulation problem, two strategies have been proposed in the literature. The first strategy (Al-Onaizan and Knight, 2002; Moore, 2003; Feng et al., 2004; Lee et al., 2006) identifies NEs only on the source side and then finds their corresponding NEs on the target side. In this way, it avoids the NE recognition errors which would otherwise be brought into the alignment stage from the target side; however, the NE errors from the source side still remain. To further reduce the errors from the source side, the second strategy (Huang et al., 2003) expands the NE candidate-sets in both languages before conducting the alignment, which is done by treating the original results as anchors, and then re-generating further candidates by</context>
</contexts>
<marker>Moore, 2003</marker>
<rawString>Moore, R. C.. 2003. Learning Translations of NamedEntity Phrases from Parallel Corpora. In Proceedings of 10th Conference of the European Chapter of ACL, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Conference of the Association for Computational Linguistics (ACL).</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan. Pages:</location>
<contexts>
<context position="14653" citStr="Och, 2003" startWordPosition="2496" endWordPosition="2497">e originally recognized Chinese NE CN . and denote the E LeftD RightD left and right distance (which are the numbers of Chinese characters) that R shrinks/enlarges CNE from the left and right boundary of its anchor CNE , respectively. As in the above example, assume that CN and are “AL rP�” E R CNE and “ rPAAf_j4t” respectively, Le and ftD RightD will be “-1” and “+3”. Also, Str[RCNE] stands for the associated Chinese string of RCNE, ccm denotes the m-th Chinese character within tributions. The corresponding weighting coefficients are obtained using the well-known Minimum Error Rate Training (Och, 2003; commonly abbreviated as MERT) algorithm by minimizing the number of associated errors in the development set. 3.3 Framework for the Proposed Model The above model is implemented with a threestage framework: (A) Initial NE Recognition; (B) NE-Candidate-Set Expansion; and (C) NE Alignment&amp;Re-identification. The Following Diagram gives the details of this framework: For each given bilingual sentence-pair: (A)Initial NE Recognition: generates the initial NE anchors with off-the-self packages. (B)NE-Candidate-Set Expansion: For each initially detected NE, several NE candidates will be re-generate</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, Franz Josef. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceedings of the 41st Annual Conference of the Association for Computational Linguistics (ACL). July 8-10, 2003. Sapporo, Japan. Pages: 160-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM -- An Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>Proc. Intl. Conf. on Spoken Language Processing,</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<location>Denver.</location>
<contexts>
<context position="23880" citStr="Stolcke, 2002" startWordPosition="4008" endWordPosition="4009">s would favor the candidates with shorter lengths, P cpnn ew n Mtypen n  RType RENE ([ , [ ], ] 1, | N , ), Eq (3),  is further normalized into the following form: 1 and is shown by Exp6 (named All-N-BiFactors). To show the influence of additional information carried by those initially recognized NEs, Exp7 (named Exp6+LeftD/RightD) adds left and right distance information into Exp6, as that specified in Eq (5). To study the monolingual bigram capability, Exp8 (named Exp6+Bigram) adds the NEtype dependant bigram model of each language to Exp6. We use SRI Language Modeling Toolkit5 (SRILM) (Stolcke, 2002) to train various character/word based bi-gram models with different NE types. Similar to what we have done on the bilingual alignment factor above, Exp9 (named Exp6+N-Bigram) adds the normalized NEtype dependant bigram to Exp6 for removing the bias induced by having different NE lengths. The normalized Chinese NEtype dependant bigram score is defined as 1 [ M P(ccm |ccm1,RType)]M . A Similar transm1 formation is also applied to the English side. Lastly, Exp10 (named Fully-JointModel) shows the full power of the proposed Recognition and Alignment Joint Model by adopting all the normalized f</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Stolcke, A. 2002. SRILM -- An Extensible Language Modeling Toolkit. Proc. Intl. Conf. on Spoken Language Processing, vol. 2, pp. 901-904, Denver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youzheng Wu</author>
<author>Jun Zhao</author>
<author>Bo Xu</author>
</authors>
<title>Chinese Named Entity Recognition Model Based on Multiple Features.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP</booktitle>
<pages>427--434</pages>
<contexts>
<context position="20031" citStr="Wu et al. (2005)" startWordPosition="3351" endWordPosition="3354"> consists of proofread bilingual entries: 73,352 person names, 76,460 location names and 68,960 organization names. than that of NEs, because not all those recognized NEs can be aligned. Besides, the development-set for MERT weight training is composed of 200 sentence pairs selected from the LDC2005T06 corpus, which includes 482 manually tagged NE pairs. There is no overlap between the training-sets, the development-set and the testing-set. 4.1 Baseline System Both the baseline and the proposed models share the same initial detection subtask, which adopts the Chinese NE recognizer reported by Wu et al. (2005), which is a hybrid statistical model incorporating multi-knowledge sources, and the English NE recognizer included in the publicly available Mallet toolkit4 to generate initial NEs. Initial Chinese NEs and English NEs are recognized by these two available packages respectively. NE-type P (%): C/E R (%): C/E F (%): C/E PER 80.2 / 79.2 87.7 / 85.3 83.8 / 82.1 LOC 89.8 / 85.9 87.3 / 81.5 88.5/ 83.6 ORG 78.6 / 82.9 82.8 / 79.6 80.6 / 81.2 ALL 83.4 / 82.1 86.0 / 82.6 84.7 / 82.3 Table 1. Initial Chinese/English NER Table 1 shows the initial NE recognition performances for both Chinese and English </context>
</contexts>
<marker>Wu, Zhao, Xu, 2005</marker>
<rawString>Wu, Youzheng, Jun Zhao and Bo Xu. 2005. Chinese Named Entity Recognition Model Based on Multiple Features. In Proceedings of HLT/EMNLP 2005, pages 427-434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Zhang</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Interpreting BLEU/NIST Scores: How Much Improvement Do We Need to Have a Better System?</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<pages>2051--2054</pages>
<contexts>
<context position="28111" citStr="Zhang et al., 2004" startWordPosition="4673" endWordPosition="4676">rison, this dictionary was also not used to train our models here. Table 3 shows the performance (F-score) using the same testing-set. The data within parentheses are relative improvements. Model 400 4,000 40,000 90,412 ME framework 36.5 50.4 62.6 67.9 (0%) (0%) (0%) (0%) Un-weighted- +4.6 +4.5 +4.3 +4.1 JointModel (+12.6%) (+8.9%) (+6.9%) (+6.0%) Weighted- +5.0 +4.7 +4.6 +4.5 JointModel (+13.7%) (+9.3%) (+7.3%) (+6.6%) Table 3. Comparison between ME Framework and Derived Model on the Testing-Set 6 Statistical significance test is measured on 95% confidence level on 1,000 re-sampling batches (Zhang et al., 2004) 7 http://www.fjoch.com/YASMET.html The improvement indicated in Table 3 clearly illustrates the benefit of deriving the model shown in Eq (2). Since a reasonably derived model not only shares the same training-set with the primitive ME version above, but also enjoys the additional knowledge introduced by the human (i.e., the assumptions/constraints implied by the model), it is not surprising to find out that a good model does help, and that it also becomes more noticeable as the training-set gets smaller. 5 Error Analysis and Discussion Although the proposed model has substantially improved t</context>
</contexts>
<marker>Zhang, Vogel, Waibel, 2004</marker>
<rawString>Zhang, Ying, Stephan Vogel, and Alex Waibel, 2004. Interpreting BLEU/NIST Scores: How Much Improvement Do We Need to Have a Better System? In Proceedings of the 4th International Conference on Language Resources and Evaluation, pages 2051--2054.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>