<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002896">
<title confidence="0.9958055">
BLCUNLP: Corpus Pattern Analysis for Verbs Based on
Dependency Chain
</title>
<author confidence="0.999066">
Yukun Feng, Qiao Deng and Dong Yu†
</author>
<affiliation confidence="0.998618">
College of Information Science, Beijing Language and Culture University
</affiliation>
<address confidence="0.587209">
No.15 Xueyuan Rd., Beijing, China, 100083. †The corresponding author.
</address>
<email confidence="0.994244">
{fengyukun,dengqiao,yudong}@blcu.edu.cn
</email>
<sectionHeader confidence="0.993802" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999808111111111">
We implemented a syntactic and
semantic tagging system for SemEval
2015 Task 15: Corpus Pattern Analysis.
For syntactic tagging, we present a
Dependency Chain Search Algorithm that
is found to be effective at identifying
structurally distant subjects and objects.
Other syntactic labels are identified using
rules defined over dependency parse
structures and the output of a verb
classification module. Semantic tagging
is performed using a simple lexical
mapping table combined with post-
processing rules written over phrase
structure constituent types and named
entity information. The final score of our
system is 0.530 F1, ranking second in this
task.
</bodyText>
<sectionHeader confidence="0.998876" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998394612903226">
Corpus Pattern Analysis (CPA) is an important
language analysis technique, which attempts to
describe the patterns of word usage in text. In this
paper, we present the system we developed for
SemEval-2015 Task 15: CPA, Subtask1: CPA
parsing. The system operates in two stages:
syntactic tagging and semantic tagging. We first
search for the syntactic roles of a verb’s arguments
in a sentence. We use the following tag set for the
syntactic roles: “subj” is for subject, “obj” is for
object, “iobj” is for indirect object, “advprep” is
for adverbial preposition or other adverbial/verbal
link, “acomp” is for adverbial or verb complement,
and “scomp” is for noun or adjective complement.
For example, take a sentence whose core verb is
“plan”: “Mr Eigen plans to wage his war
diplomatically”. The correct tagging of syntactic
and semantic roles is: Mr [subj/Human Eigen]
plans [advprep/LexicalItem to] [acomp/Activity
wage] his war diplomatically.
Due to time constraints, we put more effort into
improving the accuracy of syntactic tagging. We
rely on simpler techniques for semantic tagging.
For syntactic tagging, we use Stanford CoreNLP
to extract linguistic attributes, deduce dependency
chains through dependency relations and to
classify verbs. When performing semantic tagging,
we use a data driven mapping of words to their
most frequent semantic tag in the task&apos;s training
data in conjunction with a small number of post-
processing rules.
</bodyText>
<sectionHeader confidence="0.999854" genericHeader="method">
2 Our Methods
</sectionHeader>
<subsectionHeader confidence="0.996731">
2.1 System Framework
</subsectionHeader>
<bodyText confidence="0.999970090909091">
Our system consists of five modules (Figure 1).
The first module is Preprocessing, which generates
input files with the correct format for Stanford
CoreNLP to extract linguistic attributes.
The second module is Linguistic Attributes. For
the syntactic layer, tagged arguments must have
direct or indirect dependency relations with the
core verb. Dependency relations are thus a critical
attribute for correctly selecting tagged units and
types. We employ a number of additional
linguistic attributes for our tagging rules: parts of
speech (POS) provide useful information for
syntactic tagging; direct dependency relations and
phrase type are helpful in identifying and
following a dependency chain. Last, named entity
(NE) tags and phrase-structure constituent types
contribute to semantic tagging. In general, we
extract four categories of attributes from sentences:
dependency relations, POS tags, phrase-structure
parse, and NE.
The third module is Verb Classification. Even
when a verb&apos;s dependency relations with related
</bodyText>
<page confidence="0.99686">
325
</page>
<note confidence="0.538461">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 325–328,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
</note>
<figure confidence="0.999059285714286">
Linguistic Attributes
Preprocessing
Dependency Chain
Direct dependency,
Parse tree, POS
Stanford CoreNLP
subj, obj
Processed file
Input file
scomp
iobj
NE
acomp
advprep
Similar structure based on statistics
Basic token-semantic
type table
Classification results
Verb Classification
Rules
Syntactic tagging Semantic tagging
</figure>
<figureCaption confidence="0.6850058">
Figure 1. The system has five modules: Preprocessing, Linguistic Attributes, Verb classification, Syntactic tagging, and
Semantic tagging. First, it preprocesses input files and extracts 4 attributes: direct dependency, parse tree, POS, and NE. Second,
it uses the first three attributes for syntactic tagging, during which indirect dependencies are deduced for “subj” and “obj”
relations, and verbs are classified as candidates for “advprep” tagging. Last, our system uses all four attributes and some post-
processing rules to do semantic tagging.
</figureCaption>
<bodyText confidence="0.999977823529412">
prepositions are the same, we find that different
verbs have varying degrees of preference for an
&amp;quot;advprep&amp;quot; argument. For example, both “abandon”
and “account” can be followed by “for”, yet only
“account” is tagged as “advprep”. According to
corpus statistics, “account” frequently co-occurs
with prepositions. The Verb Classification module
is designed to decide whether a verb is strongly
related to prepositions, allowing the use of this
information in our tagging rules.
The fourth module is the Syntactic Tagging.
This module assigns syntactic tags using a set of
rules that operate over the annotations provided by
the Linguistic Attributes module. When tagging
“subj” and “obj” with basic dependency relations,
we observed that many of the tagged arguments
have no direct dependency relation with the core
verb. We handle these arguments by performing a
heuristic search for the subj or obj of the nearest
ancestor having the missing relation. We find that
this is an effective approach.
The last module is Semantic Tagging. The
training data provides us with plenty of
semantically tagged words, and most of the tagged
words have only one corresponding semantic type.
We construct a word to semantic tag mapping
heuristic based on the most frequent tag for each
word in the training set. Semantic tags are related
to certain NE tags and phrase-structure constituent
types. For instance, person name is normally
tagged as “Human”, and a place is often tagged as
“Location”. To capture this, we augment our
mapping table with a small number of semantic
tagging rules.
</bodyText>
<subsectionHeader confidence="0.997846">
2.2 Linguistic Attribute Extraction
</subsectionHeader>
<bodyText confidence="0.99606875">
We use the Stanford CoreNLP toolkit to get word-
to-word dependency relations, phrase-structure
parse trees, POS, and NE attributes. Our system
rewrites some of the syntactic tags. For example,
the CoreNLP tag “nsubj” is replaced by “subj” in
train data. Table 1 shows the aggregation of all of
the linguistic attributes used by the tagging
modules in our system.
</bodyText>
<table confidence="0.998757333333333">
Attributes Description
dependent ID Sequence number in dependency
tree
dependent Dependent token
phrase type Phrase type
POS Part of speech
NE Named entity type
governor- Dependency relation
dependent Governor token
type
governor
governor ID Sequence number of the governor
</table>
<tableCaption confidence="0.999958">
Table 1. Attributes used for syntactic and semantic tagging.
</tableCaption>
<subsectionHeader confidence="0.991831">
2.3 Verb Classification
</subsectionHeader>
<bodyText confidence="0.99977925">
Before tagging, we divide verbs into two
categories according to the relationship between
the verb and its related prepositions, which leads
to better “advprep” tagging. Our system gathers
</bodyText>
<page confidence="0.995711">
326
</page>
<bodyText confidence="0.9999096">
corpus statistics that cue the affinity of each verb
for the advprep relation. Specifically, we compute
how often the verb takes a direct prepositional
argument and how often the direct prepositional
argument is adjacent to the verb:
</bodyText>
<equation confidence="0.9429628">
cnt(DirectPrep and )
V
cnt(V)
cnt(Adjacent,DirectPrep and V)
cnt(DirectPrep and V)
</equation>
<bodyText confidence="0.999081">
Here, cnt(V) is the total number of sentences that
contain the verb V, cnt(DirectPrep and V) is the
number of sentences where the verb V has a direct
prepositional argument, and cnt(Adjacent,
DirectPrep and V) counts sentences where the
verb not only has a direct dependency relation but
is also directly adjacent to the preposition. Take
the verb “account” as an example, according to
our statistics, P(DirectPrep|V) of “account” is
0.9241, and P(Adjacent|DirectPrep, V) is 0.8425.
Therefore, we can tell that “account” is strongly
related to prepositions. Through considerable
experiments, we set up two threshold values to
decide whether one verb is related to certain
prepositions. When P(DirectPrep|V)&gt;=0.45 and
P(Adjacent|DirectPrep, V)&gt;=0.5, the current verb
is considered to be related to prepositions.
</bodyText>
<subsectionHeader confidence="0.991961">
2.4 Syntactic Tagging
</subsectionHeader>
<bodyText confidence="0.9369511">
2.4.1 subj and obj
For both subj and obj tagging, we first check
whether the verb has any direct subj and obj
dependencies. When such dependencies exist, we
use them directly to assign the subj or obj tag. If a
subj or obj is not contained in the direct
dependency relations, we carry out our
Dependency Chain Search Algorithm to attempt to
find and tag a near-by possibly related subj or obj.
Figure 2 illustrates this algorithm for subj relations.
</bodyText>
<equation confidence="0.972328111111111">
1 goverWordID = GetGoverWordID(verbID);
2 for goverWordID != TREE_ROOT_NODE
3 POS = GetPOSofID(goverWordID);
4 if POS == &amp;quot;VP&amp;quot;
5 subjID = GetDirectSubjID(goverWordID);
6 if subjID != &amp;quot;null&amp;quot;
7 Tagging(subjID, &amp;quot;subj&amp;quot;);
8 break;
9 goverWordID = GetGoverWordID(goverWordID);
</equation>
<figureCaption confidence="0.998963">
Figure 2. Dependency Chain Search Algorithm.
</figureCaption>
<bodyText confidence="0.977567">
Figure 3 illustrates the operation of this
algorithm. The first column of the table is the
dependent word with its id, the second is POS, the
third is dependency relation, and the forth is
govern id.
</bodyText>
<listItem confidence="0.992986230769231">
(8) Court NP 16
nsubj
(9) of PP prep 8
(10) law NP pobj 9
(11) in PP prep 10
(14) Kingdom NP pobj 11
(15) would VP aux 16
(16) need VP ccomp 5
(18) evidence NP dobj 16
(19) before PP prep 16
(20) becoming VP pcomp 19
(21) willing ADJP scomp 20
(23) abandon VP xcomp 21
</listItem>
<figureCaption confidence="0.999463333333333">
Figure 3. An example of the Dependency Chain Search
algorithm at work. The algorithm traverses five dependency
relations to find that “court” is the subject of “abandon”.
</figureCaption>
<subsectionHeader confidence="0.924172">
2.4.2 iobj
</subsectionHeader>
<bodyText confidence="0.999932166666667">
For tokens whose indirect dependency relation
with the verb is “iobj”, we tag it directly. To
increase coverage, we build a table which contains
common double object verbs. If the core verb
belongs to this table, we replace the original tag
“obj” with “iobj”.
</bodyText>
<subsectionHeader confidence="0.826434">
2.4.3 advprep
</subsectionHeader>
<bodyText confidence="0.999957428571429">
As for prepositions which have direct dependency
relations with core verbs and their POS are “PP”,
we check the category of the verb generated by the
Verb Classification module. We produce the
&amp;quot;advprep&amp;quot; tag only if the verb is heuristically
identified as a good candidate for this relation,
otherwise we abandon tagging.
</bodyText>
<subsectionHeader confidence="0.819853">
2.4.4 acomp
</subsectionHeader>
<bodyText confidence="0.999986">
As for tokens whose dependency type with verb is
ccomp” or “xcomp”, and if its POS is “VP” or its
governor’s POS is “VP”, we tag it with “acomp”.
For tokens whose tag is “advprep”, we search
downward for a near-by word whose dependency
type is “pobj” and then tag it with “acomp”.
</bodyText>
<subsectionHeader confidence="0.866025">
2.4.5 scomp
</subsectionHeader>
<bodyText confidence="0.99688">
When a token has the dependency type “acomp”
within the dependency relations produced by
Stanford CoreNLP, it is tagged with “scomp”.
</bodyText>
<equation confidence="0.600361666666667">
P(DirectPrep  |V)
P(Adjacent|DirectPrep, )=
V
</equation>
<figure confidence="0.86573175">
5
4
3
2
1
327
2.5 Semantic Tagging set that we spent less time refining for the
semantic task.
</figure>
<bodyText confidence="0.978968333333333">
We extract words and their semantic types from
the SemEval2015 training data, and populate a
word-to-semantic-type mapping table with the
most frequent semantic type for each word. We
then apply the following semantic tagging rules:
1) If the phrase type of the current token is
“WHNP”, we tag it as “Anything”, or if the
token itself is “who”, “whom”, then we tag it
as “Human”.
2) If the phrase type of the current token is
“SBAR” or “WHADVP”, then we tag its
semantic type as “LexicalItem”.
3) If the NE type of the current token is
“NUMBER”, we tag it as “Numerical Value”.
4) If the NE type of the current token is
“PERSON”, we tag it as “Human”.
5) Else, we tag it according to the word-to-
semantic-type mapping table.
</bodyText>
<sectionHeader confidence="0.997994" genericHeader="method">
3 Evaluation Results
</sectionHeader>
<bodyText confidence="0.9993606">
Our syntactic and semantic tagging results from
the official evaluation are shown in Table 2.
During the official evaluation, we failed to upload
the “undertake” file, which lead to a
comparatively lower score on this task.
</bodyText>
<table confidence="0.999328444444445">
Verbs syntactic tagging semantic tagging
P R F P R F
operate .462 .635 .535 .348 .278 .309
apprehend .749 .634 .687 .669 .403 .503
appreciate .795 .735 .764 .718 .489 .581
continue .857 .776 .814 .701 .495 .580
crush .788 .679 .729 .561 .296 .388
decline .862 .862 .862 .660 .474 .552
undertake .000 .000 .000 .000 .000 .000
</table>
<tableCaption confidence="0.999625">
Table 2. Syntactic and semantic tagging results.
</tableCaption>
<bodyText confidence="0.999988583333333">
The final overall F-score of our system is 0.53,
ranking second on the task, with the baseline
system achieving 0.624. This F-score is calculated
by averaging the F-scores achieved on syntactic
and semantic tagging. On the evaluation data, if
we ignore the &amp;quot;undertake&amp;quot; file that we failed to
upload, the average F-score of syntactic tagging
increases to 0.732, and the combined overall score
increases to 0.619. Similar to our work, the
baseline methods are also rule based, but we
observe that our rules underperform the baseline.
We believe this is because we used a simpler rule
</bodyText>
<sectionHeader confidence="0.999402" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.9999555">
In this paper, we propose simple but reliable
techniques for syntactic and semantic tagging.
These techniques were shown to perform well
within SemEval 2015 Task 15: Corpus Pattern
Analysis. We find that an effective way to
accomplish “subj” and “obj” syntactic tagging is
to utilize our simple Dependency Chain Search
algorithm. We also incorporated verb
classification using simple rules based on corpus
statistics to increase syntactic tagging accuracy.
</bodyText>
<sectionHeader confidence="0.998929" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999840166666667">
We would like to thank the anonymous reviewers
for their helpful suggestions and comments. The
research work is funded by the Natural Science
Foundation of China (No.61300081, 61170162),
and the Fundamental Research Funds for the
Central Universities in BLCU (No. 15YJ030006).
</bodyText>
<sectionHeader confidence="0.999097" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999814814814815">
Patrick Hanks. 2004. Corpus Pattern Analysis. In
EURAALEX Proceedings. Vol. I, pp. 87-98. Lorient,
France: Université de Bretagne-Sud.
Marie-Catherine de Marneffe and Christopher D.
Manning, Stanford typed dependencies manual.
2008.
Bradbury, Jane and El Maarouf, Ismail. 2013. An
empirical classification of verbs based on Semantic
Types: the case of the &apos;poison&apos; verbs&amp;quot; . In
Proceedings of JSSP.
Buchholz, Sabine and Marsi, Erwin. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceedings of CoNLL, New York.
Carreras, Xavier and Marquez, Lluis. 2004.
Introduction to the CoNLL-2004 shared task:
Semantic role labeling. In Proceedings of CoNLL,
Boston.
Hanks, Patrick, and Pustejovsky, James. 2005. A
Pattern Dictionary for Natural Language
Processing . In Revue Française de linguistique
appliquée, 10:2.
El Maarouf, Ismail and Baisa, Vít. 2013. Automatic
classification of semantic patterns from the Pattern
Dictionary of English Verbs. In Proceedings of JSSP.
Popescu, Octavian. 2012. Building a Resource of
Patterns Using Semantic Types. In Proceedings of
LREC, Istanbul.
</reference>
<page confidence="0.998352">
328
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.243949">
<title confidence="0.7921015">BLCUNLP: Corpus Pattern Analysis for Verbs Based on Dependency Chain</title>
<author confidence="0.905196">Qiao Deng Feng</author>
<affiliation confidence="0.882893">College of Information Science, Beijing Language and Culture</affiliation>
<address confidence="0.579894">Xueyuan Rd., Beijing, China, 100083. corresponding</address>
<email confidence="0.569648">fengyukun@blcu.edu.cn</email>
<email confidence="0.569648">dengqiao@blcu.edu.cn</email>
<email confidence="0.569648">yudong@blcu.edu.cn</email>
<abstract confidence="0.997623684210526">We implemented a syntactic and semantic tagging system for SemEval 2015 Task 15: Corpus Pattern Analysis. For syntactic tagging, we present a Dependency Chain Search Algorithm that is found to be effective at identifying structurally distant subjects and objects. Other syntactic labels are identified using rules defined over dependency parse structures and the output of a verb classification module. Semantic tagging is performed using a simple lexical mapping table combined with postprocessing rules written over phrase structure constituent types and named entity information. The final score of our system is 0.530 F1, ranking second in this task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Patrick Hanks</author>
</authors>
<title>Corpus Pattern Analysis.</title>
<date>2004</date>
<booktitle>In EURAALEX Proceedings.</booktitle>
<volume>Vol. I,</volume>
<pages>87--98</pages>
<institution>Université de Bretagne-Sud.</institution>
<location>Lorient, France:</location>
<marker>Hanks, 2004</marker>
<rawString>Patrick Hanks. 2004. Corpus Pattern Analysis. In EURAALEX Proceedings. Vol. I, pp. 87-98. Lorient, France: Université de Bretagne-Sud.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>Stanford typed dependencies manual.</title>
<date>2008</date>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Christopher D. Manning, Stanford typed dependencies manual. 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Bradbury</author>
<author>Ismail El Maarouf</author>
</authors>
<title>An empirical classification of verbs based on Semantic Types: the case of the &apos;poison&apos; verbs&amp;quot; .</title>
<date>2013</date>
<booktitle>In Proceedings of JSSP.</booktitle>
<marker>Bradbury, El Maarouf, 2013</marker>
<rawString>Bradbury, Jane and El Maarouf, Ismail. 2013. An empirical classification of verbs based on Semantic Types: the case of the &apos;poison&apos; verbs&amp;quot; . In Proceedings of JSSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<location>New York.</location>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Buchholz, Sabine and Marsi, Erwin. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of CoNLL, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Lluis Marquez</author>
</authors>
<title>Introduction to the CoNLL-2004 shared task: Semantic role labeling.</title>
<date>2004</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<location>Boston.</location>
<marker>Carreras, Marquez, 2004</marker>
<rawString>Carreras, Xavier and Marquez, Lluis. 2004. Introduction to the CoNLL-2004 shared task: Semantic role labeling. In Proceedings of CoNLL, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Hanks</author>
<author>James Pustejovsky</author>
</authors>
<title>A Pattern Dictionary for Natural Language Processing .</title>
<date>2005</date>
<booktitle>In Revue Française de linguistique appliquée,</booktitle>
<pages>10--2</pages>
<marker>Hanks, Pustejovsky, 2005</marker>
<rawString>Hanks, Patrick, and Pustejovsky, James. 2005. A Pattern Dictionary for Natural Language Processing . In Revue Française de linguistique appliquée, 10:2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ismail El Maarouf</author>
<author>Vít Baisa</author>
</authors>
<title>Automatic classification of semantic patterns from the Pattern Dictionary of English Verbs.</title>
<date>2013</date>
<booktitle>In Proceedings of JSSP.</booktitle>
<marker>El Maarouf, Baisa, 2013</marker>
<rawString>El Maarouf, Ismail and Baisa, Vít. 2013. Automatic classification of semantic patterns from the Pattern Dictionary of English Verbs. In Proceedings of JSSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Octavian Popescu</author>
</authors>
<title>Building a Resource of Patterns Using Semantic Types.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Istanbul.</location>
<marker>Popescu, 2012</marker>
<rawString>Popescu, Octavian. 2012. Building a Resource of Patterns Using Semantic Types. In Proceedings of LREC, Istanbul.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>