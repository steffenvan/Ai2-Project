<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.084729">
<title confidence="0.319846">
REQUIREMENTS OF TEXT PROCESSING LEXICONS
</title>
<author confidence="0.49997">
Kenneth C. Litkowski
</author>
<affiliation confidence="0.191455">
16729 Shea Lane, Gaithersburg, Md. 20760
</affiliation>
<bodyText confidence="0.998801207407408">
Five years ago, Dwight Bolinger (11 wrote
that efforts to represent meaning had
not yet made use of the insights of lexico-
graphy. The few substantial efforts, such as
those spearheaded by Olney (2,3], Mel°Cuk
[4], Smith [5], and Simmons [6,7), made some
progress, but never came to fruition. Today,
lexicography and its products, the diction-
aries, remain an untapped resource of uncer-
tain value. Indeed, many who have analyzed
the contents of a dictionary have concluded
that it is of little value to linguistics or
artificial intelligence. Because of the size
and complexity of a dictionary, perhaps such
a conclusion is inevitable, but I believe it
is wrong. To avoid becoming irretrievably
lost in the minutiae of a dictionary and to
view the real potential of this resource, it
is necessary to develop a comprehensive
model within which a dictionary°9 detail can
be tied together. When this is done, I believe
one can identify the requirements for a se-
mantic representation of an entry in the lex-
icon to be used in natural language processing
systems. I describe herein what I have
learned from this type of effort.
I began with the objective of identifying
primitive words or concepts by following
definitional paths within a dictionary. To
search for these, I developed a model of a
dictionary using the theory of labeled di-
rected graphs. In this model, a point or node
is taken to represent a definition and a line
or arc is taken to represent a derivational
relationship between definitions. With such a
model, I could use theorems of graph theory
to predict the existence and form of primi-
tives within the dictionary. This justified
continued effort to attempt to find such
primitives.
The model showed that the big problem to be
overcome in trying to find the primitives is
the apparent rampant circularity of defining
relationships. To eliminate these apparent
vicious circles, it is necessary to make a
precise identification of derivational re-
lationships, specifically, to find the spe-
cific definition that provides the sense in
which its definiendum is used in defining an-
other word. When this is done, the spurious
cycles are broken and precise derivational
relationships are identified. Although this
can be done manually, the sheer bulk of a
dictionary requires that it be done with
well-defined procedures, i.e. with a syn-
tactic and semantic parser. It is in the
attempt to lay out the elements of such a
parser that the requirements of semantic rep-
resentations have emerged.
The parser must first be capable of handling
the syntactic complexity of the definitions
within a dictionary. This can be done by
modifying and adding to existing ATN parsers,
based on syntactic patterns present within a
dictionary. Incidentally, a dictionary is an
excellent large corpus upon which to base
such a parser.
The parser must go beyond syntactics, i.e.,
it must be capable of identifying which sense of
a word is being used. Rieger (8,91 has argued
for the necessity of sense selection or dis-
crimination nets. To develop such a net for
each word in the lexicon, I suggest the poss-
ibility of using a parser to analyze the def-
initions of a word and thereby to create a
net which will be capable of discriminating
among all definitions of a word.
The following requirements must be satisfied
by such a parser and its resulting nets.
Diagnostic or differentiating components are
needed for each definition. Each definition
must have a different semantic represent-
ation, even though there may be a core mean-
ing for all the definitions of a word. Since
the ability to traverse a net successfully
depends on the context in which a word is
used, each definition, i.e. each semantic
representation, must include slots to be
filled by that context. The slots will pro-
vide a unique context for each sense of a
word. Context is what permits disambiguation.
Since the search through a net is inherently
complex, a definition must drive the parser
in the search for context which will fill its
slots. These notions are consistent with
Rieger•sr however, they were identified in-
dependently based on my analysis of dictionary
definitions. Their viability depends on the
ability to describe procedures for developing
a parser of this type to generate the desired
semantic representations.
As mentioned before, observation of syntactic
patterns will lead to an enhancement of syn-
tactic parsing; to a limited extent, the syn-
tactic parser will permit some discrimination,
e.g. of transitive and intransitive verbs or
verbs which use particles. Further procedures
for developing semantic representations are
described using the intransitive senses of the
verb &amp;quot;change ° as examples. Procedures are de-
scribed for (1) using definitions of preposi-
tions for identifying semantic cases which
will operate as slots in the semantic repre-
sentation, (2) showing how selectional re-
strictions on what can fill such slots are
derived from the definitional matter, and
(3) identifying semantic components that are
present within a definition. It is pointed
out how it will eventually be necessary that
these representations be given in terms of
primitives. Procedures are described for
building discrimination nets from the results
of parsing the definitions and for adding to
these nets how the parser should be driven.
The emphasis of this paper is in describing
procedures that have been developed thus far.
Finally, it is shown how these procedures are
used to identify explicit derivational rela-
tionships present within a dictionary in order
to move toward identification of primitives.
Such relationships are very similar to the
Lexical functions used by Mel°Cuk, except
that in this case both the function and the
argument are elements of the lexicon, rather
than the argument alone.
</bodyText>
<page confidence="0.998173">
153
</page>
<bodyText confidence="0.999845833333333">
It has become clear that semantic represent-
ations of definitions in the form described
must ultimately constitute the elements out
of which semantic representations of multi-
sentence texts must be created, perhaps with
two foci: (1) describing entities (centered
around nouns) and (2) describing events
(centered around verbs). If multisentence
texts can then be studied empirically, the
structure of ordinary discourse will then be
based on observations rather than theory.
Although this paradigm may seem to be in-
credibly complex, I believe that it is
nothing more than what the lexicons of pre-
sent Al systems are becoming. I believe that
more rapid progress can be made with an ex-
plicit effort to exploit and not to duplicate
the efforts of lexicographers.
</bodyText>
<sectionHeader confidence="0.995759" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.998362317073171">
1. Bolinger,D., Aspects of Language, 2nd ed.,
Harcourt Brace Jovanovich, Inc., New York,
1975, p.224.
2. Olney,J., C.Revard, and P.Ziff, Toward the
Development of Computational Aids for
Obtaining a Formal Semantic Description of
English, SP-2766/001/00, System Development
Corporation, Santa Monica, California,
1 October 1968.
3. Olney,J. and D.Ramsey, &amp;quot;From machine-
readable dictionaries to a lexicon tester:
Progress, plans, and an offer,&apos; Computer
Studies in the Humanities and Verbal
Behavior, Vol.3, No.4, November 1972, PP.
213-220.
4. Mel•Cuk,I.A., &apos;A new kind of dictionary
and its role as a core component of auto-
matic text processing systems, T.A.
Informations, 1978, No.2, PP.3-8.
5. Smith,R.N., &amp;quot;Interactive lexicon updating,&apos;
Computers and the Humanities, Vol.6, No.3,
January 1972, pp. 137-145.
6. Simmons,R.F. and R.A.Amsler, Modeling
Dictionary Data, Computer Science Depart-
ment, University of Texas, Austin, April
1975.
7. Simmons,R.F. and W.P.Lehmann, A Proposal to
Develop a Computational Methodology for
Deriving Natural Language Semantic Struc-
tures via Analysis of Machine-Readable
Dictionaries, University of Texas, Austin,
1976 (Research proposal submitted to the
National Science Foundation, Sept.28,1976).
8. Rieger,C., Viewing Parsing as Word Sense
Discrimination, TR-511, Department of Com-
puter Science, University of Maryland,
College Park, Maryland, January 1977.
9. Rieger,C. and S.Small, Word Expert Parsing,
TR-734, Department of Computer Science,
University of Maryland, College Park,
Maryland, March 1979.
</reference>
<page confidence="0.999772">
154
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001362">
<title confidence="0.997659">REQUIREMENTS OF TEXT PROCESSING LEXICONS</title>
<author confidence="0.999385">Kenneth C Litkowski</author>
<address confidence="0.720353">16729 Shea Lane, Gaithersburg, Md. 20760</address>
<abstract confidence="0.999209136363637">Five years ago, Dwight Bolinger (11 wrote that efforts to represent meaning had not yet made use of the insights of lexicography. The few substantial efforts, such as those spearheaded by Olney (2,3], Mel°Cuk [4], Smith [5], and Simmons [6,7), made some progress, but never came to fruition. Today, lexicography and its products, the dictionaries, remain an untapped resource of uncertain value. Indeed, many who have analyzed the contents of a dictionary have concluded that it is of little value to linguistics or artificial intelligence. Because of the size and complexity of a dictionary, perhaps such conclusion but I believe it is wrong. To avoid becoming irretrievably lost in the minutiae of a dictionary and to view the real potential of this resource, it is necessary to develop a comprehensive model within which a dictionary°9 detail can be tied together. When this is done, I believe one can identify the requirements for a semantic representation of an entry in the lexto be used language processing systems. I describe herein what I have learned from this type of effort. I began with the objective of identifying primitive words or concepts by following definitional paths within a dictionary. To search for these, I developed a model of a dictionary using the theory of labeled directed graphs. In this model, a point or node is taken to represent a definition and a line or arc is taken to represent a derivational relationship between definitions. With such a model, I could use theorems of graph theory to predict the existence and form of primitives within the dictionary. This justified continued effort to attempt to find such primitives. The model showed that the big problem to be overcome in trying to find the primitives is the apparent rampant circularity of defining relationships. To eliminate these apparent vicious circles, it is necessary to make a precise identification of derivational relationships, specifically, to find the spedefinition that provides the sense which its definiendum is used in defining another word. When this is done, the spurious cycles are broken and precise derivational relationships are identified. Although this can be done manually, the sheer bulk of a dictionary requires that it be done with well-defined procedures, i.e. with a synand semantic parser. It is attempt to lay out the elements of such a parser that the requirements of semantic representations have emerged. The parser must first be capable of handling the syntactic complexity of the definitions within a dictionary. This can be done by modifying and adding to existing ATN parsers, based on syntactic patterns present within a Incidentally, a dictionary excellent large corpus upon which to base such a parser. The parser must go beyond syntactics, i.e., it must be capable of identifying which sense of a word is being used. Rieger (8,91 has argued for the necessity of sense selection or discrimination nets. To develop such a net for each word in the lexicon, I suggest the possibility of using a parser to analyze the definitions of a word and thereby to create a net which will be capable of discriminating among all definitions of a word. The following requirements must be satisfied by such a parser and its resulting nets. Diagnostic or differentiating components are for each definition. Each must have a different semantic representation, even though there may be a core meaning for all the definitions of a word. Since the ability to traverse a net successfully on the context in which a word definition,i.e. each semantic include slots to be by that context.The slots will provide a unique context for each sense of a word. Context is what permits disambiguation. Since the search through a net is inherently definition must drive the parser in the search for context which will fill its slots. These notions are consistent with Rieger•sr however, they were identified independently based on my analysis of dictionary definitions. Their viability depends on the ability to describe procedures for developing a parser of this type to generate the desired semantic representations. As mentioned before, observation of syntactic patterns will lead to an enhancement of syntactic parsing; to a limited extent, the syntactic parser will permit some discrimination, e.g. of transitive and intransitive verbs or verbs which use particles. Further procedures for developing semantic representations are described using the intransitive senses of the verb &amp;quot;change ° as examples. Procedures are described for (1) using definitions of prepositions for identifying semantic cases which will operate as slots in the semantic representation, (2) showing how selectional restrictions on what can fill such slots are derived from the definitional matter, and (3) identifying semantic components that are present within a definition. It is pointed out how it will eventually be necessary that these representations be given in terms of primitives. Procedures are described for building discrimination nets from the results of parsing the definitions and for adding to these nets how the parser should be driven. The emphasis of this paper is in describing procedures that have been developed thus far. Finally, it is shown how these procedures are used to identify explicit derivational relationships present within a dictionary in order to move toward identification of primitives. Such relationships are very similar to the Lexical functions used by Mel°Cuk, except that in this case both the function and the argument are elements of the lexicon, rather than the argument alone. 153 It has become clear that semantic representations of definitions in the form described must ultimately constitute the elements out of which semantic representations of multisentence texts must be created, perhaps with two foci: (1) describing entities (centered around nouns) and (2) describing events (centered around verbs). If multisentence texts can then be studied empirically, the structure of ordinary discourse will then be based on observations rather than theory. Although this paradigm may seem to be incredibly complex, I believe that it is nothing more than what the lexicons of present Al systems are becoming. I believe that rapid progress can with an explicit effort to exploit and not to duplicate the efforts of lexicographers.</abstract>
<note confidence="0.8699072">REFERENCES Bolinger,D., of Language,2nd ed., Harcourt Brace Jovanovich, Inc., New York, 1975, p.224. Olney,J., C.Revard, and P.Ziff, the Development of Computational Aids for Obtaining a Formal Semantic Description of English,SP-2766/001/00, System Development Corporation, Santa Monica, California, 1 October 1968.</note>
<abstract confidence="0.864287888888889">Olney,J. and D.Ramsey, &amp;quot;From machinereadable dictionaries to a lexicon tester: plans, and an offer,&apos; Studies in the Humanities and Verbal Behavior,Vol.3, No.4, November 1972, PP. 213-220. 4. Mel•Cuk,I.A., &apos;A new kind of dictionary and its role as a core component of automatic text processing systems, T.A.</abstract>
<note confidence="0.8662425">Informations,1978, No.2, 5. Smith,R.N., &amp;quot;Interactive lexicon updating,&apos; and the Humanities,Vol.6, No.3, January 1972, pp. 137-145. Simmons,R.F. and R.A.Amsler, Data,Computer Science Department, University of Texas, Austin, April 1975.</note>
<title confidence="0.7257385">Simmons,R.F. and W.P.Lehmann, to Develop a Computational Methodology for Deriving Natural Language Semantic Structures via Analysis of Machine-Readable</title>
<note confidence="0.6822716">Dictionaries,University of Texas, Austin, 1976 (Research proposal submitted to the National Science Foundation, Sept.28,1976). Rieger,C., Parsing as Word Sense Discrimination,TR-511, Department of Com-</note>
<affiliation confidence="0.823981">puter Science, University of Maryland,</affiliation>
<address confidence="0.823042">College Park, Maryland, January 1977.</address>
<affiliation confidence="0.923889">Rieger,C. and S.Small, Expert Parsing, TR-734, Department of Computer Science, University of Maryland, College Park,</affiliation>
<address confidence="0.898052">Maryland, March 1979.</address>
<intro confidence="0.465415">154</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Bolinger</author>
</authors>
<title>Aspects of Language, 2nd ed.,</title>
<date>1975</date>
<pages>224</pages>
<publisher>Harcourt Brace Jovanovich, Inc.,</publisher>
<location>New York,</location>
<contexts>
<context position="4804" citStr="(1)" startWordPosition="792" endWordPosition="792">ysis of dictionary definitions. Their viability depends on the ability to describe procedures for developing a parser of this type to generate the desired semantic representations. As mentioned before, observation of syntactic patterns will lead to an enhancement of syntactic parsing; to a limited extent, the syntactic parser will permit some discrimination, e.g. of transitive and intransitive verbs or verbs which use particles. Further procedures for developing semantic representations are described using the intransitive senses of the verb &amp;quot;change ° as examples. Procedures are described for (1) using definitions of prepositions for identifying semantic cases which will operate as slots in the semantic representation, (2) showing how selectional restrictions on what can fill such slots are derived from the definitional matter, and (3) identifying semantic components that are present within a definition. It is pointed out how it will eventually be necessary that these representations be given in terms of primitives. Procedures are described for building discrimination nets from the results of parsing the definitions and for adding to these nets how the parser should be driven. The emp</context>
</contexts>
<marker>1.</marker>
<rawString>Bolinger,D., Aspects of Language, 2nd ed., Harcourt Brace Jovanovich, Inc., New York, 1975, p.224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Olney</author>
<author>C Revard</author>
<author>P Ziff</author>
</authors>
<title>Toward the Development of Computational Aids for Obtaining a Formal Semantic Description of English,</title>
<date>1968</date>
<booktitle>SP-2766/001/00, System Development Corporation,</booktitle>
<location>Santa Monica, California,</location>
<contexts>
<context position="4933" citStr="(2)" startWordPosition="812" endWordPosition="812">e to generate the desired semantic representations. As mentioned before, observation of syntactic patterns will lead to an enhancement of syntactic parsing; to a limited extent, the syntactic parser will permit some discrimination, e.g. of transitive and intransitive verbs or verbs which use particles. Further procedures for developing semantic representations are described using the intransitive senses of the verb &amp;quot;change ° as examples. Procedures are described for (1) using definitions of prepositions for identifying semantic cases which will operate as slots in the semantic representation, (2) showing how selectional restrictions on what can fill such slots are derived from the definitional matter, and (3) identifying semantic components that are present within a definition. It is pointed out how it will eventually be necessary that these representations be given in terms of primitives. Procedures are described for building discrimination nets from the results of parsing the definitions and for adding to these nets how the parser should be driven. The emphasis of this paper is in describing procedures that have been developed thus far. Finally, it is shown how these procedures are </context>
</contexts>
<marker>2.</marker>
<rawString>Olney,J., C.Revard, and P.Ziff, Toward the Development of Computational Aids for Obtaining a Formal Semantic Description of English, SP-2766/001/00, System Development Corporation, Santa Monica, California, 1 October 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Olney</author>
<author>D Ramsey</author>
</authors>
<title>From machinereadable dictionaries to a lexicon tester: Progress, plans, and an offer,&apos;</title>
<date>1972</date>
<booktitle>Computer Studies in the Humanities and Verbal Behavior, Vol.3, No.4,</booktitle>
<pages>213--220</pages>
<contexts>
<context position="5048" citStr="(3)" startWordPosition="831" endWordPosition="831">d to an enhancement of syntactic parsing; to a limited extent, the syntactic parser will permit some discrimination, e.g. of transitive and intransitive verbs or verbs which use particles. Further procedures for developing semantic representations are described using the intransitive senses of the verb &amp;quot;change ° as examples. Procedures are described for (1) using definitions of prepositions for identifying semantic cases which will operate as slots in the semantic representation, (2) showing how selectional restrictions on what can fill such slots are derived from the definitional matter, and (3) identifying semantic components that are present within a definition. It is pointed out how it will eventually be necessary that these representations be given in terms of primitives. Procedures are described for building discrimination nets from the results of parsing the definitions and for adding to these nets how the parser should be driven. The emphasis of this paper is in describing procedures that have been developed thus far. Finally, it is shown how these procedures are used to identify explicit derivational relationships present within a dictionary in order to move toward identifica</context>
</contexts>
<marker>3.</marker>
<rawString>Olney,J. and D.Ramsey, &amp;quot;From machinereadable dictionaries to a lexicon tester: Progress, plans, and an offer,&apos; Computer Studies in the Humanities and Verbal Behavior, Vol.3, No.4, November 1972, PP. 213-220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I A Mel•Cuk</author>
</authors>
<title>A new kind of dictionary and its role as a core component of automatic text processing systems,</title>
<date>1978</date>
<journal>T.A. Informations,</journal>
<volume>2</volume>
<pages>3--8</pages>
<marker>4.</marker>
<rawString>Mel•Cuk,I.A., &apos;A new kind of dictionary and its role as a core component of automatic text processing systems, T.A. Informations, 1978, No.2, PP.3-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R N Smith</author>
</authors>
<title>Interactive lexicon updating,&apos; Computers and the Humanities,</title>
<date>1972</date>
<pages>137--145</pages>
<location>Vol.6, No.3,</location>
<marker>5.</marker>
<rawString>Smith,R.N., &amp;quot;Interactive lexicon updating,&apos; Computers and the Humanities, Vol.6, No.3, January 1972, pp. 137-145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R F Simmons</author>
<author>R A Amsler</author>
</authors>
<date></date>
<institution>Modeling Dictionary Data, Computer Science Department, University of Texas,</institution>
<location>Austin,</location>
<marker>6.</marker>
<rawString>Simmons,R.F. and R.A.Amsler, Modeling Dictionary Data, Computer Science Department, University of Texas, Austin, April</rawString>
</citation>
<citation valid="true">
<authors>
<author>R F Simmons</author>
<author>W P Lehmann</author>
</authors>
<title>A Proposal to Develop a Computational Methodology for Deriving Natural Language Semantic Structures via Analysis of Machine-Readable Dictionaries,</title>
<date>1976</date>
<location>University of Texas, Austin,</location>
<marker>7.</marker>
<rawString>Simmons,R.F. and W.P.Lehmann, A Proposal to Develop a Computational Methodology for Deriving Natural Language Semantic Structures via Analysis of Machine-Readable Dictionaries, University of Texas, Austin, 1976 (Research proposal submitted to the National Science Foundation, Sept.28,1976).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Rieger</author>
</authors>
<title>Viewing Parsing as Word Sense Discrimination,</title>
<date>1977</date>
<tech>TR-511,</tech>
<institution>Department of Computer Science, University of Maryland, College Park,</institution>
<location>Maryland,</location>
<marker>8.</marker>
<rawString>Rieger,C., Viewing Parsing as Word Sense Discrimination, TR-511, Department of Computer Science, University of Maryland, College Park, Maryland, January 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Rieger</author>
<author>Word S Small</author>
</authors>
<title>Expert Parsing,</title>
<date>1979</date>
<tech>TR-734,</tech>
<institution>Department of Computer Science, University of Maryland, College Park,</institution>
<location>Maryland,</location>
<marker>9.</marker>
<rawString>Rieger,C. and S.Small, Word Expert Parsing, TR-734, Department of Computer Science, University of Maryland, College Park, Maryland, March 1979.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>