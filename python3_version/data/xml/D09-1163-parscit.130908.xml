<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000206">
<title confidence="0.974927">
Latent Document Re-Ranking
</title>
<author confidence="0.999071">
Dong Zhou1,2 Vincent Wade1
</author>
<affiliation confidence="0.865044666666667">
1. University of Dublin, Trinity College, Dublin 2, Ireland
2. School of Computer and Communication, Hunan University, Changsha,
Hunan, China
</affiliation>
<email confidence="0.985483">
dongzhou1979@hotmail.com Vincent.Wade@cs.tcd.ie
</email>
<sectionHeader confidence="0.998459" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99948724">
The problem of re-ranking initial retrieval re-
sults exploring the intrinsic structure of docu-
ments is widely researched in information re-
trieval (IR) and has attracted a considerable
amount of time and study. However, one of
the drawbacks is that those algorithms treat
queries and documents separately. Further-
more, most of the approaches are predomi-
nantly built upon graph-based methods, which
may ignore some hidden information among
the retrieval set.
This paper proposes a novel document re-
ranking method based on Latent Dirichlet Al-
location (LDA) which exploits the implicit
structure of the documents with respect to
original queries. Rather than relying on graph-
based techniques to identify the internal struc-
ture, the approach tries to find the latent struc-
ture of “topics” or “concepts” in the initial re-
trieval set. Then we compute the distance be-
tween queries and initial retrieval results based
on latent semantic information deduced. Em-
pirical results demonstrate that the method can
comfortably achieve significant improvement
over various baseline systems.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999846196078431">
Consider a traditional IR problem, where there
exists a set of documents llD in the collection. In
response to an information need (as expressed in
a query q), the system determines a best fit be-
tween the query and the documents and returns a
list of retrieval results, sorted in a decreasing or-
der of their relevancy. In practice, high precision
at the top rankings of the returned results is of
particular interest. Generally, there are two ways
to automatically assist in achieving this ultimate
goal after an initial retrieval process (Baeza-
Yates and Ribeiro-Neto, 1999): document re-
ranking and query expansion/re-weighting. Since
the latter normally need a second round of re-
trieval process, our method focuses on the docu-
ment re-ranking approach. We will focus on ad-
justing the ranking positions directly over initial
retrieval results set llDinit .
Recently, there is a trend of exploring the hid-
den structure of documents to re-rank results.
Some of the approaches represent the document
entities as a connected graph G. It is usually con-
structed by links inferred from the content in-
formation as a nearest-neighbor graph. For ex-
ample, Zhang et al. (2005) proposed an affinity
ranking graph to re-rank search results by opti-
mizing diversity and information richness. Kur-
land and Lee (2005) introduced a structural re-
ranking approach by exploiting asymmetric rela-
tionships between documents induced by lan-
guage models. Diaz (2005); Deng et al. (2009)
use a family of semi-supervised machine learn-
ing methods among documents graph con-
structed by incorporating different evidences.
However in this work we are more interested in
adopting an automatic approach.
There are two important factors that should be
taken into account when designing any re-
ranking algorithms: the original queries and ini-
tial retrieval scores. One of issues is that pre-
vious structural re-ranking algorithms treat the
query and the content individually when compu-
ting re-ranking scores. Each document is as-
signed a score independent of other documents
without considering of queries. The problem we
want to address in this paper is how we can leve-
rage the interconnections between query and
documents for the re-ranking purpose.
Another problem with such approaches con-
cerns the fundamental re-ranking strategy they
adopted. HITS (Kleinberg, 1999) and PageRank
</bodyText>
<page confidence="0.934044">
1571
</page>
<note confidence="0.996679">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1571–1580,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.997480017857143">
(Brin and Page, 1998) style algorithms were
widely used in the past. However, approaches
depend only on the structure of the global graph
or sub-graph may ignore important information
content of a document entity. As pointed out by
Deng et al. (2009), re-ranking algorithms that
rely only on the structure of the global graph are
likely lead to the problem of topic drift.
Instead, we introduce a new document re-
ranking method based on Latent Dirichlet Allo-
cation (LDA) (Blei et al., 2003) which exploits
implicit structure of the documents with respect
to original queries. Rather than relying on graph-
based techniques to identify the internal struc-
ture, the approach tries to directly model the la-
tent structure of “topics” or “concepts” in the
initial retrieval set. Then we can compute the
distance between queries and initial retrieval re-
sults based on latent semantic information in-
ferred. To prevent the problem of topic drift, the
generative probability of a document is summed
over all topics induced. By combining the initial
retrieval scores calculated by language models,
we are able to gather important information for
re-ranking purposes. The intuition behind this
method is the hidden structural information
among the documents: similar documents are
likely to have the same hidden information with
respect to a query. In other words, if a group of
documents are talking about the same topic
which shares a strong similarity with a query, in
our method they will get allocated similar rank-
ing as they are more likely to be relevant to the
query. In addition, the refined ranking scores
should be relevant to the initial ranking scores,
which, in our method, are combined together
with the re-ranking score either using a linear
fashion or multiplication process.
To illustrate the effectiveness of the proposed
methodology, we apply the framework to ad-hoc
document retrieval and compare it with the initial
language model-based method and other three
PageRank style re-ranking methods. Experimen-
tal results show that the improvement brought by
our method is consistent and promising.
The rest of the paper is organized as follows.
Related work on re-ranking algorithms and LDA
based methods is briefly summarized in Section
2. Section 3 describes the re-ranking framework
based on latent information induced together
with details of how to build generative model. In
Section 4 we report on a series of experiments
performed over three different test collections in
English and French as well as results obtained.
Finally, Section 5 concludes the paper and specu-
lates on future work.
</bodyText>
<sectionHeader confidence="0.998937" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99998448">
There exist several groups of related work in the
areas of document retrieval and re-ranking.
The first category performs re-ranking by us-
ing inter-document relationship (Lee et al.,
2001), evidences obtained from external re-
sources (Kamps, 2004), or through local context
analysis (Xu and Croft, 2000). In the past, docu-
ment distances (Balinski and Daniowicz, 2005),
manually built external thesaurus (Qu et al.,
2001), and structural information (such as docu-
ment title) (Luk and Wong, 2004), etc have been
used extensively for this very purpose.
A second category of work is related to recent
advances in structural re-ranking paradigm over
graphs. Kurland and Lee performed re-ranking
based on measures of centrality in the graph
formed by generation links induced by language
model scores, through a weighted version of Pa-
geRank algorithm (Kurland and Lee, 2005) and
HITS-style cluster-based approach (Kurland and
Lee, 2006). Zhang et al. (2005) proposed a simi-
lar method to improve web search based on a
linear combination of results from text search
and authority ranking. The graph, which they
named affinity graph, shares strong similarities
with Kurland and Lee’s work with the links in-
duced by a modified version of cosine similarity
using the vector space model. Diaz (2005) used
score regularization to adjust document retrieval
rankings from an initial retrieval by a semi-
supervised learning method. Deng et al. (2009)
further developed this method. They built a latent
space graph based on content and explicit links
information. Unlike their approach we are trying
to model the latent information directly.
This work is also related to a family of me-
thods so called latent semantic analysis (LSA)
(Landauer et al., 1998), especially topic models
used for document representation. Latent Dirich-
let Allocation (LDA), after it was first introduced
by Blei et al. (2003), has quickly become one of
the most popular probabilistic text modeling
techniques and has inspired research ranging
from text classification and clustering (Phan et
al., 2008), information discovery (Mei et al.,
2007; Titov and McDonald, 2008) to information
retrieval (Wei and Croft, 2006). In this model,
each topic is represented by a set of words and
each word corresponds with a weight to measure
its contribution to the topic. Wei and Croft
</bodyText>
<page confidence="0.989055">
1572
</page>
<bodyText confidence="0.999863172413793">
(2006) described large-scale information retriev-
al experiments by using LDA. In their work,
LDA-based document model and language mod-
el-based document model were linearly com-
bined to rank the entire corpus. However, unlike
this approach we only apply LDA to a small set
of documents. There are two reasons by doing
so. One is the concern of computational cost.
LDA is a very complex model and the complexi-
ty will grow linearly with the number of topics
and the number of documents. Only running it
through a document set significantly smaller than
the whole corpus has obvious advantages. Se-
condly, it is well known that LSA-based method
suffers from an incremental build problem. Nor-
mally adding new documents to the corpus needs
to “be folded in” to the latent representation.
Such incremental addition fails to capture the co-
occurrences of the newly added documents (and
even ignores all new terms they contain). As
such, the quality of the LSA representation will
degrade as more documents are added and will
eventually require a re-computation of the LSA
representation. Because our method only requires
running LDA once for a small number of docu-
ments, this problems could be easily avoided. In
addition, we also introduce two new measures to
calculate the distance between a query and a
document.
</bodyText>
<sectionHeader confidence="0.911342" genericHeader="method">
3 Latent Re-Ranking Framework
</sectionHeader>
<bodyText confidence="0.9997742">
In this section, we describe a novel document re-
ranking method based on extracting the latent
structure among the initial retrieval set and mea-
suring the distance between queries and docu-
ments.
</bodyText>
<subsectionHeader confidence="0.999041">
3.1 Problem Definition
</subsectionHeader>
<bodyText confidence="0.999974222222222">
Let 𝔻 = {𝑑1, 𝑑2, . .., 𝑑𝑛} denote the set of docu-
ments to be retrieved. Given a query 𝑞, a set of
initial results 𝔻𝑖𝑛𝑖𝑡 ∈ 𝔻 of top documents are
returned by a standard information retrieval
model (initial ranker). However, the initial ranker
tends to be imperfect. The purpose of our re-
ranking method is to re-order a set of documents
𝔻𝑖𝑛𝑖𝑡 so as to improve retrieval accuracy at the
very top ranks of the final results.
</bodyText>
<subsectionHeader confidence="0.999652">
3.2 Latent Dirichlet Allocation
</subsectionHeader>
<bodyText confidence="0.999594095238095">
We will first introduce Latent Dirichlet Alloca-
tion model which forms the basis of the re-
ranking framework that will be detailed in the
next subsection. It was previously shown that co-
occurrence structure of terms in text documents
can be used to recover some latent topic struc-
tures without any usage of background informa-
tion (Landauer et al., 1998). This means that la-
tent-topic representations of text allow modeling
of linguistic phenomena such as synonymy and
polysemy. By doing so, information retrieval
systems can match the information needs with
content items on a meaning level rather than by
just lexical congruence.
The basic generative process of LDA closely
resembles PLSA (Hofmann, 1999). LDA extends
PLSA method by defining a complete generative
model of text. The topic mixture is drawn from a
conjugate Dirichlet prior that remains the same
for all documents. The process of generating a
document corpus is as follows:
</bodyText>
<listItem confidence="0.8863485">
1) Pick a multinomial distribution 𝜑 𝑧 for
each topic 𝑘 from a Dirichlet distribu-
</listItem>
<bodyText confidence="0.941377794117647">
tion with hyperparameter 𝛽 .
2) For each document 𝑑, pick a multi-
nomial distribution 𝜃 𝑑, from a Dirich-
let distribution with hyperparameter
𝛼 .
3) For each word token 𝑤 in document
𝑑, pick a topic 𝑧 ∈ {1 ... 𝑘} from the
multinomial distribution 𝜃 𝑑.
4) Pick word 𝑤 from the multinomial
distribution 𝜑 𝑧.
Thus, the likelihood of generating a corpus is:
𝑝 𝑑1, ... , 𝑑𝑛 |𝛼 , 𝛽
𝑛 𝑘
= 𝑝(𝜃 𝑑|𝛼 ) ∙ 𝑝( 𝜑 𝑧 |𝛽)
𝑑=1 𝑧=1
𝑁𝑑 𝑘
∙ 𝑝 𝑧𝑖 𝜃 𝑑 𝑝(𝑤𝑖 |𝑧, 𝜑 𝑧) 𝑑𝜃 𝑑 𝑑𝜑 𝑧
𝑖=1 𝑧𝑖 =1
Unlike PLSA model, LDA possesses fully
consistent generative semantics by treating the
topic mixture distribution as a 𝑘-parameter hid-
den random variable. LDA offers a new and in-
teresting framework to model a set of documents.
The documents and new text sequences (for ex-
ample, queries) could be easily connected by
“mapping” them to the topics in the corpus. In
the next subsection we will introduce how to
achieve this goal and apply it to document re-
ranking.
LDA is a complex model and cannot be solved
by exact inference. There are a few approximate
inference techniques available in the literature:
variational methods (Blei et al., 2003), expecta-
tion propagation (Griffiths and Steyvers, 2004)
</bodyText>
<page confidence="0.940178">
1573
</page>
<bodyText confidence="0.999875666666667">
and Gibbs sampling (Griffiths and Steyvers,
2004). Gibbs sampling is a special case of Mar-
kov-Chain Monte Carlo (MCMC) simulation and
often yields relatively simple algorithms. For this
reason, we choose to use Gibbs sampling to es-
timate LDA.
According to Gibbs sampling, we need to
compute the conditional probability 𝑝(𝑧𝑖 |𝑧 .𝑖, 𝑤 ),
where 𝑤 denotes the vector of all words and 𝑧 .𝑖
denotes the vector of topic assignment except the
considered word at position 𝑖 . This probability
distribution can be derived as:
</bodyText>
<equation confidence="0.9954999">
wi
𝑛 +/�
z,.𝑖 flwi
( 𝑛𝑧𝑣 + 𝛽𝑣) − 1
𝑉
𝑣=1
𝑛𝑑𝑖,.𝑖 𝑧+ 𝛼𝑘
∙
( 𝑘 𝑧
𝑧=1 𝑛𝑑𝑖 + 𝛼𝑧) − 1
</equation>
<bodyText confidence="0.997373111111111">
where 𝑛𝑧,.𝑖
𝑡 indicates the number of instances of
word 𝑤𝑖 assigned to topic 𝑧 = 𝑘, not including
the current token and 𝑛𝑑𝑖,.𝑖
𝑧 denotes the number
of words in document 𝑑𝑖 assigned to topic 𝑧 = 𝑘,
not including the current token.
Then we can obtain the multinomial parameter
sets:
</bodyText>
<equation confidence="0.98163">
𝑘
𝑛𝑑𝑖 + 𝛼𝑘
𝑘 𝑛𝑑𝑖
𝑧 + 𝛼𝑧
𝑧=1
</equation>
<bodyText confidence="0.9999166">
The Gibbs sampling algorithm runs over three
periods: initialization, burn-in and sampling. We
do not tune to optimize these parameters because
in our experiments the markov chain turns out to
converge very quickly.
</bodyText>
<subsectionHeader confidence="0.999442">
3.3 LDA-based Re-Ranking
</subsectionHeader>
<bodyText confidence="0.986124066666667">
Armed with this LDA methodology, we now
describe the main idea of our re-ranking method.
Given a set of initial results 𝔻𝑖𝑛𝑖𝑡 , we are trying
to re-measure the distance between the query and
a document. In the vector space model, this dis-
tance is normally the cosine or inner product
measure between two vectors. Under the proba-
bilistic model framework, this distance can be
obtained from a non-commutative measure of the
difference between two probability distributions.
The distance used in our approach is the Kull-
back-Leibler (KL) divergence (Kullback and
Leibler, 1951). Given two probability mass func-
tion 𝑝 𝑥 and 𝑞 (𝑥), the KL divergence (or rela-
tive entropy) between 𝑝 and 𝑞 is defined as:
𝐷(𝑝 |𝑞 = 𝑝 𝑥 𝑙𝑜𝑔
In terms of text sequences (either queries or
documents), the probability distribution can be
regarded as a probabilistic language model 𝑀𝑑
or 𝑀𝑞 from each document 𝑑 or each query 𝑞. In
other words, it assumes that there is an underly-
ing language model which “generates” a term
(sequence) (Ponte and Croft, 1998). The unigram
language model is utilized here. There are sever-
al ways to estimate the probabilities. Let
𝑔 (𝑤 ∈ 𝑑) denotes the number of times the term
𝑤 occurs in a document 𝑑 (same idea can be
used on a query). The Maximum-likelihood es-
timation (MLE) of 𝑤 with respect to 𝑑 is defined
as:
</bodyText>
<equation confidence="0.81786">
𝑀𝐿𝐸𝑑𝑤 ≝ 𝑤 ′ 𝑔 (𝑤′ ∈ 𝑑)
</equation>
<bodyText confidence="0.9686025">
Previous work in language-model-based in-
formation retrieval (Zhai and Lafferty, 2004)
advocates the use of a Dirichlet-smoothed esti-
mation:
</bodyText>
<equation confidence="0.638898">
𝐷𝐼𝑅𝑑𝑤 ≝ 𝑤′ 𝑔(𝑤′ ∈ 𝑑) + 𝜇
</equation>
<bodyText confidence="0.9994199">
where smoothing parameter 𝜇 controls the de-
gree of reliance on relative frequencies in the
document corpus rather than on the counts in 𝑑.
The initial ranker that we choose to use later in
the experiment computes the KL divergence be-
tween the 𝑀𝐿𝐸𝑞 𝑤 and a modified version of
𝐷𝐼𝑅𝑑 𝑤 (Zhai and Lafferty, 2001).
Both estimations can be easily extended to dis-
tributions over text sequences by assuming that
the terms are independent:
</bodyText>
<table confidence="0.925422666666667">
𝑛
𝑀𝐿𝐸𝑑 (𝑤1 𝑤2 ... 𝑤𝑛) ≝ 𝑀𝐿𝐸𝑑 (𝑤𝑗 )
𝑗=1
𝑛
𝐷𝐼𝑅𝑑 (𝑤1 𝑤2 ... 𝑤𝑛) ≝ 𝐷𝐼𝑅𝑑 (𝑤𝑗 )
𝑗=1
</table>
<bodyText confidence="0.974746428571429">
In the re-ranking setting, we estimate that the
probability of a document 𝑑 generates 𝑤, using a
mixture model LDA. It uses a convex combina-
tion of a set of component distributions to model
observations. In this model, a word 𝑤 is gener-
ated from a convex combination of some hidden
topics 𝑧:
</bodyText>
<equation confidence="0.944977">
𝑘
𝐿𝐷𝐴𝑑 𝑤 = 𝑝 𝑤 𝑧 𝑝(𝑧|𝑑)
𝑧=1
</equation>
<bodyText confidence="0.9997422">
where each mixture model 𝑝 (𝑤 |𝑧) is a multi-
nomial distribution over terms that correspond to
one of the latent topics 𝑧. Similar to MLE and
DIR estimations, this could be generated to give
a distribution on a sequence of text:
</bodyText>
<equation confidence="0.997451454545455">
𝑛𝑘 𝑤𝑖 + 𝛽𝑤𝑖
𝑣=1
𝑉 𝑛𝑧𝑣 +
𝛽𝑣
𝑝 𝑧𝑖 𝑧 .𝑖,𝑤 =
𝜃𝑑𝑖,𝑘 =
𝜑𝑘,𝑤𝑖 =
𝑝(𝑥)
𝑞 (𝑥)
𝑔(𝑤∈ 𝑑)
𝑔 𝑤 ∈ 𝑑 + 𝜇 ∙ 𝑀𝐿𝐸𝑤 𝔻
</equation>
<page confidence="0.939976">
1574
</page>
<table confidence="0.999339428571429">
Collection Contents Language Num of docs Size Queries
BL British Library English 1,000,100 1.2 GB 50
(CLEF2008) Data (Main)
BNF Bibliothèque Na- French (Main) 1,000,100 1.3 GB 50
(CLEF2008) tionale de France
LAT Los Angeles English 135,153 434 MB 50
(CLEF2007) Times 2002
</table>
<tableCaption confidence="0.99972">
Table 1. Statistics of test collections
</tableCaption>
<equation confidence="0.366448">
𝐿𝐷𝐴𝑑 (𝑤1𝑤2 ... 𝑤𝑛) ≝ 𝑗𝑛 =1 𝐿𝐷𝐴𝑑 (𝑤𝑗 )
</equation>
<bodyText confidence="0.998418">
Then the distance between a query and a doc-
ument based on this model can be obtained. The
first method we propose here adopts the KL di-
vergence between the query terms and document
terms to compute a Re-Rank score 𝑅𝑆𝐿𝐷𝐴
</bodyText>
<equation confidence="0.982319">
𝐾𝐿1:
𝑅𝑆𝐿𝐷𝐴
𝐾𝐿1 = −𝐷 (𝑀𝐿𝐸𝑞 (∙)||𝐿𝐷𝐴𝑑 ∙ )
</equation>
<bodyText confidence="0.999620923076923">
This method also has the property of length-
normalization to ameliorate long document bias
problems (Kurland and Lee, 2005).
The second method also measures a KL diver-
gence between a query and a document, however,
in a different way. As in the original LDA model,
the multinomial parameter 𝜃 𝑑 indicates the topic
distribution of a document 𝑑. Query 𝑞 can be
considered as topic estimation of a unknown
document 𝑤 . Thus by first randomly assigning
topics to words and then performing a number of
loops through the Gibbs sampling update, we
have:
</bodyText>
<equation confidence="0.994992166666667">
𝑝 𝑧𝑖 𝑧 ¬𝑖, 𝑤 ; 𝑧 ¬𝑖, 𝑤
𝑛𝑧,¬𝑖
𝑤𝑖 + 𝑛 𝑧,¬𝑖
𝑤𝑖 + 𝛽𝑤𝑖
(𝑛𝑧𝑣 + 𝑛 𝑧𝑣 + 𝛽𝑣) − 1
𝑉
𝑣=1
𝑛𝑑 𝑖,¬𝑖 𝑧+ 𝛼𝑘
∙
( 𝑛𝑑 𝑖
𝑘 𝑧 + 𝛼𝑧) − 1
𝑧=1
</equation>
<bodyText confidence="0.9960896">
where 𝑛 𝑧,¬𝑖
𝑤𝑖 counts the observations of word 𝑤𝑖
and topic 𝑘 in unseen document. Then the topic
distribution for the query (just the unseen docu-
ment 𝑑 𝑖) is:
</bodyText>
<equation confidence="0.99267725">
𝑛𝑑 𝑖 𝑘+ 𝛼𝑘
𝑘 𝑛𝑑 𝑖
𝑧 + 𝛼𝑧
𝑧=1
</equation>
<bodyText confidence="0.9999685">
so that the distance between a query 𝑞 and a doc-
ument 𝑑 is defined as the KL divergence be-
tween the topic distributions of 𝑞 and 𝑑. Then
the re-ranking score is calculated as:
</bodyText>
<equation confidence="0.959266">
𝑅𝑆𝐿𝐷𝐴
𝐾𝐿2 = −𝐷 (𝜃 𝑞||𝜃 𝑑 )
</equation>
<bodyText confidence="0.9999224">
Thus we can re-rank the initial retrieved docu-
ments according to the scores acquired. However,
as in other topic models, a topic in the LDA
model represents a combination of words, and it
may not be as precise a representation as words
in language model. Hence we need to further
consider how to combine initial retrieval scores
with the re-ranking scores calculated. Two com-
bination methods will be presented in the next
subsection.
</bodyText>
<subsectionHeader confidence="0.974192">
3.4 Combining Initial Retrieval Scores
</subsectionHeader>
<bodyText confidence="0.997988833333333">
Motivated by the significant improvement ob-
tained by (Wei and Croft, 2006) and (Zhang et
al., 2005), we formulate our method through a
linear combination of the re-ranking scores based
on initial ranker and the latent document re-
ranker, shown as follow:
</bodyText>
<equation confidence="0.9587595">
𝑅𝑆1 = (1 − 𝜆) ∙ 𝑂𝑆 + 𝜆 ∙ 𝑅𝑆𝐿𝐷𝐴
𝐾𝐿∙
</equation>
<bodyText confidence="0.999958714285714">
where 𝑂𝑆 denotes original scores returned by the
initial ranker and 𝜆 is a parameter that can be
tuned with 𝜆 = 0 meaning no re-ranking is per-
formed.
Another scheme considers a multiplication
combination to incorporate the original score. It
does not need to tune any parameters:
</bodyText>
<equation confidence="0.9158895">
𝑅𝑆2 = 𝑂𝑆 ∙ 𝑅𝑆𝐿𝐷𝐴
𝐾𝐿∙
</equation>
<bodyText confidence="0.999524">
This concludes our overview of the proposed
latent re-ranking method.
</bodyText>
<sectionHeader confidence="0.999175" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999921333333333">
In this section, we will empirically study the
effectiveness of the latent document re-ranking
method over three different data collections.
</bodyText>
<subsectionHeader confidence="0.978707">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999514">
Data The text corpus used in our experiment
was made up from elements of the CLEF-2007
and CLEF-2008 the European Library (TEL)
collections1 written in English and French. These
collections are described in greater detail in Ta-
ble 1. All of the documents in the experiment
were indexed using the Lemur toolkit2. Prior to
</bodyText>
<footnote confidence="0.993963">
1 http://www.clef-campaign.org
2 http://www.lemurproject.org
</footnote>
<equation confidence="0.571283">
𝜃𝑑 𝑖,𝑘 =
</equation>
<page confidence="0.932642">
1575
</page>
<bodyText confidence="0.999953901960784">
indexing, Porter&apos;s stemmer and a stopword list3
were used for the English documents. We use a
French analyzer4 to analyze French documents.
It is worth noting that the CLEF-2008 TEL
data is actually multilingual: all collections to a
greater or lesser extent contain records pointing
to documents in other languages. However this is
not a major problem because the majority of
documents in the test collection are written in
main languages of those test collections (BL-
English, BNF-French). Furthermore, documents
written in different languages tend not to match
the queries in main languages. Also the data is
very different from the newspaper articles and
news agency dispatches previously used in the
CLEF as well as TREC5. The data tends to be
very sparse. Many records contain only title, au-
thor and subject heading information; other
records provide more detail. The average docu-
ment lengths are 14.66 for BL and 24.19 for
BNF collections after pre-processing, respective-
ly. Please refer to (Agirre et al., 2008) for a more
detailed discussion about this data. The reason
we choose these data collections is that we
wanted to test the scalability of the proposed me-
thod in different settings and over different
guages. In addition we also select a more
tional collection (LAT from CLEF2007) as a test
base.
We also used the CLEF-2007 and CLEF-
2008 query sets. The query sets consist of 50
topics in English for LAT, BL and in French for
BNF, all of which were used in the experiment.
Each topic is composed of several parts such as:
Title, Description, Narrative. We chose to
conduct Title+Description runs as queries. The
queries are processed similarly to the treatment
in the test collections. The relevance judgments
are taken from the judged pool of top retrieved
documents by various participating retrieval
systems from previous CLEF workshops.
We compare the proposed latent re-ranking
method with four other approaches: the initial
ranker, mentioned above, is a KL-divergence
retrieval function using the language models.
Three other baseline systems are: Kurland and
Lee’s structural re-ranking approach (Recursive
Weighted Influx + Language Model), chosen as
it demonstrates the best performance in their pa-
per (Kurland and Lee, 2005), Zhang et al.’s af-
finity graph-based approach (Zhang et al., 2005)
</bodyText>
<footnote confidence="0.988041">
3 ftp://ftp.cs.cornell.edu/pub/smart/
4 http://lucene.apache.org/
5 http://trec.nist.gov/
</footnote>
<bodyText confidence="0.997184857142857">
and a variant of Kurland and Lee’s work with
links in the graph calculated by the vector-space
model (cosine similarity as mentioned in (Kur-
land and Lee, 2005)). We denote these four sys-
tems as InR, RWILM, AFF, and VEC respective-
ly. Furthermore, we denote the permutations of
our methods as follows: LDA1: RS2 with RS���
</bodyText>
<equation confidence="0.989636166666667">
��1,
LDA2: RS1 with RS���
��1 , LDA3:
RS2 with RS���
��2, LDA4: RS1 with RS���
��2.
</equation>
<bodyText confidence="0.999496133333333">
Because the inconsistency of the evaluation
metrics employed in the past work, we choose to
employ all of them to measure the effectiveness
of various approaches. These include: mean av-
erage precision (MAP), the precision of the top 5
documents (Prec@5), the precision of the top 10
documents (Prec@10), normalized discounted
cumulative gain (NDCG) (Jarvelin and Kekalai-
nen, 2002) and Bpref (Buckley and Voorhees,
2004). Statistical-significant differences in per-
formance were determined using a paired t-test at
a confidence level of 95%.
It is worth pointing out that the above meas-
urements are not directly comparable with those
of the CLEF participants because we restricted
our initial pool to a smaller number of documents
and the main purpose in the paper is to compare
the proposed method with different baseline sys-
tems.
Parameter Two primary parameters need to
be determined in our experiments. For the re-
ranking experiments, the combination parameter
A must be defined. For the LDA estimation, the
number of topics k must be specified. We opti-
mized settings for these parameters with respect
to MAP, not with all other metrics over the BL
collection and apply them to all three collections
directly.
The search ranges for these two parameters
were:
</bodyText>
<equation confidence="0.9792485">
 : 0.1, 0.2, ..., 0.9
k : 5, 10, 15, ..., 45
</equation>
<bodyText confidence="0.99988525">
As it turned out, for many instances, the optim-
al value of A with respect to MAP was either 0.1
or 0.2, suggesting the initial retrieval scores have
valuable information inside them. In contrast, the
optimal value of k was between 20 and 40. Al-
though this demonstrates a relatively large va-
riance, the differences in terms of MAP have
remained small and statistically insignificant. We
set llDinit to 50 in all results reported, as in Kur-
land and Lee’s paper (Kurland and Lee, 2005)
and we later show that the performance turns out
to be very stable when this set enlarged.
</bodyText>
<page confidence="0.969811">
1576
</page>
<table confidence="0.9888891875">
BL
MAP Prec@5 Prec@10 NDCG Bpref
InR 0.1913 0.52 0.452 0.3489 0.2287
RWILM 0.2152 0.532 0.468 0.3663 0.2242
AFF 0.1737 0.444 0.434 0.3273 0.22
0.1756 0.448 0.434 0.3258 0.2216
LDA1 0.21 o, a, v 0.544 a, v 0.47 0.3679 o, a, v 0.2429 a, v
LDA2
LDA3 0.1673 0.452 0.402 0.3297 0.2
LDA4 0.2035 o, a, v 0.548 a, v 0.468 a, v 0.3626 o, a, v 0.2326 a
VEC BNF
MAP Prec@5 Prec@10 NDCG bpref
InR 0.1266 0.268 0.216 0.2456 0.1482
RWILM 0.2148 o, a, v 0.58 o, a, v 0.5 o, a, v 0.3726 o, a, v 0.2491 o, l, a, v
0.1274 0.264 0.218 0.2495 0.1498
0.108 0.248 0.21 0.2221 0.1404
VEC 0.1126 0.252 0.214 0.2262 0.1463
LDA1 0.1374 a, v 0.292 a 0.242 0.2544 a, v 0.1617
LDA2 0.1452 o, a, v 0.292 a, v 0.244 a 0.2608 o, a, v 0.1697 o, l, a, v
LDA3 0.1062 0.232 0.202 0.2226 0.1439
LDA4 0.1377 a,v 0.28 a 0.246 o, a, v 0.2507 a, v 0.1672 o, a, v
AFF LAT02
MAP Prec@5 Prec@10 NDCG bpref
InR 0.3119 0.568 0.48 0.5093 0.3105
RWILM 0.3097 0.556 0.478 0.5096 0.3064
AFF 0.3065 0.572 0.492 0.5037 0.312
VEC 0.301 0.536 0.474 0.4975 0.3087
LDA1 0.3253 v 0.584 v 0.502 v 0.5158 v 0.3339 o, l, v
LDA2 0.3271 a, v 0.584 o, v 0.496 0.518 o, v 0.3351 o, l, a, v
LDA3 0.2848 0.444 0.398 0.486 0.2879
LDA4 0.3274 o 0.552 0.478 0.5202 o, v
0.3396 o, l, v
</table>
<tableCaption confidence="0.99231">
Table 2. Experimental Results. For each evaluation setting, improvements over the RWILM baseline
are given in italics (because it has highest performance); statistically significant differences between our
methods and InR, RWILM, AFF, VEC are indicated by o, l, a, v, respectively. Bold highlights the best
results over all algorithms.
</tableCaption>
<bodyText confidence="0.987596666666667">
Lastly, the parameters in the baseline systems
are set according to the tuning procedures in their
original papers6.
</bodyText>
<footnote confidence="0.909458333333333">
6 More specifically, the combination parameter was
set to 0.5 for AFF, the number of links was set to 4 for
RWILM.
</footnote>
<subsectionHeader confidence="0.560109">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.9989896">
Primary Evaluation The main experimental
results are presented in Table 2. The first four
rows in each collection specify reference-
comparison data. The first question we are inter-
ested in is how our latent re-ranking methods
</bodyText>
<page confidence="0.986516">
1577
</page>
<bodyText confidence="0.995261105882353">
perform (taken as a whole). It is shown that our
methods bring improvements upon the various
baselines in 75% of the 48 relevant comparisons
(4 latent re-ranking methods X 4 corpora X 4
baselines). Only the algorithm permutation
LDA3 performs less well. Furthermore, our me-
thods are able to achieve the highest performance
across all the evaluation metrics over three test
collections except in one case (MAP in BL col-
lection). An even more exciting observation is
that in many cases, our methods, even though
tuned for MAP, can outperform various baselines
for all the evaluation metrics, with statistically
significant improvements in many runs.
A closer examination of the results in Table 2
reveals some interesting properties. As expected,
the RWILM method bought improvements in
many cases in CLEF-2008 test collections. How-
ever, the performance over CLEF-2007 collec-
tion was somewhat disappointing. This seems to
indicate that the language model induced graph
method tends to perform better in sparse data
rather than longer documents. Also Language
Modeling requires large set training data to be
effective, while the complexity of our method is
only linear with number of topics and the number
of documents for each iteration. The affinity and
vector graph based methods demonstrated poor
performance across all the collections. This may
be due to the fact that the approach Zhang et al.
(Zhang et al., 2005) developed focuses more on
diversity and information richness and cares less
about the precision of the retrieval results while
asymmetric graph as constructed by the vector
space model fails in capturing important relation-
ship between the documents.
Another observation we can draw from Table
2 is that the relative performance tends to be sta-
ble during test collections written in different
languages. This shows a promising future for
studying structure of the documents with respect
to queries for re-ranking purpose. At the same
time, efficiency is always an issue in all re-
ranking methods. Although this is not a primary
concern in the current work, it would definitely
worth thinking in the future.
We also conducted some experiments over
queries constructed by using Title field only.
This forms some more realistic short queries.
The experiments showed very similar results
compared to longer queries. This demonstrates
that the query length is a trivial issue in our me-
thods (as in other graph-based structural re-
ranking). We examined the best and worse per-
formed queries, their performance are generally
consistent across all the methods. This phenome-
non should be investigated further in the follow
up evaluation.
Comparison of Different Methods In com-
parison of performance between four permuta-
tions of our methods, LDA2 is the clear winner
over CLEF-2008 test collections. The results ob-
tained by LDA2 and LDA4 over CLEF-2007 test
collection were mixed. LDA2 performed better
in precision at top n documents while LDA4
showed promising results in terms of more gen-
eral evaluation metrics. On the other hand, the
linear combination approach performed much
better than multiplication based combination.
The situation is even worse when we adopted the
RS���
��2 method, which was inferior in several
cases. Thus the linear combination should be
highly recommended.
Scalability We have shown that our latent
document re-ranking method is successful at ac-
complishing the goal of improving the results
returned by an initial retrieval engine. But one
may raise a question of whether it is necessary to
restrict our attention to an initial pool llDinit at
such a small size. As it happens, preliminary ex-
periments with LDA2 on larger size of the initial
pool are presented in Figure 1. As we can see,
our method can bring consistently stable im-
provements.
</bodyText>
<figureCaption confidence="0.850285">
Figure 1. Experiments with larger initial pools
</figureCaption>
<sectionHeader confidence="0.993315" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9973036">
In this paper we proposed and evaluated a la-
tent document re-ranking method for re-ordering
the initial retrieval results. The key to refine the
results is finding the latent structure of “topics”
or “concepts” in the document set, which leve-
</bodyText>
<figure confidence="0.970359230769231">
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
MAP (InR) MAP (LDA2) Prec@5 (InR) Prec@5 (LDA2)
Prec@10 (InR) Prec@10 (LDA2) NDCG (InR) NDCG (LDA2)
Bpref (InR) Bpref (LDA2)
50 100 200 300 400 500
Size of the initial retrieval set
</figure>
<page confidence="0.973738">
1578
</page>
<bodyText confidence="0.999952130434783">
rages the latent Dirichlet allocation technique for
the query-dependent ranking problem and results
in state-of-art performance.
There are many research directions we are
planning to investigate. It has been shown that
LDA-based retrieval is a promising method for
ranking the whole corpus. There is a desire to
call for a direct comparison between ranking and
re-ranking using the proposed algorithmic varia-
tions. Future work will also include the compari-
son between our methods with other related ap-
proaches, such as Kurland and Lee’s cluster-
based approach (Kurland and Lee, 2006).
There exist a sufficient number of latent se-
mantic techniques such as singular vector de-
composition, non-negative matrix factorization,
PLSA, etc. We are planning to explore these me-
thods to compare their performance. Also direct
re-ranking can be used to improve automatic
query expansion since better ranking in top re-
trieved documents can be expected to improve
the quality of the augmented query. We believe
this is another fruitful line for future research.
</bodyText>
<sectionHeader confidence="0.997311" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999843714285714">
The authors would like to thank three anonym-
ous reviewers for many constructive comments.
This research is supported by the Science Foun-
dation Ireland (Grant 07/CE/I1142) as part of the
Centre for Next Generation Localisation
(www.cngl.ie) at University of Dublin, Trinity
College.
</bodyText>
<sectionHeader confidence="0.99916" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999914378048781">
Eneko Agirre, Giorgio M. Di Nunzio, Nicola Ferro,
Thomas Mandl and Carol Peters (2008). CLEF
2008: Ad Hoc Track Overview. In Working notes of
CLEF2008.
Ricardo A. Baeza-Yates and Berthier Ribeiro-Neto
(1999). Modern Information Retrieval, Addison-
Wesley Longman Publishing Co., Inc.
Jaroslaw Balinski and Czeslaw Daniowicz (2005).
&amp;quot;Re-ranking method based on inter-document dis-
tances.&amp;quot; Inf. Process. Manage. 41(4): 759-775.
David M. Blei, Andrew Y. Ng and Michael I. Jordan
(2003). &amp;quot;Latent dirichlet allocation.&amp;quot; J. Mach.
Learn. Res. 3: 993-1022.
Sergey Brin and Lawrence Page (1998). &amp;quot;The anato-
my of a large-scale hypertextual Web search en-
gine.&amp;quot; Comput. Netw. ISDN Syst. 30(1-7): 107-117.
Chris Buckley and Ellen M. Voorhees (2004). Re-
trieval evaluation with incomplete information. In
Proceedings of the 27th annual international ACM
SIGIR conference on Research and development in
information retrieval, Sheffield, United Kingdom,
ACM. p. 25-32.
Hongbo Deng, Michael R. Lyu and Irwin King
(2009). Effective latent space graph-based re-
ranking model with global consistency. In Proceed-
ings of the Second ACM International Conference
on Web Search and Data Mining, Barcelona, Spain,
ACM. p. 212-221.
Fernando Diaz (2005). Regularizing ad hoc retrieval
scores. In Proceedings of the 14th ACM interna-
tional conference on Information and knowledge
management, Bremen, Germany, ACM. p. 672-679.
Thomas L. Griffiths and Mark Steyvers (2004). Find-
ing scientific topics. In Proceeding of the National
Academy of Sciences. p. 5228-5235.
Thomas Hofmann (1999). Probabilistic latent seman-
tic indexing. In Proceedings of the 22nd annual in-
ternational ACM SIGIR conference on Research
and development in information retrieval, Berkeley,
California, United States, ACM. p. 50-57.
Kalervo Jarvelin and Jaana Kekalainen (2002). &amp;quot;Cu-
mulated gain-based evaluation of IR techniques.&amp;quot;
ACM Trans. Inf. Syst. 20(4): 422-446.
Jaap Kamps (2004). Improving Retrieval Effective-
ness by Reranking Documents Based on Controlled
Vocabulary In Proceedings of 26th European Con-
ference on IR Research, ECIR 2004, Sunderland,
UK. p. 283-295.
Jon M. Kleinberg (1999). &amp;quot;Authoritative sources in a
hyperlinked environment.&amp;quot; J. ACM 46(5): 604-632.
S. Kullback and R. A. Leibler (1951). &amp;quot;On Informa-
tion and Sufficiency.&amp;quot; The Annals of Mathematical
Statistics 22(1): 79-86.
Oren Kurland and Lillian Lee (2005). PageRank
without hyperlinks: structural re-ranking using links
induced by language models. In Proceedings of the
28th annual international ACM SIGIR conference
on Research and development in information re-
trieval, Salvador, Brazil, ACM. p. 306-313.
Oren Kurland and Lillian Lee (2006). Respect my
authority!: HITS without hyperlinks, utilizing clus-
ter-based language models. In Proceedings of the
29th annual international ACM SIGIR conference
on Research and development in information re-
trieval, Seattle, Washington, USA, ACM. p. 83-90.
Thomas K. Landauer, Peter W. Foltz and Darrell
Laham (1998). &amp;quot;An Introduction to Latent Semantic
Analysis.&amp;quot; Discourse Processes 25: 259-284.
Kyung-Soon Lee, Young-Chan Park and Key-Sun
Choi (2001). &amp;quot;Re-ranking model based on document
clusters.&amp;quot; Inf. Process. Manage. 37(1): 1-14.
Robert W. P. Luk and K.F. Wong (2004). Pseudo-
Relevance Feedback and Title Re-ranking for Chi-
nese Information Retrieval. In Working Notes of the
Fourth NTCIR Workshop Meeting, Tokyo, Japan,
National Institute of Informatics.
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su
and ChengXiang Zhai (2007). Topic sentiment mix-
ture: modeling facets and opinions in weblogs. In
Proceedings of the 16th international conference on
World Wide Web, Banff, Alberta, Canada, ACM. p.
171-180.
</reference>
<page confidence="0.882866">
1579
</page>
<reference confidence="0.99906825">
Xuan-Hieu Phan, Le-Minh Nguyen and Susumu Ho-
riguchi (2008). Learning to classify short and sparse
text \&amp; web with hidden topics from large-scale data
collections. In Proceeding of the 17th international
conference on World Wide Web, Beijing, China,
ACM. p. 91-100.
Jay M. Ponte and W. Bruce Croft (1998). A language
modeling approach to information retrieval. In Pro-
ceedings of the 21st annual international ACM SI-
GIR conference on Research and development in in-
formation retrieval, Melbourne, Australia, ACM. p.
275-281.
Youli Qu, Guowei Xu and Jun Wang (2001). Rerank
Method Based on Individual Thesaurus. In Proceed-
ings of the Second NTCIR Workshop on Research in
Chinese &amp; Japanese Text Retrieval and Text Sum-
marization, Tokyo, Japan, National Institute of In-
formatics.
Ivan Titov and Ryan McDonald (2008). Modeling
online reviews with multi-grain topic models. In
Proceeding of the 17th international conference on
World Wide Web, Beijing, China, ACM. p. 111-120.
Xing Wei and W. Bruce Croft (2006). LDA-based
document models for ad-hoc retrieval. In Proceed-
ings of the 29th annual international ACM SIGIR
conference on Research and development in infor-
mation retrieval, Seattle, Washington, USA, ACM.
p. 178-185.
Jinxi Xu and W. Bruce Croft (2000). &amp;quot;Improving the
effectiveness of information retrieval with local con-
text analysis.&amp;quot; ACM Trans. Inf. Syst. 18(1): 79-112.
Chengxiang Zhai and John Lafferty (2001). Model-
based feedback in the language modeling approach
to information retrieval. In Proceedings of the tenth
international conference on Information and know-
ledge management, Atlanta, Georgia, USA, ACM.
p. 403-410.
Chengxiang Zhai and John Lafferty (2004). &amp;quot;A study
of smoothing methods for language models applied
to information retrieval.&amp;quot; ACM Trans. Inf. Syst.
22(2): 179-214.
Benyu Zhang, Hua Li, Yi Liu, Lei Ji, Wensi Xi, Wei-
guo Fan, Zheng Chen and Wei-Ying Ma (2005).
Improving web search results using affinity graph.
In Proceedings of the 28th annual international
ACM SIGIR conference on Research and develop-
ment in information retrieval, Salvador, Brazil,
ACM. p. 504-511.
</reference>
<page confidence="0.989963">
1580
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.349511">
<title confidence="0.993977">Latent Document Re-Ranking</title>
<author confidence="0.582039">Vincent</author>
<affiliation confidence="0.7507135">1. University of Dublin, Trinity College, Dublin 2, Ireland 2. School of Computer and Communication, Hunan University, Changsha,</affiliation>
<address confidence="0.919178">Hunan, China</address>
<email confidence="0.77557">dongzhou1979@hotmail.comVincent.Wade@cs.tcd.ie</email>
<abstract confidence="0.999843807692308">The problem of re-ranking initial retrieval results exploring the intrinsic structure of documents is widely researched in information retrieval (IR) and has attracted a considerable amount of time and study. However, one of the drawbacks is that those algorithms treat queries and documents separately. Furthermore, most of the approaches are predominantly built upon graph-based methods, which may ignore some hidden information among the retrieval set. This paper proposes a novel document reranking method based on Latent Dirichlet Allocation (LDA) which exploits the implicit structure of the documents with respect to original queries. Rather than relying on graphbased techniques to identify the internal structure, the approach tries to find the latent strucof “topics” or “concepts” in the initial trieval set. Then we compute the distance between queries and initial retrieval results based on latent semantic information deduced. Empirical results demonstrate that the method can comfortably achieve significant improvement over various baseline systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Giorgio M Di Nunzio</author>
<author>Nicola Ferro</author>
</authors>
<title>Thomas Mandl and Carol Peters</title>
<date>2008</date>
<marker>Agirre, Di Nunzio, Ferro, 2008</marker>
<rawString>Eneko Agirre, Giorgio M. Di Nunzio, Nicola Ferro, Thomas Mandl and Carol Peters (2008). CLEF 2008: Ad Hoc Track Overview. In Working notes of CLEF2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ricardo</author>
</authors>
<title>Baeza-Yates and Berthier Ribeiro-Neto</title>
<date>1999</date>
<publisher>AddisonWesley Longman Publishing Co., Inc.</publisher>
<marker>Ricardo, 1999</marker>
<rawString>Ricardo A. Baeza-Yates and Berthier Ribeiro-Neto (1999). Modern Information Retrieval, AddisonWesley Longman Publishing Co., Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaroslaw Balinski</author>
<author>Czeslaw Daniowicz</author>
</authors>
<title>Re-ranking method based on inter-document distances.&amp;quot;</title>
<date>2005</date>
<journal>Inf. Process. Manage.</journal>
<volume>41</volume>
<issue>4</issue>
<pages>759--775</pages>
<contexts>
<context position="6821" citStr="Balinski and Daniowicz, 2005" startWordPosition="1067" endWordPosition="1070">w to build generative model. In Section 4 we report on a series of experiments performed over three different test collections in English and French as well as results obtained. Finally, Section 5 concludes the paper and speculates on future work. 2 Related Work There exist several groups of related work in the areas of document retrieval and re-ranking. The first category performs re-ranking by using inter-document relationship (Lee et al., 2001), evidences obtained from external resources (Kamps, 2004), or through local context analysis (Xu and Croft, 2000). In the past, document distances (Balinski and Daniowicz, 2005), manually built external thesaurus (Qu et al., 2001), and structural information (such as document title) (Luk and Wong, 2004), etc have been used extensively for this very purpose. A second category of work is related to recent advances in structural re-ranking paradigm over graphs. Kurland and Lee performed re-ranking based on measures of centrality in the graph formed by generation links induced by language model scores, through a weighted version of PageRank algorithm (Kurland and Lee, 2005) and HITS-style cluster-based approach (Kurland and Lee, 2006). Zhang et al. (2005) proposed a simi</context>
</contexts>
<marker>Balinski, Daniowicz, 2005</marker>
<rawString>Jaroslaw Balinski and Czeslaw Daniowicz (2005). &amp;quot;Re-ranking method based on inter-document distances.&amp;quot; Inf. Process. Manage. 41(4): 759-775.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>I Michael</author>
</authors>
<title>Latent dirichlet allocation.&amp;quot;</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.</journal>
<volume>3</volume>
<pages>993--1022</pages>
<contexts>
<context position="4330" citStr="Blei et al., 2003" startWordPosition="673" endWordPosition="676">onference on Empirical Methods in Natural Language Processing, pages 1571–1580, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP (Brin and Page, 1998) style algorithms were widely used in the past. However, approaches depend only on the structure of the global graph or sub-graph may ignore important information content of a document entity. As pointed out by Deng et al. (2009), re-ranking algorithms that rely only on the structure of the global graph are likely lead to the problem of topic drift. Instead, we introduce a new document reranking method based on Latent Dirichlet Allocation (LDA) (Blei et al., 2003) which exploits implicit structure of the documents with respect to original queries. Rather than relying on graphbased techniques to identify the internal structure, the approach tries to directly model the latent structure of “topics” or “concepts” in the initial retrieval set. Then we can compute the distance between queries and initial retrieval results based on latent semantic information inferred. To prevent the problem of topic drift, the generative probability of a document is summed over all topics induced. By combining the initial retrieval scores calculated by language models, we ar</context>
<context position="8337" citStr="Blei et al. (2003)" startWordPosition="1308" endWordPosition="1311">ace model. Diaz (2005) used score regularization to adjust document retrieval rankings from an initial retrieval by a semisupervised learning method. Deng et al. (2009) further developed this method. They built a latent space graph based on content and explicit links information. Unlike their approach we are trying to model the latent information directly. This work is also related to a family of methods so called latent semantic analysis (LSA) (Landauer et al., 1998), especially topic models used for document representation. Latent Dirichlet Allocation (LDA), after it was first introduced by Blei et al. (2003), has quickly become one of the most popular probabilistic text modeling techniques and has inspired research ranging from text classification and clustering (Phan et al., 2008), information discovery (Mei et al., 2007; Titov and McDonald, 2008) to information retrieval (Wei and Croft, 2006). In this model, each topic is represented by a set of words and each word corresponds with a weight to measure its contribution to the topic. Wei and Croft 1572 (2006) described large-scale information retrieval experiments by using LDA. In their work, LDA-based document model and language model-based docu</context>
<context position="12918" citStr="Blei et al., 2003" startWordPosition="2100" endWordPosition="2103">ssesses fully consistent generative semantics by treating the topic mixture distribution as a 𝑘-parameter hidden random variable. LDA offers a new and interesting framework to model a set of documents. The documents and new text sequences (for example, queries) could be easily connected by “mapping” them to the topics in the corpus. In the next subsection we will introduce how to achieve this goal and apply it to document reranking. LDA is a complex model and cannot be solved by exact inference. There are a few approximate inference techniques available in the literature: variational methods (Blei et al., 2003), expectation propagation (Griffiths and Steyvers, 2004) 1573 and Gibbs sampling (Griffiths and Steyvers, 2004). Gibbs sampling is a special case of Markov-Chain Monte Carlo (MCMC) simulation and often yields relatively simple algorithms. For this reason, we choose to use Gibbs sampling to estimate LDA. According to Gibbs sampling, we need to compute the conditional probability 𝑝(𝑧𝑖 |𝑧 .𝑖, 𝑤 ), where 𝑤 denotes the vector of all words and 𝑧 .𝑖 denotes the vector of topic assignment except the considered word at position 𝑖 . This probability distribution can be derived as: wi 𝑛 +/� z,.𝑖 flwi ( 𝑛</context>
</contexts>
<marker>Blei, Ng, Michael, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng and Michael I. Jordan (2003). &amp;quot;Latent dirichlet allocation.&amp;quot; J. Mach. Learn. Res. 3: 993-1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The anatomy of a large-scale hypertextual Web search engine.&amp;quot;</title>
<date>1998</date>
<journal>Comput. Netw. ISDN Syst.</journal>
<volume>30</volume>
<issue>1</issue>
<pages>107--117</pages>
<contexts>
<context position="3862" citStr="Brin and Page, 1998" startWordPosition="594" endWordPosition="597">ry and the content individually when computing re-ranking scores. Each document is assigned a score independent of other documents without considering of queries. The problem we want to address in this paper is how we can leverage the interconnections between query and documents for the re-ranking purpose. Another problem with such approaches concerns the fundamental re-ranking strategy they adopted. HITS (Kleinberg, 1999) and PageRank 1571 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1571–1580, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP (Brin and Page, 1998) style algorithms were widely used in the past. However, approaches depend only on the structure of the global graph or sub-graph may ignore important information content of a document entity. As pointed out by Deng et al. (2009), re-ranking algorithms that rely only on the structure of the global graph are likely lead to the problem of topic drift. Instead, we introduce a new document reranking method based on Latent Dirichlet Allocation (LDA) (Blei et al., 2003) which exploits implicit structure of the documents with respect to original queries. Rather than relying on graphbased techniques t</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Lawrence Page (1998). &amp;quot;The anatomy of a large-scale hypertextual Web search engine.&amp;quot; Comput. Netw. ISDN Syst. 30(1-7): 107-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Buckley</author>
<author>Ellen M Voorhees</author>
</authors>
<title>Retrieval evaluation with incomplete information.</title>
<date>2004</date>
<booktitle>In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, Sheffield, United Kingdom, ACM.</booktitle>
<pages>25--32</pages>
<contexts>
<context position="23397" citStr="Buckley and Voorhees, 2004" startWordPosition="3950" endWordPosition="3953">, RWILM, AFF, and VEC respectively. Furthermore, we denote the permutations of our methods as follows: LDA1: RS2 with RS��� ��1, LDA2: RS1 with RS��� ��1 , LDA3: RS2 with RS��� ��2, LDA4: RS1 with RS��� ��2. Because the inconsistency of the evaluation metrics employed in the past work, we choose to employ all of them to measure the effectiveness of various approaches. These include: mean average precision (MAP), the precision of the top 5 documents (Prec@5), the precision of the top 10 documents (Prec@10), normalized discounted cumulative gain (NDCG) (Jarvelin and Kekalainen, 2002) and Bpref (Buckley and Voorhees, 2004). Statistical-significant differences in performance were determined using a paired t-test at a confidence level of 95%. It is worth pointing out that the above measurements are not directly comparable with those of the CLEF participants because we restricted our initial pool to a smaller number of documents and the main purpose in the paper is to compare the proposed method with different baseline systems. Parameter Two primary parameters need to be determined in our experiments. For the reranking experiments, the combination parameter A must be defined. For the LDA estimation, the number of </context>
</contexts>
<marker>Buckley, Voorhees, 2004</marker>
<rawString>Chris Buckley and Ellen M. Voorhees (2004). Retrieval evaluation with incomplete information. In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, Sheffield, United Kingdom, ACM. p. 25-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongbo Deng</author>
<author>Michael R Lyu</author>
<author>Irwin King</author>
</authors>
<title>Effective latent space graph-based reranking model with global consistency.</title>
<date>2009</date>
<booktitle>In Proceedings of the Second ACM International Conference on Web Search and Data Mining,</booktitle>
<pages>212--221</pages>
<location>Barcelona, Spain, ACM.</location>
<contexts>
<context position="2798" citStr="Deng et al. (2009)" startWordPosition="431" endWordPosition="434">ts set llDinit . Recently, there is a trend of exploring the hidden structure of documents to re-rank results. Some of the approaches represent the document entities as a connected graph G. It is usually constructed by links inferred from the content information as a nearest-neighbor graph. For example, Zhang et al. (2005) proposed an affinity ranking graph to re-rank search results by optimizing diversity and information richness. Kurland and Lee (2005) introduced a structural reranking approach by exploiting asymmetric relationships between documents induced by language models. Diaz (2005); Deng et al. (2009) use a family of semi-supervised machine learning methods among documents graph constructed by incorporating different evidences. However in this work we are more interested in adopting an automatic approach. There are two important factors that should be taken into account when designing any reranking algorithms: the original queries and initial retrieval scores. One of issues is that previous structural re-ranking algorithms treat the query and the content individually when computing re-ranking scores. Each document is assigned a score independent of other documents without considering of qu</context>
<context position="4091" citStr="Deng et al. (2009)" startWordPosition="632" endWordPosition="635">the interconnections between query and documents for the re-ranking purpose. Another problem with such approaches concerns the fundamental re-ranking strategy they adopted. HITS (Kleinberg, 1999) and PageRank 1571 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1571–1580, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP (Brin and Page, 1998) style algorithms were widely used in the past. However, approaches depend only on the structure of the global graph or sub-graph may ignore important information content of a document entity. As pointed out by Deng et al. (2009), re-ranking algorithms that rely only on the structure of the global graph are likely lead to the problem of topic drift. Instead, we introduce a new document reranking method based on Latent Dirichlet Allocation (LDA) (Blei et al., 2003) which exploits implicit structure of the documents with respect to original queries. Rather than relying on graphbased techniques to identify the internal structure, the approach tries to directly model the latent structure of “topics” or “concepts” in the initial retrieval set. Then we can compute the distance between queries and initial retrieval results b</context>
<context position="7887" citStr="Deng et al. (2009)" startWordPosition="1236" endWordPosition="1239">version of PageRank algorithm (Kurland and Lee, 2005) and HITS-style cluster-based approach (Kurland and Lee, 2006). Zhang et al. (2005) proposed a similar method to improve web search based on a linear combination of results from text search and authority ranking. The graph, which they named affinity graph, shares strong similarities with Kurland and Lee’s work with the links induced by a modified version of cosine similarity using the vector space model. Diaz (2005) used score regularization to adjust document retrieval rankings from an initial retrieval by a semisupervised learning method. Deng et al. (2009) further developed this method. They built a latent space graph based on content and explicit links information. Unlike their approach we are trying to model the latent information directly. This work is also related to a family of methods so called latent semantic analysis (LSA) (Landauer et al., 1998), especially topic models used for document representation. Latent Dirichlet Allocation (LDA), after it was first introduced by Blei et al. (2003), has quickly become one of the most popular probabilistic text modeling techniques and has inspired research ranging from text classification and clu</context>
</contexts>
<marker>Deng, Lyu, King, 2009</marker>
<rawString>Hongbo Deng, Michael R. Lyu and Irwin King (2009). Effective latent space graph-based reranking model with global consistency. In Proceedings of the Second ACM International Conference on Web Search and Data Mining, Barcelona, Spain, ACM. p. 212-221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Diaz</author>
</authors>
<title>Regularizing ad hoc retrieval scores.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th ACM international conference on Information and knowledge management,</booktitle>
<pages>672--679</pages>
<location>Bremen, Germany, ACM.</location>
<contexts>
<context position="2778" citStr="Diaz (2005)" startWordPosition="429" endWordPosition="430">trieval results set llDinit . Recently, there is a trend of exploring the hidden structure of documents to re-rank results. Some of the approaches represent the document entities as a connected graph G. It is usually constructed by links inferred from the content information as a nearest-neighbor graph. For example, Zhang et al. (2005) proposed an affinity ranking graph to re-rank search results by optimizing diversity and information richness. Kurland and Lee (2005) introduced a structural reranking approach by exploiting asymmetric relationships between documents induced by language models. Diaz (2005); Deng et al. (2009) use a family of semi-supervised machine learning methods among documents graph constructed by incorporating different evidences. However in this work we are more interested in adopting an automatic approach. There are two important factors that should be taken into account when designing any reranking algorithms: the original queries and initial retrieval scores. One of issues is that previous structural re-ranking algorithms treat the query and the content individually when computing re-ranking scores. Each document is assigned a score independent of other documents witho</context>
<context position="7741" citStr="Diaz (2005)" startWordPosition="1216" endWordPosition="1217">ed re-ranking based on measures of centrality in the graph formed by generation links induced by language model scores, through a weighted version of PageRank algorithm (Kurland and Lee, 2005) and HITS-style cluster-based approach (Kurland and Lee, 2006). Zhang et al. (2005) proposed a similar method to improve web search based on a linear combination of results from text search and authority ranking. The graph, which they named affinity graph, shares strong similarities with Kurland and Lee’s work with the links induced by a modified version of cosine similarity using the vector space model. Diaz (2005) used score regularization to adjust document retrieval rankings from an initial retrieval by a semisupervised learning method. Deng et al. (2009) further developed this method. They built a latent space graph based on content and explicit links information. Unlike their approach we are trying to model the latent information directly. This work is also related to a family of methods so called latent semantic analysis (LSA) (Landauer et al., 1998), especially topic models used for document representation. Latent Dirichlet Allocation (LDA), after it was first introduced by Blei et al. (2003), ha</context>
</contexts>
<marker>Diaz, 2005</marker>
<rawString>Fernando Diaz (2005). Regularizing ad hoc retrieval scores. In Proceedings of the 14th ACM international conference on Information and knowledge management, Bremen, Germany, ACM. p. 672-679.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<booktitle>In Proceeding of the National Academy of Sciences.</booktitle>
<pages>5228--5235</pages>
<contexts>
<context position="12974" citStr="Griffiths and Steyvers, 2004" startWordPosition="2107" endWordPosition="2110"> by treating the topic mixture distribution as a 𝑘-parameter hidden random variable. LDA offers a new and interesting framework to model a set of documents. The documents and new text sequences (for example, queries) could be easily connected by “mapping” them to the topics in the corpus. In the next subsection we will introduce how to achieve this goal and apply it to document reranking. LDA is a complex model and cannot be solved by exact inference. There are a few approximate inference techniques available in the literature: variational methods (Blei et al., 2003), expectation propagation (Griffiths and Steyvers, 2004) 1573 and Gibbs sampling (Griffiths and Steyvers, 2004). Gibbs sampling is a special case of Markov-Chain Monte Carlo (MCMC) simulation and often yields relatively simple algorithms. For this reason, we choose to use Gibbs sampling to estimate LDA. According to Gibbs sampling, we need to compute the conditional probability 𝑝(𝑧𝑖 |𝑧 .𝑖, 𝑤 ), where 𝑤 denotes the vector of all words and 𝑧 .𝑖 denotes the vector of topic assignment except the considered word at position 𝑖 . This probability distribution can be derived as: wi 𝑛 +/� z,.𝑖 flwi ( 𝑛𝑧𝑣 + 𝛽𝑣) − 1 𝑉 𝑣=1 𝑛𝑑𝑖,.𝑖 𝑧+ 𝛼𝑘 ∙ ( 𝑘 𝑧 𝑧=1 𝑛𝑑𝑖 + 𝛼𝑧) − </context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Thomas L. Griffiths and Mark Steyvers (2004). Finding scientific topics. In Proceeding of the National Academy of Sciences. p. 5228-5235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>50--57</pages>
<location>Berkeley, California, United States, ACM.</location>
<contexts>
<context position="11498" citStr="Hofmann, 1999" startWordPosition="1835" endWordPosition="1836">ranking framework that will be detailed in the next subsection. It was previously shown that cooccurrence structure of terms in text documents can be used to recover some latent topic structures without any usage of background information (Landauer et al., 1998). This means that latent-topic representations of text allow modeling of linguistic phenomena such as synonymy and polysemy. By doing so, information retrieval systems can match the information needs with content items on a meaning level rather than by just lexical congruence. The basic generative process of LDA closely resembles PLSA (Hofmann, 1999). LDA extends PLSA method by defining a complete generative model of text. The topic mixture is drawn from a conjugate Dirichlet prior that remains the same for all documents. The process of generating a document corpus is as follows: 1) Pick a multinomial distribution 𝜑 𝑧 for each topic 𝑘 from a Dirichlet distribution with hyperparameter 𝛽 . 2) For each document 𝑑, pick a multinomial distribution 𝜃 𝑑, from a Dirichlet distribution with hyperparameter 𝛼 . 3) For each word token 𝑤 in document 𝑑, pick a topic 𝑧 ∈ {1 ... 𝑘} from the multinomial distribution 𝜃 𝑑. 4) Pick word 𝑤 from the multinomia</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann (1999). Probabilistic latent semantic indexing. In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, Berkeley, California, United States, ACM. p. 50-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kalervo Jarvelin</author>
<author>Jaana Kekalainen</author>
</authors>
<title>Cumulated gain-based evaluation of IR techniques.&amp;quot;</title>
<date>2002</date>
<journal>ACM Trans. Inf. Syst.</journal>
<volume>20</volume>
<issue>4</issue>
<pages>422--446</pages>
<contexts>
<context position="23358" citStr="Jarvelin and Kekalainen, 2002" startWordPosition="3943" endWordPosition="3947">005)). We denote these four systems as InR, RWILM, AFF, and VEC respectively. Furthermore, we denote the permutations of our methods as follows: LDA1: RS2 with RS��� ��1, LDA2: RS1 with RS��� ��1 , LDA3: RS2 with RS��� ��2, LDA4: RS1 with RS��� ��2. Because the inconsistency of the evaluation metrics employed in the past work, we choose to employ all of them to measure the effectiveness of various approaches. These include: mean average precision (MAP), the precision of the top 5 documents (Prec@5), the precision of the top 10 documents (Prec@10), normalized discounted cumulative gain (NDCG) (Jarvelin and Kekalainen, 2002) and Bpref (Buckley and Voorhees, 2004). Statistical-significant differences in performance were determined using a paired t-test at a confidence level of 95%. It is worth pointing out that the above measurements are not directly comparable with those of the CLEF participants because we restricted our initial pool to a smaller number of documents and the main purpose in the paper is to compare the proposed method with different baseline systems. Parameter Two primary parameters need to be determined in our experiments. For the reranking experiments, the combination parameter A must be defined.</context>
</contexts>
<marker>Jarvelin, Kekalainen, 2002</marker>
<rawString>Kalervo Jarvelin and Jaana Kekalainen (2002). &amp;quot;Cumulated gain-based evaluation of IR techniques.&amp;quot; ACM Trans. Inf. Syst. 20(4): 422-446.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaap Kamps</author>
</authors>
<title>Improving Retrieval Effectiveness by Reranking Documents Based on Controlled Vocabulary</title>
<date>2004</date>
<booktitle>In Proceedings of 26th European Conference on IR Research, ECIR 2004,</booktitle>
<pages>283--295</pages>
<location>Sunderland, UK.</location>
<contexts>
<context position="6701" citStr="Kamps, 2004" startWordPosition="1050" endWordPosition="1051">on 3 describes the re-ranking framework based on latent information induced together with details of how to build generative model. In Section 4 we report on a series of experiments performed over three different test collections in English and French as well as results obtained. Finally, Section 5 concludes the paper and speculates on future work. 2 Related Work There exist several groups of related work in the areas of document retrieval and re-ranking. The first category performs re-ranking by using inter-document relationship (Lee et al., 2001), evidences obtained from external resources (Kamps, 2004), or through local context analysis (Xu and Croft, 2000). In the past, document distances (Balinski and Daniowicz, 2005), manually built external thesaurus (Qu et al., 2001), and structural information (such as document title) (Luk and Wong, 2004), etc have been used extensively for this very purpose. A second category of work is related to recent advances in structural re-ranking paradigm over graphs. Kurland and Lee performed re-ranking based on measures of centrality in the graph formed by generation links induced by language model scores, through a weighted version of PageRank algorithm (K</context>
</contexts>
<marker>Kamps, 2004</marker>
<rawString>Jaap Kamps (2004). Improving Retrieval Effectiveness by Reranking Documents Based on Controlled Vocabulary In Proceedings of 26th European Conference on IR Research, ECIR 2004, Sunderland, UK. p. 283-295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon M Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.&amp;quot;</title>
<date>1999</date>
<journal>J. ACM</journal>
<volume>46</volume>
<issue>5</issue>
<pages>604--632</pages>
<contexts>
<context position="3668" citStr="Kleinberg, 1999" startWordPosition="567" endWordPosition="568">e taken into account when designing any reranking algorithms: the original queries and initial retrieval scores. One of issues is that previous structural re-ranking algorithms treat the query and the content individually when computing re-ranking scores. Each document is assigned a score independent of other documents without considering of queries. The problem we want to address in this paper is how we can leverage the interconnections between query and documents for the re-ranking purpose. Another problem with such approaches concerns the fundamental re-ranking strategy they adopted. HITS (Kleinberg, 1999) and PageRank 1571 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1571–1580, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP (Brin and Page, 1998) style algorithms were widely used in the past. However, approaches depend only on the structure of the global graph or sub-graph may ignore important information content of a document entity. As pointed out by Deng et al. (2009), re-ranking algorithms that rely only on the structure of the global graph are likely lead to the problem of topic drift. Instead, we introduce a new document reranking method </context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>Jon M. Kleinberg (1999). &amp;quot;Authoritative sources in a hyperlinked environment.&amp;quot; J. ACM 46(5): 604-632. S. Kullback and R. A. Leibler (1951). &amp;quot;On Information and Sufficiency.&amp;quot; The Annals of Mathematical Statistics 22(1): 79-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Kurland</author>
<author>Lillian Lee</author>
</authors>
<title>PageRank without hyperlinks: structural re-ranking using links induced by language models.</title>
<date>2005</date>
<booktitle>In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>306--313</pages>
<location>Salvador, Brazil, ACM.</location>
<contexts>
<context position="2638" citStr="Kurland and Lee (2005)" startWordPosition="406" endWordPosition="410">of retrieval process, our method focuses on the document re-ranking approach. We will focus on adjusting the ranking positions directly over initial retrieval results set llDinit . Recently, there is a trend of exploring the hidden structure of documents to re-rank results. Some of the approaches represent the document entities as a connected graph G. It is usually constructed by links inferred from the content information as a nearest-neighbor graph. For example, Zhang et al. (2005) proposed an affinity ranking graph to re-rank search results by optimizing diversity and information richness. Kurland and Lee (2005) introduced a structural reranking approach by exploiting asymmetric relationships between documents induced by language models. Diaz (2005); Deng et al. (2009) use a family of semi-supervised machine learning methods among documents graph constructed by incorporating different evidences. However in this work we are more interested in adopting an automatic approach. There are two important factors that should be taken into account when designing any reranking algorithms: the original queries and initial retrieval scores. One of issues is that previous structural re-ranking algorithms treat the</context>
<context position="7322" citStr="Kurland and Lee, 2005" startWordPosition="1146" endWordPosition="1149">), or through local context analysis (Xu and Croft, 2000). In the past, document distances (Balinski and Daniowicz, 2005), manually built external thesaurus (Qu et al., 2001), and structural information (such as document title) (Luk and Wong, 2004), etc have been used extensively for this very purpose. A second category of work is related to recent advances in structural re-ranking paradigm over graphs. Kurland and Lee performed re-ranking based on measures of centrality in the graph formed by generation links induced by language model scores, through a weighted version of PageRank algorithm (Kurland and Lee, 2005) and HITS-style cluster-based approach (Kurland and Lee, 2006). Zhang et al. (2005) proposed a similar method to improve web search based on a linear combination of results from text search and authority ranking. The graph, which they named affinity graph, shares strong similarities with Kurland and Lee’s work with the links induced by a modified version of cosine similarity using the vector space model. Diaz (2005) used score regularization to adjust document retrieval rankings from an initial retrieval by a semisupervised learning method. Deng et al. (2009) further developed this method. The</context>
<context position="17524" citStr="Kurland and Lee, 2005" startWordPosition="2949" endWordPosition="2952">) Data (Main) BNF Bibliothèque Na- French (Main) 1,000,100 1.3 GB 50 (CLEF2008) tionale de France LAT Los Angeles English 135,153 434 MB 50 (CLEF2007) Times 2002 Table 1. Statistics of test collections 𝐿𝐷𝐴𝑑 (𝑤1𝑤2 ... 𝑤𝑛) ≝ 𝑗𝑛 =1 𝐿𝐷𝐴𝑑 (𝑤𝑗 ) Then the distance between a query and a document based on this model can be obtained. The first method we propose here adopts the KL divergence between the query terms and document terms to compute a Re-Rank score 𝑅𝑆𝐿𝐷𝐴 𝐾𝐿1: 𝑅𝑆𝐿𝐷𝐴 𝐾𝐿1 = −𝐷 (𝑀𝐿𝐸𝑞 (∙)||𝐿𝐷𝐴𝑑 ∙ ) This method also has the property of lengthnormalization to ameliorate long document bias problems (Kurland and Lee, 2005). The second method also measures a KL divergence between a query and a document, however, in a different way. As in the original LDA model, the multinomial parameter 𝜃 𝑑 indicates the topic distribution of a document 𝑑. Query 𝑞 can be considered as topic estimation of a unknown document 𝑤 . Thus by first randomly assigning topics to words and then performing a number of loops through the Gibbs sampling update, we have: 𝑝 𝑧𝑖 𝑧 ¬𝑖, 𝑤 ; 𝑧 ¬𝑖, 𝑤 𝑛𝑧,¬𝑖 𝑤𝑖 + 𝑛 𝑧,¬𝑖 𝑤𝑖 + 𝛽𝑤𝑖 (𝑛𝑧𝑣 + 𝑛 𝑧𝑣 + 𝛽𝑣) − 1 𝑉 𝑣=1 𝑛𝑑 𝑖,¬𝑖 𝑧+ 𝛼𝑘 ∙ ( 𝑛𝑑 𝑖 𝑘 𝑧 + 𝛼𝑧) − 1 𝑧=1 where 𝑛 𝑧,¬𝑖 𝑤𝑖 counts the observations of word 𝑤𝑖 and to</context>
<context position="22415" citStr="Kurland and Lee, 2005" startWordPosition="3795" endWordPosition="3798">queries are processed similarly to the treatment in the test collections. The relevance judgments are taken from the judged pool of top retrieved documents by various participating retrieval systems from previous CLEF workshops. We compare the proposed latent re-ranking method with four other approaches: the initial ranker, mentioned above, is a KL-divergence retrieval function using the language models. Three other baseline systems are: Kurland and Lee’s structural re-ranking approach (Recursive Weighted Influx + Language Model), chosen as it demonstrates the best performance in their paper (Kurland and Lee, 2005), Zhang et al.’s affinity graph-based approach (Zhang et al., 2005) 3 ftp://ftp.cs.cornell.edu/pub/smart/ 4 http://lucene.apache.org/ 5 http://trec.nist.gov/ and a variant of Kurland and Lee’s work with links in the graph calculated by the vector-space model (cosine similarity as mentioned in (Kurland and Lee, 2005)). We denote these four systems as InR, RWILM, AFF, and VEC respectively. Furthermore, we denote the permutations of our methods as follows: LDA1: RS2 with RS��� ��1, LDA2: RS1 with RS��� ��1 , LDA3: RS2 with RS��� ��2, LDA4: RS1 with RS��� ��2. Because the inconsistency of the eval</context>
<context position="24766" citStr="Kurland and Lee, 2005" startWordPosition="4186" endWordPosition="4189">pply them to all three collections directly. The search ranges for these two parameters were:  : 0.1, 0.2, ..., 0.9 k : 5, 10, 15, ..., 45 As it turned out, for many instances, the optimal value of A with respect to MAP was either 0.1 or 0.2, suggesting the initial retrieval scores have valuable information inside them. In contrast, the optimal value of k was between 20 and 40. Although this demonstrates a relatively large variance, the differences in terms of MAP have remained small and statistically insignificant. We set llDinit to 50 in all results reported, as in Kurland and Lee’s paper (Kurland and Lee, 2005) and we later show that the performance turns out to be very stable when this set enlarged. 1576 BL MAP Prec@5 Prec@10 NDCG Bpref InR 0.1913 0.52 0.452 0.3489 0.2287 RWILM 0.2152 0.532 0.468 0.3663 0.2242 AFF 0.1737 0.444 0.434 0.3273 0.22 0.1756 0.448 0.434 0.3258 0.2216 LDA1 0.21 o, a, v 0.544 a, v 0.47 0.3679 o, a, v 0.2429 a, v LDA2 LDA3 0.1673 0.452 0.402 0.3297 0.2 LDA4 0.2035 o, a, v 0.548 a, v 0.468 a, v 0.3626 o, a, v 0.2326 a VEC BNF MAP Prec@5 Prec@10 NDCG bpref InR 0.1266 0.268 0.216 0.2456 0.1482 RWILM 0.2148 o, a, v 0.58 o, a, v 0.5 o, a, v 0.3726 o, a, v 0.2491 o, l, a, v 0.1274</context>
</contexts>
<marker>Kurland, Lee, 2005</marker>
<rawString>Oren Kurland and Lillian Lee (2005). PageRank without hyperlinks: structural re-ranking using links induced by language models. In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, Salvador, Brazil, ACM. p. 306-313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Kurland</author>
<author>Lillian Lee</author>
</authors>
<title>Respect my authority!: HITS without hyperlinks, utilizing cluster-based language models.</title>
<date>2006</date>
<booktitle>In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>83--90</pages>
<location>Seattle, Washington, USA, ACM.</location>
<contexts>
<context position="7384" citStr="Kurland and Lee, 2006" startWordPosition="1154" endWordPosition="1157">the past, document distances (Balinski and Daniowicz, 2005), manually built external thesaurus (Qu et al., 2001), and structural information (such as document title) (Luk and Wong, 2004), etc have been used extensively for this very purpose. A second category of work is related to recent advances in structural re-ranking paradigm over graphs. Kurland and Lee performed re-ranking based on measures of centrality in the graph formed by generation links induced by language model scores, through a weighted version of PageRank algorithm (Kurland and Lee, 2005) and HITS-style cluster-based approach (Kurland and Lee, 2006). Zhang et al. (2005) proposed a similar method to improve web search based on a linear combination of results from text search and authority ranking. The graph, which they named affinity graph, shares strong similarities with Kurland and Lee’s work with the links induced by a modified version of cosine similarity using the vector space model. Diaz (2005) used score regularization to adjust document retrieval rankings from an initial retrieval by a semisupervised learning method. Deng et al. (2009) further developed this method. They built a latent space graph based on content and explicit lin</context>
<context position="31787" citStr="Kurland and Lee, 2006" startWordPosition="5372" endWordPosition="5375"> Size of the initial retrieval set 1578 rages the latent Dirichlet allocation technique for the query-dependent ranking problem and results in state-of-art performance. There are many research directions we are planning to investigate. It has been shown that LDA-based retrieval is a promising method for ranking the whole corpus. There is a desire to call for a direct comparison between ranking and re-ranking using the proposed algorithmic variations. Future work will also include the comparison between our methods with other related approaches, such as Kurland and Lee’s clusterbased approach (Kurland and Lee, 2006). There exist a sufficient number of latent semantic techniques such as singular vector decomposition, non-negative matrix factorization, PLSA, etc. We are planning to explore these methods to compare their performance. Also direct re-ranking can be used to improve automatic query expansion since better ranking in top retrieved documents can be expected to improve the quality of the augmented query. We believe this is another fruitful line for future research. Acknowledgments The authors would like to thank three anonymous reviewers for many constructive comments. This research is supported by</context>
</contexts>
<marker>Kurland, Lee, 2006</marker>
<rawString>Oren Kurland and Lillian Lee (2006). Respect my authority!: HITS without hyperlinks, utilizing cluster-based language models. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, Seattle, Washington, USA, ACM. p. 83-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Peter W Foltz</author>
<author>Darrell Laham</author>
</authors>
<title>An Introduction to Latent Semantic Analysis.&amp;quot;</title>
<date>1998</date>
<journal>Inf. Process. Manage.</journal>
<booktitle>Discourse Processes</booktitle>
<volume>25</volume>
<pages>259--284</pages>
<institution>Kyung-Soon Lee, Young-Chan Park and Key-Sun Choi</institution>
<contexts>
<context position="8191" citStr="Landauer et al., 1998" startWordPosition="1286" endWordPosition="1289">ty graph, shares strong similarities with Kurland and Lee’s work with the links induced by a modified version of cosine similarity using the vector space model. Diaz (2005) used score regularization to adjust document retrieval rankings from an initial retrieval by a semisupervised learning method. Deng et al. (2009) further developed this method. They built a latent space graph based on content and explicit links information. Unlike their approach we are trying to model the latent information directly. This work is also related to a family of methods so called latent semantic analysis (LSA) (Landauer et al., 1998), especially topic models used for document representation. Latent Dirichlet Allocation (LDA), after it was first introduced by Blei et al. (2003), has quickly become one of the most popular probabilistic text modeling techniques and has inspired research ranging from text classification and clustering (Phan et al., 2008), information discovery (Mei et al., 2007; Titov and McDonald, 2008) to information retrieval (Wei and Croft, 2006). In this model, each topic is represented by a set of words and each word corresponds with a weight to measure its contribution to the topic. Wei and Croft 1572 </context>
<context position="11146" citStr="Landauer et al., 1998" startWordPosition="1780" endWordPosition="1783">trieval model (initial ranker). However, the initial ranker tends to be imperfect. The purpose of our reranking method is to re-order a set of documents 𝔻𝑖𝑛𝑖𝑡 so as to improve retrieval accuracy at the very top ranks of the final results. 3.2 Latent Dirichlet Allocation We will first introduce Latent Dirichlet Allocation model which forms the basis of the reranking framework that will be detailed in the next subsection. It was previously shown that cooccurrence structure of terms in text documents can be used to recover some latent topic structures without any usage of background information (Landauer et al., 1998). This means that latent-topic representations of text allow modeling of linguistic phenomena such as synonymy and polysemy. By doing so, information retrieval systems can match the information needs with content items on a meaning level rather than by just lexical congruence. The basic generative process of LDA closely resembles PLSA (Hofmann, 1999). LDA extends PLSA method by defining a complete generative model of text. The topic mixture is drawn from a conjugate Dirichlet prior that remains the same for all documents. The process of generating a document corpus is as follows: 1) Pick a mul</context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>Thomas K. Landauer, Peter W. Foltz and Darrell Laham (1998). &amp;quot;An Introduction to Latent Semantic Analysis.&amp;quot; Discourse Processes 25: 259-284. Kyung-Soon Lee, Young-Chan Park and Key-Sun Choi (2001). &amp;quot;Re-ranking model based on document clusters.&amp;quot; Inf. Process. Manage. 37(1): 1-14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert W P Luk</author>
<author>K F Wong</author>
</authors>
<title>PseudoRelevance Feedback and Title Re-ranking for Chinese Information Retrieval.</title>
<date>2004</date>
<booktitle>In Working Notes of the Fourth NTCIR Workshop Meeting,</booktitle>
<institution>National Institute of Informatics.</institution>
<location>Tokyo, Japan,</location>
<contexts>
<context position="6948" citStr="Luk and Wong, 2004" startWordPosition="1087" endWordPosition="1090"> and French as well as results obtained. Finally, Section 5 concludes the paper and speculates on future work. 2 Related Work There exist several groups of related work in the areas of document retrieval and re-ranking. The first category performs re-ranking by using inter-document relationship (Lee et al., 2001), evidences obtained from external resources (Kamps, 2004), or through local context analysis (Xu and Croft, 2000). In the past, document distances (Balinski and Daniowicz, 2005), manually built external thesaurus (Qu et al., 2001), and structural information (such as document title) (Luk and Wong, 2004), etc have been used extensively for this very purpose. A second category of work is related to recent advances in structural re-ranking paradigm over graphs. Kurland and Lee performed re-ranking based on measures of centrality in the graph formed by generation links induced by language model scores, through a weighted version of PageRank algorithm (Kurland and Lee, 2005) and HITS-style cluster-based approach (Kurland and Lee, 2006). Zhang et al. (2005) proposed a similar method to improve web search based on a linear combination of results from text search and authority ranking. The graph, wh</context>
</contexts>
<marker>Luk, Wong, 2004</marker>
<rawString>Robert W. P. Luk and K.F. Wong (2004). PseudoRelevance Feedback and Title Re-ranking for Chinese Information Retrieval. In Working Notes of the Fourth NTCIR Workshop Meeting, Tokyo, Japan, National Institute of Informatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xu Ling</author>
<author>Matthew Wondra</author>
</authors>
<title>Hang Su and ChengXiang Zhai</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>171--180</pages>
<location>Banff, Alberta, Canada, ACM.</location>
<contexts>
<context position="8555" citStr="Mei et al., 2007" startWordPosition="1340" endWordPosition="1343">space graph based on content and explicit links information. Unlike their approach we are trying to model the latent information directly. This work is also related to a family of methods so called latent semantic analysis (LSA) (Landauer et al., 1998), especially topic models used for document representation. Latent Dirichlet Allocation (LDA), after it was first introduced by Blei et al. (2003), has quickly become one of the most popular probabilistic text modeling techniques and has inspired research ranging from text classification and clustering (Phan et al., 2008), information discovery (Mei et al., 2007; Titov and McDonald, 2008) to information retrieval (Wei and Croft, 2006). In this model, each topic is represented by a set of words and each word corresponds with a weight to measure its contribution to the topic. Wei and Croft 1572 (2006) described large-scale information retrieval experiments by using LDA. In their work, LDA-based document model and language model-based document model were linearly combined to rank the entire corpus. However, unlike this approach we only apply LDA to a small set of documents. There are two reasons by doing so. One is the concern of computational cost. LDA</context>
</contexts>
<marker>Mei, Ling, Wondra, 2007</marker>
<rawString>Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su and ChengXiang Zhai (2007). Topic sentiment mixture: modeling facets and opinions in weblogs. In Proceedings of the 16th international conference on World Wide Web, Banff, Alberta, Canada, ACM. p. 171-180.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Xuan-Hieu Phan</author>
</authors>
<title>Le-Minh Nguyen and Susumu Horiguchi (2008). Learning to classify short and sparse text \&amp; web with hidden topics from large-scale data collections.</title>
<booktitle>In Proceeding of the 17th international conference on World Wide Web,</booktitle>
<pages>91--100</pages>
<location>Beijing, China, ACM.</location>
<marker>Phan, </marker>
<rawString>Xuan-Hieu Phan, Le-Minh Nguyen and Susumu Horiguchi (2008). Learning to classify short and sparse text \&amp; web with hidden topics from large-scale data collections. In Proceeding of the 17th international conference on World Wide Web, Beijing, China, ACM. p. 91-100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay M Ponte</author>
<author>W Bruce Croft</author>
</authors>
<title>A language modeling approach to information retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>275--281</pages>
<location>Melbourne, Australia, ACM.</location>
<contexts>
<context position="15154" citStr="Ponte and Croft, 1998" startWordPosition="2496" endWordPosition="2499"> measure of the difference between two probability distributions. The distance used in our approach is the Kullback-Leibler (KL) divergence (Kullback and Leibler, 1951). Given two probability mass function 𝑝 𝑥 and 𝑞 (𝑥), the KL divergence (or relative entropy) between 𝑝 and 𝑞 is defined as: 𝐷(𝑝 |𝑞 = 𝑝 𝑥 𝑙𝑜𝑔 In terms of text sequences (either queries or documents), the probability distribution can be regarded as a probabilistic language model 𝑀𝑑 or 𝑀𝑞 from each document 𝑑 or each query 𝑞. In other words, it assumes that there is an underlying language model which “generates” a term (sequence) (Ponte and Croft, 1998). The unigram language model is utilized here. There are several ways to estimate the probabilities. Let 𝑔 (𝑤 ∈ 𝑑) denotes the number of times the term 𝑤 occurs in a document 𝑑 (same idea can be used on a query). The Maximum-likelihood estimation (MLE) of 𝑤 with respect to 𝑑 is defined as: 𝑀𝐿𝐸𝑑𝑤 ≝ 𝑤 ′ 𝑔 (𝑤′ ∈ 𝑑) Previous work in language-model-based information retrieval (Zhai and Lafferty, 2004) advocates the use of a Dirichlet-smoothed estimation: 𝐷𝐼𝑅𝑑𝑤 ≝ 𝑤′ 𝑔(𝑤′ ∈ 𝑑) + 𝜇 where smoothing parameter 𝜇 controls the degree of reliance on relative frequencies in the document corpus rather than on</context>
</contexts>
<marker>Ponte, Croft, 1998</marker>
<rawString>Jay M. Ponte and W. Bruce Croft (1998). A language modeling approach to information retrieval. In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, Melbourne, Australia, ACM. p. 275-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youli Qu</author>
<author>Guowei Xu</author>
<author>Jun Wang</author>
</authors>
<title>Rerank Method Based on Individual Thesaurus.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second NTCIR Workshop on Research in Chinese &amp; Japanese Text Retrieval and Text Summarization,</booktitle>
<institution>National Institute of Informatics.</institution>
<location>Tokyo, Japan,</location>
<contexts>
<context position="6874" citStr="Qu et al., 2001" startWordPosition="1075" endWordPosition="1078"> experiments performed over three different test collections in English and French as well as results obtained. Finally, Section 5 concludes the paper and speculates on future work. 2 Related Work There exist several groups of related work in the areas of document retrieval and re-ranking. The first category performs re-ranking by using inter-document relationship (Lee et al., 2001), evidences obtained from external resources (Kamps, 2004), or through local context analysis (Xu and Croft, 2000). In the past, document distances (Balinski and Daniowicz, 2005), manually built external thesaurus (Qu et al., 2001), and structural information (such as document title) (Luk and Wong, 2004), etc have been used extensively for this very purpose. A second category of work is related to recent advances in structural re-ranking paradigm over graphs. Kurland and Lee performed re-ranking based on measures of centrality in the graph formed by generation links induced by language model scores, through a weighted version of PageRank algorithm (Kurland and Lee, 2005) and HITS-style cluster-based approach (Kurland and Lee, 2006). Zhang et al. (2005) proposed a similar method to improve web search based on a linear co</context>
</contexts>
<marker>Qu, Xu, Wang, 2001</marker>
<rawString>Youli Qu, Guowei Xu and Jun Wang (2001). Rerank Method Based on Individual Thesaurus. In Proceedings of the Second NTCIR Workshop on Research in Chinese &amp; Japanese Text Retrieval and Text Summarization, Tokyo, Japan, National Institute of Informatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>In Proceeding of the 17th international conference on World Wide Web,</booktitle>
<pages>111--120</pages>
<location>Beijing, China, ACM.</location>
<contexts>
<context position="8582" citStr="Titov and McDonald, 2008" startWordPosition="1344" endWordPosition="1347">on content and explicit links information. Unlike their approach we are trying to model the latent information directly. This work is also related to a family of methods so called latent semantic analysis (LSA) (Landauer et al., 1998), especially topic models used for document representation. Latent Dirichlet Allocation (LDA), after it was first introduced by Blei et al. (2003), has quickly become one of the most popular probabilistic text modeling techniques and has inspired research ranging from text classification and clustering (Phan et al., 2008), information discovery (Mei et al., 2007; Titov and McDonald, 2008) to information retrieval (Wei and Croft, 2006). In this model, each topic is represented by a set of words and each word corresponds with a weight to measure its contribution to the topic. Wei and Croft 1572 (2006) described large-scale information retrieval experiments by using LDA. In their work, LDA-based document model and language model-based document model were linearly combined to rank the entire corpus. However, unlike this approach we only apply LDA to a small set of documents. There are two reasons by doing so. One is the concern of computational cost. LDA is a very complex model an</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald (2008). Modeling online reviews with multi-grain topic models. In Proceeding of the 17th international conference on World Wide Web, Beijing, China, ACM. p. 111-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xing Wei</author>
<author>W Bruce Croft</author>
</authors>
<title>LDA-based document models for ad-hoc retrieval.</title>
<date>2006</date>
<booktitle>In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>178--185</pages>
<location>Seattle, Washington, USA, ACM.</location>
<contexts>
<context position="8629" citStr="Wei and Croft, 2006" startWordPosition="1351" endWordPosition="1354">eir approach we are trying to model the latent information directly. This work is also related to a family of methods so called latent semantic analysis (LSA) (Landauer et al., 1998), especially topic models used for document representation. Latent Dirichlet Allocation (LDA), after it was first introduced by Blei et al. (2003), has quickly become one of the most popular probabilistic text modeling techniques and has inspired research ranging from text classification and clustering (Phan et al., 2008), information discovery (Mei et al., 2007; Titov and McDonald, 2008) to information retrieval (Wei and Croft, 2006). In this model, each topic is represented by a set of words and each word corresponds with a weight to measure its contribution to the topic. Wei and Croft 1572 (2006) described large-scale information retrieval experiments by using LDA. In their work, LDA-based document model and language model-based document model were linearly combined to rank the entire corpus. However, unlike this approach we only apply LDA to a small set of documents. There are two reasons by doing so. One is the concern of computational cost. LDA is a very complex model and the complexity will grow linearly with the nu</context>
<context position="19006" citStr="Wei and Croft, 2006" startWordPosition="3241" endWordPosition="3244">. Then the re-ranking score is calculated as: 𝑅𝑆𝐿𝐷𝐴 𝐾𝐿2 = −𝐷 (𝜃 𝑞||𝜃 𝑑 ) Thus we can re-rank the initial retrieved documents according to the scores acquired. However, as in other topic models, a topic in the LDA model represents a combination of words, and it may not be as precise a representation as words in language model. Hence we need to further consider how to combine initial retrieval scores with the re-ranking scores calculated. Two combination methods will be presented in the next subsection. 3.4 Combining Initial Retrieval Scores Motivated by the significant improvement obtained by (Wei and Croft, 2006) and (Zhang et al., 2005), we formulate our method through a linear combination of the re-ranking scores based on initial ranker and the latent document reranker, shown as follow: 𝑅𝑆1 = (1 − 𝜆) ∙ 𝑂𝑆 + 𝜆 ∙ 𝑅𝑆𝐿𝐷𝐴 𝐾𝐿∙ where 𝑂𝑆 denotes original scores returned by the initial ranker and 𝜆 is a parameter that can be tuned with 𝜆 = 0 meaning no re-ranking is performed. Another scheme considers a multiplication combination to incorporate the original score. It does not need to tune any parameters: 𝑅𝑆2 = 𝑂𝑆 ∙ 𝑅𝑆𝐿𝐷𝐴 𝐾𝐿∙ This concludes our overview of the proposed latent re-ranking method. 4 Evaluation I</context>
</contexts>
<marker>Wei, Croft, 2006</marker>
<rawString>Xing Wei and W. Bruce Croft (2006). LDA-based document models for ad-hoc retrieval. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, Seattle, Washington, USA, ACM. p. 178-185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinxi Xu</author>
<author>W Bruce Croft</author>
</authors>
<title>Improving the effectiveness of information retrieval with local context analysis.&amp;quot;</title>
<date>2000</date>
<journal>ACM Trans. Inf. Syst.</journal>
<volume>18</volume>
<issue>1</issue>
<pages>79--112</pages>
<contexts>
<context position="6757" citStr="Xu and Croft, 2000" startWordPosition="1057" endWordPosition="1060">latent information induced together with details of how to build generative model. In Section 4 we report on a series of experiments performed over three different test collections in English and French as well as results obtained. Finally, Section 5 concludes the paper and speculates on future work. 2 Related Work There exist several groups of related work in the areas of document retrieval and re-ranking. The first category performs re-ranking by using inter-document relationship (Lee et al., 2001), evidences obtained from external resources (Kamps, 2004), or through local context analysis (Xu and Croft, 2000). In the past, document distances (Balinski and Daniowicz, 2005), manually built external thesaurus (Qu et al., 2001), and structural information (such as document title) (Luk and Wong, 2004), etc have been used extensively for this very purpose. A second category of work is related to recent advances in structural re-ranking paradigm over graphs. Kurland and Lee performed re-ranking based on measures of centrality in the graph formed by generation links induced by language model scores, through a weighted version of PageRank algorithm (Kurland and Lee, 2005) and HITS-style cluster-based appro</context>
</contexts>
<marker>Xu, Croft, 2000</marker>
<rawString>Jinxi Xu and W. Bruce Croft (2000). &amp;quot;Improving the effectiveness of information retrieval with local context analysis.&amp;quot; ACM Trans. Inf. Syst. 18(1): 79-112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengxiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>Modelbased feedback in the language modeling approach to information retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of the tenth international conference on Information and knowledge management,</booktitle>
<pages>403--410</pages>
<publisher>ACM.</publisher>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="15941" citStr="Zhai and Lafferty, 2001" startWordPosition="2643" endWordPosition="2646"> a document 𝑑 (same idea can be used on a query). The Maximum-likelihood estimation (MLE) of 𝑤 with respect to 𝑑 is defined as: 𝑀𝐿𝐸𝑑𝑤 ≝ 𝑤 ′ 𝑔 (𝑤′ ∈ 𝑑) Previous work in language-model-based information retrieval (Zhai and Lafferty, 2004) advocates the use of a Dirichlet-smoothed estimation: 𝐷𝐼𝑅𝑑𝑤 ≝ 𝑤′ 𝑔(𝑤′ ∈ 𝑑) + 𝜇 where smoothing parameter 𝜇 controls the degree of reliance on relative frequencies in the document corpus rather than on the counts in 𝑑. The initial ranker that we choose to use later in the experiment computes the KL divergence between the 𝑀𝐿𝐸𝑞 𝑤 and a modified version of 𝐷𝐼𝑅𝑑 𝑤 (Zhai and Lafferty, 2001). Both estimations can be easily extended to distributions over text sequences by assuming that the terms are independent: 𝑛 𝑀𝐿𝐸𝑑 (𝑤1 𝑤2 ... 𝑤𝑛) ≝ 𝑀𝐿𝐸𝑑 (𝑤𝑗 ) 𝑗=1 𝑛 𝐷𝐼𝑅𝑑 (𝑤1 𝑤2 ... 𝑤𝑛) ≝ 𝐷𝐼𝑅𝑑 (𝑤𝑗 ) 𝑗=1 In the re-ranking setting, we estimate that the probability of a document 𝑑 generates 𝑤, using a mixture model LDA. It uses a convex combination of a set of component distributions to model observations. In this model, a word 𝑤 is generated from a convex combination of some hidden topics 𝑧: 𝑘 𝐿𝐷𝐴𝑑 𝑤 = 𝑝 𝑤 𝑧 𝑝(𝑧|𝑑) 𝑧=1 where each mixture model 𝑝 (𝑤 |𝑧) is a multinomial distribution over terms that</context>
</contexts>
<marker>Zhai, Lafferty, 2001</marker>
<rawString>Chengxiang Zhai and John Lafferty (2001). Modelbased feedback in the language modeling approach to information retrieval. In Proceedings of the tenth international conference on Information and knowledge management, Atlanta, Georgia, USA, ACM. p. 403-410.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengxiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>A study of smoothing methods for language models applied to information retrieval.&amp;quot;</title>
<date>2004</date>
<journal>ACM Trans. Inf. Syst.</journal>
<volume>22</volume>
<issue>2</issue>
<pages>179--214</pages>
<contexts>
<context position="15553" citStr="Zhai and Lafferty, 2004" startWordPosition="2571" endWordPosition="2574">an be regarded as a probabilistic language model 𝑀𝑑 or 𝑀𝑞 from each document 𝑑 or each query 𝑞. In other words, it assumes that there is an underlying language model which “generates” a term (sequence) (Ponte and Croft, 1998). The unigram language model is utilized here. There are several ways to estimate the probabilities. Let 𝑔 (𝑤 ∈ 𝑑) denotes the number of times the term 𝑤 occurs in a document 𝑑 (same idea can be used on a query). The Maximum-likelihood estimation (MLE) of 𝑤 with respect to 𝑑 is defined as: 𝑀𝐿𝐸𝑑𝑤 ≝ 𝑤 ′ 𝑔 (𝑤′ ∈ 𝑑) Previous work in language-model-based information retrieval (Zhai and Lafferty, 2004) advocates the use of a Dirichlet-smoothed estimation: 𝐷𝐼𝑅𝑑𝑤 ≝ 𝑤′ 𝑔(𝑤′ ∈ 𝑑) + 𝜇 where smoothing parameter 𝜇 controls the degree of reliance on relative frequencies in the document corpus rather than on the counts in 𝑑. The initial ranker that we choose to use later in the experiment computes the KL divergence between the 𝑀𝐿𝐸𝑞 𝑤 and a modified version of 𝐷𝐼𝑅𝑑 𝑤 (Zhai and Lafferty, 2001). Both estimations can be easily extended to distributions over text sequences by assuming that the terms are independent: 𝑛 𝑀𝐿𝐸𝑑 (𝑤1 𝑤2 ... 𝑤𝑛) ≝ 𝑀𝐿𝐸𝑑 (𝑤𝑗 ) 𝑗=1 𝑛 𝐷𝐼𝑅𝑑 (𝑤1 𝑤2 ... 𝑤𝑛) ≝ 𝐷𝐼𝑅𝑑 (𝑤𝑗 ) 𝑗=1 In the re-r</context>
</contexts>
<marker>Zhai, Lafferty, 2004</marker>
<rawString>Chengxiang Zhai and John Lafferty (2004). &amp;quot;A study of smoothing methods for language models applied to information retrieval.&amp;quot; ACM Trans. Inf. Syst. 22(2): 179-214.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benyu Zhang</author>
<author>Hua Li</author>
<author>Yi Liu</author>
<author>Lei Ji</author>
<author>Wensi Xi</author>
<author>Weiguo Fan</author>
</authors>
<title>Zheng Chen and Wei-Ying Ma</title>
<date>2005</date>
<booktitle>In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>504--511</pages>
<location>Salvador, Brazil, ACM.</location>
<contexts>
<context position="2504" citStr="Zhang et al. (2005)" startWordPosition="386" endWordPosition="389">aYates and Ribeiro-Neto, 1999): document reranking and query expansion/re-weighting. Since the latter normally need a second round of retrieval process, our method focuses on the document re-ranking approach. We will focus on adjusting the ranking positions directly over initial retrieval results set llDinit . Recently, there is a trend of exploring the hidden structure of documents to re-rank results. Some of the approaches represent the document entities as a connected graph G. It is usually constructed by links inferred from the content information as a nearest-neighbor graph. For example, Zhang et al. (2005) proposed an affinity ranking graph to re-rank search results by optimizing diversity and information richness. Kurland and Lee (2005) introduced a structural reranking approach by exploiting asymmetric relationships between documents induced by language models. Diaz (2005); Deng et al. (2009) use a family of semi-supervised machine learning methods among documents graph constructed by incorporating different evidences. However in this work we are more interested in adopting an automatic approach. There are two important factors that should be taken into account when designing any reranking al</context>
<context position="7405" citStr="Zhang et al. (2005)" startWordPosition="1158" endWordPosition="1161">nces (Balinski and Daniowicz, 2005), manually built external thesaurus (Qu et al., 2001), and structural information (such as document title) (Luk and Wong, 2004), etc have been used extensively for this very purpose. A second category of work is related to recent advances in structural re-ranking paradigm over graphs. Kurland and Lee performed re-ranking based on measures of centrality in the graph formed by generation links induced by language model scores, through a weighted version of PageRank algorithm (Kurland and Lee, 2005) and HITS-style cluster-based approach (Kurland and Lee, 2006). Zhang et al. (2005) proposed a similar method to improve web search based on a linear combination of results from text search and authority ranking. The graph, which they named affinity graph, shares strong similarities with Kurland and Lee’s work with the links induced by a modified version of cosine similarity using the vector space model. Diaz (2005) used score regularization to adjust document retrieval rankings from an initial retrieval by a semisupervised learning method. Deng et al. (2009) further developed this method. They built a latent space graph based on content and explicit links information. Unlik</context>
<context position="19031" citStr="Zhang et al., 2005" startWordPosition="3246" endWordPosition="3249">e is calculated as: 𝑅𝑆𝐿𝐷𝐴 𝐾𝐿2 = −𝐷 (𝜃 𝑞||𝜃 𝑑 ) Thus we can re-rank the initial retrieved documents according to the scores acquired. However, as in other topic models, a topic in the LDA model represents a combination of words, and it may not be as precise a representation as words in language model. Hence we need to further consider how to combine initial retrieval scores with the re-ranking scores calculated. Two combination methods will be presented in the next subsection. 3.4 Combining Initial Retrieval Scores Motivated by the significant improvement obtained by (Wei and Croft, 2006) and (Zhang et al., 2005), we formulate our method through a linear combination of the re-ranking scores based on initial ranker and the latent document reranker, shown as follow: 𝑅𝑆1 = (1 − 𝜆) ∙ 𝑂𝑆 + 𝜆 ∙ 𝑅𝑆𝐿𝐷𝐴 𝐾𝐿∙ where 𝑂𝑆 denotes original scores returned by the initial ranker and 𝜆 is a parameter that can be tuned with 𝜆 = 0 meaning no re-ranking is performed. Another scheme considers a multiplication combination to incorporate the original score. It does not need to tune any parameters: 𝑅𝑆2 = 𝑂𝑆 ∙ 𝑅𝑆𝐿𝐷𝐴 𝐾𝐿∙ This concludes our overview of the proposed latent re-ranking method. 4 Evaluation In this section, we will e</context>
<context position="22482" citStr="Zhang et al., 2005" startWordPosition="3806" endWordPosition="3809">ns. The relevance judgments are taken from the judged pool of top retrieved documents by various participating retrieval systems from previous CLEF workshops. We compare the proposed latent re-ranking method with four other approaches: the initial ranker, mentioned above, is a KL-divergence retrieval function using the language models. Three other baseline systems are: Kurland and Lee’s structural re-ranking approach (Recursive Weighted Influx + Language Model), chosen as it demonstrates the best performance in their paper (Kurland and Lee, 2005), Zhang et al.’s affinity graph-based approach (Zhang et al., 2005) 3 ftp://ftp.cs.cornell.edu/pub/smart/ 4 http://lucene.apache.org/ 5 http://trec.nist.gov/ and a variant of Kurland and Lee’s work with links in the graph calculated by the vector-space model (cosine similarity as mentioned in (Kurland and Lee, 2005)). We denote these four systems as InR, RWILM, AFF, and VEC respectively. Furthermore, we denote the permutations of our methods as follows: LDA1: RS2 with RS��� ��1, LDA2: RS1 with RS��� ��1 , LDA3: RS2 with RS��� ��2, LDA4: RS1 with RS��� ��2. Because the inconsistency of the evaluation metrics employed in the past work, we choose to employ all o</context>
<context position="28306" citStr="Zhang et al., 2005" startWordPosition="4809" endWordPosition="4812"> CLEF-2008 test collections. However, the performance over CLEF-2007 collection was somewhat disappointing. This seems to indicate that the language model induced graph method tends to perform better in sparse data rather than longer documents. Also Language Modeling requires large set training data to be effective, while the complexity of our method is only linear with number of topics and the number of documents for each iteration. The affinity and vector graph based methods demonstrated poor performance across all the collections. This may be due to the fact that the approach Zhang et al. (Zhang et al., 2005) developed focuses more on diversity and information richness and cares less about the precision of the retrieval results while asymmetric graph as constructed by the vector space model fails in capturing important relationship between the documents. Another observation we can draw from Table 2 is that the relative performance tends to be stable during test collections written in different languages. This shows a promising future for studying structure of the documents with respect to queries for re-ranking purpose. At the same time, efficiency is always an issue in all reranking methods. Alth</context>
</contexts>
<marker>Zhang, Li, Liu, Ji, Xi, Fan, 2005</marker>
<rawString>Benyu Zhang, Hua Li, Yi Liu, Lei Ji, Wensi Xi, Weiguo Fan, Zheng Chen and Wei-Ying Ma (2005). Improving web search results using affinity graph. In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, Salvador, Brazil, ACM. p. 504-511.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>