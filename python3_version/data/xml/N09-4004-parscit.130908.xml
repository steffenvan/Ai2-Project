<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.035987">
<title confidence="0.735348">
Extracting World and Linguistic Knowledge from Wikipedia
</title>
<note confidence="0.9366686">
Simone Paolo Ponzetto Michael Strube
Dept. of Computational Linguistics EML Research gGmbH
University of Heidelberg Schloss-Wolfsbrunnenweg 33
Heidelberg, Germany Heidelberg, Germany
http://www.cl.uni-heidelberg.de/˜ponzetto http://www.eml-research.de/˜strube
</note>
<sectionHeader confidence="0.587018" genericHeader="abstract">
Overview
</sectionHeader>
<bodyText confidence="0.99986875">
Many research efforts have been devoted to develop robust statistical modeling techniques for many NLP
tasks. Our Þeld is now moving towards more complex tasks (e.g. RTE, QA), which require to complement
these methods with a semantically rich representation based on world and linguistic knowledge (i.e. anno-
tated linguistic data). In this tutorial we show several approaches to extract this knowledge from Wikipedia.
This resource has attracted the attention of much work in the AI community, mainly because it provides
semi-structured information and a large amount of manual annotations. The purpose of this tutorial is to in-
troduce Wikipedia as a resource to the NLP community and to provide an introduction for NLP researchers
both from a scientiÞc and a practical (i.e. data acquisition and processing issues) perspective.
</bodyText>
<subsectionHeader confidence="0.541356">
Outline
</subsectionHeader>
<bodyText confidence="0.990754">
The tutorial is divided into three main parts:
</bodyText>
<listItem confidence="0.903120692307692">
1. Extracting world knowledge from Wikipedia. We review methods aiming at extracting fully struc-
tured world knowledge from the content of the online encyclopedia. We show how to take categories,
hyperlinks and infoboxes as building blocks for a semantic network with unlabeled relations between
the concepts. The task of taxonomy induction then boils down to labeling the relations between these
concepts, e.g. with isa, part-of, instance-of, located-in, etc. relations.
2. Leveraging linguistic knowledge from Wikipedia. Wikipedia provides shallow markup annotations
which can be interpreted as manual annotations of linguistic phenomena. These ‘annotations’ include
word boundaries, word senses, named entities, translations of concepts in many languages. Further-
more, Wikipedia can be used as a multilingual comparable corpus.
3. Future directions. Knowledge derived from Wikipedia has the potential to become a resource as
important for NLP as WordNet. Also the Wikipedia edit history provides a repository of linguistic
knowledge which is to be exploited. Potential applications of the knowledge implicitly encoded in the
edit history include spelling corrections, natural language generation, text summarization, etc.
</listItem>
<subsectionHeader confidence="0.899073">
Target audience
</subsectionHeader>
<bodyText confidence="0.9769855">
This tutorial is designed for students and researchers in Computer Science and Computational Linguistics.
No prior knowledge of information extraction topics is assumed.
</bodyText>
<page confidence="0.967481">
7
</page>
<reference confidence="0.575377555555556">
Proceedings of NAACL HLT 2009: Tutorials, pages 7–8,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
Speakers’ bios
Simone Paolo Ponzetto is an assistant professor at the Computational Linguistics Department of the Univer-
sity of Heidelberg, Germany. His main research interests lie in the area of information extraction, knowledge
acquisition and engineering, lexical semantics, and their application to discourse-based phenomena.
Michael Strube is group leader of the NLP group at EML Research, a privately funded research institute
in Heidelberg, Germany. The NLP group focuses on the areas of semantics, pragmatics and discourse and
applications like summarization and information extraction.
</reference>
<page confidence="0.997647">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.215419">
<title confidence="0.99887">Extracting World and Linguistic Knowledge from Wikipedia</title>
<author confidence="0.999747">Simone Paolo Michael</author>
<affiliation confidence="0.999918">Dept. of Computational EML Research University of Schloss-Wolfsbrunnenweg</affiliation>
<address confidence="0.943178">Heidelberg, Germany Heidelberg, Germany</address>
<web confidence="0.902941">http://www.cl.uni-heidelberg.de/˜ponzetto http://www.eml-research.de/˜strube</web>
<abstract confidence="0.750210714285714">Overview Many research efforts have been devoted to develop robust statistical modeling techniques for many NLP Our is now moving towards more complex tasks (e.g. RTE, QA), which require to complement these methods with a semantically rich representation based on world and linguistic knowledge (i.e. annotated linguistic data). In this tutorial we show several approaches to extract this knowledge from Wikipedia. This resource has attracted the attention of much work in the AI community, mainly because it provides semi-structured information and a large amount of manual annotations. The purpose of this tutorial is to in-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Proceedings of NAACL HLT 2009: Tutorials,</booktitle>
<pages>7--8</pages>
<marker></marker>
<rawString>Proceedings of NAACL HLT 2009: Tutorials, pages 7–8,</rawString>
</citation>
<citation valid="false">
<authors>
<author>Colorado Boulder</author>
</authors>
<title>c�2009 Association for Computational Linguistics Speakers’ bios Simone Paolo Ponzetto is an assistant professor at the Computational Linguistics Department of the University of Heidelberg, Germany. His main research interests lie in the area of information extraction, knowledge acquisition and engineering, lexical semantics, and their application to discourse-based phenomena.</title>
<date>2009</date>
<marker>Boulder, 2009</marker>
<rawString>Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Speakers’ bios Simone Paolo Ponzetto is an assistant professor at the Computational Linguistics Department of the University of Heidelberg, Germany. His main research interests lie in the area of information extraction, knowledge acquisition and engineering, lexical semantics, and their application to discourse-based phenomena.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michael</author>
</authors>
<title>Strube is group leader of the NLP group at EML Research, a privately funded research institute in Heidelberg, Germany. The NLP group focuses on the areas of semantics, pragmatics and discourse and applications like summarization and information extraction.</title>
<marker>Michael, </marker>
<rawString>Michael Strube is group leader of the NLP group at EML Research, a privately funded research institute in Heidelberg, Germany. The NLP group focuses on the areas of semantics, pragmatics and discourse and applications like summarization and information extraction.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>