<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.156823">
<title confidence="0.8444908">
The use of error tags in ARTFL&apos;s Encyclopedie:
Does good error identification lead to good error correction?
Derrick Higgins
Department of Linguistics
University of Chicago
</title>
<sectionHeader confidence="0.911924" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999914380952381">
Many corpora which are prime candidates
for automatic error correction, such as the
output of OCR software, and electronic texts
incorporating markup tags, include informa-
tion on which portions of the text are most
likely to contain errors.
This paper describes how the error
markup tag &lt;?&gt; is being incorporated in
the spell-checking of an electronic version
of Diderot&apos;s Encyclopedie, and evaluates
whether the presence of this tag has signif-
icantly aided in correcting the errors which
it marks. Although the usefulness of error
tagging may vary from project to project,
even as the precise way in which the tagging
is done varies, error tagging does not nec-
essarily confer any benefit in attempting to
correct a given word. It may, of course, nev-
ertheless be useful in marking errors to be
fixed manually at a later stage of processing
the text.
</bodyText>
<sectionHeader confidence="0.98768" genericHeader="categories and subject descriptors">
1 The Encyclopedie
</sectionHeader>
<subsectionHeader confidence="0.997554">
1.1 Project Overview
</subsectionHeader>
<bodyText confidence="0.995201882352941">
The goal of this project is ultimately to
detect and correct all errors in the elec-
tronic version of the 18th century French
encyclopedia of Diderot and d&apos;Alembert, a
corpus of ca. 18 million words. This text is
currently under development by the Project
for American and French Research on the
Treasury of the French Language (ARTFL);
a project overview and limited sample of
searchable text from the Encyclopedic are
available at:
http://humanities.uchicago.edu/ARTFL/projects/encyc/.
Andreev et al. (1999) also provides a
thorough summary of the goals and status
of the project.
The electronic text was largely transcribed
from the original, although parts of it were
produced by optical character recognition on
scanned images. Unfortunately, whether a
section of text was transcribed or produced
by OCR was not recorded at the time of data
capture, so that the error correction strategy
cannot be made sensitive to this parameter.
Judging from a small hand-checked section
of the text, the error rate is fairly low; about
one word in 40 contains an error. It should
also be added that the version of the text
with which I am working has already been
subjected to some corrective measures after
the initial data capture stage. For exam-
ple, common and easily identifiable mistakes
such as the word enfant showing up as en-
sant were simply globally repaired through-
out the text. (The original edition of the En-
cyclopedie made use of the sharp &apos;s&apos;, which
was often confused with an during data
entry—cf. Figure 1.)
At present, my focus is on non-word er-
ror detection and correction, although use of
word n-grams seems to be a fairly straight-
forward extension to allow for the kind of
context-sensitivity in error correction which
has been the focus of much recent work
(cf. Golding and Roth (1999), Mays et al.
(1991), Yarowsky (1995)).
The approach I am pursuing is an appli-
cation of Bayesian statistics. We treat the
process by which the electronic text was pro-
duced as a noisy channel, and take as our
goal the maximization of the probability of
each input word, given a string which is the
</bodyText>
<page confidence="0.998399">
30
</page>
<figureCaption confidence="0.9927265">
Figure 1: Example text from the Encyclopedie. Note the similarity between the &apos;f&apos; and the
problematic sharp &apos;s&apos; in signifie
</figureCaption>
<bodyText confidence="0.987426372093024">
ABSENT, adj. en :Omit , nific „en-gtarai qui-
conque eft .eloignk de fon domici e.
A nsrNr , c, matere de- prefcription, .fe (lir de ccini
qui eft dans tine autre prov-inee (Tile celle bit eft le
poirtlatur delonUritage. V. Pit Escru PTI PRE-
s N.r. Les obfens qui ie font pour 1&apos;inc6ric de ft.:zat
iCmt aput4s preens, pixie.: de commodis eortim agi tun
output of the noisy channel. If we repre-
sent the correct form by we, and the ob-
served form by w0, our goal can be described
as finding the we which maximizes p(welwo),
the probability that we is the intended form,
given that w, is the observed form.
By Bayes&apos; rule, this can be reduced to
the problem of maximizing P(%17c)P)(&apos;`). Of
course, the probability of the observed string
will be constant across all candidate correc-
tions, so the same we will also maximize
P(wo I wc)P(wc)
The term p(we) (the prior probability) can
be estimated by doing frequency counts on a
corpus. In this case, I am using an interpo-
lated model of Good-Turing smoothed word
and letter probabilities as the prior.
The term p(wolwe) is called the error
model. Intuitively, it quantifies the prob-
ability of certain kinds of errors resulting
from the noisy channel. It is implemented
as a confusion matrix, which associates a
probability with each input/output charac-
ter pair, representing the probability of the
input character being replaced by the out-
put character. These probabilities can be
estimated from a large corpus tagged for er-
rors, but since I do not have access to such
a source for this project, I needed to train
the matrix as described in Kernighan et al.
(1990).
Cf. Jurafsky and Martin (1999) for an in-
troduction to spelling correction using con-
fusion matrices, and Kukich (1992) for a sur-
vey of different strategies in spelling correc-
tion.
</bodyText>
<subsectionHeader confidence="0.980473">
1.2 Treatment of &lt;7&gt;
</subsectionHeader>
<bodyText confidence="0.9957911">
A number of different SGML-style tags are
currently used in the encoding of the En-
cyclopedie, ranging from form-related tags
such as &lt;i&gt; (for italic text), to semantic
markup tags such as &lt;art icle&gt;, to the error
tag &lt;?&gt;, the treatment of which is the focus
of this article. The data entry specification
for the project prescribes the use of &lt;?&gt; in
all cases in which the keyboard operator has
any doubt as to the identity of a printed
character, and also when symbols appear
in the text which cannot be represented in
the Latin-1 codepage (except for Greek text,
which is handled by other means). Other
instances of the &lt;7&gt; tag were produced as
indications of mistakes in OCR output.
Some examples of the use of the error tag
from the actual corpus include the following:
The first is a case where &lt;?&gt; was used to
mark an untypeable character. In the sec-
</bodyText>
<figure confidence="0.987354222222222">
&lt;?&gt;
&lt;?&gt;dans
ab&lt;?&gt;ci&lt;?&gt;&lt;?&gt;es
d&apos;autre&lt;?&gt;aladies
for a Hebrew
for dans
for J&apos;ai
for abscisses
for d&apos;autres maladies
</figure>
<page confidence="0.999794">
31
</page>
<bodyText confidence="0.999470402298851">
ond case, it was somehow inserted superflu-
ously (most likely by OCR). In the third row,
&lt;?&gt; stands in for a single missing character,
and in the fourth it does the same, but three
times in a single word. Finally, in the last
row the error tag indicates the omission of
multiple characters, and even a word bound-
ary.
In fact, as Table 1 shows, words which in-
clude the error tag generally have error types
which are more difficult to correct than av-
erage. Our confusion matrix-based approach
is best at handling substitutions (e.g., onfin
enfin), deletions (apellent appellent),
and insertions (asselain —+ ass elm), and can-
not correct words with multiple errors at al1.1
&amp;quot;Unrecoverable&amp;quot; errors are those in which no
&amp;quot;correction&amp;quot; is possible, for example, when
non-ASCII symbols occur in the original.
The fact that the error tag is used to code
such a wide variety of irregularities in the
corpus makes it difficult to incorporate into
our general error correction strategy. Since
&lt;7&gt; so often occurred as a replacement for a
single, missing character, however, I treated
it as a character in the language model, but
one with an extremely low probability, so
that any suggested correction would have to
get rid of it in order to appreciably increase
the probability of the word.
In short, &lt;?&gt; is included in the confusion
matrix as a character which may occur as the
result of interference from the noisy chan-
nel, but is highly unlikely to appear inde-
pendently in the language. This approach
ignores the many cases of multiple errors in-
dicated by the error tag, but these probably
pose too difficult a problem for this stage of
the project anyhow. The funding available
for the project does not currently allow us to
pursue the possibility of computer-aided er-
ror correction; rather, the program must cor-
rect as many errors as it can without human
intervention. Toward this end, we are will-
ing to sacrifice the ability to cope with more
&apos;Actually, it does have a mechanism for dealing
with cases such as ab&lt;?&gt;ci&lt;7&gt;&lt;?&gt;es, in which the
error tag occurs multiple times, but stands for a sin-
gle letter in each case.
esoteric error types in order to improve the
reliability of the system on other error types.
The actual performance of the spelling
correction algorithm on words which include
the error tag, while comparable to the per-
formance on other words, is perhaps not as
high as we might initially have hoped, given
that they were already tagged as errors. Of
the corrections suggested for words without
&lt;?&gt;, 47% were accurate, while of the cor-
rections suggested for words with &lt;7&gt;, 29%
were accurate.2 Actually, if we include cases
in which the program correctly identified an
error as &amp;quot;unrecoverable&amp;quot;, and opted to make
no change, the percentage for &lt;?&gt; sugges-
tions rises to 71%.
It may seem that these numbers in fact
undermine the thesis that the error tagging
in the Encyclopedic was not useful in error
correction. I.e., if the correction algorithm
exhibits the correct behavior on 47% of un-
tagged errors, and on 71% of tagged errors,
it seems that the tags are helping out some-
what. Actually, this is not the case. First,
we should not give the same weight to cor-
rect behavior on unrecoverable errors (which
means giving up on correction) and correct
behavior on other errors (which means actu-
ally finding the correct form). Second, the
tagged errors are often simply &apos;worse&apos; than
untagged errors, so that even if the OCR or
keyboard operator had made a guess at the
correct form, they would have easily been
identifiable as errors, and even errors of a
certain type. For example, I maintain that
the form ab&lt;?&gt;ci&lt;?&gt;&lt;7&gt;es would have been
no more difficult to correct had it occurred
instead as abfciffes.
</bodyText>
<sectionHeader confidence="0.984358" genericHeader="conclusions">
2 Conclusion
</sectionHeader>
<bodyText confidence="0.9975025">
In sum, the errors which are marked with
the &lt;?&gt; tag in the electronic version of the
</bodyText>
<footnote confidence="0.6596885">
21 admit that these numbers may seem low, but
bear in mind that the percentage reflects the accu-
racy of the first guess made by the system, since its
operation is required to be entirely automatic. Fur-
thermore, the correction task is made more difficult
by the fact that the corpus is an encyclopedia, which
contains more infrequent words and proper names
than most corpora.
</footnote>
<page confidence="0.993701">
32
</page>
<table confidence="0.9991626">
Substitution Deletion Insertion Word- Multiple Unrecoverable
breaking
Contains &lt;7&gt; 37.4% 0% 2.2% 0% 16.5% 44%
Does not 58.5% 11.6% 6.8% 12.9% 10.2% 0%
contain &lt;7&gt;
</table>
<tableCaption confidence="0.999911">
Table 1: Breakdown of error types, according to whether the word contains &lt;?&gt;
</tableCaption>
<bodyText confidence="0.999705285714286">
Ency clop edie encompass so many distinct er-
ror types, and errors of such difficulty, that
it is hard to come up with corrections for
many of them without human intervention.
For this reason, experience with the Ency-
clopedie project suggests that error tagging
is not necessarily a great aid in performing
automatic error correction.
There is certainly a great deal of room for
further investigation into the use of meta-
data in spelling correction in general, how-
ever. While the error tag is a somewhat
unique member of the tagset, in that it typ-
ically flags a subpart of a word, rather than
a string of words, this should not be taken
to mean that it is the only tag which could
be employed in spelling correction. If noth-
ing else, &amp;quot;wider-scope&amp;quot; markup tags can be
helpful in determining when certain parts of
the corpus should not be seen as represen-
tative of the language model, or should be
seen as representative of a distinct language
model. (For example, the italic tag &lt;i&gt;. of-
ten marks Latin text in the Encyclopedie.)
Ultimately, I believe that what is needed
in order for text tagging to be useful in er-
ror correction is a recognition that the tagset
will influence the correction process. Tags
which are applied in such a way as to de-
limit sections of text which are relevant to
correction (such as names, equations, and
foreign language text), will be of greater use
than tags which represent a mixture of such
classes. Error tagging in particular should
be most useful if it does not conflate quite
distinct things that may be &amp;quot;wrong&amp;quot; with
a text, such as illegibility of the original,
unrenderable symbols, and OCR inaccura-
cies. Such considerations are certainly rele-
vant in the evaluation of emerging text en-
coding standards, such as the specification
of the Text Encoding Initiative.
</bodyText>
<sectionHeader confidence="0.998308" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999795">
Leonid Andreev, Jack Iverson, and Mark
Olsen. 1999. Re-engineering a war-
machine: ARTFL&apos;s Encyclopedie. Liter-
ary and Linguistic Computing, 14(1):11-
28.
Denis Diderot and Jean Le Rond
d&apos;Alembert, editors. 1976 [1751-1765].
Encyclopedie, ou Dictionnaire raisonne
des sciences, des arts et des métiers. Re-
search Publications, New Haven, Conn.
Microfilm.
Andrew R. Golding and Dan Roth. 1999.
A winnow-based approach to context-
sensitive spelling correction. Machine
Learning, 34(1):107-130.
Daniel Jurafsky and James Martin. 1999.
Speech and Language Processing: An In-
troduction to Speech Recognition, Natural
Language Processing and Computational
Linguistics. Prentice Hall.
M. D. Kernighan, K. W. Church, and W. A.
Gale. 1990. A spelling correction program
based on a noisy channel model. In Pro-
ceedings of the 13th International Confer-
ence on Computational Linguistics (COL-
INC &apos;90), volume 2, pages 205-211.
Karen Kukich. 1992. Techniques for auto-
matically correcting words in text. ACM
Computing Surveys, 24(4):377-439.
Eric Mays, Fred J. Damerau, and Robert L.
Mercer. 1991. Context based spelling cor-
rection. Information Processing &amp; Man-
agement, 27(5):517-522.
David Yarowsky. 1995. Unsupervised word
sense disambiguation rivaling supervised
methods. In Proceedings of the 33rd An-
</reference>
<page confidence="0.986849">
33
</page>
<reference confidence="0.900036">
nual Meeting of the Association for Com-
putational Linguistics, volume 33, pages
189-196.
</reference>
<page confidence="0.999164">
34
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.045532">
<title confidence="0.983929">use of error tags in ARTFL&apos;s Does good error identification lead to good error correction?</title>
<author confidence="0.999805">Derrick Higgins</author>
<affiliation confidence="0.999656">Department of Linguistics University of Chicago</affiliation>
<abstract confidence="0.999415163265307">Many corpora which are prime candidates for automatic error correction, such as the output of OCR software, and electronic texts incorporating markup tags, include information on which portions of the text are most likely to contain errors. This paper describes how the error markup tag &lt;?&gt; is being incorporated in the spell-checking of an electronic version Diderot&apos;s evaluates whether the presence of this tag has signifaided in errors which it marks. Although the usefulness of error tagging may vary from project to project, even as the precise way in which the tagging done varies, error tagging does necany benefit in attempting to correct a given word. It may, of course, nevertheless be useful in marking errors to be fixed manually at a later stage of processing the text. The 1.1 Project Overview The goal of this project is ultimately to detect and correct all errors in the electronic version of the 18th century French encyclopedia of Diderot and d&apos;Alembert, a corpus of ca. 18 million words. This text is currently under development by the Project for American and French Research on the Treasury of the French Language (ARTFL); a project overview and limited sample of text from the available at: http://humanities.uchicago.edu/ARTFL/projects/encyc/. Andreev et al. (1999) also provides a thorough summary of the goals and status of the project. The electronic text was largely transcribed from the original, although parts of it were produced by optical character recognition on scanned images. Unfortunately, whether a section of text was transcribed or produced by OCR was not recorded at the time of data capture, so that the error correction strategy cannot be made sensitive to this parameter. Judging from a small hand-checked section of the text, the error rate is fairly low; about one word in 40 contains an error. It should also be added that the version of the text with which I am working has already been subjected to some corrective measures after the initial data capture stage. For example, common and easily identifiable mistakes as the word up as ensant were simply globally repaired throughthe text. (The original edition of the Enuse of the sharp &apos;s&apos;, which was often confused with an during data entry—cf. Figure 1.) At present, my focus is on non-word error detection and correction, although use of word n-grams seems to be a fairly straightforward extension to allow for the kind of context-sensitivity in error correction which has been the focus of much recent work (cf. Golding and Roth (1999), Mays et al. (1991), Yarowsky (1995)). The approach I am pursuing is an application of Bayesian statistics. We treat the process by which the electronic text was produced as a noisy channel, and take as our goal the maximization of the probability of each input word, given a string which is the 30 1: Example text from the the similarity between the &apos;f&apos; and the sharp &apos;s&apos; in adj. :Omit „en-gtarai quiconque eft .eloignk de fon domici e. nsrNr , c, deprefcription, .fe de eft dans tine autre (Tile celle bit eft le delonUritage. V. Pit Escru Les ie pour 1&apos;inc6ric preens, de commodis eortim agi tun output of the noisy channel. If we reprethe correct form by and the obform by our goal can be described finding the which maximizes probability that is the intended form, given that w, is the observed form. By Bayes&apos; rule, this can be reduced to problem of maximizing Of course, the probability of the observed string will be constant across all candidate correcso the same will also maximize wc)P(wc) term can be estimated by doing frequency counts on a corpus. In this case, I am using an interpolated model of Good-Turing smoothed word and letter probabilities as the prior. term called the it quantifies the probability of certain kinds of errors resulting from the noisy channel. It is implemented as a confusion matrix, which associates a probability with each input/output character pair, representing the probability of the input character being replaced by the output character. These probabilities can be estimated from a large corpus tagged for errors, but since I do not have access to such a source for this project, I needed to train the matrix as described in Kernighan et al. (1990). Cf. Jurafsky and Martin (1999) for an introduction to spelling correction using confusion matrices, and Kukich (1992) for a survey of different strategies in spelling correction. Treatment of A number of different SGML-style tags are used in the encoding of the Enfrom form-related tags such as &lt;i&gt; (for italic text), to semantic tags such as icle&gt;, the error tag &lt;?&gt;, the treatment of which is the focus of this article. The data entry specification for the project prescribes the use of &lt;?&gt; in all cases in which the keyboard operator has any doubt as to the identity of a printed character, and also when symbols appear in the text which cannot be represented in the Latin-1 codepage (except for Greek text, which is handled by other means). Other instances of the &lt;7&gt; tag were produced as indications of mistakes in OCR output. Some examples of the use of the error tag from the actual corpus include the following: The first is a case where &lt;?&gt; was used to an untypeable character. In the sec- &lt;?&gt; &lt;?&gt;dans ab&lt;?&gt;ci&lt;?&gt;&lt;?&gt;es d&apos;autre&lt;?&gt;aladies for a Hebrew maladies 31 ond case, it was somehow inserted superfluously (most likely by OCR). In the third row, &lt;?&gt; stands in for a single missing character, and in the fourth it does the same, but three times in a single word. Finally, in the last row the error tag indicates the omission of multiple characters, and even a word boundary. In fact, as Table 1 shows, words which include the error tag generally have error types which are more difficult to correct than average. Our confusion matrix-based approach best at handling substitutions (e.g., appellent), insertions —+ ass elm), cancorrect words with multiple errors at &amp;quot;Unrecoverable&amp;quot; errors are those in which no &amp;quot;correction&amp;quot; is possible, for example, when non-ASCII symbols occur in the original. The fact that the error tag is used to code such a wide variety of irregularities in the corpus makes it difficult to incorporate into our general error correction strategy. Since &lt;7&gt; so often occurred as a replacement for a single, missing character, however, I treated it as a character in the language model, but one with an extremely low probability, so that any suggested correction would have to get rid of it in order to appreciably increase the probability of the word. In short, &lt;?&gt; is included in the confusion matrix as a character which may occur as the result of interference from the noisy channel, but is highly unlikely to appear independently in the language. This approach ignores the many cases of multiple errors indicated by the error tag, but these probably pose too difficult a problem for this stage of the project anyhow. The funding available for the project does not currently allow us to pursue the possibility of computer-aided error correction; rather, the program must correct as many errors as it can without human intervention. Toward this end, we are willing to sacrifice the ability to cope with more &apos;Actually, it does have a mechanism for dealing cases such as which the error tag occurs multiple times, but stands for a single letter in each case. esoteric error types in order to improve the reliability of the system on other error types. The actual performance of the spelling correction algorithm on words which include the error tag, while comparable to the performance on other words, is perhaps not as high as we might initially have hoped, given that they were already tagged as errors. Of the corrections suggested for words without &lt;?&gt;, 47% were accurate, while of the corrections suggested for words with &lt;7&gt;, 29% Actually, if we include cases in which the program correctly identified an error as &amp;quot;unrecoverable&amp;quot;, and opted to make no change, the percentage for &lt;?&gt; suggestions rises to 71%. It may seem that these numbers in fact undermine the thesis that the error tagging the not useful in error correction. I.e., if the correction algorithm exhibits the correct behavior on 47% of untagged errors, and on 71% of tagged errors, it seems that the tags are helping out somewhat. Actually, this is not the case. First, we should not give the same weight to correct behavior on unrecoverable errors (which means giving up on correction) and correct behavior on other errors (which means actually finding the correct form). Second, the tagged errors are often simply &apos;worse&apos; than untagged errors, so that even if the OCR or keyboard operator had made a guess at the correct form, they would have easily been identifiable as errors, and even errors of a certain type. For example, I maintain that form have been no more difficult to correct had it occurred as 2 Conclusion In sum, the errors which are marked with the &lt;?&gt; tag in the electronic version of the admit that these numbers may seem low, but bear in mind that the percentage reflects the accuof the guess by the system, since its operation is required to be entirely automatic. Furthermore, the correction task is made more difficult by the fact that the corpus is an encyclopedia, which contains more infrequent words and proper names than most corpora. 32 Substitution Deletion Insertion Wordbreaking Multiple Unrecoverable Contains &lt;7&gt; 37.4% 0% 2.2% 0% 16.5% 44% Does not contain &lt;7&gt; 58.5% 11.6% 6.8% 12.9% 10.2% 0% Table 1: Breakdown of error types, according to whether the word contains &lt;?&gt; clop edie so many distinct error types, and errors of such difficulty, that it is hard to come up with corrections for many of them without human intervention. this reason, experience with the Encysuggests that error tagging is not necessarily a great aid in performing automatic error correction. There is certainly a great deal of room for further investigation into the use of metadata in spelling correction in general, however. While the error tag is a somewhat unique member of the tagset, in that it typically flags a subpart of a word, rather than a string of words, this should not be taken to mean that it is the only tag which could be employed in spelling correction. If nothing else, &amp;quot;wider-scope&amp;quot; markup tags can be helpful in determining when certain parts of the corpus should not be seen as representative of the language model, or should be seen as representative of a distinct language model. (For example, the italic tag &lt;i&gt;. ofmarks Latin text in the Ultimately, I believe that what is needed in order for text tagging to be useful in error correction is a recognition that the tagset will influence the correction process. Tags which are applied in such a way as to delimit sections of text which are relevant to correction (such as names, equations, and foreign language text), will be of greater use than tags which represent a mixture of such classes. Error tagging in particular should be most useful if it does not conflate quite distinct things that may be &amp;quot;wrong&amp;quot; with a text, such as illegibility of the original, unrenderable symbols, and OCR inaccuracies. Such considerations are certainly relevant in the evaluation of emerging text encoding standards, such as the specification of the Text Encoding Initiative.</abstract>
<note confidence="0.912329903225807">References Leonid Andreev, Jack Iverson, and Mark Olsen. 1999. Re-engineering a war- Encyclopedie. Literand Linguistic Computing, 14(1):11- 28. Denis Diderot and Jean Le Rond d&apos;Alembert, editors. 1976 [1751-1765]. Encyclopedie, ou Dictionnaire raisonne sciences, des arts et des métiers. Research Publications, New Haven, Conn. Microfilm. Andrew R. Golding and Dan Roth. 1999. A winnow-based approach to contextspelling correction. Daniel Jurafsky and James Martin. 1999. Speech and Language Processing: An Introduction to Speech Recognition, Natural Language Processing and Computational Hall. M. D. Kernighan, K. W. Church, and W. A. Gale. 1990. A spelling correction program on a noisy channel model. In Proceedings of the 13th International Conference on Computational Linguistics (COL- &apos;90), 2, pages 205-211. Karen Kukich. 1992. Techniques for autocorrecting words in text. Surveys, Eric Mays, Fred J. Damerau, and Robert L. Mercer. 1991. Context based spelling cor-</note>
<title confidence="0.768711">Processing &amp; Man-</title>
<author confidence="0.81507">Unsupervised word</author>
<abstract confidence="0.382755333333333">sense disambiguation rivaling supervised In of the 33rd An- 33 nual Meeting of the Association for Com- Linguistics, 33, pages 189-196.</abstract>
<intro confidence="0.715011">34</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Leonid Andreev</author>
<author>Jack Iverson</author>
<author>Mark Olsen</author>
</authors>
<title>Re-engineering a warmachine: ARTFL&apos;s Encyclopedie.</title>
<date>1999</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>14--1</pages>
<contexts>
<context position="1580" citStr="Andreev et al. (1999)" startWordPosition="247" endWordPosition="250">ing errors to be fixed manually at a later stage of processing the text. 1 The Encyclopedie 1.1 Project Overview The goal of this project is ultimately to detect and correct all errors in the electronic version of the 18th century French encyclopedia of Diderot and d&apos;Alembert, a corpus of ca. 18 million words. This text is currently under development by the Project for American and French Research on the Treasury of the French Language (ARTFL); a project overview and limited sample of searchable text from the Encyclopedic are available at: http://humanities.uchicago.edu/ARTFL/projects/encyc/. Andreev et al. (1999) also provides a thorough summary of the goals and status of the project. The electronic text was largely transcribed from the original, although parts of it were produced by optical character recognition on scanned images. Unfortunately, whether a section of text was transcribed or produced by OCR was not recorded at the time of data capture, so that the error correction strategy cannot be made sensitive to this parameter. Judging from a small hand-checked section of the text, the error rate is fairly low; about one word in 40 contains an error. It should also be added that the version of the</context>
</contexts>
<marker>Andreev, Iverson, Olsen, 1999</marker>
<rawString>Leonid Andreev, Jack Iverson, and Mark Olsen. 1999. Re-engineering a warmachine: ARTFL&apos;s Encyclopedie. Literary and Linguistic Computing, 14(1):11-28.</rawString>
</citation>
<citation valid="true">
<date>1976</date>
<booktitle>Encyclopedie, ou Dictionnaire raisonne des sciences, des arts et des métiers. Research Publications,</booktitle>
<pages>1751--1765</pages>
<editor>Denis Diderot and Jean Le Rond d&apos;Alembert, editors.</editor>
<location>New Haven, Conn. Microfilm.</location>
<marker>1976</marker>
<rawString>Denis Diderot and Jean Le Rond d&apos;Alembert, editors. 1976 [1751-1765]. Encyclopedie, ou Dictionnaire raisonne des sciences, des arts et des métiers. Research Publications, New Haven, Conn. Microfilm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
<author>Dan Roth</author>
</authors>
<title>A winnow-based approach to contextsensitive spelling correction.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--1</pages>
<contexts>
<context position="2869" citStr="Golding and Roth (1999)" startWordPosition="468" endWordPosition="471">orrective measures after the initial data capture stage. For example, common and easily identifiable mistakes such as the word enfant showing up as ensant were simply globally repaired throughout the text. (The original edition of the Encyclopedie made use of the sharp &apos;s&apos;, which was often confused with an during data entry—cf. Figure 1.) At present, my focus is on non-word error detection and correction, although use of word n-grams seems to be a fairly straightforward extension to allow for the kind of context-sensitivity in error correction which has been the focus of much recent work (cf. Golding and Roth (1999), Mays et al. (1991), Yarowsky (1995)). The approach I am pursuing is an application of Bayesian statistics. We treat the process by which the electronic text was produced as a noisy channel, and take as our goal the maximization of the probability of each input word, given a string which is the 30 Figure 1: Example text from the Encyclopedie. Note the similarity between the &apos;f&apos; and the problematic sharp &apos;s&apos; in signifie ABSENT, adj. en :Omit , nific „en-gtarai quiconque eft .eloignk de fon domici e. A nsrNr , c, matere de- prefcription, .fe (lir de ccini qui eft dans tine autre prov-inee (Tile</context>
</contexts>
<marker>Golding, Roth, 1999</marker>
<rawString>Andrew R. Golding and Dan Roth. 1999. A winnow-based approach to contextsensitive spelling correction. Machine Learning, 34(1):107-130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James Martin</author>
</authors>
<title>Speech and Language Processing: An Introduction to Speech Recognition, Natural Language Processing and Computational Linguistics.</title>
<date>1999</date>
<publisher>Prentice Hall.</publisher>
<contexts>
<context position="4928" citStr="Jurafsky and Martin (1999)" startWordPosition="830" endWordPosition="833">ter probabilities as the prior. The term p(wolwe) is called the error model. Intuitively, it quantifies the probability of certain kinds of errors resulting from the noisy channel. It is implemented as a confusion matrix, which associates a probability with each input/output character pair, representing the probability of the input character being replaced by the output character. These probabilities can be estimated from a large corpus tagged for errors, but since I do not have access to such a source for this project, I needed to train the matrix as described in Kernighan et al. (1990). Cf. Jurafsky and Martin (1999) for an introduction to spelling correction using confusion matrices, and Kukich (1992) for a survey of different strategies in spelling correction. 1.2 Treatment of &lt;7&gt; A number of different SGML-style tags are currently used in the encoding of the Encyclopedie, ranging from form-related tags such as &lt;i&gt; (for italic text), to semantic markup tags such as &lt;art icle&gt;, to the error tag &lt;?&gt;, the treatment of which is the focus of this article. The data entry specification for the project prescribes the use of &lt;?&gt; in all cases in which the keyboard operator has any doubt as to the identity of a pr</context>
</contexts>
<marker>Jurafsky, Martin, 1999</marker>
<rawString>Daniel Jurafsky and James Martin. 1999. Speech and Language Processing: An Introduction to Speech Recognition, Natural Language Processing and Computational Linguistics. Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M D Kernighan</author>
<author>K W Church</author>
<author>W A Gale</author>
</authors>
<title>A spelling correction program based on a noisy channel model.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics (COLINC &apos;90),</booktitle>
<volume>2</volume>
<pages>205--211</pages>
<contexts>
<context position="4896" citStr="Kernighan et al. (1990)" startWordPosition="825" endWordPosition="828">-Turing smoothed word and letter probabilities as the prior. The term p(wolwe) is called the error model. Intuitively, it quantifies the probability of certain kinds of errors resulting from the noisy channel. It is implemented as a confusion matrix, which associates a probability with each input/output character pair, representing the probability of the input character being replaced by the output character. These probabilities can be estimated from a large corpus tagged for errors, but since I do not have access to such a source for this project, I needed to train the matrix as described in Kernighan et al. (1990). Cf. Jurafsky and Martin (1999) for an introduction to spelling correction using confusion matrices, and Kukich (1992) for a survey of different strategies in spelling correction. 1.2 Treatment of &lt;7&gt; A number of different SGML-style tags are currently used in the encoding of the Encyclopedie, ranging from form-related tags such as &lt;i&gt; (for italic text), to semantic markup tags such as &lt;art icle&gt;, to the error tag &lt;?&gt;, the treatment of which is the focus of this article. The data entry specification for the project prescribes the use of &lt;?&gt; in all cases in which the keyboard operator has any </context>
</contexts>
<marker>Kernighan, Church, Gale, 1990</marker>
<rawString>M. D. Kernighan, K. W. Church, and W. A. Gale. 1990. A spelling correction program based on a noisy channel model. In Proceedings of the 13th International Conference on Computational Linguistics (COLINC &apos;90), volume 2, pages 205-211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Kukich</author>
</authors>
<title>Techniques for automatically correcting words in text.</title>
<date>1992</date>
<journal>ACM Computing Surveys,</journal>
<pages>24--4</pages>
<contexts>
<context position="5015" citStr="Kukich (1992)" startWordPosition="846" endWordPosition="847">ies the probability of certain kinds of errors resulting from the noisy channel. It is implemented as a confusion matrix, which associates a probability with each input/output character pair, representing the probability of the input character being replaced by the output character. These probabilities can be estimated from a large corpus tagged for errors, but since I do not have access to such a source for this project, I needed to train the matrix as described in Kernighan et al. (1990). Cf. Jurafsky and Martin (1999) for an introduction to spelling correction using confusion matrices, and Kukich (1992) for a survey of different strategies in spelling correction. 1.2 Treatment of &lt;7&gt; A number of different SGML-style tags are currently used in the encoding of the Encyclopedie, ranging from form-related tags such as &lt;i&gt; (for italic text), to semantic markup tags such as &lt;art icle&gt;, to the error tag &lt;?&gt;, the treatment of which is the focus of this article. The data entry specification for the project prescribes the use of &lt;?&gt; in all cases in which the keyboard operator has any doubt as to the identity of a printed character, and also when symbols appear in the text which cannot be represented i</context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>Karen Kukich. 1992. Techniques for automatically correcting words in text. ACM Computing Surveys, 24(4):377-439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Mays</author>
<author>Fred J Damerau</author>
<author>Robert L Mercer</author>
</authors>
<title>Context based spelling correction.</title>
<date>1991</date>
<booktitle>Information Processing &amp; Management,</booktitle>
<pages>27--5</pages>
<contexts>
<context position="2889" citStr="Mays et al. (1991)" startWordPosition="472" endWordPosition="475">the initial data capture stage. For example, common and easily identifiable mistakes such as the word enfant showing up as ensant were simply globally repaired throughout the text. (The original edition of the Encyclopedie made use of the sharp &apos;s&apos;, which was often confused with an during data entry—cf. Figure 1.) At present, my focus is on non-word error detection and correction, although use of word n-grams seems to be a fairly straightforward extension to allow for the kind of context-sensitivity in error correction which has been the focus of much recent work (cf. Golding and Roth (1999), Mays et al. (1991), Yarowsky (1995)). The approach I am pursuing is an application of Bayesian statistics. We treat the process by which the electronic text was produced as a noisy channel, and take as our goal the maximization of the probability of each input word, given a string which is the 30 Figure 1: Example text from the Encyclopedie. Note the similarity between the &apos;f&apos; and the problematic sharp &apos;s&apos; in signifie ABSENT, adj. en :Omit , nific „en-gtarai quiconque eft .eloignk de fon domici e. A nsrNr , c, matere de- prefcription, .fe (lir de ccini qui eft dans tine autre prov-inee (Tile celle bit eft le po</context>
</contexts>
<marker>Mays, Damerau, Mercer, 1991</marker>
<rawString>Eric Mays, Fred J. Damerau, and Robert L. Mercer. 1991. Context based spelling correction. Information Processing &amp; Management, 27(5):517-522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>33</volume>
<pages>189--196</pages>
<contexts>
<context position="2906" citStr="Yarowsky (1995)" startWordPosition="476" endWordPosition="477">ture stage. For example, common and easily identifiable mistakes such as the word enfant showing up as ensant were simply globally repaired throughout the text. (The original edition of the Encyclopedie made use of the sharp &apos;s&apos;, which was often confused with an during data entry—cf. Figure 1.) At present, my focus is on non-word error detection and correction, although use of word n-grams seems to be a fairly straightforward extension to allow for the kind of context-sensitivity in error correction which has been the focus of much recent work (cf. Golding and Roth (1999), Mays et al. (1991), Yarowsky (1995)). The approach I am pursuing is an application of Bayesian statistics. We treat the process by which the electronic text was produced as a noisy channel, and take as our goal the maximization of the probability of each input word, given a string which is the 30 Figure 1: Example text from the Encyclopedie. Note the similarity between the &apos;f&apos; and the problematic sharp &apos;s&apos; in signifie ABSENT, adj. en :Omit , nific „en-gtarai quiconque eft .eloignk de fon domici e. A nsrNr , c, matere de- prefcription, .fe (lir de ccini qui eft dans tine autre prov-inee (Tile celle bit eft le poirtlatur delonUri</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, volume 33, pages 189-196.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>