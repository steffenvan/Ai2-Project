<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001653">
<title confidence="0.875606">
MATREX: The DCU MT System for WMT 2010
</title>
<author confidence="0.987875">
Sergio Penkale, Rejwanul Haque, Sandipan Dandapat, Pratyush Banerjee, Ankit K. Srivastava,
Jinhua Du, Pavel Pecina, Sudip Kumar Naskar, Mikel L. Forcada, Andy Way
</author>
<affiliation confidence="0.9887685">
CNGL, School of Computing
Dublin City University, Dublin 9, Ireland
</affiliation>
<email confidence="0.397586">
{ spenkale, rhaque, sdandapat, pbanerjee, asrivastava, jdu, ppecina, snaskar, mforcada, away }@computing.dcu.ie
</email>
<page confidence="0.829593">
143
</page>
<sectionHeader confidence="0.954718" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999916">
This paper describes the DCU machine
translation system in the evaluation cam-
paign of the Joint Fifth Workshop on Sta-
tistical Machine Translation and Metrics
in ACL-2010. We describe the modular
design of our multi-engine machine trans-
lation (MT) system with particular focus
on the components used in this partici-
pation. We participated in the English–
Spanish and English–Czech translation
tasks, in which we employed our multi-
engine architecture to translate. We also
participated in the system combination
task which was carried out by the MBR
decoder and confusion network decoder.
</bodyText>
<sectionHeader confidence="0.995163" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999981513513513">
In this paper, we present the DCU multi-engine
MT system MATREX (Machine Translation using
Examples). This system exploits example-based
MT, statistical MT (SMT), and system combina-
tion techniques.
We participated in the English–Spanish (en–
es) and English–Czech (en–cs) translation
tasks. For these two tasks, we employ several
individual MT systems: 1) Baseline: phrase-
based SMT (Koehn et al., 2007); 2) EBMT:
Monolingually chunking both source and target
sides of the dataset using a marker-based chunker
(Gough and Way, 2004); 3) Factored translation
model (Koehn and Hoang, 2007); 4) Source-side
context-informed (SSCI) systems (Stroppa et al.,
2007); 5) the moses-chart (a Moses imple-
mentation of the hierarchical phrase-based (HPB)
approach of Chiang (2007)) and 6) Apertium (For-
cada et al., 2009) rule-based machine translation
(RBMT). Finally, we use a word-level combina-
tion framework (Rosti et al., 2007) to combine the
multiple translation hypotheses and employ a new
rescoring model to generate the final translation.
For the system combination task, we first use
the minimum Bayes-risk (MBR) (Kumar and
Byrne, 2004) decoder to select the best hypoth-
esis as the alignment reference for the confusion
network (CN) (Mangu et al., 2000). We then build
the CN using the TER metric (Snover et al., 2006),
and finally search for the best translation.
The remainder of this paper is organised as fol-
lows: Section 2 details the various components of
our system, in particular the multi-engine strate-
gies used for the shared task. In Section 3, we
outline the complete system setup for the shared
task and provide evaluation results on the test set.
Section 4 concludes the paper.
</bodyText>
<sectionHeader confidence="0.979847" genericHeader="method">
2 The MATREX System
</sectionHeader>
<subsectionHeader confidence="0.980166">
2.1 System Architecture
</subsectionHeader>
<bodyText confidence="0.999980583333333">
The MATREX system is a combination-based
multi-engine architecture, which exploits as-
pects of both the EBMT and SMT paradigms.
The architecture includes various individual sys-
tems: phrase-based, example-based, hierarchical
phrase-based and tree-based MT.
The combination structure uses the MBR and
CN decoders, and is based on a word-level com-
bination strategy (Du et al., 2009). In the final
stage, we use a new rescoring module to process
the N-best list generated by the combination mod-
ule. Figure 1 illustrates the architecture.
</bodyText>
<subsectionHeader confidence="0.999149">
2.2 Example-Based Machine Translation
</subsectionHeader>
<bodyText confidence="0.999680833333333">
The EBMT system uses a language-specific, re-
duced set of closed-class marker morphemes or
lexemes (Gough and Way, 2004) to define a way
to segment sentences into chunks, which are then
aligned using an edit-distance-style algorithm, in
which edit costs depend on word-to-word transla-
</bodyText>
<note confidence="0.966344">
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 143–148,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999888">
Figure 1: System Framework.
</figureCaption>
<bodyText confidence="0.999507666666667">
tion probabilities and the amount of word-to-word
cognates (Stroppa and Way, 2006).
Once these phrase pairs were obtained they
were merged with the phrase pairs extracted by
the baseline system adding word alignment infor-
mation.
</bodyText>
<subsectionHeader confidence="0.999108">
2.3 Apertium RBMT
</subsectionHeader>
<bodyText confidence="0.999780666666667">
Apertium1 is a free/open-source platform for
RBMT. The current version of the en–es system
in Apertium was used for the system combination
task (section 2.7), and its morphological analysers
and part-of-speech taggers were used to build a
factored Moses model.
</bodyText>
<subsectionHeader confidence="0.985109">
2.4 Factored Translation Model
</subsectionHeader>
<bodyText confidence="0.999951083333333">
We also used a factored model for the en–es
translation task. Factored models (Koehn and
Hoang, 2007) facilitate the translation by break-
ing it down into several factors which are further
combined using a log-linear model (Och and Ney,
2002).
We used three factors in our factored translation
model, which are used in two different decoding
paths: a surface form (SF) to SF translation factor,
a lemma to lemma translation factor, and a part-of-
speech (PoS) to PoS translation factor.
Finally, we used two decoding paths based on
</bodyText>
<footnote confidence="0.878941">
1http://www.apertium.org
</footnote>
<bodyText confidence="0.999622333333333">
the above three translation factors: an SF to SF
decoding path and a path which maps lemma to
lemma, PoS to PoS, and an SF generated using
the TL lemma and PoS. The lemmas and PoS for
en and es were obtained using Apertium (sec-
tion 2.3).
</bodyText>
<subsectionHeader confidence="0.99924">
2.5 Source-Side Context-informed PB-SMT
</subsectionHeader>
<bodyText confidence="0.988105">
One natural way to express a context-informed
feature (hMBL) is to view it as the conditional
probability of the target phrases (ek) given the
source phrase ( fk) and its source-side context in-
formation (CI):
</bodyText>
<equation confidence="0.8152">
hMBL = log P(ek A, CI( A)) (1)
</equation>
<bodyText confidence="0.986620708333333">
We use a memory-based machine learning
(MBL) classifier (TRIBL:2 Daelemans and
van den Bosch (2005)) that is able to estimate
P(�ek|�fk, CI( fk)) by similarity-based reasoning
over memorized nearest-neighbour examples of
source–target phrase translations. In equation (1),
SSCI may include any feature (lexical, syntactic,
etc.), which can provide useful information to
disambiguate a given source phrase. In addition
to using local words and PoS-tags as features,
as in (Stroppa et al., 2007), we incorporate
grammatical dependency relations (Haque et al.,
2009a) and supertags (Haque et al., 2009b) as
syntactic source context features in the log-linear
PB-SMT model.
In addition to the above feature, we derived a
simple binary feature hbest, defined in (2):
�
1 if ek maximizes P(N fk, CI(fk))
hbest = 0 otherwise
(2)
We performed experiments by integrating these
two features, hMBL and hbest, directly into the
log-linear framework of Moses.
</bodyText>
<subsectionHeader confidence="0.991239">
2.6 Hierarchical PB-SMT model
</subsectionHeader>
<bodyText confidence="0.846431545454546">
For the en–cs translation task, we built
a weighted synchronous context-free grammar
model (Chiang, 2007) of translation that uses
the bilingual phrase pairs of PB-SMT as a start-
ing point to learn hierarchical rules. We used
the open-source Tree-Based translation system
moses-chart3 to perform this experiment.
2An implementation of TRIBL is freely available as part
of the TiMBL software package, which can be downloaded
from http://ilk.uvt.nl/timbl
144 3http://www.statmt.org/moses/?n=Moses.SyntaxTutorial
</bodyText>
<subsectionHeader confidence="0.980051">
2.7 System Combination
</subsectionHeader>
<bodyText confidence="0.999784">
For multiple system combination, we used an
MBR-CN framework (Du et al., 2009, 2010) as
shown in Figure 1. Due to the varying word or-
der in the MT hypotheses, it is essential to define
the backbone which determines the general word
order of the CN. Instead of using a single system
output as the skeleton, we employ an MBR de-
coder to select the best single system output Er
from the merged N-best list by minimizing the
BLEU (Papineni et al., 2002) loss, as in (3):
</bodyText>
<equation confidence="0.972088">
(1 − BLEU(Ej, Ei)) (3)
</equation>
<bodyText confidence="0.999896769230769">
where Ns indicates the number of translations in
the merged N-best list, and {Ei�Ns i=1are the trans-
lations themselves. In our task, we only merge the
1-best output of each individual system.
The CN is built by aligning other hypotheses
against the backbone, based on the TER metric.
Null words are allowed in the alignment. Ei-
ther votes or different confidence measures are as-
signed to each word in the network. Each arc in
the CN represents an alternative word at that po-
sition in the sentence and the number of votes for
each word is counted when constructing the net-
work. The features we used are as follows:
</bodyText>
<listItem confidence="0.99932475">
• word posterior probability (Fiscus, 1997);
• 3, 4-gram target language model;
• word length penalty;
• Null word length penalty;
</listItem>
<bodyText confidence="0.9976045">
We use MERT (Och, 2003) to tune the weights
of the CN.
</bodyText>
<subsectionHeader confidence="0.987346">
2.8 Rescoring
</subsectionHeader>
<bodyText confidence="0.9999128">
Rescoring is a very important part in post-
processing which can select a better hypothesis
from the N-best list. We augmented our previ-
ous rescoring model (Du et al., 2009) with more
large-scale data. The features we used include:
</bodyText>
<listItem confidence="0.999164181818182">
• Direct and inverse IBM model;
• 3, 4-gram target language model;
• 3, 4, 5-gram PoS language model (Schmid,
1994; Ratnaparkhi, 1996);
• Sentence length posterior probability (Zens
and Ney, 2006);
• N-gram posterior probabilities within the N-
Best list (Zens and Ney, 2006);
• Minimum Bayes Risk probability;
• Length ratio between source and target sen-
tence;
</listItem>
<bodyText confidence="0.987445">
The weights are optimized via MERT.
</bodyText>
<sectionHeader confidence="0.998503" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<bodyText confidence="0.9998525">
This section describes our experimental setup for
the en–cs and en–es translation tasks.
</bodyText>
<subsectionHeader confidence="0.990044">
3.1 Data
</subsectionHeader>
<bodyText confidence="0.9917659">
Bilingual data: In the experiments we used data
sets provided by the workshop organizers. For the
en–cs translation table extraction we employed
both parallel corpora (News-Commentary10 and
CzEng 0.9), and for the en–es experiments, we
used the Europarl(Koehn, 2005), News Commen-
tary and United Nations parallel data. We used a
maximum sentence length of 80 for en–es and
40 for en–cs. Detailed statistics are shown in Ta-
ble 1.
</bodyText>
<table confidence="0.998605142857143">
Corpus Langs. Sent. Source Target
tokens tokens
Europarl en–es 1.6M 43M 45M
News-comm en–es 97k 2.4M 2.7M
UN en–es 5.9M 160M 190M
News-Comm en–cs 85k 1.8M 1.6M
CzEng en–cs 7.8M 80M 69M
</table>
<tableCaption confidence="0.999896">
Table 1: Statistics of en–cs and en–es parallel data.
</tableCaption>
<bodyText confidence="0.999319461538462">
Monolingual data: For language modeling pur-
poses, in addition to the target parts of the bilin-
gual data, we used the monolingual News corpus
for cs; and the Gigaword corpus for es. For both
languages, we used the SRILM toolkit (Stolcke,
2002) to train a 5-gram language model using all
monolingual data provided. However, for en–es
we used the IRSTLM toolkit (Federico and Cet-
tolo, 2007) to train a 5-gram language model using
the es Gigaword corpus. Both language models
use modified Kneser-Ney smoothing (Chen and
Goodman, 1996). Statistics for the monolingual
corpora are given in Table 2.
</bodyText>
<table confidence="0.99972325">
Corpus Language Sentences Tokens
E/N/NC/UN es 9,6M 290M
Gigaword es 40M 1,2G
News cs 13M 210M
</table>
<tableCaption confidence="0.984338666666667">
Table 2: Statistics of Monolingual Data. E/N/NC/UN
refers to Europarl/News/News Commentary/United Nations
corpora.
</tableCaption>
<bodyText confidence="0.9893025">
For all the systems except Apertium, we first
lowercase and tokenize all the monolingual and
bilingual data using the tools provided by the
WMT10 organizers. After translation, system
</bodyText>
<equation confidence="0.9796845">
145combination output is detokenised and true-cased.
r = arg min
i
Ns
E
j=1
</equation>
<bodyText confidence="0.999906222222222">
mentary corpus) and the Apertium RBMT sys-
tem. We also derived phrase alignments using the
MaTrEx EBMT system (Stroppa and Way, 2006),
and added those phrase translations in the Moses
phrase table. The systems marked with * use a
language model built using the Spanish Gigaword
corpus, in addition to the one built using the pro-
vided monolingual data. These 6 sets of system
outputs are then used for system combination.
</bodyText>
<subsectionHeader confidence="0.91712">
3.4 Experimental Results
</subsectionHeader>
<bodyText confidence="0.997091">
The evaluation results for en–es and en–cs ex-
periments are shown in Table 3 and Table 4 re-
spectively. The output of the systems marked t
were submitted in the shared tasks.
</bodyText>
<table confidence="0.999413111111111">
System BLEU NIST METEOR TER
DCU-half †* 29.77% 7.68 59.86% 59.55%
DCU-all †* 29.63% 7.66 59.82% 59.74%
DCU-epn †* 29.45% 7.66 59.71% 59.64%
DCU-ebmt †* 29.38% 7.62 59.59% 60.11%
DCU-factor 22.58% 6.56 54.94% 67.65%
DCU-apertium 19.22% 6.37 49.68% 67.68%
DCU-system- 30.42% 7.78 60.56% 58.71%
combination †
</table>
<tableCaption confidence="0.996177">
Table 3: en–es experimental results.
</tableCaption>
<subsectionHeader confidence="0.993857">
3.2 English–Czech (en–cs) Experiments
</subsectionHeader>
<bodyText confidence="0.999948837837838">
The CzEng corpus (Bojar and ˇZabokrtsk´y, 2009)
is a collection of parallel texts from sources of dif-
ferent quality and as such it contains some noise.
As the first step, we discarded those sentence pairs
having more than 10% of non-Latin characters.
The CzEng corpus is quite large (8M sen-
tence pairs). Although we were able to build
a vanilla SMT system on all parallel data avail-
able (News-Commentary + CzEng), we also at-
tempted to build additional systems using News-
Commentary data (which we considered in-
domain) and various in-domain subsets of CzEng
hoping to achieve better results on domain-
specific data.
For our first system, we selected 128,218 sen-
tence pairs from CzEng labeled as news. For the
other two systems, we selected subsets of 2M and
4M sentence pairs identified as most similar to
the development sets (as a sample of in-domain
data) based on cosine similarity of their represen-
tation in a TF-IDF weighted vector space model
(cf. Byrne et al. (2003)). We also applied the
pseudo-relevavance-feedback technique for query
expansion (Manning et al., 2008) to select another
subset with 2M sentence pairs.
We used the output of 15 systems for sys-
tem combination for the en–cs translation task.
Among these, 5 systems were built using Moses
and varying the size of the training data (DCU-
All, DCU-Ex2M, DCU-4M, DCU-2M and DCU-
News); 9 context-informed PB-SMT systems
(DCU-SSCI-*) using (combinations of) various
context features (word, PoS, supertags and depen-
dency relations) trained only on the News Com-
mentary data (marked with t in Table 4); and one
system using the moses-chart decoder, also
trained on the news commentary data.
</bodyText>
<subsectionHeader confidence="0.994029">
3.3 English–Spanish (en–es) Experiments
</subsectionHeader>
<bodyText confidence="0.9999735">
Three baseline systems using Moses were built,
where we varied the amount of training data used:
</bodyText>
<table confidence="0.99972525">
System BLEU NIST METEOR TER
DCU-All 10.91% 4.60 39.18% 81.76%
DCU-Ex2M 10.63% 4.56 39.12% 81.96%
DCU-4M 10.61% 4.56 39.26% 82.04%
DCU-2M 10.48% 4.58 39.35% 81.56%
DCU-Chart 9.34% 4.25 37.04% 83.87%
DCU-News 8.64% 4.16 36.27% 84.96%
DCU-SSCI-ccg‡ 8.26% 4.02 34.76% 85.58%
DCU-SSCI- 8.11% 3.95 34.93% 86.63%
supertag-pair‡
DCU-SSCI- 8.09% 3.96 34.90% 86.62%
ccg-ltag‡
DCU-SSCI-PR‡ 8.06% 4.00 34.89% 85.99%
DCU-SSCI-base‡ 8.05% 3.97 34.61% 86.02%
DCU-SSCI-PRIR‡ 8.03% 3.99 34.81% 85.98%
DCU-SSCI-ltag‡ 8.00% 3.95 34.57% 86.41%
DCU-SSCI-PoS‡ 7.91% 3.94 34.57% 86.51%
DCU-SSCI-word‡ 7.57% 3.88 34.16% 87.14%
DCU-system- 13.22% 4.98 40.39% 78.59%
combination †
</table>
<tableCaption confidence="0.998272">
Table 4: en–cs experimental results.
</tableCaption>
<listItem confidence="0.999392571428572">
• epn: This system uses all of the Europarl and
News-Commentary parallel data.
• UN-half: This system uses the data suplied 4 Conclusion
to “epn”, plus an additional 2.1M sentences
pairs randomly selected from the United Na- This paper presents the Dublin City University
tions corpus. MT system in WMT2010 shared task campaign.
• all: This system uses all of the available par- This was DCU’s first attempt to translate from en
</listItem>
<bodyText confidence="0.97607180952381">
allel data. to es and cs in any shared task. We developed a
multi-engine framework which combined the out-
For en–es we also obtained output from the puts of several individual MT systems and gener-
factored model (trained only on the news com- 146ated a new N-best list after CN decoding. Then by
using some global features, the rescoring model
generated the final translation output. The experi-
mental results demonstrated that the combination
module and rescoring module are effective in our
framework for both language pairs, and produce
statistically significant improvements as measured
by bootstrap resampling methods (Koehn, 2004)
on BLEU over the single best system.
Acknowledgements: This work is supported
by Science Foundation Ireland (Grant No.
07/CE/I1142) and by PANACEA, a 7th Frame-
work Research Programme of the European
Union, contract number 7FP-ITC-248064. M.L.
Forcada’s sabbatical stay at Dublin City Univer-
sity is supported by Science Foundation Ireland
through ETS Walton Award 07/W.1/I1802 and by
the Universitat d’Alacant (Spain).
</bodyText>
<sectionHeader confidence="0.948064" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.976065363636364">
Bojar, O. and ˇZabokrtsk´y, Z. (2009). CzEng0.9:
Large Parallel Treebank with Rich Annotation.
Prague Bulletin of Mathematical Linguistics,
92:63–83.
Byrne, W., Khudanpur, S., Kim, W., Kumar, S.,
Pecina, P., Virga, P., Xu, P., and Yarowsky, D.
(2003). The Johns Hopkins University 2003
Chinese–English machine translation system.
In Proceedings of MT Summit IX, pages 447–
450, New Orleans, LA.
Chen, S. F. and Goodman, J. (1996). An Empir-
ical Study of Smoothing Techniques for Lan-
guage Modeling. In Proc. 34th Ann. Meeting of
the Association for Computational Linguistics,
pages 310–318, San Francisco, CA.
Chiang, D. (2007). Hierarchical phrase-
based translation. Computational Linguistics,
33(2):201–228.
Daelemans, W. and van den Bosch, A. (2005).
Memory-Based Language Processing (Studies
in Natural Language Processing). Cambridge
University Press, New York, NY.
Du, J., He, Y., Penkale, S., and Way, A. (2009).
MaTrEx: The DCU MT System for WMT2009.
In Proc. 3rd Workshop on Statistical Machine
Translation, EACL 2009, pages 95–99, Athens,
Greece.
Du, J., Pecina, P., and Way, A. (2010). An
Augmented Three-Pass System Combination
Framework: DCU Combination System for
WMT 2010. In Proc. ACL 2010 Joint Workshop
in Statistical Machine Translation and Metrics
Matr, Uppsala, Greece.
</reference>
<bodyText confidence="0.7054232">
Federico, M. and Cettolo, M. (2007). Efficient
Handling of N-gram Language Models for Sta-
tistical Machine Translation. In Proceedings
of the Second Workshop on Statistical Machine
Translation, pages 88–95, Prague, Czech Re-
public.
Fiscus, J. G. (1997). A post-processing sys-
tem to yield reduced word error rates: Recog-
nizer output voting error reduction (ROVER).
In Proceedings 1997 IEEE Workshop on Auto-
matic Speech Recognition and Understanding
(ASRU), pages 347–352, Santa Barbara, CA.
Forcada, M. L., Tyers, F. M., and Ramirez-
S´anchez, G. (2009). The free/open-source ma-
chine translation platform Apertium: Five years
</bodyText>
<reference confidence="0.989227606060606">
on. In Proceedings of the First International
Workshop on Free/Open-Source Rule-Based
Machine Translation FreeRBMT’09, pages 3–
10.
Gough, N. and Way, A. (2004). Robust Large-
Scale EBMT with Marker-Based Segmenta-
tion. In Proceedings of the 10th International
Conference on Theoretical and Methodological
Issues in Machine Translation (TMI-04), pages
95–104, Baltimore, MD.
Haque, R., Naskar, S. K., Bosch, A. v. d., and
Way, A. (2009a). Dependency relations as
source context in phrase-based smt. In Proc.
23rd Pacific Asia Conference on Language, In-
formation and Computation, pages 170–179,
Hong Kong, China.
Haque, R., Naskar, S. K., Ma, Y., and Way, A.
(2009b). Using supertags as source language
context in SMT. In EAMT-2009: Proceed-
ings of the 13th Annual Conference of the Eu-
ropean Association for Machine Translation,
pages 234–241, Barcelona, Spain.
Koehn, P. (2004). Statistical significance tests for
machine translation evaluation. In Proceedings
of EMNLP, volume 4, pages 388–395.
Koehn, P. (2005). Europarl: A Parallel Corpus
for Statistical Machine Translation. In Machine
Translation Summit X, pages 79–86, Phuket,
Thailand.
Koehn, P. and Hoang, H. (2007). Factored Trans-
lation Models. In Proceedings of the Joint Con-
ference on Empirical Methods in Natural Lan-
147 guage Processing and Computational Natural
</reference>
<page confidence="0.72496">
148
</page>
<reference confidence="0.987661571428571">
Language Learning (EMNLP-CoNLL), pages
868–876, Prague, Czech Republic.
Koehn, P., Hoang, H., Birch, A., Callison-Burch,
C., Federico, M., Bertoldi, N., Cowan, B.,
Shen, W., Moran, C., Zens, R., Dyer, C., Bo-
jar, O., Constantin, A., and Herbst, E. (2007).
Moses: Open Source Toolkit for Statistical Ma-
chine Translation. In Annual Meeting of the As-
sociation for Computational Linguistics (ACL),
demonstration session, pages 177–180, Prague,
Czech Republic.
Kumar, S. and Byrne, W. (2004). Minimum
Bayes-Risk Decoding for Statistical Machine
Translation. In Proceedings of the Joint Meet-
ing of the Human Language Technology Con-
ference and the North American Chapter of
the Association for Computational Linguistics
(HLT-NAACL 2004), pages 169–176, Boston,
MA.
Mangu, L., Brill, E., and Stolcke, A. (2000). Find-
ing consensus in speech recognition: Word er-
ror minimization and other applications of con-
fusion networks. Computer Speech and Lan-
guage, 14(4):373–400.
Manning, C. D., Raghavan, P., and Sch¨utze, H.
(2008). Introduction to Information Retrieval.
Cambridge University Press.
Och, F. (2003). Minimum error rate training
in statistical machine translation. In Proceed-
ings of the 41st Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL),
pages 160–167, Sapporo, Japan.
Och, F. and Ney, H. (2002). Discriminative train-
ing and maximum entropy models for statistical
machine translation. In Proceedings of ACL,
volume 2, pages 295–302.
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.
(2002). BLEU: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings
of the 40th Annual Meeting of the Association
for Computational Linguistics (ACL-02), pages
311–318, Philadelphia, PA.
Ratnaparkhi, A. (1996). A Maximum Entropy
Model for Part-Of-Speech Tagging. In Pro-
ceedings of the Empirical Methods in Natural
Language Processing Conference (EMNLP),
pages 133–142, Philadelphia, PA.
Rosti, A.-V. I., Xiang, B., Matsoukas, S.,
Schwartz, R., Ayan, N. F., and Dorr, B. J.
(2007). Combining outputs from multiple ma-
chine translation systems. In Proceedings of the
Joint Meeting of the Human Language Technol-
ogy Conference and the North American Chap-
ter of the Association for Computational Lin-
guistics (HLT-NAACL 2007), pages 228–235,
Rochester, NY.
Schmid, H. (1994). Probabilistic Part-of-Speech
Tagging Using Decision Trees. In Proceedings
of International Conference on New Methods
in Language Processing, pages 44–49, Manch-
ester, UK.
Snover, M., Dorr, B., Schwartz, R., Micciula, L.,
and Makhoul, J. (2006). A study of transla-
tion edit rate with targeted human annotation.
In Proceedings of the 7th Conference of the As-
sociation for Machine Translation in the Amer-
icas (AMTA 2006), pages 223–231, Cambridge,
MA.
Stolcke, A. (2002). SRILM - An Extensible Lan-
guage Modeling Toolkit. In Proceedings of
the International Conference Spoken Language
Processing, pages 901–904, Denver, CO.
Stroppa, N., van den Bosch, A., and Way, A.
(2007). Exploiting Source Similarity for SMT
using Context-Informed Features. In Proceed-
ings of the 11th International Conference on
Theoretical and Methodological Issues in Ma-
chine Translation (TMI-07), pages 231–240,
Sk¨ovde, Sweden.
Stroppa, N. and Way, A. (2006). MaTrEx: the
DCU machine translation system for IWSLT
2006. In Proceedings of the International Work-
shop on Spoken Language Translation, pages
31–36, Kyoto, Japan.
Zens, R. and Ney, H. (2006). N-gram Poste-
rior Probabilities for Statistical Machine Trans-
lation. In Proceedings of the Joint Meeting of
the Human Language Technology Conference
and the North American Chapter of the As-
sociation for Computational Linguistics (HLT-
NAACL 2006), pages 72–77, New York, NY.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.164006">
<title confidence="0.800245">The DCU MT System for WMT 2010</title>
<author confidence="0.8178675">Sergio Penkale</author>
<author confidence="0.8178675">Rejwanul Haque</author>
<author confidence="0.8178675">Sandipan Dandapat</author>
<author confidence="0.8178675">Pratyush Banerjee</author>
<author confidence="0.8178675">Ankit K Jinhua Du</author>
<author confidence="0.8178675">Pavel Pecina</author>
<author confidence="0.8178675">Sudip Kumar Naskar</author>
<author confidence="0.8178675">Mikel L Forcada</author>
<author confidence="0.8178675">Andy Way</author>
<affiliation confidence="0.996369">CNGL, School of Computing</affiliation>
<address confidence="0.983941">Dublin City University, Dublin 9, Ireland</address>
<email confidence="0.855315">rhaque,sdandapat,pbanerjee,asrivastava,jdu,ppecina,snaskar,mforcada,away</email>
<note confidence="0.379695">143</note>
<abstract confidence="0.996544625">This paper describes the DCU machine translation system in the evaluation campaign of the Joint Fifth Workshop on Statistical Machine Translation and Metrics in ACL-2010. We describe the modular design of our multi-engine machine translation (MT) system with particular focus on the components used in this participation. We participated in the English– Spanish and English–Czech translation tasks, in which we employed our multiengine architecture to translate. We also participated in the system combination task which was carried out by the MBR decoder and confusion network decoder.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>O Bojar</author>
<author>Z ˇZabokrtsk´y</author>
</authors>
<title>CzEng0.9: Large Parallel Treebank with Rich Annotation.</title>
<date>2009</date>
<booktitle>Prague Bulletin of Mathematical Linguistics,</booktitle>
<pages>92--63</pages>
<marker>Bojar, ˇZabokrtsk´y, 2009</marker>
<rawString>Bojar, O. and ˇZabokrtsk´y, Z. (2009). CzEng0.9: Large Parallel Treebank with Rich Annotation. Prague Bulletin of Mathematical Linguistics, 92:63–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Byrne</author>
<author>S Khudanpur</author>
<author>W Kim</author>
<author>S Kumar</author>
<author>P Pecina</author>
<author>P Virga</author>
<author>P Xu</author>
<author>D Yarowsky</author>
</authors>
<title>Chinese–English machine translation system.</title>
<date>2003</date>
<booktitle>In Proceedings of MT Summit IX,</booktitle>
<pages>447--450</pages>
<institution>The Johns Hopkins University</institution>
<location>New Orleans, LA.</location>
<contexts>
<context position="12663" citStr="Byrne et al. (2003)" startWordPosition="2021" endWordPosition="2024">tem on all parallel data available (News-Commentary + CzEng), we also attempted to build additional systems using NewsCommentary data (which we considered indomain) and various in-domain subsets of CzEng hoping to achieve better results on domainspecific data. For our first system, we selected 128,218 sentence pairs from CzEng labeled as news. For the other two systems, we selected subsets of 2M and 4M sentence pairs identified as most similar to the development sets (as a sample of in-domain data) based on cosine similarity of their representation in a TF-IDF weighted vector space model (cf. Byrne et al. (2003)). We also applied the pseudo-relevavance-feedback technique for query expansion (Manning et al., 2008) to select another subset with 2M sentence pairs. We used the output of 15 systems for system combination for the en–cs translation task. Among these, 5 systems were built using Moses and varying the size of the training data (DCUAll, DCU-Ex2M, DCU-4M, DCU-2M and DCUNews); 9 context-informed PB-SMT systems (DCU-SSCI-*) using (combinations of) various context features (word, PoS, supertags and dependency relations) trained only on the News Commentary data (marked with t in Table 4); and one sy</context>
</contexts>
<marker>Byrne, Khudanpur, Kim, Kumar, Pecina, Virga, Xu, Yarowsky, 2003</marker>
<rawString>Byrne, W., Khudanpur, S., Kim, W., Kumar, S., Pecina, P., Virga, P., Xu, P., and Yarowsky, D. (2003). The Johns Hopkins University 2003 Chinese–English machine translation system. In Proceedings of MT Summit IX, pages 447– 450, New Orleans, LA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S F Chen</author>
<author>J Goodman</author>
</authors>
<title>An Empirical Study of Smoothing Techniques for Language Modeling. In</title>
<date>1996</date>
<booktitle>Proc. 34th Ann. Meeting of the Association for Computational Linguistics,</booktitle>
<pages>310--318</pages>
<location>San Francisco, CA.</location>
<contexts>
<context position="10161" citStr="Chen and Goodman, 1996" startWordPosition="1613" endWordPosition="1616">85k 1.8M 1.6M CzEng en–cs 7.8M 80M 69M Table 1: Statistics of en–cs and en–es parallel data. Monolingual data: For language modeling purposes, in addition to the target parts of the bilingual data, we used the monolingual News corpus for cs; and the Gigaword corpus for es. For both languages, we used the SRILM toolkit (Stolcke, 2002) to train a 5-gram language model using all monolingual data provided. However, for en–es we used the IRSTLM toolkit (Federico and Cettolo, 2007) to train a 5-gram language model using the es Gigaword corpus. Both language models use modified Kneser-Ney smoothing (Chen and Goodman, 1996). Statistics for the monolingual corpora are given in Table 2. Corpus Language Sentences Tokens E/N/NC/UN es 9,6M 290M Gigaword es 40M 1,2G News cs 13M 210M Table 2: Statistics of Monolingual Data. E/N/NC/UN refers to Europarl/News/News Commentary/United Nations corpora. For all the systems except Apertium, we first lowercase and tokenize all the monolingual and bilingual data using the tools provided by the WMT10 organizers. After translation, system 145combination output is detokenised and true-cased. r = arg min i Ns E j=1 mentary corpus) and the Apertium RBMT system. We also derived phrase</context>
</contexts>
<marker>Chen, Goodman, 1996</marker>
<rawString>Chen, S. F. and Goodman, J. (1996). An Empirical Study of Smoothing Techniques for Language Modeling. In Proc. 34th Ann. Meeting of the Association for Computational Linguistics, pages 310–318, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>Hierarchical phrasebased translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="1762" citStr="Chiang (2007)" startWordPosition="258" endWordPosition="259"> MT (SMT), and system combination techniques. We participated in the English–Spanish (en– es) and English–Czech (en–cs) translation tasks. For these two tasks, we employ several individual MT systems: 1) Baseline: phrasebased SMT (Koehn et al., 2007); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker (Gough and Way, 2004); 3) Factored translation model (Koehn and Hoang, 2007); 4) Source-side context-informed (SSCI) systems (Stroppa et al., 2007); 5) the moses-chart (a Moses implementation of the hierarchical phrase-based (HPB) approach of Chiang (2007)) and 6) Apertium (Forcada et al., 2009) rule-based machine translation (RBMT). Finally, we use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final translation. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the confusion network (CN) (Mangu et al., 2000). We then build the CN using the TER metric (Snover et al., 2006), and finally search for the best translation. The re</context>
<context position="6490" citStr="Chiang, 2007" startWordPosition="1003" endWordPosition="1004">n (Stroppa et al., 2007), we incorporate grammatical dependency relations (Haque et al., 2009a) and supertags (Haque et al., 2009b) as syntactic source context features in the log-linear PB-SMT model. In addition to the above feature, we derived a simple binary feature hbest, defined in (2): � 1 if ek maximizes P(N fk, CI(fk)) hbest = 0 otherwise (2) We performed experiments by integrating these two features, hMBL and hbest, directly into the log-linear framework of Moses. 2.6 Hierarchical PB-SMT model For the en–cs translation task, we built a weighted synchronous context-free grammar model (Chiang, 2007) of translation that uses the bilingual phrase pairs of PB-SMT as a starting point to learn hierarchical rules. We used the open-source Tree-Based translation system moses-chart3 to perform this experiment. 2An implementation of TRIBL is freely available as part of the TiMBL software package, which can be downloaded from http://ilk.uvt.nl/timbl 144 3http://www.statmt.org/moses/?n=Moses.SyntaxTutorial 2.7 System Combination For multiple system combination, we used an MBR-CN framework (Du et al., 2009, 2010) as shown in Figure 1. Due to the varying word order in the MT hypotheses, it is essentia</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>Chiang, D. (2007). Hierarchical phrasebased translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>A van den Bosch</author>
</authors>
<title>Memory-Based Language Processing (Studies in Natural Language Processing).</title>
<date>2005</date>
<publisher>Cambridge University Press,</publisher>
<location>New York, NY.</location>
<marker>Daelemans, van den Bosch, 2005</marker>
<rawString>Daelemans, W. and van den Bosch, A. (2005). Memory-Based Language Processing (Studies in Natural Language Processing). Cambridge University Press, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Du</author>
<author>Y He</author>
<author>S Penkale</author>
<author>A Way</author>
</authors>
<title>MaTrEx: The DCU MT System for WMT2009.</title>
<date>2009</date>
<booktitle>In Proc. 3rd Workshop on Statistical Machine Translation, EACL</booktitle>
<pages>95--99</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="3105" citStr="Du et al., 2009" startWordPosition="471" endWordPosition="474">engine strategies used for the shared task. In Section 3, we outline the complete system setup for the shared task and provide evaluation results on the test set. Section 4 concludes the paper. 2 The MATREX System 2.1 System Architecture The MATREX system is a combination-based multi-engine architecture, which exploits aspects of both the EBMT and SMT paradigms. The architecture includes various individual systems: phrase-based, example-based, hierarchical phrase-based and tree-based MT. The combination structure uses the MBR and CN decoders, and is based on a word-level combination strategy (Du et al., 2009). In the final stage, we use a new rescoring module to process the N-best list generated by the combination module. Figure 1 illustrates the architecture. 2.2 Example-Based Machine Translation The EBMT system uses a language-specific, reduced set of closed-class marker morphemes or lexemes (Gough and Way, 2004) to define a way to segment sentences into chunks, which are then aligned using an edit-distance-style algorithm, in which edit costs depend on word-to-word translaProceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 143–148, Uppsala, Sweden, 15</context>
<context position="6994" citStr="Du et al., 2009" startWordPosition="1070" endWordPosition="1073">model For the en–cs translation task, we built a weighted synchronous context-free grammar model (Chiang, 2007) of translation that uses the bilingual phrase pairs of PB-SMT as a starting point to learn hierarchical rules. We used the open-source Tree-Based translation system moses-chart3 to perform this experiment. 2An implementation of TRIBL is freely available as part of the TiMBL software package, which can be downloaded from http://ilk.uvt.nl/timbl 144 3http://www.statmt.org/moses/?n=Moses.SyntaxTutorial 2.7 System Combination For multiple system combination, we used an MBR-CN framework (Du et al., 2009, 2010) as shown in Figure 1. Due to the varying word order in the MT hypotheses, it is essential to define the backbone which determines the general word order of the CN. Instead of using a single system output as the skeleton, we employ an MBR decoder to select the best single system output Er from the merged N-best list by minimizing the BLEU (Papineni et al., 2002) loss, as in (3): (1 − BLEU(Ej, Ei)) (3) where Ns indicates the number of translations in the merged N-best list, and {Ei�Ns i=1are the translations themselves. In our task, we only merge the 1-best output of each individual syst</context>
<context position="8390" citStr="Du et al., 2009" startWordPosition="1323" endWordPosition="1326">es are assigned to each word in the network. Each arc in the CN represents an alternative word at that position in the sentence and the number of votes for each word is counted when constructing the network. The features we used are as follows: • word posterior probability (Fiscus, 1997); • 3, 4-gram target language model; • word length penalty; • Null word length penalty; We use MERT (Och, 2003) to tune the weights of the CN. 2.8 Rescoring Rescoring is a very important part in postprocessing which can select a better hypothesis from the N-best list. We augmented our previous rescoring model (Du et al., 2009) with more large-scale data. The features we used include: • Direct and inverse IBM model; • 3, 4-gram target language model; • 3, 4, 5-gram PoS language model (Schmid, 1994; Ratnaparkhi, 1996); • Sentence length posterior probability (Zens and Ney, 2006); • N-gram posterior probabilities within the NBest list (Zens and Ney, 2006); • Minimum Bayes Risk probability; • Length ratio between source and target sentence; The weights are optimized via MERT. 3 Experimental Setup This section describes our experimental setup for the en–cs and en–es translation tasks. 3.1 Data Bilingual data: In the exp</context>
</contexts>
<marker>Du, He, Penkale, Way, 2009</marker>
<rawString>Du, J., He, Y., Penkale, S., and Way, A. (2009). MaTrEx: The DCU MT System for WMT2009. In Proc. 3rd Workshop on Statistical Machine Translation, EACL 2009, pages 95–99, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Du</author>
<author>P Pecina</author>
<author>A Way</author>
</authors>
<title>An Augmented Three-Pass System Combination Framework: DCU Combination System for WMT</title>
<date>2010</date>
<booktitle>In Proc. ACL 2010 Joint Workshop in Statistical Machine Translation and Metrics Matr,</booktitle>
<location>Uppsala, Greece.</location>
<marker>Du, Pecina, Way, 2010</marker>
<rawString>Du, J., Pecina, P., and Way, A. (2010). An Augmented Three-Pass System Combination Framework: DCU Combination System for WMT 2010. In Proc. ACL 2010 Joint Workshop in Statistical Machine Translation and Metrics Matr, Uppsala, Greece.</rawString>
</citation>
<citation valid="false">
<authors>
<author>on</author>
</authors>
<booktitle>In Proceedings of the First International Workshop on Free/Open-Source Rule-Based Machine Translation FreeRBMT’09,</booktitle>
<pages>3--10</pages>
<marker>on, </marker>
<rawString>on. In Proceedings of the First International Workshop on Free/Open-Source Rule-Based Machine Translation FreeRBMT’09, pages 3– 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Gough</author>
<author>A Way</author>
</authors>
<title>Robust LargeScale EBMT with Marker-Based Segmentation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-04),</booktitle>
<pages>95--104</pages>
<location>Baltimore, MD.</location>
<contexts>
<context position="1527" citStr="Gough and Way, 2004" startWordPosition="223" endWordPosition="226">sk which was carried out by the MBR decoder and confusion network decoder. 1 Introduction In this paper, we present the DCU multi-engine MT system MATREX (Machine Translation using Examples). This system exploits example-based MT, statistical MT (SMT), and system combination techniques. We participated in the English–Spanish (en– es) and English–Czech (en–cs) translation tasks. For these two tasks, we employ several individual MT systems: 1) Baseline: phrasebased SMT (Koehn et al., 2007); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker (Gough and Way, 2004); 3) Factored translation model (Koehn and Hoang, 2007); 4) Source-side context-informed (SSCI) systems (Stroppa et al., 2007); 5) the moses-chart (a Moses implementation of the hierarchical phrase-based (HPB) approach of Chiang (2007)) and 6) Apertium (Forcada et al., 2009) rule-based machine translation (RBMT). Finally, we use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final translation. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004)</context>
<context position="3417" citStr="Gough and Way, 2004" startWordPosition="520" endWordPosition="523">ich exploits aspects of both the EBMT and SMT paradigms. The architecture includes various individual systems: phrase-based, example-based, hierarchical phrase-based and tree-based MT. The combination structure uses the MBR and CN decoders, and is based on a word-level combination strategy (Du et al., 2009). In the final stage, we use a new rescoring module to process the N-best list generated by the combination module. Figure 1 illustrates the architecture. 2.2 Example-Based Machine Translation The EBMT system uses a language-specific, reduced set of closed-class marker morphemes or lexemes (Gough and Way, 2004) to define a way to segment sentences into chunks, which are then aligned using an edit-distance-style algorithm, in which edit costs depend on word-to-word translaProceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 143–148, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics Figure 1: System Framework. tion probabilities and the amount of word-to-word cognates (Stroppa and Way, 2006). Once these phrase pairs were obtained they were merged with the phrase pairs extracted by the baseline system adding word alignment info</context>
</contexts>
<marker>Gough, Way, 2004</marker>
<rawString>Gough, N. and Way, A. (2004). Robust LargeScale EBMT with Marker-Based Segmentation. In Proceedings of the 10th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-04), pages 95–104, Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Haque</author>
<author>S K Naskar</author>
<author>A v d Bosch</author>
<author>A Way</author>
</authors>
<title>Dependency relations as source context in phrase-based smt.</title>
<date>2009</date>
<booktitle>In Proc. 23rd Pacific Asia Conference on Language, Information and Computation,</booktitle>
<pages>170--179</pages>
<location>Hong Kong, China.</location>
<contexts>
<context position="5970" citStr="Haque et al., 2009" startWordPosition="919" endWordPosition="922">ontext information (CI): hMBL = log P(ek A, CI( A)) (1) We use a memory-based machine learning (MBL) classifier (TRIBL:2 Daelemans and van den Bosch (2005)) that is able to estimate P(�ek|�fk, CI( fk)) by similarity-based reasoning over memorized nearest-neighbour examples of source–target phrase translations. In equation (1), SSCI may include any feature (lexical, syntactic, etc.), which can provide useful information to disambiguate a given source phrase. In addition to using local words and PoS-tags as features, as in (Stroppa et al., 2007), we incorporate grammatical dependency relations (Haque et al., 2009a) and supertags (Haque et al., 2009b) as syntactic source context features in the log-linear PB-SMT model. In addition to the above feature, we derived a simple binary feature hbest, defined in (2): � 1 if ek maximizes P(N fk, CI(fk)) hbest = 0 otherwise (2) We performed experiments by integrating these two features, hMBL and hbest, directly into the log-linear framework of Moses. 2.6 Hierarchical PB-SMT model For the en–cs translation task, we built a weighted synchronous context-free grammar model (Chiang, 2007) of translation that uses the bilingual phrase pairs of PB-SMT as a starting poi</context>
</contexts>
<marker>Haque, Naskar, Bosch, Way, 2009</marker>
<rawString>Haque, R., Naskar, S. K., Bosch, A. v. d., and Way, A. (2009a). Dependency relations as source context in phrase-based smt. In Proc. 23rd Pacific Asia Conference on Language, Information and Computation, pages 170–179, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Haque</author>
<author>S K Naskar</author>
<author>Y Ma</author>
<author>A Way</author>
</authors>
<title>Using supertags as source language context in SMT.</title>
<date>2009</date>
<booktitle>In EAMT-2009: Proceedings of the 13th Annual Conference of the European Association for Machine Translation,</booktitle>
<pages>234--241</pages>
<location>Barcelona,</location>
<contexts>
<context position="5970" citStr="Haque et al., 2009" startWordPosition="919" endWordPosition="922">ontext information (CI): hMBL = log P(ek A, CI( A)) (1) We use a memory-based machine learning (MBL) classifier (TRIBL:2 Daelemans and van den Bosch (2005)) that is able to estimate P(�ek|�fk, CI( fk)) by similarity-based reasoning over memorized nearest-neighbour examples of source–target phrase translations. In equation (1), SSCI may include any feature (lexical, syntactic, etc.), which can provide useful information to disambiguate a given source phrase. In addition to using local words and PoS-tags as features, as in (Stroppa et al., 2007), we incorporate grammatical dependency relations (Haque et al., 2009a) and supertags (Haque et al., 2009b) as syntactic source context features in the log-linear PB-SMT model. In addition to the above feature, we derived a simple binary feature hbest, defined in (2): � 1 if ek maximizes P(N fk, CI(fk)) hbest = 0 otherwise (2) We performed experiments by integrating these two features, hMBL and hbest, directly into the log-linear framework of Moses. 2.6 Hierarchical PB-SMT model For the en–cs translation task, we built a weighted synchronous context-free grammar model (Chiang, 2007) of translation that uses the bilingual phrase pairs of PB-SMT as a starting poi</context>
</contexts>
<marker>Haque, Naskar, Ma, Way, 2009</marker>
<rawString>Haque, R., Naskar, S. K., Ma, Y., and Way, A. (2009b). Using supertags as source language context in SMT. In EAMT-2009: Proceedings of the 13th Annual Conference of the European Association for Machine Translation, pages 234–241, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<volume>4</volume>
<pages>388--395</pages>
<marker>Koehn, 2004</marker>
<rawString>Koehn, P. (2004). Statistical significance tests for machine translation evaluation. In Proceedings of EMNLP, volume 4, pages 388–395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Machine Translation Summit X,</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand.</location>
<contexts>
<context position="9230" citStr="Koehn, 2005" startWordPosition="1456" endWordPosition="1457">bility (Zens and Ney, 2006); • N-gram posterior probabilities within the NBest list (Zens and Ney, 2006); • Minimum Bayes Risk probability; • Length ratio between source and target sentence; The weights are optimized via MERT. 3 Experimental Setup This section describes our experimental setup for the en–cs and en–es translation tasks. 3.1 Data Bilingual data: In the experiments we used data sets provided by the workshop organizers. For the en–cs translation table extraction we employed both parallel corpora (News-Commentary10 and CzEng 0.9), and for the en–es experiments, we used the Europarl(Koehn, 2005), News Commentary and United Nations parallel data. We used a maximum sentence length of 80 for en–es and 40 for en–cs. Detailed statistics are shown in Table 1. Corpus Langs. Sent. Source Target tokens tokens Europarl en–es 1.6M 43M 45M News-comm en–es 97k 2.4M 2.7M UN en–es 5.9M 160M 190M News-Comm en–cs 85k 1.8M 1.6M CzEng en–cs 7.8M 80M 69M Table 1: Statistics of en–cs and en–es parallel data. Monolingual data: For language modeling purposes, in addition to the target parts of the bilingual data, we used the monolingual News corpus for cs; and the Gigaword corpus for es. For both languages</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Koehn, P. (2005). Europarl: A Parallel Corpus for Statistical Machine Translation. In Machine Translation Summit X, pages 79–86, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
</authors>
<title>Factored Translation Models.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Lan147 guage Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>868--876</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1582" citStr="Koehn and Hoang, 2007" startWordPosition="231" endWordPosition="234">sion network decoder. 1 Introduction In this paper, we present the DCU multi-engine MT system MATREX (Machine Translation using Examples). This system exploits example-based MT, statistical MT (SMT), and system combination techniques. We participated in the English–Spanish (en– es) and English–Czech (en–cs) translation tasks. For these two tasks, we employ several individual MT systems: 1) Baseline: phrasebased SMT (Koehn et al., 2007); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker (Gough and Way, 2004); 3) Factored translation model (Koehn and Hoang, 2007); 4) Source-side context-informed (SSCI) systems (Stroppa et al., 2007); 5) the moses-chart (a Moses implementation of the hierarchical phrase-based (HPB) approach of Chiang (2007)) and 6) Apertium (Forcada et al., 2009) rule-based machine translation (RBMT). Finally, we use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final translation. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment</context>
<context position="4437" citStr="Koehn and Hoang, 2007" startWordPosition="672" endWordPosition="675"> and the amount of word-to-word cognates (Stroppa and Way, 2006). Once these phrase pairs were obtained they were merged with the phrase pairs extracted by the baseline system adding word alignment information. 2.3 Apertium RBMT Apertium1 is a free/open-source platform for RBMT. The current version of the en–es system in Apertium was used for the system combination task (section 2.7), and its morphological analysers and part-of-speech taggers were used to build a factored Moses model. 2.4 Factored Translation Model We also used a factored model for the en–es translation task. Factored models (Koehn and Hoang, 2007) facilitate the translation by breaking it down into several factors which are further combined using a log-linear model (Och and Ney, 2002). We used three factors in our factored translation model, which are used in two different decoding paths: a surface form (SF) to SF translation factor, a lemma to lemma translation factor, and a part-ofspeech (PoS) to PoS translation factor. Finally, we used two decoding paths based on 1http://www.apertium.org the above three translation factors: an SF to SF decoding path and a path which maps lemma to lemma, PoS to PoS, and an SF generated using the TL l</context>
</contexts>
<marker>Koehn, Hoang, 2007</marker>
<rawString>Koehn, P. and Hoang, H. (2007). Factored Translation Models. In Proceedings of the Joint Conference on Empirical Methods in Natural Lan147 guage Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 868–876, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1399" citStr="Koehn et al., 2007" startWordPosition="203" endWordPosition="206">lation tasks, in which we employed our multiengine architecture to translate. We also participated in the system combination task which was carried out by the MBR decoder and confusion network decoder. 1 Introduction In this paper, we present the DCU multi-engine MT system MATREX (Machine Translation using Examples). This system exploits example-based MT, statistical MT (SMT), and system combination techniques. We participated in the English–Spanish (en– es) and English–Czech (en–cs) translation tasks. For these two tasks, we employ several individual MT systems: 1) Baseline: phrasebased SMT (Koehn et al., 2007); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker (Gough and Way, 2004); 3) Factored translation model (Koehn and Hoang, 2007); 4) Source-side context-informed (SSCI) systems (Stroppa et al., 2007); 5) the moses-chart (a Moses implementation of the hierarchical phrase-based (HPB) approach of Chiang (2007)) and 6) Apertium (Forcada et al., 2009) rule-based machine translation (RBMT). Finally, we use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to ge</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., and Herbst, E. (2007). Moses: Open Source Toolkit for Statistical Machine Translation. In Annual Meeting of the Association for Computational Linguistics (ACL), demonstration session, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kumar</author>
<author>W Byrne</author>
</authors>
<title>Minimum Bayes-Risk Decoding for Statistical Machine Translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2004),</booktitle>
<pages>169--176</pages>
<location>Boston, MA.</location>
<contexts>
<context position="2127" citStr="Kumar and Byrne, 2004" startWordPosition="313" endWordPosition="316"> (Gough and Way, 2004); 3) Factored translation model (Koehn and Hoang, 2007); 4) Source-side context-informed (SSCI) systems (Stroppa et al., 2007); 5) the moses-chart (a Moses implementation of the hierarchical phrase-based (HPB) approach of Chiang (2007)) and 6) Apertium (Forcada et al., 2009) rule-based machine translation (RBMT). Finally, we use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final translation. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the confusion network (CN) (Mangu et al., 2000). We then build the CN using the TER metric (Snover et al., 2006), and finally search for the best translation. The remainder of this paper is organised as follows: Section 2 details the various components of our system, in particular the multi-engine strategies used for the shared task. In Section 3, we outline the complete system setup for the shared task and provide evaluation results on the test set. Section 4 concludes the paper. 2 The MATREX System 2.1 System Architecture </context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>Kumar, S. and Byrne, W. (2004). Minimum Bayes-Risk Decoding for Statistical Machine Translation. In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2004), pages 169–176, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Mangu</author>
<author>E Brill</author>
<author>A Stolcke</author>
</authors>
<title>Finding consensus in speech recognition: Word error minimization and other applications of confusion networks.</title>
<date>2000</date>
<journal>Computer Speech and Language,</journal>
<volume>14</volume>
<issue>4</issue>
<contexts>
<context position="2244" citStr="Mangu et al., 2000" startWordPosition="333" endWordPosition="336">stems (Stroppa et al., 2007); 5) the moses-chart (a Moses implementation of the hierarchical phrase-based (HPB) approach of Chiang (2007)) and 6) Apertium (Forcada et al., 2009) rule-based machine translation (RBMT). Finally, we use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final translation. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the confusion network (CN) (Mangu et al., 2000). We then build the CN using the TER metric (Snover et al., 2006), and finally search for the best translation. The remainder of this paper is organised as follows: Section 2 details the various components of our system, in particular the multi-engine strategies used for the shared task. In Section 3, we outline the complete system setup for the shared task and provide evaluation results on the test set. Section 4 concludes the paper. 2 The MATREX System 2.1 System Architecture The MATREX system is a combination-based multi-engine architecture, which exploits aspects of both the EBMT and SMT p</context>
</contexts>
<marker>Mangu, Brill, Stolcke, 2000</marker>
<rawString>Mangu, L., Brill, E., and Stolcke, A. (2000). Finding consensus in speech recognition: Word error minimization and other applications of confusion networks. Computer Speech and Language, 14(4):373–400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>P Raghavan</author>
<author>H Sch¨utze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Manning, C. D., Raghavan, P., and Sch¨utze, H. (2008). Introduction to Information Retrieval. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="8173" citStr="Och, 2003" startWordPosition="1286" endWordPosition="1287"> output of each individual system. The CN is built by aligning other hypotheses against the backbone, based on the TER metric. Null words are allowed in the alignment. Either votes or different confidence measures are assigned to each word in the network. Each arc in the CN represents an alternative word at that position in the sentence and the number of votes for each word is counted when constructing the network. The features we used are as follows: • word posterior probability (Fiscus, 1997); • 3, 4-gram target language model; • word length penalty; • Null word length penalty; We use MERT (Och, 2003) to tune the weights of the CN. 2.8 Rescoring Rescoring is a very important part in postprocessing which can select a better hypothesis from the N-best list. We augmented our previous rescoring model (Du et al., 2009) with more large-scale data. The features we used include: • Direct and inverse IBM model; • 3, 4-gram target language model; • 3, 4, 5-gram PoS language model (Schmid, 1994; Ratnaparkhi, 1996); • Sentence length posterior probability (Zens and Ney, 2006); • N-gram posterior probabilities within the NBest list (Zens and Ney, 2006); • Minimum Bayes Risk probability; • Length ratio </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, F. (2003). Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL), pages 160–167, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Och</author>
<author>H Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL,</booktitle>
<volume>2</volume>
<pages>295--302</pages>
<contexts>
<context position="4577" citStr="Och and Ney, 2002" startWordPosition="695" endWordPosition="698">xtracted by the baseline system adding word alignment information. 2.3 Apertium RBMT Apertium1 is a free/open-source platform for RBMT. The current version of the en–es system in Apertium was used for the system combination task (section 2.7), and its morphological analysers and part-of-speech taggers were used to build a factored Moses model. 2.4 Factored Translation Model We also used a factored model for the en–es translation task. Factored models (Koehn and Hoang, 2007) facilitate the translation by breaking it down into several factors which are further combined using a log-linear model (Och and Ney, 2002). We used three factors in our factored translation model, which are used in two different decoding paths: a surface form (SF) to SF translation factor, a lemma to lemma translation factor, and a part-ofspeech (PoS) to PoS translation factor. Finally, we used two decoding paths based on 1http://www.apertium.org the above three translation factors: an SF to SF decoding path and a path which maps lemma to lemma, PoS to PoS, and an SF generated using the TL lemma and PoS. The lemmas and PoS for en and es were obtained using Apertium (section 2.3). 2.5 Source-Side Context-informed PB-SMT One natur</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Och, F. and Ney, H. (2002). Discriminative training and maximum entropy models for statistical machine translation. In Proceedings of ACL, volume 2, pages 295–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-02),</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="7365" citStr="Papineni et al., 2002" startWordPosition="1140" endWordPosition="1143">e as part of the TiMBL software package, which can be downloaded from http://ilk.uvt.nl/timbl 144 3http://www.statmt.org/moses/?n=Moses.SyntaxTutorial 2.7 System Combination For multiple system combination, we used an MBR-CN framework (Du et al., 2009, 2010) as shown in Figure 1. Due to the varying word order in the MT hypotheses, it is essential to define the backbone which determines the general word order of the CN. Instead of using a single system output as the skeleton, we employ an MBR decoder to select the best single system output Er from the merged N-best list by minimizing the BLEU (Papineni et al., 2002) loss, as in (3): (1 − BLEU(Ej, Ei)) (3) where Ns indicates the number of translations in the merged N-best list, and {Ei�Ns i=1are the translations themselves. In our task, we only merge the 1-best output of each individual system. The CN is built by aligning other hypotheses against the backbone, based on the TER metric. Null words are allowed in the alignment. Either votes or different confidence measures are assigned to each word in the network. Each arc in the CN represents an alternative word at that position in the sentence and the number of votes for each word is counted when construct</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002). BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-02), pages 311–318, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A Maximum Entropy Model for Part-Of-Speech Tagging.</title>
<date>1996</date>
<booktitle>In Proceedings of the Empirical Methods in Natural Language Processing Conference (EMNLP),</booktitle>
<pages>133--142</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="8583" citStr="Ratnaparkhi, 1996" startWordPosition="1357" endWordPosition="1358">ing the network. The features we used are as follows: • word posterior probability (Fiscus, 1997); • 3, 4-gram target language model; • word length penalty; • Null word length penalty; We use MERT (Och, 2003) to tune the weights of the CN. 2.8 Rescoring Rescoring is a very important part in postprocessing which can select a better hypothesis from the N-best list. We augmented our previous rescoring model (Du et al., 2009) with more large-scale data. The features we used include: • Direct and inverse IBM model; • 3, 4-gram target language model; • 3, 4, 5-gram PoS language model (Schmid, 1994; Ratnaparkhi, 1996); • Sentence length posterior probability (Zens and Ney, 2006); • N-gram posterior probabilities within the NBest list (Zens and Ney, 2006); • Minimum Bayes Risk probability; • Length ratio between source and target sentence; The weights are optimized via MERT. 3 Experimental Setup This section describes our experimental setup for the en–cs and en–es translation tasks. 3.1 Data Bilingual data: In the experiments we used data sets provided by the workshop organizers. For the en–cs translation table extraction we employed both parallel corpora (News-Commentary10 and CzEng 0.9), and for the en–es</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Ratnaparkhi, A. (1996). A Maximum Entropy Model for Part-Of-Speech Tagging. In Proceedings of the Empirical Methods in Natural Language Processing Conference (EMNLP), pages 133–142, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A-V I Rosti</author>
<author>B Xiang</author>
<author>S Matsoukas</author>
<author>R Schwartz</author>
<author>N F Ayan</author>
<author>B J Dorr</author>
</authors>
<title>Combining outputs from multiple machine translation systems.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL</booktitle>
<pages>228--235</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="1913" citStr="Rosti et al., 2007" startWordPosition="280" endWordPosition="283">ese two tasks, we employ several individual MT systems: 1) Baseline: phrasebased SMT (Koehn et al., 2007); 2) EBMT: Monolingually chunking both source and target sides of the dataset using a marker-based chunker (Gough and Way, 2004); 3) Factored translation model (Koehn and Hoang, 2007); 4) Source-side context-informed (SSCI) systems (Stroppa et al., 2007); 5) the moses-chart (a Moses implementation of the hierarchical phrase-based (HPB) approach of Chiang (2007)) and 6) Apertium (Forcada et al., 2009) rule-based machine translation (RBMT). Finally, we use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final translation. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the confusion network (CN) (Mangu et al., 2000). We then build the CN using the TER metric (Snover et al., 2006), and finally search for the best translation. The remainder of this paper is organised as follows: Section 2 details the various components of our system, in particular the multi-engine strategies used f</context>
</contexts>
<marker>Rosti, Xiang, Matsoukas, Schwartz, Ayan, Dorr, 2007</marker>
<rawString>Rosti, A.-V. I., Xiang, B., Matsoukas, S., Schwartz, R., Ayan, N. F., and Dorr, B. J. (2007). Combining outputs from multiple machine translation systems. In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2007), pages 228–235, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Probabilistic Part-of-Speech Tagging Using Decision Trees.</title>
<date>1994</date>
<booktitle>In Proceedings of International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="8563" citStr="Schmid, 1994" startWordPosition="1355" endWordPosition="1356">when constructing the network. The features we used are as follows: • word posterior probability (Fiscus, 1997); • 3, 4-gram target language model; • word length penalty; • Null word length penalty; We use MERT (Och, 2003) to tune the weights of the CN. 2.8 Rescoring Rescoring is a very important part in postprocessing which can select a better hypothesis from the N-best list. We augmented our previous rescoring model (Du et al., 2009) with more large-scale data. The features we used include: • Direct and inverse IBM model; • 3, 4-gram target language model; • 3, 4, 5-gram PoS language model (Schmid, 1994; Ratnaparkhi, 1996); • Sentence length posterior probability (Zens and Ney, 2006); • N-gram posterior probabilities within the NBest list (Zens and Ney, 2006); • Minimum Bayes Risk probability; • Length ratio between source and target sentence; The weights are optimized via MERT. 3 Experimental Setup This section describes our experimental setup for the en–cs and en–es translation tasks. 3.1 Data Bilingual data: In the experiments we used data sets provided by the workshop organizers. For the en–cs translation table extraction we employed both parallel corpora (News-Commentary10 and CzEng 0.9</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Schmid, H. (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. In Proceedings of International Conference on New Methods in Language Processing, pages 44–49, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Snover</author>
<author>B Dorr</author>
<author>R Schwartz</author>
<author>L Micciula</author>
<author>J Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA</booktitle>
<pages>223--231</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="2309" citStr="Snover et al., 2006" startWordPosition="346" endWordPosition="349">entation of the hierarchical phrase-based (HPB) approach of Chiang (2007)) and 6) Apertium (Forcada et al., 2009) rule-based machine translation (RBMT). Finally, we use a word-level combination framework (Rosti et al., 2007) to combine the multiple translation hypotheses and employ a new rescoring model to generate the final translation. For the system combination task, we first use the minimum Bayes-risk (MBR) (Kumar and Byrne, 2004) decoder to select the best hypothesis as the alignment reference for the confusion network (CN) (Mangu et al., 2000). We then build the CN using the TER metric (Snover et al., 2006), and finally search for the best translation. The remainder of this paper is organised as follows: Section 2 details the various components of our system, in particular the multi-engine strategies used for the shared task. In Section 3, we outline the complete system setup for the shared task and provide evaluation results on the test set. Section 4 concludes the paper. 2 The MATREX System 2.1 System Architecture The MATREX system is a combination-based multi-engine architecture, which exploits aspects of both the EBMT and SMT paradigms. The architecture includes various individual systems: p</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciula, Makhoul, 2006</marker>
<rawString>Snover, M., Dorr, B., Schwartz, R., Micciula, L., and Makhoul, J. (2006). A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA 2006), pages 223–231, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM - An Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference Spoken Language Processing,</booktitle>
<pages>901--904</pages>
<location>Denver, CO.</location>
<contexts>
<context position="9873" citStr="Stolcke, 2002" startWordPosition="1569" endWordPosition="1570">Nations parallel data. We used a maximum sentence length of 80 for en–es and 40 for en–cs. Detailed statistics are shown in Table 1. Corpus Langs. Sent. Source Target tokens tokens Europarl en–es 1.6M 43M 45M News-comm en–es 97k 2.4M 2.7M UN en–es 5.9M 160M 190M News-Comm en–cs 85k 1.8M 1.6M CzEng en–cs 7.8M 80M 69M Table 1: Statistics of en–cs and en–es parallel data. Monolingual data: For language modeling purposes, in addition to the target parts of the bilingual data, we used the monolingual News corpus for cs; and the Gigaword corpus for es. For both languages, we used the SRILM toolkit (Stolcke, 2002) to train a 5-gram language model using all monolingual data provided. However, for en–es we used the IRSTLM toolkit (Federico and Cettolo, 2007) to train a 5-gram language model using the es Gigaword corpus. Both language models use modified Kneser-Ney smoothing (Chen and Goodman, 1996). Statistics for the monolingual corpora are given in Table 2. Corpus Language Sentences Tokens E/N/NC/UN es 9,6M 290M Gigaword es 40M 1,2G News cs 13M 210M Table 2: Statistics of Monolingual Data. E/N/NC/UN refers to Europarl/News/News Commentary/United Nations corpora. For all the systems except Apertium, we </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Stolcke, A. (2002). SRILM - An Extensible Language Modeling Toolkit. In Proceedings of the International Conference Spoken Language Processing, pages 901–904, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Stroppa</author>
<author>A van den Bosch</author>
<author>A Way</author>
</authors>
<title>Exploiting Source Similarity for SMT using Context-Informed Features.</title>
<date>2007</date>
<booktitle>In Proceedings of the 11th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-07),</booktitle>
<pages>231--240</pages>
<location>Sk¨ovde,</location>
<marker>Stroppa, van den Bosch, Way, 2007</marker>
<rawString>Stroppa, N., van den Bosch, A., and Way, A. (2007). Exploiting Source Similarity for SMT using Context-Informed Features. In Proceedings of the 11th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-07), pages 231–240, Sk¨ovde, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Stroppa</author>
<author>A Way</author>
</authors>
<title>MaTrEx: the DCU machine translation system for IWSLT</title>
<date>2006</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation,</booktitle>
<pages>31--36</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="3879" citStr="Stroppa and Way, 2006" startWordPosition="585" endWordPosition="588">e. 2.2 Example-Based Machine Translation The EBMT system uses a language-specific, reduced set of closed-class marker morphemes or lexemes (Gough and Way, 2004) to define a way to segment sentences into chunks, which are then aligned using an edit-distance-style algorithm, in which edit costs depend on word-to-word translaProceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 143–148, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics Figure 1: System Framework. tion probabilities and the amount of word-to-word cognates (Stroppa and Way, 2006). Once these phrase pairs were obtained they were merged with the phrase pairs extracted by the baseline system adding word alignment information. 2.3 Apertium RBMT Apertium1 is a free/open-source platform for RBMT. The current version of the en–es system in Apertium was used for the system combination task (section 2.7), and its morphological analysers and part-of-speech taggers were used to build a factored Moses model. 2.4 Factored Translation Model We also used a factored model for the en–es translation task. Factored models (Koehn and Hoang, 2007) facilitate the translation by breaking it</context>
<context position="10825" citStr="Stroppa and Way, 2006" startWordPosition="1716" endWordPosition="1719">re given in Table 2. Corpus Language Sentences Tokens E/N/NC/UN es 9,6M 290M Gigaword es 40M 1,2G News cs 13M 210M Table 2: Statistics of Monolingual Data. E/N/NC/UN refers to Europarl/News/News Commentary/United Nations corpora. For all the systems except Apertium, we first lowercase and tokenize all the monolingual and bilingual data using the tools provided by the WMT10 organizers. After translation, system 145combination output is detokenised and true-cased. r = arg min i Ns E j=1 mentary corpus) and the Apertium RBMT system. We also derived phrase alignments using the MaTrEx EBMT system (Stroppa and Way, 2006), and added those phrase translations in the Moses phrase table. The systems marked with * use a language model built using the Spanish Gigaword corpus, in addition to the one built using the provided monolingual data. These 6 sets of system outputs are then used for system combination. 3.4 Experimental Results The evaluation results for en–es and en–cs experiments are shown in Table 3 and Table 4 respectively. The output of the systems marked t were submitted in the shared tasks. System BLEU NIST METEOR TER DCU-half †* 29.77% 7.68 59.86% 59.55% DCU-all †* 29.63% 7.66 59.82% 59.74% DCU-epn †* </context>
</contexts>
<marker>Stroppa, Way, 2006</marker>
<rawString>Stroppa, N. and Way, A. (2006). MaTrEx: the DCU machine translation system for IWSLT 2006. In Proceedings of the International Workshop on Spoken Language Translation, pages 31–36, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>N-gram Posterior Probabilities for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLTNAACL</booktitle>
<pages>72--77</pages>
<location>New York, NY.</location>
<contexts>
<context position="8645" citStr="Zens and Ney, 2006" startWordPosition="1364" endWordPosition="1367">posterior probability (Fiscus, 1997); • 3, 4-gram target language model; • word length penalty; • Null word length penalty; We use MERT (Och, 2003) to tune the weights of the CN. 2.8 Rescoring Rescoring is a very important part in postprocessing which can select a better hypothesis from the N-best list. We augmented our previous rescoring model (Du et al., 2009) with more large-scale data. The features we used include: • Direct and inverse IBM model; • 3, 4-gram target language model; • 3, 4, 5-gram PoS language model (Schmid, 1994; Ratnaparkhi, 1996); • Sentence length posterior probability (Zens and Ney, 2006); • N-gram posterior probabilities within the NBest list (Zens and Ney, 2006); • Minimum Bayes Risk probability; • Length ratio between source and target sentence; The weights are optimized via MERT. 3 Experimental Setup This section describes our experimental setup for the en–cs and en–es translation tasks. 3.1 Data Bilingual data: In the experiments we used data sets provided by the workshop organizers. For the en–cs translation table extraction we employed both parallel corpora (News-Commentary10 and CzEng 0.9), and for the en–es experiments, we used the Europarl(Koehn, 2005), News Commenta</context>
</contexts>
<marker>Zens, Ney, 2006</marker>
<rawString>Zens, R. and Ney, H. (2006). N-gram Posterior Probabilities for Statistical Machine Translation. In Proceedings of the Joint Meeting of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLTNAACL 2006), pages 72–77, New York, NY.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>