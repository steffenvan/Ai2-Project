<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000101">
<title confidence="0.9985">
A Probabilistic Model for Fine-Grained Expert Search
</title>
<author confidence="0.997139">
Shenghua Bao&apos;, Huizhong Duan&apos;, Qi Zhou&apos;, Miao Xiong&apos;, Yunbo Cao&apos;,2, Yong Yu&apos;
</author>
<affiliation confidence="0.837463">
1Shanghai Jiao Tong University, 2Microsoft Research Asia
Shanghai, China, 200240 Beijing, China, 100080
</affiliation>
<email confidence="0.9547365">
{shhbao,summer,jackson,xiongmiao,yyu} yunbo.cao@microsoft.com
@apex.sjtu.edu.cn
</email>
<sectionHeader confidence="0.993087" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9982807">
Expert search, in which given a query a
ranked list of experts instead of documents is
returned, has been intensively studied recently
due to its importance in facilitating the needs
of both information access and knowledge
discovery. Many approaches have been pro-
posed, including metadata extraction, expert
profile building, and formal model generation.
However, all of them conduct expert search
with a coarse-grained approach. With these,
further improvements on expert search are
hard to achieve. In this paper, we propose
conducting expert search with a fine-grained
approach. Specifically, we utilize more spe-
cific evidences existing in the documents. An
evidence-oriented probabilistic model for ex-
pert search and a method for the implementa-
tion are proposed. Experimental results show
that the proposed model and the implementa-
tion are highly effective.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999920192982457">
Nowadays, team work plays a more important role
than ever in problem solving. For instance, within
an enterprise, people handle new problems usually
by leveraging the knowledge of experienced col-
leagues. Similarly, within research communities,
novices step into a new research area often by
learning from well-established researchers in the
research area. All these scenarios involve asking
the questions like “who is an expert on X?” or
“who knows about X?” Such questions, which
cannot be answered easily through traditional
document search, raise a new requirement of
searching people with certain expertise.
To meet that requirement, a new task, called ex-
pert search, has been proposed and studied inten-
sively. For example, TREC 2005, 2006, and 2007
provide the task of expert search within the enter-
prise track. In the TREC setting, expert search is
defined as: given a query, a ranked list of experts is
returned. In this paper, we engage our study in the
same setting.
Many approaches to expert search have been
proposed by the participants of TREC and other
researchers. These approaches include metadata
extraction (Cao et al., 2005), expert profile build-
ing (Craswell, 2001, Fu et al., 2007), data fusion
(Maconald and Ounis, 2006), query expansion
(Macdonald and Ounis, 2007), hierarchical lan-
guage model (Petkova and Croft, 2006), and for-
mal model generation (Balog et al., 2006; Fang et
al., 2006). However, all of them conduct expert
search with what we call a coarse-grained ap-
proach. The discovering and use of evidence for
expert locating is carried out under a grain of
document. With it, further improvements on expert
search are hard to achieve. This is because differ-
ent blocks (or segments) of electronic documents
usually present different functions and qualities
and thus different impacts for expert locating.
In contrast, this paper is concerned with propos-
ing a probabilistic model for fine-grained expert
search. In fine-grained expert search, we are to
extract and use evidence of expert search (usually
blocks of documents) directly. Thus, the proposed
probabilistic model incorporates evidence of expert
search explicitly as a part of it. A piece of fine-
grained evidence is formally defined as a quadru-
ple, &lt;topic, person, relation, document&gt;, which
denotes the fact that a topic and a person, with a
certain relation between them, are found in a spe-
cific document. The intuition behind the quadruple
is that a query may be matched with phrases in
various forms (denoted as topic here) and an expert
candidate may appear with various name masks
(denoted as person here), e.g., full name, email, or
abbreviated names. Given a topic and person, rela-
tion type is used to measure their closeness and
</bodyText>
<page confidence="0.971493">
914
</page>
<note confidence="0.715537">
Proceedings of ACL-08: HLT, pages 914–922,
</note>
<page confidence="0.537672">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.991443928571429">
document serves as a context indicating whether it
is good evidence.
Our proposed model for fine-grained expert
search results in an implementation of two stages.
1) Evidence Extraction: document segments in
various granularities are identified and evidences
are extracted from them. For example, we can have
segments in which an expert candidate and a que-
ried topic co-occur within a same section of docu-
ment-001: “...later, Berners-Lee describes a
semantic web search engine experience...” As the
result, we can extract an evidence by using same-
section relation, i.e., &lt;semantic web search engine,
Berners-Lee, same-section, document-001&gt;.
</bodyText>
<listItem confidence="0.958496090909091">
2) Evidence Quality Evaluation: the quality (or
reliability) of evidence is evaluated. The quality of
a quadruple of evidence consists of four aspects,
namely topic-matching quality, person-name-
matching quality, relation quality, and document
quality. If we regard evidence as link of expert
candidate and queried topic, the four aspects will
correspond to the strength of the link to query, the
strength of the link to expert candidate, the type of
the link, and the document context of the link re-
spectively.
</listItem>
<bodyText confidence="0.99931">
All the evidences with their scores of quality are
merged together to generate a single score for each
expert candidate with regard to a given query. We
empirically evaluate our proposed model and im-
plementation on the W3C corpus which is used in
the expert search task at TREC 2005 and 2006.
Experimental results show that both explored evi-
dences and evaluation of evidence quality can im-
prove the expert search significantly. Compared
with existing state-of-the-art expert search methods,
the probabilistic model for fine-grained expert
search shows promising improvement.
The rest of the paper is organized as follows.
Section 2 surveys existing studies on expert search.
Section 3 and Section 4 present the proposed prob-
abilistic model and its implementation, respec-
tively. Section 5 gives the empirical evaluation.
Finally, Section 6 concludes the work.
</bodyText>
<sectionHeader confidence="0.999939" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.991262">
2.1 Expert Search Systems
</subsectionHeader>
<bodyText confidence="0.99994947826087">
One setting for automatic expert search is to as-
sume that data from specific resources are avail-
able. For example, Expertise Recommender (Kautz
et al., 1996), Expertise Browser (Mockus and
Herbsleb, 2002) and the system in (McDonald and
Ackerman, 1998) make use of log data in software
development systems to find experts. Yet another
approach is to mine expert and expertise from
email communications (Campbell et al., 2003;
Dom et al. 2003; Sihn and Heeren, 2001).
Searching expert from general documents has
also been studied (Davenport and Prusak, 1998;
Mattox et al., 1999; Hertzum and Pejtersen, 2000).
P@NOPTIC employs what is referred to as the
‘profile-based’ approach in searching for experts
(Craswell et al., 2001). Expert/Expert-Locating
(EEL) system (Steer and Lochbaum, 1988) uses
the same approach in searching for expert groups.
DEMOIR (Yimam, 1996) enhances the profile-
based approach by separating co-occurrences into
different types. In essence, the profile-based ap-
proach utilizes the co-occurrences between query
words and people within documents.
</bodyText>
<subsectionHeader confidence="0.992741">
2.2 Expert Search at TREC
</subsectionHeader>
<bodyText confidence="0.999841428571429">
A task on expert search was organized within the
enterprise track at TREC 2005, 2006 and 2007
(Craswell et al., 2005; Soboroff et al., 2006; Bai-
ley et al., 2007).
Many approaches have been proposed for tack-
ling the expert search task within the TREC track.
Cao et al. (2005) propose a two-stage model with a
set of extracted metadata. Balog et al. (2006) com-
pare two generative models for expert search. Fang
et al. (2006) further extend their generative model
by introducing the prior of expert distribution and
relevance feedback. Petkova and Croft (2006) fur-
ther extend the profile based method by using a
hierarchical language model. Macdonald and
Ounis (2006) investigate the effectiveness of the
voting approach and the associated data fusion
techniques. However, such models are conducted
in a coarse-grain scope of document as discussed
before. In contrast, our study focuses on proposing
a model for conducting expert search in a fine-
grain scope of evidence (local context).
</bodyText>
<sectionHeader confidence="0.985453" genericHeader="method">
3 Fine-grained Expert Search
</sectionHeader>
<bodyText confidence="0.9989388">
Our research is to investigate a direct use of the
local contexts for expert search. We call each local
context of such kind as fine-grained evidence.
In this work, a fine-grained evidence is formally
defined as a quadruple, &lt;topic, person, relation,
</bodyText>
<page confidence="0.997845">
915
</page>
<bodyText confidence="0.999046733333333">
document&gt;. Such a quadruple denotes that a topic
and a person occurrence, with a certain relation
between them, are found in a specific document.
Recall that topic is different from query. For ex-
ample, given a query “semantic web coordination”,
the corresponding topic may be either “semantic
web” or “web coordination”. Similarly, person
here is different from expert candidate. E.g, given
an expert candidate “Ritu Raj Tiwari”, the matched
person may be “Ritu Raj Tiwari”, “Tiwari”, or
“RRT” etc. Although both the topics and persons
may not match the query and expert candidate ex-
actly, they do have certain indication on the con-
nection of query “semantic web coordination” and
expert “Ritu Raj Tiwari”.
</bodyText>
<subsectionHeader confidence="0.995034">
3.1 Evidence-Oriented Expert Search Model
</subsectionHeader>
<bodyText confidence="0.999603333333333">
We conduct fine-grained expert search by incorpo-
rating evidence of local context explicitly in a
probabilistic model which we call an evidence-
oriented expert search model. Given a query q, the
probability of a candidate c being an expert (or
knowing something about q) is estimated as
</bodyText>
<equation confidence="0.997441833333333">
P c q
(  |) = I P c e q
( ,  |)
,
(1)
e
</equation>
<bodyText confidence="0.9964695">
where e denotes a quadruple of evidence.
Using the relaxation that the probability of c is
independent of a query q given an evidence e, we
can reduce Equation (1) as,
</bodyText>
<equation confidence="0.989204">
P c q = ! P c e P e q .
(  |) (  |) (  |) (2)
e
</equation>
<bodyText confidence="0.999949888888889">
Compared to previous work, our model conducts
expert search with a new way in which local con-
texts of evidence are used to bridge a query q and
an expert candidate c. The new way enables the
expert search system to explore various local con-
texts in a precise manner.
In the following sub-sections, we will detail two
sub-models: the expert matching model P(c|e) and
the evidence matching model P(e|q).
</bodyText>
<subsectionHeader confidence="0.992674">
3.2 Expert Matching Model
</subsectionHeader>
<bodyText confidence="0.999973285714286">
We expand the evidence e as quadruple &lt;topic,
people, relation, document&gt; (&lt;t, p, r, d&gt; for short)
for expert matching. Given a set of related evi-
dences, we assume that the generation of an expert
candidate c is independent with topic t and omit it
in expert matching. Therefore, we simplify the ex-
pert matching formula as below:
</bodyText>
<equation confidence="0.9975935">
P c e = P c p r d = P c p P p r d
(  |) (  |, , ) (  |) (  |, ) , (3)
</equation>
<bodyText confidence="0.996787875">
where P(c|p) depends on how an expert candidate c
matches to a person occurrence p (e.g. full name or
email of a person). The different ways of matching
an expert candidate c with a person occurrence p
results in varied qualities. P(c|p) represents the
quality. P(p|r,d) expresses the probability of an
occurrence p given a relation r and a document d.
P(p|r,d) is estimated in MLE as,
</bodyText>
<equation confidence="0.999154333333333">
P(p  |r, d) = freq(p, r, d) , (4)
L r d
( , )
</equation>
<bodyText confidence="0.9756474">
where freq(p,r,d) is the frequency of person p
matched by relation r in document d, and L(r, d) is
the frequency of all the persons matched by rela-
tion r in d. This estimation can further be smoothed
by using the evidence collection as follows:
PS(p|r,d)=µP(p|r,d)+(1#µ)I |Did&apos; ), (5)
where D denotes the whole document collection.
|D |is the total number of documents.
We use Dirichlet prior in smoothing of parame-
ter µ:
</bodyText>
<equation confidence="0.981955">
µ L(r,d)+K,
_ L(r, d) (6)
</equation>
<bodyText confidence="0.999933">
where K is the average frequency of all the experts
in the collection.
</bodyText>
<subsectionHeader confidence="0.993689">
3.3 Evidence Matching Model
</subsectionHeader>
<bodyText confidence="0.999904333333333">
By expanding the evidence e and employing inde-
pendence assumption, we have the following for-
mula for evidence matching:
</bodyText>
<equation confidence="0.999936">
P(e  |q) = PQ,
Pt q P p q P r q P d q
(  |) (  |) (  |) (  |)
</equation>
<bodyText confidence="0.999956888888889">
In the following, we are to explain what these
four terms represent and how they can be estimated.
The first term P(t|q) represents the probability
that a query q matches to a topic t in evidence. Re-
call that a query q may match a topic t in various
ways, not necessarily being identical to t. For ex-
ample, both topic “semantic web” and “semantic
web search engine” can match the query “semantic
web search engine”. The probability is defined as
</bodyText>
<equation confidence="0.969221888888889">
e
=1
P c e q P e q
(  |, ) (  |)
p r d  |q)
, ,
. (7)
916
P(t  |q) « P(type(t,q)), (8)
</equation>
<bodyText confidence="0.999759714285714">
where type(t, q) represents the way that q matches
to t, e.g., phrase matching. Different matching
methods are associated with different probabilities.
The second term P(p|q) represents the probabil-
ity that a person p is generated from a query q. The
probability is further approximated by the prior
probability of p,
</bodyText>
<equation confidence="0.995286">
P(p  |q) « P(p) . (9)
</equation>
<bodyText confidence="0.999331833333333">
The prior probability can be estimated by MLE,
i.e., the ratio of total occurrences of person p in the
collection.
The third term represents the probability that a
relation r is generated from a query q. Here, we
approximate the probability as
</bodyText>
<equation confidence="0.995739">
P(r  |q) « P(type(r)) , (10)
</equation>
<bodyText confidence="0.9994118">
where type(r) represents the way r connecting
query and expert. P(type(r)) represents the reliabil-
ity of relation type of r.
Following the Bayes rule, the last term can be
transformed as
</bodyText>
<equation confidence="0.991066">
P(d  |q) = P(q  |P(q) (d) « P(q  |d)P(d)
</equation>
<bodyText confidence="0.947358333333333">
where priority distribution P(d) can be estimated
based on static rank, e.g., PageRank (Brin and
Page, 1998). P(q|d) can be estimated by using a
standard language model for IR (Ponte and Croft,
1998).
In summary, Equation (7) is converted to
</bodyText>
<equation confidence="0.9997045">
P e q - Ptype t q P p P type r P q d P d
(  |) ( ( , )) ( ) ( ( )) (  |) ( ) . (12)
</equation>
<subsectionHeader confidence="0.92543">
3.4 Evidence Merging
</subsectionHeader>
<bodyText confidence="0.9996722">
We assume that the ranking score of an expert can
be acquired by summing up together all scores of
the supporting evidences. Thus we calculate ex-
perts’ scores by aggregating the scores from all
evidences as in Equation (1).
</bodyText>
<sectionHeader confidence="0.999137" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.993413">
The implementation of the proposed model con-
sists of two stages, namely evidence extraction and
evidence quality evaluation.
</bodyText>
<subsectionHeader confidence="0.991458">
4.1 Evidence Extraction
</subsectionHeader>
<bodyText confidence="0.9997954">
Recall that we define an evidence for expert search
as a quadruple &lt;topic, person, relation, document&gt;.
The evidence extraction covers the extraction of
the first three elements, namely person identifica-
tion, topic discovering and relation extraction.
</bodyText>
<subsubsectionHeader confidence="0.888218">
4.1.1 Person Identification
</subsubsectionHeader>
<bodyText confidence="0.999827333333333">
The occurrences of an expert can be in various
forms, such as name and email address. We call
each type of form an expert mask. Table 1 provides
a statistic on various masks on the basis of W3C
corpus. In Table 1, rate is the proportion of the
person occurrences with relevant masks to the per-
son occurrences with any of the masks, and ambi-
guity is defined as the probability that a mask is
shared by more than one expert.
</bodyText>
<table confidence="0.999505">
Mask Rate/Ambiguity Sample
Full Name(NF) 48.2% / 0.0000 Ritu Raj Tiwari
Email Name(NE) 20.1% / 0.0000 rtiwari@nuance.com
Combined Name 4.2% /0.3992 Tiwari, Ritu R;
(NC) R R Tiwari
Abbr. Name(NA) 21.2% / 0.4890 Ritu Raj ; Ritu
Short Name(NS) 0.7% / 0.6396 RRT
Alias, new email 7% / 0.4600 Ritiwari rti-
(NAE) wari@hotmail.com
</table>
<tableCaption confidence="0.999941">
Table 1. Various masks and their ambiguity
</tableCaption>
<bodyText confidence="0.962363866666667">
Every occurrence of a candidate’s email address
is normalized to the appropriate candidate_id.
Every occurrence of a candidate’s full_name is
normalized to the appropriate candidate_id if
there is no ambiguity; otherwise, the occurrence
is normalized to the candidate_id of the most
frequent candidate with that full_name.
Every occurrence of combined name, abbrevi-
ated name, and email alias is normalized to the
appropriate candidate_id if there is no ambigu-
ity; otherwise, the occurrence may be normal-
ized to the candidate_id of a candidate whose
full name also appears in the document.
All the personal occurrences other than those
covered by Heuristic 1) ~ 3) are ignored.
</bodyText>
<tableCaption confidence="0.989603">
Table 2. Heuristic rules for expert extraction
</tableCaption>
<bodyText confidence="0.999654">
As Table 1 demonstrates, it is not an easy task to
identify all the masks with regards to an expert. On
one hand, the extraction of full name and email
address is straightforward but suffers from low
coverage. On the other hand, the extraction of
</bodyText>
<page confidence="0.986396">
917
</page>
<bodyText confidence="0.999958818181818">
combined name and abbreviated name can com-
plement the coverage, while needs handling of am-
biguity.
Table 2 provides the heuristic rules that we use
for expert identification. In the step 2) and 3), the
rules use frequency and context discourse for re-
solving ambiguities respectively. With frequency,
each expert candidate actually is assigned a prior
probability. With context discourse, we utilize the
intuition that person names appearing similar in a
document usually refers to the same person.
</bodyText>
<subsubsectionHeader confidence="0.677224">
4.1.2 Topic Discovering
</subsubsectionHeader>
<bodyText confidence="0.998952428571429">
A queried topic can occur within documents in
various forms, too. We use a set of query process-
ing techniques to handle the issue. After the proc-
essing, a set of topics transformed from an original
query will be obtained and then be used in the
search for experts. Table 3 shows five forms of
topic discovering from a given query.
</bodyText>
<table confidence="0.998927357142857">
Forms Description Sample
Phrase The exact match with origi- “semantic web
Match(QP) nal query given by users search engine”
Bi-gram A set of matches formed by “semantic web”
Match(QB) extracting bi-gram of words “search en-
in the original query gine”
Proximity Each query term appears as “semantic web
Match(QPR) a neighborhood within a enhanced
window of specified size search engine”
Fuzzy A set of matches, each of “sementic web
Match(QF) which resembles the origi- seerch engine”
nal query in appearance.
Stemmed A match formed by stem- “sementic web
Match(QS) ming the original query. seerch engin”
</table>
<tableCaption confidence="0.975858">
Table 3. Discovered topics from query “semantic web
search engine”
</tableCaption>
<subsubsectionHeader confidence="0.544961">
4.1.3 Relation Extraction
</subsubsectionHeader>
<bodyText confidence="0.999778692307692">
We focus on extracting relations between topics
and expert candidates within a span of a document.
To make the extraction easier, we partition a
document into a pre-defined layout. Figure 1 pro-
vides a template in Backus–Naur form. Figure 2
provides a practical use of the template.
Note that we are not restricting the use of the
template only for certain corpus. Actually the tem-
plate can be applied to many kinds of documents.
For example, for web pages, we can construct the
&lt;Title&gt; from either the ‘title’ metadata or the con-
tent of web pages (Hu et al., 2006). As for e-mail,
we can use the ‘subject’ field as the &lt;Title&gt;.
</bodyText>
<figureCaption confidence="0.987648">
Figure. 1. A template of document layout
</figureCaption>
<figure confidence="0.997343">
&lt;Title&gt; RDF Primer
&lt;Author&gt;Editors: Frank Manola, fmanola@acm.org
Eric Miller, W3C, em@w3.org
&lt;Body&gt;
</figure>
<figureCaption confidence="0.999938">
Figure 2. An example use of the layout template
</figureCaption>
<bodyText confidence="0.9803146">
With the layout of partitioned documents, we
can then explore many types of relations among
different blocks. In this paper, we demonstrate the
use of five types of relations by extending the
study in (Cao et al., 2005).
Section Relation (RS): The queried topic and
the expert candidate occur in the same &lt;Section&gt;.
Windowed Section Relation (RWS): The que-
ried topic and the expert candidate occur within a
fixed window of a &lt;Section&gt;. In our experiment,
we used a window of 200 words.
Reference Section Relation (RRS): Some &lt;Sec-
tion&gt;s should be treated specially. For example,
the &lt;Section&gt; consisting of reference information
like a list of &lt;book, author&gt; can serve as a reliable
source connecting a topic and an expert candidate.
We call the relation appearing in a special type of
&lt;Section&gt; a special reference section relation. It
might be argued whether the use of special sections
can be generalized. According to our survey, the
special &lt;Section&gt;s can be found in various sites
such as Wikipedia as well as W3C.
Title-Author Relation (RTA): The queried topic
appears in the &lt;Title&gt; and the expert candidate
appears in the &lt;Author&gt;.
</bodyText>
<figure confidence="0.998020666666667">
&lt;Section&gt;
&lt;Section Title&gt;
2. Making Statements About Resources
&lt;Section Body&gt;
RDF is intended to provide a simple way to make state
These capabilities (the normative specification describe)
2.1 Basic Concepts
Imagine trying to state that someone named John Smith
The form of a simple statement such as:
...
...
...
</figure>
<page confidence="0.985546">
918
</page>
<bodyText confidence="0.993012692307692">
Section Title-Body Relation (RSTB): The que-
ried topic and the expert candidate appear in the
&lt;Section Title&gt; and &lt;Section Body&gt; of the same
&lt;Section&gt;, respectively. Reversely, the queried
topic and the expert candidate can appear in the
&lt;Section Body&gt; and &lt;Section Title&gt; of a &lt;Section&gt;.
The latter case is used to characterize the docu-
ments introducing certain expert or the expert in-
troducing certain document.
Note that our model is not restricted to use these
five relations. We use them only for the aim of
demonstrating the flexibility and effectiveness of
fine-grained expert search.
</bodyText>
<subsectionHeader confidence="0.984458">
4.2 Evidence Quality Evaluation
</subsectionHeader>
<bodyText confidence="0.9999765">
In this section, we elaborate the mechanism used
for evaluating the quality of evidence.
</bodyText>
<subsubsectionHeader confidence="0.728709">
4.2.1 Topic-Matching Quality
</subsubsectionHeader>
<bodyText confidence="0.9999476">
In Section 4.1.2, we use five techniques in process-
ing query matches, which yield five sets of match
types for a given query. Obviously, the different
query matches should be associated with different
weights because they represent different qualities.
We further note that different bi-grams gener-
ated from the same query with the bi-gram match-
ing method might also present different qualities.
For example, both topic “css test” and “test suite”
are the bi-gram matching for query “css test suite”;
however, the former might be more informative.
To model that, we use the number of returned
documents to refine the query weight. The intuition
behind that is similar to the thought of IDF popu-
larly used in IR as we prefer to the distinctive bi-
grams.
Taking into consideration the above two factors,
we calculate the topic-matching quality Qt (corre-
sponding to P(type(t,q)) in Equation (12) ) for the
given query q as
</bodyText>
<equation confidence="0.961469">
Qt = W (type(t, q)) MIN, (df,
)
dft
</equation>
<bodyText confidence="0.9997893">
where t means the discovered topic from a docu-
ment and type(t,q) is the matching type between
topic t and query q. W(type(t,q)) is the weight for a
certain query type, dft is the number of returned
documents matched by topic t. In our experiment,
we use the 10 training topics of TREC2005 as our
training data, and the best quality scores for phrase
match, bi-gram match, proximity match, fuzzy
match, and stemmed match are 1, 0.01, 0.05, 10-8,
and 10-4, respectively.
</bodyText>
<subsubsectionHeader confidence="0.641124">
4.2.2 Person-Matching Quality
</subsubsectionHeader>
<bodyText confidence="0.999982384615385">
An expert candidate can occur in the documents in
various ways. The most confident occurrence
should be the ones in full name or email address.
Others can include last name only, last name plus
initial of first name, etc. Thus, the action of reject-
ing or accepting a person from his/her mask (the
surface expression of a person in the text) is not
simply a Boolean decision, but a probabilistic one
with a reliability weight Qp (corresponding to P(c|p)
in Equation (3) ). Similarly, the best trained
weights for full name, email name, combined name,
abbreviated name, short name, and alias email are
set to 1, 1, 0.8, 0.2, 0.2, and 0.1, respectively.
</bodyText>
<subsectionHeader confidence="0.536535">
4.2.3 Relation Type Quality
</subsectionHeader>
<bodyText confidence="0.999957769230769">
The relation quality consists of two factors. One
factor is about the type of the relation. Different
types of relations indicate different strength of the
connection between expert candidates and queried
topics. In our system, the section title-body rela-
tion is given the highest confidence. The other fac-
tor is about the degree of proximity between a
query and an expert candidate. The intuition is that,
the more distant are a query and an expert candi-
date within a relation, the looser the connection
between them is. To include these two factors, the
quality score Qr (corresponding to P(type(r)) in
Equation (12) )of a relation r is defined as:
</bodyText>
<equation confidence="0.995954666666667">
Q 14
Cr ( )
dis(p,t)+1&apos;
</equation>
<bodyText confidence="0.999821875">
where Wr is the weight of relation type r, dis(p, t)
is the distance from the person occurrence p to the
queried topic t and Cr is a constant for normaliza-
tion. Again, we optimize the Wr based on the train-
ing topics, the best weights for section relation,
windowed section relation, reference section rela-
tion, title-author relation, and section title-body
relation are 1, 4, 10, 45, and 1000 respectively.
</bodyText>
<subsectionHeader confidence="0.64768">
4.2.4 Document Quality
</subsectionHeader>
<bodyText confidence="0.99986125">
The quality of evidence also depends on the quality
of the document, the context in which it is found.
The document context can affect the credibility of
the evidence in two ways:
</bodyText>
<equation confidence="0.951215">
, (13)
</equation>
<page confidence="0.99407">
919
</page>
<bodyText confidence="0.999902083333333">
Static quality: indicating the authority of a
document. In our experiment, the static quality Qd
(corresponding to P(d) in Equation (12) ) is esti-
mated by the PageRank, which is calculated using
a standard iterative algorithm with a damping fac-
tor of 0.85 (Brin and Page, 1998).
Dynamic quality: by “dynamic”, we mean the
quality score varies for different queries q. We de-
note the dynamic quality as QDY(d,q) (correspond-
ing to P(q|d) in Equation (12) ), which is actually
the document relevance score returned by a stan-
dard language model for IR(Ponte and Croft, 1998).
</bodyText>
<sectionHeader confidence="0.977683" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.99264">
5.1 The Evaluation Data
</subsectionHeader>
<bodyText confidence="0.9999962">
In our experiment, we used the data set in the ex-
pert search task of enterprise search track at TREC
2005 and 2006. The document collection is a crawl
of the public W3C sites in June 2004. The crawl
comprises in total 331,307 web pages. In the fol-
lowing experiments, we used the training set of 10
topics of TREC 2005 for tuning the parameters
aforementioned in Section 4.2, and used the test set
of 50 topics of TREC 2005 and 49 topics of TREC
2006 as the evaluation data sets.
</bodyText>
<subsectionHeader confidence="0.997802">
5.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.99986575">
We used three measures in evaluation: Mean aver-
age precision (MAP), R-precision (R-P), and Top
N precision (P@N). They are also the standard
measures used in the expert search task of TREC.
</bodyText>
<subsectionHeader confidence="0.998983">
5.3 Evidence Extraction
</subsectionHeader>
<bodyText confidence="0.9999768">
In the following experiments, we constructed the
baseline by using the query matching methods of
phrase matching, the expert matching methods of
full name matching and email matching, and the
relation of section relation. To show the contribu-
tion of each individual method for evidence extrac-
tion, we incrementally add the methods to the
baseline method. In the following description, we
will use ‘+’ to denote applying new method on the
previous setting.
</bodyText>
<subsectionHeader confidence="0.684575">
5.3.1 Query Matching
</subsectionHeader>
<bodyText confidence="0.999562714285714">
QB, QPR, QF, and QS denote bi-gram match, prox-
imity match, fuzzy match, and stemmed match,
respectively. The performance of the proposed
model increases stably on MAP when new query
matches are added incrementally. We also find that
the introduction of QF and QS bring some drop on
R-Precision and P@10. It is reasonable because
both QF and QS bring high recall while affect the
precision a bit. The overall relative improvement
of using query matching compared to the baseline
is presented in the row “Improv.”. We performed t-
tests on MAP. The p-values (&lt; 0.05) are presented
in the “T-test” row, which shows that the im-
provement is statistically significant.
</bodyText>
<table confidence="0.998992">
TREC 2005 TREC 2006
MAP R-P P@10 MAP R-P P@10
Baseline 0.1840 0.2136 0.3060 0.3752 0.4585 0.5604
+QB 0.1957 0.2438 0.3320 0.4140 0.4910 0.5799
+QPR 0.2024 0.2501 0.3360 0.4530 0.5137 0.5922
+QF ,QS 0.2030 0.2501 0.3360 0.4580 0.5112 0.5901
Improv. 10.33% 17.09% 9.80% 22.07% 11.49% 5.30%
T-test 0.0084 0.0000
</table>
<tableCaption confidence="0.999904">
Table 4. The effects of query matching
</tableCaption>
<subsubsectionHeader confidence="0.698266">
5.3.2 Person Matching
</subsubsectionHeader>
<bodyText confidence="0.998820545454545">
For person matching, we considered four types of
masks, namely combined name (NC), abbreviated
name (NA), short name (NS) and alias and new
email (NAE). Table 5 provides the results on person
matching at TREC 2005 and 2006. The baseline is
the best model achieved in previous section. It
seems that there is little improvement on P@10
while an improvement of 6.21% and 14.00% is
observed on MAP. This might be due to the fact
that the matching method such as NC has a higher
recall but lower precision.
</bodyText>
<table confidence="0.998540777777778">
TREC 2005 TREC 2006
MAP R-P P@10 MAP R-P P@10
Baseline 0.2030 0.2501 0.3360 0.4580 0.5112 0.5901
+NC 0.2056 0.2539 0.3463 0.4709 0.5152 0.5931
+NA 0.2106 0.2545 0.3400 0.5010 0.5181 0.6000
+NS 0.2111 0.2578 0.3400 0.5121 0.5192 0.6000
+NAE 0.2156 0.2591 0.3400 0.5221 0.5212 0.6000
Improv. 6.21% 3.60% 1.19% 14.00% 1.96% 1.68%
T-test 0.0064 0.0057
</table>
<tableCaption confidence="0.999824">
Table 5. The effects of person matching
</tableCaption>
<bodyText confidence="0.7737015">
Table 4 shows the results of expert search achieved
by applying different methods of query matching.
</bodyText>
<page confidence="0.984165">
920
</page>
<subsectionHeader confidence="0.526395">
5.3.3 Multiple Relations
</subsectionHeader>
<bodyText confidence="0.9996555">
For relation extraction, we experimentally demon-
strated the use of each of the five relations pro-
posed in Section 4.1.3, i.e., section relation (RS),
windowed section relation (RWS), reference section
relation (RRS), title-author relation (RTA), and sec-
tion title-body relation (RSTB). We used the best
model achieved in previous section as the baseline.
From Table 6, we can see that the section title-
body relation contributes the most to the improve-
ment of the performance. By using all the discov-
ered relations, a significant improvement of
19.94% and 8.35% is achieved.
</bodyText>
<table confidence="0.999043555555556">
TREC 2005 TREC 2006
MAP R-P P@10 MAP R-P P@10
Baseline 0.2156 0.2591 0.3400 0.5221 0.5212 0.6000
+RWS 0.2158 0.2633 0.3380 0.5255 0.5311 0.6082
+RRS 0.2160 0.2630 0.3380 0.5272 0.5314 0.6061
+RTA 0.2234 0.2634 0.3580 0.5354 0.5355 0.6245
+RSTB 0.2586 0.3107 0.3740 0.5657 0.5669 0.6510
Improv. 19.94% 19.91% 10.00% 8.35% 8.77% 8.50%
T-test 0.0013 0.0043
</table>
<tableCaption confidence="0.99376">
Table 6. The effects of relation extraction
</tableCaption>
<subsectionHeader confidence="0.98096">
5.4 Evidence Quality
</subsectionHeader>
<bodyText confidence="0.999284642857143">
The performance of expert search can be further
improved by considering the evidence quality. Ta-
ble 7 shows the results by considering the differ-
ences in quality.
We evaluated two kinds of evidence quality:
context static quality (Qd) and context dynamic
quality (QDY). Each of the evidence quality con-
tributes about 1%-2% improvement for MAP. The
improvement from the PageRank that we calcu-
lated from the corpus implies that the web scaled
rank technique is also effective in the corpus of
documents. Finally, we find a significant relative
improvement of 6.13% and 2.86% on MAP by us-
ing evidence qualities.
</bodyText>
<table confidence="0.998001714285714">
TREC 2005 TREC 2006
MAP R-P P@10 MAP R-P P@10
Baseline 0.2586 0.3107 0.3740 0.5657 0.5669 0.6510
+Qd 0.2711 0.3188 0.3720 0.5900 0.5813 0.6796
+QDY 0.2755 0.3252 0.3880 0.5943 0.5877 0.7061
Improv. 6.13% 4.67% 3.74% 2.86% 3.67% 8.61%
T-test 0.0360 0.0252
</table>
<tableCaption confidence="0.999796">
Table 7. The effects of using evidence quality
</tableCaption>
<subsectionHeader confidence="0.993676">
5.5 Comparison with Other Systems
</subsectionHeader>
<bodyText confidence="0.991270285714286">
In Table 8, we juxtapose the results of our prob-
abilistic model for fine-grained expert search with
automatic expert search systems from the TREC
evaluation. The performance of our proposed
model is rather encouraging, which achieved com-
parable results to the best automatic systems on the
TREC 2005 and 2006.
</bodyText>
<table confidence="0.997170142857143">
MAP R-prec Prec@10
Rank-1 TREC2005 0.2749 0.3330 0.4520
System
TREC20061 0.5947 0.5783 0.7041
Our TREC2005 0.2755 0.3252 0.3880
System
TREC2006 0.5943 0.5877 0.7061
</table>
<tableCaption confidence="0.999976">
Table 8. Comparison with other systems
</tableCaption>
<sectionHeader confidence="0.998978" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99900965">
This paper proposed to conduct expert search using
a fine-grained level of evidence. Specifically,
quadruple evidence was formally defined and
served as the basis of the proposed model. Differ-
ent implementations of evidence extraction and
evidence quality evaluation were also comprehen-
sively studied. The main contributions are:
1. The proposal of fine-grained expert search,
which we believe to be a promising direc-
tion for exploring subtle aspects of evidence.
2. The proposal of probabilistic model for fine-
grained expert search. The model facilitates
investigating the subtle aspects of evidence.
3. The extensive evaluation of the proposed
probabilistic model and its implementation
on the TREC data set. The evaluation shows
promising expert search results.
In future, we are to explore more domain inde-
pendent evidences and evaluate the proposed
model on the basis of the data from other domains.
</bodyText>
<sectionHeader confidence="0.998844" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9957382">
The authors would like to thank the three anony-
mous reviewers for their elaborate and helpful
comments. The authors also appreciate the valu-
able suggestions of Hang Li, Nick Craswell,
Yangbo Zhu and Linyun Fu.
</bodyText>
<footnote confidence="0.843436">
1 This system, where cluster-based re-ranking is used, is a
variation of the fine-grained model proposed in this paper.
</footnote>
<page confidence="0.996698">
921
</page>
<sectionHeader confidence="0.995836" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999113506172839">
Bailey, P., Soboroff , I., Craswell, N., and Vries A.P.,
Overview of the TREC 2007 Enterprise Track. In:
Proc. of TREC 2007.
Balog, K., Azzopardi, L., and Rijke, M. D., 2006.
Formal models for expert finding in enterprise cor-
pora. In: Proc. of SIGIR’06,pp.43-50.
Brin, S. and Page, L., 1998. The anatomy of a rlarge-
scale hypertextual Web search engine, Computer
Networks and ISDN Systems (30), pp.107-117.
Campbell, C.S., Maglio, P., Cozzi, A. and Dom, B.,
2003. Expertise identification using email communi-
cations. In: Proc. of CIKM ’03 pp.528–531.
Cao, Y., Liu, J., and Bao, S., and Li, H., 2005. Research
on expert search at enterprise track of TREC 2005. In:
Proc. of TREC 2005.
Craswell, N., Hawking, D., Vercoustre, A. M. and Wil-
kins, P., 2001. P@NOPTIC Expert: searching for ex-
perts not just for documents. In: Proc. of Ausweb’01.
Craswell, N., Vries, A.P., and Soboroff, I., 2005. Over-
view of the TREC 2005 Enterprise Track. In: Proc.
of TREC 2005.
Davenport, T. H. and Prusak, L., 1998. Working
Knowledge: how organizations manage what they
know. Howard Business, School Press, Boston, MA.
Dom, B., Eiron, I., Cozzi A. and Yi, Z., 2003. Graph-
based ranking algorithms for e-mail expertise analy-
sis, In: Proc. of SIGMOD’03 workshop on Research
issues in data mining and knowledge discovery.
Fang, H., Zhou, L., Zhai, C., 2006. Language models
for expert finding-UIUC TREC 2006 Enterprise
Track Experiments, In: Proc. of TREC2006.
Fu, Y., Xiang, R., Liu, Y., Zhang, M., Ma, S., 2007. A
CDD-based Formal Model for Expert Finding. In
Proc. of CIKM 2007.
Hertzum, M. and Pejtersen, A. M., 2000. The informa-
tion-seeking practices of engineers: searching for
documents as well as for people. Information Proc-
essing and Management, 36(5), pp.761–778.
Hu, Y., Li, H., Cao, Y., Meyerzon, D. Teng, L., and
Zheng, Q., 2006. Automatic extraction of titles from
general documents using machine learning, IPM.
Kautz, H., Selman, B. and Milewski, A., 1996. Agent
amplified communication. In: Proc. of AAAI‘96, pp.
3–9.
Mattox, D., Maybury, M. and Morey, D., 1999. Enter-
prise expert and knowledge discovery. Technical Re-
port.
McDonald, D. W. and Ackerman, M. S., 1998. Just Talk
to Me: a field study of expertise location. In: Proc. of
CSCW’98, pp.315-324.
Mockus, A. and Herbsleb, J.D., 2002. Expertise
Browser: a quantitative approach to identifying ex-
pertise, In: Proc. of ICSE’02.
Maconald, C. and Ounis, I., 2006. Voting for candi-
dates: adapting data fusion techniques for an expert
search task. In: Proc. of CIKM&apos;06, pp.387-396.
Macdonald, C. and Ounis, I., 2007. Expertise Drift and
Query Expansion in Expert Search. In Proc. of CIKM
2007.
Petkova, D., and Croft, W. B., 2006. Hierarchical lan-
guage models for expert finding in enterprise cor-
pora, In: Proc. of ICTAI’06, pp.599-608.
Ponte, J. and Croft, W., 1998. A language modeling
approach to information retrieval, In: Proc. of
SIGIR’98, pp.275-281.
Sihn, W. and Heeren F., 2001. Xpertfinder-expert find-
ing within specified subject areas through analysis of
e-mail communication. In: Proc. of the 6th Annual
Scientific conference on Web Technology.
Soboroff, I., Vries, A.P., and Craswell, N., 2006. Over-
view of the TREC 2006 Enterprise Track. In: Proc.
of TREC 2006.
Steer, L.A. and Lochbaum, K.E., 1988. An ex-
pert/expert locating system based on automatic repre-
sentation of semantic structure, In: Proc. of the 4th
IEEE Conference on Artificial Intelligence Applica-
tions.
Yimam, D., 1996. Expert finding systems for organiza-
tions: domain analysis and the DEMOIR approach.
In: ECSCW’99 workshop of beyond knowledge man-
agement: managing expertise, pp. 276–283.
</reference>
<page confidence="0.99692">
922
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.664919">
<title confidence="0.999497">A Probabilistic Model for Fine-Grained Expert Search</title>
<author confidence="0.980864">Huizhong Qi Miao Yunbo Yong</author>
<affiliation confidence="0.984773">Jiao Tong University, Research Asia</affiliation>
<address confidence="0.999861">Shanghai, China, 200240 Beijing, China, 100080</address>
<email confidence="0.837854">shhbaoyunbo.cao@microsoft.com@apex.sjtu.edu.cn</email>
<email confidence="0.837854">summeryunbo.cao@microsoft.com@apex.sjtu.edu.cn</email>
<email confidence="0.837854">jacksonyunbo.cao@microsoft.com@apex.sjtu.edu.cn</email>
<email confidence="0.837854">xiongmiaoyunbo.cao@microsoft.com@apex.sjtu.edu.cn</email>
<email confidence="0.837854">yyuyunbo.cao@microsoft.com@apex.sjtu.edu.cn</email>
<abstract confidence="0.998493952380952">Expert search, in which given a query a ranked list of experts instead of documents is returned, has been intensively studied recently due to its importance in facilitating the needs of both information access and knowledge discovery. Many approaches have been proposed, including metadata extraction, expert profile building, and formal model generation. However, all of them conduct expert search with a coarse-grained approach. With these, further improvements on expert search are hard to achieve. In this paper, we propose conducting expert search with a fine-grained approach. Specifically, we utilize more specific evidences existing in the documents. An evidence-oriented probabilistic model for expert search and a method for the implementation are proposed. Experimental results show that the proposed model and the implementation are highly effective.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Craswell</author>
<author>N</author>
<author>A P Vries</author>
</authors>
<title>Enterprise Track. In:</title>
<date>2007</date>
<journal>Overview of the TREC</journal>
<booktitle>Proc. of TREC</booktitle>
<marker>Craswell, N, Vries, 2007</marker>
<rawString>Bailey, P., Soboroff , I., Craswell, N., and Vries A.P., Overview of the TREC 2007 Enterprise Track. In: Proc. of TREC 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Balog</author>
<author>L Azzopardi</author>
<author>M D Rijke</author>
</authors>
<title>Formal models for expert finding in enterprise corpora. In:</title>
<date>2006</date>
<booktitle>Proc. of</booktitle>
<pages>06--43</pages>
<contexts>
<context position="2591" citStr="Balog et al., 2006" startWordPosition="385" endWordPosition="388">f expert search within the enterprise track. In the TREC setting, expert search is defined as: given a query, a ranked list of experts is returned. In this paper, we engage our study in the same setting. Many approaches to expert search have been proposed by the participants of TREC and other researchers. These approaches include metadata extraction (Cao et al., 2005), expert profile building (Craswell, 2001, Fu et al., 2007), data fusion (Maconald and Ounis, 2006), query expansion (Macdonald and Ounis, 2007), hierarchical language model (Petkova and Croft, 2006), and formal model generation (Balog et al., 2006; Fang et al., 2006). However, all of them conduct expert search with what we call a coarse-grained approach. The discovering and use of evidence for expert locating is carried out under a grain of document. With it, further improvements on expert search are hard to achieve. This is because different blocks (or segments) of electronic documents usually present different functions and qualities and thus different impacts for expert locating. In contrast, this paper is concerned with proposing a probabilistic model for fine-grained expert search. In fine-grained expert search, we are to extract </context>
<context position="7558" citStr="Balog et al. (2006)" startWordPosition="1168" endWordPosition="1171"> expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise track at TREC 2005, 2006 and 2007 (Craswell et al., 2005; Soboroff et al., 2006; Bailey et al., 2007). Many approaches have been proposed for tackling the expert search task within the TREC track. Cao et al. (2005) propose a two-stage model with a set of extracted metadata. Balog et al. (2006) compare two generative models for expert search. Fang et al. (2006) further extend their generative model by introducing the prior of expert distribution and relevance feedback. Petkova and Croft (2006) further extend the profile based method by using a hierarchical language model. Macdonald and Ounis (2006) investigate the effectiveness of the voting approach and the associated data fusion techniques. However, such models are conducted in a coarse-grain scope of document as discussed before. In contrast, our study focuses on proposing a model for conducting expert search in a finegrain scope</context>
</contexts>
<marker>Balog, Azzopardi, Rijke, 2006</marker>
<rawString>Balog, K., Azzopardi, L., and Rijke, M. D., 2006. Formal models for expert finding in enterprise corpora. In: Proc. of SIGIR’06,pp.43-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brin</author>
<author>L Page</author>
</authors>
<title>The anatomy of a rlargescale hypertextual Web search engine,</title>
<date>1998</date>
<journal>Computer Networks and ISDN Systems</journal>
<volume>30</volume>
<pages>107--117</pages>
<contexts>
<context position="13209" citStr="Brin and Page, 1998" startWordPosition="2198" endWordPosition="2201">) « P(p) . (9) The prior probability can be estimated by MLE, i.e., the ratio of total occurrences of person p in the collection. The third term represents the probability that a relation r is generated from a query q. Here, we approximate the probability as P(r |q) « P(type(r)) , (10) where type(r) represents the way r connecting query and expert. P(type(r)) represents the reliability of relation type of r. Following the Bayes rule, the last term can be transformed as P(d |q) = P(q |P(q) (d) « P(q |d)P(d) where priority distribution P(d) can be estimated based on static rank, e.g., PageRank (Brin and Page, 1998). P(q|d) can be estimated by using a standard language model for IR (Ponte and Croft, 1998). In summary, Equation (7) is converted to P e q - Ptype t q P p P type r P q d P d ( |) ( ( , )) ( ) ( ( )) ( |) ( ) . (12) 3.4 Evidence Merging We assume that the ranking score of an expert can be acquired by summing up together all scores of the supporting evidences. Thus we calculate experts’ scores by aggregating the scores from all evidences as in Equation (1). 4 Implementation The implementation of the proposed model consists of two stages, namely evidence extraction and evidence quality evaluatio</context>
<context position="24153" citStr="Brin and Page, 1998" startWordPosition="4036" endWordPosition="4039">ion, reference section relation, title-author relation, and section title-body relation are 1, 4, 10, 45, and 1000 respectively. 4.2.4 Document Quality The quality of evidence also depends on the quality of the document, the context in which it is found. The document context can affect the credibility of the evidence in two ways: , (13) 919 Static quality: indicating the authority of a document. In our experiment, the static quality Qd (corresponding to P(d) in Equation (12) ) is estimated by the PageRank, which is calculated using a standard iterative algorithm with a damping factor of 0.85 (Brin and Page, 1998). Dynamic quality: by “dynamic”, we mean the quality score varies for different queries q. We denote the dynamic quality as QDY(d,q) (corresponding to P(q|d) in Equation (12) ), which is actually the document relevance score returned by a standard language model for IR(Ponte and Croft, 1998). 5 Experimental Results 5.1 The Evaluation Data In our experiment, we used the data set in the expert search task of enterprise search track at TREC 2005 and 2006. The document collection is a crawl of the public W3C sites in June 2004. The crawl comprises in total 331,307 web pages. In the following exper</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Brin, S. and Page, L., 1998. The anatomy of a rlargescale hypertextual Web search engine, Computer Networks and ISDN Systems (30), pp.107-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C S Campbell</author>
<author>P Maglio</author>
<author>A Cozzi</author>
<author>B Dom</author>
</authors>
<title>Expertise identification using email communications. In:</title>
<date>2003</date>
<booktitle>Proc. of CIKM</booktitle>
<volume>03</volume>
<pages>528--531</pages>
<contexts>
<context position="6533" citStr="Campbell et al., 2003" startWordPosition="1006" endWordPosition="1009">ent the proposed probabilistic model and its implementation, respectively. Section 5 gives the empirical evaluation. Finally, Section 6 concludes the work. 2 Related Work 2.1 Expert Search Systems One setting for automatic expert search is to assume that data from specific resources are available. For example, Expertise Recommender (Kautz et al., 1996), Expertise Browser (Mockus and Herbsleb, 2002) and the system in (McDonald and Ackerman, 1998) make use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences betw</context>
</contexts>
<marker>Campbell, Maglio, Cozzi, Dom, 2003</marker>
<rawString>Campbell, C.S., Maglio, P., Cozzi, A. and Dom, B., 2003. Expertise identification using email communications. In: Proc. of CIKM ’03 pp.528–531.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Cao</author>
<author>J Liu</author>
<author>S Bao</author>
<author>H Li</author>
</authors>
<title>Research on expert search at enterprise track of TREC 2005. In:</title>
<date>2005</date>
<booktitle>Proc. of TREC</booktitle>
<contexts>
<context position="2343" citStr="Cao et al., 2005" startWordPosition="346" endWordPosition="349">l document search, raise a new requirement of searching people with certain expertise. To meet that requirement, a new task, called expert search, has been proposed and studied intensively. For example, TREC 2005, 2006, and 2007 provide the task of expert search within the enterprise track. In the TREC setting, expert search is defined as: given a query, a ranked list of experts is returned. In this paper, we engage our study in the same setting. Many approaches to expert search have been proposed by the participants of TREC and other researchers. These approaches include metadata extraction (Cao et al., 2005), expert profile building (Craswell, 2001, Fu et al., 2007), data fusion (Maconald and Ounis, 2006), query expansion (Macdonald and Ounis, 2007), hierarchical language model (Petkova and Croft, 2006), and formal model generation (Balog et al., 2006; Fang et al., 2006). However, all of them conduct expert search with what we call a coarse-grained approach. The discovering and use of evidence for expert locating is carried out under a grain of document. With it, further improvements on expert search are hard to achieve. This is because different blocks (or segments) of electronic documents usual</context>
<context position="7478" citStr="Cao et al. (2005)" startWordPosition="1154" endWordPosition="1157">EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise track at TREC 2005, 2006 and 2007 (Craswell et al., 2005; Soboroff et al., 2006; Bailey et al., 2007). Many approaches have been proposed for tackling the expert search task within the TREC track. Cao et al. (2005) propose a two-stage model with a set of extracted metadata. Balog et al. (2006) compare two generative models for expert search. Fang et al. (2006) further extend their generative model by introducing the prior of expert distribution and relevance feedback. Petkova and Croft (2006) further extend the profile based method by using a hierarchical language model. Macdonald and Ounis (2006) investigate the effectiveness of the voting approach and the associated data fusion techniques. However, such models are conducted in a coarse-grain scope of document as discussed before. In contrast, our stud</context>
<context position="18466" citStr="Cao et al., 2005" startWordPosition="3086" endWordPosition="3089">cuments. For example, for web pages, we can construct the &lt;Title&gt; from either the ‘title’ metadata or the content of web pages (Hu et al., 2006). As for e-mail, we can use the ‘subject’ field as the &lt;Title&gt;. Figure. 1. A template of document layout &lt;Title&gt; RDF Primer &lt;Author&gt;Editors: Frank Manola, fmanola@acm.org Eric Miller, W3C, em@w3.org &lt;Body&gt; Figure 2. An example use of the layout template With the layout of partitioned documents, we can then explore many types of relations among different blocks. In this paper, we demonstrate the use of five types of relations by extending the study in (Cao et al., 2005). Section Relation (RS): The queried topic and the expert candidate occur in the same &lt;Section&gt;. Windowed Section Relation (RWS): The queried topic and the expert candidate occur within a fixed window of a &lt;Section&gt;. In our experiment, we used a window of 200 words. Reference Section Relation (RRS): Some &lt;Section&gt;s should be treated specially. For example, the &lt;Section&gt; consisting of reference information like a list of &lt;book, author&gt; can serve as a reliable source connecting a topic and an expert candidate. We call the relation appearing in a special type of &lt;Section&gt; a special reference sect</context>
</contexts>
<marker>Cao, Liu, Bao, Li, 2005</marker>
<rawString>Cao, Y., Liu, J., and Bao, S., and Li, H., 2005. Research on expert search at enterprise track of TREC 2005. In: Proc. of TREC 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Craswell</author>
<author>D Hawking</author>
<author>A M Vercoustre</author>
<author>P Wilkins</author>
</authors>
<title>P@NOPTIC Expert: searching for experts not just for documents. In:</title>
<date>2001</date>
<booktitle>Proc. of Ausweb’01.</booktitle>
<contexts>
<context position="6835" citStr="Craswell et al., 2001" startWordPosition="1053" endWordPosition="1056">r example, Expertise Recommender (Kautz et al., 1996), Expertise Browser (Mockus and Herbsleb, 2002) and the system in (McDonald and Ackerman, 1998) make use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise track at TREC 2005, 2006 and 2007 (Craswell et al., 2005; Soboroff et al., 2006; Bailey et al., 2007). Many approaches have been proposed for tackling the expert search ta</context>
</contexts>
<marker>Craswell, Hawking, Vercoustre, Wilkins, 2001</marker>
<rawString>Craswell, N., Hawking, D., Vercoustre, A. M. and Wilkins, P., 2001. P@NOPTIC Expert: searching for experts not just for documents. In: Proc. of Ausweb’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Craswell</author>
<author>A P Vries</author>
<author>I Soboroff</author>
</authors>
<title>Enterprise Track. In:</title>
<date>2005</date>
<journal>Overview of the TREC</journal>
<booktitle>Proc. of TREC</booktitle>
<contexts>
<context position="7320" citStr="Craswell et al., 2005" startWordPosition="1125" endWordPosition="1128"> Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise track at TREC 2005, 2006 and 2007 (Craswell et al., 2005; Soboroff et al., 2006; Bailey et al., 2007). Many approaches have been proposed for tackling the expert search task within the TREC track. Cao et al. (2005) propose a two-stage model with a set of extracted metadata. Balog et al. (2006) compare two generative models for expert search. Fang et al. (2006) further extend their generative model by introducing the prior of expert distribution and relevance feedback. Petkova and Croft (2006) further extend the profile based method by using a hierarchical language model. Macdonald and Ounis (2006) investigate the effectiveness of the voting approac</context>
</contexts>
<marker>Craswell, Vries, Soboroff, 2005</marker>
<rawString>Craswell, N., Vries, A.P., and Soboroff, I., 2005. Overview of the TREC 2005 Enterprise Track. In: Proc. of TREC 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T H Davenport</author>
<author>L Prusak</author>
</authors>
<title>Working Knowledge: how organizations manage what they know.</title>
<date>1998</date>
<publisher>Howard Business, School Press,</publisher>
<location>Boston, MA.</location>
<contexts>
<context position="6665" citStr="Davenport and Prusak, 1998" startWordPosition="1027" endWordPosition="1030">ection 6 concludes the work. 2 Related Work 2.1 Expert Search Systems One setting for automatic expert search is to assume that data from specific resources are available. For example, Expertise Recommender (Kautz et al., 1996), Expertise Browser (Mockus and Herbsleb, 2002) and the system in (McDonald and Ackerman, 1998) make use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise t</context>
</contexts>
<marker>Davenport, Prusak, 1998</marker>
<rawString>Davenport, T. H. and Prusak, L., 1998. Working Knowledge: how organizations manage what they know. Howard Business, School Press, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dom</author>
<author>I Eiron</author>
<author>A Cozzi</author>
<author>Z Yi</author>
</authors>
<title>Graphbased ranking algorithms for e-mail expertise analysis, In:</title>
<date>2003</date>
<booktitle>Proc. of SIGMOD’03 workshop on Research issues in</booktitle>
<contexts>
<context position="6550" citStr="Dom et al. 2003" startWordPosition="1010" endWordPosition="1013">ilistic model and its implementation, respectively. Section 5 gives the empirical evaluation. Finally, Section 6 concludes the work. 2 Related Work 2.1 Expert Search Systems One setting for automatic expert search is to assume that data from specific resources are available. For example, Expertise Recommender (Kautz et al., 1996), Expertise Browser (Mockus and Herbsleb, 2002) and the system in (McDonald and Ackerman, 1998) make use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words a</context>
</contexts>
<marker>Dom, Eiron, Cozzi, Yi, 2003</marker>
<rawString>Dom, B., Eiron, I., Cozzi A. and Yi, Z., 2003. Graphbased ranking algorithms for e-mail expertise analysis, In: Proc. of SIGMOD’03 workshop on Research issues in data mining and knowledge discovery.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Fang</author>
<author>L Zhou</author>
<author>C Zhai</author>
</authors>
<title>Language models for expert finding-UIUC TREC</title>
<date>2006</date>
<booktitle>Proc. of TREC2006.</booktitle>
<contexts>
<context position="2611" citStr="Fang et al., 2006" startWordPosition="389" endWordPosition="392">in the enterprise track. In the TREC setting, expert search is defined as: given a query, a ranked list of experts is returned. In this paper, we engage our study in the same setting. Many approaches to expert search have been proposed by the participants of TREC and other researchers. These approaches include metadata extraction (Cao et al., 2005), expert profile building (Craswell, 2001, Fu et al., 2007), data fusion (Maconald and Ounis, 2006), query expansion (Macdonald and Ounis, 2007), hierarchical language model (Petkova and Croft, 2006), and formal model generation (Balog et al., 2006; Fang et al., 2006). However, all of them conduct expert search with what we call a coarse-grained approach. The discovering and use of evidence for expert locating is carried out under a grain of document. With it, further improvements on expert search are hard to achieve. This is because different blocks (or segments) of electronic documents usually present different functions and qualities and thus different impacts for expert locating. In contrast, this paper is concerned with proposing a probabilistic model for fine-grained expert search. In fine-grained expert search, we are to extract and use evidence of </context>
<context position="7626" citStr="Fang et al. (2006)" startWordPosition="1180" endWordPosition="1183">ch by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise track at TREC 2005, 2006 and 2007 (Craswell et al., 2005; Soboroff et al., 2006; Bailey et al., 2007). Many approaches have been proposed for tackling the expert search task within the TREC track. Cao et al. (2005) propose a two-stage model with a set of extracted metadata. Balog et al. (2006) compare two generative models for expert search. Fang et al. (2006) further extend their generative model by introducing the prior of expert distribution and relevance feedback. Petkova and Croft (2006) further extend the profile based method by using a hierarchical language model. Macdonald and Ounis (2006) investigate the effectiveness of the voting approach and the associated data fusion techniques. However, such models are conducted in a coarse-grain scope of document as discussed before. In contrast, our study focuses on proposing a model for conducting expert search in a finegrain scope of evidence (local context). 3 Fine-grained Expert Search Our resea</context>
</contexts>
<marker>Fang, Zhou, Zhai, 2006</marker>
<rawString>Fang, H., Zhou, L., Zhai, C., 2006. Language models for expert finding-UIUC TREC 2006 Enterprise Track Experiments, In: Proc. of TREC2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Fu</author>
<author>R Xiang</author>
<author>Y Liu</author>
<author>M Zhang</author>
<author>S Ma</author>
</authors>
<title>A CDD-based Formal Model for Expert Finding.</title>
<date>2007</date>
<booktitle>In Proc. of CIKM</booktitle>
<contexts>
<context position="2402" citStr="Fu et al., 2007" startWordPosition="356" endWordPosition="359">le with certain expertise. To meet that requirement, a new task, called expert search, has been proposed and studied intensively. For example, TREC 2005, 2006, and 2007 provide the task of expert search within the enterprise track. In the TREC setting, expert search is defined as: given a query, a ranked list of experts is returned. In this paper, we engage our study in the same setting. Many approaches to expert search have been proposed by the participants of TREC and other researchers. These approaches include metadata extraction (Cao et al., 2005), expert profile building (Craswell, 2001, Fu et al., 2007), data fusion (Maconald and Ounis, 2006), query expansion (Macdonald and Ounis, 2007), hierarchical language model (Petkova and Croft, 2006), and formal model generation (Balog et al., 2006; Fang et al., 2006). However, all of them conduct expert search with what we call a coarse-grained approach. The discovering and use of evidence for expert locating is carried out under a grain of document. With it, further improvements on expert search are hard to achieve. This is because different blocks (or segments) of electronic documents usually present different functions and qualities and thus diffe</context>
</contexts>
<marker>Fu, Xiang, Liu, Zhang, Ma, 2007</marker>
<rawString>Fu, Y., Xiang, R., Liu, Y., Zhang, M., Ma, S., 2007. A CDD-based Formal Model for Expert Finding. In Proc. of CIKM 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hertzum</author>
<author>A M Pejtersen</author>
</authors>
<title>The information-seeking practices of engineers: searching for documents as well as for people.</title>
<date>2000</date>
<journal>Information Processing and Management,</journal>
<volume>36</volume>
<issue>5</issue>
<pages>761--778</pages>
<contexts>
<context position="6716" citStr="Hertzum and Pejtersen, 2000" startWordPosition="1035" endWordPosition="1038">xpert Search Systems One setting for automatic expert search is to assume that data from specific resources are available. For example, Expertise Recommender (Kautz et al., 1996), Expertise Browser (Mockus and Herbsleb, 2002) and the system in (McDonald and Ackerman, 1998) make use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise track at TREC 2005, 2006 and 2007 (Craswell et al., </context>
</contexts>
<marker>Hertzum, Pejtersen, 2000</marker>
<rawString>Hertzum, M. and Pejtersen, A. M., 2000. The information-seeking practices of engineers: searching for documents as well as for people. Information Processing and Management, 36(5), pp.761–778.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Hu</author>
<author>H Li</author>
<author>Y Cao</author>
<author>D Teng Meyerzon</author>
<author>L</author>
<author>Q Zheng</author>
</authors>
<title>Automatic extraction of titles from general documents using machine learning,</title>
<date>2006</date>
<publisher>IPM.</publisher>
<contexts>
<context position="17993" citStr="Hu et al., 2006" startWordPosition="3008" endWordPosition="3011">mantic web search engine” 4.1.3 Relation Extraction We focus on extracting relations between topics and expert candidates within a span of a document. To make the extraction easier, we partition a document into a pre-defined layout. Figure 1 provides a template in Backus–Naur form. Figure 2 provides a practical use of the template. Note that we are not restricting the use of the template only for certain corpus. Actually the template can be applied to many kinds of documents. For example, for web pages, we can construct the &lt;Title&gt; from either the ‘title’ metadata or the content of web pages (Hu et al., 2006). As for e-mail, we can use the ‘subject’ field as the &lt;Title&gt;. Figure. 1. A template of document layout &lt;Title&gt; RDF Primer &lt;Author&gt;Editors: Frank Manola, fmanola@acm.org Eric Miller, W3C, em@w3.org &lt;Body&gt; Figure 2. An example use of the layout template With the layout of partitioned documents, we can then explore many types of relations among different blocks. In this paper, we demonstrate the use of five types of relations by extending the study in (Cao et al., 2005). Section Relation (RS): The queried topic and the expert candidate occur in the same &lt;Section&gt;. Windowed Section Relation (RWS</context>
</contexts>
<marker>Hu, Li, Cao, Meyerzon, L, Zheng, 2006</marker>
<rawString>Hu, Y., Li, H., Cao, Y., Meyerzon, D. Teng, L., and Zheng, Q., 2006. Automatic extraction of titles from general documents using machine learning, IPM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kautz</author>
<author>B Selman</author>
<author>A Milewski</author>
</authors>
<title>Agent amplified communication. In:</title>
<date>1996</date>
<booktitle>Proc. of AAAI‘96,</booktitle>
<pages>3--9</pages>
<contexts>
<context position="6266" citStr="Kautz et al., 1996" startWordPosition="964" endWordPosition="967">ith existing state-of-the-art expert search methods, the probabilistic model for fine-grained expert search shows promising improvement. The rest of the paper is organized as follows. Section 2 surveys existing studies on expert search. Section 3 and Section 4 present the proposed probabilistic model and its implementation, respectively. Section 5 gives the empirical evaluation. Finally, Section 6 concludes the work. 2 Related Work 2.1 Expert Search Systems One setting for automatic expert search is to assume that data from specific resources are available. For example, Expertise Recommender (Kautz et al., 1996), Expertise Browser (Mockus and Herbsleb, 2002) and the system in (McDonald and Ackerman, 1998) make use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) </context>
</contexts>
<marker>Kautz, Selman, Milewski, 1996</marker>
<rawString>Kautz, H., Selman, B. and Milewski, A., 1996. Agent amplified communication. In: Proc. of AAAI‘96, pp. 3–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Mattox</author>
<author>M Maybury</author>
<author>D Morey</author>
</authors>
<title>Enterprise expert and knowledge discovery.</title>
<date>1999</date>
<tech>Technical Report.</tech>
<contexts>
<context position="6686" citStr="Mattox et al., 1999" startWordPosition="1031" endWordPosition="1034"> 2 Related Work 2.1 Expert Search Systems One setting for automatic expert search is to assume that data from specific resources are available. For example, Expertise Recommender (Kautz et al., 1996), Expertise Browser (Mockus and Herbsleb, 2002) and the system in (McDonald and Ackerman, 1998) make use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise track at TREC 2005, 20</context>
</contexts>
<marker>Mattox, Maybury, Morey, 1999</marker>
<rawString>Mattox, D., Maybury, M. and Morey, D., 1999. Enterprise expert and knowledge discovery. Technical Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D W McDonald</author>
<author>M S Ackerman</author>
</authors>
<title>Just Talk to Me: a field study of expertise location. In:</title>
<date>1998</date>
<booktitle>Proc. of CSCW’98,</booktitle>
<pages>315--324</pages>
<contexts>
<context position="6361" citStr="McDonald and Ackerman, 1998" startWordPosition="978" endWordPosition="981">grained expert search shows promising improvement. The rest of the paper is organized as follows. Section 2 surveys existing studies on expert search. Section 3 and Section 4 present the proposed probabilistic model and its implementation, respectively. Section 5 gives the empirical evaluation. Finally, Section 6 concludes the work. 2 Related Work 2.1 Expert Search Systems One setting for automatic expert search is to assume that data from specific resources are available. For example, Expertise Recommender (Kautz et al., 1996), Expertise Browser (Mockus and Herbsleb, 2002) and the system in (McDonald and Ackerman, 1998) make use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR</context>
</contexts>
<marker>McDonald, Ackerman, 1998</marker>
<rawString>McDonald, D. W. and Ackerman, M. S., 1998. Just Talk to Me: a field study of expertise location. In: Proc. of CSCW’98, pp.315-324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Mockus</author>
<author>J D Herbsleb</author>
</authors>
<title>Expertise Browser: a quantitative approach to identifying expertise, In:</title>
<date>2002</date>
<booktitle>Proc. of ICSE’02.</booktitle>
<contexts>
<context position="6313" citStr="Mockus and Herbsleb, 2002" startWordPosition="970" endWordPosition="973">rch methods, the probabilistic model for fine-grained expert search shows promising improvement. The rest of the paper is organized as follows. Section 2 surveys existing studies on expert search. Section 3 and Section 4 present the proposed probabilistic model and its implementation, respectively. Section 5 gives the empirical evaluation. Finally, Section 6 concludes the work. 2 Related Work 2.1 Expert Search Systems One setting for automatic expert search is to assume that data from specific resources are available. For example, Expertise Recommender (Kautz et al., 1996), Expertise Browser (Mockus and Herbsleb, 2002) and the system in (McDonald and Ackerman, 1998) make use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same</context>
</contexts>
<marker>Mockus, Herbsleb, 2002</marker>
<rawString>Mockus, A. and Herbsleb, J.D., 2002. Expertise Browser: a quantitative approach to identifying expertise, In: Proc. of ICSE’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Maconald</author>
<author>I Ounis</author>
</authors>
<title>Voting for candidates: adapting data fusion techniques for an expert search task. In:</title>
<date>2006</date>
<booktitle>Proc. of CIKM&apos;06,</booktitle>
<pages>387--396</pages>
<contexts>
<context position="2442" citStr="Maconald and Ounis, 2006" startWordPosition="362" endWordPosition="365">eet that requirement, a new task, called expert search, has been proposed and studied intensively. For example, TREC 2005, 2006, and 2007 provide the task of expert search within the enterprise track. In the TREC setting, expert search is defined as: given a query, a ranked list of experts is returned. In this paper, we engage our study in the same setting. Many approaches to expert search have been proposed by the participants of TREC and other researchers. These approaches include metadata extraction (Cao et al., 2005), expert profile building (Craswell, 2001, Fu et al., 2007), data fusion (Maconald and Ounis, 2006), query expansion (Macdonald and Ounis, 2007), hierarchical language model (Petkova and Croft, 2006), and formal model generation (Balog et al., 2006; Fang et al., 2006). However, all of them conduct expert search with what we call a coarse-grained approach. The discovering and use of evidence for expert locating is carried out under a grain of document. With it, further improvements on expert search are hard to achieve. This is because different blocks (or segments) of electronic documents usually present different functions and qualities and thus different impacts for expert locating. In con</context>
</contexts>
<marker>Maconald, Ounis, 2006</marker>
<rawString>Maconald, C. and Ounis, I., 2006. Voting for candidates: adapting data fusion techniques for an expert search task. In: Proc. of CIKM&apos;06, pp.387-396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Macdonald</author>
<author>I Ounis</author>
</authors>
<title>Expertise Drift and Query Expansion in Expert Search.</title>
<date>2007</date>
<booktitle>In Proc. of CIKM</booktitle>
<contexts>
<context position="2487" citStr="Macdonald and Ounis, 2007" startWordPosition="368" endWordPosition="371">ert search, has been proposed and studied intensively. For example, TREC 2005, 2006, and 2007 provide the task of expert search within the enterprise track. In the TREC setting, expert search is defined as: given a query, a ranked list of experts is returned. In this paper, we engage our study in the same setting. Many approaches to expert search have been proposed by the participants of TREC and other researchers. These approaches include metadata extraction (Cao et al., 2005), expert profile building (Craswell, 2001, Fu et al., 2007), data fusion (Maconald and Ounis, 2006), query expansion (Macdonald and Ounis, 2007), hierarchical language model (Petkova and Croft, 2006), and formal model generation (Balog et al., 2006; Fang et al., 2006). However, all of them conduct expert search with what we call a coarse-grained approach. The discovering and use of evidence for expert locating is carried out under a grain of document. With it, further improvements on expert search are hard to achieve. This is because different blocks (or segments) of electronic documents usually present different functions and qualities and thus different impacts for expert locating. In contrast, this paper is concerned with proposing</context>
</contexts>
<marker>Macdonald, Ounis, 2007</marker>
<rawString>Macdonald, C. and Ounis, I., 2007. Expertise Drift and Query Expansion in Expert Search. In Proc. of CIKM 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Petkova</author>
<author>W B Croft</author>
</authors>
<title>Hierarchical language models for expert finding in enterprise corpora, In:</title>
<date>2006</date>
<booktitle>Proc. of ICTAI’06,</booktitle>
<pages>599--608</pages>
<contexts>
<context position="2542" citStr="Petkova and Croft, 2006" startWordPosition="376" endWordPosition="379">r example, TREC 2005, 2006, and 2007 provide the task of expert search within the enterprise track. In the TREC setting, expert search is defined as: given a query, a ranked list of experts is returned. In this paper, we engage our study in the same setting. Many approaches to expert search have been proposed by the participants of TREC and other researchers. These approaches include metadata extraction (Cao et al., 2005), expert profile building (Craswell, 2001, Fu et al., 2007), data fusion (Maconald and Ounis, 2006), query expansion (Macdonald and Ounis, 2007), hierarchical language model (Petkova and Croft, 2006), and formal model generation (Balog et al., 2006; Fang et al., 2006). However, all of them conduct expert search with what we call a coarse-grained approach. The discovering and use of evidence for expert locating is carried out under a grain of document. With it, further improvements on expert search are hard to achieve. This is because different blocks (or segments) of electronic documents usually present different functions and qualities and thus different impacts for expert locating. In contrast, this paper is concerned with proposing a probabilistic model for fine-grained expert search. </context>
<context position="7761" citStr="Petkova and Croft (2006)" startWordPosition="1199" endWordPosition="1202">query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise track at TREC 2005, 2006 and 2007 (Craswell et al., 2005; Soboroff et al., 2006; Bailey et al., 2007). Many approaches have been proposed for tackling the expert search task within the TREC track. Cao et al. (2005) propose a two-stage model with a set of extracted metadata. Balog et al. (2006) compare two generative models for expert search. Fang et al. (2006) further extend their generative model by introducing the prior of expert distribution and relevance feedback. Petkova and Croft (2006) further extend the profile based method by using a hierarchical language model. Macdonald and Ounis (2006) investigate the effectiveness of the voting approach and the associated data fusion techniques. However, such models are conducted in a coarse-grain scope of document as discussed before. In contrast, our study focuses on proposing a model for conducting expert search in a finegrain scope of evidence (local context). 3 Fine-grained Expert Search Our research is to investigate a direct use of the local contexts for expert search. We call each local context of such kind as fine-grained evi</context>
</contexts>
<marker>Petkova, Croft, 2006</marker>
<rawString>Petkova, D., and Croft, W. B., 2006. Hierarchical language models for expert finding in enterprise corpora, In: Proc. of ICTAI’06, pp.599-608.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ponte</author>
<author>W Croft</author>
</authors>
<title>A language modeling approach to information retrieval, In:</title>
<date>1998</date>
<booktitle>Proc. of SIGIR’98,</booktitle>
<pages>275--281</pages>
<contexts>
<context position="13300" citStr="Ponte and Croft, 1998" startWordPosition="2214" endWordPosition="2217">currences of person p in the collection. The third term represents the probability that a relation r is generated from a query q. Here, we approximate the probability as P(r |q) « P(type(r)) , (10) where type(r) represents the way r connecting query and expert. P(type(r)) represents the reliability of relation type of r. Following the Bayes rule, the last term can be transformed as P(d |q) = P(q |P(q) (d) « P(q |d)P(d) where priority distribution P(d) can be estimated based on static rank, e.g., PageRank (Brin and Page, 1998). P(q|d) can be estimated by using a standard language model for IR (Ponte and Croft, 1998). In summary, Equation (7) is converted to P e q - Ptype t q P p P type r P q d P d ( |) ( ( , )) ( ) ( ( )) ( |) ( ) . (12) 3.4 Evidence Merging We assume that the ranking score of an expert can be acquired by summing up together all scores of the supporting evidences. Thus we calculate experts’ scores by aggregating the scores from all evidences as in Equation (1). 4 Implementation The implementation of the proposed model consists of two stages, namely evidence extraction and evidence quality evaluation. 4.1 Evidence Extraction Recall that we define an evidence for expert search as a quadrup</context>
<context position="24445" citStr="Ponte and Croft, 1998" startWordPosition="4085" endWordPosition="4088"> credibility of the evidence in two ways: , (13) 919 Static quality: indicating the authority of a document. In our experiment, the static quality Qd (corresponding to P(d) in Equation (12) ) is estimated by the PageRank, which is calculated using a standard iterative algorithm with a damping factor of 0.85 (Brin and Page, 1998). Dynamic quality: by “dynamic”, we mean the quality score varies for different queries q. We denote the dynamic quality as QDY(d,q) (corresponding to P(q|d) in Equation (12) ), which is actually the document relevance score returned by a standard language model for IR(Ponte and Croft, 1998). 5 Experimental Results 5.1 The Evaluation Data In our experiment, we used the data set in the expert search task of enterprise search track at TREC 2005 and 2006. The document collection is a crawl of the public W3C sites in June 2004. The crawl comprises in total 331,307 web pages. In the following experiments, we used the training set of 10 topics of TREC 2005 for tuning the parameters aforementioned in Section 4.2, and used the test set of 50 topics of TREC 2005 and 49 topics of TREC 2006 as the evaluation data sets. 5.2 Evaluation Metrics We used three measures in evaluation: Mean averag</context>
</contexts>
<marker>Ponte, Croft, 1998</marker>
<rawString>Ponte, J. and Croft, W., 1998. A language modeling approach to information retrieval, In: Proc. of SIGIR’98, pp.275-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Sihn</author>
<author>F Heeren</author>
</authors>
<title>Xpertfinder-expert finding within specified subject areas through analysis of e-mail communication. In:</title>
<date>2001</date>
<booktitle>Proc. of the 6th Annual Scientific conference on Web Technology.</booktitle>
<contexts>
<context position="6574" citStr="Sihn and Heeren, 2001" startWordPosition="1014" endWordPosition="1017"> its implementation, respectively. Section 5 gives the empirical evaluation. Finally, Section 6 concludes the work. 2 Related Work 2.1 Expert Search Systems One setting for automatic expert search is to assume that data from specific resources are available. For example, Expertise Recommender (Kautz et al., 1996), Expertise Browser (Mockus and Herbsleb, 2002) and the system in (McDonald and Ackerman, 1998) make use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documen</context>
</contexts>
<marker>Sihn, Heeren, 2001</marker>
<rawString>Sihn, W. and Heeren F., 2001. Xpertfinder-expert finding within specified subject areas through analysis of e-mail communication. In: Proc. of the 6th Annual Scientific conference on Web Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Soboroff</author>
<author>A P Vries</author>
<author>N Craswell</author>
</authors>
<title>Enterprise Track. In:</title>
<date>2006</date>
<journal>Overview of the TREC</journal>
<booktitle>Proc. of TREC</booktitle>
<contexts>
<context position="7343" citStr="Soboroff et al., 2006" startWordPosition="1129" endWordPosition="1132">PTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise track at TREC 2005, 2006 and 2007 (Craswell et al., 2005; Soboroff et al., 2006; Bailey et al., 2007). Many approaches have been proposed for tackling the expert search task within the TREC track. Cao et al. (2005) propose a two-stage model with a set of extracted metadata. Balog et al. (2006) compare two generative models for expert search. Fang et al. (2006) further extend their generative model by introducing the prior of expert distribution and relevance feedback. Petkova and Croft (2006) further extend the profile based method by using a hierarchical language model. Macdonald and Ounis (2006) investigate the effectiveness of the voting approach and the associated da</context>
</contexts>
<marker>Soboroff, Vries, Craswell, 2006</marker>
<rawString>Soboroff, I., Vries, A.P., and Craswell, N., 2006. Overview of the TREC 2006 Enterprise Track. In: Proc. of TREC 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Steer</author>
<author>K E Lochbaum</author>
</authors>
<title>An expert/expert locating system based on automatic representation of semantic structure, In:</title>
<date>1988</date>
<booktitle>Proc. of the 4th IEEE Conference on Artificial Intelligence Applications.</booktitle>
<contexts>
<context position="6899" citStr="Steer and Lochbaum, 1988" startWordPosition="1060" endWordPosition="1063">ise Browser (Mockus and Herbsleb, 2002) and the system in (McDonald and Ackerman, 1998) make use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise track at TREC 2005, 2006 and 2007 (Craswell et al., 2005; Soboroff et al., 2006; Bailey et al., 2007). Many approaches have been proposed for tackling the expert search task within the TREC track. Cao et al. (2005) propose a two-stage </context>
</contexts>
<marker>Steer, Lochbaum, 1988</marker>
<rawString>Steer, L.A. and Lochbaum, K.E., 1988. An expert/expert locating system based on automatic representation of semantic structure, In: Proc. of the 4th IEEE Conference on Artificial Intelligence Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yimam</author>
</authors>
<title>Expert finding systems for organizations: domain analysis and the DEMOIR approach. In: ECSCW’99 workshop of beyond knowledge management: managing expertise,</title>
<date>1996</date>
<pages>276--283</pages>
<contexts>
<context position="6975" citStr="Yimam, 1996" startWordPosition="1074" endWordPosition="1075">ake use of log data in software development systems to find experts. Yet another approach is to mine expert and expertise from email communications (Campbell et al., 2003; Dom et al. 2003; Sihn and Heeren, 2001). Searching expert from general documents has also been studied (Davenport and Prusak, 1998; Mattox et al., 1999; Hertzum and Pejtersen, 2000). P@NOPTIC employs what is referred to as the ‘profile-based’ approach in searching for experts (Craswell et al., 2001). Expert/Expert-Locating (EEL) system (Steer and Lochbaum, 1988) uses the same approach in searching for expert groups. DEMOIR (Yimam, 1996) enhances the profilebased approach by separating co-occurrences into different types. In essence, the profile-based approach utilizes the co-occurrences between query words and people within documents. 2.2 Expert Search at TREC A task on expert search was organized within the enterprise track at TREC 2005, 2006 and 2007 (Craswell et al., 2005; Soboroff et al., 2006; Bailey et al., 2007). Many approaches have been proposed for tackling the expert search task within the TREC track. Cao et al. (2005) propose a two-stage model with a set of extracted metadata. Balog et al. (2006) compare two gene</context>
</contexts>
<marker>Yimam, 1996</marker>
<rawString>Yimam, D., 1996. Expert finding systems for organizations: domain analysis and the DEMOIR approach. In: ECSCW’99 workshop of beyond knowledge management: managing expertise, pp. 276–283.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>