<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.055776">
<title confidence="0.9976065">
eHumanities Desktop - An Online System for Corpus Management and
Analysis in Support of Computing in the Humanities
</title>
<author confidence="0.9492265">
R¨udiger Gleim&apos;, Ulli Waltinger2, Alexandra Ernst2, Alexander Mehler&apos;,
Tobias Feith2 &amp; Dietmar Esch2
</author>
<affiliation confidence="0.575353">
&apos;Goethe-Universit¨at Frankfurt am Main, 2Universit¨at Bielefeld
</affiliation>
<sectionHeader confidence="0.968674" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999914428571429">
This paper introduces eHumanities Desk-
top- an online system for corpus manage-
ment and analysis in support of Comput-
ing in the Humanities. Design issues and
the overall architecture are described as
well as an initial set of applications which
are offered by the system.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999877607142857">
Since there is an ongoing shift towards computer
based studies in the humanities new challenges
in maintaining and analysing electronic resources
arise. This is all the more because research groups
are often distributed over several institutes and
universities. Thus, the ability to collaboratively
work on shared resources becomes an important
issue. This aspect also marks a turn point in
the development of Corpus Management Systems
(CMS). Apart from the aspect of pure resource
management, processing and analysis of docu-
ments have traditionally been the domain of desk-
top applications. Sometimes even to the point of
command line tools. Therefore the technical skills
needed to use for example linguistic tools have ef-
fectively constrained their usage by a larger com-
munity. We emphasise the approach to offer low-
threshold access to both corpus management as
well as processing and analysis in order to address
a broader public in the humanities.
The eHumanities Desktop1 is designed as a gen-
eral purpose platform for scientists in humanities.
Based on a sophisticated data model to manage au-
thorities, resources and their interrelations the sys-
tem offers an extensible set of application modules
to process and analyse data. Users do not need to
undertake any installation efforts but simply can
login from any computer with internet connection
</bodyText>
<footnote confidence="0.996188">
1http://hudesktop.hucompute.org
</footnote>
<figureCaption confidence="0.996031">
Figure 1: The eHumanities Desktop environment
</figureCaption>
<bodyText confidence="0.952314272727273">
showing the document manager and administra-
tion dialog.
using a standard browser. Figure 1 shows the desk-
top with the Document Manager and the Adminis-
tration Dialog opened.
In the following we describe the general archi-
tecture of the system. The second part addresses
an initial set of application modules which are
currently available through eHumanities Desktop.
The last section summarises the system descrip-
tion and gives a prospect of future work.
</bodyText>
<sectionHeader confidence="0.922534" genericHeader="method">
2 System Architecture
</sectionHeader>
<bodyText confidence="0.999594">
Figure 2 gives an overview of the general archi-
tecture. The eHumanities Desktop is implemented
as a client/server system which can be used via
any JavaScript/Java capable Web Browser. The
GUI is based on the ExtJS Framework2 and pro-
vides a look and feel similar to Windows Vista.
The server side is based on Java Servlet technol-
ogy using the Tomcat3 Servlet Container. The core
of the system is the Command Dispatcher which
</bodyText>
<footnote confidence="0.720704">
2http://extjs.com
3http://tomcat.apache.org
Proceedings of the EACL 2009 Demonstrations Session, pages 21–24,
Athens, Greece, 3 April 2009. c�2009 Association for Computational Linguistics
</footnote>
<page confidence="0.999612">
21
</page>
<bodyText confidence="0.999797571428572">
manages the communication with the client and
the execution of tasks like downloading a docu-
ment for example. The Master Data include infor-
mation about all objects managed by the system,
for example users, groups, documents, resources
and their interrelations. All this information is
stored in a transactional Relational Database (us-
ing MySQL4). The underlying data model is de-
scribed later in more detail. Another important
component is the Storage Handler: Based on an
automatic mime type5 detection it decides how
to store and retrieve documents. For example
videos and audio material are best stored as files
whereas XML documents are better accessible via
a XML Database Management System or spe-
cialized DBMS (e.g. HyGraphDB (Gleim et al.,
2007)). Which kind of Storage Backend is used
to archive a given document is transparent to the
user- and also to developers using the Storage
Handler. The Document Indexer allows for struc-
ture sensitive indexing of text documents. That
way a full text search can be realised. However
this feature is not fully integrated at the moment
and thus subject of future work. Finally the Com-
mand Dispatcher connects to an extensible set of
application modules which allow to process and
analyse stored documents. These are briefly intro-
duced in the next section.
To get a better idea of how the described com-
ponents work together we give an example of how
the task to perform PoS tagging on a text docu-
ment is accomplished: The task to process a spe-
cific document is sent from the client to the server.
As a first step the Command Dispatcher checks
based on the Master Data if the requesting user
is logged in correctly, authorized to perform PoS
tagging and has permission to read the document
to be tagged. The next step is to fetch the docu-
ment from the Storage Handler as input to the PoS
Tagger application module. The tagger creates a
new document which is handed over to the Storage
Handler which decides how to store the resource.
Since the output of the tagger is a XML document
it is stored as a XML Database. Finally the in-
formation about the new document is stored in the
Master Data including a reference to the original
one in order to state from which document it has
been derived. That way it is possible to track on
which basis a given document has been created.
</bodyText>
<footnote confidence="0.987823666666667">
4http://dev.mysql.com
5http://www.iana.org/assignments/
media-types/
</footnote>
<bodyText confidence="0.999271">
Finally the Command Dispatcher signals the suc-
cessful completion of the task back to the Client.
Figure 3 shows the class diagram of the master
data model. The design is woven around the gen-
eral concept that authorities have access permis-
sions on resources. Authorities are distinguished
into users and groups. Users can be members of
one or more groups. Furthermore authorities can
have permissions to use features of the system.
That way it is possible to individually configure
the spectrum of functions someone can effectively
use. Resources are distinguished by documents
and repositories. Repositories are containers, sim-
ilar to directories known from file systems. An im-
portant addition is that resources can be member
of an arbitrary number of repositories. That way a
document or a repository can be used in different
contexts allowing for easy corpus compilation.
A typical scenario which benefits from such a
data model is a distributed research group consist-
ing of several research teams: One team collects
data from field research, a second processes and
annotates the raw data and a third team performs
statistical analysis. In this example every group
has the need to share resources with others while
keeping control over the data: The statistics team
should be able to read the annotated data but must
not be allowed to edit resources and so on.
</bodyText>
<figureCaption confidence="0.9999715">
Figure 2: Overview of the System Architecture.
Figure 3: UML Class Diagram of the Master Data.
</figureCaption>
<page confidence="0.97508">
22
</page>
<figureCaption confidence="0.990657">
Figure 4: The eHumanities Desktop environment showing a chained document and the PoS Tagger
dialog.
</figureCaption>
<sectionHeader confidence="0.996499" genericHeader="method">
3 Applications
</sectionHeader>
<bodyText confidence="0.999907666666667">
In the following we outline the initial set of appli-
cations which is currently available via eHuman-
ities Desktop. Figure 4 gives an idea of the look
and feel of the system. It shows the visualisation
of a chained document and the PoS Tagger win-
dow with an opened document selection dialog.
</bodyText>
<subsectionHeader confidence="0.999373">
3.1 Document Manager
</subsectionHeader>
<bodyText confidence="0.9999741">
The Document Manager is the core of the desktop.
It allows to upload and download documents as
well as sharing them with other users and groups.
It follows the look and feel of the Windows Ex-
plorer. Documents and repositories can be created
and edited via context menus. They can be moved
via drag and drop between different repositories.
Both can be copied via drag and drop while press-
ing the Ctrl-key. Note that repositories only con-
tain references- so a copy is not a physical redupli-
cation. Documents which are not assigned to any
repository the current user can see are gathered in
a special repository called Floating Documents. A
double click on a file will open a document viewer
which offers a rendered view of textual contents.
The button ’Access Permissions’ opens a dialog
which allows to edit the rights of other users and
groups on the currently selected resources. Finally
a search dialog at the top makes documents search-
able.
</bodyText>
<subsectionHeader confidence="0.999644">
3.2 PoS Tagging
</subsectionHeader>
<bodyText confidence="0.999957384615385">
The PoS-Tagging module enables users to pre-
process their uploaded documents. Besides to-
kenisation and sentence boundary detection, a tri-
gram HMM-Tagger is implemented in the pre-
processing system (Waltinger and Mehler, 2009).
The tagging module was trained and evaluated
based on the German Negra Corpus (Uszkoreit
et al., 2006) (F-measure of 0.96) and the En-
glish Penn Treebank (Marcus et al., 1994) (F-
measure of 0.956). Additionally a lemmatisation
and stemming module is included for both lan-
guages. As an unifying exchange format the com-
ponent utilises TEI P5 (Burnard, 2007).
</bodyText>
<subsectionHeader confidence="0.99987">
3.3 Lexical Chaining
</subsectionHeader>
<bodyText confidence="0.999904461538462">
As a further linguistic application module a lex-
ical chainer (Mehler, 2005; Mehler et al., 2007;
Waltinger et al., 2008a; Waltinger et al., 2008b)
has been included in the online desktop environ-
ment. That is, semantically related tokens of a
given text can be tracked and connected by means
of a lexical reference system. The system cur-
rently uses two different terminological ontolo-
gies - WordNet (Fellbaum, 1998) and GermaNet
(Hamp and Feldweg, 1997) - as chaining resources
which have been mapped onto the database for-
mat. However the list of resources for chaining
can easily be extended.
</bodyText>
<page confidence="0.994704">
23
</page>
<subsectionHeader confidence="0.987115">
3.4 Lexicon Exploration
</subsectionHeader>
<bodyText confidence="0.999583333333333">
With regards to lexicon exploration, the system ag-
gregates different lexical resources including En-
glish, German and Latin. In this module, not only
co-occurrence data, social and terminological on-
tologies but also social tagging enhanced data are
available for a given input token.
</bodyText>
<subsectionHeader confidence="0.974901">
3.5 Text Classification
</subsectionHeader>
<bodyText confidence="0.999960428571429">
An easy to use text classifier (Waltinger et al.,
2008a) has been implemented into the system. In
this, an automatic mapping of an unknown text
onto a social ontology is enabled. The system
uses the category tree of the German and English
Wikipedia-Project in order to assign category in-
formation to textual data.
</bodyText>
<subsectionHeader confidence="0.988723">
3.6 Historical Semantics Corpus
Management
</subsectionHeader>
<bodyText confidence="0.997969666666667">
The HSCM is developed by the research project
Historical Semantics Corpus Management (Jussen
et al., 2007). The system aims at a texttechno-
logical representation and quantitative analysis of
chronologically layered corpora. It is possible to
query for single terms or entire phrases. The con-
tents can be accessed as rendered HTML as well
as TEI P56 encoded. In its current state is supports
to browse and analyse the Patrologia Latina7.
</bodyText>
<sectionHeader confidence="0.999375" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999928384615385">
This paper introduced eHumanities Desktop- a
web based corpus management system which
offers an extensible set of application modules
which allow online exploration, processing and
analysis of resources in humanities. The use
of the system was exemplified by describing the
Document Manager, PoS Tagging, Lexical Chain-
ing, Lexicon Exploration, Text Classification and
Historical Semantics Corpus Management. Fu-
ture work will include flexible XML indexing and
queries as well as full text search on documents.
Furthermore the set of applications will be gradu-
ally extended.
</bodyText>
<sectionHeader confidence="0.987097" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.5856805">
Lou Burnard. 2007. New tricks from an old dog:
An overview of tei p5. In Lou Burnard, Milena
</bodyText>
<footnote confidence="0.993726">
6http://www.tei-c.org/Guidelines/P5
7http://pld.chadwyck.co.uk/
</footnote>
<reference confidence="0.993917767857143">
Dobreva, Norbert Fuhr, and Anke L¨udeling, edi-
tors, Digital Historical Corpora- Architecture, An-
notation, and Retrieval, number 06491 in Dagstuhl
Seminar Proceedings, Dagstuhl, Germany. Interna-
tionales Begegnungs- und Forschungszentrum f¨ur
Informatik (IBFI), Schloss Dagstuhl, Germany.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge.
R¨udiger Gleim, Alexander Mehler, and Hans-J¨urgen
Eikmeyer. 2007. Representing and maintaining
large corpora. In Proceedings of the Corpus Lin-
guistics 2007 Conference, Birmingham (UK).
Birgit Hamp and Helmut Feldweg. 1997. Germanet - a
lexical-semantic net for german. In In Proceedings
of ACL workshop Automatic Information Extraction
and Building of Lexical Semantic Resources for NLP
Applications, pages 9–15.
Bernhard Jussen, Alexander Mehler, and Alexandra
Ernst. 2007. A corpus management system for his-
torical semantics. Appears in: Sprache und Daten-
verarbeitung.
Mitchell P. Marcus, Beatrice Santorini, and Mary A.
Marcinkiewicz. 1994. Building a large annotated
corpus of english: The penn treebank. Computa-
tional Linguistics, 19(2):313–330.
Alexander Mehler, Ulli Waltinger, and Armin Weg-
ner. 2007. A formal text representation model
based on lexical chaining. In Proceedings of the
KI 2007 Workshop on Learning from Non-Vectorial
Data (LNVD 2007) September 10, Osnabr¨uck, pages
17–26, Osnabr¨uck. Universit¨at Osnabr¨uck.
Alexander Mehler. 2005. Lexical chaining as a
source of text chaining. In Jon Patrick and Christian
Matthiessen, editors, Proceedings of the 1st Compu-
tational Systemic Functional Grammar Conference,
University of Sydney, Australia, pages 12–21.
Hans Uszkoreit, Thorsten Brants, Sabine Brants, and
Christine Foeldesi. 2006. Negra corpus.
Ulli Waltinger and Alexander Mehler. 2009. Web as
preprocessed corpus: Building large annotated cor-
pora from heterogeneous web document data. In
preparation.
Ulli Waltinger, Alexander Mehler, and Gerhard Heyer.
2008a. Towards automatic content tagging: En-
hanced web services in digital libraries using lexi-
cal chaining. In 4th Int. Conf. on Web Information
Systems and Technologies (WEBIST ’08), 4-7 May,
Funchal, Portugal. Barcelona.
Ulli Waltinger, Alexander Mehler, and Maik
St¨uhrenberg. 2008b. An integrated model of
lexical chaining: Application, resources and its
format. In Angelika Storrer, Alexander Geyken,
Alexander Siebert, and Kay-Michael W¨urzner,
editors, Proceedings of KONVENS 2008 —
Erg¨anzungsband Textressourcen und lexikalisches
Wissen, pages 59–70.
</reference>
<page confidence="0.999177">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.664342">
<title confidence="0.9976265">eHumanities Desktop - An Online System for Corpus Management and Analysis in Support of Computing in the Humanities</title>
<author confidence="0.991584">Ulli Alexandra Alexander</author>
<affiliation confidence="0.869223">amp; Dietmar</affiliation>
<address confidence="0.67956">Frankfurt am Main, Bielefeld</address>
<abstract confidence="0.999311875">paper introduces Deskan online system for corpus management and analysis in support of Computing in the Humanities. Design issues and the overall architecture are described as well as an initial set of applications which are offered by the system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Norbert Fuhr Dobreva</author>
</authors>
<title>and Anke L¨udeling, editors,</title>
<booktitle>Digital Historical Corpora- Architecture, Annotation, and Retrieval, number 06491 in Dagstuhl Seminar Proceedings, Dagstuhl, Germany. Internationales Begegnungs- und Forschungszentrum f¨ur Informatik (IBFI), Schloss Dagstuhl,</booktitle>
<location>Germany.</location>
<marker>Dobreva, </marker>
<rawString>Dobreva, Norbert Fuhr, and Anke L¨udeling, editors, Digital Historical Corpora- Architecture, Annotation, and Retrieval, number 06491 in Dagstuhl Seminar Proceedings, Dagstuhl, Germany. Internationales Begegnungs- und Forschungszentrum f¨ur Informatik (IBFI), Schloss Dagstuhl, Germany.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R¨udiger Gleim</author>
<author>Alexander Mehler</author>
<author>Hans-J¨urgen Eikmeyer</author>
</authors>
<title>Representing and maintaining large corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of the Corpus Linguistics</booktitle>
<location>Birmingham (UK).</location>
<contexts>
<context position="3846" citStr="Gleim et al., 2007" startWordPosition="589" endWordPosition="592">e information about all objects managed by the system, for example users, groups, documents, resources and their interrelations. All this information is stored in a transactional Relational Database (using MySQL4). The underlying data model is described later in more detail. Another important component is the Storage Handler: Based on an automatic mime type5 detection it decides how to store and retrieve documents. For example videos and audio material are best stored as files whereas XML documents are better accessible via a XML Database Management System or specialized DBMS (e.g. HyGraphDB (Gleim et al., 2007)). Which kind of Storage Backend is used to archive a given document is transparent to the user- and also to developers using the Storage Handler. The Document Indexer allows for structure sensitive indexing of text documents. That way a full text search can be realised. However this feature is not fully integrated at the moment and thus subject of future work. Finally the Command Dispatcher connects to an extensible set of application modules which allow to process and analyse stored documents. These are briefly introduced in the next section. To get a better idea of how the described compone</context>
</contexts>
<marker>Gleim, Mehler, Eikmeyer, 2007</marker>
<rawString>R¨udiger Gleim, Alexander Mehler, and Hans-J¨urgen Eikmeyer. 2007. Representing and maintaining large corpora. In Proceedings of the Corpus Linguistics 2007 Conference, Birmingham (UK).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Birgit Hamp</author>
<author>Helmut Feldweg</author>
</authors>
<title>Germanet - a lexical-semantic net for german. In</title>
<date>1997</date>
<booktitle>In Proceedings of ACL workshop Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications,</booktitle>
<pages>9--15</pages>
<contexts>
<context position="9383" citStr="Hamp and Feldweg, 1997" startWordPosition="1522" endWordPosition="1525">lly a lemmatisation and stemming module is included for both languages. As an unifying exchange format the component utilises TEI P5 (Burnard, 2007). 3.3 Lexical Chaining As a further linguistic application module a lexical chainer (Mehler, 2005; Mehler et al., 2007; Waltinger et al., 2008a; Waltinger et al., 2008b) has been included in the online desktop environment. That is, semantically related tokens of a given text can be tracked and connected by means of a lexical reference system. The system currently uses two different terminological ontologies - WordNet (Fellbaum, 1998) and GermaNet (Hamp and Feldweg, 1997) - as chaining resources which have been mapped onto the database format. However the list of resources for chaining can easily be extended. 23 3.4 Lexicon Exploration With regards to lexicon exploration, the system aggregates different lexical resources including English, German and Latin. In this module, not only co-occurrence data, social and terminological ontologies but also social tagging enhanced data are available for a given input token. 3.5 Text Classification An easy to use text classifier (Waltinger et al., 2008a) has been implemented into the system. In this, an automatic mapping </context>
</contexts>
<marker>Hamp, Feldweg, 1997</marker>
<rawString>Birgit Hamp and Helmut Feldweg. 1997. Germanet - a lexical-semantic net for german. In In Proceedings of ACL workshop Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications, pages 9–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernhard Jussen</author>
<author>Alexander Mehler</author>
<author>Alexandra Ernst</author>
</authors>
<title>A corpus management system for historical semantics. Appears in: Sprache und Datenverarbeitung.</title>
<date>2007</date>
<contexts>
<context position="10321" citStr="Jussen et al., 2007" startWordPosition="1670" endWordPosition="1673">o-occurrence data, social and terminological ontologies but also social tagging enhanced data are available for a given input token. 3.5 Text Classification An easy to use text classifier (Waltinger et al., 2008a) has been implemented into the system. In this, an automatic mapping of an unknown text onto a social ontology is enabled. The system uses the category tree of the German and English Wikipedia-Project in order to assign category information to textual data. 3.6 Historical Semantics Corpus Management The HSCM is developed by the research project Historical Semantics Corpus Management (Jussen et al., 2007). The system aims at a texttechnological representation and quantitative analysis of chronologically layered corpora. It is possible to query for single terms or entire phrases. The contents can be accessed as rendered HTML as well as TEI P56 encoded. In its current state is supports to browse and analyse the Patrologia Latina7. 4 Conclusion This paper introduced eHumanities Desktop- a web based corpus management system which offers an extensible set of application modules which allow online exploration, processing and analysis of resources in humanities. The use of the system was exemplified </context>
</contexts>
<marker>Jussen, Mehler, Ernst, 2007</marker>
<rawString>Bernhard Jussen, Alexander Mehler, and Alexandra Ernst. 2007. A corpus management system for historical semantics. Appears in: Sprache und Datenverarbeitung.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="8729" citStr="Marcus et al., 1994" startWordPosition="1416" endWordPosition="1419">The button ’Access Permissions’ opens a dialog which allows to edit the rights of other users and groups on the currently selected resources. Finally a search dialog at the top makes documents searchable. 3.2 PoS Tagging The PoS-Tagging module enables users to preprocess their uploaded documents. Besides tokenisation and sentence boundary detection, a trigram HMM-Tagger is implemented in the preprocessing system (Waltinger and Mehler, 2009). The tagging module was trained and evaluated based on the German Negra Corpus (Uszkoreit et al., 2006) (F-measure of 0.96) and the English Penn Treebank (Marcus et al., 1994) (Fmeasure of 0.956). Additionally a lemmatisation and stemming module is included for both languages. As an unifying exchange format the component utilises TEI P5 (Burnard, 2007). 3.3 Lexical Chaining As a further linguistic application module a lexical chainer (Mehler, 2005; Mehler et al., 2007; Waltinger et al., 2008a; Waltinger et al., 2008b) has been included in the online desktop environment. That is, semantically related tokens of a given text can be tracked and connected by means of a lexical reference system. The system currently uses two different terminological ontologies - WordNet </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary A. Marcinkiewicz. 1994. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Mehler</author>
<author>Ulli Waltinger</author>
<author>Armin Wegner</author>
</authors>
<title>A formal text representation model based on lexical chaining.</title>
<date>2007</date>
<booktitle>In Proceedings of the KI 2007 Workshop on Learning from Non-Vectorial Data (LNVD 2007) September 10, Osnabr¨uck,</booktitle>
<pages>17--26</pages>
<institution>Osnabr¨uck. Universit¨at Osnabr¨uck.</institution>
<contexts>
<context position="9026" citStr="Mehler et al., 2007" startWordPosition="1464" endWordPosition="1467">Besides tokenisation and sentence boundary detection, a trigram HMM-Tagger is implemented in the preprocessing system (Waltinger and Mehler, 2009). The tagging module was trained and evaluated based on the German Negra Corpus (Uszkoreit et al., 2006) (F-measure of 0.96) and the English Penn Treebank (Marcus et al., 1994) (Fmeasure of 0.956). Additionally a lemmatisation and stemming module is included for both languages. As an unifying exchange format the component utilises TEI P5 (Burnard, 2007). 3.3 Lexical Chaining As a further linguistic application module a lexical chainer (Mehler, 2005; Mehler et al., 2007; Waltinger et al., 2008a; Waltinger et al., 2008b) has been included in the online desktop environment. That is, semantically related tokens of a given text can be tracked and connected by means of a lexical reference system. The system currently uses two different terminological ontologies - WordNet (Fellbaum, 1998) and GermaNet (Hamp and Feldweg, 1997) - as chaining resources which have been mapped onto the database format. However the list of resources for chaining can easily be extended. 23 3.4 Lexicon Exploration With regards to lexicon exploration, the system aggregates different lexica</context>
</contexts>
<marker>Mehler, Waltinger, Wegner, 2007</marker>
<rawString>Alexander Mehler, Ulli Waltinger, and Armin Wegner. 2007. A formal text representation model based on lexical chaining. In Proceedings of the KI 2007 Workshop on Learning from Non-Vectorial Data (LNVD 2007) September 10, Osnabr¨uck, pages 17–26, Osnabr¨uck. Universit¨at Osnabr¨uck.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Mehler</author>
</authors>
<title>Lexical chaining as a source of text chaining.</title>
<date>2005</date>
<booktitle>Proceedings of the 1st Computational Systemic Functional Grammar Conference, University of Sydney, Australia,</booktitle>
<pages>12--21</pages>
<editor>In Jon Patrick and Christian Matthiessen, editors,</editor>
<contexts>
<context position="9005" citStr="Mehler, 2005" startWordPosition="1462" endWordPosition="1463">ed documents. Besides tokenisation and sentence boundary detection, a trigram HMM-Tagger is implemented in the preprocessing system (Waltinger and Mehler, 2009). The tagging module was trained and evaluated based on the German Negra Corpus (Uszkoreit et al., 2006) (F-measure of 0.96) and the English Penn Treebank (Marcus et al., 1994) (Fmeasure of 0.956). Additionally a lemmatisation and stemming module is included for both languages. As an unifying exchange format the component utilises TEI P5 (Burnard, 2007). 3.3 Lexical Chaining As a further linguistic application module a lexical chainer (Mehler, 2005; Mehler et al., 2007; Waltinger et al., 2008a; Waltinger et al., 2008b) has been included in the online desktop environment. That is, semantically related tokens of a given text can be tracked and connected by means of a lexical reference system. The system currently uses two different terminological ontologies - WordNet (Fellbaum, 1998) and GermaNet (Hamp and Feldweg, 1997) - as chaining resources which have been mapped onto the database format. However the list of resources for chaining can easily be extended. 23 3.4 Lexicon Exploration With regards to lexicon exploration, the system aggreg</context>
</contexts>
<marker>Mehler, 2005</marker>
<rawString>Alexander Mehler. 2005. Lexical chaining as a source of text chaining. In Jon Patrick and Christian Matthiessen, editors, Proceedings of the 1st Computational Systemic Functional Grammar Conference, University of Sydney, Australia, pages 12–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Uszkoreit</author>
<author>Thorsten Brants</author>
<author>Sabine Brants</author>
<author>Christine Foeldesi</author>
</authors>
<date>2006</date>
<note>Negra corpus.</note>
<contexts>
<context position="8657" citStr="Uszkoreit et al., 2006" startWordPosition="1403" endWordPosition="1406">l open a document viewer which offers a rendered view of textual contents. The button ’Access Permissions’ opens a dialog which allows to edit the rights of other users and groups on the currently selected resources. Finally a search dialog at the top makes documents searchable. 3.2 PoS Tagging The PoS-Tagging module enables users to preprocess their uploaded documents. Besides tokenisation and sentence boundary detection, a trigram HMM-Tagger is implemented in the preprocessing system (Waltinger and Mehler, 2009). The tagging module was trained and evaluated based on the German Negra Corpus (Uszkoreit et al., 2006) (F-measure of 0.96) and the English Penn Treebank (Marcus et al., 1994) (Fmeasure of 0.956). Additionally a lemmatisation and stemming module is included for both languages. As an unifying exchange format the component utilises TEI P5 (Burnard, 2007). 3.3 Lexical Chaining As a further linguistic application module a lexical chainer (Mehler, 2005; Mehler et al., 2007; Waltinger et al., 2008a; Waltinger et al., 2008b) has been included in the online desktop environment. That is, semantically related tokens of a given text can be tracked and connected by means of a lexical reference system. The </context>
</contexts>
<marker>Uszkoreit, Brants, Brants, Foeldesi, 2006</marker>
<rawString>Hans Uszkoreit, Thorsten Brants, Sabine Brants, and Christine Foeldesi. 2006. Negra corpus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulli Waltinger</author>
<author>Alexander Mehler</author>
</authors>
<title>Web as preprocessed corpus: Building large annotated corpora from heterogeneous web document data. In preparation.</title>
<date>2009</date>
<contexts>
<context position="8553" citStr="Waltinger and Mehler, 2009" startWordPosition="1386" endWordPosition="1389">nt user can see are gathered in a special repository called Floating Documents. A double click on a file will open a document viewer which offers a rendered view of textual contents. The button ’Access Permissions’ opens a dialog which allows to edit the rights of other users and groups on the currently selected resources. Finally a search dialog at the top makes documents searchable. 3.2 PoS Tagging The PoS-Tagging module enables users to preprocess their uploaded documents. Besides tokenisation and sentence boundary detection, a trigram HMM-Tagger is implemented in the preprocessing system (Waltinger and Mehler, 2009). The tagging module was trained and evaluated based on the German Negra Corpus (Uszkoreit et al., 2006) (F-measure of 0.96) and the English Penn Treebank (Marcus et al., 1994) (Fmeasure of 0.956). Additionally a lemmatisation and stemming module is included for both languages. As an unifying exchange format the component utilises TEI P5 (Burnard, 2007). 3.3 Lexical Chaining As a further linguistic application module a lexical chainer (Mehler, 2005; Mehler et al., 2007; Waltinger et al., 2008a; Waltinger et al., 2008b) has been included in the online desktop environment. That is, semantically </context>
</contexts>
<marker>Waltinger, Mehler, 2009</marker>
<rawString>Ulli Waltinger and Alexander Mehler. 2009. Web as preprocessed corpus: Building large annotated corpora from heterogeneous web document data. In preparation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulli Waltinger</author>
<author>Alexander Mehler</author>
<author>Gerhard Heyer</author>
</authors>
<title>Towards automatic content tagging: Enhanced web services in digital libraries using lexical chaining.</title>
<date>2008</date>
<booktitle>In 4th Int. Conf. on Web Information Systems and Technologies (WEBIST</booktitle>
<volume>08</volume>
<pages>4--7</pages>
<location>Funchal, Portugal. Barcelona.</location>
<contexts>
<context position="9050" citStr="Waltinger et al., 2008" startWordPosition="1468" endWordPosition="1471">and sentence boundary detection, a trigram HMM-Tagger is implemented in the preprocessing system (Waltinger and Mehler, 2009). The tagging module was trained and evaluated based on the German Negra Corpus (Uszkoreit et al., 2006) (F-measure of 0.96) and the English Penn Treebank (Marcus et al., 1994) (Fmeasure of 0.956). Additionally a lemmatisation and stemming module is included for both languages. As an unifying exchange format the component utilises TEI P5 (Burnard, 2007). 3.3 Lexical Chaining As a further linguistic application module a lexical chainer (Mehler, 2005; Mehler et al., 2007; Waltinger et al., 2008a; Waltinger et al., 2008b) has been included in the online desktop environment. That is, semantically related tokens of a given text can be tracked and connected by means of a lexical reference system. The system currently uses two different terminological ontologies - WordNet (Fellbaum, 1998) and GermaNet (Hamp and Feldweg, 1997) - as chaining resources which have been mapped onto the database format. However the list of resources for chaining can easily be extended. 23 3.4 Lexicon Exploration With regards to lexicon exploration, the system aggregates different lexical resources including En</context>
</contexts>
<marker>Waltinger, Mehler, Heyer, 2008</marker>
<rawString>Ulli Waltinger, Alexander Mehler, and Gerhard Heyer. 2008a. Towards automatic content tagging: Enhanced web services in digital libraries using lexical chaining. In 4th Int. Conf. on Web Information Systems and Technologies (WEBIST ’08), 4-7 May, Funchal, Portugal. Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulli Waltinger</author>
<author>Alexander Mehler</author>
<author>Maik St¨uhrenberg</author>
</authors>
<title>An integrated model of lexical chaining: Application, resources and its format.</title>
<date>2008</date>
<booktitle>Proceedings of KONVENS 2008 — Erg¨anzungsband Textressourcen und lexikalisches Wissen,</booktitle>
<pages>59--70</pages>
<editor>In Angelika Storrer, Alexander Geyken, Alexander Siebert, and Kay-Michael W¨urzner, editors,</editor>
<marker>Waltinger, Mehler, St¨uhrenberg, 2008</marker>
<rawString>Ulli Waltinger, Alexander Mehler, and Maik St¨uhrenberg. 2008b. An integrated model of lexical chaining: Application, resources and its format. In Angelika Storrer, Alexander Geyken, Alexander Siebert, and Kay-Michael W¨urzner, editors, Proceedings of KONVENS 2008 — Erg¨anzungsband Textressourcen und lexikalisches Wissen, pages 59–70.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>