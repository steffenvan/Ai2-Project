<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.6262668">
Incremental Construction of Compact Acyclic NFAs
Kyriakos N. Sgarbas, Nikos D. Fakotakis, George K. Kokkinakis
Wire Communications Laboratory
Electrical and Computer Engineering Department
University of Patras, GR-26500 Rio, Greece
</note>
<email confidence="0.994435">
{sgarbas,fakotaki,gkokkin}@wcl.ee.upatras.gr
</email>
<sectionHeader confidence="0.996557" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998822">
This paper presents and analyzes an
incremental algorithm for the
construction of Acyclic Non-
deterministic Finite-state Automata
(NFA). Automata of this type are quite
useful in computational linguistics,
especially for storing lexicons. The
proposed algorithm produces compact
NFAs, i.e. NFAs that do not contain
equivalent states. Unlike Deterministic
Finite-state Automata (DFA), this
property is not sufficient to ensure
minimality, but still the resulting NFAs
are considerably smaller than the
minimal DFAs for the same languages.
</bodyText>
<sectionHeader confidence="0.996287" genericHeader="keywords">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.37196">
1
</subsectionHeader>
<bodyText confidence="0.99568075">
Acyclic Finite-State Automata (FSA) provide a
very efficient data structure for lexicon
representation and fast string matching, with a
great variety of applications in lexicon building
(Daciuk et al., 2000), morphological processing
(Sgarbas et al., 2000b) and speech processing
(Lacouture and De Mori, 1991). They constitute
very compact representations of lexicons, since
common word prefixes and suffixes are
represented by the same transitions. This
representation also facilitates content-
addressable pattern matching.
</bodyText>
<page confidence="0.791153">
1
</page>
<note confidence="0.582292">
Some authors (e.g. Perrin, 1990; Aoe et al. 1992;
Sgarbas et al., 1995) use the term DAWG (Directed
Acyclic Word Graph) when referring to acyclic FSAs.
However, others (e.g. Crochemore and Verin, 1997) use the
same term to denote the suffix automaton of a string.
</note>
<bodyText confidence="0.99956244">
Examples of acyclic FSAs storing lexicons
are shown in Fig.1. The FSAs consist of states
and transitions between states. Each transition
has a label. The words are stored as directed
paths on the graph. They can be retrieved by
traversing the graph from an initial state
(source) to a terminal state (sink), collecting the
labels of the transitions encountered. In this
way, traversing the graphs of Fig.1 from the
source (0) to the sink (0) we retrieve the words
dance, darts, dart, start and smart.
There are two types of FSAs. The graph of
Fig.1a is called deterministic (DFA) because no
transitions exist that have the same labels and
leave the same state. This property results to a
very efficient search function. Graphs that do
not have this property, like the one of Fig.1b, are
called non-deterministic automata (NFA). NFAs
are smaller than DFAs but they are a little
slower to search.
DFAs are more popular for lexicon
representation, especially the minimal ones, i.e.
DFAs with the least number of states. Several
algorithms are known for the construction of the
minimal DFA, given a set of words (Hopcroft
</bodyText>
<sectionHeader confidence="0.5843255" genericHeader="introduction">
Deterministic Finite-State Non-Deterministic
Automaton (DFA) Finite-State Automaton (NFA)
</sectionHeader>
<figure confidence="0.973264">
(a) (b)
</figure>
<figureCaption confidence="0.999634">
Figure 1. The same lexicon in DFA and NFA.
</figureCaption>
<figure confidence="0.980911">
d
S
m
a
r
t
n
t
a
�
r
S
e
t
�
�
d
S
n
�
a
r
d
t
a
</figure>
<equation confidence="0.823165666666667">
m
t
r
S
t
e
</equation>
<bodyText confidence="0.999744318181819">
and Ullman, 1979; Perrin, 199o; Revuz, 1992;
Watson, 1993). Recently, some incremental
algorithms have been proposed for this task
(Aoe et al., 1993; Park et al., 1994; Sgarbas et
al., 1995; Daciuk et al., 1998; Mihov, 1998;
Ciura and Deorowicz, 1999; Daciuk et al., 2ooo;
Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental
algorithms are useful because they can update
the lexicon without rebuilding the whole
structure from scratch. 2
For minimal NFAs there are also some (non-
incremental) algorithms (Kameda and Weiner,
197o; Kim, 1974; Arnold et al., 1992; Matz and
Potthoff, 1995) but unlike DFAs, there is no
single minimal NFA for a given language.
In this paper we present an incremental
algorithm for constructing Acyclic NFAs. We
consider NFAs with one source and one sink
state, like the one in Fig.1b, because this
facilitates bi-directional search in the graph. We
introduce the notion of a compact automaton 3
(i.e. one with no equivalent states) and we prove
that the presented algorithm produces compact
NFAs. We also show that (unlike DFAs) a
compact NFA is not necessarily minimal.
Therefore the algorithm does not always
produce minimal acyclic NFAs; the size of the
NFA depends on the order the words are
inserted. However, the NFAs produced by this
algorithm are typically considerably smaller
than the corresponding minimal DFAs and the
process of adding a new word to an existing
automaton is fast enough to be used on-line.
In Section 2 of this paper some basic
definitions are given that will be used
throughout the paper. We have tried to define
appropriate concepts that simplify the proofs of
the lemmas. The presentation of the algorithm
follows in Section 3 with a step-by-step
example. In Section 4, a set of interesting
lemmas is provided, resulting to a proof that the
algorithm actually produces compact NFAs.
Experimental results are presented in Section 5.
The paper conclusions follow in Section 6.
</bodyText>
<footnote confidence="0.981030166666667">
2For more information, see http://odur.let.rug.nl/alfa/
fsa_stuff/
3Not to be confused with the notion of compact
DAWGs as defined by Crochemore and Verin (1997),
Blumer et al. (1989), where whole strings are allowed as
labels on transitions.
</footnote>
<sectionHeader confidence="0.963097" genericHeader="method">
2 Definitions
</sectionHeader>
<bodyText confidence="0.99504434">
Let Q be a set of states (vertices) and be a set
of symbols (alphabet). A labeled directed
transition is then defined as a triple (n1,n2,s)
from state n1 to n2 with label s, where n1,n2»Q
and s» .
Let LºQ¤Q¤ be a set of labeled directed
transitions. Then an ordered series [(no,n1,s1),
(n1,n2,s2), (n2,n3,s3), ....., (nk-2,nk-1,sk-1), (nk-1,
nk,sk)] of successive transitions of L is called a
succession from state no to state nk and is
denoted by succ(no,nk). We say that state nk is a
successor of state no and that state no is a
predecessor of state nk. In the special case where
Isucc(no,nk)I =1, state nk is an immediate
successor of no and state no is an immediate
predecessor of nk.
There may be more than one successions
between two states. We define as SUCC(no, nk)
the set of all successions from no to nk.
For a succession G=succ(no, nk) =[(no,n1,s1),
(n1,n2,s2), (n2,n3,s3), ..., (nk-2,nk-1,sk-1), (nk-1,nk,sk)],
we define as label(G) the ordered series [s1, s2,
s3, ..., sk-1, sk] of symbols as derived by the
labels of the transitions in G.
For a set of successions H=SUCC(no, sk), we
define as LABEL(H) the set of all label(G),
&amp;quot;G»H.
Based on the above, a Finite State Automaton
with one source and one sink is defined as the
quintuple (Q,L, ,source,sink), where
source,sink»Q and &amp;quot;n»Q-{source}, SUCC(
source,n)¨3 and &amp;quot;n»Q-{sink}, SUCC(n,sink)
¨3. In other words, source is a predecessor of
every other state in Q and sink is a successor of
every other state in Q.
The graph is acyclic iff &amp;quot;n»Q,
SUCC(n,n) =3.
The set of strings or words contained in an
acyclic FSA is finite and equals to
LABEL(SUCC(source,sink)). All words in an
acyclic FSA are finite-lengthed.
If two states n1,n2»Q (with n1¨n2) satisfy the
property LABEL(SUCC(n1,sink)) = LABEL(
SUCC(n2,sink)), then we say that n1 and n2 are
down-equivalent. Accordingly, if LABEL(
SUCC(source,n1)) = LABEL(SUCC(source,n2)),
we say that n1 and n2 are up-equivalent. Saying
that n1 and n2 are equivalent means that they are
either up-equivalent or down-equivalent. Two
states that are not equivalent are called distinct.
</bodyText>
<figureCaption confidence="0.999666">
Figure 2. 0peration of the incremental algorithm.
</figureCaption>
<figure confidence="0.997430119402985">
P
P
C f
f
i
a
i
h
I
I
0
a
0
t
(b)
C
f
P
I
h
0
a
i i
a
0
t
(d)
U
P
C f
I
h
i
a
i
a
0
t
(a)
U
U
P
C f
f
I
I
h
i
a
i
a
0
0
t
(C)
U
C
f
U
i
a
h
0
P
I
t
(e)
</figure>
<bodyText confidence="0.998844054054054">
A single state is called distinct if it is not
equivalent with any other state in Q. An
automaton that contains no equivalent states is
called compact (for DFAs compact also implies
minimal).
For each state nEQ, we consider the
transitions entering n and the transitions leaving
n and we define two sets: the fan-in set of n,
F.(n) ={(n&apos;,s): (n&apos;,n,s)EL} and the fan-out set of
n, F0t,,.(n) = {(n&apos;,s): (n,n&apos;,s)EL}. Although the
transitions contained in these two sets are not
full transitions (state n is missing from the
triples) they are considered as transitions, since
state n is always known and they can be restored
into triples at any time. However, the above
representation facilitates the comparison of fan-
in and fan-out sets of different states.
An automaton is deterministic (DFA) iff
VnEQ, VsE I{n&apos;: (n&apos;,s)EF0t,,.(n)}I &lt;_1. ,.hus, in
DFAs VnEQ, IF0t,,.(n)j &lt;_1 1. An automaton is
called non-deterministic (NFA) otherwise.
If two states n1,n2EQ (with nl#n2) satisfy the
property F0t,,.(nl)=F0t,,.(n2), then we say that nl
and n2 are down-similar. Respectively, if they
satisfy the property F,N(nl)=F4n2), then we say
that nl and n2 are up-similar. Saying that two
states are similar means that they are either up-
similar or down-similar. In other words, two
states are similar if the input(output) transitions
of the one match the input(output) transitions of
the other in labels and destinations. Similar
states are always equivalent, but equivalent
states are not necessarily similar (see Lemma 1,
below).
Let D =(Q,L, ,source,sink) be an acyclic
NFA as defined above. We present the
following lemmas:
</bodyText>
<construct confidence="0.858139666666667">
Lemma 1: (a) Two down-equivalent states
of D are either down-similar or their immediate
successors are also down-equivalent. (b) Two
up-equivalent states of D are either up-similar
or their immediate predecessors are also up-
equivalent.
</construct>
<bodyText confidence="0.915131857142857">
Proof: (a) Let p,qEQ and p, q are down-
equivalent. Consider two transitions (p,p&apos;,s) and
(q,q&apos;,s) such that p&apos;#q&apos;. If for no sE two such
transitions exist, that implies F0t,,.(p)=F0t,,.(q) and
p,q are down-similar. 0therwise, if the
transitions exist, consider the states p&apos; and q&apos;.
Suppose that they are not down-equivalent. ,.hus
</bodyText>
<table confidence="0.9899534">
H STAGE 1: Attach word to NFA
1 no—source; i—O; H array w[] contains the new word
2 while (i&lt;M-1) { H M=Iw[]I
3 create new state n;
4 create new transition (no,n,w[i]);
5 if i=0 then k—(n,w[O]);
6 no—n; i++;
}
7 create new transition (no,sink,w[i]);
8 j—(no,w[i]); p—sink; q—source;
H STAGE 2: Search for up-similar states
9 searchup_failed—O; (n&apos;,c) —j; H the last-marked transition
10 while exists another (n,c)»F (p) with n¨n&apos; { H search only transitions in F (p)
11 if F (n)=F (n&apos;) then { H similarity check
12 {j}— F (n&apos;); H IF (n&apos;)I =1
13 F (n) —F (n)µ{j}; H redirect j
14 delete n&apos;, F (n&apos;), F (n&apos;);
15 p—n; go to 9; H j is the next last-marked transition
}
}
16 searchup_failed—1;
H STAGE 3: Search for down-similar states
17 searchdown_failed—O; (n&apos;,c) —k; H the first-marked transition
18 while exists another (n,c)»F (q) with n¨n&apos; { H search only transitions in F (q)
19 if F (n)=F (n&apos;) then { H similarity check
20 {k}— F (n&apos;); H IF (n&apos;)I =1
21 F (n) F (n)µ{k}; H redirect k
22 delete n&apos;, F (n&apos;), F (n&apos;);
23 q—n; go to 17; H k is the next last-marked transition
}
}
24 searchdown_failed—1;
H STAGE 4: Repeat until both Stage 2 and Stage 3 fail
25 if searchup_failed+searchdown_failed &lt; 2 then go to 9
26 end
</table>
<tableCaption confidence="0.999937">
Table 1. The incremental construction algorithm.
</tableCaption>
<bodyText confidence="0.998608285714286">
we can find two successions sp = succ(p&apos;,sink) and
sq= succ(q&apos;,sink) such that sp¨sq. Then the
successions [(p,p&apos;,s)]µsp and [(q,q&apos;,s)]µsq will
also be different. But this contradicts to the
assumption that p and q are down-equivalent.
Therefore p&apos; and q&apos; are down-equivalent. (b)
Symmetrical to (a). ❑
</bodyText>
<construct confidence="0.4794655">
Lemma 2: D is not compact isimilar states
exist in Q.
</construct>
<bodyText confidence="0.999880454545455">
Proof. First we show that if p,q»Q and p,q
are similar, then D is not compact: Similar states
are always equivalent. Therefore p and q are
equivalent and D is not compact. Next we show
that if D is not compact then Q contains similar
states: If D is not minimal then we can find
p,q»Q with p and q equivalent. By Lemma 1, it
is either p similar to q, or their immediate
successors (predecessors) p&apos; and q&apos; are
equivalent. Supposing the latter, we can apply
Lemma 1 to p&apos; and q&apos;. Since there is only one
sink and one source and Isucc(p,sink)I,
Isucc(source,p)I are finite, we eventually arrive
in two equivalent states which are also
similar. ❑
Lemma 2 constitutes a very useful criterion
for checking whether an automaton is compact
or not. Checking using this criterion is more
efficient than searching for equivalent states,
since given two states, it is much faster to decide
if they are similar than it is to check their
equivalence.
</bodyText>
<sectionHeader confidence="0.593356" genericHeader="method">
3 Presentation of the Algorithm
</sectionHeader>
<bodyText confidence="0.999499230769231">
The proposed algorithm adds a new word to an
existing acyclic NFA. Figure 2 displays an
example of word insertion. The original NFA of
Fig.2a contains six words: cut, chat, chop, chip,
flat and flip. We wish to add the word flop. The
insertion is performed as following:
STAGE l: First we attach the new word to
the existing NFA by creating a separate
succession of transitions between the source and
the sink. We mark all these transitions. ,n Fig.2b
they appear dashed.
STAGE 2: We consider the marked transition
(n&apos;,p,c) closer to the sink and we search in F,N(p)
for a state n down-similar to n&apos;. State n&apos; is
deleted (and so all its outgoing transitions) after
redirecting its incoming transition to n:
F,N(n) =F,N(n)uF,N(n&apos;). The process is repeated,
again considering the marked transition closest
to the sink, until no down-similar states can be
found (see Fig.2c).
STAGE 3: We consider the marked transition
(c,p,n&apos;) closer to the source and we search in
F,,,T(p) for a state n up-similar to n&apos;. State n&apos; is
deleted (and so all its incoming transitions) after
redirecting its outgoing transition to n:
Fo,(n) =Fo,(n)uFo,(n&apos;). The process is
repeated, again considering the marked
transition closest to the source, until no up-
similar states can be found (see Fig.2d).
STAGE 4: Stages 2 and 3 are repeated until
both of them fail to find similar states (see
Fig.2e).
The updated NFA contains all the words of
the original one, plus the new word. Note that
the algorithm does not traverse every state and
transition of the original NFA to add the new
word. However, the resulting NFA is compact.
A proof of this is given in the next section. The
algorithm is shown in Table 1.
</bodyText>
<sectionHeader confidence="0.930825" genericHeader="method">
4 Proof of Correctness
</sectionHeader>
<bodyText confidence="0.997461742857143">
For the analysis of this section, consider again
the example of Fig.2. The original NFA of
Fig.2a is compact.
The algorithm creates new states and
transitions in the first stage and it deletes states
and transitions in the following stages. The NFA
at the end of Stage 1 (Fig.2b) contains all the
words of the original NFA plus the new word,
but it is not compact.
The compaction is performed in Stages 2-4,
based on the criterion of Lemma 2: Since a non-
compact NFA always contains similar states,
Stages 2-4 find similar states and merge them,
until no more similar states can be found in the
NFA. Then by Lemma 2 the NFA will be
compact. Note that the algorithm does not
search the whole NFA to find similar states. For
every transition (n&apos;,p,c) in the path of the newly
inserted word, starting from the one closest to
the sink (source) and continuing upwards
(downwards), it considers only the states n such
that (n,c)EF,N(o,)(p) and n#n&apos;, and it checks only
them for similarity with n&apos;.
Now consider the dashed (marked)
transitions of Fig.2b. The algorithm keeps track
of them. They form a succession that
corresponds to the new word. Let Z be the set of
states contained in that succession, excluding
source and sink. Then Z contains all the new
states created by the process. ,f any state n&apos; in Z
is found similar to some other state, state n&apos; is
deleted from Z.
Following are some interesting lemmas
concerning properties of acyclic NFAs. The last
one proves the correctness of the algorithm.
</bodyText>
<construct confidence="0.9602335">
Lemma 3: For every nEZ, IF,(n)I =
IFO,(n)I =L
</construct>
<bodyText confidence="0.99173">
Proof: This property is self-evident at Stage
1 where all states in Z form a succession from
source to sink. During Stages 2 and 3 states and
transitions are deleted from the edges of the
succession only. Therefore the property is
maintained throughout the whole process. ❑
</bodyText>
<construct confidence="0.68650175">
Lemma 4: (a) There is only one state nEZ
such that exists (p,n,c) with pEQ-Z. (b) There is
only one state nEZ such that exists (n,q,c) with
qEQ-Z.
</construct>
<bodyText confidence="0.924575625">
Proof: (a) Suppose there are n,mEZ and
pEQ-Z such that both (p,n,c) and (p,m,d) exist.
But since n and m belong to the same
succession, one must be successor of the other.
Let m the successor and n the predecessor. Then
there should also exist a transition (k,m,e) where
kEZ. That implies IF,N(n)1&gt;1, contradicting to
Lemma 3. (b) Symmetrical to (a). ❑
</bodyText>
<figureCaption confidence="0.573344666666667">
Figure 3. Test results and comparison with minimal DFA.
Lemma S: There are no equivalent states in
Z.
</figureCaption>
<bodyText confidence="0.935191222222222">
Proof: Suppose there are two equivalent
states in Z. Then by Lemma 1 there are two
similar states in Z. Let p,qEZ be these states.
Then there are either two transitions (n,p,c)
(n,q,c) or two transitions (p,n,c) (q,n,c). In either
case n cannot belong to Z due to Lemma 3.
Therefore nEQ-Z and by Lemma 4, p and q
cannot both belong to Z. ❑
Lemma 6: There are no equivalent states in
the set Q-Z.
Proof: Suppose there are two equivalent
states in Q-Z. Then, by Lemma 1 we can find
two similar states p,qEQ-Z. Since they are
similar they should be directly linked to at least
one state n. By Lemma 3 n cannot belong to Z.
It should belong to Q-Z. But in that case the
original NFA also contains p, q and n and thus it
could not be compact. ❑
</bodyText>
<figureCaption confidence="0.339307">
Lemma 7: Every state in Z has at most one
equivalent state.
</figureCaption>
<bodyText confidence="0.9930248">
Proof: Let nEZ, p,qEQ such that n is
equivalent to both p and q. By Lemma 5, neither
p nor q can belong to Z, since nEZ. Thus they
must both belong to Q-Z. But since p and q are
also equivalent, this contradicts Lemma 6. ❑
</bodyText>
<figureCaption confidence="0.527137666666667">
Lemma 8: If we use the described algorithm
to add a new word to a compact acyclic NFA,
then the updated NFA is also compact.
</figureCaption>
<bodyText confidence="0.999744666666667">
Proof: Suppose that after the end of Stage 4
the updated NFA is not compact. Then by
Lemma 2 there should be two similar states in
Q. Let us examine in what sets these two states
can belong to: By Lemma 5 they cannot both
belong to Z. By Lemma 6 then cannot both
belong to Q-Z. Therefore one must belong to Z
and the other to Q-Z. But since the process has
been completed, Stages 2 and 3 have already
checked Z for similar states. Therefore it is not
possible to find two similar (or equivalent) states
in Q. Thus the updated NFA is compact. ❑
</bodyText>
<sectionHeader confidence="0.988861" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.985967193548387">
The described algorithm has been tested using a
lexicon of 230,000 Greek words in random
order. The average word length in the lexicon
was 9.5 characters; the size of the alphabet was
36. The number of states, transitions and the
construction time were measured. The results
are shown in Fig.3. The thick lines refer to the
NFA; the thin lines refer to the corresponding
minimal DFA. For the construction of the
minimal DFA an incremental algorithm was
2
used (Sgarbas et al., 2000a) with O(n ) time
performance. The test was performed on a 200
MHz PC.
Figures 3a, 3b and 3c display respectively the
number of states, the number of transitions and
the construction time of the automaton, in
respect to the size of the lexicon (number of
words). It is evident that the compact NFA
constructed by the proposed algorithm had much
fewer states than the corresponding minimal
DFA and its construction time was notably
short. However, for lexicon size grater than
130,000 words, the algorithm was less efficient
concerning the number of transitions (see
Fig.3b).
The same results are also shown in
logarithmic scales in Figs.3d, 3e and 3f,
respectively. The slopes of the lines indicate
linear growth of transitions, less than linear
growth of states and time complexity between
</bodyText>
<page confidence="0.394044">
2
</page>
<note confidence="0.416092">
O(n) and O(n ).
</note>
<figureCaption confidence="0.981446">
Figure 4. Insertion order affects NFA size.
</figureCaption>
<sectionHeader confidence="0.998514" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99997084375">
We have presented an algorithm for adding
words (strings) in acyclic NFAs and proved its
compact behavior, i.e. if this algorithm is
applied to a compact acyclic NFA, then the
resulting NFA will also be compact. This
algorithm provides an efficient and elegant way
to update acyclic NFAs without having to build
them from scratch. In experiments with Greek
lexicons, compact NFAs constructed by the
described algorithm typically required
significantly less states than the corresponding
minimal DFAs and about the same number of
transitions, while their construction time was
short enough to be used for on-line updates of
lexicons. However, the proposed algorithm
produces compact, but not necessarily minimal
NFAs, because the order of the inserted words
affects the size of the automaton. To illustrate
this, consider Fig.4. Both NFAs of Fig.4
represent the same lexicon and they have both
been produced by the described algorithm.
However, in the case of Fig.4a the words were
inserted in the order: [in, it, at, on], while in the
case of Fig.4b the words were inserted in the
order: [in, on, at, it]. Evidently, both NFAs are
compact, but only the one of Fig.4b is minimal.
Apart from its theoretic interest, this
algorithm has direct practical uses. On-line word
insertion is highly desirable in every application
where the data need to be updated regularly (e.g.
spell-checkers) and the size of the structure is
important.
</bodyText>
<sectionHeader confidence="0.994577" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999586916666667">
The work presented in this paper was part of the
R&amp;D project DELOS (EPET-II, 98 -12),
funded by the Greek Ministry of Development,
General Secretariat of Research and
Technology.
The authors would like to thank the members
of FSA-Research@yahoogroups.com, especially
Gertjan van Noord, Mark-Jan Nederhof, Jan
Daciuk, Dale Gerdemann and Bruce Watson for
their discussions on NFA minimization and
Burak Emir for his help on porting the AMoRE
program to Linux.
</bodyText>
<sectionHeader confidence="0.998478" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993554727272727">
J. Aoe, K. Morimoto and M. Hase. 1993. An
Algorithm for Compressing Common Suffixes
Used in Trie Structures. Systems and Computers in
Japan, 24(12):31-42 (Translated from Trans.
IEICE, J75-D-II(4):770-779, 1992).
A. Arnold, A. Dicky, M. Nivat. 1992. A Note About
Minimal Non-deterministic Automata. Bulletin of
the EATCS, 47:166-169.
A. Blumer, D. Haussler, and A. Ehrenfeucht. 1989.
Average Sizes of Suffix Trees and DAWGs.
Discrete Applied Mathematics, 24:37-45.
</reference>
<figure confidence="0.809283222222222">
5 states
7 transitions
(a)
4 states
6 transitions
(b)
o a
o
n
a
n
i
i
i
t
t
n
t
</figure>
<reference confidence="0.999424206896552">
M. Ciura and S. Deorowicz. 1999. Experimental
Study of Finite Automata Storing Static Lexicons.
Report BW-453/RAu-2/99 (Also at http://www-
zo.iinf.polsl.gliwice.pl/-sdeor/pub.htm).
M. Crochemore and R. Verin. 1997. Direct
Construction of Compact Directed Acyclic Word
th
Graphs. 8 Annual Symposium, CPM 97, Aarhus,
Denmark, 116-129.
J. Daciuk, S. Mihov, B. Watson and R. Watson.
2000. Incremental Construction of Minimal
Acyclic Finite State Automata. Computational
Linguistics, 26(1):3-16.
J. Daciuk, R.E. Watson and B.W. Watson. 1998.
Incremental Construction of Acyclic Finite-State
Automata and Transducers. Proceedings of Finite
State Methods in Natural Language Processing,
Bilkent University, Ankara, Turkey.
J. E. Hopcroft and J. D. Ullman. 1979. Introduction
to Automata Theory, Languages, and
Computation. Addison-Wesley, USA.
T. Kameda, P. Weiner. 1970. On the State
Minimization of Nondeterministic Finite
Automata. IEEE Trans. Comp., C-19:617-627.
J. Kim. 1974. State Minimization on
Nondeterministic Machines. IBM T. J. Watson
Res. Center, Rep. RC 4896.
R. Lacouture and R. De Mori. 1991. Lexical Tree
nd
Compression. EuroSpeech &apos;91, 2 European
Conference on Speech Communications and
Techniques, Genova, Italy, 581-584.
O. Matz, A. Miller, A. Potthoff, W. Thomas and E.
Valkema. 1995. Report on the Program AMoRE.
Bericht 9507, Institut fur Informatik und
Praktische Mathematik, Christian-Albrechts-
Universitat zu Kiel (Also at ftp://ftp.informatik.
uni-kiel.de/pub/kiel/amore).
O. Matz and A. Potthoff. 1995. Computing Small
Nondeterministic Finite Automata. Proc.
Workshop on Tools and Algorithms for the
Construction and Analysis of Systems, Dept. of
CS, Univ. of Aarhus, 74-88.
S. Mihov. 1998. Direct Construction of Minimal
Acyclic Finite States Automata. Annuaire de l&apos;
Universite de Sofia &apos;St. Kl. Ohridski&apos;, Faculte de
Mathematique et Informatique, Sofia, Bulgaria,
92(2).
K. Park, J. Aoe, K. Morimoto and M. Shishibori.
1994. An Algorithm for Dynamic Processing of
DAWG&apos;s. International Journal of Computer
Mathematics, Gordon and Breach Publishers SA,
OPA Amsterdam BV, 54:155-173.
D. Perrin. 1990. Finite Automata. In: J. van
Leeuwen, ed., Handbook of Theoretical Computer
Science, Elsevier, Amsterdam, Vol. A, 3-57.
D. Revuz. 1992. Minimization of Acyclic
Deterministic Automata in Linear Time.
Theoretical Computer Science, Elsevier 92:181-
189.
D. Revuz. 2000. Dynamic Acyclic Minimal
th
Automaton. CIAA 2000, 5 International
Conference on Implementation and Application of
Automata, London, Canada pp.226-232.
K. Sgarbas, N. Fakotakis and G. Kokkinakis. 1995.
Two Algorithms for Incremental Construction of
Directed Acyclic Word Graphs. International
Journal on Artificial Intelligence Tools, World
Scientific, 4(3):369-381.
K. Sgarbas, N. Fakotakis and G. Kokkinakis. 2000a.
Optimal Insertion in Deterministic DAWGs.
Technical Report WCL/SLT#000524, Wire
Communications Lab., Dept. of Electrical and
Computer Engineering, University of Patras,
Greece (Also at http://slt.wcl.ee.upatras.gr/
sgarbas/PublAbsEN.htm).
K. Sgarbas, N. Fakotakis and G. Kokkinakis. 2000b.
A Straightforward Approach to Morphological
Analysis and Synthesis. Proc. COMLEX 2000,
Workshop on Computational Lexicography and
Multimedia Dictionaries, Kato Achaia, Greece,
31-34.
B. Watson. 1993. A Taxonomy of Finite Automata
Minimization Algorithms. Computer Science Note
93/44, Eindhoven University of Technology, The
Netherlands (Also at http://www.OpenFIRE.org).
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.510775">
<title confidence="0.999239">Incremental Construction of Compact Acyclic NFAs</title>
<author confidence="0.997119">Kyriakos N Sgarbas</author>
<author confidence="0.997119">Nikos D Fakotakis</author>
<author confidence="0.997119">George K Kokkinakis</author>
<affiliation confidence="0.841487333333333">Wire Communications Laboratory Electrical and Computer Engineering Department University of Patras, GR-26500 Rio, Greece</affiliation>
<email confidence="0.986995">sgarbas@wcl.ee.upatras.gr</email>
<email confidence="0.986995">fakotaki@wcl.ee.upatras.gr</email>
<email confidence="0.986995">gkokkin@wcl.ee.upatras.gr</email>
<abstract confidence="0.9994646875">This paper presents and analyzes an incremental algorithm for the construction of Acyclic Nondeterministic Finite-state Automata (NFA). Automata of this type are quite useful in computational linguistics, especially for storing lexicons. The proposed algorithm produces compact NFAs, i.e. NFAs that do not contain equivalent states. Unlike Deterministic Finite-state Automata (DFA), this property is not sufficient to ensure minimality, but still the resulting NFAs are considerably smaller than the minimal DFAs for the same languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Aoe</author>
<author>K Morimoto</author>
<author>M Hase</author>
</authors>
<title>An Algorithm for Compressing Common Suffixes Used</title>
<date>1993</date>
<booktitle>in Trie Structures. Systems and Computers in Japan, 24(12):31-42 (Translated from Trans. IEICE,</booktitle>
<pages>75--4</pages>
<contexts>
<context position="3099" citStr="Aoe et al., 1993" startWordPosition="483" endWordPosition="486">s but they are a little slower to search. DFAs are more popular for lexicon representation, especially the minimal ones, i.e. DFAs with the least number of states. Several algorithms are known for the construction of the minimal DFA, given a set of words (Hopcroft Deterministic Finite-State Non-Deterministic Automaton (DFA) Finite-State Automaton (NFA) (a) (b) Figure 1. The same lexicon in DFA and NFA. d S m a r t n t a � r S e t � � d S n � a r d t a m t r S t e and Ullman, 1979; Perrin, 199o; Revuz, 1992; Watson, 1993). Recently, some incremental algorithms have been proposed for this task (Aoe et al., 1993; Park et al., 1994; Sgarbas et al., 1995; Daciuk et al., 1998; Mihov, 1998; Ciura and Deorowicz, 1999; Daciuk et al., 2ooo; Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental algorithms are useful because they can update the lexicon without rebuilding the whole structure from scratch. 2 For minimal NFAs there are also some (nonincremental) algorithms (Kameda and Weiner, 197o; Kim, 1974; Arnold et al., 1992; Matz and Potthoff, 1995) but unlike DFAs, there is no single minimal NFA for a given language. In this paper we present an incremental algorithm for constructing Acyclic NFAs. We consider NF</context>
</contexts>
<marker>Aoe, Morimoto, Hase, 1993</marker>
<rawString>J. Aoe, K. Morimoto and M. Hase. 1993. An Algorithm for Compressing Common Suffixes Used in Trie Structures. Systems and Computers in Japan, 24(12):31-42 (Translated from Trans. IEICE, J75-D-II(4):770-779, 1992).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Arnold</author>
<author>A Dicky</author>
<author>M Nivat</author>
</authors>
<title>A Note About Minimal Non-deterministic Automata.</title>
<date>1992</date>
<journal>Bulletin of the EATCS,</journal>
<pages>47--166</pages>
<contexts>
<context position="3507" citStr="Arnold et al., 1992" startWordPosition="549" endWordPosition="552"> d S m a r t n t a � r S e t � � d S n � a r d t a m t r S t e and Ullman, 1979; Perrin, 199o; Revuz, 1992; Watson, 1993). Recently, some incremental algorithms have been proposed for this task (Aoe et al., 1993; Park et al., 1994; Sgarbas et al., 1995; Daciuk et al., 1998; Mihov, 1998; Ciura and Deorowicz, 1999; Daciuk et al., 2ooo; Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental algorithms are useful because they can update the lexicon without rebuilding the whole structure from scratch. 2 For minimal NFAs there are also some (nonincremental) algorithms (Kameda and Weiner, 197o; Kim, 1974; Arnold et al., 1992; Matz and Potthoff, 1995) but unlike DFAs, there is no single minimal NFA for a given language. In this paper we present an incremental algorithm for constructing Acyclic NFAs. We consider NFAs with one source and one sink state, like the one in Fig.1b, because this facilitates bi-directional search in the graph. We introduce the notion of a compact automaton 3 (i.e. one with no equivalent states) and we prove that the presented algorithm produces compact NFAs. We also show that (unlike DFAs) a compact NFA is not necessarily minimal. Therefore the algorithm does not always produce minimal acy</context>
</contexts>
<marker>Arnold, Dicky, Nivat, 1992</marker>
<rawString>A. Arnold, A. Dicky, M. Nivat. 1992. A Note About Minimal Non-deterministic Automata. Bulletin of the EATCS, 47:166-169.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blumer</author>
<author>D Haussler</author>
<author>A Ehrenfeucht</author>
</authors>
<title>Average Sizes of Suffix Trees and DAWGs.</title>
<date>1989</date>
<journal>Discrete Applied Mathematics,</journal>
<pages>24--37</pages>
<contexts>
<context position="5067" citStr="Blumer et al. (1989)" startWordPosition="804" endWordPosition="807">re given that will be used throughout the paper. We have tried to define appropriate concepts that simplify the proofs of the lemmas. The presentation of the algorithm follows in Section 3 with a step-by-step example. In Section 4, a set of interesting lemmas is provided, resulting to a proof that the algorithm actually produces compact NFAs. Experimental results are presented in Section 5. The paper conclusions follow in Section 6. 2For more information, see http://odur.let.rug.nl/alfa/ fsa_stuff/ 3Not to be confused with the notion of compact DAWGs as defined by Crochemore and Verin (1997), Blumer et al. (1989), where whole strings are allowed as labels on transitions. 2 Definitions Let Q be a set of states (vertices) and be a set of symbols (alphabet). A labeled directed transition is then defined as a triple (n1,n2,s) from state n1 to n2 with label s, where n1,n2»Q and s» . Let LºQ¤Q¤ be a set of labeled directed transitions. Then an ordered series [(no,n1,s1), (n1,n2,s2), (n2,n3,s3), ....., (nk-2,nk-1,sk-1), (nk-1, nk,sk)] of successive transitions of L is called a succession from state no to state nk and is denoted by succ(no,nk). We say that state nk is a successor of state no and that state no</context>
</contexts>
<marker>Blumer, Haussler, Ehrenfeucht, 1989</marker>
<rawString>A. Blumer, D. Haussler, and A. Ehrenfeucht. 1989. Average Sizes of Suffix Trees and DAWGs. Discrete Applied Mathematics, 24:37-45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ciura</author>
<author>S Deorowicz</author>
</authors>
<title>Experimental Study of Finite Automata Storing Static Lexicons. Report BW-453/RAu-2/99 (Also at http://wwwzo.iinf.polsl.gliwice.pl/-sdeor/pub.htm).</title>
<date>1999</date>
<contexts>
<context position="3201" citStr="Ciura and Deorowicz, 1999" startWordPosition="501" endWordPosition="504">specially the minimal ones, i.e. DFAs with the least number of states. Several algorithms are known for the construction of the minimal DFA, given a set of words (Hopcroft Deterministic Finite-State Non-Deterministic Automaton (DFA) Finite-State Automaton (NFA) (a) (b) Figure 1. The same lexicon in DFA and NFA. d S m a r t n t a � r S e t � � d S n � a r d t a m t r S t e and Ullman, 1979; Perrin, 199o; Revuz, 1992; Watson, 1993). Recently, some incremental algorithms have been proposed for this task (Aoe et al., 1993; Park et al., 1994; Sgarbas et al., 1995; Daciuk et al., 1998; Mihov, 1998; Ciura and Deorowicz, 1999; Daciuk et al., 2ooo; Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental algorithms are useful because they can update the lexicon without rebuilding the whole structure from scratch. 2 For minimal NFAs there are also some (nonincremental) algorithms (Kameda and Weiner, 197o; Kim, 1974; Arnold et al., 1992; Matz and Potthoff, 1995) but unlike DFAs, there is no single minimal NFA for a given language. In this paper we present an incremental algorithm for constructing Acyclic NFAs. We consider NFAs with one source and one sink state, like the one in Fig.1b, because this facilitates bi-directional</context>
</contexts>
<marker>Ciura, Deorowicz, 1999</marker>
<rawString>M. Ciura and S. Deorowicz. 1999. Experimental Study of Finite Automata Storing Static Lexicons. Report BW-453/RAu-2/99 (Also at http://wwwzo.iinf.polsl.gliwice.pl/-sdeor/pub.htm).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Crochemore</author>
<author>R Verin</author>
</authors>
<date>1997</date>
<booktitle>Direct Construction of Compact Directed Acyclic Word th Graphs. 8 Annual Symposium, CPM 97,</booktitle>
<pages>116--129</pages>
<location>Aarhus,</location>
<contexts>
<context position="1567" citStr="Crochemore and Verin, 1997" startWordPosition="210" endWordPosition="213">on and fast string matching, with a great variety of applications in lexicon building (Daciuk et al., 2000), morphological processing (Sgarbas et al., 2000b) and speech processing (Lacouture and De Mori, 1991). They constitute very compact representations of lexicons, since common word prefixes and suffixes are represented by the same transitions. This representation also facilitates contentaddressable pattern matching. 1 Some authors (e.g. Perrin, 1990; Aoe et al. 1992; Sgarbas et al., 1995) use the term DAWG (Directed Acyclic Word Graph) when referring to acyclic FSAs. However, others (e.g. Crochemore and Verin, 1997) use the same term to denote the suffix automaton of a string. Examples of acyclic FSAs storing lexicons are shown in Fig.1. The FSAs consist of states and transitions between states. Each transition has a label. The words are stored as directed paths on the graph. They can be retrieved by traversing the graph from an initial state (source) to a terminal state (sink), collecting the labels of the transitions encountered. In this way, traversing the graphs of Fig.1 from the source (0) to the sink (0) we retrieve the words dance, darts, dart, start and smart. There are two types of FSAs. The gra</context>
<context position="5045" citStr="Crochemore and Verin (1997)" startWordPosition="800" endWordPosition="803">aper some basic definitions are given that will be used throughout the paper. We have tried to define appropriate concepts that simplify the proofs of the lemmas. The presentation of the algorithm follows in Section 3 with a step-by-step example. In Section 4, a set of interesting lemmas is provided, resulting to a proof that the algorithm actually produces compact NFAs. Experimental results are presented in Section 5. The paper conclusions follow in Section 6. 2For more information, see http://odur.let.rug.nl/alfa/ fsa_stuff/ 3Not to be confused with the notion of compact DAWGs as defined by Crochemore and Verin (1997), Blumer et al. (1989), where whole strings are allowed as labels on transitions. 2 Definitions Let Q be a set of states (vertices) and be a set of symbols (alphabet). A labeled directed transition is then defined as a triple (n1,n2,s) from state n1 to n2 with label s, where n1,n2»Q and s» . Let LºQ¤Q¤ be a set of labeled directed transitions. Then an ordered series [(no,n1,s1), (n1,n2,s2), (n2,n3,s3), ....., (nk-2,nk-1,sk-1), (nk-1, nk,sk)] of successive transitions of L is called a succession from state no to state nk and is denoted by succ(no,nk). We say that state nk is a successor of stat</context>
</contexts>
<marker>Crochemore, Verin, 1997</marker>
<rawString>M. Crochemore and R. Verin. 1997. Direct Construction of Compact Directed Acyclic Word th Graphs. 8 Annual Symposium, CPM 97, Aarhus, Denmark, 116-129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Daciuk</author>
<author>S Mihov</author>
<author>B Watson</author>
<author>R Watson</author>
</authors>
<date>2000</date>
<booktitle>Incremental Construction of Minimal Acyclic Finite State Automata. Computational Linguistics,</booktitle>
<pages>26--1</pages>
<contexts>
<context position="1047" citStr="Daciuk et al., 2000" startWordPosition="135" endWordPosition="138">ata of this type are quite useful in computational linguistics, especially for storing lexicons. The proposed algorithm produces compact NFAs, i.e. NFAs that do not contain equivalent states. Unlike Deterministic Finite-state Automata (DFA), this property is not sufficient to ensure minimality, but still the resulting NFAs are considerably smaller than the minimal DFAs for the same languages. 1 Introduction 1 Acyclic Finite-State Automata (FSA) provide a very efficient data structure for lexicon representation and fast string matching, with a great variety of applications in lexicon building (Daciuk et al., 2000), morphological processing (Sgarbas et al., 2000b) and speech processing (Lacouture and De Mori, 1991). They constitute very compact representations of lexicons, since common word prefixes and suffixes are represented by the same transitions. This representation also facilitates contentaddressable pattern matching. 1 Some authors (e.g. Perrin, 1990; Aoe et al. 1992; Sgarbas et al., 1995) use the term DAWG (Directed Acyclic Word Graph) when referring to acyclic FSAs. However, others (e.g. Crochemore and Verin, 1997) use the same term to denote the suffix automaton of a string. Examples of acycl</context>
</contexts>
<marker>Daciuk, Mihov, Watson, Watson, 2000</marker>
<rawString>J. Daciuk, S. Mihov, B. Watson and R. Watson. 2000. Incremental Construction of Minimal Acyclic Finite State Automata. Computational Linguistics, 26(1):3-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Daciuk</author>
<author>R E Watson</author>
<author>B W Watson</author>
</authors>
<title>Incremental Construction of Acyclic Finite-State Automata and Transducers.</title>
<date>1998</date>
<booktitle>Proceedings of Finite State Methods in Natural Language Processing,</booktitle>
<institution>Bilkent University,</institution>
<location>Ankara, Turkey.</location>
<contexts>
<context position="3161" citStr="Daciuk et al., 1998" startWordPosition="495" endWordPosition="498">ular for lexicon representation, especially the minimal ones, i.e. DFAs with the least number of states. Several algorithms are known for the construction of the minimal DFA, given a set of words (Hopcroft Deterministic Finite-State Non-Deterministic Automaton (DFA) Finite-State Automaton (NFA) (a) (b) Figure 1. The same lexicon in DFA and NFA. d S m a r t n t a � r S e t � � d S n � a r d t a m t r S t e and Ullman, 1979; Perrin, 199o; Revuz, 1992; Watson, 1993). Recently, some incremental algorithms have been proposed for this task (Aoe et al., 1993; Park et al., 1994; Sgarbas et al., 1995; Daciuk et al., 1998; Mihov, 1998; Ciura and Deorowicz, 1999; Daciuk et al., 2ooo; Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental algorithms are useful because they can update the lexicon without rebuilding the whole structure from scratch. 2 For minimal NFAs there are also some (nonincremental) algorithms (Kameda and Weiner, 197o; Kim, 1974; Arnold et al., 1992; Matz and Potthoff, 1995) but unlike DFAs, there is no single minimal NFA for a given language. In this paper we present an incremental algorithm for constructing Acyclic NFAs. We consider NFAs with one source and one sink state, like the one in Fig.1b,</context>
</contexts>
<marker>Daciuk, Watson, Watson, 1998</marker>
<rawString>J. Daciuk, R.E. Watson and B.W. Watson. 1998. Incremental Construction of Acyclic Finite-State Automata and Transducers. Proceedings of Finite State Methods in Natural Language Processing, Bilkent University, Ankara, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Hopcroft</author>
<author>J D Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages, and Computation.</title>
<date>1979</date>
<publisher>Addison-Wesley, USA.</publisher>
<marker>Hopcroft, Ullman, 1979</marker>
<rawString>J. E. Hopcroft and J. D. Ullman. 1979. Introduction to Automata Theory, Languages, and Computation. Addison-Wesley, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kameda</author>
<author>P Weiner</author>
</authors>
<title>On the State Minimization of Nondeterministic Finite Automata.</title>
<date>1970</date>
<journal>IEEE Trans. Comp.,</journal>
<pages>19--617</pages>
<marker>Kameda, Weiner, 1970</marker>
<rawString>T. Kameda, P. Weiner. 1970. On the State Minimization of Nondeterministic Finite Automata. IEEE Trans. Comp., C-19:617-627.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kim</author>
</authors>
<title>State Minimization on Nondeterministic Machines.</title>
<date>1974</date>
<journal>IBM T. J. Watson Res. Center, Rep. RC</journal>
<pages>4896</pages>
<contexts>
<context position="3486" citStr="Kim, 1974" startWordPosition="547" endWordPosition="548">FA and NFA. d S m a r t n t a � r S e t � � d S n � a r d t a m t r S t e and Ullman, 1979; Perrin, 199o; Revuz, 1992; Watson, 1993). Recently, some incremental algorithms have been proposed for this task (Aoe et al., 1993; Park et al., 1994; Sgarbas et al., 1995; Daciuk et al., 1998; Mihov, 1998; Ciura and Deorowicz, 1999; Daciuk et al., 2ooo; Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental algorithms are useful because they can update the lexicon without rebuilding the whole structure from scratch. 2 For minimal NFAs there are also some (nonincremental) algorithms (Kameda and Weiner, 197o; Kim, 1974; Arnold et al., 1992; Matz and Potthoff, 1995) but unlike DFAs, there is no single minimal NFA for a given language. In this paper we present an incremental algorithm for constructing Acyclic NFAs. We consider NFAs with one source and one sink state, like the one in Fig.1b, because this facilitates bi-directional search in the graph. We introduce the notion of a compact automaton 3 (i.e. one with no equivalent states) and we prove that the presented algorithm produces compact NFAs. We also show that (unlike DFAs) a compact NFA is not necessarily minimal. Therefore the algorithm does not alway</context>
</contexts>
<marker>Kim, 1974</marker>
<rawString>J. Kim. 1974. State Minimization on Nondeterministic Machines. IBM T. J. Watson Res. Center, Rep. RC 4896.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Lacouture</author>
<author>R De Mori</author>
</authors>
<date>1991</date>
<booktitle>Lexical Tree nd Compression. EuroSpeech &apos;91, 2 European Conference on Speech Communications and Techniques,</booktitle>
<pages>581--584</pages>
<location>Genova, Italy,</location>
<marker>Lacouture, De Mori, 1991</marker>
<rawString>R. Lacouture and R. De Mori. 1991. Lexical Tree nd Compression. EuroSpeech &apos;91, 2 European Conference on Speech Communications and Techniques, Genova, Italy, 581-584.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Matz</author>
<author>A Miller</author>
<author>A Potthoff</author>
<author>W Thomas</author>
<author>E Valkema</author>
</authors>
<date>1995</date>
<booktitle>Report on the Program AMoRE. Bericht 9507, Institut fur Informatik und Praktische Mathematik, Christian-AlbrechtsUniversitat zu Kiel (Also</booktitle>
<marker>Matz, Miller, Potthoff, Thomas, Valkema, 1995</marker>
<rawString>O. Matz, A. Miller, A. Potthoff, W. Thomas and E. Valkema. 1995. Report on the Program AMoRE. Bericht 9507, Institut fur Informatik und Praktische Mathematik, Christian-AlbrechtsUniversitat zu Kiel (Also at ftp://ftp.informatik. uni-kiel.de/pub/kiel/amore).</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Matz</author>
<author>A Potthoff</author>
</authors>
<title>Computing Small Nondeterministic Finite Automata.</title>
<date>1995</date>
<booktitle>Proc. Workshop on Tools and Algorithms for the Construction and Analysis of Systems, Dept. of CS, Univ. of Aarhus,</booktitle>
<pages>74--88</pages>
<contexts>
<context position="3533" citStr="Matz and Potthoff, 1995" startWordPosition="553" endWordPosition="556">r S e t � � d S n � a r d t a m t r S t e and Ullman, 1979; Perrin, 199o; Revuz, 1992; Watson, 1993). Recently, some incremental algorithms have been proposed for this task (Aoe et al., 1993; Park et al., 1994; Sgarbas et al., 1995; Daciuk et al., 1998; Mihov, 1998; Ciura and Deorowicz, 1999; Daciuk et al., 2ooo; Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental algorithms are useful because they can update the lexicon without rebuilding the whole structure from scratch. 2 For minimal NFAs there are also some (nonincremental) algorithms (Kameda and Weiner, 197o; Kim, 1974; Arnold et al., 1992; Matz and Potthoff, 1995) but unlike DFAs, there is no single minimal NFA for a given language. In this paper we present an incremental algorithm for constructing Acyclic NFAs. We consider NFAs with one source and one sink state, like the one in Fig.1b, because this facilitates bi-directional search in the graph. We introduce the notion of a compact automaton 3 (i.e. one with no equivalent states) and we prove that the presented algorithm produces compact NFAs. We also show that (unlike DFAs) a compact NFA is not necessarily minimal. Therefore the algorithm does not always produce minimal acyclic NFAs; the size of the</context>
</contexts>
<marker>Matz, Potthoff, 1995</marker>
<rawString>O. Matz and A. Potthoff. 1995. Computing Small Nondeterministic Finite Automata. Proc. Workshop on Tools and Algorithms for the Construction and Analysis of Systems, Dept. of CS, Univ. of Aarhus, 74-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Mihov</author>
</authors>
<title>Direct Construction of Minimal Acyclic Finite States Automata. Annuaire de l&apos;</title>
<date>1998</date>
<booktitle>Universite de Sofia &apos;St. Kl. Ohridski&apos;, Faculte de Mathematique et Informatique,</booktitle>
<location>Sofia, Bulgaria, 92(2).</location>
<contexts>
<context position="3174" citStr="Mihov, 1998" startWordPosition="499" endWordPosition="500">esentation, especially the minimal ones, i.e. DFAs with the least number of states. Several algorithms are known for the construction of the minimal DFA, given a set of words (Hopcroft Deterministic Finite-State Non-Deterministic Automaton (DFA) Finite-State Automaton (NFA) (a) (b) Figure 1. The same lexicon in DFA and NFA. d S m a r t n t a � r S e t � � d S n � a r d t a m t r S t e and Ullman, 1979; Perrin, 199o; Revuz, 1992; Watson, 1993). Recently, some incremental algorithms have been proposed for this task (Aoe et al., 1993; Park et al., 1994; Sgarbas et al., 1995; Daciuk et al., 1998; Mihov, 1998; Ciura and Deorowicz, 1999; Daciuk et al., 2ooo; Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental algorithms are useful because they can update the lexicon without rebuilding the whole structure from scratch. 2 For minimal NFAs there are also some (nonincremental) algorithms (Kameda and Weiner, 197o; Kim, 1974; Arnold et al., 1992; Matz and Potthoff, 1995) but unlike DFAs, there is no single minimal NFA for a given language. In this paper we present an incremental algorithm for constructing Acyclic NFAs. We consider NFAs with one source and one sink state, like the one in Fig.1b, because this</context>
</contexts>
<marker>Mihov, 1998</marker>
<rawString>S. Mihov. 1998. Direct Construction of Minimal Acyclic Finite States Automata. Annuaire de l&apos; Universite de Sofia &apos;St. Kl. Ohridski&apos;, Faculte de Mathematique et Informatique, Sofia, Bulgaria, 92(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Park</author>
<author>J Aoe</author>
<author>K Morimoto</author>
<author>M Shishibori</author>
</authors>
<title>An Algorithm for Dynamic Processing of DAWG&apos;s.</title>
<date>1994</date>
<journal>International Journal of Computer Mathematics, Gordon and Breach Publishers SA, OPA Amsterdam BV,</journal>
<pages>54--155</pages>
<contexts>
<context position="3118" citStr="Park et al., 1994" startWordPosition="487" endWordPosition="490">ittle slower to search. DFAs are more popular for lexicon representation, especially the minimal ones, i.e. DFAs with the least number of states. Several algorithms are known for the construction of the minimal DFA, given a set of words (Hopcroft Deterministic Finite-State Non-Deterministic Automaton (DFA) Finite-State Automaton (NFA) (a) (b) Figure 1. The same lexicon in DFA and NFA. d S m a r t n t a � r S e t � � d S n � a r d t a m t r S t e and Ullman, 1979; Perrin, 199o; Revuz, 1992; Watson, 1993). Recently, some incremental algorithms have been proposed for this task (Aoe et al., 1993; Park et al., 1994; Sgarbas et al., 1995; Daciuk et al., 1998; Mihov, 1998; Ciura and Deorowicz, 1999; Daciuk et al., 2ooo; Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental algorithms are useful because they can update the lexicon without rebuilding the whole structure from scratch. 2 For minimal NFAs there are also some (nonincremental) algorithms (Kameda and Weiner, 197o; Kim, 1974; Arnold et al., 1992; Matz and Potthoff, 1995) but unlike DFAs, there is no single minimal NFA for a given language. In this paper we present an incremental algorithm for constructing Acyclic NFAs. We consider NFAs with one source </context>
</contexts>
<marker>Park, Aoe, Morimoto, Shishibori, 1994</marker>
<rawString>K. Park, J. Aoe, K. Morimoto and M. Shishibori. 1994. An Algorithm for Dynamic Processing of DAWG&apos;s. International Journal of Computer Mathematics, Gordon and Breach Publishers SA, OPA Amsterdam BV, 54:155-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Perrin</author>
</authors>
<title>Finite Automata. In:</title>
<date>1990</date>
<booktitle>Handbook of Theoretical Computer Science, Elsevier,</booktitle>
<pages>3--57</pages>
<editor>J. van Leeuwen, ed.,</editor>
<publisher>A,</publisher>
<location>Amsterdam, Vol.</location>
<contexts>
<context position="1397" citStr="Perrin, 1990" startWordPosition="184" endWordPosition="185"> minimal DFAs for the same languages. 1 Introduction 1 Acyclic Finite-State Automata (FSA) provide a very efficient data structure for lexicon representation and fast string matching, with a great variety of applications in lexicon building (Daciuk et al., 2000), morphological processing (Sgarbas et al., 2000b) and speech processing (Lacouture and De Mori, 1991). They constitute very compact representations of lexicons, since common word prefixes and suffixes are represented by the same transitions. This representation also facilitates contentaddressable pattern matching. 1 Some authors (e.g. Perrin, 1990; Aoe et al. 1992; Sgarbas et al., 1995) use the term DAWG (Directed Acyclic Word Graph) when referring to acyclic FSAs. However, others (e.g. Crochemore and Verin, 1997) use the same term to denote the suffix automaton of a string. Examples of acyclic FSAs storing lexicons are shown in Fig.1. The FSAs consist of states and transitions between states. Each transition has a label. The words are stored as directed paths on the graph. They can be retrieved by traversing the graph from an initial state (source) to a terminal state (sink), collecting the labels of the transitions encountered. In th</context>
</contexts>
<marker>Perrin, 1990</marker>
<rawString>D. Perrin. 1990. Finite Automata. In: J. van Leeuwen, ed., Handbook of Theoretical Computer Science, Elsevier, Amsterdam, Vol. A, 3-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Revuz</author>
</authors>
<title>Minimization of Acyclic Deterministic Automata in Linear Time.</title>
<date>1992</date>
<journal>Theoretical Computer Science, Elsevier</journal>
<pages>92--181</pages>
<contexts>
<context position="2994" citStr="Revuz, 1992" startWordPosition="469" endWordPosition="470">erty, like the one of Fig.1b, are called non-deterministic automata (NFA). NFAs are smaller than DFAs but they are a little slower to search. DFAs are more popular for lexicon representation, especially the minimal ones, i.e. DFAs with the least number of states. Several algorithms are known for the construction of the minimal DFA, given a set of words (Hopcroft Deterministic Finite-State Non-Deterministic Automaton (DFA) Finite-State Automaton (NFA) (a) (b) Figure 1. The same lexicon in DFA and NFA. d S m a r t n t a � r S e t � � d S n � a r d t a m t r S t e and Ullman, 1979; Perrin, 199o; Revuz, 1992; Watson, 1993). Recently, some incremental algorithms have been proposed for this task (Aoe et al., 1993; Park et al., 1994; Sgarbas et al., 1995; Daciuk et al., 1998; Mihov, 1998; Ciura and Deorowicz, 1999; Daciuk et al., 2ooo; Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental algorithms are useful because they can update the lexicon without rebuilding the whole structure from scratch. 2 For minimal NFAs there are also some (nonincremental) algorithms (Kameda and Weiner, 197o; Kim, 1974; Arnold et al., 1992; Matz and Potthoff, 1995) but unlike DFAs, there is no single minimal NFA for a given </context>
</contexts>
<marker>Revuz, 1992</marker>
<rawString>D. Revuz. 1992. Minimization of Acyclic Deterministic Automata in Linear Time. Theoretical Computer Science, Elsevier 92:181-189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Revuz</author>
</authors>
<date>2000</date>
<journal>Dynamic Acyclic Minimal th</journal>
<marker>Revuz, 2000</marker>
<rawString>D. Revuz. 2000. Dynamic Acyclic Minimal th</rawString>
</citation>
<citation valid="false">
<authors>
<author>Automaton</author>
</authors>
<booktitle>CIAA 2000, 5 International Conference on Implementation and Application of Automata,</booktitle>
<pages>226--232</pages>
<location>London, Canada</location>
<marker>Automaton, </marker>
<rawString>Automaton. CIAA 2000, 5 International Conference on Implementation and Application of Automata, London, Canada pp.226-232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sgarbas</author>
<author>N Fakotakis</author>
<author>G Kokkinakis</author>
</authors>
<title>Two Algorithms for Incremental Construction of Directed Acyclic Word Graphs.</title>
<date>1995</date>
<journal>International Journal on Artificial Intelligence Tools, World Scientific,</journal>
<pages>4--3</pages>
<contexts>
<context position="1437" citStr="Sgarbas et al., 1995" startWordPosition="190" endWordPosition="193">uages. 1 Introduction 1 Acyclic Finite-State Automata (FSA) provide a very efficient data structure for lexicon representation and fast string matching, with a great variety of applications in lexicon building (Daciuk et al., 2000), morphological processing (Sgarbas et al., 2000b) and speech processing (Lacouture and De Mori, 1991). They constitute very compact representations of lexicons, since common word prefixes and suffixes are represented by the same transitions. This representation also facilitates contentaddressable pattern matching. 1 Some authors (e.g. Perrin, 1990; Aoe et al. 1992; Sgarbas et al., 1995) use the term DAWG (Directed Acyclic Word Graph) when referring to acyclic FSAs. However, others (e.g. Crochemore and Verin, 1997) use the same term to denote the suffix automaton of a string. Examples of acyclic FSAs storing lexicons are shown in Fig.1. The FSAs consist of states and transitions between states. Each transition has a label. The words are stored as directed paths on the graph. They can be retrieved by traversing the graph from an initial state (source) to a terminal state (sink), collecting the labels of the transitions encountered. In this way, traversing the graphs of Fig.1 f</context>
<context position="3140" citStr="Sgarbas et al., 1995" startWordPosition="491" endWordPosition="494">rch. DFAs are more popular for lexicon representation, especially the minimal ones, i.e. DFAs with the least number of states. Several algorithms are known for the construction of the minimal DFA, given a set of words (Hopcroft Deterministic Finite-State Non-Deterministic Automaton (DFA) Finite-State Automaton (NFA) (a) (b) Figure 1. The same lexicon in DFA and NFA. d S m a r t n t a � r S e t � � d S n � a r d t a m t r S t e and Ullman, 1979; Perrin, 199o; Revuz, 1992; Watson, 1993). Recently, some incremental algorithms have been proposed for this task (Aoe et al., 1993; Park et al., 1994; Sgarbas et al., 1995; Daciuk et al., 1998; Mihov, 1998; Ciura and Deorowicz, 1999; Daciuk et al., 2ooo; Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental algorithms are useful because they can update the lexicon without rebuilding the whole structure from scratch. 2 For minimal NFAs there are also some (nonincremental) algorithms (Kameda and Weiner, 197o; Kim, 1974; Arnold et al., 1992; Matz and Potthoff, 1995) but unlike DFAs, there is no single minimal NFA for a given language. In this paper we present an incremental algorithm for constructing Acyclic NFAs. We consider NFAs with one source and one sink state, li</context>
</contexts>
<marker>Sgarbas, Fakotakis, Kokkinakis, 1995</marker>
<rawString>K. Sgarbas, N. Fakotakis and G. Kokkinakis. 1995. Two Algorithms for Incremental Construction of Directed Acyclic Word Graphs. International Journal on Artificial Intelligence Tools, World Scientific, 4(3):369-381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sgarbas</author>
<author>N Fakotakis</author>
<author>G Kokkinakis</author>
</authors>
<title>Optimal Insertion in Deterministic DAWGs.</title>
<date>2000</date>
<tech>Technical Report WCL/SLT#000524,</tech>
<institution>Wire Communications Lab., Dept. of Electrical and Computer Engineering, University of Patras, Greece</institution>
<note>(Also at http://slt.wcl.ee.upatras.gr/ sgarbas/PublAbsEN.htm).</note>
<contexts>
<context position="1095" citStr="Sgarbas et al., 2000" startWordPosition="141" endWordPosition="144">al linguistics, especially for storing lexicons. The proposed algorithm produces compact NFAs, i.e. NFAs that do not contain equivalent states. Unlike Deterministic Finite-state Automata (DFA), this property is not sufficient to ensure minimality, but still the resulting NFAs are considerably smaller than the minimal DFAs for the same languages. 1 Introduction 1 Acyclic Finite-State Automata (FSA) provide a very efficient data structure for lexicon representation and fast string matching, with a great variety of applications in lexicon building (Daciuk et al., 2000), morphological processing (Sgarbas et al., 2000b) and speech processing (Lacouture and De Mori, 1991). They constitute very compact representations of lexicons, since common word prefixes and suffixes are represented by the same transitions. This representation also facilitates contentaddressable pattern matching. 1 Some authors (e.g. Perrin, 1990; Aoe et al. 1992; Sgarbas et al., 1995) use the term DAWG (Directed Acyclic Word Graph) when referring to acyclic FSAs. However, others (e.g. Crochemore and Verin, 1997) use the same term to denote the suffix automaton of a string. Examples of acyclic FSAs storing lexicons are shown in Fig.1. The</context>
<context position="18532" citStr="Sgarbas et al., 2000" startWordPosition="3204" endWordPosition="3207">s. Therefore it is not possible to find two similar (or equivalent) states in Q. Thus the updated NFA is compact. ❑ 5 Experimental Results The described algorithm has been tested using a lexicon of 230,000 Greek words in random order. The average word length in the lexicon was 9.5 characters; the size of the alphabet was 36. The number of states, transitions and the construction time were measured. The results are shown in Fig.3. The thick lines refer to the NFA; the thin lines refer to the corresponding minimal DFA. For the construction of the minimal DFA an incremental algorithm was 2 used (Sgarbas et al., 2000a) with O(n ) time performance. The test was performed on a 200 MHz PC. Figures 3a, 3b and 3c display respectively the number of states, the number of transitions and the construction time of the automaton, in respect to the size of the lexicon (number of words). It is evident that the compact NFA constructed by the proposed algorithm had much fewer states than the corresponding minimal DFA and its construction time was notably short. However, for lexicon size grater than 130,000 words, the algorithm was less efficient concerning the number of transitions (see Fig.3b). The same results are als</context>
</contexts>
<marker>Sgarbas, Fakotakis, Kokkinakis, 2000</marker>
<rawString>K. Sgarbas, N. Fakotakis and G. Kokkinakis. 2000a. Optimal Insertion in Deterministic DAWGs. Technical Report WCL/SLT#000524, Wire Communications Lab., Dept. of Electrical and Computer Engineering, University of Patras, Greece (Also at http://slt.wcl.ee.upatras.gr/ sgarbas/PublAbsEN.htm).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sgarbas</author>
<author>N Fakotakis</author>
<author>G Kokkinakis</author>
</authors>
<title>A Straightforward Approach to Morphological Analysis and Synthesis.</title>
<date>2000</date>
<booktitle>Proc. COMLEX 2000, Workshop on Computational Lexicography and Multimedia Dictionaries, Kato Achaia, Greece,</booktitle>
<pages>31--34</pages>
<contexts>
<context position="1095" citStr="Sgarbas et al., 2000" startWordPosition="141" endWordPosition="144">al linguistics, especially for storing lexicons. The proposed algorithm produces compact NFAs, i.e. NFAs that do not contain equivalent states. Unlike Deterministic Finite-state Automata (DFA), this property is not sufficient to ensure minimality, but still the resulting NFAs are considerably smaller than the minimal DFAs for the same languages. 1 Introduction 1 Acyclic Finite-State Automata (FSA) provide a very efficient data structure for lexicon representation and fast string matching, with a great variety of applications in lexicon building (Daciuk et al., 2000), morphological processing (Sgarbas et al., 2000b) and speech processing (Lacouture and De Mori, 1991). They constitute very compact representations of lexicons, since common word prefixes and suffixes are represented by the same transitions. This representation also facilitates contentaddressable pattern matching. 1 Some authors (e.g. Perrin, 1990; Aoe et al. 1992; Sgarbas et al., 1995) use the term DAWG (Directed Acyclic Word Graph) when referring to acyclic FSAs. However, others (e.g. Crochemore and Verin, 1997) use the same term to denote the suffix automaton of a string. Examples of acyclic FSAs storing lexicons are shown in Fig.1. The</context>
<context position="18532" citStr="Sgarbas et al., 2000" startWordPosition="3204" endWordPosition="3207">s. Therefore it is not possible to find two similar (or equivalent) states in Q. Thus the updated NFA is compact. ❑ 5 Experimental Results The described algorithm has been tested using a lexicon of 230,000 Greek words in random order. The average word length in the lexicon was 9.5 characters; the size of the alphabet was 36. The number of states, transitions and the construction time were measured. The results are shown in Fig.3. The thick lines refer to the NFA; the thin lines refer to the corresponding minimal DFA. For the construction of the minimal DFA an incremental algorithm was 2 used (Sgarbas et al., 2000a) with O(n ) time performance. The test was performed on a 200 MHz PC. Figures 3a, 3b and 3c display respectively the number of states, the number of transitions and the construction time of the automaton, in respect to the size of the lexicon (number of words). It is evident that the compact NFA constructed by the proposed algorithm had much fewer states than the corresponding minimal DFA and its construction time was notably short. However, for lexicon size grater than 130,000 words, the algorithm was less efficient concerning the number of transitions (see Fig.3b). The same results are als</context>
</contexts>
<marker>Sgarbas, Fakotakis, Kokkinakis, 2000</marker>
<rawString>K. Sgarbas, N. Fakotakis and G. Kokkinakis. 2000b. A Straightforward Approach to Morphological Analysis and Synthesis. Proc. COMLEX 2000, Workshop on Computational Lexicography and Multimedia Dictionaries, Kato Achaia, Greece, 31-34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Watson</author>
</authors>
<title>A Taxonomy of Finite Automata Minimization Algorithms. Computer Science Note 93/44,</title>
<date>1993</date>
<institution>Eindhoven University of Technology, The Netherlands</institution>
<note>(Also at http://www.OpenFIRE.org).</note>
<contexts>
<context position="3009" citStr="Watson, 1993" startWordPosition="471" endWordPosition="472">e one of Fig.1b, are called non-deterministic automata (NFA). NFAs are smaller than DFAs but they are a little slower to search. DFAs are more popular for lexicon representation, especially the minimal ones, i.e. DFAs with the least number of states. Several algorithms are known for the construction of the minimal DFA, given a set of words (Hopcroft Deterministic Finite-State Non-Deterministic Automaton (DFA) Finite-State Automaton (NFA) (a) (b) Figure 1. The same lexicon in DFA and NFA. d S m a r t n t a � r S e t � � d S n � a r d t a m t r S t e and Ullman, 1979; Perrin, 199o; Revuz, 1992; Watson, 1993). Recently, some incremental algorithms have been proposed for this task (Aoe et al., 1993; Park et al., 1994; Sgarbas et al., 1995; Daciuk et al., 1998; Mihov, 1998; Ciura and Deorowicz, 1999; Daciuk et al., 2ooo; Revuz, 2ooo; Sgarbas et al., 2oooa). Incremental algorithms are useful because they can update the lexicon without rebuilding the whole structure from scratch. 2 For minimal NFAs there are also some (nonincremental) algorithms (Kameda and Weiner, 197o; Kim, 1974; Arnold et al., 1992; Matz and Potthoff, 1995) but unlike DFAs, there is no single minimal NFA for a given language. In th</context>
</contexts>
<marker>Watson, 1993</marker>
<rawString>B. Watson. 1993. A Taxonomy of Finite Automata Minimization Algorithms. Computer Science Note 93/44, Eindhoven University of Technology, The Netherlands (Also at http://www.OpenFIRE.org).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>