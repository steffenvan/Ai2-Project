<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001452">
<title confidence="0.993295">
Unsupervised Solution Post Identification from Discussion Forums
</title>
<author confidence="0.914474">
Deepak P Karthik Visweswariah
</author>
<affiliation confidence="0.876044">
IBM Research - India IBM Research - India
Bangalore, India Bangalore, India
</affiliation>
<email confidence="0.993228">
deepak.s.p@in.ibm.com v-karthik@in.ibm.com
</email>
<sectionHeader confidence="0.993756" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999824392857143">
Discussion forums have evolved into a de-
pendable source of knowledge to solve
common problems. However, only a mi-
nority of the posts in discussion forums
are solution posts. Identifying solution
posts from discussion forums, hence, is an
important research problem. In this pa-
per, we present a technique for unsuper-
vised solution post identification leverag-
ing a so far unexplored textual feature, that
of lexical correlations between problems
and solutions. We use translation mod-
els and language models to exploit lex-
ical correlations and solution post char-
acter respectively. Our technique is de-
signed to not rely much on structural fea-
tures such as post metadata since such
features are often not uniformly available
across forums. Our clustering-based itera-
tive solution identification approach based
on the EM-formulation performs favor-
ably in an empirical evaluation, beating
the only unsupervised solution identifica-
tion technique from literature by a very
large margin. We also show that our unsu-
pervised technique is competitive against
methods that require supervision, outper-
forming one such technique comfortably.
</bodyText>
<sectionHeader confidence="0.999331" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999107833333333">
Discussion forums have become a popular knowl-
edge source for finding solutions to common prob-
lems. StackOverflow1, a popular discussion forum
for programmers is among the top-100 most vis-
ited sites globally2. Now, there are discussion fo-
rums for almost every major product ranging from
</bodyText>
<footnote confidence="0.999414">
1http://www.stackoverflow.com
2http://www.alexa.com/siteinfo/stackoverflow.com
</footnote>
<bodyText confidence="0.995203151515151">
automobiles3 to gadgets such as those of Mac4 or
Samsung5. These typically start with a registered
user posting a question/problem6 to which other
users respond. Typical response posts include so-
lutions or clarification requests, whereas feedback
posts form another major category of forum posts.
As is the case with any community of humans,
discussion forums have their share of inflamma-
tory remarks too. Mining problem-solution pairs
from discussion forums has attracted much atten-
tion from the scholarly community in the recent
past. Since the first post most usually contains
the problem description, identifying its solutions
from among the other posts in the thread has been
the focus of many recent efforts (e.g., (Gandhe et
al., 2012; Hong and Davison, 2009)). Extract-
ing problem-solution pairs from forums enables
the usage of such knowledge in knowledge reuse
frameworks such as case-based reasoning (Kolod-
ner, 1992) that use problem-solution pairs as raw
material. In this paper, we address the problem
of unsupervised solution post identification7 from
discussion forums.
Among the first papers to address the solution
identification problem was the unsupervised ap-
proach proposed by (Cong et al., 2008). It em-
ploys a graph propagation method that prioritizes
posts that are (a) more similar to the problem post,
(b) more similar to other posts, and (c) authored
by a more authoritative user, to be labeled as so-
lution posts. Though seen to be effective in iden-
tifying solutions from travel forums, the first two
assumptions, (a) and (b), were seen to be not very
</bodyText>
<footnote confidence="0.9979211">
3http://www.cadillacforums.com/
4https://discussions.apple.com/
5http://www.galaxyforums.net/
6We use problem and question, as well as solution and
answer interchangeably in this paper.
7This problem has been referred to as answer extraction
by some papers earlier. However, we use solution identifica-
tion to refer to the problem since answer and extraction have
other connotations in the Question-Answering and Informa-
tion Extraction communities respectively.
</footnote>
<page confidence="0.952852">
155
</page>
<note confidence="0.832557">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 155–164,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999878407894737">
reliable in solution identification in other kinds of
discussion boards. (Catherine et al., 2012) reports
a study that illustrates that non-solution posts are,
on an average, as similar to the problem as solution
posts in technical forums. The second assump-
tion (i.e., (b) above) was also not seen to be use-
ful in discussion forums since posts that are highly
similar to other posts were seen to be complaints,
repetitive content being more pervasive among
complaint posts than solutions (Catherine et al.,
2013). Having exhausted the two obvious textual
features for solution identification, subsequent ap-
proaches have largely used the presence of lexi-
cal cues signifying solution-like narrative (e.g., in-
structive narratives such as ”check the router for
any connection issues”) as the primary content-
based feature for solution identification.
All solution identification approaches
since (Cong et al., 2008) have used super-
vised methods that require training data in the
form of labeled solution and non-solution posts.
The techniques differ from one another mostly
in the non-textual features that are employed in
representing posts. A variety of high precision as-
sumptions such as solution post typically follows
a problem post (Qu and Liu, 2011), solution posts
are likely to be within the first few posts, solution
posts are likely to have been acknowledged by
the problem post author (Catherine et al., 2012),
users with high authoritativeness are likely to
author solutions (Hong and Davison, 2009), and
so on have been seen to be useful in solution
identification. Being supervised methods, the
above assumptions are implicitly factored in
by including the appropriate feature (e.g., post
position in thread) in the feature space so that the
learner may learn the correlation (e.g., solution
posts typically are among the first few posts)
using the training data. Though such assumptions
on structural features, if generic enough, may be
built into unsupervised techniques to aid solution
identification, the variation in availability of
such features across forums limits the usage of
models that rely heavily on structural features.
For example, some forums employ chronological
order based flattening of threads (Seo et al., 2009)
making reply-to information unavailable; models
that harness reply-to features would then have
limited utility on identifying solutions within
such flattened threads. On medical forums,
privacy considerations may force forum data to
be dumped without author information, making a
host of author-id based features unavailable. On
datasets that contain data from across forums,
the model may have to be aware of the absence
of certain features in subsets of the data, or be
modeled using features that are available on all
threads.
Our Contribution: We propose an unsuper-
vised method for solution identification. The cor-
nerstone of our technique is the usage of a hith-
erto unexplored textual feature, lexical correla-
tions between problems and solutions, that is ex-
ploited along with language model based charac-
terization of solution posts. We model the lexical
correlation and solution post character using reg-
ularized translation models and unigram language
models respectively. To keep our technique appli-
cable across a large variety of forums with vary-
ing availability of non-textual features, we design
it to be able to work with minimal availability of
non-textual features. In particular, we show that
by using post position as the only non-textual fea-
ture, we are able to achieve accuracies compara-
ble to supervision-based approaches that use many
structural features (Catherine et al., 2013).
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999210791666667">
In this section, we provide a brief overview of pre-
vious work related to our problem. Though most
of the answer/solution identification approaches
proposed so far in literature are supervised meth-
ods that require a labeled training corpus, there are
a few that require limited or no supervision. Ta-
ble 1 provides an overview of some of the more
recent solution identification techniques from lit-
erature, with a focus on some features that we wish
to highlight. The common observation that most
problem-solving discussion threads have a prob-
lem description in the first post has been explic-
itly factored into many techniques; knowing the
problem/question is important for solution iden-
tification since author relations between problem
and other posts provide valuable cues for solution
identification. Most techniques use a variety of
such features as noted in Section 1. SVMs have
been the most popular method for supervised and
semi-supervised learning for the task of solution
identification.
Of particular interest to us are approaches that
use limited or no supervision, since we focus on
unsupervised solution identification in this paper.
</bodyText>
<page confidence="0.998469">
156
</page>
<table confidence="0.999883833333333">
Paper Reference Supervision Assumptions on Features other than Learning
Problem Position Post Content Used Technique
(Qu and Liu, 2011) Supervised First Post likely HMM assumes Naive Bayes
to be problem solution follows problem &amp; HMM
(Ding et al., 2008) Supervised First Post Post Position, Author, CRFs
Context Posts
(Kim et al., 2010) Supervised None Post Position, Author, MaxEnt,
Previous Posts, Profile etc. SVM, CRF
(Hong and Davison, 2009) Supervised First Post Post Position, Author, SVM
Author Authority
(Catherine et al., 2012) Supervised First Post Post Position, Author, Problem SVM
Author’s activities wrt Post
(Catherine et al., 2013) Limited First Post Post Position/Rating, Author, SVMs &amp;
Supervision Author Rating, Post Ack Co-Training
(Cong et al., 2008) Unsupervised None Author, Author Authority, Graph
Relation to Problem Author Propagation
Our Method Unsupervised First Post Post Position Translation
Models &amp; LM
</table>
<tableCaption confidence="0.999916">
Table 1: Summary of Some Solution Identification Techniquess
</tableCaption>
<bodyText confidence="0.99997765625">
The only unsupervised approach for the task, that
from (Cong et al., 2008), uses a graph propaga-
tion method on a graph modeled using posts as
vertices, and relies on the assumptions that posts
that bear high similarity to the problem and other
posts and those authored by authoritative users are
more likely to be solution posts. Some of those as-
sumptions, as mentioned in Section 1, were later
found to be not generalizable to beyond travel fo-
rums. The semi-supervised approach presented
in (Catherine et al., 2013) uses a few labeled
threads to bootstrap SVM based learners which are
then co-trained in an iterative fashion. In addition
to various features explored in literature, they use
acknowledgement modeling so that posts that have
been acknowledged positively may be favored for
being labeled as solutions.
We will use translation and language models
in our method for solution identification. Usage
of translation models for modeling the correlation
between textual problems and solutions have been
explored earlier starting from the answer retrieval
work in (Xue et al., 2008) where new queries were
conceptually expanded using the translation model
to improve retrieval. Translation models were also
seen to be useful in segmenting incident reports
into the problem and solution parts (Deepak et al.,
2012); we will use an adaptation of the generative
model presented therein, for our solution extrac-
tion formulation. Entity-level translation models
were recently shown to be useful in modeling cor-
relations in QA archives (Singh, 2012).
</bodyText>
<sectionHeader confidence="0.988035" genericHeader="method">
3 Problem Definition
</sectionHeader>
<bodyText confidence="0.999963315789474">
Let a thread T from a discussion forum be made
up of t posts. Since we assume, much like
many other earlier papers, that the first post is
the problem post, the task is to identify which
among the remaining t − 1 posts are solutions.
There could be multiple (most likely, different)
solutions within the same thread. We may now
model the thread T as t − 1 post pairs, each
pair having the problem post as the first element,
and one of the t − 1 remaining posts (i.e., re-
ply posts in T) as the second element. Let C =
{(p1, r1), (p2, r2), . . . , (p,,,, r,,,)} be the set of such
problem-reply pairs from across threads in the dis-
cussion forum. We are interested in finding a sub-
set C&apos; of C such that most of the pairs in C&apos; are
problem-solution pairs, and most of those in C−C&apos;
are not so. In short, we would like to find problem-
solution pairs from C such that the F-measure8 for
solution identification is maximized.
</bodyText>
<sectionHeader confidence="0.997589" genericHeader="method">
4 Our Approach
</sectionHeader>
<subsectionHeader confidence="0.999184">
4.1 The Correlation Assumption
</subsectionHeader>
<bodyText confidence="0.9999465">
Central to our approach is the assumption of lex-
ical correlation between the problem and solution
</bodyText>
<footnote confidence="0.988935">
8http://en.wikipedia.org/wiki/F1 score
</footnote>
<page confidence="0.996205">
157
</page>
<bodyText confidence="0.999973818181818">
texts. At the word level, this translates to assum-
ing that there exist word pairs such that the pres-
ence of the first word in the problem part pre-
dicts the presence/absence of the second word in
the solution part well. Though not yet harnessed
for solution identification, the correlation assump-
tion is not at all novel. Infact, the assumption
that similar problems have similar solutions (of
which the correlation assumption is an offshoot)
forms the foundation of case-based reasoning sys-
tems (Kolodner, 1992), a kind of knowledge reuse
systems that could be the natural consumers of
problem-solution pairs mined from forums. The
usage of translation models in QA retrieval (Xue et
al., 2008; Singh, 2012) and segmentation (Deepak
et al., 2012) were also motivated by the correlation
assumption. We use an IBM Model 1 translation
model (Brown et al., 1990) in our technique; sim-
plistically, such a model m may be thought of as
a 2-d associative array where the value m[w1][w2]
is directly related to the probability of w1 occuring
in the problem when w2 occurs in the solution.
</bodyText>
<subsectionHeader confidence="0.857466">
4.2 Generative model for Solution Posts
</subsectionHeader>
<bodyText confidence="0.999878428571429">
Consider a unigram language model SS that mod-
els the lexical characteristics of solution posts, and
a translation model TS that models the lexical cor-
relation between problems and solutions. Our gen-
erative model models the reply part of a (p, r) pair
(in which r is a solution) as being generated from
the statistical models in {SS, TS} as follows.
</bodyText>
<listItem confidence="0.99939625">
• For each word ws occuring in r,
1. Choose z ∼ U(0,1)
2. If z ≤ A, Choose w ∼ Mult(SS)
3. Else, Choose w ∼ Mult(TSp )
</listItem>
<bodyText confidence="0.977523894736842">
where TSp denotes the multionomial distribu-
tion obtained from TS conditioned over the words
in the post p; this is obtained by assigning each
candidate solution word w a weight equal to
avg{TS[w&apos;][w]|w&apos; E p}, and normalizing such
weights across all solution words. In short, each
solution word is assumed to be generated from
the language model or the translation model (con-
ditioned on the problem words) with a probabil-
ity of A and 1 − A respectively, thus accounting
for the correlation assumption. The generative
model above is similar to the proposal in (Deepak
et al., 2012), adapted suitably for our scenario. We
model non-solution posts similarly with the sole
difference being that they would be sampled from
the analogous models SN and TN that characterize
behavior of non-solution posts.
Example: Consider the following illustrative
example of a problem and solution post:
</bodyText>
<listItem confidence="0.98961775">
• Problem: I am unable to surf the web on the
BT public wifi.
• Solution: Maybe, you should try disconnect-
ing and rejoining the network.
</listItem>
<bodyText confidence="0.996961">
Of the solution words above, generic words
such as try and should could probably be ex-
plained by (i.e., sampled from) the solution lan-
guage model, whereas disconnect and rejoin could
be correlated well with surf and wifi and hence are
more likely to be supported better by the transla-
tion model.
</bodyText>
<subsectionHeader confidence="0.996316">
4.3 Clustering-based Approach
</subsectionHeader>
<bodyText confidence="0.9998254">
We propose a clustering based approach so as to
cluster each of the (p, r) pairs into either the so-
lution cluster or the non-solution cluster. The ob-
jective function that we seek to maximize is the
following:
</bodyText>
<equation confidence="0.986051333333333">
F((p, r), SS, TS) if label((p,r))=S
(p,r)EC F((p, r), SN, TN) if label((p,r))=N
(1)
</equation>
<bodyText confidence="0.996299142857143">
F((p, r), S, T) indicates the conformance of
the (p, r) pair (details in Section 4.3.1) with the
generative model that uses the S and T models as
the language and translation models respectively.
The clustering based approach labels each (p, r)
pair as either solution (i.e., S) or non-solution (i.e.,
N). Since we do not know the models or the la-
belings to start with, we use an iterative approach
modeled on the EM meta-algorithm (Dempster et
al., 1977) involving iterations, each comprising of
an E-step followed by the M-step. For simplicity
and brevity, instead of deriving the EM formula-
tion, we illustrate our approach by making an anal-
ogy with the popular K-Means clustering (Mac-
Queen, 1967) algorithm that also uses the EM for-
mulation and crisp assignments of data points like
we do. K-Means is a clustering algorithm that
clusters objects represented as multi-dimensional
points into k clusters where each cluster is rep-
resented by the centroid of all its members. Each
iteration in K-Means starts off with assigning each
</bodyText>
<page confidence="0.982176">
158
</page>
<table confidence="0.999784727272727">
In K-Means In Our Approach
Data Multi-dimensional Points (p, r) pairs
Cluster Model Respective Centroid Vector Respective S and T Models for each cluster
Initialization Random Choice of Centroids Models learnt using (p, r) pairs labeled
using the Post Position of r
E-Step label(d) = label((p,r)) = arg maxi F((p,r), Si, Ti)
arg mini dist(d, centroidi) (Sec 4.3.1), and learn solution word
source probabilities (Sec 4.3.2)
M-Step centroidi = avg{d|label(d) = i} Re-learn SS and TS using pairs labeled S
SN and TN using pairs labeled N (Sec 4.3.3)
Output The clustering of points (p, r) pairs labeled as S
</table>
<tableCaption confidence="0.999417">
Table 2: Illustrating Our Approach wrt K-Means Clustering
</tableCaption>
<bodyText confidence="0.999578944444445">
data object to its nearest centroid, followed by re-
computing the centroid vector based on the assign-
ments made. The analogy with K-Means is illus-
trated in Table 2.
Though the analogy in Table 2 serves to provide
a high-level picture of our approach, the details re-
quire further exposition. In short, our approach is
a 2-way clustering algorithm that uses two pairs of
models, [SS, TS] and [SN, TN], to model solution
pairs and non-solution pairs respectively. At each
iteration, the post-pairs are labeled as either solu-
tion (S) or non-solution (N) based on which pair
of models they better conform to. Within the same
iteration, the four models are then re-learnt using
the labels and other side information. At the end
of the iterations, the pairs labeled S are output as
solution pairs. We describe the various details in
separate subsections herein.
</bodyText>
<subsubsectionHeader confidence="0.4846">
4.3.1 E-Step: Estimating Labels
</subsubsectionHeader>
<bodyText confidence="0.986398666666667">
As outlined in Table 2, each (p, r) pair would
be assigned to one of the classes, solution or
non-solution, based on whether it conforms better
with the solution models (i.e., SS &amp; TS) or non-
solution models (SN &amp; TN), as determined using
the F((p, r), S, T) function, i.e.,
</bodyText>
<equation confidence="0.9703804">
label((p,r)) = arg max F((p, r), Si, Ti)
iE{S,N}
F(.) falls out of the generative model:
F((p,r),S,T) = � AxS[w]+(1−A)xTp[w]
wEr
</equation>
<bodyText confidence="0.9858385">
where S[w] denotes the probability of w from
S and Tp[w] denotes the probability of w from
the multinomial distribution derived from T con-
ditioned over the words in p, as in Section 4.2.
</bodyText>
<subsubsectionHeader confidence="0.704875">
4.3.2 E-Step: Estimating Reply Word Source
</subsubsectionHeader>
<bodyText confidence="0.999904777777778">
Since the language and translation models operate
at the word level, the objective function entails that
we let the models learn based on their fractional
contribution of the words from the language and
translation models. Thus, we estimate the propor-
tional contribution of each word from the language
and translation models too, in the E-step. The frac-
tional contributions of the word w E r in the (p, r)
pair labeled as solution (i.e., S) is as follows:
</bodyText>
<equation confidence="0.999089666666667">
f(p,r) SS[w]
�S (w) =
SS[w] + TSp [w]
fTs,r) 7
(w) = s [w]
SS[w] + TSp [w]
</equation>
<bodyText confidence="0.99914075">
The fractional contributions are just the actual
supports for the word w, normalized by the to-
tal contribution for the word from across the two
models. Similar estimates, f(p,r)
</bodyText>
<equation confidence="0.9995295">
�N (.) and f(p,r)
�N (.)
</equation>
<bodyText confidence="0.775524888888889">
are made for reply words from pairs labeled N.
In our example from Section 4.2, words such as
rejoin are likely to get higher f(p,r)
�S (.) scores due
to being better correlated with problem words and
consequently better supported by the translation
model; those such as try may get higher f(p,r)
�S (.)
scores.
</bodyText>
<subsectionHeader confidence="0.74597">
4.3.3 M-Step: Learning Models
</subsectionHeader>
<bodyText confidence="0.999930666666667">
We use the labels and reply-word source estimates
from the E-step to re-learn the language and trans-
lation models in this step. As may be obvious
from the ensuing discussion, those pairs labeled
as solution pairs are used to learn the SS and TS
models and those labeled as non-solution pairs are
</bodyText>
<page confidence="0.997811">
159
</page>
<bodyText confidence="0.9998281875">
used to learn the models with subscript N. We let
each reply word contribute as much to the respec-
tive language and translation models according to
the estimates in Section 4.3.2. In our example, if
the word disconnect is assigned a source proba-
bility of 0.9 and 0.1 for the translation and lan-
guage models respectively, the virtual document-
pair from (p, r) that goes into the training of the
respective T model would assume that disconnect
occurs in r with a frequency of 0.9; similarly, the
respective S would account for disconnect with a
frequency of 0.1. Though fractional word frequen-
cies are not possible in real documents, statistical
models can accomodate such fractional frequen-
cies in a straightforward manner. The language
models are learnt only over the r parts of the (p, r)
pairs since they are meant to characterize reply be-
havior; on the other hand, translation models learn
over both p and r parts to model correlation.
Regularizing the T models: In our formula-
tion, the language and translation models may be
seen as competing for ”ownership” of reply words.
Consider the post and reply vocabularies to be
of sizes A and B respectively; then, the transla-
tion model would have A x B variables, whereas
the unigram language model has only B variables.
This gives the translation model an implicit edge
due to having more parameters to tune to the data,
putting the language models at a disadvantage.
To level off the playing field, we use a regular-
ization9 operation in the learning of the transla-
tion models. The IBM Model 1 learning pro-
cess uses an internal EM approach where the E-
step estimates the alignment vector for each prob-
lem word; this vector indicates the distribution of
alignments of the problem word across the solu-
tion words. In our example, an example alignment
vector for wifi could be: {rejoin : 0.4, network :
0.4, disconnect : 0.1,...}. Our regularization
method uses a parameter T to discard the long tail
in the alignment vector by resetting entries hav-
ing a value ≤ T to 0.0 followed by re-normalizing
the alignment vector to add up to 1.0. Such prun-
ing is performed at each iteration in the learn-
ing of the translation model, so that the following
M-steps learn the probability matrix according to
such modified alignment vectors.
The semantics of the T parameter may be in-
</bodyText>
<footnote confidence="0.88460475">
9We use the word regularization in a generic sense to
mean adapting models to avoid overfitting; in particular, it
may be noted that we are not using popular regularization
methods such as L1-regularization.
</footnote>
<figureCaption confidence="0.461903">
Alg. 1 Clustering-based Solution Identification
</figureCaption>
<bodyText confidence="0.857601333333333">
Input. C, a set of (p, r) pairs
Output. C&apos;, the set of identified solution pairs
Initialization
</bodyText>
<listItem confidence="0.985572">
1. b(p, r) E C
2. if(r.postpos = 2) label((p, r)) = S
3. else label((p, r)) = N
4. Learn SS &amp; TS using pairs labeled S
5. Learn SN &amp; TN using pairs labeled N
EM Iterations
6. while(not converged ∧ #Iterations &lt; 10)
E-Step:
7. b(p, r) E C
8. label((p, r)) = arg maxi F((p, r), Si, Ti)
9. bwEr , ,
10. Estimate fs abel(p,r) (w) , fTla,b/l(p,r) (w)
M-Step:
11. Learn SS &amp; TS from pairs labeled S
using the f(p,r)
</listItem>
<equation confidence="0.941337555555556">
�S (.) f(p,r)
�S (.) estimates
12. Learn SN &amp; TN from pairs labeled N
using the f(p,r)
�N (.) f(p,r)
�N (.) estimates
Output
13. Output (p, r) pairs from C with
label((p, r)) = S as C&apos;
</equation>
<bodyText confidence="0.997762">
tuitively outlined. If we would like to allow align-
ment vectors to allow a problem word to align with
upto two reply words, we would need to set T to
a value close to 0.5(= 12); ideally though, to al-
low for the mass consumed by an almost inevitable
long tail of very low values in the alignment vec-
tor, we would need to set it to slightly lower than
0.5, say 0.4.
</bodyText>
<subsectionHeader confidence="0.483748">
4.3.4 Initialization
</subsectionHeader>
<bodyText confidence="0.999116714285715">
K-Means clustering mostly initializes centroid
vectors randomly; however, it is non-trivial to ini-
tialize the complex translation and language mod-
els randomly. Moreover, an initialization such that
the SS and TS models favor the solution pairs
more than the non-solution pairs is critical so that
they may progressively lean towards modeling so-
lution behaviour better across iterations. Towards
this, we make use of a structural feature; in partic-
ular, adapting the hypothesis that solutions occur
in the first N posts (Ref. (Catherine et al., 2012)),
we label the pairs that have the the reply from the
second post (note that the first post is assumed to
be the problem post) in the thread as a solution
</bodyText>
<page confidence="0.992387">
160
</page>
<bodyText confidence="0.999333272727273">
post, and all others as non-solution posts. Such
an initialization along with uniform reply word
source probabilities is used to learn the initial es-
timates of the SS, TS, SN and TN models to be
used in the E-step for the first iteration. We will
show that we are able to effectively perform solu-
tion identification using our approach by exploit-
ing just one structural feature, the post position,
as above. However, we will also show that we can
exploit other features as and when available, to de-
liver higher accuracy clusterings.
</bodyText>
<subsectionHeader confidence="0.970787">
4.3.5 Method Summary
</subsectionHeader>
<bodyText confidence="0.9959046">
The overall method comprising the steps that
have been described is presented in Algorithm 1.
The initialization using the post position (Ref.
Sec 4.3.4) is illustrated in Lines 1-5, whereas the
EM-iterations form Steps 6 through 12. Of these,
the E-step incorporates labeling (Line 8) as de-
scribed in Sec 4.3.1 and reply-word source estima-
tion (Line 10) detailed in Sec 4.3.2. The models
are then re-learnt in the M-Step (Lines 11-12) as
outlined in Sec 4.3.3. At the end of the iterations
that may run up to 10 times if the labelings do not
stabilize earlier, the pairs labeled S are output as
identified solutions (Line 13).
Time Complexity: Let n denote JCJ, and the
number of unique words in each problem and re-
ply post be a and b respectively. We will de-
note the vocabulary size of problem posts as A
and that of reply posts as B. Learning of the
language and translation models in each iteration
costs O(nb + B) and O(k&apos;(nab + AB)) respec-
tively (assuming the translation model learning
runs for k&apos; iterations). The E-step labeling and
source estimation cost O(nab) each. For k iter-
ations of our algorithm, this leads to an overall
complexity of O(kk&apos;(nab + AB)).
</bodyText>
<sectionHeader confidence="0.991985" genericHeader="evaluation">
5 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.999855888888889">
We use a crawl of 140k threads from Apple Dis-
cussion forums10. Out of these, 300 threads (com-
prising 1440 posts) were randomly chosen and
each post was manually tagged as either solution
or non-solution by the authors of (Catherine et al.,
2013) (who were kind enough to share the data
with us) with an inter-annotator agreement11 of
0.71. On an average, 40% of replies in each thread
and 77% of first replies were seen to be solutions,
</bodyText>
<footnote confidence="0.999156">
10http://discussions.apple.com
11http://en.wikipedia.org/wiki/Cohen’s kappa
</footnote>
<figureCaption confidence="0.997876">
Figure 1: F% (Y) vs. #Iterations (X)
</figureCaption>
<table confidence="0.999695416666667">
ProblemWord, SolutionWord TS[p][s]
network, guest 0.0754
connect, adaptor 0.0526
TS wireless, adaptor 0.0526
translat, shortcut 0.0492
updat, rebuilt 0.0405
SolutionWord SS[s]
your 0.0115
SS try 0.0033
router 0.0033
see 0.0033
password 0.0023
</table>
<tableCaption confidence="0.999622">
Table 4: Sample TS and SS Estimates
</tableCaption>
<bodyText confidence="0.999922727272727">
leading to an F-measure of 53% for our initializa-
tion heuristic. We use the F-measure12 for solu-
tion identification, as the primary evaluation mea-
sure. While we vary the various parameters sep-
arately in order to evaluate the trends, we use a
dataset of 800 threads (containing the 300 labeled
threads) and set λ = 0.5 and T = 0.4 unless other-
wise mentioned. Since we have only 300 labeled
threads, accuracy measures are reported on those
(like in (Catherine et al., 2013)). We pre-process
the post data by stemming words (Porter, 1980).
</bodyText>
<subsectionHeader confidence="0.99878">
5.1 Quality Evaluation
</subsectionHeader>
<bodyText confidence="0.994324363636364">
In this study, we compare the performance of our
method under varying settings of λ against the
only unsupervised approach for solution identi-
fication from literature, that from (Cong et al.,
2008). We use an independent implementation
of the technique using Kullback-Leibler Diver-
gence (Kullback, 1997) as the similarity measure
between posts; KL-Divergence was seen to per-
form best in the experiments reported in (Cong et
al., 2008).
Table 3 illustrates the comparative performance
</bodyText>
<footnote confidence="0.958621">
12http://en.wikipedia.org/wiki/F1 score
</footnote>
<page confidence="0.984482">
161
</page>
<table confidence="0.999479714285714">
Technique Precision Recall F-Measure
Unsupervised Graph Propagation (Cong et al., 2008) 29.7 % 55.6 % 38.7 %
Our Method with only Translation Models (A = 0.0) 41.8 % 86.8 % 56.5 %
Our Method with only Language Models (A = 1.0) 63.2 % 62.1 % 62.6 %
Our Method with Both Models (A = 0.5) 61.3 % 66.9 % 64.0 %
ANS CT 40.6 % 88.0 % 55.6 %
Methods using Supervision (Catherine et al., 2013) ANS-ACK PCT 56.8 % 84.1 % 67.8%
</table>
<tableCaption confidence="0.997587">
Table 3: Quality Evaluation
</tableCaption>
<figureCaption confidence="0.998503">
Figure 2: F% (Y) vs. λ (X) Figure 3: F% (Y) vs. τ (X) Figure 4: F% (Y) vs. ¢#Threads (X)
</figureCaption>
<bodyText confidence="0.998422344827586">
on various quality metrics, of which F-Measure is
typically considered most important. Our pure-
LM13 setting (i.e., A = 1) was seen to perform up
to 6 F-Measure points better than the pure-TM14
setting (i.e., A = 0), whereas the uniform mix is
seen to be able to harness both to give a 1.4 point
(i.e., 2.2%) improvement over the pure-LM case.
The comparison with the approach from (Cong et
al., 2008) illustrates that our method is very clearly
the superior method for solution identification out-
performing the former by large margins on all the
evaluation measures, with the improvement on F-
measure being more than 25 points.
Comparison wrt Methods from (Catherine et
al., 2013): Table 3 also lists the performance of
SVM-based methods from (Catherine et al., 2013)
that use supervised information for solution iden-
tification, to help put the performance of our tech-
nique in perspective. Of the two methods therein,
ANS CT is a more general method that uses two
views (structural and lexical) of solutions which
are then co-trained. ANS-ACK PCT is an en-
hanced method that requires author-id informa-
tion and a means of classifying posts as acknowl-
edgements (which is done using additional super-
vision); a post being acknowledged by the prob-
lem author is then used as a signal to enhance
the solution-ness of a post. In the absence of
author information (such as may be common in
</bodyText>
<footnote confidence="0.989779">
13Language Model
14Translation Model
</footnote>
<bodyText confidence="0.999194870967742">
privacy-constrained domains such as medical fo-
rums) and extrinsic information to enable identify
acknowledgements, ANS CT is the only technique
available. Our technique is seen to outperform
ANS CT by a respectable margin (8.6 F-measure
points) while trailing behind the enhanced ANS-
ACK PCT method with a reasonably narrow 3.8
F-measure point margin. Thus, our unsupervised
method is seen to be a strong competitor even for
techniques using supervision outlined in (Cather-
ine et al., 2013), illustrating the effectiveness of
LM and TM modeling of reply posts.
Across Iterations: For scenarios where com-
putation is at a premium, it is useful to know how
quickly the quality of solution identification sta-
bilizes, so that the results can be collected after
fewer iterations. Figure 1 plots the F-measure
across iterations for the run with A = 0.5, T = 0.4
setting, where the F-measure is seen to stabilize in
as few as 4-5 iterations. Similar trends were ob-
served for other runs as well, confirming that the
run may be stopped as early as after the fourth it-
eration without considerable loss in quality.
Example Estimates from LMs and TMs: In
order to understand the behavior of the statistical
models, we took the highest 100 entries from both
Ss and Ts and attempted to qualitatively evalu-
ate semantics of the words (or word pairs) corre-
sponding to those. Though the stemming made it
hard to make sense of some entries, we present
some of the understandable entries from among
</bodyText>
<page confidence="0.993084">
162
</page>
<bodyText confidence="0.999879444444444">
the top-100 in Table 4. The first three entries from
TS deal with connection issues for which adaptor
or guest account related solutions are proposed,
whereas the remaining have something to do with
the mac translator app and rebuilding libraries af-
ter an update. The top words from SS include im-
perative words and words from solutions to com-
mon issues that include actions pertaining to the
router or password.
</bodyText>
<subsectionHeader confidence="0.999621">
5.2 Varying Parameter Settings
</subsectionHeader>
<bodyText confidence="0.999509648148148">
We now analyse the performance of our approach
against varying parameter settings. In particular,
we vary A and T values and the dataset size, and
experiment with some initialization variations.
Varying A: A is the weighting parameter that
indicates the fraction of weight assigned to LMs
(vis-a-vis TMs). As may be seen from Figure 2,
the quality of the results as measured by the F-
measure is seen to peak around the middle (i.e.,
A = 0.5), and decline slowly towards either ex-
treme, with a sharp decline at A = 0 (i.e., pure-
TM setting). This indicates that a uniform mix is
favorable; however, if one were to choose only one
type of model, usage of LMs is seen to be prefer-
able than TMs.
Varying T: T is directly related to the extent of
pruning of TMs, in the regularization operation;
all values in the alignment vector G T are pruned.
Thus, each problem word is roughly allowed to be
aligned with at most — 1τ solution words. The
trends from Figure 3 suggests that allowing a prob-
lem word to be aligned to up to 2.5 solution words
(i.e., T = 0.4) is seen to yield the best performance
though the quality decline is graceful towards ei-
ther side of the [0.1, 0.5] range.
Varying Data Size: Though more data always
tends to be beneficial since statistical models ben-
efit from redundancy, the marginal utility of ad-
ditional data drops to very small levels beyond
a point; we are interested in the amount of data
beyond which the quality of solution identifica-
tion flattens out. Figure 4 suggests that there is
a sharp improvement in quality while increasing
the amount of data from 300 threads (i.e., 1440
(p, r) pairs) to 550 (2454 pairs), whereas the in-
crement is smaller when adding another 250 pairs
(total of 3400 pairs). Beyond 800 threads, the F-
measure was seen to flatten out rapidly and stabi-
lize at — 64%.
Initialization: In Apple discussion forums,
posts by Apple employees that are labeled with
the Apple employees tag (approximately — 7% of
posts in our dataset) tend to be solutions. So are
posts that are marked Helpful (— 3% of posts) by
other users. Being specific to Apple forums, we
did not use them for initialization in experiments
so far with the intent of keeping the technique
generic. However, when such posts are initial-
ized as solutions (in addition to first replies as we
did earlier), the F-score for solution identification
for our technique was seen to improve slightly, to
64.5% (from 64%). Thus, our technique is able
to exploit any extra solution identifying structural
features that are available.
</bodyText>
<sectionHeader confidence="0.999076" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999998">
We considered the problem of unsupervised so-
lution post identification from discussion forum
threads. Towards identifying solutions to the prob-
lem posed in the initial post, we proposed the us-
age of a hitherto unexplored textual feature for
the solution identification problem; that of lexical
correlations between problems and solutions. We
model and harness lexical correlations using trans-
lation models, in the company of unigram lan-
guage models that are used to characterize reply
posts, and formulate a clustering-based EM ap-
proach for solution identification. We show that
our technique is able to effectively identify solu-
tions using just one non-content based feature, the
post position, whereas previous techniques in liter-
ature have depended heavily on structural features
(that are not always available in many forums) and
supervised information. Our technique is seen to
outperform the sole unsupervised solution identi-
fication technique in literature, by a large margin;
further, our method is even seen to be competi-
tive to recent methods that use supervision, beat-
ing one of them comfortably, and trailing another
by a narrow margin. In short, our empirical analy-
sis illustrates the superior performance and estab-
lishes our method as the method of choice for un-
supervised solution identification.
Exploration into the usage of translation models
to aid other operations in discussion forums such
as proactive word suggestions for solution author-
ing would be interesting direction for follow-up
work. Discovery of problem-solution pairs in
cases where the problem post is not known before-
hand, would be a challenging problem to address.
</bodyText>
<page confidence="0.998669">
163
</page>
<sectionHeader confidence="0.995883" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999918753424658">
Peter F Brown, John Cocke, Stephen A Della Pietra,
Vincent J Della Pietra, Fredrick Jelinek, John D Laf-
ferty, Robert L Mercer, and Paul S Roossin. 1990.
A statistical approach to machine translation. Com-
putational linguistics, 16(2):79–85.
Rose Catherine, Amit Singh, Rashmi Gangadharaiah,
Dinesh Raghu, and Karthik Visweswariah. 2012.
Does similarity matter? the case of answer extrac-
tion from technical discussion forums. In COLING
(Posters), pages 175–184.
Rose Catherine, Rashmi Gangadharaiah, Karthik
Visweswariah, and Dinesh Raghu. 2013. Semi-
supervised answer extraction from discussion fo-
rums. In IJCNLP.
Gao Cong, Long Wang, Chin-Yew Lin, Young-In Song,
and Yueheng Sun. 2008. Finding question-answer
pairs from online forums. In Proceedings of the
31st annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 467–474. ACM.
P. Deepak, Karthik Visweswariah, Nirmalie Wiratunga,
and Sadiq Sani. 2012. Two-part segmentation of
text documents. In CIKM, pages 793–802.
Arthur P Dempster, Nan M Laird, and Donald B Ru-
bin. 1977. Maximum likelihood from incomplete
data via the em algorithm. Journal of the Royal Sta-
tistical Society. Series B (Methodological), pages 1–
38.
Shilin Ding, Gao Cong, Chin-Yew Lin, and Xianyan
Zhu. 2008. Using conditional random fields to ex-
tract contexts and answers of questions from online
forums. In ACL.
Ankur Gandhe, Dinesh Raghu, and Rose Catherine.
2012. Domain adaptive answer extraction for dis-
cussion boards. In Proceedings of the 21st interna-
tional conference companion on World Wide Web,
pages 501–502. ACM.
Liangjie Hong and Brian D Davison. 2009. A
classification-based approach to question answering
in discussion boards. In Proceedings of the 32nd in-
ternational ACM SIGIR conference on Research and
development in information retrieval, pages 171–
178. ACM.
Su Nam Kim, Li Wang, and Timothy Baldwin. 2010.
Tagging and linking web forum posts. In Proceed-
ings of the Fourteenth Conference on Computational
Natural Language Learning, pages 192–202. Asso-
ciation for Computational Linguistics.
Janet L Kolodner. 1992. An introduction to case-based
reasoning. Artificial Intelligence Review, 6(1):3–34.
Solomon Kullback. 1997. Information theory and
statistics. Courier Dover Publications.
James MacQueen. 1967. Some methods for classi-
fication and analysis of multivariate observations.
In Proceedings of the fifth Berkeley symposium on
mathematical statistics and probability, volume 1,
page 14. California, USA.
Martin F Porter. 1980. An algorithm for suffix strip-
ping. Program: electronic library and information
systems, 14(3):130–137.
Zhonghua Qu and Yang Liu. 2011. Finding problem
solving threads in online forum. In IJCNLP, pages
1413–1417.
Jangwon Seo, W Bruce Croft, and David A Smith.
2009. Online community search using thread struc-
ture. In Proceedings of the 18th ACM conference
on Information and knowledge management, pages
1907–1910. ACM.
Amit Singh. 2012. Entity based q&amp;a retrieval. In
EMNLP-CoNLL, pages 1266–1277.
Xiaobing Xue, Jiwoon Jeon, and W. Bruce Croft. 2008.
Retrieval models for question and answer archives.
In SIGIR, pages 475–482.
</reference>
<page confidence="0.998522">
164
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.925853">
<title confidence="0.998868">Unsupervised Solution Post Identification from Discussion Forums</title>
<author confidence="0.991389">Deepak P Karthik Visweswariah</author>
<affiliation confidence="0.99973">IBM Research - India IBM Research - India</affiliation>
<address confidence="0.984539">Bangalore, India Bangalore, India</address>
<email confidence="0.999163">deepak.s.p@in.ibm.comv-karthik@in.ibm.com</email>
<abstract confidence="0.99828624137931">Discussion forums have evolved into a dependable source of knowledge to solve common problems. However, only a minority of the posts in discussion forums are solution posts. Identifying solution posts from discussion forums, hence, is an important research problem. In this paper, we present a technique for unsupervised solution post identification leveraging a so far unexplored textual feature, that of lexical correlations between problems and solutions. We use translation models and language models to exploit lexical correlations and solution post character respectively. Our technique is designed to not rely much on structural features such as post metadata since such features are often not uniformly available across forums. Our clustering-based iterative solution identification approach based on the EM-formulation performs favorably in an empirical evaluation, beating the only unsupervised solution identification technique from literature by a very large margin. We also show that our unsupervised technique is competitive against methods that require supervision, outperforming one such technique comfortably.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>John Cocke</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Fredrick Jelinek</author>
<author>John D Lafferty</author>
<author>Robert L Mercer</author>
<author>Paul S Roossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Computational linguistics,</journal>
<pages>16--2</pages>
<contexts>
<context position="13305" citStr="Brown et al., 1990" startWordPosition="2063" endWordPosition="2066">ssed for solution identification, the correlation assumption is not at all novel. Infact, the assumption that similar problems have similar solutions (of which the correlation assumption is an offshoot) forms the foundation of case-based reasoning systems (Kolodner, 1992), a kind of knowledge reuse systems that could be the natural consumers of problem-solution pairs mined from forums. The usage of translation models in QA retrieval (Xue et al., 2008; Singh, 2012) and segmentation (Deepak et al., 2012) were also motivated by the correlation assumption. We use an IBM Model 1 translation model (Brown et al., 1990) in our technique; simplistically, such a model m may be thought of as a 2-d associative array where the value m[w1][w2] is directly related to the probability of w1 occuring in the problem when w2 occurs in the solution. 4.2 Generative model for Solution Posts Consider a unigram language model SS that models the lexical characteristics of solution posts, and a translation model TS that models the lexical correlation between problems and solutions. Our generative model models the reply part of a (p, r) pair (in which r is a solution) as being generated from the statistical models in {SS, TS} a</context>
</contexts>
<marker>Brown, Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, Roossin, 1990</marker>
<rawString>Peter F Brown, John Cocke, Stephen A Della Pietra, Vincent J Della Pietra, Fredrick Jelinek, John D Lafferty, Robert L Mercer, and Paul S Roossin. 1990. A statistical approach to machine translation. Computational linguistics, 16(2):79–85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rose Catherine</author>
<author>Amit Singh</author>
<author>Rashmi Gangadharaiah</author>
<author>Dinesh Raghu</author>
<author>Karthik Visweswariah</author>
</authors>
<title>Does similarity matter? the case of answer extraction from technical discussion forums.</title>
<date>2012</date>
<booktitle>In COLING (Posters),</booktitle>
<pages>175--184</pages>
<contexts>
<context position="4064" citStr="Catherine et al., 2012" startWordPosition="591" endWordPosition="594">solution and answer interchangeably in this paper. 7This problem has been referred to as answer extraction by some papers earlier. However, we use solution identification to refer to the problem since answer and extraction have other connotations in the Question-Answering and Information Extraction communities respectively. 155 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 155–164, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics reliable in solution identification in other kinds of discussion boards. (Catherine et al., 2012) reports a study that illustrates that non-solution posts are, on an average, as similar to the problem as solution posts in technical forums. The second assumption (i.e., (b) above) was also not seen to be useful in discussion forums since posts that are highly similar to other posts were seen to be complaints, repetitive content being more pervasive among complaint posts than solutions (Catherine et al., 2013). Having exhausted the two obvious textual features for solution identification, subsequent approaches have largely used the presence of lexical cues signifying solution-like narrative </context>
<context position="5383" citStr="Catherine et al., 2012" startWordPosition="799" endWordPosition="802">ry contentbased feature for solution identification. All solution identification approaches since (Cong et al., 2008) have used supervised methods that require training data in the form of labeled solution and non-solution posts. The techniques differ from one another mostly in the non-textual features that are employed in representing posts. A variety of high precision assumptions such as solution post typically follows a problem post (Qu and Liu, 2011), solution posts are likely to be within the first few posts, solution posts are likely to have been acknowledged by the problem post author (Catherine et al., 2012), users with high authoritativeness are likely to author solutions (Hong and Davison, 2009), and so on have been seen to be useful in solution identification. Being supervised methods, the above assumptions are implicitly factored in by including the appropriate feature (e.g., post position in thread) in the feature space so that the learner may learn the correlation (e.g., solution posts typically are among the first few posts) using the training data. Though such assumptions on structural features, if generic enough, may be built into unsupervised techniques to aid solution identification, t</context>
<context position="9311" citStr="Catherine et al., 2012" startWordPosition="1404" endWordPosition="1407">upervision, since we focus on unsupervised solution identification in this paper. 156 Paper Reference Supervision Assumptions on Features other than Learning Problem Position Post Content Used Technique (Qu and Liu, 2011) Supervised First Post likely HMM assumes Naive Bayes to be problem solution follows problem &amp; HMM (Ding et al., 2008) Supervised First Post Post Position, Author, CRFs Context Posts (Kim et al., 2010) Supervised None Post Position, Author, MaxEnt, Previous Posts, Profile etc. SVM, CRF (Hong and Davison, 2009) Supervised First Post Post Position, Author, SVM Author Authority (Catherine et al., 2012) Supervised First Post Post Position, Author, Problem SVM Author’s activities wrt Post (Catherine et al., 2013) Limited First Post Post Position/Rating, Author, SVMs &amp; Supervision Author Rating, Post Ack Co-Training (Cong et al., 2008) Unsupervised None Author, Author Authority, Graph Relation to Problem Author Propagation Our Method Unsupervised First Post Post Position Translation Models &amp; LM Table 1: Summary of Some Solution Identification Techniquess The only unsupervised approach for the task, that from (Cong et al., 2008), uses a graph propagation method on a graph modeled using posts as</context>
<context position="24464" citStr="Catherine et al., 2012" startWordPosition="4004" endWordPosition="4007"> need to set it to slightly lower than 0.5, say 0.4. 4.3.4 Initialization K-Means clustering mostly initializes centroid vectors randomly; however, it is non-trivial to initialize the complex translation and language models randomly. Moreover, an initialization such that the SS and TS models favor the solution pairs more than the non-solution pairs is critical so that they may progressively lean towards modeling solution behaviour better across iterations. Towards this, we make use of a structural feature; in particular, adapting the hypothesis that solutions occur in the first N posts (Ref. (Catherine et al., 2012)), we label the pairs that have the the reply from the second post (note that the first post is assumed to be the problem post) in the thread as a solution 160 post, and all others as non-solution posts. Such an initialization along with uniform reply word source probabilities is used to learn the initial estimates of the SS, TS, SN and TN models to be used in the E-step for the first iteration. We will show that we are able to effectively perform solution identification using our approach by exploiting just one structural feature, the post position, as above. However, we will also show that w</context>
</contexts>
<marker>Catherine, Singh, Gangadharaiah, Raghu, Visweswariah, 2012</marker>
<rawString>Rose Catherine, Amit Singh, Rashmi Gangadharaiah, Dinesh Raghu, and Karthik Visweswariah. 2012. Does similarity matter? the case of answer extraction from technical discussion forums. In COLING (Posters), pages 175–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rose Catherine</author>
<author>Rashmi Gangadharaiah</author>
<author>Karthik Visweswariah</author>
<author>Dinesh Raghu</author>
</authors>
<title>Semisupervised answer extraction from discussion forums.</title>
<date>2013</date>
<booktitle>In IJCNLP.</booktitle>
<contexts>
<context position="4479" citStr="Catherine et al., 2013" startWordPosition="660" endWordPosition="663">cs, pages 155–164, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics reliable in solution identification in other kinds of discussion boards. (Catherine et al., 2012) reports a study that illustrates that non-solution posts are, on an average, as similar to the problem as solution posts in technical forums. The second assumption (i.e., (b) above) was also not seen to be useful in discussion forums since posts that are highly similar to other posts were seen to be complaints, repetitive content being more pervasive among complaint posts than solutions (Catherine et al., 2013). Having exhausted the two obvious textual features for solution identification, subsequent approaches have largely used the presence of lexical cues signifying solution-like narrative (e.g., instructive narratives such as ”check the router for any connection issues”) as the primary contentbased feature for solution identification. All solution identification approaches since (Cong et al., 2008) have used supervised methods that require training data in the form of labeled solution and non-solution posts. The techniques differ from one another mostly in the non-textual features that are employ</context>
<context position="7608" citStr="Catherine et al., 2013" startWordPosition="1140" endWordPosition="1143">g with language model based characterization of solution posts. We model the lexical correlation and solution post character using regularized translation models and unigram language models respectively. To keep our technique applicable across a large variety of forums with varying availability of non-textual features, we design it to be able to work with minimal availability of non-textual features. In particular, we show that by using post position as the only non-textual feature, we are able to achieve accuracies comparable to supervision-based approaches that use many structural features (Catherine et al., 2013). 2 Related Work In this section, we provide a brief overview of previous work related to our problem. Though most of the answer/solution identification approaches proposed so far in literature are supervised methods that require a labeled training corpus, there are a few that require limited or no supervision. Table 1 provides an overview of some of the more recent solution identification techniques from literature, with a focus on some features that we wish to highlight. The common observation that most problem-solving discussion threads have a problem description in the first post has been </context>
<context position="9422" citStr="Catherine et al., 2013" startWordPosition="1420" endWordPosition="1423">on Assumptions on Features other than Learning Problem Position Post Content Used Technique (Qu and Liu, 2011) Supervised First Post likely HMM assumes Naive Bayes to be problem solution follows problem &amp; HMM (Ding et al., 2008) Supervised First Post Post Position, Author, CRFs Context Posts (Kim et al., 2010) Supervised None Post Position, Author, MaxEnt, Previous Posts, Profile etc. SVM, CRF (Hong and Davison, 2009) Supervised First Post Post Position, Author, SVM Author Authority (Catherine et al., 2012) Supervised First Post Post Position, Author, Problem SVM Author’s activities wrt Post (Catherine et al., 2013) Limited First Post Post Position/Rating, Author, SVMs &amp; Supervision Author Rating, Post Ack Co-Training (Cong et al., 2008) Unsupervised None Author, Author Authority, Graph Relation to Problem Author Propagation Our Method Unsupervised First Post Post Position Translation Models &amp; LM Table 1: Summary of Some Solution Identification Techniquess The only unsupervised approach for the task, that from (Cong et al., 2008), uses a graph propagation method on a graph modeled using posts as vertices, and relies on the assumptions that posts that bear high similarity to the problem and other posts an</context>
<context position="26618" citStr="Catherine et al., 2013" startWordPosition="4383" endWordPosition="4386"> reply posts as B. Learning of the language and translation models in each iteration costs O(nb + B) and O(k&apos;(nab + AB)) respectively (assuming the translation model learning runs for k&apos; iterations). The E-step labeling and source estimation cost O(nab) each. For k iterations of our algorithm, this leads to an overall complexity of O(kk&apos;(nab + AB)). 5 Experimental Evaluation We use a crawl of 140k threads from Apple Discussion forums10. Out of these, 300 threads (comprising 1440 posts) were randomly chosen and each post was manually tagged as either solution or non-solution by the authors of (Catherine et al., 2013) (who were kind enough to share the data with us) with an inter-annotator agreement11 of 0.71. On an average, 40% of replies in each thread and 77% of first replies were seen to be solutions, 10http://discussions.apple.com 11http://en.wikipedia.org/wiki/Cohen’s kappa Figure 1: F% (Y) vs. #Iterations (X) ProblemWord, SolutionWord TS[p][s] network, guest 0.0754 connect, adaptor 0.0526 TS wireless, adaptor 0.0526 translat, shortcut 0.0492 updat, rebuilt 0.0405 SolutionWord SS[s] your 0.0115 SS try 0.0033 router 0.0033 see 0.0033 password 0.0023 Table 4: Sample TS and SS Estimates leading to an F-</context>
<context position="28675" citStr="Catherine et al., 2013" startWordPosition="4716" endWordPosition="4719">llback, 1997) as the similarity measure between posts; KL-Divergence was seen to perform best in the experiments reported in (Cong et al., 2008). Table 3 illustrates the comparative performance 12http://en.wikipedia.org/wiki/F1 score 161 Technique Precision Recall F-Measure Unsupervised Graph Propagation (Cong et al., 2008) 29.7 % 55.6 % 38.7 % Our Method with only Translation Models (A = 0.0) 41.8 % 86.8 % 56.5 % Our Method with only Language Models (A = 1.0) 63.2 % 62.1 % 62.6 % Our Method with Both Models (A = 0.5) 61.3 % 66.9 % 64.0 % ANS CT 40.6 % 88.0 % 55.6 % Methods using Supervision (Catherine et al., 2013) ANS-ACK PCT 56.8 % 84.1 % 67.8% Table 3: Quality Evaluation Figure 2: F% (Y) vs. λ (X) Figure 3: F% (Y) vs. τ (X) Figure 4: F% (Y) vs. ¢#Threads (X) on various quality metrics, of which F-Measure is typically considered most important. Our pureLM13 setting (i.e., A = 1) was seen to perform up to 6 F-Measure points better than the pure-TM14 setting (i.e., A = 0), whereas the uniform mix is seen to be able to harness both to give a 1.4 point (i.e., 2.2%) improvement over the pure-LM case. The comparison with the approach from (Cong et al., 2008) illustrates that our method is very clearly the s</context>
<context position="30730" citStr="Catherine et al., 2013" startWordPosition="5063" endWordPosition="5067">ance the solution-ness of a post. In the absence of author information (such as may be common in 13Language Model 14Translation Model privacy-constrained domains such as medical forums) and extrinsic information to enable identify acknowledgements, ANS CT is the only technique available. Our technique is seen to outperform ANS CT by a respectable margin (8.6 F-measure points) while trailing behind the enhanced ANSACK PCT method with a reasonably narrow 3.8 F-measure point margin. Thus, our unsupervised method is seen to be a strong competitor even for techniques using supervision outlined in (Catherine et al., 2013), illustrating the effectiveness of LM and TM modeling of reply posts. Across Iterations: For scenarios where computation is at a premium, it is useful to know how quickly the quality of solution identification stabilizes, so that the results can be collected after fewer iterations. Figure 1 plots the F-measure across iterations for the run with A = 0.5, T = 0.4 setting, where the F-measure is seen to stabilize in as few as 4-5 iterations. Similar trends were observed for other runs as well, confirming that the run may be stopped as early as after the fourth iteration without considerable loss</context>
</contexts>
<marker>Catherine, Gangadharaiah, Visweswariah, Raghu, 2013</marker>
<rawString>Rose Catherine, Rashmi Gangadharaiah, Karthik Visweswariah, and Dinesh Raghu. 2013. Semisupervised answer extraction from discussion forums. In IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gao Cong</author>
<author>Long Wang</author>
<author>Chin-Yew Lin</author>
<author>Young-In Song</author>
<author>Yueheng Sun</author>
</authors>
<title>Finding question-answer pairs from online forums.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>467--474</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2945" citStr="Cong et al., 2008" startWordPosition="428" endWordPosition="431">iption, identifying its solutions from among the other posts in the thread has been the focus of many recent efforts (e.g., (Gandhe et al., 2012; Hong and Davison, 2009)). Extracting problem-solution pairs from forums enables the usage of such knowledge in knowledge reuse frameworks such as case-based reasoning (Kolodner, 1992) that use problem-solution pairs as raw material. In this paper, we address the problem of unsupervised solution post identification7 from discussion forums. Among the first papers to address the solution identification problem was the unsupervised approach proposed by (Cong et al., 2008). It employs a graph propagation method that prioritizes posts that are (a) more similar to the problem post, (b) more similar to other posts, and (c) authored by a more authoritative user, to be labeled as solution posts. Though seen to be effective in identifying solutions from travel forums, the first two assumptions, (a) and (b), were seen to be not very 3http://www.cadillacforums.com/ 4https://discussions.apple.com/ 5http://www.galaxyforums.net/ 6We use problem and question, as well as solution and answer interchangeably in this paper. 7This problem has been referred to as answer extracti</context>
<context position="4877" citStr="Cong et al., 2008" startWordPosition="716" endWordPosition="719"> seen to be useful in discussion forums since posts that are highly similar to other posts were seen to be complaints, repetitive content being more pervasive among complaint posts than solutions (Catherine et al., 2013). Having exhausted the two obvious textual features for solution identification, subsequent approaches have largely used the presence of lexical cues signifying solution-like narrative (e.g., instructive narratives such as ”check the router for any connection issues”) as the primary contentbased feature for solution identification. All solution identification approaches since (Cong et al., 2008) have used supervised methods that require training data in the form of labeled solution and non-solution posts. The techniques differ from one another mostly in the non-textual features that are employed in representing posts. A variety of high precision assumptions such as solution post typically follows a problem post (Qu and Liu, 2011), solution posts are likely to be within the first few posts, solution posts are likely to have been acknowledged by the problem post author (Catherine et al., 2012), users with high authoritativeness are likely to author solutions (Hong and Davison, 2009), a</context>
<context position="9546" citStr="Cong et al., 2008" startWordPosition="1438" endWordPosition="1441">ost likely HMM assumes Naive Bayes to be problem solution follows problem &amp; HMM (Ding et al., 2008) Supervised First Post Post Position, Author, CRFs Context Posts (Kim et al., 2010) Supervised None Post Position, Author, MaxEnt, Previous Posts, Profile etc. SVM, CRF (Hong and Davison, 2009) Supervised First Post Post Position, Author, SVM Author Authority (Catherine et al., 2012) Supervised First Post Post Position, Author, Problem SVM Author’s activities wrt Post (Catherine et al., 2013) Limited First Post Post Position/Rating, Author, SVMs &amp; Supervision Author Rating, Post Ack Co-Training (Cong et al., 2008) Unsupervised None Author, Author Authority, Graph Relation to Problem Author Propagation Our Method Unsupervised First Post Post Position Translation Models &amp; LM Table 1: Summary of Some Solution Identification Techniquess The only unsupervised approach for the task, that from (Cong et al., 2008), uses a graph propagation method on a graph modeled using posts as vertices, and relies on the assumptions that posts that bear high similarity to the problem and other posts and those authored by authoritative users are more likely to be solution posts. Some of those assumptions, as mentioned in Sec</context>
<context position="27959" citStr="Cong et al., 2008" startWordPosition="4595" endWordPosition="4598">ion measure. While we vary the various parameters separately in order to evaluate the trends, we use a dataset of 800 threads (containing the 300 labeled threads) and set λ = 0.5 and T = 0.4 unless otherwise mentioned. Since we have only 300 labeled threads, accuracy measures are reported on those (like in (Catherine et al., 2013)). We pre-process the post data by stemming words (Porter, 1980). 5.1 Quality Evaluation In this study, we compare the performance of our method under varying settings of λ against the only unsupervised approach for solution identification from literature, that from (Cong et al., 2008). We use an independent implementation of the technique using Kullback-Leibler Divergence (Kullback, 1997) as the similarity measure between posts; KL-Divergence was seen to perform best in the experiments reported in (Cong et al., 2008). Table 3 illustrates the comparative performance 12http://en.wikipedia.org/wiki/F1 score 161 Technique Precision Recall F-Measure Unsupervised Graph Propagation (Cong et al., 2008) 29.7 % 55.6 % 38.7 % Our Method with only Translation Models (A = 0.0) 41.8 % 86.8 % 56.5 % Our Method with only Language Models (A = 1.0) 63.2 % 62.1 % 62.6 % Our Method with Both </context>
<context position="29225" citStr="Cong et al., 2008" startWordPosition="4820" endWordPosition="4823">6 % 88.0 % 55.6 % Methods using Supervision (Catherine et al., 2013) ANS-ACK PCT 56.8 % 84.1 % 67.8% Table 3: Quality Evaluation Figure 2: F% (Y) vs. λ (X) Figure 3: F% (Y) vs. τ (X) Figure 4: F% (Y) vs. ¢#Threads (X) on various quality metrics, of which F-Measure is typically considered most important. Our pureLM13 setting (i.e., A = 1) was seen to perform up to 6 F-Measure points better than the pure-TM14 setting (i.e., A = 0), whereas the uniform mix is seen to be able to harness both to give a 1.4 point (i.e., 2.2%) improvement over the pure-LM case. The comparison with the approach from (Cong et al., 2008) illustrates that our method is very clearly the superior method for solution identification outperforming the former by large margins on all the evaluation measures, with the improvement on Fmeasure being more than 25 points. Comparison wrt Methods from (Catherine et al., 2013): Table 3 also lists the performance of SVM-based methods from (Catherine et al., 2013) that use supervised information for solution identification, to help put the performance of our technique in perspective. Of the two methods therein, ANS CT is a more general method that uses two views (structural and lexical) of sol</context>
</contexts>
<marker>Cong, Wang, Lin, Song, Sun, 2008</marker>
<rawString>Gao Cong, Long Wang, Chin-Yew Lin, Young-In Song, and Yueheng Sun. 2008. Finding question-answer pairs from online forums. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pages 467–474. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Deepak</author>
<author>Karthik Visweswariah</author>
<author>Nirmalie Wiratunga</author>
<author>Sadiq Sani</author>
</authors>
<title>Two-part segmentation of text documents.</title>
<date>2012</date>
<booktitle>In CIKM,</booktitle>
<pages>793--802</pages>
<contexts>
<context position="11089" citStr="Deepak et al., 2012" startWordPosition="1678" endWordPosition="1681">edgement modeling so that posts that have been acknowledged positively may be favored for being labeled as solutions. We will use translation and language models in our method for solution identification. Usage of translation models for modeling the correlation between textual problems and solutions have been explored earlier starting from the answer retrieval work in (Xue et al., 2008) where new queries were conceptually expanded using the translation model to improve retrieval. Translation models were also seen to be useful in segmenting incident reports into the problem and solution parts (Deepak et al., 2012); we will use an adaptation of the generative model presented therein, for our solution extraction formulation. Entity-level translation models were recently shown to be useful in modeling correlations in QA archives (Singh, 2012). 3 Problem Definition Let a thread T from a discussion forum be made up of t posts. Since we assume, much like many other earlier papers, that the first post is the problem post, the task is to identify which among the remaining t − 1 posts are solutions. There could be multiple (most likely, different) solutions within the same thread. We may now model the thread T </context>
<context position="13193" citStr="Deepak et al., 2012" startWordPosition="2044" endWordPosition="2047">the problem part predicts the presence/absence of the second word in the solution part well. Though not yet harnessed for solution identification, the correlation assumption is not at all novel. Infact, the assumption that similar problems have similar solutions (of which the correlation assumption is an offshoot) forms the foundation of case-based reasoning systems (Kolodner, 1992), a kind of knowledge reuse systems that could be the natural consumers of problem-solution pairs mined from forums. The usage of translation models in QA retrieval (Xue et al., 2008; Singh, 2012) and segmentation (Deepak et al., 2012) were also motivated by the correlation assumption. We use an IBM Model 1 translation model (Brown et al., 1990) in our technique; simplistically, such a model m may be thought of as a 2-d associative array where the value m[w1][w2] is directly related to the probability of w1 occuring in the problem when w2 occurs in the solution. 4.2 Generative model for Solution Posts Consider a unigram language model SS that models the lexical characteristics of solution posts, and a translation model TS that models the lexical correlation between problems and solutions. Our generative model models the rep</context>
<context position="14614" citStr="Deepak et al., 2012" startWordPosition="2297" endWordPosition="2300"> Mult(SS) 3. Else, Choose w ∼ Mult(TSp ) where TSp denotes the multionomial distribution obtained from TS conditioned over the words in the post p; this is obtained by assigning each candidate solution word w a weight equal to avg{TS[w&apos;][w]|w&apos; E p}, and normalizing such weights across all solution words. In short, each solution word is assumed to be generated from the language model or the translation model (conditioned on the problem words) with a probability of A and 1 − A respectively, thus accounting for the correlation assumption. The generative model above is similar to the proposal in (Deepak et al., 2012), adapted suitably for our scenario. We model non-solution posts similarly with the sole difference being that they would be sampled from the analogous models SN and TN that characterize behavior of non-solution posts. Example: Consider the following illustrative example of a problem and solution post: • Problem: I am unable to surf the web on the BT public wifi. • Solution: Maybe, you should try disconnecting and rejoining the network. Of the solution words above, generic words such as try and should could probably be explained by (i.e., sampled from) the solution language model, whereas disc</context>
</contexts>
<marker>Deepak, Visweswariah, Wiratunga, Sani, 2012</marker>
<rawString>P. Deepak, Karthik Visweswariah, Nirmalie Wiratunga, and Sadiq Sani. 2012. Two-part segmentation of text documents. In CIKM, pages 793–802.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur P Dempster</author>
<author>Nan M Laird</author>
<author>Donald B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the em algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society. Series B (Methodological),</journal>
<pages>1--38</pages>
<contexts>
<context position="16129" citStr="Dempster et al., 1977" startWordPosition="2555" endWordPosition="2558">olution cluster. The objective function that we seek to maximize is the following: F((p, r), SS, TS) if label((p,r))=S (p,r)EC F((p, r), SN, TN) if label((p,r))=N (1) F((p, r), S, T) indicates the conformance of the (p, r) pair (details in Section 4.3.1) with the generative model that uses the S and T models as the language and translation models respectively. The clustering based approach labels each (p, r) pair as either solution (i.e., S) or non-solution (i.e., N). Since we do not know the models or the labelings to start with, we use an iterative approach modeled on the EM meta-algorithm (Dempster et al., 1977) involving iterations, each comprising of an E-step followed by the M-step. For simplicity and brevity, instead of deriving the EM formulation, we illustrate our approach by making an analogy with the popular K-Means clustering (MacQueen, 1967) algorithm that also uses the EM formulation and crisp assignments of data points like we do. K-Means is a clustering algorithm that clusters objects represented as multi-dimensional points into k clusters where each cluster is represented by the centroid of all its members. Each iteration in K-Means starts off with assigning each 158 In K-Means In Our A</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Arthur P Dempster, Nan M Laird, and Donald B Rubin. 1977. Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society. Series B (Methodological), pages 1– 38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shilin Ding</author>
<author>Gao Cong</author>
<author>Chin-Yew Lin</author>
<author>Xianyan Zhu</author>
</authors>
<title>Using conditional random fields to extract contexts and answers of questions from online forums.</title>
<date>2008</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="9027" citStr="Ding et al., 2008" startWordPosition="1362" endWordPosition="1365"> identification. Most techniques use a variety of such features as noted in Section 1. SVMs have been the most popular method for supervised and semi-supervised learning for the task of solution identification. Of particular interest to us are approaches that use limited or no supervision, since we focus on unsupervised solution identification in this paper. 156 Paper Reference Supervision Assumptions on Features other than Learning Problem Position Post Content Used Technique (Qu and Liu, 2011) Supervised First Post likely HMM assumes Naive Bayes to be problem solution follows problem &amp; HMM (Ding et al., 2008) Supervised First Post Post Position, Author, CRFs Context Posts (Kim et al., 2010) Supervised None Post Position, Author, MaxEnt, Previous Posts, Profile etc. SVM, CRF (Hong and Davison, 2009) Supervised First Post Post Position, Author, SVM Author Authority (Catherine et al., 2012) Supervised First Post Post Position, Author, Problem SVM Author’s activities wrt Post (Catherine et al., 2013) Limited First Post Post Position/Rating, Author, SVMs &amp; Supervision Author Rating, Post Ack Co-Training (Cong et al., 2008) Unsupervised None Author, Author Authority, Graph Relation to Problem Author Pro</context>
</contexts>
<marker>Ding, Cong, Lin, Zhu, 2008</marker>
<rawString>Shilin Ding, Gao Cong, Chin-Yew Lin, and Xianyan Zhu. 2008. Using conditional random fields to extract contexts and answers of questions from online forums. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ankur Gandhe</author>
<author>Dinesh Raghu</author>
<author>Rose Catherine</author>
</authors>
<title>Domain adaptive answer extraction for discussion boards.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference companion on World Wide Web,</booktitle>
<pages>501--502</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2471" citStr="Gandhe et al., 2012" startWordPosition="358" endWordPosition="361">/problem6 to which other users respond. Typical response posts include solutions or clarification requests, whereas feedback posts form another major category of forum posts. As is the case with any community of humans, discussion forums have their share of inflammatory remarks too. Mining problem-solution pairs from discussion forums has attracted much attention from the scholarly community in the recent past. Since the first post most usually contains the problem description, identifying its solutions from among the other posts in the thread has been the focus of many recent efforts (e.g., (Gandhe et al., 2012; Hong and Davison, 2009)). Extracting problem-solution pairs from forums enables the usage of such knowledge in knowledge reuse frameworks such as case-based reasoning (Kolodner, 1992) that use problem-solution pairs as raw material. In this paper, we address the problem of unsupervised solution post identification7 from discussion forums. Among the first papers to address the solution identification problem was the unsupervised approach proposed by (Cong et al., 2008). It employs a graph propagation method that prioritizes posts that are (a) more similar to the problem post, (b) more similar</context>
</contexts>
<marker>Gandhe, Raghu, Catherine, 2012</marker>
<rawString>Ankur Gandhe, Dinesh Raghu, and Rose Catherine. 2012. Domain adaptive answer extraction for discussion boards. In Proceedings of the 21st international conference companion on World Wide Web, pages 501–502. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liangjie Hong</author>
<author>Brian D Davison</author>
</authors>
<title>A classification-based approach to question answering in discussion boards.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>171--178</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2496" citStr="Hong and Davison, 2009" startWordPosition="362" endWordPosition="365">her users respond. Typical response posts include solutions or clarification requests, whereas feedback posts form another major category of forum posts. As is the case with any community of humans, discussion forums have their share of inflammatory remarks too. Mining problem-solution pairs from discussion forums has attracted much attention from the scholarly community in the recent past. Since the first post most usually contains the problem description, identifying its solutions from among the other posts in the thread has been the focus of many recent efforts (e.g., (Gandhe et al., 2012; Hong and Davison, 2009)). Extracting problem-solution pairs from forums enables the usage of such knowledge in knowledge reuse frameworks such as case-based reasoning (Kolodner, 1992) that use problem-solution pairs as raw material. In this paper, we address the problem of unsupervised solution post identification7 from discussion forums. Among the first papers to address the solution identification problem was the unsupervised approach proposed by (Cong et al., 2008). It employs a graph propagation method that prioritizes posts that are (a) more similar to the problem post, (b) more similar to other posts, and (c) </context>
<context position="5474" citStr="Hong and Davison, 2009" startWordPosition="812" endWordPosition="815"> since (Cong et al., 2008) have used supervised methods that require training data in the form of labeled solution and non-solution posts. The techniques differ from one another mostly in the non-textual features that are employed in representing posts. A variety of high precision assumptions such as solution post typically follows a problem post (Qu and Liu, 2011), solution posts are likely to be within the first few posts, solution posts are likely to have been acknowledged by the problem post author (Catherine et al., 2012), users with high authoritativeness are likely to author solutions (Hong and Davison, 2009), and so on have been seen to be useful in solution identification. Being supervised methods, the above assumptions are implicitly factored in by including the appropriate feature (e.g., post position in thread) in the feature space so that the learner may learn the correlation (e.g., solution posts typically are among the first few posts) using the training data. Though such assumptions on structural features, if generic enough, may be built into unsupervised techniques to aid solution identification, the variation in availability of such features across forums limits the usage of models that</context>
<context position="9220" citStr="Hong and Davison, 2009" startWordPosition="1391" endWordPosition="1394">lution identification. Of particular interest to us are approaches that use limited or no supervision, since we focus on unsupervised solution identification in this paper. 156 Paper Reference Supervision Assumptions on Features other than Learning Problem Position Post Content Used Technique (Qu and Liu, 2011) Supervised First Post likely HMM assumes Naive Bayes to be problem solution follows problem &amp; HMM (Ding et al., 2008) Supervised First Post Post Position, Author, CRFs Context Posts (Kim et al., 2010) Supervised None Post Position, Author, MaxEnt, Previous Posts, Profile etc. SVM, CRF (Hong and Davison, 2009) Supervised First Post Post Position, Author, SVM Author Authority (Catherine et al., 2012) Supervised First Post Post Position, Author, Problem SVM Author’s activities wrt Post (Catherine et al., 2013) Limited First Post Post Position/Rating, Author, SVMs &amp; Supervision Author Rating, Post Ack Co-Training (Cong et al., 2008) Unsupervised None Author, Author Authority, Graph Relation to Problem Author Propagation Our Method Unsupervised First Post Post Position Translation Models &amp; LM Table 1: Summary of Some Solution Identification Techniquess The only unsupervised approach for the task, that </context>
</contexts>
<marker>Hong, Davison, 2009</marker>
<rawString>Liangjie Hong and Brian D Davison. 2009. A classification-based approach to question answering in discussion boards. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, pages 171– 178. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Li Wang</author>
<author>Timothy Baldwin</author>
</authors>
<title>Tagging and linking web forum posts.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>192--202</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9110" citStr="Kim et al., 2010" startWordPosition="1375" endWordPosition="1378">1. SVMs have been the most popular method for supervised and semi-supervised learning for the task of solution identification. Of particular interest to us are approaches that use limited or no supervision, since we focus on unsupervised solution identification in this paper. 156 Paper Reference Supervision Assumptions on Features other than Learning Problem Position Post Content Used Technique (Qu and Liu, 2011) Supervised First Post likely HMM assumes Naive Bayes to be problem solution follows problem &amp; HMM (Ding et al., 2008) Supervised First Post Post Position, Author, CRFs Context Posts (Kim et al., 2010) Supervised None Post Position, Author, MaxEnt, Previous Posts, Profile etc. SVM, CRF (Hong and Davison, 2009) Supervised First Post Post Position, Author, SVM Author Authority (Catherine et al., 2012) Supervised First Post Post Position, Author, Problem SVM Author’s activities wrt Post (Catherine et al., 2013) Limited First Post Post Position/Rating, Author, SVMs &amp; Supervision Author Rating, Post Ack Co-Training (Cong et al., 2008) Unsupervised None Author, Author Authority, Graph Relation to Problem Author Propagation Our Method Unsupervised First Post Post Position Translation Models &amp; LM T</context>
</contexts>
<marker>Kim, Wang, Baldwin, 2010</marker>
<rawString>Su Nam Kim, Li Wang, and Timothy Baldwin. 2010. Tagging and linking web forum posts. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 192–202. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet L Kolodner</author>
</authors>
<title>An introduction to case-based reasoning.</title>
<date>1992</date>
<journal>Artificial Intelligence Review,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="2656" citStr="Kolodner, 1992" startWordPosition="386" endWordPosition="388"> with any community of humans, discussion forums have their share of inflammatory remarks too. Mining problem-solution pairs from discussion forums has attracted much attention from the scholarly community in the recent past. Since the first post most usually contains the problem description, identifying its solutions from among the other posts in the thread has been the focus of many recent efforts (e.g., (Gandhe et al., 2012; Hong and Davison, 2009)). Extracting problem-solution pairs from forums enables the usage of such knowledge in knowledge reuse frameworks such as case-based reasoning (Kolodner, 1992) that use problem-solution pairs as raw material. In this paper, we address the problem of unsupervised solution post identification7 from discussion forums. Among the first papers to address the solution identification problem was the unsupervised approach proposed by (Cong et al., 2008). It employs a graph propagation method that prioritizes posts that are (a) more similar to the problem post, (b) more similar to other posts, and (c) authored by a more authoritative user, to be labeled as solution posts. Though seen to be effective in identifying solutions from travel forums, the first two a</context>
<context position="12958" citStr="Kolodner, 1992" startWordPosition="2008" endWordPosition="2009">tion of lexical correlation between the problem and solution 8http://en.wikipedia.org/wiki/F1 score 157 texts. At the word level, this translates to assuming that there exist word pairs such that the presence of the first word in the problem part predicts the presence/absence of the second word in the solution part well. Though not yet harnessed for solution identification, the correlation assumption is not at all novel. Infact, the assumption that similar problems have similar solutions (of which the correlation assumption is an offshoot) forms the foundation of case-based reasoning systems (Kolodner, 1992), a kind of knowledge reuse systems that could be the natural consumers of problem-solution pairs mined from forums. The usage of translation models in QA retrieval (Xue et al., 2008; Singh, 2012) and segmentation (Deepak et al., 2012) were also motivated by the correlation assumption. We use an IBM Model 1 translation model (Brown et al., 1990) in our technique; simplistically, such a model m may be thought of as a 2-d associative array where the value m[w1][w2] is directly related to the probability of w1 occuring in the problem when w2 occurs in the solution. 4.2 Generative model for Soluti</context>
</contexts>
<marker>Kolodner, 1992</marker>
<rawString>Janet L Kolodner. 1992. An introduction to case-based reasoning. Artificial Intelligence Review, 6(1):3–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Solomon Kullback</author>
</authors>
<title>Information theory and statistics.</title>
<date>1997</date>
<publisher>Courier Dover Publications.</publisher>
<contexts>
<context position="28065" citStr="Kullback, 1997" startWordPosition="4611" endWordPosition="4612">t of 800 threads (containing the 300 labeled threads) and set λ = 0.5 and T = 0.4 unless otherwise mentioned. Since we have only 300 labeled threads, accuracy measures are reported on those (like in (Catherine et al., 2013)). We pre-process the post data by stemming words (Porter, 1980). 5.1 Quality Evaluation In this study, we compare the performance of our method under varying settings of λ against the only unsupervised approach for solution identification from literature, that from (Cong et al., 2008). We use an independent implementation of the technique using Kullback-Leibler Divergence (Kullback, 1997) as the similarity measure between posts; KL-Divergence was seen to perform best in the experiments reported in (Cong et al., 2008). Table 3 illustrates the comparative performance 12http://en.wikipedia.org/wiki/F1 score 161 Technique Precision Recall F-Measure Unsupervised Graph Propagation (Cong et al., 2008) 29.7 % 55.6 % 38.7 % Our Method with only Translation Models (A = 0.0) 41.8 % 86.8 % 56.5 % Our Method with only Language Models (A = 1.0) 63.2 % 62.1 % 62.6 % Our Method with Both Models (A = 0.5) 61.3 % 66.9 % 64.0 % ANS CT 40.6 % 88.0 % 55.6 % Methods using Supervision (Catherine et </context>
</contexts>
<marker>Kullback, 1997</marker>
<rawString>Solomon Kullback. 1997. Information theory and statistics. Courier Dover Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James MacQueen</author>
</authors>
<title>Some methods for classification and analysis of multivariate observations.</title>
<date>1967</date>
<booktitle>In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability,</booktitle>
<volume>1</volume>
<pages>14</pages>
<location>California, USA.</location>
<contexts>
<context position="16373" citStr="MacQueen, 1967" startWordPosition="2595" endWordPosition="2597">.1) with the generative model that uses the S and T models as the language and translation models respectively. The clustering based approach labels each (p, r) pair as either solution (i.e., S) or non-solution (i.e., N). Since we do not know the models or the labelings to start with, we use an iterative approach modeled on the EM meta-algorithm (Dempster et al., 1977) involving iterations, each comprising of an E-step followed by the M-step. For simplicity and brevity, instead of deriving the EM formulation, we illustrate our approach by making an analogy with the popular K-Means clustering (MacQueen, 1967) algorithm that also uses the EM formulation and crisp assignments of data points like we do. K-Means is a clustering algorithm that clusters objects represented as multi-dimensional points into k clusters where each cluster is represented by the centroid of all its members. Each iteration in K-Means starts off with assigning each 158 In K-Means In Our Approach Data Multi-dimensional Points (p, r) pairs Cluster Model Respective Centroid Vector Respective S and T Models for each cluster Initialization Random Choice of Centroids Models learnt using (p, r) pairs labeled using the Post Position of</context>
</contexts>
<marker>MacQueen, 1967</marker>
<rawString>James MacQueen. 1967. Some methods for classification and analysis of multivariate observations. In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability, volume 1, page 14. California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin F Porter</author>
</authors>
<title>An algorithm for suffix stripping. Program: electronic library and information systems,</title>
<date>1980</date>
<pages>14--3</pages>
<contexts>
<context position="27737" citStr="Porter, 1980" startWordPosition="4562" endWordPosition="4563"> router 0.0033 see 0.0033 password 0.0023 Table 4: Sample TS and SS Estimates leading to an F-measure of 53% for our initialization heuristic. We use the F-measure12 for solution identification, as the primary evaluation measure. While we vary the various parameters separately in order to evaluate the trends, we use a dataset of 800 threads (containing the 300 labeled threads) and set λ = 0.5 and T = 0.4 unless otherwise mentioned. Since we have only 300 labeled threads, accuracy measures are reported on those (like in (Catherine et al., 2013)). We pre-process the post data by stemming words (Porter, 1980). 5.1 Quality Evaluation In this study, we compare the performance of our method under varying settings of λ against the only unsupervised approach for solution identification from literature, that from (Cong et al., 2008). We use an independent implementation of the technique using Kullback-Leibler Divergence (Kullback, 1997) as the similarity measure between posts; KL-Divergence was seen to perform best in the experiments reported in (Cong et al., 2008). Table 3 illustrates the comparative performance 12http://en.wikipedia.org/wiki/F1 score 161 Technique Precision Recall F-Measure Unsupervis</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Martin F Porter. 1980. An algorithm for suffix stripping. Program: electronic library and information systems, 14(3):130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhonghua Qu</author>
<author>Yang Liu</author>
</authors>
<title>Finding problem solving threads in online forum.</title>
<date>2011</date>
<booktitle>In IJCNLP,</booktitle>
<pages>1413--1417</pages>
<contexts>
<context position="5218" citStr="Qu and Liu, 2011" startWordPosition="771" endWordPosition="774">he presence of lexical cues signifying solution-like narrative (e.g., instructive narratives such as ”check the router for any connection issues”) as the primary contentbased feature for solution identification. All solution identification approaches since (Cong et al., 2008) have used supervised methods that require training data in the form of labeled solution and non-solution posts. The techniques differ from one another mostly in the non-textual features that are employed in representing posts. A variety of high precision assumptions such as solution post typically follows a problem post (Qu and Liu, 2011), solution posts are likely to be within the first few posts, solution posts are likely to have been acknowledged by the problem post author (Catherine et al., 2012), users with high authoritativeness are likely to author solutions (Hong and Davison, 2009), and so on have been seen to be useful in solution identification. Being supervised methods, the above assumptions are implicitly factored in by including the appropriate feature (e.g., post position in thread) in the feature space so that the learner may learn the correlation (e.g., solution posts typically are among the first few posts) us</context>
<context position="8909" citStr="Qu and Liu, 2011" startWordPosition="1342" endWordPosition="1345">for solution identification since author relations between problem and other posts provide valuable cues for solution identification. Most techniques use a variety of such features as noted in Section 1. SVMs have been the most popular method for supervised and semi-supervised learning for the task of solution identification. Of particular interest to us are approaches that use limited or no supervision, since we focus on unsupervised solution identification in this paper. 156 Paper Reference Supervision Assumptions on Features other than Learning Problem Position Post Content Used Technique (Qu and Liu, 2011) Supervised First Post likely HMM assumes Naive Bayes to be problem solution follows problem &amp; HMM (Ding et al., 2008) Supervised First Post Post Position, Author, CRFs Context Posts (Kim et al., 2010) Supervised None Post Position, Author, MaxEnt, Previous Posts, Profile etc. SVM, CRF (Hong and Davison, 2009) Supervised First Post Post Position, Author, SVM Author Authority (Catherine et al., 2012) Supervised First Post Post Position, Author, Problem SVM Author’s activities wrt Post (Catherine et al., 2013) Limited First Post Post Position/Rating, Author, SVMs &amp; Supervision Author Rating, Pos</context>
</contexts>
<marker>Qu, Liu, 2011</marker>
<rawString>Zhonghua Qu and Yang Liu. 2011. Finding problem solving threads in online forum. In IJCNLP, pages 1413–1417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jangwon Seo</author>
<author>W Bruce Croft</author>
<author>David A Smith</author>
</authors>
<title>Online community search using thread structure.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM conference on Information and knowledge management,</booktitle>
<pages>1907--1910</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="6210" citStr="Seo et al., 2009" startWordPosition="924" endWordPosition="927"> implicitly factored in by including the appropriate feature (e.g., post position in thread) in the feature space so that the learner may learn the correlation (e.g., solution posts typically are among the first few posts) using the training data. Though such assumptions on structural features, if generic enough, may be built into unsupervised techniques to aid solution identification, the variation in availability of such features across forums limits the usage of models that rely heavily on structural features. For example, some forums employ chronological order based flattening of threads (Seo et al., 2009) making reply-to information unavailable; models that harness reply-to features would then have limited utility on identifying solutions within such flattened threads. On medical forums, privacy considerations may force forum data to be dumped without author information, making a host of author-id based features unavailable. On datasets that contain data from across forums, the model may have to be aware of the absence of certain features in subsets of the data, or be modeled using features that are available on all threads. Our Contribution: We propose an unsupervised method for solution iden</context>
</contexts>
<marker>Seo, Croft, Smith, 2009</marker>
<rawString>Jangwon Seo, W Bruce Croft, and David A Smith. 2009. Online community search using thread structure. In Proceedings of the 18th ACM conference on Information and knowledge management, pages 1907–1910. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Singh</author>
</authors>
<title>Entity based q&amp;a retrieval.</title>
<date>2012</date>
<booktitle>In EMNLP-CoNLL,</booktitle>
<pages>1266--1277</pages>
<contexts>
<context position="11319" citStr="Singh, 2012" startWordPosition="1715" endWordPosition="1716">odeling the correlation between textual problems and solutions have been explored earlier starting from the answer retrieval work in (Xue et al., 2008) where new queries were conceptually expanded using the translation model to improve retrieval. Translation models were also seen to be useful in segmenting incident reports into the problem and solution parts (Deepak et al., 2012); we will use an adaptation of the generative model presented therein, for our solution extraction formulation. Entity-level translation models were recently shown to be useful in modeling correlations in QA archives (Singh, 2012). 3 Problem Definition Let a thread T from a discussion forum be made up of t posts. Since we assume, much like many other earlier papers, that the first post is the problem post, the task is to identify which among the remaining t − 1 posts are solutions. There could be multiple (most likely, different) solutions within the same thread. We may now model the thread T as t − 1 post pairs, each pair having the problem post as the first element, and one of the t − 1 remaining posts (i.e., reply posts in T) as the second element. Let C = {(p1, r1), (p2, r2), . . . , (p,,,, r,,,)} be the set of suc</context>
<context position="13154" citStr="Singh, 2012" startWordPosition="2040" endWordPosition="2041"> presence of the first word in the problem part predicts the presence/absence of the second word in the solution part well. Though not yet harnessed for solution identification, the correlation assumption is not at all novel. Infact, the assumption that similar problems have similar solutions (of which the correlation assumption is an offshoot) forms the foundation of case-based reasoning systems (Kolodner, 1992), a kind of knowledge reuse systems that could be the natural consumers of problem-solution pairs mined from forums. The usage of translation models in QA retrieval (Xue et al., 2008; Singh, 2012) and segmentation (Deepak et al., 2012) were also motivated by the correlation assumption. We use an IBM Model 1 translation model (Brown et al., 1990) in our technique; simplistically, such a model m may be thought of as a 2-d associative array where the value m[w1][w2] is directly related to the probability of w1 occuring in the problem when w2 occurs in the solution. 4.2 Generative model for Solution Posts Consider a unigram language model SS that models the lexical characteristics of solution posts, and a translation model TS that models the lexical correlation between problems and solutio</context>
</contexts>
<marker>Singh, 2012</marker>
<rawString>Amit Singh. 2012. Entity based q&amp;a retrieval. In EMNLP-CoNLL, pages 1266–1277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaobing Xue</author>
<author>Jiwoon Jeon</author>
<author>W Bruce Croft</author>
</authors>
<title>Retrieval models for question and answer archives.</title>
<date>2008</date>
<booktitle>In SIGIR,</booktitle>
<pages>475--482</pages>
<contexts>
<context position="10858" citStr="Xue et al., 2008" startWordPosition="1643" endWordPosition="1646">pproach presented in (Catherine et al., 2013) uses a few labeled threads to bootstrap SVM based learners which are then co-trained in an iterative fashion. In addition to various features explored in literature, they use acknowledgement modeling so that posts that have been acknowledged positively may be favored for being labeled as solutions. We will use translation and language models in our method for solution identification. Usage of translation models for modeling the correlation between textual problems and solutions have been explored earlier starting from the answer retrieval work in (Xue et al., 2008) where new queries were conceptually expanded using the translation model to improve retrieval. Translation models were also seen to be useful in segmenting incident reports into the problem and solution parts (Deepak et al., 2012); we will use an adaptation of the generative model presented therein, for our solution extraction formulation. Entity-level translation models were recently shown to be useful in modeling correlations in QA archives (Singh, 2012). 3 Problem Definition Let a thread T from a discussion forum be made up of t posts. Since we assume, much like many other earlier papers, </context>
<context position="13140" citStr="Xue et al., 2008" startWordPosition="2036" endWordPosition="2039">airs such that the presence of the first word in the problem part predicts the presence/absence of the second word in the solution part well. Though not yet harnessed for solution identification, the correlation assumption is not at all novel. Infact, the assumption that similar problems have similar solutions (of which the correlation assumption is an offshoot) forms the foundation of case-based reasoning systems (Kolodner, 1992), a kind of knowledge reuse systems that could be the natural consumers of problem-solution pairs mined from forums. The usage of translation models in QA retrieval (Xue et al., 2008; Singh, 2012) and segmentation (Deepak et al., 2012) were also motivated by the correlation assumption. We use an IBM Model 1 translation model (Brown et al., 1990) in our technique; simplistically, such a model m may be thought of as a 2-d associative array where the value m[w1][w2] is directly related to the probability of w1 occuring in the problem when w2 occurs in the solution. 4.2 Generative model for Solution Posts Consider a unigram language model SS that models the lexical characteristics of solution posts, and a translation model TS that models the lexical correlation between proble</context>
</contexts>
<marker>Xue, Jeon, Croft, 2008</marker>
<rawString>Xiaobing Xue, Jiwoon Jeon, and W. Bruce Croft. 2008. Retrieval models for question and answer archives. In SIGIR, pages 475–482.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>