<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010347">
<title confidence="0.991478">
A robust and extensible exemplar-based model of thematic fit
</title>
<author confidence="0.999025">
Bram Vandekerckhovea, Dominiek Sandraa, Walter Daelemansb
</author>
<affiliation confidence="0.880041333333333">
aCenter for Psycholinguistics, bCenter for Dutch Language and Speech (CNTS)
University of Antwerp
Antwerp, Belgium
</affiliation>
<email confidence="0.998457">
{bram.vandekerckhove,dominiek.sandra,walter.daelemans}@ua.ac.be
</email>
<sectionHeader confidence="0.997383" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999898095238095">
This paper presents a new, exemplar-based
model of thematic fit. In contrast to pre-
vious models, it does not approximate
thematic fit as argument plausibility or
‘fit with verb selectional preferences’, but
directly as semantic role plausibility for
a verb-argument pair, through similarity-
based generalization from previously seen
verb-argument pairs. This makes the
model very robust for data sparsity. We
argue that the model is easily extensible to
a model of semantic role ambiguity reso-
lution during online sentence comprehen-
sion.
The model is evaluated on human seman-
tic role plausibility judgments. Its predic-
tions correlate significantly with the hu-
man judgments. It rivals two state-of-the-
art models of thematic fit and exceeds their
performance on previously unseen or low-
frequency items.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999937631578948">
Thematic fit (or semantic role plausibility) is the
plausibility of a noun phrase referent playing a
specific semantic role (like agent or patient) in
the event denoted by a verbal predicate, e.g. the
plausibility that a judge sentences someone (which
makes the judge the agent of the sentencing event)
or that a judge is sentenced him- or herself (which
makes the judge the patient). Thematic fit has been
an important concept in psycholinguistics as a pre-
dictor variable in models of human sentence com-
prehension, either to discriminate between pos-
sible structural analyses during initial processing
in constraint-based models (see MacDonald and
Seidenberg (2006) for a recent overview), or af-
ter initial syntactic processing in modular models
(e.g. Frazier (1987)). In fact, thematic fit is at the
core of the most-studied of all structural ambiguity
phenomena, the ambiguity between a main clause
or a reduced relative clause interpretation of an NP
verb-ed sequence (the MV/RR ambiguity), which
is essentially a semantic role ambiguity. If the
temporarily ambiguous sentence The judge sen-
tenced ... is continued as a main clause (e.g. The
judge sentenced him to 10 years in prison), the
noun phrase the judge would be the agent of the
verb sentenced, while it would be the patient of
sentenced in a reduced relative clause continuation
(e.g. The judge sentenced to 4 years in prison for
indecent exposure could also lose his state pen-
sion). Apart from its importance in psycholinguis-
tics, the concept of thematic fit is also relevant for
computational linguistics in general (see Pad´o et
al. (2007) for some examples).
A number of models that try to capture hu-
man thematic fit preferences have been developed
in recent years (Resnik, 1996; Pad´o et al., 2006;
Pad´o et al., 2007). These previous approaches rely
on the linguistic notion of verb selectional pref-
erences. The plausibility that an argument plays
a specific semantic role in the event denoted by
a verb—in other words, that a verb, role and argu-
ment occur together—is predicted by how well the
argument head fits the restrictions that the verb im-
poses on the argument candidates for the semantic
role slot under consideration (e.g. eat prefers ed-
ible arguments to fill its patient slot). Therefore,
what these models capture is actually not seman-
tic role plausibility, but argument plausibility.
The model presented here takes a different ap-
proach. Instead of predicting the plausibility of an
argument given a verb-role pair (e.g. the plausi-
bility of judge given sentence-patient), it predicts
the plausibility of a semantic role given a verb-
argument pair (e.g. the plausibility of patient given
sentence-judge), through similarity-based general-
ization from previously seen verb-argument pairs.
In the context of modeling thematic fit as a con-
</bodyText>
<note confidence="0.9229525">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 826–834,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.997956">
826
</page>
<bodyText confidence="0.99990737037037">
straint in the resolution of sentence-level ambigu-
ity problems like the MV/RR ambiguity, predict-
ing role fit instead of argument fit seems to be the
most straightforward approach. After all, when
thematic fit is approached in this way, the model
directly captures the semantic role ambiguity that
is at stake during the analysis of sentences that are
temporarily ambiguous between a main clause and
a reduced relative interpretation. This means that
our model of thematic fit should be very easy to
extend into a full-blown model of the resolution
of any sentence-level ambiguity that crucially re-
volves around a semantic role ambiguity. In ad-
dition, the fact that it generalizes from previously
seen verb-argument pairs, based on their similarity
to the target pair, should make it more robust than
previous approaches.
The remainder of the paper is organized as fol-
lows: in the next section, we briefly discuss two
state-of-the-art thematic fit models, the perfor-
mance of which will be compared to that of our
model. Section 3 introduces three different instan-
tiations of our model. The evaluation of the model
and the comparison of its performance with that of
the models discussed in Section 2 is presented in
Section 4. Section 5 ties everything together with
some general conclusions.
</bodyText>
<sectionHeader confidence="0.971191" genericHeader="method">
2 Previous models
</sectionHeader>
<bodyText confidence="0.999956">
In this section of the paper, we look at two state-of-
the-art models of thematic fit, developed by Pad´o
et al. (2006) and Pad´o et al. (2007). We will
not discuss the selectional preferences model of
Resnik (1996), but for a comparison between the
Resnik model and the Pad´o models, see Pad´o et al.
(2007).
</bodyText>
<subsectionHeader confidence="0.996838">
2.1 Pad´o et al. (2006)
</subsectionHeader>
<bodyText confidence="0.999989571428571">
In their model of thematic fit, Pad´o et al. (2006)
use FrameNet thematic roles (Fillmore et al.,
2003) to approximate semantic roles. The the-
matic fit of a verb-role-argument triple (v, r, a) is
given by the joint probability of the role r, the ar-
gument headword a, the verb sense vs, and the
grammatical function gf of a:
</bodyText>
<equation confidence="0.903746">
Plausibilityv,r,a = P(vs, r, a, gf) (1)
</equation>
<bodyText confidence="0.998699">
Since computing this joint probability from cor-
pus co-occurrence frequencies is problematic due
to an obvious sparse data issue, the term is
decomposed into several subterms, including a
term P(a|vs, gf, r) that captures selectional pref-
erences. Good-Turing and class-based smoothing
are used to further alleviate the remaining sparse
data problem, but because of the fact that the
model can only make predictions for verbs that oc-
cur in the small FrameNet corpus, for a large num-
ber of verbs, it cannot provide any output. For the
verbs that do occur in the training corpus, how-
ever, the model’s predictions correlate very well
with human plausibility ratings.
</bodyText>
<subsectionHeader confidence="0.998296">
2.2 Pad´o et al. (2007)
</subsectionHeader>
<bodyText confidence="0.999882571428571">
The model of Pad´o et al. (2007) does not use se-
mantically annotated resources, but approximates
the agent and patient relations with the syntac-
tic subject and object relations, respectively. The
plausibility of a verb-role-argument triple (v, r, a)
is found by calculating the weighted mean seman-
tic similarity of the argument headword a to all
headwords that have previously been seen together
with the verb-role pair (v, r), as shown in Equa-
tion 2. The prediction is that high semantic sim-
ilarity of a target headword a to seen headwords
for a given (v, r) tuple corresponds to high the-
matic fit of the (v, r, a) tuple, while low similarity
implies low thematic fit.
</bodyText>
<equation confidence="0.997556">
Plausibilityv,r,a =
w(a&apos;) x sim(a, a&apos;) (2)
|5eenr(v)|
</equation>
<bodyText confidence="0.999925809523809">
w(a&apos;) is the weighting factor. Pad´o et al. (2007)
used the frequency of the previously seen ar-
gument headwords as weights. Similarity be-
tween headwords was defined as the cosine be-
tween so-called ‘dependency vector’ representa-
tions of these headwords (Pad´o and Lapata, 2007).
These vectors are constructed from the frequency
counts with which the target items occur at one
end of specific paths in a corpus of syntactic de-
pendency trees. The argument headword vectors
Pad´o et al. (2007) used in their experiments con-
sisted of 2000 features, representing the most fre-
quent (head, subject) and (head, object) pairs in
the British National Corpus (BNC). The feature-
values of the headword vectors were the log-
likelihoods of the headwords occurring at the de-
pendent end of these (relation, head) pairs (so
either as subjects or objects of the heads). The
model’s performance approaches that of the Pad´o
et al. (2006) model on the correlation of its predic-
tions with human ratings, and it attains higher cov-
</bodyText>
<equation confidence="0.815753">
�
a&apos;ESeen,(v)
</equation>
<page confidence="0.978252">
827
</page>
<bodyText confidence="0.999912428571429">
erage (it can provide plausibility values for a larger
proportion of the test items), since the model only
requires that the verb occurs with subject and ob-
ject arguments in the training corpus, and that the
target argument headwords occur in the training
data frequently enough to attain reliable depen-
dency vectors.
</bodyText>
<sectionHeader confidence="0.9657515" genericHeader="method">
3 Exemplar-based modeling of thematic
fit
</sectionHeader>
<bodyText confidence="0.999750029850746">
Exemplar-based models of cognition (also known
as Memory-Based Learning or instance/case-
based reasoning/learning models) (Fix and
Hodges, 1951; Cover and Hart, 1967; Daelemans
and van den Bosch, 2005) are classification
models that extrapolate their behavior from stored
representations of earlier experiences to new
situations, based on the similarity of the old and
the new situation. These models keep a database
of stored exemplars and refer to that database to
guide their behavior in new situations. Models
can extrapolate from only one similar memory
exemplar, a group of similar exemplars (a nearest
neighbor set), or even the whole exemplar mem-
ory, using some decay function to give less weight
to less similar exemplars.
Applied to our model of thematic fit, this means
that the model should have a database in which se-
mantic representations of verb-argument pairs are
stored together with the semantic roles of the ar-
guments. The plausibility of a semantic role given
a new verb-argument pair is then determined by
the support for that role among the verb-argument
pairs in memory that are semantically most similar
to the target pair.
An immediately obvious advantage of this ap-
proach should be its potential robustness for data
sparsity, since similarity-based smoothing is an in-
trinsic part of the model. Even if neither the verb
nor the argument of a verb-argument pair occur
in the exemplar memory, role plausibilities can be
predicted, as long as the similarity of the target ex-
emplar’s semantic representation with the seman-
tic representations in the exemplar memory can be
calculated. An additional advantage of similarity-
based smoothing is that it does not involve the es-
timation of an exponential number of smoothing
parameters, as is the case for backed-off smooth-
ing methods (Zavrel and Daelemans, 1997).
For this study, we will implement three different
kinds of exemplar-based models. The first model
is a basic k-Nearest Neighbor (k-NN) model. In
this model, the plausibility rating for a semantic
role given a verb-argument pair is simply deter-
mined by the (relative) frequency with which that
semantic role is assigned to the k verb-argument
pairs that are nearest (i.e. most similar) to the tar-
get verb-argument pair (these exemplars constitute
the nearest neighbor set). The second model adds
a decay function to this simple k-NN model, so
that not only the role frequency, but also the ab-
solute semantic distance between the target item
and the neighbors in the nearest neighbor set de-
termine the plausibility rating. In the third model,
a normalization factor ensures that distance of the
exemplars in the nearest neighbor set to the target
item determines their weight in the calculation of
the plausibility rating while factoring out an effect
of absolute distance.
The semantic distance between two verb-
argument exemplars is determined by the seman-
tic distance between the verbs and between the
nouns. In all models described below, the distance
between two exemplars i and j (dij) is given by
the sum of the weighted distances (S) between the
semantic representations of the exemplars’ nouns
(n) and verbs (v):
</bodyText>
<equation confidence="0.926332">
dij = w„ x S(vi7 vj) + wn x S(ni7 nj) (3)
</equation>
<bodyText confidence="0.9999575">
We are not theoretically committed to any spe-
cific semantic representation or similarity metric
for the computation of S(vi7 vj) and S(ni7 nj). The
only requirement is that they should be able to dis-
tinguish nouns that typically occur in the same
contexts, but in different roles (like writer and
book), which probably excludes all vector-based
approaches that do not take into account syntactic
information (see also Pad´o et al. (2007)).
In the next three sections, each of the three
exemplar-based models is discussed in more de-
tail.
</bodyText>
<subsectionHeader confidence="0.999548">
3.1 A basic k-NN model
</subsectionHeader>
<bodyText confidence="0.999132">
The most basic of all exemplar-based models is a
k-NN model in which the preference strength of a
class upon presentation of a stimulus is simply the
relative frequency of that class among the nearest
neighbors of the stimulus. In the context of the-
matic fit, this means that the preference strength
(P5) for a semantic role response J given a verb-
argument stimulus i is found by summing the fre-
quencies of all exemplars with semantic role J
</bodyText>
<page confidence="0.994167">
828
</page>
<table confidence="0.999749">
Verb Noun Role Rating
sentence judge agent 6.9
sentence judge patient 1.3
sentence criminal agent 1.3
sentence criminal patient 6.7
</table>
<tableCaption confidence="0.900549">
Table 1: Example mean thematic fit ratings from
McRae et al. (1998)
</tableCaption>
<bodyText confidence="0.9996332">
among the k nearest neighbors of i (CkJ) and di-
viding this by the total number of exemplars in
the k-nearest neighbor set, with k (the number of
nearest neighbors taken into consideration) being
a free parameter:
</bodyText>
<equation confidence="0.99455">
PS(RJ|Si) = EjECkJ f(j) (4)
ElECk f(l)
</equation>
<bodyText confidence="0.999828">
We will call this model the k-NN frequency model
(henceforth kNNf).
</bodyText>
<subsectionHeader confidence="0.998713">
3.2 A distance decay model
</subsectionHeader>
<bodyText confidence="0.999940293103448">
The kNNf model uses the similarity between the
target exemplar and the memory exemplars only
to determine which items belong to the nearest
neighbor set. Whether these nearest neighbors are
very similar or only slightly similar to the target
exemplar, or whether there are some very similar
items but also some very dissimilar items among
those neighbors does not have any influence on
the class’s preference strength; only relative fre-
quency within the nearest neighbor set counts.
Only relying on the relative frequency of se-
mantic roles within the nearest neighbor set to pre-
dict their plausibilities might indeed be a reason-
able approach to modeling thematic fit in a lot of
cases. Being a good agent for a given verb of-
ten entails being a bad patient for that same verb
(or even in general), and the other way around.
For example, judge is a very plausible agent of
the verb sentence, while at the same time it is a
rather unlikely patient of the same verb, while it
is exactly the other way around for criminal, as
the mean participant ratings (on a 7-point scale)
in Table 1 show (these were taken from McRae
et al. (1998)). The relative frequencies of the
agent and patient roles in the nearest neighbor set
could in theory perfectly explain these ratings: a
high relative frequency of the agent role among
the nearest neighbors of the verb-argument pair
(sentence, judge) should correspond to a high
rating for the role, and implies low relative fre-
quencies for other roles such as the patient role,
which means the patient role should receive a low
rating. For (sentence, criminal) this works in
exactly the opposite way.
Solely relying on the the relative semantic role
frequencies in the nearest neighbor set might not
always work, though, since it implies that plausi-
bility ratings for different roles are always com-
pletely dependent on and therefore perfectly pre-
dictable from each other: high plausibility for a
certain semantic role given a verb-argument pair
always implies low plausibility for the other roles
in the nearest neighbor set, and low plausibility for
one semantic role invariably means higher plausi-
bility for the other ones. However, nouns can also
be more or less equally good as agents and patients
for a given verb—one is hopefully as likely to be
helped by a friend as to help a friend oneself—
or equally bad—houses only kill in horror movies,
and ‘to kill a house’ can only be made sense of in a
metaphorical way. Therefore, we also implement a
model that takes distance into account for its plau-
sibility ratings. The basic idea is that a seman-
tic role will receive a lower rating as the nearest
neighbors supporting that role become less simi-
lar to the target item. The plausibility rating for
a semantic role given a verb-argument pair in this
model is a joint function of:
</bodyText>
<listItem confidence="0.90105825">
1. the frequency with which the role occurs in
the set of memory exemplars that are seman-
tically most similar to the target pair
2. the target pairs similarity to those exemplars
</listItem>
<bodyText confidence="0.999437428571428">
We will call this model the Distance Decay model
(henceforth DD).
Formally, the preference strength (PS) for a se-
mantic role J (RJ) given a verb-argument tuple i
(Si) is found by summing the distance-weighted
frequency of all exemplars with semantic role J in
the nearest neighbor set (CkJ):
</bodyText>
<equation confidence="0.9708595">
PS(RJ|Si) = � f(j) X % (5)
jECj
</equation>
<bodyText confidence="0.99969075">
The weight of an exemplar j (,%) is given by an
exponential decay function, taken from Shepard
(1987), over the distance between that exemplar
and the target exemplar i (dij):
</bodyText>
<equation confidence="0.863498">
11j = e−αxdij (6)
</equation>
<page confidence="0.976798">
829
</page>
<bodyText confidence="0.999746666666667">
In Equation 6, the free parameter a determines the
rate of decay over dij. Higher values of a result in
a faster drop in similarity as dij increases.
</bodyText>
<subsectionHeader confidence="0.998565">
3.3 A normalized distance decay model
</subsectionHeader>
<bodyText confidence="0.999527923076923">
In Equation 5, we do not include a denominator
that sums over the similarity strengths of all ex-
emplars in the nearest neighbor set, because we
want to keep the absolute effect of distance into
the formula, so as to be able to accurately pre-
dict the bad fit of both the agent and patient roles
for verb-argument pairs like (kill, house) or the
good fit of both agent and patient roles for a pair
like (help, friend). To find out whether a non-
normalized model is indeed a better predictor of
thematic fit than a normalized model, we also
run experiments with a normalized version of the
model presented in Section 3.2:
</bodyText>
<equation confidence="0.997903">
P5(RJ|Ti) _ EjECj f(j) X (7)
ElECk f(l) X �l
</equation>
<bodyText confidence="0.999841142857143">
Someone familiar with the literature on human
categorization behavior might recognize Equation
7; this model is actually simply a Generalized
Context Model (GCM) (Nosofsky, 1986), with the
‘context’ being restricted to the k nearest neigh-
bors of the target item. Therefore, we will refer to
this model using the shorthand kGCM.
</bodyText>
<sectionHeader confidence="0.999739" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9342850625">
4.1 The task: predicting human plausibility
judgments
The model is evaluated by comparing its predic-
tions to thematic fit or semantic role plausibility
judgments from two rating experiments with hu-
man subjects. In these tasks, participants had to
rate the plausibility of verb-role-argument triples
on a scale from 1 to 7. They were asked ques-
tions like How common is it for a judge to sen-
tence someone?, in which judge is the agent, or
How common is it for a judge to be sentenced?, in
which judge is the patient. The prediction is that
model preference strengths of semantic roles given
specific verb-argument pairs should correlate pos-
itively with participant ratings for the correspond-
ing verb-role-argument triples.
</bodyText>
<subsectionHeader confidence="0.979616">
4.2 Training the model
</subsectionHeader>
<bodyText confidence="0.999985038461538">
In exemplar-based models, training the model
simply amounts to storing exemplars in memory.
Our model uses an exemplar memory that consists
of 133566 verb-role-noun triples extracted from
the Wall Street Journal and Brown parts of the
Penn Treebank (Marcus et al., 1993). These were
first annotated with semantic roles using a state-
of-the-art semantic role labeling system (Koomen
et al., 2005).
Semantic roles are approximated by PropBank
argument roles (Palmer et al., 2005). These con-
sist of a limited set of numbered roles that are used
for all verbs but are defined on a verb-by-verb ba-
sis. This contrasts with FrameNet roles, which are
sense-specific. Hence PropBank roles provide a
shallower level of semantic role annotation. They
also do not refer consistently to the same semantic
roles over different verbs, although the A0 and A1
roles in the majority of cases do correspond to the
agent and patient roles, respectively. The A2 role
refers to a third participant involved in the event,
but the label can stand for several types of seman-
tic roles, such as beneficiary or recipient. To create
the exemplar memory, all lemmatized verb-noun-
role triples that contained the A0, A1, or A2 roles
were extracted.
</bodyText>
<subsectionHeader confidence="0.998467">
4.3 Testing the model
</subsectionHeader>
<bodyText confidence="0.995448384615385">
To obtain the semantic distances between nouns
and verbs for the calculation of the distance be-
tween exemplars (see Equation 3), we make use
of a thesaurus compiled by Lin (1998), which
lists the 200 nearest neighbors for a large num-
ber of English noun and verb lemmas, together
with their similarity values. This resource was
created by computing the similarity between word
dependency vectors that are composed of fre-
quency counts of (head, relation, dependent)
triples (dependency triples) in a 64-million word
parsed corpus. To compute these similarities, an
information-theoretic similarity metric was used.
The basic idea of this metric is that the similarity
between two words is the amount of information
contained in the commonality between the two
words, i.e. the frequency counts of the dependency
triples that occur in the descriptions of both words,
divided by the amount of information in the de-
scriptions of the words, i.e. the frequency counts
of the dependency triples that occur in either of
the two words. See Lin (1998) for details. These
similarity values were transformed into distances
by subtracting them from the maximum similarity
value 1.
Gain Ratio is used to determine the weights of
</bodyText>
<page confidence="0.99116">
830
</page>
<bodyText confidence="0.99994109375">
the nouns and verbs in the distance calculation.
Gain Ratio is a normalization of Information Gain,
an information-theoretic measure that quantifies
how informative a feature is in the prediction of a
class label; in this case how informative in general
nouns or verbs are when one has to predict a se-
mantic role. Based on our exemplar memory, the
Gain Ratio values and so the feature weights are
0.0402 for the verbs, and 0.0333 for the nouns.
The model predictions are evaluated against
two data sets of human semantic role plausibil-
ity ratings for verb-role-noun triples (McRae et al.,
1998; Pad´o et al., 2006). These data sets were cho-
sen because they are the same data sets that were
originally used in the evaluation of the two other
models discussed in sections 2.1 and 2.2.
The first data set, from McRae et al. (1998),
consists of semantic role plausibility ratings for 40
verbs, each coupled with both a good agent and a
good patient, which were presented to the raters in
both roles. This means there are 40 x 2 x 2 = 160
items in total. We divide this data set in the same
60-item development and 100-item test sets that
were used by Pad´o et al. (2006) and Pad´o et al.
(2007) for the evaluation of their models.
For most of the McRae items, being a good
agent for a given verb also entails being a bad pa-
tient for that same verb, and the other way around.
This leads us to predict that on this data set the
kNNf model (see section 3.1) and the kGCM (see
section 3.3) should perform no worse than the DD
model (see section 3.2).
The second data set is taken from Pad´o et al.
(2006) and consists of 414 verb-role-noun triples.
Agent and patient ratings are more evenly dis-
tributed, so we predict that a model that exclu-
sively relies on the relative role frequencies in the
nearest neighbor sets of these items might not cap-
ture as much variability as a model that takes dis-
tance into account to weight the exemplars. There-
fore, we expect the DD model to do better than the
kNNf model on this data set. We randomly divide
the data set in a 276-item development set, and a
138-items test set.
Because of the non-normal distribution of the
test data, we use Spearman’s rank correlation test
to measure the correlation strength between the
plausibility ratings predicted by the model and the
human ratings. To estimate whether the strength
with which the predictions of the different mod-
els correlate with the human judgments differs
significantly between the models, we use an ap-
proximate test statistic described in Raghunathan
(2003). This test statistic is robust for sample size
differences, which is necessary in this case given
the fact that the models differ in their coverage.
We will refer to this statistic as the Q-statistic.
Experiments on the development sets are run
to find optimal values per model for two param-
eters: k, the number of nearest neighbors that are
taken into account for the construction of the near-
est neighbor set, and α (for the DD and kGCM
models), the rate of decay over distance (see Equa-
tion 6).
</bodyText>
<subsectionHeader confidence="0.7850855">
4.4 Results
4.4.1 McRae data
</subsectionHeader>
<bodyText confidence="0.996823517241379">
Results on the McRae test set are summarized in
Table 2. The first three rows contain the results
for the exemplar-based models. The last two rows
show the results of the two previous models for
comparison. The values for k and α that were
found to be optimal in the experiments on the de-
velopment set are specified where applicable.
The predictions of all three exemplar-based
models correlate significantly with the human rat-
ings, with the DD model doing somewhat bet-
ter than the kNNf model and the kGCM model,
although these differences are not significant
(Q(0.28) = 0.134, p = 2.8x10−1 and Q(0.28) =
0.116, p = 2.9 x 10−1, respectively). Coverage of
the exemplar-based models is very high.
When we compare the results of the exemplar-
based models with those of the Pad´o models, we
find that the predictions of the DD model correlate
significantly stronger with the human ratings than
the predictions of the Pad´o et al. (2007) model,
Q(0.98) = 4.398, p = 3.5 x 10−2. The DD
model also matches the high performance of the
Pad´o et al. (2006) model. Actually, the correlation
strength of the DD predictions with the human rat-
ings is higher, but that difference is not significant,
Q(0.93) = 0.285, p = 5.6 x 10−1. However, the
DD model has a much higher coverage than the
model of Pad´o et al. (2006), x2(1, N = 100) =
44.5, p = 2.5 x 10−11.
</bodyText>
<subsectionHeader confidence="0.607222">
4.4.2 Pad´o data
</subsectionHeader>
<bodyText confidence="0.984662">
Table 3 summarizes the results for the Pad´o
data set. We find that the predictions of all
three exemplar-based models correlate signifi-
cantly with the human ratings, and that there are
</bodyText>
<page confidence="0.994234">
831
</page>
<table confidence="0.9987335">
Model k α Coverage p p
kNNf 9 - 96% .407 p = 3.9 x 10−5
DD 11 5 96% .488 p = 4.6 x 10−7
kGCM 9 21 96% .397 p = 6.2 x 10−5
Pad´o et al. (2006) - - 56% .415 p = 1.5 x 10−3
Pad´o et al. (2007) - - 91% .218 p = 3.8 x 10−2
</table>
<tableCaption confidence="0.767318">
Table 2: Results for the McRae data.
</tableCaption>
<table confidence="0.999698333333333">
Model k α Coverage p p
kNNf 12 - 97% .521 p = 1.1 x 10−10
DD 8 21 97% .523 p = 9.1 x 10−11
kGCM 10 25 97% .512 p = 2.7 x 10−10
Pad´o et al. (2006) - - 96% .514 p = 2.9 x 10−10
Pad´o et al. (2007) - - 98% .506 p = 3.7 x 10−10
</table>
<tableCaption confidence="0.999202">
Table 3: Results for the Pad´o data.
</tableCaption>
<bodyText confidence="0.999454">
no significant differences between the three model
instantiations. Coverage is again very high.
There are no significant performance differ-
ences between the exemplar-based models and the
Pad´o models. Correlation strengths and coverage
are more or less the same for all models.
</bodyText>
<subsectionHeader confidence="0.970218">
4.5 Discussion
</subsectionHeader>
<bodyText confidence="0.999464826923077">
In general, we find that our exemplar-based, se-
mantic role predicting approach attains a very
good fit with the human semantic role plausibil-
ity ratings from both the McRae and the Pad´o data
set. Moreover, because of the fact that generaliza-
tion is determined by similarity-based extrapola-
tion from verb-noun pairs, the high correlations of
the model’s predictions with the human ratings are
accompanied by a very high coverage.
As concerns the comparison with the models of
Pad´o et al. (2006) and Pad´o et al. (2007) on the
Pad´o data, we can be brief: the exemplar-based
models’ performance matches that of the Pad´o
models, and basically all models perform equally
well, both on correlation strength and coverage.
However, there is a striking discrepancy be-
tween the performance of the Pad´o models and
the DD model on the McRae data sets. We find
that the DD model performs well for both correla-
tion strength and coverage, as opposed to the Pad´o
models, both of which score less well on one or
the other of these two dimensions. Although the
model of Pad´o et al. (2006) attains a good fit on the
McRae data, its coverage is very low. This is espe-
cially problematic considering the fact that it is ex-
actly this type of test items that is used in the kind
of sentence comprehension experiments for which
these thematic fit models should help explain the
results. The model of Pad´o et al. (2007) succeeds
in boosting coverage, but at the expense of corre-
lation strength, which is reduced to approximately
half the correlation strength attained by the Pad´o
et al. (2006) model.
The model of Pad´o et al. (2006) requires the
test verbs and their senses to be attested in the
FrameNet corpus to be able to make its predic-
tions. However, only 64 of the 100 test items in
the McRae data set contain verbs that are attested
in the FrameNet corpus, 8 of which involve an
unattested verb sense. On the other hand, the only
requirement for the exemplar-based model to be
able to make its predictions is that the similarities
between the verbs and the nouns in the target ex-
emplars and the memory exemplars can be com-
puted. In our case, this means that the verbs and
nouns need to have entries in the thesaurus we use
(see Section 4.3). In the McRae data set, this is the
case for all verbs, and for 48 out of the 50 nouns.
This explains the large difference in coverage be-
tween the DD model and the model of Pad´o et al.
(2006).
Pad´o et al. (2007) attribute the poorer correla-
</bodyText>
<page confidence="0.990696">
832
</page>
<bodyText confidence="0.99998835">
tion of their 2007 model with the human ratings
in the McRae data set to the much lower frequen-
cies of the nouns in that data set as compared to
the frequencies of the nouns in the Pad´o data set.
That is probably also the explanation for the dif-
ference in correlation strength between our model
and the model of Pad´o et al. (2007). Both models
use similarity-based smoothing to compensate for
low-frequency target items, but the generalization
problem caused by low frequency nouns is allevi-
ated in our model by the fact that the model not
only generalizes over nouns, but also over verbs.
Since the model can base its generalizations on
verb-noun pairs that contain the noun of the tar-
get pair coupled to a verb that is different from the
verb in the target pair, the neighbor set that it gen-
eralizes from can contain a larger number of ex-
emplars with nouns that are identical to the noun
in the target pair. The model of Pad´o et al. (2007)
has no access to nouns that are not coupled to the
target verb in the training corpus.
In Section 3, we predicted that the kNNf and
the kGCM should perform equally well as the DD
model on the McRae data set, because of the bal-
anced nature of that data set (all nouns are either
good agents and bad patients, or the other way
around), but that the DD model should do better
on the less balanced Pad´o data set. This predic-
tion is not borne out by the results, since the DD
model does not perform significantly better on ei-
ther of the data sets, although on both data sets
it achieves the highest correlation strength of all
three models. However, what we see is that the
performance difference between the DD model on
the one hand and the kNNf model and kGCM on
the other hand is larger on the McRae data than
on the Pad´o data, which is exactly the opposite of
what we predicted. The fact that the differences
are not significant makes us hesitant to draw any
conclusions from this finding, though.
</bodyText>
<sectionHeader confidence="0.999301" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999995895833333">
We presented an exemplar-based model of the-
matic fit that is founded on the idea that seman-
tic role plausibility can be predicted by similarity-
based generalization over verb-argument pairs. In
contrast to previous models, this model does not
implement semantic role plausibility as ‘fit with
verb selectional preferences’, but directly captures
the semantic role ambiguity problem comprehen-
ders have to solve when confronted with sentences
that contain structural ambiguities like the MV/RR
ambiguity, namely deciding which semantic role a
noun has in the event denoted by the verb. There-
fore, the model should be easily extensible to-
wards a complete model of any sentence-level am-
biguity that revolves around a semantic role ambi-
guity.
We have shown that our model can account very
well for human semantic role plausibility judg-
ments, attaining both high correlations with hu-
man ratings and high coverage overall, and im-
proving on two state-of-the-art models, the per-
formance of which deteriorates when there is a
small overlap between the verbs in the training
corpus and in the test data, or when the test nouns
have low frequencies in the training corpus. We
suggest that this improvement is due to the fact
that our model applies similarity-based smoothing
over both nouns and verbs. Generally, one can
say that the exemplar-based model’s architecture
makes it very robust for data sparsity.
We also found that a non-normalized version
of our model that takes distance into account
to weight the memory exemplars seems to per-
form somewhat better than a simple nearest neigh-
bor model or a normalized distance decay model.
However, these performance differences are not
statistically significant, and we did not find the
predicted advantage of the non-normalized dis-
tance decay model on the Pad´o data set.
In future work, we will test our claim of
straightforward extensibility of the model by in-
deed extending our model to account for reading
time patterns in the online processing of sentences
exemplifying temporary semantic role ambigui-
ties, more specifically the MV/RR ambiguity. An-
other avenue for future research is to see how our
approach to thematic fit can be used to augment
existing semantic role labeling systems.
</bodyText>
<sectionHeader confidence="0.998965" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998095">
This work was supported by a grant from the
Research Foundation – Flanders (FWO). We are
grateful to Ken McRae and Ulrike Pad´o for mak-
ing their datasets available, Dekang Lin for the
thesaurus, and the people of the Cognitive Com-
putation Group at UIUC for their SRL system.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.83485">
Thomas M. Cover and Peter E. Hart. 1967. Nearest
neighbor pattern classification. IEEE Transactions
</reference>
<page confidence="0.991583">
833
</page>
<reference confidence="0.999292954545455">
on Information Theory, 13(1):21–27.
Walter Daelemans and Antal van den Bosch. 2005.
Memory-based language processing. Cambridge
University Press, Cambridge.
Charles J. Fillmore, Christopher R. Johnson, and
Miriam R. L. Petruck. 2003. Background to
FrameNet. International Journal of Lexicography,
16:235–250.
Evelyn Fix and Joseph L. Hodges. 1951. Discrimina-
tory analysis—nonparametric discrimination: con-
sistency properties. Technical Report Project 21-
49-004, Report No. 4, USAF School of Aviation
Medicine, Randolp Field, TX.
Lyn Frazier. 1987. Sentence processing: A tutorial re-
view. In Max Coltheart, editor, Attention and Per-
formance XII: The Psychology of Reading, pages
559–586. Erlbaum, Hillsdale, NJ.
Peter Koomen, Vasin Punyakanok, Dan Roth, and
Wen-tau Yih. 2005. Generalized inference with
multiple semantic role labeling systems. In Ido
Dagan and Daniel Gildea, editors, Proceedings of
the Ninth Conference on Computational Natural
Language Learning (CoNLL-2005), pages 181–184.
Association for Computational Linguistics, Morris-
town, NJ.
Dekang Lin. 1998. Automatic retrieval and cluster-
ing of similar words. In Christian Boitet and Pete
Whitelock, editors, Proceedings of the 17th Inter-
national Conference on Computational Linguistics,
pages 768–774. Association for Computational Lin-
guistics, Morristown, NJ.
Maryellen C. MacDonald and Mark S. Seidenberg.
2006. Constraint satisfaction accounts of lexical
and sentence comprehension. In Matthew J. Traxler
and Morton A. Gernsbacher, editors, Handbook of
Psycholinguistics (Second Edition), pages 581–611.
Academic Press, London.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of english: the Penn Treebank. Compu-
tational Linguistics, 19(2):313–330.
Ken McRae, Michael J. Spivey-Knowlton, and
Michael K. Tanenhaus. 1998. Modeling the influ-
ence of thematic fit (and other constraints) in on-line
sentence comprehension. Journal of Memory and
Language, 38(3):283–312.
Robert M. Nosofsky. 1986. Attention, similar-
ity, and the identification-categorization relation-
ship. Journal of Experimental Psychology-General,
115(1):39–57.
Sebastian Pad´o and Mirella Lapata. 2007.
Dependency-based construction of semantic space
models. Computational Linguistics, 33(2):161–199.
Ulrike Pad´o, Frank Keller, and Matthew Crocker.
2006. Combining syntax and thematic fit in a prob-
abilistic model of sentence processing. In Ron Sun
and Naomi Miyake, editors, Proceedings of the 28th
Annual Conference of the Cognitive Science Society,
pages 657–662. Cognitive Science Society, Austin,
TX.
Sebastian Pad´o, Ulrike Pad´o, and Katrin Erk. 2007.
Flexible, corpus-based modelling of human plau-
sibility judgements. In Jason Eisner, editor, Pro-
ceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 400–409. Association for Computa-
tional Linguistics, Morristown, NJ.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71–106.
Trivellore Raghunathan. 2003. An approximate test
for homogeneity of correlated correlation coeffi-
cients. Quality and Quantity, 4(1):99–110.
Philip Resnik. 1996. Selectional constraints: an
information-theoretic model and its computational
realization. Cognition, 61(1-2):127–159.
Roger N. Shepard. 1987. Toward a universal law of
generalization for psychological science. Science,
237(4820):1317–1323.
Jakub Zavrel and Walter Daelemans. 1997. Memory-
based learning: Using similarity for smoothing.
In Philip R. Cohen and Wolfgang Wahlster, edi-
tors, Proceedings of the 35th Annual Meeting of the
Association for Computational Linguistics, pages
436–443. Association for Computational Linguis-
tics, Morristown, NJ.
</reference>
<page confidence="0.998712">
834
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.860028">
<title confidence="0.99849">A robust and extensible exemplar-based model of thematic fit</title>
<author confidence="0.993951">Dominiek Walter</author>
<affiliation confidence="0.973741">for Psycholinguistics, for Dutch Language and Speech (CNTS) University of Antwerp</affiliation>
<address confidence="0.963093">Antwerp, Belgium</address>
<abstract confidence="0.997534727272728">This paper presents a new, exemplar-based model of thematic fit. In contrast to previous models, it does not approximate thematic fit as argument plausibility or ‘fit with verb selectional preferences’, but directly as semantic role plausibility for a verb-argument pair, through similaritybased generalization from previously seen verb-argument pairs. This makes the model very robust for data sparsity. We argue that the model is easily extensible to a model of semantic role ambiguity resolution during online sentence comprehension. The model is evaluated on human semantic role plausibility judgments. Its predictions correlate significantly with the human judgments. It rivals two state-of-theart models of thematic fit and exceeds their performance on previously unseen or lowfrequency items.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thomas M Cover</author>
<author>Peter E Hart</author>
</authors>
<title>Nearest neighbor pattern classification.</title>
<date>1967</date>
<journal>IEEE Transactions on Information Theory,</journal>
<volume>13</volume>
<issue>1</issue>
<contexts>
<context position="9077" citStr="Cover and Hart, 1967" startWordPosition="1458" endWordPosition="1461">e correlation of its predictions with human ratings, and it attains higher cov� a&apos;ESeen,(v) 827 erage (it can provide plausibility values for a larger proportion of the test items), since the model only requires that the verb occurs with subject and object arguments in the training corpus, and that the target argument headwords occur in the training data frequently enough to attain reliable dependency vectors. 3 Exemplar-based modeling of thematic fit Exemplar-based models of cognition (also known as Memory-Based Learning or instance/casebased reasoning/learning models) (Fix and Hodges, 1951; Cover and Hart, 1967; Daelemans and van den Bosch, 2005) are classification models that extrapolate their behavior from stored representations of earlier experiences to new situations, based on the similarity of the old and the new situation. These models keep a database of stored exemplars and refer to that database to guide their behavior in new situations. Models can extrapolate from only one similar memory exemplar, a group of similar exemplars (a nearest neighbor set), or even the whole exemplar memory, using some decay function to give less weight to less similar exemplars. Applied to our model of thematic </context>
</contexts>
<marker>Cover, Hart, 1967</marker>
<rawString>Thomas M. Cover and Peter E. Hart. 1967. Nearest neighbor pattern classification. IEEE Transactions on Information Theory, 13(1):21–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal van den Bosch</author>
</authors>
<title>Memory-based language processing.</title>
<date>2005</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<marker>Daelemans, van den Bosch, 2005</marker>
<rawString>Walter Daelemans and Antal van den Bosch. 2005. Memory-based language processing. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Christopher R Johnson</author>
<author>Miriam R L Petruck</author>
</authors>
<title>Background to FrameNet.</title>
<date>2003</date>
<journal>International Journal of Lexicography,</journal>
<pages>16--235</pages>
<contexts>
<context position="5859" citStr="Fillmore et al., 2003" startWordPosition="924" endWordPosition="927">omparison of its performance with that of the models discussed in Section 2 is presented in Section 4. Section 5 ties everything together with some general conclusions. 2 Previous models In this section of the paper, we look at two state-ofthe-art models of thematic fit, developed by Pad´o et al. (2006) and Pad´o et al. (2007). We will not discuss the selectional preferences model of Resnik (1996), but for a comparison between the Resnik model and the Pad´o models, see Pad´o et al. (2007). 2.1 Pad´o et al. (2006) In their model of thematic fit, Pad´o et al. (2006) use FrameNet thematic roles (Fillmore et al., 2003) to approximate semantic roles. The thematic fit of a verb-role-argument triple (v, r, a) is given by the joint probability of the role r, the argument headword a, the verb sense vs, and the grammatical function gf of a: Plausibilityv,r,a = P(vs, r, a, gf) (1) Since computing this joint probability from corpus co-occurrence frequencies is problematic due to an obvious sparse data issue, the term is decomposed into several subterms, including a term P(a|vs, gf, r) that captures selectional preferences. Good-Turing and class-based smoothing are used to further alleviate the remaining sparse data</context>
</contexts>
<marker>Fillmore, Johnson, Petruck, 2003</marker>
<rawString>Charles J. Fillmore, Christopher R. Johnson, and Miriam R. L. Petruck. 2003. Background to FrameNet. International Journal of Lexicography, 16:235–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evelyn Fix</author>
<author>Joseph L Hodges</author>
</authors>
<title>Discriminatory analysis—nonparametric discrimination: consistency properties.</title>
<date>1951</date>
<tech>Technical Report Project 21-49-004, Report No. 4,</tech>
<institution>USAF School of Aviation Medicine,</institution>
<location>Randolp Field, TX.</location>
<contexts>
<context position="9055" citStr="Fix and Hodges, 1951" startWordPosition="1454" endWordPosition="1457">al. (2006) model on the correlation of its predictions with human ratings, and it attains higher cov� a&apos;ESeen,(v) 827 erage (it can provide plausibility values for a larger proportion of the test items), since the model only requires that the verb occurs with subject and object arguments in the training corpus, and that the target argument headwords occur in the training data frequently enough to attain reliable dependency vectors. 3 Exemplar-based modeling of thematic fit Exemplar-based models of cognition (also known as Memory-Based Learning or instance/casebased reasoning/learning models) (Fix and Hodges, 1951; Cover and Hart, 1967; Daelemans and van den Bosch, 2005) are classification models that extrapolate their behavior from stored representations of earlier experiences to new situations, based on the similarity of the old and the new situation. These models keep a database of stored exemplars and refer to that database to guide their behavior in new situations. Models can extrapolate from only one similar memory exemplar, a group of similar exemplars (a nearest neighbor set), or even the whole exemplar memory, using some decay function to give less weight to less similar exemplars. Applied to </context>
</contexts>
<marker>Fix, Hodges, 1951</marker>
<rawString>Evelyn Fix and Joseph L. Hodges. 1951. Discriminatory analysis—nonparametric discrimination: consistency properties. Technical Report Project 21-49-004, Report No. 4, USAF School of Aviation Medicine, Randolp Field, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lyn Frazier</author>
</authors>
<title>Sentence processing: A tutorial review.</title>
<date>1987</date>
<booktitle>Attention and Performance XII: The Psychology of Reading,</booktitle>
<pages>559--586</pages>
<editor>In Max Coltheart, editor,</editor>
<publisher>Erlbaum,</publisher>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="1888" citStr="Frazier (1987)" startWordPosition="274" endWordPosition="275">he event denoted by a verbal predicate, e.g. the plausibility that a judge sentences someone (which makes the judge the agent of the sentencing event) or that a judge is sentenced him- or herself (which makes the judge the patient). Thematic fit has been an important concept in psycholinguistics as a predictor variable in models of human sentence comprehension, either to discriminate between possible structural analyses during initial processing in constraint-based models (see MacDonald and Seidenberg (2006) for a recent overview), or after initial syntactic processing in modular models (e.g. Frazier (1987)). In fact, thematic fit is at the core of the most-studied of all structural ambiguity phenomena, the ambiguity between a main clause or a reduced relative clause interpretation of an NP verb-ed sequence (the MV/RR ambiguity), which is essentially a semantic role ambiguity. If the temporarily ambiguous sentence The judge sentenced ... is continued as a main clause (e.g. The judge sentenced him to 10 years in prison), the noun phrase the judge would be the agent of the verb sentenced, while it would be the patient of sentenced in a reduced relative clause continuation (e.g. The judge sentenced</context>
</contexts>
<marker>Frazier, 1987</marker>
<rawString>Lyn Frazier. 1987. Sentence processing: A tutorial review. In Max Coltheart, editor, Attention and Performance XII: The Psychology of Reading, pages 559–586. Erlbaum, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Koomen</author>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>Generalized inference with multiple semantic role labeling systems.</title>
<date>2005</date>
<booktitle>In Ido Dagan and Daniel Gildea, editors, Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005),</booktitle>
<pages>181--184</pages>
<location>Morristown, NJ.</location>
<contexts>
<context position="19500" citStr="Koomen et al., 2005" startWordPosition="3222" endWordPosition="3225"> prediction is that model preference strengths of semantic roles given specific verb-argument pairs should correlate positively with participant ratings for the corresponding verb-role-argument triples. 4.2 Training the model In exemplar-based models, training the model simply amounts to storing exemplars in memory. Our model uses an exemplar memory that consists of 133566 verb-role-noun triples extracted from the Wall Street Journal and Brown parts of the Penn Treebank (Marcus et al., 1993). These were first annotated with semantic roles using a stateof-the-art semantic role labeling system (Koomen et al., 2005). Semantic roles are approximated by PropBank argument roles (Palmer et al., 2005). These consist of a limited set of numbered roles that are used for all verbs but are defined on a verb-by-verb basis. This contrasts with FrameNet roles, which are sense-specific. Hence PropBank roles provide a shallower level of semantic role annotation. They also do not refer consistently to the same semantic roles over different verbs, although the A0 and A1 roles in the majority of cases do correspond to the agent and patient roles, respectively. The A2 role refers to a third participant involved in the eve</context>
</contexts>
<marker>Koomen, Punyakanok, Roth, Yih, 2005</marker>
<rawString>Peter Koomen, Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2005. Generalized inference with multiple semantic role labeling systems. In Ido Dagan and Daniel Gildea, editors, Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005), pages 181–184. Association for Computational Linguistics, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>Proceedings of the 17th International Conference on Computational Linguistics,</booktitle>
<pages>768--774</pages>
<editor>In Christian Boitet and Pete Whitelock, editors,</editor>
<location>Morristown, NJ.</location>
<contexts>
<context position="20522" citStr="Lin (1998)" startWordPosition="3397" endWordPosition="3398">erent verbs, although the A0 and A1 roles in the majority of cases do correspond to the agent and patient roles, respectively. The A2 role refers to a third participant involved in the event, but the label can stand for several types of semantic roles, such as beneficiary or recipient. To create the exemplar memory, all lemmatized verb-nounrole triples that contained the A0, A1, or A2 roles were extracted. 4.3 Testing the model To obtain the semantic distances between nouns and verbs for the calculation of the distance between exemplars (see Equation 3), we make use of a thesaurus compiled by Lin (1998), which lists the 200 nearest neighbors for a large number of English noun and verb lemmas, together with their similarity values. This resource was created by computing the similarity between word dependency vectors that are composed of frequency counts of (head, relation, dependent) triples (dependency triples) in a 64-million word parsed corpus. To compute these similarities, an information-theoretic similarity metric was used. The basic idea of this metric is that the similarity between two words is the amount of information contained in the commonality between the two words, i.e. the freq</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Christian Boitet and Pete Whitelock, editors, Proceedings of the 17th International Conference on Computational Linguistics, pages 768–774. Association for Computational Linguistics, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maryellen C MacDonald</author>
<author>Mark S Seidenberg</author>
</authors>
<title>Constraint satisfaction accounts of lexical and sentence comprehension.</title>
<date>2006</date>
<booktitle>Handbook of Psycholinguistics (Second Edition),</booktitle>
<pages>581--611</pages>
<editor>In Matthew J. Traxler and Morton A. Gernsbacher, editors,</editor>
<publisher>Academic Press,</publisher>
<location>London.</location>
<contexts>
<context position="1787" citStr="MacDonald and Seidenberg (2006)" startWordPosition="256" endWordPosition="259">usibility) is the plausibility of a noun phrase referent playing a specific semantic role (like agent or patient) in the event denoted by a verbal predicate, e.g. the plausibility that a judge sentences someone (which makes the judge the agent of the sentencing event) or that a judge is sentenced him- or herself (which makes the judge the patient). Thematic fit has been an important concept in psycholinguistics as a predictor variable in models of human sentence comprehension, either to discriminate between possible structural analyses during initial processing in constraint-based models (see MacDonald and Seidenberg (2006) for a recent overview), or after initial syntactic processing in modular models (e.g. Frazier (1987)). In fact, thematic fit is at the core of the most-studied of all structural ambiguity phenomena, the ambiguity between a main clause or a reduced relative clause interpretation of an NP verb-ed sequence (the MV/RR ambiguity), which is essentially a semantic role ambiguity. If the temporarily ambiguous sentence The judge sentenced ... is continued as a main clause (e.g. The judge sentenced him to 10 years in prison), the noun phrase the judge would be the agent of the verb sentenced, while it </context>
</contexts>
<marker>MacDonald, Seidenberg, 2006</marker>
<rawString>Maryellen C. MacDonald and Mark S. Seidenberg. 2006. Constraint satisfaction accounts of lexical and sentence comprehension. In Matthew J. Traxler and Morton A. Gernsbacher, editors, Handbook of Psycholinguistics (Second Edition), pages 581–611. Academic Press, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of english: the Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="19376" citStr="Marcus et al., 1993" startWordPosition="3203" endWordPosition="3206"> someone?, in which judge is the agent, or How common is it for a judge to be sentenced?, in which judge is the patient. The prediction is that model preference strengths of semantic roles given specific verb-argument pairs should correlate positively with participant ratings for the corresponding verb-role-argument triples. 4.2 Training the model In exemplar-based models, training the model simply amounts to storing exemplars in memory. Our model uses an exemplar memory that consists of 133566 verb-role-noun triples extracted from the Wall Street Journal and Brown parts of the Penn Treebank (Marcus et al., 1993). These were first annotated with semantic roles using a stateof-the-art semantic role labeling system (Koomen et al., 2005). Semantic roles are approximated by PropBank argument roles (Palmer et al., 2005). These consist of a limited set of numbered roles that are used for all verbs but are defined on a verb-by-verb basis. This contrasts with FrameNet roles, which are sense-specific. Hence PropBank roles provide a shallower level of semantic role annotation. They also do not refer consistently to the same semantic roles over different verbs, although the A0 and A1 roles in the majority of cas</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of english: the Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken McRae</author>
<author>Michael J Spivey-Knowlton</author>
<author>Michael K Tanenhaus</author>
</authors>
<title>Modeling the influence of thematic fit (and other constraints) in on-line sentence comprehension.</title>
<date>1998</date>
<journal>Journal of Memory and Language,</journal>
<volume>38</volume>
<issue>3</issue>
<contexts>
<context position="13307" citStr="McRae et al. (1998)" startWordPosition="2160" endWordPosition="2163">plar-based models is a k-NN model in which the preference strength of a class upon presentation of a stimulus is simply the relative frequency of that class among the nearest neighbors of the stimulus. In the context of thematic fit, this means that the preference strength (P5) for a semantic role response J given a verbargument stimulus i is found by summing the frequencies of all exemplars with semantic role J 828 Verb Noun Role Rating sentence judge agent 6.9 sentence judge patient 1.3 sentence criminal agent 1.3 sentence criminal patient 6.7 Table 1: Example mean thematic fit ratings from McRae et al. (1998) among the k nearest neighbors of i (CkJ) and dividing this by the total number of exemplars in the k-nearest neighbor set, with k (the number of nearest neighbors taken into consideration) being a free parameter: PS(RJ|Si) = EjECkJ f(j) (4) ElECk f(l) We will call this model the k-NN frequency model (henceforth kNNf). 3.2 A distance decay model The kNNf model uses the similarity between the target exemplar and the memory exemplars only to determine which items belong to the nearest neighbor set. Whether these nearest neighbors are very similar or only slightly similar to the target exemplar, </context>
<context position="14784" citStr="McRae et al. (1998)" startWordPosition="2419" endWordPosition="2422">e frequency of semantic roles within the nearest neighbor set to predict their plausibilities might indeed be a reasonable approach to modeling thematic fit in a lot of cases. Being a good agent for a given verb often entails being a bad patient for that same verb (or even in general), and the other way around. For example, judge is a very plausible agent of the verb sentence, while at the same time it is a rather unlikely patient of the same verb, while it is exactly the other way around for criminal, as the mean participant ratings (on a 7-point scale) in Table 1 show (these were taken from McRae et al. (1998)). The relative frequencies of the agent and patient roles in the nearest neighbor set could in theory perfectly explain these ratings: a high relative frequency of the agent role among the nearest neighbors of the verb-argument pair (sentence, judge) should correspond to a high rating for the role, and implies low relative frequencies for other roles such as the patient role, which means the patient role should receive a low rating. For (sentence, criminal) this works in exactly the opposite way. Solely relying on the the relative semantic role frequencies in the nearest neighbor set might no</context>
<context position="22154" citStr="McRae et al., 1998" startWordPosition="3661" endWordPosition="3664">rmine the weights of 830 the nouns and verbs in the distance calculation. Gain Ratio is a normalization of Information Gain, an information-theoretic measure that quantifies how informative a feature is in the prediction of a class label; in this case how informative in general nouns or verbs are when one has to predict a semantic role. Based on our exemplar memory, the Gain Ratio values and so the feature weights are 0.0402 for the verbs, and 0.0333 for the nouns. The model predictions are evaluated against two data sets of human semantic role plausibility ratings for verb-role-noun triples (McRae et al., 1998; Pad´o et al., 2006). These data sets were chosen because they are the same data sets that were originally used in the evaluation of the two other models discussed in sections 2.1 and 2.2. The first data set, from McRae et al. (1998), consists of semantic role plausibility ratings for 40 verbs, each coupled with both a good agent and a good patient, which were presented to the raters in both roles. This means there are 40 x 2 x 2 = 160 items in total. We divide this data set in the same 60-item development and 100-item test sets that were used by Pad´o et al. (2006) and Pad´o et al. (2007) fo</context>
</contexts>
<marker>McRae, Spivey-Knowlton, Tanenhaus, 1998</marker>
<rawString>Ken McRae, Michael J. Spivey-Knowlton, and Michael K. Tanenhaus. 1998. Modeling the influence of thematic fit (and other constraints) in on-line sentence comprehension. Journal of Memory and Language, 38(3):283–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert M Nosofsky</author>
</authors>
<title>Attention, similarity, and the identification-categorization relationship.</title>
<date>1986</date>
<journal>Journal of Experimental Psychology-General,</journal>
<volume>115</volume>
<issue>1</issue>
<contexts>
<context position="18199" citStr="Nosofsky, 1986" startWordPosition="3013" endWordPosition="3014"> accurately predict the bad fit of both the agent and patient roles for verb-argument pairs like (kill, house) or the good fit of both agent and patient roles for a pair like (help, friend). To find out whether a nonnormalized model is indeed a better predictor of thematic fit than a normalized model, we also run experiments with a normalized version of the model presented in Section 3.2: P5(RJ|Ti) _ EjECj f(j) X (7) ElECk f(l) X �l Someone familiar with the literature on human categorization behavior might recognize Equation 7; this model is actually simply a Generalized Context Model (GCM) (Nosofsky, 1986), with the ‘context’ being restricted to the k nearest neighbors of the target item. Therefore, we will refer to this model using the shorthand kGCM. 4 Evaluation 4.1 The task: predicting human plausibility judgments The model is evaluated by comparing its predictions to thematic fit or semantic role plausibility judgments from two rating experiments with human subjects. In these tasks, participants had to rate the plausibility of verb-role-argument triples on a scale from 1 to 7. They were asked questions like How common is it for a judge to sentence someone?, in which judge is the agent, or </context>
</contexts>
<marker>Nosofsky, 1986</marker>
<rawString>Robert M. Nosofsky. 1986. Attention, similarity, and the identification-categorization relationship. Journal of Experimental Psychology-General, 115(1):39–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Dependency-based construction of semantic space models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Pad´o, Lapata, 2007</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2007. Dependency-based construction of semantic space models. Computational Linguistics, 33(2):161–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrike Pad´o</author>
<author>Frank Keller</author>
<author>Matthew Crocker</author>
</authors>
<title>Combining syntax and thematic fit in a probabilistic model of sentence processing.</title>
<date>2006</date>
<booktitle>In Ron Sun and Naomi Miyake, editors, Proceedings of the 28th Annual Conference of the Cognitive Science Society,</booktitle>
<pages>657--662</pages>
<publisher>Cognitive Science Society,</publisher>
<location>Austin, TX.</location>
<marker>Pad´o, Keller, Crocker, 2006</marker>
<rawString>Ulrike Pad´o, Frank Keller, and Matthew Crocker. 2006. Combining syntax and thematic fit in a probabilistic model of sentence processing. In Ron Sun and Naomi Miyake, editors, Proceedings of the 28th Annual Conference of the Cognitive Science Society, pages 657–662. Cognitive Science Society, Austin, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Ulrike Pad´o</author>
<author>Katrin Erk</author>
</authors>
<title>Flexible, corpus-based modelling of human plausibility judgements.</title>
<date>2007</date>
<booktitle>Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>400--409</pages>
<editor>In Jason Eisner, editor,</editor>
<location>Morristown, NJ.</location>
<marker>Pad´o, Pad´o, Erk, 2007</marker>
<rawString>Sebastian Pad´o, Ulrike Pad´o, and Katrin Erk. 2007. Flexible, corpus-based modelling of human plausibility judgements. In Jason Eisner, editor, Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 400–409. Association for Computational Linguistics, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="19582" citStr="Palmer et al., 2005" startWordPosition="3234" endWordPosition="3237">rb-argument pairs should correlate positively with participant ratings for the corresponding verb-role-argument triples. 4.2 Training the model In exemplar-based models, training the model simply amounts to storing exemplars in memory. Our model uses an exemplar memory that consists of 133566 verb-role-noun triples extracted from the Wall Street Journal and Brown parts of the Penn Treebank (Marcus et al., 1993). These were first annotated with semantic roles using a stateof-the-art semantic role labeling system (Koomen et al., 2005). Semantic roles are approximated by PropBank argument roles (Palmer et al., 2005). These consist of a limited set of numbered roles that are used for all verbs but are defined on a verb-by-verb basis. This contrasts with FrameNet roles, which are sense-specific. Hence PropBank roles provide a shallower level of semantic role annotation. They also do not refer consistently to the same semantic roles over different verbs, although the A0 and A1 roles in the majority of cases do correspond to the agent and patient roles, respectively. The A2 role refers to a third participant involved in the event, but the label can stand for several types of semantic roles, such as beneficia</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trivellore Raghunathan</author>
</authors>
<title>An approximate test for homogeneity of correlated correlation coefficients.</title>
<date>2003</date>
<journal>Quality and Quantity,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="24107" citStr="Raghunathan (2003)" startWordPosition="4016" endWordPosition="4017">s. Therefore, we expect the DD model to do better than the kNNf model on this data set. We randomly divide the data set in a 276-item development set, and a 138-items test set. Because of the non-normal distribution of the test data, we use Spearman’s rank correlation test to measure the correlation strength between the plausibility ratings predicted by the model and the human ratings. To estimate whether the strength with which the predictions of the different models correlate with the human judgments differs significantly between the models, we use an approximate test statistic described in Raghunathan (2003). This test statistic is robust for sample size differences, which is necessary in this case given the fact that the models differ in their coverage. We will refer to this statistic as the Q-statistic. Experiments on the development sets are run to find optimal values per model for two parameters: k, the number of nearest neighbors that are taken into account for the construction of the nearest neighbor set, and α (for the DD and kGCM models), the rate of decay over distance (see Equation 6). 4.4 Results 4.4.1 McRae data Results on the McRae test set are summarized in Table 2. The first three </context>
</contexts>
<marker>Raghunathan, 2003</marker>
<rawString>Trivellore Raghunathan. 2003. An approximate test for homogeneity of correlated correlation coefficients. Quality and Quantity, 4(1):99–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selectional constraints: an information-theoretic model and its computational realization.</title>
<date>1996</date>
<journal>Cognition,</journal>
<pages>61--1</pages>
<contexts>
<context position="2866" citStr="Resnik, 1996" startWordPosition="438" endWordPosition="439">e (e.g. The judge sentenced him to 10 years in prison), the noun phrase the judge would be the agent of the verb sentenced, while it would be the patient of sentenced in a reduced relative clause continuation (e.g. The judge sentenced to 4 years in prison for indecent exposure could also lose his state pension). Apart from its importance in psycholinguistics, the concept of thematic fit is also relevant for computational linguistics in general (see Pad´o et al. (2007) for some examples). A number of models that try to capture human thematic fit preferences have been developed in recent years (Resnik, 1996; Pad´o et al., 2006; Pad´o et al., 2007). These previous approaches rely on the linguistic notion of verb selectional preferences. The plausibility that an argument plays a specific semantic role in the event denoted by a verb—in other words, that a verb, role and argument occur together—is predicted by how well the argument head fits the restrictions that the verb imposes on the argument candidates for the semantic role slot under consideration (e.g. eat prefers edible arguments to fill its patient slot). Therefore, what these models capture is actually not semantic role plausibility, but ar</context>
<context position="5637" citStr="Resnik (1996)" startWordPosition="886" endWordPosition="887">uss two state-of-the-art thematic fit models, the performance of which will be compared to that of our model. Section 3 introduces three different instantiations of our model. The evaluation of the model and the comparison of its performance with that of the models discussed in Section 2 is presented in Section 4. Section 5 ties everything together with some general conclusions. 2 Previous models In this section of the paper, we look at two state-ofthe-art models of thematic fit, developed by Pad´o et al. (2006) and Pad´o et al. (2007). We will not discuss the selectional preferences model of Resnik (1996), but for a comparison between the Resnik model and the Pad´o models, see Pad´o et al. (2007). 2.1 Pad´o et al. (2006) In their model of thematic fit, Pad´o et al. (2006) use FrameNet thematic roles (Fillmore et al., 2003) to approximate semantic roles. The thematic fit of a verb-role-argument triple (v, r, a) is given by the joint probability of the role r, the argument headword a, the verb sense vs, and the grammatical function gf of a: Plausibilityv,r,a = P(vs, r, a, gf) (1) Since computing this joint probability from corpus co-occurrence frequencies is problematic due to an obvious sparse </context>
</contexts>
<marker>Resnik, 1996</marker>
<rawString>Philip Resnik. 1996. Selectional constraints: an information-theoretic model and its computational realization. Cognition, 61(1-2):127–159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger N Shepard</author>
</authors>
<title>Toward a universal law of generalization for psychological science.</title>
<date>1987</date>
<journal>Science,</journal>
<volume>237</volume>
<issue>4820</issue>
<contexts>
<context position="17073" citStr="Shepard (1987)" startWordPosition="2814" endWordPosition="2815">ction of: 1. the frequency with which the role occurs in the set of memory exemplars that are semantically most similar to the target pair 2. the target pairs similarity to those exemplars We will call this model the Distance Decay model (henceforth DD). Formally, the preference strength (PS) for a semantic role J (RJ) given a verb-argument tuple i (Si) is found by summing the distance-weighted frequency of all exemplars with semantic role J in the nearest neighbor set (CkJ): PS(RJ|Si) = � f(j) X % (5) jECj The weight of an exemplar j (,%) is given by an exponential decay function, taken from Shepard (1987), over the distance between that exemplar and the target exemplar i (dij): 11j = e−αxdij (6) 829 In Equation 6, the free parameter a determines the rate of decay over dij. Higher values of a result in a faster drop in similarity as dij increases. 3.3 A normalized distance decay model In Equation 5, we do not include a denominator that sums over the similarity strengths of all exemplars in the nearest neighbor set, because we want to keep the absolute effect of distance into the formula, so as to be able to accurately predict the bad fit of both the agent and patient roles for verb-argument pai</context>
</contexts>
<marker>Shepard, 1987</marker>
<rawString>Roger N. Shepard. 1987. Toward a universal law of generalization for psychological science. Science, 237(4820):1317–1323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakub Zavrel</author>
<author>Walter Daelemans</author>
</authors>
<title>Memorybased learning: Using similarity for smoothing.</title>
<date>1997</date>
<booktitle>Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>436--443</pages>
<editor>In Philip R. Cohen and Wolfgang Wahlster, editors,</editor>
<location>Morristown, NJ.</location>
<contexts>
<context position="10739" citStr="Zavrel and Daelemans, 1997" startWordPosition="1727" endWordPosition="1730">ould be its potential robustness for data sparsity, since similarity-based smoothing is an intrinsic part of the model. Even if neither the verb nor the argument of a verb-argument pair occur in the exemplar memory, role plausibilities can be predicted, as long as the similarity of the target exemplar’s semantic representation with the semantic representations in the exemplar memory can be calculated. An additional advantage of similaritybased smoothing is that it does not involve the estimation of an exponential number of smoothing parameters, as is the case for backed-off smoothing methods (Zavrel and Daelemans, 1997). For this study, we will implement three different kinds of exemplar-based models. The first model is a basic k-Nearest Neighbor (k-NN) model. In this model, the plausibility rating for a semantic role given a verb-argument pair is simply determined by the (relative) frequency with which that semantic role is assigned to the k verb-argument pairs that are nearest (i.e. most similar) to the target verb-argument pair (these exemplars constitute the nearest neighbor set). The second model adds a decay function to this simple k-NN model, so that not only the role frequency, but also the absolute </context>
</contexts>
<marker>Zavrel, Daelemans, 1997</marker>
<rawString>Jakub Zavrel and Walter Daelemans. 1997. Memorybased learning: Using similarity for smoothing. In Philip R. Cohen and Wolfgang Wahlster, editors, Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, pages 436–443. Association for Computational Linguistics, Morristown, NJ.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>