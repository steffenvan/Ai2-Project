<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001835">
<title confidence="0.992258">
Simple, Robust and (almost) Unsupervised Generation of Polarity
Lexicons for Multiple Languages
</title>
<author confidence="0.927518">
I˜naki San Vicente, Rodrigo Agerri, German Rigau
</author>
<affiliation confidence="0.894409">
IXA NLP Group
University of the Basque Country (UPV/EHU)
</affiliation>
<address confidence="0.614854">
Donostia-San Sebasti´an
</address>
<email confidence="0.998719">
{inaki.sanvicente,rodrigo.agerri,german.rigau}@ehu.es
</email>
<sectionHeader confidence="0.997386" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999813947368421">
This paper presents a simple, robust and
(almost) unsupervised dictionary-based
method, qwn-ppv (Q-WordNet as Person-
alized PageRanking Vector) to automati-
cally generate polarity lexicons. We show
that qwn-ppv outperforms other automat-
ically generated lexicons for the four ex-
trinsic evaluations presented here. It also
shows very competitive and robust results
with respect to manually annotated ones.
Results suggest that no single lexicon is
best for every task and dataset and that
the intrinsic evaluation of polarity lexicons
is not a good performance indicator on
a Sentiment Analysis task. The qwn-ppv
method allows to easily create quality po-
larity lexicons whenever no domain-based
annotated corpora are available for a given
language.
</bodyText>
<sectionHeader confidence="0.999511" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.980577220338983">
Opinion Mining and Sentiment Analysis are im-
portant for determining opinions about commer-
cial products, on companies reputation manage-
ment, brand monitoring, or to track attitudes by
mining social media, etc. Given the explosion of
information produced and shared via the Internet,
it is not possible to keep up with the constant flow
of new information by manual methods.
Sentiment Analysis often relies on the availabil-
ity of words and phrases annotated according to
the positive or negative connotations they convey.
‘Beautiful’, ‘wonderful’, and ‘amazing’ are exam-
ples of positive words whereas ‘bad’, ‘awful’, and
‘poor’ are examples of negatives.
The creation of lists of sentiment words has
generally been performed by means of manual-,
dictionary- and corpus-based methods. Manually
collecting such lists of polarity annotated words is
labor intensive and time consuming, and is thus
usually combined with automated approaches as
the final check to correct mistakes. However,
there are well known lexicons which have been
fully (Stone et al., 1966; Taboada et al., 2010) or
at least partially manually created (Hu and Liu,
2004; Riloff and Wiebe, 2003).
Dictionary-based methods rely on some dictio-
nary or lexical knowledge base (LKB) such as
WordNet (Fellbaum and Miller, 1998) that con-
tain synonyms and antonyms for each word. A
simple technique in this approach is to start with
some sentiment words as seeds which are then
used to perform some iterative propagation on the
LKB (Hu and Liu, 2004; Strapparava and Vali-
tutti, 2004; Kim and Hovy, 2004; Takamura et al.,
2005; Turney and Littman, 2003; Mohammad et
al., 2009; Agerri and Garc´ıa-Serrano, 2010; Bac-
cianella et al., 2010).
Corpus-based methods have usually been ap-
plied to obtain domain-specific polarity lexicons:
they have been created by either starting from a
seed list of known words and trying to find other
related words in a corpus or by attempting to di-
rectly adapt a given lexicon to a new one using
a domain-specific corpus (Hatzivassiloglou and
McKeown, 1997; Turney and Littman, 2003; Ding
et al., 2008; Choi and Cardie, 2009; Mihalcea et
al., 2007). One particular issue arising from cor-
pus methods is that for a given domain the same
word can be positive in one context but negative
in another. This is also a problem shared by man-
ual and dictionary-based methods, and that is why
qwn-ppv also produces synset-based lexicons for
approaches on Sentiment Analysis at sense level.
This paper presents a simple, robust and
(almost) unsupervised dictionary-based method,
QWordNet-PPV (QWordNet by Personalized
PageRank Vector) to automatically generate
polarity lexicons based on propagating some
automatically created seeds using a Personalized
</bodyText>
<page confidence="0.98898">
88
</page>
<note confidence="0.9935165">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 88–97,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.996998823529412">
PageRank algorithm (Agirre et al., 2014; Agirre
and Soroa, 2009) over a LKB projected into a
graph. We see qwn-ppv as an effective method-
ology to easily create polarity lexicons for any
language for which a WordNet is available.
This paper empirically shows that: (i) qwn-ppv
outperforms other automatically generated lexi-
cons (e.g. SentiWordNet 3.0, MSOL) on the 4
extrinsic evaluations presented here; it also dis-
plays competitive and robust results also with re-
spect to manually annotated lexicons; (ii) no single
polarity lexicon is fit for every Sentiment Analy-
sis task; depending on the text data and the task
itself, one lexicon will perform better than oth-
ers; (iii) if required, qwn-ppv efficently generates
many lexicons on demand, depending on the task
on which they will be used; (iv) intrinsic evalua-
tion is not appropriate to judge whether a polar-
ity lexicon is fit for a given Sentiment Analysis
(SA) task because good correlation with respect to
a gold-standard does not correspond with correla-
tion with respect to a SA task; (v) it is easily ap-
plicable to create qwn-ppv(s) for other languages,
and we demonstrate it here by creating many po-
larity lexicons not only for English but also for
Spanish; (vi) the method works at both word and
sense levels and it only requires the availability
of a LKB or dictionary; finally, (vii) a dictionary-
based method like qwn-ppv allows to easily cre-
ate quality polarity lexicons whenever no domain-
based annotated reviews are available for a given
language. After all, there usually is available a
dictionary for a given language; for example, the
Open Multilingual WordNet site lists WordNets
for up to 57 languages (Bond and Foster, 2013).
Although there has been previous work using
graph methods for obtaining lexicons via propa-
gation, the qwn-ppv method to combine the seed
generation and the Personalized PageRank prop-
agation is novel. Furthermore, it is considerable
simpler and obtains better and easier to reproduce
results than previous automatic approaches (Esuli
and Sebastiani, 2007; Mohammad et al., 2009;
Rao and Ravichandran, 2009).
Next section reviews previous related work, tak-
ing special interest on those that are currently
available for evaluation purposes. Section 3 de-
scribes the qwn-ppv method to automatically gen-
erate lexicons. The resulting lexical resources are
evaluated in section 4. We finish with some con-
cluding remarks and future work in section 5.
</bodyText>
<sectionHeader confidence="0.999786" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99978484">
There is a large amount of work on Sentiment
Analysis and Opinion Mining, and good com-
prehensive overviews are already available (Pang
and Lee, 2008; Liu, 2012), so we will review
the most representative and closest to the present
work. This means that we will not be review-
ing corpus-based approaches but rather those con-
structed manually or upon a dictionary or LKB.
We will in turn use the approaches here reviewed
for comparison with qwn-ppv in section 4.
The most popular manually-built polarity lexi-
con is part of the General Inquirer (Stone et al.,
1966), and consists of 1915 words labelled as
“positive” and 2291 as “negative”. Taboada et al.
(2010) manually created their lexicons annotating
the polarity of 6232 words on a scale of 5 to -5.
Liu et al., starting with Hu and Liu (2004), have
along the years collected a manually corrected po-
larity lexicon which is formed by 4818 negative
and 2041 positive words. Another manually cor-
rected lexicon (Riloff and Wiebe, 2003) is the one
used by the Opinion Finder system (Wilson et al.,
2005) and contains 4903 negatively and 2718 pos-
itively annotated words respectively.
Among the automatically built lexicons, Turney
and Littman (2003) proposed a minimally super-
vised algorithm to calculate the polarity of a word
depending on whether it co-ocurred more with a
previously collected small set of positive words
rather than with a set of negative ones. Agerri and
Garcia Serrano presented a very simple method
to extract the polarity information starting from
the quality synset in WordNet (Agerri and Garcia-
Serrano, 2010). Mohammad et al. (2009) de-
veloped a method in which they first identify (by
means of affixes rules) a set of positive/negative
words which act as seeds, then used a Roget-like
thesaurus to mark the synonymous words for each
polarity type and to generalize from the seeds.
They produce several lexicons the best of which,
MSOL(ASL and GI) contains 51K and 76K en-
tries respectively and uses the full General Inquirer
as seeds. They performed both intrinsic and ex-
trinsic evaluations using the MPQA 1.1 corpus.
Finally, there are two approaches that are some-
what closer to us, because they are based on Word-
Net and graph-based methods. SentiWordNet 3.0
(Baccianella et al., 2010) is built in 4 steps: (i)
they select the synsets of 14 paradigmatic pos-
itive and negative words used as seeds (Turney
</bodyText>
<page confidence="0.999588">
89
</page>
<bodyText confidence="0.999403642857143">
and Littman, 2003). These seeds are then it-
eratively extended following the construction of
WordNet-Affect (Strapparava and Valitutti, 2004).
(ii) They train 7 supervised classifiers with the
synsets’ glosses which are used to assign polar-
ity and objectivity scores to WordNet senses. (iii)
In SentiWordNet 3.0 (Esuli and Sebastiani, 2007)
they take the output of the supervised classifiers
as input to applying PageRank to WordNet 3.0’s
graph. (iv) They intrinsically evaluate it with re-
spect to MicroWnOp-3.0 using the p-normalized
Kendall τ distance (Baccianella et al., 2010). Rao
and Ravichandran (2009) apply different semi-
supervised graph algorithms (Mincuts, Random-
ized Mincuts and Label Propagation) to a set of
seeds constructed from the General Inquirer. They
evaluate the generated lexicons intrinsically taking
the General Inquirer as the gold standard for those
words that had a match in the generated lexicons.
In this paper, we describe two methods to au-
tomatically generate seeds either by following
Agerri and Garcia-Serrano (2010) or using Tur-
ney and Littman’s (2003) seeds. The automati-
cally obtained seeds are then fed into a Person-
alized PageRank algorithm which is applied over
a WordNet projected on a graph. This method is
fully automatic, simple and unsupervised as it only
relies on the availability of a LKB.
</bodyText>
<sectionHeader confidence="0.996262" genericHeader="method">
3 Generating qwn-ppv
</sectionHeader>
<bodyText confidence="0.999857">
The overall procedure of our approach consists of
two steps: (1) automatically creates a set of seeds
by iterating over a LKB (e.g. a WordNet) rela-
tions; and (2) uses the seeds to initialize contexts
to propagate over the LKB graph using a Personal-
ized Pagerank algorithm. The result is qwn-ppv(s):
Q-WordNets as Personalized PageRanking Vec-
tors.
</bodyText>
<subsectionHeader confidence="0.99966">
3.1 Seed Generation
</subsectionHeader>
<bodyText confidence="0.998907">
We generate seeds by means of two different auto-
matic procedures.
</bodyText>
<listItem confidence="0.9248425">
1. AG: We start at the quality synset of WordNet
and iterate over WordNet relations following
the original Q-WordNet method described in
Agerri and Garcia Serrano (2010).
2. TL: We take a short manually created list
of 14 positive and negative words (Turney
and Littman, 2003) and iterate over Word-
Net using five relations: antonymy, similarity,
</listItem>
<subsubsectionHeader confidence="0.346884">
derived-from, pertains-to and also-see.
</subsubsectionHeader>
<bodyText confidence="0.999955619047619">
The AG method starts the propagation from
the attributes of the quality synset in WordNet.
There are five noun quality senses in WordNet,
two of which contain attribute relations (to adjec-
tives). From the qualityn synset the attribute re-
lation takes us to positives, negatives, goods and
bads; quality�n leads to the attributes superiors and
inferiora. The following step is to iterate through
every WordNet relation collecting (i.e., annotat-
ing) those synsets that are accessible from the
seeds. Both AG and TL methods to generate seeds
rely on a number of relations to obtain a more bal-
anced POS distribution in the output synsets. The
output of both methods is a list of (assumed to be)
positive and negative synsets. Depending on the
number of iterations performed a different number
of seeds to feed UKB is obtained. Seed numbers
vary from 100 hundred to 10K synsets. Both seed
creation methods can be applied to any WordNet,
not only Princeton WordNet, as we show in sec-
tion 4.
</bodyText>
<subsectionHeader confidence="0.998567">
3.2 PPV generation
</subsectionHeader>
<bodyText confidence="0.999954">
The second and last step to generate qwn-ppv(s)
consists of propagating over a WordNet graph to
obtain a Personalized PageRanking Vector (PPV),
one for each polarity. This step requires:
</bodyText>
<listItem confidence="0.9942288">
1. A LKB projected over a graph.
2. A Personalized PageRanking algorithm
which is applied over the graph.
3. Seeds to create contexts to start the propaga-
tion, either words or synsets.
</listItem>
<bodyText confidence="0.999739533333333">
Several undirected graphs based on WordNet
3.0 as represented by the MCR 3.0 (Agirre et
al., 2012) have been created for the experimenta-
tion, which correspond to 4 main sets: (G1) two
graphs consisting of every synset linked by the
synonymy and antonymy relations; (G2) a graph
with the nodes linked by every relation, includ-
ing glosses; (G3) a graph consisting of the synsets
linked by every relation except those that are
linked by antonymy; finally, (G4) a graph consist-
ing of the nodes related by every relation except
the antonymy and gloss relations.
Using the (G1) graphs, we propagate from the
seeds over each type of graph (synonymy and
antonymy) to obtain two rankings per polarity.
</bodyText>
<page confidence="0.994653">
90
</page>
<table confidence="0.999914285714286">
Synset Level Word level
Lexicon size P Positives F Negatives size P Positives F Negatives
R P R F R P R F
Automatically created
MSOL(ASL-GI)* 32706 .65 .45 .53 .58 .76 .66 76400 .70 .49 .58 .61 .79 .69
QWN 15508 .69 .53 .60 .62 .76 .68 11693 .64 .53 .58 .60 .70 .65
SWN 27854 .73 .57 .64 .65 .79 .71 38346 .70 .55 .62 .63 .77 .69
QWN-PPV-AG(s03 G1/w01 G1) 2589 .77 .63 .69 .69 .81 .74 5119 .68 .77 .72 .73 .64 .68
QWN-PPV-TL(s04 G1/w01 G1) 5010 .76 .66 .70 .70 .79 .74 4644 .68 .71 .69 .70 .67 .68
(Semi-) Manually created
GI* 2791 .74 .57 .64 .65 .80 .72 3376 .79 .64 .71 .70 .83 .76
OF* 4640 .77 .61 .68 .68 .81 .74 6860 .82 .71 .76 .74 .84 .79
Liu* 4127 .81 .63 .71 .70 .85 .76 6786 .85 .74 .79 .77 .87 .82
SO-CAL* 4212 .75 .57 .64 .65 .81 .72 6226 .82 .70 .76 .74 .85 .79
</table>
<tableCaption confidence="0.999935">
Table 1: Evaluation of lexicons at document level using Bespalov’s Corpus.
</tableCaption>
<bodyText confidence="0.964896869565217">
The graphs created in (G2), (G3) and (G4) are
used to obtain two ranks, one for each polarity by
propagating from the seeds. In all four cases the
different polarity rankings have to be combined in
order to obtain a final polarity lexicon: the polar-
ity score pol(s) of a given synset s is computed
by adding its scores in the positive rankings and
subtracting its scores in the negative rankings. If
pol(s) &gt; 0 then s is included in the final lexicon
as positive. If pol(s) &lt; 0 then s is included in the
final lexicon as negative. We assume that synsets
with null polarity scores have no polarity and con-
sequently they are excluded from the final lexicon.
The Personalized PageRanking propagation is
performed starting from both synsets and words
and using both AG and TL styles of seed gen-
eration, as explained in section 3.1. Combin-
ing the various possibilities will produce at least
6 different lexicons for each iteration, depending
on which decisions are taken about which graph,
seeds and word/synset to create the qwn-ppv(s). In
fact, the experiments produced hundreds of lexi-
cons, according to the different iterations for seed
generation1, but we will only refer to those that
obtain the best results in the extrinsic evaluations.
With respect to the algorithm to propagate over
the WordNet graph from the automatically created
seeds, we use a Personalized PageRank algorithm
(Agirre et al., 2014; Agirre and Soroa, 2009). The
famous PageRank (Brin and Page, 1998) algo-
rithm is a method to produce a rank from the ver-
tices in a graph according to their relative struc-
tural importance. PageRank has also been viewed
as the result of a Random Walk process, where the
final rank of a given node represents the probabil-
ity of a random walk over the graph which ends on
that same node. Thus, if we take the created Word-
1The total time to generate the final 352 QWN-PPV prop-
agations amounted to around two hours of processing time in
a standard PC.
Net graph G with N vertices vi, ... , vn and di as
being the outdegree of node i, plus a N × N tran-
sition probability matrix M where Mei = 1/di
if a link from i to j exists and 0 otherwise, then
calculating the PageRank vector over a graph G
amounts to solve the following equation (1):
</bodyText>
<equation confidence="0.988168">
Pr = cMPr + (1 − c)v (1)
</equation>
<bodyText confidence="0.99998555">
In the traditional PageRank, vector v is a uni-
form normalized vector whose elements values are
all 1/N, which means that all nodes in the graph
are assigned the same probabilities in case of a
random walk. Personalizing the PageRank algo-
rithm in this case means that it is possible to make
vector v non-uniform and assign stronger proba-
bilities to certain nodes, which would make the
algorithm to propagate the initial importance of
those nodes to their vicinity. Following Agirre et
al. (2014), in our approach this translates into ini-
tializing vector v with those senses obtained by the
seed generation methods described above in sec-
tion 3.1. Thus, the initialization of vector v us-
ing the seeds allows the Personalized propagation
to assign greater importance to those synsets in
the graph identified as being positive and negative,
which resuls in a PPV with the weigths skewed to-
wards those nodes initialized/personalized as pos-
itive and negative.
</bodyText>
<sectionHeader confidence="0.99944" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999972666666667">
Previous approaches have provided intrinsic eval-
uation (Mohammad et al., 2009; Rao and
Ravichandran, 2009; Baccianella et al., 2010) us-
ing manually annotated resources such as the Gen-
eral Inquirer (Stone et al., 1966) as gold stan-
dard. To facilitate comparison, we also provide
such evaluation in section 4.3. Nevertheless, and
as demonstrated by the results of the extrinsic eval-
uations, we believe that polarity lexicons should
</bodyText>
<page confidence="0.99397">
91
</page>
<table confidence="0.999965928571429">
Synset Level Word level
Lexicon size P Positives F Negatives size P Positives F Negatives
R P R F R P R F
Automatically created
MSOL(ASL-GI)* 32706 .56 .37 .44 .76 .87 .81 76400 .67 .5 .57 .80 .89 .85
QWN 15508 .63 .22 .33 .73 .94 .83 11693 .58 .22 .31 .73 .93 .82
SWN 27854 .57 .33 .42 .75 .89 .81 38346 .55 .55 .55 .80 .8 .80
QWN-PPV-AG (w10 G3/s09 G4) 117485 .60 .63 .62 .83 .82 .83 144883 .65 .50 .57 .80 .88 .84
QWN-PPV-TL (s05 G4) 114698 .61 .58 .59 .82 .83 .83 144883 .66 .53 .59 .81 .88 .84
(Semi-) Manually created
GI* 2791 .70 .32 .44 .76 .94 .84 3376 .71 .56 .62 .82 .90 .86
OF* 4640 .67 .37 .48 .77 .92 .84 6860 .75 .68 .71 .87 .90 .88
Liu* 4127 .67 .33 .44 .76 .93 .83 6786 .78 .45 .57 .79 .94 .86
SO-CAL* 4212 .69 .3 .42 .75 .94 .84 6226 .73 .53 .61 .81 .91 .86
</table>
<tableCaption confidence="0.999795">
Table 2: Evaluation of lexicons using averaged ratio on the MPQA 1.2test Corpus.
</tableCaption>
<bodyText confidence="0.996733666666667">
in general be evaluated extrinsically. After all,
any polarity lexicon is as good as the results ob-
tained by using it for a particular Sentiment Anal-
ysis task.
Our goal is to evaluate the polarity lexicons
simplifying the evaluation parameters to avoid as
many external influences as possible on the re-
sults. We compare our work with most of the
lexicons reviewed in section 2, both at synset
and word level, both manually and automatically
generated: General Inquirer (GI), Opinion Finder
(OF), Liu, Taboada et al.’s (SO-CAL), Agerri
and Garcia-Serrano (2010) (QWN), Mohammad
et al’s, (MSOL(ASL-GI)) and SentiWordNet 3.0
(SWN). The results presented in section 4.2 show
that extrinsic evaluation is more meaningful to de-
termine the adequacy of a polarity lexicon for a
specific Sentiment Analysis task.
</bodyText>
<subsectionHeader confidence="0.969282">
4.1 Datasets and Evaluation System
</subsectionHeader>
<bodyText confidence="0.999983833333334">
Three different corpora were used: Bespalov et
al.’s (2011) and MPQA (Riloff and Wiebe, 2003)
for English, and HOpinion2 in Spanish. In addi-
tion, we divided the corpus into two subsets (75%
development and 25% test) for applying our ratio
system for the phrase polarity task too. Note that
the development set is only used to set up the po-
larity classification task, and that the generation of
qwn-ppv lexicons is unsupervised.
For Spanish we tried to reproduce the English
settings with Bespalov’s corpus. Thus, both devel-
opment and test sets were created from the HOpin-
ion corpus. As it contains a much higher propor-
tion of positive reviews, we created also subsets
which contain a balanced number of positive and
negative reviews to allow for a more meaningful
comparison than that of table 6. Table 3 shows the
number of documents per polarity for Bespalov’s,
</bodyText>
<footnote confidence="0.911089">
2http://clic.ub.edu/corpus/hopinion
</footnote>
<table confidence="0.968468636363636">
MPQA 1.2 and HOpinion.
Corpus POS docs NEG docs Total
Bespalovdev 23,112 23,112 46,227
Bespalovtest 10,557 10,557 21,115
MPQA 1.2dev 2,315 5,260 7,575
MPQA 1.2test 771 1,753 2,524
MPQA 1.2total 3,086 7,013 10,099
HOpinion Balanceddev 1,582 1,582 3,164
HOpinion Balancedtest 528 528 1,056
HOpiniondev 9,236 1,582 10,818
HOpiniontest 3,120 528 3,648
</table>
<tableCaption confidence="0.753194">
Table 3: Number of positive and negative docu-
ments in train and test sets.
</tableCaption>
<bodyText confidence="0.999602285714286">
We report results of 4 extrinsic evaluations or
tasks, three of them based on a simple ratio av-
erage system, inspired by Turney (2002), and an-
other one based on Mohammad et al. (2009). We
first implemented a simple average ratio classi�er
which computes the average ratio of the polarity
words found in document d:
</bodyText>
<equation confidence="0.945259">
polarity(d) = Ew∈ d p l(w) (2)
Idl
</equation>
<bodyText confidence="0.999962470588235">
where, for each polarity, pol(w) is 1 if w is in-
cluded in the polarity lexicon and 0 otherwise.
Documents that reach a certain threshold are clas-
sified as positive, and otherwise as negative. To
setup an evaluation enviroment as fair as possi-
ble for every lexicon, the threshold is optimised by
maximising accuracy over the development data.
Second, we implemented a phrase polarity task
identification as described by Mohammad et al.
(2009). Their method consists of: (i) if any of
the words in the target phrase is contained in the
negative lexicon, then the polarity is negative; (ii)
if none of the words are negative, and at least one
word is in the positive lexicon, then is positive;
(iii) the rest are not tagged.
We chose this very simple polarity estimators
because our aim was to minimize the role other
</bodyText>
<page confidence="0.992169">
92
</page>
<table confidence="0.999936357142857">
Synset Level Word level
Lexicon size P Positives F Negatives size P Positives F Negatives
R P R F R P R F
Automatically created
MSOL(ASL-GI)* 32706 .52 .48 .50 .85 .62 .71 76400 .68 .56 .62 .82 .86 .84
QWN 15508 .50 .36 .42 .84 .32 .46 11693 .45 .49 .47 .78 .51 .61
SWN 27854 .50 .45 .47 .85 .48 .61 38346 .49 .52 .50 .78 .68 .73
QWN-PPV-AG (s09 G3/w02 G3) 117485 .59 .67 .63 .85 .78 .82 147194 .64 .64 .64 .84 .83 .83
QWN-PPV-TL (w02 G3/s06 G3) 117485 .59 .57 .58 .82 .81 .81 147194 .63 .67 .65 .85 .81 .83
(Semi-) Manually created
GI* 2791 .60 .40 .47 .91 .38 .54 3376 .70 .60 .65 .93 .52 .67
OF* 4640 .63 .42 .50 .93 .46 .62 6860 .75 .71 .73 .95 .66 .78
Liu* 4127 .65 .36 .47 .94 .45 .60 6786 .78 .49 .60 .97 .61 .75
SO-CAL* 4212 .65 .37 .47 .92 .45 .60 6226 .73 .57 .64 .96 .59 .73
</table>
<tableCaption confidence="0.9927725">
Table 4: Evaluation of lexicons at phrase level using Mohammad et al.’s (2009) method on MPQA
1.2total Corpus.
</tableCaption>
<bodyText confidence="0.999161310344828">
aspects play in the evaluation and focus on how,
other things being equal, polarity lexicons perform
in a Sentiment Analysis task. The average ratio
is used to present results of tables 1 and 2 (with
Bespalov corpus), and 5 and 6 (with HOpinion),
whereas Mohammad et al.’s is used to report re-
sults in table 4. Mohammad et al.’s (2009) testset
based on MPQA 1.1 is smaller, but both MPQA
1.1 and 1.2 are hugely skewed towards negative
polarity (30% positive vs. 70% negative).
All datasets were POS tagged and Word
Sense Disambiguated using FreeLing (Padr´o and
Stanilovsky, 2012; Agirre and Soroa, 2009). Hav-
ing word sense annotated datasets gives us the op-
portunity to evaluate the lexicons both at word and
sense levels. For the evaluation of those lexicons
that are synset-based, such as qwn-ppv and Sen-
tiWordNet 3.0, we convert them from senses to
words by taking every word or variant contained
in each of their senses. Moreover, if a lemma ap-
pears as a variant in several synsets the most fre-
quent polarity is assigned to that lemma.
With respect to lexicons at word level, we take
the most frequent sense according to WordNet 3.0
for each of their positive and negative words. Note
that the latter conversion, for synset based evalua-
tion, is mostly done to show that the evaluation at
synset level is harder independently of the quality
of the lexicon evaluated.
</bodyText>
<sectionHeader confidence="0.715737" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.999907744680851">
Although tables 1, 2 and 4 also present re-
sults at synset level, it should be noted that the
only polarity lexicons available to us for com-
parison at synset level were Q-WordNet (Agerri
and Garcia-Serrano, 2010) and SentiWordNet 3.0
(Baccianella et al., 2010). QWN-PPV-AG refers
to the lexicon generated starting from AG’s seeds,
and QWN-PPV-TL using TL’s seeds as described
in section 3.1. Henceforth, we will use qwn-ppv to
refer to the overall method presented in this paper,
regardless of the seeds used.
For every qwn-ppv result reported in this sec-
tion, we have used every graph described in sec-
tion 3.2. The configuration of each qwn-ppv in the
results specifies which seed iteration is used as the
initialization of the Personalized PageRank algo-
rithm, and on which graph. Thus, QWN-PPV-TL
(s05 G4) in table 2 means that the 5th iteration of
synset seeds was used to propagate over graph G4.
If the configuration were (w05 G4) it would have
meant ‘the 5th iteration of word seeds were used
to propagate over graph G4’. The simplicity of
our approach allows us to generate many lexicons
simply by projecting a LKB over different graphs.
The lexicons marked with an asterisk denote
those that have been converted from word to
senses using the most frequent sense of WordNet
3.0. We would like to stress again that the purpose
of such word to synset conversion is to show that
SA tasks at synset level are harder than at word
level. In addition, it should also be noted that in
the case of SO-CAL (Taboada et al., 2010), we
have reduced what is a graded lexicon with scores
ranging from 5 to -5 into a binary one.
Table 1 shows that (at least partially) manually
built lexicons obtain the best results on this eval-
uation. It also shows that qwn-ppv clearly out-
performs any other automatically built lexicons.
Moreover, manually built lexicons suffer from the
evaluation at synset level, obtaining most of them
lower scores than qwn-ppv, although Liu’s (Hu
and Liu, 2004) still obtains the best results. In any
case, for an unsupervised procedure, qwn-ppv lex-
icons obtain very competitive results with respect
to manually created lexicons and is the best among
the automatic methods. It should also be noted that
the best results of qwn-ppv are obtained with graph
</bodyText>
<page confidence="0.997315">
93
</page>
<bodyText confidence="0.979462214285714">
G1 and with very few seed iterations.
Table 2 again sees the manually built lexi-
cons performing better although overall the dif-
ferences are lower with respect to automatically
built lexicons. Among these, qwn-ppv again ob-
tains the best results, both at synset and word
level, although in the latter the differences with
MSOL(ASL-GI) are not large. Finally, table 4
shows that qwn-ppv again outperforms other auto-
matic approaches and is closer to those have been
(partially at least) manually built. In both MPQA
evaluations the best graph overall to propagate the
seeds is G3 because this type of task favours high
recall.
</bodyText>
<table confidence="0.94741825">
Positives Negatives
Lexicon size P R F P R F
Automatically created
SWN 27854 .87 .99 .93 .70 .16 .27
QWN-PPV-AG 3306 .86 .00 .92 .67 .01 .02
(wrd01 G1)
QWN-PPV-TL 5010 .89 .96 .93 .58 .30 .39
(s04 G1)
</table>
<tableCaption confidence="0.965862">
Table 5: Evaluation of Spanish lexicons using the
full HOpinion corpus at synset level.
</tableCaption>
<bodyText confidence="0.9992232">
We report results on the Spanish HOpinion cor-
pus in tables 5 and 6. Mihalcea(f) is a manu-
ally revised lexicon based on the automatically
built Mihalcea(m) (P´erez-Rosas et al., 2012). Elh-
Polar (Saralegi and San Vicente, 2013) is semi-
automatically built and manually corrected. SO-
CAL is built manually. SWN and QWN-PPV have
been built via the MCR 3.0’s ILI by applying the
synset to word conversion previously described on
the Spanish dictionary of the MCR. The results for
Spanish at word level in table 6 show the same
trend as for English: qwn-ppv is the best of the
automatic approaches and it obtains competitive
although not as good as the best of the manually
created lexicons (ElhPolar). Due to the dispro-
portionate number of positive reviews, the results
for the negative polarity are not useful to draw any
meaningful conclusions. Thus, we also performed
an evaluation with HOpinion Balanced set as listed
in table 3.
The results with a balanced HOpinion, not
shown due to lack of space, also confirm the pre-
vious trend: qwn-ppv outperforms other automatic
approaches but is still worse than the best of the
manually created ones (ElhPolar).
</bodyText>
<table confidence="0.982543615384615">
Positives Negatives
Lexicon size P R F P R F
Automatically created
Mihalcea(m) 2496 .86 .00 .92 .00 .00 .00
SWN 9712 .88 .97 .92 .55 .19 .28
QWN-PPV-AG 1926 .89 .97 .93 .59 .26 .36
(s11 G1)
QWN-PPV-TL 939 .89 .98 .93 .71 .26 .38
(s03 G1)
(Semi-) Manually created
ElhPolar 4673 .94 .94 .94 .64 .64 .64
Mihalcea(f) 1347 .91 .96 .93 .61 .41 .49
SO-CAL 4664 .92 .96 .94 .70 .51 .59
</table>
<tableCaption confidence="0.9979135">
Table 6: Evaluation of Spanish lexicons using the
full HOpinion corpus at word level.
</tableCaption>
<subsectionHeader confidence="0.995182">
4.3 Intrinsic evaluation
</subsectionHeader>
<bodyText confidence="0.999275235294118">
To facilitate intrinsic comparison with previous
approaches, we evaluate our automatically gener-
ated lexicons against GI. For each qwn-ppv lex-
icon shown in previous extrinsic evaluations, we
compute the intersection between the lexicon and
GI, and evaluate the words in that intersection. Ta-
ble 7 shows results for the best-performing QWN-
PPV lexicons (both using AG and TL seeds) in
the extrinsic evaluations at word level of tables 1
(first two rows), 2 (rows 3 and 4) and 4 (rows 5
and 6). We can see that QWN-PPV lexicons sys-
tematically outperform SWN in number of correct
entries. QWN-PPV-TL lexicons obtain 75.04%
of correctness on average. The best performing
lexicon contains up to 81.07% of correct entries.
Note that we did not compare the results with
MSOL(ASL-GI) because it contains the GI.
</bodyText>
<table confidence="0.999297375">
Lexicon ∩ wrt. GI Acc. Pos Neg
SWN 2,755 .74 .76 .73
QWN-PPV-AG (w01 G1) 849 .71 .68 .75
QWN-PPV-TL (w01 G1) 713 .78 .80 .76
QWN-PPV-AG (s09 G4) 3,328 .75 .75 .77
QWN-PPV-TL (s05 G4) 3,333 .80 .84 .77
QWN-PPV-AG (w02 G3) 3,340 .74 .71 .77
QWN-PPV-TL (s06 G3) 3,340 .77 .79 .77
</table>
<tableCaption confidence="0.927554">
Table 7: Accuracy QWN-PPV lexicons and SWN
with respect to the GI lexicon.
</tableCaption>
<subsectionHeader confidence="0.989493">
4.4 Discussion
</subsectionHeader>
<bodyText confidence="0.9999465">
QWN-PPV lexicons obtain the best results among
the evaluations for English and Spanish. Further-
more, across tasks and datasets qwn-ppv provides
a more consistent and robust behaviour than most
of the manually-built lexicons apart from OF. The
results also show that for a task requiring high
</bodyText>
<page confidence="0.998525">
94
</page>
<bodyText confidence="0.999970523809524">
recall the larger graphs, e.g. G3, are preferable,
whereas for a more balanced dataset and document
level task smaller G1 graphs perform better.
These are good results considering that our
method to generate qwn-ppv is simpler, more ro-
bust and adaptable than previous automatic ap-
proaches. Furthermore, although also based on
a Personalized PageRank application, it is much
simpler than SentiWordNet 3.0, consistently out-
performed by qwn-ppv on every evaluation and
dataset. The main differences with respect to Sen-
tiWordNet’s approach are the following: (i) the
seed generation and training of 7 supervised clas-
sifiers corresponds in qwn-ppv to only one simple
step, namely, the automatic generation of seeds
as explained in section 3.1; (ii) the generation
of qwn-ppv only requires a LKB’s graph for the
Personalized PageRank propagation, no disam-
biguated glosses; (iii) the graph they use to do
the propagation also depends on disambiguated
glosses, not readily available for any language.
The fact that qwn-ppv is based on already
available WordNets projected onto simple graphs
is crucial for the robustness and adaptability of
the qwn-ppv method across evaluation tasks and
datasets: Our method can quickly create, over dif-
ferent graphs, many lexicons of diffent sizes which
can then be evaluated on a particular polarity clas-
sification task and dataset. Hence the different
configurations of the qwn-ppv lexicons, because
for some tasks a G3 graph with more AG/TL seed
iterations will obtain better recall and viceversa.
This is confirmed by the results: the tasks using
MPQA seem to clearly benefit from high recall
whereas the Bespalov’s corpus has overall, more
balanced scores. This could also be due to the size
of Bespalov’s corpus, almost 10 times larger than
MPQA 1.2.
The experiments to generate Spanish lexicons
confirm the trend showed by the English evalua-
tions: Lexicons generated by qwn-ppv consistenly
outperform other automatic approaches, although
some manual lexicon is better on a given task and
dataset (usually a different one). Nonetheless the
Spanish evaluation shows that our method is also
robust across languages as it gets quite close to
the manually corrected lexicon of Mihalcea(full)
(P´erez-Rosas et al., 2012).
The results also confirm that no single lexicon is
the most appropriate for any SA task or dataset and
domain. In this sense, the adaptability of qwn-ppv
is a desirable feature for lexicons to be employed
in SA tasks: the unsupervised qwn-ppv method
only relies on the availability of a LKB to build
hundreds of polarity lexicons which can then be
evaluated on a given task and dataset to choose the
best fit. If not annotated evaluation set is avail-
able, G3-based propagations provide the best re-
call whereas the G1-based lexicons are less noisy.
Finally, we believe that the results reported here
point out to the fact that intrinsic evaluations are
not meaningful to judge the adequacy a polarity
lexicon for a specific SA task.
</bodyText>
<sectionHeader confidence="0.985214" genericHeader="conclusions">
5 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999925615384615">
This paper presents an unsupervised dictionary-
based method qwn-ppv to automatically generate
polarity lexicons. Although simpler than similar
automatic approaches, it still obtains better results
on the four extrinsic evaluations presented. Be-
cause it only depends on the availability of a LKB,
we believe that this method can be valuable to gen-
erate on-demand polarity lexicons for a given lan-
guage when not sufficient annotated data is avail-
able. We demonstrate the adaptability of our ap-
proach by producing good performance polarity
lexicons for different evaluation scenarios and for
more than one language.
Further work includes investigating different
graph projections of WordNet relations to do the
propagation as well as exploiting synset weights.
We also plan to investigate the use of annotated
corpora to generate lexicons at word level to try
and close the gap with those that have been (at
least partially) manually annotated.
The qwn-ppv lexicons and graphs used in this
paper are publicly available (under CC-BY li-
cense): http://adimen.si.ehu.es/web/qwn-ppv. The
qwn-ppv tool to automatically generate polarity
lexicons given a WordNet in any language will
soon be available in the aforementioned URL.
</bodyText>
<sectionHeader confidence="0.997837" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<footnote confidence="0.9768496">
This work has been supported by the OpeNER FP7
project under Grant No. 296451, the FP7 News-
Reader project, Grant No. 316404 and by the
Spanish MICINN project SKATER under Grant
No. TIN2012-38584-C06-01.
</footnote>
<page confidence="0.997925">
95
</page>
<sectionHeader confidence="0.996396" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999859663551402">
R. Agerri and A. Garc´ıa-Serrano. 2010. Q-WordNet:
extracting polarity from WordNet senses. In Seventh
Conference on International Language Resources
and Evaluation, Malta. Retrieved May, volume 25,
page 2010.
Eneko Agirre and Aitor Soroa. 2009. Personalizing
pagerank for word sense disambiguation. In Pro-
ceedings of the 12th Conference of the European
Chapter of the Association for Computational Lin-
guistics (EACL-2009), Athens, Greece.
Aitor Gonz´alez Agirre, Egoitz Laparra, German Rigau,
and Basque Country Donostia. 2012. Multilin-
gual central repository version 3.0: upgrading a very
large lexical knowledge base. In GWC 2012 6th In-
ternational Global Wordnet Conference, page 118.
Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa.
2014. Random walks for knowledge-based word
sense disambiguation. Computational Linguistics,
(Early Access).
S. Baccianella, A. Esuli, and F. Sebastiani. 2010. Sen-
tiWordNet 3.0: An enhanced lexical resource for
sentiment analysis and opinion mining. In Seventh
conference on International Language Resources
and Evaluation (LREC-2010), Malta., volume 25.
Dmitriy Bespalov, Bing Bai, Yanjun Qi, and Ali Shok-
oufandeh. 2011. Sentiment classification based on
supervised latent n-gram analysis. In Proceedings of
the 20th ACM international conference on Informa-
tion and knowledge management, pages 375–382.
Francis Bond and Ryan Foster. 2013. Linking and ex-
tending an open multilingual wordnet. In 51st An-
nual Meeting of the Association for Computational
Linguistics: ACL-2013.
Sergey Brin and Lawrence Page. 1998. The
anatomy of a large-scale hypertextual web search
engine. Computer networks and ISDN systems,
30(1):107117.
Y. Choi and C. Cardie. 2009. Adapting a polarity lexi-
con using integer linear programming for domain-
specific sentiment classification. In Proceedings
of the 2009 Conference on Empirical Methods in
Natural Language Processing: Volume 2-Volume 2,
pages 590–598.
X. Ding, B. Liu, and P. S. Yu. 2008. A holistic lexicon-
based approach to opinion mining. In Proceedings
of the international conference on Web search and
web data mining, pages 231–240.
Andrea Esuli and Fabrizio Sebastiani. 2007. Pager-
anking wordnet synsets: An application to opinion
mining. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 424–431, Prague, Czech Republic, June. As-
sociation for Computational Linguistics.
C. Fellbaum and G. Miller, editors. 1998. Wordnet:
An Electronic Lexical Database. MIT Press, Cam-
bridge (MA).
V. Hatzivassiloglou and K. R McKeown. 1997. Pre-
dicting the semantic orientation of adjectives. In
Proceedings of the eighth conference on European
chapter of the Association for Computational Lin-
guistics, pages 174–181.
M. Hu and B. Liu. 2004. Mining and summariz-
ing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 168–177.
Soo-Min Kim and Eduard Hovy. 2004. Determining
the sentiment of opinions. In Proceedings of Coling
2004, pages 1367–1373, Geneva, Switzerland, Aug
23–Aug 27. COLING.
Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.
R. Mihalcea, C. Banea, and J. Wiebe. 2007. Learning
multilingual subjective language via cross-lingual
projections. In Annual Meeting of the Associa-
tion for Computational Linguistics, volume 45, page
976.
S. Mohammad, C. Dunne, and B. Dorr. 2009. Gen-
erating high-coverage semantic orientation lexicons
from overtly marked words and a thesaurus. In
Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume
2-Volume 2, pages 599–608.
Llu´ıs Padr´o and Evgeny Stanilovsky. 2012. Freeling
3.0: Towards wider multilinguality. In Proceedings
of the Language Resources and Evaluation Confer-
ence (LREC 2012), Istanbul, Turkey, May. ELRA.
B. Pang and L. Lee. 2008. Opinion mining and senti-
ment analysis. Foundations and Trends in Informa-
tion Retrieval, 2(1-2):1–135.
Ver´onica P´erez-Rosas, Carmen Banea, and Rada Mi-
halcea. 2012. Learning sentiment lexicons in span-
ish. In LREC, pages 3077–3081.
D. Rao and D. Ravichandran. 2009. Semi-supervised
polarity lexicon induction. In Proceedings of the
12th Conference of the European Chapter of the As-
sociation for Computational Linguistics, pages 675–
682.
E. Riloff and J. Wiebe. 2003. Learning extraction pat-
terns for subjective expressions. In Proceedings of
the International Conference on Empirical Methods
in Natural Language Processing (EMNLP’03).
Xabier Saralegi and I˜naki San Vicente. 2013. Elhuyar
at TASS2013. In XXIX Congreso de la Sociedad Es-
paola de Procesamiento de lenguaje natural, Work-
shop on Sentiment Analysis at SEPLN (TASS2013),
pages 143–150, Madrid.
</reference>
<page confidence="0.972019">
96
</page>
<reference confidence="0.999719323529412">
P. Stone, D. Dunphy, M. Smith, and D. Ogilvie. 1966.
The General Inquirer: A Computer Approach to
Content Analysis. Cambridge (MA): MIT Press.
Carlo Strapparava and Alessandro Valitutti. 2004.
Wordnet-affect: an affective extension of wordnet.
In Proceedings of the 4th International Conference
on Languages Resources and Evaluation (LREC
2004), pages 1083–1086, Lisbon, May.
M. Taboada, J. Brooke, M. Tofiloski, K. Voll, and
M. Stede. 2010. Lexicon-based methods for sen-
timent analysis. Computational Linguistics, (Early
Access):141.
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientations of words us-
ing spin model. In Proceedings of the 43rd Annual
Meeting of the Association for Computational Lin-
guistics (ACL’05), page 133140, Ann Arbor, Michi-
gan, June. Association for Computational Linguis-
tics.
P. Turney and M. Littman. 2003. Measuring praise and
criticism: Inference of semantic oreintation from as-
sociation. ACM Transaction on Information Sys-
tems, 21(4):315–346.
P.D. Turney. 2002. Thumbs up or thumbs down?: se-
mantic orientation applied to unsupervised classifi-
cation of reviews. In Proceedings of the 40th Annual
Meeting on Association for Computational Linguis-
tics, page 417424.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of the con-
ference on Human Language Technology and Em-
pirical Methods in Natural Language Processing,
page 347354.
</reference>
<page confidence="0.999691">
97
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.254205">
<title confidence="0.9992835">Simple, Robust and (almost) Unsupervised Generation of Lexicons for Multiple Languages</title>
<author confidence="0.995815">San Vicente</author>
<author confidence="0.995815">Rodrigo Agerri</author>
<author confidence="0.995815">German</author>
<affiliation confidence="0.9896475">IXA NLP University of the Basque Country</affiliation>
<note confidence="0.292105">Donostia-San</note>
<abstract confidence="0.9947724">This paper presents a simple, robust and (almost) unsupervised dictionary-based as Personalized PageRanking Vector) to automatically generate polarity lexicons. We show other automatically generated lexicons for the four extrinsic evaluations presented here. It also shows very competitive and robust results with respect to manually annotated ones. Results suggest that no single lexicon is best for every task and dataset and that the intrinsic evaluation of polarity lexicons is not a good performance indicator on Sentiment Analysis task. The method allows to easily create quality polarity lexicons whenever no domain-based annotated corpora are available for a given language.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Agerri</author>
<author>A Garc´ıa-Serrano</author>
</authors>
<title>Q-WordNet: extracting polarity from WordNet senses.</title>
<date>2010</date>
<booktitle>In Seventh Conference on International Language Resources and Evaluation,</booktitle>
<volume>25</volume>
<pages>page</pages>
<location>Malta. Retrieved</location>
<marker>Agerri, Garc´ıa-Serrano, 2010</marker>
<rawString>R. Agerri and A. Garc´ıa-Serrano. 2010. Q-WordNet: extracting polarity from WordNet senses. In Seventh Conference on International Language Resources and Evaluation, Malta. Retrieved May, volume 25, page 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>Personalizing pagerank for word sense disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2009),</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="4052" citStr="Agirre and Soroa, 2009" startWordPosition="609" endWordPosition="612">produces synset-based lexicons for approaches on Sentiment Analysis at sense level. This paper presents a simple, robust and (almost) unsupervised dictionary-based method, QWordNet-PPV (QWordNet by Personalized PageRank Vector) to automatically generate polarity lexicons based on propagating some automatically created seeds using a Personalized 88 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 88–97, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics PageRank algorithm (Agirre et al., 2014; Agirre and Soroa, 2009) over a LKB projected into a graph. We see qwn-ppv as an effective methodology to easily create polarity lexicons for any language for which a WordNet is available. This paper empirically shows that: (i) qwn-ppv outperforms other automatically generated lexicons (e.g. SentiWordNet 3.0, MSOL) on the 4 extrinsic evaluations presented here; it also displays competitive and robust results also with respect to manually annotated lexicons; (ii) no single polarity lexicon is fit for every Sentiment Analysis task; depending on the text data and the task itself, one lexicon will perform better than oth</context>
<context position="15349" citStr="Agirre and Soroa, 2009" startWordPosition="2508" endWordPosition="2511">ined in section 3.1. Combining the various possibilities will produce at least 6 different lexicons for each iteration, depending on which decisions are taken about which graph, seeds and word/synset to create the qwn-ppv(s). In fact, the experiments produced hundreds of lexicons, according to the different iterations for seed generation1, but we will only refer to those that obtain the best results in the extrinsic evaluations. With respect to the algorithm to propagate over the WordNet graph from the automatically created seeds, we use a Personalized PageRank algorithm (Agirre et al., 2014; Agirre and Soroa, 2009). The famous PageRank (Brin and Page, 1998) algorithm is a method to produce a rank from the vertices in a graph according to their relative structural importance. PageRank has also been viewed as the result of a Random Walk process, where the final rank of a given node represents the probability of a random walk over the graph which ends on that same node. Thus, if we take the created Word1The total time to generate the final 352 QWN-PPV propagations amounted to around two hours of processing time in a standard PC. Net graph G with N vertices vi, ... , vn and di as being the outdegree of node</context>
<context position="23270" citStr="Agirre and Soroa, 2009" startWordPosition="3923" endWordPosition="3926">A 1.2total Corpus. aspects play in the evaluation and focus on how, other things being equal, polarity lexicons perform in a Sentiment Analysis task. The average ratio is used to present results of tables 1 and 2 (with Bespalov corpus), and 5 and 6 (with HOpinion), whereas Mohammad et al.’s is used to report results in table 4. Mohammad et al.’s (2009) testset based on MPQA 1.1 is smaller, but both MPQA 1.1 and 1.2 are hugely skewed towards negative polarity (30% positive vs. 70% negative). All datasets were POS tagged and Word Sense Disambiguated using FreeLing (Padr´o and Stanilovsky, 2012; Agirre and Soroa, 2009). Having word sense annotated datasets gives us the opportunity to evaluate the lexicons both at word and sense levels. For the evaluation of those lexicons that are synset-based, such as qwn-ppv and SentiWordNet 3.0, we convert them from senses to words by taking every word or variant contained in each of their senses. Moreover, if a lemma appears as a variant in several synsets the most frequent polarity is assigned to that lemma. With respect to lexicons at word level, we take the most frequent sense according to WordNet 3.0 for each of their positive and negative words. Note that the latte</context>
</contexts>
<marker>Agirre, Soroa, 2009</marker>
<rawString>Eneko Agirre and Aitor Soroa. 2009. Personalizing pagerank for word sense disambiguation. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2009), Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aitor Gonz´alez Agirre</author>
<author>Egoitz Laparra</author>
<author>German Rigau</author>
<author>Basque Country Donostia</author>
</authors>
<title>Multilingual central repository version 3.0: upgrading a very large lexical knowledge base.</title>
<date>2012</date>
<booktitle>In GWC 2012 6th International Global Wordnet Conference,</booktitle>
<pages>118</pages>
<contexts>
<context position="12470" citStr="Agirre et al., 2012" startWordPosition="1987" endWordPosition="1990">red to 10K synsets. Both seed creation methods can be applied to any WordNet, not only Princeton WordNet, as we show in section 4. 3.2 PPV generation The second and last step to generate qwn-ppv(s) consists of propagating over a WordNet graph to obtain a Personalized PageRanking Vector (PPV), one for each polarity. This step requires: 1. A LKB projected over a graph. 2. A Personalized PageRanking algorithm which is applied over the graph. 3. Seeds to create contexts to start the propagation, either words or synsets. Several undirected graphs based on WordNet 3.0 as represented by the MCR 3.0 (Agirre et al., 2012) have been created for the experimentation, which correspond to 4 main sets: (G1) two graphs consisting of every synset linked by the synonymy and antonymy relations; (G2) a graph with the nodes linked by every relation, including glosses; (G3) a graph consisting of the synsets linked by every relation except those that are linked by antonymy; finally, (G4) a graph consisting of the nodes related by every relation except the antonymy and gloss relations. Using the (G1) graphs, we propagate from the seeds over each type of graph (synonymy and antonymy) to obtain two rankings per polarity. 90 Sy</context>
</contexts>
<marker>Agirre, Laparra, Rigau, Donostia, 2012</marker>
<rawString>Aitor Gonz´alez Agirre, Egoitz Laparra, German Rigau, and Basque Country Donostia. 2012. Multilingual central repository version 3.0: upgrading a very large lexical knowledge base. In GWC 2012 6th International Global Wordnet Conference, page 118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Oier Lopez de Lacalle</author>
<author>Aitor Soroa</author>
</authors>
<title>Random walks for knowledge-based word sense disambiguation. Computational Linguistics, (Early Access).</title>
<date>2014</date>
<marker>Agirre, de Lacalle, Soroa, 2014</marker>
<rawString>Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa. 2014. Random walks for knowledge-based word sense disambiguation. Computational Linguistics, (Early Access).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Baccianella</author>
<author>A Esuli</author>
<author>F Sebastiani</author>
</authors>
<title>SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In Seventh conference on International Language Resources and Evaluation (LREC-2010),</booktitle>
<volume>25</volume>
<contexts>
<context position="2741" citStr="Baccianella et al., 2010" startWordPosition="408" endWordPosition="412"> al., 2010) or at least partially manually created (Hu and Liu, 2004; Riloff and Wiebe, 2003). Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet (Fellbaum and Miller, 1998) that contain synonyms and antonyms for each word. A simple technique in this approach is to start with some sentiment words as seeds which are then used to perform some iterative propagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been applied to obtain domain-specific polarity lexicons: they have been created by either starting from a seed list of known words and trying to find other related words in a corpus or by attempting to directly adapt a given lexicon to a new one using a domain-specific corpus (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Ding et al., 2008; Choi and Cardie, 2009; Mihalcea et al., 2007). One particular issue arising from corpus methods is that for a given domain the same word can be positive in one context but negative in another. This is als</context>
<context position="8698" citStr="Baccianella et al., 2010" startWordPosition="1374" endWordPosition="1377"> they first identify (by means of affixes rules) a set of positive/negative words which act as seeds, then used a Roget-like thesaurus to mark the synonymous words for each polarity type and to generalize from the seeds. They produce several lexicons the best of which, MSOL(ASL and GI) contains 51K and 76K entries respectively and uses the full General Inquirer as seeds. They performed both intrinsic and extrinsic evaluations using the MPQA 1.1 corpus. Finally, there are two approaches that are somewhat closer to us, because they are based on WordNet and graph-based methods. SentiWordNet 3.0 (Baccianella et al., 2010) is built in 4 steps: (i) they select the synsets of 14 paradigmatic positive and negative words used as seeds (Turney 89 and Littman, 2003). These seeds are then iteratively extended following the construction of WordNet-Affect (Strapparava and Valitutti, 2004). (ii) They train 7 supervised classifiers with the synsets’ glosses which are used to assign polarity and objectivity scores to WordNet senses. (iii) In SentiWordNet 3.0 (Esuli and Sebastiani, 2007) they take the output of the supervised classifiers as input to applying PageRank to WordNet 3.0’s graph. (iv) They intrinsically evaluate </context>
<context position="17281" citStr="Baccianella et al., 2010" startWordPosition="2853" endWordPosition="2856"> Agirre et al. (2014), in our approach this translates into initializing vector v with those senses obtained by the seed generation methods described above in section 3.1. Thus, the initialization of vector v using the seeds allows the Personalized propagation to assign greater importance to those synsets in the graph identified as being positive and negative, which resuls in a PPV with the weigths skewed towards those nodes initialized/personalized as positive and negative. 4 Evaluation Previous approaches have provided intrinsic evaluation (Mohammad et al., 2009; Rao and Ravichandran, 2009; Baccianella et al., 2010) using manually annotated resources such as the General Inquirer (Stone et al., 1966) as gold standard. To facilitate comparison, we also provide such evaluation in section 4.3. Nevertheless, and as demonstrated by the results of the extrinsic evaluations, we believe that polarity lexicons should 91 Synset Level Word level Lexicon size P Positives F Negatives size P Positives F Negatives R P R F R P R F Automatically created MSOL(ASL-GI)* 32706 .56 .37 .44 .76 .87 .81 76400 .67 .5 .57 .80 .89 .85 QWN 15508 .63 .22 .33 .73 .94 .83 11693 .58 .22 .31 .73 .93 .82 SWN 27854 .57 .33 .42 .75 .89 .81 </context>
<context position="24308" citStr="Baccianella et al., 2010" startWordPosition="4103" endWordPosition="4106">assigned to that lemma. With respect to lexicons at word level, we take the most frequent sense according to WordNet 3.0 for each of their positive and negative words. Note that the latter conversion, for synset based evaluation, is mostly done to show that the evaluation at synset level is harder independently of the quality of the lexicon evaluated. 4.2 Results Although tables 1, 2 and 4 also present results at synset level, it should be noted that the only polarity lexicons available to us for comparison at synset level were Q-WordNet (Agerri and Garcia-Serrano, 2010) and SentiWordNet 3.0 (Baccianella et al., 2010). QWN-PPV-AG refers to the lexicon generated starting from AG’s seeds, and QWN-PPV-TL using TL’s seeds as described in section 3.1. Henceforth, we will use qwn-ppv to refer to the overall method presented in this paper, regardless of the seeds used. For every qwn-ppv result reported in this section, we have used every graph described in section 3.2. The configuration of each qwn-ppv in the results specifies which seed iteration is used as the initialization of the Personalized PageRank algorithm, and on which graph. Thus, QWN-PPV-TL (s05 G4) in table 2 means that the 5th iteration of synset se</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>S. Baccianella, A. Esuli, and F. Sebastiani. 2010. SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In Seventh conference on International Language Resources and Evaluation (LREC-2010), Malta., volume 25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitriy Bespalov</author>
<author>Bing Bai</author>
<author>Yanjun Qi</author>
<author>Ali Shokoufandeh</author>
</authors>
<title>Sentiment classification based on supervised latent n-gram analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM international conference on Information and knowledge management,</booktitle>
<pages>375--382</pages>
<marker>Bespalov, Bai, Qi, Shokoufandeh, 2011</marker>
<rawString>Dmitriy Bespalov, Bing Bai, Yanjun Qi, and Ali Shokoufandeh. 2011. Sentiment classification based on supervised latent n-gram analysis. In Proceedings of the 20th ACM international conference on Information and knowledge management, pages 375–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francis Bond</author>
<author>Ryan Foster</author>
</authors>
<title>Linking and extending an open multilingual wordnet.</title>
<date>2013</date>
<booktitle>In 51st Annual Meeting of the Association for Computational Linguistics: ACL-2013.</booktitle>
<contexts>
<context position="5682" citStr="Bond and Foster, 2013" startWordPosition="881" endWordPosition="884"> create qwn-ppv(s) for other languages, and we demonstrate it here by creating many polarity lexicons not only for English but also for Spanish; (vi) the method works at both word and sense levels and it only requires the availability of a LKB or dictionary; finally, (vii) a dictionarybased method like qwn-ppv allows to easily create quality polarity lexicons whenever no domainbased annotated reviews are available for a given language. After all, there usually is available a dictionary for a given language; for example, the Open Multilingual WordNet site lists WordNets for up to 57 languages (Bond and Foster, 2013). Although there has been previous work using graph methods for obtaining lexicons via propagation, the qwn-ppv method to combine the seed generation and the Personalized PageRank propagation is novel. Furthermore, it is considerable simpler and obtains better and easier to reproduce results than previous automatic approaches (Esuli and Sebastiani, 2007; Mohammad et al., 2009; Rao and Ravichandran, 2009). Next section reviews previous related work, taking special interest on those that are currently available for evaluation purposes. Section 3 describes the qwn-ppv method to automatically gene</context>
</contexts>
<marker>Bond, Foster, 2013</marker>
<rawString>Francis Bond and Ryan Foster. 2013. Linking and extending an open multilingual wordnet. In 51st Annual Meeting of the Association for Computational Linguistics: ACL-2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The anatomy of a large-scale hypertextual web search engine.</title>
<date>1998</date>
<booktitle>Computer networks and ISDN systems,</booktitle>
<pages>30--1</pages>
<contexts>
<context position="15392" citStr="Brin and Page, 1998" startWordPosition="2515" endWordPosition="2518">sibilities will produce at least 6 different lexicons for each iteration, depending on which decisions are taken about which graph, seeds and word/synset to create the qwn-ppv(s). In fact, the experiments produced hundreds of lexicons, according to the different iterations for seed generation1, but we will only refer to those that obtain the best results in the extrinsic evaluations. With respect to the algorithm to propagate over the WordNet graph from the automatically created seeds, we use a Personalized PageRank algorithm (Agirre et al., 2014; Agirre and Soroa, 2009). The famous PageRank (Brin and Page, 1998) algorithm is a method to produce a rank from the vertices in a graph according to their relative structural importance. PageRank has also been viewed as the result of a Random Walk process, where the final rank of a given node represents the probability of a random walk over the graph which ends on that same node. Thus, if we take the created Word1The total time to generate the final 352 QWN-PPV propagations amounted to around two hours of processing time in a standard PC. Net graph G with N vertices vi, ... , vn and di as being the outdegree of node i, plus a N × N transition probability mat</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Lawrence Page. 1998. The anatomy of a large-scale hypertextual web search engine. Computer networks and ISDN systems, 30(1):107117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choi</author>
<author>C Cardie</author>
</authors>
<title>Adapting a polarity lexicon using integer linear programming for domainspecific sentiment classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>2</volume>
<pages>590--598</pages>
<contexts>
<context position="3158" citStr="Choi and Cardie, 2009" startWordPosition="479" endWordPosition="482"> (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been applied to obtain domain-specific polarity lexicons: they have been created by either starting from a seed list of known words and trying to find other related words in a corpus or by attempting to directly adapt a given lexicon to a new one using a domain-specific corpus (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Ding et al., 2008; Choi and Cardie, 2009; Mihalcea et al., 2007). One particular issue arising from corpus methods is that for a given domain the same word can be positive in one context but negative in another. This is also a problem shared by manual and dictionary-based methods, and that is why qwn-ppv also produces synset-based lexicons for approaches on Sentiment Analysis at sense level. This paper presents a simple, robust and (almost) unsupervised dictionary-based method, QWordNet-PPV (QWordNet by Personalized PageRank Vector) to automatically generate polarity lexicons based on propagating some automatically created seeds usi</context>
</contexts>
<marker>Choi, Cardie, 2009</marker>
<rawString>Y. Choi and C. Cardie. 2009. Adapting a polarity lexicon using integer linear programming for domainspecific sentiment classification. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2-Volume 2, pages 590–598.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Ding</author>
<author>B Liu</author>
<author>P S Yu</author>
</authors>
<title>A holistic lexiconbased approach to opinion mining.</title>
<date>2008</date>
<booktitle>In Proceedings of the international conference on Web</booktitle>
<pages>231--240</pages>
<contexts>
<context position="3135" citStr="Ding et al., 2008" startWordPosition="475" endWordPosition="478">pagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been applied to obtain domain-specific polarity lexicons: they have been created by either starting from a seed list of known words and trying to find other related words in a corpus or by attempting to directly adapt a given lexicon to a new one using a domain-specific corpus (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Ding et al., 2008; Choi and Cardie, 2009; Mihalcea et al., 2007). One particular issue arising from corpus methods is that for a given domain the same word can be positive in one context but negative in another. This is also a problem shared by manual and dictionary-based methods, and that is why qwn-ppv also produces synset-based lexicons for approaches on Sentiment Analysis at sense level. This paper presents a simple, robust and (almost) unsupervised dictionary-based method, QWordNet-PPV (QWordNet by Personalized PageRank Vector) to automatically generate polarity lexicons based on propagating some automati</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>X. Ding, B. Liu, and P. S. Yu. 2008. A holistic lexiconbased approach to opinion mining. In Proceedings of the international conference on Web search and web data mining, pages 231–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Pageranking wordnet synsets: An application to opinion mining.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>424--431</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="6037" citStr="Esuli and Sebastiani, 2007" startWordPosition="933" endWordPosition="936">y lexicons whenever no domainbased annotated reviews are available for a given language. After all, there usually is available a dictionary for a given language; for example, the Open Multilingual WordNet site lists WordNets for up to 57 languages (Bond and Foster, 2013). Although there has been previous work using graph methods for obtaining lexicons via propagation, the qwn-ppv method to combine the seed generation and the Personalized PageRank propagation is novel. Furthermore, it is considerable simpler and obtains better and easier to reproduce results than previous automatic approaches (Esuli and Sebastiani, 2007; Mohammad et al., 2009; Rao and Ravichandran, 2009). Next section reviews previous related work, taking special interest on those that are currently available for evaluation purposes. Section 3 describes the qwn-ppv method to automatically generate lexicons. The resulting lexical resources are evaluated in section 4. We finish with some concluding remarks and future work in section 5. 2 Related Work There is a large amount of work on Sentiment Analysis and Opinion Mining, and good comprehensive overviews are already available (Pang and Lee, 2008; Liu, 2012), so we will review the most represe</context>
<context position="9159" citStr="Esuli and Sebastiani, 2007" startWordPosition="1447" endWordPosition="1450">nally, there are two approaches that are somewhat closer to us, because they are based on WordNet and graph-based methods. SentiWordNet 3.0 (Baccianella et al., 2010) is built in 4 steps: (i) they select the synsets of 14 paradigmatic positive and negative words used as seeds (Turney 89 and Littman, 2003). These seeds are then iteratively extended following the construction of WordNet-Affect (Strapparava and Valitutti, 2004). (ii) They train 7 supervised classifiers with the synsets’ glosses which are used to assign polarity and objectivity scores to WordNet senses. (iii) In SentiWordNet 3.0 (Esuli and Sebastiani, 2007) they take the output of the supervised classifiers as input to applying PageRank to WordNet 3.0’s graph. (iv) They intrinsically evaluate it with respect to MicroWnOp-3.0 using the p-normalized Kendall τ distance (Baccianella et al., 2010). Rao and Ravichandran (2009) apply different semisupervised graph algorithms (Mincuts, Randomized Mincuts and Label Propagation) to a set of seeds constructed from the General Inquirer. They evaluate the generated lexicons intrinsically taking the General Inquirer as the gold standard for those words that had a match in the generated lexicons. In this paper</context>
</contexts>
<marker>Esuli, Sebastiani, 2007</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2007. Pageranking wordnet synsets: An application to opinion mining. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 424–431, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
<author>G Miller</author>
<author>editors</author>
</authors>
<title>Wordnet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge (MA).</location>
<marker>Fellbaum, Miller, editors, 1998</marker>
<rawString>C. Fellbaum and G. Miller, editors. 1998. Wordnet: An Electronic Lexical Database. MIT Press, Cambridge (MA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>K R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics,</booktitle>
<pages>174--181</pages>
<contexts>
<context position="3090" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="467" endWordPosition="470">rds as seeds which are then used to perform some iterative propagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been applied to obtain domain-specific polarity lexicons: they have been created by either starting from a seed list of known words and trying to find other related words in a corpus or by attempting to directly adapt a given lexicon to a new one using a domain-specific corpus (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Ding et al., 2008; Choi and Cardie, 2009; Mihalcea et al., 2007). One particular issue arising from corpus methods is that for a given domain the same word can be positive in one context but negative in another. This is also a problem shared by manual and dictionary-based methods, and that is why qwn-ppv also produces synset-based lexicons for approaches on Sentiment Analysis at sense level. This paper presents a simple, robust and (almost) unsupervised dictionary-based method, QWordNet-PPV (QWordNet by Personalized PageRank Vector) to automatically generate polarit</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>V. Hatzivassiloglou and K. R McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics, pages 174–181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="2184" citStr="Hu and Liu, 2004" startWordPosition="316" endWordPosition="319"> ‘Beautiful’, ‘wonderful’, and ‘amazing’ are examples of positive words whereas ‘bad’, ‘awful’, and ‘poor’ are examples of negatives. The creation of lists of sentiment words has generally been performed by means of manual-, dictionary- and corpus-based methods. Manually collecting such lists of polarity annotated words is labor intensive and time consuming, and is thus usually combined with automated approaches as the final check to correct mistakes. However, there are well known lexicons which have been fully (Stone et al., 1966; Taboada et al., 2010) or at least partially manually created (Hu and Liu, 2004; Riloff and Wiebe, 2003). Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet (Fellbaum and Miller, 1998) that contain synonyms and antonyms for each word. A simple technique in this approach is to start with some sentiment words as seeds which are then used to perform some iterative propagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been ap</context>
<context position="7236" citStr="Hu and Liu (2004)" startWordPosition="1135" endWordPosition="1138">w the most representative and closest to the present work. This means that we will not be reviewing corpus-based approaches but rather those constructed manually or upon a dictionary or LKB. We will in turn use the approaches here reviewed for comparison with qwn-ppv in section 4. The most popular manually-built polarity lexicon is part of the General Inquirer (Stone et al., 1966), and consists of 1915 words labelled as “positive” and 2291 as “negative”. Taboada et al. (2010) manually created their lexicons annotating the polarity of 6232 words on a scale of 5 to -5. Liu et al., starting with Hu and Liu (2004), have along the years collected a manually corrected polarity lexicon which is formed by 4818 negative and 2041 positive words. Another manually corrected lexicon (Riloff and Wiebe, 2003) is the one used by the Opinion Finder system (Wilson et al., 2005) and contains 4903 negatively and 2718 positively annotated words respectively. Among the automatically built lexicons, Turney and Littman (2003) proposed a minimally supervised algorithm to calculate the polarity of a word depending on whether it co-ocurred more with a previously collected small set of positive words rather than with a set of</context>
<context position="26024" citStr="Hu and Liu, 2004" startWordPosition="4399" endWordPosition="4402">version is to show that SA tasks at synset level are harder than at word level. In addition, it should also be noted that in the case of SO-CAL (Taboada et al., 2010), we have reduced what is a graded lexicon with scores ranging from 5 to -5 into a binary one. Table 1 shows that (at least partially) manually built lexicons obtain the best results on this evaluation. It also shows that qwn-ppv clearly outperforms any other automatically built lexicons. Moreover, manually built lexicons suffer from the evaluation at synset level, obtaining most of them lower scores than qwn-ppv, although Liu’s (Hu and Liu, 2004) still obtains the best results. In any case, for an unsupervised procedure, qwn-ppv lexicons obtain very competitive results with respect to manually created lexicons and is the best among the automatic methods. It should also be noted that the best results of qwn-ppv are obtained with graph 93 G1 and with very few seed iterations. Table 2 again sees the manually built lexicons performing better although overall the differences are lower with respect to automatically built lexicons. Among these, qwn-ppv again obtains the best results, both at synset and word level, although in the latter the </context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>M. Hu and B. Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>1367--1373</pages>
<publisher>COLING.</publisher>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="2608" citStr="Kim and Hovy, 2004" startWordPosition="388" endWordPosition="391"> final check to correct mistakes. However, there are well known lexicons which have been fully (Stone et al., 1966; Taboada et al., 2010) or at least partially manually created (Hu and Liu, 2004; Riloff and Wiebe, 2003). Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet (Fellbaum and Miller, 1998) that contain synonyms and antonyms for each word. A simple technique in this approach is to start with some sentiment words as seeds which are then used to perform some iterative propagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been applied to obtain domain-specific polarity lexicons: they have been created by either starting from a seed list of known words and trying to find other related words in a corpus or by attempting to directly adapt a given lexicon to a new one using a domain-specific corpus (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Ding et al., 2008; Choi and Cardie, 2009; Mihalcea et al., 2007). One particular issue ari</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2004. Determining the sentiment of opinions. In Proceedings of Coling 2004, pages 1367–1373, Geneva, Switzerland, Aug 23–Aug 27. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="6601" citStr="Liu, 2012" startWordPosition="1026" endWordPosition="1027">tomatic approaches (Esuli and Sebastiani, 2007; Mohammad et al., 2009; Rao and Ravichandran, 2009). Next section reviews previous related work, taking special interest on those that are currently available for evaluation purposes. Section 3 describes the qwn-ppv method to automatically generate lexicons. The resulting lexical resources are evaluated in section 4. We finish with some concluding remarks and future work in section 5. 2 Related Work There is a large amount of work on Sentiment Analysis and Opinion Mining, and good comprehensive overviews are already available (Pang and Lee, 2008; Liu, 2012), so we will review the most representative and closest to the present work. This means that we will not be reviewing corpus-based approaches but rather those constructed manually or upon a dictionary or LKB. We will in turn use the approaches here reviewed for comparison with qwn-ppv in section 4. The most popular manually-built polarity lexicon is part of the General Inquirer (Stone et al., 1966), and consists of 1915 words labelled as “positive” and 2291 as “negative”. Taboada et al. (2010) manually created their lexicons annotating the polarity of 6232 words on a scale of 5 to -5. Liu et a</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>C Banea</author>
<author>J Wiebe</author>
</authors>
<title>Learning multilingual subjective language via cross-lingual projections.</title>
<date>2007</date>
<booktitle>In Annual Meeting of the Association for Computational Linguistics,</booktitle>
<volume>45</volume>
<pages>976</pages>
<contexts>
<context position="3182" citStr="Mihalcea et al., 2007" startWordPosition="483" endWordPosition="486">apparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been applied to obtain domain-specific polarity lexicons: they have been created by either starting from a seed list of known words and trying to find other related words in a corpus or by attempting to directly adapt a given lexicon to a new one using a domain-specific corpus (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Ding et al., 2008; Choi and Cardie, 2009; Mihalcea et al., 2007). One particular issue arising from corpus methods is that for a given domain the same word can be positive in one context but negative in another. This is also a problem shared by manual and dictionary-based methods, and that is why qwn-ppv also produces synset-based lexicons for approaches on Sentiment Analysis at sense level. This paper presents a simple, robust and (almost) unsupervised dictionary-based method, QWordNet-PPV (QWordNet by Personalized PageRank Vector) to automatically generate polarity lexicons based on propagating some automatically created seeds using a Personalized 88 Pro</context>
</contexts>
<marker>Mihalcea, Banea, Wiebe, 2007</marker>
<rawString>R. Mihalcea, C. Banea, and J. Wiebe. 2007. Learning multilingual subjective language via cross-lingual projections. In Annual Meeting of the Association for Computational Linguistics, volume 45, page 976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Mohammad</author>
<author>C Dunne</author>
<author>B Dorr</author>
</authors>
<title>Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>2</volume>
<pages>599--608</pages>
<contexts>
<context position="2680" citStr="Mohammad et al., 2009" startWordPosition="400" endWordPosition="403">ons which have been fully (Stone et al., 1966; Taboada et al., 2010) or at least partially manually created (Hu and Liu, 2004; Riloff and Wiebe, 2003). Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet (Fellbaum and Miller, 1998) that contain synonyms and antonyms for each word. A simple technique in this approach is to start with some sentiment words as seeds which are then used to perform some iterative propagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been applied to obtain domain-specific polarity lexicons: they have been created by either starting from a seed list of known words and trying to find other related words in a corpus or by attempting to directly adapt a given lexicon to a new one using a domain-specific corpus (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Ding et al., 2008; Choi and Cardie, 2009; Mihalcea et al., 2007). One particular issue arising from corpus methods is that for a given domain the same word can be</context>
<context position="6060" citStr="Mohammad et al., 2009" startWordPosition="937" endWordPosition="940">nbased annotated reviews are available for a given language. After all, there usually is available a dictionary for a given language; for example, the Open Multilingual WordNet site lists WordNets for up to 57 languages (Bond and Foster, 2013). Although there has been previous work using graph methods for obtaining lexicons via propagation, the qwn-ppv method to combine the seed generation and the Personalized PageRank propagation is novel. Furthermore, it is considerable simpler and obtains better and easier to reproduce results than previous automatic approaches (Esuli and Sebastiani, 2007; Mohammad et al., 2009; Rao and Ravichandran, 2009). Next section reviews previous related work, taking special interest on those that are currently available for evaluation purposes. Section 3 describes the qwn-ppv method to automatically generate lexicons. The resulting lexical resources are evaluated in section 4. We finish with some concluding remarks and future work in section 5. 2 Related Work There is a large amount of work on Sentiment Analysis and Opinion Mining, and good comprehensive overviews are already available (Pang and Lee, 2008; Liu, 2012), so we will review the most representative and closest to </context>
<context position="8045" citStr="Mohammad et al. (2009)" startWordPosition="1264" endWordPosition="1267">) is the one used by the Opinion Finder system (Wilson et al., 2005) and contains 4903 negatively and 2718 positively annotated words respectively. Among the automatically built lexicons, Turney and Littman (2003) proposed a minimally supervised algorithm to calculate the polarity of a word depending on whether it co-ocurred more with a previously collected small set of positive words rather than with a set of negative ones. Agerri and Garcia Serrano presented a very simple method to extract the polarity information starting from the quality synset in WordNet (Agerri and GarciaSerrano, 2010). Mohammad et al. (2009) developed a method in which they first identify (by means of affixes rules) a set of positive/negative words which act as seeds, then used a Roget-like thesaurus to mark the synonymous words for each polarity type and to generalize from the seeds. They produce several lexicons the best of which, MSOL(ASL and GI) contains 51K and 76K entries respectively and uses the full General Inquirer as seeds. They performed both intrinsic and extrinsic evaluations using the MPQA 1.1 corpus. Finally, there are two approaches that are somewhat closer to us, because they are based on WordNet and graph-based</context>
<context position="17226" citStr="Mohammad et al., 2009" startWordPosition="2845" endWordPosition="2848">ortance of those nodes to their vicinity. Following Agirre et al. (2014), in our approach this translates into initializing vector v with those senses obtained by the seed generation methods described above in section 3.1. Thus, the initialization of vector v using the seeds allows the Personalized propagation to assign greater importance to those synsets in the graph identified as being positive and negative, which resuls in a PPV with the weigths skewed towards those nodes initialized/personalized as positive and negative. 4 Evaluation Previous approaches have provided intrinsic evaluation (Mohammad et al., 2009; Rao and Ravichandran, 2009; Baccianella et al., 2010) using manually annotated resources such as the General Inquirer (Stone et al., 1966) as gold standard. To facilitate comparison, we also provide such evaluation in section 4.3. Nevertheless, and as demonstrated by the results of the extrinsic evaluations, we believe that polarity lexicons should 91 Synset Level Word level Lexicon size P Positives F Negatives size P Positives F Negatives R P R F R P R F Automatically created MSOL(ASL-GI)* 32706 .56 .37 .44 .76 .87 .81 76400 .67 .5 .57 .80 .89 .85 QWN 15508 .63 .22 .33 .73 .94 .83 11693 .58</context>
<context position="20784" citStr="Mohammad et al. (2009)" startWordPosition="3462" endWordPosition="3465">corpus/hopinion MPQA 1.2 and HOpinion. Corpus POS docs NEG docs Total Bespalovdev 23,112 23,112 46,227 Bespalovtest 10,557 10,557 21,115 MPQA 1.2dev 2,315 5,260 7,575 MPQA 1.2test 771 1,753 2,524 MPQA 1.2total 3,086 7,013 10,099 HOpinion Balanceddev 1,582 1,582 3,164 HOpinion Balancedtest 528 528 1,056 HOpiniondev 9,236 1,582 10,818 HOpiniontest 3,120 528 3,648 Table 3: Number of positive and negative documents in train and test sets. We report results of 4 extrinsic evaluations or tasks, three of them based on a simple ratio average system, inspired by Turney (2002), and another one based on Mohammad et al. (2009). We first implemented a simple average ratio classi�er which computes the average ratio of the polarity words found in document d: polarity(d) = Ew∈ d p l(w) (2) Idl where, for each polarity, pol(w) is 1 if w is included in the polarity lexicon and 0 otherwise. Documents that reach a certain threshold are classified as positive, and otherwise as negative. To setup an evaluation enviroment as fair as possible for every lexicon, the threshold is optimised by maximising accuracy over the development data. Second, we implemented a phrase polarity task identification as described by Mohammad et al</context>
</contexts>
<marker>Mohammad, Dunne, Dorr, 2009</marker>
<rawString>S. Mohammad, C. Dunne, and B. Dorr. 2009. Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2-Volume 2, pages 599–608.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Llu´ıs Padr´o</author>
<author>Evgeny Stanilovsky</author>
</authors>
<title>Freeling 3.0: Towards wider multilinguality.</title>
<date>2012</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC 2012),</booktitle>
<publisher>ELRA.</publisher>
<location>Istanbul, Turkey,</location>
<marker>Padr´o, Stanilovsky, 2012</marker>
<rawString>Llu´ıs Padr´o and Evgeny Stanilovsky. 2012. Freeling 3.0: Towards wider multilinguality. In Proceedings of the Language Resources and Evaluation Conference (LREC 2012), Istanbul, Turkey, May. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="6589" citStr="Pang and Lee, 2008" startWordPosition="1022" endWordPosition="1025">lts than previous automatic approaches (Esuli and Sebastiani, 2007; Mohammad et al., 2009; Rao and Ravichandran, 2009). Next section reviews previous related work, taking special interest on those that are currently available for evaluation purposes. Section 3 describes the qwn-ppv method to automatically generate lexicons. The resulting lexical resources are evaluated in section 4. We finish with some concluding remarks and future work in section 5. 2 Related Work There is a large amount of work on Sentiment Analysis and Opinion Mining, and good comprehensive overviews are already available (Pang and Lee, 2008; Liu, 2012), so we will review the most representative and closest to the present work. This means that we will not be reviewing corpus-based approaches but rather those constructed manually or upon a dictionary or LKB. We will in turn use the approaches here reviewed for comparison with qwn-ppv in section 4. The most popular manually-built polarity lexicon is part of the General Inquirer (Stone et al., 1966), and consists of 1915 words labelled as “positive” and 2291 as “negative”. Taboada et al. (2010) manually created their lexicons annotating the polarity of 6232 words on a scale of 5 to </context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>B. Pang and L. Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ver´onica P´erez-Rosas</author>
<author>Carmen Banea</author>
<author>Rada Mihalcea</author>
</authors>
<title>Learning sentiment lexicons in spanish.</title>
<date>2012</date>
<booktitle>In LREC,</booktitle>
<pages>3077--3081</pages>
<marker>P´erez-Rosas, Banea, Mihalcea, 2012</marker>
<rawString>Ver´onica P´erez-Rosas, Carmen Banea, and Rada Mihalcea. 2012. Learning sentiment lexicons in spanish. In LREC, pages 3077–3081.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Rao</author>
<author>D Ravichandran</author>
</authors>
<title>Semi-supervised polarity lexicon induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>675--682</pages>
<contexts>
<context position="6089" citStr="Rao and Ravichandran, 2009" startWordPosition="941" endWordPosition="944">s are available for a given language. After all, there usually is available a dictionary for a given language; for example, the Open Multilingual WordNet site lists WordNets for up to 57 languages (Bond and Foster, 2013). Although there has been previous work using graph methods for obtaining lexicons via propagation, the qwn-ppv method to combine the seed generation and the Personalized PageRank propagation is novel. Furthermore, it is considerable simpler and obtains better and easier to reproduce results than previous automatic approaches (Esuli and Sebastiani, 2007; Mohammad et al., 2009; Rao and Ravichandran, 2009). Next section reviews previous related work, taking special interest on those that are currently available for evaluation purposes. Section 3 describes the qwn-ppv method to automatically generate lexicons. The resulting lexical resources are evaluated in section 4. We finish with some concluding remarks and future work in section 5. 2 Related Work There is a large amount of work on Sentiment Analysis and Opinion Mining, and good comprehensive overviews are already available (Pang and Lee, 2008; Liu, 2012), so we will review the most representative and closest to the present work. This means </context>
<context position="9428" citStr="Rao and Ravichandran (2009)" startWordPosition="1488" endWordPosition="1491">s seeds (Turney 89 and Littman, 2003). These seeds are then iteratively extended following the construction of WordNet-Affect (Strapparava and Valitutti, 2004). (ii) They train 7 supervised classifiers with the synsets’ glosses which are used to assign polarity and objectivity scores to WordNet senses. (iii) In SentiWordNet 3.0 (Esuli and Sebastiani, 2007) they take the output of the supervised classifiers as input to applying PageRank to WordNet 3.0’s graph. (iv) They intrinsically evaluate it with respect to MicroWnOp-3.0 using the p-normalized Kendall τ distance (Baccianella et al., 2010). Rao and Ravichandran (2009) apply different semisupervised graph algorithms (Mincuts, Randomized Mincuts and Label Propagation) to a set of seeds constructed from the General Inquirer. They evaluate the generated lexicons intrinsically taking the General Inquirer as the gold standard for those words that had a match in the generated lexicons. In this paper, we describe two methods to automatically generate seeds either by following Agerri and Garcia-Serrano (2010) or using Turney and Littman’s (2003) seeds. The automatically obtained seeds are then fed into a Personalized PageRank algorithm which is applied over a WordN</context>
<context position="17254" citStr="Rao and Ravichandran, 2009" startWordPosition="2849" endWordPosition="2852">to their vicinity. Following Agirre et al. (2014), in our approach this translates into initializing vector v with those senses obtained by the seed generation methods described above in section 3.1. Thus, the initialization of vector v using the seeds allows the Personalized propagation to assign greater importance to those synsets in the graph identified as being positive and negative, which resuls in a PPV with the weigths skewed towards those nodes initialized/personalized as positive and negative. 4 Evaluation Previous approaches have provided intrinsic evaluation (Mohammad et al., 2009; Rao and Ravichandran, 2009; Baccianella et al., 2010) using manually annotated resources such as the General Inquirer (Stone et al., 1966) as gold standard. To facilitate comparison, we also provide such evaluation in section 4.3. Nevertheless, and as demonstrated by the results of the extrinsic evaluations, we believe that polarity lexicons should 91 Synset Level Word level Lexicon size P Positives F Negatives size P Positives F Negatives R P R F R P R F Automatically created MSOL(ASL-GI)* 32706 .56 .37 .44 .76 .87 .81 76400 .67 .5 .57 .80 .89 .85 QWN 15508 .63 .22 .33 .73 .94 .83 11693 .58 .22 .31 .73 .93 .82 SWN 278</context>
</contexts>
<marker>Rao, Ravichandran, 2009</marker>
<rawString>D. Rao and D. Ravichandran. 2009. Semi-supervised polarity lexicon induction. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 675– 682.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>J Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Conference on Empirical Methods in Natural Language Processing (EMNLP’03).</booktitle>
<contexts>
<context position="2209" citStr="Riloff and Wiebe, 2003" startWordPosition="320" endWordPosition="323">derful’, and ‘amazing’ are examples of positive words whereas ‘bad’, ‘awful’, and ‘poor’ are examples of negatives. The creation of lists of sentiment words has generally been performed by means of manual-, dictionary- and corpus-based methods. Manually collecting such lists of polarity annotated words is labor intensive and time consuming, and is thus usually combined with automated approaches as the final check to correct mistakes. However, there are well known lexicons which have been fully (Stone et al., 1966; Taboada et al., 2010) or at least partially manually created (Hu and Liu, 2004; Riloff and Wiebe, 2003). Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet (Fellbaum and Miller, 1998) that contain synonyms and antonyms for each word. A simple technique in this approach is to start with some sentiment words as seeds which are then used to perform some iterative propagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been applied to obtain domain-sp</context>
<context position="7424" citStr="Riloff and Wiebe, 2003" startWordPosition="1165" endWordPosition="1168"> or LKB. We will in turn use the approaches here reviewed for comparison with qwn-ppv in section 4. The most popular manually-built polarity lexicon is part of the General Inquirer (Stone et al., 1966), and consists of 1915 words labelled as “positive” and 2291 as “negative”. Taboada et al. (2010) manually created their lexicons annotating the polarity of 6232 words on a scale of 5 to -5. Liu et al., starting with Hu and Liu (2004), have along the years collected a manually corrected polarity lexicon which is formed by 4818 negative and 2041 positive words. Another manually corrected lexicon (Riloff and Wiebe, 2003) is the one used by the Opinion Finder system (Wilson et al., 2005) and contains 4903 negatively and 2718 positively annotated words respectively. Among the automatically built lexicons, Turney and Littman (2003) proposed a minimally supervised algorithm to calculate the polarity of a word depending on whether it co-ocurred more with a previously collected small set of positive words rather than with a set of negative ones. Agerri and Garcia Serrano presented a very simple method to extract the polarity information starting from the quality synset in WordNet (Agerri and GarciaSerrano, 2010). M</context>
<context position="19371" citStr="Riloff and Wiebe, 2003" startWordPosition="3231" endWordPosition="3234">We compare our work with most of the lexicons reviewed in section 2, both at synset and word level, both manually and automatically generated: General Inquirer (GI), Opinion Finder (OF), Liu, Taboada et al.’s (SO-CAL), Agerri and Garcia-Serrano (2010) (QWN), Mohammad et al’s, (MSOL(ASL-GI)) and SentiWordNet 3.0 (SWN). The results presented in section 4.2 show that extrinsic evaluation is more meaningful to determine the adequacy of a polarity lexicon for a specific Sentiment Analysis task. 4.1 Datasets and Evaluation System Three different corpora were used: Bespalov et al.’s (2011) and MPQA (Riloff and Wiebe, 2003) for English, and HOpinion2 in Spanish. In addition, we divided the corpus into two subsets (75% development and 25% test) for applying our ratio system for the phrase polarity task too. Note that the development set is only used to set up the polarity classification task, and that the generation of qwn-ppv lexicons is unsupervised. For Spanish we tried to reproduce the English settings with Bespalov’s corpus. Thus, both development and test sets were created from the HOpinion corpus. As it contains a much higher proportion of positive reviews, we created also subsets which contain a balanced </context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>E. Riloff and J. Wiebe. 2003. Learning extraction patterns for subjective expressions. In Proceedings of the International Conference on Empirical Methods in Natural Language Processing (EMNLP’03).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xabier Saralegi</author>
<author>I˜naki San Vicente</author>
</authors>
<title>Elhuyar at TASS2013.</title>
<date>2013</date>
<booktitle>In XXIX Congreso de la Sociedad Espaola de Procesamiento de lenguaje natural, Workshop on Sentiment Analysis at SEPLN (TASS2013),</booktitle>
<pages>143--150</pages>
<location>Madrid.</location>
<marker>Saralegi, Vicente, 2013</marker>
<rawString>Xabier Saralegi and I˜naki San Vicente. 2013. Elhuyar at TASS2013. In XXIX Congreso de la Sociedad Espaola de Procesamiento de lenguaje natural, Workshop on Sentiment Analysis at SEPLN (TASS2013), pages 143–150, Madrid.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Stone</author>
<author>D Dunphy</author>
<author>M Smith</author>
<author>D Ogilvie</author>
</authors>
<title>The General Inquirer: A Computer Approach to Content Analysis.</title>
<date>1966</date>
<publisher>MIT Press.</publisher>
<location>Cambridge (MA):</location>
<contexts>
<context position="2104" citStr="Stone et al., 1966" startWordPosition="302" endWordPosition="305"> phrases annotated according to the positive or negative connotations they convey. ‘Beautiful’, ‘wonderful’, and ‘amazing’ are examples of positive words whereas ‘bad’, ‘awful’, and ‘poor’ are examples of negatives. The creation of lists of sentiment words has generally been performed by means of manual-, dictionary- and corpus-based methods. Manually collecting such lists of polarity annotated words is labor intensive and time consuming, and is thus usually combined with automated approaches as the final check to correct mistakes. However, there are well known lexicons which have been fully (Stone et al., 1966; Taboada et al., 2010) or at least partially manually created (Hu and Liu, 2004; Riloff and Wiebe, 2003). Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet (Fellbaum and Miller, 1998) that contain synonyms and antonyms for each word. A simple technique in this approach is to start with some sentiment words as seeds which are then used to perform some iterative propagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Ser</context>
<context position="7002" citStr="Stone et al., 1966" startWordPosition="1093" endWordPosition="1096">ding remarks and future work in section 5. 2 Related Work There is a large amount of work on Sentiment Analysis and Opinion Mining, and good comprehensive overviews are already available (Pang and Lee, 2008; Liu, 2012), so we will review the most representative and closest to the present work. This means that we will not be reviewing corpus-based approaches but rather those constructed manually or upon a dictionary or LKB. We will in turn use the approaches here reviewed for comparison with qwn-ppv in section 4. The most popular manually-built polarity lexicon is part of the General Inquirer (Stone et al., 1966), and consists of 1915 words labelled as “positive” and 2291 as “negative”. Taboada et al. (2010) manually created their lexicons annotating the polarity of 6232 words on a scale of 5 to -5. Liu et al., starting with Hu and Liu (2004), have along the years collected a manually corrected polarity lexicon which is formed by 4818 negative and 2041 positive words. Another manually corrected lexicon (Riloff and Wiebe, 2003) is the one used by the Opinion Finder system (Wilson et al., 2005) and contains 4903 negatively and 2718 positively annotated words respectively. Among the automatically built l</context>
<context position="17366" citStr="Stone et al., 1966" startWordPosition="2868" endWordPosition="2871">e senses obtained by the seed generation methods described above in section 3.1. Thus, the initialization of vector v using the seeds allows the Personalized propagation to assign greater importance to those synsets in the graph identified as being positive and negative, which resuls in a PPV with the weigths skewed towards those nodes initialized/personalized as positive and negative. 4 Evaluation Previous approaches have provided intrinsic evaluation (Mohammad et al., 2009; Rao and Ravichandran, 2009; Baccianella et al., 2010) using manually annotated resources such as the General Inquirer (Stone et al., 1966) as gold standard. To facilitate comparison, we also provide such evaluation in section 4.3. Nevertheless, and as demonstrated by the results of the extrinsic evaluations, we believe that polarity lexicons should 91 Synset Level Word level Lexicon size P Positives F Negatives size P Positives F Negatives R P R F R P R F Automatically created MSOL(ASL-GI)* 32706 .56 .37 .44 .76 .87 .81 76400 .67 .5 .57 .80 .89 .85 QWN 15508 .63 .22 .33 .73 .94 .83 11693 .58 .22 .31 .73 .93 .82 SWN 27854 .57 .33 .42 .75 .89 .81 38346 .55 .55 .55 .80 .8 .80 QWN-PPV-AG (w10 G3/s09 G4) 117485 .60 .63 .62 .83 .82 .8</context>
</contexts>
<marker>Stone, Dunphy, Smith, Ogilvie, 1966</marker>
<rawString>P. Stone, D. Dunphy, M. Smith, and D. Ogilvie. 1966. The General Inquirer: A Computer Approach to Content Analysis. Cambridge (MA): MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Alessandro Valitutti</author>
</authors>
<title>Wordnet-affect: an affective extension of wordnet.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Languages Resources and Evaluation (LREC 2004),</booktitle>
<pages>1083--1086</pages>
<location>Lisbon,</location>
<contexts>
<context position="2588" citStr="Strapparava and Valitutti, 2004" startWordPosition="383" endWordPosition="387"> with automated approaches as the final check to correct mistakes. However, there are well known lexicons which have been fully (Stone et al., 1966; Taboada et al., 2010) or at least partially manually created (Hu and Liu, 2004; Riloff and Wiebe, 2003). Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet (Fellbaum and Miller, 1998) that contain synonyms and antonyms for each word. A simple technique in this approach is to start with some sentiment words as seeds which are then used to perform some iterative propagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been applied to obtain domain-specific polarity lexicons: they have been created by either starting from a seed list of known words and trying to find other related words in a corpus or by attempting to directly adapt a given lexicon to a new one using a domain-specific corpus (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Ding et al., 2008; Choi and Cardie, 2009; Mihalcea et al., 2007). One </context>
<context position="8960" citStr="Strapparava and Valitutti, 2004" startWordPosition="1416" endWordPosition="1419">best of which, MSOL(ASL and GI) contains 51K and 76K entries respectively and uses the full General Inquirer as seeds. They performed both intrinsic and extrinsic evaluations using the MPQA 1.1 corpus. Finally, there are two approaches that are somewhat closer to us, because they are based on WordNet and graph-based methods. SentiWordNet 3.0 (Baccianella et al., 2010) is built in 4 steps: (i) they select the synsets of 14 paradigmatic positive and negative words used as seeds (Turney 89 and Littman, 2003). These seeds are then iteratively extended following the construction of WordNet-Affect (Strapparava and Valitutti, 2004). (ii) They train 7 supervised classifiers with the synsets’ glosses which are used to assign polarity and objectivity scores to WordNet senses. (iii) In SentiWordNet 3.0 (Esuli and Sebastiani, 2007) they take the output of the supervised classifiers as input to applying PageRank to WordNet 3.0’s graph. (iv) They intrinsically evaluate it with respect to MicroWnOp-3.0 using the p-normalized Kendall τ distance (Baccianella et al., 2010). Rao and Ravichandran (2009) apply different semisupervised graph algorithms (Mincuts, Randomized Mincuts and Label Propagation) to a set of seeds constructed f</context>
</contexts>
<marker>Strapparava, Valitutti, 2004</marker>
<rawString>Carlo Strapparava and Alessandro Valitutti. 2004. Wordnet-affect: an affective extension of wordnet. In Proceedings of the 4th International Conference on Languages Resources and Evaluation (LREC 2004), pages 1083–1086, Lisbon, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Taboada</author>
<author>J Brooke</author>
<author>M Tofiloski</author>
<author>K Voll</author>
<author>M Stede</author>
</authors>
<title>Lexicon-based methods for sentiment analysis. Computational Linguistics,</title>
<date>2010</date>
<location>(Early Access):141.</location>
<contexts>
<context position="2127" citStr="Taboada et al., 2010" startWordPosition="306" endWordPosition="309">ccording to the positive or negative connotations they convey. ‘Beautiful’, ‘wonderful’, and ‘amazing’ are examples of positive words whereas ‘bad’, ‘awful’, and ‘poor’ are examples of negatives. The creation of lists of sentiment words has generally been performed by means of manual-, dictionary- and corpus-based methods. Manually collecting such lists of polarity annotated words is labor intensive and time consuming, and is thus usually combined with automated approaches as the final check to correct mistakes. However, there are well known lexicons which have been fully (Stone et al., 1966; Taboada et al., 2010) or at least partially manually created (Hu and Liu, 2004; Riloff and Wiebe, 2003). Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet (Fellbaum and Miller, 1998) that contain synonyms and antonyms for each word. A simple technique in this approach is to start with some sentiment words as seeds which are then used to perform some iterative propagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella</context>
<context position="7099" citStr="Taboada et al. (2010)" startWordPosition="1109" endWordPosition="1112">ntiment Analysis and Opinion Mining, and good comprehensive overviews are already available (Pang and Lee, 2008; Liu, 2012), so we will review the most representative and closest to the present work. This means that we will not be reviewing corpus-based approaches but rather those constructed manually or upon a dictionary or LKB. We will in turn use the approaches here reviewed for comparison with qwn-ppv in section 4. The most popular manually-built polarity lexicon is part of the General Inquirer (Stone et al., 1966), and consists of 1915 words labelled as “positive” and 2291 as “negative”. Taboada et al. (2010) manually created their lexicons annotating the polarity of 6232 words on a scale of 5 to -5. Liu et al., starting with Hu and Liu (2004), have along the years collected a manually corrected polarity lexicon which is formed by 4818 negative and 2041 positive words. Another manually corrected lexicon (Riloff and Wiebe, 2003) is the one used by the Opinion Finder system (Wilson et al., 2005) and contains 4903 negatively and 2718 positively annotated words respectively. Among the automatically built lexicons, Turney and Littman (2003) proposed a minimally supervised algorithm to calculate the pol</context>
<context position="25573" citStr="Taboada et al., 2010" startWordPosition="4324" endWordPosition="4327">the configuration were (w05 G4) it would have meant ‘the 5th iteration of word seeds were used to propagate over graph G4’. The simplicity of our approach allows us to generate many lexicons simply by projecting a LKB over different graphs. The lexicons marked with an asterisk denote those that have been converted from word to senses using the most frequent sense of WordNet 3.0. We would like to stress again that the purpose of such word to synset conversion is to show that SA tasks at synset level are harder than at word level. In addition, it should also be noted that in the case of SO-CAL (Taboada et al., 2010), we have reduced what is a graded lexicon with scores ranging from 5 to -5 into a binary one. Table 1 shows that (at least partially) manually built lexicons obtain the best results on this evaluation. It also shows that qwn-ppv clearly outperforms any other automatically built lexicons. Moreover, manually built lexicons suffer from the evaluation at synset level, obtaining most of them lower scores than qwn-ppv, although Liu’s (Hu and Liu, 2004) still obtains the best results. In any case, for an unsupervised procedure, qwn-ppv lexicons obtain very competitive results with respect to manuall</context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2010</marker>
<rawString>M. Taboada, J. Brooke, M. Tofiloski, K. Voll, and M. Stede. 2010. Lexicon-based methods for sentiment analysis. Computational Linguistics, (Early Access):141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting semantic orientations of words using spin model.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>133140</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="2631" citStr="Takamura et al., 2005" startWordPosition="392" endWordPosition="395">ect mistakes. However, there are well known lexicons which have been fully (Stone et al., 1966; Taboada et al., 2010) or at least partially manually created (Hu and Liu, 2004; Riloff and Wiebe, 2003). Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet (Fellbaum and Miller, 1998) that contain synonyms and antonyms for each word. A simple technique in this approach is to start with some sentiment words as seeds which are then used to perform some iterative propagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been applied to obtain domain-specific polarity lexicons: they have been created by either starting from a seed list of known words and trying to find other related words in a corpus or by attempting to directly adapt a given lexicon to a new one using a domain-specific corpus (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Ding et al., 2008; Choi and Cardie, 2009; Mihalcea et al., 2007). One particular issue arising from corpus method</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientations of words using spin model. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), page 133140, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
<author>M Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic oreintation from association.</title>
<date>2003</date>
<journal>ACM Transaction on Information Systems,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="2657" citStr="Turney and Littman, 2003" startWordPosition="396" endWordPosition="399">there are well known lexicons which have been fully (Stone et al., 1966; Taboada et al., 2010) or at least partially manually created (Hu and Liu, 2004; Riloff and Wiebe, 2003). Dictionary-based methods rely on some dictionary or lexical knowledge base (LKB) such as WordNet (Fellbaum and Miller, 1998) that contain synonyms and antonyms for each word. A simple technique in this approach is to start with some sentiment words as seeds which are then used to perform some iterative propagation on the LKB (Hu and Liu, 2004; Strapparava and Valitutti, 2004; Kim and Hovy, 2004; Takamura et al., 2005; Turney and Littman, 2003; Mohammad et al., 2009; Agerri and Garc´ıa-Serrano, 2010; Baccianella et al., 2010). Corpus-based methods have usually been applied to obtain domain-specific polarity lexicons: they have been created by either starting from a seed list of known words and trying to find other related words in a corpus or by attempting to directly adapt a given lexicon to a new one using a domain-specific corpus (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Ding et al., 2008; Choi and Cardie, 2009; Mihalcea et al., 2007). One particular issue arising from corpus methods is that for a given doma</context>
<context position="7636" citStr="Turney and Littman (2003)" startWordPosition="1198" endWordPosition="1201">sists of 1915 words labelled as “positive” and 2291 as “negative”. Taboada et al. (2010) manually created their lexicons annotating the polarity of 6232 words on a scale of 5 to -5. Liu et al., starting with Hu and Liu (2004), have along the years collected a manually corrected polarity lexicon which is formed by 4818 negative and 2041 positive words. Another manually corrected lexicon (Riloff and Wiebe, 2003) is the one used by the Opinion Finder system (Wilson et al., 2005) and contains 4903 negatively and 2718 positively annotated words respectively. Among the automatically built lexicons, Turney and Littman (2003) proposed a minimally supervised algorithm to calculate the polarity of a word depending on whether it co-ocurred more with a previously collected small set of positive words rather than with a set of negative ones. Agerri and Garcia Serrano presented a very simple method to extract the polarity information starting from the quality synset in WordNet (Agerri and GarciaSerrano, 2010). Mohammad et al. (2009) developed a method in which they first identify (by means of affixes rules) a set of positive/negative words which act as seeds, then used a Roget-like thesaurus to mark the synonymous words</context>
<context position="10887" citStr="Turney and Littman, 2003" startWordPosition="1725" endWordPosition="1728">es a set of seeds by iterating over a LKB (e.g. a WordNet) relations; and (2) uses the seeds to initialize contexts to propagate over the LKB graph using a Personalized Pagerank algorithm. The result is qwn-ppv(s): Q-WordNets as Personalized PageRanking Vectors. 3.1 Seed Generation We generate seeds by means of two different automatic procedures. 1. AG: We start at the quality synset of WordNet and iterate over WordNet relations following the original Q-WordNet method described in Agerri and Garcia Serrano (2010). 2. TL: We take a short manually created list of 14 positive and negative words (Turney and Littman, 2003) and iterate over WordNet using five relations: antonymy, similarity, derived-from, pertains-to and also-see. The AG method starts the propagation from the attributes of the quality synset in WordNet. There are five noun quality senses in WordNet, two of which contain attribute relations (to adjectives). From the qualityn synset the attribute relation takes us to positives, negatives, goods and bads; quality�n leads to the attributes superiors and inferiora. The following step is to iterate through every WordNet relation collecting (i.e., annotating) those synsets that are accessible from the </context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>P. Turney and M. Littman. 2003. Measuring praise and criticism: Inference of semantic oreintation from association. ACM Transaction on Information Systems, 21(4):315–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>417424</pages>
<contexts>
<context position="20735" citStr="Turney (2002)" startWordPosition="3454" endWordPosition="3455">ity for Bespalov’s, 2http://clic.ub.edu/corpus/hopinion MPQA 1.2 and HOpinion. Corpus POS docs NEG docs Total Bespalovdev 23,112 23,112 46,227 Bespalovtest 10,557 10,557 21,115 MPQA 1.2dev 2,315 5,260 7,575 MPQA 1.2test 771 1,753 2,524 MPQA 1.2total 3,086 7,013 10,099 HOpinion Balanceddev 1,582 1,582 3,164 HOpinion Balancedtest 528 528 1,056 HOpiniondev 9,236 1,582 10,818 HOpiniontest 3,120 528 3,648 Table 3: Number of positive and negative documents in train and test sets. We report results of 4 extrinsic evaluations or tasks, three of them based on a simple ratio average system, inspired by Turney (2002), and another one based on Mohammad et al. (2009). We first implemented a simple average ratio classi�er which computes the average ratio of the polarity words found in document d: polarity(d) = Ew∈ d p l(w) (2) Idl where, for each polarity, pol(w) is 1 if w is included in the polarity lexicon and 0 otherwise. Documents that reach a certain threshold are classified as positive, and otherwise as negative. To setup an evaluation enviroment as fair as possible for every lexicon, the threshold is optimised by maximising accuracy over the development data. Second, we implemented a phrase polarity t</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>P.D. Turney. 2002. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, page 417424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>347354</pages>
<contexts>
<context position="7491" citStr="Wilson et al., 2005" startWordPosition="1178" endWordPosition="1181">on with qwn-ppv in section 4. The most popular manually-built polarity lexicon is part of the General Inquirer (Stone et al., 1966), and consists of 1915 words labelled as “positive” and 2291 as “negative”. Taboada et al. (2010) manually created their lexicons annotating the polarity of 6232 words on a scale of 5 to -5. Liu et al., starting with Hu and Liu (2004), have along the years collected a manually corrected polarity lexicon which is formed by 4818 negative and 2041 positive words. Another manually corrected lexicon (Riloff and Wiebe, 2003) is the one used by the Opinion Finder system (Wilson et al., 2005) and contains 4903 negatively and 2718 positively annotated words respectively. Among the automatically built lexicons, Turney and Littman (2003) proposed a minimally supervised algorithm to calculate the polarity of a word depending on whether it co-ocurred more with a previously collected small set of positive words rather than with a set of negative ones. Agerri and Garcia Serrano presented a very simple method to extract the polarity information starting from the quality synset in WordNet (Agerri and GarciaSerrano, 2010). Mohammad et al. (2009) developed a method in which they first identi</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, page 347354.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>