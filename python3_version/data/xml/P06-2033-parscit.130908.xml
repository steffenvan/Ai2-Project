<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.998578">
Conceptual Coherence in the Generation of Referring Expressions
</title>
<author confidence="0.996619">
Albert Gatt
</author>
<affiliation confidence="0.998602">
Department of Computing Science
University of Aberdeen
</affiliation>
<email confidence="0.980954">
agatt@csd.abdn.ac.uk
</email>
<author confidence="0.748738">
Kees van Deemter
</author>
<affiliation confidence="0.992765">
Department of Computing Science
University of Aberdeen
</affiliation>
<email confidence="0.991475">
kvdeemte@csd.abdn.ac.uk
</email>
<sectionHeader confidence="0.993759" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999933888888889">
One of the challenges in the automatic
generation of referring expressions is to
identify a set of domain entities coher-
ently, that is, from the same conceptual
perspective. We describe and evaluate
an algorithm that generates a conceptually
coherent description of a target set. The
design of the algorithm is motivated by the
results of psycholinguistic experiments.
</bodyText>
<sectionHeader confidence="0.998796" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999875714285714">
Algorithms for the Generation of Referring Ex-
pressions (GRE) seek a set of properties that dis-
tinguish an intended referent from its distractors
in a knowledge base. Much of the GRE litera-
ture has focused on developing efficient content
determination strategies that output the best avail-
able description according to some interpretation
of the Gricean maxims (Dale and Reiter, 1995),
especially Brevity. Work on reference to sets has
also proceeded within this general framework (van
Deemter, 2002; Gardent, 2002; Horacek, 2004).
One problem that has not received much atten-
tion is that of conceptual coherence in the genera-
tion of plural references, i.e. the ascription of re-
lated properties to elements of a set, so that the
resulting description constitutes a coherent cover
for the plurality. As an example, consider a ref-
erence to {e1, e3} in Table 1 using the Incremen-
tal Algorithm (IA) (Dale and Reiter, 1995). IA
searches along an ordered list of attributes, select-
ing properties of the intended referents that re-
move some distractors. Assuming the ordering in
the top row, IA would yield the postgraduate and
the chef, which is fine in case occupation is the
relevant attribute in the discourse, but otherwise is
arguably worse than an alternative like the italian
and the maltese, because it is more difficult to see
what a postgraduate and a chef have in common.
</bodyText>
<table confidence="0.6083645">
type occupation nationality
e1 man postgraduate maltese
e2 man undergraduate greek
eg man chef italian
</table>
<tableCaption confidence="0.999088">
Table 1: Example domain
</tableCaption>
<bodyText confidence="0.958048212121212">
Such examples lead us to hypothesise the follow-
ing constraint:
Conceptual Coherence Constraint
(CC): As far as possible, describe
objects using related properties.
Related issues have been raised in the formal
semantics literature. Aloni (2002) argues that an
appropriate answer to a question of the form ‘Wh
x?’ must conceptualise the different instantiations
of x using a perspective which is relevant given the
hearer’s information state and the context. Kron-
feld (1989) distinguishes a description’s functional
relevance – i.e. its success in distinguishing a ref-
erent – from its conversational relevance, which
arises in part from implicatures. In our example,
describing e1 as the postgraduate carries the im-
plicature that the entity’s academic role is relevant.
When two entities are described using contrasting
properties, say the student and the italian, the con-
trast may be misleading for the listener.
Any attempt to port these observations to the
GRE scenario must do so without sacrificing logi-
cal completeness. While a GRE algorithm should
attempt to find the most coherent description avail-
able, it should not fail in the absence of a coher-
ent set of properties. This paper aims to achieve
a dual goal. First (§2), we will show that the CC
can be explained and modelled in terms of lexi-
cal semantic forces within a description, a claim
supported by the results of two experiments. Our
focus on ‘low-level’, lexical, determinants of ad-
equacy constitutes a departure from the standard
Gricean view. Second, we describe an algorithm
</bodyText>
<page confidence="0.973895">
255
</page>
<note confidence="0.724846">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 255–262,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.992509">
motivated by the experimental findings (§3) which
seeks to find the most coherent description avail-
able in a domain according to CC.
</bodyText>
<sectionHeader confidence="0.953505" genericHeader="method">
2 Empirical evidence
</sectionHeader>
<bodyText confidence="0.999686235294118">
We take as paradigmatic the case where a plural
reference involves disjunction/union, that is, has
the logical form Ax (p(x) V q(x)), realised as a
description of the form the N1 and the N2. By hy-
pothesis, the case where all referents can be de-
scribed using identical properties (logically, a con-
junction), is a limiting case of CC.
Previous work on plural anaphor processing has
shown that pronoun resolution is easier when an-
tecedents are ontologically similar (e.g. all hu-
mans) (Kaup et al., 2002; Koh and Clifton, 2002).
Reference to a heterogeneous set increases pro-
cessing difficulty.
Our experiments extended these findings to full
definite NP reference. Throughout, we used a dis-
tributional definition of similarity, as defined by
Lin (1998), which was found to be highly corre-
lated to people’s preferences for disjunctive de-
scriptions (Gatt and van Deemter, 2005). The sim-
ilarity of two arbitrary objects a and b is a function
of the information gained by giving a joint descrip-
tion of a and b in terms of what they have in com-
mon, compared to describing a and b separately.
The relevant data in the lexical domain is the
grammatical environment in which words occur.
This information is represented as a set of triples
(rel, w, w′), where rel is a grammatical relation,
w the word of interest and w′ its co-argument
in rel (e.g. (premodifies, dog, domestic )). Let
F(w) be a list of such triples. The information
content of this set is defined as mutual information
I(F(w)) (Church and Hanks, 1990). The similar-
ity of two words w1 and w2, of the same grammat-
ical category, is:
</bodyText>
<equation confidence="0.999660333333333">
2 x I(F(w1) n F(w2))
Q(w1, w2) � (1)
I (F(w1)) + I (F(w2))
</equation>
<bodyText confidence="0.89016275">
For example, if premodifies is one of the rele-
vant grammatical relations, then dog and cat might
occur several times in a corpus with the same pre-
modifiers (tame, domestic, etc). Thus, Q(dog, cat)
is large because in a corpus, they often occur in
the same contexts and there is considerable infor-
mation gain in a description of their common data.
Rather than using a hand-crafted ontology to in-
fer similarity, this definition looks at real language
Condition a b c distractor
HDS spanner chisel plug thimble
LDS toothbrush knife ashtray clock
</bodyText>
<figureCaption confidence="0.998811">
Figure 1: Conditions in Experiment 1
</figureCaption>
<bodyText confidence="0.9997115">
use. It covers ontological similarity to the extent
that ontologically similar objects are talked about
in the same contexts, but also cuts across ontolog-
ical distinctions (for example newspaper and jour-
nalist might turn out to be very similar).
We use the information contained in the
SketchEngine database1 (Kilgarriff, 2003), a
largescale implementation of Lin’s theory based
on the BNC, which contains grammatical triples
in the form of Word Sketches for each word, with
each triple accompanied by a salience value in-
dicating the likelihood of occurrence of the word
with its argument in a grammatical relation. Each
word also has a thesaurus entry, containing a
ranked list of words of the same category, ordered
by their similarity to the head word.
</bodyText>
<subsectionHeader confidence="0.968359">
2.1 Experiment 1
</subsectionHeader>
<bodyText confidence="0.995036692307692">
In Experiment 1, participants were placed in a sit-
uation where they were buying objects from an on-
line store. They saw scenarios containing four pic-
tures of objects, three of which (the targets) were
identically priced. Participants referred to them by
completing a 2-sentence discourse:
S1 The object1 and the object 2 cost amount.
S2 The object3 also costs amount.
If similarity is a constraint on referential coher-
ence in plural references, then if two targets are
similar (and dissimilar to the third), a plural refer-
ence to them in S1 should be more likely, with the
third entity referred to in S2.
Materials, design and procedure All the pic-
tures were artefacts selected from a set of draw-
ings normed in a picture-naming task with British
English speakers (Barry et al., 1997).
Each trial consisted of the four pictures ar-
ranged in an array on a screen. Of the three targets
(a, b, c), c was always an object whose name in
the norms was dissimilar to that of a and b. The
semantic similarity of (nouns denoting) a and b
was manipulated as a factor with two levels: High
Distributional Similarity (HDS) meant that b oc-
curred among the top 50 most similar items to a in
its Sketchengine thesaurus entry. Low DS (LDS))
</bodyText>
<footnote confidence="0.991936">
1http://www.sketchengine.co.uk
</footnote>
<page confidence="0.994985">
256
</page>
<bodyText confidence="0.991217390410959">
meant that b did not occur in the top 500 entries Three millionaires with a passion for antiques were spotted
for a. Examples are shown in Figure 2.1. dining at a London restaurant.
Visual Similarity (VS) of a and b was also con- e1 One of the men, a Rumanian, is a dealeri.
trolled. Pairs of pictures were first normed with a e2 The second, a princej , is a collectori.
group who rated them on a 10-point scale based eg The third, a dukej , is a bachelor.
on their visual properties. High-VS (HVS) pairs The XXXX were both accompanied by servants, but the
had a mean rating ≥ 6; Low-VS LVS) pairs had bachelor wasn’t .
mean ratings ≤ 2. Two sets of materials were con-
structed, for a total of 2 (D5) x 2 (V 5) x 2 = 8
trials.
29 self-reported native or fluent speakers of En-
glish completed the experiment over the web. To
complete the sentences, participants clicked on the
objects in the order they wished to refer to them.
Nouns appeared in the next available space2.
Results and discussion Responses were coded
according to whether objects a and b were referred
to in the plural subject of S1 (a + b responses) or
not (a − b responses). If our hypothesis is correct,
there should be a higher proportion of a + b re-
sponses in the HDS condition. We did not expect
an effect of VS. In what follows, we report by-
subjects Friedman analyses (xi); by-items analy-
ses (x22); and by-subjects sign tests (Z) on propor-
tions of responses for pairwise comparisons.
Response frequencies across conditions differed
reliably by subjects (xi = 46.124,p &lt; .001).
The frequency of a + b responses in S1 was re-
liably higher than that of a − b in the HDS condi-
tion (x2 2 = 41.371, p &lt; .001), but not the HVS
condition (x2 2 = 1.755, ns). Pairwise compar-
isons between HDS and LDS showed a signif-
icantly higher proportion of a + b responses in
the former (Z = 4.48,p &lt; .001); the differ-
ence was barely significant across VS conditions
(Z = 1.9,p = .06).
The results show that, given a clear choice of
entities to refer to in a plurality, people are more
likely to describe similar entities in a plural de-
scription. However, these results raise two further
questions. First, given a choice of distinguishing
properties for individuals making up a target set,
will participants follow the predictions of the CC?
(In other words, is distributional similarity rele-
vant for content determination?) Second, does the
similarity effect carry over to modifiers, such as
adjectives, or is the CC exclusively a constraint on
types?
Figure 2: Example discourses
2.2 Experiment 2
Experiment 2 was a sentence continuation task,
designed to closely approximate content determi-
nation in GRE. Participants saw a series of dis-
courses, in which three entities (e1, e2, e3) were
introduced, each with two distinguishing proper-
ties. The final sentence in each discourse had a
missing plural subject NP referring to two of these.
The context made it clear which of the three en-
tities had to be referred to. Our hypothesis was
that participants would prefer to use semantically
similar properties for the plural reference, even if
dissimilar properties were also available.
Materials, design and procedure Materials
consisted of 24 discourses, such as those in Fig-
ure 2.2. After an initial introductory sentence, the
3 entities were introduced in separate sentences.
In all discourses, the pairs {e1, e2} and {e2, e3}
could be described using either pairwise similar or
dissimilar properties (similar pairs are coindexed
in the figure). In half the discourses, the dis-
tinguishing properties of each entity were nouns;
thus, although all three entities belonged to the
same ontological category (e.g. all human), they
had distinct types (e.g. duke, prince, bachelor). In
the other half, entities were of the same type, that
is the NPs introducing them had the same nominal
head, but had distinguishing adjectival modifiers.
For counterbalancing, two versions of each dis-
course were constructed, such that, if {e1, e2} was
the target set in Version 1, then {e2, e3} was the
target in Version 2. Twelve filler items requiring
singular reference in the continuation were also in-
cluded. The order in which the entities were intro-
duced was randomised across participants, as was
the order of trials. The experiment was completed
by 18 native speakers of English, selected from the
Aberdeen NLG Group database. They were ran-
domly assigned to either Version 1 or 2.
Results and discussion Responses were coded
1 if the semantically similar properties were used
(e.g. the prince and the duke in Fig. 2.2); 2 if the
2Earler replications involving typing yielded parallel re-
sults and high conformity between the words used and those
predicted by the picture norms.
257
similar properties were used together with other
properties (e.g. the prince and the bachelor duke);
3 if a superordinate term was used to replace the
similar properties (e.g. the noblemen); 4 otherwise
(e.g. The duke and the collector).
Response types differed significantly in the
nominal condition both by subjects (xi =
45.89, p &lt; .001) and by items (x2 2 = 287.9, p &lt;
.001). Differences were also reliable in the mod-
ifier condition (x21 = 36.3, p &lt; .001, x22 =
199.2, p &lt; .001). However, the trends across con-
ditions were opposed, with more items in the 1 re-
sponse category in the nominal condition (53.7%)
and more in the 4 category in the modifier condi-
tion (47.2%). Recoding responses as binary (‘sim-
ilar’ = 1,2,3; ‘dissimilar’ = 4) showed a significant
difference in proportions for the nominal category
(x2 = 4.78, p = .03), but not the modifier cate-
gory. Pairwise comparisons showed a significantly
larger proportion of 1 (Z = 2.7,p = .007) and
2 responses (Z = 2.54,p = .01) in the nominal
compared to the modifier condition.
The results suggest that in a referential task, par-
ticipants are likely to conform to the CC, but that
the CC operates mainly on nouns, and less so on
(adjectival) modifiers. Nouns (or types, as we shall
sometimes call them) have the function of cate-
gorising objects; thus similar types facilitate the
mental representation of a plurality in a concep-
tually coherent way. According to the definition
in (1), this is because similarity of two types im-
plies a greater likelihood of their being used in
the same predicate-argument structures. As a re-
sult, it is easier to map the elements of a plural-
ity to a common role in a sentence. A related
proposal has been made by Moxey and Sanford
(1995), whose Scenario Mapping Principle holds
that a plural reference is licensed to the extent that
the elements of the plurality can be mapped to a
common role in the discourse. This is influenced
by how easy it is to conceive of such a role for the
referents. Our results can be viewed as providing
a handle on the notion of ‘ease of conception of a
common role’; in particular we propose that likeli-
hood of occurrence in the same linguistic contexts
directly reflects the extent to which two types can
be mapped to a single plural role.
As regards modifiers, while it is probably pre-
mature to suggest that CC plays no role in modifier
selection, it is likely that modifiers play a different
role from nouns. Previous work has shown that
</bodyText>
<table confidence="0.9986738">
id base type occupation specialisation girth
e1 woman professor physicist plump
e2 woman lecturer geologist thin
eg man lecturer biologist plump
eq man chemist thin
</table>
<tableCaption confidence="0.999604">
Table 2: An example knowledge base
</tableCaption>
<bodyText confidence="0.999338411764706">
restrictions on the plausibility of adjective-noun
combinations exist (Lapata et al., 1999), and that
using unlikely combinations (e.g. the immaculate
kitchen rather than the spotless kitchen) impacts
processing in online tasks (Murphy, 1984). Unlike
types, which have a categorisation function, mod-
ifiers have the role of adding information about an
element of a category. This would partially ex-
plain the experimental results: When elements of
a plurality have identical types (as in the modifier
version of our experiment), the CC is already satis-
fied, and selection of modifiers would presumably
depend on respecting adjective-noun combination
restrictions. Further research is required to ver-
ify this, although the algorithm presented below
makes use of the Sketch Engine database to take
modifier-noun combinations into account.
</bodyText>
<sectionHeader confidence="0.914452" genericHeader="method">
3 An algorithm for referring to sets
</sectionHeader>
<bodyText confidence="0.999936428571429">
Our next task is to port the results to GRE. The
main ingredient to achieve conceptual coherence
will be the definition of semantic similarity. In
what follows, all examples will be drawn from the
domain in Table 3.
We make the following assumptions. There is
a set U of domain entities, properties of which
are specified in a KB as attribute-value pairs. We
assume a distinction between types, that is, any
property that can be realised as a noun; and modi-
fiers, or non-types. Given a set of target referents
R ⊆ U, the algorithm described below generates a
description D in Disjunctive Normal Form (DNF),
having the following properties:
</bodyText>
<listItem confidence="0.895819111111111">
1. Any disjunct in D contains a ‘type’ property,
i.e. a property realisable as a head noun.
2. If D has two or more disjuncts, each a con-
junction containing at least one type, then the
disjoined types should be as similar as pos-
sible, given the information in the KB and
the completeness requirement: that the algo-
rithm find a distinguishing description when-
ever one exists.
</listItem>
<page confidence="0.990382">
258
</page>
<bodyText confidence="0.9999565">
We first make our interpretation of the CC more
precise. Let T be the set of types in the KB, and
let Q(t, t′) be the (symmetrical) similarity between
any two types t and t′. These determine a seman-
tic space S = (T, Q). We define the notion of a
perspective as follows.
</bodyText>
<equation confidence="0.69437525">
Definition 1. Perspective
A perspective P is a convex subset of S, i.e.:
bt, t′, t″E T :
It, t′} C_ P ∧ Q(t,t″) &gt; Q(t,t′) , t″E P
</equation>
<bodyText confidence="0.999913166666667">
The aims of the algorithm are to describe ele-
ments of R using types from the same perspective,
failing which, it attempts to minimise the distance
between the perspectives from which types are se-
lected in the disjunctions of D. Distance between
perspectives is defined below.
</bodyText>
<subsectionHeader confidence="0.999236">
3.1 Finding perspectives
</subsectionHeader>
<bodyText confidence="0.999992344827586">
The system makes use of the SketchEngine
database as its primary knowledge source. Since
the definition of similarity applies to words, rather
than properties, the first step is to generate all pos-
sible lexicalisations of the available attribute-value
pairs in the domain. In this paper, we simplify by
assuming a one-to-one mapping between proper-
ties and words.
Another requirement is to distinguish between
type properties (the set T), and non-types (M)3.
The Thesaurus is used to find pairwise similarity
of types in order to group them into related clus-
ters. Word Sketches are used to find, for each type,
the modifiers in the KB that are appropriate to the
type, on the basis of the associated salience values.
For example, in Table 3, e3 has plump as the value
for girth, which combines more felicitously with
man, than with biologist.
Types are clustered using the algorithm de-
scribed in Gatt (2006). For each type t, the al-
gorithm finds its nearest neighbour nt in seman-
tic space. Clusters are then found by recursively
grouping elements with their nearest neighbours.
If t, t′ have a common nearest neighbour n, then
It, t′, n} is a cluster. Clearly, the resulting sets are
convex in the sense of Definition 1. Each modi-
fier is assigned to a cluster by finding in its Word
Sketch the type with which it co-occurs with the
greatest salience value. Thus, a cluster is a pair
</bodyText>
<footnote confidence="0.933022666666667">
3This is determined using corpus-derived information.
Note that T and M need not be disjoint, and entities can have
more than one type property
</footnote>
<note confidence="0.688801">
T: {lecturer, professor}[
</note>
<figureCaption confidence="0.999694">
Figure 3: Perspective Graph
</figureCaption>
<bodyText confidence="0.9479805">
(P, M′) where P is a perspective, and M′ C_ M.
The distance S(A, B) between two clusters A and
B is defined straightforwardly in terms of the dis-
tance between their perspectives PA and PB:
</bodyText>
<equation confidence="0.990415">
1
S(A, B) = 1 + E-EPA,yEPB -(-,y) (2)
</equation>
<bodyText confidence="0.999966214285714">
Finally, a weighted, connected graph !9 =
(V, E, S) is created, where V is the set of clus-
ters, and E is the set of edges with edge weights
defined as the semantic distance between perspec-
tives. Figure 3.1 shows the graph constructed for
the domain in Table 3.
We now define the coherence of a description
more precisely. Given a DNF description D, we
shall say that a perspective P is realised in D if
there is at least one type t E P which is in D.
Let PD be the set of perspectives realised in D.
Since !9 is connected, PD determines a connected
subgraph of !9. The total weight of D, w(D) is the
sum of weights of the edges in PD.
</bodyText>
<subsectionHeader confidence="0.392012">
Definition 2. Maximal coherence
</subsectionHeader>
<bodyText confidence="0.95174">
A description D is maximally coherent iff there
is no description D′ coextensive with D such that
w(D) &gt; w(D′).
(Note that several descriptions of the same ref-
erent may all be maximally coherent.)
</bodyText>
<subsectionHeader confidence="0.999628">
3.2 Content determination
</subsectionHeader>
<bodyText confidence="0.9999666">
The core of the content determination procedure
maintains the DNF description D as an associa-
tive array, such that for any r E R, D[r] is a con-
junction of properties true of r. Given a cluster
(P, M), the procedure searches incrementally first
through P, and then M, selecting properties that
are true of at least one referent and exclude some
distractors, as in the IA (Dale and Reiter, 1995).
By Definition 2, the task of the algorithm is
to minimise the total weight w(D). If PD is the
</bodyText>
<figure confidence="0.9885524">
T: {woman, man}0
M: {plump, thin}0
20
10
T: {geologist, physicist,[
biologist, chemist}0
30
10
10 0.60
|?AX?B|
</figure>
<page confidence="0.995967">
259
</page>
<bodyText confidence="0.999863833333333">
set of perspectives represented in D on termina-
tion, then maximal coherence would require PD
to be the subgraph of !g with the lowest total cost
from which a distinguishing description could be
constructed. Under this interpretation, PD corre-
sponds to a Shortest Connection, or Steiner, Net-
work. Finding such networks is known to be NP-
Hard. Therefore, we adopt a weaker (greedy) in-
terpretation. Under the new definition, if D is
the only description for R, then it trivially satis-
fies maximal coherence. Otherwise, the algorithm
aims to maximise local coherence.
</bodyText>
<subsectionHeader confidence="0.817145">
Definition 3. Local coherence
</subsectionHeader>
<bodyText confidence="0.994116">
A description D is locally coherent iff:
</bodyText>
<listItem confidence="0.9475674">
a. either D is maximally coherent or
b. there is no D′ coextensive with D, obtained
by replacing types from some perspective in
PD with types from another perspective such
that w(D) &gt; w(D′).
</listItem>
<bodyText confidence="0.999825928571429">
Our implementation of this idea begins the
search for distinguishing properties by identifying
the vertex of !g which contains the greatest num-
ber of referents in its extension. This constitutes
the root node of the search path. For each node
of the graph it visits, the algorithm searches for
properties that are true of some subset of R, and
removes some distractors, maintaining a set N of
the perspectives which are represented in D up to
the current point. The crucial choice points arise
when a new node (perspective) needs to be visited
in the graph. At each such point, the next node n
to be visited is the one which minimises the total
weight of N, that is:
</bodyText>
<equation confidence="0.590955">
�min w(u, n) (3)
n∈V u∈N
</equation>
<bodyText confidence="0.996162448275862">
The results of this procedure closely approxi-
mate maximal coherence, because the algorithm
starts with the vertex most likely to distinguish
the referents, and then greedily proceeds to those
nodes which minimise w(D) given the current
state, that is, taking all previously used nodes into
account.
As an example of the output, we will take
R = {e1, e3, e4} as the intended referents in Table
3. First, the algorithm determines the cluster with
the greatest number of referents in its extension.
In this case, there is a tie between clusters 2 and
3 in Figure 3.1, since all three entities have type
properties in these clusters. In either case, the
entities are distinguishable from a single cluster.
If cluster 3 is selected as the root, the output is
Ax [physicist(x) V biologist(x) V chemist(x)].
In case the algorithm selects cluster 2 as the
root node the final output is the logical form
Ax [man(x) V (woman(x) ∧ plump(x))].
There is an alternative description that the
algorithm does not consider. An algorithm
that aimed for conciseness would generate
Ax [professor(x) V man(x)] (the professor and
the men), which does not satisfy local coherence.
These examples therefore highlight the possible
tension between the avoidance of redundancy and
achieving coherence. It is to an investigation of
this tension that we now turn.
</bodyText>
<sectionHeader confidence="0.99821" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999987333333333">
It has been known at least since Dale and Reiter
(1995) that the best distinguishing description is
not always the shortest one. Yet, brevity plays a
part in all GRE algorithms, sometimes in a strict
form (Dale, 1989), or by letting the algorithm ap-
proximate the shortest description (for example, in
the Dale and Reiter’s IA). This is also true of refer-
ences to sets, the clearest example being Gardent’s
constraint based approach, which always finds the
description with the smallest number of logical op-
erators. Such proposals do not take coherence (in
our sense of the word) into account. This raises
obvious questions about the relative importance of
brevity and coherence in reference to sets.
The evaluation took the form of an experiment
to compare the output of our Coherence Model
with the family of algorithms that have placed
Brevity at the centre of content determination. Par-
ticipants were asked to compare pairs of descrip-
tions of one and the same target set, selecting the
one they found most natural. Each description
could either be optimally brief or not (+b) and also
either optimally coherent or not (+c). Non-brief
descriptions, took the form the A, the B and the C.
Brief descriptions ‘aggregated’ two disjuncts into
one (e.g. the A and the D’s where D comprises the
union of B and C). We expected to find that:
</bodyText>
<equation confidence="0.87814025">
H1 +c descriptions are preferred over −c.
H2 (+c, −b) descriptions are preferred over ones
that are (−c, +b).
H3 +b descriptions are preferred over −b.
</equation>
<bodyText confidence="0.99184">
Confirmation of H1 would be interpreted as ev-
idence that, by taking coherence into account, our
</bodyText>
<page confidence="0.991835">
260
</page>
<tableCaption confidence="0.2725946">
Three old manuscripts were auctioned at Sotheby’s.
e1 One of them is a book, a biography of a composer.
e2 The second, a sailor’s journal, was published
in the form of a pamphlet. It is a record of a voyage.
eg The third, another pamphlet, is an essay by Hume.
(+c, −b) The biography, the journal and the essay were sold to a col-
lector.
(+c, +b) The book and the pamphlets were sold to a collector.
(−c, +b) The biography and the pamphlets were sold to a collector.
(−c, −b) The book, the record and the essay were sold to a collector.
</tableCaption>
<figureCaption confidence="0.998845">
Figure 4: Example domain in the evaluation
</figureCaption>
<bodyText confidence="0.99864919047619">
algorithm is on the right track. If H3 were con-
firmed, then earlier algorithms were (also) on the
right track by taking brevity into account. Con-
firmation of H2 would be interpreted as meaning
that, in references to sets, conceptual coherence is
more important than brevity (defined as the num-
ber of disjuncts in a disjunctive reference to a set).
Materials, design and procedure Six dis-
courses were constructed, each introducing three
entities. Each set of three could be described
using all 4 possible combinations of +b x +c
(see Figure 4). Entities were human in two of
the discourses, and artefacts of various kinds in
the remainder. Properties of entities were intro-
duced textually; the order of presentation was ran-
domised. A forced-choice task was used. Each
discourse was presented with 2 possible continua-
tions consisting of a sentence with a plural subject
NP, and participants were asked to indicate the one
they found most natural. The 6 comparisons cor-
responded to 6 sub-conditions:
</bodyText>
<figure confidence="0.943684888888889">
C1. Coherence constant
a. (+c, −b) vs. (+c, +b)
b. (−c, −b) vs. (−c, +b)
C2. Brevity constant
a. (+c, −b) vs. (−c, −b)
b. (+c, +b) vs. (−c, +b)
C3. Tradeoff/control
a. (+c, −b) vs. (−c, +b)
b. (−c, −b) vs. (+c, +b)
</figure>
<bodyText confidence="0.993674375">
Participants saw each discourse in a single con-
dition. They were randomly divided into six
groups, so that each discourse was used for a dif-
ferent condition in each group. 39 native English
speakers, all undergraduates at the University of
Aberdeen, took part in the study.
Results and discussion Results were coded ac-
cording to whether a participant’s choice was +b
</bodyText>
<table confidence="0.992153666666667">
C1a C1b C2a C2b C3a C3b
+b 51.3 43.6 – – 30.8 76.9
+c – – 82.1 79.5 69.2 76.9
</table>
<tableCaption confidence="0.999655">
Table 3: Response proportions (%)
</tableCaption>
<bodyText confidence="0.995352342105263">
and/or +c. Table 4 displays response propor-
tions. Overall, the conditions had a significant
impact on responses, both by subjects (Friedman
x2 = 107.3,p &lt; .001) and by items (x2 =
30.2,p &lt; .001). When coherence was kept con-
stant (C1a and C1b), the likelihood of a response
being +b was no different from −b (C1a: x2 =
.023,p = .8; C1b: x2 = .64,p = .4); the con-
ditions C1a and C1b did not differ significantly
(x2 = .46,p = .5). By contrast, conditions
where brevity was kept constant (C2a and C2b)
resulted in very significantly higher proportions of
+c choices (C2a: x2 = 16.03,p &lt; .001; C2b:
x2 = 13.56,p &lt; .001). No difference was ob-
served between C2a and C2b (x2 = .08, p = .8).
In the tradeoff case (C3a), participants were much
more likely to select a +c description than a +b
one (x2 = 39.0,p &lt; .001); a majority opted
for the (+b, +c) description in the control case
(x2 = 39.0,p &lt; .001).
The results strongly support H1 and H2, since
participants’ choices are impacted by Coherence.
They do not indicate a preference for brief de-
scriptions, a finding that echoes Jordan’s (2000),
to the effect that speakers often relinquish brevity
in favour of observing task or discourse con-
straints. Since this experiment compared our al-
gorithm against the current state of the art in ref-
erences to sets, these results do not necessarily
warrant the affirmation of the null hypothesis in
the case of H3. We limited Brevity to number of
disjuncts, omitting negation, and varying only be-
tween length 2 or 3. Longer or more complex de-
scriptions might evince different tendencies. Nev-
ertheless, the results show a strong impact of Co-
herence, compared to (a kind of) brevity, in strong
support of the algorithm presented above, as a re-
alisation of the Coherence Model.
</bodyText>
<sectionHeader confidence="0.99607" genericHeader="conclusions">
5 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.9999534">
This paper started with an empirical investigation
of conceptual coherence in reference, which led
to a definition of local coherence as the basis for
a new greedy algorithm that tries to minimise the
semantic distance between the perspectives repre-
</bodyText>
<page confidence="0.990217">
261
</page>
<bodyText confidence="0.99978">
sented in a description. The evaluation strongly
supports our Coherence Model.
We are extending this work in two directions.
First, we are investigating similarity effects across
noun phrases, and their impact on text readabil-
ity. Finding an impact of such factors would make
this model a useful complement to current theories
of discourse, which usually interpret coherence in
terms of discourse/sentential structure.
Second, we intend to relinquish the assumption
of a one-to-one correspondence between proper-
ties and words (cf. Siddharthan and Copestake
(2004)), making use of the fact that words can be
disambiguated by nearby words that are similar.
To use a well-worn example: the ‘financial institu-
tion’ sense of bank might not make the river and
its bank lexically incoherent as a description of a
piece of scenery, since the word river might cause
the hearer to focus on the aquatic reading of the
word anyway.
</bodyText>
<sectionHeader confidence="0.999431" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.989973857142857">
Thanks to Ielka van der Sluis, Imtiaz
Khan, Ehud Reiter, Chris Mellish, Graeme
Ritchie and Judith Masthoff for useful com-
ments. This work is part of the TUNA
project (http://www.csd.abdn.ac.uk/
research/tuna), supported by EPSRC grant
no. GR/S13330/01
</bodyText>
<sectionHeader confidence="0.998879" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999930785714286">
M. Aloni. 2002. Questions under cover. In D. Barker-
Plummer, D. Beaver, J. van Benthem, and P. Scotto
de Luzio, editors, Words, Proofs, and Diagrams.
CSLI, Stanford, Ca.
C. Barry, C. M. Morrison, and A. W. Ellis. 1997.
Naming the snodgrass and vanderwart pictures.
Quarterly Journal of Experimental Psychology,
50A(3):560–585.
K. W. Church and P. Hanks. 1990. Word association
norms, mutual information and lexicography. Com-
putational Linguistics, 16(1):22–29.
R. Dale and E. Reiter. 1995. Computational interpre-
tation of the Gricean maxims in the generation of re-
ferring expressions. Cognitive Science, 19(8):233–
263.
Robert Dale. 1989. Cooking up referring expressions.
In Proc. 27th Annual Meeting of the Association for
Computational Linguistics.
C. Gardent. 2002. Generating minimal definite de-
scriptions. In Proc. 40th Annual Meeting of the As-
sociation for Computational Linguistics.
A. Gatt and K. van Deemter. 2005. Semantic simi-
larity and the generation of referring expressions: A
first report. In Proceedings of the 6th International
Workshop on Computational Semantics, IWCS-6.
A. Gatt. 2006. Structuring knowledge for reference
generation: A clustering algorithm. In Proc. 11th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics.
H. Horacek. 2004. On referring to sets of objects natu-
rally. In Proc. 3rd International Conference on Nat-
ural Language Generation.
P. W. Jordan. 2000. Can nominal expressions achieve
multiple goals? In Proceedings of the 38th Annual
Meeting of the Association for Computational Lin-
guistics.
B. Kaup, S. Kelter, and C. Habel. 2002. Represent-
ing referents ofplural expressions and resolving plu-
ral anaphors. Language and Cognitive Processes,
17(4):405–450.
A. Kilgarriff. 2003. Thesauruses for natural language
processing. In Proc. NLP-KE, Beijing.
S. Koh and C. Clifton. 2002. Resolution of the an-
tecedent of a plural pronoun: Ontological categories
and predicate symmetry. Journal of Memory and
Language, 46:830–844.
A. Kronfeld. 1989. Conversationally relevant descrip-
tions. In Proc. 27th Annual Meeting of the Associa-
tion for Computational Linguistics.
M. Lapata, S. McDonald, and F. Keller. 1999. Deter-
minants of adjective-noun plausibility. In Proc. 9th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics.
D. Lin. 1998. An information-theoretic definition
of similarity. In Proc. International Conference on
Machine Learning.
L. Moxey and A. Sanford. 1995. Notes on plural refer-
ence and the scenario-mapping principle in compre-
hension. In C.Habel and G.Rickheit, editors, Focus
and cohesion in discourse. de Gruyter, Berlin.
G.L. Murphy. 1984. Establishing and accessing refer-
ents in discourse. Memory and Cognition, 12:489–
497.
A. Siddharthan and A. Copestake. 2004. Generat-
ing referring expressions in open domains. In Proc.
42nd Annual Meeting of the Association for Compu-
tational Linguistics.
K. van Deemter. 2002. Generating referring expres-
sions: Boolean extensions of the incremental algo-
rithm. Computational Linguistics, 28(1):37–52.
</reference>
<page confidence="0.997295">
262
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.979433">
<title confidence="0.999763">Conceptual Coherence in the Generation of Referring Expressions</title>
<author confidence="0.999944">Albert Gatt</author>
<affiliation confidence="0.9998635">Department of Computing Science University of Aberdeen</affiliation>
<email confidence="0.986983">agatt@csd.abdn.ac.uk</email>
<author confidence="0.9973">Kees van_Deemter</author>
<affiliation confidence="0.9998725">Department of Computing Science University of Aberdeen</affiliation>
<email confidence="0.99812">kvdeemte@csd.abdn.ac.uk</email>
<abstract confidence="0.9997614">One of the challenges in the automatic generation of referring expressions is to identify a set of domain entities coherently, that is, from the same conceptual perspective. We describe and evaluate an algorithm that generates a conceptually coherent description of a target set. The design of the algorithm is motivated by the results of psycholinguistic experiments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Aloni</author>
</authors>
<title>Questions under cover. In</title>
<date>2002</date>
<editor>D. BarkerPlummer, D. Beaver, J. van Benthem, and P. Scotto de Luzio, editors, Words, Proofs, and Diagrams. CSLI, Stanford,</editor>
<location>Ca.</location>
<contexts>
<context position="2387" citStr="Aloni (2002)" startWordPosition="368" endWordPosition="369"> is fine in case occupation is the relevant attribute in the discourse, but otherwise is arguably worse than an alternative like the italian and the maltese, because it is more difficult to see what a postgraduate and a chef have in common. type occupation nationality e1 man postgraduate maltese e2 man undergraduate greek eg man chef italian Table 1: Example domain Such examples lead us to hypothesise the following constraint: Conceptual Coherence Constraint (CC): As far as possible, describe objects using related properties. Related issues have been raised in the formal semantics literature. Aloni (2002) argues that an appropriate answer to a question of the form ‘Wh x?’ must conceptualise the different instantiations of x using a perspective which is relevant given the hearer’s information state and the context. Kronfeld (1989) distinguishes a description’s functional relevance – i.e. its success in distinguishing a referent – from its conversational relevance, which arises in part from implicatures. In our example, describing e1 as the postgraduate carries the implicature that the entity’s academic role is relevant. When two entities are described using contrasting properties, say the stude</context>
</contexts>
<marker>Aloni, 2002</marker>
<rawString>M. Aloni. 2002. Questions under cover. In D. BarkerPlummer, D. Beaver, J. van Benthem, and P. Scotto de Luzio, editors, Words, Proofs, and Diagrams. CSLI, Stanford, Ca.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Barry</author>
<author>C M Morrison</author>
<author>A W Ellis</author>
</authors>
<title>Naming the snodgrass and vanderwart pictures.</title>
<date>1997</date>
<journal>Quarterly Journal of Experimental Psychology,</journal>
<pages>50--3</pages>
<contexts>
<context position="7778" citStr="Barry et al., 1997" startWordPosition="1269" endWordPosition="1272">s, three of which (the targets) were identically priced. Participants referred to them by completing a 2-sentence discourse: S1 The object1 and the object 2 cost amount. S2 The object3 also costs amount. If similarity is a constraint on referential coherence in plural references, then if two targets are similar (and dissimilar to the third), a plural reference to them in S1 should be more likely, with the third entity referred to in S2. Materials, design and procedure All the pictures were artefacts selected from a set of drawings normed in a picture-naming task with British English speakers (Barry et al., 1997). Each trial consisted of the four pictures arranged in an array on a screen. Of the three targets (a, b, c), c was always an object whose name in the norms was dissimilar to that of a and b. The semantic similarity of (nouns denoting) a and b was manipulated as a factor with two levels: High Distributional Similarity (HDS) meant that b occurred among the top 50 most similar items to a in its Sketchengine thesaurus entry. Low DS (LDS)) 1http://www.sketchengine.co.uk 256 meant that b did not occur in the top 500 entries Three millionaires with a passion for antiques were spotted for a. Examples</context>
</contexts>
<marker>Barry, Morrison, Ellis, 1997</marker>
<rawString>C. Barry, C. M. Morrison, and A. W. Ellis. 1997. Naming the snodgrass and vanderwart pictures. Quarterly Journal of Experimental Psychology, 50A(3):560–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="5505" citStr="Church and Hanks, 1990" startWordPosition="882" endWordPosition="885">ity of two arbitrary objects a and b is a function of the information gained by giving a joint description of a and b in terms of what they have in common, compared to describing a and b separately. The relevant data in the lexical domain is the grammatical environment in which words occur. This information is represented as a set of triples (rel, w, w′), where rel is a grammatical relation, w the word of interest and w′ its co-argument in rel (e.g. (premodifies, dog, domestic )). Let F(w) be a list of such triples. The information content of this set is defined as mutual information I(F(w)) (Church and Hanks, 1990). The similarity of two words w1 and w2, of the same grammatical category, is: 2 x I(F(w1) n F(w2)) Q(w1, w2) � (1) I (F(w1)) + I (F(w2)) For example, if premodifies is one of the relevant grammatical relations, then dog and cat might occur several times in a corpus with the same premodifiers (tame, domestic, etc). Thus, Q(dog, cat) is large because in a corpus, they often occur in the same contexts and there is considerable information gain in a description of their common data. Rather than using a hand-crafted ontology to infer similarity, this definition looks at real language Condition a b</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>K. W. Church and P. Hanks. 1990. Word association norms, mutual information and lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
<author>E Reiter</author>
</authors>
<title>Computational interpretation of the Gricean maxims in the generation of referring expressions.</title>
<date>1995</date>
<journal>Cognitive Science,</journal>
<volume>19</volume>
<issue>8</issue>
<pages>263</pages>
<contexts>
<context position="1024" citStr="Dale and Reiter, 1995" startWordPosition="145" endWordPosition="148">same conceptual perspective. We describe and evaluate an algorithm that generates a conceptually coherent description of a target set. The design of the algorithm is motivated by the results of psycholinguistic experiments. 1 Introduction Algorithms for the Generation of Referring Expressions (GRE) seek a set of properties that distinguish an intended referent from its distractors in a knowledge base. Much of the GRE literature has focused on developing efficient content determination strategies that output the best available description according to some interpretation of the Gricean maxims (Dale and Reiter, 1995), especially Brevity. Work on reference to sets has also proceeded within this general framework (van Deemter, 2002; Gardent, 2002; Horacek, 2004). One problem that has not received much attention is that of conceptual coherence in the generation of plural references, i.e. the ascription of related properties to elements of a set, so that the resulting description constitutes a coherent cover for the plurality. As an example, consider a reference to {e1, e3} in Table 1 using the Incremental Algorithm (IA) (Dale and Reiter, 1995). IA searches along an ordered list of attributes, selecting prope</context>
<context position="21315" citStr="Dale and Reiter, 1995" startWordPosition="3629" endWordPosition="3632">rence A description D is maximally coherent iff there is no description D′ coextensive with D such that w(D) &gt; w(D′). (Note that several descriptions of the same referent may all be maximally coherent.) 3.2 Content determination The core of the content determination procedure maintains the DNF description D as an associative array, such that for any r E R, D[r] is a conjunction of properties true of r. Given a cluster (P, M), the procedure searches incrementally first through P, and then M, selecting properties that are true of at least one referent and exclude some distractors, as in the IA (Dale and Reiter, 1995). By Definition 2, the task of the algorithm is to minimise the total weight w(D). If PD is the T: {woman, man}0 M: {plump, thin}0 20 10 T: {geologist, physicist,[ biologist, chemist}0 30 10 10 0.60 |?AX?B| 259 set of perspectives represented in D on termination, then maximal coherence would require PD to be the subgraph of !g with the lowest total cost from which a distinguishing description could be constructed. Under this interpretation, PD corresponds to a Shortest Connection, or Steiner, Network. Finding such networks is known to be NPHard. Therefore, we adopt a weaker (greedy) interpreta</context>
<context position="24445" citStr="Dale and Reiter (1995)" startWordPosition="4162" endWordPosition="4165">st(x) V chemist(x)]. In case the algorithm selects cluster 2 as the root node the final output is the logical form Ax [man(x) V (woman(x) ∧ plump(x))]. There is an alternative description that the algorithm does not consider. An algorithm that aimed for conciseness would generate Ax [professor(x) V man(x)] (the professor and the men), which does not satisfy local coherence. These examples therefore highlight the possible tension between the avoidance of redundancy and achieving coherence. It is to an investigation of this tension that we now turn. 4 Evaluation It has been known at least since Dale and Reiter (1995) that the best distinguishing description is not always the shortest one. Yet, brevity plays a part in all GRE algorithms, sometimes in a strict form (Dale, 1989), or by letting the algorithm approximate the shortest description (for example, in the Dale and Reiter’s IA). This is also true of references to sets, the clearest example being Gardent’s constraint based approach, which always finds the description with the smallest number of logical operators. Such proposals do not take coherence (in our sense of the word) into account. This raises obvious questions about the relative importance of</context>
</contexts>
<marker>Dale, Reiter, 1995</marker>
<rawString>R. Dale and E. Reiter. 1995. Computational interpretation of the Gricean maxims in the generation of referring expressions. Cognitive Science, 19(8):233– 263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
</authors>
<title>Cooking up referring expressions.</title>
<date>1989</date>
<booktitle>In Proc. 27th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="24607" citStr="Dale, 1989" startWordPosition="4191" endWordPosition="4192">ve description that the algorithm does not consider. An algorithm that aimed for conciseness would generate Ax [professor(x) V man(x)] (the professor and the men), which does not satisfy local coherence. These examples therefore highlight the possible tension between the avoidance of redundancy and achieving coherence. It is to an investigation of this tension that we now turn. 4 Evaluation It has been known at least since Dale and Reiter (1995) that the best distinguishing description is not always the shortest one. Yet, brevity plays a part in all GRE algorithms, sometimes in a strict form (Dale, 1989), or by letting the algorithm approximate the shortest description (for example, in the Dale and Reiter’s IA). This is also true of references to sets, the clearest example being Gardent’s constraint based approach, which always finds the description with the smallest number of logical operators. Such proposals do not take coherence (in our sense of the word) into account. This raises obvious questions about the relative importance of brevity and coherence in reference to sets. The evaluation took the form of an experiment to compare the output of our Coherence Model with the family of algorit</context>
</contexts>
<marker>Dale, 1989</marker>
<rawString>Robert Dale. 1989. Cooking up referring expressions. In Proc. 27th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gardent</author>
</authors>
<title>Generating minimal definite descriptions.</title>
<date>2002</date>
<booktitle>In Proc. 40th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1154" citStr="Gardent, 2002" startWordPosition="166" endWordPosition="167">design of the algorithm is motivated by the results of psycholinguistic experiments. 1 Introduction Algorithms for the Generation of Referring Expressions (GRE) seek a set of properties that distinguish an intended referent from its distractors in a knowledge base. Much of the GRE literature has focused on developing efficient content determination strategies that output the best available description according to some interpretation of the Gricean maxims (Dale and Reiter, 1995), especially Brevity. Work on reference to sets has also proceeded within this general framework (van Deemter, 2002; Gardent, 2002; Horacek, 2004). One problem that has not received much attention is that of conceptual coherence in the generation of plural references, i.e. the ascription of related properties to elements of a set, so that the resulting description constitutes a coherent cover for the plurality. As an example, consider a reference to {e1, e3} in Table 1 using the Incremental Algorithm (IA) (Dale and Reiter, 1995). IA searches along an ordered list of attributes, selecting properties of the intended referents that remove some distractors. Assuming the ordering in the top row, IA would yield the postgraduat</context>
</contexts>
<marker>Gardent, 2002</marker>
<rawString>C. Gardent. 2002. Generating minimal definite descriptions. In Proc. 40th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gatt</author>
<author>K van Deemter</author>
</authors>
<title>Semantic similarity and the generation of referring expressions: A first report.</title>
<date>2005</date>
<booktitle>In Proceedings of the 6th International Workshop on Computational Semantics, IWCS-6.</booktitle>
<marker>Gatt, van Deemter, 2005</marker>
<rawString>A. Gatt and K. van Deemter. 2005. Semantic similarity and the generation of referring expressions: A first report. In Proceedings of the 6th International Workshop on Computational Semantics, IWCS-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gatt</author>
</authors>
<title>Structuring knowledge for reference generation: A clustering algorithm.</title>
<date>2006</date>
<booktitle>In Proc. 11th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="19131" citStr="Gatt (2006)" startWordPosition="3229" endWordPosition="3230">lify by assuming a one-to-one mapping between properties and words. Another requirement is to distinguish between type properties (the set T), and non-types (M)3. The Thesaurus is used to find pairwise similarity of types in order to group them into related clusters. Word Sketches are used to find, for each type, the modifiers in the KB that are appropriate to the type, on the basis of the associated salience values. For example, in Table 3, e3 has plump as the value for girth, which combines more felicitously with man, than with biologist. Types are clustered using the algorithm described in Gatt (2006). For each type t, the algorithm finds its nearest neighbour nt in semantic space. Clusters are then found by recursively grouping elements with their nearest neighbours. If t, t′ have a common nearest neighbour n, then It, t′, n} is a cluster. Clearly, the resulting sets are convex in the sense of Definition 1. Each modifier is assigned to a cluster by finding in its Word Sketch the type with which it co-occurs with the greatest salience value. Thus, a cluster is a pair 3This is determined using corpus-derived information. Note that T and M need not be disjoint, and entities can have more tha</context>
</contexts>
<marker>Gatt, 2006</marker>
<rawString>A. Gatt. 2006. Structuring knowledge for reference generation: A clustering algorithm. In Proc. 11th Conference of the European Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Horacek</author>
</authors>
<title>On referring to sets of objects naturally.</title>
<date>2004</date>
<booktitle>In Proc. 3rd International Conference on Natural Language Generation.</booktitle>
<contexts>
<context position="1170" citStr="Horacek, 2004" startWordPosition="168" endWordPosition="169">lgorithm is motivated by the results of psycholinguistic experiments. 1 Introduction Algorithms for the Generation of Referring Expressions (GRE) seek a set of properties that distinguish an intended referent from its distractors in a knowledge base. Much of the GRE literature has focused on developing efficient content determination strategies that output the best available description according to some interpretation of the Gricean maxims (Dale and Reiter, 1995), especially Brevity. Work on reference to sets has also proceeded within this general framework (van Deemter, 2002; Gardent, 2002; Horacek, 2004). One problem that has not received much attention is that of conceptual coherence in the generation of plural references, i.e. the ascription of related properties to elements of a set, so that the resulting description constitutes a coherent cover for the plurality. As an example, consider a reference to {e1, e3} in Table 1 using the Incremental Algorithm (IA) (Dale and Reiter, 1995). IA searches along an ordered list of attributes, selecting properties of the intended referents that remove some distractors. Assuming the ordering in the top row, IA would yield the postgraduate and the chef, </context>
</contexts>
<marker>Horacek, 2004</marker>
<rawString>H. Horacek. 2004. On referring to sets of objects naturally. In Proc. 3rd International Conference on Natural Language Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Jordan</author>
</authors>
<title>Can nominal expressions achieve multiple goals?</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<marker>Jordan, 2000</marker>
<rawString>P. W. Jordan. 2000. Can nominal expressions achieve multiple goals? In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Kaup</author>
<author>S Kelter</author>
<author>C Habel</author>
</authors>
<title>Representing referents ofplural expressions and resolving plural anaphors. Language and Cognitive Processes,</title>
<date>2002</date>
<contexts>
<context position="4496" citStr="Kaup et al., 2002" startWordPosition="709" endWordPosition="712">gs (§3) which seeks to find the most coherent description available in a domain according to CC. 2 Empirical evidence We take as paradigmatic the case where a plural reference involves disjunction/union, that is, has the logical form Ax (p(x) V q(x)), realised as a description of the form the N1 and the N2. By hypothesis, the case where all referents can be described using identical properties (logically, a conjunction), is a limiting case of CC. Previous work on plural anaphor processing has shown that pronoun resolution is easier when antecedents are ontologically similar (e.g. all humans) (Kaup et al., 2002; Koh and Clifton, 2002). Reference to a heterogeneous set increases processing difficulty. Our experiments extended these findings to full definite NP reference. Throughout, we used a distributional definition of similarity, as defined by Lin (1998), which was found to be highly correlated to people’s preferences for disjunctive descriptions (Gatt and van Deemter, 2005). The similarity of two arbitrary objects a and b is a function of the information gained by giving a joint description of a and b in terms of what they have in common, compared to describing a and b separately. The relevant da</context>
</contexts>
<marker>Kaup, Kelter, Habel, 2002</marker>
<rawString>B. Kaup, S. Kelter, and C. Habel. 2002. Representing referents ofplural expressions and resolving plural anaphors. Language and Cognitive Processes, 17(4):405–450.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>Thesauruses for natural language processing.</title>
<date>2003</date>
<booktitle>In Proc. NLP-KE,</booktitle>
<location>Beijing.</location>
<contexts>
<context position="6550" citStr="Kilgarriff, 2003" startWordPosition="1062" endWordPosition="1063"> information gain in a description of their common data. Rather than using a hand-crafted ontology to infer similarity, this definition looks at real language Condition a b c distractor HDS spanner chisel plug thimble LDS toothbrush knife ashtray clock Figure 1: Conditions in Experiment 1 use. It covers ontological similarity to the extent that ontologically similar objects are talked about in the same contexts, but also cuts across ontological distinctions (for example newspaper and journalist might turn out to be very similar). We use the information contained in the SketchEngine database1 (Kilgarriff, 2003), a largescale implementation of Lin’s theory based on the BNC, which contains grammatical triples in the form of Word Sketches for each word, with each triple accompanied by a salience value indicating the likelihood of occurrence of the word with its argument in a grammatical relation. Each word also has a thesaurus entry, containing a ranked list of words of the same category, ordered by their similarity to the head word. 2.1 Experiment 1 In Experiment 1, participants were placed in a situation where they were buying objects from an online store. They saw scenarios containing four pictures </context>
</contexts>
<marker>Kilgarriff, 2003</marker>
<rawString>A. Kilgarriff. 2003. Thesauruses for natural language processing. In Proc. NLP-KE, Beijing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Koh</author>
<author>C Clifton</author>
</authors>
<title>Resolution of the antecedent of a plural pronoun: Ontological categories and predicate symmetry.</title>
<date>2002</date>
<journal>Journal of Memory and Language,</journal>
<pages>46--830</pages>
<contexts>
<context position="4520" citStr="Koh and Clifton, 2002" startWordPosition="713" endWordPosition="716"> to find the most coherent description available in a domain according to CC. 2 Empirical evidence We take as paradigmatic the case where a plural reference involves disjunction/union, that is, has the logical form Ax (p(x) V q(x)), realised as a description of the form the N1 and the N2. By hypothesis, the case where all referents can be described using identical properties (logically, a conjunction), is a limiting case of CC. Previous work on plural anaphor processing has shown that pronoun resolution is easier when antecedents are ontologically similar (e.g. all humans) (Kaup et al., 2002; Koh and Clifton, 2002). Reference to a heterogeneous set increases processing difficulty. Our experiments extended these findings to full definite NP reference. Throughout, we used a distributional definition of similarity, as defined by Lin (1998), which was found to be highly correlated to people’s preferences for disjunctive descriptions (Gatt and van Deemter, 2005). The similarity of two arbitrary objects a and b is a function of the information gained by giving a joint description of a and b in terms of what they have in common, compared to describing a and b separately. The relevant data in the lexical domain</context>
</contexts>
<marker>Koh, Clifton, 2002</marker>
<rawString>S. Koh and C. Clifton. 2002. Resolution of the antecedent of a plural pronoun: Ontological categories and predicate symmetry. Journal of Memory and Language, 46:830–844.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kronfeld</author>
</authors>
<title>Conversationally relevant descriptions.</title>
<date>1989</date>
<booktitle>In Proc. 27th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2616" citStr="Kronfeld (1989)" startWordPosition="404" endWordPosition="406">ave in common. type occupation nationality e1 man postgraduate maltese e2 man undergraduate greek eg man chef italian Table 1: Example domain Such examples lead us to hypothesise the following constraint: Conceptual Coherence Constraint (CC): As far as possible, describe objects using related properties. Related issues have been raised in the formal semantics literature. Aloni (2002) argues that an appropriate answer to a question of the form ‘Wh x?’ must conceptualise the different instantiations of x using a perspective which is relevant given the hearer’s information state and the context. Kronfeld (1989) distinguishes a description’s functional relevance – i.e. its success in distinguishing a referent – from its conversational relevance, which arises in part from implicatures. In our example, describing e1 as the postgraduate carries the implicature that the entity’s academic role is relevant. When two entities are described using contrasting properties, say the student and the italian, the contrast may be misleading for the listener. Any attempt to port these observations to the GRE scenario must do so without sacrificing logical completeness. While a GRE algorithm should attempt to find the</context>
</contexts>
<marker>Kronfeld, 1989</marker>
<rawString>A. Kronfeld. 1989. Conversationally relevant descriptions. In Proc. 27th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lapata</author>
<author>S McDonald</author>
<author>F Keller</author>
</authors>
<title>Determinants of adjective-noun plausibility.</title>
<date>1999</date>
<booktitle>In Proc. 9th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="15724" citStr="Lapata et al., 1999" startWordPosition="2649" endWordPosition="2652">ccurrence in the same linguistic contexts directly reflects the extent to which two types can be mapped to a single plural role. As regards modifiers, while it is probably premature to suggest that CC plays no role in modifier selection, it is likely that modifiers play a different role from nouns. Previous work has shown that id base type occupation specialisation girth e1 woman professor physicist plump e2 woman lecturer geologist thin eg man lecturer biologist plump eq man chemist thin Table 2: An example knowledge base restrictions on the plausibility of adjective-noun combinations exist (Lapata et al., 1999), and that using unlikely combinations (e.g. the immaculate kitchen rather than the spotless kitchen) impacts processing in online tasks (Murphy, 1984). Unlike types, which have a categorisation function, modifiers have the role of adding information about an element of a category. This would partially explain the experimental results: When elements of a plurality have identical types (as in the modifier version of our experiment), the CC is already satisfied, and selection of modifiers would presumably depend on respecting adjective-noun combination restrictions. Further research is required </context>
</contexts>
<marker>Lapata, McDonald, Keller, 1999</marker>
<rawString>M. Lapata, S. McDonald, and F. Keller. 1999. Determinants of adjective-noun plausibility. In Proc. 9th Conference of the European Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In Proc. International Conference on Machine Learning.</booktitle>
<contexts>
<context position="4746" citStr="Lin (1998)" startWordPosition="748" endWordPosition="749">sed as a description of the form the N1 and the N2. By hypothesis, the case where all referents can be described using identical properties (logically, a conjunction), is a limiting case of CC. Previous work on plural anaphor processing has shown that pronoun resolution is easier when antecedents are ontologically similar (e.g. all humans) (Kaup et al., 2002; Koh and Clifton, 2002). Reference to a heterogeneous set increases processing difficulty. Our experiments extended these findings to full definite NP reference. Throughout, we used a distributional definition of similarity, as defined by Lin (1998), which was found to be highly correlated to people’s preferences for disjunctive descriptions (Gatt and van Deemter, 2005). The similarity of two arbitrary objects a and b is a function of the information gained by giving a joint description of a and b in terms of what they have in common, compared to describing a and b separately. The relevant data in the lexical domain is the grammatical environment in which words occur. This information is represented as a set of triples (rel, w, w′), where rel is a grammatical relation, w the word of interest and w′ its co-argument in rel (e.g. (premodifi</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. An information-theoretic definition of similarity. In Proc. International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Moxey</author>
<author>A Sanford</author>
</authors>
<title>Notes on plural reference and the scenario-mapping principle in comprehension.</title>
<date>1995</date>
<booktitle>In C.Habel and G.Rickheit, editors, Focus and cohesion in discourse. de Gruyter,</booktitle>
<location>Berlin.</location>
<contexts>
<context position="14697" citStr="Moxey and Sanford (1995)" startWordPosition="2474" endWordPosition="2477">ely to conform to the CC, but that the CC operates mainly on nouns, and less so on (adjectival) modifiers. Nouns (or types, as we shall sometimes call them) have the function of categorising objects; thus similar types facilitate the mental representation of a plurality in a conceptually coherent way. According to the definition in (1), this is because similarity of two types implies a greater likelihood of their being used in the same predicate-argument structures. As a result, it is easier to map the elements of a plurality to a common role in a sentence. A related proposal has been made by Moxey and Sanford (1995), whose Scenario Mapping Principle holds that a plural reference is licensed to the extent that the elements of the plurality can be mapped to a common role in the discourse. This is influenced by how easy it is to conceive of such a role for the referents. Our results can be viewed as providing a handle on the notion of ‘ease of conception of a common role’; in particular we propose that likelihood of occurrence in the same linguistic contexts directly reflects the extent to which two types can be mapped to a single plural role. As regards modifiers, while it is probably premature to suggest </context>
</contexts>
<marker>Moxey, Sanford, 1995</marker>
<rawString>L. Moxey and A. Sanford. 1995. Notes on plural reference and the scenario-mapping principle in comprehension. In C.Habel and G.Rickheit, editors, Focus and cohesion in discourse. de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G L Murphy</author>
</authors>
<title>Establishing and accessing referents in discourse.</title>
<date>1984</date>
<journal>Memory and Cognition,</journal>
<volume>12</volume>
<pages>497</pages>
<contexts>
<context position="15875" citStr="Murphy, 1984" startWordPosition="2672" endWordPosition="2673">t is probably premature to suggest that CC plays no role in modifier selection, it is likely that modifiers play a different role from nouns. Previous work has shown that id base type occupation specialisation girth e1 woman professor physicist plump e2 woman lecturer geologist thin eg man lecturer biologist plump eq man chemist thin Table 2: An example knowledge base restrictions on the plausibility of adjective-noun combinations exist (Lapata et al., 1999), and that using unlikely combinations (e.g. the immaculate kitchen rather than the spotless kitchen) impacts processing in online tasks (Murphy, 1984). Unlike types, which have a categorisation function, modifiers have the role of adding information about an element of a category. This would partially explain the experimental results: When elements of a plurality have identical types (as in the modifier version of our experiment), the CC is already satisfied, and selection of modifiers would presumably depend on respecting adjective-noun combination restrictions. Further research is required to verify this, although the algorithm presented below makes use of the Sketch Engine database to take modifier-noun combinations into account. 3 An al</context>
</contexts>
<marker>Murphy, 1984</marker>
<rawString>G.L. Murphy. 1984. Establishing and accessing referents in discourse. Memory and Cognition, 12:489– 497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Siddharthan</author>
<author>A Copestake</author>
</authors>
<title>Generating referring expressions in open domains.</title>
<date>2004</date>
<booktitle>In Proc. 42nd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="30854" citStr="Siddharthan and Copestake (2004)" startWordPosition="5269" endWordPosition="5272"> to minimise the semantic distance between the perspectives repre261 sented in a description. The evaluation strongly supports our Coherence Model. We are extending this work in two directions. First, we are investigating similarity effects across noun phrases, and their impact on text readability. Finding an impact of such factors would make this model a useful complement to current theories of discourse, which usually interpret coherence in terms of discourse/sentential structure. Second, we intend to relinquish the assumption of a one-to-one correspondence between properties and words (cf. Siddharthan and Copestake (2004)), making use of the fact that words can be disambiguated by nearby words that are similar. To use a well-worn example: the ‘financial institution’ sense of bank might not make the river and its bank lexically incoherent as a description of a piece of scenery, since the word river might cause the hearer to focus on the aquatic reading of the word anyway. 6 Acknowledgements Thanks to Ielka van der Sluis, Imtiaz Khan, Ehud Reiter, Chris Mellish, Graeme Ritchie and Judith Masthoff for useful comments. This work is part of the TUNA project (http://www.csd.abdn.ac.uk/ research/tuna), supported by E</context>
</contexts>
<marker>Siddharthan, Copestake, 2004</marker>
<rawString>A. Siddharthan and A. Copestake. 2004. Generating referring expressions in open domains. In Proc. 42nd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K van Deemter</author>
</authors>
<title>Generating referring expressions: Boolean extensions of the incremental algorithm.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>1</issue>
<marker>van Deemter, 2002</marker>
<rawString>K. van Deemter. 2002. Generating referring expressions: Boolean extensions of the incremental algorithm. Computational Linguistics, 28(1):37–52.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>