<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004002">
<title confidence="0.999368">
A method for the approximation of incremental understanding of explicit
utterance meaning using predictive models in finite domains
</title>
<author confidence="0.996563">
David DeVault and David Traum
</author>
<affiliation confidence="0.989619">
Institute for Creative Technologies, University of Southern California,
</affiliation>
<address confidence="0.955322">
12015 Waterfront Dr., Playa Vista, CA 90094 USA
</address>
<email confidence="0.999606">
{devault,traum}@ict.usc.edu
</email>
<sectionHeader confidence="0.995653" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999674272727273">
This paper explores the relationship between explicit
and predictive models of incremental speech under-
standing in a dialogue system that supports a finite
set of user utterance meanings. We present a method
that enables the approximation of explicit under-
standing using information implicit in a predictive
understanding model for the same domain. We show
promising performance for this method in a corpus
evaluation, and discuss its practical application and
annotation costs in relation to some alternative ap-
proaches.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999975766666667">
In recent years, there has been a growing interest among
researchers in methods for incremental natural language
understanding (NLU) for spoken dialogue systems; see
e.g. (Skantze and Schlangen, 2009; Sagae et al., 2009;
Schlangen et al., 2009; Heintze et al., 2010; DeVault et
al., 2011a; Selfridge et al., 2012). This work has gen-
erally been motivated by a desire to make dialogue sys-
tems more efficient and more natural, by enabling them to
provide lower latency responses (Skantze and Schlangen,
2009), human-like feedback such as backchannels that in-
dicate how well the system is understanding user speech
(DeVault et al., 2011b; Traum et al., 2012), and more in-
teractive response capabilities such as collaborative com-
pletions of user utterances (DeVault et al., 2011a), more
adaptive handling of interruptions (Buschmeier et al.,
2012), and others.
This paper builds on techniques developed in previous
work that has adopted a predictive approach to incremen-
tal NLU (DeVault et al., 2011a). On this approach, at
specific moments while a user’s speech is in progress,
an attempt is made to predict what the full meaning of
the complete user utterance will be. Predictive models
can be contrasted with explicit approaches to incremen-
tal NLU. We use the term explicit understanding to refer
to approaches that attempt to determine the meaning that
has been expressed explicitly in the user’s partial utter-
ance so far (without predicting further aspects of mean-
ing to come). Explicit understanding of partial utterances
can be implemented using statistical classification or se-
quential tagging models (Heintze et al., 2010).
Both predictive and explicit incremental NLU capabil-
ities can be valuable in a dialogue system. Prediction
can support specific response capabilities, such as sys-
tem completion of user utterances (DeVault et al., 2011a)
and reduced response latency.1 However, explicit models
support additional and complementary capabilities. For
instance, depending on the application domain (Heintze
et al., 2010) and on the individual utterance (DeVault et
al., 2011b), it may be difficult for a system to predict a
user’s impending meaning with confidence. Neverthe-
less, it may often be possible for systems to determine
the meaning of what a user has said so far, and to take
action based on this partial understanding. As one exam-
ple, items in a user interface could be highlighted when
mentioned by a user (Buß and Schlangen, 2011). An-
other capability would be to provide grounding feedback,
such as verbal back-channels or head nods (in embod-
ied systems), to indicate when the system is understand-
ing the user’s meaning (Traum et al., 2012). Explicit ut-
terance meanings also allow a system to distinguish be-
tween meaning that has been expressed and meaning that
is merely implied or inferred, which may be less reliable.
In the near future, as incremental processing capabilities
in dialogue systems grow, it may prove valuable for di-
alogue systems to combine both predictive and explicit
incremental understanding capabilities.
In this paper, we present a technique for approximating
a user’s explicit meaning using an existing predictive un-
derstanding framework (DeVault et al., 2011a). The spe-
cific new contributions in this paper are (1) to show that
</bodyText>
<footnote confidence="0.990322">
1A simple approach to reducing response latency is to begin to plan
a response to the predicted meaning while the user is still speaking.
</footnote>
<page confidence="0.964879">
1092
</page>
<note confidence="0.473199">
Proceedings of NAACL-HLT 2013, pages 1092–1099,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999810692307692">
an estimate of a user’s explicit utterance meaning can be
derived from this kind of predictive understanding model
(Section 2); (2) to quantify the performance of this new
method in a corpus evaluation (Section 3); (3) to provide
concrete examples and discussion of the annotation costs
associated with implementing this technique, in relation
to some alternative approaches to explicit understanding
(Section 4). Our results and discussion show that the
proposed method offers promising performance, has rela-
tively low annotation costs, and enables explicit and pre-
dictive understanding to be easily combined within a di-
alogue system. It may therefore be a useful incremental
understanding technique for some dialogue systems.
</bodyText>
<subsectionHeader confidence="0.537995">
2 Technical Approach and Data Set
</subsectionHeader>
<bodyText confidence="0.9997962">
In Sections 2.1-2.3, we briefly summarize the data set and
approach to predictive incremental NLU (DeVault et al.,
2011a) that serves as the starting point for the new work
in this paper. Sections 2.4 and 2.5 present our new ap-
proach to explicit understanding based on this approach.
</bodyText>
<subsectionHeader confidence="0.992558">
2.1 Data set
</subsectionHeader>
<bodyText confidence="0.998357740740741">
For the experiments reported here, we use a corpus of
user utterances collected with the SASO-EN spoken dia-
logue system (Hartholt et al., 2008; Traum et al., 2008).
Briefly, this system is designed to allow a trainee to prac-
tice multi-party negotiation skills by engaging in face to
face negotiation with virtual humans. The scenario in-
volves a negotiation about the possible re-location of a
medical clinic in an Iraqi village. A human trainee plays
the role of a US Army captain, and there are two virtual
humans that he negotiates with: Doctor Perez, the head
of an NGO clinic, and a local village elder, al-Hassan.
The captain’s main objective is to convince the doctor and
the elder to move the clinic out of an unsafe marketplace
area.
The corpus used for the experiments in this paper in-
cludes 3,826 training and 449 testing utterances drawn
from user dialogues in this domain. The corpus and its se-
mantic annotation are described in (DeVault et al., 2010;
DeVault et al., 2011a). All user utterances have been au-
dio recorded, transcribed, and manually annotated with
the correct NLU output frame for the entire utterance.
(We discuss the cost of this annotation in Section 4.) Each
NLU output frame contains a set of attributes and values
that represent semantic information linked to a domain-
specific ontology and task model (Traum, 2003). Exam-
ples of the NLU output frames are included in Figures 2,
3, and 5.
</bodyText>
<subsectionHeader confidence="0.997165">
2.2 Predictive incremental NLU
</subsectionHeader>
<bodyText confidence="0.99839875">
This approach uses a predictive incremental NLU mod-
ule, mxNLU (Sagae et al., 2009; DeVault et al., 2011a),
which is based on maximum entropy classification. The
approach treats entire individual frames as output classes,
and extracts input features from partial ASR results. To
define the incremental understanding problem, the audio
of the utterances in the training data were fed through
an ASR module, PocketSphinx (Huggins-Daines et al.,
2006), in 200 millisecond chunks, and each partial ASR
result produced by the ASR was recorded. Each par-
tial ASR result then serves as an incremental input to
mxNLU. NLU is predictive in the sense that, for each
partial ASR result, the task of mxNLU is to produce as
output the complete frame that has been associated by a
human annotator with the user’s complete utterance, even
if that utterance has not yet been fully processed by the
ASR.
The human annotation defines a finite set S =
{S1, ..., SN} of possible NLU output frames, where each
frame Si = {e1, ..., e,,,} is a set of key-value pairs or
frame elements. For notation, a user utterance u generally
creates a sequence of m partial ASR results (r1, ..., r.),
where each ASR result rj is a partial text such as we need
to move. Let G,,, denote the correct (or “gold”) frame for
the complete utterance u. For each result rj and for each
complete frame Si, the maximum entropy model pro-
vides P(G,,, = Si|rj). The NLU output frame SNLU jis
the complete frame for which this probability is highest.
</bodyText>
<subsectionHeader confidence="0.999612">
2.3 Performance of predictive incremental NLU
</subsectionHeader>
<bodyText confidence="0.999887071428572">
The performance of this predictive incremental NLU
framework has been evaluated using the training and
test portions of the SASO-EN data set described in Sec-
tion 2.1. Performance is quantified by looking at pre-
cision, recall, and F-score of the frame elements that
compose the predicted (SNLU
j ) and correct (GJ frames
for each partial ASR result. When evaluated over all
the 5,736 partial ASR results for the 449 test utterances,
the precision/recall/F-Score of this predictive NLU, in
relation to the complete frames, are 0.67/0.47/0.56, re-
spectively. When evaluated on only the ASR results
for complete test utterances, these scores increase to
0.81/0.71/0.76, respectively.
</bodyText>
<subsectionHeader confidence="0.999454">
2.4 Assigning probability to frame elements
</subsectionHeader>
<bodyText confidence="0.99897775">
An interesting question is whether we can use this model
to attach useful probabilities not only to complete pre-
dicted frames but also to the individual frame elements
that make up those frames. To explore this, for each par-
tial ASR result rj in each utterance u, and for each frame
element e in SASO-EN, let us model the probability that
e will be part of the correct frame for the complete utter-
ance as:
</bodyText>
<equation confidence="0.938407">
P(e � G�|rj) = � P(G. = Si|rj) (1)
Si:eESi
</equation>
<page confidence="0.957286">
1093
</page>
<figure confidence="0.997418">
1.0
0.9
Relative frequency of frame element in correct frame
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
0.00 0.10 0.20 0.30 0.40 0.50 0.60 0.70 0.80 0.90 1.00
Probability assigned to frame element
</figure>
<figureCaption confidence="0.999877">
Figure 1: Calibration of frame element probabilities.
</figureCaption>
<figure confidence="0.999743384615385">
Model calibration (left axis)
Perfect calibration (left axis)
Relative frequency of
assigned probabilities
(right axis)
0.7 Relative frequency of probability being assigned to a frame element
0.6
0.5
0.4
0.3
0.2
0.1
0
</figure>
<bodyText confidence="0.99996892">
This method derives the probability of frame elements
from the probabilities assigned to the possible frames that
contain them. Computing this sum is straightforward in a
finite semantic domain such as SASO-EN.
We computed this probability for all frame elements
e and all partial ASR results rj in our test set, yielding
approximately 478,000 probability values. We grouped
these probability values into bins of size 0.05, and cal-
culated the frequency with which the frame elements in
each bin were indeed present in the correct frame Gu for
the relevant utterance u. The results are presented in Fig-
ure 1, which shows that the probability values derived
from Equation (1) are relatively “well calibrated”, in the
sense that the relative frequency with which a frame el-
ement is in the final frame is very close to the numeric
probability assigned by Equation (1). The figure also
shows how frequently the model assigns various proba-
bility ranges to frame elements (blue dotted line, plotted
against the secondary right axis). Note that most frame
elements are assigned very little probability for most par-
tial ASR results.
We conclude from these observations that the probabil-
ities assigned by (1) could indeed carry useful informa-
tion about the likelihood that individual key values will
be present in the complete utterance meaning.
</bodyText>
<subsectionHeader confidence="0.999247">
2.5 Selecting probable frame elements
</subsectionHeader>
<bodyText confidence="0.999887166666667">
In exploring the model of frame element probabilities
given in Equation (1), we observed that often the reason
a frame element has lower probability, at a given point
within a user utterance, is that it is a prediction rather than
something that has been expressed explicitly. Building on
this observation, our technique for estimating the user’s
explicit meaning uses a probability threshold to select
those individual frame elements which are most likely to
be in the frame for a complete utterance, according to the
predictive model. That is, at each partial result rj, we
estimate the user’s explicit meaning using a constructed
frame:
</bodyText>
<equation confidence="0.923826">
S�UB
j = {e|P(e E Gu|rj) &gt; T} (2)
</equation>
<bodyText confidence="0.999950111111111">
This approximation could work well if, in practice, the
most probable frame elements prove to match fairly
closely the user’s non-incremental utterance meaning at
the point this frame is constructed. We evaluate this in
the next section.
Note that, in general, the returned subset of frame
elements may not be identical to any complete frame
Si E S; rather it will correspond to parts of these com-
plete frames or “subframes”.
</bodyText>
<sectionHeader confidence="0.989089" genericHeader="introduction">
3 Performance Evaluation
</sectionHeader>
<bodyText confidence="0.999878">
To evaluate this technique, we constructed subsets of
frame elements or “explicit subframes” using Equation
(2) and various minimum probability thresholds T for par-
tial ASR results in our test set. We then compared the
resulting subframes both to the final complete frame Gu
for each utterance u, and also to manually annotated sub-
</bodyText>
<page confidence="0.966409">
1094
</page>
<table confidence="0.887476142857143">
Explicit subframe (with frame element probabilities) Predicted complete frame Annotated subframe
Partial ASR result: hello
0.813 &lt;S&gt;.sem.speechact.type greeting &lt;S&gt;.sem.speechact.type greeting &lt;S&gt;.sem.speechact.type greeting
&lt;S&gt;.addressee doctor-perez
Partial ASR result: hello elder
0.945 &lt;S&gt;.sem.speechact.type greeting &lt;S&gt;.sem.speechact.type greeting &lt;S&gt;.sem.speechact.type greeting
0.934 &lt;S&gt;.addressee elder-al-hassan &lt;S&gt;.addressee elder-al-hassan &lt;S&gt;.addressee elder-al-hassan
</table>
<figureCaption confidence="0.979703">
Figure 2: Explicit subframes and predicted complete frames for two partial ASR results in a user utterance of hello elder.
</figureCaption>
<bodyText confidence="0.991977764705882">
frames that represent human judgments of explicit incre-
mental utterance meaning.
To collect these judgments, we hand-annotated a word-
meaning alignment for 50 random utterances in our test
set.2 To perform this annotation, successively larger pre-
fixes of each utterance transcript were mapped to succes-
sively larger subframes of the full frame for the complete
utterance. The annotated subframes for each utterance
prefix were selected to be explicit; they include only those
frame elements that are explicitly expressed in the corre-
sponding prefix of the user’s utterance. (We discuss the
cost of this annotation in Section 4.)
We provide a simple concrete example in Figure 2.
This example shows two partial ASR results during
an utterance of hello elder by a user. For each par-
tial ASR result, three frames are indicated horizon-
tally. At the right, labeled “Annotated subframe”, we
show the human judgment of explicit incremental ut-
terance meaning for this partial utterance. Our hu-
man judge has indicated that the word hello corresponds
to the frame element &lt;S&gt;.sem.speechact.type
greeting, and that the words hello elder correspond
to an expanded frame that includes the frame element
&lt;S&gt;.addressee elder-al-hassan.
At the left, labeled “Explicit subframe”, we show
the subframe selected by Equation (2) for each par-
tial ASR result, with threshold T = 0.5. A relevant
background fact for this example is that in this sce-
nario, the user can generally address either of two vir-
tual humans who are present, Doctor Perez or Elder
Al-Hassan. After the user has said hello, the frame
element &lt;S&gt;.sem.speechact.type greetingis
assigned probability 0.813 by Equation (1), and only this
frame element appears in the explicit subframe.
In the middle, labeled “Predicted complete frame”, the
figure also shows the full predicted frame from mxNLU
at each point. After the user has said hello, the full
predicted output includes an additional frame element,
&lt;S&gt;.addressee doctor-perez, indicating a pre-
diction that the addressee of this user utterance will be
Doctor Perez rather than Elder al-Hassan. However, the
2Note that no utterances in our training set were annotated.
probability assigned to this prediction by Equation (1) is
less than 0.5, and so this predicted frame element is ex-
cluded from the explicit subframe. And indeed, this is the
correct explicit representation of the meaning of hello in
this system.
This simple example illustrates how our proposed tech-
nique can enable a dialogue system to have access to both
explicit and predicted utterance meaning as a user’s ut-
terance progresses. An excerpt from a more complex
utterance is given in Figure 3. This example shows in-
cremental outputs for two partial ASR results during a
user utterance of we will provide transportation at no
cost. In this example, the explicit subframe for we
will includes frame elements that convey that the cap-
tain (i.e. the user) is promising to do something. This
subframe does not exactly match the human judgment
of explicit meaning at the right, which does not include
at this point the &lt;S&gt;.sem.agent captain-kirk
and &lt;S&gt;.sem.type event frame elements. How-
ever, the explicit subframe more closely matches the hu-
man judgment than does the predicted complete frame
from mxNLU (middle column), which includes an in-
correct prediction that the captain is promising to de-
liver medical supplies (represented by the key values
&lt;S&gt;.sem.event deliver and &lt;S&gt;.sem.theme
medical-supplies). For the next partial ASR re-
sult shown in the figure, the explicit subframe correctly
adds several additional frame elements which formalize
the meaning of the phrase provide transportation in this
scenario as having the army move the clinic out of the
market area.
To understand more quantitatively how well this tech-
nique works, we evaluated this technique in the SASO-
EN test corpus, using different probability thresholds in
the range [0.5,1.0). We present the results in Figure 4. To
understand the effect of the threshold T, note that, in gen-
eral, the effect of selecting a higher threshold should be to
“cherry pick” those frame elements which are most likely
to appear in the complete frame G,,,, thereby increasing
precision while decreasing recall of the frame elements in
��&amp;quot;&apos;
� in relation to G,,,. In the figure, we can see that this
is indeed the case. The lines marked “(complete frame)”
</bodyText>
<page confidence="0.881423">
1095
</page>
<table confidence="0.964437315789474">
Explicit subframe (with frame element probabilities) Predicted complete frame Annotated subframe
Partial ASR result: we will
0.856 &lt;S&gt;.mood declarative &lt;S&gt;.mood declarative &lt;S&gt;.mood declarative
0.824 &lt;S&gt;.sem.agent captain-kirk &lt;S&gt;.sem.agent captain-kirk &lt;S&gt;.sem.modal.intention will
0.663 &lt;S&gt;.sem.modal.intention will &lt;S&gt;.sem.event deliver &lt;S&gt;.sem.speechact.type promise
0.663 &lt;S&gt;.sem.speechact.type promise &lt;S&gt;.sem.modal.intention will
0.776 &lt;S&gt;.sem.type event &lt;S&gt;.sem.speechact.type promise
&lt;S&gt;.sem.theme medical-supplies
&lt;S&gt;.sem.type event
Partial ASR result: we will provide transportation
0.991 &lt;S&gt;.mood declarative
0.990 &lt;S&gt;.sem.agent captain-kirk
0.927 &lt;S&gt;.sem.event move
0.905 &lt;S&gt;.sem.instrument us-army
0.964 &lt;S&gt;.sem.modal.intention will
0.927 &lt;S&gt;.sem.source market
0.964 &lt;S&gt;.sem.speechact.type promise
0.928 &lt;S&gt;.sem.theme clinic
0.989 &lt;S&gt;.sem.type event
</table>
<figure confidence="0.990441611111111">
&lt;S&gt;.mood declarative
&lt;S&gt;.sem.agent captain-kirk
&lt;S&gt;.sem.event move
&lt;S&gt;.sem.instrument us-army
&lt;S&gt;.sem.modal.intention will
&lt;S&gt;.sem.source market
&lt;S&gt;.sem.speechact.type promise
&lt;S&gt;.sem.theme clinic
&lt;S&gt;.sem.type event
&lt;S&gt;.mood declarative
&lt;S&gt;.sem.agent captain-kirk
&lt;S&gt;.sem.event move
&lt;S&gt;.sem.instrument us-army
&lt;S&gt;.sem.modal.intention will
&lt;S&gt;.sem.source market
&lt;S&gt;.sem.speechact.type promise
&lt;S&gt;.sem.theme clinic
&lt;S&gt;.sem.type event
</figure>
<figureCaption confidence="0.9962755">
Figure 3: Explicit subframes and predicted complete frames for two partial ASR results in a user utterance of we will provide
transportation at no cost.
</figureCaption>
<figure confidence="0.647836">
threshold
</figure>
<figureCaption confidence="0.9971345">
Figure 4: The effect of threshold on precision, recall, and F-Score of explicit subframes. All scores are measured in relation to
complete utterance frames and annotated subframes.
</figureCaption>
<figure confidence="0.97218625">
0.5 0.6 0.7 0.8 0.9 1.0
0.8
0.6
0.4
0.2
0.0
1.0
o
o
o
Precision (complete frame)
Precision (annotated subframe)
Recall (complete frame)
Recall (annotated subframe)
F−Score (complete frame)
F−Score (annotated subframe)
</figure>
<page confidence="0.98956">
1096
</page>
<bodyText confidence="0.995959532258065">
in the figure evaluate the returned subframes in relation
to the complete frame G,,, associated with the user’s com-
plete utterance. We see that this method enables us to
select subsets of frame elements that are most likely to
appear in G,,,: by increasing the threshold, it is possible
to return subframes which are of increasingly higher pre-
cision in relation to the final frame G,,,, but that also have
lower recall.
We also evaluated the returned subframes in relation to
the hand-annotated subframes, to assess its performance
at identifying the user’s explicit meaning. For an utter-
ance u that generates partial ASR results (r1, ..., r,..),
we denote the hand-annotated subframe corresponding to
partial ASR result rj by G�UB
j . In the lines marked “(an-
notated subframe)”, we show the precision, recall, and
F-score of the explicit subframe for each ASR result rj
in relation to the annotated subframe G�UB
j .
As a first observation, note that at any threshold level,
the explicit subframes do better at recalling the hand-
annotated subframe elements than they do at recalling the
complete frame elements. This means our new method is
better at recalling what has been said already by the user
than it is at predicting what will be said, as intended. We
have seen two examples of this already, for the partial
ASR result hello in Figure 2, and for the partial ASR re-
sult we will in Figure 3.
A second observation in Figure 4 is that precision re-
mains better against the complete utterance frame than
against the hand-annotated subframe (at all threshold lev-
els). This indicates that the explicit subframes are often
still predicting some aspects of the full frame. An exam-
ple of this is given in Figure 5, where the user’s partial
utterance we need to is assigned an explicit subframe that
includes frame elements describing an event of moving
the clinic, which the user has not said explicitly. This
happens because, in the SASO-EN domain, in fact there
is nothing else that the interlocutors need to do besides
move the clinic. So based on the NLU training data,
the data-driven probabilities assigned by Equation (1) de-
scribe the additional frame elements as about as probable
as the ones capturing the we need to part of the semantics
(given at the right).
Finally, a third observation is that overall, the preci-
sion, recall, and F-score results against the annotated sub-
frames using our method are surprisingly strong. For
example, when evaluating the explicit subframes over
all partial ASR results, an F-score of 0.75 is attained at
thresholds in the range 0.5-0.55. This F-score is sub-
stantially better than the F-score of our predictive NLU
in relation to the final full frames, which is 0.56 when
evaluated over all partial ASR results. This means that
our proposed model works better as an explicit incre-
mental NLU than mxNLU works as a predictive incre-
mental NLU. Further, we observe that this F-score of
0.75 against hand-annotated subframes is approximately
as good as the F-score of 0.76 that is achieved when
mxNLU is used to interpret complete utterances. We
therefore conclude that the proposed model is a promis-
ing and viable approach to explicit incremental NLU in
SASO-EN.
</bodyText>
<sectionHeader confidence="0.961404" genericHeader="related work">
4 Discussion and Related Approaches
</sectionHeader>
<bodyText confidence="0.999936413043478">
In this section, we discuss some of the practical aspects
of using the technique presented here, in relation to some
alternative approaches.
An important consideration for NLU techniques is the
cost, in both time and knowledge, of the annotation that
is needed. One attractive aspect of our technique is that
the only semantic annotation that is required is the asso-
ciation of complete user utterances with complete NLU
output frames. This task can be performed by anyone fa-
miliar with the scenario and the semantic frame format,
such as a system developer or scenario designer. In fact,
the annotation of the SASO-EN data set we use in this
paper has been described in (DeVault et al., 2010), which
reports that the overall corpus of 4678 token utterances
was semantically annotated at an average rate of about 10
seconds per unique utterance.
The model in Equation (2) is what (Heintze et al.,
2010) call a hybrid output approach, in which larger and
larger frames are provided as partial input grows, but
in which a detailed alignment between surface text and
frames is not provided by the incremental NLU compo-
nent. They contrast hybrid output systems with tech-
niques that deliver either whole-frame output (like the
predictive mxNLU) or aligned output that connects indi-
vidual words to their meanings. A data-driven approach
to providing aligned outputs would involve preparing
a more detailed annotated corpus that aligns individ-
ual words and surface expressions to their corresponding
frame elements. Given such a word-aligned corpus, one
could train several kinds of models to produce the aligned
outputs incrementally. One strategy would be to use a se-
quential tagging model such as a CRF to tag partial utter-
ances with the frame elements that capture their explicit
meaning, as in (Heintze et al., 2010).
Using a machine learning approach that models a
more detailed alignment between surface text and frames
would be one way to more cleanly separate explicit from
predictive aspects of meaning. Preparing the training data
for such models, however, would create additional an-
notation costs. As part of creating the annotated sub-
frames for the evaluation presented in Section 3, we mea-
sured the time requirement for such annotation of word-
meaning alignments at about 30 seconds per unique ut-
terance. Performing full word-meaning alignment there-
fore takes about three times as much time as the com-
plete utterance annotation needed for our technique. Ad-
</bodyText>
<page confidence="0.971926">
1097
</page>
<table confidence="0.997820833333333">
Explicit subframe (with frame element probabilities) Predicted complete frame Annotated subframe
Partial ASR result: we
0.753 &lt;S&gt;.mood declarative &lt;S&gt;.mood declarative
0.687 &lt;S&gt;.sem.agent captain-kirk &lt;S&gt;.sem.agent captain-kirk
0.692 &lt;S&gt;.sem.type event &lt;S&gt;.sem.event deliver
&lt;S&gt;.sem.modal.possibility can
&lt;S&gt;.sem.speechact.type offer
&lt;S&gt;.sem.theme medical-supplies
&lt;S&gt;.sem.type event
Partial ASR result: we need to
0.945 &lt;S&gt;.mood declarative &lt;S&gt;.mood declarative &lt;S&gt;.mood declarative
0.928 &lt;S&gt;.sem.agent captain-kirk &lt;S&gt;.sem.agent captain-kirk &lt;S&gt;.sem.modal.deontic must
0.900 &lt;S&gt;.sem.event move &lt;S&gt;.sem.event move &lt;S&gt;.sem.speechact.type statement
0.816 &lt;S&gt;.sem.modal.deontic must &lt;S&gt;.sem.modal.deontic must
0.900 &lt;S&gt;.sem.source market &lt;S&gt;.sem.source market
0.900 &lt;S&gt;.sem.speechact.type statement &lt;S&gt;.sem.speechact.type statement
0.906 &lt;S&gt;.sem.theme clinic &lt;S&gt;.sem.theme clinic
0.930 &lt;S&gt;.sem.type event &lt;S&gt;.sem.type event
</table>
<figureCaption confidence="0.9961085">
Figure 5: Explicit subframes and predicted complete frames for two partial ASR results in a user utterance of we need to move the
clinic.
</figureCaption>
<bodyText confidence="0.999992327586207">
ditionally, this task requires a greater degree of linguis-
tic knowledge and sophistication, as the annotator must
be able to segment the utterance and align specific sur-
face segments with potentially complex aspects of mean-
ing such as modality, polarity, speech act types, and
others. An example of the kinds of complexities that
arise is illustrated in Figure 3, where the relationship be-
tween specific words like “provide” and “transportation”
to frame elements like &lt;S&gt;.sem.event move and
&lt;S&gt;.sem.theme clinic is not transparent, even if
it is straightforward to mark the whole utterance as con-
veying that meaning in this domain. We have generally
found this alignment task challenging for people without
advanced linguistics training.
The reason we describe the method in this paper as an
approximation of explicit NLU is that, partly because it
is trained without detailed word-meaning alignments, it
can be expected to occasionally include some predictive
aspects of user utterance meaning. An example of this is
the method’s explicit subframe output for the phrase we
need to in Figure 5.
Another way to approximate explicit NLU would be
using the method (Heintze et al., 2010) call an ensem-
ble of classifiers; it involves training an individual clas-
sifier for each frame key. Like the method presented
here, an ensemble of classifiers can be easily trained to
predict those frame elements that will appear in the fi-
nal frame G,,, for each utterance. And like our method,
prediction with an ensemble of classifiers does not re-
quire detailed annotation of word-meaning alignment in
the training data. One difference is that, with our method,
by selecting an appropriate threshold, it is easy to enforce
certain consistency properties on subframe outputs. In an
ensemble of classifiers approach, there is no immediate
guarantee that the output frame constructed by the inde-
pendent classifiers will be internally consistent from the
standpoint of downstream system modules (Heintze et al.,
2010). For example, in the SASO-EN domain, an NLU
frame should not contain frame elements that mix aspects
of events and states in the SASO-EN ontology; e.g., the
frame element &lt;S&gt;.sem.type event should not co-
occur in an NLU output frame with the frame element
&lt;S&gt;.sem.object-id market (which would be ap-
propriate for a state frame but not for an event frame).
With the method proposed here, if we select a threshold
T that is greater than 0.5, and if none of the complete
NLU frames contain incompatible key values (which is
relatively easy to enforce as part of the annotation task),
then it will be mathematically impossible for two incom-
patible frame elements to be returned in a subframe.3
Ultimately, a classification method that is trained on
word-meaning aligned data and that uses additional tech-
niques to ensure that only valid, grammatical output
frames are produced could prove to be an attractive ap-
proach. In future work, we will explore such techniques,
and compare both their performance as well as their anno-
tation and development costs to the approximation tech-
nique presented here.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.962652111111111">
The analysis in this paper has explored a method of ap-
proximating explicit incremental NLU using predictive
3Suppose frame element ei is incompatible with ej, and that
P(ei E Gu|rj) &gt; 0.5. By stipulation, no complete frame S E S
such that ei E S will also contain ej. Since we know that the total
probability of all the frames containing ei must be greater than 0.5 in
order for ei to be selected, we can infer that the total probability of all
frames including ej must be less than 0.5, and thus that ej will not be
selected.
</bodyText>
<page confidence="0.983401">
1098
</page>
<bodyText confidence="0.999988111111111">
techniques in finite semantic domains. We have shown
that an estimate of a user’s explicit utterance meaning
can be derived from an existing predictive understand-
ing model in an example domain. We have quantified
the performance of this new method in a corpus evalu-
ation, showing that the method returns incremental ex-
plicit subframes with performance – as measured by pre-
cision, recall, and F-Score against hand-annotated sub-
frames – that is competitive with a current statistical,
data-driven approach for understanding complete spoken
utterances in the same domain. We have provided ex-
amples that illustrate its strengths and weaknesses, and
discussed the annotation costs associated with imple-
menting this technique in relation to some alternative ap-
proaches. The method requires no additional annotation
beyond what is needed for training an NLU module to
understand complete spoken utterances. (Hand annota-
tion of word-meaning alignment for a small number of
utterances may be performed in order to tune the se-
lected threshold and evaluate explicit understanding per-
formance.) The method provides a free parameter that
can be used to target the most advantageous levels of pre-
cision and recall for a particular dialogue system applica-
tion. In future work, we will explore additional machine
learning models that leverage richer training data, and in-
vestigate further the combination of explicit and predic-
tive techniques.
</bodyText>
<sectionHeader confidence="0.9982" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999971">
The project or effort described here has been sponsored
by the U.S. Army Research, Development, and Engi-
neering Command (RDECOM). Statements and opinions
expressed do not necessarily reflect the position or the
policy of the United States Government, and no official
endorsement should be inferred. This material is based
upon work supported by the National Science Founda-
tion under Grant No. IIS-1219253. Any opinions, find-
ings, and conclusions or recommendations expressed in
this material are those of the author(s) and do not neces-
sarily reflect the views of the National Science Founda-
tion.
</bodyText>
<sectionHeader confidence="0.999243" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999232797101449">
Hendrik Buschmeier, Timo Baumann, Benjamin Dosch, Ste-
fan Kopp, and David Schlangen. 2012. Combining incre-
mental language generation and incremental speech synthe-
sis for adaptive information presentation. In Proceedings of
the 13th Annual Meeting of the Special Interest Group on
Discourse and Dialogue, pages 295–303, Seoul, South Ko-
rea, July. Association for Computational Linguistics.
Okko Buß and David Schlangen. 2011. Dium - an incremental
dialogue manager that can produce self-corrections. In Pro-
ceedings of the 15th Workshop on the Semantics and Prag-
matics of Dialogue (SemDial).
David DeVault, Susan Robinson, and David Traum. 2010.
IORelator: A graphical user interface to enable rapid seman-
tic annotation for data-driven natural language understand-
ing. In Fifth Joint ISO-ACL/SIGSEM Workshop on Interop-
erable Semantic Annotation.
David DeVault, Kenji Sagae, and David Traum. 2011a. Incre-
mental interpretation and prediction of utterance meaning for
interactive dialogue. Dialogue &amp; Discourse, 2(1).
David DeVault, Kenji Sagae, and David R. Traum. 2011b. De-
tecting the status of a predictive incremental speech under-
standing model for real-time decision-making in a spoken
dialogue system. In Interspeech, pages 1021–1024.
Arno Hartholt, Thomas Russ, David Traum, Eduard Hovy,
and Susan Robinson. 2008. A common ground for vir-
tual humans: Using an ontology in a natural language ori-
ented virtual human architecture. In European Language
Resources Association (ELRA), editor, Proc. LREC, Mar-
rakech, Morocco, may.
Silvan Heintze, Timo Baumann, and David Schlangen. 2010.
Comparing local and sequential models for statistical incre-
mental natural language understanding. In The 11th Annual
Meeting of the Special Interest Group in Discourse and Dia-
logue (SIGDIAL 2010).
David Huggins-Daines, Mohit Kumar, Arthur Chan, Alan W.
Black, Mosur Ravishankar, and Alex I. Rudnicky. 2006.
Pocketsphinx: A free, real-time continuous speech recog-
nition system for hand-held devices. In Proceedings of
ICASSP.
Kenji Sagae, Gwen Christian, David DeVault, and David R.
Traum. 2009. Towards natural language understanding of
partial speech recognition results in dialogue systems. In
NAACL HLT.
David Schlangen, Timo Baumann, and Michaela Atterer. 2009.
Incremental reference resolution: The task, metrics for eval-
uation, and a bayesian filtering model that is sensitive to dis-
fluencies. In SIGDIAL.
Ethan O. Selfridge, Iker Arizmendi, Peter A. Heeman, and Ja-
son D. Williams. 2012. Integrating incremental speech
recognition and pomdp-based dialogue systems. In Proceed-
ings of the 13th Annual Meeting of the Special Interest Group
on Discourse and Dialogue, pages 275–279, Seoul, South
Korea, July. Association for Computational Linguistics.
Gabriel Skantze and David Schlangen. 2009. Incremental di-
alogue processing in a micro-domain. In Proceedings of
EACL 2009.
David Traum, Stacy Marsella, Jonathan Gratch, Jina Lee, and
Arno Hartholt. 2008. Multi-party, multi-issue, multi-
strategy negotiation for multi-modal virtual agents. In Proc.
of Intelligent Virtual Agents Conference IVA-2008.
David Traum, David DeVault, Jina Lee, Zhiyang Wang, and
Stacy C. Marsella. 2012. Incremental dialogue understand-
ing and feedback for multi-party, multimodal conversation.
In The 12th International Conference on Intelligent Virtual
Agents (IVA), Santa Cruz, CA, September.
David Traum. 2003. Semantics and pragmatics of questions
and answers for dialogue agents. In Proc. of the Interna-
tional Workshop on Computational Semantics, pages 380–
394, January.
</reference>
<page confidence="0.997278">
1099
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.828155">
<title confidence="0.9928945">A method for the approximation of incremental understanding of utterance meaning using predictive models in finite domains</title>
<author confidence="0.993022">DeVault Traum</author>
<affiliation confidence="0.999942">Institute for Creative Technologies, University of Southern</affiliation>
<address confidence="0.999111">12015 Waterfront Dr., Playa Vista, CA 90094 USA</address>
<email confidence="0.99979">devault@ict.usc.edu</email>
<email confidence="0.99979">traum@ict.usc.edu</email>
<abstract confidence="0.986955416666667">This paper explores the relationship between explicit and predictive models of incremental speech understanding in a dialogue system that supports a finite set of user utterance meanings. We present a method that enables the approximation of explicit understanding using information implicit in a predictive understanding model for the same domain. We show promising performance for this method in a corpus evaluation, and discuss its practical application and annotation costs in relation to some alternative approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hendrik Buschmeier</author>
<author>Timo Baumann</author>
<author>Benjamin Dosch</author>
<author>Stefan Kopp</author>
<author>David Schlangen</author>
</authors>
<title>Combining incremental language generation and incremental speech synthesis for adaptive information presentation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,</booktitle>
<pages>295--303</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seoul, South</location>
<contexts>
<context position="1698" citStr="Buschmeier et al., 2012" startWordPosition="249" endWordPosition="252">9; Schlangen et al., 2009; Heintze et al., 2010; DeVault et al., 2011a; Selfridge et al., 2012). This work has generally been motivated by a desire to make dialogue systems more efficient and more natural, by enabling them to provide lower latency responses (Skantze and Schlangen, 2009), human-like feedback such as backchannels that indicate how well the system is understanding user speech (DeVault et al., 2011b; Traum et al., 2012), and more interactive response capabilities such as collaborative completions of user utterances (DeVault et al., 2011a), more adaptive handling of interruptions (Buschmeier et al., 2012), and others. This paper builds on techniques developed in previous work that has adopted a predictive approach to incremental NLU (DeVault et al., 2011a). On this approach, at specific moments while a user’s speech is in progress, an attempt is made to predict what the full meaning of the complete user utterance will be. Predictive models can be contrasted with explicit approaches to incremental NLU. We use the term explicit understanding to refer to approaches that attempt to determine the meaning that has been expressed explicitly in the user’s partial utterance so far (without predicting f</context>
</contexts>
<marker>Buschmeier, Baumann, Dosch, Kopp, Schlangen, 2012</marker>
<rawString>Hendrik Buschmeier, Timo Baumann, Benjamin Dosch, Stefan Kopp, and David Schlangen. 2012. Combining incremental language generation and incremental speech synthesis for adaptive information presentation. In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 295–303, Seoul, South Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Okko Buß</author>
<author>David Schlangen</author>
</authors>
<title>Dium - an incremental dialogue manager that can produce self-corrections.</title>
<date>2011</date>
<booktitle>In Proceedings of the 15th Workshop on the Semantics and Pragmatics of Dialogue (SemDial).</booktitle>
<contexts>
<context position="3306" citStr="Buß and Schlangen, 2011" startWordPosition="505" endWordPosition="508">eVault et al., 2011a) and reduced response latency.1 However, explicit models support additional and complementary capabilities. For instance, depending on the application domain (Heintze et al., 2010) and on the individual utterance (DeVault et al., 2011b), it may be difficult for a system to predict a user’s impending meaning with confidence. Nevertheless, it may often be possible for systems to determine the meaning of what a user has said so far, and to take action based on this partial understanding. As one example, items in a user interface could be highlighted when mentioned by a user (Buß and Schlangen, 2011). Another capability would be to provide grounding feedback, such as verbal back-channels or head nods (in embodied systems), to indicate when the system is understanding the user’s meaning (Traum et al., 2012). Explicit utterance meanings also allow a system to distinguish between meaning that has been expressed and meaning that is merely implied or inferred, which may be less reliable. In the near future, as incremental processing capabilities in dialogue systems grow, it may prove valuable for dialogue systems to combine both predictive and explicit incremental understanding capabilities. I</context>
</contexts>
<marker>Buß, Schlangen, 2011</marker>
<rawString>Okko Buß and David Schlangen. 2011. Dium - an incremental dialogue manager that can produce self-corrections. In Proceedings of the 15th Workshop on the Semantics and Pragmatics of Dialogue (SemDial).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David DeVault</author>
<author>Susan Robinson</author>
<author>David Traum</author>
</authors>
<title>IORelator: A graphical user interface to enable rapid semantic annotation for data-driven natural language understanding.</title>
<date>2010</date>
<booktitle>In Fifth Joint ISO-ACL/SIGSEM Workshop on Interoperable Semantic Annotation.</booktitle>
<contexts>
<context position="6426" citStr="DeVault et al., 2010" startWordPosition="1009" endWordPosition="1012"> a negotiation about the possible re-location of a medical clinic in an Iraqi village. A human trainee plays the role of a US Army captain, and there are two virtual humans that he negotiates with: Doctor Perez, the head of an NGO clinic, and a local village elder, al-Hassan. The captain’s main objective is to convince the doctor and the elder to move the clinic out of an unsafe marketplace area. The corpus used for the experiments in this paper includes 3,826 training and 449 testing utterances drawn from user dialogues in this domain. The corpus and its semantic annotation are described in (DeVault et al., 2010; DeVault et al., 2011a). All user utterances have been audio recorded, transcribed, and manually annotated with the correct NLU output frame for the entire utterance. (We discuss the cost of this annotation in Section 4.) Each NLU output frame contains a set of attributes and values that represent semantic information linked to a domainspecific ontology and task model (Traum, 2003). Examples of the NLU output frames are included in Figures 2, 3, and 5. 2.2 Predictive incremental NLU This approach uses a predictive incremental NLU module, mxNLU (Sagae et al., 2009; DeVault et al., 2011a), whic</context>
<context position="23707" citStr="DeVault et al., 2010" startWordPosition="3731" endWordPosition="3734">technique presented here, in relation to some alternative approaches. An important consideration for NLU techniques is the cost, in both time and knowledge, of the annotation that is needed. One attractive aspect of our technique is that the only semantic annotation that is required is the association of complete user utterances with complete NLU output frames. This task can be performed by anyone familiar with the scenario and the semantic frame format, such as a system developer or scenario designer. In fact, the annotation of the SASO-EN data set we use in this paper has been described in (DeVault et al., 2010), which reports that the overall corpus of 4678 token utterances was semantically annotated at an average rate of about 10 seconds per unique utterance. The model in Equation (2) is what (Heintze et al., 2010) call a hybrid output approach, in which larger and larger frames are provided as partial input grows, but in which a detailed alignment between surface text and frames is not provided by the incremental NLU component. They contrast hybrid output systems with techniques that deliver either whole-frame output (like the predictive mxNLU) or aligned output that connects individual words to t</context>
</contexts>
<marker>DeVault, Robinson, Traum, 2010</marker>
<rawString>David DeVault, Susan Robinson, and David Traum. 2010. IORelator: A graphical user interface to enable rapid semantic annotation for data-driven natural language understanding. In Fifth Joint ISO-ACL/SIGSEM Workshop on Interoperable Semantic Annotation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David DeVault</author>
<author>Kenji Sagae</author>
<author>David Traum</author>
</authors>
<title>Incremental interpretation and prediction of utterance meaning for interactive dialogue.</title>
<date>2011</date>
<booktitle>Dialogue &amp; Discourse,</booktitle>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="1143" citStr="DeVault et al., 2011" startWordPosition="162" endWordPosition="165">hod that enables the approximation of explicit understanding using information implicit in a predictive understanding model for the same domain. We show promising performance for this method in a corpus evaluation, and discuss its practical application and annotation costs in relation to some alternative approaches. 1 Introduction In recent years, there has been a growing interest among researchers in methods for incremental natural language understanding (NLU) for spoken dialogue systems; see e.g. (Skantze and Schlangen, 2009; Sagae et al., 2009; Schlangen et al., 2009; Heintze et al., 2010; DeVault et al., 2011a; Selfridge et al., 2012). This work has generally been motivated by a desire to make dialogue systems more efficient and more natural, by enabling them to provide lower latency responses (Skantze and Schlangen, 2009), human-like feedback such as backchannels that indicate how well the system is understanding user speech (DeVault et al., 2011b; Traum et al., 2012), and more interactive response capabilities such as collaborative completions of user utterances (DeVault et al., 2011a), more adaptive handling of interruptions (Buschmeier et al., 2012), and others. This paper builds on techniques</context>
<context position="2701" citStr="DeVault et al., 2011" startWordPosition="407" endWordPosition="410">s to incremental NLU. We use the term explicit understanding to refer to approaches that attempt to determine the meaning that has been expressed explicitly in the user’s partial utterance so far (without predicting further aspects of meaning to come). Explicit understanding of partial utterances can be implemented using statistical classification or sequential tagging models (Heintze et al., 2010). Both predictive and explicit incremental NLU capabilities can be valuable in a dialogue system. Prediction can support specific response capabilities, such as system completion of user utterances (DeVault et al., 2011a) and reduced response latency.1 However, explicit models support additional and complementary capabilities. For instance, depending on the application domain (Heintze et al., 2010) and on the individual utterance (DeVault et al., 2011b), it may be difficult for a system to predict a user’s impending meaning with confidence. Nevertheless, it may often be possible for systems to determine the meaning of what a user has said so far, and to take action based on this partial understanding. As one example, items in a user interface could be highlighted when mentioned by a user (Buß and Schlangen, </context>
<context position="4061" citStr="DeVault et al., 2011" startWordPosition="623" endWordPosition="626">te when the system is understanding the user’s meaning (Traum et al., 2012). Explicit utterance meanings also allow a system to distinguish between meaning that has been expressed and meaning that is merely implied or inferred, which may be less reliable. In the near future, as incremental processing capabilities in dialogue systems grow, it may prove valuable for dialogue systems to combine both predictive and explicit incremental understanding capabilities. In this paper, we present a technique for approximating a user’s explicit meaning using an existing predictive understanding framework (DeVault et al., 2011a). The specific new contributions in this paper are (1) to show that 1A simple approach to reducing response latency is to begin to plan a response to the predicted meaning while the user is still speaking. 1092 Proceedings of NAACL-HLT 2013, pages 1092–1099, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics an estimate of a user’s explicit utterance meaning can be derived from this kind of predictive understanding model (Section 2); (2) to quantify the performance of this new method in a corpus evaluation (Section 3); (3) to provide concrete examples and disc</context>
<context position="5286" citStr="DeVault et al., 2011" startWordPosition="811" endWordPosition="814">n of the annotation costs associated with implementing this technique, in relation to some alternative approaches to explicit understanding (Section 4). Our results and discussion show that the proposed method offers promising performance, has relatively low annotation costs, and enables explicit and predictive understanding to be easily combined within a dialogue system. It may therefore be a useful incremental understanding technique for some dialogue systems. 2 Technical Approach and Data Set In Sections 2.1-2.3, we briefly summarize the data set and approach to predictive incremental NLU (DeVault et al., 2011a) that serves as the starting point for the new work in this paper. Sections 2.4 and 2.5 present our new approach to explicit understanding based on this approach. 2.1 Data set For the experiments reported here, we use a corpus of user utterances collected with the SASO-EN spoken dialogue system (Hartholt et al., 2008; Traum et al., 2008). Briefly, this system is designed to allow a trainee to practice multi-party negotiation skills by engaging in face to face negotiation with virtual humans. The scenario involves a negotiation about the possible re-location of a medical clinic in an Iraqi vi</context>
<context position="7018" citStr="DeVault et al., 2011" startWordPosition="1108" endWordPosition="1111">bed in (DeVault et al., 2010; DeVault et al., 2011a). All user utterances have been audio recorded, transcribed, and manually annotated with the correct NLU output frame for the entire utterance. (We discuss the cost of this annotation in Section 4.) Each NLU output frame contains a set of attributes and values that represent semantic information linked to a domainspecific ontology and task model (Traum, 2003). Examples of the NLU output frames are included in Figures 2, 3, and 5. 2.2 Predictive incremental NLU This approach uses a predictive incremental NLU module, mxNLU (Sagae et al., 2009; DeVault et al., 2011a), which is based on maximum entropy classification. The approach treats entire individual frames as output classes, and extracts input features from partial ASR results. To define the incremental understanding problem, the audio of the utterances in the training data were fed through an ASR module, PocketSphinx (Huggins-Daines et al., 2006), in 200 millisecond chunks, and each partial ASR result produced by the ASR was recorded. Each partial ASR result then serves as an incremental input to mxNLU. NLU is predictive in the sense that, for each partial ASR result, the task of mxNLU is to produ</context>
</contexts>
<marker>DeVault, Sagae, Traum, 2011</marker>
<rawString>David DeVault, Kenji Sagae, and David Traum. 2011a. Incremental interpretation and prediction of utterance meaning for interactive dialogue. Dialogue &amp; Discourse, 2(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David DeVault</author>
<author>Kenji Sagae</author>
<author>David R Traum</author>
</authors>
<title>Detecting the status of a predictive incremental speech understanding model for real-time decision-making in a spoken dialogue system.</title>
<date>2011</date>
<booktitle>In Interspeech,</booktitle>
<pages>1021--1024</pages>
<contexts>
<context position="1143" citStr="DeVault et al., 2011" startWordPosition="162" endWordPosition="165">hod that enables the approximation of explicit understanding using information implicit in a predictive understanding model for the same domain. We show promising performance for this method in a corpus evaluation, and discuss its practical application and annotation costs in relation to some alternative approaches. 1 Introduction In recent years, there has been a growing interest among researchers in methods for incremental natural language understanding (NLU) for spoken dialogue systems; see e.g. (Skantze and Schlangen, 2009; Sagae et al., 2009; Schlangen et al., 2009; Heintze et al., 2010; DeVault et al., 2011a; Selfridge et al., 2012). This work has generally been motivated by a desire to make dialogue systems more efficient and more natural, by enabling them to provide lower latency responses (Skantze and Schlangen, 2009), human-like feedback such as backchannels that indicate how well the system is understanding user speech (DeVault et al., 2011b; Traum et al., 2012), and more interactive response capabilities such as collaborative completions of user utterances (DeVault et al., 2011a), more adaptive handling of interruptions (Buschmeier et al., 2012), and others. This paper builds on techniques</context>
<context position="2701" citStr="DeVault et al., 2011" startWordPosition="407" endWordPosition="410">s to incremental NLU. We use the term explicit understanding to refer to approaches that attempt to determine the meaning that has been expressed explicitly in the user’s partial utterance so far (without predicting further aspects of meaning to come). Explicit understanding of partial utterances can be implemented using statistical classification or sequential tagging models (Heintze et al., 2010). Both predictive and explicit incremental NLU capabilities can be valuable in a dialogue system. Prediction can support specific response capabilities, such as system completion of user utterances (DeVault et al., 2011a) and reduced response latency.1 However, explicit models support additional and complementary capabilities. For instance, depending on the application domain (Heintze et al., 2010) and on the individual utterance (DeVault et al., 2011b), it may be difficult for a system to predict a user’s impending meaning with confidence. Nevertheless, it may often be possible for systems to determine the meaning of what a user has said so far, and to take action based on this partial understanding. As one example, items in a user interface could be highlighted when mentioned by a user (Buß and Schlangen, </context>
<context position="4061" citStr="DeVault et al., 2011" startWordPosition="623" endWordPosition="626">te when the system is understanding the user’s meaning (Traum et al., 2012). Explicit utterance meanings also allow a system to distinguish between meaning that has been expressed and meaning that is merely implied or inferred, which may be less reliable. In the near future, as incremental processing capabilities in dialogue systems grow, it may prove valuable for dialogue systems to combine both predictive and explicit incremental understanding capabilities. In this paper, we present a technique for approximating a user’s explicit meaning using an existing predictive understanding framework (DeVault et al., 2011a). The specific new contributions in this paper are (1) to show that 1A simple approach to reducing response latency is to begin to plan a response to the predicted meaning while the user is still speaking. 1092 Proceedings of NAACL-HLT 2013, pages 1092–1099, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics an estimate of a user’s explicit utterance meaning can be derived from this kind of predictive understanding model (Section 2); (2) to quantify the performance of this new method in a corpus evaluation (Section 3); (3) to provide concrete examples and disc</context>
<context position="5286" citStr="DeVault et al., 2011" startWordPosition="811" endWordPosition="814">n of the annotation costs associated with implementing this technique, in relation to some alternative approaches to explicit understanding (Section 4). Our results and discussion show that the proposed method offers promising performance, has relatively low annotation costs, and enables explicit and predictive understanding to be easily combined within a dialogue system. It may therefore be a useful incremental understanding technique for some dialogue systems. 2 Technical Approach and Data Set In Sections 2.1-2.3, we briefly summarize the data set and approach to predictive incremental NLU (DeVault et al., 2011a) that serves as the starting point for the new work in this paper. Sections 2.4 and 2.5 present our new approach to explicit understanding based on this approach. 2.1 Data set For the experiments reported here, we use a corpus of user utterances collected with the SASO-EN spoken dialogue system (Hartholt et al., 2008; Traum et al., 2008). Briefly, this system is designed to allow a trainee to practice multi-party negotiation skills by engaging in face to face negotiation with virtual humans. The scenario involves a negotiation about the possible re-location of a medical clinic in an Iraqi vi</context>
<context position="7018" citStr="DeVault et al., 2011" startWordPosition="1108" endWordPosition="1111">bed in (DeVault et al., 2010; DeVault et al., 2011a). All user utterances have been audio recorded, transcribed, and manually annotated with the correct NLU output frame for the entire utterance. (We discuss the cost of this annotation in Section 4.) Each NLU output frame contains a set of attributes and values that represent semantic information linked to a domainspecific ontology and task model (Traum, 2003). Examples of the NLU output frames are included in Figures 2, 3, and 5. 2.2 Predictive incremental NLU This approach uses a predictive incremental NLU module, mxNLU (Sagae et al., 2009; DeVault et al., 2011a), which is based on maximum entropy classification. The approach treats entire individual frames as output classes, and extracts input features from partial ASR results. To define the incremental understanding problem, the audio of the utterances in the training data were fed through an ASR module, PocketSphinx (Huggins-Daines et al., 2006), in 200 millisecond chunks, and each partial ASR result produced by the ASR was recorded. Each partial ASR result then serves as an incremental input to mxNLU. NLU is predictive in the sense that, for each partial ASR result, the task of mxNLU is to produ</context>
</contexts>
<marker>DeVault, Sagae, Traum, 2011</marker>
<rawString>David DeVault, Kenji Sagae, and David R. Traum. 2011b. Detecting the status of a predictive incremental speech understanding model for real-time decision-making in a spoken dialogue system. In Interspeech, pages 1021–1024.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arno Hartholt</author>
<author>Thomas Russ</author>
<author>David Traum</author>
<author>Eduard Hovy</author>
<author>Susan Robinson</author>
</authors>
<title>A common ground for virtual humans: Using an ontology in a natural language oriented virtual human architecture.</title>
<date>2008</date>
<booktitle>In European Language Resources Association</booktitle>
<editor>(ELRA), editor,</editor>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="5606" citStr="Hartholt et al., 2008" startWordPosition="867" endWordPosition="870">tanding to be easily combined within a dialogue system. It may therefore be a useful incremental understanding technique for some dialogue systems. 2 Technical Approach and Data Set In Sections 2.1-2.3, we briefly summarize the data set and approach to predictive incremental NLU (DeVault et al., 2011a) that serves as the starting point for the new work in this paper. Sections 2.4 and 2.5 present our new approach to explicit understanding based on this approach. 2.1 Data set For the experiments reported here, we use a corpus of user utterances collected with the SASO-EN spoken dialogue system (Hartholt et al., 2008; Traum et al., 2008). Briefly, this system is designed to allow a trainee to practice multi-party negotiation skills by engaging in face to face negotiation with virtual humans. The scenario involves a negotiation about the possible re-location of a medical clinic in an Iraqi village. A human trainee plays the role of a US Army captain, and there are two virtual humans that he negotiates with: Doctor Perez, the head of an NGO clinic, and a local village elder, al-Hassan. The captain’s main objective is to convince the doctor and the elder to move the clinic out of an unsafe marketplace area. </context>
</contexts>
<marker>Hartholt, Russ, Traum, Hovy, Robinson, 2008</marker>
<rawString>Arno Hartholt, Thomas Russ, David Traum, Eduard Hovy, and Susan Robinson. 2008. A common ground for virtual humans: Using an ontology in a natural language oriented virtual human architecture. In European Language Resources Association (ELRA), editor, Proc. LREC, Marrakech, Morocco, may.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silvan Heintze</author>
<author>Timo Baumann</author>
<author>David Schlangen</author>
</authors>
<title>Comparing local and sequential models for statistical incremental natural language understanding.</title>
<date>2010</date>
<booktitle>In The 11th Annual Meeting of the Special Interest Group in Discourse and Dialogue (SIGDIAL</booktitle>
<contexts>
<context position="1121" citStr="Heintze et al., 2010" startWordPosition="158" endWordPosition="161">ings. We present a method that enables the approximation of explicit understanding using information implicit in a predictive understanding model for the same domain. We show promising performance for this method in a corpus evaluation, and discuss its practical application and annotation costs in relation to some alternative approaches. 1 Introduction In recent years, there has been a growing interest among researchers in methods for incremental natural language understanding (NLU) for spoken dialogue systems; see e.g. (Skantze and Schlangen, 2009; Sagae et al., 2009; Schlangen et al., 2009; Heintze et al., 2010; DeVault et al., 2011a; Selfridge et al., 2012). This work has generally been motivated by a desire to make dialogue systems more efficient and more natural, by enabling them to provide lower latency responses (Skantze and Schlangen, 2009), human-like feedback such as backchannels that indicate how well the system is understanding user speech (DeVault et al., 2011b; Traum et al., 2012), and more interactive response capabilities such as collaborative completions of user utterances (DeVault et al., 2011a), more adaptive handling of interruptions (Buschmeier et al., 2012), and others. This pape</context>
<context position="2482" citStr="Heintze et al., 2010" startWordPosition="374" endWordPosition="377"> approach, at specific moments while a user’s speech is in progress, an attempt is made to predict what the full meaning of the complete user utterance will be. Predictive models can be contrasted with explicit approaches to incremental NLU. We use the term explicit understanding to refer to approaches that attempt to determine the meaning that has been expressed explicitly in the user’s partial utterance so far (without predicting further aspects of meaning to come). Explicit understanding of partial utterances can be implemented using statistical classification or sequential tagging models (Heintze et al., 2010). Both predictive and explicit incremental NLU capabilities can be valuable in a dialogue system. Prediction can support specific response capabilities, such as system completion of user utterances (DeVault et al., 2011a) and reduced response latency.1 However, explicit models support additional and complementary capabilities. For instance, depending on the application domain (Heintze et al., 2010) and on the individual utterance (DeVault et al., 2011b), it may be difficult for a system to predict a user’s impending meaning with confidence. Nevertheless, it may often be possible for systems to</context>
<context position="23916" citStr="Heintze et al., 2010" startWordPosition="3766" endWordPosition="3769">ect of our technique is that the only semantic annotation that is required is the association of complete user utterances with complete NLU output frames. This task can be performed by anyone familiar with the scenario and the semantic frame format, such as a system developer or scenario designer. In fact, the annotation of the SASO-EN data set we use in this paper has been described in (DeVault et al., 2010), which reports that the overall corpus of 4678 token utterances was semantically annotated at an average rate of about 10 seconds per unique utterance. The model in Equation (2) is what (Heintze et al., 2010) call a hybrid output approach, in which larger and larger frames are provided as partial input grows, but in which a detailed alignment between surface text and frames is not provided by the incremental NLU component. They contrast hybrid output systems with techniques that deliver either whole-frame output (like the predictive mxNLU) or aligned output that connects individual words to their meanings. A data-driven approach to providing aligned outputs would involve preparing a more detailed annotated corpus that aligns individual words and surface expressions to their corresponding frame ele</context>
<context position="27725" citStr="Heintze et al., 2010" startWordPosition="4319" endWordPosition="4322">to mark the whole utterance as conveying that meaning in this domain. We have generally found this alignment task challenging for people without advanced linguistics training. The reason we describe the method in this paper as an approximation of explicit NLU is that, partly because it is trained without detailed word-meaning alignments, it can be expected to occasionally include some predictive aspects of user utterance meaning. An example of this is the method’s explicit subframe output for the phrase we need to in Figure 5. Another way to approximate explicit NLU would be using the method (Heintze et al., 2010) call an ensemble of classifiers; it involves training an individual classifier for each frame key. Like the method presented here, an ensemble of classifiers can be easily trained to predict those frame elements that will appear in the final frame G,,, for each utterance. And like our method, prediction with an ensemble of classifiers does not require detailed annotation of word-meaning alignment in the training data. One difference is that, with our method, by selecting an appropriate threshold, it is easy to enforce certain consistency properties on subframe outputs. In an ensemble of class</context>
</contexts>
<marker>Heintze, Baumann, Schlangen, 2010</marker>
<rawString>Silvan Heintze, Timo Baumann, and David Schlangen. 2010. Comparing local and sequential models for statistical incremental natural language understanding. In The 11th Annual Meeting of the Special Interest Group in Discourse and Dialogue (SIGDIAL 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Huggins-Daines</author>
<author>Mohit Kumar</author>
<author>Arthur Chan</author>
<author>Alan W Black</author>
<author>Mosur Ravishankar</author>
<author>Alex I Rudnicky</author>
</authors>
<title>Pocketsphinx: A free, real-time continuous speech recognition system for hand-held devices.</title>
<date>2006</date>
<booktitle>In Proceedings of ICASSP.</booktitle>
<contexts>
<context position="7362" citStr="Huggins-Daines et al., 2006" startWordPosition="1158" endWordPosition="1161"> information linked to a domainspecific ontology and task model (Traum, 2003). Examples of the NLU output frames are included in Figures 2, 3, and 5. 2.2 Predictive incremental NLU This approach uses a predictive incremental NLU module, mxNLU (Sagae et al., 2009; DeVault et al., 2011a), which is based on maximum entropy classification. The approach treats entire individual frames as output classes, and extracts input features from partial ASR results. To define the incremental understanding problem, the audio of the utterances in the training data were fed through an ASR module, PocketSphinx (Huggins-Daines et al., 2006), in 200 millisecond chunks, and each partial ASR result produced by the ASR was recorded. Each partial ASR result then serves as an incremental input to mxNLU. NLU is predictive in the sense that, for each partial ASR result, the task of mxNLU is to produce as output the complete frame that has been associated by a human annotator with the user’s complete utterance, even if that utterance has not yet been fully processed by the ASR. The human annotation defines a finite set S = {S1, ..., SN} of possible NLU output frames, where each frame Si = {e1, ..., e,,,} is a set of key-value pairs or fr</context>
</contexts>
<marker>Huggins-Daines, Kumar, Chan, Black, Ravishankar, Rudnicky, 2006</marker>
<rawString>David Huggins-Daines, Mohit Kumar, Arthur Chan, Alan W. Black, Mosur Ravishankar, and Alex I. Rudnicky. 2006. Pocketsphinx: A free, real-time continuous speech recognition system for hand-held devices. In Proceedings of ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Gwen Christian</author>
<author>David DeVault</author>
<author>David R Traum</author>
</authors>
<title>Towards natural language understanding of partial speech recognition results in dialogue systems.</title>
<date>2009</date>
<booktitle>In NAACL HLT.</booktitle>
<contexts>
<context position="1075" citStr="Sagae et al., 2009" startWordPosition="150" endWordPosition="153">supports a finite set of user utterance meanings. We present a method that enables the approximation of explicit understanding using information implicit in a predictive understanding model for the same domain. We show promising performance for this method in a corpus evaluation, and discuss its practical application and annotation costs in relation to some alternative approaches. 1 Introduction In recent years, there has been a growing interest among researchers in methods for incremental natural language understanding (NLU) for spoken dialogue systems; see e.g. (Skantze and Schlangen, 2009; Sagae et al., 2009; Schlangen et al., 2009; Heintze et al., 2010; DeVault et al., 2011a; Selfridge et al., 2012). This work has generally been motivated by a desire to make dialogue systems more efficient and more natural, by enabling them to provide lower latency responses (Skantze and Schlangen, 2009), human-like feedback such as backchannels that indicate how well the system is understanding user speech (DeVault et al., 2011b; Traum et al., 2012), and more interactive response capabilities such as collaborative completions of user utterances (DeVault et al., 2011a), more adaptive handling of interruptions (B</context>
<context position="6996" citStr="Sagae et al., 2009" startWordPosition="1104" endWordPosition="1107">nnotation are described in (DeVault et al., 2010; DeVault et al., 2011a). All user utterances have been audio recorded, transcribed, and manually annotated with the correct NLU output frame for the entire utterance. (We discuss the cost of this annotation in Section 4.) Each NLU output frame contains a set of attributes and values that represent semantic information linked to a domainspecific ontology and task model (Traum, 2003). Examples of the NLU output frames are included in Figures 2, 3, and 5. 2.2 Predictive incremental NLU This approach uses a predictive incremental NLU module, mxNLU (Sagae et al., 2009; DeVault et al., 2011a), which is based on maximum entropy classification. The approach treats entire individual frames as output classes, and extracts input features from partial ASR results. To define the incremental understanding problem, the audio of the utterances in the training data were fed through an ASR module, PocketSphinx (Huggins-Daines et al., 2006), in 200 millisecond chunks, and each partial ASR result produced by the ASR was recorded. Each partial ASR result then serves as an incremental input to mxNLU. NLU is predictive in the sense that, for each partial ASR result, the tas</context>
</contexts>
<marker>Sagae, Christian, DeVault, Traum, 2009</marker>
<rawString>Kenji Sagae, Gwen Christian, David DeVault, and David R. Traum. 2009. Towards natural language understanding of partial speech recognition results in dialogue systems. In NAACL HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Schlangen</author>
<author>Timo Baumann</author>
<author>Michaela Atterer</author>
</authors>
<title>Incremental reference resolution: The task, metrics for evaluation, and a bayesian filtering model that is sensitive to disfluencies.</title>
<date>2009</date>
<booktitle>In SIGDIAL.</booktitle>
<contexts>
<context position="1099" citStr="Schlangen et al., 2009" startWordPosition="154" endWordPosition="157">t of user utterance meanings. We present a method that enables the approximation of explicit understanding using information implicit in a predictive understanding model for the same domain. We show promising performance for this method in a corpus evaluation, and discuss its practical application and annotation costs in relation to some alternative approaches. 1 Introduction In recent years, there has been a growing interest among researchers in methods for incremental natural language understanding (NLU) for spoken dialogue systems; see e.g. (Skantze and Schlangen, 2009; Sagae et al., 2009; Schlangen et al., 2009; Heintze et al., 2010; DeVault et al., 2011a; Selfridge et al., 2012). This work has generally been motivated by a desire to make dialogue systems more efficient and more natural, by enabling them to provide lower latency responses (Skantze and Schlangen, 2009), human-like feedback such as backchannels that indicate how well the system is understanding user speech (DeVault et al., 2011b; Traum et al., 2012), and more interactive response capabilities such as collaborative completions of user utterances (DeVault et al., 2011a), more adaptive handling of interruptions (Buschmeier et al., 2012),</context>
</contexts>
<marker>Schlangen, Baumann, Atterer, 2009</marker>
<rawString>David Schlangen, Timo Baumann, and Michaela Atterer. 2009. Incremental reference resolution: The task, metrics for evaluation, and a bayesian filtering model that is sensitive to disfluencies. In SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ethan O Selfridge</author>
<author>Iker Arizmendi</author>
<author>Peter A Heeman</author>
<author>Jason D Williams</author>
</authors>
<title>Integrating incremental speech recognition and pomdp-based dialogue systems.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,</booktitle>
<pages>275--279</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seoul, South</location>
<contexts>
<context position="1169" citStr="Selfridge et al., 2012" startWordPosition="166" endWordPosition="169">proximation of explicit understanding using information implicit in a predictive understanding model for the same domain. We show promising performance for this method in a corpus evaluation, and discuss its practical application and annotation costs in relation to some alternative approaches. 1 Introduction In recent years, there has been a growing interest among researchers in methods for incremental natural language understanding (NLU) for spoken dialogue systems; see e.g. (Skantze and Schlangen, 2009; Sagae et al., 2009; Schlangen et al., 2009; Heintze et al., 2010; DeVault et al., 2011a; Selfridge et al., 2012). This work has generally been motivated by a desire to make dialogue systems more efficient and more natural, by enabling them to provide lower latency responses (Skantze and Schlangen, 2009), human-like feedback such as backchannels that indicate how well the system is understanding user speech (DeVault et al., 2011b; Traum et al., 2012), and more interactive response capabilities such as collaborative completions of user utterances (DeVault et al., 2011a), more adaptive handling of interruptions (Buschmeier et al., 2012), and others. This paper builds on techniques developed in previous wor</context>
</contexts>
<marker>Selfridge, Arizmendi, Heeman, Williams, 2012</marker>
<rawString>Ethan O. Selfridge, Iker Arizmendi, Peter A. Heeman, and Jason D. Williams. 2012. Integrating incremental speech recognition and pomdp-based dialogue systems. In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 275–279, Seoul, South Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel Skantze</author>
<author>David Schlangen</author>
</authors>
<title>Incremental dialogue processing in a micro-domain.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL</booktitle>
<contexts>
<context position="1055" citStr="Skantze and Schlangen, 2009" startWordPosition="146" endWordPosition="149">ng in a dialogue system that supports a finite set of user utterance meanings. We present a method that enables the approximation of explicit understanding using information implicit in a predictive understanding model for the same domain. We show promising performance for this method in a corpus evaluation, and discuss its practical application and annotation costs in relation to some alternative approaches. 1 Introduction In recent years, there has been a growing interest among researchers in methods for incremental natural language understanding (NLU) for spoken dialogue systems; see e.g. (Skantze and Schlangen, 2009; Sagae et al., 2009; Schlangen et al., 2009; Heintze et al., 2010; DeVault et al., 2011a; Selfridge et al., 2012). This work has generally been motivated by a desire to make dialogue systems more efficient and more natural, by enabling them to provide lower latency responses (Skantze and Schlangen, 2009), human-like feedback such as backchannels that indicate how well the system is understanding user speech (DeVault et al., 2011b; Traum et al., 2012), and more interactive response capabilities such as collaborative completions of user utterances (DeVault et al., 2011a), more adaptive handling</context>
</contexts>
<marker>Skantze, Schlangen, 2009</marker>
<rawString>Gabriel Skantze and David Schlangen. 2009. Incremental dialogue processing in a micro-domain. In Proceedings of EACL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Traum</author>
<author>Stacy Marsella</author>
<author>Jonathan Gratch</author>
<author>Jina Lee</author>
<author>Arno Hartholt</author>
</authors>
<title>Multi-party, multi-issue, multistrategy negotiation for multi-modal virtual agents.</title>
<date>2008</date>
<booktitle>In Proc. of Intelligent Virtual Agents Conference IVA-2008.</booktitle>
<contexts>
<context position="5627" citStr="Traum et al., 2008" startWordPosition="871" endWordPosition="874">mbined within a dialogue system. It may therefore be a useful incremental understanding technique for some dialogue systems. 2 Technical Approach and Data Set In Sections 2.1-2.3, we briefly summarize the data set and approach to predictive incremental NLU (DeVault et al., 2011a) that serves as the starting point for the new work in this paper. Sections 2.4 and 2.5 present our new approach to explicit understanding based on this approach. 2.1 Data set For the experiments reported here, we use a corpus of user utterances collected with the SASO-EN spoken dialogue system (Hartholt et al., 2008; Traum et al., 2008). Briefly, this system is designed to allow a trainee to practice multi-party negotiation skills by engaging in face to face negotiation with virtual humans. The scenario involves a negotiation about the possible re-location of a medical clinic in an Iraqi village. A human trainee plays the role of a US Army captain, and there are two virtual humans that he negotiates with: Doctor Perez, the head of an NGO clinic, and a local village elder, al-Hassan. The captain’s main objective is to convince the doctor and the elder to move the clinic out of an unsafe marketplace area. The corpus used for t</context>
</contexts>
<marker>Traum, Marsella, Gratch, Lee, Hartholt, 2008</marker>
<rawString>David Traum, Stacy Marsella, Jonathan Gratch, Jina Lee, and Arno Hartholt. 2008. Multi-party, multi-issue, multistrategy negotiation for multi-modal virtual agents. In Proc. of Intelligent Virtual Agents Conference IVA-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Traum</author>
<author>David DeVault</author>
<author>Jina Lee</author>
<author>Zhiyang Wang</author>
<author>Stacy C Marsella</author>
</authors>
<title>Incremental dialogue understanding and feedback for multi-party, multimodal conversation.</title>
<date>2012</date>
<booktitle>In The 12th International Conference on Intelligent Virtual Agents (IVA),</booktitle>
<location>Santa Cruz, CA,</location>
<contexts>
<context position="1510" citStr="Traum et al., 2012" startWordPosition="222" endWordPosition="225">rowing interest among researchers in methods for incremental natural language understanding (NLU) for spoken dialogue systems; see e.g. (Skantze and Schlangen, 2009; Sagae et al., 2009; Schlangen et al., 2009; Heintze et al., 2010; DeVault et al., 2011a; Selfridge et al., 2012). This work has generally been motivated by a desire to make dialogue systems more efficient and more natural, by enabling them to provide lower latency responses (Skantze and Schlangen, 2009), human-like feedback such as backchannels that indicate how well the system is understanding user speech (DeVault et al., 2011b; Traum et al., 2012), and more interactive response capabilities such as collaborative completions of user utterances (DeVault et al., 2011a), more adaptive handling of interruptions (Buschmeier et al., 2012), and others. This paper builds on techniques developed in previous work that has adopted a predictive approach to incremental NLU (DeVault et al., 2011a). On this approach, at specific moments while a user’s speech is in progress, an attempt is made to predict what the full meaning of the complete user utterance will be. Predictive models can be contrasted with explicit approaches to incremental NLU. We use </context>
<context position="3516" citStr="Traum et al., 2012" startWordPosition="540" endWordPosition="543">dividual utterance (DeVault et al., 2011b), it may be difficult for a system to predict a user’s impending meaning with confidence. Nevertheless, it may often be possible for systems to determine the meaning of what a user has said so far, and to take action based on this partial understanding. As one example, items in a user interface could be highlighted when mentioned by a user (Buß and Schlangen, 2011). Another capability would be to provide grounding feedback, such as verbal back-channels or head nods (in embodied systems), to indicate when the system is understanding the user’s meaning (Traum et al., 2012). Explicit utterance meanings also allow a system to distinguish between meaning that has been expressed and meaning that is merely implied or inferred, which may be less reliable. In the near future, as incremental processing capabilities in dialogue systems grow, it may prove valuable for dialogue systems to combine both predictive and explicit incremental understanding capabilities. In this paper, we present a technique for approximating a user’s explicit meaning using an existing predictive understanding framework (DeVault et al., 2011a). The specific new contributions in this paper are (1</context>
</contexts>
<marker>Traum, DeVault, Lee, Wang, Marsella, 2012</marker>
<rawString>David Traum, David DeVault, Jina Lee, Zhiyang Wang, and Stacy C. Marsella. 2012. Incremental dialogue understanding and feedback for multi-party, multimodal conversation. In The 12th International Conference on Intelligent Virtual Agents (IVA), Santa Cruz, CA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Traum</author>
</authors>
<title>Semantics and pragmatics of questions and answers for dialogue agents.</title>
<date>2003</date>
<booktitle>In Proc. of the International Workshop on Computational Semantics,</booktitle>
<pages>380--394</pages>
<contexts>
<context position="6811" citStr="Traum, 2003" startWordPosition="1073" endWordPosition="1074"> area. The corpus used for the experiments in this paper includes 3,826 training and 449 testing utterances drawn from user dialogues in this domain. The corpus and its semantic annotation are described in (DeVault et al., 2010; DeVault et al., 2011a). All user utterances have been audio recorded, transcribed, and manually annotated with the correct NLU output frame for the entire utterance. (We discuss the cost of this annotation in Section 4.) Each NLU output frame contains a set of attributes and values that represent semantic information linked to a domainspecific ontology and task model (Traum, 2003). Examples of the NLU output frames are included in Figures 2, 3, and 5. 2.2 Predictive incremental NLU This approach uses a predictive incremental NLU module, mxNLU (Sagae et al., 2009; DeVault et al., 2011a), which is based on maximum entropy classification. The approach treats entire individual frames as output classes, and extracts input features from partial ASR results. To define the incremental understanding problem, the audio of the utterances in the training data were fed through an ASR module, PocketSphinx (Huggins-Daines et al., 2006), in 200 millisecond chunks, and each partial ASR</context>
</contexts>
<marker>Traum, 2003</marker>
<rawString>David Traum. 2003. Semantics and pragmatics of questions and answers for dialogue agents. In Proc. of the International Workshop on Computational Semantics, pages 380– 394, January.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>