<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.998569">
HAL-based Cascaded Model for Variable-Length
Semantic Pattern Induction from Psychiatry Web Resources
</title>
<author confidence="0.996649">
Liang-Chih Yu and Chung-Hsien Wu
</author>
<affiliation confidence="0.9923235">
Department of Computer Science and Information Engineering
National Cheng Kung University
</affiliation>
<address confidence="0.520101">
Tainan, Taiwan, R.O.C.
</address>
<email confidence="0.998021">
{lcyu, chwu}@csie.ncku.edu.tw
</email>
<author confidence="0.993647">
Fong-Lin Jang
</author>
<affiliation confidence="0.9276365">
Department of Psychiatry
Chi-Mei Medical Center
</affiliation>
<address confidence="0.57623">
Tainan, Taiwan, R.O.C.
</address>
<email confidence="0.998075">
jcj0429@seed.net.tw
</email>
<sectionHeader confidence="0.99387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999936115384615">
Negative life events play an important
role in triggering depressive episodes.
Developing psychiatric services that can
automatically identify such events is
beneficial for mental health care and pre-
vention. Before these services can be
provided, some meaningful semantic pat-
terns, such as &lt;lost, parents&gt;, have to be
extracted. In this work, we present a text
mining framework capable of inducing
variable-length semantic patterns from
unannotated psychiatry web resources.
This framework integrates a cognitive
motivated model, Hyperspace Analog to
Language (HAL), to represent words as
well as combinations of words. Then, a
cascaded induction process (CIP) boot-
straps with a small set of seed patterns
and incorporates relevance feedback to
iteratively induce more relevant patterns.
The experimental results show that by
combining the HAL model and relevance
feedback, the CIP can induce semantic
patterns from the unannotated web cor-
pora so as to reduce the reliance on anno-
tated corpora.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994192196078432">
Depressive disorders have become a major threat
to mental health. People in their daily life may
suffer from some negative or stressful life events,
such as death of a family member, arguments
with a spouse, loss of a job, and so forth. Such
life events play an important role in triggering
depressive symptoms, such as depressed mood,
suicide attempts, and anxiety. Therefore, it is
desired to develop a system capable of identify-
ing negative life events to provide more effective
psychiatric services. For example, through the
negative life events, the health professionals can
know the background information about subjects
so as to make more correct decisions and sugges-
tions. Negative life events are often expressed in
natural language segments (e.g., sentences). To
identify them, the critical step is to transform the
segments into machine-interpretable semantic
representation. This involves the extraction of
key semantic patterns from the segments. Con-
sider the following example.
Two years ago, I lost my parents. (Event)
Since that, I have attempted to kill myself
several times. (Suicide)
In this example, the semantic pattern &lt;lost, par-
ents&gt; is constituted by two words, which indi-
cates that the subject suffered from a negative
life event that triggered the symptom “Suicide”.
A semantic pattern can be considered as a se-
mantically plausible combination of k words,
where k is the length of the pattern. Accordingly,
a semantic pattern may have variable length. In
Wu et al.’s study (2005), they have presented a
methodology to identify depressive symptoms. In
this work, we go a further step to devise a text
mining framework for variable-length semantic
pattern induction from psychiatry web resources.
Traditional approaches to semantic pattern in-
duction can be generally divided into two
streams: knowledge-based approaches and cor-
pus-based approaches (Lehnert et al., 1992;
Muslea, 1999). Knowledge-based approaches
rely on exploiting expert knowledge to design
handcrafted semantic patterns. The major limita-
tions of such approaches include the requirement
of significant time and effort on designing the
handcrafted patterns. Besides, when applying to
a new domain, these patterns have to be redes-
igned. Such limitations form a knowledge acqui-
sition bottleneck. A possible solution to reducing
the problem is to use a general-purpose ontology
</bodyText>
<page confidence="0.979756">
945
</page>
<note confidence="0.724758">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 945–952,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999937602040817">
such as WordNet (Fellbaum, 1998), or a domain-
specific ontology constructed using automatic
approaches (Yeh et al., 2004). These ontologies
contain rich concepts and inter-concept relations
such as hypernymy-hyponymy relations. How-
ever, an ontology is a static knowledge resource,
which may not reflect the dynamic characteris-
tics of language. For this consideration, we in-
stead refer to the web resources, or more restrict-
edly, the psychiatry web resources as our knowl-
edge resource.
Corpus-based approaches can automatically
learn semantic patterns from domain corpora by
applying statistical methods. The corpora have to
be annotated with domain-specific knowledge
(e.g., events). Then, various statistical methods
can be applied to induce variable-length semantic
patterns from all possible combinations of words
in the corpora. However, statistical methods may
suffer from data sparseness problem, thus they
require large corpora with annotated information
to obtain more reliable parameters. For some ap-
plication domains, such annotated corpora may
be unavailable. Therefore, we propose the use of
web resources as the corpora. When facing with
the web corpora, traditional corpus-based ap-
proaches may be infeasible. For example, it is
impractical for health professionals to annotate
the whole web corpora. Besides, it is also im-
practical to enumerate all possible combinations
of words from the web corpora, and then search
for the semantic patterns.
To address the problems, we take the notion of
weakly supervised (Stevenson and Greenwood,
2005) or unsupervised learning (Hasegawa, 2004;
Grenager et al., 2005) to develop a framework
able to bootstrap with a small set of seed patterns,
and then induce more relevant patterns form the
unannotated psychiatry web corpora. By this
way, the reliance on annotated corpora can be
significantly reduced. The proposed framework
is divided into two parts: Hyperspace Analog to
Language (HAL) model (Burgess et al., 1998;
Bai et al., 2005), and a cascaded induction proc-
ess (CIP). The HAL model, which is a cognitive
motivated model, provides an informative infra-
structure to make the CIP capable of learning
from unannotated corpora. The CIP treats the
variable-length induction task as a cascaded
process. That is, it first induces the semantic pat-
terns of length two, then length three, and so on.
In each stage, the CIP initializes the set of se-
mantic patterns to be induced based on the better
results of the previous stage, rather than enumer-
ating all possible combinations of words. This
would be helpful to avoid noisy patterns propa-
gating to the next stage, and the search space can
also be reduced.
A crucial step for semantic pattern induction is
the representation of words as well as combina-
tions of words. The HAL model constructs a
high-dimensional context space for the psychia-
try web corpora. Each word in the HAL space is
represented as a vector of its context words,
which means that the sense of a word can be in-
ferred through its contexts. Such notion is de-
rived from the observation of human behavior.
That is, when an unknown word occurs, human
beings may determine its sense by referring to
the words appearing in the contexts. Based on
the cognitive behavior, if two words share more
common contexts, they are more semantically
similar. To further represent a semantic pattern,
the HAL model provides a mechanism to com-
bine its constituent words over the HAL space.
Once the HAL space is constructed, the CIP
takes as input a seed pattern per run, and in turn
induces the semantic patterns of different lengths.
For each length, the CIP first creates the initial
set based on the results of the previous stage.
Then, the induction process is iteratively per-
formed to induce more patterns relevant to the
given seed pattern by comparing their context
distributions. In addition, we also incorporate
expert knowledge to guide the induction process
by using relevance feedback (Baeza-Yates and
Ribeiro-Neto, 1999), the most popular query re-
formulation strategy in the information retrieval
(IR) community. The induction process is termi-
nated until the termination criteria are satisfied.
In the remainder of this paper, Section 2 pre-
sents the overall framework for variable-length
semantic pattern induction. Section 3 describes
the process of constructing the HAL space. Sec-
tion 4 details the cascaded induction process.
Section 5 summarizes the experiment results.
Finally, Section 6 draws some conclusions and
suggests directions for future work.
</bodyText>
<sectionHeader confidence="0.98992" genericHeader="method">
2 Framework for Variable-Length Se-
mantic Pattern Induction
</sectionHeader>
<bodyText confidence="0.840921625">
The overall framework, as illustrated in Figure 1,
is divided into two parts: the HAL model and the
cascaded induction process. First of all, the HAL
space is constructed for the psychiatry web
corpora after word segmentation. Then, each
word in HAL space is evaluated by computing its
distance to a given seed pattern. A smaller
distance represents that the word is more
</bodyText>
<page confidence="0.996963">
946
</page>
<figure confidence="0.457072">
Cascaded Induction Process
</figure>
<figureCaption confidence="0.9591325">
Figure 1. Framework for variable-length seman-
tic pattern induction.
</figureCaption>
<bodyText confidence="0.999928516129032">
semantically related to the seed pattern.
According to the distance measure, the CIP
generates quality concepts, i.e., a set of
semantically related words to the seed pattern.
The quality concepts and the better semantic
patterns induced in the previous stage are
combined to generate the initial set for each
length. For example, in the beginning stage, i.e.,
length two, the initial set is the all possible
combinations of two quality concepts. In the later
stages, each initial set is generated by adding a
quality concept to each of the better semantic
patterns. After the initial set for a particular
length is created, each semantic pattern and the
seed pattern are represented in the HAL space for
further computing their distance. The more
similar the context distributions between two
patterns, the closer they are. Once all the
semantic patterns are evaluated, the relevance
feedback is applied to provide a set of relevant
patterns judged by the health professionals.
According to the relevant information, the seed
pattern can be refined to be more similar to the
relevant set. The refined seed pattern will be
taken as the reference basis in the next iteration.
The induction process for each stage is
performed iteratively until no more patterns are
judged as relevant or a maximum number of
iteration is reached. The relevant set produced at
the last iteration is considered as the result of the
semantic patterns.
</bodyText>
<sectionHeader confidence="0.982682" genericHeader="method">
3 HAL Space Construction
</sectionHeader>
<bodyText confidence="0.9955475">
The HAL model represents each word in the vo-
cabulary using a vector representation. Each
</bodyText>
<figureCaption confidence="0.989433">
Figure 2. Weighting scheme of the HAL model.
</figureCaption>
<bodyText confidence="0.999198875">
two years ago I lost my parents
two 0 0 0 0 0 0 0
years 5 0 0 0 0 0 0
ago 4 5 0 0 0 0 0
I 3 4 5 0 0 0 0
lost 2 3 4 5 0 0 0
my 1 2 3 4 5 0 0
parents 0 1 2 3 4 5 0
</bodyText>
<tableCaption confidence="0.958495">
Table 1. Example of HAL Space (window size=5)
</tableCaption>
<bodyText confidence="0.9999655">
dimension of the vector is a weight representing
the strength of association between the target
word and its context word. The weights are com-
puted by applying an observation window of
length l over the corpus. All words within the
window are considered as co-occurring with each
other. Thus, for any two words of distance d
within the window, the weight between them is
computed as l − d +1. Figure 2 shows an exam-
ple. The HAL space views the corpus as a se-
quence of words. Thus, after moving the window
by one word increment over the whole corpus,
the HAL space is constructed. The resultant HAL
space is an N x N matrix, where N is the vo-
cabulary size. In addition, each word in the HAL
space is called a concept. Table 1 presents the
HAL space for the example text “Two years ago,
I lost my parents.”
</bodyText>
<subsectionHeader confidence="0.999908">
3.1 Representation of a Single Concept
</subsectionHeader>
<bodyText confidence="0.999898714285714">
For each concept in Table 1, the correspond-
ing row vector represents its left context infor-
mation, i.e., the weights of the words preceding it.
Similarly, the corresponding column vector
represents its right context information. Accord-
ingly, each concept can be represented by a pair
of vectors. That is,
</bodyText>
<equation confidence="0.8969525">
( , )
v v
left right
c c
i i
= r „ left „ Jeft „ left Wright Wright wright 1
1\ �&apos;✓C`t1 , �&apos;✓Cit2 �&apos;✓CitN , Cit1 , Cit2 , , citN /1 ,
(1)
</equation>
<bodyText confidence="0.863202">
vc represent the vectors of the
</bodyText>
<equation confidence="0.5391525">
right
i
</equation>
<bodyText confidence="0.9869665">
left context information and right context infor-
mation of a concept ci, respectively, wcit jdenotes
</bodyText>
<figure confidence="0.988530918367347">
Seed
Patterns
length 2
length 3
...
length k
Induced
Patterns
Iteration +1
Iteration=0
Distance
Evaluation
Relevance
Feedback
Initial Set
(length k)
Stop
No
Yes
Induced
Patterns
Relevant
Patterns
k +1
Psychiatry
Web Corpora
Word
Segmentation
HAL Space
Construction
HAL model
Quality
Concepts
w1 w2 wl-2 wl-1 wl
weight =1 2
Observation window of length
c =
i
where
vc and
left
i
947
�����������
Right Context
w right ... right
w
c t c t
11 1 N
</figure>
<figureCaption confidence="0.9804185">
Figure 3. Conceptual representation of the HAL
space.
</figureCaption>
<bodyText confidence="0.98835755">
the weight of the j-th dimension ( tj) of a vector,
and N is the dimensionality of a vector, i.e., vo-
cabulary size. The conceptual representation is
depicted in Figure 3.
The weighting scheme of the HAL model is
frequency-based. For some extremely infrequent
words, we consider them as noises and remove
them from the vocabulary. On the other hand, a
high frequent word tends to get a higher weight,
but this does not mean the word is informative,
because it may also appear in many other vectors.
Thus, to measure the informativeness of a word,
the number of the vectors the word appears in
should be taken into account. In principle, the
more vectors the word appears in, the less infor-
mation it carries to discriminate the vectors. Here
we use a weighting scheme analogous to TF-IDF
(Baeza-Yates and Ribeiro-Neto, 1999) to re-
weight the dimensions of each vector, as de-
scribed in Equation (2).
</bodyText>
<equation confidence="0.762883666666667">
N vector
*log ,
vf (tj )
</equation>
<bodyText confidence="0.999210166666667">
where Nvector denotes the total number of vectors,
and vf (tj ) denotes the number of vectors with tj
as the dimension. After each dimension is re-
weighted, the HAL space is transformed into a
probabilistic framework. Accordingly, each
weight can be redefined as
</bodyText>
<equation confidence="0.97954">
wc t
i j
wcitj ≡ P(tj  |ci) = ∑ wcitj, (3)
j
</equation>
<bodyText confidence="0.9997645">
where P(tj  |ci) is the probability that t j appears
in the vector of ci .
</bodyText>
<subsectionHeader confidence="0.997205">
3.2 Concept Combination
</subsectionHeader>
<bodyText confidence="0.999161142857143">
A semantic pattern is constituted by a set of con-
cepts, thus it can be represented through concept
combination over the HAL space. This forms a
new concept in the HAL space. Let
sp = (c1,...,cS) be a semantic pattern with S con-
stituent concepts, i.e., length S. The concept
combination is defined as
</bodyText>
<equation confidence="0.9981675">
⊕c ≡ c ⊕ c ⊕ c ⊕ ⊕ cS (4)
s ((...( 1 2) 3) ... ),
</equation>
<bodyText confidence="0.999249333333333">
where ⊕ denotes the symbol representing the
combination operator over the HAL space, ⊕cs
denotes a new concept generated by the concept
combination. The new concept is the representa-
tion of a semantic pattern, also a vector represen-
tation. That is,
</bodyText>
<figure confidence="0.674228066666667">
c v v
( , )
left right
⊕ =
s ⊕ c ⊕c
s s
left right right
( w left
= , . . . , w , w , . . . , w ( ) ) ,
( ) 1
⊕ c t ( )
⊕ c t ( ) 1
⊕ c t ⊕c t
s s N s s N
(5)
</figure>
<bodyText confidence="0.997417333333333">
The combination operator, ⊕ , is implemented
by the product of the weights of the constituent
concepts, described as follows.
</bodyText>
<equation confidence="0.996128142857143">
S
w = ∏ w
( )
⊕ c t c t
s j s j
(6)
P(tj  |cs ),
</equation>
<bodyText confidence="0.9999805">
where w(⊕cs)tj denotes the weight of the j-th di-
mension of the new concept ⊕ cs .
</bodyText>
<sectionHeader confidence="0.994775" genericHeader="method">
4 Cascaded Induction Process
</sectionHeader>
<bodyText confidence="0.999767">
Given a seed pattern, the CIP is to induce a set of
relevant semantic patterns with variable lengths
(from 2 to k). Let spseed = (c1 ,..., cR) be a seed
pattern of length R, and sp = (c1,..., cS) be a
semantic pattern of length S. The formal
description of the CIP is presented as
</bodyText>
<equation confidence="0.99913025">
sp  |−
seed
≡ (c1 , ... ,cR) |— {(c1,...,cS)) iff ∀ Dist( ⊕cr,⊕cs)≤λ,
(7)
</equation>
<bodyText confidence="0.993583857142857">
where  |− denotes the symbol representing the
cascaded induction, ⊕cr and ⊕cs are the two
new concepts representing spseed and sp , respec-
tively, and Dist( • , • ) represents the distance
between two semantic patterns. The main steps
in the CIP include the initial set generation, dis-
tance measure, and relevance feedback.
</bodyText>
<subsectionHeader confidence="0.95939">
4.1 Initial Set Generation
</subsectionHeader>
<bodyText confidence="0.9998385">
The initial set for a particular length contains a
set of semantic patterns to be induced, i.e., the
search space. Reducing the search space would
be helpful for speeding up the induction process,
</bodyText>
<figure confidence="0.99311395">
cN
c1
.
.
.
Left Context
wleft ... wleftc1t1 c1 N
wcitj = wcitj
(2)
1
=
s
S
=
∏
1
=
s
{ }
sp
</figure>
<page confidence="0.991037">
948
</page>
<bodyText confidence="0.999952333333333">
especially for inducing those patterns with a lar-
ger length. For this purpose, we consider that the
words and the semantic patterns similar to a
given seed pattern are the better candidates for
creating the initial sets. Therefore, we generate
quality concepts, a set of semantically related
words to a seed pattern, as the basis to create the
initial set for each length. Thus, each seed pattern
will be associated with a set of quality concepts.
In addition, the better semantic patterns induced
in the previous stage are also considered. The
goodness of words and semantic patterns is
measured by their distance to a seed pattern.
Here, a word is considered as a quality concept if
its distance is smaller than the average distance
of the vocabulary. Similarly, only the semantic
patterns with a distance smaller than the average
distance of all semantic patterns in the previous
stage are preserved to the next stage. By the way,
the semantically unrelated patterns, possibly
noisy patterns, will not be propagated to the next
stage, and the search space can also be reduced.
The principles of creating the initial sets of se-
mantic patterns are summarized as follows.
</bodyText>
<listItem confidence="0.995084">
• In the beginning stage, the aim is to cre-
ate the initial set for the semantic pat-
terns with length two. Thus, the initial
set is the all possible combinations of
two quality concepts.
• In the latter stages, each initial set is cre-
ated by adding a quality concept to each
of the better semantic patterns induced in
the previous stage.
</listItem>
<subsectionHeader confidence="0.984971">
4.2 Distance Measure
</subsectionHeader>
<bodyText confidence="0.9992278">
The distance measure is to measure the distance
between the seed patterns and semantic patterns
to be induced. Let sp = (c1 ,..., cS) be a semantic
pattern and spseed =(c1,...,cR) be a given seed
pattern, their distance is defined as
</bodyText>
<equation confidence="0.762926">
Dist (sp,spseed)=Dist(®cs,®cr), (8)
</equation>
<bodyText confidence="0.999835555555555">
where Dist(®cs,®cr) denotes the distance be-
tween two semantic patterns in the HAL space.
As mentioned earlier, after concept combination,
a semantic pattern becomes a new concept in the
HAL space, which means the semantic pattern
can be represented by its left and right contexts.
Thus, the distance between two semantic patterns
can be computed through their context distance.
Equation (8) thereby can be written as
</bodyText>
<footnote confidence="0.261167">
Dist (sp,p s )=Dist(vle v.&apos;I )+Dist(vRight vRight) (9)
seed ®j s,®cr ®cs , ®cr
</footnote>
<bodyText confidence="0.9999595">
Because the weights of the vectors are repre-
sented using a probabilistic framework, each
vector of a concept can be considered as a prob-
abilistic distribution of the context words. Ac-
cordingly, we use the Kullback-Liebler (KL) dis-
tance (Manning and Schütze, 1999) to compute
the distance between two probabilistic distribu-
tions, as shown in the following.
</bodyText>
<equation confidence="0.88147225">
N P(tj s
®C)
D(v® cs %cr)=ZP(tj ED c.) ,
j=1 P(ti ®c,)
</equation>
<bodyText confidence="0.995628428571429">
where D( • • ) denotes the KL distance be-
tween two probabilistic distributions. When
Equation (10) is ill-conditioned, i.e., zero de-
nominator, the denominator will be set to a small
value (10-6). For the consideration of a symmet-
ric distance, we use the divergence measure,
shown as follows.
</bodyText>
<equation confidence="0.9803">
Div v®cs v®cr =D v®cs v®cr +D v®cr v®cs (11)
( , ) ( ) ( ).
</equation>
<bodyText confidence="0.938253333333333">
By this way, the distance between two probabil-
istic distributions can be computed by their KL
divergence. Thus, Equation (9) becomes
</bodyText>
<equation confidence="0.8440055">
Dist(v ,V )=Div(vleft ,Vleft )+Div(vRight�vRight). (12)
®cs ®cr ®cs ®cr ®cs ®cr
</equation>
<bodyText confidence="0.9586845">
After each semantic pattern is evaluated, a
ranked list is produced for relevance judgment.
</bodyText>
<subsectionHeader confidence="0.996244">
4.3 Relevance Feedback
</subsectionHeader>
<bodyText confidence="0.999989833333333">
In the induction process, some non-relevant se-
mantic patterns may have smaller distance to a
seed pattern, which may decrease the precision
of the final results. To overcome the problem,
one possible solution is to incorporate expert
knowledge to guide the induction process. For
this purpose, we use the technique of relevance
feedback. In the IR community, the relevance
feedback is to enhance the original query from
the users by indicating which retrieved docu-
ments are relevant. For our task, the relevance
feedback is applied after each semantic pattern is
evaluated. Then, the health professionals judge
which semantic patterns are relevant to the seed
pattern. In practice, only the top n semantic pat-
terns are presented for relevance judgment. Fi-
nally, the semantic patterns judged as relevant
are considered to form the relevant set, and the
others form the non-relevant set. According to
the relevant and non-relevant information, the
seed pattern can be refined to be more similar to
the relevant set, such that the induction process
can induce more relevant patterns and move
away from noisy patterns in the future iterations.
</bodyText>
<equation confidence="0.795765">
(10)
</equation>
<page confidence="0.990638">
949
</page>
<bodyText confidence="0.999930444444444">
The refinement of the seed pattern is to adjust
its context distributions (left and right). Such ad-
justment is based on re-weighting the dimensions
of the context vectors of the seed pattern. The
dimensions more frequently regarded as relevant
patterns are more significant for identifying rele-
vant patterns. Hence, such dimensions of the
seed pattern should be emphasized. The signifi-
cance of a dimension is measured as follows.
</bodyText>
<equation confidence="0.988815142857143">
⊕ ∈
c R
i
(tk) =
w(⊕cj )tk
⊕ c R
j∈
</equation>
<bodyText confidence="0.977936863636364">
where Sig(tk) denotes the significance of the di-
mension tk , ⊕ci and ⊕cj denote the semantic
patterns of the relevant set and non-relevant set,
respectively, and w(⊕ci)tk and w(⊕cj)tk denote the
weights of tk of ⊕ci and ⊕cj , respectively. The
higher the ratio, the more significant the dimen-
sion is. In order to smooth Sig(tk) to the range
from zero to one, the following formula is used:
The corresponding dimension of the seed pattern
spseed = ⊕ cr is then re-weighted by
w(⊕cr)tk =w(⊕cr)tk +Sig(tk). (15)
Once the context vectors of the seed pattern
are re-weighted, they are also transformed into a
probabilistic form using Equation (3). The re-
fined seed pattern will be taken as the reference
basis in the next iteration. The relevance feed-
back is performed iteratively until no more se-
mantic patterns are judged as relevant or a
maximum number of iteration is reached. At the
same time, the induction process for a particular
length is also stopped. The whole CIP process is
stopped until the seed patterns are exhausted
</bodyText>
<sectionHeader confidence="0.992039" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.99998652173913">
To evaluate the performance of the CIP, we built
a prototype system and provided a set of seed
patterns. The seed patterns were collected by re-
ferring to the well-defined instruments for as-
sessing negative life events (Brostedt and Peder-
sen, 2003; Pagano et al., 2004). A total of 20
seed patterns were selected by the health profes-
sionals. Then, the CIP randomly selects one seed
pattern per run without replacement from the
seed set, and iteratively induces relevant patterns
from the psychiatry web corpora. The psychiatry
web corpora used here include some professional
mental health web sites, such as PsychPark
(http://www.psychpark.org) (Bai, 2001) and John
Tung Foundation (http://www.jtf.org.tw).
In the following sections, we describe some
experiments to in turn examine the effect of us-
ing relevance feedback or not, and the coverage
on real data using the semantic patterns induced
by different approaches. Because the semantic
patterns with a length larger than 4 are very rare
to express a negative life event, we limit the
length k to the range of 2 to 4.
</bodyText>
<subsectionHeader confidence="0.997231">
5.1 Evaluation on Relevance Feedback
</subsectionHeader>
<bodyText confidence="0.9999465">
The relevance feedback employed in this study
provides the relevant and non-relevant informa-
tion for the CIP so that it can refine the seed pat-
tern to induce more relevant patterns. The rele-
vance judgment is carried out by three experi-
enced psychiatric physicians. For practical con-
sideration, only the top 30 semantic patterns are
presented to the physicians. During relevance
judgment, a majority vote mechanism is used to
handle the disagreements among the physicians.
That is, a semantic pattern is considered as rele-
vant if any two or more physicians judged it as
relevant. Finally, the semantic patterns with ma-
jority votes are obtained to form the relevant set.
To evaluate the effectiveness of the relevance
feedback, we construct three variants of the CIP,
RF(5), RF(10), and RF(20), implemented by ap-
plying the relevance feedback for 5, 10, and 20
iterations, respectively. These three CIP variants
are then compared to the one without using the
relevance feedback, denoted as RF(-). We use
the evaluation metric, precision at 30 (prec@30),
over all seed patterns to examine if the relevance
feedback can help the CIP induce more relevant
patterns. For a particular seed pattern, prec@n is
computed as the number of relevant semantic
patterns ranked in the top n of the ranked list,
divided by n. Table 2 presents the results for k=2.
The results reveal that the relevance feedback
can help the CIP induce more relevant semantic
patterns. Another observation indicates that ap-
plying the relevance feedback for more iterations
</bodyText>
<table confidence="0.911968">
RF(-) RF(5) RF(10) RF(20)
prec@30 0.203 0.263 0.318 0.387
</table>
<tableCaption confidence="0.9477065">
Table 2. Effect of applying relevance feedback
for different number of iterations or not.
</tableCaption>
<figure confidence="0.9923795">
tk
w( )
⊕ c i
∑
Sig
(13)
Sig
1
(tk) =
1
⎛ ⎞
⎜∑ ∑ ⎟
( )
c t ( )
c t
+ ⎜ w w
⊕ ⊕
i k j k ⎟
⊕ci∈R ⊕cj∈R
⎝ ⎠
.
− 1
(14)
950
0 5 10 15 20 25 30 35 40 45 50
Num. of Iterations
</figure>
<figureCaption confidence="0.9976315">
Figure 4. Effect of using the combination of rele-
vance feedback and pseudo-relevance feedback.
</figureCaption>
<bodyText confidence="0.999977911764706">
can further improve the precision. However, it is
usually impractical for experts to involve in the
guiding process for too many iterations. Conse-
quently, we further consider pseudo-relevance
feedback to automate the guiding process. The
pseudo-relevance feedback carries out the rele-
vance judgment based on the assumption that the
top ranked semantic patterns are more likely to
be the relevant ones. Thus, this approach usually
relies on setting a threshold or selecting only the
top n semantic patterns to form the relevant set.
However, determining the threshold is not trivial,
and the threshold may be different with different
seed patterns. Therefore, we apply the pseudo-
relevance feedback only after certain expert-
guided iterations, rather than applying it
throughout the induction process. The notion is
that we can get a more reliable threshold value
by observing the behavior of the relevant seman-
tic patterns in the ranked list for a few iterations.
To further examine the effectiveness of the
combined approach, we additionally construct a
CIP variant, RF(10)+pseudo, by applying the
pseudo-relevance feedback after 10 expert-
guided iterations. The threshold is determined by
the physicians during their judgments in the 10-
th iteration. The results are presented in Figure 4.
The precision of RF(10)+pseudo is inferior to
that of RF(20) before the 25-th iteration. Mean-
while, after the 30-th iteration, RF(10)+pseudo
achieves higher precision than the other methods.
This indicates that the pseudo-relevance feed-
back can also contribute to semantic pattern in-
duction in the stage without expert intervention.
</bodyText>
<subsectionHeader confidence="0.998972">
5.2 Coverage on Real Data
</subsectionHeader>
<bodyText confidence="0.998273666666667">
The final results of the semantic patterns are the
relevant sets of the last iteration produced by
RF(10)+pseudo, denoted as SPCIP . Parts of them
</bodyText>
<table confidence="0.8717186">
are shown in Table 3.
Seed &lt; boyfriend, argue &gt;
Pattern
Induced &lt;girlfriend, break up&gt;; &lt;friend, fight&gt;
Patterns
</table>
<tableCaption confidence="0.904016">
Table 3. Parts of induced semantic patterns.
</tableCaption>
<bodyText confidence="0.975527642857143">
We compare SPCIP to those created by a
corpus-based approach. The corpus-based ap-
proach relies on an annotated domain corpus and
a learning mechanism to induce the semantic
patterns. Thus, we collected 300 consultation
records from the PsychPark as the domain corpus,
and each sentence in the corpus is annotated with
a negative life event or not by the three physi-
cians. After the annotation process, the sentences
with negative life events are together to form the
training set. Then, we adopt Mutual Information
(Manning and Schütze, 1999) to learn variable-
length semantic patterns. The mutual information
between k words is defined as
</bodyText>
<equation confidence="0.9974342">
MI(w1, ... ,wk) = P(w1, ... , wk)log
∏ ( )
P w
i
1
</equation>
<bodyText confidence="0.997446193548387">
where P(w1,...wk) is the probability of the k
words co-occurring in a sentence in the training
set, and P(wi ) is the probability of a single word
occurring in the training set. Higher mutual in-
formation indicates that the k words are more
likely to form a semantic pattern of length k.
Here the length k also ranges from 2 to 4. For
each k, we compute the mutual information for
all possible combinations of words in the training
set, and those with their mutual information
above a threshold are selected to be the final re-
sults of the semantic patterns, denoted as SPMI.
In order to obtain reliable mutual information
values, only words with at least the minimum
number of occurrences (&gt;5) are considered.
To examine the coverage of SPCIP and SPMI on
real data, 15 human subjects are involved in cre-
ating a test set. The subjects provide their experi-
enced negative life events in the form of natural
language sentences. A total of 69 sentences are
collected to be the test set, of which 39 sentences
contain a semantic pattern of length two, 21 sen-
tences contain a semantic pattern of length three,
and 9 sentences contain a semantic pattern of
length four. The evaluation metric used is out-of-
pattern (OOP) rate, a ratio of unseen patterns
occurring in the test set. Thus, the OOP can be
defined as the number of test sentences contain-
ing the semantic patterns not occurring in the
training set, divided by the total number of sen-
tences in the test set. Table 4 presents the results.
</bodyText>
<figure confidence="0.96032525">
Prec@30
0.45
0.35
0.25
0.15
0.4
0.3
0.2
RF(10)+pseudo
RF(20)
RF(─)
P(w1, ... , wk)
k
(16)
i
=
</figure>
<page confidence="0.979183">
951
</page>
<table confidence="0.909387333333333">
k=2 k=3 k=4
SPCIP 0.36 (14/39) 0.48 (10/21) 0.44 (4/9)
SPMI 0.51 (20/39) 0.62 (13/21) 0.67 (6/9)
</table>
<tableCaption confidence="0.7538095">
Table 4. OOP rate of the CIP and a corpus-based
approach.
</tableCaption>
<bodyText confidence="0.999721882352941">
The results show that the OOP of SPMI is
higher than that of SPCIP . The main reason is the
lack of a large enough domain corpus with anno-
tated life events. In this circumstance, many se-
mantic patterns, especially for those with a larger
length, could not be learned, because the number
of their occurrences would be very rare in the
training set. With no doubt, one could collect a
large amount of domain corpus to reduce the
OOP rate. However, increasing the amount of
domain corpus also increases the amount of an-
notation and computation complexity. Our ap-
proach, instead, exploits the quality concepts to
reduce the search space, also applies the rele-
vance feedback to guide the induction process,
thus it can achieve better results with time-
limited constraints.
</bodyText>
<sectionHeader confidence="0.999503" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999994421052632">
This study has presented an HAL-based cascaded
model for variable-length semantic pattern in-
duction. The HAL model provides an informa-
tive infrastructure for the CIP to induce semantic
patterns from the unannotated psychiatry web
corpora. Using the quality concepts and preserv-
ing the better results from the previous stage, the
search space can be reduced to speed up the in-
duction process. In addition, combining the rele-
vance feedback and pseudo-relevance feedback,
the induction process can be guided to induce
more relevant semantic patterns. The experimen-
tal results demonstrated that our approach can
not only reduce the reliance on annotated corpora
but also obtain acceptable results with time-
limited constraints. Future work will be devoted
to investigating the detection of negative life
events using the induced patterns so as to make
the psychiatric services more effective.
</bodyText>
<sectionHeader confidence="0.99948" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999975866666667">
R. Baeza-Yates and B. Ribeiro-Neto. 1999. Modern
Information Retrieval. Addison-Wesley, Reading,
MA.
Y. M. Bai, C. C. Lin, J. Y. Chen, and W. C. Liu. 2001.
Virtual Psychiatric Clinics. American Journal of
Psychiatry, 158(7):1160-1161.
J. Bai, D. Song, P. Bruza, J. Y. Nie, and G. Cao. 2005.
Query Expansion Using Term Relationships in
Language Models for Information Retrieval. In
Proc. of the 14th ACM International Conference
on Information and Knowledge Management,
pages 688-695.
E. M. Brostedt and N. L. Pedersen. 2003. Stressful
Life Events and Affective Illness. Acta Psychiat-
rica Scandinavica, 107:208-215.
C. Burgess, K. Livesay, and K. Lund. 1998. Explora-
tions in Context Space: Words, Sentences, Dis-
course. Discourse Processes. 25(2&amp;3):211-257.
C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database. Cambridge, MA: MIT Press.
T. Grenager, D. Klein, and C. D. Manning. 2005. Un-
supervised Learning of Field Segmentation Models
for Information Extraction. In Proc. of the 43th
Annual Meeting of the ACL, pages 371-378.
T. Hasegawa, S. Sekine, R. Grishman. 2004. Discov-
ering Relations among Named Entities from Large
Corpora. In Proc. of the 42th Annual Meeting of
the ACL, pages 415-422.
W.Lehnert, C. Cardie, D. Fisher, J. McCarthy, E.
Riloff, and S. Soderland. 1992. University of Mas-
sachusetts: Description of the CIRCUS System
used for MUC-4. In Proc. of the Fourth Message
Understanding Conference, pages 282-288.
C. Manning and H. Schütze. 1999. Foundations of
Statistical Natural Language Processing. MIT
Press. Cambridge, MA.
I. Muslea. 1999. Extraction Patterns for Information
Extraction Tasks: A Survey. In Proc. of the AAAI-
99 Workshop on Machine Learning for Information
Extraction, pages 1-6.
M. E. Pagano, A. E. Skodol, R. L. Stout, M. T. Shea,
S. Yen, C. M. Grilo, C.A. Sanislow, D. S. Bender,
T. H. McGlashan, M. C. Zanarini, and J. G. Gun-
derson. 2004. Stressful Life Events as Predictors of
Functioning: Findings from the Collaborative Lon-
gitudinal Personality Disorders Study. Acta Psy-
chiatrica Scandinavica, 110:421-429.
M. Stevenson and M. A. Greenwood. 2005. A Seman-
tic Approach to IE Pattern Induction. In Proc. of
the 43th Annual Meeting of the ACL, pages 379-
386.
C. H. Wu, L. C. Yu, and F. L. Jang. 2005. Using Se-
mantic Dependencies to Mine Depressive Symp-
toms from Consultation Records. IEEE Intelligent
System, 20(6):50-58.
J. F. Yeh, C. H. Wu, M. J. Chen, and L. C. Yu. 2004.
Automated Alignment and Extraction of Bilingual
Domain Ontology for Cross-Language Domain-
Specific Applications. In Proc. of the 20th COL-
ING, pages 1140-1146.
</reference>
<page confidence="0.997576">
952
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.630520">
<title confidence="0.9736515">HAL-based Cascaded Model for Variable-Length Semantic Pattern Induction from Psychiatry Web Resources</title>
<author confidence="0.999918">Yu Wu</author>
<affiliation confidence="0.9997165">Department of Computer Science and Information Engineering National Cheng Kung University</affiliation>
<address confidence="0.992314">Tainan, Taiwan, R.O.C.</address>
<email confidence="0.949621">lcyu@csie.ncku.edu.tw</email>
<email confidence="0.949621">chwu@csie.ncku.edu.tw</email>
<author confidence="0.99836">Fong-Lin Jang</author>
<affiliation confidence="0.999364">Department of Psychiatry Chi-Mei Medical Center</affiliation>
<address confidence="0.965517">Tainan, Taiwan, R.O.C.</address>
<email confidence="0.902534">jcj0429@seed.net.tw</email>
<abstract confidence="0.992210925925926">Negative life events play an important role in triggering depressive episodes. Developing psychiatric services that can automatically identify such events is beneficial for mental health care and prevention. Before these services can be provided, some meaningful semantic patterns, such as &lt;lost, parents&gt;, have to be extracted. In this work, we present a text mining framework capable of inducing variable-length semantic patterns from web resources. This framework integrates a cognitive model, Analog to to represent words as well as combinations of words. Then, a cascaded induction process (CIP) bootstraps with a small set of seed patterns incorporates feedback iteratively induce more relevant patterns. The experimental results show that by combining the HAL model and relevance feedback, the CIP can induce semantic patterns from the unannotated web corpora so as to reduce the reliance on annotated corpora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Baeza-Yates</author>
<author>B Ribeiro-Neto</author>
</authors>
<title>Modern Information Retrieval.</title>
<date>1999</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, MA.</location>
<contexts>
<context position="7908" citStr="Baeza-Yates and Ribeiro-Neto, 1999" startWordPosition="1212" endWordPosition="1215">n, the HAL model provides a mechanism to combine its constituent words over the HAL space. Once the HAL space is constructed, the CIP takes as input a seed pattern per run, and in turn induces the semantic patterns of different lengths. For each length, the CIP first creates the initial set based on the results of the previous stage. Then, the induction process is iteratively performed to induce more patterns relevant to the given seed pattern by comparing their context distributions. In addition, we also incorporate expert knowledge to guide the induction process by using relevance feedback (Baeza-Yates and Ribeiro-Neto, 1999), the most popular query reformulation strategy in the information retrieval (IR) community. The induction process is terminated until the termination criteria are satisfied. In the remainder of this paper, Section 2 presents the overall framework for variable-length semantic pattern induction. Section 3 describes the process of constructing the HAL space. Section 4 details the cascaded induction process. Section 5 summarizes the experiment results. Finally, Section 6 draws some conclusions and suggests directions for future work. 2 Framework for Variable-Length Semantic Pattern Induction The </context>
<context position="13518" citStr="Baeza-Yates and Ribeiro-Neto, 1999" startWordPosition="2203" endWordPosition="2206">heme of the HAL model is frequency-based. For some extremely infrequent words, we consider them as noises and remove them from the vocabulary. On the other hand, a high frequent word tends to get a higher weight, but this does not mean the word is informative, because it may also appear in many other vectors. Thus, to measure the informativeness of a word, the number of the vectors the word appears in should be taken into account. In principle, the more vectors the word appears in, the less information it carries to discriminate the vectors. Here we use a weighting scheme analogous to TF-IDF (Baeza-Yates and Ribeiro-Neto, 1999) to reweight the dimensions of each vector, as described in Equation (2). N vector *log , vf (tj ) where Nvector denotes the total number of vectors, and vf (tj ) denotes the number of vectors with tj as the dimension. After each dimension is reweighted, the HAL space is transformed into a probabilistic framework. Accordingly, each weight can be redefined as wc t i j wcitj ≡ P(tj |ci) = ∑ wcitj, (3) j where P(tj |ci) is the probability that t j appears in the vector of ci . 3.2 Concept Combination A semantic pattern is constituted by a set of concepts, thus it can be represented through concep</context>
</contexts>
<marker>Baeza-Yates, Ribeiro-Neto, 1999</marker>
<rawString>R. Baeza-Yates and B. Ribeiro-Neto. 1999. Modern Information Retrieval. Addison-Wesley, Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y M Bai</author>
<author>C C Lin</author>
<author>J Y Chen</author>
<author>W C Liu</author>
</authors>
<title>Virtual Psychiatric Clinics.</title>
<date>2001</date>
<journal>American Journal of Psychiatry,</journal>
<pages>158--7</pages>
<marker>Bai, Lin, Chen, Liu, 2001</marker>
<rawString>Y. M. Bai, C. C. Lin, J. Y. Chen, and W. C. Liu. 2001. Virtual Psychiatric Clinics. American Journal of Psychiatry, 158(7):1160-1161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bai</author>
<author>D Song</author>
<author>P Bruza</author>
<author>J Y Nie</author>
<author>G Cao</author>
</authors>
<title>Query Expansion Using Term Relationships in Language Models for Information Retrieval.</title>
<date>2005</date>
<booktitle>In Proc. of the 14th ACM International Conference on Information and Knowledge Management,</booktitle>
<pages>688--695</pages>
<contexts>
<context position="5912" citStr="Bai et al., 2005" startWordPosition="875" endWordPosition="878">ombinations of words from the web corpora, and then search for the semantic patterns. To address the problems, we take the notion of weakly supervised (Stevenson and Greenwood, 2005) or unsupervised learning (Hasegawa, 2004; Grenager et al., 2005) to develop a framework able to bootstrap with a small set of seed patterns, and then induce more relevant patterns form the unannotated psychiatry web corpora. By this way, the reliance on annotated corpora can be significantly reduced. The proposed framework is divided into two parts: Hyperspace Analog to Language (HAL) model (Burgess et al., 1998; Bai et al., 2005), and a cascaded induction process (CIP). The HAL model, which is a cognitive motivated model, provides an informative infrastructure to make the CIP capable of learning from unannotated corpora. The CIP treats the variable-length induction task as a cascaded process. That is, it first induces the semantic patterns of length two, then length three, and so on. In each stage, the CIP initializes the set of semantic patterns to be induced based on the better results of the previous stage, rather than enumerating all possible combinations of words. This would be helpful to avoid noisy patterns pro</context>
</contexts>
<marker>Bai, Song, Bruza, Nie, Cao, 2005</marker>
<rawString>J. Bai, D. Song, P. Bruza, J. Y. Nie, and G. Cao. 2005. Query Expansion Using Term Relationships in Language Models for Information Retrieval. In Proc. of the 14th ACM International Conference on Information and Knowledge Management, pages 688-695.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Brostedt</author>
<author>N L Pedersen</author>
</authors>
<date>2003</date>
<booktitle>Stressful Life Events and Affective Illness. Acta Psychiatrica Scandinavica,</booktitle>
<pages>107--208</pages>
<contexts>
<context position="22360" citStr="Brostedt and Pedersen, 2003" startWordPosition="3788" endWordPosition="3792">ll be taken as the reference basis in the next iteration. The relevance feedback is performed iteratively until no more semantic patterns are judged as relevant or a maximum number of iteration is reached. At the same time, the induction process for a particular length is also stopped. The whole CIP process is stopped until the seed patterns are exhausted 5 Experimental Results To evaluate the performance of the CIP, we built a prototype system and provided a set of seed patterns. The seed patterns were collected by referring to the well-defined instruments for assessing negative life events (Brostedt and Pedersen, 2003; Pagano et al., 2004). A total of 20 seed patterns were selected by the health professionals. Then, the CIP randomly selects one seed pattern per run without replacement from the seed set, and iteratively induces relevant patterns from the psychiatry web corpora. The psychiatry web corpora used here include some professional mental health web sites, such as PsychPark (http://www.psychpark.org) (Bai, 2001) and John Tung Foundation (http://www.jtf.org.tw). In the following sections, we describe some experiments to in turn examine the effect of using relevance feedback or not, and the coverage o</context>
</contexts>
<marker>Brostedt, Pedersen, 2003</marker>
<rawString>E. M. Brostedt and N. L. Pedersen. 2003. Stressful Life Events and Affective Illness. Acta Psychiatrica Scandinavica, 107:208-215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Burgess</author>
<author>K Livesay</author>
<author>K Lund</author>
</authors>
<date>1998</date>
<booktitle>Explorations in Context Space: Words, Sentences, Discourse. Discourse Processes.</booktitle>
<pages>25--2</pages>
<contexts>
<context position="5893" citStr="Burgess et al., 1998" startWordPosition="871" endWordPosition="874">umerate all possible combinations of words from the web corpora, and then search for the semantic patterns. To address the problems, we take the notion of weakly supervised (Stevenson and Greenwood, 2005) or unsupervised learning (Hasegawa, 2004; Grenager et al., 2005) to develop a framework able to bootstrap with a small set of seed patterns, and then induce more relevant patterns form the unannotated psychiatry web corpora. By this way, the reliance on annotated corpora can be significantly reduced. The proposed framework is divided into two parts: Hyperspace Analog to Language (HAL) model (Burgess et al., 1998; Bai et al., 2005), and a cascaded induction process (CIP). The HAL model, which is a cognitive motivated model, provides an informative infrastructure to make the CIP capable of learning from unannotated corpora. The CIP treats the variable-length induction task as a cascaded process. That is, it first induces the semantic patterns of length two, then length three, and so on. In each stage, the CIP initializes the set of semantic patterns to be induced based on the better results of the previous stage, rather than enumerating all possible combinations of words. This would be helpful to avoid</context>
</contexts>
<marker>Burgess, Livesay, Lund, 1998</marker>
<rawString>C. Burgess, K. Livesay, and K. Lund. 1998. Explorations in Context Space: Words, Sentences, Discourse. Discourse Processes. 25(2&amp;3):211-257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="3955" citStr="Fellbaum, 1998" startWordPosition="584" endWordPosition="585">ely on exploiting expert knowledge to design handcrafted semantic patterns. The major limitations of such approaches include the requirement of significant time and effort on designing the handcrafted patterns. Besides, when applying to a new domain, these patterns have to be redesigned. Such limitations form a knowledge acquisition bottleneck. A possible solution to reducing the problem is to use a general-purpose ontology 945 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 945–952, Sydney, July 2006. c�2006 Association for Computational Linguistics such as WordNet (Fellbaum, 1998), or a domainspecific ontology constructed using automatic approaches (Yeh et al., 2004). These ontologies contain rich concepts and inter-concept relations such as hypernymy-hyponymy relations. However, an ontology is a static knowledge resource, which may not reflect the dynamic characteristics of language. For this consideration, we instead refer to the web resources, or more restrictedly, the psychiatry web resources as our knowledge resource. Corpus-based approaches can automatically learn semantic patterns from domain corpora by applying statistical methods. The corpora have to be annota</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet: An Electronic Lexical Database. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Grenager</author>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Unsupervised Learning of Field Segmentation Models for Information Extraction.</title>
<date>2005</date>
<booktitle>In Proc. of the 43th Annual Meeting of the ACL,</booktitle>
<pages>371--378</pages>
<contexts>
<context position="5542" citStr="Grenager et al., 2005" startWordPosition="815" endWordPosition="818">For some application domains, such annotated corpora may be unavailable. Therefore, we propose the use of web resources as the corpora. When facing with the web corpora, traditional corpus-based approaches may be infeasible. For example, it is impractical for health professionals to annotate the whole web corpora. Besides, it is also impractical to enumerate all possible combinations of words from the web corpora, and then search for the semantic patterns. To address the problems, we take the notion of weakly supervised (Stevenson and Greenwood, 2005) or unsupervised learning (Hasegawa, 2004; Grenager et al., 2005) to develop a framework able to bootstrap with a small set of seed patterns, and then induce more relevant patterns form the unannotated psychiatry web corpora. By this way, the reliance on annotated corpora can be significantly reduced. The proposed framework is divided into two parts: Hyperspace Analog to Language (HAL) model (Burgess et al., 1998; Bai et al., 2005), and a cascaded induction process (CIP). The HAL model, which is a cognitive motivated model, provides an informative infrastructure to make the CIP capable of learning from unannotated corpora. The CIP treats the variable-length</context>
</contexts>
<marker>Grenager, Klein, Manning, 2005</marker>
<rawString>T. Grenager, D. Klein, and C. D. Manning. 2005. Unsupervised Learning of Field Segmentation Models for Information Extraction. In Proc. of the 43th Annual Meeting of the ACL, pages 371-378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hasegawa</author>
<author>S Sekine</author>
<author>R Grishman</author>
</authors>
<title>Discovering Relations among Named Entities from Large Corpora.</title>
<date>2004</date>
<booktitle>In Proc. of the 42th Annual Meeting of the ACL,</booktitle>
<pages>415--422</pages>
<marker>Hasegawa, Sekine, Grishman, 2004</marker>
<rawString>T. Hasegawa, S. Sekine, R. Grishman. 2004. Discovering Relations among Named Entities from Large Corpora. In Proc. of the 42th Annual Meeting of the ACL, pages 415-422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cardie W Lehnert</author>
<author>D Fisher</author>
<author>J McCarthy</author>
<author>E Riloff</author>
<author>S Soderland</author>
</authors>
<date>1992</date>
<booktitle>University of Massachusetts: Description of the CIRCUS System used for MUC-4. In Proc. of the Fourth Message Understanding Conference,</booktitle>
<pages>282--288</pages>
<contexts>
<context position="3295" citStr="Lehnert et al., 1992" startWordPosition="488" endWordPosition="491"> symptom “Suicide”. A semantic pattern can be considered as a semantically plausible combination of k words, where k is the length of the pattern. Accordingly, a semantic pattern may have variable length. In Wu et al.’s study (2005), they have presented a methodology to identify depressive symptoms. In this work, we go a further step to devise a text mining framework for variable-length semantic pattern induction from psychiatry web resources. Traditional approaches to semantic pattern induction can be generally divided into two streams: knowledge-based approaches and corpus-based approaches (Lehnert et al., 1992; Muslea, 1999). Knowledge-based approaches rely on exploiting expert knowledge to design handcrafted semantic patterns. The major limitations of such approaches include the requirement of significant time and effort on designing the handcrafted patterns. Besides, when applying to a new domain, these patterns have to be redesigned. Such limitations form a knowledge acquisition bottleneck. A possible solution to reducing the problem is to use a general-purpose ontology 945 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 945–952, Sydney, July 2006. c�2006 Association fo</context>
</contexts>
<marker>Lehnert, Fisher, McCarthy, Riloff, Soderland, 1992</marker>
<rawString>W.Lehnert, C. Cardie, D. Fisher, J. McCarthy, E. Riloff, and S. Soderland. 1992. University of Massachusetts: Description of the CIRCUS System used for MUC-4. In Proc. of the Fourth Message Understanding Conference, pages 282-288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Manning</author>
<author>H Schütze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="18620" citStr="Manning and Schütze, 1999" startWordPosition="3160" endWordPosition="3163">ion, a semantic pattern becomes a new concept in the HAL space, which means the semantic pattern can be represented by its left and right contexts. Thus, the distance between two semantic patterns can be computed through their context distance. Equation (8) thereby can be written as Dist (sp,p s )=Dist(vle v.&apos;I )+Dist(vRight vRight) (9) seed ®j s,®cr ®cs , ®cr Because the weights of the vectors are represented using a probabilistic framework, each vector of a concept can be considered as a probabilistic distribution of the context words. Accordingly, we use the Kullback-Liebler (KL) distance (Manning and Schütze, 1999) to compute the distance between two probabilistic distributions, as shown in the following. N P(tj s ®C) D(v® cs %cr)=ZP(tj ED c.) , j=1 P(ti ®c,) where D( • • ) denotes the KL distance between two probabilistic distributions. When Equation (10) is ill-conditioned, i.e., zero denominator, the denominator will be set to a small value (10-6). For the consideration of a symmetric distance, we use the divergence measure, shown as follows. Div v®cs v®cr =D v®cs v®cr +D v®cr v®cs (11) ( , ) ( ) ( ). By this way, the distance between two probabilistic distributions can be computed by their KL diverg</context>
<context position="27667" citStr="Manning and Schütze, 1999" startWordPosition="4666" endWordPosition="4669">d, break up&gt;; &lt;friend, fight&gt; Patterns Table 3. Parts of induced semantic patterns. We compare SPCIP to those created by a corpus-based approach. The corpus-based approach relies on an annotated domain corpus and a learning mechanism to induce the semantic patterns. Thus, we collected 300 consultation records from the PsychPark as the domain corpus, and each sentence in the corpus is annotated with a negative life event or not by the three physicians. After the annotation process, the sentences with negative life events are together to form the training set. Then, we adopt Mutual Information (Manning and Schütze, 1999) to learn variablelength semantic patterns. The mutual information between k words is defined as MI(w1, ... ,wk) = P(w1, ... , wk)log ∏ ( ) P w i 1 where P(w1,...wk) is the probability of the k words co-occurring in a sentence in the training set, and P(wi ) is the probability of a single word occurring in the training set. Higher mutual information indicates that the k words are more likely to form a semantic pattern of length k. Here the length k also ranges from 2 to 4. For each k, we compute the mutual information for all possible combinations of words in the training set, and those with t</context>
</contexts>
<marker>Manning, Schütze, 1999</marker>
<rawString>C. Manning and H. Schütze. 1999. Foundations of Statistical Natural Language Processing. MIT Press. Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Muslea</author>
</authors>
<title>Extraction Patterns for Information Extraction Tasks: A Survey.</title>
<date>1999</date>
<booktitle>In Proc. of the AAAI99 Workshop on Machine Learning for Information Extraction,</booktitle>
<pages>1--6</pages>
<contexts>
<context position="3310" citStr="Muslea, 1999" startWordPosition="492" endWordPosition="493">semantic pattern can be considered as a semantically plausible combination of k words, where k is the length of the pattern. Accordingly, a semantic pattern may have variable length. In Wu et al.’s study (2005), they have presented a methodology to identify depressive symptoms. In this work, we go a further step to devise a text mining framework for variable-length semantic pattern induction from psychiatry web resources. Traditional approaches to semantic pattern induction can be generally divided into two streams: knowledge-based approaches and corpus-based approaches (Lehnert et al., 1992; Muslea, 1999). Knowledge-based approaches rely on exploiting expert knowledge to design handcrafted semantic patterns. The major limitations of such approaches include the requirement of significant time and effort on designing the handcrafted patterns. Besides, when applying to a new domain, these patterns have to be redesigned. Such limitations form a knowledge acquisition bottleneck. A possible solution to reducing the problem is to use a general-purpose ontology 945 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 945–952, Sydney, July 2006. c�2006 Association for Computational</context>
</contexts>
<marker>Muslea, 1999</marker>
<rawString>I. Muslea. 1999. Extraction Patterns for Information Extraction Tasks: A Survey. In Proc. of the AAAI99 Workshop on Machine Learning for Information Extraction, pages 1-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E Pagano</author>
<author>A E Skodol</author>
<author>R L Stout</author>
<author>M T Shea</author>
<author>S Yen</author>
<author>C M Grilo</author>
<author>C A Sanislow</author>
<author>D S Bender</author>
<author>T H McGlashan</author>
<author>M C Zanarini</author>
<author>J G Gunderson</author>
</authors>
<date>2004</date>
<booktitle>Stressful Life Events as Predictors of Functioning: Findings from the Collaborative Longitudinal Personality Disorders Study. Acta Psychiatrica Scandinavica,</booktitle>
<pages>110--421</pages>
<contexts>
<context position="22382" citStr="Pagano et al., 2004" startWordPosition="3793" endWordPosition="3796">basis in the next iteration. The relevance feedback is performed iteratively until no more semantic patterns are judged as relevant or a maximum number of iteration is reached. At the same time, the induction process for a particular length is also stopped. The whole CIP process is stopped until the seed patterns are exhausted 5 Experimental Results To evaluate the performance of the CIP, we built a prototype system and provided a set of seed patterns. The seed patterns were collected by referring to the well-defined instruments for assessing negative life events (Brostedt and Pedersen, 2003; Pagano et al., 2004). A total of 20 seed patterns were selected by the health professionals. Then, the CIP randomly selects one seed pattern per run without replacement from the seed set, and iteratively induces relevant patterns from the psychiatry web corpora. The psychiatry web corpora used here include some professional mental health web sites, such as PsychPark (http://www.psychpark.org) (Bai, 2001) and John Tung Foundation (http://www.jtf.org.tw). In the following sections, we describe some experiments to in turn examine the effect of using relevance feedback or not, and the coverage on real data using the </context>
</contexts>
<marker>Pagano, Skodol, Stout, Shea, Yen, Grilo, Sanislow, Bender, McGlashan, Zanarini, Gunderson, 2004</marker>
<rawString>M. E. Pagano, A. E. Skodol, R. L. Stout, M. T. Shea, S. Yen, C. M. Grilo, C.A. Sanislow, D. S. Bender, T. H. McGlashan, M. C. Zanarini, and J. G. Gunderson. 2004. Stressful Life Events as Predictors of Functioning: Findings from the Collaborative Longitudinal Personality Disorders Study. Acta Psychiatrica Scandinavica, 110:421-429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stevenson</author>
<author>M A Greenwood</author>
</authors>
<title>A Semantic Approach to IE Pattern Induction.</title>
<date>2005</date>
<booktitle>In Proc. of the 43th Annual Meeting of the ACL,</booktitle>
<pages>379--386</pages>
<contexts>
<context position="5477" citStr="Stevenson and Greenwood, 2005" startWordPosition="806" endWordPosition="809">e corpora with annotated information to obtain more reliable parameters. For some application domains, such annotated corpora may be unavailable. Therefore, we propose the use of web resources as the corpora. When facing with the web corpora, traditional corpus-based approaches may be infeasible. For example, it is impractical for health professionals to annotate the whole web corpora. Besides, it is also impractical to enumerate all possible combinations of words from the web corpora, and then search for the semantic patterns. To address the problems, we take the notion of weakly supervised (Stevenson and Greenwood, 2005) or unsupervised learning (Hasegawa, 2004; Grenager et al., 2005) to develop a framework able to bootstrap with a small set of seed patterns, and then induce more relevant patterns form the unannotated psychiatry web corpora. By this way, the reliance on annotated corpora can be significantly reduced. The proposed framework is divided into two parts: Hyperspace Analog to Language (HAL) model (Burgess et al., 1998; Bai et al., 2005), and a cascaded induction process (CIP). The HAL model, which is a cognitive motivated model, provides an informative infrastructure to make the CIP capable of lear</context>
</contexts>
<marker>Stevenson, Greenwood, 2005</marker>
<rawString>M. Stevenson and M. A. Greenwood. 2005. A Semantic Approach to IE Pattern Induction. In Proc. of the 43th Annual Meeting of the ACL, pages 379-386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Wu</author>
<author>L C Yu</author>
<author>F L Jang</author>
</authors>
<title>Using Semantic Dependencies to Mine Depressive Symptoms from Consultation Records.</title>
<date>2005</date>
<journal>IEEE Intelligent System,</journal>
<pages>20--6</pages>
<marker>Wu, Yu, Jang, 2005</marker>
<rawString>C. H. Wu, L. C. Yu, and F. L. Jang. 2005. Using Semantic Dependencies to Mine Depressive Symptoms from Consultation Records. IEEE Intelligent System, 20(6):50-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Yeh</author>
<author>C H Wu</author>
<author>M J Chen</author>
<author>L C Yu</author>
</authors>
<title>Automated Alignment and Extraction of Bilingual Domain Ontology for Cross-Language DomainSpecific Applications.</title>
<date>2004</date>
<booktitle>In Proc. of the 20th COLING,</booktitle>
<pages>1140--1146</pages>
<contexts>
<context position="4043" citStr="Yeh et al., 2004" startWordPosition="595" endWordPosition="598">limitations of such approaches include the requirement of significant time and effort on designing the handcrafted patterns. Besides, when applying to a new domain, these patterns have to be redesigned. Such limitations form a knowledge acquisition bottleneck. A possible solution to reducing the problem is to use a general-purpose ontology 945 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 945–952, Sydney, July 2006. c�2006 Association for Computational Linguistics such as WordNet (Fellbaum, 1998), or a domainspecific ontology constructed using automatic approaches (Yeh et al., 2004). These ontologies contain rich concepts and inter-concept relations such as hypernymy-hyponymy relations. However, an ontology is a static knowledge resource, which may not reflect the dynamic characteristics of language. For this consideration, we instead refer to the web resources, or more restrictedly, the psychiatry web resources as our knowledge resource. Corpus-based approaches can automatically learn semantic patterns from domain corpora by applying statistical methods. The corpora have to be annotated with domain-specific knowledge (e.g., events). Then, various statistical methods can</context>
</contexts>
<marker>Yeh, Wu, Chen, Yu, 2004</marker>
<rawString>J. F. Yeh, C. H. Wu, M. J. Chen, and L. C. Yu. 2004. Automated Alignment and Extraction of Bilingual Domain Ontology for Cross-Language DomainSpecific Applications. In Proc. of the 20th COLING, pages 1140-1146.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>