<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.48212">
Sentiment-Aspect Extraction based on Restricted Boltzmann Machines
</title>
<author confidence="0.988523">
Linlin Wang&apos;, Kang Liu2∗, Zhu Cao&apos;, Jun Zhao2 and Gerard de Melo&apos;
</author>
<affiliation confidence="0.987127">
&apos;Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China
2National Laboratory of Pattern Recognition, Institute of Automation,
Chinese Academy of Sciences, Beijing, China
</affiliation>
<email confidence="0.820291">
{ll-wang13, cao-z13}@mails.tsinghua.edu.cn,
{kliu, jzhao}@nlpr.ia.ac.cn, gdm@demelo.org
</email>
<sectionHeader confidence="0.997334" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999311166666667">
Aspect extraction and sentiment analysis
of reviews are both important tasks in
opinion mining. We propose a novel senti-
ment and aspect extraction model based on
Restricted Boltzmann Machines to jointly
address these two tasks in an unsupervised
setting. This model reflects the gener-
ation process of reviews by introducing
a heterogeneous structure into the hidden
layer and incorporating informative priors.
Experiments show that our model outper-
forms previous state-of-the-art methods.
</bodyText>
<sectionHeader confidence="0.999388" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999833791666667">
Nowadays, it is commonplace for people to ex-
press their opinion about various sorts of entities,
e.g., products or services, on the Internet, espe-
cially in the course of e-commerce activities. Ana-
lyzing online reviews not only helps customers ob-
tain useful product information, but also provide
companies with feedback to enhance their prod-
ucts or service quality. Aspect-based opinion min-
ing enables people to consider much more fine-
grained analyses of vast quantities of online re-
views, perhaps from numerous different merchant
sites. Thus, automatic identification of aspects of
entities and relevant sentiment polarities in Big
Data is a significant and urgent task (Liu, 2012;
Pang and Lee, 2008; Popescu and Etzioni, 2005).
Identifying aspect and analyzing sentiment
words from reviews has the ultimate goal of dis-
cerning people’s opinions, attitudes, emotions, etc.
towards entities such as products, services, orga-
nizations, individuals, events, etc. In this con-
text, aspect-based opinion mining, also known as
feature-based opinion mining, aims at extracting
and summarizing particular salient aspects of enti-
ties and determining relevant sentiment polarities
</bodyText>
<note confidence="0.401334">
∗Corresponding Author: Kang Liu (kliu@nlpr.ia.ac.cn)
</note>
<bodyText confidence="0.99993412195122">
from reviews (Hu and Liu, 2004). Consider re-
views of computers, for example. A given com-
puter’s components (e.g., hard disk, screen) and
attributes (e.g., volume, size) are viewed as aspects
to be extracted from the reviews, while sentiment
polarity classification consists in judging whether
an opinionated review expresses an overall posi-
tive or negative opinion.
Regarding aspect identification, previous meth-
ods can be divided into three main categories:
rule-based, supervised, and topic model-based
methods. For instance, association rule-based
methods (Hu and Liu, 2004; Liu et al., 1998)
tend to focus on extracting product feature words
and opinion words but neglect connecting product
features at the aspect level. Existing rule-based
methods typically are not able to group the ex-
tracted aspect terms into categories. Supervised
(Jin et al., 2009; Choi and Cardie, 2010) and semi-
supervised learning methods (Zagibalov and Car-
roll, 2008; Mukherjee and Liu, 2012) were intro-
duced to resolve certain aspect identification prob-
lems. However, supervised training requires hand-
labeled training data and has trouble coping with
domain adaptation scenarios.
Hence, unsupervised methods are often adopted
to avoid this sort of dependency on labeled data.
Latent Dirichlet Allocation, or LDA for short,
(Blei et al., 2003) performs well in automatically
extracting aspects and grouping corresponding
representative words into categories. Thus, a num-
ber of LDA-based aspect identification approaches
have been proposed in recent years (Brody and El-
hadad, 2010; Titov and McDonald, 2008; Zhao et
al., 2010). Still, these methods have several im-
portant drawbacks. First, inaccurate approxima-
tions of the distribution over topics may reduce the
computational accuracy. Second, mixture models
are unable to exploit the co-occurrence of topics
to yield high probability predictions for words that
are sharper than the distributions predicted by in-
</bodyText>
<page confidence="0.977942">
616
</page>
<note confidence="0.980504333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 616–625,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.993807945945946">
dividual topics (Hinton and Salakhutdinov, 2009).
To overcome the weaknesses of existing meth-
ods and pursue the promising direction of
jointly learning aspect and sentiment, we present
the novel Sentiment-Aspect Extraction RBM
(SERBM) model to simultaneously extract as-
pects of entities and relevant sentiment-bearing
words. This two-layer structure model is inspired
by conventional Restricted Boltzmann machines
(RBMs). In previous work, RBMs with shared
parameters (RSMs) have achieved great success
in capturing distributed semantic representations
from text (Hinton and Salakhutdinov, 2009).
Aiming to make the most of their ability to
model latent topics while also accounting for
the structured nature of aspect opinion mining,
we propose replacing the standard hidden lay-
ers of RBMs with a novel heterogeneous struc-
ture. Three different types of hidden units are
used to represent aspects, sentiments, and back-
ground words, respectively. This modification bet-
ter reflects the generative process for reviews, in
which review words are generated not only from
the aspect distribution but also affected by senti-
ment information. Furthermore, we blend back-
ground knowledge into this model using priors and
regularization to help it acquire more accurate fea-
ture representations. After m-step Contrastive Di-
vergence for parameter estimation, we can capture
the required data distribution and easily compute
the posterior distribution over latent aspects and
sentiments from reviews. In this way, aspects and
sentiments are jointly extracted from reviews, with
limited computational effort. This model is hence
a promising alternative to more complex LDA-
based models presented previously. Overall, our
main contributions are as follows:
</bodyText>
<listItem confidence="0.998918090909091">
1. Compared with previous LDA-based meth-
ods, our model avoids inaccurate approxima-
tions and captures latent aspects and senti-
ment both adequately and efficiently.
2. Our model exploits RBMs’ advantage in
properly modeling distributed semantic rep-
resentations from text, but also introduces
heterogeneous structure into the hidden layer
to reflect the generative process for online re-
views. It also uses a form of regularization to
incorporate prior knowledge into the model.
Due these modifications, our model is very
well-suited for solving aspect-based opinion
mining tasks.
3. The optimal weight matrix of this RBM
model can exactly reflect individual word
features toward aspects and sentiment, which
is hard to achieve with LDA-based models
due to the mixture model sharing mechanism.
4. Last but not the least, this RBM model is ca-
pable of jointly modeling aspect and senti-
ment information together.
</listItem>
<sectionHeader confidence="0.999573" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999453525">
We summarize prior state-of-the-art models for as-
pect extraction. In their seminal work, Hu and
Liu (2004) propose the idea of applying classical
information extraction to distinguish different as-
pects in online reviews. Methods following their
approach exploit frequent noun words and depen-
dency relations to extract product features without
supervision (Zhuang et al., 2006; Liu et al., 2005;
Somasundaran and Wiebe, 2009). These methods
work well when the aspect is strongly associated
with a single noun, but obtain less satisfactory re-
sults when the aspect emerges from a combination
of low frequency items. Additionally, rule-based
methods have a common shortcoming in failing to
group extracted aspect terms into categories.
Supervised learning methods (Jin et al., 2009;
Choi and Cardie, 2010; Jakob and Gurevych,
2010; Kobayashi et al., 2007) such as Hidden
Markov Models, one-class SVMs, and Condi-
tional Random Fields have been widely used in
aspect information extraction. These supervised
approaches for aspect identification are generally
based on standard sequence labeling techniques.
The downside of supervised learning is its require-
ment of large amounts of hand-labeled training
data to provide enough information for aspect and
opinion identification.
Subsequent studies have proposed unsuper-
vised learning methods, especially LDA-based
topic modeling, to classify aspects of comments.
Specific variants include the Multi-Grain LDA
model (Titov and McDonald, 2008) to capture
local rateable aspects, the two-step approach to
detect aspect-specific opinion words (Brody and
Elhadad, 2010), the joint sentiment/topic model
(JST) by Lin and He (2009), the topic-sentiment
mixture model with domain adaption (Mei et al.,
2007), which treats sentiment as different topics,
and MaxEnt-LDA (Zhao et al., 2010), which inte-
grates a maximum entropy approach into LDA.
</bodyText>
<page confidence="0.991553">
617
</page>
<figure confidence="0.489552">
Latent Topics
</figure>
<figureCaption confidence="0.999256">
Figure 1: RBM Schema
</figureCaption>
<bodyText confidence="0.999943333333333">
However, these LDA-based methods can only
adopt inaccurate approximations for the posterior
distribution over topics rather than exact inference.
Additionally, as a mixture model, LDA suffers
from the drawbacks mentioned in Section 1 that
are common to all mixture models.
</bodyText>
<sectionHeader confidence="0.996883" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.999903333333333">
In order to improve over previous work, we first
introduce a basic RBM-based model and then de-
scribe our modified full model.
</bodyText>
<subsectionHeader confidence="0.999634">
3.1 Basic RBM-based Model
</subsectionHeader>
<bodyText confidence="0.999591083333333">
Restricted Boltzmann Machines can be used for
topic modeling by relying on the structure shown
in Figure 1. As shown on the left side of the fig-
ure, this model is a two-layer neural network com-
posed of one visible layer and one hidden layer.
The visible layer consists of a softmax over dis-
crete visible units for words in the text, while the
hidden layer captures its topics. More precisely,
the visible layer is represented as a K x D ma-
trix v, where K is the dictionary size, and D is the
document length. Here, if visible unit i in v takes
the k-th value, we set vki = 1. The hidden layer
can be expressed as h E {0,1}F, where F is the
number of hidden layer nodes, corresponding to
topics. The right side of Figure 1 is another way
of viewing the network, with a single multinomial
visible unit (Hinton and Salakhutdinov, 2009).
The energy function of the model can be defined
as
where Wij k specifies the connection weight from
the i-th visible node of value k to the j-th hidden
node, bki corresponds to a bias of vki , and aj corre-
sponds to a bias of hj.
The probability of the input layer v is defined as
</bodyText>
<equation confidence="0.9969515">
1 X exp(−E(v, h)), (2)
P (v) =
Z
h
</equation>
<bodyText confidence="0.997840666666667">
where Z is the partition function to normalize the
probability.
The conditional probabilities from the hidden to
the visible layer and from the visible to the hidden
one are given in terms of a softmax and logistic
function, respectively, i.e.
</bodyText>
<equation confidence="0.99652075">
!hjWij k
K bq F !,
P exp i + P hjW ij q
q=1 j=1
aj + XD XK !
P( hj = 1  |v) = σ i=1 k=1 vki Wk,
ij
(3)
</equation>
<bodyText confidence="0.9930195">
where σ(x) = 1/(1 + exp(−x)) is the logistic
function.
</bodyText>
<subsectionHeader confidence="0.99914">
3.2 Our Sentiment-Aspect Extraction model
</subsectionHeader>
<bodyText confidence="0.999793307692308">
While the basic RBM-based method provides a
simple model of latent topics, real online reviews
require a more fine-grained model, as they con-
sist of opinion aspects and sentiment information.
Therefore, aspect identification is a different task
from regular topic modeling and the basic RBM-
based model may not perform well in aspect ex-
traction for reviews.
To make the most of the ability of the basic
RBM-based model in extracting latent topics, and
obtain an effective method that is well-suited to
solve aspect identification tasks, we present our
novel Sentiment-Aspect Extraction RBM model.
</bodyText>
<subsectionHeader confidence="0.752599">
3.2.1 Generative Perspective
</subsectionHeader>
<bodyText confidence="0.998787">
From a generative perspective, product reviews
can be regarded as follows. Every word in a
review text may describe a specific aspect (e.g.
“expensive” for the price aspect), or an opinion
(e.g. “amazing” for a positive sentiment and “ter-
rible” for a negative one), or some irrelevant back-
ground information (e.g. “Sunday”). In a genera-
tive model, a word may be generated from a latent
aspect variable, a sentiment variable, or a back-
ground variable. Also, there may exist certain re-
lations between such latent variables.
</bodyText>
<equation confidence="0.648149066666667">
v1 ^• ivi ••• vD
W1,1
W1,F
h1
Wi,1
Wi,F
hF
WD,1
WD,F
hi
W1 W2
v
hj
E(v, h) = − XD XF XK Wkijhjvki
i=1 j=1 k=1
vki bki −
XF
j=1
(1)
hjaj,
−
XD
i=1
XK
k=1
P( vki = 1  |h) =
bk
exp i +
PF
j=1
</equation>
<page confidence="0.973002">
618
</page>
<subsectionHeader confidence="0.558026">
Aspect Sentiment Background
</subsectionHeader>
<figureCaption confidence="0.991929">
Figure 2: Sentiment-Aspect Extraction Model
</figureCaption>
<subsectionHeader confidence="0.76419">
3.2.2 Structure
</subsectionHeader>
<bodyText confidence="0.999199517241379">
To simulate this generative process for reviews,
we adapt the standard RBM structure to reflect the
aspect-sentiment identification task.
Undirected Model. Our Sentiment-Aspect Ex-
traction model structure is illustrated in Figure 2.
Compared to standard RBMs, a crucial differ-
ence is that hidden units now have a heterogeneous
structure instead of being homogeneous as in the
standard basic RBM model. In particular, we rely
on three types of hidden units, representing aspect,
sentiment, and background, respectively. The first
two types are self-explanatory, while the back-
ground units are intended to reflect the kind of
words that do not contribute much to the aspect or
sentiment information of review documents. Since
the output of the hidden units is a re-encoding of
the information in the visible layer, we obtain a
deeper representation and a more precise expres-
sion of information in the input reviews. Thus, this
approach enables the model to learn multi-faceted
information with a simple yet expressive structure.
To formalize this, we denote v = �Di=1 vki as
the count for the k-th word, where D is the doc-
ument length. The energy function can then be
defined as follows:
where Wjk denotes the weight between the k-th
visible unit and the j-th hidden unit.
The conditional probability from visible to hid-
den unit can be expressed as:
</bodyText>
<equation confidence="0.99450925">
K
P(hj = 1|v) = U(aj + vWjk). (5)
k=1
=U(aj + Wjkv).
</equation>
<bodyText confidence="0.999783909090909">
Under this architecture, this equation can be ex-
plained as the conditional probability from visible
unit k to hidden unit j (softmax of words to as-
pect or sentiment). According to Eq. 6, the con-
ditional probability for the k-th word feature to-
wards the j-th aspect or sentiment p(hj = 1  |vk)
is a monotone function of Wjk , the (k, j)-th entry
of the optimal weight matrix. Thus, the optimal
weight matrix of this RBM model can directly re-
flect individual word features toward aspects and
sentiment.
Informative Priors. To improve the ability of
the model to extract aspects and identify senti-
ments, we capture priors for words in reviews and
incorporate this information into the learning pro-
cess of our Sentiment-Aspect Extraction model.
We regularize our model based on these priors to
constrain the aspect modeling and improve its ac-
curacy. Figure 3 provides an example of how such
priors can be applied to a sentence, with Oi repre-
senting the prior knowledge.
Research has found that most aspect words are
nouns (or noun phrases), and sentiment is often
expressed with adjectives. This additional infor-
mation has been utilized in previous work on as-
pect extraction (Hu and Liu, 2004; Benamara et
al., 2007; Pang et al., 2002). Inspired by this, we
first rely on Part of Speech (POS) Tagging to iden-
tify nouns and adjectives. For all noun words, we
first calculate their term frequency (TF) in the re-
view corpus, and then compute their inverse doc-
ument frequency (IDF) from an external Google
n-gram corpus&apos;. Finally, we rank their TF*IDF
</bodyText>
<figure confidence="0.83069655882353">
&apos;http://books.google.com/ngrams/datasets
h1 !! hi hk
1 i hj hj
hF
Aspect—i Sentiment—i
Wx,y
!
Prior Knowledge
W1,1
W1,F WD,1
WD,F
φ
1 v1 ! !
1 ! !
D vD
φ1
φ4
φ2
Joint Learning with φ
φ3
id—i # word count_i D
id1_DT id2_NN id3_CC id4_NNS id5_NN id6y id7_VBZ id8y
POS
Sentence
E(v, h) = − F K Wjkhjvk
j=1 k=1
K
−
k=1
vbk −
F
j=1
(4)
hjaj,
</figure>
<bodyText confidence="0.991431142857143">
In an RBM, every hidden unit can be activated
or restrained by visible units. Thus, every visible
unit has a potential contribution towards the acti-
vation of a given hidden unit. The probability of
whether a given visible unit affects a specific hid-
den unit is described as follows (cf. appendix for
details):
</bodyText>
<equation confidence="0.9771695">
P(hj = 1  |v) =P(hj = 1  |h−j, v)
(6)
</equation>
<page confidence="0.98978">
619
</page>
<figureCaption confidence="0.999742">
Figure 3: Prior Feature Extraction
</figureCaption>
<bodyText confidence="0.99995217948718">
values and assign them an aspect prior probability
pA,vk, indicating their general probability of be-
ing an aspect word. This TF-IDF approach is mo-
tivated by the following intuitions: the most fre-
quently mentioned candidates in reviews have the
highest probability of being an opinion target and
false target words are non-domain specific and fre-
quently appear in a general text corpus (Liu et al.,
2012; Liu et al., 2013). For all adjective words, if
the words are also included in the online sentiment
resource SentiWordNet2, we assign prior probabil-
ity ps,vk to suggest that these words are generally
recognized as sentiment words.
Apart from these general priors, we obtain a
small amount of fine-grained information as an-
other type of prior knowledge. This fine-grained
prior knowledge serves to indicate the probabil-
ity of a known aspect word belonging to a specific
aspect, denoted as pAj,vk and an identified senti-
ment word bearing positive or negative sentiment,
denoted as pSj,vk. For instance, “salad” is always
considered as a general word that belongs to the
specific aspect food, and “great” is generally con-
sidered a positive sentiment word.
To extract pAj,vk, we apply regular LDA on the
review dataset. Since the resulting topic clusters
are unlabeled, we manually assign top k words
from the topics to the target aspects. We thus
obtain fine-grained prior probabilities to suggest
these words as belonging to specific aspects. To
obtain pSj,vk, we rely on SentiWordNet and sum
up the probabilities of an identified sentiment
word being positive or negative sentiment-bearing,
respectively. Then we adopt the corresponding
percentage value as a fine-grained specific senti-
ment prior.
It is worthwhile to mention that the priors are
not a compulsory component. However, the pro-
cedure for obtaining priors is generic and can eas-
</bodyText>
<footnote confidence="0.692395">
2http://sentiwordnet.isti.cnr.it
</footnote>
<bodyText confidence="0.9998198">
ily be applied to any given dataset. Furthermore,
we only obtain such fine-grained prior knowledge
for a small amount of words in review sentences
and rely on the capability of model itself to deal
with the remaining words.
</bodyText>
<subsectionHeader confidence="0.599638">
3.2.3 Objective Function
</subsectionHeader>
<bodyText confidence="0.999953666666667">
We now construct an objective function for our
SERBM model that includes regularization based
on the priors defined above in Section 3.2.2. Sup-
pose that the training set is S = v1, v2, ... , vn3,
where ns is the number of training objects. Each
element has the form vi = (vi1, vi2, . . ., vi K)D,
where i = 1, 2, ... , ns, and these data points are
assumed to be independent and identically dis-
tributed.
We define the following novel log-likelihood
function ln LS, with four forms of regularization
corresponding to the four kinds of priors:
</bodyText>
<equation confidence="0.9928096">
+ A2 ln Y P(hj = 1  |bvk) − pA,vk
j=
kER2
1
Y[
P(hj = 1  |bvk) − pSj,vk
kER3
rF2+1
+ A4 lnYL P(hj = 1  |bvk) − pS,vk
(7)
</equation>
<bodyText confidence="0.972856636363636">
Here, P(hj = 1  |bvk) stands for the probability of
a given input word belonging to a specific hidden
unit. We assume all Ai &gt; 0 for i = 1... 4, while
F1 and F2 are integers for the offsets within the
hidden layer. Units up to index F1 capture aspects,
with the last one reserved for miscellaneous Other
Aspects, while units from F2 capture the sentiment
(with F1 = F2 + 1 &lt; F for convenience).
Our goal will be to maximize the log-likelihood
ln LS in order to adequately model the data, in ac-
cordance with the regularization.
</bodyText>
<subsectionHeader confidence="0.719361">
3.2.4 Training
</subsectionHeader>
<bodyText confidence="0.998622">
We use Stochastic Gradient Descent (SGD) to find
suitable parameters that maximize the objective
function. Given a single training instance v from
</bodyText>
<figure confidence="0.959347869565217">
Sentence Part of Speech Tagging
The_DT delicious_JJ dishes_NN in_IN the_DT restaurant_NN taste_VBZ great_JJ
φ2 Aspect φ3
Aspect_i Sentiment_i
φ4 Sentiment
φ1
ln LS = ln Yn3 P(vi) − Xn3 &amp;quot;
i=1 i=1
Y[P(hj = 1  |bvk) − pAj,vk
kER1
F1−1
A1 ln Y
j=1
12
F1
�Y
12
+ A3 ln F2+1
Y
j=F2
~2
kER4 j=F2
12#
</figure>
<page confidence="0.869157">
620
</page>
<equation confidence="0.9866234">
∂ lnL
∂θ
∂ ln P(v)
∂θ
F1−1X
j=1
X
k∈R1
− λ1
i2
X− λ2
k∈R2
hPF1
∂ ln j=1 P(hj = 1  |bvk) − pA,vk
∂θ
X− λ4
k∈R4
hPF2+1 i2
∂ ln j=F2 P(hj = 1  |bvk) − pS,vk
∂θ
F2+1X
j=F2
X
k∈R3
− λ3
XN
n=1
1
N
∂ ln P(vn)
∂Wjk
= ED1[ˆvkhj] − ED2[ˆvkhj].
F1−1X
j=1
X
k∈R1
− λ1
F1
X
j=1
X− λ2
k∈R2
Gj
(1 + Gj)2
F1 1
Pj=1 (1+Gj) − pA,vk
2bvk
F2+1X
j=F2
X
k∈R3
− λ3
F2+1X
j=F2
X− λ4
k∈R4
Gj
(1 + Gj)2,
PF2+1 1
j=F2 (1+Gj) − pS,vk
2bvk
the training set S, we obtain
∂ ln P(hj = 1  |bvk) − pAj,vk�2
∂θ
∂ ln P(hj = 1  |bvk) − pSj,vk�2
</equation>
<bodyText confidence="0.953695421052632">
∂θ
where θ = {W, aj, bi} stands for the parameters.
Given N documents {vn}N n=1, the first term in the
log-likelihood function with respect to W is:
Here, D1[·] and D2[·] represent the expectation
with respect to the data distribution and the dis-
tribution obtained by this model, respectively. We
use Contrastive Divergence (CD) to approximate
ED2[ˆvkhj] (Hinton and Salakhutdinov, 2009).
Due to the m steps of transfer between input and
hidden layers in a CD-m run of the algorithm, the
two types of hidden units, aspect and sentiment,
will jointly affect input reviews together with the
connection matrix between the two layers.
Finally, we consider the partial derivative of the
entire log-likelihood function with respect to the
parameter W. Denoting ln ∂L
∂W as ∇W, in each
step we update ∇Wjk by adding
</bodyText>
<equation confidence="0.970291857142857">
λ hP(hj = 1|v(0))v(k0) − P(hj = 1|v(cdm))v(kcdm)i
2Gjbvk
(1 + Gj)2( 1
1+Gj − pAj,vk)
2Gjbvk
(1 + Gj)2( 1
1+Gj − pSj,vk)
</equation>
<bodyText confidence="0.999932">
where Gj=e−(aj+Wjk ) for convenience, and
v(cdm) is the result from the CD-m steps.
</bodyText>
<sectionHeader confidence="0.999568" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999906666666667">
We present a series of experiments to evaluate our
model’s performance on the aspect identification
and sentiment classification tasks.
</bodyText>
<subsectionHeader confidence="0.979198">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.99998335">
For this evaluation, we rely on a restaurant review
dataset widely adopted by previous work (Ganu
et al., 2009; Brody and Elhadad, 2010; Zhao et
al., 2010), which contains 1,644,923 tokens and
52,574 documents in total. Documents in this
dataset are annotated with one or more labels from
a gold standard label set S = {Food, Staff, Ambi-
ence, Price, Anecdote, Miscellaneous}. Following
the previous studies, we select reviews with less
than 50 sentences and remove stop words. The
Stanford POS Tagger3 is used to distinguish noun
and adjective words from each other.
We later also rely on the Polarity dataset v2.04
to conduct an additional experiment on senti-
ment classification in order to better assess the
model’s overall performance. This dataset focuses
on movie reviews and consists of 1000 positive
review documents and 1000 negative ones. It
has also been used in the experiments by Lin &amp;
He (2009), among others.
</bodyText>
<subsectionHeader confidence="0.988955">
4.2 Aspect Identification
</subsectionHeader>
<bodyText confidence="0.9998475">
We first apply our novel model to identify aspects
from documents in the restaurant review dataset.
</bodyText>
<subsubsectionHeader confidence="0.40659">
4.2.1 Experimental Setup
</subsubsectionHeader>
<bodyText confidence="0.999914785714286">
For the experimental setup, we use ten hidden
units in our Sentiment-Aspect Extraction RBM
(SERBM), where units 0–6 capture aspects, units
7–8 capture sentiment information, and unit 9
stores background information. In particular, we
fix hidden units 0–6 to represent the target aspects
Food, Staff, Ambience, Price, Ambience, Miscella-
neous, and Other Aspects, respectively. Units 7–8
represent positive and negative sentiment, respec-
tively. The remaining hidden unit is intended to
capture irrelevant background information.
Note that the structure of our model needs no
modifications for new reviews. There are two
cases for datasets from a new domain. If the new
</bodyText>
<footnote confidence="0.997079666666667">
3http://nlp.stanford.edu/software/tagger.shtml
4http://www.cs.cornell.edu/people/pabo/
movie-review-data/
</footnote>
<page confidence="0.989644">
621
</page>
<table confidence="0.9731325">
Method RBM RSM SERBM
PPL 49.73 39.19 21.18
</table>
<tableCaption confidence="0.999981">
Table 1: Results in terms of perplexity
</tableCaption>
<bodyText confidence="0.999969266666667">
dataset has a gold standard label set, then we as-
sign one hidden unit to represent each label in the
gold standard set. If not, our model only obtains
the priors pA,vk and pS,vk, and the aspect set can
be inferred as in the work of Zhao et al. (2010).
For evaluation, following previous work, the an-
notated data is fed into our unsupervised model,
without any of the corresponding labels. The
model is then evaluated in terms of how well its
prediction matches the true labels. As for hyperpa-
rameter optimization, we use the perplexity scores
as defined in Eq. 10 to find the optimal hyper-
parameters.
As a baseline, we also re-implement standard
RBMs and the RSM model (Hinton and Salakhut-
dinov, 2009) to process this same restaurant re-
view dataset and identify aspects for every doc-
ument in this dataset under the same experimental
conditions. We recall that RSM is a similar undi-
rected graphical model that models topics from
raw text.
Last but not the least, we conduct addi-
tional comparative experiments, including
with LocLDA (Brody and Elhadad, 2010),
MaxEnt-LDA (Zhao et al., 2010) and the SAS
model (Mukherjee and Liu, 2012) to extract
aspects for this restaurant review dataset under the
same experimental conditions. In the following,
we use the abbreviated name MELDA to stand for
the MaxEnt LDA method.
</bodyText>
<subsectionHeader confidence="0.707861">
4.2.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999954583333333">
Brody and Elhadad (2010) and Zhao et al. (2010)
utilize three aspects to perform a quantitative eval-
uation and only use sentences with a single label
for evaluation to avoid ambiguity. The three major
aspects chosen from the gold standard labels are
S = {Food, Staff, Ambience}. The evaluation cri-
terion essentially is to judge how well the predic-
tion matches the true label, resulting in Precision,
Recall, and F1 scores. Besides these, we consider
perplexity (PPL) as another evaluation metric to
analyze the aspect identification quality. The aver-
age test perplexity PPL over words is defined as:
</bodyText>
<table confidence="0.9880435">
�log P(vn) , (10)
Aspect Method Precision Recall F1
RBM 0.753 0.680 0.715
RSM 0.718 0.736 0.727
food LocLDA 0.898 0.648 0.753
MELDA 0.874 0.787 0.828
SAS 0.867 0.772 0.817
SERBM 0.891 0.854 0.872
RBM 0.436 0.567 0.493
RSM 0.430 0.310 0.360
staff LocLDA 0.804 0.585 0.677
MELDA 0.779 0.540 0.638
SAS 0.774 0.556 0.647
SERBM 0.819 0.582 0.680
RBM 0.489 0.439 0.463
RSM 0.498 0.441 0.468
ambi LocLDA 0.603 0.677 0.638
-ence MELDA 0.773 0.588 0.668
SAS 0.780 0.542 0.640
SERBM 0.805 0.592 0.682
</table>
<tableCaption confidence="0.994967">
Table 2: Aspect identification results in terms of
</tableCaption>
<bodyText confidence="0.978709352941177">
precision, recall, and F1 scores on the restaurant
reviews dataset
where N is the number of documents, Dn repre-
sents the word number, and vn stands for the word-
count of document n.
Average perplexity results are reported in Ta-
ble 1, while Precision, Recall, and F1 evaluation
results for aspect identification are given in Ta-
ble 2. Some LDA-based methods require manual
mappings for evaluation, which causes difficulties
in obtaining a fair PPL result, so a few methods
are only considered in Table 2.
To illustrate the differences, in Table 3, we list
representative words for aspects identified by var-
ious models and highlight words without an obvi-
ous association or words that are rather unspecific
in bold.
</bodyText>
<subsectionHeader confidence="0.900522">
4.2.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999637272727273">
Considering the results from Table 1 and the
RBM, RSM, and SERBM-related results from Ta-
ble 2, we find that the RSM performs better than
the regular RBM model on this aspect identifi-
cation task. However, the average test perplex-
ity is greatly reduced even further by the SERBM
method, resulting in a relative improvement by
45.96% over the RSM model. Thus, despite
the elaborate modification, our SERBM inherits
RBMs’ ability in modeling latent topics, but sig-
nificantly outperforms other RBM family models
</bodyText>
<page confidence="0.956433">
1
1
</page>
<bodyText confidence="0.4725565">
N
exp
</bodyText>
<page confidence="0.93512925">
Dn
N
n=1
622
</page>
<table confidence="0.997757518518518">
Aspect RSM RBM Loc-LDA ME-LDA SAS SERBM
Food great menu,drink chicken chocolate food,menu salad,cheese
dessert food,pizza menu,salad dessert dessert dessert
beef chicken good cream drinks chicken
drink,BBQ seafood fish ice,cake chicken sauce
menu good drinks desserts cheeses rice,pizza
delicious sandwich wine,sauce good beers,salad food
good soup rice bread delicious dish
fish flavor cheese cheese rice sushi,menu
Staff service staff service service staff,slow service
room helpful staff,waiter staff,food waitress staff,friendly
slow waiter attentive wait,waiters attentive waitress
table friendly busy waiter helpful waitstaff
quick good,attentive slow,friendly place service attentive
waitress slow,service table restaurant minutes waitresses
friendly restaurant wait waitress wait,friendly servers
waiter minutes minutes waitstaff waiter minutes
Ambience atmosphere place great room place atmosphere
music atmosphere atmosphere dining decor atmosphere
place cozy wonderful tables great scene
dinner door music bar good place
romantic cute seating place romantic tables
room bar experience decor tables outside
comfortable great relaxed scene bar area
tables seating bar space decor ambiance
good experience room area great outdoor
ambiance romantic outside table music romantic,cozy
</table>
<tableCaption confidence="0.99977">
Table 3: Aspects and representative words
</tableCaption>
<bodyText confidence="0.99891685">
on the aspect identification task.
In Table 2, we also observe that SERBM
achieves a higher accuracy compared with
other state-of-the-art aspect identification meth-
ods. More specifically, it is evident that our
SERBM model outperforms previous methods’ F1
scores. Compared with MELDA, the F1 scores
for the SERBM lead to relative improvements of
5.31%, 6.58%, and 2.10%, respectively, for the
Food, Staff, and Ambience aspects. Compared
with SAS, the F1 scores yield relative improve-
ments by 6.73%, 5.10%, and 6.56%, respectively,
on those same aspects. As for Precision and Re-
call, the SERBM also achieves a competitive per-
formance compared with other methods in aspect
identification.
Finally, we conclude from Table 3 that the
SERBM method has the capability of extracting
word with obvious aspect-specific features and
makes less errors compared with other models.
</bodyText>
<subsectionHeader confidence="0.997442">
4.3 Sentiment Classification
</subsectionHeader>
<bodyText confidence="0.999806333333333">
We additionally conduct two experiments to eval-
uate the model’s performance on sentiment classi-
fication.
</bodyText>
<subsectionHeader confidence="0.944153">
4.3.1 Comparison with SentiWordNet
</subsectionHeader>
<bodyText confidence="0.999791285714286">
We assign a sentiment score to every document in
the restaurant review dataset based on the output
of SERBM’s sentiment-type hidden units. To ana-
lyze SERBM’s performance in sentiment classifi-
cation, we compare these results with SentiWord-
Net5, a well-known sentiment lexicon. For this
SentiWordNet baseline, we consult the resource to
obtain a sentiment label for every word and ag-
gregate these to judge the sentiment information
of an entire review document in terms of the sum
of word-specific scores. Table 4 provides a com-
parison between SERBM and SentiWordNet, with
Accuracy as the evaluation metric.
We observe in Table 4 that the sentiment
</bodyText>
<footnote confidence="0.970711">
5http://sentiwordnet.isti.cnr.it
</footnote>
<page confidence="0.994387">
623
</page>
<table confidence="0.969606">
Method SentiWordNet SERBM
Accuracy 0.703 0.788
</table>
<tableCaption confidence="0.996308">
Table 4: Accuracy for SERBM and SentiWordNet
</tableCaption>
<bodyText confidence="0.998193333333333">
classification accuracy on the restaurant review
dataset sees a relative improvement by 12.1% with
SERBM over the SentiWordNet baseline.
</bodyText>
<subsectionHeader confidence="0.879342">
4.3.2 Comparison with JST
</subsectionHeader>
<bodyText confidence="0.999934944444445">
We additionally utilize the Polarity dataset v2.0 to
conduct an additional sentiment classification ex-
periment in order to assess SERBM’s performance
more thoroughly. We compare SERBM with the
advanced joint sentiment/topic model (JST) by
Lin &amp; He (2009). For the JST and the Trying-
JST methods only, we use the filtered subjectiv-
ity lexicon (subjective MR) as prior information,
containing 374 positive and 675 negative entries,
which is the same experimental setting as in Lin
&amp; He (2009). For SERBM, we use the same gen-
eral setup as before except for the fact that aspect-
specific priors are not used here.
Table 5 provides the sentiment classification ac-
curacies on both the overall dataset and on the sub-
sets for each polarity, where pos. and neg. refer to
the positive and negative reviews in the dataset, re-
spectively.
</bodyText>
<table confidence="0.99862075">
Method overall pos. neg.
JST(%) 84.6 96.2 73
Trying-JST(%) 82 89.2 74.8
SERBM(%) 89.1 92.0 86.2
</table>
<tableCaption confidence="0.997463">
Table 5: Accuracy for SERBM and JST
</tableCaption>
<bodyText confidence="0.999925666666667">
In Table 5, we observe that SERBM outper-
forms JST both in terms of the overall accu-
racy and for the positive/negative-specific subsets.
SERBM yields a relative improvement in the over-
all accuracy by 5.31% over JST and by 8.66% over
Trying-JST.
</bodyText>
<sectionHeader confidence="0.999542" genericHeader="evaluation">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999933642857143">
In this paper, we have proposed the novel
Sentiment-Aspect Extraction RBM (SERBM)
model to jointly extract review aspects and sen-
timent polarities in an unsupervised setting. Our
approach modifies the standard RBM model by
introducing a heterogeneous structure into the hid-
den layer and incorporating informative priors into
the model. Our experimental results show that this
model can outperform LDA-based methods.
Hence, our work opens up the avenue of uti-
lizing RBM-based undirected graphical models to
solve aspect extraction and sentiment classifica-
tion tasks as well as other unsupervised tasks with
similar structure.
</bodyText>
<sectionHeader confidence="0.992883" genericHeader="conclusions">
Appendix
</sectionHeader>
<bodyText confidence="0.959213333333333">
The joint probability distribution is defined as
where Zθ is the partition function. In conjunction
with Eq. 1, we obtain
</bodyText>
<equation confidence="0.96257705">
Eθ(bvk, h) = −bibvk −
Then, we can obtain the derivation in Eq. 6.
P(hj = 1 bvk)
=P(hj = 1 h−j, bvk)
P(hj = 1, h−j, bvk)
=P(h−j, bvk)
P(hj = 1, h−j, bvk)
P(hj = 1, h−j, bvk) + P(hj = 0, h−j, bvk)
Z
1e −E(hj=1,h−j,v)
Z
1e
−E(hj=1,h−j,vk) + 1 e−E(hj=0,h−j,vk)
Z
e−E(hj=1,h−j,vk)
e−E(hj=1,h−j,vk) + e−E(hj=0,h−j,vk)
1
1 + e−E(hj=0,h−j,vk)+E(hj=1,h−j,vk)
=σ(aj + Wjkbvk)
(13)
</equation>
<sectionHeader confidence="0.999162" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998161142857143">
The research at IIIS was supported by China 973
Program Grants 2011CBA00300, 2011CBA00301
and NSFC Grants 61033001, 61361136003,
61450110088. The research at CASIA was sup-
ported by the National Basic Research Program
of China Grant No. 2012CB316300 and NSFC
Grants 61272332 and 61202329.
</bodyText>
<equation confidence="0.892004428571428">
1 Eθ(v,h)
pθ(v, h) = ,
Z
e (11)
θ
XF ajhj − XF hjWjkbvk
j=1 j=1 (12)
</equation>
<bodyText confidence="0.84612225">
=
=
=
=
</bodyText>
<page confidence="0.991112">
624
</page>
<sectionHeader confidence="0.998329" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999952458715597">
Farah Benamara, Carmine Cesarano, Antonio Pi-
cariello, Diego Reforgiato Recupero, and Venkatra-
mana Subrahmanian. 2007. Sentiment analysis:
Adjectives and adverbs are better than adjectives
alone. In Proceedings of ICWSM 2007.
David Blei, Andrew Ng, and Michael Jordan. 2003.
Latent dirichlet allocation. Journal of Machine
Learning Research, 3:993–1022.
Samuel Brody and Noemie Elhadad. 2010. An unsu-
pervised aspect-sentiment model for online reviews.
In Proceedings of NAACL-HLT 2010, pages 804–
812. Association for Computational Linguistics.
Yejin Choi and Claire Cardie. 2010. Hierarchical se-
quential learning for extracting opinions and their
attributes. In Proceedings of ACL 2010, pages 269–
274. Association for Computational Linguistics.
Gayatree Ganu, Noemie Elhadad, and Am´elie Marian.
2009. Beyond the stars: Improving rating predic-
tions using review text content. In Proceedings of
WebDB 2009, pages 1–6.
Geoffrey Hinton and Ruslan Salakhutdinov. 2009.
Replicated softmax: an undirected topic model. In
Advances in Neural Information Processing Systems
(NIPS 2009), pages 1607–1614.
Minqing Hu and Bing Liu. 2004. Mining and sum-
marizing customer reviews. In Proceedings of KDD
2004, pages 168–177, New York, NY, USA. ACM.
Niklas Jakob and Iryna Gurevych. 2010. Extracting
opinion targets in a single-and cross-domain setting
with Conditional Random Fields. In Proceedings
of EMNLP 2010, pages 1035–1045. Association for
Computational Linguistics.
Wei Jin, Hung Hay Ho, and Rohini K Srihari. 2009. A
novel lexicalized HMM-based learning framework
for Web opinion mining. In Proceedings of ICML
2009, pages 465–472.
Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.
2007. Extracting aspect-evaluation and aspect-of
relations in opinion mining. In Proceedings of
EMNLP-CoNLL, pages 1065–1074.
Chenghua Lin and Yulan He. 2009. Joint senti-
ment/topic model for sentiment analysis. In Pro-
ceedings of the 18th ACM Conference on Infor-
mation and Knowledge Management (CIKM 2009),
pages 375–384. ACM.
Bing Liu, Wynne Hsu, and Yiming Ma. 1998. In-
tegrating classification and association rule mining.
In Proceedings of KDD 1998, pages 80–86. AAAI
Press.
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opin-
ions on the Web. In Proceedings of the 14th inter-
national conference on World Wide Web, pages 342–
351. ACM.
Kang Liu, Liheng Xu, and Jun Zhao. 2012. Opin-
ion target extraction using word-based translation
model. In Proceedings of EMNLP-CoNLL 2012,
pages 1346–1356.
Kang Liu, Liheng Xu, Yang Liu, and Jun Zhao. 2013.
Opinion target extraction using partially-supervised
word alignment model. In Proceedings of the 23rd
International Joint Conference on Artificial Intelli-
gence (IJCAI2013), pages 2134–2140. AAAI Press.
Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,
and ChengXiang Zhai. 2007. Topic sentiment mix-
ture: modeling facets and opinions in weblogs. In
Proceedings of the 16th international conference on
the World Wide Web (WWW 2007), pages 171–180.
ACM.
Arjun Mukherjee and Bing Liu. 2012. Aspect extrac-
tion through semi-supervised modeling. In Proceed-
ings of ACL 2012, pages 339–348.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and trends in infor-
mation retrieval, 2(1-2):1–135.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: Sentiment classification us-
ing machine learning techniques. In Proceedings of
EMNLP 2002, pages 79–86. Association for Com-
putational Linguistics.
Ana-Maria Popescu and Orena Etzioni. 2005. Extract-
ing product features and opinions from reviews. In
Proceedings of HLT/EMNLP 2005. Springer.
Swapna Somasundaran and Janyce Wiebe. 2009. Rec-
ognizing stances in online debates. In Proceedings
of ACL-IJCNLP 2009, pages 226–234. Association
for Computational Linguistics.
Ivan Titov and Ryan McDonald. 2008. Modeling
online reviews with multi-grain topic models. In
Proceedings of the 17th international conference on
the World Wide Web (WWW 2008), pages 111–120.
ACM.
Taras Zagibalov and John Carroll. 2008. Automatic
seed word selection for unsupervised sentiment clas-
sification of Chinese text. In Proceedings of COL-
ING 2008, pages 1073–1080.
Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaom-
ing Li. 2010. Jointly modeling aspects and opin-
ions with a MaxEnt-LDA hybrid. In Proceedings of
EMNLP 2010, pages 56–65. Association for Com-
putational Linguistics.
Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006.
Movie review mining and summarization. In Pro-
ceedings of the 15th ACM international Conference
on Information and Knowledge Management (CIKM
2006), pages 43–50. ACM.
</reference>
<page confidence="0.998799">
625
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.860225">
<title confidence="0.999216">Sentiment-Aspect Extraction based on Restricted Boltzmann Machines</title>
<author confidence="0.999841">Kang Zhu Jun</author>
<author confidence="0.999841">Gerard de</author>
<affiliation confidence="0.947127333333333">for Interdisciplinary Information Sciences, Tsinghua University, Beijing, Laboratory of Pattern Recognition, Institute of Chinese Academy of Sciences, Beijing,</affiliation>
<abstract confidence="0.997550307692308">Aspect extraction and sentiment analysis of reviews are both important tasks in opinion mining. We propose a novel sentiment and aspect extraction model based on Restricted Boltzmann Machines to jointly address these two tasks in an unsupervised setting. This model reflects the generation process of reviews by introducing a heterogeneous structure into the hidden layer and incorporating informative priors. Experiments show that our model outperforms previous state-of-the-art methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Farah Benamara</author>
<author>Carmine Cesarano</author>
<author>Antonio Picariello</author>
<author>Diego Reforgiato Recupero</author>
<author>Venkatramana Subrahmanian</author>
</authors>
<title>Sentiment analysis: Adjectives and adverbs are better than adjectives alone.</title>
<date>2007</date>
<booktitle>In Proceedings of ICWSM</booktitle>
<contexts>
<context position="15006" citStr="Benamara et al., 2007" startWordPosition="2364" endWordPosition="2367">entiments, we capture priors for words in reviews and incorporate this information into the learning process of our Sentiment-Aspect Extraction model. We regularize our model based on these priors to constrain the aspect modeling and improve its accuracy. Figure 3 provides an example of how such priors can be applied to a sentence, with Oi representing the prior knowledge. Research has found that most aspect words are nouns (or noun phrases), and sentiment is often expressed with adjectives. This additional information has been utilized in previous work on aspect extraction (Hu and Liu, 2004; Benamara et al., 2007; Pang et al., 2002). Inspired by this, we first rely on Part of Speech (POS) Tagging to identify nouns and adjectives. For all noun words, we first calculate their term frequency (TF) in the review corpus, and then compute their inverse document frequency (IDF) from an external Google n-gram corpus&apos;. Finally, we rank their TF*IDF &apos;http://books.google.com/ngrams/datasets h1 !! hi hk 1 i hj hj hF Aspect—i Sentiment—i Wx,y ! Prior Knowledge W1,1 W1,F WD,1 WD,F φ 1 v1 ! ! 1 ! ! D vD φ1 φ4 φ2 Joint Learning with φ φ3 id—i # word count_i D id1_DT id2_NN id3_CC id4_NNS id5_NN id6y id7_VBZ id8y POS S</context>
</contexts>
<marker>Benamara, Cesarano, Picariello, Recupero, Subrahmanian, 2007</marker>
<rawString>Farah Benamara, Carmine Cesarano, Antonio Picariello, Diego Reforgiato Recupero, and Venkatramana Subrahmanian. 2007. Sentiment analysis: Adjectives and adverbs are better than adjectives alone. In Proceedings of ICWSM 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>Andrew Ng</author>
<author>Michael Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="3484" citStr="Blei et al., 2003" startWordPosition="495" endWordPosition="498">t the aspect level. Existing rule-based methods typically are not able to group the extracted aspect terms into categories. Supervised (Jin et al., 2009; Choi and Cardie, 2010) and semisupervised learning methods (Zagibalov and Carroll, 2008; Mukherjee and Liu, 2012) were introduced to resolve certain aspect identification problems. However, supervised training requires handlabeled training data and has trouble coping with domain adaptation scenarios. Hence, unsupervised methods are often adopted to avoid this sort of dependency on labeled data. Latent Dirichlet Allocation, or LDA for short, (Blei et al., 2003) performs well in automatically extracting aspects and grouping corresponding representative words into categories. Thus, a number of LDA-based aspect identification approaches have been proposed in recent years (Brody and Elhadad, 2010; Titov and McDonald, 2008; Zhao et al., 2010). Still, these methods have several important drawbacks. First, inaccurate approximations of the distribution over topics may reduce the computational accuracy. Second, mixture models are unable to exploit the co-occurrence of topics to yield high probability predictions for words that are sharper than the distributi</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David Blei, Andrew Ng, and Michael Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Noemie Elhadad</author>
</authors>
<title>An unsupervised aspect-sentiment model for online reviews.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL-HLT 2010,</booktitle>
<pages>804--812</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3720" citStr="Brody and Elhadad, 2010" startWordPosition="527" endWordPosition="531">roll, 2008; Mukherjee and Liu, 2012) were introduced to resolve certain aspect identification problems. However, supervised training requires handlabeled training data and has trouble coping with domain adaptation scenarios. Hence, unsupervised methods are often adopted to avoid this sort of dependency on labeled data. Latent Dirichlet Allocation, or LDA for short, (Blei et al., 2003) performs well in automatically extracting aspects and grouping corresponding representative words into categories. Thus, a number of LDA-based aspect identification approaches have been proposed in recent years (Brody and Elhadad, 2010; Titov and McDonald, 2008; Zhao et al., 2010). Still, these methods have several important drawbacks. First, inaccurate approximations of the distribution over topics may reduce the computational accuracy. Second, mixture models are unable to exploit the co-occurrence of topics to yield high probability predictions for words that are sharper than the distributions predicted by in616 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 616–625, Beijing, China, July 26-31, 2015. c</context>
<context position="8634" citStr="Brody and Elhadad, 2010" startWordPosition="1248" endWordPosition="1251">. These supervised approaches for aspect identification are generally based on standard sequence labeling techniques. The downside of supervised learning is its requirement of large amounts of hand-labeled training data to provide enough information for aspect and opinion identification. Subsequent studies have proposed unsupervised learning methods, especially LDA-based topic modeling, to classify aspects of comments. Specific variants include the Multi-Grain LDA model (Titov and McDonald, 2008) to capture local rateable aspects, the two-step approach to detect aspect-specific opinion words (Brody and Elhadad, 2010), the joint sentiment/topic model (JST) by Lin and He (2009), the topic-sentiment mixture model with domain adaption (Mei et al., 2007), which treats sentiment as different topics, and MaxEnt-LDA (Zhao et al., 2010), which integrates a maximum entropy approach into LDA. 617 Latent Topics Figure 1: RBM Schema However, these LDA-based methods can only adopt inaccurate approximations for the posterior distribution over topics rather than exact inference. Additionally, as a mixture model, LDA suffers from the drawbacks mentioned in Section 1 that are common to all mixture models. 3 Model In order </context>
<context position="21640" citStr="Brody and Elhadad, 2010" startWordPosition="3562" endWordPosition="3565">tire log-likelihood function with respect to the parameter W. Denoting ln ∂L ∂W as ∇W, in each step we update ∇Wjk by adding λ hP(hj = 1|v(0))v(k0) − P(hj = 1|v(cdm))v(kcdm)i 2Gjbvk (1 + Gj)2( 1 1+Gj − pAj,vk) 2Gjbvk (1 + Gj)2( 1 1+Gj − pSj,vk) where Gj=e−(aj+Wjk ) for convenience, and v(cdm) is the result from the CD-m steps. 4 Experiments We present a series of experiments to evaluate our model’s performance on the aspect identification and sentiment classification tasks. 4.1 Data For this evaluation, we rely on a restaurant review dataset widely adopted by previous work (Ganu et al., 2009; Brody and Elhadad, 2010; Zhao et al., 2010), which contains 1,644,923 tokens and 52,574 documents in total. Documents in this dataset are annotated with one or more labels from a gold standard label set S = {Food, Staff, Ambience, Price, Anecdote, Miscellaneous}. Following the previous studies, we select reviews with less than 50 sentences and remove stop words. The Stanford POS Tagger3 is used to distinguish noun and adjective words from each other. We later also rely on the Polarity dataset v2.04 to conduct an additional experiment on sentiment classification in order to better assess the model’s overall performan</context>
<context position="24494" citStr="Brody and Elhadad, 2010" startWordPosition="4015" endWordPosition="4018"> well its prediction matches the true labels. As for hyperparameter optimization, we use the perplexity scores as defined in Eq. 10 to find the optimal hyperparameters. As a baseline, we also re-implement standard RBMs and the RSM model (Hinton and Salakhutdinov, 2009) to process this same restaurant review dataset and identify aspects for every document in this dataset under the same experimental conditions. We recall that RSM is a similar undirected graphical model that models topics from raw text. Last but not the least, we conduct additional comparative experiments, including with LocLDA (Brody and Elhadad, 2010), MaxEnt-LDA (Zhao et al., 2010) and the SAS model (Mukherjee and Liu, 2012) to extract aspects for this restaurant review dataset under the same experimental conditions. In the following, we use the abbreviated name MELDA to stand for the MaxEnt LDA method. 4.2.2 Evaluation Brody and Elhadad (2010) and Zhao et al. (2010) utilize three aspects to perform a quantitative evaluation and only use sentences with a single label for evaluation to avoid ambiguity. The three major aspects chosen from the gold standard labels are S = {Food, Staff, Ambience}. The evaluation criterion essentially is to ju</context>
</contexts>
<marker>Brody, Elhadad, 2010</marker>
<rawString>Samuel Brody and Noemie Elhadad. 2010. An unsupervised aspect-sentiment model for online reviews. In Proceedings of NAACL-HLT 2010, pages 804– 812. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Hierarchical sequential learning for extracting opinions and their attributes.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL 2010,</booktitle>
<pages>269--274</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3042" citStr="Choi and Cardie, 2010" startWordPosition="429" endWordPosition="432">ation consists in judging whether an opinionated review expresses an overall positive or negative opinion. Regarding aspect identification, previous methods can be divided into three main categories: rule-based, supervised, and topic model-based methods. For instance, association rule-based methods (Hu and Liu, 2004; Liu et al., 1998) tend to focus on extracting product feature words and opinion words but neglect connecting product features at the aspect level. Existing rule-based methods typically are not able to group the extracted aspect terms into categories. Supervised (Jin et al., 2009; Choi and Cardie, 2010) and semisupervised learning methods (Zagibalov and Carroll, 2008; Mukherjee and Liu, 2012) were introduced to resolve certain aspect identification problems. However, supervised training requires handlabeled training data and has trouble coping with domain adaptation scenarios. Hence, unsupervised methods are often adopted to avoid this sort of dependency on labeled data. Latent Dirichlet Allocation, or LDA for short, (Blei et al., 2003) performs well in automatically extracting aspects and grouping corresponding representative words into categories. Thus, a number of LDA-based aspect identif</context>
<context position="7828" citStr="Choi and Cardie, 2010" startWordPosition="1136" endWordPosition="1139">uish different aspects in online reviews. Methods following their approach exploit frequent noun words and dependency relations to extract product features without supervision (Zhuang et al., 2006; Liu et al., 2005; Somasundaran and Wiebe, 2009). These methods work well when the aspect is strongly associated with a single noun, but obtain less satisfactory results when the aspect emerges from a combination of low frequency items. Additionally, rule-based methods have a common shortcoming in failing to group extracted aspect terms into categories. Supervised learning methods (Jin et al., 2009; Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007) such as Hidden Markov Models, one-class SVMs, and Conditional Random Fields have been widely used in aspect information extraction. These supervised approaches for aspect identification are generally based on standard sequence labeling techniques. The downside of supervised learning is its requirement of large amounts of hand-labeled training data to provide enough information for aspect and opinion identification. Subsequent studies have proposed unsupervised learning methods, especially LDA-based topic modeling, to classify aspects of comme</context>
</contexts>
<marker>Choi, Cardie, 2010</marker>
<rawString>Yejin Choi and Claire Cardie. 2010. Hierarchical sequential learning for extracting opinions and their attributes. In Proceedings of ACL 2010, pages 269– 274. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gayatree Ganu</author>
<author>Noemie Elhadad</author>
<author>Am´elie Marian</author>
</authors>
<title>Beyond the stars: Improving rating predictions using review text content.</title>
<date>2009</date>
<booktitle>In Proceedings of WebDB</booktitle>
<pages>1--6</pages>
<contexts>
<context position="21615" citStr="Ganu et al., 2009" startWordPosition="3558" endWordPosition="3561">erivative of the entire log-likelihood function with respect to the parameter W. Denoting ln ∂L ∂W as ∇W, in each step we update ∇Wjk by adding λ hP(hj = 1|v(0))v(k0) − P(hj = 1|v(cdm))v(kcdm)i 2Gjbvk (1 + Gj)2( 1 1+Gj − pAj,vk) 2Gjbvk (1 + Gj)2( 1 1+Gj − pSj,vk) where Gj=e−(aj+Wjk ) for convenience, and v(cdm) is the result from the CD-m steps. 4 Experiments We present a series of experiments to evaluate our model’s performance on the aspect identification and sentiment classification tasks. 4.1 Data For this evaluation, we rely on a restaurant review dataset widely adopted by previous work (Ganu et al., 2009; Brody and Elhadad, 2010; Zhao et al., 2010), which contains 1,644,923 tokens and 52,574 documents in total. Documents in this dataset are annotated with one or more labels from a gold standard label set S = {Food, Staff, Ambience, Price, Anecdote, Miscellaneous}. Following the previous studies, we select reviews with less than 50 sentences and remove stop words. The Stanford POS Tagger3 is used to distinguish noun and adjective words from each other. We later also rely on the Polarity dataset v2.04 to conduct an additional experiment on sentiment classification in order to better assess the </context>
</contexts>
<marker>Ganu, Elhadad, Marian, 2009</marker>
<rawString>Gayatree Ganu, Noemie Elhadad, and Am´elie Marian. 2009. Beyond the stars: Improving rating predictions using review text content. In Proceedings of WebDB 2009, pages 1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Hinton</author>
<author>Ruslan Salakhutdinov</author>
</authors>
<title>Replicated softmax: an undirected topic model.</title>
<date>2009</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS</booktitle>
<pages>1607--1614</pages>
<contexts>
<context position="4416" citStr="Hinton and Salakhutdinov, 2009" startWordPosition="626" endWordPosition="629">ods have several important drawbacks. First, inaccurate approximations of the distribution over topics may reduce the computational accuracy. Second, mixture models are unable to exploit the co-occurrence of topics to yield high probability predictions for words that are sharper than the distributions predicted by in616 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 616–625, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics dividual topics (Hinton and Salakhutdinov, 2009). To overcome the weaknesses of existing methods and pursue the promising direction of jointly learning aspect and sentiment, we present the novel Sentiment-Aspect Extraction RBM (SERBM) model to simultaneously extract aspects of entities and relevant sentiment-bearing words. This two-layer structure model is inspired by conventional Restricted Boltzmann machines (RBMs). In previous work, RBMs with shared parameters (RSMs) have achieved great success in capturing distributed semantic representations from text (Hinton and Salakhutdinov, 2009). Aiming to make the most of their ability to model l</context>
<context position="10209" citStr="Hinton and Salakhutdinov, 2009" startWordPosition="1522" endWordPosition="1525"> one visible layer and one hidden layer. The visible layer consists of a softmax over discrete visible units for words in the text, while the hidden layer captures its topics. More precisely, the visible layer is represented as a K x D matrix v, where K is the dictionary size, and D is the document length. Here, if visible unit i in v takes the k-th value, we set vki = 1. The hidden layer can be expressed as h E {0,1}F, where F is the number of hidden layer nodes, corresponding to topics. The right side of Figure 1 is another way of viewing the network, with a single multinomial visible unit (Hinton and Salakhutdinov, 2009). The energy function of the model can be defined as where Wij k specifies the connection weight from the i-th visible node of value k to the j-th hidden node, bki corresponds to a bias of vki , and aj corresponds to a bias of hj. The probability of the input layer v is defined as 1 X exp(−E(v, h)), (2) P (v) = Z h where Z is the partition function to normalize the probability. The conditional probabilities from the hidden to the visible layer and from the visible to the hidden one are given in terms of a softmax and logistic function, respectively, i.e. !hjWij k K bq F !, P exp i + P hjW ij q</context>
<context position="20720" citStr="Hinton and Salakhutdinov, 2009" startWordPosition="3405" endWordPosition="3408">=1 X− λ2 k∈R2 Gj (1 + Gj)2 F1 1 Pj=1 (1+Gj) − pA,vk 2bvk F2+1X j=F2 X k∈R3 − λ3 F2+1X j=F2 X− λ4 k∈R4 Gj (1 + Gj)2, PF2+1 1 j=F2 (1+Gj) − pS,vk 2bvk the training set S, we obtain ∂ ln P(hj = 1 |bvk) − pAj,vk�2 ∂θ ∂ ln P(hj = 1 |bvk) − pSj,vk�2 ∂θ where θ = {W, aj, bi} stands for the parameters. Given N documents {vn}N n=1, the first term in the log-likelihood function with respect to W is: Here, D1[·] and D2[·] represent the expectation with respect to the data distribution and the distribution obtained by this model, respectively. We use Contrastive Divergence (CD) to approximate ED2[ˆvkhj] (Hinton and Salakhutdinov, 2009). Due to the m steps of transfer between input and hidden layers in a CD-m run of the algorithm, the two types of hidden units, aspect and sentiment, will jointly affect input reviews together with the connection matrix between the two layers. Finally, we consider the partial derivative of the entire log-likelihood function with respect to the parameter W. Denoting ln ∂L ∂W as ∇W, in each step we update ∇Wjk by adding λ hP(hj = 1|v(0))v(k0) − P(hj = 1|v(cdm))v(kcdm)i 2Gjbvk (1 + Gj)2( 1 1+Gj − pAj,vk) 2Gjbvk (1 + Gj)2( 1 1+Gj − pSj,vk) where Gj=e−(aj+Wjk ) for convenience, and v(cdm) is the re</context>
<context position="24139" citStr="Hinton and Salakhutdinov, 2009" startWordPosition="3956" endWordPosition="3960">to represent each label in the gold standard set. If not, our model only obtains the priors pA,vk and pS,vk, and the aspect set can be inferred as in the work of Zhao et al. (2010). For evaluation, following previous work, the annotated data is fed into our unsupervised model, without any of the corresponding labels. The model is then evaluated in terms of how well its prediction matches the true labels. As for hyperparameter optimization, we use the perplexity scores as defined in Eq. 10 to find the optimal hyperparameters. As a baseline, we also re-implement standard RBMs and the RSM model (Hinton and Salakhutdinov, 2009) to process this same restaurant review dataset and identify aspects for every document in this dataset under the same experimental conditions. We recall that RSM is a similar undirected graphical model that models topics from raw text. Last but not the least, we conduct additional comparative experiments, including with LocLDA (Brody and Elhadad, 2010), MaxEnt-LDA (Zhao et al., 2010) and the SAS model (Mukherjee and Liu, 2012) to extract aspects for this restaurant review dataset under the same experimental conditions. In the following, we use the abbreviated name MELDA to stand for the MaxEn</context>
</contexts>
<marker>Hinton, Salakhutdinov, 2009</marker>
<rawString>Geoffrey Hinton and Ruslan Salakhutdinov. 2009. Replicated softmax: an undirected topic model. In Advances in Neural Information Processing Systems (NIPS 2009), pages 1607–1614.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of KDD 2004,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2192" citStr="Hu and Liu, 2004" startWordPosition="302" endWordPosition="305"> is a significant and urgent task (Liu, 2012; Pang and Lee, 2008; Popescu and Etzioni, 2005). Identifying aspect and analyzing sentiment words from reviews has the ultimate goal of discerning people’s opinions, attitudes, emotions, etc. towards entities such as products, services, organizations, individuals, events, etc. In this context, aspect-based opinion mining, also known as feature-based opinion mining, aims at extracting and summarizing particular salient aspects of entities and determining relevant sentiment polarities ∗Corresponding Author: Kang Liu (kliu@nlpr.ia.ac.cn) from reviews (Hu and Liu, 2004). Consider reviews of computers, for example. A given computer’s components (e.g., hard disk, screen) and attributes (e.g., volume, size) are viewed as aspects to be extracted from the reviews, while sentiment polarity classification consists in judging whether an opinionated review expresses an overall positive or negative opinion. Regarding aspect identification, previous methods can be divided into three main categories: rule-based, supervised, and topic model-based methods. For instance, association rule-based methods (Hu and Liu, 2004; Liu et al., 1998) tend to focus on extracting product</context>
<context position="7134" citStr="Hu and Liu (2004)" startWordPosition="1032" endWordPosition="1035">of regularization to incorporate prior knowledge into the model. Due these modifications, our model is very well-suited for solving aspect-based opinion mining tasks. 3. The optimal weight matrix of this RBM model can exactly reflect individual word features toward aspects and sentiment, which is hard to achieve with LDA-based models due to the mixture model sharing mechanism. 4. Last but not the least, this RBM model is capable of jointly modeling aspect and sentiment information together. 2 Related Work We summarize prior state-of-the-art models for aspect extraction. In their seminal work, Hu and Liu (2004) propose the idea of applying classical information extraction to distinguish different aspects in online reviews. Methods following their approach exploit frequent noun words and dependency relations to extract product features without supervision (Zhuang et al., 2006; Liu et al., 2005; Somasundaran and Wiebe, 2009). These methods work well when the aspect is strongly associated with a single noun, but obtain less satisfactory results when the aspect emerges from a combination of low frequency items. Additionally, rule-based methods have a common shortcoming in failing to group extracted aspe</context>
<context position="14983" citStr="Hu and Liu, 2004" startWordPosition="2360" endWordPosition="2363">cts and identify sentiments, we capture priors for words in reviews and incorporate this information into the learning process of our Sentiment-Aspect Extraction model. We regularize our model based on these priors to constrain the aspect modeling and improve its accuracy. Figure 3 provides an example of how such priors can be applied to a sentence, with Oi representing the prior knowledge. Research has found that most aspect words are nouns (or noun phrases), and sentiment is often expressed with adjectives. This additional information has been utilized in previous work on aspect extraction (Hu and Liu, 2004; Benamara et al., 2007; Pang et al., 2002). Inspired by this, we first rely on Part of Speech (POS) Tagging to identify nouns and adjectives. For all noun words, we first calculate their term frequency (TF) in the review corpus, and then compute their inverse document frequency (IDF) from an external Google n-gram corpus&apos;. Finally, we rank their TF*IDF &apos;http://books.google.com/ngrams/datasets h1 !! hi hk 1 i hj hj hF Aspect—i Sentiment—i Wx,y ! Prior Knowledge W1,1 W1,F WD,1 WD,F φ 1 v1 ! ! 1 ! ! D vD φ1 φ4 φ2 Joint Learning with φ φ3 id—i # word count_i D id1_DT id2_NN id3_CC id4_NNS id5_NN </context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of KDD 2004, pages 168–177, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niklas Jakob</author>
<author>Iryna Gurevych</author>
</authors>
<title>Extracting opinion targets in a single-and cross-domain setting with Conditional Random Fields.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP 2010,</booktitle>
<pages>1035--1045</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7854" citStr="Jakob and Gurevych, 2010" startWordPosition="1140" endWordPosition="1143">in online reviews. Methods following their approach exploit frequent noun words and dependency relations to extract product features without supervision (Zhuang et al., 2006; Liu et al., 2005; Somasundaran and Wiebe, 2009). These methods work well when the aspect is strongly associated with a single noun, but obtain less satisfactory results when the aspect emerges from a combination of low frequency items. Additionally, rule-based methods have a common shortcoming in failing to group extracted aspect terms into categories. Supervised learning methods (Jin et al., 2009; Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007) such as Hidden Markov Models, one-class SVMs, and Conditional Random Fields have been widely used in aspect information extraction. These supervised approaches for aspect identification are generally based on standard sequence labeling techniques. The downside of supervised learning is its requirement of large amounts of hand-labeled training data to provide enough information for aspect and opinion identification. Subsequent studies have proposed unsupervised learning methods, especially LDA-based topic modeling, to classify aspects of comments. Specific variants inc</context>
</contexts>
<marker>Jakob, Gurevych, 2010</marker>
<rawString>Niklas Jakob and Iryna Gurevych. 2010. Extracting opinion targets in a single-and cross-domain setting with Conditional Random Fields. In Proceedings of EMNLP 2010, pages 1035–1045. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hung Hay Ho</author>
<author>Rohini K Srihari</author>
</authors>
<title>A novel lexicalized HMM-based learning framework for Web opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of ICML</booktitle>
<pages>465--472</pages>
<contexts>
<context position="3018" citStr="Jin et al., 2009" startWordPosition="425" endWordPosition="428">polarity classification consists in judging whether an opinionated review expresses an overall positive or negative opinion. Regarding aspect identification, previous methods can be divided into three main categories: rule-based, supervised, and topic model-based methods. For instance, association rule-based methods (Hu and Liu, 2004; Liu et al., 1998) tend to focus on extracting product feature words and opinion words but neglect connecting product features at the aspect level. Existing rule-based methods typically are not able to group the extracted aspect terms into categories. Supervised (Jin et al., 2009; Choi and Cardie, 2010) and semisupervised learning methods (Zagibalov and Carroll, 2008; Mukherjee and Liu, 2012) were introduced to resolve certain aspect identification problems. However, supervised training requires handlabeled training data and has trouble coping with domain adaptation scenarios. Hence, unsupervised methods are often adopted to avoid this sort of dependency on labeled data. Latent Dirichlet Allocation, or LDA for short, (Blei et al., 2003) performs well in automatically extracting aspects and grouping corresponding representative words into categories. Thus, a number of </context>
<context position="7805" citStr="Jin et al., 2009" startWordPosition="1132" endWordPosition="1135">raction to distinguish different aspects in online reviews. Methods following their approach exploit frequent noun words and dependency relations to extract product features without supervision (Zhuang et al., 2006; Liu et al., 2005; Somasundaran and Wiebe, 2009). These methods work well when the aspect is strongly associated with a single noun, but obtain less satisfactory results when the aspect emerges from a combination of low frequency items. Additionally, rule-based methods have a common shortcoming in failing to group extracted aspect terms into categories. Supervised learning methods (Jin et al., 2009; Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007) such as Hidden Markov Models, one-class SVMs, and Conditional Random Fields have been widely used in aspect information extraction. These supervised approaches for aspect identification are generally based on standard sequence labeling techniques. The downside of supervised learning is its requirement of large amounts of hand-labeled training data to provide enough information for aspect and opinion identification. Subsequent studies have proposed unsupervised learning methods, especially LDA-based topic modeling, to cl</context>
</contexts>
<marker>Jin, Ho, Srihari, 2009</marker>
<rawString>Wei Jin, Hung Hay Ho, and Rohini K Srihari. 2009. A novel lexicalized HMM-based learning framework for Web opinion mining. In Proceedings of ICML 2009, pages 465–472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nozomi Kobayashi</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Extracting aspect-evaluation and aspect-of relations in opinion mining.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>1065--1074</pages>
<contexts>
<context position="7879" citStr="Kobayashi et al., 2007" startWordPosition="1144" endWordPosition="1147"> following their approach exploit frequent noun words and dependency relations to extract product features without supervision (Zhuang et al., 2006; Liu et al., 2005; Somasundaran and Wiebe, 2009). These methods work well when the aspect is strongly associated with a single noun, but obtain less satisfactory results when the aspect emerges from a combination of low frequency items. Additionally, rule-based methods have a common shortcoming in failing to group extracted aspect terms into categories. Supervised learning methods (Jin et al., 2009; Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007) such as Hidden Markov Models, one-class SVMs, and Conditional Random Fields have been widely used in aspect information extraction. These supervised approaches for aspect identification are generally based on standard sequence labeling techniques. The downside of supervised learning is its requirement of large amounts of hand-labeled training data to provide enough information for aspect and opinion identification. Subsequent studies have proposed unsupervised learning methods, especially LDA-based topic modeling, to classify aspects of comments. Specific variants include the Multi-Grain LDA </context>
</contexts>
<marker>Kobayashi, Inui, Matsumoto, 2007</marker>
<rawString>Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto. 2007. Extracting aspect-evaluation and aspect-of relations in opinion mining. In Proceedings of EMNLP-CoNLL, pages 1065–1074.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenghua Lin</author>
<author>Yulan He</author>
</authors>
<title>Joint sentiment/topic model for sentiment analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM</booktitle>
<pages>375--384</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="8694" citStr="Lin and He (2009)" startWordPosition="1258" endWordPosition="1261">ly based on standard sequence labeling techniques. The downside of supervised learning is its requirement of large amounts of hand-labeled training data to provide enough information for aspect and opinion identification. Subsequent studies have proposed unsupervised learning methods, especially LDA-based topic modeling, to classify aspects of comments. Specific variants include the Multi-Grain LDA model (Titov and McDonald, 2008) to capture local rateable aspects, the two-step approach to detect aspect-specific opinion words (Brody and Elhadad, 2010), the joint sentiment/topic model (JST) by Lin and He (2009), the topic-sentiment mixture model with domain adaption (Mei et al., 2007), which treats sentiment as different topics, and MaxEnt-LDA (Zhao et al., 2010), which integrates a maximum entropy approach into LDA. 617 Latent Topics Figure 1: RBM Schema However, these LDA-based methods can only adopt inaccurate approximations for the posterior distribution over topics rather than exact inference. Additionally, as a mixture model, LDA suffers from the drawbacks mentioned in Section 1 that are common to all mixture models. 3 Model In order to improve over previous work, we first introduce a basic RB</context>
<context position="22412" citStr="Lin &amp; He (2009)" startWordPosition="3689" endWordPosition="3692">old standard label set S = {Food, Staff, Ambience, Price, Anecdote, Miscellaneous}. Following the previous studies, we select reviews with less than 50 sentences and remove stop words. The Stanford POS Tagger3 is used to distinguish noun and adjective words from each other. We later also rely on the Polarity dataset v2.04 to conduct an additional experiment on sentiment classification in order to better assess the model’s overall performance. This dataset focuses on movie reviews and consists of 1000 positive review documents and 1000 negative ones. It has also been used in the experiments by Lin &amp; He (2009), among others. 4.2 Aspect Identification We first apply our novel model to identify aspects from documents in the restaurant review dataset. 4.2.1 Experimental Setup For the experimental setup, we use ten hidden units in our Sentiment-Aspect Extraction RBM (SERBM), where units 0–6 capture aspects, units 7–8 capture sentiment information, and unit 9 stores background information. In particular, we fix hidden units 0–6 to represent the target aspects Food, Staff, Ambience, Price, Ambience, Miscellaneous, and Other Aspects, respectively. Units 7–8 represent positive and negative sentiment, respe</context>
<context position="30733" citStr="Lin &amp; He (2009)" startWordPosition="4970" endWordPosition="4973">y as the evaluation metric. We observe in Table 4 that the sentiment 5http://sentiwordnet.isti.cnr.it 623 Method SentiWordNet SERBM Accuracy 0.703 0.788 Table 4: Accuracy for SERBM and SentiWordNet classification accuracy on the restaurant review dataset sees a relative improvement by 12.1% with SERBM over the SentiWordNet baseline. 4.3.2 Comparison with JST We additionally utilize the Polarity dataset v2.0 to conduct an additional sentiment classification experiment in order to assess SERBM’s performance more thoroughly. We compare SERBM with the advanced joint sentiment/topic model (JST) by Lin &amp; He (2009). For the JST and the TryingJST methods only, we use the filtered subjectivity lexicon (subjective MR) as prior information, containing 374 positive and 675 negative entries, which is the same experimental setting as in Lin &amp; He (2009). For SERBM, we use the same general setup as before except for the fact that aspectspecific priors are not used here. Table 5 provides the sentiment classification accuracies on both the overall dataset and on the subsets for each polarity, where pos. and neg. refer to the positive and negative reviews in the dataset, respectively. Method overall pos. neg. JST(%</context>
</contexts>
<marker>Lin, He, 2009</marker>
<rawString>Chenghua Lin and Yulan He. 2009. Joint sentiment/topic model for sentiment analysis. In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM 2009), pages 375–384. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Wynne Hsu</author>
<author>Yiming Ma</author>
</authors>
<title>Integrating classification and association rule mining.</title>
<date>1998</date>
<booktitle>In Proceedings of KDD</booktitle>
<pages>80--86</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="2756" citStr="Liu et al., 1998" startWordPosition="384" endWordPosition="387"> (kliu@nlpr.ia.ac.cn) from reviews (Hu and Liu, 2004). Consider reviews of computers, for example. A given computer’s components (e.g., hard disk, screen) and attributes (e.g., volume, size) are viewed as aspects to be extracted from the reviews, while sentiment polarity classification consists in judging whether an opinionated review expresses an overall positive or negative opinion. Regarding aspect identification, previous methods can be divided into three main categories: rule-based, supervised, and topic model-based methods. For instance, association rule-based methods (Hu and Liu, 2004; Liu et al., 1998) tend to focus on extracting product feature words and opinion words but neglect connecting product features at the aspect level. Existing rule-based methods typically are not able to group the extracted aspect terms into categories. Supervised (Jin et al., 2009; Choi and Cardie, 2010) and semisupervised learning methods (Zagibalov and Carroll, 2008; Mukherjee and Liu, 2012) were introduced to resolve certain aspect identification problems. However, supervised training requires handlabeled training data and has trouble coping with domain adaptation scenarios. Hence, unsupervised methods are of</context>
</contexts>
<marker>Liu, Hsu, Ma, 1998</marker>
<rawString>Bing Liu, Wynne Hsu, and Yiming Ma. 1998. Integrating classification and association rule mining. In Proceedings of KDD 1998, pages 80–86. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: analyzing and comparing opinions on the Web.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th international conference on World Wide Web,</booktitle>
<pages>342--351</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="7421" citStr="Liu et al., 2005" startWordPosition="1074" endWordPosition="1077"> which is hard to achieve with LDA-based models due to the mixture model sharing mechanism. 4. Last but not the least, this RBM model is capable of jointly modeling aspect and sentiment information together. 2 Related Work We summarize prior state-of-the-art models for aspect extraction. In their seminal work, Hu and Liu (2004) propose the idea of applying classical information extraction to distinguish different aspects in online reviews. Methods following their approach exploit frequent noun words and dependency relations to extract product features without supervision (Zhuang et al., 2006; Liu et al., 2005; Somasundaran and Wiebe, 2009). These methods work well when the aspect is strongly associated with a single noun, but obtain less satisfactory results when the aspect emerges from a combination of low frequency items. Additionally, rule-based methods have a common shortcoming in failing to group extracted aspect terms into categories. Supervised learning methods (Jin et al., 2009; Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007) such as Hidden Markov Models, one-class SVMs, and Conditional Random Fields have been widely used in aspect information extraction. These sup</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: analyzing and comparing opinions on the Web. In Proceedings of the 14th international conference on World Wide Web, pages 342– 351. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kang Liu</author>
<author>Liheng Xu</author>
<author>Jun Zhao</author>
</authors>
<title>Opinion target extraction using word-based translation model.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-CoNLL 2012,</booktitle>
<pages>1346--1356</pages>
<contexts>
<context position="16463" citStr="Liu et al., 2012" startWordPosition="2628" endWordPosition="2631">n unit. The probability of whether a given visible unit affects a specific hidden unit is described as follows (cf. appendix for details): P(hj = 1 |v) =P(hj = 1 |h−j, v) (6) 619 Figure 3: Prior Feature Extraction values and assign them an aspect prior probability pA,vk, indicating their general probability of being an aspect word. This TF-IDF approach is motivated by the following intuitions: the most frequently mentioned candidates in reviews have the highest probability of being an opinion target and false target words are non-domain specific and frequently appear in a general text corpus (Liu et al., 2012; Liu et al., 2013). For all adjective words, if the words are also included in the online sentiment resource SentiWordNet2, we assign prior probability ps,vk to suggest that these words are generally recognized as sentiment words. Apart from these general priors, we obtain a small amount of fine-grained information as another type of prior knowledge. This fine-grained prior knowledge serves to indicate the probability of a known aspect word belonging to a specific aspect, denoted as pAj,vk and an identified sentiment word bearing positive or negative sentiment, denoted as pSj,vk. For instance</context>
</contexts>
<marker>Liu, Xu, Zhao, 2012</marker>
<rawString>Kang Liu, Liheng Xu, and Jun Zhao. 2012. Opinion target extraction using word-based translation model. In Proceedings of EMNLP-CoNLL 2012, pages 1346–1356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kang Liu</author>
<author>Liheng Xu</author>
<author>Yang Liu</author>
<author>Jun Zhao</author>
</authors>
<title>Opinion target extraction using partially-supervised word alignment model.</title>
<date>2013</date>
<booktitle>In Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI2013),</booktitle>
<pages>2134--2140</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="16482" citStr="Liu et al., 2013" startWordPosition="2632" endWordPosition="2635">ility of whether a given visible unit affects a specific hidden unit is described as follows (cf. appendix for details): P(hj = 1 |v) =P(hj = 1 |h−j, v) (6) 619 Figure 3: Prior Feature Extraction values and assign them an aspect prior probability pA,vk, indicating their general probability of being an aspect word. This TF-IDF approach is motivated by the following intuitions: the most frequently mentioned candidates in reviews have the highest probability of being an opinion target and false target words are non-domain specific and frequently appear in a general text corpus (Liu et al., 2012; Liu et al., 2013). For all adjective words, if the words are also included in the online sentiment resource SentiWordNet2, we assign prior probability ps,vk to suggest that these words are generally recognized as sentiment words. Apart from these general priors, we obtain a small amount of fine-grained information as another type of prior knowledge. This fine-grained prior knowledge serves to indicate the probability of a known aspect word belonging to a specific aspect, denoted as pAj,vk and an identified sentiment word bearing positive or negative sentiment, denoted as pSj,vk. For instance, “salad” is always</context>
</contexts>
<marker>Liu, Xu, Liu, Zhao, 2013</marker>
<rawString>Kang Liu, Liheng Xu, Yang Liu, and Jun Zhao. 2013. Opinion target extraction using partially-supervised word alignment model. In Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI2013), pages 2134–2140. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="1619" citStr="Liu, 2012" startWordPosition="225" endWordPosition="226">arious sorts of entities, e.g., products or services, on the Internet, especially in the course of e-commerce activities. Analyzing online reviews not only helps customers obtain useful product information, but also provide companies with feedback to enhance their products or service quality. Aspect-based opinion mining enables people to consider much more finegrained analyses of vast quantities of online reviews, perhaps from numerous different merchant sites. Thus, automatic identification of aspects of entities and relevant sentiment polarities in Big Data is a significant and urgent task (Liu, 2012; Pang and Lee, 2008; Popescu and Etzioni, 2005). Identifying aspect and analyzing sentiment words from reviews has the ultimate goal of discerning people’s opinions, attitudes, emotions, etc. towards entities such as products, services, organizations, individuals, events, etc. In this context, aspect-based opinion mining, also known as feature-based opinion mining, aims at extracting and summarizing particular salient aspects of entities and determining relevant sentiment polarities ∗Corresponding Author: Kang Liu (kliu@nlpr.ia.ac.cn) from reviews (Hu and Liu, 2004). Consider reviews of compu</context>
<context position="3133" citStr="Liu, 2012" startWordPosition="445" endWordPosition="446">on. Regarding aspect identification, previous methods can be divided into three main categories: rule-based, supervised, and topic model-based methods. For instance, association rule-based methods (Hu and Liu, 2004; Liu et al., 1998) tend to focus on extracting product feature words and opinion words but neglect connecting product features at the aspect level. Existing rule-based methods typically are not able to group the extracted aspect terms into categories. Supervised (Jin et al., 2009; Choi and Cardie, 2010) and semisupervised learning methods (Zagibalov and Carroll, 2008; Mukherjee and Liu, 2012) were introduced to resolve certain aspect identification problems. However, supervised training requires handlabeled training data and has trouble coping with domain adaptation scenarios. Hence, unsupervised methods are often adopted to avoid this sort of dependency on labeled data. Latent Dirichlet Allocation, or LDA for short, (Blei et al., 2003) performs well in automatically extracting aspects and grouping corresponding representative words into categories. Thus, a number of LDA-based aspect identification approaches have been proposed in recent years (Brody and Elhadad, 2010; Titov and M</context>
<context position="24570" citStr="Liu, 2012" startWordPosition="4030" endWordPosition="4031">he perplexity scores as defined in Eq. 10 to find the optimal hyperparameters. As a baseline, we also re-implement standard RBMs and the RSM model (Hinton and Salakhutdinov, 2009) to process this same restaurant review dataset and identify aspects for every document in this dataset under the same experimental conditions. We recall that RSM is a similar undirected graphical model that models topics from raw text. Last but not the least, we conduct additional comparative experiments, including with LocLDA (Brody and Elhadad, 2010), MaxEnt-LDA (Zhao et al., 2010) and the SAS model (Mukherjee and Liu, 2012) to extract aspects for this restaurant review dataset under the same experimental conditions. In the following, we use the abbreviated name MELDA to stand for the MaxEnt LDA method. 4.2.2 Evaluation Brody and Elhadad (2010) and Zhao et al. (2010) utilize three aspects to perform a quantitative evaluation and only use sentences with a single label for evaluation to avoid ambiguity. The three major aspects chosen from the gold standard labels are S = {Food, Staff, Ambience}. The evaluation criterion essentially is to judge how well the prediction matches the true label, resulting in Precision, </context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xu Ling</author>
<author>Matthew Wondra</author>
<author>Hang Su</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Topic sentiment mixture: modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th international conference on the World Wide Web (WWW</booktitle>
<pages>171--180</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="8769" citStr="Mei et al., 2007" startWordPosition="1269" endWordPosition="1272">ed learning is its requirement of large amounts of hand-labeled training data to provide enough information for aspect and opinion identification. Subsequent studies have proposed unsupervised learning methods, especially LDA-based topic modeling, to classify aspects of comments. Specific variants include the Multi-Grain LDA model (Titov and McDonald, 2008) to capture local rateable aspects, the two-step approach to detect aspect-specific opinion words (Brody and Elhadad, 2010), the joint sentiment/topic model (JST) by Lin and He (2009), the topic-sentiment mixture model with domain adaption (Mei et al., 2007), which treats sentiment as different topics, and MaxEnt-LDA (Zhao et al., 2010), which integrates a maximum entropy approach into LDA. 617 Latent Topics Figure 1: RBM Schema However, these LDA-based methods can only adopt inaccurate approximations for the posterior distribution over topics rather than exact inference. Additionally, as a mixture model, LDA suffers from the drawbacks mentioned in Section 1 that are common to all mixture models. 3 Model In order to improve over previous work, we first introduce a basic RBM-based model and then describe our modified full model. 3.1 Basic RBM-base</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and ChengXiang Zhai. 2007. Topic sentiment mixture: modeling facets and opinions in weblogs. In Proceedings of the 16th international conference on the World Wide Web (WWW 2007), pages 171–180. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
</authors>
<title>Aspect extraction through semi-supervised modeling.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL 2012,</booktitle>
<pages>339--348</pages>
<contexts>
<context position="3133" citStr="Mukherjee and Liu, 2012" startWordPosition="443" endWordPosition="446">negative opinion. Regarding aspect identification, previous methods can be divided into three main categories: rule-based, supervised, and topic model-based methods. For instance, association rule-based methods (Hu and Liu, 2004; Liu et al., 1998) tend to focus on extracting product feature words and opinion words but neglect connecting product features at the aspect level. Existing rule-based methods typically are not able to group the extracted aspect terms into categories. Supervised (Jin et al., 2009; Choi and Cardie, 2010) and semisupervised learning methods (Zagibalov and Carroll, 2008; Mukherjee and Liu, 2012) were introduced to resolve certain aspect identification problems. However, supervised training requires handlabeled training data and has trouble coping with domain adaptation scenarios. Hence, unsupervised methods are often adopted to avoid this sort of dependency on labeled data. Latent Dirichlet Allocation, or LDA for short, (Blei et al., 2003) performs well in automatically extracting aspects and grouping corresponding representative words into categories. Thus, a number of LDA-based aspect identification approaches have been proposed in recent years (Brody and Elhadad, 2010; Titov and M</context>
<context position="24570" citStr="Mukherjee and Liu, 2012" startWordPosition="4028" endWordPosition="4031">tion, we use the perplexity scores as defined in Eq. 10 to find the optimal hyperparameters. As a baseline, we also re-implement standard RBMs and the RSM model (Hinton and Salakhutdinov, 2009) to process this same restaurant review dataset and identify aspects for every document in this dataset under the same experimental conditions. We recall that RSM is a similar undirected graphical model that models topics from raw text. Last but not the least, we conduct additional comparative experiments, including with LocLDA (Brody and Elhadad, 2010), MaxEnt-LDA (Zhao et al., 2010) and the SAS model (Mukherjee and Liu, 2012) to extract aspects for this restaurant review dataset under the same experimental conditions. In the following, we use the abbreviated name MELDA to stand for the MaxEnt LDA method. 4.2.2 Evaluation Brody and Elhadad (2010) and Zhao et al. (2010) utilize three aspects to perform a quantitative evaluation and only use sentences with a single label for evaluation to avoid ambiguity. The three major aspects chosen from the gold standard labels are S = {Food, Staff, Ambience}. The evaluation criterion essentially is to judge how well the prediction matches the true label, resulting in Precision, </context>
</contexts>
<marker>Mukherjee, Liu, 2012</marker>
<rawString>Arjun Mukherjee and Bing Liu. 2012. Aspect extraction through semi-supervised modeling. In Proceedings of ACL 2012, pages 339–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Foundations and trends in information retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="1639" citStr="Pang and Lee, 2008" startWordPosition="227" endWordPosition="230">s of entities, e.g., products or services, on the Internet, especially in the course of e-commerce activities. Analyzing online reviews not only helps customers obtain useful product information, but also provide companies with feedback to enhance their products or service quality. Aspect-based opinion mining enables people to consider much more finegrained analyses of vast quantities of online reviews, perhaps from numerous different merchant sites. Thus, automatic identification of aspects of entities and relevant sentiment polarities in Big Data is a significant and urgent task (Liu, 2012; Pang and Lee, 2008; Popescu and Etzioni, 2005). Identifying aspect and analyzing sentiment words from reviews has the ultimate goal of discerning people’s opinions, attitudes, emotions, etc. towards entities such as products, services, organizations, individuals, events, etc. In this context, aspect-based opinion mining, also known as feature-based opinion mining, aims at extracting and summarizing particular salient aspects of entities and determining relevant sentiment polarities ∗Corresponding Author: Kang Liu (kliu@nlpr.ia.ac.cn) from reviews (Hu and Liu, 2004). Consider reviews of computers, for example. A</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP 2002,</booktitle>
<pages>79--86</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="15026" citStr="Pang et al., 2002" startWordPosition="2368" endWordPosition="2371">riors for words in reviews and incorporate this information into the learning process of our Sentiment-Aspect Extraction model. We regularize our model based on these priors to constrain the aspect modeling and improve its accuracy. Figure 3 provides an example of how such priors can be applied to a sentence, with Oi representing the prior knowledge. Research has found that most aspect words are nouns (or noun phrases), and sentiment is often expressed with adjectives. This additional information has been utilized in previous work on aspect extraction (Hu and Liu, 2004; Benamara et al., 2007; Pang et al., 2002). Inspired by this, we first rely on Part of Speech (POS) Tagging to identify nouns and adjectives. For all noun words, we first calculate their term frequency (TF) in the review corpus, and then compute their inverse document frequency (IDF) from an external Google n-gram corpus&apos;. Finally, we rank their TF*IDF &apos;http://books.google.com/ngrams/datasets h1 !! hi hk 1 i hj hj hF Aspect—i Sentiment—i Wx,y ! Prior Knowledge W1,1 W1,F WD,1 WD,F φ 1 v1 ! ! 1 ! ! D vD φ1 φ4 φ2 Joint Learning with φ φ3 id—i # word count_i D id1_DT id2_NN id3_CC id4_NNS id5_NN id6y id7_VBZ id8y POS Sentence E(v, h) = − </context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: Sentiment classification using machine learning techniques. In Proceedings of EMNLP 2002, pages 79–86. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Orena Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="1667" citStr="Popescu and Etzioni, 2005" startWordPosition="231" endWordPosition="234"> products or services, on the Internet, especially in the course of e-commerce activities. Analyzing online reviews not only helps customers obtain useful product information, but also provide companies with feedback to enhance their products or service quality. Aspect-based opinion mining enables people to consider much more finegrained analyses of vast quantities of online reviews, perhaps from numerous different merchant sites. Thus, automatic identification of aspects of entities and relevant sentiment polarities in Big Data is a significant and urgent task (Liu, 2012; Pang and Lee, 2008; Popescu and Etzioni, 2005). Identifying aspect and analyzing sentiment words from reviews has the ultimate goal of discerning people’s opinions, attitudes, emotions, etc. towards entities such as products, services, organizations, individuals, events, etc. In this context, aspect-based opinion mining, also known as feature-based opinion mining, aims at extracting and summarizing particular salient aspects of entities and determining relevant sentiment polarities ∗Corresponding Author: Kang Liu (kliu@nlpr.ia.ac.cn) from reviews (Hu and Liu, 2004). Consider reviews of computers, for example. A given computer’s components</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Orena Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of HLT/EMNLP 2005. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Janyce Wiebe</author>
</authors>
<title>Recognizing stances in online debates.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP 2009,</booktitle>
<pages>226--234</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7452" citStr="Somasundaran and Wiebe, 2009" startWordPosition="1078" endWordPosition="1081">achieve with LDA-based models due to the mixture model sharing mechanism. 4. Last but not the least, this RBM model is capable of jointly modeling aspect and sentiment information together. 2 Related Work We summarize prior state-of-the-art models for aspect extraction. In their seminal work, Hu and Liu (2004) propose the idea of applying classical information extraction to distinguish different aspects in online reviews. Methods following their approach exploit frequent noun words and dependency relations to extract product features without supervision (Zhuang et al., 2006; Liu et al., 2005; Somasundaran and Wiebe, 2009). These methods work well when the aspect is strongly associated with a single noun, but obtain less satisfactory results when the aspect emerges from a combination of low frequency items. Additionally, rule-based methods have a common shortcoming in failing to group extracted aspect terms into categories. Supervised learning methods (Jin et al., 2009; Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007) such as Hidden Markov Models, one-class SVMs, and Conditional Random Fields have been widely used in aspect information extraction. These supervised approaches for aspect i</context>
</contexts>
<marker>Somasundaran, Wiebe, 2009</marker>
<rawString>Swapna Somasundaran and Janyce Wiebe. 2009. Recognizing stances in online debates. In Proceedings of ACL-IJCNLP 2009, pages 226–234. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th international conference on the World Wide Web (WWW</booktitle>
<pages>111--120</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3746" citStr="Titov and McDonald, 2008" startWordPosition="532" endWordPosition="535"> Liu, 2012) were introduced to resolve certain aspect identification problems. However, supervised training requires handlabeled training data and has trouble coping with domain adaptation scenarios. Hence, unsupervised methods are often adopted to avoid this sort of dependency on labeled data. Latent Dirichlet Allocation, or LDA for short, (Blei et al., 2003) performs well in automatically extracting aspects and grouping corresponding representative words into categories. Thus, a number of LDA-based aspect identification approaches have been proposed in recent years (Brody and Elhadad, 2010; Titov and McDonald, 2008; Zhao et al., 2010). Still, these methods have several important drawbacks. First, inaccurate approximations of the distribution over topics may reduce the computational accuracy. Second, mixture models are unable to exploit the co-occurrence of topics to yield high probability predictions for words that are sharper than the distributions predicted by in616 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 616–625, Beijing, China, July 26-31, 2015. c�2015 Association for Comp</context>
<context position="8511" citStr="Titov and McDonald, 2008" startWordPosition="1231" endWordPosition="1234">s Hidden Markov Models, one-class SVMs, and Conditional Random Fields have been widely used in aspect information extraction. These supervised approaches for aspect identification are generally based on standard sequence labeling techniques. The downside of supervised learning is its requirement of large amounts of hand-labeled training data to provide enough information for aspect and opinion identification. Subsequent studies have proposed unsupervised learning methods, especially LDA-based topic modeling, to classify aspects of comments. Specific variants include the Multi-Grain LDA model (Titov and McDonald, 2008) to capture local rateable aspects, the two-step approach to detect aspect-specific opinion words (Brody and Elhadad, 2010), the joint sentiment/topic model (JST) by Lin and He (2009), the topic-sentiment mixture model with domain adaption (Mei et al., 2007), which treats sentiment as different topics, and MaxEnt-LDA (Zhao et al., 2010), which integrates a maximum entropy approach into LDA. 617 Latent Topics Figure 1: RBM Schema However, these LDA-based methods can only adopt inaccurate approximations for the posterior distribution over topics rather than exact inference. Additionally, as a mi</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008. Modeling online reviews with multi-grain topic models. In Proceedings of the 17th international conference on the World Wide Web (WWW 2008), pages 111–120. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taras Zagibalov</author>
<author>John Carroll</author>
</authors>
<title>Automatic seed word selection for unsupervised sentiment classification of Chinese text.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>1073--1080</pages>
<contexts>
<context position="3107" citStr="Zagibalov and Carroll, 2008" startWordPosition="438" endWordPosition="442">esses an overall positive or negative opinion. Regarding aspect identification, previous methods can be divided into three main categories: rule-based, supervised, and topic model-based methods. For instance, association rule-based methods (Hu and Liu, 2004; Liu et al., 1998) tend to focus on extracting product feature words and opinion words but neglect connecting product features at the aspect level. Existing rule-based methods typically are not able to group the extracted aspect terms into categories. Supervised (Jin et al., 2009; Choi and Cardie, 2010) and semisupervised learning methods (Zagibalov and Carroll, 2008; Mukherjee and Liu, 2012) were introduced to resolve certain aspect identification problems. However, supervised training requires handlabeled training data and has trouble coping with domain adaptation scenarios. Hence, unsupervised methods are often adopted to avoid this sort of dependency on labeled data. Latent Dirichlet Allocation, or LDA for short, (Blei et al., 2003) performs well in automatically extracting aspects and grouping corresponding representative words into categories. Thus, a number of LDA-based aspect identification approaches have been proposed in recent years (Brody and </context>
</contexts>
<marker>Zagibalov, Carroll, 2008</marker>
<rawString>Taras Zagibalov and John Carroll. 2008. Automatic seed word selection for unsupervised sentiment classification of Chinese text. In Proceedings of COLING 2008, pages 1073–1080.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Xin Zhao</author>
<author>Jing Jiang</author>
<author>Hongfei Yan</author>
<author>Xiaoming Li</author>
</authors>
<title>Jointly modeling aspects and opinions with a MaxEnt-LDA hybrid.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP 2010,</booktitle>
<pages>56--65</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3766" citStr="Zhao et al., 2010" startWordPosition="536" endWordPosition="539">d to resolve certain aspect identification problems. However, supervised training requires handlabeled training data and has trouble coping with domain adaptation scenarios. Hence, unsupervised methods are often adopted to avoid this sort of dependency on labeled data. Latent Dirichlet Allocation, or LDA for short, (Blei et al., 2003) performs well in automatically extracting aspects and grouping corresponding representative words into categories. Thus, a number of LDA-based aspect identification approaches have been proposed in recent years (Brody and Elhadad, 2010; Titov and McDonald, 2008; Zhao et al., 2010). Still, these methods have several important drawbacks. First, inaccurate approximations of the distribution over topics may reduce the computational accuracy. Second, mixture models are unable to exploit the co-occurrence of topics to yield high probability predictions for words that are sharper than the distributions predicted by in616 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 616–625, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistic</context>
<context position="8849" citStr="Zhao et al., 2010" startWordPosition="1281" endWordPosition="1284">o provide enough information for aspect and opinion identification. Subsequent studies have proposed unsupervised learning methods, especially LDA-based topic modeling, to classify aspects of comments. Specific variants include the Multi-Grain LDA model (Titov and McDonald, 2008) to capture local rateable aspects, the two-step approach to detect aspect-specific opinion words (Brody and Elhadad, 2010), the joint sentiment/topic model (JST) by Lin and He (2009), the topic-sentiment mixture model with domain adaption (Mei et al., 2007), which treats sentiment as different topics, and MaxEnt-LDA (Zhao et al., 2010), which integrates a maximum entropy approach into LDA. 617 Latent Topics Figure 1: RBM Schema However, these LDA-based methods can only adopt inaccurate approximations for the posterior distribution over topics rather than exact inference. Additionally, as a mixture model, LDA suffers from the drawbacks mentioned in Section 1 that are common to all mixture models. 3 Model In order to improve over previous work, we first introduce a basic RBM-based model and then describe our modified full model. 3.1 Basic RBM-based Model Restricted Boltzmann Machines can be used for topic modeling by relying </context>
<context position="21660" citStr="Zhao et al., 2010" startWordPosition="3566" endWordPosition="3569">ion with respect to the parameter W. Denoting ln ∂L ∂W as ∇W, in each step we update ∇Wjk by adding λ hP(hj = 1|v(0))v(k0) − P(hj = 1|v(cdm))v(kcdm)i 2Gjbvk (1 + Gj)2( 1 1+Gj − pAj,vk) 2Gjbvk (1 + Gj)2( 1 1+Gj − pSj,vk) where Gj=e−(aj+Wjk ) for convenience, and v(cdm) is the result from the CD-m steps. 4 Experiments We present a series of experiments to evaluate our model’s performance on the aspect identification and sentiment classification tasks. 4.1 Data For this evaluation, we rely on a restaurant review dataset widely adopted by previous work (Ganu et al., 2009; Brody and Elhadad, 2010; Zhao et al., 2010), which contains 1,644,923 tokens and 52,574 documents in total. Documents in this dataset are annotated with one or more labels from a gold standard label set S = {Food, Staff, Ambience, Price, Anecdote, Miscellaneous}. Following the previous studies, we select reviews with less than 50 sentences and remove stop words. The Stanford POS Tagger3 is used to distinguish noun and adjective words from each other. We later also rely on the Polarity dataset v2.04 to conduct an additional experiment on sentiment classification in order to better assess the model’s overall performance. This dataset foc</context>
<context position="23688" citStr="Zhao et al. (2010)" startWordPosition="3882" endWordPosition="3885">irrelevant background information. Note that the structure of our model needs no modifications for new reviews. There are two cases for datasets from a new domain. If the new 3http://nlp.stanford.edu/software/tagger.shtml 4http://www.cs.cornell.edu/people/pabo/ movie-review-data/ 621 Method RBM RSM SERBM PPL 49.73 39.19 21.18 Table 1: Results in terms of perplexity dataset has a gold standard label set, then we assign one hidden unit to represent each label in the gold standard set. If not, our model only obtains the priors pA,vk and pS,vk, and the aspect set can be inferred as in the work of Zhao et al. (2010). For evaluation, following previous work, the annotated data is fed into our unsupervised model, without any of the corresponding labels. The model is then evaluated in terms of how well its prediction matches the true labels. As for hyperparameter optimization, we use the perplexity scores as defined in Eq. 10 to find the optimal hyperparameters. As a baseline, we also re-implement standard RBMs and the RSM model (Hinton and Salakhutdinov, 2009) to process this same restaurant review dataset and identify aspects for every document in this dataset under the same experimental conditions. We re</context>
</contexts>
<marker>Zhao, Jiang, Yan, Li, 2010</marker>
<rawString>Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaoming Li. 2010. Jointly modeling aspects and opinions with a MaxEnt-LDA hybrid. In Proceedings of EMNLP 2010, pages 56–65. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhuang</author>
<author>Feng Jing</author>
<author>Xiao-Yan Zhu</author>
</authors>
<title>Movie review mining and summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th ACM international Conference on Information and Knowledge Management (CIKM</booktitle>
<pages>43--50</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="7403" citStr="Zhuang et al., 2006" startWordPosition="1070" endWordPosition="1073">spects and sentiment, which is hard to achieve with LDA-based models due to the mixture model sharing mechanism. 4. Last but not the least, this RBM model is capable of jointly modeling aspect and sentiment information together. 2 Related Work We summarize prior state-of-the-art models for aspect extraction. In their seminal work, Hu and Liu (2004) propose the idea of applying classical information extraction to distinguish different aspects in online reviews. Methods following their approach exploit frequent noun words and dependency relations to extract product features without supervision (Zhuang et al., 2006; Liu et al., 2005; Somasundaran and Wiebe, 2009). These methods work well when the aspect is strongly associated with a single noun, but obtain less satisfactory results when the aspect emerges from a combination of low frequency items. Additionally, rule-based methods have a common shortcoming in failing to group extracted aspect terms into categories. Supervised learning methods (Jin et al., 2009; Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007) such as Hidden Markov Models, one-class SVMs, and Conditional Random Fields have been widely used in aspect information ext</context>
</contexts>
<marker>Zhuang, Jing, Zhu, 2006</marker>
<rawString>Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006. Movie review mining and summarization. In Proceedings of the 15th ACM international Conference on Information and Knowledge Management (CIKM 2006), pages 43–50. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>