<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.994051">
Multi-Prototype Vector-Space Models of Word Meaning
</title>
<author confidence="0.998016">
Joseph Reisinger
</author>
<affiliation confidence="0.992584333333333">
Department of Computer Science
The University of Texas at Austin
1 University Station C0500
</affiliation>
<address confidence="0.810727">
Austin, TX 78712-0233
</address>
<email confidence="0.998877">
joeraii@cs.utexas.edu
</email>
<author confidence="0.949569">
Raymond J. Mooney
</author>
<affiliation confidence="0.992413333333333">
Department of Computer Science
The University of Texas at Austin
1 University Station C0500
</affiliation>
<address confidence="0.810789">
Austin, TX 78712-0233
</address>
<email confidence="0.999113">
mooney@cs.utexas.edu
</email>
<sectionHeader confidence="0.993867" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9989180625">
Current vector-space models of lexical seman-
tics create a single “prototype” vector to rep-
resent the meaning of a word. However, due
to lexical ambiguity, encoding word mean-
ing with a single vector is problematic. This
paper presents a method that uses cluster-
ing to produce multiple “sense-specific” vec-
tors for each word. This approach provides
a context-dependent vector representation of
word meaning that naturally accommodates
homonymy and polysemy. Experimental com-
parisons to human judgements of semantic
similarity for both isolated words as well as
words in sentential contexts demonstrate the
superiority of this approach over both proto-
type and exemplar based vector-space models.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999968056603774">
Automatically judging the degree of semantic sim-
ilarity between words is an important task useful
in text classification (Baker and McCallum, 1998),
information retrieval (Sanderson, 1994), textual en-
tailment, and other language processing tasks. The
standard empirical approach to this task exploits the
distributional hypothesis, i.e. that similar words ap-
pear in similar contexts (Curran and Moens, 2002;
Lin and Pantel, 2002; Pereira et al., 1993). Tra-
ditionally, word types are represented by a sin-
gle vector of contextual features derived from co-
occurrence information, and semantic similarity is
computed using some measure of vector distance
(Lee, 1999; Lowe, 2001).
However, due to homonymy and polysemy, cap-
turing the semantics of a word with a single vector is
problematic. For example, the word club is similar
to both bat and association, which are not at all simi-
lar to each other. Word meaning violates the triangle
inequality when viewed at the level of word types,
posing a problem for vector-space models (Tver-
sky and Gati, 1982). A single “prototype” vector
is simply incapable of capturing phenomena such as
homonymy and polysemy. Also, most vector-space
models are context independent, while the meaning
of a word clearly depends on context. The word club
in “The caveman picked up the club” is similar to bat
in “John hit the robber with a bat,” but not in “The
bat flew out of the cave.”
We present a new resource-lean vector-space
model that represents a word’s meaning by a set of
distinct “sense specific” vectors. The similarity of
two isolated words A and B is defined as the mini-
mum distance between one of A’s vectors and one of
B’s vectors. In addition, a context-dependent mean-
ing for a word is determined by choosing one of the
vectors in its set based on minimizing the distance
to the vector representing the current context. Con-
sequently, the model supports judging the similarity
of both words in isolation and words in context.
The set of vectors for a word is determined by un-
supervised word sense discovery (WSD) (Sch¨utze,
1998), which clusters the contexts in which a word
appears. In previous work, vector-space lexical sim-
ilarity and word sense discovery have been treated
as two separate tasks. This paper shows how they
can be combined to create an improved vector-space
model of lexical semantics. First, a word’s contexts
are clustered to produce groups of similar context
vectors. An average “prototype” vector is then com-
puted separately for each cluster, producing a set of
vectors for each word. Finally, as described above,
these cluster vectors can be used to determine the se-
</bodyText>
<page confidence="0.987705">
109
</page>
<note confidence="0.7527305">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 109–117,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999679913043478">
mantic similarity of both isolated words and words
in context. The approach is completely modular, and
can integrate any clustering method with any tradi-
tional vector-space model.
We present experimental comparisons to human
judgements of semantic similarity for both isolated
words and words in sentential context. The results
demonstrate the superiority of a clustered approach
over both traditional prototype and exemplar-based
vector-space models. For example, given the iso-
lated target word singer our method produces the
most similar word vocalist, while using a single pro-
totype gives musician. Given the word cell in the
context: “The book was published while Piasecki
was still in prison, and a copy was delivered to his
cell.” the standard approach produces protein while
our method yields incarcerated.
The remainder of the paper is organized as fol-
lows: Section 2 gives relevant background on pro-
totype and exemplar methods for lexical semantics,
Section 3 presents our multi-prototype method, Sec-
tion 4 presents our experimental evaluations, Section
5 discusses future work, and Section 6 concludes.
</bodyText>
<sectionHeader confidence="0.970707" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.9937985">
Psychological concept models can be roughly di-
vided into two classes:
</bodyText>
<listItem confidence="0.9984845">
1. Prototype models represented concepts by an
abstract prototypical instance, similar to a clus-
ter centroid in parametric density estimation.
2. Exemplar models represent concepts by a con-
</listItem>
<bodyText confidence="0.911134541666667">
crete set of observed instances, similar to non-
parametric approaches to density estimation in
statistics (Ashby and Alfonso-Reese, 1995).
Tversky and Gati (1982) famously showed that con-
ceptual similarity violates the triangle inequality,
lending evidence for exemplar-based models in psy-
chology. Exemplar models have been previously
used for lexical semantics problems such as selec-
tional preference (Erk, 2007) and thematic fit (Van-
dekerckhove et al., 2009). Individual exemplars can
be quite noisy and the model can incur high com-
putational overhead at prediction time since naively
computing the similarity between two words using
each occurrence in a textual corpus as an exemplar
requires O(n2) comparisons. Instead, the standard
... chose Zbigniew Brzezinski
for the position of ...
... thus the symbol s position
on his clothing was ...
... writes call options against
the stock position ...
... offered a position with ...
... a position he would hold
until his retirement in ...
</bodyText>
<figure confidence="0.980633">
... endanger their position as
a cultural group...
... on the chart of the vessel s
current position ...
... not in a position to help...
(collect contexts) (cluster)
</figure>
<figureCaption confidence="0.998768">
Figure 1: Overview of the multi-prototype approach
</figureCaption>
<bodyText confidence="0.99580221875">
to near-synonym discovery for a single target word
independent of context. Occurrences are clustered
and cluster centroids are used as prototype vectors.
Note the “hurricane” sense of position (cluster 3) is
not typically considered appropriate in WSD.
approach is to compute a single prototype vector for
each word from its occurrences.
This paper presents a multi-prototype vector space
model for lexical semantics with a single parame-
ter K (the number of clusters) that generalizes both
prototype (K = 1) and exemplar (K = N, the total
number of instances) methods. Such models have
been widely studied in the Psychology literature
(Griffiths et al., 2007; Love et al., 2004; Rosseel,
2002). By employing multiple prototypes per word,
vector space models can account for homonymy,
polysemy and thematic variation in word usage.
Furthermore, such approaches require only O(K2)
comparisons for computing similarity, yielding po-
tential computational savings over the exemplar ap-
proach when K « N, while reaping many of the
same benefits.
Previous work on lexical semantic relatedness has
focused on two approaches: (1) mining monolin-
gual or bilingual dictionaries or other pre-existing
resources to construct networks of related words
(Agirre and Edmond, 2006; Ramage et al., 2009),
and (2) using the distributional hypothesis to au-
tomatically infer a vector-space prototype of word
meaning from large corpora (Agirre et al., 2009;
Curran, 2004; Harris, 1954). The former approach
tends to have greater precision, but depends on hand-
</bodyText>
<figure confidence="0.998196842105263">
single
prototype
(similarity)
(cluster#4)
lineman,
tackle, role,
scorer
(cluster#1)
location
importance
bombing
(cluster#2)
post
appointme
nt, role, job
(cluster#3)
intensity,
winds,
hour, gust
</figure>
<page confidence="0.983815">
110
</page>
<bodyText confidence="0.999935294117647">
crafted dictionaries and cannot, in general, model
sense frequency (Budanitsky and Hirst, 2006). The
latter approach is fundamentally more scalable as it
does not rely on specific resources and can model
corpus-specific sense distributions. However, the
distributional approach can suffer from poor preci-
sion, as thematically similar words (e.g., singer and
actor) and antonyms often occur in similar contexts
(Lin et al., 2003).
Unsupervised word-sense discovery has been
studied by number of researchers (Agirre and Ed-
mond, 2006; Sch¨utze, 1998). Most work has also
focused on corpus-based distributional approaches,
varying the vector-space representation, e.g. by in-
corporating syntactic and co-occurrence information
from the words surrounding the target term (Pereira
et al., 1993; Pantel and Lin, 2002).
</bodyText>
<sectionHeader confidence="0.996029" genericHeader="method">
3 Multi-Prototype Vector-Space Models
</sectionHeader>
<bodyText confidence="0.999981777777778">
Our approach is similar to standard vector-space
models of word meaning, with the addition of a per-
word-type clustering step: Occurrences for a spe-
cific word type are collected from the corpus and
clustered using any appropriate method (§3.1). Sim-
ilarity between two word types is then computed as
a function of their cluster centroids (§3.2), instead of
the centroid of all the word’s occurrences. Figure 1
gives an overview of this process.
</bodyText>
<subsectionHeader confidence="0.999661">
3.1 Clustering Occurrences
</subsectionHeader>
<bodyText confidence="0.99994928">
Multiple prototypes for each word w are generated
by clustering feature vectors v(c) derived from each
occurrence c E C(w) in a large textual corpus and
collecting the resulting cluster centroids 7rk(w), k E
[1, K]. This approach is commonly employed in un-
supervised word sense discovery; however, we do
not assume that clusters correspond to traditional
word senses. Rather, we only rely on clusters to cap-
ture meaningful variation in word usage.
Our experiments employ a mixture of von Mises-
Fisher distributions (movMF) clustering method
with first-order unigram contexts (Banerjee et al.,
2005). Feature vectors v(c) are composed of indi-
vidual features I(c, f), taken as all unigrams occur-
ring f E F in a 10-word window around w.
Like spherical k-means (Dhillon and Modha,
2001), movMF models semantic relatedness using
cosine similarity, a standard measure of textual sim-
ilarity. However, movMF introduces an additional
per-cluster concentration parameter controlling its
semantic breadth, allowing it to more accurately
model non-uniformities in the distribution of cluster
sizes. Based on preliminary experiments comparing
various clustering methods, we found movMF gave
the best results.
</bodyText>
<subsectionHeader confidence="0.999923">
3.2 Measuring Semantic Similarity
</subsectionHeader>
<bodyText confidence="0.999956714285714">
The similarity between two words in a multi-
prototype model can be computed straightforwardly,
requiring only simple modifications to standard dis-
tributional similarity methods such as those pre-
sented by Curran (2004). Given words w and w0, we
define two noncontextual clustered similarity met-
rics to measure similarity of isolated words:
</bodyText>
<equation confidence="0.992698833333333">
XK
AvgSim(w, w&apos;) def � 1
K2
j=1
MaxSim(w, w&apos;) def � max
1&lt;j&lt;K,1&lt;k&lt;K
</equation>
<bodyText confidence="0.999916833333333">
where d(·, ·) is a standard distributional similarity
measure. In AvgSim, word similarity is computed
as the average similarity of all pairs of prototype
vectors; In MaxSim the similarity is the maximum
over all pairwise prototype similarities. All results
reported in this paper use cosine similarity, 1
</bodyText>
<equation confidence="0.571577">
Cos (w, w0) _ P f ∈F I (w, f) · I (w0, f)
</equation>
<bodyText confidence="0.999821866666667">
We compare across two different feature functions
tf-idf weighting and X2 weighting, chosen due to
their ubiquity in the literature (Agirre et al., 2009;
Curran, 2004).
In AvgSim, all prototype pairs contribute equally
to the similarity computation, thus two words are
judged as similar if many of their senses are simi-
lar. MaxSim, on the other hand, only requires a sin-
gle pair of prototypes to be close for the words to be
judged similar. Thus, MaxSim models the similarity
of words that share only a single sense (e.g. bat and
club) at the cost of lower robustness to noisy clusters
that might be introduced when K is large.
When contextual information is available,
AvgSim and MaxSim can be modified to produce
</bodyText>
<footnote confidence="0.791215">
1The main results also hold for weighted Jaccard similarity.
</footnote>
<equation confidence="0.9958436">
K
X d(7rk(w), 7rj(w&apos;))
k=1
d(7rk(w), 7rj(w&apos;))
qPf∈F I(w,f)2qPf∈F I(w0,f)2
</equation>
<page confidence="0.958186">
111
</page>
<bodyText confidence="0.956464">
more precise similarity computations:
</bodyText>
<equation confidence="0.945583">
def
AvgSimC (w, w&apos;) =
dc,w,kdc,,w,,jd(7rk(w),7rj(w&apos;))
MaxSimC(w, w&apos;) def = d(�r(w), �r(w&apos;))
def
</equation>
<bodyText confidence="0.999862785714286">
where d�,w,k = d(v(c), 7rk(w)) is the likelihood of
context c belonging to cluster 7rk(w), and �r(w) def=
7rargmax1&lt;k&lt;K dc,w,k(w), the maximum likelihood
cluster for w in context c. Thus, AvgSimC corre-
sponds to soft cluster assignment, weighting each
similarity term in AvgSim by the likelihood of the
word contexts appearing in their respective clus-
ters. MaxSimC corresponds to hard assignment,
using only the most probable cluster assignment.
Note that AvgSim and MaxSim can be thought of as
special cases of AvgSimC and MaxSimC with uni-
form weight to each cluster; hence AvgSimC and
MaxSimC can be used to compare words in context
to isolated words as well.
</bodyText>
<sectionHeader confidence="0.999741" genericHeader="method">
4 Experimental Evaluation
</sectionHeader>
<subsectionHeader confidence="0.994179">
4.1 Corpora
</subsectionHeader>
<bodyText confidence="0.99989">
We employed two corpora to train our models:
</bodyText>
<listItem confidence="0.882171">
1. A snapshot of English Wikipedia taken on Sept.
</listItem>
<bodyText confidence="0.828735692307692">
29th, 2009. Wikitext markup is removed, as
are articles with fewer than 100 words, leaving
2.8M articles with a total of 2.0513 words.
2. The third edition English Gigaword corpus,
with articles containing fewer than 100 words
removed, leaving 6.6M articles and 3.913 words
(Graff, 2003).
Wikipedia covers a wider range of sense distribu-
tions, whereas Gigaword contains only newswire
text and tends to employ fewer senses of most am-
biguous words. Our method outperforms baseline
methods even on Gigaword, indicating its advan-
tages even when the corpus covers few senses.
</bodyText>
<subsectionHeader confidence="0.995313">
4.2 Judging Semantic Similarity
</subsectionHeader>
<bodyText confidence="0.976688530612245">
To evaluate the quality of various models, we first
compared their lexical similarity measurements to
human similarity judgements from the WordSim-
353 data set (Finkelstein et al., 2001). This test
corpus contains multiple human judgements on 353
word pairs, covering both monosemous and poly-
semous words, each rated on a 1–10 integer scale.
Spearman’s rank correlation (p) with average human
judgements (Agirre et al., 2009) was used to mea-
sure the quality of various models.
Figure 2 plots Spearman’s p on WordSim-353
against the number of clusters (K) for Wikipedia
and Gigaword corpora, using pruned tf-idf and k2
features.2 In general pruned tf-idf features yield
higher correlation than k2 features. Using AvgSim,
the multi-prototype approach (K &gt; 1) yields higher
correlation than the single-prototype approach (K =
1) across all corpora and feature types, achieving
state-of-the-art results with pruned tf-idf features.
This result is statistically significant in all cases for
tf-idf and for K E [2,10] on Wikipedia and K &gt; 4
on Gigaword for k2 features.3 MaxSim yields simi-
lar performance when K &lt; 10 but performance de-
grades as K increases.
It is possible to circumvent the model-selection
problem (choosing the best value of K) by simply
combining the prototypes from clusterings of dif-
ferent sizes. This approach represents words using
both semantically broad and semantically tight pro-
totypes, similar to hierarchical clustering. Table 1
and Figure 2 (squares) show the result of such a com-
bined approach, where the prototypes for clusterings
of size 2-5, 10, 20, 50, and 100 are unioned to form a
single large prototype set. In general, this approach
works about as well as picking the optimal value of
K, even outperforming the single best cluster size
for Wikipedia.
Finally, we also compared our method to a pure
exemplar approach, averaging similarity across all
occurrence pairs.4 Table 1 summarizes the results.
The exemplar approach yields significantly higher
correlation than the single prototype approach in all
cases except Gigaword with tf-idf features (p &lt;
0.05). Furthermore, it performs significantly worse
2(Feature pruning) We find that results using tf-idf features
are extremely sensitive to feature pruning while x2 features are
more robust. In all experiments we prune tf-idf features by their
overall weight, taking the top 5000. This setting was found to
optimize the performance of the single-prototype approach.
</bodyText>
<footnote confidence="0.99587325">
3Significance is calculated using the large-sample approxi-
mation of the Spearman rank test; (p &lt; 0.05).
4Averaging across all pairs was found to yield higher corre-
lation than averaging over the most similar pairs.
</footnote>
<equation confidence="0.930978875">
1
K2
K
E
k=1
K
E
j=1
</equation>
<page confidence="0.980808">
112
</page>
<table confidence="0.999104333333333">
Spearman’s p prototype exemplar multi-prototype (AvgSim) combined
K = 5 K = 20 K = 50
Wikipedia tf-idf 0.53±0.02 0.60±0.06 0.69±0.02 0.76±0.01 0.76±0.01 0.77±0.01
Wikipedia x2 0.54±0.03 0.65±0.07 0.58±0.02 0.56±0.02 0.52±0.03 0.59±0.04
Gigaword tf-idf 0.49±0.02 0.48±0.10 0.64±0.02 0.61±0.02 0.61±0.02 0.62±0.02
Gigaword x2 0.25±0.03 0.41±0.14 0.32±0.03 0.35±0.03 0.33±0.03 0.34±0.03
</table>
<tableCaption confidence="0.999794">
Table 1: Spearman correlation on the WordSim-353 dataset broken down by corpus and feature type.
</tableCaption>
<figureCaption confidence="0.827662">
Figure 2: WordSim-353 rank correlation vs. num-
</figureCaption>
<bodyText confidence="0.942596692307692">
ber of clusters (log scale) for both the Wikipedia
(left) and Gigaword (right) corpora. Horizontal bars
show the performance of single-prototype. Squares
indicate performance when combining across clus-
terings. Error bars depict 95% confidence intervals
using the Spearman test. Squares indicate perfor-
mance when combining across clusterings.
than combined multi-prototype for tf-idf features,
and does not differ significantly for x2 features.
Overall this result indicates that multi-prototype per-
forms at least as well as exemplar in the worst case,
and significantly outperforms when using the best
feature representation / corpus pair.
</bodyText>
<subsectionHeader confidence="0.998364">
4.3 Predicting Near-Synonyms
</subsectionHeader>
<bodyText confidence="0.999990375">
We next evaluated the multi-prototype approach on
its ability to determine the most closely related
words for a given target word (using the Wikipedia
corpus with tf-idf features). The top k most simi-
lar words were computed for each prototype of each
target word. Using a forced-choice setup, human
subjects were asked to evaluate the quality of these
near synonyms relative to those produced by a sin-
</bodyText>
<subsectionHeader confidence="0.724076">
homonymous
</subsectionHeader>
<bodyText confidence="0.95984">
carrier, crane, cell, company, issue, interest, match,
media, nature, party, practice, plant, racket, recess,
reservation, rock, space, value
</bodyText>
<subsectionHeader confidence="0.43558">
polysemous
</subsectionHeader>
<bodyText confidence="0.6262795">
cause, chance, journal, market, network, policy,
power, production, series, trading, train
</bodyText>
<tableCaption confidence="0.990813">
Table 2: Words used in predicting near synonyms.
</tableCaption>
<bodyText confidence="0.999833181818182">
gle prototype. Participants on Amazon’s Mechani-
cal Turk5 (Snow et al., 2008) were asked to choose
between two possible alternatives (one from a proto-
type model and one from a multi-prototype model)
as being most similar to a given target word. The
target words were presented either in isolation or in
a sentential context randomly selected from the cor-
pus. Table 2 lists the ambiguous words used for this
task. They are grouped into homonyms (words with
very distinct senses) and polysemes (words with re-
lated senses). All words were chosen such that their
usages occur within the same part of speech.
In the non-contextual task, 79 unique raters com-
pleted 7,620 comparisons of which 72 were dis-
carded due to poor performance on a known test set.6
In the contextual task, 127 raters completed 9,930
comparisons of which 87 were discarded.
For the non-contextual case, Figure 3 left plots
the fraction of raters preferring the multi-prototype
prediction (using AvgSim) over that of a single pro-
totype as the number of clusters is varied. When
asked to choose between the single best word for
</bodyText>
<footnote confidence="0.7367045">
5http://mturk.com
6(Rater reliability) The reliability of Mechanical Turk
raters is quite variable, so we computed an accuracy score for
each rater by including a control question with a known cor-
rect answer in each HIT. Control questions were generated by
selecting a random word from WordNet 3.0 and including as
possible choices a word in the same synset (correct answer) and
a word in a synset with a high path distance (incorrect answer).
Raters who got less than 50% of these control questions correct,
or spent too little time on the HIT were discarded.
</footnote>
<page confidence="0.997309">
113
</page>
<figure confidence="0.420199">
Non-contextual Near-Synonym Prediction Contextual Near-Synonym Prediction
</figure>
<figureCaption confidence="0.910799">
Figure 3: (left) Near-synonym evaluation for isolated words showing fraction of raters preferring multi-
prototype results vs. number of clusters. Colored squares indicate performance when combining across
clusterings. 95% confidence intervals computed using the Wald test. (right) Near-synonym evaluation for
words in a sentential context chosen either from the minority sense or the majority sense.
</figureCaption>
<bodyText confidence="0.958982090909091">
each method (top word), the multi-prototype pre-
diction is chosen significantly more frequently (i.e.
the result is above 0.5) when the number of clus-
ters is small, but the two methods perform sim-
ilarly for larger numbers of clusters (Wald test,
α = 0.05.) Clustering more accurately identi-
fies homonyms’ clearly distinct senses and produces
prototypes that better capture the different uses of
these words. As a result, compared to using a sin-
gle prototype, our approach produces better near-
synonyms for homonyms compared to polysemes.
However, given the right number of clusters, it also
produces better results for polysemous words.
The near-synonym prediction task highlights one
of the weaknesses of the multi-prototype approach:
as the number of clusters increases, the number of
occurrences assigned to each cluster decreases, in-
creasing noise and resulting in some poor prototypes
that mainly cover outliers. The word similarity task
is somewhat robust to this phenomenon, but syn-
onym prediction is more affected since only the top
predicted choice is used. When raters are forced
to chose between the top three predictions for each
method (presented as top set in Figure 3 left), the ef-
fect of this noise is reduced and the multi-prototype
approach remains dominant even for a large num-
ber of clusters. This indicates that although more
clusters can capture finer-grained sense distinctions,
they also can introduce noise.
When presented with words in context (Figure
3 right),7 raters found no significant difference in
the two methods for words used in their majority
sense.8 However, when a minority sense is pre-
</bodyText>
<footnote confidence="0.9993268">
7Results for the multi-prototype method are generated using
AvgSimC (soft assignment) as this was found to significantly
outperform MaxSimC.
8Sense frequency determined using Google; senses labeled
manually by trained human evaluators.
</footnote>
<page confidence="0.997464">
114
</page>
<bodyText confidence="0.999799875">
sented (e.g. the “prison” sense of cell), raters pre-
fer the choice predicted by the multi-prototype ap-
proach. This result is to be expected since the sin-
gle prototype mainly reflects the majority sense, pre-
venting it from predicting appropriate synonyms for
a minority sense. Also, once again, the perfor-
mance of the multi-prototype approach is better for
homonyms than polysemes.
</bodyText>
<subsectionHeader confidence="0.999802">
4.4 Predicting Variation in Human Ratings
</subsectionHeader>
<bodyText confidence="0.999652594594594">
Variance in pairwise prototype distances can help
explain the variance in human similarity judgements
for a given word pair. We evaluate this hypothe-
sis empirically on WordSim-353 by computing the
Spearman correlation between the variance of the
per-cluster similarity computations, V[D], D def =
{d(7rk(w), 7rj(w&apos;)) : 1 &lt; k, j &lt; K}, and the vari-
ance of the human annotations for that pair. Cor-
relations for each dataset are shown in Figure 4 left.
In general, we find a statistically significant negative
correlation between these values using x2 features,
indicating that as the entropy of the pairwise cluster
similarities increases (i.e., prototypes become more
similar, and similarities become uniform), rater dis-
agreement increases. This result is intuitive: if the
occurrences of a particular word cannot be easily
separated into coherent clusters (perhaps indicating
high polysemy instead of homonymy), then human
judgement will be naturally more difficult.
Rater variance depends more directly on the ac-
tual word similarity: word pairs at the extreme
ranges of similarity have significantly lower vari-
ance as raters are more certain. By removing word
pairs with similarity judgements in the middle two
quartile ranges (4.4 to 7.5) we find significantly
higher variance correlation (Figure 4 right). This
result indicates that multi-prototype similarity vari-
ance accounts for a secondary effect separate from
the primary effect that variance is naturally lower for
ratings in extreme ranges.
Although the entropy of the prototypes correlates
with the variance of the human ratings, we find that
the individual senses captured by each prototype do
not correspond to human intuition for a given word,
e.g. the “hurricane” sense of position in Figure 1.
This notion is evaluated empirically by computing
the correlation between the predicted similarity us-
</bodyText>
<figureCaption confidence="0.535539">
Figure 4: Plots of variance correlation; lower num-
bers indicate higher negative correlation, i.e. that
prototype entropy predicts rater disagreement.
</figureCaption>
<bodyText confidence="0.999950888888889">
ing the contextual multi-prototype method and hu-
man similarity judgements for different usages of
the same word. The Usage Similarity (USim) data
set collected in Erk et al. (2009) provides such simi-
larity scores from human raters. However, we find
no evidence for correlation between USim scores
and their corresponding prototype similarity scores
(p = 0.04), indicating that prototype vectors may
not correspond well to human senses.
</bodyText>
<sectionHeader confidence="0.988016" genericHeader="evaluation">
5 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.999928947368421">
Table 3 compares the inferred synonyms for several
target words, generally demonstrating the ability of
the multi-prototype model to improve the precision
of inferred near-synonyms (e.g. in the case of singer
or need) as well as its ability to include synonyms
from less frequent senses (e.g., the experiment sense
of research or the verify sense of prove). However,
there are a number of ways it could be improved:
Feature representations: Multiple prototypes im-
prove Spearman correlation on WordSim-353 com-
pared to previous methods using the same under-
lying representation (Agirre et al., 2009). How-
ever we have not yet evaluated its performance
when using more powerful feature representations
such those based on Latent or Explicit Semantic
Analysis (Deerwester et al., 1990; Gabrilovich and
Markovitch, 2007). Due to its modularity, the multi-
prototype approach can easily incorporate such ad-
vances in order to further improve its effectiveness.
</bodyText>
<page confidence="0.996565">
115
</page>
<table confidence="0.430175904761905">
Inferred Thesaurus
bass
single guitar, drums, rhythm, piano, acoustic
multi basses, contrabass, rhythm, guitar, drums
claim
single argue, say, believe, assert, contend
multi assert, contend, allege, argue, insist
hold
single carry, take, receive, reach, maintain
multi carry, maintain, receive, accept, reach
maintain
single ensure, establish, achieve, improve, promote
multi preserve, ensure, establish, retain, restore
prove
single demonstrate, reveal, ensure, confirm, say
multi demonstrate, verify, confirm, reveal, admit
research
single studies, work, study, training, development
multi studies, experiments, study, investigations,
training
singer
</table>
<tableCaption confidence="0.77855575">
single musician, actress, actor, guitarist, composer
multi vocalist, guitarist, musician, singer-
songwriter, singers
Table 3: Examples of the top 5 inferred near-
</tableCaption>
<bodyText confidence="0.998477636363636">
synonyms using the single- and multi-prototype ap-
proaches (with results merged). In general such
clustering improves the precision and coverage of
the inferred near-synonyms.
Nonparametric clustering: The success of the
combined approach indicates that the optimal num-
ber of clusters may vary per word. A more prin-
cipled approach to selecting the number of proto-
types per word is to employ a clustering model with
infinite capacity, e.g. the Dirichlet Process Mixture
Model (Rasmussen, 2000). Such a model would al-
low naturally more polysemous words to adopt more
flexible representations.
Cluster similarity metrics: Besides AvgSim and
MaxSim, there are many similarity metrics over
mixture models, e.g. KL-divergence, which may
correlate better with human similarity judgements.
Comparing to traditional senses: Compared to
WordNet, our best-performing clusterings are sig-
nificantly more fine-grained. Furthermore, they of-
ten do not correspond to agreed upon semantic dis-
tinctions (e.g., the “hurricane” sense of position in
Fig. 1). We posit that the finer-grained senses actu-
ally capture useful aspects of word meaning, leading
to better correlation with WordSim-353. However, it
would be good to compare prototypes learned from
supervised sense inventories to prototypes produced
by automatic clustering.
Joint model: The current method independently
clusters the contexts of each word, so the senses dis-
covered for w cannot influence the senses discovered
for w&apos; 7� w. Sharing statistical strength across simi-
lar words could yield better results for rarer words.
</bodyText>
<sectionHeader confidence="0.999462" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999949444444444">
We presented a resource-light model for vector-
space word meaning that represents words as col-
lections of prototype vectors, naturally accounting
for lexical ambiguity. The multi-prototype approach
uses word sense discovery to partition a word’s con-
texts and construct “sense specific” prototypes for
each cluster. Doing so significantly increases the ac-
curacy of lexical-similarity computation as demon-
strated by improved correlation with human similar-
ity judgements and generation of better near syn-
onyms according to human evaluators. Further-
more, we show that, although performance is sen-
sitive to the number of prototypes, combining pro-
totypes across a large range of clusterings performs
nearly as well as the ex-post best clustering. Finally,
variance in the prototype similarities is found to cor-
relate with inter-annotator disagreement, suggesting
psychological plausibility.
</bodyText>
<sectionHeader confidence="0.994948" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999058666666667">
We would like to thank Katrin Erk for helpful dis-
cussions and making the USim data set available.
This work was supported by an NSF Graduate Re-
search Fellowship and a Google Research Award.
Experiments were run on the Mastodon Cluster, pro-
vided by NSF Grant EIA-0303609.
</bodyText>
<sectionHeader confidence="0.998786" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992315555555556">
Eneko Agirre and Phillip Edmond. 2006. Word Sense
Disambiguation: Algorithms and Applications (Text,
Speech and Language Technology). Springer-Verlag
New York, Inc., Secaucus, NJ, USA.
Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana
Kravalova, Marius Pas¸ca, and Aitor Soroa. 2009. A
study on similarity and relatedness using distributional
and WordNet-based approaches. In Proc. of NAACL-
HLT-09, pages 19–27.
</reference>
<page confidence="0.995647">
116
</page>
<reference confidence="0.997110509433963">
F. Gregory Ashby and Leola A. Alfonso-Reese. 1995.
Categorization as probability density estimation. J.
Math. Psychol., 39(2):216–233.
L. Douglas Baker and Andrew K. McCallum. 1998. Dis-
tributional clustering of words for text classification.
In Proceedings of 21st International ACM SIGIR Con-
ference on Research and Development in Information
Retrieval, pages 96–103.
Arindam Banerjee, Inderjit Dhillon, Joydeep Ghosh, and
Suvrit Sra. 2005. Clustering on the unit hypersphere
using von Mises-Fisher distributions. Journal of Ma-
chine Learning Research, 6:1345–1382.
Alexander Budanitsky and Graeme Hirst. 2006. Evalu-
ating wordnet-based measures of lexical semantic re-
latedness. Computational Linguistics, 32(1):13–47.
James R. Curran and Marc Moens. 2002. Improvements
in automatic thesaurus extraction. In Proceedings of
the ACL-02 workshop on Unsupervised lexical acqui-
sition, pages 59–66.
James R. Curran. 2004. From Distributional to Seman-
tic Similarity. Ph.D. thesis, University of Edinburgh.
College of Science.
Scott C. Deerwester, Susan T. Dumais, George W. Fur-
nas, Thomas K. Landauer, and Richard A. Harshman.
1990. Indexing by latent semantic analysis. Jour-
nal of the American Society for Information Science,
41:391–407.
Inderjit S. Dhillon and Dharmendra S. Modha. 2001.
Concept decompositions for large sparse text data us-
ing clustering. Machine Learning, 42:143–175.
Katrin Erk, Diana McCarthy, Nicholas Gaylord Investi-
gations on Word Senses, and Word Usages. 2009. In-
vestigations on word senses and word usages. In Proc.
of ACL-09.
Katrin Erk. 2007. A simple, similarity-based model for
selectional preferences. In Proceedings of the 45th
Annual Meeting of the Association for Computational
Linguistics. Association for Computer Linguistics.
Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,
Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan
Ruppin. 2001. Placing search in context: the concept
revisited. In Proc. of WWW-01, pages 406–414, New
York, NY, USA. ACM.
Evgeniy Gabrilovich and Shaul Markovitch. 2007. Com-
puting semantic relatedness using Wikipedia-based ex-
plicit semantic analysis. In Proc. of IJCAI-07, pages
1606–1611.
David Graff. 2003. English Gigaword. Linguistic Data
Consortium, Philadephia.
Tom L. Griffiths, Kevin. R. Canini, Adam N. Sanborn,
and Daniel. J. Navarro. 2007. Unifying rational mod-
els of categorization via the hierarchical Dirichlet pro-
cess. In Proc. of CogSci-07.
Zellig Harris. 1954. Distributional structure. Word,
10(23):146–162.
Lillian Lee. 1999. Measures of distributional similarity.
In 37th Annual Meeting of the Association for Compu-
tational Linguistics, pages 25–32.
Dekang Lin and Patrick Pantel. 2002. Concept discovery
from text. In Proc. of COLING-02, pages 1–7.
Dekang Lin, Shaojun Zhao, Lijuan Qin, and Ming Zhou.
2003. Identifying synonyms among distributionally
similar words. In Proceedings of the Interational Joint
Conference on Artificial Intelligence, pages 1492–
1493. Morgan Kaufmann.
Bradley C. Love, Douglas L. Medin, and Todd M.
Gureckis. 2004. SUSTAIN: A network model of cat-
egory learning. Psych. Review, 111(2):309–332.
Will Lowe. 2001. Towards a theory of semantic space.
In Proceedings of the 23rd Annual Meeting of the Cog-
nitive Science Society, pages 576–581.
Patrick Pantel and Dekang Lin. 2002. Discovering word
senses from text. In Proc. of SIGKDD-02, pages 613–
619, New York, NY, USA. ACM.
Fernando C. N. Pereira, Naftali Tishby, and Lillian Lee.
1993. Distributional clustering of English words. In
Proceedings of the 31st Annual Meeting of the Associ-
ation for Computational Linguistics (ACL-93), pages
183–190, Columbus, Ohio.
Daniel Ramage, Anna N. Rafferty, and Christopher D.
Manning. 2009. Random walks for text seman-
tic similarity. In Proc. of the 2009 Workshop on
Graph-based Methods for Natural Language Process-
ing (TextGraphs-4), pages 23–31.
Carl E. Rasmussen. 2000. The infinite Gaussian mixture
model. In Advances in Neural Information Processing
Systems, pages 554–560. MIT Press.
Yves Rosseel. 2002. Mixture models of categorization.
J. Math. Psychol., 46(2):178–210.
Mark Sanderson. 1994. Word sense disambiguation and
information retrieval. In Proc. of SIGIR-94, pages
142–151.
Hinrich Sch¨utze. 1998. Automatic word sense discrimi-
nation. Computational Linguistics, 24(1):97–123.
Rion Snow, Brendan O’Connor, Daniel Jurafsky, and An-
drew Ng. 2008. Cheap and fast—but is it good? Eval-
uating non-expert annotations for natural language
tasks. In Proc. of EMNLP-08.
Amos Tversky and Itamar Gati. 1982. Similarity, sepa-
rability, and the triangle inequality. Psychological Re-
view, 89(2):123–154.
Bram Vandekerckhove, Dominiek Sandra, and Walter
Daelemans. 2009. A robust and extensible exemplar-
based model of thematic fit. In Proc. of EACL 2009,
pages 826–834. Association for Computational Lin-
guistics.
</reference>
<page confidence="0.998138">
117
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.378484">
<title confidence="0.999901">Multi-Prototype Vector-Space Models of Word Meaning</title>
<author confidence="0.99468">Joseph</author>
<affiliation confidence="0.998953">Department of Computer The University of Texas at 1 University Station</affiliation>
<address confidence="0.570627">Austin, TX</address>
<email confidence="0.998847">joeraii@cs.utexas.edu</email>
<author confidence="0.99987">J Raymond</author>
<affiliation confidence="0.923226">Department of Computer The University of Texas at 1 University Station Austin, TX</affiliation>
<email confidence="0.999248">mooney@cs.utexas.edu</email>
<abstract confidence="0.997802117647059">Current vector-space models of lexical semantics create a single “prototype” vector to represent the meaning of a word. However, due to lexical ambiguity, encoding word meaning with a single vector is problematic. This paper presents a method that uses clustering to produce multiple “sense-specific” vectors for each word. This approach provides a context-dependent vector representation of word meaning that naturally accommodates homonymy and polysemy. Experimental comparisons to human judgements of semantic similarity for both isolated words as well as words in sentential contexts demonstrate the superiority of this approach over both prototype and exemplar based vector-space models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Phillip Edmond</author>
</authors>
<title>Word Sense Disambiguation: Algorithms and Applications (Text, Speech and Language Technology).</title>
<date>2006</date>
<publisher>Springer-Verlag</publisher>
<location>New York, Inc., Secaucus, NJ, USA.</location>
<contexts>
<context position="7758" citStr="Agirre and Edmond, 2006" startWordPosition="1205" endWordPosition="1208">Griffiths et al., 2007; Love et al., 2004; Rosseel, 2002). By employing multiple prototypes per word, vector space models can account for homonymy, polysemy and thematic variation in word usage. Furthermore, such approaches require only O(K2) comparisons for computing similarity, yielding potential computational savings over the exemplar approach when K « N, while reaping many of the same benefits. Previous work on lexical semantic relatedness has focused on two approaches: (1) mining monolingual or bilingual dictionaries or other pre-existing resources to construct networks of related words (Agirre and Edmond, 2006; Ramage et al., 2009), and (2) using the distributional hypothesis to automatically infer a vector-space prototype of word meaning from large corpora (Agirre et al., 2009; Curran, 2004; Harris, 1954). The former approach tends to have greater precision, but depends on handsingle prototype (similarity) (cluster#4) lineman, tackle, role, scorer (cluster#1) location importance bombing (cluster#2) post appointme nt, role, job (cluster#3) intensity, winds, hour, gust 110 crafted dictionaries and cannot, in general, model sense frequency (Budanitsky and Hirst, 2006). The latter approach is fundamen</context>
</contexts>
<marker>Agirre, Edmond, 2006</marker>
<rawString>Eneko Agirre and Phillip Edmond. 2006. Word Sense Disambiguation: Algorithms and Applications (Text, Speech and Language Technology). Springer-Verlag New York, Inc., Secaucus, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Enrique Alfonseca</author>
<author>Keith Hall</author>
<author>Jana Kravalova</author>
<author>Marius Pas¸ca</author>
<author>Aitor Soroa</author>
</authors>
<title>A study on similarity and relatedness using distributional and WordNet-based approaches.</title>
<date>2009</date>
<booktitle>In Proc. of NAACLHLT-09,</booktitle>
<pages>pages</pages>
<marker>Agirre, Alfonseca, Hall, Kravalova, Pas¸ca, Soroa, 2009</marker>
<rawString>Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana Kravalova, Marius Pas¸ca, and Aitor Soroa. 2009. A study on similarity and relatedness using distributional and WordNet-based approaches. In Proc. of NAACLHLT-09, pages 19–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Gregory Ashby</author>
<author>Leola A Alfonso-Reese</author>
</authors>
<title>Categorization as probability density estimation.</title>
<date>1995</date>
<journal>J. Math. Psychol.,</journal>
<volume>39</volume>
<issue>2</issue>
<contexts>
<context position="5428" citStr="Ashby and Alfonso-Reese, 1995" startWordPosition="841" endWordPosition="844">background on prototype and exemplar methods for lexical semantics, Section 3 presents our multi-prototype method, Section 4 presents our experimental evaluations, Section 5 discusses future work, and Section 6 concludes. 2 Background Psychological concept models can be roughly divided into two classes: 1. Prototype models represented concepts by an abstract prototypical instance, similar to a cluster centroid in parametric density estimation. 2. Exemplar models represent concepts by a concrete set of observed instances, similar to nonparametric approaches to density estimation in statistics (Ashby and Alfonso-Reese, 1995). Tversky and Gati (1982) famously showed that conceptual similarity violates the triangle inequality, lending evidence for exemplar-based models in psychology. Exemplar models have been previously used for lexical semantics problems such as selectional preference (Erk, 2007) and thematic fit (Vandekerckhove et al., 2009). Individual exemplars can be quite noisy and the model can incur high computational overhead at prediction time since naively computing the similarity between two words using each occurrence in a textual corpus as an exemplar requires O(n2) comparisons. Instead, the standard </context>
</contexts>
<marker>Ashby, Alfonso-Reese, 1995</marker>
<rawString>F. Gregory Ashby and Leola A. Alfonso-Reese. 1995. Categorization as probability density estimation. J. Math. Psychol., 39(2):216–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Douglas Baker</author>
<author>Andrew K McCallum</author>
</authors>
<title>Distributional clustering of words for text classification.</title>
<date>1998</date>
<booktitle>In Proceedings of 21st International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>96--103</pages>
<contexts>
<context position="1222" citStr="Baker and McCallum, 1998" startWordPosition="172" endWordPosition="175">nts a method that uses clustering to produce multiple “sense-specific” vectors for each word. This approach provides a context-dependent vector representation of word meaning that naturally accommodates homonymy and polysemy. Experimental comparisons to human judgements of semantic similarity for both isolated words as well as words in sentential contexts demonstrate the superiority of this approach over both prototype and exemplar based vector-space models. 1 Introduction Automatically judging the degree of semantic similarity between words is an important task useful in text classification (Baker and McCallum, 1998), information retrieval (Sanderson, 1994), textual entailment, and other language processing tasks. The standard empirical approach to this task exploits the distributional hypothesis, i.e. that similar words appear in similar contexts (Curran and Moens, 2002; Lin and Pantel, 2002; Pereira et al., 1993). Traditionally, word types are represented by a single vector of contextual features derived from cooccurrence information, and semantic similarity is computed using some measure of vector distance (Lee, 1999; Lowe, 2001). However, due to homonymy and polysemy, capturing the semantics of a word</context>
</contexts>
<marker>Baker, McCallum, 1998</marker>
<rawString>L. Douglas Baker and Andrew K. McCallum. 1998. Distributional clustering of words for text classification. In Proceedings of 21st International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 96–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arindam Banerjee</author>
<author>Inderjit Dhillon</author>
<author>Joydeep Ghosh</author>
<author>Suvrit Sra</author>
</authors>
<title>Clustering on the unit hypersphere using von Mises-Fisher distributions.</title>
<date>2005</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>6--1345</pages>
<contexts>
<context position="10146" citStr="Banerjee et al., 2005" startWordPosition="1562" endWordPosition="1565">1 Clustering Occurrences Multiple prototypes for each word w are generated by clustering feature vectors v(c) derived from each occurrence c E C(w) in a large textual corpus and collecting the resulting cluster centroids 7rk(w), k E [1, K]. This approach is commonly employed in unsupervised word sense discovery; however, we do not assume that clusters correspond to traditional word senses. Rather, we only rely on clusters to capture meaningful variation in word usage. Our experiments employ a mixture of von MisesFisher distributions (movMF) clustering method with first-order unigram contexts (Banerjee et al., 2005). Feature vectors v(c) are composed of individual features I(c, f), taken as all unigrams occurring f E F in a 10-word window around w. Like spherical k-means (Dhillon and Modha, 2001), movMF models semantic relatedness using cosine similarity, a standard measure of textual similarity. However, movMF introduces an additional per-cluster concentration parameter controlling its semantic breadth, allowing it to more accurately model non-uniformities in the distribution of cluster sizes. Based on preliminary experiments comparing various clustering methods, we found movMF gave the best results. 3.</context>
</contexts>
<marker>Banerjee, Dhillon, Ghosh, Sra, 2005</marker>
<rawString>Arindam Banerjee, Inderjit Dhillon, Joydeep Ghosh, and Suvrit Sra. 2005. Clustering on the unit hypersphere using von Mises-Fisher distributions. Journal of Machine Learning Research, 6:1345–1382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating wordnet-based measures of lexical semantic relatedness.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<contexts>
<context position="8325" citStr="Budanitsky and Hirst, 2006" startWordPosition="1285" endWordPosition="1288">construct networks of related words (Agirre and Edmond, 2006; Ramage et al., 2009), and (2) using the distributional hypothesis to automatically infer a vector-space prototype of word meaning from large corpora (Agirre et al., 2009; Curran, 2004; Harris, 1954). The former approach tends to have greater precision, but depends on handsingle prototype (similarity) (cluster#4) lineman, tackle, role, scorer (cluster#1) location importance bombing (cluster#2) post appointme nt, role, job (cluster#3) intensity, winds, hour, gust 110 crafted dictionaries and cannot, in general, model sense frequency (Budanitsky and Hirst, 2006). The latter approach is fundamentally more scalable as it does not rely on specific resources and can model corpus-specific sense distributions. However, the distributional approach can suffer from poor precision, as thematically similar words (e.g., singer and actor) and antonyms often occur in similar contexts (Lin et al., 2003). Unsupervised word-sense discovery has been studied by number of researchers (Agirre and Edmond, 2006; Sch¨utze, 1998). Most work has also focused on corpus-based distributional approaches, varying the vector-space representation, e.g. by incorporating syntactic and</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating wordnet-based measures of lexical semantic relatedness. Computational Linguistics, 32(1):13–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
<author>Marc Moens</author>
</authors>
<title>Improvements in automatic thesaurus extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition,</booktitle>
<pages>59--66</pages>
<contexts>
<context position="1481" citStr="Curran and Moens, 2002" startWordPosition="208" endWordPosition="211">dgements of semantic similarity for both isolated words as well as words in sentential contexts demonstrate the superiority of this approach over both prototype and exemplar based vector-space models. 1 Introduction Automatically judging the degree of semantic similarity between words is an important task useful in text classification (Baker and McCallum, 1998), information retrieval (Sanderson, 1994), textual entailment, and other language processing tasks. The standard empirical approach to this task exploits the distributional hypothesis, i.e. that similar words appear in similar contexts (Curran and Moens, 2002; Lin and Pantel, 2002; Pereira et al., 1993). Traditionally, word types are represented by a single vector of contextual features derived from cooccurrence information, and semantic similarity is computed using some measure of vector distance (Lee, 1999; Lowe, 2001). However, due to homonymy and polysemy, capturing the semantics of a word with a single vector is problematic. For example, the word club is similar to both bat and association, which are not at all similar to each other. Word meaning violates the triangle inequality when viewed at the level of word types, posing a problem for vec</context>
</contexts>
<marker>Curran, Moens, 2002</marker>
<rawString>James R. Curran and Marc Moens. 2002. Improvements in automatic thesaurus extraction. In Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition, pages 59–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
</authors>
<title>From Distributional to Semantic Similarity.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh. College of Science.</institution>
<contexts>
<context position="7943" citStr="Curran, 2004" startWordPosition="1236" endWordPosition="1237">urthermore, such approaches require only O(K2) comparisons for computing similarity, yielding potential computational savings over the exemplar approach when K « N, while reaping many of the same benefits. Previous work on lexical semantic relatedness has focused on two approaches: (1) mining monolingual or bilingual dictionaries or other pre-existing resources to construct networks of related words (Agirre and Edmond, 2006; Ramage et al., 2009), and (2) using the distributional hypothesis to automatically infer a vector-space prototype of word meaning from large corpora (Agirre et al., 2009; Curran, 2004; Harris, 1954). The former approach tends to have greater precision, but depends on handsingle prototype (similarity) (cluster#4) lineman, tackle, role, scorer (cluster#1) location importance bombing (cluster#2) post appointme nt, role, job (cluster#3) intensity, winds, hour, gust 110 crafted dictionaries and cannot, in general, model sense frequency (Budanitsky and Hirst, 2006). The latter approach is fundamentally more scalable as it does not rely on specific resources and can model corpus-specific sense distributions. However, the distributional approach can suffer from poor precision, as </context>
<context position="10994" citStr="Curran (2004)" startWordPosition="1687" endWordPosition="1688">milarity, a standard measure of textual similarity. However, movMF introduces an additional per-cluster concentration parameter controlling its semantic breadth, allowing it to more accurately model non-uniformities in the distribution of cluster sizes. Based on preliminary experiments comparing various clustering methods, we found movMF gave the best results. 3.2 Measuring Semantic Similarity The similarity between two words in a multiprototype model can be computed straightforwardly, requiring only simple modifications to standard distributional similarity methods such as those presented by Curran (2004). Given words w and w0, we define two noncontextual clustered similarity metrics to measure similarity of isolated words: XK AvgSim(w, w&apos;) def � 1 K2 j=1 MaxSim(w, w&apos;) def � max 1&lt;j&lt;K,1&lt;k&lt;K where d(·, ·) is a standard distributional similarity measure. In AvgSim, word similarity is computed as the average similarity of all pairs of prototype vectors; In MaxSim the similarity is the maximum over all pairwise prototype similarities. All results reported in this paper use cosine similarity, 1 Cos (w, w0) _ P f ∈F I (w, f) · I (w0, f) We compare across two different feature functions tf-idf weight</context>
</contexts>
<marker>Curran, 2004</marker>
<rawString>James R. Curran. 2004. From Distributional to Semantic Similarity. Ph.D. thesis, University of Edinburgh. College of Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott C Deerwester</author>
<author>Susan T Dumais</author>
<author>George W Furnas</author>
<author>Thomas K Landauer</author>
<author>Richard A Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<pages>41--391</pages>
<contexts>
<context position="26176" citStr="Deerwester et al., 1990" startWordPosition="4057" endWordPosition="4060">of inferred near-synonyms (e.g. in the case of singer or need) as well as its ability to include synonyms from less frequent senses (e.g., the experiment sense of research or the verify sense of prove). However, there are a number of ways it could be improved: Feature representations: Multiple prototypes improve Spearman correlation on WordSim-353 compared to previous methods using the same underlying representation (Agirre et al., 2009). However we have not yet evaluated its performance when using more powerful feature representations such those based on Latent or Explicit Semantic Analysis (Deerwester et al., 1990; Gabrilovich and Markovitch, 2007). Due to its modularity, the multiprototype approach can easily incorporate such advances in order to further improve its effectiveness. 115 Inferred Thesaurus bass single guitar, drums, rhythm, piano, acoustic multi basses, contrabass, rhythm, guitar, drums claim single argue, say, believe, assert, contend multi assert, contend, allege, argue, insist hold single carry, take, receive, reach, maintain multi carry, maintain, receive, accept, reach maintain single ensure, establish, achieve, improve, promote multi preserve, ensure, establish, retain, restore pro</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Scott C. Deerwester, Susan T. Dumais, George W. Furnas, Thomas K. Landauer, and Richard A. Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society for Information Science, 41:391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjit S Dhillon</author>
<author>Dharmendra S Modha</author>
</authors>
<title>Concept decompositions for large sparse text data using clustering.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<pages>42--143</pages>
<contexts>
<context position="10330" citStr="Dhillon and Modha, 2001" startWordPosition="1595" endWordPosition="1598">ecting the resulting cluster centroids 7rk(w), k E [1, K]. This approach is commonly employed in unsupervised word sense discovery; however, we do not assume that clusters correspond to traditional word senses. Rather, we only rely on clusters to capture meaningful variation in word usage. Our experiments employ a mixture of von MisesFisher distributions (movMF) clustering method with first-order unigram contexts (Banerjee et al., 2005). Feature vectors v(c) are composed of individual features I(c, f), taken as all unigrams occurring f E F in a 10-word window around w. Like spherical k-means (Dhillon and Modha, 2001), movMF models semantic relatedness using cosine similarity, a standard measure of textual similarity. However, movMF introduces an additional per-cluster concentration parameter controlling its semantic breadth, allowing it to more accurately model non-uniformities in the distribution of cluster sizes. Based on preliminary experiments comparing various clustering methods, we found movMF gave the best results. 3.2 Measuring Semantic Similarity The similarity between two words in a multiprototype model can be computed straightforwardly, requiring only simple modifications to standard distributi</context>
</contexts>
<marker>Dhillon, Modha, 2001</marker>
<rawString>Inderjit S. Dhillon and Dharmendra S. Modha. 2001. Concept decompositions for large sparse text data using clustering. Machine Learning, 42:143–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Diana McCarthy</author>
</authors>
<title>Nicholas Gaylord Investigations on Word Senses, and Word Usages.</title>
<date>2009</date>
<booktitle>In Proc. of ACL-09.</booktitle>
<marker>Erk, McCarthy, 2009</marker>
<rawString>Katrin Erk, Diana McCarthy, Nicholas Gaylord Investigations on Word Senses, and Word Usages. 2009. Investigations on word senses and word usages. In Proc. of ACL-09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
</authors>
<title>A simple, similarity-based model for selectional preferences.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association</booktitle>
<institution>for Computational Linguistics. Association for Computer Linguistics.</institution>
<contexts>
<context position="5704" citStr="Erk, 2007" startWordPosition="882" endWordPosition="883">classes: 1. Prototype models represented concepts by an abstract prototypical instance, similar to a cluster centroid in parametric density estimation. 2. Exemplar models represent concepts by a concrete set of observed instances, similar to nonparametric approaches to density estimation in statistics (Ashby and Alfonso-Reese, 1995). Tversky and Gati (1982) famously showed that conceptual similarity violates the triangle inequality, lending evidence for exemplar-based models in psychology. Exemplar models have been previously used for lexical semantics problems such as selectional preference (Erk, 2007) and thematic fit (Vandekerckhove et al., 2009). Individual exemplars can be quite noisy and the model can incur high computational overhead at prediction time since naively computing the similarity between two words using each occurrence in a textual corpus as an exemplar requires O(n2) comparisons. Instead, the standard ... chose Zbigniew Brzezinski for the position of ... ... thus the symbol s position on his clothing was ... ... writes call options against the stock position ... ... offered a position with ... ... a position he would hold until his retirement in ... ... endanger their posi</context>
</contexts>
<marker>Erk, 2007</marker>
<rawString>Katrin Erk. 2007. A simple, similarity-based model for selectional preferences. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics. Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Finkelstein</author>
<author>Evgeniy Gabrilovich</author>
<author>Yossi Matias</author>
<author>Ehud Rivlin</author>
<author>Zach Solan</author>
<author>Gadi Wolfman</author>
<author>Eytan Ruppin</author>
</authors>
<title>Placing search in context: the concept revisited.</title>
<date>2001</date>
<booktitle>In Proc. of WWW-01,</booktitle>
<pages>406--414</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="14101" citStr="Finkelstein et al., 2001" startWordPosition="2191" endWordPosition="2194"> Gigaword corpus, with articles containing fewer than 100 words removed, leaving 6.6M articles and 3.913 words (Graff, 2003). Wikipedia covers a wider range of sense distributions, whereas Gigaword contains only newswire text and tends to employ fewer senses of most ambiguous words. Our method outperforms baseline methods even on Gigaword, indicating its advantages even when the corpus covers few senses. 4.2 Judging Semantic Similarity To evaluate the quality of various models, we first compared their lexical similarity measurements to human similarity judgements from the WordSim353 data set (Finkelstein et al., 2001). This test corpus contains multiple human judgements on 353 word pairs, covering both monosemous and polysemous words, each rated on a 1–10 integer scale. Spearman’s rank correlation (p) with average human judgements (Agirre et al., 2009) was used to measure the quality of various models. Figure 2 plots Spearman’s p on WordSim-353 against the number of clusters (K) for Wikipedia and Gigaword corpora, using pruned tf-idf and k2 features.2 In general pruned tf-idf features yield higher correlation than k2 features. Using AvgSim, the multi-prototype approach (K &gt; 1) yields higher correlation tha</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2001</marker>
<rawString>Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin. 2001. Placing search in context: the concept revisited. In Proc. of WWW-01, pages 406–414, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Computing semantic relatedness using Wikipedia-based explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In Proc. of IJCAI-07,</booktitle>
<pages>1606--1611</pages>
<contexts>
<context position="26211" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="4061" endWordPosition="4064"> (e.g. in the case of singer or need) as well as its ability to include synonyms from less frequent senses (e.g., the experiment sense of research or the verify sense of prove). However, there are a number of ways it could be improved: Feature representations: Multiple prototypes improve Spearman correlation on WordSim-353 compared to previous methods using the same underlying representation (Agirre et al., 2009). However we have not yet evaluated its performance when using more powerful feature representations such those based on Latent or Explicit Semantic Analysis (Deerwester et al., 1990; Gabrilovich and Markovitch, 2007). Due to its modularity, the multiprototype approach can easily incorporate such advances in order to further improve its effectiveness. 115 Inferred Thesaurus bass single guitar, drums, rhythm, piano, acoustic multi basses, contrabass, rhythm, guitar, drums claim single argue, say, believe, assert, contend multi assert, contend, allege, argue, insist hold single carry, take, receive, reach, maintain multi carry, maintain, receive, accept, reach maintain single ensure, establish, achieve, improve, promote multi preserve, ensure, establish, retain, restore prove single demonstrate, reveal, ensu</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007. Computing semantic relatedness using Wikipedia-based explicit semantic analysis. In Proc. of IJCAI-07, pages 1606–1611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Graff</author>
</authors>
<date>2003</date>
<journal>English Gigaword. Linguistic Data Consortium, Philadephia.</journal>
<contexts>
<context position="13600" citStr="Graff, 2003" startWordPosition="2116" endWordPosition="2117">Sim can be thought of as special cases of AvgSimC and MaxSimC with uniform weight to each cluster; hence AvgSimC and MaxSimC can be used to compare words in context to isolated words as well. 4 Experimental Evaluation 4.1 Corpora We employed two corpora to train our models: 1. A snapshot of English Wikipedia taken on Sept. 29th, 2009. Wikitext markup is removed, as are articles with fewer than 100 words, leaving 2.8M articles with a total of 2.0513 words. 2. The third edition English Gigaword corpus, with articles containing fewer than 100 words removed, leaving 6.6M articles and 3.913 words (Graff, 2003). Wikipedia covers a wider range of sense distributions, whereas Gigaword contains only newswire text and tends to employ fewer senses of most ambiguous words. Our method outperforms baseline methods even on Gigaword, indicating its advantages even when the corpus covers few senses. 4.2 Judging Semantic Similarity To evaluate the quality of various models, we first compared their lexical similarity measurements to human similarity judgements from the WordSim353 data set (Finkelstein et al., 2001). This test corpus contains multiple human judgements on 353 word pairs, covering both monosemous a</context>
</contexts>
<marker>Graff, 2003</marker>
<rawString>David Graff. 2003. English Gigaword. Linguistic Data Consortium, Philadephia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Canini</author>
<author>Adam N Sanborn</author>
<author>Daniel J Navarro</author>
</authors>
<title>Unifying rational models of categorization via the hierarchical Dirichlet process.</title>
<date>2007</date>
<booktitle>In Proc. of CogSci-07.</booktitle>
<marker>Canini, Sanborn, Navarro, 2007</marker>
<rawString>Tom L. Griffiths, Kevin. R. Canini, Adam N. Sanborn, and Daniel. J. Navarro. 2007. Unifying rational models of categorization via the hierarchical Dirichlet process. In Proc. of CogSci-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<date>1954</date>
<journal>Distributional structure. Word,</journal>
<volume>10</volume>
<issue>23</issue>
<contexts>
<context position="7958" citStr="Harris, 1954" startWordPosition="1238" endWordPosition="1239">ch approaches require only O(K2) comparisons for computing similarity, yielding potential computational savings over the exemplar approach when K « N, while reaping many of the same benefits. Previous work on lexical semantic relatedness has focused on two approaches: (1) mining monolingual or bilingual dictionaries or other pre-existing resources to construct networks of related words (Agirre and Edmond, 2006; Ramage et al., 2009), and (2) using the distributional hypothesis to automatically infer a vector-space prototype of word meaning from large corpora (Agirre et al., 2009; Curran, 2004; Harris, 1954). The former approach tends to have greater precision, but depends on handsingle prototype (similarity) (cluster#4) lineman, tackle, role, scorer (cluster#1) location importance bombing (cluster#2) post appointme nt, role, job (cluster#3) intensity, winds, hour, gust 110 crafted dictionaries and cannot, in general, model sense frequency (Budanitsky and Hirst, 2006). The latter approach is fundamentally more scalable as it does not rely on specific resources and can model corpus-specific sense distributions. However, the distributional approach can suffer from poor precision, as thematically si</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Zellig Harris. 1954. Distributional structure. Word, 10(23):146–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lillian Lee</author>
</authors>
<title>Measures of distributional similarity.</title>
<date>1999</date>
<booktitle>In 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="1735" citStr="Lee, 1999" startWordPosition="250" endWordPosition="251">rity between words is an important task useful in text classification (Baker and McCallum, 1998), information retrieval (Sanderson, 1994), textual entailment, and other language processing tasks. The standard empirical approach to this task exploits the distributional hypothesis, i.e. that similar words appear in similar contexts (Curran and Moens, 2002; Lin and Pantel, 2002; Pereira et al., 1993). Traditionally, word types are represented by a single vector of contextual features derived from cooccurrence information, and semantic similarity is computed using some measure of vector distance (Lee, 1999; Lowe, 2001). However, due to homonymy and polysemy, capturing the semantics of a word with a single vector is problematic. For example, the word club is similar to both bat and association, which are not at all similar to each other. Word meaning violates the triangle inequality when viewed at the level of word types, posing a problem for vector-space models (Tversky and Gati, 1982). A single “prototype” vector is simply incapable of capturing phenomena such as homonymy and polysemy. Also, most vector-space models are context independent, while the meaning of a word clearly depends on contex</context>
</contexts>
<marker>Lee, 1999</marker>
<rawString>Lillian Lee. 1999. Measures of distributional similarity. In 37th Annual Meeting of the Association for Computational Linguistics, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Concept discovery from text.</title>
<date>2002</date>
<booktitle>In Proc. of COLING-02,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="1503" citStr="Lin and Pantel, 2002" startWordPosition="212" endWordPosition="215">ilarity for both isolated words as well as words in sentential contexts demonstrate the superiority of this approach over both prototype and exemplar based vector-space models. 1 Introduction Automatically judging the degree of semantic similarity between words is an important task useful in text classification (Baker and McCallum, 1998), information retrieval (Sanderson, 1994), textual entailment, and other language processing tasks. The standard empirical approach to this task exploits the distributional hypothesis, i.e. that similar words appear in similar contexts (Curran and Moens, 2002; Lin and Pantel, 2002; Pereira et al., 1993). Traditionally, word types are represented by a single vector of contextual features derived from cooccurrence information, and semantic similarity is computed using some measure of vector distance (Lee, 1999; Lowe, 2001). However, due to homonymy and polysemy, capturing the semantics of a word with a single vector is problematic. For example, the word club is similar to both bat and association, which are not at all similar to each other. Word meaning violates the triangle inequality when viewed at the level of word types, posing a problem for vector-space models (Tver</context>
</contexts>
<marker>Lin, Pantel, 2002</marker>
<rawString>Dekang Lin and Patrick Pantel. 2002. Concept discovery from text. In Proc. of COLING-02, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Shaojun Zhao</author>
<author>Lijuan Qin</author>
<author>Ming Zhou</author>
</authors>
<title>Identifying synonyms among distributionally similar words.</title>
<date>2003</date>
<booktitle>In Proceedings of the Interational Joint Conference on Artificial Intelligence,</booktitle>
<pages>1492--1493</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="8658" citStr="Lin et al., 2003" startWordPosition="1335" endWordPosition="1338">ototype (similarity) (cluster#4) lineman, tackle, role, scorer (cluster#1) location importance bombing (cluster#2) post appointme nt, role, job (cluster#3) intensity, winds, hour, gust 110 crafted dictionaries and cannot, in general, model sense frequency (Budanitsky and Hirst, 2006). The latter approach is fundamentally more scalable as it does not rely on specific resources and can model corpus-specific sense distributions. However, the distributional approach can suffer from poor precision, as thematically similar words (e.g., singer and actor) and antonyms often occur in similar contexts (Lin et al., 2003). Unsupervised word-sense discovery has been studied by number of researchers (Agirre and Edmond, 2006; Sch¨utze, 1998). Most work has also focused on corpus-based distributional approaches, varying the vector-space representation, e.g. by incorporating syntactic and co-occurrence information from the words surrounding the target term (Pereira et al., 1993; Pantel and Lin, 2002). 3 Multi-Prototype Vector-Space Models Our approach is similar to standard vector-space models of word meaning, with the addition of a perword-type clustering step: Occurrences for a specific word type are collected fr</context>
</contexts>
<marker>Lin, Zhao, Qin, Zhou, 2003</marker>
<rawString>Dekang Lin, Shaojun Zhao, Lijuan Qin, and Ming Zhou. 2003. Identifying synonyms among distributionally similar words. In Proceedings of the Interational Joint Conference on Artificial Intelligence, pages 1492– 1493. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bradley C Love</author>
<author>Douglas L Medin</author>
<author>Todd M Gureckis</author>
</authors>
<title>SUSTAIN: A network model of category learning.</title>
<date>2004</date>
<journal>Psych. Review,</journal>
<volume>111</volume>
<issue>2</issue>
<contexts>
<context position="7176" citStr="Love et al., 2004" startWordPosition="1120" endWordPosition="1123">nt of context. Occurrences are clustered and cluster centroids are used as prototype vectors. Note the “hurricane” sense of position (cluster 3) is not typically considered appropriate in WSD. approach is to compute a single prototype vector for each word from its occurrences. This paper presents a multi-prototype vector space model for lexical semantics with a single parameter K (the number of clusters) that generalizes both prototype (K = 1) and exemplar (K = N, the total number of instances) methods. Such models have been widely studied in the Psychology literature (Griffiths et al., 2007; Love et al., 2004; Rosseel, 2002). By employing multiple prototypes per word, vector space models can account for homonymy, polysemy and thematic variation in word usage. Furthermore, such approaches require only O(K2) comparisons for computing similarity, yielding potential computational savings over the exemplar approach when K « N, while reaping many of the same benefits. Previous work on lexical semantic relatedness has focused on two approaches: (1) mining monolingual or bilingual dictionaries or other pre-existing resources to construct networks of related words (Agirre and Edmond, 2006; Ramage et al., 2</context>
</contexts>
<marker>Love, Medin, Gureckis, 2004</marker>
<rawString>Bradley C. Love, Douglas L. Medin, and Todd M. Gureckis. 2004. SUSTAIN: A network model of category learning. Psych. Review, 111(2):309–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Will Lowe</author>
</authors>
<title>Towards a theory of semantic space.</title>
<date>2001</date>
<booktitle>In Proceedings of the 23rd Annual Meeting of the Cognitive Science Society,</booktitle>
<pages>576--581</pages>
<contexts>
<context position="1748" citStr="Lowe, 2001" startWordPosition="252" endWordPosition="253">n words is an important task useful in text classification (Baker and McCallum, 1998), information retrieval (Sanderson, 1994), textual entailment, and other language processing tasks. The standard empirical approach to this task exploits the distributional hypothesis, i.e. that similar words appear in similar contexts (Curran and Moens, 2002; Lin and Pantel, 2002; Pereira et al., 1993). Traditionally, word types are represented by a single vector of contextual features derived from cooccurrence information, and semantic similarity is computed using some measure of vector distance (Lee, 1999; Lowe, 2001). However, due to homonymy and polysemy, capturing the semantics of a word with a single vector is problematic. For example, the word club is similar to both bat and association, which are not at all similar to each other. Word meaning violates the triangle inequality when viewed at the level of word types, posing a problem for vector-space models (Tversky and Gati, 1982). A single “prototype” vector is simply incapable of capturing phenomena such as homonymy and polysemy. Also, most vector-space models are context independent, while the meaning of a word clearly depends on context. The word c</context>
</contexts>
<marker>Lowe, 2001</marker>
<rawString>Will Lowe. 2001. Towards a theory of semantic space. In Proceedings of the 23rd Annual Meeting of the Cognitive Science Society, pages 576–581.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>Discovering word senses from text.</title>
<date>2002</date>
<booktitle>In Proc. of SIGKDD-02,</booktitle>
<pages>613--619</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="9039" citStr="Pantel and Lin, 2002" startWordPosition="1388" endWordPosition="1391">s and can model corpus-specific sense distributions. However, the distributional approach can suffer from poor precision, as thematically similar words (e.g., singer and actor) and antonyms often occur in similar contexts (Lin et al., 2003). Unsupervised word-sense discovery has been studied by number of researchers (Agirre and Edmond, 2006; Sch¨utze, 1998). Most work has also focused on corpus-based distributional approaches, varying the vector-space representation, e.g. by incorporating syntactic and co-occurrence information from the words surrounding the target term (Pereira et al., 1993; Pantel and Lin, 2002). 3 Multi-Prototype Vector-Space Models Our approach is similar to standard vector-space models of word meaning, with the addition of a perword-type clustering step: Occurrences for a specific word type are collected from the corpus and clustered using any appropriate method (§3.1). Similarity between two word types is then computed as a function of their cluster centroids (§3.2), instead of the centroid of all the word’s occurrences. Figure 1 gives an overview of this process. 3.1 Clustering Occurrences Multiple prototypes for each word w are generated by clustering feature vectors v(c) deriv</context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>Patrick Pantel and Dekang Lin. 2002. Discovering word senses from text. In Proc. of SIGKDD-02, pages 613– 619, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (ACL-93),</booktitle>
<pages>183--190</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="1526" citStr="Pereira et al., 1993" startWordPosition="216" endWordPosition="219">ted words as well as words in sentential contexts demonstrate the superiority of this approach over both prototype and exemplar based vector-space models. 1 Introduction Automatically judging the degree of semantic similarity between words is an important task useful in text classification (Baker and McCallum, 1998), information retrieval (Sanderson, 1994), textual entailment, and other language processing tasks. The standard empirical approach to this task exploits the distributional hypothesis, i.e. that similar words appear in similar contexts (Curran and Moens, 2002; Lin and Pantel, 2002; Pereira et al., 1993). Traditionally, word types are represented by a single vector of contextual features derived from cooccurrence information, and semantic similarity is computed using some measure of vector distance (Lee, 1999; Lowe, 2001). However, due to homonymy and polysemy, capturing the semantics of a word with a single vector is problematic. For example, the word club is similar to both bat and association, which are not at all similar to each other. Word meaning violates the triangle inequality when viewed at the level of word types, posing a problem for vector-space models (Tversky and Gati, 1982). A </context>
<context position="9016" citStr="Pereira et al., 1993" startWordPosition="1384" endWordPosition="1387">y on specific resources and can model corpus-specific sense distributions. However, the distributional approach can suffer from poor precision, as thematically similar words (e.g., singer and actor) and antonyms often occur in similar contexts (Lin et al., 2003). Unsupervised word-sense discovery has been studied by number of researchers (Agirre and Edmond, 2006; Sch¨utze, 1998). Most work has also focused on corpus-based distributional approaches, varying the vector-space representation, e.g. by incorporating syntactic and co-occurrence information from the words surrounding the target term (Pereira et al., 1993; Pantel and Lin, 2002). 3 Multi-Prototype Vector-Space Models Our approach is similar to standard vector-space models of word meaning, with the addition of a perword-type clustering step: Occurrences for a specific word type are collected from the corpus and clustered using any appropriate method (§3.1). Similarity between two word types is then computed as a function of their cluster centroids (§3.2), instead of the centroid of all the word’s occurrences. Figure 1 gives an overview of this process. 3.1 Clustering Occurrences Multiple prototypes for each word w are generated by clustering fea</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Fernando C. N. Pereira, Naftali Tishby, and Lillian Lee. 1993. Distributional clustering of English words. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics (ACL-93), pages 183–190, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ramage</author>
<author>Anna N Rafferty</author>
<author>Christopher D Manning</author>
</authors>
<title>Random walks for text semantic similarity.</title>
<date>2009</date>
<booktitle>In Proc. of the 2009 Workshop on Graph-based Methods for Natural Language Processing (TextGraphs-4),</booktitle>
<pages>23--31</pages>
<contexts>
<context position="7780" citStr="Ramage et al., 2009" startWordPosition="1209" endWordPosition="1212">ove et al., 2004; Rosseel, 2002). By employing multiple prototypes per word, vector space models can account for homonymy, polysemy and thematic variation in word usage. Furthermore, such approaches require only O(K2) comparisons for computing similarity, yielding potential computational savings over the exemplar approach when K « N, while reaping many of the same benefits. Previous work on lexical semantic relatedness has focused on two approaches: (1) mining monolingual or bilingual dictionaries or other pre-existing resources to construct networks of related words (Agirre and Edmond, 2006; Ramage et al., 2009), and (2) using the distributional hypothesis to automatically infer a vector-space prototype of word meaning from large corpora (Agirre et al., 2009; Curran, 2004; Harris, 1954). The former approach tends to have greater precision, but depends on handsingle prototype (similarity) (cluster#4) lineman, tackle, role, scorer (cluster#1) location importance bombing (cluster#2) post appointme nt, role, job (cluster#3) intensity, winds, hour, gust 110 crafted dictionaries and cannot, in general, model sense frequency (Budanitsky and Hirst, 2006). The latter approach is fundamentally more scalable as</context>
</contexts>
<marker>Ramage, Rafferty, Manning, 2009</marker>
<rawString>Daniel Ramage, Anna N. Rafferty, and Christopher D. Manning. 2009. Random walks for text semantic similarity. In Proc. of the 2009 Workshop on Graph-based Methods for Natural Language Processing (TextGraphs-4), pages 23–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl E Rasmussen</author>
</authors>
<title>The infinite Gaussian mixture model.</title>
<date>2000</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>554--560</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="27656" citStr="Rasmussen, 2000" startWordPosition="4263" endWordPosition="4264">itarist, composer multi vocalist, guitarist, musician, singersongwriter, singers Table 3: Examples of the top 5 inferred nearsynonyms using the single- and multi-prototype approaches (with results merged). In general such clustering improves the precision and coverage of the inferred near-synonyms. Nonparametric clustering: The success of the combined approach indicates that the optimal number of clusters may vary per word. A more principled approach to selecting the number of prototypes per word is to employ a clustering model with infinite capacity, e.g. the Dirichlet Process Mixture Model (Rasmussen, 2000). Such a model would allow naturally more polysemous words to adopt more flexible representations. Cluster similarity metrics: Besides AvgSim and MaxSim, there are many similarity metrics over mixture models, e.g. KL-divergence, which may correlate better with human similarity judgements. Comparing to traditional senses: Compared to WordNet, our best-performing clusterings are significantly more fine-grained. Furthermore, they often do not correspond to agreed upon semantic distinctions (e.g., the “hurricane” sense of position in Fig. 1). We posit that the finer-grained senses actually capture</context>
</contexts>
<marker>Rasmussen, 2000</marker>
<rawString>Carl E. Rasmussen. 2000. The infinite Gaussian mixture model. In Advances in Neural Information Processing Systems, pages 554–560. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Rosseel</author>
</authors>
<title>Mixture models of categorization.</title>
<date>2002</date>
<journal>J. Math. Psychol.,</journal>
<volume>46</volume>
<issue>2</issue>
<contexts>
<context position="7192" citStr="Rosseel, 2002" startWordPosition="1124" endWordPosition="1125">rrences are clustered and cluster centroids are used as prototype vectors. Note the “hurricane” sense of position (cluster 3) is not typically considered appropriate in WSD. approach is to compute a single prototype vector for each word from its occurrences. This paper presents a multi-prototype vector space model for lexical semantics with a single parameter K (the number of clusters) that generalizes both prototype (K = 1) and exemplar (K = N, the total number of instances) methods. Such models have been widely studied in the Psychology literature (Griffiths et al., 2007; Love et al., 2004; Rosseel, 2002). By employing multiple prototypes per word, vector space models can account for homonymy, polysemy and thematic variation in word usage. Furthermore, such approaches require only O(K2) comparisons for computing similarity, yielding potential computational savings over the exemplar approach when K « N, while reaping many of the same benefits. Previous work on lexical semantic relatedness has focused on two approaches: (1) mining monolingual or bilingual dictionaries or other pre-existing resources to construct networks of related words (Agirre and Edmond, 2006; Ramage et al., 2009), and (2) us</context>
</contexts>
<marker>Rosseel, 2002</marker>
<rawString>Yves Rosseel. 2002. Mixture models of categorization. J. Math. Psychol., 46(2):178–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Sanderson</author>
</authors>
<title>Word sense disambiguation and information retrieval.</title>
<date>1994</date>
<booktitle>In Proc. of SIGIR-94,</booktitle>
<pages>142--151</pages>
<contexts>
<context position="1263" citStr="Sanderson, 1994" startWordPosition="178" endWordPosition="179">ple “sense-specific” vectors for each word. This approach provides a context-dependent vector representation of word meaning that naturally accommodates homonymy and polysemy. Experimental comparisons to human judgements of semantic similarity for both isolated words as well as words in sentential contexts demonstrate the superiority of this approach over both prototype and exemplar based vector-space models. 1 Introduction Automatically judging the degree of semantic similarity between words is an important task useful in text classification (Baker and McCallum, 1998), information retrieval (Sanderson, 1994), textual entailment, and other language processing tasks. The standard empirical approach to this task exploits the distributional hypothesis, i.e. that similar words appear in similar contexts (Curran and Moens, 2002; Lin and Pantel, 2002; Pereira et al., 1993). Traditionally, word types are represented by a single vector of contextual features derived from cooccurrence information, and semantic similarity is computed using some measure of vector distance (Lee, 1999; Lowe, 2001). However, due to homonymy and polysemy, capturing the semantics of a word with a single vector is problematic. For</context>
</contexts>
<marker>Sanderson, 1994</marker>
<rawString>Mark Sanderson. 1994. Word sense disambiguation and information retrieval. In Proc. of SIGIR-94, pages 142–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>Hinrich Sch¨utze. 1998. Automatic word sense discrimination. Computational Linguistics, 24(1):97–123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Brendan O’Connor</author>
<author>Daniel Jurafsky</author>
<author>Andrew Ng</author>
</authors>
<title>Cheap and fast—but is it good? Evaluating non-expert annotations for natural language tasks.</title>
<date>2008</date>
<booktitle>In Proc. of EMNLP-08.</booktitle>
<marker>Snow, O’Connor, Jurafsky, Ng, 2008</marker>
<rawString>Rion Snow, Brendan O’Connor, Daniel Jurafsky, and Andrew Ng. 2008. Cheap and fast—but is it good? Evaluating non-expert annotations for natural language tasks. In Proc. of EMNLP-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amos Tversky</author>
<author>Itamar Gati</author>
</authors>
<title>Similarity, separability, and the triangle inequality.</title>
<date>1982</date>
<journal>Psychological Review,</journal>
<volume>89</volume>
<issue>2</issue>
<contexts>
<context position="2122" citStr="Tversky and Gati, 1982" startWordPosition="315" endWordPosition="319">2002; Pereira et al., 1993). Traditionally, word types are represented by a single vector of contextual features derived from cooccurrence information, and semantic similarity is computed using some measure of vector distance (Lee, 1999; Lowe, 2001). However, due to homonymy and polysemy, capturing the semantics of a word with a single vector is problematic. For example, the word club is similar to both bat and association, which are not at all similar to each other. Word meaning violates the triangle inequality when viewed at the level of word types, posing a problem for vector-space models (Tversky and Gati, 1982). A single “prototype” vector is simply incapable of capturing phenomena such as homonymy and polysemy. Also, most vector-space models are context independent, while the meaning of a word clearly depends on context. The word club in “The caveman picked up the club” is similar to bat in “John hit the robber with a bat,” but not in “The bat flew out of the cave.” We present a new resource-lean vector-space model that represents a word’s meaning by a set of distinct “sense specific” vectors. The similarity of two isolated words A and B is defined as the minimum distance between one of A’s vectors</context>
<context position="5453" citStr="Tversky and Gati (1982)" startWordPosition="845" endWordPosition="848">plar methods for lexical semantics, Section 3 presents our multi-prototype method, Section 4 presents our experimental evaluations, Section 5 discusses future work, and Section 6 concludes. 2 Background Psychological concept models can be roughly divided into two classes: 1. Prototype models represented concepts by an abstract prototypical instance, similar to a cluster centroid in parametric density estimation. 2. Exemplar models represent concepts by a concrete set of observed instances, similar to nonparametric approaches to density estimation in statistics (Ashby and Alfonso-Reese, 1995). Tversky and Gati (1982) famously showed that conceptual similarity violates the triangle inequality, lending evidence for exemplar-based models in psychology. Exemplar models have been previously used for lexical semantics problems such as selectional preference (Erk, 2007) and thematic fit (Vandekerckhove et al., 2009). Individual exemplars can be quite noisy and the model can incur high computational overhead at prediction time since naively computing the similarity between two words using each occurrence in a textual corpus as an exemplar requires O(n2) comparisons. Instead, the standard ... chose Zbigniew Brzezi</context>
</contexts>
<marker>Tversky, Gati, 1982</marker>
<rawString>Amos Tversky and Itamar Gati. 1982. Similarity, separability, and the triangle inequality. Psychological Review, 89(2):123–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bram Vandekerckhove</author>
<author>Dominiek Sandra</author>
<author>Walter Daelemans</author>
</authors>
<title>A robust and extensible exemplarbased model of thematic fit.</title>
<date>2009</date>
<booktitle>In Proc. of EACL 2009,</booktitle>
<pages>826--834</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5751" citStr="Vandekerckhove et al., 2009" startWordPosition="887" endWordPosition="891">represented concepts by an abstract prototypical instance, similar to a cluster centroid in parametric density estimation. 2. Exemplar models represent concepts by a concrete set of observed instances, similar to nonparametric approaches to density estimation in statistics (Ashby and Alfonso-Reese, 1995). Tversky and Gati (1982) famously showed that conceptual similarity violates the triangle inequality, lending evidence for exemplar-based models in psychology. Exemplar models have been previously used for lexical semantics problems such as selectional preference (Erk, 2007) and thematic fit (Vandekerckhove et al., 2009). Individual exemplars can be quite noisy and the model can incur high computational overhead at prediction time since naively computing the similarity between two words using each occurrence in a textual corpus as an exemplar requires O(n2) comparisons. Instead, the standard ... chose Zbigniew Brzezinski for the position of ... ... thus the symbol s position on his clothing was ... ... writes call options against the stock position ... ... offered a position with ... ... a position he would hold until his retirement in ... ... endanger their position as a cultural group... ... on the chart of</context>
</contexts>
<marker>Vandekerckhove, Sandra, Daelemans, 2009</marker>
<rawString>Bram Vandekerckhove, Dominiek Sandra, and Walter Daelemans. 2009. A robust and extensible exemplarbased model of thematic fit. In Proc. of EACL 2009, pages 826–834. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>