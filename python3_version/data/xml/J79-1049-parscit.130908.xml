<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.661818333333333">
American Journal of Computational Linguistics Microfiche 49
THE FINITE STRING
NEWSLETTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
</title>
<author confidence="0.629126">
VOLUME 13 - NUMBER 4 MAY 1976
</author>
<sectionHeader confidence="0.734945" genericHeader="abstract">
TABLE OF CONTENTS
</sectionHeader>
<table confidence="0.914162875">
CLAM: A COMPUTER LANGUAGE MODEL Nicholas J. S. Dobree 2
R F P : FEDERAL RESEARCH AND DEVELOPMENT BY CONTRACT
Washington Office, State University of New York . . . 53
AFIPS: SOCIAL IMPLICATIONS COMMITTEE .
94
NFAIS: STRUCTURE AND PURPOSE 95
KURZWEIL READING MACHINE 96
TRANSLATING MACHINE DEVELOPED
</table>
<page confidence="0.874495">
97
</page>
<sectionHeader confidence="0.731667" genericHeader="categories and subject descriptors">
AMERICAN JOURNAL OF COMPUTATIONAL LINGUISTICS is published
</sectionHeader>
<title confidence="0.304689">
by the Center for Applied Linguistics for the Association
</title>
<author confidence="0.303257">
for Computational Linguistics
</author>
<affiliation confidence="0.294184">
EDITOR: David G. Hays Professor of Linguistics, SUNY Buffalo
</affiliation>
<note confidence="0.7452795">
EDITORIAL ASSISTANT: William Benzon
EDITORIAL ADDRESS: Twin Willows, Wanakah, New York 14075
MANAGING EDITOR: A. Hood Roberts Deputy Director, Center for
Applied Linguistics
MANAGEMENT ASSISTANT: James Megginson
PRODUCTION AND SUBSCRIPTION ADDRESS: 1611 North Kent Street,
Arlingon, Virginia 22209
CopyrightÂ© 1976,
Association for Computational Linguistics
American Journal of Computational Linguistics Microfiche 49 : 2
CLAM: ACOMPUTER LANGUAGE MODEL
NICHOLAS J. S. DOBREE
</note>
<bodyText confidence="0.866664782608696">
International Language Centre
P. 0. Box 155712
Beirut, LOanon
Temporarily: Rose Cottage, Hindon, Wiltshire, England
This paper describes a program which translates English
into French. It is difficult to delineate the subset which a
program can deal with, so sample sentences are given.
The analyser is multiple path, single pass, akin to
Woods&apos; A.T.N. grammar. The syntax is dealt with by matching.
with templates, the semantics by the application of semantic
rebtrictions to syntactically associated pairs of word meanings.
To limit the number of paths, all available guns, syntactic and
semantic, are brought to bear at every stage. The output is a
list of disambiguated word meanings, formed into a tree structure
but with semantic rather than syntactio relationships between
them.
The French generation first makes appropriate tense changes,
then finds the French word(s) and redistributes them if
necessary. This may generate a French structure radically
different from the English. Then the words are sequenced and
put into the correct form.
The program consists of about 8,500 Fortran instructions and
the processing averages about 15 seconds per word on a 3691-40.
</bodyText>
<sectionHeader confidence="0.8458595" genericHeader="keywords">
TABLE OF CONTENTS
Introduction
</sectionHeader>
<figure confidence="0.46771825">
Results 6
Sample Sentences 15
Description of Method 19
Flowchart 21
</figure>
<bodyText confidence="0.927862">
Reduction of the Passage to Base Form 22
Generation of the French Translation 46
</bodyText>
<sectionHeader confidence="0.6827025" genericHeader="method">
Conclusion 48
ACKNOWLEDGEMENT
</sectionHeader>
<bodyText confidence="0.996246">
My thanks are due to the Managers of IBM Near East and-IBM
Lebanon and many members of the staff of IBM Lebanon, who have
helped and encouraged me in every way. I am also indebted to
Yorick Wilks, Margaret King and Walther Bischoff of the
Fondazione dalle Molle, who have been very helpful with their
advice and ideas.
</bodyText>
<page confidence="0.5641585">
3
4
</page>
<sectionHeader confidence="0.862881" genericHeader="method">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.9608155">
There are, I hope three reasons why CLAM will be of
interest to computational linguists.
</bodyText>
<listItem confidence="0.812709125">
(1) It is a working model. This is not a &amp;quot;paper&amp;quot;
containing &amp;quot;ideas&amp;quot;. It is a description of a model which works.
To be more specific, it is a description of a large program,
written in FORTRAN, which runs on a 360-40. It accepts as input
English text, carries out a syntactic and semantic analysis of
it, stores the result, and translates it into good French.
(2) The subset of English which it is capable of analysing
is, by present standards, extremely large. The vocabulary is
about 1300 words, many of which have a variety of meanings. More
important that the size of the vocabulary is, of course, the
range of syntactic structures and, perhaps most significantly,
the degree of complexity of sentences which can be dealt with.
Increasing the length and complexity of sentences does not bring
likelihood of combinatorial explosion. The amount of working
store and computing time required to analyse a sentence is of
the order of the number of words in a sentence, although of
course it varies according to the number of meanings of the words
and the types of syntactic structure involved.
(3) The program is continuously extensible. This
extensibility applies first to the subset of language which can
be analysed, secondly to the target languages into which trans-
lations can be generated, and thirdly to the uses to which the
analysis of the text can be put. In other words, I believe that
5
</listItem>
<bodyText confidence="0.990730192307692">
the program embodies 4 sound method of syntactic and semantic
analysis such as must be the basis of a computer language model.
Extension of the subset of language which can be analysed
is a matter of addition and refinement. It can be stated with
confidence that such extension can be achieved because nothing
fundamentally different from what has already been achieved is
inVolved. New syntactic structures, well formed or otherwise,
can be incorporated, by addition partly to the files and partly
to the program. Continual refinements can be made to the method
of finding pronoun antecedents. This problem, which seems to be
generally accepted as the most difficult single problem in
analysis, will never be solved by one simple algorithm, and the
fact that a particular program at any given stage of its develop-
ment gives the wrong answer in a particular case, so far from
invalidating the program, rather points the way to further
refinements (cf. Wilks, June 1975). What is important is that
the program should provide the tools which enable the refinement
to be made, and CLAM does this.
Extension of the target languages involves applying to
other languages the same method which is used to generate French.
This can be done, and indeed part of the actual program used for
French would be generally applicable. It will be interesting to
attack a language outside the Indo-European group, and Arabic is
the first one I have in mind, although how soon this can be done
is a question of time and priorities.
The obvious use to which the analysis can be put other than
</bodyText>
<page confidence="0.603355">
6
</page>
<bodyText confidence="0.999361619047619">
translation is a questionLanswer system, and work on this is at
present in hand. A question-answer system must be based on an
effective analyser, and it is believed that CLAM can provide
this. However, I do not maintain that the analyser Should be
independent of&apos;the memory and inferencing part of the system.
Obviously it should not be independent of the memory, since an
analyser must create and use its own memory, and although it
would be theoretically possible for the analyser to have one
type of memory and the latter part of the program to have
another, this would be a ludicrous arrangement. The same
argument applies tp inferencing, which again has to be performed
by an analyser. Therefore it seems that a question-answer
system should be more integrated than many A.1. researchers
appear to allow. On this score, I support the view of Wilks
vis-a-vis Charniak.
To create a question-.answer system, and, indeed, to improve
the translation program, the memory and the semantics of the
present program have to be developed. I use the word &amp;quot;developed&amp;quot;
advisedly because I believe that the existing memory and
semantics form a sound basiS upon which a more comprehensive
system can be built.
</bodyText>
<sectionHeader confidence="0.99598" genericHeader="method">
RESULTS
</sectionHeader>
<bodyText confidence="0.997188333333333">
Assessment of the Subset of Language which the Model can Analyse
It is normal practice when describing a language model to
leave discussion of the achieveMents of the model until the end.
</bodyText>
<page confidence="0.895617">
7
</page>
<bodyText confidence="0.999910807692308">
First comes the description of how the model does ,or would
operate, then, if it is actually in operation, an account of
what it can do. En this description I am reversing the
procedure, because I would not like to think of a rPader
ploughing through details of how something is done 1/ he
subsequently comes to the conclusion that what was done was not
worth doing anyway. Let him first see what can be done, and
then decide whether it is worth the trouble of reading on to
discover how it is done.
Having said this, I am immediately confronted by the problem
adumbrated by Woods of how a reader can assess the range and
scope of a particular model, and by implication, of how the
programmer can honestly present it. There are two standard
methods of preentation. One is by rather sweeping general
statements such as &amp;quot;the program can cope with noun clauses,
adjectival clauses, conjunction, questions&amp;quot; etc., according to
what claims are being made. Such generalisations are inevitably
suspect and rightly so, since no reader will believe that he
could not find, for example, adjectival clauses which the program
could not cope with. The alternative method of presentation is
to give sample sentences which the program has coped with, and
hope that the reader will make for himself the type of general-
isation which the programmer has scrupulously avoided. If the
first method is adopted, the programmer may justifiably be
branded as a charlatan. If the second, he runs the risk of
having his sentences dismissed as &amp;quot;a few examples&amp;quot;.
</bodyText>
<page confidence="0.596767">
8
</page>
<bodyText confidence="0.958074181818182">
The problem is real, and the solution far from obvious:
how to deftne a subset of language. Supposing that we were
conderned only with single sentences and not longer texts; and
sup-pe-sing that it were possible, which evidently it is not, to
list all the sentences of the subset: then how can we find a
definition which .would include all the sentences which we have
listed and exclude any which we have not listed? Two things
are clear. The definition would be very long, Aid it would
contain an agglomeration of embedded provisos. For example) the
section on relative dlauses might include something like this:
Relative clauses are admissible, provided that
</bodyText>
<listItem confidence="0.992266714285714">
1. they do not contain more than seven words;
2. they do not contain a passive verb
unless (a) it is a verb of &apos;cooking&apos;
(b) the clause is a &apos;subject&apos; clause;
3. there is no word between the noun and the relative
clause unless it is part of a supervening relative
clause;
</listItem>
<bodyText confidence="0.7437885">
L1. the noun is not part of a subsidiary clause unless
the subsidiary clause is itself a relative clause
provided that (a) the noun is not the object of the
C lause
and (b) the noun is not a &apos;time&apos; noun.
All of the above provisos are of a type which could well be
applicable at any particular stage in the development of a
program, although some may be more likely than others. The
programmer&apos;s difficulty is that until he has tried an appropriate
type of sentence, he probably will not realise the existence of a.
</bodyText>
<equation confidence="0.313299">
9
</equation>
<bodyText confidence="0.972509">
particular limitation. The first indication of it is that the
sentence doesn&apos;t work, and he then has to rack his brain to
find ,out why not, and alter the program to eliminate the limit-
ation, thereby enlarging the subset in that particular direction
(hoping that he is not at the same time being. so stupid as to
reduce it in another). Therefore if a programmer asserts that
his program can deal with e.g. relative clauses of all types,
he is probably not being dishonest but merely ignorant about
the limitations of his Â°lin program. Whether such limitations
should rightly be described as bugs, which Woods implies, is
dubious, because that is tantamount to execting a program which
can deal with some relative clauses to be able to deal with all
relative clauses, and asserting that insofar as it cannot, some-
thing has gone wrong. Rather might one think of a program in
terms of a pool of water spreading slowly over an area and
gradually covering more and more of that area. The fact that
the water covered a particular part of the area would carry no
implication of covering any other part, although there would be
a reasonable expectation of its spreading to a contiguous area
next. This analogy, though valuable in helping to destroy a
misconception, is evidently incomplete in two respects. It is
two-dimensional, whereas language is.multi-dimensional; and the
program would advance not continuously, like a pool of water,
but by fits and starts, in discrete steps. Each of these points
is worth further examination.
Lip service has long been paid to the multi-dimensional
nature of language, and yet the importance of this aspect in
10
attempting to analyse language has rather sIowly come to be
recognised. How many features are there which have to be taken
into account, and what are they? How many possible relation-
ships can exist between Which of them? And, a question
raised with particular force by computer analysers, what
combinations of features are relevant? As a simple example,
consider two features, both as it happens syntactic although
the argument applies to semantic as well as syntactic features:
relative clauses, and the passive voice. If a program can
analyse each of the features separately, does it follow that
it can analyse them in combination? Suppose, for example, it
can analyse both of these sentences:
</bodyText>
<listItem confidence="0.8883615">
1. The man who came to dinner stole the silver.
2. The man was hit by a bus.
</listItem>
<bodyText confidence="0.885341512195122">
Does it follow that it can analyse this?
The man who was hit by a bus stole the silver.
Alas, it does not. It may in fact be able to, but there is no
logical rule from which it an be deduced that it must be able
to. Is the absence of suc a rule merely a computational quirk,
or does it correspond to some linguistic truth? In this case,
but not necessarily in all such cases, I would say that it does
so cerrespond. We may asK ourselves if it is possible to imagine
a language in which relative clauses e,d_st, and the passive
voice exists, but in which the verb in a relative clause cannot
be in the passive. Of course it is, and there may for all I
know be such languages. It is this absence of a logical rule of
combination which makes the task of defining the bounds of a
11
subset of language so appallingly difficult, especially when it
is remembered that it is not merely combinations of two features,
4s in the above example, but combinations of many features which
have to be taken into account. Multi-dimensionality is such a
cardinal characteristic of language that analysers dealing uith
tiny subsets from which this characteristic has been removed
should probably be treated with reserve. They may give valuable
insights, but they may also be misleading. I do not of course
refer to the memory ot inferencing part of microworld models,
which is usually their raison d&apos;etre, but only to their interfade
with natural language input. The designers of such models are
inclined to regard the input analysis as little more than a
tedious chore, and would be unlikely to take exception to what I
am saying since they themselves normally make no great claims
for this part of their models. But ethers, commenting on the
moaels, sometimes maice exaggerated claims on behalf of the
analysers, and these claims should be guarded against. Perhaps
the relationship between a language and a tiny subset of it with
a strictly limited number of features should be thought of as
akin to the relationship between a wall and a stone.. They are
recognisably composed of the same substance, but one has
essential characteristics which the other totally. lacks.
Before leaving the sUbjept of multi-dimensionality, I would
like to touch briefly on the possibility, at some time in the
future, of devising a standard method of determining the extent
of a subset of a language. The following idea could be considered,
probably to be rejected, but at least it could provide a starting-
</bodyText>
<page confidence="0.528049">
12
</page>
<bodyText confidence="0.999962518518518">
point for discussion. A number of features, say n, could be
decided upon, the number varying according to the degree of
subtlety of delineation required. An n-dimensional array with
n+1 columns in each dimension (Mr the n features + 1 blank)
would then contain an element corresponding to evOry combination
of these features. Some of these elements would be irrlevant,
since they would represent impossible combinations. The valid
elements could be filled or not, according to whether the subset
contained the combination of features which they represented.
For a programmer building up the subset which his program was
capable of analysing, such an array could provide both a measure
of achievement and a guide to what was missing.
To return now to the analogy of the puddle, the second
respect in which it was incomplete as that a program, as it
develops, does not advance continuously, like water spreading,
but by fits and starts, in discrete steps. Suppose, for example,
that a programmer is testing a particular feature like, say,
relative clauses, as that is the feature we have previously
discussed. Sentences containing relative clauses have been
entered repeatedly, and each time they have been rejected or
analysed incorrectly. Then at last comes the moment of triumph
and relief when, for the first time, the program takes in such
a sentence and analyses it dorrectly. At that moment, the
program has not merely edged forward, but it has leapt. In
terms of the array postulated in the last paragraph, not just one
but several elements will in all probability have been covered in
one step. It will not be known for certain which elements, until
</bodyText>
<page confidence="0.67462">
13
</page>
<bodyText confidence="0.991940555555556">
more testing has been done and more sentences tried. Bui just
as it would be ludicrous to suppose that because a program can
analyse one relative clause it can analyse all, it would be
equally ludicrous not to expect a program which can analyse one
relative clause to be able to analyse at least some others.
There is a section of program common to all relative clauses,
which has to work before any can be analysed correctly, and once
that section is working irn combination with any features, the
lik4hood is that it will work in combination with at least some
others.
What follows from this? Firstly, that no reliable method
at present exists for the designer of a language model to
delineate the subset of language which his model can analyse,.
Secondly, that desirable aa it undoubtedly is, for the benefit
of both the designers of models and those who seek to assess
their scope, to devise such a method, it is going to be extremely
difficult to do so. Thirdly, that in this unfortunate state of
affairs a designer can but fall back on the established system of
presenting a list of sentences which his program has analysed
correctly, and leave it to the reader to make his. own assessment
of where the bounds of the subset analysable by the model lie.
To discuss the sentences as simply a few examples would be un-
intelligent; equally unintelligent to see in them visions of
universality. Where, between these two extremes, the reader&apos;s
judgement falls should depend upon the variety of the sentences,
and upon their complexity. If the program can&apos; de]- with
complexity in any area, it should be some indication of its power,
</bodyText>
<page confidence="0.403144">
14
</page>
<bodyText confidence="0.963991136363636">
perhaps yet unrealised, to do so in other areas. It would be a
sign of its vers,atility, of its ability to disentangle elaborate
patterns and resolVe them into their elementary components.
After this rather prolix introduction, I come eventually to
my on &amp;quot;list of sentences&amp;quot; that have been successfully analysed
by CLAM. They fall into two categ9ries: those which have been
translated into French, in which case the French translation is
given; and those which have simply been analysed syntactically,
and semantically and reduced to a base form. This is because
during the last year I have not been working on the French
generator but concentrating on certain aspects of the analyser,.
and so in order to save computer time, the French ;eneration hab
been omitted. Thus the sentences without translation have been
processed last.
The question arises of what exactly is meant by &amp;quot;analysed
syntactically and semantically&amp;quot; and &amp;quot;reduced to base form&amp;quot;. This
will be more fully explained in the subsequent text. At this
stage ft is sufficient to say that a syntactic tree has been formed
and semantic ambiguities resolved, and that semantic relations
betWeen words in the tree have been determined (e.g. a syntactit
subject of a passive verb is recorded as the semantic object).
Sing/e word meanings are retained as basic units. There is no
Schankian-type resolution into semantic primitives, except inso-
far as this is implicit in the classification system. This is
the base form from which the French has been generated. It has
not so far proved necessary to go any baser. Development, as
will be explained later, is envisaged along the lines of extending
15
the network rather than breaking down the units.
SAMPLE SENTENCES
The following are samples of sentences which have been
correctly anatiled by the program. They are given, together
with the French translations where these have been produced by
the program, and with comments on points &apos;of interest in the
sentences.
I. The shirt which you sold is dirty.
La chemise que vous avez vendue est sale.
Relative clause.
2. The man and woman doctors saw have eaten the bread.
L&apos;homme et la femme quo les medecins ont vu ont mange le pain.
Contact clause (relative clause with relative pronoun
missing).
Simple conjunctive phrase.
No article in English but article required in French.
</bodyText>
<listItem confidence="0.988597636363636">
3. I want the king to read the book.
Je veux quo le roi use le livre.
Accusative and infinitive.
4. I thought she would eat.
Jtai pense qutelle mangerait.
Object clause with &amp;quot;that&amp;quot; missing.
5. He hurt some donkeys last month.
Il a fait mal a des anes le mois dernier.
Multiple-word verb in French.
16
6. He went to see the house.
</listItem>
<bodyText confidence="0.839457804878049">
Il est alle voir la maison.
He laved to eat.
Il a vecu pour manger.
Different types of infinitives.
7. The watch will work when the mechanic finishes working.
La montre fonctionner quand le mecanicien finira de travailler.
Time clause: present tense in English becomes future in
French.
&amp;quot;De&amp;quot; after &amp;quot;finir&amp;quot; followed by infinitive instead of
gerund.
Different meanings of &amp;quot;work&amp;quot;.
8. When did you open the door?
Quand es -ce que vous avez ouvert la porte?
Question.
9. Drink the milk faster.
Buvez plus rapidement le lait.
Command.
10. The men got up.
Les hommes se sont leves.
Two-word verb.
4eflexive.
Verb takes &amp;quot;etre&amp;quot;.
11. The clever queen&apos;s uncle disagreed.
Lioncle de la reine intelligene n&apos;a pas ete d&apos;accord.
Possessive.
Position of adjective.
12. Peel the potatoes for your mother.
Epluchez les pommes de terre pour votre mere.
Multiple-word noun.
13. Teachers write plays in March in some countries.
Les instituteurs ecrivent des pieces en Mars dans des
campagnes.
Semantic resolution of &amp;quot;in&amp;quot;.
&apos;Des campagnes&apos; should be icertaintpays
14 He stood up to put the fire off.
Ti s&apos;est leve pour eteindre le chauffage.
Two-word verbs.
15. That waiter, fat and stupid, was breaking the plates.
Ce serVeur gros et stupide cassait les assiettes.
Appositional adjectives between commas.
Continuous tense.
</bodyText>
<listItem confidence="0.732132777777778">
16. The man who drank the wine does not laugh.
L&apos;homme qui a bu le vin ne rit pas.
Negative.
17. You frightened the man whose pen you stole.
Vous avez effraye l&apos;homme dont vous avez vole la plume.
&amp;quot;Whose&amp;quot;-- difficult construction.
18. The woman who you swam with is happy.
La femme avec qui vois avez nage est contente.
Floating preposition at end of relative clause.
</listItem>
<figure confidence="0.824730636363636">
18
19. The woman looks depressed and bored.
La femme a l&apos;air ennuye and drprime.
Semantic resolution of &amp;quot;looks&amp;quot;
&apos;Ennuyel and Ideprimel should be feminine. My ignorance.
20:1I( queens should have arrived.
Les reines auraient du arriver.
&amp;quot;Should have&amp;quot; -- difficult construction.
21 I had to learn to shout.
J&apos;ai du apprendre a crier.
Semantic resolution of &amp;quot;had&amp;quot;.
</figure>
<listItem confidence="0.3200995">
22. Yaur brother, you and r found and your father bought her
horses.
</listItem>
<bodyText confidence="0.967269933333333">
Votre frere, vous et moi avons trouve et votre were a
achete ses chevaux.
Mixed conjui_otion.
23. If you had come you would have met him.
Vous l&apos;auriez recontre si vous etiez venus.
Conditional clause.
Compound tenses.
Pronoun object.
Concord of past participle after &amp;quot;etre&amp;quot;.
24. Picking flowers is wrong.
Cueillir des fleurs est mauvais.
Gerund subject.
25. The king is as large as a cow.
Le roi est aussi grand qu&apos;une vache.
&amp;quot;As&amp;quot; comparative.
</bodyText>
<listItem confidence="0.9288065">
19
26. I have never behaved rudely since you allowed me to stay.
27. He prefers painting pictures to working.
28. As many as six aeroplanes took off.
29. Men bought the book and clock. They mended it. It often
did work.
Pronoun resolution.
30. How good a game is tennis.
31. I know which &apos;house the man was living in.
32. I know how easily embarrassed you are.
33. How clean a brush did you sweep the room with.
34. Men can understand which book is best.
</listItem>
<sectionHeader confidence="0.986092" genericHeader="method">
DESCRIPTION OF METHOD
</sectionHeader>
<bodyText confidence="0.992743457142857">
Before going into some detail about the method used to
achieve these results, I would like to say something about the
danger of over-sophistication on the part of the reader. There
is a natural tendency for researchers, on reading something new,
to look for points of broad similarity with something, anything,
that they have read.before; and, having found it, to sit back
with relief and feel absolved Trom reading any further. In a
field in which vast amounts are being written, it is a proper
self-defence on the part of the reader, but in A.1. in part-
icular, it has its special dangers.
When one passes from the realm of pure ideas to thg,hard
practicalities of writing a computer program, a subtle change
of emphasis occurs. The ideas, all embracing they may have
20
seemed at their inception, recede into the background, and
what become vital are the details, the tiny mosaic pieces
which determine wh-ether the program succeeds. To judge a
computer program by a crude classification of its method is
like judging a picture by saying that it is impressionistic.
Certainly it is impressionistic, but is it any good?
In case the reader is not convinced by this argument,
let me say immediately that this is a multiple-path, single-
pass, left-to-right, word-by-word analyser, akin to the
multiple-path analyser of Oettinger and the augmented
transition.networ grammar of Woods. In order to tackle the
semantics, and indeed also the syntactics, the meanings of
words have been coded according to a hierarchical taxonomy
That they are coded has been largely dictated by the demands
of FORTRAN, in which the program is written, although some
system more overtly like a networ could have been used. That
the classification should be essentially hierarchical, with
certain necessary refinements, has always seemed obvious.
Some details of how the program works now follow. I will
start with the syntactic and semantic analysis, and come later
to the generation of the French.
</bodyText>
<figure confidence="0.8414272">
FLOWCHART
find codes syntactic and semantic analysis French
21
READ
22
</figure>
<sectionHeader confidence="0.79904" genericHeader="method">
REDUCTION OF THE PASSAGE TO BASE FORM
</sectionHeader>
<bodyText confidence="0.990046636363636">
A glance at the flowchart on the preceding page shows
that there are two main parts of the program: first, the
single subroutine READ, and second, a. group of subroutines
comprising the syntactic and semantic analysis.
READ This subroutine first transfers the base form of
the preceding sentence to semi-permanent store. Then it
reads the next sentence. It looks up each word in the
dictionary file (VOCAB). If it cannot find it at first, it
tests for_certain endings such as -s, -ed, and -ing, subtracts
them and tries again. When it finds the word it stores all
the possible codes which are associated with the word in
VOCAB. It also assembles compounds such as &apos;in front of&apos;,
&apos;in order to&apos;, or infinitives, for which there is no single
code. Proverbs or cliches can be &apos;similarly treated.
Coding Every possible Meaning of a word has a code
number containing a maximum of twelve digits. These code
numbe/los are stored with the word in VOCAB and extracted in
READ. The coding is based on a straightforward classification.
2 1 1 1
For example the code of &apos;bull&apos; is noun concrete creature male
6 2 1
animal farm cow Such classification is essential to reduce
the number of syntactic and semantic patterns which have to be
stored. It may be noted in passing that the system of coding
contains the elements of both syntactic and semantic class-
ification. The distinction between the two is at times tenuous.
Further explanation of the coding is given in the appendix.
23
Syntactic and Semantic Analysis This is the most
complicated part of the model, and comprises several sub-
routines. For ease of explanation, many of them are here
treated as parts of the larger routines CON, UPDT and OACR.
As the flowchart shows, these three routines operate in
turn on each word of a sentence, and when the end of the
sentence is reached, a fourth routine, ENDR, is called on to
operate on the complete sentence .
Before giving some account of the functions of these
routines, it is necessary to explain the term EP, and to
describe JEP and JSP, the two principle files referred to in
this part of the program.
EP (English pattern). Take the sentence, The man with a
long nose always snores. The program breaks this down into
four EPs, as follows:
EP 1 EP 2 EP 3 EP LJ
lead word snores man with
nose
subsidiary word man the nose a
subsidiary word always with long
An EP contains one lead word plus a number of subsidiaries,
and is classified according to the nature of thp 1Pad word.
Thus EP 1 is a verb EP, EPs 2 and 4 are noun EPs, and EP 3 is
a preposition EP. Man, the lead word of EP2, is a subsidiary
of EP 1, so EP 2 is dependent on EP 1. Similarly, EP 3 is
depenaent on EP 2, and EP 4 on EP 3. Splitting a sentence into
EPs is simply forming it into a tree structure.
</bodyText>
<equation confidence="0.352571666666667">
24
snores
NN
</equation>
<bodyText confidence="0.948859329268292">
man always
//&apos;
the with
nose
d//
long
JEP This file contains the templates for all the different
types of EP. For example the template for a noun EP contains
various -types of adjective in appropriate sequence. These are
followed by the lead noun. This is then followed by
adjectives, appositional nouns, prepositions and relative pro-
nouns. In an EP certain positions, such as the lead, are
necessary, while others are optional. In a noun EP, the only
necessary position is the lead noun. In a preposition EP,
besides the lead preposition, the following noun is necessary.
By far the most complitated EP is of course the verb EP. In
this EP, later positions can be either closed, or opened, or
made necessary, by a particular class of word in a particular
position. For example, a pre-verb subject closes a host-verb
subject. A question verb makes a post-verb subject necessary.
One class of verbs opens a subsequent gerund position and
closes a subsequent infinitive. Once an EP has been started,
the program tests to see if the next word could occupy an
open position on the template as far as the next necessary
position (cf. below). Note that these templates are of syntactic
patterns and bear no relation to Wilks&apos; semantic templates.
25
JSP This file contains all the semantic patterns (SPs).
An example of an SP is 12119 21 21102. This means that all
verbs whose codes start with the digits 12119 can have as
subjects any nouns whose codes start with the digits 21102.
More specifically, it means that human beings read or write.
In this case the verb would be the lead of a verb EP, and the
noun would be a subsidiary word in the subject position of the
EP. The middle group of digits in the SP specify the relation-
ship between subsidiary and the lead. In this case, 21
specifies subject of verb. Similarly, SPs govern the relation-
ships between the lead verb and all other subsidiary positions
in the verb EP, and between lea91 and subsidiaries of all the
other EPs. For example, 621 2 226 means that time prepositions,
whose code words start with the digits 621, can have as objects
any time nouns whose codes start with digits 226. When deciding
whether a word is acceptnble in a subsidiary position of a
particular EP, a, semantic match is made between that word and
the lead word: JSP is searched to see if an SP exists permit-
ting that word to be associated in that subsidiary position
with that lead word (cf. below).
Processing the Sentence The sentence is processed in a
single pass word by word from left to right. After each word,
a number of possible continuation paths are open. The next
word is tested along each of these paths, and if no place can
be found for it that path is closed. If no places can be found,
the path is reproduced n-1 times and the word added to each path
Each path may then have one or more continuations.
26
Let us now return to thle sentences The man with a long nose
always snores. The program goes through the sentence word by
word, starting from the first. At the beginning, a verb EP
is &amp;quot;open&amp;quot;. That is to say, the program looks for all positions
which could start a verb EP which the first word satisfies. In
this case, &apos;the&apos; cannot be part of a verb EP, but only of a
noun EP, so the program will start a noun EP which is dependent
on the subject position of a verb EP. The next word must
continue the noun EP. Therefore on going to the next word,
only EP2 is &amp;quot;open&amp;quot;. ,Ilviant is then read, and EP2 and also EP1
are updated. At this point there are two alternative
continuations. Either EP2 could be continued, as in fact happens,
or EP2 could be &amp;quot;closed&amp;quot; and EP1 continued. Therefore on going
to the next word, EPs 1 and 2 are both open. So the process is
continued through the sentence.
As shown in the flowchart, there are three subroutines which
operate on each word--CON, UPDT and OACR.
CON takes each EP which is open, and tests each sense of the
word against each possible continuation of the EP. If the word
could satThfy a position, it then looks to see whether a form
match is necessary. In general, in English, a form test is only
necessary between subject and verb, when the number and person
must agree. If this hurdle is overcome, CON then proceeds to a
semantic match. In general, the lead word of an EP must be
matched semantically with every subsidiary word of that EP.
For example a subject must be matched with a vQrb. So A check
is performed, to see if that particular noun taken in that
</bodyText>
<page confidence="0.479906">
27
</page>
<bodyText confidence="0.874382148148148">
particular sense could be the subject of that particular verb
taken in that particular sense. Having found all the possible
solutions, CON then gives way to UPDT.
UPDT updates each EP according to the solutions found in
CON. It reproduces EPs as necessary where more than one
solution has been found, and discards EPs which have become
defunct because no solution has been found. It also determines
which later positions of an EP either can or must be filled as
a result of the current word becoming a part of the EP. It then
hands over to OACR.
OACR (Open and Close Routine) determines which EPs must
be kept &amp;quot;open&amp;quot; for the next word. It also performs some
juggling with EPs in certain rather tricky cases such as
relative clauses. It then returns control to the root program
for the next word.
When all the words of the sentence have been processed,
ENDR is entered. This examines all existing solutions. It
discards any that are incomplete, and performs some housekeeping
on those which are complete in order to separate them. In
future, it will make a choice between alternative solutions,
although this part of the program has not yet been written.
After ENDR, the sentence has been reduced to one (or more)
sets of connected EPs. Within an EP, for each subsidiary word
the relationship to the lead word (eg. verb/object, verb/time-
noun, noun/article, etc.) is specified, as are the code(s)
remaining as a result of the semantic matches which that word
has undergone during the analysis.
</bodyText>
<page confidence="0.528749">
28
</page>
<bodyText confidence="0.999515">
After this brief description of the functions of the various
subroutines, a more detailed explanation of the semantic match
follows. We then show how the program deals with some of the
more complex problems which it oncountors.
Semantic Matching. ln order to illustrate the method, a
simplified example is given, using the word &apos;in&apos;. Take the
sentence, She walked in fields in May. Suppose after READ, the
following codes are in store:
</bodyText>
<figure confidence="0.8255669">
1..312 1
2..1141., 2
3..1141
4..521 3
5..621 3
6..6216 3
7..6212 3
8..631 3
9..6311 3
10..21274..4
</figure>
<bodyText confidence="0.964867469387755">
The last digits, 1 to 6, refer to the
word number. &apos;In&apos; is words 3 and 5
with code numbers 4-9, 11-16. Suppose
the codes have the same meanings as
shown ascribed to 11-16. Suppose
further that &amp;quot;places&amp;quot; start with
digits 2127, and that &apos;field&apos; is 21274,
also that &amp;quot;time periods&amp;quot; start with
digits 223, and that &amp;quot;months&amp;quot; start
with 2235.
11..521 5 adverb
12..621 5 place preposition object - place
13..6211 5 place preposition object - city
14..6212 5 place preposition object - country
15..631 5 time preposition object - time period
16..6311 5 time preposition object - month
17..22355 6
It may well be asked why the distinction has been made
between the three place prepositions and between the two time
prepositions. There could be two reasons: either that the
29
concept of the preposition changes (which is probably not
true here), or that the tranaIation is different in some
target language. If it is only the second case, the
distinction could have been left for the program which
generates the target language to draw. However, it is more
economical to deal with it diring the semantic Matching.
Now let us see how the disambiguation process works.
This example is simplified because it does not show the
semantib matching across prepositions, between &apos;walked&apos; and
&apos;fields&apos;, and between &apos;walked&apos; and &apos;May&apos;. Although sometimes
necessary for complete disambiguation, it is not so in this
example, and as it complicates the explanation, I will omit it
here for the sake of simplicity.
After the second word, there is only one EP open.
o0cle range
Ville meaning of &amp;quot;code
EP1 lead waTk 2-2
range&amp;quot; will appear
subject sde 1-1 presently.)
The third word, &apos;in&apos;, has two syntactic classes, adverb
or preposition. Both are acceptable at this point in the verb
EP. So a semantic match is performed between each class of
&apos;in&apos; and the lead word &apos;walk&apos;.
Suppose that one SP gives 114 5 52,
another gives 11 6 62,
and another gives 11 6 63.
Al] the codes of lin&apos; are accepted-- code 4 by the first SP,
codes 5, 6 and 7 by the second SP, and codes 8 and 9 by the third
</bodyText>
<page confidence="0.403863">
30
</page>
<table confidence="0.705490666666667">
The EP has to be reproduced because there are two syntactic
classes of &apos;in&apos;. We therefore have the following:
code range code ranges
EPI lead walk 2-2 EP2 lead walk 2-2 2-2
subject she 1-1 subject she 1-1 1-1
adverb in 4-4 preposition in 5-7 8-9
</table>
<bodyText confidence="0.984245222222222">
in EP2 there are two code ranges, one for the place preposition
and one for the time prepositions. EP3, a preposition EP
attached to EP2, is now opened, and for the next word this
preposition EP and EP1 are open, but EP2 is closed.
The next word, &apos;fields&apos;, is a place noun. It is not
accepted in EP1, which is therefore discarded. It is accepted
in EP3 as the object of the preposition, so a semantic match is
performed between &apos;in&apos; and &apos;fields&apos;.
Suppose there is an SP, 62 2 2127. Codes 5-7 are then
accepted by this SP, and EP3 then looks like this:
code range
EP3 lead in 5-7
object field 10-10
A reconciliation is now carried out between the codes of &apos;in&apos;
in EP3 and EP2. As a result, the second code range in EP2 is
eliminated.
The next word, &apos;in&apos; again, is now read, and the process is
repeated. EP2 now looks like this:
</bodyText>
<table confidence="0.70767675">
EP2 lead walk 2-2 2-2 31
subject she 1-1 1-1
preposition in 5-7 5-7
preposition in 12-14 15-16
</table>
<bodyText confidence="0.983058666666667">
This time, on &apos;May&apos;, the relevant SP is 6311 2 2235.
There would also be an SP like this: 63 2 223.
But the first SP gives a narrower code range (16-16 instead
of 15-16), and so it is preferred. This time, on reconciliation,
the first code range in EP2 is eliminated and the second is
reduced. So at the end, the three EPs are thus:
EP2 le0. walk 2-2 EP3 lead in 5-7 EP4 lead in 16-16
subject she 1-1 object fields 10-10 object May 17-17
preposition in 5-7
preposition in 16-16
We are now left with a code range for the first &apos;in&apos;
containing three codes. In such cases, it is the first code of
the range which is selected. So &apos;in&apos; has been disambiguated to
621 in the first case, and to 6311 in the second.
Syntactic Complexities Of course, it is all very well for
a program to be able to digest, She walked in fields in May.
But can it also cope with this?
The farmers we were talking about grew, and the green-
grocers, thieves and liars, sold those apples.
In other words, the program must be capable of being expanded
to deal with the myriad complexities and exceptions of natural
</bodyText>
<page confidence="0.760537">
32
</page>
<bodyText confidence="0.936895740740741">
language. However sound the principles underlying a program
may be, such expansion involves a deal of intricate and
detailed work. At every stagev flexibility and rigidity have
to be balanced. The program must be flexible enough to
envisage possibilities, but rigid enough to exclude im-
possibilities and to latch onto the right solution when it
appears. The programmer&apos;s task resembles a tailor&apos;s. Let out
an inch or two mere, take in a couple there. It would be
satisfactory inaeed if an algorithm could be found both concise
and comprehensive which would encompass all the requirements,
but language is such a barnacled growth that this seems on the
face of it improbable. It would be surprising if excrescences
in the program were not necessary to deal with excrescences in
the language. In the development of this program, when the
treatment of a new structure has been added, whenever possible
the original framework has been adapted to incorporate it,
thereby avoiding the necessity of adding large sections of
program. This is only commonsensical. Nevertheless, the program
has grown considerably with its eapacity to handle larger areas of
language.
Here is perhaps a suitable point to emphasise that, since
this is a multiple-path analyser, at each point all the avail-
able information, syntactic and semantic, has been deployed to
eliminate incorrect paths. This has been done not only to
avoid unnecessary computation, but also because the storage
limits have made it essential. There are only 25 EPs. Frequently
during testing this store overflowed, but interestingly enough
</bodyText>
<page confidence="0.603119">
33
</page>
<bodyText confidence="0.973264222222222">
it has always been possible to bring the demand on it back
within bounds by finding some restriction Which had been over-
looked and which cut out one of the paths. It had originally
been feared that 25 EPs would not be nearly enough. One of
the satisfying discoveries of the program is that
Of course the deployment of all available information is
not the only approach. Most of the earlier program concentrated
on the syntax and paid little heed to the semantics. Wilks,
on the other hand, is relying primarily on the semantics and
is taking from the syntax only what is absolutely necessary.
It will be fascinating if his research is able to determine
exactly how much of the syntax is unnecessary. There are obvious
redundancies in the form of unnecessary safe-guards in language.
No one who has struggled with German case endings is ignorant
of this. In English, we have the concord between subject and
verb in the third perSbon of the present, patently unnecessary
since it exists only in this one instance. There are many
sentences in which the semantics alone are clearly sufficient.
In the sentence, &amp;quot;The man ate the steak with a fork.&amp;quot;, the words
could appear in any sequence and the meaning would be decipherable,
although it might take longer to decipher. The interesting
question is what features of the syntax can be consistently
ignored, without occasional sentences cropping up which can only
be deciphered with the help of these features.
There now follows a description of the treatment of three
notoriottsly awkward problems-- relative clauses, pronouns, and
conjunction.
</bodyText>
<page confidence="0.320072">
34
</page>
<listItem confidence="0.836622">
Relative Clauses Six cases are distinguished:
1. The man who met you. 5. The man you met.
2. The man who(m) you met. 6. The man you gave it to.
3. The man who(m) you gave it to.
</listItem>
<bodyText confidence="0.939850416666666">
L1. The man to whom you gave it.
After the lead of a noun EP, a relative pronoun (94), a pre-
position (6), and a contact noun (2R) are all possible
continuations.
&apos;Who&apos; has three relative pronoun codes, starting with,
941, subject of relative clause,
942, object of relative clause,
943, object of prepositian in relative clause.-
&apos;Whom&apos; obviously only has the last two.
EP1 man EP2 man EP3 man EP4
the the the (man) (subject)
who 941 who 942 who 943
</bodyText>
<equation confidence="0.5822205">
EP5 EP6--- EP7 ---
(man) (object) (man) (preposition object)
</equation>
<bodyText confidence="0.99451175">
When a relative pronoun is recognised, the noun EP, EP1,
is reproduced to EPs 2 and 3, and the codes 941, 942, and 943 are
added to separate noun EPs. Then in OACR, new EPs 4 6 are
opened dependent upon the noun EPs. In the case of 941 and 942,
the lead of the noun EP, &apos;man&apos;, is bntered in the nelt EPs,as
subject and object respectively. They are marked so as to avoid
translation, but they are necessary for semantic matching in
the relative clause. In the case of 943, an additional new
</bodyText>
<page confidence="0.549047">
35
</page>
<bodyText confidence="0.9930608">
preposition EP, EP7, is opened dependent upon the relative
clause EP, and the lead of the noun EP, &apos;man&apos;, is entered as
the object of this preposition EP. The relative clause EP
is marked as waiting for a flOating preposition, although when
a preposition comes this EP is reproduced, and in one EP the
preposition is taken as the floating preposition, while in the
other EP it is taken as another preposition. This is necessary
to allow for such clauses as, the man whom you gave the book
in the end to.
In the cases of 941, 942 and 943, the only EP which is open
for the next word is the relative clause EP. For 941 the next
necessary word in the EP is the lead verb, while for 942 and 943
the next necessary word is the subject. In practice, one or
more of these EPs is usually eliminated on the next word.
When a contact noun is recognised, it is marked in the noun
EP as being in reality a relative pronoun. Then the procedure
for 942 and 943 above is followed; but in addition, the contact
noun is entered as the subject of the relative clause EP.
When u preposition is recognised, the noun EP is reproduced
once, because the preposition might be in the noun EP, like dog
in a manger, or it might be in a relative clause. For the
relative clause path, a preposition EP and a relative clause EP
are opened. Only the preposition EP is left open for the next
word, which must be a relative pronoun.
For indirect questions,
</bodyText>
<page confidence="0.620372">
36
</page>
<bodyText confidence="0.991861285714286">
I don&apos;t know which house he bought.
I don&apos;t know what he lived in. etc
the treatment is somewhat similar to that for relative clauses.
Pronouns For either a translation or a question-answering
program, the noun which the pronoun replaces, called here the
replacement noun, has to be identified. In a question-
ailswering program, the reasons are obvious enough. In a
translation program, it is necessary for semantic matching and
also because in many target languages the gender of the pronoun
varies with that of the replacement noun.
The replacement noun might be in the same sentence as the
pronoun, or in a previous sentence. Therefore, in dealing with
pronouns, the program must be able to refer to preceding
sentences. So after ENDR, the essential information for the
sentence just processed is extracted from the first chain of
EPs and stored. At present, thi-s is only done for one chain of
EPs, i.e. one solution. This essential information consists
of a tree, containing one code for each word and the relation
of each word to the code to which it is attached. Reverting
to, The man with a long nose always snores., the information
is as follows.
</bodyText>
<figure confidence="0.504764444444444">
37
snores 1 1175
tense 2 tense, mood, code T 1
man 3 211021 1 1
the Lt 4032 3
with 5 617 3
nose 6 212 5
a 7 4033 6
long 8 4176 6
</figure>
<bodyText confidence="0.986147789473684">
alwEtys 9 536.... 1
The last coiumn points to t.,e code to which the word is
attached. The previous column contains any relationship
information not implicit in the code itself or, in the case
of a pronoun, a pointer to the code of the replacement noun.
If is important to notice that the code itself usually does
provide the relationship information. For example 61, the
first two digits of &apos;with&apos;, specify with some precision the
relationship of &apos;with&apos; to &apos;man&apos;.
With the preceding sentences available in this form, the
processing of a pronoun worlcs as follows. When the pronoun
is first encountered for a semantic match, all the possiWe
replacement nouns are found; that is to say, all those nouns
which agree in number and person with the pronoun and which
are either before the pronoun in the same sentende but not in
the same clause, or in a preceding. sentence. The program only
goes back through the preceding sentences until a suitable
noun has been found. If for example there were one or more
suitable nouns in the second sentence before the current one,
</bodyText>
<page confidence="0.577058">
38
</page>
<bodyText confidence="0.996537740740741">
it would not examine the third sentence berore the current
one. Consider the following sentences.
The man went into the shop where he had seen the raincoat.
He bought a hat and took it away.
For &apos;he&apos;, the only possible replacement noun is &apos;man&apos; because
it is the only noun which agrees in person. For &apos;itt, the
program finds &apos;hat&apos;, &apos;raincoat&apos;, and &apos;shop&apos; as possible re-
placement nouns. If there were a preceding sentence, it
would not bother to search it. Semantic matches are then
carried out between &apos;take&apos; and each of the three nouns and all
three nouns are accepted, so they are all entered into the
EP after &apos;it&apos;. But the code ranges for &apos;shop&apos; are more
restricted than for &apos;hat&apos; and &apos;raincoat&apos;, because the physical-
movement meaning of &apos;take&apos; is excluded with &apos;shop&apos; because
&apos;shop&apos; is immoveable. When &apos;away&apos; is read and matched with
&apos;take&apos;, all meanings of &apos;take&apos; except the physical-movement
meaning are eliminated. &apos;Shop&apos; is now left dangling, so to
speak, and is eliminated as a possible replacement noun. So
when the end of the sentence is reached, there are two possible
surviving replacement nouns, &apos;hat&apos; and &apos;raincoat&apos;. There is
no semantic reason for preferring one of these to the other,
because the number of digits matched In the semantic match
with &apos;take&apos; is the same in both cases. Therefore in ENDR a
choice is made according to a formula of priorities and &apos;hat&apos;
is selected, as a more recent verb object.
This &amp;quot;formula of priorities&amp;quot;, which is only applied if
there is no semantic preference for one noun, is probably at
</bodyText>
<page confidence="0.817241">
39
</page>
<bodyText confidence="0.999159407407407">
the moment -a. rather blunt instrument. It is concerned with
two factors -- which noun occurred in a 1.ater clause, and
which noun has the same function as the pronoun; subject,
object, preposition object, or object of the same preposition.
In the majority of cases it produces the correct answer, but
it is possible to think up examples in which it doesn&apos;t.
With experience of use, the formula will be refined.
A complication is addea ay the possibility that, when a
subject, &apos;it&apos; may be impersonal. This sense is treated
essentially as one possible replacement noun.
There is still work to be done in developing the formula
of priorities. CLAM extracts the information required to
solve the pronoun problem. The question is, how to use it.
Conjunction No part of the program is more complex than
that dealing with conjunction. The principles are clear, even
simple, enough; but applying them has demanded a considerable
amount of care. Consider the fragment,
He cleaned the carpets in the bedroom and
When &apos;and&apos; is read, the EPs are as follows:
EP1 cleaned EP2 carpets EP3 in EP4 bedroom
he the bedroom the
carpets in
All four of these EPs are alive, which is to say that the next
word might be a continuation of any of them. On recognising
a conjunction, the program looks for nnssible continuations in
all alive EPs, from the beginning of the EP up to the point
which has been reached. It carries out the necessary semantic
</bodyText>
<page confidence="0.597103">
40
</page>
<bodyText confidence="0.998231947368421">
matches, it opens a new &amp;quot;conjep&amp;quot; or conjunctive EP for each
solution, and it enters dummy words in both the conjep and
the EPs above it in the chain where necessary. To clarify
this procedure, we will consider two possible continuations.
(a) and I &apos;I&apos; can only be the subject of a
verb EP, so the conjep, EP5, must be joined to EP1. The
program adds a IC entry, and opens EP5 thus:
EP1 cleaned EP5
he
carpets EP5 is dependent on EP1 at the subject
position
K5
(b) and curtains. &apos;Curtains&apos; could be joined to
EP2 as the lead, or Ea-&apos;1 as the object. The conjep is
attached to the lower EP, EP2, but a dummy word is entered
in EP1 and the semantic match is carried out between the
dummy word, tourtains&apos; and the lead of the EP. &apos;cleaned&apos;
EP1 cleaned EP2 carpets EP5 curtains
he the thex
carpets in
curtainsx K5 lead position.
EP5 is dependent on E22 at the
&apos;The&apos; Is entered as a dummy word in EP5 because it comes before
the point at which EP5 is dependent on EP2. A semantic match
is carried out between &apos;the&apos; and &apos;curtains&apos;.
ICUrtainst might also be the subject of a verb EP, so
EP1 is reproduced and another conjep started, attached to the
reproduced EP at the subject position, as for and I
abovie. This path is unlikely to be correct, and will probably
soon be eliminated.
An attempt is also made to attach -curtains&apos; to EP4 in
the lead position, but it fails because a dummy word
curtains&apos; is then put into EP3, and the semantic match
between tint and &apos;curtains&apos; is tried and fails.
Now let us see what the EPs look,like at the end of a
more cdmplex conjunctive sentence:
I, you and Nellie saw, watched and greeted the men,
women and tired children.
</bodyText>
<page confidence="0.511679">
41
</page>
<figure confidence="0.776919882352941">
EP1 saw EP2 I
K3
you KLx
EP5 watched EP6 greeted EP7 men
the
you you K8
Nelliex EP3 you Nelliex Nelliex K9
K5 K4 K6 menx EP8 women
x
x the
K6 EP4 men
Nellie women
men womenx
childrenx K9
womenx
childrenx
EP9 children
</figure>
<bodyText confidence="0.928252454545455">
childrenx
thex
tired
It will be seen that control passes from the conjeps 5
and 6 up to EP1 before &apos;men&apos;, so that &apos;men&apos; is entered as a
word in EP1. But it is also entered as a dummy word in EPs
5 and 6, and semantic matches are carried out with &apos;watched&apos;
and &apos;greeted&apos;. Also &apos;women&apos; and &apos;children&apos;, although only
dummy words in EP1, are entered as dummy words in EPs 5 and
6 as well.
A conjep remains open, and the EP on which it depends
</bodyText>
<page confidence="0.522182">
42
</page>
<bodyText confidence="0.997070074074074">
remains closed until the last necessary word up to the branCh
has been filled. If the sentence had read,
you and Nellie saw, and &apos;he&apos; watched and greeted..etc.
EP5 would have opened with &apos;he&apos;. tift &apos;you&apos; and &apos;Nellie&apos; would
not have been entered in it as dummy words. EP5 would have
remained open, and EP1 closed until after the lead word
&apos;watched&apos;.
A comma is treated as a possible conjunction or as a
possible bracket. Because of the dual role of a comma, the
programming associated with it is rather awkward.
To sum up the treatment of conjunction, the possible
continuations from a conjunction, particularly if&apos; there have
been previous conjunctions in the sentence, can be numerous.
But by the strict use of dummy entries and their associated
semantic matches, false continuations are usually quickly
nosed out and eliminated. Also, for the recording of the
full meaning of a conjunctive sentence for the purpose of
later interrogation, the dummy entry system is of course
essential. And in the special case of comparative sentences,
it is only by such a system that it can be clearly established
exactly what is being compared.
Summary. I conclude this section with an assessment of what
the analysis can and cannot achieve. The purpose of analysis
might be described as follows: to select, from among all the
possible meanings of each word in the passage, its correct
meaning in the context, and to determine what S emantic
relationships exist between which words. CLAM can do this
</bodyText>
<page confidence="0.601758">
45
</page>
<bodyText confidence="0.973066">
with considerable efficiency within the confines of 4 single
sentence. It is just beginning to enlarge its horizens to
deal with longer texts.
To clarify this statement let us consider the aids which
enable us to select one meaning of a word rather than another,
and see which of them CLAM applies.
</bodyText>
<listItem confidence="0.96929675">
1. Syntactic class. Example: &amp;quot;The car will work when
the mechanic finishes his work.&amp;quot; Here the word &apos;work&apos; is
evidently a verb on the first occasion and 4 noun on the
second. CLAM can usually deal easily enough with this type of
</listItem>
<bodyText confidence="0.708285">
ambiguity.
2. Rules for pronoun antecedents. This has already been
discussed at some length.. The rules are both semantic and
syntactic. When the rules are determined, CLAM will be in a
position to apply than&apos;.
</bodyText>
<listItem confidence="0.58571">
3. Semantic restrictions on syntactically associated pairs,
</listItem>
<bodyText confidence="0.96751141025641">
of &apos;words which exclude one meaning. Example: &amp;quot;He took off his
grandmother.&amp;quot; Here the two word verb &apos;take off&apos; mut mean
&apos;mimic&apos;. The personal subject and the existence of an object
excludes the sense of a plane taking off. &apos;Grandmother&apos; as
object excludes the sense of taking off clothes. Such
restrictions are the basis of CLAM&apos;s semantic match, and
ambiguities of this sort are resolved as a matter of course.
4. Semantic restrictions on syntactically associated
Vairs of words Which give preference to one meaning. Example:
&amp;quot;I killed the man with a gun.&amp;quot; Here, there is a syntaLtic as
well as a semantic ambiguity. It is less straightforward than
44
the previous example because the ambiguous word is &apos;with&apos;,
which might be an instrument preposition attached to the verb
or a possessÂ±on preposition attached to the noun
&apos;man&apos;. The semantic relationships which determine the choice,
however, only involve &apos;with&apos; indi ectly. They are between &apos;kill&apos;
and &apos;gun&apos; in one case, and between &apos;man&apos; and &apos;gun&apos; in the
other. Normally Me preference would be for the instrument
interpretation because &apos;gun&apos; is more strongly associated with
&apos;kill&apos; as an instrument than with &apos;man&apos; as a possession. CLAM
chooses the stronger association by taking the &apos;deeper&apos;
semantic match, or in other words the match involving the
Larger number of digits. It does this correctly, but as we
shall see in a moment, it is not always correct to do so.
5. Remoter contextual environment. Sometimes the
factors enabling a choice to be made are more remote from the
word in question than in the examples given above. In order
to find these factors, a longer journey has to be made into
the environment of the word.
Examples: (i) &amp;quot;The mayor hit the alderman so hard that he
fell down.&amp;quot; The normal rules for selection of pronotin
antecedents would prefer &apos;mayor&apos; as the antecedent of &apos;he&apos;
because it is the subject, but in the environment of hitting,
it is much more likely to be the person hit who falls down
rather than the hitter, so &apos;alderman&apos; must be preferred.
(ii) &amp;quot;Two men came in. One had a gun and the other had
a knife. I killed the man with a gun.&amp;quot; Here &apos;with&apos; is
obviously not an instrument preposition attached to
</bodyText>
<page confidence="0.573399">
45
</page>
<bodyText confidence="0.999724666666666">
but a possession preposition attached to &apos;man&apos;. This is so
because the definite article &apos;the&apos; attached to &apos;man&apos; implies
that &apos;man&apos; has already been defined. But in fact two men
have already been defined, and more information is needed to
determine which of them is referred to. The only possible
additional information which could satisfy this requirement
is &apos;with a gun&apos;, which does suffice to distinguish one of the
previously determined men. Therefore this phrase must be
attached to &apos;man&apos;.
At present, CLAM could not resolve either of these
ambiguities. In order to do so it would need, in the first
case, more information about the environment of &apos;hit&apos; than
is contained in the semantic restrictions now at its
disposal, and in the second case, both a better memory and a
routine for dealing with definition of nouns. Work is in
progress on these vital additions. They will involve
adding to the type and range of the semantic relationships
between pairs of words referred to in the definition of the
purpose of analysis given at the beginning of this summary.
At present, CLAM only holds semantic relationships between
words which are syntactically related. This is not enough.
Adding to the types of relationships held, and extending them
to pairs of words which are syntactically remote, will greatly
increase the scope of the model.
</bodyText>
<sectionHeader confidence="0.966693" genericHeader="method">
GENERATION OF THE FRENCH TRANSLATION
</sectionHeader>
<bodyText confidence="0.9921032">
As shown in the flowchart, the sentence is operated on
sequentially by four subroutines--TWEN, ITRN, FRORM and
PRIN. Briefly the function of each of these subroutines
is as follows.
TWEN examines all the verbs. It welds them (joins
auxiliaries to main verbs), and determines their tense in
French. This is not of course necessarily the same as in
English. Other features of the sentence often have to be
examined. Thus, &amp;quot;When he arrives we will meet him&amp;quot;, becomes
in French, &amp;quot;When he will arrive we will meet him&amp;quot;. And
&amp;quot;I have been here for five years&amp;quot; becomes &amp;quot;I am here since
five years.&amp;quot; Gerunds, infinitives and participles are also
dealt with by TWENJ It may well be asked why the weld part
of this routine is thus left until the French generation.
Should it not be done auring the reduction of the English
sentence to base form? The answer is that logically it
should, and it will sooner or later be transferred, probably
to ENDR. But at present it doesn&apos;t matter. The part of the
program described in the section on pronouns which stores the
base form of the last sentences is in fact performed after the
French translation has been generated, and therefore, after
the verbs have been welded.
ITRN takes each word in the sentence in turn. It finds
the code number in FRILE, the French dictionary file, and
extracts the French word(s). Sometimes of course there is
</bodyText>
<page confidence="0.8017555">
46
47
</page>
<bodyText confidence="0.999183">
more than one. Sometimes there is zero because the English
word does not have to be translated. Any particular French
word may not have the same function in the sentence as the
English word. In such cases, the French word entry in FRILE
is followed by a code which specifies the word&apos;s function in
relation to the English word being translated. For example,
if 212237 is the code for &apos;potato&apos;, the-FRILE entry will be
212237 POMME F DE 6 TERRE 6x. The F after POMME shows that
it is feminine. The 6 after DE shows that its function is as
a ptepgsition in the EP of which POMME is the lead. The 6x2
after TERRE shows that it is the object in the EP of which DE
is the lead.
Sometimes it isâmecessary to go up the tree. For example
Y1x5 means an adverb (5) in the verb EP (1) of which the
English word is a subsidiary (Y). It is thus possible to
generate a French sentence of a radically different shape from
English.
ITRIsT, also finds a French sequence code for each word.
This is a code which provides the ordering of words within an
EP. All lead words have the code 200. A pre-noun adjective
may have a code 14Q, and a post-noun adjective 350. So these
codes do not determine what is the actual sequence of words
in the sentence, but they do provide the basic information
from which the sequence is derived in FRORM.
FRORM first derives the actual sequence of words in the
,sentence. It then takes each French word and puts it into the
</bodyText>
<page confidence="0.547608">
48
</page>
<bodyText confidence="0.9968864">
correct Iorm. Obviously the most arduous part of this task
is finding the forms of the verbs. FRORM refers to tables
which contain the verb endings for both irregular and regular
verbs, and the irregular feminine and plural endings for
nouns and adjectives.
PRIN prints the French translation, haying made any
necessary elisions. If there is more than one solution, it
prints alternative translations of particular words on sub-
sequent lines or, if appropriate, it will print complete
alternative sentences.
</bodyText>
<sectionHeader confidence="0.979498" genericHeader="conclusions">
CONCLUSION
</sectionHeader>
<subsectionHeader confidence="0.638561">
Programming Details and Future Developments
</subsectionHeader>
<bodyText confidence="0.998344">
Programmers may be interested in some details. The program
runs on a 360-40 uskng 146K of core store. The program is
written in FORTRAN IV, not an ideal choice but the best
available in the circumstances. The reduction of the English
to base form requires about 6,000 instructions, and the French
generation about 2,500. At present all the files are kept
in core store except for the two large dictionary files VOCAB
and FRILE, which are accessed on disk. It will eventually be
necessary to Keep JSP also on disk.
At present the processing takes about 15 seconds per word
on average, of which READ takes 40%, the semantic and
syntactic analysis about 20%, and the French generation 40%.
No seriams attempt has yet been made to optimise the program and
this time could certainly be reduced. But the reduction would
</bodyText>
<page confidence="0.800699">
49
</page>
<bodyText confidence="0.999961">
be offset by the eventual need to keep JSP on disk. So as
a practical proposition for translating texts, it would be
necessary for the processing time to be reduced by a factor
of about 10. Presumably this will come sooner or later with
improvement in hardware.
There are certain improvements which would have to be
made to the program before it could be used, apart from the
extension of the vocabulary. Most obvious:
</bodyText>
<listItem confidence="0.968480714285714">
(a) there are some syntactic structures such as
inversion after negatives which the program does
not at present recognise;
(b) a selection routine must be incorporated in ENDR
to choose between alternative solutions if more
than one emerges;
(c) if no solution emerges the program should try
</listItem>
<bodyText confidence="0.879323090909091">
again, selectively suppressing semantic matching,
allowing words to be used outside their normal sense;
(d) the sizes of some of the temporary stores would
have to be increased.
No particular difficulty is anticipated with any of these
developments, in that they involve no methodology fundamentally
different from what has already been applied. It is primarily
a matter of time and priorities. However with a fifth develop-
ment, namely the extension of the memory as outlined at the
end of the section oh analysis, new ground must be covered,
and work on this is at present in progress.
</bodyText>
<figure confidence="0.9604424">
APPENDIX
Coding System :,Principal Categories
50
2nd 3rd
1 intransitive
2 noun object
3 clause predicate 1 noun + part part.
2 noun + to + infin.
3 noun + gerund
5 noun clause
4 verb sequel 1 infinitive
2 to + infinitive
3 gerund
5 noun + clause 1 noun + infinitive
predicate
2 noun + to + infin.
Digit 1st
1 verb
4 noun + prep.
gerund
5 noun + noun clause
6 complement sequel
7 be (pres. cont.)
8
1 concrete
</figure>
<footnote confidence="0.7980861">
2 abstract
0 qualify concrete or
2 noun
3 prpnoun
4 adjective
1 be (passive)
2 have (pres. perf.
1 animate
2 inanimate
abstract noun
</footnote>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001164">
<note confidence="0.739868">Journal of Computational Linguistics 49</note>
<title confidence="0.522635">THE FINITE STRING</title>
<affiliation confidence="0.868595">NEWSLETTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS</affiliation>
<address confidence="0.781035">13 - NUMBER 4</address>
<note confidence="0.677266571428571">TABLE OF CONTENTS COMPUTER LANGUAGE MODEL J. S. Dobree 2 F P : RESEARCH AND DEVELOPMENT BY CONTRACT Office, State University of York . . . 53 IMPLICATIONS COMMITTEE . AND PURPOSE 95 KURZWEIL READING MACHINE 96</note>
<title confidence="0.70064375">TRANSLATING MACHINE DEVELOPED AMERICAN JOURNAL OF COMPUTATIONAL LINGUISTICS is published by the Center for Applied Linguistics for the Association for Computational Linguistics</title>
<author confidence="0.73154">David G Hays of Linguistics</author>
<author confidence="0.73154">SUNY Buffalo EDITORIAL ASSISTANT William Benzon</author>
<address confidence="0.609719">Willows, Wanakah, New York 14075</address>
<title confidence="0.6537725">EDITOR: A. Roberts Director, Center for Applied Linguistics</title>
<author confidence="0.868708">MANAGEMENT ASSISTANT James Megginson</author>
<affiliation confidence="0.723692">AND SUBSCRIPTION ADDRESS: North Kent</affiliation>
<address confidence="0.810579">Arlingon, Virginia 22209</address>
<note confidence="0.970084333333333">CopyrightÂ© 1976, Association for Computational Linguistics Journal of Computational Linguistics 49 : 2</note>
<title confidence="0.945885">LANGUAGE MODEL</title>
<author confidence="0.999181">NICHOLAS J S DOBREE</author>
<affiliation confidence="0.979387">International Language Centre</affiliation>
<address confidence="0.961287">P. 0. Box 155712</address>
<abstract confidence="0.940413095238095">Beirut, LOanon Temporarily: Rose Cottage, Hindon, Wiltshire, England This paper describes a program which translates English into French. It is difficult to delineate the subset which a program can deal with, so sample sentences are given. The analyser is multiple path, single pass, akin to Woods&apos; A.T.N. grammar. The syntax is dealt with by matching. with templates, the semantics by the application of semantic rebtrictions to syntactically associated pairs of word meanings. To limit the number of paths, all available guns, syntactic and semantic, are brought to bear at every stage. The output is a list of disambiguated word meanings, formed into a tree structure but with semantic rather than syntactio relationships between them. The French generation first makes appropriate tense changes, then finds the French word(s) and redistributes them if necessary. This may generate a French structure radically different from the English. Then the words are sequenced and put into the correct form. The program consists of about 8,500 Fortran instructions and the processing averages about 15 seconds per word on a 3691-40.</abstract>
<intro confidence="0.934749">TABLE OF CONTENTS</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>