<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9543795">
Chinese Verb Sense Discrimination Using an EM Clustering Model with Rich
Linguistic Features
</title>
<author confidence="0.996565">
Anying Chen, Martha Palmer
</author>
<affiliation confidence="0.998727">
Department of Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.876159">
Philadelphia, PA, 19104
</address>
<email confidence="0.996588">
{jinying,mpalmer}@linc.cis.upenn.edu
</email>
<sectionHeader confidence="0.992453" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999961">
This paper discusses the application of the
Expectation-Maximization (EM) clustering
algorithm to the task of Chinese verb sense
discrimination. The model utilized rich
linguistic features that capture predicate-
argument structure information of the target
verbs. A semantic taxonomy for Chinese
nouns, which was built semi-automatically
based on two electronic Chinese semantic
dictionaries, was used to provide semantic
features for the model. Purity and normalized
mutual information were used to evaluate the
clustering performance on 12 Chinese verbs.
The experimental results show that the EM
clustering model can learn sense or sense
group distinctions for most of the verbs
successfully. We further enhanced the model
with certain fine-grained semantic categories
called lexical sets. Our results indicate that
these lexical sets improve the model&apos;s
performance for the three most challenging
verbs chosen from the first set of experiments.
</bodyText>
<sectionHeader confidence="0.999001" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999958372881356">
Highly ambiguous words may lead to irrelevant
document retrieval and inaccurate lexical choice in
machine translation (Palmer et al., 2000), which
suggests that word sense disambiguation (WSD) is
beneficial and sometimes even necessary in such
NLP tasks. This paper addresses WSD in Chinese
through developing an Expectation-Maximization
(EM) clustering model to learn Chinese verb sense
distinctions. The major goal is to do sense
discrimination rather than sense labeling, similar to
(Schütze, 1998). The basic idea is to divide
instances of a word into several clusters that have
no sense labels. The instances in the same cluster
are regarded as having the same meaning. Word
sense discrimination can be applied to document
retrieval and similar tasks in information access,
and to facilitating the building of large annotated
corpora. In addition, since the clustering model can
be trained on large unannotated corpora and
evaluated on a relatively small sense-tagged
corpus, it can be used to find indicative features for
sense distinctions through exploring huge amount
of available unannotated text data.
The EM clustering algorithm (Hofmann and
Puzicha, 1998) used here is an unsupervised
machine learning algorithm that has been applied
in many NLP tasks, such as inducing a
semantically labeled lexicon and determining
lexical choice in machine translation (Rooth et al.,
1998), automatic acquisition of verb semantic
classes (Schulte im Walde, 2000) and automatic
semantic labeling (Gildea and Jurafsky, 2002). In
our task, we equipped the EM clustering model
with rich linguistic features that capture the
predicate-argument structure information of verbs
and restricted the feature set for each verb using
knowledge from dictionaries. We also semi-
automatically built a semantic taxonomy for
Chinese nouns based on two Chinese electronic
semantic dictionaries, the Hownet dictionary1 and
the Rocling dictionary.2 The 7 top-level categories
of this taxonomy were used as semantic features
for the model. Since external knowledge is used to
obtain the semantic features and guide feature
selection, the model is not completely
unsupervised from this perspective; however, it
does not make use of any annotated training data.
Two external quality measures, purity and
normalized mutual information (NMI) (Strehl.
2002), were used to evaluate the model&apos;s
performance on 12 Chinese verbs. The
experimental results show that rich linguistic
features and the semantic taxonomy are both very
useful in sense discrimination. The model
generally performs well in learning sense group
distinctions for difficult, highly polysemous verbs
and sense distinctions for other verbs. Enhanced by
certain fine-grained semantic categories called
lexical sets (Hanks, 1996), the model&apos;s
</bodyText>
<footnote confidence="0.919981">
1 http://www.keenage.com/.
</footnote>
<page confidence="0.449401">
2 A Chinese electronic dictionary liscenced from The
</page>
<affiliation confidence="0.632574">
Association for Computational Linguistics and Chinese
Language Processing (ACLCLP), Nankang, Taipei,
Taiwan.
</affiliation>
<bodyText confidence="0.999643076923077">
performance improved in a preliminary experiment
for the three most difficult verbs chosen from the
first set of experiments.
The paper is organized as follows: we briefly
introduce the EM clustering model in Section 2
and describe the features used by the model in
Section 3. In Section 4, we introduce a semantic
taxonomy for Chinese nouns, which is built semi-
automatically for our task but can also be used in
other NLP tasks such as co-reference resolution
and relation detection in information extraction.
We report our experimental results in Section 5
and conclude our discussion in Section 6.
</bodyText>
<sectionHeader confidence="0.989517" genericHeader="method">
2 EM Clustering Model
</sectionHeader>
<bodyText confidence="0.9985145">
The basic idea of our EM clustering approach is
similar to the probabilistic model of co-occurrence
described in detail in (Hofmann and Puzicha
1998). In our model, we treat a set of features
{f1,f2,...,fm } , which are extracted from the
parsed sentences that contain a target verb, as
observed variables. These variables are assumed to
be independent given a hidden variable c, the sense
of the target verb. Therefore the joint probability of
the observed variables (features) for each verb
instance, i.e., each parsed sentence containing the
target verb, is defined in equation (1),
</bodyText>
<equation confidence="0.9959055">
m
p f f fm
( , ,..., ) () (  |)
=∑ ∏
p c p f i c (1)
1 2c i=1
</equation>
<bodyText confidence="0.943167133333333">
In the maximization step (M-step), p(c) and
c) are re-computed by maximizing the log-
likelihood of all the observed data which is
calculated by using
estimated
in the E-step. The E-step and M-step are repeated
for a fixed number of rounds, which is set to 20 in
our experiments,4 or till the amount of change of
p(c) and
c) is under the threshold 0.001.
When doing classification, for each verb
instance, the model calculates the same conditional
probability as in equation (3) and assigns the
instance to the cluster with the maximal
p(fi|
</bodyText>
<equation confidence="0.986082">
(  |, ,..., )
p � c f 1 f2 fm
p(fi|
p(c|f1,f2,...,fm).
</equation>
<bodyText confidence="0.999671">
The fi&apos;s are discrete-valued features that can
take multiple values. A typical feature used in our
model is shown in (2),
</bodyText>
<listItem confidence="0.7262742">
0 iff the target verb has no sentential
complement
1 iff the target verb has a nonfinite (2)
sentential complement
2 iff the target verb has a finite
</listItem>
<subsectionHeader confidence="0.762113">
sentential complement
</subsectionHeader>
<bodyText confidence="0.9980868">
At the beginning of training (i.e., clustering), the
model&apos;s parameters p(c) and p(fi  |c) are
randomly initialized.3 Then, the probability of c
conditioned on the observed features is computed
in the expectation step (E-step), using equation (3),
</bodyText>
<equation confidence="0.984078705882353">
Ac |f,f2,...,fm)
∑p (
p
c)∏ p (  |)
(  |)
f c
f c
i
i
c
c.
out
/right away
他们/their县/county出/go
门/door就
是/be 山 /mountain
&amp;quot;In their county, you can see mountains as soon
</equation>
<bodyText confidence="0.767341117647059">
as you step out of the doors.&amp;quot;
The verb has the sense produce in
and its
object should be something producible, such as
While in
with the sense
happen, the verb typically takes an event or event-
like object, such as
event&amp;quot;,
or
etc. In
the verb&apos;s object
is closely related to
location, consistent with the sense go out. In
contrast, simple lexical or POS tag features
sometimes fail to capture such information, which
can
</bodyText>
<equation confidence="0.96189208">
(1a)
&amp;quot;香蕉/banana&amp;quot;.
(1b),
&amp;quot;大事/big
&amp;quot;事故/accident&amp;quot;
&amp;quot;问题/problem&amp;quot;
(1c),
&amp;quot;门/door&amp;quot;
be seen clearly in (2),





fi

m
( ) (  |)
i
= i 1 m (3)
∏
p c p f c
i
=
1
</equation>
<footnote confidence="0.274419166666667">
3 In our experiments, for verbs with more than 3
senses, syntactic and semantic restrictions derived from
dictionary entries are used to constrain the ran
dom
initialization.
3 Features Used in the Model
</footnote>
<bodyText confidence="0.653376666666666">
The EM clustering model uses a set of linguistic
features to capture the predicate-argument
structure information of the target verbs. These
features are usually more indicative of verb sense
distinctions than simple features such as words
next to the target verb or their POS tags. For
example, the Chinese verb
has a sense
of produce, the distinction between this sense an
&amp;quot;出|chu1&amp;quot;
d
the verb&apos;s other senses, such as happen and go out,
largely depends on the semantic category of the
verb&apos;s direct object. Typical examples are shown
in (1),
(1) a.
/banana
&amp;quot;Their county produces ban
他们/their县/county出/produce香蕉
anas.&amp;quot;
/big
/event
b. 他们/their县/county出/happen大
事
了 /ASP
&amp;quot;A big event happened in their county.&amp;quot;
In our experiments, we set 20 as the maximal
number of rounds after trying different numbers of
rounds (20, 40, 60, 80, 100) in a preliminary
experi
4
ment.
(2) a. 去年/last year 出/produce 香蕉/banana 3000
公斤/ kilogram
&amp;quot;3000 kilograms of bananas were produced last
year.&amp;quot;
b. 要/in order to 出/produce 海南/Hainan
最好/best 的/DE 香蕉 /banana
&amp;quot;In order to produce the best bananas in
Hainan, &amp;quot;
The verb&apos;s object &amp;quot;香蕉/banana&amp;quot;, which is next
to the verb in (2a), is far away from the verb in
(2b). For (2b), a classifier only looking at the
adjacent positions of the target verb tends to be
misled by the NP right after the verb, i.e.,
&amp;quot;海南/Hainan&amp;quot;, which is a Province in China and a
typical object of the verb with the sense go out.
Five types of features are used in our model:
</bodyText>
<listItem confidence="0.9983183">
1. Semantic category of the subject of the target
verb
2. Semantic category of the object of the target
verb
3. Transitivity of the target verb
4. Whether the target verb takes a sentential
complement and which type of sentential
complement (finite or nonfinite) it takes
5. Whether the target verb occurs in a verb
compound
</listItem>
<bodyText confidence="0.999912961538461">
We obtain the values for the first two types of
features (1) and (2) from a semantic taxonomy for
Chinese nouns, which we will introduce in detail in
the next section.
In our implementation, the model uses different
features for different verbs. The criteria for feature
selection are from the electronic CETA dictionary
file 5 and a hard copy English-Chinese dictionary,
The Warmth Modern Chinese-English Dictionary.6
For example, the verb &amp;quot;出|chu1&amp;quot; never takes
sentential complements, thus the fourth type of
feature is not used for it. It could be supposed that
we can still have a uniform model, i.e., a model
using the same set of features for all the target
verbs, and just let the EM clustering algorithm find
useful features for different verbs automatically.
The problem here is that unsupervised learning
models (i.e., models trained on unlabeled data) are
more likely to be affected by noisy data than
supervised ones. Since all the features used in our
model are extracted from automatically parsed
sentences that inevitably have preprocessing errors
such as segmentation, POS tagging and parsing
errors, using verb-specific sets of features can
alleviate the problem caused by noisy data to some
extent. For example, if the model already knows
</bodyText>
<footnote confidence="0.400346333333333">
5 Licensed from the Department of Defense
6 The Warmth Modern Chinese-English Dictionary,
Wang-Wen Books Ltd, 1997.
</footnote>
<bodyText confidence="0.999890666666667">
that a verb like &amp;quot;出|chu1&amp;quot; can never take sentential
complements (i.e., it does not use the fourth type of
feature for that verb), it will not be misled by
erroneous parsing information saying that the verb
takes sentential complements in certain sentences.
Since the corresponding feature is not included, the
noisy data is filtered out. In our EM clustering
model, all the features selected for a target verb are
treated in the same way, as described in Section 2.
</bodyText>
<sectionHeader confidence="0.931552" genericHeader="method">
4 A Semantic Taxonomy Built Semi-
automatically
</sectionHeader>
<bodyText confidence="0.999932027777778">
Examples in (1) have shown that the semantic
category of the object of a verb sometimes is
crucial in distinguishing certain Chinese verb
senses. And our previous work on information
extraction in Chinese (Chen et al., 2004) has
shown that semantic features, which are more
general than lexical features but still contain rich
information about words, can be used to improve a
model&apos;s capability of handling unknown words,
thus alleviating potential sparse data problems.
We have two Chinese electronic semantic
dictionaries: the Hownet dictionary, which assigns
26,106 nouns to 346 semantic categories, and the
Rocling dictionary, which assigns 4,474 nouns to
110 semantic categories.7 A preliminary
experimental result suggests that these semantic
categories might be too fine-grained for the EM
clustering model (see Section 5.2 for greater
details). An analysis of the sense distinctions of
several Chinese verbs also suggests that more
general categories on top of the Hownet and
Rocling categories could still be informative and
most importantly, could enable the model to
generate meaningful clusters more easily. We
therefore built a three-level semantic taxonomy
based on the two semantic dictionaries using both
automatic methods and manual effort.
The taxonomy was built in three steps. First, a
simple mapping algorithm was used to map
semantic categories defined in Hownet and
Rocling into 27 top-level WordNet categories.8
The Hownet or Rocling semantic categories have
English glosses. For each category gloss, the
algorithm looks through the hypernyms of its first
sense in WordNet and chooses the first WordNet
top-level category it finds.
</bodyText>
<footnote confidence="0.96851825">
7 Hownet assigns multiple entries (could be different
semantic categories) to polysemous words. The Rocling
dictionary we used only assigns one entry (i.e., one
semantic category) to each noun.
8 The 27 categories contain 25 unique beginners for
noun source files in WordNet, as defined in (Fellbaum,
1998) and two higher level categories Entity and
Abstraction.
</footnote>
<figureCaption confidence="0.979066">
Figure 1. Part of the 3-level Semantic Taxonomy for Chinese Nouns (other top-level nodes
are Time, Human, Animal and State)
</figureCaption>
<figure confidence="0.995411363636363">
Location
Top level
Intermediate level
Hownet/Rocling
categories
Event
Entity
Plant Artifact
Document
Food
Money
drinks, edible, meals, vegetable, ...
institution, army, corporation, ...
Activity ......
Process
chase, cut, pass, split, cheat, ...
process, BecomeLess, StateChange, disappear, ....
Natural Phenomena
Happening
Location—Part
Location
Group......
</figure>
<bodyText confidence="0.999827051282051">
The mapping obtained from step 1 needs further
modification for two reasons. First, the glosses of
Hownet or Rocling semantic categories usually
have multiple senses in WordNet. Sometimes, the
first sense in WordNet for a category gloss is not
its intended meaning in Hownet or Rocling. In this
case, the simple algorithm cannot get the correct
mapping. Second, Hownet and Rocling sometimes
use adjectives or non-words as category glosses,
such as animate and LandYehicle etc., which have
no WordNet nominal hypernyms at all. However,
those adjectives or non-words usually have
straightforward meanings and can be easily
reassigned to an appropriate WordNet category.
Although not accurate, the automatic mapping in
step 1 provides a basic framework or skeleton for
the semantic taxonomy we want to build and
makes subsequent work easier.
In step 2, hand correction, we found that we
could make judgments and necessary adjustments
on about 80% of the mappings by only looking at
the category glosses used by Hownet or Rocling,
such as livestock, money, building and so on. For
the other 20%, we could make quick decisions by
looking them up in an electronic table we created.
For each Hownet or Rocling category, our table
lists all the nouns assigned to it by the two
dictionaries. We merged two WordNet categories
into others and subdivided three categories that
seemed more coarse-grained than others into 2~5
subcategories. Step 2 took three days and 35
intermediate-level categories were generated.
In step 3, we manually clustered the 35
intermediate-level categories into 7 top-level
semantic categories. Figure 1 shows part of the
taxonomy.
The EM clustering model uses the 7 top-level
categories to define the first two types of features
that were introduced in Section 3. For example, the
</bodyText>
<listItem confidence="0.673197666666667">
value of a feature fk is 1 if and only if the object
NP of the target verb belongs to the semantic
category Event and is otherwise 0.
</listItem>
<sectionHeader confidence="0.942452" genericHeader="method">
5 Clustering Experiments
</sectionHeader>
<bodyText confidence="0.999994862068965">
Since we need labeled data to evaluate the
clustering performance but have limited sense-
tagged corpora, we applied the clustering model to
12 Chinese verbs in our experiments. The verbs are
chosen from 28 annotated verbs in Penn Chinese
Treebank so that they have at least two verb
meanings in the corpus and for each of them, the
number of instances for a single verb sense does
not exceed 90% of the total number of instances.
In our task, we generally do not include senses
for other parts of speech of the selected words,
such as noun, preposition, conjunction and particle
etc., since the parser we used has a very high
accuracy in distinguishing different parts of speech
of these words (&gt;98% for most of them). However,
we do include senses for conjunctional and/or
prepositional usage of two words, &amp;quot;到|dao4&amp;quot; and
&amp;quot;为|wei4&amp;quot;, since our parser cannot distinguish the
verb usage from the conjunctional or prepositional
usage for the two words very well.
Five verbs, the first five listed in Table 1, are
both highly polysemous and difficult for a
supervised word sense classifier (Dang et al.,
2002). 9 In our experiments, we manually grouped
the verb senses for the five verbs. The criteria for
the grouping are similar to Palmer et al.&apos;s (to
appear) work on English verbs, which considers
both sense coherence and predicate-argument
structure distinctions. Figure 2 gives an example of
</bodyText>
<footnote confidence="0.738849">
9 In the supervised task, their accuracies are lower
than 85%, and four of them are even lower than the
baselines.
</footnote>
<bodyText confidence="0.518397">
Senses for &amp;quot;到|dao4&amp;quot; Sense groups for &amp;quot;到|dao4&amp;quot;
</bodyText>
<listItem confidence="0.88567">
1. to go to, leave for
2. to come
3. to arrive
4. to reach a particular stage, condition, or level
5. marker for completion of activities (after a verb)
6. marker for direction of activities (after a verb)
7. to reach a time point
8. up to, until (prepositional usage)
9. up to, until, (from ...) to ... (conjunctional usage)
</listItem>
<figure confidence="0.99308625">
1, 2 5
3
4,7,8,9
6
</figure>
<figureCaption confidence="0.999971">
Figure 2. Sense groups for the Chinese verb &amp;quot;到|dao4&amp;quot;
</figureCaption>
<bodyText confidence="0.996641333333333">
the definition of sense groups. The manually
defined sense groups are used to evaluate the
model&apos;s performance on the five verbs.
The model was trained on an unannotated
corpus, People&apos;s Daily News (PDN), and tested on
the manually sense-tagged Chinese Treebank (with
some additional sense-tagged PDN data).10 We
parsed the training and test data using a Maximum
Entropy parser and extracted the features from the
parsed data automatically. The number of clusters
used by the model is set to the number of the
defined senses or sense groups of each target verb.
For each verb, we ran the EM clustering algorithm
ten times. Table 2 shows the average performance
and the standard deviation for each verb. Table 1
summarizes the data used in the experiments,
where we also give the normalized sense
perplexity11 of each verb in the test data.
</bodyText>
<sectionHeader confidence="0.512834" genericHeader="evaluation">
5.1 Evaluation Methods
</sectionHeader>
<bodyText confidence="0.940459085714286">
We use two external quality measures, purity
and normalized mutual information (NMI) (Strehl.
2002) to evaluate the clustering performance.
Assuming a verb has l senses, the clustering model
assigns n instances of the verb into k clusters, ni is
the size of the ith cluster, j
n is the number of
instances hand-tagged with the jth sense, and j
ni is
the number of instances with the jth sense in the ith
cluster, purity is defined in equation (4):
10 The sense-tagged PDN data we used here are the
same as in (Dang et al., 2002).
11 It is calculated as the entropy of the sense
distribution of a verb in the test data divided by the
largest possible entropy, i.e., log2 (the number of senses
of the verb in the test data).
It can be interpreted as classification accuracy
when for each cluster we treat the majority of
instances that have the same sense as correctly
classified. The baseline purity is calculated by
treating all instances for a target verb in a single
cluster. The purity measure is very intuitive. In our
case, since the number of clusters is preset to the
number of senses, purity for verbs with two senses
is equal to classification accuracy defined in
supervised WSD. However, for verbs with more
than 2 senses, purity is less informative in that a
clustering model could achieve high purity by
making the instances of 2 or 3 dominant senses the
majority instances of all the clusters.
Mutual information (MI) is more theoretically
well-founded than purity. Treating the verb sense
and the cluster as random variables S and C, the
MI between them is defined in equation (5):
</bodyText>
<equation confidence="0.949003">
MI(S,C) = p(s ,c
</equation>
<bodyText confidence="0.999485631578947">
MI(S,C) characterizes the reduction in
uncertainty of one random variable S (or C) due to
knowing the other variable C (or S). A single
cluster with all instances for a target verb has a
zero MI. Random clustering also has a zero MI in
the limit. In our experiments, we used [0,1]-
normalized
0,1]-
normalized mutual information (NMI) (Strehl.
2002). A shortcoming of this measure, however, is
that the best possible clustering (upper bound)
evaluates to less than 1, unless classes are
balanced. Unfortunately, unbalanced sense
distribution is the usual case in WSD tasks, which
makes NMI itself hard to interpret. Therefore, in
addition to NMI, we also give its upper bound
(upper-NMI) and the ratio of NMI and its upper
bound (NMI-ratio) for each verb, as shown in
columns 6 to 8 in Table 2.
</bodyText>
<figure confidence="0.8322092">
1
k
n
max
(4)
j
purity
j
i
∑=
i 1
n
s c
,
j
</figure>
<equation confidence="0.916146">
i
l k
n
∑∑
n
j=1 i=1
∑
p s c
( , )
p s p c
( ) ( )
j
log n n
i
n n
i
) log
j
(5)
</equation>
<table confidence="0.996982166666667">
Verb |Pinyin Sample senses of
the verb
出 |chu1 go out /produce
到 |dao4 come /reach
见 |jian4 see /show
想 |xiang3 think/suppose
要 |yao4 Should/intend to
表示|biao3shi4 Indicate /express
发现|fa1xian4 discover /realize
发展|fa1zhan3 develop /grow
恢复|hui1fu4 resume /restore
说 |shuo1 say /express by
written words
投入|tou2ru4 to input /plunge into
为 |wei2�4 to be /in order to
# Senses in # Sense Sense # # Training # Test
test data groups in perplexity Clusters instances instances
test data
16 7 0.68 8 399 157
9 5 0.72 6 1838 186
8 5 0.68 6 117 82
6 4 0.64 6 94 228
8 4 0.65 7 2781 185
2 0.93 2 666 97
2 0.76 2 319 27
3 0.69 3 458 130
4 0.83 4 107 125
7 0.40 7 2692 307
2 1.00 2 136 23
6 0.82 6 547 463
</table>
<tableCaption confidence="0.997712">
Table 1. A summary of the training and test data used in the experiments
</tableCaption>
<table confidence="0.999983933333333">
Verb Sense Baseline Purity Std. Dev. of NMI Upper- NMI- Std. Dev. of
perplexity Purity (%) (%) purity (%) NMI ratio (%) NMI ratio (%)
出 0.68 52.87 63.31 1.59 0.2954 0.6831 43.24 1.76
到 0.72 40.32 90.48 1.08 0.4802 0.7200 75.65 0.00
见 0.68 58.54 72.20 1.61 0.1526 0.6806 22.41 0.66
想 0.64 68.42 79.39 3.74 0.2366 0.6354 37.24 8.22
要 0.65 69.19 69.62 0.34 0.0108 0.6550 1.65 0.78
表示 0.93 64.95 98.04 1.49 0.8670 0.9345 92.77 0.00
发现 0.76 77.78 97.04 3.87 0.7161 0.7642 93.71 13.26
发展 0.69 53.13 90.77 0.24 0.4482 0.6918 64.79 2.26
恢复 0.83 45.97 65.32 0.00 0.1288 0.8234 15.64 0.00
说 0.40 80.13 93.00 0.58 0.3013 0.3958 76.13 4.07
投入 1.00 52.17 95.65 0.00 0.7827 0.9986 78.38 0.00
为 0.82 32.61 75.12 0.43 0.4213 0.8213 51.30 2.07
Average 0.73 58.01 82.50 1.12 0.4088 0.7336 54.41 3.31
</table>
<tableCaption confidence="0.992669">
Table 2. The performance of the EM clustering model on 12 Chinese verbs measured
by purity and normalized mutual information (NMI)
</tableCaption>
<subsectionHeader confidence="0.998647">
5.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.976913870967742">
Table 2 summarizes the experimental results for
the 12 Chinese verbs. As we see, the EM clustering
model performs well on most of them, except the
verb &amp;quot;要|yao4&amp;quot;.12 The NMI measure NMI-ratio
turns out to be more stringent than purity. A high
purity does not necessarily mean a high NMI-ratio.
Although intuitively, NMI-ratio should be related
to sense perplexity and purity, it is hard to
formalize the relationships between them from the
results. In fact, the NMI-ratio for a particular verb
is eventually determined by its concrete sense
distribution in the test data and the model&apos;s
clustering behavior for that verb. For example, the
verbs &amp;quot;出|chu1&amp;quot; and &amp;quot;见|jian4&amp;quot; have the same
sense perplexity and &amp;quot;见|jian4&amp;quot; has a higher purity
than &amp;quot;出|chu1&amp;quot; (72.20% vs. 63.31%), but the NMI-
ratio for &amp;quot;见|jian4&amp;quot; is much lower than &amp;quot;出|chu1&amp;quot;
(22.41% vs. 43.24%). An analysis of the
12 For all the verbs except &amp;quot;要|yao4&amp;quot;, the model&apos;s
purities outperformed the baseline purities significantly
(p&lt;0.05, and p&lt;0.001 for 8 of them).
classification results for &amp;quot;见|jian4&amp;quot; shows that the
clustering model made the instances of the verb&apos;s
most dominant sense the majority instances of
three clusters (of total 5 clusters), which is
penalized heavily by the NMI measure.
Rich linguistic features turn out to be very
effective in learning Chinese verb sense
distinctions. Except for the two verbs,
&amp;quot;发现|fa1xian4&amp;quot; and &amp;quot;表示|biao3shi4&amp;quot;, the sense
distinctions of which can usually be made only by
syntactic alternations,13 features such as semantic
features or combinations of semantic features and
syntactic alternations are very beneficial and
sometimes even necessary for learning sense
distinctions of other verbs. For example, the verb
&amp;quot;见|jian4&amp;quot; has one sense see, in which the verb
typically takes a Human subject and a sentential
complement, while in another sense show, the verb
typically takes an Entity subject and a State object.
An inspection of the classification results shows
13 For example, the verb &amp;quot;发现|fa1xian4&amp;quot; takes an
object in one sense discover and a sentential
complement in the other sense realize.
that the EM clustering model has indeed learned
such combinatory patterns from the training data.
The experimental results also indicate that the
semantic taxonomy we built is beneficial for the
task. For example, the verb &amp;quot;投入|tou1ru4&amp;quot; has
two senses, input and plunge into. It typically takes
an Event object for the second sense but not for the
first one. A single feature obtained from our
semantic taxonomy, which tests whether the verb
takes an Event object, captures this property neatly
(achieves purity 95.65% and NMI-ratio 78.38%
when using 2 clusters). Without the taxonomy, the
top-level category Event is split into many fine-
grained Hownet or Rocling categories, which
makes it very difficult for the EM clustering model
to learn sense distinctions for this verb. In fact, in a
preliminary experiment only using the Hownet and
Rocling categories, the model had the same purity
as the baseline (52.17%) and a low NMI-ratio
(4.22%) when using 2 clusters. The purity
improved when using more clusters (70.43% with
4 clusters and 76.09% with 6), but it was still much
lower than the purity achieved by using the
semantic taxonomy and the NMI-ratio dropped
further (1.19% and 1.20% for the two cases).
By looking at the classification results, we
identified three major types of errors. First,
preprocessing errors create noisy data for the
model. Second, certain sense distinctions depend
heavily on global contextual information (cross-
sentence information) that is not captured by our
model. This problem is especially serious for the
verb &amp;quot;要|yao4&amp;quot;. For example, without global
contextual information, the verb can have at least
three meanings want, need or should in the same
clause, as shown in (3).
(3) 他/he 要/want/need/should 马上/at once
读完/finish reading 这本/this 书/book.
&amp;quot;He wants to/needs to/should finish reading this
book at once.&amp;quot;
Third, a target verb sometimes has specific types
of NP arguments or co-occurs with specific types
of verbs in verb compounds in certain senses. Such
information is crucial for distinguishing these
senses from others, but is not captured by the
general semantic taxonomy used here. We did
further experiments to investigate how much
improvement the model could gain by capturing
such information, as discussed in Section 5.3.
</bodyText>
<subsectionHeader confidence="0.987456">
5.3 Experiments with Lexical Sets
</subsectionHeader>
<bodyText confidence="0.970335916666667">
As discussed by Patrick Hanks (1996), certain
senses of a verb are often distinguished by very
narrowly defined semantic classes (called lexical
sets) that are specific to the meaning of that verb
sense. For example, in our case, the verb
&amp;quot;恢复|hui1fu4&amp;quot; has a sense recover in which its
direct object should be something that can be
recovered naturally. A typical set of object NPs of
the verb for this particular sense is partially listed
in (4),
(4) Lexical set for naturally recoverable things
J体力/physical strength, 身体/body, 健康 /health,
精力/mental energy, 听力/hearing, 知觉 /feeling,
记忆力/memory, ......}
Most words in this lexical set belong to the
Hownet category attribute and the top-level
category State in our taxonomy. However, even the
lower-level category attribute still contains many
other words irrelevant to the lexical set, some of
which are even typical objects of the verb for two
other senses, resume and regain, such as
&amp;quot;邦交/diplomatic relations&amp;quot; in &amp;quot;恢复/resume
邦交/diplomatic relations&amp;quot; and &amp;quot;名誉/reputation&amp;quot;
in &amp;quot;恢复/regain名誉/reputation&amp;quot;. Therefore, a
lexical set like (4) is necessary for distinguishing
the recover sense from other senses of the verb.
It has been argued that the extensional definition
of lexical sets can only be done using corpus
evidence and it cannot be done fully automatically
(Hanks, 1997). In our experiments, we use a
bootstrapping approach to obtain five lexical sets
semi-automatically for three verbs &amp;quot;出|chu1&amp;quot;,
&amp;quot;见|jian4&amp;quot; and &amp;quot;恢复|hui1fu4&amp;quot; that have both low
purity and low NMI-ratio in the first set of
experiments. 14 We first extracted candidates for
the lexical sets from the training data. For example,
we extracted all the direct objects of the verb
&amp;quot;恢复|hui1fu4&amp;quot; and all the verbs that combined
with the verb &amp;quot;出|chu1&amp;quot; to form verb compounds
from the automatically parsed training data. From
the candidates, we manually selected words to
form five initial seed sets, each of which contains
no more than ten words. A simple algorithm was
used to search for all the words that have the same
detailed Hownet semantic definitions (semantic
category plus certain supplementary information)
as the seed words. We did not use Rocling because
its semantic definitions are so general that a seed
word tends to extend to a huge set of irrelevant
words. Highly relevant words were manually
selected from all the words found by the searching
algorithm and added to the initial seed sets. The
enlarged sets were used as lexical sets.
The enhanced model first uses the lexical sets to
obtain the semantic category of the NP arguments
14 We did not include &amp;quot;要|yao4&amp;quot;, since its meaning
rarely depends on local predicate-argument structure
information.
of the three verbs. Only when the search fails does
the model resort to the general semantic taxonomy.
The model also uses the lexical sets to determine
the types of the compound verbs that contain the
target verb &amp;quot;f|chu1&amp;quot; and uses them as new
features.
Table 3 shows the model&apos;s performance on the
three verbs with or without using lexical sets. As
we see, lexical sets improves the model&apos;s
performance on all of them, especially on the verb
&amp;quot;f|chu1&amp;quot;. Although the results are still
preliminary, they nevertheless provide us hints of
how much a WSD model for Chinese verbs could
gain from lexical sets.
</bodyText>
<table confidence="0.9359132">
Verb w/o lexical sets (%) with lexical sets (%)
Purity NMI-ratio Purity NMI-ratio
f 63.61 43.24 76.50 52.81
见 72.20 22.41 77.56 34.63
恢A 65.32 15.64 69.03 19.71
</table>
<tableCaption confidence="0.996065">
Table 3. Clustering performance with and
</tableCaption>
<bodyText confidence="0.499863">
without lexical sets for three Chinese verbs
</bodyText>
<sectionHeader confidence="0.999127" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999882777777778">
We have shown that an EM clustering model
that uses rich linguistic features and a general
semantic taxonomy for Chinese nouns generally
performs well in learning sense distinctions for 12
Chinese verbs. In addition, using lexical sets
improves the model&apos;s performance on three of the
most challenging verbs.
Future work is to extend our coverage and to
apply the semantic taxonomy and the same types
of features to supervised WSD in Chinese. Since
the experimental results suggest that a general
semantic taxonomy and more constrained lexical
sets are both beneficial for WSD tasks, we will
develop automatic methods to build large-scale
semantic taxonomies and lexical sets for Chinese,
which reduce human effort as much as possible but
still ensure high quality of the obtained taxonomies
or lexical sets.
</bodyText>
<sectionHeader confidence="0.999255" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.996584142857143">
This work has been supported by an ITIC
supplement to a National Science Foundation
Grant, NSF-ITR-EIA-0205448. Any opinions,
findings, and conclusions or recommendations
expressed in this material are those of the author(s)
and do not necessarily reflect the views of the
National Science Foundation.
</bodyText>
<sectionHeader confidence="0.99795" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999178928571429">
Jinying Chen, Nianwen Xue and Martha Palmer.
2004. Using a Smoothing Maximum Entropy
Model for Chinese Nominal Entity Tagging. In
Proceedings of the 1st Int. Joint Conference on
Natural Language Processing. Hainan Island,
China.
Hoa Trang Dang, Ching-yi Chia, Martha Palmer,
and Fu-Dong Chiou. 2002. Simple Features for
Chinese Word Sense Disambiguation. In
Proceedings of COLING-2002 Nineteenth Int.
Conference on Computational Linguistics,
Taipei, Aug.24-Sept.1.
Christiane Fellbaum. 1998. WordNet - an
Electronic Lexical Database. The MIT Press,
Cambridge, Massachusetts, London.
Daniel Gildea and Daniel Jurafsky. 2002.
Automatic Labeling of Semantic Roles.
Computational Linguistics, 28(3): 245-288,
2002.
Patrick Hanks. 1996. Contextual dependencies and
lexical sets. The Int. Journal of Corpus
Linguistics, 1:1.
Patrick Hanks. 1997. Lexical sets: relevance and
probability. in B. Lewandowska-Tomaszczyk
and M. Thelen (eds.) Translation and Meaning,
Part 4, School of Translation and Interpreting,
Maastricht, The Netherlands.
Thomas Hofmann and Puzicha Jan. 1998.
Statistical models for co-occurrence data, MIT
Artificial Intelligence Lab., Technical Report
AIM-1625.
Adam Kilgarriff and Martha Palmer. 2000.
Introduction to the sepcial issue on SENSEVAL.
Computers and the Humanities, 34(1-2): 15-48.
Martha Palmer, Hoa Trang Dang, and Christiane
Fellbaum. To appear. Making fine-grained and
coarse-grained sense distinctions, both manually
and automatically. Natural Language
Engineering.
Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn
Carroll, and Franz Beil. 1998. EM-based
clustering for NLP applications. AIMS Report
4(3).Institut für Maschinelle Sprachverarbeitung.
Sabine Schulte im Walde. 2000. Clustering verbs
semantically according to their alternation
behaviour. In Proceedings of the 18th Int.
Conference on Computational Linguistics, 747-
753.
Hinrich Schütze. 1998. Automatic Word Sense
Discrimination. Computational Linguistics, 24
(1): 97-124.
Alexander Strehl. 2002. Relationship-based
Clustering and Cluster Ensembles for High-
dimensional Data Mining. Dissertation. The
University of Texas at Austin. http://www.lans.
ece.utexas.edu/~strehl/diss/.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.980644">
<title confidence="0.994005">Chinese Verb Sense Discrimination Using an EM Clustering Model with Rich Linguistic Features</title>
<author confidence="0.999247">Anying Chen</author>
<author confidence="0.999247">Martha Palmer</author>
<affiliation confidence="0.9999">Department of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.999743">Philadelphia, PA, 19104</address>
<email confidence="0.999484">jinying@linc.cis.upenn.edu</email>
<email confidence="0.999484">mpalmer@linc.cis.upenn.edu</email>
<abstract confidence="0.999737">This paper discusses the application of the Expectation-Maximization (EM) clustering algorithm to the task of Chinese verb sense discrimination. The model utilized rich linguistic features that capture predicateargument structure information of the target verbs. A semantic taxonomy for Chinese nouns, which was built semi-automatically based on two electronic Chinese semantic dictionaries, was used to provide semantic features for the model. Purity and normalized mutual information were used to evaluate the clustering performance on 12 Chinese verbs. The experimental results show that the EM clustering model can learn sense or sense group distinctions for most of the verbs successfully. We further enhanced the model with certain fine-grained semantic categories called lexical sets. Our results indicate that these lexical sets improve the model&apos;s performance for the three most challenging verbs chosen from the first set of experiments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jinying Chen</author>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Using a Smoothing Maximum Entropy Model for Chinese Nominal Entity Tagging.</title>
<date>2004</date>
<booktitle>In Proceedings of the 1st Int. Joint Conference on Natural Language Processing.</booktitle>
<location>Hainan Island, China.</location>
<contexts>
<context position="11453" citStr="Chen et al., 2004" startWordPosition="1849" endWordPosition="1852">that verb), it will not be misled by erroneous parsing information saying that the verb takes sentential complements in certain sentences. Since the corresponding feature is not included, the noisy data is filtered out. In our EM clustering model, all the features selected for a target verb are treated in the same way, as described in Section 2. 4 A Semantic Taxonomy Built Semiautomatically Examples in (1) have shown that the semantic category of the object of a verb sometimes is crucial in distinguishing certain Chinese verb senses. And our previous work on information extraction in Chinese (Chen et al., 2004) has shown that semantic features, which are more general than lexical features but still contain rich information about words, can be used to improve a model&apos;s capability of handling unknown words, thus alleviating potential sparse data problems. We have two Chinese electronic semantic dictionaries: the Hownet dictionary, which assigns 26,106 nouns to 346 semantic categories, and the Rocling dictionary, which assigns 4,474 nouns to 110 semantic categories.7 A preliminary experimental result suggests that these semantic categories might be too fine-grained for the EM clustering model (see Sect</context>
</contexts>
<marker>Chen, Xue, Palmer, 2004</marker>
<rawString>Jinying Chen, Nianwen Xue and Martha Palmer. 2004. Using a Smoothing Maximum Entropy Model for Chinese Nominal Entity Tagging. In Proceedings of the 1st Int. Joint Conference on Natural Language Processing. Hainan Island, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoa Trang Dang</author>
<author>Ching-yi Chia</author>
<author>Martha Palmer</author>
<author>Fu-Dong Chiou</author>
</authors>
<title>Simple Features for Chinese Word Sense Disambiguation.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING-2002 Nineteenth Int. Conference on Computational Linguistics,</booktitle>
<location>Taipei, Aug.24-Sept.1.</location>
<contexts>
<context position="16791" citStr="Dang et al., 2002" startWordPosition="2688" endWordPosition="2691">her parts of speech of the selected words, such as noun, preposition, conjunction and particle etc., since the parser we used has a very high accuracy in distinguishing different parts of speech of these words (&gt;98% for most of them). However, we do include senses for conjunctional and/or prepositional usage of two words, &amp;quot;到|dao4&amp;quot; and &amp;quot;为|wei4&amp;quot;, since our parser cannot distinguish the verb usage from the conjunctional or prepositional usage for the two words very well. Five verbs, the first five listed in Table 1, are both highly polysemous and difficult for a supervised word sense classifier (Dang et al., 2002). 9 In our experiments, we manually grouped the verb senses for the five verbs. The criteria for the grouping are similar to Palmer et al.&apos;s (to appear) work on English verbs, which considers both sense coherence and predicate-argument structure distinctions. Figure 2 gives an example of 9 In the supervised task, their accuracies are lower than 85%, and four of them are even lower than the baselines. Senses for &amp;quot;到|dao4&amp;quot; Sense groups for &amp;quot;到|dao4&amp;quot; 1. to go to, leave for 2. to come 3. to arrive 4. to reach a particular stage, condition, or level 5. marker for completion of activities (after a ver</context>
<context position="19030" citStr="Dang et al., 2002" startWordPosition="3077" endWordPosition="3080">e the normalized sense perplexity11 of each verb in the test data. 5.1 Evaluation Methods We use two external quality measures, purity and normalized mutual information (NMI) (Strehl. 2002) to evaluate the clustering performance. Assuming a verb has l senses, the clustering model assigns n instances of the verb into k clusters, ni is the size of the ith cluster, j n is the number of instances hand-tagged with the jth sense, and j ni is the number of instances with the jth sense in the ith cluster, purity is defined in equation (4): 10 The sense-tagged PDN data we used here are the same as in (Dang et al., 2002). 11 It is calculated as the entropy of the sense distribution of a verb in the test data divided by the largest possible entropy, i.e., log2 (the number of senses of the verb in the test data). It can be interpreted as classification accuracy when for each cluster we treat the majority of instances that have the same sense as correctly classified. The baseline purity is calculated by treating all instances for a target verb in a single cluster. The purity measure is very intuitive. In our case, since the number of clusters is preset to the number of senses, purity for verbs with two senses is</context>
</contexts>
<marker>Dang, Chia, Palmer, Chiou, 2002</marker>
<rawString>Hoa Trang Dang, Ching-yi Chia, Martha Palmer, and Fu-Dong Chiou. 2002. Simple Features for Chinese Word Sense Disambiguation. In Proceedings of COLING-2002 Nineteenth Int. Conference on Computational Linguistics, Taipei, Aug.24-Sept.1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet - an Electronic Lexical Database.</title>
<date>1998</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts, London.</location>
<contexts>
<context position="13192" citStr="Fellbaum, 1998" startWordPosition="2113" endWordPosition="2114">semantic categories defined in Hownet and Rocling into 27 top-level WordNet categories.8 The Hownet or Rocling semantic categories have English glosses. For each category gloss, the algorithm looks through the hypernyms of its first sense in WordNet and chooses the first WordNet top-level category it finds. 7 Hownet assigns multiple entries (could be different semantic categories) to polysemous words. The Rocling dictionary we used only assigns one entry (i.e., one semantic category) to each noun. 8 The 27 categories contain 25 unique beginners for noun source files in WordNet, as defined in (Fellbaum, 1998) and two higher level categories Entity and Abstraction. Figure 1. Part of the 3-level Semantic Taxonomy for Chinese Nouns (other top-level nodes are Time, Human, Animal and State) Location Top level Intermediate level Hownet/Rocling categories Event Entity Plant Artifact Document Food Money drinks, edible, meals, vegetable, ... institution, army, corporation, ... Activity ...... Process chase, cut, pass, split, cheat, ... process, BecomeLess, StateChange, disappear, .... Natural Phenomena Happening Location—Part Location Group...... The mapping obtained from step 1 needs further modification </context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet - an Electronic Lexical Database. The MIT Press, Cambridge, Massachusetts, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<pages>245--288</pages>
<contexts>
<context position="2748" citStr="Gildea and Jurafsky, 2002" startWordPosition="393" endWordPosition="396">on large unannotated corpora and evaluated on a relatively small sense-tagged corpus, it can be used to find indicative features for sense distinctions through exploring huge amount of available unannotated text data. The EM clustering algorithm (Hofmann and Puzicha, 1998) used here is an unsupervised machine learning algorithm that has been applied in many NLP tasks, such as inducing a semantically labeled lexicon and determining lexical choice in machine translation (Rooth et al., 1998), automatic acquisition of verb semantic classes (Schulte im Walde, 2000) and automatic semantic labeling (Gildea and Jurafsky, 2002). In our task, we equipped the EM clustering model with rich linguistic features that capture the predicate-argument structure information of verbs and restricted the feature set for each verb using knowledge from dictionaries. We also semiautomatically built a semantic taxonomy for Chinese nouns based on two Chinese electronic semantic dictionaries, the Hownet dictionary1 and the Rocling dictionary.2 The 7 top-level categories of this taxonomy were used as semantic features for the model. Since external knowledge is used to obtain the semantic features and guide feature selection, the model i</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic Labeling of Semantic Roles. Computational Linguistics, 28(3): 245-288, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Hanks</author>
</authors>
<title>Contextual dependencies and lexical sets. The Int.</title>
<date>1996</date>
<journal>Journal of Corpus Linguistics,</journal>
<volume>1</volume>
<contexts>
<context position="3992" citStr="Hanks, 1996" startWordPosition="576" endWordPosition="577">om this perspective; however, it does not make use of any annotated training data. Two external quality measures, purity and normalized mutual information (NMI) (Strehl. 2002), were used to evaluate the model&apos;s performance on 12 Chinese verbs. The experimental results show that rich linguistic features and the semantic taxonomy are both very useful in sense discrimination. The model generally performs well in learning sense group distinctions for difficult, highly polysemous verbs and sense distinctions for other verbs. Enhanced by certain fine-grained semantic categories called lexical sets (Hanks, 1996), the model&apos;s 1 http://www.keenage.com/. 2 A Chinese electronic dictionary liscenced from The Association for Computational Linguistics and Chinese Language Processing (ACLCLP), Nankang, Taipei, Taiwan. performance improved in a preliminary experiment for the three most difficult verbs chosen from the first set of experiments. The paper is organized as follows: we briefly introduce the EM clustering model in Section 2 and describe the features used by the model in Section 3. In Section 4, we introduce a semantic taxonomy for Chinese nouns, which is built semiautomatically for our task but can </context>
<context position="27175" citStr="Hanks (1996)" startWordPosition="4481" endWordPosition="4482">should 马上/at once 读完/finish reading 这本/this 书/book. &amp;quot;He wants to/needs to/should finish reading this book at once.&amp;quot; Third, a target verb sometimes has specific types of NP arguments or co-occurs with specific types of verbs in verb compounds in certain senses. Such information is crucial for distinguishing these senses from others, but is not captured by the general semantic taxonomy used here. We did further experiments to investigate how much improvement the model could gain by capturing such information, as discussed in Section 5.3. 5.3 Experiments with Lexical Sets As discussed by Patrick Hanks (1996), certain senses of a verb are often distinguished by very narrowly defined semantic classes (called lexical sets) that are specific to the meaning of that verb sense. For example, in our case, the verb &amp;quot;恢复|hui1fu4&amp;quot; has a sense recover in which its direct object should be something that can be recovered naturally. A typical set of object NPs of the verb for this particular sense is partially listed in (4), (4) Lexical set for naturally recoverable things J体力/physical strength, 身体/body, 健康 /health, 精力/mental energy, 听力/hearing, 知觉 /feeling, 记忆力/memory, ......} Most words in this lexical set bel</context>
</contexts>
<marker>Hanks, 1996</marker>
<rawString>Patrick Hanks. 1996. Contextual dependencies and lexical sets. The Int. Journal of Corpus Linguistics, 1:1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Hanks</author>
</authors>
<title>Lexical sets: relevance and probability.</title>
<date>1997</date>
<booktitle>Translation and Meaning, Part 4, School of Translation and Interpreting,</booktitle>
<editor>in B. Lewandowska-Tomaszczyk and M. Thelen (eds.)</editor>
<location>Maastricht, The Netherlands.</location>
<contexts>
<context position="28464" citStr="Hanks, 1997" startWordPosition="4681" endWordPosition="4682">taxonomy. However, even the lower-level category attribute still contains many other words irrelevant to the lexical set, some of which are even typical objects of the verb for two other senses, resume and regain, such as &amp;quot;邦交/diplomatic relations&amp;quot; in &amp;quot;恢复/resume 邦交/diplomatic relations&amp;quot; and &amp;quot;名誉/reputation&amp;quot; in &amp;quot;恢复/regain名誉/reputation&amp;quot;. Therefore, a lexical set like (4) is necessary for distinguishing the recover sense from other senses of the verb. It has been argued that the extensional definition of lexical sets can only be done using corpus evidence and it cannot be done fully automatically (Hanks, 1997). In our experiments, we use a bootstrapping approach to obtain five lexical sets semi-automatically for three verbs &amp;quot;出|chu1&amp;quot;, &amp;quot;见|jian4&amp;quot; and &amp;quot;恢复|hui1fu4&amp;quot; that have both low purity and low NMI-ratio in the first set of experiments. 14 We first extracted candidates for the lexical sets from the training data. For example, we extracted all the direct objects of the verb &amp;quot;恢复|hui1fu4&amp;quot; and all the verbs that combined with the verb &amp;quot;出|chu1&amp;quot; to form verb compounds from the automatically parsed training data. From the candidates, we manually selected words to form five initial seed sets, each of which </context>
</contexts>
<marker>Hanks, 1997</marker>
<rawString>Patrick Hanks. 1997. Lexical sets: relevance and probability. in B. Lewandowska-Tomaszczyk and M. Thelen (eds.) Translation and Meaning, Part 4, School of Translation and Interpreting, Maastricht, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
<author>Puzicha Jan</author>
</authors>
<title>Statistical models for co-occurrence data,</title>
<date>1998</date>
<journal>MIT Artificial Intelligence Lab.,</journal>
<tech>Technical Report AIM-1625.</tech>
<marker>Hofmann, Jan, 1998</marker>
<rawString>Thomas Hofmann and Puzicha Jan. 1998. Statistical models for co-occurrence data, MIT Artificial Intelligence Lab., Technical Report AIM-1625.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
<author>Martha Palmer</author>
</authors>
<title>Introduction to the sepcial issue on</title>
<date>2000</date>
<booktitle>SENSEVAL. Computers and the Humanities,</booktitle>
<pages>34--1</pages>
<marker>Kilgarriff, Palmer, 2000</marker>
<rawString>Adam Kilgarriff and Martha Palmer. 2000. Introduction to the sepcial issue on SENSEVAL. Computers and the Humanities, 34(1-2): 15-48.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Martha Palmer</author>
</authors>
<title>Hoa Trang Dang, and Christiane Fellbaum. To appear. Making fine-grained and coarse-grained sense distinctions, both manually and automatically. Natural Language Engineering.</title>
<marker>Palmer, </marker>
<rawString>Martha Palmer, Hoa Trang Dang, and Christiane Fellbaum. To appear. Making fine-grained and coarse-grained sense distinctions, both manually and automatically. Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
<author>Stefan Riezler</author>
<author>Detlef Prescher</author>
<author>Glenn Carroll</author>
<author>Franz Beil</author>
</authors>
<title>EM-based clustering for NLP applications. AIMS Report 4(3).Institut für Maschinelle Sprachverarbeitung.</title>
<date>1998</date>
<contexts>
<context position="2615" citStr="Rooth et al., 1998" startWordPosition="375" endWordPosition="378">n access, and to facilitating the building of large annotated corpora. In addition, since the clustering model can be trained on large unannotated corpora and evaluated on a relatively small sense-tagged corpus, it can be used to find indicative features for sense distinctions through exploring huge amount of available unannotated text data. The EM clustering algorithm (Hofmann and Puzicha, 1998) used here is an unsupervised machine learning algorithm that has been applied in many NLP tasks, such as inducing a semantically labeled lexicon and determining lexical choice in machine translation (Rooth et al., 1998), automatic acquisition of verb semantic classes (Schulte im Walde, 2000) and automatic semantic labeling (Gildea and Jurafsky, 2002). In our task, we equipped the EM clustering model with rich linguistic features that capture the predicate-argument structure information of verbs and restricted the feature set for each verb using knowledge from dictionaries. We also semiautomatically built a semantic taxonomy for Chinese nouns based on two Chinese electronic semantic dictionaries, the Hownet dictionary1 and the Rocling dictionary.2 The 7 top-level categories of this taxonomy were used as seman</context>
</contexts>
<marker>Rooth, Riezler, Prescher, Carroll, Beil, 1998</marker>
<rawString>Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Carroll, and Franz Beil. 1998. EM-based clustering for NLP applications. AIMS Report 4(3).Institut für Maschinelle Sprachverarbeitung.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Clustering verbs semantically according to their alternation behaviour.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th Int. Conference on Computational Linguistics,</booktitle>
<pages>747--753</pages>
<contexts>
<context position="2688" citStr="Walde, 2000" startWordPosition="387" endWordPosition="388">on, since the clustering model can be trained on large unannotated corpora and evaluated on a relatively small sense-tagged corpus, it can be used to find indicative features for sense distinctions through exploring huge amount of available unannotated text data. The EM clustering algorithm (Hofmann and Puzicha, 1998) used here is an unsupervised machine learning algorithm that has been applied in many NLP tasks, such as inducing a semantically labeled lexicon and determining lexical choice in machine translation (Rooth et al., 1998), automatic acquisition of verb semantic classes (Schulte im Walde, 2000) and automatic semantic labeling (Gildea and Jurafsky, 2002). In our task, we equipped the EM clustering model with rich linguistic features that capture the predicate-argument structure information of verbs and restricted the feature set for each verb using knowledge from dictionaries. We also semiautomatically built a semantic taxonomy for Chinese nouns based on two Chinese electronic semantic dictionaries, the Hownet dictionary1 and the Rocling dictionary.2 The 7 top-level categories of this taxonomy were used as semantic features for the model. Since external knowledge is used to obtain th</context>
</contexts>
<marker>Walde, 2000</marker>
<rawString>Sabine Schulte im Walde. 2000. Clustering verbs semantically according to their alternation behaviour. In Proceedings of the 18th Int. Conference on Computational Linguistics, 747-753.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Schütze</author>
</authors>
<title>Automatic Word Sense Discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<pages>97--124</pages>
<contexts>
<context position="1728" citStr="Schütze, 1998" startWordPosition="239" endWordPosition="240">odel&apos;s performance for the three most challenging verbs chosen from the first set of experiments. 1 Introduction Highly ambiguous words may lead to irrelevant document retrieval and inaccurate lexical choice in machine translation (Palmer et al., 2000), which suggests that word sense disambiguation (WSD) is beneficial and sometimes even necessary in such NLP tasks. This paper addresses WSD in Chinese through developing an Expectation-Maximization (EM) clustering model to learn Chinese verb sense distinctions. The major goal is to do sense discrimination rather than sense labeling, similar to (Schütze, 1998). The basic idea is to divide instances of a word into several clusters that have no sense labels. The instances in the same cluster are regarded as having the same meaning. Word sense discrimination can be applied to document retrieval and similar tasks in information access, and to facilitating the building of large annotated corpora. In addition, since the clustering model can be trained on large unannotated corpora and evaluated on a relatively small sense-tagged corpus, it can be used to find indicative features for sense distinctions through exploring huge amount of available unannotated</context>
</contexts>
<marker>Schütze, 1998</marker>
<rawString>Hinrich Schütze. 1998. Automatic Word Sense Discrimination. Computational Linguistics, 24 (1): 97-124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Strehl</author>
</authors>
<title>Relationship-based Clustering and Cluster Ensembles for Highdimensional Data Mining. Dissertation. The University of Texas at Austin.</title>
<date>2002</date>
<note>http://www.lans. ece.utexas.edu/~strehl/diss/.</note>
<marker>Strehl, 2002</marker>
<rawString>Alexander Strehl. 2002. Relationship-based Clustering and Cluster Ensembles for Highdimensional Data Mining. Dissertation. The University of Texas at Austin. http://www.lans. ece.utexas.edu/~strehl/diss/.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>