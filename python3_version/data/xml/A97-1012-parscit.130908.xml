<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000032">
<title confidence="0.521065">
INCREMENTAL FINITE-STATE PARSING
</title>
<author confidence="0.940855">
Salah Ait-Mokhtar, Jean-Pierre Chanod
</author>
<affiliation confidence="0.94723">
Rank Xerox Research Centre
</affiliation>
<address confidence="0.768313666666667">
6, Chemin de Maupertuis
F-38240 Meylan, France
AitOgrenoble.rxrc.xerox.com
</address>
<email confidence="0.726269">
ChanodOgrenoble.rxrc.xerox.com
</email>
<sectionHeader confidence="0.984121" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999987611111111">
This paper describes a new finite-state
shallow parser. It merges constructive and
reductionist approaches within a highly
modular architecture. Syntactic informa-
tion is added at the sentence level in an
incremental way, depending on the contex-
tual information available at a given stage.
This approach overcomes the inefficiency
of previous fully reductionist constraint-
based systems, while maintaining broad
coverage and linguistic granularity. The
implementation relies on a sequence of
networks built with the replace operator.
Given the high level of modularity, the core
grammar is easily augmented with corpus-
specific sub-grammars. The current system
is implemented for French and is being ex-
panded to new languages.
</bodyText>
<sectionHeader confidence="0.990525" genericHeader="keywords">
1 Background
</sectionHeader>
<bodyText confidence="0.999956056603774">
Previous work in finite-state parsing at sentence
level falls into two categories: the constructive ap-
proach or the reductionist approach.
The origins of the constructive approach go back
to the parser developed by Joshi (Joshi, 1996). It is
based on a lexical description of large collections of
syntactic patterns (up to several hundred thousand
rules) using subcategorisation frames (verbs + essen-
tial arguments) and local grammars (Roche, 1993).
It is, however, still unclear whether this heavily lex-
icalized method can account for all sentence struc-
tures actually found in corpora, especially due to
the proliferation of non-argumental complements in
corpus analysis.
Another constructive line of research concentrates
on identifying basic phrases such as in the FASTUS
information extraction system (Appelt et al., 1993)
or in the chunking approach proposed in (Abney,
1991; Federici et al., 1996). Attempts were made to
mark the segments with additional syntactic infor-
mation (e.g. subject or object) (Grefenstette, 1996)
using simple heuristics, for the purpose of informa-
tion retrieval, but not for robust parsing.
The reductionist approach starts from a large
number of alternative analyses that get reduced
through the application of constraints. The con-
straints may be expressed by a set of elimi-
nation rules applied in a sequence (Voutilainen,
Tapanainen, 1993) or by a set of restrictions applied
in parallel (Koskenniemi et al., 1992). In a finite-
state constraint grammar (Chanod, Tapanainen,
1996), the initial sentence network represents all
the combinations of the lexical readings associated
with each token. The acceptable readings result
from the intersection of the initial sentence network
with the constraint networks. This approach led to
very broad coverage analyzers, with good linguistic
granularity (the information is richer than in typical
chunking systems). However, the size of the interme-
diate networks resulting from the intersection of the
initial sentence network with the sets of constraints
raises serious efficiency issues.
The new approach proposed in this paper aims at
merging the constructive and the reductionist ap-
proaches, so as to maintain the coverage and gran-
ularity of the constraint-based approach at a much
lower computational cost. In particular, segments
(chunks) are defined by constraints rather than pat-
terns, in order to ensure broader coverage. At the
same time, segments are defined in a cautious way,
to ensure that clause boundaries and syntactic func-
tions (e.g. subject, object, PP-Obj) can be defined
with a high degree of accuracy.
</bodyText>
<sectionHeader confidence="0.913194" genericHeader="introduction">
2 The incremental parser
</sectionHeader>
<subsectionHeader confidence="0.971606">
2.1 Overview
</subsectionHeader>
<bodyText confidence="0.9993245">
The input to the parser is a tagged text. We cur-
rently use a modified version of the Xerox French
</bodyText>
<page confidence="0.996792">
72
</page>
<bodyText confidence="0.999787028571429">
tagger (Chanod, Tapanainen, 1995). The revisions
are meant to reduce the impact of the most frequent
errors of the tagger (e.g. errors between adjectives
and past participles), and to refine the tagset.
Each input token is assigned a single tag, generally
representing the part-of-speech and some limited
morphological information (e.g the number, but not
the gender of nouns). The sentence is initially rep-
resented by a sequence of wordform-plus-tag pairs.
The incremental parser consists of a sequence of
transducers. These transducers are compiled from
regular expressions that use finite-state calculus op-
erators, mainly the Replace operators (Karttunen,
1996). Each of these transducers adds syntactic in-
formation represented by reserved symbols (annota-
tions), such as brackets and names for segments and
syntactic functions. The application of each trans-
ducer composes it with the result of previous appli-
cations.
If the constraints stipulated in a given transducer
are not verified, the string remains unchanged. This
ensures that there is always an output string at the
end of the sequence, with possibly underspecified
segments.
Each transducer performs a specific linguistic
task. For instance, some networks identify segments
for NPs, PPs, APs (adjective phrases) and verbs,
while others are dedicated to subject or object. The
same task (e.g. subject assignment or verb segmen-
tation) may be performed by more than one trans-
ducer. The additional information provided at each
stage of the sequence is instrumental in the defini-
tion of the later stages of the sequence. Networks
are ordered in such a way that the easiest tasks are
addressed first.
</bodyText>
<subsectionHeader confidence="0.99968">
2.2 Non-monotonicity
</subsectionHeader>
<bodyText confidence="0.9992752">
The replace operators allow one not only to add in-
formation but also to modify previously computed
information. It is thus possible to reassign syntactic
markings at a later stage of the sequence. This has
two major usages:
</bodyText>
<listItem confidence="0.99950325">
• assigning some segments with a default marking
at some stage of the process in order to provide
preliminary information that is essential to the
subsequent stages; and correcting the default
marking later if the context so requires
• assigning some segments with very general
marking; and refining the marking later if the
context so permits.
</listItem>
<bodyText confidence="0.9996226">
In that sense, our incremental parser is non-
monotonic: earlier decisions may be refined or even
revised. However, all the transducers can, in prin-
ciple, be composed into a single transducer which
produces the final outcome in a single step.
</bodyText>
<subsectionHeader confidence="0.9839875">
2.3 Cautious segmentation and syntactic
marking
</subsectionHeader>
<bodyText confidence="0.999977333333333">
Each transducer defines syntactic constructions us-
ing two major operations: segmentation and syn-
tactic marking. Segmentation consists of bracket-
ing and labeling adjacent constituents that belong
to a same partial construction (e.g. a nominal or a
verbal phrase, or a more primitive/partial syntactic
chain if necessary). Segmentation also includes the
identification of clause boundaries. Syntactic mark-
ing annotates segments with syntactic functions (e.g.
subject, object, PPObj).
The two operations, segmentation and syntactic
marking, are performed throughout the sequence in
an interrelated fashion. Some segmentations depend
on previous syntactic marking and vice versa.
If a construction is not recognized at some point of
the sequence because the constraints are too strong,
it can still be recognized at a later stage, using other
linguistic statements and different background infor-
mation. This notion of delayed assignment is crucial
for robust parsing, and requires that each statement
in the sequence be linguistically cautious. Cautious
segmentation prevents us from grouping syntacti-
cally independent segments.
This is why we avoid the use of simplifying ap-
proximations that would block the possibility of per-
forming delayed assignment. For example, unlike
(Abney, 1991), we do not systematically use longest
pattern matching for segmentation. Segments are
restricted by their underlying linguistic indetermi-
nacy (e.g. post-nominal adjectives are not attached
to the immediate noun on their left, and coordinated
segments are not systematically merged, until strong
evidence is established for their linkage).
</bodyText>
<subsectionHeader confidence="0.9848095">
2.4 Incremental parsing and linguistic
description
</subsectionHeader>
<bodyText confidence="0.999693333333333">
The parsing process is incremental in the sense that
the linguistic description attached to a given trans-
ducer in the sequence:
</bodyText>
<listItem confidence="0.99975075">
• relies on the preceding sequence of transducers
• covers only some occurrences of a given linguis-
tic phenomenon
• can be revised at a later stage.
</listItem>
<bodyText confidence="0.9800335">
This has a strong impact on the linguistic char-
acter of the work. The ordering of the linguistic
</bodyText>
<page confidence="0.938664">
73
</page>
<bodyText confidence="0.977540918032787">
descriptions is in itself a matter of linguistic descrip- stage that the initial subject-verb construction was
tion: i.e. the grammarian must split the description not recognized for that particular clause (other-
of phenomena into sub-descriptions, depending on wise, the application of the verb-subject construc-
the available amount of linguistic knowledge at a tion would be blocked).
given stage of the sequence. Further down in the sequence, transducers may
This may sound like a severe disadvantage of the allow for verb-subject constructions outside the
approach, as deciding on the order of the transduc- previously considered contexts. If none of these
ers relies mostly on the grammarian&apos;s intuition. But subject-pickup constructions applies, the final sen-
we argue that this incremental view of parsing is tence string remains underspecified: the output does
instrumental in achieving robust parsing in a prin- not specify where the subject stands.
cipled fashion. When it comes to parsing, no state- It should be observed that in real texts, not only
ment is fully accurate (one may for instance find ex- may one find subjects that do not agree with the
amples where even the subject and the verb do not verb (and even in correct sentences), but one may
agree in perfectly correct French sentences). How- also find finite verbs without a subject. This is the
ever, one may construct statements which are true case for instance in elliptic technical reports (esp.
almost everywhere, that is, which are always true in failure reports) or on cigarette packs with inscrip-
some frequently occuring context. tions like Nuit gravement a /a sante&apos;.
By identifying the classes of such statements, we This is a major feature of shallow and robust
reduce the overall syntactic ambiguity and we sim- parsers (Jensen et al., 1993; Ejerhed, 1993): they
plify the task of handling less frequent phenomena. may provide partial and underspecified parses when
The less frequent phenomena apply only to segments full analyses cannot be performed; the issue of gram-
that are not covered by previous linguistic descrip- maticality is independent from the parsing process;
tion stages. the parser identifies the most likely interpretations
To some extent, this is reminiscent of the optimal- for any given input.
ity theory, in which: An additional feature of the incremental parser
• Constraints are ranked; derives from its modular architecture: one may han-
• Constraints can be violated. dle underspecified elements in a tractable fashion, by
Transducers at the top of the sequence are ranked adding optional transducers to the sequence. For in-
higher, in the sense that they apply first, thus block- stance, one may use corpus specific transducers (e.g.
ing the application of similar constructions at a later sub-grammars for technical manuals are specially
stage in the sequence. useful to block analyses that are linguistically ac-
If the constraints attached to a given transducer ceptable, but unlikely in technical manuals: a good
are not fulfilled, the transducer has no effect. The example in French is to forbid second person sin-
output annotated string is identical to the input gular imperatives in technical manuals as they are
string and the construction is bypassed. However, often ambiguous with nouns in a syntactically unde-
a bypassed construction may be reconsidered at a cidable fashion). One may also use heuristics which
later stage, using different linguistic statements. In go beyond the cautious statements of the core gram-
that sense, bypassing allows for the violation of con- mar (to get back to the example of French subjects,
straints. heuristics can identify any underspecified NP as the
2.5 An example of incremental description: subject of a finite verb if the slot is available at the
French Subjects end of the sequence). How specific grammars and
As French is typically SVO, the first transducer in heuristics can be used is obviously application de-
the sequence to mark subjects checks for NPs on the pendent.
left side of finite verbs.
Later in the sequence, other transducers allow
for subject inversion (thus violating the constraint
on subject-verb order), especially in some specific
contexts where inversion is likely to occur, e.g.
within relative or subordinate clauses, or with mo-
tion verbs. Whenever a transducer defines a verb-
subject construction, it is implicitly known at this
74
3 Architecture
The parser has four main linguistic modules, each of
them consisting of one or several sequenced trans-
ducers:
&apos;Seriously endangers your health. This example rep-
resents an interesting case of deixis and at the same time
a challenge for the POS tagger as Nuit is more likely to
be recognized as a noun (Night) than as a verb (Endan-
gers) in this particular context.
</bodyText>
<listItem confidence="0.99997875">
• Primary segmentation
• Subject tagging
• Segment expansion (Optional)
• Other syntactic functions tagging
</listItem>
<bodyText confidence="0.999928944444444">
The input text is first tagged with part-of-speech
information using the Xerox tagger. The tagger uses
44 morphosyntactic tags such as NOUN-SG for sin-
gular nouns and VERB-P3SG for verb 3rd person
singular.
The morphosyntactic tags are used to mark AP,
NP, PP and VP segments. We then use the segmen-
tation tags and some additional information (includ-
ing typography) to mark subjects which, in turn,
determine to what extent VCs (Verb Chunks) can
be expanded. Finally, other syntactic functions are
tagged within the segments.
Marking transducers are compiled from regular
expressions of the form A 0-&gt; Ti . T2 that con-
tains the left-to-right longest match replace opera-
tor 0-&gt; . Such a transducer marks in a left-to-right
fashion the maximal instances of A by adding the
bracketing strings Ti and T2.
</bodyText>
<sectionHeader confidence="0.992919" genericHeader="method">
4 Primary Segmentation
</sectionHeader>
<bodyText confidence="0.999568375">
A segment is a continuous sequence of words that are
syntactically linked to each other or to a main word
(the Head). In the primary segmentation step, we
mark segment boundaries within sentences as shown
below where NP stands for Noun Phrase, PP for
Preposition Phrase and VC for Verb Chunk (a VC
contains at least one verb and possibly some of its
arguments and modifiers).
</bodyText>
<sectionHeader confidence="0.614426" genericHeader="method">
Example:
</sectionHeader>
<bodyText confidence="0.944034135135135">
[VC [VC Lorsqu&apos; [NP on NP] tourne VC] [NP le
commutateur NP] [PP de demarrage PP] [PP sur la
position PP] [AP auxiliaire AP] , [NP
aiguille NP] retourne alors [PP a zero PP] VC]
./SENT2
All the words within a segment should be linked to
words in the same segment at the same level, ex-
cept the head. For instance, in the NP le commu-
tateur (the switch), le should be linked to commu-
tateur (the head) which, in turn, should be linked
to the verb tourne, and not to the verb retourne be-
cause the two words are not in the same segment.
The main purpose of marking segments is therefore
to constrain the particular linguistic space that de-
termines the syntactic function of a word.
2 Turning the starter switch to the auxiliary position,
the pointer will then return to zero.
As one can notice from the example above, seg-
mentation is very cautious, and structural ambiguity
inherent to modifier attachment (even postnominal
adjectives), verb arguments and coordination is not
resolved at this stage.
In order to get more robust linguistic descriptions
and networks that compile faster, segments are not
defined by marking sequences that match classical
regular expressions of the type [Det (Coord Det)
Adj* Noun], except in simple or heavily constrained
cases (APs, Infinitives, etc). Rather, we take ad-
vantage of the fact that, within a linguistic segment
introduced by some grammatical words and termi-
nated by the head, there is no attachement ambigu-
ity and therefore these words can be safely used as
segment delimiters (Bes, 1993). We first mark pos-
sible beginnings and endings of a segment and then
associate each beginning tag with an ending if some
internal constraints are satisfied. Hence, the main
steps in segmentation are:
</bodyText>
<listItem confidence="0.999938333333333">
• Tag potential beginnings and ends of a segment
• Use these temporary tags to mark the segment
• Remove the temporary tags.
</listItem>
<subsectionHeader confidence="0.926563">
4.1 AP Segmentation
</subsectionHeader>
<bodyText confidence="0.9985755">
Adjective phrases are marked by a replacement
transducer which inserts the [AP and AP] bound-
aries around any word sequence that matches the
regular expression (RE):
</bodyText>
<equation confidence="0.997067">
[ (ADVP) ADJ ( COMMA [ (ADVP) ADJ
COMMA ]+ ) ( COORD (ADVP) ADJ ) ]
</equation>
<bodyText confidence="0.808863">
ADVP stands for adverb phrase and is defined as:
</bodyText>
<sectionHeader confidence="0.528594" genericHeader="method">
[ ADV+ [[COORDICOMMA] ADV+]* ]
</sectionHeader>
<subsectionHeader confidence="0.963894">
4.2 NP Segmentation
</subsectionHeader>
<bodyText confidence="0.9997005">
Unlike APs, NPs are marked in two steps where the
basic idea is the following: we first insert a special
mark wherever a beginning of an NP is possible, i.e,
on the left of a determiner, a numeral, a pronoun,
etc. The mark is called a temporary beginning of
NP (TBeginNP). The same is done for all possible
ends of NP (TEndNP), i.e. nouns, numerals, pro-
nouns, etc. Then, using a replacement transducer,
we insert the [NP and NP] boundaries around the
longest sequence that contains at least one tempo-
rary beginning of NP followed by one temporary end
of NP:
</bodyText>
<equation confidence="0.763624">
[TBeginNP -$[TEndNP] TEndNP ] 0-&gt;
Beg inNP EndNP
</equation>
<page confidence="0.983953">
75
</page>
<figureCaption confidence="0.685532107142857">
This way, we implicitly handle complicated NPs 4.4.3 Finite Verb Segments
such as le ou les responsables (the-SG or the-PL per- Here we use the basic idea described in the NP
son(s) in charge), les trois ou quatre affaires (the marking: temporary beginnings (TBeginVC) and
three or four cases), etc. ends (TEndVC) of VC are first marked.
4.3 PP Segmentation Temporary beginnings of VCs are usually intro-
Once NP boundaries are marked, we insert on the duced by grammatical words such as qui (relative
left of any preposition a temporary PP beginning pronoun), lorsque, et (coordination) etc. However,
mark (TBeginPP = not all these words are certain VC boundaries: et
&lt;PP Avec on &lt;PP sans [NP le premier could be an NP coordinator, while que (tagged as
ministre NP3] CONJQUE by the HMM tagger) could be used in
Then the longest sequence containing at least one comparatives (e.g. plus blanc que blanc). Therefore,
TBeginPP followed by one EndNP is surrounded we use three kinds of TBeginVC to handle differ-
with the [PP and PP] boundaries using the RE: ent levels of uncertainty: a certain TBeginVC (TBe-
[TBeginPP &amp;quot;$[EndNPITVerb] EndNP] 0-&gt; ginVC1), a possible BeginVC (TBeginVC2) and an
Beg inPP ... EndPP initial TBeginVC (TBeginVCS) automatically in-
which eventually leads to: serted at the beginning of every sentence in the input
[PP Avec ou sans le premier ministre PP] text. With TBeginVCS, we assume that the sen-
4.4 VC Segmentation tence has a main finite verb, as is usually the case,
A VC (Verb Chunk) is a sequence containing at least but this is just an assumption that can be corrected
one verb (the head). It may include words or seg- later.
ments (NPs, PPs, APs or other VCs) that are pos- A temporary end of VC (TEndVC) is then in-
sibly linked as arguments or adjuncts to the verb. serted on the right of any finite verb, and the process
There are three types of VCs: infinitives, present of recognizing VCs consists of the following steps:
participle phrases and finite verb phrases. We first • Step 1: Each certain TBeginVC1 is matched
mark infinitives and present participle segments as with a TEndVC, and the sequence is marked
they are simpler than finite verb phrases—they are with [VC and VC]. The matching is applied
not recursive, they cannot contain other VCs. iteratively on the input text to handle the case
4.4.1 Infinitives of embedded clauses (arbitrarily bound to three
</figureCaption>
<table confidence="0.965380933333333">
The infinitive phrases are recognized using the reg- iterations in the current implementations).
ular expression: • Step 2: The same is done with the TBeginVCS
[ (PREPO) (NEG) (ADVP) PC* INF (inserted at the beginning of a sentence).
[(ADVP PastPartV+) 1 PastPartV*]] • Step 3: If there is still a TEndVC that was not
e.g.: sans meme prevenir (without even warning): matched in (1) or (2), then it is matched with
[VC [NP Mr NP] [NP Guilhaume NP] supprime VC] a possible TBeginVC2, if any, and the sequence
[PP des emissions PP] [VC sans meme prevenir is marked with [VC and VC].
VC] [NP leurs responsables NP] • Step 4: Any TBeginVC that was not matched
4.4.2 Present Participle Segments in (1), (2) or (3) is removed.
The present participle phrases are recognized us-
ing the regular expression:
[ (EN) (NEG) PC* PrePart
[(ADVP PastPartV+) 1 PastPartV*]]
e.g.: en denoncant (while denouncing)
[VC en donongant VC] [NP les provocations
NP] [ADJ mensongeres ADJ]
Verb Segmentation Example:
Initial input
Lorsqu&apos; [NP on NP] appuie [PP sur l&apos;
interrupteur PP] [PP de feux PP] [PP de
detresse PP] , [NP tous_les indicateurs NP] [PP
de direction PP] clignotent simultandment et
[NP un triangle NP] [AP rouge AP] clignote [PP
dans l&apos; interrupteur PP] ./SENT4
4 When the hazard warning switch is pressed all the
direction indicators will flash in unison and the switch
will flash a red triangle.
3 With or without the prime minister.
76
Temporary tagging of VC boundaries
&lt;VCS &lt;VC1 Lorsqu&apos; [NP on NP] appuie VC&gt; [PP
sur interrupteur PP] [PP de feux PP] [PP de
detresse PP] , [NP tous_les indicateurs NP] [PP
de direction PP] clignotent VC&gt; simultanement
&lt;VC2 et [NP un triangle NP] [AP rouge AP]
clignote VC&gt; [PP dans l&apos; interrupteur PP]
/SENT
VC marking
[Ix Lorsqu&apos; [NP on NP] appuie VC] [PP sur
• interrupteur PP] [PP de feux PP] [PP de
detresse PP] , [NP tous_].es indicateurs NP] [PP
de direction PP] clignotent VC] simultanement
[VC et [NP un triangle NP] [AP rouge AP]
clignote VC] [PP dans l&apos; interrupteur PP]
./SENT
</table>
<sectionHeader confidence="0.92529" genericHeader="method">
5 Marking Syntactic Functions
</sectionHeader>
<bodyText confidence="0.9934106">
The process of tagging words and segments with
syntactic functions is a good example of the
non-monotonic nature of the parser and its hy-
brid constructive-reductionnist approach. Syntac-
tic functions within non recursive segments (AP, NP
and PP) are addressed first because they are easier
to tag. Then other functions within verb segments
and at sentence level (subject, direct object, verb
modifier, etc.) are considered.
Potential subjects are marked first: an NP is a
potential subject if and only if it satisfies some ty-
pographical conditions (it should not be separated
from the verb with only one comma, etc.). This
prevents the NP Jacques, for example, from being
marked as a subject in the sentence below:
[VC [NP le president NP]/SUBJ [PP du CSA PP],
ENP Jacques NP] [NP Boutet NP] , a decide VC]
[VC de publier VC] [NP la profession NP] [PP de
foi PP] ./SENT 5
Then constraints are applied to eliminate some of the
potential subject candidates. The constraints are
mainly syntactic: they are about subject uniqueness
(unless there is a coordination), the necessary shar-
ing of the subject function among coordinated NPs,
etc. The remaining candidates are then considered
as real subjects. The other syntactic functions, such
as object, PP-Obj, verb modifier, etc. are tagged
using similar steps.
The CSA president, Jacques Boutet, decided to
present his profession of faith.
</bodyText>
<sectionHeader confidence="0.926048" genericHeader="method">
6 Expanding Verb Segments
</sectionHeader>
<bodyText confidence="0.990505590909091">
Because primary segmentation is cautious, verb seg-
ments end right after a verb in order to avoid arbi-
trary attachment of argument or adjunct segments
(NPs, PPs and APs on the right of a verb). How-
ever, experiments have shown that in some kinds of
texts, mainly in technical manuals written in a &amp;quot;con-
trolled language&amp;quot;, it is worth applying the &amp;quot;nearest
attachment&amp;quot; principle. We expand VCs to include
segments and to consider them as arguments or ad-
juncts of the VC head. This reduces structural am-
biguity in the parser output with a very small error
rate. For instance, expanding VCs in the sentence
given in the previous section leads to the following
structure:
[VC [NP le president NP]/SUBJ [PP du CSA PP],
[NP Jacques NP] [NP Boutet NP] , a decide [VC
de publier [NP la profession NP] [PP de foi PP]
VC] VC] ./SENT
Nevertheless, as this principle leads to a significant
number of incorrect attachments in the case of more
free-style texts, the VC expansion network is option-
ally applied depending on the input text.
</bodyText>
<sectionHeader confidence="0.993322" genericHeader="method">
7 Performance
</sectionHeader>
<bodyText confidence="0.99999355">
As mentioned above, the parser is implemented as
a sequence of finite state networks. The total size
of the 14 networks we currently use is about 500
KBytes of disk space. The speed of analysis is
around 150 words per second on a SPARCstation 10
machine running in a development environment that
we expect to optimize in the future. As for linguistic
performance, we conducted a preliminary evaluation
of subject recognition over a technical manual text
(2320 words, 157 sentences) and newspaper articles
from Le Monde (5872 words, 249 sentences). The
precision and recall rates were respectively 99.2%
and 97.8% in the first case, 92.6% and 82.6% in the
case of the newspaper articles. This difference in
performance is due to the fact that, on the one hand,
we used the technical manual text to develop the
parser and on the other hand, it shows much less
rich syntactic structures than the newspaper text.
We are currently conducting wider experiments to
evaluate the linguistic accuracy of the parser.
</bodyText>
<sectionHeader confidence="0.98326" genericHeader="method">
8 Parsing Samples
</sectionHeader>
<bodyText confidence="0.9997862">
Below are some parsing samples, where the output is
slightly simplified to make it more readable. In par-
ticular, morphosyntactic tags are hidden and only
the major functions and the segment boundaries ap-
pear.
</bodyText>
<page confidence="0.995373">
77
</page>
<bodyText confidence="0.335213666666667">
A l&apos;interpretation des sentiments presidentiels s&apos;a-
joute l&apos;atmosphere de surenchere politique qui
precede tout congres du Parti socialiste.
</bodyText>
<table confidence="0.983662">
[VC [PP A/PrepN&gt; l&apos;/DET&gt; interpretation
PP]/PPObj [PP des/PrepN&gt; sentiments PP]/PPObj
[AP presidentiels AP]/&lt;NM s&apos; ajoutelMV VC] [NP
l&apos;/DET&gt; atmosphere NP]/&lt;SUBJ [PP de/PrepN&gt;
surenchere PP]/PPObj [AP politique AP]/&lt;NM [VC
[NP qui NP]/SUBJ precede VC] tout/VM [NP
congres NP]/OBJ [PP du/PrepN&gt; Parti PP]/PPObj
[AP socialiste AP]/&lt;NM ./SENT
</table>
<construct confidence="0.792349409090909">
Les deputes azerbaidjanais ont adresse a moscou un
ultimatum exigeant la levee de l&apos;etat d&apos;urgence, et le
ret rait des troupes, faute de quoi ids reconsidereraient
&amp;quot; l&apos;acte d&apos;union &amp;quot; integrant l&apos;Azerbaidjan a l&apos;URSS.
[VC [NP Les/DET&gt; deputes NP]/SUBJ [AP
azerbaidjanais AP]/&lt;NM ont adresselMV VC] [PP
a/PrepN&gt; Moscou PP]/PPObj [NP un/DET&gt;
ultimatum NP]/OBJ [VC exigeant VC] [NP la/DET&gt;
levee NP]/OBJ [PP de/PrepN&gt; l&apos;/DET&gt; état
PP]/PPObj [PP d&apos;/PrepN&gt; urgence PP]/PPObj , et
[NP le/DET&gt; retrait NP]/N [PP des/PrepN&gt;
troupes PP]/PPObj , [VC faute_de_quoi [NP us
NP]/SUBJ reconsidereraient VC] [NP l&apos;/DET&gt; acte
NP]/OBJ [PP d&apos;/PrepN&gt; union PP]/PPObj [VC
integrant VC] [NP l&apos;/DET&gt; Azerbaidjan NP]/OBJ [PP
a/PrepN&gt; l&apos;/DET&gt; URSS PP]/PPObj ./SENT
A l&apos;heure, vendredi soir, on les troupes sovietiques
s&apos;appretaient a penetrer dans Bakou, la minuscule
Republique autonome du Nakhitchevan, territoire
azeri enclave en Armenie a la frontiere de l&apos;Iran,
proclamait unilateralement son independance, par
decision de son propre Soviet supreme.
</construct>
<table confidence="0.43417725">
[VC [PP A/PrepN&gt; l&apos;/DET&gt; heure PP]/PPObj , [NP
vendredi NP]/N [NP soir NP]/&lt;NM , [VC on [NP
les/DET&gt; troupes NP]/SUBJ [AP sovietiques
AP]/&lt;NM s&apos; appretaient VC] [VC A penetrer VC]
[PP dans/PrepN&gt; Bakou PP]/PPObj , [NP la/DET&gt;
[AP minuscule AP]/NM&gt; Republique NP]/SUBJ [AP
autonome AP]/&lt;NM [PP du/PrepN&gt; Nakhitchevan
PP]/PPObj , [NP territoire NP]/N [AP azeri
AP]/&lt;NM [AP enclave AP]/&lt;NM [PP en/PREP
Armenie PP]/PPObj [PP a/PrepN&gt; la/DET&gt;
frontiere PP]/PPObj [PP de/PrepN&gt; l&apos;/DET&gt; Iran
PP]/PPObj , proclamaitIMV VC] unilateralement/VM
[NP son/DET&gt; independance NP]/OBJ [PP par/PrepN&gt;
decision PP]/PPObj [PP de/PrepN&gt; son/DET&gt;
[AP propre AP]/NM&gt; Soviet PP]/PPObj
[AP supreme AP]/&lt;NM ./SENT
</table>
<sectionHeader confidence="0.980945" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.99995955">
The incremental finite-state parser presented here
merges both constructive and reductionist ap-
proaches. As a whole, the parser is constructive:
it makes incremental decisions throughout the pars-
ing process. However, at each step, linguistic con-
traints may eliminate or correct some of the previ-
ously added information. Therefore, the analysis is
non-monotonic and handles uncertainty.
The linguistic modularity of the system makes it
tractable and easy to adapt for specific texts (e.g.
technical manuals or newspaper texts). This is done
by adding specialized modules into the parsing se-
quence. This way, the core grammar is clearly
separated from optional linguistic descriptions and
heuristics.
Ongoing work includes expansion of the French
grammar, a wider evaluation, and grammar devel-
opment for new languages. We will also experiment
with our primary target applications, information
retrieval and translation assistance.
</bodyText>
<sectionHeader confidence="0.99604" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99962725">
We would like to thank Kenneth R. Beesley and
Lauri Karttunen for their editorial advice and Gre-
gory Grefenstette for the valuable discussions we had
about finite-state parsing and filtering.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9974204">
Steven P. Abney, &apos;Parsing by chunks&apos;, in Principled-
Based Parsing, eds., R. Berwick, S. Abney, and
C. Tenny, Kluwer Academic Publishers, Dor-
drecht, (1991).
Douglas E. Appelt, Jerry R. Hobbs, John Bear,
David Israel, and Mabry Tyson TASTUS: A
Finite-State Processor for Information Extraction
from Real-World Text&apos;, in Proceedings IJCA I-93,
Chambery, France, August 1993.
Gabriel G. Bes, `Axiomas y algoritmos en la de-
scripcion de las lenguas naturales&apos;, V Congreso
Argentino de Lingiiistica, Mendoza, 1993.
Jean-Pierre Chanod and Pasi Tapanainen, &apos;Tagging
French - comparing a statistical and a constraint-
based method&apos;, in Proceedings of the Seventh Con-
ference of the European Chapter of the Associa-
tion for Computational Linguistics, pp. 149-156,
Dublin, (1995).
Jean-Pierre Chanod and Pasi Tapanainen. &apos;A Ro-
bust Finite-State Parser for French&apos;, in ESSLLI&apos;96
</reference>
<page confidence="0.974396">
78
</page>
<reference confidence="0.998812466666667">
Workshop on Robust Parsing, August 1996 12-16,
Prague, Czech Republic.
Eva Ejerhed, &apos;Nouveaux courants en analyse syntax-
ique&apos;, Traitement automatique des langues, 34(1),
(1993).
Stefano Federici, Simonetta Montemagni and Vito
Pirrelli &apos;Shallow Parsing and Text Chunking. a
View on Underspecification in Syntax&apos;, in ESS-
LLI&apos;96 Workshop on Robust Parsing, August 1996
12-16, Prague, Czech Republic.
Gregory Grefenstette, &apos;Light Parsing as Finite-State
Filtering&apos;, in Proceedings ECAI &apos;96 workshop
on &amp;quot;Extended finite state models of language&amp;quot; Aug.
11-12, 1996, Budapest.
Karen Jensen, George E. Heidorn, and Stephen D.
Richardson, eds., Natural language processing:
the PLNLP approach, number 196 in The
Kluwer international series in engineering and
computer science, Kluwer Academic Publishers,
Boston/Dordrecht/London, 1993.
Aravind Joshi. &apos;A Parser from Antiquity: An Early
Application of Finite State Transducers to Natu-
ral Language Parsing&apos;, in Proceedings ECAI &apos;96
workshop on &amp;quot;Extended finite state models of lan-
guage&amp;quot;, Budapest, August 11-12, 1996, Budapest.
Lauri Karttunen, &apos;Directed replacement&apos;, in Proceed-
ings of the 34th Annual Meeting of the Association
for Computational Linguistics, Santa Cruz, USA,
(June 1996). Association for Computational Lin-
guistics.
Kimmo Koskenniemi, Pasi Tapanainen, and Atro
Voutilainen, &apos;Compiling and using finite-state syn-
tactic rules&apos;, in Proceedings of the Fourteenth
International Conference on Computational Lin-
guistics COLING-92 vol. I, pp. 156-162. Nantes,
(1992).
Emmanuel Roche, Analyse syntaxique transforma-
tionnelle du frangais par transducteurs et lexique-
grammaire, Ph.D. dissertation, Universite de
Paris 7, 1993.
Atro Voutilainen and Pasi Tapanainen, &apos;Ambigu-
ity resolution in a reductionistic parser&apos;, in Pro-
ceedings of the Sixth Conference of the Euro-
pean Chapter of the Association for Computa-
tional Linguistics, pp. 394-403, Utrecht, (1993).
</reference>
<page confidence="0.999036">
79
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000036">
<title confidence="0.97465">INCREMENTAL FINITE-STATE PARSING</title>
<author confidence="0.870633">Salah Ait-Mokhtar</author>
<author confidence="0.870633">Jean-Pierre Chanod</author>
<affiliation confidence="0.797588">Rank Xerox Research Centre</affiliation>
<address confidence="0.6975935">6, Chemin de Maupertuis F-38240 Meylan, France</address>
<email confidence="0.988296">AitOgrenoble.rxrc.xerox.comChanodOgrenoble.rxrc.xerox.com</email>
<abstract confidence="0.994307519427403">This paper describes a new finite-state shallow parser. It merges constructive and reductionist approaches within a highly modular architecture. Syntactic information is added at the sentence level in an incremental way, depending on the contextual information available at a given stage. This approach overcomes the inefficiency of previous fully reductionist constraintbased systems, while maintaining broad coverage and linguistic granularity. The implementation relies on a sequence of networks built with the replace operator. Given the high level of modularity, the core grammar is easily augmented with corpusspecific sub-grammars. The current system is implemented for French and is being expanded to new languages. 1 Background Previous work in finite-state parsing at sentence level falls into two categories: the constructive approach or the reductionist approach. The origins of the constructive approach go back to the parser developed by Joshi (Joshi, 1996). It is based on a lexical description of large collections of syntactic patterns (up to several hundred thousand rules) using subcategorisation frames (verbs + essential arguments) and local grammars (Roche, 1993). It is, however, still unclear whether this heavily lexicalized method can account for all sentence structures actually found in corpora, especially due to the proliferation of non-argumental complements in corpus analysis. Another constructive line of research concentrates on identifying basic phrases such as in the FASTUS information extraction system (Appelt et al., 1993) or in the chunking approach proposed in (Abney, 1991; Federici et al., 1996). Attempts were made to mark the segments with additional syntactic information (e.g. subject or object) (Grefenstette, 1996) using simple heuristics, for the purpose of information retrieval, but not for robust parsing. The reductionist approach starts from a large number of alternative analyses that get reduced through the application of constraints. The constraints may be expressed by a set of elimination rules applied in a sequence (Voutilainen, Tapanainen, 1993) or by a set of restrictions applied in parallel (Koskenniemi et al., 1992). In a finitestate constraint grammar (Chanod, Tapanainen, 1996), the initial sentence network represents all the combinations of the lexical readings associated with each token. The acceptable readings result from the intersection of the initial sentence network with the constraint networks. This approach led to very broad coverage analyzers, with good linguistic granularity (the information is richer than in typical chunking systems). However, the size of the intermediate networks resulting from the intersection of the initial sentence network with the sets of constraints raises serious efficiency issues. The new approach proposed in this paper aims at merging the constructive and the reductionist approaches, so as to maintain the coverage and granularity of the constraint-based approach at a much lower computational cost. In particular, segments (chunks) are defined by constraints rather than patterns, in order to ensure broader coverage. At the same time, segments are defined in a cautious way, to ensure that clause boundaries and syntactic functions (e.g. subject, object, PP-Obj) can be defined with a high degree of accuracy. 2 The incremental parser 2.1 Overview The input to the parser is a tagged text. We currently use a modified version of the Xerox French 72 tagger (Chanod, Tapanainen, 1995). The revisions are meant to reduce the impact of the most frequent errors of the tagger (e.g. errors between adjectives and past participles), and to refine the tagset. Each input token is assigned a single tag, generally representing the part-of-speech and some limited morphological information (e.g the number, but not the gender of nouns). The sentence is initially represented by a sequence of wordform-plus-tag pairs. The incremental parser consists of a sequence of transducers. These transducers are compiled from regular expressions that use finite-state calculus operators, mainly the Replace operators (Karttunen, 1996). Each of these transducers adds syntactic information represented by reserved symbols (annotations), such as brackets and names for segments and syntactic functions. The application of each transducer composes it with the result of previous applications. If the constraints stipulated in a given transducer are not verified, the string remains unchanged. This ensures that there is always an output string at the end of the sequence, with possibly underspecified segments. Each transducer performs a specific linguistic task. For instance, some networks identify segments for NPs, PPs, APs (adjective phrases) and verbs, while others are dedicated to subject or object. The same task (e.g. subject assignment or verb segmentation) may be performed by more than one transducer. The additional information provided at each stage of the sequence is instrumental in the definition of the later stages of the sequence. Networks are ordered in such a way that the easiest tasks are addressed first. 2.2 Non-monotonicity replace operators allow one not only to information but also to modify previously computed information. It is thus possible to reassign syntactic markings at a later stage of the sequence. This has two major usages: • assigning some segments with a default marking at some stage of the process in order to provide preliminary information that is essential to the subsequent stages; and correcting the default marking later if the context so requires • assigning some segments with very general marking; and refining the marking later if the context so permits. In that sense, our incremental parser is nonmonotonic: earlier decisions may be refined or even revised. However, all the transducers can, in principle, be composed into a single transducer which produces the final outcome in a single step. 2.3 Cautious segmentation and syntactic marking Each transducer defines syntactic constructions using two major operations: segmentation and syntactic marking. Segmentation consists of bracketing and labeling adjacent constituents that belong to a same partial construction (e.g. a nominal or a verbal phrase, or a more primitive/partial syntactic chain if necessary). Segmentation also includes the identification of clause boundaries. Syntactic marking annotates segments with syntactic functions (e.g. subject, object, PPObj). The two operations, segmentation and syntactic marking, are performed throughout the sequence in an interrelated fashion. Some segmentations depend on previous syntactic marking and vice versa. If a construction is not recognized at some point of the sequence because the constraints are too strong, it can still be recognized at a later stage, using other linguistic statements and different background information. This notion of delayed assignment is crucial for robust parsing, and requires that each statement in the sequence be linguistically cautious. Cautious segmentation prevents us from grouping syntactically independent segments. This is why we avoid the use of simplifying approximations that would block the possibility of performing delayed assignment. For example, unlike (Abney, 1991), we do not systematically use longest pattern matching for segmentation. Segments are restricted by their underlying linguistic indeterminacy (e.g. post-nominal adjectives are not attached the immediate noun on their left, segments are not systematically merged, until strong evidence is established for their linkage). 2.4 Incremental parsing and linguistic description The parsing process is incremental in the sense that the linguistic description attached to a given transducer in the sequence: • relies on the preceding sequence of transducers • covers only some occurrences of a given linguistic phenomenon • can be revised at a later stage. This has a strong impact on the linguistic character of the work. The ordering of the linguistic 73 descriptions is in itself a matter of linguistic descrip-tion: i.e. the grammarian must split the description of phenomena into sub-descriptions, depending on the available amount of linguistic knowledge at a given stage of the sequence. stage that the initial subject-verb construction was not recognized for that particular clause (other-wise, the application of the verb-subject construc-tion would be blocked). This may sound like a severe disadvantage of the approach, as deciding on the order of the transduc-ers relies mostly on the grammarian&apos;s intuition. But we argue that this incremental view of parsing is instrumental in achieving robust parsing in a prin-cipled fashion. When it comes to parsing, no state-ment is fully accurate (one may for instance find ex-amples where even the subject and the verb do not agree in perfectly correct French sentences). How-ever, one may construct statements which are true almost everywhere, that is, which are always true in some frequently occuring context. Further down in the sequence, transducers may allow for verb-subject constructions outside the previously considered contexts. If none of these subject-pickup constructions applies, the final sen-tence string remains underspecified: the output does not specify where the subject stands. By identifying the classes of such statements, we reduce the overall syntactic ambiguity and we sim-plify the task of handling less frequent phenomena. The less frequent phenomena apply only to segments that are not covered by previous linguistic descrip-tion stages. It should be observed that in real texts, not only may one find subjects that do not agree with the verb (and even in correct sentences), but one may also find finite verbs without a subject. This is the case for instance in elliptic technical reports (esp. failure reports) or on cigarette packs with inscriplike gravement To some extent, this is reminiscent of the optimal-ity theory, in which: This is a major feature of shallow and robust parsers (Jensen et al., 1993; Ejerhed, 1993): they may provide partial and underspecified parses when full analyses cannot be performed; the issue of gram-maticality is independent from the parsing process; the parser identifies the most likely interpretations for any given input. • Constraints are ranked; An additional feature of the incremental parser derives from its modular architecture: one may han-dle underspecified elements in a tractable fashion, by adding optional transducers to the sequence. For in-stance, one may use corpus specific transducers (e.g. sub-grammars for technical manuals are specially useful to block analyses that are linguistically ac-ceptable, but unlikely in technical manuals: a good example in French is to forbid second person sin-gular imperatives in technical manuals as they are often ambiguous with nouns in a syntactically unde-cidable fashion). One may also use heuristics which go beyond the cautious statements of the core gram-mar (to get back to the example of French subjects, heuristics can identify any underspecified NP as the subject of a finite verb if the slot is available at the end of the sequence). How specific grammars and heuristics can be used is obviously application de-pendent. • Constraints can be violated. Transducers at the top of the sequence are ranked higher, in the sense that they apply first, thus block-ing the application of similar constructions at a later stage in the sequence. If the constraints attached to a given transducer are not fulfilled, the transducer has no effect. The output annotated string is identical to the input string and the construction is bypassed. However, a bypassed construction may be reconsidered at a later stage, using different linguistic statements. In that sense, bypassing allows for the violation of con-straints. 2.5 An example of incremental description: French Subjects As French is typically SVO, the first transducer in the sequence to mark subjects checks for NPs on the left side of finite verbs. Later in the sequence, other transducers allow for subject inversion (thus violating the constraint on subject-verb order), especially in some specific contexts where inversion is likely to occur, e.g. within relative or subordinate clauses, or with mo-tion verbs. Whenever a transducer defines a verb-subject construction, it is implicitly known at this 74 3 Architecture The parser has four main linguistic modules, each of them consisting of one or several sequenced trans-ducers: your example rep-resents an interesting case of deixis and at the same time challenge for the POS tagger as more likely to recognized as a noun as a verb (Endan-gers) in this particular context. • Primary segmentation • Subject tagging • Segment expansion (Optional) • Other syntactic functions tagging The input text is first tagged with part-of-speech information using the Xerox tagger. The tagger uses 44 morphosyntactic tags such as NOUN-SG for singular nouns and VERB-P3SG for verb 3rd person singular. The morphosyntactic tags are used to mark AP, NP, PP and VP segments. We then use the segmentation tags and some additional information (including typography) to mark subjects which, in turn, determine to what extent VCs (Verb Chunks) can be expanded. Finally, other syntactic functions are tagged within the segments. Marking transducers are compiled from regular of the form Ti . T2 tains the left-to-right longest match replace operator 0-&gt; . Such a transducer marks in a left-to-right fashion the maximal instances of A by adding the bracketing strings Ti and T2. 4 Primary Segmentation A segment is a continuous sequence of words that are syntactically linked to each other or to a main word (the Head). In the primary segmentation step, we mark segment boundaries within sentences as shown below where NP stands for Noun Phrase, PP for Preposition Phrase and VC for Verb Chunk (a VC contains at least one verb and possibly some of its arguments and modifiers). Example: [VC [VC Lorsqu&apos; [NP on NP] tourne VC] [NP le commutateur NP] [PP de demarrage PP] [PP sur la position PP] [AP auxiliaire AP] , [NP NP] retourne alors [PP PP] VC] All the words within a segment should be linked to words in the same segment at the same level, exthe head. For instance, in the NP commu- (the switch), le be linked to commuhead) which, in turn, should be linked the verb tourne, and not to the verb because the two words are not in the same segment. The main purpose of marking segments is therefore to constrain the particular linguistic space that determines the syntactic function of a word. 2Turning the starter switch to the pointer will then zero. As one can notice from the example above, segmentation is very cautious, and structural ambiguity inherent to modifier attachment (even postnominal adjectives), verb arguments and coordination is not resolved at this stage. In order to get more robust linguistic descriptions and networks that compile faster, segments are not defined by marking sequences that match classical regular expressions of the type [Det (Coord Det) Adj* Noun], except in simple or heavily constrained cases (APs, Infinitives, etc). Rather, we take advantage of the fact that, within a linguistic segment introduced by some grammatical words and terminated by the head, there is no attachement ambiguity and therefore these words can be safely used as segment delimiters (Bes, 1993). We first mark possible beginnings and endings of a segment and then associate each beginning tag with an ending if some internal constraints are satisfied. Hence, the main steps in segmentation are: • Tag potential beginnings and ends of a segment • Use these temporary tags to mark the segment • Remove the temporary tags. 4.1 AP Segmentation Adjective phrases are marked by a replacement which inserts the boundaries around any word sequence that matches the regular expression (RE): [ (ADVP) ADJ ( COMMA [ (ADVP) ADJ COMMA ]+ ) ( COORD (ADVP) ADJ ) ] ADVP stands for adverb phrase and is defined as: [ ADV+ [[COORDICOMMA] ADV+]* ] 4.2 NP Segmentation Unlike APs, NPs are marked in two steps where the basic idea is the following: we first insert a special mark wherever a beginning of an NP is possible, i.e, on the left of a determiner, a numeral, a pronoun, etc. The mark is called a temporary beginning of NP (TBeginNP). The same is done for all possible ends of NP (TEndNP), i.e. nouns, numerals, pronouns, etc. Then, using a replacement transducer, insert the and NP] around the longest sequence that contains at least one temporary beginning of NP followed by one temporary end of NP: TEndNP ] Beg inNP EndNP 75 This way, we implicitly handle complicated NPs as ou les responsables (the-SG or the-PL per-son(s) in charge), les trois ou quatre affaires (the or four cases), 4.4.3 Finite Verb Segments 4.3 PP Segmentation Here we use the basic idea described in the NP marking: temporary beginnings (TBeginVC) and ends (TEndVC) of VC are first marked. Once NP boundaries are marked, we insert on the left of any preposition a temporary PP beginning mark (TBeginPP = Temporary beginnings of VCs are usually introby grammatical words such qui et etc. However, all these words are certain VC boundaries: be an NP coordinator, while as CONJQUE by the HMM tagger) could be used in (e.g. blanc que blanc). we use three kinds of TBeginVC to handle differ-ent levels of uncertainty: a certain TBeginVC (TBe-ginVC1), a possible BeginVC (TBeginVC2) and an initial TBeginVC (TBeginVCS) automatically in-serted at the beginning of every sentence in the input text. With TBeginVCS, we assume that the senhas a main finite verb, as is usually the but this is just an assumption that can be corrected later. &lt;PP Avec on &lt;PP sans [NP le premier A temporary end of VC (TEndVC) is then in-serted on the right of any finite verb, and the process of recognizing VCs consists of the following steps: Then the longest sequence containing at least one TBeginPP followed by one EndNP is surrounded with the [PP and PP] boundaries using the RE: • Step 1: Each certain TBeginVC1 is matched with a TEndVC, and the sequence is marked matching is applied iteratively on the input text to handle the case of embedded clauses (arbitrarily bound to three iterations in the current implementations). [TBeginPP &amp;quot;$[EndNPITVerb] EndNP] 0-&gt; Beg inPP ... EndPP • Step 2: The same is done with the TBeginVCS (inserted at the beginning of a sentence). which eventually leads to: • Step 3: If there is still a TEndVC that was not matched in (1) or (2), then it is matched with a possible TBeginVC2, if any, and the sequence is marked with [VC and VC]. [PP Avec ou sans le premier ministre PP] 4.4 VC Segmentation • Step 4: Any TBeginVC that was not matched in (1), (2) or (3) is removed. VC (Verb Chunk) a sequence containing at least one verb (the head). It may include words or seg-ments (NPs, PPs, APs or other VCs) that are pos-sibly linked as arguments or adjuncts to the verb. There are three types of VCs: infinitives, present participle phrases and finite verb phrases. We first mark infinitives and present participle segments as they are simpler than finite verb phrases—they are not recursive, they cannot contain other VCs. 4.4.1 Infinitives The infinitive phrases are recognized using the reg-ular expression: [ (PREPO) (NEG) (ADVP) PC* INF [(ADVP PastPartV+) 1 PastPartV*]] meme even warning): [VC [NP Mr NP] [NP Guilhaume NP] supprime VC] [PP des emissions PP] [VC sans meme prevenir VC] [NP leurs responsables NP] 4.4.2 Present Participle Segments The present participle phrases are recognized us-ing the regular expression: [ (EN) (NEG) PC* PrePart [(ADVP PastPartV+) 1 PastPartV*]] denoncant (while denouncing) [VC en donongant VC] [NP les provocations NP] [ADJ mensongeres ADJ] Verb Segmentation Example: Initial input Lorsqu&apos; [NP on NP] appuie [PP sur l&apos; interrupteur PP] [PP de feux PP] [PP de PP] , [NP NP] [PP de direction PP] clignotent simultandment et [NP un triangle NP] [AP rouge AP] clignote [PP l&apos; interrupteur PP] 4When the hazard warning switch is pressed all the indicators will flash in unison switch flash a triangle. 3With the minister. 76 Temporary tagging of VC boundaries &lt;VCS &lt;VC1 Lorsqu&apos; [NP on NP] appuie VC&gt; [PP sur interrupteur PP] [PP de feux PP] [PP de detresse PP] , [NP tous_les indicateurs NP] [PP de direction PP] clignotent VC&gt; simultanement &lt;VC2 et [NP un triangle NP] [AP rouge AP] clignote VC&gt; [PP dans l&apos; interrupteur PP] /SENT VC marking [NP on NP] appuie VC] [PP sur PP] [PP de feux PP] [PP de detresse PP] , [NP tous_].es indicateurs NP] [PP de direction PP] clignotent VC] simultanement [VC et [NP un triangle NP] [AP rouge AP] clignote VC] [PP dans l&apos; interrupteur PP] ./SENT 5 Marking Syntactic Functions The process of tagging words and segments with syntactic functions is a good example of the non-monotonic nature of the parser and its hybrid constructive-reductionnist approach. Syntactic functions within non recursive segments (AP, NP and PP) are addressed first because they are easier to tag. Then other functions within verb segments and at sentence level (subject, direct object, verb modifier, etc.) are considered. Potential subjects are marked first: an NP is a potential subject if and only if it satisfies some typographical conditions (it should not be separated from the verb with only one comma, etc.). This the NP example, from being marked as a subject in the sentence below: [NP president NP]/SUBJ [PP du CSA PP], ENP Jacques NP] [NP Boutet NP] , a decide VC] [VC de publier VC] [NP la profession NP] [PP de PP] ./SENT 5 Then constraints are applied to eliminate some of the potential subject candidates. The constraints are mainly syntactic: they are about subject uniqueness (unless there is a coordination), the necessary sharing of the subject function among coordinated NPs, etc. The remaining candidates are then considered as real subjects. The other syntactic functions, such as object, PP-Obj, verb modifier, etc. are tagged using similar steps. The CSA president, Jacques Boutet, decided to present his profession of faith. 6 Expanding Verb Segments Because primary segmentation is cautious, verb segments end right after a verb in order to avoid arbitrary attachment of argument or adjunct segments (NPs, PPs and APs on the right of a verb). However, experiments have shown that in some kinds of texts, mainly in technical manuals written in a &amp;quot;controlled language&amp;quot;, it is worth applying the &amp;quot;nearest attachment&amp;quot; principle. We expand VCs to include segments and to consider them as arguments or adjuncts of the VC head. This reduces structural ambiguity in the parser output with a very small error rate. For instance, expanding VCs in the sentence given in the previous section leads to the following structure: president NP]/SUBJ [PP du CSA PP], [NP Jacques NP] [NP Boutet NP] , a decide [VC de publier [NP la profession NP] [PP de foi PP] VC] VC] ./SENT Nevertheless, as this principle leads to a significant number of incorrect attachments in the case of more free-style texts, the VC expansion network is optionally applied depending on the input text. 7 Performance As mentioned above, the parser is implemented as a sequence of finite state networks. The total size of the 14 networks we currently use is about 500 KBytes of disk space. The speed of analysis is around 150 words per second on a SPARCstation 10 machine running in a development environment that we expect to optimize in the future. As for linguistic performance, we conducted a preliminary evaluation of subject recognition over a technical manual text (2320 words, 157 sentences) and newspaper articles Monde words, 249 sentences). The precision and recall rates were respectively 99.2% and 97.8% in the first case, 92.6% and 82.6% in the case of the newspaper articles. This difference in performance is due to the fact that, on the one hand, we used the technical manual text to develop the parser and on the other hand, it shows much less rich syntactic structures than the newspaper text. We are currently conducting wider experiments to evaluate the linguistic accuracy of the parser. 8 Parsing Samples Below are some parsing samples, where the output is slightly simplified to make it more readable. In particular, morphosyntactic tags are hidden and only the major functions and the segment boundaries appear. 77 A l&apos;interpretation des sentiments presidentiels s&apos;ajoute l&apos;atmosphere de surenchere politique qui precede tout congres du Parti socialiste. [VC [PP A/PrepN&gt; l&apos;/DET&gt; interpretation PP]/PPObj [PP des/PrepN&gt; sentiments PP]/PPObj [AP presidentiels AP]/&lt;NM s&apos; ajoutelMV VC] [NP l&apos;/DET&gt; atmosphere NP]/&lt;SUBJ [PP de/PrepN&gt; surenchere PP]/PPObj [AP politique AP]/&lt;NM [VC [NP qui NP]/SUBJ precede VC] tout/VM [NP congres NP]/OBJ [PP du/PrepN&gt; Parti PP]/PPObj [AP socialiste AP]/&lt;NM ./SENT deputes azerbaidjanais ont adresse a ultimatum exigeant la levee de l&apos;etat d&apos;urgence, et le ret rait des troupes, faute de quoi ids reconsidereraient &amp;quot; l&apos;acte d&apos;union &amp;quot; integrant l&apos;Azerbaidjan a l&apos;URSS. [VC [NP Les/DET&gt; deputes NP]/SUBJ [AP azerbaidjanais AP]/&lt;NM ont adresselMV VC] [PP a/PrepN&gt; Moscou PP]/PPObj [NP un/DET&gt; ultimatum NP]/OBJ [VC exigeant VC] [NP la/DET&gt; levee NP]/OBJ [PP de/PrepN&gt; l&apos;/DET&gt; état PP]/PPObj [PP d&apos;/PrepN&gt; urgence PP]/PPObj , et [NP le/DET&gt; retrait NP]/N [PP des/PrepN&gt; PP]/PPObj , [VC faute_de_quoi [NP NP]/SUBJ reconsidereraient VC] [NP l&apos;/DET&gt; acte NP]/OBJ [PP d&apos;/PrepN&gt; union PP]/PPObj [VC integrant VC] [NP l&apos;/DET&gt; Azerbaidjan NP]/OBJ [PP a/PrepN&gt; l&apos;/DET&gt; URSS PP]/PPObj ./SENT A l&apos;heure, vendredi soir, on les troupes sovietiques s&apos;appretaient a penetrer dans Bakou, la minuscule autonome territoire azeri enclave en Armenie a la frontiere de l&apos;Iran, proclamait unilateralement son independance, par decision de son propre Soviet supreme. [VC [PP A/PrepN&gt; l&apos;/DET&gt; heure PP]/PPObj , [NP soir NP]/&lt;NM , [VC les/DET&gt; troupes NP]/SUBJ [AP sovietiques AP]/&lt;NM s&apos; appretaient VC] [VC A penetrer VC] [PP dans/PrepN&gt; Bakou PP]/PPObj , [NP la/DET&gt; [AP minuscule AP]/NM&gt; Republique NP]/SUBJ [AP autonome AP]/&lt;NM [PP du/PrepN&gt; Nakhitchevan PP]/PPObj , [NP territoire NP]/N [AP azeri AP]/&lt;NM [AP enclave AP]/&lt;NM [PP en/PREP Armenie PP]/PPObj [PP a/PrepN&gt; la/DET&gt; frontiere PP]/PPObj [PP de/PrepN&gt; l&apos;/DET&gt; Iran PP]/PPObj , proclamaitIMV VC] unilateralement/VM [NP son/DET&gt; independance NP]/OBJ [PP par/PrepN&gt; PP]/PPObj [PP son/DET&gt; [AP propre AP]/NM&gt; Soviet PP]/PPObj [AP supreme AP]/&lt;NM ./SENT 9 Conclusion The incremental finite-state parser presented here merges both constructive and reductionist approaches. As a whole, the parser is constructive: it makes incremental decisions throughout the parsing process. However, at each step, linguistic contraints may eliminate or correct some of the previously added information. Therefore, the analysis is non-monotonic and handles uncertainty. The linguistic modularity of the system makes it tractable and easy to adapt for specific texts (e.g. technical manuals or newspaper texts). This is done by adding specialized modules into the parsing sequence. This way, the core grammar is clearly separated from optional linguistic descriptions and heuristics. Ongoing work includes expansion of the French grammar, a wider evaluation, and grammar development for new languages. We will also experiment with our primary target applications, information retrieval and translation assistance. Acknowledgements We would like to thank Kenneth R. Beesley and Lauri Karttunen for their editorial advice and Gregory Grefenstette for the valuable discussions we had about finite-state parsing and filtering.</abstract>
<note confidence="0.771352438596491">References P. Abney, &apos;Parsing by chunks&apos;, in Principled- Parsing, R. Berwick, S. Abney, and C. Tenny, Kluwer Academic Publishers, Dordrecht, (1991). Douglas E. Appelt, Jerry R. Hobbs, John Bear, David Israel, and Mabry Tyson TASTUS: A Finite-State Processor for Information Extraction Real-World Text&apos;, in IJCA Chambery, France, August 1993. Gabriel G. Bes, `Axiomas y algoritmos en la descripcion de las lenguas naturales&apos;, V Congreso Argentino de Lingiiistica, Mendoza, 1993. Jean-Pierre Chanod and Pasi Tapanainen, &apos;Tagging French comparing a statistical and a constraintmethod&apos;, in of the Seventh Conference of the European Chapter of the Associafor Computational Linguistics, Dublin, (1995). Jean-Pierre Chanod and Pasi Tapanainen. &apos;A Ro- Finite-State Parser for French&apos;, in 78 on Robust Parsing, 1996 12-16, Prague, Czech Republic. Eva Ejerhed, &apos;Nouveaux courants en analyse syntaxautomatique des langues, (1993). Stefano Federici, Simonetta Montemagni and Vito Pirrelli &apos;Shallow Parsing and Text Chunking. a on Underspecification in Syntax&apos;, in ESS- Workshop on Robust Parsing, 1996 12-16, Prague, Czech Republic. Gregory Grefenstette, &apos;Light Parsing as Finite-State in ECAI &apos;96 workshop &amp;quot;Extended finite state models of language&amp;quot; 11-12, 1996, Budapest. Karen Jensen, George E. Heidorn, and Stephen D. eds., language processing: PLNLP approach, 196 in The Kluwer international series in engineering and computer science, Kluwer Academic Publishers, Boston/Dordrecht/London, 1993. Aravind Joshi. &apos;A Parser from Antiquity: An Early Application of Finite State Transducers to Natu- Language Parsing&apos;, in ECAI &apos;96 workshop on &amp;quot;Extended finite state models of lan- August 11-12, 1996, Budapest. Karttunen, &apos;Directed replacement&apos;, in Proceedof the 34th of the Association Computational Linguistics, Cruz, USA, (June 1996). Association for Computational Linguistics. Kimmo Koskenniemi, Pasi Tapanainen, and Atro Voutilainen, &apos;Compiling and using finite-state synrules&apos;, in of the Fourteenth International Conference on Computational Lin- COLING-92 156-162. Nantes,</note>
<abstract confidence="0.68921575">(1992). Roche, syntaxique transformationnelle du frangais par transducteurs et lexiquedissertation, Universite de</abstract>
<note confidence="0.816400428571429">Paris 7, 1993. Atro Voutilainen and Pasi Tapanainen, &apos;Ambiguresolution in a reductionistic parser&apos;, in Proceedings of the Sixth Conference of the European Chapter of the Association for Computa- Linguistics, 394-403, Utrecht, (1993). 79</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven P Abney</author>
</authors>
<title>Parsing by chunks&apos;,</title>
<date>1991</date>
<editor>in PrincipledBased Parsing, eds., R. Berwick, S. Abney, and C. Tenny,</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht,</location>
<contexts>
<context position="1829" citStr="Abney, 1991" startWordPosition="259" endWordPosition="260">tion of large collections of syntactic patterns (up to several hundred thousand rules) using subcategorisation frames (verbs + essential arguments) and local grammars (Roche, 1993). It is, however, still unclear whether this heavily lexicalized method can account for all sentence structures actually found in corpora, especially due to the proliferation of non-argumental complements in corpus analysis. Another constructive line of research concentrates on identifying basic phrases such as in the FASTUS information extraction system (Appelt et al., 1993) or in the chunking approach proposed in (Abney, 1991; Federici et al., 1996). Attempts were made to mark the segments with additional syntactic information (e.g. subject or object) (Grefenstette, 1996) using simple heuristics, for the purpose of information retrieval, but not for robust parsing. The reductionist approach starts from a large number of alternative analyses that get reduced through the application of constraints. The constraints may be expressed by a set of elimination rules applied in a sequence (Voutilainen, Tapanainen, 1993) or by a set of restrictions applied in parallel (Koskenniemi et al., 1992). In a finitestate constraint </context>
<context position="7508" citStr="Abney, 1991" startWordPosition="1133" endWordPosition="1134">sa. If a construction is not recognized at some point of the sequence because the constraints are too strong, it can still be recognized at a later stage, using other linguistic statements and different background information. This notion of delayed assignment is crucial for robust parsing, and requires that each statement in the sequence be linguistically cautious. Cautious segmentation prevents us from grouping syntactically independent segments. This is why we avoid the use of simplifying approximations that would block the possibility of performing delayed assignment. For example, unlike (Abney, 1991), we do not systematically use longest pattern matching for segmentation. Segments are restricted by their underlying linguistic indeterminacy (e.g. post-nominal adjectives are not attached to the immediate noun on their left, and coordinated segments are not systematically merged, until strong evidence is established for their linkage). 2.4 Incremental parsing and linguistic description The parsing process is incremental in the sense that the linguistic description attached to a given transducer in the sequence: • relies on the preceding sequence of transducers • covers only some occurrences </context>
</contexts>
<marker>Abney, 1991</marker>
<rawString>Steven P. Abney, &apos;Parsing by chunks&apos;, in PrincipledBased Parsing, eds., R. Berwick, S. Abney, and C. Tenny, Kluwer Academic Publishers, Dordrecht, (1991).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas E Appelt</author>
<author>Jerry R Hobbs</author>
<author>John Bear</author>
<author>David Israel</author>
<author>Mabry Tyson</author>
</authors>
<title>TASTUS: A Finite-State Processor for Information Extraction from Real-World Text&apos;,</title>
<date>1993</date>
<booktitle>in Proceedings IJCA I-93,</booktitle>
<location>Chambery, France,</location>
<contexts>
<context position="1776" citStr="Appelt et al., 1993" startWordPosition="248" endWordPosition="251">loped by Joshi (Joshi, 1996). It is based on a lexical description of large collections of syntactic patterns (up to several hundred thousand rules) using subcategorisation frames (verbs + essential arguments) and local grammars (Roche, 1993). It is, however, still unclear whether this heavily lexicalized method can account for all sentence structures actually found in corpora, especially due to the proliferation of non-argumental complements in corpus analysis. Another constructive line of research concentrates on identifying basic phrases such as in the FASTUS information extraction system (Appelt et al., 1993) or in the chunking approach proposed in (Abney, 1991; Federici et al., 1996). Attempts were made to mark the segments with additional syntactic information (e.g. subject or object) (Grefenstette, 1996) using simple heuristics, for the purpose of information retrieval, but not for robust parsing. The reductionist approach starts from a large number of alternative analyses that get reduced through the application of constraints. The constraints may be expressed by a set of elimination rules applied in a sequence (Voutilainen, Tapanainen, 1993) or by a set of restrictions applied in parallel (Ko</context>
</contexts>
<marker>Appelt, Hobbs, Bear, Israel, Tyson, 1993</marker>
<rawString>Douglas E. Appelt, Jerry R. Hobbs, John Bear, David Israel, and Mabry Tyson TASTUS: A Finite-State Processor for Information Extraction from Real-World Text&apos;, in Proceedings IJCA I-93, Chambery, France, August 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel G Bes</author>
</authors>
<title>Axiomas y algoritmos en la descripcion de las lenguas naturales&apos;, V Congreso Argentino de Lingiiistica,</title>
<date>1993</date>
<location>Mendoza,</location>
<contexts>
<context position="15907" citStr="Bes, 1993" startWordPosition="2502" endWordPosition="2503">adjectives), verb arguments and coordination is not resolved at this stage. In order to get more robust linguistic descriptions and networks that compile faster, segments are not defined by marking sequences that match classical regular expressions of the type [Det (Coord Det) Adj* Noun], except in simple or heavily constrained cases (APs, Infinitives, etc). Rather, we take advantage of the fact that, within a linguistic segment introduced by some grammatical words and terminated by the head, there is no attachement ambiguity and therefore these words can be safely used as segment delimiters (Bes, 1993). We first mark possible beginnings and endings of a segment and then associate each beginning tag with an ending if some internal constraints are satisfied. Hence, the main steps in segmentation are: • Tag potential beginnings and ends of a segment • Use these temporary tags to mark the segment • Remove the temporary tags. 4.1 AP Segmentation Adjective phrases are marked by a replacement transducer which inserts the [AP and AP] boundaries around any word sequence that matches the regular expression (RE): [ (ADVP) ADJ ( COMMA [ (ADVP) ADJ COMMA ]+ ) ( COORD (ADVP) ADJ ) ] ADVP stands for adver</context>
</contexts>
<marker>Bes, 1993</marker>
<rawString>Gabriel G. Bes, `Axiomas y algoritmos en la descripcion de las lenguas naturales&apos;, V Congreso Argentino de Lingiiistica, Mendoza, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Pierre Chanod</author>
<author>Pasi Tapanainen</author>
</authors>
<title>Tagging French - comparing a statistical and a constraintbased method&apos;,</title>
<date>1995</date>
<booktitle>in Proceedings of the Seventh Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>149--156</pages>
<location>Dublin,</location>
<marker>Chanod, Tapanainen, 1995</marker>
<rawString>Jean-Pierre Chanod and Pasi Tapanainen, &apos;Tagging French - comparing a statistical and a constraintbased method&apos;, in Proceedings of the Seventh Conference of the European Chapter of the Association for Computational Linguistics, pp. 149-156, Dublin, (1995).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jean-Pierre Chanod</author>
<author>Pasi Tapanainen</author>
</authors>
<title>A Robust Finite-State Parser for French&apos;,</title>
<note>in ESSLLI&apos;96</note>
<marker>Chanod, Tapanainen, </marker>
<rawString>Jean-Pierre Chanod and Pasi Tapanainen. &apos;A Robust Finite-State Parser for French&apos;, in ESSLLI&apos;96</rawString>
</citation>
<citation valid="true">
<date>1996</date>
<booktitle>Workshop on Robust Parsing,</booktitle>
<pages>12--16</pages>
<location>Prague, Czech Republic.</location>
<marker>1996</marker>
<rawString>Workshop on Robust Parsing, August 1996 12-16, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva Ejerhed</author>
</authors>
<title>Nouveaux courants en analyse syntaxique&apos;, Traitement automatique des langues,</title>
<date>1993</date>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="10115" citStr="Ejerhed, 1993" startWordPosition="1547" endWordPosition="1548">n in correct sentences), but one may agree in perfectly correct French sentences). How- also find finite verbs without a subject. This is the ever, one may construct statements which are true case for instance in elliptic technical reports (esp. almost everywhere, that is, which are always true in failure reports) or on cigarette packs with inscripsome frequently occuring context. tions like Nuit gravement a /a sante&apos;. By identifying the classes of such statements, we This is a major feature of shallow and robust reduce the overall syntactic ambiguity and we sim- parsers (Jensen et al., 1993; Ejerhed, 1993): they plify the task of handling less frequent phenomena. may provide partial and underspecified parses when The less frequent phenomena apply only to segments full analyses cannot be performed; the issue of gramthat are not covered by previous linguistic descrip- maticality is independent from the parsing process; tion stages. the parser identifies the most likely interpretations To some extent, this is reminiscent of the optimal- for any given input. ity theory, in which: An additional feature of the incremental parser • Constraints are ranked; derives from its modular architecture: one may</context>
</contexts>
<marker>Ejerhed, 1993</marker>
<rawString>Eva Ejerhed, &apos;Nouveaux courants en analyse syntaxique&apos;, Traitement automatique des langues, 34(1), (1993).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Federici</author>
</authors>
<title>Simonetta Montemagni and Vito Pirrelli &apos;Shallow Parsing and Text Chunking. a View on Underspecification in Syntax&apos;,</title>
<date>1996</date>
<booktitle>in ESSLLI&apos;96 Workshop on Robust Parsing,</booktitle>
<pages>12--16</pages>
<location>Prague, Czech Republic.</location>
<marker>Federici, 1996</marker>
<rawString>Stefano Federici, Simonetta Montemagni and Vito Pirrelli &apos;Shallow Parsing and Text Chunking. a View on Underspecification in Syntax&apos;, in ESSLLI&apos;96 Workshop on Robust Parsing, August 1996 12-16, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>Light Parsing as Finite-State Filtering&apos;,</title>
<date>1996</date>
<booktitle>in Proceedings ECAI &apos;96</booktitle>
<location>Budapest.</location>
<contexts>
<context position="1978" citStr="Grefenstette, 1996" startWordPosition="281" endWordPosition="282">ments) and local grammars (Roche, 1993). It is, however, still unclear whether this heavily lexicalized method can account for all sentence structures actually found in corpora, especially due to the proliferation of non-argumental complements in corpus analysis. Another constructive line of research concentrates on identifying basic phrases such as in the FASTUS information extraction system (Appelt et al., 1993) or in the chunking approach proposed in (Abney, 1991; Federici et al., 1996). Attempts were made to mark the segments with additional syntactic information (e.g. subject or object) (Grefenstette, 1996) using simple heuristics, for the purpose of information retrieval, but not for robust parsing. The reductionist approach starts from a large number of alternative analyses that get reduced through the application of constraints. The constraints may be expressed by a set of elimination rules applied in a sequence (Voutilainen, Tapanainen, 1993) or by a set of restrictions applied in parallel (Koskenniemi et al., 1992). In a finitestate constraint grammar (Chanod, Tapanainen, 1996), the initial sentence network represents all the combinations of the lexical readings associated with each token. </context>
</contexts>
<marker>Grefenstette, 1996</marker>
<rawString>Gregory Grefenstette, &apos;Light Parsing as Finite-State Filtering&apos;, in Proceedings ECAI &apos;96 workshop on &amp;quot;Extended finite state models of language&amp;quot; Aug. 11-12, 1996, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Jensen</author>
<author>George E Heidorn</author>
<author>D Stephen</author>
</authors>
<date>1993</date>
<booktitle>Natural language processing: the PLNLP approach, number 196 in The Kluwer international series in engineering and computer science,</booktitle>
<editor>Richardson, eds.,</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Boston/Dordrecht/London,</location>
<contexts>
<context position="10099" citStr="Jensen et al., 1993" startWordPosition="1543" endWordPosition="1546"> do not verb (and even in correct sentences), but one may agree in perfectly correct French sentences). How- also find finite verbs without a subject. This is the ever, one may construct statements which are true case for instance in elliptic technical reports (esp. almost everywhere, that is, which are always true in failure reports) or on cigarette packs with inscripsome frequently occuring context. tions like Nuit gravement a /a sante&apos;. By identifying the classes of such statements, we This is a major feature of shallow and robust reduce the overall syntactic ambiguity and we sim- parsers (Jensen et al., 1993; Ejerhed, 1993): they plify the task of handling less frequent phenomena. may provide partial and underspecified parses when The less frequent phenomena apply only to segments full analyses cannot be performed; the issue of gramthat are not covered by previous linguistic descrip- maticality is independent from the parsing process; tion stages. the parser identifies the most likely interpretations To some extent, this is reminiscent of the optimal- for any given input. ity theory, in which: An additional feature of the incremental parser • Constraints are ranked; derives from its modular archi</context>
</contexts>
<marker>Jensen, Heidorn, Stephen, 1993</marker>
<rawString>Karen Jensen, George E. Heidorn, and Stephen D. Richardson, eds., Natural language processing: the PLNLP approach, number 196 in The Kluwer international series in engineering and computer science, Kluwer Academic Publishers, Boston/Dordrecht/London, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind Joshi</author>
</authors>
<title>A Parser from Antiquity: An Early Application of Finite State Transducers to Natural Language Parsing&apos;,</title>
<date>1996</date>
<booktitle>in Proceedings ECAI &apos;96</booktitle>
<location>Budapest,</location>
<contexts>
<context position="1184" citStr="Joshi, 1996" startWordPosition="163" endWordPosition="164">t constraintbased systems, while maintaining broad coverage and linguistic granularity. The implementation relies on a sequence of networks built with the replace operator. Given the high level of modularity, the core grammar is easily augmented with corpusspecific sub-grammars. The current system is implemented for French and is being expanded to new languages. 1 Background Previous work in finite-state parsing at sentence level falls into two categories: the constructive approach or the reductionist approach. The origins of the constructive approach go back to the parser developed by Joshi (Joshi, 1996). It is based on a lexical description of large collections of syntactic patterns (up to several hundred thousand rules) using subcategorisation frames (verbs + essential arguments) and local grammars (Roche, 1993). It is, however, still unclear whether this heavily lexicalized method can account for all sentence structures actually found in corpora, especially due to the proliferation of non-argumental complements in corpus analysis. Another constructive line of research concentrates on identifying basic phrases such as in the FASTUS information extraction system (Appelt et al., 1993) or in t</context>
</contexts>
<marker>Joshi, 1996</marker>
<rawString>Aravind Joshi. &apos;A Parser from Antiquity: An Early Application of Finite State Transducers to Natural Language Parsing&apos;, in Proceedings ECAI &apos;96 workshop on &amp;quot;Extended finite state models of language&amp;quot;, Budapest, August 11-12, 1996, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>Directed replacement&apos;,</title>
<date>1996</date>
<booktitle>in Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Santa Cruz, USA,</location>
<contexts>
<context position="4351" citStr="Karttunen, 1996" startWordPosition="648" endWordPosition="649"> are meant to reduce the impact of the most frequent errors of the tagger (e.g. errors between adjectives and past participles), and to refine the tagset. Each input token is assigned a single tag, generally representing the part-of-speech and some limited morphological information (e.g the number, but not the gender of nouns). The sentence is initially represented by a sequence of wordform-plus-tag pairs. The incremental parser consists of a sequence of transducers. These transducers are compiled from regular expressions that use finite-state calculus operators, mainly the Replace operators (Karttunen, 1996). Each of these transducers adds syntactic information represented by reserved symbols (annotations), such as brackets and names for segments and syntactic functions. The application of each transducer composes it with the result of previous applications. If the constraints stipulated in a given transducer are not verified, the string remains unchanged. This ensures that there is always an output string at the end of the sequence, with possibly underspecified segments. Each transducer performs a specific linguistic task. For instance, some networks identify segments for NPs, PPs, APs (adjectiv</context>
</contexts>
<marker>Karttunen, 1996</marker>
<rawString>Lauri Karttunen, &apos;Directed replacement&apos;, in Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, Santa Cruz, USA, (June 1996). Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kimmo Koskenniemi</author>
</authors>
<title>Pasi Tapanainen, and Atro Voutilainen, &apos;Compiling and using finite-state syntactic rules&apos;,</title>
<date>1992</date>
<booktitle>in Proceedings of the Fourteenth International Conference on Computational Linguistics COLING-92</booktitle>
<volume>vol. I,</volume>
<pages>156--162</pages>
<location>Nantes,</location>
<marker>Koskenniemi, 1992</marker>
<rawString>Kimmo Koskenniemi, Pasi Tapanainen, and Atro Voutilainen, &apos;Compiling and using finite-state syntactic rules&apos;, in Proceedings of the Fourteenth International Conference on Computational Linguistics COLING-92 vol. I, pp. 156-162. Nantes, (1992).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Roche</author>
</authors>
<title>Analyse syntaxique transformationnelle du frangais par transducteurs et lexiquegrammaire,</title>
<date>1993</date>
<institution>Universite de Paris</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="1398" citStr="Roche, 1993" startWordPosition="195" endWordPosition="196">ore grammar is easily augmented with corpusspecific sub-grammars. The current system is implemented for French and is being expanded to new languages. 1 Background Previous work in finite-state parsing at sentence level falls into two categories: the constructive approach or the reductionist approach. The origins of the constructive approach go back to the parser developed by Joshi (Joshi, 1996). It is based on a lexical description of large collections of syntactic patterns (up to several hundred thousand rules) using subcategorisation frames (verbs + essential arguments) and local grammars (Roche, 1993). It is, however, still unclear whether this heavily lexicalized method can account for all sentence structures actually found in corpora, especially due to the proliferation of non-argumental complements in corpus analysis. Another constructive line of research concentrates on identifying basic phrases such as in the FASTUS information extraction system (Appelt et al., 1993) or in the chunking approach proposed in (Abney, 1991; Federici et al., 1996). Attempts were made to mark the segments with additional syntactic information (e.g. subject or object) (Grefenstette, 1996) using simple heuris</context>
</contexts>
<marker>Roche, 1993</marker>
<rawString>Emmanuel Roche, Analyse syntaxique transformationnelle du frangais par transducteurs et lexiquegrammaire, Ph.D. dissertation, Universite de Paris 7, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atro Voutilainen</author>
<author>Pasi Tapanainen</author>
</authors>
<title>Ambiguity resolution in a reductionistic parser&apos;,</title>
<date>1993</date>
<booktitle>in Proceedings of the Sixth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>394--403</pages>
<location>Utrecht,</location>
<marker>Voutilainen, Tapanainen, 1993</marker>
<rawString>Atro Voutilainen and Pasi Tapanainen, &apos;Ambiguity resolution in a reductionistic parser&apos;, in Proceedings of the Sixth Conference of the European Chapter of the Association for Computational Linguistics, pp. 394-403, Utrecht, (1993).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>