<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000043">
<title confidence="0.987575">
Using Universal Linguistic Knowledge to Guide Grammar Induction
</title>
<author confidence="0.999143">
Tahira Naseem, Harr Chen, Regina Barzilay Mark Johnson
</author>
<affiliation confidence="0.998225">
Computer Science and Artificial Intelligence Laboratory Department of Computing
Massachusetts Institute of Technology Macquarie University
</affiliation>
<email confidence="0.995823">
{tahira, harr, regina} @csail.mit.edu mark.johnson@mq.edu.au
</email>
<sectionHeader confidence="0.995584" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999482117647059">
We present an approach to grammar induc-
tion that utilizes syntactic universals to im-
prove dependency parsing across a range of
languages. Our method uses a single set
of manually-specified language-independent
rules that identify syntactic dependencies be-
tween pairs of syntactic categories that com-
monly occur across languages. During infer-
ence of the probabilistic model, we use pos-
terior expectation constraints to require that a
minimum proportion of the dependencies we
infer be instances of these rules. We also auto-
matically refine the syntactic categories given
in our coarsely tagged input. Across six lan-
guages our approach outperforms state-of-the-
art unsupervised methods by a significant mar-
gin.1
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998875384615385">
Despite surface differences, human languages ex-
hibit striking similarities in many fundamental as-
pects of syntactic structure. These structural corre-
spondences, referred to as syntactic universals, have
been extensively studied in linguistics (Baker, 2001;
Carnie, 2002; White, 2003; Newmeyer, 2005) and
underlie many approaches in multilingual parsing.
In fact, much recent work has demonstrated that
learning cross-lingual correspondences from cor-
pus data greatly reduces the ambiguity inherent in
syntactic analysis (Kuhn, 2004; Burkett and Klein,
2008; Cohen and Smith, 2009a; Snyder et al., 2009;
Berg-Kirkpatrick and Klein, 2010).
</bodyText>
<footnote confidence="0.9996275">
1The source code for the work presented in this paper is
available at http://groups.csail.mit.edu/rbg/code/dependency/
</footnote>
<table confidence="0.998140285714286">
Root —* Auxiliary Noun —* Adjective
Root —* Verb Noun —* Article
Verb —* Noun Noun —* Noun
Verb —* Pronoun Noun —* Numeral
Verb —* Adverb Preposition —* Noun
Verb —* Verb Adjective —* Adverb
Auxiliary —* Verb
</table>
<tableCaption confidence="0.9632494">
Table 1: The manually-specified universal dependency
rules used in our experiments. These rules specify head-
dependent relationships between coarse (i.e., unsplit)
syntactic categories. An explanation of the ruleset is pro-
vided in Section 5.
</tableCaption>
<bodyText confidence="0.99995945">
In this paper, we present an alternative gram-
mar induction approach that exploits these struc-
tural correspondences by declaratively encoding a
small set of universal dependency rules. As input
to the model, we assume a corpus annotated with
coarse syntactic categories (i.e., high-level part-of-
speech tags) and a set of universal rules defined over
these categories, such as those in Table 1. These
rules incorporate the definitional properties of syn-
tactic categories in terms of their interdependencies
and thus are universal across languages. They can
potentially help disambiguate structural ambiguities
that are difficult to learn from data alone — for
example, our rules prefer analyses in which verbs
are dependents of auxiliaries, even though analyz-
ing auxiliaries as dependents of verbs is also consis-
tent with the data. Leveraging these universal rules
has the potential to improve parsing performance
for a large number of human languages; this is par-
ticularly relevant to the processing of low-resource
</bodyText>
<page confidence="0.943584">
1234
</page>
<note confidence="0.816481">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1234–1244,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999681578947369">
languages. Furthermore, these universal rules are
compact and well-understood, making them easy to
manually construct.
In addition to these universal dependencies, each
specific language typically possesses its own id-
iosyncratic set of dependencies. We address this
challenge by requiring the universal constraints to
only hold in expectation rather than absolutely, i.e.,
we permit a certain number of violations of the con-
straints.
We formulate a generative Bayesian model that
explains the observed data while accounting for
declarative linguistic rules during inference. These
rules are used as expectation constraints on the
posterior distribution over dependency structures.
This approach is based on the posterior regular-
ization technique (Grac¸a et al., 2009), which we
apply to a variational inference algorithm for our
parsing model. Our model can also optionally re-
fine common high-level syntactic categories into
per-language categories by inducing a clustering of
words using Dirichlet Processes (Ferguson, 1973).
Since the universals guide induction toward linguis-
tically plausible structures, automatic refinement be-
comes feasible even in the absence of manually an-
notated syntactic trees.
We test the effectiveness of our grammar induc-
tion model on six Indo-European languages from
three language groups: English, Danish, Portuguese,
Slovene, Spanish, and Swedish. Though these lan-
guages share a high-level Indo-European ancestry,
they cover a diverse range of syntactic phenomenon.
Our results demonstrate that universal rules greatly
improve the accuracy of dependency parsing across
all of these languages, outperforming current state-
of-the-art unsupervised grammar induction meth-
ods (Headden III et al., 2009; Berg-Kirkpatrick and
Klein, 2010).
</bodyText>
<sectionHeader confidence="0.999851" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.991411444444444">
Learning with Linguistic Constraints Our work
is situated within a broader class of unsupervised ap-
proaches that employ declarative knowledge to im-
prove learning of linguistic structure (Haghighi and
Klein, 2006; Chang et al., 2007; Grac¸a et al., 2007;
Cohen and Smith, 2009b; Druck et al., 2009; Liang
et al., 2009a). The way we apply constraints is clos-
est to the latter two approaches of posterior regular-
ization and generalized expectation criteria.
In the posterior regularization framework, con-
straints are expressed in the form of expectations on
posteriors (Grac¸a et al., 2007; Ganchev et al., 2009;
Grac¸a et al., 2009; Ganchev et al., 2010). This de-
sign enables the model to reflect constraints that are
difficult to encode via the model structure or as pri-
ors on its parameters. In their approach, parame-
ters are estimated using a modified EM algorithm,
where the E-step minimizes the KL-divergence be-
tween the model posterior and the set of distributions
that satisfies the constraints. Our approach also ex-
presses constraints as expectations on the posterior;
we utilize the machinery of their framework within
a variational inference algorithm with a mean field
approximation.
Generalized expectation criteria, another tech-
nique for declaratively specifying expectation con-
straints, has previously been successfully applied to
the task of dependency parsing (Druck et al., 2009).
This objective expresses constraints in the form of
preferences over model expectations. The objective
is penalized by the square distance between model
expectations and the prespecified values of the ex-
pectation. This approach yields significant gains
compared to a fully unsupervised counterpart. The
constraints they studied are corpus- and language-
specific. Our work demonstrates that a small set of
language-independent universals can also serve as
effective constraints. Furthermore, we find that our
method outperforms the generalized expectation ap-
proach using corpus-specific constraints.
Learning to Refine Syntactic Categories Recent
research has demonstrated the usefulness of auto-
matically refining the granularity of syntactic cat-
egories. While most of the existing approaches
are implemented in the supervised setting (Finkel
et al., 2007; Petrov and Klein, 2007), Liang et al.
(2007) propose a non-parametric Bayesian model
that learns the granularity of PCFG categories in
an unsupervised fashion. For each non-terminal
grammar symbol, the model posits a Hierarchical
Dirichlet Process over its refinements (subsymbols)
to automatically learn the granularity of syntactic
categories. As with their work, we also use non-
parametric priors for category refinement and em-
</bodyText>
<page confidence="0.982072">
1235
</page>
<bodyText confidence="0.99954462962963">
ploy variational methods for inference. However,
our goal is to apply category refinement to depen-
dency parsing, rather than to PCFGs, requiring a
substantially different model formulation. While
Liang et al. (2007) demonstrated empirical gains on
a synthetic corpus, our experiments focus on unsu-
pervised category refinement on real language data.
Universal Rules in NLP Despite the recent surge
of interest in multilingual learning (Kuhn, 2004; Co-
hen and Smith, 2009a; Snyder et al., 2009; Berg-
Kirkpatrick and Klein, 2010), there is surprisingly
little computational work on linguistic universals.
On the acquisition side, Daum´e III and Campbell
(2007) proposed a computational technique for dis-
covering universal implications in typological fea-
tures. More closely related to our work is the posi-
tion paper by Bender (2009), which advocates the
use of manually-encoded cross-lingual generaliza-
tions for the development of NLP systems. She ar-
gues that a system employing such knowledge could
be easily adapted to a particular language by spe-
cializing this high level knowledge based on the ty-
pological features of the language. We also argue
that cross-language universals are beneficial for au-
tomatic language processing; however, our focus is
on learning language-specific adaptations of these
rules from data.
</bodyText>
<sectionHeader confidence="0.994329" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.996924882352941">
The central hypothesis of this work is that unsu-
pervised dependency grammar induction can be im-
proved using universal linguistic knowledge. To-
ward this end our approach is comprised of two
components: a probabilistic model that explains
how sentences are generated from latent dependency
structures and a technique for incorporating declar-
ative rules into the inference process.
We first describe the generative story in this sec-
tion before turning to how constraints are applied
during inference in Section 4. Our model takes as
input (i.e., as observed) a set of sentences where
each word is annotated with a coarse part-of-speech
tag. Table 2 provides a detailed technical descrip-
tion of our model’s generative process, and Figure 1
presents a model diagram.
For each observed coarse symbol s:
</bodyText>
<listItem confidence="0.99821575">
1. Draw top-level infinite multinomial over
subsymbols βs — GEM(γ).
2. For each subsymbol z of symbol s:
(a) Draw word emission multinomial
φsz — Dir(φ0).
(b) For each context value c:
i. Draw child symbol generation
multinomial θszc — Dir(θ0).
</listItem>
<bodyText confidence="0.780303833333333">
ii. For each child symbol s&apos;:
A. Draw second-level infinite
multinomial over subsymbols
πs0szc — DP(α,βs0).
For each tree node i generated in context c by
parent symbol s&apos; and parent subsymbol z&apos;:
</bodyText>
<listItem confidence="0.998421666666667">
1. Draw coarse symbol si — Mult(θs0z0).
2. Draw subsymbol zi — Mult(πsis0z0c).
3. Draw word xi — Mult(φsizi).
</listItem>
<tableCaption confidence="0.751638">
Table 2: The generative process for model parameters
</tableCaption>
<bodyText confidence="0.914868238095238">
and parses. In the above GEM, DP, Dir, and Mult refer
respectively to the stick breaking distribution, Dirichlet
process, Dirichlet distribution, and multinomial distribu-
tion.
Generating Symbols and Words We describe
how a single node of the tree is generated before
discussing how the entire tree structure is formed.
Each node of the dependency tree is comprised of
three random variables: an observed coarse symbol
s, a hidden refined subsymbol z, and an observed
word x. In the following let the parent of the cur-
rent node have symbol s&apos; and subsymbol z&apos;; the root
node is generated from separate root-specific distri-
butions. Subsymbol refinement is an optional com-
ponent of the full model and can be omitted by de-
terministically equating s and z. As we explain at
the end of this section, without this aspect the gener-
ative story closely resembles the classic dependency
model with valence (DMV) of Klein and Manning
(2004).
First we draw symbol s from a finite multinomial
</bodyText>
<page confidence="0.960408">
1236
</page>
<table confidence="0.909029777777778">
s - coarse symbol (observed)
z - refined subsymbol
x - word (observed)
θszc - distr over child coarse symbols for
each parent s and z and context c
βs - top-level distr over subsymbols for s
πssIzIc - distr over subsymbols for each s,
parent s&apos; and z&apos;, and context c
φsz - distr over words for s and z
</table>
<figureCaption confidence="0.983118">
Figure 1: Graphical representation of the model and a summary of the notation. There is a copy of the outer plate for
each distinct symbol in the observed coarse tags. Here, node 3 is shown to be the parent of nodes 1 and 2. Shaded
variables are observed, square variables are hyperparameters. The elongated oval around s and z represents the two
variables jointly. For clarity the diagram omits some arrows from θ to each s, π to each z, and φ to each x.
</figureCaption>
<bodyText confidence="0.999890360655738">
distribution with parameters θs0z0c. As the indices
indicate, we have one such set of multinomial pa-
rameters for every combination of parent symbol
s&apos; and subsymbol z&apos; along with a context c. Here
the context of the current node can take one of six
values corresponding to every combination of di-
rection (left or right) and valence (first, second, or
third or higher child) with respect to its parent. The
prior (base distribution) for each θs0z0c is a symmet-
ric Dirichlet with hyperparameter θ0.
Next we draw the refined syntactic category sub-
symbol z from an infinite multinomial with parame-
ters πss0z0c. Here the selection of π is indexed by the
current node’s coarse symbol s, the symbol s&apos; and
subsymbol z&apos; of the parent node, and the context c
of the current node.
For each unique coarse symbol s we tie together
the distributions πss0z0c for all possible parent and
context combinations (i.e., s&apos;, z&apos;, and c) using a Hi-
erarchical Dirichlet Process (HDP). Specifically, for
a single s, each distribution πss0z0c over subsymbols
is drawn from a DP with concentration parameter
α and base distribution βs over subsymbols. This
base distribution βs is itself drawn from a GEM prior
with concentration parameter γ. By formulating the
generation of z as an HDP, we can share parame-
ters for a single coarse symbol’s subsymbol distribu-
tion while allowing for individual variability based
on node parent and context. Note that parameters
are not shared across different coarse symbols, pre-
serving the distinctions expressed via the coarse tag
annotations.
Finally, we generate the word x from a finite
multinomial with parameters φsz, where s and z are
the symbol and subsymbol of the current node. The
φ distributions are drawn from a symmetric Dirich-
let prior.
Generating the Tree Structure We now consider
how the structure of the tree arises. We follow
an approach similar to the widely-referenced DMV
model (Klein and Manning, 2004), which forms
the basis of the current state-of-the-art unsuper-
vised grammar induction model (Headden III et al.,
2009). After a node is drawn we generate children
on each side until we produce a designated STOP
symbol. We encode more detailed valence informa-
tion than Klein and Manning (2004) and condition
child generation on parent valence. Specifically, af-
ter drawing a node we first decide whether to pro-
ceed to generate a child or to stop conditioned on the
parent symbol and subsymbol and the current con-
text (direction and valence). If we decide to gener-
ate a child we follow the previously described pro-
cess for constructing a node. We can combine the
stopping decision with the generation of the child
symbol by including a distinguished STOP symbol
as a possible outcome in distribution θ.
No-Split Model Variant In the absence of sub-
symbol refinement (i.e., when subsymbol z is set to
be identical to coarse symbol s), our model simpli-
fies in some respects. In particular, the HDP gener-
</bodyText>
<page confidence="0.95991">
1237
</page>
<bodyText confidence="0.999629625">
ation of z is obviated and word x is drawn from a
word distribution 0s indexed solely by coarse sym-
bol s. The resulting simplified model closely resem-
bles DMV (Klein and Manning, 2004), except that it
1) explicitly generate words x rather than only part-
of-speech tags s, 2) encodes richer context and va-
lence information, and 3) imposes a Dirichlet prior
on the symbol distribution B.
</bodyText>
<sectionHeader confidence="0.992516" genericHeader="method">
4 Inference with Constraints
</sectionHeader>
<bodyText confidence="0.991123176470588">
We now describe how to augment our generative
model of dependency structure with constraints de-
rived from linguistic knowledge. Incorporating arbi-
trary linguistic rules directly in the generative story
is challenging as it requires careful tuning of either
the model structure or priors for each constraint. In-
stead, following the approach of Grac¸a et al. (2007),
we constrain the posterior to satisfy the rules in ex-
pectation during inference. This effectively biases
the inference toward linguistically plausible settings.
In standard variational inference, an intractable
true posterior is approximated by a distribution from
a tractable set (Bishop, 2006). This tractable set typ-
ically makes stronger independence assumptions be-
tween model parameters than the model itself. To in-
corporate the constraints, we further restrict the set
to only include distributions that satisfy the specified
expectation constraints over hidden variables.
In general, for some given model, let B denote
the entire set of model parameters and z and x de-
note the hidden structure and observations respec-
tively. We are interested in estimating the posterior
p(B, z  |x). Variational inference transforms this
problem into an optimization problem where we try
to find a distribution q(B, z) from a restricted set Q
that minimizes the KL-divergence between q(B, z)
and p(B, z  |x):
KL(q(B, z) k p(B, z  |x))
Thus F is a lower bound on likelihood. Maximizing
this lower bound is equivalent to minimizing the KL-
divergence between p(B, z  |x) and q(B, z). To make
this maximization tractable we make a mean field
assumption that q belongs to a set Q of distributions
that factorize as follows:
</bodyText>
<equation confidence="0.700439">
q(B, z) = q(B)q(z).
</equation>
<bodyText confidence="0.996666230769231">
We further constrain q to be from the subset of Q
that satisfies the expectation constraint Eq[f(z)] ≤ b
where f is a deterministically computable function
of the hidden structures. In our model, for exam-
ple, f counts the dependency edges that are an in-
stance of one of the declaratively specified depen-
dency rules, while b is the proportion of the total
dependencies that we expect should fulfill this con-
straint.2
With the mean field factorization and the expec-
tation constraints in place, solving the maximization
of F in (1) separately for each factor yields the fol-
lowing updates:
</bodyText>
<equation confidence="0.999208333333333">
KL (q(B) k q&apos;(B)), (2)
KL (q(z) k q&apos;(z))
s.t. Eq(z)[f(z)] ≤ b, (3)
</equation>
<bodyText confidence="0.819801">
where
</bodyText>
<equation confidence="0.9959125">
q&apos;(B) ∝ exp Eq(z)[log p(B, z, x)], (4)
q&apos;(z) ∝ exp Eq(B)[log p(B, z, x)]. (5)
</equation>
<bodyText confidence="0.999468428571429">
We can solve (2) by setting q(B) to q&apos;(B) — since
q(z) is held fixed while updating q(B), the expecta-
tion function of the constraint remains constant dur-
ing this update. As shown by Grac¸a et al. (2007), the
update in (3) is a constrained optimization problem
and can be solved by performing gradient search on
its dual:
</bodyText>
<equation confidence="0.974291117647059">
q(B) = argmin
q(B)
q(z) = argmin
q(z)
= J q(B, z) log q(B, z)) dBdz + log p(x).
p
(B, z, x
�
argmin ATb + log
A
q&apos;(z) exp(−ATf(z)) (6)
z
Rearranging the above yields:
logp(x) = KL(q(B, z) k p(B, z  |x)) + F,
where F is defined as
J q(B, z) log p(B, z, x) F ≡dBdz. (1)
q(B, z)
</equation>
<bodyText confidence="0.906292333333333">
For a fixed value of A the optimal q(z) ∝
q&apos;(z) exp(−ATf(z)). By updating q(B) and q(z)
as in (2) and (3) we are effectively maximizing the
lower bound F.
2Constraints of the form E9[f(z)] &gt; b are easily imposed
by negating f(z) and b.
</bodyText>
<page confidence="0.964197">
1238
</page>
<subsectionHeader confidence="0.95945">
4.1 Variational Updates
</subsectionHeader>
<bodyText confidence="0.999944666666667">
We now derive the specific variational updates for
our dependency induction model. First we assume
the following mean-field factorization of our varia-
tional distribution:
The only factor affected by the expectation con-
straints is q(z). Recall from the previous section that
the update for q(z) is performed via gradient search
on the dual of a constrained minimization problem
of the form:
</bodyText>
<equation confidence="0.990164214285714">
q(β, θ, π, φ, z)
q(z) = argmin
q(z)
q(βs0) &apos;
q(φs0z0)&apos;
T
H
z0=1
KL(q(z) 11 q0(z)).
Thus we first compute the update for q0(z):
H= q(z) &apos;
s0
H q(θs0z0c) &apos; H q(πss0z0c), (7)
c s
</equation>
<bodyText confidence="0.999910052631579">
where s0 varies over the set of unique symbols in the
observed tags, z0 denotes subsymbols for each sym-
bol, c varies over context values comprising a pair
of direction (left or right) and valence (first, second,
or third or higher) values, and s corresponds to child
symbols.
We restrict q(θs0z0c) and q(φs0z0) to be Dirichlet
distributions and q(z) to be multinomial. As with
prior work (Liang et al., 2009b), we assume a de-
generate q(β) - δ0∗(β) for tractability reasons, i.e.,
all mass is concentrated on some single β∗. We also
assume that the top level stick-breaking distribution
is truncated at T, i.e., q(β) assigns zero probability
to integers greater than T. Because of the truncation
of β, we can approximate q(πss0z0c) with an asym-
metric finite dimensional Dirichlet.
The factors are updated one at a time holding all
other factors fixed. The variational update for q(π)
is given by:
</bodyText>
<equation confidence="0.980243">
q(πss0z0c) = Dir (πss0z0c; αβ + Eq(z)[Css0z0c(z)]) ,
</equation>
<bodyText confidence="0.999284833333333">
where term Eq(z)[Css0z0c(z)] is the expected count
w.r.t. q(z) of child symbol s and subsymbol z in
context c when generated by parent symbol s0 and
subsymbol z0.
Similarly, the updates for q(θ) and q(φ) are given
by:
</bodyText>
<equation confidence="0.9999185">
q(θs0z0c) = Dir (θs0z0c; θ0 + Eq(z)[Cs0z0c(s)]) ,
q(φs0z0) = Dir (φs0z0; φ0 + Eq(z)[Cs0z0(x)]) ,
</equation>
<bodyText confidence="0.999821">
where Cs0z0c(s) is the count of child symbol s being
generated by the parent symbol s0 and subsymbol z0
in context c and Cs0z0x is the count of word x being
generated by symbol s0 and subsymbol z0.
</bodyText>
<equation confidence="0.9965132">
N len(n)
q0(z) a H H (exp Eq(0)[log φsnjznj(xnj)]
n=1 j=1
x exp Eq(B)[log θsh(nj)zh(nj)cnj(snj)]
x exp Eq(7r)[log πsnjsh(nj)zh(nj)cnj(znj)]),
</equation>
<bodyText confidence="0.99703">
where N is the total number of sentences, len(n)
is the length of sentence n, and index h(nj) refers
to the head of the jth node of sentence n. Given
this q0(z) a gradient search is performed using (6) to
find the optimal λ and thus the primal solution for
updating q(z).
Finally, we update the degenerate factor q(βs)
with the projected gradient search algorithm used
by Liang et al. (2009b).
</bodyText>
<sectionHeader confidence="0.995534" genericHeader="method">
5 Linguistic Constraints
</sectionHeader>
<bodyText confidence="0.998646210526316">
Universal Dependency Rules We compile a set of
13 universal dependency rules consistent with vari-
ous linguistic accounts (Carnie, 2002; Newmeyer,
2005), shown in Table 1. These rules are defined
over coarse part-of-speech tags: Noun, Verb, Adjec-
tive, Adverb, Pronoun, Article, Auxiliary, Preposi-
tion, Numeral and Conjunction. Each rule specifies
a part-of-speech for the head and argument but does
not provide ordering information.
We require that a minimum proportion of the pos-
terior dependencies be instances of these rules in ex-
pectation. In contrast to prior work on rule-driven
dependency induction (Druck et al., 2009), where
each rule has a separately specified expectation, we
only set a single minimum expectation for the pro-
portion of all dependencies that must match one of
the rules. This setup is more relevant for learn-
ing with universals since individual rule frequencies
vary greatly between languages.
</bodyText>
<page confidence="0.983562">
1239
</page>
<listItem confidence="0.997127473684211">
1. Identify non-recursive NPs:
• All nouns, pronouns and possessive
marker are part of an NP.
• All adjectives, conjunctions and deter-
miners immediately preceding an NP
are part of the NP.
2. The first verb or modal in the sentence is the
headword.
3. All words in an NP are headed by the last
word in the NP.
4. The last word in an NP is headed by the
word immediately before the NP if it is a
preposition, otherwise it is headed by the
headword of the sentence if the NP is be-
fore the headword, else it is headed by the
word preceding the NP.
5. For the first word set its head to be the head-
word of the sentence. For each other word
set its headword to be the previous word.
</listItem>
<tableCaption confidence="0.998887">
Table 3: English-specific dependency rules.
</tableCaption>
<bodyText confidence="0.996334636363636">
English-specific Dependency Rules For English,
we also consider a small set of hand-crafted depen-
dency rules designed by Michael Collins3 for deter-
ministic parsing, shown in Table 3. Unlike the uni-
versals from Table 1, these rules alone are enough to
construct a full dependency tree. Thus they allow us
to judge whether the model is able to improve upon
a human-engineered deterministic parser. Moreover,
with this dataset we can assess the additional benefit
of using rules tailored to an individual language as
opposed to universal rules.
</bodyText>
<sectionHeader confidence="0.998942" genericHeader="method">
6 Experimental Setup
</sectionHeader>
<bodyText confidence="0.9951822">
Datasets and Evaluation We test the effective-
ness of our grammar induction approach on English,
Danish, Portuguese, Slovene, Spanish, and Swedish.
For English we use the Penn Treebank (Marcus et
al., 1993), transformed from CFG parses into depen-
</bodyText>
<footnote confidence="0.614947">
3Personal communication.
</footnote>
<bodyText confidence="0.996355657894737">
dencies with the Collins head finding rules (Collins,
1999); for the other languages we use data from the
2006 CoNLL-X Shared Task (Buchholz and Marsi,
2006). Each dataset provides manually annotated
part-of-speech tags that are used for both training
and testing. For comparison purposes with previ-
ous work, we limit the cross-lingual experiments to
sentences of length 10 or less (not counting punc-
tuation). For English, we also explore sentences of
length up to 20.
The final output metric is directed dependency ac-
curacy. This is computed based on the Viterbi parses
produced using the final unnormalized variational
distribution q(z) over dependency structures.
Hyperparameters and Training Regimes Un-
less otherwise stated, in experiments with rule-based
constraints the expected proportion of dependencies
that must satisfy those constraints is set to 0.8. This
threshold value was chosen based on minimal tun-
ing on a single language and ruleset (English with
universal rules) and carried over to each other ex-
perimental condition. A more detailed discussion of
the threshold’s empirical impact is presented in Sec-
tion 7.1.
Variational approximations to the HDP are trun-
cated at 10. All hyperparameter values are fixed to 1
except α which is fixed to 10.
We also conduct a set of No-Split experiments to
evaluate the importance of syntactic refinement; in
these experiments each coarse symbol corresponds
to only one refined symbol. This is easily effected
during inference by setting the HDP variational ap-
proximation truncation level to one.
For each experiment we run 50 iterations of vari-
ational updates; for each iteration we perform five
steps of gradient search to compute the update for
the variational distribution q(z) over dependency
structures.
</bodyText>
<sectionHeader confidence="0.999924" genericHeader="evaluation">
7 Results
</sectionHeader>
<bodyText confidence="0.9999072">
In the following section we present our primary
cross-lingual results using universal rules (Sec-
tion 7.1) before performing a more in-depth analysis
of model properties such as sensitivity to ruleset se-
lection and inference stability (Section 7.2).
</bodyText>
<page confidence="0.964532">
1240
</page>
<table confidence="0.999839857142857">
DMV PGI No-Split HDP-DEP
English 47.1 62.3 71.5 71.9 (0.3)
Danish 33.5 41.6 48.8 51.9 (1.6)
Portuguese 38.5 63.0 54.0 71.5 (0.5)
Slovene 38.5 48.4 50.6 50.9 (5.5)
Spanish 28.0 58.4 64.8 67.2 (0.4)
Swedish 45.3 58.3 63.3 62.1 (0.5)
</table>
<tableCaption confidence="0.998636">
Table 4: Directed dependency accuracy using our model
</tableCaption>
<bodyText confidence="0.654212">
with universal dependency rules (No-Split and HDP-
DEP), compared to DMV (Klein and Manning, 2004) and
PGI (Berg-Kirkpatrick and Klein, 2010). The DMV re-
sults are taken from Berg-Kirkpatrick and Klein (2010).
Bold numbers indicate the best result for each language.
For the full model, the standard deviation in performance
over five runs is indicated in parentheses.
</bodyText>
<subsectionHeader confidence="0.998111">
7.1 Main Cross-Lingual Results
</subsectionHeader>
<bodyText confidence="0.999968766666667">
Table 4 shows the performance of both our full
model (HDP-DEP) and its No-Split version using
universal dependency rules across six languages.
We also provide the performance of two baselines —
the dependency model with valence (DMV) (Klein
and Manning, 2004) and the phylogenetic grammar
induction (PGI) model (Berg-Kirkpatrick and Klein,
2010).
HDP-DEP outperforms both DMV and PGI
across all six languages. Against DMV we achieve
an average absolute improvement of 24.1%. This
improvement is expected given that DMV does not
have access to the additional information provided
through the universal rules. PGI is more relevant
as a point of comparison, since it is able to lever-
age multilingual data to learn information similar to
what we have declaratively specified using universal
rules. Specifically, PGI reduces induction ambigu-
ity by connecting language-specific parameters via
phylogenetic priors. We find, however, that we out-
perform PGI by an average margin of 7.2%, demon-
strating the benefits of explicit rule specification.
An additional point of comparison is the lexi-
calized unsupervised parser of Headden III et al.
(2009), which yields the current state-of-the-art un-
supervised accuracy on English at 68.8%. Our
method also outperforms this approach, without em-
ploying lexicalization and sophisticated smoothing
as they do. This result suggests that combining the
complementary strengths of their approach and ours
</bodyText>
<table confidence="0.996736833333333">
English
Rule Excluded Acc Loss Gold Freq
Preposition → Noun 61.0 10.9 5.1
Verb → Noun 61.4 10.5 14.8
Noun → Noun 64.4 7.5 10.7
Noun → Article 64.7 7.2 8.5
Spanish
Rule Excluded Acc Loss Gold Freq
Preposition → Noun 53.4 13.8 8.2
Verb → Noun 61.9 5.4 12.9
Noun → Noun 62.6 4.7 2.0
Root → Verb 65.4 1.8 12.3
</table>
<tableCaption confidence="0.999697">
Table 5: Ablation experiment results for universal depen-
</tableCaption>
<bodyText confidence="0.9741025625">
dency rules on English and Spanish. For each rule, we
evaluate the model using the ruleset excluding that rule,
and list the most significant rules for each language. The
second last column is the absolute loss in performance
compared to the setting where all rules are available. The
last column shows the percentage of the gold dependen-
cies that satisfy the rule.
can yield further performance improvements.
Table 4 also shows the No-Split results where syn-
tactic categories are not refined. We find that such
refinement usually proves to be beneficial, yielding
an average performance gain of 3.7%. However, we
note that the impact of incorporating splitting varies
significantly across languages. Further understand-
ing of this connection is an area of future research.
Finally, we note that our model exhibits low vari-
ance for most languages. This result attests to how
the expectation constraints consistently guide infer-
ence toward high-accuracy areas of the search space.
Ablation Analysis Our next experiment seeks to
understand the relative importance of the various
universal rules from Table 1. We study how accu-
racy is affected when each of the rules is removed
one at a time for English and Spanish. Table 5 lists
the rules with the greatest impact on performance
when removed. We note the high overlap between
the most significant rules for English and Spanish.
We also observe that the relationship between
a rule’s frequency and its importance for high ac-
curacy is not straightforward. For example, the
“Preposition → Noun” rule, whose removal de-
grades accuracy the most for both English and Span-
</bodyText>
<page confidence="0.954253">
1241
</page>
<table confidence="0.942604272727273">
Length
&lt; 10 &lt; 20
Universal Dependency Rules
1 HDP-DEP 71.9 50.4
No Rules (Random Init)
2 HDP-DEP 24.9 24.4
3 Headden III et al. (2009) 68.8 -
English-Specific Parsing Rules
4 Deterministic (rules only) 70.0 62.6
5 HDP-DEP 73.8 66.1
Druck et al. (2009) Rules
</table>
<figure confidence="0.92848625">
6 Druck et al. (2009) 61.3 -
7 HDP-DEP 64.9 42.2
75
Gold 70 75 80 85 90
Accuracy
70
65
60
55
50
Average English
Constraints Threshold
</figure>
<figureCaption confidence="0.987263571428571">
Figure 2: Accuracy of our model with different threshold
settings, on English only and averaged over all languages.
“Gold” refers to the setting where each language’s thresh-
old is set independently to the proportion of gold depen-
dencies satisfying the rules — for English this proportion
is 70%, while the average proportion across languages is
63%.
</figureCaption>
<bodyText confidence="0.937938676470588">
ish, is not the most frequent rule in either language.
This result suggests that some rules are harder to
learn than others regardless of their frequency, so
their presence in the specified ruleset yields stronger
performance gains.
Varying the Constraint Threshold In our main
experiments we require that at least 80% of the ex-
pected dependencies satisfy the rule constraints. We
arrived at this threshold by tuning on the basis of En-
glish only. As shown in Figure 2, for English a broad
band of threshold values from 75% to 90% yields re-
sults within 2.5% of each other, with a slight peak at
80%.
To further study the sensitivity of our method to
how the threshold is set, we perform post hoc ex-
periments with other threshold values on each of the
other languages. As Figure 2 also shows, on average
a value of 80% is optimal across languages, though
again accuracy is stable within 2.5% between thresh-
olds of 75% to 90%. These results demonstrate that
a single threshold is broadly applicable across lan-
guages.
Interestingly, setting the threshold value indepen-
dently for each language to its “true” proportion
based on the gold dependencies (denoted as the
“Gold” case in Figure 2) does not achieve optimal
Table 6: Directed accuracy of our model (HDP-DEP) on
sentences of length 10 or less and 20 or less from WSJ
with different rulesets and with no rules, along with vari-
ous baselines from the literature. Entries in this table are
numbered for ease of reference in the text.
performance. Thus, knowledge of the true language-
specific rule proportions is not necessary for high
accuracy.
</bodyText>
<subsectionHeader confidence="0.99918">
7.2 Analysis of Model Properties
</subsectionHeader>
<bodyText confidence="0.999811454545455">
We perform a set of additional experiments on En-
glish to gain further insight into HDP-DEP’s behav-
ior. Our choice of language is motivated by the
fact that a wide range of prior parsing algorithms
were developed for and tested exclusively on En-
glish. The experiments below demonstrate that 1)
universal rules alone are powerful, but language-
and dataset-tailored rules can further improve per-
formance; 2) our model learns jointly from the
rules and data, outperforming a rules-only deter-
ministic parser; 3) the way we incorporate posterior
constraints outperforms the generalized expectation
constraint framework; and 4) our model exhibits low
variance when seeded with different initializations.
These results are summarized in Table 6 and dis-
cussed in detail below; line numbers refer to entries
in Table 6. Each run of HDP-DEP below is with
syntactic refinement enabled.
Impact of Rules Selection We compare the per-
formance of HDP-DEP using the universal rules ver-
sus a set of rules designed for deterministically pars-
ing the Penn Treebank (see Section 5 for details).
</bodyText>
<page confidence="0.980002">
1242
</page>
<bodyText confidence="0.996356069767442">
As lines 1 and 5 of Table 6 show, language-specific
rules yield better performance. For sentences of
length 10 or less, the difference between the two
rulesets is a relatively small 1.9%; for longer sen-
tences, however, the difference is a substantially
larger 15.7%. This is likely because longer sen-
tences tend to be more complex and thus exhibit
more language-idiosyncratic dependencies. Such
dependencies can be better captured by the refined
language-specific rules.
We also test model performance when no linguis-
tic rules are available, i.e., performing unconstrained
variational inference. The model performs substan-
tially worse (line 2), confirming that syntactic cat-
egory refinement in a fully unsupervised setup is
challenging.
Learning Beyond Provided Rules Since HDP-
DEP is provided with linguistic rules, a legitimate
question is whether it improves upon what the rules
encode, especially when the rules are complete and
language-specific. We can answer this question by
comparing the performance of our model seeded
with the English-specific rules against a determin-
istic parser that implements the same rules. Lines
4 and 5 of Table 6 demonstrate that the model out-
performs a rules-only deterministic parser by 3.8%
for sentences of length 10 or less and by 3.5% for
sentences of length 20 or less.
Comparison with Alternative Semi-supervised
Parser The dependency parser based on the gen-
eralized expectation criteria (Druck et al., 2009) is
the closest to our reported work in terms of tech-
nique. To compare the two, we run HDP-DEP using
the 20 rules given by Druck et al. (2009). Our model
achieves an accuracy of 64.9% (line 7) compared to
61.3% (line 6) reported in their work. Note that we
do not rely on rule-specific expectation information
as they do, instead requiring only a single expecta-
tion constraint parameter.4
Model Stability It is commonly acknowledged
in the literature that unsupervised grammar induc-
tion methods exhibit sensitivity to initialization.
As in the previous section, we find that the pres-
</bodyText>
<footnote confidence="0.907453">
4As explained in Section 5, having a single expectation pa-
rameter is motivated by our focus on parsing with universal
rules.
</footnote>
<bodyText confidence="0.9976205">
ence of linguistic rules greatly reduces this sensitiv-
ity: for HDP-DEP, the standard deviation over five
randomly initialized runs with the English-specific
rules is 1.5%, compared to 4.5% for the parser de-
veloped by Headden III et al. (2009) and 8.0% for
DMV (Klein and Manning, 2004).
</bodyText>
<sectionHeader confidence="0.998813" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.9994095">
In this paper we demonstrated that syntactic uni-
versals encoded as declarative constraints improve
grammar induction. We formulated a generative
model for dependency structure that models syntac-
tic category refinement and biases inference to co-
here with the provided constraints. Our experiments
showed that encoding a compact, well-accepted set
of language-independent constraints significantly
improves accuracy on multiple languages compared
to the current state-of-the-art in unsupervised pars-
ing.
While our present work has yielded substantial
gains over previous unsupervised methods, a large
gap still remains between our method and fully su-
pervised techniques. In future work we intend to
study ways to bridge this gap by 1) incorporat-
ing more sophisticated linguistically-driven gram-
mar rulesets to guide induction, 2) lexicalizing the
model, and 3) combining our constraint-based ap-
proach with richer unsupervised models (e.g., Head-
den III et al. (2009)) to benefit from their comple-
mentary strengths.
</bodyText>
<sectionHeader confidence="0.998361" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999959">
The authors acknowledge the support of the NSF
(CAREER grant IIS-0448168, grant IIS-0904684,
and a Graduate Research Fellowship). We are es-
pecially grateful to Michael Collins for inspiring us
toward this line of inquiry and providing determin-
istic rules for English parsing. Thanks to Taylor
Berg-Kirkpatrick, Sabine Iatridou, Ramesh Sridha-
ran, and members of the MIT NLP group for their
suggestions and comments. Any opinions, findings,
conclusions, or recommendations expressed in this
paper are those of the authors, and do not necessar-
ily reflect the views of the funding organizations.
</bodyText>
<page confidence="0.978002">
1243
</page>
<sectionHeader confidence="0.99581" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999766653846154">
Mark C. Baker. 2001. The Atoms of Language: The
Mind’s Hidden Rules of Grammar. Basic Books.
Emily M. Bender. 2009. Linguistically naive != lan-
guage independent: Why NLP needs linguistic typol-
ogy. In Proceedings of the EACL 2009 Workshop
on the Interaction between Linguistics and Compu-
tational Linguistics: Virtuous, Vicious or Vacuous?,
pages 26–32.
Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phylo-
genetic grammar induction. In Proceedings of ACL,
pages 1288–1297.
Christopher M. Bishop. 2006. Pattern Recognition and
Machine Learning. Information Science and Statis-
tics. Springer.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceedings of CoNLL, pages 149–164.
David Burkett and Dan Klein. 2008. Two languages are
better than one (for syntactic parsing). In Proceedings
of EMNLP, pages 877–886.
Andrew Carnie. 2002. Syntax: A Generative Introduc-
tion (Introducing Linguistics). Blackwell Publishing.
Ming-Wei Chang, Lev Ratinov, and Dan Roth.
2007. Guiding semi-supervision with constraint-
driven learning. In Proceedings of ACL, pages 280–
287.
Shay B. Cohen and Noah A. Smith. 2009a. Shared lo-
gistic normal distributions for soft parameter tying in
unsupervised grammar induction. In Proceedings of
NAACL/HLT, pages 74–82.
Shay B. Cohen and Noah A. Smith. 2009b. Variational
inference for grammar induction with prior knowl-
edge. In Proceedings of ACL/IJCNLP 2009 Confer-
ence Short Papers, pages 1–4.
Michael Collins. 1999. Head-driven statistical models
for natural language parsing. Ph.D. thesis, University
of Pennsylvania.
Hal Daum´e III and Lyle Campbell. 2007. A bayesian
model for discovering typological implications. In
Proceedings of ACL, pages 65–72.
Gregory Druck, Gideon Mann, and Andrew McCal-
lum. 2009. Semi-supervised learning of dependency
parsers using generalized expectation criteria. In Pro-
ceedings of ACL/IJCNLP, pages 360–368.
Thomas S. Ferguson. 1973. A bayesian analysis of
some nonparametric problems. Annals of Statistics,
1(2):209–230.
Jenny Rose Finkel, Trond Grenager, and Christopher D.
Manning. 2007. The infinite tree. In Proceedings of
ACL, pages 272–279.
Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar.
2009. Dependency grammar induction via bitext pro-
jection constraints. In Proceedings of ACL/IJCNLP,
pages 369–377.
Kuzman Ganchev, Jo˜ao Grac¸a, Jennifer Gillenwater, and
Ben Taskar. 2010. Posterior regularization for struc-
tured latent variable models. Journal of Machine
Learning Research, 11:2001–2049.
Jo˜ao Grac¸a, Kuzman Ganchev, Ben Taskar, and Fernando
Pereira. 2009. Posterior vs. parameter sparsity in la-
tent variable models. In Advances in NIPS, pages 664–
672.
Jo˜ao Grac¸a, Kuzman Ganchev, and Ben Taskar. 2007.
Expectation maximization and posterior constraints.
In Advances in NIPS, pages 569–576.
Aria Haghighi and Dan Klein. 2006. Prototype-driven
grammar induction. In Proceedings of ACL, pages
881–888.
William P. Headden III, Mark Johnson, and David Mc-
Closky. 2009. Improving unsupervised dependency
parsing with richer contexts and smoothing. In Pro-
ceedings of NAACL/HLT, pages 101–109.
Dan Klein and Christopher Manning. 2004. Corpus-
based induction of syntactic structure: Models of de-
pendency and constituency. In Proceedings of ACL,
pages 478–485.
Jonas Kuhn. 2004. Experiments in parallel-text based
grammar induction. In Proceedings of ACL, pages
470–477.
Percy Liang, Slav Petrov, Michael Jordan, and Dan Klein.
2007. The infinite PCFG using hierarchical Dirichlet
processes. In Proceedings of EMNLP/CoNLL, pages
688–697.
Percy Liang, Michael I. Jordan, and Dan Klein. 2009a.
Learning from measurements in exponential families.
In Proceedings of ICML, pages 641–648.
Percy Liang, Michael I. Jordan, and Dan Klein. 2009b.
Probabilistic grammars and hierarchical Dirichlet pro-
cesses. The Handbook of Applied Bayesian Analysis.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated cor-
pus of english: The penn treebank. Computational
Linguistics, 19(2):313–330.
Frederick J. Newmeyer. 2005. Possible and Probable
Languages: A Generative Perspective on Linguistic
Typology. Oxford University Press.
Slav Petrov and Dan Klein. 2007. Learning and infer-
ence for hierarchically split PCFGs. In Proceeding of
AAAI, pages 1663–1666.
Benjamin Snyder, Tahira Naseem, and Regina Barzilay.
2009. Unsupervised multilingual grammar induction.
In Proceedings of ACL/IJCNLP, pages 73–81.
Lydia White. 2003. Second Language Acquisition and
Universal Grammar. Cambridge University Press.
</reference>
<page confidence="0.993786">
1244
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.785373">
<title confidence="0.999962">Using Universal Linguistic Knowledge to Guide Grammar Induction</title>
<author confidence="0.999953">Tahira Naseem</author>
<author confidence="0.999953">Harr Chen</author>
<author confidence="0.999953">Regina Barzilay Mark Johnson</author>
<affiliation confidence="0.999879">Computer Science and Artificial Intelligence Laboratory Department of Computing Massachusetts Institute of Technology Macquarie University</affiliation>
<email confidence="0.969651">harr,mark.johnson@mq.edu.au</email>
<abstract confidence="0.988747235294118">We present an approach to grammar induction that utilizes syntactic universals to improve dependency parsing across a range of languages. Our method uses a single set of manually-specified language-independent rules that identify syntactic dependencies between pairs of syntactic categories that commonly occur across languages. During inference of the probabilistic model, we use posterior expectation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules. We also automatically refine the syntactic categories given in our coarsely tagged input. Across six languages our approach outperforms state-of-theart unsupervised methods by a significant mar-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mark C Baker</author>
</authors>
<title>The Atoms of Language: The Mind’s Hidden Rules of Grammar.</title>
<date>2001</date>
<publisher>Basic Books.</publisher>
<contexts>
<context position="1307" citStr="Baker, 2001" startWordPosition="178" endWordPosition="179">odel, we use posterior expectation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules. We also automatically refine the syntactic categories given in our coarsely tagged input. Across six languages our approach outperforms state-of-theart unsupervised methods by a significant margin.1 1 Introduction Despite surface differences, human languages exhibit striking similarities in many fundamental aspects of syntactic structure. These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing. In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). 1The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/ Root —* Auxiliary Noun —* Adjective Root —* Verb Noun —* Article Verb —* Noun Noun —* Noun Verb —* </context>
</contexts>
<marker>Baker, 2001</marker>
<rawString>Mark C. Baker. 2001. The Atoms of Language: The Mind’s Hidden Rules of Grammar. Basic Books.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily M Bender</author>
</authors>
<title>Linguistically naive != language independent: Why NLP needs linguistic typology.</title>
<date>2009</date>
<booktitle>In Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics: Virtuous, Vicious or Vacuous?,</booktitle>
<pages>26--32</pages>
<contexts>
<context position="8767" citStr="Bender (2009)" startWordPosition="1277" endWordPosition="1278">7) demonstrated empirical gains on a synthetic corpus, our experiments focus on unsupervised category refinement on real language data. Universal Rules in NLP Despite the recent surge of interest in multilingual learning (Kuhn, 2004; Cohen and Smith, 2009a; Snyder et al., 2009; BergKirkpatrick and Klein, 2010), there is surprisingly little computational work on linguistic universals. On the acquisition side, Daum´e III and Campbell (2007) proposed a computational technique for discovering universal implications in typological features. More closely related to our work is the position paper by Bender (2009), which advocates the use of manually-encoded cross-lingual generalizations for the development of NLP systems. She argues that a system employing such knowledge could be easily adapted to a particular language by specializing this high level knowledge based on the typological features of the language. We also argue that cross-language universals are beneficial for automatic language processing; however, our focus is on learning language-specific adaptations of these rules from data. 3 Model The central hypothesis of this work is that unsupervised dependency grammar induction can be improved u</context>
</contexts>
<marker>Bender, 2009</marker>
<rawString>Emily M. Bender. 2009. Linguistically naive != language independent: Why NLP needs linguistic typology. In Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics: Virtuous, Vicious or Vacuous?, pages 26–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Phylogenetic grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1288--1297</pages>
<contexts>
<context position="1687" citStr="Berg-Kirkpatrick and Klein, 2010" startWordPosition="230" endWordPosition="233">spite surface differences, human languages exhibit striking similarities in many fundamental aspects of syntactic structure. These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing. In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). 1The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/ Root —* Auxiliary Noun —* Adjective Root —* Verb Noun —* Article Verb —* Noun Noun —* Noun Verb —* Pronoun Noun —* Numeral Verb —* Adverb Preposition —* Noun Verb —* Verb Adjective —* Adverb Auxiliary —* Verb Table 1: The manually-specified universal dependency rules used in our experiments. These rules specify headdependent relationships between coarse (i.e., unsplit) syntactic categories. An explanation of the ruleset is provided in Section 5. In this paper, we present an </context>
<context position="5239" citStr="Berg-Kirkpatrick and Klein, 2010" startWordPosition="748" endWordPosition="751">ecomes feasible even in the absence of manually annotated syntactic trees. We test the effectiveness of our grammar induction model on six Indo-European languages from three language groups: English, Danish, Portuguese, Slovene, Spanish, and Swedish. Though these languages share a high-level Indo-European ancestry, they cover a diverse range of syntactic phenomenon. Our results demonstrate that universal rules greatly improve the accuracy of dependency parsing across all of these languages, outperforming current stateof-the-art unsupervised grammar induction methods (Headden III et al., 2009; Berg-Kirkpatrick and Klein, 2010). 2 Related Work Learning with Linguistic Constraints Our work is situated within a broader class of unsupervised approaches that employ declarative knowledge to improve learning of linguistic structure (Haghighi and Klein, 2006; Chang et al., 2007; Grac¸a et al., 2007; Cohen and Smith, 2009b; Druck et al., 2009; Liang et al., 2009a). The way we apply constraints is closest to the latter two approaches of posterior regularization and generalized expectation criteria. In the posterior regularization framework, constraints are expressed in the form of expectations on posteriors (Grac¸a et al., 2</context>
<context position="26567" citStr="Berg-Kirkpatrick and Klein, 2010" startWordPosition="4268" endWordPosition="4271">ry cross-lingual results using universal rules (Section 7.1) before performing a more in-depth analysis of model properties such as sensitivity to ruleset selection and inference stability (Section 7.2). 1240 DMV PGI No-Split HDP-DEP English 47.1 62.3 71.5 71.9 (0.3) Danish 33.5 41.6 48.8 51.9 (1.6) Portuguese 38.5 63.0 54.0 71.5 (0.5) Slovene 38.5 48.4 50.6 50.9 (5.5) Spanish 28.0 58.4 64.8 67.2 (0.4) Swedish 45.3 58.3 63.3 62.1 (0.5) Table 4: Directed dependency accuracy using our model with universal dependency rules (No-Split and HDPDEP), compared to DMV (Klein and Manning, 2004) and PGI (Berg-Kirkpatrick and Klein, 2010). The DMV results are taken from Berg-Kirkpatrick and Klein (2010). Bold numbers indicate the best result for each language. For the full model, the standard deviation in performance over five runs is indicated in parentheses. 7.1 Main Cross-Lingual Results Table 4 shows the performance of both our full model (HDP-DEP) and its No-Split version using universal dependency rules across six languages. We also provide the performance of two baselines — the dependency model with valence (DMV) (Klein and Manning, 2004) and the phylogenetic grammar induction (PGI) model (Berg-Kirkpatrick and Klein, 20</context>
</contexts>
<marker>Berg-Kirkpatrick, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phylogenetic grammar induction. In Proceedings of ACL, pages 1288–1297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher M Bishop</author>
</authors>
<date>2006</date>
<booktitle>Pattern Recognition and Machine Learning. Information Science and Statistics.</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="16420" citStr="Bishop, 2006" startWordPosition="2555" endWordPosition="2556">odel of dependency structure with constraints derived from linguistic knowledge. Incorporating arbitrary linguistic rules directly in the generative story is challenging as it requires careful tuning of either the model structure or priors for each constraint. Instead, following the approach of Grac¸a et al. (2007), we constrain the posterior to satisfy the rules in expectation during inference. This effectively biases the inference toward linguistically plausible settings. In standard variational inference, an intractable true posterior is approximated by a distribution from a tractable set (Bishop, 2006). This tractable set typically makes stronger independence assumptions between model parameters than the model itself. To incorporate the constraints, we further restrict the set to only include distributions that satisfy the specified expectation constraints over hidden variables. In general, for some given model, let B denote the entire set of model parameters and z and x denote the hidden structure and observations respectively. We are interested in estimating the posterior p(B, z |x). Variational inference transforms this problem into an optimization problem where we try to find a distribu</context>
</contexts>
<marker>Bishop, 2006</marker>
<rawString>Christopher M. Bishop. 2006. Pattern Recognition and Machine Learning. Information Science and Statistics. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<pages>149--164</pages>
<contexts>
<context position="24273" citStr="Buchholz and Marsi, 2006" startWordPosition="3910" endWordPosition="3913">gineered deterministic parser. Moreover, with this dataset we can assess the additional benefit of using rules tailored to an individual language as opposed to universal rules. 6 Experimental Setup Datasets and Evaluation We test the effectiveness of our grammar induction approach on English, Danish, Portuguese, Slovene, Spanish, and Swedish. For English we use the Penn Treebank (Marcus et al., 1993), transformed from CFG parses into depen3Personal communication. dencies with the Collins head finding rules (Collins, 1999); for the other languages we use data from the 2006 CoNLL-X Shared Task (Buchholz and Marsi, 2006). Each dataset provides manually annotated part-of-speech tags that are used for both training and testing. For comparison purposes with previous work, we limit the cross-lingual experiments to sentences of length 10 or less (not counting punctuation). For English, we also explore sentences of length up to 20. The final output metric is directed dependency accuracy. This is computed based on the Viterbi parses produced using the final unnormalized variational distribution q(z) over dependency structures. Hyperparameters and Training Regimes Unless otherwise stated, in experiments with rule-bas</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of CoNLL, pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Burkett</author>
<author>Dan Klein</author>
</authors>
<title>Two languages are better than one (for syntactic parsing).</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>877--886</pages>
<contexts>
<context position="1607" citStr="Burkett and Klein, 2008" startWordPosition="218" endWordPosition="221">heart unsupervised methods by a significant margin.1 1 Introduction Despite surface differences, human languages exhibit striking similarities in many fundamental aspects of syntactic structure. These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing. In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). 1The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/ Root —* Auxiliary Noun —* Adjective Root —* Verb Noun —* Article Verb —* Noun Noun —* Noun Verb —* Pronoun Noun —* Numeral Verb —* Adverb Preposition —* Noun Verb —* Verb Adjective —* Adverb Auxiliary —* Verb Table 1: The manually-specified universal dependency rules used in our experiments. These rules specify headdependent relationships between coarse (i.e., unsplit) syntactic categories. An ex</context>
</contexts>
<marker>Burkett, Klein, 2008</marker>
<rawString>David Burkett and Dan Klein. 2008. Two languages are better than one (for syntactic parsing). In Proceedings of EMNLP, pages 877–886.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carnie</author>
</authors>
<title>Syntax: A Generative Introduction (Introducing Linguistics).</title>
<date>2002</date>
<publisher>Blackwell Publishing.</publisher>
<contexts>
<context position="1321" citStr="Carnie, 2002" startWordPosition="180" endWordPosition="181">posterior expectation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules. We also automatically refine the syntactic categories given in our coarsely tagged input. Across six languages our approach outperforms state-of-theart unsupervised methods by a significant margin.1 1 Introduction Despite surface differences, human languages exhibit striking similarities in many fundamental aspects of syntactic structure. These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing. In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). 1The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/ Root —* Auxiliary Noun —* Adjective Root —* Verb Noun —* Article Verb —* Noun Noun —* Noun Verb —* Pronoun Noun —</context>
<context position="21770" citStr="Carnie, 2002" startWordPosition="3492" endWordPosition="3493">(nj)cnj(snj)] x exp Eq(7r)[log πsnjsh(nj)zh(nj)cnj(znj)]), where N is the total number of sentences, len(n) is the length of sentence n, and index h(nj) refers to the head of the jth node of sentence n. Given this q0(z) a gradient search is performed using (6) to find the optimal λ and thus the primal solution for updating q(z). Finally, we update the degenerate factor q(βs) with the projected gradient search algorithm used by Liang et al. (2009b). 5 Linguistic Constraints Universal Dependency Rules We compile a set of 13 universal dependency rules consistent with various linguistic accounts (Carnie, 2002; Newmeyer, 2005), shown in Table 1. These rules are defined over coarse part-of-speech tags: Noun, Verb, Adjective, Adverb, Pronoun, Article, Auxiliary, Preposition, Numeral and Conjunction. Each rule specifies a part-of-speech for the head and argument but does not provide ordering information. We require that a minimum proportion of the posterior dependencies be instances of these rules in expectation. In contrast to prior work on rule-driven dependency induction (Druck et al., 2009), where each rule has a separately specified expectation, we only set a single minimum expectation for the pr</context>
</contexts>
<marker>Carnie, 2002</marker>
<rawString>Andrew Carnie. 2002. Syntax: A Generative Introduction (Introducing Linguistics). Blackwell Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Guiding semi-supervision with constraintdriven learning.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>280--287</pages>
<contexts>
<context position="5487" citStr="Chang et al., 2007" startWordPosition="786" endWordPosition="789"> languages share a high-level Indo-European ancestry, they cover a diverse range of syntactic phenomenon. Our results demonstrate that universal rules greatly improve the accuracy of dependency parsing across all of these languages, outperforming current stateof-the-art unsupervised grammar induction methods (Headden III et al., 2009; Berg-Kirkpatrick and Klein, 2010). 2 Related Work Learning with Linguistic Constraints Our work is situated within a broader class of unsupervised approaches that employ declarative knowledge to improve learning of linguistic structure (Haghighi and Klein, 2006; Chang et al., 2007; Grac¸a et al., 2007; Cohen and Smith, 2009b; Druck et al., 2009; Liang et al., 2009a). The way we apply constraints is closest to the latter two approaches of posterior regularization and generalized expectation criteria. In the posterior regularization framework, constraints are expressed in the form of expectations on posteriors (Grac¸a et al., 2007; Ganchev et al., 2009; Grac¸a et al., 2009; Ganchev et al., 2010). This design enables the model to reflect constraints that are difficult to encode via the model structure or as priors on its parameters. In their approach, parameters are estim</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007. Guiding semi-supervision with constraintdriven learning. In Proceedings of ACL, pages 280– 287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Noah A Smith</author>
</authors>
<title>Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL/HLT,</booktitle>
<pages>74--82</pages>
<contexts>
<context position="1630" citStr="Cohen and Smith, 2009" startWordPosition="222" endWordPosition="225">s by a significant margin.1 1 Introduction Despite surface differences, human languages exhibit striking similarities in many fundamental aspects of syntactic structure. These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing. In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). 1The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/ Root —* Auxiliary Noun —* Adjective Root —* Verb Noun —* Article Verb —* Noun Noun —* Noun Verb —* Pronoun Noun —* Numeral Verb —* Adverb Preposition —* Noun Verb —* Verb Adjective —* Adverb Auxiliary —* Verb Table 1: The manually-specified universal dependency rules used in our experiments. These rules specify headdependent relationships between coarse (i.e., unsplit) syntactic categories. An explanation of the rulese</context>
<context position="5531" citStr="Cohen and Smith, 2009" startWordPosition="794" endWordPosition="797">an ancestry, they cover a diverse range of syntactic phenomenon. Our results demonstrate that universal rules greatly improve the accuracy of dependency parsing across all of these languages, outperforming current stateof-the-art unsupervised grammar induction methods (Headden III et al., 2009; Berg-Kirkpatrick and Klein, 2010). 2 Related Work Learning with Linguistic Constraints Our work is situated within a broader class of unsupervised approaches that employ declarative knowledge to improve learning of linguistic structure (Haghighi and Klein, 2006; Chang et al., 2007; Grac¸a et al., 2007; Cohen and Smith, 2009b; Druck et al., 2009; Liang et al., 2009a). The way we apply constraints is closest to the latter two approaches of posterior regularization and generalized expectation criteria. In the posterior regularization framework, constraints are expressed in the form of expectations on posteriors (Grac¸a et al., 2007; Ganchev et al., 2009; Grac¸a et al., 2009; Ganchev et al., 2010). This design enables the model to reflect constraints that are difficult to encode via the model structure or as priors on its parameters. In their approach, parameters are estimated using a modified EM algorithm, where th</context>
<context position="8409" citStr="Cohen and Smith, 2009" startWordPosition="1220" endWordPosition="1224"> to automatically learn the granularity of syntactic categories. As with their work, we also use nonparametric priors for category refinement and em1235 ploy variational methods for inference. However, our goal is to apply category refinement to dependency parsing, rather than to PCFGs, requiring a substantially different model formulation. While Liang et al. (2007) demonstrated empirical gains on a synthetic corpus, our experiments focus on unsupervised category refinement on real language data. Universal Rules in NLP Despite the recent surge of interest in multilingual learning (Kuhn, 2004; Cohen and Smith, 2009a; Snyder et al., 2009; BergKirkpatrick and Klein, 2010), there is surprisingly little computational work on linguistic universals. On the acquisition side, Daum´e III and Campbell (2007) proposed a computational technique for discovering universal implications in typological features. More closely related to our work is the position paper by Bender (2009), which advocates the use of manually-encoded cross-lingual generalizations for the development of NLP systems. She argues that a system employing such knowledge could be easily adapted to a particular language by specializing this high level</context>
</contexts>
<marker>Cohen, Smith, 2009</marker>
<rawString>Shay B. Cohen and Noah A. Smith. 2009a. Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction. In Proceedings of NAACL/HLT, pages 74–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Noah A Smith</author>
</authors>
<title>Variational inference for grammar induction with prior knowledge.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL/IJCNLP 2009 Conference Short Papers,</booktitle>
<pages>1--4</pages>
<contexts>
<context position="1630" citStr="Cohen and Smith, 2009" startWordPosition="222" endWordPosition="225">s by a significant margin.1 1 Introduction Despite surface differences, human languages exhibit striking similarities in many fundamental aspects of syntactic structure. These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing. In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). 1The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/ Root —* Auxiliary Noun —* Adjective Root —* Verb Noun —* Article Verb —* Noun Noun —* Noun Verb —* Pronoun Noun —* Numeral Verb —* Adverb Preposition —* Noun Verb —* Verb Adjective —* Adverb Auxiliary —* Verb Table 1: The manually-specified universal dependency rules used in our experiments. These rules specify headdependent relationships between coarse (i.e., unsplit) syntactic categories. An explanation of the rulese</context>
<context position="5531" citStr="Cohen and Smith, 2009" startWordPosition="794" endWordPosition="797">an ancestry, they cover a diverse range of syntactic phenomenon. Our results demonstrate that universal rules greatly improve the accuracy of dependency parsing across all of these languages, outperforming current stateof-the-art unsupervised grammar induction methods (Headden III et al., 2009; Berg-Kirkpatrick and Klein, 2010). 2 Related Work Learning with Linguistic Constraints Our work is situated within a broader class of unsupervised approaches that employ declarative knowledge to improve learning of linguistic structure (Haghighi and Klein, 2006; Chang et al., 2007; Grac¸a et al., 2007; Cohen and Smith, 2009b; Druck et al., 2009; Liang et al., 2009a). The way we apply constraints is closest to the latter two approaches of posterior regularization and generalized expectation criteria. In the posterior regularization framework, constraints are expressed in the form of expectations on posteriors (Grac¸a et al., 2007; Ganchev et al., 2009; Grac¸a et al., 2009; Ganchev et al., 2010). This design enables the model to reflect constraints that are difficult to encode via the model structure or as priors on its parameters. In their approach, parameters are estimated using a modified EM algorithm, where th</context>
<context position="8409" citStr="Cohen and Smith, 2009" startWordPosition="1220" endWordPosition="1224"> to automatically learn the granularity of syntactic categories. As with their work, we also use nonparametric priors for category refinement and em1235 ploy variational methods for inference. However, our goal is to apply category refinement to dependency parsing, rather than to PCFGs, requiring a substantially different model formulation. While Liang et al. (2007) demonstrated empirical gains on a synthetic corpus, our experiments focus on unsupervised category refinement on real language data. Universal Rules in NLP Despite the recent surge of interest in multilingual learning (Kuhn, 2004; Cohen and Smith, 2009a; Snyder et al., 2009; BergKirkpatrick and Klein, 2010), there is surprisingly little computational work on linguistic universals. On the acquisition side, Daum´e III and Campbell (2007) proposed a computational technique for discovering universal implications in typological features. More closely related to our work is the position paper by Bender (2009), which advocates the use of manually-encoded cross-lingual generalizations for the development of NLP systems. She argues that a system employing such knowledge could be easily adapted to a particular language by specializing this high level</context>
</contexts>
<marker>Cohen, Smith, 2009</marker>
<rawString>Shay B. Cohen and Noah A. Smith. 2009b. Variational inference for grammar induction with prior knowledge. In Proceedings of ACL/IJCNLP 2009 Conference Short Papers, pages 1–4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="24175" citStr="Collins, 1999" startWordPosition="3895" endWordPosition="3896"> tree. Thus they allow us to judge whether the model is able to improve upon a human-engineered deterministic parser. Moreover, with this dataset we can assess the additional benefit of using rules tailored to an individual language as opposed to universal rules. 6 Experimental Setup Datasets and Evaluation We test the effectiveness of our grammar induction approach on English, Danish, Portuguese, Slovene, Spanish, and Swedish. For English we use the Penn Treebank (Marcus et al., 1993), transformed from CFG parses into depen3Personal communication. dencies with the Collins head finding rules (Collins, 1999); for the other languages we use data from the 2006 CoNLL-X Shared Task (Buchholz and Marsi, 2006). Each dataset provides manually annotated part-of-speech tags that are used for both training and testing. For comparison purposes with previous work, we limit the cross-lingual experiments to sentences of length 10 or less (not counting punctuation). For English, we also explore sentences of length up to 20. The final output metric is directed dependency accuracy. This is computed based on the Viterbi parses produced using the final unnormalized variational distribution q(z) over dependency stru</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-driven statistical models for natural language parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Lyle Campbell</author>
</authors>
<title>A bayesian model for discovering typological implications.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>65--72</pages>
<marker>Daum´e, Campbell, 2007</marker>
<rawString>Hal Daum´e III and Lyle Campbell. 2007. A bayesian model for discovering typological implications. In Proceedings of ACL, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Druck</author>
<author>Gideon Mann</author>
<author>Andrew McCallum</author>
</authors>
<title>Semi-supervised learning of dependency parsers using generalized expectation criteria.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL/IJCNLP,</booktitle>
<pages>360--368</pages>
<contexts>
<context position="5552" citStr="Druck et al., 2009" startWordPosition="798" endWordPosition="801">a diverse range of syntactic phenomenon. Our results demonstrate that universal rules greatly improve the accuracy of dependency parsing across all of these languages, outperforming current stateof-the-art unsupervised grammar induction methods (Headden III et al., 2009; Berg-Kirkpatrick and Klein, 2010). 2 Related Work Learning with Linguistic Constraints Our work is situated within a broader class of unsupervised approaches that employ declarative knowledge to improve learning of linguistic structure (Haghighi and Klein, 2006; Chang et al., 2007; Grac¸a et al., 2007; Cohen and Smith, 2009b; Druck et al., 2009; Liang et al., 2009a). The way we apply constraints is closest to the latter two approaches of posterior regularization and generalized expectation criteria. In the posterior regularization framework, constraints are expressed in the form of expectations on posteriors (Grac¸a et al., 2007; Ganchev et al., 2009; Grac¸a et al., 2009; Ganchev et al., 2010). This design enables the model to reflect constraints that are difficult to encode via the model structure or as priors on its parameters. In their approach, parameters are estimated using a modified EM algorithm, where the E-step minimizes th</context>
<context position="22261" citStr="Druck et al., 2009" startWordPosition="3565" endWordPosition="3568">sal Dependency Rules We compile a set of 13 universal dependency rules consistent with various linguistic accounts (Carnie, 2002; Newmeyer, 2005), shown in Table 1. These rules are defined over coarse part-of-speech tags: Noun, Verb, Adjective, Adverb, Pronoun, Article, Auxiliary, Preposition, Numeral and Conjunction. Each rule specifies a part-of-speech for the head and argument but does not provide ordering information. We require that a minimum proportion of the posterior dependencies be instances of these rules in expectation. In contrast to prior work on rule-driven dependency induction (Druck et al., 2009), where each rule has a separately specified expectation, we only set a single minimum expectation for the proportion of all dependencies that must match one of the rules. This setup is more relevant for learning with universals since individual rule frequencies vary greatly between languages. 1239 1. Identify non-recursive NPs: • All nouns, pronouns and possessive marker are part of an NP. • All adjectives, conjunctions and determiners immediately preceding an NP are part of the NP. 2. The first verb or modal in the sentence is the headword. 3. All words in an NP are headed by the last word i</context>
<context position="30488" citStr="Druck et al. (2009)" startWordPosition="4902" endWordPosition="4905">atest impact on performance when removed. We note the high overlap between the most significant rules for English and Spanish. We also observe that the relationship between a rule’s frequency and its importance for high accuracy is not straightforward. For example, the “Preposition → Noun” rule, whose removal degrades accuracy the most for both English and Span1241 Length &lt; 10 &lt; 20 Universal Dependency Rules 1 HDP-DEP 71.9 50.4 No Rules (Random Init) 2 HDP-DEP 24.9 24.4 3 Headden III et al. (2009) 68.8 - English-Specific Parsing Rules 4 Deterministic (rules only) 70.0 62.6 5 HDP-DEP 73.8 66.1 Druck et al. (2009) Rules 6 Druck et al. (2009) 61.3 - 7 HDP-DEP 64.9 42.2 75 Gold 70 75 80 85 90 Accuracy 70 65 60 55 50 Average English Constraints Threshold Figure 2: Accuracy of our model with different threshold settings, on English only and averaged over all languages. “Gold” refers to the setting where each language’s threshold is set independently to the proportion of gold dependencies satisfying the rules — for English this proportion is 70%, while the average proportion across languages is 63%. ish, is not the most frequent rule in either language. This result suggests that some rules are harder to lea</context>
<context position="35132" citStr="Druck et al., 2009" startWordPosition="5662" endWordPosition="5665">stion is whether it improves upon what the rules encode, especially when the rules are complete and language-specific. We can answer this question by comparing the performance of our model seeded with the English-specific rules against a deterministic parser that implements the same rules. Lines 4 and 5 of Table 6 demonstrate that the model outperforms a rules-only deterministic parser by 3.8% for sentences of length 10 or less and by 3.5% for sentences of length 20 or less. Comparison with Alternative Semi-supervised Parser The dependency parser based on the generalized expectation criteria (Druck et al., 2009) is the closest to our reported work in terms of technique. To compare the two, we run HDP-DEP using the 20 rules given by Druck et al. (2009). Our model achieves an accuracy of 64.9% (line 7) compared to 61.3% (line 6) reported in their work. Note that we do not rely on rule-specific expectation information as they do, instead requiring only a single expectation constraint parameter.4 Model Stability It is commonly acknowledged in the literature that unsupervised grammar induction methods exhibit sensitivity to initialization. As in the previous section, we find that the pres4As explained in </context>
</contexts>
<marker>Druck, Mann, McCallum, 2009</marker>
<rawString>Gregory Druck, Gideon Mann, and Andrew McCallum. 2009. Semi-supervised learning of dependency parsers using generalized expectation criteria. In Proceedings of ACL/IJCNLP, pages 360–368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas S Ferguson</author>
</authors>
<title>A bayesian analysis of some nonparametric problems.</title>
<date>1973</date>
<journal>Annals of Statistics,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="4501" citStr="Ferguson, 1973" startWordPosition="647" endWordPosition="648">ons of the constraints. We formulate a generative Bayesian model that explains the observed data while accounting for declarative linguistic rules during inference. These rules are used as expectation constraints on the posterior distribution over dependency structures. This approach is based on the posterior regularization technique (Grac¸a et al., 2009), which we apply to a variational inference algorithm for our parsing model. Our model can also optionally refine common high-level syntactic categories into per-language categories by inducing a clustering of words using Dirichlet Processes (Ferguson, 1973). Since the universals guide induction toward linguistically plausible structures, automatic refinement becomes feasible even in the absence of manually annotated syntactic trees. We test the effectiveness of our grammar induction model on six Indo-European languages from three language groups: English, Danish, Portuguese, Slovene, Spanish, and Swedish. Though these languages share a high-level Indo-European ancestry, they cover a diverse range of syntactic phenomenon. Our results demonstrate that universal rules greatly improve the accuracy of dependency parsing across all of these languages,</context>
</contexts>
<marker>Ferguson, 1973</marker>
<rawString>Thomas S. Ferguson. 1973. A bayesian analysis of some nonparametric problems. Annals of Statistics, 1(2):209–230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher D Manning</author>
</authors>
<title>The infinite tree.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>272--279</pages>
<contexts>
<context position="7505" citStr="Finkel et al., 2007" startWordPosition="1086" endWordPosition="1089"> significant gains compared to a fully unsupervised counterpart. The constraints they studied are corpus- and languagespecific. Our work demonstrates that a small set of language-independent universals can also serve as effective constraints. Furthermore, we find that our method outperforms the generalized expectation approach using corpus-specific constraints. Learning to Refine Syntactic Categories Recent research has demonstrated the usefulness of automatically refining the granularity of syntactic categories. While most of the existing approaches are implemented in the supervised setting (Finkel et al., 2007; Petrov and Klein, 2007), Liang et al. (2007) propose a non-parametric Bayesian model that learns the granularity of PCFG categories in an unsupervised fashion. For each non-terminal grammar symbol, the model posits a Hierarchical Dirichlet Process over its refinements (subsymbols) to automatically learn the granularity of syntactic categories. As with their work, we also use nonparametric priors for category refinement and em1235 ploy variational methods for inference. However, our goal is to apply category refinement to dependency parsing, rather than to PCFGs, requiring a substantially dif</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2007</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher D. Manning. 2007. The infinite tree. In Proceedings of ACL, pages 272–279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Dependency grammar induction via bitext projection constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL/IJCNLP,</booktitle>
<pages>369--377</pages>
<contexts>
<context position="5864" citStr="Ganchev et al., 2009" startWordPosition="847" endWordPosition="850">elated Work Learning with Linguistic Constraints Our work is situated within a broader class of unsupervised approaches that employ declarative knowledge to improve learning of linguistic structure (Haghighi and Klein, 2006; Chang et al., 2007; Grac¸a et al., 2007; Cohen and Smith, 2009b; Druck et al., 2009; Liang et al., 2009a). The way we apply constraints is closest to the latter two approaches of posterior regularization and generalized expectation criteria. In the posterior regularization framework, constraints are expressed in the form of expectations on posteriors (Grac¸a et al., 2007; Ganchev et al., 2009; Grac¸a et al., 2009; Ganchev et al., 2010). This design enables the model to reflect constraints that are difficult to encode via the model structure or as priors on its parameters. In their approach, parameters are estimated using a modified EM algorithm, where the E-step minimizes the KL-divergence between the model posterior and the set of distributions that satisfies the constraints. Our approach also expresses constraints as expectations on the posterior; we utilize the machinery of their framework within a variational inference algorithm with a mean field approximation. Generalized exp</context>
</contexts>
<marker>Ganchev, Gillenwater, Taskar, 2009</marker>
<rawString>Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar. 2009. Dependency grammar induction via bitext projection constraints. In Proceedings of ACL/IJCNLP, pages 369–377.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Jo˜ao Grac¸a</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2010</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>11--2001</pages>
<marker>Ganchev, Grac¸a, Gillenwater, Taskar, 2010</marker>
<rawString>Kuzman Ganchev, Jo˜ao Grac¸a, Jennifer Gillenwater, and Ben Taskar. 2010. Posterior regularization for structured latent variable models. Journal of Machine Learning Research, 11:2001–2049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo˜ao Grac¸a</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
<author>Fernando Pereira</author>
</authors>
<title>Posterior vs. parameter sparsity in latent variable models.</title>
<date>2009</date>
<booktitle>In Advances in NIPS,</booktitle>
<pages>664--672</pages>
<marker>Grac¸a, Ganchev, Taskar, Pereira, 2009</marker>
<rawString>Jo˜ao Grac¸a, Kuzman Ganchev, Ben Taskar, and Fernando Pereira. 2009. Posterior vs. parameter sparsity in latent variable models. In Advances in NIPS, pages 664– 672.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo˜ao Grac¸a</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
</authors>
<title>Expectation maximization and posterior constraints.</title>
<date>2007</date>
<booktitle>In Advances in NIPS,</booktitle>
<pages>569--576</pages>
<marker>Grac¸a, Ganchev, Taskar, 2007</marker>
<rawString>Jo˜ao Grac¸a, Kuzman Ganchev, and Ben Taskar. 2007. Expectation maximization and posterior constraints. In Advances in NIPS, pages 569–576.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Prototype-driven grammar induction.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>881--888</pages>
<contexts>
<context position="5467" citStr="Haghighi and Klein, 2006" startWordPosition="782" endWordPosition="785"> and Swedish. Though these languages share a high-level Indo-European ancestry, they cover a diverse range of syntactic phenomenon. Our results demonstrate that universal rules greatly improve the accuracy of dependency parsing across all of these languages, outperforming current stateof-the-art unsupervised grammar induction methods (Headden III et al., 2009; Berg-Kirkpatrick and Klein, 2010). 2 Related Work Learning with Linguistic Constraints Our work is situated within a broader class of unsupervised approaches that employ declarative knowledge to improve learning of linguistic structure (Haghighi and Klein, 2006; Chang et al., 2007; Grac¸a et al., 2007; Cohen and Smith, 2009b; Druck et al., 2009; Liang et al., 2009a). The way we apply constraints is closest to the latter two approaches of posterior regularization and generalized expectation criteria. In the posterior regularization framework, constraints are expressed in the form of expectations on posteriors (Grac¸a et al., 2007; Ganchev et al., 2009; Grac¸a et al., 2009; Ganchev et al., 2010). This design enables the model to reflect constraints that are difficult to encode via the model structure or as priors on its parameters. In their approach, </context>
</contexts>
<marker>Haghighi, Klein, 2006</marker>
<rawString>Aria Haghighi and Dan Klein. 2006. Prototype-driven grammar induction. In Proceedings of ACL, pages 881–888.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William P Headden Mark Johnson</author>
<author>David McClosky</author>
</authors>
<title>Improving unsupervised dependency parsing with richer contexts and smoothing.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL/HLT,</booktitle>
<pages>101--109</pages>
<marker>Johnson, McClosky, 2009</marker>
<rawString>William P. Headden III, Mark Johnson, and David McClosky. 2009. Improving unsupervised dependency parsing with richer contexts and smoothing. In Proceedings of NAACL/HLT, pages 101–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher Manning</author>
</authors>
<title>Corpusbased induction of syntactic structure: Models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>478--485</pages>
<contexts>
<context position="11594" citStr="Klein and Manning (2004)" startWordPosition="1734" endWordPosition="1737">ure is formed. Each node of the dependency tree is comprised of three random variables: an observed coarse symbol s, a hidden refined subsymbol z, and an observed word x. In the following let the parent of the current node have symbol s&apos; and subsymbol z&apos;; the root node is generated from separate root-specific distributions. Subsymbol refinement is an optional component of the full model and can be omitted by deterministically equating s and z. As we explain at the end of this section, without this aspect the generative story closely resembles the classic dependency model with valence (DMV) of Klein and Manning (2004). First we draw symbol s from a finite multinomial 1236 s - coarse symbol (observed) z - refined subsymbol x - word (observed) θszc - distr over child coarse symbols for each parent s and z and context c βs - top-level distr over subsymbols for s πssIzIc - distr over subsymbols for each s, parent s&apos; and z&apos;, and context c φsz - distr over words for s and z Figure 1: Graphical representation of the model and a summary of the notation. There is a copy of the outer plate for each distinct symbol in the observed coarse tags. Here, node 3 is shown to be the parent of nodes 1 and 2. Shaded variables </context>
<context position="14343" citStr="Klein and Manning, 2004" startWordPosition="2213" endWordPosition="2216">ol’s subsymbol distribution while allowing for individual variability based on node parent and context. Note that parameters are not shared across different coarse symbols, preserving the distinctions expressed via the coarse tag annotations. Finally, we generate the word x from a finite multinomial with parameters φsz, where s and z are the symbol and subsymbol of the current node. The φ distributions are drawn from a symmetric Dirichlet prior. Generating the Tree Structure We now consider how the structure of the tree arises. We follow an approach similar to the widely-referenced DMV model (Klein and Manning, 2004), which forms the basis of the current state-of-the-art unsupervised grammar induction model (Headden III et al., 2009). After a node is drawn we generate children on each side until we produce a designated STOP symbol. We encode more detailed valence information than Klein and Manning (2004) and condition child generation on parent valence. Specifically, after drawing a node we first decide whether to proceed to generate a child or to stop conditioned on the parent symbol and subsymbol and the current context (direction and valence). If we decide to generate a child we follow the previously d</context>
<context position="26524" citStr="Klein and Manning, 2004" startWordPosition="4262" endWordPosition="4265">owing section we present our primary cross-lingual results using universal rules (Section 7.1) before performing a more in-depth analysis of model properties such as sensitivity to ruleset selection and inference stability (Section 7.2). 1240 DMV PGI No-Split HDP-DEP English 47.1 62.3 71.5 71.9 (0.3) Danish 33.5 41.6 48.8 51.9 (1.6) Portuguese 38.5 63.0 54.0 71.5 (0.5) Slovene 38.5 48.4 50.6 50.9 (5.5) Spanish 28.0 58.4 64.8 67.2 (0.4) Swedish 45.3 58.3 63.3 62.1 (0.5) Table 4: Directed dependency accuracy using our model with universal dependency rules (No-Split and HDPDEP), compared to DMV (Klein and Manning, 2004) and PGI (Berg-Kirkpatrick and Klein, 2010). The DMV results are taken from Berg-Kirkpatrick and Klein (2010). Bold numbers indicate the best result for each language. For the full model, the standard deviation in performance over five runs is indicated in parentheses. 7.1 Main Cross-Lingual Results Table 4 shows the performance of both our full model (HDP-DEP) and its No-Split version using universal dependency rules across six languages. We also provide the performance of two baselines — the dependency model with valence (DMV) (Klein and Manning, 2004) and the phylogenetic grammar induction </context>
<context position="36125" citStr="Klein and Manning, 2004" startWordPosition="5828" endWordPosition="5831">straint parameter.4 Model Stability It is commonly acknowledged in the literature that unsupervised grammar induction methods exhibit sensitivity to initialization. As in the previous section, we find that the pres4As explained in Section 5, having a single expectation parameter is motivated by our focus on parsing with universal rules. ence of linguistic rules greatly reduces this sensitivity: for HDP-DEP, the standard deviation over five randomly initialized runs with the English-specific rules is 1.5%, compared to 4.5% for the parser developed by Headden III et al. (2009) and 8.0% for DMV (Klein and Manning, 2004). 8 Conclusions In this paper we demonstrated that syntactic universals encoded as declarative constraints improve grammar induction. We formulated a generative model for dependency structure that models syntactic category refinement and biases inference to cohere with the provided constraints. Our experiments showed that encoding a compact, well-accepted set of language-independent constraints significantly improves accuracy on multiple languages compared to the current state-of-the-art in unsupervised parsing. While our present work has yielded substantial gains over previous unsupervised me</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>Dan Klein and Christopher Manning. 2004. Corpusbased induction of syntactic structure: Models of dependency and constituency. In Proceedings of ACL, pages 478–485.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonas Kuhn</author>
</authors>
<title>Experiments in parallel-text based grammar induction.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>470--477</pages>
<contexts>
<context position="1582" citStr="Kuhn, 2004" startWordPosition="216" endWordPosition="217">s state-of-theart unsupervised methods by a significant margin.1 1 Introduction Despite surface differences, human languages exhibit striking similarities in many fundamental aspects of syntactic structure. These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing. In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). 1The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/ Root —* Auxiliary Noun —* Adjective Root —* Verb Noun —* Article Verb —* Noun Noun —* Noun Verb —* Pronoun Noun —* Numeral Verb —* Adverb Preposition —* Noun Verb —* Verb Adjective —* Adverb Auxiliary —* Verb Table 1: The manually-specified universal dependency rules used in our experiments. These rules specify headdependent relationships between coarse (i.e., unsplit) sy</context>
<context position="8386" citStr="Kuhn, 2004" startWordPosition="1218" endWordPosition="1219">(subsymbols) to automatically learn the granularity of syntactic categories. As with their work, we also use nonparametric priors for category refinement and em1235 ploy variational methods for inference. However, our goal is to apply category refinement to dependency parsing, rather than to PCFGs, requiring a substantially different model formulation. While Liang et al. (2007) demonstrated empirical gains on a synthetic corpus, our experiments focus on unsupervised category refinement on real language data. Universal Rules in NLP Despite the recent surge of interest in multilingual learning (Kuhn, 2004; Cohen and Smith, 2009a; Snyder et al., 2009; BergKirkpatrick and Klein, 2010), there is surprisingly little computational work on linguistic universals. On the acquisition side, Daum´e III and Campbell (2007) proposed a computational technique for discovering universal implications in typological features. More closely related to our work is the position paper by Bender (2009), which advocates the use of manually-encoded cross-lingual generalizations for the development of NLP systems. She argues that a system employing such knowledge could be easily adapted to a particular language by speci</context>
</contexts>
<marker>Kuhn, 2004</marker>
<rawString>Jonas Kuhn. 2004. Experiments in parallel-text based grammar induction. In Proceedings of ACL, pages 470–477.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Slav Petrov</author>
<author>Michael Jordan</author>
<author>Dan Klein</author>
</authors>
<title>The infinite PCFG using hierarchical Dirichlet processes.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP/CoNLL,</booktitle>
<pages>688--697</pages>
<contexts>
<context position="7551" citStr="Liang et al. (2007)" startWordPosition="1094" endWordPosition="1097">vised counterpart. The constraints they studied are corpus- and languagespecific. Our work demonstrates that a small set of language-independent universals can also serve as effective constraints. Furthermore, we find that our method outperforms the generalized expectation approach using corpus-specific constraints. Learning to Refine Syntactic Categories Recent research has demonstrated the usefulness of automatically refining the granularity of syntactic categories. While most of the existing approaches are implemented in the supervised setting (Finkel et al., 2007; Petrov and Klein, 2007), Liang et al. (2007) propose a non-parametric Bayesian model that learns the granularity of PCFG categories in an unsupervised fashion. For each non-terminal grammar symbol, the model posits a Hierarchical Dirichlet Process over its refinements (subsymbols) to automatically learn the granularity of syntactic categories. As with their work, we also use nonparametric priors for category refinement and em1235 ploy variational methods for inference. However, our goal is to apply category refinement to dependency parsing, rather than to PCFGs, requiring a substantially different model formulation. While Liang et al. (</context>
</contexts>
<marker>Liang, Petrov, Jordan, Klein, 2007</marker>
<rawString>Percy Liang, Slav Petrov, Michael Jordan, and Dan Klein. 2007. The infinite PCFG using hierarchical Dirichlet processes. In Proceedings of EMNLP/CoNLL, pages 688–697.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning from measurements in exponential families.</title>
<date>2009</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>641--648</pages>
<contexts>
<context position="5572" citStr="Liang et al., 2009" startWordPosition="802" endWordPosition="805">yntactic phenomenon. Our results demonstrate that universal rules greatly improve the accuracy of dependency parsing across all of these languages, outperforming current stateof-the-art unsupervised grammar induction methods (Headden III et al., 2009; Berg-Kirkpatrick and Klein, 2010). 2 Related Work Learning with Linguistic Constraints Our work is situated within a broader class of unsupervised approaches that employ declarative knowledge to improve learning of linguistic structure (Haghighi and Klein, 2006; Chang et al., 2007; Grac¸a et al., 2007; Cohen and Smith, 2009b; Druck et al., 2009; Liang et al., 2009a). The way we apply constraints is closest to the latter two approaches of posterior regularization and generalized expectation criteria. In the posterior regularization framework, constraints are expressed in the form of expectations on posteriors (Grac¸a et al., 2007; Ganchev et al., 2009; Grac¸a et al., 2009; Ganchev et al., 2010). This design enables the model to reflect constraints that are difficult to encode via the model structure or as priors on its parameters. In their approach, parameters are estimated using a modified EM algorithm, where the E-step minimizes the KL-divergence betw</context>
<context position="20020" citStr="Liang et al., 2009" startWordPosition="3196" endWordPosition="3199"> minimization problem of the form: q(β, θ, π, φ, z) q(z) = argmin q(z) q(βs0) &apos; q(φs0z0)&apos; T H z0=1 KL(q(z) 11 q0(z)). Thus we first compute the update for q0(z): H= q(z) &apos; s0 H q(θs0z0c) &apos; H q(πss0z0c), (7) c s where s0 varies over the set of unique symbols in the observed tags, z0 denotes subsymbols for each symbol, c varies over context values comprising a pair of direction (left or right) and valence (first, second, or third or higher) values, and s corresponds to child symbols. We restrict q(θs0z0c) and q(φs0z0) to be Dirichlet distributions and q(z) to be multinomial. As with prior work (Liang et al., 2009b), we assume a degenerate q(β) - δ0∗(β) for tractability reasons, i.e., all mass is concentrated on some single β∗. We also assume that the top level stick-breaking distribution is truncated at T, i.e., q(β) assigns zero probability to integers greater than T. Because of the truncation of β, we can approximate q(πss0z0c) with an asymmetric finite dimensional Dirichlet. The factors are updated one at a time holding all other factors fixed. The variational update for q(π) is given by: q(πss0z0c) = Dir (πss0z0c; αβ + Eq(z)[Css0z0c(z)]) , where term Eq(z)[Css0z0c(z)] is the expected count w.r.t. </context>
<context position="21607" citStr="Liang et al. (2009" startWordPosition="3467" endWordPosition="3470">xt c and Cs0z0x is the count of word x being generated by symbol s0 and subsymbol z0. N len(n) q0(z) a H H (exp Eq(0)[log φsnjznj(xnj)] n=1 j=1 x exp Eq(B)[log θsh(nj)zh(nj)cnj(snj)] x exp Eq(7r)[log πsnjsh(nj)zh(nj)cnj(znj)]), where N is the total number of sentences, len(n) is the length of sentence n, and index h(nj) refers to the head of the jth node of sentence n. Given this q0(z) a gradient search is performed using (6) to find the optimal λ and thus the primal solution for updating q(z). Finally, we update the degenerate factor q(βs) with the projected gradient search algorithm used by Liang et al. (2009b). 5 Linguistic Constraints Universal Dependency Rules We compile a set of 13 universal dependency rules consistent with various linguistic accounts (Carnie, 2002; Newmeyer, 2005), shown in Table 1. These rules are defined over coarse part-of-speech tags: Noun, Verb, Adjective, Adverb, Pronoun, Article, Auxiliary, Preposition, Numeral and Conjunction. Each rule specifies a part-of-speech for the head and argument but does not provide ordering information. We require that a minimum proportion of the posterior dependencies be instances of these rules in expectation. In contrast to prior work on</context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>Percy Liang, Michael I. Jordan, and Dan Klein. 2009a. Learning from measurements in exponential families. In Proceedings of ICML, pages 641–648.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Probabilistic grammars and hierarchical Dirichlet processes. The Handbook of Applied Bayesian Analysis.</title>
<date>2009</date>
<contexts>
<context position="5572" citStr="Liang et al., 2009" startWordPosition="802" endWordPosition="805">yntactic phenomenon. Our results demonstrate that universal rules greatly improve the accuracy of dependency parsing across all of these languages, outperforming current stateof-the-art unsupervised grammar induction methods (Headden III et al., 2009; Berg-Kirkpatrick and Klein, 2010). 2 Related Work Learning with Linguistic Constraints Our work is situated within a broader class of unsupervised approaches that employ declarative knowledge to improve learning of linguistic structure (Haghighi and Klein, 2006; Chang et al., 2007; Grac¸a et al., 2007; Cohen and Smith, 2009b; Druck et al., 2009; Liang et al., 2009a). The way we apply constraints is closest to the latter two approaches of posterior regularization and generalized expectation criteria. In the posterior regularization framework, constraints are expressed in the form of expectations on posteriors (Grac¸a et al., 2007; Ganchev et al., 2009; Grac¸a et al., 2009; Ganchev et al., 2010). This design enables the model to reflect constraints that are difficult to encode via the model structure or as priors on its parameters. In their approach, parameters are estimated using a modified EM algorithm, where the E-step minimizes the KL-divergence betw</context>
<context position="20020" citStr="Liang et al., 2009" startWordPosition="3196" endWordPosition="3199"> minimization problem of the form: q(β, θ, π, φ, z) q(z) = argmin q(z) q(βs0) &apos; q(φs0z0)&apos; T H z0=1 KL(q(z) 11 q0(z)). Thus we first compute the update for q0(z): H= q(z) &apos; s0 H q(θs0z0c) &apos; H q(πss0z0c), (7) c s where s0 varies over the set of unique symbols in the observed tags, z0 denotes subsymbols for each symbol, c varies over context values comprising a pair of direction (left or right) and valence (first, second, or third or higher) values, and s corresponds to child symbols. We restrict q(θs0z0c) and q(φs0z0) to be Dirichlet distributions and q(z) to be multinomial. As with prior work (Liang et al., 2009b), we assume a degenerate q(β) - δ0∗(β) for tractability reasons, i.e., all mass is concentrated on some single β∗. We also assume that the top level stick-breaking distribution is truncated at T, i.e., q(β) assigns zero probability to integers greater than T. Because of the truncation of β, we can approximate q(πss0z0c) with an asymmetric finite dimensional Dirichlet. The factors are updated one at a time holding all other factors fixed. The variational update for q(π) is given by: q(πss0z0c) = Dir (πss0z0c; αβ + Eq(z)[Css0z0c(z)]) , where term Eq(z)[Css0z0c(z)] is the expected count w.r.t. </context>
<context position="21607" citStr="Liang et al. (2009" startWordPosition="3467" endWordPosition="3470">xt c and Cs0z0x is the count of word x being generated by symbol s0 and subsymbol z0. N len(n) q0(z) a H H (exp Eq(0)[log φsnjznj(xnj)] n=1 j=1 x exp Eq(B)[log θsh(nj)zh(nj)cnj(snj)] x exp Eq(7r)[log πsnjsh(nj)zh(nj)cnj(znj)]), where N is the total number of sentences, len(n) is the length of sentence n, and index h(nj) refers to the head of the jth node of sentence n. Given this q0(z) a gradient search is performed using (6) to find the optimal λ and thus the primal solution for updating q(z). Finally, we update the degenerate factor q(βs) with the projected gradient search algorithm used by Liang et al. (2009b). 5 Linguistic Constraints Universal Dependency Rules We compile a set of 13 universal dependency rules consistent with various linguistic accounts (Carnie, 2002; Newmeyer, 2005), shown in Table 1. These rules are defined over coarse part-of-speech tags: Noun, Verb, Adjective, Adverb, Pronoun, Article, Auxiliary, Preposition, Numeral and Conjunction. Each rule specifies a part-of-speech for the head and argument but does not provide ordering information. We require that a minimum proportion of the posterior dependencies be instances of these rules in expectation. In contrast to prior work on</context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>Percy Liang, Michael I. Jordan, and Dan Klein. 2009b. Probabilistic grammars and hierarchical Dirichlet processes. The Handbook of Applied Bayesian Analysis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="24051" citStr="Marcus et al., 1993" startWordPosition="3876" endWordPosition="3879">inistic parsing, shown in Table 3. Unlike the universals from Table 1, these rules alone are enough to construct a full dependency tree. Thus they allow us to judge whether the model is able to improve upon a human-engineered deterministic parser. Moreover, with this dataset we can assess the additional benefit of using rules tailored to an individual language as opposed to universal rules. 6 Experimental Setup Datasets and Evaluation We test the effectiveness of our grammar induction approach on English, Danish, Portuguese, Slovene, Spanish, and Swedish. For English we use the Penn Treebank (Marcus et al., 1993), transformed from CFG parses into depen3Personal communication. dencies with the Collins head finding rules (Collins, 1999); for the other languages we use data from the 2006 CoNLL-X Shared Task (Buchholz and Marsi, 2006). Each dataset provides manually annotated part-of-speech tags that are used for both training and testing. For comparison purposes with previous work, we limit the cross-lingual experiments to sentences of length 10 or less (not counting punctuation). For English, we also explore sentences of length up to 20. The final output metric is directed dependency accuracy. This is c</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick J Newmeyer</author>
</authors>
<title>Possible and Probable Languages: A Generative Perspective on Linguistic Typology.</title>
<date>2005</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="1351" citStr="Newmeyer, 2005" startWordPosition="184" endWordPosition="185">raints to require that a minimum proportion of the dependencies we infer be instances of these rules. We also automatically refine the syntactic categories given in our coarsely tagged input. Across six languages our approach outperforms state-of-theart unsupervised methods by a significant margin.1 1 Introduction Despite surface differences, human languages exhibit striking similarities in many fundamental aspects of syntactic structure. These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing. In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). 1The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/ Root —* Auxiliary Noun —* Adjective Root —* Verb Noun —* Article Verb —* Noun Noun —* Noun Verb —* Pronoun Noun —* Numeral Verb —* Adverb Prepo</context>
<context position="21787" citStr="Newmeyer, 2005" startWordPosition="3494" endWordPosition="3495">x exp Eq(7r)[log πsnjsh(nj)zh(nj)cnj(znj)]), where N is the total number of sentences, len(n) is the length of sentence n, and index h(nj) refers to the head of the jth node of sentence n. Given this q0(z) a gradient search is performed using (6) to find the optimal λ and thus the primal solution for updating q(z). Finally, we update the degenerate factor q(βs) with the projected gradient search algorithm used by Liang et al. (2009b). 5 Linguistic Constraints Universal Dependency Rules We compile a set of 13 universal dependency rules consistent with various linguistic accounts (Carnie, 2002; Newmeyer, 2005), shown in Table 1. These rules are defined over coarse part-of-speech tags: Noun, Verb, Adjective, Adverb, Pronoun, Article, Auxiliary, Preposition, Numeral and Conjunction. Each rule specifies a part-of-speech for the head and argument but does not provide ordering information. We require that a minimum proportion of the posterior dependencies be instances of these rules in expectation. In contrast to prior work on rule-driven dependency induction (Druck et al., 2009), where each rule has a separately specified expectation, we only set a single minimum expectation for the proportion of all d</context>
</contexts>
<marker>Newmeyer, 2005</marker>
<rawString>Frederick J. Newmeyer. 2005. Possible and Probable Languages: A Generative Perspective on Linguistic Typology. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Learning and inference for hierarchically split PCFGs.</title>
<date>2007</date>
<booktitle>In Proceeding of AAAI,</booktitle>
<pages>1663--1666</pages>
<contexts>
<context position="7530" citStr="Petrov and Klein, 2007" startWordPosition="1090" endWordPosition="1093">mpared to a fully unsupervised counterpart. The constraints they studied are corpus- and languagespecific. Our work demonstrates that a small set of language-independent universals can also serve as effective constraints. Furthermore, we find that our method outperforms the generalized expectation approach using corpus-specific constraints. Learning to Refine Syntactic Categories Recent research has demonstrated the usefulness of automatically refining the granularity of syntactic categories. While most of the existing approaches are implemented in the supervised setting (Finkel et al., 2007; Petrov and Klein, 2007), Liang et al. (2007) propose a non-parametric Bayesian model that learns the granularity of PCFG categories in an unsupervised fashion. For each non-terminal grammar symbol, the model posits a Hierarchical Dirichlet Process over its refinements (subsymbols) to automatically learn the granularity of syntactic categories. As with their work, we also use nonparametric priors for category refinement and em1235 ploy variational methods for inference. However, our goal is to apply category refinement to dependency parsing, rather than to PCFGs, requiring a substantially different model formulation.</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Learning and inference for hierarchically split PCFGs. In Proceeding of AAAI, pages 1663–1666.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Tahira Naseem</author>
<author>Regina Barzilay</author>
</authors>
<title>Unsupervised multilingual grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL/IJCNLP,</booktitle>
<pages>73--81</pages>
<contexts>
<context position="1652" citStr="Snyder et al., 2009" startWordPosition="226" endWordPosition="229">n.1 1 Introduction Despite surface differences, human languages exhibit striking similarities in many fundamental aspects of syntactic structure. These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing. In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). 1The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/ Root —* Auxiliary Noun —* Adjective Root —* Verb Noun —* Article Verb —* Noun Noun —* Noun Verb —* Pronoun Noun —* Numeral Verb —* Adverb Preposition —* Noun Verb —* Verb Adjective —* Adverb Auxiliary —* Verb Table 1: The manually-specified universal dependency rules used in our experiments. These rules specify headdependent relationships between coarse (i.e., unsplit) syntactic categories. An explanation of the ruleset is provided in Secti</context>
<context position="8431" citStr="Snyder et al., 2009" startWordPosition="1225" endWordPosition="1228">the granularity of syntactic categories. As with their work, we also use nonparametric priors for category refinement and em1235 ploy variational methods for inference. However, our goal is to apply category refinement to dependency parsing, rather than to PCFGs, requiring a substantially different model formulation. While Liang et al. (2007) demonstrated empirical gains on a synthetic corpus, our experiments focus on unsupervised category refinement on real language data. Universal Rules in NLP Despite the recent surge of interest in multilingual learning (Kuhn, 2004; Cohen and Smith, 2009a; Snyder et al., 2009; BergKirkpatrick and Klein, 2010), there is surprisingly little computational work on linguistic universals. On the acquisition side, Daum´e III and Campbell (2007) proposed a computational technique for discovering universal implications in typological features. More closely related to our work is the position paper by Bender (2009), which advocates the use of manually-encoded cross-lingual generalizations for the development of NLP systems. She argues that a system employing such knowledge could be easily adapted to a particular language by specializing this high level knowledge based on th</context>
</contexts>
<marker>Snyder, Naseem, Barzilay, 2009</marker>
<rawString>Benjamin Snyder, Tahira Naseem, and Regina Barzilay. 2009. Unsupervised multilingual grammar induction. In Proceedings of ACL/IJCNLP, pages 73–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lydia White</author>
</authors>
<title>Second Language Acquisition and Universal Grammar.</title>
<date>2003</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1334" citStr="White, 2003" startWordPosition="182" endWordPosition="183">ctation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules. We also automatically refine the syntactic categories given in our coarsely tagged input. Across six languages our approach outperforms state-of-theart unsupervised methods by a significant margin.1 1 Introduction Despite surface differences, human languages exhibit striking similarities in many fundamental aspects of syntactic structure. These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing. In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010). 1The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/ Root —* Auxiliary Noun —* Adjective Root —* Verb Noun —* Article Verb —* Noun Noun —* Noun Verb —* Pronoun Noun —* Numeral Ver</context>
</contexts>
<marker>White, 2003</marker>
<rawString>Lydia White. 2003. Second Language Acquisition and Universal Grammar. Cambridge University Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>