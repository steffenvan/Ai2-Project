<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006214">
<title confidence="0.986155">
Criteria for Measuring Term Recognition
</title>
<author confidence="0.996047">
Andy Lauriston
</author>
<affiliation confidence="0.998713">
Department of Languages and Linguistics
University of Manchester Institute of Science and Technology
</affiliation>
<address confidence="0.965109">
P.O. Box 88
Manchester M60 1QD
United Kingdom
</address>
<email confidence="0.911959">
andyl©ccl.umist.ac.uk
</email>
<sectionHeader confidence="0.997911" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999937">
This paper qualifies what a true term-
recognition systems would have to recog-
nize. The exact bracketing of the maximal
termform is then proposed as an achieve-
able goal upon which current system per-
formance should be measured. How recall
and precision metrics are best adapted for
measuring term recognition is suggested.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999721169811321">
In recent years, the automatic extraction of terms
from running text has become a subject of grow-
ing interest. Practical applications such as dictio-
nary, lexicon and thesaurus construction and main-
tenance, automatic indexing and machine transla-
tion have fuelled this interest. Given that concerns
in automatic term recognition are practical, rather
than theoretical, the lack of serious performance
measurements in the published literature is surpris-
ing.
Accounts of term-recognition systems sometimes
consist of a purely descriptive statement of the ad-
vantages of a particular approach and make no at-
tempt to measure the pay-off the proposed approach
yields (David, 1990). Others produce partial fig-
ures without any clear statement of how they are
derived (Otman, 1991). One of the best efforts to
quantify the performance of a term-recognition sys-
tem (Smadja, 1993) does so only for one processing
stage, leaving unassessed the text-to-output perfor-
mance of the system.
While most automatic term-recognition systems
developed to date have been experimental or in-
house ones, a few systems like TermCruncher (Nor-
mand, 1993) are now being marketed. Both the
developers and users of such systems would benefit
greatly by clearly qualifying what each system aims
to achieve, and precisely quantifying how closely the
system comes to achieving its stated aim.
Before discussing what a term-recognition system
should be expected to recognize and how perfor-
mance in recognition should be measured, two un-
denying premises should be made clear. Firstly,
the automatic system is designed to recognize seg-
ments of text that, conventionally, have been man-
ually identified by a terminologist, indexer, lexicog-
rapher or other trained individual. Secondly, the
performance of automatic term-recognition systems
is best measured against human performance for the
same task. These premises mean that for any given
application - terminological standardization and vo-
cabulary compilation being the focus here - it is pos-
sible to measure the performance of an automatic
term-recognition system, and the best yardstick for
doing so is human performance.
Section 2 below draws on the theory of terminol-
ogy in order to qualify what a true term-recognition
system must achieve and what, in the short term,
such systems can be expected to achieve. Section
3 specifies how the established ratios used in infor-
mation retrieval - recall and precision - can best be
adapted for measuring the recognition of single- and
multi-word noun terms.
</bodyText>
<sectionHeader confidence="0.692425" genericHeader="method">
2 What is to be Recognized?
</sectionHeader>
<bodyText confidence="0.99864925">
Depending upon the meaning given to the expres-
sion &amp;quot;term recognition&amp;quot;, it can be viewed as either a
rather trivial, low-level processing task or one that
is impossible to automate. A limited form of term
recognition has been achieved using current tech-
niques (Perron, 1991; Bourigault, 1994; Normand,
1993). To appreciate what current limitations are
and what would be required to achieve full term
recognition, it is useful to draw the distinction be-
tween &amp;quot;term&amp;quot; and &amp;quot;termform&amp;quot; on the one hand, and
&amp;quot;term recognition&amp;quot; and &amp;quot;term interpretation&amp;quot; on the
other.
</bodyText>
<subsectionHeader confidence="0.987681">
2.1 Term vs Termform
</subsectionHeader>
<bodyText confidence="0.986310833333333">
Particularly in the computing community, there is a
tendency to consider &amp;quot;terms&amp;quot; as strictly formal en-
tities. Although usage among terminologists varies,
a term is generally accepted as being the &amp;quot;designa-
tion of a defined concept in a special language by a
linguistic expression&amp;quot; (ISO, 1988). A term is hence
</bodyText>
<page confidence="0.994555">
17
</page>
<figure confidence="0.9917805">
I Concept I
I I I I
I I I TERM I I I
I Ternd oral I
</figure>
<figureCaption confidence="0.999966">
Figure 1: Term vs Termform
</figureCaption>
<bodyText confidence="0.997798976744186">
the intersection between a conceptual realm (a de-
fined semantic content) and a linguistic realm (an
expression or termform) as illustrated in Figure 1.
A term, thus conceived, cannot be polysemous al-
though termforms can, and often do, 11 aye several
meanings. As terms precisely defined in information
processing, &amp;quot;virus&amp;quot; and &amp;quot;Trojan Horse&amp;quot; are unam-
biguous; as termforms they have other meanings in
medicine and Greek mythology respectively.
This view of a term has one very important con-
sequence when discussing term recognition. Firstly,
term recognition cannot be carried out on purely
formal grounds. It requires some level of linguis-
tic analysis. Indeed, two term-formation processes
do not result in new termforms: conversion and
semantic drift&apos;. A third term-formation process,
compression, can also result in a new meaning be-
ing associated with an existing termform2.
Proper attention to capitalization can generally
result in the correct recognition of compressed forms.
Part-of-speech tagging is required to detect new
terms formed through conversion. This is quite
feasible using statistical taggers like those of Gar-
side (1987), Church (1988) or Foster (1991) which
achieve performance upwards of 97% on unrestricted
text. Terms formed through semantic drift are the
wolves in sheep&apos;s clothing stealing through termino-
logical pastures. They are well enough concealed to
allude at times even the human reader and no au-
tomatic term-recognition system has attempted to
distinguish such terms, despite the prevalence of pol-
ysemy in such fields as the social sciences (Riggs,
1993) and the importance for purposes of termi-
nological standardization that &amp;quot;deviant&amp;quot; usage be
tracked. Implementing a system to distinguish new
&apos;Conversion occurs when a term is formed by a
change in grammatical category. Verb-to-noun conver-
sion commonly occurs for commands in programming or
word processing (e.g. Undelete works if you catch your
mistake quickly). Semantic drift involves a (sometimes
subtle) change in meaning without any change in gram-
matical category (viz. &amp;quot;term&amp;quot; as understood in this pa-
pr vs th.- lonse wage of &amp;quot;i■-rm&amp;quot; to mean &amp;quot;termform&amp;quot;).
</bodyText>
<footnote confidence="0.7132085">
2Compression is the shortening of (usually complex)
termforms to form acronyms or other initialisms. Thus
PAD can either designate a resistive loss in an electrical
circuit or a &amp;quot;packet assembler-disassembler&amp;quot;.
</footnote>
<bodyText confidence="0.993905888888889">
meanings of established termforms would require an-
alyzing discourse-level clues that an author is assign-
ing a new meaning, and possibly require the appli-
cation of pragmatic knowledge. Until such advanced
levels of analysis can be practically implemented,
&amp;quot;term recognition&amp;quot; will largely remain &amp;quot;termform
recognition&amp;quot; and the failure to detect new terms in
old termforms will remain a qualitative shortcoming
of all term-recognition systems.
</bodyText>
<subsectionHeader confidence="0.735831">
2.2 Term Recognition vs Term
Interpretation
</subsectionHeader>
<bodyText confidence="0.999610130434783">
The vast majority of terms in published technical
dictionaries and terminology standards are nouns.
Furthermore, most terms have a complex termform,
i.e. they are comprised of more than one word.
Sublanguages create series of complex termforms in
which complex forms serve as modifiers (natural lan-
guage = [natural language] processing) and/or are
themselves modified (applied [[naivral language] pro-
cessing]). In special language, complex termforms
containing nested termforms, or significant subex-
pressions (Baudot, 1984), have hundreds of possi-
ble syntagmatic structures (Portelance, 1989; Lau-
riston, 1993). The challenge facing developers of
term-recognition systems consists in determining the
syntactic and conceptual unity that complex nomi-
nals must possess in order to achieve termhood 3.
Another, and it will be argued far more ambitious,
undertaking is term interpretation. Leonard
(1984), Finen (1985) and others have attempted to
devise systems that can produce a gloss explicat-
ing the semantic relationship that holds between the
constituents of complex nominals (e.g. family es-
tate estate owned by a family). Such attempts
at achieving even limited &amp;quot;interpretation&amp;quot; result in
large sets of possible relationships but fail to ac-
count for all compounds. Furthermore, they have
generally been restricted to termforms with two con-
stituents. For complex termforms with three or more
constituents, merely identifying how constituents are
nested, i.e., between which constituents there exists
a semantic relationship, can be difficult to automate
(Sparck-Jones, 1985).
In most cases, however, term recognition can be
achieved without interpreting the meaning of the
term and without analyzing the internal structure
of complex termforms. Many term-recognition sys-
tems like TERMINO (David, 1990), the noun-phrase
detector of LOGOS (Logos, 1987), LEXTER (Bouri-
gault, 1994), etc., nevertheless attempt to recognize
nested termforms. Encountering &amp;quot;automatic protec-
tion switching equipment&amp;quot;, systems adopting this
2In this respect, complex termforms, unlike colloca-
tions, must designate definable nodes of the conceptual
system of an area of specialized human activity. Hence
general trend may be as strong a collocation as general
election, and yet only the latter be considered a term.
</bodyText>
<page confidence="0.995209">
18
</page>
<bodyText confidence="0.969004448275862">
approach would produce as output several nested
termforms (switching equipment, protection switch-
ing, protection switching equipment, automatic pro-
tection,automatic protection switching) as well as
the maximal termform automatic protection switch-
ing equipment. Because such systems list nested
termforms in the absence of higher-level analysis,
many erroneous &amp;quot;terms&amp;quot; are generated.
It has been argued previously on pragmatic
grounds (Lauriston, 1994) that a safer approach is
to detect only the maximal termform. It could
further be said that doing so is theoretically sound.
Nesting termforms is a means by which an author
achieves transparency. Once nested, however, a
termform no longer fulfills the naming function. It
serves as a mnemonic device. In different languages,
different nested termforms are sometimes selected to
perform this mnemonic function (e.g. on-line credit
card checking, for which a documented French equiv-
alent is verification de credit au point de vente, lit-
erally &amp;quot;point-of-sale credit verification&amp;quot;). Only the
maximal termform refers to the designated concept
and thus only recognition of the maximal termform
constitutes term recognition4.
Term interpretation may be required, however., to
correctly delimit complex termforms combined by
means of conjunctions. Consider the following three
conjunctive expressions taken from telecommunica-
tion texts:
</bodyText>
<listItem confidence="0.9510805">
(1) buffer content and packet delay distributions
(2) mean misframe and frame detection times
(3) generalized intersymbol-interference and jitter-
free modulated signals
</listItem>
<bodyText confidence="0.984388361702128">
Even the uninitiated reader would probably be in-
clined to interpret, correctly, that expression (1) is a
combination of two complex termforms: buffer con-
tent distribution and packet delay distribution. Syn-
tax or coarse semantics do nothing, however, to pre-
vent an incorrect reading: buffer content delay dis-
tribution and buffer packet delay distribution. Ex-
pression (2) consists of words having the same se-
quence of grammatical categories as expression (1),
but in which this second reading is, in fact, correct:
mean misframe detection time and mean frame de-
tection time. Although rather similar to the first
two, conjunctive expression (3) is a single term,
sometimes designated by the initialism CLIP.
Complex termforms appearing in conjunctive ex-
pressions may thus require term interpretation for
proper term recognition, i.e. reconstructing the con-
juncts. If term recognition is to be carried out inde-
pendently of and prior to term interpretation, as is
4This does not imply that analyzing the internal
structure of complex termforms is valueless. It has the
very important, but distinct, value of providing clues to
paradigmatic relationships between terms.
presently feasible, then it can only be properly seen
as &amp;quot;maximal termform recognition&amp;quot; with the mean-
ing of &amp;quot;maximal termform&amp;quot; extended to include the
outermost bracketing of structurally ambiguous con-
junctive expressions like the three examples above.
This extension in meaning is not a matter of theo-
retical soundness but simply of practical necessity.
In summary, current systems recognise termforms
but lack mechanisms to detect new terms resulting
from several term-formation processes, particularly
semantic drift. Under these circumstances, it is best
to admit that &amp;quot;termform recognition&amp;quot; is the cur-
rently feasible objective and to measure performance
in achieving it. Furthermore, since the nested struc-
tures of complex termforms perform a mnemonic
rather than a naming function, it is theoretically un-
sound for an automatic term-recognition system to
present them as terms. For purposes of measurement
and comparison, &amp;quot;term recognition&amp;quot; should thus be
regarded as &amp;quot;maximal termform recognition&amp;quot;. Once
this goal has been reliably achieved, the output of
a term-recognition system could feed a future &amp;quot;term
interpreter&amp;quot;, that would also be required to recog-
nize terms in ambiguous conjunctive expressions.
</bodyText>
<sectionHeader confidence="0.9961275" genericHeader="method">
3 How Can Recognition be
Measured?
</sectionHeader>
<bodyText confidence="0.99996175">
Once a consensus has been reached about what is to
be recognized, there must be some agreement con-
cerning the way in which performance is to be mea-
sured. Fortunately, established performance mea-
surements used in information retrieval - recall and
precision - can be adapted quite readily for mea-
suring the term-recognition task. These measures
have, in fact, been used previously in measuring
term recognition (Smadja, 1993; Bourigault, 1994;
Lauriston, 1994). No study, however, adequately
discusses how these measurements are applied to
term recognition.
</bodyText>
<subsectionHeader confidence="0.998904">
3.1 Recall and Precision
</subsectionHeader>
<bodyText confidence="0.999937352941177">
Traditionally, performance in document retrieval is
measured by means of a few simple ratios (Salton,
1989). These are based on the premise that any
given document in a collection is either pertinent or
non-pertinent to a particular user&apos;s needs. There
is no scale of relative pertinence. For a given user
query, retrieving a pertinent document constitutes a
hit, failing to retrieve a pertinent document consti-
tutes a miss, and retrieving a non-pertinent docu-
ment constitutes a false hit. Recall, the ratio of
the number of hits to the number of pertinent doc-
uments in the collection, measures the effectiveness
of retrieval. Precision, the ratio of the number of
hits to the number of retrieved documents, measures
the efficiency of retrieval. The complement of recall
is omission (misses/total pertinent). The comple-
ment of precision is noise (false hits/total retrieved).
</bodyText>
<page confidence="0.996294">
19
</page>
<bodyText confidence="0.996760666666667">
Ideally, recall and precision would equal 1.0, omis-
sion and noise 0.0. Practical document retrieval in-
volves a trade-off between recall and precision.
The performance measurements in document re-
trieval are quite apparently applicable to term recog-
nition. The basic premise of a pertinent/non-
pertinent dichotomy, which prevails in document re-
trieval, is probably even better justified for terms
than for documents. Unlike an evaluation of
the pertinence of the content of a document, the
term/nonterm distinction is based on a relatively
simple and cohesive semantic content5.User judge-
ments of document pertinence would appear to be
much more subjective and difficult to quantify.
If all termforms were simple, i.e. single words,
and only simple termforms were recognized, then us-
ing document retrieval measurements would be per-
fectly straightforward. A manually bracketed term
would give rise to a hit or a miss and an automati-
cally recognized word would be a hit or a false hit.
Since complex termforms are prevalent in sublan-
guage texts, however, further clarification is neces-
sary. In particular, &amp;quot;hit&amp;quot; has to be defined more
precisely. Consider the following sentence:
The latest committee draft reports progress toward
constitutional reform.
A terminologist would probably recognize two
terms in this sentence: committee draft and consti-
tutional reform. The termform of each is complex.
Regardless of whether symbolic or statistical tech-
niques are used, &amp;quot;hits&amp;quot; of debatable usefulness are
apt to be produced by automatic term-recognition
systems. A syntactically based system might have
particular difficulty with the three consecutive cases
of noun-verb ambiguity draft, reports, progress. A
statistically based system might detect draft reports,
since this cooccurrence might well be frequent as a
termform elsewhere in the text. Consequently, the
definition of &amp;quot;hit&amp;quot; needs further qualification.
</bodyText>
<subsectionHeader confidence="0.999604">
3.2 Perfect and Imperfect Recognition
</subsectionHeader>
<bodyText confidence="0.991887">
Two types of hits must be distinguished. A per-
fect hit occurs when the boundaries assigned by
the term-recognition system coincide with those of
a term&apos;s maximal termform ([committee draft] and
[constitutional reform] above). An imperfect hit
occurs when the boundaries assigned do not coincide
with those of a term&apos;s maximal termform but contain
at least one wordform belonging to a term&apos;s maximal
termform. A hit is imperfect if bracketing either in-
cludes spurious wordforms ([latest committee draft]
5In practice, terminologists have some difficulty
agreeing on the exact delimitation of complex termforms.
Still five experienced terminologists scanning a 2,861
word text were found to agree on the identity and bound-
aries of complex termforms three-quarters of the time
(Lauriston, 1993).
</bodyText>
<figure confidence="0.927077916666667">
RECOGNIZED TERMFORMS
I I false
perfect 11 hits
hits I I
TARGET
TERMFORMS
misses ?&lt;=limperfect hits &gt;?
hits: perfect (+ imperfect?)
recall =
hits: perfect + (imperfect?)
precision =
recognized termforms
</figure>
<figureCaption confidence="0.999217">
Figure 2: Recall, Precision and Imperfect Hits
</figureCaption>
<bodyText confidence="0.991214742857143">
or [committee draft reports]), fails to bracket a term
constituent (committee [draft]) or both (committee
[draft reports]). Bracketing a segment containing no
wordform that is part of a term&apos;s maximal termform
is, of course, a false hit ([reports progress]).
The problematic case is clearly that of an imper-
fect hit. In calculating recall and precision, should
imperfect hits be grouped with perfect hits, counted
as misses, or somehow accounted for separately (Fig-
ure 2)? How do the perfect recall and precision ra-
tios compare with imperfect recall and precision (in-
cluding imperfect hits in the numerator) when these
performance measurements are applied to real texts?
Counting imperfectly recognized termforms as hits
will obviously lead to higher ratios for recall and
precision, but how much higher?
To answer these questions, a complex-termform
recognition algorithm based on weighted syntactic
term-formation rules, the details of which are given
in Lauriston (1993), was applied to a tagged 2,861
word text. The weightings were based on the analy-
sis of a 117,000 word corpus containing 11,614 com-
plex termforms as determined by manual bracketing.
The recognition algorithm includes the possibility of
weighting of the terminological strength of particu-
lar adjectives. This was carried out to produce the
results shown in Figure 3.
Recall and precision, both perfect and imperfect,
were plotted as the algorithm&apos;s term-recognition
threshold was varied. By choosing a higher thresh-
old, only syntactically stronger links between ad-
jacent words are considered &amp;quot;terminological links&amp;quot;.
Thus the higher the threshold, the shorter the av-
erage complex termform, as weaker modifiers are
target termforms
</bodyText>
<page confidence="0.813084">
20
</page>
<table confidence="0.965241142857143">
1.0 +
I r r
P 0.9 + r r r r
e I r r r r p
r 0.8+ r r r P r p
f I r r rp rp
o 0.7+ r r r P r p
r I Hr Rr p rp rp
m 0.6+ Hr P Hr P r P r P
a I Rr p Rr p rp rp
n 0.5+ Hr p Hr p r p r p
c I RrpRrp rp rp
e 0.4 + Hr Pp Hr Pp Hr Pp r p
I Hr Pp Hr Pp Hr Pp r p
0.3 + Hr Pp Hr Pp Hr Pp r p
r I Hr Pp Hr Pp Hr Pp Rr Pp
a 0.2 + Hr Pp Hr Pp Hr Pp Hr Pp
t I Hr Pp Hr Pp Hr Pp Hr Pp
i 0.1 + Hr Pp Hr Pp Hr Pp Hr Pp
o I Hr Pp Hr Pp Hr Pp Hr Pp
0.0+ + + + +
0.05 0.40 0.75 0.95
term-recognition threshold
KEY:
R perfect recall (perfect hits only)
r imperfect recall (imperfect also)
P perfect precision (perfect hits only)
p imperfect precision (imperfect also)
</table>
<figureCaption confidence="0.9857475">
Figure 3: Effect of Imperfect Hits of Performance
Ratios
</figureCaption>
<bodyText confidence="0.995537414634146">
stripped from the nucleus. Lower recall and higher
precision can be expected as the threshold rises since
only constituents that are surer bets are included in
the maximal termform.
This Figure 3 shows that both recall and precision
scores are considerably higher when imperfect hits
are included in calculating the ratios. As expected,
raising the threshold results in lower recall regardless
of whether the ratios are calculated for perfect or im-
perfect recognition. There is a marked reduction in
perfect recall, however, and only a marginal reduc-
tion in imperfect recall. The precision ratios provide
the most interesting point of comparison. As the
threshold is raised, imperfect precision increases just
as the principle of recall-precision tradeoff in docu-
ment retrieval would lead one to expect. Perfect pre-
cision, on the other hand, actually declines slightly.
The difference between perfect and imperfect pre-
cision (between the P-bar and p-bar in each group)
increases appreciably as the threshold is raised. This
difference is due to the greater number of recognized
complex termforms either containing spurious words
or only part of the maximal termform.
Two conclusions can be drawn from Figure 3.
Firstly, the recognition algorithm implemented is
poor at perfect recognition (perfect recall 0.70;
perfect precision ^4 0.40) and only becomes poorer
as more stringent rule-weighting is applied. Sec-
ondly, and more importantly for the purpose of this
paper, Figure 3 shows that allowing for imperfect
bracketing in term recognition makes it possible to
obtain artificially high performance ratios for both
recall and precision. Output that recognizes almost
all terms but includes spurious words in complex
termforms or falls short of recognizing the entire
termform leaves a burdensome filtering task for the
human user and is next to useless if the &amp;quot;user&amp;quot; is an-
other level of automatic text processing. Only the
exact bracketing of the maximal termform provides
a useful standard for measuring and comparing the
performance of term-recognition systems.
</bodyText>
<sectionHeader confidence="0.999461" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999984608695652">
The term-recognition criteria proposed above - mea-
suring recall and precision for the exact bracketing of
maximal termforms - provide a basic minimum of in-
formation needed to assess system performance. For
some applications, it is useful to further specify how
these performance ratios differ for the recognition of
simple and complex termforms, how they vary for
terms resulting from different term-formation pro-
cesses, what the ratios are for termform types as op-
posed to tokens, or how well the system recognizes
novel termforms not already in a system lexicon or
previously encountered in a training corpus. Pre-
cision measurements might usefully state to what
extent errors are due to syntactic noise (bracket-
ing crossing syntactic constituents) as distinguished
from terminological noise (bracketing including
nonclassificatory modifiers or omitting classificatory
ones).
Publishing such performance results for term-
recognition systems would not only display their
strengths but also expose their weaknesses. Doing
so would ultimately benefit researchers, developers
and users of term-recognition systems.
</bodyText>
<sectionHeader confidence="0.971754" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.9794079375">
Baudot, Jean, and Andre Clas (1984). A model
for a bilingual terminology mini-bank. In Lebende
Sprachen, Vol.19, No.2, pp.283-298.
Black, Ezra, Roger Garside, and Geoffrey Leech
(1993). Statistically-driven computer grammars of
English: the IBM/Lancaster approach. Amsterdam:
Rodopi.
Bourigault, Didier (1992). LEXTER, un Logi-
ciel d&apos;EXtraction de TERminologie. In Colloque
sur le reperage de l&apos;information textuelle, Montréal,
Quebec, Hydro-Quebec, March, pp.15-25.
Bourigault, Didier (1994). Extraction et struc-
turation automatique de terminologie pour l&apos;aide a
l&apos;acquisition des connaissances a partir de textes. In
Reconnaissance des formes et intelligence artificielle
(RFIA &apos;9.0, Paris, January.
</bodyText>
<page confidence="0.997142">
21
</page>
<bodyText confidence="0.9385772">
Church, Kenneth W. (1988). A stochastic parts
program and noun phrase parser for unrestricted
text. In Proceedings of the Second Conference
on Applied Natural Language Processing, Austin,
Texas. Association for Computational Linguistics,
Morristown, New Jersey, pp.136-143.
Daille, Beatrice (1994). Approche mixte pour
l&apos;extraction automatique de terminologie : statis-
tique lexicale et filtres linguistiques. Universite de
Paris 7 (PhD Thesis), Paris, January.
David, Sophie and Pierre Plante (1990). De la
necessite d&apos;une approche morphosyntaxique en anal-
yse de textes. In Intelligence artificielle et sci-
ences cognitives au Québec, Vol.3 No.3, September,
pp.140-155.
</bodyText>
<reference confidence="0.9800557375">
Finin, Timothy W. (1986). Constraining the in-
terpretation of nominal compounds in a limited con-
text. In Ralph Grishman and Richard Kittredge,
editors, Analyzing language in restricted domains,
Hillsdale, New Jersey: Lawrence Erlbaum Asso-
ciates, pp.163-173.
Foster, George F. (1991). Statistical lexical dis-
ambiguation. McGill University (MSc Thesis),
Montréal, Quebec.
Garside, Roger, Geoffrey Leech, and Geoffrey
Sampson, editors (1987). The computational anal-
ysis of English: a corpus-based approach, London,
Longman.
Gaussier, Eric and Jean-Marc Lange (1994). Some
methods for the extraction of bilingual terminol-
ogy. In Proceedings of the International Confer-
ence on New Methods in Language Processing (NeM-
LaP), Manchester, England, University of Manch-
ester Institute of Science and Technology (UMIST),
September, pp.242-247.
International Organization for Standardization
(ISO) (1988). Terminolgy - vocabulary. (ISO/DIS
1087), Geneva, Switzerland.
Jones, Leslie, Edward W. Gassie, and Sridhar
Radhakrishnon (1990). INDEX: the statistical basis
for an automatic conceptual phrase-indexing system.
In Journal of the American Society for Information
Science, Vol.41, No.2, pp.87-97.
Lauriston, Andy (1993). Le reperage automa-
tique des syntagmes terminologiques. Universite du
Quebec a Montreal (MA Thesis), Montreal, Quebec.
Lauriston, Andy (1994). Automatic recognition
of complex terms: problems and the &amp;quot;Termino&amp;quot; so-
lution. In Terminology: applications in interdisci-
plinary communication, Vol.1, No.1, pp.147-170.
Leonard, Rosemary (1984). The interpretation of
English noun sequences on the computer, Amster-
dam, North-Holland.
Logos Corporation (1987). LOGOS English
Source Release 7.0, Dedham, Mass., Logos Corpo-
ration.
Normand, Diane (1993). Quand la terminologie
s&apos;automatise: du nouveau en terminotique: Term
Cruncher, un logicel de depouillement. In Circuit,
No.42, December, pp.29-30.
Otman, Gabriel (1991). Des ambitions et des
performances d&apos;un systeme de depouillement termi-
nologique assiste par ordinateur. In La Banque des
mots (special issue on terminology software), No.4,
pp.59-96.
Perron, Jean (1991). Presentation du progiciel de
depouillement terminologique assiste par ordinateur:
Termino. In Les industries de la langue: perspec-
tives des annies 1990, Monteal, Quebec, Office de la
langue francaise/Societe des traducteurs du Quebec,
pp.715-755.
Portelance, Christine (1989). Les formations syn-
tagmatiques en langues de specialite. Universite de
Montreal, (PhD Thesis), Montreal, Quebec.
Riggs, Fred (1993). Social science terminology:
basic problems and proposed solutions. In Helmi B.
Sonneveld and Kurt T. Loening, editors, Terminol-
ogy: applications in interdisciplinary communica-
tion, Amsterdam, John Benjamins, pp.195-222.
Salton, Gerard (1989). Automatic text process-
ing: the transformation, analysis, and retrieval of
information by computer, Reading, Mass., Addison-
Wesley.
Smadja, Frank (1993). Retrieving collocations
from text: Xtract. In Computational linguistics,
Vol.19, No.l.
Spark-Jones, Karen (1985). Compound Noun
Interpretation Problems. In Frank Fallside and
William A. Woods, editors, Computer Speech Pro-
cessing, Englewood Cliffs, New Jersey, Prentice-
Hall, pp.363-381.
Van der Eijk, Pik (1993). Automating the acqui-
sition of bilingual terminology. Proceedings of the
European Chapter of the Association for Computa-
tional Linguistics (EACL), pp.113-119.
</reference>
<page confidence="0.999024">
22
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.727197">
<title confidence="0.99925">Criteria for Measuring Term Recognition</title>
<author confidence="0.999817">Andy Lauriston</author>
<affiliation confidence="0.998176">Department of Languages and Linguistics University of Manchester Institute of Science and Technology</affiliation>
<address confidence="0.890612333333333">P.O. Box 88 Manchester M60 1QD United Kingdom</address>
<email confidence="0.991118">andyl©ccl.umist.ac.uk</email>
<abstract confidence="0.998869555555555">This paper qualifies what a true termrecognition systems would have to recognize. The exact bracketing of the maximal termform is then proposed as an achieveable goal upon which current system performance should be measured. How recall and precision metrics are best adapted for measuring term recognition is suggested.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy W Finin</author>
</authors>
<title>Constraining the interpretation of nominal compounds in a limited context.</title>
<date>1986</date>
<booktitle>Analyzing language in restricted domains,</booktitle>
<pages>163--173</pages>
<editor>In Ralph Grishman and Richard Kittredge, editors,</editor>
<location>Hillsdale, New Jersey: Lawrence</location>
<marker>Finin, 1986</marker>
<rawString>Finin, Timothy W. (1986). Constraining the interpretation of nominal compounds in a limited context. In Ralph Grishman and Richard Kittredge, editors, Analyzing language in restricted domains, Hillsdale, New Jersey: Lawrence Erlbaum Associates, pp.163-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George F Foster</author>
</authors>
<title>Statistical lexical disambiguation.</title>
<date>1991</date>
<institution>McGill University (MSc Thesis),</institution>
<location>Montréal, Quebec.</location>
<contexts>
<context position="5252" citStr="Foster (1991)" startWordPosition="825" endWordPosition="826">annot be carried out on purely formal grounds. It requires some level of linguistic analysis. Indeed, two term-formation processes do not result in new termforms: conversion and semantic drift&apos;. A third term-formation process, compression, can also result in a new meaning being associated with an existing termform2. Proper attention to capitalization can generally result in the correct recognition of compressed forms. Part-of-speech tagging is required to detect new terms formed through conversion. This is quite feasible using statistical taggers like those of Garside (1987), Church (1988) or Foster (1991) which achieve performance upwards of 97% on unrestricted text. Terms formed through semantic drift are the wolves in sheep&apos;s clothing stealing through terminological pastures. They are well enough concealed to allude at times even the human reader and no automatic term-recognition system has attempted to distinguish such terms, despite the prevalence of polysemy in such fields as the social sciences (Riggs, 1993) and the importance for purposes of terminological standardization that &amp;quot;deviant&amp;quot; usage be tracked. Implementing a system to distinguish new &apos;Conversion occurs when a term is formed b</context>
</contexts>
<marker>Foster, 1991</marker>
<rawString>Foster, George F. (1991). Statistical lexical disambiguation. McGill University (MSc Thesis), Montréal, Quebec.</rawString>
</citation>
<citation valid="true">
<title>The computational analysis of English: a corpus-based approach,</title>
<date>1987</date>
<editor>Garside, Roger, Geoffrey Leech, and Geoffrey Sampson, editors</editor>
<location>London, Longman.</location>
<contexts>
<context position="5220" citStr="(1987)" startWordPosition="821" endWordPosition="821">rstly, term recognition cannot be carried out on purely formal grounds. It requires some level of linguistic analysis. Indeed, two term-formation processes do not result in new termforms: conversion and semantic drift&apos;. A third term-formation process, compression, can also result in a new meaning being associated with an existing termform2. Proper attention to capitalization can generally result in the correct recognition of compressed forms. Part-of-speech tagging is required to detect new terms formed through conversion. This is quite feasible using statistical taggers like those of Garside (1987), Church (1988) or Foster (1991) which achieve performance upwards of 97% on unrestricted text. Terms formed through semantic drift are the wolves in sheep&apos;s clothing stealing through terminological pastures. They are well enough concealed to allude at times even the human reader and no automatic term-recognition system has attempted to distinguish such terms, despite the prevalence of polysemy in such fields as the social sciences (Riggs, 1993) and the importance for purposes of terminological standardization that &amp;quot;deviant&amp;quot; usage be tracked. Implementing a system to distinguish new &apos;Conversio</context>
</contexts>
<marker>1987</marker>
<rawString>Garside, Roger, Geoffrey Leech, and Geoffrey Sampson, editors (1987). The computational analysis of English: a corpus-based approach, London, Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Gaussier</author>
<author>Jean-Marc Lange</author>
</authors>
<title>Some methods for the extraction of bilingual terminology.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing (NeMLaP),</booktitle>
<pages>242--247</pages>
<institution>University of Manchester Institute of Science and Technology (UMIST),</institution>
<location>Manchester, England,</location>
<marker>Gaussier, Lange, 1994</marker>
<rawString>Gaussier, Eric and Jean-Marc Lange (1994). Some methods for the extraction of bilingual terminology. In Proceedings of the International Conference on New Methods in Language Processing (NeMLaP), Manchester, England, University of Manchester Institute of Science and Technology (UMIST), September, pp.242-247.</rawString>
</citation>
<citation valid="true">
<title>International Organization for Standardization (ISO)</title>
<date>1988</date>
<booktitle>Terminolgy - vocabulary. (ISO/DIS 1087),</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="5235" citStr="(1988)" startWordPosition="823" endWordPosition="823">ognition cannot be carried out on purely formal grounds. It requires some level of linguistic analysis. Indeed, two term-formation processes do not result in new termforms: conversion and semantic drift&apos;. A third term-formation process, compression, can also result in a new meaning being associated with an existing termform2. Proper attention to capitalization can generally result in the correct recognition of compressed forms. Part-of-speech tagging is required to detect new terms formed through conversion. This is quite feasible using statistical taggers like those of Garside (1987), Church (1988) or Foster (1991) which achieve performance upwards of 97% on unrestricted text. Terms formed through semantic drift are the wolves in sheep&apos;s clothing stealing through terminological pastures. They are well enough concealed to allude at times even the human reader and no automatic term-recognition system has attempted to distinguish such terms, despite the prevalence of polysemy in such fields as the social sciences (Riggs, 1993) and the importance for purposes of terminological standardization that &amp;quot;deviant&amp;quot; usage be tracked. Implementing a system to distinguish new &apos;Conversion occurs when a</context>
<context position="23963" citStr="(1988)" startWordPosition="3714" endWordPosition="3714">83-298. Black, Ezra, Roger Garside, and Geoffrey Leech (1993). Statistically-driven computer grammars of English: the IBM/Lancaster approach. Amsterdam: Rodopi. Bourigault, Didier (1992). LEXTER, un Logiciel d&apos;EXtraction de TERminologie. In Colloque sur le reperage de l&apos;information textuelle, Montréal, Quebec, Hydro-Quebec, March, pp.15-25. Bourigault, Didier (1994). Extraction et structuration automatique de terminologie pour l&apos;aide a l&apos;acquisition des connaissances a partir de textes. In Reconnaissance des formes et intelligence artificielle (RFIA &apos;9.0, Paris, January. 21 Church, Kenneth W. (1988). A stochastic parts program and noun phrase parser for unrestricted text. In Proceedings of the Second Conference on Applied Natural Language Processing, Austin, Texas. Association for Computational Linguistics, Morristown, New Jersey, pp.136-143. Daille, Beatrice (1994). Approche mixte pour l&apos;extraction automatique de terminologie : statistique lexicale et filtres linguistiques. Universite de Paris 7 (PhD Thesis), Paris, January. David, Sophie and Pierre Plante (1990). De la necessite d&apos;une approche morphosyntaxique en analyse de textes. In Intelligence artificielle et sciences cognitives au</context>
</contexts>
<marker>1988</marker>
<rawString>International Organization for Standardization (ISO) (1988). Terminolgy - vocabulary. (ISO/DIS 1087), Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leslie Jones</author>
<author>Edward W Gassie</author>
<author>Sridhar Radhakrishnon</author>
</authors>
<title>INDEX: the statistical basis for an automatic conceptual phrase-indexing system.</title>
<date>1990</date>
<journal>In Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<pages>87--97</pages>
<marker>Jones, Gassie, Radhakrishnon, 1990</marker>
<rawString>Jones, Leslie, Edward W. Gassie, and Sridhar Radhakrishnon (1990). INDEX: the statistical basis for an automatic conceptual phrase-indexing system. In Journal of the American Society for Information Science, Vol.41, No.2, pp.87-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andy Lauriston</author>
</authors>
<title>Le reperage automatique des syntagmes terminologiques. Universite du Quebec a Montreal (MA Thesis),</title>
<date>1993</date>
<location>Montreal, Quebec.</location>
<contexts>
<context position="7534" citStr="Lauriston, 1993" startWordPosition="1161" endWordPosition="1163">tation The vast majority of terms in published technical dictionaries and terminology standards are nouns. Furthermore, most terms have a complex termform, i.e. they are comprised of more than one word. Sublanguages create series of complex termforms in which complex forms serve as modifiers (natural language = [natural language] processing) and/or are themselves modified (applied [[naivral language] processing]). In special language, complex termforms containing nested termforms, or significant subexpressions (Baudot, 1984), have hundreds of possible syntagmatic structures (Portelance, 1989; Lauriston, 1993). The challenge facing developers of term-recognition systems consists in determining the syntactic and conceptual unity that complex nominals must possess in order to achieve termhood 3. Another, and it will be argued far more ambitious, undertaking is term interpretation. Leonard (1984), Finen (1985) and others have attempted to devise systems that can produce a gloss explicating the semantic relationship that holds between the constituents of complex nominals (e.g. family estate estate owned by a family). Such attempts at achieving even limited &amp;quot;interpretation&amp;quot; result in large sets of possi</context>
<context position="17374" citStr="Lauriston, 1993" startWordPosition="2630" endWordPosition="2631">mmittee draft] and [constitutional reform] above). An imperfect hit occurs when the boundaries assigned do not coincide with those of a term&apos;s maximal termform but contain at least one wordform belonging to a term&apos;s maximal termform. A hit is imperfect if bracketing either includes spurious wordforms ([latest committee draft] 5In practice, terminologists have some difficulty agreeing on the exact delimitation of complex termforms. Still five experienced terminologists scanning a 2,861 word text were found to agree on the identity and boundaries of complex termforms three-quarters of the time (Lauriston, 1993). RECOGNIZED TERMFORMS I I false perfect 11 hits hits I I TARGET TERMFORMS misses ?&lt;=limperfect hits &gt;? hits: perfect (+ imperfect?) recall = hits: perfect + (imperfect?) precision = recognized termforms Figure 2: Recall, Precision and Imperfect Hits or [committee draft reports]), fails to bracket a term constituent (committee [draft]) or both (committee [draft reports]). Bracketing a segment containing no wordform that is part of a term&apos;s maximal termform is, of course, a false hit ([reports progress]). The problematic case is clearly that of an imperfect hit. In calculating recall and precis</context>
<context position="18598" citStr="Lauriston (1993)" startWordPosition="2816" endWordPosition="2817">uld imperfect hits be grouped with perfect hits, counted as misses, or somehow accounted for separately (Figure 2)? How do the perfect recall and precision ratios compare with imperfect recall and precision (including imperfect hits in the numerator) when these performance measurements are applied to real texts? Counting imperfectly recognized termforms as hits will obviously lead to higher ratios for recall and precision, but how much higher? To answer these questions, a complex-termform recognition algorithm based on weighted syntactic term-formation rules, the details of which are given in Lauriston (1993), was applied to a tagged 2,861 word text. The weightings were based on the analysis of a 117,000 word corpus containing 11,614 complex termforms as determined by manual bracketing. The recognition algorithm includes the possibility of weighting of the terminological strength of particular adjectives. This was carried out to produce the results shown in Figure 3. Recall and precision, both perfect and imperfect, were plotted as the algorithm&apos;s term-recognition threshold was varied. By choosing a higher threshold, only syntactically stronger links between adjacent words are considered &amp;quot;terminol</context>
</contexts>
<marker>Lauriston, 1993</marker>
<rawString>Lauriston, Andy (1993). Le reperage automatique des syntagmes terminologiques. Universite du Quebec a Montreal (MA Thesis), Montreal, Quebec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andy Lauriston</author>
</authors>
<title>Automatic recognition of complex terms: problems and the &amp;quot;Termino&amp;quot; solution.</title>
<date>1994</date>
<booktitle>In Terminology: applications in interdisciplinary communication, Vol.1, No.1,</booktitle>
<pages>147--170</pages>
<contexts>
<context position="9669" citStr="Lauriston, 1994" startWordPosition="1468" endWordPosition="1469">m of an area of specialized human activity. Hence general trend may be as strong a collocation as general election, and yet only the latter be considered a term. 18 approach would produce as output several nested termforms (switching equipment, protection switching, protection switching equipment, automatic protection,automatic protection switching) as well as the maximal termform automatic protection switching equipment. Because such systems list nested termforms in the absence of higher-level analysis, many erroneous &amp;quot;terms&amp;quot; are generated. It has been argued previously on pragmatic grounds (Lauriston, 1994) that a safer approach is to detect only the maximal termform. It could further be said that doing so is theoretically sound. Nesting termforms is a means by which an author achieves transparency. Once nested, however, a termform no longer fulfills the naming function. It serves as a mnemonic device. In different languages, different nested termforms are sometimes selected to perform this mnemonic function (e.g. on-line credit card checking, for which a documented French equivalent is verification de credit au point de vente, literally &amp;quot;point-of-sale credit verification&amp;quot;). Only the maximal ter</context>
<context position="13638" citStr="Lauriston, 1994" startWordPosition="2063" endWordPosition="2064">ld feed a future &amp;quot;term interpreter&amp;quot;, that would also be required to recognize terms in ambiguous conjunctive expressions. 3 How Can Recognition be Measured? Once a consensus has been reached about what is to be recognized, there must be some agreement concerning the way in which performance is to be measured. Fortunately, established performance measurements used in information retrieval - recall and precision - can be adapted quite readily for measuring the term-recognition task. These measures have, in fact, been used previously in measuring term recognition (Smadja, 1993; Bourigault, 1994; Lauriston, 1994). No study, however, adequately discusses how these measurements are applied to term recognition. 3.1 Recall and Precision Traditionally, performance in document retrieval is measured by means of a few simple ratios (Salton, 1989). These are based on the premise that any given document in a collection is either pertinent or non-pertinent to a particular user&apos;s needs. There is no scale of relative pertinence. For a given user query, retrieving a pertinent document constitutes a hit, failing to retrieve a pertinent document constitutes a miss, and retrieving a non-pertinent document constitutes </context>
</contexts>
<marker>Lauriston, 1994</marker>
<rawString>Lauriston, Andy (1994). Automatic recognition of complex terms: problems and the &amp;quot;Termino&amp;quot; solution. In Terminology: applications in interdisciplinary communication, Vol.1, No.1, pp.147-170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosemary Leonard</author>
</authors>
<title>The interpretation of English noun sequences on the computer,</title>
<date>1984</date>
<location>Amsterdam, North-Holland.</location>
<contexts>
<context position="7823" citStr="Leonard (1984)" startWordPosition="1204" endWordPosition="1205">s (natural language = [natural language] processing) and/or are themselves modified (applied [[naivral language] processing]). In special language, complex termforms containing nested termforms, or significant subexpressions (Baudot, 1984), have hundreds of possible syntagmatic structures (Portelance, 1989; Lauriston, 1993). The challenge facing developers of term-recognition systems consists in determining the syntactic and conceptual unity that complex nominals must possess in order to achieve termhood 3. Another, and it will be argued far more ambitious, undertaking is term interpretation. Leonard (1984), Finen (1985) and others have attempted to devise systems that can produce a gloss explicating the semantic relationship that holds between the constituents of complex nominals (e.g. family estate estate owned by a family). Such attempts at achieving even limited &amp;quot;interpretation&amp;quot; result in large sets of possible relationships but fail to account for all compounds. Furthermore, they have generally been restricted to termforms with two constituents. For complex termforms with three or more constituents, merely identifying how constituents are nested, i.e., between which constituents there exist</context>
</contexts>
<marker>Leonard, 1984</marker>
<rawString>Leonard, Rosemary (1984). The interpretation of English noun sequences on the computer, Amsterdam, North-Holland.</rawString>
</citation>
<citation valid="true">
<date>1987</date>
<journal>LOGOS English Source Release</journal>
<volume>7</volume>
<publisher>Corporation.</publisher>
<institution>Logos Corporation</institution>
<location>Dedham, Mass., Logos</location>
<contexts>
<context position="5220" citStr="(1987)" startWordPosition="821" endWordPosition="821">rstly, term recognition cannot be carried out on purely formal grounds. It requires some level of linguistic analysis. Indeed, two term-formation processes do not result in new termforms: conversion and semantic drift&apos;. A third term-formation process, compression, can also result in a new meaning being associated with an existing termform2. Proper attention to capitalization can generally result in the correct recognition of compressed forms. Part-of-speech tagging is required to detect new terms formed through conversion. This is quite feasible using statistical taggers like those of Garside (1987), Church (1988) or Foster (1991) which achieve performance upwards of 97% on unrestricted text. Terms formed through semantic drift are the wolves in sheep&apos;s clothing stealing through terminological pastures. They are well enough concealed to allude at times even the human reader and no automatic term-recognition system has attempted to distinguish such terms, despite the prevalence of polysemy in such fields as the social sciences (Riggs, 1993) and the importance for purposes of terminological standardization that &amp;quot;deviant&amp;quot; usage be tracked. Implementing a system to distinguish new &apos;Conversio</context>
</contexts>
<marker>1987</marker>
<rawString>Logos Corporation (1987). LOGOS English Source Release 7.0, Dedham, Mass., Logos Corporation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diane Normand</author>
</authors>
<title>Quand la terminologie s&apos;automatise: du nouveau en terminotique: Term Cruncher, un logicel de depouillement.</title>
<date>1993</date>
<booktitle>In Circuit, No.42,</booktitle>
<pages>29--30</pages>
<contexts>
<context position="1691" citStr="Normand, 1993" startWordPosition="253" endWordPosition="255"> of a purely descriptive statement of the advantages of a particular approach and make no attempt to measure the pay-off the proposed approach yields (David, 1990). Others produce partial figures without any clear statement of how they are derived (Otman, 1991). One of the best efforts to quantify the performance of a term-recognition system (Smadja, 1993) does so only for one processing stage, leaving unassessed the text-to-output performance of the system. While most automatic term-recognition systems developed to date have been experimental or inhouse ones, a few systems like TermCruncher (Normand, 1993) are now being marketed. Both the developers and users of such systems would benefit greatly by clearly qualifying what each system aims to achieve, and precisely quantifying how closely the system comes to achieving its stated aim. Before discussing what a term-recognition system should be expected to recognize and how performance in recognition should be measured, two undenying premises should be made clear. Firstly, the automatic system is designed to recognize segments of text that, conventionally, have been manually identified by a terminologist, indexer, lexicographer or other trained in</context>
<context position="3416" citStr="Normand, 1993" startWordPosition="528" endWordPosition="529">system must achieve and what, in the short term, such systems can be expected to achieve. Section 3 specifies how the established ratios used in information retrieval - recall and precision - can best be adapted for measuring the recognition of single- and multi-word noun terms. 2 What is to be Recognized? Depending upon the meaning given to the expression &amp;quot;term recognition&amp;quot;, it can be viewed as either a rather trivial, low-level processing task or one that is impossible to automate. A limited form of term recognition has been achieved using current techniques (Perron, 1991; Bourigault, 1994; Normand, 1993). To appreciate what current limitations are and what would be required to achieve full term recognition, it is useful to draw the distinction between &amp;quot;term&amp;quot; and &amp;quot;termform&amp;quot; on the one hand, and &amp;quot;term recognition&amp;quot; and &amp;quot;term interpretation&amp;quot; on the other. 2.1 Term vs Termform Particularly in the computing community, there is a tendency to consider &amp;quot;terms&amp;quot; as strictly formal entities. Although usage among terminologists varies, a term is generally accepted as being the &amp;quot;designation of a defined concept in a special language by a linguistic expression&amp;quot; (ISO, 1988). A term is hence 17 I Concept I I </context>
</contexts>
<marker>Normand, 1993</marker>
<rawString>Normand, Diane (1993). Quand la terminologie s&apos;automatise: du nouveau en terminotique: Term Cruncher, un logicel de depouillement. In Circuit, No.42, December, pp.29-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel Otman</author>
</authors>
<title>Des ambitions et des performances d&apos;un systeme de depouillement terminologique assiste par ordinateur.</title>
<date>1991</date>
<booktitle>In La Banque des mots (special issue on terminology software), No.4,</booktitle>
<pages>59--96</pages>
<contexts>
<context position="1338" citStr="Otman, 1991" startWordPosition="199" endWordPosition="200">con and thesaurus construction and maintenance, automatic indexing and machine translation have fuelled this interest. Given that concerns in automatic term recognition are practical, rather than theoretical, the lack of serious performance measurements in the published literature is surprising. Accounts of term-recognition systems sometimes consist of a purely descriptive statement of the advantages of a particular approach and make no attempt to measure the pay-off the proposed approach yields (David, 1990). Others produce partial figures without any clear statement of how they are derived (Otman, 1991). One of the best efforts to quantify the performance of a term-recognition system (Smadja, 1993) does so only for one processing stage, leaving unassessed the text-to-output performance of the system. While most automatic term-recognition systems developed to date have been experimental or inhouse ones, a few systems like TermCruncher (Normand, 1993) are now being marketed. Both the developers and users of such systems would benefit greatly by clearly qualifying what each system aims to achieve, and precisely quantifying how closely the system comes to achieving its stated aim. Before discuss</context>
</contexts>
<marker>Otman, 1991</marker>
<rawString>Otman, Gabriel (1991). Des ambitions et des performances d&apos;un systeme de depouillement terminologique assiste par ordinateur. In La Banque des mots (special issue on terminology software), No.4, pp.59-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Perron</author>
</authors>
<title>Presentation du progiciel de depouillement terminologique assiste par ordinateur: Termino.</title>
<date>1991</date>
<booktitle>In Les industries de la langue: perspectives des annies</booktitle>
<pages>715--755</pages>
<location>Monteal, Quebec, Office</location>
<contexts>
<context position="3382" citStr="Perron, 1991" startWordPosition="524" endWordPosition="525">fy what a true term-recognition system must achieve and what, in the short term, such systems can be expected to achieve. Section 3 specifies how the established ratios used in information retrieval - recall and precision - can best be adapted for measuring the recognition of single- and multi-word noun terms. 2 What is to be Recognized? Depending upon the meaning given to the expression &amp;quot;term recognition&amp;quot;, it can be viewed as either a rather trivial, low-level processing task or one that is impossible to automate. A limited form of term recognition has been achieved using current techniques (Perron, 1991; Bourigault, 1994; Normand, 1993). To appreciate what current limitations are and what would be required to achieve full term recognition, it is useful to draw the distinction between &amp;quot;term&amp;quot; and &amp;quot;termform&amp;quot; on the one hand, and &amp;quot;term recognition&amp;quot; and &amp;quot;term interpretation&amp;quot; on the other. 2.1 Term vs Termform Particularly in the computing community, there is a tendency to consider &amp;quot;terms&amp;quot; as strictly formal entities. Although usage among terminologists varies, a term is generally accepted as being the &amp;quot;designation of a defined concept in a special language by a linguistic expression&amp;quot; (ISO, 1988).</context>
</contexts>
<marker>Perron, 1991</marker>
<rawString>Perron, Jean (1991). Presentation du progiciel de depouillement terminologique assiste par ordinateur: Termino. In Les industries de la langue: perspectives des annies 1990, Monteal, Quebec, Office de la langue francaise/Societe des traducteurs du Quebec, pp.715-755.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christine Portelance</author>
</authors>
<title>Les formations syntagmatiques en langues de specialite. Universite de Montreal, (PhD Thesis),</title>
<date>1989</date>
<location>Montreal, Quebec.</location>
<contexts>
<context position="7516" citStr="Portelance, 1989" startWordPosition="1159" endWordPosition="1160">n vs Term Interpretation The vast majority of terms in published technical dictionaries and terminology standards are nouns. Furthermore, most terms have a complex termform, i.e. they are comprised of more than one word. Sublanguages create series of complex termforms in which complex forms serve as modifiers (natural language = [natural language] processing) and/or are themselves modified (applied [[naivral language] processing]). In special language, complex termforms containing nested termforms, or significant subexpressions (Baudot, 1984), have hundreds of possible syntagmatic structures (Portelance, 1989; Lauriston, 1993). The challenge facing developers of term-recognition systems consists in determining the syntactic and conceptual unity that complex nominals must possess in order to achieve termhood 3. Another, and it will be argued far more ambitious, undertaking is term interpretation. Leonard (1984), Finen (1985) and others have attempted to devise systems that can produce a gloss explicating the semantic relationship that holds between the constituents of complex nominals (e.g. family estate estate owned by a family). Such attempts at achieving even limited &amp;quot;interpretation&amp;quot; result in l</context>
</contexts>
<marker>Portelance, 1989</marker>
<rawString>Portelance, Christine (1989). Les formations syntagmatiques en langues de specialite. Universite de Montreal, (PhD Thesis), Montreal, Quebec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred Riggs</author>
</authors>
<title>Social science terminology: basic problems and proposed solutions.</title>
<date>1993</date>
<booktitle>Terminology: applications in interdisciplinary communication,</booktitle>
<pages>195--222</pages>
<editor>In Helmi B. Sonneveld and Kurt T. Loening, editors,</editor>
<location>Amsterdam, John Benjamins,</location>
<contexts>
<context position="5669" citStr="Riggs, 1993" startWordPosition="890" endWordPosition="891">ms. Part-of-speech tagging is required to detect new terms formed through conversion. This is quite feasible using statistical taggers like those of Garside (1987), Church (1988) or Foster (1991) which achieve performance upwards of 97% on unrestricted text. Terms formed through semantic drift are the wolves in sheep&apos;s clothing stealing through terminological pastures. They are well enough concealed to allude at times even the human reader and no automatic term-recognition system has attempted to distinguish such terms, despite the prevalence of polysemy in such fields as the social sciences (Riggs, 1993) and the importance for purposes of terminological standardization that &amp;quot;deviant&amp;quot; usage be tracked. Implementing a system to distinguish new &apos;Conversion occurs when a term is formed by a change in grammatical category. Verb-to-noun conversion commonly occurs for commands in programming or word processing (e.g. Undelete works if you catch your mistake quickly). Semantic drift involves a (sometimes subtle) change in meaning without any change in grammatical category (viz. &amp;quot;term&amp;quot; as understood in this papr vs th.- lonse wage of &amp;quot;i■-rm&amp;quot; to mean &amp;quot;termform&amp;quot;). 2Compression is the shortening of (usual</context>
</contexts>
<marker>Riggs, 1993</marker>
<rawString>Riggs, Fred (1993). Social science terminology: basic problems and proposed solutions. In Helmi B. Sonneveld and Kurt T. Loening, editors, Terminology: applications in interdisciplinary communication, Amsterdam, John Benjamins, pp.195-222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
</authors>
<title>Automatic text processing: the transformation, analysis, and retrieval of information by computer,</title>
<date>1989</date>
<publisher>AddisonWesley.</publisher>
<location>Reading, Mass.,</location>
<contexts>
<context position="13868" citStr="Salton, 1989" startWordPosition="2096" endWordPosition="2097"> be some agreement concerning the way in which performance is to be measured. Fortunately, established performance measurements used in information retrieval - recall and precision - can be adapted quite readily for measuring the term-recognition task. These measures have, in fact, been used previously in measuring term recognition (Smadja, 1993; Bourigault, 1994; Lauriston, 1994). No study, however, adequately discusses how these measurements are applied to term recognition. 3.1 Recall and Precision Traditionally, performance in document retrieval is measured by means of a few simple ratios (Salton, 1989). These are based on the premise that any given document in a collection is either pertinent or non-pertinent to a particular user&apos;s needs. There is no scale of relative pertinence. For a given user query, retrieving a pertinent document constitutes a hit, failing to retrieve a pertinent document constitutes a miss, and retrieving a non-pertinent document constitutes a false hit. Recall, the ratio of the number of hits to the number of pertinent documents in the collection, measures the effectiveness of retrieval. Precision, the ratio of the number of hits to the number of retrieved documents,</context>
</contexts>
<marker>Salton, 1989</marker>
<rawString>Salton, Gerard (1989). Automatic text processing: the transformation, analysis, and retrieval of information by computer, Reading, Mass., AddisonWesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>Retrieving collocations from text: Xtract.</title>
<date>1993</date>
<booktitle>In Computational linguistics, Vol.19,</booktitle>
<location>No.l.</location>
<contexts>
<context position="1435" citStr="Smadja, 1993" startWordPosition="215" endWordPosition="216">fuelled this interest. Given that concerns in automatic term recognition are practical, rather than theoretical, the lack of serious performance measurements in the published literature is surprising. Accounts of term-recognition systems sometimes consist of a purely descriptive statement of the advantages of a particular approach and make no attempt to measure the pay-off the proposed approach yields (David, 1990). Others produce partial figures without any clear statement of how they are derived (Otman, 1991). One of the best efforts to quantify the performance of a term-recognition system (Smadja, 1993) does so only for one processing stage, leaving unassessed the text-to-output performance of the system. While most automatic term-recognition systems developed to date have been experimental or inhouse ones, a few systems like TermCruncher (Normand, 1993) are now being marketed. Both the developers and users of such systems would benefit greatly by clearly qualifying what each system aims to achieve, and precisely quantifying how closely the system comes to achieving its stated aim. Before discussing what a term-recognition system should be expected to recognize and how performance in recogni</context>
<context position="13602" citStr="Smadja, 1993" startWordPosition="2059" endWordPosition="2060">of a term-recognition system could feed a future &amp;quot;term interpreter&amp;quot;, that would also be required to recognize terms in ambiguous conjunctive expressions. 3 How Can Recognition be Measured? Once a consensus has been reached about what is to be recognized, there must be some agreement concerning the way in which performance is to be measured. Fortunately, established performance measurements used in information retrieval - recall and precision - can be adapted quite readily for measuring the term-recognition task. These measures have, in fact, been used previously in measuring term recognition (Smadja, 1993; Bourigault, 1994; Lauriston, 1994). No study, however, adequately discusses how these measurements are applied to term recognition. 3.1 Recall and Precision Traditionally, performance in document retrieval is measured by means of a few simple ratios (Salton, 1989). These are based on the premise that any given document in a collection is either pertinent or non-pertinent to a particular user&apos;s needs. There is no scale of relative pertinence. For a given user query, retrieving a pertinent document constitutes a hit, failing to retrieve a pertinent document constitutes a miss, and retrieving a</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Smadja, Frank (1993). Retrieving collocations from text: Xtract. In Computational linguistics, Vol.19, No.l.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Spark-Jones</author>
</authors>
<title>Compound Noun Interpretation Problems.</title>
<date>1985</date>
<booktitle>Computer Speech Processing,</booktitle>
<pages>363--381</pages>
<editor>In Frank Fallside and William A. Woods, editors,</editor>
<location>Englewood Cliffs, New Jersey, PrenticeHall,</location>
<marker>Spark-Jones, 1985</marker>
<rawString>Spark-Jones, Karen (1985). Compound Noun Interpretation Problems. In Frank Fallside and William A. Woods, editors, Computer Speech Processing, Englewood Cliffs, New Jersey, PrenticeHall, pp.363-381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Van der Eijk</author>
</authors>
<title>Automating the acquisition of bilingual terminology.</title>
<date>1993</date>
<booktitle>Proceedings of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>113--119</pages>
<marker>Van der Eijk, 1993</marker>
<rawString>Van der Eijk, Pik (1993). Automating the acquisition of bilingual terminology. Proceedings of the European Chapter of the Association for Computational Linguistics (EACL), pp.113-119.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>