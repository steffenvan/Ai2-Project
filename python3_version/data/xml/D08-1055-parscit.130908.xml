<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99404">
A Japanese Predicate Argument Structure Analysis using Decision Lists
</title>
<author confidence="0.978214">
Hirotoshi Taira, Sanae Fujita, Masaaki Nagata
</author>
<affiliation confidence="0.891487666666667">
NTT Communication Science Laboratories
2-4, Hikaridai, Seika-cho,
Keihanna Science City,
</affiliation>
<address confidence="0.540686">
Kyoto 619-0237, Japan
</address>
<email confidence="0.997659">
{{taira,sanae}@cslab.kecl, nagata.masaaki@lab}.ntt.co.jp
</email>
<sectionHeader confidence="0.995636" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999149375">
This paper describes a new automatic method
for Japanese predicate argument structure
analysis. The method learns relevant features
to assign case roles to the argument of the tar-
get predicate using the features of the words
located closest to the target predicate under
various constraints such as dependency types,
words, semantic categories, parts of speech,
functional words and predicate voices. We
constructed decision lists in which these fea-
tures were sorted by their learned weights. Us-
ing our method, we integrated the tasks of se-
mantic role labeling and zero-pronoun iden-
tification, and achieved a 17% improvement
compared with a baseline method in a sen-
tence level performance analysis.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999783583333334">
Recently, predicate argument structure analysis has
attracted the attention of researchers because this
information can increase the precision of text pro-
cessing tasks, such as machine translation, informa-
tion extraction (Hirschman et al., 1999), question
answering (Narayanan and Harabagiu, 2004) (Shen
and Lapata, 2007), and summarization (Melli et
al., 2005). In English predicate argument structure
analysis, large corpora such as FrameNet (Fillmore
et al., 2001), PropBank (Palmer et al., 2005) and
NomBank (Meyers et al., 2004) have been created
and utilized. Recently, the GDA Corpus (Hashida,
2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al.,
2002) and NAIST Text Corpus (Iida et al., 2007)
were constructed in Japanese, and these corpora
have become the target of an automatic Japanese
predicate argument structure analysis system. We
conducted Japanese predicate argument structure
(PAS) analysis for the NAIST Text Corpus, which
is the largest of these three corpora, and, as far as
we know, this is the first time PAS analysis has been
conducted for whole articles of the corpus.
The NAIST Text Corpus has the following char-
acteristics, i) semantic roles for both predicates and
event nouns are annotated in the corpus, ii) three ma-
jor case roles,1 namely the ga, wo and ni-cases in
Japanese are annotated for the base form of pred-
icates and event nouns, iii) both the case roles in
sentences containing the target predicates and those
outside the sentences (zero-pronouns) are annotated,
and iv) coreference relations are also annotated.
As regards i), recently there has been an increase
in the number of papers dealing with nominalized
predicates (Pradhan et al., 2004) (Jiang and Ng,
2006) (Xue, 2006) (Liu and Ng, 2007). For exam-
ple, ‘trip’ in the sentence “During my trip to Italy, I
met him.” refers not only to the event “I met him”
but also to the event “I traveled to Italy.” As in this
example, nouns sometimes have argument structures
referring to an event. Such nouns are called event
nouns (Komachi et al., 2007) in the NAIST Text
Corpus. At the same time, the problems related to
compound nouns are also important. In Japanese, a
compound noun sometimes simultaneously contains
both an event noun and its arguments. For example,
the compound noun, ‘企業買収 (corporate buyout)’
contains an event noun ‘買収 (buyout)’ and its ac-
cusative, ‘企業 (corporate).’ However, compound
</bodyText>
<footnote confidence="0.695061">
1Kyoto Text Corpus has about 15 case roles.
</footnote>
<page confidence="0.957397">
523
</page>
<note confidence="0.9622355">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 523–532,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.999962975">
nouns provide no information about syntactic de-
pendency or about case markers, so it is difficult to
specify the predicate-argument structure. Komachi
et al. investigated the argument structure of event
nouns using the co-occurrence of target nouns and
their case roles in the same sentence (Komachi et
al., 2007). In these approaches, predicates and event
nouns are dealt with separately. Here, we try to
unify these different argument structures using de-
cision lists.
As regards ii), for example, in the causative sen-
tence, ‘メアリーはトムに夕食を作らせる (Mary
makes Tom fix dinner),’ the basic form of the
causative verb, ‘作らせる (make fix)’ is ‘作る (fix),’
and its nominative is ‘トム (Tom)’ and the ac-
cusative case role (wo-case) is ‘夕食 (dinner),’ al-
though the surface case particle is ni (dative). We
must deal with syntactic transformations in passive,
causative, and benefactive constructions when ana-
lyzing the corpus.
As regards iii) and iv), in Japanese, zero pronouns
often occur, especially when the argument has al-
ready been mentioned in previous sentences. There
have been many studies of zero-pronoun identifica-
tion (Walker et al., 1994) (Nakaiwa, 1997) (Iida et
al., 2006).
In this paper, we present a general procedure for
handling both the case role assignment of predicates
and event nouns, and zero-pronoun identification.
We use the decision list learning of rules to find the
closest words with various constraints, because with
decision lists the readability of learned lists is high
and the learning is fast.
The rest of this paper is organized as follows. We
describe the NAIST Text Corpus, which is our tar-
get corpus in Section 2. We describe our proposed
method in Section 3. The result of experiments us-
ing the NAIST Text Corpus and our method are re-
ported in Section 4 and our conclusions are provided
in Section 5.
</bodyText>
<sectionHeader confidence="0.990409" genericHeader="introduction">
2 NAIST Text Corpus
</sectionHeader>
<bodyText confidence="0.999976566666667">
In the NAIST Text Corpus, three major obligatory
Japanese case roles are annotated, namely the ga-
case (nominative or subjective case), the wo-case
(accusative or direct object) and the ni-case (da-
tive or in-direct object). The NAIST Text Corpus
is based on the Kyoto Text Corpus Ver. 3.0, which
contains 38,384 sentences in 2,929 texts taken from
news articles and editorials in a Japanese newspaper,
the ‘Mainichi Shinbun’.
We divided these case roles into four types by lo-
cation in the article as in (Iida et al., 2006), i) the
case role depends on the predicate or the predicate
depends on the case role in the intra-sentence (‘de-
pendency relations’), ii) the case role does not de-
pend on the predicate and the predicate does not de-
pend on the case role in the intra-sentence (‘zero-
anaphoric (intra-sentential)’), iii) the case role is
not in the sentence containing the predicate (‘zero-
anaphoric (inter-sentential)’), and iv) the case role
and the predicate are in the same phrase (‘in same
phrase’). Here, we do not deal with exophora.
We show the distribution of the above four types
in test samples in our split of the NAIST Text
Corpus in Tables 1 and 2. In predicates, the
‘dependency relations’ type in the wo-case and
the ni-case occur frequently. In event nouns,
the ‘zero-anaphoric (intra-sentential)’ and ‘zero-
anaphoric (inter-sentential)’ types in the ga-case oc-
cur frequently. With respect to the ‘in same phrase’
type, the wo-case occurs frequently.
</bodyText>
<sectionHeader confidence="0.7499895" genericHeader="method">
3 Predicate Argument Structure Analysis
using Features of Closest Words
</sectionHeader>
<bodyText confidence="0.99998125">
In this section, we describe our algorithm. In the
algorithm, we used various constraints when search-
ing for the words located closest to the target predi-
cate. We described these constraints as features with
the direct products of dependency types (ic, oc, ga c,
wo c, ni c, sc, nc, fw and bw), generalization levels
(words, semantic categories, parts of speech), func-
tional words and voices.
</bodyText>
<subsectionHeader confidence="0.998859">
3.1 Dependency Types
</subsectionHeader>
<bodyText confidence="0.999994555555555">
In Japanese, the functional words in a phrase (Bun-
setsu in Japanese) and the interdependency of bun-
setsu phrases are important for determining the
predicate argument structure. In accordance with
the character of the dependency between the case
roles and the predicates or event nouns, we divided
Japanese word dependency into the following seven
types that cover all dependency types in Japanese.
Additionally, we use two optional dependency types.
</bodyText>
<page confidence="0.998876">
524
</page>
<tableCaption confidence="0.999221">
Table 1: Distribution of case roles for predicates (Test Data)
</tableCaption>
<table confidence="0.962859">
predicate
ga (Nominative) wo (Accusative) ni (Dative)
all 15,996 (100.00%) 8,348 (100.00%) 4,871 (100.00%)
dependency relations 9,591 ( 59.96%) 7,184 ( 86.06%) 4,276 ( 87.78%)
zero-anaphoric (intra-sentential) 3,856 ( 24.11%) 870 ( 10.42%) 360 ( 7.39%)
zero-anaphoric (inter-sentential) 2,496 ( 15.60%) 225 ( 2.70%) 132 ( 2.71%)
in same phrase 53 ( 0.33%) 69 ( 0.83%) 103 ( 2.11%)
</table>
<tableCaption confidence="0.965689">
Table 2: Distribution of case roles for event nouns (Test Data)
</tableCaption>
<figureCaption confidence="0.7750855">
event noun
ga (Nominative) wo (Accusative) ni (Dative)
all 4,099 (100.00%) 2,314 (100.00%) 423 (100.00%)
dependency relations 977 (23.84%) 648 (28.00%) 105 (24.82%)
zero-anaphoric (intra-sentential) 1,672 (40.79%) 348 (15.04%) 135 (31.91%)
zero-anaphoric (inter-sentential) 1,040 (25.37%) 165 (7.13%) 44 (10.40%)
in same phrase 410 (10.00%) 1,153 (49.83%) 139 (32.86%)
Figure 1: Type ic
3.1.1 Incoming Connection Type (ic)
With this type, the target case role is the head-
word of a bunsetsu phrase and the case role phrase
depends on the target predicate phrase (Figure 1).
3.1.2 Outgoing Connection Type (oc)
With this type, the target case role is the headword
of a phrase and a phrase containing a target predicate
or event noun depends on the case role phrase (Fig-
ure 2).
Figure 2: Type oc
</figureCaption>
<page confidence="0.972075">
525
</page>
<figureCaption confidence="0.9998905">
Figure 3: Type sc
Figure 4: Type ga c, wo c, ni c
</figureCaption>
<subsectionHeader confidence="0.923881">
3.1.3 ‘Within the Same Phrase’ Type (sc)
</subsectionHeader>
<bodyText confidence="0.999922333333333">
With this type, the target case role and the target
predicate or event noun are in the same phrase (Fig-
ure 3).
</bodyText>
<construct confidence="0.338707">
3.1.4 ‘Connection into Other Case role Types
(ga c, wo c, ni c)
</construct>
<bodyText confidence="0.999875333333333">
With these types, a phrase containing the target
case role depends on a phrase containing another
predetermined case role (Figure 4). We use the terms
‘ga c’, ‘wo c’ and ‘ni c’ when the predetermined
case roles are the ga-case, wo-case and ni-case, re-
spectively.
</bodyText>
<figureCaption confidence="0.994844">
Figure 5: Type nc
</figureCaption>
<subsectionHeader confidence="0.607181">
3.1.5 Non-connection Type (nc)
</subsectionHeader>
<bodyText confidence="0.999979">
With this type, a phrase containing the target case
role and a phrase containing the target predicate or
event noun are in the same article, but these phrases
do not depend on each other (Figure 5).
</bodyText>
<subsectionHeader confidence="0.943494">
3.1.6 Optional Type (fw and bw)
</subsectionHeader>
<bodyText confidence="0.999988636363637">
Type fw and bw stand for ‘forward’ and ‘back-
ward’ types, respectively. Type fw means the word
located closest to the target predicate or event noun
without considering functional words or voices.
With fw, the word is located between the top of the
article containing the target predicate and the target
predicate or event noun. Similarly, type bw means
the word located closest to the target predicate or
noun, which is located between the targeted predi-
cate or event noun, and the tail of the article con-
taining the predicate.
</bodyText>
<subsectionHeader confidence="0.999512">
3.2 Generalization Levels
</subsectionHeader>
<bodyText confidence="0.999862545454545">
We used three levels of generalization for every case
role candidate, that is, word, semantic category, and
part of speech. Every word is annotated with a part
of speech in the Kyoto Text Corpus, and we used
these annotations. With regard to semantic cate-
gories, we annotated every word with a semantic
category based on a Japanese thesaurus, Nihongo
Goi Taikei. The thesaurus consists of a hierarchy
of 2,710 semantic classes, defined for over 264,312
nouns, with a maximum depth of twelve (Ikehara et
al., 1997). We mainly used the semantic classes of
</bodyText>
<page confidence="0.996036">
526
</page>
<figureCaption confidence="0.996182">
Figure 6: Top 3 levels of the Japanese thesaurus, ‘Ni-
hongo Goi Taikei’
</figureCaption>
<bodyText confidence="0.9999432">
the third level, and partly the fourth level, which are
similar to semantic roles. We show the top three lev-
els of the Nihongo Goi Taikei common noun the-
saurus in Figure 6. We annotated the words with
their semantic category by hand.
</bodyText>
<subsectionHeader confidence="0.999404">
3.3 Functional Word and Voice
</subsectionHeader>
<bodyText confidence="0.999992666666667">
We used a functional word in the phrase containing
the target case role and active and passive voices for
the predicate as base features.
</bodyText>
<subsectionHeader confidence="0.98007">
3.4 Training Algorithm
</subsectionHeader>
<bodyText confidence="0.999942166666667">
The training algorithm used for our method is shown
in Figure 7. First, the algorithm constructs features
that search for the words located closest to the tar-
get predicate under various constraints. Next, the
algorithm learns by using linear Support Vector Ma-
chines (SVMs) (Vapnik, 1995). SVMs learn effec-
tive features by the one vs. rest method for every
case role. We used TinySVM 2 as an SVM imple-
mentation. Moreover, we construct decision lists
sorted by weight from linear SVMs. Finally, the al-
gorithm calculates the existing probabilities of case
roles for every predicate or event noun. This step
</bodyText>
<footnote confidence="0.843351">
2http://chasen.org/˜taku/software/TinySVM/
</footnote>
<bodyText confidence="0.999680545454545">
produces the criterion that decides whether or not
we will determine the case roles when there is no in-
terdependency between the case role candidate and
the predicate.
Our split of the NAIST Text Corpus has only
62,264 training samples for 2,874 predicates, and we
predict that there will be a shortage of training sam-
ples when adopting traditional learning algorithms,
such as learning algorithms using entropy. So, we
used SVMs with a high generalization capability to
learn the decision lists.
</bodyText>
<subsectionHeader confidence="0.991844">
3.5 Test Algorithm
</subsectionHeader>
<bodyText confidence="0.999992461538462">
The test algorithm of our method is shown in Fig-
ure 8. In the test phase, we analyzed test samples
using decision lists and the existing probabilities of
case roles learned in the training phase. In step 1, we
determined case roles using a decision list consisting
of features exhibiting case role and predicate inter-
dependency, that is, ic, oc, ga c, wo c, and ni c. This
is because there are many cases in Japanese where
the syntactic constraint is stronger than the seman-
tic constraint when we determine the case roles. In
step 2, we determined case roles using a decision list
of sc (‘in same phrase’) for the case roles that were
not determined in step 1. This step was mainly for
event nouns. Japanese event nouns frequently form
compound nouns that contain case roles. In step 3,
we decided whether or not to proceed to the next
step by using the existing probabilities of case roles.
If the probability was less than a certain threshold
(50%), then the algorithm stopped. In step 4, we de-
termined case roles using a decision list of the fea-
tures that have no interdependency, that is, nc, fw
and bw. This step will be executed when the target
case role is syntactically necessary and determined
by the co-occurrence of the case roles and predicate
or event noun without syntactic clues, such as de-
pendency, functional words and voices.
</bodyText>
<sectionHeader confidence="0.998095" genericHeader="method">
4 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.942933">
4.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.9993822">
We performed our experiments using the NAIST
Text Corpus 1.40 (Iida et al., 2007). We used
49,527 predicates and 12,737 event nouns from arti-
cles published from January 1st to January 11th and
the editorials from January to August as training ex-
</bodyText>
<page confidence="0.926217">
527
</page>
<bodyText confidence="0.50016">
for each predicate pi in all predicates appeared in the training corpus do
</bodyText>
<equation confidence="0.742591222222222">
feature list(pi) = {} ; n +— 0
clear (x, y)
for each instance pij of pi, in the training corpus do
Clear order() for all features
aij +— the article including pij
Wij +— the number of words in aij
pred index +— the word index of pij in aij
for (m = pred index − 1; m &gt; 1; m − −) do
n + +
</equation>
<bodyText confidence="0.880117666666667">
dep type = get dependency type(wm, pij)
if dep type == ‘ic’, ‘nc’, ‘ga c’, ‘wo c’ or ‘ni c’ then inc order(n, dep type, wm, pij)
else if dep type == ‘sc’ then inc order(n, dep type, ‘’, ‘’)
</bodyText>
<equation confidence="0.76017">
endif
inc order(n, ‘fw’, ‘’, ‘’)
if wm is the ga-case role then yn,ga +— 1 else yn,ga +— 0
if wm is the wo-case role then yn,wo +— 1 else yn,wo +— 0
if wm is the ni-case role then yn,ni +— 1 else yn,ni +— 0
end for
for (m = pred index + 1; m &lt; Wij; m + +) do
n + +
</equation>
<bodyText confidence="0.906703666666667">
dep type = get dependency type(wm, pij)
if dep type == ‘oc’, ‘nc’, ‘ga c’, ‘wo c’ or ‘ni c’ then inc order(n, dep type, wm, pij)
else if dep type == ‘sc’ then inc order(n, dep type, ‘’, ‘’)
</bodyText>
<construct confidence="0.7559724">
endif
inc order(n, ‘bw’, ‘’, ‘’)
if wm is the ga-case role then yn,ga +— 1 else yn,ga +— 0
if wm is the wo-case role then yn,wo +— 1 else yn,wo +— 0
if wm is the ni-case role then yn,ni +— 1 else yn,ni +— 0
</construct>
<tableCaption confidence="0.7065515">
end for
end for
</tableCaption>
<table confidence="0.877463714285714">
Learn linear SVMs using (x1, y1,ga), ..., (xn, yn,ga)
Learn linear SVMs using (x1, y1,wo), ..., (xn, yn,wo)
Learn linear SVMs using (x1, y1,ni), ..., (xn, yn,ni)
Make the decision list for pi, sorting features by weight.
Calculate the existing probabilities of case roles for pi.
end for
procedure get dependency type(wm, pij)
if phrase(wm) depends on phrase(pij) then return ‘ic’
else if phrase(pij) depends on phrase(wm) then return ‘oc’
else if phrase(wm) depends on phrase(pga) then return ‘ga c’
else if phrase(wm) depends on phrase(pwo) then return ‘wo c’
else if phrase(wm) depends on phrase(pni) then return ‘ni c’
else if phrase(wm) equals phrase(pij) then return ‘sc’
else return ‘nc’
</table>
<subsectionHeader confidence="0.565823">
end procedure
</subsectionHeader>
<bodyText confidence="0.6142062">
procedure inc order(n, dep type, func, voice)
Set a feature fw = (wm, dep type, func, voice) ; order(fw)++ ; if order(fw) == 1 then xn,fw +— 1
Set a feature fs = (sem(wm), dep type, func, voice) ; order(fs)++ ; if order(fs) == 1 then xn,f. +— 1
Set a feature fp = (pos(wm), dep type, func, voice) ; order(fp)++ ; if order(fp) == 1 then xn,f� � 1
feature list(pi) +— feature list(pi) U{fw, fs, fp}
</bodyText>
<footnote confidence="0.235894">
end procedure
</footnote>
<figureCaption confidence="0.996932">
Figure 7: Training algorithm
</figureCaption>
<page confidence="0.917704">
528
</page>
<bodyText confidence="0.9329194">
Step 1. Determine case roles using a decision list concerning ic, oc, ga c, wo c and ni c.
Step 2. Determine case roles using a decision list concerning sc for undetermined case roles in
Step.1.
Step 3. If the existing probability of case roles &lt; 50 % then the program ends.
Step 4. Determine case roles using a decision list concerning nc, fw and bw types.
</bodyText>
<figureCaption confidence="0.998056">
Figure 8: Test algorithm
</figureCaption>
<bodyText confidence="0.999941333333333">
amples. We used 11,023 predicates and 3,161 event
nouns from articles published on January 12th and
13th and the September editorials as development
examples. And we used 19,501 predicate and 5,276
event nouns from articles dated January 14th to 17th
and editorials dated October to December as test ex-
amples. This is a typical way to split the data.
We used the annotations in the Kyoto Text Corpus
as the interdependency of bunsetsu phrases. We used
both individual and multiple words as case roles. We
used the phrase boundaries annotated in the NAIST
Text Corpus in the training phase, and used those
annotated automatically by our system using POSs
and simple rules in the test phase. The accuracy of
the automatic annotation is about 90%.
</bodyText>
<subsectionHeader confidence="0.964601">
4.2 Baseline Method
</subsectionHeader>
<bodyText confidence="0.999991916666667">
To evaluate our algorithm, we conducted experi-
ments using a baseline method. With the method,
we used only nouns that depended on predicates or
event nouns as case role candidates. If the functional
word (post-positional case) in the phrase is ‘ga’,‘wo’
and ‘ni’, we determined the ga-case, wo-case, or ni-
case for the candidates. Next, as regards event nouns
in compound nouns, if there was another word in a
compound noun containing an event noun and it co-
occurred with the event noun as a case role with a
higher probability in the training samples, then the
word was selected for the case role.
</bodyText>
<subsectionHeader confidence="0.996922">
4.3 Entropy Method
</subsectionHeader>
<bodyText confidence="0.9986918">
The conventional approach for making decision lists
utilizes the entropy of samples selected by the
rules (Yarowsky, 1994) (Goodman, 2002). We per-
formed comparative experiments using Yarowsky’s
entropy algorithm (Yarowsky, 1994).
</bodyText>
<tableCaption confidence="0.9870615">
Table 3: Existing probabilities of case roles for predicates
and event nouns
</tableCaption>
<table confidence="0.999380142857143">
Predicate ga (NOM) Existing ni (DAT)
or Event Noun Probability
wo (ACC)
使う (use) 44.72% 82.92% 5.33%
交渉 (negotiation) 77.41% 30.70% 0.00%
参加 (participation) 87.09% 0.00% 72.46%
基づく (based on) 81.89% 0.00% 100.00%
</table>
<subsectionHeader confidence="0.996658">
4.4 Overall Results
</subsectionHeader>
<bodyText confidence="0.999978896551724">
The overall results are shown in Table 7. Here, ‘en-
tropy’ indicates Yarowsky’s algorithm, which uses
entropy (Yarowsky, 1994). Throughout the test data,
the F-measure (%) of our method exceeded that of
the baseline system and the ‘entropy’ system. With
the ga-case (nominative) in particular, the F-measure
increased 9 points.
Table 3 shows some examples of the existing
probabilities of case roles for predicates or event
nouns. When the probabilities are extreme values
such as the ni-case (dative) of 交渉 (negotiation), the
wo-case (accusative) of 参加 (participation), and the
wo-case and ni-base of 基づく (based on), we can
decide to fill the targeted case role or not with high
precision. However, it is difficult to decide to fill
the targeted case role or not when the probability is
close to 50 percent as in the ga-case of 使う (use).
We show the learned decision list of the ic type
(the case role depends on the predicate or event
noun), sc type (in the same phrase) and the other
types for event noun 交渉 (negotiation) in Tables 4, 5
and 6, respectively. Here, ‘word’ in the ‘level’
column means ‘base form of predicate’ and ‘sem’
means ’semantic category of predicate.’ In the ic
and sc type decision lists, features with semantic
categories, such as ‘REGION’, ’LOCATION’ and
‘EVENT’, occupy a higher order. In contrast, in
the list of the other types, the features that occupy
the higher order are the features of the word base
</bodyText>
<page confidence="0.99916">
529
</page>
<tableCaption confidence="0.999729">
Table 4: Decision list for ic type of event noun 3Z$ (negotiation)
</tableCaption>
<table confidence="0.993471916666667">
order case dep type level head word functional voice weight
word
1 ga ic word kf AMALVM (North Korea) 0) (of) active 0.9820
2 ga ic sem fWA (REGION) 0) (of) active 0.6381
3 ga ic word H *A4M (both Japan and U.S.) 0) (of) active 0.5502
4 wo ic word I&amp;quot; #11W RA (establishment of joint ventures) 0) (of) active 0.5288
5 wo ic word %%W03 ff (telecommunications) 0) (of) active 0.4142
6 wo ic word kf AMALVM (North Korea) L0) (for) active 0.3168
7 wo ic word HA (ACTION) 0) (of) active 0.3083
8 ga ic sem X3 p (OOV NOUN) 0) (of) active 0.2939
9 wo ic word n 1*•HInj`fian3 ff (car and auto parts sector) 0) (of) active 0.2775
10 wo ic sem * (LOCATION) 0) (of) active 0.2471
</table>
<tableCaption confidence="0.996051">
Table 5: Decision list for sc type of event noun 3Z$ (negotiation)
</tableCaption>
<table confidence="0.507652818181818">
order case dep type level head word weight
1 wo sc sem (EVENT) 1.1738
2 wo sc word � (arrangement) 1.0000
3 ga sc word HrPPAM&apos; (airline of Japan and China) 0.9392
4 wo sc sem ,t:# (MENTAL STATE) 0.8958
5 ga sc word H -e7,3 ff (financial services of Japan and U.S.) 0.8371
6 wo sc word NVW&amp; (contract extension) 0.7870
7 wo sc word I&amp;quot;# (joint venture) 0.7865
8 wo sc word �nfflfilf0 (intellectual property rights) 0.7224
9 wo sc word n 1*•HInj`fian (car and auto parts) 0.7196
10 ga sc word H01 (Japan and North Korea) 0.6771
</table>
<tableCaption confidence="0.994361">
Table 6: Decision list for other types of event noun 3Z$ (negotiation)
</tableCaption>
<table confidence="0.887906181818182">
order case dep type level head word functional word voice weight
1 ga fw word H* (Japan and U.S.) 1.9954
2 ga fw word O (Taiwan) 1.9952
3 ga fw word *01 (U.S. and North Korea) 1.4979
4 ga fw word ArP (U.K. and China) 1.1773
5 ga nc word AM (both nations) U (TOP) active 1.1379
6 wo fw word M3ZEWL (diplomatic normalization) 1.0000
7 ga bw word *01 (U.S. and North Korea) 1.0000
8 ga fw word � (t (capital and labor) 1.0000
9 wo fw word n 1*3 ff (automotive area) 1.0000
10 ga nc word W)7 (both sides) U (TOP) active 1.0000
</table>
<tableCaption confidence="0.967139">
Table 7: Overall results for NAIST Text Corpus (F-measure(%))
</tableCaption>
<table confidence="0.9863366">
training data test data
sentence ga (NOM) wo (ACC) ni (DAT) sentence ga (NOM) wo (ACC) ni (DAT)
baseline 25.32 32.58 74.51 82.70 21.34 30.08 69.48 76.62
entropy 73.46 89.53 92.72 91.09 33.10 45.67 73.28 77.77
our method 64.81 86.76 92.52 92.20 38.06 55.07 75.82 80.45
</table>
<page confidence="0.898965">
530
</page>
<tableCaption confidence="0.978741">
Table 8: Results for predicates in test sets (F-measure(%))
</tableCaption>
<table confidence="0.993992428571429">
baseline / our method
ga (Nominative) wo (Accusative) ni (Dative)
all 34.44 / 57.40 77.00 / 79.50 79.83 / 83.15
dependency relations 51.96 / 75.53 85.42 / 88.20 81.83 / 89.51
zero-anaphoric (intra-sentential) 0.00 / 30.15 0.00 / 11.41 0.00 / 3.66
zero-anaphoric (inter-sentential) 1.85 / 23.45 3.00 / 9.32 0.00 / 11.76
in same phrase 0.00 / 75.00 0.00 / 51.78 0.00 / 84.65
</table>
<tableCaption confidence="0.988958">
Table 9: Results for event nouns (F-measure(%))
</tableCaption>
<bodyText confidence="0.95185">
baseline / our method
ga (Nominative) wo (Accusative) ni (Dative)
all 11.05 / 45.64 32.30 / 61.80 20.85 / 38.88
dependency relations 12.98 / 68.01 25.00 / 62.46 40.00 / 56.05
zero-anaphoric (intra-sentential) 0.00 / 36.19 0.00 / 20.46 0.00 / 6.62
zero-anaphoric (inter-sentential) 1.40 / 23.25 1.06 / 10.37 0.00 / 3.51
in same phrase 58.76 / 78.93 47.44 / 77.96 28.91 / 58.13
form. This means local knowledge of relations be-
tween case roles and predicates or event nouns in
the word level is more important than semantic level
knowledge.
</bodyText>
<sectionHeader confidence="0.822191" genericHeader="method">
4.5 Results for Predicates in Test Sets
</sectionHeader>
<bodyText confidence="0.999801">
We show the results we obtained for predicates in
Table 8. The results reveal that our method is supe-
rior to the baseline system. Our algorithm is partic-
ularly effective in the ga-case.
</bodyText>
<sectionHeader confidence="0.975367" genericHeader="evaluation">
4.6 Results for Event Nouns in Test Sets
</sectionHeader>
<bodyText confidence="0.9999206">
We show the results we obtained for event nouns in
Table 9. This also shows that our method is superior
to the baseline system. The precision with sc type
is high and our method is effective as regards event
nouns.
</bodyText>
<sectionHeader confidence="0.998953" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999963571428571">
We presented a new method for Japanese automatic
predicate argument structure analysis using deci-
sion lists based on the features of the words located
closest to the target predicate under various con-
straints. The method learns the relative weights of
these different features for case roles and ranks them
using decision lists. Using our method, we inte-
grated the knowledge of case role determination and
zero-pronoun identification, and generally achieved
a high precision in Japanese PAS analysis. In par-
ticular, we can extract knowledge at various levels
from the corpus for event nouns. In future, we will
use richer constraints and research better ways of
distinguishing whether or not cases are obligatory.
</bodyText>
<sectionHeader confidence="0.997475" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99979125">
We thank Ryu Iida and Yuji Matsumoto of NAIST
for the definitions of the case roles in the NAIST
Text Corpus and functional words, and Franklin
Chang for valuable comments.
</bodyText>
<sectionHeader confidence="0.99855" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999231823529412">
Charles J. Fillmore, Charles Wooters, and Collin F.
Baker. 2001. Building a large lexical databank which
provides deep semantics. In Proc. of the Pacific Asian
Conference on Language, Information and Computa-
tion (PACLING).
Joshua Goodman. 2002. An incremental decision
list learner. In Proc. of the ACL-02 Conference
on Empirical Methods in Natural Language Process-
ing(EMNLP02), pages 17–24.
Kouichi Hashida. 2005. Global document annotation
(GDA) manual. http://i-content.org/GDA/.
Lynette Hirschman, Patricia Robinson, Lisa Ferro, Nancy
Chinchor, Erica Brown, Ralph Grishman, and Beth
Sundheim. 1999. Hub-4 Event’99 general guidelines.
Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2006. Ex-
ploiting syntactic patterns as clues in zero-anaphora
resolution. In Proc. of the 21st International Confer-
</reference>
<page confidence="0.974666">
531
</page>
<reference confidence="0.999103236842105">
ence on Computational Linguistics and 44th Annual
Meeting of the ACL, pages 625–632.
Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji Mat-
sumoto. 2007. Annotating a Japanese text corpus
with predicate-argument and coreference relations. In
Proc. of ACL 2007 Workshop on Linguistic Annota-
tion, pages 132–139.
Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio
Yokoo, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi
Ooyama, and Yoshihiko Hayashi. 1997. Nihongo Goi
Taikei, A Japanese Lexicon. Iwanami Shoten, Tokyo.
Zheng Ping Jiang and Hwee Tou Ng. 2006. Semantic
role labeling of NomBank: A maximum entropy ap-
proach. In Proc. of the Conference on Empirical Meth-
ods in Natural Language Processing.
Daisuke Kawahara, Sadao Kurohashi, and Koichi
Hashida. 2002. Construction of a Japanese relevance-
tagged corpus (in Japanese). Proc. of the 8th Annual
Meeting of the Association for Natural Language Pro-
cessing, pages 495–498.
Mamoru Komachi, Ryu Iida, Kentaro Inui, and Yuji Mat-
sumoto. 2007. Learning-based argument structure
analysis of event-nouns in Japanese. In Proc. of the
Conference of the Pacific Association for Computa-
tional Linguistics (PACLING), pages 120–128.
Chang Liu and Hwee Tou Ng. 2007. Learning predictive
structures for semantic role labeling of NomBank. In
Proc. of the 45th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 208–215.
Gabor Melli, Yang Wang, Yudong Liu, Mehdi M.
Kashani, Zhongmin Shi, Baohua Gu, Anoop Sarkar,
and Fred Popowich. 2005. Description of SQUASH,
the SFU question answering summary handler for the
DUC-2005 summarization task. In Proc. of DUC
2005.
Adam Meyers, Ruth Reeves, Catherine Macleod, Rachel
Szekely, Veronika Zielinska, Brian Young, and Ralph
Grishman. 2004. The NomBank project: An interim
report. In Proc. of HLT-NAACL 2004 Workshop on
Frontiers in Corpus Annotation.
Hiromi Nakaiwa. 1997. Automatic identification of zero
pronouns and their antecedents within aligned sen-
tence pairs. In Proc. of the 3rd Annual Meeting of
the Association for Natural Language Processing (in
Japanese).
Srini Narayanan and Sanda Harabagiu. 2004. Question
answering based on semantic structures. In Proc. of
the 20th International Conference on Computational
Linguistics (COLING).
M. Palmer, P. Kingsbury, and D. Gildea. 2005. The
proposition bank: An annotated corpus of semantic
roles. Computational Linguistics, 31(1):71–106.
Sameer Pradhan, Waybe Ward, Kadri Hacioglu, James
Martin, and Dan Jurafsky. 2004. Shallow seman-
tic parsing using support vector machines. In Proc.
of the Human Language Technology Conference/North
American Chapter of the Association of Computa-
tional Linguistics HLT/NAACL 2004.
Dan Shen and Mirella Lapata. 2007. Using semantic
roles to improve question answering. In Proc. of the
2007 Joint Conference on Empirical Methods in Natu-
ral Language Processing and Computational Natural
Language Learning (EMNLP/CoNLL), pages 12–21.
V. Vapnik. 1995. The Nature of Statistical Learning The-
ory. Springer-Verlag, New York.
M. Walker, M. Iida, and S. Cote. 1994. Japanese dis-
course and the process of centering. Computational
Linguistics, 20(2):193–233.
Nianwen Xue. 2006. Semantic role labeling of nomi-
nalized predicates in Chinese. In Proc. of the HLT-
NAACL, pages 431–438.
David Yarowsky. 1994. Decision lists for lexical am-
biguity resolution: Application to accent restoration
in Spanish and French. In Proc. of the 32nd Annual
Meeting of the Association for Computational Linguis-
tics (ACL), pages 88–95.
</reference>
<page confidence="0.997181">
532
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.426198">
<title confidence="0.999859">A Japanese Predicate Argument Structure Analysis using Decision Lists</title>
<author confidence="0.993517">Hirotoshi Taira</author>
<author confidence="0.993517">Sanae Fujita</author>
<author confidence="0.993517">Masaaki</author>
<affiliation confidence="0.998088">NTT Communication Science</affiliation>
<address confidence="0.942332">2-4, Hikaridai,</address>
<affiliation confidence="0.664566">Keihanna Science</affiliation>
<address confidence="0.488488">Kyoto 619-0237,</address>
<abstract confidence="0.99912405882353">This paper describes a new automatic method for Japanese predicate argument structure analysis. The method learns relevant features to assign case roles to the argument of the target predicate using the features of the words located closest to the target predicate under various constraints such as dependency types, words, semantic categories, parts of speech, functional words and predicate voices. We constructed decision lists in which these features were sorted by their learned weights. Using our method, we integrated the tasks of semantic role labeling and zero-pronoun identification, and achieved a 17% improvement compared with a baseline method in a sentence level performance analysis.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Charles Wooters</author>
<author>Collin F Baker</author>
</authors>
<title>Building a large lexical databank which provides deep semantics.</title>
<date>2001</date>
<booktitle>In Proc. of the Pacific Asian Conference on Language, Information and Computation (PACLING).</booktitle>
<contexts>
<context position="1474" citStr="Fillmore et al., 2001" startWordPosition="203" endWordPosition="206">g and zero-pronoun identification, and achieved a 17% improvement compared with a baseline method in a sentence level performance analysis. 1 Introduction Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) have been created and utilized. Recently, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002) and NAIST Text Corpus (Iida et al., 2007) were constructed in Japanese, and these corpora have become the target of an automatic Japanese predicate argument structure analysis system. We conducted Japanese predicate argument structure (PAS) analysis for the NAIST Text Corpus, which is the largest of these three corpora, and, as far as we know, this is the first time PAS analysis has been conducted for whol</context>
</contexts>
<marker>Fillmore, Wooters, Baker, 2001</marker>
<rawString>Charles J. Fillmore, Charles Wooters, and Collin F. Baker. 2001. Building a large lexical databank which provides deep semantics. In Proc. of the Pacific Asian Conference on Language, Information and Computation (PACLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua Goodman</author>
</authors>
<title>An incremental decision list learner.</title>
<date>2002</date>
<booktitle>In Proc. of the ACL-02 Conference on Empirical Methods in Natural Language Processing(EMNLP02),</booktitle>
<pages>17--24</pages>
<contexts>
<context position="18692" citStr="Goodman, 2002" startWordPosition="3159" endWordPosition="3160">or event nouns as case role candidates. If the functional word (post-positional case) in the phrase is ‘ga’,‘wo’ and ‘ni’, we determined the ga-case, wo-case, or nicase for the candidates. Next, as regards event nouns in compound nouns, if there was another word in a compound noun containing an event noun and it cooccurred with the event noun as a case role with a higher probability in the training samples, then the word was selected for the case role. 4.3 Entropy Method The conventional approach for making decision lists utilizes the entropy of samples selected by the rules (Yarowsky, 1994) (Goodman, 2002). We performed comparative experiments using Yarowsky’s entropy algorithm (Yarowsky, 1994). Table 3: Existing probabilities of case roles for predicates and event nouns Predicate ga (NOM) Existing ni (DAT) or Event Noun Probability wo (ACC) 使う (use) 44.72% 82.92% 5.33% 交渉 (negotiation) 77.41% 30.70% 0.00% 参加 (participation) 87.09% 0.00% 72.46% 基づく (based on) 81.89% 0.00% 100.00% 4.4 Overall Results The overall results are shown in Table 7. Here, ‘entropy’ indicates Yarowsky’s algorithm, which uses entropy (Yarowsky, 1994). Throughout the test data, the F-measure (%) of our method exceeded that</context>
</contexts>
<marker>Goodman, 2002</marker>
<rawString>Joshua Goodman. 2002. An incremental decision list learner. In Proc. of the ACL-02 Conference on Empirical Methods in Natural Language Processing(EMNLP02), pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kouichi Hashida</author>
</authors>
<title>Global document annotation (GDA)</title>
<date>2005</date>
<note>manual. http://i-content.org/GDA/.</note>
<contexts>
<context position="1613" citStr="Hashida, 2005" startWordPosition="227" endWordPosition="228">duction Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) have been created and utilized. Recently, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002) and NAIST Text Corpus (Iida et al., 2007) were constructed in Japanese, and these corpora have become the target of an automatic Japanese predicate argument structure analysis system. We conducted Japanese predicate argument structure (PAS) analysis for the NAIST Text Corpus, which is the largest of these three corpora, and, as far as we know, this is the first time PAS analysis has been conducted for whole articles of the corpus. The NAIST Text Corpus has the following characteristics, i) semantic roles for both predicates and event nouns ar</context>
</contexts>
<marker>Hashida, 2005</marker>
<rawString>Kouichi Hashida. 2005. Global document annotation (GDA) manual. http://i-content.org/GDA/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynette Hirschman</author>
<author>Patricia Robinson</author>
<author>Lisa Ferro</author>
<author>Nancy Chinchor</author>
<author>Erica Brown</author>
<author>Ralph Grishman</author>
<author>Beth Sundheim</author>
</authors>
<date>1999</date>
<note>Hub-4 Event’99 general guidelines.</note>
<contexts>
<context position="1252" citStr="Hirschman et al., 1999" startWordPosition="172" endWordPosition="175">egories, parts of speech, functional words and predicate voices. We constructed decision lists in which these features were sorted by their learned weights. Using our method, we integrated the tasks of semantic role labeling and zero-pronoun identification, and achieved a 17% improvement compared with a baseline method in a sentence level performance analysis. 1 Introduction Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) have been created and utilized. Recently, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002) and NAIST Text Corpus (Iida et al., 2007) were constructed in Japanese, and these corpora have become the target of an automatic Japanese predicate argument structure analysis system. We </context>
</contexts>
<marker>Hirschman, Robinson, Ferro, Chinchor, Brown, Grishman, Sundheim, 1999</marker>
<rawString>Lynette Hirschman, Patricia Robinson, Lisa Ferro, Nancy Chinchor, Erica Brown, Ralph Grishman, and Beth Sundheim. 1999. Hub-4 Event’99 general guidelines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Exploiting syntactic patterns as clues in zero-anaphora resolution.</title>
<date>2006</date>
<booktitle>In Proc. of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL,</booktitle>
<pages>625--632</pages>
<contexts>
<context position="4795" citStr="Iida et al., 2006" startWordPosition="738" endWordPosition="741">es Tom fix dinner),’ the basic form of the causative verb, ‘作らせる (make fix)’ is ‘作る (fix),’ and its nominative is ‘トム (Tom)’ and the accusative case role (wo-case) is ‘夕食 (dinner),’ although the surface case particle is ni (dative). We must deal with syntactic transformations in passive, causative, and benefactive constructions when analyzing the corpus. As regards iii) and iv), in Japanese, zero pronouns often occur, especially when the argument has already been mentioned in previous sentences. There have been many studies of zero-pronoun identification (Walker et al., 1994) (Nakaiwa, 1997) (Iida et al., 2006). In this paper, we present a general procedure for handling both the case role assignment of predicates and event nouns, and zero-pronoun identification. We use the decision list learning of rules to find the closest words with various constraints, because with decision lists the readability of learned lists is high and the learning is fast. The rest of this paper is organized as follows. We describe the NAIST Text Corpus, which is our target corpus in Section 2. We describe our proposed method in Section 3. The result of experiments using the NAIST Text Corpus and our method are reported in </context>
</contexts>
<marker>Iida, Inui, Matsumoto, 2006</marker>
<rawString>Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2006. Exploiting syntactic patterns as clues in zero-anaphora resolution. In Proc. of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 625–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Mamoru Komachi</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Annotating a Japanese text corpus with predicate-argument and coreference relations.</title>
<date>2007</date>
<booktitle>In Proc. of ACL 2007 Workshop on Linguistic Annotation,</booktitle>
<pages>132--139</pages>
<contexts>
<context position="1706" citStr="Iida et al., 2007" startWordPosition="241" endWordPosition="244">searchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) have been created and utilized. Recently, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002) and NAIST Text Corpus (Iida et al., 2007) were constructed in Japanese, and these corpora have become the target of an automatic Japanese predicate argument structure analysis system. We conducted Japanese predicate argument structure (PAS) analysis for the NAIST Text Corpus, which is the largest of these three corpora, and, as far as we know, this is the first time PAS analysis has been conducted for whole articles of the corpus. The NAIST Text Corpus has the following characteristics, i) semantic roles for both predicates and event nouns are annotated in the corpus, ii) three major case roles,1 namely the ga, wo and ni-cases in Jap</context>
<context position="14237" citStr="Iida et al., 2007" startWordPosition="2324" endWordPosition="2327">xisting probabilities of case roles. If the probability was less than a certain threshold (50%), then the algorithm stopped. In step 4, we determined case roles using a decision list of the features that have no interdependency, that is, nc, fw and bw. This step will be executed when the target case role is syntactically necessary and determined by the co-occurrence of the case roles and predicate or event noun without syntactic clues, such as dependency, functional words and voices. 4 Experimental Results 4.1 Experimental Setting We performed our experiments using the NAIST Text Corpus 1.40 (Iida et al., 2007). We used 49,527 predicates and 12,737 event nouns from articles published from January 1st to January 11th and the editorials from January to August as training ex527 for each predicate pi in all predicates appeared in the training corpus do feature list(pi) = {} ; n +— 0 clear (x, y) for each instance pij of pi, in the training corpus do Clear order() for all features aij +— the article including pij Wij +— the number of words in aij pred index +— the word index of pij in aij for (m = pred index − 1; m &gt; 1; m − −) do n + + dep type = get dependency type(wm, pij) if dep type == ‘ic’, ‘nc’, ‘g</context>
</contexts>
<marker>Iida, Komachi, Inui, Matsumoto, 2007</marker>
<rawString>Ryu Iida, Mamoru Komachi, Kentaro Inui, and Yuji Matsumoto. 2007. Annotating a Japanese text corpus with predicate-argument and coreference relations. In Proc. of ACL 2007 Workshop on Linguistic Annotation, pages 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoru Ikehara</author>
<author>Masahiro Miyazaki</author>
<author>Satoshi Shirai</author>
</authors>
<title>Akio Yokoo, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi Ooyama, and Yoshihiko Hayashi.</title>
<date>1997</date>
<location>Tokyo.</location>
<contexts>
<context position="11060" citStr="Ikehara et al., 1997" startWordPosition="1785" endWordPosition="1788">ed predicate or event noun, and the tail of the article containing the predicate. 3.2 Generalization Levels We used three levels of generalization for every case role candidate, that is, word, semantic category, and part of speech. Every word is annotated with a part of speech in the Kyoto Text Corpus, and we used these annotations. With regard to semantic categories, we annotated every word with a semantic category based on a Japanese thesaurus, Nihongo Goi Taikei. The thesaurus consists of a hierarchy of 2,710 semantic classes, defined for over 264,312 nouns, with a maximum depth of twelve (Ikehara et al., 1997). We mainly used the semantic classes of 526 Figure 6: Top 3 levels of the Japanese thesaurus, ‘Nihongo Goi Taikei’ the third level, and partly the fourth level, which are similar to semantic roles. We show the top three levels of the Nihongo Goi Taikei common noun thesaurus in Figure 6. We annotated the words with their semantic category by hand. 3.3 Functional Word and Voice We used a functional word in the phrase containing the target case role and active and passive voices for the predicate as base features. 3.4 Training Algorithm The training algorithm used for our method is shown in Figu</context>
</contexts>
<marker>Ikehara, Miyazaki, Shirai, 1997</marker>
<rawString>Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio Yokoo, Hiromi Nakaiwa, Kentaro Ogura, Yoshifumi Ooyama, and Yoshihiko Hayashi. 1997. Nihongo Goi Taikei, A Japanese Lexicon. Iwanami Shoten, Tokyo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Ping Jiang</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Semantic role labeling of NomBank: A maximum entropy approach.</title>
<date>2006</date>
<booktitle>In Proc. of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="2713" citStr="Jiang and Ng, 2006" startWordPosition="405" endWordPosition="408">rpus. The NAIST Text Corpus has the following characteristics, i) semantic roles for both predicates and event nouns are annotated in the corpus, ii) three major case roles,1 namely the ga, wo and ni-cases in Japanese are annotated for the base form of predicates and event nouns, iii) both the case roles in sentences containing the target predicates and those outside the sentences (zero-pronouns) are annotated, and iv) coreference relations are also annotated. As regards i), recently there has been an increase in the number of papers dealing with nominalized predicates (Pradhan et al., 2004) (Jiang and Ng, 2006) (Xue, 2006) (Liu and Ng, 2007). For example, ‘trip’ in the sentence “During my trip to Italy, I met him.” refers not only to the event “I met him” but also to the event “I traveled to Italy.” As in this example, nouns sometimes have argument structures referring to an event. Such nouns are called event nouns (Komachi et al., 2007) in the NAIST Text Corpus. At the same time, the problems related to compound nouns are also important. In Japanese, a compound noun sometimes simultaneously contains both an event noun and its arguments. For example, the compound noun, ‘企業買収 (corporate buyout)’ cont</context>
</contexts>
<marker>Jiang, Ng, 2006</marker>
<rawString>Zheng Ping Jiang and Hwee Tou Ng. 2006. Semantic role labeling of NomBank: A maximum entropy approach. In Proc. of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
<author>Koichi Hashida</author>
</authors>
<title>Construction of a Japanese relevancetagged corpus (in</title>
<date>2002</date>
<booktitle>Japanese). Proc. of the 8th Annual Meeting of the Association for Natural Language Processing,</booktitle>
<pages>495--498</pages>
<contexts>
<context position="1664" citStr="Kawahara et al., 2002" startWordPosition="233" endWordPosition="236">ure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) have been created and utilized. Recently, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002) and NAIST Text Corpus (Iida et al., 2007) were constructed in Japanese, and these corpora have become the target of an automatic Japanese predicate argument structure analysis system. We conducted Japanese predicate argument structure (PAS) analysis for the NAIST Text Corpus, which is the largest of these three corpora, and, as far as we know, this is the first time PAS analysis has been conducted for whole articles of the corpus. The NAIST Text Corpus has the following characteristics, i) semantic roles for both predicates and event nouns are annotated in the corpus, ii) three major case rol</context>
</contexts>
<marker>Kawahara, Kurohashi, Hashida, 2002</marker>
<rawString>Daisuke Kawahara, Sadao Kurohashi, and Koichi Hashida. 2002. Construction of a Japanese relevancetagged corpus (in Japanese). Proc. of the 8th Annual Meeting of the Association for Natural Language Processing, pages 495–498.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mamoru Komachi</author>
<author>Ryu Iida</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Learning-based argument structure analysis of event-nouns in Japanese.</title>
<date>2007</date>
<booktitle>In Proc. of the Conference of the Pacific Association for Computational Linguistics (PACLING),</booktitle>
<pages>120--128</pages>
<contexts>
<context position="3046" citStr="Komachi et al., 2007" startWordPosition="467" endWordPosition="470">he target predicates and those outside the sentences (zero-pronouns) are annotated, and iv) coreference relations are also annotated. As regards i), recently there has been an increase in the number of papers dealing with nominalized predicates (Pradhan et al., 2004) (Jiang and Ng, 2006) (Xue, 2006) (Liu and Ng, 2007). For example, ‘trip’ in the sentence “During my trip to Italy, I met him.” refers not only to the event “I met him” but also to the event “I traveled to Italy.” As in this example, nouns sometimes have argument structures referring to an event. Such nouns are called event nouns (Komachi et al., 2007) in the NAIST Text Corpus. At the same time, the problems related to compound nouns are also important. In Japanese, a compound noun sometimes simultaneously contains both an event noun and its arguments. For example, the compound noun, ‘企業買収 (corporate buyout)’ contains an event noun ‘買収 (buyout)’ and its accusative, ‘企業 (corporate).’ However, compound 1Kyoto Text Corpus has about 15 case roles. 523 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 523–532, Honolulu, October 2008.c�2008 Association for Computational Linguistics nouns provide no info</context>
</contexts>
<marker>Komachi, Iida, Inui, Matsumoto, 2007</marker>
<rawString>Mamoru Komachi, Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2007. Learning-based argument structure analysis of event-nouns in Japanese. In Proc. of the Conference of the Pacific Association for Computational Linguistics (PACLING), pages 120–128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chang Liu</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Learning predictive structures for semantic role labeling of NomBank.</title>
<date>2007</date>
<booktitle>In Proc. of the 45th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>208--215</pages>
<contexts>
<context position="2744" citStr="Liu and Ng, 2007" startWordPosition="411" endWordPosition="414">he following characteristics, i) semantic roles for both predicates and event nouns are annotated in the corpus, ii) three major case roles,1 namely the ga, wo and ni-cases in Japanese are annotated for the base form of predicates and event nouns, iii) both the case roles in sentences containing the target predicates and those outside the sentences (zero-pronouns) are annotated, and iv) coreference relations are also annotated. As regards i), recently there has been an increase in the number of papers dealing with nominalized predicates (Pradhan et al., 2004) (Jiang and Ng, 2006) (Xue, 2006) (Liu and Ng, 2007). For example, ‘trip’ in the sentence “During my trip to Italy, I met him.” refers not only to the event “I met him” but also to the event “I traveled to Italy.” As in this example, nouns sometimes have argument structures referring to an event. Such nouns are called event nouns (Komachi et al., 2007) in the NAIST Text Corpus. At the same time, the problems related to compound nouns are also important. In Japanese, a compound noun sometimes simultaneously contains both an event noun and its arguments. For example, the compound noun, ‘企業買収 (corporate buyout)’ contains an event noun ‘買収 (buyout)</context>
</contexts>
<marker>Liu, Ng, 2007</marker>
<rawString>Chang Liu and Hwee Tou Ng. 2007. Learning predictive structures for semantic role labeling of NomBank. In Proc. of the 45th Annual Meeting of the Association for Computational Linguistics (ACL), pages 208–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabor Melli</author>
<author>Yang Wang</author>
<author>Yudong Liu</author>
<author>Mehdi M Kashani</author>
<author>Zhongmin Shi</author>
<author>Baohua Gu</author>
<author>Anoop Sarkar</author>
<author>Fred Popowich</author>
</authors>
<title>Description of SQUASH, the SFU question answering summary handler for the DUC-2005 summarization task.</title>
<date>2005</date>
<booktitle>In Proc. of DUC</booktitle>
<contexts>
<context position="1368" citStr="Melli et al., 2005" startWordPosition="188" endWordPosition="191">ere sorted by their learned weights. Using our method, we integrated the tasks of semantic role labeling and zero-pronoun identification, and achieved a 17% improvement compared with a baseline method in a sentence level performance analysis. 1 Introduction Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) have been created and utilized. Recently, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002) and NAIST Text Corpus (Iida et al., 2007) were constructed in Japanese, and these corpora have become the target of an automatic Japanese predicate argument structure analysis system. We conducted Japanese predicate argument structure (PAS) analysis for the NAIST Text Corpus, which is the largest of th</context>
</contexts>
<marker>Melli, Wang, Liu, Kashani, Shi, Gu, Sarkar, Popowich, 2005</marker>
<rawString>Gabor Melli, Yang Wang, Yudong Liu, Mehdi M. Kashani, Zhongmin Shi, Baohua Gu, Anoop Sarkar, and Fred Popowich. 2005. Description of SQUASH, the SFU question answering summary handler for the DUC-2005 summarization task. In Proc. of DUC 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Meyers</author>
<author>Ruth Reeves</author>
<author>Catherine Macleod</author>
<author>Rachel Szekely</author>
<author>Veronika Zielinska</author>
<author>Brian Young</author>
<author>Ralph Grishman</author>
</authors>
<title>The NomBank project: An interim report.</title>
<date>2004</date>
<booktitle>In Proc. of HLT-NAACL 2004 Workshop on Frontiers in Corpus Annotation.</booktitle>
<contexts>
<context position="1540" citStr="Meyers et al., 2004" startWordPosition="214" endWordPosition="217">mpared with a baseline method in a sentence level performance analysis. 1 Introduction Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) have been created and utilized. Recently, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002) and NAIST Text Corpus (Iida et al., 2007) were constructed in Japanese, and these corpora have become the target of an automatic Japanese predicate argument structure analysis system. We conducted Japanese predicate argument structure (PAS) analysis for the NAIST Text Corpus, which is the largest of these three corpora, and, as far as we know, this is the first time PAS analysis has been conducted for whole articles of the corpus. The NAIST Text Corpus has the following </context>
</contexts>
<marker>Meyers, Reeves, Macleod, Szekely, Zielinska, Young, Grishman, 2004</marker>
<rawString>Adam Meyers, Ruth Reeves, Catherine Macleod, Rachel Szekely, Veronika Zielinska, Brian Young, and Ralph Grishman. 2004. The NomBank project: An interim report. In Proc. of HLT-NAACL 2004 Workshop on Frontiers in Corpus Annotation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiromi Nakaiwa</author>
</authors>
<title>Automatic identification of zero pronouns and their antecedents within aligned sentence pairs.</title>
<date>1997</date>
<booktitle>In Proc. of the 3rd Annual Meeting of the Association for Natural Language Processing (in Japanese).</booktitle>
<contexts>
<context position="4775" citStr="Nakaiwa, 1997" startWordPosition="736" endWordPosition="737">食を作らせる (Mary makes Tom fix dinner),’ the basic form of the causative verb, ‘作らせる (make fix)’ is ‘作る (fix),’ and its nominative is ‘トム (Tom)’ and the accusative case role (wo-case) is ‘夕食 (dinner),’ although the surface case particle is ni (dative). We must deal with syntactic transformations in passive, causative, and benefactive constructions when analyzing the corpus. As regards iii) and iv), in Japanese, zero pronouns often occur, especially when the argument has already been mentioned in previous sentences. There have been many studies of zero-pronoun identification (Walker et al., 1994) (Nakaiwa, 1997) (Iida et al., 2006). In this paper, we present a general procedure for handling both the case role assignment of predicates and event nouns, and zero-pronoun identification. We use the decision list learning of rules to find the closest words with various constraints, because with decision lists the readability of learned lists is high and the learning is fast. The rest of this paper is organized as follows. We describe the NAIST Text Corpus, which is our target corpus in Section 2. We describe our proposed method in Section 3. The result of experiments using the NAIST Text Corpus and our met</context>
</contexts>
<marker>Nakaiwa, 1997</marker>
<rawString>Hiromi Nakaiwa. 1997. Automatic identification of zero pronouns and their antecedents within aligned sentence pairs. In Proc. of the 3rd Annual Meeting of the Association for Natural Language Processing (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
<author>Sanda Harabagiu</author>
</authors>
<title>Question answering based on semantic structures.</title>
<date>2004</date>
<booktitle>In Proc. of the 20th International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="1304" citStr="Narayanan and Harabagiu, 2004" startWordPosition="178" endWordPosition="181">d predicate voices. We constructed decision lists in which these features were sorted by their learned weights. Using our method, we integrated the tasks of semantic role labeling and zero-pronoun identification, and achieved a 17% improvement compared with a baseline method in a sentence level performance analysis. 1 Introduction Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) have been created and utilized. Recently, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002) and NAIST Text Corpus (Iida et al., 2007) were constructed in Japanese, and these corpora have become the target of an automatic Japanese predicate argument structure analysis system. We conducted Japanese predicate argument structure (PAS</context>
</contexts>
<marker>Narayanan, Harabagiu, 2004</marker>
<rawString>Srini Narayanan and Sanda Harabagiu. 2004. Question answering based on semantic structures. In Proc. of the 20th International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>P Kingsbury</author>
<author>D Gildea</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="1506" citStr="Palmer et al., 2005" startWordPosition="208" endWordPosition="211"> and achieved a 17% improvement compared with a baseline method in a sentence level performance analysis. 1 Introduction Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) have been created and utilized. Recently, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002) and NAIST Text Corpus (Iida et al., 2007) were constructed in Japanese, and these corpora have become the target of an automatic Japanese predicate argument structure analysis system. We conducted Japanese predicate argument structure (PAS) analysis for the NAIST Text Corpus, which is the largest of these three corpora, and, as far as we know, this is the first time PAS analysis has been conducted for whole articles of the corpus. The NA</context>
</contexts>
<marker>Palmer, Kingsbury, Gildea, 2005</marker>
<rawString>M. Palmer, P. Kingsbury, and D. Gildea. 2005. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Waybe Ward</author>
<author>Kadri Hacioglu</author>
<author>James Martin</author>
<author>Dan Jurafsky</author>
</authors>
<title>Shallow semantic parsing using support vector machines.</title>
<date>2004</date>
<booktitle>In Proc. of the Human Language Technology Conference/North American Chapter of the Association of Computational Linguistics HLT/NAACL</booktitle>
<contexts>
<context position="2692" citStr="Pradhan et al., 2004" startWordPosition="401" endWordPosition="404">hole articles of the corpus. The NAIST Text Corpus has the following characteristics, i) semantic roles for both predicates and event nouns are annotated in the corpus, ii) three major case roles,1 namely the ga, wo and ni-cases in Japanese are annotated for the base form of predicates and event nouns, iii) both the case roles in sentences containing the target predicates and those outside the sentences (zero-pronouns) are annotated, and iv) coreference relations are also annotated. As regards i), recently there has been an increase in the number of papers dealing with nominalized predicates (Pradhan et al., 2004) (Jiang and Ng, 2006) (Xue, 2006) (Liu and Ng, 2007). For example, ‘trip’ in the sentence “During my trip to Italy, I met him.” refers not only to the event “I met him” but also to the event “I traveled to Italy.” As in this example, nouns sometimes have argument structures referring to an event. Such nouns are called event nouns (Komachi et al., 2007) in the NAIST Text Corpus. At the same time, the problems related to compound nouns are also important. In Japanese, a compound noun sometimes simultaneously contains both an event noun and its arguments. For example, the compound noun, ‘企業買収 (co</context>
</contexts>
<marker>Pradhan, Ward, Hacioglu, Martin, Jurafsky, 2004</marker>
<rawString>Sameer Pradhan, Waybe Ward, Kadri Hacioglu, James Martin, and Dan Jurafsky. 2004. Shallow semantic parsing using support vector machines. In Proc. of the Human Language Technology Conference/North American Chapter of the Association of Computational Linguistics HLT/NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Shen</author>
<author>Mirella Lapata</author>
</authors>
<title>Using semantic roles to improve question answering.</title>
<date>2007</date>
<booktitle>In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL),</booktitle>
<pages>12--21</pages>
<contexts>
<context position="1328" citStr="Shen and Lapata, 2007" startWordPosition="182" endWordPosition="185">ed decision lists in which these features were sorted by their learned weights. Using our method, we integrated the tasks of semantic role labeling and zero-pronoun identification, and achieved a 17% improvement compared with a baseline method in a sentence level performance analysis. 1 Introduction Recently, predicate argument structure analysis has attracted the attention of researchers because this information can increase the precision of text processing tasks, such as machine translation, information extraction (Hirschman et al., 1999), question answering (Narayanan and Harabagiu, 2004) (Shen and Lapata, 2007), and summarization (Melli et al., 2005). In English predicate argument structure analysis, large corpora such as FrameNet (Fillmore et al., 2001), PropBank (Palmer et al., 2005) and NomBank (Meyers et al., 2004) have been created and utilized. Recently, the GDA Corpus (Hashida, 2005), Kyoto Text Corpus Ver.4.0 (Kawahara et al., 2002) and NAIST Text Corpus (Iida et al., 2007) were constructed in Japanese, and these corpora have become the target of an automatic Japanese predicate argument structure analysis system. We conducted Japanese predicate argument structure (PAS) analysis for the NAIST</context>
</contexts>
<marker>Shen, Lapata, 2007</marker>
<rawString>Dan Shen and Mirella Lapata. 2007. Using semantic roles to improve question answering. In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL), pages 12–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer-Verlag,</publisher>
<location>New York.</location>
<contexts>
<context position="11888" citStr="Vapnik, 1995" startWordPosition="1929" endWordPosition="1930">three levels of the Nihongo Goi Taikei common noun thesaurus in Figure 6. We annotated the words with their semantic category by hand. 3.3 Functional Word and Voice We used a functional word in the phrase containing the target case role and active and passive voices for the predicate as base features. 3.4 Training Algorithm The training algorithm used for our method is shown in Figure 7. First, the algorithm constructs features that search for the words located closest to the target predicate under various constraints. Next, the algorithm learns by using linear Support Vector Machines (SVMs) (Vapnik, 1995). SVMs learn effective features by the one vs. rest method for every case role. We used TinySVM 2 as an SVM implementation. Moreover, we construct decision lists sorted by weight from linear SVMs. Finally, the algorithm calculates the existing probabilities of case roles for every predicate or event noun. This step 2http://chasen.org/˜taku/software/TinySVM/ produces the criterion that decides whether or not we will determine the case roles when there is no interdependency between the case role candidate and the predicate. Our split of the NAIST Text Corpus has only 62,264 training samples for </context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>V. Vapnik. 1995. The Nature of Statistical Learning Theory. Springer-Verlag, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
<author>M Iida</author>
<author>S Cote</author>
</authors>
<title>Japanese discourse and the process of centering.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="4759" citStr="Walker et al., 1994" startWordPosition="732" endWordPosition="735">e sentence, ‘メアリーはトムに夕食を作らせる (Mary makes Tom fix dinner),’ the basic form of the causative verb, ‘作らせる (make fix)’ is ‘作る (fix),’ and its nominative is ‘トム (Tom)’ and the accusative case role (wo-case) is ‘夕食 (dinner),’ although the surface case particle is ni (dative). We must deal with syntactic transformations in passive, causative, and benefactive constructions when analyzing the corpus. As regards iii) and iv), in Japanese, zero pronouns often occur, especially when the argument has already been mentioned in previous sentences. There have been many studies of zero-pronoun identification (Walker et al., 1994) (Nakaiwa, 1997) (Iida et al., 2006). In this paper, we present a general procedure for handling both the case role assignment of predicates and event nouns, and zero-pronoun identification. We use the decision list learning of rules to find the closest words with various constraints, because with decision lists the readability of learned lists is high and the learning is fast. The rest of this paper is organized as follows. We describe the NAIST Text Corpus, which is our target corpus in Section 2. We describe our proposed method in Section 3. The result of experiments using the NAIST Text Co</context>
</contexts>
<marker>Walker, Iida, Cote, 1994</marker>
<rawString>M. Walker, M. Iida, and S. Cote. 1994. Japanese discourse and the process of centering. Computational Linguistics, 20(2):193–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Semantic role labeling of nominalized predicates in Chinese.</title>
<date>2006</date>
<booktitle>In Proc. of the HLTNAACL,</booktitle>
<pages>431--438</pages>
<contexts>
<context position="2725" citStr="Xue, 2006" startWordPosition="409" endWordPosition="410">Corpus has the following characteristics, i) semantic roles for both predicates and event nouns are annotated in the corpus, ii) three major case roles,1 namely the ga, wo and ni-cases in Japanese are annotated for the base form of predicates and event nouns, iii) both the case roles in sentences containing the target predicates and those outside the sentences (zero-pronouns) are annotated, and iv) coreference relations are also annotated. As regards i), recently there has been an increase in the number of papers dealing with nominalized predicates (Pradhan et al., 2004) (Jiang and Ng, 2006) (Xue, 2006) (Liu and Ng, 2007). For example, ‘trip’ in the sentence “During my trip to Italy, I met him.” refers not only to the event “I met him” but also to the event “I traveled to Italy.” As in this example, nouns sometimes have argument structures referring to an event. Such nouns are called event nouns (Komachi et al., 2007) in the NAIST Text Corpus. At the same time, the problems related to compound nouns are also important. In Japanese, a compound noun sometimes simultaneously contains both an event noun and its arguments. For example, the compound noun, ‘企業買収 (corporate buyout)’ contains an even</context>
</contexts>
<marker>Xue, 2006</marker>
<rawString>Nianwen Xue. 2006. Semantic role labeling of nominalized predicates in Chinese. In Proc. of the HLTNAACL, pages 431–438.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Decision lists for lexical ambiguity resolution: Application to accent restoration in Spanish and French.</title>
<date>1994</date>
<booktitle>In Proc. of the 32nd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>88--95</pages>
<contexts>
<context position="18676" citStr="Yarowsky, 1994" startWordPosition="3157" endWordPosition="3158">ed on predicates or event nouns as case role candidates. If the functional word (post-positional case) in the phrase is ‘ga’,‘wo’ and ‘ni’, we determined the ga-case, wo-case, or nicase for the candidates. Next, as regards event nouns in compound nouns, if there was another word in a compound noun containing an event noun and it cooccurred with the event noun as a case role with a higher probability in the training samples, then the word was selected for the case role. 4.3 Entropy Method The conventional approach for making decision lists utilizes the entropy of samples selected by the rules (Yarowsky, 1994) (Goodman, 2002). We performed comparative experiments using Yarowsky’s entropy algorithm (Yarowsky, 1994). Table 3: Existing probabilities of case roles for predicates and event nouns Predicate ga (NOM) Existing ni (DAT) or Event Noun Probability wo (ACC) 使う (use) 44.72% 82.92% 5.33% 交渉 (negotiation) 77.41% 30.70% 0.00% 参加 (participation) 87.09% 0.00% 72.46% 基づく (based on) 81.89% 0.00% 100.00% 4.4 Overall Results The overall results are shown in Table 7. Here, ‘entropy’ indicates Yarowsky’s algorithm, which uses entropy (Yarowsky, 1994). Throughout the test data, the F-measure (%) of our meth</context>
</contexts>
<marker>Yarowsky, 1994</marker>
<rawString>David Yarowsky. 1994. Decision lists for lexical ambiguity resolution: Application to accent restoration in Spanish and French. In Proc. of the 32nd Annual Meeting of the Association for Computational Linguistics (ACL), pages 88–95.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>