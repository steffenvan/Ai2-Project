<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004333">
<title confidence="0.998471">
A Statistical Model for Unsupervised and Semi-supervised Transliteration
Mining
</title>
<author confidence="0.995957">
Hassan Sajjad Alexander Fraser Helmut Schmid
</author>
<affiliation confidence="0.996488">
Institute for Natural Language Processing
University of Stuttgart
</affiliation>
<email confidence="0.99803">
{sajjad,fraser,schmid}@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.998593" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998597">
We propose a novel model to automatically
extract transliteration pairs from parallel cor-
pora. Our model is efficient, language pair
independent and mines transliteration pairs in
a consistent fashion in both unsupervised and
semi-supervised settings. We model transliter-
ation mining as an interpolation of translitera-
tion and non-transliteration sub-models. We
evaluate on NEWS 2010 shared task data and
on parallel corpora with competitive results.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999914314814815">
Transliteration mining is the extraction of translit-
eration pairs from unlabelled data. Most transliter-
ation mining systems are built using labelled train-
ing data or using heuristics to extract transliteration
pairs. These systems are language pair dependent or
require labelled information for training. Our sys-
tem extracts transliteration pairs in an unsupervised
fashion. It is also able to utilize labelled information
if available, obtaining improved performance.
We present a novel model of transliteration min-
ing defined as a mixture of a transliteration model
and a non-transliteration model. The transliteration
model is a joint source channel model (Li et al.,
2004). The non-transliteration model assumes no
correlation between source and target word charac-
ters, and independently generates a source and a tar-
get word using two fixed unigram character models.
We use Expectation Maximization (EM) to learn pa-
rameters maximizing the likelihood of the interpola-
tion of both sub-models. At test time, we label word
pairs as transliterations if they have a higher proba-
bility assigned by the transliteration sub-model than
by the non-transliteration sub-model.
We extend the unsupervised system to a semi-
supervised system by adding a new S-step to the
EM algorithm. The S-step takes the probability es-
timates from unlabelled data (computed in the M-
step) and uses them as a backoff distribution to
smooth probabilities which were estimated from la-
belled data. The smoothed probabilities are then
used in the next E-step. In this way, the parame-
ters learned by EM are constrained to values which
are close to those estimated from the labelled data.
We evaluate our unsupervised and semi-
supervised transliteration mining system on the
datasets available from the NEWS 2010 shared task
on transliteration mining (Kumaran et al., 2010b).
We call this task NEWS10 later on. Compared with
a baseline unsupervised system our unsupervised
system achieves up to 5% better F-measure. On
the NEWS10 dataset, our unsupervised system
achieves an F-measure of up to 95.7%, and on three
language pairs, it performs better than all systems
which participated in NEWS10. We also evaluate
our semi-supervised system which additionally uses
the NEWS10 labelled data for training. It achieves
an improvement of up to 3.7% F-measure over our
unsupervised system. Additional experiments on
parallel corpora show that we are able to effectively
mine transliteration pairs from very noisy data.
The paper is organized as follows. Section 2 de-
scribes previous work. Sections 3 and 4 define our
unsupervised and semi-supervised models. Section
5 presents the evaluation. Section 6 concludes.
</bodyText>
<page confidence="0.994333">
469
</page>
<note confidence="0.986113">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 469–477,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.988897" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999919841269841">
We first discuss the literature on semi-supervised
and supervised techniques for transliteration min-
ing and then describe a previously defined unsuper-
vised system. Supervised and semi-supervised sys-
tems use a manually labelled set of training data to
learn character mappings between source and tar-
get strings. The labelled training data either con-
sists of a few hundred transliteration pairs or of
just a few carefully selected transliteration pairs.
The NEWS 2010 shared task on transliteration min-
ing (NEWS10) (Kumaran et al., 2010b) is a semi-
supervised task conducted on Wikipedia InterLan-
guage Links (WIL) data. The NEWS10 dataset con-
tains 1000 labelled examples (called the “seed data”)
for initial training. All systems which participated
in the NEWS10 shared task are either supervised or
semi-supervised. They are described in (Kumaran
et al., 2010a). Our transliteration mining model
can mine transliterations without using any labelled
data. However, if there is some labelled data avail-
able, our system is able to use it effectively.
The transliteration mining systems evaluated on
the NEWS10 dataset generally used heuristic meth-
ods, discriminative models or generative models for
transliteration mining (Kumaran et al., 2010a).
The heuristic-based system of Jiampojamarn et
al. (2010) is based on the edit distance method
which scores the similarity between source and tar-
get words. They presented two discriminative meth-
ods – an SVM-based classifier and alignment-based
string similarity for transliteration mining. These
methods model the conditional probability distribu-
tion and require supervised/semi-supervised infor-
mation for learning. We propose a flexible genera-
tive model for transliteration mining usable for both
unsupervised and semi-supervised learning.
Previous work on generative approaches uses
Hidden Markov Models (Nabende, 2010; Darwish,
2010; Jiampojamarn et al., 2010), Finite State Au-
tomata (Noeman and Madkour, 2010) and Bayesian
learning (Kahki et al., 2011) to learn transliteration
pairs from labelled data. Our method is different
from theirs as our generative story explains the un-
labelled data using a combination of a transliteration
and a non-transliteration sub-model. The translit-
eration model jointly generates source and target
strings, whereas the non-transliteration system gen-
erates them independently of each other.
Sajjad et al. (2011) proposed a heuristic-based un-
supervised transliteration mining system. We later
call it Sajjad11. It is the only unsupervised mining
system that was evaluated on the NEWS10 dataset
up until now, as far as we know. That system is com-
putationally expensive. We show in Section 5 that its
runtime is much higher than that of our system.
In this paper, we propose a novel model-based
approach to transliteration mining. Our approach
is language pair independent – at least for alpha-
betic languages – and efficient. Unlike the pre-
vious unsupervised system, and unlike the super-
vised and semi-supervised systems we mentioned,
our model can be used for both unsupervised and
semi-supervised mining in a consistent way.
</bodyText>
<sectionHeader confidence="0.9777125" genericHeader="method">
3 Unsupervised Transliteration Mining
Model
</sectionHeader>
<bodyText confidence="0.999976625">
A source word and its corresponding target word can
be character-aligned in many ways. We refer to a
possible alignment sequence which aligns a source
word a and a target word f as “a”. The function
Align(e, f) returns the set of all valid alignment se-
quences a of a word pair (e, f). The joint transliter-
ation probability p1(e, f) of a word pair is the sum
of the probabilities of all alignment sequences:
</bodyText>
<equation confidence="0.997837">
p1(e, f) = � p(a) (1)
aEAlign(e,f)
</equation>
<bodyText confidence="0.999142307692308">
Transliteration systems are trained on a list of
transliteration pairs. The alignment between the
transliteration pairs is learned with Expectation
Maximization (EM). We use a simple unigram
model, so an alignment sequence from function
Align(e, f) is a combination of 0–1, 1–1, and 1–
0 character alignments between a source word a and
its transliteration f. We refer to a character align-
ment unit as “multigram” later on and represent it
by the symbol “q”. A sequence of multigrams forms
an alignment of a source and target word. The prob-
ability of a sequence of multigrams a is the product
of the probabilities of the multigrams it contains.
</bodyText>
<equation confidence="0.953687333333333">
|a|
p(a) = p(q1, q2,..., q|a|) = H p(qj) (2)
j=1
</equation>
<page confidence="0.96316">
470
</page>
<bodyText confidence="0.999620909090909">
While transliteration systems are trained on a
clean list of transliteration pairs, our translitera-
tion mining system has to learn from data con-
taining both transliterations and non-transliterations.
The transliteration model p1(e, f) handles only the
transliteration pairs. We propose a second model
p2(e, f) to deal with non-transliteration pairs (the
“non-transliteration model”). Interpolation with the
non-transliteration model allows the transliteration
model to concentrate on modelling transliterations
during EM training. After EM training, transliter-
ation word pairs are assigned a high probability by
the transliteration submodel and a low probability by
the non-transliteration submodel, and vice versa for
non-transliteration pairs. This property is exploited
to identify transliterations.
In a non-transliteration word pair, the characters
of the source and target words are unrelated. We
model them as randomly seeing a source word and a
target word together. The non-transliteration model
uses random generation of characters from two uni-
gram models. It is defined as follows:
</bodyText>
<equation confidence="0.996353">
p2(e,f) = pE(e) pF(f7)7 (3)
pE (e) = e1 pE(ei) and pF (f = 771 pF(fi).
</equation>
<bodyText confidence="0.9525626">
The transliteration mining model is an interpo-
lation of the transliteration model p1(e, f) and the
non-transliteration model p2(e, f):
p(e, f) = (1 − λ)p1(e, f) + λp2(e, f) (4)
λ is the prior probability of non-transliteration.
</bodyText>
<subsectionHeader confidence="0.998933">
3.1 Model Estimation
</subsectionHeader>
<bodyText confidence="0.999802931034483">
In this section, we discuss the estimation of the pa-
rameters of the transliteration model p1(e, f) and the
non-transliteration model p2(e, f).
The non-transliteration model consists of two un-
igram character models. Their parameters are esti-
mated from the source and target words of the train-
ing data, respectively, and the parameters do not
change during EM training.
For the transliteration model, we implement a
simplified form of the grapheme-to-phoneme con-
verter, g2p (Bisani and Ney, 2008). In the follow-
ing, we use notations from Bisani and Ney (2008).
g2p learns m-to-n character alignments between a
source and a target word. We restrict ourselves to
0–1,1–1,1–0 character alignments and to a unigram
model.1 The Expectation Maximization (EM) algo-
rithm is used to train the model. It maximizes the
likelihood of the training data. In the E-step the EM
algorithm computes expected counts for the multi-
grams and in the M-step the multigram probabilities
are reestimated from these counts. These two steps
are iterated. For the first EM iteration, the multigram
probabilities are initialized with a uniform distribu-
tion and λ is set to 0.5.
The expected count of a multigram q (E-step) is
computed by multiplying the posterior probability
of each alignment a with the frequency of q in a and
summing these weighted frequencies over all align-
ments of all word pairs.
</bodyText>
<equation confidence="0.992289">
p(q) = Pq/c(q) (5) c(q�)
</equation>
<bodyText confidence="0.998922">
Likewise, we calculate the expected count of non-
transliterations by summing the posterior probabili-
ties of non-transliteration given each word pair:
</bodyText>
<equation confidence="0.970997">
λp2(ei,fi) (6)
p(ei, fi)
</equation>
<bodyText confidence="0.9999285">
λ is then reestimated by dividing the expected count
of non-transliterations by N.
</bodyText>
<subsectionHeader confidence="0.99943">
3.2 Implementation Details
</subsectionHeader>
<bodyText confidence="0.986041222222222">
We use the Forward-Backward algorithm to estimate
the counts of multigrams. The algorithm has a for-
ward variable α and a backward variable β which are
calculated in the standard way (Deligne and Bimbot,
1995). Consider a node r which is connected with
a node s via an arc labelled with the multigram q.
The expected count of a transition between r and s
is calculated using the forward and backward prob-
abilities as follows:
</bodyText>
<equation confidence="0.993695">
α(r) p(q) β(s)
7rs = (7)
α(E)
</equation>
<bodyText confidence="0.849098">
1In preliminary experiments, using an n-gram order of
greater than one or more than one character on the source side or
the target side or both sides of the multigram caused the translit-
eration model to incorrectly learn non-transliteration informa-
tion from the training data.
</bodyText>
<equation confidence="0.9980065">
c(q) = XN X (1 − λ)p1(a, ei, fi) n (a)
i=1 aEAlign(ei,fi) p( ei, fi) q
</equation>
<bodyText confidence="0.9002365">
nq(a) is here the number of times the multigram q
occurs in the sequence a and p(ei, fi) is defined in
Equation 4. The new estimate of the probability of a
multigram is given by:
</bodyText>
<equation confidence="0.997879">
cntr = XN pntr(ei,fi) = XN
i=1 i=1
</equation>
<page confidence="0.976004">
471
</page>
<bodyText confidence="0.999942444444444">
where E is the final node of the graph.
We multiply the expected count of a transition
by the posterior probability of transliteration (1 −
pntr(e, f)) which indicates how likely the string pair
is to be a transliteration. The counts -yrs are then
summed for all multigram types q over all training
pairs to obtain the frequencies c(q) which are used
to reestimate the multigram probabilities according
to Equation 5.
</bodyText>
<sectionHeader confidence="0.9375815" genericHeader="method">
4 Semi-supervised Transliteration Mining
Model
</sectionHeader>
<bodyText confidence="0.999993333333333">
Our unsupervised transliteration mining system can
be applied to language pairs for which no labelled
data is available. However, the unsupervised sys-
tem is focused on high recall and also mines close
transliterations (see Section 5 for details). In a task
dependent scenario, it is difficult for the unsuper-
vised system to mine transliteration pairs according
to the details of a particular definition of what is con-
sidered a transliteration (which may vary somewhat
with the task). In this section, we propose an exten-
sion of our unsupervised model which overcomes
this shortcoming by using labelled data. The idea
is to rely on probabilities from labelled data where
they can be estimated reliably and to use probabili-
ties from unlabelled data where the labelled data is
sparse. This is achieved by smoothing the labelled
data probabilities using the unlabelled data probabil-
ities as a backoff.
</bodyText>
<subsectionHeader confidence="0.998907">
4.1 Model Estimation
</subsectionHeader>
<bodyText confidence="0.999955333333333">
We calculate the unlabelled data probabilities in the
E-step using Equation 4. For labelled data (contain-
ing only transliterations) we set A = 0 and get:
</bodyText>
<equation confidence="0.997237">
p(e, f) = � p1(e, f, a) (8)
aEAlign(e,f)
</equation>
<bodyText confidence="0.99981225">
In every EM iteration, we smooth the probability
distribution in such a way that the estimates of the
multigrams of the unlabelled data that do not occur
in the labelled data would be penalized. We obtain
this effect by smoothing the probability distribution
of unlabelled and labelled data using a technique
similar to Witten-Bell smoothing (Witten and Bell,
1991), as we describe below.
</bodyText>
<figureCaption confidence="0.999038">
Figure 1: Semi-supervised training
</figureCaption>
<subsectionHeader confidence="0.952298">
4.2 Implementation Details
</subsectionHeader>
<bodyText confidence="0.99978192">
We divide the training process of semi-supervised
mining in two steps as shown in Figure 1. The first
step creates a reasonable alignment of the labelled
data from which multigram counts can be obtained.
The labelled data is a small list of transliteration
pairs. Therefore we use the unlabelled data to help
correctly align it and train our unsupervised min-
ing system on the combined labelled and unlabelled
training data. In the expectation step, the prior prob-
ability of non-transliteration A is set to zero on the
labelled data since it contains only transliterations.
The first step passes the resulting multigram proba-
bility distribution to the second step.
We start the second step with the probability es-
timates from the first step and run the E-step sepa-
rately on labelled and unlabelled data. The E-step
on the labelled data is done using Equation 8, which
forces the posterior probability of non-transliteration
to zero, while the E-step on the unlabelled data uses
Equation 4. After the two E-steps, we estimate
a probability distribution from the counts obtained
from the unlabelled data (M-step) and use it as a
backoff distribution in computing smoothed proba-
bilities from the labelled data counts (S-step).
The smoothed probability estimate p(q) is:
</bodyText>
<equation confidence="0.999253">
cs(q) + 77sp(q)
�p(q) = (9)
Ns + 77s
</equation>
<bodyText confidence="0.9999362">
where cs(q) is the labelled data count of the multi-
gram q, p(q) is the unlabelled data probability es-
timate, and Ns = EQ cs(q), and 77s is the number
of different multigram types observed in the Viterbi
alignment of the labelled data.
</bodyText>
<page confidence="0.997061">
472
</page>
<sectionHeader confidence="0.999193" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999963846153846">
We evaluate our unsupervised system and semi-
supervised system on two tasks, NEWS10 and paral-
lel corpora. NEWS10 is a standard task on translit-
eration mining from WIL. On NEWS10, we com-
pare our results with the unsupervised mining sys-
tem of Sajjad et al. (2011), the best supervised
and semi-supervised systems presented at NEWS10
(Kumaran et al., 2010b) and the best supervised and
semi-supervised results reported in the literature for
the NEWS10 task. For the challenging task of min-
ing from parallel corpora, we use the English/Hindi
and English/Arabic gold standard provided by Saj-
jad et al. (2011) to evaluate our results.
</bodyText>
<subsectionHeader confidence="0.85776">
5.1 Experiments using the NEWS10 Dataset
</subsectionHeader>
<bodyText confidence="0.999984428571429">
We conduct experiments on four language pairs: En-
glish/Arabic, English/Hindi, English/Tamil and En-
glish/Russian using data provided at NEWS10. Ev-
ery dataset contains training data, seed data and ref-
erence data. The NEWS10 data consists of pairs of
titles of the same Wikipedia pages written in dif-
ferent languages, which may be transliterations or
translations. The seed data is a list of 1000 transliter-
ation pairs provided to semi-supervised systems for
initial training. We use the seed data only in our
semi-supervised system, and not in the unsupervised
system. The reference data is a small subset of the
training data which is manually annotated with pos-
itive and negative examples.
</bodyText>
<subsubsectionHeader confidence="0.463771">
5.1.1 Training
</subsubsectionHeader>
<bodyText confidence="0.999328133333333">
We word-aligned the parallel phrases of the train-
ing data using GIZA++ (Och and Ney, 2003), and
symmetrized the alignments using the grow-diag-
final-and heuristic (Koehn et al., 2003). We extract
all word pairs which occur as 1-to-1 alignments (like
Sajjad et al. (2011)) and later refer to them as the
word-aligned list. We compared the word-aligned
list with the NEWS10 reference data and found that
the word-aligned list is missing some transliteration
pairs because of word-alignment errors. We built an-
other list by adding a word pair for every source
word that cooccurs with a target word in a paral-
lel phrase/sentence and call it the cross-product list
later on. The cross-product list is noisier but con-
tains almost all transliteration pairs in the corpus.
</bodyText>
<table confidence="0.999434833333333">
Word-aligned Cross-product
P R F P R F
EA 27.8 97.1 43.3 14.3 98.0 25.0
EH 42.5 98.7 59.4 20.5 99.6 34.1
ET 32.0 98.1 48.3 17.2 99.6 29.3
ER 25.5 95.6 40.3 12.8 99.0 22.7
</table>
<tableCaption confidence="0.95483825">
Table 1: Statistics of word-aligned and cross-product
list calculated from the NEWS10 dataset, before min-
ing. EA is English/Arabic, EH is English/Hindi, ET is
English/Tamil and ER is English/Russian
</tableCaption>
<bodyText confidence="0.9765413">
Table 1 shows the statistics of the word-aligned
list and the cross-product list calculated using the
NEWS10 reference data.2 The word-aligned list cal-
culated from the NEWS10 dataset is used to com-
pare our unsupervised system with the unsupervised
system of Sajjad et al. (2011) on the same training
data. All the other experiments on NEWS10 use
cross-product lists. We remove numbers from both
lists as they are defined as non-transliterations (Ku-
maran et al., 2010b).
</bodyText>
<subsubsectionHeader confidence="0.819809">
5.1.2 Unsupervised Transliteration Mining
</subsubsectionHeader>
<bodyText confidence="0.998313523809524">
We run our unsupervised transliteration mining
system on the word-aligned list and the cross-
product list. The word pairs with a posterior prob-
ability of transliteration 1 − p,,,tr(e, f) = 1 −
Ap2(ei, fi)/p(ei, fi) greater than 0.5 are selected as
transliteration pairs.
We compare our unsupervised system with the
unsupervised system of Sajjad11. Our unsupervised
system trained on the word-aligned list shows F-
measures of 91.7%, 95.5%, 92.9% and 77.7% which
is 4.3%, 3.3%, 2.8% and 1.7% better than the sys-
tem of Sajjad11 on English/Arabic, English/Hindi,
English/Tamil and English/Russian respectively.
Sajjad11 is computationally expensive. For in-
stance, a phrase-based statistical MT system is
built once in every iteration of the heuristic proce-
dure. We ran Sajjad11 on the English/Russian word-
aligned list using a 2.4 GHz Dual-Core AMD ma-
chine, which took almost 10 days. On the same ma-
chine, our transliteration mining system only takes
1.5 hours to finish the same experiment.
</bodyText>
<footnote confidence="0.6045234">
2Due to inconsistent word definition used in the reference
data, we did not achieve 100% recall in our cross-product list.
For example, the underscore is defined as a word boundary for
English WIL phrases. This assumption is not followed for cer-
tain phrases like ”New York” and ”New Mexico”.
</footnote>
<page confidence="0.997589">
473
</page>
<table confidence="0.999492285714286">
Unsupervised Semi-supervised/Supervised
SJD OU OS SBest GR DBN
EA 87.4 92.4 92.7 91.5 94.1 -
EH 92.2 95.7 96.3 94.4 93.2 95.5
ET 90.1 93.2 94.6 91.4 95.5 93.9
ER 76.0 79.4 83.1 87.5 92.3 82.5
Unsupervised
P R F
Semi-supervised
P R F
EA 89.2 95.7 92.4 92.9 92.4 92.7
EH 92.6 99.0 95.7 95.5 97.0 96.3
ET 88.3 98.6 93.2 93.4 95.8 94.6
ER 67.2 97.1 79.4 74.0 94.9 83.1
</table>
<tableCaption confidence="0.940161285714286">
Table 2: F-measure results on NEWS10 datasets where
SJD is the unsupervised system of Sajjad11, OU is
our unsupervised system built on the cross-product list,
OS is our semi-supervised system, SBest is the best
NEWS10 system, GR is the supervised system of Kahki
et al. (2011) and DBN is the semi-supervised system of
Nabende (2011)
</tableCaption>
<bodyText confidence="0.990242828571429">
Our unsupervised mining system built on the
cross-product list consistently outperforms the one
built on the word-aligned list. Later, we consider
only the system built on the cross-product list. Ta-
ble 2 shows the results of our unsupervised sys-
tem OU in comparison with the unsupervised sys-
tem of Sajjad11 (SJD), the best semi-supervised sys-
tems presented at NEWS10 (SBEST) and the best
semi-supervised results reported on the NEWS10
dataset (GR, DBN). On three language pairs, our
unsupervised system performs better than all semi-
supervised systems which participated in NEWS10.
It has competitive results with the best supervised
results reported on NEWS10 datasets. On En-
glish/Hindi, our unsupervised system outperforms
the state-of-the-art supervised and semi-supervised
systems. Kahki et al. (2011) (GR) achieved
the best results on English/Arabic, English/Tamil
and English/Russian. For the English/Arabic task,
they normalized the data using language dependent
heuristics3 and also used a non-standard evaluation
method (discussed in Section 5.1.4).
On the English/Russian dataset, our unsupervised
system faces the problem that it extracts cognates
as transliterations. The same problem was reported
in Sajjad et al. (2011). Cognates are close translit-
erations which differ by only one or two characters
from an exact transliteration pair. The unsupervised
system learns to delete the additional one or two
characters with a high probability and incorrectly
mines such word pairs as transliterations.
3They applied an Arabic word segmenter which uses lan-
guage dependent information. Arabic long vowels which have
identical sound but are written differently were merged to one
form. English characters were normalized by dropping accents.
</bodyText>
<tableCaption confidence="0.994691666666667">
Table 3: Precision(P), Recall(R) and F-measure(F) of our
unsupervised and semi-supervised transliteration mining
systems on NEWS10 datasets
</tableCaption>
<subsubsectionHeader confidence="0.821116">
5.1.3 Semi-supervised Transliteration Mining
</subsubsectionHeader>
<bodyText confidence="0.99998">
Our semi-supervised system uses similar initial-
ization of the parameters as used for unsupervised
system. Table 2 shows on three language pairs, our
semi-supervised system OS only achieves a small
gain in F-measure over our unsupervised system
OU. This shows that the unlabelled training data is
already providing most of the transliteration infor-
mation. The seed data is used to help the translit-
eration mining system to learn the right definition
of transliteration. On the English/Russian dataset,
our semi-supervised system achieves almost 7% in-
crease in precision with a 2.2% drop in recall com-
pared to our unsupervised system. This provides a
3.7% gain on F-measure. The increase in precision
shows that the seed data is helping the system in dis-
ambiguating transliteration pairs from cognates.
</bodyText>
<sectionHeader confidence="0.474388" genericHeader="method">
5.1.4 Discussion
</sectionHeader>
<bodyText confidence="0.999953157894737">
The unsupervised system produces lists with high
recall. The semi-supervised system tends to better
balance out precision and recall. Table 3 compares
the precision, recall and F-measure of our unsuper-
vised and semi-supervised mining systems.
The errors made by our semi-supervised system
can be classified into the following categories:
Pronunciation differences: English proper
names may be pronounced differently in other lan-
guages. Sometimes, English short vowels are con-
verted to long vowels in Hindi such as the English
word “Lanthanum” which is pronounced “Laan-
thanum” in Hindi. Our transliteration mining system
wrongly extracts such pairs as transliterations.
In some cases, different vowels are used in two
languages. The English word “January” is pro-
nounced as “Janvary” in Hindi. Such word pairs are
non-transliterations according to the gold standard
but our system extracts them as transliterations. Ta-
</bodyText>
<page confidence="0.999445">
474
</page>
<tableCaption confidence="0.992305">
Table 5: Examples of word pairs which are wrongly an-
notated as transliterations in the gold standard
</tableCaption>
<bodyText confidence="0.999219567567567">
ble 4 shows a few examples of such word pairs.
Inconsistencies in the gold standard: There are
several inconsistencies in the gold standard where
our transliteration system correctly identifies a word
pair as a transliteration but it is marked as a non-
transliteration or vice versa. Consider the example
of the English word “George” which is pronounced
as “Jaarj” in Hindi. Our semi-supervised system
learns this as a non-transliteration but it is wrongly
annotated as a transliteration in the gold standard.
Arabic nouns have an article “al” attached to them
which is translated in English as “the”. There are
various cases in the training data where an English
noun such as “Quran” is matched with an Arabic
noun “alQuran”. Our mining system classifies such
cases as non-transliterations, but 24 of them are in-
correctly annotated as transliterations in the gold
standard. We did not correct this, and are there-
fore penalized. Kahki et al. (2011) preprocessed
such Arabic words and separated “al” from the noun
“Quran” before mining. They report a match if the
version of the Arabic word with “al” appears with
the corresponding English word in the gold stan-
dard. Table 5 shows examples of word pairs which
are wrongly annotated as transliterations.
Cognates: Sometimes a word pair differs by only
one or two ending characters from a true translit-
eration. For example in the English/Russian train-
ing data, the Russian nouns are marked with cases
whereas their English counterparts do not mark the
case or translate it as a separate word. Often the
Russian word differs only by the last character from
a correct transliteration of the English word. Due
to the large amount of such word pairs in the En-
glish/Russian data, our mining system learns to
delete the final case marking characters from the
Russian words. It assigns a high transliteration prob-
</bodyText>
<tableCaption confidence="0.976724">
Table 6: A few examples of English/Russian cognates
</tableCaption>
<bodyText confidence="0.9996725">
ability to these word pairs and extracts them as
transliterations. Table 6 shows some examples.
There are two English/Russian supervised sys-
tems which are better than our semi-supervised sys-
tem. The Kahki et al. (2011) system is built on seed
data only. Jiampojamarn et al. (2010)’s best sys-
tem on English/Russian is based on the edit distance
method. Both of these systems are focused on high
precision. Our semi-supervised system is focused
on high recall at the cost of lower precision.4
</bodyText>
<subsectionHeader confidence="0.9875725">
5.2 Transliteration Mining using Parallel
Corpora
</subsectionHeader>
<bodyText confidence="0.999986066666667">
The percentage of transliteration pairs in the
NEWS10 datasets is high. We further check the ef-
fectiveness of our unsupervised and semi-supervised
mining systems by evaluating them on parallel cor-
pora with as few as 2% transliteration pairs.
We conduct experiments using two language
pairs, English/Hindi and English/Arabic. The En-
glish/Hindi corpus is from the shared task on word
alignment organized as part of the ACL 2005 Work-
shop on Building and Using Parallel Texts (WA05)
(Martin et al., 2005). For English/Arabic, we use
200,000 parallel sentences from the United Nations
(UN) corpus (Eisele and Chen, 2010). The En-
glish/Hindi and English/Arabic transliteration gold
standards were provided by Sajjad et al. (2011).
</bodyText>
<sectionHeader confidence="0.694751" genericHeader="evaluation">
5.2.1 Experiments
</sectionHeader>
<bodyText confidence="0.9999775">
We follow the procedure for creating the training
data described in Section 5.1.1 and build a word-
aligned list and a cross-product list from the parallel
corpus. We first train and test our unsupervised min-
ing system on the word-aligned list and compare our
results with Sajjad et al. Table 7 shows the results.
Our unsupervised system achieves 0.6% and 1.8%
higher F-measure than Sajjad et al. respectively.
The cross-product list is huge in comparison to
the word-aligned list. It is noisier than the word-
</bodyText>
<footnote confidence="0.86536775">
4We implemented a bigram version of our system to learn
the contextual information at the end of the word pairs, but only
achieved a gain of less than 1% F-measure over our unigram
semi-supervised system. Details are omitted due to space.
</footnote>
<tableCaption confidence="0.960653">
Table 4: Word pairs with pronunciation differences
</tableCaption>
<page confidence="0.955962">
475
</page>
<table confidence="0.99533875">
EHSaD 170 10 2039 45 79.1 94.4 86.1
EHO 176 4 2034 50 77.9 97.8 86.7
EASaD 197 91 6580 59 77.0 68.4 72.5
EAO 288 0 6440 199 59.1 100 74.3
</table>
<tableCaption confidence="0.98998125">
Table 7: Transliteration mining results of our unsuper-
vised system and Sajjad11 system trained and tested
on the word-aligned list of English/Hindi and En-
glish/Arabic parallel corpus
</tableCaption>
<table confidence="0.9999565">
EHU 393 19 12279 129 75.3 95.4 84.2
EHS 365 47 12340 68 84.3 88.6 86.4
EAU 277 11 6444 195 58.7 96.2 72.9
EAS 272 16 6497 142 65.7 94.4 77.5
</table>
<tableCaption confidence="0.99707675">
Table 8: Transliteration mining results of our unsuper-
vised and semi-supervised systems trained on the word-
aligned list and tested on the cross-product list of En-
glish/Hindi and English/Arabic parallel corpus
</tableCaption>
<bodyText confidence="0.999856">
aligned list but has almost 100% recall of transliter-
ation pairs. The English-Hindi cross-product list has
almost 55% more transliteration pairs (412 types)
than the word-aligned list (180 types). We can not
report these numbers on the English/Arabic cross-
product list since the English/Arabic gold standard
is built on the word-aligned list.
In order to keep the experiment computationally
inexpensive, we train our mining systems on the
word-aligned list and test them on the cross-product
list.5 We also perform the first semi-supervised eval-
uation on this task. For our semi-supervised sys-
tem, we additionally use the English/Hindi and En-
glish/Arabic seed data provided by NEWS10.
Table 8 shows the results of our unsupervised
and semi-supervised systems on the English/Hindi
and English/Arabic parallel corpora. Our unsu-
pervised system achieves higher recall than our
semi-supervised system but lower precision. The
semi-supervised system shows an improvement in
F-measure for both language pairs. We looked
into the errors made by our systems. The mined
transliteration pairs of our unsupervised system con-
tains 65 and 111 close transliterations for the En-
glish/Hindi and English/Arabic task respectively.
</bodyText>
<footnote confidence="0.9367992">
5There are some multigrams of the cross-product list which
are unknown to the model learned on the word-aligned list. We
define their probability as the inverse of the number of multi-
gram tokens in the Viterbi alignment of the labelled and unla-
belled data together.
</footnote>
<bodyText confidence="0.998712428571429">
The close transliterations only differ by one or two
characters from correct transliterations. We think
these pairs provide transliteration information to
the systems and help them to avoid problems with
data sparseness. Our semi-supervised system uses
the seed data to identify close transliterations as
non-transliterations and decreases the number of
false positives. They are reduced to 35 and 89
for English/Hindi and English/Arabic respectively.
The seed data and the training data used in the
semi-supervised system are from different domains
(Wikipedia and UN). Seed data extracted from the
same domain is likely to work better, resulting in
even higher scores than we have reported.
</bodyText>
<sectionHeader confidence="0.998839" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999992888888889">
We presented a novel model to automatically
mine transliteration pairs. Our approach is ef-
ficient and language pair independent (for alpha-
betic languages). Both the unsupervised and semi-
supervised systems achieve higher accuracy than the
only unsupervised transliteration mining system we
are aware of and are competitive with the state-
of-the-art supervised and semi-supervised systems.
Our semi-supervised system outperformed our un-
supervised system, in particular in the presence of
prevalent cognates in the Russian/English data.
In future work, we plan to adapt our approach
to language pairs where one language is alphabetic
and the other language is non-alphabetic such as En-
glish/Japanese. These language pairs require one-
to-many character mappings to learn transliteration
units, while our current system only learns unigram
character alignments.
</bodyText>
<sectionHeader confidence="0.998965" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999992461538461">
The authors wish to thank the anonymous review-
ers. We would like to thank Syed Aoun Raza for
discussions of implementation efficiency. Hassan
Sajjad was funded by the Higher Education Com-
mission of Pakistan. Alexander Fraser was funded
by Deutsche Forschungsgemeinschaft grant Models
of Morphosyntax for Statistical Machine Transla-
tion. Helmut Schmid was supported by Deutsche
Forschungsgemeinschaft grant SFB 732. This work
was supported in part by the IST Programme of
the European Community, under the PASCAL2 Net-
work of Excellence, IST-2007-216886. This publi-
cation only reflects the authors’ views.
</bodyText>
<equation confidence="0.891561">
TP FN TN FP P R F
TP FN TN FP P R F
</equation>
<page confidence="0.998828">
476
</page>
<sectionHeader confidence="0.998335" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999630038961039">
Maximilian Bisani and Hermann Ney. 2008. Joint-
sequence models for grapheme-to-phoneme conver-
sion. Speech Communication, 50(5).
Kareem Darwish. 2010. Transliteration mining with
phonetic conflation and iterative training. In Proceed-
ings of the 2010 Named Entities Workshop, Uppsala,
Sweden.
Sabine Deligne and Fr´ed´eric Bimbot. 1995. Language
modeling by variable length sequences : Theoreti-
cal formulation and evaluation of multigrams. In
Proceedings of the IEEE International Conference on
Acoustics, Speech, and Signal Processing, volume 1,
Los Alamitos, CA, USA.
Andreas Eisele and Yu Chen. 2010. MultiUN: A multi-
lingual corpus from United Nation documents. In Pro-
ceedings of the Seventh conference on International
Language Resources and Evaluation (LREC’10), Val-
letta, Malta.
Sittichai Jiampojamarn, Kenneth Dwyer, Shane Bergsma,
Aditya Bhargava, Qing Dou, Mi-Young Kim, and
Grzegorz Kondrak. 2010. Transliteration generation
and mining with limited training resources. In Pro-
ceedings of the 2010 Named Entities Workshop, Upp-
sala, Sweden.
Ali El Kahki, Kareem Darwish, Ahmed Saad El Din,
Mohamed Abd El-Wahab, Ahmed Hefny, and Waleed
Ammar. 2011. Improved transliteration mining using
graph reinforcement. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing (EMNLP), Edinburgh, UK.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
the Human Language Technology and North Ameri-
can Association for Computational Linguistics Con-
ference, Edmonton, Canada.
A Kumaran, Mitesh M. Khapra, and Haizhou Li. 2010a.
Report of NEWS 2010 transliteration mining shared
task. In Proceedings of the 2010 Named Entities Work-
shop, Uppsala, Sweden.
A Kumaran, Mitesh M. Khapra, and Haizhou Li. 2010b.
Whitepaper of NEWS 2010 shared task on translitera-
tion mining. In Proceedings of the 2010 Named Enti-
ties Workshop, Uppsala, Sweden.
Haizhou Li, Zhang Min, and Su Jian. 2004. A joint
source-channel model for machine transliteration. In
ACL ’04: Proceedings of the 42nd Annual Meeting on
Association for Computational Linguistics, Barcelona,
Spain.
Joel Martin, Rada Mihalcea, and Ted Pedersen. 2005.
Word alignment for languages with scarce resources.
In ParaText ’05: Proceedings of the ACL Workshop
on Building and Using Parallel Texts, Morristown, NJ,
USA.
Peter Nabende. 2010. Mining transliterations from
wikipedia using pair hmms. In Proceedings of the
2010 Named Entities Workshop, Uppsala, Sweden.
Peter Nabende. 2011. Mining transliterations from
Wikipedia using dynamic bayesian networks. In Pro-
ceedings of the International Conference Recent Ad-
vances in Natural Language Processing 2011, Hissar,
Bulgaria.
Sara Noeman and Amgad Madkour. 2010. Language
independent transliteration mining system using finite
state automata framework. In Proceedings of the 2010
Named Entities Workshop, Uppsala, Sweden.
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1).
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2011. An algorithm for unsupervised transliteration
mining with an application to word alignment. In Pro-
ceedings of the 49th Annual Conference of the Associ-
ation for Computational Linguistics, Portland, USA.
Ian H. Witten and Timothy C. Bell. 1991. The zero-
frequency problem: Estimating the probabilities of
novel events in adaptive text compression. In IEEE
Transactions on Information Theory, volume 37.
</reference>
<page confidence="0.99842">
477
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.971531">
<title confidence="0.9979025">A Statistical Model for Unsupervised and Semi-supervised Transliteration Mining</title>
<author confidence="0.978823">Hassan Sajjad Alexander Fraser Helmut Schmid</author>
<affiliation confidence="0.99941">Institute for Natural Language University of Stuttgart</affiliation>
<abstract confidence="0.999644272727273">We propose a novel model to automatically extract transliteration pairs from parallel corpora. Our model is efficient, language pair independent and mines transliteration pairs in a consistent fashion in both unsupervised and semi-supervised settings. We model transliteration mining as an interpolation of transliteration and non-transliteration sub-models. We evaluate on NEWS 2010 shared task data and on parallel corpora with competitive results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Maximilian Bisani</author>
<author>Hermann Ney</author>
</authors>
<title>Jointsequence models for grapheme-to-phoneme conversion.</title>
<date>2008</date>
<journal>Speech Communication,</journal>
<volume>50</volume>
<issue>5</issue>
<contexts>
<context position="9790" citStr="Bisani and Ney, 2008" startWordPosition="1492" endWordPosition="1495">el p2(e, f): p(e, f) = (1 − λ)p1(e, f) + λp2(e, f) (4) λ is the prior probability of non-transliteration. 3.1 Model Estimation In this section, we discuss the estimation of the parameters of the transliteration model p1(e, f) and the non-transliteration model p2(e, f). The non-transliteration model consists of two unigram character models. Their parameters are estimated from the source and target words of the training data, respectively, and the parameters do not change during EM training. For the transliteration model, we implement a simplified form of the grapheme-to-phoneme converter, g2p (Bisani and Ney, 2008). In the following, we use notations from Bisani and Ney (2008). g2p learns m-to-n character alignments between a source and a target word. We restrict ourselves to 0–1,1–1,1–0 character alignments and to a unigram model.1 The Expectation Maximization (EM) algorithm is used to train the model. It maximizes the likelihood of the training data. In the E-step the EM algorithm computes expected counts for the multigrams and in the M-step the multigram probabilities are reestimated from these counts. These two steps are iterated. For the first EM iteration, the multigram probabilities are initializ</context>
</contexts>
<marker>Bisani, Ney, 2008</marker>
<rawString>Maximilian Bisani and Hermann Ney. 2008. Jointsequence models for grapheme-to-phoneme conversion. Speech Communication, 50(5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kareem Darwish</author>
</authors>
<title>Transliteration mining with phonetic conflation and iterative training.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Named Entities Workshop,</booktitle>
<location>Uppsala, Sweden.</location>
<contexts>
<context position="5472" citStr="Darwish, 2010" startWordPosition="806" endWordPosition="807">ystem of Jiampojamarn et al. (2010) is based on the edit distance method which scores the similarity between source and target words. They presented two discriminative methods – an SVM-based classifier and alignment-based string similarity for transliteration mining. These methods model the conditional probability distribution and require supervised/semi-supervised information for learning. We propose a flexible generative model for transliteration mining usable for both unsupervised and semi-supervised learning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al., 2010), Finite State Automata (Noeman and Madkour, 2010) and Bayesian learning (Kahki et al., 2011) to learn transliteration pairs from labelled data. Our method is different from theirs as our generative story explains the unlabelled data using a combination of a transliteration and a non-transliteration sub-model. The transliteration model jointly generates source and target strings, whereas the non-transliteration system generates them independently of each other. Sajjad et al. (2011) proposed a heuristic-based unsupervised transliteration mining system. We later call </context>
</contexts>
<marker>Darwish, 2010</marker>
<rawString>Kareem Darwish. 2010. Transliteration mining with phonetic conflation and iterative training. In Proceedings of the 2010 Named Entities Workshop, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Deligne</author>
<author>Fr´ed´eric Bimbot</author>
</authors>
<title>Language modeling by variable length sequences : Theoretical formulation and evaluation of multigrams.</title>
<date>1995</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing,</booktitle>
<volume>1</volume>
<location>Los Alamitos, CA, USA.</location>
<contexts>
<context position="11184" citStr="Deligne and Bimbot, 1995" startWordPosition="1719" endWordPosition="1722"> with the frequency of q in a and summing these weighted frequencies over all alignments of all word pairs. p(q) = Pq/c(q) (5) c(q�) Likewise, we calculate the expected count of nontransliterations by summing the posterior probabilities of non-transliteration given each word pair: λp2(ei,fi) (6) p(ei, fi) λ is then reestimated by dividing the expected count of non-transliterations by N. 3.2 Implementation Details We use the Forward-Backward algorithm to estimate the counts of multigrams. The algorithm has a forward variable α and a backward variable β which are calculated in the standard way (Deligne and Bimbot, 1995). Consider a node r which is connected with a node s via an arc labelled with the multigram q. The expected count of a transition between r and s is calculated using the forward and backward probabilities as follows: α(r) p(q) β(s) 7rs = (7) α(E) 1In preliminary experiments, using an n-gram order of greater than one or more than one character on the source side or the target side or both sides of the multigram caused the transliteration model to incorrectly learn non-transliteration information from the training data. c(q) = XN X (1 − λ)p1(a, ei, fi) n (a) i=1 aEAlign(ei,fi) p( ei, fi) q nq(a)</context>
</contexts>
<marker>Deligne, Bimbot, 1995</marker>
<rawString>Sabine Deligne and Fr´ed´eric Bimbot. 1995. Language modeling by variable length sequences : Theoretical formulation and evaluation of multigrams. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, volume 1, Los Alamitos, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Eisele</author>
<author>Yu Chen</author>
</authors>
<title>MultiUN: A multilingual corpus from United Nation documents.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<location>Valletta,</location>
<contexts>
<context position="27412" citStr="Eisele and Chen, 2010" startWordPosition="4344" endWordPosition="4347">orpora The percentage of transliteration pairs in the NEWS10 datasets is high. We further check the effectiveness of our unsupervised and semi-supervised mining systems by evaluating them on parallel corpora with as few as 2% transliteration pairs. We conduct experiments using two language pairs, English/Hindi and English/Arabic. The English/Hindi corpus is from the shared task on word alignment organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts (WA05) (Martin et al., 2005). For English/Arabic, we use 200,000 parallel sentences from the United Nations (UN) corpus (Eisele and Chen, 2010). The English/Hindi and English/Arabic transliteration gold standards were provided by Sajjad et al. (2011). 5.2.1 Experiments We follow the procedure for creating the training data described in Section 5.1.1 and build a wordaligned list and a cross-product list from the parallel corpus. We first train and test our unsupervised mining system on the word-aligned list and compare our results with Sajjad et al. Table 7 shows the results. Our unsupervised system achieves 0.6% and 1.8% higher F-measure than Sajjad et al. respectively. The cross-product list is huge in comparison to the word-aligned</context>
</contexts>
<marker>Eisele, Chen, 2010</marker>
<rawString>Andreas Eisele and Yu Chen. 2010. MultiUN: A multilingual corpus from United Nation documents. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10), Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Kenneth Dwyer</author>
<author>Shane Bergsma</author>
<author>Aditya Bhargava</author>
<author>Qing Dou</author>
<author>Mi-Young Kim</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Transliteration generation and mining with limited training resources.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Named Entities Workshop,</booktitle>
<location>Uppsala, Sweden.</location>
<contexts>
<context position="4894" citStr="Jiampojamarn et al. (2010)" startWordPosition="725" endWordPosition="728">led the “seed data”) for initial training. All systems which participated in the NEWS10 shared task are either supervised or semi-supervised. They are described in (Kumaran et al., 2010a). Our transliteration mining model can mine transliterations without using any labelled data. However, if there is some labelled data available, our system is able to use it effectively. The transliteration mining systems evaluated on the NEWS10 dataset generally used heuristic methods, discriminative models or generative models for transliteration mining (Kumaran et al., 2010a). The heuristic-based system of Jiampojamarn et al. (2010) is based on the edit distance method which scores the similarity between source and target words. They presented two discriminative methods – an SVM-based classifier and alignment-based string similarity for transliteration mining. These methods model the conditional probability distribution and require supervised/semi-supervised information for learning. We propose a flexible generative model for transliteration mining usable for both unsupervised and semi-supervised learning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al.,</context>
<context position="26536" citStr="Jiampojamarn et al. (2010)" startWordPosition="4206" endWordPosition="4209">ord differs only by the last character from a correct transliteration of the English word. Due to the large amount of such word pairs in the English/Russian data, our mining system learns to delete the final case marking characters from the Russian words. It assigns a high transliteration probTable 6: A few examples of English/Russian cognates ability to these word pairs and extracts them as transliterations. Table 6 shows some examples. There are two English/Russian supervised systems which are better than our semi-supervised system. The Kahki et al. (2011) system is built on seed data only. Jiampojamarn et al. (2010)’s best system on English/Russian is based on the edit distance method. Both of these systems are focused on high precision. Our semi-supervised system is focused on high recall at the cost of lower precision.4 5.2 Transliteration Mining using Parallel Corpora The percentage of transliteration pairs in the NEWS10 datasets is high. We further check the effectiveness of our unsupervised and semi-supervised mining systems by evaluating them on parallel corpora with as few as 2% transliteration pairs. We conduct experiments using two language pairs, English/Hindi and English/Arabic. The English/Hi</context>
</contexts>
<marker>Jiampojamarn, Dwyer, Bergsma, Bhargava, Dou, Kim, Kondrak, 2010</marker>
<rawString>Sittichai Jiampojamarn, Kenneth Dwyer, Shane Bergsma, Aditya Bhargava, Qing Dou, Mi-Young Kim, and Grzegorz Kondrak. 2010. Transliteration generation and mining with limited training resources. In Proceedings of the 2010 Named Entities Workshop, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ali El Kahki</author>
<author>Kareem Darwish</author>
</authors>
<title>Ahmed Saad El Din, Mohamed Abd El-Wahab, Ahmed Hefny, and Waleed Ammar.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<location>Edinburgh, UK.</location>
<marker>El Kahki, Darwish, 2011</marker>
<rawString>Ali El Kahki, Kareem Darwish, Ahmed Saad El Din, Mohamed Abd El-Wahab, Ahmed Hefny, and Waleed Ammar. 2011. Improved transliteration mining using graph reinforcement. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="17138" citStr="Koehn et al., 2003" startWordPosition="2711" endWordPosition="2714">ikipedia pages written in different languages, which may be transliterations or translations. The seed data is a list of 1000 transliteration pairs provided to semi-supervised systems for initial training. We use the seed data only in our semi-supervised system, and not in the unsupervised system. The reference data is a small subset of the training data which is manually annotated with positive and negative examples. 5.1.1 Training We word-aligned the parallel phrases of the training data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using the grow-diagfinal-and heuristic (Koehn et al., 2003). We extract all word pairs which occur as 1-to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the word-aligned list. We compared the word-aligned list with the NEWS10 reference data and found that the word-aligned list is missing some transliteration pairs because of word-alignment errors. We built another list by adding a word pair for every source word that cooccurs with a target word in a parallel phrase/sentence and call it the cross-product list later on. The cross-product list is noisier but contains almost all transliteration pairs in the corpus. Word-aligned Cross</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kumaran</author>
<author>Mitesh M Khapra</author>
<author>Haizhou Li</author>
</authors>
<title>transliteration mining shared task.</title>
<date>2010</date>
<journal>Report of NEWS</journal>
<booktitle>In Proceedings of the 2010 Named Entities Workshop,</booktitle>
<location>Uppsala, Sweden.</location>
<contexts>
<context position="2546" citStr="Kumaran et al., 2010" startWordPosition="372" endWordPosition="375">vised system by adding a new S-step to the EM algorithm. The S-step takes the probability estimates from unlabelled data (computed in the Mstep) and uses them as a backoff distribution to smooth probabilities which were estimated from labelled data. The smoothed probabilities are then used in the next E-step. In this way, the parameters learned by EM are constrained to values which are close to those estimated from the labelled data. We evaluate our unsupervised and semisupervised transliteration mining system on the datasets available from the NEWS 2010 shared task on transliteration mining (Kumaran et al., 2010b). We call this task NEWS10 later on. Compared with a baseline unsupervised system our unsupervised system achieves up to 5% better F-measure. On the NEWS10 dataset, our unsupervised system achieves an F-measure of up to 95.7%, and on three language pairs, it performs better than all systems which participated in NEWS10. We also evaluate our semi-supervised system which additionally uses the NEWS10 labelled data for training. It achieves an improvement of up to 3.7% F-measure over our unsupervised system. Additional experiments on parallel corpora show that we are able to effectively mine tra</context>
<context position="4130" citStr="Kumaran et al., 2010" startWordPosition="612" endWordPosition="615">rea, 8-14 July 2012. c�2012 Association for Computational Linguistics 2 Previous Work We first discuss the literature on semi-supervised and supervised techniques for transliteration mining and then describe a previously defined unsupervised system. Supervised and semi-supervised systems use a manually labelled set of training data to learn character mappings between source and target strings. The labelled training data either consists of a few hundred transliteration pairs or of just a few carefully selected transliteration pairs. The NEWS 2010 shared task on transliteration mining (NEWS10) (Kumaran et al., 2010b) is a semisupervised task conducted on Wikipedia InterLanguage Links (WIL) data. The NEWS10 dataset contains 1000 labelled examples (called the “seed data”) for initial training. All systems which participated in the NEWS10 shared task are either supervised or semi-supervised. They are described in (Kumaran et al., 2010a). Our transliteration mining model can mine transliterations without using any labelled data. However, if there is some labelled data available, our system is able to use it effectively. The transliteration mining systems evaluated on the NEWS10 dataset generally used heuris</context>
<context position="15933" citStr="Kumaran et al., 2010" startWordPosition="2520" endWordPosition="2523">) = (9) Ns + 77s where cs(q) is the labelled data count of the multigram q, p(q) is the unlabelled data probability estimate, and Ns = EQ cs(q), and 77s is the number of different multigram types observed in the Viterbi alignment of the labelled data. 472 5 Evaluation We evaluate our unsupervised system and semisupervised system on two tasks, NEWS10 and parallel corpora. NEWS10 is a standard task on transliteration mining from WIL. On NEWS10, we compare our results with the unsupervised mining system of Sajjad et al. (2011), the best supervised and semi-supervised systems presented at NEWS10 (Kumaran et al., 2010b) and the best supervised and semi-supervised results reported in the literature for the NEWS10 task. For the challenging task of mining from parallel corpora, we use the English/Hindi and English/Arabic gold standard provided by Sajjad et al. (2011) to evaluate our results. 5.1 Experiments using the NEWS10 Dataset We conduct experiments on four language pairs: English/Arabic, English/Hindi, English/Tamil and English/Russian using data provided at NEWS10. Every dataset contains training data, seed data and reference data. The NEWS10 data consists of pairs of titles of the same Wikipedia pages</context>
<context position="18556" citStr="Kumaran et al., 2010" startWordPosition="2948" endWordPosition="2952">-product list calculated from the NEWS10 dataset, before mining. EA is English/Arabic, EH is English/Hindi, ET is English/Tamil and ER is English/Russian Table 1 shows the statistics of the word-aligned list and the cross-product list calculated using the NEWS10 reference data.2 The word-aligned list calculated from the NEWS10 dataset is used to compare our unsupervised system with the unsupervised system of Sajjad et al. (2011) on the same training data. All the other experiments on NEWS10 use cross-product lists. We remove numbers from both lists as they are defined as non-transliterations (Kumaran et al., 2010b). 5.1.2 Unsupervised Transliteration Mining We run our unsupervised transliteration mining system on the word-aligned list and the crossproduct list. The word pairs with a posterior probability of transliteration 1 − p,,,tr(e, f) = 1 − Ap2(ei, fi)/p(ei, fi) greater than 0.5 are selected as transliteration pairs. We compare our unsupervised system with the unsupervised system of Sajjad11. Our unsupervised system trained on the word-aligned list shows Fmeasures of 91.7%, 95.5%, 92.9% and 77.7% which is 4.3%, 3.3%, 2.8% and 1.7% better than the system of Sajjad11 on English/Arabic, English/Hind</context>
</contexts>
<marker>Kumaran, Khapra, Li, 2010</marker>
<rawString>A Kumaran, Mitesh M. Khapra, and Haizhou Li. 2010a. Report of NEWS 2010 transliteration mining shared task. In Proceedings of the 2010 Named Entities Workshop, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kumaran</author>
<author>Mitesh M Khapra</author>
<author>Haizhou Li</author>
</authors>
<title>shared task on transliteration mining.</title>
<date>2010</date>
<journal>Whitepaper of NEWS</journal>
<booktitle>In Proceedings of the 2010 Named Entities Workshop,</booktitle>
<location>Uppsala, Sweden.</location>
<contexts>
<context position="2546" citStr="Kumaran et al., 2010" startWordPosition="372" endWordPosition="375">vised system by adding a new S-step to the EM algorithm. The S-step takes the probability estimates from unlabelled data (computed in the Mstep) and uses them as a backoff distribution to smooth probabilities which were estimated from labelled data. The smoothed probabilities are then used in the next E-step. In this way, the parameters learned by EM are constrained to values which are close to those estimated from the labelled data. We evaluate our unsupervised and semisupervised transliteration mining system on the datasets available from the NEWS 2010 shared task on transliteration mining (Kumaran et al., 2010b). We call this task NEWS10 later on. Compared with a baseline unsupervised system our unsupervised system achieves up to 5% better F-measure. On the NEWS10 dataset, our unsupervised system achieves an F-measure of up to 95.7%, and on three language pairs, it performs better than all systems which participated in NEWS10. We also evaluate our semi-supervised system which additionally uses the NEWS10 labelled data for training. It achieves an improvement of up to 3.7% F-measure over our unsupervised system. Additional experiments on parallel corpora show that we are able to effectively mine tra</context>
<context position="4130" citStr="Kumaran et al., 2010" startWordPosition="612" endWordPosition="615">rea, 8-14 July 2012. c�2012 Association for Computational Linguistics 2 Previous Work We first discuss the literature on semi-supervised and supervised techniques for transliteration mining and then describe a previously defined unsupervised system. Supervised and semi-supervised systems use a manually labelled set of training data to learn character mappings between source and target strings. The labelled training data either consists of a few hundred transliteration pairs or of just a few carefully selected transliteration pairs. The NEWS 2010 shared task on transliteration mining (NEWS10) (Kumaran et al., 2010b) is a semisupervised task conducted on Wikipedia InterLanguage Links (WIL) data. The NEWS10 dataset contains 1000 labelled examples (called the “seed data”) for initial training. All systems which participated in the NEWS10 shared task are either supervised or semi-supervised. They are described in (Kumaran et al., 2010a). Our transliteration mining model can mine transliterations without using any labelled data. However, if there is some labelled data available, our system is able to use it effectively. The transliteration mining systems evaluated on the NEWS10 dataset generally used heuris</context>
<context position="15933" citStr="Kumaran et al., 2010" startWordPosition="2520" endWordPosition="2523">) = (9) Ns + 77s where cs(q) is the labelled data count of the multigram q, p(q) is the unlabelled data probability estimate, and Ns = EQ cs(q), and 77s is the number of different multigram types observed in the Viterbi alignment of the labelled data. 472 5 Evaluation We evaluate our unsupervised system and semisupervised system on two tasks, NEWS10 and parallel corpora. NEWS10 is a standard task on transliteration mining from WIL. On NEWS10, we compare our results with the unsupervised mining system of Sajjad et al. (2011), the best supervised and semi-supervised systems presented at NEWS10 (Kumaran et al., 2010b) and the best supervised and semi-supervised results reported in the literature for the NEWS10 task. For the challenging task of mining from parallel corpora, we use the English/Hindi and English/Arabic gold standard provided by Sajjad et al. (2011) to evaluate our results. 5.1 Experiments using the NEWS10 Dataset We conduct experiments on four language pairs: English/Arabic, English/Hindi, English/Tamil and English/Russian using data provided at NEWS10. Every dataset contains training data, seed data and reference data. The NEWS10 data consists of pairs of titles of the same Wikipedia pages</context>
<context position="18556" citStr="Kumaran et al., 2010" startWordPosition="2948" endWordPosition="2952">-product list calculated from the NEWS10 dataset, before mining. EA is English/Arabic, EH is English/Hindi, ET is English/Tamil and ER is English/Russian Table 1 shows the statistics of the word-aligned list and the cross-product list calculated using the NEWS10 reference data.2 The word-aligned list calculated from the NEWS10 dataset is used to compare our unsupervised system with the unsupervised system of Sajjad et al. (2011) on the same training data. All the other experiments on NEWS10 use cross-product lists. We remove numbers from both lists as they are defined as non-transliterations (Kumaran et al., 2010b). 5.1.2 Unsupervised Transliteration Mining We run our unsupervised transliteration mining system on the word-aligned list and the crossproduct list. The word pairs with a posterior probability of transliteration 1 − p,,,tr(e, f) = 1 − Ap2(ei, fi)/p(ei, fi) greater than 0.5 are selected as transliteration pairs. We compare our unsupervised system with the unsupervised system of Sajjad11. Our unsupervised system trained on the word-aligned list shows Fmeasures of 91.7%, 95.5%, 92.9% and 77.7% which is 4.3%, 3.3%, 2.8% and 1.7% better than the system of Sajjad11 on English/Arabic, English/Hind</context>
</contexts>
<marker>Kumaran, Khapra, Li, 2010</marker>
<rawString>A Kumaran, Mitesh M. Khapra, and Haizhou Li. 2010b. Whitepaper of NEWS 2010 shared task on transliteration mining. In Proceedings of the 2010 Named Entities Workshop, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>Zhang Min</author>
<author>Su Jian</author>
</authors>
<title>A joint source-channel model for machine transliteration.</title>
<date>2004</date>
<booktitle>In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="1386" citStr="Li et al., 2004" startWordPosition="187" endWordPosition="190">pairs from unlabelled data. Most transliteration mining systems are built using labelled training data or using heuristics to extract transliteration pairs. These systems are language pair dependent or require labelled information for training. Our system extracts transliteration pairs in an unsupervised fashion. It is also able to utilize labelled information if available, obtaining improved performance. We present a novel model of transliteration mining defined as a mixture of a transliteration model and a non-transliteration model. The transliteration model is a joint source channel model (Li et al., 2004). The non-transliteration model assumes no correlation between source and target word characters, and independently generates a source and a target word using two fixed unigram character models. We use Expectation Maximization (EM) to learn parameters maximizing the likelihood of the interpolation of both sub-models. At test time, we label word pairs as transliterations if they have a higher probability assigned by the transliteration sub-model than by the non-transliteration sub-model. We extend the unsupervised system to a semisupervised system by adding a new S-step to the EM algorithm. The</context>
</contexts>
<marker>Li, Min, Jian, 2004</marker>
<rawString>Haizhou Li, Zhang Min, and Su Jian. 2004. A joint source-channel model for machine transliteration. In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Martin</author>
<author>Rada Mihalcea</author>
<author>Ted Pedersen</author>
</authors>
<title>Word alignment for languages with scarce resources.</title>
<date>2005</date>
<booktitle>In ParaText ’05: Proceedings of the ACL Workshop on Building and Using Parallel Texts,</booktitle>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="27297" citStr="Martin et al., 2005" startWordPosition="4327" endWordPosition="4330">sed system is focused on high recall at the cost of lower precision.4 5.2 Transliteration Mining using Parallel Corpora The percentage of transliteration pairs in the NEWS10 datasets is high. We further check the effectiveness of our unsupervised and semi-supervised mining systems by evaluating them on parallel corpora with as few as 2% transliteration pairs. We conduct experiments using two language pairs, English/Hindi and English/Arabic. The English/Hindi corpus is from the shared task on word alignment organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts (WA05) (Martin et al., 2005). For English/Arabic, we use 200,000 parallel sentences from the United Nations (UN) corpus (Eisele and Chen, 2010). The English/Hindi and English/Arabic transliteration gold standards were provided by Sajjad et al. (2011). 5.2.1 Experiments We follow the procedure for creating the training data described in Section 5.1.1 and build a wordaligned list and a cross-product list from the parallel corpus. We first train and test our unsupervised mining system on the word-aligned list and compare our results with Sajjad et al. Table 7 shows the results. Our unsupervised system achieves 0.6% and 1.8%</context>
</contexts>
<marker>Martin, Mihalcea, Pedersen, 2005</marker>
<rawString>Joel Martin, Rada Mihalcea, and Ted Pedersen. 2005. Word alignment for languages with scarce resources. In ParaText ’05: Proceedings of the ACL Workshop on Building and Using Parallel Texts, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Nabende</author>
</authors>
<title>Mining transliterations from wikipedia using pair hmms.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Named Entities Workshop,</booktitle>
<location>Uppsala, Sweden.</location>
<contexts>
<context position="5457" citStr="Nabende, 2010" startWordPosition="804" endWordPosition="805">uristic-based system of Jiampojamarn et al. (2010) is based on the edit distance method which scores the similarity between source and target words. They presented two discriminative methods – an SVM-based classifier and alignment-based string similarity for transliteration mining. These methods model the conditional probability distribution and require supervised/semi-supervised information for learning. We propose a flexible generative model for transliteration mining usable for both unsupervised and semi-supervised learning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al., 2010), Finite State Automata (Noeman and Madkour, 2010) and Bayesian learning (Kahki et al., 2011) to learn transliteration pairs from labelled data. Our method is different from theirs as our generative story explains the unlabelled data using a combination of a transliteration and a non-transliteration sub-model. The transliteration model jointly generates source and target strings, whereas the non-transliteration system generates them independently of each other. Sajjad et al. (2011) proposed a heuristic-based unsupervised transliteration mining system.</context>
</contexts>
<marker>Nabende, 2010</marker>
<rawString>Peter Nabende. 2010. Mining transliterations from wikipedia using pair hmms. In Proceedings of the 2010 Named Entities Workshop, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Nabende</author>
</authors>
<title>Mining transliterations from Wikipedia using dynamic bayesian networks.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference Recent Advances in Natural Language Processing</booktitle>
<location>Hissar, Bulgaria.</location>
<contexts>
<context position="20580" citStr="Nabende (2011)" startWordPosition="3288" endWordPosition="3289">.5 94.1 - EH 92.2 95.7 96.3 94.4 93.2 95.5 ET 90.1 93.2 94.6 91.4 95.5 93.9 ER 76.0 79.4 83.1 87.5 92.3 82.5 Unsupervised P R F Semi-supervised P R F EA 89.2 95.7 92.4 92.9 92.4 92.7 EH 92.6 99.0 95.7 95.5 97.0 96.3 ET 88.3 98.6 93.2 93.4 95.8 94.6 ER 67.2 97.1 79.4 74.0 94.9 83.1 Table 2: F-measure results on NEWS10 datasets where SJD is the unsupervised system of Sajjad11, OU is our unsupervised system built on the cross-product list, OS is our semi-supervised system, SBest is the best NEWS10 system, GR is the supervised system of Kahki et al. (2011) and DBN is the semi-supervised system of Nabende (2011) Our unsupervised mining system built on the cross-product list consistently outperforms the one built on the word-aligned list. Later, we consider only the system built on the cross-product list. Table 2 shows the results of our unsupervised system OU in comparison with the unsupervised system of Sajjad11 (SJD), the best semi-supervised systems presented at NEWS10 (SBEST) and the best semi-supervised results reported on the NEWS10 dataset (GR, DBN). On three language pairs, our unsupervised system performs better than all semisupervised systems which participated in NEWS10. It has competitive</context>
</contexts>
<marker>Nabende, 2011</marker>
<rawString>Peter Nabende. 2011. Mining transliterations from Wikipedia using dynamic bayesian networks. In Proceedings of the International Conference Recent Advances in Natural Language Processing 2011, Hissar, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Noeman</author>
<author>Amgad Madkour</author>
</authors>
<title>Language independent transliteration mining system using finite state automata framework.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Named Entities Workshop,</booktitle>
<location>Uppsala, Sweden.</location>
<contexts>
<context position="5550" citStr="Noeman and Madkour, 2010" startWordPosition="816" endWordPosition="819">method which scores the similarity between source and target words. They presented two discriminative methods – an SVM-based classifier and alignment-based string similarity for transliteration mining. These methods model the conditional probability distribution and require supervised/semi-supervised information for learning. We propose a flexible generative model for transliteration mining usable for both unsupervised and semi-supervised learning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al., 2010), Finite State Automata (Noeman and Madkour, 2010) and Bayesian learning (Kahki et al., 2011) to learn transliteration pairs from labelled data. Our method is different from theirs as our generative story explains the unlabelled data using a combination of a transliteration and a non-transliteration sub-model. The transliteration model jointly generates source and target strings, whereas the non-transliteration system generates them independently of each other. Sajjad et al. (2011) proposed a heuristic-based unsupervised transliteration mining system. We later call it Sajjad11. It is the only unsupervised mining system that was evaluated on t</context>
</contexts>
<marker>Noeman, Madkour, 2010</marker>
<rawString>Sara Noeman and Amgad Madkour. 2010. Language independent transliteration mining system using finite state automata framework. In Proceedings of the 2010 Named Entities Workshop, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="17046" citStr="Och and Ney, 2003" startWordPosition="2698" endWordPosition="2701">ta, seed data and reference data. The NEWS10 data consists of pairs of titles of the same Wikipedia pages written in different languages, which may be transliterations or translations. The seed data is a list of 1000 transliteration pairs provided to semi-supervised systems for initial training. We use the seed data only in our semi-supervised system, and not in the unsupervised system. The reference data is a small subset of the training data which is manually annotated with positive and negative examples. 5.1.1 Training We word-aligned the parallel phrases of the training data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using the grow-diagfinal-and heuristic (Koehn et al., 2003). We extract all word pairs which occur as 1-to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the word-aligned list. We compared the word-aligned list with the NEWS10 reference data and found that the word-aligned list is missing some transliteration pairs because of word-alignment errors. We built another list by adding a word pair for every source word that cooccurs with a target word in a parallel phrase/sentence and call it the cross-product list later on. The cross-product lis</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sajjad</author>
<author>Alexander Fraser</author>
<author>Helmut Schmid</author>
</authors>
<title>An algorithm for unsupervised transliteration mining with an application to word alignment.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Conference of the Association for Computational Linguistics,</booktitle>
<location>Portland, USA.</location>
<contexts>
<context position="5986" citStr="Sajjad et al. (2011)" startWordPosition="880" endWordPosition="883">d learning. Previous work on generative approaches uses Hidden Markov Models (Nabende, 2010; Darwish, 2010; Jiampojamarn et al., 2010), Finite State Automata (Noeman and Madkour, 2010) and Bayesian learning (Kahki et al., 2011) to learn transliteration pairs from labelled data. Our method is different from theirs as our generative story explains the unlabelled data using a combination of a transliteration and a non-transliteration sub-model. The transliteration model jointly generates source and target strings, whereas the non-transliteration system generates them independently of each other. Sajjad et al. (2011) proposed a heuristic-based unsupervised transliteration mining system. We later call it Sajjad11. It is the only unsupervised mining system that was evaluated on the NEWS10 dataset up until now, as far as we know. That system is computationally expensive. We show in Section 5 that its runtime is much higher than that of our system. In this paper, we propose a novel model-based approach to transliteration mining. Our approach is language pair independent – at least for alphabetic languages – and efficient. Unlike the previous unsupervised system, and unlike the supervised and semi-supervised s</context>
<context position="15842" citStr="Sajjad et al. (2011)" startWordPosition="2507" endWordPosition="2510">elled data counts (S-step). The smoothed probability estimate p(q) is: cs(q) + 77sp(q) �p(q) = (9) Ns + 77s where cs(q) is the labelled data count of the multigram q, p(q) is the unlabelled data probability estimate, and Ns = EQ cs(q), and 77s is the number of different multigram types observed in the Viterbi alignment of the labelled data. 472 5 Evaluation We evaluate our unsupervised system and semisupervised system on two tasks, NEWS10 and parallel corpora. NEWS10 is a standard task on transliteration mining from WIL. On NEWS10, we compare our results with the unsupervised mining system of Sajjad et al. (2011), the best supervised and semi-supervised systems presented at NEWS10 (Kumaran et al., 2010b) and the best supervised and semi-supervised results reported in the literature for the NEWS10 task. For the challenging task of mining from parallel corpora, we use the English/Hindi and English/Arabic gold standard provided by Sajjad et al. (2011) to evaluate our results. 5.1 Experiments using the NEWS10 Dataset We conduct experiments on four language pairs: English/Arabic, English/Hindi, English/Tamil and English/Russian using data provided at NEWS10. Every dataset contains training data, seed data </context>
<context position="17225" citStr="Sajjad et al. (2011)" startWordPosition="2726" endWordPosition="2729">ations. The seed data is a list of 1000 transliteration pairs provided to semi-supervised systems for initial training. We use the seed data only in our semi-supervised system, and not in the unsupervised system. The reference data is a small subset of the training data which is manually annotated with positive and negative examples. 5.1.1 Training We word-aligned the parallel phrases of the training data using GIZA++ (Och and Ney, 2003), and symmetrized the alignments using the grow-diagfinal-and heuristic (Koehn et al., 2003). We extract all word pairs which occur as 1-to-1 alignments (like Sajjad et al. (2011)) and later refer to them as the word-aligned list. We compared the word-aligned list with the NEWS10 reference data and found that the word-aligned list is missing some transliteration pairs because of word-alignment errors. We built another list by adding a word pair for every source word that cooccurs with a target word in a parallel phrase/sentence and call it the cross-product list later on. The cross-product list is noisier but contains almost all transliteration pairs in the corpus. Word-aligned Cross-product P R F P R F EA 27.8 97.1 43.3 14.3 98.0 25.0 EH 42.5 98.7 59.4 20.5 99.6 34.1 </context>
<context position="21813" citStr="Sajjad et al. (2011)" startWordPosition="3465" endWordPosition="3468"> the best supervised results reported on NEWS10 datasets. On English/Hindi, our unsupervised system outperforms the state-of-the-art supervised and semi-supervised systems. Kahki et al. (2011) (GR) achieved the best results on English/Arabic, English/Tamil and English/Russian. For the English/Arabic task, they normalized the data using language dependent heuristics3 and also used a non-standard evaluation method (discussed in Section 5.1.4). On the English/Russian dataset, our unsupervised system faces the problem that it extracts cognates as transliterations. The same problem was reported in Sajjad et al. (2011). Cognates are close transliterations which differ by only one or two characters from an exact transliteration pair. The unsupervised system learns to delete the additional one or two characters with a high probability and incorrectly mines such word pairs as transliterations. 3They applied an Arabic word segmenter which uses language dependent information. Arabic long vowels which have identical sound but are written differently were merged to one form. English characters were normalized by dropping accents. Table 3: Precision(P), Recall(R) and F-measure(F) of our unsupervised and semi-superv</context>
<context position="27519" citStr="Sajjad et al. (2011)" startWordPosition="4359" endWordPosition="4362">ness of our unsupervised and semi-supervised mining systems by evaluating them on parallel corpora with as few as 2% transliteration pairs. We conduct experiments using two language pairs, English/Hindi and English/Arabic. The English/Hindi corpus is from the shared task on word alignment organized as part of the ACL 2005 Workshop on Building and Using Parallel Texts (WA05) (Martin et al., 2005). For English/Arabic, we use 200,000 parallel sentences from the United Nations (UN) corpus (Eisele and Chen, 2010). The English/Hindi and English/Arabic transliteration gold standards were provided by Sajjad et al. (2011). 5.2.1 Experiments We follow the procedure for creating the training data described in Section 5.1.1 and build a wordaligned list and a cross-product list from the parallel corpus. We first train and test our unsupervised mining system on the word-aligned list and compare our results with Sajjad et al. Table 7 shows the results. Our unsupervised system achieves 0.6% and 1.8% higher F-measure than Sajjad et al. respectively. The cross-product list is huge in comparison to the word-aligned list. It is noisier than the word4We implemented a bigram version of our system to learn the contextual in</context>
</contexts>
<marker>Sajjad, Fraser, Schmid, 2011</marker>
<rawString>Hassan Sajjad, Alexander Fraser, and Helmut Schmid. 2011. An algorithm for unsupervised transliteration mining with an application to word alignment. In Proceedings of the 49th Annual Conference of the Association for Computational Linguistics, Portland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Timothy C Bell</author>
</authors>
<title>The zerofrequency problem: Estimating the probabilities of novel events in adaptive text compression.</title>
<date>1991</date>
<booktitle>In IEEE Transactions on Information Theory,</booktitle>
<volume>37</volume>
<contexts>
<context position="13941" citStr="Witten and Bell, 1991" startWordPosition="2190" endWordPosition="2193">abelled data probabilities as a backoff. 4.1 Model Estimation We calculate the unlabelled data probabilities in the E-step using Equation 4. For labelled data (containing only transliterations) we set A = 0 and get: p(e, f) = � p1(e, f, a) (8) aEAlign(e,f) In every EM iteration, we smooth the probability distribution in such a way that the estimates of the multigrams of the unlabelled data that do not occur in the labelled data would be penalized. We obtain this effect by smoothing the probability distribution of unlabelled and labelled data using a technique similar to Witten-Bell smoothing (Witten and Bell, 1991), as we describe below. Figure 1: Semi-supervised training 4.2 Implementation Details We divide the training process of semi-supervised mining in two steps as shown in Figure 1. The first step creates a reasonable alignment of the labelled data from which multigram counts can be obtained. The labelled data is a small list of transliteration pairs. Therefore we use the unlabelled data to help correctly align it and train our unsupervised mining system on the combined labelled and unlabelled training data. In the expectation step, the prior probability of non-transliteration A is set to zero on </context>
</contexts>
<marker>Witten, Bell, 1991</marker>
<rawString>Ian H. Witten and Timothy C. Bell. 1991. The zerofrequency problem: Estimating the probabilities of novel events in adaptive text compression. In IEEE Transactions on Information Theory, volume 37.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>