<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005937">
<note confidence="0.7435225">
U: Let me show you how to find someone&apos;s publications
U: Go to this webpage
Navigates to http://scholar.google.com
U: Click on the advanced search link
</note>
<figure confidence="0.871784580645161">
Clicks Advanced Scholar Search
U: Put the author&apos;s name here
Types the name in the Author text field
U: Click the search button
Clicks on the Search Scholar button
U: OK here is the list of results
Selects the table on page
PLOW: Can you check that I understand the data.
PLOW: puts up a new window with the results.
U: OK this is good.
U: this is the article title
Highlights a title
PLOW: attempts to find all titles and displays them
U: This is wrong.
PLOW OK
U: This is another article title
Highlights another correct title
PLOW: recomputes all the titles and displays them
Switches back to Scholar window
U: OK click next to get more results
Clicks the Next link
PLOW: When should I stop searching?
U: Get thirty results
PLOW: OK. I will do that
PLOW: iterates through pages until it gets 30 results
PLOW: I’m done.
U: We&apos;re done with the demonstration
U: Let&apos;s practice
PLOW: what is the name of the author?
Enters a new name
PLOW executes the procedure successfully!!
</figure>
<figureCaption confidence="0.998621">
Figure 2: Learning to find titles of an author’s publications (U = user)
</figureCaption>
<sectionHeader confidence="0.522282" genericHeader="abstract">
Evaluation
</sectionHeader>
<bodyText confidence="0.99999325">
The PLOW system was evaluated by independent
evaluators who considered four task learning
systems developed in the CALO project. There
were 16 human subjects who received training on
each of the systems and who worked through a
number of successful scripted training sessions
with each. They were then given ten new
problems, ranging from slight variations to
problems they had seen to problems that were
substantially new. They were free to choose which
problems to work on and which system to use and
the resulting tasks learned were tested with
different settings of the parameters and scored out
of a total of 4 points based on a complex
predefined evaluation criteria (not known to the
developers). The PLOW system did well in the
test, not only receiving the highest average score
on tasks learned by a system (figure 3) but also
was strongly preferred by the users and selected
more than half the time (figure 4).
</bodyText>
<subsectionHeader confidence="0.906521">
The Demonstration
</subsectionHeader>
<bodyText confidence="0.99993">
If we are allowed a presentation we will
demonstrate PLOW live on a task selected by the
audience. In addition, we would like to have the
system available for an extended period of time
during the conference so that attendees can spend
time using the system to teach it simple tasks. The
system runs on a laptop and all that is needed for
a demo is internet access.
</bodyText>
<sectionHeader confidence="0.994823" genericHeader="categories and subject descriptors">
Acknowledgements &amp; References
</sectionHeader>
<reference confidence="0.876614909090909">
This work was supported by DARPA grant NBCH-
D-03-0010 under a subcontract from SRI International,
ONR grant N000140510314, and NSF grant5-28096.
Chambers, N. et al. (2006). Using Semantics to Identify
Web Objects. Proceedings AAAI.
Jung, H., J. Allen, et al. (2006). One-Shot Proce-dure
Learning from Instruction and Observation. FLAIRS,
Melbourne, FL.
Lent, M. and Laird, J. (2001) Learning Procedural
Knowledge through Observation, Proc. of the Intl
Conf. on Knowledge Capture.
</reference>
<figureCaption confidence="0.894682">
Figure 3: Average score (out of 4) Figure 4: User preference for systems (55 trials)
</figureCaption>
<page confidence="0.991364">
2
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.057659">
<title confidence="0.7145662">U: Let me show you how to find someone&apos;s publications U: Go to this webpage Navigates to http://scholar.google.com U: Click on the advanced search link Clicks Advanced Scholar Search</title>
<abstract confidence="0.993423163934426">U: Put the author&apos;s name here Types the name in the Author text field U: Click the search button Clicks on the Search Scholar button U: OK here is the list of results Selects the table on page PLOW: Can you check that I understand the data. puts up a new window with the U: OK this is good. U: this is the article title Highlights a title PLOW: attempts to find all titles and displays them U: This is wrong. PLOW OK U: This is another article title Highlights another correct title PLOW: recomputes all the titles and displays them back to Scholar window U: OK click next to get more results Clicks the Next link PLOW: When should I stop searching? U: Get thirty results PLOW: OK. I will do that PLOW: iterates through pages until it gets 30 results PLOW: I’m done. U: We&apos;re done with the demonstration U: Let&apos;s practice PLOW: what is the name of the author? Enters a new name PLOW executes the procedure successfully!! Figure 2: Learning to find titles of an author’s publications (U = user) Evaluation The PLOW system was evaluated by independent evaluators who considered four task learning systems developed in the CALO project. There were 16 human subjects who received training on each of the systems and who worked through a number of successful scripted training sessions with each. They were then given ten new problems, ranging from slight variations to problems they had seen to problems that were substantially new. They were free to choose which problems to work on and which system to use and the resulting tasks learned were tested with different settings of the parameters and scored out of a total of 4 points based on a complex predefined evaluation criteria (not known to the developers). The PLOW system did well in the test, not only receiving the highest average score on tasks learned by a system (figure 3) but also was strongly preferred by the users and selected more than half the time (figure 4). The Demonstration If we are allowed a presentation we will demonstrate PLOW live on a task selected by the audience. In addition, we would like to have the system available for an extended period of time during the conference so that attendees can spend time using the system to teach it simple tasks. The system runs on a laptop and all that is needed for a demo is internet access.</abstract>
<note confidence="0.939726857142857">Acknowledgements &amp; References This work was supported by DARPA grant NBCH- D-03-0010 under a subcontract from SRI International, ONR grant N000140510314, and NSF grant5-28096. N. et al. (2006). Semantics to Identify Objects. H., J. Allen, et al. (2006). Proce-dure Learning from Instruction and Observation. FLAIRS, Melbourne, FL. M. and Laird, J. (2001) Procedural through Proc. of the Intl Conf. on Knowledge Capture. Figure 3: Average score (out of 4) Figure 4: User preference for systems (55 trials) 2</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>This work was supported by DARPA grant NBCHD-03-0010 under a subcontract from</title>
<booktitle>SRI International, ONR grant N000140510314, and NSF</booktitle>
<pages>5--28096</pages>
<marker></marker>
<rawString>This work was supported by DARPA grant NBCHD-03-0010 under a subcontract from SRI International, ONR grant N000140510314, and NSF grant5-28096.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chambers</author>
</authors>
<title>Using Semantics to Identify Web Objects.</title>
<date>2006</date>
<booktitle>Proceedings AAAI.</booktitle>
<marker>Chambers, 2006</marker>
<rawString>Chambers, N. et al. (2006). Using Semantics to Identify Web Objects. Proceedings AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Jung</author>
<author>J Allen</author>
</authors>
<date>2006</date>
<booktitle>One-Shot Proce-dure Learning from Instruction and Observation. FLAIRS,</booktitle>
<location>Melbourne, FL.</location>
<marker>Jung, Allen, 2006</marker>
<rawString>Jung, H., J. Allen, et al. (2006). One-Shot Proce-dure Learning from Instruction and Observation. FLAIRS, Melbourne, FL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lent</author>
<author>J Laird</author>
</authors>
<date>2001</date>
<booktitle>Learning Procedural Knowledge through Observation, Proc. of the Intl Conf. on Knowledge Capture.</booktitle>
<marker>Lent, Laird, 2001</marker>
<rawString>Lent, M. and Laird, J. (2001) Learning Procedural Knowledge through Observation, Proc. of the Intl Conf. on Knowledge Capture.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>