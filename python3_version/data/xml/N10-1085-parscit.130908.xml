<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002343">
<title confidence="0.964493">
Prenominal Modifier Ordering via Multiple Sequence Alignment
</title>
<author confidence="0.995682">
Aaron Dunlop Margaret Mitchell Brian Roark
</author>
<affiliation confidence="0.965706">
Oregon Health &amp; Science University University of Aberdeen Oregon Health &amp; Science University
</affiliation>
<address confidence="0.524874">
Portland, OR Aberdeen, Scotland, U.K. Portland, OR
</address>
<email confidence="0.990992">
dunlopa@cslu.ogi.edu m.mitchell@abdn.ac.uk roark@cslu.ogi.edu
</email>
<sectionHeader confidence="0.97979" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9983565">
Producing a fluent ordering for a set of
prenominal modifiers in a noun phrase
(NP) is a problematic task for natural lan-
guage generation and machine translation
systems. We present a novel approach
to this issue, adapting multiple sequence
alignment techniques used in computa-
tional biology to the alignment of modi-
fiers. We describe two training techniques
to create such alignments based on raw
text, and demonstrate ordering accuracies
superior to earlier reported approaches.
</bodyText>
<sectionHeader confidence="0.995511" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953870967742">
Natural language generation and machine trans-
lation systems must produce text which not only
conforms to a reasonable grammatical model,
but which also sounds smooth and natural to
a human consumer. Ordering prenominal mod-
ifiers in noun phrases is particularly difficult
in these applications, as the rules underlying
these orderings are subtle and not well under-
stood. For example, the phrase “big red ball”
seems natural, while “red big ball” seems more
marked, suitable only in specific contexts. There
is some consensus that the order of prenom-
inal modifiers in noun phrases is governed in
part by semantic constraints, but there is no
agreement on the exact constraints necessary to
specify consistent orderings for any given set of
modifiers. General principles of modifier order-
ing based on semantic constraints also fall short
on larger domains, where it is not always clear
how to map prenominal modifiers to proposed
semantic groups.
With the recent advantages of large corpora
and powerful computational resources, work
on automatically ordering prenominal modifiers
has moved away from approaches based on gen-
eral principles, and towards learning ordering
preferences empirically from existing corpora.
Such approaches have several advantages: (1)
The predicted orderings are based on prior evi-
dence from ‘real-world’ texts, ensuring that they
are therefore reasonably natural. (2) Many (if
not all) prenominal modifiers can be ordered.
(3) Expanding the training data with more and
larger corpora often improves the system with-
out requiring significant manual labor.
In this paper, we introduce a novel approach
to prenominal modifier ordering adapted from
multiple sequence alignment (MSA) techniques
used in computational biology. MSA is generally
applied to DNA, RNA, and protein sequences,
aligning three or more biological sequences in or-
der to determine, for example, common ancestry
(Durbin et al., 1999; Gusfield, 1997; Carrillo and
Lipman, 1988). MSA techniques have not been
widely applied in NLP, but have produced some
promising results for building a generation map-
ping dictionary (Barzilay and Lee, 2002), para-
phrasing (Barzilay and Lee, 2003), and phone
recognition (White et al., 2006).
We believe that multiple sequence alignment
is well-suited for aligning linguistic sequences,
and that these alignments can be used to predict
prenominal modifier ordering for any given set
of modifiers. Our technique utilizes simple fea-
tures within the raw text, and does not require
any semantic information. We achieve good per-
formance using this approach, with results com-
petitive with earlier work (Shaw and Hatzivas-
siloglou, 1999; Malouf, 2000; Mitchell, 2009) and
higher recall and F-measure than that reported
in Mitchell (2009) when tested on the same cor-
pus.
</bodyText>
<page confidence="0.958362">
600
</page>
<note confidence="0.783613">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 600–608,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.990992" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999695372340426">
In one of the first attempts at automatically or-
dering prenominal modifiers, Shaw and Hatzi-
vassiloglou (1999) present three empirical meth-
ods to order a variety of prenominal modifier
types. Their approach provides ordering deci-
sions for adjectives, gerunds (such as “running”
in “running man&amp;quot;), and past participles (such
as “heated” in “heated debate”), as well as for
modifying nouns (such as “baseball” in “base-
ball field&amp;quot;). A morphology module transforms
plural nouns and comparative/superlative forms
into their base forms, increasing the frequency
counts for each modifier. We will briefly re-
cap their three methods, which are categorized
as the direct evidence method, the transitivity
method, and the clustering method.
Given prenominal modifiers a and b in a train-
ing corpus, the direct evidence method com-
pares frequency counts of the ordered sequences
&lt;a,b&gt; and &lt;b,a&gt;. This approach works well,
but is limited by data sparsity; groups of two or
more modifiers before a noun are relatively in-
frequent in traditional corpora, and finding the
same pair of modifiers together more than once
is particularly rare.
To overcome this issue, Shaw and Hatzi-
vassiloglou&apos;s transitivity and clustering meth-
ods make inferences about unseen orderings
among prenominal modifiers. In the transitiv-
ity method, given three modifiers a,b,c, where a
precedes b and b precedes c, the model concludes
that a precedes c. The clustering method calcu-
lates a similarity score between modifiers based
on where the modifiers occur in relation to the
other modifiers in the corpus. Those modifiers
that are most similar are clustered together, and
ordering decisions can be made between modi-
fiers in separate clusters. All three approaches
are designed to order pairs of modifiers; it is un-
clear how to extend these approaches to order
groups larger than a pair.
Shaw and Hatzivassiloglou find that NPs with
only adjectives as modifiers (including gerunds
and past participles) are considerably easier to
order than those which contain both adjectives
and nouns. They also find large differences in
accuracy across domains; their systems achieve
much lower overall accuracy on financial text
(the Wall Street Journal (WSJ) corpus (Marcus
et al., 1999)) than on medical discharge sum-
maries.
Looking at all modifier pairs, the authors
achieve their highest prediction accuracy of
90.7% using the transitivity technique on a med-
ical corpus. We do not have access to this cor-
pus, but we do have access to the WSJ corpus,
which provides a way to compare our methods.
On this corpus, their model produces predic-
tions for 62.5% of all modifier pairs and achieves
83.6% accuracy when it is able to make a predic-
tion. Random guessing on the remainder yields
an overall accuracy of 71.0%.
Malouf (2000) also examines the problem of
prenominal modifier ordering. He too proposes
several statistical techniques, achieving results
ranging from 78.3% to 91.9% accuracy. He
achieves his best results by combining memory-
based learning and positional probability to
modifiers from the first 100 million tokens of
the BNC. However, this evaluation is limited to
the ordering of prenominal adjectives, which is a
considerably simpler task than ordering all types
of prenominal modifiers. Malouf&apos;s approaches
are also limited to ordering pairs of modifiers.
Mitchell (2009) proposes another approach,
grouping modifiers into classes and ordering
based on those classes. A modifier&apos;s class is as-
signed based on its placement before a noun,
relative to the other modifiers it appears with.
Classes are composed of those modifiers that
tend to be placed closer to the head noun, those
modifiers that tend to be placed farther from the
head noun, etc., with each class corresponding
to a general positional preference. Unlike earlier
work, these classes allow more than one ordering
to be proposed for some pairs of modifiers.
Combining corpora of various genres,
Mitchell’s system achieves a token precision
of 89.6% (see Section 4 for discussion and
comparison of various evaluation metrics).
However, the model only makes predictions for
74.1% of all modifier pairs in the test data, so
recall is quite low (see Tables 4 and 6).
Overall, previous work in noun-phrase order-
</bodyText>
<page confidence="0.99766">
601
</page>
<bodyText confidence="0.999929">
ing has produced impressive accuracies in some
domains, but currently available systems tend
to adapt poorly to unseen modifiers and do not
generalize well to unseen domains.
</bodyText>
<sectionHeader confidence="0.998469" genericHeader="method">
3 Methods
</sectionHeader>
<subsectionHeader confidence="0.999785">
3.1 Multiple Sequence Alignment
</subsectionHeader>
<bodyText confidence="0.999953">
Multiple sequence alignment algorithms align
sequences of discrete tokens into a series of
columns. They attempt to align identical or
easily-substitutable tokens within a column, in-
serting gaps when such gaps will result in a bet-
ter alignment (more homogeneous token assign-
ments within each column). For example, con-
sider the simple alignment shown in Table 1.
The two sequences `GAACTGAT&apos; and `AAGT-
GTAT&apos; are aligned to maximize the number of
identical items that appear in the same column,
substituting tokens (column 3), and inserting
gaps (columns 1 and 6)i.
A full MSA is generally constructed by itera-
tively aligning each new sequence with an identi-
cal or similar sequence already in the MSA (so-
called “progressive alignment”). The costs of
token substitution are often taken from a hand-
tuned substitution matrix. A cost may also be
associated with inserting a gap into the exist-
ing MSA (a “gap penalty”). Once the full MSA
has been constructed, a Position Specific Score
Matrix (PSSM) can be induced, in which each
token (including a special gap token) is assigned
a separate alignment cost for each column. An
unseen sequence can then be aligned with the
full MSA by Viterbi search.
Predicting sequence ordering within a noun
phrase is a natural application for MSA tech-
niques, and it seems reasonable to propose that
aligning an unseen set of modifiers with such an
MSA model will yield acceptable orderings. Ta-
ble 2 illustrates how MSA may be applied to
modifiers before a noun. Given an NP preceded
by modifiers hungry, big, and Grizzly, alignment
of the modifiers with NPs seen in the training
corpus determines the prenominal ordering big
hungry Grizzly. We then align every permuta-
</bodyText>
<footnote confidence="0.944054">
1See Durbin et al. (1999) for details on standard align-
ment techniques.
</footnote>
<table confidence="0.799009666666667">
G A C T G - A T
- A G T G T A T
1 2 3 4 5 6 7 8
</table>
<tableCaption confidence="0.9796555">
Table 1: Alignment of the two DNA sequences
`GAACTGAT&apos; and `AAGTGTAT&apos;.
</tableCaption>
<table confidence="0.885604">
small clumsy black bear
big - black cow
two-story - brown house
big clumsy - bull
small fuzzy brown duck
large - green house
big hungry Grizzly bear
</table>
<tableCaption confidence="0.997045">
Table 2: Example noun-phrase alignment.
</tableCaption>
<bodyText confidence="0.999909666666667">
tion of the NP and choose the best-scoring align-
ment.
The vocabulary for a linguistic alignment is
large enough to render a hand-tuned substitu-
tion matrix impractical, so we instead construct
a cost function based on features of the token
under consideration and those of the other to-
kens already aligned in a column.
We know of no prior work on methods for
training such an alignment. We present and
compare two training methods, each of which
produces competitive ordering accuracies. Both
training methods share the feature-set described
in Table 3. In each case, we train an MSA by
aligning each instance in the training data.
</bodyText>
<subsectionHeader confidence="0.999383">
3.2 Maximum Likelihood Training
</subsectionHeader>
<bodyText confidence="0.999986384615385">
In our alignment approach, the features listed in
Table 3 are grouped into several classes. All ob-
served words are a class, all observed stems are
a class (Porter, 1980), and so on. We treat each
indicator feature as a separate class, and make
the assumption that classes are independent of
one another. This assumption is clearly false,
but serves as a reasonable first approximation,
similar to the independence assumption in Naive
Bayesian analysis. After aligning each instance,
we estimate the probability of a feature appear-
ing in a column as the simple maximum like-
lihood estimate given the observed occurrences
</bodyText>
<page confidence="0.995369">
602
</page>
<table confidence="0.996168363636364">
Identity Features
Word Token
Stem Word stem, derived by the Porter Stemmer
Length ‘Binned’ length indicators: 1, 2, 3, 4, 5-6, 7-8, 9-12, 13-18, &gt;18 characters
Indicator Features
Capitalized Token begins with a capital
All-caps Entire token is capitalized
Hyphenated Token contains a hyphen
Numeric Entire token is numeric (e.g. 234)
Initial Numeric Token begins with a numeral (e.g. 123, 2-sided)
Endings Token ends with -al, -ble, -ed, -er, -est, -ic, -ing, -ive, -ly
</table>
<tableCaption confidence="0.999646">
Table 3: Description of the feature-set.
</tableCaption>
<bodyText confidence="0.995831869565217">
within its class.2 This produces a new PSSM
with which to align the next instance.
Our problem differs from alignment of biolog-
ical sequences in that we have little prior knowl-
edge of the similarity between sequences. `Sim-
ilarity&apos; can be defined in many ways; for bio-
logical sequences, a simple Levenshtein distance
is effective, using a matrix of substitution costs
or simple token identity (equivalent to a ma-
trix with cost 0 on the diagonal and 1 every-
where else). These matrices are constructed and
tuned by domain experts, and are used both in
choosing alignment order (i.e., which sequence
to align next) and during the actual alignment.
When aligning biological sequences, it is cus-
tomary to first calculate the pairwise distance
between each two sequences and then introduce
new sequences into the MSA in order of simi-
larity. In this way, identical sequences may be
aligned first, followed by less similar sequences
(Durbin et al., 1999).
However, we have no principled method of de-
termining the ‘similarity’ of two words in an NP.
We have no a priori notion of what the cost
of substituting ‘two-story’ for `red&apos; should be.
Lacking this prior knowledge, we have no opti-
mal alignment order and we must in effect learn
the substitution costs as we construct the MSA.
Therefore, we choose to add instances in the or-
der they occur in the corpus, and to iterate over
the entire MSA, re-introducing each sequence.
2 W treat two special symbols for gaps and unknown
words as members of the word class.
This allows a word to ‘move’ from its original
column to a column which became more likely
as more sequences were aligned. Each iteration
is similar to a step in the EM algorithm: create a
model (build up an MSA and PSSM), apply the
model to the data (re-align all sequences), and
repeat. Randomly permuting the training cor-
pus did not change our results significantly, so
we believe our results are not greatly dependent
on the initial sequence order.
Instead of assigning substitution costs, we
compute the cost of aligning a word into a par-
ticular column, as follows:
</bodyText>
<equation confidence="0.6442475">
C = The set of i feature classes, Ci E C
j = Features 1... |Ci |from class Ci
</equation>
<bodyText confidence="0.94642375">
cnt(i, j, k) = The count of instances of
feature j from class
i in column k
λi = Laplace smoothing count
for feature class Ci
A = The number of aligned instances
{ 1 if word w has feature j from
Ci,
</bodyText>
<sectionHeader confidence="0.662612" genericHeader="method">
0 otherwise
</sectionHeader>
<bodyText confidence="0.9995265">
These help define feature positional probabilities
for column k:
</bodyText>
<equation confidence="0.9972355">
cnt(i, j, k) + λi
p(i,j,k) = (1)
A + λi · |Ci|
f(w, i,j) =
</equation>
<page confidence="0.988204">
603
</page>
<bodyText confidence="0.999985">
That is, the probability of feature j from class
i occurring in column k is a simple maximum-
likelihood estimate —count the number of times
we have already aligned that feature in the col-
umn and divide by the number of sequences
aligned. We smooth that probability with sim-
ple Laplace smoothing.
We can now calculate the probability of align-
ing a word w into column k by multiplying the
product of the probabilities of aligning each of
the word’s features. Taking the negative log to
convert that probability into a cost function:
</bodyText>
<equation confidence="0.977255">
log (p(i, j, k) · f(w, i, j)) (2)
</equation>
<bodyText confidence="0.999296833333333">
Finally, we define the cost of inserting a new
column into the alignment to be equal to the
number of columns in the existing alignment,
thereby increasingly penalizing each inserted
column until additional columns become pro-
hibitively expensive.
</bodyText>
<equation confidence="0.998836">
i(j) = I · Length of existing alignment (3)
</equation>
<bodyText confidence="0.9999916">
The longest NPs aligned were 7 words, and
most ML MSAs ended with 12-14 columns.
We experimented with various column insertion
costs and values for the smoothing A and found
no significant differences in overall performance.
</bodyText>
<subsectionHeader confidence="0.995257">
3.3 Discriminative Training
</subsectionHeader>
<bodyText confidence="0.999985942857143">
We also trained a discriminative model, us-
ing the same feature-set. Discriminative train-
ing does not require division of the features
into classes or the independence assumption dis-
cussed in Section 3.2. We again produced a cost
vector for each column. We fixed the alignment
length at 8 columns, allowing alignment of the
longest instances in our test corpus.
Our training data consists of ordered se-
quences, but the model we are attempting to
learn is a set of column probabilities. Since we
have no gold-standard MSAs, we instead align
the ordered NPs with the current model and
treat the least cost alignment of the correct or-
dering as the reference for training.
We trained this model using the averaged per-
ceptron algorithm (Collins, 2002). A percep-
tron learns from classifier errors, i.e., when it
misorders an NP. At each training instance, we
align all possible permutations of the modifiers
with the MSA. If the least cost alignment does
not correspond to the correct ordering of the
modifiers, we update the perceptron to penal-
ize features occurring in that alignment and to
reward features occurring in the least cost align-
ment corresponding to the correct ordering, us-
ing standard perceptron updates.
Examining every permutation of the NP in-
volves a non-polynomial cost, but the sequences
under consideration are quite short (less than
1% of the NPs in our corpus have more than 3
modifiers, and the longest has 6; see Table 7). So
exhaustive search is practical for our problem; if
we were to apply MSA to longer sequences, we
would need to prune heavily.3
</bodyText>
<sectionHeader confidence="0.995576" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.992227954545454">
We trained and tested on the same corpus used
by Mitchell (2009), including identical 10-fold
cross-validation splits. The corpus consists of
all NPs extracted from the Penn Treebank,
the Brown corpus, and the Switchboard corpus
(Marcus et al., 1999; Kucera and Francis, 1967;
Godfrey et al., 1992). The corpus is heavily
biased toward WSJ text (74%), with approxi-
mately 13% of the NPs from each of the other
corpora.
We evaluated our system using several related
but distinct metrics, and on both modifier pairs
and full NPs.
We define:
T = The set of unique orderings found in the
test corpus
P = The set of unique orderings predicted by
the system
Type Precision (|P n T|/|P|) measures the
probability that a predicted ordering is ‘reason-
able’ (where ‘reasonable’ is defined as orderings
which are found in the test corpus).
</bodyText>
<footnote confidence="0.7357105">
3The same issue arises when evaluating candidate or-
derings; see Section 4.
</footnote>
<equation confidence="0.9557588">
c(w, k) = −
� AI
=1
� IC1
Z=1
</equation>
<page confidence="0.997467">
604
</page>
<table confidence="0.999868">
Token Accuracy Type Precision Type Recall Type F-measure
Mitchell N/A 90.3% (2.2) 67.2% (3.4) 77.1%
ML MSA 85.5% (1.0) 84.6% (1.1) 84.7% (1.1) 84.7%
Perceptron MSA 88.9% (0.7) 88.2% (0.8) 88.1% (0.8) 88.2%
</table>
<tableCaption confidence="0.986438">
Table 4: Results on the combined WSJ, Switchboard, and Brown corpus; averages and standard deviations
over a 10-fold cross validation. Winning scores are in bold.
</tableCaption>
<bodyText confidence="0.997853739130435">
Type Recall (|P n T|/|T|) measures the per-
centage of ‘reasonable’ orderings which the sys-
tem recreates.
Note that these two metrics differ only in no-
tation from those used by Mitchell (2009).
We also define a third metric, Token Accu-
racy, which measures accuracy on each individ-
ual ordering in the test corpus, rather than on
unique orderings. This penalizes producing or-
derings which are legal, but uncommon. For ex-
ample, if {a,b} occurs eight times in the test cor-
pus as &lt;a,b&gt; and two times as &lt;b,a&gt;, we will
be limited to a maximum accuracy of 80% (pre-
suming our system correctly predicts the more
common ordering). However, even though sug-
gesting &lt;b,a&gt; is not strictly incorrect, we gen-
erally prefer to reward a system that produces
more common orderings, an attribute not em-
phasized by type-based metrics. Our test cor-
pus does not contain many ambiguous pairings,
so our theoretical maximum token accuracy is
99.8%.
We define:
</bodyText>
<equation confidence="0.903625888888889">
o1..N = All modifier orderings in the
test data
pred(oz) = The predicted ordering for
modifiers in oz
�
1 if pred(oz) = oz�
az =
0 otherwise
Token Accuracy =
</equation>
<subsectionHeader confidence="0.987381">
4.1 Pairwise Ordering
</subsectionHeader>
<bodyText confidence="0.99985630952381">
Most earlier work has focused on ordering pairs
of modifiers. The results in Table 4 are di-
rectly comparable to those found in Mitchell
(2009). Mitchell’s earlier approach does not gen-
erate a prediction when the system has insuffi-
cient evidence, and allows generation of multiple
predictions given conflicting evidence. In the-
ory, generating multiple predictions could im-
prove recall, but in practice her system appears
biased toward under-predicting, favoring preci-
sion. Our approach, in contrast, forces predic-
tion of a single ordering for each test instance,
occasionally costing some precision (in particu-
lar in cross-domain trials; see Table 5), but con-
sistently balancing recall and precision.
Our measurement of Token Accuracy is com-
parable to the accuracy measure reported in
Shaw and Hatzivassiloglou (1999) and Malouf
(2000) (although we evaluate on a different cor-
pus). Their approaches produce a single order-
ing for each test instance evaluated, so for each
incorrectly ordered modifier pair, there is a cor-
responding modifier pair in the test data that
was not predicted.
Shaw and Hatzivassiloglou found financial
text particularly difficult to order, and reported
that their performance dropped by 19% when
they included nouns as well as adjectives. Mal-
ouf&apos;s system surpasses theirs, achieving an accu-
racy of 91.9%. However, his corpus was derived
from the BNC —he did not attempt to order fi-
nancial text — and he ordered only adjectives as
modifiers. In contrast, our test corpus consists
mainly of WSJ text, and we test on all forms
of prenominal modifiers. We believe this to be
a considerably more difficult task, so our peak
performance of 88.9% would appear to be—at
worst —quite competitive.
Table 5 presents an evaluation of cross-
domain generalization, splitting the same cor-
pus by genre—Brown, Switchboard, and WSJ.
In each trial, we train on two genres and test on
</bodyText>
<equation confidence="0.530581">
N
az
z=0 N
</equation>
<page confidence="0.989461">
605
</page>
<table confidence="0.999831636363636">
Training Testing Token Type Type Type
Corpora Corpus Accuracy Precision Recall F-measure
Brown+WSJ Swbd N/A 94.2% 58.2% 72.0%
Mitchell Swbd+WSJ Brown N/A 87.0% 51.2% 64.5%
Swbd+Brown WSJ N/A 82.4% 27.2% 40.9%
Brown+WSJ Swbd 74.6% 74.7% 75.3% 75.0%
ML MSA Swbd+WSJ Brown 75.3% 74.7% 74.9% 74.8%
Swbd+Brown WSJ 70.2% 71.6% 71.8% 71.7%
Brown+WSJ Swbd 77.2% 78.2% 77.6% 77.9%
Perceptron MSA Swbd+WSJ Brown 76.4% 76.7% 76.4% 76.5%
Swbd+Brown WSJ 77.9% 77.5% 77.3% 77.4%
</table>
<tableCaption confidence="0.990349">
Table 5: Cross-domain generalization.
</tableCaption>
<table confidence="0.99981025">
Token Accuracy Token Precision Token Recall Token F-measure
Mitchell N/A 94.4% 78.6% (1.2) 85.7%
ML MSA 76.9% (1.6) 76.5% (1.4) 76.5% (1.4) 76.50%
Perceptron MSA 86.7% (0.9) 86.7% (0.9) 86.7% (0.9) 86.7%
</table>
<tableCaption confidence="0.876550666666667">
Table 6: Full NP ordering accuracies; averages and standard deviations over a 10-fold cross validation. To
compare directly with Mitchell (2009), we report token precision and recall instead of type. Our system
always proposes one and only one ordering, so token accuracy, precision, and recall are identical.
</tableCaption>
<bodyText confidence="0.9999118">
the third.4 Our results mirror those in the previ-
ous trials —forcing a prediction costs some pre-
cision (vis-a-vis Mitchell’s 2009 system), but our
recall is dramatically higher, resulting in more
balanced performance overall.
</bodyText>
<subsectionHeader confidence="0.963875">
4.2 Full NP Ordering
</subsectionHeader>
<bodyText confidence="0.968178555555556">
We now extend our analysis to ordering en-
tire NPs, a task we feel the MSA approach
should be particularly suited to, since (unlike
pairwise models) it can model positional prob-
abilities over an entire NP. To our knowledge,
the only previously reported work on this task
is Mitchell’s (2009). We train this model on
the full NP instead of on modifier pairs; this
makes little difference in pairwise accuracy, but
improves full-NP ordering considerably.
As seen in Table 6, both MSA models perform
quite well, the perceptron-trained MSA again
outperforming the maximum likelihood model.
However, we were somewhat disappointed in the
performance on longer sequences. We expected
the MSA to encode enough global information
¢Note that the WSJ corpus is much larger than the
other two, comprising approximately 84% of the total.
</bodyText>
<table confidence="0.9990762">
Modifiers Frequency Token Pairwise
Accuracy Accuracy
2 89.1% 89.7% 89.7%
3 10.0% 64.5% 84.4%
4 0.9% 37.2% 80.7%
</table>
<tableCaption confidence="0.9833415">
Table 7: Descriminative model performance on NPs
of various lengths, including pairwise measures.
</tableCaption>
<bodyText confidence="0.99995925">
to perform accurate full sequence ordering, but
found the accuracy drops off dramatically on
NPs with more modifiers. In fact, the accu-
racy on longer sequences is worse than we would
expect by simply extending a pairwise model.
For instance, ordering three modifiers requires
three pairwise decisions. We predict pairwise
orderings with 88% accuracy, so we would ex-
pect no worse than (.88)3, or 68% accuracy on
such sequences. However, the pairwise accu-
racy declines on longer NPs, so it underperforms
even that theoretical minimum. Sparse training
data for longer NPs biases the model strongly
toward short sequences and transitivity (which
our model does not encode) may become impor-
tant when ordering several modifiers.
</bodyText>
<page confidence="0.998445">
606
</page>
<sectionHeader confidence="0.993188" genericHeader="method">
5 Ablation Tests
</sectionHeader>
<bodyText confidence="0.9996745">
We performed limited ablation testing on the
discriminative model, removing features individ-
ually and comparing token accuracy (see Table
8). We found that few of the features provided
great benefit individually; the overall system
performance remains dominated by the word.
The word and stem features appear to cap-
ture essentially the same information; note that
performance does not decline when the word
or stem features are ablated, but drops dras-
tically when both are omitted. Performance de-
clines slightly more when ending features are ab-
lated as well as words and stems, so it appears
that—as expected—the information captured
by ending features overlaps somewhat with lex-
ical identity. The effects of individual features
are all small and none are statistically signifi-
cant.
</bodyText>
<table confidence="0.9892445">
Feature(s) Gain/Loss
Word 0.0
Stem 0.0
Capitalization -0.1
All-Caps 0.0
Numeric -0.2
Initial-numeral 0.0
Length -0.1
Hyphen 0.0
-al 0.0
-ble -0.4
-ed -0.4
-er 0.0
-est -0.1
-ic +0.1
-ing 0.0
-ive -0.1
-ly 0.0
Word and stem -22.9
Word, stem, and endings -24.2
</table>
<tableCaption confidence="0.979694">
Table 8: Ablation test results on the discriminative
model.
</tableCaption>
<sectionHeader confidence="0.963416" genericHeader="evaluation">
6 Summary and Future Directions
</sectionHeader>
<bodyText confidence="0.999984818181818">
We adapted MSA approaches commonly used
in computational biology to linguistic problems
and presented two novel methods for training
such alignments. We applied these techniques
to the problem of ordering prenominal modi-
fiers in noun phrases, and achieved performance
competitive with—and in many cases, superior
to—the best results previously reported.
In our current work, we have focused on rel-
atively simple features, which should be adapt-
able to other languages without expensive re-
sources or much linguistic insight. We are inter-
ested in exploring richer sources of features for
ordering information. We found simple morpho-
logical features provided discriminative clues for
otherwise ambiguous instances, and believe that
richer morphological features might be helpful
even in a language as morphologically impover-
ished as English. Boleda et al. (2005) achieved
promising preliminary results using morphology
for classifying adjectives in Catalan.
Further, we might be able to capture some
of the semantic relationships noted by psycho-
logical analyses (Ziff, 1960; Martin, 1969) by
labeling words which belong to known seman-
tic classes (e.g., colors, size denominators, etc.).
We intend to explore deriving such labels from
resources such as WordNet or OntoNotes.
We also plan to continue exploration of MSA
training methods. We see considerable room
for refinement in generative MSA models; our
maximum likelihood training provides a strong
starting point for EM optimization, conditional
likelihood, or gradient descent methods. We are
also considering applying maximum entropy ap-
proaches to improving the discriminative model.
Finally (and perhaps most importantly), we
expect that our model would benefit from ad-
ditional training data, and plan to train on a
larger, automatically-parsed corpus.
Even in its current form, our approach im-
proves the state-of-the-art, and we believe MSA
techniques can be a useful tool for ordering
prenominal modifiers in NLP tasks.
</bodyText>
<sectionHeader confidence="0.998278" genericHeader="conclusions">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9998338">
This research was supported in part by NSF
Grant #IIS-0811745. Any opinions, findings,
conclusions or recommendations expressed in
this publication are those of the authors and do
not necessarily reflect the views of the NSF.
</bodyText>
<page confidence="0.997489">
607
</page>
<sectionHeader confidence="0.988889" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999878892857143">
Regina Barzilay and Lillian Lee. 2002. Bootstrap-
ping lexical choice via multiple-sequence align-
ment. In Proceedings of the ACL-02 conference on
Empirical methods in natural language processing
- Volume 10, pages 164–171, Philadelphia. Asso-
ciation for Computational Linguistics.
Regina Barzilay and Lillian Lee. 2003. Learning
to paraphrase: An unsupervised approach using
multiple-sequence alignment. In Proceedings of
the Human Language Technology Conference of
the North American Chapter of the Association for
Computational Linguistics (HLT-NAACL), vol-
ume 15, pages 201–31, Edmonton, Canada. As-
sociation for Computational Linguistics.
Gemma Boleda, Toni Badia, and Sabine Schulte
im Walde. 2005. Morphology vs. syntax in adjec-
tive class acquisition. In Proceedings of the ACL-
SIGLEX Workshop on Deep Lexical Acquisition,
pages 77–86, Ann Arbor, Michigan, June. Associ-
ation for Computational Linguistics.
Humberto Carrillo and David Lipman. 1988. The
multiple sequence alignment problem in biol-
ogy. SIAM Journal on Applied Mathematics,
48(5):1073–1082, October.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: theory and experi-
ments with perceptron algorithms. In Proceedings
of the ACL-02 conference on Empirical methods in
natural language processing, volume 10, pages 1–8,
Philadelphia, July. Association for Computational
Linguistics.
Richard Durbin, Sean R. Eddy, Anders Krogh, and
Graeme Mitchison. 1999. Biological Sequence
Analysis: Probabilistic Models of Proteins and Nu-
cleic Acids. Cambridge University Press, West
Nyack, NY, July.
John J. Godfrey, Edward C. Holliman, and Jane
McDaniel. 1992. SWITCHBOARD: telephone
speech corpus for research and development. In
Acoustics, Speech, and Signal Processing, IEEE
International Conference on, volume 1, pages 517–
520, Los Alamitos, CA, USA. IEEE Computer So-
ciety.
Dan Gusfield. 1997. Algorithms on Strings, Trees
and Sequences: Computer Science and Computa-
tional Biology. Cambridge University Press, West
Nyack, NY, May.
H. Kucera and W. N Francis. 1967. Computational
analysis of present-day American English. Brown
University Press, Providence, RI.
Robert Malouf. 2000. The order of prenominal ad-
jectives in natural language generation. In Pro-
ceedings of the 38th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 85–92,
Hong Kong, October. Association for Computa-
tional Linguistics.
Mitchell P Marcus, Beatrice Santorini, Mary Ann
Marcinkiewicz, and Ann Taylor. 1999. Treebank-
3. Linguistic Data Consortium, Philadelphia.
J. E. Martin. 1969. Semantic determinants of pre-
ferred adjective order. Journal of Verbal Learning
&amp; Verbal Behavior. Vol, 8(6):697–704.
Margaret Mitchell. 2009. Class-Based ordering of
prenominal modifiers. In Proceedings of the 12th
European Workshop on Natural Language Gener-
ation (ENLG 2009), pages 50–57, Athens, Greece,
March. Association for Computational Linguis-
tics.
M.F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130—137.
James Shaw and Vasileios Hatzivassiloglou. 1999.
Ordering among premodifiers. In Proceedings of
the 37th Annual Meeting of the Association for
Computational Linguistics, pages 135–143, Col-
lege Park, Maryland, USA, June. Association for
Computational Linguistics.
Christopher White, Izhak Shafran, and Jean luc
Gauvain. 2006. Discriminative classifiers for
language recognition. In Proceedings of the
2006 IEEE International Conference on Acous-
tics, Speech, and Signal Processing (ICASSP),
pages 213–216, Toulouse, France. IEEE.
Paul Ziff. 1960. Semantic Analysis. Cornell Univer-
sity Press, Ithaca, New York.
</reference>
<page confidence="0.997246">
608
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.925869">
<title confidence="0.998749">Prenominal Modifier Ordering via Multiple Sequence Alignment</title>
<author confidence="0.999946">Aaron Dunlop Margaret Mitchell Brian Roark</author>
<affiliation confidence="0.999997">Oregon Health &amp; Science University University of Aberdeen Oregon Health &amp; Science University</affiliation>
<address confidence="0.971133">Portland, OR Aberdeen, Scotland, U.K. Portland, OR</address>
<email confidence="0.997078">dunlopa@cslu.ogi.edum.mitchell@abdn.ac.ukroark@cslu.ogi.edu</email>
<abstract confidence="0.996554">Producing a fluent ordering for a set of prenominal modifiers in a noun phrase (NP) is a problematic task for natural language generation and machine translation systems. We present a novel approach to this issue, adapting multiple sequence alignment techniques used in computational biology to the alignment of modifiers. We describe two training techniques to create such alignments based on raw text, and demonstrate ordering accuracies superior to earlier reported approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Bootstrapping lexical choice via multiple-sequence alignment.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing - Volume</booktitle>
<volume>10</volume>
<pages>164--171</pages>
<institution>Philadelphia. Association for Computational Linguistics.</institution>
<contexts>
<context position="2946" citStr="Barzilay and Lee, 2002" startWordPosition="434" endWordPosition="437">a often improves the system without requiring significant manual labor. In this paper, we introduce a novel approach to prenominal modifier ordering adapted from multiple sequence alignment (MSA) techniques used in computational biology. MSA is generally applied to DNA, RNA, and protein sequences, aligning three or more biological sequences in order to determine, for example, common ancestry (Durbin et al., 1999; Gusfield, 1997; Carrillo and Lipman, 1988). MSA techniques have not been widely applied in NLP, but have produced some promising results for building a generation mapping dictionary (Barzilay and Lee, 2002), paraphrasing (Barzilay and Lee, 2003), and phone recognition (White et al., 2006). We believe that multiple sequence alignment is well-suited for aligning linguistic sequences, and that these alignments can be used to predict prenominal modifier ordering for any given set of modifiers. Our technique utilizes simple features within the raw text, and does not require any semantic information. We achieve good performance using this approach, with results competitive with earlier work (Shaw and Hatzivassiloglou, 1999; Malouf, 2000; Mitchell, 2009) and higher recall and F-measure than that report</context>
</contexts>
<marker>Barzilay, Lee, 2002</marker>
<rawString>Regina Barzilay and Lillian Lee. 2002. Bootstrapping lexical choice via multiple-sequence alignment. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing - Volume 10, pages 164–171, Philadelphia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Learning to paraphrase: An unsupervised approach using multiple-sequence alignment.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL),</booktitle>
<volume>15</volume>
<pages>201--31</pages>
<publisher>Association for</publisher>
<institution>Computational Linguistics.</institution>
<location>Edmonton, Canada.</location>
<contexts>
<context position="2985" citStr="Barzilay and Lee, 2003" startWordPosition="440" endWordPosition="443">uiring significant manual labor. In this paper, we introduce a novel approach to prenominal modifier ordering adapted from multiple sequence alignment (MSA) techniques used in computational biology. MSA is generally applied to DNA, RNA, and protein sequences, aligning three or more biological sequences in order to determine, for example, common ancestry (Durbin et al., 1999; Gusfield, 1997; Carrillo and Lipman, 1988). MSA techniques have not been widely applied in NLP, but have produced some promising results for building a generation mapping dictionary (Barzilay and Lee, 2002), paraphrasing (Barzilay and Lee, 2003), and phone recognition (White et al., 2006). We believe that multiple sequence alignment is well-suited for aligning linguistic sequences, and that these alignments can be used to predict prenominal modifier ordering for any given set of modifiers. Our technique utilizes simple features within the raw text, and does not require any semantic information. We achieve good performance using this approach, with results competitive with earlier work (Shaw and Hatzivassiloglou, 1999; Malouf, 2000; Mitchell, 2009) and higher recall and F-measure than that reported in Mitchell (2009) when tested on th</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Regina Barzilay and Lillian Lee. 2003. Learning to paraphrase: An unsupervised approach using multiple-sequence alignment. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL), volume 15, pages 201–31, Edmonton, Canada. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gemma Boleda</author>
<author>Toni Badia</author>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Morphology vs. syntax in adjective class acquisition.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACLSIGLEX Workshop on Deep Lexical Acquisition,</booktitle>
<pages>77--86</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="26683" citStr="Boleda et al. (2005)" startWordPosition="4338" endWordPosition="4341">ses, and achieved performance competitive with—and in many cases, superior to—the best results previously reported. In our current work, we have focused on relatively simple features, which should be adaptable to other languages without expensive resources or much linguistic insight. We are interested in exploring richer sources of features for ordering information. We found simple morphological features provided discriminative clues for otherwise ambiguous instances, and believe that richer morphological features might be helpful even in a language as morphologically impoverished as English. Boleda et al. (2005) achieved promising preliminary results using morphology for classifying adjectives in Catalan. Further, we might be able to capture some of the semantic relationships noted by psychological analyses (Ziff, 1960; Martin, 1969) by labeling words which belong to known semantic classes (e.g., colors, size denominators, etc.). We intend to explore deriving such labels from resources such as WordNet or OntoNotes. We also plan to continue exploration of MSA training methods. We see considerable room for refinement in generative MSA models; our maximum likelihood training provides a strong starting p</context>
</contexts>
<marker>Boleda, Badia, Walde, 2005</marker>
<rawString>Gemma Boleda, Toni Badia, and Sabine Schulte im Walde. 2005. Morphology vs. syntax in adjective class acquisition. In Proceedings of the ACLSIGLEX Workshop on Deep Lexical Acquisition, pages 77–86, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Humberto Carrillo</author>
<author>David Lipman</author>
</authors>
<title>The multiple sequence alignment problem in biology.</title>
<date>1988</date>
<journal>SIAM Journal on Applied Mathematics,</journal>
<volume>48</volume>
<issue>5</issue>
<contexts>
<context position="2782" citStr="Carrillo and Lipman, 1988" startWordPosition="408" endWordPosition="411">ring that they are therefore reasonably natural. (2) Many (if not all) prenominal modifiers can be ordered. (3) Expanding the training data with more and larger corpora often improves the system without requiring significant manual labor. In this paper, we introduce a novel approach to prenominal modifier ordering adapted from multiple sequence alignment (MSA) techniques used in computational biology. MSA is generally applied to DNA, RNA, and protein sequences, aligning three or more biological sequences in order to determine, for example, common ancestry (Durbin et al., 1999; Gusfield, 1997; Carrillo and Lipman, 1988). MSA techniques have not been widely applied in NLP, but have produced some promising results for building a generation mapping dictionary (Barzilay and Lee, 2002), paraphrasing (Barzilay and Lee, 2003), and phone recognition (White et al., 2006). We believe that multiple sequence alignment is well-suited for aligning linguistic sequences, and that these alignments can be used to predict prenominal modifier ordering for any given set of modifiers. Our technique utilizes simple features within the raw text, and does not require any semantic information. We achieve good performance using this a</context>
</contexts>
<marker>Carrillo, Lipman, 1988</marker>
<rawString>Humberto Carrillo and David Lipman. 1988. The multiple sequence alignment problem in biology. SIAM Journal on Applied Mathematics, 48(5):1073–1082, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing,</booktitle>
<volume>10</volume>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Philadelphia,</location>
<contexts>
<context position="16488" citStr="Collins, 2002" startWordPosition="2692" endWordPosition="2693">es into classes or the independence assumption discussed in Section 3.2. We again produced a cost vector for each column. We fixed the alignment length at 8 columns, allowing alignment of the longest instances in our test corpus. Our training data consists of ordered sequences, but the model we are attempting to learn is a set of column probabilities. Since we have no gold-standard MSAs, we instead align the ordered NPs with the current model and treat the least cost alignment of the correct ordering as the reference for training. We trained this model using the averaged perceptron algorithm (Collins, 2002). A perceptron learns from classifier errors, i.e., when it misorders an NP. At each training instance, we align all possible permutations of the modifiers with the MSA. If the least cost alignment does not correspond to the correct ordering of the modifiers, we update the perceptron to penalize features occurring in that alignment and to reward features occurring in the least cost alignment corresponding to the correct ordering, using standard perceptron updates. Examining every permutation of the NP involves a non-polynomial cost, but the sequences under consideration are quite short (less t</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing, volume 10, pages 1–8, Philadelphia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Durbin</author>
<author>Sean R Eddy</author>
<author>Anders Krogh</author>
<author>Graeme Mitchison</author>
</authors>
<title>Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids.</title>
<date>1999</date>
<publisher>Cambridge University Press,</publisher>
<location>West Nyack, NY,</location>
<contexts>
<context position="2738" citStr="Durbin et al., 1999" startWordPosition="402" endWordPosition="405">vidence from ‘real-world’ texts, ensuring that they are therefore reasonably natural. (2) Many (if not all) prenominal modifiers can be ordered. (3) Expanding the training data with more and larger corpora often improves the system without requiring significant manual labor. In this paper, we introduce a novel approach to prenominal modifier ordering adapted from multiple sequence alignment (MSA) techniques used in computational biology. MSA is generally applied to DNA, RNA, and protein sequences, aligning three or more biological sequences in order to determine, for example, common ancestry (Durbin et al., 1999; Gusfield, 1997; Carrillo and Lipman, 1988). MSA techniques have not been widely applied in NLP, but have produced some promising results for building a generation mapping dictionary (Barzilay and Lee, 2002), paraphrasing (Barzilay and Lee, 2003), and phone recognition (White et al., 2006). We believe that multiple sequence alignment is well-suited for aligning linguistic sequences, and that these alignments can be used to predict prenominal modifier ordering for any given set of modifiers. Our technique utilizes simple features within the raw text, and does not require any semantic informati</context>
<context position="9991" citStr="Durbin et al. (1999)" startWordPosition="1562" endWordPosition="1565">r each column. An unseen sequence can then be aligned with the full MSA by Viterbi search. Predicting sequence ordering within a noun phrase is a natural application for MSA techniques, and it seems reasonable to propose that aligning an unseen set of modifiers with such an MSA model will yield acceptable orderings. Table 2 illustrates how MSA may be applied to modifiers before a noun. Given an NP preceded by modifiers hungry, big, and Grizzly, alignment of the modifiers with NPs seen in the training corpus determines the prenominal ordering big hungry Grizzly. We then align every permuta1See Durbin et al. (1999) for details on standard alignment techniques. G A C T G - A T - A G T G T A T 1 2 3 4 5 6 7 8 Table 1: Alignment of the two DNA sequences `GAACTGAT&apos; and `AAGTGTAT&apos;. small clumsy black bear big - black cow two-story - brown house big clumsy - bull small fuzzy brown duck large - green house big hungry Grizzly bear Table 2: Example noun-phrase alignment. tion of the NP and choose the best-scoring alignment. The vocabulary for a linguistic alignment is large enough to render a hand-tuned substitution matrix impractical, so we instead construct a cost function based on features of the token under </context>
<context position="13088" citStr="Durbin et al., 1999" startWordPosition="2087" endWordPosition="2090">ive, using a matrix of substitution costs or simple token identity (equivalent to a matrix with cost 0 on the diagonal and 1 everywhere else). These matrices are constructed and tuned by domain experts, and are used both in choosing alignment order (i.e., which sequence to align next) and during the actual alignment. When aligning biological sequences, it is customary to first calculate the pairwise distance between each two sequences and then introduce new sequences into the MSA in order of similarity. In this way, identical sequences may be aligned first, followed by less similar sequences (Durbin et al., 1999). However, we have no principled method of determining the ‘similarity’ of two words in an NP. We have no a priori notion of what the cost of substituting ‘two-story’ for `red&apos; should be. Lacking this prior knowledge, we have no optimal alignment order and we must in effect learn the substitution costs as we construct the MSA. Therefore, we choose to add instances in the order they occur in the corpus, and to iterate over the entire MSA, re-introducing each sequence. 2 W treat two special symbols for gaps and unknown words as members of the word class. This allows a word to ‘move’ from its ori</context>
</contexts>
<marker>Durbin, Eddy, Krogh, Mitchison, 1999</marker>
<rawString>Richard Durbin, Sean R. Eddy, Anders Krogh, and Graeme Mitchison. 1999. Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids. Cambridge University Press, West Nyack, NY, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John J Godfrey</author>
<author>Edward C Holliman</author>
<author>Jane McDaniel</author>
</authors>
<title>SWITCHBOARD: telephone speech corpus for research and development.</title>
<date>1992</date>
<booktitle>In Acoustics, Speech, and Signal Processing, IEEE International Conference on,</booktitle>
<volume>1</volume>
<pages>517--520</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Los Alamitos, CA, USA.</location>
<contexts>
<context position="17625" citStr="Godfrey et al., 1992" startWordPosition="2879" endWordPosition="2882">a non-polynomial cost, but the sequences under consideration are quite short (less than 1% of the NPs in our corpus have more than 3 modifiers, and the longest has 6; see Table 7). So exhaustive search is practical for our problem; if we were to apply MSA to longer sequences, we would need to prune heavily.3 4 Evaluation We trained and tested on the same corpus used by Mitchell (2009), including identical 10-fold cross-validation splits. The corpus consists of all NPs extracted from the Penn Treebank, the Brown corpus, and the Switchboard corpus (Marcus et al., 1999; Kucera and Francis, 1967; Godfrey et al., 1992). The corpus is heavily biased toward WSJ text (74%), with approximately 13% of the NPs from each of the other corpora. We evaluated our system using several related but distinct metrics, and on both modifier pairs and full NPs. We define: T = The set of unique orderings found in the test corpus P = The set of unique orderings predicted by the system Type Precision (|P n T|/|P|) measures the probability that a predicted ordering is ‘reasonable’ (where ‘reasonable’ is defined as orderings which are found in the test corpus). 3The same issue arises when evaluating candidate orderings; see Sectio</context>
</contexts>
<marker>Godfrey, Holliman, McDaniel, 1992</marker>
<rawString>John J. Godfrey, Edward C. Holliman, and Jane McDaniel. 1992. SWITCHBOARD: telephone speech corpus for research and development. In Acoustics, Speech, and Signal Processing, IEEE International Conference on, volume 1, pages 517– 520, Los Alamitos, CA, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Gusfield</author>
</authors>
<title>Algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology.</title>
<date>1997</date>
<publisher>Cambridge University Press,</publisher>
<location>West Nyack, NY,</location>
<contexts>
<context position="2754" citStr="Gusfield, 1997" startWordPosition="406" endWordPosition="407">rld’ texts, ensuring that they are therefore reasonably natural. (2) Many (if not all) prenominal modifiers can be ordered. (3) Expanding the training data with more and larger corpora often improves the system without requiring significant manual labor. In this paper, we introduce a novel approach to prenominal modifier ordering adapted from multiple sequence alignment (MSA) techniques used in computational biology. MSA is generally applied to DNA, RNA, and protein sequences, aligning three or more biological sequences in order to determine, for example, common ancestry (Durbin et al., 1999; Gusfield, 1997; Carrillo and Lipman, 1988). MSA techniques have not been widely applied in NLP, but have produced some promising results for building a generation mapping dictionary (Barzilay and Lee, 2002), paraphrasing (Barzilay and Lee, 2003), and phone recognition (White et al., 2006). We believe that multiple sequence alignment is well-suited for aligning linguistic sequences, and that these alignments can be used to predict prenominal modifier ordering for any given set of modifiers. Our technique utilizes simple features within the raw text, and does not require any semantic information. We achieve g</context>
</contexts>
<marker>Gusfield, 1997</marker>
<rawString>Dan Gusfield. 1997. Algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology. Cambridge University Press, West Nyack, NY, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kucera</author>
<author>W N Francis</author>
</authors>
<title>Computational analysis of present-day American English.</title>
<date>1967</date>
<publisher>Brown University Press,</publisher>
<location>Providence, RI.</location>
<contexts>
<context position="17602" citStr="Kucera and Francis, 1967" startWordPosition="2875" endWordPosition="2878">tation of the NP involves a non-polynomial cost, but the sequences under consideration are quite short (less than 1% of the NPs in our corpus have more than 3 modifiers, and the longest has 6; see Table 7). So exhaustive search is practical for our problem; if we were to apply MSA to longer sequences, we would need to prune heavily.3 4 Evaluation We trained and tested on the same corpus used by Mitchell (2009), including identical 10-fold cross-validation splits. The corpus consists of all NPs extracted from the Penn Treebank, the Brown corpus, and the Switchboard corpus (Marcus et al., 1999; Kucera and Francis, 1967; Godfrey et al., 1992). The corpus is heavily biased toward WSJ text (74%), with approximately 13% of the NPs from each of the other corpora. We evaluated our system using several related but distinct metrics, and on both modifier pairs and full NPs. We define: T = The set of unique orderings found in the test corpus P = The set of unique orderings predicted by the system Type Precision (|P n T|/|P|) measures the probability that a predicted ordering is ‘reasonable’ (where ‘reasonable’ is defined as orderings which are found in the test corpus). 3The same issue arises when evaluating candidat</context>
</contexts>
<marker>Kucera, Francis, 1967</marker>
<rawString>H. Kucera and W. N Francis. 1967. Computational analysis of present-day American English. Brown University Press, Providence, RI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Malouf</author>
</authors>
<title>The order of prenominal adjectives in natural language generation.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>85--92</pages>
<institution>Hong Kong, October. Association for Computational Linguistics.</institution>
<contexts>
<context position="3480" citStr="Malouf, 2000" startWordPosition="518" endWordPosition="519"> results for building a generation mapping dictionary (Barzilay and Lee, 2002), paraphrasing (Barzilay and Lee, 2003), and phone recognition (White et al., 2006). We believe that multiple sequence alignment is well-suited for aligning linguistic sequences, and that these alignments can be used to predict prenominal modifier ordering for any given set of modifiers. Our technique utilizes simple features within the raw text, and does not require any semantic information. We achieve good performance using this approach, with results competitive with earlier work (Shaw and Hatzivassiloglou, 1999; Malouf, 2000; Mitchell, 2009) and higher recall and F-measure than that reported in Mitchell (2009) when tested on the same corpus. 600 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 600–608, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics 2 Related work In one of the first attempts at automatically ordering prenominal modifiers, Shaw and Hatzivassiloglou (1999) present three empirical methods to order a variety of prenominal modifier types. Their approach provides ordering decisions for adjectives, gerunds (such</context>
<context position="6591" citStr="Malouf (2000)" startWordPosition="1015" endWordPosition="1016">nancial text (the Wall Street Journal (WSJ) corpus (Marcus et al., 1999)) than on medical discharge summaries. Looking at all modifier pairs, the authors achieve their highest prediction accuracy of 90.7% using the transitivity technique on a medical corpus. We do not have access to this corpus, but we do have access to the WSJ corpus, which provides a way to compare our methods. On this corpus, their model produces predictions for 62.5% of all modifier pairs and achieves 83.6% accuracy when it is able to make a prediction. Random guessing on the remainder yields an overall accuracy of 71.0%. Malouf (2000) also examines the problem of prenominal modifier ordering. He too proposes several statistical techniques, achieving results ranging from 78.3% to 91.9% accuracy. He achieves his best results by combining memorybased learning and positional probability to modifiers from the first 100 million tokens of the BNC. However, this evaluation is limited to the ordering of prenominal adjectives, which is a considerably simpler task than ordering all types of prenominal modifiers. Malouf&apos;s approaches are also limited to ordering pairs of modifiers. Mitchell (2009) proposes another approach, grouping mo</context>
<context position="20579" citStr="Malouf (2000)" startWordPosition="3377" endWordPosition="3378">s insufficient evidence, and allows generation of multiple predictions given conflicting evidence. In theory, generating multiple predictions could improve recall, but in practice her system appears biased toward under-predicting, favoring precision. Our approach, in contrast, forces prediction of a single ordering for each test instance, occasionally costing some precision (in particular in cross-domain trials; see Table 5), but consistently balancing recall and precision. Our measurement of Token Accuracy is comparable to the accuracy measure reported in Shaw and Hatzivassiloglou (1999) and Malouf (2000) (although we evaluate on a different corpus). Their approaches produce a single ordering for each test instance evaluated, so for each incorrectly ordered modifier pair, there is a corresponding modifier pair in the test data that was not predicted. Shaw and Hatzivassiloglou found financial text particularly difficult to order, and reported that their performance dropped by 19% when they included nouns as well as adjectives. Malouf&apos;s system surpasses theirs, achieving an accuracy of 91.9%. However, his corpus was derived from the BNC —he did not attempt to order financial text — and he ordere</context>
</contexts>
<marker>Malouf, 2000</marker>
<rawString>Robert Malouf. 2000. The order of prenominal adjectives in natural language generation. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 85–92, Hong Kong, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Ann Taylor</author>
</authors>
<date>1999</date>
<booktitle>Treebank3. Linguistic Data Consortium,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="6050" citStr="Marcus et al., 1999" startWordPosition="918" endWordPosition="921">ed together, and ordering decisions can be made between modifiers in separate clusters. All three approaches are designed to order pairs of modifiers; it is unclear how to extend these approaches to order groups larger than a pair. Shaw and Hatzivassiloglou find that NPs with only adjectives as modifiers (including gerunds and past participles) are considerably easier to order than those which contain both adjectives and nouns. They also find large differences in accuracy across domains; their systems achieve much lower overall accuracy on financial text (the Wall Street Journal (WSJ) corpus (Marcus et al., 1999)) than on medical discharge summaries. Looking at all modifier pairs, the authors achieve their highest prediction accuracy of 90.7% using the transitivity technique on a medical corpus. We do not have access to this corpus, but we do have access to the WSJ corpus, which provides a way to compare our methods. On this corpus, their model produces predictions for 62.5% of all modifier pairs and achieves 83.6% accuracy when it is able to make a prediction. Random guessing on the remainder yields an overall accuracy of 71.0%. Malouf (2000) also examines the problem of prenominal modifier ordering.</context>
<context position="17576" citStr="Marcus et al., 1999" startWordPosition="2871" endWordPosition="2874">Examining every permutation of the NP involves a non-polynomial cost, but the sequences under consideration are quite short (less than 1% of the NPs in our corpus have more than 3 modifiers, and the longest has 6; see Table 7). So exhaustive search is practical for our problem; if we were to apply MSA to longer sequences, we would need to prune heavily.3 4 Evaluation We trained and tested on the same corpus used by Mitchell (2009), including identical 10-fold cross-validation splits. The corpus consists of all NPs extracted from the Penn Treebank, the Brown corpus, and the Switchboard corpus (Marcus et al., 1999; Kucera and Francis, 1967; Godfrey et al., 1992). The corpus is heavily biased toward WSJ text (74%), with approximately 13% of the NPs from each of the other corpora. We evaluated our system using several related but distinct metrics, and on both modifier pairs and full NPs. We define: T = The set of unique orderings found in the test corpus P = The set of unique orderings predicted by the system Type Precision (|P n T|/|P|) measures the probability that a predicted ordering is ‘reasonable’ (where ‘reasonable’ is defined as orderings which are found in the test corpus). 3The same issue arise</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, Taylor, 1999</marker>
<rawString>Mitchell P Marcus, Beatrice Santorini, Mary Ann Marcinkiewicz, and Ann Taylor. 1999. Treebank3. Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Martin</author>
</authors>
<title>Semantic determinants of preferred adjective order.</title>
<date>1969</date>
<journal>Journal of Verbal Learning &amp; Verbal Behavior. Vol,</journal>
<volume>8</volume>
<issue>6</issue>
<contexts>
<context position="26909" citStr="Martin, 1969" startWordPosition="4372" endWordPosition="4373">out expensive resources or much linguistic insight. We are interested in exploring richer sources of features for ordering information. We found simple morphological features provided discriminative clues for otherwise ambiguous instances, and believe that richer morphological features might be helpful even in a language as morphologically impoverished as English. Boleda et al. (2005) achieved promising preliminary results using morphology for classifying adjectives in Catalan. Further, we might be able to capture some of the semantic relationships noted by psychological analyses (Ziff, 1960; Martin, 1969) by labeling words which belong to known semantic classes (e.g., colors, size denominators, etc.). We intend to explore deriving such labels from resources such as WordNet or OntoNotes. We also plan to continue exploration of MSA training methods. We see considerable room for refinement in generative MSA models; our maximum likelihood training provides a strong starting point for EM optimization, conditional likelihood, or gradient descent methods. We are also considering applying maximum entropy approaches to improving the discriminative model. Finally (and perhaps most importantly), we expec</context>
</contexts>
<marker>Martin, 1969</marker>
<rawString>J. E. Martin. 1969. Semantic determinants of preferred adjective order. Journal of Verbal Learning &amp; Verbal Behavior. Vol, 8(6):697–704.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret Mitchell</author>
</authors>
<title>Class-Based ordering of prenominal modifiers.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th European Workshop on Natural Language Generation (ENLG</booktitle>
<pages>50--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece,</location>
<contexts>
<context position="3497" citStr="Mitchell, 2009" startWordPosition="520" endWordPosition="521">uilding a generation mapping dictionary (Barzilay and Lee, 2002), paraphrasing (Barzilay and Lee, 2003), and phone recognition (White et al., 2006). We believe that multiple sequence alignment is well-suited for aligning linguistic sequences, and that these alignments can be used to predict prenominal modifier ordering for any given set of modifiers. Our technique utilizes simple features within the raw text, and does not require any semantic information. We achieve good performance using this approach, with results competitive with earlier work (Shaw and Hatzivassiloglou, 1999; Malouf, 2000; Mitchell, 2009) and higher recall and F-measure than that reported in Mitchell (2009) when tested on the same corpus. 600 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 600–608, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics 2 Related work In one of the first attempts at automatically ordering prenominal modifiers, Shaw and Hatzivassiloglou (1999) present three empirical methods to order a variety of prenominal modifier types. Their approach provides ordering decisions for adjectives, gerunds (such as “running” in </context>
<context position="7152" citStr="Mitchell (2009)" startWordPosition="1097" endWordPosition="1098">der yields an overall accuracy of 71.0%. Malouf (2000) also examines the problem of prenominal modifier ordering. He too proposes several statistical techniques, achieving results ranging from 78.3% to 91.9% accuracy. He achieves his best results by combining memorybased learning and positional probability to modifiers from the first 100 million tokens of the BNC. However, this evaluation is limited to the ordering of prenominal adjectives, which is a considerably simpler task than ordering all types of prenominal modifiers. Malouf&apos;s approaches are also limited to ordering pairs of modifiers. Mitchell (2009) proposes another approach, grouping modifiers into classes and ordering based on those classes. A modifier&apos;s class is assigned based on its placement before a noun, relative to the other modifiers it appears with. Classes are composed of those modifiers that tend to be placed closer to the head noun, those modifiers that tend to be placed farther from the head noun, etc., with each class corresponding to a general positional preference. Unlike earlier work, these classes allow more than one ordering to be proposed for some pairs of modifiers. Combining corpora of various genres, Mitchell’s sy</context>
<context position="17391" citStr="Mitchell (2009)" startWordPosition="2846" endWordPosition="2847">penalize features occurring in that alignment and to reward features occurring in the least cost alignment corresponding to the correct ordering, using standard perceptron updates. Examining every permutation of the NP involves a non-polynomial cost, but the sequences under consideration are quite short (less than 1% of the NPs in our corpus have more than 3 modifiers, and the longest has 6; see Table 7). So exhaustive search is practical for our problem; if we were to apply MSA to longer sequences, we would need to prune heavily.3 4 Evaluation We trained and tested on the same corpus used by Mitchell (2009), including identical 10-fold cross-validation splits. The corpus consists of all NPs extracted from the Penn Treebank, the Brown corpus, and the Switchboard corpus (Marcus et al., 1999; Kucera and Francis, 1967; Godfrey et al., 1992). The corpus is heavily biased toward WSJ text (74%), with approximately 13% of the NPs from each of the other corpora. We evaluated our system using several related but distinct metrics, and on both modifier pairs and full NPs. We define: T = The set of unique orderings found in the test corpus P = The set of unique orderings predicted by the system Type Precisio</context>
<context position="18823" citStr="Mitchell (2009)" startWordPosition="3088" endWordPosition="3089">rings; see Section 4. c(w, k) = − � AI =1 � IC1 Z=1 604 Token Accuracy Type Precision Type Recall Type F-measure Mitchell N/A 90.3% (2.2) 67.2% (3.4) 77.1% ML MSA 85.5% (1.0) 84.6% (1.1) 84.7% (1.1) 84.7% Perceptron MSA 88.9% (0.7) 88.2% (0.8) 88.1% (0.8) 88.2% Table 4: Results on the combined WSJ, Switchboard, and Brown corpus; averages and standard deviations over a 10-fold cross validation. Winning scores are in bold. Type Recall (|P n T|/|T|) measures the percentage of ‘reasonable’ orderings which the system recreates. Note that these two metrics differ only in notation from those used by Mitchell (2009). We also define a third metric, Token Accuracy, which measures accuracy on each individual ordering in the test corpus, rather than on unique orderings. This penalizes producing orderings which are legal, but uncommon. For example, if {a,b} occurs eight times in the test corpus as &lt;a,b&gt; and two times as &lt;b,a&gt;, we will be limited to a maximum accuracy of 80% (presuming our system correctly predicts the more common ordering). However, even though suggesting &lt;b,a&gt; is not strictly incorrect, we generally prefer to reward a system that produces more common orderings, an attribute not emphasized by</context>
<context position="22500" citStr="Mitchell (2009)" startWordPosition="3686" endWordPosition="3687">75.3% 75.0% ML MSA Swbd+WSJ Brown 75.3% 74.7% 74.9% 74.8% Swbd+Brown WSJ 70.2% 71.6% 71.8% 71.7% Brown+WSJ Swbd 77.2% 78.2% 77.6% 77.9% Perceptron MSA Swbd+WSJ Brown 76.4% 76.7% 76.4% 76.5% Swbd+Brown WSJ 77.9% 77.5% 77.3% 77.4% Table 5: Cross-domain generalization. Token Accuracy Token Precision Token Recall Token F-measure Mitchell N/A 94.4% 78.6% (1.2) 85.7% ML MSA 76.9% (1.6) 76.5% (1.4) 76.5% (1.4) 76.50% Perceptron MSA 86.7% (0.9) 86.7% (0.9) 86.7% (0.9) 86.7% Table 6: Full NP ordering accuracies; averages and standard deviations over a 10-fold cross validation. To compare directly with Mitchell (2009), we report token precision and recall instead of type. Our system always proposes one and only one ordering, so token accuracy, precision, and recall are identical. the third.4 Our results mirror those in the previous trials —forcing a prediction costs some precision (vis-a-vis Mitchell’s 2009 system), but our recall is dramatically higher, resulting in more balanced performance overall. 4.2 Full NP Ordering We now extend our analysis to ordering entire NPs, a task we feel the MSA approach should be particularly suited to, since (unlike pairwise models) it can model positional probabilities o</context>
</contexts>
<marker>Mitchell, 2009</marker>
<rawString>Margaret Mitchell. 2009. Class-Based ordering of prenominal modifiers. In Proceedings of the 12th European Workshop on Natural Language Generation (ENLG 2009), pages 50–57, Athens, Greece, March. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="11178" citStr="Porter, 1980" startWordPosition="1779" endWordPosition="1780">atures of the token under consideration and those of the other tokens already aligned in a column. We know of no prior work on methods for training such an alignment. We present and compare two training methods, each of which produces competitive ordering accuracies. Both training methods share the feature-set described in Table 3. In each case, we train an MSA by aligning each instance in the training data. 3.2 Maximum Likelihood Training In our alignment approach, the features listed in Table 3 are grouped into several classes. All observed words are a class, all observed stems are a class (Porter, 1980), and so on. We treat each indicator feature as a separate class, and make the assumption that classes are independent of one another. This assumption is clearly false, but serves as a reasonable first approximation, similar to the independence assumption in Naive Bayesian analysis. After aligning each instance, we estimate the probability of a feature appearing in a column as the simple maximum likelihood estimate given the observed occurrences 602 Identity Features Word Token Stem Word stem, derived by the Porter Stemmer Length ‘Binned’ length indicators: 1, 2, 3, 4, 5-6, 7-8, 9-12, 13-18, &gt;</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>M.F. Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130—137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shaw</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Ordering among premodifiers.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>135--143</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>College Park, Maryland, USA,</location>
<contexts>
<context position="3466" citStr="Shaw and Hatzivassiloglou, 1999" startWordPosition="513" endWordPosition="517"> but have produced some promising results for building a generation mapping dictionary (Barzilay and Lee, 2002), paraphrasing (Barzilay and Lee, 2003), and phone recognition (White et al., 2006). We believe that multiple sequence alignment is well-suited for aligning linguistic sequences, and that these alignments can be used to predict prenominal modifier ordering for any given set of modifiers. Our technique utilizes simple features within the raw text, and does not require any semantic information. We achieve good performance using this approach, with results competitive with earlier work (Shaw and Hatzivassiloglou, 1999; Malouf, 2000; Mitchell, 2009) and higher recall and F-measure than that reported in Mitchell (2009) when tested on the same corpus. 600 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 600–608, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics 2 Related work In one of the first attempts at automatically ordering prenominal modifiers, Shaw and Hatzivassiloglou (1999) present three empirical methods to order a variety of prenominal modifier types. Their approach provides ordering decisions for adjectives,</context>
<context position="20561" citStr="Shaw and Hatzivassiloglou (1999)" startWordPosition="3372" endWordPosition="3375">erate a prediction when the system has insufficient evidence, and allows generation of multiple predictions given conflicting evidence. In theory, generating multiple predictions could improve recall, but in practice her system appears biased toward under-predicting, favoring precision. Our approach, in contrast, forces prediction of a single ordering for each test instance, occasionally costing some precision (in particular in cross-domain trials; see Table 5), but consistently balancing recall and precision. Our measurement of Token Accuracy is comparable to the accuracy measure reported in Shaw and Hatzivassiloglou (1999) and Malouf (2000) (although we evaluate on a different corpus). Their approaches produce a single ordering for each test instance evaluated, so for each incorrectly ordered modifier pair, there is a corresponding modifier pair in the test data that was not predicted. Shaw and Hatzivassiloglou found financial text particularly difficult to order, and reported that their performance dropped by 19% when they included nouns as well as adjectives. Malouf&apos;s system surpasses theirs, achieving an accuracy of 91.9%. However, his corpus was derived from the BNC —he did not attempt to order financial te</context>
</contexts>
<marker>Shaw, Hatzivassiloglou, 1999</marker>
<rawString>James Shaw and Vasileios Hatzivassiloglou. 1999. Ordering among premodifiers. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 135–143, College Park, Maryland, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher White</author>
<author>Izhak Shafran</author>
<author>Jean luc Gauvain</author>
</authors>
<title>Discriminative classifiers for language recognition.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<pages>213--216</pages>
<publisher>IEEE.</publisher>
<location>Toulouse, France.</location>
<contexts>
<context position="3029" citStr="White et al., 2006" startWordPosition="447" endWordPosition="450">we introduce a novel approach to prenominal modifier ordering adapted from multiple sequence alignment (MSA) techniques used in computational biology. MSA is generally applied to DNA, RNA, and protein sequences, aligning three or more biological sequences in order to determine, for example, common ancestry (Durbin et al., 1999; Gusfield, 1997; Carrillo and Lipman, 1988). MSA techniques have not been widely applied in NLP, but have produced some promising results for building a generation mapping dictionary (Barzilay and Lee, 2002), paraphrasing (Barzilay and Lee, 2003), and phone recognition (White et al., 2006). We believe that multiple sequence alignment is well-suited for aligning linguistic sequences, and that these alignments can be used to predict prenominal modifier ordering for any given set of modifiers. Our technique utilizes simple features within the raw text, and does not require any semantic information. We achieve good performance using this approach, with results competitive with earlier work (Shaw and Hatzivassiloglou, 1999; Malouf, 2000; Mitchell, 2009) and higher recall and F-measure than that reported in Mitchell (2009) when tested on the same corpus. 600 Human Language Technologi</context>
</contexts>
<marker>White, Shafran, Gauvain, 2006</marker>
<rawString>Christopher White, Izhak Shafran, and Jean luc Gauvain. 2006. Discriminative classifiers for language recognition. In Proceedings of the 2006 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pages 213–216, Toulouse, France. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ziff</author>
</authors>
<title>Semantic Analysis.</title>
<date>1960</date>
<publisher>Cornell University Press,</publisher>
<location>Ithaca, New York.</location>
<contexts>
<context position="26894" citStr="Ziff, 1960" startWordPosition="4370" endWordPosition="4371">nguages without expensive resources or much linguistic insight. We are interested in exploring richer sources of features for ordering information. We found simple morphological features provided discriminative clues for otherwise ambiguous instances, and believe that richer morphological features might be helpful even in a language as morphologically impoverished as English. Boleda et al. (2005) achieved promising preliminary results using morphology for classifying adjectives in Catalan. Further, we might be able to capture some of the semantic relationships noted by psychological analyses (Ziff, 1960; Martin, 1969) by labeling words which belong to known semantic classes (e.g., colors, size denominators, etc.). We intend to explore deriving such labels from resources such as WordNet or OntoNotes. We also plan to continue exploration of MSA training methods. We see considerable room for refinement in generative MSA models; our maximum likelihood training provides a strong starting point for EM optimization, conditional likelihood, or gradient descent methods. We are also considering applying maximum entropy approaches to improving the discriminative model. Finally (and perhaps most importa</context>
</contexts>
<marker>Ziff, 1960</marker>
<rawString>Paul Ziff. 1960. Semantic Analysis. Cornell University Press, Ithaca, New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>