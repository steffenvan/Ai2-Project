<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.935561">
Toward Natural Language Computation 1
</title>
<author confidence="0.6463145">
Alan W. Biermann
Bruce W. Ballard2
</author>
<affiliation confidence="0.9367115">
Department of Computer Science
Duke University
</affiliation>
<address confidence="0.486836">
Durham, North Carolina 27706
</address>
<bodyText confidence="0.948416166666667">
A computer programming system called the &amp;quot;Natural Language Computer&amp;quot; (NLC) is
described which allows a user to type English commands while watching them executed on
sample data appearing on a display screen. Direct visual feedback enables the user to
detect most misinterpretation errors as they are made so that incorrect or ambiguous
commands can be retyped or clarified immediately. A sequence of correctly executed
commands may be given a name and used as a subroutine, thus extending the set of
available operations and allowing larger English-language programs to be constructed
hierarchically. In addition to discussing the transition network syntax and procedural
semantics of the system, special attention is devoted to the following topics: the nature of
imperative sentences in the matrix domain; the processing of non-trivial noun phrases;
conjunction; pronominals; and programming constructs such as &amp;quot;if&amp;quot;, &amp;quot;repeat&amp;quot;, and proce-
dure definition.
</bodyText>
<sectionHeader confidence="0.990295" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.9998564">
Natural language programming has been proposed
by many authors (Balzer[2], Green[13], Heidorn[17],
Petrick[25], Sammet[27], Woods[38]) as the best way
for humans to input their commands to computers.
Humans have developed exquisitely efficient abilities
for communicating with each other through natural
language, and the possibility of similarly interacting
with machines is worthy of investigation. The ability
to program in natural language instead of traditional
programming languages would enable people to use
familiar constructs in expressing their requests, thus
making machines accessible to a wider user group.
Automatic speech recognition and synthesis devices
could eventually smooth the communication even fur-
ther.
On the other hand, many problems could arise
when natural language programming is attempted
(Dijkstra[11], Petrick[25], Simmons[32]), and any
such research must deal with them. For example, it
has been argued that current natural language technol-
</bodyText>
<note confidence="0.858898">
1 This material is based upon work supported by the National
Science Foundation under Grant Numbers MCS74-14445-A01 and
MC S-7904120.
2 Current address: Department of Computer and Information
Science, The Ohio State University, Columbus, Ohio 43210.
</note>
<bodyText confidence="0.966806310344828">
ogy is too primitive to handle a wide variety of syntac-
tic and semantic constructs so that the user of such a
system has the difficult task of learning what consti-
tutes an acceptable input to the system. Instead of
having to learn the relatively simple syntax of a clearly
defined programming language, the user would be
forced to learn a voluminous and very detailed set of
rules giving what words and phrases can be used and
how they can be combined. Thus the user would be
taxed more heavily with a natural language system
than with a traditional system. A second argument
against natural language programming relates to its
intrinsic vagueness and ambiguity. It is maintained
that if one wishes to manipulate information precisely
and reliably within a machine, a clearly defined and
unambiguous language should be used. The program-
mer should not have to wonder about the meaning of a
particular input to the system; he or she should know
the meaning or be able to look it up easily in a manu-
al. A third argument asserts that no one would use a
natural language programming system, even if one
existed, because it would be too verbose. Why should
one be willing to input long and wordy descriptions of
a desired computation when there exist simple, easy-
to-learn, and concise notations for doing the same
thing?
Copyright 1980 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted
provided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included on
the first page. To copy otherwise, or to republish, requires a fee and/or specific permission.
</bodyText>
<page confidence="0.402468">
0362-613X/80/020071-16$01.00
</page>
<note confidence="0.963946">
American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 71
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<subsectionHeader confidence="0.996997">
1.1 A Natural Language Computer
</subsectionHeader>
<bodyText confidence="0.99885">
Formidable as these criticisms may seem, this paper
will attempt to show that some of them can be over-
come with a careful system design, while others may
be simply wrong. This paper describes a system,
called the Natural Language Computer (NLC), which
makes it possible to perform a limited amount of natu-
ral language programming. This system enables a
person to sit at a computer display terminal, observe
his or her data structures on the screen, and watch the
computation proceed as the individual commands are
typed. The current implementation is specifically de-
signed for array and matrix computation. In the ex-
ample interaction of Figure 1, the user is creating a
subroutine to add up the rows and columns of an arbi-
trary matrix. Each item that is modified by a com-
mand is marked with an asterisk and other items used
in the calculation are marked with an apostrophe. The
first two commands cause two matrices to appear on
the screen, one to be operated on and the other to
receive the answer. The third command provides some
sample data for the calculation and the fourth com-
mand indicates that the imperative verb &amp;quot;sumcolrow&amp;quot;
is about to be defined. Subsequent inputs tell exactly
what operations must be done to sumcolrow a matrix
into another matrix. For example, if after this dia-
logue the system receives the input
&amp;quot;Sumcolrow matrix Al into matrix Z.&amp;quot;
where Al and Z are matrices of appropriate dimen-
sions, the procedure body following the define state-
ment will be executed. Thus the dialogue causes the
system to create a subroutine to be called by using the
newly defined imperative verb &amp;quot;sumcolrow&amp;quot;.
This process is explained in greater detail in later
sections of the paper. The important point to be no-
ticed here is that the user is able to watch the system
respond to each command as it is entered. Whenever
the system yields an undesired action, the user can
back up and rephrase his or her command more clear-
ly. This format for natural language programming
enables users to examine system performance as each
command is typed and to detect most errors immedi-
ately.
</bodyText>
<subsectionHeader confidence="0.997931">
1.2 Concerning the Objections
</subsectionHeader>
<bodyText confidence="0.977134909090909">
Given this brief introduction to the NLC user inter-
face, it is already possible to respond to the first criti-
cism of natural language programming given above.
Although we feel that present day natural language
processors tend to have very limited capabilities, it is
quite possible within the NLC environment to direct
the user to restrict the inputs appropriately. For this
reason, the user is asked to follow two simple rules
which are easily understood from the user&apos;s point of
&amp;quot;Display a 3 by 3 matrix. Call it testmat.&amp;quot;
Testmat
</bodyText>
<equation confidence="0.97611025">
1 2 3
1 0 0 0
2 0 0 0
3 0 0 0
&amp;quot;Display a 3 by 2 matrix. Call it ans.&amp;quot;
Testmat ans
1 2 3 1 2
1 0 0 0 1 0 0
2 0 0 0 2 0 0
3 0 0 0 3 0 0
&amp;quot;Fill testmat with random numbers.&amp;quot;
Testmat ans
1 2 3 1 2
1 1* 4* -7* 1 0 0
2 2* 3* 1* 2 0 0
3 4* 2* 2* 3 0 0
</equation>
<bodyText confidence="0.6458378">
&amp;quot;Define a way to sumcolrow testmat into
ans.&amp;quot;
&amp;quot;Add each column in testmat to
column 1 in ans.&amp;quot;
testmat ans
</bodyText>
<equation confidence="0.98747775">
1&apos; 2&apos; 3&apos; 1* 2
1 1&apos; 4&apos; -7&apos; 1 -2* 0
2 2&apos; 3&apos; 1&apos; 2 6* 0
3 4&apos; 2&apos; 2&apos; 3 8* 0
</equation>
<bodyText confidence="0.750498375">
&amp;quot;Add each row in testmat to
column 2 of ans.&amp;quot;
testmat ans
1 2 3 1 2*
1&apos; 1&apos; 4&apos; -7&apos; 1 -2 7*
2&apos; 2&apos; 3&apos; 1&apos; 2 6 9*
3&apos; 4&apos; 2&apos; 2&apos; 3 8 -4*
&amp;quot;End the definition.&amp;quot;
</bodyText>
<figureCaption confidence="0.996599">
Figure 1. Defining the verb &amp;quot;sumcolrowâ€œ.
</figureCaption>
<bodyText confidence="0.990347875">
view and which simultaneously ease the job of the
system designers and implementers considerably.
The first rule concerns the semantics of inputs:
(1) The user may refer only to the data struc-
tures seen on the terminal screen and specify
simple operations upon them.
That is, the user may refer to matrices, rows, columns,
entries, labels, numbers, variables, etc., and specify
simple operations such as add, subtract, move, ex-
change, delete, label, etc. The user may not use do-
main specific vocabulary or concepts such as airplane
flights, seats, passengers, and reservations. This rule is
easily explained to a user and makes it possible to
build a system without getting into the peculiarities of
any specific domain. Although it requires the user to
translate his or her problem into the vocabulary of the
</bodyText>
<note confidence="0.7632925">
72 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<bodyText confidence="0.998011566037736">
system, it also makes it possible to experiment with
the system in many different domains.
The second rule concerns the syntax of the inputs:
(2) The user must begin each sentence with an
imperative verb.
This rule is also easy to explain to the user and it also
greatly restricts the variety of sentences to be proc-
essed. If this rule is followed, the system can find out
much about each clause from its first word, including
what words or concepts may occur later in the clause.
In summary, the strategy for achieving person-to-
machine language compatibility taken here is (1) to
find a small number of simple rules which a person can
easily follow to restrict the set of inputs; and then (2)
to stretch the language processing technology to the
point where it can reasonably cover that set. When
this is done, the first criticism of natural language
programming stated earlier is overcome.
The other major objections to natural language
programming relate to its vagueness, ambiguity, and
alleged verbosity. Perspectives on these issues can be
achieved by examining some examples of natural lan-
guage and the corresponding programs in traditional
programming languages. Consider for example the
command
&amp;quot;Square the sixth positive entry in matrix M.&amp;quot;
Vagueness does not appear to be a problem with the
English of this example. In fact, the sentence is prob-
ably shorter than most equivalent formulations written
in traditional programming languages. The corre-
sponding code in almost any programming language
will require some declarations and a nesting of looping
and branching constructs. As an additional example,
the reader should examine the English language pro-
gram and its corresponding PL/I counterpart which is
included in the Appendix. Our experience so far with
English language programming seems to indicate that
the language is as precise as its user wants it to be.
Concerning the length of English language programs,
they seem to be comparable to the length of ordinary
programs in the domains we have examined. Of
course, one could write down a complicated arithmetic
expression from some standard programming language
and note that its English equivalent is relatively long,
unreadable, and unwieldy. The solution to this prob-
lem is to include in the natural language processor the
ability to handle such arithmetic expressions. Consid-
ering the complexity of any reasonable natural lan-
guage processor, the cost of adding something like an
arithmetic expression handler is modest. Other con-
structs from programming languages which are shown
to be convenient could also be considered for inclu-
sion.
</bodyText>
<subsectionHeader confidence="0.998934">
1.3 Background
</subsectionHeader>
<bodyText confidence="0.999958423076923">
The NLC system has grown out of an earlier series
of studies on the &amp;quot;autoprogrammer&amp;quot; (Biermann[6])
and bears much resemblance to it. Program synthesis
in both the current and the previous systems is based
upon example calculations done by the user on dis-
played data structures. In the current system, the
example is done in restricted English with all its pow-
er, which is a dramatic departure from the earlier ap-
proach, which simply involved pointing with a light
pen. However, it is expected that many of the fea-
tures from the autoprogrammer, such as &amp;quot;continue&amp;quot;
and &amp;quot;automatic indexing&amp;quot;, will transfer quite naturally
into NLC. This paper emphasizes the natural lan-
guage aspects of the system, while other reports deal
with some of the additional automatic programming
features. The relationship of NLC to other research in
natural language processing is discussed in a later sec-
tion.
The next section presents an overview of NLC,
after which subsequent sections discuss scanning, syn-
tactic and semantic processing, and interpretation of
commands in the &amp;quot;matrix computer&amp;quot;. The next two
sections discuss the processing of flow-of-control com-
mands and the level of behavior achieved by the sys-
tem. The final sections include a discussion of related
research and conclusions.
</bodyText>
<sectionHeader confidence="0.73204" genericHeader="keywords">
2. System Overview
</sectionHeader>
<bodyText confidence="0.999925148148148">
The NLC system is organized as shown in Figure 2,
with the user input passing through the conventional
sequence of stages: lexical, syntactic, and semantic
processing. The scanner finds the tokens in the input
sentence and looks them up in the dictionary. It per-
forms some morphological processing and spelling
correction for items not appearing in the dictionary.
Additionally, abbreviations (such as &amp;quot;col&amp;quot; for
&amp;quot;column&amp;quot;) and spelled-out numbers and ordinals
(&amp;quot;twenty-two&amp;quot;, &amp;quot;seventh&amp;quot;, etc.) are recognized. The
identified words with their meanings are passed on to
the parser, which is programmed with nondeterministic
transition nets similar to the augmented transition
networks of Woods[40]. The parser has the ability to
screen out many syntactically correct but semantically
meaningless structures so that the first parse it finds is
usually correct. The parser output goes to the flow-
of-control semantics routines which make decisions
about the nature of the input command and then prop-
erly guide it through subsequent processing.
The input sentence may be a simple request for a
system defined computation or it may be a flow-of-
control command such as a user-defined subroutine
call. An example of the first case is &amp;quot;Add row 1 to
row 2.&amp;quot; Here flow-of-control processing sends the
sentence directly to the sentence semantics routines
which resolve the noun groups and invoke the matrix
</bodyText>
<note confidence="0.539614">
American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 73
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<figure confidence="0.992805625">
Input
Dictionary SCANNER
Grammar PARSER
Procedures FLOW-OF-CONTROL
SEMANTICS
MATRIX
COMPUTER
Output to Display
</figure>
<figureCaption confidence="0.998983">
Figure 2. The NLC system modules (upper case) and their associated data structures (lower case).
</figureCaption>
<figure confidence="0.978008666666667">
User-Defined Names
Parse Trees
Context
&lt;----&gt; SENTENCE
SEMANTICS
Data World
</figure>
<bodyText confidence="0.999890487179487">
computer to perform the indicated operation. An
example of the second case is a command beginning
with a user-defined verb such as &amp;quot;sumcolrow&amp;quot;. Here
flow-of-control processing brings in from a file the set
of commands for the subroutine which defines the
word &amp;quot;sumcolrow&amp;quot;. Then those commands, with par-
ameters properly instantiated, are sequentially trans-
ferred to sentence semantics for execution.
The major task of the sentence semantics routines
is the processing of noun groups. They begin with the
head noun in any particular noun group and build a
representation for the meaning of the noun group by
sequentially processing whatever modifying words and
phrases there may be. These routines are concerned
with qualifying relative clauses, prepositional phrases,
adjectives, ordinals, pronouns, and numerous other
constructions appearing in noun groups. The result of
noun group processing is usually a designation of an
item or set of items in the displayed data structures to
be manipulated by the matrix computer.
Most imperative verbs such as &amp;quot;double&amp;quot; or &amp;quot;add&amp;quot;
pass through the system without change until they
reach the matrix computer. This routine then per-
forms the indicated operation on the data specified by
the processed noun groups. All changes in the data
structures are immediately updated on the display
screen, along with markers to show the user where the
changes have been made. A few imperative verbs are
not processed by the matrix computer. Some examples
are &amp;quot;find&amp;quot; or &amp;quot;choose&amp;quot;, which are processed by the
sentence semantics module, and &amp;quot;repeat&amp;quot; or user-
defined imperatives, which are processed by flow-of-
control semantics.
Every effort has been made to modularize the sys-
tem for understandability and easy modification. In
addition, the design attempts to use limited computer
resources economically. It is written in the C language
and runs on a PDP-l1/70 under the UNIX operating
system.
</bodyText>
<subsectionHeader confidence="0.72206">
3. The Scanner
</subsectionHeader>
<bodyText confidence="0.999947538461538">
The scanner collects the string of tokens from the
input and identifies them as well as possible. These
tokens may be numbers or ordinals in various forms,
names known to the system, punctuation, or dictionary
words which may be abbreviated or misspelled in a
minor way. The scanner outputs a set of alternative
definitions for each incoming token, and the syntax
stage attempts to select the intended meaning for each
one.
Each dictionary entry consists of a set of pairs of
features. Two examples appear in Figure 3, the defi-
nitions of the word &amp;quot;zero&amp;quot; as an imperative verb and
as an adjective. &amp;quot;Zero&amp;quot; as a verb takes one argument
</bodyText>
<page confidence="0.906168">
74 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980
</page>
<note confidence="0.920157">
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<bodyText confidence="0.996787142857143">
and no particle (type OPS1). The meaning of an im-
perative verb is built into the execution code of the
matrix computer as explained in Section 6. As an
adjective, the meaning of &amp;quot;zero&amp;quot; is embedded in the
semantics code described in Section 5. That code will
execute a routine associated with the name in the
AMEANS field, zero.
</bodyText>
<figure confidence="0.976397833333333">
1. (QUOTE zero)
(PART IMPERATIVE)
( IMPERTYPE OPS1)
2. (QUOTE zero)
(PART ADJ)
(AMEANS zero)
</figure>
<figureCaption confidence="0.708911615384615">
Figure 3. Two sample dictionary entries.
Figure 4 shows the output from the scanner for an
example input sentence. Associated with each token is
the set of alternate definitions proposed by the system
and the syntax stage will attempt to make appropriate
choices such that the sentence is meaningful. Most
tokens are found in the dictionary, but the string
&amp;quot;thee&amp;quot; is not. So dictionary entries are selected by
the spelling corrector which are similar to the un-
known. The token &amp;quot;y&amp;quot; is also not found in the dic-
tionary but is recognized as the name of an existing
matrix entity. The words &amp;quot;zero&amp;quot; and &amp;quot;to&amp;quot; appear in
the dictionary with multiple meanings.
</figureCaption>
<figure confidence="0.426567736842105">
INTERPRETATION (S)
add - verb
- propname
to - verbicle
to - prep
thee - propname
the - art
them - pron
then - etc
there - etc
these - pron
these - art
three - num
zero verb
zero adj
zero num
entries entries - noun
- punctuation
&amp;quot;Add y to thee zero entries.&amp;quot;
</figure>
<figureCaption confidence="0.859774">
Figure 4. Scanner output for a sample sentence giving alternate
interpretations for each word.
</figureCaption>
<sectionHeader confidence="0.794869" genericHeader="introduction">
4. Syntax
</sectionHeader>
<bodyText confidence="0.998212388888889">
Most of the sentences processed by the system can
be thought of as imperative verbs with their associated
operands. For example, the sentence
&amp;quot;Add the first and last positive entries in
row 1 and the second to smallest entry in
the matrix to each entry in the last row.&amp;quot;
exhibits the overall form
(add x to y)
where x is the noun group &amp;quot;the first and last ... in the
matrix&amp;quot; and y is &amp;quot;each entry in the last row&amp;quot;. The
system separately processes constructions related to
the imperative verbs and those related to noun groups.
The following two sections discuss these types of con-
structions. Then, Section 4.3 describes a method for
rejecting certain kinds of syntactically correct but se-
mantically unacceptable parses, Section 4.4 describes
our approach to handling syntactic ambiguity, and
Section 4.5 gives the form of the output for the parser.
</bodyText>
<subsectionHeader confidence="0.998483">
4.1 Imperatives And Their Operands
</subsectionHeader>
<bodyText confidence="0.981855384615384">
A transition net for processing the above impera-
tive form for &amp;quot;add&amp;quot; is shown in Figure 5. The word
PARSE means to call routines appropriate for parsing
the indicated construct. IMPERATIVE refers to the
imperative verb, and NG refers to the noun group.
VERBICLE refers to a particular type of preposition
which is often associated with an imperative verb to
distinguish its operands. Thus in the sentences
&amp;quot;Multiply x by y.&amp;quot;
&amp;quot;Store x in y.&amp;quot;
the words &amp;quot;by&amp;quot; and &amp;quot;in&amp;quot; are verbicles. Of course, any
given imperative will have only a few acceptable verbi-
cies, so the parser checks that a suitable one is found.
</bodyText>
<figure confidence="0.974923222222222">
START
PARSE IMPERATIVE
1
PARSE NG
PARSE VERBICLE
1
PARSE NG
PARSE &amp;quot;.&amp;quot;
SUCCEED
</figure>
<figureCaption confidence="0.99895">
Figure 5. A top-level parser for sentences of the form
&amp;quot;add X to Y&amp;quot;.
</figureCaption>
<figure confidence="0.804644">
WORD
Add
to
thee
zero
American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 75
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</figure>
<subsubsectionHeader confidence="0.501706">
4.1.1 Conjunction Handling
</subsubsectionHeader>
<bodyText confidence="0.999034">
Although the routine of Figure 5 might be adequate
for a large fraction of the sentences received by NLC,
we decided to formulate a facility for handling a wide
variety of conjunctions [33]. Toward this goal, a rou-
tine called MIX was designed as shown in Figure 6.
</bodyText>
<figure confidence="0.993088333333333">
START
PARSE A
---- PARSE A
---&gt;PARSE &amp;quot;and&amp;quot; &lt;--PARSE
PARSE A
&gt; SUCCEED
</figure>
<figureCaption confidence="0.999788">
Figure 6. A simplified transition network for MIX A.
</figureCaption>
<bodyText confidence="0.8317098">
Suppose A is a given construct and suppose xl, x2,
and x3 are instances of that construct. Then MIX A
will process forms such as
x 1
x 1 and x2
x 1, x2, and x3
x 1 and x2 and x3
and others. If, for example, A represents the impera-
tive clause construct, then MIX A will process
&amp;quot;Add yl to y2, add y3 to y4, and add y5 to y6.&amp;quot;
If A is the unconjoined noun group, then MIX A will
process
&amp;quot;row 1, row 2, and row 3.&amp;quot;
Figure 7 shows how a series of calls of the MIX rou-
tine can be used to process reasonably complex nest-
ings of conjunctions. For example, these routines will
parse the sentence
&amp;quot;Add yl to y2, to y3, and to y4
and y5 to y6
and add y7 to y8.&amp;quot;
</bodyText>
<subsubsectionHeader confidence="0.557513">
4.1.2 Other Sentence Forms
</subsubsectionHeader>
<bodyText confidence="0.995655846153846">
Of course, not all verbs take two operands and a
verbicle as in the examples above. Indeed, verbs such
as &amp;quot;call&amp;quot; have two operands without a verbicle:
&amp;quot;Call the matrix x.&amp;quot; (Call yl y2.)
There are also one-operand verbs which take a parti-
cle, such as &amp;quot;add up&amp;quot;. Particles present a special
problem since they can appear in various positions in
the sentence; NLC handles most of the common
placements. Many one-operand verbs appear without
particles as in
&amp;quot;Double row 1.&amp;quot; (Double yl.)
and there are verbs that take no operand: either with
a particle, as in
&amp;quot;Back up.&amp;quot;
or without a particle, as in
&amp;quot;Quit.&amp;quot;
Most of the imperatives handled by NLC fall into
one or more of the six categories listed above: zero,
one, or two operands, with or without a
verbicle/particle. The conjunction handling described
above extends to all of these types of imperatives in a
natural way. Although NLC has facilities for accept-
ing imperatives with more than two operands or with
formats other than those given here, a large proportion
of all imperatives in our domain do fit into the simple
scheme given here.
</bodyText>
<subsectionHeader confidence="0.999048">
4.2 Noun Group Syntax
</subsectionHeader>
<bodyText confidence="0.999915571428572">
Four types of noun groups appear in the sentences
processed by NLC. The most common type refers to
the entities on the NLC display screen: numbers,
entries, rows, matrices and so forth. These are the
noun groups that appear as operands for the impera-
tive verbs. Many examples appear in previous sec-
tions. The second type of noun group is the noun
</bodyText>
<figure confidence="0.917379230769231">
START START
MIX Si PARSE IMPERATIVE
PARSE &amp;quot; . &amp;quot; MIX NGVNG
SUCCEED SUCCEED
(a) Top level (b) Clause level
routine S routine Si.
START START
PARSE NG PARSE VERBICLE
MIX VNG PARSE NG
SUCCEED SUCCEED
(c) Noun-verbicle- (d) Verbicle-noun
noun level level routine VNG
routine NGVNG
</figure>
<figureCaption confidence="0.999359">
Figure 7. A sentence parser allowing nested conjunctions.
</figureCaption>
<bodyText confidence="0.958263517857143">
&gt; PARSE
76 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
result group, which refers to the result of a computa-
tion. Some examples are &amp;quot;the sum of rows 1 and 2&amp;quot;
and &amp;quot;the absolute value of x&amp;quot; where in each case the
object being referred to appears not on the screen but
is found by manipulating displayed objects. The third
type of noun group is the noun place group, as illus-
trated by &amp;quot;bottom&amp;quot; in
&amp;quot;Add the second from bottom row to row 3.&amp;quot;
&amp;quot;Bottom&amp;quot; in this example is the place from which the
ordinal processor begins counting. Some other words
that can fit into this slot are &amp;quot;right&amp;quot;, &amp;quot;left&amp;quot;, &amp;quot;top&amp;quot;,
and &amp;quot;last&amp;quot;. The fourth type of noun group is the noun
procedure group, which refers to a procedure, a com-
mand, or a set of commands in the NLC input. This
type is illustrated in
&amp;quot;Repeat the last three commands ten times.&amp;quot;
&amp;quot;Double the entries the third command
incremented.&amp;quot;
Only the operand noun groups will be discussed in
detail here.
Operand level noun groups follow a format similar
to the one given by Winograd[37]. Let OPT be a
routine which optionally calls a set of routines. As an
illustration, OPT DETERMINER calls routines to
parse a determiner If those routines fail, however,
OPT succeeds anyway, assuming that the noun group
exists without a determiner. The basic format for the
operand level noun group parser, given in Figure 8, is
completely exercised by the noun group
&amp;quot;the first three positive matrix 1 entries
which are odd&amp;quot;
DETERMINER: the
ORDINAL: first
NUMBER: three
ADJECTIVE: positive
CLASSIFIER: matrix 1
NOUN: entries
QUALIFIER: which are odd
Since OPT is used to look for most of the constituents,
the parser analyzes noun groups with those elements
missing. (Examples: &amp;quot;the positive entries&amp;quot;, &amp;quot;seven
numbers greater than 10&amp;quot;, &amp;quot;the smallest entry&amp;quot;, etc.)
Constructs of the form &amp;quot;row 1&amp;quot;, &amp;quot;columns 2 and 3&amp;quot;,
or &amp;quot;the constant 4.5&amp;quot; require separate recognition.
The DETERMINER routine parses not only the
simple determiners &amp;quot;the&amp;quot; and &amp;quot;a/an&amp;quot; but also a varie-
ty of quantifiers such as &amp;quot;all&amp;quot;, &amp;quot;all of the&amp;quot;, &amp;quot;both&amp;quot;,
&amp;quot;no more than six of the&amp;quot;, &amp;quot;exactly two of the&amp;quot;, and
many others. The ORDINAL routine processes the
common ordinals &amp;quot;first&amp;quot;, &amp;quot;second&amp;quot;, &amp;quot;next&amp;quot;, and
&amp;quot;last&amp;quot;, which can also appear with superlatives
(&amp;quot;second greatest&amp;quot;) or with modifiers (&amp;quot;second from
right&amp;quot;, &amp;quot;second from last&amp;quot;).
</bodyText>
<figure confidence="0.886287888888889">
START
OPT DETERMINER
OPT ORDINAL
OPT NUMBER
OPT ADJECTIVE
OPT CLASSIFIER
PARSE NOUN
OPT QUALIFIER
SUCCEED
</figure>
<figureCaption confidence="0.999679">
Figure 8. A Winograd-style noun phrase parser.
</figureCaption>
<bodyText confidence="0.97494">
Six types of qualifiers are handled by NLC:
</bodyText>
<listItem confidence="0.716552125">
1. Preposition groups:
&amp;quot;the rows IN MATRIX 2&amp;quot;
2. Adjective groups:
&amp;quot;the numbers LARGER THAN 6&amp;quot;
3. Relative clauses:
&amp;quot;the rows WHICH CONTAIN
NEGATIVE NUMBERS&amp;quot;
4. ED groups:
&amp;quot;the entries ADDED&amp;quot;
&amp;quot;the entries ADDED TO&amp;quot;
&amp;quot;the entries ADDED TO ROW 4&amp;quot;
&amp;quot;the entries ADDED BY THE LAST
COMMAND&amp;quot;
5. ING groups:
&amp;quot;the columns CONTAINING 5.5&amp;quot;
6. Rank-shifted clauses:
</listItem>
<bodyText confidence="0.971349">
&amp;quot;the entries COLUMN 2 CONTAINS&amp;quot;
Many types of conjoined phrases are processed
using the MIX routine as in &amp;quot;the first and last en-
tries&amp;quot;, &amp;quot;the first two and last three entries&amp;quot;, &amp;quot;the first
two and the last three entries&amp;quot;, and others. Noun
groups may be nested within other noun groups as
illustrated in
</bodyText>
<note confidence="0.8794425">
American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 77
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<bodyText confidence="0.982790333333333">
&apos;&apos;the largest entry
in the first row
of the matrix
containing the column
that was doubled by the second to last
command&amp;quot;
</bodyText>
<subsectionHeader confidence="0.999596">
4.3 Semantic Checking During Syntactic Processing
</subsectionHeader>
<bodyText confidence="0.999180483870968">
If the parser is provided with some information
about the types of nouns and the relationships they
may have with each other, it can reject inappropriate
parses. As an illustration, in the following phrase a
possible parse of the qualifiers is as indicated by the
parentheses.
the entry (in row 2 (in column 3) )
That is, row 2 is &amp;quot;in&amp;quot; column 3 and the entry being
referred to is in that row 2. However, in an ordinary
matrix it is not possible for a row to be contained in a
column and so it is desirable that this parse be reject-
ed. The correct parse will be found if it is known that
row-in-column is a disallowed pattern, forcing &amp;quot;row 2&amp;quot;
to stand alone as a noun group:
the entry (in row 2) (in column 3)
Thus both the qualifiers &amp;quot;in row 2&amp;quot; and &amp;quot;in column 3&amp;quot;
modify the noun &amp;quot;entry&amp;quot;. Since entry-in-row and
entry-in-column are semantically acceptable patterns,
this parse can be passed to the semantics processor.
Observations of this type lead to the concept of
semantically acceptable patterns and a mechanism for
checking for them. A hash-coded table was added to
NLC which contains the set of all semantically accept-
able patterns for certain constructions. At various
times during the processing, checks are made to see
that a sensible parse is being assembled. Besides
checking for compatibility in prepositional modifiers as
indicated above, the system tests relationships given
by relative clauses and adjective groups. It also
checks that the operands of imperative verbs are legiti-
mate.
</bodyText>
<subsectionHeader confidence="0.999433">
4.4 Syntactic Ambiguity
</subsectionHeader>
<bodyText confidence="0.999986642857143">
The strategy for dealing with syntactic ambiguity is
to attempt to anticipate the situations in which it is
most likely to arise and to decide, whenever possible,
which alternative is most reasonable. Having made
such decisions, it is usually possible to order the gram-
mar rules in such a way that the preferred parse is the
one arrived at first, thus combining the efficiency of a
blind search with the accuracy of a more extensive
one. Perhaps surprisingly, the method has proven
quite successful in meeting the stated objectives. (See
[5].) This is due in part to the formulation of several
general principles stemming from our observations of
how natural language is employed in the NLC domain.
The most important of these are:
</bodyText>
<listItem confidence="0.961469304347826">
1. Deep parses are generally preferred. Thus,
&amp;quot;x in y in z&amp;quot;
more often attaches the qualifier &amp;quot;in z&amp;quot; with y
than with x when both readings are meaningful.
2. When ambiguity arises because of a conjunction,
the intended conjuncts are likely to have similar
type. This contrasts sharply with conventional
programming languages, where operators rather
than operands determine the &amp;quot;binding&amp;quot; in arith-
metic expressions such as &amp;quot;a + b * c&amp;quot;. The
preference for conjoining similar units is auto-
matically supplied by using the MIX routine
described earlier.
3. Compatibility checks based on semantic relation-
ships should be checked during the parse as de-
scribed in Section 4.3. This offers the benefit
of suspending parsing to obtain semantic infor-
mation without incurring the inefficiency of such
action.
4. Special cases exist and should be introduced as
such, rather than erroneously generalized to the
point of introducing the possibility for parses
which users would find ungrammatical.
</listItem>
<subsectionHeader confidence="0.995405">
4.5 Syntactic Processor Output
</subsectionHeader>
<bodyText confidence="0.9996">
The output of the syntax processor is a template
for each clause giving the imperative verb and pointers
to structures which represent the operands. Figure 9
gives an example of such an output.
</bodyText>
<figure confidence="0.4067732">
Imperative Verb Template
OPERATOR add
OPERAND 1
ARTICLE DETERMINED
ARTSP SING-PLUR
NOUN entry
NOUNSP PLUR
Modifier 1
PREP IN
NOUN row
NOUNSP SING
WHICH 1
Modifier 2
COMP GREATER
NOUN CONSTANT
WHICH 6 . 0
VERBICLE to
OPERAND 2
NOUN PROPNAME
QUOTE X
</figure>
<figureCaption confidence="0.979466">
Figure 9. Output of the syntax processor for the sentence &amp;quot;add the
entries in row 1 greater than 6.0 to X.&amp;quot;.
</figureCaption>
<note confidence="0.738168">
78 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<sectionHeader confidence="0.819295" genericHeader="method">
5. Sentence Semantics
</sectionHeader>
<bodyText confidence="0.993614928571429">
The primary responsibility of the semantics module
of NLC is the processing of noun groups to determine
their referents. Input to semantics consists of the
parse trees constructed by the syntactic processor.
The imperative, along with its verbicle/particle, is
saved for later context references, but not operated
upon at this time. The principal role of semantics is to
produce a precise internal representation that can be
used by the matrix computer in carrying out the re-
quested command.
A secondary role of semantics is to update context
as a consequence of resolving noun phrases. In this
way, one may refer to previous actions of the system.
Thus:
&amp;quot;Clear the column that was added to column 2.&amp;quot;
&amp;quot;Increment by 5 the row which the last
command squared.&amp;quot;
Context is also utilized in the location of referents for
pronouns and other words requiring pronominal proc-
essing. Some examples are:
&amp;quot;Multiply the smallest entry by IT.&amp;quot;
&amp;quot;Replace THAT ENTRY by ITS reciprocal.&amp;quot;
&amp;quot;Subtract the NEXT 2 entries from each
member of row 2.&amp;quot;
&amp;quot;Sum up the OTHER entries in those rows.&amp;quot;
The following sections describe briefly the repre-
sentations used in the system, noun group resolution,
and the processing of pronominal structures.
</bodyText>
<subsectionHeader confidence="0.994337">
5.1 Internal Data Structures
</subsectionHeader>
<bodyText confidence="0.940548127272727">
For the matrix computer to carry out users&apos; com-
mands, physical addresses of the operands must be
available. The resolved nouns must also be stored at a
conceptual level so that later sentences may refer to
the objects operated upon. For these reasons, the
basic internal representation of the domain entities
consists of a collection of intermediate structures from
which hardware addresses are computed. Since the
syntax parse trees are available, this intermediate no-
tation does not refer to the natural language input.
Most of the internal structures, denoted
&amp;quot;datareps&amp;quot;, refer to a singular domain entity and have
a fixed number of parameters. These &amp;quot;primitives&amp;quot; are:
entry, row, column, matrix, domain, float constant, int
constant, name, noun result, result, and command. As
an example, the datarep for the noun group &amp;quot;row 2&amp;quot; is
(ROW 1 2) which fills 5 bytes in memory and gives
the name of the entity, the matrix number, and the
item designation.
Plurals may arise in a variety of ways, some of
which are presented here. In the simplest case, a plu-
ral datarep is the direct result of the resolution of a
plural noun, as in
&amp;quot;rows 3, 4 and 5&amp;quot;
&amp;quot;the entries in rows 1 and 2&amp;quot;
Word-meaning routines such as adjective, ordinal, and
superlative may produce a plural output, as in
&amp;quot;the positive entries in row 2&amp;quot;
&amp;quot;the last 3 entries that were doubled&amp;quot;
&amp;quot;the smallest 3 numbers in the last column&amp;quot;
In addition, plurals may result from the conjoining of
singular datareps
&amp;quot;row 4 and column 5&amp;quot;
&amp;quot;row 2 and the last row&amp;quot;
or from conjunctions in which one or more of the
conjuncts is itself plural
&amp;quot;row 3 and the rows containing positive entries&amp;quot;
&amp;quot;the first 3 and the last 2 rows in matrix 1&amp;quot;
An important feature common to all the types of con-
junctions mentioned above is that the members of the
&amp;quot;set&amp;quot; which represents the resulting plural datarep are
themselves singular. Thus, for the noun phrase
&amp;quot;row 6 and the first 2 rows&amp;quot;
the resolution will be
SET of size 3:
ROW 6
ROW 1
ROW 2
Because of the manner of manipulating the internal
structures and passing them between modules of the
NLC system, an array-like data structure was chosen
for sets instead of a LISP-like representation. A de-
tailed description of the precise mechanism for repre-
senting sets, beyond the scope of the present paper,
may be found in Ballard[1].
</bodyText>
<subsectionHeader confidence="0.999758">
5.2 Noun Group Resolution
</subsectionHeader>
<bodyText confidence="0.996967111111111">
The discovery of the meaning of a particular noun
group begins with the head noun and any &amp;quot;in&amp;quot; qualifi-
er which may be found. Thus in the phrase
&amp;quot;the smallest entry in row 2 greater than 10,&amp;quot;
the meaning of the words &amp;quot;entry in row 2&amp;quot; is initially
represented as the set [(ENTRY 2 1), (ENTRY 2 2),
. . . , (ENTRY 2 N)}. Then processing of other
qualifiers and lastly prenominal modifiers has the ef-
fect of removing entries from the initial set. In this
case, processing of &amp;quot;greater than 10&amp;quot; causes the sys-
tem to reference the values of the listed entries and
remove from the set those entries not meeting the
specified criterion, &amp;quot;greater than 10&amp;quot;. Processing of
&amp;quot;smallest&amp;quot; results in all but the appropriate smallest
entry being removed, and processing of &amp;quot;the&amp;quot; involves
checking that the resulting set has only one member
since the head noun is singular. The final meaning of
the noun group is thus the set {(ENTRY 2 i) } for
</bodyText>
<note confidence="0.8526285">
American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 79
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<bodyText confidence="0.996209">
some i and this representation is passed to the matrix
computer as an operand for some computation.
</bodyText>
<subsectionHeader confidence="0.99919">
5.3 Pronominalization
</subsectionHeader>
<bodyText confidence="0.999494">
The basic syntactic types of the pronouns within
the matrix domain are the following:
</bodyText>
<listItem confidence="0.9954844">
1. pure pronoun
&amp;quot;it&amp;quot; / &amp;quot;them&amp;quot;
&amp;quot;itself&amp;quot; / &amp;quot;themselves&amp;quot;
2. pronominal determiner
&amp;quot;THAT entry&amp;quot; / &amp;quot;THOSE columns&amp;quot;
3. possessive determiner
&amp;quot;ITS rows&amp;quot; / &amp;quot;THEIR columns&amp;quot;
4. pronominal ordinal
&amp;quot;NEXT row&amp;quot;
&amp;quot;OTHER entries&amp;quot;
</listItem>
<bodyText confidence="0.999934666666667">
The fourth category is included among the listing of
pronouns because the semantics involve most of the
same principles. For instance, &amp;quot;the other entries&amp;quot;
demands the semantics that would occur for &amp;quot;the en-
tries other than ?&amp;quot;, where &amp;quot;?&amp;quot; represents the most
general possible pronoun, having no type or number
constraints.
Pronoun reference is done by considering previous
datareps rather than by traversing trees as described
by Hobbs [22]. Specific guidelines for posing the
eligible referents to pronouns in a reasonable order
include, in order of importance:
</bodyText>
<listItem confidence="0.990940333333333">
1. In all cases, require type, number, and semantic
constraints of the pronoun to agree with the
datarep being examined.
2. Prefer more recently created datareps.
3. For case-level (operand) pronouns, try to match
source with an old datarep source, destination
with an old destination.
4. &amp;quot;Fuse&amp;quot;, or conjoin, singular datareps to produce
a plural referent if necessary. Thus
</listItem>
<bodyText confidence="0.768511866666666">
&amp;quot;Add row 1 to row 2.&amp;quot;
&amp;quot;Double those rows.&amp;quot;
entails creating the set consisting of rows 1 and
2 at the time pronoun referent location occurs.
5. Consult more distant sentences only after trying
all possibilities on an intervening sentence.
Thus,
&amp;quot;Clear rows 1 and 2.&amp;quot;
&amp;quot;Triple column 4.&amp;quot;
&amp;quot;Add row 3 to row 4.&amp;quot;
&amp;quot;Double those rows.&amp;quot;
will prefer the complicated but recent fusion in
the immediately preceding command over the
exact but less immediate plural three sentences
earlier.
</bodyText>
<sectionHeader confidence="0.915688" genericHeader="method">
6. The Matrix Computer
</sectionHeader>
<bodyText confidence="0.983074">
The &amp;quot;matrix computer&amp;quot; of NLC is assigned two
major tasks: (1) carrying out the computations which
the user has requested and (2) displaying on the termi-
nal the resulting data world. Since the latter function
is conceptually simple (although tedious to code effec-
tively) and since sample system outputs are provided
in Figure 1, this section will concentrate only upon the
techniques which the matrix computer uses to perform
the desired computations.
As discussed in the previous section, essentially all
processing of noun phrases is completed by the seman-
tics module. What is made available then to the ma-
trix computer is a collection of templates, similar to
the ones generated as the parser output, as shown
earlier in Figure 9, but with the noun arguments fully
&amp;quot;resolved&amp;quot; into datareps as already described. As an
example of the templates received by the matrix com-
puter, consider the English input
&amp;quot;Add up the first row, double row 2, and
subtract row 4 from row 5.&amp;quot;
</bodyText>
<table confidence="0.229449928571429">
The semantics output for this input is
Template 1:
Verb: &amp;quot;add&amp;quot;
Verbicle/Particle: &amp;quot;up&amp;quot;
Operand: (ROW 1)
Template 2:
Verb: &amp;quot;double&amp;quot;
Verbicle/Particle:
Operand: (ROW 2)
Template 3:
Verb: &amp;quot;subtract&amp;quot;
Verbicle/Particle: &amp;quot;from&amp;quot;
Operand 1: (ROW 4)
Operand 2: (ROW 5)
</table>
<bodyText confidence="0.9981455625">
The task of the matrix computer is to decide upon the
appropriate operations and to apply them to the ope-
rands.
It was mentioned earlier that the imperatives, parti-
cles, and verbicles recognized at parse time pass
through semantics without alteration. When the out-
put from semantics becomes available to the matrix
computer, the imperative verb and the associated
verbicle/particle (if there is one) are looked up in a
table to determine the appropriate action. In most
cases, it has not been necessary to write a separate
procedure for each imperative. Specifically, &amp;quot;double&amp;quot;
is treated as a special case of &amp;quot;multiply&amp;quot;. Thus the
user input
&amp;quot;Double the first 2 entries in column 1.&amp;quot;
entails the matrix computer operations
</bodyText>
<table confidence="0.377151">
Arith-op(*, 2.0, (ENTRY 1 1))
Arith-op(*, 2.0, (ENTRY 2 1))
</table>
<page confidence="0.648854">
80 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980
</page>
<note confidence="0.875721">
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<bodyText confidence="0.990823620689655">
where &amp;quot;Arith:op&amp;quot; is the general coding capable of
performing the basic arithmetic operations. In this
way, the matrix computer has accommodated a large
number of arithmetic commands by the mere addition
of one table entry (8 bytes). Further instances of
arithmetic verbs which make use of the arithmetic-op
code are clear, copy, decrease, decrement, divide,
halve, and many others.
In general, operating with a scalar (element, varia-
ble, or constant) upon an aggregate (row, column or
matrix) means to operate independently on each mem-
ber. The knowledge of how to perform the intended
operations for all meaningful source-destination pairs
must be coded into the system. This means specifying
for each X-Y pair exactly what is required by
Arith-op(op, X, Y)
for datareps &apos;X&apos; and &apos;Y&apos;
and &apos;op&apos; a member of { *, }
The remaining type of matrix computer operation
deals with the noun result such as in
&amp;quot;Add the PRODUCT of the positive entries
to row 1.&amp;quot;
&amp;quot;Add the SUM of rows 3, 4 and 5 to row 6.&amp;quot;
Notice that a noun result may yield a scalar as in the
first example or a vector as in the second. The noun
result is evaluated similarly to imperative verb opera-
tions, and the result of the calculation is inserted into
the appropriate higher level structure for further proc-
essing.
</bodyText>
<sectionHeader confidence="0.874243" genericHeader="method">
7. Flow-of-Control Semantics
</sectionHeader>
<bodyText confidence="0.999939">
Thus far, this paper has discussed sentence by sen-
tence processing, where system actions occur one at a
time, determined directly from keyboard inputs. Most
means of enhancing the usefulness of the system fall
into one of two categories: (1) the introduction of
programming-language type control structures and (2)
the ability to define and execute self-contained por-
tions of natural language &amp;quot;coding&amp;quot;. These topics are
addressed separately here.
</bodyText>
<subsectionHeader confidence="0.999769">
7.1 Conditional Execution
</subsectionHeader>
<bodyText confidence="0.986903769230769">
To specify conditional execution of a command or
a group of commands in English, one uses such words
as &amp;quot;if&amp;quot;, &amp;quot;when&amp;quot;, &amp;quot;unless&amp;quot;, &amp;quot;otherwise&amp;quot;, etc. Follow-
ing are some sentences typical of inputs that NLC-like
systems will likely be called upon to process.
&amp;quot;IF row 3 contains a positive entry ...&amp;quot;
&amp;quot;IF the largest entry occurs in the last row ...&amp;quot;
Implementation of this facility is not complete on
the NLC system. When it becomes totally operative,
users will be told that they may begin sentences with
the word &amp;quot;if&amp;quot; as well as with imperative verbs. The
characteristic language feature appearing in each of
the above sentences is the independent clause: decla-
rative (rather than imperative) in nature, and requiring
the evaluation of a Boolean (i.e., a condition whose
truth or falsity is to be determined). Fortunately, the
conjugated verbs are typically either &amp;quot;be&amp;quot; or one of
the verbs which have already occurred in relative
clauses, and so an appreciable degree of different syn-
tactic processing is not required. Thus,
&amp;quot;if row 3 contains a positive entry ...&amp;quot;
relates directly to
&amp;quot;the rows which contain a positive entry&amp;quot;
The semantic routines originally written for qualifier
verbs can, therefore, with a slight modification be used
in handling these constructs.
</bodyText>
<subsectionHeader confidence="0.999837">
7.2 Looping
</subsectionHeader>
<bodyText confidence="0.996954551724138">
NLC provides several ways of creating loops using
the verb &amp;quot;repeat.&amp;quot; In the typical situation, the user
supplies and observes the execution of a sequence of
commands on particular members of the data world.
The system is then capable of abstracting, from the
specific instructions, general code to operate on other
entities. Frequently, an algorithm requires the applica-
tion of a sequence of commands to several members of
the domain. One way of accomplishing this is to make
use of the following pattern.
&amp;quot;Choose an entry which ... and call it x.&amp;quot;
&amp;quot;... to x.&amp;quot;
&amp;quot;... x by ...&amp;quot;
&amp;quot;Repeat for the other entries.&amp;quot;
When such a sequence is recognized, the &amp;quot;repeat&amp;quot;
processor finds the set given to the most recent un-
matched &amp;quot;choose&amp;quot; (or &amp;quot;pick&amp;quot;, etc.) and thereby knows
what &amp;quot;other&amp;quot; members are to have the intervening
commands applied to them. In instances where there
is no non-deterministic &amp;quot;choose&amp;quot;-type operation to
delineate the statements to be repeated or to make
explicit the set to which previous commands are to be
applied, alternate versions of &amp;quot;repeat&amp;quot; are provided.
Examples include
&amp;quot;Repeat the last 3 commands.&amp;quot;
&amp;quot;Repeat the last command 5 times.&amp;quot;
&amp;quot;Repeat the last 3 commands for all
other odd entries.&amp;quot;
&amp;quot;Repeat those commands twice on row 3.&amp;quot;
</bodyText>
<subsectionHeader confidence="0.999079">
7.3 Procedures
</subsectionHeader>
<bodyText confidence="0.999326833333333">
Another way of extending sentence by sentence
processing is the facility for defining procedures, ena-
bling the user to describe operations in terms of exist-
ing commands. Subsequent inputs may access the
newly-created imperatives as though they had been
previously defined, including their use in further pro-
</bodyText>
<note confidence="0.922849">
American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 81
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<bodyText confidence="0.9999725">
cedure definitions. Programmers will recognize the
following illustration as an instance of the &amp;quot;called-
procedure&amp;quot; type of subroutine. There is no reason,
however, for not providing the &amp;quot;function&amp;quot; procedure
as well. Interestingly, the &amp;quot;noun result&amp;quot; discussed
earlier corresponds to this value-returning subroutine.
In addition, the NLC design includes the creation of
new adjectives. The correspondences between natural
language words and conventional programming lan-
guage procedures are roughly as follows.
</bodyText>
<subsubsectionHeader confidence="0.677678">
Natural Language Programming Language
</subsubsectionHeader>
<bodyText confidence="0.968276260869565">
imperative verb &amp;quot;called&amp;quot; subroutine
noun result * &amp;quot;function&amp;quot; subroutine
adjective * &amp;quot;predicate&amp;quot;
(* - not yet operative on NLC)
Both the noun result and the adjective routines require
an explicit &amp;quot;return&amp;quot; command. Methods of incorpo-
rating them into the present system, as well as ways of
relaxing the restrictions for the imperative verb proce-
dures discussed below, are being developed.
In order to assure correct re-execution of the com-
mands within a procedure, it is necessary to detect
occurrences of the parameters among the nouns of the
procedure body. To accomplish this, the system re-
quires that the arguments at the time of procedure
definition be names. When a user input indicates that
a procedure is about to be defined, names are saved so
that their re-occurrence can be recognized as denoting
a parameter rather than simply the current argument.
While the procedure definition is in progress, appropri-
ate changes are made in the syntax trees, which are
then saved on disc. As an example, suppose the user
types
&amp;quot;Define a procedure to zap z into w.&amp;quot;
</bodyText>
<figure confidence="0.871192777777778">
&amp;quot;Double w.&amp;quot;
&amp;quot;Add z to w.&amp;quot;
&amp;quot;Negate z.&amp;quot;
&amp;quot;End.&amp;quot;
filename contents
Zap.0001 double param-2
Zap.0002 add param-1 to param-2
Zap.0003 negate param-1
Zap.0004 end
</figure>
<bodyText confidence="0.874985666666667">
This enables flow-of-control semantics processing,
when an invocation of the new &amp;quot;zap...into&amp;quot; imperative
is detected, to evaluate the arguments and substitute
them appropriately into the procedure&apos;s syntax trees
wherever param-i is present.
Syntax for user-created imperatives parallels that
for the system-provided routines of corresponding
type. For instance, the same type of verbicle/particle
compatibility checking (where applicable) takes place.
Thus some acceptable inputs are
&amp;quot;Zap row 3 into row 6.&amp;quot;
&amp;quot;Zap into column 4 the second column.&amp;quot;
and some intentionally rejected inputs are
&amp;quot;Zap row 5.&amp;quot; [missing operand]
&amp;quot;Zap row 5 from row 6.&amp;quot; [wrong verbicle]
</bodyText>
<subsectionHeader confidence="0.739677">
8. System Behavior
</subsectionHeader>
<bodyText confidence="0.9992202">
The sentence processing capabilities of the system
will be indicated in this section by demonstrating its
ability to handle paraphrases and by describing an
experiment in which it was used by paid subjects to
solve problems.
</bodyText>
<subsectionHeader confidence="0.999742">
8.1 Syntactic Breadth
</subsectionHeader>
<bodyText confidence="0.998889">
To demonstrate the variety of the syntax handled
by the system, fifty-five paraphrases are given below
for the sentence
&amp;quot;Double the first row in matrix 1.&amp;quot;
These paraphrases are not all exact in that some of
them omit reference to matrix 1, assuming context
makes it clear, others entail side effects, such as the
creation of a label, etc. This set gives only a small
fraction of all the possible paraphrases that can be
processed, but it is representative. The typical time
required for complete processing of each sentence is
two seconds on the PDP-11/70.
The first set of paraphrases demonstrates some
variations on the qualifier.
</bodyText>
<listItem confidence="0.9989228">
1. &amp;quot;Double the first row of matrix 1.&amp;quot;
2. &amp;quot;Double the first row which is in matrix 1.&amp;quot;
3. &amp;quot;Double the first row that appears in matrix 1.&amp;quot;
4. &amp;quot;Double the first row that matrix 1 contains.&amp;quot;
5. &amp;quot;Double the first row matrix 1 contains.&amp;quot;
</listItem>
<bodyText confidence="0.553306">
The matrix reference can also appear as a classifier
</bodyText>
<listItem confidence="0.9699453">
6. &amp;quot;Double the first matrix 1 row.&amp;quot;
can be
7. &amp;quot;Double the first row.&amp;quot;
8. &amp;quot;Double row 1.&amp;quot;
A row may be referred to by the values it contains.
9. &amp;quot;Double the first row that contains a positive or
a nonpositive number.&amp;quot;
10. &amp;quot;Double the row that contains the first entry of
matrix 1.&amp;quot;
11. &amp;quot;Double the row in which
</listItem>
<bodyText confidence="0.927492142857143">
the first entry of matrix 1 appears.&amp;quot;
12. &amp;quot;Double the first row in which there is
a positive or a nonpositive number.&amp;quot;
At this point, there will be four new files contain-
ing parse trees which can be informally represented as
follows, or if context indicates the matrix reference, it
omitted.
</bodyText>
<page confidence="0.813614">
82 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980
</page>
<note confidence="0.924602">
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<listItem confidence="0.80510668">
13. &amp;quot;Double the row containing the first entry
of column 1.&amp;quot;
14. &amp;quot;Consider column 2.
Consider the first entry in it.
Double the row which contains that entry.&amp;quot;
Rows may be thought of as sets of entries.
15. &amp;quot;Double the entries of row 1.&amp;quot;
16. &amp;quot;Double the elements in row 1.&amp;quot;
17. &amp;quot;Double the row 1 entries.&amp;quot;
18. &amp;quot;Double the row 1 numbers.&amp;quot;
The next several sentences illustrate some quantifiers.
19. &amp;quot;Double all the entries of row 1.&amp;quot;
20. &amp;quot;Double each entry in row 1.&amp;quot;
21. &amp;quot;Double every entry in row 1.&amp;quot;
22. &amp;quot;Double each one of the entries in row 1.&amp;quot;
Assume the row has 5 members.
23. &amp;quot;Double the first five entries of matrix 1.&amp;quot;
Some rows may be located positionally.
24. &amp;quot;Double the top row.&amp;quot;
Suppose there are four rows in the matrix. The first
row can be found by counting up from the bottom.
25. &amp;quot;Double the fourth row from the bottom.&amp;quot;
26. &amp;quot;Double the fourth from the bottom row.&amp;quot;
27. &amp;quot;Double the fourth from bottom row.&amp;quot;
28. &amp;quot;Double the fourth from the last row.&amp;quot;
</listItem>
<bodyText confidence="0.971671833333334">
Generality of ordinal processing allows for some rather
strange sentences.
29. &amp;quot;Double the first one row.&amp;quot;
30. &amp;quot;Double the first row from the top.&amp;quot;
Row 1 can be located with respect to other rows.
31. &amp;quot;Double the row in matrix 1 corresponding to
row 1 in matrix 2.&amp;quot;
32. &amp;quot;Double the row in matrix 1 which corresponds
to row 1 of matrix 2.&amp;quot;
One can use multiple clauses by labelling or focusing
attention in one clause and then using it in the second
clause.
</bodyText>
<reference confidence="0.967127896551724">
33. &amp;quot;Consider row 1 and double it.&amp;quot;
34. &amp;quot;Consider row 1. Double it.&amp;quot;
35. &amp;quot;Consider row 1. Double that row.&amp;quot;
36. &amp;quot;Consider and double row 1.&amp;quot;
37. &amp;quot;Consider row 1.
Double the row considered by the
last command.&amp;quot;
38. &amp;quot;Consider row 1.
Double the row the last command considered.&amp;quot;
39. &amp;quot;Consider matrix 1 and double its first row.&amp;quot;
40. &amp;quot;Consider rows 2, 3 and 4.
Double the other row.&amp;quot;
41. &amp;quot;Consider row 1 of matrix 2.
Double the row in matrix 1 corresponding to it.&amp;quot;
Users may access entities by naming them.
42. &amp;quot;Call row 1 x. Double x.&amp;quot;
43. &amp;quot;Call row 1 x. Double row x.&amp;quot;
44. &amp;quot;Call row 1 x. Double it.&amp;quot;
45. &amp;quot;Call row 1 x. Double the x row.&amp;quot;
46. &amp;quot;Call the first entry x. Double the x row.&amp;quot;
The &amp;quot;backup&amp;quot; command will undo the calculation of
previous commands.
47. &amp;quot;Double row 1. Clear it. Backup.&amp;quot;
Other imperatives can be used to achieve the result of
&amp;quot;double&amp;quot;.
48. &amp;quot;Add row 1 to itself.&amp;quot;
49. &amp;quot;Add row 1 to row 1.&amp;quot;
50. &amp;quot;Multiply row 1 by 2.&amp;quot;
51. &amp;quot;Divide row 1 by 0.5.&amp;quot;
</reference>
<bodyText confidence="0.761279444444444">
52. &amp;quot;Divide 0.5 into the first row.&amp;quot;
53. &amp;quot;Add the entries in row 1 to themselves.&amp;quot;
Finally, noun result groups may be used.
54. &amp;quot;Put the product of 2 and row 1 into row
55. &amp;quot;Subtract the negative of row 1 from
that row.&amp;quot;
There are, of course, many paraphrases which are
not currently recognized by NLC. Some examples
include sentences with superfluous words or phrases:
</bodyText>
<listItem confidence="0.8527965">
1. &amp;quot;PLEASE double row 1.&amp;quot;
2. &amp;quot;Double the VERY first row of matrix 1.&amp;quot;
3. &amp;quot;Double the first BUT NOT THE
SECOND row.&amp;quot;
certain unimplemented noun-result formats:
4. &amp;quot;Put twice row 1 into row 1.&amp;quot;
5. &amp;quot;Put row 1 times 2 into row 1.&amp;quot;
and verbs taking more than 2 operands:
6. &amp;quot;Add row 1 to itself, putting the result
into row 1.&amp;quot;
</listItem>
<subsectionHeader confidence="0.999087">
8.2 Some Observations of Performance
</subsectionHeader>
<bodyText confidence="0.999977333333333">
In April of 1979, twenty-three students in a first
course in programming at Duke were paid to be sub-
jects in an experiment on the system. Each subject
was left alone in a room with the display terminal and
given a short tutorial to read, a few simple practice
exercises to do, and a problem to solve. No verbal
interactions were allowed between experimenter and
subject except those related to the administration of
the test. Typical times required to complete the tuto-
rial, the exercises, and the problem were 35, 15, and
50 minutes, respectively. In the problem solving ses-
sions, the subjects typed a total of 1581 sentences, 81
</bodyText>
<note confidence="0.9031675">
American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 83
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<bodyText confidence="0.9715355">
percent of which were processed immediately and
correctly. Approximately half of the remaining 19
percent were rejected because of system inadequacies,
and the other half were rejected because of errors in
user inputs. This experiment is described in [5] by
Biermann, Ballard, and Holler, with an analysis of the
types of errors that were made. Also included in the
experiment was a test of the subjects&apos; ability to do the
same problems in the programming language from
their course, PL/C. These results are discussed in [5],
too.
Some specific observations that have come out of
the experiment and other usages of the system are as
follows:
1. The vocabulary of over 300 words is nearly ade-
quate for a reasonable class of problems. Only
eight words were typed during the experiment
which were not available in the system. Howev-
er, any casual user who attempts to push the
system capabilities significantly will quickly find
many unimplemented words.
2. Some of the implemented words have inade-
quate definitions. For example, NLC will proc-
ess &amp;quot;the entry corresponding to x&amp;quot; but not &amp;quot;the
corresponding entry&amp;quot;. The latter form is more
difficult because the item to be corresponded to
is not explicit.
3. The variety of the syntactic structures which are
processed is approximately as good as indicated
by the experiment: About 70 to 90 percent of a
typical user&apos;s inputs will be handled by the par-
ser.
4. The error messages for the system are inade-
quate.
5. The processor for quantification needs to be
redesigned. We notice for example that NLC
processes &amp;quot;Double EACH entry in the first col-
umn&amp;quot; but not &amp;quot;Double the first entry in EACH
column.&amp;quot; In the former case, the first column is
found and the matrix computer doubles its en-
tries in one operation. In the later case, the
definitions of &amp;quot;entry&amp;quot;, &amp;quot;first&amp;quot;, &amp;quot;the&amp;quot;, and
&amp;quot;double&amp;quot; must be invoked in that order for ev-
ery column.
</bodyText>
<sectionHeader confidence="0.551918" genericHeader="method">
9. Comparison With Other Work
</sectionHeader>
<bodyText confidence="0.999985490566038">
A number of projects in automatic programming
propose to have a user converse about a problem in a
completely natural manner, using problem dependent
vocabulary, and largely omitting discussion of data
structures and coding details. Examples of such work
have been described by Balzer[2,3], Biermann[4],
Green[13,14], Heidorn[16,17,18,19], and Martin et
al.[23]. Inputs to these systems typically include a
collection of fragments about the program to be gener-
ated, in which case the system must perform consider-
able induction and synthesis to produce an output.
While the long term goals of the NLC project are sim-
ilar to those of these other projects, the method of
research is somewhat different. Whereas many pro-
jects attempt to tackle problems associated with sever-
al levels of cognition at once, NLC attempts to begin
with a reliable sentence-by-sentence processor and to
add facilities slowly while reducing demands on the
user.
Many of the research efforts in natural language
processing have been associated with information re-
trieval from data base systems (Codd[9], Harris[15],
Hendrix et al.[20,21], Petrick[25], Plath[26], Sim-
mons[31], Thompson &amp; Thompson[34], Waltz[35,36],
and WoOds[39]). Most of the inputs for these systems
are questions or simple imperatives such as &amp;quot;list all of
the ...&amp;quot; Top level sentence syntax for these systems
may have more variety than NLC. At the noun group
level, however, NLC appears to have more extensive
capabilities. This is due to the need in the NLC envi-
ronment to conveniently refer to objects or sets of
objects on the basis of their properties, geometrical
location, operations performed upon them, etc.
Concerning world modelling, a system which bears
some resemblance to NLC is SOPHIE by Brown and
Burton[8]. Their system allows natural language inter-
action with a simulator for an electric circuit.
In the artificial intelligence literature, there is much
emphasis on (I) artificial cognitive abilities, (2) induc-
tion mechanisms, (3) problem solving facilities, and
(4) mechanisms for dealing with context and sequence.
Future work on NLC will move in the direction of
adding such facilities, but in its current state the sys-
tem works more like an interpreter for English in the
style of programming language interpreters than like a
&amp;quot;thinking&amp;quot; machine. Thus the mechanisms described
in Bobrow &amp; Collins[7], Cullingford[10], Minsky[24],
Schank[28,29,30], Winograd[37], and others for vari-
ous kinds of cognition and problem solving are, for the
time being, largely without counterpart in NLC. The
philosophy of this project has been to build from the
bottom, attempting to solve the least difficult, though
still challenging, problems first.
</bodyText>
<sectionHeader confidence="0.690674" genericHeader="method">
10. Conclusion
</sectionHeader>
<bodyText confidence="0.999979833333333">
Natural language programming has seemed in re-
cent years to be a rather remote possibility because of
the slow progress in representation theory, inference
theory, and computational linguistics. The NLC sys-
tem is designed to compensate partially for the weak-
ness of current technology in these areas by presenting
</bodyText>
<page confidence="0.757068">
84 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980
</page>
<note confidence="0.966975">
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
</note>
<bodyText confidence="0.997877875">
the user with.a good environment and with some well-
designed linguistic facilities. All of the quoted phrases
and sentences in this paper and the Appendix have
been run on the system except for the &amp;quot;if&amp;quot; construc-
tions in Section 7. Current efforts are aimed at the
development of a number of flow-of-control semantics
facilities for handling various types of control struc-
tures and definitions of new vocabulary items.
</bodyText>
<sectionHeader confidence="0.898584" genericHeader="method">
Appendix: A Natural Language Program and Its
PL/I Equivalent
</sectionHeader>
<bodyText confidence="0.988388">
The following &amp;quot;pivot&amp;quot; routine uses a computational
technique described in Gallie and Ramm[12] and gives
an example of a nontrivial usage of the system.
&amp;quot;Display a 4 by 5 matrix and call it testmat.&amp;quot;
&amp;quot;Fill the matrix with random values.&amp;quot;
&amp;quot;Choose an entry and call it p.&amp;quot;
&amp;quot;Define a method to pivot testmat about p.&amp;quot;
&amp;quot;Choose an entry not in the p row and not in
the p column and call it q.&amp;quot;
&amp;quot;Compute the product of the entry which cor-
responds to q in the p row and the entry
which corresponds to q in the p column.&amp;quot;
&amp;quot;Divide the result by p and subtract this result
from q.&amp;quot;
&amp;quot;Repeat for all other entries not in the p row
and not in the p column.&amp;quot;
&amp;quot;Divide each entry except p in the p row by p
and negate those entries.&amp;quot;
&amp;quot;Divide each entry except p in the p column
by p.&amp;quot;
&amp;quot;Put the reciprocal of p into p.&amp;quot;
&amp;quot;End the definition.&amp;quot;
The PLA equivalent program as given in [12] is as
follows:
</bodyText>
<sectionHeader confidence="0.888907285714286" genericHeader="method">
EXCHANGE:
PROCEDURE (MATRIX, PIVROW PIVCOL)
DECLARE (MATRIX (* , *) , PIVOT) FLOAT,
( PIVROW , PIVCOL , ROWS , COLMNS, I ,J)
FIXED BINARY;
/* DETERMINE NUMBER OF ROWS
AND COLUMNS */
</sectionHeader>
<equation confidence="0.930515655172414">
ROWS = HBOUND(MATRIX,1);
COLMNS = HBOUND(MATRIX,2);
/* NAME THE PIVOT ELEMENT */
PIVOT = MATRIX(PIVROW,PIVCOL);
/* APPLY THE &amp;quot;RECTANGLE RULE&amp;quot; */
DO I = 1 to PIVROW-1,
PIVROW+1 TO ROWS;
DO J = 1 TO PIVCOL-1,
PIVCOL+1 TO COLMNS;
MATRIX ( I , J) = MATRIX ( I , J)
â€” MATRIX ( I , PIVCOL ) *
MATRIX ( PIVROW , J) / PIVOT;
END;
END;
/* CHANGE THE OLD PIVOT ROW */
DO J = 1 TO PIVCOL-1,
PIVCOL+1 TO COLMNS;
MATRIX(PIVROW,J) =
â€” MATRIX(PIVROW,J) / PIVOT;
END;
/* CHANGE THE OLD PIVOT COLUMN */
DO.I = 1 TO PIVROW-1,
PIVROW+1 TO ROWS;
MATRIX(I,PIVCOL) =
MATRIX(I,PIVCOL) / PIVOT;
END;
/* CHANGE THE PIVOT */
MATRIX(PIVROW,PIVCOL) = 1 / PIVOT;
END EXCHANGE;
</equation>
<sectionHeader confidence="0.873549" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9971565">
Miss Anne Holler has produced several sections of
code in the NLC system, including the spelling correc-
tor, the syntax networks for the &amp;quot;if&amp;quot; and &amp;quot;repeat&amp;quot;
clauses, semantics and matrix computer routines for
noun result groups, and all the terminal display rou-
tines. We are grateful to George Heidorn and the
referees for extensive help in improving and shortening
the original 87 page report.
</bodyText>
<sectionHeader confidence="0.995163" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994795580882353">
1. Ballard, B.W. Semantic Processing For A Natural Language
Programming System (Ph.D. Dissertation), Report CS-1979-5,
Duke University, Durham, North Carolina, May, 1979.
2. Balzer, R.M. &amp;quot;A Global View Of Automatic Programming&amp;quot;,
Proc. 3rd Joint Conference On Artificial Intelligence, August,
1973, pp. 494-499.
3. Balzer, R.M. &amp;quot;Imprecise Program Specification&amp;quot;, Proc. Con-
siglio Nazi. Ric. 1st. Elaborazione Inf., 1975.
4. Biermann, A. &amp;quot;Approaches To Automatic Programming, in
Advances in Computers, Volume 15, Academic Press, New
York, 1976, pp. 1-63.
5. Biermann A., Ballard, B., and Holler, A. &amp;quot;An Experimental
Study Of Natural Language Programming,&amp;quot; Report CS-1979-
9, Duke University, Durham, North Carolina, July, 1979.
6. Biermann, A. and Krishnaswamy, R. &amp;quot;Constructing Programs
From Example Computations&amp;quot;, IEEE Transactions on Software
Engineering, September, 1976, pp. 141-153.
American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 85
Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation
7. Bobrow, D.G. and Collins, A. Ed., Representation and Under-
standing, Academic Press, New York, 1975.
8. Brown, J.S. and Burton, R.R. &amp;quot;Multiple Representations Of
Knowledge For Tutorial Reasoning&amp;quot;, in Representation and
Understanding (Bobrow, D.G. and Collins, A., Eds.), Academic
Press, New York, 1975, pp. 311 - 349.
9. Codd, E.F. &amp;quot;Seven Steps to RENDEZVOUS With The Casual
User&amp;quot;, IBM Report J1333 (#20842), January 17, 1974. Pres-
ented at the IFIP-TC2 Conference on Data Base Management,
Cargese, Corsica, April 1-5, 1974.
10. Cullingford, R.E. Script Application: Computer Understanding
of Newspaper Stories (Ph.D. Dissertation). Research Report
#116, Yale University, 1978.
11. Dijkstra, E.W. &amp;quot;On The Foolishness Of &apos;Natural Language
Programming&apos;. Unpublished report, 1978.
12. Gallie, T. and Ramm, D. Computer Science/I: An Introduction
To Structured Programming. Kendall/Hunt, Dubuque, Iowa,
1976.
13. Green, C: &amp;quot;A Summary Of The PSI Program Synthesis Sys-
tem&amp;quot;, Proceedings Of 5th International Conference on Artifi-
cial Intelligence, Volume I, August 1977, pp. 380 - 381.
14. Green, C.C., Waldinger, R.J., Barstow, D.R., Elschlager, R.,
Lenat, D.B., McCune, B.P., Shaw, D.E., and Steinberg, L.I.
&amp;quot;Progress Report On Program-Understanding Systems&amp;quot;, Memo
AIM-240, Stanford Artificial Intelligence Laboratory, Stan-
ford, California.
15. Harris, L.R. &amp;quot;Status Report On ROBOT NL Query Proc-
essor&amp;quot;, SIGART Newsletter, August, 1978, pp. 3-4
16. Heidorn, George E. &amp;quot;Augmented Phrase Structure Gram-
mars&amp;quot;, IBM Thomas J. Watson Research Center, Yorktown
Heights, New York, December, 1975.
17. Heidorn, George E. &amp;quot;Automatic Programming Through Natu-
ral Language Dialogue: A Survey&amp;quot;, IBM J. Res. Develop.,
July, 1976, pp. 302-313.
18. Heidorn, George E. Natural Language Inputs To A Simulation
Programming System. Naval Postgraduate School, October,
1972.
19. Heidorn, George E. &amp;quot;Supporting A Computer-Directed Natural
Language Dialogue For Automatic Business Programming&amp;quot;,
Research Report 26157, IBM Thomas J. Watson Research
Center, Yorktown Heights, New York, June, 1976.
20. Hendrix, Gary G., Sacerdoti, Earl D., Sagalowicz, Daniel, and
Slocum, Jonathan &amp;quot;Developing A Natural Language Interface
To Complex Data&amp;quot;, ACM Trans. on Database Systems, June,
1978, pp. 105-147.
21. Hendrix, Gary G. &amp;quot;Human Engineering For Applied Natural
Language Processing&amp;quot;, Proceedings Of 5th International Con-
ference on Artificial Intelligence, Volume I, August, 1977, pp.
183-191.
22. Hobbs, Jerry R. &amp;quot;Pronoun Resolution&amp;quot;, Research Report
76-1, Department of Computer Sciences, City College of New
York, August, 1976.
23. Martin, W.A., Ginzberg, M.J., Krumland, R., Mark, B., Mor-
genstern, M., Niamir, B., and Sunguroff, A. Internal Memos,
Automatic Programming Group, MIT, Cambridge, Massachu-
setts, 1974.
24. Minsky, M. &amp;quot;A Framework For Representing Knowledge&amp;quot;, in
The Psychology Of Computer Vision, Winston, P.H. ed.,
McGraw-Hill, New York, 1975.
25. Petrick, S.R. &amp;quot;On Natural Language Based Computer Sys-
tems&amp;quot;, IBM J. Res. Develop., July, 1976, pp. 314-325. Also
appears in Linguistic Structures Processing, A. Zampolli, ed.,
North-Holland Publishing Company, Amsterdam, Holland,
1977.
26. Plath, W.J. &amp;quot;REQUEST: A Natural Language Question-
Answering System&amp;quot;, IBM J. Res. Develop., July, 1976, pp.
326-335.
27. Sammet, J.E. &amp;quot;The Use of English As A Programming Lan-
guage&amp;quot;, Comm. ACM, March, 1966, pp. 228-229.
28. Schank, R.C. &amp;quot;Identification of Conceptualizations Underly-
ing Natural Language&amp;quot;, in Computer Models Of Thought And
Language, R.C. Schank, R.C. and K.M. Colby, Eds., W.H.
Freeman and Company, San Francisco, 1973, pp. 187-247.
29. Schank, R. and Abelson, R. Scripts, Plans, Goals, And Under-
standing. Lawrence Erlbaum Associates, Hillsdale, New Jer-
sey, 1977.
30. Schank, R.C. and Colby, K.M. Computer Models of Thought
And Language. W.H. Freeman and Company, San Francisco,
1973.
31. Simmons, R.F. &amp;quot;Natural Language Question Answering Sys-
tems: 1969&amp;quot;, Comm. ACM, January, 1970, pp. 15-30.
32. Simmons, R.F. Personal Communication at TINLAP-2 Con-
ference, Univ. of Illinois, July, 1978.
33. Stockwell, R. Schachter, P., and Partee, B. The Major Syntac-
tic Structures Of English. Holt, Rinehart and Winston, Inc.,
New York, 1973, pp. 294-418.
34. Thompson, Frederick B. and Thompson, Bozena H. &amp;quot;Practical
Natural Language Processing: The REL System as Proto-
type&amp;quot;, in Advances In Computers, Volume 13, M. Rubinoff and
M.C. Yovits, Eds., Academic Press, New York, 1975, pp.
109-168.
35. Waltz, D.L. &amp;quot;An English Language Question Answering
System For A Large Relational Database&amp;quot;, Comm. ACM, July,
1978, pp. 526-539.
36. Waltz, D.L., ed. &amp;quot;Natural Language Interfaces&amp;quot;, SIGART
Newsletter, February, 1977.
37. Winograd, T. Understanding Natural Language, Academic
Press, New York, 1972.
38. Woods, W.A. &amp;quot;A Personal View Of Natural Language Under-
standing&amp;quot;, in &amp;quot;Natural Language Interfaces&amp;quot;, SIGART Newslet-
ter, February, 1977, pp. 17-20.
39. Woods, W.A., Kaplan, R.M., and Nash-Weber, B. The Lunar
Sciences Natural Language Information System: Final Report.
Report Number 2378, Bolt, Beranek and Newman, Inc., Cam-
bridge, Massachusetts, 1972.
40. Woods, W.A. &amp;quot;Transition Network Grammars For Natural
Language Analysis&amp;quot;, Comm. ACM, October, 1970, pp. 591-
606.
Alan W. Biermann is an associate professor in the
Department of Computer Science at Duke University.
He received the Ph.D. degree in electrical engineering
and computer science from the University of California
at Berkeley in 1968.
Bruce W. Ballard is an assistant professor in the
Department of Computer and Information Science at
The Ohio State University. He received the Ph.D. degree
in computer science from Duke University in 1979.
</reference>
<page confidence="0.888913">
86 American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.374424">
<title confidence="0.996659">Natural Language Computation 1</title>
<author confidence="0.998637">W Alan</author>
<affiliation confidence="0.825208333333333">W. Department of Computer Duke University</affiliation>
<address confidence="0.995937">Durham, North Carolina 27706</address>
<abstract confidence="0.981228833333333">A computer programming system called the &amp;quot;Natural Language Computer&amp;quot; (NLC) is described which allows a user to type English commands while watching them executed on sample data appearing on a display screen. Direct visual feedback enables the user to detect most misinterpretation errors as they are made so that incorrect or ambiguous commands can be retyped or clarified immediately. A sequence of correctly executed commands may be given a name and used as a subroutine, thus extending the set of available operations and allowing larger English-language programs to be constructed hierarchically. In addition to discussing the transition network syntax and procedural semantics of the system, special attention is devoted to the following topics: the nature of imperative sentences in the matrix domain; the processing of non-trivial noun phrases; conjunction; pronominals; and programming constructs such as &amp;quot;if&amp;quot;, &amp;quot;repeat&amp;quot;, and procedure definition.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Consider row 1 and double it.&amp;quot;</title>
<contexts>
<context position="20427" citStr="[33]" startWordPosition="3390" endWordPosition="3390">bicies, so the parser checks that a suitable one is found. START PARSE IMPERATIVE 1 PARSE NG PARSE VERBICLE 1 PARSE NG PARSE &amp;quot;.&amp;quot; SUCCEED Figure 5. A top-level parser for sentences of the form &amp;quot;add X to Y&amp;quot;. WORD Add to thee zero American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 75 Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation 4.1.1 Conjunction Handling Although the routine of Figure 5 might be adequate for a large fraction of the sentences received by NLC, we decided to formulate a facility for handling a wide variety of conjunctions [33]. Toward this goal, a routine called MIX was designed as shown in Figure 6. START PARSE A ---- PARSE A ---&gt;PARSE &amp;quot;and&amp;quot; &lt;--PARSE PARSE A &gt; SUCCEED Figure 6. A simplified transition network for MIX A. Suppose A is a given construct and suppose xl, x2, and x3 are instances of that construct. Then MIX A will process forms such as x 1 x 1 and x2 x 1, x2, and x3 x 1 and x2 and x3 and others. If, for example, A represents the imperative clause construct, then MIX A will process &amp;quot;Add yl to y2, add y3 to y4, and add y5 to y6.&amp;quot; If A is the unconjoined noun group, then MIX A will process &amp;quot;row 1, row 2, a</context>
</contexts>
<marker>33.</marker>
<rawString>&amp;quot;Consider row 1 and double it.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Consider row 1. Double it.&amp;quot;</title>
<marker>34.</marker>
<rawString>&amp;quot;Consider row 1. Double it.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Consider row 1. Double that row.&amp;quot;</title>
<marker>35.</marker>
<rawString>&amp;quot;Consider row 1. Double that row.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Consider and double row 1.&amp;quot;</title>
<marker>36.</marker>
<rawString>&amp;quot;Consider and double row 1.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Consider row 1. Double the row considered by the last command.&amp;quot;</title>
<contexts>
<context position="24227" citStr="[37]" startWordPosition="4082" endWordPosition="4082">m bottom row to row 3.&amp;quot; &amp;quot;Bottom&amp;quot; in this example is the place from which the ordinal processor begins counting. Some other words that can fit into this slot are &amp;quot;right&amp;quot;, &amp;quot;left&amp;quot;, &amp;quot;top&amp;quot;, and &amp;quot;last&amp;quot;. The fourth type of noun group is the noun procedure group, which refers to a procedure, a command, or a set of commands in the NLC input. This type is illustrated in &amp;quot;Repeat the last three commands ten times.&amp;quot; &amp;quot;Double the entries the third command incremented.&amp;quot; Only the operand noun groups will be discussed in detail here. Operand level noun groups follow a format similar to the one given by Winograd[37]. Let OPT be a routine which optionally calls a set of routines. As an illustration, OPT DETERMINER calls routines to parse a determiner If those routines fail, however, OPT succeeds anyway, assuming that the noun group exists without a determiner. The basic format for the operand level noun group parser, given in Figure 8, is completely exercised by the noun group &amp;quot;the first three positive matrix 1 entries which are odd&amp;quot; DETERMINER: the ORDINAL: first NUMBER: three ADJECTIVE: positive CLASSIFIER: matrix 1 NOUN: entries QUALIFIER: which are odd Since OPT is used to look for most of the constit</context>
</contexts>
<marker>37.</marker>
<rawString>&amp;quot;Consider row 1. Double the row considered by the last command.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Consider row 1. Double the row the last command considered.&amp;quot;</title>
<contexts>
<context position="1253" citStr="[38]" startWordPosition="178" endWordPosition="178">available operations and allowing larger English-language programs to be constructed hierarchically. In addition to discussing the transition network syntax and procedural semantics of the system, special attention is devoted to the following topics: the nature of imperative sentences in the matrix domain; the processing of non-trivial noun phrases; conjunction; pronominals; and programming constructs such as &amp;quot;if&amp;quot;, &amp;quot;repeat&amp;quot;, and procedure definition. 1. Introduction Natural language programming has been proposed by many authors (Balzer[2], Green[13], Heidorn[17], Petrick[25], Sammet[27], Woods[38]) as the best way for humans to input their commands to computers. Humans have developed exquisitely efficient abilities for communicating with each other through natural language, and the possibility of similarly interacting with machines is worthy of investigation. The ability to program in natural language instead of traditional programming languages would enable people to use familiar constructs in expressing their requests, thus making machines accessible to a wider user group. Automatic speech recognition and synthesis devices could eventually smooth the communication even further. On th</context>
</contexts>
<marker>38.</marker>
<rawString>&amp;quot;Consider row 1. Double the row the last command considered.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Consider matrix 1 and double its first row.&amp;quot;</title>
<marker>39.</marker>
<rawString>&amp;quot;Consider matrix 1 and double its first row.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Consider rows 2, 3 and 4. Double the other row.&amp;quot;</title>
<contexts>
<context position="13092" citStr="[40]" startWordPosition="2173" endWordPosition="2173">e conventional sequence of stages: lexical, syntactic, and semantic processing. The scanner finds the tokens in the input sentence and looks them up in the dictionary. It performs some morphological processing and spelling correction for items not appearing in the dictionary. Additionally, abbreviations (such as &amp;quot;col&amp;quot; for &amp;quot;column&amp;quot;) and spelled-out numbers and ordinals (&amp;quot;twenty-two&amp;quot;, &amp;quot;seventh&amp;quot;, etc.) are recognized. The identified words with their meanings are passed on to the parser, which is programmed with nondeterministic transition nets similar to the augmented transition networks of Woods[40]. The parser has the ability to screen out many syntactically correct but semantically meaningless structures so that the first parse it finds is usually correct. The parser output goes to the flowof-control semantics routines which make decisions about the nature of the input command and then properly guide it through subsequent processing. The input sentence may be a simple request for a system defined computation or it may be a flow-ofcontrol command such as a user-defined subroutine call. An example of the first case is &amp;quot;Add row 1 to row 2.&amp;quot; Here flow-of-control processing sends the senten</context>
</contexts>
<marker>40.</marker>
<rawString>&amp;quot;Consider rows 2, 3 and 4. Double the other row.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Consider row 1 of matrix 2. Double the row in matrix 1 corresponding to it.&amp;quot; Users may access entities by naming them.</title>
<marker>41.</marker>
<rawString>&amp;quot;Consider row 1 of matrix 2. Double the row in matrix 1 corresponding to it.&amp;quot; Users may access entities by naming them.</rawString>
</citation>
<citation valid="false">
<title>Call row 1 x. Double x.&amp;quot;</title>
<marker>42.</marker>
<rawString>&amp;quot;Call row 1 x. Double x.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Call row 1 x. Double row x.&amp;quot;</title>
<marker>43.</marker>
<rawString>&amp;quot;Call row 1 x. Double row x.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Call row 1 x. Double it.&amp;quot;</title>
<marker>44.</marker>
<rawString>&amp;quot;Call row 1 x. Double it.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Call row 1 x. Double the x row.&amp;quot;</title>
<marker>45.</marker>
<rawString>&amp;quot;Call row 1 x. Double the x row.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Call the first entry x. Double the x row.&amp;quot; The &amp;quot;backup&amp;quot; command will undo the calculation of previous commands.</title>
<marker>46.</marker>
<rawString>&amp;quot;Call the first entry x. Double the x row.&amp;quot; The &amp;quot;backup&amp;quot; command will undo the calculation of previous commands.</rawString>
</citation>
<citation valid="false">
<title>Double row 1. Clear it. Backup.&amp;quot; Other imperatives can be used to achieve the result of &amp;quot;double&amp;quot;.</title>
<marker>47.</marker>
<rawString>&amp;quot;Double row 1. Clear it. Backup.&amp;quot; Other imperatives can be used to achieve the result of &amp;quot;double&amp;quot;.</rawString>
</citation>
<citation valid="false">
<title>Add row 1 to itself.&amp;quot;</title>
<marker>48.</marker>
<rawString>&amp;quot;Add row 1 to itself.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Add row 1 to row 1.&amp;quot;</title>
<marker>49.</marker>
<rawString>&amp;quot;Add row 1 to row 1.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Multiply row 1 by 2.&amp;quot;</title>
<marker>50.</marker>
<rawString>&amp;quot;Multiply row 1 by 2.&amp;quot;</rawString>
</citation>
<citation valid="false">
<title>Divide row 1 by 0.5.&amp;quot;</title>
<marker>51.</marker>
<rawString>&amp;quot;Divide row 1 by 0.5.&amp;quot;</rawString>
</citation>
<citation valid="true">
<authors>
<author>B W Ballard</author>
</authors>
<title>Semantic Processing For A Natural Language Programming System (Ph.D.</title>
<date>1979</date>
<tech>Dissertation), Report CS-1979-5,</tech>
<institution>Duke University,</institution>
<location>Durham, North Carolina,</location>
<contexts>
<context position="34265" citStr="[1]" startWordPosition="5756" endWordPosition="5756"> to all the types of conjunctions mentioned above is that the members of the &amp;quot;set&amp;quot; which represents the resulting plural datarep are themselves singular. Thus, for the noun phrase &amp;quot;row 6 and the first 2 rows&amp;quot; the resolution will be SET of size 3: ROW 6 ROW 1 ROW 2 Because of the manner of manipulating the internal structures and passing them between modules of the NLC system, an array-like data structure was chosen for sets instead of a LISP-like representation. A detailed description of the precise mechanism for representing sets, beyond the scope of the present paper, may be found in Ballard[1]. 5.2 Noun Group Resolution The discovery of the meaning of a particular noun group begins with the head noun and any &amp;quot;in&amp;quot; qualifier which may be found. Thus in the phrase &amp;quot;the smallest entry in row 2 greater than 10,&amp;quot; the meaning of the words &amp;quot;entry in row 2&amp;quot; is initially represented as the set [(ENTRY 2 1), (ENTRY 2 2), . . . , (ENTRY 2 N)}. Then processing of other qualifiers and lastly prenominal modifiers has the effect of removing entries from the initial set. In this case, processing of &amp;quot;greater than 10&amp;quot; causes the system to reference the values of the listed entries and remove from the</context>
</contexts>
<marker>1.</marker>
<rawString>Ballard, B.W. Semantic Processing For A Natural Language Programming System (Ph.D. Dissertation), Report CS-1979-5, Duke University, Durham, North Carolina, May, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Balzer</author>
</authors>
<title>A Global View Of Automatic Programming&amp;quot;,</title>
<date>1973</date>
<booktitle>Proc. 3rd Joint Conference On Artificial Intelligence,</booktitle>
<pages>494--499</pages>
<contexts>
<context position="1193" citStr="[2]" startWordPosition="173" endWordPosition="173">a name and used as a subroutine, thus extending the set of available operations and allowing larger English-language programs to be constructed hierarchically. In addition to discussing the transition network syntax and procedural semantics of the system, special attention is devoted to the following topics: the nature of imperative sentences in the matrix domain; the processing of non-trivial noun phrases; conjunction; pronominals; and programming constructs such as &amp;quot;if&amp;quot;, &amp;quot;repeat&amp;quot;, and procedure definition. 1. Introduction Natural language programming has been proposed by many authors (Balzer[2], Green[13], Heidorn[17], Petrick[25], Sammet[27], Woods[38]) as the best way for humans to input their commands to computers. Humans have developed exquisitely efficient abilities for communicating with each other through natural language, and the possibility of similarly interacting with machines is worthy of investigation. The ability to program in natural language instead of traditional programming languages would enable people to use familiar constructs in expressing their requests, thus making machines accessible to a wider user group. Automatic speech recognition and synthesis devices c</context>
</contexts>
<marker>2.</marker>
<rawString>Balzer, R.M. &amp;quot;A Global View Of Automatic Programming&amp;quot;, Proc. 3rd Joint Conference On Artificial Intelligence, August, 1973, pp. 494-499.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Balzer</author>
</authors>
<title>Imprecise Program Specification&amp;quot;,</title>
<date>1975</date>
<booktitle>Proc. Consiglio Nazi. Ric. 1st. Elaborazione Inf.,</booktitle>
<marker>3.</marker>
<rawString>Balzer, R.M. &amp;quot;Imprecise Program Specification&amp;quot;, Proc. Consiglio Nazi. Ric. 1st. Elaborazione Inf., 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Biermann</author>
</authors>
<title>Approaches To Automatic Programming,</title>
<date>1976</date>
<booktitle>in Advances in Computers, Volume 15,</booktitle>
<pages>1--63</pages>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<marker>4.</marker>
<rawString>Biermann, A. &amp;quot;Approaches To Automatic Programming, in Advances in Computers, Volume 15, Academic Press, New York, 1976, pp. 1-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Biermann</author>
<author>B Ballard</author>
<author>A Holler</author>
</authors>
<title>An Experimental Study Of Natural Language Programming,&amp;quot;</title>
<date>1979</date>
<tech>Report CS-1979-9,</tech>
<institution>Duke University,</institution>
<location>Durham, North Carolina,</location>
<contexts>
<context position="28767" citStr="[5]" startWordPosition="4834" endWordPosition="4834">s of imperative verbs are legitimate. 4.4 Syntactic Ambiguity The strategy for dealing with syntactic ambiguity is to attempt to anticipate the situations in which it is most likely to arise and to decide, whenever possible, which alternative is most reasonable. Having made such decisions, it is usually possible to order the grammar rules in such a way that the preferred parse is the one arrived at first, thus combining the efficiency of a blind search with the accuracy of a more extensive one. Perhaps surprisingly, the method has proven quite successful in meeting the stated objectives. (See [5].) This is due in part to the formulation of several general principles stemming from our observations of how natural language is employed in the NLC domain. The most important of these are: 1. Deep parses are generally preferred. Thus, &amp;quot;x in y in z&amp;quot; more often attaches the qualifier &amp;quot;in z&amp;quot; with y than with x when both readings are meaningful. 2. When ambiguity arises because of a conjunction, the intended conjuncts are likely to have similar type. This contrasts sharply with conventional programming languages, where operators rather than operands determine the &amp;quot;binding&amp;quot; in arithmetic expressi</context>
</contexts>
<marker>5.</marker>
<rawString>Biermann A., Ballard, B., and Holler, A. &amp;quot;An Experimental Study Of Natural Language Programming,&amp;quot; Report CS-1979-9, Duke University, Durham, North Carolina, July, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Biermann</author>
<author>R Krishnaswamy</author>
</authors>
<title>Constructing Programs From Example Computations&amp;quot;,</title>
<date>1976</date>
<journal>IEEE Transactions on Software Engineering,</journal>
<volume>6</volume>
<pages>141--153</pages>
<contexts>
<context position="11204" citStr="[6]" startWordPosition="1879" endWordPosition="1879">ng language and note that its English equivalent is relatively long, unreadable, and unwieldy. The solution to this problem is to include in the natural language processor the ability to handle such arithmetic expressions. Considering the complexity of any reasonable natural language processor, the cost of adding something like an arithmetic expression handler is modest. Other constructs from programming languages which are shown to be convenient could also be considered for inclusion. 1.3 Background The NLC system has grown out of an earlier series of studies on the &amp;quot;autoprogrammer&amp;quot; (Biermann[6]) and bears much resemblance to it. Program synthesis in both the current and the previous systems is based upon example calculations done by the user on displayed data structures. In the current system, the example is done in restricted English with all its power, which is a dramatic departure from the earlier approach, which simply involved pointing with a light pen. However, it is expected that many of the features from the autoprogrammer, such as &amp;quot;continue&amp;quot; and &amp;quot;automatic indexing&amp;quot;, will transfer quite naturally into NLC. This paper emphasizes the natural language aspects of the system, wh</context>
</contexts>
<marker>6.</marker>
<rawString>Biermann, A. and Krishnaswamy, R. &amp;quot;Constructing Programs From Example Computations&amp;quot;, IEEE Transactions on Software Engineering, September, 1976, pp. 141-153. American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 85 Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation</rawString>
</citation>
<citation valid="true">
<authors>
<author>D G Bobrow</author>
<author>A Ed Collins</author>
</authors>
<title>Representation and Understanding,</title>
<date>1975</date>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<marker>7.</marker>
<rawString>Bobrow, D.G. and Collins, A. Ed., Representation and Understanding, Academic Press, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Brown</author>
<author>R R Burton</author>
</authors>
<title>Multiple Representations Of Knowledge For Tutorial Reasoning&amp;quot;, in Representation and Understanding</title>
<date>1975</date>
<pages>311--349</pages>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<marker>8.</marker>
<rawString>Brown, J.S. and Burton, R.R. &amp;quot;Multiple Representations Of Knowledge For Tutorial Reasoning&amp;quot;, in Representation and Understanding (Bobrow, D.G. and Collins, A., Eds.), Academic Press, New York, 1975, pp. 311 - 349.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E F Codd</author>
</authors>
<title>Seven Steps to RENDEZVOUS With The Casual User&amp;quot;,</title>
<date>1974</date>
<booktitle>Presented at the IFIP-TC2 Conference on Data Base Management, Cargese, Corsica,</booktitle>
<tech>IBM Report J1333 (#20842),</tech>
<marker>9.</marker>
<rawString>Codd, E.F. &amp;quot;Seven Steps to RENDEZVOUS With The Casual User&amp;quot;, IBM Report J1333 (#20842), January 17, 1974. Presented at the IFIP-TC2 Conference on Data Base Management, Cargese, Corsica, April 1-5, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Cullingford</author>
</authors>
<title>Script Application: Computer Understanding of Newspaper Stories (Ph.D.</title>
<date>1978</date>
<tech>Dissertation). Research Report #116,</tech>
<institution>Yale University,</institution>
<marker>10.</marker>
<rawString>Cullingford, R.E. Script Application: Computer Understanding of Newspaper Stories (Ph.D. Dissertation). Research Report #116, Yale University, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E W Dijkstra</author>
</authors>
<title>On The Foolishness Of &apos;Natural Language Programming&apos;.</title>
<date>1978</date>
<tech>Unpublished report,</tech>
<contexts>
<context position="1953" citStr="[11]" startWordPosition="277" endWordPosition="277">tely efficient abilities for communicating with each other through natural language, and the possibility of similarly interacting with machines is worthy of investigation. The ability to program in natural language instead of traditional programming languages would enable people to use familiar constructs in expressing their requests, thus making machines accessible to a wider user group. Automatic speech recognition and synthesis devices could eventually smooth the communication even further. On the other hand, many problems could arise when natural language programming is attempted (Dijkstra[11], Petrick[25], Simmons[32]), and any such research must deal with them. For example, it has been argued that current natural language technol1 This material is based upon work supported by the National Science Foundation under Grant Numbers MCS74-14445-A01 and MC S-7904120. 2 Current address: Department of Computer and Information Science, The Ohio State University, Columbus, Ohio 43210. ogy is too primitive to handle a wide variety of syntactic and semantic constructs so that the user of such a system has the difficult task of learning what constitutes an acceptable input to the system. Inste</context>
</contexts>
<marker>11.</marker>
<rawString>Dijkstra, E.W. &amp;quot;On The Foolishness Of &apos;Natural Language Programming&apos;. Unpublished report, 1978.</rawString>
</citation>
<citation valid="false">
<authors>
<author>T Gallie</author>
<author>D Ramm</author>
</authors>
<title>Computer Science/I: An Introduction To Structured Programming. Kendall/Hunt,</title>
<location>Dubuque, Iowa,</location>
<marker>12.</marker>
<rawString>Gallie, T. and Ramm, D. Computer Science/I: An Introduction To Structured Programming. Kendall/Hunt, Dubuque, Iowa,</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Green</author>
</authors>
<title>A Summary Of The PSI Program Synthesis System&amp;quot;,</title>
<date>1977</date>
<booktitle>Proceedings Of 5th International Conference on Artificial Intelligence, Volume I,</booktitle>
<pages>380--381</pages>
<contexts>
<context position="1204" citStr="[13]" startWordPosition="174" endWordPosition="174"> used as a subroutine, thus extending the set of available operations and allowing larger English-language programs to be constructed hierarchically. In addition to discussing the transition network syntax and procedural semantics of the system, special attention is devoted to the following topics: the nature of imperative sentences in the matrix domain; the processing of non-trivial noun phrases; conjunction; pronominals; and programming constructs such as &amp;quot;if&amp;quot;, &amp;quot;repeat&amp;quot;, and procedure definition. 1. Introduction Natural language programming has been proposed by many authors (Balzer[2], Green[13], Heidorn[17], Petrick[25], Sammet[27], Woods[38]) as the best way for humans to input their commands to computers. Humans have developed exquisitely efficient abilities for communicating with each other through natural language, and the possibility of similarly interacting with machines is worthy of investigation. The ability to program in natural language instead of traditional programming languages would enable people to use familiar constructs in expressing their requests, thus making machines accessible to a wider user group. Automatic speech recognition and synthesis devices could eventu</context>
</contexts>
<marker>13.</marker>
<rawString>Green, C: &amp;quot;A Summary Of The PSI Program Synthesis System&amp;quot;, Proceedings Of 5th International Conference on Artificial Intelligence, Volume I, August 1977, pp. 380 - 381.</rawString>
</citation>
<citation valid="false">
<authors>
<author>C C Green</author>
<author>R J Waldinger</author>
<author>D R Barstow</author>
<author>R Elschlager</author>
<author>D B Lenat</author>
<author>B P McCune</author>
<author>D E Shaw</author>
<author>L I Steinberg</author>
</authors>
<title>Progress Report On Program-Understanding Systems&amp;quot;,</title>
<booktitle>Memo AIM-240, Stanford Artificial Intelligence Laboratory,</booktitle>
<location>Stanford, California.</location>
<marker>14.</marker>
<rawString>Green, C.C., Waldinger, R.J., Barstow, D.R., Elschlager, R., Lenat, D.B., McCune, B.P., Shaw, D.E., and Steinberg, L.I. &amp;quot;Progress Report On Program-Understanding Systems&amp;quot;, Memo AIM-240, Stanford Artificial Intelligence Laboratory, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Harris</author>
</authors>
<title>Status Report On ROBOT NL Query Processor&amp;quot;,</title>
<date>1978</date>
<journal>SIGART Newsletter,</journal>
<pages>3--4</pages>
<marker>15.</marker>
<rawString>Harris, L.R. &amp;quot;Status Report On ROBOT NL Query Processor&amp;quot;, SIGART Newsletter, August, 1978, pp. 3-4</rawString>
</citation>
<citation valid="true">
<authors>
<author>George E Heidorn</author>
</authors>
<title>Augmented Phrase Structure Grammars&amp;quot;,</title>
<date>1975</date>
<journal>IBM Thomas J. Watson Research</journal>
<location>Center, Yorktown Heights, New York,</location>
<marker>16.</marker>
<rawString>Heidorn, George E. &amp;quot;Augmented Phrase Structure Grammars&amp;quot;, IBM Thomas J. Watson Research Center, Yorktown Heights, New York, December, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George E Heidorn</author>
</authors>
<title>Automatic Programming Through Natural Language Dialogue: A Survey&amp;quot;,</title>
<date>1976</date>
<journal>IBM J. Res. Develop.,</journal>
<pages>302--313</pages>
<contexts>
<context position="1217" citStr="[17]" startWordPosition="175" endWordPosition="175">broutine, thus extending the set of available operations and allowing larger English-language programs to be constructed hierarchically. In addition to discussing the transition network syntax and procedural semantics of the system, special attention is devoted to the following topics: the nature of imperative sentences in the matrix domain; the processing of non-trivial noun phrases; conjunction; pronominals; and programming constructs such as &amp;quot;if&amp;quot;, &amp;quot;repeat&amp;quot;, and procedure definition. 1. Introduction Natural language programming has been proposed by many authors (Balzer[2], Green[13], Heidorn[17], Petrick[25], Sammet[27], Woods[38]) as the best way for humans to input their commands to computers. Humans have developed exquisitely efficient abilities for communicating with each other through natural language, and the possibility of similarly interacting with machines is worthy of investigation. The ability to program in natural language instead of traditional programming languages would enable people to use familiar constructs in expressing their requests, thus making machines accessible to a wider user group. Automatic speech recognition and synthesis devices could eventually smooth t</context>
</contexts>
<marker>17.</marker>
<rawString>Heidorn, George E. &amp;quot;Automatic Programming Through Natural Language Dialogue: A Survey&amp;quot;, IBM J. Res. Develop., July, 1976, pp. 302-313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George E Heidorn</author>
</authors>
<title>Natural Language Inputs To A Simulation Programming System.</title>
<date></date>
<location>Naval Postgraduate School,</location>
<marker>18.</marker>
<rawString>Heidorn, George E. Natural Language Inputs To A Simulation Programming System. Naval Postgraduate School, October,</rawString>
</citation>
<citation valid="true">
<authors>
<author>George E Heidorn</author>
</authors>
<title>Supporting A Computer-Directed Natural Language Dialogue For Automatic Business Programming&amp;quot;,</title>
<date>1976</date>
<journal>Research Report 26157, IBM Thomas J. Watson Research</journal>
<location>Center, Yorktown Heights, New York,</location>
<marker>19.</marker>
<rawString>Heidorn, George E. &amp;quot;Supporting A Computer-Directed Natural Language Dialogue For Automatic Business Programming&amp;quot;, Research Report 26157, IBM Thomas J. Watson Research Center, Yorktown Heights, New York, June, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary G Hendrix</author>
<author>Earl D Sacerdoti</author>
<author>Daniel Sagalowicz</author>
<author>Jonathan Slocum</author>
</authors>
<title>Developing A Natural Language Interface To Complex Data&amp;quot;,</title>
<date>1978</date>
<journal>ACM Trans. on Database Systems,</journal>
<pages>105--147</pages>
<marker>20.</marker>
<rawString>Hendrix, Gary G., Sacerdoti, Earl D., Sagalowicz, Daniel, and Slocum, Jonathan &amp;quot;Developing A Natural Language Interface To Complex Data&amp;quot;, ACM Trans. on Database Systems, June, 1978, pp. 105-147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary G Hendrix</author>
</authors>
<title>Human Engineering For Applied Natural Language Processing&amp;quot;,</title>
<date>1977</date>
<booktitle>Proceedings Of 5th International Conference on Artificial Intelligence, Volume I,</booktitle>
<pages>183--191</pages>
<marker>21.</marker>
<rawString>Hendrix, Gary G. &amp;quot;Human Engineering For Applied Natural Language Processing&amp;quot;, Proceedings Of 5th International Conference on Artificial Intelligence, Volume I, August, 1977, pp. 183-191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Pronoun Resolution&amp;quot;,</title>
<date>1976</date>
<tech>Research Report 76-1,</tech>
<institution>Department of Computer Sciences, City College of</institution>
<location>New York,</location>
<contexts>
<context position="36237" citStr="[22]" startWordPosition="6086" endWordPosition="6086">selves&amp;quot; 2. pronominal determiner &amp;quot;THAT entry&amp;quot; / &amp;quot;THOSE columns&amp;quot; 3. possessive determiner &amp;quot;ITS rows&amp;quot; / &amp;quot;THEIR columns&amp;quot; 4. pronominal ordinal &amp;quot;NEXT row&amp;quot; &amp;quot;OTHER entries&amp;quot; The fourth category is included among the listing of pronouns because the semantics involve most of the same principles. For instance, &amp;quot;the other entries&amp;quot; demands the semantics that would occur for &amp;quot;the entries other than ?&amp;quot;, where &amp;quot;?&amp;quot; represents the most general possible pronoun, having no type or number constraints. Pronoun reference is done by considering previous datareps rather than by traversing trees as described by Hobbs [22]. Specific guidelines for posing the eligible referents to pronouns in a reasonable order include, in order of importance: 1. In all cases, require type, number, and semantic constraints of the pronoun to agree with the datarep being examined. 2. Prefer more recently created datareps. 3. For case-level (operand) pronouns, try to match source with an old datarep source, destination with an old destination. 4. &amp;quot;Fuse&amp;quot;, or conjoin, singular datareps to produce a plural referent if necessary. Thus &amp;quot;Add row 1 to row 2.&amp;quot; &amp;quot;Double those rows.&amp;quot; entails creating the set consisting of rows 1 and 2 at the </context>
</contexts>
<marker>22.</marker>
<rawString>Hobbs, Jerry R. &amp;quot;Pronoun Resolution&amp;quot;, Research Report 76-1, Department of Computer Sciences, City College of New York, August, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Martin</author>
<author>M J Ginzberg</author>
<author>R Krumland</author>
<author>B Mark</author>
<author>M Morgenstern</author>
<author>B Niamir</author>
<author>A Sunguroff</author>
</authors>
<title>Internal Memos, Automatic Programming Group,</title>
<date>1974</date>
<location>MIT, Cambridge, Massachusetts,</location>
<marker>23.</marker>
<rawString>Martin, W.A., Ginzberg, M.J., Krumland, R., Mark, B., Morgenstern, M., Niamir, B., and Sunguroff, A. Internal Memos, Automatic Programming Group, MIT, Cambridge, Massachusetts, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Minsky</author>
</authors>
<title>A Framework For Representing Knowledge&amp;quot;,</title>
<date>1975</date>
<booktitle>in The Psychology Of Computer Vision,</booktitle>
<editor>Winston, P.H. ed.,</editor>
<publisher>McGraw-Hill,</publisher>
<location>New York,</location>
<marker>24.</marker>
<rawString>Minsky, M. &amp;quot;A Framework For Representing Knowledge&amp;quot;, in The Psychology Of Computer Vision, Winston, P.H. ed., McGraw-Hill, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Petrick</author>
</authors>
<title>On Natural Language Based Computer Systems&amp;quot;,</title>
<date>1976</date>
<booktitle>Also appears in Linguistic Structures Processing,</booktitle>
<pages>314--325</pages>
<editor>IBM J. Res. Develop.,</editor>
<publisher>North-Holland Publishing Company,</publisher>
<location>Amsterdam, Holland,</location>
<contexts>
<context position="1230" citStr="[25]" startWordPosition="176" endWordPosition="176">s extending the set of available operations and allowing larger English-language programs to be constructed hierarchically. In addition to discussing the transition network syntax and procedural semantics of the system, special attention is devoted to the following topics: the nature of imperative sentences in the matrix domain; the processing of non-trivial noun phrases; conjunction; pronominals; and programming constructs such as &amp;quot;if&amp;quot;, &amp;quot;repeat&amp;quot;, and procedure definition. 1. Introduction Natural language programming has been proposed by many authors (Balzer[2], Green[13], Heidorn[17], Petrick[25], Sammet[27], Woods[38]) as the best way for humans to input their commands to computers. Humans have developed exquisitely efficient abilities for communicating with each other through natural language, and the possibility of similarly interacting with machines is worthy of investigation. The ability to program in natural language instead of traditional programming languages would enable people to use familiar constructs in expressing their requests, thus making machines accessible to a wider user group. Automatic speech recognition and synthesis devices could eventually smooth the communicat</context>
</contexts>
<marker>25.</marker>
<rawString>Petrick, S.R. &amp;quot;On Natural Language Based Computer Systems&amp;quot;, IBM J. Res. Develop., July, 1976, pp. 314-325. Also appears in Linguistic Structures Processing, A. Zampolli, ed., North-Holland Publishing Company, Amsterdam, Holland,</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J Plath</author>
</authors>
<title>REQUEST: A Natural Language QuestionAnswering System&amp;quot;,</title>
<date>1976</date>
<journal>IBM J. Res. Develop.,</journal>
<pages>326--335</pages>
<marker>26.</marker>
<rawString>Plath, W.J. &amp;quot;REQUEST: A Natural Language QuestionAnswering System&amp;quot;, IBM J. Res. Develop., July, 1976, pp. 326-335.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Sammet</author>
</authors>
<title>The Use of English As A Programming Language&amp;quot;,</title>
<date>1966</date>
<journal>Comm. ACM,</journal>
<pages>228--229</pages>
<contexts>
<context position="1242" citStr="[27]" startWordPosition="177" endWordPosition="177">the set of available operations and allowing larger English-language programs to be constructed hierarchically. In addition to discussing the transition network syntax and procedural semantics of the system, special attention is devoted to the following topics: the nature of imperative sentences in the matrix domain; the processing of non-trivial noun phrases; conjunction; pronominals; and programming constructs such as &amp;quot;if&amp;quot;, &amp;quot;repeat&amp;quot;, and procedure definition. 1. Introduction Natural language programming has been proposed by many authors (Balzer[2], Green[13], Heidorn[17], Petrick[25], Sammet[27], Woods[38]) as the best way for humans to input their commands to computers. Humans have developed exquisitely efficient abilities for communicating with each other through natural language, and the possibility of similarly interacting with machines is worthy of investigation. The ability to program in natural language instead of traditional programming languages would enable people to use familiar constructs in expressing their requests, thus making machines accessible to a wider user group. Automatic speech recognition and synthesis devices could eventually smooth the communication even fur</context>
</contexts>
<marker>27.</marker>
<rawString>Sammet, J.E. &amp;quot;The Use of English As A Programming Language&amp;quot;, Comm. ACM, March, 1966, pp. 228-229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Schank</author>
</authors>
<title>Identification of Conceptualizations Underlying Natural Language&amp;quot;, in Computer Models Of Thought And Language,</title>
<date>1973</date>
<pages>187--247</pages>
<marker>28.</marker>
<rawString>Schank, R.C. &amp;quot;Identification of Conceptualizations Underlying Natural Language&amp;quot;, in Computer Models Of Thought And Language, R.C. Schank, R.C. and K.M. Colby, Eds., W.H. Freeman and Company, San Francisco, 1973, pp. 187-247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Schank</author>
<author>R Scripts Abelson</author>
</authors>
<title>Plans, Goals, And Understanding. Lawrence Erlbaum Associates,</title>
<date>1977</date>
<location>Hillsdale, New Jersey,</location>
<marker>29.</marker>
<rawString>Schank, R. and Abelson, R. Scripts, Plans, Goals, And Understanding. Lawrence Erlbaum Associates, Hillsdale, New Jersey, 1977.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R C Schank</author>
<author>K M Colby</author>
</authors>
<title>Computer Models of Thought And Language. W.H. Freeman and Company,</title>
<location>San Francisco,</location>
<marker>30.</marker>
<rawString>Schank, R.C. and Colby, K.M. Computer Models of Thought And Language. W.H. Freeman and Company, San Francisco,</rawString>
</citation>
<citation valid="true">
<authors>
<author>R F Simmons</author>
</authors>
<title>Natural Language Question Answering Systems:</title>
<date>1969</date>
<journal>Comm. ACM,</journal>
<pages>15--30</pages>
<marker>31.</marker>
<rawString>Simmons, R.F. &amp;quot;Natural Language Question Answering Systems: 1969&amp;quot;, Comm. ACM, January, 1970, pp. 15-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R F Simmons</author>
</authors>
<date>1978</date>
<booktitle>Personal Communication at TINLAP-2 Conference, Univ. of Illinois,</booktitle>
<contexts>
<context position="1979" citStr="[32]" startWordPosition="279" endWordPosition="279">or communicating with each other through natural language, and the possibility of similarly interacting with machines is worthy of investigation. The ability to program in natural language instead of traditional programming languages would enable people to use familiar constructs in expressing their requests, thus making machines accessible to a wider user group. Automatic speech recognition and synthesis devices could eventually smooth the communication even further. On the other hand, many problems could arise when natural language programming is attempted (Dijkstra[11], Petrick[25], Simmons[32]), and any such research must deal with them. For example, it has been argued that current natural language technol1 This material is based upon work supported by the National Science Foundation under Grant Numbers MCS74-14445-A01 and MC S-7904120. 2 Current address: Department of Computer and Information Science, The Ohio State University, Columbus, Ohio 43210. ogy is too primitive to handle a wide variety of syntactic and semantic constructs so that the user of such a system has the difficult task of learning what constitutes an acceptable input to the system. Instead of having to learn the </context>
</contexts>
<marker>32.</marker>
<rawString>Simmons, R.F. Personal Communication at TINLAP-2 Conference, Univ. of Illinois, July, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Schachter Stockwell</author>
<author>P</author>
<author>B Partee</author>
</authors>
<title>The Major Syntactic Structures Of English.</title>
<date>1973</date>
<pages>294--418</pages>
<publisher>and Winston, Inc.,</publisher>
<location>Holt, Rinehart</location>
<contexts>
<context position="20427" citStr="[33]" startWordPosition="3390" endWordPosition="3390">bicies, so the parser checks that a suitable one is found. START PARSE IMPERATIVE 1 PARSE NG PARSE VERBICLE 1 PARSE NG PARSE &amp;quot;.&amp;quot; SUCCEED Figure 5. A top-level parser for sentences of the form &amp;quot;add X to Y&amp;quot;. WORD Add to thee zero American Journal of Computational Linguistics, Volume 6, Number 2, April-June 1980 75 Alan W. Biermann and Bruce W. Ballard Toward Natural Language Computation 4.1.1 Conjunction Handling Although the routine of Figure 5 might be adequate for a large fraction of the sentences received by NLC, we decided to formulate a facility for handling a wide variety of conjunctions [33]. Toward this goal, a routine called MIX was designed as shown in Figure 6. START PARSE A ---- PARSE A ---&gt;PARSE &amp;quot;and&amp;quot; &lt;--PARSE PARSE A &gt; SUCCEED Figure 6. A simplified transition network for MIX A. Suppose A is a given construct and suppose xl, x2, and x3 are instances of that construct. Then MIX A will process forms such as x 1 x 1 and x2 x 1, x2, and x3 x 1 and x2 and x3 and others. If, for example, A represents the imperative clause construct, then MIX A will process &amp;quot;Add yl to y2, add y3 to y4, and add y5 to y6.&amp;quot; If A is the unconjoined noun group, then MIX A will process &amp;quot;row 1, row 2, a</context>
</contexts>
<marker>33.</marker>
<rawString>Stockwell, R. Schachter, P., and Partee, B. The Major Syntactic Structures Of English. Holt, Rinehart and Winston, Inc., New York, 1973, pp. 294-418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick B Thompson</author>
<author>Bozena H Thompson</author>
</authors>
<title>Practical Natural Language Processing: The REL System as Prototype&amp;quot;,</title>
<date>1975</date>
<booktitle>in Advances In Computers, Volume 13,</booktitle>
<pages>109--168</pages>
<publisher>Eds., Academic Press,</publisher>
<location>New York,</location>
<marker>34.</marker>
<rawString>Thompson, Frederick B. and Thompson, Bozena H. &amp;quot;Practical Natural Language Processing: The REL System as Prototype&amp;quot;, in Advances In Computers, Volume 13, M. Rubinoff and M.C. Yovits, Eds., Academic Press, New York, 1975, pp. 109-168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Waltz</author>
</authors>
<title>An English Language Question Answering System For A Large Relational Database&amp;quot;,</title>
<date>1978</date>
<journal>Comm. ACM,</journal>
<pages>526--539</pages>
<marker>35.</marker>
<rawString>Waltz, D.L. &amp;quot;An English Language Question Answering System For A Large Relational Database&amp;quot;, Comm. ACM, July, 1978, pp. 526-539.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Waltz</author>
<author>ed</author>
</authors>
<title>Natural Language Interfaces&amp;quot;,</title>
<date>1977</date>
<journal>SIGART Newsletter,</journal>
<marker>36.</marker>
<rawString>Waltz, D.L., ed. &amp;quot;Natural Language Interfaces&amp;quot;, SIGART Newsletter, February, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>Understanding Natural Language,</title>
<date>1972</date>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="24227" citStr="[37]" startWordPosition="4082" endWordPosition="4082">m bottom row to row 3.&amp;quot; &amp;quot;Bottom&amp;quot; in this example is the place from which the ordinal processor begins counting. Some other words that can fit into this slot are &amp;quot;right&amp;quot;, &amp;quot;left&amp;quot;, &amp;quot;top&amp;quot;, and &amp;quot;last&amp;quot;. The fourth type of noun group is the noun procedure group, which refers to a procedure, a command, or a set of commands in the NLC input. This type is illustrated in &amp;quot;Repeat the last three commands ten times.&amp;quot; &amp;quot;Double the entries the third command incremented.&amp;quot; Only the operand noun groups will be discussed in detail here. Operand level noun groups follow a format similar to the one given by Winograd[37]. Let OPT be a routine which optionally calls a set of routines. As an illustration, OPT DETERMINER calls routines to parse a determiner If those routines fail, however, OPT succeeds anyway, assuming that the noun group exists without a determiner. The basic format for the operand level noun group parser, given in Figure 8, is completely exercised by the noun group &amp;quot;the first three positive matrix 1 entries which are odd&amp;quot; DETERMINER: the ORDINAL: first NUMBER: three ADJECTIVE: positive CLASSIFIER: matrix 1 NOUN: entries QUALIFIER: which are odd Since OPT is used to look for most of the constit</context>
</contexts>
<marker>37.</marker>
<rawString>Winograd, T. Understanding Natural Language, Academic Press, New York, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>A Personal View Of Natural Language Understanding&amp;quot;, in &amp;quot;Natural Language Interfaces&amp;quot;,</title>
<date>1977</date>
<journal>SIGART Newsletter,</journal>
<pages>17--20</pages>
<contexts>
<context position="1253" citStr="[38]" startWordPosition="178" endWordPosition="178">available operations and allowing larger English-language programs to be constructed hierarchically. In addition to discussing the transition network syntax and procedural semantics of the system, special attention is devoted to the following topics: the nature of imperative sentences in the matrix domain; the processing of non-trivial noun phrases; conjunction; pronominals; and programming constructs such as &amp;quot;if&amp;quot;, &amp;quot;repeat&amp;quot;, and procedure definition. 1. Introduction Natural language programming has been proposed by many authors (Balzer[2], Green[13], Heidorn[17], Petrick[25], Sammet[27], Woods[38]) as the best way for humans to input their commands to computers. Humans have developed exquisitely efficient abilities for communicating with each other through natural language, and the possibility of similarly interacting with machines is worthy of investigation. The ability to program in natural language instead of traditional programming languages would enable people to use familiar constructs in expressing their requests, thus making machines accessible to a wider user group. Automatic speech recognition and synthesis devices could eventually smooth the communication even further. On th</context>
</contexts>
<marker>38.</marker>
<rawString>Woods, W.A. &amp;quot;A Personal View Of Natural Language Understanding&amp;quot;, in &amp;quot;Natural Language Interfaces&amp;quot;, SIGART Newsletter, February, 1977, pp. 17-20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
<author>R M Kaplan</author>
<author>B Nash-Weber</author>
</authors>
<title>The Lunar Sciences Natural Language Information System:</title>
<date>1972</date>
<tech>Final Report. Report Number 2378,</tech>
<institution>Bolt, Beranek and Newman, Inc.,</institution>
<location>Cambridge, Massachusetts,</location>
<marker>39.</marker>
<rawString>Woods, W.A., Kaplan, R.M., and Nash-Weber, B. The Lunar Sciences Natural Language Information System: Final Report. Report Number 2378, Bolt, Beranek and Newman, Inc., Cambridge, Massachusetts, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Transition Network Grammars For Natural Language Analysis&amp;quot;,</title>
<date>1970</date>
<journal>Comm. ACM,</journal>
<pages>591</pages>
<contexts>
<context position="13092" citStr="[40]" startWordPosition="2173" endWordPosition="2173">e conventional sequence of stages: lexical, syntactic, and semantic processing. The scanner finds the tokens in the input sentence and looks them up in the dictionary. It performs some morphological processing and spelling correction for items not appearing in the dictionary. Additionally, abbreviations (such as &amp;quot;col&amp;quot; for &amp;quot;column&amp;quot;) and spelled-out numbers and ordinals (&amp;quot;twenty-two&amp;quot;, &amp;quot;seventh&amp;quot;, etc.) are recognized. The identified words with their meanings are passed on to the parser, which is programmed with nondeterministic transition nets similar to the augmented transition networks of Woods[40]. The parser has the ability to screen out many syntactically correct but semantically meaningless structures so that the first parse it finds is usually correct. The parser output goes to the flowof-control semantics routines which make decisions about the nature of the input command and then properly guide it through subsequent processing. The input sentence may be a simple request for a system defined computation or it may be a flow-ofcontrol command such as a user-defined subroutine call. An example of the first case is &amp;quot;Add row 1 to row 2.&amp;quot; Here flow-of-control processing sends the senten</context>
</contexts>
<marker>40.</marker>
<rawString>Woods, W.A. &amp;quot;Transition Network Grammars For Natural Language Analysis&amp;quot;, Comm. ACM, October, 1970, pp. 591-</rawString>
</citation>
<citation valid="false">
<authors>
<author>W Alan</author>
</authors>
<title>Biermann is an associate professor in the Department of Computer Science at Duke University. He received the Ph.D. degree in electrical engineering and computer science from the University of California at Berkeley in 1968. Bruce W. Ballard is an assistant professor in the Department of Computer and Information Science at The Ohio State University. He received the Ph.D. degree in computer science from Duke University in</title>
<date>1979</date>
<marker>606.</marker>
<rawString> Alan W. Biermann is an associate professor in the Department of Computer Science at Duke University. He received the Ph.D. degree in electrical engineering and computer science from the University of California at Berkeley in 1968. Bruce W. Ballard is an assistant professor in the Department of Computer and Information Science at The Ohio State University. He received the Ph.D. degree in computer science from Duke University in 1979.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>