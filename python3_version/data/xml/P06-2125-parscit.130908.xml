<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000042">
<title confidence="0.998754">
An HMM-Based Approach to Automatic Phrasing for Mandarin Text-
to-Speech Synthesis
</title>
<author confidence="0.999066">
Jing Zhu
</author>
<affiliation confidence="0.996622">
Department of Electronic Engineering
Shanghai Jiao Tong University
</affiliation>
<email confidence="0.994543">
zhujing@sjtu.edu.cn
</email>
<author confidence="0.994628">
Jian-Hua Li
</author>
<affiliation confidence="0.9980975">
Department of Electronic Engineering
Shanghai Jiao Tong University
</affiliation>
<email confidence="0.98552">
lijh888@sjtu.edu.cn
</email>
<sectionHeader confidence="0.997247" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999498272727273">
Automatic phrasing is essential to Mandarin text-
to-speech synthesis. We select word format as
target linguistic feature and propose an HMM-
based approach to this issue. Then we define four
states of prosodic positions for each word when
employing a discrete hidden Markov model. The
approach achieves high accuracy of roughly 82%,
which is very close to that from manual labeling.
Our experimental results also demonstrate that
this approach has advantages over those part-of-
speech-based ones.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999747658536586">
Owing to the limitation of vital capacity and
contextual information, breaks or pauses are
always an important ingredient of human speech.
They play a great role in signaling structural
boundaries. Similarly, in the area of text-to-
speech (TTS) synthesis, assigning breaks is very
crucial to naturalness and intelligibility,
particularly in long sentences.
The challenge in achieving naturalness mainly
results from prosody generation in TTS synthesis.
Generally speaking, prosody deals with phrasing,
loudness, duration and speech intonation. Among
these prosodic features, phrasing divides
utterances into meaningful chunks of information,
called hierarchic breaks. However, there is no
unique solution to prosodic phrasing in most
cases. Different solution in phrasing can result in
different meaning that a listener could perceive.
Considering its importance, recent TTS research
has focused on automatic prediction of prosodic
phrase based on the part-of-speech (POS) feature
or syntactic structure(Black and Taylor, 1994;
Klatt, 1987; Wightman, 1992; Hirschberg 1996;
Wang, 1995; Taylor and Black, 1998).
To our understanding, POS is a grammar-
based structure that can be extracted from text.
There is no explicit relationship between POS
and the prosodic structure. At least, in Mandarin
speech synthesis, we cannot derive the prosodic
structure from POS sequence directly. By
contrast, a word carries rich information related
to phonetic feature. For example, in Mandarin, a
word can reveal many phonetic features such as
pronunciation, syllable number, stress pattern,
tone, light tone (if available) and retroflexion (if
available) etc. So we begin to explore the role of
word in predicting prosodic phrase and propose a
word-based statistical method for prosodic-
phrase grouping. This method chooses Hidden
Markov Model (HMM) as the training and
predicting model.
</bodyText>
<sectionHeader confidence="0.999931" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999671611111111">
Automatic prediction of prosodic phrase is a
complex task. There are two reasons for this
conclusion. One is that there is no explicit
relationship between text and phonetic features.
The other lies in the ambiguity of word
segmentation, POS tagging and parsing in the
Chinese natural language processing. As a result,
the input information for the prediction of
prosodic phrase is quite “noisy”. We can find
that most of published methods, including (Chen
et al., 1996; Chen et al., 2000; Chou et al., 1996;
Chou et al., 1997; Gu et al., 2000; Hu et al., 2000;
Lv et al., 2001; Qian et al., 2001; Ying and Shi,
2001) do not make use of high-level syntactic
features due to two reasons. Firstly, it is very
challenging to parse Chinese sentence because
no grammar is formal enough to be applied to
Chinese parsing. In addition, lack of
</bodyText>
<page confidence="0.970572">
977
</page>
<bodyText confidence="0.927924777777778">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 977–982,
Sydney, July 2006. c�2006 Association for Computational Linguistics
morphologies also causes many problems in
parsing. Secondly, the syntactic structure is not
isomorphic to the prosodic phrase structure.
Prosodic phrasing remains an open task in the
Chinese speech generation. In summary, all the
known methods depend on POS features more or
less.
</bodyText>
<sectionHeader confidence="0.9987" genericHeader="method">
3 Word-based Prediction
</sectionHeader>
<bodyText confidence="0.999761818181818">
As noted previously, the prosodic phrasing is
associated with words to some extent in
Mandarin TTS synthesis. We observe that some
function words (such as “ ”) never occur in
phrase-initial position. Some prepositions seldom
act as phrase-finals. These observations lead to
investigating the role of words in prediction of
prosodic phrase. In addition, large-scale training
data is readily available, which enables us to
apply data-driven models more conveniently
than before.
</bodyText>
<subsectionHeader confidence="0.98604">
3.1 The Model
</subsectionHeader>
<bodyText confidence="0.989047">
The sentence length in real text can vary
significantly. A model with a fixed-dimension
input does not fit the issue in prosodic breaking.
Alternatively, the breaking prediction can be
converted into an optimization problem that
allows us to adopt the hidden Markov model
(HMM).
An HMM for discrete symbol observations is
characterized by the following:
- the state set Q ={qi}, where 1 ≤ i ≤ N, N is the
number of states
- the number of distinct observation symbol per
state M
-the state-transition probability distribution
A={aij}, where
</bodyText>
<equation confidence="0.9815345">
aij=P[qt+1=j|qt=i], 1 ≤ i,j≤
N
</equation>
<bodyText confidence="0.868928">
-the observation symbol probability
distribution B={bj(k)}, where
</bodyText>
<equation confidence="0.95888">
bj (k) = P[ot = vk  |qt = j] ,
1≤ i,j≤ N
</equation>
<bodyText confidence="0.987975">
- the initial state distribution π={πi}, where πi
=P[ot=vk|qt=j] , 1 ≤ i,j ≤ M .
The complete parameter set of the model is
denoted as a compact notation λ=(A,B,π).
Here, we define our prosodic positions for a
word to apply the HMM as follows.
</bodyText>
<equation confidence="0.636863">
0 phrase-initial
1 phrase-medial
2 phrase-final
3 separate
</equation>
<bodyText confidence="0.999281">
This means that Q can be represented as
Q={0,1,2,3}, corresponding to the four prosodic
positions. The word itself is defined as a discrete
symbol observation.
</bodyText>
<subsectionHeader confidence="0.999107">
3.2 The Corpus
</subsectionHeader>
<bodyText confidence="0.9998171">
The text corpus is divided into two parts. One
serves as training data. This part contains 17,535
sentences, among which, 9,535 sentences have
corresponding utterances. The other is a test set,
which includes 1,174 sentences selected from the
Chinese People’s Daily. The sentence length,
namely the number of words in a sentence varies
from 1 to 30. The distribution of word length,
phrase length and sentence length(all in character
number) is shown in Figure 1.
</bodyText>
<figure confidence="0.44523">
Word length Phrase length Sentence length
</figure>
<figureCaption confidence="0.978448">
Figure 1. Statistical results from the corpus
</figureCaption>
<bodyText confidence="0.999822133333333">
In a real text, there may exist words that are
difficult to enumerate in the system lexicon,
called “non-standard” words (NSW). Examples
of NSW are proper names, digit strings,
derivative words by adding prefix or suffix.
Proper names include person name, place name,
institution name and abbreviations, etc.
Alternatively, some characters are usually
viewed as prefix and suffix in Chinese text. For
instance, the character (pseudo-) always
serves as a prefix, while another character (-
like) serves as a suffix. There are 130 analogous
Chinese characters have been collected roundly.
A word segmentation module is designed to
identify these non-standard words.
</bodyText>
<subsectionHeader confidence="0.997911">
3.3 Parameter estimation
</subsectionHeader>
<bodyText confidence="0.9999006">
Parameter estimation of the model can be treated
as an optimization problem. The parametric
methods will be optimal if distribution derived
from the training data is in the class of
distributions being considered. But there is no
</bodyText>
<page confidence="0.992417">
978
</page>
<bodyText confidence="0.94463425">
known way so far for maximizing the probability
of the observation sequence in a closed form. In
the present approach, a straightforward,
reasonable yet, method to re-estimate parameters
of the HMM is applied. Firstly, statistics for the
occurring times of word, prosodic position,
prosodic-position pair are conducted. Secondly,
the simple ratio of occurring times is used to
calculate the probability distribution. The
following expressions are used to implement
calculations,
State probability distribution
, 1 ≤ i ≤ N
Fi is the occurring times of state qi
the state-transition probability
distribution A = {ai j } ,
a ij ≈ Fij, 1 ≤ i, j ≤ N , Fij is the occurringFi
times of state pair (qi,qj).
represent the zero valued observation-
probabilities.
</bodyText>
<subsectionHeader confidence="0.935648">
3.5 The search procedure
</subsectionHeader>
<bodyText confidence="0.999953625">
In this stage, an optimal state sequence that
explains the given observations by the model is
searched. That is to say, for the input sentence,
an optimal prosodic-position sequence is
predicted with the HHM. Instead of using the
popular Viterbi algorithm, which is
asymptotically optimal, we apply the Forward-
Backward procedure to conduct searching.
</bodyText>
<subsectionHeader confidence="0.754514">
Backward and forward search
</subsectionHeader>
<bodyText confidence="0.968614666666667">
All the definitions described in (Rabiner, 1999)
are followed in the present approach.
The forward procedure
</bodyText>
<equation confidence="0.981113818181818">
forward variable: αt (i) = P(o1 o2 ... ot , qt = i  |λ )
initialization: α1(i) = πi bi (o1), 1≤ i≤ N.
induction:
�N 1
α j
( ) = � α i a b o
( ) � ( ), 1 t T - 1 , 1 j N
≤ ≤ ≤ ≤
t 1 t ij j t+1
+ �
� �
� i = 1 �
N
Fi
≈ N
P[qi]
Fj
�=
j 1
.
Observation probability distribution
B = {bj(k)} ,
termination: P(O  |λ) =
i=1
where T is the number of observations.
α ( )
T i
bj (k) ≈ F(q = j,o = vk)
F
j
b j(k) ∝
P q
[
</equation>
<bodyText confidence="0.828111">
where
</bodyText>
<equation confidence="0.9953375">
F(q = j,o = vk) = E F(qt = j,o=
t
</equation>
<bodyText confidence="0.997542">
is the concurring times of state qj and observation
vk.
With respect to the proper names, all the person
names are dealt with identically. This is based on
an assumption that the proper names of
individual category have the same usage.
</bodyText>
<subsectionHeader confidence="0.968305">
3.4 Parameter adjustment
</subsectionHeader>
<bodyText confidence="0.999928">
Note that the training corpus is discrete, finite set.
The parameter set resulting from the limited
samples cannot converge to the “true” values
with probability. In particular, some words may
not be included in the corpus. In this case, the
above expressions for training may result in zero
valued observation-probability. This, of course,
is unexpected. The parameters should be adjusted
after the automatic model training. The way is to
use a sufficiently small positive constant ε to
</bodyText>
<equation confidence="0.9061939">
The backward procedure
backward variable:
A(i)=P(ot+1ot+2 ... oT |qt =i,λ)
initialization βT (i) =1, 1≤ i≤ N
induction:
N
βt (i)=&apos;,aijbj(ot+1)βt+1(j) t=T- 1 , T- 2 ,... 1, 1≤i≤ N
j
=1
The “optimal” state sequence
</equation>
<bodyText confidence="0.91436575">
posteriori probability variable: γt (i) , this is
the probability of being in state i at time t given
the observation sequence O and the model λ. It
can be expressed as follows:
</bodyText>
<equation confidence="0.984177090909091">
~=
i 1 α β
t t
() ( )
i i
most likely state *
qt at time t:
qt = *arg max [ ( )] 1 t T
γt i ≤ ≤ .
1 i
≤ ≤ N
</equation>
<bodyText confidence="0.990324">
Here comes a question. It is, whether the
optimal state sequence means the optimal
path.
</bodyText>
<equation confidence="0.979998823529412">
α β
( ) ( )
i i
t t
,
O
λ
)
N
(i)=P(qt =i|
γt
F q j , o v k )
( = =
]
j
)
vk
</equation>
<page confidence="0.989554">
979
</page>
<bodyText confidence="0.974733555555555">
Search based on dynamic programming
The preceding search procedure targets the
optimal state sequence satisfying one criterion.
But it does not reflect the probability of
occurrence of sequences of states. This issue is
explored based on a dynamic programming (DP)
like approach, as described below.
For convenience, we illustrate the problem as
shown in Figure 2.
</bodyText>
<figureCaption confidence="0.994939">
Figure 2. Illustration of search procedure in trellis
(quoted from [Rabiner, 1999])
</figureCaption>
<bodyText confidence="0.999931346153846">
From Figure 2, it can be seen that the transition
from state i to state j only occurs in the two
consecutive stages, namely time synchronous.
Totally, there are T stages, N 2 T arcs. Therefore,
the optimal-path issue is a multi-stage
optimization problem, which is similar to the DP
problem. The slight difference lies in that a node
in the conventional DP problem does not contain
any additional attribute, while a node in HMM
carries the attribute of observation probability
distribution. Considering this difference, we
modify the conventional DP approach in the
following way.
In the trellis above, we add a virtual node
(state), where the start node qs corresponding to
time 0 before time 1. All the transitions from qs
to nodes in the first stage (time 1) equal to 1/N.
Furthermore, all the observation probability
distributions equal to 1/M. Denoting the optimal
path from qs to the node qi of time t as path(t,i),
path(t,i) is a set of sequential states. Accordingly,
we denote the score of path(t,i) as s(t,i). Then,
s(t,i) is associated with the state-transition
probability distribution and observation
probability distribution. We describe the
induction process as follows.
</bodyText>
<equation confidence="0.972703363636363">
initialization:
s(0,i) = 1 , 1 i N
≤ ≤
M N
×
path(0, i) = {qs }.
induction:
given
j s t j
, ( , )= max [s(t −1, i) × bi (ot) × aij ], 1≤ t≤ T ,
1≤i≤N
denotes
k = arg max [s(t −1, i) × bi (ot) × aij ]
1 i
≤ ≤ N , then
path(t,j)=path(t-1,k) ∪ {k}.
termination:
at time T, k arg
= max s (T, i) .
1≤i≤N
then path(T,k) - {qs} is the
optimal path.
</equation>
<bodyText confidence="0.99996605">
Basically, the main idea of our approach lies in
that if the final optimal path passes a node j at
time t, it passes all the nodes in path(t,j)
sequentially. This idea is similar to the forward
procedure of DP. We can begin with the
termination T and derive an alternative approach.
As for time complexity, the above trellis can be
viewed as a special DAG. The state transition
from time t to time t+1 requires 2N2 calculations,
resulting in the time complexity O(TN 2).
Intuitively, the optimal path differs from the
optimal state sequence generated by the
Forward-Backward procedure. The underlying
idea of Forward-Backward procedure is that the
target state sequence can explain the
observations optimally. To support our claim,
we can give a simple example (T=2, N=2,π
=[0.5,0.5]T ) as follows:
Apparently, the optimal state sequence is (1,1),
while the optimal path is {1,2}.
</bodyText>
<sectionHeader confidence="0.994502" genericHeader="evaluation">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.998033">
Before reporting the experimental results, we
first define the criterion of evaluation and the
related issues.
</bodyText>
<figure confidence="0.685526">
1 2
</figure>
<figureCaption confidence="0.916555">
Figure 3. Optimal state sequence vs. optimal path
</figureCaption>
<figure confidence="0.9971182">
1
0.82
1.0
2
0.18
0.0
0.9
0.1
0.8
0.2
</figure>
<page confidence="0.977725">
980
</page>
<subsectionHeader confidence="0.986568">
4.1 The evaluation method
</subsectionHeader>
<bodyText confidence="0.999890588235294">
After analyzing the existing evaluation methods,
we feel that the method proposed in (Taylor and
Black, 1998) is appropriate for our application.
By employing this method, we can examine each
word pair in the test set. If the algorithm
generated break fully matches the manually
labeled break, it marks correct. Similarly, if there
is no labeled break and the algorithm does not
place a break, it also marks correct. Otherwise,
an error arises. To emphasize the effectiveness
of break prediction, we define the adjusted score,
Sa, as follows.
where
S is the ratio of the number of correct word
pairs to the total number of word pairs;
B is the ratio of non-breaks to the number
of word-pairs.
</bodyText>
<subsectionHeader confidence="0.997088">
4.2 The test corpora
</subsectionHeader>
<bodyText confidence="0.981100272727273">
From the perspective of perception, multiple
predictions of prosodic phrasing may be
acceptable in many cases. At the labeling stage,
three experts (E1, E2, E3) were requested to
label 1,174 sentences independently. Experts
first read the sentences silently. Then, they
marked the breaks in sentences independently.
Table 1 and 2 show their labeling differences in
terms of S and Sa, respectively.
Table 1 indicates that any two can achieve a
consistency of roughly 87% among three experts.
</bodyText>
<subsectionHeader confidence="0.997617">
4.3 The results
</subsectionHeader>
<bodyText confidence="0.99919945">
To evaluate the approaches mentioned above, we
conducted a series of experiments. In all our
experiments, we assume that no breaking is
necessary for those sentences that are shorter
than the average phrase length and remove them
in the statistic computation. For the approaches
based on HMM path, we further define that the
initial and final words of a sentence can only
assume two state values, namely, (phrase initial,
separate) and (phrase final, separate),
respectively. With this definition, we modify the
approach HMM-Path to HMM-Path-I.
Alternatively, to investigate acceptance, we also
calculate the matching score between the
approaches and any expert (We assume the
prediction is acceptable if the predicted phrase
sequence matches any of three phrase sequences
labeled by the experts). By employing the
preceding criterion, we achieve the results as
shown in Table 3 and 4.
</bodyText>
<table confidence="0.9884425">
E1 E2 E3 Any
HMM 0.78 0.77 0.77 0.85
HMM-path 0.79 0.77 0.78 0.85
HMM-path-I 0.82 0.80 0.82 0.88
</table>
<tableCaption confidence="0.992323">
Table 3. Matching scores of 3 approaches
</tableCaption>
<table confidence="0.998625">
E1 E2 E3 Any
HMM 0.55 0.53 0.44 0.66
HMM-path 0.52 0.54 0.44 0.67
HMM-path-I 0.62 0.60 0.55 0.74
</table>
<tableCaption confidence="0.999703">
Table 4. Adjusted matching scores of 3 approaches
</tableCaption>
<bodyText confidence="0.999872571428572">
A sentence consumes less than 0.3 ms on
average for all the evaluated methods. So they
are all computationally efficient. Alternatively,
we compared the HMM-based approach base on
word format and some POS-based ones on the
same training set and test set. Overall, HMM-
path-I can achieve high accuracy by about 10%.
</bodyText>
<sectionHeader confidence="0.986405" genericHeader="conclusions">
5 Conclusions/Discussions
</sectionHeader>
<bodyText confidence="0.9999819">
We described an approach to automatic prosodic
phrasing for Mandarin TTS synthesis based on
word format and HMM and its variants. We also
evaluated these methods through experiments
and demonstrated promising results. According
to the experimental results, we can conclude that
word-based prediction is an effective approach
and has advantages over the POS-based ones. It
confirms that the syllable number of a word has
substantial impact on prosodic phrasing.
</bodyText>
<sectionHeader confidence="0.9921" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.7194125">
Black, A.W., Taylor, P., 1994. “Assigning
intonational elements and prosodic phrasing for
</bodyText>
<figure confidence="0.959850714285714">
Sa
S B
−
−
B
=
1
</figure>
<table confidence="0.862473">
E1 E2 E3
E1 1.00 0.87 0.87
E2 0.87 1.00 0.86
E3 0.87 0.86 1.00
</table>
<tableCaption confidence="0.651485666666667">
Table 1.
Three experts’
matching scores
</tableCaption>
<table confidence="0.9420905">
E1 E2 E3
E1 1.00 0.74 0.67
E2 0.74 1.00 0.66
E3 0.72 0.72 1.00
</table>
<tableCaption confidence="0.67644">
Table 2.
Three experts’
adjusted matching
scores
</tableCaption>
<page confidence="0.993217">
981
</page>
<reference confidence="0.998430275862069">
English speech synthesis from high level
linguistic input”, Proc. ICSLIP
Chen, S.H., Hwang, S.H., Wang, Y.R., 1998.
“An RNN-based prosodic information
synthesizer for Mandarin text-to-speech”, IEEE
Trans. Speech Audio Processing, 6: 226-239.
Chen, Y.Q., Gao, W., , Zhu, T.S., Ma, J.Y., 2000.
“Multi-strategy data mining on Mandarin
prosodic patterns”, Proc. ISCLIP
Chou, F.C., Tseng, C.Y., Lee, L.S. 1996.
“Automatic generation of prosodic structure for
high quality Mandarin speech synthesis”, Proc.
ICSLP
Chou, F.C, Tseng, C.Y, Chen, K.J., Lee, L.S,
1997. “A Chinese text-to-speech system based
on part-of-speech analysis, prosodic modeling
and non-uniform units”, ICASSP’97
Klatt, D.H., 1987, “Review of text-to-speech
conversion for English”, J. Acoust. Soc. Am.,
182: 737-79
Gu, Z.L, Mori, H., Kasuya, H. 2000. “Prosodic
variation of focused syllables of disyllabic word
in Mandarin Chinese”, Proc. ICSLP,
Hirschberg, J., 1996. “Training intonational
phrasing rules automatically for English and
Spanish text-to-speech”, Speech Communication,
18:281-290
Hu, Y., Liu, Q.F., Wang, R.H., 2000, “Prosody
generation in Chinese synthesis using the
template of quantified prosodic unit and base
intonation contour”, Proc. ICSLIP
Lu, S.N., He, L., Yang, Y.F., Cao, J.F., 2000,
“Prosodic control in Chinese TTS system”, Proc.
ICSLP,
Lv, X., Zhao, T.J., Liu, Z.Y., Yang M.Y., 2001,
“Automatic detection of prosody phrase
boundaries for text-to-speech system”, Proc.
IWPT
Qian, Y., Chu, M., Peng, H., 2001,
“Segmenting unrestricted Chinese text into
prosodic words instead of lexical words”, Proc.
ICASSP.
Rabiner, L., 1999, Fundamentals of Speech
Recognition, pp.336, Prentice-Hall and Tsinghua
Univ. Press, Beijing
Taylor P., Black A.W., 1998, “Assigning phrase
breaks from part-of-speech sequences”,
Computer Speech and Language, 12: 99-117,
Wang, M.Q., Hirschberg, J., 1995, “Automatic
classification of intonational phrase boundaries”,
Computer Speech and Language, pp.175-196,
Vol. 6,
Wightman, C.W., 1992, “Segmental durations in
the vicinity of prosodic phrase boundaries”, J.
Acoust. Soc. Am., 91:1707-1717
Ying, Z.W., Shi, X.H., 2001, “An RNN-based
algorithm to detect prosodic phrase for Chinese
TTS”, Proc. ICASSP
</reference>
<page confidence="0.997154">
982
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.402307">
<title confidence="0.9941595">An HMM-Based Approach to Automatic Phrasing for Mandarin Textto-Speech Synthesis</title>
<author confidence="0.999542">Jing Zhu</author>
<affiliation confidence="0.896041">Department of Electronic Engineering Shanghai Jiao Tong University</affiliation>
<email confidence="0.804258">zhujing@sjtu.edu.cn</email>
<author confidence="0.998807">Jian-Hua Li</author>
<affiliation confidence="0.963407">Department of Electronic Engineering Shanghai Jiao Tong University</affiliation>
<email confidence="0.741019">lijh888@sjtu.edu.cn</email>
<abstract confidence="0.997613333333333">Automatic phrasing is essential to Mandarin textto-speech synthesis. We select word format as target linguistic feature and propose an HMMbased approach to this issue. Then we define four states of prosodic positions for each word when employing a discrete hidden Markov model. The approach achieves high accuracy of roughly 82%, which is very close to that from manual labeling. Our experimental results also demonstrate that this approach has advantages over those part-ofspeech-based ones.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>English speech synthesis from high level linguistic input”,</title>
<booktitle>Proc. ICSLIP</booktitle>
<marker></marker>
<rawString>English speech synthesis from high level linguistic input”, Proc. ICSLIP</rawString>
</citation>
<citation valid="true">
<authors>
<author>S H Chen</author>
<author>S H Hwang</author>
<author>Y R Wang</author>
</authors>
<title>An RNN-based prosodic information synthesizer for Mandarin text-to-speech”,</title>
<date>1998</date>
<journal>IEEE Trans. Speech Audio Processing,</journal>
<volume>6</volume>
<pages>226--239</pages>
<marker>Chen, Hwang, Wang, 1998</marker>
<rawString>Chen, S.H., Hwang, S.H., Wang, Y.R., 1998. “An RNN-based prosodic information synthesizer for Mandarin text-to-speech”, IEEE Trans. Speech Audio Processing, 6: 226-239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Q Chen</author>
<author>W Gao</author>
</authors>
<title>Multi-strategy data mining on Mandarin prosodic patterns”,</title>
<date>2000</date>
<booktitle>Proc. ISCLIP</booktitle>
<marker>Chen, Gao, 2000</marker>
<rawString>Chen, Y.Q., Gao, W., , Zhu, T.S., Ma, J.Y., 2000. “Multi-strategy data mining on Mandarin prosodic patterns”, Proc. ISCLIP</rawString>
</citation>
<citation valid="true">
<authors>
<author>F C Chou</author>
<author>C Y Tseng</author>
<author>L S Lee</author>
</authors>
<title>Automatic generation of prosodic structure for high quality Mandarin speech synthesis”,</title>
<date>1996</date>
<booktitle>Proc. ICSLP</booktitle>
<contexts>
<context position="3187" citStr="Chou et al., 1996" startWordPosition="467" endWordPosition="470"> grouping. This method chooses Hidden Markov Model (HMM) as the training and predicting model. 2 Related Work Automatic prediction of prosodic phrase is a complex task. There are two reasons for this conclusion. One is that there is no explicit relationship between text and phonetic features. The other lies in the ambiguity of word segmentation, POS tagging and parsing in the Chinese natural language processing. As a result, the input information for the prediction of prosodic phrase is quite “noisy”. We can find that most of published methods, including (Chen et al., 1996; Chen et al., 2000; Chou et al., 1996; Chou et al., 1997; Gu et al., 2000; Hu et al., 2000; Lv et al., 2001; Qian et al., 2001; Ying and Shi, 2001) do not make use of high-level syntactic features due to two reasons. Firstly, it is very challenging to parse Chinese sentence because no grammar is formal enough to be applied to Chinese parsing. In addition, lack of 977 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 977–982, Sydney, July 2006. c�2006 Association for Computational Linguistics morphologies also causes many problems in parsing. Secondly, the syntactic structure is not isomorphic to the prosod</context>
</contexts>
<marker>Chou, Tseng, Lee, 1996</marker>
<rawString>Chou, F.C., Tseng, C.Y., Lee, L.S. 1996. “Automatic generation of prosodic structure for high quality Mandarin speech synthesis”, Proc. ICSLP</rawString>
</citation>
<citation valid="true">
<authors>
<author>F C Chou</author>
<author>C Y Tseng</author>
<author>K J Chen</author>
<author>L S Lee</author>
</authors>
<title>A Chinese text-to-speech system based on part-of-speech analysis, prosodic modeling and non-uniform units”,</title>
<date>1997</date>
<pages>97</pages>
<contexts>
<context position="3206" citStr="Chou et al., 1997" startWordPosition="471" endWordPosition="474">hod chooses Hidden Markov Model (HMM) as the training and predicting model. 2 Related Work Automatic prediction of prosodic phrase is a complex task. There are two reasons for this conclusion. One is that there is no explicit relationship between text and phonetic features. The other lies in the ambiguity of word segmentation, POS tagging and parsing in the Chinese natural language processing. As a result, the input information for the prediction of prosodic phrase is quite “noisy”. We can find that most of published methods, including (Chen et al., 1996; Chen et al., 2000; Chou et al., 1996; Chou et al., 1997; Gu et al., 2000; Hu et al., 2000; Lv et al., 2001; Qian et al., 2001; Ying and Shi, 2001) do not make use of high-level syntactic features due to two reasons. Firstly, it is very challenging to parse Chinese sentence because no grammar is formal enough to be applied to Chinese parsing. In addition, lack of 977 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 977–982, Sydney, July 2006. c�2006 Association for Computational Linguistics morphologies also causes many problems in parsing. Secondly, the syntactic structure is not isomorphic to the prosodic phrase structure</context>
</contexts>
<marker>Chou, Tseng, Chen, Lee, 1997</marker>
<rawString>Chou, F.C, Tseng, C.Y, Chen, K.J., Lee, L.S, 1997. “A Chinese text-to-speech system based on part-of-speech analysis, prosodic modeling and non-uniform units”, ICASSP’97</rawString>
</citation>
<citation valid="true">
<authors>
<author>D H Klatt</author>
</authors>
<title>Review of text-to-speech conversion for English”,</title>
<date>1987</date>
<journal>J. Acoust. Soc. Am.,</journal>
<volume>182</volume>
<pages>737--79</pages>
<contexts>
<context position="1831" citStr="Klatt, 1987" startWordPosition="255" endWordPosition="256">ration in TTS synthesis. Generally speaking, prosody deals with phrasing, loudness, duration and speech intonation. Among these prosodic features, phrasing divides utterances into meaningful chunks of information, called hierarchic breaks. However, there is no unique solution to prosodic phrasing in most cases. Different solution in phrasing can result in different meaning that a listener could perceive. Considering its importance, recent TTS research has focused on automatic prediction of prosodic phrase based on the part-of-speech (POS) feature or syntactic structure(Black and Taylor, 1994; Klatt, 1987; Wightman, 1992; Hirschberg 1996; Wang, 1995; Taylor and Black, 1998). To our understanding, POS is a grammarbased structure that can be extracted from text. There is no explicit relationship between POS and the prosodic structure. At least, in Mandarin speech synthesis, we cannot derive the prosodic structure from POS sequence directly. By contrast, a word carries rich information related to phonetic feature. For example, in Mandarin, a word can reveal many phonetic features such as pronunciation, syllable number, stress pattern, tone, light tone (if available) and retroflexion (if available</context>
</contexts>
<marker>Klatt, 1987</marker>
<rawString>Klatt, D.H., 1987, “Review of text-to-speech conversion for English”, J. Acoust. Soc. Am., 182: 737-79</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z L Gu</author>
<author>H Mori</author>
<author>H Kasuya</author>
</authors>
<title>Prosodic variation of focused syllables of disyllabic word in Mandarin Chinese”,</title>
<date>2000</date>
<booktitle>Proc. ICSLP,</booktitle>
<contexts>
<context position="3223" citStr="Gu et al., 2000" startWordPosition="475" endWordPosition="478">Markov Model (HMM) as the training and predicting model. 2 Related Work Automatic prediction of prosodic phrase is a complex task. There are two reasons for this conclusion. One is that there is no explicit relationship between text and phonetic features. The other lies in the ambiguity of word segmentation, POS tagging and parsing in the Chinese natural language processing. As a result, the input information for the prediction of prosodic phrase is quite “noisy”. We can find that most of published methods, including (Chen et al., 1996; Chen et al., 2000; Chou et al., 1996; Chou et al., 1997; Gu et al., 2000; Hu et al., 2000; Lv et al., 2001; Qian et al., 2001; Ying and Shi, 2001) do not make use of high-level syntactic features due to two reasons. Firstly, it is very challenging to parse Chinese sentence because no grammar is formal enough to be applied to Chinese parsing. In addition, lack of 977 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 977–982, Sydney, July 2006. c�2006 Association for Computational Linguistics morphologies also causes many problems in parsing. Secondly, the syntactic structure is not isomorphic to the prosodic phrase structure. Prosodic phrasi</context>
</contexts>
<marker>Gu, Mori, Kasuya, 2000</marker>
<rawString>Gu, Z.L, Mori, H., Kasuya, H. 2000. “Prosodic variation of focused syllables of disyllabic word in Mandarin Chinese”, Proc. ICSLP,</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hirschberg</author>
</authors>
<title>Training intonational phrasing rules automatically for English and Spanish text-to-speech”,</title>
<date>1996</date>
<journal>Speech Communication,</journal>
<pages>18--281</pages>
<contexts>
<context position="1864" citStr="Hirschberg 1996" startWordPosition="259" endWordPosition="260">rally speaking, prosody deals with phrasing, loudness, duration and speech intonation. Among these prosodic features, phrasing divides utterances into meaningful chunks of information, called hierarchic breaks. However, there is no unique solution to prosodic phrasing in most cases. Different solution in phrasing can result in different meaning that a listener could perceive. Considering its importance, recent TTS research has focused on automatic prediction of prosodic phrase based on the part-of-speech (POS) feature or syntactic structure(Black and Taylor, 1994; Klatt, 1987; Wightman, 1992; Hirschberg 1996; Wang, 1995; Taylor and Black, 1998). To our understanding, POS is a grammarbased structure that can be extracted from text. There is no explicit relationship between POS and the prosodic structure. At least, in Mandarin speech synthesis, we cannot derive the prosodic structure from POS sequence directly. By contrast, a word carries rich information related to phonetic feature. For example, in Mandarin, a word can reveal many phonetic features such as pronunciation, syllable number, stress pattern, tone, light tone (if available) and retroflexion (if available) etc. So we begin to explore the</context>
</contexts>
<marker>Hirschberg, 1996</marker>
<rawString>Hirschberg, J., 1996. “Training intonational phrasing rules automatically for English and Spanish text-to-speech”, Speech Communication, 18:281-290</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Hu</author>
<author>Q F Liu</author>
<author>R H Wang</author>
</authors>
<title>Prosody generation in Chinese synthesis using the template of quantified prosodic unit and base intonation contour”,</title>
<date>2000</date>
<booktitle>Proc. ICSLIP</booktitle>
<contexts>
<context position="3240" citStr="Hu et al., 2000" startWordPosition="479" endWordPosition="482">) as the training and predicting model. 2 Related Work Automatic prediction of prosodic phrase is a complex task. There are two reasons for this conclusion. One is that there is no explicit relationship between text and phonetic features. The other lies in the ambiguity of word segmentation, POS tagging and parsing in the Chinese natural language processing. As a result, the input information for the prediction of prosodic phrase is quite “noisy”. We can find that most of published methods, including (Chen et al., 1996; Chen et al., 2000; Chou et al., 1996; Chou et al., 1997; Gu et al., 2000; Hu et al., 2000; Lv et al., 2001; Qian et al., 2001; Ying and Shi, 2001) do not make use of high-level syntactic features due to two reasons. Firstly, it is very challenging to parse Chinese sentence because no grammar is formal enough to be applied to Chinese parsing. In addition, lack of 977 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 977–982, Sydney, July 2006. c�2006 Association for Computational Linguistics morphologies also causes many problems in parsing. Secondly, the syntactic structure is not isomorphic to the prosodic phrase structure. Prosodic phrasing remains an ope</context>
</contexts>
<marker>Hu, Liu, Wang, 2000</marker>
<rawString>Hu, Y., Liu, Q.F., Wang, R.H., 2000, “Prosody generation in Chinese synthesis using the template of quantified prosodic unit and base intonation contour”, Proc. ICSLIP</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Lu</author>
<author>L He</author>
<author>Y F Yang</author>
<author>J F Cao</author>
</authors>
<date>2000</date>
<booktitle>Prosodic control in Chinese TTS system”, Proc. ICSLP,</booktitle>
<marker>Lu, He, Yang, Cao, 2000</marker>
<rawString>Lu, S.N., He, L., Yang, Y.F., Cao, J.F., 2000, “Prosodic control in Chinese TTS system”, Proc. ICSLP,</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Lv</author>
<author>T J Zhao</author>
<author>Z Y Liu</author>
<author>M Y Yang</author>
</authors>
<title>Automatic detection of prosody phrase boundaries for text-to-speech system”,</title>
<date>2001</date>
<booktitle>Proc. IWPT</booktitle>
<contexts>
<context position="3257" citStr="Lv et al., 2001" startWordPosition="483" endWordPosition="486"> and predicting model. 2 Related Work Automatic prediction of prosodic phrase is a complex task. There are two reasons for this conclusion. One is that there is no explicit relationship between text and phonetic features. The other lies in the ambiguity of word segmentation, POS tagging and parsing in the Chinese natural language processing. As a result, the input information for the prediction of prosodic phrase is quite “noisy”. We can find that most of published methods, including (Chen et al., 1996; Chen et al., 2000; Chou et al., 1996; Chou et al., 1997; Gu et al., 2000; Hu et al., 2000; Lv et al., 2001; Qian et al., 2001; Ying and Shi, 2001) do not make use of high-level syntactic features due to two reasons. Firstly, it is very challenging to parse Chinese sentence because no grammar is formal enough to be applied to Chinese parsing. In addition, lack of 977 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 977–982, Sydney, July 2006. c�2006 Association for Computational Linguistics morphologies also causes many problems in parsing. Secondly, the syntactic structure is not isomorphic to the prosodic phrase structure. Prosodic phrasing remains an open task in the Chi</context>
</contexts>
<marker>Lv, Zhao, Liu, Yang, 2001</marker>
<rawString>Lv, X., Zhao, T.J., Liu, Z.Y., Yang M.Y., 2001, “Automatic detection of prosody phrase boundaries for text-to-speech system”, Proc. IWPT</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Qian</author>
<author>M Chu</author>
<author>H Peng</author>
</authors>
<title>Segmenting unrestricted Chinese text into prosodic words instead of lexical words”,</title>
<date>2001</date>
<booktitle>Proc. ICASSP.</booktitle>
<contexts>
<context position="3276" citStr="Qian et al., 2001" startWordPosition="487" endWordPosition="490">odel. 2 Related Work Automatic prediction of prosodic phrase is a complex task. There are two reasons for this conclusion. One is that there is no explicit relationship between text and phonetic features. The other lies in the ambiguity of word segmentation, POS tagging and parsing in the Chinese natural language processing. As a result, the input information for the prediction of prosodic phrase is quite “noisy”. We can find that most of published methods, including (Chen et al., 1996; Chen et al., 2000; Chou et al., 1996; Chou et al., 1997; Gu et al., 2000; Hu et al., 2000; Lv et al., 2001; Qian et al., 2001; Ying and Shi, 2001) do not make use of high-level syntactic features due to two reasons. Firstly, it is very challenging to parse Chinese sentence because no grammar is formal enough to be applied to Chinese parsing. In addition, lack of 977 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 977–982, Sydney, July 2006. c�2006 Association for Computational Linguistics morphologies also causes many problems in parsing. Secondly, the syntactic structure is not isomorphic to the prosodic phrase structure. Prosodic phrasing remains an open task in the Chinese speech generat</context>
</contexts>
<marker>Qian, Chu, Peng, 2001</marker>
<rawString>Qian, Y., Chu, M., Peng, H., 2001, “Segmenting unrestricted Chinese text into prosodic words instead of lexical words”, Proc. ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rabiner</author>
</authors>
<title>Fundamentals of Speech Recognition,</title>
<date>1999</date>
<booktitle>pp.336, Prentice-Hall and Tsinghua</booktitle>
<publisher>Univ. Press,</publisher>
<location>Beijing</location>
<contexts>
<context position="8300" citStr="Rabiner, 1999" startWordPosition="1286" endWordPosition="1287">ity distribution A = {ai j } , a ij ≈ Fij, 1 ≤ i, j ≤ N , Fij is the occurringFi times of state pair (qi,qj). represent the zero valued observationprobabilities. 3.5 The search procedure In this stage, an optimal state sequence that explains the given observations by the model is searched. That is to say, for the input sentence, an optimal prosodic-position sequence is predicted with the HHM. Instead of using the popular Viterbi algorithm, which is asymptotically optimal, we apply the ForwardBackward procedure to conduct searching. Backward and forward search All the definitions described in (Rabiner, 1999) are followed in the present approach. The forward procedure forward variable: αt (i) = P(o1 o2 ... ot , qt = i |λ ) initialization: α1(i) = πi bi (o1), 1≤ i≤ N. induction: �N 1 α j ( ) = � α i a b o ( ) � ( ), 1 t T - 1 , 1 j N ≤ ≤ ≤ ≤ t 1 t ij j t+1 + � � � � i = 1 � N Fi ≈ N P[qi] Fj �= j 1 . Observation probability distribution B = {bj(k)} , termination: P(O |λ) = i=1 where T is the number of observations. α ( ) T i bj (k) ≈ F(q = j,o = vk) F j b j(k) ∝ P q [ where F(q = j,o = vk) = E F(qt = j,o= t is the concurring times of state qj and observation vk. With respect to the proper names, al</context>
<context position="10672" citStr="Rabiner, 1999" startWordPosition="1775" endWordPosition="1776">e comes a question. It is, whether the optimal state sequence means the optimal path. α β ( ) ( ) i i t t , O λ ) N (i)=P(qt =i| γt F q j , o v k ) ( = = ] j ) vk 979 Search based on dynamic programming The preceding search procedure targets the optimal state sequence satisfying one criterion. But it does not reflect the probability of occurrence of sequences of states. This issue is explored based on a dynamic programming (DP) like approach, as described below. For convenience, we illustrate the problem as shown in Figure 2. Figure 2. Illustration of search procedure in trellis (quoted from [Rabiner, 1999]) From Figure 2, it can be seen that the transition from state i to state j only occurs in the two consecutive stages, namely time synchronous. Totally, there are T stages, N 2 T arcs. Therefore, the optimal-path issue is a multi-stage optimization problem, which is similar to the DP problem. The slight difference lies in that a node in the conventional DP problem does not contain any additional attribute, while a node in HMM carries the attribute of observation probability distribution. Considering this difference, we modify the conventional DP approach in the following way. In the trellis a</context>
</contexts>
<marker>Rabiner, 1999</marker>
<rawString>Rabiner, L., 1999, Fundamentals of Speech Recognition, pp.336, Prentice-Hall and Tsinghua Univ. Press, Beijing</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Taylor</author>
<author>A W Black</author>
</authors>
<title>Assigning phrase breaks from part-of-speech sequences”,</title>
<date>1998</date>
<journal>Computer Speech and Language,</journal>
<volume>12</volume>
<pages>99--117</pages>
<location>Wang, M.Q., Hirschberg, J.,</location>
<contexts>
<context position="1901" citStr="Taylor and Black, 1998" startWordPosition="263" endWordPosition="266"> with phrasing, loudness, duration and speech intonation. Among these prosodic features, phrasing divides utterances into meaningful chunks of information, called hierarchic breaks. However, there is no unique solution to prosodic phrasing in most cases. Different solution in phrasing can result in different meaning that a listener could perceive. Considering its importance, recent TTS research has focused on automatic prediction of prosodic phrase based on the part-of-speech (POS) feature or syntactic structure(Black and Taylor, 1994; Klatt, 1987; Wightman, 1992; Hirschberg 1996; Wang, 1995; Taylor and Black, 1998). To our understanding, POS is a grammarbased structure that can be extracted from text. There is no explicit relationship between POS and the prosodic structure. At least, in Mandarin speech synthesis, we cannot derive the prosodic structure from POS sequence directly. By contrast, a word carries rich information related to phonetic feature. For example, in Mandarin, a word can reveal many phonetic features such as pronunciation, syllable number, stress pattern, tone, light tone (if available) and retroflexion (if available) etc. So we begin to explore the role of word in predicting prosodic </context>
<context position="13449" citStr="Taylor and Black, 1998" startWordPosition="2261" endWordPosition="2264">rd procedure is that the target state sequence can explain the observations optimally. To support our claim, we can give a simple example (T=2, N=2,π =[0.5,0.5]T ) as follows: Apparently, the optimal state sequence is (1,1), while the optimal path is {1,2}. 4 Experimental Results Before reporting the experimental results, we first define the criterion of evaluation and the related issues. 1 2 Figure 3. Optimal state sequence vs. optimal path 1 0.82 1.0 2 0.18 0.0 0.9 0.1 0.8 0.2 980 4.1 The evaluation method After analyzing the existing evaluation methods, we feel that the method proposed in (Taylor and Black, 1998) is appropriate for our application. By employing this method, we can examine each word pair in the test set. If the algorithm generated break fully matches the manually labeled break, it marks correct. Similarly, if there is no labeled break and the algorithm does not place a break, it also marks correct. Otherwise, an error arises. To emphasize the effectiveness of break prediction, we define the adjusted score, Sa, as follows. where S is the ratio of the number of correct word pairs to the total number of word pairs; B is the ratio of non-breaks to the number of word-pairs. 4.2 The test cor</context>
</contexts>
<marker>Taylor, Black, 1998</marker>
<rawString>Taylor P., Black A.W., 1998, “Assigning phrase breaks from part-of-speech sequences”, Computer Speech and Language, 12: 99-117, Wang, M.Q., Hirschberg, J., 1995, “Automatic classification of intonational phrase boundaries”, Computer Speech and Language, pp.175-196, Vol. 6,</rawString>
</citation>
<citation valid="true">
<authors>
<author>C W Wightman</author>
</authors>
<title>Segmental durations in the vicinity of prosodic phrase boundaries”,</title>
<date>1992</date>
<journal>J. Acoust. Soc. Am.,</journal>
<pages>91--1707</pages>
<contexts>
<context position="1847" citStr="Wightman, 1992" startWordPosition="257" endWordPosition="258"> synthesis. Generally speaking, prosody deals with phrasing, loudness, duration and speech intonation. Among these prosodic features, phrasing divides utterances into meaningful chunks of information, called hierarchic breaks. However, there is no unique solution to prosodic phrasing in most cases. Different solution in phrasing can result in different meaning that a listener could perceive. Considering its importance, recent TTS research has focused on automatic prediction of prosodic phrase based on the part-of-speech (POS) feature or syntactic structure(Black and Taylor, 1994; Klatt, 1987; Wightman, 1992; Hirschberg 1996; Wang, 1995; Taylor and Black, 1998). To our understanding, POS is a grammarbased structure that can be extracted from text. There is no explicit relationship between POS and the prosodic structure. At least, in Mandarin speech synthesis, we cannot derive the prosodic structure from POS sequence directly. By contrast, a word carries rich information related to phonetic feature. For example, in Mandarin, a word can reveal many phonetic features such as pronunciation, syllable number, stress pattern, tone, light tone (if available) and retroflexion (if available) etc. So we beg</context>
</contexts>
<marker>Wightman, 1992</marker>
<rawString>Wightman, C.W., 1992, “Segmental durations in the vicinity of prosodic phrase boundaries”, J. Acoust. Soc. Am., 91:1707-1717</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z W Ying</author>
<author>X H Shi</author>
</authors>
<title>An RNN-based algorithm to detect prosodic phrase for Chinese TTS”,</title>
<date>2001</date>
<booktitle>Proc. ICASSP</booktitle>
<contexts>
<context position="3297" citStr="Ying and Shi, 2001" startWordPosition="491" endWordPosition="494">k Automatic prediction of prosodic phrase is a complex task. There are two reasons for this conclusion. One is that there is no explicit relationship between text and phonetic features. The other lies in the ambiguity of word segmentation, POS tagging and parsing in the Chinese natural language processing. As a result, the input information for the prediction of prosodic phrase is quite “noisy”. We can find that most of published methods, including (Chen et al., 1996; Chen et al., 2000; Chou et al., 1996; Chou et al., 1997; Gu et al., 2000; Hu et al., 2000; Lv et al., 2001; Qian et al., 2001; Ying and Shi, 2001) do not make use of high-level syntactic features due to two reasons. Firstly, it is very challenging to parse Chinese sentence because no grammar is formal enough to be applied to Chinese parsing. In addition, lack of 977 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 977–982, Sydney, July 2006. c�2006 Association for Computational Linguistics morphologies also causes many problems in parsing. Secondly, the syntactic structure is not isomorphic to the prosodic phrase structure. Prosodic phrasing remains an open task in the Chinese speech generation. In summary, all </context>
</contexts>
<marker>Ying, Shi, 2001</marker>
<rawString>Ying, Z.W., Shi, X.H., 2001, “An RNN-based algorithm to detect prosodic phrase for Chinese TTS”, Proc. ICASSP</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>