<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9886785">
Generating Spatial Descriptions for
Cross-modal References
</title>
<author confidence="0.995448">
Peter Wazinski
</author>
<affiliation confidence="0.9909635">
SFB 314, Department of Computer Science
University of Saarbriicken
</affiliation>
<address confidence="0.681322">
D-6600 Saarbriicken, Germany
</address>
<email confidence="0.957404">
email: wazinski©cs.uni-sb.de
</email>
<sectionHeader confidence="0.995709" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999895857142857">
We present a localisation component that sup-
ports the generation of cross-modal deictic ex-
pressions in the knowledge-based presentation
system WIP. We deal with relative localisations
(e.g., &amp;quot;The object to the left of object X.&amp;quot;),
absolute localisations (e.g., &amp;quot;The object in the
upper left part of the picture.&amp;quot;) and corner lo-
calisations (e.g., &amp;quot;The object in the lower right
corner of the picture&amp;quot;). In addition, we distin-
guish two localisation granularities, one less de-
tailed (e.g., &amp;quot;the object. to the left of object X.&amp;quot;)
and one more detailed (e.g., &amp;quot;the object above
and to the left of object X.&amp;quot;). We consider cor-
ner localisations to be similar to absolute local-
isations and in turn absolute localisations to be
specialisations of relative localisations. This al-
lows us to compute all three localisation types
with one generic localisation procedure. As
elementary localisations are derived from pre-
viously computed composite localisations, we
can cope with both localisation granularities
in a computationally efficient way. Based on
these primary localisation procedures, we dis-
cuss how objects can be localised among several
other objects. Finally we introduce group local-
isations (e.g., &amp;quot;The object to left of the group
of other objects.&amp;quot;) and show how to deal with
them.
</bodyText>
<sectionHeader confidence="0.999165" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999879">
The increasing amount of information to be communi-
cated to users of complex technical systems nowadays
makes it necessary to find new ways to present infor-
mation. Neither the variety of all possible presentation
situations can be anticipated nor it is further adequate
to present the required information in a single communi-
cation mode, such as either text or graphics. Therefore,
the automatic generation of multimodal presentations
tailored to the individual user has become necessary.
Current research projects in artificial intelligence like
SAGE ([Roth et al., 1990]), FN/ANDD ([Marks and
Reiter, 1990, COMET ([Feiner and McKeown, 19901)
and WIP ([Wahlster et al., 1991a]) reflect the growing
interest in this topic.
For the knowledge-based presentation system WIP,
the task is the generation of a multimodal document ac-
cording to the formal description of the communicative
intent of the planned presentation and a set of generation
parameters. The current scenario for WIP is the gener-
ation of instructions for using an espresso-machine. A
typical fragment of an instruction manual for an espresso
machine is shown in figure 1.
</bodyText>
<figureCaption confidence="0.6256686">
Before you lift the lid
make sure that the
knob in the middle is in
position C.
Figure 1: Fragment from an instruction manual
</figureCaption>
<bodyText confidence="0.872613681818182">
Cross-modal deictic expressions, e.g., &amp;quot;the lid&amp;quot; or &amp;quot;the
knob in the middle,&amp;quot; help to establish the coreferentiality
between the entities mentioned in the text and shown in
the picture as well ([Wahlster et al., 1991b]). The use ol
spatial relationships such as &amp;quot;the knob in the middle&amp;quot;
simplifies the generation of referring expressions that
have to identify a particular object in a picture. Ob-
viously these spatial relationships cannot be computed
in advance because they depend on the projection para-
meters for the picture, e.g., the viewpoint, which in turn
themselves depend on the communicative intent of the
document to be planned&apos;.
The localisation component described in this paper
was developed in order to support the generation oi
cross-modal deictic referring expressions. All procedures
are fully implemented and were recently integrated intc
the first WIP prototype. They are coded in Commor
I Even if the projection parameters are constant, it is not
feasible to compute all possible relative localisations from a
combinatoric point of view.
Remove the cover and
pour in cold tap water.
</bodyText>
<page confidence="0.975194">
56
</page>
<bodyText confidence="0.999858125">
Lisp and run under Genera 8.0 on a MacIvory. A testbed
called LOC-SYS was also developed: it allows the con-
venient generation and manipulation of rectangle scenes
like the examples given in this paper.
Before we describe the methods which underlie the
various localisation procedures, in the following section
we present our views about localisation phenomena and
introduce the terminology used in the rest of this paper.
</bodyText>
<sectionHeader confidence="0.984436" genericHeader="method">
2 Object Localisation
</sectionHeader>
<bodyText confidence="0.999981606060606">
A lot of work has been done on &apos;Object localisation&apos;
and its linguistic complement, &apos;spatial prepositions&apos;.
Wunderlich/Herweg ([Wunderlich, 1982], [Wunderlich
and Herweg, forthcoming]) and Herskovits ([llerskovits,
1985]) provide linguistic approaches to the semantics of
spatial prepositions. NL-systems like NAOS ([Neumann
and Novak, 1986]), HAM-RPM ([Hahn et al., 1980]),
SWYSS ([HuBmann and Schefe, 1984]) and CITYTOUR
([André et al., 1985],[Andre et al., 1986]) address var-
ious issues regarding computational aspects. Schirra
([Schirra, to appear 19921) and Habel/Pribbenow ([Ha-
bel and Pribbenow, 1988],[Pribbenow, 1990]) also incor-
porate relevant work from cognitive psychology.
In our approach, we concentrate on the requirements
for localising objects in pictures. We assume that the
user can see the picture containing the objects to be
localised and we do not deal with the problem of an-
ticipating possibly wrong visualisations of the user in
the case he/she cannot see the picture. We do not deal
with possible intrinsic orientations of depicted objects
(c.f. [Retz-Schmidt, 1988]) and assume the deictic refer-
ence frame of a common viewer (c.f. figure 5). Together
with every localisation, we compute a so-called applica-
bility degree from the intervall [0..1]. The applicability
degree is not only used to generate linguistic hedges (c.f.
[Lakoff, 19721) as in SWYSS or CITYTOUR, but also
for selecting the &apos;best&apos; localisation from a set of alter-
natives. The localisations computed on our system are
two-dimensional localisations in the sense that they are
based on the 2D-projection of a picture and not on its
possible 3D-representation. In the rest of this section
we will describe the localisation phenomena we take into
account and introduce our terminology.
</bodyText>
<subsectionHeader confidence="0.935721">
2.1 Relative and absolute localisations
</subsectionHeader>
<bodyText confidence="0.745136666666667">
The objects shown in part A of figure 2 can be localised
as follows:
A. B.
</bodyText>
<listItem confidence="0.8788528">
Figure 2: Localising objects in a picture
(1) &amp;quot;Object A is on the right side of the picture.&amp;quot;
(2) &amp;quot;Object B is in the lower part of the picture.&amp;quot;
(3) &amp;quot;Object A is to the right of Object B.&amp;quot;
(4) &amp;quot;Object B is below Object A.&amp;quot;
</listItem>
<bodyText confidence="0.897787772727273">
Sentences (1) and (2) are considered to contain ab-
solute localisations: an object is localised by stating
its absolute position in the picture. Sentences (3) and
(4) are examples of relative localisations: an object
is localised by stating its position relative to another ob-
ject. The object to be located will be called the primary
object (LO for short). The object that serves as refer-
ence for locating the primary object is called reference
object (REFO for short).
How can we explain the similarity between absolute
and relative localisations, between &amp;quot;on the right side of
the picture&amp;quot; and &amp;quot;to the right of Object B&amp;quot;? Our hy-
pothesis is:,
Absolute localisations are specialisations of
relative localisations in the sense that for ab-
solute localisations the center of the picture
functions as an implicit reference object.
Part B of figure 2 shows how the absolute localisation
of part A can be explained as a relative localisation by
assuming a circle-shaped center: &amp;quot;Object A is on the
right side of the picure.&amp;quot; is equivalent to &amp;quot;Object A is
to the right of the center of the picture.&amp;quot;
</bodyText>
<subsectionHeader confidence="0.984947">
2.2 Elementary and composite localisations
</subsectionHeader>
<bodyText confidence="0.999822">
Whereas the unambiguous localisations of the objects in
figure 2 could be achieved by naming either the horizon-
tal (&amp;quot;on the right side&amp;quot;, &amp;quot;to the right of&amp;quot;) or vertical
relation (&amp;quot;in the lower part&amp;quot;, &amp;quot;below&amp;quot;), figure 3 shows a
situation in which it is necessary to give both the hori-
zontal and vertical position of the object with respect to
the reference object:
</bodyText>
<subsectionHeader confidence="0.508">
A. B.
</subsectionHeader>
<figureCaption confidence="0.992237">
Figure 3: Elementary and composite localisations
</figureCaption>
<bodyText confidence="0.9912890625">
In part A of figure 3, it is sufficient to describe object
C as the object &amp;quot;to the right of&amp;quot; or &amp;quot;above&amp;quot; object A.
But in part B, both descriptions would be ambiguous,
because &amp;quot;to the right of&amp;quot; or &amp;quot;above&amp;quot; could refer to object
D or B respectively. The only possibility to localise C
unambiguously is to describe it as being &amp;quot;above and to
the right&amp;quot; of A.
Localisations where either the horizontal or vertical
relation is given will be called elementary localisa-
tions. If both relations are stated together, we will call
it a composite localisation.
The localisation types introduced so far — absolute vs.
relative and elementary vs. composite — are orthogonal.
Therefore, an absolute or a relative localisation can be
further subcategorized as being an elementary or a corn-
posite localisation.
</bodyText>
<figure confidence="0.995468666666667">
A
Center I A
A
</figure>
<page confidence="0.996432">
57
</page>
<bodyText confidence="0.962164071428571">
Composite localisations cannot always be applied, e.g.,
in figure 2 object B cannot be localised as &amp;quot;the object
in the lower left part of the picture.&amp;quot; Criteria for the
applicability of composite localisations will not be ex-
amined further in this paper as this would lead to more
complex questions, e.g., whether an object can be lo-
calised at all. A detailed discussion of these problems is
given in Mazinski, 19911.
2.3 The construction of the horizontal and
vertical reference frame
One important feature of the localisation procedures
is the division of the horizontal and vertical reference
frame into three parts. The reason for this are `center&apos;-
localisations as shown in figure 4:
</bodyText>
<figure confidence="0.9570875">
A
A
</figure>
<figureCaption confidence="0.999815">
Figure 4: Center localisations
</figureCaption>
<bodyText confidence="0.999871071428572">
In all pictures, object A can be localised as the object
&amp;quot;in the center of the picture.&amp;quot; In order to integrate this
observation with the elementary vs. composite distinc-
tion we divided the horizontal and vertical dimension
into three parts: &apos;top&apos;, &apos;horizontal center&apos; and &apos;bottom&apos;
and &apos;left&apos;, &apos;vertical center&apos; and &apos;top&apos; respectively (c.f. fig-
ure 5). Under these conditions the `center&apos;-localisation
in the left part of figure 4 can be analysed as a com-
posite (&apos;vertical center&apos;,`horizontal center&apos;)-localisation.
For the picture in the middle it is an elementary &apos;verti-
cal center&apos;-localisation and for the right one an elemen-
tary &apos;horizontal center&apos;-localisation. When transforming
these different localisations into a surface string they all
become the same: &amp;quot;in the center of the picture.&amp;quot;
</bodyText>
<figure confidence="0.827671">
left vertical
center
top
horizontal
center
bottom
</figure>
<figureCaption confidence="0.997706">
Figure 5: Horizontal and vertical reference frame
</figureCaption>
<bodyText confidence="0.993538727272728">
Figure 6 shows that it is also useful to adopt the
this partition scheme for relative localisations: B would
usually be described as the object &amp;quot;to the right of A&amp;quot;
and C as the object &amp;quot;above and to the right of A.&amp;quot;
With respect to the partition scheme a (&apos;right&apos;, &apos;top&apos;)-
localisation can be applied to C and a (&apos;right&apos;, &apos;horizontal
center&apos;)-localisation to B. The former matches exactly
with the surface string. The latter can be matched with
&amp;quot;to the right of A&amp;quot; by assuming that the `center&apos;-part of
a composite localisation is a special part of a composite
localisation that does not appear at the linguistic level.
</bodyText>
<figure confidence="0.638566">
A
</figure>
<figureCaption confidence="0.916191">
Figure 6: Center localisations and relative localisations
2.4 Corner Localisations
</figureCaption>
<bodyText confidence="0.99975925">
An additional localisation type that can be used to lo-
calise objects in pictures is the corner localisation: if
an object is placed in one of the four corner regions of
the picture it can be localised as, e.g., &amp;quot;the object in the
left upper corner of the picture.&amp;quot;
The difference between absolute composite localisa-
tions and corner localisations is illustrated in figure 7:
While object B can be localised as being &amp;quot;in the lower
right corner of the picture&amp;quot; it is not possible to use a
corner localisation for A. In that case, only &amp;quot;in the left
upper part of the picture&amp;quot; could be used. Therefore, we
consider corner localisations to be more precise than ab-
solute composite localisations, i.e., the applicability of a
corner localisation implies the applicability of the cor-
responding absolute composite localisation but not vice
versa.
</bodyText>
<figure confidence="0.480406">
A
</figure>
<figureCaption confidence="0.970049">
Figure 7: Corner localisations vs. absolute composite
localisations
</figureCaption>
<sectionHeader confidence="0.958715" genericHeader="method">
3 Basic Localisation Procedures
</sectionHeader>
<bodyText confidence="0.999882">
In this section we present matrix-oriented localisation
procedures for absolute and relative localisations. As
mentioned in section 2.2, both the horizontal and ver-
tical relation of the primary object are given in case of
a composite localisation. This suggests that composite
localisations are composed of elementary localisations.
The procedures presented here, though, behave differ-
ently: for the sake of efficiency they compute the com-
posite localisations first and derive the elementary lo-
calisations from these previously computed localisation
results.
</bodyText>
<figure confidence="0.75118">
A
right
</figure>
<page confidence="0.968667">
58
</page>
<subsectionHeader confidence="0.993158">
3.1 Absolute localisations
</subsectionHeader>
<bodyText confidence="0.999847666666667">
We approximate the center of the picture with a rect-
angle whose horizontal and vertical extension is one third
of the horizontal and vertical extension of the picture.
Figure 8 shows the construction of the horizontal and
vertical reference system according to the rectangular
center region.
</bodyText>
<figure confidence="0.983866833333333">
vertical right
lett center
top
horizontal
center
bottom
</figure>
<figureCaption confidence="0.9745515">
Figure 8: The construction of the horizontal and vertical
reference system
</figureCaption>
<bodyText confidence="0.9997895">
Before describing the evaluation function for compos-
ite localisations, we give a few definitions:
</bodyText>
<listItem confidence="0.986603">
• The horizontal reference system is abbreviated by
XLOC = {left, x-center, right}, the vertical one by
YLOC = {top, y-center, bottom}. Composite locali-
sations are denoted by CLOG = XLOC XYLOC. Both
reference systems together are described with ULOC
= XLOCUYLOC.
• The constant CENTER denotes the center rectangle
of a given picture.
• POLY denotes the set of all polygons that can ap-
pear in a picture. For given polygons P1 and
P2 the associative and commutative operator n,
n : POLY X POLY POLY computes the in-
tersection polygon. The empty polygon is denoted
by Po. The following holds: VP E POLY : Po fl P
P n Po = P0.
• The function PR (Partial Rectangle), PR : CLOG x
</listItem>
<bodyText confidence="0.560733333333333">
POLY POLY, computes the rectangle correspond-
ing to a given composite localisation and the rec-
tangle partition of the picture induced by a given
polygon. For example PR((left,top), CENTER)
computes the upper left rectangle according to the
partition scheme shown in figure 8.
</bodyText>
<listItem confidence="0.622856333333333">
• R denotes the set of the real numbers. Given a
polygon P, the function f, f : POLY:,&apos; computes
computes
</listItem>
<bodyText confidence="0.994650636363636">
the area of a polygon. It is f(P0) = 0.
The applicability degree of a composite localisation
evaluates how good the position of the object in ques-
tion is described by that particular localisation. We de-
fine the applicability degree as the portion of the area of
the object that lies in the rectangle of the picture that
corresponds to the composite localisation and the rec-
tangle partition of that picture. Thus we can define A,
as follows:
For object LO in figure 9, the above definition yields the
following results:
</bodyText>
<equation confidence="0.993491666666667">
A,((left, top), LO) = 1/12,
A,((x-center, top), LO) = 1/6,
A,((left, y-center), LO) = 1/4,
A,((x-center, y-center), LO) = 1/2.
For all other 1 E CLOG we have A,(I, LO) = 0 because
f(p) = f(Pe) = O.
</equation>
<figure confidence="0.625449333333333">
left
vertical
center right
</figure>
<figureCaption confidence="0.999413">
Figure 9: Computing absolute localisations
</figureCaption>
<bodyText confidence="0.999022333333333">
For elementary localisations we adopted an analogous
definition: the applicability degree A, of an elementary
localisation is determined by the portion of the area of
the object that lies in the corresponding row or column
of the picture. As already mentioned at the beginning
of this section we can write A. in terms of A, :
</bodyText>
<equation confidence="0.968577545454545">
: xLoc. X POLY
= E A((1,1), LO)
lyEYLOC
: YLOC x POLY
A(1, LO) = E A,((1,,/y),L0)
GEXL0C
A, : uLoc x POLY
if E XLOG
Af (1, LO)
A,(1, LO) =
24(1, LO) if 1 E YLOC
</equation>
<bodyText confidence="0.999854666666667">
Af and A,Y„ compute the applicability for the horizon-
tal and vertical dimension by summing up the applicabil-
ity degrees of the corresponding composite localisations.
They are combined in A, order to have a function that
is defined on both dimensions, i.e., ULOC.
With respect to figure 9 we get:
</bodyText>
<equation confidence="0.894981375">
Ae(top, LO) = A,((left, top), LO) A,((x-
center, top), LO) = 1/4,
Ae(y-center, LO) = Ae((left, y-center), LO)
A,((x-center, y-center), LO) = 3/4,
Ae(left, LO) = Ac((left, top), LO) Ac((left,
y-center), LO) = 1/3 and
Ae(x-center, LO) = .4((x-center, top), LO)
Ac((x-center, y-center), LO) = 2/3.
</equation>
<figure confidence="0.837832461538462">
/3
2/3
1/4
3/4
A, : CLOG x POLY 1-4 SR
P
A,(1, LO) = f()
f(LO)
with p = PR(1, CENTER) n LO
top
horizontal
center
bottom
</figure>
<page confidence="0.992251">
59
</page>
<bodyText confidence="0.991675307692308">
As argued in paragraph 2.4 corner localisations
are similar to composite (&apos;left&apos;/&apos;right&apos;, `top&apos;rbottom&apos;)-
localisations, but less general. This property can be
modelled by corner regions that are smaller than the
corner regions for absolute localisations. In turn, these
corner regions correspond to a larger center as shown in
figure 10. Thus we can compute corner localisations just
by changing the size of the center.
Figure 10: The relation between corner and center re-
gions
Instead of 1/3 as for absolute localisations we take 4/5
of the horizontal and vertical extension of the picture for
the extended center.
</bodyText>
<subsectionHeader confidence="0.984356">
3.2 Relative localisatious
</subsectionHeader>
<bodyText confidence="0.9994056">
The localisation procedure for relative localisations is
similar to the one for absolute localisations. One ma-
jor difference is that now the construction of the hori-
zontal and vertical reference frame is done with respect
to a given reference object and not to the implicit as-
sumed center of the picture (c.f. figure 11). The second
difference concerns the computation of the applicability
degree: for relative localisations, not only the portion
of an area is taken into account, but also the distance
between the primary object and the reference object.
</bodyText>
<figure confidence="0.916245666666667">
vertical right
left center
REFO
</figure>
<figureCaption confidence="0.9455635">
FigureFigure 11: The construction of the reference frame for
relative localisations
</figureCaption>
<bodyText confidence="0.999819333333333">
The basic idea for the evaluation of the distance be-
tween primary object and reference object is adopted
from the CITYTOUR system: first we compute the cen-
ter of gravity for the primary object. Then we determine
its coordinates with respect to the reference system es-
tablished by the reference object. Finally we use these
coordinates for the computation of the applicability de-
gree. Figure 12 illustrates the various factors that affect
the applicability of an `above&apos;-localisation:
</bodyText>
<listItem confidence="0.655003888888889">
1. The applicability degree decreases with an increas-
ing vertical distance. In Part A of figure 12 the ap-
plic.ability degree for &amp;quot;P1 is above REFO&amp;quot; is greater
than for &amp;quot;P2 is above REFO.&amp;quot;
2. The applicability degree decreases with an increas-
ing horizontal distance. In Part B the applicability
degree for &amp;quot;P3 is above REFO&amp;quot; is greater than for
&amp;quot;P4 is above REFO.&amp;quot;
3. If the horizontal and vertical distances increase by
</listItem>
<bodyText confidence="0.676904888888889">
the same amount, then the applicability degree de-
creases more with the increasing horizontal distance
than with the increasing vertical distance. This is
shown in Part C: the applicability degree for &amp;quot;P6
is above REFO&amp;quot; is greater than for &amp;quot;P7 is above
REFO&amp;quot;, although the vertical distance between P5
and P6 and the horizontal distance between P5 and
P7 are equal.
A. B. C.
</bodyText>
<figureCaption confidence="0.977019">
Figure 12: Evaluating the distance of a point
</figureCaption>
<bodyText confidence="0.972631785714286">
Let eval denote the function that evaluates the dis-
tance between a point and a rectangle according to the
criteria mentioned above. Let further POINT denote the
set of all points within a picture and RECT C POLY the
set of all rectangular polygons. Then the signature ol
eval can be written as2:
eval: CLOG X POINT X RECT
Now we are almost able to define the function i4c, which
computes the applicability degree of a composite lo-
calisation. Let CG,. CG : POLY 1—* POINT , compute
the center of gravity for a polygon and let further SR,
SR: POLY 1—* RECT , compute the smallest surrounding
rectangle for a polygon. Then the applicability degree
A, of a composite localisation can be defined as:
</bodyText>
<equation confidence="0.9746045">
CLOG X POLY X POLY
f(LO)
</equation>
<bodyText confidence="0.99885775">
211i reality eval is slightly more complicated because it
maps into x and not only into R. The reason for this
that the different evaluation of increasing vertical and hori-
zontal distances can result in different evaluations for pointE
to which both a horizontal or vertical localisation can be ap.
plied. E.g., P7 in figure 12 would get a different evaluation foi
an `above&apos;- than for a &apos;right of&apos;-localisation. Therefore, thes(
two values would be grouped to a tuple. For the computation
of an elementary localisation 1 E XLOC we would sum up th(
first component of the tuple. If 1 E YLOC, we take the seconc
component. We abstract from this detail in order to mak(
the principle of the procedure clearer.
</bodyText>
<figure confidence="0.9766523125">
P4
P3
• •
7-71
P.6
P7
P.5 •
EF
top
horizontal
center
bottom
A,(1, LO, REFO) = w eval(1, CG(p)„911(REFO))
with p = PR(1, REFO) fl LO
(r)
w
</figure>
<page confidence="0.593435">
6 0
</page>
<bodyText confidence="0.999187375">
p is the part of the primary object that lies in the
rectangle corresponding to the composite localisation I.
The factor w weighs the result of eval according to the
portion of the area of the primary object that lies in the
rectangle corresponding to I.
Now the definition of A, , the applicability degree for
an elementary localisation, can be given in terms of A,
again:
</bodyText>
<equation confidence="0.99380025">
Ale&amp;quot; : xLoc, x POLY X POLY
Af(lLO, REFO) = E A,((1,,1y),LO,REFO)
GEYLoc
: YLOC X POLY X POLY
A(1y, LO, REFO) = E A,((lz,1y), LO, REFO)
XLOC
A, : tftoc x POLY X POLY 1-4 ai
Af(1, LO, REFO) if 1 E XL0c
</equation>
<bodyText confidence="0.963407076923077">
LO, REFO) = LO, REFO) if / E YLOC
This means that the applicability degree A, for a pri-
mary object LO is the sum of the composite localisa-
tions for the corresponding row or column of the refer-
ence frame.
For figure 13 we get the following results:
A,((x-center, top), LO, REFO)
▪ A eval((x-center, top), ,SR(REFO)
= 51 * 0.7 = 0.23
A,((right, top), LO, REFO)
= evaCright, top), P2, SR(REFO)
= * 0.65 = 0.43
A,(1, LO, REFO)
</bodyText>
<listItem confidence="0.6241995">
4 A generic localisation procedure for
absolute and relative localisations
</listItem>
<bodyText confidence="0.999720166666667">
The similarities between the localisation procedures dis-
cussed in the previous section allow us to design one
generic localisation procedure that can be specialised to
a procedure for absolute, relative or corner localisations.
Given the primary object LO and the reference object
REFO the first step is to determine the 3x3 matrix Mr&apos;,
which contains the intersection polygons of LO and the
partial rectangles in the picture with respect to REFO.
For relative localisations, REFO varies, for absolute lo-
calisations and corner localisations the parameter is set
to either the normal or the extended center area (c.f.
section 3.1). Thus, for x E xLoc, y E YLOC we compute
</bodyText>
<footnote confidence="0.533456">
M2,y = PR((x, y), REFO) n LO
</footnote>
<note confidence="0.8001854">
P2
P1 • LO •
1/3 2/3
RE
,
</note>
<figureCaption confidence="0.998102">
Figure 13: Computing relative localisations
</figureCaption>
<bodyText confidence="0.978346428571428">
The second step is the computation of the evaluation
matrix MA, which contains the applicability degrees of
the composite localisations. The computation requires a
function E, E : POLY x POLY X POLY W. E corresponds
exactly to the function A, for absolute and relative local-
isations in section 3.1 and 3.2. The only difference results
from the previous computation of Mr&apos;: the subexpres-
sion p = PR((x, y), REFO) n LO is factored from A, and
therefore computed only once.
= E(Mx.n,y, LO, REFO)
The third step is the computation of the elementary lo-
calisations. The vector X contains the evaluations of the
horizontal localisations and Y the ones for the vertical
localisations:
</bodyText>
<equation confidence="0.9449575">
E mxAy
yEYLOC
E
XEXL0C
</equation>
<bodyText confidence="0.937349714285714">
This means that we have A,(1) for I E XLOC and
= A,(/) for / E YLOC.
Finally, we can determine the best composite and el-
ementary localisation and their applicability degrees by
computing the maximum value of MA and X or Y re-
spectively.
For figure 13 we get
0 0.23 0.43
MA=(0 0 0 ,
0 0 0
= (0 0.23 0.43) and Y = (0.66 0 0). The best compos-
ite localisation is &amp;quot;(right, top)&amp;quot; with applicability degree
0.43. The best elementary localisation is &amp;quot;top&amp;quot; with ap-
plicability degree 0.66.
</bodyText>
<sectionHeader confidence="0.697899" genericHeader="method">
5 Localising objects in a complex scene
</sectionHeader>
<bodyText confidence="0.999161428571429">
In the previous sections we considered pictures with
a minimal number of objects. In order to deal with
more complex object configurations the localisation pro-
cedures presented above have to be extended. The new
task is no longer &amp;quot;Localise LO with respect to REFO!&amp;quot;
but &amp;quot;Given a set of REFO candidates, choose the best
one for LO!&amp;quot;
</bodyText>
<table confidence="0.8326859">
A, (top, LO, REFO)
= A,((x-center, top), LO, REFO)+
A,((right, top), LO, REFO) = 0.66
A,(right, LO, REFO)
= A,((right, top), LO, REFO) = 0.43
A, (x-center , LO, REFO)
= A,((x-center, top), LO, REFO) = 0.23
f (P)
• 0 as for all other 1 E cLoc : w = =0
f(LO)
</table>
<page confidence="0.998508">
61
</page>
<bodyText confidence="0.970750434782608">
In order to reduce the search space for REFO candi-
dates, first a kind of `between&apos;-test is applied to the set
of possible reference objects. The idea behind this test
is that an exclusion procedure based on simple geomet-
ric overlapping tests can be performed more efficiently
than a comparison of applicability degrees that have to
be computed by the rather complex localisation proce-
dures. An example is given in figure 14: When searching
for a suitable reference object for object A in figure 14,
object D would be ruled out because object B is found
in the `between&apos;-area of A and D.
Figure 14: Search space reduction for complex object
configurations
The determination of the best reference object raises
the problem of ambiguity. Not only is the applicability
degree of a localisation important, but also whether the
use of the reference object would result in an ambiguous
localisation. In that case, a different reference object
has to be chosen. If all possible localisations are am-
biguous, then the particular object cannot be localised
at all. E.g., in Part A of figure 15 object D could be
localised as being either &amp;quot;above A&amp;quot; or &amp;quot;to the right of
But the first localisation is ambiguous because both,
</bodyText>
<figure confidence="0.6543588">
C and D, are &amp;quot;above A.&amp;quot;
Es
A
A
A. B. C.
</figure>
<figureCaption confidence="0.988498">
Figure 15: Ambiguous reference objects
</figureCaption>
<bodyText confidence="0.9972295">
With respect to elementary and composite localisa-
tions we distinguish three cases of ambiguity:
</bodyText>
<reference confidence="0.3756603">
1. In Part A of figure 15, the localisation of object C or
D would be ambiguous with respect to A because for
both objects the composite localisations, (x-center,
top), are equal.
2. In Part B a composite localisation cannot be applied
to object D (neither &amp;quot;D is above and to the right of
A&amp;quot; nor &amp;quot;D is immediately above A&amp;quot; are adequate)
and its elementary localisation, &apos;top&apos;, is part of the
composite localisation, (x-center, top), of object C.
3. In Part C a composite localisation can be applied
</reference>
<bodyText confidence="0.9169285">
neither to C nor to D and their elementary locali-
sations, &apos;top&apos;, are equal.
</bodyText>
<sectionHeader confidence="0.977373" genericHeader="method">
6 Localising Groups of Objects
</sectionHeader>
<bodyText confidence="0.998996041666667">
Control knobs and switches are often grouped together
in a control panel in order to provide for easier operation
of technical devices. Moreover spatially adjacent objects
can also be grouped as one perceptual unit according
to the &apos;law of the good gestalt&apos; in Gestalt psychology
([Murch and Woodworth, 1978]). Thus the possibility
to generate localisations with respect to a given group
structure is neccessary for the &amp;quot;naturalness&amp;quot; of a local-
isation. Besides this, group localisations are also useful
if the objects in the immediate neighbourhood of the
primary object have exactly the same properties (c.f.
[Wahlster el al., 1978]). In this case, the primary ob-
ject can be localised with respect to its group and has
not to be localised with respect to the whole scene, which
could have resulted in an ambiguous localisation.
For our localisation procedures this means that groups
can function as a reference object as well as a primary
object. In addition, objects can be localised absolutely
with respect to the group they are contained in. In figure
16 object B would be localised as the object &amp;quot;to the right
of the triangles.&amp;quot; Vice versa we can say &amp;quot;The triangles
to the left of object B&amp;quot; and we can localise object A as
being &amp;quot;the upper left of the triangles that are to the left
of B.&amp;quot;
</bodyText>
<figureCaption confidence="0.972522">
Figure 16: Group localisations
</figureCaption>
<bodyText confidence="0.999901071428572">
The last example also illustrates the hierarchical char&apos;
acter of group localisations: An object can be localise(
absolutely within a group. This group might be localise(
again within a surrounding group or — if there is nom
— this group can be localised relatively with respect t(
another (group of) object(s).
The algorithm for group localisations cannot detect
group hierarchies. Instead it expects a tree representa-
tion of the group hierarchy as an input. The output con.
sists of two parts: According to the depth of the grout
tree the algorithm computes a chain of absolute locali
sations. In addition the outermost surrounding group o
the primary object is localised relatively to an optiona
(group of) reference object(s).
</bodyText>
<sectionHeader confidence="0.999522" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.963909714285714">
We have introduced a unifying approach for absolute
relative and corner localisations of objects in pictures. Ii
addition, the use of a special partition scheme for the ref
erence frame of a preposition allows us to deal with twi
different localisation granularities for absolute and rela
tive localisations. By defining the evaluation function
A
</bodyText>
<page confidence="0.99691">
62
</page>
<bodyText confidence="0.999905">
for elementary localisations in terms of the evaluation
functions for the corresponding composite localisations,
we have been able to design one procedure that handles
all three localisation types and both localisation granu-
larities efficiently. Furthermore, we have given a solution
to the problem of localising an object within a complex
configuration on the basis of this localisation procedure.
Finally, we have shown how our system deals with group
localisations.
</bodyText>
<sectionHeader confidence="0.998871" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998857051546392">
[André et al., 1985] E. André, G. Bosch, G. Herzog, and
T. Rist. CITYTOUR — Ein natiirlichsprachliches
Anfragesystem zur Evaluierung raumlicher Priposi-
tionen. Abschluf3bericht des Fortgeschrittenenprak-
tikums, Department of Computer Science, University
of Saarbriicken, 1985.
[André et al., 1986] E. André, G. Bosch, G. Herzog, and
T. Rist. Characterising Trajectories of Moving Ob-
jects using Natural Language Path Descriptions. In
Proc. of the 7th ECAI, pages 1-8, 1986.
[Feiner and McKeown, 1990] S. K. Feiner and K. R.
McKeown. Coordinating Text and Graphics in Expla-
nation Generation. In Proc. 8th AAAI, pages 442-449,
1990.
[Habel and Pribbenow, 1988]
C. Habel and S. Pribbenow. Gebietskonstituierende
Prozesse. LILOG-Report 18, IBM Germany, 1988.
[Hahn et al., 1980] W. v. Hahn, W: Hoeppner, A. Jame-
son, and W. Wahlster. The Anatomy of the Natural
Language Dialogue System HAM-RPM. In L. Bole,
editor, Natural Language Based Computer Systems,
pages 119-254. Miinchen: Hanser, 1980.
[Herskovits, 19851 A. Herskovits. Semantics and Prag-
matics of Locative Expressions. Cognitive Science,
9:341-378, 1985.
[Huf3mann and Schefe, 1984] M. Huf3mann and P. Sche-
fe. The Design of SWYSS, a Dialogue System for
Scene Analysis. In L. Bole, editor, Natural Language
Communication with Pictorial Information Process-
ing. Munchen: Hanser McMillan, 1984.
[Lakoff, 1972] G. Lakoff. Hedges: A Study in Meaning
Criteria and the Logic of Fuzzy Concepts. In J .N
Levi and C.C. Phares, editors, Papers from the 8th
regional Meeting of the Chicago Linguistics Society,
pages 183-228. University of Chicago, Chicago, IL,
1972.
[Marks and Reiter, 1990] J. Marks and E. Reiter.
Avoiding Unwanted Conversational Implicatures in
Text and Graphics. In Proc. 8th AAAI, pages 450-
455, 1990.
[Murch and Woodworth, 1978] G.M. Murch and GI.
Woodworth. Wahrnehmung. Stuttgart: Kohlhammer,
1978.
[Neumann and Novak, 1986] B. Neumann and H.-J. No-
vak. NAOS: Ein System zur natiirlichsprachlichen
Beschreibung zeitveranderlicher Szenen. Informatik
Forschuny und Entwicklung, pages 83-92, 1986.
[Pribbenow, 1990] S. Pribbenow. Interaktion von propo-
sitionalen und bildhaften Reprasentationen. In C. Ha-
bel and C. Freksa, editors, Reprdsentation und Ver-
arbeitung rdmlichen Wissens, pages 156-174. Berlin:
Springer, 1990.
[Retz-Schmidt, 1988] C. Retz-Schmidt. Various Views
on Spatial Prepositions. Al Magazine, 9(2):95-105,
1988.
[Roth et al., 1990] S. Roth, J. Mattis, and X. Mesnard.
Graphics and Natural Language as Components of
Automatic Explanation. In J. W. Sullivan and S. W.
Tyler, editors, Intelligent User Interfaces, pages 207-
239. Reading, MA: Addison Wesley, 1990.
[Schirra, to appear 1992] J. Schirra. A Contribution to
the Reference Semantics of Spatial Prepositions: The
Visualization Problem and its Solution in VITRA. In
Proceedings of the JAI Workshop &amp;quot;On the Semantics
of Prepositions in Natural Language Processing. Mou-
ton, de Gruyter, to appear 1992. Also available as
Technical Report 75, SFB 314, Department of Corn-
puter Science, University of Saarbriicken.
[Wahlster et al., 1978] W. Wahlster, A. Jameson, and
W. Hoeppner. Glancing, Referring and Explaining in
the Dialougue System HAM-RPM. American Journal
of Computer Linguistics, Microfiche 77, pages 53-67,
1978.
[Wahlster et al., 1991a]
W. Wahlster, E. Andre, S. Bandyopadhyay, W. Graf,
and T. Rist. WIP: The Coordinated Generation of
Multimodal Presentations from a Common Represen-
tation. In 0. Stock, J. Slack, and A. Ortony, editors,
Computational Theories of Communication and their
Applications. Berlin: Springer, 1991.
[Wahlster et al., 1991b] W. Wahlster, E. Andre,
W. Graf, and T. Rist. Designing Illustrated Text:
How Language Production is Influenced by Text and
Graphics. In Proc. 5th Conf. of the European Chap-
ter of the Association for Computational Linguistics
(EACL), pages 8-14, 1991.
[Wazinski, 1991] P. Wazinski. Objektlokalisation in gra-
phischen Darstellungen. Master&apos;s thesis, Universitat
Koblenz-Landau, Abt. Koblenz/DFKI Saarbriicken,
1991.
[Wunderlich and Herweg, forthcoming] D. Wunderlich
and M. Herweg. Lokale und Direktionale. In A. v.
Stechow and D. Wunderlich, editors, Handbuch der
Semantik. Konigstein Ts.: Athenaum Verlag, forth-
coming.
[Wunderlich, 1982] D. Wunderlich. Sprache und Raum.
Studium Linguistik, 12:1-19, 1982.
</reference>
<page confidence="0.999461">
63
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.971203">
<title confidence="0.999784">Generating Spatial Descriptions for Cross-modal References</title>
<author confidence="0.999886">Peter Wazinski</author>
<affiliation confidence="0.999941">Department of Computer Science University of Saarbriicken</affiliation>
<address confidence="0.999441">D-6600 Saarbriicken, Germany</address>
<email confidence="0.998047">wazinski©cs.uni-sb.de</email>
<abstract confidence="0.99904024137931">We present a localisation component that supports the generation of cross-modal deictic expressions in the knowledge-based presentation system WIP. We deal with relative localisations (e.g., &amp;quot;The object to the left of object X.&amp;quot;), absolute localisations (e.g., &amp;quot;The object in the upper left part of the picture.&amp;quot;) and corner localisations (e.g., &amp;quot;The object in the lower right corner of the picture&amp;quot;). In addition, we distinguish two localisation granularities, one less detailed (e.g., &amp;quot;the object. to the left of object X.&amp;quot;) and one more detailed (e.g., &amp;quot;the object above and to the left of object X.&amp;quot;). We consider corner localisations to be similar to absolute localisations and in turn absolute localisations to be specialisations of relative localisations. This allows us to compute all three localisation types with one generic localisation procedure. As elementary localisations are derived from previously computed composite localisations, we can cope with both localisation granularities in a computationally efficient way. Based on these primary localisation procedures, we discuss how objects can be localised among several other objects. Finally we introduce group localisations (e.g., &amp;quot;The object to left of the group of other objects.&amp;quot;) and show how to deal with them.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>1. In Part A of figure 15, the localisation of object C or D would be ambiguous with respect to A because for both objects the composite localisations, (x-center, top), are equal. 2. In Part B a composite localisation cannot be applied to object D (neither &amp;quot;D is above and to the right of A&amp;quot; nor &amp;quot;D is immediately above A&amp;quot; are adequate) and its elementary localisation, &apos;top&apos;, is part of the composite localisation, (x-center, top), of object C. 3. In Part C a composite localisation can be applied</title>
<marker></marker>
<rawString> 1. In Part A of figure 15, the localisation of object C or D would be ambiguous with respect to A because for both objects the composite localisations, (x-center, top), are equal. 2. In Part B a composite localisation cannot be applied to object D (neither &amp;quot;D is above and to the right of A&amp;quot; nor &amp;quot;D is immediately above A&amp;quot; are adequate) and its elementary localisation, &apos;top&apos;, is part of the composite localisation, (x-center, top), of object C. 3. In Part C a composite localisation can be applied</rawString>
</citation>
<citation valid="true">
<authors>
<author>E André</author>
<author>G Bosch</author>
<author>G Herzog</author>
<author>T Rist</author>
</authors>
<date>1985</date>
<booktitle>CITYTOUR — Ein natiirlichsprachliches Anfragesystem zur Evaluierung raumlicher Pripositionen. Abschluf3bericht des Fortgeschrittenenpraktikums,</booktitle>
<institution>Department of Computer Science, University of Saarbriicken,</institution>
<marker>[André et al., 1985]</marker>
<rawString>E. André, G. Bosch, G. Herzog, and T. Rist. CITYTOUR — Ein natiirlichsprachliches Anfragesystem zur Evaluierung raumlicher Pripositionen. Abschluf3bericht des Fortgeschrittenenpraktikums, Department of Computer Science, University of Saarbriicken, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E André</author>
<author>G Bosch</author>
<author>G Herzog</author>
<author>T Rist</author>
</authors>
<title>Characterising Trajectories of Moving Objects using Natural Language Path Descriptions.</title>
<date>1986</date>
<booktitle>In Proc. of the 7th ECAI,</booktitle>
<pages>1--8</pages>
<marker>[André et al., 1986]</marker>
<rawString>E. André, G. Bosch, G. Herzog, and T. Rist. Characterising Trajectories of Moving Objects using Natural Language Path Descriptions. In Proc. of the 7th ECAI, pages 1-8, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S K Feiner</author>
<author>K R McKeown</author>
</authors>
<title>Coordinating Text and Graphics in Explanation Generation.</title>
<date>1990</date>
<booktitle>In Proc. 8th AAAI,</booktitle>
<pages>442--449</pages>
<marker>[Feiner and McKeown, 1990]</marker>
<rawString>S. K. Feiner and K. R. McKeown. Coordinating Text and Graphics in Explanation Generation. In Proc. 8th AAAI, pages 442-449, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Habel</author>
<author>S Pribbenow</author>
</authors>
<title>Gebietskonstituierende Prozesse. LILOG-Report 18, IBM</title>
<date>1988</date>
<marker>[Habel and Pribbenow, 1988]</marker>
<rawString> C. Habel and S. Pribbenow. Gebietskonstituierende Prozesse. LILOG-Report 18, IBM Germany, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W v Hahn</author>
<author>W Hoeppner</author>
<author>A Jameson</author>
<author>W Wahlster</author>
</authors>
<title>The Anatomy of the Natural Language Dialogue System HAM-RPM.</title>
<date>1980</date>
<journal>Natural Language Based Computer Systems,</journal>
<booktitle>Herskovits, 19851 A. Herskovits. Semantics and Pragmatics of Locative Expressions. Cognitive Science,</booktitle>
<pages>119--254</pages>
<editor>In L. Bole, editor,</editor>
<location>Miinchen: Hanser,</location>
<marker>[Hahn et al., 1980]</marker>
<rawString>W. v. Hahn, W: Hoeppner, A. Jameson, and W. Wahlster. The Anatomy of the Natural Language Dialogue System HAM-RPM. In L. Bole, editor, Natural Language Based Computer Systems, pages 119-254. Miinchen: Hanser, 1980. [Herskovits, 19851 A. Herskovits. Semantics and Pragmatics of Locative Expressions. Cognitive Science, 9:341-378, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Huf3mann</author>
<author>P Schefe</author>
</authors>
<title>The Design of SWYSS, a Dialogue System for Scene Analysis. In</title>
<date>1984</date>
<booktitle>Natural Language Communication with Pictorial Information Processing.</booktitle>
<editor>L. Bole, editor,</editor>
<publisher>Munchen: Hanser McMillan,</publisher>
<marker>[Huf3mann and Schefe, 1984]</marker>
<rawString>M. Huf3mann and P. Schefe. The Design of SWYSS, a Dialogue System for Scene Analysis. In L. Bole, editor, Natural Language Communication with Pictorial Information Processing. Munchen: Hanser McMillan, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lakoff</author>
</authors>
<title>Hedges: A Study in Meaning Criteria and the Logic of Fuzzy Concepts.</title>
<date>1972</date>
<booktitle>Papers from the 8th regional Meeting of the Chicago Linguistics Society,</booktitle>
<pages>183--228</pages>
<editor>In J .N Levi and C.C. Phares, editors,</editor>
<institution>University of Chicago,</institution>
<location>Chicago, IL,</location>
<marker>[Lakoff, 1972]</marker>
<rawString>G. Lakoff. Hedges: A Study in Meaning Criteria and the Logic of Fuzzy Concepts. In J .N Levi and C.C. Phares, editors, Papers from the 8th regional Meeting of the Chicago Linguistics Society, pages 183-228. University of Chicago, Chicago, IL, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Marks</author>
<author>E Reiter</author>
</authors>
<title>Avoiding Unwanted Conversational Implicatures in Text and Graphics.</title>
<date>1990</date>
<booktitle>In Proc. 8th AAAI,</booktitle>
<pages>450--455</pages>
<marker>[Marks and Reiter, 1990]</marker>
<rawString>J. Marks and E. Reiter. Avoiding Unwanted Conversational Implicatures in Text and Graphics. In Proc. 8th AAAI, pages 450-455, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Woodworth Wahrnehmung</author>
</authors>
<date>1978</date>
<location>Stuttgart: Kohlhammer,</location>
<marker>[Murch and Woodworth, 1978]</marker>
<rawString>G.M. Murch and GI. Woodworth. Wahrnehmung. Stuttgart: Kohlhammer, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Neumann</author>
<author>H-J Novak</author>
</authors>
<date>1986</date>
<booktitle>NAOS: Ein System zur natiirlichsprachlichen Beschreibung zeitveranderlicher Szenen. Informatik Forschuny und Entwicklung,</booktitle>
<pages>83--92</pages>
<marker>[Neumann and Novak, 1986]</marker>
<rawString>B. Neumann and H.-J. Novak. NAOS: Ein System zur natiirlichsprachlichen Beschreibung zeitveranderlicher Szenen. Informatik Forschuny und Entwicklung, pages 83-92, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pribbenow</author>
</authors>
<title>Interaktion von propositionalen und bildhaften Reprasentationen.</title>
<date>1990</date>
<booktitle>Reprdsentation und Verarbeitung rdmlichen Wissens,</booktitle>
<pages>156--174</pages>
<editor>In C. Habel and C. Freksa, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin:</location>
<marker>[Pribbenow, 1990]</marker>
<rawString>S. Pribbenow. Interaktion von propositionalen und bildhaften Reprasentationen. In C. Habel and C. Freksa, editors, Reprdsentation und Verarbeitung rdmlichen Wissens, pages 156-174. Berlin: Springer, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Retz-Schmidt</author>
</authors>
<title>Various Views on Spatial Prepositions. Al Magazine,</title>
<date>1988</date>
<marker>[Retz-Schmidt, 1988]</marker>
<rawString>C. Retz-Schmidt. Various Views on Spatial Prepositions. Al Magazine, 9(2):95-105, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Roth</author>
<author>J Mattis</author>
<author>X Mesnard</author>
</authors>
<title>Graphics and Natural Language as Components of Automatic Explanation.</title>
<date>1990</date>
<booktitle>Intelligent User Interfaces,</booktitle>
<pages>207--239</pages>
<editor>In J. W. Sullivan and S. W. Tyler, editors,</editor>
<publisher>Addison Wesley,</publisher>
<location>Reading, MA:</location>
<marker>[Roth et al., 1990]</marker>
<rawString>S. Roth, J. Mattis, and X. Mesnard. Graphics and Natural Language as Components of Automatic Explanation. In J. W. Sullivan and S. W. Tyler, editors, Intelligent User Interfaces, pages 207-239. Reading, MA: Addison Wesley, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schirra</author>
</authors>
<title>A Contribution to the Reference Semantics of Spatial Prepositions: The Visualization Problem and its Solution in VITRA.</title>
<date>1992</date>
<booktitle>In Proceedings of the JAI Workshop &amp;quot;On the Semantics of Prepositions in Natural Language Processing.</booktitle>
<tech>Technical Report 75, SFB 314,</tech>
<institution>Department of Cornputer Science, University of Saarbriicken.</institution>
<note>Mouton, de Gruyter, to appear</note>
<marker>[Schirra, to appear 1992]</marker>
<rawString>J. Schirra. A Contribution to the Reference Semantics of Spatial Prepositions: The Visualization Problem and its Solution in VITRA. In Proceedings of the JAI Workshop &amp;quot;On the Semantics of Prepositions in Natural Language Processing. Mouton, de Gruyter, to appear 1992. Also available as Technical Report 75, SFB 314, Department of Cornputer Science, University of Saarbriicken.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glancing</author>
</authors>
<title>Referring and Explaining in the Dialougue System HAM-RPM.</title>
<date>1978</date>
<journal>American Journal of Computer Linguistics, Microfiche</journal>
<volume>77</volume>
<pages>53--67</pages>
<marker>[Wahlster et al., 1978]</marker>
<rawString>W. Wahlster, A. Jameson, and W. Hoeppner. Glancing, Referring and Explaining in the Dialougue System HAM-RPM. American Journal of Computer Linguistics, Microfiche 77, pages 53-67, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
<author>E Andre</author>
<author>S Bandyopadhyay</author>
<author>W Graf</author>
<author>T Rist</author>
</authors>
<title>WIP: The Coordinated Generation of Multimodal Presentations from a Common Representation. In</title>
<date>1991</date>
<booktitle>Computational Theories of Communication and their Applications.</booktitle>
<editor>0. Stock, J. Slack, and A. Ortony, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin:</location>
<marker>[Wahlster et al., 1991a]</marker>
<rawString> W. Wahlster, E. Andre, S. Bandyopadhyay, W. Graf, and T. Rist. WIP: The Coordinated Generation of Multimodal Presentations from a Common Representation. In 0. Stock, J. Slack, and A. Ortony, editors, Computational Theories of Communication and their Applications. Berlin: Springer, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
<author>E Andre</author>
<author>W Graf</author>
<author>T Rist</author>
</authors>
<title>Designing Illustrated Text: How Language Production is Influenced by Text and Graphics.</title>
<date>1991</date>
<booktitle>In Proc. 5th Conf. of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>8--14</pages>
<marker>[Wahlster et al., 1991b]</marker>
<rawString>W. Wahlster, E. Andre, W. Graf, and T. Rist. Designing Illustrated Text: How Language Production is Influenced by Text and Graphics. In Proc. 5th Conf. of the European Chapter of the Association for Computational Linguistics (EACL), pages 8-14, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wazinski</author>
</authors>
<title>Objektlokalisation in graphischen Darstellungen.</title>
<date>1991</date>
<tech>Master&apos;s thesis,</tech>
<institution>Universitat Koblenz-Landau, Abt. Koblenz/DFKI Saarbriicken,</institution>
<marker>[Wazinski, 1991]</marker>
<rawString>P. Wazinski. Objektlokalisation in graphischen Darstellungen. Master&apos;s thesis, Universitat Koblenz-Landau, Abt. Koblenz/DFKI Saarbriicken, 1991.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D Wunderlich</author>
<author>M Herweg</author>
</authors>
<title>Lokale und Direktionale.</title>
<editor>In A. v. Stechow and D. Wunderlich, editors, Handbuch der Semantik. Konigstein Ts.:</editor>
<publisher>Athenaum Verlag, forthcoming.</publisher>
<marker>[Wunderlich and Herweg, forthcoming]</marker>
<rawString>D. Wunderlich and M. Herweg. Lokale und Direktionale. In A. v. Stechow and D. Wunderlich, editors, Handbuch der Semantik. Konigstein Ts.: Athenaum Verlag, forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wunderlich</author>
</authors>
<title>Sprache und Raum.</title>
<date>1982</date>
<journal>Studium Linguistik,</journal>
<pages>12--1</pages>
<marker>[Wunderlich, 1982]</marker>
<rawString>D. Wunderlich. Sprache und Raum. Studium Linguistik, 12:1-19, 1982.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>