<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000700">
<title confidence="0.977162">
Cross-Lingual Latent Topic Extraction
</title>
<author confidence="0.995267">
Duo Zhang Qiaozhu Mei ChengXiang Zhai
</author>
<affiliation confidence="0.997189">
University of Illinois at University of Michigan University of Illinois at
</affiliation>
<email confidence="0.891634">
Urbana-Champaign qmei@umich.edu Urbana-Champaign
dzhang22@cs.uiuc.edu czhai@cs.uiuc.edu
</email>
<sectionHeader confidence="0.993603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998446">
Probabilistic latent topic models have re-
cently enjoyed much success in extracting
and analyzing latent topics in text in an un-
supervised way. One common deficiency
of existing topic models, though, is that
they would not work well for extracting
cross-lingual latent topics simply because
words in different languages generally do
not co-occur with each other. In this paper,
we propose a way to incorporate a bilin-
gual dictionary into a probabilistic topic
model so that we can apply topic models to
extract shared latent topics in text data of
different languages. Specifically, we pro-
pose a new topic model called Probabilis-
tic Cross-Lingual Latent Semantic Anal-
ysis (PCLSA) which extends the Proba-
bilistic Latent Semantic Analysis (PLSA)
model by regularizing its likelihood func-
tion with soft constraints defined based on
a bilingual dictionary. Both qualitative and
quantitative experimental results show that
the PCLSA model can effectively extract
cross-lingual latent topics from multilin-
gual text data.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998547018518519">
As a robust unsupervised way to perform shallow
latent semantic analysis of topics in text, prob-
abilistic topic models (Hofmann, 1999a; Blei et
al., 2003b) have recently attracted much atten-
tion. The common idea behind these models is the
following. A topic is represented by a multino-
mial word distribution so that words characteriz-
ing a topic generally have higher probabilities than
other words. We can then hypothesize the exis-
tence of multiple topics in text and define a gener-
ative model based on the hypothesized topics. By
fitting the model to text data, we can obtain an es-
timate of all the word distributions corresponding
to the latent topics as well as the topic distributions
in text. Intuitively, the learned word distributions
capture clusters of words that co-occur with each
other probabilistically.
Although many topic models have been pro-
posed and shown to be useful (see Section 2 for
more detailed discussion of related work), most
of them share a common deficiency: they are de-
signed to work only for mono-lingual text data and
would not work well for extracting cross-lingual
latent topics, i.e. topics shared in text data in
two different natural languages. The deficiency
comes from the fact that all these models rely on
co-occurrences of words forming a topical cluster,
but words in different language generally do not
co-occur with each other. Thus with the existing
models, we can only extract topics from text in
each language, but cannot extract common topics
shared in multiple languages.
In this paper, we propose a novel topic model,
called Probabilistic Cross-Lingual Latent Seman-
tic Analysis (PCLSA) model, which can be used to
mine shared latent topics from unaligned text data
in different languages. PCLSA extends the Proba-
bilistic Latent Semantic Analysis (PLSA) model
by regularizing its likelihood function with soft
constraints defined based on a bilingual dictio-
nary. The dictionary-based constraints are key to
bridge the gap of different languages and would
force the captured co-occurrences of words in
each language by PCLSA to be “synchronized”
so that related words in the two languages would
have similar probabilities. PCLSA can be esti-
mated efficiently using the General Expectation-
Maximization (GEM) algorithm. As a topic ex-
traction algorithm, PCLSA would take a pair of
unaligned document sets in different languages
and a bilingual dictionary as input, and output a
set of aligned word distributions in both languages
that can characterize the shared topics in the two
languages. In addition, it also outputs a topic cov-
</bodyText>
<page confidence="0.950299">
1128
</page>
<note confidence="0.9421215">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1128–1137,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999968971428572">
erage distribution for each language to indicate the
relative coverage of different shared topics in each
language.
To the best of our knowledge, no previous work
has attempted to solve this topic extraction prob-
lem and generate the same output. The closest
existing work to ours is the MuTo model pro-
posed in (Boyd-Graber and Blei, 2009) and the
JointLDA model published recently in (Jagarala-
mudi and Daum´e III, 2010). Both used a bilingual
dictionary to bridge the language gap in a topic
model. However, the goals of their work are dif-
ferent from ours in that their models mainly focus
on mining cross-lingual topics of matching word
pairs and discovering the correspondence at the
vocabulary level. Therefore, the topics extracted
using their model cannot indicate how a common
topic is covered differently in the two languages,
because the words in each word pair share the
same probability in a common topic. Our work fo-
cuses on discovering correspondence at the topic
level. In our model, since we only add a soft con-
straint on word pairs in the dictionary, their prob-
abilities in common topics are generally different,
naturally capturing which shows the different vari-
ations of a common topic in different languages.
We use a cross-lingual news data set and a re-
view data set to evaluate PCLSA. We also propose
a “cross-collection” likelihood measure to quanti-
tatively evaluate the quality of mined topics. Ex-
perimental results show that the PCLSA model
can effectively extract cross-lingual latent topics
from multilingual text data, and it outperforms a
baseline approach using the standard PLSA on text
data in each language.
</bodyText>
<sectionHeader confidence="0.999765" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999844487804878">
Many topic models have been proposed, and the
two basic models are the Probabilistic Latent Se-
mantic Analysis (PLSA) model (Hofmann, 1999a)
and the Latent Dirichlet Allocation (LDA) model
(Blei et al., 2003b). They and their extensions
have been successfully applied to many prob-
lems, including hierarchical topic extraction (Hof-
mann, 1999b; Blei et al., 2003a; Li and McCal-
lum, 2006), author-topic modeling (Steyvers et al.,
2004), contextual topic analysis (Mei and Zhai,
2006), dynamic and correlated topic models (Blei
and Lafferty, 2005; Blei and Lafferty, 2006), and
opinion analysis (Mei et al., 2007; Branavan et al.,
2008). Our work is an extension of PLSA by in-
corporating the knowledge of a bilingual dictio-
nary as soft constraints. Such an extension is sim-
ilar to the extension of PLSA for incorporating so-
cial network analysis (Mei et al., 2008a) but our
constraint is different.
Some previous work on multilingual topic mod-
els assume documents in multiple languages are
aligned either at the document level, sentence level
or by time stamps (Mimno et al., 2009; Zhao and
Xing, 2006; Kim and Khudanpur, 2004; Ni et al.,
2009; Wang et al., 2007). However, in many ap-
plications, we need to mine topics from unaligned
text corpus. For example, mining topics from
search results in different languages can facilitate
summarization of multilingual search results.
Besides all the multilingual topic modeling
work discussed above, comparable corpora have
also been studied extensively (e.g. (Fung, 1995;
Franz et al., 1998; Masuichi et al., 2000; Sadat
et al., 2003; Gliozzo and Strapparava, 2006)), but
most previous work aims at acquiring word trans-
lation knowledge or cross-lingual text categoriza-
tion from comparable corpora. Our work differs
from this line of previous work in that our goal is
to discover shared latent topics from multi-lingual
text data that are weakly comparable (e.g. the data
does not have to be aligned by time).
</bodyText>
<sectionHeader confidence="0.987157" genericHeader="method">
3 Problem Formulation
</sectionHeader>
<bodyText confidence="0.999886272727273">
In general, the problem of cross-lingual topic ex-
traction can be defined as to extract a set of com-
mon cross-lingual latent topics covered in text col-
lections in different natural languages. A cross-
lingual latent topic will be represented as a multi-
nomial word distribution over the words in all
the languages, i.e. a multilingual word distri-
bution. For example, given two collections of
news articles in English and Chinese, respectively,
we would like to extract common topics simul-
taneously from the two collections. A discov-
ered common topic, such as the terrorist attack
on September 11, 2001, would be characterized
by a word distribution that would assign relatively
high probabilities to words related to this event in
both English and Chinese (e.g. “terror”, “attack”,
“afghanistan”, “taliban”, and their translations in
Chinese).
As a computational problem, our input is a
multi-lingual text corpus, and output is a set of
cross-lingual latent topics. We now define this
problem more formally.
</bodyText>
<page confidence="0.992248">
1129
</page>
<bodyText confidence="0.96966355">
Definition 1(Multi-Lingual Corpus) A multi-
lingual corpus C is a set of text collections
{C1, C2, ... , Cs}, where Ci = {di1, di2,..., di Mi}
is a collection of documents in language Li with
vocabulary Vi = {wi1, wi2, ... , wiNi}. Here, Mi is
the total number of documents in Ci, Ni is the to-
tal number of words in Vi, and dij is a document in
collection Ci.
Following the common assumption of bag-of-
words representation, we represent document dij
with a bag of words {wij1, wi j2,..., wijd}, and use
c(wik, dij) to denote the count of word wik in docu-
ment dij.
Definition 2 (Cross-Lingual Topic): A cross-
lingual topic θ is a semantically coherent multi-
nomial distribution over all the words in the vo-
cabularies of languages L1, ..., Ls. That is, p(w|θ)
would give the probability of a word w which can
be in any of the s languages under consideration. θ
is semantically coherent if it assigns high probabil-
ities to words that are semantically related either in
the same language or across different languages.
Clearly, we have Es�w∈Vi p(w|θ) = 1 for any
i=1
cross-lingual topic θ.
Definition 3 (Cross-Lingual Topic Extrac-
tion) Given a multi-lingual corpus C, the task of
cross-lingual topic extraction is to model and ex-
tract k major cross-lingual topics {θ1, θ2, ... , θk}
from C, where θi is a cross-lingual topic, and k is
a user specified parameter.
The extracted cross-lingual topics can be di-
rectly used as a summary of the common con-
tent of the multi-lingual data set. Note that once
a cross-lingual topic is extracted, we can eas-
ily obtain its representation in each language Li
by “splitting” the cross-lingual topic into multi-
ple word distributions in different languages. For-
mally, the word distribution of a cross-lingual
topic θ in language Li is given by pi(wi|θ) =
</bodyText>
<equation confidence="0.679123">
p(wi|θ)
� w∈Vi p(w|θ).
</equation>
<bodyText confidence="0.9999472">
These aligned language-specific word distribu-
tions can directly review the variations of topics
in different languages. They can also be used to
analyze the difference of the coverage of the same
topic in different languages. Moreover, they are
also useful for retrieving relevant articles or pas-
sages in each language and aligning them to the
same common topic, thus essentially also allow-
ing us to integrate and align articles in multiple
languages.
</bodyText>
<sectionHeader confidence="0.922902" genericHeader="method">
4 Probabilistic Cross-Lingual Latent
</sectionHeader>
<subsectionHeader confidence="0.936154">
Semantic Analysis
</subsectionHeader>
<bodyText confidence="0.999984469387755">
In this section, we present our probabilistic cross-
lingual latent semantic analysis (PCLSA) model
and discuss how it can be used to extract cross-
lingual topics from multi-lingual text data.
The main reason why existing topic models
can’t be used for cross-lingual topic extraction is
because they cannot cross the language barrier.
Intuitively, in order to cross the language barrier
and extract a common topic shared in articles in
different languages, we must rely on some kind
of linguistic knowledge. Our PCLSA model as-
sumes the availability of bi-lingual dictionaries for
at least some language pairs, which are generally
available for major language pairs. Specifically,
for text data in languages L1, ..., Ls, if we rep-
resent each language as a node in a graph and
connect those language pairs for which we have a
bilingual dictionary, the minimum requirement is
that the whole graph is connected. Thus, as a min-
imum, we will need s −1 distinct bilingual dictio-
naries. This is so that we can potentially cross all
the language barriers.
Our key idea is to “synchronize” the extraction
of monolingual “component topics” of a cross-
lingual topic from individual languages by forcing
a cross-lingual topic word distribution to assign
similar probabilities to words that are potential
translations according to a Li-Lj bilingual dictio-
nary. We achieve this by adding such preferences
formally to the likelihood function of a probabilis-
tic topic model as “soft constraints” so that when
we estimate the model, we would try to not only
fit the text data well (which is necessary to extract
coherent component topics from each language),
but also satisfy our specified preferences (which
would ensure the extracted component topics in
different languages are semantically related). Be-
low we present how we implement this idea in
more detail.
A bilingual dictionary for languages Li and Lj
generally would give us a many-to-many map-
ping between the vocabularies of the two lan-
guages. With such a mapping, we can construct
a bipartite graph Gij = (Vij, Eij) between the
two languages where if one word can be poten-
tially translated into another word, the two words
would be connected with an edge. An edge can
be weighted based on the probability of the cor-
responding translation. An example graph for
</bodyText>
<page confidence="0.94016">
1130
</page>
<figure confidence="0.425716">
Chinese-English dictionary is shown in Figure 1.
</figure>
<figureCaption confidence="0.999796">
Figure 1: A Dictionary based Word Graph
</figureCaption>
<bodyText confidence="0.999969730769231">
With multiple bilingual dictionaries, we can
merge the graphs to generate a multi-partite graph
G = (V, E). Based on this graph, the PCLSA
model extends the standard PLSA by adding a
constraint to the likelihood function to “smooth”
the word distributions of topics in PLSA on the
multi-partite graph so that we would encourage the
words that are connected in the graph (i.e. pos-
sible translations of each other) to be given simi-
lar probabilities by every cross-lingual topic. Thus
when a cross-lingual topic picks up words that co-
occur in mono-lingual text, it would prefer pick-
ing up word pairs whose translations in other lan-
guages also co-occur with each other, giving us a
coherent multilingual word distribution that char-
acterizes well the content of text in different lan-
guages.
Specifically, let O = {Bj} (j = 1, ..., k) be a set
of k cross-lingual topic models to be discovered
from a multilingual text data set with s languages
such that p(w|Oi) is the probability of word w ac-
cording to the topic model Bi.
If we are to use the regular PLSA to model our
data, we would have the following log-likelihood
and we usually use a maximum likelihood estima-
tor to estimate parameters and discover topics.
</bodyText>
<equation confidence="0.755549">
p(0j|d)p(w|0j)
</equation>
<bodyText confidence="0.999731857142857">
Our main extension is to add to L(C) a cross-
lingual constraint term R(C) to incorporate the
knowledge of bilingual dictionaries. R(C) is de-
fined as
where w(u, v) is the weight on the edge between
u and v in the multi-partite graph G = (V, E),
which in our experiments is set to 1, and Deg(u)
is the degree of word u, i.e. the sum of the weights
of all the edges ending with u.
Intuitively, R(C) measures the difference be-
tween p(wu|0j) and p(wv|0j) for each pair (u, v)
in a bilingual dictionary; the more they differ, the
larger R(C) would be. So it can be regarded as
a “loss function” to help us assess how well the
“component word distributions” in multiple lan-
guages are correlated semantically. Clearly, we
would like the extracted topics to have a small
R(C). We choose this specific form of loss func-
tion because it would make it convenient to solve
the optimization problem of maximizing the cor-
responding regularized maximum likelihood (Mei
et al., 2008b). The normalization with Deg(u)
and Deg(v) can be regarded as a way to compen-
sate for the potential ambiguity of u and v in their
translations.
Putting L(C) and R(C) together, we would
like to maximize the following objective function
which is a regularized log-likelihood:
</bodyText>
<equation confidence="0.971124">
O(C, G) = (1 − A)L(C) − AR(C) (1)
</equation>
<bodyText confidence="0.997117388888889">
where A E (0, 1) is a parameter to balance the
likelihood and the regularizer. When A = 0, we
recover the standard PLSA.
Specifically, we will search for a set of values
for all our parameters that can maximize the ob-
jective function defined above. Our parameters
include all the cross-lingual topics and the cov-
erage distributions of the topics in all documents,
which we denote by IF = {p(w|0j), p(Bj|d)}d,w,j
where j = 1, ..., k, w varies over the entire vo-
cabularies of all the languages , d varies over
all the documents in our collection. This opti-
mization problem can be solved using a General-
ized Expectation-Maximization (GEM) algorithm
as described in (Mei et al., 2008a).
Specifically, in the E-step of the algorithm, the
distribution of hidden variables is computed using
Eq. 2.
</bodyText>
<equation confidence="0.996948">
z(w, d, j) = p(0j|d)p(w|0j) (2)
∑j′ p(Bj′  |d)p(w|0j′)
</equation>
<bodyText confidence="0.994517">
Then in the M-step, we need to maximize the
complete data likelihood Q(IF; IFn):
</bodyText>
<equation confidence="0.99575028">
Q(&apos;F; IFn) = (1 − A)L′(C) − AR(C)
∑
1
R(C) = 2
(u,v)EE
(p(wu|ej) p(wv|ej) 2
D D
eg(u) � eg(v) )
k
∑
j=1
w(u, v)
∑s
i=1
c(w, d) log
L(C) =
∑
w
k
∑
j=1
∑
d∈Ci
1131
z(w, d, j) log p(Bj|d)p(w|Bj), (3)
</equation>
<bodyText confidence="0.836503">
with the constraints that ∑j p(θj|d) = 1 and
∑w p(w|θj) = 1.
There is a closed form solution if we only want
to maximize the L′(C) part:
</bodyText>
<equation confidence="0.962882166666667">
p(n+1)(θj|d) =
∑ ∑j′ c(w, d)z(w, d, j′)
w
∑d c(w, d)z(w, d, j)
p(n+1)(w|θj) = ∑ ∑′ w c(w′, d)z(w′, d, j)(4)
d
</equation>
<bodyText confidence="0.999862444444445">
However, there is no closed form solution in the
M-step for the whole objective function. Fortu-
nately, according to GEM we do not need to find
the local maximum of Q(Ψ; Ψn) in every M-step,
and we only need to find a new value Ψn+1 to im-
prove the complete data likelihood, i.e. to make
sure Q(Ψn+1;Ψn) &gt; Q(Ψn; Ψn). So our method
is to first maximize the L′(C) part using Eq. 4 and
then use Eq. 5 to gradually increase the R(C) part.
</bodyText>
<equation confidence="0.998611">
p(t+1)(wu|θj) = (1 − α)p(t)(wu|θj) (5)
Deg(v)p(t)(wv|θj)
w(u, v)
</equation>
<bodyText confidence="0.999863777777778">
Here, parameter α is the length of each smooth-
ing step. Obviously, after each smoothing step,
the sum of the probabilities of all the words in one
topic is still equal to 1. We smooth the parameters
until we cannot get a better parameter set Ψn+1.
Then, we continue to the next E-step. If there is
no Ψn+1 s.t. Q(Ψn+1;Ψn) &gt; Q(Ψn; Ψn), then
we consider Ψn to be the local maximum point of
the objective function Eq. 1.
</bodyText>
<sectionHeader confidence="0.99942" genericHeader="method">
5 Experiment Design
</sectionHeader>
<subsectionHeader confidence="0.998419">
5.1 Data Set
</subsectionHeader>
<bodyText confidence="0.999977315789474">
The data set we used in our experiment is collected
from news articles of Xinhua English and Chi-
nese newswires. The whole data set is quite big,
containing around 40,000 articles in Chinese and
35,000 articles in English. For different purpose of
our experiments, we randomly selected different
number of documents from the whole corpus, and
we will describe the concrete statistics in each ex-
periment. To process the Chinese corpus, we use
a simple segmenter1 to split the data into Chinese
phrases. Both Chinese and English stopwords are
removed from our data.
The dictionary file we used for our PCLSA
model is from mandarintools.com2. For each Chi-
nese phrase, if it has several English meanings, we
add an edge between it and each of its English
translation. If one English translation is an En-
glish phrase, we add an edge between the Chinese
phrase and each English word in the phrase.
</bodyText>
<subsectionHeader confidence="0.993232">
5.2 Baseline Method
</subsectionHeader>
<bodyText confidence="0.999982916666667">
As a baseline method, we can apply the standard
PLSA (Hofmann, 1999a) directly to the multi-
lingual corpus. Since PLSA takes advantage of
the word co-occurrences in the document level to
find semantic topics, directly using it for a multi-
lingual corpus will result in finding topics mainly
reflecting a single language (because words in dif-
ferent languages would not co-occur in the same
document in general). That is, the discovered top-
ics are mostly monolingual. These monolingual
topics can then be aligned based on a bilingual dic-
tionary to suggest a possible cross-lingual topic.
</bodyText>
<sectionHeader confidence="0.994994" genericHeader="evaluation">
6 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.990808">
6.1 Qualitative Comparison
</subsectionHeader>
<bodyText confidence="0.96304025">
To qualitatively compare PCLSA with the baseline
method, we compare the word distributions of top-
ics extracted by them. The data set we used in this
experiment is selected from the Xinhua News data
during the period from Jun. 8th, 2001 to Jun. 15th,
2001. There are totally 1799 English articles and
1485 Chinese articles in the data set. The num-
ber of topics to be extracted is set to 10 for both
methods.
Table 1 shows the experimental results. To
make it easier to understand, we add an English
translation to each Chinese phrase in our results.
The first ten rows show sample topics of the mod-
eling results of traditional PLSA model. We can
see that it only contains mono-language topics,
i.e. the topics are either in Chinese or in En-
glish. The next ten rows are the results from
our PCLSA model. Compared with the base-
line method, PCLSA can not only find coherent
topics from the cross-lingual corpus, but it can
also show the content about one topic from both
two language corpora. For example, in ’Topic 2’
lhttp://www.mandarintools.com/segmenter.html
zhttp://www.mandarintools.com/cedict.html
</bodyText>
<figure confidence="0.952066857142857">
where ∑ ∑c(w, d)
∑L′(C) � w j
d
∑
w c(w, d)z(w, d, j)
∑+ α
(u,v)EE
</figure>
<page confidence="0.994634">
1132
</page>
<tableCaption confidence="0.996102">
Table 2: Synthetic Data Set from Xinhua News
</tableCaption>
<table confidence="0.911723">
English Shrine Olympic Championship
90 101 70
Chinese CPC Anniversary Afghan War Championship
95 206 72
</table>
<bodyText confidence="0.997635444444444">
which is about ’Israel’ and ’Palestinian’, the Chi-
nese corpus mentions a lot about ’Arafat’ who is
the leader of ’Palestinian’, while the English cor-
pus discusses more on topics such as ’cease fire’
and ’women’. Similarly, in ’Topic 9’, the topic
is related to Philippine, the Chinese corpus men-
tions some environmental situation in Philippine,
while the English corpus mentions a lot about
’Abu Sayyaf’.
</bodyText>
<subsectionHeader confidence="0.996428">
6.2 Discovering Common Topics
</subsectionHeader>
<bodyText confidence="0.999986823529412">
To demonstrate the ability of PCLSA for finding
common topics in cross-lingual corpus, we use
some event names, e.g. ’Shrine’ and ’Olympic’,
as queries and randomly select a certain number of
documents from the whole corpus, which are re-
lated to the queries. The number of documents for
each query in the synthetic data set is shown in Ta-
ble 2. In either the English corpus or the Chinese
corpus, we select a smaller number of documents
about topic ’Championship’ combined with the
other two topics in the same corpus. In this way,
when we want to extract two topics from either En-
glish or Chinese corpus, the ’Championship’ topic
may not be easy to extract, because the other two
topics have more documents in the corpus. How-
ever, when we use PCLSA to extract four topics
from the two corpora together, we expect that the
topic ’Championship’ will be found, because now
the sum of English and Chinese documents related
to ’Championship’ is larger than other topics. The
experimental result is shown in Table 3. The first
two columns are the two topics extracted from En-
gish corpus, the third and the forth columns are
two topics from Chinese corpus, and the other four
columns are the results from cross-lingual cor-
pus. We can see that in either the Chinese sub-
collection or the English sub-collection, the topic
’Championship’ is not extracted as a significant
topic. But, as expected, the topic ’Championship’
is extracted from the cross-lingual corpus, while
the topic ’Olympic’ and topic ’Shrine’ are merged
together. This demonstrate that PCLSA is capable
of extracting common topics from a cross-lingual
corpus.
</bodyText>
<subsectionHeader confidence="0.998289">
6.3 Quantitative Evaluation
</subsectionHeader>
<bodyText confidence="0.994592078431373">
We also quantitatively evaluate how well our
PCLSA model can discover common topics
among corpus in different languages. We pro-
pose a “cross-collection” likelihood measure for
this purpose. The basic idea is: suppose we got
k cross-lingual topics from the whole corpus, then
for each topic, we split the topic into two sepa-
rate set of topics, English topics and Chinese top-
ics, using the splitting formula described before,
i.e. pi(wi|o) _ �w∈1wz|θ) |θ� . Then, we use the
z
word distribution of the Chinese topics (translating
the words into English) to fit the English Corpus
and use the word distribution of the English top-
ics (translating the words into Chinese) to fit the
Chinese Corpus. If the topics mined are common
topics in the whole corpus, then such a “cross-
collection” likelihood should be larger than those
topics which are not commonly shared by the En-
glish and the Chinese corpus. To calculate the
likelihood of fitness, we use the folding-in method
proposed in (Hofmann, 2001). To translate topics
from one language to another, e.g. Chinese to En-
glish, we look up the bilingual dictionary and do
word-to-word translation. If one Chinese word has
several English translations, we simply distribute
its probability mass equally to each English trans-
lation.
For comparison, we use the standard PLSA
model as the baseline. Basically, suppose PLSA
mined k semantic topics in the Chinese corpus and
k semantic topics in the English corpus. Then, we
also use the “cross-collection” likelihood measure
to see how well those k semantic Chinese topics fit
the English corpus and those k semantic English
topics fit the Chinese corpus.
We totally collect three data sets to compare the
performance. For the first data set, (English 1,
Chinese 1), both the Chinese and English corpus
are chosen from the Xinhua News Data during
the period from 2001.06.08 to 2001.06.15, which
has 1799 English articles and 1485 Chinese ar-
ticles. For the second data set, (English 2, Chi-
nese 2), the Chinese corpus Chinese 2 is the same
as Chinese 1, but the English corpus is chosen
from 2001.06.14 to 2001.06.19 which has 1547
documents. For the third data set, (English 3, Chi-
nese 3), the Chinese corpus is the same as in data
set one, but the English corpus is chosen from
2001.10.02 to 2001.10.07 which contains 1530
documents. In other words, in the first data set,
</bodyText>
<page confidence="0.996077">
1133
</page>
<tableCaption confidence="0.998398">
Table 1: Qualitative Evaluation
</tableCaption>
<table confidence="0.999748142857143">
Topic 0 Topic 1 Topic 2 Topic 3 Topic 4 Topic 5 Topic 6 Topic 7 Topic 8 Topic 9
A(party) o(crime) {&amp;(athlete) (palestine) f1=(collaboration) (education) israel bt dollar china
A(communist) V(agriculture) (champion) (palestine) (shanghai) (ball) palestinian beat percent cooperate
(revolution) (travel) (championship) (israel) A(relation) (league) eu final million shanghai
A(party member) M(heathendom) a(base) f#(cease fire) (bilateral) 0(soccer) police championship index develop
A(central) (public security) (badminton) (UN) (trade) (minute) report play stock beije
(ism) (name) 4(sports) A,:.(mid east) AqE(president) K(team member) secure champion point particulate
(cadre) (case) (final) N(lebanon) (country) (teacher) kill win share matter
A,:.(chairman mao) (law enforcement) 49(macedon) (friendly) ��(school) europe olympic close sco
(chinese communist) (city) *$(chess) 5�(conflict) �(meet) K(team) egypt game 0 invest
%(leader) (penalize) (fitness) (talk) (russia) (grade A) treaty cup billion project
(bilateral) (league) israel cooperate A(athlete) party eu invest 0 (absorb)
f1=(collaboration) (name) (israel) sco particulate A(party) khatami Wf(investment) dollar II
(talk) (ball) bt develop  communist ireland (billion) percent (abu)
(friendly) (shenhua) palestinian country athlete revolution (ireland) (education) index I
(palestine) (host) ceasefire president champion (-ism) elect (environ. protect.) million (particle)
country A *(arafat) apec ii (antiwar) vote (money) stock philippine
(UN) ball women shanghai *$(chess) II(comrade) presidential ��(school) billion abu
%(leader)  (jinde) jerusalem africa competition (revolution) cpc market point a(base)
bilateral (season) mideast meet contestant AHR(party) iran (teacher) (billion) III
state (player) lebanon (zemin jiang) 4(gymnastics) ideology referendum business share ftobject)
</table>
<tableCaption confidence="0.997409">
Table 3: Effectiveness of Extracting Common Topics
</tableCaption>
<table confidence="0.948500818181818">
English 1 English 2 Chinese 1 Chinese 2 Cross 1 Cross 2 Cross 3 Cross 4
japan olympic A(CPC) (afghan) koizumi (taliban) swim (worker)
shrine ioc (championship) (taliban) yasukuni (military) (championship) party
visit beije (world) (taliban) ioc city N(free style) (three)
koizumi game AR(thought) (military) japan refugee Ok(diving) (marx)
yasukuni july (theory) IT(attack) olympic side (championship) communist
war bid (marx) (US army) beije (US army) (semi final) marx
august swim (swim) fl-(laden) shrine (bomb) competition theory
asia vote (championship) K(army) visit (kabul) (swim) A(found party)
criminal championship A(party) (bomb) (olympic)  (attack) (record) A(CPC)
ii committee A(found party) (kabul) F—(olympic) 4(refugee)  (xuejuan luo) revolution
</table>
<bodyText confidence="0.998867838709677">
the English corpus and Chinese corpus are com-
parable with each other, because they cover simi-
lar events during the same period. In the second
data set, the English and Chinese corpora share
some common topics during the overlap period.
The third data is the most tough one since the two
corpora are from different periods. The purpose of
using these three different data sets for evaluation
is to test how well PCLSA can mine common top-
ics from either a data set where the English corpus
and the Chinese corpus are comparable or a data
set where the English corpus and the Chinese cor-
pus rarely share common topics.
The experimental results are shown in Table 4.
Each row shows the “cross-collection” likelihood
of using the “cross-collection” topics to fit the data
set named in the first column. For example, in
the first row, the values are the “cross-collection”
likelihood of using Chinese topics found by differ-
ent methods from the first data set to fit English 1.
The last collum shows how much improvement we
got from PCLSA compared with PLSA. From the
results, we can see that in all the data sets, our
PCLSA has higher “cross-collection” likelihood
value, which means it can find better common top-
ics compared to the baseline method. Notice that
the Chinese corpora are the same in all three data
sets. The results show that both PCLSA and PLSA
get lower “cross-collection” likelihood for fitting
the Chinese corpora when the data set becomes
“tougher”, i.e. less topic overlapping, but the im-
</bodyText>
<tableCaption confidence="0.8444825">
Table 4: Quantitative Evaluation of Common
Topic Finding (“cross-collection” log-likelihood)
</tableCaption>
<table confidence="0.949554714285714">
PCLSA PLSA Rel. Imprv.
English 1 -2.86294E+06 -3.03176E+06 5.6%
Chinese 1 -4.69989E+06 -4.85369E+06 3.2%
English 2 -2.48174E+06 -2.60805E+06 4.8%
Chinese 2 -4.73218E+06 -4.88906E+06 3.2%
English 3 -2.44714E+06 -2.60540E+06 6.1%
Chinese 3 -4.79639E+06 -4.94273E+06 3.0%
</table>
<bodyText confidence="0.9753672">
provement of PCLSA over PLSA does not drop
much. On the other hand, the improvement of
PCLSA over PLSA on the three English corpora
does not show any correlation with the difficulty
of the data set.
</bodyText>
<subsectionHeader confidence="0.999549">
6.4 Extracting from Multi-Language Corpus
</subsectionHeader>
<bodyText confidence="0.9999694">
In the previous experiments, we have shown the
capability and effectiveness of the PCLSA model
in latent topic extraction from two language cor-
pora. In fact, the proposed model is general and
capable of extracting latent topics from multi-
language corpus. For example, if we have dic-
tionaries among multiple languages, we can con-
struct a multi-partite graph based on the corre-
spondence between those vocabularies, and then
smooth the PCLSA model with this graph.
To show the effectiveness of PCLSA in min-
ing multiple language corpus, we first construct a
simulated data set based on 1115 reviews of three
brands of laptops, namely IBM (303), Apple(468)
and DELL(344). To simulate a three language cor-
</bodyText>
<page confidence="0.99833">
1134
</page>
<tableCaption confidence="0.999288">
Table 5: Effectiveness of Latent Topic Extraction from Multi-Language Corpus
</tableCaption>
<table confidence="0.951525806451613">
Topic 0 Topic 1 Topic 2 Topic 3 Topic 4 Topic 5 Topic 6 Topic 7
cd(apple) battery(dell) mouse(dell) print(apple) port(ibm) laptop(ibm) os(apple) port(dell)
port(apple) drive(dell) button(dell) resolution(dell) card(ibm) t20(ibm) run(apple) 2(dell)
drive(apple) 8200(dell) touchpad(dell) burn(apple) modem(ibm) thinkpad(ibm) 1(apple) usb(dell)
airport(apple) inspiron(dell) pad(dell) normal(dell) display(ibm) battery(ibm) ram(apple) 1(dell)
firewire(apple) system(dell) keyboard(dell) image(dell) built(ibm) notebook(ibm) mac(apple) 0(dell)
dvd(apple) hour(dell) point(dell) digital(apple) swap(ibm) ibm(ibm) battery(apple) slot(dell)
usb(apple) sound(dell) stick(dell) organize(apple) easy(ibm) 3(ibm) hour(apple) firewire(dell)
rw(apple) dell(dell) rest(dell) cds(apple) connector(ibm) feel(ibm) 12(apple) display(dell)
card(apple) service(dell) touch(dell) latch(apple) feature(ibm) hour(ibm) operate(apple) standard(dell)
mouse(apple) life(dell) erase(dell) advertise(dell) cd(ibm) high(ibm) word(apple) fast(dell)
osx(apple) applework(apple) port(dell) battery(dell) lightest(ibm) uxga(dell) light(ibm) battery(apple)
memory(dell) file(apple) port(apple) battery(ibm) quality(dell) ultrasharp(dell) ultrabay(ibm) point(dell)
special(dell) bounce(apple) port(ibm) battery(apple) year(ibm) display(dell) connector(ibm) touchpad(dell)
crucial(dell) quit(apple) firewire(apple) geforce4(dell) hassle(ibm) organize(apple) dvd(ibm) button(dell)
memory(apple) word(apple) imac(apple) 100mhz(apple) bania(dell) learn(apple) nice(ibm) hour(apple)
memory(ibm) file(ibm) firewire(dell) 440(dell) 800mhz(apple) logo(apple) modem(ibm) battery(ibm)
netscape(apple) file(dell) firewire(ibm) bus(apple) trackpad(apple) postscript(apple) connector(dell) battery(dell)
reseller(apple) microsoft(apple) jack(apple) 8200(dell) cover(ibm) ll(apple) light(apple) fan(dell)
10(dell) ms(apple) playback(dell) 8100(dell) workmanship(dell) sxga(dell) light(dell) erase(dell)
special(apple) excel(apple) jack(dell) chipset(dell) section(apple) warm(apple) floppy(ibm) point(apple)
2000(ibm) ram(apple) port(dell) itune(apple) uxga(dell) port(apple) pentium(dell) drive(ibm)
window(ibm) ram(ibm) port(apple) applework(apple) screen(dell) port(ibm) processor(dell) drive(dell)
2000(apple) ram(dell) port(ibm) imovie(apple) screen(ibm) port(dell) p4(dell) drive(apple)
2000(dell) screen(apple) 2(dell) import(apple) screen(apple) usb(apple) power(dell) hard(ibm)
window(apple) 1(apple) 2(apple) battery(apple) ultrasharp(dell) plug(apple) pentium(apple) osx(apple)
window(dell) screen(ibm) 2(ibm) iphoto(apple) 1600x1200(dell) cord(apple) pentium(ibm) hard(dell)
portege(ibm) screen(dell) speak(dell) battery(ibm) display(dell) usb(ibm) keyboard(dell) hard(apple)
option(ibm) 1(ibm) toshiba(dell) battery(dell) display(apple) usb(dell) processor(ibm) card(ibm)
hassle(ibm) 1(dell) speak(ibm) hour(apple) display(ibm) firewire(apple) processor(apple) dvd(ibm)
device(ibm) maco(apple) toshiba(ibm) hour(ibm) view(dell) plug(ibm) power(apple) card(dell)
</table>
<bodyText confidence="0.999984935483871">
pus, we use an ’IBM’ word, an ’Apple’ word, and
a ’Dell’ word to replace an English word in their
corpus. For example, we use ’IBM10’, ’Apple10’,
’Dell10’ to replace the word ’CD’ whenever it ap-
pears in an IBM’s, Apple’s, or Dell’s review. Af-
ter the replacement, the reviews about IBM, Ap-
ple, and Dell will not share vocabularies with each
other. On the other hand, for any three created
words which represent the same English word, we
add three edges among them, and therefore we
get a simulated dictionary graph for our PCLSA
model.
The experimental result is shown in Table 5, in
which we try to extract 8 topics from the cross-
lingual corpus. The first ten rows show the re-
sult of our PCLSA model, in which we set a very
small value to the weight parameter A for the reg-
ularizer part. This can be used as an approxima-
tion of the result from the traditional PLSA model
on this three language corpus. We can see that
the extracted topics are mainly written in mono-
language. As we set the value of parameter A
larger, the extracted topics become multi-lingual,
which is shown in the next ten rows. From this
result, we can see the difference between the re-
views of different brands about the similar topic.
In addition, if we set the A even larger, we will
get topics that are mostly made of the same words
from the three different brands, which means the
extracted topics are very smooth on the dictionary
graph now.
</bodyText>
<sectionHeader confidence="0.999046" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99998">
In this paper, we study the problem of cross-
lingual latent topic extraction where the task is to
extract a set of common latent topics from multi-
lingual text data. We propose a novel probabilistic
topic model (i.e. the Probabilistic Cross-Lingual
Latent Semantic Analysis (PCLSA) model) that
can incorporate translation knowledge in bilingual
dictionaries as a regularizer to constrain the pa-
rameter estimation so that the learned topic models
would be synchronized in multiple languages. We
evaluated the model using several data sets. The
experimental results show that PCLSA is effec-
tive in extracting common latent topics from mul-
tilingual text data, and it outperforms the baseline
method which uses the standard PLSA to fit each
monolingual text data set.
Our work opens up some interesting future re-
search directions to further explore. First, in
this paper, we have only experimented with uni-
form weighting of edge in the bilingual graph.
It should be very interesting to explore how to
assign weights to the edges and study whether
weighted graphs can further improve performance.
Second, it would also be interesting to further
extend PCLSA to accommodate discovering top-
ics in each language that aren’t well-aligned with
other languages.
</bodyText>
<sectionHeader confidence="0.998786" genericHeader="acknowledgments">
8 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999891">
We sincerely thank the anonymous reviewers for
their comprehensive and constructive comments.
The work was supported in part by NASA grant
</bodyText>
<page confidence="0.97368">
1135
</page>
<bodyText confidence="0.991304">
NNX08AC35A, by the National Science Foun-
dation under Grant Numbers IIS-0713581, IIS-
0713571, and CNS-0834709, and by a Sloan Re-
search Fellowship.
</bodyText>
<sectionHeader confidence="0.989129" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999746204081633">
David Blei and John Lafferty. 2005. Correlated topic
models. In NIPS ’05: Advances in Neural Informa-
tion Processing Systems 18.
David M. Blei and John D. Lafferty. 2006. Dynamic
topic models. In Proceedings of the 23rd interna-
tional conference on Machine learning, pages 113–
120.
D. Blei, T. Griffiths, M. Jordan, and J. Tenenbaum.
2003a. Hierarchical topic models and the nested
chinese restaurant process. In Neural Information
Processing Systems (NIPS) 16.
D. Blei, A. Ng, and M. Jordan. 2003b. Latent Dirichlet
allocation. Journal of Machine Learning Research,
3:993–1022.
J. Boyd-Graber and D. Blei. 2009. Multilingual topic
models for unaligned text. In Uncertainty in Artifi-
cial Intelligence.
S. R. K. Branavan, Harr Chen, Jacob Eisenstein, and
Regina Barzilay. 2008. Learning document-level
semantic properties from free-text annotations. In
Proceedings of ACL 2008.
Martin Franz, J. Scott McCarley, and Salim Roukos.
1998. Ad hoc and multilingual information retrieval
at IBM. In Text REtrieval Conference, pages 104–
115.
Pascale Fung. 1995. A pattern matching method
for finding noun and proper noun translations from
noisy parallel corpora. In Proceedings ofACL 1995,
pages 236–243.
Alfio Gliozzo and Carlo Strapparava. 2006. Exploit-
ing comparable corpora and bilingual dictionaries
for cross-language text categorization. In ACL-44:
Proceedings of the 21st International Conference
on Computational Linguistics and the 44th annual
meeting of the Association for Computational Lin-
guistics, pages 553–560, Morristown, NJ, USA. As-
sociation for Computational Linguistics.
T. Hofmann. 1999a. Probabilistic latent semantic anal-
ysis. In Proceedings of UAI 1999, pages 289–296.
Thomas Hofmann. 1999b. The cluster-abstraction
model: Unsupervised learning of topic hierarchies
from text data. In IJCAI’ 99, pages 682–687.
Thomas Hofmann. 2001. Unsupervised learning by
probabilistic latent semantic analysis. Mach. Learn.,
42(1-2):177–196.
Jagadeesh Jagaralamudi and Hal Daum´e III. 2010. Ex-
tracting multilingual topics from unaligned corpora.
In Proceedings of the European Conference on In-
formation Retrieval (ECIR), Milton Keynes, United
Kingdom.
Woosung Kim and Sanjeev Khudanpur. 2004. Lex-
ical triggers and latent semantic analysis for cross-
lingual language model adaptation. ACM Trans-
actions on Asian Language Information Processing
(TALIP), 3(2):94–112.
Wei Li and Andrew McCallum. 2006. Pachinko allo-
cation: Dag-structured mixture models of topic cor-
relations. In ICML ’06: Proceedings of the 23rd in-
ternational conference on Machine learning, pages
577–584.
H. Masuichi, R. Flournoy, S. Kaufmann, and S. Peters.
2000. A bootstrapping method for extracting bilin-
gual text pairs. In Proc. 18th COLINC, pages 1066–
1070.
Qiaozhu Mei and ChengXiang Zhai. 2006. A mixture
model for contextual text mining. In Proceedings of
KDD ’06, pages 649–655.
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,
and ChengXiang Zhai. 2007. Topic sentiment mix-
ture: Modeling facets and opinions in weblogs. In
Proceedings of WWW ’07.
Qiaozhu Mei, Deng Cai, Duo Zhang, and ChengXiang
Zhai. 2008a. Topic modeling with network regular-
ization. In WWW, pages 101–110.
Qiaozhu Mei, Duo Zhang, and ChengXiang Zhai.
2008b. A general optimization framework for
smoothing language models on graph structures. In
SIGIR ’08: Proceedings of the 31st annual interna-
tional ACM SIGIR conference on Research and de-
velopment in information retrieval, pages 611–618,
New York, NY, USA. ACM.
David Mimno, Hanna M. Wallach, Jason Naradowsky,
David A. Smith, and Andrew Mccallum. 2009.
Polylingual topic models. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing, pages 880–889, Singapore,
August. Association for Computational Linguistics.
Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.
2009. Mining multilingual topics from wikipedia.
In WWW ’09: Proceedings of the 18th international
conference on World wide web, pages 1155–1156,
New York, NY, USA. ACM.
F. Sadat, M. Yoshikawa, and S. Uemura. 2003. Bilin-
gual terminology acquisition from comparable cor-
pora and phrasal translation to cross-language infor-
mation retrieval. In ACL ’03: Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics, pages 141–144.
</reference>
<page confidence="0.86364">
1136
</page>
<reference confidence="0.999540266666667">
Mark Steyvers, Padhraic Smyth, Michal Rosen-Zvi,
and Thomas Griffiths. 2004. Probabilistic author-
topic models for information discovery. In Proceed-
ings of KDD’04, pages 306–315.
Xuanhui Wang, ChengXiang Zhai, Xiao Hu, and
Richard Sproat. 2007. Mining correlated bursty
topic patterns from coordinated text streams. In
KDD ’07: Proceedings of the 13th ACM SIGKDD
international conference on Knowledge discovery
and data mining, pages 784–793, New York, NY,
USA. ACM.
Bing Zhao and Eric P. Xing. 2006. Bitam: Bilingual
topic admixture models for word alignment. In In
Proceedings of the 44th Annual Meeting of the As-
sociation for Computational Linguistics.
</reference>
<page confidence="0.995174">
1137
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.952944">
<title confidence="0.999528">Cross-Lingual Latent Topic Extraction</title>
<author confidence="0.999389">Duo Zhang Qiaozhu Mei ChengXiang Zhai</author>
<affiliation confidence="0.99913">University of Illinois at University of Michigan University of Illinois at</affiliation>
<email confidence="0.987004">dzhang22@cs.uiuc.educzhai@cs.uiuc.edu</email>
<abstract confidence="0.998715961538462">Probabilistic latent topic models have recently enjoyed much success in extracting and analyzing latent topics in text in an unsupervised way. One common deficiency of existing topic models, though, is that they would not work well for extracting cross-lingual latent topics simply because words in different languages generally do not co-occur with each other. In this paper, we propose a way to incorporate a bilingual dictionary into a probabilistic topic model so that we can apply topic models to extract shared latent topics in text data of different languages. Specifically, we propose a new topic model called Probabilistic Cross-Lingual Latent Semantic Analysis (PCLSA) which extends the Probabilistic Latent Semantic Analysis (PLSA) model by regularizing its likelihood function with soft constraints defined based on a bilingual dictionary. Both qualitative and quantitative experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>John Lafferty</author>
</authors>
<title>Correlated topic models.</title>
<date>2005</date>
<booktitle>In NIPS ’05: Advances in Neural Information Processing Systems 18.</booktitle>
<contexts>
<context position="6243" citStr="Blei and Lafferty, 2005" startWordPosition="977" endWordPosition="980">ne approach using the standard PLSA on text data in each language. 2 Related Work Many topic models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b). They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wa</context>
</contexts>
<marker>Blei, Lafferty, 2005</marker>
<rawString>David Blei and John Lafferty. 2005. Correlated topic models. In NIPS ’05: Advances in Neural Information Processing Systems 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>John D Lafferty</author>
</authors>
<title>Dynamic topic models.</title>
<date>2006</date>
<booktitle>In Proceedings of the 23rd international conference on Machine learning,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="6269" citStr="Blei and Lafferty, 2006" startWordPosition="981" endWordPosition="984">ndard PLSA on text data in each language. 2 Related Work Many topic models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b). They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However,</context>
</contexts>
<marker>Blei, Lafferty, 2006</marker>
<rawString>David M. Blei and John D. Lafferty. 2006. Dynamic topic models. In Proceedings of the 23rd international conference on Machine learning, pages 113– 120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blei</author>
<author>T Griffiths</author>
<author>M Jordan</author>
<author>J Tenenbaum</author>
</authors>
<title>Hierarchical topic models and the nested chinese restaurant process.</title>
<date>2003</date>
<booktitle>In Neural Information Processing Systems (NIPS)</booktitle>
<pages>16</pages>
<contexts>
<context position="1430" citStr="Blei et al., 2003" startWordPosition="206" endWordPosition="209">s. Specifically, we propose a new topic model called Probabilistic Cross-Lingual Latent Semantic Analysis (PCLSA) which extends the Probabilistic Latent Semantic Analysis (PLSA) model by regularizing its likelihood function with soft constraints defined based on a bilingual dictionary. Both qualitative and quantitative experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data. 1 Introduction As a robust unsupervised way to perform shallow latent semantic analysis of topics in text, probabilistic topic models (Hofmann, 1999a; Blei et al., 2003b) have recently attracted much attention. The common idea behind these models is the following. A topic is represented by a multinomial word distribution so that words characterizing a topic generally have higher probabilities than other words. We can then hypothesize the existence of multiple topics in text and define a generative model based on the hypothesized topics. By fitting the model to text data, we can obtain an estimate of all the word distributions corresponding to the latent topics as well as the topic distributions in text. Intuitively, the learned word distributions capture clu</context>
<context position="5908" citStr="Blei et al., 2003" startWordPosition="927" endWordPosition="930">ingual news data set and a review data set to evaluate PCLSA. We also propose a “cross-collection” likelihood measure to quantitatively evaluate the quality of mined topics. Experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data, and it outperforms a baseline approach using the standard PLSA on text data in each language. 2 Related Work Many topic models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b). They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for inco</context>
</contexts>
<marker>Blei, Griffiths, Jordan, Tenenbaum, 2003</marker>
<rawString>D. Blei, T. Griffiths, M. Jordan, and J. Tenenbaum. 2003a. Hierarchical topic models and the nested chinese restaurant process. In Neural Information Processing Systems (NIPS) 16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blei</author>
<author>A Ng</author>
<author>M Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="1430" citStr="Blei et al., 2003" startWordPosition="206" endWordPosition="209">s. Specifically, we propose a new topic model called Probabilistic Cross-Lingual Latent Semantic Analysis (PCLSA) which extends the Probabilistic Latent Semantic Analysis (PLSA) model by regularizing its likelihood function with soft constraints defined based on a bilingual dictionary. Both qualitative and quantitative experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data. 1 Introduction As a robust unsupervised way to perform shallow latent semantic analysis of topics in text, probabilistic topic models (Hofmann, 1999a; Blei et al., 2003b) have recently attracted much attention. The common idea behind these models is the following. A topic is represented by a multinomial word distribution so that words characterizing a topic generally have higher probabilities than other words. We can then hypothesize the existence of multiple topics in text and define a generative model based on the hypothesized topics. By fitting the model to text data, we can obtain an estimate of all the word distributions corresponding to the latent topics as well as the topic distributions in text. Intuitively, the learned word distributions capture clu</context>
<context position="5908" citStr="Blei et al., 2003" startWordPosition="927" endWordPosition="930">ingual news data set and a review data set to evaluate PCLSA. We also propose a “cross-collection” likelihood measure to quantitatively evaluate the quality of mined topics. Experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data, and it outperforms a baseline approach using the standard PLSA on text data in each language. 2 Related Work Many topic models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b). They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for inco</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>D. Blei, A. Ng, and M. Jordan. 2003b. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Boyd-Graber</author>
<author>D Blei</author>
</authors>
<title>Multilingual topic models for unaligned text.</title>
<date>2009</date>
<booktitle>In Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="4386" citStr="Boyd-Graber and Blei, 2009" startWordPosition="678" endWordPosition="681">n characterize the shared topics in the two languages. In addition, it also outputs a topic cov1128 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1128–1137, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics erage distribution for each language to indicate the relative coverage of different shared topics in each language. To the best of our knowledge, no previous work has attempted to solve this topic extraction problem and generate the same output. The closest existing work to ours is the MuTo model proposed in (Boyd-Graber and Blei, 2009) and the JointLDA model published recently in (Jagaralamudi and Daum´e III, 2010). Both used a bilingual dictionary to bridge the language gap in a topic model. However, the goals of their work are different from ours in that their models mainly focus on mining cross-lingual topics of matching word pairs and discovering the correspondence at the vocabulary level. Therefore, the topics extracted using their model cannot indicate how a common topic is covered differently in the two languages, because the words in each word pair share the same probability in a common topic. Our work focuses on di</context>
</contexts>
<marker>Boyd-Graber, Blei, 2009</marker>
<rawString>J. Boyd-Graber and D. Blei. 2009. Multilingual topic models for unaligned text. In Uncertainty in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R K Branavan</author>
<author>Harr Chen</author>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Learning document-level semantic properties from free-text annotations.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="6333" citStr="Branavan et al., 2008" startWordPosition="992" endWordPosition="995">c models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b). They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned tex</context>
</contexts>
<marker>Branavan, Chen, Eisenstein, Barzilay, 2008</marker>
<rawString>S. R. K. Branavan, Harr Chen, Jacob Eisenstein, and Regina Barzilay. 2008. Learning document-level semantic properties from free-text annotations. In Proceedings of ACL 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Franz</author>
<author>J Scott McCarley</author>
<author>Salim Roukos</author>
</authors>
<title>Ad hoc and multilingual information retrieval at IBM.</title>
<date>1998</date>
<booktitle>In Text REtrieval Conference,</booktitle>
<pages>104--115</pages>
<contexts>
<context position="7231" citStr="Franz et al., 1998" startWordPosition="1138" endWordPosition="1141"> on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora have also been studied extensively (e.g. (Fung, 1995; Franz et al., 1998; Masuichi et al., 2000; Sadat et al., 2003; Gliozzo and Strapparava, 2006)), but most previous work aims at acquiring word translation knowledge or cross-lingual text categorization from comparable corpora. Our work differs from this line of previous work in that our goal is to discover shared latent topics from multi-lingual text data that are weakly comparable (e.g. the data does not have to be aligned by time). 3 Problem Formulation In general, the problem of cross-lingual topic extraction can be defined as to extract a set of common cross-lingual latent topics covered in text collections </context>
</contexts>
<marker>Franz, McCarley, Roukos, 1998</marker>
<rawString>Martin Franz, J. Scott McCarley, and Salim Roukos. 1998. Ad hoc and multilingual information retrieval at IBM. In Text REtrieval Conference, pages 104– 115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
</authors>
<title>A pattern matching method for finding noun and proper noun translations from noisy parallel corpora.</title>
<date>1995</date>
<booktitle>In Proceedings ofACL</booktitle>
<pages>236--243</pages>
<contexts>
<context position="7211" citStr="Fung, 1995" startWordPosition="1136" endWordPosition="1137">revious work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora have also been studied extensively (e.g. (Fung, 1995; Franz et al., 1998; Masuichi et al., 2000; Sadat et al., 2003; Gliozzo and Strapparava, 2006)), but most previous work aims at acquiring word translation knowledge or cross-lingual text categorization from comparable corpora. Our work differs from this line of previous work in that our goal is to discover shared latent topics from multi-lingual text data that are weakly comparable (e.g. the data does not have to be aligned by time). 3 Problem Formulation In general, the problem of cross-lingual topic extraction can be defined as to extract a set of common cross-lingual latent topics covered </context>
</contexts>
<marker>Fung, 1995</marker>
<rawString>Pascale Fung. 1995. A pattern matching method for finding noun and proper noun translations from noisy parallel corpora. In Proceedings ofACL 1995, pages 236–243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alfio Gliozzo</author>
<author>Carlo Strapparava</author>
</authors>
<title>Exploiting comparable corpora and bilingual dictionaries for cross-language text categorization.</title>
<date>2006</date>
<booktitle>In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>553--560</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="7306" citStr="Gliozzo and Strapparava, 2006" startWordPosition="1150" endWordPosition="1153">uages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora have also been studied extensively (e.g. (Fung, 1995; Franz et al., 1998; Masuichi et al., 2000; Sadat et al., 2003; Gliozzo and Strapparava, 2006)), but most previous work aims at acquiring word translation knowledge or cross-lingual text categorization from comparable corpora. Our work differs from this line of previous work in that our goal is to discover shared latent topics from multi-lingual text data that are weakly comparable (e.g. the data does not have to be aligned by time). 3 Problem Formulation In general, the problem of cross-lingual topic extraction can be defined as to extract a set of common cross-lingual latent topics covered in text collections in different natural languages. A crosslingual latent topic will be represe</context>
</contexts>
<marker>Gliozzo, Strapparava, 2006</marker>
<rawString>Alfio Gliozzo and Carlo Strapparava. 2006. Exploiting comparable corpora and bilingual dictionaries for cross-language text categorization. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 553–560, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hofmann</author>
</authors>
<title>Probabilistic latent semantic analysis.</title>
<date>1999</date>
<booktitle>In Proceedings of UAI</booktitle>
<pages>289--296</pages>
<contexts>
<context position="1410" citStr="Hofmann, 1999" startWordPosition="204" endWordPosition="205">fferent languages. Specifically, we propose a new topic model called Probabilistic Cross-Lingual Latent Semantic Analysis (PCLSA) which extends the Probabilistic Latent Semantic Analysis (PLSA) model by regularizing its likelihood function with soft constraints defined based on a bilingual dictionary. Both qualitative and quantitative experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data. 1 Introduction As a robust unsupervised way to perform shallow latent semantic analysis of topics in text, probabilistic topic models (Hofmann, 1999a; Blei et al., 2003b) have recently attracted much attention. The common idea behind these models is the following. A topic is represented by a multinomial word distribution so that words characterizing a topic generally have higher probabilities than other words. We can then hypothesize the existence of multiple topics in text and define a generative model based on the hypothesized topics. By fitting the model to text data, we can obtain an estimate of all the word distributions corresponding to the latent topics as well as the topic distributions in text. Intuitively, the learned word distr</context>
<context position="5839" citStr="Hofmann, 1999" startWordPosition="918" endWordPosition="919">ations of a common topic in different languages. We use a cross-lingual news data set and a review data set to evaluate PCLSA. We also propose a “cross-collection” likelihood measure to quantitatively evaluate the quality of mined topics. Experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data, and it outperforms a baseline approach using the standard PLSA on text data in each language. 2 Related Work Many topic models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b). They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constr</context>
<context position="19177" citStr="Hofmann, 1999" startWordPosition="3210" endWordPosition="3211">ncrete statistics in each experiment. To process the Chinese corpus, we use a simple segmenter1 to split the data into Chinese phrases. Both Chinese and English stopwords are removed from our data. The dictionary file we used for our PCLSA model is from mandarintools.com2. For each Chinese phrase, if it has several English meanings, we add an edge between it and each of its English translation. If one English translation is an English phrase, we add an edge between the Chinese phrase and each English word in the phrase. 5.2 Baseline Method As a baseline method, we can apply the standard PLSA (Hofmann, 1999a) directly to the multilingual corpus. Since PLSA takes advantage of the word co-occurrences in the document level to find semantic topics, directly using it for a multilingual corpus will result in finding topics mainly reflecting a single language (because words in different languages would not co-occur in the same document in general). That is, the discovered topics are mostly monolingual. These monolingual topics can then be aligned based on a bilingual dictionary to suggest a possible cross-lingual topic. 6 Experimental Results 6.1 Qualitative Comparison To qualitatively compare PCLSA wi</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>T. Hofmann. 1999a. Probabilistic latent semantic analysis. In Proceedings of UAI 1999, pages 289–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>The cluster-abstraction model: Unsupervised learning of topic hierarchies from text data.</title>
<date>1999</date>
<booktitle>In IJCAI’ 99,</booktitle>
<pages>682--687</pages>
<contexts>
<context position="1410" citStr="Hofmann, 1999" startWordPosition="204" endWordPosition="205">fferent languages. Specifically, we propose a new topic model called Probabilistic Cross-Lingual Latent Semantic Analysis (PCLSA) which extends the Probabilistic Latent Semantic Analysis (PLSA) model by regularizing its likelihood function with soft constraints defined based on a bilingual dictionary. Both qualitative and quantitative experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data. 1 Introduction As a robust unsupervised way to perform shallow latent semantic analysis of topics in text, probabilistic topic models (Hofmann, 1999a; Blei et al., 2003b) have recently attracted much attention. The common idea behind these models is the following. A topic is represented by a multinomial word distribution so that words characterizing a topic generally have higher probabilities than other words. We can then hypothesize the existence of multiple topics in text and define a generative model based on the hypothesized topics. By fitting the model to text data, we can obtain an estimate of all the word distributions corresponding to the latent topics as well as the topic distributions in text. Intuitively, the learned word distr</context>
<context position="5839" citStr="Hofmann, 1999" startWordPosition="918" endWordPosition="919">ations of a common topic in different languages. We use a cross-lingual news data set and a review data set to evaluate PCLSA. We also propose a “cross-collection” likelihood measure to quantitatively evaluate the quality of mined topics. Experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data, and it outperforms a baseline approach using the standard PLSA on text data in each language. 2 Related Work Many topic models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b). They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constr</context>
<context position="19177" citStr="Hofmann, 1999" startWordPosition="3210" endWordPosition="3211">ncrete statistics in each experiment. To process the Chinese corpus, we use a simple segmenter1 to split the data into Chinese phrases. Both Chinese and English stopwords are removed from our data. The dictionary file we used for our PCLSA model is from mandarintools.com2. For each Chinese phrase, if it has several English meanings, we add an edge between it and each of its English translation. If one English translation is an English phrase, we add an edge between the Chinese phrase and each English word in the phrase. 5.2 Baseline Method As a baseline method, we can apply the standard PLSA (Hofmann, 1999a) directly to the multilingual corpus. Since PLSA takes advantage of the word co-occurrences in the document level to find semantic topics, directly using it for a multilingual corpus will result in finding topics mainly reflecting a single language (because words in different languages would not co-occur in the same document in general). That is, the discovered topics are mostly monolingual. These monolingual topics can then be aligned based on a bilingual dictionary to suggest a possible cross-lingual topic. 6 Experimental Results 6.1 Qualitative Comparison To qualitatively compare PCLSA wi</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999b. The cluster-abstraction model: Unsupervised learning of topic hierarchies from text data. In IJCAI’ 99, pages 682–687.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Unsupervised learning by probabilistic latent semantic analysis.</title>
<date>2001</date>
<pages>42--1</pages>
<location>Mach. Learn.,</location>
<contexts>
<context position="24143" citStr="Hofmann, 2001" startWordPosition="4039" endWordPosition="4040">ing the splitting formula described before, i.e. pi(wi|o) _ �w∈1wz|θ) |θ� . Then, we use the z word distribution of the Chinese topics (translating the words into English) to fit the English Corpus and use the word distribution of the English topics (translating the words into Chinese) to fit the Chinese Corpus. If the topics mined are common topics in the whole corpus, then such a “crosscollection” likelihood should be larger than those topics which are not commonly shared by the English and the Chinese corpus. To calculate the likelihood of fitness, we use the folding-in method proposed in (Hofmann, 2001). To translate topics from one language to another, e.g. Chinese to English, we look up the bilingual dictionary and do word-to-word translation. If one Chinese word has several English translations, we simply distribute its probability mass equally to each English translation. For comparison, we use the standard PLSA model as the baseline. Basically, suppose PLSA mined k semantic topics in the Chinese corpus and k semantic topics in the English corpus. Then, we also use the “cross-collection” likelihood measure to see how well those k semantic Chinese topics fit the English corpus and those k</context>
</contexts>
<marker>Hofmann, 2001</marker>
<rawString>Thomas Hofmann. 2001. Unsupervised learning by probabilistic latent semantic analysis. Mach. Learn., 42(1-2):177–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jagadeesh Jagaralamudi</author>
<author>Hal Daum´e</author>
</authors>
<title>Extracting multilingual topics from unaligned corpora.</title>
<date>2010</date>
<booktitle>In Proceedings of the European Conference on Information Retrieval (ECIR),</booktitle>
<location>Milton Keynes, United Kingdom.</location>
<marker>Jagaralamudi, Daum´e, 2010</marker>
<rawString>Jagadeesh Jagaralamudi and Hal Daum´e III. 2010. Extracting multilingual topics from unaligned corpora. In Proceedings of the European Conference on Information Retrieval (ECIR), Milton Keynes, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Woosung Kim</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Lexical triggers and latent semantic analysis for crosslingual language model adaptation.</title>
<date>2004</date>
<journal>ACM Transactions on Asian Language Information Processing (TALIP),</journal>
<volume>3</volume>
<issue>2</issue>
<contexts>
<context position="6822" citStr="Kim and Khudanpur, 2004" startWordPosition="1076" endWordPosition="1079">elated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora have also been studied extensively (e.g. (Fung, 1995; Franz et al., 1998; Masuichi et al., 2000; Sadat et al., 2003; Gliozzo and Strapparava, 2006)), but most previous work aims at acquiring word translation knowledge or cross-lingual text categorization from com</context>
</contexts>
<marker>Kim, Khudanpur, 2004</marker>
<rawString>Woosung Kim and Sanjeev Khudanpur. 2004. Lexical triggers and latent semantic analysis for crosslingual language model adaptation. ACM Transactions on Asian Language Information Processing (TALIP), 3(2):94–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Li</author>
<author>Andrew McCallum</author>
</authors>
<title>Pachinko allocation: Dag-structured mixture models of topic correlations.</title>
<date>2006</date>
<booktitle>In ICML ’06: Proceedings of the 23rd international conference on Machine learning,</booktitle>
<pages>577--584</pages>
<contexts>
<context position="6086" citStr="Li and McCallum, 2006" startWordPosition="954" endWordPosition="958"> Experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data, and it outperforms a baseline approach using the standard PLSA on text data in each language. 2 Related Work Many topic models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b). They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are </context>
</contexts>
<marker>Li, McCallum, 2006</marker>
<rawString>Wei Li and Andrew McCallum. 2006. Pachinko allocation: Dag-structured mixture models of topic correlations. In ICML ’06: Proceedings of the 23rd international conference on Machine learning, pages 577–584.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Masuichi</author>
<author>R Flournoy</author>
<author>S Kaufmann</author>
<author>S Peters</author>
</authors>
<title>A bootstrapping method for extracting bilingual text pairs.</title>
<date>2000</date>
<booktitle>In Proc. 18th COLINC,</booktitle>
<pages>1066--1070</pages>
<contexts>
<context position="7254" citStr="Masuichi et al., 2000" startWordPosition="1142" endWordPosition="1145">ic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora have also been studied extensively (e.g. (Fung, 1995; Franz et al., 1998; Masuichi et al., 2000; Sadat et al., 2003; Gliozzo and Strapparava, 2006)), but most previous work aims at acquiring word translation knowledge or cross-lingual text categorization from comparable corpora. Our work differs from this line of previous work in that our goal is to discover shared latent topics from multi-lingual text data that are weakly comparable (e.g. the data does not have to be aligned by time). 3 Problem Formulation In general, the problem of cross-lingual topic extraction can be defined as to extract a set of common cross-lingual latent topics covered in text collections in different natural la</context>
</contexts>
<marker>Masuichi, Flournoy, Kaufmann, Peters, 2000</marker>
<rawString>H. Masuichi, R. Flournoy, S. Kaufmann, and S. Peters. 2000. A bootstrapping method for extracting bilingual text pairs. In Proc. 18th COLINC, pages 1066– 1070.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>ChengXiang Zhai</author>
</authors>
<title>A mixture model for contextual text mining.</title>
<date>2006</date>
<booktitle>In Proceedings of KDD ’06,</booktitle>
<pages>649--655</pages>
<contexts>
<context position="6181" citStr="Mei and Zhai, 2006" startWordPosition="968" endWordPosition="971">s from multilingual text data, and it outperforms a baseline approach using the standard PLSA on text data in each language. 2 Related Work Many topic models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b). They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zha</context>
</contexts>
<marker>Mei, Zhai, 2006</marker>
<rawString>Qiaozhu Mei and ChengXiang Zhai. 2006. A mixture model for contextual text mining. In Proceedings of KDD ’06, pages 649–655.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xu Ling</author>
<author>Matthew Wondra</author>
<author>Hang Su</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Topic sentiment mixture: Modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proceedings of WWW ’07.</booktitle>
<contexts>
<context position="6309" citStr="Mei et al., 2007" startWordPosition="988" endWordPosition="991">ted Work Many topic models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b). They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine t</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and ChengXiang Zhai. 2007. Topic sentiment mixture: Modeling facets and opinions in weblogs. In Proceedings of WWW ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Deng Cai</author>
<author>Duo Zhang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Topic modeling with network regularization.</title>
<date>2008</date>
<booktitle>In WWW,</booktitle>
<pages>101--110</pages>
<contexts>
<context position="6559" citStr="Mei et al., 2008" startWordPosition="1033" endWordPosition="1036">been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora </context>
<context position="15570" citStr="Mei et al., 2008" startWordPosition="2548" endWordPosition="2551"> all the edges ending with u. Intuitively, R(C) measures the difference between p(wu|0j) and p(wv|0j) for each pair (u, v) in a bilingual dictionary; the more they differ, the larger R(C) would be. So it can be regarded as a “loss function” to help us assess how well the “component word distributions” in multiple languages are correlated semantically. Clearly, we would like the extracted topics to have a small R(C). We choose this specific form of loss function because it would make it convenient to solve the optimization problem of maximizing the corresponding regularized maximum likelihood (Mei et al., 2008b). The normalization with Deg(u) and Deg(v) can be regarded as a way to compensate for the potential ambiguity of u and v in their translations. Putting L(C) and R(C) together, we would like to maximize the following objective function which is a regularized log-likelihood: O(C, G) = (1 − A)L(C) − AR(C) (1) where A E (0, 1) is a parameter to balance the likelihood and the regularizer. When A = 0, we recover the standard PLSA. Specifically, we will search for a set of values for all our parameters that can maximize the objective function defined above. Our parameters include all the cross-ling</context>
</contexts>
<marker>Mei, Cai, Zhang, Zhai, 2008</marker>
<rawString>Qiaozhu Mei, Deng Cai, Duo Zhang, and ChengXiang Zhai. 2008a. Topic modeling with network regularization. In WWW, pages 101–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Duo Zhang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>A general optimization framework for smoothing language models on graph structures.</title>
<date>2008</date>
<booktitle>In SIGIR ’08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>611--618</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6559" citStr="Mei et al., 2008" startWordPosition="1033" endWordPosition="1036">been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora </context>
<context position="15570" citStr="Mei et al., 2008" startWordPosition="2548" endWordPosition="2551"> all the edges ending with u. Intuitively, R(C) measures the difference between p(wu|0j) and p(wv|0j) for each pair (u, v) in a bilingual dictionary; the more they differ, the larger R(C) would be. So it can be regarded as a “loss function” to help us assess how well the “component word distributions” in multiple languages are correlated semantically. Clearly, we would like the extracted topics to have a small R(C). We choose this specific form of loss function because it would make it convenient to solve the optimization problem of maximizing the corresponding regularized maximum likelihood (Mei et al., 2008b). The normalization with Deg(u) and Deg(v) can be regarded as a way to compensate for the potential ambiguity of u and v in their translations. Putting L(C) and R(C) together, we would like to maximize the following objective function which is a regularized log-likelihood: O(C, G) = (1 − A)L(C) − AR(C) (1) where A E (0, 1) is a parameter to balance the likelihood and the regularizer. When A = 0, we recover the standard PLSA. Specifically, we will search for a set of values for all our parameters that can maximize the objective function defined above. Our parameters include all the cross-ling</context>
</contexts>
<marker>Mei, Zhang, Zhai, 2008</marker>
<rawString>Qiaozhu Mei, Duo Zhang, and ChengXiang Zhai. 2008b. A general optimization framework for smoothing language models on graph structures. In SIGIR ’08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, pages 611–618, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Hanna M Wallach</author>
<author>Jason Naradowsky</author>
<author>David A Smith</author>
<author>Andrew Mccallum</author>
</authors>
<title>Polylingual topic models.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>880--889</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6776" citStr="Mimno et al., 2009" startWordPosition="1068" endWordPosition="1071">is (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora have also been studied extensively (e.g. (Fung, 1995; Franz et al., 1998; Masuichi et al., 2000; Sadat et al., 2003; Gliozzo and Strapparava, 2006)), but most previous work aims at acquiring word translation knowledge</context>
</contexts>
<marker>Mimno, Wallach, Naradowsky, Smith, Mccallum, 2009</marker>
<rawString>David Mimno, Hanna M. Wallach, Jason Naradowsky, David A. Smith, and Andrew Mccallum. 2009. Polylingual topic models. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 880–889, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaochuan Ni</author>
<author>Jian-Tao Sun</author>
<author>Jian Hu</author>
<author>Zheng Chen</author>
</authors>
<title>Mining multilingual topics from wikipedia.</title>
<date>2009</date>
<booktitle>In WWW ’09: Proceedings of the 18th international conference on World wide web,</booktitle>
<pages>1155--1156</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6839" citStr="Ni et al., 2009" startWordPosition="1080" endWordPosition="1083"> and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora have also been studied extensively (e.g. (Fung, 1995; Franz et al., 1998; Masuichi et al., 2000; Sadat et al., 2003; Gliozzo and Strapparava, 2006)), but most previous work aims at acquiring word translation knowledge or cross-lingual text categorization from comparable corpora. </context>
</contexts>
<marker>Ni, Sun, Hu, Chen, 2009</marker>
<rawString>Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen. 2009. Mining multilingual topics from wikipedia. In WWW ’09: Proceedings of the 18th international conference on World wide web, pages 1155–1156, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sadat</author>
<author>M Yoshikawa</author>
<author>S Uemura</author>
</authors>
<title>Bilingual terminology acquisition from comparable corpora and phrasal translation to cross-language information retrieval.</title>
<date>2003</date>
<booktitle>In ACL ’03: Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>141--144</pages>
<contexts>
<context position="7274" citStr="Sadat et al., 2003" startWordPosition="1146" endWordPosition="1149">nts in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora have also been studied extensively (e.g. (Fung, 1995; Franz et al., 1998; Masuichi et al., 2000; Sadat et al., 2003; Gliozzo and Strapparava, 2006)), but most previous work aims at acquiring word translation knowledge or cross-lingual text categorization from comparable corpora. Our work differs from this line of previous work in that our goal is to discover shared latent topics from multi-lingual text data that are weakly comparable (e.g. the data does not have to be aligned by time). 3 Problem Formulation In general, the problem of cross-lingual topic extraction can be defined as to extract a set of common cross-lingual latent topics covered in text collections in different natural languages. A crossling</context>
</contexts>
<marker>Sadat, Yoshikawa, Uemura, 2003</marker>
<rawString>F. Sadat, M. Yoshikawa, and S. Uemura. 2003. Bilingual terminology acquisition from comparable corpora and phrasal translation to cross-language information retrieval. In ACL ’03: Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 141–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steyvers</author>
<author>Padhraic Smyth</author>
<author>Michal Rosen-Zvi</author>
<author>Thomas Griffiths</author>
</authors>
<title>Probabilistic authortopic models for information discovery.</title>
<date>2004</date>
<booktitle>In Proceedings of KDD’04,</booktitle>
<pages>306--315</pages>
<contexts>
<context position="6133" citStr="Steyvers et al., 2004" startWordPosition="961" endWordPosition="964"> can effectively extract cross-lingual latent topics from multilingual text data, and it outperforms a baseline approach using the standard PLSA on text data in each language. 2 Related Work Many topic models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b). They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence </context>
</contexts>
<marker>Steyvers, Smyth, Rosen-Zvi, Griffiths, 2004</marker>
<rawString>Mark Steyvers, Padhraic Smyth, Michal Rosen-Zvi, and Thomas Griffiths. 2004. Probabilistic authortopic models for information discovery. In Proceedings of KDD’04, pages 306–315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuanhui Wang</author>
<author>ChengXiang Zhai</author>
<author>Xiao Hu</author>
<author>Richard Sproat</author>
</authors>
<title>Mining correlated bursty topic patterns from coordinated text streams.</title>
<date>2007</date>
<booktitle>In KDD ’07: Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>784--793</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6859" citStr="Wang et al., 2007" startWordPosition="1084" endWordPosition="1087">05; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora have also been studied extensively (e.g. (Fung, 1995; Franz et al., 1998; Masuichi et al., 2000; Sadat et al., 2003; Gliozzo and Strapparava, 2006)), but most previous work aims at acquiring word translation knowledge or cross-lingual text categorization from comparable corpora. Our work differs fro</context>
</contexts>
<marker>Wang, Zhai, Hu, Sproat, 2007</marker>
<rawString>Xuanhui Wang, ChengXiang Zhai, Xiao Hu, and Richard Sproat. 2007. Mining correlated bursty topic patterns from coordinated text streams. In KDD ’07: Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 784–793, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Eric P Xing</author>
</authors>
<title>Bitam: Bilingual topic admixture models for word alignment. In</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="6797" citStr="Zhao and Xing, 2006" startWordPosition="1072" endWordPosition="1075">06), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al., 2008). Our work is an extension of PLSA by incorporating the knowledge of a bilingual dictionary as soft constraints. Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different. Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007). However, in many applications, we need to mine topics from unaligned text corpus. For example, mining topics from search results in different languages can facilitate summarization of multilingual search results. Besides all the multilingual topic modeling work discussed above, comparable corpora have also been studied extensively (e.g. (Fung, 1995; Franz et al., 1998; Masuichi et al., 2000; Sadat et al., 2003; Gliozzo and Strapparava, 2006)), but most previous work aims at acquiring word translation knowledge or cross-lingual tex</context>
</contexts>
<marker>Zhao, Xing, 2006</marker>
<rawString>Bing Zhao and Eric P. Xing. 2006. Bitam: Bilingual topic admixture models for word alignment. In In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>