<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001148">
<note confidence="0.690985">
The viability of web-derived polarity lexicons
</note>
<author confidence="0.653944">
Leonid Velikovich Sasha Blair-Goldensohn Kerry Hannan Ryan McDonald
</author>
<affiliation confidence="0.653206">
Google Inc., New York, NY
</affiliation>
<email confidence="0.985246">
{leonidv|sasha|khannan|ryanmcd}@google.com
</email>
<sectionHeader confidence="0.997232" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997640875">
We examine the viability of building large
polarity lexicons semi-automatically from the
web. We begin by describing a graph propa-
gation framework inspired by previous work
on constructing polarity lexicons from lexi-
cal graphs (Kim and Hovy, 2004; Hu and
Liu, 2004; Esuli and Sabastiani, 2009; Blair-
Goldensohn et al., 2008; Rao and Ravichan-
dran, 2009). We then apply this technique
to build an English lexicon that is signifi-
cantly larger than those previously studied.
Crucially, this web-derived lexicon does not
require WordNet, part-of-speech taggers, or
other language-dependent resources typical of
sentiment analysis systems. As a result, the
lexicon is not limited to specific word classes
– e.g., adjectives that occur in WordNet –
and in fact contains slang, misspellings, multi-
word expressions, etc. We evaluate a lexicon
derived from English documents, both qual-
itatively and quantitatively, and show that it
provides superior performance to previously
studied lexicons, including one derived from
WordNet.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939021739131">
Polarity lexicons are large lists of phrases that en-
code the polarity of each phrase within it – either
positive or negative – often with some score rep-
resenting the magnitude of the polarity (Hatzivas-
siloglou and McKeown, 1997; Wiebe, 2000; Turney,
2002). Though classifiers built with machine learn-
ing algorithms have become commonplace in the
sentiment analysis literature, e.g., Pang et al. (2002),
the core of many academic and commercial senti-
ment analysis systems remains the polarity lexicon,
which can be constructed manually (Das and Chen,
2007), through heuristics (Kim and Hovy, 2004;
Esuli and Sabastiani, 2009) or using machine learn-
ing (Turney, 2002; Rao and Ravichandran, 2009).
Often lexicons are combined with machine learning
for improved results (Wilson et al., 2005). The per-
vasiveness and sustained use of lexicons can be as-
cribed to a number of reasons, including their inter-
pretability in large-scale systems as well as the gran-
ularity of their analysis.
In this work we investigate the viability of polar-
ity lexicons that are derived solely from unlabeled
web documents. We propose a method based on
graph propagation algorithms inspired by previous
work on constructing polarity lexicons from lexical
graphs (Kim and Hovy, 2004; Hu and Liu, 2004;
Esuli and Sabastiani, 2009; Blair-Goldensohn et al.,
2008; Rao and Ravichandran, 2009). Whereas past
efforts have used linguistic resources – e.g., Word-
Net – to construct the lexical graph over which prop-
agation runs, our lexicons are constructed using a
graph built from co-occurrence statistics from the
entire web. Thus, the method we investigate can
be seen as a combination of methods for propagat-
ing sentiment across lexical graphs and methods for
building sentiment lexicons based on distributional
characteristics of phrases in raw data (Turney, 2002).
The advantage of breaking the dependence on Word-
Net (or related resources like thesauri (Mohammad
et al., 2009)) is that it allows the lexicons to include
non-standard entries, most notably spelling mistakes
and variations, slang, and multiword expressions.
The primary goal of our study is to understand the
characteristics and practical usefulness of such a lex-
icon. Towards this end, we provide both a qualitative
and quantitative analysis for a web-derived English
</bodyText>
<page confidence="0.954395">
777
</page>
<note confidence="0.752585">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 777–785,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999958096774194">
lexicon relative to two previously published lexicons
– the lexicon used in Wilson et al. (2005) and the
lexicon used in Blair-Goldensohn et al. (2008). Our
experiments show that a web-derived lexicon is not
only significantly larger, but has improved accuracy
on a sentence polarity classification task, which is
an important problem in many sentiment analysis
applications, including sentiment aggregation and
summarization (Hu and Liu, 2004; Carenini et al.,
2006; Lerman et al., 2009). These results hold true
both when the lexicons are used in conjunction with
string matching to classify sentences, and when they
are included within a contextual classifier frame-
work (Wilson et al., 2005).
Extracting polarity lexicons from the web has
been investigated previously by Kaji and Kitsure-
gawa (2007), who study the problem exclusively for
Japanese. In that work a set of positive/negative sen-
tences are first extracted from the web using cues
from a syntactic parser as well as the document
structure. Adjectives phrases are then extracted from
these sentences based on different statistics of their
occurrence in the positive or negative set. Our work,
on the other hand, does not rely on syntactic parsers
or restrict the set of candidate lexicon entries to spe-
cific syntactic classes, i.e., adjective phrases. As a
result, the lexicon built in our study is on a different
scale than that examined in Kaji and Kitsuregawa
(2007). Though this hypothesis is not tested here, it
also makes our techniques more amenable to adap-
tation for other languages.
</bodyText>
<sectionHeader confidence="0.799187" genericHeader="method">
2 Constructing the Lexicon
</sectionHeader>
<bodyText confidence="0.999589666666667">
In this section we describe a method to construct po-
larity lexicons using graph propagation over a phrase
similarity graph constructed from the web.
</bodyText>
<subsectionHeader confidence="0.991113">
2.1 Graph Propagation Algorithm
</subsectionHeader>
<bodyText confidence="0.999848890909091">
We construct our lexicon using graph propagation
techniques, which have previously been investigated
in the construction of polarity lexicons (Kim and
Hovy, 2004; Hu and Liu, 2004; Esuli and Sabas-
tiani, 2009; Blair-Goldensohn et al., 2008; Rao and
Ravichandran, 2009). We assume as input an undi-
rected edge weighted graph G = (V, E), where
wij E [0, 1] is the weight of edge (vi, vj) E E. The
node set V is the set of candidate phrases for inclu-
sion in a sentiment lexicon. In practice, G should en-
code semantic similarities between two nodes, e.g.,
for sentiment analysis one would hope that wij &gt;
wik if vi=good, vj=great and vk=bad. We also as-
sume as input two sets of seed phrases, denoted P
for the positive seed set and N for the negative seed
set. The common property among all graph propaga-
tion algorithms is that they attempt to propagate in-
formation from the seed sets to the rest of the graph
through its edges. This can be done using machine
learning, graph algorithms or more heuristic means.
The specific algorithm used in this study is given
in Figure 1, which is distinct from common graph
propagation algorithms, e.g., label propagation (see
Section 2.3). The output is a polarity vector pol E
RIVE such that poli is the polarity score for the ith
candidate phrase (or the ith node in G). In particular,
we desire pol to have the following semantics:
{ &gt; 0 ith phrase has positive polarity
� 0 ith phrase has negative polarity
= 0 ith phrase has no sentiment
Intuitively, the algorithm works by computing both
a positive and a negative polarity magnitude for
each node in the graph, call them pol+i and pol-i.
These values are equal to the sum over the max
weighted path from every seed word (either posi-
tive or negative) to node vi. Phrases that are con-
nected to multiple positive seed words through short
yet highly weighted paths will receive high positive
values. The final polarity of a phrase is then set to
poli = pol+i − Qpol-i, where Q a constant meant to
account for the difference in overall mass of positive
and negative flow in the graph. Thus, after the al-
gorithm is run, if a phrase has a higher positive than
negative polarity score, then its final polarity will be
positive, and negative otherwise.
There are some implementation details worth
pointing out. First, the algorithm in Figure 1 is writ-
ten in an iterative framework, where on each itera-
tion, paths of increasing lengths are considered. The
input variable T controls the max path length con-
sidered by the algorithm. This can be set to be a
small value in practice, since the multiplicative path
weights result in long paths rarely contributing to
polarity scores. Second, the parameter -y is a thresh-
old that defines the minimum polarity magnitude a
</bodyText>
<equation confidence="0.7757838">
poli =
778
Input: G = (V, E), wij E [0, 1],
P,N,yER,TEN
Output: pol E R|V |
</equation>
<bodyText confidence="0.897625">
Initialize: poli, pol+i, pol-i = 0, for all i
pol+i = 1.0 for all vi E P and
pol-i = 1.0 for all vi E N
</bodyText>
<listItem confidence="0.972496857142857">
1. set αij = 0 for all i, j
2. for vi E P
3. F = {vi}
4. fort: 1 ... T
5. for (vk, vj) E E such that vk E F
6. αij = max{αij, αik · wkj}
F = F U {vj}
7. for vj E V
j = �
8. pol+ v;�P αij
9. Repeat steps 1-8 using N to compute pol-
10. O = Ei pol+i / Ei pol-i
11. poli = pol+i − Opol-i, for all i
12. if |poli |&lt; y then poli = 0.0, for all i
</listItem>
<figureCaption confidence="0.997337">
Figure 1: Graph Propagation Algorithm.
</figureCaption>
<bodyText confidence="0.9997304">
phrase must have to be included in the lexicon. Both
T and y were tuned on held-out data.
To construct the final lexicon, the remaining
nodes – those with polarity scores above y – are ex-
tracted and assigned their corresponding polarity.
</bodyText>
<subsectionHeader confidence="0.999714">
2.2 Building a Phrase Graph from the Web
</subsectionHeader>
<bodyText confidence="0.999994283018868">
Graph propagation algorithms rely on the existence
of graphs that encode meaningful relationships be-
tween candidate nodes. Past studies on building po-
larity lexicons have used linguistic resources like
WordNet to define the graph through synonym and
antonym relations (Kim and Hovy, 2004; Esuli and
Sabastiani, 2009; Blair-Goldensohn et al., 2008;
Rao and Ravichandran, 2009). The goal of this study
is to examine the size and quality of polarity lexi-
cons when the graph is induced automatically from
documents on the web.
Constructing a graph from web-computed lexi-
cal co-occurrence statistics is a difficult challenge
in and of itself and the research and implementa-
tion hurdles that arise are beyond the scope of this
work (Alfonseca et al., 2009; Pantel et al., 2009).
For this study, we used an English graph where the
node set V was based on all n-grams up to length
10 extracted from 4 billion web pages. This list was
filtered to 20 million candidate phrases using a num-
ber of heuristics including frequency and mutual in-
formation of word boundaries. A context vector for
each candidate phrase was then constructed based
on a window of size six aggregated over all men-
tions of the phrase in the 4 billion documents. The
edge set E was constructed by first, for each po-
tential edge (vi, vj), computing the cosine similar-
ity value between context vectors. All edges (vi, vj)
were then discarded if they were not one of the 25
highest weighted edges adjacent to either node vi or
vj. This serves to both reduce the size of the graph
and to eliminate many spurious edges for frequently
occurring phrases, while still keeping the graph rela-
tively connected. The weight of the remaining edges
was set to the corresponding cosine similarity value.
Since this graph encodes co-occurrences over a
large, but local context window, it can be noisy for
our purposes. In particular, we might see a number
of edges between positive and negative sentiment
words as well as sentiment words and non-sentiment
words, e.g., sentiment adjectives and all other adjec-
tives that are distributionally similar. Larger win-
dows theoretically alleviate this problem as they en-
code semantic as opposed to syntactic similarities.
We note, however, that the graph propagation al-
gorithm described above calculates the sentiment of
each phrase as the aggregate of all the best paths to
seed words. Thus, even if some local edges are erro-
neous in the graph, one hopes that, globally, positive
phrases will be influenced more by paths from pos-
itive seed words as opposed to negative seed words.
Section 3, and indeed this paper, aims to measure
whether this is true or not.
</bodyText>
<subsectionHeader confidence="0.998895">
2.3 Why Not Label Propagation?
</subsectionHeader>
<bodyText confidence="0.999892916666667">
Previous studies on constructing polarity lexicons
from lexical graphs, e.g., Rao and Ravichandran
(2009), have used the label propagation algorithm,
which takes the form in Figure 2 (Zhu and Ghahra-
mani, 2002). Label propagation is an iterative algo-
rithm where each node takes on the weighted aver-
age of its neighbour’s values from the previous iter-
ation. The result is that nodes with many paths to
seeds get high polarities due to the influence from
their neighbours. The label propagation algorithm
is known to have many desirable properties includ-
ing convergence, a well defined objective function
</bodyText>
<page confidence="0.98819">
779
</page>
<bodyText confidence="0.8550024">
Input: G = (V, E), wig ∈ [0, 1], P, N
Output: pol ∈ R|V |
Initialize: poli = 1.0 for all vi ∈ P and
poli = −1.0 for all vi ∈ N and
poli = 0.0 ∀vi ∈� P ∪ N
</bodyText>
<listItem confidence="0.9949968">
1. for: t .. T
r- (�i, vj) EE w*j XPolj
2. poli = wij, ∀vi ∈ V
3. reset poli = 1.0 ∀vi ∈ P
reset poli = −1.0 ∀vi ∈ N
</listItem>
<figureCaption confidence="0.998304">
Figure 2: The label propagation algorithm (Zhu and
Ghahramani, 2002).
</figureCaption>
<bodyText confidence="0.999947404761905">
(minimize squared error between values of adjacent
nodes), and an equivalence to computing random
walks through graphs.
The primary difference between standard label
propagation and the graph propagation algorithm
given in Section 2.1, is that a node with multiple
paths to a seed will be influenced by all these paths
in the label propagation algorithm, whereas only the
single path from a seed will influence the polarity
of a node in our proposed propagation algorithm –
namely the path with highest weight. The intuition
behind label propagation seems justified. That is, if
a node has multiple paths to a seed, it should be re-
flected in a higher score. This is certainly true when
the graph is of high quality and all paths trustwor-
thy. However, in a graph constructed from web co-
occurrence statistics, this is rarely the case.
Our graph consisted of many dense subgraphs,
each representing some semantic entity class, such
as actors, authors, tech companies, etc. Problems
arose when polarity flowed into these dense sub-
graphs with the label propagation algorithm. Ulti-
mately, this flow would amplify since the dense sub-
graph provided exponentially many paths from each
node to the source of the flow, which caused a re-
inforcement effect. As a result, the lexicon would
consist of large groups of actor names, companies,
etc. This also led to convergence issues since the
polarity is divided proportional to the size of the
dense subgraph. Additionally, negative phrases in
the graph appeared to be in more densely connected
regions, which resulted in the final lexicons being
highly skewed towards negative entries due to the
influence of multiple paths to seed words.
For best path propagation, these problems were
less acute as each node in the dense subgraph would
only get the polarity a single time from each seed,
which is decayed by the fact that edge weights are
smaller than 1. Furthermore, the fact that edge
weights are less than 1 results in most long paths
having weights near zero, which in turn results in
fast convergence.
</bodyText>
<sectionHeader confidence="0.992346" genericHeader="method">
3 Lexicon Evaluation
</sectionHeader>
<bodyText confidence="0.997325055555556">
We ran the best path graph propagation algorithm
over a graph constructed from the web using manu-
ally constructed positive and negative seed sets of
187 and 192 words in size, respectively. These
words were generated by a set of five humans and
many are morphological variants of the same root,
e.g., excel/excels/excelled. The algorithm produced
a lexicon that contained 178,104 entries. Depending
on the threshold -y (see Figure 1), this lexicon could
be larger or smaller. As stated earlier, our selection
of -y and all hyperparameters was based on manual
inspection of the resulting lexicons and performance
on held-out data.
In the rest of this section we investigate the prop-
erties of this lexicon to understand both its general
characteristics as well as its possible utility in sen-
timent applications. To this end we compare three
different lexicons:
</bodyText>
<listItem confidence="0.9994801875">
1. Wilson et al.: Described in Wilson et al.
(2005). Lexicon constructed by combining the
lexicon built in Riloff and Wiebe (2003) with
other sources1. Entries are are coarsely rated
– strong/weak positive/negative – which we
weighted as 1.0, 0.5, -0.5, and -1.0 for our ex-
periments.
2. WordNet LP: Described in Blair-Goldensohn
et al. (2008). Constructed using label propaga-
tion over a graph derived from WordNet syn-
onym and antonym links. Note that label prop-
agation is not prone to the kinds of errors dis-
cussed in Section 2.3 since the lexical graph is
derived from a high quality source.
3. Web GP: The web-derived lexicon described
in Section 2.1 and Section 2.2.
</listItem>
<footnote confidence="0.998032">
1See http://www.cs.pitt.edu/mpqa/
</footnote>
<page confidence="0.983315">
780
</page>
<subsectionHeader confidence="0.990509">
3.1 Qualitative Evaluation
</subsectionHeader>
<bodyText confidence="0.999918666666667">
Table 1 breaks down the lexicon by the number of
positive and negative entries of each lexicon, which
clearly shows that the lexicon derived from the web
is more than an order of magnitude larger than pre-
viously constructed lexicons.2 This in and of it-
self is not much of an achievement if the additional
phrases are of poor quality. However, in Section 3.2
we present an empirical evaluation that suggests that
these terms provide both additional and useful in-
formation. Table 1 also shows the recall of the each
lexicon relative to the other. Whereas the Wilson
et al. (2005) and WordNet lexicon have a recall of
only 3% relative to the web lexicon, the web lexi-
con has a recall of 48% and 70% relative to the two
other lexicons, indicating that it contains a signifi-
cant amount of information from the other lexicons.
However, this overlap is still small, suggesting that
a combination of all the lexicons could provide the
best performance. In Section 3.2 we investigate this
empirically through a meta classification system.
Table 2 shows the distribution of phrases in the
web-derived lexicon relative to the number of to-
kens in each phrase. Here a token is simply defined
by whitespace and punctuation, with punctuation
counting as a token, e.g., “half-baked” is counted as
3 tokens. For the most part, we see what one might
expect, as the number of tokens increases, the num-
ber of corresponding phrases in the lexicon also de-
creases. Longer phrases are less frequent and thus
will have both fewer and lower weighted edges to
adjacent nodes in the graph. There is a single phrase
of length 9, which is “motion to dismiss for failure
to state a claim”. In fact, the lexicon contains quite
a number of legal and medical phrases. This should
not be surprising, since in a graph induced from the
web, a phrase like “cancer” (or any disease) should
be distributionally similar to phrases like “illness”,
“sick”, and “death”, which themselves will be simi-
lar to standard sentiment phrases like “bad” and “ter-
rible”. These terms are predominantly negative in
the lexicon representing the broad notion that legal
and medical events are undesirable.
</bodyText>
<footnote confidence="0.9987235">
2This also includes the web-derived lexicon of (Kaji and Kit-
suregawa, 2007), which has 10K entries. A recent study by
Mohammad et al. (2009) generated lexicons from thesauri with
76K entries.
</footnote>
<table confidence="0.99985725">
Phrase length 1 2 3
# of phrases 37,449 108,631 27,822
Phrase length 4 5 6 7 8 9
# of phrases 3,489 598 71 29 4 1
</table>
<tableCaption confidence="0.9935985">
Table 2: Number of phrases by phrase length in lexicon
built from the web.
</tableCaption>
<bodyText confidence="0.999962256410256">
Perhaps the most interesting characteristic of the
lexicon is that the most frequent phrase length is 2
and not 1. The primary reason for this is an abun-
dance of adjective phrases consisting of an adverb
and an adjective, such as “more brittle” and “less
brittle”. Almost every adjective of length 1 is fre-
quently combined in such a way on the web, so it
not surprising that we see many of these phrases
in the lexicon. Ideally we would see an order on
such phrases, e.g., “more brittle” has a larger neg-
ative polarity than “brittle”, which in turn has a
larger negative polarity than “less brittle”. However,
this is rarely the case and usually the adjective has
the highest polarity magnitude. Again, this is eas-
ily explained. These phrases are necessarily more
common and will thus have more edges with larger
weights in the graph and thus a greater chance of ac-
cumulating a high sentiment score. The prominence
of such phrases suggests that a more principled treat-
ment of them should be investigated in the future.
Finally, Table 3 presents a selection of phrases
from both the positive and negative lexicons cate-
gorized into revealing verticals. For both positive
and negative phrases we present typical examples of
phrases – usually adjectives – that one would expect
to be in a sentiment lexicon. These are phrases not
included in the seed sets. We also present multiword
phrases for both positive and negative cases, which
displays concretely the advantage of building lexi-
cons from the web as opposed to using restricted lin-
guistic resources such as WordNet. Finally, we show
two special cases. The first is spelling variations
(and mistakes) for positive phrases, which were far
more prominent than for negative phrases. Many of
these correspond to social media text where one ex-
presses an increased level of sentiment by repeat-
ing characters. The second is vulgarity in negative
phrases, which was far more prominent than for pos-
itive phrases. Some of these are clearly appropri-
</bodyText>
<page confidence="0.994934">
781
</page>
<table confidence="0.999628">
Recall wrt other lexicons
All Phrases Pos. Phrases Neg. Phrases Wilson et al. WordNet LP Web GP
Wilson et al. 7,628 2,718 4,910 100% 37% 2%
WordNet LP 12,310 5,705 6,605 21% 100% 3%
Web GP 178,104 90,337 87,767 70% 48% 100%
</table>
<tableCaption confidence="0.998633333333333">
Table 1: Lexicon statistics. Wilson et al. is the lexicon used in Wilson et al. (2005), WordNet LP is the lexicon
constructed by Blair-Goldensohn et al. (2008) that uses label propagation algorithms over a graph constructed through
WordNet, and Web GP is the web-derived lexicon from this study.
</tableCaption>
<table confidence="0.726205">
POSITIVE PHRASES NEGATIVE PHRASES
Typical Multiword expressions Spelling variations Typical Multiword expressions Vulgarity
cute once in a life time loveable dirty run of the mill fucking stupid
fabulous state - of - the - art nicee repulsive out of touch fucked up
cuddly fail - safe operation niice crappy over the hill complete bullshit
</table>
<bodyText confidence="0.694308142857143">
plucky just what the doctor ordered cooool sucky flash in the pan shitty
ravishing out of this world coooool subpar bumps in the road half assed
spunky top of the line koool horrendous foaming at the mouth jackass
enchanting melt in your mouth kewl miserable dime a dozen piece of shit
precious snug as a bug cozy lousy pie - in - the - sky son of a bitch
charming out of the box cosy abysmal sick to my stomach sonofabitch
stupendous more good than bad sikk wretched pain in my ass sonuvabitch
</bodyText>
<tableCaption confidence="0.996099">
Table 3: Example positive and negative phrases from web lexicon.
</tableCaption>
<bodyText confidence="0.999921833333333">
ate, e.g., “shitty”, but some are clearly insults and
outbursts that are most likely included due to their
co-occurrence with angry texts. There were also a
number of derogatory terms and racial slurs in the
lexicon, again most of which received negative sen-
timent due to their typical disparaging usage.
</bodyText>
<subsectionHeader confidence="0.999481">
3.2 Quantitative Evaluation
</subsectionHeader>
<bodyText confidence="0.9928878">
To determine the practical usefulness of a polarity
lexicon derived from the web, we measured the per-
formance of the lexicon on a sentence classifica-
tion/ranking task. The input is a set of sentences and
the output is a classification of the sentences as be-
ing either positive, negative or neutral in sentiment.
Additionally, the system outputs two rankings, the
first a ranking of the sentence by positive polarity
and the second a ranking of the sentence by negative
polarity. Classifying sentences by their sentiment is
a subtask of sentiment aggregation systems (Hu and
Liu, 2004; Gamon et al., 2005). Ranking sentences
by their polarity is a critical sub-task in extractive
sentiment summarization (Carenini et al., 2006; Ler-
man et al., 2009).
To classify sentences as being positive, negative
or neutral, we used an augmented vote-flip algo-
rithm (Choi and Cardie, 2009), which is given in
Figure 3. This intuition behind this algorithm is sim-
ple. The number of matched positive and negative
phrases from the lexicon are counted and whichever
has the most votes wins. The algorithm flips the de-
cision if the number of negations is odd. Though this
algorithm appears crude, it benefits from not relying
on threshold values for neutral classification, which
is difficult due to the fact that the polarity scores in
the three lexicons are not on the same scale.
To rank sentences we defined the purity of a sen-
tence X as the normalized sum of the sentiment
scores for each phrase x in the sentence:
</bodyText>
<equation confidence="0.9972035">
purity(X) _ ExcX polx
6 + ExcX |polx|
</equation>
<bodyText confidence="0.999465538461539">
This is a normalized score in the range [−1, 1]. In-
tuitively, sentences with many terms of the same po-
larity will have purity scores at the extreme points of
the range. Before calculating purity, a simple nega-
tion heuristic was implemented that reversed the
sentiment scores of terms that were within the scope
of negations. The term 6 helps to favor sentences
with multiple phrase matches. Purity is a common
metric used for ranking sentences for inclusion in
sentiment summaries (Lerman et al., 2009). Purity
and negative purity were used to rank sentences as
being positive and negative sentiment, respectively.
The data used in our initial English-only experi-
</bodyText>
<page confidence="0.991954">
782
</page>
<table confidence="0.996767272727273">
Wilson et al.
WordNet LP
Web GP
Meta Classifier
Lexicon Classifier Contextual Classifier
Positive Negative Positive Negative
P R AP P R AP P R AP P R AP
56.4 61.8 60.8 58.1 39.0 59.7 74.5 70.3 76.2 80.7 70.1 81.2
50.9 61.7 62.0 54.9 36.4 59.7 72.0 72.5 75.7 78.0 69.8 79.3
57.7 65.11 69.61 60.3 42.9 68.51 74.1 75.01 79.91 80.5 72.61 82.91
- - - - - - 76.6$ 74.7 81.2$ 81.8$ 72.2 84.1$
</table>
<tableCaption confidence="0.981684">
Table 4: Positive and negative precision (P), recall (R), and average precision (AP) for three lexicons using either
lexical matching or contextual classification strategies. 1 Web GP is statistically significantly better than Wilson et al.
and WordNet LP (p &lt; 0.05). $ Meta Classifier is statistically significantly better than all other systems (p &lt; 0.05).
</tableCaption>
<table confidence="0.566576">
Input: Scored lexicon pol, negation list NG,
input sentence X
Output: sentiment E {POS, NEG, NEU}
</table>
<listItem confidence="0.983030818181818">
1. set p, n, ng = 0
2. for x E X
3. if pol., &gt; 0 then p++
4. else if pol., &lt; 0 then n++
5. else if x E NG then ng++
6. flip = (ng % 2 == 1) //ng is odd
7. if (p &gt; n &amp; flip) 11 (n &gt; p &amp; flip)
return POS
8. else if (p &gt; n &amp; flip) 11 (n &gt; p &amp; flip)
return NEG
19. return NEU
</listItem>
<figureCaption confidence="0.997863">
Figure 3: Vote-flip algorithm (Choi and Cardie, 2009).
</figureCaption>
<bodyText confidence="0.999990666666667">
ments were a set of 554 consumer reviews described
in (McDonald et al., 2007). Each review was sen-
tence split and annotated by a human as being pos-
itive, negative or neutral in sentiment. This resulted
in 3,916 sentences, with 1,525, 1,542 and 849 posi-
tive, negative and neutral sentences, respectively.
The first six columns of Table 4 shows: 1) the pos-
itive/negative precision-recall of each lexicon-based
system where sentence classes were determined us-
ing the vote-flip algorithm, and 2) the average preci-
sion for each lexicon-based system where purity (or
negative purity) was used to rank sentences. Both
the Wilson et al. and WordNet LP lexicons perform
at a similar level, with the former slightly better, es-
pecially in terms of precision. The web-derived lex-
icon, Web GP, outperforms the other two lexicons
across the board, in particular when looking at av-
erage precision, where the gains are near 10% ab-
solute. If we plot the precision-recall graphs using
purity to classify sentences – as opposed to the vote-
flip algorithm, which only provides an unweighted
classification – we can see that at almost all recall
levels the web-derived lexicon has superior preci-
sion to the other lexicons (Figure 4). Thus, even
though the web-derived lexicon is constructed from
a lexical graph that contains noise, the graph prop-
agation algorithms appear to be fairly robust to this
noise and are capable of producing large and accu-
rate polarity lexicons.
The second six columns of Table 4 shows the per-
formance of each lexicon as the core of a contextual
classifier (Wilson et al., 2005). A contextual classi-
fier is a machine learned classifier that predicts the
polarity of a sentence using features of that sentence
and its context. For our experiments, this was a max-
imum entropy classifier trained and evaluated us-
ing 10-fold cross-validation on the evaluation data.
The features included in the classifier were the pu-
rity score, the number of positive and negative lex-
icon matches, and the number of negations in the
sentence, as well as concatenations of these features
within the sentence and with the same features de-
rived from the sentences in a window of size 1.
For each sentence, the contextual classifier pre-
dicted either a positive, negative or neutral classifi-
cation based on the label with highest probability.
Additionally, all sentences were placed in the posi-
tive and negative sentence rankings by the probabil-
ity the classifier assigned to the positive and negative
classes, respectively. Mirroring the results of Wil-
son et al. (2005), we see that contextual classifiers
improve results substantially over lexical matching.
More interestingly, we see that the a contextual clas-
sifier over the web-derived lexicons maintains the
performance edge over the other lexicons, though
the gap is smaller. Figure 5 plots the precision-recall
curves for the positive and negative sentence rank-
</bodyText>
<page confidence="0.992169">
783
</page>
<figure confidence="0.999901269230769">
0 0.2 0.4 0.6 0.8 1
Recall
Precision
0.9
0.8
0.7
0.6
0.5
0.4
1
Wilson et al.
WordNet LP
Web GP
0 0.2 0.4 0.6 0.8 1
Recall
Precision
0.9
0.8
0.7
0.6
0.5
0.4
1
Wilson et al.
WordNet LP
Web GP
</figure>
<figureCaption confidence="0.995974">
Figure 4: Lexicon classifier precision/recall curves for positive (left) and negative (right) classes.
</figureCaption>
<figure confidence="0.999833592592593">
0 0.2 0.4 0.6 0.8 1
Recall
0 0.2 0.4 0.6 0.8 1
Recall
Precision
0.9
0.8
0.7
0.6
0.5
0.4
1
Wilson et al. CC
WordNet LP CC
Web GP CC
Meta Classifier
Wilson et al. CC
WordNet LP CC
Web GP CC
Meta Classifier
Precision 1
0.9
0.8
0.7
0.6
0.5
0.4
</figure>
<figureCaption confidence="0.999968">
Figure 5: Contextual classifier precision/recall curves for positive (left) and negative (right) classes
</figureCaption>
<bodyText confidence="0.998508333333333">
ings, again showing that at almost every level of re-
call, the web-derived lexicon has higher precision.
For a final English experiment we built a meta-
classification system that is identical to the contex-
tual classifiers, except it is trained using features de-
rived from all lexicons. Results are shown in the
last row of Table 4 and precision-recall curves are
shown in Figure 5. Not surprisingly, this system has
the best performance in terms of average precision
as it has access to the largest amount of information,
though its performance is only slightly better than
the contextual classifier for the web-derived lexicon.
</bodyText>
<sectionHeader confidence="0.999767" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999534423076923">
In this paper we examined the viability of senti-
ment lexicons learned semi-automatically from the
web, as opposed to those that rely on manual anno-
tation and/or resources such as WordNet. Our quali-
tative experiments indicate that the web derived lex-
icon can include a wide range of phrases that have
not been available to previous systems, most no-
tably spelling variations, slang, vulgarity, and multi-
word expressions. Quantitatively, we observed that
the web derived lexicon had superior performance
to previously published lexicons for English clas-
sification. Ultimately, a meta classifier that incor-
porates features from all lexicons provides the best
performance. In the future we plan to investigate the
construction of web-derived lexicons for languages
other than English, which is an active area of re-
search (Mihalcea et al., 2007; Jijkoun and Hofmann,
2009; Rao and Ravichandran, 2009). The advantage
of the web-derived lexicons studied here is that they
do not rely on language specific resources besides
unlabeled data and seed lists. A primary question is
whether such lexicons improve performance over a
translate-to-English strategy (Banea et al., 2008).
Acknowledgements: The authors thank Andrew
Hogue, Raj Krishnan and Deepak Ravichandran for
insightful discussions about this work.
</bodyText>
<page confidence="0.996903">
784
</page>
<sectionHeader confidence="0.996372" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999124666666667">
E. Alfonseca, K. Hall, and S. Hartmann. 2009. Large-
scale computation of distributional similarities for
queries. In Proceedings of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL-HLT).
C. Banea, R. Mihalcea, J. Wiebe, and S. Hassan. 2008.
Multilingual subjectivity analysis using machine trans-
lation. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing (EMNLP).
S. Blair-Goldensohn, K. Hannan, R. McDonald, T. Ney-
lon, G.A. Reis, and J. Reynar. 2008. Building a senti-
ment summarizer for local service reviews. In NLP in
the Information Explosion Era.
G. Carenini, R. Ng, and A. Pauls. 2006. Multi-document
summarization of evaluative text. In Proceedings of
the European Chapter of the Association for Compu-
tational Linguistics (EACL).
Y. Choi and C. Cardie. 2009. Adapting a polarity lexicon
using integer linear programming for domain-specific
sentiment classification. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing (EMNLP).
S.R. Das and M.Y. Chen. 2007. Yahoo! for Amazon:
Sentiment extraction from small talk on the web. Man-
agement Science, 53(9):1375–1388.
A Esuli and F. Sabastiani. 2009. SentiWordNet: A pub-
licly available lexical resource for opinion mining. In
Proceedings of the Language Resource and Evaluation
Conference (LREC).
M. Gamon, A. Aue, S. Corston-Oliver, and E. Ringger.
2005. Pulse: Mining customer opinions from free text.
In Proceedings of the 6th International Symposium on
Intelligent Data Analysis (IDA).
V. Hatzivassiloglou and K.R. McKeown. 1997. Predict-
ing the semantic orientation of adjectives. In Proceed-
ings of the European Chapter of the Association for
Computational Linguistics (EACL).
M. Hu and B. Liu. 2004. Mining and summarizing cus-
tomer reviews. In Proceedings of the International
Conference on Knowledge Discovery and Data Min-
ing (KDD).
V.B. Jijkoun and K. Hofmann. 2009. Generating a non-
english subjectivity lexicon: Relations that matter. In
Proceedings of the European Chapter of the Associa-
tion for Computational Linguistics (EACL).
N. Kaji and M. Kitsuregawa. 2007. Building lexicon for
sentiment analysis from massive collection of HTML
documents. In Proceedings of the Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL).
S.M. Kim and E. Hovy. 2004. Determining the senti-
ment of opinions. In Proceedings of the International
Conference on Computational Linguistics (COLING).
Kevin Lerman, Sasha Blair-Goldensohn, and Ryan Mc-
Donald. 2009. Sentiment summarization: Evaluat-
ing and learning user preferences. In Proceedings of
the European Chapter of the Association for Compu-
tational Linguistics (EACL).
R. McDonald, K. Hannan, T. Neylon, M. Wells, and
J. Reynar. 2007. Structured models for fine-to-coarse
sentiment analysis. In Proceedings of the Annual Con-
ference of the Association for Computational Linguis-
tics (ACL).
R. Mihalcea, C. Banea, and J. Wiebe. 2007. Learning
multilingual subjective language via cross-lingual pro-
jections. In Proceedings of the Annual Conference of
the Association for Computational Linguistics (ACL).
S. Mohammad, B. Dorr, and C. Dunne. 2009. Generat-
ing high-coverage semantic orientation lexicons from
overtly marked words and a thesaurus. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing (EMNLP).
B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs
up? Sentiment classification using machine learn-
ing techniques. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP).
P. Pantel, E. Crestan, A. Borkovsky, A. Popescu, and
V. Vyas. 2009. Web-scale distributional similarity and
entity set expansion. In Proceedings of Conference on
Empirical Methods in Natural Language Processing
(EMNLP).
D. Rao and D. Ravichandran. 2009. Semi-Supervised
Polarity Lexicon Induction. In Proceedings of the Eu-
ropean Chapter of the Association for Computational
Linguistics (EACL).
E. Riloff and J. Wiebe. 2003. Learning extraction pat-
terns for subjective expressions. In Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP).
P. Turney. 2002. Thumbs up or thumbs down? Sentiment
orientation applied to unsupervised classification of re-
views. In Proceedings of the Annual Conference of the
Association for Computational Linguistics (ACL).
J. Wiebe. 2000. Learning subjective adjectives from cor-
pora. In Proceedings of the National Conference on
Artificial Intelligence (AAAI).
T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recogniz-
ing contextual polarity in phrase-level sentiment anal-
ysis. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing (EMNLP).
X. Zhu and Z. Ghahramani. 2002. Learning from labeled
and unlabeled data with label propagation. Technical
report, CMU CALD tech report CMU-CALD-02.
</reference>
<page confidence="0.998448">
785
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.270498">
<title confidence="0.999226">The viability of web-derived polarity lexicons</title>
<author confidence="0.774929">Leonid Velikovich Sasha Blair-Goldensohn Kerry Hannan Ryan Google Inc</author>
<author confidence="0.774929">New York</author>
<author confidence="0.774929">NY</author>
<abstract confidence="0.989546583333333">We examine the viability of building large polarity lexicons semi-automatically from the web. We begin by describing a graph propagation framework inspired by previous work on constructing polarity lexicons from lexical graphs (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; Blair- Goldensohn et al., 2008; Rao and Ravichandran, 2009). We then apply this technique to build an English lexicon that is significantly larger than those previously studied. Crucially, this web-derived lexicon does not require WordNet, part-of-speech taggers, or other language-dependent resources typical of sentiment analysis systems. As a result, the lexicon is not limited to specific word classes – e.g., adjectives that occur in WordNet – and in fact contains slang, misspellings, multiword expressions, etc. We evaluate a lexicon derived from English documents, both qualitatively and quantitatively, and show that it provides superior performance to previously studied lexicons, including one derived from</abstract>
<intro confidence="0.552633">WordNet.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Alfonseca</author>
<author>K Hall</author>
<author>S Hartmann</author>
</authors>
<title>Largescale computation of distributional similarities for queries.</title>
<date>2009</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT).</booktitle>
<contexts>
<context position="9825" citStr="Alfonseca et al., 2009" startWordPosition="1640" endWordPosition="1643"> studies on building polarity lexicons have used linguistic resources like WordNet to define the graph through synonym and antonym relations (Kim and Hovy, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). The goal of this study is to examine the size and quality of polarity lexicons when the graph is induced automatically from documents on the web. Constructing a graph from web-computed lexical co-occurrence statistics is a difficult challenge in and of itself and the research and implementation hurdles that arise are beyond the scope of this work (Alfonseca et al., 2009; Pantel et al., 2009). For this study, we used an English graph where the node set V was based on all n-grams up to length 10 extracted from 4 billion web pages. This list was filtered to 20 million candidate phrases using a number of heuristics including frequency and mutual information of word boundaries. A context vector for each candidate phrase was then constructed based on a window of size six aggregated over all mentions of the phrase in the 4 billion documents. The edge set E was constructed by first, for each potential edge (vi, vj), computing the cosine similarity value between cont</context>
</contexts>
<marker>Alfonseca, Hall, Hartmann, 2009</marker>
<rawString>E. Alfonseca, K. Hall, and S. Hartmann. 2009. Largescale computation of distributional similarities for queries. In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Banea</author>
<author>R Mihalcea</author>
<author>J Wiebe</author>
<author>S Hassan</author>
</authors>
<title>Multilingual subjectivity analysis using machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<marker>Banea, Mihalcea, Wiebe, Hassan, 2008</marker>
<rawString>C. Banea, R. Mihalcea, J. Wiebe, and S. Hassan. 2008. Multilingual subjectivity analysis using machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Blair-Goldensohn</author>
<author>K Hannan</author>
<author>R McDonald</author>
<author>T Neylon</author>
<author>G A Reis</author>
<author>J Reynar</author>
</authors>
<title>Building a sentiment summarizer for local service reviews.</title>
<date>2008</date>
<booktitle>In NLP in the Information Explosion Era.</booktitle>
<contexts>
<context position="2557" citStr="Blair-Goldensohn et al., 2008" startWordPosition="383" endWordPosition="386">lexicons are combined with machine learning for improved results (Wilson et al., 2005). The pervasiveness and sustained use of lexicons can be ascribed to a number of reasons, including their interpretability in large-scale systems as well as the granularity of their analysis. In this work we investigate the viability of polarity lexicons that are derived solely from unlabeled web documents. We propose a method based on graph propagation algorithms inspired by previous work on constructing polarity lexicons from lexical graphs (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). Whereas past efforts have used linguistic resources – e.g., WordNet – to construct the lexical graph over which propagation runs, our lexicons are constructed using a graph built from co-occurrence statistics from the entire web. Thus, the method we investigate can be seen as a combination of methods for propagating sentiment across lexical graphs and methods for building sentiment lexicons based on distributional characteristics of phrases in raw data (Turney, 2002). The advantage of breaking the dependence on WordNet (or related resources like thesauri (Mohamma</context>
<context position="3883" citStr="Blair-Goldensohn et al. (2008)" startWordPosition="586" endWordPosition="589">elling mistakes and variations, slang, and multiword expressions. The primary goal of our study is to understand the characteristics and practical usefulness of such a lexicon. Towards this end, we provide both a qualitative and quantitative analysis for a web-derived English 777 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 777–785, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics lexicon relative to two previously published lexicons – the lexicon used in Wilson et al. (2005) and the lexicon used in Blair-Goldensohn et al. (2008). Our experiments show that a web-derived lexicon is not only significantly larger, but has improved accuracy on a sentence polarity classification task, which is an important problem in many sentiment analysis applications, including sentiment aggregation and summarization (Hu and Liu, 2004; Carenini et al., 2006; Lerman et al., 2009). These results hold true both when the lexicons are used in conjunction with string matching to classify sentences, and when they are included within a contextual classifier framework (Wilson et al., 2005). Extracting polarity lexicons from the web has been inve</context>
<context position="5733" citStr="Blair-Goldensohn et al., 2008" startWordPosition="877" endWordPosition="880">rent scale than that examined in Kaji and Kitsuregawa (2007). Though this hypothesis is not tested here, it also makes our techniques more amenable to adaptation for other languages. 2 Constructing the Lexicon In this section we describe a method to construct polarity lexicons using graph propagation over a phrase similarity graph constructed from the web. 2.1 Graph Propagation Algorithm We construct our lexicon using graph propagation techniques, which have previously been investigated in the construction of polarity lexicons (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). We assume as input an undirected edge weighted graph G = (V, E), where wij E [0, 1] is the weight of edge (vi, vj) E E. The node set V is the set of candidate phrases for inclusion in a sentiment lexicon. In practice, G should encode semantic similarities between two nodes, e.g., for sentiment analysis one would hope that wij &gt; wik if vi=good, vj=great and vk=bad. We also assume as input two sets of seed phrases, denoted P for the positive seed set and N for the negative seed set. The common property among all graph propagation algorithms is that they attempt to </context>
<context position="9422" citStr="Blair-Goldensohn et al., 2008" startWordPosition="1572" endWordPosition="1575">hm. phrase must have to be included in the lexicon. Both T and y were tuned on held-out data. To construct the final lexicon, the remaining nodes – those with polarity scores above y – are extracted and assigned their corresponding polarity. 2.2 Building a Phrase Graph from the Web Graph propagation algorithms rely on the existence of graphs that encode meaningful relationships between candidate nodes. Past studies on building polarity lexicons have used linguistic resources like WordNet to define the graph through synonym and antonym relations (Kim and Hovy, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). The goal of this study is to examine the size and quality of polarity lexicons when the graph is induced automatically from documents on the web. Constructing a graph from web-computed lexical co-occurrence statistics is a difficult challenge in and of itself and the research and implementation hurdles that arise are beyond the scope of this work (Alfonseca et al., 2009; Pantel et al., 2009). For this study, we used an English graph where the node set V was based on all n-grams up to length 10 extracted from 4 billion web pages. This list was filtered to 20 milli</context>
<context position="15970" citStr="Blair-Goldensohn et al. (2008)" startWordPosition="2693" endWordPosition="2696">f the resulting lexicons and performance on held-out data. In the rest of this section we investigate the properties of this lexicon to understand both its general characteristics as well as its possible utility in sentiment applications. To this end we compare three different lexicons: 1. Wilson et al.: Described in Wilson et al. (2005). Lexicon constructed by combining the lexicon built in Riloff and Wiebe (2003) with other sources1. Entries are are coarsely rated – strong/weak positive/negative – which we weighted as 1.0, 0.5, -0.5, and -1.0 for our experiments. 2. WordNet LP: Described in Blair-Goldensohn et al. (2008). Constructed using label propagation over a graph derived from WordNet synonym and antonym links. Note that label propagation is not prone to the kinds of errors discussed in Section 2.3 since the lexical graph is derived from a high quality source. 3. Web GP: The web-derived lexicon described in Section 2.1 and Section 2.2. 1See http://www.cs.pitt.edu/mpqa/ 780 3.1 Qualitative Evaluation Table 1 breaks down the lexicon by the number of positive and negative entries of each lexicon, which clearly shows that the lexicon derived from the web is more than an order of magnitude larger than previo</context>
<context position="21268" citStr="Blair-Goldensohn et al. (2008)" startWordPosition="3604" endWordPosition="3607">orrespond to social media text where one expresses an increased level of sentiment by repeating characters. The second is vulgarity in negative phrases, which was far more prominent than for positive phrases. Some of these are clearly appropri781 Recall wrt other lexicons All Phrases Pos. Phrases Neg. Phrases Wilson et al. WordNet LP Web GP Wilson et al. 7,628 2,718 4,910 100% 37% 2% WordNet LP 12,310 5,705 6,605 21% 100% 3% Web GP 178,104 90,337 87,767 70% 48% 100% Table 1: Lexicon statistics. Wilson et al. is the lexicon used in Wilson et al. (2005), WordNet LP is the lexicon constructed by Blair-Goldensohn et al. (2008) that uses label propagation algorithms over a graph constructed through WordNet, and Web GP is the web-derived lexicon from this study. POSITIVE PHRASES NEGATIVE PHRASES Typical Multiword expressions Spelling variations Typical Multiword expressions Vulgarity cute once in a life time loveable dirty run of the mill fucking stupid fabulous state - of - the - art nicee repulsive out of touch fucked up cuddly fail - safe operation niice crappy over the hill complete bullshit plucky just what the doctor ordered cooool sucky flash in the pan shitty ravishing out of this world coooool subpar bumps i</context>
</contexts>
<marker>Blair-Goldensohn, Hannan, McDonald, Neylon, Reis, Reynar, 2008</marker>
<rawString>S. Blair-Goldensohn, K. Hannan, R. McDonald, T. Neylon, G.A. Reis, and J. Reynar. 2008. Building a sentiment summarizer for local service reviews. In NLP in the Information Explosion Era.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carenini</author>
<author>R Ng</author>
<author>A Pauls</author>
</authors>
<title>Multi-document summarization of evaluative text.</title>
<date>2006</date>
<booktitle>In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="4198" citStr="Carenini et al., 2006" startWordPosition="631" endWordPosition="634">l Conference of the North American Chapter of the ACL, pages 777–785, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics lexicon relative to two previously published lexicons – the lexicon used in Wilson et al. (2005) and the lexicon used in Blair-Goldensohn et al. (2008). Our experiments show that a web-derived lexicon is not only significantly larger, but has improved accuracy on a sentence polarity classification task, which is an important problem in many sentiment analysis applications, including sentiment aggregation and summarization (Hu and Liu, 2004; Carenini et al., 2006; Lerman et al., 2009). These results hold true both when the lexicons are used in conjunction with string matching to classify sentences, and when they are included within a contextual classifier framework (Wilson et al., 2005). Extracting polarity lexicons from the web has been investigated previously by Kaji and Kitsuregawa (2007), who study the problem exclusively for Japanese. In that work a set of positive/negative sentences are first extracted from the web using cues from a syntactic parser as well as the document structure. Adjectives phrases are then extracted from these sentences bas</context>
<context position="23363" citStr="Carenini et al., 2006" startWordPosition="3952" endWordPosition="3955">mance of the lexicon on a sentence classification/ranking task. The input is a set of sentences and the output is a classification of the sentences as being either positive, negative or neutral in sentiment. Additionally, the system outputs two rankings, the first a ranking of the sentence by positive polarity and the second a ranking of the sentence by negative polarity. Classifying sentences by their sentiment is a subtask of sentiment aggregation systems (Hu and Liu, 2004; Gamon et al., 2005). Ranking sentences by their polarity is a critical sub-task in extractive sentiment summarization (Carenini et al., 2006; Lerman et al., 2009). To classify sentences as being positive, negative or neutral, we used an augmented vote-flip algorithm (Choi and Cardie, 2009), which is given in Figure 3. This intuition behind this algorithm is simple. The number of matched positive and negative phrases from the lexicon are counted and whichever has the most votes wins. The algorithm flips the decision if the number of negations is odd. Though this algorithm appears crude, it benefits from not relying on threshold values for neutral classification, which is difficult due to the fact that the polarity scores in the thr</context>
</contexts>
<marker>Carenini, Ng, Pauls, 2006</marker>
<rawString>G. Carenini, R. Ng, and A. Pauls. 2006. Multi-document summarization of evaluative text. In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choi</author>
<author>C Cardie</author>
</authors>
<title>Adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="23513" citStr="Choi and Cardie, 2009" startWordPosition="3977" endWordPosition="3980">s being either positive, negative or neutral in sentiment. Additionally, the system outputs two rankings, the first a ranking of the sentence by positive polarity and the second a ranking of the sentence by negative polarity. Classifying sentences by their sentiment is a subtask of sentiment aggregation systems (Hu and Liu, 2004; Gamon et al., 2005). Ranking sentences by their polarity is a critical sub-task in extractive sentiment summarization (Carenini et al., 2006; Lerman et al., 2009). To classify sentences as being positive, negative or neutral, we used an augmented vote-flip algorithm (Choi and Cardie, 2009), which is given in Figure 3. This intuition behind this algorithm is simple. The number of matched positive and negative phrases from the lexicon are counted and whichever has the most votes wins. The algorithm flips the decision if the number of negations is odd. Though this algorithm appears crude, it benefits from not relying on threshold values for neutral classification, which is difficult due to the fact that the polarity scores in the three lexicons are not on the same scale. To rank sentences we defined the purity of a sentence X as the normalized sum of the sentiment scores for each </context>
<context position="26012" citStr="Choi and Cardie, 2009" startWordPosition="4442" endWordPosition="4445">on strategies. 1 Web GP is statistically significantly better than Wilson et al. and WordNet LP (p &lt; 0.05). $ Meta Classifier is statistically significantly better than all other systems (p &lt; 0.05). Input: Scored lexicon pol, negation list NG, input sentence X Output: sentiment E {POS, NEG, NEU} 1. set p, n, ng = 0 2. for x E X 3. if pol., &gt; 0 then p++ 4. else if pol., &lt; 0 then n++ 5. else if x E NG then ng++ 6. flip = (ng % 2 == 1) //ng is odd 7. if (p &gt; n &amp; flip) 11 (n &gt; p &amp; flip) return POS 8. else if (p &gt; n &amp; flip) 11 (n &gt; p &amp; flip) return NEG 19. return NEU Figure 3: Vote-flip algorithm (Choi and Cardie, 2009). ments were a set of 554 consumer reviews described in (McDonald et al., 2007). Each review was sentence split and annotated by a human as being positive, negative or neutral in sentiment. This resulted in 3,916 sentences, with 1,525, 1,542 and 849 positive, negative and neutral sentences, respectively. The first six columns of Table 4 shows: 1) the positive/negative precision-recall of each lexicon-based system where sentence classes were determined using the vote-flip algorithm, and 2) the average precision for each lexicon-based system where purity (or negative purity) was used to rank sen</context>
</contexts>
<marker>Choi, Cardie, 2009</marker>
<rawString>Y. Choi and C. Cardie. 2009. Adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Das</author>
<author>M Y Chen</author>
</authors>
<title>Yahoo! for Amazon: Sentiment extraction from small talk on the web.</title>
<date>2007</date>
<journal>Management Science,</journal>
<volume>53</volume>
<issue>9</issue>
<contexts>
<context position="1782" citStr="Das and Chen, 2007" startWordPosition="260" endWordPosition="263">ed lexicons, including one derived from WordNet. 1 Introduction Polarity lexicons are large lists of phrases that encode the polarity of each phrase within it – either positive or negative – often with some score representing the magnitude of the polarity (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Turney, 2002). Though classifiers built with machine learning algorithms have become commonplace in the sentiment analysis literature, e.g., Pang et al. (2002), the core of many academic and commercial sentiment analysis systems remains the polarity lexicon, which can be constructed manually (Das and Chen, 2007), through heuristics (Kim and Hovy, 2004; Esuli and Sabastiani, 2009) or using machine learning (Turney, 2002; Rao and Ravichandran, 2009). Often lexicons are combined with machine learning for improved results (Wilson et al., 2005). The pervasiveness and sustained use of lexicons can be ascribed to a number of reasons, including their interpretability in large-scale systems as well as the granularity of their analysis. In this work we investigate the viability of polarity lexicons that are derived solely from unlabeled web documents. We propose a method based on graph propagation algorithms i</context>
</contexts>
<marker>Das, Chen, 2007</marker>
<rawString>S.R. Das and M.Y. Chen. 2007. Yahoo! for Amazon: Sentiment extraction from small talk on the web. Management Science, 53(9):1375–1388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Esuli</author>
<author>F Sabastiani</author>
</authors>
<title>SentiWordNet: A publicly available lexical resource for opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the Language Resource and Evaluation Conference (LREC).</booktitle>
<contexts>
<context position="1851" citStr="Esuli and Sabastiani, 2009" startWordPosition="270" endWordPosition="273">on Polarity lexicons are large lists of phrases that encode the polarity of each phrase within it – either positive or negative – often with some score representing the magnitude of the polarity (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Turney, 2002). Though classifiers built with machine learning algorithms have become commonplace in the sentiment analysis literature, e.g., Pang et al. (2002), the core of many academic and commercial sentiment analysis systems remains the polarity lexicon, which can be constructed manually (Das and Chen, 2007), through heuristics (Kim and Hovy, 2004; Esuli and Sabastiani, 2009) or using machine learning (Turney, 2002; Rao and Ravichandran, 2009). Often lexicons are combined with machine learning for improved results (Wilson et al., 2005). The pervasiveness and sustained use of lexicons can be ascribed to a number of reasons, including their interpretability in large-scale systems as well as the granularity of their analysis. In this work we investigate the viability of polarity lexicons that are derived solely from unlabeled web documents. We propose a method based on graph propagation algorithms inspired by previous work on constructing polarity lexicons from lexic</context>
<context position="5702" citStr="Esuli and Sabastiani, 2009" startWordPosition="872" endWordPosition="876">t in our study is on a different scale than that examined in Kaji and Kitsuregawa (2007). Though this hypothesis is not tested here, it also makes our techniques more amenable to adaptation for other languages. 2 Constructing the Lexicon In this section we describe a method to construct polarity lexicons using graph propagation over a phrase similarity graph constructed from the web. 2.1 Graph Propagation Algorithm We construct our lexicon using graph propagation techniques, which have previously been investigated in the construction of polarity lexicons (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). We assume as input an undirected edge weighted graph G = (V, E), where wij E [0, 1] is the weight of edge (vi, vj) E E. The node set V is the set of candidate phrases for inclusion in a sentiment lexicon. In practice, G should encode semantic similarities between two nodes, e.g., for sentiment analysis one would hope that wij &gt; wik if vi=good, vj=great and vk=bad. We also assume as input two sets of seed phrases, denoted P for the positive seed set and N for the negative seed set. The common property among all graph propagation algo</context>
<context position="9391" citStr="Esuli and Sabastiani, 2009" startWordPosition="1568" endWordPosition="1571">1: Graph Propagation Algorithm. phrase must have to be included in the lexicon. Both T and y were tuned on held-out data. To construct the final lexicon, the remaining nodes – those with polarity scores above y – are extracted and assigned their corresponding polarity. 2.2 Building a Phrase Graph from the Web Graph propagation algorithms rely on the existence of graphs that encode meaningful relationships between candidate nodes. Past studies on building polarity lexicons have used linguistic resources like WordNet to define the graph through synonym and antonym relations (Kim and Hovy, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). The goal of this study is to examine the size and quality of polarity lexicons when the graph is induced automatically from documents on the web. Constructing a graph from web-computed lexical co-occurrence statistics is a difficult challenge in and of itself and the research and implementation hurdles that arise are beyond the scope of this work (Alfonseca et al., 2009; Pantel et al., 2009). For this study, we used an English graph where the node set V was based on all n-grams up to length 10 extracted from 4 billion web pages. Thi</context>
</contexts>
<marker>Esuli, Sabastiani, 2009</marker>
<rawString>A Esuli and F. Sabastiani. 2009. SentiWordNet: A publicly available lexical resource for opinion mining. In Proceedings of the Language Resource and Evaluation Conference (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gamon</author>
<author>A Aue</author>
<author>S Corston-Oliver</author>
<author>E Ringger</author>
</authors>
<title>Pulse: Mining customer opinions from free text.</title>
<date>2005</date>
<booktitle>In Proceedings of the 6th International Symposium on Intelligent Data Analysis (IDA).</booktitle>
<contexts>
<context position="23242" citStr="Gamon et al., 2005" startWordPosition="3935" endWordPosition="3938">ive Evaluation To determine the practical usefulness of a polarity lexicon derived from the web, we measured the performance of the lexicon on a sentence classification/ranking task. The input is a set of sentences and the output is a classification of the sentences as being either positive, negative or neutral in sentiment. Additionally, the system outputs two rankings, the first a ranking of the sentence by positive polarity and the second a ranking of the sentence by negative polarity. Classifying sentences by their sentiment is a subtask of sentiment aggregation systems (Hu and Liu, 2004; Gamon et al., 2005). Ranking sentences by their polarity is a critical sub-task in extractive sentiment summarization (Carenini et al., 2006; Lerman et al., 2009). To classify sentences as being positive, negative or neutral, we used an augmented vote-flip algorithm (Choi and Cardie, 2009), which is given in Figure 3. This intuition behind this algorithm is simple. The number of matched positive and negative phrases from the lexicon are counted and whichever has the most votes wins. The algorithm flips the decision if the number of negations is odd. Though this algorithm appears crude, it benefits from not relyi</context>
</contexts>
<marker>Gamon, Aue, Corston-Oliver, Ringger, 2005</marker>
<rawString>M. Gamon, A. Aue, S. Corston-Oliver, and E. Ringger. 2005. Pulse: Mining customer opinions from free text. In Proceedings of the 6th International Symposium on Intelligent Data Analysis (IDA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>K R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="1454" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="210" endWordPosition="214">tems. As a result, the lexicon is not limited to specific word classes – e.g., adjectives that occur in WordNet – and in fact contains slang, misspellings, multiword expressions, etc. We evaluate a lexicon derived from English documents, both qualitatively and quantitatively, and show that it provides superior performance to previously studied lexicons, including one derived from WordNet. 1 Introduction Polarity lexicons are large lists of phrases that encode the polarity of each phrase within it – either positive or negative – often with some score representing the magnitude of the polarity (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Turney, 2002). Though classifiers built with machine learning algorithms have become commonplace in the sentiment analysis literature, e.g., Pang et al. (2002), the core of many academic and commercial sentiment analysis systems remains the polarity lexicon, which can be constructed manually (Das and Chen, 2007), through heuristics (Kim and Hovy, 2004; Esuli and Sabastiani, 2009) or using machine learning (Turney, 2002; Rao and Ravichandran, 2009). Often lexicons are combined with machine learning for improved results (Wilson et al., 2005). The pervasiveness and sustained use of</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>V. Hatzivassiloglou and K.R. McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Knowledge Discovery and Data Mining (KDD).</booktitle>
<contexts>
<context position="2498" citStr="Hu and Liu, 2004" startWordPosition="375" endWordPosition="378">ney, 2002; Rao and Ravichandran, 2009). Often lexicons are combined with machine learning for improved results (Wilson et al., 2005). The pervasiveness and sustained use of lexicons can be ascribed to a number of reasons, including their interpretability in large-scale systems as well as the granularity of their analysis. In this work we investigate the viability of polarity lexicons that are derived solely from unlabeled web documents. We propose a method based on graph propagation algorithms inspired by previous work on constructing polarity lexicons from lexical graphs (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). Whereas past efforts have used linguistic resources – e.g., WordNet – to construct the lexical graph over which propagation runs, our lexicons are constructed using a graph built from co-occurrence statistics from the entire web. Thus, the method we investigate can be seen as a combination of methods for propagating sentiment across lexical graphs and methods for building sentiment lexicons based on distributional characteristics of phrases in raw data (Turney, 2002). The advantage of breaking the depende</context>
<context position="4175" citStr="Hu and Liu, 2004" startWordPosition="627" endWordPosition="630">es: The 2010 Annual Conference of the North American Chapter of the ACL, pages 777–785, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics lexicon relative to two previously published lexicons – the lexicon used in Wilson et al. (2005) and the lexicon used in Blair-Goldensohn et al. (2008). Our experiments show that a web-derived lexicon is not only significantly larger, but has improved accuracy on a sentence polarity classification task, which is an important problem in many sentiment analysis applications, including sentiment aggregation and summarization (Hu and Liu, 2004; Carenini et al., 2006; Lerman et al., 2009). These results hold true both when the lexicons are used in conjunction with string matching to classify sentences, and when they are included within a contextual classifier framework (Wilson et al., 2005). Extracting polarity lexicons from the web has been investigated previously by Kaji and Kitsuregawa (2007), who study the problem exclusively for Japanese. In that work a set of positive/negative sentences are first extracted from the web using cues from a syntactic parser as well as the document structure. Adjectives phrases are then extracted f</context>
<context position="5674" citStr="Hu and Liu, 2004" startWordPosition="868" endWordPosition="871">, the lexicon built in our study is on a different scale than that examined in Kaji and Kitsuregawa (2007). Though this hypothesis is not tested here, it also makes our techniques more amenable to adaptation for other languages. 2 Constructing the Lexicon In this section we describe a method to construct polarity lexicons using graph propagation over a phrase similarity graph constructed from the web. 2.1 Graph Propagation Algorithm We construct our lexicon using graph propagation techniques, which have previously been investigated in the construction of polarity lexicons (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). We assume as input an undirected edge weighted graph G = (V, E), where wij E [0, 1] is the weight of edge (vi, vj) E E. The node set V is the set of candidate phrases for inclusion in a sentiment lexicon. In practice, G should encode semantic similarities between two nodes, e.g., for sentiment analysis one would hope that wij &gt; wik if vi=good, vj=great and vk=bad. We also assume as input two sets of seed phrases, denoted P for the positive seed set and N for the negative seed set. The common property amon</context>
<context position="23221" citStr="Hu and Liu, 2004" startWordPosition="3931" endWordPosition="3934">age. 3.2 Quantitative Evaluation To determine the practical usefulness of a polarity lexicon derived from the web, we measured the performance of the lexicon on a sentence classification/ranking task. The input is a set of sentences and the output is a classification of the sentences as being either positive, negative or neutral in sentiment. Additionally, the system outputs two rankings, the first a ranking of the sentence by positive polarity and the second a ranking of the sentence by negative polarity. Classifying sentences by their sentiment is a subtask of sentiment aggregation systems (Hu and Liu, 2004; Gamon et al., 2005). Ranking sentences by their polarity is a critical sub-task in extractive sentiment summarization (Carenini et al., 2006; Lerman et al., 2009). To classify sentences as being positive, negative or neutral, we used an augmented vote-flip algorithm (Choi and Cardie, 2009), which is given in Figure 3. This intuition behind this algorithm is simple. The number of matched positive and negative phrases from the lexicon are counted and whichever has the most votes wins. The algorithm flips the decision if the number of negations is odd. Though this algorithm appears crude, it be</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>M. Hu and B. Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the International Conference on Knowledge Discovery and Data Mining (KDD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>V B Jijkoun</author>
<author>K Hofmann</author>
</authors>
<title>Generating a nonenglish subjectivity lexicon: Relations that matter.</title>
<date>2009</date>
<booktitle>In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<marker>Jijkoun, Hofmann, 2009</marker>
<rawString>V.B. Jijkoun and K. Hofmann. 2009. Generating a nonenglish subjectivity lexicon: Relations that matter. In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kaji</author>
<author>M Kitsuregawa</author>
</authors>
<title>Building lexicon for sentiment analysis from massive collection of HTML documents.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</booktitle>
<contexts>
<context position="4533" citStr="Kaji and Kitsuregawa (2007)" startWordPosition="683" endWordPosition="687">that a web-derived lexicon is not only significantly larger, but has improved accuracy on a sentence polarity classification task, which is an important problem in many sentiment analysis applications, including sentiment aggregation and summarization (Hu and Liu, 2004; Carenini et al., 2006; Lerman et al., 2009). These results hold true both when the lexicons are used in conjunction with string matching to classify sentences, and when they are included within a contextual classifier framework (Wilson et al., 2005). Extracting polarity lexicons from the web has been investigated previously by Kaji and Kitsuregawa (2007), who study the problem exclusively for Japanese. In that work a set of positive/negative sentences are first extracted from the web using cues from a syntactic parser as well as the document structure. Adjectives phrases are then extracted from these sentences based on different statistics of their occurrence in the positive or negative set. Our work, on the other hand, does not rely on syntactic parsers or restrict the set of candidate lexicon entries to specific syntactic classes, i.e., adjective phrases. As a result, the lexicon built in our study is on a different scale than that examined</context>
<context position="18586" citStr="Kaji and Kitsuregawa, 2007" startWordPosition="3135" endWordPosition="3139"> 9, which is “motion to dismiss for failure to state a claim”. In fact, the lexicon contains quite a number of legal and medical phrases. This should not be surprising, since in a graph induced from the web, a phrase like “cancer” (or any disease) should be distributionally similar to phrases like “illness”, “sick”, and “death”, which themselves will be similar to standard sentiment phrases like “bad” and “terrible”. These terms are predominantly negative in the lexicon representing the broad notion that legal and medical events are undesirable. 2This also includes the web-derived lexicon of (Kaji and Kitsuregawa, 2007), which has 10K entries. A recent study by Mohammad et al. (2009) generated lexicons from thesauri with 76K entries. Phrase length 1 2 3 # of phrases 37,449 108,631 27,822 Phrase length 4 5 6 7 8 9 # of phrases 3,489 598 71 29 4 1 Table 2: Number of phrases by phrase length in lexicon built from the web. Perhaps the most interesting characteristic of the lexicon is that the most frequent phrase length is 2 and not 1. The primary reason for this is an abundance of adjective phrases consisting of an adverb and an adjective, such as “more brittle” and “less brittle”. Almost every adjective of len</context>
</contexts>
<marker>Kaji, Kitsuregawa, 2007</marker>
<rawString>N. Kaji and M. Kitsuregawa. 2007. Building lexicon for sentiment analysis from massive collection of HTML documents. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Kim</author>
<author>E Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="1822" citStr="Kim and Hovy, 2004" startWordPosition="266" endWordPosition="269">ordNet. 1 Introduction Polarity lexicons are large lists of phrases that encode the polarity of each phrase within it – either positive or negative – often with some score representing the magnitude of the polarity (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Turney, 2002). Though classifiers built with machine learning algorithms have become commonplace in the sentiment analysis literature, e.g., Pang et al. (2002), the core of many academic and commercial sentiment analysis systems remains the polarity lexicon, which can be constructed manually (Das and Chen, 2007), through heuristics (Kim and Hovy, 2004; Esuli and Sabastiani, 2009) or using machine learning (Turney, 2002; Rao and Ravichandran, 2009). Often lexicons are combined with machine learning for improved results (Wilson et al., 2005). The pervasiveness and sustained use of lexicons can be ascribed to a number of reasons, including their interpretability in large-scale systems as well as the granularity of their analysis. In this work we investigate the viability of polarity lexicons that are derived solely from unlabeled web documents. We propose a method based on graph propagation algorithms inspired by previous work on constructing</context>
<context position="5656" citStr="Kim and Hovy, 2004" startWordPosition="864" endWordPosition="867">phrases. As a result, the lexicon built in our study is on a different scale than that examined in Kaji and Kitsuregawa (2007). Though this hypothesis is not tested here, it also makes our techniques more amenable to adaptation for other languages. 2 Constructing the Lexicon In this section we describe a method to construct polarity lexicons using graph propagation over a phrase similarity graph constructed from the web. 2.1 Graph Propagation Algorithm We construct our lexicon using graph propagation techniques, which have previously been investigated in the construction of polarity lexicons (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). We assume as input an undirected edge weighted graph G = (V, E), where wij E [0, 1] is the weight of edge (vi, vj) E E. The node set V is the set of candidate phrases for inclusion in a sentiment lexicon. In practice, G should encode semantic similarities between two nodes, e.g., for sentiment analysis one would hope that wij &gt; wik if vi=good, vj=great and vk=bad. We also assume as input two sets of seed phrases, denoted P for the positive seed set and N for the negative seed set. The co</context>
<context position="9363" citStr="Kim and Hovy, 2004" startWordPosition="1564" endWordPosition="1567">0, for all i Figure 1: Graph Propagation Algorithm. phrase must have to be included in the lexicon. Both T and y were tuned on held-out data. To construct the final lexicon, the remaining nodes – those with polarity scores above y – are extracted and assigned their corresponding polarity. 2.2 Building a Phrase Graph from the Web Graph propagation algorithms rely on the existence of graphs that encode meaningful relationships between candidate nodes. Past studies on building polarity lexicons have used linguistic resources like WordNet to define the graph through synonym and antonym relations (Kim and Hovy, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). The goal of this study is to examine the size and quality of polarity lexicons when the graph is induced automatically from documents on the web. Constructing a graph from web-computed lexical co-occurrence statistics is a difficult challenge in and of itself and the research and implementation hurdles that arise are beyond the scope of this work (Alfonseca et al., 2009; Pantel et al., 2009). For this study, we used an English graph where the node set V was based on all n-grams up to length 10 extracted f</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>S.M. Kim and E. Hovy. 2004. Determining the sentiment of opinions. In Proceedings of the International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Lerman</author>
<author>Sasha Blair-Goldensohn</author>
<author>Ryan McDonald</author>
</authors>
<title>Sentiment summarization: Evaluating and learning user preferences.</title>
<date>2009</date>
<booktitle>In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="4220" citStr="Lerman et al., 2009" startWordPosition="635" endWordPosition="638">th American Chapter of the ACL, pages 777–785, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics lexicon relative to two previously published lexicons – the lexicon used in Wilson et al. (2005) and the lexicon used in Blair-Goldensohn et al. (2008). Our experiments show that a web-derived lexicon is not only significantly larger, but has improved accuracy on a sentence polarity classification task, which is an important problem in many sentiment analysis applications, including sentiment aggregation and summarization (Hu and Liu, 2004; Carenini et al., 2006; Lerman et al., 2009). These results hold true both when the lexicons are used in conjunction with string matching to classify sentences, and when they are included within a contextual classifier framework (Wilson et al., 2005). Extracting polarity lexicons from the web has been investigated previously by Kaji and Kitsuregawa (2007), who study the problem exclusively for Japanese. In that work a set of positive/negative sentences are first extracted from the web using cues from a syntactic parser as well as the document structure. Adjectives phrases are then extracted from these sentences based on different statis</context>
<context position="23385" citStr="Lerman et al., 2009" startWordPosition="3956" endWordPosition="3960"> a sentence classification/ranking task. The input is a set of sentences and the output is a classification of the sentences as being either positive, negative or neutral in sentiment. Additionally, the system outputs two rankings, the first a ranking of the sentence by positive polarity and the second a ranking of the sentence by negative polarity. Classifying sentences by their sentiment is a subtask of sentiment aggregation systems (Hu and Liu, 2004; Gamon et al., 2005). Ranking sentences by their polarity is a critical sub-task in extractive sentiment summarization (Carenini et al., 2006; Lerman et al., 2009). To classify sentences as being positive, negative or neutral, we used an augmented vote-flip algorithm (Choi and Cardie, 2009), which is given in Figure 3. This intuition behind this algorithm is simple. The number of matched positive and negative phrases from the lexicon are counted and whichever has the most votes wins. The algorithm flips the decision if the number of negations is odd. Though this algorithm appears crude, it benefits from not relying on threshold values for neutral classification, which is difficult due to the fact that the polarity scores in the three lexicons are not on</context>
<context position="24679" citStr="Lerman et al., 2009" startWordPosition="4181" endWordPosition="4184">s the normalized sum of the sentiment scores for each phrase x in the sentence: purity(X) _ ExcX polx 6 + ExcX |polx| This is a normalized score in the range [−1, 1]. Intuitively, sentences with many terms of the same polarity will have purity scores at the extreme points of the range. Before calculating purity, a simple negation heuristic was implemented that reversed the sentiment scores of terms that were within the scope of negations. The term 6 helps to favor sentences with multiple phrase matches. Purity is a common metric used for ranking sentences for inclusion in sentiment summaries (Lerman et al., 2009). Purity and negative purity were used to rank sentences as being positive and negative sentiment, respectively. The data used in our initial English-only experi782 Wilson et al. WordNet LP Web GP Meta Classifier Lexicon Classifier Contextual Classifier Positive Negative Positive Negative P R AP P R AP P R AP P R AP 56.4 61.8 60.8 58.1 39.0 59.7 74.5 70.3 76.2 80.7 70.1 81.2 50.9 61.7 62.0 54.9 36.4 59.7 72.0 72.5 75.7 78.0 69.8 79.3 57.7 65.11 69.61 60.3 42.9 68.51 74.1 75.01 79.91 80.5 72.61 82.91 - - - - - - 76.6$ 74.7 81.2$ 81.8$ 72.2 84.1$ Table 4: Positive and negative precision (P), rec</context>
</contexts>
<marker>Lerman, Blair-Goldensohn, McDonald, 2009</marker>
<rawString>Kevin Lerman, Sasha Blair-Goldensohn, and Ryan McDonald. 2009. Sentiment summarization: Evaluating and learning user preferences. In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Hannan</author>
<author>T Neylon</author>
<author>M Wells</author>
<author>J Reynar</author>
</authors>
<title>Structured models for fine-to-coarse sentiment analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="26091" citStr="McDonald et al., 2007" startWordPosition="4456" endWordPosition="4459">. and WordNet LP (p &lt; 0.05). $ Meta Classifier is statistically significantly better than all other systems (p &lt; 0.05). Input: Scored lexicon pol, negation list NG, input sentence X Output: sentiment E {POS, NEG, NEU} 1. set p, n, ng = 0 2. for x E X 3. if pol., &gt; 0 then p++ 4. else if pol., &lt; 0 then n++ 5. else if x E NG then ng++ 6. flip = (ng % 2 == 1) //ng is odd 7. if (p &gt; n &amp; flip) 11 (n &gt; p &amp; flip) return POS 8. else if (p &gt; n &amp; flip) 11 (n &gt; p &amp; flip) return NEG 19. return NEU Figure 3: Vote-flip algorithm (Choi and Cardie, 2009). ments were a set of 554 consumer reviews described in (McDonald et al., 2007). Each review was sentence split and annotated by a human as being positive, negative or neutral in sentiment. This resulted in 3,916 sentences, with 1,525, 1,542 and 849 positive, negative and neutral sentences, respectively. The first six columns of Table 4 shows: 1) the positive/negative precision-recall of each lexicon-based system where sentence classes were determined using the vote-flip algorithm, and 2) the average precision for each lexicon-based system where purity (or negative purity) was used to rank sentences. Both the Wilson et al. and WordNet LP lexicons perform at a similar lev</context>
</contexts>
<marker>McDonald, Hannan, Neylon, Wells, Reynar, 2007</marker>
<rawString>R. McDonald, K. Hannan, T. Neylon, M. Wells, and J. Reynar. 2007. Structured models for fine-to-coarse sentiment analysis. In Proceedings of the Annual Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>C Banea</author>
<author>J Wiebe</author>
</authors>
<title>Learning multilingual subjective language via cross-lingual projections.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics (ACL).</booktitle>
<marker>Mihalcea, Banea, Wiebe, 2007</marker>
<rawString>R. Mihalcea, C. Banea, and J. Wiebe. 2007. Learning multilingual subjective language via cross-lingual projections. In Proceedings of the Annual Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Mohammad</author>
<author>B Dorr</author>
<author>C Dunne</author>
</authors>
<title>Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="3172" citStr="Mohammad et al., 2009" startWordPosition="479" endWordPosition="482">., 2008; Rao and Ravichandran, 2009). Whereas past efforts have used linguistic resources – e.g., WordNet – to construct the lexical graph over which propagation runs, our lexicons are constructed using a graph built from co-occurrence statistics from the entire web. Thus, the method we investigate can be seen as a combination of methods for propagating sentiment across lexical graphs and methods for building sentiment lexicons based on distributional characteristics of phrases in raw data (Turney, 2002). The advantage of breaking the dependence on WordNet (or related resources like thesauri (Mohammad et al., 2009)) is that it allows the lexicons to include non-standard entries, most notably spelling mistakes and variations, slang, and multiword expressions. The primary goal of our study is to understand the characteristics and practical usefulness of such a lexicon. Towards this end, we provide both a qualitative and quantitative analysis for a web-derived English 777 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 777–785, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics lexicon relative to two previously publi</context>
<context position="18651" citStr="Mohammad et al. (2009)" startWordPosition="3148" endWordPosition="3151">, the lexicon contains quite a number of legal and medical phrases. This should not be surprising, since in a graph induced from the web, a phrase like “cancer” (or any disease) should be distributionally similar to phrases like “illness”, “sick”, and “death”, which themselves will be similar to standard sentiment phrases like “bad” and “terrible”. These terms are predominantly negative in the lexicon representing the broad notion that legal and medical events are undesirable. 2This also includes the web-derived lexicon of (Kaji and Kitsuregawa, 2007), which has 10K entries. A recent study by Mohammad et al. (2009) generated lexicons from thesauri with 76K entries. Phrase length 1 2 3 # of phrases 37,449 108,631 27,822 Phrase length 4 5 6 7 8 9 # of phrases 3,489 598 71 29 4 1 Table 2: Number of phrases by phrase length in lexicon built from the web. Perhaps the most interesting characteristic of the lexicon is that the most frequent phrase length is 2 and not 1. The primary reason for this is an abundance of adjective phrases consisting of an adverb and an adjective, such as “more brittle” and “less brittle”. Almost every adjective of length 1 is frequently combined in such a way on the web, so it not </context>
</contexts>
<marker>Mohammad, Dorr, Dunne, 2009</marker>
<rawString>S. Mohammad, B. Dorr, and C. Dunne. 2009. Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="1628" citStr="Pang et al. (2002)" startWordPosition="236" endWordPosition="239">luate a lexicon derived from English documents, both qualitatively and quantitatively, and show that it provides superior performance to previously studied lexicons, including one derived from WordNet. 1 Introduction Polarity lexicons are large lists of phrases that encode the polarity of each phrase within it – either positive or negative – often with some score representing the magnitude of the polarity (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Turney, 2002). Though classifiers built with machine learning algorithms have become commonplace in the sentiment analysis literature, e.g., Pang et al. (2002), the core of many academic and commercial sentiment analysis systems remains the polarity lexicon, which can be constructed manually (Das and Chen, 2007), through heuristics (Kim and Hovy, 2004; Esuli and Sabastiani, 2009) or using machine learning (Turney, 2002; Rao and Ravichandran, 2009). Often lexicons are combined with machine learning for improved results (Wilson et al., 2005). The pervasiveness and sustained use of lexicons can be ascribed to a number of reasons, including their interpretability in large-scale systems as well as the granularity of their analysis. In this work we invest</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>E Crestan</author>
<author>A Borkovsky</author>
<author>A Popescu</author>
<author>V Vyas</author>
</authors>
<title>Web-scale distributional similarity and entity set expansion.</title>
<date>2009</date>
<booktitle>In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="9847" citStr="Pantel et al., 2009" startWordPosition="1644" endWordPosition="1647">arity lexicons have used linguistic resources like WordNet to define the graph through synonym and antonym relations (Kim and Hovy, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). The goal of this study is to examine the size and quality of polarity lexicons when the graph is induced automatically from documents on the web. Constructing a graph from web-computed lexical co-occurrence statistics is a difficult challenge in and of itself and the research and implementation hurdles that arise are beyond the scope of this work (Alfonseca et al., 2009; Pantel et al., 2009). For this study, we used an English graph where the node set V was based on all n-grams up to length 10 extracted from 4 billion web pages. This list was filtered to 20 million candidate phrases using a number of heuristics including frequency and mutual information of word boundaries. A context vector for each candidate phrase was then constructed based on a window of size six aggregated over all mentions of the phrase in the 4 billion documents. The edge set E was constructed by first, for each potential edge (vi, vj), computing the cosine similarity value between context vectors. All edges</context>
</contexts>
<marker>Pantel, Crestan, Borkovsky, Popescu, Vyas, 2009</marker>
<rawString>P. Pantel, E. Crestan, A. Borkovsky, A. Popescu, and V. Vyas. 2009. Web-scale distributional similarity and entity set expansion. In Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Rao</author>
<author>D Ravichandran</author>
</authors>
<title>Semi-Supervised Polarity Lexicon Induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="1920" citStr="Rao and Ravichandran, 2009" startWordPosition="281" endWordPosition="284">ity of each phrase within it – either positive or negative – often with some score representing the magnitude of the polarity (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Turney, 2002). Though classifiers built with machine learning algorithms have become commonplace in the sentiment analysis literature, e.g., Pang et al. (2002), the core of many academic and commercial sentiment analysis systems remains the polarity lexicon, which can be constructed manually (Das and Chen, 2007), through heuristics (Kim and Hovy, 2004; Esuli and Sabastiani, 2009) or using machine learning (Turney, 2002; Rao and Ravichandran, 2009). Often lexicons are combined with machine learning for improved results (Wilson et al., 2005). The pervasiveness and sustained use of lexicons can be ascribed to a number of reasons, including their interpretability in large-scale systems as well as the granularity of their analysis. In this work we investigate the viability of polarity lexicons that are derived solely from unlabeled web documents. We propose a method based on graph propagation algorithms inspired by previous work on constructing polarity lexicons from lexical graphs (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani</context>
<context position="5762" citStr="Rao and Ravichandran, 2009" startWordPosition="881" endWordPosition="884">n Kaji and Kitsuregawa (2007). Though this hypothesis is not tested here, it also makes our techniques more amenable to adaptation for other languages. 2 Constructing the Lexicon In this section we describe a method to construct polarity lexicons using graph propagation over a phrase similarity graph constructed from the web. 2.1 Graph Propagation Algorithm We construct our lexicon using graph propagation techniques, which have previously been investigated in the construction of polarity lexicons (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). We assume as input an undirected edge weighted graph G = (V, E), where wij E [0, 1] is the weight of edge (vi, vj) E E. The node set V is the set of candidate phrases for inclusion in a sentiment lexicon. In practice, G should encode semantic similarities between two nodes, e.g., for sentiment analysis one would hope that wij &gt; wik if vi=good, vj=great and vk=bad. We also assume as input two sets of seed phrases, denoted P for the positive seed set and N for the negative seed set. The common property among all graph propagation algorithms is that they attempt to propagate information from th</context>
<context position="9451" citStr="Rao and Ravichandran, 2009" startWordPosition="1576" endWordPosition="1579">uded in the lexicon. Both T and y were tuned on held-out data. To construct the final lexicon, the remaining nodes – those with polarity scores above y – are extracted and assigned their corresponding polarity. 2.2 Building a Phrase Graph from the Web Graph propagation algorithms rely on the existence of graphs that encode meaningful relationships between candidate nodes. Past studies on building polarity lexicons have used linguistic resources like WordNet to define the graph through synonym and antonym relations (Kim and Hovy, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). The goal of this study is to examine the size and quality of polarity lexicons when the graph is induced automatically from documents on the web. Constructing a graph from web-computed lexical co-occurrence statistics is a difficult challenge in and of itself and the research and implementation hurdles that arise are beyond the scope of this work (Alfonseca et al., 2009; Pantel et al., 2009). For this study, we used an English graph where the node set V was based on all n-grams up to length 10 extracted from 4 billion web pages. This list was filtered to 20 million candidate phrases using a </context>
<context position="11859" citStr="Rao and Ravichandran (2009)" startWordPosition="1985" endWordPosition="1988">code semantic as opposed to syntactic similarities. We note, however, that the graph propagation algorithm described above calculates the sentiment of each phrase as the aggregate of all the best paths to seed words. Thus, even if some local edges are erroneous in the graph, one hopes that, globally, positive phrases will be influenced more by paths from positive seed words as opposed to negative seed words. Section 3, and indeed this paper, aims to measure whether this is true or not. 2.3 Why Not Label Propagation? Previous studies on constructing polarity lexicons from lexical graphs, e.g., Rao and Ravichandran (2009), have used the label propagation algorithm, which takes the form in Figure 2 (Zhu and Ghahramani, 2002). Label propagation is an iterative algorithm where each node takes on the weighted average of its neighbour’s values from the previous iteration. The result is that nodes with many paths to seeds get high polarities due to the influence from their neighbours. The label propagation algorithm is known to have many desirable properties including convergence, a well defined objective function 779 Input: G = (V, E), wig ∈ [0, 1], P, N Output: pol ∈ R|V | Initialize: poli = 1.0 for all vi ∈ P and</context>
</contexts>
<marker>Rao, Ravichandran, 2009</marker>
<rawString>D. Rao and D. Ravichandran. 2009. Semi-Supervised Polarity Lexicon Induction. In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>J Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="15758" citStr="Riloff and Wiebe (2003)" startWordPosition="2659" endWordPosition="2662">ained 178,104 entries. Depending on the threshold -y (see Figure 1), this lexicon could be larger or smaller. As stated earlier, our selection of -y and all hyperparameters was based on manual inspection of the resulting lexicons and performance on held-out data. In the rest of this section we investigate the properties of this lexicon to understand both its general characteristics as well as its possible utility in sentiment applications. To this end we compare three different lexicons: 1. Wilson et al.: Described in Wilson et al. (2005). Lexicon constructed by combining the lexicon built in Riloff and Wiebe (2003) with other sources1. Entries are are coarsely rated – strong/weak positive/negative – which we weighted as 1.0, 0.5, -0.5, and -1.0 for our experiments. 2. WordNet LP: Described in Blair-Goldensohn et al. (2008). Constructed using label propagation over a graph derived from WordNet synonym and antonym links. Note that label propagation is not prone to the kinds of errors discussed in Section 2.3 since the lexical graph is derived from a high quality source. 3. Web GP: The web-derived lexicon described in Section 2.1 and Section 2.2. 1See http://www.cs.pitt.edu/mpqa/ 780 3.1 Qualitative Evalua</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>E. Riloff and J. Wiebe. 2003. Learning extraction patterns for subjective expressions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Thumbs up or thumbs down? Sentiment orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="1482" citStr="Turney, 2002" startWordPosition="217" endWordPosition="218">specific word classes – e.g., adjectives that occur in WordNet – and in fact contains slang, misspellings, multiword expressions, etc. We evaluate a lexicon derived from English documents, both qualitatively and quantitatively, and show that it provides superior performance to previously studied lexicons, including one derived from WordNet. 1 Introduction Polarity lexicons are large lists of phrases that encode the polarity of each phrase within it – either positive or negative – often with some score representing the magnitude of the polarity (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Turney, 2002). Though classifiers built with machine learning algorithms have become commonplace in the sentiment analysis literature, e.g., Pang et al. (2002), the core of many academic and commercial sentiment analysis systems remains the polarity lexicon, which can be constructed manually (Das and Chen, 2007), through heuristics (Kim and Hovy, 2004; Esuli and Sabastiani, 2009) or using machine learning (Turney, 2002; Rao and Ravichandran, 2009). Often lexicons are combined with machine learning for improved results (Wilson et al., 2005). The pervasiveness and sustained use of lexicons can be ascribed to</context>
<context position="3059" citStr="Turney, 2002" startWordPosition="463" endWordPosition="464">lexical graphs (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). Whereas past efforts have used linguistic resources – e.g., WordNet – to construct the lexical graph over which propagation runs, our lexicons are constructed using a graph built from co-occurrence statistics from the entire web. Thus, the method we investigate can be seen as a combination of methods for propagating sentiment across lexical graphs and methods for building sentiment lexicons based on distributional characteristics of phrases in raw data (Turney, 2002). The advantage of breaking the dependence on WordNet (or related resources like thesauri (Mohammad et al., 2009)) is that it allows the lexicons to include non-standard entries, most notably spelling mistakes and variations, slang, and multiword expressions. The primary goal of our study is to understand the characteristics and practical usefulness of such a lexicon. Towards this end, we provide both a qualitative and quantitative analysis for a web-derived English 777 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 777–785, Los Angeles,</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>P. Turney. 2002. Thumbs up or thumbs down? Sentiment orientation applied to unsupervised classification of reviews. In Proceedings of the Annual Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
</authors>
<title>Learning subjective adjectives from corpora.</title>
<date>2000</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence (AAAI).</booktitle>
<contexts>
<context position="1467" citStr="Wiebe, 2000" startWordPosition="215" endWordPosition="216">t limited to specific word classes – e.g., adjectives that occur in WordNet – and in fact contains slang, misspellings, multiword expressions, etc. We evaluate a lexicon derived from English documents, both qualitatively and quantitatively, and show that it provides superior performance to previously studied lexicons, including one derived from WordNet. 1 Introduction Polarity lexicons are large lists of phrases that encode the polarity of each phrase within it – either positive or negative – often with some score representing the magnitude of the polarity (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Turney, 2002). Though classifiers built with machine learning algorithms have become commonplace in the sentiment analysis literature, e.g., Pang et al. (2002), the core of many academic and commercial sentiment analysis systems remains the polarity lexicon, which can be constructed manually (Das and Chen, 2007), through heuristics (Kim and Hovy, 2004; Esuli and Sabastiani, 2009) or using machine learning (Turney, 2002; Rao and Ravichandran, 2009). Often lexicons are combined with machine learning for improved results (Wilson et al., 2005). The pervasiveness and sustained use of lexicons can</context>
</contexts>
<marker>Wiebe, 2000</marker>
<rawString>J. Wiebe. 2000. Learning subjective adjectives from corpora. In Proceedings of the National Conference on Artificial Intelligence (AAAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>P Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="2014" citStr="Wilson et al., 2005" startWordPosition="295" endWordPosition="298">agnitude of the polarity (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Turney, 2002). Though classifiers built with machine learning algorithms have become commonplace in the sentiment analysis literature, e.g., Pang et al. (2002), the core of many academic and commercial sentiment analysis systems remains the polarity lexicon, which can be constructed manually (Das and Chen, 2007), through heuristics (Kim and Hovy, 2004; Esuli and Sabastiani, 2009) or using machine learning (Turney, 2002; Rao and Ravichandran, 2009). Often lexicons are combined with machine learning for improved results (Wilson et al., 2005). The pervasiveness and sustained use of lexicons can be ascribed to a number of reasons, including their interpretability in large-scale systems as well as the granularity of their analysis. In this work we investigate the viability of polarity lexicons that are derived solely from unlabeled web documents. We propose a method based on graph propagation algorithms inspired by previous work on constructing polarity lexicons from lexical graphs (Kim and Hovy, 2004; Hu and Liu, 2004; Esuli and Sabastiani, 2009; Blair-Goldensohn et al., 2008; Rao and Ravichandran, 2009). Whereas past efforts have </context>
<context position="3828" citStr="Wilson et al. (2005)" startWordPosition="577" endWordPosition="580">include non-standard entries, most notably spelling mistakes and variations, slang, and multiword expressions. The primary goal of our study is to understand the characteristics and practical usefulness of such a lexicon. Towards this end, we provide both a qualitative and quantitative analysis for a web-derived English 777 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 777–785, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics lexicon relative to two previously published lexicons – the lexicon used in Wilson et al. (2005) and the lexicon used in Blair-Goldensohn et al. (2008). Our experiments show that a web-derived lexicon is not only significantly larger, but has improved accuracy on a sentence polarity classification task, which is an important problem in many sentiment analysis applications, including sentiment aggregation and summarization (Hu and Liu, 2004; Carenini et al., 2006; Lerman et al., 2009). These results hold true both when the lexicons are used in conjunction with string matching to classify sentences, and when they are included within a contextual classifier framework (Wilson et al., 2005). </context>
<context position="15679" citStr="Wilson et al. (2005)" startWordPosition="2647" endWordPosition="2650">oot, e.g., excel/excels/excelled. The algorithm produced a lexicon that contained 178,104 entries. Depending on the threshold -y (see Figure 1), this lexicon could be larger or smaller. As stated earlier, our selection of -y and all hyperparameters was based on manual inspection of the resulting lexicons and performance on held-out data. In the rest of this section we investigate the properties of this lexicon to understand both its general characteristics as well as its possible utility in sentiment applications. To this end we compare three different lexicons: 1. Wilson et al.: Described in Wilson et al. (2005). Lexicon constructed by combining the lexicon built in Riloff and Wiebe (2003) with other sources1. Entries are are coarsely rated – strong/weak positive/negative – which we weighted as 1.0, 0.5, -0.5, and -1.0 for our experiments. 2. WordNet LP: Described in Blair-Goldensohn et al. (2008). Constructed using label propagation over a graph derived from WordNet synonym and antonym links. Note that label propagation is not prone to the kinds of errors discussed in Section 2.3 since the lexical graph is derived from a high quality source. 3. Web GP: The web-derived lexicon described in Section 2.</context>
<context position="16940" citStr="Wilson et al. (2005)" startWordPosition="2858" endWordPosition="2861">t.edu/mpqa/ 780 3.1 Qualitative Evaluation Table 1 breaks down the lexicon by the number of positive and negative entries of each lexicon, which clearly shows that the lexicon derived from the web is more than an order of magnitude larger than previously constructed lexicons.2 This in and of itself is not much of an achievement if the additional phrases are of poor quality. However, in Section 3.2 we present an empirical evaluation that suggests that these terms provide both additional and useful information. Table 1 also shows the recall of the each lexicon relative to the other. Whereas the Wilson et al. (2005) and WordNet lexicon have a recall of only 3% relative to the web lexicon, the web lexicon has a recall of 48% and 70% relative to the two other lexicons, indicating that it contains a significant amount of information from the other lexicons. However, this overlap is still small, suggesting that a combination of all the lexicons could provide the best performance. In Section 3.2 we investigate this empirically through a meta classification system. Table 2 shows the distribution of phrases in the web-derived lexicon relative to the number of tokens in each phrase. Here a token is simply define</context>
<context position="21195" citStr="Wilson et al. (2005)" startWordPosition="3593" endWordPosition="3596">e far more prominent than for negative phrases. Many of these correspond to social media text where one expresses an increased level of sentiment by repeating characters. The second is vulgarity in negative phrases, which was far more prominent than for positive phrases. Some of these are clearly appropri781 Recall wrt other lexicons All Phrases Pos. Phrases Neg. Phrases Wilson et al. WordNet LP Web GP Wilson et al. 7,628 2,718 4,910 100% 37% 2% WordNet LP 12,310 5,705 6,605 21% 100% 3% Web GP 178,104 90,337 87,767 70% 48% 100% Table 1: Lexicon statistics. Wilson et al. is the lexicon used in Wilson et al. (2005), WordNet LP is the lexicon constructed by Blair-Goldensohn et al. (2008) that uses label propagation algorithms over a graph constructed through WordNet, and Web GP is the web-derived lexicon from this study. POSITIVE PHRASES NEGATIVE PHRASES Typical Multiword expressions Spelling variations Typical Multiword expressions Vulgarity cute once in a life time loveable dirty run of the mill fucking stupid fabulous state - of - the - art nicee repulsive out of touch fucked up cuddly fail - safe operation niice crappy over the hill complete bullshit plucky just what the doctor ordered cooool sucky f</context>
<context position="27598" citStr="Wilson et al., 2005" startWordPosition="4707" endWordPosition="4710">ng purity to classify sentences – as opposed to the voteflip algorithm, which only provides an unweighted classification – we can see that at almost all recall levels the web-derived lexicon has superior precision to the other lexicons (Figure 4). Thus, even though the web-derived lexicon is constructed from a lexical graph that contains noise, the graph propagation algorithms appear to be fairly robust to this noise and are capable of producing large and accurate polarity lexicons. The second six columns of Table 4 shows the performance of each lexicon as the core of a contextual classifier (Wilson et al., 2005). A contextual classifier is a machine learned classifier that predicts the polarity of a sentence using features of that sentence and its context. For our experiments, this was a maximum entropy classifier trained and evaluated using 10-fold cross-validation on the evaluation data. The features included in the classifier were the purity score, the number of positive and negative lexicon matches, and the number of negations in the sentence, as well as concatenations of these features within the sentence and with the same features derived from the sentences in a window of size 1. For each sente</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>Z Ghahramani</author>
</authors>
<title>Learning from labeled and unlabeled data with label propagation.</title>
<date>2002</date>
<tech>Technical report, CMU CALD tech report CMU-CALD-02.</tech>
<contexts>
<context position="11963" citStr="Zhu and Ghahramani, 2002" startWordPosition="2002" endWordPosition="2006"> described above calculates the sentiment of each phrase as the aggregate of all the best paths to seed words. Thus, even if some local edges are erroneous in the graph, one hopes that, globally, positive phrases will be influenced more by paths from positive seed words as opposed to negative seed words. Section 3, and indeed this paper, aims to measure whether this is true or not. 2.3 Why Not Label Propagation? Previous studies on constructing polarity lexicons from lexical graphs, e.g., Rao and Ravichandran (2009), have used the label propagation algorithm, which takes the form in Figure 2 (Zhu and Ghahramani, 2002). Label propagation is an iterative algorithm where each node takes on the weighted average of its neighbour’s values from the previous iteration. The result is that nodes with many paths to seeds get high polarities due to the influence from their neighbours. The label propagation algorithm is known to have many desirable properties including convergence, a well defined objective function 779 Input: G = (V, E), wig ∈ [0, 1], P, N Output: pol ∈ R|V | Initialize: poli = 1.0 for all vi ∈ P and poli = −1.0 for all vi ∈ N and poli = 0.0 ∀vi ∈� P ∪ N 1. for: t .. T r- (�i, vj) EE w*j XPolj 2. poli </context>
</contexts>
<marker>Zhu, Ghahramani, 2002</marker>
<rawString>X. Zhu and Z. Ghahramani. 2002. Learning from labeled and unlabeled data with label propagation. Technical report, CMU CALD tech report CMU-CALD-02.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>