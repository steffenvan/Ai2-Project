<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001118">
<title confidence="0.989251">
An Open-Source Package for Recognizing Textual Entailment
</title>
<author confidence="0.554087">
Milen Kouylekov and Matteo Negri
</author>
<address confidence="0.431752">
FBK - Fondazione Bruno Kessler
Via Sommarive 18, 38100 Povo (TN), Italy
</address>
<email confidence="0.979648">
[kouylekov,negri]@fbk.eu
</email>
<sectionHeader confidence="0.997131" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999979285714286">
This paper presents a general-purpose
open source package for recognizing Tex-
tual Entailment. The system implements a
collection of algorithms, providing a con-
figurable framework to quickly set up a
working environment to experiment with
the RTE task. Fast prototyping of new
solutions is also allowed by the possibil-
ity to extend its modular architecture. We
present the tool as a useful resource to ap-
proach the Textual Entailment problem, as
an instrument for didactic purposes, and as
an opportunity to create a collaborative en-
vironment to promote research in the field.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.987415661016949">
Textual Entailment (TE) has been proposed as
a unifying generic framework for modeling lan-
guage variability and semantic inference in dif-
ferent Natural Language Processing (NLP) tasks.
The Recognizing Textual Entailment (RTE) task
(Dagan and Glickman, 2007) consists in deciding,
given two text fragments (respectively called Text
- T, and Hypothesis - H), whether the meaning of
H can be inferred from the meaning of T, as in:
T: ”Yahoo acquired Overture”
H: ”Yahoo owns Overture”
The RTE problem is relevant for many different
areas of text processing research, since it repre-
sents the core of the semantic-oriented inferences
involved in a variety of practical NLP applications
including Question Answering, Information Re-
trieval, Information Extraction, Document Sum-
marization, and Machine Translation. However, in
spite of the great potential of integrating RTE into
complex NLP architectures, little has been done
to actually move from the controlled scenario pro-
posed by the RTE evaluation campaigns1 to more
practical applications. On one side, current RTE
technology might not be mature enough to provide
reliable components for such integration. Due to
the intrinsic complexity of the problem, in fact,
state of the art results still show large room for im-
provement. On the other side, the lack of available
tools makes experimentation with the task, and the
fast prototyping of new solutions, particularly dif-
ficult. To the best of our knowledge, the broad
literature describing RTE systems is not accompa-
nied with a corresponding effort on making these
systems open-source, or at least freely available.
We believe that RTE research would significantly
benefit from such availability, since it would allow
to quickly set up a working environment for ex-
periments, encourage participation of newcomers,
and eventually promote state of the art advances.
The main contribution of this paper is to present
the latest release of EDITS (Edit Distance Textual
Entailment Suite), a freely available, open source
software package for recognizing Textual Entail-
ment. The system has been designed following
three basic requirements:
Modularity. System architecture is such that the
overall processing task is broken up into major
modules. Modules can be composed through a
configuration file, and extended as plug-ins ac-
cording to individual requirements. System’s
workflow, the behavior of the basic components,
and their IO formats are described in a compre-
hensive documentation available upon download.
Flexibility. The system is general-purpose, and
suited for any TE corpus provided in a simple
XML format. In addition, both language depen-
dent and language independent configurations are
allowed by algorithms that manipulate different
representations of the input data.
</bodyText>
<footnote confidence="0.997064">
1TAC RTE Challenge: http://www.nist.gov/tac
EVALITA TE task: http://evalita.itc.it
</footnote>
<page confidence="0.98528">
42
</page>
<note confidence="0.885477">
Proceedings of the ACL 2010 System Demonstrations, pages 42–47,
Uppsala, Sweden, 13 July 2010. c�2010 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9779885">
Figure 1: Entailment Engine, main components
and workflow
</figureCaption>
<bodyText confidence="0.993242428571429">
Adaptability. Modules can be tuned over train-
ing data to optimize performance along several di-
mensions (e.g. overall Accuracy, Precision/Recall
trade-off on YES and NO entailment judgements).
In addition, an optimization component based on
genetic algorithms is available to automatically set
parameters starting from a basic configuration.
EDITS is open source, and available under
GNU Lesser General Public Licence (LGPL). The
tool is implemented in Java, it runs on Unix-based
Operating Systems, and has been tested on MAC
OSX, Linux, and Sun Solaris. The latest release
of the package can be downloaded from http:
//edits.fbk.eu.
</bodyText>
<sectionHeader confidence="0.964102" genericHeader="method">
2 System Overview
</sectionHeader>
<bodyText confidence="0.992506">
The EDITS package allows to:
</bodyText>
<listItem confidence="0.9901611">
• Create an Entailment Engine (Figure 1) by
defining its basic components (i.e. algo-
rithms, cost schemes, rules, and optimizers);
• Train such Entailment Engine over an anno-
tated RTE corpus (containing T-H pairs anno-
tated in terms of entailment) to learn a Model;
• Use the Entailment Engine and the Model to
assign an entailment judgement and a confi-
dence score to each pair of an un-annotated
test corpus.
</listItem>
<bodyText confidence="0.997658333333334">
EDITS implements a distance-based framework
which assumes that the probability of an entail-
ment relation between a given T-H pair is inversely
proportional to the distance between T and H (i.e.
the higher the distance, the lower is the probability
of entailment). Within this framework the system
implements and harmonizes different approaches
to distance computation, providing both edit dis-
tance algorithms, and similarity algorithms (see
Section 3.1). Each algorithm returns a normalized
distance score (a number between 0 and 1). At a
training stage, distance scores calculated over an-
notated T-H pairs are used to estimate a threshold
that best separates positive from negative exam-
ples. The threshold, which is stored in a Model, is
used at a test stage to assign an entailment judge-
ment and a confidence score to each test pair.
In the creation of a distance Entailment Engine,
algorithms are combined with cost schemes (see
Section 3.2) that can be optimized to determine
their behaviour (see Section 3.3), and optional ex-
ternal knowledge represented as rules (see Section
3.4). Besides the definition of a single Entailment
Engine, a unique feature of EDITS is that it al-
lows for the combination of multiple Entailment
Engines in different ways (see Section 4.4).
Pre-defined basic components are already pro-
vided with EDITS, allowing to create a variety of
entailment engines. Fast prototyping of new solu-
tions is also allowed by the possibility to extend
the modular architecture of the system with new
algorithms, cost schemes, rules, or plug-ins to new
language processing components.
</bodyText>
<sectionHeader confidence="0.978967" genericHeader="method">
3 Basic Components
</sectionHeader>
<bodyText confidence="0.99926725">
This section overviews the main components of
a distance Entailment Engine, namely: i) algo-
rithms, iii) cost schemes, iii) the cost optimizer,
and iv) entailment/contradiction rules.
</bodyText>
<subsectionHeader confidence="0.996504">
3.1 Algorithms
</subsectionHeader>
<bodyText confidence="0.9998820625">
Algorithms are used to compute a distance score
between T-H pairs.
EDITS provides a set of predefined algorithms,
including edit distance algorithms, and similar-
ity algorithms adapted to the proposed distance
framework. The choice of the available algorithms
is motivated by their large use documented in RTE
literature2.
Edit distance algorithms cast the RTE task as
the problem of mapping the whole content of H
into the content of T. Mappings are performed
as sequences of editing operations (i.e. insertion,
deletion, substitution of text portions) needed to
transform T into H, where each edit operation has
a cost associated with it. The distance algorithms
available in the current release of the system are:
</bodyText>
<footnote confidence="0.936823333333333">
2Detailed descriptions of all the systems participating in
the TAC RTE Challenge are available at http://www.
nist.gov/tac/publications
</footnote>
<page confidence="0.999152">
43
</page>
<listItem confidence="0.922605333333333">
• Token Edit Distance: a token-based version
of the Levenshtein distance algorithm, with
edit operations defined over sequences of to-
kens of T and H;
• Tree Edit Distance: an implementation of the
algorithm described in (Zhang and Shasha,
1990), with edit operations defined over sin-
gle nodes of a syntactic representation of T
and H.
</listItem>
<bodyText confidence="0.995316272727273">
Similarity algorithms are adapted to the ED-
ITS distance framework by transforming measures
of the lexical/semantic similarity between T and H
into distance measures. These algorithms are also
adapted to use the three edit operations to support
overlap calculation, and define term weights. For
instance, substitutable terms in T and H can be
treated as equal, and non-overlapping terms can be
weighted proportionally to their insertion/deletion
costs. Five similarity algorithms are available,
namely:
</bodyText>
<listItem confidence="0.9979285">
• Word Overlap: computes an overall (dis-
tance) score as the proportion of common
words in T and H;
• Jaro-Winkler distance: a similarity algorithm
between strings, adapted to similarity on
words;
• Cosine Similarity: a common vector-based
similarity measure;
• Longest Common Subsequence: searches the
longest possible sequence of words appearing
both in T and H in the same order, normaliz-
ing its length by the length of H;
• Jaccard Coefficient: confronts the intersec-
tion of words in T and H to their union.
</listItem>
<subsectionHeader confidence="0.999685">
3.2 Cost Schemes
</subsectionHeader>
<bodyText confidence="0.999970363636364">
Cost schemes are used to define the cost of each
edit operation.
Cost schemes are defined as XML files that ex-
plicitly associate a cost (a positive real number) to
each edit operation applied to elements of T and
H. Elements, referred to as A and B, can be of dif-
ferent types, depending on the algorithm used. For
instance, Tree Edit Distance will manipulate nodes
in a dependency tree representation, whereas To-
ken Edit Distance and similarity algorithms will
manipulate words. Figure 2 shows an example of
</bodyText>
<figure confidence="0.999238583333333">
&lt;scheme&gt;
&lt;insertion&gt;&lt;cost&gt;10&lt;/cost&gt;&lt;/insertion&gt;
&lt;deletion&gt;&lt;cost&gt;10&lt;/cost&gt;&lt;/deletion&gt;
&lt;substitution&gt;
&lt;condition&gt;(equals A B)&lt;/condition&gt;
&lt;cost&gt;0&lt;/cost&gt;
&lt;/substitution&gt;
&lt;substitution&gt;
&lt;condition&gt;(not (equals A B))&lt;/condition&gt;
&lt;cost&gt;20&lt;/cost&gt;
&lt;/substitution&gt;
&lt;/scheme&gt;
</figure>
<figureCaption confidence="0.999977">
Figure 2: Example of XML Cost Scheme
</figureCaption>
<bodyText confidence="0.980994666666667">
cost scheme, where edit operation costs are de-
fined as follows:
Insertion(B)=10 - inserting an element B from H
to T, no matter what B is, always costs 10;
Deletion(A)=10 - deleting an element A from T,
no matter what A is, always costs 10;
</bodyText>
<equation confidence="0.851823333333333">
substitution(A,B)=0 if A=B - substituting A with
B costs 0 if A and B are equal;
substitution(A,B)=20 if ASB - substituting A
</equation>
<bodyText confidence="0.989116294117647">
with B costs 20 if A and B are different.
In the distance-based framework adopted by
EDITS, the interaction between algorithms and
cost schemes plays a central role. Given a T-H
pair, in fact, the distance score returned by an al-
gorithm directly depends on the cost of the opera-
tions applied to transform T into H (edit distance
algorithms), or on the cost of mapping words in
H with words in T (similarity algorithms). Such
interaction determines the overall behaviour of an
Entailment Engine, since distance scores returned
by the same algorithm with different cost schemes
can be considerably different. This allows users to
define (and optimize, as explained in Section 3.3)
the cost schemes that best suit the RTE data they
want to model3.
EDITS provides two predefined cost schemes:
</bodyText>
<listItem confidence="0.998407111111111">
• Simple Cost Scheme - the one shown in Fig-
ure 2, setting fixed costs for each edit opera-
tion.
• IDF Cost Scheme - insertion and deletion
costs for a word w are set to the inverse doc-
ument frequency of w (IDF(w)). The sub-
stitution cost is set to 0 if a word w1 from
T and a word w2 from H are the same, and
IDF(w1)+IDF(w2) otherwise.
</listItem>
<footnote confidence="0.975001">
3For instance, when dealing with T-H pairs composed by
texts that are much longer than the hypotheses (as in the RTE5
Campaign), setting low deletion costs avoids penalization to
short Hs fully contained in the Ts.
</footnote>
<page confidence="0.99878">
44
</page>
<bodyText confidence="0.999970076923077">
In the creation of new cost schemes, users can
express edit operation costs, and conditions over
the A and B elements, using a meta-language
based on a lisp-like syntax (e.g. (+ (IDF A) (IDF
B)), (not (equals A B))). The system also provides
functions to access data stored in hash files. For
example, the IDF Cost Scheme accesses the IDF
values of the most frequent 100K English words
(calculated on the Brown Corpus) stored in a file
distributed with the system. Users can create new
hash files to collect statistics about words in other
languages, or other information to be used inside
the cost scheme.
</bodyText>
<subsectionHeader confidence="0.999744">
3.3 Cost Optimizer
</subsectionHeader>
<bodyText confidence="0.999959636363636">
A cost optimizer is used to adapt cost schemes (ei-
ther those provided with the system, or new ones
defined by the user) to specific datasets.
The optimizer is based on cost adaptation
through genetic algorithms, as proposed in
(Mehdad, 2009). To this aim, cost schemes can
be parametrized by externalizing as parameters the
edit operations costs. The optimizer iterates over
training data using different values of these param-
eters until on optimal set is found (i.e. the one that
best performs on the training set).
</bodyText>
<subsectionHeader confidence="0.942902">
3.4 Rules
</subsectionHeader>
<bodyText confidence="0.999446578947368">
Rules are used to provide the Entailment Engine
with knowledge (e.g. lexical, syntactic, semantic)
about the probability of entailment or contradic-
tion between elements of T and H. Rules are in-
voked by cost schemes to influence the cost of sub-
stitutions between elements of T and H. Typically,
the cost of the substitution between two elements
A and B is inversely proportional to the probability
that A entails B.
Rules are stored in XML files called Rule
Repositories, with the format shown in Figure 3.
Each rule consists of three parts: i) a left-hand
side, ii) a right-hand side, iii) a probability that
the left-hand side entails (or contradicts) the right-
hand side.
EDITS provides three predefined sets of lexical
entailment rules acquired from lexical resources
widely used in RTE: WordNet4, Lin’s word sim-
ilarity dictionaries5, and VerbOcean6.
</bodyText>
<footnote confidence="0.999286666666667">
4http://wordnet.princeton.edu
5http://webdocs.cs.ualberta.ca/ lindek/downloads.htm
6http://demo.patrickpantel.com/Content/verbocean
</footnote>
<figure confidence="0.9938711">
&lt;rule entailment=&amp;quot;ENTAILMENT&amp;quot;&gt;
&lt;t&gt;acquire&lt;/t&gt;
&lt;h&gt;own&lt;/h&gt;
&lt;probability&gt;0.95&lt;/probability&gt;
&lt;/rule&gt;
&lt;rule entailment=&amp;quot;CONTRADICTION&amp;quot;&gt;
&lt;t&gt;beautiful&lt;/t&gt;
&lt;h&gt;ugly&lt;/h&gt;
&lt;probability&gt;0.88&lt;/probability&gt;
&lt;/rule&gt;
</figure>
<figureCaption confidence="0.999955">
Figure 3: Example of XML Rule Repository
</figureCaption>
<sectionHeader confidence="0.843699" genericHeader="method">
4 Using the System
</sectionHeader>
<bodyText confidence="0.9998818">
This section provides basic information about the
use of EDITS, which can be run with commands
in a Unix Shell. A complete guide to all the pa-
rameters of the main script is available as HTML
documentation downloadable with the package.
</bodyText>
<subsectionHeader confidence="0.877692">
4.1 Input
</subsectionHeader>
<bodyText confidence="0.999912421052632">
The input of the system is an entailment corpus
represented in the EDITS Text Annotation Format
(ETAF), a simple XML internal annotation for-
mat. ETAF is used to represent both the input T-H
pairs, and the entailment and contradiction rules.
ETAF allows to represent texts at two different
levels: i) as sequences of tokens with their asso-
ciated morpho-syntactic properties, or ii) as syn-
tactic trees with structural relations among nodes.
Plug-ins for several widely used annotation
tools (including TreeTagger, Stanford Parser, and
OpenNLP) can be downloaded from the system’s
website. Users can also extend EDITS by imple-
menting plug-ins to convert the output of other an-
notation tools in ETAF.
Publicly available RTE corpora (RTE 1-3, and
EVALITA 2009), annotated in ETAF at both the
annotation levels, are delivered together with the
system to be used as first experimental datasets.
</bodyText>
<subsectionHeader confidence="0.999754">
4.2 ConÞguration
</subsectionHeader>
<bodyText confidence="0.999959285714286">
The creation of an Entailment Engine is done by
defining its basic components (algorithms, cost
schemes, optimizer, and rules) through an XML
configuration file. The configuration file is divided
in modules, each having a set of options. The fol-
lowing XML fragment represents a simple exam-
ple of configuration file:
</bodyText>
<footnote confidence="0.9671335">
&lt;module alias=&amp;quot;distance&amp;quot;&gt;
&lt;module alias=&amp;quot;tree&amp;quot;/&gt;
&lt;module alias=&amp;quot;xml&amp;quot;&gt;
&lt;option name=&amp;quot;scheme-file&amp;quot;
</footnote>
<page confidence="0.998217">
45
</page>
<figure confidence="0.95456625">
value=&amp;quot;IDF_Scheme.xml&amp;quot;/&gt;
&lt;/module&gt;
&lt;module alias=&amp;quot;pso&amp;quot;/&gt;
&lt;/module&gt;
</figure>
<bodyText confidence="0.932955538461538">
This configuration defines a distance Entailment
Engine that combines Tree Edit Distance as a core
distance algorithm, and the predefined IDF Cost
Scheme that will be optimized on training data
with the Particle Swarm Optimization algorithm
(“pso”) as in (Mehdad, 2009). Adding external
knowledge to an entailment engine can be done by
extending the configuration file with a reference to
a rules file (e.g. “rules.xml”) as follows:
&lt;module alias=&amp;quot;rules&amp;quot;&gt;
&lt;option name=&amp;quot;rules-file&amp;quot;
value=&amp;quot;rules.xml&amp;quot;/&gt;
&lt;/module&gt;
</bodyText>
<subsectionHeader confidence="0.995452">
4.3 Training and Test
</subsectionHeader>
<bodyText confidence="0.999963047619047">
Given a configuration file and an RTE corpus an-
notated in ETAF, the user can run the training
procedure to learn a model. At this stage, ED-
ITS allows to tune performance along several di-
mensions (e.g. overall Accuracy, Precision/Recall
trade-off on YES and/or NO entailment judge-
ments). By default the system maximizes the over-
all accuracy (distinction between YES and NO
pairs). The output of the training phase is a model:
a zip file that contains the learned threshold, the
configuration file, the cost scheme, and the en-
tailment/contradiction rules used to calculate the
threshold. The explicit availability of all this in-
formation in the model allows users to share, repli-
cate and modify experiments7.
Given a model and an un-annotated RTE corpus
as input, the test procedure produces a file con-
taining for each pair: i) the decision of the system
(YES, NO), ii) the confidence of the decision, iii)
the entailment score, iv) the sequence of edit oper-
ations made to calculate the entailment score.
</bodyText>
<subsectionHeader confidence="0.999751">
4.4 Combining Engines
</subsectionHeader>
<bodyText confidence="0.811385833333333">
A relevant feature of EDITS is the possibility to
combine multiple Entailment Engines into a sin-
gle one. This can be done by grouping their def-
initions as sub-modules in the configuration file.
EDITS allows users to define customized combi-
nation strategies, or to use two predefined com-
bination modalities provided with the package,
7Our policy is to publish online the models we use for par-
ticipation in the RTE Challenges. We encourage other users
of EDITS to do the same, thus creating a collaborative envi-
ronment, allow new users to quickly modify working config-
urations, and replicate results.
</bodyText>
<figureCaption confidence="0.999629">
Figure 4: Combined Entailment Engines
</figureCaption>
<bodyText confidence="0.99764275">
namely: i) Linear Combination, and ii) Classi-
fier Combination. The two modalities combine in
different ways the entailment scores produced by
multiple independent engines, and return a final
decision for each T-H pair.
Linear Combination returns an overall entail-
ment score as the weighted sum of the entailment
scores returned by each engine:
</bodyText>
<equation confidence="0.986008666666667">
n
scorecombination = E scorei * weighti (1)
i=0
</equation>
<bodyText confidence="0.999855157894737">
In this formula, weighti is an ad-hoc weight
parameter for each entailment engine. Optimal
weight parameters can be determined using the
same optimization strategy used to optimize the
cost schemes, as described in Section 3.3.
ClassiÞer Combination is similar to the ap-
proach proposed in (Malakasiotis and Androut-
sopoulos, 2007), and is based on using the entail-
ment scores returned by each engine as features to
train a classifier (see Figure 4). To this aim, ED-
ITS provides a plug-in that uses the Weka8 ma-
chine learning workbench as a core. By default
the plug-in uses an SVM classifier, but other Weka
algorithms can be specified as options in the con-
figuration file.
The following configuration file describes a
combination of two engines (i.e. one based on
Tree Edit Distance, the other based on Cosine
Similarity), used to train a classifier with Weka9.
</bodyText>
<figure confidence="0.982421375">
&lt;module alias=&amp;quot;weka&amp;quot;&gt;
&lt;module alias=&amp;quot;distance&amp;quot;&gt;
&lt;module alias=&amp;quot;tree&amp;quot;/&gt;
&lt;module alias=&amp;quot;xml&amp;quot;&gt;
&lt;option name=&amp;quot;scheme-file&amp;quot;
value=&amp;quot;IDF_Scheme.xml&amp;quot;/&gt;
&lt;/module&gt;
&lt;/module&gt;
</figure>
<footnote confidence="0.982853">
8http://www.cs.waikato.ac.nz/ml/weka
9A linear combination can be easily obtained by changing
the alias of the highest-level module (“weka”) into “linear”.
</footnote>
<page confidence="0.999066">
46
</page>
<figure confidence="0.9914054">
&lt;module alias=&amp;quot;distance&amp;quot;&gt;
&lt;module alias=&amp;quot;cosine&amp;quot;/&gt;
&lt;module alias=&amp;quot;IDF_Scheme.xml&amp;quot;/&gt;
&lt;/module&gt;
&lt;/module&gt;
</figure>
<sectionHeader confidence="0.901577" genericHeader="method">
5 Experiments with EDITS
</sectionHeader>
<bodyText confidence="0.990101833333334">
To give an idea of the potentialities of the ED-
ITS package in terms of flexibility and adaptabil-
ity, this section reports some results achieved in
RTE-related tasks by previous versions of the tool.
The system has been tested in different scenarios,
ranging from the evaluation of standalone systems
within task-specific RTE Challenges, to their inte-
gration in more complex architectures.
As regards the RTE Challenges, in the last
years EDITS has been used to participate both in
the PASCAL/TAC RTE Campaigns for the En-
glish language (Mehdad et al., 2009), and in the
EVALITA RTE task for Italian (Cabrio et al.,
2009). In the last RTE-5 Campaign the result
achieved in the traditional “2-way Main task”
(60.17% Accuracy) roughly corresponds to the
performance of the average participating systems
(60.36%). In the “Search” task (which consists in
finding all the sentences that entail a given H in
a given set of documents about a topic) the same
configuration achieved an F1 of 33.44%, rank-
ing 3rd out of eight participants (average score
29.17% F1). In the EVALITA 2009 RTE task,
EDITS ranked first with an overall 71.0% Accu-
racy. To promote the use of EDITS and ease ex-
perimentation, the complete models used to pro-
duce each submitted run can be downloaded with
the system. An improved model obtained with the
current release of EDITS, and trained over RTE-5
data (61.83% Accuracy on the “2-way Main task”
test set), is also available upon download.
As regards application-oriented integrations,
EDITS has been successfully used as a core com-
ponent in a Restricted-Domain Question Answer-
ing system within the EU-Funded QALL-ME
Project10. Within this project, an entailment-based
approach to Relation Extraction has been defined
as the task of checking for the existence of en-
tailment relations between an input question (the
text in RTE parlance), and a set of textual realiza-
tions of domain-specific binary relations (the hy-
potheses in RTE parlance). In recognizing 14 re-
lations relevant in the CINEMA domain present in
a collection of spoken English requests, the system
10http://qallme.fbk.eu
achieved an F1 of 72.9%, allowing to return cor-
rect answers to 83% of 400 test questions (Negri
and Kouylekov, 2009).
</bodyText>
<sectionHeader confidence="0.999495" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999995636363636">
We have presented the first open source package
for recognizing Textual Entailment. The system
offers a modular, flexible, and adaptable working
environment to experiment with the task. In addi-
tion, the availability of pre-defined system config-
urations, tested in the past Evaluation Campaigns,
represents a first contribution to set up a collabo-
rative environment, and promote advances in RTE
research. Current activities are focusing on the de-
velopment of a Graphical User Interface, to further
simplify the use of the system.
</bodyText>
<sectionHeader confidence="0.999506" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99970825">
The research leading to these results has received
funding from the European Community’s Sev-
enth Framework Programme (FP7/2007-2013) un-
der Grant Agreement n. 248531 (CoSyne project).
</bodyText>
<sectionHeader confidence="0.999423" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998097407407407">
Prodromos Malakasiotis and Ion Androutsopoulos
2007. Learning Textual Entailment using SVMs and
String Similarity Measures. Proc. of the ACL ’07
Workshop on Textual Entailment and Paraphrasing.
Ido Dagan and 0ren Glickman 2004. Probabilistic
Textual Entailment: Generic Applied Modeling of
Language Variability. Proc. of the PASCAL Work-
shop on Learning Methods for Text Understanding
and Mining.
Kaizhong Zhang and Dennis Shasha 1990. Fast Al-
gorithm for the Unit Cost Editing Distance Between
Trees. Journal of Algorithms. vol.11.
Yashar Mehdad 2009. Automatic Cost Estimation for
Tree Edit Distance Using Particle Swarm Optimiza-
tion. Proc. of ACL-IJCNLP 2009.
Matteo Negri and Milen Kouylekov 2009. Question
Answering over Structured Data: an Entailment-
Based Approach to Question Analysis. Proc. of
RANLP-2009.
Elena Cabrio, Yashar Mehdad, Matteo Negri, Milen
Kouylekov, and Bernardo Magnini 2009. Rec-
ognizing Textual Entailment for Italian EDITS @
EVALITA 2009 Proc. of EVALITA 2009.
Yashar Mehdad, Matteo Negri, Elena Cabrio, Milen
Kouylekov, and Bernardo Magnini 2009. Recogniz-
ing Textual Entailment for English EDITS @ TAC
2009 To appear in Proceedings of TAC 2009.
</reference>
<page confidence="0.999478">
47
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.229094">
<title confidence="0.999672">An Open-Source Package for Recognizing Textual Entailment</title>
<author confidence="0.855326">Milen Kouylekov</author>
<author confidence="0.855326">Matteo Negri FBK</author>
<address confidence="0.597589">Via Sommarive 18, 38100 Povo (TN), Italy</address>
<email confidence="0.996475">[kouylekov,negri]@fbk.eu</email>
<abstract confidence="0.977091733333333">This paper presents a general-purpose open source package for recognizing Textual Entailment. The system implements a collection of algorithms, providing a conframework to quickly set up a working environment to experiment with the RTE task. Fast prototyping of new solutions is also allowed by the possibility to extend its modular architecture. We present the tool as a useful resource to approach the Textual Entailment problem, as an instrument for didactic purposes, and as an opportunity to create a collaborative ento promote research in the</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Prodromos Malakasiotis</author>
<author>Ion Androutsopoulos</author>
</authors>
<title>Learning Textual Entailment using SVMs and String Similarity Measures.</title>
<date>2007</date>
<booktitle>Proc. of the ACL ’07 Workshop on Textual Entailment and Paraphrasing.</booktitle>
<contexts>
<context position="18444" citStr="Malakasiotis and Androutsopoulos, 2007" startWordPosition="2874" endWordPosition="2878">combine in different ways the entailment scores produced by multiple independent engines, and return a final decision for each T-H pair. Linear Combination returns an overall entailment score as the weighted sum of the entailment scores returned by each engine: n scorecombination = E scorei * weighti (1) i=0 In this formula, weighti is an ad-hoc weight parameter for each entailment engine. Optimal weight parameters can be determined using the same optimization strategy used to optimize the cost schemes, as described in Section 3.3. ClassiÞer Combination is similar to the approach proposed in (Malakasiotis and Androutsopoulos, 2007), and is based on using the entailment scores returned by each engine as features to train a classifier (see Figure 4). To this aim, EDITS provides a plug-in that uses the Weka8 machine learning workbench as a core. By default the plug-in uses an SVM classifier, but other Weka algorithms can be specified as options in the configuration file. The following configuration file describes a combination of two engines (i.e. one based on Tree Edit Distance, the other based on Cosine Similarity), used to train a classifier with Weka9. &lt;module alias=&amp;quot;weka&amp;quot;&gt; &lt;module alias=&amp;quot;distance&amp;quot;&gt; &lt;module alias=&amp;quot;tree</context>
</contexts>
<marker>Malakasiotis, Androutsopoulos, 2007</marker>
<rawString>Prodromos Malakasiotis and Ion Androutsopoulos 2007. Learning Textual Entailment using SVMs and String Similarity Measures. Proc. of the ACL ’07 Workshop on Textual Entailment and Paraphrasing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>0ren Glickman</author>
</authors>
<title>Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability.</title>
<date>2004</date>
<booktitle>Proc. of the PASCAL Workshop on Learning Methods for Text Understanding and Mining.</booktitle>
<marker>Dagan, Glickman, 2004</marker>
<rawString>Ido Dagan and 0ren Glickman 2004. Probabilistic Textual Entailment: Generic Applied Modeling of Language Variability. Proc. of the PASCAL Workshop on Learning Methods for Text Understanding and Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kaizhong Zhang</author>
<author>Dennis Shasha</author>
</authors>
<title>Fast Algorithm for the Unit Cost Editing Distance Between Trees.</title>
<date>1990</date>
<journal>Journal of Algorithms.</journal>
<volume>11</volume>
<contexts>
<context position="7855" citStr="Zhang and Shasha, 1990" startWordPosition="1203" endWordPosition="1206">editing operations (i.e. insertion, deletion, substitution of text portions) needed to transform T into H, where each edit operation has a cost associated with it. The distance algorithms available in the current release of the system are: 2Detailed descriptions of all the systems participating in the TAC RTE Challenge are available at http://www. nist.gov/tac/publications 43 • Token Edit Distance: a token-based version of the Levenshtein distance algorithm, with edit operations defined over sequences of tokens of T and H; • Tree Edit Distance: an implementation of the algorithm described in (Zhang and Shasha, 1990), with edit operations defined over single nodes of a syntactic representation of T and H. Similarity algorithms are adapted to the EDITS distance framework by transforming measures of the lexical/semantic similarity between T and H into distance measures. These algorithms are also adapted to use the three edit operations to support overlap calculation, and define term weights. For instance, substitutable terms in T and H can be treated as equal, and non-overlapping terms can be weighted proportionally to their insertion/deletion costs. Five similarity algorithms are available, namely: • Word </context>
</contexts>
<marker>Zhang, Shasha, 1990</marker>
<rawString>Kaizhong Zhang and Dennis Shasha 1990. Fast Algorithm for the Unit Cost Editing Distance Between Trees. Journal of Algorithms. vol.11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
</authors>
<title>Automatic Cost Estimation for Tree Edit Distance Using Particle Swarm Optimization.</title>
<date>2009</date>
<booktitle>Proc. of ACL-IJCNLP</booktitle>
<contexts>
<context position="12362" citStr="Mehdad, 2009" startWordPosition="1950" endWordPosition="1951"> access data stored in hash files. For example, the IDF Cost Scheme accesses the IDF values of the most frequent 100K English words (calculated on the Brown Corpus) stored in a file distributed with the system. Users can create new hash files to collect statistics about words in other languages, or other information to be used inside the cost scheme. 3.3 Cost Optimizer A cost optimizer is used to adapt cost schemes (either those provided with the system, or new ones defined by the user) to specific datasets. The optimizer is based on cost adaptation through genetic algorithms, as proposed in (Mehdad, 2009). To this aim, cost schemes can be parametrized by externalizing as parameters the edit operations costs. The optimizer iterates over training data using different values of these parameters until on optimal set is found (i.e. the one that best performs on the training set). 3.4 Rules Rules are used to provide the Entailment Engine with knowledge (e.g. lexical, syntactic, semantic) about the probability of entailment or contradiction between elements of T and H. Rules are invoked by cost schemes to influence the cost of substitutions between elements of T and H. Typically, the cost of the subs</context>
<context position="15796" citStr="Mehdad, 2009" startWordPosition="2454" endWordPosition="2455">ML configuration file. The configuration file is divided in modules, each having a set of options. The following XML fragment represents a simple example of configuration file: &lt;module alias=&amp;quot;distance&amp;quot;&gt; &lt;module alias=&amp;quot;tree&amp;quot;/&gt; &lt;module alias=&amp;quot;xml&amp;quot;&gt; &lt;option name=&amp;quot;scheme-file&amp;quot; 45 value=&amp;quot;IDF_Scheme.xml&amp;quot;/&gt; &lt;/module&gt; &lt;module alias=&amp;quot;pso&amp;quot;/&gt; &lt;/module&gt; This configuration defines a distance Entailment Engine that combines Tree Edit Distance as a core distance algorithm, and the predefined IDF Cost Scheme that will be optimized on training data with the Particle Swarm Optimization algorithm (“pso”) as in (Mehdad, 2009). Adding external knowledge to an entailment engine can be done by extending the configuration file with a reference to a rules file (e.g. “rules.xml”) as follows: &lt;module alias=&amp;quot;rules&amp;quot;&gt; &lt;option name=&amp;quot;rules-file&amp;quot; value=&amp;quot;rules.xml&amp;quot;/&gt; &lt;/module&gt; 4.3 Training and Test Given a configuration file and an RTE corpus annotated in ETAF, the user can run the training procedure to learn a model. At this stage, EDITS allows to tune performance along several dimensions (e.g. overall Accuracy, Precision/Recall trade-off on YES and/or NO entailment judgements). By default the system maximizes the overall accu</context>
</contexts>
<marker>Mehdad, 2009</marker>
<rawString>Yashar Mehdad 2009. Automatic Cost Estimation for Tree Edit Distance Using Particle Swarm Optimization. Proc. of ACL-IJCNLP 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matteo Negri</author>
<author>Milen Kouylekov</author>
</authors>
<title>Question Answering over Structured Data: an EntailmentBased Approach to Question Analysis.</title>
<date>2009</date>
<booktitle>Proc. of RANLP-2009.</booktitle>
<contexts>
<context position="21646" citStr="Negri and Kouylekov, 2009" startWordPosition="3375" endWordPosition="3378">ring system within the EU-Funded QALL-ME Project10. Within this project, an entailment-based approach to Relation Extraction has been defined as the task of checking for the existence of entailment relations between an input question (the text in RTE parlance), and a set of textual realizations of domain-specific binary relations (the hypotheses in RTE parlance). In recognizing 14 relations relevant in the CINEMA domain present in a collection of spoken English requests, the system 10http://qallme.fbk.eu achieved an F1 of 72.9%, allowing to return correct answers to 83% of 400 test questions (Negri and Kouylekov, 2009). 6 Conclusion We have presented the first open source package for recognizing Textual Entailment. The system offers a modular, flexible, and adaptable working environment to experiment with the task. In addition, the availability of pre-defined system configurations, tested in the past Evaluation Campaigns, represents a first contribution to set up a collaborative environment, and promote advances in RTE research. Current activities are focusing on the development of a Graphical User Interface, to further simplify the use of the system. Acknowledgments The research leading to these results ha</context>
</contexts>
<marker>Negri, Kouylekov, 2009</marker>
<rawString>Matteo Negri and Milen Kouylekov 2009. Question Answering over Structured Data: an EntailmentBased Approach to Question Analysis. Proc. of RANLP-2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Cabrio</author>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Milen Kouylekov</author>
<author>Bernardo Magnini</author>
</authors>
<title>Recognizing Textual Entailment for Italian EDITS @ EVALITA</title>
<date>2009</date>
<booktitle>Proc. of EVALITA</booktitle>
<contexts>
<context position="20048" citStr="Cabrio et al., 2009" startWordPosition="3116" endWordPosition="3119"> To give an idea of the potentialities of the EDITS package in terms of flexibility and adaptability, this section reports some results achieved in RTE-related tasks by previous versions of the tool. The system has been tested in different scenarios, ranging from the evaluation of standalone systems within task-specific RTE Challenges, to their integration in more complex architectures. As regards the RTE Challenges, in the last years EDITS has been used to participate both in the PASCAL/TAC RTE Campaigns for the English language (Mehdad et al., 2009), and in the EVALITA RTE task for Italian (Cabrio et al., 2009). In the last RTE-5 Campaign the result achieved in the traditional “2-way Main task” (60.17% Accuracy) roughly corresponds to the performance of the average participating systems (60.36%). In the “Search” task (which consists in finding all the sentences that entail a given H in a given set of documents about a topic) the same configuration achieved an F1 of 33.44%, ranking 3rd out of eight participants (average score 29.17% F1). In the EVALITA 2009 RTE task, EDITS ranked first with an overall 71.0% Accuracy. To promote the use of EDITS and ease experimentation, the complete models used to pr</context>
</contexts>
<marker>Cabrio, Mehdad, Negri, Kouylekov, Magnini, 2009</marker>
<rawString>Elena Cabrio, Yashar Mehdad, Matteo Negri, Milen Kouylekov, and Bernardo Magnini 2009. Recognizing Textual Entailment for Italian EDITS @ EVALITA 2009 Proc. of EVALITA 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Elena Cabrio</author>
<author>Milen Kouylekov</author>
<author>Bernardo Magnini</author>
</authors>
<title>Recognizing Textual Entailment for</title>
<date>2009</date>
<journal>English EDITS @ TAC</journal>
<booktitle>Proceedings of TAC</booktitle>
<note>To appear in</note>
<contexts>
<context position="19985" citStr="Mehdad et al., 2009" startWordPosition="3104" endWordPosition="3107">&amp;quot;IDF_Scheme.xml&amp;quot;/&gt; &lt;/module&gt; &lt;/module&gt; 5 Experiments with EDITS To give an idea of the potentialities of the EDITS package in terms of flexibility and adaptability, this section reports some results achieved in RTE-related tasks by previous versions of the tool. The system has been tested in different scenarios, ranging from the evaluation of standalone systems within task-specific RTE Challenges, to their integration in more complex architectures. As regards the RTE Challenges, in the last years EDITS has been used to participate both in the PASCAL/TAC RTE Campaigns for the English language (Mehdad et al., 2009), and in the EVALITA RTE task for Italian (Cabrio et al., 2009). In the last RTE-5 Campaign the result achieved in the traditional “2-way Main task” (60.17% Accuracy) roughly corresponds to the performance of the average participating systems (60.36%). In the “Search” task (which consists in finding all the sentences that entail a given H in a given set of documents about a topic) the same configuration achieved an F1 of 33.44%, ranking 3rd out of eight participants (average score 29.17% F1). In the EVALITA 2009 RTE task, EDITS ranked first with an overall 71.0% Accuracy. To promote the use of</context>
</contexts>
<marker>Mehdad, Negri, Cabrio, Kouylekov, Magnini, 2009</marker>
<rawString>Yashar Mehdad, Matteo Negri, Elena Cabrio, Milen Kouylekov, and Bernardo Magnini 2009. Recognizing Textual Entailment for English EDITS @ TAC 2009 To appear in Proceedings of TAC 2009.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>