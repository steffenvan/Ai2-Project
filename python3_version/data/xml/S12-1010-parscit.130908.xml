<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.035524">
<title confidence="0.990045">
Sorting out the Most Confusing English Phrasal Verbs
</title>
<author confidence="0.999359">
Yuancheng Tu Dan Roth
</author>
<affiliation confidence="0.9997275">
Department of Linguistics Department of Computer Science
University of Illinois University of Illinois
</affiliation>
<email confidence="0.999381">
ytu@illinois.edu danr@illinois.edu
</email>
<sectionHeader confidence="0.993914" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999826">
In this paper, we investigate a full-fledged
supervised machine learning framework for
identifying English phrasal verbs in a given
context. We concentrate on those that we de-
fine as the most confusing phrasal verbs, in the
sense that they are the most commonly used
ones whose occurrence may correspond either
to a true phrasal verb or an alignment of a sim-
ple verb with a preposition.
We construct a benchmark dataset1 with 1,348
sentences from BNC, annotated via an Inter-
net crowdsourcing platform. This dataset is
further split into two groups, more idiomatic
group which consists of those that tend to be
used as a true phrasal verb and more compo-
sitional group which tends to be used either
way. We build a discriminative classifier with
easily available lexical and syntactic features
and test it over the datasets. The classifier
overall achieves 79.4% accuracy, 41.1% er-
ror deduction compared to the corpus major-
ity baseline 65%. However, it is even more
interesting to discover that the classifier learns
more from the more compositional examples
than those idiomatic ones.
</bodyText>
<sectionHeader confidence="0.999127" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99398">
Phrasal verbs in English, are syntactically defined
as combinations of verbs and prepositions or parti-
cles, but semantically their meanings are generally
not the direct sum of their parts. For example, give
in means submit, yield in the sentence, Adam’s say-
ing it’s important to stand firm , not give in to ter-
rorists. Adam was not giving anything and he was
</bodyText>
<footnote confidence="0.974644">
1http://cogcomp.cs.illinois.edu/page/resources/PVC Data
</footnote>
<bodyText confidence="0.9990367">
not in anywhere either. (Kolln and Funk, 1998) uses
the test of meaning to detect English phrasal verbs,
i.e., each phrasal verb could be replaced by a single
verb with the same general meaning, for example,
using yield to replace give in in the aforementioned
sentence. To confuse the issue even further, some
phrasal verbs, for example, give in in the follow-
ing two sentences, are used either as a true phrasal
verb (the first sentence) or not (the second sentence)
though their surface forms look cosmetically similar.
</bodyText>
<listItem confidence="0.923543">
1. How many Englishmen gave in to their emo-
tions like that ?
2. It is just this denial of anything beyond what is
directly given in experience that marks Berke-
ley out as an empiricist.
</listItem>
<bodyText confidence="0.9972801">
This paper is targeting to build an automatic learner
which can recognize a true phrasal verb from its
orthographically identical construction with a verb
and a prepositional phrase. Similar to other types
of MultiWord Expressions (MWEs) (Sag et al.,
2002), the syntactic complexity and semantic id-
iosyncrasies of phrasal verbs pose many particular
challenges in empirical Natural Language Process-
ing (NLP). Even though a few of previous works
have explored this identification problem empiri-
cally (Li et al., 2003; Kim and Baldwin, 2009) and
theoretically (Jackendoff, 2002), we argue in this pa-
per that this context sensitive identification problem
is not so easy as conceivably shown before, espe-
cially when it is used to handle those more com-
positional phrasal verbs which are empirically used
either way in the corpus as a true phrasal verb or
a simplex verb with a preposition combination. In
addition, there is still a lack of adequate resources
or benchmark datasets to identify and treat phrasal
</bodyText>
<page confidence="0.998493">
65
</page>
<note confidence="0.528025">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 65–69,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999961555555556">
verbs within a given context. This research is also
an attempt to bridge this gap by constructing a pub-
licly available dataset which focuses on some of the
most commonly used phrasal verbs within their most
confusing contexts.
Our study in this paper focuses on six of the most
frequently used verbs, take, make, have, get, do
and give and their combination with nineteen com-
mon prepositions or particles, such as on, in, up
etc. We categorize these phrasal verbs according to
their continuum of compositionality, splitting them
into two groups based on the biggest gap within
this scale, and build a discriminative learner which
uses easily available syntactic and lexical features to
analyze them comparatively. This learner achieves
79.4% overall accuracy for the whole dataset and
learns the most from the more compositional data
with 51.2% error reduction over its 46.6% baseline.
</bodyText>
<sectionHeader confidence="0.999781" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999831461538461">
Phrasal verbs in English were observed as one kind
of composition that is used frequently and consti-
tutes the greatest difficulty for language learners
more than two hundred and fifty years ago in Samuel
Johnson’s Dictionary of English Language2. They
have also been well-studied in modern linguistics
since early days (Bolinger, 1971; Kolln and Funk,
1998; Jackendoff, 2002). Careful linguistic descrip-
tions and investigations reveal a wide range of En-
glish phrasal verbs that are syntactically uniform,
but diverge largely in semantics, argument struc-
ture and lexical status. The complexity and idiosyn-
crasies of English phrasal verbs also pose a spe-
cial challenge to computational linguistics and at-
tract considerable amount of interest and investi-
gation for their extraction, disambiguation as well
as identification. Recent computational research on
English phrasal verbs have been focused on increas-
ing the coverage and scalability of phrasal verbs by
either extracting unlisted phrasal verbs from large
corpora (Villavicencio, 2003; Villavicencio, 2006),
or constructing productive lexical rules to gener-
ate new cases (Villanvicencio and Copestake, 2003).
Some other researchers follow the semantic regular-
ities of the particles associated with these phrasal
verbs and concentrate on disambiguation of phrasal
</bodyText>
<footnote confidence="0.732313">
2It is written in the Preface of that dictionary.
</footnote>
<bodyText confidence="0.999826678571429">
verb semantics, such as the investigation of the most
common particle up by (Cook and Stevenson, 2006).
Research on token identification of phrasal verbs
is much less compared to the extraction. (Li et
al., 2003) describes a regular expression based sim-
ple system. Regular expression based method re-
quires human constructed regular patterns and can-
not make predictions for Out-Of-Vocabulary phrasal
verbs. Thus, it is hard to be adapted to other NLP
applications directly. (Kim and Baldwin, 2009) pro-
poses a memory-based system with post-processed
linguistic features such as selectional preferences.
Their system assumes the perfect outputs of a parser
and requires laborious human corrections to them.
The research presented in this paper differs from
these previous identification works mainly in two
aspects. First of all, our learning system is fully
automatic in the sense that no human intervention
is needed, no need to construct regular patterns or
to correct parser mistakes. Secondly, we focus our
attention on the comparison of the two groups of
phrasal verbs, the more idiomatic group and the
more compositional group. We argue that while
more idiomatic phrasal verbs may be easier to iden-
tify and can have above 90% accuracy, there is still
much room to learn for those more compostional
phrasal verbs which tend to be used either positively
or negatively depending on the given context.
</bodyText>
<sectionHeader confidence="0.897526" genericHeader="method">
3 Identification of English Phrasal Verbs
</sectionHeader>
<bodyText confidence="0.999961625">
We formulate the context sensitive English phrasal
verb identification task as a supervised binary clas-
sification problem. For each target candidate within
a sentence, the classifier decides if it is a true phrasal
verb or a simplex verb with a preposition. Formally,
given a set of n labeled examples {xi, yi}i1, we
learn a function f : X—* Y where Y E {−1, 1}.
The learning algorithm we use is the soft-margin
SVM with L2-loss. The learning package we use
is LIBLINEAR (Chang and Lin, 2001)3.
Three types of features are used in this discrimi-
native model. (1)Words: given the window size from
the one before to the one after the target phrase,
Words feature consists of every surface string of
all shallow chunks within that window. It can be
an n-word chunk or a single word depending on
</bodyText>
<footnote confidence="0.963227">
3http://www.csie.ntu.edu.tw/—cjlin/liblinear/
</footnote>
<page confidence="0.984157">
66
</page>
<bodyText confidence="0.999673357142857">
the the chunk’s bracketing. (2)ChunkLabel: the
chunk name with the given window size, such as VP,
PP, etc. (3)ParserBigram: the bi-gram of the non-
terminal label of the parents of both the verb and
the particle. For example, from this partial tree (VP
(VB get)(PP (IN through)(NP (DT the)(NN day))),
the parent label for the verb get is VP and the par-
ent node label for the particle through is PP. Thus,
this feature value is VP-PP. Our feature extractor
is implemented in Java through a publicly available
NLP library4 via the tool called Curator (Clarke et
al., 2012). The shallow parser is publicly avail-
able (Punyakanok and Roth, 2001)5 and the parser
we use is from (Charniak and Johnson, 2005).
</bodyText>
<subsectionHeader confidence="0.998546">
3.1 Data Preparation and Annotation
</subsectionHeader>
<bodyText confidence="0.999982230769231">
All sentences in our dataset are extracted from BNC
(XML Edition), a balanced synchronic corpus con-
taining 100 million words collected from various
sources of British English. We first construct a list of
phrasal verbs for the six verbs that we are interested
in from two resources, WN3.0 (Fellbaum, 1998)
and DIRECT6. Since these targeted verbs are also
commonly used in English Light Verb Constructions
(LVCs), we filter out LVCs in our list using a pub-
licly available LVC corpus (Tu and Roth, 2011). The
result list consists of a total of 245 phrasal verbs.
We then search over BNC and find sentences for all
of them. We choose the frequency threshold to be
25 and generate a list of 122 phrasal verbs. Finally
we manually pick out 23 of these phrasal verbs and
sample randomly 10% extracted sentences for each
of them for annotation.
The annotation is done through a crowdsourcing
platform7. The annotators are asked to identify true
phrasal verbs within a sentence. The reported inner-
annotator agreement is 84.5% and the gold aver-
age accuracy is 88%. These numbers indicate the
good quality of the annotation. The final corpus
consists of 1,348 sentences among which, 65% with
a true phrasal verb and 35% with a simplex verb-
preposition combination.
</bodyText>
<footnote confidence="0.99973275">
4http://cogcomp.cs.illinois.edu/software/edison/
5http://cogcomp.cs.illinois.edu/page/software view/Chunker
6http://u.cs.biu.ac.il/-nlp/downloads/DIRECT.html
7crowdflower.com
</footnote>
<subsectionHeader confidence="0.99816">
3.2 Dataset Splitting
</subsectionHeader>
<bodyText confidence="0.999753684210526">
Table 1 lists all verbs in the dataset. Total is the to-
tal number of sentences annotated for that phrasal
verb and Positive indicated the number of examples
which are annotated as containing the true phrasal
verb usage. In this table, the decreasing percent-
age of the true phrasal verb usage within the dataset
indicates the increasing compositionality of these
phrasal verbs. The natural division line with this
scale is the biggest percentage gap (about 10%) be-
tween make out and get at. Hence, two groups are
split over that gap. The more idiomatic group con-
sists of the first 11 verbs with 554 sentences and 91%
of these sentences include true phrasal verb usage.
This data group is more biased toward the positive
examples. The more compositional data group has
12 verbs with 794 examples and only 46.6% of them
contain true phrasal verb usage. Therefore, this data
group is more balanced with respective to positive
and negative usage of the phrase verbs.
</bodyText>
<table confidence="0.99745976">
Verb Total Positive Percent(%)
get onto 6 6 1.00
get through 61 60 0.98
get together 28 27 0.96
get on with 70 67 0.96
get down to 17 16 0.94
get by 11 10 0.91
get off 51 45 0.88
get behind 7 6 0.86
take on 212 181 0.85
get over 34 29 0.85
make out 57 48 0.84
get at 35 26 0.74
get on 142 103 0.73
take after 10 7 0.70
do up 13 8 0.62
get out 206 118 0.57
do good 8 4 0.50
make for 140 65 0.46
get it on 9 3 0.33
get about 20 6 0.30
make over 12 3 0.25
give in 118 27 0.23
have on 81 13 0.16
Total: 23 1348 878 0.65
</table>
<tableCaption confidence="0.999573">
Table 1: The top group consists of the more idiomatic
</tableCaption>
<bodyText confidence="0.75334825">
phrasal verbs with 91% of their occurrence within the
dataset to be a true phrasal verb. The second group con-
sists of those more compositional ones with only 46.6%
of their usage in the dataset to be a true phrasal verb.
</bodyText>
<page confidence="0.9986">
67
</page>
<subsectionHeader confidence="0.999658">
3.3 Experimental Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999919045454546">
Our results are computed via 5-cross validation. We
plot the classifier performance with respect to the
overall dataset, the more compositional group and
the more idiomatic group in Figure 1. The clas-
sifier only improves 0.6% when evaluated on the
idiomatic group. Phrasal verbs in this dataset are
more biased toward behaving like an idiom regard-
less of their contexts, thus are more likely to be cap-
tured by rules or patterns. We assume this may ex-
plain some high numbers reported in some previ-
ous works. However, our classifier is more effec-
tive over the more compositional group and reaches
73.9% accuracy, a 51.1% error deduction comparing
to its majority baseline. Phrasal verbs in this set tend
to be used equally likely as a true phrasal verb and
as a simplex verb-preposition combination, depend-
ing on their context. We argue phrasal verbs such as
these pose a real challenge for building an automatic
context sensitive phrasal verb classifier. The overall
accuracy of our preliminary classifier is about 79.4%
when it is evaluated over all examples from these
two groups.
</bodyText>
<figure confidence="0.56734375">
Classifier Accuracy for Different Data Groups
Comparison against their Majority Baselines Respectively
Overall Compositional Idiomatic
Data Groups
</figure>
<figureCaption confidence="0.9690405">
Figure 1: Classifier Accuracy of each data group, com-
paring with their baseline respectively. Classifier learns
the most from the more compositional group, indicated
by its biggest histogram gap.
</figureCaption>
<bodyText confidence="0.999971083333333">
Finally, we conduct an ablation analysis to ex-
plore the contributions of the three types of features
in our model and their accuracies with respect to
each data group are listed in Table 2 with the bold-
faced best performance. Each type of features is
used individually in the classifier. The feature type
Words is the most effective feature with respect to
the idiomatic group and the overall dataset. And the
chunk feature is more effective towards the compo-
sitional group, which may explain the linguistic in-
tuition that negative phrasal verbs usually do not be-
long to the same syntactic chunk.
</bodyText>
<table confidence="0.999153">
Datasets
Overall Compositional Idiom.
Baseline 65.0% 46.6% 91%
Words 78.6% 70.2% 91.4%
Chunk 65.6% 70.7% 89.4%
ParserBi 64.4% 67.2% 89.4%
</table>
<tableCaption confidence="0.95872">
Table 2: Accuracies achieved by the classifier when
tested on different data groups. Features are used indi-
vidually to evaluate the effectiveness of each type.
</tableCaption>
<sectionHeader confidence="0.998093" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999635">
In this paper, we build a discriminative learner to
identify English phrasal verbs in a given context.
Our contributions in this paper are threefold. We
construct a publicly available context sensitive En-
glish phrasal verb dataset with 1,348 sentences from
BNC. We split the dataset into two groups according
to their tendency toward idiosyncrasy and compo-
sitionality, and build a discriminative learner which
uses easily available syntactic and lexical features to
analyze them comparatively. We demonstrate em-
pirically that high accuracy achieved by models may
be due to the stronger idiomatic tendency of these
phrasal verbs. For many of the more ambiguous
cases, a classifier learns more from the composi-
tional examples and these phrasal verbs are shown
to be more challenging.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999579833333333">
The authors would like to thank four annonymous
reviewers for their valuable comments. The research
in this paper was supported by the Multimodal Infor-
mation Access &amp; Synthesis Center at UIUC, part of
CCICADA, a DHS Science and Technology Center
of Excellence and the Defense Advanced Research
Projects Agency (DARPA) Machine Reading Pro-
gram under Air Force Research Laboratory (AFRL)
prime contract no. FA8750-09-C-0181. Any opin-
ions and findings expressed in this material are those
of the authors and do not necessarily reflect the view
of DHS, DARPA, AFRL, or the US government.
</bodyText>
<figure confidence="0.9958989">
Accuracy
0.8
0.6
0.4
0.2
1.2
0
1
Majority Baseline
Classifier Accuracy
</figure>
<page confidence="0.99468">
68
</page>
<sectionHeader confidence="0.989886" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999916290909091">
D. Bolinger. 1971. The Phrasal Verb in English. Har-
vard University Press.
C. Chang and C. Lin, 2001. LIBSVM: a library
for support vector machines. Software available at
http://www.csie.ntu.edu.tw/∼cjlin/libsvm.
E. Charniak and M. Johnson. 2005. Coarse-to-fine n-
best parsing and maxent discriminative reranking. In
Proceedings ofACL-2005.
J. Clarke, V. Srikumar, M. Sammons, and D. Roth. 2012.
An NLP curator: How I learned to stop worrying and
love NLP pipelines. In Proceedings ofLREC-2012.
P. Cook and S. Stevenson. 2006. Classifying particle
semantics in English verb-particle constructions. In
Proceedings of the Workshop on Multiword Expres-
sions: Identifying and Exploiting Underlying Proper-
ties, pages 45–53, Sydney, Australia.
C. Fellbaum, editor. 1998. WordNet: An Electronic Lex-
ical Database. MIT Press.
R. Jackendoff. 2002. English particle constructions, the
lexicon, and the autonomy of syntax. In N. Deh´e,
R. Jackendoff, A. McIntyre, and S. Urban, editors,
Verb-Particle Explorations, pages 67–94. Mouton de
Gruyter.
S Kim and T. Baldwin. 2009. How to pick out token
instances of English verb-particle constructions. Jour-
nal ofLanguage Resources and Evaluation.
M. Kolln and R. Funk. 1998. Understanding English
Grammar. Allyn and Bacon.
W. Li, X. Zhang, C. Niu, Y. Jiang, and R. Srihari. 2003.
An expert lexicon approach to identifying English
phrasal verbs. In Proceedings of the 41stAnnual Meet-
ing ofACL, pages 513–520.
V. Punyakanok and D. Roth. 2001. The use of classifiers
in sequential inference. In NIPS, pages 995–1001.
I. Sag, T. Baldwin, F. Bond, and A. Copestake. 2002.
Multiword expressions: A pain in the neck for NLP.
In Proc. of the 3rd International Conference on Intel-
ligent Text Processing and Computational Linguistics
(CICLing-2002), pages 1–15.
Y. Tu and D. Roth. 2011. Learning english light verb
constructions: Contextual or statistica. In Proceedings
of the ACL Workshop on Multiword Expressions: from
Parsing and Generation to the Real World.
A. Villanvicencio and A. Copestake. 2003. Verb-particle
constructions in a computational grammar of English.
In Proceedings of the 9th International Conference on
HPSG, pages 357–371.
A. Villavicencio. 2003. Verb-particle constructions and
lexical resources. In Proceedings of the ACL 2003
Workshop on Multiword Expressions: Analysis, Acqui-
sition and Treatment, pages 57–64.
A. Villavicencio, 2006. Computational Linguistics Di-
mensions of the Syntax and Semantics of Prepositions,
chapter Verb-Particel Constructions in the World Wide
Web. Springer.
</reference>
<page confidence="0.999317">
69
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.665985">
<title confidence="0.99936">Sorting out the Most Confusing English Phrasal Verbs</title>
<author confidence="0.999929">Yuancheng Tu Dan Roth</author>
<affiliation confidence="0.999962">Department of Linguistics Department of Computer Science University of Illinois University of Illinois</affiliation>
<email confidence="0.999653">ytu@illinois.edudanr@illinois.edu</email>
<abstract confidence="0.9998474">In this paper, we investigate a full-fledged supervised machine learning framework for identifying English phrasal verbs in a given context. We concentrate on those that we deas most confusing verbs, in the sense that they are the most commonly used ones whose occurrence may correspond either to a true phrasal verb or an alignment of a simple verb with a preposition. construct a benchmark with 1,348 sentences from BNC, annotated via an Internet crowdsourcing platform. This dataset is split into two groups, more group which consists of those that tend to be as a true phrasal verb and more compowhich tends to be used either way. We build a discriminative classifier with easily available lexical and syntactic features and test it over the datasets. The classifier overall achieves 79.4% accuracy, 41.1% error deduction compared to the corpus majority baseline 65%. However, it is even more interesting to discover that the classifier learns from the more</abstract>
<intro confidence="0.669089">those</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Bolinger</author>
</authors>
<title>The Phrasal Verb in English.</title>
<date>1971</date>
<publisher>Harvard University Press.</publisher>
<contexts>
<context position="4853" citStr="Bolinger, 1971" startWordPosition="775" endWordPosition="776">er which uses easily available syntactic and lexical features to analyze them comparatively. This learner achieves 79.4% overall accuracy for the whole dataset and learns the most from the more compositional data with 51.2% error reduction over its 46.6% baseline. 2 Related Work Phrasal verbs in English were observed as one kind of composition that is used frequently and constitutes the greatest difficulty for language learners more than two hundred and fifty years ago in Samuel Johnson’s Dictionary of English Language2. They have also been well-studied in modern linguistics since early days (Bolinger, 1971; Kolln and Funk, 1998; Jackendoff, 2002). Careful linguistic descriptions and investigations reveal a wide range of English phrasal verbs that are syntactically uniform, but diverge largely in semantics, argument structure and lexical status. The complexity and idiosyncrasies of English phrasal verbs also pose a special challenge to computational linguistics and attract considerable amount of interest and investigation for their extraction, disambiguation as well as identification. Recent computational research on English phrasal verbs have been focused on increasing the coverage and scalabil</context>
</contexts>
<marker>Bolinger, 1971</marker>
<rawString>D. Bolinger. 1971. The Phrasal Verb in English. Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Chang</author>
<author>C Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm.</title>
<date>2001</date>
<contexts>
<context position="7822" citStr="Chang and Lin, 2001" startWordPosition="1238" endWordPosition="1241">which tend to be used either positively or negatively depending on the given context. 3 Identification of English Phrasal Verbs We formulate the context sensitive English phrasal verb identification task as a supervised binary classification problem. For each target candidate within a sentence, the classifier decides if it is a true phrasal verb or a simplex verb with a preposition. Formally, given a set of n labeled examples {xi, yi}i1, we learn a function f : X—* Y where Y E {−1, 1}. The learning algorithm we use is the soft-margin SVM with L2-loss. The learning package we use is LIBLINEAR (Chang and Lin, 2001)3. Three types of features are used in this discriminative model. (1)Words: given the window size from the one before to the one after the target phrase, Words feature consists of every surface string of all shallow chunks within that window. It can be an n-word chunk or a single word depending on 3http://www.csie.ntu.edu.tw/—cjlin/liblinear/ 66 the the chunk’s bracketing. (2)ChunkLabel: the chunk name with the given window size, such as VP, PP, etc. (3)ParserBigram: the bi-gram of the nonterminal label of the parents of both the verb and the particle. For example, from this partial tree (VP (</context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>C. Chang and C. Lin, 2001. LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>M Johnson</author>
</authors>
<title>Coarse-to-fine nbest parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL-2005.</booktitle>
<contexts>
<context position="8868" citStr="Charniak and Johnson, 2005" startWordPosition="1414" endWordPosition="1417">n window size, such as VP, PP, etc. (3)ParserBigram: the bi-gram of the nonterminal label of the parents of both the verb and the particle. For example, from this partial tree (VP (VB get)(PP (IN through)(NP (DT the)(NN day))), the parent label for the verb get is VP and the parent node label for the particle through is PP. Thus, this feature value is VP-PP. Our feature extractor is implemented in Java through a publicly available NLP library4 via the tool called Curator (Clarke et al., 2012). The shallow parser is publicly available (Punyakanok and Roth, 2001)5 and the parser we use is from (Charniak and Johnson, 2005). 3.1 Data Preparation and Annotation All sentences in our dataset are extracted from BNC (XML Edition), a balanced synchronic corpus containing 100 million words collected from various sources of British English. We first construct a list of phrasal verbs for the six verbs that we are interested in from two resources, WN3.0 (Fellbaum, 1998) and DIRECT6. Since these targeted verbs are also commonly used in English Light Verb Constructions (LVCs), we filter out LVCs in our list using a publicly available LVC corpus (Tu and Roth, 2011). The result list consists of a total of 245 phrasal verbs. W</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>E. Charniak and M. Johnson. 2005. Coarse-to-fine nbest parsing and maxent discriminative reranking. In Proceedings ofACL-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clarke</author>
<author>V Srikumar</author>
<author>M Sammons</author>
<author>D Roth</author>
</authors>
<title>An NLP curator: How I learned to stop worrying and love NLP pipelines.</title>
<date>2012</date>
<booktitle>In Proceedings ofLREC-2012.</booktitle>
<contexts>
<context position="8738" citStr="Clarke et al., 2012" startWordPosition="1392" endWordPosition="1395">on 3http://www.csie.ntu.edu.tw/—cjlin/liblinear/ 66 the the chunk’s bracketing. (2)ChunkLabel: the chunk name with the given window size, such as VP, PP, etc. (3)ParserBigram: the bi-gram of the nonterminal label of the parents of both the verb and the particle. For example, from this partial tree (VP (VB get)(PP (IN through)(NP (DT the)(NN day))), the parent label for the verb get is VP and the parent node label for the particle through is PP. Thus, this feature value is VP-PP. Our feature extractor is implemented in Java through a publicly available NLP library4 via the tool called Curator (Clarke et al., 2012). The shallow parser is publicly available (Punyakanok and Roth, 2001)5 and the parser we use is from (Charniak and Johnson, 2005). 3.1 Data Preparation and Annotation All sentences in our dataset are extracted from BNC (XML Edition), a balanced synchronic corpus containing 100 million words collected from various sources of British English. We first construct a list of phrasal verbs for the six verbs that we are interested in from two resources, WN3.0 (Fellbaum, 1998) and DIRECT6. Since these targeted verbs are also commonly used in English Light Verb Constructions (LVCs), we filter out LVCs </context>
</contexts>
<marker>Clarke, Srikumar, Sammons, Roth, 2012</marker>
<rawString>J. Clarke, V. Srikumar, M. Sammons, and D. Roth. 2012. An NLP curator: How I learned to stop worrying and love NLP pipelines. In Proceedings ofLREC-2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cook</author>
<author>S Stevenson</author>
</authors>
<title>Classifying particle semantics in English verb-particle constructions.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties,</booktitle>
<pages>45--53</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="5988" citStr="Cook and Stevenson, 2006" startWordPosition="940" endWordPosition="943">esearch on English phrasal verbs have been focused on increasing the coverage and scalability of phrasal verbs by either extracting unlisted phrasal verbs from large corpora (Villavicencio, 2003; Villavicencio, 2006), or constructing productive lexical rules to generate new cases (Villanvicencio and Copestake, 2003). Some other researchers follow the semantic regularities of the particles associated with these phrasal verbs and concentrate on disambiguation of phrasal 2It is written in the Preface of that dictionary. verb semantics, such as the investigation of the most common particle up by (Cook and Stevenson, 2006). Research on token identification of phrasal verbs is much less compared to the extraction. (Li et al., 2003) describes a regular expression based simple system. Regular expression based method requires human constructed regular patterns and cannot make predictions for Out-Of-Vocabulary phrasal verbs. Thus, it is hard to be adapted to other NLP applications directly. (Kim and Baldwin, 2009) proposes a memory-based system with post-processed linguistic features such as selectional preferences. Their system assumes the perfect outputs of a parser and requires laborious human corrections to them</context>
</contexts>
<marker>Cook, Stevenson, 2006</marker>
<rawString>P. Cook and S. Stevenson. 2006. Classifying particle semantics in English verb-particle constructions. In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, pages 45–53, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>C. Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>C. Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jackendoff</author>
</authors>
<title>English particle constructions, the lexicon, and the autonomy of syntax.</title>
<date>2002</date>
<booktitle>Verb-Particle Explorations,</booktitle>
<pages>67--94</pages>
<editor>In N. Deh´e, R. Jackendoff, A. McIntyre, and S. Urban, editors,</editor>
<note>Mouton de Gruyter.</note>
<contexts>
<context position="3018" citStr="Jackendoff, 2002" startWordPosition="481" endWordPosition="482">that marks Berkeley out as an empiricist. This paper is targeting to build an automatic learner which can recognize a true phrasal verb from its orthographically identical construction with a verb and a prepositional phrase. Similar to other types of MultiWord Expressions (MWEs) (Sag et al., 2002), the syntactic complexity and semantic idiosyncrasies of phrasal verbs pose many particular challenges in empirical Natural Language Processing (NLP). Even though a few of previous works have explored this identification problem empirically (Li et al., 2003; Kim and Baldwin, 2009) and theoretically (Jackendoff, 2002), we argue in this paper that this context sensitive identification problem is not so easy as conceivably shown before, especially when it is used to handle those more compositional phrasal verbs which are empirically used either way in the corpus as a true phrasal verb or a simplex verb with a preposition combination. In addition, there is still a lack of adequate resources or benchmark datasets to identify and treat phrasal 65 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 65–69, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics </context>
<context position="4894" citStr="Jackendoff, 2002" startWordPosition="781" endWordPosition="782">ic and lexical features to analyze them comparatively. This learner achieves 79.4% overall accuracy for the whole dataset and learns the most from the more compositional data with 51.2% error reduction over its 46.6% baseline. 2 Related Work Phrasal verbs in English were observed as one kind of composition that is used frequently and constitutes the greatest difficulty for language learners more than two hundred and fifty years ago in Samuel Johnson’s Dictionary of English Language2. They have also been well-studied in modern linguistics since early days (Bolinger, 1971; Kolln and Funk, 1998; Jackendoff, 2002). Careful linguistic descriptions and investigations reveal a wide range of English phrasal verbs that are syntactically uniform, but diverge largely in semantics, argument structure and lexical status. The complexity and idiosyncrasies of English phrasal verbs also pose a special challenge to computational linguistics and attract considerable amount of interest and investigation for their extraction, disambiguation as well as identification. Recent computational research on English phrasal verbs have been focused on increasing the coverage and scalability of phrasal verbs by either extracting</context>
</contexts>
<marker>Jackendoff, 2002</marker>
<rawString>R. Jackendoff. 2002. English particle constructions, the lexicon, and the autonomy of syntax. In N. Deh´e, R. Jackendoff, A. McIntyre, and S. Urban, editors, Verb-Particle Explorations, pages 67–94. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>T Baldwin</author>
</authors>
<title>How to pick out token instances of English verb-particle constructions. Journal ofLanguage Resources and Evaluation.</title>
<date>2009</date>
<contexts>
<context position="2981" citStr="Kim and Baldwin, 2009" startWordPosition="475" endWordPosition="478">yond what is directly given in experience that marks Berkeley out as an empiricist. This paper is targeting to build an automatic learner which can recognize a true phrasal verb from its orthographically identical construction with a verb and a prepositional phrase. Similar to other types of MultiWord Expressions (MWEs) (Sag et al., 2002), the syntactic complexity and semantic idiosyncrasies of phrasal verbs pose many particular challenges in empirical Natural Language Processing (NLP). Even though a few of previous works have explored this identification problem empirically (Li et al., 2003; Kim and Baldwin, 2009) and theoretically (Jackendoff, 2002), we argue in this paper that this context sensitive identification problem is not so easy as conceivably shown before, especially when it is used to handle those more compositional phrasal verbs which are empirically used either way in the corpus as a true phrasal verb or a simplex verb with a preposition combination. In addition, there is still a lack of adequate resources or benchmark datasets to identify and treat phrasal 65 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 65–69, Montr´eal, Canada, June 7-8, 2012. c�2012 Assoc</context>
<context position="6382" citStr="Kim and Baldwin, 2009" startWordPosition="1001" endWordPosition="1004">iated with these phrasal verbs and concentrate on disambiguation of phrasal 2It is written in the Preface of that dictionary. verb semantics, such as the investigation of the most common particle up by (Cook and Stevenson, 2006). Research on token identification of phrasal verbs is much less compared to the extraction. (Li et al., 2003) describes a regular expression based simple system. Regular expression based method requires human constructed regular patterns and cannot make predictions for Out-Of-Vocabulary phrasal verbs. Thus, it is hard to be adapted to other NLP applications directly. (Kim and Baldwin, 2009) proposes a memory-based system with post-processed linguistic features such as selectional preferences. Their system assumes the perfect outputs of a parser and requires laborious human corrections to them. The research presented in this paper differs from these previous identification works mainly in two aspects. First of all, our learning system is fully automatic in the sense that no human intervention is needed, no need to construct regular patterns or to correct parser mistakes. Secondly, we focus our attention on the comparison of the two groups of phrasal verbs, the more idiomatic grou</context>
</contexts>
<marker>Kim, Baldwin, 2009</marker>
<rawString>S Kim and T. Baldwin. 2009. How to pick out token instances of English verb-particle constructions. Journal ofLanguage Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kolln</author>
<author>R Funk</author>
</authors>
<title>Understanding English Grammar. Allyn and Bacon.</title>
<date>1998</date>
<contexts>
<context position="1782" citStr="Kolln and Funk, 1998" startWordPosition="276" endWordPosition="279">However, it is even more interesting to discover that the classifier learns more from the more compositional examples than those idiomatic ones. 1 Introduction Phrasal verbs in English, are syntactically defined as combinations of verbs and prepositions or particles, but semantically their meanings are generally not the direct sum of their parts. For example, give in means submit, yield in the sentence, Adam’s saying it’s important to stand firm , not give in to terrorists. Adam was not giving anything and he was 1http://cogcomp.cs.illinois.edu/page/resources/PVC Data not in anywhere either. (Kolln and Funk, 1998) uses the test of meaning to detect English phrasal verbs, i.e., each phrasal verb could be replaced by a single verb with the same general meaning, for example, using yield to replace give in in the aforementioned sentence. To confuse the issue even further, some phrasal verbs, for example, give in in the following two sentences, are used either as a true phrasal verb (the first sentence) or not (the second sentence) though their surface forms look cosmetically similar. 1. How many Englishmen gave in to their emotions like that ? 2. It is just this denial of anything beyond what is directly g</context>
<context position="4875" citStr="Kolln and Funk, 1998" startWordPosition="777" endWordPosition="780">sily available syntactic and lexical features to analyze them comparatively. This learner achieves 79.4% overall accuracy for the whole dataset and learns the most from the more compositional data with 51.2% error reduction over its 46.6% baseline. 2 Related Work Phrasal verbs in English were observed as one kind of composition that is used frequently and constitutes the greatest difficulty for language learners more than two hundred and fifty years ago in Samuel Johnson’s Dictionary of English Language2. They have also been well-studied in modern linguistics since early days (Bolinger, 1971; Kolln and Funk, 1998; Jackendoff, 2002). Careful linguistic descriptions and investigations reveal a wide range of English phrasal verbs that are syntactically uniform, but diverge largely in semantics, argument structure and lexical status. The complexity and idiosyncrasies of English phrasal verbs also pose a special challenge to computational linguistics and attract considerable amount of interest and investigation for their extraction, disambiguation as well as identification. Recent computational research on English phrasal verbs have been focused on increasing the coverage and scalability of phrasal verbs b</context>
</contexts>
<marker>Kolln, Funk, 1998</marker>
<rawString>M. Kolln and R. Funk. 1998. Understanding English Grammar. Allyn and Bacon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Li</author>
<author>X Zhang</author>
<author>C Niu</author>
<author>Y Jiang</author>
<author>R Srihari</author>
</authors>
<title>An expert lexicon approach to identifying English phrasal verbs.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41stAnnual Meeting ofACL,</booktitle>
<pages>513--520</pages>
<contexts>
<context position="2957" citStr="Li et al., 2003" startWordPosition="471" endWordPosition="474">al of anything beyond what is directly given in experience that marks Berkeley out as an empiricist. This paper is targeting to build an automatic learner which can recognize a true phrasal verb from its orthographically identical construction with a verb and a prepositional phrase. Similar to other types of MultiWord Expressions (MWEs) (Sag et al., 2002), the syntactic complexity and semantic idiosyncrasies of phrasal verbs pose many particular challenges in empirical Natural Language Processing (NLP). Even though a few of previous works have explored this identification problem empirically (Li et al., 2003; Kim and Baldwin, 2009) and theoretically (Jackendoff, 2002), we argue in this paper that this context sensitive identification problem is not so easy as conceivably shown before, especially when it is used to handle those more compositional phrasal verbs which are empirically used either way in the corpus as a true phrasal verb or a simplex verb with a preposition combination. In addition, there is still a lack of adequate resources or benchmark datasets to identify and treat phrasal 65 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 65–69, Montr´eal, Canada, June</context>
<context position="6098" citStr="Li et al., 2003" startWordPosition="958" endWordPosition="961">r extracting unlisted phrasal verbs from large corpora (Villavicencio, 2003; Villavicencio, 2006), or constructing productive lexical rules to generate new cases (Villanvicencio and Copestake, 2003). Some other researchers follow the semantic regularities of the particles associated with these phrasal verbs and concentrate on disambiguation of phrasal 2It is written in the Preface of that dictionary. verb semantics, such as the investigation of the most common particle up by (Cook and Stevenson, 2006). Research on token identification of phrasal verbs is much less compared to the extraction. (Li et al., 2003) describes a regular expression based simple system. Regular expression based method requires human constructed regular patterns and cannot make predictions for Out-Of-Vocabulary phrasal verbs. Thus, it is hard to be adapted to other NLP applications directly. (Kim and Baldwin, 2009) proposes a memory-based system with post-processed linguistic features such as selectional preferences. Their system assumes the perfect outputs of a parser and requires laborious human corrections to them. The research presented in this paper differs from these previous identification works mainly in two aspects.</context>
</contexts>
<marker>Li, Zhang, Niu, Jiang, Srihari, 2003</marker>
<rawString>W. Li, X. Zhang, C. Niu, Y. Jiang, and R. Srihari. 2003. An expert lexicon approach to identifying English phrasal verbs. In Proceedings of the 41stAnnual Meeting ofACL, pages 513–520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Punyakanok</author>
<author>D Roth</author>
</authors>
<title>The use of classifiers in sequential inference.</title>
<date>2001</date>
<booktitle>In NIPS,</booktitle>
<pages>995--1001</pages>
<contexts>
<context position="8808" citStr="Punyakanok and Roth, 2001" startWordPosition="1403" endWordPosition="1406">k’s bracketing. (2)ChunkLabel: the chunk name with the given window size, such as VP, PP, etc. (3)ParserBigram: the bi-gram of the nonterminal label of the parents of both the verb and the particle. For example, from this partial tree (VP (VB get)(PP (IN through)(NP (DT the)(NN day))), the parent label for the verb get is VP and the parent node label for the particle through is PP. Thus, this feature value is VP-PP. Our feature extractor is implemented in Java through a publicly available NLP library4 via the tool called Curator (Clarke et al., 2012). The shallow parser is publicly available (Punyakanok and Roth, 2001)5 and the parser we use is from (Charniak and Johnson, 2005). 3.1 Data Preparation and Annotation All sentences in our dataset are extracted from BNC (XML Edition), a balanced synchronic corpus containing 100 million words collected from various sources of British English. We first construct a list of phrasal verbs for the six verbs that we are interested in from two resources, WN3.0 (Fellbaum, 1998) and DIRECT6. Since these targeted verbs are also commonly used in English Light Verb Constructions (LVCs), we filter out LVCs in our list using a publicly available LVC corpus (Tu and Roth, 2011).</context>
</contexts>
<marker>Punyakanok, Roth, 2001</marker>
<rawString>V. Punyakanok and D. Roth. 2001. The use of classifiers in sequential inference. In NIPS, pages 995–1001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Sag</author>
<author>T Baldwin</author>
<author>F Bond</author>
<author>A Copestake</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2002),</booktitle>
<pages>1--15</pages>
<contexts>
<context position="2699" citStr="Sag et al., 2002" startWordPosition="432" endWordPosition="435"> in the following two sentences, are used either as a true phrasal verb (the first sentence) or not (the second sentence) though their surface forms look cosmetically similar. 1. How many Englishmen gave in to their emotions like that ? 2. It is just this denial of anything beyond what is directly given in experience that marks Berkeley out as an empiricist. This paper is targeting to build an automatic learner which can recognize a true phrasal verb from its orthographically identical construction with a verb and a prepositional phrase. Similar to other types of MultiWord Expressions (MWEs) (Sag et al., 2002), the syntactic complexity and semantic idiosyncrasies of phrasal verbs pose many particular challenges in empirical Natural Language Processing (NLP). Even though a few of previous works have explored this identification problem empirically (Li et al., 2003; Kim and Baldwin, 2009) and theoretically (Jackendoff, 2002), we argue in this paper that this context sensitive identification problem is not so easy as conceivably shown before, especially when it is used to handle those more compositional phrasal verbs which are empirically used either way in the corpus as a true phrasal verb or a simpl</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, 2002</marker>
<rawString>I. Sag, T. Baldwin, F. Bond, and A. Copestake. 2002. Multiword expressions: A pain in the neck for NLP. In Proc. of the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2002), pages 1–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tu</author>
<author>D Roth</author>
</authors>
<title>Learning english light verb constructions: Contextual or statistica.</title>
<date>2011</date>
<booktitle>In Proceedings of the ACL Workshop on Multiword Expressions: from Parsing and Generation to the Real World.</booktitle>
<contexts>
<context position="9407" citStr="Tu and Roth, 2011" startWordPosition="1503" endWordPosition="1506">nok and Roth, 2001)5 and the parser we use is from (Charniak and Johnson, 2005). 3.1 Data Preparation and Annotation All sentences in our dataset are extracted from BNC (XML Edition), a balanced synchronic corpus containing 100 million words collected from various sources of British English. We first construct a list of phrasal verbs for the six verbs that we are interested in from two resources, WN3.0 (Fellbaum, 1998) and DIRECT6. Since these targeted verbs are also commonly used in English Light Verb Constructions (LVCs), we filter out LVCs in our list using a publicly available LVC corpus (Tu and Roth, 2011). The result list consists of a total of 245 phrasal verbs. We then search over BNC and find sentences for all of them. We choose the frequency threshold to be 25 and generate a list of 122 phrasal verbs. Finally we manually pick out 23 of these phrasal verbs and sample randomly 10% extracted sentences for each of them for annotation. The annotation is done through a crowdsourcing platform7. The annotators are asked to identify true phrasal verbs within a sentence. The reported innerannotator agreement is 84.5% and the gold average accuracy is 88%. These numbers indicate the good quality of th</context>
</contexts>
<marker>Tu, Roth, 2011</marker>
<rawString>Y. Tu and D. Roth. 2011. Learning english light verb constructions: Contextual or statistica. In Proceedings of the ACL Workshop on Multiword Expressions: from Parsing and Generation to the Real World.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Villanvicencio</author>
<author>A Copestake</author>
</authors>
<title>Verb-particle constructions in a computational grammar of English.</title>
<date>2003</date>
<booktitle>In Proceedings of the 9th International Conference on HPSG,</booktitle>
<pages>357--371</pages>
<contexts>
<context position="5680" citStr="Villanvicencio and Copestake, 2003" startWordPosition="892" endWordPosition="895">n semantics, argument structure and lexical status. The complexity and idiosyncrasies of English phrasal verbs also pose a special challenge to computational linguistics and attract considerable amount of interest and investigation for their extraction, disambiguation as well as identification. Recent computational research on English phrasal verbs have been focused on increasing the coverage and scalability of phrasal verbs by either extracting unlisted phrasal verbs from large corpora (Villavicencio, 2003; Villavicencio, 2006), or constructing productive lexical rules to generate new cases (Villanvicencio and Copestake, 2003). Some other researchers follow the semantic regularities of the particles associated with these phrasal verbs and concentrate on disambiguation of phrasal 2It is written in the Preface of that dictionary. verb semantics, such as the investigation of the most common particle up by (Cook and Stevenson, 2006). Research on token identification of phrasal verbs is much less compared to the extraction. (Li et al., 2003) describes a regular expression based simple system. Regular expression based method requires human constructed regular patterns and cannot make predictions for Out-Of-Vocabulary phr</context>
</contexts>
<marker>Villanvicencio, Copestake, 2003</marker>
<rawString>A. Villanvicencio and A. Copestake. 2003. Verb-particle constructions in a computational grammar of English. In Proceedings of the 9th International Conference on HPSG, pages 357–371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Villavicencio</author>
</authors>
<title>Verb-particle constructions and lexical resources.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="5557" citStr="Villavicencio, 2003" startWordPosition="878" endWordPosition="879">igations reveal a wide range of English phrasal verbs that are syntactically uniform, but diverge largely in semantics, argument structure and lexical status. The complexity and idiosyncrasies of English phrasal verbs also pose a special challenge to computational linguistics and attract considerable amount of interest and investigation for their extraction, disambiguation as well as identification. Recent computational research on English phrasal verbs have been focused on increasing the coverage and scalability of phrasal verbs by either extracting unlisted phrasal verbs from large corpora (Villavicencio, 2003; Villavicencio, 2006), or constructing productive lexical rules to generate new cases (Villanvicencio and Copestake, 2003). Some other researchers follow the semantic regularities of the particles associated with these phrasal verbs and concentrate on disambiguation of phrasal 2It is written in the Preface of that dictionary. verb semantics, such as the investigation of the most common particle up by (Cook and Stevenson, 2006). Research on token identification of phrasal verbs is much less compared to the extraction. (Li et al., 2003) describes a regular expression based simple system. Regula</context>
</contexts>
<marker>Villavicencio, 2003</marker>
<rawString>A. Villavicencio. 2003. Verb-particle constructions and lexical resources. In Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Villavicencio</author>
</authors>
<date>2006</date>
<booktitle>Computational Linguistics Dimensions of the Syntax and Semantics of Prepositions, chapter Verb-Particel Constructions in the World Wide</booktitle>
<publisher>Web. Springer.</publisher>
<contexts>
<context position="5579" citStr="Villavicencio, 2006" startWordPosition="880" endWordPosition="881">e range of English phrasal verbs that are syntactically uniform, but diverge largely in semantics, argument structure and lexical status. The complexity and idiosyncrasies of English phrasal verbs also pose a special challenge to computational linguistics and attract considerable amount of interest and investigation for their extraction, disambiguation as well as identification. Recent computational research on English phrasal verbs have been focused on increasing the coverage and scalability of phrasal verbs by either extracting unlisted phrasal verbs from large corpora (Villavicencio, 2003; Villavicencio, 2006), or constructing productive lexical rules to generate new cases (Villanvicencio and Copestake, 2003). Some other researchers follow the semantic regularities of the particles associated with these phrasal verbs and concentrate on disambiguation of phrasal 2It is written in the Preface of that dictionary. verb semantics, such as the investigation of the most common particle up by (Cook and Stevenson, 2006). Research on token identification of phrasal verbs is much less compared to the extraction. (Li et al., 2003) describes a regular expression based simple system. Regular expression based met</context>
</contexts>
<marker>Villavicencio, 2006</marker>
<rawString>A. Villavicencio, 2006. Computational Linguistics Dimensions of the Syntax and Semantics of Prepositions, chapter Verb-Particel Constructions in the World Wide Web. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>