<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007705">
<title confidence="0.989705">
Learning the Latent Semantics of a Concept from its Definition
</title>
<author confidence="0.998278">
Weiwei Guo
</author>
<affiliation confidence="0.899119">
Department of Computer Science,
Columbia University,
</affiliation>
<address confidence="0.959951">
New York, NY, USA
</address>
<email confidence="0.999179">
weiwei@cs.columbia.edu
</email>
<author confidence="0.991464">
Mona Diab
</author>
<affiliation confidence="0.8998785">
Center for Computational Learning Systems,
Columbia University,
</affiliation>
<address confidence="0.918753">
New York, NY, USA
</address>
<email confidence="0.999603">
mdiab@ccls.columbia.edu
</email>
<sectionHeader confidence="0.994367" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9287485">
In this paper we study unsupervised word
sense disambiguation (WSD) based on sense
definition. We learn low-dimensional latent
semantic vectors of concept definitions to con-
struct a more robust sense similarity measure
wmfvec. Experiments on four all-words WSD
data sets show significant improvement over
the baseline WSD systems and LDA based
similarity measures, achieving results compa-
rable to state of the art WSD systems.
</bodyText>
<sectionHeader confidence="0.998645" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999862727272728">
To date, many unsupervised WSD systems rely on
a sense similarity module that returns a similar-
ity score given two senses. Many similarity mea-
sures use the taxonomy structure of WordNet [WN]
(Fellbaum, 1998), which allows only noun-noun and
verb-verb pair similarity computation since the other
parts of speech (adjectives and adverbs) do not have
a taxonomic representation structure. For example,
the jcn similarity measure (Jiang and Conrath, 1997)
computes the sense pair similarity score based on the
information content of three senses: the two senses
and their least common subsumer in the noun/verb
hierarchy.
The most popular sense similarity measure is the
Extended Lesk [elesk] measure (Banerjee and Peder-
sen, 2003). In elesk, the similarity score is computed
based on the length of overlapping words/phrases
between two extended dictionary definitions. The
definitions are extended by definitions of neighbor
senses to discover more overlapping words. How-
ever, exact word matching is lossy. Below are two
definitions from WN:
</bodyText>
<footnote confidence="0.9245918">
bank#n#1: a financial institution that accepts deposits
and channels the money into lending activities
stock#n#1: the capital raised by a corporation through
the issue of shares entitling holders to an ownership in-
terest (equity)
</footnote>
<bodyText confidence="0.990585361111111">
Despite the high semantic relatedness of the two
senses, the overlapping words in the two definitions
are only a, the, leading to a very low similarity score.
Accordingly we are interested in extracting latent
semantics from sense definitions to improve elesk.
However, the challenge lies in that sense defini-
tions are typically too short/sparse for latent vari-
able models to learn accurate semantics, since these
models are designed for long documents. For exam-
ple, topic models such as LDA (Blei et al., 2003),
can only find the dominant topic based on the ob-
served words in a definition (financial topic in
bank#n#1 and stock#n#1) without further dis-
cernibility. In this case, many senses will share the
same latent semantics profile, as long as they are in
the same topic/domain.
To solve the sparsity issue we use missing words
as negative evidence of latent semantics, as in (Guo
and Diab, 2012). We define missing words of a sense
definition as the whole vocabulary in a corpus minus
the observed words in the sense definition. Since
observed words in definitions are too few to reveal
the semantics of senses, missing words can be used
to tell the model what the definition is not about.
Therefore, we want to find a latent semantics pro-
file that is related to observed words in a definition,
but also not related to missing words, so that the in-
duced latent semantics is unique for the sense.
Finally we also show how to use WN neighbor
sense definitions to construct a nuanced sense simi-
larity wmfvec, based on the inferred latent semantic
vectors of senses. We show that wmfvec outperforms
elesk and LDA based approaches in four All-words
WSD data sets. To our best knowledge, wmfvec is
the first sense similarity measure based on latent se-
mantics of sense definitions.
</bodyText>
<page confidence="0.963314">
140
</page>
<note confidence="0.834245">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 140–144,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<table confidence="0.99258125">
financial sport institution Ro Rm
v1 1 0 0 20 600
v2 0.6 0 0.1 18 300
v3 0.2 0.3 0.2 5 100
</table>
<tableCaption confidence="0.980022">
Table 1: Three possible hypotheses of latent vectors for
the definition of bank#n#1
</tableCaption>
<sectionHeader confidence="0.636121" genericHeader="method">
2 Learning Latent Semantics of Definitions
</sectionHeader>
<subsectionHeader confidence="0.873457">
2.1 Intuition
</subsectionHeader>
<bodyText confidence="0.98141196875">
Given only a few observed words in a definition,
there are many hypotheses of latent vectors that are
highly related to the observed words. Therefore,
missing words can be used to prune the hypotheses
that are also highly related to the missing words.
Consider the hypotheses of latent vectors in ta-
ble 1 for bank#n#1. Assume there are 3 dimen-
sions in our latent model: financial, sport, institu-
tion. We use Rvo to denote the sum of relatedness
between latent vector v and all observed words; sim-
ilarly, Rvm is the sum of relatedness between the
vector v and all missing words. Hypothesis v1 is
given by topic models, where only the financial
dimension is found, and it has the maximum relat-
edness to observed words in bank#n#1 definition
Rv1
o = 20. v2 is the ideal latent vector, since it also
detects that bank#n#1 is related to institution. It
has a slightly smaller Rv2
o = 18, but more impor-
tantly, its relatedness to missing words, Rv2m = 300,
is substantially smaller than Rv1m = 600.
However, we cannot simply choose a hypothesis
with the maximum Ro − Rm value, since v3, which
is clearly not related to bank#n#1 but with a min-
imum Rm = 100, will therefore be (erroneously)
returned as the answer. The solution is straightfor-
ward: give a smaller weight to missing words, e.g.,
so that the algorithm tries to select a hypothesis with
maximum value of Ro − 0.01 x Rm. We choose
weighted matrix factorization [WMF] (Srebro and
Jaakkola, 2003) to implement this idea.
</bodyText>
<subsectionHeader confidence="0.999345">
2.2 Modeling Missing Words by Weighted
Matrix Factorization
</subsectionHeader>
<bodyText confidence="0.999693285714286">
We represent the corpus of WN definitions as an
M x N matrix X, where row entries are M unique
words existing in WN definitions, and columns rep-
resent N WN sense ids. The cell Xij records the
TF-IDF value of word wi appearing in definition of
sense sj.
In WMF, the original matrix X is factorized into
two matrices such that X ,. PTQ, where P is a
K x M matrix, and Q is a K x N matrix. In
this scenario, the latent semantics of each word wi
or sense sj is represented as a K-dimension vector
P·,i or Q·,j respectively. Note that the inner product
of P·,i and Q·,j is used to approximate the seman-
tic relatedness of word wi and definition of sense sj:
Xij ,. P·,i � Q·,j.
In WMF each cell is associated with a weight, so
missing words cells (Xij=0) can have a much less
contribution than observed words. Assume wm is
the weight for missing words cells. The latent vec-
tors of words P and senses Q are estimated by min-
imizing the objective function:1
</bodyText>
<equation confidence="0.843707333333333">
E Wij (P·,i · Q·,j − Xij)2 +
J 1, if Xij 54 0 (1)
where Wi j = l wm, if Xij = 0
</equation>
<bodyText confidence="0.999926777777778">
Equation 1 explicitly requires the latent vector of
sense Q·,j to be not related to missing words (P·,i �
Q·,j should be close to 0 for missing words Xij =
0). Also weight wm for missing words is very small
to make sure latent vectors such as v3 in table 1 will
not be chosen. In experiments we set wm = 0.01.
After we run WMF on the definitions corpus, the
similarity of two senses sj and sk can be computed
by the inner product of Q·,j and Q·,k.
</bodyText>
<subsectionHeader confidence="0.999211">
2.3 A Nuanced Sense Similarity: wmfvec
</subsectionHeader>
<bodyText confidence="0.981989875">
We can further use the features in WordNet to con-
struct a better sense similarity measure. The most
important feature of WN is senses are connected by
relations such as hypernymy, meronymy, similar at-
tributes, etc. We observe that neighbor senses are
usually similar, hence they could be a good indica-
tor for the latent semantics of the target sense.
We use WN neighbors in a way similar to elesk.
Note that in elesk each definition is extended by in-
cluding definitions of its neighbor senses. Also, they
do not normalize the length. In our case, we also
adopt these two ideas: (1) a sense is represented by
the sum of its original latent vector and its neigh-
bors’ latent vectors. Let N(j) be the set of neigh-
bor senses of sense j. then new latent vector is:
Qnew
</bodyText>
<equation confidence="0.642068">
·,j = Q·,j + Ek
</equation>
<bodyText confidence="0.951441">
EN(j) Q·,k (2) Inner product (in-
stead of cosine similarity) of the two resulting sense
vectors is treated as the sense pair similarity. We
refer to our sense similarity measure as wmfvec.
</bodyText>
<footnote confidence="0.94357">
1Due to limited space inference and update rules for P and
Q are omitted, but can be found in (Srebro and Jaakkola, 2003)
</footnote>
<equation confidence="0.9326785">
λ||P||22 + λ||Q||22
i j
</equation>
<page confidence="0.994276">
141
</page>
<sectionHeader confidence="0.997518" genericHeader="method">
3 Experiment Setting
</sectionHeader>
<bodyText confidence="0.997161244444444">
Task: We choose the fine-grained All-Words Sense
Disambiguation task, where systems are required to
disambiguate all the content words (noun, adjective,
adverb and verb) in documents. The data sets we use
are all-words tasks in SENSEVAL2 [SE2], SENSE-
VAL3 [SE3], SEMEVAL-2007 [SE07], and Semcor.
We tune the parameters in wmfvec and other base-
lines based on SE2, and then directly apply the tuned
models on other three data sets.
Data: The sense inventory is WN3.0 for the four
WSD data sets. WMF and LDA are built on the cor-
pus of sense definitions of two dictionaries: WN and
Wiktionary [Wik].2 We do not link the senses across
dictionaries, hence Wik is only used as augmented
data for WMF to better learn the semantics of words.
All data is tokenized, POS tagged (Toutanova et al.,
2003) and lemmatized, resulting in 341,557 sense
definitions and 3,563,649 words.
WSD Algorithm: To perform WSD we need two
components: (1) a sense similarity measure that re-
turns a similarity score given two senses; (2) a dis-
ambiguation algorithm that determines which senses
to choose as final answers based on the sense pair
similarity scores. We choose the Indegree algorithm
used in (Sinha and Mihalcea, 2007; Guo and Diab,
2010) as our disambiguation algorithm. Itis a graph-
based algorithm, where nodes are senses, and edge
weight equals to the sense pair similarity. The final
answer is chosen as the sense with maximum inde-
gree. Using the Indegree algorithm allows us to eas-
ily replace the sense similarity with wmfvec. In In-
degree, two senses are connected if their words are
within a local window. We use the optimal window
size of 6 tested in (Sinha and Mihalcea, 2007; Guo
and Diab, 2010).
Baselines: We compare with (1) elesk, the most
widely used sense similarity. We use the implemen-
tation in (Pedersen et al., 2004).
We believe WMF is a better approach to model
latent semantics than LDA, hence the second base-
line (2) LDA using Gibbs sampling (Griffiths and
Steyvers, 2004). However, we cannot directly use
estimated topic distribution P(zld) to represent the
definition since it only has non-zero values on one
or two topics. Instead, we calculate the latent vec-
</bodyText>
<footnote confidence="0.954283">
2http://en.wiktionary.org/
</footnote>
<table confidence="0.99990292">
Data Model Total Noun Adj Adv Verb
SE2 random 40.7 43.9 43.6 58.2 21.6
elesk 56.0 63.5 63.9 62.1 30.8
ldavec 58.6 68.6 60.2 66.1 33.2
wmfvec 60.5 69.7 64.5 67.1 34.9
jcn+elesk 60.1 69.3 63.9 62.8 37.1
jcn+wmfvec 62.1 70.8 64.5 67.1 39.9
SE3 random 33.5 39.9 44.1 - 33.5
elesk 52.3 58.5 57.7 - 41.4
ldavec 53.5 58.1 60.8 - 43.7
wmfvec 55.8 61.5 64.4 - 43.9
jcn+elesk 55.4 60.5 57.7 - 47.4
jcn+wmfvec 57.4 61.2 64.4 - 48.8
SE07 random 25.6 27.4 - - 24.6
elesk 42.2 47.2 - - 39.5
ldavec 43.7 49.7 - - 40.5
wmfvec 45.1 52.2 - - 41.2
jcn+elesk 44.5 52.8 - - 40.0
jcn+wmfvec 45.5 53.5 - - 41.2
Semcor random 35.26 40.13 50.02 58.90 20.08
elesk 55.43 61.04 69.30 62.85 43.36
ldavec 58.17 63.15 70.08 67.97 46.91
wmfvec 59.10 64.64 71.44 67.05 47.52
jcn+elesk 61.61 69.61 69.30 62.85 50.72
jcn+wmfvec 63.05 70.64 71.45 67.05 51.72
</table>
<tableCaption confidence="0.998826">
Table 2: WSD results per POS (K = 100)
</tableCaption>
<bodyText confidence="0.999923">
tor of a definition by summing up the P(zlw) of
all constituent words weighted by Xij, which gives
much better WSD results.3 We produce LDA vec-
tors [ldavec] in the same setting as wmfvec, which
means it is trained on the same corpus, uses WN
neighbors, and is tuned on SE2.
At last, we compare wmfvec with a mature WSD
system based on sense similarities, (3) (Sinha and
Mihalcea, 2007) [jcn+elesk], where they evaluate six
sense similarities, select the best of them and com-
bine them into one system. Specifically, in their im-
plementation they use jcn for noun-noun and verb-
verb pairs, and elesk for other pairs. (Sinha and Mi-
halcea, 2007) used to be the state-of-the-art system
on SE2 and SE3.
</bodyText>
<sectionHeader confidence="0.993762" genericHeader="method">
4 Experiment Results
</sectionHeader>
<bodyText confidence="0.9998975">
The disambiguation results (K = 100) are summa-
rized in Table 2. We also present in Table 3 results
using other values of dimensions K for wmfvec and
ldavec. There are very few words that are not cov-
ered due to failure of lemmatization or POS tag mis-
matches, thereby F-measure is reported.
Based on SE2, wmfvec’s parameters are tuned as
A = 20,w.. = 0.01; ldavec’s parameters are tuned
as α = 0.05, Q = 0.05. We run WMF on WN+Wik
for 30 iterations, and LDA for 2000 iterations. For
</bodyText>
<footnote confidence="0.860937">
3It should be noted that this renders LDA a very challenging
baseline to outperform.
</footnote>
<page confidence="0.997207">
142
</page>
<bodyText confidence="0.99984325">
LDA, more robust P(w|z) is generated by averag-
ing over the last 10 sampling iterations. We also set
a threshold to elesk similarity values, which yields
better performance. Same as (Sinha and Mihalcea,
2007), values of elesk larger than 240 are set to 1,
and the rest are mapped to [0,1].
elesk vs wmfvec: wmfvec outperforms elesk consis-
tently in all POS cases (noun, adjective, adverb and
verb) on four datasets by a large margin (2.9% −
4.5% in total case). Observing the results yielded
per POS, we find a large improvement comes from
nouns. Same trend has been reported in other distri-
butional methods based on word co-occurrence (Cai
et al., 2007; Li et al., 2010; Guo and Diab, 2011).
More interestingly, wmfvec also improves verbs ac-
curacy significantly.
ldavec vs wmfvec: ldavec also performs very well,
again proving the superiority of latent semantics
over surface words matching. However, wmfvec also
outperforms ldavec in every POS case except Sem-
cor adverbs (at least +1% in total case). We observe
the trend is consistent in Table 3 where different di-
mensions are used for ldavec and wmfvec. These
results show that given the same text data, WMF
outperforms LDA on modeling latent semantics of
senses by exploiting missing words.
jcn+elesk vs jcn+wmfvec: jcn+elesk is a very ma-
ture WSD system that takes advantage of the great
performance of jcn on noun-noun and verb-verb
pairs. Although wmfvec does much better than elesk,
using wmfvec solely is sometimes outperformed by
jcn+elesk on nouns and verbs. Therefore to beat
jcn+elesk, we replace the elesk in jcn+elesk with
wmfvec (hence jcn+wmfvec). Similar to (Sinha and
Mihalcea, 2007), we normalize wmfvec similarity
such that values greater than 400 are set to 1, and
the rest values are mapped to [0,1]. We choose the
value 400 based on the WSD performance on tun-
ing set SE2. As expected, the resulting jcn+wmfvec
can further improve jcn+elesk for all cases. More-
over, jcn+wmfvec produces similar results to state-
of-the-art unsupervised systems on SE02, 61.92%
F-mearure in (Guo and Diab, 2010) using WN1.7.1,
and SE03, 57.4% in (Agirre and Soroa, 2009) us-
ing WN1.7. It shows wmfvec is robust that it not
only performs very well individually, but also can
be easily incorporated with existing evidence as rep-
resented using jcn.
</bodyText>
<table confidence="0.999725">
dim SE2 SE3 SE07 Semcor
50 57.4 - 60.5 52.9 - 54.9 43.1 - 44.2 57.90 - 58.99
75 57.8 - 60.3 53.5 - 55.2 43.3 - 44.6 58.12 - 59.07
100 58.6 - 60.5 53.5 - 55.8 43.7 - 45.1 58.17 - 59.10
125 58.2 - 60.2 53.9 - 55.5 43.7 - 45.1 58.26 - 59.19
150 58.2 - 59.8 53.6 - 54.6 44.4 - 45.9 58.13 - 59.15
</table>
<tableCaption confidence="0.999537">
Table 3: ldavec and wmfvec (latter) results per # of dimensions
</tableCaption>
<subsectionHeader confidence="0.959327">
4.1 Discussion
</subsectionHeader>
<bodyText confidence="0.999890545454545">
We look closely into WSD results to obtain an in-
tuitive feel for what is captured by wmfvec. For ex-
ample, the target word mouse in the context: ... in
experiments with mice that a gene called p53 could
transform normal cells into cancerous ones... elesk
returns the wrong sense computer device, due to the
sparsity of overlapping words between definitions
of animal mouse and the context words. wmfvec
chooses the correct sense animal mouse, by recog-
nizing the biology element of animal mouse and re-
lated context words gene, cell, cancerous.
</bodyText>
<sectionHeader confidence="0.999968" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999858230769231">
Sense similarity measures have been the core com-
ponent in many unsupervised WSD systems and
lexical semantics research/applications. To date,
elesk is the most popular such measure (McCarthy
et al., 2004; Mihalcea, 2005; Brody et al., 2006).
Sometimes people use jcn to obtain similarity of
noun-noun and verb-verb pairs (Sinha and Mihalcea,
2007; Guo and Diab, 2010). Our similarity measure
wmfvec exploits the same information (sense defini-
tions) elesk and ldavec use, and outperforms them
significantly on four standardized data sets. To our
best knowledge, we are the first to construct a sense
similarity by latent semantics of sense definitions.
</bodyText>
<sectionHeader confidence="0.999625" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.9999474">
We construct a sense similarity wmfvec from the la-
tent semantics of sense definitions. Experiment re-
sults show wmfvec significantly outperforms previ-
ous definition-based similarity measures and LDA
vectors on four all-words WSD data sets.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9997725">
This research was funded by the Office of the Di-
rector of National Intelligence (ODNI), Intelligence
Advanced Research Projects Activity (IARPA),
through the U.S. Army Research Lab. All state-
ments of fact, opinion or conclusions contained
herein are those of the authors and should not be
construed as representing the official views or poli-
cies of IARPA, the ODNI or the U.S. Government.
</bodyText>
<page confidence="0.998785">
143
</page>
<sectionHeader confidence="0.987376" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.986268256410257">
Eneko Agirre and Aitor Soroa. 2009. Proceedings of per-
sonalizing pagerank for word sense disambiguation.
In the 12th Conference of the European Chapter of the
ACL.
Satanjeev Banerjee and Ted Pedersen. 2003. Extended
gloss overlaps as a measure of semantic relatedness.
In Proceedings of the 18th International Joint Confer-
ence on Artificial Intelligence, pages 805–810.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Machine
Learning Research, 3.
Samuel Brody, Roberto Navigli, and Mirella Lapata.
2006. Ensemble methods for unsupervised wsd. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meeting
of the ACL.
Jun Fu Cai, Wee Sun Lee, and Yee Whye Teh. 2007.
Improving word sense disambiguation using topic fea-
tures. In Proceedings of the 2007 Joint Conference on
Empirical Methods in Natural Language Processing
and Computational Natural Language Learning.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press.
Thomas L. Griffiths and Mark Steyvers. 2004. Find-
ing scientific topics. Proceedings of the National
Academy of Sciences, 101.
Weiwei Guo and Mona Diab. 2010. Combining orthogo-
nal monolingual and multilingual sources of evidence
for all words wsd. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics.
Weiwei Guo and Mona Diab. 2011. Semantic topic mod-
els: Combining word distributional statistics and dic-
tionary definitions. In Proceedings of the 2011 Con-
ference on Empirical Methods in Natural Language
Processing.
Weiwei Guo and Mona Diab. 2012. Modeling sentences
in the latent space. In Proceedings of the 50th Annual
Meeting of the Association for Computational Linguis-
tics.
Jay J. Jiang and David W. Conrath. 1997. Finding pre-
dominant word senses in untagged text. In Proceed-
ings of International Conference Research on Compu-
tational Linguistics.
Linlin Li, Benjamin Roth, and Caroline Sporleder. 2010.
Topic models for word sense disambiguation and
token-based idiom detection. In Proceedings of the
48th Annual Meeting of the Association for Computa-
tional Linguistics.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2004. Finding predominant word senses in
untagged text. In Proceedings of the 42nd Meeting of
the Association for Computational Linguistics.
Rada Mihalcea. 2005. Unsupervised large-vocabulary
word sense disambiguation with graph-based algo-
rithms for sequence data labeling. In Proceedings of
the Joint Conference on Human Language Technology
and Empirical Methods in Natural Language Process-
ing, pages 411–418.
Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. Wordnet::similarity - measuring the re-
latedness of concepts. In Proceedings of Fifth Annual
Meeting of the North American Chapter of the Associ-
ation for Computational Linguistics.
Ravi Sinha and Rada Mihalcea. 2007. Unsupervised
graph-based word sense disambiguation using mea-
sures of word semantic similarity. In Proceedings of
the IEEE International Conference on Semantic Com-
puting, pages 363–369.
Nathan Srebro and Tommi Jaakkola. 2003. Weighted
low-rank approximations. In Proceedings of the Twen-
tieth International Conference on Machine Learning.
Kristina Toutanova, Dan Klein, Christopher Manning, ,
and Yoram Singer. 2003. Feature-rich part-of-speech
tagging with a cyclic dependency network. In Pro-
ceedings of the 2003 Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics on Human Language Technology.
</reference>
<page confidence="0.998555">
144
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.649635">
<title confidence="0.999992">Learning the Latent Semantics of a Concept from its Definition</title>
<author confidence="0.999847">Weiwei Guo</author>
<affiliation confidence="0.99975">Department of Computer Science, Columbia University,</affiliation>
<address confidence="0.997566">New York, NY, USA</address>
<email confidence="0.99933">weiwei@cs.columbia.edu</email>
<author confidence="0.948459">Mona</author>
<affiliation confidence="0.999238">Center for Computational Learning</affiliation>
<address confidence="0.944858">Columbia</address>
<author confidence="0.730047">New York</author>
<author confidence="0.730047">NY</author>
<email confidence="0.999682">mdiab@ccls.columbia.edu</email>
<abstract confidence="0.997625363636364">In this paper we study unsupervised word sense disambiguation (WSD) based on sense definition. We learn low-dimensional latent semantic vectors of concept definitions to construct a more robust sense similarity measure Experiments on four all-words WSD data sets show significant improvement over the baseline WSD systems and LDA based similarity measures, achieving results comparable to state of the art WSD systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>Proceedings of personalizing pagerank for word sense disambiguation.</title>
<date>2009</date>
<booktitle>In the 12th Conference of the European Chapter of the ACL.</booktitle>
<contexts>
<context position="14863" citStr="Agirre and Soroa, 2009" startWordPosition="2561" endWordPosition="2564">on nouns and verbs. Therefore to beat jcn+elesk, we replace the elesk in jcn+elesk with wmfvec (hence jcn+wmfvec). Similar to (Sinha and Mihalcea, 2007), we normalize wmfvec similarity such that values greater than 400 are set to 1, and the rest values are mapped to [0,1]. We choose the value 400 based on the WSD performance on tuning set SE2. As expected, the resulting jcn+wmfvec can further improve jcn+elesk for all cases. Moreover, jcn+wmfvec produces similar results to stateof-the-art unsupervised systems on SE02, 61.92% F-mearure in (Guo and Diab, 2010) using WN1.7.1, and SE03, 57.4% in (Agirre and Soroa, 2009) using WN1.7. It shows wmfvec is robust that it not only performs very well individually, but also can be easily incorporated with existing evidence as represented using jcn. dim SE2 SE3 SE07 Semcor 50 57.4 - 60.5 52.9 - 54.9 43.1 - 44.2 57.90 - 58.99 75 57.8 - 60.3 53.5 - 55.2 43.3 - 44.6 58.12 - 59.07 100 58.6 - 60.5 53.5 - 55.8 43.7 - 45.1 58.17 - 59.10 125 58.2 - 60.2 53.9 - 55.5 43.7 - 45.1 58.26 - 59.19 150 58.2 - 59.8 53.6 - 54.6 44.4 - 45.9 58.13 - 59.15 Table 3: ldavec and wmfvec (latter) results per # of dimensions 4.1 Discussion We look closely into WSD results to obtain an intuitiv</context>
</contexts>
<marker>Agirre, Soroa, 2009</marker>
<rawString>Eneko Agirre and Aitor Soroa. 2009. Proceedings of personalizing pagerank for word sense disambiguation. In the 12th Conference of the European Chapter of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>Extended gloss overlaps as a measure of semantic relatedness.</title>
<date>2003</date>
<booktitle>In Proceedings of the 18th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>805--810</pages>
<contexts>
<context position="1461" citStr="Banerjee and Pedersen, 2003" startWordPosition="211" endWordPosition="215"> score given two senses. Many similarity measures use the taxonomy structure of WordNet [WN] (Fellbaum, 1998), which allows only noun-noun and verb-verb pair similarity computation since the other parts of speech (adjectives and adverbs) do not have a taxonomic representation structure. For example, the jcn similarity measure (Jiang and Conrath, 1997) computes the sense pair similarity score based on the information content of three senses: the two senses and their least common subsumer in the noun/verb hierarchy. The most popular sense similarity measure is the Extended Lesk [elesk] measure (Banerjee and Pedersen, 2003). In elesk, the similarity score is computed based on the length of overlapping words/phrases between two extended dictionary definitions. The definitions are extended by definitions of neighbor senses to discover more overlapping words. However, exact word matching is lossy. Below are two definitions from WN: bank#n#1: a financial institution that accepts deposits and channels the money into lending activities stock#n#1: the capital raised by a corporation through the issue of shares entitling holders to an ownership interest (equity) Despite the high semantic relatedness of the two senses, t</context>
</contexts>
<marker>Banerjee, Pedersen, 2003</marker>
<rawString>Satanjeev Banerjee and Ted Pedersen. 2003. Extended gloss overlaps as a measure of semantic relatedness. In Proceedings of the 18th International Joint Conference on Artificial Intelligence, pages 805–810.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>3</volume>
<contexts>
<context position="2514" citStr="Blei et al., 2003" startWordPosition="375" endWordPosition="378">al raised by a corporation through the issue of shares entitling holders to an ownership interest (equity) Despite the high semantic relatedness of the two senses, the overlapping words in the two definitions are only a, the, leading to a very low similarity score. Accordingly we are interested in extracting latent semantics from sense definitions to improve elesk. However, the challenge lies in that sense definitions are typically too short/sparse for latent variable models to learn accurate semantics, since these models are designed for long documents. For example, topic models such as LDA (Blei et al., 2003), can only find the dominant topic based on the observed words in a definition (financial topic in bank#n#1 and stock#n#1) without further discernibility. In this case, many senses will share the same latent semantics profile, as long as they are in the same topic/domain. To solve the sparsity issue we use missing words as negative evidence of latent semantics, as in (Guo and Diab, 2012). We define missing words of a sense definition as the whole vocabulary in a corpus minus the observed words in the sense definition. Since observed words in definitions are too few to reveal the semantics of s</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Roberto Navigli</author>
<author>Mirella Lapata</author>
</authors>
<title>Ensemble methods for unsupervised wsd.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="16206" citStr="Brody et al., 2006" startWordPosition="2806" endWordPosition="2809">a gene called p53 could transform normal cells into cancerous ones... elesk returns the wrong sense computer device, due to the sparsity of overlapping words between definitions of animal mouse and the context words. wmfvec chooses the correct sense animal mouse, by recognizing the biology element of animal mouse and related context words gene, cell, cancerous. 5 Related Work Sense similarity measures have been the core component in many unsupervised WSD systems and lexical semantics research/applications. To date, elesk is the most popular such measure (McCarthy et al., 2004; Mihalcea, 2005; Brody et al., 2006). Sometimes people use jcn to obtain similarity of noun-noun and verb-verb pairs (Sinha and Mihalcea, 2007; Guo and Diab, 2010). Our similarity measure wmfvec exploits the same information (sense definitions) elesk and ldavec use, and outperforms them significantly on four standardized data sets. To our best knowledge, we are the first to construct a sense similarity by latent semantics of sense definitions. 6 Conclusions We construct a sense similarity wmfvec from the latent semantics of sense definitions. Experiment results show wmfvec significantly outperforms previous definition-based simi</context>
</contexts>
<marker>Brody, Navigli, Lapata, 2006</marker>
<rawString>Samuel Brody, Roberto Navigli, and Mirella Lapata. 2006. Ensemble methods for unsupervised wsd. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Fu Cai</author>
<author>Wee Sun Lee</author>
<author>Yee Whye Teh</author>
</authors>
<title>Improving word sense disambiguation using topic features.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</booktitle>
<contexts>
<context position="13393" citStr="Cai et al., 2007" startWordPosition="2322" endWordPosition="2325">d by averaging over the last 10 sampling iterations. We also set a threshold to elesk similarity values, which yields better performance. Same as (Sinha and Mihalcea, 2007), values of elesk larger than 240 are set to 1, and the rest are mapped to [0,1]. elesk vs wmfvec: wmfvec outperforms elesk consistently in all POS cases (noun, adjective, adverb and verb) on four datasets by a large margin (2.9% − 4.5% in total case). Observing the results yielded per POS, we find a large improvement comes from nouns. Same trend has been reported in other distributional methods based on word co-occurrence (Cai et al., 2007; Li et al., 2010; Guo and Diab, 2011). More interestingly, wmfvec also improves verbs accuracy significantly. ldavec vs wmfvec: ldavec also performs very well, again proving the superiority of latent semantics over surface words matching. However, wmfvec also outperforms ldavec in every POS case except Semcor adverbs (at least +1% in total case). We observe the trend is consistent in Table 3 where different dimensions are used for ldavec and wmfvec. These results show that given the same text data, WMF outperforms LDA on modeling latent semantics of senses by exploiting missing words. jcn+ele</context>
</contexts>
<marker>Cai, Lee, Teh, 2007</marker>
<rawString>Jun Fu Cai, Wee Sun Lee, and Yee Whye Teh. 2007. Improving word sense disambiguation using topic features. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="942" citStr="Fellbaum, 1998" startWordPosition="136" endWordPosition="137">d word sense disambiguation (WSD) based on sense definition. We learn low-dimensional latent semantic vectors of concept definitions to construct a more robust sense similarity measure wmfvec. Experiments on four all-words WSD data sets show significant improvement over the baseline WSD systems and LDA based similarity measures, achieving results comparable to state of the art WSD systems. 1 Introduction To date, many unsupervised WSD systems rely on a sense similarity module that returns a similarity score given two senses. Many similarity measures use the taxonomy structure of WordNet [WN] (Fellbaum, 1998), which allows only noun-noun and verb-verb pair similarity computation since the other parts of speech (adjectives and adverbs) do not have a taxonomic representation structure. For example, the jcn similarity measure (Jiang and Conrath, 1997) computes the sense pair similarity score based on the information content of three senses: the two senses and their least common subsumer in the noun/verb hierarchy. The most popular sense similarity measure is the Extended Lesk [elesk] measure (Banerjee and Pedersen, 2003). In elesk, the similarity score is computed based on the length of overlapping w</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<pages>101</pages>
<contexts>
<context position="10377" citStr="Griffiths and Steyvers, 2004" startWordPosition="1782" endWordPosition="1785"> similarity. The final answer is chosen as the sense with maximum indegree. Using the Indegree algorithm allows us to easily replace the sense similarity with wmfvec. In Indegree, two senses are connected if their words are within a local window. We use the optimal window size of 6 tested in (Sinha and Mihalcea, 2007; Guo and Diab, 2010). Baselines: We compare with (1) elesk, the most widely used sense similarity. We use the implementation in (Pedersen et al., 2004). We believe WMF is a better approach to model latent semantics than LDA, hence the second baseline (2) LDA using Gibbs sampling (Griffiths and Steyvers, 2004). However, we cannot directly use estimated topic distribution P(zld) to represent the definition since it only has non-zero values on one or two topics. Instead, we calculate the latent vec2http://en.wiktionary.org/ Data Model Total Noun Adj Adv Verb SE2 random 40.7 43.9 43.6 58.2 21.6 elesk 56.0 63.5 63.9 62.1 30.8 ldavec 58.6 68.6 60.2 66.1 33.2 wmfvec 60.5 69.7 64.5 67.1 34.9 jcn+elesk 60.1 69.3 63.9 62.8 37.1 jcn+wmfvec 62.1 70.8 64.5 67.1 39.9 SE3 random 33.5 39.9 44.1 - 33.5 elesk 52.3 58.5 57.7 - 41.4 ldavec 53.5 58.1 60.8 - 43.7 wmfvec 55.8 61.5 64.4 - 43.9 jcn+elesk 55.4 60.5 57.7 - </context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences, 101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Guo</author>
<author>Mona Diab</author>
</authors>
<title>Combining orthogonal monolingual and multilingual sources of evidence for all words wsd.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="9621" citStr="Guo and Diab, 2010" startWordPosition="1651" endWordPosition="1654">o not link the senses across dictionaries, hence Wik is only used as augmented data for WMF to better learn the semantics of words. All data is tokenized, POS tagged (Toutanova et al., 2003) and lemmatized, resulting in 341,557 sense definitions and 3,563,649 words. WSD Algorithm: To perform WSD we need two components: (1) a sense similarity measure that returns a similarity score given two senses; (2) a disambiguation algorithm that determines which senses to choose as final answers based on the sense pair similarity scores. We choose the Indegree algorithm used in (Sinha and Mihalcea, 2007; Guo and Diab, 2010) as our disambiguation algorithm. Itis a graphbased algorithm, where nodes are senses, and edge weight equals to the sense pair similarity. The final answer is chosen as the sense with maximum indegree. Using the Indegree algorithm allows us to easily replace the sense similarity with wmfvec. In Indegree, two senses are connected if their words are within a local window. We use the optimal window size of 6 tested in (Sinha and Mihalcea, 2007; Guo and Diab, 2010). Baselines: We compare with (1) elesk, the most widely used sense similarity. We use the implementation in (Pedersen et al., 2004). W</context>
<context position="14804" citStr="Guo and Diab, 2010" startWordPosition="2551" endWordPosition="2554">g wmfvec solely is sometimes outperformed by jcn+elesk on nouns and verbs. Therefore to beat jcn+elesk, we replace the elesk in jcn+elesk with wmfvec (hence jcn+wmfvec). Similar to (Sinha and Mihalcea, 2007), we normalize wmfvec similarity such that values greater than 400 are set to 1, and the rest values are mapped to [0,1]. We choose the value 400 based on the WSD performance on tuning set SE2. As expected, the resulting jcn+wmfvec can further improve jcn+elesk for all cases. Moreover, jcn+wmfvec produces similar results to stateof-the-art unsupervised systems on SE02, 61.92% F-mearure in (Guo and Diab, 2010) using WN1.7.1, and SE03, 57.4% in (Agirre and Soroa, 2009) using WN1.7. It shows wmfvec is robust that it not only performs very well individually, but also can be easily incorporated with existing evidence as represented using jcn. dim SE2 SE3 SE07 Semcor 50 57.4 - 60.5 52.9 - 54.9 43.1 - 44.2 57.90 - 58.99 75 57.8 - 60.3 53.5 - 55.2 43.3 - 44.6 58.12 - 59.07 100 58.6 - 60.5 53.5 - 55.8 43.7 - 45.1 58.17 - 59.10 125 58.2 - 60.2 53.9 - 55.5 43.7 - 45.1 58.26 - 59.19 150 58.2 - 59.8 53.6 - 54.6 44.4 - 45.9 58.13 - 59.15 Table 3: ldavec and wmfvec (latter) results per # of dimensions 4.1 Discus</context>
<context position="16333" citStr="Guo and Diab, 2010" startWordPosition="2826" endWordPosition="2829"> sparsity of overlapping words between definitions of animal mouse and the context words. wmfvec chooses the correct sense animal mouse, by recognizing the biology element of animal mouse and related context words gene, cell, cancerous. 5 Related Work Sense similarity measures have been the core component in many unsupervised WSD systems and lexical semantics research/applications. To date, elesk is the most popular such measure (McCarthy et al., 2004; Mihalcea, 2005; Brody et al., 2006). Sometimes people use jcn to obtain similarity of noun-noun and verb-verb pairs (Sinha and Mihalcea, 2007; Guo and Diab, 2010). Our similarity measure wmfvec exploits the same information (sense definitions) elesk and ldavec use, and outperforms them significantly on four standardized data sets. To our best knowledge, we are the first to construct a sense similarity by latent semantics of sense definitions. 6 Conclusions We construct a sense similarity wmfvec from the latent semantics of sense definitions. Experiment results show wmfvec significantly outperforms previous definition-based similarity measures and LDA vectors on four all-words WSD data sets. Acknowledgments This research was funded by the Office of the </context>
</contexts>
<marker>Guo, Diab, 2010</marker>
<rawString>Weiwei Guo and Mona Diab. 2010. Combining orthogonal monolingual and multilingual sources of evidence for all words wsd. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Guo</author>
<author>Mona Diab</author>
</authors>
<title>Semantic topic models: Combining word distributional statistics and dictionary definitions.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="13431" citStr="Guo and Diab, 2011" startWordPosition="2330" endWordPosition="2333">pling iterations. We also set a threshold to elesk similarity values, which yields better performance. Same as (Sinha and Mihalcea, 2007), values of elesk larger than 240 are set to 1, and the rest are mapped to [0,1]. elesk vs wmfvec: wmfvec outperforms elesk consistently in all POS cases (noun, adjective, adverb and verb) on four datasets by a large margin (2.9% − 4.5% in total case). Observing the results yielded per POS, we find a large improvement comes from nouns. Same trend has been reported in other distributional methods based on word co-occurrence (Cai et al., 2007; Li et al., 2010; Guo and Diab, 2011). More interestingly, wmfvec also improves verbs accuracy significantly. ldavec vs wmfvec: ldavec also performs very well, again proving the superiority of latent semantics over surface words matching. However, wmfvec also outperforms ldavec in every POS case except Semcor adverbs (at least +1% in total case). We observe the trend is consistent in Table 3 where different dimensions are used for ldavec and wmfvec. These results show that given the same text data, WMF outperforms LDA on modeling latent semantics of senses by exploiting missing words. jcn+elesk vs jcn+wmfvec: jcn+elesk is a very </context>
</contexts>
<marker>Guo, Diab, 2011</marker>
<rawString>Weiwei Guo and Mona Diab. 2011. Semantic topic models: Combining word distributional statistics and dictionary definitions. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Guo</author>
<author>Mona Diab</author>
</authors>
<title>Modeling sentences in the latent space.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2904" citStr="Guo and Diab, 2012" startWordPosition="442" endWordPosition="445">e lies in that sense definitions are typically too short/sparse for latent variable models to learn accurate semantics, since these models are designed for long documents. For example, topic models such as LDA (Blei et al., 2003), can only find the dominant topic based on the observed words in a definition (financial topic in bank#n#1 and stock#n#1) without further discernibility. In this case, many senses will share the same latent semantics profile, as long as they are in the same topic/domain. To solve the sparsity issue we use missing words as negative evidence of latent semantics, as in (Guo and Diab, 2012). We define missing words of a sense definition as the whole vocabulary in a corpus minus the observed words in the sense definition. Since observed words in definitions are too few to reveal the semantics of senses, missing words can be used to tell the model what the definition is not about. Therefore, we want to find a latent semantics profile that is related to observed words in a definition, but also not related to missing words, so that the induced latent semantics is unique for the sense. Finally we also show how to use WN neighbor sense definitions to construct a nuanced sense similari</context>
</contexts>
<marker>Guo, Diab, 2012</marker>
<rawString>Weiwei Guo and Mona Diab. 2012. Modeling sentences in the latent space. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay J Jiang</author>
<author>David W Conrath</author>
</authors>
<title>Finding predominant word senses in untagged text.</title>
<date>1997</date>
<booktitle>In Proceedings of International Conference Research on Computational Linguistics.</booktitle>
<contexts>
<context position="1186" citStr="Jiang and Conrath, 1997" startWordPosition="169" endWordPosition="172">s show significant improvement over the baseline WSD systems and LDA based similarity measures, achieving results comparable to state of the art WSD systems. 1 Introduction To date, many unsupervised WSD systems rely on a sense similarity module that returns a similarity score given two senses. Many similarity measures use the taxonomy structure of WordNet [WN] (Fellbaum, 1998), which allows only noun-noun and verb-verb pair similarity computation since the other parts of speech (adjectives and adverbs) do not have a taxonomic representation structure. For example, the jcn similarity measure (Jiang and Conrath, 1997) computes the sense pair similarity score based on the information content of three senses: the two senses and their least common subsumer in the noun/verb hierarchy. The most popular sense similarity measure is the Extended Lesk [elesk] measure (Banerjee and Pedersen, 2003). In elesk, the similarity score is computed based on the length of overlapping words/phrases between two extended dictionary definitions. The definitions are extended by definitions of neighbor senses to discover more overlapping words. However, exact word matching is lossy. Below are two definitions from WN: bank#n#1: a f</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jay J. Jiang and David W. Conrath. 1997. Finding predominant word senses in untagged text. In Proceedings of International Conference Research on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linlin Li</author>
<author>Benjamin Roth</author>
<author>Caroline Sporleder</author>
</authors>
<title>Topic models for word sense disambiguation and token-based idiom detection.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="13410" citStr="Li et al., 2010" startWordPosition="2326" endWordPosition="2329">r the last 10 sampling iterations. We also set a threshold to elesk similarity values, which yields better performance. Same as (Sinha and Mihalcea, 2007), values of elesk larger than 240 are set to 1, and the rest are mapped to [0,1]. elesk vs wmfvec: wmfvec outperforms elesk consistently in all POS cases (noun, adjective, adverb and verb) on four datasets by a large margin (2.9% − 4.5% in total case). Observing the results yielded per POS, we find a large improvement comes from nouns. Same trend has been reported in other distributional methods based on word co-occurrence (Cai et al., 2007; Li et al., 2010; Guo and Diab, 2011). More interestingly, wmfvec also improves verbs accuracy significantly. ldavec vs wmfvec: ldavec also performs very well, again proving the superiority of latent semantics over surface words matching. However, wmfvec also outperforms ldavec in every POS case except Semcor adverbs (at least +1% in total case). We observe the trend is consistent in Table 3 where different dimensions are used for ldavec and wmfvec. These results show that given the same text data, WMF outperforms LDA on modeling latent semantics of senses by exploiting missing words. jcn+elesk vs jcn+wmfvec:</context>
</contexts>
<marker>Li, Roth, Sporleder, 2010</marker>
<rawString>Linlin Li, Benjamin Roth, and Caroline Sporleder. 2010. Topic models for word sense disambiguation and token-based idiom detection. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Finding predominant word senses in untagged text.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="16169" citStr="McCarthy et al., 2004" startWordPosition="2800" endWordPosition="2803">ext: ... in experiments with mice that a gene called p53 could transform normal cells into cancerous ones... elesk returns the wrong sense computer device, due to the sparsity of overlapping words between definitions of animal mouse and the context words. wmfvec chooses the correct sense animal mouse, by recognizing the biology element of animal mouse and related context words gene, cell, cancerous. 5 Related Work Sense similarity measures have been the core component in many unsupervised WSD systems and lexical semantics research/applications. To date, elesk is the most popular such measure (McCarthy et al., 2004; Mihalcea, 2005; Brody et al., 2006). Sometimes people use jcn to obtain similarity of noun-noun and verb-verb pairs (Sinha and Mihalcea, 2007; Guo and Diab, 2010). Our similarity measure wmfvec exploits the same information (sense definitions) elesk and ldavec use, and outperforms them significantly on four standardized data sets. To our best knowledge, we are the first to construct a sense similarity by latent semantics of sense definitions. 6 Conclusions We construct a sense similarity wmfvec from the latent semantics of sense definitions. Experiment results show wmfvec significantly outpe</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll. 2004. Finding predominant word senses in untagged text. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>Unsupervised large-vocabulary word sense disambiguation with graph-based algorithms for sequence data labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the Joint Conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>411--418</pages>
<contexts>
<context position="16185" citStr="Mihalcea, 2005" startWordPosition="2804" endWordPosition="2805"> with mice that a gene called p53 could transform normal cells into cancerous ones... elesk returns the wrong sense computer device, due to the sparsity of overlapping words between definitions of animal mouse and the context words. wmfvec chooses the correct sense animal mouse, by recognizing the biology element of animal mouse and related context words gene, cell, cancerous. 5 Related Work Sense similarity measures have been the core component in many unsupervised WSD systems and lexical semantics research/applications. To date, elesk is the most popular such measure (McCarthy et al., 2004; Mihalcea, 2005; Brody et al., 2006). Sometimes people use jcn to obtain similarity of noun-noun and verb-verb pairs (Sinha and Mihalcea, 2007; Guo and Diab, 2010). Our similarity measure wmfvec exploits the same information (sense definitions) elesk and ldavec use, and outperforms them significantly on four standardized data sets. To our best knowledge, we are the first to construct a sense similarity by latent semantics of sense definitions. 6 Conclusions We construct a sense similarity wmfvec from the latent semantics of sense definitions. Experiment results show wmfvec significantly outperforms previous </context>
</contexts>
<marker>Mihalcea, 2005</marker>
<rawString>Rada Mihalcea. 2005. Unsupervised large-vocabulary word sense disambiguation with graph-based algorithms for sequence data labeling. In Proceedings of the Joint Conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 411–418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>Wordnet::similarity - measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Proceedings of Fifth Annual Meeting of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="10218" citStr="Pedersen et al., 2004" startWordPosition="1755" endWordPosition="1758">2007; Guo and Diab, 2010) as our disambiguation algorithm. Itis a graphbased algorithm, where nodes are senses, and edge weight equals to the sense pair similarity. The final answer is chosen as the sense with maximum indegree. Using the Indegree algorithm allows us to easily replace the sense similarity with wmfvec. In Indegree, two senses are connected if their words are within a local window. We use the optimal window size of 6 tested in (Sinha and Mihalcea, 2007; Guo and Diab, 2010). Baselines: We compare with (1) elesk, the most widely used sense similarity. We use the implementation in (Pedersen et al., 2004). We believe WMF is a better approach to model latent semantics than LDA, hence the second baseline (2) LDA using Gibbs sampling (Griffiths and Steyvers, 2004). However, we cannot directly use estimated topic distribution P(zld) to represent the definition since it only has non-zero values on one or two topics. Instead, we calculate the latent vec2http://en.wiktionary.org/ Data Model Total Noun Adj Adv Verb SE2 random 40.7 43.9 43.6 58.2 21.6 elesk 56.0 63.5 63.9 62.1 30.8 ldavec 58.6 68.6 60.2 66.1 33.2 wmfvec 60.5 69.7 64.5 67.1 34.9 jcn+elesk 60.1 69.3 63.9 62.8 37.1 jcn+wmfvec 62.1 70.8 64</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004. Wordnet::similarity - measuring the relatedness of concepts. In Proceedings of Fifth Annual Meeting of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Sinha</author>
<author>Rada Mihalcea</author>
</authors>
<title>Unsupervised graph-based word sense disambiguation using measures of word semantic similarity.</title>
<date>2007</date>
<booktitle>In Proceedings of the IEEE International Conference on Semantic Computing,</booktitle>
<pages>363--369</pages>
<contexts>
<context position="9600" citStr="Sinha and Mihalcea, 2007" startWordPosition="1647" endWordPosition="1650">nd Wiktionary [Wik].2 We do not link the senses across dictionaries, hence Wik is only used as augmented data for WMF to better learn the semantics of words. All data is tokenized, POS tagged (Toutanova et al., 2003) and lemmatized, resulting in 341,557 sense definitions and 3,563,649 words. WSD Algorithm: To perform WSD we need two components: (1) a sense similarity measure that returns a similarity score given two senses; (2) a disambiguation algorithm that determines which senses to choose as final answers based on the sense pair similarity scores. We choose the Indegree algorithm used in (Sinha and Mihalcea, 2007; Guo and Diab, 2010) as our disambiguation algorithm. Itis a graphbased algorithm, where nodes are senses, and edge weight equals to the sense pair similarity. The final answer is chosen as the sense with maximum indegree. Using the Indegree algorithm allows us to easily replace the sense similarity with wmfvec. In Indegree, two senses are connected if their words are within a local window. We use the optimal window size of 6 tested in (Sinha and Mihalcea, 2007; Guo and Diab, 2010). Baselines: We compare with (1) elesk, the most widely used sense similarity. We use the implementation in (Pede</context>
<context position="11841" citStr="Sinha and Mihalcea, 2007" startWordPosition="2047" endWordPosition="2050">.90 20.08 elesk 55.43 61.04 69.30 62.85 43.36 ldavec 58.17 63.15 70.08 67.97 46.91 wmfvec 59.10 64.64 71.44 67.05 47.52 jcn+elesk 61.61 69.61 69.30 62.85 50.72 jcn+wmfvec 63.05 70.64 71.45 67.05 51.72 Table 2: WSD results per POS (K = 100) tor of a definition by summing up the P(zlw) of all constituent words weighted by Xij, which gives much better WSD results.3 We produce LDA vectors [ldavec] in the same setting as wmfvec, which means it is trained on the same corpus, uses WN neighbors, and is tuned on SE2. At last, we compare wmfvec with a mature WSD system based on sense similarities, (3) (Sinha and Mihalcea, 2007) [jcn+elesk], where they evaluate six sense similarities, select the best of them and combine them into one system. Specifically, in their implementation they use jcn for noun-noun and verbverb pairs, and elesk for other pairs. (Sinha and Mihalcea, 2007) used to be the state-of-the-art system on SE2 and SE3. 4 Experiment Results The disambiguation results (K = 100) are summarized in Table 2. We also present in Table 3 results using other values of dimensions K for wmfvec and ldavec. There are very few words that are not covered due to failure of lemmatization or POS tag mismatches, thereby F-m</context>
<context position="14392" citStr="Sinha and Mihalcea, 2007" startWordPosition="2482" endWordPosition="2485">consistent in Table 3 where different dimensions are used for ldavec and wmfvec. These results show that given the same text data, WMF outperforms LDA on modeling latent semantics of senses by exploiting missing words. jcn+elesk vs jcn+wmfvec: jcn+elesk is a very mature WSD system that takes advantage of the great performance of jcn on noun-noun and verb-verb pairs. Although wmfvec does much better than elesk, using wmfvec solely is sometimes outperformed by jcn+elesk on nouns and verbs. Therefore to beat jcn+elesk, we replace the elesk in jcn+elesk with wmfvec (hence jcn+wmfvec). Similar to (Sinha and Mihalcea, 2007), we normalize wmfvec similarity such that values greater than 400 are set to 1, and the rest values are mapped to [0,1]. We choose the value 400 based on the WSD performance on tuning set SE2. As expected, the resulting jcn+wmfvec can further improve jcn+elesk for all cases. Moreover, jcn+wmfvec produces similar results to stateof-the-art unsupervised systems on SE02, 61.92% F-mearure in (Guo and Diab, 2010) using WN1.7.1, and SE03, 57.4% in (Agirre and Soroa, 2009) using WN1.7. It shows wmfvec is robust that it not only performs very well individually, but also can be easily incorporated wit</context>
<context position="16312" citStr="Sinha and Mihalcea, 2007" startWordPosition="2822" endWordPosition="2825">omputer device, due to the sparsity of overlapping words between definitions of animal mouse and the context words. wmfvec chooses the correct sense animal mouse, by recognizing the biology element of animal mouse and related context words gene, cell, cancerous. 5 Related Work Sense similarity measures have been the core component in many unsupervised WSD systems and lexical semantics research/applications. To date, elesk is the most popular such measure (McCarthy et al., 2004; Mihalcea, 2005; Brody et al., 2006). Sometimes people use jcn to obtain similarity of noun-noun and verb-verb pairs (Sinha and Mihalcea, 2007; Guo and Diab, 2010). Our similarity measure wmfvec exploits the same information (sense definitions) elesk and ldavec use, and outperforms them significantly on four standardized data sets. To our best knowledge, we are the first to construct a sense similarity by latent semantics of sense definitions. 6 Conclusions We construct a sense similarity wmfvec from the latent semantics of sense definitions. Experiment results show wmfvec significantly outperforms previous definition-based similarity measures and LDA vectors on four all-words WSD data sets. Acknowledgments This research was funded </context>
</contexts>
<marker>Sinha, Mihalcea, 2007</marker>
<rawString>Ravi Sinha and Rada Mihalcea. 2007. Unsupervised graph-based word sense disambiguation using measures of word semantic similarity. In Proceedings of the IEEE International Conference on Semantic Computing, pages 363–369.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Nathan Srebro</author>
<author>Tommi Jaakkola</author>
</authors>
<title>Weighted low-rank approximations.</title>
<date>2003</date>
<booktitle>In Proceedings of the Twentieth International Conference on Machine Learning. Kristina Toutanova,</booktitle>
<location>Dan Klein, Christopher</location>
<contexts>
<context position="5662" citStr="Srebro and Jaakkola, 2003" startWordPosition="923" endWordPosition="926">elated to institution. It has a slightly smaller Rv2 o = 18, but more importantly, its relatedness to missing words, Rv2m = 300, is substantially smaller than Rv1m = 600. However, we cannot simply choose a hypothesis with the maximum Ro − Rm value, since v3, which is clearly not related to bank#n#1 but with a minimum Rm = 100, will therefore be (erroneously) returned as the answer. The solution is straightforward: give a smaller weight to missing words, e.g., so that the algorithm tries to select a hypothesis with maximum value of Ro − 0.01 x Rm. We choose weighted matrix factorization [WMF] (Srebro and Jaakkola, 2003) to implement this idea. 2.2 Modeling Missing Words by Weighted Matrix Factorization We represent the corpus of WN definitions as an M x N matrix X, where row entries are M unique words existing in WN definitions, and columns represent N WN sense ids. The cell Xij records the TF-IDF value of word wi appearing in definition of sense sj. In WMF, the original matrix X is factorized into two matrices such that X ,. PTQ, where P is a K x M matrix, and Q is a K x N matrix. In this scenario, the latent semantics of each word wi or sense sj is represented as a K-dimension vector P·,i or Q·,j respectiv</context>
<context position="8352" citStr="Srebro and Jaakkola, 2003" startWordPosition="1438" endWordPosition="1441">itions of its neighbor senses. Also, they do not normalize the length. In our case, we also adopt these two ideas: (1) a sense is represented by the sum of its original latent vector and its neighbors’ latent vectors. Let N(j) be the set of neighbor senses of sense j. then new latent vector is: Qnew ·,j = Q·,j + Ek EN(j) Q·,k (2) Inner product (instead of cosine similarity) of the two resulting sense vectors is treated as the sense pair similarity. We refer to our sense similarity measure as wmfvec. 1Due to limited space inference and update rules for P and Q are omitted, but can be found in (Srebro and Jaakkola, 2003) λ||P||22 + λ||Q||22 i j 141 3 Experiment Setting Task: We choose the fine-grained All-Words Sense Disambiguation task, where systems are required to disambiguate all the content words (noun, adjective, adverb and verb) in documents. The data sets we use are all-words tasks in SENSEVAL2 [SE2], SENSEVAL3 [SE3], SEMEVAL-2007 [SE07], and Semcor. We tune the parameters in wmfvec and other baselines based on SE2, and then directly apply the tuned models on other three data sets. Data: The sense inventory is WN3.0 for the four WSD data sets. WMF and LDA are built on the corpus of sense definitions o</context>
</contexts>
<marker>Srebro, Jaakkola, 2003</marker>
<rawString>Nathan Srebro and Tommi Jaakkola. 2003. Weighted low-rank approximations. In Proceedings of the Twentieth International Conference on Machine Learning. Kristina Toutanova, Dan Klein, Christopher Manning, , and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>