<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001784">
<title confidence="0.981368">
A Corpus of Scope-disambiguated English Text
</title>
<author confidence="0.998595">
Mehdi Manshadi, James Allen, Mary Swift
</author>
<affiliation confidence="0.999653">
Department of Computer Science, University of Rochester
</affiliation>
<address confidence="0.766469">
Rochester, NY, 14627, USA
</address>
<email confidence="0.999694">
{mehdih,james,swift}@cs.rochester.edu
</email>
<sectionHeader confidence="0.99338" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.8581025">
Previous work on quantifier scope annotation
focuses on scoping sentences with only two
quantified noun phrases (NPs), where the quan-
tifiers are restricted to a predefined list. It also
ignores negation, modal/logical operators, and
other sentential adverbials. We present a com-
prehensive scope annotation scheme. We anno-
tate the scope interaction between all scopal
terms in the sentence from quantifiers to scopal
adverbials, without putting any restriction on
the number of scopal terms in a sentence. In ad-
dition, all NPs, explicitly quantified or not, with
no restriction on the type of quantification, are
investigated for possible scope interactions.
</bodyText>
<sectionHeader confidence="0.998853" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999969557692308">
Since the early days of natural language under-
standing (NLU), quantifier scope disambiguation
has been an extremely hard task. Therefore, early
NLU systems either devised some mechanism for
leaving the semantic representation underspecified
(Woods 1978, Hobbs and Shieber 1987), or tried to
assign scoping to sentences based on heuristics
(VanLehn 1978, Moran 1988, Alshawi 1992).
There has been a lot of work since then on devel-
oping frameworks for scope-underspecified seman-
tic representations (Alshawi and Crouch 1992, Bos
1996, Copestake et al., 2001, Egg et al., 2001). The
motivation of most recent formalisms is to develop
a constraint-based framework where you can in-
crementally add constraints to filter out unwanted
scopings. However, almost all of these formalisms
are based on hard constraints, which have to be
satisfied in every reading of the sentence. It seems
that the story is different in practice. Most of the
constraints one can hope for (imposed by dis-
course, pragmatics, word knowledge, etc.) are soft
constraints, that is they define a preference over
the possible readings of a sentence. As a result,
statistical methods seem to be well suited for scope
disambiguation.
Surprisingly enough, after two decades of ex-
tensive work on statistical techniques in natural
language processing, there has not been much
work on scope disambiguation (see section 6 for a
review). In addition, as discussed later, this work is
very restricted. It considers sentences with only
two quantifiers, where the quantifiers are picked
from a predefined list. For example, it ignores de-
finites, bare singulars/plurals, and proper nouns, as
well as negations and other scopal operators.
A major reason for the lack of work on statisti-
cal scope disambiguation is the lack of a
comprehensive scope-disambiguated corpus. In
fact, there is not even a standard test set for
evaluation purposes. The reason behind this latter
fact is simple. Scope disambiguation is very hard
even for humans. In fact, our own early effort to
annotate part of the Penn Treebank with full scope
information soon proved to be too ambitious.
Instead, we have picked a domain that covers
many challenging phenomena in scope disam-
biguation, while keeping the scope disambiguation
fairly intuitive. This helps us to build the first
moderately sized corpus of natural language text
with full scope information. By fully scoping a
sentence, we mean to label the scope interaction
between every two scopal elements in that sen-
</bodyText>
<page confidence="0.977565">
141
</page>
<note confidence="0.5843155">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 141–146,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.996830571428571">
tence. We scope all scope-bearing NPs (quantified
or not), negations, logical/modal operators, and
other sentential adverbials. We also annotate plu-
rals with their distributive vs. collective readings.
In addition, we label sentences with coreference
relations because they affect the scope interaction
between NPs.
</bodyText>
<sectionHeader confidence="0.989953" genericHeader="introduction">
2 Domain
</sectionHeader>
<bodyText confidence="0.99994385">
The domain is the description of tasks about edit-
ing plain text files; in other words, a natural lan-
guage interface for text editors such as Linux SED,
AWK, or EMACS programs. Figure (1) gives
some sentences from the corpus. This domain has
several properties that make it a great choice for a
first effort to build a comprehensive scope-
disambiguated corpus.
First, it carries a lot of scope interactions. As
shown in the examples, the domain carries many
quantified NPs. Also, scopal operators such as ne-
gation, and logical operators occur pretty often in
the domain. Second, scope disambiguation is criti-
cal for deep understanding in this domain. Third,
scoping is fairly intuitive, because a conscious
knowledge of scoping is required in order to be
able to accomplish the explained task. This is ex-
actly the key property of this domain that makes
building a comprehensive scope-disambiguated
corpus feasible.
</bodyText>
<sectionHeader confidence="0.999193" genericHeader="method">
3 Corpus
</sectionHeader>
<subsectionHeader confidence="0.99993">
3.1 The core corpus
</subsectionHeader>
<bodyText confidence="0.999874333333333">
The core part of the corpus has been gathered from
three different resources, each making up roughly
one third of the core corpus.
</bodyText>
<listItem confidence="0.989051545454546">
• One liners: These are help documents found on
the web for Linux command-line text editors
such as SED and AWK, giving a description of a
task plus one line of code performing the task.
• Online tutorials: Many other online tutorials on
1. Find an occurrence of the word &amp;quot;TBA&amp;quot; in every
line and remove it from the line.
2. Print a list of the lines that do not start with a
digit or end with a letter.
3. Replace every string &amp;quot;anti&amp;quot; possibly followed by a
hyphen with &amp;quot;not&amp;quot;.
</listItem>
<figureCaption confidence="0.996835">
Figure 1. Some examples from the core corpus
</figureCaption>
<bodyText confidence="0.997601333333333">
using command-line editors and regular expres-
sions exist. Sentences were manually extracted
from examples and exercises in these tutorials.
</bodyText>
<listItem confidence="0.9953934">
• Computer science graduate students: These are
the sentences provided by CS graduate students
describing some of the routine text editing tasks
they often do. The sentences have been provided
by both native and non-native English speakers.
</listItem>
<subsectionHeader confidence="0.996467">
3.2 Expanding corpus with crowd sourcing
</subsectionHeader>
<bodyText confidence="0.999975857142857">
The core corpus was used to get more sentences
using crowd sourcing. We provided input/output
(I/O) examples for each task in the core corpus,
and asked the workers on Mechanical Turk to pro-
vide the description of the task based on the I/O
example(s). Figure (2) shows an example of two
I/O pairs given to the workers in order to get the
description of a single task. The reason for using
two I/O pairs (instead of only one) is that there is
almost always a trivial description for a single I/O
pair. Even with two I/O pairs, we sometimes get
the description of a different task, which happens
to work for the both pairs. For example the original
description for the task given in figure (2) is:
</bodyText>
<listItem confidence="0.935483">
1. Sort all the lines by their second field.
</listItem>
<bodyText confidence="0.942113">
The following descriptions are provided by three
workers based on the given input/output texts:
</bodyText>
<listItem confidence="0.9977296">
2. Sort the lines alphabetically by the values in the 2nd
column.
3. Sort the lines by the first group of letters.
4. Alphabetize each line using the first letter of each
word in the second column.
</listItem>
<bodyText confidence="0.916056142857143">
(3) gives the description of a different task, but it
works for the given I/O pairs. This is not a problem
for us, but actually a case that we would prefer to
happen, because this way, we not only get a variety
of sentences defining the same task, but also obtain
descriptions of new tasks. We can add these new
tasks to the core corpus, label them with new I/O
</bodyText>
<figure confidence="0.985080333333333">
INPUT OUTPUT
1000 NY April 4000 AL June
3000 HU August 3000 HU August
4000 OR May 1000 NY April
4000 AL June 4000 OR May
c josh 21 a adams 23
a adams 23 b john 25
d sam 26 c josh 21
b john 25 d sam 26
</figure>
<figureCaption confidence="0.999727">
Figure 2. Two I/O pairs given for a single task
</figureCaption>
<page confidence="0.987393">
142
</page>
<bodyText confidence="0.999931285714286">
pairs and hence expand the corpus in a bootstrap-
ping fashion.
The data acquired from Mechanical Turk is of-
ten quite noisy, therefore all sentences are re-
viewed manually and tagged with different
categories (e.g. paraphrase of the original descrip-
tion, wrong but coherent description, etc.).
</bodyText>
<subsectionHeader confidence="0.999948">
3.3 Pre-processing the corpus
</subsectionHeader>
<bodyText confidence="0.999983722222222">
The corpus is tokenized and parsed using the Stan-
ford PCFG parser (Klein and Manning 2003). We
guide the parser by giving suggestions on part-of-
speech (POS) tags based on the gold standard POS
tags provided for some classes of words such as
verbs. Shallow NP chunks and negations are auto-
matically extracted from the parse trees and in-
dexed. The resulting NP-chunked sentences are
then reviewed manually, first to fix the chunking
errors, hence providing gold standard chunks, and
second, to add chunks for other scopal operators
such as sentential adverbials since the above auto-
mated approach will not extract those. Figure (3)
shows the examples in figure (1) after chunking.
As shown in these examples, NP chunks are in-
dexed by numbers, negation by the letter ‘N’ fol-
lowed by a number and all other scopal operators
by the letter ‘O’ followed by a number.
</bodyText>
<sectionHeader confidence="0.990001" genericHeader="method">
4 Scope annotation
</sectionHeader>
<bodyText confidence="0.999548666666667">
The chunked sentences are given to the annotators
for scope annotation. Given a pair of chunks i and
j, three kinds of relation could hold between them.
</bodyText>
<listItem confidence="0.9906891">
• Outscoping constraints: represented as (i&gt;j),
which means chunk i outscopes (i.e. has a wider
scope over) chunk j.
• Coreference relations: represented as (i=j). This
could be between a pronoun and its antecedent or
between two nouns.1
• No scope interaction: If a pair is left unscoped, it
means that either there is no scope interaction
between the chunks, or switching the order of the
chunks results in a logically equivalent formula.
</listItem>
<bodyText confidence="0.702896714285714">
The overall scoping is represented as a list of
semicolon-separated constraints. The annotators
1 Bridging anaphora relations are simply represented as out-
scoping relations, because often there is not a clear distinction
between the two. However for theoretical purposes, an out-
scoping constraint (i&gt;j), where i is not accessible to j, is being
understood as a bridging anaphora relation.
</bodyText>
<listItem confidence="0.805444333333333">
1. Find [1/ an instance] of [2/ the word &amp;quot;TBA&amp;quot;] in [3/
every line] and remove [4/ it] from [5/ the line].
(3&gt;1 ; 3=5 ; 1=4) // concise form: (5=3&gt;1=4)
2. Print [1/ a list] of [2/ the lines] that do [N1/ not]
start with [3/ a digit] [O1/ or] end with [4/ a letter].
(2&gt;1 ; 2d&gt;N1&gt;3,4 ; N1&gt;O1) // (i&gt;j,k) ≡ (i&gt;j; i&gt;k)
3. Replace [1/ every string &amp;quot;anti&amp;quot;] [O1/ possibly] fol-
lowed by [2/ a hyphen] with [3/ &amp;quot;not&amp;quot;].
(1&gt;O1&gt;2 ; 1&gt;3)
</listItem>
<figureCaption confidence="0.999192">
Figure 3. Chunked sentences labeled with scopings
</figureCaption>
<bodyText confidence="0.996121">
are allowed to cascade constraints to form a more
concise representation (see Figure 3).
</bodyText>
<subsectionHeader confidence="0.994837">
4.1 Logical equivalence vs. intuitive scoping
</subsectionHeader>
<bodyText confidence="0.999989846153846">
Our early experiments showed that a main source
of inter-annotator disagreement are pairs of chunks
for which, both orderings are logically equivalent
(e.g. two existentials or two universals), but an an-
notator may label them with outscoping constraints
based on his/her intuition. It turns out that the an-
notators’ intuitions are not consistent in these
cases. Even a single annotator does not remain
consistent throughout the data in such cases. Al-
though it does not make any difference in logic,
this shows up as inter-annotator disagreement. In
order to prevent this, annotators were asked to rec-
ognize these cases and leave them unscoped.
</bodyText>
<subsectionHeader confidence="0.941723">
4.2 Plurals
</subsectionHeader>
<bodyText confidence="0.99998755">
Plurals, in general, introduce a major source of
complexity both in formal and computational se-
mantics (Link 1997). From a scope–
disambiguation point of view, the main issue with
plurals come from the fact that they carry two pos-
sible kinds of readings: collective vs. distributive.
We treat plurals as a set of individuals and assume
that the index of a plural NP refers to the set (col-
lective reading). However, we also assume that
every plural potentially carries an implicit univer-
sal quantifier ranging over all elements in the set.
We represent this implicit universal with id (‘d’ for
distributive) where i is the index of the plural NP.
It is important to notice that while most theoretical
papers talk about the collectivity vs. distributivity
distinction at the sentence level, for us the right
treatment is to make this distinction at the con-
straint level. That is, a plural may have a collective
reading in one constraint but a distributive reading
in another, as shown in example 2 in figure (3).
</bodyText>
<page confidence="0.997877">
143
</page>
<subsectionHeader confidence="0.95837">
4.3 Other challenges of scope annotation
</subsectionHeader>
<bodyText confidence="0.999992043478261">
In spite of choosing a specific domain with fairly
intuitive quantifier scoping, the scope annotation
has been a very challenging job. There are several
major sources of difficulty in scope annotation.
First, there has not been much work on corpus-
based study of quantifier scoping. Most work on
quantifier scoping focuses on scoping phenomena,
which may be interesting from theoretical perspec-
tive, but do not occur very often in practice. There-
fore many challenging practical phenomena remain
unexplored. During annotation of the corpus, we
encountered a lot of these phenomena, which we
have tried to generalize and find a reasonable
treatment for. Second, other sources of ambiguity
are likely to show up as scope disagreement. Fi-
nally, very often the disagreement in scoping does
not result from the different interpretations of the
sentence, but the different representations of the
same interpretation. In writing the annotation
scheme, extreme care has been taken to prevent
these spurious disagreements. Technical details of
the annotation scheme are beyond the scope of this
paper. We leave those for a longer paper.
</bodyText>
<sectionHeader confidence="0.995535" genericHeader="method">
5 Statistics
</sectionHeader>
<bodyText confidence="0.999986923076923">
The current corpus contains around 500 sentences
in the core level and 2000 sentences acquired from
crowd sourcing. The number of scopal terms per
sentence is 3.9, out of which 95% are NPs and the
rest are scopal operators. Table (1) shows the per-
centage of different types of NP in the corpus.
The core corpus has already been annotated,
out of which a hundred sentences have been anno-
tated by three annotators in order to measure the
inter-annotator agreement (IAA). Two of the anno-
tators are native English speakers and the third is a
non-native speaker who is fluent in English. All
three have some background in linguistics.
</bodyText>
<subsectionHeader confidence="0.81192">
5.1 Inter-annotator agreement
</subsectionHeader>
<bodyText confidence="0.998389125">
Although coreference relations were labeled in the
corpus, we do not incorporate them in calculating
IAA. This is because, annotating coreference rela-
tions is much easier than scope disambiguation, so
incorporating them favors toward higher IAAs,
which may be deceiving. Furthermore previous
work only considers scope relations and hence we
do the same in order to have a fair comparison.
</bodyText>
<table confidence="0.999508428571429">
Type of NP chunk Percentage
NPs with explicit quantifiers 35%
(including indefinite A)
Definites 27%
Bare singulars/plurals 25%
Pronouns 7%
Proper names (files, variables, etc.) 6%
</table>
<tableCaption confidence="0.999946">
Table 1. Corpus statistics
</tableCaption>
<bodyText confidence="0.999898">
We represent each scoping using a directed graph
over the chunk indices. For every outscoping rela-
tion i&gt;j, node i is connected to node j by the di-
rected edge (i,j). For example, figure (4a)
represents the scoping in (5).
</bodyText>
<listItem confidence="0.504497666666667">
5. Delete [1/ the first character] of [2/ every word]
and [3/ the first word] of [4/ every line] in [5/
the file].
</listItem>
<equation confidence="0.336158">
(5&gt;2&gt;1 ; 5&gt;4&gt;3)
</equation>
<bodyText confidence="0.999130625">
Note that the directed graph must be a DAG (di-
rected acyclic graph), otherwise the scoping is not
valid. In order to be able to measure the similarity
of two DAGs corresponding to two different scop-
ings of a single sentence, we borrow the notion of
transitive closure from graph theory. The transitive
closure (TC) of a directed graph G=(V,E) is the
graph G+=(V,E+), where E+ is defined as follows:
</bodyText>
<listItem confidence="0.6655255">
6. E+={(i,j)  |i,j EV and i reaches j using a non-
null directed path in G}
</listItem>
<bodyText confidence="0.998623666666667">
Given the TC graph of a scoping, every pair (i,j),
where i precedes j in the sentence, has one of the
following three labels:
</bodyText>
<listItem confidence="0.99958">
• WS (i outscopes j): (i,j) E E+
• NS (j outscopes i): (j,i) E E+
• NI (no interaction): (i,j) o E+ ∧ (j,i) o E+
</listItem>
<bodyText confidence="0.998984666666667">
A pair is considered a match between two scop-
ings, if it has the same label in both. We define the
metrics at two levels, constraint level and sentence
level. At constraint level, every pair of chunks in
every sentence is considered one instance. At sen-
tence level, every sentence is treated as an in-
</bodyText>
<figure confidence="0.992808">
(a) (b)
</figure>
<figureCaption confidence="0.999867">
Figure 4. DAG of scoping in (5) and its TC
</figureCaption>
<page confidence="0.996215">
144
</page>
<bodyText confidence="0.999834714285714">
stance. A sentence counts as a match if and only if
every pair of chunks in the sentence has the same
label in both scopings. Unlike previous work (sec-
tion 6) where there is a strong skew in label distri-
bution, in our corpus the labels are almost evenly
distributed, each consisting around 33% of the in-
stances. We use Cohen’s kappa score for multiple
annotators (Davies &amp; Fleiss 1982) to measure IAA.
Table (2) reports the kappa score.
The IAA defined above serves well for theo-
retical purposes, but an easier metric could be de-
fined which works fine for most practical purposes.
For example, if the target language is first order
logic with generalized quantifiers, the relative
scope of the chunks labeled NI does not affect the
interpretation.2 Therefore, we define a new version
of observed agreement in which we consider a pair
a match if it is labeled NI in one scoping or as-
signed the same label in both scopings. Table (2)
reports the IAA based on the latter similarity
measure, called κ-EZ.
</bodyText>
<sectionHeader confidence="0.999966" genericHeader="method">
6 Related work
</sectionHeader>
<bodyText confidence="0.999292217391304">
To the best of our knowledge, there have been
three major efforts on building a scope-
disambiguated corpus for statistical scope disam-
biguation, among which Higgins and Sadock
(2003) is the most comprehensive. Their corpus
consists of 890 sentences from the Wall Street
journal section of the Penn Treebank. They pick
sentences containing exactly two quantifiers from a
predefined list. This list does not include definites,
indefinites, or bare singulars/plurals. Every sen-
tence is labeled with one of the three labels
corresponding to the first quantifier having wide-
scope, the second quantifier having wide scope, or
no scope interaction between the two. They
achieve an IAA of 52% on this task. The majority
of sentences in their corpus (more than 60%) have
been labeled with no scope interaction.
Galen and McCartney (2004) is another effort
to provide scope-disambiguated data. They pick a
set of sentences from LSAT and GRE logic games,
which again contain only two quantifiers from a
limited list of quantifiers. Their corpus consists of
305 sentences. In around 70% of these sentences,
</bodyText>
<footnote confidence="0.792484">
2 Note that any pair left unscoped is labeled NI. Most of these
pairs are those whose both orderings are logically equivalent
(section 4.1). Besides, we assume all the scopings are valid
that is there is at least one interpretation satisfying them.
</footnote>
<table confidence="0.995737">
Constraint-level Sentence-level
κ 75.0% 66%
κ-EZ 92.3% 89%
</table>
<tableCaption confidence="0.999836">
Table 2. Inter-annotator agreement
</tableCaption>
<bodyText confidence="0.999955142857143">
the first quantifier has wide scope. A major prob-
lem with this data is that the sentences are artifi-
cially constructed for the LSAT and GRE tests.
In a recent work Srinivasan and Yates (2009)
study the usage of pragmatic knowledge in finding
the intended scoping of a sentence. Their labeled
data set consists of 46 sentences, extracted from
Web1Tgram (from Google, Inc) and hence is open-
domain. The corpus consists of short sentences
with two specific quantifiers: Every and A. All sen-
tences share the same syntactic structure, an active
voice English sentence of the form (S (NP (V (NP |
PP)))). In fact, they try to isolate the effect of
pragmatic knowledge on scope disambiguation.
</bodyText>
<sectionHeader confidence="0.967326" genericHeader="conclusions">
7 Summary and future work
</sectionHeader>
<bodyText confidence="0.999994869565218">
We have constructed a comprehensive scope–
disambiguated corpus of English text within the
domain of editing plain text files. The domain car-
ries many scope interactions. Our work does not
put any restriction on the type or the number of
scope-bearing elements in the sentence. We
achieve the IAA of 75% on this task. Previous
work focuses on annotating the relative scope of
two NPs per sentence, while ignoring the complex
scope-bearing NPs such as definites and indefi-
nites, and achieves the IAA of 52%.
The current corpus contains 2500 sentences,
out of which 500 sentences have already been an-
notated. Our goal is to expand the corpus up to
twice in size. 20% of the corpus will be annotated
and the rest will be left for the purpose of semi-
supervised learning. Since world knowledge plays
a major role in scope disambiguation, we believe
that leveraging unlabeled domain specific data in
order to extract lexical information is a promising
approach for scope disambiguation. We hope that
availability of this corpus motivates more research
on statistical scope disambiguation.
</bodyText>
<sectionHeader confidence="0.998961" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.884844">
This work was supported in part by grants from the
National Science Foundation (IIS-1012205) and
The Office of Naval Research (N000141110417).
</bodyText>
<page confidence="0.998667">
145
</page>
<sectionHeader confidence="0.995873" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998889933333333">
Alshawi, H. (ed.) (1992) The core language Engine.
Cambridge, MA, MIT Press.
Alshawi, H. and Crouch, R. (1992) Monotonic semantic
interpretation. In Proc. 30th ACL, pages 32–39.
Bos, J. (1996) Predicate logic unplugged. In Proc. 10th
Amsterdam Colloquium, pages 133–143.
Copestake, A., Lascarides, A. and Flickinger, D. (2001)
An Algebra for Semantic Construction in Constraint-
Based Grammars. ACL-01. Toulouse, France.
Davies, M. and Fleiss, J. (1982) Measuring Agreement
for Multinomial Data. Biometrics, 38:1047–1051,
Egg M., Koller A., and Niehren J. (2001) The constraint
language for lambda structures. Journal of Logic,
Language, and Information, 10:457–485.
Galen, A. and MacCartney, B. (2004). Statistical resolu-
tion of scope ambiguity in Natural language.
http://nlp.stanford.edu/nlkr/scoper.pdf.
Higgins, D. and Sadock, J. (2003). A machine learning
ap-proach to modeling scope preferences. Computa-
tional Linguistics, 29(1).
Hobbs, J. and Shieber, S. M. (1987) An Algorithm for
Generating Quantifier Scopings. Computational Lin-
guistics 13, pp. 47–63.
Klein, D. and Manning, C. D. (2003). Accurate Unlexi-
calized Parsing. Proceedings of the 41st Meeting of
the Association for Computational Linguistics, pp.
423-430.
Link, G. (1998) Ten Years of Research on Plurals -
Where Do We Stand? Plurality and quantification By
Fritz Hamm, Erhard W. Hinrichs, 1998 Kluwer
Academic Publishers.
Moran, D. B. (1988). QuantiÞer scoping in the SRI core
language engine. In Proceedings of the 26th Annual
Meeting of the Association for Computational Lin-
guistics.
Srinivasan, P., and Yates, A. (2009). QuantiÞer scope
disambiguation using extracted pragmatic knowl-
edge: Preliminary results. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing.
VanLehn, K. (1988) Determining the scope of English
quantifiers, TR AI-TR-483, AI Lab, MIT.
Woods, W. A. (1978) Semantics and quantification in
natural language question answering, Advances in.
Computers, vol. 17, pp 1-87.
</reference>
<page confidence="0.998809">
146
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.988248">
<title confidence="0.99876">A Corpus of Scope-disambiguated English Text</title>
<author confidence="0.99905">Mehdi Manshadi</author>
<author confidence="0.99905">James Allen</author>
<author confidence="0.99905">Mary</author>
<affiliation confidence="0.998783">Department of Computer Science, University of</affiliation>
<address confidence="0.999728">Rochester, NY, 14627, USA</address>
<email confidence="0.99979">mehdih@cs.rochester.edu</email>
<email confidence="0.99979">james@cs.rochester.edu</email>
<email confidence="0.99979">swift@cs.rochester.edu</email>
<abstract confidence="0.999427466666667">Previous work on quantifier scope annotation focuses on scoping sentences with only two quantified noun phrases (NPs), where the quantifiers are restricted to a predefined list. It also ignores negation, modal/logical operators, and other sentential adverbials. We present a comprehensive scope annotation scheme. We annotate the scope interaction between all scopal terms in the sentence from quantifiers to scopal adverbials, without putting any restriction on the number of scopal terms in a sentence. In addition, all NPs, explicitly quantified or not, with no restriction on the type of quantification, are investigated for possible scope interactions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Alshawi</author>
</authors>
<title>The core language Engine.</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="1266" citStr="Alshawi 1992" startWordPosition="179" endWordPosition="180">ting any restriction on the number of scopal terms in a sentence. In addition, all NPs, explicitly quantified or not, with no restriction on the type of quantification, are investigated for possible scope interactions. 1 Introduction Since the early days of natural language understanding (NLU), quantifier scope disambiguation has been an extremely hard task. Therefore, early NLU systems either devised some mechanism for leaving the semantic representation underspecified (Woods 1978, Hobbs and Shieber 1987), or tried to assign scoping to sentences based on heuristics (VanLehn 1978, Moran 1988, Alshawi 1992). There has been a lot of work since then on developing frameworks for scope-underspecified semantic representations (Alshawi and Crouch 1992, Bos 1996, Copestake et al., 2001, Egg et al., 2001). The motivation of most recent formalisms is to develop a constraint-based framework where you can incrementally add constraints to filter out unwanted scopings. However, almost all of these formalisms are based on hard constraints, which have to be satisfied in every reading of the sentence. It seems that the story is different in practice. Most of the constraints one can hope for (imposed by discours</context>
</contexts>
<marker>Alshawi, 1992</marker>
<rawString>Alshawi, H. (ed.) (1992) The core language Engine. Cambridge, MA, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Alshawi</author>
<author>R Crouch</author>
</authors>
<title>Monotonic semantic interpretation.</title>
<date>1992</date>
<booktitle>In Proc. 30th ACL,</booktitle>
<pages>32--39</pages>
<contexts>
<context position="1407" citStr="Alshawi and Crouch 1992" startWordPosition="199" endWordPosition="202">iction on the type of quantification, are investigated for possible scope interactions. 1 Introduction Since the early days of natural language understanding (NLU), quantifier scope disambiguation has been an extremely hard task. Therefore, early NLU systems either devised some mechanism for leaving the semantic representation underspecified (Woods 1978, Hobbs and Shieber 1987), or tried to assign scoping to sentences based on heuristics (VanLehn 1978, Moran 1988, Alshawi 1992). There has been a lot of work since then on developing frameworks for scope-underspecified semantic representations (Alshawi and Crouch 1992, Bos 1996, Copestake et al., 2001, Egg et al., 2001). The motivation of most recent formalisms is to develop a constraint-based framework where you can incrementally add constraints to filter out unwanted scopings. However, almost all of these formalisms are based on hard constraints, which have to be satisfied in every reading of the sentence. It seems that the story is different in practice. Most of the constraints one can hope for (imposed by discourse, pragmatics, word knowledge, etc.) are soft constraints, that is they define a preference over the possible readings of a sentence. As a re</context>
</contexts>
<marker>Alshawi, Crouch, 1992</marker>
<rawString>Alshawi, H. and Crouch, R. (1992) Monotonic semantic interpretation. In Proc. 30th ACL, pages 32–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bos</author>
</authors>
<title>Predicate logic unplugged.</title>
<date>1996</date>
<booktitle>In Proc. 10th Amsterdam Colloquium,</booktitle>
<pages>133--143</pages>
<contexts>
<context position="1417" citStr="Bos 1996" startWordPosition="203" endWordPosition="204">ntification, are investigated for possible scope interactions. 1 Introduction Since the early days of natural language understanding (NLU), quantifier scope disambiguation has been an extremely hard task. Therefore, early NLU systems either devised some mechanism for leaving the semantic representation underspecified (Woods 1978, Hobbs and Shieber 1987), or tried to assign scoping to sentences based on heuristics (VanLehn 1978, Moran 1988, Alshawi 1992). There has been a lot of work since then on developing frameworks for scope-underspecified semantic representations (Alshawi and Crouch 1992, Bos 1996, Copestake et al., 2001, Egg et al., 2001). The motivation of most recent formalisms is to develop a constraint-based framework where you can incrementally add constraints to filter out unwanted scopings. However, almost all of these formalisms are based on hard constraints, which have to be satisfied in every reading of the sentence. It seems that the story is different in practice. Most of the constraints one can hope for (imposed by discourse, pragmatics, word knowledge, etc.) are soft constraints, that is they define a preference over the possible readings of a sentence. As a result, stat</context>
</contexts>
<marker>Bos, 1996</marker>
<rawString>Bos, J. (1996) Predicate logic unplugged. In Proc. 10th Amsterdam Colloquium, pages 133–143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>A Lascarides</author>
<author>D Flickinger</author>
</authors>
<title>An Algebra for Semantic Construction in ConstraintBased Grammars.</title>
<date>2001</date>
<booktitle>ACL-01.</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="1441" citStr="Copestake et al., 2001" startWordPosition="205" endWordPosition="208">n, are investigated for possible scope interactions. 1 Introduction Since the early days of natural language understanding (NLU), quantifier scope disambiguation has been an extremely hard task. Therefore, early NLU systems either devised some mechanism for leaving the semantic representation underspecified (Woods 1978, Hobbs and Shieber 1987), or tried to assign scoping to sentences based on heuristics (VanLehn 1978, Moran 1988, Alshawi 1992). There has been a lot of work since then on developing frameworks for scope-underspecified semantic representations (Alshawi and Crouch 1992, Bos 1996, Copestake et al., 2001, Egg et al., 2001). The motivation of most recent formalisms is to develop a constraint-based framework where you can incrementally add constraints to filter out unwanted scopings. However, almost all of these formalisms are based on hard constraints, which have to be satisfied in every reading of the sentence. It seems that the story is different in practice. Most of the constraints one can hope for (imposed by discourse, pragmatics, word knowledge, etc.) are soft constraints, that is they define a preference over the possible readings of a sentence. As a result, statistical methods seem to </context>
</contexts>
<marker>Copestake, Lascarides, Flickinger, 2001</marker>
<rawString>Copestake, A., Lascarides, A. and Flickinger, D. (2001) An Algebra for Semantic Construction in ConstraintBased Grammars. ACL-01. Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Davies</author>
<author>J Fleiss</author>
</authors>
<title>Measuring Agreement for Multinomial Data.</title>
<date>1982</date>
<journal>Biometrics,</journal>
<pages>38--1047</pages>
<contexts>
<context position="16283" citStr="Davies &amp; Fleiss 1982" startWordPosition="2723" endWordPosition="2726">s, constraint level and sentence level. At constraint level, every pair of chunks in every sentence is considered one instance. At sentence level, every sentence is treated as an in(a) (b) Figure 4. DAG of scoping in (5) and its TC 144 stance. A sentence counts as a match if and only if every pair of chunks in the sentence has the same label in both scopings. Unlike previous work (section 6) where there is a strong skew in label distribution, in our corpus the labels are almost evenly distributed, each consisting around 33% of the instances. We use Cohen’s kappa score for multiple annotators (Davies &amp; Fleiss 1982) to measure IAA. Table (2) reports the kappa score. The IAA defined above serves well for theoretical purposes, but an easier metric could be defined which works fine for most practical purposes. For example, if the target language is first order logic with generalized quantifiers, the relative scope of the chunks labeled NI does not affect the interpretation.2 Therefore, we define a new version of observed agreement in which we consider a pair a match if it is labeled NI in one scoping or assigned the same label in both scopings. Table (2) reports the IAA based on the latter similarity measur</context>
</contexts>
<marker>Davies, Fleiss, 1982</marker>
<rawString>Davies, M. and Fleiss, J. (1982) Measuring Agreement for Multinomial Data. Biometrics, 38:1047–1051,</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Egg</author>
<author>A Koller</author>
<author>J Niehren</author>
</authors>
<title>The constraint language for lambda structures.</title>
<date>2001</date>
<journal>Journal of Logic, Language, and Information,</journal>
<pages>10--457</pages>
<contexts>
<context position="1460" citStr="Egg et al., 2001" startWordPosition="209" endWordPosition="212">possible scope interactions. 1 Introduction Since the early days of natural language understanding (NLU), quantifier scope disambiguation has been an extremely hard task. Therefore, early NLU systems either devised some mechanism for leaving the semantic representation underspecified (Woods 1978, Hobbs and Shieber 1987), or tried to assign scoping to sentences based on heuristics (VanLehn 1978, Moran 1988, Alshawi 1992). There has been a lot of work since then on developing frameworks for scope-underspecified semantic representations (Alshawi and Crouch 1992, Bos 1996, Copestake et al., 2001, Egg et al., 2001). The motivation of most recent formalisms is to develop a constraint-based framework where you can incrementally add constraints to filter out unwanted scopings. However, almost all of these formalisms are based on hard constraints, which have to be satisfied in every reading of the sentence. It seems that the story is different in practice. Most of the constraints one can hope for (imposed by discourse, pragmatics, word knowledge, etc.) are soft constraints, that is they define a preference over the possible readings of a sentence. As a result, statistical methods seem to be well suited for </context>
</contexts>
<marker>Egg, Koller, Niehren, 2001</marker>
<rawString>Egg M., Koller A., and Niehren J. (2001) The constraint language for lambda structures. Journal of Logic, Language, and Information, 10:457–485.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Galen</author>
<author>B MacCartney</author>
</authors>
<title>Statistical resolution of scope ambiguity in Natural language.</title>
<date>2004</date>
<note>http://nlp.stanford.edu/nlkr/scoper.pdf.</note>
<marker>Galen, MacCartney, 2004</marker>
<rawString>Galen, A. and MacCartney, B. (2004). Statistical resolution of scope ambiguity in Natural language. http://nlp.stanford.edu/nlkr/scoper.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Higgins</author>
<author>J Sadock</author>
</authors>
<title>A machine learning ap-proach to modeling scope preferences.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="17095" citStr="Higgins and Sadock (2003)" startWordPosition="2862" endWordPosition="2865">urposes. For example, if the target language is first order logic with generalized quantifiers, the relative scope of the chunks labeled NI does not affect the interpretation.2 Therefore, we define a new version of observed agreement in which we consider a pair a match if it is labeled NI in one scoping or assigned the same label in both scopings. Table (2) reports the IAA based on the latter similarity measure, called κ-EZ. 6 Related work To the best of our knowledge, there have been three major efforts on building a scopedisambiguated corpus for statistical scope disambiguation, among which Higgins and Sadock (2003) is the most comprehensive. Their corpus consists of 890 sentences from the Wall Street journal section of the Penn Treebank. They pick sentences containing exactly two quantifiers from a predefined list. This list does not include definites, indefinites, or bare singulars/plurals. Every sentence is labeled with one of the three labels corresponding to the first quantifier having widescope, the second quantifier having wide scope, or no scope interaction between the two. They achieve an IAA of 52% on this task. The majority of sentences in their corpus (more than 60%) have been labeled with no</context>
</contexts>
<marker>Higgins, Sadock, 2003</marker>
<rawString>Higgins, D. and Sadock, J. (2003). A machine learning ap-proach to modeling scope preferences. Computational Linguistics, 29(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
<author>S M Shieber</author>
</authors>
<title>An Algorithm for Generating Quantifier Scopings.</title>
<date>1987</date>
<journal>Computational Linguistics</journal>
<volume>13</volume>
<pages>47--63</pages>
<contexts>
<context position="1164" citStr="Hobbs and Shieber 1987" startWordPosition="161" endWordPosition="164">he scope interaction between all scopal terms in the sentence from quantifiers to scopal adverbials, without putting any restriction on the number of scopal terms in a sentence. In addition, all NPs, explicitly quantified or not, with no restriction on the type of quantification, are investigated for possible scope interactions. 1 Introduction Since the early days of natural language understanding (NLU), quantifier scope disambiguation has been an extremely hard task. Therefore, early NLU systems either devised some mechanism for leaving the semantic representation underspecified (Woods 1978, Hobbs and Shieber 1987), or tried to assign scoping to sentences based on heuristics (VanLehn 1978, Moran 1988, Alshawi 1992). There has been a lot of work since then on developing frameworks for scope-underspecified semantic representations (Alshawi and Crouch 1992, Bos 1996, Copestake et al., 2001, Egg et al., 2001). The motivation of most recent formalisms is to develop a constraint-based framework where you can incrementally add constraints to filter out unwanted scopings. However, almost all of these formalisms are based on hard constraints, which have to be satisfied in every reading of the sentence. It seems </context>
</contexts>
<marker>Hobbs, Shieber, 1987</marker>
<rawString>Hobbs, J. and Shieber, S. M. (1987) An Algorithm for Generating Quantifier Scopings. Computational Linguistics 13, pp. 47–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Accurate Unlexicalized Parsing.</title>
<date>2003</date>
<booktitle>Proceedings of the 41st Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="7990" citStr="Klein and Manning 2003" startWordPosition="1312" endWordPosition="1315">000 HU August 3000 HU August 4000 OR May 1000 NY April 4000 AL June 4000 OR May c josh 21 a adams 23 a adams 23 b john 25 d sam 26 c josh 21 b john 25 d sam 26 Figure 2. Two I/O pairs given for a single task 142 pairs and hence expand the corpus in a bootstrapping fashion. The data acquired from Mechanical Turk is often quite noisy, therefore all sentences are reviewed manually and tagged with different categories (e.g. paraphrase of the original description, wrong but coherent description, etc.). 3.3 Pre-processing the corpus The corpus is tokenized and parsed using the Stanford PCFG parser (Klein and Manning 2003). We guide the parser by giving suggestions on part-ofspeech (POS) tags based on the gold standard POS tags provided for some classes of words such as verbs. Shallow NP chunks and negations are automatically extracted from the parse trees and indexed. The resulting NP-chunked sentences are then reviewed manually, first to fix the chunking errors, hence providing gold standard chunks, and second, to add chunks for other scopal operators such as sentential adverbials since the above automated approach will not extract those. Figure (3) shows the examples in figure (1) after chunking. As shown in</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein, D. and Manning, C. D. (2003). Accurate Unlexicalized Parsing. Proceedings of the 41st Meeting of the Association for Computational Linguistics, pp. 423-430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Link</author>
</authors>
<title>Ten Years of Research on Plurals -Where Do We Stand? Plurality and quantification By Fritz</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>Link, 1998</marker>
<rawString>Link, G. (1998) Ten Years of Research on Plurals -Where Do We Stand? Plurality and quantification By Fritz Hamm, Erhard W. Hinrichs, 1998 Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D B Moran</author>
</authors>
<title>QuantiÞer scoping in the SRI core language engine.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1251" citStr="Moran 1988" startWordPosition="177" endWordPosition="178"> without putting any restriction on the number of scopal terms in a sentence. In addition, all NPs, explicitly quantified or not, with no restriction on the type of quantification, are investigated for possible scope interactions. 1 Introduction Since the early days of natural language understanding (NLU), quantifier scope disambiguation has been an extremely hard task. Therefore, early NLU systems either devised some mechanism for leaving the semantic representation underspecified (Woods 1978, Hobbs and Shieber 1987), or tried to assign scoping to sentences based on heuristics (VanLehn 1978, Moran 1988, Alshawi 1992). There has been a lot of work since then on developing frameworks for scope-underspecified semantic representations (Alshawi and Crouch 1992, Bos 1996, Copestake et al., 2001, Egg et al., 2001). The motivation of most recent formalisms is to develop a constraint-based framework where you can incrementally add constraints to filter out unwanted scopings. However, almost all of these formalisms are based on hard constraints, which have to be satisfied in every reading of the sentence. It seems that the story is different in practice. Most of the constraints one can hope for (impo</context>
</contexts>
<marker>Moran, 1988</marker>
<rawString>Moran, D. B. (1988). QuantiÞer scoping in the SRI core language engine. In Proceedings of the 26th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Srinivasan</author>
<author>A Yates</author>
</authors>
<title>QuantiÞer scope disambiguation using extracted pragmatic knowledge: Preliminary results.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="18542" citStr="Srinivasan and Yates (2009)" startWordPosition="3097" endWordPosition="3100">st of quantifiers. Their corpus consists of 305 sentences. In around 70% of these sentences, 2 Note that any pair left unscoped is labeled NI. Most of these pairs are those whose both orderings are logically equivalent (section 4.1). Besides, we assume all the scopings are valid that is there is at least one interpretation satisfying them. Constraint-level Sentence-level κ 75.0% 66% κ-EZ 92.3% 89% Table 2. Inter-annotator agreement the first quantifier has wide scope. A major problem with this data is that the sentences are artificially constructed for the LSAT and GRE tests. In a recent work Srinivasan and Yates (2009) study the usage of pragmatic knowledge in finding the intended scoping of a sentence. Their labeled data set consists of 46 sentences, extracted from Web1Tgram (from Google, Inc) and hence is opendomain. The corpus consists of short sentences with two specific quantifiers: Every and A. All sentences share the same syntactic structure, an active voice English sentence of the form (S (NP (V (NP | PP)))). In fact, they try to isolate the effect of pragmatic knowledge on scope disambiguation. 7 Summary and future work We have constructed a comprehensive scope– disambiguated corpus of English text</context>
</contexts>
<marker>Srinivasan, Yates, 2009</marker>
<rawString>Srinivasan, P., and Yates, A. (2009). QuantiÞer scope disambiguation using extracted pragmatic knowledge: Preliminary results. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K VanLehn</author>
</authors>
<title>Determining the scope of English quantifiers,</title>
<date>1988</date>
<journal>TR AI-TR-483, AI Lab, MIT.</journal>
<marker>VanLehn, 1988</marker>
<rawString>VanLehn, K. (1988) Determining the scope of English quantifiers, TR AI-TR-483, AI Lab, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Semantics and quantification in natural language question answering,</title>
<date>1978</date>
<journal>Advances in. Computers,</journal>
<volume>17</volume>
<pages>1--87</pages>
<contexts>
<context position="1139" citStr="Woods 1978" startWordPosition="159" endWordPosition="160">e annotate the scope interaction between all scopal terms in the sentence from quantifiers to scopal adverbials, without putting any restriction on the number of scopal terms in a sentence. In addition, all NPs, explicitly quantified or not, with no restriction on the type of quantification, are investigated for possible scope interactions. 1 Introduction Since the early days of natural language understanding (NLU), quantifier scope disambiguation has been an extremely hard task. Therefore, early NLU systems either devised some mechanism for leaving the semantic representation underspecified (Woods 1978, Hobbs and Shieber 1987), or tried to assign scoping to sentences based on heuristics (VanLehn 1978, Moran 1988, Alshawi 1992). There has been a lot of work since then on developing frameworks for scope-underspecified semantic representations (Alshawi and Crouch 1992, Bos 1996, Copestake et al., 2001, Egg et al., 2001). The motivation of most recent formalisms is to develop a constraint-based framework where you can incrementally add constraints to filter out unwanted scopings. However, almost all of these formalisms are based on hard constraints, which have to be satisfied in every reading o</context>
</contexts>
<marker>Woods, 1978</marker>
<rawString>Woods, W. A. (1978) Semantics and quantification in natural language question answering, Advances in. Computers, vol. 17, pp 1-87.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>