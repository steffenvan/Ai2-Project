<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000760">
<title confidence="0.934127">
Enhancement of Lexical Concepts Using Cross-lingual Web Mining
</title>
<author confidence="0.812579">
Dmitry Davidov
</author>
<affiliation confidence="0.658203">
ICNC
The Hebrew University of Jerusalem
</affiliation>
<email confidence="0.946951">
dmitry@alice.nc.huji.ac.il
</email>
<author confidence="0.992054">
Ari Rappoport
</author>
<affiliation confidence="0.993341">
Institute of Computer Science
The Hebrew University of Jerusalem
</affiliation>
<email confidence="0.988249">
arir@cs.huji.ac.il
</email>
<sectionHeader confidence="0.993697" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999877761904762">
Sets of lexical items sharing a significant
aspect of their meaning (concepts) are fun-
damental in linguistics and NLP. Manual
concept compilation is labor intensive, er-
ror prone and subjective. We present a
web-based concept extension algorithm.
Given a set of terms specifying a concept
in some language, we translate them to
a wide range of intermediate languages,
disambiguate the translations using web
counts, and discover additional concept
terms using symmetric patterns. We then
translate the discovered terms back into
the original language, score them, and ex-
tend the original concept by adding back-
translations having high scores. We eval-
uate our method in 3 source languages and
45 intermediate languages, using both hu-
man judgments and WordNet. In all cases,
our cross-lingual algorithm significantly
improves high quality concept extension.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999987327272727">
A concept (or lexical category) is a set of lex-
ical items sharing a significant aspect of their
meanings (e.g., types of food, tool names, etc).
Concepts are fundamental in linguistics and NLP,
in thesauri, dictionaries, and various applications
such as textual entailment and question answering.
Great efforts have been invested in manual
preparation of concept resources such as WordNet
(WN). However, manual preparation is labor in-
tensive, which means it is both costly and slow
to update. Applications needing data on some
very specific domain or on a recent news-related
event may find such resources lacking. In addition,
manual preparation is error-prone and susceptible
to subjective concept membership decisions, fre-
quently resulting in concepts whose terms do not
belong to the same level of granularity1. As a re-
sult, there is a need to find methods for automatic
improvement of concept coverage and quality.
The web is a huge up-to-date corpus covering
many domains, so using it for concept extension
has the potential to address the above problems.
The majority of web pages are written in a few
salient languages, hence most of the web-based in-
formation retrieval studies are done on these lan-
guages. However, due to the substantial growth of
the multilingual web2, languages in which concept
terms are expressed in the most precise manner
frequently do not match the language where in-
formation is needed. Moreover, representations of
the same concept in different languages may com-
plement each other.
In order to benefit from such cross-lingual in-
formation, concept acquisition systems should be
able to gather concept terms from many available
languages and convert them to the desired lan-
guage. In this paper we present such an algorithm.
Given a set of words specifying a concept in some
source language, we translate them to a range
of intermediate languages and disambiguate the
translations using web counts. Then we discover
additional concept terms using symmetric patterns
and translate the discovered terms back into the
original language. Finally we score the back-
translations using their intermediate languages’
properties, and extend the original concept by
adding back-translations having high scores. The
only language-specific resource required by the al-
gorithm are multilingual dictionaries, and its pro-
cessing times are very modest.
We performed thorough evaluation for 24 con-
cepts in 3 source languages (Hebrew, English and
Russian) and 45 intermediate languages. Concept
definitions were taken from existing WordNet sub-
trees, and the obtained new terms were manually
</bodyText>
<footnote confidence="0.997363">
1See Section 5.1.1.
2http://www.internetworldstats.com/stats7.htm
</footnote>
<page confidence="0.911542">
852
</page>
<note confidence="0.9966335">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 852–861,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999313">
scored by human judges. In all cases we have sig-
nificantly extended the original concept set with
high precision. We have also performed a fully
automatic evaluation with 150 concepts, showing
that the algorithm can re-discover WN concepts
with high precision and recall when given only
partial lists as input.
Section 2 discusses related work, Section 3 de-
tails the algorithm, Section 4 describes the evalua-
tion protocol and Section 5 presents our results.
</bodyText>
<sectionHeader confidence="0.999622" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999888611111112">
One of the main goals of this paper is the extension
or automated creation of lexical databases such
as WN. Due to the importance of WN for NLP
tasks, substantial research was done on direct or
indirect automated extension of the English WN
(e.g., (Snow et al., 2006)) or WN in other lan-
guages (e.g., (Vintar and Fiˇser, 2008)). The major-
ity of this research was done on extending the tree
structure (finding new synsets (Snow et al., 2006)
or enriching WN with new relationships (Cuadros
and Rigau, 2008)) rather than improving the qual-
ity of existing concept/synset nodes. Other re-
lated studies develop concept acquisition frame-
works for on-demand tasks where concepts are de-
fined by user-provided seeds or patterns (Etzioni et
al., 2005; Davidov et al., 2007), or for fully unsu-
pervised database creation where concepts are dis-
covered from scratch (Banko et al., 2007; Davi-
dov and Rappoport, 2006).
Some papers directly target specific applica-
tions, and build lexical resources as a side effect.
Named Entity Recognition can be viewed as an in-
stance of the concept acquisition problem where
the desired concepts contain words that are names
of entities of a particular kind, as done in (Fre-
itag, 2004) using co-clustering and in (Etzioni et
al., 2005) using predefined pattern types.
The two main algorithmic approaches to the
problem are pattern-based concept discovery and
clustering of context feature vectors. The latter
approach represents word contexts as vectors in
some space and uses similarity measures and au-
tomatic clustering in that space (Deerwester et al.,
1990). Pereira et al.(1993), Curran and Moens
(2002) and Lin (1998) use syntactic features in the
vector definition. Pantel and Lin (2002) improves
on the latter by clustering by committee. Cara-
ballo (1999) uses conjunction and appositive an-
notations in the vector representation. While great
effort has been made for improving the computa-
tional complexity of these methods (Gorman and
Curran, 2006), they still remain data and compu-
tation intensive.
The second major algorithmic approach is to
use lexico-syntactic patterns. Patterns have been
shown to produce more accurate results than fea-
ture vectors, at a lower computational cost on large
corpora (Pantel et al., 2004). In concept acquisi-
tion, pattern-based methods were shown to out-
perform LSA by a large margin (Widdows and
Dorow, 2002). Since (Hearst, 1992), who used a
manually prepared set of initial lexical patterns in
order to acquire relationships, numerous pattern-
based methods have been proposed for the discov-
ery of concepts from seeds (Pantel et al., 2004;
Davidov et al., 2007; Pasca et al., 2006). Most of
these studies were done for English, while some
show the applicability of their methods to other
languages, including Greek, Czech, Slovene and
French.
Most of these papers attempt to discover con-
cepts from data available in some specific lan-
guage. Recently several studies have proposed to
utilize a second language or several specified lan-
guages in order to extract or extend concepts (Vin-
tar and Fiˇser, 2008; van der Plas and Tiedemann,
2006) or paraphrases (Bosma and Callison-Burch,
2007). However, these methods usually require
the availability of parallel corpora, which limits
their usefulness. Most of these methods utilize
distributional measures, hence they do not possess
the advantages of the pattern-based framework.
Unlike in the majority of recent studies, where
the framework is designed with specific languages
in mind, in our task, in order to take advantage
of information from diverse languages, the algo-
rithm should be able to deal well with a wide va-
riety of possible intermediate languages without
any manual adaptations. Relying solely on mul-
tilingual dictionaries and the web, our algorithm
should be able to discover language-specific pat-
terns and concept terms. While some of the pro-
posed frameworks could potentially be language-
independent, little research has been done to con-
firm this. There are a few obstacles that may
hinder applying common pattern-based methods
to other languages. Many studies utilize parsing
or POS tagging, which frequently depend on the
availability and quality of language-specific tools.
Some studies specify seed patterns in advance, and
</bodyText>
<page confidence="0.998415">
853
</page>
<bodyText confidence="0.9990013">
it is not clear whether translated patterns can work
well on different languages. Also, the absence of
clear word segmentation in some languages (e.g.,
Chinese) can make many methods inapplicable.
A few recently proposed concept acquisition
methods require only a handful of seed words and
no pattern pre-specification (Davidov et al., 2007;
Pasca and Van Durme, 2008). While these studies
avoid some of the obstacles above, it still remains
open whether such methods are indeed language-
independent. In the translation to intermediate lan-
guages part of our framework, we adapt the algo-
rithms in (Davidov and Rappoport, 2006; Davi-
dov et al., 2007) to suit diverse languages (includ-
ing ones without explicit word segmentation). We
also develop a method for efficient automated dis-
ambiguation and translation of terms to and from
any available intermediate language.
Our study is related to cross-language infor-
mation retrieval (CLIR/CLEF) frameworks. Both
deal with information extracted from a set of lan-
guages. However, the majority of CLIR stud-
ies pursue different targets. One of the main
CLIR goals is the retrieval of documents based
on explicit queries, when the document lan-
guage is not the query language (Volk and Buite-
laar, 2002). These frameworks usually develop
language-specific tools and algorithms including
parsers and taggers in order to integrate multilin-
gual queries and documents (Jagarlamudi and Ku-
maran, 2007). Our goal is to develop a language-
independent method using cross-lingual informa-
tion, for the extension and improvement of con-
cepts rather than the retrieval of documents. Be-
sides, unlike in many CLIR frameworks, interme-
diate languages are not specified in advance and
the language of requested data is the same as the
language of request, while available information
may be found in many different intermediate lan-
guages.
</bodyText>
<sectionHeader confidence="0.989177" genericHeader="method">
3 The Algorithm
</sectionHeader>
<bodyText confidence="0.999963565217391">
Our algorithm is comprised of the following
stages: (1) given a set of words in a source lan-
guage as a specification for some concept, we au-
tomatically translate them to a diverse set of inter-
mediate languages, using multilingual dictionar-
ies; (2) the translations are disambiguated using
web counts; (3) for each language, we retrieve a
set of web snippets where these translations co-
appear and apply a pattern-based concept exten-
sion algorithm for discovering additional terms;
(4) we translate the discovered terms back to the
source language, and disambiguate them; (5) we
score the back-translated terms using data on their
behavior in the intermediate languages, and merge
the sets obtained from different languages into a
single one, retaining terms whose score passes a
certain threshold. Stages 1-3 of the algorithm have
been described in (Davidov and Rappoport, 2009),
where the goal was to translate a concept given in
one language to other languages. The framework
presented here includes the new stages 4-5, and its
goal and evaluation methods are completely dif-
ferent.
</bodyText>
<subsectionHeader confidence="0.999796">
3.1 Concept specification and translation
</subsectionHeader>
<bodyText confidence="0.9999464375">
We start from a set of words denoting a concept in
a given source language. Thus we may use words
like (apple, banana, ...) as the definition of the
concept of fruit or (bear, wolf, fox, ...) as the def-
inition of wild animals. In order to reduce noise,
we limit the length (in words) of multiword ex-
pressions considered as terms. To calculate this
limit for a language, we randomly take 100 terms
from the appropriate dictionary and set a limit
as LimmTAJ, = round(avg(length(w))) where
length(w) is the number of words in term w. For
languages like Chinese without inherent word seg-
mentation, length(w) is the number of characters
in w. While for many languages LimmTAJ, = 1,
some languages like Vietnamese usually require
two or more words to express terms.
</bodyText>
<subsectionHeader confidence="0.99985">
3.2 Disambiguation of translated terms
</subsectionHeader>
<bodyText confidence="0.999981666666667">
One of the problems in utilization of multilingual
information is ambiguity of translation. First, in
order to apply the concept acquisition algorithm,
at least some of the given concept terms must be
automatically translated to each intermediate lan-
guage. In order to avoid reliance on parallel cor-
pora, which do not exist or are extremely small for
most of our language pairs, we use bilingual dic-
tionaries. Such dictionaries usually provide many
translations, one or more for each sense, so this
translation is inherently fuzzy. Second, once we
acquire translated term lists for each intermedi-
ate language, we need to translate them back to
the source language and such back-translations are
also fuzzy. In both cases, we need to select the ap-
propriate translation for each term.
While our desire would be to work with as many
languages as possible, in practice, some or even
</bodyText>
<page confidence="0.993925">
854
</page>
<bodyText confidence="0.999861533333333">
most of the concept terms may be absent from the
appropriate dictionary. Such concept terms are ig-
nored.
One way to deal with ambiguity is by applying
distributional methods, usually requiring a large
single-language corpus or, more frequently, paral-
lel corpora. However, such corpora are not readily
available for many languages and domains. Ex-
tracting such statistical information on-demand is
also computationally demanding, limiting its us-
ability. Hence, we take a simple but effective
query-based approach. This approach, while be-
ing powerful as we show in the evaluation, only
relies on a few web queries and does not rely on
any language-specific resources or data.
We use the conjecture that terms of the same
concept tend to co-appear more frequently than
ones belonging to different concepts3. Thus, we
select a translation of a term co-appearing most
frequently with some translation of a different
term of the same concept. We estimate how well
translations of different terms are connected to
each other. Let C = {CZ} be the given seed
words for some concept. Let Tr(CZ, n) be the
n-th available translation of word CZ and Cnt(s)
denote the web count of string s obtained by a
search engine. We select a translation Tr(CZ)
according to:
We utilize the Yahoo! “x * y”,“x * * y” wild-
cards that allow to count only co-appearances
where x and y are separated by a single word or
word pair. As a result, we obtain a set of disam-
biguated term translations. This method is used
both in order to translate from the source lan-
guage to each intermediate language and to back-
translate the newly discovered concept terms from
the intermediate to the source language.
The number of queries in this stage depends on
the ambiguity of the concept terms’ translations.
In order to decrease the amount of queries, if there
are more than three possible senses we sort them
by frequency4 and take three senses with medium
frequency. This allows us to skip the most ambigu-
ous and rare senses without any significant effect
on performance. Also, if the number of combina-
</bodyText>
<footnote confidence="0.9983975">
3Our results here support this conjecture.
4Frequency is estimated by web count for a given word.
</footnote>
<bodyText confidence="0.982760065217391">
tions is still too high (&gt;30), we randomly sample
at most 30 of the possible combinations.
3.3 Pattern-based extension of concept terms
in intermediate languages
We first mine the web for contexts containing
the translations. Then we extract from the re-
trieved snippets contexts where translated terms
co-appear, and detect patterns where they co-
appear symmetrically. Then we use the detected
patterns to discover additional concept terms. In
order to define word boundaries, for each language
we manually specify boundary characters such as
punctuation/space symbols. This data, along with
dictionaries, is the only language-specific data in
our framework.
Web mining for translation contexts. In order
to get language-specific data, we need to restrict
web mining each time to the processed interme-
diate language. This restriction is straightforward
if the alphabet or term translations are language-
specific or if the search API supports restriction to
this language5. In case where there are no such
natural restrictions, we attempt to detect and add
to our queries a few language-specific frequent
words. Using our dictionaries, we find 1–3 of the
15 most frequent words in a desired language that
are unique to that language, and we ‘and’ them
with the queries to ensure proper language selec-
tion. This works well for almost all languages (Es-
peranto being a notable exception).
For each pair A, B of disambiguated term trans-
lations, we construct and execute the following
two queries: {“A * B”, “B * A”}6. When we
have 3 or more terms we also add {A B C D}-like
conjunction queries which include 3-5 words. For
languages with LimmTAJ, &gt; 1, we also construct
queries with several “*” wildcards between terms.
For each query we collect snippets containing text
fragments of web pages. Such snippets frequently
include the search terms. Since Yahoo! Boss al-
lows retrieval of up to the 1000 first results (50 in
each query), we collect several thousands snippets.
For most of the intermediate languages, only a few
dozen queries (40 on the average) are required to
obtain sufficient data, and queries can be paral-
lelized. Thus the relevant data can be downloaded
</bodyText>
<footnote confidence="0.9916785">
5Yahoo! allows restriction for 42 languages.
6These are Yahoo! queries where enclosing words in “”
means searching for an exact phrase and “*” means a wild-
card for exactly one arbitrary word.
</footnote>
<equation confidence="0.7396642">
F(w1, w2) = Cnt(w1) x Cnt(w2)
Cnt(“w1 * w2”) x Cnt(“w2 * w1”)
Tr(Ci) = argmax max I(F(Tr(Ci, si), Tr(Cj, sj)))
si sj
joi
</equation>
<page confidence="0.982443">
855
</page>
<bodyText confidence="0.999795285714286">
in seconds. This makes our approach practical for
on-demand retrieval or concept verification tasks.
Meta-patterns. Following (Davidov et al.,
2007), we seek symmetric patterns to retrieve
concept terms. We use two meta-pattern types.
First, a Two-Slot pattern type constructed as
follows:
</bodyText>
<equation confidence="0.714469">
[Prefix] C1 [Infix] C2 [Postfix]
</equation>
<bodyText confidence="0.998423111111111">
Ci are slots for concept terms. We allow up to
Limmwe space-separated7 words to be in a sin-
gle slot. Infix may contain punctuation, spaces,
and up to Limmwe × 4 words. Prefix and Post-
fix are limited to contain punctuation characters
and/or Limmwe words.
Terms of the same concept frequently co-appear
in lists. To utilize this, we introduce two additional
List pattern types$:
</bodyText>
<equation confidence="0.82324">
[Prefix] C1 [Infix] (Ci [Infix])+ (1)
[Infix] (Ci [Infix])+ Cn [Postfix] (2)
</equation>
<bodyText confidence="0.987243333333333">
Following (Widdows and Dorow, 2002), we define
a pattern graph. Nodes correspond to terms and
patterns to edges. If term pair (w1, w2) appears
in pattern P, we add nodes Nw1, Nw2 to the graph
and a directed edge EP (Nw1, Nw2) between them.
Symmetric patterns. We consider only sym-
metric patterns. We define a symmetric pat-
tern as a pattern where some concept terms
Ci, Cj appear both in left-to-right and right-to-
left order. For example, if we consider the
terms {apple, pineapple} we select a List pattern
“(one Ci, )+ and Cn.” if we find both “one apple,
one pineapple, one guava and orange.” and “one
watermelon, one pineapple and apple.”. If no such
patterns are found, we turn to a weaker definition,
considering as symmetric those patterns where the
same terms appear in the corpus in at least two dif-
ferent slots. Thus, we select a pattern “for C1 and
C2” if we see both “for apple and guava,” and “for
orange and apple,”.
Retrieving concept terms. We collect terms in
two stages. First, we obtain “high-quality” core
terms and then we retrieve potentially more noisy
ones. At the first stage we collect all terms9 that
</bodyText>
<footnote confidence="0.99892875">
7As before, for languages without space-based word sep-
aration Lim,,,,,,,, limits the number of characters instead.
$(E)+ means one or more instances of E.
9We do not consider as terms the 50 most frequent words.
</footnote>
<bodyText confidence="0.999439333333333">
are bidirectionally connected to at least two differ-
ent original translations, and call them core con-
cept terms Ccore. We also add the original ones as
core terms. Then we detect the rest of the terms
Crest that are connected to the core stronger than
to the remaining words, as follows:
</bodyText>
<equation confidence="0.456351">
Gin(c)={w∈Ccore|E(Nw, Nc) ∨ E(Nc, Nw)}
Gout(c)={w/∈Ccore|E(Nw, Nc) ∨ E(Nc, Nw)}
Crest={c||Gin(c)|&gt;|Gout(c)|}
</equation>
<bodyText confidence="0.999292777777778">
For the sake of simplicity, we do not attempt to
discover more patterns/instances iteratively by re-
querying the web. If we have enough data, we use
windowing to improve result quality. If we obtain
more than 400 snippets for some concept, we di-
vide the data into equal parts, each containing up
to 400 snippets. We apply our algorithm indepen-
dently to each part and select only the words that
appear in more than one part.
</bodyText>
<subsectionHeader confidence="0.997185">
3.4 Back-translation and disambiguation
</subsectionHeader>
<bodyText confidence="0.9999904">
At the concept acquisition phase of our framework
we obtained sets of terms for each intermediate
language, each set representing a concept. In or-
der to be useful for the enhancement of the origi-
nal concept, these terms are now back-translated to
the source language. We disambiguate each back-
translated term using the process described in Sec-
tion 3.2. Having sets of back-translated terms for
each intermediate language, our goal is to combine
these into a single set.
</bodyText>
<subsectionHeader confidence="0.791826">
3.5 Scoring and merging the back
translations
</subsectionHeader>
<bodyText confidence="0.989099666666667">
We do this merging using the following scoring
strategy, assigning for each proposed term t&apos; in
concept C the score S(t&apos;, C), and selecting terms
with S(t&apos;, C) &gt; H where H is a predefined
threshold.
Our scoring is based on the two following con-
siderations. First, we assume that terms extracted
from more languages tend to be less noisy and
language-dependent. Second, we would like to fa-
vor languages with less resources for a given con-
cept, since noise empirically appears to be less
prominent in such languages10.
For language L and concept C = {t1 ... tk}
we get a disambiguated set of translations
{Tr(t1, L) ... Tr(tk, L)}. We define relative lan-
</bodyText>
<footnote confidence="0.986602666666667">
10Preliminary experimentation, as well as the evaluation
results presented in this paper, support both of these consid-
erations.
</footnote>
<page confidence="0.984737">
856
</page>
<equation confidence="0.936002">
LFreq(L, C) =
EL&apos;,tiEC(Freq(Tr(ti, L&apos;))
</equation>
<bodyText confidence="0.982464555555556">
where Freq(Tr(ti, L)) is a frequency of term’s ti
translation to language L estimated by the num-
ber of web hits. Thus languages in which trans-
lated concept terms appear more times will get
higher relative frequency, potentially indicating a
greater concept translation ambiguity. Now, for
each new term t&apos; discovered through LNum(t&apos;)
different languages L1 ... LLNum(t,) we calculate
a term score 11 5(t&apos;, C):
</bodyText>
<equation confidence="0.9886115">
5(t&apos;, C) = LNum(t&apos;)·1 −
i �LFreq(Li, C)
</equation>
<bodyText confidence="0.990548230769231">
For each discovered term t&apos;, 5(t&apos;, C) ∈
[0, LNum(t&apos;)], while discovery of t&apos; in less fre-
quent languages will cause the score to be closer to
LNum(t&apos;). So terms appearing in a greater num-
ber of infrequent languages will get higher scores.
After the calculation of score for each proposed
term, we retain terms whose scores are above the
predefined threshold H. In our experiments we
have used H = 3, usually meaning that acquisi-
tion of a term through 3-4 uncommon intermedi-
ate languages should be enough to accept it. The
same score measure can also be used to filter out
“bad” terms in an already existing concept.
</bodyText>
<sectionHeader confidence="0.999024" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.99998">
We describe here the languages, concepts and dic-
tionaries we used in our experiments.
</bodyText>
<subsectionHeader confidence="0.999026">
4.1 Languages and concepts
</subsectionHeader>
<bodyText confidence="0.949948375">
One of the main goals in this research is to take
advantage of concept data in every possible lan-
guage. As intermediate languages, we used 45 lan-
guages including major west European languages
like French or German, Slavic languages like Rus-
sian, Semitic languages as Hebrew and Arabic,
and diverse Asian languages such as Chinese and
Persian. To configure parameters we have used a
set of 10 concepts in Russian as a development set.
These concepts were not used in evaluation.
We examined a wide variety of concepts and for
each of them we used all languages with available
translations. Table 1 shows the resulting top 10
most utilized languages in our experiments.
11In this expression i runs only on languages with term t&apos;
hence the summation is not 1.
</bodyText>
<table confidence="0.999127636363636">
English Russian Hebrew
German(68%) English(70%) English(66%)
French(60%) German(62%) German(65%)
Italian(60%) French(62%) Italian(61%)
Portuguese(57%) Spanish(58%) French(59%)
Spanish(55%) Italian(56%) Spanish(57%)
Turkish(51%) Portuguese(54%) Portuguese(57%)
Russian(50%) Korean(50%) Korean(48%)
Korean(46%) Turkish(49%) Russian(43%)
Chinese(45%) Chinese(47%) Turkish(43%)
Czech(42%) Polish (44%) Czech(40%)
</table>
<tableCaption confidence="0.940941333333333">
Table 1: The ten most utilized intermediate languages in
our experiments. In parentheses we show the percentage of
new terms that these languages helped discover.
</tableCaption>
<bodyText confidence="0.9999478">
We have used the English, Hebrew (Ordan and
Winter, 2008) and Russian (Gelfenbeynand et al.,
2003) WordNets as sources for concepts and for
the automatic evaluation. Our concept set selec-
tion was based on English WN subtrees. To per-
form comparable experiments with Russian and
Hebrew, we have selected the same subtrees in
the Hebrew and Russian WN. Concept definitions
given to human judges for evaluation were based
on the corresponding WN glosses. For automated
evaluation we selected 150 synsets/subtrees con-
taining at least 10 single word terms (existing in
all three tested languages).
For manual evaluation we used a subset of 24
of these concepts. In this subset we tried to select
generic concepts manually, such that no domain
expert knowledge was required to check their cor-
rectness. Ten of these concepts were identical to
ones used in (Widdows and Dorow, 2002; Davi-
dov and Rappoport, 2006), which allowed us to
compare our results to recent work in case of En-
glish. Table 2 shows these 10 concepts along with
the sample terms. While the number of tested con-
cepts is not very large, it provides a good indica-
tion for the quality of our approach.
</bodyText>
<table confidence="0.999320636363636">
Concept Sample terms
Musical instruments guitar, flute, piano
Vehicles/transport train, bus, car
Academic subjects physics, chemistry, psychology
Body parts hand, leg, shoulder
Food egg, butter, bread
Clothes pants, skirt, jacket
Tools hammer, screwdriver, wrench
Places park, castle, garden
Crimes murder, theft, fraud
Diseases rubella, measles, jaundice
</table>
<tableCaption confidence="0.999366">
Table 2: Ten of the selected concepts with sample terms.
</tableCaption>
<bodyText confidence="0.450852">
guage frequency by
</bodyText>
<equation confidence="0.528688">
E
tiEC(Freq(Tr(ti, L)))
</equation>
<page confidence="0.982567">
857
</page>
<subsectionHeader confidence="0.995214">
4.2 Multilingual dictionaries
</subsectionHeader>
<bodyText confidence="0.999979625">
We developed tools for automatic access to a num-
ber of dictionaries. We used Wikipedia cross-
language links as our main source (&gt; 60%) for
offline translation. These links include translation
of Wikipedia terms into dozens of languages. The
main advantage of using Wikipedia is its wide cov-
erage of concepts and languages. However, one
problem it has is that it frequently encodes too
specific senses and misses common ones (bear is
translated as family Ursidae, missing its common
“wild animal” sense). To overcome these difficul-
ties, we also used Wiktionary and complemented
these offline resources with automated queries to
several (25) online dictionaries. We start with
Wikipedia definitions, then Wiktionary, and then,
if not found, we turn to online dictionaries.
</bodyText>
<sectionHeader confidence="0.980332" genericHeader="evaluation">
5 Evaluation and Results
</sectionHeader>
<bodyText confidence="0.999734666666667">
Potential applications of our framework include
both the extension of existing lexical databases
and the construction of new databases from a small
set of seeds for each concept. Consequently, in
our evaluation we aim to check both the ability
to extend nearly complete concepts and the abil-
ity to discover most of the concept given a few
seeds. Since in our current framework we extend
a small subset of concepts rather than the whole
database, we could not utilize application-based
evaluation strategies such as performance in WSD
tasks (Cuadros and Rigau, 2008).
</bodyText>
<subsectionHeader confidence="0.998149">
5.1 Human judgment evaluation
</subsectionHeader>
<bodyText confidence="0.99997872">
In order to check how well we can extend existing
concepts, we count and verify the quality of new
concept terms discovered by the algorithm given
complete concepts from WN. Performing an auto-
matic evaluation of such new terms is a challeng-
ing task, since there are no exhaustive term lists
available. Thus, in order to check how well newly
added terms fit the concept definition, we have to
use human judges.
We provided four human subjects with 24 lists
of newly discovered terms, together with original
concept definitions (written as descriptive natural
language sentences) and asked them to rank (1-10,
10 being best) how well each of these terms fits
the given definition. We have instructed judges to
accept common misspellings and reject words that
are too general/narrow for the provided definition.
We mixed the discovered terms with equal
amounts of terms from three control sets: (1) terms
from the original WN concept; (2) randomly se-
lected WN terms; (3) terms obtained by apply-
ing the single-language concept acquisition algo-
rithm described in Section 3.3 in the source lan-
guage. Kappa inter-annotator agreement scores
were above 0.6 for all tests below.
</bodyText>
<subsectionHeader confidence="0.653497">
5.1.1 WordNet concept extension
</subsectionHeader>
<bodyText confidence="0.999985896551724">
The middle column of Table 3 shows the judge
scores and average amount of added terms for
each source language. In this case the algorithm
was provided with complete term lists as con-
cept definitions, and was requested to extend these
lists. We can see that while the scores for original
WN terms are not perfect (7/10), single-language
and cross-lingual concept extension achieve nearly
the same scores. However, the latter discovers
many more new concept terms without reducing
quality. The difference becomes more substan-
tial for Hebrew, which is a resource-poor source
language, heavily affecting the performance of
single-language concept extension methods.
The low ranks for WN reflect the ambiguity of
definition of some of its classification subtrees.
Thus, for the ‘body part’ concept defined in Word-
Net as “any part of an organism such as an or-
gan or extremity” (which is not supposed to re-
quire domain-specific knowledge to identify) low
scores were given (correctly) by judges to generic
terms such as tissue, system, apparatus and pro-
cess (process defined in WN as “a natural pro-
longation or projection from a part of an organ-
ism”), positioned in WN as direct hyponyms of
body parts. Low scores were also given to very
specific terms like “saddle” (posterior part of the
back of a domestic fowl) or very ambiguous terms
like “small” (the slender part of the back).
</bodyText>
<subsectionHeader confidence="0.577607">
5.1.2 Seed-based concept extension
</subsectionHeader>
<bodyText confidence="0.99991075">
The rightmost column of Table 3 shows similar in-
formation to the middle column, but when only
the three most frequent terms from the original
WN concept were given as concept definitions.
We can see that even given three words as seeds,
the cross-lingual framework allows to discover
many new terms. Surprisingly, terms extracted by
the cross-lingual framework achieve significantly
higher scores not only in comparison to the single-
language algorithm but also in comparison to ex-
isting WN terms. Thus while the “native” WN
concept and single-language concept extension re-
</bodyText>
<page confidence="0.994582">
858
</page>
<bodyText confidence="0.998333857142857">
sults get a score of 7/10, terms obtained by the
cross-lingual framework obtain an average score
of nearly 9/10.
This suggests that our cross-lingual framework
can lead to better (from a human judgment point
of view) assignment of terms to concepts, even in
comparison to manual annotation.
</bodyText>
<table confidence="0.998618647058824">
Input
all terms 3 terms
English
WordNet 7.2 7.2
Random 1.8 1.8
SingleLanguage 7.0(10) 7.8(18)
Crosslingual 6.9(19) 8.8(26)
Russian
WordNet 7.8 7.8
Random 1.9 1.9
SingleLanguage 7.4(10) 8.1(16)
Crosslingual 7.6(21) 9.0(29)
Hebrew
WordNet 7.0 7.0
Random 1.3 1.3
SingleLanguage 6.5(4) 7.5(6)
Crosslingual 6.8(18) 8.9(24)
</table>
<tableCaption confidence="0.859816333333333">
Table 3: Human judgment scores for concept extension in
three languages (1 ... 10, 10 is best). The WordNet, Random
and SingleLanguage rows provide corresponding baselines.
Average count of newly added terms are shown in parenthe-
ses. Average original WN concept size in this set was 36 for
English, 32 for Russian and 27 for Hebrew.
</tableCaption>
<subsectionHeader confidence="0.990638">
5.2 WordNet-based evaluation
</subsectionHeader>
<bodyText confidence="0.999778133333333">
While human judgment evaluation provides a
good indication for the quality of our framework,
it has severe limitations. Thus terms in many con-
cepts require domain expertise to be properly la-
beled. We have complemented human judgment
evaluation with automated WN-based evaluation
with a greater (150) number of concepts. For each
of the 150 concepts, we have applied our frame-
work on a subset of the available terms, and esti-
mated precision and recall of the resulting term list
in comparison to the original WN term list. The
evaluation protocol and metrics were very simi-
lar to (Davidov and Rappoport, 2006; Widdows
and Dorow, 2002) which allowed us to do indirect
comparison to previous work.
Table 4 shows precision and recall for this task
comparing single-language concept extension and
the cross-lingual framework. We can see that
in all cases, utilization of the latter greatly im-
proves recall. It also significantly outperforms
the single-language pattern-based method intro-
duced by (Davidov and Rappoport, 2006), which
achieves average precision of 79.3 on a similar set
in English (in comparison to 86.7 in this study).
We can also see a decrease in precision when the
algorithm is provided with 50% of the concept
terms as input and had to discover the remaining
50%. However, careful examination of the results
shows that this decrease is due to discovery of ad-
ditional correct terms not present in WordNet.
</bodyText>
<table confidence="0.9983775">
Input
50% terms 3 terms
P R F P R F
English
SingleLanguage 89.2 75.9 82.0 80.6 15.2 25.6
CrossLingual 86.5 91.1 88.7 86.7 60.2 71.1
Russian
SingleLanguage 91.3 69.0 78.6 82.1 18.3 29.9
CrossLingual 84.9 86.2 85.5 85.3 62.1 71.9
Hebrew
SingleLanguage 93.8 38.6 54.7 90.2 5.7 10.7
CrossLingual 86.5 82.4 84.4 93.9 55.6 69.8
</table>
<tableCaption confidence="0.996212">
Table 4: WordNet-based precision (P) and recall (R) for
concept extension.
</tableCaption>
<subsectionHeader confidence="0.998649">
5.3 Contribution of each language
</subsectionHeader>
<bodyText confidence="0.999996846153846">
Each of the 45 languages we used influences the
score of at least 5% of the discovered terms. How-
ever, it is not apparent if all languages are indeed
beneficial or if only a handful of languages can
be used. In order to check this point we have per-
formed partial automated tests as described in Sec-
tion 5.2, removing one language at a time. We also
tried to remove random subsets of 2-3 languages,
comparing them to removal of one of them. We
saw that in each case removal of more languages
caused a consistent (while sometimes minor) de-
crease both in precision and recall metrics. Thus,
each language contributes to the system.
</bodyText>
<sectionHeader confidence="0.999795" genericHeader="conclusions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.9999836875">
We proposed a framework which given a set of
terms defining a concept in some language, uti-
lizes multilingual information available on the
web in order to extend this list. This method
allows to take advantage of web data in many
languages, requiring only multilingual dictionar-
ies. Our method was able to discover a substan-
tially greater number of terms than state-of-the-art
single language pattern-based concept extension
methods, while retaining high precision.
We also showed that concepts obtained by this
method tend to be more coherent in compari-
son to corresponding concepts in WN, a man-
ually prepared resource. Due to its relative
language-independence and modest data require-
ments, this framework allows gathering required
</bodyText>
<page confidence="0.995409">
859
</page>
<bodyText confidence="0.999821666666667">
concept information from the web even if it is scat-
tered among different and relatively uncommon or
resource-poor languages.
</bodyText>
<sectionHeader confidence="0.996441" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999813161290323">
Mishele Banko, Michael J Cafarella , Stephen Soder-
land, Matt Broadhead, Oren Etzioni, 2007. Open
information extraction from the Web. IJCAI ’07.
Wauter Bosma, Chris Callison-Burch, 2007. Para-
phrase substitution for recognizing textual entail-
ment.. Evaluation of Multilingual and Multimodal
Information Retrieval, Lecture Notes in Computer
Science ’07.
Sharon Caraballo, 1999. Automatic construction of
a hypernym-labeled noun hierarchy from text. ACL
’99.
Montse Cuadros, German Rigau, 2008. KnowNet:
Building a large net of knowledge from the Web.
COLING ’08.
James R. Curran, Marc Moens, 2002. Improvements
in automatic thesaurus extraction SIGLEX 02’, 59–
66.
Dmitry Davidov, Ari Rappoport, 2006. Effi-
cient unsupervised discovery of word categories us-
ing symmetric patterns and high frequency words.
COLING-ACL ’06.
Dmitry Davidov, Ari Rappoport, Moshe Koppel,
2007. Fully unsupervised discovery of concept-
specific relationships by web mining. ACL ’07.
Dmitry Davidov, Ari Rappoport, 2009. Translation
and extension of concepts across languages. EACL
’09.
Scott Deerwester, Susan Dumais, George Furnas,
Thomas Landauer, Richard Harshman, 1990. In-
dexing by latent semantic analysis. J. of the Ameri-
can Society for Info. Science, 41(6):391–407.
Beate Dorow, Dominic Widdows, Katarina Ling, Jean-
Pierre Eckmann, Danilo Sergi, Elisha Moses, 2005.
Using curvature and Markov clustering in graphs for
lexical acquisition and word sense discrimination.
MEANING ’05.
Oren Etzioni, Michael Cafarella, Doug Downey,
S. Kok, Ana-Maria Popescu, Tal Shaked, Stephen
Soderland, Daniel Weld, Alexander Yates, 2005.
Unsupervised named-entity extraction from the
web: An experimental study. Arti�cial Intelligence,
165(1):91134.
Dayne Freitag, 2004. Trained named entity recogni-
tion using distributional clusters. EMNLP ’04.
Ilya Gelfenbeyn, Artem Goncharuk, Vladislav Lehelt,
Anton Lipatov, Victor Shilo, 2003. Automatic
translation of WordNet semantic network to Russian
language (in Russian) International Dialog 2003
Workshop.
J. Gorman, J.R. Curran, 2006. Scaling distributional
similarity to large corpora. COLING-ACL ’06.
Marti Hearst, 1992. Automatic acquisition of hy-
ponyms from large text corpora. COLING ’92.
Jagadeesh Jagarlamudi, A Kumaran, 2007. Cross-
lingual information retrieval system for Indian lan-
guages. Working Notes for the CLEF 2007 Work-
shop.
Dekang Lin, 1998. Automatic retrieval and clustering
of similar words. COLING ’98.
Noam Ordan, Shuly Wintner, 2007. Hebrew Word-
Net: a test case of aligning lexical databases across
languages. International Journal of Translation
19(1):39-58, 2007.
Marius Pasca, Dekang Lin, Jeffrey Bigham, Andrei
Lifchits, Alpa Jain, 2006. Names and similarities on
the web: fact extraction in the fast lane. COLING-
ACL ’06.
Marius Pasca, Benjamin Van Durme, 2008. Weakly-
supervised acquisition of open-domain classes and
class attributes from web documents and query logs.
ACL ’08.
Patrick Pantel, Dekang Lin, 2002. Discovering word
senses from text. SIGKDD ’02.
Patrick Pantel, Deepak Ravichandran, Eduard Hovy,
2004. Towards terascale knowledge acquisition.
COLING ’04.
John Paolillo, Daniel Pimienta, Daniel Prado, et al.,
2005. Measuring linguistic diversity on the Internet.
UNESCO Institute for Statistics Montreal, Canada.
Adam Pease, Christiane Fellbaum, Piek Vossen, 2008.
Building the global WordNet grid. CIL18.
Fernando Pereira, Naftali Tishby, Lillian Lee, 1993.
Distributional clustering of English words. ACL ’93.
Ellen Riloff, Rosie Jones, 1999. Learning dictionaries
for information extraction by multi-level bootstrap-
ping. AAAI ’99.
Rion Snow, Daniel Jurafsky, Andrew Ng, 2006. Se-
mantic taxonomy induction from heterogeneous ev-
idence. COLING-ACL ’06.
Lonneke van der Plas, Jorg Tiedemann, 2006. Find-
ing synonyms using automatic word alignment and
measures of distributional similarity. COLING-ACL
’06.
</reference>
<page confidence="0.97203">
860
</page>
<reference confidence="0.998528555555556">
Martin Volk, Paul Buitelaar, 2002. A systematic eval-
uation of concept-based cross-language information
retrieval in the medical domain. In: Proc. of 3rd
Dutch-Belgian Information Retrieval Workshop.
ˇSpela Vintar, Darja Fiˇser, 2008. Harvesting multi-
word expressions from parallel corpora. LREC ’08.
Dominic Widdows, Beate Dorow, 2002. A graph
model for unsupervised lexical acquisition. COL-
ING ’02.
</reference>
<page confidence="0.998357">
861
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.262894">
<title confidence="0.61616525">Enhancement of Lexical Concepts Using Cross-lingual Web Mining Dmitry The Hebrew University of dmitry@alice.nc.huji.ac.il</title>
<author confidence="0.888492">Ari</author>
<affiliation confidence="0.9370875">Institute of Computer The Hebrew University of</affiliation>
<email confidence="0.955874">arir@cs.huji.ac.il</email>
<abstract confidence="0.999153363636364">Sets of lexical items sharing a significant of their meaning are fundamental in linguistics and NLP. Manual concept compilation is labor intensive, error prone and subjective. We present a web-based concept extension algorithm. Given a set of terms specifying a concept in some language, we translate them to a wide range of intermediate languages, disambiguate the translations using web counts, and discover additional concept terms using symmetric patterns. We then translate the discovered terms back into the original language, score them, and extend the original concept by adding backtranslations having high scores. We evaluate our method in 3 source languages and 45 intermediate languages, using both human judgments and WordNet. In all cases, our cross-lingual algorithm significantly improves high quality concept extension.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<date>2007</date>
<booktitle>Open information extraction from the Web. IJCAI ’07.</booktitle>
<marker>Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Mishele Banko, Michael J Cafarella , Stephen Soderland, Matt Broadhead, Oren Etzioni, 2007. Open information extraction from the Web. IJCAI ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wauter Bosma</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrase substitution for recognizing textual entailment.. Evaluation of Multilingual and Multimodal Information Retrieval,</title>
<date>2007</date>
<journal>Lecture Notes in Computer Science</journal>
<volume>07</volume>
<contexts>
<context position="7565" citStr="Bosma and Callison-Burch, 2007" startWordPosition="1178" endWordPosition="1181">ods have been proposed for the discovery of concepts from seeds (Pantel et al., 2004; Davidov et al., 2007; Pasca et al., 2006). Most of these studies were done for English, while some show the applicability of their methods to other languages, including Greek, Czech, Slovene and French. Most of these papers attempt to discover concepts from data available in some specific language. Recently several studies have proposed to utilize a second language or several specified languages in order to extract or extend concepts (Vintar and Fiˇser, 2008; van der Plas and Tiedemann, 2006) or paraphrases (Bosma and Callison-Burch, 2007). However, these methods usually require the availability of parallel corpora, which limits their usefulness. Most of these methods utilize distributional measures, hence they do not possess the advantages of the pattern-based framework. Unlike in the majority of recent studies, where the framework is designed with specific languages in mind, in our task, in order to take advantage of information from diverse languages, the algorithm should be able to deal well with a wide variety of possible intermediate languages without any manual adaptations. Relying solely on multilingual dictionaries and</context>
</contexts>
<marker>Bosma, Callison-Burch, 2007</marker>
<rawString>Wauter Bosma, Chris Callison-Burch, 2007. Paraphrase substitution for recognizing textual entailment.. Evaluation of Multilingual and Multimodal Information Retrieval, Lecture Notes in Computer Science ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Caraballo</author>
</authors>
<title>Automatic construction of a hypernym-labeled noun hierarchy from text.</title>
<date>1999</date>
<journal>ACL</journal>
<volume>99</volume>
<contexts>
<context position="6200" citStr="Caraballo (1999)" startWordPosition="961" endWordPosition="963">icular kind, as done in (Freitag, 2004) using co-clustering and in (Etzioni et al., 2005) using predefined pattern types. The two main algorithmic approaches to the problem are pattern-based concept discovery and clustering of context feature vectors. The latter approach represents word contexts as vectors in some space and uses similarity measures and automatic clustering in that space (Deerwester et al., 1990). Pereira et al.(1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition. Pantel and Lin (2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. While great effort has been made for improving the computational complexity of these methods (Gorman and Curran, 2006), they still remain data and computation intensive. The second major algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004). In concept acquisition, pattern-based methods were shown to outperform LSA by a large margin (Widdows and Dorow, 2002). Since (Hea</context>
</contexts>
<marker>Caraballo, 1999</marker>
<rawString>Sharon Caraballo, 1999. Automatic construction of a hypernym-labeled noun hierarchy from text. ACL ’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Montse Cuadros</author>
<author>German Rigau</author>
</authors>
<title>KnowNet: Building a large net of knowledge from the Web.</title>
<date>2008</date>
<journal>COLING</journal>
<volume>08</volume>
<contexts>
<context position="4924" citStr="Cuadros and Rigau, 2008" startWordPosition="758" endWordPosition="761"> details the algorithm, Section 4 describes the evaluation protocol and Section 5 presents our results. 2 Related work One of the main goals of this paper is the extension or automated creation of lexical databases such as WN. Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al., 2006)) or WN in other languages (e.g., (Vintar and Fiˇser, 2008)). The majority of this research was done on extending the tree structure (finding new synsets (Snow et al., 2006) or enriching WN with new relationships (Cuadros and Rigau, 2008)) rather than improving the quality of existing concept/synset nodes. Other related studies develop concept acquisition frameworks for on-demand tasks where concepts are defined by user-provided seeds or patterns (Etzioni et al., 2005; Davidov et al., 2007), or for fully unsupervised database creation where concepts are discovered from scratch (Banko et al., 2007; Davidov and Rappoport, 2006). Some papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of the concept acquisition problem where the desired</context>
<context position="27842" citStr="Cuadros and Rigau, 2008" startWordPosition="4475" endWordPosition="4478">, we turn to online dictionaries. 5 Evaluation and Results Potential applications of our framework include both the extension of existing lexical databases and the construction of new databases from a small set of seeds for each concept. Consequently, in our evaluation we aim to check both the ability to extend nearly complete concepts and the ability to discover most of the concept given a few seeds. Since in our current framework we extend a small subset of concepts rather than the whole database, we could not utilize application-based evaluation strategies such as performance in WSD tasks (Cuadros and Rigau, 2008). 5.1 Human judgment evaluation In order to check how well we can extend existing concepts, we count and verify the quality of new concept terms discovered by the algorithm given complete concepts from WN. Performing an automatic evaluation of such new terms is a challenging task, since there are no exhaustive term lists available. Thus, in order to check how well newly added terms fit the concept definition, we have to use human judges. We provided four human subjects with 24 lists of newly discovered terms, together with original concept definitions (written as descriptive natural language s</context>
</contexts>
<marker>Cuadros, Rigau, 2008</marker>
<rawString>Montse Cuadros, German Rigau, 2008. KnowNet: Building a large net of knowledge from the Web. COLING ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
<author>Marc Moens</author>
</authors>
<date>2002</date>
<booktitle>Improvements in automatic thesaurus extraction SIGLEX 02’,</booktitle>
<pages>59--66</pages>
<contexts>
<context position="6046" citStr="Curran and Moens (2002)" startWordPosition="935" endWordPosition="938"> Entity Recognition can be viewed as an instance of the concept acquisition problem where the desired concepts contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using co-clustering and in (Etzioni et al., 2005) using predefined pattern types. The two main algorithmic approaches to the problem are pattern-based concept discovery and clustering of context feature vectors. The latter approach represents word contexts as vectors in some space and uses similarity measures and automatic clustering in that space (Deerwester et al., 1990). Pereira et al.(1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition. Pantel and Lin (2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. While great effort has been made for improving the computational complexity of these methods (Gorman and Curran, 2006), they still remain data and computation intensive. The second major algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora</context>
</contexts>
<marker>Curran, Moens, 2002</marker>
<rawString>James R. Curran, Marc Moens, 2002. Improvements in automatic thesaurus extraction SIGLEX 02’, 59– 66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
</authors>
<title>Efficient unsupervised discovery of word categories using symmetric patterns and high frequency words.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="5319" citStr="Davidov and Rappoport, 2006" startWordPosition="820" endWordPosition="824">WN in other languages (e.g., (Vintar and Fiˇser, 2008)). The majority of this research was done on extending the tree structure (finding new synsets (Snow et al., 2006) or enriching WN with new relationships (Cuadros and Rigau, 2008)) rather than improving the quality of existing concept/synset nodes. Other related studies develop concept acquisition frameworks for on-demand tasks where concepts are defined by user-provided seeds or patterns (Etzioni et al., 2005; Davidov et al., 2007), or for fully unsupervised database creation where concepts are discovered from scratch (Banko et al., 2007; Davidov and Rappoport, 2006). Some papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of the concept acquisition problem where the desired concepts contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using co-clustering and in (Etzioni et al., 2005) using predefined pattern types. The two main algorithmic approaches to the problem are pattern-based concept discovery and clustering of context feature vectors. The latter approach represents word contexts as vectors in some space and uses simi</context>
<context position="9296" citStr="Davidov and Rappoport, 2006" startWordPosition="1445" endWordPosition="1448">853 it is not clear whether translated patterns can work well on different languages. Also, the absence of clear word segmentation in some languages (e.g., Chinese) can make many methods inapplicable. A few recently proposed concept acquisition methods require only a handful of seed words and no pattern pre-specification (Davidov et al., 2007; Pasca and Van Durme, 2008). While these studies avoid some of the obstacles above, it still remains open whether such methods are indeed languageindependent. In the translation to intermediate languages part of our framework, we adapt the algorithms in (Davidov and Rappoport, 2006; Davidov et al., 2007) to suit diverse languages (including ones without explicit word segmentation). We also develop a method for efficient automated disambiguation and translation of terms to and from any available intermediate language. Our study is related to cross-language information retrieval (CLIR/CLEF) frameworks. Both deal with information extracted from a set of languages. However, the majority of CLIR studies pursue different targets. One of the main CLIR goals is the retrieval of documents based on explicit queries, when the document language is not the query language (Volk and B</context>
<context position="25736" citStr="Davidov and Rappoport, 2006" startWordPosition="4142" endWordPosition="4146">nd Hebrew, we have selected the same subtrees in the Hebrew and Russian WN. Concept definitions given to human judges for evaluation were based on the corresponding WN glosses. For automated evaluation we selected 150 synsets/subtrees containing at least 10 single word terms (existing in all three tested languages). For manual evaluation we used a subset of 24 of these concepts. In this subset we tried to select generic concepts manually, such that no domain expert knowledge was required to check their correctness. Ten of these concepts were identical to ones used in (Widdows and Dorow, 2002; Davidov and Rappoport, 2006), which allowed us to compare our results to recent work in case of English. Table 2 shows these 10 concepts along with the sample terms. While the number of tested concepts is not very large, it provides a good indication for the quality of our approach. Concept Sample terms Musical instruments guitar, flute, piano Vehicles/transport train, bus, car Academic subjects physics, chemistry, psychology Body parts hand, leg, shoulder Food egg, butter, bread Clothes pants, skirt, jacket Tools hammer, screwdriver, wrench Places park, castle, garden Crimes murder, theft, fraud Diseases rubella, measle</context>
<context position="32642" citStr="Davidov and Rappoport, 2006" startWordPosition="5251" endWordPosition="5254">et-based evaluation While human judgment evaluation provides a good indication for the quality of our framework, it has severe limitations. Thus terms in many concepts require domain expertise to be properly labeled. We have complemented human judgment evaluation with automated WN-based evaluation with a greater (150) number of concepts. For each of the 150 concepts, we have applied our framework on a subset of the available terms, and estimated precision and recall of the resulting term list in comparison to the original WN term list. The evaluation protocol and metrics were very similar to (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) which allowed us to do indirect comparison to previous work. Table 4 shows precision and recall for this task comparing single-language concept extension and the cross-lingual framework. We can see that in all cases, utilization of the latter greatly improves recall. It also significantly outperforms the single-language pattern-based method introduced by (Davidov and Rappoport, 2006), which achieves average precision of 79.3 on a similar set in English (in comparison to 86.7 in this study). We can also see a decrease in precision when the algorithm is provided with 5</context>
</contexts>
<marker>Davidov, Rappoport, 2006</marker>
<rawString>Dmitry Davidov, Ari Rappoport, 2006. Efficient unsupervised discovery of word categories using symmetric patterns and high frequency words. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
<author>Moshe Koppel</author>
</authors>
<title>Fully unsupervised discovery of conceptspecific relationships by web mining.</title>
<date>2007</date>
<journal>ACL</journal>
<volume>07</volume>
<contexts>
<context position="5181" citStr="Davidov et al., 2007" startWordPosition="798" endWordPosition="801">LP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al., 2006)) or WN in other languages (e.g., (Vintar and Fiˇser, 2008)). The majority of this research was done on extending the tree structure (finding new synsets (Snow et al., 2006) or enriching WN with new relationships (Cuadros and Rigau, 2008)) rather than improving the quality of existing concept/synset nodes. Other related studies develop concept acquisition frameworks for on-demand tasks where concepts are defined by user-provided seeds or patterns (Etzioni et al., 2005; Davidov et al., 2007), or for fully unsupervised database creation where concepts are discovered from scratch (Banko et al., 2007; Davidov and Rappoport, 2006). Some papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of the concept acquisition problem where the desired concepts contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using co-clustering and in (Etzioni et al., 2005) using predefined pattern types. The two main algorithmic approaches to the problem are pattern-based concep</context>
<context position="7040" citStr="Davidov et al., 2007" startWordPosition="1093" endWordPosition="1096">d computation intensive. The second major algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004). In concept acquisition, pattern-based methods were shown to outperform LSA by a large margin (Widdows and Dorow, 2002). Since (Hearst, 1992), who used a manually prepared set of initial lexical patterns in order to acquire relationships, numerous patternbased methods have been proposed for the discovery of concepts from seeds (Pantel et al., 2004; Davidov et al., 2007; Pasca et al., 2006). Most of these studies were done for English, while some show the applicability of their methods to other languages, including Greek, Czech, Slovene and French. Most of these papers attempt to discover concepts from data available in some specific language. Recently several studies have proposed to utilize a second language or several specified languages in order to extract or extend concepts (Vintar and Fiˇser, 2008; van der Plas and Tiedemann, 2006) or paraphrases (Bosma and Callison-Burch, 2007). However, these methods usually require the availability of parallel corpo</context>
<context position="9013" citStr="Davidov et al., 2007" startWordPosition="1399" endWordPosition="1402">e are a few obstacles that may hinder applying common pattern-based methods to other languages. Many studies utilize parsing or POS tagging, which frequently depend on the availability and quality of language-specific tools. Some studies specify seed patterns in advance, and 853 it is not clear whether translated patterns can work well on different languages. Also, the absence of clear word segmentation in some languages (e.g., Chinese) can make many methods inapplicable. A few recently proposed concept acquisition methods require only a handful of seed words and no pattern pre-specification (Davidov et al., 2007; Pasca and Van Durme, 2008). While these studies avoid some of the obstacles above, it still remains open whether such methods are indeed languageindependent. In the translation to intermediate languages part of our framework, we adapt the algorithms in (Davidov and Rappoport, 2006; Davidov et al., 2007) to suit diverse languages (including ones without explicit word segmentation). We also develop a method for efficient automated disambiguation and translation of terms to and from any available intermediate language. Our study is related to cross-language information retrieval (CLIR/CLEF) fra</context>
<context position="18138" citStr="Davidov et al., 2007" startWordPosition="2899" endWordPosition="2902">y a few dozen queries (40 on the average) are required to obtain sufficient data, and queries can be parallelized. Thus the relevant data can be downloaded 5Yahoo! allows restriction for 42 languages. 6These are Yahoo! queries where enclosing words in “” means searching for an exact phrase and “*” means a wildcard for exactly one arbitrary word. F(w1, w2) = Cnt(w1) x Cnt(w2) Cnt(“w1 * w2”) x Cnt(“w2 * w1”) Tr(Ci) = argmax max I(F(Tr(Ci, si), Tr(Cj, sj))) si sj joi 855 in seconds. This makes our approach practical for on-demand retrieval or concept verification tasks. Meta-patterns. Following (Davidov et al., 2007), we seek symmetric patterns to retrieve concept terms. We use two meta-pattern types. First, a Two-Slot pattern type constructed as follows: [Prefix] C1 [Infix] C2 [Postfix] Ci are slots for concept terms. We allow up to Limmwe space-separated7 words to be in a single slot. Infix may contain punctuation, spaces, and up to Limmwe × 4 words. Prefix and Postfix are limited to contain punctuation characters and/or Limmwe words. Terms of the same concept frequently co-appear in lists. To utilize this, we introduce two additional List pattern types$: [Prefix] C1 [Infix] (Ci [Infix])+ (1) [Infix] (C</context>
</contexts>
<marker>Davidov, Rappoport, Koppel, 2007</marker>
<rawString>Dmitry Davidov, Ari Rappoport, Moshe Koppel, 2007. Fully unsupervised discovery of conceptspecific relationships by web mining. ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
</authors>
<title>Translation and extension of concepts across languages.</title>
<date>2009</date>
<journal>EACL</journal>
<volume>09</volume>
<contexts>
<context position="11420" citStr="Davidov and Rappoport, 2009" startWordPosition="1781" endWordPosition="1784">he translations are disambiguated using web counts; (3) for each language, we retrieve a set of web snippets where these translations coappear and apply a pattern-based concept extension algorithm for discovering additional terms; (4) we translate the discovered terms back to the source language, and disambiguate them; (5) we score the back-translated terms using data on their behavior in the intermediate languages, and merge the sets obtained from different languages into a single one, retaining terms whose score passes a certain threshold. Stages 1-3 of the algorithm have been described in (Davidov and Rappoport, 2009), where the goal was to translate a concept given in one language to other languages. The framework presented here includes the new stages 4-5, and its goal and evaluation methods are completely different. 3.1 Concept specification and translation We start from a set of words denoting a concept in a given source language. Thus we may use words like (apple, banana, ...) as the definition of the concept of fruit or (bear, wolf, fox, ...) as the definition of wild animals. In order to reduce noise, we limit the length (in words) of multiword expressions considered as terms. To calculate this limi</context>
</contexts>
<marker>Davidov, Rappoport, 2009</marker>
<rawString>Dmitry Davidov, Ari Rappoport, 2009. Translation and extension of concepts across languages. EACL ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>Susan Dumais</author>
<author>George Furnas</author>
<author>Thomas Landauer</author>
<author>Richard Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>J. of the American Society for Info. Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="5999" citStr="Deerwester et al., 1990" startWordPosition="928" endWordPosition="931"> build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of the concept acquisition problem where the desired concepts contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using co-clustering and in (Etzioni et al., 2005) using predefined pattern types. The two main algorithmic approaches to the problem are pattern-based concept discovery and clustering of context feature vectors. The latter approach represents word contexts as vectors in some space and uses similarity measures and automatic clustering in that space (Deerwester et al., 1990). Pereira et al.(1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition. Pantel and Lin (2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. While great effort has been made for improving the computational complexity of these methods (Gorman and Curran, 2006), they still remain data and computation intensive. The second major algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors,</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Scott Deerwester, Susan Dumais, George Furnas, Thomas Landauer, Richard Harshman, 1990. Indexing by latent semantic analysis. J. of the American Society for Info. Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beate Dorow</author>
<author>Dominic Widdows</author>
<author>Katarina Ling</author>
<author>JeanPierre Eckmann</author>
<author>Danilo Sergi</author>
<author>Elisha Moses</author>
</authors>
<title>Using curvature and Markov clustering in graphs for lexical acquisition and word sense discrimination.</title>
<date>2005</date>
<journal>MEANING</journal>
<volume>05</volume>
<marker>Dorow, Widdows, Ling, Eckmann, Sergi, Moses, 2005</marker>
<rawString>Beate Dorow, Dominic Widdows, Katarina Ling, JeanPierre Eckmann, Danilo Sergi, Elisha Moses, 2005. Using curvature and Markov clustering in graphs for lexical acquisition and word sense discrimination. MEANING ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
<author>S Kok</author>
</authors>
<title>Ana-Maria Popescu, Tal Shaked, Stephen Soderland, Daniel Weld, Alexander Yates,</title>
<date>2005</date>
<journal>Arti�cial Intelligence,</journal>
<volume>165</volume>
<issue>1</issue>
<contexts>
<context position="5158" citStr="Etzioni et al., 2005" startWordPosition="794" endWordPosition="797">importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al., 2006)) or WN in other languages (e.g., (Vintar and Fiˇser, 2008)). The majority of this research was done on extending the tree structure (finding new synsets (Snow et al., 2006) or enriching WN with new relationships (Cuadros and Rigau, 2008)) rather than improving the quality of existing concept/synset nodes. Other related studies develop concept acquisition frameworks for on-demand tasks where concepts are defined by user-provided seeds or patterns (Etzioni et al., 2005; Davidov et al., 2007), or for fully unsupervised database creation where concepts are discovered from scratch (Banko et al., 2007; Davidov and Rappoport, 2006). Some papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of the concept acquisition problem where the desired concepts contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using co-clustering and in (Etzioni et al., 2005) using predefined pattern types. The two main algorithmic approaches to the problem a</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Kok, 2005</marker>
<rawString>Oren Etzioni, Michael Cafarella, Doug Downey, S. Kok, Ana-Maria Popescu, Tal Shaked, Stephen Soderland, Daniel Weld, Alexander Yates, 2005. Unsupervised named-entity extraction from the web: An experimental study. Arti�cial Intelligence, 165(1):91134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dayne Freitag</author>
</authors>
<title>Trained named entity recognition using distributional clusters.</title>
<date>2004</date>
<journal>EMNLP</journal>
<volume>04</volume>
<contexts>
<context position="5623" citStr="Freitag, 2004" startWordPosition="873" endWordPosition="875">tudies develop concept acquisition frameworks for on-demand tasks where concepts are defined by user-provided seeds or patterns (Etzioni et al., 2005; Davidov et al., 2007), or for fully unsupervised database creation where concepts are discovered from scratch (Banko et al., 2007; Davidov and Rappoport, 2006). Some papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of the concept acquisition problem where the desired concepts contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using co-clustering and in (Etzioni et al., 2005) using predefined pattern types. The two main algorithmic approaches to the problem are pattern-based concept discovery and clustering of context feature vectors. The latter approach represents word contexts as vectors in some space and uses similarity measures and automatic clustering in that space (Deerwester et al., 1990). Pereira et al.(1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition. Pantel and Lin (2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and a</context>
</contexts>
<marker>Freitag, 2004</marker>
<rawString>Dayne Freitag, 2004. Trained named entity recognition using distributional clusters. EMNLP ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ilya Gelfenbeyn</author>
<author>Artem Goncharuk</author>
<author>Vladislav Lehelt</author>
<author>Anton Lipatov</author>
<author>Victor Shilo</author>
</authors>
<title>Automatic translation of WordNet semantic network to Russian language (in Russian) International Dialog</title>
<date>2003</date>
<note>Workshop.</note>
<marker>Gelfenbeyn, Goncharuk, Lehelt, Lipatov, Shilo, 2003</marker>
<rawString>Ilya Gelfenbeyn, Artem Goncharuk, Vladislav Lehelt, Anton Lipatov, Victor Shilo, 2003. Automatic translation of WordNet semantic network to Russian language (in Russian) International Dialog 2003 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gorman</author>
<author>J R Curran</author>
</authors>
<title>Scaling distributional similarity to large corpora.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="6393" citStr="Gorman and Curran, 2006" startWordPosition="989" endWordPosition="992">based concept discovery and clustering of context feature vectors. The latter approach represents word contexts as vectors in some space and uses similarity measures and automatic clustering in that space (Deerwester et al., 1990). Pereira et al.(1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition. Pantel and Lin (2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. While great effort has been made for improving the computational complexity of these methods (Gorman and Curran, 2006), they still remain data and computation intensive. The second major algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004). In concept acquisition, pattern-based methods were shown to outperform LSA by a large margin (Widdows and Dorow, 2002). Since (Hearst, 1992), who used a manually prepared set of initial lexical patterns in order to acquire relationships, numerous patternbased methods have been proposed for the discovery of concepts from s</context>
</contexts>
<marker>Gorman, Curran, 2006</marker>
<rawString>J. Gorman, J.R. Curran, 2006. Scaling distributional similarity to large corpora. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<journal>COLING</journal>
<volume>92</volume>
<contexts>
<context position="6810" citStr="Hearst, 1992" startWordPosition="1057" endWordPosition="1058">99) uses conjunction and appositive annotations in the vector representation. While great effort has been made for improving the computational complexity of these methods (Gorman and Curran, 2006), they still remain data and computation intensive. The second major algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004). In concept acquisition, pattern-based methods were shown to outperform LSA by a large margin (Widdows and Dorow, 2002). Since (Hearst, 1992), who used a manually prepared set of initial lexical patterns in order to acquire relationships, numerous patternbased methods have been proposed for the discovery of concepts from seeds (Pantel et al., 2004; Davidov et al., 2007; Pasca et al., 2006). Most of these studies were done for English, while some show the applicability of their methods to other languages, including Greek, Czech, Slovene and French. Most of these papers attempt to discover concepts from data available in some specific language. Recently several studies have proposed to utilize a second language or several specified l</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti Hearst, 1992. Automatic acquisition of hyponyms from large text corpora. COLING ’92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jagadeesh Jagarlamudi</author>
</authors>
<title>A Kumaran,</title>
<date>2007</date>
<note>Workshop.</note>
<marker>Jagarlamudi, 2007</marker>
<rawString>Jagadeesh Jagarlamudi, A Kumaran, 2007. Crosslingual information retrieval system for Indian languages. Working Notes for the CLEF 2007 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<journal>COLING</journal>
<volume>98</volume>
<contexts>
<context position="6061" citStr="Lin (1998)" startWordPosition="940" endWordPosition="941">iewed as an instance of the concept acquisition problem where the desired concepts contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using co-clustering and in (Etzioni et al., 2005) using predefined pattern types. The two main algorithmic approaches to the problem are pattern-based concept discovery and clustering of context feature vectors. The latter approach represents word contexts as vectors in some space and uses similarity measures and automatic clustering in that space (Deerwester et al., 1990). Pereira et al.(1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition. Pantel and Lin (2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. While great effort has been made for improving the computational complexity of these methods (Gorman and Curran, 2006), they still remain data and computation intensive. The second major algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al.</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin, 1998. Automatic retrieval and clustering of similar words. COLING ’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Ordan</author>
</authors>
<title>Shuly Wintner,</title>
<date>2007</date>
<journal>International Journal of Translation</journal>
<marker>Ordan, 2007</marker>
<rawString>Noam Ordan, Shuly Wintner, 2007. Hebrew WordNet: a test case of aligning lexical databases across languages. International Journal of Translation 19(1):39-58, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pasca</author>
<author>Dekang Lin</author>
<author>Jeffrey Bigham</author>
</authors>
<title>Andrei Lifchits, Alpa Jain,</title>
<date>2006</date>
<journal>COLINGACL</journal>
<volume>06</volume>
<contexts>
<context position="7061" citStr="Pasca et al., 2006" startWordPosition="1097" endWordPosition="1100">e. The second major algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004). In concept acquisition, pattern-based methods were shown to outperform LSA by a large margin (Widdows and Dorow, 2002). Since (Hearst, 1992), who used a manually prepared set of initial lexical patterns in order to acquire relationships, numerous patternbased methods have been proposed for the discovery of concepts from seeds (Pantel et al., 2004; Davidov et al., 2007; Pasca et al., 2006). Most of these studies were done for English, while some show the applicability of their methods to other languages, including Greek, Czech, Slovene and French. Most of these papers attempt to discover concepts from data available in some specific language. Recently several studies have proposed to utilize a second language or several specified languages in order to extract or extend concepts (Vintar and Fiˇser, 2008; van der Plas and Tiedemann, 2006) or paraphrases (Bosma and Callison-Burch, 2007). However, these methods usually require the availability of parallel corpora, which limits thei</context>
</contexts>
<marker>Pasca, Lin, Bigham, 2006</marker>
<rawString>Marius Pasca, Dekang Lin, Jeffrey Bigham, Andrei Lifchits, Alpa Jain, 2006. Names and similarities on the web: fact extraction in the fast lane. COLINGACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pasca</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Weaklysupervised acquisition of open-domain classes and class attributes from web documents and query logs.</title>
<date>2008</date>
<journal>ACL</journal>
<volume>08</volume>
<marker>Pasca, Van Durme, 2008</marker>
<rawString>Marius Pasca, Benjamin Van Durme, 2008. Weaklysupervised acquisition of open-domain classes and class attributes from web documents and query logs. ACL ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>Discovering word senses from text.</title>
<date>2002</date>
<journal>SIGKDD</journal>
<volume>02</volume>
<contexts>
<context position="6132" citStr="Pantel and Lin (2002)" startWordPosition="949" endWordPosition="952">e the desired concepts contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using co-clustering and in (Etzioni et al., 2005) using predefined pattern types. The two main algorithmic approaches to the problem are pattern-based concept discovery and clustering of context feature vectors. The latter approach represents word contexts as vectors in some space and uses similarity measures and automatic clustering in that space (Deerwester et al., 1990). Pereira et al.(1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition. Pantel and Lin (2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. While great effort has been made for improving the computational complexity of these methods (Gorman and Curran, 2006), they still remain data and computation intensive. The second major algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004). In concept acquisition, pattern-based methods were shown to ou</context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>Patrick Pantel, Dekang Lin, 2002. Discovering word senses from text. SIGKDD ’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
</authors>
<title>Deepak Ravichandran, Eduard Hovy,</title>
<date>2004</date>
<journal>COLING</journal>
<volume>04</volume>
<marker>Pantel, 2004</marker>
<rawString>Patrick Pantel, Deepak Ravichandran, Eduard Hovy, 2004. Towards terascale knowledge acquisition. COLING ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Paolillo</author>
<author>Daniel Pimienta</author>
<author>Daniel Prado</author>
</authors>
<title>Measuring linguistic diversity on the Internet. UNESCO Institute for Statistics</title>
<date>2005</date>
<location>Montreal, Canada.</location>
<marker>Paolillo, Pimienta, Prado, 2005</marker>
<rawString>John Paolillo, Daniel Pimienta, Daniel Prado, et al., 2005. Measuring linguistic diversity on the Internet. UNESCO Institute for Statistics Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Pease</author>
<author>Christiane Fellbaum</author>
<author>Piek Vossen</author>
</authors>
<title>Building the global WordNet grid.</title>
<date>2008</date>
<pages>18</pages>
<marker>Pease, Fellbaum, Vossen, 2008</marker>
<rawString>Adam Pease, Christiane Fellbaum, Piek Vossen, 2008. Building the global WordNet grid. CIL18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<journal>ACL</journal>
<volume>93</volume>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Fernando Pereira, Naftali Tishby, Lillian Lee, 1993. Distributional clustering of English words. ACL ’93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Rosie Jones</author>
</authors>
<title>Learning dictionaries for information extraction by multi-level bootstrapping.</title>
<date>1999</date>
<journal>AAAI</journal>
<volume>99</volume>
<marker>Riloff, Jones, 1999</marker>
<rawString>Ellen Riloff, Rosie Jones, 1999. Learning dictionaries for information extraction by multi-level bootstrapping. AAAI ’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogeneous evidence.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="4686" citStr="Snow et al., 2006" startWordPosition="717" endWordPosition="720">also performed a fully automatic evaluation with 150 concepts, showing that the algorithm can re-discover WN concepts with high precision and recall when given only partial lists as input. Section 2 discusses related work, Section 3 details the algorithm, Section 4 describes the evaluation protocol and Section 5 presents our results. 2 Related work One of the main goals of this paper is the extension or automated creation of lexical databases such as WN. Due to the importance of WN for NLP tasks, substantial research was done on direct or indirect automated extension of the English WN (e.g., (Snow et al., 2006)) or WN in other languages (e.g., (Vintar and Fiˇser, 2008)). The majority of this research was done on extending the tree structure (finding new synsets (Snow et al., 2006) or enriching WN with new relationships (Cuadros and Rigau, 2008)) rather than improving the quality of existing concept/synset nodes. Other related studies develop concept acquisition frameworks for on-demand tasks where concepts are defined by user-provided seeds or patterns (Etzioni et al., 2005; Davidov et al., 2007), or for fully unsupervised database creation where concepts are discovered from scratch (Banko et al., 2</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Rion Snow, Daniel Jurafsky, Andrew Ng, 2006. Semantic taxonomy induction from heterogeneous evidence. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lonneke van der Plas</author>
<author>Jorg Tiedemann</author>
</authors>
<title>Finding synonyms using automatic word alignment and measures of distributional similarity.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<marker>van der Plas, Tiedemann, 2006</marker>
<rawString>Lonneke van der Plas, Jorg Tiedemann, 2006. Finding synonyms using automatic word alignment and measures of distributional similarity. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Volk</author>
<author>Paul Buitelaar</author>
</authors>
<title>A systematic evaluation of concept-based cross-language information retrieval in the medical domain. In:</title>
<date>2002</date>
<booktitle>Proc. of 3rd Dutch-Belgian Information Retrieval Workshop.</booktitle>
<contexts>
<context position="9911" citStr="Volk and Buitelaar, 2002" startWordPosition="1543" endWordPosition="1547">port, 2006; Davidov et al., 2007) to suit diverse languages (including ones without explicit word segmentation). We also develop a method for efficient automated disambiguation and translation of terms to and from any available intermediate language. Our study is related to cross-language information retrieval (CLIR/CLEF) frameworks. Both deal with information extracted from a set of languages. However, the majority of CLIR studies pursue different targets. One of the main CLIR goals is the retrieval of documents based on explicit queries, when the document language is not the query language (Volk and Buitelaar, 2002). These frameworks usually develop language-specific tools and algorithms including parsers and taggers in order to integrate multilingual queries and documents (Jagarlamudi and Kumaran, 2007). Our goal is to develop a languageindependent method using cross-lingual information, for the extension and improvement of concepts rather than the retrieval of documents. Besides, unlike in many CLIR frameworks, intermediate languages are not specified in advance and the language of requested data is the same as the language of request, while available information may be found in many different intermed</context>
</contexts>
<marker>Volk, Buitelaar, 2002</marker>
<rawString>Martin Volk, Paul Buitelaar, 2002. A systematic evaluation of concept-based cross-language information retrieval in the medical domain. In: Proc. of 3rd Dutch-Belgian Information Retrieval Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ˇSpela Vintar</author>
</authors>
<title>Darja Fiˇser,</title>
<date>2008</date>
<journal>LREC</journal>
<volume>08</volume>
<marker>Vintar, 2008</marker>
<rawString>ˇSpela Vintar, Darja Fiˇser, 2008. Harvesting multiword expressions from parallel corpora. LREC ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
<author>Beate Dorow</author>
</authors>
<title>A graph model for unsupervised lexical acquisition.</title>
<date>2002</date>
<journal>COLING</journal>
<volume>02</volume>
<contexts>
<context position="6788" citStr="Widdows and Dorow, 2002" startWordPosition="1052" endWordPosition="1055">ering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. While great effort has been made for improving the computational complexity of these methods (Gorman and Curran, 2006), they still remain data and computation intensive. The second major algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004). In concept acquisition, pattern-based methods were shown to outperform LSA by a large margin (Widdows and Dorow, 2002). Since (Hearst, 1992), who used a manually prepared set of initial lexical patterns in order to acquire relationships, numerous patternbased methods have been proposed for the discovery of concepts from seeds (Pantel et al., 2004; Davidov et al., 2007; Pasca et al., 2006). Most of these studies were done for English, while some show the applicability of their methods to other languages, including Greek, Czech, Slovene and French. Most of these papers attempt to discover concepts from data available in some specific language. Recently several studies have proposed to utilize a second language </context>
<context position="18802" citStr="Widdows and Dorow, 2002" startWordPosition="3006" endWordPosition="3009"> concept terms. We use two meta-pattern types. First, a Two-Slot pattern type constructed as follows: [Prefix] C1 [Infix] C2 [Postfix] Ci are slots for concept terms. We allow up to Limmwe space-separated7 words to be in a single slot. Infix may contain punctuation, spaces, and up to Limmwe × 4 words. Prefix and Postfix are limited to contain punctuation characters and/or Limmwe words. Terms of the same concept frequently co-appear in lists. To utilize this, we introduce two additional List pattern types$: [Prefix] C1 [Infix] (Ci [Infix])+ (1) [Infix] (Ci [Infix])+ Cn [Postfix] (2) Following (Widdows and Dorow, 2002), we define a pattern graph. Nodes correspond to terms and patterns to edges. If term pair (w1, w2) appears in pattern P, we add nodes Nw1, Nw2 to the graph and a directed edge EP (Nw1, Nw2) between them. Symmetric patterns. We consider only symmetric patterns. We define a symmetric pattern as a pattern where some concept terms Ci, Cj appear both in left-to-right and right-toleft order. For example, if we consider the terms {apple, pineapple} we select a List pattern “(one Ci, )+ and Cn.” if we find both “one apple, one pineapple, one guava and orange.” and “one watermelon, one pineapple and a</context>
<context position="25706" citStr="Widdows and Dorow, 2002" startWordPosition="4138" endWordPosition="4141">xperiments with Russian and Hebrew, we have selected the same subtrees in the Hebrew and Russian WN. Concept definitions given to human judges for evaluation were based on the corresponding WN glosses. For automated evaluation we selected 150 synsets/subtrees containing at least 10 single word terms (existing in all three tested languages). For manual evaluation we used a subset of 24 of these concepts. In this subset we tried to select generic concepts manually, such that no domain expert knowledge was required to check their correctness. Ten of these concepts were identical to ones used in (Widdows and Dorow, 2002; Davidov and Rappoport, 2006), which allowed us to compare our results to recent work in case of English. Table 2 shows these 10 concepts along with the sample terms. While the number of tested concepts is not very large, it provides a good indication for the quality of our approach. Concept Sample terms Musical instruments guitar, flute, piano Vehicles/transport train, bus, car Academic subjects physics, chemistry, psychology Body parts hand, leg, shoulder Food egg, butter, bread Clothes pants, skirt, jacket Tools hammer, screwdriver, wrench Places park, castle, garden Crimes murder, theft, </context>
<context position="32668" citStr="Widdows and Dorow, 2002" startWordPosition="5255" endWordPosition="5258">an judgment evaluation provides a good indication for the quality of our framework, it has severe limitations. Thus terms in many concepts require domain expertise to be properly labeled. We have complemented human judgment evaluation with automated WN-based evaluation with a greater (150) number of concepts. For each of the 150 concepts, we have applied our framework on a subset of the available terms, and estimated precision and recall of the resulting term list in comparison to the original WN term list. The evaluation protocol and metrics were very similar to (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) which allowed us to do indirect comparison to previous work. Table 4 shows precision and recall for this task comparing single-language concept extension and the cross-lingual framework. We can see that in all cases, utilization of the latter greatly improves recall. It also significantly outperforms the single-language pattern-based method introduced by (Davidov and Rappoport, 2006), which achieves average precision of 79.3 on a similar set in English (in comparison to 86.7 in this study). We can also see a decrease in precision when the algorithm is provided with 50% of the concept terms as</context>
</contexts>
<marker>Widdows, Dorow, 2002</marker>
<rawString>Dominic Widdows, Beate Dorow, 2002. A graph model for unsupervised lexical acquisition. COLING ’02.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>