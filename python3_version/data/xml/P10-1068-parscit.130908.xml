<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000019">
<title confidence="0.864201">
Towards robust multi-tool tagging. An OWL/DL-based approach
</title>
<author confidence="0.989828">
Christian Chiarcos
</author>
<affiliation confidence="0.760001">
University of Potsdam, Germany
chiarcos@uni-potsdam.de
</affiliation>
<sectionHeader confidence="0.981536" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999887">
This paper describes a series of experi-
ments to test the hypothesis that the paral-
lel application of multiple NLP tools and
the integration of their results improves the
correctness and robustness of the resulting
analysis.
It is shown how annotations created by
seven NLP tools are mapped onto tool-
independent descriptions that are defined
with reference to an ontology of linguistic
annotations, and how a majority vote and
ontological consistency constraints can be
used to integrate multiple alternative ana-
lyses of the same token in a consistent
way.
For morphosyntactic (parts of speech) and
morphological annotations of three Ger-
man corpora, the resulting merged sets of
ontological descriptions are evaluated in
comparison to (ontological representation
of) existing reference annotations.
</bodyText>
<sectionHeader confidence="0.857605" genericHeader="keywords">
1 Motivation and overview
</sectionHeader>
<bodyText confidence="0.999736604651163">
NLP systems for higher-level operations or com-
plex annotations often integrate redundant modu-
les that provide alternative analyses for the same
linguistic phenomenon in order to benefit from
their respective strengths and to compensate for
their respective weaknesses, e.g., in parsing (Crys-
mann et al., 2002), or in machine translation (Carl
et al., 2000). The current trend to parallel and dis-
tributed NLP architectures (Aschenbrenner et al.,
2006; Gietz et al., 2006; Egner et al., 2007; Luis
and de Matos, 2009) opens the possibility of ex-
ploring the potential of redundant parallel annota-
tions also for lower levels of linguistic analysis.
This paper evaluates the potential benefits of
such an approach with respect to morphosyntax
(parts of speech, pos) and morphology in German:
In comparison to English, German shows a rich
and polysemous morphology, and a considerable
number of NLP tools are available, making it a
promising candidate for such an experiment.
Previous research indicates that the integration
of multiple part of speech taggers leads to more
accurate analyses. So far, however, this line of re-
search focused on tools that were trained on the
same corpus (Brill and Wu, 1998; Halteren et al.,
2001), or that specialize to different subsets of the
same tagset (Zavrel and Daelemans, 2000; Tufis¸,
2000; Borin, 2000). An even more substantial in-
crease in accuracy and detail can be expected if
tools are combined that make use of different an-
notation schemes.
For this task, ontologies of linguistic annota-
tions are employed to assess the linguistic infor-
mation conveyed in a particular annotation and to
integrate the resulting ontological descriptions in a
consistent and tool-independent way. The merged
set of ontological descriptions is then evaluated
with reference to morphosyntactic and morpho-
logical annotations of three corpora of German
newspaper articles, the NEGRA corpus (Skut et
al., 1998), the TIGER corpus (Brants et al., 2002)
and the Potsdam Commentary Corpus (Stede,
2004, PCC).
</bodyText>
<sectionHeader confidence="0.861502" genericHeader="introduction">
2 Ontologies and annotations
</sectionHeader>
<bodyText confidence="0.998132090909091">
Various repositories of linguistic annotation termi-
nology have been developed in the last decades,
ranging from early texts on annotation standards
(Bakker et al., 1993; Leech and Wilson, 1996)
over relational data base models (Bickel and
Nichols, 2000; Bickel and Nichols, 2002) to
more recent formalizations in OWL/RDF (or with
OWL/RDF export), e.g., the General Ontology of
Linguistic Description (Farrar and Langendoen,
2003, GOLD), the ISO TC37/SC4 Data Cate-
gory Registry (Ide and Romary, 2004; Kemps-
</bodyText>
<page confidence="0.985752">
659
</page>
<note confidence="0.86059675">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 659–670,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
Snijders et al., 2009, DCR), the OntoTag ontology
(Aguado de Cea et al., 2002), or the Typological
</note>
<bodyText confidence="0.990119304347826">
Database System ontology (Saulwick et al., 2005,
TDS). Despite their common level of representa-
tion, however, these efforts have not yet converged
into a unified and generally accepted ontology of
linguistic annotation terminology, but rather, dif-
ferent resources are maintained by different com-
munities, so that a considerable amount of dis-
agreement between them and their respective defi-
nitions can be observed.1
Such conceptual mismatches and incompatibi-
lities between existing terminological repositories
have been the motivation to develop the OLiA ar-
chitecture (Chiarcos, 2008) that employs a shal-
low Reference Model to mediate between (onto-
logical models of) annotation schemes and several
existing terminology repositories, incl. GOLD, the
DCR, and OntoTag. When an annotation receives
a representation in the OLiA Reference Model,
it is thus also interpretable with respect to other
linguistic ontologies. Therefore, the findings for
the OLiA Reference Model in the experiments de-
scribed below entail similar results for an applica-
tion of GOLD or the DCR to the same task.
</bodyText>
<subsectionHeader confidence="0.967601">
2.1 The OLiA ontologies
</subsectionHeader>
<bodyText confidence="0.999826583333333">
The Ontologies of Linguistic Annotations –
briefly, OLiA ontologies (Chiarcos, 2008) – re-
present an architecture of modular OWL/DL on-
tologies that formalize several intermediate steps
of the mapping between concrete annotations, a
Reference Model and existing terminology reposi-
tories (‘External Reference Models’ in OLiA ter-
minology) such as the DCR.2
The OLiA ontologies were originally develo-
ped as part of an infrastructure for the sustain-
able maintenance of linguistic resources (Schmidt
et al., 2006) where they were originally applied
</bodyText>
<footnote confidence="0.8781765">
1As one example, a GOLD Numeral is a De-
terminer (Numeral C_ Quantifier C_ Determiner,
http://linguistics-ontology.org/gold/2008/
Numeral), whereas a DCR Numeral is de-
fined on the basis of its semantic function,
without any references to syntactic categories
(http://www.isocat.org/datcat/DC-1334).
Thus, two in two of them is a DCR Numeral but not a GOLD
Numeral.
2The OLiA Reference Model is accessible via
http://nachhalt.sfb632.uni-potsdam.de/owl/
olia.owl. Several annotation models, e.g., stts.owl,
tiger.owl, connexor.owl, morphisto.owl can be
found in the same directory together with the corresponding
linking files stts-link.rdf, tiger-link.rdf,
connexor-link.rdf and morphisto-link.rdf.
</footnote>
<bodyText confidence="0.976817941176471">
to the formal representation and documentation of
annotation schemes, and for concept-based anno-
tation queries over to multiple, heterogeneous cor-
pora annotated with different annotation schemes
(Rehm et al., 2007; Chiarcos et al., 2008). NLP
applications of the OLiA ontologies include a pro-
posal to integrate them with the OntoTag ontolo-
gies and to use them for interface specifications
between modules in NLP pipeline architectures
(Buyko et al., 2008). Further, Hellmann (2010)
described the application of the OLiA ontologies
within NLP2RDF, an OWL-based blackboard ap-
proach to assess the meaning of text from gram-
matical analyses and subsequent enrichment with
ontological knowledge sources.
OLiA distinguishes three different classes of
ontologies:
</bodyText>
<listItem confidence="0.963128310344828">
• The OLIA REFERENCE MODEL specifies
the common terminology that different anno-
tation schemes can refer to. It is primarily
based on a blend of concepts of EAGLES and
GOLD, and further extended in accordance
with different annotation schemes, with the
TDS ontology and with the DCR (Chiarcos,
2010).
• Multiple OLIA ANNOTATION MODELs for-
malize annotation schemes and tag sets. An-
notation Models are based on the original
documentation and data samples, so that they
provide an authentic representation of the an-
notation not biased with respect to any partic-
ular interpretation.
• For every Annotation Model, a LINKING
MODEL defines subClassOf (C) relation-
ships between concepts/properties in the re-
spective Annotation Model and the Refe-
rence Model. Linking Models are interpre-
tations of Annotation Model concepts and
properties in terms of the Reference Model,
and thus multiple alternative Linking Models
for the same Annotation Model are possi-
ble. Other Linking Models specify C re-
lationships between Reference Model con-
cepts/properties and concepts/properties of
an External Reference Model such as GOLD
or the DCR.
</listItem>
<bodyText confidence="0.9863775">
The OLiA Reference Model (namespace olia)
specifies concepts that describe linguistic cate-
gories (e.g., olia:Determiner) and grammati-
cal features (e.g., olia:Accusative), as well
</bodyText>
<page confidence="0.996649">
660
</page>
<figureCaption confidence="0.995563333333333">
Figure 1: Attributive demonstrative pronouns Figure 2: Selected morphosyntactic categories in the
(PDAT) in the STTS Annotation Model OLiA Reference Model
Figure 3: Individuals for accusative and sin- Figure 4: Selected morphological features in the
</figureCaption>
<bodyText confidence="0.990113777777778">
gular in the TIGER Annotation Model OLiA Reference Model
as properties that define possible relations be-
tween those (e.g., olia:hasCase). More gen-
eral concepts that represent organizational in-
formation rather than possible annotations (e.g.,
MorphosyntacticCategory and CaseFeature)
are stored in a separate ontology (namespace
olia top).
The Reference Model is a shallow ontology: It
does not specify disjointness conditions of con-
cepts and cardinality or domain restrictions of
properties. Instead, it assumes that such con-
straints are inherited by means of C relationships
from an External Reference Model. Different Ex-
ternal Reference Models may take different posi-
tions on the issue – as languages do3 –, so that
this aspect is left underspecified in the Reference
Model.
</bodyText>
<footnote confidence="0.761273833333333">
3Based on primary experience with Western Euro-
pean languages, for example, one might assume that a
hasGender property applies to nouns, adjectives, pronouns
and determiners only. Yet, this is language-specific restric-
tion: Russian finite verbs, for example, show gender congru-
ency in past tense.
</footnote>
<bodyText confidence="0.998394954545455">
Figs. 2 and 4 show excerpts of category and fea-
ture hierarchies in the Reference Model.
With respect to morphosyntactic annotations
(parts of speech, pos) and morphological an-
notations (morph), five Annotation Models for
German are currently available: STTS (Schiller
et al., 1999, pos), TIGER (Brants and Hansen,
2002, morph), Morphisto (Zielinski and Simon,
2008, pos, morph), RFTagger (Schmid and Laws,
2008, pos, morph), Connexor (Tapanainen and
J¨arvinen, 1997, pos, morph). Further Annotation
Models for pos and morph cover five different an-
notation schemes for English (Marcus et al., 1994;
Sampson, 1995; Mandel, 2006; Kim et al., 2003,
Connexor), two annotation schemes for Russian
(Meyer, 2003; Sharoff et al., 2008), an annotation
scheme designed for typological research and cur-
rently applied to approx. 30 different languages
(Dipper et al., 2007), an annotation scheme for
Old High German (Petrova et al., 2009), and an an-
notation scheme for Tibetan (Wagner and Zeisler,
2004).
</bodyText>
<page confidence="0.985586">
661
</page>
<bodyText confidence="0.737873">
or the DCR).
As an example, consider the attributive demon-
strative pronoun diese in (1).
</bodyText>
<figure confidence="0.991889875">
Diese nicht neue Erkenntnis konnte
(1) this not new insight could
der Markt der M¨oglichkeiten am
the market of.the possibilities on.the
Sonnabend in Treuenbrietzen bestens
Saturday in Treuenbrietzen in.the.best.way
unterstreichen .
underline
</figure>
<figureCaption confidence="0.918293">
‘The ‘Market of Possibilities’, held this Saturday
in Treuenbrietzen, provided best evidence for this
well-known (lit. ‘not new’) insight.’ (PCC, #4794)
Figure 5: The STTS tags PDAT and ART, their rep-
resentation in the Annotation Model and linking
with the Reference Model.
</figureCaption>
<bodyText confidence="0.999831727272727">
Annotation Models differ from the Reference
Model mostly in that they include not only con-
cepts and properties, but also individuals: An-
notation Model concepts reflect an abstract con-
ceptual categorization, whereas individuals re-
present concrete values used to annotate the
corresponding phenomenon. An individual is
applicable to all annotations that match the
string value specified by this individual’s hasTag,
hasTagContaining, hasTagStartingWith, or
hasTagEndingWith properties. Fig. 1 illus-
trates the structure of the STTS Annotation
Model (namespace stts) for the individual
stts:PDAT that represents the tag used for at-
tributive demonstrative pronouns (demonstrative
determiners). Fig. 3 illustrates the individuals
tiger:accusative and tiger:singular from
the hierarchy of morphological features in the
TIGER Annotation Model (namespace tiger).
Fig. 5 illustrates the linking between the STTS
Annotation Model and the OLiA Reference Model
for the individuals stts:PDAT and stts:ART.
</bodyText>
<subsectionHeader confidence="0.9835705">
2.2 Integrating different morphosyntactic
and morphological analyses
</subsectionHeader>
<bodyText confidence="0.999714857142857">
With the OLiA ontologies as described above, an-
notations from different annotation schemes can
now be interpreted in terms of the OLiA Reference
Model (or External Reference Models like GOLD
The phrase diese nicht neue Erkenntnis poses two
challenges. First, it has to be recognized that the
demonstrative pronoun is attributive, although it is
separated from adjective and noun by nicht ‘not’.
Second, the phrase is in accusative case, although
the morphology is ambiguous between accusative
and nominative, and nominative case would be ex-
pected for a sentence-initial NP.
The Connexor analysis (Tapanainen and
Jirvinen, 1997) actually fails in both aspects (2).
</bodyText>
<listItem confidence="0.613436">
(2) PRON Dem FEM SG NOM (Connexor)
</listItem>
<bodyText confidence="0.999773625">
The ontological analysis of this annotation begins
by identifying the set of individuals from the Con-
nexor Annotation Model that match it according
to their hasTag (etc.) properties. The RDF triplet
connexor:NOM connexor:hasTagContaining
‘NOM’4 indicates that the tag is an application
of the individual connexor:NOM, an instance
of connexor:Case. Further, the annota-
tion matches connexor:PRON (an instance of
connexor:Pronoun), etc. The result is a set of
individuals that express different aspects of the
meaning of the annotation.
For these individuals, the Annotation Model
specifies superclasses (rdf:type) and other prop-
erties, i.e., connexor:NOM connexor:hasCase
connexor:NOM, etc. The linguistic unit repre-
sented by the actual token can now be character-
ized by these properties: Every property applica-
ble to a member in the individual set is assumed to
be applicable to the linguistic unit as well. In order
to save space, we use a notation closer to predicate
logic (with the token as implicit subject). In terms
of the Annotation Model, the token diese is thus
described by the following descriptions:
</bodyText>
<footnote confidence="0.8993735">
4RDF triplets are quoted in simplified form, with XML
namespaces replacing the actual URIs.
</footnote>
<page confidence="0.968914">
662
</page>
<listItem confidence="0.4578215">
(3) rdf:type(connexor:Pronoun)
connexor:hasCase(connexor:NOM) ...
</listItem>
<bodyText confidence="0.998587210526316">
The Linking Model connexor-link.rdf
provides us with the information that (i)
connexor:Pronoun is a subclass of the Re-
ference Model concept olia:Pronoun, (ii)
connexor:NOM is an instance of the Reference
Model concept olia:Nominative, and (iii)
olia:hasCase is a subproperty of olia:hasCase.
Accordingly, the predicates that describe the to-
ken these can be reformulated in terms of the Re-
ference Model. rdf:type(connexor:Pronoun)
entails rdf:type(olia:Pronoun), etc. Similarly,
we know that for some i:olia:Nominative it is
true that olia:hasCase(i), abbreviated here as
olia:hasCase(some olia:Nominative).
In this way, the grammatical information con-
veyed in the original Connexor annotation can
be represented in an annotation-independent and
tagset-neutral way as shown for the Connexor a-
nalysis in (4).
</bodyText>
<equation confidence="0.956143333333333">
(4) rdf:type(olia:PronounOrDeterminer)
rdf:type(olia:Pronoun)
olia:hasNumber(some olia:Singular)
olia:hasGender(some olia:Feminine)
rdf:type(olia:DemonstrativePronoun)
olia:hasCase(some olia:Nominative)
</equation>
<bodyText confidence="0.9976975">
Analogously, the corresponding RFTagger analy-
sis (Schmid and Laws, 2008) given in (5) can
be transformed into a description in terms of the
OLiA Reference Model such as in (6).
</bodyText>
<listItem confidence="0.989934285714286">
(5) PRO.Dem.Attr.-3.Acc.Sg.Fem (RFTagger)
(6) rdf:type(olia:PronounOrDeterminer)
olia:hasNumber(some olia:Singular)
olia:hasGender(some olia:Feminine)
olia:hasCase(some olia:Accusative)
rdf:type(olia:DemonstrativeDeterminer)
rdf:type(olia:Determiner)
</listItem>
<bodyText confidence="0.99991025">
For every description obtained from these (and
further) analyses, an integrated and consistent gen-
eralization can be established as described in the
following section.
</bodyText>
<sectionHeader confidence="0.824952" genericHeader="method">
3 Processing linguistic annotations
</sectionHeader>
<subsectionHeader confidence="0.998629">
3.1 Evaluation setup
</subsectionHeader>
<bodyText confidence="0.996637">
Fig. 6 sketches the architecture of the evalua-
tion environment set up for this study.5 The in-
put to the system is a set of documents with
</bodyText>
<footnote confidence="0.989884">
5The code used for the evaluation setup is available under
http://multiparse.sourceforge.net.
</footnote>
<figureCaption confidence="0.999839">
Figure 6: Evaluation setup
</figureCaption>
<bodyText confidence="0.999882">
TIGER/NEGRA-style morphosyntactic or mor-
phological annotation (Skut et al., 1998; Brants
and Hansen, 2002) whose annotations are used as
gold standard.
From the annotated document, the plain tok-
enized text is extracted and analyzed by one or
more of the following NLP tools:
</bodyText>
<listItem confidence="0.890317">
(i) Morphisto, a morphological analyzer without
contextual disambiguation (Zielinski and Si-
mon, 2008),
(ii) two part of speech taggers: the TreeTag-
ger (Schmid, 1994) and the Stanford Tagger
(Toutanova et al., 2003),
(iii) the RFTagger that performs part of speech and
morphological analysis (Schmid and Laws,
2008),
(iv) two PCFG parsers: the StanfordParser (Klein
and Manning, 2003) and the BerkeleyParser
(Petrov and Klein, 2007), and
(v) the Connexor dependency parser (Tapanainen
and J¨arvinen, 1997).
</listItem>
<bodyText confidence="0.99781925">
These tools annotate parts of speech, and those in
(i), (iii) and (v) also provide morphological fea-
tures. All components ran in parallel threads on
the same machine, with the exception of Mor-
phisto that was addressed as a web service. The set
of matching Annotation Model individuals for ev-
ery annotation and the respective set of Reference
Model descriptions are determined by means of
</bodyText>
<page confidence="0.997148">
663
</page>
<table confidence="0.999748863636364">
OLiA description Morphisto Connexor RF Tree Stanford Stanford Berkeley
Tagger Tagger Tagger Parser Parser
word class type(...) 5.5 7 1 1 1 1 1 1
PronounOrDeterminer 5.5 0 1 1 1 1 1
Determiner 1.5 0 1 1 1 1 1
DemonstrativeDeterminer 1.5 1 0 0 0 0 0
Pronoun 1(4/4)* 1 0 0 0 0 0
DemonstrativePronoun 0.5**
0.5**
0.5**
0.5**
morphology hasXY(...) 2.5 0.5 (2/4) 1 1 n/a n/a n/a n/a
hasNumber(some Singular) 2.5 0.5 (2/4) 1 1
hasGender(some Feminine) 1.5 0.5 (2/4) 0 1
hasCase(some Accusative) 1.5 0.5 (2/4) 1 0
hasCase(some Nominative) 0.5 0.5 (2/4) 0 0
hasNumber(some Plural)
* Morphisto produces four alternative candidate analyses
for this example, so every alternative analysis receives the
confidence score 0.25
** Morphisto does not distinguish attributive and substitutive
pronouns, it predicts type(Determiner LJ Pronoun)
</table>
<tableCaption confidence="0.999853">
Table 1: Confidence scores for diese in ex. (1)
</tableCaption>
<bodyText confidence="0.993295142857143">
the Pellet reasoner (Sirin et al., 2007) as described
above.
A disambiguation routine (see below) then de-
termines the maximal consistent set of ontological
descriptions. Finally, the outcome of this process
is compared to the set of descriptions correspond-
ing to the original annotation in the corpus.
</bodyText>
<subsectionHeader confidence="0.992922">
3.2 Disambiguation
</subsectionHeader>
<bodyText confidence="0.997154">
Returning to examples (4) and (6) above, we
see that the resulting set of descriptions con-
veys properties that are obviously contradic-
ting, e.g., hasCase(some Nominative) besides
hasCase(some Accusative).
Our approach to disambiguation combines on-
tological consistency criteria with a confidence
ranking. As we simulate an uninformed approach,
the confidence ranking follows a majority vote.
For diese in (1), the consultation of all seven
tools results a confidence ranking as shown in Tab.
1: If a tool supports a description with its analy-
sis, the confidence score is increased by 1 (or by
1/n if the tool proposes n alternative annotations).
A maximal consistent set of descriptions is then
established as follows:
</bodyText>
<listItem confidence="0.969320888888889">
(i) Given a confidence-ranked list of available
descriptions S = (s1, ..., sn) and a result set
T = O.
(ii) Let s1 be the first element of S =
(s1, ..., sn).
(iii) If s1 is consistent with every description t E
T, then add s1 to T: T := T U {s1}
(iv) Remove s1 from S and iterate in (ii) until S
is empty.
</listItem>
<bodyText confidence="0.9798085">
The consistency of ontological descriptions is de-
fined here as follows:6
</bodyText>
<listItem confidence="0.9956996">
• Two concepts A and B are consistent iff
A - BorACBorBCA
Otherwise, A and B are disjoint.
• Two descriptions pred1(A) and pred2(B)
are consistent iff
</listItem>
<bodyText confidence="0.990887434782609">
A and B are consistent or
pred1 is neither a subproperty
nor a superproperty of pred2
This heuristic formalizes an implicit disjoint-
ness assumption for all concepts in the on-
tology (all concepts are disjoint unless one
is a subconcept of the other). Further, it
imposes an implicit cardinality constraint on
properties (e.g., hasCase(some Accusative) and
hasCase(some Nominative) are inconsistent be-
cause Accusative and Nominative are sibling
concepts and thus disjoint).
For the example diese, the descriptions
type(Pronoun) and type(DemonstrativePro-
noun) are inconsistent with type(Determiner),
and hasNumber(some Plural) is inconsistent
with hasNumber(some Singular) (Figs. 2 and
4); these descriptions are thus ruled out. The
hasCase descriptions have identical confidence
scores, so that the first hasCase description that
the algorithm encounters is chosen for the set of
resulting descriptions, the other one is ruled out
because of their inconsistency.
</bodyText>
<footnote confidence="0.9919306">
6The OLiA Reference Model does not specify disjoint-
ness constraints, and neither do GOLD or the DCR as Exter-
nal Reference Models. The axioms of the OntoTag ontolo-
gies, however, are specific to Spanish and cannot be directly
applied to German.
</footnote>
<page confidence="0.975647">
664
</page>
<table confidence="0.99879525">
PCC TIGER NEGRA TIGER NEGRA
best-performing tool (StanfordTagger) .990* 1 tool .678 (.106) .660 (.091)
.960 .956 Morphisto .573 .568
average (and std. deviation) for tool combinations Connexor .674 .662
1 tool .868 (.109) .864 (.122) .870 (.113) RFTagger .786 .751
2 tools .928 (.018) .931 (.021) .943 (.028) 2 tools .761 (.019) .740 (.012)
3 tools .947 (.014) .948 (.013) .956 (.018) C+M .738 .730
4 tools .956 (.006) .955 (.009) .963 (.013) M+R .769 .737
5 tools .959 (.006) .960 (.007) .964 (.009) C+R .773 .753
6 tools .963 (.003) .963 (.007) .965 (.007) all tools .791 .770
all tools .967 .960 .965
* The Stanford Tagger was trained on the NEGRA corpus. Table 3: Recall for morphological
</table>
<tableCaption confidence="0.986286">
Table 2: Recall for rdf:type descriptions for word classes hasXY() descriptions
</tableCaption>
<bodyText confidence="0.998108">
The resulting, maximal consistent set of de-
scriptions is then compared with the ontological
descriptions that correspond to the original anno-
tation in the corpus.
</bodyText>
<sectionHeader confidence="0.99934" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.997784105263158">
Six experiments were conducted with the goal to
evaluate the prediction of word classes and mor-
phological features on parts of three corpora of
German newspaper articles: NEGRA (Skut et al.,
1998), TIGER (Brants et al., 2002), and the Pots-
dam Commentary Corpus (Stede, 2004, PCC).
From every corpus 10,000 tokens were considered
for the analysis.
TIGER and NEGRA are well-known resources
that also influenced the design of several of the
tools considered. For this reason, the PCC was
consulted, a small collection of newspaper com-
mentaries, 30,000 tokens in total, annotated with
TIGER-style parts of speech and syntax (by mem-
bers of the TIGER project). None of the tools con-
sidered here were trained on this data, so that it
provides independent test data.
The ontological descriptions were evaluated for
recall:7
</bodyText>
<equation confidence="0.999581333333333">
�� i�1 |Dpredicted(ti)nDtarget(ti)|
(7) recall(T) =
E 1 |Dtarget(ti)|
</equation>
<bodyText confidence="0.937283">
In (7), T is a text (a list of tokens) with T =
(ti, ..., tn), Dpredicted(t) are descriptions retrieved
from the NLP analyses of the token t, and
Dtarget(t) is the set of descriptions that corres-
pond to the original annotation of t in the corpus.
7Precision and accuracy may not be appropriate measure-
ments in this case: Annotation schemes differ in their ex-
pressiveness, so that a description predicted by an NLP tool
but not found in the reference annotation may nevertheless
be correct. The RFTagger, for example, assigns demonstra-
tive pronouns the feature ‘3rd person’, that is not found in
TIGER/NEGRA-style annotation because of its redundancy.
</bodyText>
<subsectionHeader confidence="0.996129">
4.1 Word classes
</subsectionHeader>
<bodyText confidence="0.99993075">
Table 2 shows that the recall of rdf:type de-
scriptions (for word classes) increases continu-
ously with the number of NLP tools applied. The
combination of all seven tools actually shows a
better recall than the best-performing single NLP
tool. (The NEGRA corpus is an apparent excep-
tion only; the exceptionally high recall of the Stan-
ford Tagger reflects the fact that it was trained on
NEGRA.)
A particularly high increase in recall occurs
when tools are combined that compensate for their
respective deficits. Morphisto, for example, ge-
nerates alternative morphological analyses, so that
the disambiguation algorithm performs a random
choice between these. Morphisto has thus the
worst recall among all tools considered (PCC .69,
TIGER .65, NEGRA .70 for word classes). As
compared to this, Connexor performs a contextual
disambiguation; its recall is, however, limited by
its coarse-grained word classes (PCC .73, TIGER
.72, NEGRA .73). The combination of both tools
yields a more detailed and context-sensitive ana-
lysis and thus results in a boost in recall by more
than 13% (PCC .87, TIGER .86, NEGRA .86).
</bodyText>
<subsectionHeader confidence="0.992832">
4.2 Morphological features
</subsectionHeader>
<bodyText confidence="0.999837454545455">
For morphological features, Tab. 3 shows the
same tendencies that were also observed for word
classes: The more tools are combined, the greater
the recall of the generated descriptions, and the re-
call of combined tools often outperforms the recall
of individual tools.
The three tools that provide morphological an-
notations (Morphisto, Connexor, RFTagger) were
evaluated against 10,000 tokens from TIGER and
NEGRA respectively. The best-performing tool
was the RFTagger, which possibly reflects the fact
</bodyText>
<page confidence="0.997653">
665
</page>
<bodyText confidence="0.999802">
that it was trained on TIGER-style annotations,
whereas Morphisto and Connexor were developed
on the basis of independent resources and thus dif-
fer from the reference annotation in their respec-
tive degree of granularity.
</bodyText>
<sectionHeader confidence="0.943517" genericHeader="evaluation">
5 Summary and Discussion
</sectionHeader>
<bodyText confidence="0.995519746268657">
With the ontology-based approach described in
this paper, the performance of annotation tools can
be evaluated on a conceptual basis rather than by
means of a string comparison with target annota-
tions. A formal model of linguistic concepts is ex-
tensible, finer-grained and, thus, potentially more
adequate for the integration of linguistic annota-
tions than string-based representations, especially
for heterogeneous annotations, if the tagsets in-
volved are structured according to different design
principles (e.g., due to different terminological tra-
ditions, different communities involved, etc.).
It has been shown that by abstracting from
tool-specific representations of linguistic anno-
tations, annotations from different tagsets can be
represented with reference to the OLiA ontologies
(and/or with other OWL/RDF-based terminology
repositories linked as External Reference Models).
In particular, it is possible to compare an existing
reference annotation with annotations produced by
NLP tools that use independently developed and
differently structured annotation schemes (such as
Connexor vs. RFTagger vs. Morphisto).
Further, an algorithm for the integration of dif-
ferent annotations has been proposed that makes
use of a majority-based confidence ranking and
ontological consistency conditions. As consis-
tency conditions are not formally defined in the
OLiA Reference Model (which is expected to in-
herit such constraints from External Reference
Models), a heuristic, structure-based definition of
consistency was applied.
This heuristic consistency definition is overly
rigid and rules out a number of consistent alter-
native analyses, as it is the case for overlapping
categories.8 Despite this rigidity, we witness an
increase of recall when multiple alternative analy-
ses are integrated. This increase of recall may re-
sult from a compensation of tool-specific deficits,
e.g., with respect to annotation granularity. Also,
the improved recall can be explained by a compen-
sation of overfitting, or deficits that are inherent to
8Preposition-determiner compounds like German am ‘on
the’, for example, are both prepositions and determiners.
a particular approach (e.g., differences in the co-
verage of the linguistic context).
It can thus be stated that the integration of mul-
tiple alternative analyses has the potential to pro-
duce linguistic analyses that are both more robust
and more detailed than those of the original tools.
The primary field of application of this ap-
proach is most likely to be seen in a context where
applications are designed that make direct use of
OWL/RDF representations as described, for ex-
ample, by Hellmann (2010). It is, however, also
possible to use ontological representations to boot-
strap novel and more detailed annotation schemes,
cf. Zavrel and Daelemans (2000). Further, the
conversion from string-based representations to
ontological descriptions is reversible, so that re-
sults of ontology-based disambiguation and vali-
dation can also be reintegrated with the original
annotation scheme. The idea of such a reversion
algorithm was sketched by Buyko et al. (2008)
where the OLiA ontologies were suggested as a
means to translate between different annotation
schemes.9
</bodyText>
<sectionHeader confidence="0.984122" genericHeader="conclusions">
6 Extensions and Related Research
</sectionHeader>
<bodyText confidence="0.9798135">
Natural extensions of the approach described in
this paper include:
</bodyText>
<listItem confidence="0.732808583333333">
(i) Experiments with formally defined consis-
tency conditions (e.g., with respect to restric-
tions on the domain of properties).
(ii) Context-sensitive disambiguation of mor-
phological features (e.g., by combination
with a chunker and adjustment of confidence
scores for morphological features over all to-
kens in the current chunk, cf. Kermes and
Evert, 2002).
(iii) Replacement of majority vote by more elab-
orate strategies to merge grammatical analy-
ses.
</listItem>
<bodyText confidence="0.783313818181818">
9The mapping from ontological descriptions to tags of a
particular scheme is possible, but neither trivial nor neces-
sarily lossless: Information of ontological descriptions that
cannot be expressed in the annotation scheme under consid-
eration (e.g., the distinction between attributive and substitu-
tive pronouns in the Morphisto scheme) will be missing in
the resulting string representation. For complex annotations,
where ontological descriptions correspond to different sub-
strings, an additional ‘tag grammar’ may be necessary to de-
termine the appropriate ordering of substrings according to
the annotation scheme (e.g., in the Connexor analysis).
</bodyText>
<page confidence="0.997066">
666
</page>
<bodyText confidence="0.981206390243903">
(iv) Application of the algorithm for the ontolog-
ical processing of node labels and edge labels
in syntax annotations.
(v) Integration with other ontological knowledge
sources in order to improve the recall of
morphosyntactic and morphological analy-
ses (e.g., for disambiguating grammatical
case).
Extensions (iii) and (iv) are currently pursued in
an ongoing research effort described by Chiarcos
et al. (2010). Like morphosyntactic and morpho-
logical features, node and edge labels of syntac-
tic trees are ontologically represented in several
Annotation Models, the OLiA Reference Model,
and External Reference Models, the merging al-
gorithm as described above can thus be applied
for syntax, as well. Syntactic annotations, how-
ever, involve the additional challenge to align dif-
ferent structures before node and edge labels can
be addressed, an issue not further discussed here
for reasons of space limitations.
Alternative strategies to merge grammatical a-
nalyses may include alternative voting strategies
as discussed in literature on classifier combina-
tion, e.g., weighted majority vote, pairwise voting
(Halteren et al., 1998), credibility profiles (Tufis¸,
2000), or hand-crafted rules (Borin, 2000). A
novel feature of our approach as compared to exis-
ting applications of these methods is that confi-
dence scores are not attached to plain strings, but
to ontological descriptions: Tufis¸, for example,
assigned confidence scores not to tools (as in a
weighted majority vote), but rather, assessed the
‘credibility’ of a tool with respect to the predicted
tag. If this approach is applied to ontological de-
scriptions in place of tags, it allows us to consider
the credibility of pieces of information regardless
of the actual string representation of tags. For ex-
ample, the credibility of hasCase descriptions can
be assessed independently from the credibility of
hasGender descriptions even if the original anno-
tation merged both aspects in one single tag (as the
RFTagger does, for example, cf. ex. 5).
Extension (v) has been addressed in previous re-
search, although mostly with the opposite perspec-
tive: Already Cimiano and Reyle (2003) noted that
the integration of grammatical and semantic ana-
lyses may be used to resolve ambiguity and un-
derspecifications, and this insight has also moti-
vated the ontological representation of linguistic
resources such as WordNet (Gangemi et al., 2003),
FrameNet (Scheffczyk et al., 2006), the linking of
corpora with such ontologies (Hovy et al., 2006),
the modelling of entire corpora in OWL/DL (Bur-
chardt et al., 2008), and the extension of existing
ontologies with ontological representations of se-
lected linguistic features (Buitelaar et al., 2006;
Davis et al., 2008).
Aguado de Cea et al. (2004) sketched an ar-
chitecture for the closer ontology-based integra-
tion of grammatical and semantic information u-
sing OntoTag and several NLP tools for Spanish.
Aguado de Cea et al. (2008) evaluate the benefits
of this approach for the Spanish particle se, and
conclude for this example that the combination of
multiple tools yields more detailed and more ac-
curate linguistic analyses of particularly proble-
matic, polysemous function words. A similar in-
crease in accuracy has also been repeatedly re-
ported for ensemble combination approaches, that
are, however, limited to tools that produce annota-
tions according to the same tagset (Brill and Wu,
1998; Halteren et al., 2001).
These observations provide further support for
our conclusion that the ontology-based integration
of morphosyntactic analyses enhances both the ro-
bustness and the level of detail of morphosyntac-
tic and morphological analyses. Our approach ex-
tends the philosophy of ensemble combination ap-
proaches to NLP tools that do not only employ dif-
ferent strategies and philosophies, but also differ-
ent annotation schemes.
</bodyText>
<sectionHeader confidence="0.962633" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999576230769231">
From 2005 to 2008, the research on linguistic
ontologies described in this paper was funded
by the German Research Foundation (DFG) in
the context of the Collaborative Research Center
(SFB) 441 “Linguistic Data Structures”, Project
C2 “Sustainability of Linguistic Resources” (Uni-
versity of T¨ubingen), and since 2007 in the context
of the SFB 632 “Information Structure”, Project
D1 “Linguistic Database” (University of Pots-
dam). The author would also like to thank Ju-
lia Ritz, Angela Lahee, Olga Chiarcos and three
anonymous reviewers for helpful hints and com-
ments.
</bodyText>
<page confidence="0.995801">
667
</page>
<sectionHeader confidence="0.795841" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.987662412844037">
G. Aguado de Cea, ´A. I. de Mon-Rego, A. Pareja-Lora,
and R. Plaza-Arteche. 2002. OntoTag: A semantic
web page linguistic annotation model. In Procee-
dings of the ECAI 2002 Workshop on Semantic Au-
thoring, Annotation and Knowledge Markup, Lyon,
France, July.
G. Aguado de Cea, A. Gomez-Perez, I. Alvarez de
Mon, and A. Pareja-Lora. 2004. OntoTag’s lin-
guistic ontologies: Improving semantic web anno-
tations for a better language understanding in ma-
chines. In Proceedings of the International Confe-
rence on Information Technology: Coding and Com-
puting (ITCC’04), Las Vegas, Nevada, USA, April.
G. Aguado de Cea, J. Puch, and J. ´A. Ramos. 2008.
Tagging Spanish texts: The problem of “se”. In Pro-
ceedings of the Sixth International Conference on
Language Resources and Evaluation (LREC 2008),
Marrakech, Morocco, May.
A. Aschenbrenner, P. Gietz, M.W. K¨uster, C. Ludwig,
and H. Neuroth. 2006. TextGrid. A modular plat-
form for collaborative textual editing. In Procee-
dings of the International Workshop on Digital Lib-
rary Goes e-Science (DLSci06), pages 27–36, Ali-
cante, Spain, September.
D. Bakker, O. Dahl, M. Haspelmath, M. Koptjevskaja-
Tamm, C. Lehmann, and A. Siewierska. 1993.
EUROTYP guidelines. Technical report, European
Science Foundation Programme in Language Typol-
ogy.
B. Bickel and J. Nichols. 2000. The
goals and principles of AUTOTYP.
http://www.uni-leipzig.de/∼autotyp/
theory.html. version of 01/12/2007.
B. Bickel and J. Nichols. 2002. Autotypologizing
databases and their use in fieldwork. In Proceedings
of the LREC 2002 Workshop on Resources and Tools
in Field Linguistics, Las Palmas, Spain, May.
L. Borin. 2000. Something borrowed, something
blue: Rule-based combination of POS taggers. In
Proceedings of the 2nd International Conference on
Language Resources and Evaluation (LREC 2000),
Athens, Greece, May, 31st – June, 2nd.
S. Brants and S. Hansen. 2002. Developments in the
TIGER annotation scheme and their realization in
the corpus. In Proceedings of the Third Interna-
tional Conference on Language Resources and Eva-
luation (LREC 2002), pages 1643–1649, Las Pal-
mas, Spain, May.
S. Brants, S. Dipper, S. Hansen, W. Lezius, and
G. Smith. 2002. The TIGER treebank. In Procee-
dings of the Workshop on Treebanks and Linguistic
Theories, pages 24–41, Sozopol, Bulgaria, Septem-
ber.
E. Brill and J. Wu. 1998. Classifier combination
for improved lexical disambiguation. In Procee-
dings of the 36th Annual Meeting of the Association
for Computational Linguistics and the 17th Inter-
national Conference on Computational Linguistics
(COLING-ACL 1998), pages 191–195, Montr´eal,
Canada, August.
P. Buitelaar, T. Declerck, A. Frank, S. Racioppa,
M. Kiesel, M. Sintek, R. Engel, M. Romanelli,
D. Sonntag, B. Loos, V. Micelli, R. Porzel, and
P. Cimiano. 2006. LingInfo: Design and applica-
tions of a model for the integration of linguistic in-
formation in ontologies. In Proceedings of the 5th
International Conference on Language Resources
and Evaluation (LREC 2006), Genoa, Italy, May.
A. Burchardt, S. Pad´o, D. Spohr, A. Frank, and
U. Heid. 2008. Formalising Multi-layer Corpora in
OWL/DL – Lexicon Modelling, Querying and Con-
sistency Control. In Proceedings of the 3rd Inter-
national Joint Conference on NLP (IJCNLP 2008),
Hyderabad, India, January.
E. Buyko, C. Chiarcos, and A. Pareja-Lora. 2008.
Ontology-based interface specifications for a NLP
pipeline architecture. In Proceedings of the Interna-
tional Conference on Language Resources and Eva-
luation (LREC 2008), Marrakech, Morocco, May.
M. Carl, C. Pease, L.L. Iomdin, and O. Streiter. 2000.
Towards a dynamic linkage of example-based and
rule-based machine translation. Machine Transla-
tion, 15(3):223–257.
C. Chiarcos, S. Dipper, M. G¨otze, U. Leser,
A. L¨udeling, J. Ritz, and M. Stede. 2008. A Flexible
Framework for Integrating Annotations from Differ-
ent Tools and Tag Sets. Traitement Automatique des
Langues, 49(2).
C. Chiarcos, K. Eckart, and J. Ritz. 2010. Creating and
exploiting a resource of parallel parses. In 4th Lin-
guistic Annotation Workshop (LAW 2010), held in
conjunction with ACL-2010, Uppsala, Sweden, July.
C. Chiarcos. 2008. An ontology of linguistic annota-
tions. LDV Forum, 23(1):1–16. Foundations of On-
tologies in Text Technology, Part II: Applications.
C. Chiarcos. 2010. Grounding an ontology of lin-
guistic annotations in the Data Category Registry.
In Workshop on Language Resource and Language
Technology Standards (LR&amp;LTS 2010), held in con-
junction with LREC 2010, Valetta, Malta, May.
P. Cimiano and U. Reyle. 2003. Ontology-based se-
mantic construction, underspecification and disam-
biguation. In Proceedings of the Lorraine/Saarland
Workshop on Prospects and Recent Advances in the
Syntax-Semantics Interface, pages 33–38, Nancy,
France, October.
B. Crysmann, A. Frank, B. Kiefer, S. M¨uller, G. Neu-
mann, J. Piskorski, U. Sch¨afer, M. Siegel, H. Uszko-
reit, F. Xu, M. Becker, and H. Krieger. 2002. An
</reference>
<page confidence="0.991023">
668
</page>
<reference confidence="0.996365927927928">
integrated architecture for shallow and deep proces-
sing. In Proceedings of 40th Annual Meeting of the
Association for Computational Linguistics, pages
441–448, Philadelphia, Pennsylvania, USA, July.
B. Davis, S. Handschuh, A. Troussov, J. Judge, and
M. Sogrin. 2008. Linguistically light lexical ex-
tensions for ontologies. In Proceedings of the Sixth
International Conference on Language Resources
and Evaluation (LREC 2008), Marrakech, Morocco,
May.
S. Dipper, M. G¨otze, and S. Skopeteas, editors. 2007.
Information Structure in Cross-Linguistic Corpora:
Annotation Guidelines for Phonology, Morpholo-
gy, Syntax, Semantics, and Information Structure.
Interdisciplinary Studies on Information Structure
(ISIS), Working Papers of the SFB 632; 7. Univer-
sit¨atsverlag Potsdam, Potsdam, Germany.
M.T. Egner, M. Lorch, and E. Biddle. 2007. UIMA
Grid: Distributed large-scale text analysis. In Pro-
ceedings of the Seventh IEEE International Sym-
posium on Cluster Computing and the Grid (CC-
GRID’07), pages 317–326, Rio de Janeiro, Brazil,
May.
S. Farrar and D.T. Langendoen. 2003. Markup and
the GOLD ontology. In EMELD Workshop on Di-
gitizing and Annotating Text and Field Recordings.
Michigan State University, July.
A. Gangemi, R. Navigli, and P. Velardi. 2003. The On-
toWordNet project: Extension and axiomatization of
conceptual relations in WordNet. In R. Meersman
and Z. Tari, editors, Proceedings of On the Move
to Meaningful Internet Systems (OTM2003), pages
820–838, Catania, Italy, November.
P. Gietz, A. Aschenbrenner, S. Budenbender, F. Jan-
nidis, M.W. K¨uster, C. Ludwig, W. Pempe, T. Vitt,
W. Wegstein, and A. Zielinski. 2006. TextGrid
and eHumanities. In Proceedings of the Second
IEEE International Conference on e-Science and
Grid Computing (E-SCIENCE ’06), pages 133–141,
Amsterdam, The Netherlands, December.
H. van Halteren, J. Zavrel, and W. Daelmans. 1998.
Improving data driven wordclass tagging by system
combination. In Proceedings of the 36th Annual
Meeting of the Association for Computational Lin-
guistics and the 17th International Conference on
Computational Linguistics (COLING-ACL 1998),
Montr´eal, Canada, August.
H. van Halteren, J. Zavrel, and W. Daelmans. 2001.
Improving accuracy in word class tagging through
the combination of machine learning systems. Com-
putational Linguistics, 27(2):199–229.
S. Hellmann. 2010. The semantic gap of formalized
meaning. In The 7th Extended Semantic Web Confe-
rence (ESWC 2010), Heraklion, Greece, May 30th –
June 3rd.
E. Hovy, M. Marcus, M. Palmer, L. Ramshaw, and
R. Weischedel. 2006. Ontonotes: the 90% solu-
tion. In Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology (HLT-NAACL 2006),
pages 57–60, New York, June.
N. Ide and L. Romary. 2004. A registry of standard
data categories for linguistic annotation. In Procee-
dings of the Fourth Language Resources and Evalu-
ation Conference (LREC 2004), pages 135–39, Lis-
boa, Portugal, May.
M. Kemps-Snijders, M. Windhouwer, P. Wittenburg,
and S.E. Wright. 2009. ISOcat: remodelling meta-
data for language resources. International Journal
of Metadata, Semantics and Ontologies, 4(4):261–
276.
H. Kermes and S. Evert. 2002. YAC – A recur-
sive chunker for unrestricted German text. In Pro-
ceedings of the Third International Conference on
Language Resources and Evaluation (LREC 2002),
pages 1805–1812, Las Palmas, Spain, May.
J.D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. GE-
NIA corpus – A semantically annotated corpus for
bio-textmining. Bioinformatics, 19(1):180–182.
D. Klein and C.D. Manning. 2003. Accurate unlexi-
calized parsing. In Proceedings of the 41st Annual
Meeting of the Association for Computational Lin-
guistics, pages 423–430, Sapporo, Japan, July.
G. Leech and A. Wilson. 1996. EAGLES recommen-
dations for the morphosyntactic annotation of cor-
pora. Version of March 1996.
T. Lu´ıs and D.M. de Matos. 2009. High-performance
high-volume layered corpora annotation. In Procee-
dings of the Third Linguistic Annotation Workshop
(LAW-III) held in conjunction with ACL-IJCNLP
2009, pages 99–107, Singapore, August.
M. Mandel. 2006. Integrated annotation of biomedical
text: Creating the PennBioIE corpus. In Text Min-
ing Ontologies and Natural Language Processing in
Biomedicine, Manchester, UK, March.
M.P. Marcus, B. Santorini, and M.A. Marcinkiewicz.
1994. Building a large annotated corpus of En-
glish: The Penn Treebank. Computational linguis-
tics, 19(2):313–330.
R. Meyer. 2003. Halbautomatische morphosyntak-
tische Annotation russischer Texte. In R. Ham-
mel and L. Geist, editors, Linguistische Beitr¨age
zur Slavistik aus Deutschland und ¨Osterreich. X.
JungslavistInnen-Treffen, Berlin 2001, pages 92–
105. Sagner, M¨unchen.
S. Petrov and D. Klein. 2007. Improved inference for
unlexicalized parsing. In Proceedings of the Confe-
rence of the North American Chapter of the Associ-
ation for Computational Linguistics on Human Lan-
guage Technology (HLT-NAACL 2007), pages 404–
411, Rochester, NY, April.
</reference>
<page confidence="0.98301">
669
</page>
<reference confidence="0.999938051020409">
S. Petrova, C. Chiarcos, J. Ritz, M. Solf, and A. Zeldes.
2009. Building and using a richly annotated inter-
linear diachronic corpus: The case of Old High Ger-
man Tatian. Traitement automatique des langues et
langues anciennes, 50(2):47–71.
G. Rehm, R. Eckart, and C. Chiarcos. 2007. An OWL-
and XQuery-based mechanism for the retrieval of
linguistic patterns from XML-corpora. In Procee-
dings of Recent Advances in Natural Language Pro-
cessing (RANLP 2007), Borovets, Bulgaria, Septem-
ber.
G. Sampson. 1995. English for the computer: The SU-
SANNE corpus and analytic scheme. Oxford Uni-
versity Press.
A. Saulwick, M. Windhouwer, A. Dimitriadis, and
R. Goedemans. 2005. Distributed tasking in on-
tology mediated integration of typological databases
for linguistic research. In Proceedings of the 17th
Conference on Advanced Information Systems Engi-
neering (CAiSE’05), Porto, Portugal, June.
J. Scheffczyk, A. Pease, and M. Ellsworth. 2006.
Linking FrameNet to the suggested upper merged
ontology. In Proceedings of the Fourth Interna-
tional Conference on Formal Ontology in Informa-
tion Systems (FOIS 2006), pages 289–300, Balti-
more, Maryland, USA, November.
A. Schiller, S. Teufel, C. Thielen, and C. St¨ockert.
1999. Guidelines f¨ur das Tagging deutscher
Textcorpora mit STTS. Technical report, University
of Stuttgart, University of T¨ubingen.
H. Schmid and F. Laws. 2008. Estimation of condi-
tional probabilities with decision trees and an ap-
plication to fine-grained pos tagging. In Procee-
dings of the 22nd International Conference on Com-
putational Linguistics (COLING 2008), Manchester,
UK, August.
H. Schmid. 1994. Probabilistic part-of-speech tagging
using decision trees. In Proceedings of International
Conference on New Methods in Language Process-
ing, pages 44–49, Manchester, UK, September.
T. Schmidt, C. Chiarcos, T. Lehmberg, G. Rehm,
A. Witt, and E. Hinrichs. 2006. Avoiding data
graveyards: From heterogeneous data collected in
multiple research projects to sustainable linguistic
resources. In Proceedings of the E-MELD work-
shop on Digital Language Documentation: Tools
and Standards: The State of the Art, East Lansing,
Michigan, US, June.
S. Sharoff, M. Kopotev, T. Erjavec, A. Feldman, and
D. Divjak. 2008. Designing and evaluating Rus-
sian tagsets. In Proceedings of the 6th International
Conference on Language Resources and Evaluation
(LREC 2008), Marrakech, Morocco, May.
E. Sirin, B. Parsia, B.C. Grau, A. Kalyanpur, and
Y. Katz. 2007. Pellet: A practical OWL/DL rea-
soner. Web Semantics: Science, Services and Agents
on the World Wide Web, 5(2):51–53.
W. Skut, T. Brants, B. Krenn, and H. Uszkoreit. 1998.
A linguistically interpreted corpus of German news-
paper text. In In Proceedings of the ESSLLI Work-
shop on Recent Advances in Corpus Annotation,
Saarbr¨ucken, Germany, August.
M. Stede. 2004. The Potsdam Commentary Corpus.
In Proceedings of the 2004 ACL Workshop on Dis-
course Annotation, pages 96–102, Barcelona, Spain,
July.
P. Tapanainen and T. J¨arvinen. 1997. A nonprojec-
tive dependency parser. In Proceedings of the 5th
Conference on Applied Natural Language Process-
ing, pages 64–71, Washington, DC, April.
K. Toutanova, D. Klein, C.D. Manning, and Y. Singer.
2003. Feature-rich part-of-speech tagging with a
cyclic dependency network. In Proceedings of the
2003 Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology (HLT-NAACL 2003),
Edmonton, Canada, May.
D. Tufis¸. 2000. Using a large set of EAGLES-
compliant morpho-syntactic descriptors as a tagset
for probabilistic tagging. In Proceedings of the 2nd
International Conference on Language Resources
and Evaluation (LREC 2000), pages 1105–1112,
Athens, Greece, May, 31st – June, 2nd.
A. Wagner and B. Zeisler. 2004. A syntactically an-
notated corpus of Tibetan. In Fourth International
Conference on Language Resources and Evaluation
(LREC 2004), Lisboa, Portugal, May.
J. Zavrel and W. Daelemans. 2000. Bootstrapping a
tagged corpus through combination of existing het-
erogeneous taggers. In Proceedings of the 2nd In-
ternational Conference on Language Resources and
Evaluation (LREC 2000), Athens, Greece, May, 31st
– June, 2nd.
A. Zielinski and C. Simon. 2008. Morphisto: An
open-source morphological analyzer for German. In
Proceedings of the Conference on Finite State Meth-
ods in Natural Language Processing (FSMNLP), Is-
pra, Italy, September.
</reference>
<page confidence="0.997942">
670
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999217">Towards robust multi-tool tagging. An OWL/DL-based approach</title>
<author confidence="0.999806">Christian Chiarcos</author>
<affiliation confidence="0.954377">University of Potsdam, Germany</affiliation>
<email confidence="0.998192">chiarcos@uni-potsdam.de</email>
<abstract confidence="0.991131789473684">This paper describes a series of experiments to test the hypothesis that the parallel application of multiple NLP tools and the integration of their results improves the correctness and robustness of the resulting analysis. It is shown how annotations created by seven NLP tools are mapped onto toolindependent descriptions that are defined with reference to an ontology of linguistic annotations, and how a majority vote and ontological consistency constraints can be used to integrate multiple alternative analyses of the same token in a consistent way. For morphosyntactic (parts of speech) and morphological annotations of three German corpora, the resulting merged sets of ontological descriptions are evaluated in comparison to (ontological representation of) existing reference annotations. 1 Motivation and overview NLP systems for higher-level operations or complex annotations often integrate redundant modules that provide alternative analyses for the same linguistic phenomenon in order to benefit from their respective strengths and to compensate for their respective weaknesses, e.g., in parsing (Crysmann et al., 2002), or in machine translation (Carl et al., 2000). The current trend to parallel and distributed NLP architectures (Aschenbrenner et al., 2006; Gietz et al., 2006; Egner et al., 2007; Luis and de Matos, 2009) opens the possibility of exploring the potential of redundant parallel annotations also for lower levels of linguistic analysis. This paper evaluates the potential benefits of such an approach with respect to morphosyntax (parts of speech, pos) and morphology in German: In comparison to English, German shows a rich and polysemous morphology, and a considerable number of NLP tools are available, making it a promising candidate for such an experiment. Previous research indicates that the integration of multiple part of speech taggers leads to more accurate analyses. So far, however, this line of research focused on tools that were trained on the same corpus (Brill and Wu, 1998; Halteren et al., 2001), or that specialize to different subsets of the tagset (Zavrel and Daelemans, 2000; 2000; Borin, 2000). An even more substantial increase in accuracy and detail can be expected if tools are combined that make use of different annotation schemes. For this task, ontologies of linguistic annotations are employed to assess the linguistic information conveyed in a particular annotation and to integrate the resulting ontological descriptions in a consistent and tool-independent way. The merged set of ontological descriptions is then evaluated with reference to morphosyntactic and morphological annotations of three corpora of German newspaper articles, the NEGRA corpus (Skut et al., 1998), the TIGER corpus (Brants et al., 2002) and the Potsdam Commentary Corpus (Stede, 2004, PCC). 2 Ontologies and annotations Various repositories of linguistic annotation terminology have been developed in the last decades, ranging from early texts on annotation standards (Bakker et al., 1993; Leech and Wilson, 1996) over relational data base models (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen,</abstract>
<address confidence="0.855138">2003, GOLD), the ISO TC37/SC4 Data Cate-</address>
<note confidence="0.832701142857143">Registry (Ide and Romary, 2004; Kemps- 659 of the 48th Annual Meeting of the Association for Computational pages 659–670, Sweden, 11-16 July 2010. Association for Computational Linguistics Snijders et al., 2009, DCR), the OntoTag ontology (Aguado de Cea et al., 2002), or the Typological Database System ontology (Saulwick et al., 2005,</note>
<abstract confidence="0.983803235382309">TDS). Despite their common level of representation, however, these efforts have not yet converged into a unified and generally accepted ontology of linguistic annotation terminology, but rather, different resources are maintained by different communities, so that a considerable amount of disagreement between them and their respective defican be Such conceptual mismatches and incompatibilities between existing terminological repositories have been the motivation to develop the OLiA architecture (Chiarcos, 2008) that employs a shallow Reference Model to mediate between (ontological models of) annotation schemes and several existing terminology repositories, incl. GOLD, the DCR, and OntoTag. When an annotation receives a representation in the OLiA Reference Model, it is thus also interpretable with respect to other linguistic ontologies. Therefore, the findings for the OLiA Reference Model in the experiments described below entail similar results for an application of GOLD or the DCR to the same task. 2.1 The OLiA ontologies The Ontologies of Linguistic Annotations – briefly, OLiA ontologies (Chiarcos, 2008) – represent an architecture of modular OWL/DL ontologies that formalize several intermediate steps of the mapping between concrete annotations, a Reference Model and existing terminology repositories (‘External Reference Models’ in OLiA tersuch as the The OLiA ontologies were originally developed as part of an infrastructure for the sustainable maintenance of linguistic resources (Schmidt et al., 2006) where they were originally applied one example, a GOLD Numeral is a De- (Numeral http://linguistics-ontology.org/gold/2008/ whereas a DCR Numeral is defined on the basis of its semantic function, without any references to syntactic categories of them a DCR Numeral but not a GOLD Numeral. OLiA Reference Model is accessible via http://nachhalt.sfb632.uni-potsdam.de/owl/ Several annotation models, e.g., be found in the same directory together with the corresponding files to the formal representation and documentation of annotation schemes, and for concept-based annotation queries over to multiple, heterogeneous corpora annotated with different annotation schemes (Rehm et al., 2007; Chiarcos et al., 2008). NLP applications of the OLiA ontologies include a proposal to integrate them with the OntoTag ontologies and to use them for interface specifications between modules in NLP pipeline architectures (Buyko et al., 2008). Further, Hellmann (2010) described the application of the OLiA ontologies within NLP2RDF, an OWL-based blackboard approach to assess the meaning of text from grammatical analyses and subsequent enrichment with ontological knowledge sources. OLiA distinguishes three different classes of ontologies: The the common terminology that different annotation schemes can refer to. It is primarily based on a blend of concepts of EAGLES and GOLD, and further extended in accordance with different annotation schemes, with the TDS ontology and with the DCR (Chiarcos, 2010). Multiple formalize annotation schemes and tag sets. Annotation Models are based on the original documentation and data samples, so that they provide an authentic representation of the annotation not biased with respect to any particular interpretation. For every Annotation Model, a relationships between concepts/properties in the respective Annotation Model and the Reference Model. Linking Models are interpretations of Annotation Model concepts and properties in terms of the Reference Model, and thus multiple alternative Linking Models for the same Annotation Model are possi- Other Linking Models specify relationships between Reference Model concepts/properties and concepts/properties of an External Reference Model such as GOLD or the DCR. OLiA Reference Model (namespace specifies concepts that describe linguistic cate- (e.g., and grammatifeatures (e.g., as well 660 Figure 1: Attributive demonstrative pronouns Figure 2: Selected morphosyntactic categories in the in the STTS Annotation Model OLiA Reference Model Figure 3: Individuals for accusative and sin- Figure 4: Selected morphological features in the gular in the TIGER Annotation Model OLiA Reference Model as properties that define possible relations bethose (e.g., More general concepts that represent organizational information rather than possible annotations (e.g., are stored in a separate ontology (namespace The Reference Model is a shallow ontology: It does not specify disjointness conditions of concepts and cardinality or domain restrictions of properties. Instead, it assumes that such conare inherited by means of from an External Reference Model. Different External Reference Models may take different posion the issue – as languages –, so that this aspect is left underspecified in the Reference Model. on primary experience with Western European languages, for example, one might assume that a applies to nouns, adjectives, pronouns and determiners only. Yet, this is language-specific restriction: Russian finite verbs, for example, show gender congruency in past tense. Figs. 2 and 4 show excerpts of category and feature hierarchies in the Reference Model. With respect to morphosyntactic annotations of speech, and morphological anfive Annotation Models for German are currently available: STTS (Schiller al., 1999, TIGER (Brants and Hansen, Morphisto (Zielinski and Simon, RFTagger (Schmid and Laws, Connexor (Tapanainen and 1997, Further Annotation for five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an annotation scheme for Tibetan (Wagner and Zeisler, 2004). 661 or the DCR). As an example, consider the attributive demonpronoun (1). Diese nicht neue Erkenntnis konnte (1) this not new insight could der Markt der M¨oglichkeiten am the market of.the possibilities on.the Sonnabend in Treuenbrietzen bestens Saturday in Treuenbrietzen in.the.best.way unterstreichen . underline ‘The ‘Market of Possibilities’, held this Saturday in Treuenbrietzen, provided best evidence for this well-known (lit. ‘not new’) insight.’ (PCC, #4794) 5: The STTS tags their representation in the Annotation Model and linking with the Reference Model. Annotation Models differ from the Reference Model mostly in that they include not only concepts and properties, but also individuals: Annotation Model concepts reflect an abstract conceptual categorization, whereas individuals represent concrete values used to annotate the corresponding phenomenon. An individual is applicable to all annotations that match the value specified by this individual’s or Fig. 1 trates the structure of the STTS Annotation (namespace for the individual represents the tag used for attributive demonstrative pronouns (demonstrative determiners). Fig. 3 illustrates the individuals the hierarchy of morphological features in the Annotation Model (namespace Fig. 5 illustrates the linking between the STTS Annotation Model and the OLiA Reference Model the individuals 2.2 Integrating different morphosyntactic and morphological analyses With the OLiA ontologies as described above, annotations from different annotation schemes can now be interpreted in terms of the OLiA Reference Model (or External Reference Models like GOLD phrase nicht neue Erkenntnis two challenges. First, it has to be recognized that the demonstrative pronoun is attributive, although it is from adjective and noun by Second, the phrase is in accusative case, although the morphology is ambiguous between accusative and nominative, and nominative case would be expected for a sentence-initial NP. The Connexor analysis (Tapanainen and Jirvinen, 1997) actually fails in both aspects (2). Dem FEM SG NOM The ontological analysis of this annotation begins by identifying the set of individuals from the Connexor Annotation Model that match it according their properties. The RDF triplet connexor:NOM connexor:hasTagContaining indicates that the tag is an application the individual an instance Further, the matches instance of etc. The result is a set of individuals that express different aspects of the meaning of the annotation. For these individuals, the Annotation Model superclasses and other propi.e., connexor:hasCase etc. The linguistic unit represented by the actual token can now be characterized by these properties: Every property applicable to a member in the individual set is assumed to be applicable to the linguistic unit as well. In order to save space, we use a notation closer to predicate logic (with the token as implicit subject). In terms the Annotation Model, the token thus described by the following descriptions: triplets are quoted in simplified form, with XML namespaces replacing the actual URIs. 662 (3) rdf:type(connexor:Pronoun) connexor:hasCase(connexor:NOM) ... Linking Model provides us with the information that (i) a subclass of the Re- Model concept (ii) an instance of the Reference concept and (iii) a subproperty of Accordingly, the predicates that describe the tobe reformulated in terms of the Re- Model. etc. Similarly, know that for some is that abbreviated here as In this way, the grammatical information conveyed in the original Connexor annotation can be represented in an annotation-independent and tagset-neutral way as shown for the Connexor analysis in (4). (4) rdf:type(olia:PronounOrDeterminer) rdf:type(olia:Pronoun) olia:hasNumber(some olia:Singular) olia:hasGender(some olia:Feminine) rdf:type(olia:DemonstrativePronoun) olia:hasCase(some olia:Nominative) Analogously, the corresponding RFTagger analysis (Schmid and Laws, 2008) given in (5) can be transformed into a description in terms of the OLiA Reference Model such as in (6). PRO.Dem.Attr.-3.Acc.Sg.Fem (6) rdf:type(olia:PronounOrDeterminer) olia:hasNumber(some olia:Singular) olia:hasGender(some olia:Feminine) olia:hasCase(some olia:Accusative) rdf:type(olia:DemonstrativeDeterminer) rdf:type(olia:Determiner) For every description obtained from these (and further) analyses, an integrated and consistent generalization can be established as described in the following section. 3 Processing linguistic annotations 3.1 Evaluation setup Fig. 6 sketches the architecture of the evaluaenvironment set up for this The input to the system is a set of documents with code used for the evaluation setup is available under Figure 6: Evaluation setup TIGER/NEGRA-style morphosyntactic or morphological annotation (Skut et al., 1998; Brants and Hansen, 2002) whose annotations are used as gold standard. From the annotated document, the plain tokenized text is extracted and analyzed by one or more of the following NLP tools: (i) Morphisto, a morphological analyzer without contextual disambiguation (Zielinski and Simon, 2008), (ii) two part of speech taggers: the TreeTagger (Schmid, 1994) and the Stanford Tagger (Toutanova et al., 2003), (iii) the RFTagger that performs part of speech and morphological analysis (Schmid and Laws, 2008), (iv) two PCFG parsers: the StanfordParser (Klein and Manning, 2003) and the BerkeleyParser (Petrov and Klein, 2007), and (v) the Connexor dependency parser (Tapanainen and J¨arvinen, 1997). These tools annotate parts of speech, and those in (i), (iii) and (v) also provide morphological features. All components ran in parallel threads on the same machine, with the exception of Morphisto that was addressed as a web service. The set of matching Annotation Model individuals for every annotation and the respective set of Reference Model descriptions are determined by means of 663 OLiA description Morphisto Connexor RF Tree Stanford Stanford Berkeley Tagger Tagger Tagger Parser Parser class PronounOrDeterminer Determiner DemonstrativeDeterminer Pronoun DemonstrativePronoun 5.5 7 1 0 0 1 1 1 1 1 1 1 1 1 0 0 5.5 1 1 1 1 1.5 1 1 1 1 1.5 0 0 0 0 0 0 0 0 hasNumber(some Singular) hasGender(some Feminine) hasCase(some Accusative) hasCase(some Nominative) hasNumber(some Plural) 2.5 2.5 1.5 1.5 0.5 0.5 (2/4) 0.5 (2/4) 0.5 (2/4) 0.5 (2/4) 0.5 (2/4) 1 1 0 1 0 1 1 1 0 0 n/a n/a n/a n/a produces four alternative candidate analyses for this example, so every alternative analysis receives the confidence score 0.25 does not distinguish attributive and substitutive it predicts 1: Confidence scores for ex. (1) the Pellet reasoner (Sirin et al., 2007) as described above. A disambiguation routine (see below) then determines the maximal consistent set of ontological descriptions. Finally, the outcome of this process is compared to the set of descriptions corresponding to the original annotation in the corpus. 3.2 Disambiguation Returning to examples (4) and (6) above, we see that the resulting set of descriptions conveys properties that are obviously contradice.g., Nominative) Our approach to disambiguation combines ontological consistency criteria with a confidence ranking. As we simulate an uninformed approach, the confidence ranking follows a majority vote. (1), the consultation of all seven tools results a confidence ranking as shown in Tab. 1: If a tool supports a description with its analysis, the confidence score is increased by 1 (or by the tool proposes annotations). A maximal consistent set of descriptions is then established as follows: (i) Given a confidence-ranked list of available ..., a result set Let the first element of ..., If consistent with every description then add Remove iterate in (ii) until is empty. The consistency of ontological descriptions is dehere as Two concepts consistent iff disjoint. Two descriptions are consistent iff consistent or neither a subproperty a superproperty of This heuristic formalizes an implicit disjointness assumption for all concepts in the ontology (all concepts are disjoint unless one is a subconcept of the other). Further, it imposes an implicit cardinality constraint on (e.g., Accusative) Nominative) inconsistent besibling concepts and thus disjoint). the example the descriptions type(DemonstrativeProinconsistent with Plural) inconsistent Singular) 2 and 4); these descriptions are thus ruled out. The have identical confidence so that the first that the algorithm encounters is chosen for the set of resulting descriptions, the other one is ruled out because of their inconsistency. OLiA Reference Model does not specify disjointness constraints, and neither do GOLD or the DCR as External Reference Models. The axioms of the OntoTag ontologies, however, are specific to Spanish and cannot be directly applied to German. 664 PCC TIGER NEGRA TIGER NEGRA best-performing tool (StanfordTagger) 1 tool .678 (.106) .660 (.091) .960 .956 Morphisto .573 .568 average (and std. deviation) for tool combinations Connexor .674 .662 1 tool .868 (.109) .864 (.122) .870 (.113) RFTagger .786 .751 2 tools .928 (.018) .931 (.021) .943 (.028) 2 tools .761 (.019) .740 (.012) 3 tools .947 (.014) .948 (.013) .956 (.018) C+M .738 .730 4 tools .956 (.006) .955 (.009) .963 (.013) M+R .769 .737 5 tools .959 (.006) .960 (.007) .964 (.009) C+R .773 .753 6 tools .963 (.003) .963 (.007) .965 (.007) all tools .791 .770 all tools .967 .960 .965 Stanford Tagger was trained on the NEGRA corpus. 3: Recall for morphological 2: Recall for for word classes The resulting, maximal consistent set of descriptions is then compared with the ontological descriptions that correspond to the original annotation in the corpus. 4 Evaluation Six experiments were conducted with the goal to evaluate the prediction of word classes and morphological features on parts of three corpora of German newspaper articles: NEGRA (Skut et al., 1998), TIGER (Brants et al., 2002), and the Potsdam Commentary Corpus (Stede, 2004, PCC). From every corpus 10,000 tokens were considered for the analysis. TIGER and NEGRA are well-known resources that also influenced the design of several of the tools considered. For this reason, the PCC was consulted, a small collection of newspaper commentaries, 30,000 tokens in total, annotated with TIGER-style parts of speech and syntax (by members of the TIGER project). None of the tools considered here were trained on this data, so that it provides independent test data. The ontological descriptions were evaluated for = (7), a text (a list of tokens) with ..., descriptions retrieved the NLP analyses of the token and the set of descriptions that corresto the original annotation of the corpus. and accuracy may not be appropriate measurements in this case: Annotation schemes differ in their expressiveness, so that a description predicted by an NLP tool but not found in the reference annotation may nevertheless be correct. The RFTagger, for example, assigns demonstrative pronouns the feature ‘3rd person’, that is not found in TIGER/NEGRA-style annotation because of its redundancy. 4.1 Word classes 2 shows that the recall of descriptions (for word classes) increases continuously with the number of NLP tools applied. The combination of all seven tools actually shows a better recall than the best-performing single NLP tool. (The NEGRA corpus is an apparent exception only; the exceptionally high recall of the Stanford Tagger reflects the fact that it was trained on NEGRA.) A particularly high increase in recall occurs when tools are combined that compensate for their respective deficits. Morphisto, for example, generates alternative morphological analyses, so that the disambiguation algorithm performs a random choice between these. Morphisto has thus the worst recall among all tools considered (PCC .69, TIGER .65, NEGRA .70 for word classes). As compared to this, Connexor performs a contextual disambiguation; its recall is, however, limited by its coarse-grained word classes (PCC .73, TIGER .72, NEGRA .73). The combination of both tools yields a more detailed and context-sensitive analysis and thus results in a boost in recall by more than 13% (PCC .87, TIGER .86, NEGRA .86). 4.2 Morphological features For morphological features, Tab. 3 shows the same tendencies that were also observed for word classes: The more tools are combined, the greater the recall of the generated descriptions, and the recall of combined tools often outperforms the recall of individual tools. The three tools that provide morphological annotations (Morphisto, Connexor, RFTagger) were evaluated against 10,000 tokens from TIGER and NEGRA respectively. The best-performing tool was the RFTagger, which possibly reflects the fact 665 that it was trained on TIGER-style annotations, whereas Morphisto and Connexor were developed on the basis of independent resources and thus differ from the reference annotation in their respective degree of granularity. 5 Summary and Discussion With the ontology-based approach described in this paper, the performance of annotation tools can be evaluated on a conceptual basis rather than by means of a string comparison with target annotations. A formal model of linguistic concepts is extensible, finer-grained and, thus, potentially more adequate for the integration of linguistic annotations than string-based representations, especially for heterogeneous annotations, if the tagsets involved are structured according to different design principles (e.g., due to different terminological traditions, different communities involved, etc.). has been shown that by from representations linguistic annotations, annotations from different tagsets can be represented with reference to the OLiA ontologies (and/or with other OWL/RDF-based terminology repositories linked as External Reference Models). In particular, it is possible to compare an existing reference annotation with annotations produced by NLP tools that use independently developed and differently structured annotation schemes (such as Connexor vs. RFTagger vs. Morphisto). an algorithm for the of difannotations been proposed that makes use of a majority-based confidence ranking and ontological consistency conditions. As consistency conditions are not formally defined in the OLiA Reference Model (which is expected to inherit such constraints from External Reference Models), a heuristic, structure-based definition of consistency was applied. This heuristic consistency definition is overly rigid and rules out a number of consistent alternative analyses, as it is the case for overlapping Despite this rigidity, we witness an of recall multiple alternative analyses are integrated. This increase of recall may result from a compensation of tool-specific deficits, e.g., with respect to annotation granularity. Also, the improved recall can be explained by a compensation of overfitting, or deficits that are inherent to compounds like German the’, for example, are both prepositions and determiners. a particular approach (e.g., differences in the coverage of the linguistic context). It can thus be stated that the integration of multiple alternative analyses has the potential to produce linguistic analyses that are both more robust and more detailed than those of the original tools. The primary field of application of this approach is most likely to be seen in a context where applications are designed that make direct use of OWL/RDF representations as described, for example, by Hellmann (2010). It is, however, also possible to use ontological representations to bootstrap novel and more detailed annotation schemes, cf. Zavrel and Daelemans (2000). Further, the conversion from string-based representations to ontological descriptions is reversible, so that results of ontology-based disambiguation and validation can also be reintegrated with the original annotation scheme. The idea of such a reversion algorithm was sketched by Buyko et al. (2008) where the OLiA ontologies were suggested as a means to translate between different annotation 6 Extensions and Related Research Natural extensions of the approach described in this paper include: (i) Experiments with formally defined consistency conditions (e.g., with respect to restrictions on the domain of properties). (ii) Context-sensitive disambiguation of morphological features (e.g., by combination with a chunker and adjustment of confidence scores for morphological features over all tokens in the current chunk, cf. Kermes and Evert, 2002). (iii) Replacement of majority vote by more elaborate strategies to merge grammatical analyses. mapping from ontological descriptions to tags of a particular scheme is possible, but neither trivial nor necessarily lossless: Information of ontological descriptions that cannot be expressed in the annotation scheme under consideration (e.g., the distinction between attributive and substitutive pronouns in the Morphisto scheme) will be missing in the resulting string representation. For complex annotations, where ontological descriptions correspond to different substrings, an additional ‘tag grammar’ may be necessary to determine the appropriate ordering of substrings according to the annotation scheme (e.g., in the Connexor analysis). 666 (iv) Application of the algorithm for the ontological processing of node labels and edge labels in syntax annotations. (v) Integration with other ontological knowledge sources in order to improve the recall of morphosyntactic and morphological analyses (e.g., for disambiguating grammatical case). Extensions (iii) and (iv) are currently pursued in an ongoing research effort described by Chiarcos et al. (2010). Like morphosyntactic and morphological features, node and edge labels of syntactic trees are ontologically represented in several Annotation Models, the OLiA Reference Model, and External Reference Models, the merging algorithm as described above can thus be applied for syntax, as well. Syntactic annotations, however, involve the additional challenge to align different structures before node and edge labels can be addressed, an issue not further discussed here for reasons of space limitations. Alternative strategies to merge grammatical analyses may include alternative voting strategies as discussed in literature on classifier combination, e.g., weighted majority vote, pairwise voting et al., 1998), credibility profiles 2000), or hand-crafted rules (Borin, 2000). A novel feature of our approach as compared to existing applications of these methods is that confidence scores are not attached to plain strings, but ontological descriptions: for example, assigned confidence scores not to tools (as in a weighted majority vote), but rather, assessed the of a tool respect to the predicted If this approach is applied to ontological descriptions in place of tags, it allows us to consider the credibility of pieces of information regardless of the actual string representation of tags. For exthe credibility of can be assessed independently from the credibility of even if the original annotation merged both aspects in one single tag (as the RFTagger does, for example, cf. ex. 5). Extension (v) has been addressed in previous research, although mostly with the opposite perspective: Already Cimiano and Reyle (2003) noted that the integration of grammatical and semantic analyses may be used to resolve ambiguity and underspecifications, and this insight has also motivated the ontological representation of linguistic resources such as WordNet (Gangemi et al., 2003), FrameNet (Scheffczyk et al., 2006), the linking of corpora with such ontologies (Hovy et al., 2006), the modelling of entire corpora in OWL/DL (Burchardt et al., 2008), and the extension of existing ontologies with ontological representations of selected linguistic features (Buitelaar et al., 2006; Davis et al., 2008). Aguado de Cea et al. (2004) sketched an architecture for the closer ontology-based integration of grammatical and semantic information using OntoTag and several NLP tools for Spanish. Aguado de Cea et al. (2008) evaluate the benefits this approach for the Spanish particle and conclude for this example that the combination of multiple tools yields more detailed and more accurate linguistic analyses of particularly problematic, polysemous function words. A similar increase in accuracy has also been repeatedly reported for ensemble combination approaches, that are, however, limited to tools that produce annotaaccording to the (Brill and Wu, 1998; Halteren et al., 2001). These observations provide further support for our conclusion that the ontology-based integration of morphosyntactic analyses enhances both the robustness and the level of detail of morphosyntactic and morphological analyses. Our approach extends the philosophy of ensemble combination approaches to NLP tools that do not only employ different strategies and philosophies, but also different annotation schemes. Acknowledgements From 2005 to 2008, the research on linguistic ontologies described in this paper was funded by the German Research Foundation (DFG) in the context of the Collaborative Research Center (SFB) 441 “Linguistic Data Structures”, Project C2 “Sustainability of Linguistic Resources” (University of T¨ubingen), and since 2007 in the context of the SFB 632 “Information Structure”, Project D1 “Linguistic Database” (University of Potsdam). The author would also like to thank Julia Ritz, Angela Lahee, Olga Chiarcos and three anonymous reviewers for helpful hints and comments.</abstract>
<note confidence="0.452813">667</note>
<title confidence="0.976304">References</title>
<author confidence="0.954746333333333">OntoTag A semantic page linguistic annotation model In Procee-</author>
<affiliation confidence="0.963971">dings of the ECAI 2002 Workshop on Semantic Au- Annotation and Knowledge Lyon,</affiliation>
<address confidence="0.969622">France, July.</address>
<note confidence="0.842607615384615">G. Aguado de Cea, A. Gomez-Perez, I. Alvarez de Mon, and A. Pareja-Lora. 2004. OntoTag’s linguistic ontologies: Improving semantic web annotations for a better language understanding in ma- In of the International Conference on Information Technology: Coding and Com- Las Vegas, Nevada, USA, April. G. Aguado de Cea, J. Puch, and J. ´A. Ramos. 2008. Spanish texts: The problem of “se”. In Proceedings of the Sixth International Conference on Resources and Evaluation (LREC Marrakech, Morocco, May. A. Aschenbrenner, P. Gietz, M.W. K¨uster, C. Ludwig, and H. Neuroth. 2006. TextGrid. A modular platfor collaborative textual editing. In Proceedings of the International Workshop on Digital Lib- Goes e-Science pages 27–36, Alicante, Spain, September. D. Bakker, O. Dahl, M. Haspelmath, M. Koptjevskaja- Tamm, C. Lehmann, and A. Siewierska. 1993. EUROTYP guidelines. Technical report, European Science Foundation Programme in Language Typology. B. Bickel and J. Nichols. 2000. The goals and principles of AUTOTYP. version of 01/12/2007. B. Bickel and J. Nichols. 2002. Autotypologizing and their use in fieldwork. In of the LREC 2002 Workshop on Resources and Tools Field Las Palmas, Spain, May. L. Borin. 2000. Something borrowed, something blue: Rule-based combination of POS taggers. In Proceedings of the 2nd International Conference on Resources and Evaluation (LREC Athens, Greece, May, 31st – June, 2nd. S. Brants and S. Hansen. 2002. Developments in the TIGER annotation scheme and their realization in corpus. In of the Third International Conference on Language Resources and Eva- (LREC pages 1643–1649, Las Palmas, Spain, May. S. Brants, S. Dipper, S. Hansen, W. Lezius, and Smith. 2002. The TIGER treebank. In Proceedings of the Workshop on Treebanks and Linguistic pages 24–41, Sozopol, Bulgaria, September. E. Brill and J. Wu. 1998. Classifier combination improved lexical disambiguation. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics pages 191–195, Montr´eal,</note>
<address confidence="0.965492">Canada, August.</address>
<author confidence="0.951702">P Buitelaar</author>
<author confidence="0.951702">T Declerck</author>
<author confidence="0.951702">A Frank</author>
<author confidence="0.951702">S Racioppa</author>
<author confidence="0.951702">M Kiesel</author>
<author confidence="0.951702">M Sintek</author>
<author confidence="0.951702">R Engel</author>
<author confidence="0.951702">M Romanelli</author>
<note confidence="0.849797322033898">D. Sonntag, B. Loos, V. Micelli, R. Porzel, and P. Cimiano. 2006. LingInfo: Design and applications of a model for the integration of linguistic inin ontologies. In of the 5th International Conference on Language Resources Evaluation (LREC Genoa, Italy, May. A. Burchardt, S. Pad´o, D. Spohr, A. Frank, and U. Heid. 2008. Formalising Multi-layer Corpora in OWL/DL – Lexicon Modelling, Querying and Con- Control. In of the 3rd Inter- Joint Conference on NLP (IJCNLP Hyderabad, India, January. E. Buyko, C. Chiarcos, and A. Pareja-Lora. 2008. Ontology-based interface specifications for a NLP architecture. In of the International Conference on Language Resources and Eva- (LREC Marrakech, Morocco, May. M. Carl, C. Pease, L.L. Iomdin, and O. Streiter. 2000. Towards a dynamic linkage of example-based and machine translation. Transla- 15(3):223–257. C. Chiarcos, S. Dipper, M. G¨otze, U. Leser, A. L¨udeling, J. Ritz, and M. Stede. 2008. A Flexible Framework for Integrating Annotations from Differ- Tools and Tag Sets. Automatique des 49(2). C. Chiarcos, K. Eckart, and J. Ritz. 2010. Creating and a resource of parallel parses. In Linguistic Annotation Workshop (LAW 2010), held in with Uppsala, Sweden, July. C. Chiarcos. 2008. An ontology of linguistic annota- 23(1):1–16. Foundations of Ontologies in Text Technology, Part II: Applications. C. Chiarcos. 2010. Grounding an ontology of linguistic annotations in the Data Category Registry. on Language Resource and Language Technology Standards (LR&amp;LTS 2010), held in conwith LREC Valetta, Malta, May. P. Cimiano and U. Reyle. 2003. Ontology-based semantic construction, underspecification and disam- In of the Lorraine/Saarland Workshop on Prospects and Recent Advances in the pages 33–38, Nancy, France, October. B. Crysmann, A. Frank, B. Kiefer, S. M¨uller, G. Neumann, J. Piskorski, U. Sch¨afer, M. Siegel, H. Uszkoreit, F. Xu, M. Becker, and H. Krieger. 2002. An 668 integrated architecture for shallow and deep proces- In of 40th Annual Meeting of the for Computational pages 441–448, Philadelphia, Pennsylvania, USA, July. B. Davis, S. Handschuh, A. Troussov, J. Judge, and M. Sogrin. 2008. Linguistically light lexical exfor ontologies. In of the Sixth International Conference on Language Resources Evaluation (LREC Marrakech, Morocco, May. S. Dipper, M. G¨otze, and S. Skopeteas, editors. 2007.</note>
<title confidence="0.7999685">Information Structure in Cross-Linguistic Corpora: Annotation Guidelines for Phonology, Morpholo- Syntax, Semantics, and Information Interdisciplinary Studies on Information Structure</title>
<note confidence="0.807510549618321">(ISIS), Working Papers of the SFB 632; 7. Universit¨atsverlag Potsdam, Potsdam, Germany. M.T. Egner, M. Lorch, and E. Biddle. 2007. UIMA Distributed large-scale text analysis. In Proceedings of the Seventh IEEE International Symposium on Cluster Computing and the Grid (CCpages 317–326, Rio de Janeiro, Brazil, May. S. Farrar and D.T. Langendoen. 2003. Markup and GOLD ontology. In Workshop on Diand Annotating Text and Field Michigan State University, July. A. Gangemi, R. Navigli, and P. Velardi. 2003. The OntoWordNet project: Extension and axiomatization of conceptual relations in WordNet. In R. Meersman Z. Tari, editors, of On the Move Meaningful Internet Systems pages 820–838, Catania, Italy, November. P. Gietz, A. Aschenbrenner, S. Budenbender, F. Jannidis, M.W. K¨uster, C. Ludwig, W. Pempe, T. Vitt, W. Wegstein, and A. Zielinski. 2006. TextGrid eHumanities. In of the Second IEEE International Conference on e-Science and Computing (E-SCIENCE pages 133–141, Amsterdam, The Netherlands, December. H. van Halteren, J. Zavrel, and W. Daelmans. 1998. Improving data driven wordclass tagging by system In of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Linguistics (COLING-ACL Montr´eal, Canada, August. H. van Halteren, J. Zavrel, and W. Daelmans. 2001. Improving accuracy in word class tagging through combination of machine learning systems. Com- 27(2):199–229. S. Hellmann. 2010. The semantic gap of formalized In 7th Extended Semantic Web Confe- (ESWC Heraklion, Greece, May 30th – June 3rd. E. Hovy, M. Marcus, M. Palmer, L. Ramshaw, and R. Weischedel. 2006. Ontonotes: the 90% solu- In of the North American Chapter of the Association for Computational Linguistics on Language Technology (HLT-NAACL pages 57–60, New York, June. N. Ide and L. Romary. 2004. A registry of standard categories for linguistic annotation. In Proceedings of the Fourth Language Resources and Evalu- Conference (LREC pages 135–39, Lisboa, Portugal, May. M. Kemps-Snijders, M. Windhouwer, P. Wittenburg, and S.E. Wright. 2009. ISOcat: remodelling metafor language resources. Journal Metadata, Semantics and 4(4):261– 276. H. Kermes and S. Evert. 2002. YAC – A recurchunker for unrestricted German text. In Proceedings of the Third International Conference on Resources and Evaluation (LREC pages 1805–1812, Las Palmas, Spain, May. J.D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. GE- NIA corpus – A semantically annotated corpus for 19(1):180–182. D. Klein and C.D. Manning. 2003. Accurate unlexiparsing. In of the 41st Annual Meeting of the Association for Computational Linpages 423–430, Sapporo, Japan, July. G. Leech and A. Wilson. 1996. EAGLES recommendations for the morphosyntactic annotation of corpora. Version of March 1996. T. Lu´ıs and D.M. de Matos. 2009. High-performance layered corpora annotation. In Proceedings of the Third Linguistic Annotation Workshop (LAW-III) held in conjunction with ACL-IJCNLP pages 99–107, Singapore, August. M. Mandel. 2006. Integrated annotation of biomedical Creating the PennBioIE corpus. In Mining Ontologies and Natural Language Processing in Manchester, UK, March. M.P. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1994. Building a large annotated corpus of En- The Penn Treebank. linguis- 19(2):313–330. R. Meyer. 2003. Halbautomatische morphosyntaktische Annotation russischer Texte. In R. Hamand L. Geist, editors, Beitr¨age Slavistik aus Deutschland und X. Berlin pages 92– 105. Sagner, M¨unchen. S. Petrov and D. Klein. 2007. Improved inference for parsing. In of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Lan- Technology (HLT-NAACL pages 404– 411, Rochester, NY, April. 669 S. Petrova, C. Chiarcos, J. Ritz, M. Solf, and A. Zeldes. 2009. Building and using a richly annotated interlinear diachronic corpus: The case of Old High Ger- Tatian. automatique des langues et 50(2):47–71. G. Rehm, R. Eckart, and C. Chiarcos. 2007. An OWLand XQuery-based mechanism for the retrieval of patterns from XML-corpora. In Proceedings of Recent Advances in Natural Language Pro- (RANLP Borovets, Bulgaria, September. Sampson. 1995. for the computer: The SUcorpus and analytic Oxford University Press. A. Saulwick, M. Windhouwer, A. Dimitriadis, and R. Goedemans. 2005. Distributed tasking in ontology mediated integration of typological databases linguistic research. In of the 17th Conference on Advanced Information Systems Engi- Porto, Portugal, June. J. Scheffczyk, A. Pease, and M. Ellsworth. 2006. Linking FrameNet to the suggested upper merged In of the Fourth International Conference on Formal Ontology in Informa- Systems (FOIS pages 289–300, Baltimore, Maryland, USA, November. A. Schiller, S. Teufel, C. Thielen, and C. St¨ockert. 1999. Guidelines f¨ur das Tagging deutscher Textcorpora mit STTS. Technical report, University of Stuttgart, University of T¨ubingen. H. Schmid and F. Laws. 2008. Estimation of conditional probabilities with decision trees and an apto fine-grained pos tagging. In Proceedings of the 22nd International Conference on Com-</note>
<affiliation confidence="0.773714">Linguistics (COLING Manchester,</affiliation>
<address confidence="0.841983">UK, August.</address>
<abstract confidence="0.6497749">H. Schmid. 1994. Probabilistic part-of-speech tagging decision trees. In of International Conference on New Methods in Language Processpages 44–49, Manchester, UK, September. T. Schmidt, C. Chiarcos, T. Lehmberg, G. Rehm, A. Witt, and E. Hinrichs. 2006. Avoiding data graveyards: From heterogeneous data collected in multiple research projects to sustainable linguistic In of the E-MELD workshop on Digital Language Documentation: Tools</abstract>
<affiliation confidence="0.977173">Standards: The State of the East Lansing,</affiliation>
<address confidence="0.987392">Michigan, US, June.</address>
<note confidence="0.757476725490196">S. Sharoff, M. Kopotev, T. Erjavec, A. Feldman, and D. Divjak. 2008. Designing and evaluating Rustagsets. In of the 6th International Conference on Language Resources and Evaluation Marrakech, Morocco, May. E. Sirin, B. Parsia, B.C. Grau, A. Kalyanpur, and Y. Katz. 2007. Pellet: A practical OWL/DL rea- Semantics: Science, Services and Agents the World Wide 5(2):51–53. W. Skut, T. Brants, B. Krenn, and H. Uszkoreit. 1998. A linguistically interpreted corpus of German newstext. In Proceedings of the ESSLLI Workon Recent Advances in Corpus Saarbr¨ucken, Germany, August. M. Stede. 2004. The Potsdam Commentary Corpus. of the 2004 ACL Workshop on Dispages 96–102, Barcelona, Spain, July. P. Tapanainen and T. J¨arvinen. 1997. A nonprojecdependency parser. In of the 5th Conference on Applied Natural Language Processpages 64–71, Washington, DC, April. K. Toutanova, D. Klein, C.D. Manning, and Y. Singer. 2003. Feature-rich part-of-speech tagging with a dependency network. In of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Language Technology (HLT-NAACL Edmonton, Canada, May. 2000. Using a large set of EAGLEScompliant morpho-syntactic descriptors as a tagset probabilistic tagging. In of the 2nd International Conference on Language Resources Evaluation (LREC pages 1105–1112, Athens, Greece, May, 31st – June, 2nd. A. Wagner and B. Zeisler. 2004. A syntactically ancorpus of Tibetan. In International Conference on Language Resources and Evaluation Lisboa, Portugal, May. J. Zavrel and W. Daelemans. 2000. Bootstrapping a tagged corpus through combination of existing hettaggers. In of the 2nd International Conference on Language Resources and (LREC Athens, Greece, May, 31st – June, 2nd. A. Zielinski and C. Simon. 2008. Morphisto: An open-source morphological analyzer for German. In Proceedings of the Conference on Finite State Methin Natural Language Processing Ispra, Italy, September. 670</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Aguado de Cea</author>
<author>´A I de Mon-Rego</author>
<author>A Pareja-Lora</author>
<author>R Plaza-Arteche</author>
</authors>
<title>OntoTag: A semantic web page linguistic annotation model.</title>
<date>2002</date>
<booktitle>In Proceedings of the ECAI 2002 Workshop on Semantic Authoring, Annotation and Knowledge Markup,</booktitle>
<location>Lyon, France,</location>
<marker>de Cea, de Mon-Rego, Pareja-Lora, Plaza-Arteche, 2002</marker>
<rawString>G. Aguado de Cea, ´A. I. de Mon-Rego, A. Pareja-Lora, and R. Plaza-Arteche. 2002. OntoTag: A semantic web page linguistic annotation model. In Proceedings of the ECAI 2002 Workshop on Semantic Authoring, Annotation and Knowledge Markup, Lyon, France, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Aguado de Cea</author>
<author>A Gomez-Perez</author>
<author>I Alvarez de Mon</author>
<author>A Pareja-Lora</author>
</authors>
<title>OntoTag’s linguistic ontologies: Improving semantic web annotations for a better language understanding in machines.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Information Technology: Coding and Computing (ITCC’04),</booktitle>
<location>Las Vegas, Nevada, USA,</location>
<marker>de Cea, Gomez-Perez, de Mon, Pareja-Lora, 2004</marker>
<rawString>G. Aguado de Cea, A. Gomez-Perez, I. Alvarez de Mon, and A. Pareja-Lora. 2004. OntoTag’s linguistic ontologies: Improving semantic web annotations for a better language understanding in machines. In Proceedings of the International Conference on Information Technology: Coding and Computing (ITCC’04), Las Vegas, Nevada, USA, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Aguado de Cea</author>
<author>J Puch</author>
<author>J ´A Ramos</author>
</authors>
<title>Tagging Spanish texts: The problem of “se”.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC 2008),</booktitle>
<location>Marrakech, Morocco,</location>
<marker>de Cea, Puch, Ramos, 2008</marker>
<rawString>G. Aguado de Cea, J. Puch, and J. ´A. Ramos. 2008. Tagging Spanish texts: The problem of “se”. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC 2008), Marrakech, Morocco, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Aschenbrenner</author>
<author>P Gietz</author>
<author>M W K¨uster</author>
<author>C Ludwig</author>
<author>H Neuroth</author>
</authors>
<title>TextGrid. A modular platform for collaborative textual editing.</title>
<date>2006</date>
<booktitle>In Proceedings of the International Workshop on Digital Library Goes e-Science (DLSci06),</booktitle>
<pages>27--36</pages>
<location>Alicante, Spain,</location>
<marker>Aschenbrenner, Gietz, K¨uster, Ludwig, Neuroth, 2006</marker>
<rawString>A. Aschenbrenner, P. Gietz, M.W. K¨uster, C. Ludwig, and H. Neuroth. 2006. TextGrid. A modular platform for collaborative textual editing. In Proceedings of the International Workshop on Digital Library Goes e-Science (DLSci06), pages 27–36, Alicante, Spain, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bakker</author>
<author>O Dahl</author>
<author>M Haspelmath</author>
<author>M KoptjevskajaTamm</author>
<author>C Lehmann</author>
<author>A Siewierska</author>
</authors>
<title>EUROTYP guidelines. Technical report, European Science Foundation Programme in Language Typology.</title>
<date>1993</date>
<contexts>
<context position="3186" citStr="Bakker et al., 1993" startWordPosition="482" endWordPosition="485">articular annotation and to integrate the resulting ontological descriptions in a consistent and tool-independent way. The merged set of ontological descriptions is then evaluated with reference to morphosyntactic and morphological annotations of three corpora of German newspaper articles, the NEGRA corpus (Skut et al., 1998), the TIGER corpus (Brants et al., 2002) and the Potsdam Commentary Corpus (Stede, 2004, PCC). 2 Ontologies and annotations Various repositories of linguistic annotation terminology have been developed in the last decades, ranging from early texts on annotation standards (Bakker et al., 1993; Leech and Wilson, 1996) over relational data base models (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen, 2003, GOLD), the ISO TC37/SC4 Data Category Registry (Ide and Romary, 2004; Kemps659 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 659–670, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Snijders et al., 2009, DCR), the OntoTag ontology (Aguado de Cea et al.,</context>
</contexts>
<marker>Bakker, Dahl, Haspelmath, KoptjevskajaTamm, Lehmann, Siewierska, 1993</marker>
<rawString>D. Bakker, O. Dahl, M. Haspelmath, M. KoptjevskajaTamm, C. Lehmann, and A. Siewierska. 1993. EUROTYP guidelines. Technical report, European Science Foundation Programme in Language Typology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Bickel</author>
<author>J Nichols</author>
</authors>
<title>The goals and principles of AUTOTYP. http://www.uni-leipzig.de/∼autotyp/ theory.html. version of 01/12/2007.</title>
<date>2000</date>
<contexts>
<context position="3270" citStr="Bickel and Nichols, 2000" startWordPosition="495" endWordPosition="498"> a consistent and tool-independent way. The merged set of ontological descriptions is then evaluated with reference to morphosyntactic and morphological annotations of three corpora of German newspaper articles, the NEGRA corpus (Skut et al., 1998), the TIGER corpus (Brants et al., 2002) and the Potsdam Commentary Corpus (Stede, 2004, PCC). 2 Ontologies and annotations Various repositories of linguistic annotation terminology have been developed in the last decades, ranging from early texts on annotation standards (Bakker et al., 1993; Leech and Wilson, 1996) over relational data base models (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen, 2003, GOLD), the ISO TC37/SC4 Data Category Registry (Ide and Romary, 2004; Kemps659 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 659–670, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Snijders et al., 2009, DCR), the OntoTag ontology (Aguado de Cea et al., 2002), or the Typological Database System ontology (Saulwick et al., 2005, TDS). De</context>
</contexts>
<marker>Bickel, Nichols, 2000</marker>
<rawString>B. Bickel and J. Nichols. 2000. The goals and principles of AUTOTYP. http://www.uni-leipzig.de/∼autotyp/ theory.html. version of 01/12/2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Bickel</author>
<author>J Nichols</author>
</authors>
<title>Autotypologizing databases and their use in fieldwork.</title>
<date>2002</date>
<booktitle>In Proceedings of the LREC 2002 Workshop on Resources and Tools in Field Linguistics,</booktitle>
<location>Las Palmas, Spain,</location>
<contexts>
<context position="3297" citStr="Bickel and Nichols, 2002" startWordPosition="499" endWordPosition="502">ependent way. The merged set of ontological descriptions is then evaluated with reference to morphosyntactic and morphological annotations of three corpora of German newspaper articles, the NEGRA corpus (Skut et al., 1998), the TIGER corpus (Brants et al., 2002) and the Potsdam Commentary Corpus (Stede, 2004, PCC). 2 Ontologies and annotations Various repositories of linguistic annotation terminology have been developed in the last decades, ranging from early texts on annotation standards (Bakker et al., 1993; Leech and Wilson, 1996) over relational data base models (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen, 2003, GOLD), the ISO TC37/SC4 Data Category Registry (Ide and Romary, 2004; Kemps659 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 659–670, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Snijders et al., 2009, DCR), the OntoTag ontology (Aguado de Cea et al., 2002), or the Typological Database System ontology (Saulwick et al., 2005, TDS). Despite their common level of</context>
</contexts>
<marker>Bickel, Nichols, 2002</marker>
<rawString>B. Bickel and J. Nichols. 2002. Autotypologizing databases and their use in fieldwork. In Proceedings of the LREC 2002 Workshop on Resources and Tools in Field Linguistics, Las Palmas, Spain, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Borin</author>
</authors>
<title>Something borrowed, something blue: Rule-based combination of POS taggers.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC 2000),</booktitle>
<location>Athens, Greece,</location>
<contexts>
<context position="2306" citStr="Borin, 2000" startWordPosition="350" endWordPosition="351">rphosyntax (parts of speech, pos) and morphology in German: In comparison to English, German shows a rich and polysemous morphology, and a considerable number of NLP tools are available, making it a promising candidate for such an experiment. Previous research indicates that the integration of multiple part of speech taggers leads to more accurate analyses. So far, however, this line of research focused on tools that were trained on the same corpus (Brill and Wu, 1998; Halteren et al., 2001), or that specialize to different subsets of the same tagset (Zavrel and Daelemans, 2000; Tufis¸, 2000; Borin, 2000). An even more substantial increase in accuracy and detail can be expected if tools are combined that make use of different annotation schemes. For this task, ontologies of linguistic annotations are employed to assess the linguistic information conveyed in a particular annotation and to integrate the resulting ontological descriptions in a consistent and tool-independent way. The merged set of ontological descriptions is then evaluated with reference to morphosyntactic and morphological annotations of three corpora of German newspaper articles, the NEGRA corpus (Skut et al., 1998), the TIGER </context>
<context position="30943" citStr="Borin, 2000" startWordPosition="4642" endWordPosition="4643">External Reference Models, the merging algorithm as described above can thus be applied for syntax, as well. Syntactic annotations, however, involve the additional challenge to align different structures before node and edge labels can be addressed, an issue not further discussed here for reasons of space limitations. Alternative strategies to merge grammatical analyses may include alternative voting strategies as discussed in literature on classifier combination, e.g., weighted majority vote, pairwise voting (Halteren et al., 1998), credibility profiles (Tufis¸, 2000), or hand-crafted rules (Borin, 2000). A novel feature of our approach as compared to existing applications of these methods is that confidence scores are not attached to plain strings, but to ontological descriptions: Tufis¸, for example, assigned confidence scores not to tools (as in a weighted majority vote), but rather, assessed the ‘credibility’ of a tool with respect to the predicted tag. If this approach is applied to ontological descriptions in place of tags, it allows us to consider the credibility of pieces of information regardless of the actual string representation of tags. For example, the credibility of hasCase des</context>
</contexts>
<marker>Borin, 2000</marker>
<rawString>L. Borin. 2000. Something borrowed, something blue: Rule-based combination of POS taggers. In Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC 2000), Athens, Greece, May, 31st – June, 2nd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brants</author>
<author>S Hansen</author>
</authors>
<title>Developments in the TIGER annotation scheme and their realization in the corpus.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1643--1649</pages>
<location>Las Palmas, Spain,</location>
<contexts>
<context position="9857" citStr="Brants and Hansen, 2002" startWordPosition="1464" endWordPosition="1467">e Model. 3Based on primary experience with Western European languages, for example, one might assume that a hasGender property applies to nouns, adjectives, pronouns and determiners only. Yet, this is language-specific restriction: Russian finite verbs, for example, show gender congruency in past tense. Figs. 2 and 4 show excerpts of category and feature hierarchies in the Reference Model. With respect to morphosyntactic annotations (parts of speech, pos) and morphological annotations (morph), five Annotation Models for German are currently available: STTS (Schiller et al., 1999, pos), TIGER (Brants and Hansen, 2002, morph), Morphisto (Zielinski and Simon, 2008, pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph), Connexor (Tapanainen and J¨arvinen, 1997, pos, morph). Further Annotation Models for pos and morph cover five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al.</context>
<context position="16203" citStr="Brants and Hansen, 2002" startWordPosition="2349" endWordPosition="2352">rminer) rdf:type(olia:Determiner) For every description obtained from these (and further) analyses, an integrated and consistent generalization can be established as described in the following section. 3 Processing linguistic annotations 3.1 Evaluation setup Fig. 6 sketches the architecture of the evaluation environment set up for this study.5 The input to the system is a set of documents with 5The code used for the evaluation setup is available under http://multiparse.sourceforge.net. Figure 6: Evaluation setup TIGER/NEGRA-style morphosyntactic or morphological annotation (Skut et al., 1998; Brants and Hansen, 2002) whose annotations are used as gold standard. From the annotated document, the plain tokenized text is extracted and analyzed by one or more of the following NLP tools: (i) Morphisto, a morphological analyzer without contextual disambiguation (Zielinski and Simon, 2008), (ii) two part of speech taggers: the TreeTagger (Schmid, 1994) and the Stanford Tagger (Toutanova et al., 2003), (iii) the RFTagger that performs part of speech and morphological analysis (Schmid and Laws, 2008), (iv) two PCFG parsers: the StanfordParser (Klein and Manning, 2003) and the BerkeleyParser (Petrov and Klein, 2007)</context>
</contexts>
<marker>Brants, Hansen, 2002</marker>
<rawString>S. Brants and S. Hansen. 2002. Developments in the TIGER annotation scheme and their realization in the corpus. In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC 2002), pages 1643–1649, Las Palmas, Spain, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brants</author>
<author>S Dipper</author>
<author>S Hansen</author>
<author>W Lezius</author>
<author>G Smith</author>
</authors>
<title>The TIGER treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Treebanks and Linguistic Theories,</booktitle>
<pages>24--41</pages>
<location>Sozopol, Bulgaria,</location>
<contexts>
<context position="2934" citStr="Brants et al., 2002" startWordPosition="445" endWordPosition="448">n more substantial increase in accuracy and detail can be expected if tools are combined that make use of different annotation schemes. For this task, ontologies of linguistic annotations are employed to assess the linguistic information conveyed in a particular annotation and to integrate the resulting ontological descriptions in a consistent and tool-independent way. The merged set of ontological descriptions is then evaluated with reference to morphosyntactic and morphological annotations of three corpora of German newspaper articles, the NEGRA corpus (Skut et al., 1998), the TIGER corpus (Brants et al., 2002) and the Potsdam Commentary Corpus (Stede, 2004, PCC). 2 Ontologies and annotations Various repositories of linguistic annotation terminology have been developed in the last decades, ranging from early texts on annotation standards (Bakker et al., 1993; Leech and Wilson, 1996) over relational data base models (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen, 2003, GOLD), the ISO TC37/SC4 Data Category Registry (Ide and Romary, 2004; Kemps659 Proceed</context>
<context position="22095" citStr="Brants et al., 2002" startWordPosition="3304" endWordPosition="3307">007) all tools .791 .770 all tools .967 .960 .965 * The Stanford Tagger was trained on the NEGRA corpus. Table 3: Recall for morphological Table 2: Recall for rdf:type descriptions for word classes hasXY() descriptions The resulting, maximal consistent set of descriptions is then compared with the ontological descriptions that correspond to the original annotation in the corpus. 4 Evaluation Six experiments were conducted with the goal to evaluate the prediction of word classes and morphological features on parts of three corpora of German newspaper articles: NEGRA (Skut et al., 1998), TIGER (Brants et al., 2002), and the Potsdam Commentary Corpus (Stede, 2004, PCC). From every corpus 10,000 tokens were considered for the analysis. TIGER and NEGRA are well-known resources that also influenced the design of several of the tools considered. For this reason, the PCC was consulted, a small collection of newspaper commentaries, 30,000 tokens in total, annotated with TIGER-style parts of speech and syntax (by members of the TIGER project). None of the tools considered here were trained on this data, so that it provides independent test data. The ontological descriptions were evaluated for recall:7 �� i�1 |D</context>
</contexts>
<marker>Brants, Dipper, Hansen, Lezius, Smith, 2002</marker>
<rawString>S. Brants, S. Dipper, S. Hansen, W. Lezius, and G. Smith. 2002. The TIGER treebank. In Proceedings of the Workshop on Treebanks and Linguistic Theories, pages 24–41, Sozopol, Bulgaria, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>J Wu</author>
</authors>
<title>Classifier combination for improved lexical disambiguation.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics (COLING-ACL</booktitle>
<pages>191--195</pages>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="2166" citStr="Brill and Wu, 1998" startWordPosition="326" endWordPosition="329">allel annotations also for lower levels of linguistic analysis. This paper evaluates the potential benefits of such an approach with respect to morphosyntax (parts of speech, pos) and morphology in German: In comparison to English, German shows a rich and polysemous morphology, and a considerable number of NLP tools are available, making it a promising candidate for such an experiment. Previous research indicates that the integration of multiple part of speech taggers leads to more accurate analyses. So far, however, this line of research focused on tools that were trained on the same corpus (Brill and Wu, 1998; Halteren et al., 2001), or that specialize to different subsets of the same tagset (Zavrel and Daelemans, 2000; Tufis¸, 2000; Borin, 2000). An even more substantial increase in accuracy and detail can be expected if tools are combined that make use of different annotation schemes. For this task, ontologies of linguistic annotations are employed to assess the linguistic information conveyed in a particular annotation and to integrate the resulting ontological descriptions in a consistent and tool-independent way. The merged set of ontological descriptions is then evaluated with reference to m</context>
<context position="33132" citStr="Brill and Wu, 1998" startWordPosition="4990" endWordPosition="4993">the closer ontology-based integration of grammatical and semantic information using OntoTag and several NLP tools for Spanish. Aguado de Cea et al. (2008) evaluate the benefits of this approach for the Spanish particle se, and conclude for this example that the combination of multiple tools yields more detailed and more accurate linguistic analyses of particularly problematic, polysemous function words. A similar increase in accuracy has also been repeatedly reported for ensemble combination approaches, that are, however, limited to tools that produce annotations according to the same tagset (Brill and Wu, 1998; Halteren et al., 2001). These observations provide further support for our conclusion that the ontology-based integration of morphosyntactic analyses enhances both the robustness and the level of detail of morphosyntactic and morphological analyses. Our approach extends the philosophy of ensemble combination approaches to NLP tools that do not only employ different strategies and philosophies, but also different annotation schemes. Acknowledgements From 2005 to 2008, the research on linguistic ontologies described in this paper was funded by the German Research Foundation (DFG) in the contex</context>
</contexts>
<marker>Brill, Wu, 1998</marker>
<rawString>E. Brill and J. Wu. 1998. Classifier combination for improved lexical disambiguation. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics (COLING-ACL 1998), pages 191–195, Montr´eal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Buitelaar</author>
<author>T Declerck</author>
<author>A Frank</author>
<author>S Racioppa</author>
<author>M Kiesel</author>
<author>M Sintek</author>
<author>R Engel</author>
<author>M Romanelli</author>
<author>D Sonntag</author>
<author>B Loos</author>
<author>V Micelli</author>
<author>R Porzel</author>
<author>P Cimiano</author>
</authors>
<title>LingInfo: Design and applications of a model for the integration of linguistic information in ontologies.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC</booktitle>
<location>Genoa, Italy,</location>
<contexts>
<context position="32434" citStr="Buitelaar et al., 2006" startWordPosition="4877" endWordPosition="4880">mostly with the opposite perspective: Already Cimiano and Reyle (2003) noted that the integration of grammatical and semantic analyses may be used to resolve ambiguity and underspecifications, and this insight has also motivated the ontological representation of linguistic resources such as WordNet (Gangemi et al., 2003), FrameNet (Scheffczyk et al., 2006), the linking of corpora with such ontologies (Hovy et al., 2006), the modelling of entire corpora in OWL/DL (Burchardt et al., 2008), and the extension of existing ontologies with ontological representations of selected linguistic features (Buitelaar et al., 2006; Davis et al., 2008). Aguado de Cea et al. (2004) sketched an architecture for the closer ontology-based integration of grammatical and semantic information using OntoTag and several NLP tools for Spanish. Aguado de Cea et al. (2008) evaluate the benefits of this approach for the Spanish particle se, and conclude for this example that the combination of multiple tools yields more detailed and more accurate linguistic analyses of particularly problematic, polysemous function words. A similar increase in accuracy has also been repeatedly reported for ensemble combination approaches, that are, h</context>
</contexts>
<marker>Buitelaar, Declerck, Frank, Racioppa, Kiesel, Sintek, Engel, Romanelli, Sonntag, Loos, Micelli, Porzel, Cimiano, 2006</marker>
<rawString>P. Buitelaar, T. Declerck, A. Frank, S. Racioppa, M. Kiesel, M. Sintek, R. Engel, M. Romanelli, D. Sonntag, B. Loos, V. Micelli, R. Porzel, and P. Cimiano. 2006. LingInfo: Design and applications of a model for the integration of linguistic information in ontologies. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC 2006), Genoa, Italy, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Burchardt</author>
<author>S Pad´o</author>
<author>D Spohr</author>
<author>A Frank</author>
<author>U Heid</author>
</authors>
<title>Formalising Multi-layer Corpora in OWL/DL – Lexicon Modelling, Querying and Consistency Control.</title>
<date>2008</date>
<booktitle>In Proceedings of the 3rd International Joint Conference on NLP (IJCNLP 2008),</booktitle>
<location>Hyderabad, India,</location>
<marker>Burchardt, Pad´o, Spohr, Frank, Heid, 2008</marker>
<rawString>A. Burchardt, S. Pad´o, D. Spohr, A. Frank, and U. Heid. 2008. Formalising Multi-layer Corpora in OWL/DL – Lexicon Modelling, Querying and Consistency Control. In Proceedings of the 3rd International Joint Conference on NLP (IJCNLP 2008), Hyderabad, India, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Buyko</author>
<author>C Chiarcos</author>
<author>A Pareja-Lora</author>
</authors>
<title>Ontology-based interface specifications for a NLP pipeline architecture.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Language Resources and Evaluation (LREC 2008),</booktitle>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="6613" citStr="Buyko et al., 2008" startWordPosition="979" endWordPosition="982">histo.owl can be found in the same directory together with the corresponding linking files stts-link.rdf, tiger-link.rdf, connexor-link.rdf and morphisto-link.rdf. to the formal representation and documentation of annotation schemes, and for concept-based annotation queries over to multiple, heterogeneous corpora annotated with different annotation schemes (Rehm et al., 2007; Chiarcos et al., 2008). NLP applications of the OLiA ontologies include a proposal to integrate them with the OntoTag ontologies and to use them for interface specifications between modules in NLP pipeline architectures (Buyko et al., 2008). Further, Hellmann (2010) described the application of the OLiA ontologies within NLP2RDF, an OWL-based blackboard approach to assess the meaning of text from grammatical analyses and subsequent enrichment with ontological knowledge sources. OLiA distinguishes three different classes of ontologies: • The OLIA REFERENCE MODEL specifies the common terminology that different annotation schemes can refer to. It is primarily based on a blend of concepts of EAGLES and GOLD, and further extended in accordance with different annotation schemes, with the TDS ontology and with the DCR (Chiarcos, 2010).</context>
<context position="28424" citStr="Buyko et al. (2008)" startWordPosition="4273" endWordPosition="4276">most likely to be seen in a context where applications are designed that make direct use of OWL/RDF representations as described, for example, by Hellmann (2010). It is, however, also possible to use ontological representations to bootstrap novel and more detailed annotation schemes, cf. Zavrel and Daelemans (2000). Further, the conversion from string-based representations to ontological descriptions is reversible, so that results of ontology-based disambiguation and validation can also be reintegrated with the original annotation scheme. The idea of such a reversion algorithm was sketched by Buyko et al. (2008) where the OLiA ontologies were suggested as a means to translate between different annotation schemes.9 6 Extensions and Related Research Natural extensions of the approach described in this paper include: (i) Experiments with formally defined consistency conditions (e.g., with respect to restrictions on the domain of properties). (ii) Context-sensitive disambiguation of morphological features (e.g., by combination with a chunker and adjustment of confidence scores for morphological features over all tokens in the current chunk, cf. Kermes and Evert, 2002). (iii) Replacement of majority vote </context>
</contexts>
<marker>Buyko, Chiarcos, Pareja-Lora, 2008</marker>
<rawString>E. Buyko, C. Chiarcos, and A. Pareja-Lora. 2008. Ontology-based interface specifications for a NLP pipeline architecture. In Proceedings of the International Conference on Language Resources and Evaluation (LREC 2008), Marrakech, Morocco, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Carl</author>
<author>C Pease</author>
<author>L L Iomdin</author>
<author>O Streiter</author>
</authors>
<title>Towards a dynamic linkage of example-based and rule-based machine translation.</title>
<date>2000</date>
<journal>Machine Translation,</journal>
<volume>15</volume>
<issue>3</issue>
<contexts>
<context position="1323" citStr="Carl et al., 2000" startWordPosition="189" endWordPosition="192">rphosyntactic (parts of speech) and morphological annotations of three German corpora, the resulting merged sets of ontological descriptions are evaluated in comparison to (ontological representation of) existing reference annotations. 1 Motivation and overview NLP systems for higher-level operations or complex annotations often integrate redundant modules that provide alternative analyses for the same linguistic phenomenon in order to benefit from their respective strengths and to compensate for their respective weaknesses, e.g., in parsing (Crysmann et al., 2002), or in machine translation (Carl et al., 2000). The current trend to parallel and distributed NLP architectures (Aschenbrenner et al., 2006; Gietz et al., 2006; Egner et al., 2007; Luis and de Matos, 2009) opens the possibility of exploring the potential of redundant parallel annotations also for lower levels of linguistic analysis. This paper evaluates the potential benefits of such an approach with respect to morphosyntax (parts of speech, pos) and morphology in German: In comparison to English, German shows a rich and polysemous morphology, and a considerable number of NLP tools are available, making it a promising candidate for such a</context>
</contexts>
<marker>Carl, Pease, Iomdin, Streiter, 2000</marker>
<rawString>M. Carl, C. Pease, L.L. Iomdin, and O. Streiter. 2000. Towards a dynamic linkage of example-based and rule-based machine translation. Machine Translation, 15(3):223–257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Chiarcos</author>
<author>S Dipper</author>
<author>M G¨otze</author>
<author>U Leser</author>
<author>A L¨udeling</author>
<author>J Ritz</author>
<author>M Stede</author>
</authors>
<title>A Flexible Framework for Integrating Annotations from Different Tools and Tag Sets. Traitement Automatique des Langues,</title>
<date>2008</date>
<volume>49</volume>
<issue>2</issue>
<marker>Chiarcos, Dipper, G¨otze, Leser, L¨udeling, Ritz, Stede, 2008</marker>
<rawString>C. Chiarcos, S. Dipper, M. G¨otze, U. Leser, A. L¨udeling, J. Ritz, and M. Stede. 2008. A Flexible Framework for Integrating Annotations from Different Tools and Tag Sets. Traitement Automatique des Langues, 49(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Chiarcos</author>
<author>K Eckart</author>
<author>J Ritz</author>
</authors>
<title>Creating and exploiting a resource of parallel parses.</title>
<date>2010</date>
<booktitle>In 4th Linguistic Annotation Workshop (LAW 2010), held in conjunction with ACL-2010,</booktitle>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="30150" citStr="Chiarcos et al. (2010)" startWordPosition="4525" endWordPosition="4528">ions correspond to different substrings, an additional ‘tag grammar’ may be necessary to determine the appropriate ordering of substrings according to the annotation scheme (e.g., in the Connexor analysis). 666 (iv) Application of the algorithm for the ontological processing of node labels and edge labels in syntax annotations. (v) Integration with other ontological knowledge sources in order to improve the recall of morphosyntactic and morphological analyses (e.g., for disambiguating grammatical case). Extensions (iii) and (iv) are currently pursued in an ongoing research effort described by Chiarcos et al. (2010). Like morphosyntactic and morphological features, node and edge labels of syntactic trees are ontologically represented in several Annotation Models, the OLiA Reference Model, and External Reference Models, the merging algorithm as described above can thus be applied for syntax, as well. Syntactic annotations, however, involve the additional challenge to align different structures before node and edge labels can be addressed, an issue not further discussed here for reasons of space limitations. Alternative strategies to merge grammatical analyses may include alternative voting strategies as d</context>
</contexts>
<marker>Chiarcos, Eckart, Ritz, 2010</marker>
<rawString>C. Chiarcos, K. Eckart, and J. Ritz. 2010. Creating and exploiting a resource of parallel parses. In 4th Linguistic Annotation Workshop (LAW 2010), held in conjunction with ACL-2010, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Chiarcos</author>
</authors>
<title>An ontology of linguistic annotations.</title>
<date>2008</date>
<journal>LDV Forum,</journal>
<booktitle>Foundations of Ontologies in Text Technology,</booktitle>
<volume>23</volume>
<issue>1</issue>
<publisher>Applications.</publisher>
<location>Part II:</location>
<contexts>
<context position="4396" citStr="Chiarcos, 2008" startWordPosition="661" endWordPosition="662"> al., 2002), or the Typological Database System ontology (Saulwick et al., 2005, TDS). Despite their common level of representation, however, these efforts have not yet converged into a unified and generally accepted ontology of linguistic annotation terminology, but rather, different resources are maintained by different communities, so that a considerable amount of disagreement between them and their respective definitions can be observed.1 Such conceptual mismatches and incompatibilities between existing terminological repositories have been the motivation to develop the OLiA architecture (Chiarcos, 2008) that employs a shallow Reference Model to mediate between (ontological models of) annotation schemes and several existing terminology repositories, incl. GOLD, the DCR, and OntoTag. When an annotation receives a representation in the OLiA Reference Model, it is thus also interpretable with respect to other linguistic ontologies. Therefore, the findings for the OLiA Reference Model in the experiments described below entail similar results for an application of GOLD or the DCR to the same task. 2.1 The OLiA ontologies The Ontologies of Linguistic Annotations – briefly, OLiA ontologies (Chiarcos</context>
</contexts>
<marker>Chiarcos, 2008</marker>
<rawString>C. Chiarcos. 2008. An ontology of linguistic annotations. LDV Forum, 23(1):1–16. Foundations of Ontologies in Text Technology, Part II: Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Chiarcos</author>
</authors>
<title>Grounding an ontology of linguistic annotations in the Data Category Registry.</title>
<date>2010</date>
<booktitle>In Workshop on Language Resource and Language Technology Standards (LR&amp;LTS 2010), held in conjunction with LREC 2010,</booktitle>
<location>Valetta, Malta,</location>
<contexts>
<context position="7212" citStr="Chiarcos, 2010" startWordPosition="1071" endWordPosition="1072">ko et al., 2008). Further, Hellmann (2010) described the application of the OLiA ontologies within NLP2RDF, an OWL-based blackboard approach to assess the meaning of text from grammatical analyses and subsequent enrichment with ontological knowledge sources. OLiA distinguishes three different classes of ontologies: • The OLIA REFERENCE MODEL specifies the common terminology that different annotation schemes can refer to. It is primarily based on a blend of concepts of EAGLES and GOLD, and further extended in accordance with different annotation schemes, with the TDS ontology and with the DCR (Chiarcos, 2010). • Multiple OLIA ANNOTATION MODELs formalize annotation schemes and tag sets. Annotation Models are based on the original documentation and data samples, so that they provide an authentic representation of the annotation not biased with respect to any particular interpretation. • For every Annotation Model, a LINKING MODEL defines subClassOf (C) relationships between concepts/properties in the respective Annotation Model and the Reference Model. Linking Models are interpretations of Annotation Model concepts and properties in terms of the Reference Model, and thus multiple alternative Linking</context>
</contexts>
<marker>Chiarcos, 2010</marker>
<rawString>C. Chiarcos. 2010. Grounding an ontology of linguistic annotations in the Data Category Registry. In Workshop on Language Resource and Language Technology Standards (LR&amp;LTS 2010), held in conjunction with LREC 2010, Valetta, Malta, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cimiano</author>
<author>U Reyle</author>
</authors>
<title>Ontology-based semantic construction, underspecification and disambiguation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Lorraine/Saarland Workshop on Prospects and Recent Advances in the Syntax-Semantics Interface,</booktitle>
<pages>33--38</pages>
<location>Nancy, France,</location>
<contexts>
<context position="31882" citStr="Cimiano and Reyle (2003)" startWordPosition="4792" endWordPosition="4795"> of a tool with respect to the predicted tag. If this approach is applied to ontological descriptions in place of tags, it allows us to consider the credibility of pieces of information regardless of the actual string representation of tags. For example, the credibility of hasCase descriptions can be assessed independently from the credibility of hasGender descriptions even if the original annotation merged both aspects in one single tag (as the RFTagger does, for example, cf. ex. 5). Extension (v) has been addressed in previous research, although mostly with the opposite perspective: Already Cimiano and Reyle (2003) noted that the integration of grammatical and semantic analyses may be used to resolve ambiguity and underspecifications, and this insight has also motivated the ontological representation of linguistic resources such as WordNet (Gangemi et al., 2003), FrameNet (Scheffczyk et al., 2006), the linking of corpora with such ontologies (Hovy et al., 2006), the modelling of entire corpora in OWL/DL (Burchardt et al., 2008), and the extension of existing ontologies with ontological representations of selected linguistic features (Buitelaar et al., 2006; Davis et al., 2008). Aguado de Cea et al. (200</context>
</contexts>
<marker>Cimiano, Reyle, 2003</marker>
<rawString>P. Cimiano and U. Reyle. 2003. Ontology-based semantic construction, underspecification and disambiguation. In Proceedings of the Lorraine/Saarland Workshop on Prospects and Recent Advances in the Syntax-Semantics Interface, pages 33–38, Nancy, France, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Crysmann</author>
<author>A Frank</author>
<author>B Kiefer</author>
<author>S M¨uller</author>
<author>G Neumann</author>
<author>J Piskorski</author>
<author>U Sch¨afer</author>
<author>M Siegel</author>
<author>H Uszkoreit</author>
<author>F Xu</author>
<author>M Becker</author>
<author>H Krieger</author>
</authors>
<title>An integrated architecture for shallow and deep processing.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>441--448</pages>
<location>Philadelphia, Pennsylvania, USA,</location>
<marker>Crysmann, Frank, Kiefer, M¨uller, Neumann, Piskorski, Sch¨afer, Siegel, Uszkoreit, Xu, Becker, Krieger, 2002</marker>
<rawString>B. Crysmann, A. Frank, B. Kiefer, S. M¨uller, G. Neumann, J. Piskorski, U. Sch¨afer, M. Siegel, H. Uszkoreit, F. Xu, M. Becker, and H. Krieger. 2002. An integrated architecture for shallow and deep processing. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 441–448, Philadelphia, Pennsylvania, USA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Davis</author>
<author>S Handschuh</author>
<author>A Troussov</author>
<author>J Judge</author>
<author>M Sogrin</author>
</authors>
<title>Linguistically light lexical extensions for ontologies.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC 2008),</booktitle>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="32455" citStr="Davis et al., 2008" startWordPosition="4881" endWordPosition="4884"> perspective: Already Cimiano and Reyle (2003) noted that the integration of grammatical and semantic analyses may be used to resolve ambiguity and underspecifications, and this insight has also motivated the ontological representation of linguistic resources such as WordNet (Gangemi et al., 2003), FrameNet (Scheffczyk et al., 2006), the linking of corpora with such ontologies (Hovy et al., 2006), the modelling of entire corpora in OWL/DL (Burchardt et al., 2008), and the extension of existing ontologies with ontological representations of selected linguistic features (Buitelaar et al., 2006; Davis et al., 2008). Aguado de Cea et al. (2004) sketched an architecture for the closer ontology-based integration of grammatical and semantic information using OntoTag and several NLP tools for Spanish. Aguado de Cea et al. (2008) evaluate the benefits of this approach for the Spanish particle se, and conclude for this example that the combination of multiple tools yields more detailed and more accurate linguistic analyses of particularly problematic, polysemous function words. A similar increase in accuracy has also been repeatedly reported for ensemble combination approaches, that are, however, limited to to</context>
</contexts>
<marker>Davis, Handschuh, Troussov, Judge, Sogrin, 2008</marker>
<rawString>B. Davis, S. Handschuh, A. Troussov, J. Judge, and M. Sogrin. 2008. Linguistically light lexical extensions for ontologies. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC 2008), Marrakech, Morocco, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dipper</author>
<author>M G¨otze</author>
<author>S Skopeteas</author>
<author>editors</author>
</authors>
<date>2007</date>
<booktitle>Information Structure in Cross-Linguistic Corpora: Annotation Guidelines for Phonology, Morphology, Syntax, Semantics, and Information Structure. Interdisciplinary Studies on Information Structure (ISIS), Working Papers of the SFB 632; 7. Universit¨atsverlag</booktitle>
<location>Potsdam, Potsdam, Germany.</location>
<marker>Dipper, G¨otze, Skopeteas, editors, 2007</marker>
<rawString>S. Dipper, M. G¨otze, and S. Skopeteas, editors. 2007. Information Structure in Cross-Linguistic Corpora: Annotation Guidelines for Phonology, Morphology, Syntax, Semantics, and Information Structure. Interdisciplinary Studies on Information Structure (ISIS), Working Papers of the SFB 632; 7. Universit¨atsverlag Potsdam, Potsdam, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Egner</author>
<author>M Lorch</author>
<author>E Biddle</author>
</authors>
<title>UIMA Grid: Distributed large-scale text analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the Seventh IEEE International Symposium on Cluster Computing and the Grid (CCGRID’07),</booktitle>
<pages>317--326</pages>
<location>Rio de Janeiro, Brazil,</location>
<contexts>
<context position="1456" citStr="Egner et al., 2007" startWordPosition="211" endWordPosition="214">iptions are evaluated in comparison to (ontological representation of) existing reference annotations. 1 Motivation and overview NLP systems for higher-level operations or complex annotations often integrate redundant modules that provide alternative analyses for the same linguistic phenomenon in order to benefit from their respective strengths and to compensate for their respective weaknesses, e.g., in parsing (Crysmann et al., 2002), or in machine translation (Carl et al., 2000). The current trend to parallel and distributed NLP architectures (Aschenbrenner et al., 2006; Gietz et al., 2006; Egner et al., 2007; Luis and de Matos, 2009) opens the possibility of exploring the potential of redundant parallel annotations also for lower levels of linguistic analysis. This paper evaluates the potential benefits of such an approach with respect to morphosyntax (parts of speech, pos) and morphology in German: In comparison to English, German shows a rich and polysemous morphology, and a considerable number of NLP tools are available, making it a promising candidate for such an experiment. Previous research indicates that the integration of multiple part of speech taggers leads to more accurate analyses. So</context>
</contexts>
<marker>Egner, Lorch, Biddle, 2007</marker>
<rawString>M.T. Egner, M. Lorch, and E. Biddle. 2007. UIMA Grid: Distributed large-scale text analysis. In Proceedings of the Seventh IEEE International Symposium on Cluster Computing and the Grid (CCGRID’07), pages 317–326, Rio de Janeiro, Brazil, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Farrar</author>
<author>D T Langendoen</author>
</authors>
<title>Markup and the GOLD ontology.</title>
<date>2003</date>
<booktitle>In EMELD Workshop on Digitizing and Annotating Text and</booktitle>
<institution>Field Recordings. Michigan State University,</institution>
<contexts>
<context position="3446" citStr="Farrar and Langendoen, 2003" startWordPosition="520" endWordPosition="523"> corpora of German newspaper articles, the NEGRA corpus (Skut et al., 1998), the TIGER corpus (Brants et al., 2002) and the Potsdam Commentary Corpus (Stede, 2004, PCC). 2 Ontologies and annotations Various repositories of linguistic annotation terminology have been developed in the last decades, ranging from early texts on annotation standards (Bakker et al., 1993; Leech and Wilson, 1996) over relational data base models (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen, 2003, GOLD), the ISO TC37/SC4 Data Category Registry (Ide and Romary, 2004; Kemps659 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 659–670, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Snijders et al., 2009, DCR), the OntoTag ontology (Aguado de Cea et al., 2002), or the Typological Database System ontology (Saulwick et al., 2005, TDS). Despite their common level of representation, however, these efforts have not yet converged into a unified and generally accepted ontology of linguistic annotation terminology, b</context>
</contexts>
<marker>Farrar, Langendoen, 2003</marker>
<rawString>S. Farrar and D.T. Langendoen. 2003. Markup and the GOLD ontology. In EMELD Workshop on Digitizing and Annotating Text and Field Recordings. Michigan State University, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gangemi</author>
<author>R Navigli</author>
<author>P Velardi</author>
</authors>
<title>The OntoWordNet project: Extension and axiomatization of conceptual relations in WordNet. In</title>
<date>2003</date>
<booktitle>Proceedings of On the Move to Meaningful Internet Systems (OTM2003),</booktitle>
<pages>820--838</pages>
<editor>R. Meersman and Z. Tari, editors,</editor>
<location>Catania, Italy,</location>
<contexts>
<context position="32134" citStr="Gangemi et al., 2003" startWordPosition="4831" endWordPosition="4834">the credibility of hasCase descriptions can be assessed independently from the credibility of hasGender descriptions even if the original annotation merged both aspects in one single tag (as the RFTagger does, for example, cf. ex. 5). Extension (v) has been addressed in previous research, although mostly with the opposite perspective: Already Cimiano and Reyle (2003) noted that the integration of grammatical and semantic analyses may be used to resolve ambiguity and underspecifications, and this insight has also motivated the ontological representation of linguistic resources such as WordNet (Gangemi et al., 2003), FrameNet (Scheffczyk et al., 2006), the linking of corpora with such ontologies (Hovy et al., 2006), the modelling of entire corpora in OWL/DL (Burchardt et al., 2008), and the extension of existing ontologies with ontological representations of selected linguistic features (Buitelaar et al., 2006; Davis et al., 2008). Aguado de Cea et al. (2004) sketched an architecture for the closer ontology-based integration of grammatical and semantic information using OntoTag and several NLP tools for Spanish. Aguado de Cea et al. (2008) evaluate the benefits of this approach for the Spanish particle s</context>
</contexts>
<marker>Gangemi, Navigli, Velardi, 2003</marker>
<rawString>A. Gangemi, R. Navigli, and P. Velardi. 2003. The OntoWordNet project: Extension and axiomatization of conceptual relations in WordNet. In R. Meersman and Z. Tari, editors, Proceedings of On the Move to Meaningful Internet Systems (OTM2003), pages 820–838, Catania, Italy, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Gietz</author>
<author>A Aschenbrenner</author>
<author>S Budenbender</author>
<author>F Jannidis</author>
<author>M W K¨uster</author>
<author>C Ludwig</author>
<author>W Pempe</author>
<author>T Vitt</author>
<author>W Wegstein</author>
<author>A Zielinski</author>
</authors>
<title>TextGrid and eHumanities.</title>
<date>2006</date>
<booktitle>In Proceedings of the Second IEEE International Conference on e-Science and Grid Computing (E-SCIENCE ’06),</booktitle>
<pages>133--141</pages>
<location>Amsterdam, The Netherlands,</location>
<marker>Gietz, Aschenbrenner, Budenbender, Jannidis, K¨uster, Ludwig, Pempe, Vitt, Wegstein, Zielinski, 2006</marker>
<rawString>P. Gietz, A. Aschenbrenner, S. Budenbender, F. Jannidis, M.W. K¨uster, C. Ludwig, W. Pempe, T. Vitt, W. Wegstein, and A. Zielinski. 2006. TextGrid and eHumanities. In Proceedings of the Second IEEE International Conference on e-Science and Grid Computing (E-SCIENCE ’06), pages 133–141, Amsterdam, The Netherlands, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H van Halteren</author>
<author>J Zavrel</author>
<author>W Daelmans</author>
</authors>
<title>Improving data driven wordclass tagging by system combination.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics (COLING-ACL</booktitle>
<location>Montr´eal, Canada,</location>
<marker>van Halteren, Zavrel, Daelmans, 1998</marker>
<rawString>H. van Halteren, J. Zavrel, and W. Daelmans. 1998. Improving data driven wordclass tagging by system combination. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics (COLING-ACL 1998), Montr´eal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H van Halteren</author>
<author>J Zavrel</author>
<author>W Daelmans</author>
</authors>
<title>Improving accuracy in word class tagging through the combination of machine learning systems.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>2</issue>
<marker>van Halteren, Zavrel, Daelmans, 2001</marker>
<rawString>H. van Halteren, J. Zavrel, and W. Daelmans. 2001. Improving accuracy in word class tagging through the combination of machine learning systems. Computational Linguistics, 27(2):199–229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hellmann</author>
</authors>
<title>The semantic gap of formalized meaning.</title>
<date>2010</date>
<booktitle>In The 7th Extended Semantic Web Conference (ESWC 2010), Heraklion, Greece, May 30th –</booktitle>
<contexts>
<context position="6639" citStr="Hellmann (2010)" startWordPosition="984" endWordPosition="985">same directory together with the corresponding linking files stts-link.rdf, tiger-link.rdf, connexor-link.rdf and morphisto-link.rdf. to the formal representation and documentation of annotation schemes, and for concept-based annotation queries over to multiple, heterogeneous corpora annotated with different annotation schemes (Rehm et al., 2007; Chiarcos et al., 2008). NLP applications of the OLiA ontologies include a proposal to integrate them with the OntoTag ontologies and to use them for interface specifications between modules in NLP pipeline architectures (Buyko et al., 2008). Further, Hellmann (2010) described the application of the OLiA ontologies within NLP2RDF, an OWL-based blackboard approach to assess the meaning of text from grammatical analyses and subsequent enrichment with ontological knowledge sources. OLiA distinguishes three different classes of ontologies: • The OLIA REFERENCE MODEL specifies the common terminology that different annotation schemes can refer to. It is primarily based on a blend of concepts of EAGLES and GOLD, and further extended in accordance with different annotation schemes, with the TDS ontology and with the DCR (Chiarcos, 2010). • Multiple OLIA ANNOTATIO</context>
<context position="27966" citStr="Hellmann (2010)" startWordPosition="4208" endWordPosition="4209">o 8Preposition-determiner compounds like German am ‘on the’, for example, are both prepositions and determiners. a particular approach (e.g., differences in the coverage of the linguistic context). It can thus be stated that the integration of multiple alternative analyses has the potential to produce linguistic analyses that are both more robust and more detailed than those of the original tools. The primary field of application of this approach is most likely to be seen in a context where applications are designed that make direct use of OWL/RDF representations as described, for example, by Hellmann (2010). It is, however, also possible to use ontological representations to bootstrap novel and more detailed annotation schemes, cf. Zavrel and Daelemans (2000). Further, the conversion from string-based representations to ontological descriptions is reversible, so that results of ontology-based disambiguation and validation can also be reintegrated with the original annotation scheme. The idea of such a reversion algorithm was sketched by Buyko et al. (2008) where the OLiA ontologies were suggested as a means to translate between different annotation schemes.9 6 Extensions and Related Research Nat</context>
</contexts>
<marker>Hellmann, 2010</marker>
<rawString>S. Hellmann. 2010. The semantic gap of formalized meaning. In The 7th Extended Semantic Web Conference (ESWC 2010), Heraklion, Greece, May 30th – June 3rd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy</author>
<author>M Marcus</author>
<author>M Palmer</author>
<author>L Ramshaw</author>
<author>R Weischedel</author>
</authors>
<title>Ontonotes: the 90% solution.</title>
<date>2006</date>
<booktitle>In Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (HLT-NAACL</booktitle>
<pages>57--60</pages>
<location>New York,</location>
<contexts>
<context position="32235" citStr="Hovy et al., 2006" startWordPosition="4847" endWordPosition="4850">descriptions even if the original annotation merged both aspects in one single tag (as the RFTagger does, for example, cf. ex. 5). Extension (v) has been addressed in previous research, although mostly with the opposite perspective: Already Cimiano and Reyle (2003) noted that the integration of grammatical and semantic analyses may be used to resolve ambiguity and underspecifications, and this insight has also motivated the ontological representation of linguistic resources such as WordNet (Gangemi et al., 2003), FrameNet (Scheffczyk et al., 2006), the linking of corpora with such ontologies (Hovy et al., 2006), the modelling of entire corpora in OWL/DL (Burchardt et al., 2008), and the extension of existing ontologies with ontological representations of selected linguistic features (Buitelaar et al., 2006; Davis et al., 2008). Aguado de Cea et al. (2004) sketched an architecture for the closer ontology-based integration of grammatical and semantic information using OntoTag and several NLP tools for Spanish. Aguado de Cea et al. (2008) evaluate the benefits of this approach for the Spanish particle se, and conclude for this example that the combination of multiple tools yields more detailed and more</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>E. Hovy, M. Marcus, M. Palmer, L. Ramshaw, and R. Weischedel. 2006. Ontonotes: the 90% solution. In Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (HLT-NAACL 2006), pages 57–60, New York, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>L Romary</author>
</authors>
<title>A registry of standard data categories for linguistic annotation.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth Language Resources and Evaluation Conference (LREC 2004),</booktitle>
<pages>135--39</pages>
<location>Lisboa, Portugal,</location>
<contexts>
<context position="3516" citStr="Ide and Romary, 2004" startWordPosition="532" endWordPosition="535">the TIGER corpus (Brants et al., 2002) and the Potsdam Commentary Corpus (Stede, 2004, PCC). 2 Ontologies and annotations Various repositories of linguistic annotation terminology have been developed in the last decades, ranging from early texts on annotation standards (Bakker et al., 1993; Leech and Wilson, 1996) over relational data base models (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen, 2003, GOLD), the ISO TC37/SC4 Data Category Registry (Ide and Romary, 2004; Kemps659 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 659–670, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Snijders et al., 2009, DCR), the OntoTag ontology (Aguado de Cea et al., 2002), or the Typological Database System ontology (Saulwick et al., 2005, TDS). Despite their common level of representation, however, these efforts have not yet converged into a unified and generally accepted ontology of linguistic annotation terminology, but rather, different resources are maintained by different communities</context>
</contexts>
<marker>Ide, Romary, 2004</marker>
<rawString>N. Ide and L. Romary. 2004. A registry of standard data categories for linguistic annotation. In Proceedings of the Fourth Language Resources and Evaluation Conference (LREC 2004), pages 135–39, Lisboa, Portugal, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kemps-Snijders</author>
<author>M Windhouwer</author>
<author>P Wittenburg</author>
<author>S E Wright</author>
</authors>
<title>ISOcat: remodelling metadata for language resources.</title>
<date>2009</date>
<journal>International Journal of Metadata, Semantics and Ontologies,</journal>
<volume>4</volume>
<issue>4</issue>
<pages>276</pages>
<marker>Kemps-Snijders, Windhouwer, Wittenburg, Wright, 2009</marker>
<rawString>M. Kemps-Snijders, M. Windhouwer, P. Wittenburg, and S.E. Wright. 2009. ISOcat: remodelling metadata for language resources. International Journal of Metadata, Semantics and Ontologies, 4(4):261– 276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kermes</author>
<author>S Evert</author>
</authors>
<title>YAC – A recursive chunker for unrestricted German text.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1805--1812</pages>
<location>Las Palmas, Spain,</location>
<contexts>
<context position="28987" citStr="Kermes and Evert, 2002" startWordPosition="4356" endWordPosition="4359">ch a reversion algorithm was sketched by Buyko et al. (2008) where the OLiA ontologies were suggested as a means to translate between different annotation schemes.9 6 Extensions and Related Research Natural extensions of the approach described in this paper include: (i) Experiments with formally defined consistency conditions (e.g., with respect to restrictions on the domain of properties). (ii) Context-sensitive disambiguation of morphological features (e.g., by combination with a chunker and adjustment of confidence scores for morphological features over all tokens in the current chunk, cf. Kermes and Evert, 2002). (iii) Replacement of majority vote by more elaborate strategies to merge grammatical analyses. 9The mapping from ontological descriptions to tags of a particular scheme is possible, but neither trivial nor necessarily lossless: Information of ontological descriptions that cannot be expressed in the annotation scheme under consideration (e.g., the distinction between attributive and substitutive pronouns in the Morphisto scheme) will be missing in the resulting string representation. For complex annotations, where ontological descriptions correspond to different substrings, an additional ‘tag</context>
</contexts>
<marker>Kermes, Evert, 2002</marker>
<rawString>H. Kermes and S. Evert. 2002. YAC – A recursive chunker for unrestricted German text. In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC 2002), pages 1805–1812, Las Palmas, Spain, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Kim</author>
<author>T Ohta</author>
<author>Y Tateisi</author>
<author>J Tsujii</author>
</authors>
<title>GENIA corpus – A semantically annotated corpus for bio-textmining.</title>
<date>2003</date>
<journal>Bioinformatics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="10182" citStr="Kim et al., 2003" startWordPosition="1513" endWordPosition="1516"> of category and feature hierarchies in the Reference Model. With respect to morphosyntactic annotations (parts of speech, pos) and morphological annotations (morph), five Annotation Models for German are currently available: STTS (Schiller et al., 1999, pos), TIGER (Brants and Hansen, 2002, morph), Morphisto (Zielinski and Simon, 2008, pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph), Connexor (Tapanainen and J¨arvinen, 1997, pos, morph). Further Annotation Models for pos and morph cover five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an annotation scheme for Tibetan (Wagner and Zeisler, 2004). 661 or the DCR). As an example, consider the attributive demonstrative pronoun diese in (1). Diese nicht neue Erkenntnis konnte (1) this not new insight could der Markt der M¨oglichkeiten am the market of.the possibilities on.the Sonnabend in Treuenbr</context>
</contexts>
<marker>Kim, Ohta, Tateisi, Tsujii, 2003</marker>
<rawString>J.D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. GENIA corpus – A semantically annotated corpus for bio-textmining. Bioinformatics, 19(1):180–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="16755" citStr="Klein and Manning, 2003" startWordPosition="2435" endWordPosition="2438">or morphological annotation (Skut et al., 1998; Brants and Hansen, 2002) whose annotations are used as gold standard. From the annotated document, the plain tokenized text is extracted and analyzed by one or more of the following NLP tools: (i) Morphisto, a morphological analyzer without contextual disambiguation (Zielinski and Simon, 2008), (ii) two part of speech taggers: the TreeTagger (Schmid, 1994) and the Stanford Tagger (Toutanova et al., 2003), (iii) the RFTagger that performs part of speech and morphological analysis (Schmid and Laws, 2008), (iv) two PCFG parsers: the StanfordParser (Klein and Manning, 2003) and the BerkeleyParser (Petrov and Klein, 2007), and (v) the Connexor dependency parser (Tapanainen and J¨arvinen, 1997). These tools annotate parts of speech, and those in (i), (iii) and (v) also provide morphological features. All components ran in parallel threads on the same machine, with the exception of Morphisto that was addressed as a web service. The set of matching Annotation Model individuals for every annotation and the respective set of Reference Model descriptions are determined by means of 663 OLiA description Morphisto Connexor RF Tree Stanford Stanford Berkeley Tagger Tagger </context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>D. Klein and C.D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 423–430, Sapporo, Japan, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leech</author>
<author>A Wilson</author>
</authors>
<title>EAGLES recommendations for the morphosyntactic annotation of corpora. Version of</title>
<date>1996</date>
<contexts>
<context position="3211" citStr="Leech and Wilson, 1996" startWordPosition="486" endWordPosition="489">and to integrate the resulting ontological descriptions in a consistent and tool-independent way. The merged set of ontological descriptions is then evaluated with reference to morphosyntactic and morphological annotations of three corpora of German newspaper articles, the NEGRA corpus (Skut et al., 1998), the TIGER corpus (Brants et al., 2002) and the Potsdam Commentary Corpus (Stede, 2004, PCC). 2 Ontologies and annotations Various repositories of linguistic annotation terminology have been developed in the last decades, ranging from early texts on annotation standards (Bakker et al., 1993; Leech and Wilson, 1996) over relational data base models (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen, 2003, GOLD), the ISO TC37/SC4 Data Category Registry (Ide and Romary, 2004; Kemps659 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 659–670, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Snijders et al., 2009, DCR), the OntoTag ontology (Aguado de Cea et al., 2002), or the Typologica</context>
</contexts>
<marker>Leech, Wilson, 1996</marker>
<rawString>G. Leech and A. Wilson. 1996. EAGLES recommendations for the morphosyntactic annotation of corpora. Version of March 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Lu´ıs</author>
<author>D M de Matos</author>
</authors>
<title>High-performance high-volume layered corpora annotation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Third Linguistic Annotation Workshop (LAW-III) held in conjunction with ACL-IJCNLP</booktitle>
<pages>99--107</pages>
<location>Singapore,</location>
<marker>Lu´ıs, de Matos, 2009</marker>
<rawString>T. Lu´ıs and D.M. de Matos. 2009. High-performance high-volume layered corpora annotation. In Proceedings of the Third Linguistic Annotation Workshop (LAW-III) held in conjunction with ACL-IJCNLP 2009, pages 99–107, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mandel</author>
</authors>
<title>Integrated annotation of biomedical text: Creating the PennBioIE corpus.</title>
<date>2006</date>
<booktitle>In Text Mining Ontologies and Natural Language Processing in Biomedicine,</booktitle>
<location>Manchester, UK,</location>
<contexts>
<context position="10164" citStr="Mandel, 2006" startWordPosition="1511" endWordPosition="1512"> show excerpts of category and feature hierarchies in the Reference Model. With respect to morphosyntactic annotations (parts of speech, pos) and morphological annotations (morph), five Annotation Models for German are currently available: STTS (Schiller et al., 1999, pos), TIGER (Brants and Hansen, 2002, morph), Morphisto (Zielinski and Simon, 2008, pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph), Connexor (Tapanainen and J¨arvinen, 1997, pos, morph). Further Annotation Models for pos and morph cover five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an annotation scheme for Tibetan (Wagner and Zeisler, 2004). 661 or the DCR). As an example, consider the attributive demonstrative pronoun diese in (1). Diese nicht neue Erkenntnis konnte (1) this not new insight could der Markt der M¨oglichkeiten am the market of.the possibilities on.the Son</context>
</contexts>
<marker>Mandel, 2006</marker>
<rawString>M. Mandel. 2006. Integrated annotation of biomedical text: Creating the PennBioIE corpus. In Text Mining Ontologies and Natural Language Processing in Biomedicine, Manchester, UK, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational linguistics,</title>
<date>1994</date>
<contexts>
<context position="10135" citStr="Marcus et al., 1994" startWordPosition="1505" endWordPosition="1508">gruency in past tense. Figs. 2 and 4 show excerpts of category and feature hierarchies in the Reference Model. With respect to morphosyntactic annotations (parts of speech, pos) and morphological annotations (morph), five Annotation Models for German are currently available: STTS (Schiller et al., 1999, pos), TIGER (Brants and Hansen, 2002, morph), Morphisto (Zielinski and Simon, 2008, pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph), Connexor (Tapanainen and J¨arvinen, 1997, pos, morph). Further Annotation Models for pos and morph cover five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an annotation scheme for Tibetan (Wagner and Zeisler, 2004). 661 or the DCR). As an example, consider the attributive demonstrative pronoun diese in (1). Diese nicht neue Erkenntnis konnte (1) this not new insight could der Markt der M¨oglichkeiten am the market of</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>M.P. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1994. Building a large annotated corpus of English: The Penn Treebank. Computational linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Meyer</author>
</authors>
<title>Halbautomatische morphosyntaktische Annotation russischer Texte. In</title>
<date>2003</date>
<booktitle>Linguistische Beitr¨age zur Slavistik aus Deutschland und ¨Osterreich. X. JungslavistInnen-Treffen,</booktitle>
<pages>92--105</pages>
<editor>R. Hammel and L. Geist, editors,</editor>
<publisher>Sagner, M¨unchen.</publisher>
<location>Berlin</location>
<contexts>
<context position="10242" citStr="Meyer, 2003" startWordPosition="1523" endWordPosition="1524"> respect to morphosyntactic annotations (parts of speech, pos) and morphological annotations (morph), five Annotation Models for German are currently available: STTS (Schiller et al., 1999, pos), TIGER (Brants and Hansen, 2002, morph), Morphisto (Zielinski and Simon, 2008, pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph), Connexor (Tapanainen and J¨arvinen, 1997, pos, morph). Further Annotation Models for pos and morph cover five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an annotation scheme for Tibetan (Wagner and Zeisler, 2004). 661 or the DCR). As an example, consider the attributive demonstrative pronoun diese in (1). Diese nicht neue Erkenntnis konnte (1) this not new insight could der Markt der M¨oglichkeiten am the market of.the possibilities on.the Sonnabend in Treuenbrietzen bestens Saturday in Treuenbrietzen in.the.best.way un</context>
</contexts>
<marker>Meyer, 2003</marker>
<rawString>R. Meyer. 2003. Halbautomatische morphosyntaktische Annotation russischer Texte. In R. Hammel and L. Geist, editors, Linguistische Beitr¨age zur Slavistik aus Deutschland und ¨Osterreich. X. JungslavistInnen-Treffen, Berlin 2001, pages 92– 105. Sagner, M¨unchen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (HLT-NAACL</booktitle>
<pages>404--411</pages>
<location>Rochester, NY,</location>
<contexts>
<context position="16803" citStr="Petrov and Klein, 2007" startWordPosition="2442" endWordPosition="2445">rants and Hansen, 2002) whose annotations are used as gold standard. From the annotated document, the plain tokenized text is extracted and analyzed by one or more of the following NLP tools: (i) Morphisto, a morphological analyzer without contextual disambiguation (Zielinski and Simon, 2008), (ii) two part of speech taggers: the TreeTagger (Schmid, 1994) and the Stanford Tagger (Toutanova et al., 2003), (iii) the RFTagger that performs part of speech and morphological analysis (Schmid and Laws, 2008), (iv) two PCFG parsers: the StanfordParser (Klein and Manning, 2003) and the BerkeleyParser (Petrov and Klein, 2007), and (v) the Connexor dependency parser (Tapanainen and J¨arvinen, 1997). These tools annotate parts of speech, and those in (i), (iii) and (v) also provide morphological features. All components ran in parallel threads on the same machine, with the exception of Morphisto that was addressed as a web service. The set of matching Annotation Model individuals for every annotation and the respective set of Reference Model descriptions are determined by means of 663 OLiA description Morphisto Connexor RF Tree Stanford Stanford Berkeley Tagger Tagger Tagger Parser Parser word class type(...) 5.5 7 </context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>S. Petrov and D. Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (HLT-NAACL 2007), pages 404– 411, Rochester, NY, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrova</author>
<author>C Chiarcos</author>
<author>J Ritz</author>
<author>M Solf</author>
<author>A Zeldes</author>
</authors>
<title>Building and using a richly annotated interlinear diachronic corpus: The case of Old High German Tatian. Traitement automatique des langues et langues anciennes,</title>
<date>2009</date>
<pages>50--2</pages>
<contexts>
<context position="10464" citStr="Petrova et al., 2009" startWordPosition="1556" endWordPosition="1559">d Hansen, 2002, morph), Morphisto (Zielinski and Simon, 2008, pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph), Connexor (Tapanainen and J¨arvinen, 1997, pos, morph). Further Annotation Models for pos and morph cover five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an annotation scheme for Tibetan (Wagner and Zeisler, 2004). 661 or the DCR). As an example, consider the attributive demonstrative pronoun diese in (1). Diese nicht neue Erkenntnis konnte (1) this not new insight could der Markt der M¨oglichkeiten am the market of.the possibilities on.the Sonnabend in Treuenbrietzen bestens Saturday in Treuenbrietzen in.the.best.way unterstreichen . underline ‘The ‘Market of Possibilities’, held this Saturday in Treuenbrietzen, provided best evidence for this well-known (lit. ‘not new’) insight.’ (PCC, #4794) Figure 5: The STTS tags PDAT and ART, their </context>
</contexts>
<marker>Petrova, Chiarcos, Ritz, Solf, Zeldes, 2009</marker>
<rawString>S. Petrova, C. Chiarcos, J. Ritz, M. Solf, and A. Zeldes. 2009. Building and using a richly annotated interlinear diachronic corpus: The case of Old High German Tatian. Traitement automatique des langues et langues anciennes, 50(2):47–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Rehm</author>
<author>R Eckart</author>
<author>C Chiarcos</author>
</authors>
<title>An OWLand XQuery-based mechanism for the retrieval of linguistic patterns from XML-corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of Recent Advances in Natural Language Processing (RANLP</booktitle>
<location>Borovets, Bulgaria,</location>
<contexts>
<context position="6371" citStr="Rehm et al., 2007" startWordPosition="940" endWordPosition="943">34). Thus, two in two of them is a DCR Numeral but not a GOLD Numeral. 2The OLiA Reference Model is accessible via http://nachhalt.sfb632.uni-potsdam.de/owl/ olia.owl. Several annotation models, e.g., stts.owl, tiger.owl, connexor.owl, morphisto.owl can be found in the same directory together with the corresponding linking files stts-link.rdf, tiger-link.rdf, connexor-link.rdf and morphisto-link.rdf. to the formal representation and documentation of annotation schemes, and for concept-based annotation queries over to multiple, heterogeneous corpora annotated with different annotation schemes (Rehm et al., 2007; Chiarcos et al., 2008). NLP applications of the OLiA ontologies include a proposal to integrate them with the OntoTag ontologies and to use them for interface specifications between modules in NLP pipeline architectures (Buyko et al., 2008). Further, Hellmann (2010) described the application of the OLiA ontologies within NLP2RDF, an OWL-based blackboard approach to assess the meaning of text from grammatical analyses and subsequent enrichment with ontological knowledge sources. OLiA distinguishes three different classes of ontologies: • The OLIA REFERENCE MODEL specifies the common terminolo</context>
</contexts>
<marker>Rehm, Eckart, Chiarcos, 2007</marker>
<rawString>G. Rehm, R. Eckart, and C. Chiarcos. 2007. An OWLand XQuery-based mechanism for the retrieval of linguistic patterns from XML-corpora. In Proceedings of Recent Advances in Natural Language Processing (RANLP 2007), Borovets, Bulgaria, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Sampson</author>
</authors>
<title>English for the computer: The SUSANNE corpus and analytic scheme.</title>
<date>1995</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="10150" citStr="Sampson, 1995" startWordPosition="1509" endWordPosition="1510">. Figs. 2 and 4 show excerpts of category and feature hierarchies in the Reference Model. With respect to morphosyntactic annotations (parts of speech, pos) and morphological annotations (morph), five Annotation Models for German are currently available: STTS (Schiller et al., 1999, pos), TIGER (Brants and Hansen, 2002, morph), Morphisto (Zielinski and Simon, 2008, pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph), Connexor (Tapanainen and J¨arvinen, 1997, pos, morph). Further Annotation Models for pos and morph cover five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an annotation scheme for Tibetan (Wagner and Zeisler, 2004). 661 or the DCR). As an example, consider the attributive demonstrative pronoun diese in (1). Diese nicht neue Erkenntnis konnte (1) this not new insight could der Markt der M¨oglichkeiten am the market of.the possibilit</context>
</contexts>
<marker>Sampson, 1995</marker>
<rawString>G. Sampson. 1995. English for the computer: The SUSANNE corpus and analytic scheme. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Saulwick</author>
<author>M Windhouwer</author>
<author>A Dimitriadis</author>
<author>R Goedemans</author>
</authors>
<title>Distributed tasking in ontology mediated integration of typological databases for linguistic research.</title>
<date>2005</date>
<booktitle>In Proceedings of the 17th Conference on Advanced Information Systems Engineering (CAiSE’05),</booktitle>
<location>Porto, Portugal,</location>
<contexts>
<context position="3860" citStr="Saulwick et al., 2005" startWordPosition="582" endWordPosition="585">odels (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen, 2003, GOLD), the ISO TC37/SC4 Data Category Registry (Ide and Romary, 2004; Kemps659 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 659–670, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Snijders et al., 2009, DCR), the OntoTag ontology (Aguado de Cea et al., 2002), or the Typological Database System ontology (Saulwick et al., 2005, TDS). Despite their common level of representation, however, these efforts have not yet converged into a unified and generally accepted ontology of linguistic annotation terminology, but rather, different resources are maintained by different communities, so that a considerable amount of disagreement between them and their respective definitions can be observed.1 Such conceptual mismatches and incompatibilities between existing terminological repositories have been the motivation to develop the OLiA architecture (Chiarcos, 2008) that employs a shallow Reference Model to mediate between (onto</context>
</contexts>
<marker>Saulwick, Windhouwer, Dimitriadis, Goedemans, 2005</marker>
<rawString>A. Saulwick, M. Windhouwer, A. Dimitriadis, and R. Goedemans. 2005. Distributed tasking in ontology mediated integration of typological databases for linguistic research. In Proceedings of the 17th Conference on Advanced Information Systems Engineering (CAiSE’05), Porto, Portugal, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Scheffczyk</author>
<author>A Pease</author>
<author>M Ellsworth</author>
</authors>
<title>Linking FrameNet to the suggested upper merged ontology.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fourth International Conference on Formal Ontology in Information Systems (FOIS</booktitle>
<pages>289--300</pages>
<location>Baltimore, Maryland, USA,</location>
<contexts>
<context position="32170" citStr="Scheffczyk et al., 2006" startWordPosition="4836" endWordPosition="4839">ptions can be assessed independently from the credibility of hasGender descriptions even if the original annotation merged both aspects in one single tag (as the RFTagger does, for example, cf. ex. 5). Extension (v) has been addressed in previous research, although mostly with the opposite perspective: Already Cimiano and Reyle (2003) noted that the integration of grammatical and semantic analyses may be used to resolve ambiguity and underspecifications, and this insight has also motivated the ontological representation of linguistic resources such as WordNet (Gangemi et al., 2003), FrameNet (Scheffczyk et al., 2006), the linking of corpora with such ontologies (Hovy et al., 2006), the modelling of entire corpora in OWL/DL (Burchardt et al., 2008), and the extension of existing ontologies with ontological representations of selected linguistic features (Buitelaar et al., 2006; Davis et al., 2008). Aguado de Cea et al. (2004) sketched an architecture for the closer ontology-based integration of grammatical and semantic information using OntoTag and several NLP tools for Spanish. Aguado de Cea et al. (2008) evaluate the benefits of this approach for the Spanish particle se, and conclude for this example tha</context>
</contexts>
<marker>Scheffczyk, Pease, Ellsworth, 2006</marker>
<rawString>J. Scheffczyk, A. Pease, and M. Ellsworth. 2006. Linking FrameNet to the suggested upper merged ontology. In Proceedings of the Fourth International Conference on Formal Ontology in Information Systems (FOIS 2006), pages 289–300, Baltimore, Maryland, USA, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Schiller</author>
<author>S Teufel</author>
<author>C Thielen</author>
<author>C St¨ockert</author>
</authors>
<title>Guidelines f¨ur das Tagging deutscher Textcorpora mit STTS.</title>
<date>1999</date>
<tech>Technical report,</tech>
<institution>University of Stuttgart, University of T¨ubingen.</institution>
<marker>Schiller, Teufel, Thielen, St¨ockert, 1999</marker>
<rawString>A. Schiller, S. Teufel, C. Thielen, and C. St¨ockert. 1999. Guidelines f¨ur das Tagging deutscher Textcorpora mit STTS. Technical report, University of Stuttgart, University of T¨ubingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
<author>F Laws</author>
</authors>
<title>Estimation of conditional probabilities with decision trees and an application to fine-grained pos tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008),</booktitle>
<location>Manchester, UK,</location>
<contexts>
<context position="9949" citStr="Schmid and Laws, 2008" startWordPosition="1477" endWordPosition="1480">assume that a hasGender property applies to nouns, adjectives, pronouns and determiners only. Yet, this is language-specific restriction: Russian finite verbs, for example, show gender congruency in past tense. Figs. 2 and 4 show excerpts of category and feature hierarchies in the Reference Model. With respect to morphosyntactic annotations (parts of speech, pos) and morphological annotations (morph), five Annotation Models for German are currently available: STTS (Schiller et al., 1999, pos), TIGER (Brants and Hansen, 2002, morph), Morphisto (Zielinski and Simon, 2008, pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph), Connexor (Tapanainen and J¨arvinen, 1997, pos, morph). Further Annotation Models for pos and morph cover five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an annotation scheme for Tibetan (Wagner and Zeisler, 2004). 661 or the DCR). A</context>
<context position="15257" citStr="Schmid and Laws, 2008" startWordPosition="2229" endWordPosition="2232">, etc. Similarly, we know that for some i:olia:Nominative it is true that olia:hasCase(i), abbreviated here as olia:hasCase(some olia:Nominative). In this way, the grammatical information conveyed in the original Connexor annotation can be represented in an annotation-independent and tagset-neutral way as shown for the Connexor analysis in (4). (4) rdf:type(olia:PronounOrDeterminer) rdf:type(olia:Pronoun) olia:hasNumber(some olia:Singular) olia:hasGender(some olia:Feminine) rdf:type(olia:DemonstrativePronoun) olia:hasCase(some olia:Nominative) Analogously, the corresponding RFTagger analysis (Schmid and Laws, 2008) given in (5) can be transformed into a description in terms of the OLiA Reference Model such as in (6). (5) PRO.Dem.Attr.-3.Acc.Sg.Fem (RFTagger) (6) rdf:type(olia:PronounOrDeterminer) olia:hasNumber(some olia:Singular) olia:hasGender(some olia:Feminine) olia:hasCase(some olia:Accusative) rdf:type(olia:DemonstrativeDeterminer) rdf:type(olia:Determiner) For every description obtained from these (and further) analyses, an integrated and consistent generalization can be established as described in the following section. 3 Processing linguistic annotations 3.1 Evaluation setup Fig. 6 sketches the</context>
<context position="16686" citStr="Schmid and Laws, 2008" startWordPosition="2425" endWordPosition="2428">.net. Figure 6: Evaluation setup TIGER/NEGRA-style morphosyntactic or morphological annotation (Skut et al., 1998; Brants and Hansen, 2002) whose annotations are used as gold standard. From the annotated document, the plain tokenized text is extracted and analyzed by one or more of the following NLP tools: (i) Morphisto, a morphological analyzer without contextual disambiguation (Zielinski and Simon, 2008), (ii) two part of speech taggers: the TreeTagger (Schmid, 1994) and the Stanford Tagger (Toutanova et al., 2003), (iii) the RFTagger that performs part of speech and morphological analysis (Schmid and Laws, 2008), (iv) two PCFG parsers: the StanfordParser (Klein and Manning, 2003) and the BerkeleyParser (Petrov and Klein, 2007), and (v) the Connexor dependency parser (Tapanainen and J¨arvinen, 1997). These tools annotate parts of speech, and those in (i), (iii) and (v) also provide morphological features. All components ran in parallel threads on the same machine, with the exception of Morphisto that was addressed as a web service. The set of matching Annotation Model individuals for every annotation and the respective set of Reference Model descriptions are determined by means of 663 OLiA description</context>
</contexts>
<marker>Schmid, Laws, 2008</marker>
<rawString>H. Schmid and F. Laws. 2008. Estimation of conditional probabilities with decision trees and an application to fine-grained pos tagging. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008), Manchester, UK, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="16537" citStr="Schmid, 1994" startWordPosition="2404" endWordPosition="2405"> The input to the system is a set of documents with 5The code used for the evaluation setup is available under http://multiparse.sourceforge.net. Figure 6: Evaluation setup TIGER/NEGRA-style morphosyntactic or morphological annotation (Skut et al., 1998; Brants and Hansen, 2002) whose annotations are used as gold standard. From the annotated document, the plain tokenized text is extracted and analyzed by one or more of the following NLP tools: (i) Morphisto, a morphological analyzer without contextual disambiguation (Zielinski and Simon, 2008), (ii) two part of speech taggers: the TreeTagger (Schmid, 1994) and the Stanford Tagger (Toutanova et al., 2003), (iii) the RFTagger that performs part of speech and morphological analysis (Schmid and Laws, 2008), (iv) two PCFG parsers: the StanfordParser (Klein and Manning, 2003) and the BerkeleyParser (Petrov and Klein, 2007), and (v) the Connexor dependency parser (Tapanainen and J¨arvinen, 1997). These tools annotate parts of speech, and those in (i), (iii) and (v) also provide morphological features. All components ran in parallel threads on the same machine, with the exception of Morphisto that was addressed as a web service. The set of matching Ann</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>H. Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of International Conference on New Methods in Language Processing, pages 44–49, Manchester, UK, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Schmidt</author>
<author>C Chiarcos</author>
<author>T Lehmberg</author>
<author>G Rehm</author>
<author>A Witt</author>
<author>E Hinrichs</author>
</authors>
<title>Avoiding data graveyards: From heterogeneous data collected in multiple research projects to sustainable linguistic resources.</title>
<date>2006</date>
<booktitle>In Proceedings of the E-MELD workshop on Digital Language Documentation: Tools and Standards: The State of the Art,</booktitle>
<location>East Lansing, Michigan, US,</location>
<contexts>
<context position="5425" citStr="Schmidt et al., 2006" startWordPosition="817" endWordPosition="820">ribed below entail similar results for an application of GOLD or the DCR to the same task. 2.1 The OLiA ontologies The Ontologies of Linguistic Annotations – briefly, OLiA ontologies (Chiarcos, 2008) – represent an architecture of modular OWL/DL ontologies that formalize several intermediate steps of the mapping between concrete annotations, a Reference Model and existing terminology repositories (‘External Reference Models’ in OLiA terminology) such as the DCR.2 The OLiA ontologies were originally developed as part of an infrastructure for the sustainable maintenance of linguistic resources (Schmidt et al., 2006) where they were originally applied 1As one example, a GOLD Numeral is a Determiner (Numeral C_ Quantifier C_ Determiner, http://linguistics-ontology.org/gold/2008/ Numeral), whereas a DCR Numeral is defined on the basis of its semantic function, without any references to syntactic categories (http://www.isocat.org/datcat/DC-1334). Thus, two in two of them is a DCR Numeral but not a GOLD Numeral. 2The OLiA Reference Model is accessible via http://nachhalt.sfb632.uni-potsdam.de/owl/ olia.owl. Several annotation models, e.g., stts.owl, tiger.owl, connexor.owl, morphisto.owl can be found in the s</context>
</contexts>
<marker>Schmidt, Chiarcos, Lehmberg, Rehm, Witt, Hinrichs, 2006</marker>
<rawString>T. Schmidt, C. Chiarcos, T. Lehmberg, G. Rehm, A. Witt, and E. Hinrichs. 2006. Avoiding data graveyards: From heterogeneous data collected in multiple research projects to sustainable linguistic resources. In Proceedings of the E-MELD workshop on Digital Language Documentation: Tools and Standards: The State of the Art, East Lansing, Michigan, US, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sharoff</author>
<author>M Kopotev</author>
<author>T Erjavec</author>
<author>A Feldman</author>
<author>D Divjak</author>
</authors>
<title>Designing and evaluating Russian tagsets.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC 2008),</booktitle>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="10265" citStr="Sharoff et al., 2008" startWordPosition="1525" endWordPosition="1528">orphosyntactic annotations (parts of speech, pos) and morphological annotations (morph), five Annotation Models for German are currently available: STTS (Schiller et al., 1999, pos), TIGER (Brants and Hansen, 2002, morph), Morphisto (Zielinski and Simon, 2008, pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph), Connexor (Tapanainen and J¨arvinen, 1997, pos, morph). Further Annotation Models for pos and morph cover five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an annotation scheme for Tibetan (Wagner and Zeisler, 2004). 661 or the DCR). As an example, consider the attributive demonstrative pronoun diese in (1). Diese nicht neue Erkenntnis konnte (1) this not new insight could der Markt der M¨oglichkeiten am the market of.the possibilities on.the Sonnabend in Treuenbrietzen bestens Saturday in Treuenbrietzen in.the.best.way unterstreichen . underlin</context>
</contexts>
<marker>Sharoff, Kopotev, Erjavec, Feldman, Divjak, 2008</marker>
<rawString>S. Sharoff, M. Kopotev, T. Erjavec, A. Feldman, and D. Divjak. 2008. Designing and evaluating Russian tagsets. In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC 2008), Marrakech, Morocco, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sirin</author>
<author>B Parsia</author>
<author>B C Grau</author>
<author>A Kalyanpur</author>
<author>Y Katz</author>
</authors>
<title>Pellet: A practical OWL/DL reasoner. Web Semantics: Science, Services and Agents on the World Wide Web,</title>
<date>2007</date>
<pages>5--2</pages>
<contexts>
<context position="18183" citStr="Sirin et al., 2007" startWordPosition="2670" endWordPosition="2673">un 0.5** 0.5** 0.5** 0.5** morphology hasXY(...) 2.5 0.5 (2/4) 1 1 n/a n/a n/a n/a hasNumber(some Singular) 2.5 0.5 (2/4) 1 1 hasGender(some Feminine) 1.5 0.5 (2/4) 0 1 hasCase(some Accusative) 1.5 0.5 (2/4) 1 0 hasCase(some Nominative) 0.5 0.5 (2/4) 0 0 hasNumber(some Plural) * Morphisto produces four alternative candidate analyses for this example, so every alternative analysis receives the confidence score 0.25 ** Morphisto does not distinguish attributive and substitutive pronouns, it predicts type(Determiner LJ Pronoun) Table 1: Confidence scores for diese in ex. (1) the Pellet reasoner (Sirin et al., 2007) as described above. A disambiguation routine (see below) then determines the maximal consistent set of ontological descriptions. Finally, the outcome of this process is compared to the set of descriptions corresponding to the original annotation in the corpus. 3.2 Disambiguation Returning to examples (4) and (6) above, we see that the resulting set of descriptions conveys properties that are obviously contradicting, e.g., hasCase(some Nominative) besides hasCase(some Accusative). Our approach to disambiguation combines ontological consistency criteria with a confidence ranking. As we simulate</context>
</contexts>
<marker>Sirin, Parsia, Grau, Kalyanpur, Katz, 2007</marker>
<rawString>E. Sirin, B. Parsia, B.C. Grau, A. Kalyanpur, and Y. Katz. 2007. Pellet: A practical OWL/DL reasoner. Web Semantics: Science, Services and Agents on the World Wide Web, 5(2):51–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Skut</author>
<author>T Brants</author>
<author>B Krenn</author>
<author>H Uszkoreit</author>
</authors>
<title>A linguistically interpreted corpus of German newspaper text. In</title>
<date>1998</date>
<booktitle>In Proceedings of the ESSLLI Workshop on Recent Advances in Corpus Annotation,</booktitle>
<location>Saarbr¨ucken, Germany,</location>
<contexts>
<context position="2894" citStr="Skut et al., 1998" startWordPosition="438" endWordPosition="441">00; Tufis¸, 2000; Borin, 2000). An even more substantial increase in accuracy and detail can be expected if tools are combined that make use of different annotation schemes. For this task, ontologies of linguistic annotations are employed to assess the linguistic information conveyed in a particular annotation and to integrate the resulting ontological descriptions in a consistent and tool-independent way. The merged set of ontological descriptions is then evaluated with reference to morphosyntactic and morphological annotations of three corpora of German newspaper articles, the NEGRA corpus (Skut et al., 1998), the TIGER corpus (Brants et al., 2002) and the Potsdam Commentary Corpus (Stede, 2004, PCC). 2 Ontologies and annotations Various repositories of linguistic annotation terminology have been developed in the last decades, ranging from early texts on annotation standards (Bakker et al., 1993; Leech and Wilson, 1996) over relational data base models (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen, 2003, GOLD), the ISO TC37/SC4 Data Category Registry</context>
<context position="16177" citStr="Skut et al., 1998" startWordPosition="2345" endWordPosition="2348">a:DemonstrativeDeterminer) rdf:type(olia:Determiner) For every description obtained from these (and further) analyses, an integrated and consistent generalization can be established as described in the following section. 3 Processing linguistic annotations 3.1 Evaluation setup Fig. 6 sketches the architecture of the evaluation environment set up for this study.5 The input to the system is a set of documents with 5The code used for the evaluation setup is available under http://multiparse.sourceforge.net. Figure 6: Evaluation setup TIGER/NEGRA-style morphosyntactic or morphological annotation (Skut et al., 1998; Brants and Hansen, 2002) whose annotations are used as gold standard. From the annotated document, the plain tokenized text is extracted and analyzed by one or more of the following NLP tools: (i) Morphisto, a morphological analyzer without contextual disambiguation (Zielinski and Simon, 2008), (ii) two part of speech taggers: the TreeTagger (Schmid, 1994) and the Stanford Tagger (Toutanova et al., 2003), (iii) the RFTagger that performs part of speech and morphological analysis (Schmid and Laws, 2008), (iv) two PCFG parsers: the StanfordParser (Klein and Manning, 2003) and the BerkeleyParse</context>
<context position="22066" citStr="Skut et al., 1998" startWordPosition="3299" endWordPosition="3302"> (.003) .963 (.007) .965 (.007) all tools .791 .770 all tools .967 .960 .965 * The Stanford Tagger was trained on the NEGRA corpus. Table 3: Recall for morphological Table 2: Recall for rdf:type descriptions for word classes hasXY() descriptions The resulting, maximal consistent set of descriptions is then compared with the ontological descriptions that correspond to the original annotation in the corpus. 4 Evaluation Six experiments were conducted with the goal to evaluate the prediction of word classes and morphological features on parts of three corpora of German newspaper articles: NEGRA (Skut et al., 1998), TIGER (Brants et al., 2002), and the Potsdam Commentary Corpus (Stede, 2004, PCC). From every corpus 10,000 tokens were considered for the analysis. TIGER and NEGRA are well-known resources that also influenced the design of several of the tools considered. For this reason, the PCC was consulted, a small collection of newspaper commentaries, 30,000 tokens in total, annotated with TIGER-style parts of speech and syntax (by members of the TIGER project). None of the tools considered here were trained on this data, so that it provides independent test data. The ontological descriptions were eva</context>
</contexts>
<marker>Skut, Brants, Krenn, Uszkoreit, 1998</marker>
<rawString>W. Skut, T. Brants, B. Krenn, and H. Uszkoreit. 1998. A linguistically interpreted corpus of German newspaper text. In In Proceedings of the ESSLLI Workshop on Recent Advances in Corpus Annotation, Saarbr¨ucken, Germany, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stede</author>
</authors>
<title>The Potsdam Commentary Corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 ACL Workshop on Discourse Annotation,</booktitle>
<pages>96--102</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="2981" citStr="Stede, 2004" startWordPosition="454" endWordPosition="455">e expected if tools are combined that make use of different annotation schemes. For this task, ontologies of linguistic annotations are employed to assess the linguistic information conveyed in a particular annotation and to integrate the resulting ontological descriptions in a consistent and tool-independent way. The merged set of ontological descriptions is then evaluated with reference to morphosyntactic and morphological annotations of three corpora of German newspaper articles, the NEGRA corpus (Skut et al., 1998), the TIGER corpus (Brants et al., 2002) and the Potsdam Commentary Corpus (Stede, 2004, PCC). 2 Ontologies and annotations Various repositories of linguistic annotation terminology have been developed in the last decades, ranging from early texts on annotation standards (Bakker et al., 1993; Leech and Wilson, 1996) over relational data base models (Bickel and Nichols, 2000; Bickel and Nichols, 2002) to more recent formalizations in OWL/RDF (or with OWL/RDF export), e.g., the General Ontology of Linguistic Description (Farrar and Langendoen, 2003, GOLD), the ISO TC37/SC4 Data Category Registry (Ide and Romary, 2004; Kemps659 Proceedings of the 48th Annual Meeting of the Associat</context>
<context position="22143" citStr="Stede, 2004" startWordPosition="3314" endWordPosition="3315">tanford Tagger was trained on the NEGRA corpus. Table 3: Recall for morphological Table 2: Recall for rdf:type descriptions for word classes hasXY() descriptions The resulting, maximal consistent set of descriptions is then compared with the ontological descriptions that correspond to the original annotation in the corpus. 4 Evaluation Six experiments were conducted with the goal to evaluate the prediction of word classes and morphological features on parts of three corpora of German newspaper articles: NEGRA (Skut et al., 1998), TIGER (Brants et al., 2002), and the Potsdam Commentary Corpus (Stede, 2004, PCC). From every corpus 10,000 tokens were considered for the analysis. TIGER and NEGRA are well-known resources that also influenced the design of several of the tools considered. For this reason, the PCC was consulted, a small collection of newspaper commentaries, 30,000 tokens in total, annotated with TIGER-style parts of speech and syntax (by members of the TIGER project). None of the tools considered here were trained on this data, so that it provides independent test data. The ontological descriptions were evaluated for recall:7 �� i�1 |Dpredicted(ti)nDtarget(ti)| (7) recall(T) = E 1 |</context>
</contexts>
<marker>Stede, 2004</marker>
<rawString>M. Stede. 2004. The Potsdam Commentary Corpus. In Proceedings of the 2004 ACL Workshop on Discourse Annotation, pages 96–102, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tapanainen</author>
<author>T J¨arvinen</author>
</authors>
<title>A nonprojective dependency parser.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th Conference on Applied Natural Language Processing,</booktitle>
<pages>64--71</pages>
<location>Washington, DC,</location>
<marker>Tapanainen, J¨arvinen, 1997</marker>
<rawString>P. Tapanainen and T. J¨arvinen. 1997. A nonprojective dependency parser. In Proceedings of the 5th Conference on Applied Natural Language Processing, pages 64–71, Washington, DC, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>D Klein</author>
<author>C D Manning</author>
<author>Y Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (HLT-NAACL</booktitle>
<location>Edmonton, Canada,</location>
<contexts>
<context position="16586" citStr="Toutanova et al., 2003" startWordPosition="2410" endWordPosition="2413">cuments with 5The code used for the evaluation setup is available under http://multiparse.sourceforge.net. Figure 6: Evaluation setup TIGER/NEGRA-style morphosyntactic or morphological annotation (Skut et al., 1998; Brants and Hansen, 2002) whose annotations are used as gold standard. From the annotated document, the plain tokenized text is extracted and analyzed by one or more of the following NLP tools: (i) Morphisto, a morphological analyzer without contextual disambiguation (Zielinski and Simon, 2008), (ii) two part of speech taggers: the TreeTagger (Schmid, 1994) and the Stanford Tagger (Toutanova et al., 2003), (iii) the RFTagger that performs part of speech and morphological analysis (Schmid and Laws, 2008), (iv) two PCFG parsers: the StanfordParser (Klein and Manning, 2003) and the BerkeleyParser (Petrov and Klein, 2007), and (v) the Connexor dependency parser (Tapanainen and J¨arvinen, 1997). These tools annotate parts of speech, and those in (i), (iii) and (v) also provide morphological features. All components ran in parallel threads on the same machine, with the exception of Morphisto that was addressed as a web service. The set of matching Annotation Model individuals for every annotation an</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>K. Toutanova, D. Klein, C.D. Manning, and Y. Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (HLT-NAACL 2003), Edmonton, Canada, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tufis¸</author>
</authors>
<title>Using a large set of EAGLEScompliant morpho-syntactic descriptors as a tagset for probabilistic tagging.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1105--1112</pages>
<location>Athens, Greece,</location>
<marker>Tufis¸, 2000</marker>
<rawString>D. Tufis¸. 2000. Using a large set of EAGLEScompliant morpho-syntactic descriptors as a tagset for probabilistic tagging. In Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC 2000), pages 1105–1112, Athens, Greece, May, 31st – June, 2nd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Wagner</author>
<author>B Zeisler</author>
</authors>
<title>A syntactically annotated corpus of Tibetan.</title>
<date>2004</date>
<booktitle>In Fourth International Conference on Language Resources and Evaluation (LREC 2004),</booktitle>
<location>Lisboa, Portugal,</location>
<contexts>
<context position="10529" citStr="Wagner and Zeisler, 2004" startWordPosition="1567" endWordPosition="1570"> pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph), Connexor (Tapanainen and J¨arvinen, 1997, pos, morph). Further Annotation Models for pos and morph cover five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an annotation scheme for Tibetan (Wagner and Zeisler, 2004). 661 or the DCR). As an example, consider the attributive demonstrative pronoun diese in (1). Diese nicht neue Erkenntnis konnte (1) this not new insight could der Markt der M¨oglichkeiten am the market of.the possibilities on.the Sonnabend in Treuenbrietzen bestens Saturday in Treuenbrietzen in.the.best.way unterstreichen . underline ‘The ‘Market of Possibilities’, held this Saturday in Treuenbrietzen, provided best evidence for this well-known (lit. ‘not new’) insight.’ (PCC, #4794) Figure 5: The STTS tags PDAT and ART, their representation in the Annotation Model and linking with the Refer</context>
</contexts>
<marker>Wagner, Zeisler, 2004</marker>
<rawString>A. Wagner and B. Zeisler. 2004. A syntactically annotated corpus of Tibetan. In Fourth International Conference on Language Resources and Evaluation (LREC 2004), Lisboa, Portugal, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zavrel</author>
<author>W Daelemans</author>
</authors>
<title>Bootstrapping a tagged corpus through combination of existing heterogeneous taggers.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC 2000),</booktitle>
<location>Athens, Greece,</location>
<contexts>
<context position="2278" citStr="Zavrel and Daelemans, 2000" startWordPosition="344" endWordPosition="347">its of such an approach with respect to morphosyntax (parts of speech, pos) and morphology in German: In comparison to English, German shows a rich and polysemous morphology, and a considerable number of NLP tools are available, making it a promising candidate for such an experiment. Previous research indicates that the integration of multiple part of speech taggers leads to more accurate analyses. So far, however, this line of research focused on tools that were trained on the same corpus (Brill and Wu, 1998; Halteren et al., 2001), or that specialize to different subsets of the same tagset (Zavrel and Daelemans, 2000; Tufis¸, 2000; Borin, 2000). An even more substantial increase in accuracy and detail can be expected if tools are combined that make use of different annotation schemes. For this task, ontologies of linguistic annotations are employed to assess the linguistic information conveyed in a particular annotation and to integrate the resulting ontological descriptions in a consistent and tool-independent way. The merged set of ontological descriptions is then evaluated with reference to morphosyntactic and morphological annotations of three corpora of German newspaper articles, the NEGRA corpus (Sk</context>
<context position="28121" citStr="Zavrel and Daelemans (2000)" startWordPosition="4229" endWordPosition="4232">ifferences in the coverage of the linguistic context). It can thus be stated that the integration of multiple alternative analyses has the potential to produce linguistic analyses that are both more robust and more detailed than those of the original tools. The primary field of application of this approach is most likely to be seen in a context where applications are designed that make direct use of OWL/RDF representations as described, for example, by Hellmann (2010). It is, however, also possible to use ontological representations to bootstrap novel and more detailed annotation schemes, cf. Zavrel and Daelemans (2000). Further, the conversion from string-based representations to ontological descriptions is reversible, so that results of ontology-based disambiguation and validation can also be reintegrated with the original annotation scheme. The idea of such a reversion algorithm was sketched by Buyko et al. (2008) where the OLiA ontologies were suggested as a means to translate between different annotation schemes.9 6 Extensions and Related Research Natural extensions of the approach described in this paper include: (i) Experiments with formally defined consistency conditions (e.g., with respect to restri</context>
</contexts>
<marker>Zavrel, Daelemans, 2000</marker>
<rawString>J. Zavrel and W. Daelemans. 2000. Bootstrapping a tagged corpus through combination of existing heterogeneous taggers. In Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC 2000), Athens, Greece, May, 31st – June, 2nd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Zielinski</author>
<author>C Simon</author>
</authors>
<title>Morphisto: An open-source morphological analyzer for German.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Finite State Methods in Natural Language Processing (FSMNLP),</booktitle>
<location>Ispra, Italy,</location>
<contexts>
<context position="9903" citStr="Zielinski and Simon, 2008" startWordPosition="1470" endWordPosition="1473">estern European languages, for example, one might assume that a hasGender property applies to nouns, adjectives, pronouns and determiners only. Yet, this is language-specific restriction: Russian finite verbs, for example, show gender congruency in past tense. Figs. 2 and 4 show excerpts of category and feature hierarchies in the Reference Model. With respect to morphosyntactic annotations (parts of speech, pos) and morphological annotations (morph), five Annotation Models for German are currently available: STTS (Schiller et al., 1999, pos), TIGER (Brants and Hansen, 2002, morph), Morphisto (Zielinski and Simon, 2008, pos, morph), RFTagger (Schmid and Laws, 2008, pos, morph), Connexor (Tapanainen and J¨arvinen, 1997, pos, morph). Further Annotation Models for pos and morph cover five different annotation schemes for English (Marcus et al., 1994; Sampson, 1995; Mandel, 2006; Kim et al., 2003, Connexor), two annotation schemes for Russian (Meyer, 2003; Sharoff et al., 2008), an annotation scheme designed for typological research and currently applied to approx. 30 different languages (Dipper et al., 2007), an annotation scheme for Old High German (Petrova et al., 2009), and an annotation scheme for Tibetan </context>
<context position="16473" citStr="Zielinski and Simon, 2008" startWordPosition="2390" endWordPosition="2394">etches the architecture of the evaluation environment set up for this study.5 The input to the system is a set of documents with 5The code used for the evaluation setup is available under http://multiparse.sourceforge.net. Figure 6: Evaluation setup TIGER/NEGRA-style morphosyntactic or morphological annotation (Skut et al., 1998; Brants and Hansen, 2002) whose annotations are used as gold standard. From the annotated document, the plain tokenized text is extracted and analyzed by one or more of the following NLP tools: (i) Morphisto, a morphological analyzer without contextual disambiguation (Zielinski and Simon, 2008), (ii) two part of speech taggers: the TreeTagger (Schmid, 1994) and the Stanford Tagger (Toutanova et al., 2003), (iii) the RFTagger that performs part of speech and morphological analysis (Schmid and Laws, 2008), (iv) two PCFG parsers: the StanfordParser (Klein and Manning, 2003) and the BerkeleyParser (Petrov and Klein, 2007), and (v) the Connexor dependency parser (Tapanainen and J¨arvinen, 1997). These tools annotate parts of speech, and those in (i), (iii) and (v) also provide morphological features. All components ran in parallel threads on the same machine, with the exception of Morphi</context>
</contexts>
<marker>Zielinski, Simon, 2008</marker>
<rawString>A. Zielinski and C. Simon. 2008. Morphisto: An open-source morphological analyzer for German. In Proceedings of the Conference on Finite State Methods in Natural Language Processing (FSMNLP), Ispra, Italy, September.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>