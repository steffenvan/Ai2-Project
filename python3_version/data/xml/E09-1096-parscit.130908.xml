<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000068">
<title confidence="0.9950675">
Feature-based Method for Document Alignment in
Comparable News Corpora
</title>
<author confidence="0.991568">
Thuy Vu, Ai Ti Aw, Min Zhang
</author>
<affiliation confidence="0.8311095">
Department of Human Language Technology, Institute for Infocomm Research
1 Fusionopolis Way, #21-01 Connexis, South Tower, Singapore 138632
</affiliation>
<email confidence="0.994876">
{tvu, aaiti, mzhang}@i2r.a-star.edu.sg
</email>
<sectionHeader confidence="0.993878" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998323363636364">
In this paper, we present a feature-based me-
thod to align documents with similar content
across two sets of bilingual comparable cor-
pora from daily news texts. We evaluate the
contribution of each individual feature and
investigate the incorporation of these diverse
statistical and heuristic features for the task of
bilingual document alignment. Experimental
results on the English-Chinese and English-
Malay comparable news corpora show that
our proposed Discrete Fourier Transform-
based term frequency distribution feature is
very effective. It contributes 4.1% and 8% to
performance improvement over Pearson’s
correlation method on the two comparable
corpora. In addition, when more heuristic and
statistical features as well as a bilingual dic-
tionary are utilized, our method shows an ab-
solute performance improvement of 23.2%
and 15.3% on the two sets of bilingual corpo-
ra when comparing with a prior information
retrieval-based method.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999936440677966">
The problem of document alignment is described
as the task of aligning documents, news articles
for instance, across two corpora based on content
similarity. The groups of corpora can be in the
same or in different languages, depending on the
purpose of one’s task. In our study, we attempt to
align similar documents across comparable cor-
pora which are bilingual, each set written in a
different language but having similar content and
domain coverage for different communication
needs.
Previous works on monolingual document
alignment focus on automatic alignment between
documents and their presentation slides or be-
tween documents and their abstracts. Kan (2007)
uses two similarity measures, Cosine and Jac-
card, to calculate the candidate alignment score
in his SlideSeer system, a digital library software
that retrieves documents and their narrated slide
presentations. Daumé and Marcu (2004) use a
phrase-based HMM model to mine the alignment
between documents and their human-written ab-
stracts. The main purpose of this work is to in-
crease the size of the training corpus for a
statistical-based summarization system.
The research on similarity calculation for mul-
tilingual comparable corpora has attracted more
attention than monolingual comparable corpora.
However, the purpose and scenario of these
works are rather varied. Steinberger et al. (2002)
represent document contents using descriptor
terms of a multilingual thesaurus EUROVOC1,
and calculate the semantic similarity based on the
distance between the two documents’ representa-
tions. The assignment of descriptors is trained by
log-likelihood test and computed by TFIDF, Co-
sine, and Okapi. Similarly, Pouliquen et al.
(2004) use a linear combination of three types of
knowledge: cognates, geographical place names
reference, and map documents based on the
EUROVOC. The major limitation of these works
is the use of EUROVOC, which is a specific re-
source workable only for European languages.
Aligning documents across parallel corpora is
another area of interest. Patry and Langlais (2005)
use three similarity scores, Cosine, Normalized
Edit Distance, and Sentence Alignment Score, to
compute the similarity between two parallel doc-
uments. An Adaboost classifier is trained on a list
of scored text pairs labeled as parallel or non-
parallel. Then, the learned classifier is used to
check the correctness of each alignment candidate.
Their method is simple but effective. However,
the features used in this method are only suitable
for parallel corpora as the measurement is mainly
based on structural similarity. One goal of docu-
ment alignment is for parallel sentence extraction
for applications like statistical machine transla-
tion. Cheung and Fung (2004) highlight that most
</bodyText>
<footnote confidence="0.9812895">
1 EUROVOC is a multilingual thesaurus covering the fields
in which the European Communities are active.
</footnote>
<note confidence="0.961819">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 843–851,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.998845">
843
</page>
<bodyText confidence="0.997078363636364">
of the current sentence alignment models are ap-
plicable for parallel documents, rather than com-
parable documents. In addition, they argue that
document alignment should be done before paral-
lel sentence extraction.
Tao and Zhai (2005) propose a general method
to extract comparable bilingual text without us-
ing any linguistic resources. The main feature of
this method is the frequency correlation of words
in different languages. They assume that those
words in different languages should have similar
frequency correlation if they are actually transla-
tions of each other. The association between two
documents is then calculated based on this in-
formation using Pearson’s correlation together
with two monolingual features BM25 , a term
frequency normalization (Stephan et al., 1994),
and IDF. The main advantages of this approach
are that it is purely statistical-based and it is lan-
guage-independent. However, its performance
may be compromised due to the lack of linguistic
knowledge, particularly across corpora which are
linguistically very different. Recently, Munteanu
(2006) introduces a rather simple way to get the
group of similar content document in multilin-
gual comparable corpus by using the Lemur IR
Toolkit (Ogilvie and Callan, 2001). This method
first pushes all the target documents into the da-
tabase of the Lemur, and then uses a word-by-
word translation of each source document as a
query to retrieve similar content target docu-
ments.
This paper will leverage on previous work,
and propose and explore diverse range of fea-
tures in our system. Our document alignment
system consists of three stages: candidate genera-
tion, feature extraction and feature combination.
We verify our method on two set of bilingual
news comparable corpora English-Chinese and
English-Malay. Experimental results show that
1) when only using Fourier Transform-based
term frequency, our method outperforms our re-
implementation of Tao (2005)’s method by 4.1%
and 8% for the top 100 alignment candidates and,
2) when using all features, our method signifi-
cantly outperforms our implementation of Mun-
teanu’s (2006) method by 23.2% and 15.3%.
The paper is organized as follows. In section
2, we describe the overall architecture of our sys-
tem. Section 3 discusses our improved frequency
correlation-based feature, while Section 4 de-
scribes in detail the document relationship heu-
ristics used in our model. Section 5 reports the
experimental results. Finally, we conclude our
work in section 6.
</bodyText>
<sectionHeader confidence="0.902264" genericHeader="method">
2 System Architecture
</sectionHeader>
<bodyText confidence="0.999610285714286">
Fig 1 shows the general architecture of our doc-
ument alignment system. It consists of three
components: candidate generation, feature ex-
traction, and feature combination. Our system
works on two sets of monolingual corpora to de-
rive a set of document alignments that are com-
parable in their content.
</bodyText>
<subsectionHeader confidence="0.7001245">
Fig 1. Architecture for Document Alignment Model.
2.1 Candidate Generation
</subsectionHeader>
<bodyText confidence="0.999885620689655">
Like many other text processing systems, the
system first defines two filtering criteria to prune
out “clearly bad” candidates. This will dramati-
cally reduce the search space. We implement the
following filers for this purpose:
Date-Window Filter: As mentioned earlier,
the data used for the present work are news cor-
pora—a text genre that has very strong links with
the time element. The published date of docu-
ment is available in data, and can easily be used
as an indicator to evaluate the relation between
two articles in terms of time. Similar to Muntea-
nu’s (2006), we aim to constrain the number of
candidates by assuming that documents with
similar content should have publication dates
which are fairly close to each other, even though
they reside in two different sets of corpora. By
imposing this constraint, both the complexity and
the cost in computation can be reduced tremend-
ously as the number of candidates would be sig-
nificantly reduced. For example, when a 1-day
window size is set, this means that for a given
source document, the search for its target candi-
dates is set within 3 days of the source document:
the same day of publication, the day after, and
the day before. With this filter, using the data of
one-month in our experiment, a reduction of 90%
of all possible alignments can be achieved (sec-
tion 5.1). Moreover, with our evaluation data,
</bodyText>
<page confidence="0.996431">
844
</page>
<bodyText confidence="0.99994656">
after filtering out document pairs using a 1-day
window size, up to 81.6% for English-Chinese
and 80.3% for English-Malay of the golden
alignments are covered. If the window size is
increased to 5, the coverage is 96.6% and 95.6%
for two language pairs respectively.
Title-n-Content Filter: previous date window
filter constrains the number of candidates based
purely on temporal information without exploit-
ing any knowledge of the documents’ contents.
The number of candidates to be generated is thus
dependent on the number of published articles
per day, instead of the candidates’ potential con-
tent similarity. For this reason, we introduce
another filter which makes use of document titles
to gauge content-wise cross document similarity.
As document titles are available in news data, we
capitalize on words found in these document
titles, favoring alignment candidates where at
least one of the title-words in the source docu-
ment has its translation found in the content of
the other target document. This filter can reduce
a further 47.9% (English-Chinese) and 26.3%
(English-Malay) of the remaining alignment can-
didates after applying the date-window filter.
</bodyText>
<subsectionHeader confidence="0.998917">
2.2 Feature Extraction
</subsectionHeader>
<bodyText confidence="0.999992125">
The second step extracts all the features for each
candidate and computes the score for each indi-
vidual feature function. In our model, the feature
set is composed of the Title-n-Content score
(ܶܰܥ), Linguistic-Independent-Unit score (ܮܫܷ),
and Monolingual Term Distribution similarity
(ܯܶܦ). We will discuss all three features in sec-
tions 3 and 4.
</bodyText>
<subsectionHeader confidence="0.998028">
2.3 Feature Combination
</subsectionHeader>
<bodyText confidence="0.99998835">
The final score for each alignment candidate is
computed by combining all the feature function
scores into a unique score. In literature, there are
many methods concerning the estimation of the
overall score for a given feature set, which vary
from supervised to unsupervised method. Super-
vised methods such as Support Vector Machine
(SVM) and Maximum Entropy (ME) estimate
the weight of each feature based on training data
which are then used to calculate the final score.
However, these supervised learning-based me-
thods may not be applicable to our proposed is-
sue as we are motivated to build a language
independent unsupervised system. We simply
take a product of all normalized features to ob-
tain one unique score. This is because our fea-
tures are probabilistically independent. In our
implementation, we normalize the scores to make
them less sensitive to the absolute value by tak-
ing the logarithm ݈݊ሺ. ሻ as follows:
</bodyText>
<equation confidence="0.9903835">
݊݋ݎ݉ሺݔሻ ൌ ൜݈݊ሺݔ ൅ ܶሻ, ݔ ൐ ሺ݁ െ ܶሻ (1)
1, ݈݁ݏ݁
</equation>
<bodyText confidence="0.981675">
ሺ݁ െ ܶሻ is a threshold for ݔ to contribute posi-
tively to the unique score. In our experiment, we
empirically choose ܶ be 2.2, and the threshold
for ݔ is 0.51828 (as ݁ ൎ 2.71828).
</bodyText>
<sectionHeader confidence="0.964708" genericHeader="method">
3 Monolingual Term Distribution
</sectionHeader>
<subsectionHeader confidence="0.952219">
3.1 Baseline Model
</subsectionHeader>
<bodyText confidence="0.999812230769231">
The main feature used in Tao and Zhai (2005) is
the frequency distribution similarity or frequency
correlation of words in two given corpora. It is
assumed that frequency distributions of topically-
related words in multilingual comparable corpora
are often correlated due to the correlated cover-
age of the same events.
Let ܠ ൌ ሼݔଵ, ݔଶ, ... , ݔ௡ሽ and ܡ ൌ ሼݕଵ, ݕଶ, ... , ݕ௡ሽ
be the frequency distribution vectors of two
words ݔ and ݕ in two documents respectively.
The frequency correlation of the two words is
computed by Pearson’s Correlation Coefficient
in (2).
</bodyText>
<equation confidence="0.994766833333333">
೙ ೙
∑ ௫೔௬೔ ି∑ ௫೔
೙ ೔సభ ∑ ௬೔
೔సభ ೔సభ
ݎሺݔ, ݕሻ ൌ ೔సభ ൯మቁ (2)
ටቀ∑ ௫೔
೙ మ
೔సభ ିభ ೙൫∑ ௫೔
೙ ೔సభ ൯మቁቀ∑ ௬೔
೙ మ
೔సభ ିభ ೙൫∑ ௬೔
೙
</equation>
<bodyText confidence="0.99992325">
The similarity of two documents is calculated
with the addition of two features namely Inverse
Document Frequency (ܫܦܨ) and ܤܯ25 term fre-
quency normalization shown in the equation (3).
</bodyText>
<equation confidence="0.9804745">
ݏሺ݀ଵ, ݀ଶሻ ൌ ∑௫אௗభ,௬אௗమ ܫܦܨሺݔሻ · ܫܦܨሺݕሻ · ݎሺݔ, ݕሻ · (3)
ܤܯ25ሺݔ, ݀ଵሻ · ܤܯ25ሺݕ, ݀ଶሻ
</equation>
<bodyText confidence="0.998479">
Where ܤܯ25ሺݓ,݀ሻ is the word frequency
normalization for word ݓ in document ݀ , and
ܣݒ݁ܦ݋ܿܮ݁݊ is the average length of a document.
</bodyText>
<equation confidence="0.989054">
௞భ௖ሺ௪,ௗሻ
ܤܯ25ሺݓ, ݀ሻ ൌ ௖ሺ௪,ௗሻା௞భቀଵି௕ା௕ |೏|
ಲೡ೐ವ೚೎ಽ೐೙ቁ (4)
</equation>
<bodyText confidence="0.966147666666667">
It is noted that the key feature used by Tao and
Zhai (2005) is the ݎሺݔ, ݕሻ score which depends
purely on statistical information. Therefore, our
motivation is to propose more features to link the
source and target documents more effectively for
a better performance.
</bodyText>
<subsectionHeader confidence="0.999632">
3.2 Study on Frequency Correlation
</subsectionHeader>
<bodyText confidence="0.999873">
We further investigate the frequency correlation of
words from comparable sets of corpora compris-
ing three different languages using the above-
defined model.
</bodyText>
<page confidence="0.997558">
845
</page>
<figureCaption confidence="0.982967">
Fig 2. Sample of frequency correlation for “Bank Dunia”, “World Bank”, and “世界银行”.
</figureCaption>
<figure confidence="0.998675">
0.03
0.02
0.01
0
1 11 21 31 41 51 61 71 81 91
Dunia World 世界
</figure>
<figureCaption confidence="0.9993615">
Fig 3. Sample of frequency correlation for “Dunia”, “World”, and “世界”.
Fig 4. Sample of frequency correlation for “Filipina”, “Information Technology”, and “联合国”.
</figureCaption>
<figure confidence="0.973025307692308">
0.2
0.15
0.1
0.05
0
1 11 21 31 41 51 61 71 81 91
Bank Dunia World Bank 世界银行
0.15
0.1
0.05
0
1 11 21 31 41 51 61 71 81 91
Filipina Information Technology 联合国
</figure>
<bodyText confidence="0.998277277777778">
Using three months - May to July, 2006 – of daily
newspaper in Strait Times2 (in English), Zao Bao3
(in Chinese), and Berita Harian4 (in Malay), we
conduct the experiments described in the follow-
ing Fig 2, Fig 3, and Fig 4 showing three different
cases of term or word correlation. In these figures,
the ݔ-axis denotes time and the ݕ-axis shows the
frequency distribution of the term or word.
Multi-word versus Single-word: Fig 2
illustrates that the distributions for multi-word
term such as “World Bank”, “世界银行(World
Bank in Chinese)”, and “Bank Dunia (World
Bank in Malay)” in the three language corpora
are almost similar because of the discriminative
power of that phrase. The phrase has no variance
and contains no ambiguity. On the other hand,
the distributions for single words may have much
less similarity.
</bodyText>
<footnote confidence="0.970533833333333">
2 http://www.straitstimes.com/ an English news agency in
Singapore. Source © Singapore Press Holdings Ltd.
3 http://www.zaobao.com/ a Chinese news agency in Singa-
pore. Source © Singapore Press Holdings Ltd.
4 http://cyberita.asia1.com.sg/ a Malay news agency in Sin-
gapore. Source © Singapore Press Holdings Ltd.
</footnote>
<bodyText confidence="0.99528795">
Related Common Word: we also investigate
the similarity in frequency distribution for related
common single words in the case of “World”,
“世界 (world in Chinese)”, and “Dunia (world in
Malay)” as shown in Fig 3. It can be observed
that the correlation of these common words is not
as strong as that in the multi-word sample illu-
strated in Fig 2. The reason is that there are many
variances of these common words, which usually
do not have high discriminative power due to the
ambiguities presented within them. Nonetheless,
among these variances, there is still a small simi-
lar distribution trends that can be detected, which
may enable us to discover the associations be-
tween them.
Unrelated Common Word: Fig 4 shows the
frequency distribution of three unrelated com-
mon words over the same three-month period.
No correlation in distribution is found among
them.
</bodyText>
<page confidence="0.991891">
846
</page>
<figure confidence="0.3995815">
3.3.3 Distribution Similarity Measurement
3.3 Enhancement from Baseline Model using Monolingual Term
</figure>
<subsectionHeader confidence="0.668555">
3.3.1 Monolingual Term Correlation
</subsectionHeader>
<bodyText confidence="0.999962956521739">
Due to the inadequacy of the baseline’s purely
statistical approach, and our studies on the corre-
lations of single, multiple and commonly appear-
ing words, we propose using “term” or “multi-
word” instead of “single-word” or “word” to cal-
culate the similarity of term frequency
distribution between two documents. This
presents us with two main advantages. Firstly,
the smaller number of terms compared to the
number of words present in any document would
imply fewer possible document alignment pairs
for the system. This increases the computation
speed remarkably. To extract automatically the
list of terms in each document, we use the term
extraction model from Vu et al. (2008). In corpo-
ra used in our experiments, the average ratios of
word/term per document are 556/37, 410/28 and
384/28 for English, Chinese, and Malay respec-
tively. The other advantage of using terms is that
terms are more distinctive than words as they
contain less ambiguity, thus enabling high corre-
lation to be observed when compared with single
words.
</bodyText>
<subsectionHeader confidence="0.929186">
3.3.2 Bilingual Dictionary Incorporation
</subsectionHeader>
<bodyText confidence="0.999942391304348">
In addition to using terms for the computation,
we observed from equation (3) that the only mu-
tual feature relating the two documents is the
frequency distribution coefficient r(x, y). It is
likely that the alignment performance could be
enhanced if more features relating the two doc-
uments are incorporated.
Following that, we introduce a linguistic fea-
ture, DicScore(x, y), to the baseline model to
enhance the association between two documents.
This feature involves the comparison of the
translations of words within a particular term in
one language, and the presence of these transla-
tions in the corresponding target language term.
If more translations obtained from a bilingual
dictionary of words within a term are found in
the term extracted from the other language’s
document, it is more likely that the 2 bilingual
terms are translations of each other. This feature
counts the number of word translation found be-
tween the two terms, as described in the follow-
ing. Let tl and tz be the term list of dl and dz
respectively, the similarity score in our model is:
</bodyText>
<equation confidence="0.9596795">
Sdic(dl, dz) = Exetl,yetpIDF(x) · IDF(y) · r(x, y) · (5)
DicScore(x, y) · BM25(x,dl) · BM25(y, dz)
</equation>
<bodyText confidence="0.999979923076923">
Finally, we apply the results of time-series re-
search to replace Pearson’s correlation which is
used in the baseline model, in our calculation of
the similarity score of two frequency distribu-
tions. A popular technique for time sequence
matching is to use Discrete Fourier Transform
(DFT) (Agrawal et al, 1993). More recently,
Klementiev and Roth (2006) also use F-index
(Hetland, 2004), a score using DFT, to calculate
the time distribution similarity. In our model, we
assume that the frequency chain of a word is a
sequence, and calculate DFT score for each
chain by the following formula:
</bodyText>
<equation confidence="0.998322">
Hn = Y hk. ez7rikn/N (6)
k=0
</equation>
<bodyText confidence="0.9999924">
In time series research, it is proven that only
the first few k coefficients of a DFT chain are
strong and important for comparison (Agrawal et
al, 1993). Our experiments in section 5 show that
the best value for k is 7 for both language pairs.
</bodyText>
<equation confidence="0.9990393">
R(x,y) _(j Y(Hxi — Hyi)z
k
i=0 (7)
The r(x, y) in equation (5) is replaced by
R(x, y) in equation (8) to calculate the Monolin-
gual Term Distribution (MTD) score.
SMTD(dl, dz) _ Y IDF(x) · IDF(y)
xEt1,yEtp
· R(x, y) · DicScore(x, y) (8)
· BM25(x, dl) · BM25(y, dz)
</equation>
<sectionHeader confidence="0.980708" genericHeader="method">
4 Document Relationship Heuristics
</sectionHeader>
<bodyText confidence="0.9616776">
namely the Title-n-Content score— TNC
measures the relationship between the title and
content of a document pair, and Linguistic Inde-
pendent Unit score
LIU, which make use of
orthographic similarity between unit of words for
the different lan
, which
–
guages.
</bodyText>
<subsectionHeader confidence="0.99541">
4.1 Title-n-Content Score (TNC)
</subsectionHeader>
<bodyText confidence="0.9995687">
Besides the MTD, we also propose two heuristic-
based features that focus directly on the
relationship between two multilingual documents,
Besides being a filter for removing bad align-
ment can
didates, TNC is also incorporated as a
feature in the computation of document align-
ment score. In the corpora used, in most docu-
ments, “title” does reveal the main topic of a
document. The use of words in a news title is
</bodyText>
<equation confidence="0.362688">
_l
</equation>
<page confidence="0.976312">
847
</page>
<bodyText confidence="0.977622333333333">
typically concise and conveys the essence of the
information in the document. Thus, a high TNC
score would indicate a high likelihood of similar-
ity between two bilingual documents. Therefore,
we use TNC as a quantitative feature in our fea-
ture set. Function TR(w, c) checks whether the
translation of a word in a document’s title is
found in the content of its aligned document:
TRw, c _ 1, translation of w is in c1 9
( ) 0, else ( )
The TNC score of document ds and dt is cal-
culated by the following formula:
</bodyText>
<equation confidence="0.981308666666667">
TNC(d,, dt) _
YTR(wi,ct) + L TR(wj,ds) (10)
wtiETs wjETt
</equation>
<bodyText confidence="0.999975857142857">
Where ct and cs are the content of document
dt and ds; and TS and Tt are the set of title words
of two documents.
In addition, this method speeds up the align-
ment process without compromising perfor-
mance when compared with the calculation
based only on contents on both sides.
</bodyText>
<subsectionHeader confidence="0.971567">
4.2 Linguistic Independent Unit (LIU)
</subsectionHeader>
<bodyText confidence="0.992015333333333">
Linguistic Independent Unit score (LIU) is de-
fined as the piece of information, which is writ-
ten in the same way for different languages. The
following highlight the number 25, 11, and 50 as
linguistic-independent-units for the two sen-
tences.
English: Between Feb 25 and March 11 this
year, she used counterfeit $50 notes 10 times to
pay taxi fares ranging from $2.50 to $4.20.
</bodyText>
<figure confidence="0.553874">
Chinese:�Ufl伪钞OjtW,MMS 2 A
25 p�E3A 11 p,�k 50 3—tll额Oj伪钞,缴
J-1j/ -T 2 3—t 5 -A�E 4 3—t 2 -AOjf1f费.
</figure>
<sectionHeader confidence="0.95375" genericHeader="method">
5 Experiment and Evaluation
</sectionHeader>
<subsectionHeader confidence="0.930101">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999815444444444">
The experiments were conducted on two sets of
comparable corpora namely English-Chinese and
English-Malay. The data are from three news
publications in Singapore: the Strait Times (ST,
English), Lian He Zao Bao (ZB, Chinese), and
Berita Harian (BH, Malay). Since these languag-
es are from different language families 5, our
model can be considered as language indepen-
dent.
</bodyText>
<footnote confidence="0.953164">
5 English is in Indo-European; Chinese is in Sino-Tibetan;
Malay is in Austronesian family [Wikipedia].
</footnote>
<bodyText confidence="0.997220928571428">
The evaluation is conducted based on a set of
manually aligned documents prepared by a group
of bilingual students. It is done by carefully read-
ing through each article in the month of June
(2006) for both sets of corpora and trying to find
articles of similar content in the other language
within the given time window. Alignment is
based on similarity of content where the same
story or event is mentioned. Any two bilingual
articles with at least 50% content overlapping are
considered as comparable. This set of reference
data is cross-validated between annotators. Table
1 shows the statistics of our reference data for
document alignment.
</bodyText>
<table confidence="0.78621575">
Language pair ST – ZB ST – BH
Distinct source 396 176
Distinct target 437 175
Total alignments 438 183
</table>
<tableCaption confidence="0.999416">
Table 1. Statistics on evaluation data.
</tableCaption>
<bodyText confidence="0.998648">
Note that although there are 438 alignments
for ST-ZB, the number of unique ST articles are
396, implying that the mapping is not one-to-one.
</bodyText>
<subsectionHeader confidence="0.998256">
5.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999932055555556">
Evaluation is performed on two levels to reflect
performance from two different perspectives.
“Macro evaluation” is conducted to assess the
correctness of the alignment candidates given
their rank among all the alignment candidates.
“Micro evaluation” concerns about the correctness
of the aligned documents returned for a given
source document.
Macro evaluation: we present the perfor-
mance for macro evaluation using average preci-
sion. It is used to evaluate the performance of a
ranked list and gives higher score for the list that
returns more correct alignment in the top.
Micro evaluation: for micro evaluation, we
evaluate the F-Score, calculated from recall and
precision, based on the number of correct align-
ments for the top of alignment candidates for
each source document.
</bodyText>
<subsectionHeader confidence="0.996946">
5.3 Experiment and Result
</subsectionHeader>
<bodyText confidence="0.99998125">
First we implement the method of Tao and Zhai
(2005) as the baseline. Basically, this method
does not depend on any linguistic resources and
calculates the similarity between two documents
purely by comparing all possible pairs of words.
In addition to this, we also implement Muntea-
nu’s (2006) method which uses Okapi scoring
function from the Lemur Toolkit (Ogilvie and
</bodyText>
<page confidence="0.99388">
848
</page>
<bodyText confidence="0.999887244444445">
Callan, 2001) to obtain the similarity score. This
approach relies heavily on bilingual dictionaries.
To assess performances more fairly, the result
from baseline method of Tao and Zhai are com-
pared against the results of the following list of
incremental approaches: the baseline (A); the
baseline using term instead of word (B); replac-
ing r(x, y) by R(x, y) for DFT feature, with and
without bilingual dictionaries in (C) and (D) re-
spectively; and including LIU and TNC for our
final model in (E). Our model is also compared
our model with results from the implementation
of Munteanu (2006) using Okapi (F), and the
results from a combination of our model with
Okapi (G). Table 2 and Table 3 show the expe-
rimental results for two language pairs English –
Chinese (ST-ZB) and English – Malay (ST-BH),
respectively. Each row displays the result of each
experiment at a certain cut-off among the top
returned alignments. The “Top” columns reflect
the cut-off threshold.
The first three cases (A), (B) and (C), which
do not rely on linguistic resources, suggest that
our new features lead to better performance im-
provement over the baseline. It can be seen that
the use of term and DFT significantly improves
the performance. The improvement indicated by
a sharp increase in all cases from (C) to (D)
shows that dictionaries can indeed help DFT fea-
tures.
Based on the result of (E), our final model
significantly outperforms the model of Munteanu
(F) in both macro and micro evaluation. It is
noted that our features rely less heavily on dic-
tionaries as it only makes use of this resource to
translate term words and title words of a docu-
ment while Munteanu (2006) needs to translate
entire documents, exclude stopword, and relying
on an IR system. It is also observed that the per-
formance of (G) shows that although the incor-
poration of Okapi score in our final model (E)
improves the average precision performance of
ST-ZB slightly, it does not appear to be helpful
for our ST-BH data. However, Okapi does help
in the F-Measure on both corpora.
</bodyText>
<table confidence="0.997991923076923">
Pair Strait Times – Zao Bao
Level Top A B C D E F G
Ave/Precision 50 0.042 0.083 0.08 0.559 0.430 0.209 0.508
Macro 0.194 0.479
100 0.042 0.069 0.083 0.438 0.426
200 0.025 0.069 0.110 0.342 0.396 0.153 0.439
500 0.025 0.054 0.110 0.270 0.351 0.111 0.376
F-Measure 1 0.005 0.007 0.009 0.297 0.315 0.157 0.333
Micro
2 0.006 0.005 0.013 0.277 0.286 0.133 0.308
5 0.005 0.006 0.009 0.200 0.190 0.096 0.206
10 0.005 0.005 0.007 0.123 0.119 0.063 0.126
20 0.006 0.008 0.007 0.073 0.074 0.038 0.076
</table>
<tableCaption confidence="0.997959">
Table 2. Performance of Strait Times – Zao Bao.
</tableCaption>
<table confidence="0.999803666666667">
Level Top A B C D E F G
Ave/Precision 50 0.000 0.000 0.000 0.514 0.818 0.000 0.782
Macro
100 0.000 0.000 0.080 0.484 0.759 0.052 0.729
200 0.000 0.008 0.090 0.443 0.687 0.073 0.673
500 0.005 0.008 0.010 0.383 0.604 0.078 0.591
F-Measure 1 0.000 0.000 0.005 0.399 0.634 0.119 0.650
Micro
2 0.000 0.004 0.010 0.340 0.515 0.128 0.515
5 0.002 0.005 0.010 0.205 0.270 0.105 0.273
10 0.004 0.014 0.013 0.130 0.150 0.076 0.150
20 0.006 0.017 0.017 0.074 0.078 0.043 0.078
</table>
<tableCaption confidence="0.998517">
Table 3. Performance of Strait Times – Berita Harian.
</tableCaption>
<table confidence="0.453861">
Pair Strait Times – Berita Harian
</table>
<page confidence="0.994542">
849
</page>
<sectionHeader confidence="0.525447" genericHeader="method">
5.4 Discussion
</sectionHeader>
<bodyText confidence="0.998365333333333">
It can be seen from Table 2 and Table 3 that by
exploiting the frequency distribution of terms
using Discrete Fourier Transform instead of
words on Pearson’s Correlation, performance is
noticeably improved. Fig 5 shows the incremen-
tal improvement of our model for top-200 and
top-2 alignments using macro and micro evalua-
tion respectively. The sharp increase can be seen
in Fig 5 from point (C) onwards.
</bodyText>
<figure confidence="0.998650444444445">
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
</figure>
<figureCaption confidence="0.9965495">
Fig 5. Step-wise improvement at top-200 for macro
and top-2 for micro evaluation.
</figureCaption>
<bodyText confidence="0.9602416">
Fig 6 compares the performance of our system
with Tao and Zhai (2005) and Munteanu (2006).
It is shown that our systems outperform these
two systems under the same experimental
parameters. Moreover, even without the use of
dictionaries, our system’s performance on ST-
BH data is much better than Munteanu’s (2006)
on the same data.
Tao and Zhai (2005) Our System w/o Dict
Our System w Dict Munteanu (2006)
Fig 6. System comparison for ST-ZB and ST-BH at
top-500 for macro and top-5 for micro evaluation.
We find that dictionary usage contributes
much more to performance improvement in ST-
BH compared to that in ST-ZB. We attribute this
to the fact that the feature LIU already contri-
butes markedly to the increase in the perfor-
mance of ST-BH. As a result, it is harder to make
further improvements even with the application
of bilingual dictionaries.
</bodyText>
<sectionHeader confidence="0.988891" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999825793103448">
In this paper, we propose a feature based model
for aligning documents from multilingual com-
parable corpora. Our feature set is selected based
on the need for a method to be adaptable to new
language-pairs without relying heavily on lin-
guistic resources, unsupervised learning strategy.
Thus, in the proposed method we make use of
simple bilingual dictionaries, which are rather
inexpensive and easily obtained nowadays. We
also explore diverse features, including Mono-
lingual Term Distribution ( MTD ), Title-and-
Content (TNC), and Linguistic Independent Unit
(LIU) and measure their contributions in an in-
cremental way. The experiment results show that
our system can retrieve similar documents from
two comparable corpora much better than using
an information retrieval, such as that used by
Munteanu (2006). It also performs better than a
word correlation-based method such as Tao’s
(2005).
Besides document alignment as an end, there
are many tasks that can directly benefit from
comparable corpora with documents that are
well-aligned. These include sentence alignment,
term alignment, and machine translation, espe-
cially statistical machine translation. In the future,
we aim to extract other valuable information
from comparable corpora which benefits from
comparable documents.
</bodyText>
<sectionHeader confidence="0.996549" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999844">
We would like to thank the anonymous review-
ers for their many constructive suggestions for
improving this paper. Our thanks also go to Ma-
hani Aljunied for her contributions to the linguis-
tic assessment in our work.
</bodyText>
<sectionHeader confidence="0.999477" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.979655111111111">
Percy Cheung and Pascale Fung. 2004. Sentence
Alignment in Parallel, Comparable, and Quasi-
comparable Corpora. In Proceedings of 4th Inter-
national Conference on Language Resources and
Evaluation (LREC). Lisbon, Portugal.
Hal Daume III and Daniel Marcu. 2004. A Phrase-
Based HMM Approach to Document/Abstract
Alignment. In Proceedings of Empirical Methods
in Natural Language Processing (EMNLP). Spain.
</reference>
<figure confidence="0.9990572">
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
A/Prec F-Score
ST - ZB
A/Prec F-Score
ST - BH
A B C D E
ST - ZB A/Prec ST - ZB F-Score
ST - BH A/Prec ST - BH F-Score
</figure>
<page confidence="0.965221">
850
</page>
<reference confidence="0.999873088235294">
Min-Yen Kan. 2007. SlideSeer: A Digital Library of
Aligned Document and Presentation Pairs. In Pro-
ceedings of the Joint Conference on Digital Libra-
ries (JCDL). Vancouver, Canada.
Soto Montalvo, Raquel Martinez, Arantza Casillas,
and Victor Fresno. 2006. Multilingual Document
Clustering: a Heuristic Approach Based on Cog-
nate Named Entities. In Proceedings of the 21st In-
ternational Conference on Computational
Linguistics and the 44th Annual Meeting of the
ACL.
Stephen E. Robertson, Steve Walker, Susan Jones,
Micheline Hancock-Beaulieu, and Mike Gatford.
1994. Okapi at TREC-3. In Proceedings of the
Third Text REtrieval Conference (TREC 1994).
Gaithersburg, USA.
Dragos Stefan Munteanu. 2006. Exploiting Compara-
ble Corpora. PhD Thesis. Information Sciences In-
stitute, University of Southern California. USA.
Ogilvie, P., and Callan, J. 2001. Experiments using
the Lemur toolkit. In Proceedings of the 10th Text
REtrieval Conference (TREC).
Alexandre Patry and Philippe Langlais. 2005. Auto-
matic Identification of Parallel Documents with
light or without Linguistics Resources. In Proceed-
ings of 18th Annual Conference on Artificial Intel-
ligent.
Bruno Pouliquen, Ralf Steinberger, Camelia Ignat,
Emilia Kasper, and Irina Temnikova. 2004. Multi-
lingual and Cross-lingual news topic tracking. In
Proceedings of the 20th International Conference
on Computational Linguistics (COLING).
Ralf Steinberger, Bruno Pouliquen, and Johan Hag-
man. 2002. Cross-lingual Document Similarity
Calculation Using the Multilingual Thesaurus
EUROVOC. Computational Linguistics and Intel-
ligent Text Processing.
Tao Tao and ChengXiang Zhai. 2005. Mining Com-
parable Bilingual Text Corpora for Cross-
Language Information Integration. In Proceedings
of the 2005 ACM SIGKDD International Confe-
rence on Knowledge Discovery and Data Mining.
Thuy Vu, Ai Ti Aw and Min Zhang. 2008. Term ex-
traction through unithood and termhood unification.
In Proceedings of the 3rd International Joint Con-
ference on Natural Language Processing
(IJCNLP-08). Hyderabad, India.
ChengXiang Zhai and John Lafferty. 2001. A study of
smoothing methods for language models applied to
Ad Hoc information retrieval. In Proceedings of
the 24th annual international ACM SIGIR confe-
rence on Research and development in information
retrieval. Louisiana, United States.
R. Agrawal, C. Faloutsos, and A. Swami. 1993. Effi-
cient similarity search in sequence databases. In
Proceedings of the 4th International Conference on
Foundations of Data Organization and Algorithms.
Chicago, United States.
Magnus Lie Hetland. 2004. A survey of recent me-
thods for efficient retrieval of similar time se-
quences. In Data Mining in Time Series Databases.
World Scientific.
Alexandre Klementiev and Dan Roth. 2006. Weakly
Supervised Named Entity Transliteration and Dis-
covery from Multilingual Comparable Corpora. In
Proceedings of the 21st International Conference
on Computational Linguistics and the 44th Annual
Meeting of the ACL.
</reference>
<page confidence="0.998668">
851
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.502167">
<title confidence="0.9938165">Feature-based Method for Document Alignment in Comparable News Corpora</title>
<author confidence="0.999872">Thuy Vu</author>
<author confidence="0.999872">Ai Ti Aw</author>
<author confidence="0.999872">Min Zhang</author>
<affiliation confidence="0.99871">Department of Human Language Technology, Institute for Infocomm Research</affiliation>
<address confidence="0.552082">1 Fusionopolis Way, #21-01 Connexis, South Tower, Singapore 138632</address>
<email confidence="0.756885">tvu@i2r.a-star.edu.sg</email>
<email confidence="0.756885">aaiti@i2r.a-star.edu.sg</email>
<email confidence="0.756885">mzhang@i2r.a-star.edu.sg</email>
<abstract confidence="0.997968652173913">In this paper, we present a feature-based method to align documents with similar content across two sets of bilingual comparable corpora from daily news texts. We evaluate the contribution of each individual feature and investigate the incorporation of these diverse statistical and heuristic features for the task of bilingual document alignment. Experimental results on the English-Chinese and English- Malay comparable news corpora show that our proposed Discrete Fourier Transformbased term frequency distribution feature is very effective. It contributes 4.1% and 8% to performance improvement over Pearson’s correlation method on the two comparable corpora. In addition, when more heuristic and statistical features as well as a bilingual dictionary are utilized, our method shows an absolute performance improvement of 23.2% and 15.3% on the two sets of bilingual corpora when comparing with a prior information retrieval-based method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Percy Cheung</author>
<author>Pascale Fung</author>
</authors>
<title>Sentence Alignment in Parallel, Comparable, and Quasicomparable Corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of 4th International Conference on Language Resources and Evaluation (LREC).</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="3971" citStr="Cheung and Fung (2004)" startWordPosition="592" endWordPosition="595">ed Edit Distance, and Sentence Alignment Score, to compute the similarity between two parallel documents. An Adaboost classifier is trained on a list of scored text pairs labeled as parallel or nonparallel. Then, the learned classifier is used to check the correctness of each alignment candidate. Their method is simple but effective. However, the features used in this method are only suitable for parallel corpora as the measurement is mainly based on structural similarity. One goal of document alignment is for parallel sentence extraction for applications like statistical machine translation. Cheung and Fung (2004) highlight that most 1 EUROVOC is a multilingual thesaurus covering the fields in which the European Communities are active. Proceedings of the 12th Conference of the European Chapter of the ACL, pages 843–851, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 843 of the current sentence alignment models are applicable for parallel documents, rather than comparable documents. In addition, they argue that document alignment should be done before parallel sentence extraction. Tao and Zhai (2005) propose a general method to extract comparable bilingual text</context>
</contexts>
<marker>Cheung, Fung, 2004</marker>
<rawString>Percy Cheung and Pascale Fung. 2004. Sentence Alignment in Parallel, Comparable, and Quasicomparable Corpora. In Proceedings of 4th International Conference on Language Resources and Evaluation (LREC). Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daume</author>
<author>Daniel Marcu</author>
</authors>
<title>A PhraseBased HMM Approach to Document/Abstract Alignment.</title>
<date>2004</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<publisher>Spain.</publisher>
<marker>Daume, Marcu, 2004</marker>
<rawString>Hal Daume III and Daniel Marcu. 2004. A PhraseBased HMM Approach to Document/Abstract Alignment. In Proceedings of Empirical Methods in Natural Language Processing (EMNLP). Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min-Yen Kan</author>
</authors>
<title>SlideSeer: A Digital Library of Aligned Document and Presentation Pairs.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Digital Libraries (JCDL).</booktitle>
<location>Vancouver, Canada.</location>
<contexts>
<context position="1910" citStr="Kan (2007)" startWordPosition="282" endWordPosition="283">sk of aligning documents, news articles for instance, across two corpora based on content similarity. The groups of corpora can be in the same or in different languages, depending on the purpose of one’s task. In our study, we attempt to align similar documents across comparable corpora which are bilingual, each set written in a different language but having similar content and domain coverage for different communication needs. Previous works on monolingual document alignment focus on automatic alignment between documents and their presentation slides or between documents and their abstracts. Kan (2007) uses two similarity measures, Cosine and Jaccard, to calculate the candidate alignment score in his SlideSeer system, a digital library software that retrieves documents and their narrated slide presentations. Daumé and Marcu (2004) use a phrase-based HMM model to mine the alignment between documents and their human-written abstracts. The main purpose of this work is to increase the size of the training corpus for a statistical-based summarization system. The research on similarity calculation for multilingual comparable corpora has attracted more attention than monolingual comparable corpora</context>
</contexts>
<marker>Kan, 2007</marker>
<rawString>Min-Yen Kan. 2007. SlideSeer: A Digital Library of Aligned Document and Presentation Pairs. In Proceedings of the Joint Conference on Digital Libraries (JCDL). Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soto Montalvo</author>
<author>Raquel Martinez</author>
<author>Arantza Casillas</author>
<author>Victor Fresno</author>
</authors>
<title>Multilingual Document Clustering: a Heuristic Approach Based on Cognate Named Entities.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the ACL.</booktitle>
<marker>Montalvo, Martinez, Casillas, Fresno, 2006</marker>
<rawString>Soto Montalvo, Raquel Martinez, Arantza Casillas, and Victor Fresno. 2006. Multilingual Document Clustering: a Heuristic Approach Based on Cognate Named Entities. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen E Robertson</author>
<author>Steve Walker</author>
<author>Susan Jones</author>
<author>Micheline Hancock-Beaulieu</author>
<author>Mike Gatford</author>
</authors>
<title>Okapi at TREC-3.</title>
<date>1994</date>
<booktitle>In Proceedings of the Third Text REtrieval Conference (TREC</booktitle>
<location>Gaithersburg, USA.</location>
<marker>Robertson, Walker, Jones, Hancock-Beaulieu, Gatford, 1994</marker>
<rawString>Stephen E. Robertson, Steve Walker, Susan Jones, Micheline Hancock-Beaulieu, and Mike Gatford. 1994. Okapi at TREC-3. In Proceedings of the Third Text REtrieval Conference (TREC 1994). Gaithersburg, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Stefan Munteanu</author>
</authors>
<title>Exploiting Comparable Corpora.</title>
<date>2006</date>
<tech>PhD Thesis.</tech>
<institution>Information Sciences Institute, University of Southern California. USA.</institution>
<contexts>
<context position="5358" citStr="Munteanu (2006)" startWordPosition="803" endWordPosition="804">rent languages should have similar frequency correlation if they are actually translations of each other. The association between two documents is then calculated based on this information using Pearson’s correlation together with two monolingual features BM25 , a term frequency normalization (Stephan et al., 1994), and IDF. The main advantages of this approach are that it is purely statistical-based and it is language-independent. However, its performance may be compromised due to the lack of linguistic knowledge, particularly across corpora which are linguistically very different. Recently, Munteanu (2006) introduces a rather simple way to get the group of similar content document in multilingual comparable corpus by using the Lemur IR Toolkit (Ogilvie and Callan, 2001). This method first pushes all the target documents into the database of the Lemur, and then uses a word-byword translation of each source document as a query to retrieve similar content target documents. This paper will leverage on previous work, and propose and explore diverse range of features in our system. Our document alignment system consists of three stages: candidate generation, feature extraction and feature combination</context>
<context position="24225" citStr="Munteanu (2006)" startWordPosition="3954" endWordPosition="3955">olkit (Ogilvie and 848 Callan, 2001) to obtain the similarity score. This approach relies heavily on bilingual dictionaries. To assess performances more fairly, the result from baseline method of Tao and Zhai are compared against the results of the following list of incremental approaches: the baseline (A); the baseline using term instead of word (B); replacing r(x, y) by R(x, y) for DFT feature, with and without bilingual dictionaries in (C) and (D) respectively; and including LIU and TNC for our final model in (E). Our model is also compared our model with results from the implementation of Munteanu (2006) using Okapi (F), and the results from a combination of our model with Okapi (G). Table 2 and Table 3 show the experimental results for two language pairs English – Chinese (ST-ZB) and English – Malay (ST-BH), respectively. Each row displays the result of each experiment at a certain cut-off among the top returned alignments. The “Top” columns reflect the cut-off threshold. The first three cases (A), (B) and (C), which do not rely on linguistic resources, suggest that our new features lead to better performance improvement over the baseline. It can be seen that the use of term and DFT signific</context>
<context position="27399" citStr="Munteanu (2006)" startWordPosition="4514" endWordPosition="4515">ssion It can be seen from Table 2 and Table 3 that by exploiting the frequency distribution of terms using Discrete Fourier Transform instead of words on Pearson’s Correlation, performance is noticeably improved. Fig 5 shows the incremental improvement of our model for top-200 and top-2 alignments using macro and micro evaluation respectively. The sharp increase can be seen in Fig 5 from point (C) onwards. 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Fig 5. Step-wise improvement at top-200 for macro and top-2 for micro evaluation. Fig 6 compares the performance of our system with Tao and Zhai (2005) and Munteanu (2006). It is shown that our systems outperform these two systems under the same experimental parameters. Moreover, even without the use of dictionaries, our system’s performance on STBH data is much better than Munteanu’s (2006) on the same data. Tao and Zhai (2005) Our System w/o Dict Our System w Dict Munteanu (2006) Fig 6. System comparison for ST-ZB and ST-BH at top-500 for macro and top-5 for micro evaluation. We find that dictionary usage contributes much more to performance improvement in STBH compared to that in ST-ZB. We attribute this to the fact that the feature LIU already contributes m</context>
<context position="28998" citStr="Munteanu (2006)" startWordPosition="4772" endWordPosition="4773">guage-pairs without relying heavily on linguistic resources, unsupervised learning strategy. Thus, in the proposed method we make use of simple bilingual dictionaries, which are rather inexpensive and easily obtained nowadays. We also explore diverse features, including Monolingual Term Distribution ( MTD ), Title-andContent (TNC), and Linguistic Independent Unit (LIU) and measure their contributions in an incremental way. The experiment results show that our system can retrieve similar documents from two comparable corpora much better than using an information retrieval, such as that used by Munteanu (2006). It also performs better than a word correlation-based method such as Tao’s (2005). Besides document alignment as an end, there are many tasks that can directly benefit from comparable corpora with documents that are well-aligned. These include sentence alignment, term alignment, and machine translation, especially statistical machine translation. In the future, we aim to extract other valuable information from comparable corpora which benefits from comparable documents. Acknowledgements We would like to thank the anonymous reviewers for their many constructive suggestions for improving this </context>
</contexts>
<marker>Munteanu, 2006</marker>
<rawString>Dragos Stefan Munteanu. 2006. Exploiting Comparable Corpora. PhD Thesis. Information Sciences Institute, University of Southern California. USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ogilvie</author>
<author>J Callan</author>
</authors>
<title>Experiments using the Lemur toolkit.</title>
<date>2001</date>
<booktitle>In Proceedings of the 10th Text REtrieval Conference (TREC).</booktitle>
<contexts>
<context position="5525" citStr="Ogilvie and Callan, 2001" startWordPosition="829" endWordPosition="832">lated based on this information using Pearson’s correlation together with two monolingual features BM25 , a term frequency normalization (Stephan et al., 1994), and IDF. The main advantages of this approach are that it is purely statistical-based and it is language-independent. However, its performance may be compromised due to the lack of linguistic knowledge, particularly across corpora which are linguistically very different. Recently, Munteanu (2006) introduces a rather simple way to get the group of similar content document in multilingual comparable corpus by using the Lemur IR Toolkit (Ogilvie and Callan, 2001). This method first pushes all the target documents into the database of the Lemur, and then uses a word-byword translation of each source document as a query to retrieve similar content target documents. This paper will leverage on previous work, and propose and explore diverse range of features in our system. Our document alignment system consists of three stages: candidate generation, feature extraction and feature combination. We verify our method on two set of bilingual news comparable corpora English-Chinese and English-Malay. Experimental results show that 1) when only using Fourier Tra</context>
</contexts>
<marker>Ogilvie, Callan, 2001</marker>
<rawString>Ogilvie, P., and Callan, J. 2001. Experiments using the Lemur toolkit. In Proceedings of the 10th Text REtrieval Conference (TREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Patry</author>
<author>Philippe Langlais</author>
</authors>
<title>Automatic Identification of Parallel Documents with light or without Linguistics Resources.</title>
<date>2005</date>
<booktitle>In Proceedings of 18th Annual Conference on Artificial Intelligent.</booktitle>
<contexts>
<context position="3303" citStr="Patry and Langlais (2005)" startWordPosition="489" endWordPosition="492">saurus EUROVOC1, and calculate the semantic similarity based on the distance between the two documents’ representations. The assignment of descriptors is trained by log-likelihood test and computed by TFIDF, Cosine, and Okapi. Similarly, Pouliquen et al. (2004) use a linear combination of three types of knowledge: cognates, geographical place names reference, and map documents based on the EUROVOC. The major limitation of these works is the use of EUROVOC, which is a specific resource workable only for European languages. Aligning documents across parallel corpora is another area of interest. Patry and Langlais (2005) use three similarity scores, Cosine, Normalized Edit Distance, and Sentence Alignment Score, to compute the similarity between two parallel documents. An Adaboost classifier is trained on a list of scored text pairs labeled as parallel or nonparallel. Then, the learned classifier is used to check the correctness of each alignment candidate. Their method is simple but effective. However, the features used in this method are only suitable for parallel corpora as the measurement is mainly based on structural similarity. One goal of document alignment is for parallel sentence extraction for appli</context>
</contexts>
<marker>Patry, Langlais, 2005</marker>
<rawString>Alexandre Patry and Philippe Langlais. 2005. Automatic Identification of Parallel Documents with light or without Linguistics Resources. In Proceedings of 18th Annual Conference on Artificial Intelligent.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Pouliquen</author>
<author>Ralf Steinberger</author>
<author>Camelia Ignat</author>
<author>Emilia Kasper</author>
<author>Irina Temnikova</author>
</authors>
<title>Multilingual and Cross-lingual news topic tracking.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="2939" citStr="Pouliquen et al. (2004)" startWordPosition="432" endWordPosition="435">g corpus for a statistical-based summarization system. The research on similarity calculation for multilingual comparable corpora has attracted more attention than monolingual comparable corpora. However, the purpose and scenario of these works are rather varied. Steinberger et al. (2002) represent document contents using descriptor terms of a multilingual thesaurus EUROVOC1, and calculate the semantic similarity based on the distance between the two documents’ representations. The assignment of descriptors is trained by log-likelihood test and computed by TFIDF, Cosine, and Okapi. Similarly, Pouliquen et al. (2004) use a linear combination of three types of knowledge: cognates, geographical place names reference, and map documents based on the EUROVOC. The major limitation of these works is the use of EUROVOC, which is a specific resource workable only for European languages. Aligning documents across parallel corpora is another area of interest. Patry and Langlais (2005) use three similarity scores, Cosine, Normalized Edit Distance, and Sentence Alignment Score, to compute the similarity between two parallel documents. An Adaboost classifier is trained on a list of scored text pairs labeled as parallel</context>
</contexts>
<marker>Pouliquen, Steinberger, Ignat, Kasper, Temnikova, 2004</marker>
<rawString>Bruno Pouliquen, Ralf Steinberger, Camelia Ignat, Emilia Kasper, and Irina Temnikova. 2004. Multilingual and Cross-lingual news topic tracking. In Proceedings of the 20th International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Steinberger</author>
<author>Bruno Pouliquen</author>
<author>Johan Hagman</author>
</authors>
<date>2002</date>
<booktitle>Cross-lingual Document Similarity Calculation Using the Multilingual Thesaurus EUROVOC. Computational Linguistics and Intelligent Text Processing.</booktitle>
<contexts>
<context position="2605" citStr="Steinberger et al. (2002)" startWordPosition="384" endWordPosition="387">ndidate alignment score in his SlideSeer system, a digital library software that retrieves documents and their narrated slide presentations. Daumé and Marcu (2004) use a phrase-based HMM model to mine the alignment between documents and their human-written abstracts. The main purpose of this work is to increase the size of the training corpus for a statistical-based summarization system. The research on similarity calculation for multilingual comparable corpora has attracted more attention than monolingual comparable corpora. However, the purpose and scenario of these works are rather varied. Steinberger et al. (2002) represent document contents using descriptor terms of a multilingual thesaurus EUROVOC1, and calculate the semantic similarity based on the distance between the two documents’ representations. The assignment of descriptors is trained by log-likelihood test and computed by TFIDF, Cosine, and Okapi. Similarly, Pouliquen et al. (2004) use a linear combination of three types of knowledge: cognates, geographical place names reference, and map documents based on the EUROVOC. The major limitation of these works is the use of EUROVOC, which is a specific resource workable only for European languages.</context>
</contexts>
<marker>Steinberger, Pouliquen, Hagman, 2002</marker>
<rawString>Ralf Steinberger, Bruno Pouliquen, and Johan Hagman. 2002. Cross-lingual Document Similarity Calculation Using the Multilingual Thesaurus EUROVOC. Computational Linguistics and Intelligent Text Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Tao</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Mining Comparable Bilingual Text Corpora for CrossLanguage Information Integration.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2005 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</booktitle>
<contexts>
<context position="4509" citStr="Tao and Zhai (2005)" startWordPosition="675" endWordPosition="678">ion for applications like statistical machine translation. Cheung and Fung (2004) highlight that most 1 EUROVOC is a multilingual thesaurus covering the fields in which the European Communities are active. Proceedings of the 12th Conference of the European Chapter of the ACL, pages 843–851, Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics 843 of the current sentence alignment models are applicable for parallel documents, rather than comparable documents. In addition, they argue that document alignment should be done before parallel sentence extraction. Tao and Zhai (2005) propose a general method to extract comparable bilingual text without using any linguistic resources. The main feature of this method is the frequency correlation of words in different languages. They assume that those words in different languages should have similar frequency correlation if they are actually translations of each other. The association between two documents is then calculated based on this information using Pearson’s correlation together with two monolingual features BM25 , a term frequency normalization (Stephan et al., 1994), and IDF. The main advantages of this approach ar</context>
<context position="11339" citStr="Tao and Zhai (2005)" startWordPosition="1779" endWordPosition="1782">rvised system. We simply take a product of all normalized features to obtain one unique score. This is because our features are probabilistically independent. In our implementation, we normalize the scores to make them less sensitive to the absolute value by taking the logarithm ݈݊ሺ. ሻ as follows: ݊ݎ݉ሺݔሻ ൌ ݈݊ሺݔ  ܶሻ, ݔ  ሺ݁ െ ܶሻ (1) 1, ݈݁ݏ݁ ሺ݁ െ ܶሻ is a threshold for ݔ to contribute positively to the unique score. In our experiment, we empirically choose ܶ be 2.2, and the threshold for ݔ is 0.51828 (as ݁  2.71828). 3 Monolingual Term Distribution 3.1 Baseline Model The main feature used in Tao and Zhai (2005) is the frequency distribution similarity or frequency correlation of words in two given corpora. It is assumed that frequency distributions of topicallyrelated words in multilingual comparable corpora are often correlated due to the correlated coverage of the same events. Let ܠ ൌ ሼݔଵ, ݔଶ, ... , ݔሽ and ܡ ൌ ሼݕଵ, ݕଶ, ... , ݕሽ be the frequency distribution vectors of two words ݔ and ݕ in two documents respectively. The frequency correlation of the two words is computed by Pearson’s Correlation Coefficient in (2).   ∑ ௫௬ ି∑ ௫  సభ ∑ ௬ సభ సభ ݎሺݔ, ݕሻ ൌ సభ ൯మቁ (2) ටቀ∑ ௫  మ సభ ିభ ൫∑ ௫</context>
<context position="23309" citStr="Tao and Zhai (2005)" startWordPosition="3802" endWordPosition="3805">luation” concerns about the correctness of the aligned documents returned for a given source document. Macro evaluation: we present the performance for macro evaluation using average precision. It is used to evaluate the performance of a ranked list and gives higher score for the list that returns more correct alignment in the top. Micro evaluation: for micro evaluation, we evaluate the F-Score, calculated from recall and precision, based on the number of correct alignments for the top of alignment candidates for each source document. 5.3 Experiment and Result First we implement the method of Tao and Zhai (2005) as the baseline. Basically, this method does not depend on any linguistic resources and calculates the similarity between two documents purely by comparing all possible pairs of words. In addition to this, we also implement Munteanu’s (2006) method which uses Okapi scoring function from the Lemur Toolkit (Ogilvie and 848 Callan, 2001) to obtain the similarity score. This approach relies heavily on bilingual dictionaries. To assess performances more fairly, the result from baseline method of Tao and Zhai are compared against the results of the following list of incremental approaches: the base</context>
<context position="27379" citStr="Tao and Zhai (2005)" startWordPosition="4509" endWordPosition="4512">ita Harian 849 5.4 Discussion It can be seen from Table 2 and Table 3 that by exploiting the frequency distribution of terms using Discrete Fourier Transform instead of words on Pearson’s Correlation, performance is noticeably improved. Fig 5 shows the incremental improvement of our model for top-200 and top-2 alignments using macro and micro evaluation respectively. The sharp increase can be seen in Fig 5 from point (C) onwards. 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 Fig 5. Step-wise improvement at top-200 for macro and top-2 for micro evaluation. Fig 6 compares the performance of our system with Tao and Zhai (2005) and Munteanu (2006). It is shown that our systems outperform these two systems under the same experimental parameters. Moreover, even without the use of dictionaries, our system’s performance on STBH data is much better than Munteanu’s (2006) on the same data. Tao and Zhai (2005) Our System w/o Dict Our System w Dict Munteanu (2006) Fig 6. System comparison for ST-ZB and ST-BH at top-500 for macro and top-5 for micro evaluation. We find that dictionary usage contributes much more to performance improvement in STBH compared to that in ST-ZB. We attribute this to the fact that the feature LIU a</context>
</contexts>
<marker>Tao, Zhai, 2005</marker>
<rawString>Tao Tao and ChengXiang Zhai. 2005. Mining Comparable Bilingual Text Corpora for CrossLanguage Information Integration. In Proceedings of the 2005 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thuy Vu</author>
<author>Ai Ti Aw</author>
<author>Min Zhang</author>
</authors>
<title>Term extraction through unithood and termhood unification.</title>
<date>2008</date>
<booktitle>In Proceedings of the 3rd International Joint Conference on Natural Language Processing (IJCNLP-08).</booktitle>
<location>Hyderabad, India.</location>
<contexts>
<context position="16166" citStr="Vu et al. (2008)" startWordPosition="2595" endWordPosition="2598">oach, and our studies on the correlations of single, multiple and commonly appearing words, we propose using “term” or “multiword” instead of “single-word” or “word” to calculate the similarity of term frequency distribution between two documents. This presents us with two main advantages. Firstly, the smaller number of terms compared to the number of words present in any document would imply fewer possible document alignment pairs for the system. This increases the computation speed remarkably. To extract automatically the list of terms in each document, we use the term extraction model from Vu et al. (2008). In corpora used in our experiments, the average ratios of word/term per document are 556/37, 410/28 and 384/28 for English, Chinese, and Malay respectively. The other advantage of using terms is that terms are more distinctive than words as they contain less ambiguity, thus enabling high correlation to be observed when compared with single words. 3.3.2 Bilingual Dictionary Incorporation In addition to using terms for the computation, we observed from equation (3) that the only mutual feature relating the two documents is the frequency distribution coefficient r(x, y). It is likely that the a</context>
</contexts>
<marker>Vu, Aw, Zhang, 2008</marker>
<rawString>Thuy Vu, Ai Ti Aw and Min Zhang. 2008. Term extraction through unithood and termhood unification. In Proceedings of the 3rd International Joint Conference on Natural Language Processing (IJCNLP-08). Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ChengXiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>A study of smoothing methods for language models applied to Ad Hoc information retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval.</booktitle>
<location>Louisiana, United States.</location>
<marker>Zhai, Lafferty, 2001</marker>
<rawString>ChengXiang Zhai and John Lafferty. 2001. A study of smoothing methods for language models applied to Ad Hoc information retrieval. In Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval. Louisiana, United States.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Agrawal</author>
<author>C Faloutsos</author>
<author>A Swami</author>
</authors>
<title>Efficient similarity search in sequence databases.</title>
<date>1993</date>
<booktitle>In Proceedings of the 4th International Conference on Foundations of Data Organization and Algorithms.</booktitle>
<location>Chicago, United States.</location>
<contexts>
<context position="18038" citStr="Agrawal et al, 1993" startWordPosition="2904" endWordPosition="2907">er. This feature counts the number of word translation found between the two terms, as described in the following. Let tl and tz be the term list of dl and dz respectively, the similarity score in our model is: Sdic(dl, dz) = Exetl,yetpIDF(x) · IDF(y) · r(x, y) · (5) DicScore(x, y) · BM25(x,dl) · BM25(y, dz) Finally, we apply the results of time-series research to replace Pearson’s correlation which is used in the baseline model, in our calculation of the similarity score of two frequency distributions. A popular technique for time sequence matching is to use Discrete Fourier Transform (DFT) (Agrawal et al, 1993). More recently, Klementiev and Roth (2006) also use F-index (Hetland, 2004), a score using DFT, to calculate the time distribution similarity. In our model, we assume that the frequency chain of a word is a sequence, and calculate DFT score for each chain by the following formula: Hn = Y hk. ez7rikn/N (6) k=0 In time series research, it is proven that only the first few k coefficients of a DFT chain are strong and important for comparison (Agrawal et al, 1993). Our experiments in section 5 show that the best value for k is 7 for both language pairs. R(x,y) _(j Y(Hxi — Hyi)z k i=0 (7) The r(x,</context>
</contexts>
<marker>Agrawal, Faloutsos, Swami, 1993</marker>
<rawString>R. Agrawal, C. Faloutsos, and A. Swami. 1993. Efficient similarity search in sequence databases. In Proceedings of the 4th International Conference on Foundations of Data Organization and Algorithms. Chicago, United States.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Lie Hetland</author>
</authors>
<title>A survey of recent methods for efficient retrieval of similar time sequences. In Data Mining in Time Series Databases. World Scientific.</title>
<date>2004</date>
<contexts>
<context position="18114" citStr="Hetland, 2004" startWordPosition="2917" endWordPosition="2918">, as described in the following. Let tl and tz be the term list of dl and dz respectively, the similarity score in our model is: Sdic(dl, dz) = Exetl,yetpIDF(x) · IDF(y) · r(x, y) · (5) DicScore(x, y) · BM25(x,dl) · BM25(y, dz) Finally, we apply the results of time-series research to replace Pearson’s correlation which is used in the baseline model, in our calculation of the similarity score of two frequency distributions. A popular technique for time sequence matching is to use Discrete Fourier Transform (DFT) (Agrawal et al, 1993). More recently, Klementiev and Roth (2006) also use F-index (Hetland, 2004), a score using DFT, to calculate the time distribution similarity. In our model, we assume that the frequency chain of a word is a sequence, and calculate DFT score for each chain by the following formula: Hn = Y hk. ez7rikn/N (6) k=0 In time series research, it is proven that only the first few k coefficients of a DFT chain are strong and important for comparison (Agrawal et al, 1993). Our experiments in section 5 show that the best value for k is 7 for both language pairs. R(x,y) _(j Y(Hxi — Hyi)z k i=0 (7) The r(x, y) in equation (5) is replaced by R(x, y) in equation (8) to calculate the </context>
</contexts>
<marker>Hetland, 2004</marker>
<rawString>Magnus Lie Hetland. 2004. A survey of recent methods for efficient retrieval of similar time sequences. In Data Mining in Time Series Databases. World Scientific.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Dan Roth</author>
</authors>
<title>Weakly Supervised Named Entity Transliteration and Discovery from Multilingual Comparable Corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="18081" citStr="Klementiev and Roth (2006)" startWordPosition="2910" endWordPosition="2913"> word translation found between the two terms, as described in the following. Let tl and tz be the term list of dl and dz respectively, the similarity score in our model is: Sdic(dl, dz) = Exetl,yetpIDF(x) · IDF(y) · r(x, y) · (5) DicScore(x, y) · BM25(x,dl) · BM25(y, dz) Finally, we apply the results of time-series research to replace Pearson’s correlation which is used in the baseline model, in our calculation of the similarity score of two frequency distributions. A popular technique for time sequence matching is to use Discrete Fourier Transform (DFT) (Agrawal et al, 1993). More recently, Klementiev and Roth (2006) also use F-index (Hetland, 2004), a score using DFT, to calculate the time distribution similarity. In our model, we assume that the frequency chain of a word is a sequence, and calculate DFT score for each chain by the following formula: Hn = Y hk. ez7rikn/N (6) k=0 In time series research, it is proven that only the first few k coefficients of a DFT chain are strong and important for comparison (Agrawal et al, 1993). Our experiments in section 5 show that the best value for k is 7 for both language pairs. R(x,y) _(j Y(Hxi — Hyi)z k i=0 (7) The r(x, y) in equation (5) is replaced by R(x, y) </context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>Alexandre Klementiev and Dan Roth. 2006. Weakly Supervised Named Entity Transliteration and Discovery from Multilingual Comparable Corpora. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>