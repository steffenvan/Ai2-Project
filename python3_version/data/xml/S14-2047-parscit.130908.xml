<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009404">
<title confidence="0.921047">
FBK-TR: SVM for Semantic Relatedness and Corpus Patterns for RTE
</title>
<author confidence="0.706353">
Ngoc Phuoc An Vo
</author>
<affiliation confidence="0.825199">
Fondazione Bruno Kessler
University of Trento
</affiliation>
<address confidence="0.605783">
Trento, Italy
</address>
<email confidence="0.996847">
ngoc@fbk.eu
</email>
<author confidence="0.684367">
Octavian Popescu
</author>
<affiliation confidence="0.597427">
Fondazione Bruno Kessler
</affiliation>
<address confidence="0.56782">
Trento, Italy
</address>
<email confidence="0.968857">
popescu@fbk.eu
</email>
<author confidence="0.60734">
Tommaso Caselli
</author>
<affiliation confidence="0.514789">
TrentoRISE
</affiliation>
<address confidence="0.589797">
Trento, Italy
</address>
<email confidence="0.977348">
t.caselli@trentorise.eu
</email>
<sectionHeader confidence="0.993358" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999259714285714">
This paper reports the description and
scores of our system, FBK-TR, which
participated at the SemEval 2014 task
#1 &amp;quot;Evaluation of Compositional Distribu-
tional Semantic Models on Full Sentences
through Semantic Relatedness and Entail-
ment&amp;quot;. The system consists of two parts:
one for computing semantic relatedness,
based on SVM, and the other for identi-
fying the entailment values on the basis
of both semantic relatedness scores and
entailment patterns based on verb-specific
semantic frames. The system ranked 11th
on both tasks with competitive results.
</bodyText>
<sectionHeader confidence="0.998796" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999961421052632">
In the Natural Language Processing community,
meaning related tasks have gained an increasing
popularity. These tasks focus, in general, on a
couple of short pieces of text, like pair of sen-
tences, and the systems are required to infer a cer-
tain meaning relationship that exists between these
texts. Two of the most popular meaning related
tasks are the identification of Semantic Text Sim-
ilarity (STS) and Recognizing Textual Entailment
(RTE). The STS tasks require to identify the de-
gree of similarity (or relatedness) that exists be-
tween two text fragments (sentences, paragraphs,
... ), where similarity is a broad concept and its
value is normally obtained by averaging the opin-
ion of several annotators. The RTE task requires
the identification of a directional relation between
a pair of text fragments, namely a text (T) and a
hypothesis (H). The relation (T → H) holds when-
ever the truth of H follows from T.
</bodyText>
<footnote confidence="0.74788125">
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.998673725">
At SemEval 2014, the Task #1 &amp;quot;Evaluation
of Compositional Distributional Semantic Models
on Full Sentences through Semantic Relatedness
and Entailment&amp;quot; (Marelli et al., 2014a) primarily
aimed at evaluating Compositional Distributional
Semantic Models (CDSMs) of meaning over two
subtasks, namely semantic relatedness and tex-
tual entailment (ENTAILMENT, CONTRADIC-
TION and NEUTRAL), over pairs of sentences
(Marelli et al., 2014b). Concerning the relatedness
subtask, the system outputs are evaluated against
gold standard ratings in two ways, using Pearson
correlation and Spearman’s rank correlation (rho).
The Pearson correlation is used for evaluating and
ranking the participating systems. Similarly, for
the textual entailment subtask, system outputs are
evaluated against a gold standard rating with re-
spect to accuracy.
Our team, FBK-TR, participated in both sub-
tasks with five different runs. In this paper, we
present a comprehensive description of our system
which obtained competitive results in both tasks
and which is not based on CDSMs. Our approach
for the relatedness task is based on machine learn-
ing techniques to learn models from different lexi-
cal and semantic features from the train corpus and
then to make prediction on the test corpus. Par-
ticularly, we used support vector machine (SVM)
(Chang and Lin, 2011), regression model to solve
this subtask. On the other hand, the textual en-
tailment task uses a methodology mainly based on
corpus patterns automatically extracted from an-
notated text corpora.
The remainder of the paper is organized as
follows: Section 2 presents the SVM system
for semantic relatedness. Section 3 describes
the methodology used for extracting patterns and
computing the textual entailment values. Finally,
Section 4 discusses about the evaluations and Sec-
tion 5 presents conclusions and future work.
</bodyText>
<page confidence="0.980274">
289
</page>
<note confidence="0.830696">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 289–293,
Dublin, Ireland, August 23-24, 2014.
</note>
<figureCaption confidence="0.99969">
Figure 1: Schema of the system for computing entailment.
</figureCaption>
<sectionHeader confidence="0.8050615" genericHeader="method">
2 System Overview for Semantic
Relatedness Subtask
</sectionHeader>
<bodyText confidence="0.99864175">
Concerning the Semantic Relatedness subtask our
SVM system is built on different linguistic fea-
tures, ranging from relatedness at the lexical level
(WordNet based measures, Wikipedia relatedness
and Latent Semantic Analysis), to sentence level,
including topic modeling based on Latent Dirich-
let allocation (LDA) and string similarity (Longest
Common Substring).
</bodyText>
<subsectionHeader confidence="0.993952">
2.1 Lexical Features
</subsectionHeader>
<bodyText confidence="0.999973263157895">
At the lexical level, we built a simple, yet effective
Semantic Word Relatedness model, which con-
sists of 3 components: WordNet similarity (based
on the Lin measure as implemented in Pedersen
package WordNet:Similarity (Pedersen et
al., 2004), Wikipedia relatedness (as provided by
the Wikipedia Miner package (Milne and Witten,
2013)), and Latent Semantic Analysis (Landauer
et al., 1998), with a model trained on the British
National Corpus (BNC) 1 and Wikipedia. At this
level of analysis, we concentrated only on the
best matched (lemma) pairs of content words, i.e.
Noun-Noun, Verb-Verb, extracted from each sen-
tence pair. The content words have been automati-
cally extracted by means of part-of-speech tagging
(TreeTagger (Schmid, 1994)) and lemmatization.
For words which are not present in WordNet,
the relatedness score has been obtained by means
of the Levenshtein distance (Levenshtein, 1966).
</bodyText>
<footnote confidence="0.956427">
1http://www.natcorp.ox.ac.uk
</footnote>
<subsectionHeader confidence="0.992562">
2.2 Topic Modeling
</subsectionHeader>
<bodyText confidence="0.999996727272727">
We have applied topic modeling based on Latent
Dirichlet allocation (LDA) (Blei et al., 2003) as
implemented in the MALLET package (McCal-
lum, 2002). The topic model was developed us-
ing the BNC and Wikipedia (with the numbers
of topics varying from 20 to 500 topics). From
the proportion vectors (distribution of documents
over topics) of the given texts, we apply 3 differ-
ent measures (Cosine similarity, Kullback-Leibler
and Jensen-Shannon divergences) to compute the
distances between each pair of sentences.
</bodyText>
<subsectionHeader confidence="0.994487">
2.3 String Similarity: Longest Common
Substring
</subsectionHeader>
<bodyText confidence="0.999996307692308">
As for the string level, two given sentences are
considered similar/related if they are overlap-
ping/covering each other (e.g sentence 1 covers
a part of sentence 2, or otherwise). Hence, we
considered the text overlapping between two
given texts as a feature for our system. The
extraction of the features at the string level was
computed in two steps: first, we obtained Longest
Common Substring between two given sentences.
After this, we also considered measuring the
similarity for the parts before and after the LCS
between two given texts, by means of the Lin
measure and the Levenshtein distance.
</bodyText>
<sectionHeader confidence="0.902956" genericHeader="method">
3 System Overview for RTE Subtask
</sectionHeader>
<bodyText confidence="0.9410115">
The system for the identification of the entailment
values is illustrated in Figure 1. Entailment values
</bodyText>
<page confidence="0.973867">
290
</page>
<bodyText confidence="0.999661492307693">
are computed starting from a baseline (only EN-
TAILMENT and NEUTRAL values) which relies
on the output (i.e. scores) of the semantic related-
ness system. After this step, two groups of entail-
ment patterns are applied whether the surface form
of a sentence pair is affirmative (i.e. absence of
negation words) or negative. Each type of pattern
provides in output an associated entailment value
which corresponds to the final value assigned by
the system.
The entailment patterns are based on verb-
specific semantic frames that include both syn-
tactic and semantic information. Hence, we have
explicit access to the information that individual
words have and to the process of combining them
in bigger units, namely phrases, which carry out
meanings. The patterns have two properties: i.)
the senses of the words inside the pattern are sta-
ble, they do not change whatever context is added
to the left, right or inside the phrase matching the
pattern, and ii.) the replacement of a word with an-
other word belonging to a certain class changes the
senses of the words. Patterns with these properties
are called Sense Discriminative Patterns (SDPs).
It has been noted (Popescu et al., 2011) that we can
associate to a phrase that is matched by an SDP a
set of phrases for which an entailment relationship
is decidable showing that there is a direct relation-
ship between SDPs and entailment.
SDP patterns have been obtained from large
parsed corpora. To maximize the accuracy of the
corpus we have chosen sentences containing at
maximum two finite verbs from BNC and Anno-
tated English Gigaword. We parsed this corpus
with the Stanford parser, discarding the sentences
from the Annotated English Gigaword which have
a different parsing. Each words is replaced with
their possible SUMO attributes (Niles and Pease,
2003). Only the following Stanford dependen-
cies are retained as valid [n, nsub]sbj, [d,i,p]obj,
prep, [x,c]comp. We considered only the most fre-
quent occurrences of such patterns for each verb.
To cluster into a single SDP pattern, all patterns
that are sense auto-determinative, we used the
OntoNotes (Hovy et al., 2006) and CPA (Hanks,
2008) lexica. Inside each cluster, we searched
for the most general hypernyms for each syntac-
tic slot such that there are no common patterns
between clusters (Popescu, 2013). However, the
patterns thus obtained are not sufficient enough
for the task. Some expressions may be the para-
phrasis a word in the context of an SDP. To ex-
tract this information, we considered all the pairs
in training that are in an ENTAILMENT relation-
ship, with a high relatedness score (4 to 5), and we
extracted the parts that are different for each gram-
matical slot. In this way, we compiled a list of
quasi synonym phrases that can be replaced inside
an SDP without affecting the replacement. This
is the only component that depends on the train-
ing corpus. Figure 2 describes the algorithm for
computing entailment on the basis of the SDPs.
The following subsections illustrate the identifi-
cation of entailment relation for affirmative sen-
tences and negated sentences.
</bodyText>
<figureCaption confidence="0.989839">
Figure 2: Algorithm for computing entailment.
</figureCaption>
<subsectionHeader confidence="0.998657">
3.1 Entailment on Affirmative Sentences
</subsectionHeader>
<bodyText confidence="0.999994928571428">
Affirmative sentences use three types of entail-
ment patterns. The switch baseline and hyponym
patterns works in this way: If two sentences are
matched by the same SDP, and the difference be-
tween them is that the second one contains a hy-
pernym on the same syntactic position, then the
first one is entailed by the second (i.e. ENTAIL-
MENT). If the two SDPs are such that the dif-
ference between them is that the second contains
a word which is not synonym, hypernym or hy-
ponym on the same syntactic position, then there is
no entailment between the two phrases (i.e. NEU-
TRAL). The entailment direction is from the sen-
tence that contains the hyponym toward the other
</bodyText>
<page confidence="0.99406">
291
</page>
<bodyText confidence="0.999495">
sentence. The antonym patterns check if the two
SDPs are the same, with the only difference be-
ing in the verb of the second sentence being an
antonym of the verb in the first sentence (i.e.
CONTRADICTION).
</bodyText>
<subsectionHeader confidence="0.998643">
3.2 Entailment on Negative Sentences
</subsectionHeader>
<bodyText confidence="0.999986">
As for negated sentences, we distinguish between
existential negative phrases (i.e. there is no or
there are no) and factual negative ones (presence
of a negative polarity word). An assumption re-
lated to each SDP is that it entails the existence
of any of the component of the pattern which can
be expressed by means of dedicated phrases. A
SDP of the kind &amp;quot;[Human] beat [Animal]&amp;quot;, en-
tails both phrases, namely there is a [Human] and
there is a [Animal]. We call this set of associ-
ated existential phrases, Existential Assumptions
(EAs). This type of existential entailment obtained
through the usage of SDP has a direct consequence
for handling the ENTAILMENT, CONTRADIC-
TION and NEUTRAL types of entailment when
one of the phrases is negated. If the first phrase
belongs to the EA of the second one, then the
first phrase is entailed by the second phrase; if the
first phrase is an existential negation of a phrase
belonging to the EA set of the second phrase,
meaning that it contains the string there is/are no,
then the first one is a contradiction of the second
phrase; if neither the first phrase, nor its negation
belong to the EA set of the second phrase, then the
two sentences are neutral with respect to the en-
tailment. The general rule described in 3.1 applies
to these types of phrases as well: replacing a word
on the same syntactic slot inside a phrase that is
matched by a SDP leads to a CONTRADICTION
type of entailment, if the replacement is a hyper-
nym of the original word. Similarly, the approach
can be applied to factual negative phrases. The
scope of negation is considered to be the extension
of the SDP and thus the negative set of EAs.
</bodyText>
<sectionHeader confidence="0.983472" genericHeader="evaluation">
4 Evaluation and Ranking
</sectionHeader>
<bodyText confidence="0.99967375">
Table 1 illustrates the results for Pearson and
Spearman correlations for the relatedness subtask
on the test set. Table 2 reports the Accuracy values
for the entailment subtask on the test set.
Concerning the relatedness results our systems
ranked 11th out of 17 participating systems. Best
score of our system is reported in Table 1. One
of the main reason for the relatively low results
</bodyText>
<table confidence="0.911633">
Team Pearson Spearman
ECNU_run1 (ranked 1st) 0.82795 0.76892
FBK-TR_run3 0.70892 0.64430
</table>
<tableCaption confidence="0.952457">
Table 1: Results for semantic relatedness subtask.
</tableCaption>
<table confidence="0.9984004">
Team Accuracy
Illinois-LH_run1 (ranked 1st) 84.575
FBK-TR_run3 75.401
*FBK-TR_baseline 64.080
*FBK-TR_new 85.082
</table>
<tableCaption confidence="0.996438">
Table 2: Results for entailment subtask.
</tableCaption>
<bodyText confidence="0.9998934">
of the systems for this subtask concerns the fact
that it is designed for a general-level of texts (i.e.
compositionality is not taken into account).
As for the entailment subtask, our system
ranked 11th out of 18 participating systems. The
submitted results of the system are illustrated in
Table 2 and are compared against the best system,
our baseline system (*FBK-TR_baseline) as de-
scribed in Figure 1, and a new version of the par-
ticipating system after fixing some bugs in the sub-
mitted version due to the processing of the parser’s
output (*FBK-TR_new). The new version of the
system scores in the top provides a new state of the
art result, with an improvement of 10 points with
respect to our submitted system.
</bodyText>
<sectionHeader confidence="0.990526" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999967388888889">
This paper reports the description of our system,
FBK-TR, which implements a general SVM se-
mantic relatedness system based on distributional
features (LSA, LDA), knowledge-based related
features (WordNet and Wikipedia) and string over-
lap (LCS). On top of that, we added structural in-
formation at both semantic and syntactic level by
using SDP patterns. The system reached compet-
itive results in both subtasks. By correcting some
bugs in the entailment scripts, we obtained an im-
provement over our submitted systems as well as
for the best ranking system. We plan to improve
and extend the relatedness system by means of
compositional methods. Finally, the entailment
system can be improved by taking into account
additional linguistic evidences, such as the alter-
nation between indefinite and definite determiners,
noun modifiers and semantically empty heads.
</bodyText>
<page confidence="0.994405">
292
</page>
<sectionHeader confidence="0.990162" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998931887096774">
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent Dirichlet Allocation. The Journal of
Machine Learning research, 3:993–1022.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A Library for Support Vector Machines.
ACM Transactions on Intelligent Systems and Tech-
nology (TIST), 2(3):27.
Patrick Hanks. 2008. Mapping meaning onto use: a
Pattern Dictionary of English Verbs. In Proceedings
of the AACL 2008.
Eduard Hovy, Mitchell Marcus, Martha Palmer,
Lance Ramshaw, and Ralph Weischedel. 2006.
OntoNotes: The 90% Solution. In Proceedings of
the human language technology conference of the
NAACL, Companion Volume: Short Papers, pages
57–60.
Thomas K Landauer, Peter W Foltz, and Darrell La-
ham. 1998. An Introduction to Latent Semantic
Analysis. Discourse processes, 25(2-3):259–284.
Vladimir I Levenshtein. 1966. Binary Codes Capa-
ble of Correcting Deletions, Insertions and Rever-
sals. In Soviet Physics Doklady, volume 10, page
707.
M Marelli, L Bentivogli, M Baroni, R Bernardi,
S Menini, and R Zamparelli. 2014a. Semeval-2014
Task 1: Evaluation of compositional distributional
semantic models on full sentences through seman-
tic relatedness and textual entailment. In Proceed-
ings of SemEval 2014: International Workshop on
Semantic Evaluation, August 23-24, 2014, Dublin,
Ireland.
M Marelli, S Menini, M Baroni, L Bentivogli,
R Bernardi, and R Zamparelli. 2014b. A SICK
cure for the evaluation of compositional distribu-
tional semantic models. In Proceedings of LREC
2014, Reykjavik (Iceland): ELRA.
Andrew Kachites McCallum. 2002. MALLET: A Ma-
chine Learning for Language Toolkit.
David Milne and Ian H Witten. 2013. An Open-
Source Toolkit for Mining Wikipedia. Artificial In-
telligence, 194:222–239.
Ian Niles and Adam Pease. 2003. Mapping Word-
Net to the SUMO Ontology. In Proceedings of the
IEEE International Knowledge Engineering Confer-
ence, pages 23–26.
Ted Pedersen, Patwardhan Siddharth, and Michelizzi
Jason. 2004. Wordnet::Similarity: Measuring the
Relatedness of Concepts. In Proceedings of the
HLT-NAACL 2004.
Octavian Popescu, Elena Cabrio, and Bernardo
Magnini. 2011. Textual Entailment Using Chain
Clarifying Relationships. In Proceedings of the IJ-
CAI Workshop Learning by Reasoning and its Appli-
cations in Intelligent Question-Answering.
Octavian Popescu. 2013. Learning Corpus Patterns
Using Finite State Automata. In Proceedings of the
ICSC 2013.
Helmut Schmid. 1994. Probabilistic Part-of-Sspeech
Tagging Using Decision Trees. In Proceedings of
international conference on new methods in lan-
guage processing, volume 12, pages 44–49. Manch-
ester, UK.
</reference>
<page confidence="0.998955">
293
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.036006">
<title confidence="0.9129665">FBK-TR: SVM for Semantic Relatedness and Corpus Patterns for RTE Ngoc Phuoc An</title>
<author confidence="0.960728">Fondazione Bruno</author>
<affiliation confidence="0.781705">University of Trento,</affiliation>
<email confidence="0.988424">ngoc@fbk.eu</email>
<title confidence="0.34741">Octavian</title>
<author confidence="0.73003">Fondazione Bruno</author>
<affiliation confidence="0.691392">Trento,</affiliation>
<email confidence="0.982658">popescu@fbk.eu</email>
<affiliation confidence="0.416857">Tommaso</affiliation>
<address confidence="0.570359">Trento,</address>
<email confidence="0.99827">t.caselli@trentorise.eu</email>
<abstract confidence="0.999645214285714">This paper reports the description and scores of our system, FBK-TR, which participated at the SemEval 2014 task tional Semantic Models on Full Sentences through Semantic Relatedness and Entailment&amp;quot;. The system consists of two parts: one for computing semantic relatedness, based on SVM, and the other for identifying the entailment values on the basis of both semantic relatedness scores and entailment patterns based on verb-specific frames. The system ranked on both tasks with competitive results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet Allocation.</title>
<date>2003</date>
<journal>The Journal of Machine Learning research,</journal>
<pages>3--993</pages>
<contexts>
<context position="5527" citStr="Blei et al., 2003" startWordPosition="823" endWordPosition="826">National Corpus (BNC) 1 and Wikipedia. At this level of analysis, we concentrated only on the best matched (lemma) pairs of content words, i.e. Noun-Noun, Verb-Verb, extracted from each sentence pair. The content words have been automatically extracted by means of part-of-speech tagging (TreeTagger (Schmid, 1994)) and lemmatization. For words which are not present in WordNet, the relatedness score has been obtained by means of the Levenshtein distance (Levenshtein, 1966). 1http://www.natcorp.ox.ac.uk 2.2 Topic Modeling We have applied topic modeling based on Latent Dirichlet allocation (LDA) (Blei et al., 2003) as implemented in the MALLET package (McCallum, 2002). The topic model was developed using the BNC and Wikipedia (with the numbers of topics varying from 20 to 500 topics). From the proportion vectors (distribution of documents over topics) of the given texts, we apply 3 different measures (Cosine similarity, Kullback-Leibler and Jensen-Shannon divergences) to compute the distances between each pair of sentences. 2.3 String Similarity: Longest Common Substring As for the string level, two given sentences are considered similar/related if they are overlapping/covering each other (e.g sentence </context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent Dirichlet Allocation. The Journal of Machine Learning research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A Library for Support Vector Machines.</title>
<date>2011</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>2--3</pages>
<contexts>
<context position="3331" citStr="Chang and Lin, 2011" startWordPosition="500" endWordPosition="503"> textual entailment subtask, system outputs are evaluated against a gold standard rating with respect to accuracy. Our team, FBK-TR, participated in both subtasks with five different runs. In this paper, we present a comprehensive description of our system which obtained competitive results in both tasks and which is not based on CDSMs. Our approach for the relatedness task is based on machine learning techniques to learn models from different lexical and semantic features from the train corpus and then to make prediction on the test corpus. Particularly, we used support vector machine (SVM) (Chang and Lin, 2011), regression model to solve this subtask. On the other hand, the textual entailment task uses a methodology mainly based on corpus patterns automatically extracted from annotated text corpora. The remainder of the paper is organized as follows: Section 2 presents the SVM system for semantic relatedness. Section 3 describes the methodology used for extracting patterns and computing the textual entailment values. Finally, Section 4 discusses about the evaluations and Section 5 presents conclusions and future work. 289 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval </context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A Library for Support Vector Machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Hanks</author>
</authors>
<title>Mapping meaning onto use: a Pattern Dictionary of English Verbs.</title>
<date>2008</date>
<booktitle>In Proceedings of the AACL</booktitle>
<contexts>
<context position="8885" citStr="Hanks, 2008" startWordPosition="1371" endWordPosition="1372">ite verbs from BNC and Annotated English Gigaword. We parsed this corpus with the Stanford parser, discarding the sentences from the Annotated English Gigaword which have a different parsing. Each words is replaced with their possible SUMO attributes (Niles and Pease, 2003). Only the following Stanford dependencies are retained as valid [n, nsub]sbj, [d,i,p]obj, prep, [x,c]comp. We considered only the most frequent occurrences of such patterns for each verb. To cluster into a single SDP pattern, all patterns that are sense auto-determinative, we used the OntoNotes (Hovy et al., 2006) and CPA (Hanks, 2008) lexica. Inside each cluster, we searched for the most general hypernyms for each syntactic slot such that there are no common patterns between clusters (Popescu, 2013). However, the patterns thus obtained are not sufficient enough for the task. Some expressions may be the paraphrasis a word in the context of an SDP. To extract this information, we considered all the pairs in training that are in an ENTAILMENT relationship, with a high relatedness score (4 to 5), and we extracted the parts that are different for each grammatical slot. In this way, we compiled a list of quasi synonym phrases th</context>
</contexts>
<marker>Hanks, 2008</marker>
<rawString>Patrick Hanks. 2008. Mapping meaning onto use: a Pattern Dictionary of English Verbs. In Proceedings of the AACL 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>OntoNotes: The 90% Solution.</title>
<date>2006</date>
<booktitle>In Proceedings of the human language technology conference of the NAACL, Companion Volume: Short Papers,</booktitle>
<pages>57--60</pages>
<contexts>
<context position="8863" citStr="Hovy et al., 2006" startWordPosition="1365" endWordPosition="1368">ontaining at maximum two finite verbs from BNC and Annotated English Gigaword. We parsed this corpus with the Stanford parser, discarding the sentences from the Annotated English Gigaword which have a different parsing. Each words is replaced with their possible SUMO attributes (Niles and Pease, 2003). Only the following Stanford dependencies are retained as valid [n, nsub]sbj, [d,i,p]obj, prep, [x,c]comp. We considered only the most frequent occurrences of such patterns for each verb. To cluster into a single SDP pattern, all patterns that are sense auto-determinative, we used the OntoNotes (Hovy et al., 2006) and CPA (Hanks, 2008) lexica. Inside each cluster, we searched for the most general hypernyms for each syntactic slot such that there are no common patterns between clusters (Popescu, 2013). However, the patterns thus obtained are not sufficient enough for the task. Some expressions may be the paraphrasis a word in the context of an SDP. To extract this information, we considered all the pairs in training that are in an ENTAILMENT relationship, with a high relatedness score (4 to 5), and we extracted the parts that are different for each grammatical slot. In this way, we compiled a list of qu</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. OntoNotes: The 90% Solution. In Proceedings of the human language technology conference of the NAACL, Companion Volume: Short Papers, pages 57–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Peter W Foltz</author>
<author>Darrell Laham</author>
</authors>
<title>An Introduction to Latent Semantic Analysis. Discourse processes,</title>
<date>1998</date>
<pages>25--2</pages>
<contexts>
<context position="4871" citStr="Landauer et al., 1998" startWordPosition="725" endWordPosition="728">rdNet based measures, Wikipedia relatedness and Latent Semantic Analysis), to sentence level, including topic modeling based on Latent Dirichlet allocation (LDA) and string similarity (Longest Common Substring). 2.1 Lexical Features At the lexical level, we built a simple, yet effective Semantic Word Relatedness model, which consists of 3 components: WordNet similarity (based on the Lin measure as implemented in Pedersen package WordNet:Similarity (Pedersen et al., 2004), Wikipedia relatedness (as provided by the Wikipedia Miner package (Milne and Witten, 2013)), and Latent Semantic Analysis (Landauer et al., 1998), with a model trained on the British National Corpus (BNC) 1 and Wikipedia. At this level of analysis, we concentrated only on the best matched (lemma) pairs of content words, i.e. Noun-Noun, Verb-Verb, extracted from each sentence pair. The content words have been automatically extracted by means of part-of-speech tagging (TreeTagger (Schmid, 1994)) and lemmatization. For words which are not present in WordNet, the relatedness score has been obtained by means of the Levenshtein distance (Levenshtein, 1966). 1http://www.natcorp.ox.ac.uk 2.2 Topic Modeling We have applied topic modeling based </context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>Thomas K Landauer, Peter W Foltz, and Darrell Laham. 1998. An Introduction to Latent Semantic Analysis. Discourse processes, 25(2-3):259–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir I Levenshtein</author>
</authors>
<title>Binary Codes Capable of Correcting Deletions, Insertions and Reversals.</title>
<date>1966</date>
<booktitle>In Soviet Physics Doklady,</booktitle>
<volume>10</volume>
<pages>707</pages>
<contexts>
<context position="5384" citStr="Levenshtein, 1966" startWordPosition="806" endWordPosition="807">e Wikipedia Miner package (Milne and Witten, 2013)), and Latent Semantic Analysis (Landauer et al., 1998), with a model trained on the British National Corpus (BNC) 1 and Wikipedia. At this level of analysis, we concentrated only on the best matched (lemma) pairs of content words, i.e. Noun-Noun, Verb-Verb, extracted from each sentence pair. The content words have been automatically extracted by means of part-of-speech tagging (TreeTagger (Schmid, 1994)) and lemmatization. For words which are not present in WordNet, the relatedness score has been obtained by means of the Levenshtein distance (Levenshtein, 1966). 1http://www.natcorp.ox.ac.uk 2.2 Topic Modeling We have applied topic modeling based on Latent Dirichlet allocation (LDA) (Blei et al., 2003) as implemented in the MALLET package (McCallum, 2002). The topic model was developed using the BNC and Wikipedia (with the numbers of topics varying from 20 to 500 topics). From the proportion vectors (distribution of documents over topics) of the given texts, we apply 3 different measures (Cosine similarity, Kullback-Leibler and Jensen-Shannon divergences) to compute the distances between each pair of sentences. 2.3 String Similarity: Longest Common S</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>Vladimir I Levenshtein. 1966. Binary Codes Capable of Correcting Deletions, Insertions and Reversals. In Soviet Physics Doklady, volume 10, page 707.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marelli</author>
<author>L Bentivogli</author>
<author>M Baroni</author>
<author>R Bernardi</author>
<author>S Menini</author>
<author>R Zamparelli</author>
</authors>
<title>Semeval-2014 Task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment.</title>
<date>2014</date>
<booktitle>In Proceedings of SemEval 2014: International Workshop on Semantic Evaluation,</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="2173" citStr="Marelli et al., 2014" startWordPosition="325" endWordPosition="328">ion of several annotators. The RTE task requires the identification of a directional relation between a pair of text fragments, namely a text (T) and a hypothesis (H). The relation (T → H) holds whenever the truth of H follows from T. This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ At SemEval 2014, the Task #1 &amp;quot;Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Entailment&amp;quot; (Marelli et al., 2014a) primarily aimed at evaluating Compositional Distributional Semantic Models (CDSMs) of meaning over two subtasks, namely semantic relatedness and textual entailment (ENTAILMENT, CONTRADICTION and NEUTRAL), over pairs of sentences (Marelli et al., 2014b). Concerning the relatedness subtask, the system outputs are evaluated against gold standard ratings in two ways, using Pearson correlation and Spearman’s rank correlation (rho). The Pearson correlation is used for evaluating and ranking the participating systems. Similarly, for the textual entailment subtask, system outputs are evaluated agai</context>
</contexts>
<marker>Marelli, Bentivogli, Baroni, Bernardi, Menini, Zamparelli, 2014</marker>
<rawString>M Marelli, L Bentivogli, M Baroni, R Bernardi, S Menini, and R Zamparelli. 2014a. Semeval-2014 Task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment. In Proceedings of SemEval 2014: International Workshop on Semantic Evaluation, August 23-24, 2014, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marelli</author>
<author>S Menini</author>
<author>M Baroni</author>
<author>L Bentivogli</author>
<author>R Bernardi</author>
<author>R Zamparelli</author>
</authors>
<title>A SICK cure for the evaluation of compositional distributional semantic models.</title>
<date>2014</date>
<booktitle>In Proceedings of LREC 2014,</booktitle>
<publisher>ELRA.</publisher>
<location>Reykjavik (Iceland):</location>
<contexts>
<context position="2173" citStr="Marelli et al., 2014" startWordPosition="325" endWordPosition="328">ion of several annotators. The RTE task requires the identification of a directional relation between a pair of text fragments, namely a text (T) and a hypothesis (H). The relation (T → H) holds whenever the truth of H follows from T. This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ At SemEval 2014, the Task #1 &amp;quot;Evaluation of Compositional Distributional Semantic Models on Full Sentences through Semantic Relatedness and Entailment&amp;quot; (Marelli et al., 2014a) primarily aimed at evaluating Compositional Distributional Semantic Models (CDSMs) of meaning over two subtasks, namely semantic relatedness and textual entailment (ENTAILMENT, CONTRADICTION and NEUTRAL), over pairs of sentences (Marelli et al., 2014b). Concerning the relatedness subtask, the system outputs are evaluated against gold standard ratings in two ways, using Pearson correlation and Spearman’s rank correlation (rho). The Pearson correlation is used for evaluating and ranking the participating systems. Similarly, for the textual entailment subtask, system outputs are evaluated agai</context>
</contexts>
<marker>Marelli, Menini, Baroni, Bentivogli, Bernardi, Zamparelli, 2014</marker>
<rawString>M Marelli, S Menini, M Baroni, L Bentivogli, R Bernardi, and R Zamparelli. 2014b. A SICK cure for the evaluation of compositional distributional semantic models. In Proceedings of LREC 2014, Reykjavik (Iceland): ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>MALLET: A Machine Learning for Language Toolkit.</title>
<date>2002</date>
<contexts>
<context position="5581" citStr="McCallum, 2002" startWordPosition="833" endWordPosition="835">nalysis, we concentrated only on the best matched (lemma) pairs of content words, i.e. Noun-Noun, Verb-Verb, extracted from each sentence pair. The content words have been automatically extracted by means of part-of-speech tagging (TreeTagger (Schmid, 1994)) and lemmatization. For words which are not present in WordNet, the relatedness score has been obtained by means of the Levenshtein distance (Levenshtein, 1966). 1http://www.natcorp.ox.ac.uk 2.2 Topic Modeling We have applied topic modeling based on Latent Dirichlet allocation (LDA) (Blei et al., 2003) as implemented in the MALLET package (McCallum, 2002). The topic model was developed using the BNC and Wikipedia (with the numbers of topics varying from 20 to 500 topics). From the proportion vectors (distribution of documents over topics) of the given texts, we apply 3 different measures (Cosine similarity, Kullback-Leibler and Jensen-Shannon divergences) to compute the distances between each pair of sentences. 2.3 String Similarity: Longest Common Substring As for the string level, two given sentences are considered similar/related if they are overlapping/covering each other (e.g sentence 1 covers a part of sentence 2, or otherwise). Hence, w</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. MALLET: A Machine Learning for Language Toolkit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>An OpenSource Toolkit for Mining Wikipedia.</title>
<date>2013</date>
<journal>Artificial Intelligence,</journal>
<pages>194--222</pages>
<contexts>
<context position="4816" citStr="Milne and Witten, 2013" startWordPosition="717" endWordPosition="720">tures, ranging from relatedness at the lexical level (WordNet based measures, Wikipedia relatedness and Latent Semantic Analysis), to sentence level, including topic modeling based on Latent Dirichlet allocation (LDA) and string similarity (Longest Common Substring). 2.1 Lexical Features At the lexical level, we built a simple, yet effective Semantic Word Relatedness model, which consists of 3 components: WordNet similarity (based on the Lin measure as implemented in Pedersen package WordNet:Similarity (Pedersen et al., 2004), Wikipedia relatedness (as provided by the Wikipedia Miner package (Milne and Witten, 2013)), and Latent Semantic Analysis (Landauer et al., 1998), with a model trained on the British National Corpus (BNC) 1 and Wikipedia. At this level of analysis, we concentrated only on the best matched (lemma) pairs of content words, i.e. Noun-Noun, Verb-Verb, extracted from each sentence pair. The content words have been automatically extracted by means of part-of-speech tagging (TreeTagger (Schmid, 1994)) and lemmatization. For words which are not present in WordNet, the relatedness score has been obtained by means of the Levenshtein distance (Levenshtein, 1966). 1http://www.natcorp.ox.ac.uk 2</context>
</contexts>
<marker>Milne, Witten, 2013</marker>
<rawString>David Milne and Ian H Witten. 2013. An OpenSource Toolkit for Mining Wikipedia. Artificial Intelligence, 194:222–239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Niles</author>
<author>Adam Pease</author>
</authors>
<title>Mapping WordNet to the SUMO Ontology.</title>
<date>2003</date>
<booktitle>In Proceedings of the IEEE International Knowledge Engineering Conference,</booktitle>
<pages>23--26</pages>
<contexts>
<context position="8547" citStr="Niles and Pease, 2003" startWordPosition="1315" endWordPosition="1318"> we can associate to a phrase that is matched by an SDP a set of phrases for which an entailment relationship is decidable showing that there is a direct relationship between SDPs and entailment. SDP patterns have been obtained from large parsed corpora. To maximize the accuracy of the corpus we have chosen sentences containing at maximum two finite verbs from BNC and Annotated English Gigaword. We parsed this corpus with the Stanford parser, discarding the sentences from the Annotated English Gigaword which have a different parsing. Each words is replaced with their possible SUMO attributes (Niles and Pease, 2003). Only the following Stanford dependencies are retained as valid [n, nsub]sbj, [d,i,p]obj, prep, [x,c]comp. We considered only the most frequent occurrences of such patterns for each verb. To cluster into a single SDP pattern, all patterns that are sense auto-determinative, we used the OntoNotes (Hovy et al., 2006) and CPA (Hanks, 2008) lexica. Inside each cluster, we searched for the most general hypernyms for each syntactic slot such that there are no common patterns between clusters (Popescu, 2013). However, the patterns thus obtained are not sufficient enough for the task. Some expressions</context>
</contexts>
<marker>Niles, Pease, 2003</marker>
<rawString>Ian Niles and Adam Pease. 2003. Mapping WordNet to the SUMO Ontology. In Proceedings of the IEEE International Knowledge Engineering Conference, pages 23–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Patwardhan Siddharth</author>
<author>Michelizzi Jason</author>
</authors>
<title>Wordnet::Similarity: Measuring the Relatedness of Concepts.</title>
<date>2004</date>
<booktitle>In Proceedings of the HLT-NAACL</booktitle>
<contexts>
<context position="4724" citStr="Pedersen et al., 2004" startWordPosition="704" endWordPosition="707">erning the Semantic Relatedness subtask our SVM system is built on different linguistic features, ranging from relatedness at the lexical level (WordNet based measures, Wikipedia relatedness and Latent Semantic Analysis), to sentence level, including topic modeling based on Latent Dirichlet allocation (LDA) and string similarity (Longest Common Substring). 2.1 Lexical Features At the lexical level, we built a simple, yet effective Semantic Word Relatedness model, which consists of 3 components: WordNet similarity (based on the Lin measure as implemented in Pedersen package WordNet:Similarity (Pedersen et al., 2004), Wikipedia relatedness (as provided by the Wikipedia Miner package (Milne and Witten, 2013)), and Latent Semantic Analysis (Landauer et al., 1998), with a model trained on the British National Corpus (BNC) 1 and Wikipedia. At this level of analysis, we concentrated only on the best matched (lemma) pairs of content words, i.e. Noun-Noun, Verb-Verb, extracted from each sentence pair. The content words have been automatically extracted by means of part-of-speech tagging (TreeTagger (Schmid, 1994)) and lemmatization. For words which are not present in WordNet, the relatedness score has been obtai</context>
</contexts>
<marker>Pedersen, Siddharth, Jason, 2004</marker>
<rawString>Ted Pedersen, Patwardhan Siddharth, and Michelizzi Jason. 2004. Wordnet::Similarity: Measuring the Relatedness of Concepts. In Proceedings of the HLT-NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Octavian Popescu</author>
<author>Elena Cabrio</author>
<author>Bernardo Magnini</author>
</authors>
<title>Textual Entailment Using Chain Clarifying Relationships.</title>
<date>2011</date>
<booktitle>In Proceedings of the IJCAI Workshop Learning by Reasoning and its Applications in Intelligent Question-Answering.</booktitle>
<contexts>
<context position="7920" citStr="Popescu et al., 2011" startWordPosition="1212" endWordPosition="1215">information. Hence, we have explicit access to the information that individual words have and to the process of combining them in bigger units, namely phrases, which carry out meanings. The patterns have two properties: i.) the senses of the words inside the pattern are stable, they do not change whatever context is added to the left, right or inside the phrase matching the pattern, and ii.) the replacement of a word with another word belonging to a certain class changes the senses of the words. Patterns with these properties are called Sense Discriminative Patterns (SDPs). It has been noted (Popescu et al., 2011) that we can associate to a phrase that is matched by an SDP a set of phrases for which an entailment relationship is decidable showing that there is a direct relationship between SDPs and entailment. SDP patterns have been obtained from large parsed corpora. To maximize the accuracy of the corpus we have chosen sentences containing at maximum two finite verbs from BNC and Annotated English Gigaword. We parsed this corpus with the Stanford parser, discarding the sentences from the Annotated English Gigaword which have a different parsing. Each words is replaced with their possible SUMO attribu</context>
</contexts>
<marker>Popescu, Cabrio, Magnini, 2011</marker>
<rawString>Octavian Popescu, Elena Cabrio, and Bernardo Magnini. 2011. Textual Entailment Using Chain Clarifying Relationships. In Proceedings of the IJCAI Workshop Learning by Reasoning and its Applications in Intelligent Question-Answering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Octavian Popescu</author>
</authors>
<title>Learning Corpus Patterns Using Finite State Automata.</title>
<date>2013</date>
<booktitle>In Proceedings of the ICSC</booktitle>
<contexts>
<context position="9053" citStr="Popescu, 2013" startWordPosition="1398" endWordPosition="1399">have a different parsing. Each words is replaced with their possible SUMO attributes (Niles and Pease, 2003). Only the following Stanford dependencies are retained as valid [n, nsub]sbj, [d,i,p]obj, prep, [x,c]comp. We considered only the most frequent occurrences of such patterns for each verb. To cluster into a single SDP pattern, all patterns that are sense auto-determinative, we used the OntoNotes (Hovy et al., 2006) and CPA (Hanks, 2008) lexica. Inside each cluster, we searched for the most general hypernyms for each syntactic slot such that there are no common patterns between clusters (Popescu, 2013). However, the patterns thus obtained are not sufficient enough for the task. Some expressions may be the paraphrasis a word in the context of an SDP. To extract this information, we considered all the pairs in training that are in an ENTAILMENT relationship, with a high relatedness score (4 to 5), and we extracted the parts that are different for each grammatical slot. In this way, we compiled a list of quasi synonym phrases that can be replaced inside an SDP without affecting the replacement. This is the only component that depends on the training corpus. Figure 2 describes the algorithm for</context>
</contexts>
<marker>Popescu, 2013</marker>
<rawString>Octavian Popescu. 2013. Learning Corpus Patterns Using Finite State Automata. In Proceedings of the ICSC 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic Part-of-Sspeech Tagging Using Decision Trees.</title>
<date>1994</date>
<booktitle>In Proceedings of international conference on new methods in language processing,</booktitle>
<volume>12</volume>
<pages>44--49</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="5223" citStr="Schmid, 1994" startWordPosition="782" endWordPosition="783">similarity (based on the Lin measure as implemented in Pedersen package WordNet:Similarity (Pedersen et al., 2004), Wikipedia relatedness (as provided by the Wikipedia Miner package (Milne and Witten, 2013)), and Latent Semantic Analysis (Landauer et al., 1998), with a model trained on the British National Corpus (BNC) 1 and Wikipedia. At this level of analysis, we concentrated only on the best matched (lemma) pairs of content words, i.e. Noun-Noun, Verb-Verb, extracted from each sentence pair. The content words have been automatically extracted by means of part-of-speech tagging (TreeTagger (Schmid, 1994)) and lemmatization. For words which are not present in WordNet, the relatedness score has been obtained by means of the Levenshtein distance (Levenshtein, 1966). 1http://www.natcorp.ox.ac.uk 2.2 Topic Modeling We have applied topic modeling based on Latent Dirichlet allocation (LDA) (Blei et al., 2003) as implemented in the MALLET package (McCallum, 2002). The topic model was developed using the BNC and Wikipedia (with the numbers of topics varying from 20 to 500 topics). From the proportion vectors (distribution of documents over topics) of the given texts, we apply 3 different measures (Cos</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic Part-of-Sspeech Tagging Using Decision Trees. In Proceedings of international conference on new methods in language processing, volume 12, pages 44–49. Manchester, UK.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>