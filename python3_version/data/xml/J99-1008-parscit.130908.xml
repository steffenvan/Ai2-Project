<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.031434">
<title confidence="0.584798">
Briefly Noted
Les linguistiques de corpus
</title>
<author confidence="0.442262">
Benoit Habert, Adeline Nazarenko, and
André Salem
</author>
<bodyText confidence="0.983708817073171">
(ENS de Fontenay-Saint-Cloud, Universite
Paris-XIII, and Universite Paris-III)
Paris: Editions Armand Colin, 1997, 240 pp;
paperbound, ISBN 2-200-01775-8, FF 125.00
In Les linguistiques de corpus, newcomers as
well as experts in the field will find a very
interesting, well-written, and concise survey
of corpus linguistics. The book gives a good
overview of the multiple methods used and
the problems involved in the creation and
the annotation of a corpus. It also presents
proposed applications for these corpora. The
authors do not relate their own work, but
present to the reader in an organized way
(by topic) the work of many researchers. The
book is written in French, but most of the
works presented are based on corpora of En-
glish texts.
Among other things, the authors discuss
what makes a &amp;quot;good corpus,&amp;quot; how represen-
tative and reliable a corpus can be, and what
corpora annotated at the lexical, syntactic, or
semantic level presently exist. They analyze
the interesting problem of the dependency
of a corpus annotation on the foreseen appli-
cations for the corpus. The authors present
applications such as word sense disambig-
uation and lexical acquisition from text, but
they also present different applications that
are of more concern to the literary commu-
nity, such as discovering changes in the us-
age of a word between periods or between
authors.
In the authors&apos; view (which I certainly
share and consider very positive), corpus lin-
guistics leaves linguists (and language spe-
cialists) and computer scientists no choice
but to finally come together and use each
other&apos;s strengths (deep understanding of lan-
guage and deep understanding of computer
technology); they must share their expertise
to push the field forward.—Caroline Barriere,
School of Information Technology and Engineer-
ing, University of Ottawa, Canada
Text Retrieval and Filtering: Analytic
Models of Performance
Robert M. Losee
(University of North Carolina)
Boston: Kluwer Academic Publishers (The
Kluwer international series on information
retrieval, edited by W. Bruce Croft), 1998,
x+242 pp; hardbound, ISBN 0-7923-8177-7,
$115.00, £78.25, Dfl 260.00
This is the first book that addresses the prob-
lem of analytically computing the perfor-
mance of text retrieval and filtering systems.
It describes means by which retrieval may
be studied analytically, allowing one to de-
scribe current performance, to predict future
performance, and to understand why sys-
tems perform as they do. The focus is on re-
trieving and filtering natural language text—
full sentences as well as phrases and indi-
vidual words. The book addresses retrieval
performance for the simple case of queries
with a single term, for the more complex
case with multiple terms (both with term
independence and term dependence), and
for the use of grammatical information to
improve performance. Unambiguous state-
ments of the conditions under which one
method or system will be more effective
than another are developed. The last chapter
explicitly addresses how grammatical con-
structs and methods may be studied in the
context of retrieval or filtering system per-
formance. The book builds towards solving
this problem, although the material in ear-
lier chapters is as useful to those address-
ing nonlinguistic, statistical concerns as it is
to linguists.—Based on the publisher&apos;s announce-
ment
</bodyText>
<page confidence="0.980134">
170
</page>
<figure confidence="0.5229956">
Briefly Noted
Linguistic Specifications for Typed Fea-
ture Structure Formalisms
Frank Van Eynde and Paul Schmidt
(editors)
</figure>
<bodyText confidence="0.98553574137931">
(Katholieke Universiteit Leuven and Univer-
sitat des Saarlandes)
Luxembourg: Office for Official Publications
of the European Communities (Studies in
machine translation and natural language
processing, edited by Erwin Valentini,
volume 10), 1998, 344 pp; paperbound, ISSN
1017-6568, ECU 15.00
&amp;quot;This volume is an abridged and revised ver-
sion of the final report of the project &amp;quot;Inves-
tigation of Linguistic Specifications for Fu-
ture Industrial Standards&amp;quot;. This project was
part of the Multilingual Action Plan of the
European Union (1994-1995) and was car-
ried out by a consortium of seven research
institutes....
&amp;quot;The purpose of the project was the de-
velopment of linguistic specifications for
TFS-based formalisms, i.e. formalisms which
make use of typed feature structures
(TFS) for the representation of linguistic
information.... These specifications are not
geared to any particular language, but pro-
vided a starting point for the development of
more detailed specifications for a number of
individual languages.... The linguistic spec-
ifications which will be presented in this vol-
ume ... aim at compatibility with any kind
of TFS-based formalism.
&amp;quot;Apart from compatibility with this fam-
ily of NLP formalisms there are a number of
further requirements which the specifications
aim to fulfill, such as breadth of coverage,
internal coherence and multilingual orienta-
tion. On a more technical level the specifica-
tions are required to be monostratal, lexical-
ist and constraint-based. Since these are the
main characteristics of Head-driven Phrase
Structure Grammar, it will not come as a sur-
prise that HPSG forms the point of departure
for most of the work which will be presented
in this volume.&amp;quot;—From the editors&apos; introduction
The contents of the volume are as follows:
Introduction by Frank Van Eynde and Paul
Schmidt;
&amp;quot;Formal assumptions&amp;quot; by Paul Schmidt;
&amp;quot;Lexical generalisations&amp;quot; by Stella Markanto-
natou and Louisa Sadler;
&amp;quot;Phrase structure&amp;quot; by Paul Bennett and Paul
Schmidt;
&amp;quot;Predicate-argument structure&amp;quot; by Toni Ba-
dia and Carme Colominas;
&amp;quot;Tense, aspect and negation&amp;quot; by Frank Van
Eynde;
&amp;quot;Determination and quantification&amp;quot; by Vale-
rio Allegranza;
&amp;quot;Support verb constructions&amp;quot; by Fiammetta
Namer.
</bodyText>
<page confidence="0.99731">
171
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001465">
<title confidence="0.992591">Briefly Noted linguistiques de</title>
<author confidence="0.9275385">Benoit Habert</author>
<author confidence="0.9275385">Adeline Nazarenko</author>
<author confidence="0.9275385">André Salem</author>
<affiliation confidence="0.8656635">(ENS de Fontenay-Saint-Cloud, Universite Paris-XIII, and Universite Paris-III)</affiliation>
<address confidence="0.59495">Paris: Editions Armand Colin, 1997, 240 pp; paperbound, ISBN 2-200-01775-8, FF 125.00</address>
<abstract confidence="0.997659921052632">linguistiques de corpus, as well as experts in the field will find a very interesting, well-written, and concise survey of corpus linguistics. The book gives a good overview of the multiple methods used and the problems involved in the creation and the annotation of a corpus. It also presents proposed applications for these corpora. The authors do not relate their own work, but present to the reader in an organized way (by topic) the work of many researchers. The book is written in French, but most of the works presented are based on corpora of English texts. Among other things, the authors discuss what makes a &amp;quot;good corpus,&amp;quot; how representative and reliable a corpus can be, and what corpora annotated at the lexical, syntactic, or semantic level presently exist. They analyze the interesting problem of the dependency of a corpus annotation on the foreseen applications for the corpus. The authors present applications such as word sense disambiguation and lexical acquisition from text, but they also present different applications that are of more concern to the literary community, such as discovering changes in the usage of a word between periods or between authors. In the authors&apos; view (which I certainly share and consider very positive), corpus linguistics leaves linguists (and language specialists) and computer scientists no choice but to finally come together and use each other&apos;s strengths (deep understanding of language and deep understanding of computer technology); they must share their expertise push the field forward.—Caroline</abstract>
<affiliation confidence="0.947486">School of Information Technology and Engineer-</affiliation>
<address confidence="0.83649">ing, University of Ottawa, Canada</address>
<title confidence="0.957601">Text Retrieval and Filtering: Analytic Models of Performance</title>
<author confidence="0.999977">Robert M Losee</author>
<affiliation confidence="0.813853">(University of North Carolina)</affiliation>
<note confidence="0.895816333333333">Boston: Kluwer Academic Publishers (The Kluwer international series on information retrieval, edited by W. Bruce Croft), 1998,</note>
<abstract confidence="0.9479495625">x+242 pp; hardbound, ISBN 0-7923-8177-7, $115.00, £78.25, Dfl 260.00 This is the first book that addresses the problem of analytically computing the performance of text retrieval and filtering systems. It describes means by which retrieval may be studied analytically, allowing one to describe current performance, to predict future performance, and to understand why systems perform as they do. The focus is on retrieving and filtering natural language text— full sentences as well as phrases and individual words. The book addresses retrieval performance for the simple case of queries with a single term, for the more complex case with multiple terms (both with term independence and term dependence), and for the use of grammatical information to improve performance. Unambiguous statements of the conditions under which one method or system will be more effective than another are developed. The last chapter explicitly addresses how grammatical constructs and methods may be studied in the context of retrieval or filtering system performance. The book builds towards solving this problem, although the material in earlier chapters is as useful to those addressing nonlinguistic, statistical concerns as it is linguists.—Based the publisher&apos;s announcement 170</abstract>
<title confidence="0.975305333333333">Briefly Noted Linguistic Specifications for Typed Feature Structure Formalisms</title>
<author confidence="0.999854">Frank Van_Eynde</author>
<author confidence="0.999854">Paul Schmidt</author>
<email confidence="0.786775">(editors)</email>
<degree confidence="0.5187726">(Katholieke Universiteit Leuven and Universitat des Saarlandes) Luxembourg: Office for Official Publications of the European Communities (Studies in machine translation and natural language</degree>
<author confidence="0.48021">edited by Erwin Valentini processing</author>
<address confidence="0.552397">volume 10), 1998, 344 pp; paperbound, ISSN 1017-6568, ECU 15.00</address>
<abstract confidence="0.985875151515152">amp;quot;This volume is an abridged and revised version of the final report of the project &amp;quot;Investigation of Linguistic Specifications for Future Industrial Standards&amp;quot;. This project was part of the Multilingual Action Plan of the European Union (1994-1995) and was carried out by a consortium of seven research institutes.... &amp;quot;The purpose of the project was the development of linguistic specifications for TFS-based formalisms, i.e. formalisms which make use of typed feature structures (TFS) for the representation of linguistic information.... These specifications are not geared to any particular language, but provided a starting point for the development of more detailed specifications for a number of individual languages.... The linguistic specifications which will be presented in this volume ... aim at compatibility with any kind of TFS-based formalism. &amp;quot;Apart from compatibility with this family of NLP formalisms there are a number of further requirements which the specifications aim to fulfill, such as breadth of coverage, internal coherence and multilingual orientation. On a more technical level the specifications are required to be monostratal, lexicalist and constraint-based. Since these are the main characteristics of Head-driven Phrase Structure Grammar, it will not come as a surprise that HPSG forms the point of departure for most of the work which will be presented</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>