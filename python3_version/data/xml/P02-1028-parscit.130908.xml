<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<note confidence="0.457164">
Proceedings of the 40th Annual Meeting of the Association for
Computational Linguistics (ACL), Philadelphia, July 2002, pp. 215-222.
</note>
<bodyText confidence="0.998113625">
pattern of B or C might be different from that
of A (in case of Japanese, case markers might
change).
This paper proposes a method to solve these
problems simultaneously by aligning case frames
of A and those of B and C. We utilize wide cov-
erage and specific enough case frames which are
automatically constructed from a raw corpus.
</bodyText>
<sectionHeader confidence="0.946645" genericHeader="abstract">
2 Dictionary based Paraphrase
</sectionHeader>
<subsectionHeader confidence="0.901591">
2.1 Basic Idea
</subsectionHeader>
<bodyText confidence="0.999934230769231">
An ordinary dictionary provides us with defini-
tions of headwords in simpler words and expres-
sions. In case of verbs, the head of the definition
(we call it a def-head hereafter) and the adverb
modifying the def-head, if any, are an equivalent
of the headword and can be used as a paraphrase
of it. For example, the definition of chiratstdat
(shimmer) is as follows:
chiratsuku (shimmer) yowaku hikaru (shine
faintly).
The def-head, &amp;quot;shine&amp;quot; and its modifier &amp;quot;faintly&amp;quot;
can be seen as an equivalent of chiratstdat (shim-
mer), and can be used as a paraphrase as follows:
</bodyText>
<listItem confidence="0.8835845">
• The lamp shimmers —&gt; The lamp shines
faintly
</listItem>
<subsectionHeader confidence="0.7702">
2.2 Difficulties
</subsectionHeader>
<bodyText confidence="0.961341714285714">
Replacing a headword with the def-head and the
adverb, however, does not always work because
of the following problems.
Word sense ambiguity
When a headword has two or more meanings,
the meaning of the headword in a given context
must be chosen. For example, keitott (devote)
has the following two meanings.
keitou (devote) 1 necchuu (be enthusiastic).
2 shitau (admire)
If an input is &amp;quot;literature ni keitou-suru (devote
oneself to literature)&amp;quot;, keitott has the first mean-
ing and the input should be paraphrased into
&amp;quot;literature ni nechuu-suru&amp;quot;12. If an input is
</bodyText>
<footnote confidence="0.98420975">
1In Japanese, postpositions function as case markers
and a verb is final in a sentence
2Nouns in definitions and case frames are given in En-
glish translation in this paper.
</footnote>
<bodyText confidence="0.985829714285714">
&amp;quot;Lincoln ni keitou-suru (devote oneself to Lin-
coln)&amp;quot;, keitott has the second meaning and the
input should be paraphrased into &amp;quot;Lincoln wo
shitau (admire Lincoln) &amp;quot; .
Size of the equivalent
Sometimes, the equivalent of a headword is
larger than the def-head and its modifier. For
example, as shown below, the equivalent of
&amp;quot;taitoku (acquire)&amp;quot; is not &amp;quot;tsukeru (get)&amp;quot;, but
&amp;quot;mi ni tsukeru (get for oneself)&amp;quot;.
taitoku (acquire) knowledge ya skill wo mi ni
tsukeru (get knowledge or skill for oneself).
Transformation of case marker
When the verb is paraphrased to its equiva-
lent, the sentential pattern (case markers) might
have to be modified. For example, when &amp;quot;mis-
take wo miotosu (overlook a mistake)&amp;quot; is para-
phrased by the following definition of &amp;quot;miotosu
(overlook)&amp;quot;, &amp;quot;mistake&amp;quot; shoule be transformed
from wo case to ni case.
miotosu (overlook) kizukanai (not notice).
</bodyText>
<subsectionHeader confidence="0.8244955">
2.3 Verb Paraphrase based on Case
Frame Alignment
</subsectionHeader>
<bodyText confidence="0.999935333333333">
The problems mentioned above can be solved
by finding a correspondence between an input
and definitions. However, such a correspondence
is very hard to find since predicate-argument
structure of the def-head is not fully given in
the definition, and the input also contains some
omissions. That is, the information is too small
to find an appropriate correspondence.
For example, as shown above, keitott has two
meanings, but there is no information about its
arguments in the dictionary. It is almost im-
possible to find which definition should be used
in what way to paraphrase &amp;quot;literature ni keitou-
suru (devote oneself to literature)&amp;quot;.
Then, we have developed a method which
grasps several usages of a headword and those
of the def-heads as a form of their case frames
and aligns those case frames, which means the
acquisition of word sense disambiguation rules
and the detection of the appropriate equivalent
and case marker transformation. Case frames
</bodyText>
<figure confidence="0.996908946808511">
ga
{experience:1} tsumu
wo
1 Case Frames of necchuu ( to be enthusiastic )
Case Frames of keitou ( to devote )
predicate-argument examples
initial case frames
{player, he...} ga {golf, soccer...}ni
{students, children...} {soccer, tennnis...}
ga
ni
ni
ni
2 Case Frames of shitau ( to admire )
{son, she... } {music}
ga ni
{she, I...} {president}
ga ni
Dictionary
keitou ( to devote )
1 necchuu ( to be enthusiastic )
2 shitau ( to admire )
{parent, people...} {art}
ga
{he, woman...} {computer}
ga
{child, son...} {mother, father... }
ga
wo
{students, he...} {teacher, professor...} wo
ga
{she, I...} ga {president} ni
keitou ( to devote )
{students, he...} ga {teacher, professor...} wo
shitau ( to admire )
{baggage:2}wo tsumu
{worker:1}ga {car: 1}ni
ni
tsumu
{ }
truck:1
airplane:1
{supply:2}wo
{player:1}ga
{experience:1
}wo
tsumu
case frames
ni
truck
wo
ni
supply
wo
airplane
supply
player ga experience
(accumulate)
tsumu
wo
raw corpus
parsing
car ni baggage wo tsumu
(load)
tsumu
(load)
tsumu
(load)
wo
tsumu
(load)
worker ga baggage
car:1 {baggage:2}
ga truck:1 ni wo tsumu
{ } supply:2
airplane:1
{worker:1}
{player:1}
tsumu
wo
F :
1 {worker:3} ga
{car:5} ni
(load)
F :
2
tsumu
wo
ni
{truck:3, airplane:2}
{baggage:8}
1.0 0.86 0.91
{supply:10}
(load)
</figure>
<bodyText confidence="0.460949">
ities of case examples as follows:
</bodyText>
<equation confidence="0.818934333333333">
c2i) —
Eel Ech Ee2EC2, Alleille2HiM(61,62)
Eel Ecli Ee2E,2, A/16111621
</equation>
<bodyText confidence="0.998988625">
where lei and 1e21 represent the frequencies of
el and e2 respectively.
Weighted sum of case component
similarities
The case components&apos; similarities calculated
by the above measure are summed up with the
weight of case components&apos; frequencies as fol-
lows:
</bodyText>
<equation confidence="0.995415">
WSofCCS =
A/IciiIIC2i1..92M(C1 ,C2i)
</equation>
<bodyText confidence="0.647825">
where
</bodyText>
<equation confidence="0.81321">
rid E eu, IC2i1= E 1e21
eiECi e2EC2,
Ratio of aligned case components
</equation>
<bodyText confidence="0.9981625">
The ratio of aligned case components is cal-
culated as follows:
</bodyText>
<equation confidence="0.9397485">
Rof ACC = EL Milx ELu 1C21
Erin=1 1Cli I E7i-L-1 Ic2i I (4)
</equation>
<bodyText confidence="0.996967666666667">
Similarity between two case frames
Finally, similarity between two case frames is
calculated as follows:
</bodyText>
<equation confidence="0.840827">
sim(Fi, F2) = W Sof CC S x Rof ACC (5)
</equation>
<bodyText confidence="0.998912">
Based on this similarity measure, case frames
whose similarity is more than the threshold, 0.9,
are merged.
</bodyText>
<subsectionHeader confidence="0.999814">
3.3 Selection of Case Components
</subsectionHeader>
<bodyText confidence="0.841427625">
If a case component whose frequency is much
lower than other case components in a case
frame, it might be collected because of parsing
errors, or has little relation to its verb. We set
the threshold for the case component frequency
experimentally as follows:
2 x \ (frequency of the most
frequent case component
</bodyText>
<tableCaption confidence="0.999397">
Table 1: Pruning of def-head case frames
</tableCaption>
<table confidence="0.551906909090909">
Obligatory case (ga, wo, ni)
Case-1: book wo read = Case frames whose closest
case component is &amp;quot;book&amp;quot;.
Case-2: book or article wo read = Case frames whose
closest case component is similar to &amp;quot;book&amp;quot; or &amp;quot;arti-
cle&amp;quot;.
Case-3: people ni ask = Case frames whose closest
case component belongs the category &lt; HUMAN &gt;.
Optional case
Case-4: room de read = Case frames similar to the
definition.
</table>
<bodyText confidence="0.998126333333333">
If the frequency of a case component is less than
the threshold, it is discarded. For example, sup-
pose the most frequent case component in a case
frame is wo case, 100 times, and the frequency
of ni case is 16, ni case is discarded (since it is
less than the threshold, 20).
</bodyText>
<sectionHeader confidence="0.996108" genericHeader="keywords">
4 Case Frame Alignment
</sectionHeader>
<bodyText confidence="0.9998296">
This section describes how to align the case
frames of a headword and those of the def-heads,
resulting in word sense disambiguation and de-
tection of equivalents and case marker transfor-
mation.
</bodyText>
<subsectionHeader confidence="0.998291">
4.1 Pruning of Def-Head Case Frames
</subsectionHeader>
<bodyText confidence="0.999621085106383">
When a def-head has sense ambiguity, a part of
its case frames corresponds to headword&apos;s case
frames. Suppose that dokusyo has a definition
&amp;quot;hon wo yomtt(read a book)&amp;quot; and its def-head
is &amp;quot;yomtt (read)&amp;quot;. In the case frame dictio-
nary, there are many case frames of yomtt, such
as &amp;quot;{magazine,article}wo yomtt&amp;quot;or &amp;quot;{mind} wo
yomtt&amp;quot;. But the usage of yomtt in &amp;quot;{mind}wo
yomtt&amp;quot; is obviously different from that in the
definition. So, that case frame will never cor-
respond to headword&apos;s case frame. If all case
frames of the def-head are blindly used, the ac-
curacy of case frame alignment becomes lower.
In order to mitigate such a problem, we utilize
the definition sentence to prune def-head case
frames. The point of this process is similar to
the automatic case frame construction in section
3. That is, we exploit the information of the
closest case component of the def-head.
Table 1 summarizes how to prune def-head
case frames. If the closest case component of
the def-head is an obligatory case (ga, wo, or ni
case), we prune case frames in three ways ac-
cording to the case component word.
If the closest case component of the def-head
is an ordinal noun such as &amp;quot;book wo read&amp;quot; (case-
1 of Table 1), the definition is so specific and
we need to consider only this usage of the def-
head. Therefore, we only use the case frame
whose closest case component contains the same
word in the next alignment step.
If the closest case component has a coordinate
structure such as &amp;quot;book or article&amp;quot; (case-2), the
definition is not so specific as the previous case,
but we probably can limit the usages of the def-
head whose closest case component is similar to
the conjuncts. Therefore, we use the case frames
whose closest case component is very similar to
one of conjucts (word similarity is larger than
0.9).
If the closest case component is a general term
such as &amp;quot;people&amp;quot; (case-3), it specifies the usage
of the def-head categorically. We use the case
frames whose closest case component belongs to
the specified category, that is, has appropriate
semantic markers in the NTT thesaurus as fol-
lows:
</bodyText>
<equation confidence="0.596139">
people/opponent : &lt; HUMAN &gt;
things: &lt; ABSTRACT &gt;
place: &lt; PLACE &gt;
</equation>
<bodyText confidence="0.9998312">
If the closest case component is an optional case
(case-4), it cannot be used to prune case frames
by itself. In such a case, we calculate the sim-
ilarity between the definition sentence and the
def-head case frames by the same criteria in Sec-
tion 3.2, and use case frames whose similarity is
0.8 or more.
If there is no case component in the defini-
tion, of course we cannot prune the def-head case
frames.
</bodyText>
<subsectionHeader confidence="0.9992815">
4.2 Alignment of Headword Case
Frames and Def-Head Case Frames
</subsectionHeader>
<bodyText confidence="0.9991545">
Headword case frames and def-head case frames
which survived in the pruning process are
aligned (see Figure 1). For each headword case
frame, we try to find the most similar def-head
case frame and the best correspondences of their
case components. The difference between this
process and the case frame clustering in Sec-
tion 3.2 is that case components can correspond
without case marker agreement in order to allow
case marker transformation in paraphrasing.
The similarity measure between the two case
frames is almost the same as the similarity mea-
sure in Section 3.2. The only difference is the
calculation of the similarity between two case
components. Instead of the formula (2), the fol-
lowing formula is used:
</bodyText>
<equation confidence="0.703213333333333">
C2i) — (6)
Eel Ecli .max{sim(ei &apos;62)162 EC2i
E&amp;quot;Ecli
</equation>
<bodyText confidence="0.9984625">
Probably because a def-head is more general
term than a headword, a case component (case
examples) of a def-head often covers wider se-
mantic range than that of the headword. There-
fore, we do not consider the similarities of all
possible pairs of case examples, but the best cor-
respondence for each case example of the head-
word.
</bodyText>
<sectionHeader confidence="0.979438" genericHeader="introduction">
5 Experiments and Discussion
</sectionHeader>
<subsectionHeader confidence="0.783108">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.999998111111111">
We applied the automatic case frame construc-
tion method to Mainichi Newspaper Corpus and
Nikkei Newspaper Corpus (20 years in total,
15,000,000 sentences). From these corpora, case
frames of about 20,000 verbs are constructed;
the average number of example case frames of
a verb is 16.6; the average number of case slots
of a verb is 2.2; the average number of example
nouns in a case slot is 4.4.
We used the dictionary, Reikai Shaugaktt dic-
tionary for paraphrasing (Tadika, 1997). The
top 2,000 frequent words in definitions of the
dictionary were considered as a basic vocabulary
of Japanese. Other than these basic words, 220
verbs were randomly chosen, and for each verb
a test sentence including the verb was collected
from another dictionary, Shinmeikai dictionary.
We used those 220 sentences as a test set.
</bodyText>
<subsectionHeader confidence="0.992709">
5.2 Experimental Results
</subsectionHeader>
<tableCaption confidence="0.680686666666667">
Table 2 shows the result of word sense disam-
biguation. Out of 220 verbs, 115 verbs have
Table 2: Result of word sense disambiguation.
</tableCaption>
<table confidence="0.99948">
Correct Incorrect Accuracy
Baseline 60 55 52.1 %
Our method 82 33 71.3 %
</table>
<tableCaption confidence="0.994247">
Table 3: Result of verb paraphrase.
</tableCaption>
<table confidence="0.930134444444445">
Test sentences whose sense disambiguation was successful
and those without sense ambiguity.
Correct Incorrect Accuracy
Baseline 163 24 87.1 %
Our method 170 17 90.9 %
Total
Correct Incorrect Accuracy
Baseline 147 73 66.8 %
Our method 170 50 77.2 %
</table>
<bodyText confidence="0.99262238">
word sense ambiguity, that is, they have two or
more definitions. On average one verb has 2.5
definitions.
The accuracy of our method is 71.3% (the de-
tection of equivalent and case marker transfor-
mation are not checked here). The accuracy of
the baseline method which just chooses the first
definition is 52.1%.
In SENSEVAL-2 Japanese dictionary task, and
the accuracy of the participant systems were
75% to 78%, but they were all supervised sys-
tems which used large training data (Shirai,
2001). In SENSEVAL-2 English lexical sample
task, the best accuracy of supervised systems
was 64%, and that of unsupervised systems was
40% (Kilgarriff, 2001). Considering these scores,
we can say the accuracy of our unsupervised
WSD method seems reasonably good. Table
3 shows the accuracy of paraphrasing, indicat-
ing the effectiveness of our method compared
to the baselines. Here, when the equivalent is
properly detected and case markers are properly
changed, if necessary, the analysis was regarded
as correct. Our method could paraphrase 13
sentences correctly in 24 sentences which the
baseline method failed, but failed to paraphrase
6 sentences in the 163 sentences which the base-
line method could paraphrase correctly.
The upper part of Table 3 is the result for test
sentences whose sense disambiguation was suc-
cessful (82 sentences) and those without sense
ambiguity (105 sentences). The baseline re-
garded a def-head alone as the equivalent and
did not change case markers. The lower part
of Table 3 shows the total performance of para-
phrasing of 220 sentences. The baseline means
the same as the above methods.
5.3 Discussion
Table 4 shows examples of successful paraphras-
ing, including examples which properly detect
larger equivalents and transform case markers.
The main cause of incorrect paraphrase is the
data sparseness problem of automatically con-
structed case frames. Since they are constructed
from newspaper corpus, they do not cover daily-
life expressions well. Furthermore, since defini-
tion sentences are sometimes strange from the
view point of standard usage of language, it was
harder to collect def-head case frames than those
of headwords.
</bodyText>
<sectionHeader confidence="0.806205" genericHeader="related work">
5.4 Related Work
</sectionHeader>
<bodyText confidence="0.999254928571429">
Kondou et al. used a dictionary as a knowl-
edge base of paraphrase (Kondo et al., 1999),
but did not handle word sense ambiguity and
case marker transformation.
Takahashi et al. proposed a software envi-
ronment for manual construction of sentential
pattern transformation (Takahashi et al., 2001).
Barzilay et al. pointed out that there are
many paraphrases in a corpus of multiple En-
glish translations of the same source text, and
proposed an unsupervised method of extracting
paraphrases from such
a parallel corpus.(Barzilay and McKeown,
2001)
</bodyText>
<sectionHeader confidence="0.999201" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998653533333333">
This paper proposed a method of translating a
predicate-argument structure of a verb into that
of an equivalent verb, which is a core compo-
nent of the dictionary-based paraphrasing. Our
method grasps several usages of a headword
and those of the def-heads as a form of their
case frames and aligns those case frames, which
means the acquisition of word sense disambigua-
tion rules and the detection of the appropriate
equivalent and case marker transformation.
We are planning to extend our dictionary-
based paraphrasing system to more complicated
phrases and sentences. We also would like to
apply the proposed method to a word selection
task in machine translation.
</bodyText>
<tableCaption confidence="0.993874">
Table 4: Examples of successful paraphrases.
</tableCaption>
<figure confidence="0.860723818181818">
kakageru 1 takakn agern hirokn shirarern yonni snrn
(highly) (raise) (publicly) (make known)
2 kangae ya shntyon wo nosern
(idea) (request) (publish)
3 shinbnn nado ni
(newspaper)
kokki wo kakagern kokki wo takakn agern
(national flag) (national flag) (highly) (raise)
kouryaku 1 teki no jinchi ya shiro wo nban
(enemy) (encampment) (castle) (obtain)
2 aite wo semmete makasn
(opponent) (attack) (defeat)
yokoznna wo konryakn snrn yokoznna wo makasn
(grand champion) (grand champion) (defeat)
tozakeru 1 tookn he hanare sasern
(away) (get)
2 tsnkiawa nakn snrn
(not to get along)
aknynn wo
(bad friend)
narihibiku 1 narn oto ga kikoern
(ring) (sound) (hear)
2 hyonban ga hirokn sirewatarn
(reputation) (widely) (have)
bell ga narihibikn bell no oto ga kikoern
(sound) (hear)
tozakern aknynn to tsnkiawa nakn snrn
(bad friend) (not to get along)
nagabiku zikan ga kakarn
(time) (take)
nagabikn
konsyon ga konsyon ni zikan ga kakarn
(negotiation) (negotiation) (time) (take)
</figure>
<sectionHeader confidence="0.922185" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999198756756757">
Regina Barzilay and Kathleen R. McKeown. 2001.
Extracting paraphrases from a parallel corpus. In
Proceedings of the 39th Annual Meeting of the As-
sociation for Computational Linguistics, pages 50-
57.
Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai,
Akio Yokoo, Hiromi Nakaiwa, Kentarou Ogura,
and Yoshifumi Oyama Yoshihiko Hayashi, editors.
1997. Japanese Lexicon. Iwanami Publishing.
Daisuke Kawahara and Sadao Kurohashi. 2001.
Japanese case frame construction by coupling the
verb and its closest case component. In Proceed-
ings of the Human Language Technology Confer-
ence, pages 204-210.
Adam Kilgarriff. 2001. English lexical sample
task description. In Proceedings of SENSEVAL-
2, pages 17-20.
Keiko Kondo, Satoshi Sato, and Manabu Okumura.
1999. Paraphrasing of &amp;quot;sahen-noun + suru&amp;quot; (in
Japanese). Journal of Information Processing So-
ciety of Japan, 40(11):4064-4074.
Sadao Kurohashi and Makoto Nagao. 1994. A syn-
tactic analysis method of long japanese sentences
based on the detection of conjunctive structures.
Computational Linguistics, 20(4).
Kiyoaki Shirai. 2001. Senseval-2 japanese dictionary
task. In Proceedings of SENSEVAL-2, pages 33-
36.
Jyunichi Tadika, editor. 1997. Reikai Shougaku
Kokugojiten (Japanese dictionary for children).
Sanseido.
Tetsuro Takahashi, Tomoya Iwakura, Ryu Iida, At-
sushi Fujita, and Kentaro Inui. 2001. Kura: A
revision-based lexico-structural paraphrasing en-
gine. In Proceedings of the Natural Language Pro-
cessing Pacific Rim Symposium Post-Conference
Workshop, pages 37-46.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.004043">
<note confidence="0.915639">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), Philadelphia, July 2002, pp. 215-222.</note>
<abstract confidence="0.99696414498934">of be different from that of A (in case of Japanese, case markers might change). This paper proposes a method to solve these problems simultaneously by aligning case frames of A and those of B and C. We utilize wide coverage and specific enough case frames which are automatically constructed from a raw corpus. 2 Dictionary based Paraphrase 2.1 Basic Idea An ordinary dictionary provides us with definitions of headwords in simpler words and expressions. In case of verbs, the head of the definition call it a and the adverb modifying the def-head, if any, are an equivalent of the headword and can be used as a paraphrase it. For example, the definition of (shimmer) is as follows: chiratsuku (shimmer) yowaku hikaru (shine faintly). The def-head, &amp;quot;shine&amp;quot; and its modifier &amp;quot;faintly&amp;quot; be seen as an equivalent of (shimmer), and can be used as a paraphrase as follows: • The lamp shimmers —&gt; The lamp shines faintly 2.2 Difficulties Replacing a headword with the def-head and the adverb, however, does not always work because of the following problems. Word sense ambiguity When a headword has two or more meanings, the meaning of the headword in a given context be chosen. For example, has the following two meanings. keitou (devote) 1 necchuu (be enthusiastic). 2 shitau (admire) If an input is &amp;quot;literature ni keitou-suru (devote to literature)&amp;quot;, the first meaning and the input should be paraphrased into ni If an input is Japanese, postpositions function as case markers and a verb is final in a sentence in definitions and case frames are given in English translation in this paper. &amp;quot;Lincoln ni keitou-suru (devote oneself to Linthe second meaning and the input should be paraphrased into &amp;quot;Lincoln wo shitau (admire Lincoln) &amp;quot; . Size of the equivalent Sometimes, the equivalent of a headword is larger than the def-head and its modifier. For example, as shown below, the equivalent of &amp;quot;taitoku (acquire)&amp;quot; is not &amp;quot;tsukeru (get)&amp;quot;, but &amp;quot;mi ni tsukeru (get for oneself)&amp;quot;. taitoku (acquire) knowledge ya skill wo mi ni tsukeru (get knowledge or skill for oneself). Transformation of case marker When the verb is paraphrased to its equivalent, the sentential pattern (case markers) might have to be modified. For example, when &amp;quot;mistake wo miotosu (overlook a mistake)&amp;quot; is paraphrased by the following definition of &amp;quot;miotosu (overlook)&amp;quot;, &amp;quot;mistake&amp;quot; shoule be transformed from wo case to ni case. miotosu (overlook) kizukanai (not notice). 2.3 Verb Paraphrase based on Case Frame Alignment The problems mentioned above can be solved by finding a correspondence between an input and definitions. However, such a correspondence is very hard to find since predicate-argument structure of the def-head is not fully given in the definition, and the input also contains some omissions. That is, the information is too small to find an appropriate correspondence. example, as shown above, two meanings, but there is no information about its arguments in the dictionary. It is almost impossible to find which definition should be used in what way to paraphrase &amp;quot;literature ni keitousuru (devote oneself to literature)&amp;quot;. Then, we have developed a method which grasps several usages of a headword and those of the def-heads as a form of their case frames and aligns those case frames, which means the acquisition of word sense disambiguation rules and the detection of the appropriate equivalent and case marker transformation. Case frames ga wo Frames of to be enthusiastic ) Frames of to devote ) predicate-argument examples initial case frames he...} {students, children...} {soccer, tennnis...} ga ni ni ni Frames of to admire ) {son, she... } {music} ga ni {she, I...} {president} ga ni Dictionary to devote ) to be enthusiastic ) to admire ) {parent, people...} {art} ga {he, woman...} {computer} ga {child, son...} {mother, father... } ga wo he...} {teacher, professor...} ga I...} to devote ) he...} professor...} to admire ) tsumu ni tsumu { } truck:1 airplane:1 tsumu case frames ni truck wo ni supply wo airplane supply (accumulate) tsumu wo raw corpus parsing tsumu (load) tsumu (load) tsumu (load) wo tsumu (load) truck:1ni wo tsumu } supply:2 airplane:1 tsumu wo F : (load) F : tsumu wo ni {truck:3, airplane:2} {baggage:8} 1.0 0.86 0.91 {supply:10} (load) ities of case examples as follows: c2i) — A/16111621 where lei and 1e21 represent the frequencies of el and e2 respectively. Weighted sum of case component similarities The case components&apos; similarities calculated by the above measure are summed up with the weight of case components&apos; frequencies as follows: WSofCCS = A/IciiIIC2i1..92M(C1 where E Ratio of aligned case components The ratio of aligned case components is calculated as follows: ACC = ELu 1Cli Ic2i Similarity between two case frames Finally, similarity between two case frames is calculated as follows: = W Sof CC S x Rof ACC Based on this similarity measure, case frames whose similarity is more than the threshold, 0.9, are merged. 3.3 Selection of Case Components If a case component whose frequency is much lower than other case components in a case frame, it might be collected because of parsing errors, or has little relation to its verb. We set the threshold for the case component frequency experimentally as follows: x \ of the most frequent case component Table 1: Pruning of def-head case frames Obligatory case (ga, wo, ni) Case-1: book wo read = Case frames whose closest case component is &amp;quot;book&amp;quot;. Case-2: book or article wo read = Case frames whose closest case component is similar to &amp;quot;book&amp;quot; or &amp;quot;article&amp;quot;. Case-3: people ni ask = Case frames whose closest component category&lt; HUMAN &gt;. Optional case Case-4: room de read = Case frames similar to the definition. If the frequency of a case component is less than the threshold, it is discarded. For example, suppose the most frequent case component in a case is 100 times, and the frequency of ni case is 16, ni case is discarded (since it is less than the threshold, 20). 4 Case Frame Alignment This section describes how to align the case frames of a headword and those of the def-heads, resulting in word sense disambiguation and detection of equivalents and case marker transformation. 4.1 Pruning of Def-Head Case Frames When a def-head has sense ambiguity, a part of its case frames corresponds to headword&apos;s case Suppose that a definition wo a book)&amp;quot; and its def-head In the case frame dictiothere are many case frames of &amp;quot;{magazine,article}wo wo the usage of &amp;quot;{mind}wo obviously different from that in the definition. So, that case frame will never correspond to headword&apos;s case frame. If all case frames of the def-head are blindly used, the accuracy of case frame alignment becomes lower. In order to mitigate such a problem, we utilize the definition sentence to prune def-head case frames. The point of this process is similar to the automatic case frame construction in section 3. That is, we exploit the information of the closest case component of the def-head. Table 1 summarizes how to prune def-head case frames. If the closest case component of the def-head is an obligatory case (ga, wo, or ni case), we prune case frames in three ways according to the case component word. If the closest case component of the def-head is an ordinal noun such as &amp;quot;book wo read&amp;quot; (case- 1 of Table 1), the definition is so specific and we need to consider only this usage of the defhead. Therefore, we only use the case frame whose closest case component contains the same word in the next alignment step. If the closest case component has a coordinate structure such as &amp;quot;book or article&amp;quot; (case-2), the definition is not so specific as the previous case, but we probably can limit the usages of the defhead whose closest case component is similar to the conjuncts. Therefore, we use the case frames whose closest case component is very similar to one of conjucts (word similarity is larger than 0.9). If the closest case component is a general term such as &amp;quot;people&amp;quot; (case-3), it specifies the usage of the def-head categorically. We use the case frames whose closest case component belongs to the specified category, that is, has appropriate semantic markers in the NTT thesaurus as follows: people/opponent : &lt; HUMAN &gt; things: &lt; ABSTRACT &gt; place: &lt; PLACE &gt; If the closest case component is an optional case (case-4), it cannot be used to prune case frames by itself. In such a case, we calculate the similarity between the definition sentence and the def-head case frames by the same criteria in Section 3.2, and use case frames whose similarity is 0.8 or more. If there is no case component in the definition, of course we cannot prune the def-head case frames. 4.2 Alignment of Headword Case Frames and Def-Head Case Frames Headword case frames and def-head case frames which survived in the pruning process are aligned (see Figure 1). For each headword case frame, we try to find the most similar def-head case frame and the best correspondences of their case components. The difference between this process and the case frame clustering in Section 3.2 is that case components can correspond without case marker agreement in order to allow case marker transformation in paraphrasing. The similarity measure between the two case frames is almost the same as the similarity measure in Section 3.2. The only difference is the calculation of the similarity between two case components. Instead of the formula (2), the following formula is used: C2i) — (6) Ecli.max{sim(ei EC2i Probably because a def-head is more general term than a headword, a case component (case examples) of a def-head often covers wider semantic range than that of the headword. Therefore, we do not consider the similarities of all possible pairs of case examples, but the best correspondence for each case example of the headword. 5 Experiments and Discussion 5.1 Data We applied the automatic case frame construction method to Mainichi Newspaper Corpus and Nikkei Newspaper Corpus (20 years in total, 15,000,000 sentences). From these corpora, case frames of about 20,000 verbs are constructed; the average number of example case frames of a verb is 16.6; the average number of case slots of a verb is 2.2; the average number of example nouns in a case slot is 4.4. used the dictionary, Shaugaktt dictionary for paraphrasing (Tadika, 1997). The top 2,000 frequent words in definitions of the dictionary were considered as a basic vocabulary of Japanese. Other than these basic words, 220 verbs were randomly chosen, and for each verb a test sentence including the verb was collected another dictionary, We used those 220 sentences as a test set. 5.2 Experimental Results Table 2 shows the result of word sense disambiguation. Out of 220 verbs, 115 verbs have Table 2: Result of word sense disambiguation. Correct Incorrect Accuracy Baseline 60 55 52.1 % Our method 82 33 71.3 % Table 3: Result of verb paraphrase. Test sentences whose sense disambiguation was successful and those without sense ambiguity. Correct Incorrect Accuracy Baseline 163 24 87.1 % Our method 170 17 90.9 % Total Correct Incorrect Accuracy Baseline 147 73 66.8 % Our method 170 50 77.2 % word sense ambiguity, that is, they have two or more definitions. On average one verb has 2.5 definitions. The accuracy of our method is 71.3% (the detection of equivalent and case marker transformation are not checked here). The accuracy of the baseline method which just chooses the first definition is 52.1%. dictionary task, and the accuracy of the participant systems were 75% to 78%, but they were all supervised systems which used large training data (Shirai, In lexical sample task, the best accuracy of supervised systems was 64%, and that of unsupervised systems was 40% (Kilgarriff, 2001). Considering these scores, we can say the accuracy of our unsupervised WSD method seems reasonably good. Table 3 shows the accuracy of paraphrasing, indicating the effectiveness of our method compared to the baselines. Here, when the equivalent is properly detected and case markers are properly changed, if necessary, the analysis was regarded as correct. Our method could paraphrase 13 sentences correctly in 24 sentences which the baseline method failed, but failed to paraphrase 6 sentences in the 163 sentences which the baseline method could paraphrase correctly. The upper part of Table 3 is the result for test sentences whose sense disambiguation was successful (82 sentences) and those without sense ambiguity (105 sentences). The baseline regarded a def-head alone as the equivalent and did not change case markers. The lower part of Table 3 shows the total performance of paraphrasing of 220 sentences. The baseline means the same as the above methods. 5.3 Discussion Table 4 shows examples of successful paraphrasing, including examples which properly detect larger equivalents and transform case markers. The main cause of incorrect paraphrase is the data sparseness problem of automatically constructed case frames. Since they are constructed from newspaper corpus, they do not cover dailylife expressions well. Furthermore, since definition sentences are sometimes strange from the view point of standard usage of language, it was harder to collect def-head case frames than those of headwords. 5.4 Related Work Kondou et al. used a dictionary as a knowledge base of paraphrase (Kondo et al., 1999), but did not handle word sense ambiguity and case marker transformation. Takahashi et al. proposed a software environment for manual construction of sentential pattern transformation (Takahashi et al., 2001). Barzilay et al. pointed out that there are many paraphrases in a corpus of multiple English translations of the same source text, and proposed an unsupervised method of extracting paraphrases from such a parallel corpus.(Barzilay and McKeown, 2001) 6 Conclusion This paper proposed a method of translating a predicate-argument structure of a verb into that of an equivalent verb, which is a core component of the dictionary-based paraphrasing. Our method grasps several usages of a headword and those of the def-heads as a form of their case frames and aligns those case frames, which means the acquisition of word sense disambiguation rules and the detection of the appropriate equivalent and case marker transformation. We are planning to extend our dictionarybased paraphrasing system to more complicated phrases and sentences. We also would like to apply the proposed method to a word selection task in machine translation. Table 4: Examples of successful paraphrases. kakageru 1 takakn agern hirokn shirarern yonni snrn (highly) (raise) (publicly) (make known) ya shntyon wo nosern (publish) (idea) (request) nado (newspaper) kokki wo kakagern kokki wo takakn agern (national flag) (national flag) (highly) (raise) teki no jinchi ya shiro wo nban (enemy) (encampment) (castle) (obtain) wo semmete makasn (opponent) (attack) (defeat) yokoznna wo konryakn snrn yokoznna wo makasn (grand champion) (grand champion) (defeat) tookn he hanare sasern (away) (get) nakn snrn (not to get along) aknynn wo (bad friend) 1 oto ga kikoern (ring) (sound) (hear) ga hirokn sirewatarn (reputation) (widely) (have) bell ga narihibikn bell no oto ga kikoern (sound) (hear) tozakern aknynn to tsnkiawa nakn snrn (bad friend) (not to get along) nagabiku zikan ga kakarn (time) (take) nagabikn konsyon ga (negotiation) zikan ga kakarn (negotiation) (time) (take)</abstract>
<note confidence="0.78253745">References Barzilay and Kathleen R. McKeown. Extracting paraphrases from a parallel corpus. In Proceedings of the 39th Annual Meeting of the Asfor Computational Linguistics, 50- 57. Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio Yokoo, Hiromi Nakaiwa, Kentarou Ogura, and Yoshifumi Oyama Yoshihiko Hayashi, editors. Lexicon. Publishing. Daisuke Kawahara and Sadao Kurohashi. 2001. Japanese case frame construction by coupling the and its closest case component. In Proceedings of the Human Language Technology Confer- 204-210. Adam Kilgarriff. 2001. English lexical sample description. In of SENSEVAL- 17-20. Keiko Kondo, Satoshi Sato, and Manabu Okumura. 1999. Paraphrasing of &amp;quot;sahen-noun + suru&amp;quot; (in</note>
<affiliation confidence="0.4288625">of Information Processing Soof Japan,</affiliation>
<address confidence="0.511279">Sadao Kurohashi and Makoto Nagao. 1994. A syn-</address>
<abstract confidence="0.9917485">tactic analysis method of long japanese sentences based on the detection of conjunctive structures.</abstract>
<note confidence="0.754844384615385">Linguistics, Shirai. 2001. japanese dictionary In of 33- 36. Tadika, editor. 1997. Shougaku Kokugojiten (Japanese dictionary for children). Sanseido. Tetsuro Takahashi, Tomoya Iwakura, Ryu Iida, Atsushi Fujita, and Kentaro Inui. 2001. Kura: A revision-based lexico-structural paraphrasing en- In of the Natural Language Processing Pacific Rim Symposium Post-Conference 37-46.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>50--57</pages>
<contexts>
<context position="14977" citStr="Barzilay and McKeown, 2001" startWordPosition="2498" endWordPosition="2501">s harder to collect def-head case frames than those of headwords. 5.4 Related Work Kondou et al. used a dictionary as a knowledge base of paraphrase (Kondo et al., 1999), but did not handle word sense ambiguity and case marker transformation. Takahashi et al. proposed a software environment for manual construction of sentential pattern transformation (Takahashi et al., 2001). Barzilay et al. pointed out that there are many paraphrases in a corpus of multiple English translations of the same source text, and proposed an unsupervised method of extracting paraphrases from such a parallel corpus.(Barzilay and McKeown, 2001) 6 Conclusion This paper proposed a method of translating a predicate-argument structure of a verb into that of an equivalent verb, which is a core component of the dictionary-based paraphrasing. Our method grasps several usages of a headword and those of the def-heads as a form of their case frames and aligns those case frames, which means the acquisition of word sense disambiguation rules and the detection of the appropriate equivalent and case marker transformation. We are planning to extend our dictionarybased paraphrasing system to more complicated phrases and sentences. We also would lik</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, pages 50-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoru Ikehara</author>
</authors>
<title>Masahiro Miyazaki, Satoshi Shirai, Akio Yokoo, Hiromi Nakaiwa, Kentarou Ogura, and Yoshifumi Oyama Yoshihiko Hayashi, editors.</title>
<date>1997</date>
<publisher>Iwanami Publishing.</publisher>
<marker>Ikehara, 1997</marker>
<rawString>Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio Yokoo, Hiromi Nakaiwa, Kentarou Ogura, and Yoshifumi Oyama Yoshihiko Hayashi, editors. 1997. Japanese Lexicon. Iwanami Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Japanese case frame construction by coupling the verb and its closest case component.</title>
<date>2001</date>
<booktitle>In Proceedings of the Human Language Technology Conference,</booktitle>
<pages>204--210</pages>
<marker>Kawahara, Kurohashi, 2001</marker>
<rawString>Daisuke Kawahara and Sadao Kurohashi. 2001. Japanese case frame construction by coupling the verb and its closest case component. In Proceedings of the Human Language Technology Conference, pages 204-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>English lexical sample task description.</title>
<date>2001</date>
<booktitle>In Proceedings of SENSEVAL2,</booktitle>
<pages>17--20</pages>
<contexts>
<context position="12904" citStr="Kilgarriff, 2001" startWordPosition="2173" endWordPosition="2174">they have two or more definitions. On average one verb has 2.5 definitions. The accuracy of our method is 71.3% (the detection of equivalent and case marker transformation are not checked here). The accuracy of the baseline method which just chooses the first definition is 52.1%. In SENSEVAL-2 Japanese dictionary task, and the accuracy of the participant systems were 75% to 78%, but they were all supervised systems which used large training data (Shirai, 2001). In SENSEVAL-2 English lexical sample task, the best accuracy of supervised systems was 64%, and that of unsupervised systems was 40% (Kilgarriff, 2001). Considering these scores, we can say the accuracy of our unsupervised WSD method seems reasonably good. Table 3 shows the accuracy of paraphrasing, indicating the effectiveness of our method compared to the baselines. Here, when the equivalent is properly detected and case markers are properly changed, if necessary, the analysis was regarded as correct. Our method could paraphrase 13 sentences correctly in 24 sentences which the baseline method failed, but failed to paraphrase 6 sentences in the 163 sentences which the baseline method could paraphrase correctly. The upper part of Table 3 is </context>
</contexts>
<marker>Kilgarriff, 2001</marker>
<rawString>Adam Kilgarriff. 2001. English lexical sample task description. In Proceedings of SENSEVAL2, pages 17-20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keiko Kondo</author>
<author>Satoshi Sato</author>
<author>Manabu Okumura</author>
</authors>
<title>Paraphrasing of &amp;quot;sahen-noun + suru&amp;quot; (in Japanese).</title>
<date>1999</date>
<journal>Journal of Information Processing Society of Japan,</journal>
<pages>40--11</pages>
<contexts>
<context position="14519" citStr="Kondo et al., 1999" startWordPosition="2429" endWordPosition="2432">xamples of successful paraphrasing, including examples which properly detect larger equivalents and transform case markers. The main cause of incorrect paraphrase is the data sparseness problem of automatically constructed case frames. Since they are constructed from newspaper corpus, they do not cover dailylife expressions well. Furthermore, since definition sentences are sometimes strange from the view point of standard usage of language, it was harder to collect def-head case frames than those of headwords. 5.4 Related Work Kondou et al. used a dictionary as a knowledge base of paraphrase (Kondo et al., 1999), but did not handle word sense ambiguity and case marker transformation. Takahashi et al. proposed a software environment for manual construction of sentential pattern transformation (Takahashi et al., 2001). Barzilay et al. pointed out that there are many paraphrases in a corpus of multiple English translations of the same source text, and proposed an unsupervised method of extracting paraphrases from such a parallel corpus.(Barzilay and McKeown, 2001) 6 Conclusion This paper proposed a method of translating a predicate-argument structure of a verb into that of an equivalent verb, which is a</context>
</contexts>
<marker>Kondo, Sato, Okumura, 1999</marker>
<rawString>Keiko Kondo, Satoshi Sato, and Manabu Okumura. 1999. Paraphrasing of &amp;quot;sahen-noun + suru&amp;quot; (in Japanese). Journal of Information Processing Society of Japan, 40(11):4064-4074.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>A syntactic analysis method of long japanese sentences based on the detection of conjunctive structures.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<marker>Kurohashi, Nagao, 1994</marker>
<rawString>Sadao Kurohashi and Makoto Nagao. 1994. A syntactic analysis method of long japanese sentences based on the detection of conjunctive structures. Computational Linguistics, 20(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoaki Shirai</author>
</authors>
<title>Senseval-2 japanese dictionary task.</title>
<date>2001</date>
<booktitle>In Proceedings of SENSEVAL-2,</booktitle>
<pages>33--36</pages>
<contexts>
<context position="12751" citStr="Shirai, 2001" startWordPosition="2150" endWordPosition="2151">3 24 87.1 % Our method 170 17 90.9 % Total Correct Incorrect Accuracy Baseline 147 73 66.8 % Our method 170 50 77.2 % word sense ambiguity, that is, they have two or more definitions. On average one verb has 2.5 definitions. The accuracy of our method is 71.3% (the detection of equivalent and case marker transformation are not checked here). The accuracy of the baseline method which just chooses the first definition is 52.1%. In SENSEVAL-2 Japanese dictionary task, and the accuracy of the participant systems were 75% to 78%, but they were all supervised systems which used large training data (Shirai, 2001). In SENSEVAL-2 English lexical sample task, the best accuracy of supervised systems was 64%, and that of unsupervised systems was 40% (Kilgarriff, 2001). Considering these scores, we can say the accuracy of our unsupervised WSD method seems reasonably good. Table 3 shows the accuracy of paraphrasing, indicating the effectiveness of our method compared to the baselines. Here, when the equivalent is properly detected and case markers are properly changed, if necessary, the analysis was regarded as correct. Our method could paraphrase 13 sentences correctly in 24 sentences which the baseline met</context>
</contexts>
<marker>Shirai, 2001</marker>
<rawString>Kiyoaki Shirai. 2001. Senseval-2 japanese dictionary task. In Proceedings of SENSEVAL-2, pages 33-36.</rawString>
</citation>
<citation valid="true">
<title>Reikai Shougaku Kokugojiten (Japanese dictionary for children).</title>
<date>1997</date>
<editor>Jyunichi Tadika, editor.</editor>
<publisher>Sanseido.</publisher>
<marker>1997</marker>
<rawString>Jyunichi Tadika, editor. 1997. Reikai Shougaku Kokugojiten (Japanese dictionary for children). Sanseido.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuro Takahashi</author>
<author>Tomoya Iwakura</author>
<author>Ryu Iida</author>
<author>Atsushi Fujita</author>
<author>Kentaro Inui</author>
</authors>
<title>Kura: A revision-based lexico-structural paraphrasing engine.</title>
<date>2001</date>
<booktitle>In Proceedings of the Natural Language Processing Pacific Rim Symposium Post-Conference Workshop,</booktitle>
<pages>37--46</pages>
<contexts>
<context position="14727" citStr="Takahashi et al., 2001" startWordPosition="2459" endWordPosition="2462">ically constructed case frames. Since they are constructed from newspaper corpus, they do not cover dailylife expressions well. Furthermore, since definition sentences are sometimes strange from the view point of standard usage of language, it was harder to collect def-head case frames than those of headwords. 5.4 Related Work Kondou et al. used a dictionary as a knowledge base of paraphrase (Kondo et al., 1999), but did not handle word sense ambiguity and case marker transformation. Takahashi et al. proposed a software environment for manual construction of sentential pattern transformation (Takahashi et al., 2001). Barzilay et al. pointed out that there are many paraphrases in a corpus of multiple English translations of the same source text, and proposed an unsupervised method of extracting paraphrases from such a parallel corpus.(Barzilay and McKeown, 2001) 6 Conclusion This paper proposed a method of translating a predicate-argument structure of a verb into that of an equivalent verb, which is a core component of the dictionary-based paraphrasing. Our method grasps several usages of a headword and those of the def-heads as a form of their case frames and aligns those case frames, which means the acq</context>
</contexts>
<marker>Takahashi, Iwakura, Iida, Fujita, Inui, 2001</marker>
<rawString>Tetsuro Takahashi, Tomoya Iwakura, Ryu Iida, Atsushi Fujita, and Kentaro Inui. 2001. Kura: A revision-based lexico-structural paraphrasing engine. In Proceedings of the Natural Language Processing Pacific Rim Symposium Post-Conference Workshop, pages 37-46.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>